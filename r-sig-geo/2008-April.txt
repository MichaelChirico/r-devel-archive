From murray.richardson at utoronto.ca  Tue Apr  1 04:31:17 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Mon, 31 Mar 2008 22:31:17 -0400
Subject: [R-sig-Geo] ogr2ogr for converting postGIS layer to shapefile
In-Reply-To: <e12429640803311209n413db72fp1ff9c87d43d0dfea@mail.gmail.com>
References: <47F11791.1040701@utoronto.ca>	
	<e12429640803311107w1df052a6pa1613786bf2ce2b@mail.gmail.com>	
	<47F131D6.9040109@utoronto.ca>
	<e12429640803311209n413db72fp1ff9c87d43d0dfea@mail.gmail.com>
Message-ID: <47F19E75.9040205@utoronto.ca>

I am not calling CGAL from R yet - currently I am just using dumping x y 
points from R to alpha shapes in a loosely coupled fashion and then 
reading the results back into R and into a postGIS database.  The alpha 
shapes is a "concave" hull routine.  I need to call the cgal C++ code 
from R and will soon work on that.  I understand it should be possible.

It would be great to have CGAL bindings in R.

Murray



G. Allegri wrote:
> Great, I didn't know it... I just made a rapid try some time ago but
> it failed because I didn't use the ""
>
> I'm sorry for bothering, how are you using R with CGAL?
>
>
> 2008/3/31, Murray Richardson <murray.richardson at utoronto.ca>:
>   
>>  See below. Haven't tried this yet.
>>
>>  Yes that is what CGAL stands for.
>>
>>  Murray
>>
>>
>>
>>
>>
>>
>>  Hi Murray,
>>
>>  Regarding the first question, you can read into R first and then output
>>  it again. You could also call ogr2ogr using a system call like:
>>
>>  system("ogr2ogr normal syntax stuff")
>>
>>  cheers,
>>  Paul
>>
>>
>>
>>  G. Allegri wrote:
>>  > Hi Murray.
>>  > About the first question. As far as I understand, you're working in R
>>  > on a *imported* PostGIS layer (I suppose you use rgdal to do it,
>>  > right?). Then you would need to export it to a shapefile (easily done
>>  > with writeOGR). Why are you considering the use of ogr2ogr? As you
>>  > probably  know, it's a binary callable from a command line, and it's
>>  > not possible (AFAIK) to do it from R...
>>  >
>>  > I dont' understand your second question...
>>  >
>>  >> Or even better could ogr be used to do this directly on a postGIS layer?
>>  >>
>>  > What do you mean?
>>  >
>>  > Giovanni
>>  >
>>  >
>>
>>     
>
>



From tkeitt at gmail.com  Tue Apr  1 06:53:38 2008
From: tkeitt at gmail.com (Tim Keitt)
Date: Tue, 1 Apr 2008 04:53:38 +0000 (UTC)
Subject: [R-sig-Geo] ogr2ogr for converting postGIS layer to shapefile
References: <47F11791.1040701@utoronto.ca>	
	<e12429640803311107w1df052a6pa1613786bf2ce2b@mail.gmail.com>	
	<47F131D6.9040109@utoronto.ca>
	<e12429640803311209n413db72fp1ff9c87d43d0dfea@mail.gmail.com>
	<47F19E75.9040205@utoronto.ca>
Message-ID: <loom.20080401T045111-916@post.gmane.org>

Murray Richardson <murray.richardson <at> utoronto.ca> writes:

> 
> It would be great to have CGAL bindings in R.
> 

Agreed. This is something I've been contemplating as well.

THK



From giohappy at gmail.com  Tue Apr  1 09:53:57 2008
From: giohappy at gmail.com (G. Allegri)
Date: Tue, 1 Apr 2008 09:53:57 +0200
Subject: [R-sig-Geo] ogr2ogr for converting postGIS layer to shapefile
In-Reply-To: <47F19E75.9040205@utoronto.ca>
References: <47F11791.1040701@utoronto.ca>
	<e12429640803311107w1df052a6pa1613786bf2ce2b@mail.gmail.com>
	<47F131D6.9040109@utoronto.ca>
	<e12429640803311209n413db72fp1ff9c87d43d0dfea@mail.gmail.com>
	<47F19E75.9040205@utoronto.ca>
Message-ID: <e12429640804010053g7890bb8kc1c71743d55e3ed3@mail.gmail.com>

Intereseting work...
I haven't had the time yet to investigate on it but, as I'm not a C++
developer, I was thinking to couple CGAL and R through thei respective
Python bindings for alpha shapes processing. Obviously, it would be
better having a low-level binding... but there's no time to learn
everything! :-)

Giovanni



From Bjarke.Christensen at sydbank.dk  Tue Apr  1 15:38:59 2008
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Tue, 1 Apr 2008 15:38:59 +0200
Subject: [R-sig-Geo] drawing a vector map on top of an aerial photograph
In-Reply-To: <mailman.9.1207044002.18262.r-sig-geo@stat.math.ethz.ch>
Message-ID: <OFFA96554E.0479CB12-ONC125741E.0041E79D-C125741E.004AFB3D@bdpnet.dk>

Hi,

I have a bunch of 256x256 pixel aerial photographs that span a territory
for which I also have simple arcview vector maps. I'd like to be able to
plot these vector maps along with some vector shapes that result from my
calculations, and to use the aerial photos as background.

Roger Bivand has answered a similar question on
http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6178.html - but I can't
seem to get the solution to work. Specifically,
image(readGDAL("image.jpg")) produces an orange-tinted image which
naturally has no coordinates (since it's just a jpeg).

So my problem is firstly, how to attach coordinates to the raster image
when loading it, secondly, how to resample the image up to the same scale
as the vector map, and thirdly, how to 'glue' the tiles together to span
the area being mapped.

Any help would be greatly appreciated!
Bjarke.



From Roger.Bivand at nhh.no  Tue Apr  1 16:44:55 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 1 Apr 2008 16:44:55 +0200 (CEST)
Subject: [R-sig-Geo] drawing a vector map on top of an aerial photograph
In-Reply-To: <OFFA96554E.0479CB12-ONC125741E.0041E79D-C125741E.004AFB3D@bdpnet.dk>
References: <OFFA96554E.0479CB12-ONC125741E.0041E79D-C125741E.004AFB3D@bdpnet.dk>
Message-ID: <Pine.LNX.4.64.0804011626130.21945@reclus.nhh.no>

On Tue, 1 Apr 2008, Bjarke Christensen wrote:

> Hi,
>
> I have a bunch of 256x256 pixel aerial photographs that span a territory
> for which I also have simple arcview vector maps. I'd like to be able to
> plot these vector maps along with some vector shapes that result from my
> calculations, and to use the aerial photos as background.
>
> Roger Bivand has answered a similar question on
> http://tolstoy.newcastle.edu.au/R/e2/help/06/11/6178.html - but I can't
> seem to get the solution to work. Specifically,
> image(readGDAL("image.jpg")) produces an orange-tinted image which
> naturally has no coordinates (since it's just a jpeg).

It is plotting the first band using default heat.colors(), hence the 
orange appearance. If you want three bands, you'll need to add red=, 
green= and blue= arguments to the call to image().

>
> So my problem is firstly, how to attach coordinates to the raster image
> when loading it,

Can you use a format that has the correct coordinates in it already, such 
as Geotiff? Do you know the correct coordinates for the jpeg images? Do 
you know how they are represented in terms of the coordinate reference 
system? If so, something might be possible. Do you, for example have a 
World file for the jpeg, and is it in the same directory - if it was, GDAL 
would use it, see http://www.gdal.org/frmt_jpeg.html. See:

http://www.nps.gov/gis/av3_online/documents/section7/docs/section7_pg3.html

for how you might create one.

> secondly, how to resample the image up to the same scale
> as the vector map,

Doing image() of the correctly configured raster data (with both known 
coordinates and coordinate reference system) makes this easy - just do 
plot(..., add=TRUE) to plot the vector data (providing the coordinate 
reference systems are the same, otherwise use spTransfrom() in rgdal).

> and thirdly, how to 'glue' the tiles together to span
> the area being mapped.

If this is just for display, why not just set xlim= and ylim= in the first 
image(), then do image(..., add=TRUE) to fill in. There are rbind() 
methods for SpatialPixelsDataFrame objects in sp, so you could cast to 
those, or straight to SpatialPointsDataFrame objects, which can then be 
cast back to a SpatialGridDataFrame object when done.

Roger

>
> Any help would be greatly appreciated!
> Bjarke.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jay.douillard at ubc.ca  Tue Apr  1 20:41:44 2008
From: jay.douillard at ubc.ca (Jay Douillard)
Date: Tue, 1 Apr 2008 11:41:44 -0700 (PDT)
Subject: [R-sig-Geo] Exporting the SDF object created in spgwr to ESRI
	shapefile (shp)
In-Reply-To: <8516978.506511207075213326.JavaMail.root@verrazzano>
Message-ID: <14425001.506531207075304211.JavaMail.root@verrazzano>

Hello,

So I have imported a shapefile into R, and ran the gw.cov function. Now I wish to export a sub set of this information back to arcgis for visualization.

1805 variables were created, of which a need 30 or so. I have been trying to just export the SDF with rgdal and writeOGR


writeOGR(gwls$SDF,td, "filename", driver="ESRI Shapefile")

Which results in "Can't parse PROJ.4-style parameter string" is the result

Alternatively I've considered that I could just export a subset of the variables as a dbf, and join it to the original shapefile in arcgis. 

My imported object has a "n_code" column that is my key variable for each polygon. Is there a way to carry this through the gw.cov function so the object generated object still has the id column, which would allow an easy textfile (or dbf) export?


Thanks! 
and please forgive me inexperience with R and spgwr!



From Roger.Bivand at nhh.no  Tue Apr  1 21:16:27 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 1 Apr 2008 21:16:27 +0200 (CEST)
Subject: [R-sig-Geo] Exporting the SDF object created in spgwr to ESRI
 shapefile (shp)
In-Reply-To: <14425001.506531207075304211.JavaMail.root@verrazzano>
References: <14425001.506531207075304211.JavaMail.root@verrazzano>
Message-ID: <Pine.LNX.4.64.0804012055030.26622@reclus.nhh.no>

On Tue, 1 Apr 2008, Jay Douillard wrote:

> Hello,
>
> So I have imported a shapefile into R, and ran the gw.cov function. Now 
> I wish to export a sub set of this information back to arcgis for 
> visualization.

Note that gw.cov() is just an (anti)-proof of concept, and likely tells 
you nothing whatsoever, especially with many variables, very much GIGO.

>
> 1805 variables were created, of which a need 30 or so. I have been 
> trying to just export the SDF with rgdal and writeOGR
>

You asked for the local correlation coefficients, you can set cor=FALSE. 
But you still get the covariance pairs. Subset by matching (or grepping) 
on the names of SDF). How many input variables were there, and why?

>
> writeOGR(gwls$SDF,td, "filename", driver="ESRI Shapefile")
>
> Which results in "Can't parse PROJ.4-style parameter string" is the 
> result

Why td? Do you really want to write to a temporary directory?

Where is the output of traceback()? Where is the output of summary() of 
your input SpatialPolygonsDataFrame object? Is proj4string(gwls$SDF) as it 
should be? Could you set it for x as input object:

proj4string(gwls$SDF) <- CRS(proj4string(x))

What was proj4string(x), was it as it should be? Did you read with 
readOGR() and was there a *.prj file?

>
> Alternatively I've considered that I could just export a subset of the 
> variables as a dbf, and join it to the original shapefile in arcgis.
>
> My imported object has a "n_code" column that is my key variable for 
> each polygon. Is there a way to carry this through the gw.cov function 
> so the object generated object still has the id column, which would 
> allow an easy textfile (or dbf) export?

If the input object was x, why not just say

gwls$SDF$n_code <- x$n_code

unless you are using the fp= argument. If you are, there is no match 
anyway, because your fit points and data points differ.

This looks suspiciously like real estate data mining. GWR generally and GW 
local statistics are (very) thin ice and crucially depend on the bandwidth 
and the actual model of the data. Unless you know your data very well, 
they may be very misleading, I'm afraid. If you do know where apparent 
non-stationarity is coming from, it is better to model it properly.

Roger

>
>
> Thanks!
> and please forgive me inexperience with R and spgwr!
>

Inexperience with R/spgwr isn't a problem, but using GWR as a data mining 
tool is a problem. It isn't proven, really.

> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Melanie.Abecassis at noaa.gov  Wed Apr  2 04:21:49 2008
From: Melanie.Abecassis at noaa.gov (Melanie Abecassis)
Date: Tue, 01 Apr 2008 16:21:49 -1000
Subject: [R-sig-Geo] map projection problem
Message-ID: <47F2EDBD.3090301@noaa.gov>

Hi,
I am unsuccessfully trying to change the map projection  in map function 
of the maps library.

Here is my code :

library(maps)
library(mapdata)
library(mapproj)

map(database = "world", fill = TRUE, col = 1, plot = TRUE,add=F, 
xlim = c(-200,-120), ylim = c(-5,45))
map.axes()

This gives me a map centered on Hawaii.


I now want to have *the same map but in the mercator projection* :

map(database = "world", fill = TRUE, col = 1, plot = TRUE,add=F, 
projection="mercator", xlim = c(-200,-120), ylim = c(-5,45))
map.axes()

And I get a weird map of the US  and parts of Canada only.


Then I tried this :

A=mapproject(c(-200,-120), c(-5,45), projection="mercator")

map(database = "world", fill = TRUE, col = 1, plot = TRUE,add=F, 
projection="mercator", xlim = A$x, ylim = A$y)
map.axes()

which should be the correct way to do this I think, but I get this :
Error in map.poly(database, regions, exact, xlim, ylim, boundary, 
interior,  :
  nothing to draw: all regions out of bounds

Could anyone help me with this ?
Thanks a lot,
Melanie



From Roger.Bivand at nhh.no  Wed Apr  2 09:00:14 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Apr 2008 09:00:14 +0200 (CEST)
Subject: [R-sig-Geo] Recombining polygon shapefiles using maptools
In-Reply-To: <p06230912c411df0e3348@[128.115.92.33]>
References: <p06230912c411df0e3348@[128.115.92.33]>
Message-ID: <Pine.LNX.4.64.0804020840210.28925@reclus.nhh.no>

On Thu, 27 Mar 2008, Don MacQueen wrote:

> I have six polygon shapefiles. Two of them represent my area of
> interest (call them A and B), and the other four (call them C, D, E,
> F) represent holes in the first two.
>
> I would like to create a single object that can be passed to
> spsample() for spatial sampling, such that spsample will place
> samples inside A and B, but not in C, D, E, or F.
>
> I know how to do this by what might be called "brute force" (see below).

Sorry for not replying earlier. For this case, brute force may be the most 
suitable.

>
> The real question is, are there ways to do this more effectively
> using higher level functions?
>

The higher level methods (spCbind() in maptools) are for Polygons objects 
rather than for Polygon objects, because spCbind() expects to cbind two 
lists of Polygons objects and two data frames.

The difficulty here is to find out how to pack and unpack your geometries 
to use checkPolygonsHoles() in maptools. If you can put all your 
geometries into a single Polygons object, checkPolygonsHoles() will return 
a single Polygons object with the holes correctly identified, and that 
will work with spsample. It will, however, treat the sammpled points as 
lying within the same Polygons object, but maybe that doesn't matter.

This is untried:

Do spCbind() on the 5 SpatialPolygonDataFrames after having given the 
constituent Polygons objects unique IDs (spChFIDs() method).

ALL <- spCbind(spCbind(spCbind(spCbind(A, B), C), D), E)

Add a constant vector to the output object, and use it as the IDs= 
argument to unionSpatialPolygons()

ALL$all <- 1
out <- unionSpatialPolygons(as(ALL, "SpatialPolygons"), IDs=ALL$all)

Check out - it may be that the first pass through gpclib will be enough, 
or

out1 <- sapply(slot(out, "polygons"), checkPolygonsHoles)

where out1 will be a list of Polygons object of length

length(slot(out, "polygons"))

If only one, just use spsample() on that (there is a sample.Polygons() 
method), if more than one, build a SpatialPolygons object, and use 
spsample() on that.

Have you considered using the spsurvey package - it is more targetted than 
spsample() methods - or does spsample() meet your needs?

Hope this helps,

Roger

> If there were, it might make for easier to understand scripts, for
> example, or be easier to repeat using different sets of shapefiles
> (the script below doesn't easily generalize, especially if any of the
> shapefiles consist of multiple polygons).
>
> Thanks
> -Don
>
>
>
> Here is my solution; I've run it and it works. I apologize for not
> being able to supply the shapefiles and thus a reproducible example.
>
> Each shapefile consists of a single polygon, and I don't need any of
> the attribute information from the shapefiles.
> This simplifies things, quite a lot, I think.
>
> Extract the single polygon from each, into six separate two column matrices.
>
> # A
> vz1 <- readShapePoly('shapefiles-zones/Zone-TK')
> tmp <- as(vz1 , 'SpatialPolygons')
> tmp <- tmp at polygons[[1]]   ## since I know it has only one polygon
> poly1 <- tmp at Polygons[[1]]@coords  ## a matrix of coordinates
>
> ## repeat for additional shapefiles 2 through 6
>
>
> Combine the polygons following the example in ?overlay
>
> ## this example uses only the first three of my polygons
> tmp <- Polygons(
>                 list(Polygon(poly1,hole=FALSE),  # A
>                       Polygon(poly2,hole=FALSE),  # B
>                       Polygon(poly3,hole=TRUE)),  # C
>                 ID=1)
> sr <- SpatialPolygons(list(tmp))
>
>
> plot(sr)
> tmp <- spsample(sr, type='random', n=500)
> points(tmp)  ## looks good!
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Apr  2 10:36:48 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Apr 2008 10:36:48 +0200 (CEST)
Subject: [R-sig-Geo] map projection problem
In-Reply-To: <47F2EDBD.3090301@noaa.gov>
References: <47F2EDBD.3090301@noaa.gov>
Message-ID: <Pine.LNX.4.64.0804021018130.28925@reclus.nhh.no>

On Tue, 1 Apr 2008, Melanie Abecassis wrote:

> Hi,
> I am unsuccessfully trying to change the map projection  in map function
> of the maps library.
>
> Here is my code :
>
> library(maps)
> library(mapdata)
> library(mapproj)
>
> map(database = "world", fill = TRUE, col = 1, plot = TRUE,add=F,
> xlim = c(-200,-120), ylim = c(-5,45))
> map.axes()
>
> This gives me a map centered on Hawaii.
>
>
> I now want to have *the same map but in the mercator projection* :
>
> map(database = "world", fill = TRUE, col = 1, plot = TRUE,add=F,
> projection="mercator", xlim = c(-200,-120), ylim = c(-5,45))
> map.axes()
>
> And I get a weird map of the US  and parts of Canada only.
>

When fill=TRUE, map() actually returns the whole polygon, so you are 
seeing what you asked map() for, that's just the way it works. If you 
don't need fill, it dangles a bit, but only gives you a little more than 
you asked for.

There are two alternatives, one using map which leaves you with the 
continental US and Canada (I'm going to -180 rather than -200):

library(maps)
library(mapproj)
m0 <- map(database = "world", plot = FALSE, fill=TRUE,
  xlim = c(-200,-120), ylim = c(-5,45))
IDs <- sapply(strsplit(m0$names, ":"), function(x) x[1])
library(maptools)
m1 <- map2SpatialPolygons(m0, IDs=IDs, proj4string = CRS("+proj=longlat"))
summary(m1)
library(rgdal)
m2 <- spTransform(m1, CRS("+proj=merc"))
bb <- cbind(c(-180,-120), c(-5,45))
bbSP <- SpatialPoints(bb, proj4string = CRS("+proj=longlat"))
bbmerc <- spTransform(bbSP, CRS("+proj=merc"))
plot(m2, col=1, xlim=bbc[,1], ylim=bbc[,2])
summary(m2)

which gets you there but isn't clipped, or:

library(maptools)
gshhs.c.b <- system.file("share/gshhs_c.b", package="maptools")
g0 <- Rgshhs(gshhs.c.b, xlim=c(180, 240), ylim=c(-5, 45), level=1)
summary(g0$SP)
library(rgdal)
g2 <- spTransform(g0$SP, CRS("+proj=merc"))
plot(g2, col=1)
summary(g2)

using the coarse version of the GSHHS shorelines shipped with maptools. 
Both shrink the bounding box of the object to the actual shorelines.

In both of these cases, the output Mercator coordinates are the true 
coordinates, not the display coordinates used by mapproj.

Hope this helps,

Roger

>
> Then I tried this :
>
> A=mapproject(c(-200,-120), c(-5,45), projection="mercator")
>
> map(database = "world", fill = TRUE, col = 1, plot = TRUE,add=F,
> projection="mercator", xlim = A$x, ylim = A$y)
> map.axes()
>
> which should be the correct way to do this I think, but I get this :
> Error in map.poly(database, regions, exact, xlim, ylim, boundary,
> interior,  :
>  nothing to draw: all regions out of bounds
>
> Could anyone help me with this ?
> Thanks a lot,
> Melanie
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Wed Apr  2 11:10:04 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 02 Apr 2008 11:10:04 +0200
Subject: [R-sig-Geo] mdf files
Message-ID: <47F34D6C.70807@ija.csic.es>

Has anyone imported mdf files from IMPS4.1 
(http://www.census.gov/ipc/www/imps/index.html) or
know of any tool for this?

I've been browsing the files, writing the R function
does not seem too
difficult but wanted to make sure that the tool
does not exist yet.

Thanks

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Wed Apr  2 11:26:33 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Apr 2008 11:26:33 +0200 (CEST)
Subject: [R-sig-Geo] mdf files
In-Reply-To: <47F34D6C.70807@ija.csic.es>
References: <47F34D6C.70807@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0804021120580.28925@reclus.nhh.no>

On Wed, 2 Apr 2008, Agustin Lobo wrote:

> Has anyone imported mdf files from IMPS4.1
> (http://www.census.gov/ipc/www/imps/index.html) or
> know of any tool for this?
>
> I've been browsing the files, writing the R function
> does not seem too
> difficult but wanted to make sure that the tool
> does not exist yet.

Not as far as I know. Since both the *.map and the *.mdf are ASCII, it 
certainly looks possible, and seems to fit into the Polygons/Polygon 
object structure well. Would you consider contributing an interface tool 
to maptools?

Roger

>
> Thanks
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From vanessa.stelzenmuller at cefas.co.uk  Wed Apr  2 11:31:57 2008
From: vanessa.stelzenmuller at cefas.co.uk (Vanessa Stelzenmuller (Cefas))
Date: Wed, 2 Apr 2008 10:31:57 +0100
Subject: [R-sig-Geo] question about regression kriging
Message-ID: <04A370231C10664C88B28D1EF74F487935F3C6@LOWEXPRESS.corp.cefas.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080402/7f4a300a/attachment.pl>

From Roger.Bivand at nhh.no  Wed Apr  2 11:53:10 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Apr 2008 11:53:10 +0200 (CEST)
Subject: [R-sig-Geo] Recombining polygon shapefiles using maptools
In-Reply-To: <Pine.LNX.4.64.0804020840210.28925@reclus.nhh.no>
References: <p06230912c411df0e3348@[128.115.92.33]>
	<Pine.LNX.4.64.0804020840210.28925@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0804021152060.28925@reclus.nhh.no>

On Wed, 2 Apr 2008, Roger Bivand wrote:

> On Thu, 27 Mar 2008, Don MacQueen wrote:
>
>> I have six polygon shapefiles. Two of them represent my area of
>> interest (call them A and B), and the other four (call them C, D, E,
>> F) represent holes in the first two.
>>
>> I would like to create a single object that can be passed to
>> spsample() for spatial sampling, such that spsample will place
>> samples inside A and B, but not in C, D, E, or F.
>>
>> I know how to do this by what might be called "brute force" (see below).
>
> Sorry for not replying earlier. For this case, brute force may be the most
> suitable.
>
>>
>> The real question is, are there ways to do this more effectively
>> using higher level functions?
>>
>
> The higher level methods (spCbind() in maptools) are for Polygons objects
> rather than for Polygon objects, because spCbind() expects to cbind two
> lists of Polygons objects and two data frames.
>
> The difficulty here is to find out how to pack and unpack your geometries
> to use checkPolygonsHoles() in maptools. If you can put all your
> geometries into a single Polygons object, checkPolygonsHoles() will return
> a single Polygons object with the holes correctly identified, and that
> will work with spsample. It will, however, treat the sammpled points as
> lying within the same Polygons object, but maybe that doesn't matter.
>
> This is untried:
>
> Do spCbind() on the 5 SpatialPolygonDataFrames after having given the
> constituent Polygons objects unique IDs (spChFIDs() method).
>
> ALL <- spCbind(spCbind(spCbind(spCbind(A, B), C), D), E)

Certainly untried - not spCbind() methods, but, of course, spRbind() 
methods to bind the *rows*, sorry.

Roger

>
> Add a constant vector to the output object, and use it as the IDs=
> argument to unionSpatialPolygons()
>
> ALL$all <- 1
> out <- unionSpatialPolygons(as(ALL, "SpatialPolygons"), IDs=ALL$all)
>
> Check out - it may be that the first pass through gpclib will be enough,
> or
>
> out1 <- sapply(slot(out, "polygons"), checkPolygonsHoles)
>
> where out1 will be a list of Polygons object of length
>
> length(slot(out, "polygons"))
>
> If only one, just use spsample() on that (there is a sample.Polygons()
> method), if more than one, build a SpatialPolygons object, and use
> spsample() on that.
>
> Have you considered using the spsurvey package - it is more targetted than
> spsample() methods - or does spsample() meet your needs?
>
> Hope this helps,
>
> Roger
>
>> If there were, it might make for easier to understand scripts, for
>> example, or be easier to repeat using different sets of shapefiles
>> (the script below doesn't easily generalize, especially if any of the
>> shapefiles consist of multiple polygons).
>>
>> Thanks
>> -Don
>>
>>
>>
>> Here is my solution; I've run it and it works. I apologize for not
>> being able to supply the shapefiles and thus a reproducible example.
>>
>> Each shapefile consists of a single polygon, and I don't need any of
>> the attribute information from the shapefiles.
>> This simplifies things, quite a lot, I think.
>>
>> Extract the single polygon from each, into six separate two column matrices.
>>
>> # A
>> vz1 <- readShapePoly('shapefiles-zones/Zone-TK')
>> tmp <- as(vz1 , 'SpatialPolygons')
>> tmp <- tmp at polygons[[1]]   ## since I know it has only one polygon
>> poly1 <- tmp at Polygons[[1]]@coords  ## a matrix of coordinates
>>
>> ## repeat for additional shapefiles 2 through 6
>>
>>
>> Combine the polygons following the example in ?overlay
>>
>> ## this example uses only the first three of my polygons
>> tmp <- Polygons(
>>                 list(Polygon(poly1,hole=FALSE),  # A
>>                       Polygon(poly2,hole=FALSE),  # B
>>                       Polygon(poly3,hole=TRUE)),  # C
>>                 ID=1)
>> sr <- SpatialPolygons(list(tmp))
>>
>>
>> plot(sr)
>> tmp <- spsample(sr, type='random', n=500)
>> points(tmp)  ## looks good!
>>
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Thierry.ONKELINX at inbo.be  Wed Apr  2 11:55:54 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 2 Apr 2008 11:55:54 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <04A370231C10664C88B28D1EF74F487935F3C6@LOWEXPRESS.corp.cefas.co.uk>
References: <04A370231C10664C88B28D1EF74F487935F3C6@LOWEXPRESS.corp.cefas.co.uk>
Message-ID: <2E9C414912813E4EB981326983E0A10404942F5C@inboexch.inbo.be>

Dear Vanessa,

What residuals did you use? The ones in the original scale or in the logit scale? Interpolate the residuals in the logit scale and add these to the model predictions in the logit scale. And the transform those values back to the original scale. This will prevent values outside the 0-1 range.

Maybe you should have a loot at the geoRglm package.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Vanessa Stelzenmuller (Cefas)
Verzonden: woensdag 2 april 2008 11:32
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] question about regression kriging

Hello,



We work on the application of regression kriging to presence / absence data in the context of species distribution modelling. In R in a first step we fit the trend surfaces with logistic regression models. Then we fit a variogram to the regression residuals and interpolate the residuals with OK. Now we face the situation that when combining trend surfaces with residual surfaces for some locations our occurrence probability is <0 or >1. Thus taking into account the spatial structure of the data (residuals)  has the potential to convert a predicted high occurrence probability into a low occurrence probability or vice versa. Are there some restriction for presence/ absence data for this approach? How to deal with these estimations (<0 and >1)?



Many thanks

Vanessa  





________________________________

Dr. Vanessa Stelzenm?ller

Marine Scientist (GIS), CEFAS

Pakefield Road, Lowestoft, NR33 0HT, UK



Tel.: +44 (0)1502 527779



www.cefas.co.uk





***********************************************************************************
This email and any attachments are intended for the =\ n...{{dropped:3}}



From Agustin.Lobo at ija.csic.es  Wed Apr  2 13:03:41 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 02 Apr 2008 13:03:41 +0200
Subject: [R-sig-Geo] mdf files
In-Reply-To: <Pine.LNX.4.64.0804021120580.28925@reclus.nhh.no>
References: <47F34D6C.70807@ija.csic.es>
	<Pine.LNX.4.64.0804021120580.28925@reclus.nhh.no>
Message-ID: <47F3680D.1050509@ija.csic.es>

Sure, (if I manage to do it...)
Agus


Roger Bivand escribi?:
> On Wed, 2 Apr 2008, Agustin Lobo wrote:
> 
>> Has anyone imported mdf files from IMPS4.1
>> (http://www.census.gov/ipc/www/imps/index.html) or
>> know of any tool for this?
>>
>> I've been browsing the files, writing the R function
>> does not seem too
>> difficult but wanted to make sure that the tool
>> does not exist yet.
> 
> Not as far as I know. Since both the *.map and the *.mdf are ASCII, it 
> certainly looks possible, and seems to fit into the Polygons/Polygon 
> object structure well. Would you consider contributing an interface tool 
> to maptools?
> 
> Roger
> 
>>
>> Thanks
>>
>> Agus
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From famuvie at alumni.uv.es  Wed Apr  2 16:45:06 2008
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Wed, 02 Apr 2008 16:45:06 +0200
Subject: [R-sig-Geo] readVECT6 temporary failure
Message-ID: <47F39BF2.6080101@alumni.uv.es>


Hello list,

i've been dealing all day with this, and i can't find the problem.
It suddenly begun to happen.

Im working with GRASS 6.2.3 under CygWin, and with R 6.2.2 with the 
latest libraries (in fact, while trying to solve this problem, i removed 
all R versions, and reinstalled the latest. But is still failing).

This is it:
i start GRASS, and open the location i'm working with.
then i start R from GRASS console, load spgrass6 library, and i transfer 
a vector map:

	GRASS> r --no-save
	R> library(spgrass6)
	R> medidas <- readVECT6("medidas")

everything goes fine so far.
but if i try to transfer some other vector map, it fails. In fact, if i 
just try to export a vector map to the temporary directory used by 
readVECT then:

	v.out.ogr input=ejes_1 type=line,boundary 
dsn=/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo olayer=mmtest 
layer=1 format=ESRI_Shapefile

	ERROR 4: Unable to open 
/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.shx or 
/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.SHX.
ERROR 4: Failed to open shapefile 
/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.shp.
It may be corrupt.


	No se puede abrir el origen de datos OGR 
'/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo'



Note that while i tried to write a file called mmtest, the error talks 
about de previously wwritten file: medidas
Besides, i can write fine to any other directory.

So i go see what's going on in there, and i verify that after the first 
transfer is done there remains those files medidas.dbf and medidas.shp, 
which are responsible of the failure, since if i remove them manually, 
the failure stops.

the problem arises only after de use of readVECT6. If i try to export a 
map to that directory it doesn't "hang" the directory.

it looks as if the use of readVECT6 blocked the directory.


Thank you in advance.
Departament d'Estad?stica i Investigaci? Operativa
Universitat de Val?ncia (Estudi General)
Facultat de Matem?tiques, Dr. Moliner 50, 46100 Burjassot, Spain.
(+34) 96 354 3987, fax: (+34) 96 354 3238
e-mail: Facundo.Munoz at uv.es



From Roger.Bivand at nhh.no  Wed Apr  2 16:59:44 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 2 Apr 2008 16:59:44 +0200 (CEST)
Subject: [R-sig-Geo] readVECT6 temporary failure
In-Reply-To: <47F39BF2.6080101@alumni.uv.es>
References: <47F39BF2.6080101@alumni.uv.es>
Message-ID: <Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>

On Wed, 2 Apr 2008, Facundo Mu?oz wrote:

>
> Hello list,
>
> i've been dealing all day with this, and i can't find the problem.
> It suddenly begun to happen.
>
> Im working with GRASS 6.2.3 under CygWin, and with R 6.2.2 with the
> latest libraries (in fact, while trying to solve this problem, i removed
> all R versions, and reinstalled the latest. But is still failing).
>
> This is it:
> i start GRASS, and open the location i'm working with.
> then i start R from GRASS console, load spgrass6 library, and i transfer
> a vector map:
>
> 	GRASS> r --no-save
> 	R> library(spgrass6)
> 	R> medidas <- readVECT6("medidas")
>
> everything goes fine so far.

Is there a stray *.dbf file in the temporary directory? OGR with the ESRI 
Shapefile driver does not like extra *.dbf or other irregularities.

In situations like this, just side-step readVECT6, use 
system("r.out.ogr ...") to an arbitrary directory, and readOGR() from 
there. There are multiple components operating, so complete control is not 
possible, but I have seen problems with stray *.dbf files before that were 
hard to debug.

Roger

> but if i try to transfer some other vector map, it fails. In fact, if i
> just try to export a vector map to the temporary directory used by
> readVECT then:
>
> 	v.out.ogr input=ejes_1 type=line,boundary
> dsn=/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo olayer=mmtest
> layer=1 format=ESRI_Shapefile
>
> 	ERROR 4: Unable to open
> /home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.shx or
> /home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.SHX.
> ERROR 4: Failed to open shapefile
> /home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.shp.
> It may be corrupt.
>
>
> 	No se puede abrir el origen de datos OGR
> '/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo'
>
>
>
> Note that while i tried to write a file called mmtest, the error talks
> about de previously wwritten file: medidas
> Besides, i can write fine to any other directory.
>
> So i go see what's going on in there, and i verify that after the first
> transfer is done there remains those files medidas.dbf and medidas.shp,
> which are responsible of the failure, since if i remove them manually,
> the failure stops.
>
> the problem arises only after de use of readVECT6. If i try to export a
> map to that directory it doesn't "hang" the directory.
>
> it looks as if the use of readVECT6 blocked the directory.
>
>
> Thank you in advance.
> Departament d'Estad?stica i Investigaci? Operativa
> Universitat de Val?ncia (Estudi General)
> Facultat de Matem?tiques, Dr. Moliner 50, 46100 Burjassot, Spain.
> (+34) 96 354 3987, fax: (+34) 96 354 3238
> e-mail: Facundo.Munoz at uv.es
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From greliermathieu at gmail.com  Wed Apr  2 17:54:27 2008
From: greliermathieu at gmail.com (mathieu grelier)
Date: Wed, 2 Apr 2008 17:54:27 +0200
Subject: [R-sig-Geo] dimensions do not match
Message-ID: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080402/a9676d05/attachment.pl>

From Agustin.Lobo at ija.csic.es  Wed Apr  2 22:03:11 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 02 Apr 2008 22:03:11 +0200
Subject: [R-sig-Geo] Test of independency in a contingency table for spatial
	variables
Message-ID: <47F3E67F.7020307@ija.csic.es>

Dear list,

I've classified a set of points according
to two different sets of descriptors (assume
a set of descriptors is biological, the other set environmental) into
N and M classes respectively, thus I have
2 vectors V1 and V2 recording each classification.
I've made a contingency table
conti <- table(V1,V2) of dimensions NxM

summary(conti) provides the chi statistic
to test for independence of both classifications,
but, I suspect, if I'm classifying points
the test should take spatial autocorrelation
into account. Which test would be appropriate?
The idea that comes to my mind is to randomize
the values of the descriptors among the points
and use a Monte Carlo approach. Is there any other
way?

Thanks!

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Tom.Mulholland at dpi.wa.gov.au  Thu Apr  3 06:14:10 2008
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 3 Apr 2008 12:14:10 +0800
Subject: [R-sig-Geo] Colouring hatch lines
Message-ID: <C36843D783908044A2EA05A4E15F84CC0A7244@MAILSVR01.dpi.wa.gov.au>

I might be having finger problems, but I have been unable to get R to
overlay coloured hatching on one of my plots.

This code replicates my problem which I would have thought would have
given me vertical yellow lines.

require(maptools)
require(classInt)
columbus <- readShapePoly(system.file("etc/shapes/columbus.shp",
 package="spdep")[1])
mypal <- c("wheat1", "red3")
f5 <- classIntervals(columbus$CRIME, n=5, style="fisher")
f5Colours <- findColours(f5, mypal)
# or f5Colours <- c("red","green","blue") without classInt
plot(columbus, col = f5Colours)
plot(columbus[which(columbus$HOVAL > 40),], density = 15, angle = 0, add
= TRUE)
plot(columbus[which(columbus$HOVAL > 40),], density = 15, angle = 90,
col = "yellow",add = TRUE)

I am not that well versed with sp:::plot.SpatialPolygons but it looks to
me as if it eventually uses the polygon command which suggests that
'col' will be used for the colour of the hatching if density is given.

Any help would be appreciated as I have exhausted my ideas for keywords
to find any answers to the problem that are already on the list.


I am using
platform       i386-pc-mingw32             
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          2                           
minor          6.2                         
year           2008                        
month          02                          
day            08                          
svn rev        44383                       
language       R                           
version.string R version 2.6.2 (2008-02-08)

Tom Mulholland



From andrex.hoskins at gmail.com  Thu Apr  3 08:42:33 2008
From: andrex.hoskins at gmail.com (Andrew James Hoskins)
Date: Thu, 3 Apr 2008 17:42:33 +1100
Subject: [R-sig-Geo] sum of point values within a grid square
Message-ID: <b9ba56a00804022342i17ac304cn3526133ef9be7566@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080403/dbe73eee/attachment.pl>

From hengl at science.uva.nl  Thu Apr  3 10:04:15 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Thu, 3 Apr 2008 10:04:15 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <2E9C414912813E4EB981326983E0A10404942F5C@inboexch.inbo.be>
Message-ID: <00d901c89561$4f28cf20$3a871291@pcibed193>


I completely agree with Thierry.

Take a look at this also:
https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/003176.html 

The instructions on how to run RK with binary variables in R you can find in sec 4.3.3 (Fig. 4.15)
of my lecture notes.

Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of Environmental Variables. EUR 22904
EN Scientific and Technical Research series, Office for Official Publications of the European
Communities, Luxemburg, 143 pp.
http://bookshop.europa.eu/uri?target=EUB:NOTICE:LBNA22904:EN:HTML 


Tom Hengl
http://spatial-analyst.net 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
ONKELINX, Thierry
Sent: woensdag 2 april 2008 11:56
To: Vanessa Stelzenmuller (Cefas); r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging

Dear Vanessa,

What residuals did you use? The ones in the original scale or in the logit scale? Interpolate the
residuals in the logit scale and add these to the model predictions in the logit scale. And the
transform those values back to the original scale. This will prevent values outside the 0-1 range.

Maybe you should have a loot at the geoRglm package.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality
assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more than asking him to perform a
post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable
answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Vanessa
Stelzenmuller (Cefas)
Verzonden: woensdag 2 april 2008 11:32
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] question about regression kriging

Hello,



We work on the application of regression kriging to presence / absence data in the context of
species distribution modelling. In R in a first step we fit the trend surfaces with logistic
regression models. Then we fit a variogram to the regression residuals and interpolate the residuals
with OK. Now we face the situation that when combining trend surfaces with residual surfaces for
some locations our occurrence probability is <0 or >1. Thus taking into account the spatial
structure of the data (residuals)  has the potential to convert a predicted high occurrence
probability into a low occurrence probability or vice versa. Are there some restriction for
presence/ absence data for this approach? How to deal with these estimations (<0 and >1)?



Many thanks

Vanessa  





________________________________

Dr. Vanessa Stelzenm?ller

Marine Scientist (GIS), CEFAS

Pakefield Road, Lowestoft, NR33 0HT, UK



Tel.: +44 (0)1502 527779



www.cefas.co.uk





***********************************************************************************
This email and any attachments are intended for the =\...{{dropped:8}}



From marcelino.delacruz at upm.es  Thu Apr  3 11:11:59 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 03 Apr 2008 11:11:59 +0200
Subject: [R-sig-Geo] Test of independency in a contingency table for
 spatial variables
In-Reply-To: <47F3E67F.7020307@ija.csic.es>
References: <47F3E67F.7020307@ija.csic.es>
Message-ID: <200804030912.m339C2wd004245@smtp.upm.es>

It seems to me that this can be analysed 
with  Syrjala's test [Syrjala, S. E. 1996, A 
Statistical Test for a Difference between the 
Spatial Distributions of Two Populations. Ecology, 77(1): 75-80]

I have some experimental code to run this test, in case you are interrested.

Regards,

Marcelino




At 22:03 02/04/2008, Agustin Lobo wrote:
>Dear list,
>
>I've classified a set of points according
>to two different sets of descriptors (assume
>a set of descriptors is biological, the other set environmental) into
>N and M classes respectively, thus I have
>2 vectors V1 and V2 recording each classification.
>I've made a contingency table
>conti <- table(V1,V2) of dimensions NxM
>
>summary(conti) provides the chi statistic
>to test for independence of both classifications,
>but, I suspect, if I'm classifying points
>the test should take spatial autocorrelation
>into account. Which test would be appropriate?
>The idea that comes to my mind is to randomize
>the values of the descriptors among the points
>and use a Monte Carlo approach. Is there any other
>way?
>
>Thanks!
>
>--
>Dr. Agustin Lobo
>Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>LLuis Sole Sabaris s/n
>08028 Barcelona
>Spain
>Tel. 34 934095410
>Fax. 34 934110012
>email: Agustin.Lobo at ija.csic.es
>http://www.ija.csic.es/gt/obster
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es



From greliermathieu at gmail.com  Thu Apr  3 16:24:41 2008
From: greliermathieu at gmail.com (mathieu grelier)
Date: Thu, 3 Apr 2008 16:24:41 +0200
Subject: [R-sig-Geo] dimensions do not match
Message-ID: <6d400d3e0804030724u4820b912p94ddc449eff4d7c3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080403/3f5c6359/attachment.pl>

From louzao at cebc.cnrs.fr  Thu Apr  3 16:57:50 2008
From: louzao at cebc.cnrs.fr (LOUZAO)
Date: Thu, 03 Apr 2008 16:57:50 +0200
Subject: [R-sig-Geo] extracting data from raster
In-Reply-To: <6d400d3e0804030724u4820b912p94ddc449eff4d7c3@mail.gmail.com>
References: <6d400d3e0804030724u4820b912p94ddc449eff4d7c3@mail.gmail.com>
Message-ID: <47F4F06E.8090808@cebc.cnrs.fr>

Hello,

I would like to extract data from a raster in R (sst for example) but I 
have two queries for you. The sst data is built in a 0.05dg cell size 
but I would like to extract the data for a 0.15dg cell size. So,

- First, I need to create an empty grid of 0.15dg. I have done it with 
the arcgen () function using the Adehabitat package.
- Second, I need a function to overlap both rasters and extract data 
(the median, maximum and minimum) from the 0.05dg raster to the 0.15dg 
raster. How could I do that? I have been searching but I have found a 
direct function. But I think that it should be done.

Thanks in advance,

Maite

**************************
Maite Louzao Arsuaga
Postdoctoral Researcher

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934 
79360 Villiers-en-Bois, France 
Tel: +33 (0)5.49.09.35.57
Fax: +33 (0)5.49.09.65.26 
http://www.cebc.cnrs.fr/
**************************




________ Information from NOD32 ________
This message was checked by NOD32 Antivirus System for Linux Mail Servers.
http://www.eset.com



From renatagrigorio at yahoo.com.br  Thu Apr  3 18:00:16 2008
From: renatagrigorio at yahoo.com.br (Renata Grigorio)
Date: Thu, 3 Apr 2008 09:00:16 -0700 (PDT)
Subject: [R-sig-Geo] .shp
Message-ID: <242447.50181.qm@web65605.mail.ac4.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080403/0aa4e5a1/attachment.pl>

From Roger.Bivand at nhh.no  Thu Apr  3 19:39:31 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Apr 2008 19:39:31 +0200 (CEST)
Subject: [R-sig-Geo] Colouring hatch lines
In-Reply-To: <C36843D783908044A2EA05A4E15F84CC0A7244@MAILSVR01.dpi.wa.gov.au>
References: <C36843D783908044A2EA05A4E15F84CC0A7244@MAILSVR01.dpi.wa.gov.au>
Message-ID: <Pine.LNX.4.64.0804031937160.527@reclus.nhh.no>

On Thu, 3 Apr 2008, Mulholland, Tom wrote:

> I might be having finger problems, but I have been unable to get R to
> overlay coloured hatching on one of my plots.
>
> This code replicates my problem which I would have thought would have
> given me vertical yellow lines.
>
> require(maptools)
> require(classInt)
> columbus <- readShapePoly(system.file("etc/shapes/columbus.shp",
> package="spdep")[1])
> mypal <- c("wheat1", "red3")
> f5 <- classIntervals(columbus$CRIME, n=5, style="fisher")
> f5Colours <- findColours(f5, mypal)
> # or f5Colours <- c("red","green","blue") without classInt
> plot(columbus, col = f5Colours)
> plot(columbus[which(columbus$HOVAL > 40),], density = 15, angle = 0, add
> = TRUE)
> plot(columbus[which(columbus$HOVAL > 40),], density = 15, angle = 90,
> col = "yellow",add = TRUE)
>
> I am not that well versed with sp:::plot.SpatialPolygons but it looks to
> me as if it eventually uses the polygon command which suggests that
> 'col' will be used for the colour of the hatching if density is given.

Thanks for a very clear report. As things stand, the plot method for sp 
objects does not pass the col= argument through if density= is given. I'll 
try to fix this for the next release.

Roger

>
> Any help would be appreciated as I have exhausted my ideas for keywords
> to find any answers to the problem that are already on the list.
>
>
> I am using
> platform       i386-pc-mingw32
> arch           i386
> os             mingw32
> system         i386, mingw32
> status
> major          2
> minor          6.2
> year           2008
> month          02
> day            08
> svn rev        44383
> language       R
> version.string R version 2.6.2 (2008-02-08)
>
> Tom Mulholland
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Apr  3 20:50:40 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Apr 2008 20:50:40 +0200 (CEST)
Subject: [R-sig-Geo] sum of point values within a grid square
In-Reply-To: <b9ba56a00804022342i17ac304cn3526133ef9be7566@mail.gmail.com>
References: <b9ba56a00804022342i17ac304cn3526133ef9be7566@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0804032047540.527@reclus.nhh.no>

On Thu, 3 Apr 2008, Andrew James Hoskins wrote:

> Hi all,
>
> I'm trying to get the sum of value z for all points that fall within a grid
> square.  I've been trying to use the overlay function on a grid converted to
> polygons, however, it returns the sum of the coordinates and the z values,
> how can I have it return only the sum of z?
> Also, once I have the sum of z how then can I assign that to it's
> corresponding grid square?
>
> ## Example code
>
> g <- GridTopology(c(-10,-10), c(1,1), c(21,21))
> g.poly <- as(g, "SpatialPolygons")
>
> x <- c(1:10,1:10)
> y <- c(10:1,10:1)
> z <- 1:20
>
> xyz <- SpatialPointsDataFrame(cbind(x,y),data.frame(z))
>
> ol <- overlay(xyz, g.poly, fn=sum)

This is quite a long way round. Something like:

SG <- SpatialGrid(g)
ol <- overlay(SG, xyz)
z_agg <- aggregate(xyz$z, list(ol=ol), sum)
names(z_agg)
n <- nrow(coordinates(SG))
df <- data.frame(z=rep(NA, n))
df$z[z_agg$ol] <- z_agg$x
SGDF <- SpatialGridDataFrame(g, data=df)
image(SGDF)

gets you there without having to create polygons, and aggregate() is a 
pretty flexible function. Check the ol vector for NAs, though.

Roger

>
>
> Thanks in advance.
>
> Andrew.
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Apr  3 21:03:42 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Apr 2008 21:03:42 +0200 (CEST)
Subject: [R-sig-Geo] .shp
In-Reply-To: <242447.50181.qm@web65605.mail.ac4.yahoo.com>
References: <242447.50181.qm@web65605.mail.ac4.yahoo.com>
Message-ID: <Pine.LNX.4.64.0804032053500.527@reclus.nhh.no>

On Thu, 3 Apr 2008, Renata Grigorio wrote:

> I'm trying to do an application thatread a file.shp in a server by 
> Rserve, but I didn??t. Can you give me asugestion to do this?

The answer is no. The R lists have a posting guide, which says that if you 
do not give a simple, working example of your problem, you should not 
expect an answer. If you send a script with a couple of commands 
illustrating your problem, someone will try to help.

For the time being, forget Rserve, try to make the script work at the 
command line. There may not be anyone at all who uses Rserve for spatial 
data - all such interfaces, like (D)COM, have trouble with rich objects. 
Unless you have reflected the R class used to read the shapefile into your 
target language, you have no easy access to its contents, and the same 
applies in the other direction too. As you know, you read shapefiles best 
in R by:

library(rgdal)
shp <- readOGR(dsn="...", layer="...")

where shp is a Spatial*DataFrame defined in the sp package. But that is on 
the R side of the interface, not on the foreign language side. You need to 
say what you actually need to do, and to think through what data needs to 
be on which side. You could just as will use GDAL/OGR bindings in your 
foreign language and extract the data of interest there.

A long no, but there you go.

Roger

>
> Thank you
>
>
>
>
> para armazenamento!
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From famuvie at alumni.uv.es  Fri Apr  4 09:46:04 2008
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Fri, 04 Apr 2008 09:46:04 +0200
Subject: [R-sig-Geo] readVECT6 temporary failure
In-Reply-To: <Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>
References: <47F39BF2.6080101@alumni.uv.es>
	<Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>
Message-ID: <47F5DCBC.1060906@alumni.uv.es>



Roger Bivand escribi?:
> On Wed, 2 Apr 2008, Facundo Mu?oz wrote:
>
>>
>> Hello list,
>>
>> i've been dealing all day with this, and i can't find the problem.
>> It suddenly begun to happen.
>>
>> Im working with GRASS 6.2.3 under CygWin, and with R 6.2.2 with the
>> latest libraries (in fact, while trying to solve this problem, i removed
>> all R versions, and reinstalled the latest. But is still failing).
>>
>> This is it:
>> i start GRASS, and open the location i'm working with.
>> then i start R from GRASS console, load spgrass6 library, and i transfer
>> a vector map:
>>
>>     GRASS> r --no-save
>>     R> library(spgrass6)
>>     R> medidas <- readVECT6("medidas")
>>
>> everything goes fine so far.
>
> Is there a stray *.dbf file in the temporary directory? OGR with the 
> ESRI Shapefile driver does not like extra *.dbf or other irregularities.
>
> In situations like this, just side-step readVECT6, use 
> system("r.out.ogr ...") to an arbitrary directory, and readOGR() from 
> there. There are multiple components operating, so complete control is 
> not possible, but I have seen problems with stray *.dbf files before 
> that were hard to debug.
>
> Roger

No, i made sure to clean things: I even erased de whole directory and 
let GRASS create it again when he needed it.
Any way, the alternate way is easy and works well.
(A curiosity: writeVECT6 keeps working fine)

Thank you very much.
       Facundo.-

-- 
Departament d'Estad?stica i Investigaci? Operativa Universitat de 
Val?ncia (Estudi General)
Facultat de Matem?tiques, Dr. Moliner 50, 46100 Burjassot, Spain.
(+34) 96 354 3987, fax: (+34) 96 354 3238
e-mail: Facundo.Munoz at uv.es, web: http://www.uv.es/~famarmu/



From famuvie at alumni.uv.es  Fri Apr  4 09:58:34 2008
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Fri, 04 Apr 2008 09:58:34 +0200
Subject: [R-sig-Geo] readVECT6 temporary failure
In-Reply-To: <47F5DCBC.1060906@alumni.uv.es>
References: <47F39BF2.6080101@alumni.uv.es>	<Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>
	<47F5DCBC.1060906@alumni.uv.es>
Message-ID: <47F5DFAA.8080209@alumni.uv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080404/79c82ab1/attachment.pl>

From Roger.Bivand at nhh.no  Fri Apr  4 11:55:25 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 4 Apr 2008 11:55:25 +0200 (CEST)
Subject: [R-sig-Geo] readVECT6 temporary failure
In-Reply-To: <47F5DFAA.8080209@alumni.uv.es>
References: <47F39BF2.6080101@alumni.uv.es>
	<Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>
	<47F5DCBC.1060906@alumni.uv.es> <47F5DFAA.8080209@alumni.uv.es>
Message-ID: <Pine.LNX.4.64.0804041147140.6762@reclus.nhh.no>

On Fri, 4 Apr 2008, Facundo Mu?oz wrote:

> I correct myself:
> when the directory is clean readVECT6 does the job, but leaving a .shp and a 
> .dbf files, who are responsible of the failure in the next readVECT6.
> So the real question would be: why it does leave those trailing files?

The function does try to unlink those files. Are there any spaces in the 
names of the files and directories used, are there any non-ASCII 
characters in the names? Could you please paste everything you see running 
the first time into an email, and attach a screen shot of the terminal 
window too - I guess that this is a path or file name question.

Roger

>
> Greetings!
>       Facundo.-
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From famuvie at alumni.uv.es  Fri Apr  4 12:58:45 2008
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Fri, 04 Apr 2008 12:58:45 +0200
Subject: [R-sig-Geo] readVECT6 temporary failure
In-Reply-To: <Pine.LNX.4.64.0804041147140.6762@reclus.nhh.no>
References: <47F39BF2.6080101@alumni.uv.es>
	<Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>
	<47F5DCBC.1060906@alumni.uv.es> <47F5DFAA.8080209@alumni.uv.es>
	<Pine.LNX.4.64.0804041147140.6762@reclus.nhh.no>
Message-ID: <47F609E5.8010703@alumni.uv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080404/6dd518e0/attachment.pl>

From Roger.Bivand at nhh.no  Fri Apr  4 13:07:46 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 4 Apr 2008 13:07:46 +0200 (CEST)
Subject: [R-sig-Geo] readVECT6 temporary failure
In-Reply-To: <47F609E5.8010703@alumni.uv.es>
References: <47F39BF2.6080101@alumni.uv.es>
	<Pine.LNX.4.64.0804021656020.28925@reclus.nhh.no>
	<47F5DCBC.1060906@alumni.uv.es> <47F5DFAA.8080209@alumni.uv.es>
	<Pine.LNX.4.64.0804041147140.6762@reclus.nhh.no>
	<47F609E5.8010703@alumni.uv.es>
Message-ID: <Pine.LNX.4.64.0804041300210.6762@reclus.nhh.no>

On Fri, 4 Apr 2008, Facundo Mu?oz wrote:

> Roger Bivand escribi?:
>>  On Fri, 4 Apr 2008, Facundo Mu?oz wrote:
>> 
>> >  I correct myself:
>> >  when the directory is clean readVECT6 does the job, but leaving a .shp 
>> >  and a .dbf files, who are responsible of the failure in the next 
>> >  readVECT6.
>> >  So the real question would be: why it does leave those trailing files?
>>
>>  The function does try to unlink those files. Are there any spaces in the
>>  names of the files and directories used, are there any non-ASCII
>>  characters in the names? Could you please paste everything you see running
>>  the first time into an email, and attach a screen shot of the terminal
>>  window too - I guess that this is a path or file name question.
>
> Ok, here is a paste of the GRASS console window, with comments inserted:
>
> Welcome to GRASS 6.2.3 (2007)
> GRASS homepage:                          http://grass.itc.it/
> This version running thru:               GNU Bash (Cygwin) 
> (/usr/bin/bash.exe)
> [...]
> GRASS 6.2.3 (Valencia):~/scr > r --no-save
>
> R version 2.6.2 (2008-02-08)
> Copyright (C) 2008 The R Foundation for Statistical Computing
> [...]
>
>>  library(spgrass6)
> library(spgrass6)
> Loading required package: sp
> Loading required package: rgdal
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.5.0, released 2007/12/18
> GDAL_DATA: c:/Archiv~1/R/R-2.6.2/library/rgdal/gdal
> Loaded PROJ.4 runtime: Rel. 4.6.0, 21 Dec 2007
> PROJ_LIB: c:/Archiv~1/R/R-2.6.2/library/rgdal/proj
>
> Up here is the only path that contains spaces: "Archiv~1" is "Archivos de 
> Programa" (Program Files) in the Windows directory structure.
>
>>  medidas <- readVECT6("medidas")
> Exporting 52 points/lines...
> 100%
> 52 features written
> medidas <- readVECT6("medidas")
> OGR data source with driver: ESRI Shapefile
> Source: "C:\cygwin\home\usuario\grassdata\Valencia\geo_info\.tmp\facundo", 
> layer: "medidas"
> with  52  rows and  11  columns
>
> First transfer completes successfully, but leaves the folowing files in the 
> temporary directory
> C:\cygwin\home\usuario\grassdata\Valencia\geo_info\.tmp\facundo:
> 179.0 (O bytes), medidas.dbf, medidas.shp
> And, if I try to transfer something else...

It could be that the R unlink() is not removing the files, though it is 
removing medidas.shx.

I'll look at this on my Cygwin system, and see if I can find a solution. 
Is your Valencia location very large? Could you make a tarball available 
to try with your data, if it is not too big?

Could you also paste the output of sessionInfo() into an email - perhaps R 
in Windows and cygwin think that they are in different locales? Something 
is affecting unlink() or list.files(), and the list of file names to 
unlink is not being created correctly.

Roger

>
>>  medidas2 <- readVECT6("medidas")
> ERROR 4: Unable to open 
> /home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/m
> edidas.shx or 
> /home/usuario/grassdata/Valencia/geo_info/.tmp/facundo/medidas.SHX
> .
> ERROR 4: Failed to open shapefile 
> /home/usuario/grassdata/Valencia/geo_info/.tmp
> /facundo/medidas.shp.
> It may be corrupt.
>
> Two notes about this error:
> - it is independent of what map I try to transfer. I used the same map for 
> the example, but the same happens for any other map with any other name
> - it's the same error i get if i try to manually export from GRASS any map to 
> that directory.
>
> ERROR:No se puede abrir el origen de datos OGR
>     '/home/usuario/grassdata/Valencia/geo_info/.tmp/facundo'
> medidas2 <- readVECT6("medidas")
> Error en ogrInfo(dsn = dsn, layer = layer) :
>       GDAL Error 4: Unable to open 
> C:\cygwin\home\usuario\grassdata\Valencia\g
> eo_info\.tmp\facundo\medidas.shx or 
> C:\cygwin\home\usuario\grassdata\Valencia\ge
> o_info\.tmp\facundo\medidas.SHX.
> Calls: readVECT6 -> readOGR -> ogrInfo -> .Call
> Ejecuci?n interrumpida
> GRASS 6.2.3 (Valencia):~/scr >
>
> Greetings!
>      Facundo.-
> ---
> Departament d'Estad?stica i Investigaci? Operativa
> Universitat de Val?ncia (Estudi General)
> Facultat de Matem?tiques, Dr. Moliner 50, 46100 Burjassot, Spain.
> (+34) 96 354 3987, fax: (+34) 96 354 3238
> e-mail: Facundo.Munoz at uv.es, web: http://www.uv.es/~famarmu/
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From whatchawhatcha at yahoo.com  Sat Apr  5 07:27:03 2008
From: whatchawhatcha at yahoo.com (K. Grace)
Date: Fri, 4 Apr 2008 22:27:03 -0700 (PDT)
Subject: [R-sig-Geo] fancy-ing up a  readShapePoly plot
Message-ID: <751666.92969.qm@web52912.mail.re2.yahoo.com>

Hi,

I am very bad at this!  Anyway, I have plotted my data using readShapePoly and have a lovely outline of a country with 8 geographic regions.  I would like to place a barplot in the center of each region.  I have no idea how to create a barplot without overwriting the readShapePoly plot.
Here is the barplot code I am trying to use:

tN <- table(Ni <- rpois(100, lambda=5))
r <- barplot(tN, col=rainbow(20))
#- type = "h" plotting *is* 'bar'plot
lines(r, tN, type='h', col='red', lwd=2)

Any suggestions are greatly appreciated!  

Thanks,
Kat







      ____________________________________________________________________________________
[[elided Yahoo spam]]



From juliane_struve at yahoo.co.uk  Sat Apr  5 13:20:20 2008
From: juliane_struve at yahoo.co.uk (Juliane Struve)
Date: Sat, 5 Apr 2008 11:20:20 +0000 (GMT)
Subject: [R-sig-Geo] Reading an ArcGIS raster file
Message-ID: <467156.63561.qm@web27209.mail.ukl.yahoo.com>

Dear members,

how can i read and plot an ArcGis raster file? The .aux file contains floating point bathymetry values. I have managed to read and plot a shoreline 
using rgdal, maptools and PBSmapping, but I am stuck now. Any help would be much appreciated.

Regards,

Juliane 
 


      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/



From Roger.Bivand at nhh.no  Sat Apr  5 13:35:36 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 5 Apr 2008 13:35:36 +0200 (CEST)
Subject: [R-sig-Geo] Reading an ArcGIS raster file
In-Reply-To: <467156.63561.qm@web27209.mail.ukl.yahoo.com>
References: <467156.63561.qm@web27209.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.64.0804051328560.13432@reclus.nhh.no>

On Sat, 5 Apr 2008, Juliane Struve wrote:

> Dear members,
>
> how can i read and plot an ArcGis raster file? The .aux file contains 
> floating point bathymetry values. I have managed to read and plot a 
> shoreline using rgdal, maptools and PBSmapping, but I am stuck now. Any 
> help would be much appreciated.

?readGDAL perhaps? What other files do you have, just an *.aux? Is this a 
PCI *.aux file where the real file is *?

Which OS (Windows I guess)?

By the way, ther is no "aux" on:

http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?TopicName=Supported_raster_dataset_file_formats

Roger

>
> Regards,
>
> Juliane
>
>
>
>      ___________________________________________________________
> Yahoo! For Good helps you make a difference
>
> http://uk.promotions.yahoo.com/forgood/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From giohappy at gmail.com  Sat Apr  5 14:08:13 2008
From: giohappy at gmail.com (G. Allegri)
Date: Sat, 5 Apr 2008 14:08:13 +0200
Subject: [R-sig-Geo] Reading an ArcGIS raster file
In-Reply-To: <Pine.LNX.4.64.0804051328560.13432@reclus.nhh.no>
References: <467156.63561.qm@web27209.mail.ukl.yahoo.com>
	<Pine.LNX.4.64.0804051328560.13432@reclus.nhh.no>
Message-ID: <e12429640804050508o8eac54cr14a4de2a8c6d7aab@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080405/3638794f/attachment.pl>

From juliane_struve at yahoo.co.uk  Sat Apr  5 19:04:38 2008
From: juliane_struve at yahoo.co.uk (Juliane Struve)
Date: Sat, 5 Apr 2008 17:04:38 +0000 (GMT)
Subject: [R-sig-Geo] Reading an ArcGIS raster file
Message-ID: <552982.62108.qm@web27208.mail.ukl.yahoo.com>

Hello Giovanni,

thank you very much for your helpful comments. I have just started working on this project and my experience on the data structure and files both in ArcGIS and R are yet limited. I will try to export the relevant data file as you suggested.

Best wishes,

Juliane 

 
Dr. Juliane Struve
Adjunct Environmental Scientist
Mote Marine Laboratory
Center for Fisheries Enhancement
1600 Ken Thomson Parkway
Sarasota, Florida, 34236
(941)388-4441 Ext. 408


----- Original Message ----
From: G. Allegri <giohappy at gmail.com>
To: Roger.Bivand at nhh.no
Cc: r-sig-geo at stat.math.ethz.ch; Juliane Struve <juliane_struve at yahoo.co.uk>
Sent: Saturday, 5 April, 2008 8:08:13 AM
Subject: Re: [R-sig-Geo] Reading an ArcGIS raster file

Are you sure you have the data stored in AUX? ArcGIS Desktop uses an AUX
file for images that do not support storing coordinate system information
internally. The image header and AUX file tells ArcMap about the coordinate
system including units and projection.
It happens that AUX files are created also when ArcGIS produce image
pyramids.
I suggest to export your data in Arc/Info Binary Grid, a format easily
handled by GDAL [1] . In this case you have to point gdal to the "hdr.adf"
file (one of the many *.adf files produces while exportiong), which is the
header file.

Giovanni

[http://www.gdal.org/frmt_various.html#AIG]

2008/4/5, Roger Bivand <Roger.Bivand at nhh.no>:
>
> On Sat, 5 Apr 2008, Juliane Struve wrote:
>
> > Dear members,
> >
> > how can i read and plot an ArcGis raster file? The .aux file contains
> > floating point bathymetry values. I have managed to read and plot a
> > shoreline using rgdal, maptools and PBSmapping, but I am stuck now. Any
> > help would be much appreciated.
>
>
> ?readGDAL perhaps? What other files do you have, just an *.aux? Is this a
> PCI *.aux file where the real file is *?
>
> Which OS (Windows I guess)?
>
> By the way, ther is no "aux" on:
>
>
> http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?TopicName=Supported_raster_dataset_file_formats
>
> Roger
>
>
> >
> > Regards,
> >
> > Juliane
> >
> >
> >
> >      ___________________________________________________________
> > Yahoo! For Good helps you make a difference
> >
> > http://uk.promotions.yahoo.com/forgood/
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

    [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/



From giohappy at gmail.com  Sun Apr  6 11:00:24 2008
From: giohappy at gmail.com (G. Allegri)
Date: Sun, 6 Apr 2008 11:00:24 +0200
Subject: [R-sig-Geo] sp package: how to manage gridlines spacing
Message-ID: <e12429640804060200u793a8bc4h3744fc04cb81fb9c@mail.gmail.com>

Is it possible to manage the lines spacing returned from the
gridlines() inside sp package?

Giovanni



From giohappy at gmail.com  Sun Apr  6 11:09:48 2008
From: giohappy at gmail.com (G. Allegri)
Date: Sun, 6 Apr 2008 11:09:48 +0200
Subject: [R-sig-Geo] sp package: how to manage gridlines spacing
In-Reply-To: <e12429640804060200u793a8bc4h3744fc04cb81fb9c@mail.gmail.com>
References: <e12429640804060200u793a8bc4h3744fc04cb81fb9c@mail.gmail.com>
Message-ID: <e12429640804060209t59695e09o9ec43c93b607fcde@mail.gmail.com>

I answer myswelf:
> lines(gridlines(x,easts=pretty(bbox(x)[1,],n=20),norths=pretty(bbox(x)[2,],n=20)))
to create 20 lines. I didn't know the pretty() function...

2008/4/6, G. Allegri <giohappy at gmail.com>:
> Is it possible to manage the lines spacing returned from the
>  gridlines() inside sp package?
>
>  Giovanni
>



From edzer.pebesma at uni-muenster.de  Sun Apr  6 23:03:14 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 06 Apr 2008 23:03:14 +0200
Subject: [R-sig-Geo] sum of point values within a grid square
In-Reply-To: <b9ba56a00804022342i17ac304cn3526133ef9be7566@mail.gmail.com>
References: <b9ba56a00804022342i17ac304cn3526133ef9be7566@mail.gmail.com>
Message-ID: <47F93A92.5010305@uni-muenster.de>

Andrew,

this is a bug; thanks for the clear report.

the code in cvs has it corrected, meaning that the next CRAN release 
should work.

I also noted that fn is ignored for grids; it should work there too, so 
that the lengthy

g.poly <- as(g, "SpatialPolygons")

wouldn't be required. This still needs some work.
--
Edzer

Andrew James Hoskins wrote:
> Hi all,
>
> I'm trying to get the sum of value z for all points that fall within a grid
> square.  I've been trying to use the overlay function on a grid converted to
> polygons, however, it returns the sum of the coordinates and the z values,
> how can I have it return only the sum of z?
> Also, once I have the sum of z how then can I assign that to it's
> corresponding grid square?
>
> ## Example code
>
> g <- GridTopology(c(-10,-10), c(1,1), c(21,21))
> g.poly <- as(g, "SpatialPolygons")
>
> x <- c(1:10,1:10)
> y <- c(10:1,10:1)
> z <- 1:20
>
> xyz <- SpatialPointsDataFrame(cbind(x,y),data.frame(z))
>
> ol <- overlay(xyz, g.poly, fn=sum)
>
>
> Thanks in advance.
>
> Andrew.
>
>
>
>



From edzer.pebesma at uni-muenster.de  Mon Apr  7 12:42:28 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 07 Apr 2008 12:42:28 +0200
Subject: [R-sig-Geo] dimensions do not match
In-Reply-To: <6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>
References: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>	
	<47F93200.3030207@uni-muenster.de>
	<6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>
Message-ID: <47F9FA94.2000900@uni-muenster.de>

Thanks Mathieu, for sending me the data off-line.

If you have a massive data set, you should use kriging within a local 
neighbourhood to prevent forming and inverting a covariance matrix of 
4.3 Gb (24067 records, squared, times 8 bytes per double). You may try 
to convince the author of automap to take care of this, automatically.

When applying local kriging to your data set, I get the error message:

 > k = krige(valeur~1,sitesR,mask_SG,vgm(1, "Exp",300), nmax=30)
[using ordinary kriging]

"chfactor.c", line 130: singular matrix in function LDLfactor()
Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
  LDLfactor

which is usually, and in this case as well, due to duplicate 
observations, try

 > zerodist(sitesR)

Does automap take care of them, and if yes how?
--
Edzer



mathieu grelier wrote:
> Ok, this is the data I use and the commands.
> It is really weird because I use R CMD within grass and I can't
> reproduce exactly the same error message when I follow the commands
> directly in R.
> This is the message I get now :
>
> "memory.c", line 57: can't allocate memory in function m_get()
> Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>         m_get
>
> But, I already had this memory error when working on big datasets.
> In the same way, I looked on the archives to see if this memory
> problem could be solved and I didn't find anything.
>
> Do you know it?
> Thanks.
>
> Mathieu
>
>
> 2008/4/6, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>   
>> Please send me the data as a .RData R data file, along with the steps that
>> led to the error message.
>>  --
>>  Edzer
>>
>>  mathieu grelier wrote:
>>
>>     
>>> A question about a problem already described in this list (
>>>
>>>       
>> https://stat.ethz.ch/pipermail/r-sig-geo/2006-July/001160.html),
>> but I
>>     
>>> didn't find any answer.
>>> I am trying to achieve ordinary kriging using gstat (via the autokrige
>>> package) in GRASS with a big dataset (24067 points).
>>>
>>> After the program removes duplicate data, I get the following same error :
>>> "Error : dimensions do not match: locations 39916 and data 24067"
>>> I don't have any NAs apparently.
>>> Checking logfile, I could see that the error is occurring in the krige
>>> function.
>>>
>>> Is there a known way to fix this problem?
>>> Maybe I can send my data, but I don't send it for now to the list as its
>>> weight is ~1Mo.
>>>
>>> Thanks
>>> Mathieu
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>       
> >



From Friderike.Oehler at fao.org  Mon Apr  7 13:51:14 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Mon, 07 Apr 2008 13:51:14 +0200
Subject: [R-sig-Geo] newbie: spplot/ colour ramps
Message-ID: <1A28265B00AA7E4085BB761555D3FCE8016AF815@hqagex02.fao.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080407/ac88bfc3/attachment.pl>

From giohappy at gmail.com  Mon Apr  7 13:52:41 2008
From: giohappy at gmail.com (G. Allegri)
Date: Mon, 7 Apr 2008 13:52:41 +0200
Subject: [R-sig-Geo] grid has empty column/rows warning
Message-ID: <e12429640804070452k1d935184n2d1f4593d80fc38d@mail.gmail.com>

Hi list,
what does this warning mean?

"Warning in points2grid(points,tolerance):
grid has empty columns/rows in dimension 1"

It gets out when doing an overlay between points and grid
[overlay(grid, pointsdataframe)], with sp package.

I receive a complete list of values for the points, uploaded from the
grid, but I don't know if I have to care about the warning...

Giovanni



From edzer.pebesma at uni-muenster.de  Mon Apr  7 13:57:27 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 07 Apr 2008 13:57:27 +0200
Subject: [R-sig-Geo] grid has empty column/rows warning
In-Reply-To: <e12429640804070452k1d935184n2d1f4593d80fc38d@mail.gmail.com>
References: <e12429640804070452k1d935184n2d1f4593d80fc38d@mail.gmail.com>
Message-ID: <47FA0C27.5030601@uni-muenster.de>

G. Allegri wrote:
> Hi list,
> what does this warning mean?
>
> "Warning in points2grid(points,tolerance):
> grid has empty columns/rows in dimension 1"
>   
That, when forming a grid from points, complete rows/columns are emtpy. 
Dimension 1 is x.
> It gets out when doing an overlay between points and grid
> [overlay(grid, pointsdataframe)], with sp package.
>   
Probably because it converts a SpatialPixels object (points on a grid) 
to the full grid representation.
> I receive a complete list of values for the points, uploaded from the
> grid, but I don't know if I have to care about the warning...
>   
Probably not.
--
Edzer
> Giovanni
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From giohappy at gmail.com  Mon Apr  7 14:05:52 2008
From: giohappy at gmail.com (G. Allegri)
Date: Mon, 7 Apr 2008 14:05:52 +0200
Subject: [R-sig-Geo] grid has empty column/rows warning
In-Reply-To: <47FA0C27.5030601@uni-muenster.de>
References: <e12429640804070452k1d935184n2d1f4593d80fc38d@mail.gmail.com>
	<47FA0C27.5030601@uni-muenster.de>
Message-ID: <e12429640804070505o44b4c59ase0c87ed2039693ee@mail.gmail.com>

Thanks Edzer. It's a sparse grid, indeed. I created it as SpatialPixels.
I won't care... :-)

2008/4/7, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> G. Allegri wrote:
> > Hi list,
> > what does this warning mean?
> >
> > "Warning in points2grid(points,tolerance):
> > grid has empty columns/rows in dimension 1"
> >
> >
> That, when forming a grid from points, complete rows/columns are emtpy.
> Dimension 1 is x.
> > It gets out when doing an overlay between points and grid
> > [overlay(grid, pointsdataframe)], with sp package.
> >
> >
> Probably because it converts a SpatialPixels object (points on a grid) to
> the full grid representation.
> > I receive a complete list of values for the points, uploaded from the
> > grid, but I don't know if I have to care about the warning...
> >
> >
> Probably not.
> --
> Edzer
> > Giovanni
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
>
>



From edzer.pebesma at uni-muenster.de  Mon Apr  7 15:27:02 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 07 Apr 2008 15:27:02 +0200
Subject: [R-sig-Geo] newbie: spplot/ colour ramps
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE8016AF815@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE8016AF815@hqagex02.fao.org>
Message-ID: <47FA2126.7080107@uni-muenster.de>

Oehler, Friderike (AGPP) wrote:
> Dear list members,
>
> I am still struggeling with spplot. Sorry for being that unprofessional, but
> honestly I find the spplot help page quite hard to understand. (Many thanks
> Edzer for the very helpful hint a few days ago.)
>
> 1) My first plot actually works all fine, but the colours seem to loop, i.e.
> the same colour is assigned to level 1 (20, "Immature adults") and 4
> (80,"Egglaying"). Why is that and how can I change it?
>
> ad1942$TYPE<-as.factor(ad1942$TYPE)
> colpal=colorRampPalette(c("yellow","orange","darkred"), bias=1,
> interpolate=("linear"))
> spplot(ad1942, zcol="TYPE", cuts=c(20,30,40,80), legendEntries=c("Immature
> adults","Mature adults","Maturity unknown","Egglaying"),
> col.regions=colpal(nlevels(ad1942$TYPE)), scales=list(draw=TRUE), sp.layout =
> list("sp.polygons", EA)) 
>   
This cannot work, as colpal is not a function. Or is it?
> 2) My second plot also works fine so far: 
>
> arrow=list('SpatialPolygonsRescale', layout.north.arrow(), offset=c(50,15),
> scale=2)
> line1<-list("sp.lines", WE, type="l", col="blue")
> line2<-list("sp.lines", NS, type="l", col="blue") 
> points <- list("sp.points", ad1942, pch=19, col="red", cex=0.8) 
> spplot(EA, zcol='ADM0_CODE', sp.layout=list(points,line1,line2, arrow),
> scales=list(draw=TRUE), xlim=c(30,52), ylim=c(-10,18),
> col.regions='transparent', colorkey=FALSE, main="Reported locust swarms",
> sub="1942") # EA is an imported shape-file as SpatialPolygonsDataFrame
>
> However I would like to add the "TYPE" as z-value to the points again. The
> following does not seem to work. All points are plotted in blue. Any
> suggestions?
>   
That is very hard to see from here.

Please use examples that are reproducible for people on the list. Also 
consider providing simple examples, start with spplot-ing without any 
arguments, then start using arguments and tell us where you got stuck.
--
Edzer
> points <- list("sp.points", ad1942, zcol="TYPE", pch=19,
> col.regions=colpal(nlevels(ad1942$TYPE)), cex=0.8)
>
> MANY THANKS in advance!!!
> Friderike
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Greg.Snow at imail.org  Mon Apr  7 17:54:26 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 7 Apr 2008 09:54:26 -0600
Subject: [R-sig-Geo] fancy-ing up a  readShapePoly plot
In-Reply-To: <751666.92969.qm@web52912.mail.re2.yahoo.com>
References: <751666.92969.qm@web52912.mail.re2.yahoo.com>
Message-ID: <07E228A5BE53C24CAD490193A7381BBBFC47D5@LP-EXCHVS07.CO.IHC.COM>

Look at the subplot function in the TeachingDemos package, one of the
examples shows adding barplots to a map.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of K. Grace
> Sent: Friday, April 04, 2008 11:27 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] fancy-ing up a readShapePoly plot
> 
> Hi,
> 
> I am very bad at this!  Anyway, I have plotted my data using 
> readShapePoly and have a lovely outline of a country with 8 
> geographic regions.  I would like to place a barplot in the 
> center of each region.  I have no idea how to create a 
> barplot without overwriting the readShapePoly plot.
> Here is the barplot code I am trying to use:
> 
> tN <- table(Ni <- rpois(100, lambda=5))
> r <- barplot(tN, col=rainbow(20))
> #- type = "h" plotting *is* 'bar'plot
> lines(r, tN, type='h', col='red', lwd=2)
> 
> Any suggestions are greatly appreciated!  
> 
> Thanks,
> Kat
> 
> 
> 
> 
> 
> 
> 
>       
> ______________________________________________________________
> ______________________
> [[elided Yahoo spam]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 



From mardones.p at gmail.com  Mon Apr  7 22:32:29 2008
From: mardones.p at gmail.com (Pedro Mardones)
Date: Mon, 7 Apr 2008 16:32:29 -0400
Subject: [R-sig-Geo] variogram maps / newbie
Message-ID: <83dca7860804071332k11142ce1v9845984719802f68@mail.gmail.com>

Dear all;
Does anyone knows how to obtain a variogram map using the package geoR?
I was able to obtain these plots using the gstat package but the
results form the variog function are different to those from variogram
function in gstat (I guess that has something to do with the bin and
maximum distance but not sure)
Suggestions will be appreciated
PM



From andrex.hoskins at gmail.com  Tue Apr  8 03:06:09 2008
From: andrex.hoskins at gmail.com (Andrew James Hoskins)
Date: Tue, 8 Apr 2008 11:06:09 +1000
Subject: [R-sig-Geo] sum of point values within a grid square
In-Reply-To: <47F93A92.5010305@uni-muenster.de>
References: <b9ba56a00804022342i17ac304cn3526133ef9be7566@mail.gmail.com>
	<47F93A92.5010305@uni-muenster.de>
Message-ID: <b9ba56a00804071806w7554cf3dxd60d4e15cd04b01f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080408/f8c08a61/attachment.pl>

From Friderike.Oehler at fao.org  Tue Apr  8 10:27:16 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Tue, 08 Apr 2008 10:27:16 +0200
Subject: [R-sig-Geo] newbie: spplot/ colour ramps
Message-ID: <1A28265B00AA7E4085BB761555D3FCE8016AF817@hqagex02.fao.org>

Thanks Edzer, I shall try again:

1) I would like to use spplot to map my factor "TYP" as dots of different
colours, however the resulting plot uses the same colours for the first and
last value (10,40). I guess that my use of the "cuts" argument is wrong, but
I can't find any better: 

LAT <-c(-6.5, -5.5, -9.5, -8.5, -7.5, -6.5, -7.5, -6.5)
LON <-c(31.5, 31.5, 32.5, 32.5, 32.5, 32.5, 33.5, 33.5)
TYP <-c(rep(c(10,20,30,40),2))
a1<- as.data.frame(cbind(LON, LAT, TYP))
coordinates(a1)<- ~ LON + LAT
a1$TYP<-as.factor(a1$TYP)
spplot(a1, zcol="TYP", cuts=c(10,20,30,40), col.regions=heat.colors(4),
scales=list(draw=TRUE))

2) I would then like to overlay these dots over the SpatialPolygonsDataFrame
of an imported shapefile EA:

points <- list("sp.points", a1, zcol="TYP",
cuts=c(10,20,30,40),col.regions=heat.colors(4),pch=19)
spplot(EA, zcol='ADM0_CODE', sp.layout=list(points), scales=list(draw=TRUE),
col.regions='transparent', colorkey=FALSE, xlim=c(31,34), ylim=c(-10,-5))

Does this work? I only get unicoloured dots and am not sure whether this is
due to my problem 1) or whether there is another error.

Very grateful for any help,
Friderike



From famuvie at alumni.uv.es  Tue Apr  8 11:49:23 2008
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Tue, 08 Apr 2008 11:49:23 +0200
Subject: [R-sig-Geo] variogram maps / newbie
In-Reply-To: <83dca7860804071332k11142ce1v9845984719802f68@mail.gmail.com>
References: <83dca7860804071332k11142ce1v9845984719802f68@mail.gmail.com>
Message-ID: <47FB3FA3.9000307@alumni.uv.es>

Hi Pedro,

perhaps if you could paste some sample code, we could talk about 
something more concrete...

I understand that you were able to plot empirical variograms using both 
variog (geoR) and variogram (gstat).

In both of them you control the maximum distance:
   in geoR: using max.dist, or uvec which also allows to define the bins
   in gstat : with cutoff

and the binning: uvec (geoR) and width (gstat).

In despite of this, they will not plot the same empirical variograms 
even if you define the same bins and maximum distance, since variog 
(geoR) places the estimates exactly at the bins limits, while variogram 
(gstat) calculates the mean of the distances of the pairs of 
observations used for each estimate, and places the estimate at that 
precise distance. (Ajjj, i'm sure it can be said better)

In sum: even if you manage to make them calculate the same estimates 
with the same pairs of observations each, you will have the same 
estimates but located at (more or less slightly) different ordinates.

Reagards
      Facundo.-

Pedro Mardones escribi?:
> Dear all;
> Does anyone knows how to obtain a variogram map using the package geoR?
> I was able to obtain these plots using the gstat package but the
> results form the variog function are different to those from variogram
> function in gstat (I guess that has something to do with the bin and
> maximum distance but not sure)
> Suggestions will be appreciated
> PM



From edzer.pebesma at uni-muenster.de  Tue Apr  8 12:29:23 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 08 Apr 2008 12:29:23 +0200
Subject: [R-sig-Geo] newbie: spplot/ colour ramps
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE8016AF817@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE8016AF817@hqagex02.fao.org>
Message-ID: <47FB4903.80800@uni-muenster.de>

Oehler, Friderike (AGPP) wrote:
> Thanks Edzer, I shall try again:
>
> 1) I would like to use spplot to map my factor "TYP" as dots of different
> colours, however the resulting plot uses the same colours for the first and
> last value (10,40). I guess that my use of the "cuts" argument is wrong, but
> I can't find any better: 
>
> LAT <-c(-6.5, -5.5, -9.5, -8.5, -7.5, -6.5, -7.5, -6.5)
> LON <-c(31.5, 31.5, 32.5, 32.5, 32.5, 32.5, 33.5, 33.5)
> TYP <-c(rep(c(10,20,30,40),2))
> a1<- as.data.frame(cbind(LON, LAT, TYP))
> coordinates(a1)<- ~ LON + LAT
> a1$TYP<-as.factor(a1$TYP)
> spplot(a1, zcol="TYP", cuts=c(10,20,30,40), col.regions=heat.colors(4),
> scales=list(draw=TRUE))
>   
I see. The plot looks fine if you omit the cuts=c(...) argument. Why do 
you want to classify using continuous values, when the variable is a factor?
> 2) I would then like to overlay these dots over the SpatialPolygonsDataFrame
> of an imported shapefile EA:
>
> points <- list("sp.points", a1, zcol="TYP",
> cuts=c(10,20,30,40),col.regions=heat.colors(4),pch=19)
> spplot(EA, zcol='ADM0_CODE', sp.layout=list(points), scales=list(draw=TRUE),
> col.regions='transparent', colorkey=FALSE, xlim=c(31,34), ylim=c(-10,-5))
>
> Does this work? I only get unicoloured dots and am not sure whether this is
> due to my problem 1) or whether there is another error.
>   
Try to spplot the points object, and pass the polygon in the sp.layout 
argument.

spplot wraps xyplot or levelplot, both in package lattice. These plots 
can only have a single variable to assign a color scale to, as far as I 
am aware.
--
Edzer



From edzer.pebesma at uni-muenster.de  Tue Apr  8 12:37:28 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 08 Apr 2008 12:37:28 +0200
Subject: [R-sig-Geo] variogram maps / newbie
In-Reply-To: <47FB3FA3.9000307@alumni.uv.es>
References: <83dca7860804071332k11142ce1v9845984719802f68@mail.gmail.com>
	<47FB3FA3.9000307@alumni.uv.es>
Message-ID: <47FB4AE8.8000502@uni-muenster.de>

Facundo,

your explenation is very clear.

When I once tried, In addition I found different numbers of point pairs 
across the two packages; this could be due to classification of point 
pairs with distances exactly on the bin boundary, but I didn't come to a 
conclusive feeling about it, back then.
--
Edzer

Facundo Mu?oz wrote:
> Hi Pedro,
>
> perhaps if you could paste some sample code, we could talk about 
> something more concrete...
>
> I understand that you were able to plot empirical variograms using both 
> variog (geoR) and variogram (gstat).
>
> In both of them you control the maximum distance:
>    in geoR: using max.dist, or uvec which also allows to define the bins
>    in gstat : with cutoff
>
> and the binning: uvec (geoR) and width (gstat).
>
> In despite of this, they will not plot the same empirical variograms 
> even if you define the same bins and maximum distance, since variog 
> (geoR) places the estimates exactly at the bins limits, while variogram 
> (gstat) calculates the mean of the distances of the pairs of 
> observations used for each estimate, and places the estimate at that 
> precise distance. (Ajjj, i'm sure it can be said better)
>
> In sum: even if you manage to make them calculate the same estimates 
> with the same pairs of observations each, you will have the same 
> estimates but located at (more or less slightly) different ordinates.
>
> Reagards
>       Facundo.-
>
> Pedro Mardones escribi?:
>   
>> Dear all;
>> Does anyone knows how to obtain a variogram map using the package geoR?
>> I was able to obtain these plots using the gstat package but the
>> results form the variog function are different to those from variogram
>> function in gstat (I guess that has something to do with the bin and
>> maximum distance but not sure)
>> Suggestions will be appreciated
>> PM
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Agustin.Lobo at ija.csic.es  Tue Apr  8 15:01:50 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 08 Apr 2008 15:01:50 +0200
Subject: [R-sig-Geo] extracting polygons
Message-ID: <47FB6CBE.70005@ija.csic.es>

Dear list,

I want to distribute a set of N circles according to a random distribution
within a set of polygons (N circles within each polygon).

I have an object of class SpatialPolygonsDataFrame with the polygons.

My idea is to use something like:

for (i in 1:length(absUTMpolys at polygons)){
  delme <- runifpoint(3, win=as.owin(absUTMpolys at polygons[i]))
  ...

but I'm not being successful at extracting each polygon and
as.owin refuses the conversion:

I've tried
 > as(absUTMpolys at polygons[1], "owin")
Error in as(absUTMpolys at polygons[1], "owin") :
   no method or default for coercing "list" to "owin"

and
 > as(absUTMpolys at polygons[1][[1]], "owin")
Error in as(absUTMpolys at polygons[1][[1]], "owin") :
   no method or default for coercing "Polygons" to "owin"


which is the proper way
of selecting each polygon from within the SpatialPolygonsDataFrame
object?

Thanks!

Agus


-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From andrew.niccolai at yale.edu  Tue Apr  8 15:09:07 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Tue, 8 Apr 2008 09:09:07 -0400
Subject: [R-sig-Geo] extracting polygons
In-Reply-To: <47FB6CBE.70005@ija.csic.es>
References: <47FB6CBE.70005@ija.csic.es>
Message-ID: <001301c89979$bad08760$30719620$@niccolai@yale.edu>

Try this code from my dataset:

## Read in var crown circular model
crown.shp <-
"C:/Niccolai/01_PhD/Papers/Paper003/GIS_LAYERS/CB_CRLOCS_ADJ_ALL_PREDINT99_B
uffer.shp"
crown.poly <- readShapePoly(crown.shp)
crown.data <-
read.dbf("C:/Niccolai/01_PhD/Papers/Paper003/GIS_LAYERS/CB_CRLOCS_ADJ_ALL_PR
EDINT99_Buffer.dbf")
head(crown.data)

## Visualize the newly created poly object.
plot(crown.poly, col="orange", main="")

crown.super.io <- list(crown.poly[1,])
looplen <- nrow(crown.data)
for ( i in 2:looplen){
i <- list(crown.poly[i,])
crown.super.io <- c(crown.super.io, i)
}

plot(crown.super.io[[1]], col="blue", add=TRUE)

Hope that helps!


Andrew Niccolai
Doctoral Candidate
Yale School of Forestry


 
-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
Sent: Tuesday, April 08, 2008 9:02 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] extracting polygons

Dear list,

I want to distribute a set of N circles according to a random distribution
within a set of polygons (N circles within each polygon).

I have an object of class SpatialPolygonsDataFrame with the polygons.

My idea is to use something like:

for (i in 1:length(absUTMpolys at polygons)){
  delme <- runifpoint(3, win=as.owin(absUTMpolys at polygons[i]))
  ...

but I'm not being successful at extracting each polygon and
as.owin refuses the conversion:

I've tried
 > as(absUTMpolys at polygons[1], "owin")
Error in as(absUTMpolys at polygons[1], "owin") :
   no method or default for coercing "list" to "owin"

and
 > as(absUTMpolys at polygons[1][[1]], "owin")
Error in as(absUTMpolys at polygons[1][[1]], "owin") :
   no method or default for coercing "Polygons" to "owin"


which is the proper way
of selecting each polygon from within the SpatialPolygonsDataFrame
object?

Thanks!

Agus


-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From p.hiemstra at geo.uu.nl  Tue Apr  8 15:43:49 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 08 Apr 2008 15:43:49 +0200
Subject: [R-sig-Geo] Fwd:  dimensions do not match
In-Reply-To: <6d400d3e0804070735w776ae45dx3143cdedde6d3779@mail.gmail.com>
References: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>	
	<47F93200.3030207@uni-muenster.de>	
	<6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>	
	<47F9FA94.2000900@uni-muenster.de>
	<6d400d3e0804070735w776ae45dx3143cdedde6d3779@mail.gmail.com>
Message-ID: <47FB7695.8060705@geo.uu.nl>

Hi Mathieu,

As a default autoKrige deals with duplicate measurements. This is done 
by deleting one of them. It gives a warning message to the user that 
observations have been removed. This behavior can be suppressed by 
setting 'remove.duplicates = FALSE' in the call to autoKrige, now gstat 
will crash with the usual error.

cheers,
Paul

mathieu grelier wrote:
> Ok,
> I've just tried to use zerodist before calling the autoKrige function
> but the error remains the same (memory_c...).
> Did you manage to perform the local kriging? You said there was still an error.
>
> I forward this message to the author of automap.
> I don't know if automap can handle this situation.
> Paul, please could you give us an answer about last question from edzer?
>
> Thanks
> Mathieu
>
> ---------- Forwarded message ----------
> From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> Date: 7 avr. 2008 12:42
> Subject: Re: [R-sig-Geo] dimensions do not match
> To: mathieu grelier <greliermathieu at gmail.com>, r-sig-geo at stat.math.ethz.ch
>
>
> Thanks Mathieu, for sending me the data off-line.
>
>  If you have a massive data set, you should use kriging within a local
> neighbourhood to prevent forming and inverting a covariance matrix of
> 4.3 Gb (24067 records, squared, times 8 bytes per double). You may try
> to convince the author of automap to take care of this, automatically.
>
>  When applying local kriging to your data set, I get the error message:
>
>  > k = krige(valeur~1,sitesR,mask_SG,vgm(1, "Exp",300), nmax=30)
>  [using ordinary kriging]
>
>  "chfactor.c", line 130: singular matrix in function LDLfactor()
>  Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>   LDLfactor
>
>  which is usually, and in this case as well, due to duplicate observations, try
>
>  > zerodist(sitesR)
>
>  Does automap take care of them, and if yes how?
>  --
>  Edzer
>
>
>
>
>  mathieu grelier wrote:
>
>   
>> Ok, this is the data I use and the commands.
>> It is really weird because I use R CMD within grass and I can't
>> reproduce exactly the same error message when I follow the commands
>> directly in R.
>> This is the message I get now :
>>
>> "memory.c", line 57: can't allocate memory in function m_get()
>> Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>>        m_get
>>
>> But, I already had this memory error when working on big datasets.
>> In the same way, I looked on the archives to see if this memory
>> problem could be solved and I didn't find anything.
>>
>> Do you know it?
>> Thanks.
>>
>> Mathieu
>>
>>
>> 2008/4/6, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>>
>>
>>     
>>> Please send me the data as a .RData R data file, along with the steps that
>>> led to the error message.
>>>  --
>>>  Edzer
>>>
>>>  mathieu grelier wrote:
>>>
>>>
>>>
>>>       
>>>> A question about a problem already described in this list (
>>>>
>>>>
>>>>
>>>>         
>>> https://stat.ethz.ch/pipermail/r-sig-geo/2006-July/001160.html),
>>> but I
>>>
>>>
>>>       
>>>> didn't find any answer.
>>>> I am trying to achieve ordinary kriging using gstat (via the autokrige
>>>> package) in GRASS with a big dataset (24067 points).
>>>>
>>>> After the program removes duplicate data, I get the following same error :
>>>> "Error : dimensions do not match: locations 39916 and data 24067"
>>>> I don't have any NAs apparently.
>>>> Checking logfile, I could see that the error is occurring in the krige
>>>> function.
>>>>
>>>> Is there a known way to fix this problem?
>>>> Maybe I can send my data, but I don't send it for now to the list as its
>>>> weight is ~1Mo.
>>>>
>>>> Thanks
>>>> Mathieu
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>>
>>>>
>>>>         
>>>       


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From david.maxwell at cefas.co.uk  Tue Apr  8 15:56:54 2008
From: david.maxwell at cefas.co.uk (David Maxwell (Cefas))
Date: Tue, 8 Apr 2008 14:56:54 +0100
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <04A370231C10664C88B28D1EF74F487935F3D2@LOWEXPRESS.corp.cefas.co.uk>
Message-ID: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>

Hi,

Tom and Thierry, Thank you for your advice, the lecture notes are very useful. We will try geoRglm but for now regression kriging using the working residuals gives sensible answers even though there are some issues with using working residuals, i.e. not Normally distributed, occasional very large values and inv.logit(prediction type="link" + working residual) doesn't quite give the observed values.

Our final question about this is how to estimate standard errors for the regression kriging predictions of the binary variable?

On the logit scale we are using
 rk prediction (s0) = glm prediction (s0) + kriged residual prediction (s0) 
for location s0

Is assuming independence of the two components adequate?
 var rk(s0) ~= var glm prediction (s0) + var kriged residual prediction (s0) 

Thanks again,
David Maxwell & Vanessa Stelzenm?ller

david.maxwell at cefas.co.uk

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Tomislav Hengl
Sent: 03 April 2008 09:04
To: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging


I completely agree with Thierry.

Take a look at this also:
https://stat.ethz.ch/pipermail/r-sig-geo/2008-February/003176.html 

The instructions on how to run RK with binary variables in R you can find in sec 4.3.3 (Fig. 4.15)
of my lecture notes.

Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of Environmental Variables. EUR 22904
EN Scientific and Technical Research series, Office for Official Publications of the European
Communities, Luxemburg, 143 pp.
http://bookshop.europa.eu/uri?target=EUB:NOTICE:LBNA22904:EN:HTML 


Tom Hengl
http://spatial-analyst.net 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
ONKELINX, Thierry
Sent: woensdag 2 april 2008 11:56
To: Vanessa Stelzenmuller (Cefas); r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging

Dear Vanessa,

What residuals did you use? The ones in the original scale or in the logit scale? Interpolate the
residuals in the logit scale and add these to the model predictions in the logit scale. And the
transform those values back to the original scale. This will prevent values outside the 0-1 range.

Maybe you should have a loot at the geoRglm package.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality
assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more than asking him to perform a
post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable
answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Vanessa
Stelzenmuller (Cefas)
Verzonden: woensdag 2 april 2008 11:32
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] question about regression kriging

Hello,



We work on the application of regression kriging to presence / absence data in the context of
species distribution modelling. In R in a first step we fit the trend surfaces with logistic
regression models. Then we fit a variogram to the regression residuals and interpolate the residuals
with OK. Now we face the situation that when combining trend surfaces with residual surfaces for
some locations our occurrence probability is <0 or >1. Thus taking into account the spatial
structure of the data (residuals)  has the potential to convert a predicted high occurrence
probability into a low occurrence probability or vice versa. Are there some restriction for
presence/ absence data for this approach? How to deal with these estimations (<0 and >1)?



Many thanks

Vanessa  





________________________________

Dr. Vanessa Stelzenm?ller

Marine Scientist (GIS), CEFAS

Pakefield Road, Lowestoft, NR33 0HT, UK



Tel.: +44 (0)1502 527779



www.cefas.co.uk





***********************************************************************************
This email and any attachments are intended for the =\...{{dropped:20}}



From Hans.Gardfjell at srh.slu.se  Tue Apr  8 15:58:14 2008
From: Hans.Gardfjell at srh.slu.se (Hans Gardfjell)
Date: Tue, 8 Apr 2008 15:58:14 +0200
Subject: [R-sig-Geo] Importing GML-files
Message-ID: <1B19B5CCE30E1A41A63F856C83DD3D4027B689606E@exmbx2.ad.slu.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080408/5ad33307/attachment.pl>

From Roger.Bivand at nhh.no  Tue Apr  8 16:37:34 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 8 Apr 2008 16:37:34 +0200 (CEST)
Subject: [R-sig-Geo] Importing GML-files
In-Reply-To: <1B19B5CCE30E1A41A63F856C83DD3D4027B689606E@exmbx2.ad.slu.se>
References: <1B19B5CCE30E1A41A63F856C83DD3D4027B689606E@exmbx2.ad.slu.se>
Message-ID: <Pine.LNX.4.64.0804081615190.15213@reclus.nhh.no>

On Tue, 8 Apr 2008, Hans Gardfjell wrote:

> Dear R-SIG readers,
>
> The European Union is promoting the use of open source software and 
> standards. As a R-user that's certainly positive, but it also creates 
> new challenges. One open format that is used by EU is GML, a 
> "geographically XML" format. It's possible to import (or export) a 
> GML-file with ESRI's ArcGIS software, but does anyone of you have any 
> experience importing GML-files into R? Maybe into a 
> spatialPolygonDataframe object (given that the GML contain polygon 
> data)? I have included the beginning of one of the GML-files I'm using 
> below.

GML 2.0 is supported by OGR/GDAL, accessible in R in the rgdal package, if 
the driver is available. On Unix/Linux, and OSX, users get the drivers 
they themselves have built into GDAL/OGR. On Windows, the basic binary 
rgdal package does not include the underlying Xerces DLL. Note that 
writeOGR() can write (export) GML files without Xerces, but will not be 
able to read them.

The rapid alternative for reading GML files is to convert a vector GML 
file to a format for which a driver is available using ogr2ogr from GDAL 
binaries (for example FWTools, http://fwtools.maptools.org/). If there is 
enough interest, or helpers willing to work out how to build Xerces under 
MSyS/MinGW on Windows to link to GDAL/OGR built under MSyS/MinGW on 
Windows, the full GML driver could be made available in the rgdal Windows 
binary package.

So we're half-way for everybody, but reading (importing) will require more 
effort.

Roger

>
> Thanks,
>
> Hans Gardfjell
> Department of Forest Resource Management
> SLU, Sweden
>
>
>
> Example of the beginning of a GML-file:
>
> <?xml version="1.0" encoding="UTF-8"?>
> <gml:FeatureCollection
> xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
> xsi:noNamespaceSchemaLocation="http://biodiversity.eionet.europa.eu/schemas/dir9243eec/gml_art17.xsd"
> xmlns:gml="http://www.opengis.net/gml"
> xmlns:met="http://biodiversity.eionet.europa.eu/schemas/dir9243eec">
> <gml:metaDataProperty>
> <met:info href="map-distribution-9170.gml">
> <met:mapOwner label="Owner of the map">
> <met:organisationName label="Organisation name"></met:organisationName>
> ***
> Some Metadata removed
> ***
> </met:datasetsRetrievedFrom><met:projection label="ESRI projection metadata">PROJCS[&quot;ETRS_1989_LAEA&quot;,GEOGCS[&quot;GCS_ETRS_1989&quot;,DATUM[&quot;D_ETRS_1989&quot;,SPHEROID[&quot;GRS_1980&quot;,6378137.0,298.257222101]],PRIMEM[&quot;Greenwich&quot;,0.0],UNIT[&quot;Degree&quot;,0.0174532925199433]],PROJECTION[&quot;Lambert_Azimuthal_Equal_Area&quot;],PARAMETER[&quot;False_Easting&quot;,4321000.0],PARAMETER[&quot;False_Northing&quot;,3210000.0],PARAMETER[&quot;Central_Meridian&quot;,10.0],PARAMETER[&quot;Latitude_Of_Origin&quot;,52.0],UNIT[&quot;Meter&quot;,1.0]]</met:projection>
> </met:info>
> </gml:metaDataProperty>
> <gml:boundedBy>
> <gml:Envelope>
> <gml:coord>
> <gml:X>4500000.22367543</gml:X>
> <gml:Y>3620000.00447305</gml:Y>
> </gml:coord>
> <gml:coord>
> <gml:X>4690000.24615209</gml:X>
> <gml:Y>3709999.93080836</gml:Y>
> </gml:coord>
> </gml:Envelope>
> </gml:boundedBy
>
> The rest of the file removed...
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Tue Apr  8 18:55:43 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 08 Apr 2008 18:55:43 +0200
Subject: [R-sig-Geo] extracting polygons
In-Reply-To: <47FB6CBE.70005@ija.csic.es>
References: <47FB6CBE.70005@ija.csic.es>
Message-ID: <47FBA38F.3020503@ija.csic.es>

I think that (at least part of) my problem comes
from being confused about Polygons and SpatialPolygons.
(and [ and [[ !!!)

I have an object with all my polygons:

 > class(absUTMpolys)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

 > str(absUTMpolys,max.level=2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame': 69 obs. of  3 variables:
   ..@ polygons   :List of 69
   ..@ plotOrder  : int [1:69] 1 2 3 4 5 6 7 8 9 10 ...
   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots

how is it that an SpatialPolygonsDataFrame has polygons instead
of SpatialPolygons?

Well, I've created absUTMpolys with:
absUTM <- read.table("poblptXsans_absents.txt",header=T)
absUTMpolys <- faigcell(datafr=absUTM)

where faigcell() is a function I've made:

"faigcell" <- function(datafr=absUTM)
{
   require(sp)
   lista <- vector(length=nrow(datafr),mode="list")
   names(lista) <- datafr[,1]
   for(i in 1:nrow(datafr)){
    swx <- datafr[i,5]
    swy <- datafr[i,8]
    sex<- swx + 2000
    sey <- swy
    nex <- sex
    ney <- sey+2000
    nwx <- swx
    nwy <- ney
    Sr1 <- Polygon(cbind(c(nwx,nex,sex,swx,nwx), c(nwy,ney,sey,swy,nwy)))
    Sr1 <- Polygons(list(Sr1), datafr[i,1])
    lista[i] <- Sr1
    }
   datos <- cbind(datafr[,1:2],abnd=rep(0,nrow(datafr)))
   row.names(datos) <- datafr[,1]
   Sr<- SpatialPolygons(lista,pO=1:nrow(datafr),CRS("+proj=tmerc 
+lat_0=0 +lon_0=2.999999982811267 +k=0.999600 +x_0=500000 +y_0=0 
+ellps=intl +units=m +no_defs"))
   SpatialPolygonsDataFrame(Sr, data=datos, match.ID = TRUE)
}

Note that Sr is made using SpatialPolygons(), and then I use 
SpatialPolygonsDataFrame() with Sr. Why don't I have SpatialPolygons
within absUTMpolys ?

The problem is that I need SpatialPolygons to get as.owin to work.

I've found that I can do:
as.owin(SpatialPolygons(absUTMpolys at polygons[1]))

and it works, but is this not very weird? should not the following just 
work:

as.owin(absUTMpolys at polygons[[1]])
?

That is, instead of having polygons:
 > class(absUTMpolys at polygons[[1]])
[1] "Polygons"
attr(,"package")
[1] "sp"

why don't I have SpatialPolygons?

Than

Agus



Agustin Lobo escribi?:
> Dear list,
> 
> I want to distribute a set of N circles according to a random distribution
> within a set of polygons (N circles within each polygon).
> 
> I have an object of class SpatialPolygonsDataFrame with the polygons.
> 
> My idea is to use something like:
> 
> for (i in 1:length(absUTMpolys at polygons)){
>  delme <- runifpoint(3, win=as.owin(absUTMpolys at polygons[i]))
>  ...
> 
> but I'm not being successful at extracting each polygon and
> as.owin refuses the conversion:
> 
> I've tried
>  > as(absUTMpolys at polygons[1], "owin")
> Error in as(absUTMpolys at polygons[1], "owin") :
>   no method or default for coercing "list" to "owin"
> 
> and
>  > as(absUTMpolys at polygons[1][[1]], "owin")
> Error in as(absUTMpolys at polygons[1][[1]], "owin") :
>   no method or default for coercing "Polygons" to "owin"
> 
> 
> which is the proper way
> of selecting each polygon from within the SpatialPolygonsDataFrame
> object?
> 
> Thanks!
> 
> Agus
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From andrew.niccolai at yale.edu  Tue Apr  8 20:37:34 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Tue, 8 Apr 2008 14:37:34 -0400
Subject: [R-sig-Geo] extracting polygons
In-Reply-To: <47FBA38F.3020503@ija.csic.es>
References: <47FB6CBE.70005@ija.csic.es> <47FBA38F.3020503@ija.csic.es>
Message-ID: <001d01c899a7$9d024920$d706db60$@niccolai@yale.edu>

I think there may be an issue in your faigcell function for your lines:

    Sr1 <- Polygon(cbind(c(nwx,nex,sex,swx,nwx), c(nwy,ney,sey,swy,nwy)))
    Sr1 <- Polygons(list(Sr1), datafr[i,1])
    lista[i] <- Sr1

try instead:

    Sr1 <- list(Polygons(list(Polygon(cbind(c(nwx,nex,sex,swx,nwx),
c(nwy,ney,sey,swy,nwy)))), datafr[i,1]))
    lista[i] <- Sr1

I can't be sure if that will work as I tend to iteratively claw my way to
successful code but the trick lies somewhere in setting up the
Polygons/Polygon lists.

Andrew Niccolai
Doctoral Candidate
Yale School of Forestry


 

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
Sent: Tuesday, April 08, 2008 12:56 PM
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] extracting polygons

I think that (at least part of) my problem comes
from being confused about Polygons and SpatialPolygons.
(and [ and [[ !!!)

I have an object with all my polygons:

 > class(absUTMpolys)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

 > str(absUTMpolys,max.level=2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame': 69 obs. of  3 variables:
   ..@ polygons   :List of 69
   ..@ plotOrder  : int [1:69] 1 2 3 4 5 6 7 8 9 10 ...
   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots

how is it that an SpatialPolygonsDataFrame has polygons instead
of SpatialPolygons?

Well, I've created absUTMpolys with:
absUTM <- read.table("poblptXsans_absents.txt",header=T)
absUTMpolys <- faigcell(datafr=absUTM)

where faigcell() is a function I've made:

"faigcell" <- function(datafr=absUTM)
{
   require(sp)
   lista <- vector(length=nrow(datafr),mode="list")
   names(lista) <- datafr[,1]
   for(i in 1:nrow(datafr)){
    swx <- datafr[i,5]
    swy <- datafr[i,8]
    sex<- swx + 2000
    sey <- swy
    nex <- sex
    ney <- sey+2000
    nwx <- swx
    nwy <- ney
    Sr1 <- Polygon(cbind(c(nwx,nex,sex,swx,nwx), c(nwy,ney,sey,swy,nwy)))
    Sr1 <- Polygons(list(Sr1), datafr[i,1])
    lista[i] <- Sr1
    }
   datos <- cbind(datafr[,1:2],abnd=rep(0,nrow(datafr)))
   row.names(datos) <- datafr[,1]
   Sr<- SpatialPolygons(lista,pO=1:nrow(datafr),CRS("+proj=tmerc 
+lat_0=0 +lon_0=2.999999982811267 +k=0.999600 +x_0=500000 +y_0=0 
+ellps=intl +units=m +no_defs"))
   SpatialPolygonsDataFrame(Sr, data=datos, match.ID = TRUE)
}

Note that Sr is made using SpatialPolygons(), and then I use 
SpatialPolygonsDataFrame() with Sr. Why don't I have SpatialPolygons
within absUTMpolys ?

The problem is that I need SpatialPolygons to get as.owin to work.

I've found that I can do:
as.owin(SpatialPolygons(absUTMpolys at polygons[1]))

and it works, but is this not very weird? should not the following just 
work:

as.owin(absUTMpolys at polygons[[1]])
?

That is, instead of having polygons:
 > class(absUTMpolys at polygons[[1]])
[1] "Polygons"
attr(,"package")
[1] "sp"

why don't I have SpatialPolygons?

Than

Agus



Agustin Lobo escribi?:
> Dear list,
> 
> I want to distribute a set of N circles according to a random distribution
> within a set of polygons (N circles within each polygon).
> 
> I have an object of class SpatialPolygonsDataFrame with the polygons.
> 
> My idea is to use something like:
> 
> for (i in 1:length(absUTMpolys at polygons)){
>  delme <- runifpoint(3, win=as.owin(absUTMpolys at polygons[i]))
>  ...
> 
> but I'm not being successful at extracting each polygon and
> as.owin refuses the conversion:
> 
> I've tried
>  > as(absUTMpolys at polygons[1], "owin")
> Error in as(absUTMpolys at polygons[1], "owin") :
>   no method or default for coercing "list" to "owin"
> 
> and
>  > as(absUTMpolys at polygons[1][[1]], "owin")
> Error in as(absUTMpolys at polygons[1][[1]], "owin") :
>   no method or default for coercing "Polygons" to "owin"
> 
> 
> which is the proper way
> of selecting each polygon from within the SpatialPolygonsDataFrame
> object?
> 
> Thanks!
> 
> Agus
> 
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From edzer.pebesma at uni-muenster.de  Tue Apr  8 20:49:30 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 08 Apr 2008 20:49:30 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>
References: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>
Message-ID: <47FBBE3A.9080604@uni-muenster.de>

David Maxwell (Cefas) wrote:
> Hi,
>
> Tom and Thierry, Thank you for your advice, the lecture notes are very useful. We will try geoRglm but for now regression kriging using the working residuals gives sensible answers even though there are some issues with using working residuals, i.e. not Normally distributed, occasional very large values and inv.logit(prediction type="link" + working residual) doesn't quite give the observed values.
>
> Our final question about this is how to estimate standard errors for the regression kriging predictions of the binary variable?
>
> On the logit scale we are using
>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction (s0) 
> for location s0
>
> Is assuming independence of the two components adequate?
>  var rk(s0) ~= var glm prediction (s0) + var kriged residual prediction (s0) 
>   
In principle, no. The extreme case is prediction at observation 
locations, where the correlation is -1 so that the final prediction 
variance becomes zero. I never got to looking how large the correlation 
is otherwise, but that shouldn't be hard to do in the linear case, as 
you can get the first and second separately, and also the combined using 
universal kriging.

Another question: how do you transform this variance back to the 
observation scale?
--
Edzer



From hengl at science.uva.nl  Wed Apr  9 09:53:28 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 9 Apr 2008 09:53:28 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <47FBBE3A.9080604@uni-muenster.de>
Message-ID: <000a01c89a16$cc61d220$3a871291@pcibed193>


The two components of the regression-kriging model are not independent, hence you are doing a wrong
thing if you are just summing them. You should use instead the universal kriging variance that is
derived in gstat. The complete derivation of the Universal kriging variance is available in Cressie
(1993; p.154), or even better Papritz and Stein (1999; p.94). See also pages 7-8 of our technical
note:

Hengl T., Heuvelink G.B.M. and Stein A., 2003. Comparison of kriging with external drift and
regression-kriging. Technical report, International Institute for Geo-information Science and Earth
Observation (ITC), Enschede, pp. 18.
http://www.itc.nl/library/Papers_2003/misca/hengl_comparison.pdf

Edzer is right, you can not back-transform prediction variance of the transformed variable (logits).
However, you can standardize/normalize the UK variance by diving it with global variance (see e.g.
http://dx.doi.org/10.1016/j.geoderma.2003.08.018), so that you can evaluate the success of
prediction in relative terms (see also http://spatial-analyst.net/visualization.php).


Tom Hengl
http://spatial-analyst.net 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Edzer Pebesma
Sent: dinsdag 8 april 2008 20:50
To: David Maxwell (Cefas)
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging

David Maxwell (Cefas) wrote:
> Hi,
>
> Tom and Thierry, Thank you for your advice, the lecture notes are very useful. We will try geoRglm
but for now regression kriging using the working residuals gives sensible answers even though there
are some issues with using working residuals, i.e. not Normally distributed, occasional very large
values and inv.logit(prediction type="link" + working residual) doesn't quite give the observed
values.
>
> Our final question about this is how to estimate standard errors for the regression kriging
predictions of the binary variable?
>
> On the logit scale we are using
>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction (s0) 
> for location s0
>
> Is assuming independence of the two components adequate?
>  var rk(s0) ~= var glm prediction (s0) + var kriged residual prediction (s0) 
>   
In principle, no. The extreme case is prediction at observation 
locations, where the correlation is -1 so that the final prediction 
variance becomes zero. I never got to looking how large the correlation 
is otherwise, but that shouldn't be hard to do in the linear case, as 
you can get the first and second separately, and also the combined using 
universal kriging.

Another question: how do you transform this variance back to the 
observation scale?
--
Edzer

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Thierry.ONKELINX at inbo.be  Wed Apr  9 10:25:44 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 9 Apr 2008 10:25:44 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <47FBBE3A.9080604@uni-muenster.de>
References: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>
	<47FBBE3A.9080604@uni-muenster.de>
Message-ID: <2E9C414912813E4EB981326983E0A10404943C6F@inboexch.inbo.be>

Dear David,

An other option would be to use sequential gaussian simulation. That
will allow to calculate confidence intervals in the logit scale. These
can be back-transformed into the original scale because the logit
transformation is monotone. 

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Edzer Pebesma
Verzonden: dinsdag 8 april 2008 20:50
Aan: David Maxwell (Cefas)
CC: r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] question about regression kriging

David Maxwell (Cefas) wrote:
> Hi,
>
> Tom and Thierry, Thank you for your advice, the lecture notes are very
useful. We will try geoRglm but for now regression kriging using the
working residuals gives sensible answers even though there are some
issues with using working residuals, i.e. not Normally distributed,
occasional very large values and inv.logit(prediction type="link" +
working residual) doesn't quite give the observed values.
>
> Our final question about this is how to estimate standard errors for
the regression kriging predictions of the binary variable?
>
> On the logit scale we are using
>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction
(s0) 
> for location s0
>
> Is assuming independence of the two components adequate?
>  var rk(s0) ~= var glm prediction (s0) + var kriged residual
prediction (s0) 
>   
In principle, no. The extreme case is prediction at observation 
locations, where the correlation is -1 so that the final prediction 
variance becomes zero. I never got to looking how large the correlation 
is otherwise, but that shouldn't be hard to do in the linear case, as 
you can get the first and second separately, and also the combined using

universal kriging.

Another question: how do you transform this variance back to the 
observation scale?
--
Edzer

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From edzer.pebesma at uni-muenster.de  Wed Apr  9 10:49:00 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 09 Apr 2008 10:49:00 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <000a01c89a16$cc61d220$3a871291@pcibed193>
References: <000a01c89a16$cc61d220$3a871291@pcibed193>
Message-ID: <47FC82FC.3090703@uni-muenster.de>

Tom,

I'm afraid things are harder than you sketch. In glm's, the parameter 
estimation is done using iteratively reweighted least squares, where the 
weights depend on a variance function that links the variance of 
observations to the mean. So, observations (residuals) are assumed to be 
unstationary, in principle, and because of the mean-dependency this 
changes over the iterations. The equations and references you mention 
afaik all assume a known, and fixed variogram, and one-step solutions, 
no iteration.

Also, you falsly accuse me of claiming one cannot back-transform 
prediction variances. I did not claim this (I have seen suggestions on 
how to do this), I just asked how David would do this.
--
Edzer

Tomislav Hengl wrote:
> The two components of the regression-kriging model are not independent, hence you are doing a wrong
> thing if you are just summing them. You should use instead the universal kriging variance that is
> derived in gstat. The complete derivation of the Universal kriging variance is available in Cressie
> (1993; p.154), or even better Papritz and Stein (1999; p.94). See also pages 7-8 of our technical
> note:
>
> Hengl T., Heuvelink G.B.M. and Stein A., 2003. Comparison of kriging with external drift and
> regression-kriging. Technical report, International Institute for Geo-information Science and Earth
> Observation (ITC), Enschede, pp. 18.
> http://www.itc.nl/library/Papers_2003/misca/hengl_comparison.pdf
>
> Edzer is right, you can not back-transform prediction variance of the transformed variable (logits).
> However, you can standardize/normalize the UK variance by diving it with global variance (see e.g.
> http://dx.doi.org/10.1016/j.geoderma.2003.08.018), so that you can evaluate the success of
> prediction in relative terms (see also http://spatial-analyst.net/visualization.php).
>
>
> Tom Hengl
> http://spatial-analyst.net 
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> Edzer Pebesma
> Sent: dinsdag 8 april 2008 20:50
> To: David Maxwell (Cefas)
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] question about regression kriging
>
> David Maxwell (Cefas) wrote:
>   
>> Hi,
>>
>> Tom and Thierry, Thank you for your advice, the lecture notes are very useful. We will try geoRglm
>>     
> but for now regression kriging using the working residuals gives sensible answers even though there
> are some issues with using working residuals, i.e. not Normally distributed, occasional very large
> values and inv.logit(prediction type="link" + working residual) doesn't quite give the observed
> values.
>   
>> Our final question about this is how to estimate standard errors for the regression kriging
>>     
> predictions of the binary variable?
>   
>> On the logit scale we are using
>>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction (s0) 
>> for location s0
>>
>> Is assuming independence of the two components adequate?
>>  var rk(s0) ~= var glm prediction (s0) + var kriged residual prediction (s0) 
>>   
>>     
> In principle, no. The extreme case is prediction at observation 
> locations, where the correlation is -1 so that the final prediction 
> variance becomes zero. I never got to looking how large the correlation 
> is otherwise, but that shouldn't be hard to do in the linear case, as 
> you can get the first and second separately, and also the combined using 
> universal kriging.
>
> Another question: how do you transform this variance back to the 
> observation scale?
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Wed Apr  9 10:57:19 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 09 Apr 2008 10:57:19 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <2E9C414912813E4EB981326983E0A10404943C6F@inboexch.inbo.be>
References: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>
	<47FBBE3A.9080604@uni-muenster.de>
	<2E9C414912813E4EB981326983E0A10404943C6F@inboexch.inbo.be>
Message-ID: <47FC84EF.8020901@uni-muenster.de>

Thierry,

how would you setup a Gaussian simulation such that the end result is 
different from the case where these confidence intervals were directly 
computed from the kriged mean and variance and a Gaussian assumption on 
the errors?
--
Edzer


ONKELINX, Thierry wrote:
> Dear David,
>
> An other option would be to use sequential gaussian simulation. That
> will allow to calculate confidence intervals in the logit scale. These
> can be back-transformed into the original scale because the logit
> transformation is monotone. 
>
> HTH,
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be 
> www.inbo.be 
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Edzer Pebesma
> Verzonden: dinsdag 8 april 2008 20:50
> Aan: David Maxwell (Cefas)
> CC: r-sig-geo at stat.math.ethz.ch
> Onderwerp: Re: [R-sig-Geo] question about regression kriging
>
> David Maxwell (Cefas) wrote:
>   
>> Hi,
>>
>> Tom and Thierry, Thank you for your advice, the lecture notes are very
>>     
> useful. We will try geoRglm but for now regression kriging using the
> working residuals gives sensible answers even though there are some
> issues with using working residuals, i.e. not Normally distributed,
> occasional very large values and inv.logit(prediction type="link" +
> working residual) doesn't quite give the observed values.
>   
>> Our final question about this is how to estimate standard errors for
>>     
> the regression kriging predictions of the binary variable?
>   
>> On the logit scale we are using
>>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction
>>     
> (s0) 
>   
>> for location s0
>>
>> Is assuming independence of the two components adequate?
>>  var rk(s0) ~= var glm prediction (s0) + var kriged residual
>>     
> prediction (s0) 
>   
>>   
>>     
> In principle, no. The extreme case is prediction at observation 
> locations, where the correlation is -1 so that the final prediction 
> variance becomes zero. I never got to looking how large the correlation 
> is otherwise, but that shouldn't be hard to do in the linear case, as 
> you can get the first and second separately, and also the combined using
>
> universal kriging.
>
> Another question: how do you transform this variance back to the 
> observation scale?
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Thierry.ONKELINX at inbo.be  Wed Apr  9 11:05:56 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 9 Apr 2008 11:05:56 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <47FC84EF.8020901@uni-muenster.de>
References: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>
	<47FBBE3A.9080604@uni-muenster.de>
	<2E9C414912813E4EB981326983E0A10404943C6F@inboexch.inbo.be>
	<47FC84EF.8020901@uni-muenster.de>
Message-ID: <2E9C414912813E4EB981326983E0A10404943C9C@inboexch.inbo.be>

Edzer,

One assumes a normal distribution of the predictions in every point when
calculating a confidence interval based on the kriged mean and variance.
AFAIK sequential Gaussian simulation doesn't have to yield normally
distributed predictions per point. Therefore can the confidence
intervals based on SGS differ from those based on the kriged mean and
variance. Or am I missing something?

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Verzonden: woensdag 9 april 2008 10:57
Aan: ONKELINX, Thierry
CC: David Maxwell (Cefas); r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] question about regression kriging

Thierry,

how would you setup a Gaussian simulation such that the end result is 
different from the case where these confidence intervals were directly 
computed from the kriged mean and variance and a Gaussian assumption on 
the errors?
--
Edzer


ONKELINX, Thierry wrote:
> Dear David,
>
> An other option would be to use sequential gaussian simulation. That
> will allow to calculate confidence intervals in the logit scale. These
> can be back-transformed into the original scale because the logit
> transformation is monotone. 
>
> HTH,
>
> Thierry
>
>
------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be 
> www.inbo.be 
>
> To call in the statistician after the experiment is done may be no
more
> than asking him to perform a post-mortem examination: he may be able
to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does
not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Edzer Pebesma
> Verzonden: dinsdag 8 april 2008 20:50
> Aan: David Maxwell (Cefas)
> CC: r-sig-geo at stat.math.ethz.ch
> Onderwerp: Re: [R-sig-Geo] question about regression kriging
>
> David Maxwell (Cefas) wrote:
>   
>> Hi,
>>
>> Tom and Thierry, Thank you for your advice, the lecture notes are
very
>>     
> useful. We will try geoRglm but for now regression kriging using the
> working residuals gives sensible answers even though there are some
> issues with using working residuals, i.e. not Normally distributed,
> occasional very large values and inv.logit(prediction type="link" +
> working residual) doesn't quite give the observed values.
>   
>> Our final question about this is how to estimate standard errors for
>>     
> the regression kriging predictions of the binary variable?
>   
>> On the logit scale we are using
>>  rk prediction (s0) = glm prediction (s0) + kriged residual
prediction
>>     
> (s0) 
>   
>> for location s0
>>
>> Is assuming independence of the two components adequate?
>>  var rk(s0) ~= var glm prediction (s0) + var kriged residual
>>     
> prediction (s0) 
>   
>>   
>>     
> In principle, no. The extreme case is prediction at observation 
> locations, where the correlation is -1 so that the final prediction 
> variance becomes zero. I never got to looking how large the
correlation 
> is otherwise, but that shouldn't be hard to do in the linear case, as 
> you can get the first and second separately, and also the combined
using
>
> universal kriging.
>
> Another question: how do you transform this variance back to the 
> observation scale?
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   



From edzer.pebesma at uni-muenster.de  Wed Apr  9 11:17:09 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 09 Apr 2008 11:17:09 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <2E9C414912813E4EB981326983E0A10404943C9C@inboexch.inbo.be>
References: <8F90BAFE30CE2D458953FC0F1709830B0956D9@LOWEXPRESS.corp.cefas.co.uk>
	<47FBBE3A.9080604@uni-muenster.de>
	<2E9C414912813E4EB981326983E0A10404943C6F@inboexch.inbo.be>
	<47FC84EF.8020901@uni-muenster.de>
	<2E9C414912813E4EB981326983E0A10404943C9C@inboexch.inbo.be>
Message-ID: <47FC8995.80505@uni-muenster.de>

Thierry, this is one of the frequent misconceptions in geostatistics.

Sequential Gaussian simulation yields for each point a normal 
distribution, with mean and standard deviation equal (in the limit of 
very many simulations) to the kriged mean and standard deviation.
--
Edzer

ONKELINX, Thierry wrote:
> Edzer,
>
> One assumes a normal distribution of the predictions in every point when
> calculating a confidence interval based on the kriged mean and variance.
> AFAIK sequential Gaussian simulation doesn't have to yield normally
> distributed predictions per point. Therefore can the confidence
> intervals based on SGS differ from those based on the kriged mean and
> variance. Or am I missing something?
>
> Thierry
>
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium 
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be 
> www.inbo.be 
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
> Verzonden: woensdag 9 april 2008 10:57
> Aan: ONKELINX, Thierry
> CC: David Maxwell (Cefas); r-sig-geo at stat.math.ethz.ch
> Onderwerp: Re: [R-sig-Geo] question about regression kriging
>
> Thierry,
>
> how would you setup a Gaussian simulation such that the end result is 
> different from the case where these confidence intervals were directly 
> computed from the kriged mean and variance and a Gaussian assumption on 
> the errors?
> --
> Edzer
>
>
> ONKELINX, Thierry wrote:
>   
>> Dear David,
>>
>> An other option would be to use sequential gaussian simulation. That
>> will allow to calculate confidence intervals in the logit scale. These
>> can be back-transformed into the original scale because the logit
>> transformation is monotone. 
>>
>> HTH,
>>
>> Thierry
>>
>>
>>     
> ------------------------------------------------------------------------
>   
>> ----
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and Forest
>> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
>> methodology and quality assurance
>> Gaverstraat 4
>> 9500 Geraardsbergen
>> Belgium 
>> tel. + 32 54/436 185
>> Thierry.Onkelinx at inbo.be 
>> www.inbo.be 
>>
>> To call in the statistician after the experiment is done may be no
>>     
> more
>   
>> than asking him to perform a post-mortem examination: he may be able
>>     
> to
>   
>> say what the experiment died of.
>> ~ Sir Ronald Aylmer Fisher
>>
>> The plural of anecdote is not data.
>> ~ Roger Brinner
>>
>> The combination of some data and an aching desire for an answer does
>>     
> not
>   
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> -----Oorspronkelijk bericht-----
>> Van: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Edzer Pebesma
>> Verzonden: dinsdag 8 april 2008 20:50
>> Aan: David Maxwell (Cefas)
>> CC: r-sig-geo at stat.math.ethz.ch
>> Onderwerp: Re: [R-sig-Geo] question about regression kriging
>>
>> David Maxwell (Cefas) wrote:
>>   
>>     
>>> Hi,
>>>
>>> Tom and Thierry, Thank you for your advice, the lecture notes are
>>>       
> very
>   
>>>     
>>>       
>> useful. We will try geoRglm but for now regression kriging using the
>> working residuals gives sensible answers even though there are some
>> issues with using working residuals, i.e. not Normally distributed,
>> occasional very large values and inv.logit(prediction type="link" +
>> working residual) doesn't quite give the observed values.
>>   
>>     
>>> Our final question about this is how to estimate standard errors for
>>>     
>>>       
>> the regression kriging predictions of the binary variable?
>>   
>>     
>>> On the logit scale we are using
>>>  rk prediction (s0) = glm prediction (s0) + kriged residual
>>>       
> prediction
>   
>>>     
>>>       
>> (s0) 
>>   
>>     
>>> for location s0
>>>
>>> Is assuming independence of the two components adequate?
>>>  var rk(s0) ~= var glm prediction (s0) + var kriged residual
>>>     
>>>       
>> prediction (s0) 
>>   
>>     
>>>   
>>>     
>>>       
>> In principle, no. The extreme case is prediction at observation 
>> locations, where the correlation is -1 so that the final prediction 
>> variance becomes zero. I never got to looking how large the
>>     
> correlation 
>   
>> is otherwise, but that shouldn't be hard to do in the linear case, as 
>> you can get the first and second separately, and also the combined
>>     
> using
>   
>> universal kriging.
>>
>> Another question: how do you transform this variance back to the 
>> observation scale?
>> --
>> Edzer
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>>     
>
>



From david.maxwell at cefas.co.uk  Wed Apr  9 11:38:31 2008
From: david.maxwell at cefas.co.uk (David Maxwell (Cefas))
Date: Wed, 9 Apr 2008 10:38:31 +0100
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <47FC82FC.3090703@uni-muenster.de>
Message-ID: <8F90BAFE30CE2D458953FC0F1709830B0956DF@LOWEXPRESS.corp.cefas.co.uk>

Hi,
Both Edzer's example (extreme case when prediction is at observation locations) and Tom's tech report (pg8 "note that the Eq.(19) looks very much like (17), except it will give slightly lower values") suggest that assuming independence of the two variances will give values that are too large, if so this is useful to know.

For the follow-up question: how to present the prediction uncertainty? I would follow the usual approach for a binary glm, calculate a confidence interval on the logit scale, then back-transform the limits to the 0,1 scale. If space to present mapped outputs is limited I plan to calculate the width of the confidence interval on the 0,1 scale and map this. 

Thanks again, this list is an excellent catalyst for learning
David
david.maxwell at cefas.co.uk

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de]
Sent: 09 April 2008 09:49
To: Tomislav Hengl
Cc: David Maxwell (Cefas); r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging


Tom,

I'm afraid things are harder than you sketch. In glm's, the parameter 
estimation is done using iteratively reweighted least squares, where the 
weights depend on a variance function that links the variance of 
observations to the mean. So, observations (residuals) are assumed to be 
unstationary, in principle, and because of the mean-dependency this 
changes over the iterations. The equations and references you mention 
afaik all assume a known, and fixed variogram, and one-step solutions, 
no iteration.

Also, you falsly accuse me of claiming one cannot back-transform 
prediction variances. I did not claim this (I have seen suggestions on 
how to do this), I just asked how David would do this.
--
Edzer

Tomislav Hengl wrote:
> The two components of the regression-kriging model are not independent, hence you are doing a wrong
> thing if you are just summing them. You should use instead the universal kriging variance that is
> derived in gstat. The complete derivation of the Universal kriging variance is available in Cressie
> (1993; p.154), or even better Papritz and Stein (1999; p.94). See also pages 7-8 of our technical
> note:
>
> Hengl T., Heuvelink G.B.M. and Stein A., 2003. Comparison of kriging with external drift and
> regression-kriging. Technical report, International Institute for Geo-information Science and Earth
> Observation (ITC), Enschede, pp. 18.
> http://www.itc.nl/library/Papers_2003/misca/hengl_comparison.pdf
>
> Edzer is right, you can not back-transform prediction variance of the transformed variable (logits).
> However, you can standardize/normalize the UK variance by diving it with global variance (see e.g.
> http://dx.doi.org/10.1016/j.geoderma.2003.08.018), so that you can evaluate the success of
> prediction in relative terms (see also http://spatial-analyst.net/visualization.php).
>
>
> Tom Hengl
> http://spatial-analyst.net 
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> Edzer Pebesma
> Sent: dinsdag 8 april 2008 20:50
> To: David Maxwell (Cefas)
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] question about regression kriging
>
> David Maxwell (Cefas) wrote:
>   
>> Hi,
>>
>> Tom and Thierry, Thank you for your advice, the lecture notes are very useful. We will try geoRglm
>>     
> but for now regression kriging using the working residuals gives sensible answers even though there
> are some issues with using working residuals, i.e. not Normally distributed, occasional very large
> values and inv.logit(prediction type="link" + working residual) doesn't quite give the observed
> values.
>   
>> Our final question about this is how to estimate standard errors for the regression kriging
>>     
> predictions of the binary variable?
>   
>> On the logit scale we are using
>>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction (s0) 
>> for location s0
>>
>> Is assuming independence of the two components adequate?
>>  var rk(s0) ~= var glm prediction (s0) + var kriged residual prediction (s0) 
>>   
>>     
> In principle, no. The extreme case is prediction at observation 
> locations, where the correlation is -1 so that the final prediction 
> variance becomes zero. I never got to looking how large the correlation 
> is otherwise, but that shouldn't be hard to do in the linear case, as 
> you can get the first and second separately, and also the combined using 
> universal kriging.
>
> Another question: how do you transform this variance back to the 
> observation scale?
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo




***********************************************************************************
This email and any attachments are intended for the name...{{dropped:10}}



From hengl at science.uva.nl  Wed Apr  9 12:33:30 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 9 Apr 2008 12:33:30 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <47FC82FC.3090703@uni-muenster.de>
Message-ID: <001801c89a2d$275273e0$3a871291@pcibed193>


Edzer,

I do not want to get into too much discussion (this is definitively not a place to discuss basic
mathematical/statistical theories). My experience is - things are complicated when trying to run
regression-kriging with 0/1 variables. 

In practice, I guess you can fit GLM model, then estimate the variogram for residuals. Imagine that
we have a point map showing binary observations (0/1) and a set of raster maps PC1-PC5 (pc.comps).
Then, we can make predictions using glms and your package gstat:

# regression (GLM) modelling:
> occurrences.absences$pr = ifelse(is.na(occurrences.absences$value), 0, 1)
> vtbin.lm = glm(pr~PC1+PC2+PC3+PC4+PC5, binomial(link=logit), occurrences.absences)
> vtbin.lm$residual = vtbin.lm$model$occurrence - vtbin.lm$fitted.values

# variogram modelling (original scale):
> vt.rebin = variogram(vtbin.lm$residual~1, occurrences.absences)
> vt.rbvgm = fit.variogram(vt.rebin, vgm(nugget=0.01, model="Exp", range=40000, psill=0.03))

# final predictions (A) regression-kriging:
> vt.bin.trend = predict(vtbin.lm, newdata=pc.comps, type="response")
> vt.gres = gstat(id=c("occur"), formula=vtbin.lm$residual~1, data=occurrences.absences,
model=vt.rbvgm)
> vt.rkbin = predict.gstat(vt.gres, pc.comps, nmax=100, beta=1, BLUE=FALSE)
> vt.rkbin$pred.bin = vt.bin.trend + vt.rkbin$occur.pred

Now you have the predictions that can exceed 0-1 range, and no estimate of the UK variance (this is
the problem David has, I think). What we can do instead is to run UK in gstat on logits first, then
back-transform to original 0-1 scale: 

# Estimate the binary variable at logit-scale (as an average of the output of GLM and original 0/1
value). This is not possible if values are equal to 0/1, so we have to 'smooth' them:
> vtbin.lm$prs = (10*occurrences.absences$pr+vtbin.lm$fitted.values)/11
# Now the values can be back-transformed to logit scale
> occurrences.absences$logits = log((vtbin.lm$prs)/(1-(vtbin.lm$prs)))

# now fit variogram for residuals (logits):
> vt.relogit = variogram(vtbin.lm$residuals~1, occurrences.absences)
> vt.logitvgm = fit.variogram(vt.relogit, vgm(nugget=0, model="Exp", range=40000, psill=4))

# final predictions (B) UK in gstat:
> vt.prs = gstat(id=c("occur"), formula=logits~PC1+PC2+PC3+PC4+PC5, data=occurrences.absences,
model=vt.logitvgm)
> vt.rkprs = predict.gstat(vt.prs, pc.comps, nmax=100, beta=1, BLUE=FALSE)
# Back-transform (-20 to 20 values) to original scale:
> vt.rkprs$pr = exp(vt.rkprs$occur.pred)/(1+exp(vt.rkprs$occur.pred))

Obviously, predictions with (B) are more attractive than predictions with (A), because the values
are within the 0-1 range and we also have the UK variance (but this is hard to interpret). Then, one
can standardize the prediction variance using the global variance so that you can do some
interpretation:

> vt.rkprs$nvar = vt.rkprs$occur.var/var(occurrences.absences$logits)

Of course, (B) is only a short-cut solution. One really needs to develop a sound methodology to
solve such problems (we at least offer a detailed discussion in
http://dx.doi.org/10.1016/j.geoderma.2007.04.022).


PS: How do you back-transform the GLM prediction variance to original scale (I was not aware of
this, apologies)? A reference would do.

Tom


-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: woensdag 9 april 2008 10:49
To: Tomislav Hengl
Cc: 'David Maxwell (Cefas)'; r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging

Tom,

I'm afraid things are harder than you sketch. In glm's, the parameter 
estimation is done using iteratively reweighted least squares, where the 
weights depend on a variance function that links the variance of 
observations to the mean. So, observations (residuals) are assumed to be 
unstationary, in principle, and because of the mean-dependency this 
changes over the iterations. The equations and references you mention 
afaik all assume a known, and fixed variogram, and one-step solutions, 
no iteration.

Also, you falsly accuse me of claiming one cannot back-transform 
prediction variances. I did not claim this (I have seen suggestions on 
how to do this), I just asked how David would do this.
--
Edzer

Tomislav Hengl wrote:
> The two components of the regression-kriging model are not independent, hence you are doing a
wrong
> thing if you are just summing them. You should use instead the universal kriging variance that is
> derived in gstat. The complete derivation of the Universal kriging variance is available in
Cressie
> (1993; p.154), or even better Papritz and Stein (1999; p.94). See also pages 7-8 of our technical
> note:
>
> Hengl T., Heuvelink G.B.M. and Stein A., 2003. Comparison of kriging with external drift and
> regression-kriging. Technical report, International Institute for Geo-information Science and
Earth
> Observation (ITC), Enschede, pp. 18.
> http://www.itc.nl/library/Papers_2003/misca/hengl_comparison.pdf
>
> Edzer is right, you can not back-transform prediction variance of the transformed variable
(logits).
> However, you can standardize/normalize the UK variance by diving it with global variance (see e.g.
> http://dx.doi.org/10.1016/j.geoderma.2003.08.018), so that you can evaluate the success of
> prediction in relative terms (see also http://spatial-analyst.net/visualization.php).
>
>
> Tom Hengl
> http://spatial-analyst.net 
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
Of
> Edzer Pebesma
> Sent: dinsdag 8 april 2008 20:50
> To: David Maxwell (Cefas)
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] question about regression kriging
>
> David Maxwell (Cefas) wrote:
>   
>> Hi,
>>
>> Tom and Thierry, Thank you for your advice, the lecture notes are very useful. We will try
geoRglm
>>     
> but for now regression kriging using the working residuals gives sensible answers even though
there
> are some issues with using working residuals, i.e. not Normally distributed, occasional very large
> values and inv.logit(prediction type="link" + working residual) doesn't quite give the observed
> values.
>   
>> Our final question about this is how to estimate standard errors for the regression kriging
>>     
> predictions of the binary variable?
>   
>> On the logit scale we are using
>>  rk prediction (s0) = glm prediction (s0) + kriged residual prediction (s0) 
>> for location s0
>>
>> Is assuming independence of the two components adequate?
>>  var rk(s0) ~= var glm prediction (s0) + var kriged residual prediction (s0) 
>>   
>>     
> In principle, no. The extreme case is prediction at observation 
> locations, where the correlation is -1 so that the final prediction 
> variance becomes zero. I never got to looking how large the correlation 
> is otherwise, but that shouldn't be hard to do in the linear case, as 
> you can get the first and second separately, and also the combined using 
> universal kriging.
>
> Another question: how do you transform this variance back to the 
> observation scale?
> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Wed Apr  9 14:48:28 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 09 Apr 2008 14:48:28 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <001801c89a2d$275273e0$3a871291@pcibed193>
References: <001801c89a2d$275273e0$3a871291@pcibed193>
Message-ID: <47FCBB1C.20908@uni-muenster.de>

Tomislav Hengl wrote:
> PS: How do you back-transform the GLM prediction variance to original scale (I was not aware of
> this, apologies)? A reference would do.
>   
1. The white book, "Statistical Models in S"
2. The source of predict.glm (not for the faint of heart)
3. McCullogh & Nelder (I guess it's in there, but my copy is still in a 
box!)
--
Edzer



From hengl at science.uva.nl  Wed Apr  9 15:19:39 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Wed, 9 Apr 2008 15:19:39 +0200
Subject: [R-sig-Geo] question about regression kriging
In-Reply-To: <47FCBB1C.20908@uni-muenster.de>
Message-ID: <001b01c89a44$5e90f130$3a871291@pcibed193>


Sorry, I meant "UK variance of the interpolated logits".

I guess the solution is to either:

(A)
1. Run 100 SG simulations using logits;
2. Back-transform the values to 0-1 scale;
3. Determine the variance per grid node (now in 0-1 scale).

Running simulations could also be rather time-consuming (I often give up running SG simulations in
gstat with multiple raster maps as predictors -- memory limit problems, too time-consuming).

(B)
1. Determine the upper and lower 1-s confidence intervals -- 2 maps (in logit scale);
2. Back-transform the maps and derive the difference in 0-1 scale (estimation error);

But I guess that a method to directly back-transform the UK variance from logit scale to 0-1 scale
does not exist.

Tom Hengl

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: woensdag 9 april 2008 14:48
To: Tomislav Hengl
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] question about regression kriging

Tomislav Hengl wrote:
> PS: How do you back-transform the GLM prediction variance to original scale (I was not aware of
> this, apologies)? A reference would do.
>   
1. The white book, "Statistical Models in S"
2. The source of predict.glm (not for the faint of heart)
3. McCullogh & Nelder (I guess it's in there, but my copy is still in a 
box!)
--
Edzer



From Agustin.Lobo at ija.csic.es  Wed Apr  9 15:47:56 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 09 Apr 2008 15:47:56 +0200
Subject: [R-sig-Geo] intersection of objects SpatialPolygonsDataFrame
Message-ID: <47FCC90C.8070408@ija.csic.es>

Dear list,

I have two objects of class "SpatialPolygonsDataFrame"
and I want to get the intersection. The first object (x)
are circles (approached as polygons) with a fake data
frame. The circles could be just in a SpatialPolygons
object, I just put the fake data frame to get the same
class as I would have got from importing a shp file via readOGR.
The second object (absUTMpolysHABS2) is a map of habitats
(imported from a shp file
via readOGR). I want the circles to intersect the map
so that I can calculate the area of each habitat in
each circle. I'm not sure if I'm on the right path:

It seemed to me that I had to use function joinPolys()
with operation="INT" from package PBSmapping,

a <- (joinPolys(SpatialPolygons2PolySet(x), 
SpatialPolygons2PolySet(absUTMpolysHABS2)))

a looks good (circles subdivided into polygons)
but SpatialPolygons2PolySet() makes me loss the information
in the data frame of the map, so I do not know the habitat
for each polygon within each circle.

Any way to relate the new polygons to the data frame of the map?
Or should I use an entirely different apporach in R?
Or should I export x to a GIS and do this operation there?

Thanks!

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From andrew.niccolai at yale.edu  Wed Apr  9 16:15:57 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Wed, 9 Apr 2008 10:15:57 -0400
Subject: [R-sig-Geo] intersection of objects SpatialPolygonsDataFrame
In-Reply-To: <47FCC90C.8070408@ija.csic.es>
References: <47FCC90C.8070408@ija.csic.es>
Message-ID: <000301c89a4c$3b9b3ac0$b2d1b040$@niccolai@yale.edu>

Try 

?PolySet2SpatialPolygons

This function will bring the newly intersected polygon back to class SPDF
and then you should be able to attach the corresponding data.frame to the
new polygon object.

Andrew Niccolai
Doctoral Candidate
Yale School of Forestry


 
-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
Sent: Wednesday, April 09, 2008 9:48 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] intersection of objects SpatialPolygonsDataFrame

Dear list,

I have two objects of class "SpatialPolygonsDataFrame"
and I want to get the intersection. The first object (x)
are circles (approached as polygons) with a fake data
frame. The circles could be just in a SpatialPolygons
object, I just put the fake data frame to get the same
class as I would have got from importing a shp file via readOGR.
The second object (absUTMpolysHABS2) is a map of habitats
(imported from a shp file
via readOGR). I want the circles to intersect the map
so that I can calculate the area of each habitat in
each circle. I'm not sure if I'm on the right path:

It seemed to me that I had to use function joinPolys()
with operation="INT" from package PBSmapping,

a <- (joinPolys(SpatialPolygons2PolySet(x), 
SpatialPolygons2PolySet(absUTMpolysHABS2)))

a looks good (circles subdivided into polygons)
but SpatialPolygons2PolySet() makes me loss the information
in the data frame of the map, so I do not know the habitat
for each polygon within each circle.

Any way to relate the new polygons to the data frame of the map?
Or should I use an entirely different apporach in R?
Or should I export x to a GIS and do this operation there?

Thanks!

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Agustin.Lobo at ija.csic.es  Wed Apr  9 20:26:24 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Wed, 09 Apr 2008 20:26:24 +0200
Subject: [R-sig-Geo] intersection of objects SpatialPolygonsDataFrame
In-Reply-To: <000301c89a4c$3b9b3ac0$b2d1b040$@niccolai@yale.edu>
References: <47FCC90C.8070408@ija.csic.es>
	<000301c89a4c$3b9b3ac0$b2d1b040$@niccolai@yale.edu>
Message-ID: <47FD0A50.1020203@ija.csic.es>

Thanks,

I get a problem in the inverse transform:
 > delme <- 
PolySet2SpatialPolygons(SpatialPolygons2PolySet(absUTMpolysHABS2))
Error in 
PolySet2SpatialPolygons(SpatialPolygons2PolySet(absUTMpolysHABS2)) :
   unknown coordinate reference system

probably because
 > absUTMpolysHABS2 at proj4string
CRS arguments: NA

despite the fact that I do have a *.prj file in the directory
where I import with  rgdal (thought that rgdal would read the *.prj file
if present).

I'm working on this (proj4 strings are not straightforward for ED50). 
Meanwhile wanted to run the example in the PolySet2SpatialPolygons
help page but:

 > nor_coast_poly_sp <- map2SpatialPolygons(nor_coast_poly, IDs=IDs,
+  proj4string=CRS("+proj=longlat +datum=wgs84"))
Error in CRS("+proj=longlat +datum=wgs84") :
   unknown elliptical parameter name

does anybody know the right proj4string in that case?

Agus


Andrew Niccolai escribi?:
> Try 
> 
> ?PolySet2SpatialPolygons
> 
> This function will bring the newly intersected polygon back to class SPDF
> and then you should be able to attach the corresponding data.frame to the
> new polygon object.
> 
> Andrew Niccolai
> Doctoral Candidate
> Yale School of Forestry
> 
> 
>  
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
> Sent: Wednesday, April 09, 2008 9:48 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] intersection of objects SpatialPolygonsDataFrame
> 
> Dear list,
> 
> I have two objects of class "SpatialPolygonsDataFrame"
> and I want to get the intersection. The first object (x)
> are circles (approached as polygons) with a fake data
> frame. The circles could be just in a SpatialPolygons
> object, I just put the fake data frame to get the same
> class as I would have got from importing a shp file via readOGR.
> The second object (absUTMpolysHABS2) is a map of habitats
> (imported from a shp file
> via readOGR). I want the circles to intersect the map
> so that I can calculate the area of each habitat in
> each circle. I'm not sure if I'm on the right path:
> 
> It seemed to me that I had to use function joinPolys()
> with operation="INT" from package PBSmapping,
> 
> a <- (joinPolys(SpatialPolygons2PolySet(x), 
> SpatialPolygons2PolySet(absUTMpolysHABS2)))
> 
> a looks good (circles subdivided into polygons)
> but SpatialPolygons2PolySet() makes me loss the information
> in the data frame of the map, so I do not know the habitat
> for each polygon within each circle.
> 
> Any way to relate the new polygons to the data frame of the map?
> Or should I use an entirely different apporach in R?
> Or should I export x to a GIS and do this operation there?
> 
> Thanks!
> 
> Agus
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Thu Apr 10 08:17:43 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 10 Apr 2008 08:17:43 +0200
Subject: [R-sig-Geo] extracting polygons
In-Reply-To: <001d01c899a7$9d024920$d706db60$@niccolai@yale.edu>
References: <47FB6CBE.70005@ija.csic.es> <47FBA38F.3020503@ija.csic.es>
	<001d01c899a7$9d024920$d706db60$@niccolai@yale.edu>
Message-ID: <47FDB107.3060400@ija.csic.es>

Andrew,

I get the same behaviour,
 > delme <- faigcell2(datafr=absUTM)
 > str(delme,max.level=2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame': 69 obs. of  3 variables:
   ..@ polygons   :List of 69
   ..@ plotOrder  : int [1:69] 1 2 3 4 5 6 7 8 9 10 ...
   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots

 > as.owin(delme at polygons[[1]])
Error in as.owin.default(delme at polygons[[1]]) :
   Can't interpret W as a window
 > class(delme at polygons[[1]])
[1] "Polygons"
attr(,"package")
[1] "sp"

where faigcell2() includes your suggestion instead of the original lines.

The following works (as for the result of the original faigcell()):
 > class(SpatialPolygons(delme at polygons[1]))
[1] "SpatialPolygons"
attr(,"package")
[1] "sp"
 > as.owin(SpatialPolygons(delme at polygons[1]))
window: polygonal boundary
enclosing rectangle: [418000, 420000] x [4590000, 4592000] units

The point is, I would expect the components of an 
SpatialPolygonsDataFrame to be SpatialPolygons, not just Polygons.

Agus

Andrew Niccolai escribi?:
> I think there may be an issue in your faigcell function for your lines:
> 
>     Sr1 <- Polygon(cbind(c(nwx,nex,sex,swx,nwx), c(nwy,ney,sey,swy,nwy)))
>     Sr1 <- Polygons(list(Sr1), datafr[i,1])
>     lista[i] <- Sr1
> 
> try instead:
> 
>     Sr1 <- list(Polygons(list(Polygon(cbind(c(nwx,nex,sex,swx,nwx),
> c(nwy,ney,sey,swy,nwy)))), datafr[i,1]))
>     lista[i] <- Sr1
> 
> I can't be sure if that will work as I tend to iteratively claw my way to
> successful code but the trick lies somewhere in setting up the
> Polygons/Polygon lists.
> 
> Andrew Niccolai
> Doctoral Candidate
> Yale School of Forestry
> 
> 
>  
> 
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
> Sent: Tuesday, April 08, 2008 12:56 PM
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] extracting polygons
> 
> I think that (at least part of) my problem comes
> from being confused about Polygons and SpatialPolygons.
> (and [ and [[ !!!)
> 
> I have an object with all my polygons:
> 
>  > class(absUTMpolys)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
> 
>  > str(absUTMpolys,max.level=2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>    ..@ data       :'data.frame': 69 obs. of  3 variables:
>    ..@ polygons   :List of 69
>    ..@ plotOrder  : int [1:69] 1 2 3 4 5 6 7 8 9 10 ...
>    ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>    .. ..- attr(*, "dimnames")=List of 2
>    ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> 
> how is it that an SpatialPolygonsDataFrame has polygons instead
> of SpatialPolygons?
> 
> Well, I've created absUTMpolys with:
> absUTM <- read.table("poblptXsans_absents.txt",header=T)
> absUTMpolys <- faigcell(datafr=absUTM)
> 
> where faigcell() is a function I've made:
> 
> "faigcell" <- function(datafr=absUTM)
> {
>    require(sp)
>    lista <- vector(length=nrow(datafr),mode="list")
>    names(lista) <- datafr[,1]
>    for(i in 1:nrow(datafr)){
>     swx <- datafr[i,5]
>     swy <- datafr[i,8]
>     sex<- swx + 2000
>     sey <- swy
>     nex <- sex
>     ney <- sey+2000
>     nwx <- swx
>     nwy <- ney
>     Sr1 <- Polygon(cbind(c(nwx,nex,sex,swx,nwx), c(nwy,ney,sey,swy,nwy)))
>     Sr1 <- Polygons(list(Sr1), datafr[i,1])
>     lista[i] <- Sr1
>     }
>    datos <- cbind(datafr[,1:2],abnd=rep(0,nrow(datafr)))
>    row.names(datos) <- datafr[,1]
>    Sr<- SpatialPolygons(lista,pO=1:nrow(datafr),CRS("+proj=tmerc 
> +lat_0=0 +lon_0=2.999999982811267 +k=0.999600 +x_0=500000 +y_0=0 
> +ellps=intl +units=m +no_defs"))
>    SpatialPolygonsDataFrame(Sr, data=datos, match.ID = TRUE)
> }
> 
> Note that Sr is made using SpatialPolygons(), and then I use 
> SpatialPolygonsDataFrame() with Sr. Why don't I have SpatialPolygons
> within absUTMpolys ?
> 
> The problem is that I need SpatialPolygons to get as.owin to work.
> 
> I've found that I can do:
> as.owin(SpatialPolygons(absUTMpolys at polygons[1]))
> 
> and it works, but is this not very weird? should not the following just 
> work:
> 
> as.owin(absUTMpolys at polygons[[1]])
> ?
> 
> That is, instead of having polygons:
>  > class(absUTMpolys at polygons[[1]])
> [1] "Polygons"
> attr(,"package")
> [1] "sp"
> 
> why don't I have SpatialPolygons?
> 
> Than
> 
> Agus
> 
> 
> 
> Agustin Lobo escribi?:
>> Dear list,
>>
>> I want to distribute a set of N circles according to a random distribution
>> within a set of polygons (N circles within each polygon).
>>
>> I have an object of class SpatialPolygonsDataFrame with the polygons.
>>
>> My idea is to use something like:
>>
>> for (i in 1:length(absUTMpolys at polygons)){
>>  delme <- runifpoint(3, win=as.owin(absUTMpolys at polygons[i]))
>>  ...
>>
>> but I'm not being successful at extracting each polygon and
>> as.owin refuses the conversion:
>>
>> I've tried
>>  > as(absUTMpolys at polygons[1], "owin")
>> Error in as(absUTMpolys at polygons[1], "owin") :
>>   no method or default for coercing "list" to "owin"
>>
>> and
>>  > as(absUTMpolys at polygons[1][[1]], "owin")
>> Error in as(absUTMpolys at polygons[1][[1]], "owin") :
>>   no method or default for coercing "Polygons" to "owin"
>>
>>
>> which is the proper way
>> of selecting each polygon from within the SpatialPolygonsDataFrame
>> object?
>>
>> Thanks!
>>
>> Agus
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Thu Apr 10 08:42:30 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 10 Apr 2008 08:42:30 +0200
Subject: [R-sig-Geo] readOGR and proj4 string
Message-ID: <47FDB6D6.9050402@ija.csic.es>

The manual page of readOGR states:

p4s 	PROJ4 string defining CRS, if default NULL, the value is read from 
the OGR data set

then, if a  *.prj file is present for a *.shp,
why is the proj4string of the resulting SpatialPolygonsDataframe
set to NA? is this a general behaviour or am I doing someting
wrong?

 > absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")

where I have:

test_TNT.avl
test_TNT.dbf
test_TNT.prj
test_TNT.shp
test_TNT.shx

with test_TNT.prj:

PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM["D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS84[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]]

I get:
 > class(delme)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
 > str(delme,max.level=2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame': 1555 obs. of  16 variables:
   ..@ polygons   :List of 1555
   ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 1127 
1160 ...
   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
 > delme at proj4string
CRS arguments: NA

Agus
-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Thu Apr 10 08:57:16 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Apr 2008 08:57:16 +0200 (CEST)
Subject: [R-sig-Geo] readOGR and proj4 string
In-Reply-To: <47FDB6D6.9050402@ija.csic.es>
References: <47FDB6D6.9050402@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0804100856140.32757@reclus.nhh.no>

On Thu, 10 Apr 2008, Agustin Lobo wrote:

> The manual page of readOGR states:
>
> p4s 	PROJ4 string defining CRS, if default NULL, the value is read from
> the OGR data set
>
> then, if a  *.prj file is present for a *.shp,
> why is the proj4string of the resulting SpatialPolygonsDataframe
> set to NA? is this a general behaviour or am I doing someting
> wrong?

Puzzling. Could you make your test file available for me to check?

Roger

>
> > absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>
> where I have:
>
> test_TNT.avl
> test_TNT.dbf
> test_TNT.prj
> test_TNT.shp
> test_TNT.shx
>
> with test_TNT.prj:
>
> PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM["D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS84[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]]
>
> I get:
> > class(delme)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
> > str(delme,max.level=2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>   ..@ data       :'data.frame': 1555 obs. of  16 variables:
>   ..@ polygons   :List of 1555
>   ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 1127
> 1160 ...
>   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>   .. ..- attr(*, "dimnames")=List of 2
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> > delme at proj4string
> CRS arguments: NA
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From greliermathieu at gmail.com  Thu Apr 10 09:21:01 2008
From: greliermathieu at gmail.com (mathieu grelier)
Date: Thu, 10 Apr 2008 09:21:01 +0200
Subject: [R-sig-Geo] Fwd:  dimensions do not match
In-Reply-To: <47FA3C06.6050509@uni-muenster.de>
References: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>
	<47F93200.3030207@uni-muenster.de>
	<6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>
	<47F9FA94.2000900@uni-muenster.de>
	<6d400d3e0804070735w776ae45dx3143cdedde6d3779@mail.gmail.com>
	<47FA3C06.6050509@uni-muenster.de>
Message-ID: <6d400d3e0804100021s374eaefetc61ba71809744ca1@mail.gmail.com>

Hi,
Yes, autokrige deals with duplicates.
But I found there were two problems, and the first come from the way
autokrige calls the krige function from gstat.
Edzer, you gave the answer : it was necessary to specify "nmax=30" in the call.
Automap doesn't do it and adding this argument to the call remove the
"memory.c" problem.

The second problem (dimensions do not match) comes from the formula
parameter for the krige function.
If your data column is z, and you want to perform ordinary kriging,
you have to specify z~1.
In my case, I only know the data column name at execution time as it
is a parameter in my script.
And I must admit that I didn't achieve to find the right code to pass
this parameter to the formula argument.
Basically "variable~1" doesn't work and I don't know why exactly.
It was my code that was wrong and if I use hard code to give the
formula argument to the autokrige call, it works fine.

So last question is :
-how can I modify "z~1" in the krige formula to be able to use my data
column parameter??

Thanks
Mathieu





2008/4/7, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> The following worked for me, although I didn't understand the result:
>
>  > zd = zerodist(sitesR)
>  > kriging_result = krige(valeur~1, sitesR[-zd[,1],], mask_SG, vgm(1, "Exp",
> 300), nmax = 30)
>
>  of course arbitrarily throwing away the first of each location-paired
> point, choosing an nmax, and some nonsense variogram.
>
>  Please keep r-sig-geo in the mail loop.
>
>  --
>  Edzer
>
>  mathieu grelier wrote:
>
> > Ok,
> > I've just tried to use zerodist before calling the autoKrige function
> > but the error remains the same (memory_c...).
> > Did you manage to perform the local kriging? You said there was still an
> error.
> >
> > I forward this message to the author of automap.
> > I don't know if automap can handle this situation.
> > Paul, please could you give us an answer about last question from edzer?
> >
> > Thanks
> > Mathieu
> >
> > ---------- Forwarded message ----------
> > From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> > Date: 7 avr. 2008 12:42
> > Subject: Re: [R-sig-Geo] dimensions do not match
> > To: mathieu grelier <greliermathieu at gmail.com>,
> r-sig-geo at stat.math.ethz.ch
> >
> >
> > Thanks Mathieu, for sending me the data off-line.
> >
> >  If you have a massive data set, you should use kriging within a local
> > neighbourhood to prevent forming and inverting a covariance matrix of
> > 4.3 Gb (24067 records, squared, times 8 bytes per double). You may try
> > to convince the author of automap to take care of this, automatically.
> >
> >  When applying local kriging to your data set, I get the error message:
> >
> >  > k = krige(valeur~1,sitesR,mask_SG,vgm(1, "Exp",300),
> nmax=30)
> >  [using ordinary kriging]
> >
> >  "chfactor.c", line 130: singular matrix in function LDLfactor()
> >  Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
> :
> >  LDLfactor
> >
> >  which is usually, and in this case as well, due to duplicate
> observations, try
> >
> >  > zerodist(sitesR)
> >
> >  Does automap take care of them, and if yes how?
> >  --
> >  Edzer
> >
> >
> >
> >
> >  mathieu grelier wrote:
> >
> >
> >
> > > Ok, this is the data I use and the commands.
> > > It is really weird because I use R CMD within grass and I can't
> > > reproduce exactly the same error message when I follow the commands
> > > directly in R.
> > > This is the message I get now :
> > >
> > > "memory.c", line 57: can't allocate memory in function m_get()
> > > Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>  :
> > >       m_get
> > >
> > > But, I already had this memory error when working on big datasets.
> > > In the same way, I looked on the archives to see if this memory
> > > problem could be solved and I didn't find anything.
> > >
> > > Do you know it?
> > > Thanks.
> > >
> > > Mathieu
> > >
> > >
> > > 2008/4/6, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> > >
> > >
> > >
> > >
> > > > Please send me the data as a .RData R data file, along with the steps
> that
> > > > led to the error message.
> > > >  --
> > > >  Edzer
> > > >
> > > >  mathieu grelier wrote:
> > > >
> > > >
> > > >
> > > >
> > > >
> > > > > A question about a problem already described in this list (
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > >
> https://stat.ethz.ch/pipermail/r-sig-geo/2006-July/001160.html),
> > > > but I
> > > >
> > > >
> > > >
> > > >
> > > > > didn't find any answer.
> > > > > I am trying to achieve ordinary kriging using gstat (via the
> autokrige
> > > > > package) in GRASS with a big dataset (24067 points).
> > > > >
> > > > > After the program removes duplicate data, I get the following same
> error :
> > > > > "Error : dimensions do not match: locations 39916 and data 24067"
> > > > > I don't have any NAs apparently.
> > > > > Checking logfile, I could see that the error is occurring in the
> krige
> > > > > function.
> > > > >
> > > > > Is there a known way to fix this problem?
> > > > > Maybe I can send my data, but I don't send it for now to the list as
> its
> > > > > weight is ~1Mo.
> > > > >
> > > > > Thanks
> > > > > Mathieu
> > > > >
> > > > >      [[alternative HTML version deleted]]
> > > > >
> > > > > _______________________________________________
> > > > > R-sig-Geo mailing list
> > > > > R-sig-Geo at stat.math.ethz.ch
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > >
> > > >
> > >
> >
>
>



From Friderike.Oehler at fao.org  Thu Apr 10 09:41:20 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Thu, 10 Apr 2008 09:41:20 +0200
Subject: [R-sig-Geo] readOGR and proj4 string
Message-ID: <1A28265B00AA7E4085BB761555D3FCE801752DD6@hqagex02.fao.org>

Not sure whether this is helpful, but I found that the same problem has been
reported elsewhere: http://osdir.com/ml/lang.r.geo/2006-09/msg00040.html

Importing with readShapePoly does not recognize existant .prj files neither,
but I guess that in this case it is not supposed to do so?

Friderike (Newbie)

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Roger Bivand
Sent: 10 April 2008 08:57
To: Agustin Lobo
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] readOGR and proj4 string


On Thu, 10 Apr 2008, Agustin Lobo wrote:

> The manual page of readOGR states:
>
> p4s 	PROJ4 string defining CRS, if default NULL, the value is read from
> the OGR data set
>
> then, if a  *.prj file is present for a *.shp,
> why is the proj4string of the resulting SpatialPolygonsDataframe set 
> to NA? is this a general behaviour or am I doing someting wrong?

Puzzling. Could you make your test file available for me to check?

Roger

>
> > absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>
> where I have:
>
> test_TNT.avl
> test_TNT.dbf
> test_TNT.prj
> test_TNT.shp
> test_TNT.shx
>
> with test_TNT.prj:
>
> PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM[
> "D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS8
> 4[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["
> Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"
> ],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",
> 3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",
> 500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]]
>
> I get:
> > class(delme)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
> > str(delme,max.level=2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>   ..@ data       :'data.frame': 1555 obs. of  16 variables:
>   ..@ polygons   :List of 1555
>   ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 1127 
> 1160 ...
>   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>   .. ..- attr(*, "dimnames")=List of 2
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> > delme at proj4string
> CRS arguments: NA
>
> Agus
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From p.hiemstra at geo.uu.nl  Thu Apr 10 10:21:04 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 10 Apr 2008 10:21:04 +0200
Subject: [R-sig-Geo] Fwd:  dimensions do not match
In-Reply-To: <6d400d3e0804100021s374eaefetc61ba71809744ca1@mail.gmail.com>
References: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>	
	<47F93200.3030207@uni-muenster.de>	
	<6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>	
	<47F9FA94.2000900@uni-muenster.de>	
	<6d400d3e0804070735w776ae45dx3143cdedde6d3779@mail.gmail.com>	
	<47FA3C06.6050509@uni-muenster.de>
	<6d400d3e0804100021s374eaefetc61ba71809744ca1@mail.gmail.com>
Message-ID: <47FDCDF0.7000101@geo.uu.nl>

Hi mathieu,

I'm not sure if I understand what your last question is. Why do you want 
to modify "z~1" if z is your data column name? If you want "variable~1" 
to work you need to change your column name to variable.

cheers,
Paul

mathieu grelier wrote:
> Hi,
> Yes, autokrige deals with duplicates.
> But I found there were two problems, and the first come from the way
> autokrige calls the krige function from gstat.
> Edzer, you gave the answer : it was necessary to specify "nmax=30" in the call.
> Automap doesn't do it and adding this argument to the call remove the
> "memory.c" problem.
>
> The second problem (dimensions do not match) comes from the formula
> parameter for the krige function.
> If your data column is z, and you want to perform ordinary kriging,
> you have to specify z~1.
> In my case, I only know the data column name at execution time as it
> is a parameter in my script.
> And I must admit that I didn't achieve to find the right code to pass
> this parameter to the formula argument.
> Basically "variable~1" doesn't work and I don't know why exactly.
> It was my code that was wrong and if I use hard code to give the
> formula argument to the autokrige call, it works fine.
>
> So last question is :
> -how can I modify "z~1" in the krige formula to be able to use my data
> column parameter??
>
> Thanks
> Mathieu
>
>
>
>
>
> 2008/4/7, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>   
>> The following worked for me, although I didn't understand the result:
>>
>>  > zd = zerodist(sitesR)
>>  > kriging_result = krige(valeur~1, sitesR[-zd[,1],], mask_SG, vgm(1, "Exp",
>> 300), nmax = 30)
>>
>>  of course arbitrarily throwing away the first of each location-paired
>> point, choosing an nmax, and some nonsense variogram.
>>
>>  Please keep r-sig-geo in the mail loop.
>>
>>  --
>>  Edzer
>>
>>  mathieu grelier wrote:
>>
>>     
>>> Ok,
>>> I've just tried to use zerodist before calling the autoKrige function
>>> but the error remains the same (memory_c...).
>>> Did you manage to perform the local kriging? You said there was still an
>>>       
>> error.
>>     
>>> I forward this message to the author of automap.
>>> I don't know if automap can handle this situation.
>>> Paul, please could you give us an answer about last question from edzer?
>>>
>>> Thanks
>>> Mathieu
>>>
>>> ---------- Forwarded message ----------
>>> From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
>>> Date: 7 avr. 2008 12:42
>>> Subject: Re: [R-sig-Geo] dimensions do not match
>>> To: mathieu grelier <greliermathieu at gmail.com>,
>>>       
>> r-sig-geo at stat.math.ethz.ch
>>     
>>> Thanks Mathieu, for sending me the data off-line.
>>>
>>>  If you have a massive data set, you should use kriging within a local
>>> neighbourhood to prevent forming and inverting a covariance matrix of
>>> 4.3 Gb (24067 records, squared, times 8 bytes per double). You may try
>>> to convince the author of automap to take care of this, automatically.
>>>
>>>  When applying local kriging to your data set, I get the error message:
>>>
>>>  > k = krige(valeur~1,sitesR,mask_SG,vgm(1, "Exp",300),
>>>       
>> nmax=30)
>>     
>>>  [using ordinary kriging]
>>>
>>>  "chfactor.c", line 130: singular matrix in function LDLfactor()
>>>  Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>>       
>> :
>>     
>>>  LDLfactor
>>>
>>>  which is usually, and in this case as well, due to duplicate
>>>       
>> observations, try
>>     
>>>  > zerodist(sitesR)
>>>
>>>  Does automap take care of them, and if yes how?
>>>  --
>>>  Edzer
>>>
>>>
>>>
>>>
>>>  mathieu grelier wrote:
>>>
>>>
>>>
>>>       
>>>> Ok, this is the data I use and the commands.
>>>> It is really weird because I use R CMD within grass and I can't
>>>> reproduce exactly the same error message when I follow the commands
>>>> directly in R.
>>>> This is the message I get now :
>>>>
>>>> "memory.c", line 57: can't allocate memory in function m_get()
>>>> Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>>>         
>>  :
>>     
>>>>       m_get
>>>>
>>>> But, I already had this memory error when working on big datasets.
>>>> In the same way, I looked on the archives to see if this memory
>>>> problem could be solved and I didn't find anything.
>>>>
>>>> Do you know it?
>>>> Thanks.
>>>>
>>>> Mathieu
>>>>
>>>>
>>>> 2008/4/6, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>>>>
>>>>
>>>>
>>>>
>>>>         
>>>>> Please send me the data as a .RData R data file, along with the steps
>>>>>           
>> that
>>     
>>>>> led to the error message.
>>>>>  --
>>>>>  Edzer
>>>>>
>>>>>  mathieu grelier wrote:
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>           
>>>>>> A question about a problem already described in this list (
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>             
>> https://stat.ethz.ch/pipermail/r-sig-geo/2006-July/001160.html),
>>     
>>>>> but I
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>           
>>>>>> didn't find any answer.
>>>>>> I am trying to achieve ordinary kriging using gstat (via the
>>>>>>             
>> autokrige
>>     
>>>>>> package) in GRASS with a big dataset (24067 points).
>>>>>>
>>>>>> After the program removes duplicate data, I get the following same
>>>>>>             
>> error :
>>     
>>>>>> "Error : dimensions do not match: locations 39916 and data 24067"
>>>>>> I don't have any NAs apparently.
>>>>>> Checking logfile, I could see that the error is occurring in the
>>>>>>             
>> krige
>>     
>>>>>> function.
>>>>>>
>>>>>> Is there a known way to fix this problem?
>>>>>> Maybe I can send my data, but I don't send it for now to the list as
>>>>>>             
>> its
>>     
>>>>>> weight is ~1Mo.
>>>>>>
>>>>>> Thanks
>>>>>> Mathieu
>>>>>>
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>             
>>>>>           
>>     


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From j.skoien at geo.uu.nl  Thu Apr 10 10:41:42 2008
From: j.skoien at geo.uu.nl (Jon Olav Skoien)
Date: Thu, 10 Apr 2008 10:41:42 +0200
Subject: [R-sig-Geo] Fwd:  dimensions do not match
In-Reply-To: <47FDCDF0.7000101@geo.uu.nl>
References: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>		<47F93200.3030207@uni-muenster.de>		<6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>		<47F9FA94.2000900@uni-muenster.de>		<6d400d3e0804070735w776ae45dx3143cdedde6d3779@mail.gmail.com>		<47FA3C06.6050509@uni-muenster.de>	<6d400d3e0804100021s374eaefetc61ba71809744ca1@mail.gmail.com>
	<47FDCDF0.7000101@geo.uu.nl>
Message-ID: <47FDD2C6.8020305@geo.uu.nl>

Hi,

I think Mathieu wanted to know how to create formula strings from 
variable names. The function "as.formula" should be able to do what he 
is looking for.

as.formula(paste(names(meuse)[4],"~",names(meuse)[6]) )

is an alternative way of calling a function with the formula zinc~dist, 
knowing that these are the 4th and 6th column respectively:

library(automap)
data(meuse)
coordinates(meuse) =~ x+y
names(meuse)
v1 = 
autofitVariogram(as.formula(paste(names(meuse)[4],"~",names(meuse)[6]) 
), meuse)
v1
v2 = autofitVariogram(zinc~dist,meuse)
v2

Cheers,
Jon

Paul Hiemstra wrote:
> Hi mathieu,
>
> I'm not sure if I understand what your last question is. Why do you want 
> to modify "z~1" if z is your data column name? If you want "variable~1" 
> to work you need to change your column name to variable.
>
> cheers,
> Paul
>
> mathieu grelier wrote:
>   
>> Hi,
>> Yes, autokrige deals with duplicates.
>> But I found there were two problems, and the first come from the way
>> autokrige calls the krige function from gstat.
>> Edzer, you gave the answer : it was necessary to specify "nmax=30" in the call.
>> Automap doesn't do it and adding this argument to the call remove the
>> "memory.c" problem.
>>
>> The second problem (dimensions do not match) comes from the formula
>> parameter for the krige function.
>> If your data column is z, and you want to perform ordinary kriging,
>> you have to specify z~1.
>> In my case, I only know the data column name at execution time as it
>> is a parameter in my script.
>> And I must admit that I didn't achieve to find the right code to pass
>> this parameter to the formula argument.
>> Basically "variable~1" doesn't work and I don't know why exactly.
>> It was my code that was wrong and if I use hard code to give the
>> formula argument to the autokrige call, it works fine.
>>
>> So last question is :
>> -how can I modify "z~1" in the krige formula to be able to use my data
>> column parameter??
>>
>> Thanks
>> Mathieu
>>
>>
>>
>>
>>
>> 2008/4/7, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>>   
>>     
>>> The following worked for me, although I didn't understand the result:
>>>
>>>  > zd = zerodist(sitesR)
>>>  > kriging_result = krige(valeur~1, sitesR[-zd[,1],], mask_SG, vgm(1, "Exp",
>>> 300), nmax = 30)
>>>
>>>  of course arbitrarily throwing away the first of each location-paired
>>> point, choosing an nmax, and some nonsense variogram.
>>>
>>>  Please keep r-sig-geo in the mail loop.
>>>
>>>  --
>>>  Edzer
>>>
>>>  mathieu grelier wrote:
>>>
>>>     
>>>       
>>>> Ok,
>>>> I've just tried to use zerodist before calling the autoKrige function
>>>> but the error remains the same (memory_c...).
>>>> Did you manage to perform the local kriging? You said there was still an
>>>>       
>>>>         
>>> error.
>>>     
>>>       
>>>> I forward this message to the author of automap.
>>>> I don't know if automap can handle this situation.
>>>> Paul, please could you give us an answer about last question from edzer?
>>>>
>>>> Thanks
>>>> Mathieu
>>>>
>>>> ---------- Forwarded message ----------
>>>> From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
>>>> Date: 7 avr. 2008 12:42
>>>> Subject: Re: [R-sig-Geo] dimensions do not match
>>>> To: mathieu grelier <greliermathieu at gmail.com>,
>>>>       
>>>>         
>>> r-sig-geo at stat.math.ethz.ch
>>>     
>>>       
>>>> Thanks Mathieu, for sending me the data off-line.
>>>>
>>>>  If you have a massive data set, you should use kriging within a local
>>>> neighbourhood to prevent forming and inverting a covariance matrix of
>>>> 4.3 Gb (24067 records, squared, times 8 bytes per double). You may try
>>>> to convince the author of automap to take care of this, automatically.
>>>>
>>>>  When applying local kriging to your data set, I get the error message:
>>>>
>>>>  > k = krige(valeur~1,sitesR,mask_SG,vgm(1, "Exp",300),
>>>>       
>>>>         
>>> nmax=30)
>>>     
>>>       
>>>>  [using ordinary kriging]
>>>>
>>>>  "chfactor.c", line 130: singular matrix in function LDLfactor()
>>>>  Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>>>       
>>>>         
>>> :
>>>     
>>>       
>>>>  LDLfactor
>>>>
>>>>  which is usually, and in this case as well, due to duplicate
>>>>       
>>>>         
>>> observations, try
>>>     
>>>       
>>>>  > zerodist(sitesR)
>>>>
>>>>  Does automap take care of them, and if yes how?
>>>>  --
>>>>  Edzer
>>>>
>>>>
>>>>
>>>>
>>>>  mathieu grelier wrote:
>>>>
>>>>
>>>>
>>>>       
>>>>         
>>>>> Ok, this is the data I use and the commands.
>>>>> It is really weird because I use R CMD within grass and I can't
>>>>> reproduce exactly the same error message when I follow the commands
>>>>> directly in R.
>>>>> This is the message I get now :
>>>>>
>>>>> "memory.c", line 57: can't allocate memory in function m_get()
>>>>> Error in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>>>>         
>>>>>           
>>>  :
>>>     
>>>       
>>>>>       m_get
>>>>>
>>>>> But, I already had this memory error when working on big datasets.
>>>>> In the same way, I looked on the archives to see if this memory
>>>>> problem could be solved and I didn't find anything.
>>>>>
>>>>> Do you know it?
>>>>> Thanks.
>>>>>
>>>>> Mathieu
>>>>>
>>>>>
>>>>> 2008/4/6, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>         
>>>>>           
>>>>>> Please send me the data as a .RData R data file, along with the steps
>>>>>>           
>>>>>>             
>>> that
>>>     
>>>       
>>>>>> led to the error message.
>>>>>>  --
>>>>>>  Edzer
>>>>>>
>>>>>>  mathieu grelier wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>           
>>>>>>             
>>>>>>> A question about a problem already described in this list (
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>             
>>>>>>>               
>>> https://stat.ethz.ch/pipermail/r-sig-geo/2006-July/001160.html),
>>>     
>>>       
>>>>>> but I
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>           
>>>>>>             
>>>>>>> didn't find any answer.
>>>>>>> I am trying to achieve ordinary kriging using gstat (via the
>>>>>>>             
>>>>>>>               
>>> autokrige
>>>     
>>>       
>>>>>>> package) in GRASS with a big dataset (24067 points).
>>>>>>>
>>>>>>> After the program removes duplicate data, I get the following same
>>>>>>>             
>>>>>>>               
>>> error :
>>>     
>>>       
>>>>>>> "Error : dimensions do not match: locations 39916 and data 24067"
>>>>>>> I don't have any NAs apparently.
>>>>>>> Checking logfile, I could see that the error is occurring in the
>>>>>>>             
>>>>>>>               
>>> krige
>>>     
>>>       
>>>>>>> function.
>>>>>>>
>>>>>>> Is there a known way to fix this problem?
>>>>>>> Maybe I can send my data, but I don't send it for now to the list as
>>>>>>>             
>>>>>>>               
>>> its
>>>     
>>>       
>>>>>>> weight is ~1Mo.
>>>>>>>
>>>>>>> Thanks
>>>>>>> Mathieu
>>>>>>>
>>>>>>>      [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>             
>>>>>>>               
>>>>>>           
>>>>>>             
>>>     
>>>       
>
>
>



From Roger.Bivand at nhh.no  Thu Apr 10 10:44:12 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Apr 2008 10:44:12 +0200 (CEST)
Subject: [R-sig-Geo] readOGR and proj4 string
In-Reply-To: <Pine.LNX.4.64.0804100856140.32757@reclus.nhh.no>
References: <47FDB6D6.9050402@ija.csic.es>
	<Pine.LNX.4.64.0804100856140.32757@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0804100953020.32757@reclus.nhh.no>

On Thu, 10 Apr 2008, Roger Bivand wrote:

> On Thu, 10 Apr 2008, Agustin Lobo wrote:
>
>> The manual page of readOGR states:
>>
>> p4s 	PROJ4 string defining CRS, if default NULL, the value is read from
>> the OGR data set
>>
>> then, if a  *.prj file is present for a *.shp,
>> why is the proj4string of the resulting SpatialPolygonsDataframe
>> set to NA? is this a general behaviour or am I doing someting
>> wrong?
>
> Puzzling. Could you make your test file available for me to check?

OK, thanks. I can reproduce the problem. PROJ.4 does not support 
projection "names" as such, they are often not unique (same name but 
different parameters. In addition, ED50 is a collection of standards, not 
one standard. I suggest entering:

t1 <- CRS(paste("+proj=utm +zone=31 +ellps=intl",
  "+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0")

manually. http://www.asprs.org/resources/grids/, July 200, gives different 
+towgs84= values. The ones in the file are prepended by a comma, which 
looks odd, but removing it doesn't help in parsing the file.

CRS("+init=epsg:23031")

is correct, but as usual with EPSG, no +towgs84= is given for ED50, 
because they vary so much.

So the underlying code in readOGR is erring on the side of caution - if 
the *.prj file cannot be interpreted unequivocally, return NA.

I set the value above:

x <- readOGR(".", "test_TNT")
proj4string(x) <- t1
x1 <- spTransform(x, CRS("+proj=longlat +datum=WGS84"))
writeOGR(x1, "x1.kml", "x1", driver="KML")

and viewed in Google Earth, things looked more-or-less OK. You could try 
the +towgs84 parameters from Grids & Datums and see if they fit better on 
the ground.

Hope this helps,

Roger

>
> Roger
>
>>
>>> absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>>
>> where I have:
>>
>> test_TNT.avl
>> test_TNT.dbf
>> test_TNT.prj
>> test_TNT.shp
>> test_TNT.shx
>>
>> with test_TNT.prj:
>>
>> PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM["D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS84[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]]
>>
>> I get:
>>> class(delme)
>> [1] "SpatialPolygonsDataFrame"
>> attr(,"package")
>> [1] "sp"
>>> str(delme,max.level=2)
>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>   ..@ data       :'data.frame': 1555 obs. of  16 variables:
>>   ..@ polygons   :List of 1555
>>   ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 1127
>> 1160 ...
>>   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>>   .. ..- attr(*, "dimnames")=List of 2
>>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>> delme at proj4string
>> CRS arguments: NA
>>
>> Agus
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From goarant at cebc.cnrs.fr  Thu Apr 10 14:07:52 2008
From: goarant at cebc.cnrs.fr (Anne GOARANT)
Date: Thu, 10 Apr 2008 14:07:52 +0200
Subject: [R-sig-Geo] spatial GLM using glmmPQL
Message-ID: <47FE0318.7070800@cebc.cnrs.fr>

Hi List,
I have observations of insect counts and environmental variables. My 
first goal was to compute a GLM to explain the insect counts with the 
environment. The thing is that my insect counts are not spatially 
independant and show spatial autocorrelation (a spherical variogram 
model can be fit to the data).
So I intend to compute the same GLM model and taking into account the 
spatial autocorrelation. The final objective would be to compare both 
model (spatial and non spatial and check which one is the best).
I read that a way to do a spatial GLM is using the glmmPQL function of 
MASS and putting all the observations in the same group for the random 
effect (Dorman, Ecography 30, 2007).  I was wondering if the "non 
computed" Log-Likelihood value (but it can be computed by changing a 
line code in the glmmPQL code function) is correct. I did some trials to 
compare the model outputs for the same dataset for glm and glmmPQL (with 
all the observations in the same group) and it gave me the same 
estimated parameters. It also gave me the same Log-Likelihood for both 
methods.
Do you have any idea if the Log-Likelihood from glmmPQL is correct when 
one considers all the data in the same group for the random effect?
Is there any other methods to do what I want (comparison of spatial and 
non-spatial GLM)?
Thanks for your help.
Anne



________ Information from NOD32 ________
This message was checked by NOD32 Antivirus System for Linux Mail Servers.
http://www.eset.com



From greliermathieu at gmail.com  Thu Apr 10 14:15:31 2008
From: greliermathieu at gmail.com (mathieu grelier)
Date: Thu, 10 Apr 2008 14:15:31 +0200
Subject: [R-sig-Geo] Fwd: dimensions do not match
In-Reply-To: <47FDD2C6.8020305@geo.uu.nl>
References: <6d400d3e0804020854o68d3df9ep78a6a3ef2ac4e327@mail.gmail.com>
	<47F93200.3030207@uni-muenster.de>
	<6d400d3e0804070206i2dbd3763j386111f86012d735@mail.gmail.com>
	<47F9FA94.2000900@uni-muenster.de>
	<6d400d3e0804070735w776ae45dx3143cdedde6d3779@mail.gmail.com>
	<47FA3C06.6050509@uni-muenster.de>
	<6d400d3e0804100021s374eaefetc61ba71809744ca1@mail.gmail.com>
	<47FDCDF0.7000101@geo.uu.nl> <47FDD2C6.8020305@geo.uu.nl>
Message-ID: <6d400d3e0804100515y2151e450rf8ed0e45706cfa4f@mail.gmail.com>

Yes that's it.
It works perfectly with my variable "column" for data column name :

as.formula(paste(column,"~",1))

Thank you all.

Mathieu

--------

2008/4/10, Jon Olav Skoien <j.skoien at geo.uu.nl>:
> Hi,
>
>  I think Mathieu wanted to know how to create formula strings from variable
> names. The function "as.formula" should be able to do what he is looking
> for.
>
>  as.formula(paste(names(meuse)[4],"~",names(meuse)[6]) )
>
>  is an alternative way of calling a function with the formula zinc~dist,
> knowing that these are the 4th and 6th column respectively:
>
>  library(automap)
>  data(meuse)
>  coordinates(meuse) =~ x+y
>  names(meuse)
>  v1 =
> autofitVariogram(as.formula(paste(names(meuse)[4],"~",names(meuse)[6])
> ), meuse)
>  v1
>  v2 = autofitVariogram(zinc~dist,meuse)
>  v2
>
>  Cheers,
>  Jon
>
>
>  Paul Hiemstra wrote:
>
> > Hi mathieu,
> >
> > I'm not sure if I understand what your last question is. Why do you want
> to modify "z~1" if z is your data column name? If you want "variable~1" to
> work you need to change your column name to variable.
> >
> > cheers,
> > Paul
> >
> > mathieu grelier wrote:
> >
> >
> > > Hi,
> > > Yes, autokrige deals with duplicates.
> > > But I found there were two problems, and the first come from the way
> > > autokrige calls the krige function from gstat.
> > > Edzer, you gave the answer : it was necessary to specify "nmax=30" in
> the call.
> > > Automap doesn't do it and adding this argument to the call remove the
> > > "memory.c" problem.
> > >
> > > The second problem (dimensions do not match) comes from the formula
> > > parameter for the krige function.
> > > If your data column is z, and you want to perform ordinary kriging,
> > > you have to specify z~1.
> > > In my case, I only know the data column name at execution time as it
> > > is a parameter in my script.
> > > And I must admit that I didn't achieve to find the right code to pass
> > > this parameter to the formula argument.
> > > Basically "variable~1" doesn't work and I don't know why exactly.
> > > It was my code that was wrong and if I use hard code to give the
> > > formula argument to the autokrige call, it works fine.
> > >
> > > So last question is :
> > > -how can I modify "z~1" in the krige formula to be able to use my data
> > > column parameter??
> > >
> > > Thanks
> > > Mathieu
> > >
> > >
> > >
> > >
> > >
> > > 2008/4/7, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> > >
> > >
> > > > The following worked for me, although I didn't understand the result:
> > > >
> > > >  > zd = zerodist(sitesR)
> > > >  > kriging_result = krige(valeur~1, sitesR[-zd[,1],], mask_SG, vgm(1,
> "Exp",
> > > > 300), nmax = 30)
> > > >
> > > >  of course arbitrarily throwing away the first of each location-paired
> > > > point, choosing an nmax, and some nonsense variogram.
> > > >
> > > >  Please keep r-sig-geo in the mail loop.
> > > >
> > > >  --
> > > >  Edzer
> > > >
> > > >  mathieu grelier wrote:
> > > >
> > > >
> > > >
> > > > > Ok,
> > > > > I've just tried to use zerodist before calling the autoKrige
> function
> > > > > but the error remains the same (memory_c...).
> > > > > Did you manage to perform the local kriging? You said there was
> still an
> > > > >
> > > > >
> > > > error.
> > > >
> > > >
> > > > > I forward this message to the author of automap.
> > > > > I don't know if automap can handle this situation.
> > > > > Paul, please could you give us an answer about last question from
> edzer?
> > > > >
> > > > > Thanks
> > > > > Mathieu
> > > > >
> > > > > ---------- Forwarded message ----------
> > > > > From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> > > > > Date: 7 avr. 2008 12:42
> > > > > Subject: Re: [R-sig-Geo] dimensions do not match
> > > > > To: mathieu grelier <greliermathieu at gmail.com>,
> > > > >
> > > > >
> > > > r-sig-geo at stat.math.ethz.ch
> > > >
> > > >
> > > > > Thanks Mathieu, for sending me the data off-line.
> > > > >
> > > > >  If you have a massive data set, you should use kriging within a
> local
> > > > > neighbourhood to prevent forming and inverting a covariance matrix
> of
> > > > > 4.3 Gb (24067 records, squared, times 8 bytes per double). You may
> try
> > > > > to convince the author of automap to take care of this,
> automatically.
> > > > >
> > > > >  When applying local kriging to your data set, I get the error
> message:
> > > > >
> > > > >  > k = krige(valeur~1,sitesR,mask_SG,vgm(1,
> "Exp",300),
> > > > >
> > > > >
> > > > nmax=30)
> > > >
> > > >
> > > > >  [using ordinary kriging]
> > > > >
> > > > >  "chfactor.c", line 130: singular matrix in function LDLfactor()
> > > > >  Error in predict.gstat(g, newdata = newdata, block = block, nsim =
> nsim,
> > > > >
> > > > >
> > > > :
> > > >
> > > >
> > > > >  LDLfactor
> > > > >
> > > > >  which is usually, and in this case as well, due to duplicate
> > > > >
> > > > >
> > > > observations, try
> > > >
> > > >
> > > > >  > zerodist(sitesR)
> > > > >
> > > > >  Does automap take care of them, and if yes how?
> > > > >  --
> > > > >  Edzer
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >  mathieu grelier wrote:
> > > > >
> > > > >
> > > > >
> > > > >
> > > > >
> > > > > > Ok, this is the data I use and the commands.
> > > > > > It is really weird because I use R CMD within grass and I can't
> > > > > > reproduce exactly the same error message when I follow the
> commands
> > > > > > directly in R.
> > > > > > This is the message I get now :
> > > > > >
> > > > > > "memory.c", line 57: can't allocate memory in function m_get()
> > > > > > Error in predict.gstat(g, newdata = newdata, block = block, nsim =
> nsim,
> > > > > >
> > > > > >
> > > > >
> > > >  :
> > > >
> > > >
> > > > >
> > > > > >      m_get
> > > > > >
> > > > > > But, I already had this memory error when working on big datasets.
> > > > > > In the same way, I looked on the archives to see if this memory
> > > > > > problem could be solved and I didn't find anything.
> > > > > >
> > > > > > Do you know it?
> > > > > > Thanks.
> > > > > >
> > > > > > Mathieu
> > > > > >
> > > > > >
> > > > > > 2008/4/6, Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > >
> > > > > > > Please send me the data as a .RData R data file, along with the
> steps
> > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > > that
> > > >
> > > >
> > > > >
> > > > > >
> > > > > > > led to the error message.
> > > > > > >  --
> > > > > > >  Edzer
> > > > > > >
> > > > > > >  mathieu grelier wrote:
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > > A question about a problem already described in this list (
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > >
> https://stat.ethz.ch/pipermail/r-sig-geo/2006-July/001160.html),
> > > >
> > > >
> > > > >
> > > > > >
> > > > > > > but I
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > > didn't find any answer.
> > > > > > > > I am trying to achieve ordinary kriging using gstat (via the
> > > > > > > >
> > > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > > autokrige
> > > >
> > > >
> > > > >
> > > > > >
> > > > > > >
> > > > > > > > package) in GRASS with a big dataset (24067 points).
> > > > > > > >
> > > > > > > > After the program removes duplicate data, I get the following
> same
> > > > > > > >
> > > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > > error :
> > > >
> > > >
> > > > >
> > > > > >
> > > > > > >
> > > > > > > > "Error : dimensions do not match: locations 39916 and data
> 24067"
> > > > > > > > I don't have any NAs apparently.
> > > > > > > > Checking logfile, I could see that the error is occurring in
> the
> > > > > > > >
> > > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > > krige
> > > >
> > > >
> > > > >
> > > > > >
> > > > > > >
> > > > > > > > function.
> > > > > > > >
> > > > > > > > Is there a known way to fix this problem?
> > > > > > > > Maybe I can send my data, but I don't send it for now to the
> list as
> > > > > > > >
> > > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > > its
> > > >
> > > >
> > > > >
> > > > > >
> > > > > > >
> > > > > > > > weight is ~1Mo.
> > > > > > > >
> > > > > > > > Thanks
> > > > > > > > Mathieu
> > > > > > > >
> > > > > > > >     [[alternative HTML version deleted]]
> > > > > > > >
> > > > > > > >
> _______________________________________________
> > > > > > > > R-sig-Geo mailing list
> > > > > > > > R-sig-Geo at stat.math.ethz.ch
> > > > > > > >
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > > >
> > > > > > >
> > > > > > >
> > > > > >
> > > > >
> > > >
> > > >
> > >
> >
> >
> >
> >
>



From alexandru.dumitrescu at gmail.com  Thu Apr 10 14:16:29 2008
From: alexandru.dumitrescu at gmail.com (Alexandru Dumitrescu)
Date: Thu, 10 Apr 2008 15:16:29 +0300
Subject: [R-sig-Geo] join csv tables
Message-ID: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080410/04b4a5a2/attachment.pl>

From spluque at gmail.com  Thu Apr 10 14:19:13 2008
From: spluque at gmail.com (Sebastian P. Luque)
Date: Thu, 10 Apr 2008 07:19:13 -0500
Subject: [R-sig-Geo] join csv tables
References: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
Message-ID: <87k5j57vi6.fsf@patagonia.sebmags.homelinux.org>

On Thu, 10 Apr 2008 15:16:29 +0300,
"Alexandru Dumitrescu" <alexandru.dumitrescu at gmail.com> wrote:

> Hi everybody, Is there a way to join two csv tables in R using a
> common column having the same values?

Yes, ?merge


-- 
Seb



From Roger.Bivand at nhh.no  Thu Apr 10 14:19:07 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Apr 2008 14:19:07 +0200 (CEST)
Subject: [R-sig-Geo] join csv tables
In-Reply-To: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
References: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0804101418470.32757@reclus.nhh.no>

On Thu, 10 Apr 2008, Alexandru Dumitrescu wrote:

> Hi everybody,
> Is there a way to join two csv tables
> in R using a common column having the same values?

?merge

>
> Alexandru Dumitrescu
> NATIONAL METEOROLOGICAL ADMINISTRATION
> Sos. Bucuresti-Ploiesti, Nr. 97
> Bucuresti 013686, ROMANIA
> Tel. +40-21-3183240 / 142
> Fax: +40-21-3167762
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From edzer.pebesma at uni-muenster.de  Thu Apr 10 14:24:42 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 10 Apr 2008 14:24:42 +0200
Subject: [R-sig-Geo] join csv tables
In-Reply-To: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
References: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
Message-ID: <47FE070A.9090902@uni-muenster.de>

This has little to do with r-sig-geo, but have a look at ?merge

After you import the csv table with read.csv, you can write it out with 
write.csv.
--
Edzer

Alexandru Dumitrescu wrote:
> Hi everybody,
> Is there a way to join two csv tables
> in R using a common column having the same values?
>
> Alexandru Dumitrescu
> NATIONAL METEOROLOGICAL ADMINISTRATION
> Sos. Bucuresti-Ploiesti, Nr. 97
> Bucuresti 013686, ROMANIA
> Tel. +40-21-3183240 / 142
> Fax: +40-21-3167762
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From szybalski at gmail.com  Thu Apr 10 15:44:59 2008
From: szybalski at gmail.com (Lukasz Szybalski)
Date: Thu, 10 Apr 2008 08:44:59 -0500
Subject: [R-sig-Geo] join csv tables
In-Reply-To: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
References: <c578a12e0804100516n50f51f40gf092ed569fe84d44@mail.gmail.com>
Message-ID: <804e5c70804100644o2aef890dpd46c12592badae58@mail.gmail.com>

On Thu, Apr 10, 2008 at 7:16 AM, Alexandru Dumitrescu
<alexandru.dumitrescu at gmail.com> wrote:
> Hi everybody,
>  Is there a way to join two csv tables
>  in R using a common column having the same values?
>

FYI.

If you wanted to do it outside of R, before your read it in, you could
use this script:

http://lucasmanual.com/out/combine.py

#Program that combines multiple tsv files into one based on the column name
#Requirement: Same column names that exist on first row
#Action: Will combine all tsv that are in current directory, and
output all.tsv file

You can change line 20 to: 	reader= csv.reader(open(i))
to read csv instead of tsv.

Then do:
python combine.py   (and this will merge all csv in folder into all.csv)

Lucas



From Agustin.Lobo at ija.csic.es  Thu Apr 10 16:14:23 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 10 Apr 2008 16:14:23 +0200
Subject: [R-sig-Geo] readOGR and proj4 string
In-Reply-To: <Pine.LNX.4.64.0804100953020.32757@reclus.nhh.no>
References: <47FDB6D6.9050402@ija.csic.es>
	<Pine.LNX.4.64.0804100856140.32757@reclus.nhh.no>
	<Pine.LNX.4.64.0804100953020.32757@reclus.nhh.no>
Message-ID: <47FE20BF.70901@ija.csic.es>

Thanks,

This is what I'm doing:

 > absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
 > t1 <- CRS(paste("+proj=utm +zone=31 
+ellps=intl","+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0"))
 > proj4string(absUTMpolysHABS2) <-t1
 > proj4string(x) <-t1

As my goal is
 > a <- (joinPolys(SpatialPolygons2PolySet(x), 
SpatialPolygons2PolySet(absUTMpolysHABS2)))

the critical issue is that both objects have the
same proj4string. But I'm saving absUTMpolysHABS2 again
as shp and will look at it carefully to clarify
the problem of the ED50 definition.

But I'm getting this problem, which seems to be related to the
proj4string:

 > a1 <- SpatialPolygons2PolySet(absUTMpolysHABS2)
 > a2 <- PolySet2SpatialPolygons(a1)
Error in CRS(p4s) : invalid UTM zone number

 > summary(a1)
PolySet

Records         : 95995
   Contours      : 1595
     Holes       : 0
   Events        : NA
     On boundary : NA

Ranges
   X             : [412000, 466000]
   Y             : [4584000, 4624000]

Attributes
   Projection    : UTM
   Zone          : 31

Extra columns   :

Agus

Roger Bivand escribi?:
> On Thu, 10 Apr 2008, Roger Bivand wrote:
> 
>> On Thu, 10 Apr 2008, Agustin Lobo wrote:
>>
>>> The manual page of readOGR states:
>>>
>>> p4s     PROJ4 string defining CRS, if default NULL, the value is read 
>>> from
>>> the OGR data set
>>>
>>> then, if a  *.prj file is present for a *.shp,
>>> why is the proj4string of the resulting SpatialPolygonsDataframe
>>> set to NA? is this a general behaviour or am I doing someting
>>> wrong?
>>
>> Puzzling. Could you make your test file available for me to check?
> 
> OK, thanks. I can reproduce the problem. PROJ.4 does not support 
> projection "names" as such, they are often not unique (same name but 
> different parameters. In addition, ED50 is a collection of standards, 
> not one standard. I suggest entering:
> 
> t1 <- CRS(paste("+proj=utm +zone=31 +ellps=intl",
>  "+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0")
> 
> manually. http://www.asprs.org/resources/grids/, July 200, gives 
> different +towgs84= values. The ones in the file are prepended by a 
> comma, which looks odd, but removing it doesn't help in parsing the file.
> 
> CRS("+init=epsg:23031")
> 
> is correct, but as usual with EPSG, no +towgs84= is given for ED50, 
> because they vary so much.
> 
> So the underlying code in readOGR is erring on the side of caution - if 
> the *.prj file cannot be interpreted unequivocally, return NA.
> 
> I set the value above:
> 
> x <- readOGR(".", "test_TNT")
> proj4string(x) <- t1
> x1 <- spTransform(x, CRS("+proj=longlat +datum=WGS84"))
> writeOGR(x1, "x1.kml", "x1", driver="KML")
> 
> and viewed in Google Earth, things looked more-or-less OK. You could try 
> the +towgs84 parameters from Grids & Datums and see if they fit better 
> on the ground.
> 
> Hope this helps,
> 
> Roger
> 
>>
>> Roger
>>
>>>
>>>> absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>>>
>>> where I have:
>>>
>>> test_TNT.avl
>>> test_TNT.dbf
>>> test_TNT.prj
>>> test_TNT.shp
>>> test_TNT.shx
>>>
>>> with test_TNT.prj:
>>>
>>> PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM["D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS84[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]] 
>>>
>>>
>>> I get:
>>>> class(delme)
>>> [1] "SpatialPolygonsDataFrame"
>>> attr(,"package")
>>> [1] "sp"
>>>> str(delme,max.level=2)
>>> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>>   ..@ data       :'data.frame': 1555 obs. of  16 variables:
>>>   ..@ polygons   :List of 1555
>>>   ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 1127
>>> 1160 ...
>>>   ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>>>   .. ..- attr(*, "dimnames")=List of 2
>>>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>>> delme at proj4string
>>> CRS arguments: NA
>>>
>>> Agus
>>>
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Thu Apr 10 16:21:21 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 10 Apr 2008 16:21:21 +0200
Subject: [R-sig-Geo] PolySet2SpatialPolygons: ring not closed
Message-ID: <47FE2261.2050306@ija.csic.es>

I do:

 > a <- (joinPolys(SpatialPolygons2PolySet(x), 		 
SpatialPolygons2PolySet(absUTMpolysHABS2)))
 > str(a,max.level=2)
Classes ?PolySet? and 'data.frame':     506 obs. of  5 variables:
  $ PID: int  5 5 5 5 5 5 5 5 5 5 ...
  $ SID: int  1 1 1 1 1 1 1 1 1 1 ...
  $ POS: int  1 2 3 4 5 6 7 8 9 10 ...
  $ X  : num  418438 418452 418452 418452 418451 ...
  $ Y  : num  4591484 4591478 4591477 4591477 4591476 ...
  - attr(*, "projection")= chr "UTM"
  - attr(*, "zone")= int 31

 > ab <- PolySet2SpatialPolygons(a)
Error in validityMethod(object) : ring not closed

any way to clarify this error? plotMap(a) seems correct.

Thanks

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From andrew.niccolai at yale.edu  Thu Apr 10 16:28:38 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Thu, 10 Apr 2008 10:28:38 -0400
Subject: [R-sig-Geo] PolySet2SpatialPolygons: ring not closed
In-Reply-To: <47FE2261.2050306@ija.csic.es>
References: <47FE2261.2050306@ija.csic.es>
Message-ID: <000901c89b17$2b13f360$813bda20$@niccolai@yale.edu>

Sorry, I have never run into this issue but maybe Roger can weigh in on this
as he was the source "coder" for these functions.  Did you try including the
close_polys=TRUE line in PolySet2SpatialPolygons?  It more than likely
defaults to TRUE but it might be worth a shot to see.

Andrew 

-----Original Message-----
From: Agustin Lobo [mailto:aloboaleu at gmail.com] On Behalf Of Agustin Lobo
Sent: Thursday, April 10, 2008 10:21 AM
To: Andrew Niccolai; r-sig-geo at stat.math.ethz.ch
Subject: PolySet2SpatialPolygons: ring not closed

I do:

 > a <- (joinPolys(SpatialPolygons2PolySet(x), 		 
SpatialPolygons2PolySet(absUTMpolysHABS2)))
 > str(a,max.level=2)
Classes 'PolySet' and 'data.frame':     506 obs. of  5 variables:
  $ PID: int  5 5 5 5 5 5 5 5 5 5 ...
  $ SID: int  1 1 1 1 1 1 1 1 1 1 ...
  $ POS: int  1 2 3 4 5 6 7 8 9 10 ...
  $ X  : num  418438 418452 418452 418452 418451 ...
  $ Y  : num  4591484 4591478 4591477 4591477 4591476 ...
  - attr(*, "projection")= chr "UTM"
  - attr(*, "zone")= int 31

 > ab <- PolySet2SpatialPolygons(a)
Error in validityMethod(object) : ring not closed

any way to clarify this error? plotMap(a) seems correct.

Thanks

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Thu Apr 10 16:55:22 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 10 Apr 2008 16:55:22 +0200 (CEST)
Subject: [R-sig-Geo] readOGR and proj4 string
In-Reply-To: <47FE20BF.70901@ija.csic.es>
References: <47FDB6D6.9050402@ija.csic.es>
	<Pine.LNX.4.64.0804100856140.32757@reclus.nhh.no>
	<Pine.LNX.4.64.0804100953020.32757@reclus.nhh.no>
	<47FE20BF.70901@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0804101638120.32757@reclus.nhh.no>

On Thu, 10 Apr 2008, Agustin Lobo wrote:

> Thanks,
>
> This is what I'm doing:
>
>>  absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>>  t1 <- CRS(paste("+proj=utm +zone=31 
> +ellps=intl","+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0"))
>>  proj4string(absUTMpolysHABS2) <-t1
>>  proj4string(x) <-t1
>
> As my goal is
>>  a <- (joinPolys(SpatialPolygons2PolySet(x), 
> SpatialPolygons2PolySet(absUTMpolysHABS2)))
>
> the critical issue is that both objects have the
> same proj4string. But I'm saving absUTMpolysHABS2 again
> as shp and will look at it carefully to clarify
> the problem of the ED50 definition.
>
> But I'm getting this problem, which seems to be related to the
> proj4string:
>
>>  a1 <- SpatialPolygons2PolySet(absUTMpolysHABS2)
>>  a2 <- PolySet2SpatialPolygons(a1)
> Error in CRS(p4s) : invalid UTM zone number

Please ensure that t1 looks sane, spaces between tag=value pairs.

PBS have changed the way they store the UTM zone - it is now a top level 
attribute, but was an attribute of an attribute:

t1 <- CRS(paste("+proj=utm +zone=31 +ellps=intl",
    "+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0"))
proj4string(x) <- t1
a1 <- SpatialPolygons2PolySet(x)
attr(a1, "projection")
attr(attr(a1, "projection"), "zone") <- attr(a1, "zone")
attr(a1, "projection")
a2 <- PolySet2SpatialPolygons(a1)

I'll update the function in due course.

Hope this helps,

Roger

>
>>  summary(a1)
> PolySet
>
> Records         : 95995
>   Contours      : 1595
>     Holes       : 0
>   Events        : NA
>     On boundary : NA
>
> Ranges
>   X             : [412000, 466000]
>   Y             : [4584000, 4624000]
>
> Attributes
>   Projection    : UTM
>   Zone          : 31
>
> Extra columns   :
>
> Agus
>
> Roger Bivand escribi?:
>>  On Thu, 10 Apr 2008, Roger Bivand wrote:
>> 
>> >  On Thu, 10 Apr 2008, Agustin Lobo wrote:
>> > 
>> > >  The manual page of readOGR states:
>> > > 
>> > >  p4s     PROJ4 string defining CRS, if default NULL, the value is read 
>> > >  from
>> > >  the OGR data set
>> > > 
>> > >  then, if a  *.prj file is present for a *.shp,
>> > >  why is the proj4string of the resulting SpatialPolygonsDataframe
>> > >  set to NA? is this a general behaviour or am I doing someting
>> > >  wrong?
>> > 
>> >  Puzzling. Could you make your test file available for me to check?
>>
>>  OK, thanks. I can reproduce the problem. PROJ.4 does not support
>>  projection "names" as such, they are often not unique (same name but
>>  different parameters. In addition, ED50 is a collection of standards, not
>>  one standard. I suggest entering:
>>
>>  t1 <- CRS(paste("+proj=utm +zone=31 +ellps=intl",
>>   "+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0")
>>
>>  manually. http://www.asprs.org/resources/grids/, July 200, gives different
>>  +towgs84= values. The ones in the file are prepended by a comma, which
>>  looks odd, but removing it doesn't help in parsing the file.
>>
>>  CRS("+init=epsg:23031")
>>
>>  is correct, but as usual with EPSG, no +towgs84= is given for ED50,
>>  because they vary so much.
>>
>>  So the underlying code in readOGR is erring on the side of caution - if
>>  the *.prj file cannot be interpreted unequivocally, return NA.
>>
>>  I set the value above:
>>
>>  x <- readOGR(".", "test_TNT")
>>  proj4string(x) <- t1
>>  x1 <- spTransform(x, CRS("+proj=longlat +datum=WGS84"))
>>  writeOGR(x1, "x1.kml", "x1", driver="KML")
>>
>>  and viewed in Google Earth, things looked more-or-less OK. You could try
>>  the +towgs84 parameters from Grids & Datums and see if they fit better on
>>  the ground.
>>
>>  Hope this helps,
>>
>>  Roger
>> 
>> > 
>> >  Roger
>> > 
>> > > 
>> > > >  absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>> > > 
>> > >  where I have:
>> > > 
>> > >  test_TNT.avl
>> > >  test_TNT.dbf
>> > >  test_TNT.prj
>> > >  test_TNT.shp
>> > >  test_TNT.shx
>> > > 
>> > >  with test_TNT.prj:
>> > > 
>> > >  PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM["D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS84[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]] 
>> > > 
>> > > 
>> > >  I get:
>> > > >  class(delme)
>> > >  [1] "SpatialPolygonsDataFrame"
>> > >  attr(,"package")
>> > >  [1] "sp"
>> > > >  str(delme,max.level=2)
>> > >  Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>> > >    ..@ data       :'data.frame': 1555 obs. of  16 variables:
>> > >    ..@ polygons   :List of 1555
>> > >    ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 1127
>> > >  1160 ...
>> > >    ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>> > >    .. ..- attr(*, "dimnames")=List of 2
>> > >    ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>> > > >  delme at proj4string
>> > >  CRS arguments: NA
>> > > 
>> > >  Agus
>> > > 
>> > 
>> >
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Agustin.Lobo at ija.csic.es  Thu Apr 10 17:44:49 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Thu, 10 Apr 2008 17:44:49 +0200
Subject: [R-sig-Geo] readOGR and proj4 string
In-Reply-To: <Pine.LNX.4.64.0804101638120.32757@reclus.nhh.no>
References: <47FDB6D6.9050402@ija.csic.es>
	<Pine.LNX.4.64.0804100856140.32757@reclus.nhh.no>
	<Pine.LNX.4.64.0804100953020.32757@reclus.nhh.no>
	<47FE20BF.70901@ija.csic.es>
	<Pine.LNX.4.64.0804101638120.32757@reclus.nhh.no>
Message-ID: <47FE35F1.8030300@ija.csic.es>

It works fine now, thanks.
Then, back to the original problem of recovering
a SpatialPolygonsDataFrame from a PolySet
(which I get after joinPolys() ):

a1 <- SpatialPolygons2PolySet(x)
attr(a1, "projection")
attr(attr(a1, "projection"), "zone") <- attr(a1, "zone")
attr(a1, "projection")
a2 <- PolySet2SpatialPolygons(a1)
a3 <- SpatialPolygonsDataFrame(a2,x at data)

where a3 is identical to x, right?

Almost there. The problem with the ring
after joinPolys() remains, though. Also, once
I'll able to get the result of joinPolys() back to
SpatialPolygons I will have to subset and update
the original data.frame.

Agus

Roger Bivand escribi?:
> On Thu, 10 Apr 2008, Agustin Lobo wrote:
> 
>> Thanks,
>>
>> This is what I'm doing:
>>
>>>  absUTMpolysHABS2 <- readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>>>  t1 <- CRS(paste("+proj=utm +zone=31 
>> +ellps=intl","+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0"))
>>>  proj4string(absUTMpolysHABS2) <-t1
>>>  proj4string(x) <-t1
>>
>> As my goal is
>>>  a <- (joinPolys(SpatialPolygons2PolySet(x), 
>> SpatialPolygons2PolySet(absUTMpolysHABS2)))
>>
>> the critical issue is that both objects have the
>> same proj4string. But I'm saving absUTMpolysHABS2 again
>> as shp and will look at it carefully to clarify
>> the problem of the ED50 definition.
>>
>> But I'm getting this problem, which seems to be related to the
>> proj4string:
>>
>>>  a1 <- SpatialPolygons2PolySet(absUTMpolysHABS2)
>>>  a2 <- PolySet2SpatialPolygons(a1)
>> Error in CRS(p4s) : invalid UTM zone number
> 
> Please ensure that t1 looks sane, spaces between tag=value pairs.
> 
> PBS have changed the way they store the UTM zone - it is now a top level 
> attribute, but was an attribute of an attribute:
> 
> t1 <- CRS(paste("+proj=utm +zone=31 +ellps=intl",
>    "+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0"))
> proj4string(x) <- t1
> a1 <- SpatialPolygons2PolySet(x)
> attr(a1, "projection")
> attr(attr(a1, "projection"), "zone") <- attr(a1, "zone")
> attr(a1, "projection")
> a2 <- PolySet2SpatialPolygons(a1)
> 
> I'll update the function in due course.
> 
> Hope this helps,
> 
> Roger
> 
>>
>>>  summary(a1)
>> PolySet
>>
>> Records         : 95995
>>   Contours      : 1595
>>     Holes       : 0
>>   Events        : NA
>>     On boundary : NA
>>
>> Ranges
>>   X             : [412000, 466000]
>>   Y             : [4584000, 4624000]
>>
>> Attributes
>>   Projection    : UTM
>>   Zone          : 31
>>
>> Extra columns   :
>>
>> Agus
>>
>> Roger Bivand escribi?:
>>>  On Thu, 10 Apr 2008, Roger Bivand wrote:
>>>
>>> >  On Thu, 10 Apr 2008, Agustin Lobo wrote:
>>> > > >  The manual page of readOGR states:
>>> > > > >  p4s     PROJ4 string defining CRS, if default NULL, the 
>>> value is read > >  from
>>> > >  the OGR data set
>>> > > > >  then, if a  *.prj file is present for a *.shp,
>>> > >  why is the proj4string of the resulting SpatialPolygonsDataframe
>>> > >  set to NA? is this a general behaviour or am I doing someting
>>> > >  wrong?
>>> > >  Puzzling. Could you make your test file available for me to check?
>>>
>>>  OK, thanks. I can reproduce the problem. PROJ.4 does not support
>>>  projection "names" as such, they are often not unique (same name but
>>>  different parameters. In addition, ED50 is a collection of 
>>> standards, not
>>>  one standard. I suggest entering:
>>>
>>>  t1 <- CRS(paste("+proj=utm +zone=31 +ellps=intl",
>>>   "+towgs84=-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0")
>>>
>>>  manually. http://www.asprs.org/resources/grids/, July 200, gives 
>>> different
>>>  +towgs84= values. The ones in the file are prepended by a comma, which
>>>  looks odd, but removing it doesn't help in parsing the file.
>>>
>>>  CRS("+init=epsg:23031")
>>>
>>>  is correct, but as usual with EPSG, no +towgs84= is given for ED50,
>>>  because they vary so much.
>>>
>>>  So the underlying code in readOGR is erring on the side of caution - if
>>>  the *.prj file cannot be interpreted unequivocally, return NA.
>>>
>>>  I set the value above:
>>>
>>>  x <- readOGR(".", "test_TNT")
>>>  proj4string(x) <- t1
>>>  x1 <- spTransform(x, CRS("+proj=longlat +datum=WGS84"))
>>>  writeOGR(x1, "x1.kml", "x1", driver="KML")
>>>
>>>  and viewed in Google Earth, things looked more-or-less OK. You could 
>>> try
>>>  the +towgs84 parameters from Grids & Datums and see if they fit 
>>> better on
>>>  the ground.
>>>
>>>  Hope this helps,
>>>
>>>  Roger
>>>
>>> > >  Roger
>>> > > > > > >  absUTMpolysHABS2 <- 
>>> readOGR("C:/ALOBO/Lidia",layer="test_TNT")
>>> > > > >  where I have:
>>> > > > >  test_TNT.avl
>>> > >  test_TNT.dbf
>>> > >  test_TNT.prj
>>> > >  test_TNT.shp
>>> > >  test_TNT.shx
>>> > > > >  with test_TNT.prj:
>>> > > > >  
>>> PROJCS["ED50_/_UTM_zone_31N_(CM_3E)",GEOGCS["ED50_/_Geographic",DATUM["D_European_1950",SPHEROID["International_1924",6378388.0,297.0]TOWGS84[,-87.0,-98.0,-121.0,0.0,0.0,0.0,0.0]],PRIMEM["Greenwich",0.0],UNIT["Decimal_Degree",0.01745329251994330]],PROJECTION["Transverse_Mercator"],PARAMETER["Latitude_Of_Center",0.0],PARAMETER["Longitude_Of_Origin",3.0],PARAMETER["Scale_Factor",0.9996000000],PARAMETER["False_Easting",500000.0],PARAMETER["False_Northing",0.0],UNIT["Meter",1.0]] 
>>> > > > > > >  I get:
>>> > > >  class(delme)
>>> > >  [1] "SpatialPolygonsDataFrame"
>>> > >  attr(,"package")
>>> > >  [1] "sp"
>>> > > >  str(delme,max.level=2)
>>> > >  Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>>> > >    ..@ data       :'data.frame': 1555 obs. of  16 variables:
>>> > >    ..@ polygons   :List of 1555
>>> > >    ..@ plotOrder  : int [1:1555] 148 143 792 740 209 335 895 619 
>>> 1127
>>> > >  1160 ...
>>> > >    ..@ bbox       : num [1:2, 1:2]  412000 4584000  466000 4624000
>>> > >    .. ..- attr(*, "dimnames")=List of 2
>>> > >    ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>> > > >  delme at proj4string
>>> > >  CRS arguments: NA
>>> > > > >  Agus
>>> > > > >
>>>
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From mardones.p at gmail.com  Fri Apr 11 03:19:34 2008
From: mardones.p at gmail.com (Pedro Mardones)
Date: Thu, 10 Apr 2008 21:19:34 -0400
Subject: [R-sig-Geo] semivariogram + coordinate units
Message-ID: <83dca7860804101819g6d9a72b0pa9d1227e538bdc9a@mail.gmail.com>

Dear list members;
I'm a newbie in geostatistics so this question may have an obvious
answer that I'm not aware of (sorry about this). I've a grid of points
in which the x-axis is measured in cm (from 1 to 20) and the y-axis in
meters (from 1 to 20). So basically I have 20 x 20 points to work
with. Here is where I'm kind of confused. Do I need to transform the
coordinates to the same units, say cm or meters, before obtaining an
empirical semivariogram? What could be the effect of using the
coordinates in the given units (ie without transforming them to the
same units) on the analysis?
Thanks for any hint
PM



From scionforbai at gmail.com  Fri Apr 11 04:46:18 2008
From: scionforbai at gmail.com (Scionforbai)
Date: Fri, 11 Apr 2008 04:46:18 +0200
Subject: [R-sig-Geo] semivariogram + coordinate units
In-Reply-To: <83dca7860804101819g6d9a72b0pa9d1227e538bdc9a@mail.gmail.com>
References: <83dca7860804101819g6d9a72b0pa9d1227e538bdc9a@mail.gmail.com>
Message-ID: <e9ee1f0a0804101946m27d8cc55g36203828e23083d8@mail.gmail.com>

> What could be the effect of using the  coordinates in the given units
> (ie without transforming them to the same units) on the analysis?

It would be a strange kind of "anisotropy" if you want to calculate
the empirical omni-directional variogram. Indeed, the semivariogram is
a vectorial function. In the expression:
gamma(h)=E[Z(x+h)-Z(x)]?
h is a vector; of course it is supposed that both coordinates have the
same units. If not, you are working on a transformed space, not on a
cartesian one.

Such things are done to filter anisotropy of data (i.e.
stratification, "zonal anisotropy"); but they are meaningful only if
you compute the directional variograms (one in the x-direction, one in
the y-dir, each with its own unit).

Do the transformation.

ScionForbai

From Roger.Bivand at nhh.no  Fri Apr 11 09:38:03 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 11 Apr 2008 09:38:03 +0200 (CEST)
Subject: [R-sig-Geo] spatial GLM using glmmPQL
In-Reply-To: <47FE0318.7070800@cebc.cnrs.fr>
References: <47FE0318.7070800@cebc.cnrs.fr>
Message-ID: <Pine.LNX.4.64.0804110930000.3973@reclus.nhh.no>

On Thu, 10 Apr 2008, Anne GOARANT wrote:

> Hi List,
> I have observations of insect counts and environmental variables. My
> first goal was to compute a GLM to explain the insect counts with the
> environment. The thing is that my insect counts are not spatially
> independant and show spatial autocorrelation (a spherical variogram
> model can be fit to the data).
> So I intend to compute the same GLM model and taking into account the
> spatial autocorrelation. The final objective would be to compare both
> model (spatial and non spatial and check which one is the best).
> I read that a way to do a spatial GLM is using the glmmPQL function of
> MASS and putting all the observations in the same group for the random
> effect (Dorman, Ecography 30, 2007).  I was wondering if the "non
> computed" Log-Likelihood value (but it can be computed by changing a
> line code in the glmmPQL code function) is correct. I did some trials to
> compare the model outputs for the same dataset for glm and glmmPQL (with
> all the observations in the same group) and it gave me the same
> estimated parameters. It also gave me the same Log-Likelihood for both
> methods.
> Do you have any idea if the Log-Likelihood from glmmPQL is correct when
> one considers all the data in the same group for the random effect?
> Is there any other methods to do what I want (comparison of spatial and
> non-spatial GLM)?

When this came up recently on R-help, Douglas Bates, whose views deserve 
respect, commented that using a single group was not advisable:

https://stat.ethz.ch/pipermail/r-help/2008-March/157672.html

Using one group for each observation may be another alternative. The 
choice in the Dormann et al. paper was motivated by a desire to get the 
same results as SAS GLIMMIX, not by any considered judgement - the authors 
in fact call their "hack" an "abuse" of the method (see the electronic 
supplement).

Hope this helps,

Roger

> Thanks for your help.
> Anne
>
>
>
> ________ Information from NOD32 ________
> This message was checked by NOD32 Antivirus System for Linux Mail Servers.
> http://www.eset.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mardones.p at gmail.com  Fri Apr 11 20:10:46 2008
From: mardones.p at gmail.com (Pedro Mardones)
Date: Fri, 11 Apr 2008 14:10:46 -0400
Subject: [R-sig-Geo] semivariogram + coordinate units
In-Reply-To: <2439f5740804110622m8678612h2cbfa85b079a7364@mail.gmail.com>
References: <83dca7860804101819g6d9a72b0pa9d1227e538bdc9a@mail.gmail.com>
	<2439f5740804110622m8678612h2cbfa85b079a7364@mail.gmail.com>
Message-ID: <83dca7860804111110u52e2e35bpff44488a98f36283@mail.gmail.com>

Thanks for the advice. I found this comment on a web page (from a
geostats class): "...If the data coordinates were in different units
then we would need to standardize these coordinates (otherwise km in
the horizontal and m in the vertical produce very flatten out
grids)...", so I'm wondering that if by using "relative" locations
(say 0 to 1) instead of the absolute ones (cm or m) can be utilized as
an alternative for the analysis. The point is that by transforming
everything to meters I'm having some problems to fit the models and I
guess is due to the reduced range of the x-axis (0-0.02 m) compare to
the y-axis (0-20 m).
BTW: the grid represents a set of data points measured within a pole,
so that's the reason of the differences in scale (x is from the center
of the pole to the outer part of the pole) and y from the bottom to
the top.
PM



On Fri, Apr 11, 2008 at 9:22 AM, Steve Friedman
<friedman.steve at gmail.com> wrote:
> Pedro,
>
> You absolutely need to have the coordinates in the same units of
> measurement. The geostatistics model is based on the premise of location,
> distance between samples, and the variance between locations.  The bigger
> concern that I can think of is the "change in support"  For example lets
> hypothesize that the variance changes much faster in the x direction which
> in your case is measured in cm.  So far that seems ok, but how can you tell
> whether the variance is changing at the same spatial lag in the y direction
> which is measured (and perhaps sampled) 10 more crudely?  Changing the
> coordinates to the same units of measurement is a transformation that may or
> may not mean much if your sampling scheme is problematic.
>
> Good luck
> Steve
>
>
>
> On Thu, Apr 10, 2008 at 9:19 PM, Pedro Mardones <mardones.p at gmail.com>
> wrote:
> >
> >
> >
> > Dear list members;
> > I'm a newbie in geostatistics so this question may have an obvious
> > answer that I'm not aware of (sorry about this). I've a grid of points
> > in which the x-axis is measured in cm (from 1 to 20) and the y-axis in
> > meters (from 1 to 20). So basically I have 20 x 20 points to work
> > with. Here is where I'm kind of confused. Do I need to transform the
> > coordinates to the same units, say cm or meters, before obtaining an
> > empirical semivariogram? What could be the effect of using the
> > coordinates in the given units (ie without transforming them to the
> > same units) on the analysis?
> > Thanks for any hint
> > PM
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Steve Friedman
> Phone 561 - 744 - 4642
> Cell 517 - 648 - 6290



From juliane_struve at yahoo.co.uk  Fri Apr 11 23:24:09 2008
From: juliane_struve at yahoo.co.uk (Juliane Struve)
Date: Fri, 11 Apr 2008 21:24:09 +0000 (GMT)
Subject: [R-sig-Geo] How can I read a Fishnet.dll shapefile into R ? newbie
Message-ID: <607710.13756.qm@web27210.mail.ukl.yahoo.com>

Dear list,

I am trying to read a shapefile into R that was created with Fishnet and consists of > 200 000 regularly spaced points projected in UTM coordinates. The 
shape file is called "water_centroids".

MapPolysDataFrameWaterCentroids <- readOGR("water_centroids.shp","water_centroids")
ProjString = proj4string(MapPolysDataFrameWaterCentroids)
plot(MapPolysDataFrameWaterCentroids)

works fine and plots the grid, but 

SarasotaPolysSP<-readShapeLines("water_centroids",  
proj4string=CRS("+proj=utm +zone=17"))
SarasotaPolysPS<-SpatialLines2PolySet(SarasotaPolysSP)    
plotPolys(SarasotaPolysPS,projection=TRUE)  

makes R 2.5.1 crash, although it works with my other shapefiles. 

How can I check that the file meets the specifications for using readShapeLines and is there some procedure to convert it if necessary ?
There may be a simple solution that I am not aware of, apologies if that is the case, but I am quite new to R.

Many thanks in advance for any suggestions.

Regards,

Juliane 



 
Dr. Juliane Struve
Adjunct Environmental Scientist
Mote Marine Laboratory
Center for Fisheries Enhancement
1600 Ken Thomson Parkway
Sarasota, Florida, 34236
(941)388-4441 Ext. 408


      ___________________________________________________________ 
Yahoo! For Good helps you make a difference  

http://uk.promotions.yahoo.com/forgood/



From shaofei.chen at utdallas.edu  Fri Apr 11 23:52:04 2008
From: shaofei.chen at utdallas.edu (Shaofei Chen)
Date: Fri, 11 Apr 2008 16:52:04 -0500
Subject: [R-sig-Geo] Can spgwr give the significance test of non-stationarity
Message-ID: <00ca01c89c1e$47693bd0$83416e0a@DG7G3P71>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080411/e9ef9664/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sun Apr 13 17:35:16 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 13 Apr 2008 16:35:16 +0100
Subject: [R-sig-Geo] R spatial data server
Message-ID: <48022834.3050300@lancaster.ac.uk>

I've just this afternoon made a way to serve R spatial data up to a 
whole raft of possible clients, thanks to...

"FeatureServer": http://www.featureserver.org/ is a server for geodata 
written in python that can read various spatial data sources (OGR, 
PostGIS, WFS etc) and present them as GeoJSON, KML, GeoRSS and so on. 
This made me think that with a bit of Rpy hackery it could read 
R-spatial datasets too...

So in about 25 lines of python (no kidding) I did it. I wrote a new 
'DataSource' for FeatureServer that gets coordinates and attributes of 
an R-spatial object stored in a .RData file and creates FeatureServer 
'Features' for each one. Then I fired up Google Earth and there was the 
North Carolina dataset from the maptools package neatly overlaid on the 
globe.

  Currently it just makes point features with "coordinates(foo)" because 
unravelling multiple polygon construction would have taken a bit of 
time, and I was really only doing this for hack-value and to see if 
anyone was interested.

  To try it out:

  * Get FeatureServer

  * Get R with the sp package and Python with Rpy.

  * Create a Spatial{Points,Lines,Poly}DataFrame object and save it in a 
.RData file

  * Put this entry in your featureserver.cfg file:

[metadata]
default_service=KML

[rdata]
type=RData
datafile=D:\\Maps\\maps.RData
objectname=nc
titlefield=NAME

  - where 'nc' is the name of the SpatialXDataFrame in the maps.RData 
file, and 'NAME' is the name of a column in the data frame to give as a 
title for each item.

  * Put this python code in the DataSource directory of your 
FeatureServer installation as 'RData.py'. FeatureServer should then find it:

__author__  = "Barry Rowlingson"
__copyright__ = "Copyright (c) Barry Rowlingson"
__license__ = "whatever"
__version__ = "0.1"

from FeatureServer.DataSource import DataSource
from FeatureServer.Feature import Feature

class RData (DataSource):
     """ Get spatial data from R """
     def __init__(self, name, datafile=None, titlefield=None, 
objectname=None, **args):
         DataSource.__init__(self, name, **args)
         from rpy import r
         self.r = r
         self.datafile = datafile
         r('library(sp)')
         r('maps=attach("%s")' % datafile)
         self.objectName = objectname
         self.titleField = titlefield

     def select (self, action):
         xy = self.r('coordinates(%s)' % self.objectName)
         data = self.r('as.data.frame(%s)' % self.objectName)
         features = []
         for point in range(len(xy)):
             attrs={}
             attrs['title']=data[self.titleField][point]
             for att in data.keys():
                 attrs[att]=data[att][point]
             geom = {'type':'Point', 'coordinates': [xy[point]] }
             f = Feature(point, geom, attrs)
             features.append(f)
         return features

[okay, a few more than 25 lines...]

  * Start FeatureServer, and test by going to: 
http://localhost:8080/rdata (or whichever host:port your FeatureServer 
is running on). You should get back the KML for your data set.

  * Try the same URL as a new Network Link in Google Earth...

Currently it doesn't tolerate errors very well, and it doesn't handle 
some of the other clever things that FeatureServer can do, but it's a 
start. I originally looked at this as a way of getting R spatial data 
into QGis via WFS, but the FeatureServer WFS implementation isn't 
complete enough to do that.

Here's hoping my afternoon hackery is of use to someone...

Barry



From Roger.Bivand at nhh.no  Sun Apr 13 23:28:42 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 13 Apr 2008 23:28:42 +0200 (CEST)
Subject: [R-sig-Geo] Can spgwr give the significance test of
	non-stationarity
In-Reply-To: <00ca01c89c1e$47693bd0$83416e0a@DG7G3P71>
References: <00ca01c89c1e$47693bd0$83416e0a@DG7G3P71>
Message-ID: <Pine.LNX.4.64.0804132322010.31510@reclus.nhh.no>

On Fri, 11 Apr 2008, Shaofei Chen wrote:

> Dear All,
>
> Fothingham's "GWR" book chapter 9.2 gives the significance test of 
> non-stationarity using a Monte Carlo test and a Leung test. This is also 
> implemented in his software. I wonder can spgwr also give such tests? I 
> cannot find them in the outcome. Here is an example code

R functions are typically modularised, and only provide the components 
needed. The tests require the hat matrix. So if you want tests, ask for 
the hat matrix, and run the tests on that object - they are separate 
functions - see help(package=spgwr). With regard to the tests, mileage 
varies a lot, even within the book itself. Really, there are no degrees of 
freedom left for tests, are there? The technique was intended to be 
exploratory.

>
> library(spgwr)
> data1<-read.csv(......)
> bw <- gwr.sel(y1~ X1 + X2+ X3 , data=data1, coords=cbind(data1$X, data1$Y))
> data1.gauss <- gwr(y1 ~ X1+ X2 + X3, data=data1, coords=cbind(data1$X, data1$Y), bandwidth=bw, hatmatrix=TRUE)
> names(data1.gauss)
>
> it returns "SDF"       "lhat"      "lm"        "results"   "bandwidth" "adapt" "hatmatrix" "gweight"   "this.call"
>
> If I find one exogenous variable is not significant non-stationary, how 
> can I run the mixed GWR model (including varied coefficients and 
> constant coefficients)? Thank you in advance.
>

No mixed version is provided. I guess you could use an offset of the 
product of the variable and global coefficient if you really wanted to. 
But as mentioned above, GWR is not a model, it is a way of exploring 
missing variables and/or inappropriate functional forms.

Hope this helps,

Roger

> Best,
> Shaofei
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From yong.li at unimelb.edu.au  Mon Apr 14 06:45:13 2008
From: yong.li at unimelb.edu.au (Yong Li)
Date: Mon, 14 Apr 2008 14:45:13 +1000
Subject: [R-sig-Geo] Problem with universal kriging using gstat
Message-ID: <86DBA0678E017341B449A62F258E2956386C7D@IS-EX-BEV3.unimelb.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080414/389cd434/attachment.pl>

From hengl at science.uva.nl  Mon Apr 14 10:36:31 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Mon, 14 Apr 2008 10:36:31 +0200
Subject: [R-sig-Geo] Problem with universal kriging using gstat
In-Reply-To: <86DBA0678E017341B449A62F258E2956386C7D@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <006001c89e0a$a3c075e0$3a871291@pcibed193>


Auxiliary variables that are used to explain the trend-part of variation need to be available also
at all new prediction locations.

see ?krige:

"newdata - data frame or Spatial object with prediction/simulation locations; should contain
attribute columns with the independent variables (if present) and (if locations is a formula) the
coordinates with names as defined in locations"

Gstat obviously can not find X and Y coordinates of your new locations (data.grid).

Try instead:

> data.grid <- expand.grid(x=seq(xLL,xUL,xN), y=seq(xLL,xUL,xN))
> names(data.grid) = c("X","Y")
> gridded(data.grid) <- ~X+Y

cheers,

Tom Hengl
http://spatial-analyst.net/ 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Yong Li
Sent: maandag 14 april 2008 6:45
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Problem with universal kriging using gstat

Hi ALL,
 
Can any expert to see my mistake in the following R script when I try the gstat universal kriging?
The error occurs at the last step. It sounds I missed the setup for the names of coordinates of the
SpatialGrid "data.grid".
 
Regards
 
Yong
 
> memory.size()
[1] 47930616
> memory.size(TRUE)
[1] 85377024
> memory.limit(size=2048)
NULL
> round(memory.limit()/1048576.0, 2)
[1] 2048
> options(scipen=3)
> 
> options(digits=15)
> rm(list=ls())
> require(sp)
[1] TRUE
> require(gstat)
[1] TRUE
> require(maptools)
[1] TRUE
> require(foreign)
[1] TRUE
> 
> cellsize <- 10
> 
> #                 1           2               3             4
> VarName=c("logit(SOM)","logit(TN)","logit(OLSENP)","logit(EXTK)")
> out=paste("Variable","No","Model","C0","C","Spatial","Range","R2","p","SSE",sep=",")
> setwd("E:\\Rcode\\EJSS\\Hongtong\\village")
> data <- read.dbf("libaocun_gs.dbf")
> names(data)
 [1] "ID"       "XCOOR"    "YCOOR"    "NO"       "CDBH"     "NO3N"     "NH4N"     "MINERALN" "SOM"
"TOTALN"   "OLSENP"   "EXTK"    
[13] "TN"       "X"        "Y"       
> class(data)
[1] "data.frame"
> names(data)[14] <- "X"
> names(data)[15] <- "Y"
> 
> data$X <- data$X  + 1750
> data$Y <- data$Y +  650
>  
> coordinates(data) <- ~X+Y
> proj4string(data) <- CRS("+proj=tmerc +lat_0=0 +lon_0=111 +k=1.0 +x_0=500000 +y_0=0 +ellps=krass
+units=m +no_defs +towgs84=22,-118,30.5,0,0,0,0")
> 
> #read in a shape file of the boundary
> aSHAPE <- readShapePoly("libao_bd.shp", IDvar="BSM", proj4string=CRS(proj4string(data))) 
> 
> #generate the grid coordinates (in meters)
> xLL <- round(slot(aSHAPE,"bbox")[1]) - 100
> xUR <- round(slot(aSHAPE,"bbox")[3]) + 100
> yLL <- round(slot(aSHAPE,"bbox")[2]) - 100
> yUR <- round(slot(aSHAPE,"bbox")[4]) + 100
> xN <- round((xUR-xLL)/cellsize)
> yN <- round((yUR-yLL)/cellsize)
> data.grid = SpatialGrid(GridTopology(c(xLL,yLL),c(cellsize,cellsize),c(xN,yN)))
> proj4string(data.grid) <- CRS(proj4string(aSHAPE))
> 
> 
> #data logit transformation
> SOM_MAX      <- max(data$SOM)*1.1
> SOM_MIN      <- min(data$SOM)*0.9
> SOM_DIFF     <- SOM_MAX - SOM_MIN
> data$SOMt    <- log(((data$SOM-SOM_MIN)/SOM_DIFF)/(1-(data$SOM-SOM_MIN)/SOM_DIFF))
> 
> TN_MAX      <- max(data$TN)*1.1
> TN_MIN      <- min(data$TN)*0.9
> TN_DIFF     <- TN_MAX - TN_MIN
> data$TNt    <- log(((data$TN-TN_MIN)/TN_DIFF)/(1-(data$TN-TN_MIN)/TN_DIFF))
> 
> OLSENP_MAX      <- max(data$OLSENP)*1.1
> OLSENP_MIN      <- min(data$OLSENP)*0.9
> OLSENP_DIFF     <- OLSENP_MAX - OLSENP_MIN
> data$OLSENPt    <-
log(((data$OLSENP-OLSENP_MIN)/OLSENP_DIFF)/(1-(data$OLSENP-OLSENP_MIN)/OLSENP_DIFF))
> 
> EXTK_MAX      <- max(data$EXTK)*1.1
> EXTK_MIN      <- min(data$EXTK)*0.9
> EXTK_DIFF     <- EXTK_MAX - EXTK_MIN
> data$EXTKt    <- log(((data$EXTK-EXTK_MIN)/EXTK_DIFF)/(1-(data$EXTK-EXTK_MIN)/EXTK_DIFF))
> 
> #SOM
>    # plot
>    X11(width=8, height=6.5)
>    par(mfrow=c(1,1))
>    spplot(aSHAPE["BSM"], scales=list(draw=TRUE, cex=0.7), xlab="Easting (m)", ylab="Northing (m)",
+           sp.layout=list("sp.points", pch="+", col="black", data), col.regions=FALSE,
colorkey=FALSE)
> 
>    X11(width=8, height=6.5)
>    par(mfrow=c(1,2))
>    hist(data$SOMt, main="", xlab=VarName[1], n=25)
>    boxplot(data$SOMt, xlab=VarName[1])
> 
>    #estimate semivariogram model
>    soil.v <- variogram(SOMt~X+Y+X*Y+X^2+Y^2, data=data, cutoff=1050, width=90)
>    vmodel <- vgm(0.5, "Sph", 1000, 0.1)
>    v.sph <- fit.variogram(object=soil.v, model=vmodel, fit.sills=TRUE, fit.ranges=TRUE,
fit.method=7)
>    v.sph
  model             psill            range
1   Nug 0.269063860535796   0.000000000000
2   Sph 0.217370623520010 815.994438576304
>    X11(width=8, height=6.5)
>    par(mfrow=c(1,1))
>    plot(soil.v, model=v.sph, col="red", cex=1, lwd=2.0, main=VarName[1], xlab="Separation distance
(m)")
> 
> #Univeral kriging
> data.gstat <- gstat(id="SOMt", formula=SOMt~X+Y+X*Y+X^2+Y^2, data=data, nmax=15, model=v.sph)
> 
> #Predicting surface
> data.grid <- predict(data.gstat, data.grid)
Error in eval(expr, envir, enclos) : object "X" not found
> 
> 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From hengl at science.uva.nl  Mon Apr 14 13:17:04 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Mon, 14 Apr 2008 13:17:04 +0200
Subject: [R-sig-Geo] Problem with universal kriging using gstat
In-Reply-To: <006001c89e0a$a3c075e0$3a871291@pcibed193>
Message-ID: <006901c89e21$117ec850$3a871291@pcibed193>


sorry, a type error:

> cellsize <- 10 # see also http://spatial-analyst.net/pixel.php 
> xLL <- round(slot(aSHAPE,"bbox")[1])+cellsize/2
> xUR <- round(slot(aSHAPE,"bbox")[3])-cellsize/2
> yLL <- round(slot(aSHAPE,"bbox")[2])+cellsize/2
> yUR <- round(slot(aSHAPE,"bbox")[4])-cellsize/2
> xN <- round((xUR-xLL)/cellsize)
> yN <- round((yUR-yLL)/cellsize)
> data.grid <- expand.grid(x=seq(xLL,xUR,xN), y=seq(yLL,yUR,yN))
> names(data.grid) = c("X","Y")
> gridded(data.grid) <- ~X+Y


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Tomislav Hengl
Sent: maandag 14 april 2008 10:37
To: 'Yong Li'; r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Problem with universal kriging using gstat


Auxiliary variables that are used to explain the trend-part of variation need to be available also
at all new prediction locations.

see ?krige:

"newdata - data frame or Spatial object with prediction/simulation locations; should contain
attribute columns with the independent variables (if present) and (if locations is a formula) the
coordinates with names as defined in locations"

Gstat obviously can not find X and Y coordinates of your new locations (data.grid).

Try instead:

> data.grid <- expand.grid(x=seq(xLL,xUL,xN), y=seq(xLL,xUL,xN))
> names(data.grid) = c("X","Y")
> gridded(data.grid) <- ~X+Y

cheers,

Tom Hengl
http://spatial-analyst.net/ 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Yong Li
Sent: maandag 14 april 2008 6:45
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Problem with universal kriging using gstat

Hi ALL,
 
Can any expert to see my mistake in the following R script when I try the gstat universal kriging?
The error occurs at the last step. It sounds I missed the setup for the names of coordinates of the
SpatialGrid "data.grid".
 
Regards
 
Yong
 
> memory.size()
[1] 47930616
> memory.size(TRUE)
[1] 85377024
> memory.limit(size=2048)
NULL
> round(memory.limit()/1048576.0, 2)
[1] 2048
> options(scipen=3)
> 
> options(digits=15)
> rm(list=ls())
> require(sp)
[1] TRUE
> require(gstat)
[1] TRUE
> require(maptools)
[1] TRUE
> require(foreign)
[1] TRUE
> 
> cellsize <- 10
> 
> #                 1           2               3             4
> VarName=c("logit(SOM)","logit(TN)","logit(OLSENP)","logit(EXTK)")
> out=paste("Variable","No","Model","C0","C","Spatial","Range","R2","p","SSE",sep=",")
> setwd("E:\\Rcode\\EJSS\\Hongtong\\village")
> data <- read.dbf("libaocun_gs.dbf")
> names(data)
 [1] "ID"       "XCOOR"    "YCOOR"    "NO"       "CDBH"     "NO3N"     "NH4N"     "MINERALN" "SOM"
"TOTALN"   "OLSENP"   "EXTK"    
[13] "TN"       "X"        "Y"       
> class(data)
[1] "data.frame"
> names(data)[14] <- "X"
> names(data)[15] <- "Y"
> 
> data$X <- data$X  + 1750
> data$Y <- data$Y +  650
>  
> coordinates(data) <- ~X+Y
> proj4string(data) <- CRS("+proj=tmerc +lat_0=0 +lon_0=111 +k=1.0 +x_0=500000 +y_0=0 +ellps=krass
+units=m +no_defs +towgs84=22,-118,30.5,0,0,0,0")
> 
> #read in a shape file of the boundary
> aSHAPE <- readShapePoly("libao_bd.shp", IDvar="BSM", proj4string=CRS(proj4string(data))) 
> 
> #generate the grid coordinates (in meters)
> xLL <- round(slot(aSHAPE,"bbox")[1]) - 100
> xUR <- round(slot(aSHAPE,"bbox")[3]) + 100
> yLL <- round(slot(aSHAPE,"bbox")[2]) - 100
> yUR <- round(slot(aSHAPE,"bbox")[4]) + 100
> xN <- round((xUR-xLL)/cellsize)
> yN <- round((yUR-yLL)/cellsize)
> data.grid = SpatialGrid(GridTopology(c(xLL,yLL),c(cellsize,cellsize),c(xN,yN)))
> proj4string(data.grid) <- CRS(proj4string(aSHAPE))
> 
> 
> #data logit transformation
> SOM_MAX      <- max(data$SOM)*1.1
> SOM_MIN      <- min(data$SOM)*0.9
> SOM_DIFF     <- SOM_MAX - SOM_MIN
> data$SOMt    <- log(((data$SOM-SOM_MIN)/SOM_DIFF)/(1-(data$SOM-SOM_MIN)/SOM_DIFF))
> 
> TN_MAX      <- max(data$TN)*1.1
> TN_MIN      <- min(data$TN)*0.9
> TN_DIFF     <- TN_MAX - TN_MIN
> data$TNt    <- log(((data$TN-TN_MIN)/TN_DIFF)/(1-(data$TN-TN_MIN)/TN_DIFF))
> 
> OLSENP_MAX      <- max(data$OLSENP)*1.1
> OLSENP_MIN      <- min(data$OLSENP)*0.9
> OLSENP_DIFF     <- OLSENP_MAX - OLSENP_MIN
> data$OLSENPt    <-
log(((data$OLSENP-OLSENP_MIN)/OLSENP_DIFF)/(1-(data$OLSENP-OLSENP_MIN)/OLSENP_DIFF))
> 
> EXTK_MAX      <- max(data$EXTK)*1.1
> EXTK_MIN      <- min(data$EXTK)*0.9
> EXTK_DIFF     <- EXTK_MAX - EXTK_MIN
> data$EXTKt    <- log(((data$EXTK-EXTK_MIN)/EXTK_DIFF)/(1-(data$EXTK-EXTK_MIN)/EXTK_DIFF))
> 
> #SOM
>    # plot
>    X11(width=8, height=6.5)
>    par(mfrow=c(1,1))
>    spplot(aSHAPE["BSM"], scales=list(draw=TRUE, cex=0.7), xlab="Easting (m)", ylab="Northing (m)",
+           sp.layout=list("sp.points", pch="+", col="black", data), col.regions=FALSE,
colorkey=FALSE)
> 
>    X11(width=8, height=6.5)
>    par(mfrow=c(1,2))
>    hist(data$SOMt, main="", xlab=VarName[1], n=25)
>    boxplot(data$SOMt, xlab=VarName[1])
> 
>    #estimate semivariogram model
>    soil.v <- variogram(SOMt~X+Y+X*Y+X^2+Y^2, data=data, cutoff=1050, width=90)
>    vmodel <- vgm(0.5, "Sph", 1000, 0.1)
>    v.sph <- fit.variogram(object=soil.v, model=vmodel, fit.sills=TRUE, fit.ranges=TRUE,
fit.method=7)
>    v.sph
  model             psill            range
1   Nug 0.269063860535796   0.000000000000
2   Sph 0.217370623520010 815.994438576304
>    X11(width=8, height=6.5)
>    par(mfrow=c(1,1))
>    plot(soil.v, model=v.sph, col="red", cex=1, lwd=2.0, main=VarName[1], xlab="Separation distance
(m)")
> 
> #Univeral kriging
> data.gstat <- gstat(id="SOMt", formula=SOMt~X+Y+X*Y+X^2+Y^2, data=data, nmax=15, model=v.sph)
> 
> #Predicting surface
> data.grid <- predict(data.gstat, data.grid)
Error in eval(expr, envir, enclos) : object "X" not found
> 
> 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From girodayh at unbc.ca  Tue Apr 15 20:49:49 2008
From: girodayh at unbc.ca (Honey Giroday)
Date: Tue, 15 Apr 2008 18:49:49 +0000
Subject: [R-sig-Geo] Importing raster data from Arcview to R for fitting a
	ppm
Message-ID: <BLU128-W4555C97F6194F87113DD018AEB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080415/d9715feb/attachment.pl>

From girodayh at unbc.ca  Tue Apr 15 22:24:11 2008
From: girodayh at unbc.ca (Honey Giroday)
Date: Tue, 15 Apr 2008 20:24:11 +0000
Subject: [R-sig-Geo] Subsetting a point process based on a grid of square
	owins
Message-ID: <BLU128-W45D5FB387822481929755C8AEB0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080415/d76012cf/attachment.pl>

From marcelino.delacruz at upm.es  Wed Apr 16 11:17:48 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Wed, 16 Apr 2008 11:17:48 +0200
Subject: [R-sig-Geo] Subsetting a point process based on a grid of
 square owins
In-Reply-To: <BLU128-W45D5FB387822481929755C8AEB0@phx.gbl>
References: <BLU128-W45D5FB387822481929755C8AEB0@phx.gbl>
Message-ID: <200804160917.m3G9Hjdi022982@smtp.upm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080416/8ba79484/attachment.pl>

From marcelino.delacruz at upm.es  Wed Apr 16 11:36:00 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Wed, 16 Apr 2008 11:36:00 +0200
Subject: [R-sig-Geo] Importing raster data from Arcview to R for fitting
 a ppm
In-Reply-To: <BLU128-W4555C97F6194F87113DD018AEB0@phx.gbl>
References: <BLU128-W4555C97F6194F87113DD018AEB0@phx.gbl>
Message-ID: <200804160935.m3G9ZvQm002028@smtp.upm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080416/b3c798e7/attachment.pl>

From marcelino.delacruz at upm.es  Wed Apr 16 15:33:11 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Wed, 16 Apr 2008 15:33:11 +0200
Subject: [R-sig-Geo] Importing raster data from Arcview to R for fitting
 a ppm
In-Reply-To: <200804160935.m3G9ZvQm002028@smtp.upm.es>
References: <BLU128-W4555C97F6194F87113DD018AEB0@phx.gbl>
	<200804160935.m3G9ZvQm002028@smtp.upm.es>
Message-ID: <200804161333.m3GDX6X7014468@smtp.upm.es>


May be I answered too fast....

Try better this:

xxx04.Q <- ppm(xxx04)$Q   # get default quadrature scheme

io <- !is.na(slope.subset[xxx04.Q, drop=F])  # select non-problematic points

xxx04.Qgood <- (xxx04.Q[io])       #  exclude problematic point

  class(xxx04.Qgood) <- "quad"

ppm(xxx04.Qgood, ~ x + y + slope, Poisson(), covariates = 
list(slope=slope.subset))





This should work indeed!



Marcelino









At 11:36 16/04/2008, Marcelino de la Cruz wrote:

>Hi,
>
>I don't remeber if this is corrected in the current version of
>spatstat (please, actualize) but, anyway, I think you can troubleshot
>the problem with this:
>
>
>io <- !is.na(slope.subset[xxx04, drop=F])
>
>ppm(xxx04[io], ~ x + y + slope, Poison(), covariates = 
>list(slope=slope.subset)
>
>
>
>I hope this helps,
>
>Marcelino
>
>
>
>At 20:49 15/04/2008, Honey Giroday wrote:
>
>
> >Hi All!
> >
> >I am a relatively new UseR and am currently using R 2.5.1 on a linux
> >operating system (I am connected to the linux system via remote
> >desktop connection).  I am trying to import a raster dataset (in
> >ASCII format) to fit as a covariate in a ppm.  However, I keep
> >getting this error message every time I got to fit the model.
> >
> >"Warning message:
> >Values of covariate "slope" were NA or undefined at 1% (1 out of
> >80812) of the quadrature points.  Occurred while executing:
> >ppm(xxx04, ~ x + y + slope, Poison(), covariates = list(slope=slope.subset)"
> >
> >At first I thought the problem sprung from the alignment of my image
> >(slope) with the object window of my point process
> >(xxx04).  However, I have the datasets are
> >in the same projection (UTM zone 10), and I have set the owin for
> >the points and subset the slope covariate to the same extent.  I
> >have also viewed the slope and image datasets in a plot and they
> >appear to line up correctly (i.e. there are no points that are
> >outside the extent of the slope image).  Can anyone assist me with
> >understanding the cause of this error message and suggest a method
> >to rectify/troubleshoot this problem?  Please see the code below to
> >see the steps I went through to fit the ppm.  Your help would be
> >much appreciated and thank you for your time in considering this issue.
> >
> >
> >
> >
> >
> >Sincerely,
> >
> >
> >
> >
> >
> >Honey-Marie Giroday, M.Sc. Candidate, A.Ag., B.I.T.
> >
> >University of Northern British Columbia
> >
> >
> >
> >
> >
> >#Read in shapefile data (2004, 2005, and 2006)
> >mpb04 <-
> >readShapePoints("N:/data/original/mpb/licensees/final/2004mpb_licensees")
> >
> >#Extract X and Y coordinates from ShapePoints
> >X <- mpb04$Easting
> >Y <- mpb04$Northing
> >
> >#Read in site characteristic covariates (ASCII)
> >slope <-
> >readAsciiGrid("N:/data/original/base_data/dem/bc/utm_tpi/slope20utm.txt",
> >as.image=TRUE)
> >
> >#Read in susceptibility covariates (ASCII)
> >sus0 <-
> >readAsciiGrid("N:/data/original/susceptibilitydata/climate_factor/u 
> tm_tpi/sus0.txt",
> >as.image=TRUE)
> >
> >#Convert covariates from list class to image class
> >image.slope <- as.im(slope)
> >sus0 <- as.im(sus0)
> >
> >#Create object window for analysis from one of the susceptibility datasets
> >sus0.win <- as.owin(sus0)
> >
> >#Subset site characteristic and landform datasets susceptibility boundary
> >slope.subset <- image.slope[sus0.win, drop=FALSE]
> >
> >#Use cut command to make landform and susceptibility a factor!
> >sus0.cut <- cut(sus0, 2)
> >
> >#Convert ShapePoints to point pattern manually
> >xxx04 <- ppp(x=mpb04$Easting, y=mpb04$Northing, window=sus0.win)
> >
> >#Test if model fitting works
> >fm1 <- ppm(xxx04, ~ x + y + slope, Poisson(), covariates=list(slope=slope))
> >
> >
> >_________________________________________________________________
> >Turn every day into $1000. Learn more at SignInAndWIN.ca
> >http://g.msn.ca/ca55/213
> >         [[alternative HTML version deleted]]
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at stat.math.ethz.ch
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>***************************************
>Marcelino de la Cruz Rot
>Depto. Biologia Vegetal
>EUIT Agricola
>Universidad Politecnica de Madrid
>28040-Madrid
>SPAIN
>***************************************
>         [[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


***************************************
Marcelino de la Cruz Rot
Depto. Biologia Vegetal
EUIT Agricola
Universidad Politecnica de Madrid
28040-Madrid
SPAIN



From adrian at maths.uwa.edu.au  Thu Apr 17 07:17:05 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Thu, 17 Apr 2008 13:17:05 +0800 (WST)
Subject: [R-sig-Geo] Importing raster data from Arcview to R for fitting a
 ppm
Message-ID: <52437.130.95.98.17.1208409425.squirrel@130.95.98.17>

Honey Giroday <girodayh at unbc.ca> writes:

> I am a relatively new UseR and am currently using R 2.5.1 on a
> linux operating system (I am connected to the linux system via
> remote desktop connection).  I am trying to import a raster
> dataset (in ASCII format) to fit as a covariate in a ppm.

ppm is part of the 'spatstat' package. It's usually best to contact the
authors of the package if you have trouble.

My first comment is that you do not seem to be running the current version
of spatstat. The current version is spatstat 1.13-0 and this requires R
2.6.0 (see www.spatstat.org) so apparently the installation of R and
spatstat on your Linux system are out of date.

> However, I keep getting this error message every time I got to fit
> the model.
> "Warning message:
> Values of covariate "slope" were NA or undefined at 1% (1 out of 80812)
> of the quadrature points.

Although the message says 1% of values were NA, that number has been
rounded upward. The exact figure is given in the parentheses: just ONE of
the quadrature points, out of 80812 quadrature points, gave an NA value.
This probably occurred at one of the corners of the window. Since it's
only one quadrature point that is problematic, this is probably not worth
worrying about.

I suggest you upgrade to the latest versions of R and spatstat and see if
the warning message is still present.

Adrian Baddeley
co-author of spatstat



From MMSullivan at ric.edu  Fri Apr 18 19:44:35 2008
From: MMSullivan at ric.edu (Sullivan, Mary M)
Date: Fri, 18 Apr 2008 13:44:35 -0400
Subject: [R-sig-Geo] help with glsm.mcmc
Message-ID: <38329C144184084CA2E572C51002D8FECEF8EB@mailsvr1.RICOL.EDU>

Greetings,
 
I am a novice user of geoRglm and am running into a problem with ghe glsm.mcmc command.  My data are binomial (with response a vector of 0 and 1), about 625 cases, with covariates.
 
My attempts to use the command result in the following:
 
> lds.2<- list(trend = ~x + y + urban01 + nymphsc + dist2edges + dist2rdss + totedges + H100s + H320s + H400s , beta = 0, cov.model = "exponential", cov.pars = c(1.2,23), nugget = 0.0036, family="binomial")
> mcmc.2.test <-mcmc.control(S.scale=0.2, n.iter=1000)
> test.2.tune <-glsm.mcmc(sampdat.geo, model=lds.2,  mcmc.input=mcmc.2.test)
Error in glsm.mcmc(sampdat.geo, model = lds.2, mcmc.input = mcmc.2.test) : 
  size of beta is incompatible with trend specified
 
In reading help, I am referred to prepare.likfit.glsm and likfit.glsm, but prepare.likfit.glsm needs the output from the glsm.mcmc, which is what I can't seem to get!  Would appreciate help on putting in a beta value.  FYI, the cov.pars and nugget came from fitting the exponential variogram.
 
Thanks,
Mary Sullivan

 
Mary M. Sullivan, Ed. D. 
Professor of Mathematics and Educational Studies 
Rhode Island College 
600 Mt. Pleasant Ave. Providence, RI 02908 
401-456-9851
mmsullivan at ric.edu



From blopes at email.unc.edu  Mon Apr 21 01:41:05 2008
From: blopes at email.unc.edu (Brian J. Lopes)
Date: Sun, 20 Apr 2008 19:41:05 -0400
Subject: [R-sig-Geo] White space in maps library
Message-ID: <480BD491.4090005@email.unc.edu>

Hey All,

I have a quick question regarding the maps package, and I'm not sure 
what I'm missing.

Let's say I just want a plot of the US, by using the world data and to 
save it as a png

library(maps)
png("test.png")
map('world', xlim=c(-125,-50),ylim=c(25,50))
map.axes()
dev.off()

The limits are actually important for me, so that's why I'm not using 
'usa'.  As you can see by looking at the png file, there is a lot of 
excess white space both above and below the file, I guess this has to do 
with the dimensions of the png file, but setting the dimensions in the 
png() function doesn't seem to help the matter.

Any advice on how to deal with this?

TIA,
Brian



From FredeA.Togersen at agrsci.dk  Mon Apr 21 08:30:13 2008
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Mon, 21 Apr 2008 08:30:13 +0200
Subject: [R-sig-Geo] White space in maps library
In-Reply-To: <480BD491.4090005@email.unc.edu>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC05FA74F9@DJFPOST01.djf.agrsci.dk>


Well, it has something to do with with the dimensions of the png. The default height and width is 480 pixels. 

Try

png("test.png", width = 960)
par(mar=c(5,5,0,0))
map('world', xlim=c(-125,-50),ylim=c(25,50))
map.axes()
dev.off()

where I have used the mar-settings of par() too. See ?par.

Med venlig hilsen
Frede Aakmann T?gersen
 

 

> -----Oprindelig meddelelse-----
> Fra: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] P? vegne af 
> Brian J. Lopes
> Sendt: 21. april 2008 01:41
> Til: r-sig-geo at stat.math.ethz.ch
> Emne: [R-sig-Geo] White space in maps library
> 
> Hey All,
> 
> I have a quick question regarding the maps package, and I'm 
> not sure what I'm missing.
> 
> Let's say I just want a plot of the US, by using the world 
> data and to save it as a png
> 
> library(maps)
> png("test.png")
> map('world', xlim=c(-125,-50),ylim=c(25,50))
> map.axes()
> dev.off()
> 
> The limits are actually important for me, so that's why I'm 
> not using 'usa'.  As you can see by looking at the png file, 
> there is a lot of excess white space both above and below the 
> file, I guess this has to do with the dimensions of the png 
> file, but setting the dimensions in the
> png() function doesn't seem to help the matter.
> 
> Any advice on how to deal with this?
> 
> TIA,
> Brian
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 



From blopes at email.unc.edu  Mon Apr 21 17:58:36 2008
From: blopes at email.unc.edu (Brian J. Lopes)
Date: Mon, 21 Apr 2008 11:58:36 -0400
Subject: [R-sig-Geo] White space in maps library
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC05FA74F9@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC05FA74F9@DJFPOST01.djf.agrsci.dk>
Message-ID: <480CB9AC.9060102@email.unc.edu>

Thanks, Frede, now the png looks good.  I was playing with those 
dimensions with someone else, but we were setting both width and height. 
  I appreciate your help.

Thanks,
Brian


Frede Aakmann T?gersen wrote:
> Well, it has something to do with with the dimensions of the png. The default height and width is 480 pixels. 
> 
> Try
> 
> png("test.png", width = 960)
> par(mar=c(5,5,0,0))
> map('world', xlim=c(-125,-50),ylim=c(25,50))
> map.axes()
> dev.off()
> 
> where I have used the mar-settings of par() too. See ?par.
> 
> Med venlig hilsen
> Frede Aakmann T?gersen
>  
> 
>  
> 
>> -----Oprindelig meddelelse-----
>> Fra: r-sig-geo-bounces at stat.math.ethz.ch 
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] P? vegne af 
>> Brian J. Lopes
>> Sendt: 21. april 2008 01:41
>> Til: r-sig-geo at stat.math.ethz.ch
>> Emne: [R-sig-Geo] White space in maps library
>>
>> Hey All,
>>
>> I have a quick question regarding the maps package, and I'm 
>> not sure what I'm missing.
>>
>> Let's say I just want a plot of the US, by using the world 
>> data and to save it as a png
>>
>> library(maps)
>> png("test.png")
>> map('world', xlim=c(-125,-50),ylim=c(25,50))
>> map.axes()
>> dev.off()
>>
>> The limits are actually important for me, so that's why I'm 
>> not using 'usa'.  As you can see by looking at the png file, 
>> there is a lot of excess white space both above and below the 
>> file, I guess this has to do with the dimensions of the png 
>> file, but setting the dimensions in the
>> png() function doesn't seem to help the matter.
>>
>> Any advice on how to deal with this?
>>
>> TIA,
>> Brian
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>



From andrew.niccolai at yale.edu  Mon Apr 21 22:23:32 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Mon, 21 Apr 2008 16:23:32 -0400
Subject: [R-sig-Geo] Skeletonize, distmap, medial axis transform
In-Reply-To: <Pine.LNX.4.64.0804110930000.3973@reclus.nhh.no>
References: <47FE0318.7070800@cebc.cnrs.fr>
	<Pine.LNX.4.64.0804110930000.3973@reclus.nhh.no>
Message-ID: <004801c8a3ed$91c320c0$b5496240$@niccolai@yale.edu>

Greetings list.
Below is some code that anyone can run to produce a distance transform image
of the R logo.  I am interested in some code that will skeletonize this
distmap image or the equivalent SpatialGridDataFrame object.  Essentially I
need to find the ridgeline of the distance transform that would in theory
trace the R logo image at all locations that are the maximum distance from
the boundaries.  Any help would be greatly appreciated.  I have also read of
a way to skeletonize a set of discrete boundary points using Voronoi
tessellation and then thinning the lines but I think the medial axis
transform of the distance map will be easier to handle.  Thanks again for
any and all help!

## Code to produce distance transform image (and SGDF) of R logo.
.spatstat_check <- FALSE # this is the trick used to pass FALSE to check=
w2 <- letterR
plot(w2)
m <- complement.owin(w2)
rm(.spatstat_check)
p1 <- as.psp(w2)
plot(p1)
d <- distmap(p1)
summary(d)
plot(d)
plot(w2, add=TRUE)
d[m] <- NA
summary(d)
plot(d)
## Convert to SpatialGridDataFrame if this helps
dsgdf <- as.SpatialGridDataFrame.im(d)
image(dsgdf)





Andrew Niccolai
Doctoral Candidate
Yale School of Forestry



From hengl at science.uva.nl  Tue Apr 22 15:49:27 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Tue, 22 Apr 2008 15:49:27 +0200
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
Message-ID: <003001c8a47f$ae9373c0$3a871291@pcibed193>


Dear list,

I know that much has already been said about the memory limit problems. If there is any progress
about this problem, we would be interested to hear.

In our project, we are importing 24 maps/bands, each consists of 1,450,000 pixels. We further would
like to glue all maps into a single data frame (e.g. 'ksc' class in adehabitat package; or
'SpatialGridDataFrame' in sp package), but this seems to be impossible.

We tried to run this under windows (after following
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-us
es_0021 and setting the --max-mem-size) and under Linux Ubuntu, but still get the same error message
(seems that there is no difference in use of memory under the two OS):

"Error: Cannot allocate vector of size 11.1 Mb"

The R workspace with 24 loaded grids is also really small (18 MB), but any further gluing and
calculation is blocked due the vector size error message.

For a comparison, in a GIS such as ArcGIS or SAGA/ILWIS (open source) we have no problems of loading
and processing 3-4 times more grids. 

Should we simply give up on running spatial analysis using large grids (>10 million grids) in R?

Any suggestion or comment is more than welcome,



Tom Hengl
http://spatial-analyst.net



From Roger.Bivand at nhh.no  Tue Apr 22 16:05:02 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Apr 2008 16:05:02 +0200 (CEST)
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <003001c8a47f$ae9373c0$3a871291@pcibed193>
References: <003001c8a47f$ae9373c0$3a871291@pcibed193>
Message-ID: <Pine.LNX.4.64.0804221557060.26129@reclus.nhh.no>

On Tue, 22 Apr 2008, Tomislav Hengl wrote:

>
> Dear list,
>
> I know that much has already been said about the memory limit problems. 
> If there is any progress about this problem, we would be interested to 
> hear.
>
> In our project, we are importing 24 maps/bands, each consists of 
> 1,450,000 pixels. We further would like to glue all maps into a single 
> data frame (e.g. 'ksc' class in adehabitat package; or 
> 'SpatialGridDataFrame' in sp package), but this seems to be impossible.
>
> We tried to run this under windows (after following 
> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-us 
> es_0021 and setting the --max-mem-size) and under Linux Ubuntu, but 
> still get the same error message (seems that there is no difference in 
> use of memory under the two OS):
>
> "Error: Cannot allocate vector of size 11.1 Mb"
>
> The R workspace with 24 loaded grids is also really small (18 MB), but 
> any further gluing and calculation is blocked due the vector size error 
> message.

No, about 11MB per grid times 24 is not 18MB, you are probably looking at 
the wrong row in gc(). A lot depends on how you are reading them, are you 
using the rgdal package, or reading ASCII grids? The question is mostly 
how to organise the workflow to reduce copying to a minimum.

>
> For a comparison, in a GIS such as ArcGIS or SAGA/ILWIS (open source) we 
> have no problems of loading and processing 3-4 times more grids.
>

Recall that these are different kinds of systems, and very likely not 
holding and copying all the data in memory.

> Should we simply give up on running spatial analysis using large grids 
> (>10 million grids) in R?

Do you mean grids with over 10M grid cells, or 10K grids each of 1M grid 
cells?

If the analyses can be done in tiles, rgdal provides access to the full 
ability of GDAL to select subscenes.

Hope this helps,

Roger

>
> Any suggestion or comment is more than welcome,
>
>
>
> Tom Hengl
> http://spatial-analyst.net
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From edzer.pebesma at uni-muenster.de  Tue Apr 22 16:14:17 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 22 Apr 2008 16:14:17 +0200
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <003001c8a47f$ae9373c0$3a871291@pcibed193>
References: <003001c8a47f$ae9373c0$3a871291@pcibed193>
Message-ID: <480DF2B9.3030602@uni-muenster.de>

Hi Tom,

Tomislav Hengl wrote:
> Should we simply give up on running spatial analysis using large grids (>10 million grids) in R?
>   
Yes, and I would be very interested to hear along which other path you 
were then successful to finish the job.

Other options I can see are:
- buy a decent pc with 16 or 32 Gb memory, and use 64 bits linux (have 
you checked how much this would cost, and compared it to the budget of 
your project?). There's nothing special about it, I use it 100% of my 
time on my 1.2 kg laptop (with much less RAM).
OR:
- don't go through the grid in a single pass, but do it by tiles, e.g. 
use rgdal to read part of the grid and do that for 100 tiles, should 
reduce memory needs with a factor 100. Of course this takes a little bit 
more effort, in terms of administration (as Roger mentioned),
OR:
- rewrite the memory-hungry parts such that the bulky data is not first 
read into memory, but read directly from disk. Several attempts can be 
found in various packages.

I believe you don't mean it like that, but your question (above) sounds 
a bit like "you" want "us" to solve your problems. That's always a 
dangerous attitude on lists where help comes only voluntary.

You haven't even told us how much memory your computer or OS has.

Best wishes,
--
Edzer



From hengl at science.uva.nl  Tue Apr 22 16:59:10 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Tue, 22 Apr 2008 16:59:10 +0200
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <480DF2B9.3030602@uni-muenster.de>
Message-ID: <003401c8a489$6bb073a0$3a871291@pcibed193>


Dear Edzer, Roger,

Thanks for the tips! BTW, I was using Dell Latitude D630 laptop with 2Gb of RAM and 2GHz Intel chip
with:

(a) Windows XP professional
(b) Linux Ubuntu

Under both OS I get the same error message.

And yes, we would like to import about 25 maps of 1.5 millions pixels each. 

I will try to summarize your strategies:

(1) Import the data in tiles (e.g. via rgdal), e.g.:  

> info <- GDALinfo("dem50m.asc")
> gridmaps01 = readGDAL("dem50m.asc", region.dim = round(c(info[["rows"]]/2,info[["columns"]])))
> gridmaps02 = readGDAL("dem50m.asc", region.dim = round(c(info[["rows"]]/2,info[["columns"]])),
offset=round(c(info[["rows"]]/2,0)))

Or try reading directly from disk (any documentation on how to achieve this?).

(2) Obtain a 64 bits OS/PC with >10Gb of RAM.

We would like to use the package adehabitat that reads ArcInfo ASCII maps via 'import.asc'.
Unfortunately, I could not find that it can read the data in tiles, but we might try importing via
rgdal first and then converting to the 'ksc' class.

If anybody else has experience/solution with working with large maps we would be interested to
hear/learn from his/hear opinion. 

Just one last thing, if R is reporting an error message, that does not necessarily mean that there
is a memory limit problem with the machine - shouldn't there be a way to implement memory handling
in R in a more efficient way?

Thanks in any case,

Tom Hengl



-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: dinsdag 22 april 2008 16:14
To: Tomislav Hengl
Cc: r-sig-geo at stat.math.ethz.ch; 'Michalis Vardakis'
Subject: Re: [R-sig-Geo] Memory limit problems in R / import of maps

Hi Tom,

Tomislav Hengl wrote:
> Should we simply give up on running spatial analysis using large grids (>10 million grids) in R?
>   
Yes, and I would be very interested to hear along which other path you 
were then successful to finish the job.

Other options I can see are:
- buy a decent pc with 16 or 32 Gb memory, and use 64 bits linux (have 
you checked how much this would cost, and compared it to the budget of 
your project?). There's nothing special about it, I use it 100% of my 
time on my 1.2 kg laptop (with much less RAM).
OR:
- don't go through the grid in a single pass, but do it by tiles, e.g. 
use rgdal to read part of the grid and do that for 100 tiles, should 
reduce memory needs with a factor 100. Of course this takes a little bit 
more effort, in terms of administration (as Roger mentioned),
OR:
- rewrite the memory-hungry parts such that the bulky data is not first 
read into memory, but read directly from disk. Several attempts can be 
found in various packages.

I believe you don't mean it like that, but your question (above) sounds 
a bit like "you" want "us" to solve your problems. That's always a 
dangerous attitude on lists where help comes only voluntary.

You haven't even told us how much memory your computer or OS has.

Best wishes,
--
Edzer



From dylan.beaudette at gmail.com  Tue Apr 22 17:22:14 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Tue, 22 Apr 2008 08:22:14 -0700
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <003001c8a47f$ae9373c0$3a871291@pcibed193>
References: <003001c8a47f$ae9373c0$3a871291@pcibed193>
Message-ID: <3c5546140804220822j2ba7bb7ch5238aab086e626f0@mail.gmail.com>

On Tue, Apr 22, 2008 at 6:49 AM, Tomislav Hengl <hengl at science.uva.nl> wrote:
>
>  Dear list,
>
>  I know that much has already been said about the memory limit problems. If there is any progress
>  about this problem, we would be interested to hear.
>
>  In our project, we are importing 24 maps/bands, each consists of 1,450,000 pixels. We further would
>  like to glue all maps into a single data frame (e.g. 'ksc' class in adehabitat package; or
>  'SpatialGridDataFrame' in sp package), but this seems to be impossible.
>
>  We tried to run this under windows (after following
>  http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-us
>  es_0021 and setting the --max-mem-size) and under Linux Ubuntu, but still get the same error message
>  (seems that there is no difference in use of memory under the two OS):
>
>  "Error: Cannot allocate vector of size 11.1 Mb"
>
>  The R workspace with 24 loaded grids is also really small (18 MB), but any further gluing and
>  calculation is blocked due the vector size error message.
>
>  For a comparison, in a GIS such as ArcGIS or SAGA/ILWIS (open source) we have no problems of loading
>  and processing 3-4 times more grids.
>
>  Should we simply give up on running spatial analysis using large grids (>10 million grids) in R?

Hi,

What exactly were you hoping to do with such a massive data frame once
you overcame the initial memory problems associated with loading the
data? Any type of multivariate, classification, or inference testing
would certainly require just as much memory to perform any analysis on
the stack of grids.

Not knowing what the purpose of this operation is (although I would
guess something related to soil property or landscape modeling of some
sort), it is hard to suggest a better approach. For grid that size I
would use an algorithm that operates on strips or tiles. There are
several great starting points in the GRASS source code. Doing all of
the pre-processing, and possibly some aggregating to larger support
size, in GRASS would allow you to test any R-centric operations on a
coarser version of the original dataset.

Cheers,

Dylan



From hengl at science.uva.nl  Tue Apr 22 17:49:10 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Tue, 22 Apr 2008 17:49:10 +0200
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <3c5546140804220822j2ba7bb7ch5238aab086e626f0@mail.gmail.com>
Message-ID: <003501c8a490$67d901a0$3a871291@pcibed193>


Dylan,

Thanks for your note.

A student of mine would like to run habitat suitability analysis using the adehabitat package
(http://dx.doi.org/10.1890%2F0012-9658%282002%29083%5B2027%3AENFAHT%5D2.0.CO%3B2). I encouraged him
to use R, for many reasons.

At the moment, he is thinking of doing the whole thing in Matlab (or using the original Biomapper
software), because we would not like to give up on the original resolution (250 m).  

As a GIS person, I definitively do not see ~20 millions pixels as a Huge data set.

cheers,

Tom Hengl



-----Original Message-----
From: Dylan Beaudette [mailto:dylan.beaudette at gmail.com] 
Sent: dinsdag 22 april 2008 17:22
To: Tomislav Hengl
Cc: r-sig-geo at stat.math.ethz.ch; Michalis Vardakis
Subject: Re: [R-sig-Geo] Memory limit problems in R / import of maps

On Tue, Apr 22, 2008 at 6:49 AM, Tomislav Hengl <hengl at science.uva.nl> wrote:
>
>  Dear list,
>
>  I know that much has already been said about the memory limit problems. If there is any progress
>  about this problem, we would be interested to hear.
>
>  In our project, we are importing 24 maps/bands, each consists of 1,450,000 pixels. We further
would
>  like to glue all maps into a single data frame (e.g. 'ksc' class in adehabitat package; or
>  'SpatialGridDataFrame' in sp package), but this seems to be impossible.
>
>  We tried to run this under windows (after following
>
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-us
>  es_0021 and setting the --max-mem-size) and under Linux Ubuntu, but still get the same error
message
>  (seems that there is no difference in use of memory under the two OS):
>
>  "Error: Cannot allocate vector of size 11.1 Mb"
>
>  The R workspace with 24 loaded grids is also really small (18 MB), but any further gluing and
>  calculation is blocked due the vector size error message.
>
>  For a comparison, in a GIS such as ArcGIS or SAGA/ILWIS (open source) we have no problems of
loading
>  and processing 3-4 times more grids.
>
>  Should we simply give up on running spatial analysis using large grids (>10 million grids) in R?

Hi,

What exactly were you hoping to do with such a massive data frame once
you overcame the initial memory problems associated with loading the
data? Any type of multivariate, classification, or inference testing
would certainly require just as much memory to perform any analysis on
the stack of grids.

Not knowing what the purpose of this operation is (although I would
guess something related to soil property or landscape modeling of some
sort), it is hard to suggest a better approach. For grid that size I
would use an algorithm that operates on strips or tiles. There are
several great starting points in the GRASS source code. Doing all of
the pre-processing, and possibly some aggregating to larger support
size, in GRASS would allow you to test any R-centric operations on a
coarser version of the original dataset.

Cheers,

Dylan



From edzer.pebesma at uni-muenster.de  Tue Apr 22 18:17:08 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 22 Apr 2008 18:17:08 +0200
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <003401c8a489$6bb073a0$3a871291@pcibed193>
References: <003401c8a489$6bb073a0$3a871291@pcibed193>
Message-ID: <480E0F84.5040608@uni-muenster.de>

Tomislav Hengl wrote:
> Just one last thing, 
Two?
> if R is reporting an error message, that does not necessarily mean that there
> is a memory limit problem with the machine 
Correct, the error message should give a hint,
> - shouldn't there be a way to implement memory handling
> in R in a more efficient way?
>   
R is open source, so go ahead and modify it.

As an advice, first consider the resources you have, and consider the 
other options just kindly provided to you. PC's with 8 Gb RAM now start 
at 500 euros, so why process massive data sets on your 2 Gb notebook.
--
Edzer



From milton.ruser at gmail.com  Tue Apr 22 18:20:31 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Tue, 22 Apr 2008 13:20:31 -0300
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <003501c8a490$67d901a0$3a871291@pcibed193>
References: <3c5546140804220822j2ba7bb7ch5238aab086e626f0@mail.gmail.com>
	<003501c8a490$67d901a0$3a871291@pcibed193>
Message-ID: <3aaf1a030804220920s2041246qc448eea9d92ec669@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080422/52fd2719/attachment.pl>

From Roger.Bivand at nhh.no  Tue Apr 22 19:29:34 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Apr 2008 19:29:34 +0200 (CEST)
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <480E0F84.5040608@uni-muenster.de>
References: <003401c8a489$6bb073a0$3a871291@pcibed193>
	<480E0F84.5040608@uni-muenster.de>
Message-ID: <Pine.LNX.4.64.0804221857290.26129@reclus.nhh.no>

On Tue, 22 Apr 2008, Edzer Pebesma wrote:

> Tomislav Hengl wrote:
>> Just one last thing,
> Two?
>> if R is reporting an error message, that does not necessarily mean that there
>> is a memory limit problem with the machine
> Correct, the error message should give a hint,
>> - shouldn't there be a way to implement memory handling
>> in R in a more efficient way?
>>
> R is open source, so go ahead and modify it.
>
> As an advice, first consider the resources you have, and consider the
> other options just kindly provided to you. PC's with 8 Gb RAM now start
> at 500 euros, so why process massive data sets on your 2 Gb notebook.

Even on my 2001 1GB desktop (dual xeon, but hey, not exactly high end 
now!), reading the 25 1000x1450 rasters went like a song:

library(rgdal)
grd <- GridTopology(c(0.5, 0.5), c(1,1), c(1000, 1450))
set.seed(1)
for (i in 1:25) {
   dta <- sample(1:10, prod(slot(grd, "cells.dim")), replace=TRUE)
   SGDF <- SpatialGridDataFrame(grd, data=data.frame(band1=dta))
   fn <- paste("kasc", i, ".tif", sep="")
   writeGDAL(SGDF, fn, drivername="GTiff", type="Byte")
}
gc()
fnames0 <- list.files(pattern="kasc*")
fnames <- gsub("\\.tif", "", fnames0)
r1 <- readGDAL(fnames0[1], silent=TRUE)
Grd <- slot(r1, "grid")
n <- dim(slot(r1, "data"))[1]
indata <- matrix(0, nrow=n, ncol=length(fnames0))
for (i in 1:length(fnames0)) {
   ingrid <- readGDAL(fnames0[i], silent=TRUE)
   indata[,i] <- ingrid[[1]]
   cat(i, "\n")
   gc()
}
gc()
colnames(indata) <- fnames
str(indata)
df <- as.data.frame(indata)
gc()
rm(indata)
str(df)
gc()
ingrid <- SpatialGridDataFrame(Grd, data=df)
gc()
rm(df)
gc()

library(adehabitat)
outkasc <- spixdf2kasc(ingrid)
...

Your problem is in spixdf2kasc() in adehabitat, which makes many copies of 
the input object. It may even be possible to inject the

   readGDAL(fnames0[i], silent=TRUE)[[1]]

line into:

  lll <- lapply(1:length(uu), function(i) c(as.matrix(sg[i]))
                                                      ^^^^^

in spixdf2kasc(), which is arguably not using the best syntax for just 
getting the data out of the columns in its copy sg of ingrid. So 
contributing an optimised version of spixdf2kasc would be helpful - but 
maybe 2GB would work - I was swapping at 1.9GB, but I only have 1GB, so 
maybe you'd get through. It's mostly a matter of watching where copying 
may occur and avoiding it.

The new Braun & Murdoch introduction to statistical programming with R is 
a very useful reference in cases like these - in particular assign large 
objects once and fill them up, and if they are already OK, don't 
over-check them.

In addition, Dylan and Edzer made good points about the potential 
spuriousness of apparent resolution - suitability is in patches, isn't it, 
and the outcome won't be more or less significant with greater n? If you 
aren't using proximity, you could just train on a sample from the 25-layer 
full data set, and predict back from the fitted model, couldn't you? The 
conversion function to kasc does accept SpatialPixelsDataFrame objects, 
but unfortunately promotes them to full grids, so the sample would need to 
be a rectangular subset, I'm afraid. Maybe try the adelist for more help 
on their side, the adehabitat maintainer is helpful when possible.

Hope this helps,

Roger

> --
> Edzer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hengl at science.uva.nl  Tue Apr 22 19:40:33 2008
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Tue, 22 Apr 2008 19:40:33 +0200
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <3aaf1a030804220920s2041246qc448eea9d92ec669@mail.gmail.com>
Message-ID: <004b01c8a49f$f7945d30$3a871291@pcibed193>


Dear Miltinho,

Please clarify what do you mean by "the most important thing is the dimension (number of cols and
rows)". I the case of rgdal, R reads everything and puts as one variable e.g.:

> str(maskHG)
Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
  ..@ data       :'data.frame': 1800000 obs. of  1 variable:
  .. ..$ band1: int [1:18000] 0 0 0 0 0 0 1 1 1 1 ...
  ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
  .. .. ..@ cellcentre.offset: Named num [1:2] 3946500 3247500
  .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
  .. .. ..@ cellsize         : num [1:2] 1000 1000
  .. .. ..@ cells.dim        : int [1:2] 1500 1200
  ..@ grid.index : int(0) 
  ..@ coords     : num [1:2, 1:2] 3946500 4095500 3247500 3366500
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:2] "x" "y"
  ..@ bbox       : num [1:2, 1:2] 3946000 3247000 4096000 3367000
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : chr [1:2] "x" "y"
  .. .. ..$ : chr [1:2] "min" "max"
  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
  .. .. ..@ projargs: chr " +proj=laea +lat_0=52 +lon_0=10 +k=1.00000 +x_0=4321000 +y_0=3210000
+ellps=GRS80 +datum=WGS84 +units=m +towgs84=0,0,0"


so I do not think that col/rows makes difference.

We typically work with 1200 rows x 1300 columns maps, but would like to use even bigger maps very
soon.

I really see this problem of not being able to load larger maps to R as the biggest bottleneck
(worth investing even time to work on the R code). 

Tom


-----Original Message-----
From: milton ruser [mailto:milton.ruser at gmail.com] 
Sent: dinsdag 22 april 2008 18:21
To: Tomislav Hengl
Cc: Dylan Beaudette; r-sig-geo at stat.math.ethz.ch; Michalis Vardakis
Subject: Re: [R-sig-Geo] Memory limit problems in R / import of maps

Hi all,
 
In fact, sometimes I fill a little frustrated with some map handling on R.
I also had problem with (almost to me) not so large maps reading. The curious is that the simple
ArcView 3.2 read the files without problem (in GRD or ASC formats). 
 
In fact, I think that the most important thing is the dimension (number of cols and rows) and not
the spatial resolution (10 meters, 250 meters etc). So, Tom, how large (cols and rows) are your
maps?
 
Kind redards,
 
miltinho


 
On 4/22/08, Tomislav Hengl <hengl at science.uva.nl> wrote: 


	Dylan,
	
	Thanks for your note.
	
	A student of mine would like to run habitat suitability analysis using the adehabitat
package
	(http://dx.doi.org/10.1890%2F0012-9658%282002%29083%5B2027%3AENFAHT%5D2.0.CO%3B2). I
encouraged him
	to use R, for many reasons.
	
	At the moment, he is thinking of doing the whole thing in Matlab (or using the original
Biomapper
	software), because we would not like to give up on the original resolution (250 m).
	
	As a GIS person, I definitively do not see ~20 millions pixels as a Huge data set.
	
	cheers,
	
	Tom Hengl
	
	
	
	-----Original Message-----
	From: Dylan Beaudette [mailto:dylan.beaudette at gmail.com]
	Sent: dinsdag 22 april 2008 17:22
	To: Tomislav Hengl
	Cc: r-sig-geo at stat.math.ethz.ch; Michalis Vardakis
	Subject: Re: [R-sig-Geo] Memory limit problems in R / import of maps
	
	On Tue, Apr 22, 2008 at 6:49 AM, Tomislav Hengl <hengl at science.uva.nl> wrote:
	>
	>  Dear list,
	>
	>  I know that much has already been said about the memory limit problems. If there is any
progress
	>  about this problem, we would be interested to hear.
	>
	>  In our project, we are importing 24 maps/bands, each consists of 1,450,000 pixels. We
further
	would
	>  like to glue all maps into a single data frame (e.g. 'ksc' class in adehabitat package;
or
	>  'SpatialGridDataFrame' in sp package), but this seems to be impossible.
	>
	>  We tried to run this under windows (after following
	>
	
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-us
	>  es_0021 and setting the --max-mem-size) and under Linux Ubuntu, but still get the same
error
	message
	>  (seems that there is no difference in use of memory under the two OS):
	>
	>  "Error: Cannot allocate vector of size 11.1 Mb"
	>
	>  The R workspace with 24 loaded grids is also really small (18 MB), but any further gluing
and
	>  calculation is blocked due the vector size error message.
	>
	>  For a comparison, in a GIS such as ArcGIS or SAGA/ILWIS (open source) we have no problems
of
	loading
	>  and processing 3-4 times more grids.
	>
	>  Should we simply give up on running spatial analysis using large grids (>10 million
grids) in R?
	
	Hi,
	
	What exactly were you hoping to do with such a massive data frame once
	you overcame the initial memory problems associated with loading the
	data? Any type of multivariate, classification, or inference testing
	would certainly require just as much memory to perform any analysis on
	the stack of grids.
	
	Not knowing what the purpose of this operation is (although I would
	guess something related to soil property or landscape modeling of some
	sort), it is hard to suggest a better approach. For grid that size I
	would use an algorithm that operates on strips or tiles. There are
	several great starting points in the GRASS source code. Doing all of
	the pre-processing, and possibly some aggregating to larger support
	size, in GRASS would allow you to test any R-centric operations on a
	coarser version of the original dataset.
	
	Cheers,
	
	Dylan
	
	_______________________________________________
	R-sig-Geo mailing list
	R-sig-Geo at stat.math.ethz.ch
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Tue Apr 22 19:59:53 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 22 Apr 2008 19:59:53 +0200 (CEST)
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <004b01c8a49f$f7945d30$3a871291@pcibed193>
References: <004b01c8a49f$f7945d30$3a871291@pcibed193>
Message-ID: <Pine.LNX.4.64.0804221950430.26129@reclus.nhh.no>

On Tue, 22 Apr 2008, Tomislav Hengl wrote:

>
> Dear Miltinho,
>
> Please clarify what do you mean by "the most important thing is the 
> dimension (number of cols and rows)". I the case of rgdal, R reads 
> everything and puts as one variable e.g.:

No, please look at what the readGDAL() function actually does. It opens a 
handle to a file, and *only* reads *from* the offset *for* region.dim 
cells and chosen bands (or decimates with output.dim). You can work on 
rasters of arbitrary size, provided you do it in parts. The components are 
there, you just need to use them with insight. You haven't shown why all 
the data must be in memory (it being easier that way is an acceptable 
answer if you have 64GB). Less well resourced researchers have to use 
their wits.

Wrt. bottlenecks below, I beg to differ - another bottleneck is why the 
nth 10MB of data adds to our understanding of the data generating 
processes, if the 1st 10MB of data didn't help?

Roger


>
>> str(maskHG)
> Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
>  ..@ data       :'data.frame': 1800000 obs. of  1 variable:
>  .. ..$ band1: int [1:18000] 0 0 0 0 0 0 1 1 1 1 ...
>  ..@ grid       :Formal class 'GridTopology' [package "sp"] with 3 slots
>  .. .. ..@ cellcentre.offset: Named num [1:2] 3946500 3247500
>  .. .. .. ..- attr(*, "names")= chr [1:2] "x" "y"
>  .. .. ..@ cellsize         : num [1:2] 1000 1000
>  .. .. ..@ cells.dim        : int [1:2] 1500 1200
>  ..@ grid.index : int(0)
>  ..@ coords     : num [1:2, 1:2] 3946500 4095500 3247500 3366500
>  .. ..- attr(*, "dimnames")=List of 2
>  .. .. ..$ : NULL
>  .. .. ..$ : chr [1:2] "x" "y"
>  ..@ bbox       : num [1:2, 1:2] 3946000 3247000 4096000 3367000
>  .. ..- attr(*, "dimnames")=List of 2
>  .. .. ..$ : chr [1:2] "x" "y"
>  .. .. ..$ : chr [1:2] "min" "max"
>  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>  .. .. ..@ projargs: chr " +proj=laea +lat_0=52 +lon_0=10 +k=1.00000 +x_0=4321000 +y_0=3210000
> +ellps=GRS80 +datum=WGS84 +units=m +towgs84=0,0,0"
>
>
> so I do not think that col/rows makes difference.
>
> We typically work with 1200 rows x 1300 columns maps, but would like to 
> use even bigger maps very soon.
>
> I really see this problem of not being able to load larger maps to R as 
> the biggest bottleneck (worth investing even time to work on the R 
> code).
>
> Tom
>
>
> -----Original Message-----
> From: milton ruser [mailto:milton.ruser at gmail.com]
> Sent: dinsdag 22 april 2008 18:21
> To: Tomislav Hengl
> Cc: Dylan Beaudette; r-sig-geo at stat.math.ethz.ch; Michalis Vardakis
> Subject: Re: [R-sig-Geo] Memory limit problems in R / import of maps
>
> Hi all,
>
> In fact, sometimes I fill a little frustrated with some map handling on R.
> I also had problem with (almost to me) not so large maps reading. The curious is that the simple
> ArcView 3.2 read the files without problem (in GRD or ASC formats).
>
> In fact, I think that the most important thing is the dimension (number of cols and rows) and not
> the spatial resolution (10 meters, 250 meters etc). So, Tom, how large (cols and rows) are your
> maps?
>
> Kind redards,
>
> miltinho
>
>
>
> On 4/22/08, Tomislav Hengl <hengl at science.uva.nl> wrote:
>
>
> 	Dylan,
>
> 	Thanks for your note.
>
> 	A student of mine would like to run habitat suitability analysis using the adehabitat
> package
> 	(http://dx.doi.org/10.1890%2F0012-9658%282002%29083%5B2027%3AENFAHT%5D2.0.CO%3B2). I
> encouraged him
> 	to use R, for many reasons.
>
> 	At the moment, he is thinking of doing the whole thing in Matlab (or using the original
> Biomapper
> 	software), because we would not like to give up on the original resolution (250 m).
>
> 	As a GIS person, I definitively do not see ~20 millions pixels as a Huge data set.
>
> 	cheers,
>
> 	Tom Hengl
>
>
>
> 	-----Original Message-----
> 	From: Dylan Beaudette [mailto:dylan.beaudette at gmail.com]
> 	Sent: dinsdag 22 april 2008 17:22
> 	To: Tomislav Hengl
> 	Cc: r-sig-geo at stat.math.ethz.ch; Michalis Vardakis
> 	Subject: Re: [R-sig-Geo] Memory limit problems in R / import of maps
>
> 	On Tue, Apr 22, 2008 at 6:49 AM, Tomislav Hengl <hengl at science.uva.nl> wrote:
> 	>
> 	>  Dear list,
> 	>
> 	>  I know that much has already been said about the memory limit problems. If there is any
> progress
> 	>  about this problem, we would be interested to hear.
> 	>
> 	>  In our project, we are importing 24 maps/bands, each consists of 1,450,000 pixels. We
> further
> 	would
> 	>  like to glue all maps into a single data frame (e.g. 'ksc' class in adehabitat package;
> or
> 	>  'SpatialGridDataFrame' in sp package), but this seems to be impossible.
> 	>
> 	>  We tried to run this under windows (after following
> 	>
>
> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-us
> 	>  es_0021 and setting the --max-mem-size) and under Linux Ubuntu, but still get the same
> error
> 	message
> 	>  (seems that there is no difference in use of memory under the two OS):
> 	>
> 	>  "Error: Cannot allocate vector of size 11.1 Mb"
> 	>
> 	>  The R workspace with 24 loaded grids is also really small (18 MB), but any further gluing
> and
> 	>  calculation is blocked due the vector size error message.
> 	>
> 	>  For a comparison, in a GIS such as ArcGIS or SAGA/ILWIS (open source) we have no problems
> of
> 	loading
> 	>  and processing 3-4 times more grids.
> 	>
> 	>  Should we simply give up on running spatial analysis using large grids (>10 million
> grids) in R?
>
> 	Hi,
>
> 	What exactly were you hoping to do with such a massive data frame once
> 	you overcame the initial memory problems associated with loading the
> 	data? Any type of multivariate, classification, or inference testing
> 	would certainly require just as much memory to perform any analysis on
> 	the stack of grids.
>
> 	Not knowing what the purpose of this operation is (although I would
> 	guess something related to soil property or landscape modeling of some
> 	sort), it is hard to suggest a better approach. For grid that size I
> 	would use an algorithm that operates on strips or tiles. There are
> 	several great starting points in the GRASS source code. Doing all of
> 	the pre-processing, and possibly some aggregating to larger support
> 	size, in GRASS would allow you to test any R-centric operations on a
> 	coarser version of the original dataset.
>
> 	Cheers,
>
> 	Dylan
>
> 	_______________________________________________
> 	R-sig-Geo mailing list
> 	R-sig-Geo at stat.math.ethz.ch
> 	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From andrew.niccolai at yale.edu  Tue Apr 22 21:18:46 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Tue, 22 Apr 2008 15:18:46 -0400
Subject: [R-sig-Geo] Using rJava with ImageJ plugin
In-Reply-To: <Pine.LNX.4.64.0804221950430.26129@reclus.nhh.no>
References: <004b01c8a49f$f7945d30$3a871291@pcibed193>
	<Pine.LNX.4.64.0804221950430.26129@reclus.nhh.no>
Message-ID: <000d01c8a4ad$b04b1ff0$10e15fd0$@niccolai@yale.edu>

I have written a very simple ImageJ plugin using Java code:

import ij.*;
import ij.process.*;
import ij.gui.*;
import java.awt.*;
import ij.plugin.*;

public class My_Skel implements PlugIn {

	public void run(String arg) {
		IJ.run("Make Binary");
		IJ.run("Skeletonize");
	}

}


As long as an image is open, this plugin first converts any image to a
binary image and then uses a skeletonization operation on it.  Inside R I
run the following code,

library(rJava) #load the rJava library
.jinit(classpath="c:/liao_all/importance_sampling/java",parameters="-Xmx512m
")
#the above is to load the Java virtual
machine,"c:/liao_all/importance_sampling/java" is where the java code is.

#now you can call the Java method as
z=.jcall("My_Skel", "[I", "c:/temp/test.tif")
#z stores the result
image(z)


I get the following error message:
Exception in thread "main" Error in .jcall("My_Skel", "[I",
"c:/temp/test.tif") : 
  RcallMethod: cannot determine object class.

I get the same error message when I replace "c:/temp/test.tif", with the
SpatialGridDataFrame object that was created from the .tif file.

This java code works when I run it through ImageJ but it doesn't work when I
attempt to call it in R.  Can someone please explain what I am calling
incorrectly in .jcall?

Ultimately, I'd like to point to a .tif image in R and have the java code
execute and return a new skeletonized .tif image.  Thanks for any help!


Andrew Niccolai
Doctoral Candidate
Yale School of Forestry



From Roger.Bivand at nhh.no  Wed Apr 23 15:27:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 23 Apr 2008 15:27:30 +0200 (CEST)
Subject: [R-sig-Geo] Using rJava with ImageJ plugin
In-Reply-To: <000d01c8a4ad$b04b1ff0$10e15fd0$@niccolai@yale.edu>
References: <004b01c8a49f$f7945d30$3a871291@pcibed193>
	<Pine.LNX.4.64.0804221950430.26129@reclus.nhh.no>
	<000d01c8a4ad$b04b1ff0$10e15fd0$@niccolai@yale.edu>
Message-ID: <Pine.LNX.4.64.0804231521140.27113@reclus.nhh.no>

On Tue, 22 Apr 2008, Andrew Niccolai wrote:

> I have written a very simple ImageJ plugin using Java code:
>
> import ij.*;
> import ij.process.*;
> import ij.gui.*;
> import java.awt.*;
> import ij.plugin.*;
>
> public class My_Skel implements PlugIn {
>
> 	public void run(String arg) {
> 		IJ.run("Make Binary");
> 		IJ.run("Skeletonize");
> 	}
>
> }
>
>
> As long as an image is open, this plugin first converts any image to a
> binary image and then uses a skeletonization operation on it.  Inside R I
> run the following code,
>
> library(rJava) #load the rJava library
> .jinit(classpath="c:/liao_all/importance_sampling/java",parameters="-Xmx512m
> ")
> #the above is to load the Java virtual
> machine,"c:/liao_all/importance_sampling/java" is where the java code is.
>
> #now you can call the Java method as
> z=.jcall("My_Skel", "[I", "c:/temp/test.tif")
> #z stores the result
> image(z)
>
>
> I get the following error message:
> Exception in thread "main" Error in .jcall("My_Skel", "[I",
> "c:/temp/test.tif") :
>  RcallMethod: cannot determine object class.
>
> I get the same error message when I replace "c:/temp/test.tif", with the
> SpatialGridDataFrame object that was created from the .tif file.
>
> This java code works when I run it through ImageJ but it doesn't work when I
> attempt to call it in R.  Can someone please explain what I am calling
> incorrectly in .jcall?

Windows, right? No idea, can you use system() instead of rJava? I haven't 
bothered to make it work on any Linux platforms. I have not seen any 
results suggesting that anyone has reflected S4 sp classes to Java, so I 
guess using system() and files simplifies things enough to keep them 
working.

My rJava attempts strand on your choice of wrong Java version/wrong class 
path/etc., and have been so painful to debug that I've not found them 
fruitful to continue. On the other hand (D)COM seems to be very reliable 
on Windows, including (D)COM from Python giving a working alternative to 
Rpy on Windows.

Roger

>
> Ultimately, I'd like to point to a .tif image in R and have the java code
> execute and return a new skeletonized .tif image.  Thanks for any help!
>
>
> Andrew Niccolai
> Doctoral Candidate
> Yale School of Forestry
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Apr 23 19:58:25 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 23 Apr 2008 19:58:25 +0200 (CEST)
Subject: [R-sig-Geo] Memory limit problems in R / import of maps
In-Reply-To: <Pine.LNX.4.64.0804221857290.26129@reclus.nhh.no>
References: <003401c8a489$6bb073a0$3a871291@pcibed193>
	<480E0F84.5040608@uni-muenster.de>
	<Pine.LNX.4.64.0804221857290.26129@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0804231939580.28372@reclus.nhh.no>

On Tue, 22 Apr 2008, Roger Bivand wrote:

> On Tue, 22 Apr 2008, Edzer Pebesma wrote:
>
>> Tomislav Hengl wrote:
>>> Just one last thing,
>> Two?
>>> if R is reporting an error message, that does not necessarily mean that there
>>> is a memory limit problem with the machine
>> Correct, the error message should give a hint,
>>> - shouldn't there be a way to implement memory handling
>>> in R in a more efficient way?
>>>
>> R is open source, so go ahead and modify it.
>>
>> As an advice, first consider the resources you have, and consider the
>> other options just kindly provided to you. PC's with 8 Gb RAM now start
>> at 500 euros, so why process massive data sets on your 2 Gb notebook.
>
> Even on my 2001 1GB desktop (dual xeon, but hey, not exactly high end
> now!), reading the 25 1000x1450 rasters went like a song:
>
> library(rgdal)
> grd <- GridTopology(c(0.5, 0.5), c(1,1), c(1000, 1450))
> set.seed(1)
> for (i in 1:25) {
>   dta <- sample(1:10, prod(slot(grd, "cells.dim")), replace=TRUE)
>   SGDF <- SpatialGridDataFrame(grd, data=data.frame(band1=dta))
>   fn <- paste("kasc", i, ".tif", sep="")
>   writeGDAL(SGDF, fn, drivername="GTiff", type="Byte")
> }
> gc()
> fnames0 <- list.files(pattern="kasc*")
> fnames <- gsub("\\.tif", "", fnames0)
> r1 <- readGDAL(fnames0[1], silent=TRUE)
> Grd <- slot(r1, "grid")
> n <- dim(slot(r1, "data"))[1]
> indata <- matrix(0, nrow=n, ncol=length(fnames0))
> for (i in 1:length(fnames0)) {
>   ingrid <- readGDAL(fnames0[i], silent=TRUE)
>   indata[,i] <- ingrid[[1]]
>   cat(i, "\n")
>   gc()
> }
> gc()
> colnames(indata) <- fnames
> str(indata)
> df <- as.data.frame(indata)
> gc()
> rm(indata)
> str(df)
> gc()
> ingrid <- SpatialGridDataFrame(Grd, data=df)
> gc()
> rm(df)
> gc()
>
> library(adehabitat)
> outkasc <- spixdf2kasc(ingrid)
> ...
>
> Your problem is in spixdf2kasc() in adehabitat, which makes many copies of
> the input object. It may even be possible to inject the
>
>   readGDAL(fnames0[i], silent=TRUE)[[1]]
>
> line into:
>
>  lll <- lapply(1:length(uu), function(i) c(as.matrix(sg[i]))
>                                                      ^^^^^
>
> in spixdf2kasc(), which is arguably not using the best syntax for just
> getting the data out of the columns in its copy sg of ingrid. So
> contributing an optimised version of spixdf2kasc would be helpful - but
> maybe 2GB would work - I was swapping at 1.9GB, but I only have 1GB, so
> maybe you'd get through. It's mostly a matter of watching where copying
> may occur and avoiding it.

With a little tidying, spixdf2kasc() will run on 1GB for this 370MB 
SpatialGridDataFrame, taking just another 370MB by copying the data frame 
just once. If anyone would like a copy, please contact me off-line.

The kasc object is in fact just the SGDF data frame with the rows in 
reversed order, but since enfa() in adehabitat uses a kasc object, you 
probably need to go this way. Probably you'll be using gc() a good deal 
without a little more memory, though.

Getting the output out to an SGDF object ought to be possible too, ask 
about that later if need be.

Roger


>
> The new Braun & Murdoch introduction to statistical programming with R is
> a very useful reference in cases like these - in particular assign large
> objects once and fill them up, and if they are already OK, don't
> over-check them.
>
> In addition, Dylan and Edzer made good points about the potential
> spuriousness of apparent resolution - suitability is in patches, isn't it,
> and the outcome won't be more or less significant with greater n? If you
> aren't using proximity, you could just train on a sample from the 25-layer
> full data set, and predict back from the fitted model, couldn't you? The
> conversion function to kasc does accept SpatialPixelsDataFrame objects,
> but unfortunately promotes them to full grids, so the sample would need to
> be a rectangular subset, I'm afraid. Maybe try the adelist for more help
> on their side, the adehabitat maintainer is helpful when possible.
>
> Hope this helps,
>
> Roger
>
>> --
>> Edzer
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From vkepoglu at gmail.com  Thu Apr 24 10:16:26 2008
From: vkepoglu at gmail.com (volkan kepoglu)
Date: Thu, 24 Apr 2008 11:16:26 +0300
Subject: [R-sig-Geo] adaptive kernel density
Message-ID: <8b5938320804240116p46dd04baoec505bd95762b685@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080424/f0447d2a/attachment.pl>

From fhds2000 at yahoo.com  Fri Apr 25 00:27:27 2008
From: fhds2000 at yahoo.com (F. De Sales)
Date: Thu, 24 Apr 2008 15:27:27 -0700 (PDT)
Subject: [R-sig-Geo] smoothing contours (image.smooth)
In-Reply-To: <138648.21682.qm@web53302.mail.re2.yahoo.com>
Message-ID: <558415.10479.qm@web53310.mail.re2.yahoo.com>

    Hi all,
    I was wondering if anyone in here is familiar with
the command "image.smooth".
    How can set the arguments dx, dy and theta to
minimize the smoothing?
    Is there any other way to get smoother contour
maps, ie, without so many sharp corners?
    I'd appreciate any help.
    Thank you very much.




      ____________________________________________________________________________________

[[elided Yahoo spam]]



From Roger.Bivand at nhh.no  Fri Apr 25 08:58:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 25 Apr 2008 08:58:30 +0200 (CEST)
Subject: [R-sig-Geo] smoothing contours (image.smooth)
In-Reply-To: <558415.10479.qm@web53310.mail.re2.yahoo.com>
References: <558415.10479.qm@web53310.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0804250854111.10289@reclus.nhh.no>

On Thu, 24 Apr 2008, F. De Sales wrote:

>
>    Hi all,
>    I was wondering if anyone in here is familiar with
> the command "image.smooth".
>    How can set the arguments dx, dy and theta to
> minimize the smoothing?

Read ?image.smooth in the fields package, and run the examples with 
various values until you can see what they do, with the alternative of 
reading the source code.

>    Is there any other way to get smoother contour
> maps, ie, without so many sharp corners?

The function is not adding any information, so if there are sharp corners 
in the contours, then there are sharp corners in the data, and smoothing 
is not your friend. One possibility is to change the resolution of the 
image, which should remove sharp boundaries that are only artefacts of the 
resolution - for example by interpolating to a denser grid.

Roger

>    I'd appreciate any help.
>    Thank you very much.
>
>
>
>
>      ____________________________________________________________________________________
>
> [[elided Yahoo spam]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From graham.smith at myotis.co.uk  Fri Apr 25 13:26:40 2008
From: graham.smith at myotis.co.uk (Graham Smith)
Date: Fri, 25 Apr 2008 12:26:40 +0100
Subject: [R-sig-Geo] Extracting avg values from smoothed surface in spatstat
Message-ID: <37033244-0EC4-4954-A08B-FEDD066C7F8B@myotis.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080425/65a70243/attachment.pl>

From marcelino.delacruz at upm.es  Fri Apr 25 15:19:58 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Fri, 25 Apr 2008 15:19:58 +0200
Subject: [R-sig-Geo] Extracting avg values from smoothed surface in
 spatstat
In-Reply-To: <37033244-0EC4-4954-A08B-FEDD066C7F8B@myotis.co.uk>
References: <37033244-0EC4-4954-A08B-FEDD066C7F8B@myotis.co.uk>
Message-ID: <200804251319.m3PDJrjh029556@smtp.upm.es>



Hi,

Probably there is a simpler way, but in the 
meantime, you can use this experimental function 
"gridim" (of course you can modify as you want).

You have to especify the required "lag" of the 
grid (i.e. the desired length of the x-side or 
the y-side of each cell in the grid).
It gives you a list of images of the required 
size. Then use mean.im to obtain thte mean values.


Example of use:

library(spatstat)

data(longleaf)
Z <- smooth.ppp(longleaf)

plot(Z)

lapply(gridim(Z, xlag=10), mean.im)



Regards,

Marcelino








##### FUNCTION "gridim"#################################################

gridim <-  function (miim,xlag,ylag=xlag){

    xrange <- miim$xrange
    yrange <- miim$yrange

    x0 <- xrange[1]
    y0 <- yrange[1]

    maxx <- round(diff(xrange)/xlag)
    maxy <- round(diff(yrange)/ylag)

    result <- NULL
    z <- 0
    for (i in 1:maxx){
       for (j in 1:maxy){
         z <- z+1
         result[z] <- 
list(miim[owin(c((x0+xlag)*(i-1), 
(x0+xlag)*i),c((y0+ylag)*(j-1), (y0+ylag)*j))])
       }
    }

    class(result) <- c("gridedim", class(result))
    return(result)
}

###################################################################################3







At 13:26 25/04/2008, Graham Smith wrote:
>I've asked this in the general R list, but it may be better here.
>
>have used smooth.ppp in spatstat to create a smoothed surface plot
>based on randomly selected depth measurements across a lake (as marks
>in spatstat).
>
>I wonder, if based on the smoothed surface plot, if I can calculate
>the average depth for each 10x10 grid square across the lake.
>
>I can't see any obvious way of doing this and would appreciate some
>pointers.
>
>Many thanks,
>
>Graham
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es



From fhds2000 at yahoo.com  Fri Apr 25 20:53:14 2008
From: fhds2000 at yahoo.com (F. De Sales)
Date: Fri, 25 Apr 2008 11:53:14 -0700 (PDT)
Subject: [R-sig-Geo] smoothing contours (image.smooth)
In-Reply-To: <Pine.LNX.4.64.0804250854111.10289@reclus.nhh.no>
Message-ID: <294274.49645.qm@web53304.mail.re2.yahoo.com>

    Thanks for your help.
    I tried different dx, dy and theta values,
however, the results matrix was too smooth and some of
the main feature disappeared.
    I was just looking to get the contour lines
slightly smoother.
    Thank you.
    
--- Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 24 Apr 2008, F. De Sales wrote:
> 
> >
> >    Hi all,
> >    I was wondering if anyone in here is familiar
> with
> > the command "image.smooth".
> >    How can set the arguments dx, dy and theta to
> > minimize the smoothing?
> 
> Read ?image.smooth in the fields package, and run
> the examples with 
> various values until you can see what they do, with
> the alternative of 
> reading the source code.
> 
> >    Is there any other way to get smoother contour
> > maps, ie, without so many sharp corners?
> 
> The function is not adding any information, so if
> there are sharp corners 
> in the contours, then there are sharp corners in the
> data, and smoothing 
> is not your friend. One possibility is to change the
> resolution of the 
> image, which should remove sharp boundaries that are
> only artefacts of the 
> resolution - for example by interpolating to a
> denser grid.
> 
> Roger
> 
> >    I'd appreciate any help.
> >    Thank you very much.
> >
> >
> >
> >
> >     
>
____________________________________________________________________________________
> >
> > [[elided Yahoo spam]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics,
> Norwegian School of
> Economics and Business Administration, Helleveien
> 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> 



      ____________________________________________________________________________________

[[elided Yahoo spam]]



From fhds2000 at yahoo.com  Fri Apr 25 21:08:53 2008
From: fhds2000 at yahoo.com (F. De Sales)
Date: Fri, 25 Apr 2008 12:08:53 -0700 (PDT)
Subject: [R-sig-Geo] matching shading and contour
Message-ID: <305316.43372.qm@web53308.mail.re2.yahoo.com>

    Hello everyone.
    Once again I need you help. How to make sure that
contour lines and shading match when using the command
filled.contour?
    This is my example:

P = array(0,c(10,5))
P [1,]= c(-0.0708, -0.09906,  0.2346,  0.1556,
-0.1136)
P [2,]= c(-0.1086, -0.07813,  0.4122,  0.3290,
-0.2537)
P [3,]= c(-0.0661, -0.16677,  0.5109,  0.6276,
-0.4118)
P [4,]= c(-0.0728, -0.05032,  0.2441,  0.7046,
-0.8731)
P [5,]= c(-0.0940,  0.00464,  0.0212,  0.3605,
-1.2655)
P [6,]= c(-0.2043, -0.18422, -0.1460,  0.0917,
-1.0035)
P [7,]= c(-0.2263, -0.17598,  0.0318, -0.0685,
-0.8082)
P [8,]= c(-0.3277, -0.16696,  0.2180, -0.0898,
-0.6687)
P [9,]= c(-0.3139, -0.19312,  0.4357, -0.1240,
-0.3028)
P[10,]= c(-0.1368,  0.15187,  0.1775,  0.0379,
-0.0158)
xx = seq(1,10)
yy = seq(1,5)
filled.contour(xx,yy,P,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=20,
   color=cm.colors,
   plot.axes = {
      contour(xx,yy,P,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=20,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })

    You can see that in the center of the plot the
contour lines do no match the shaded pink area.

    Any idea?
    Thank you again for your help.
    F. De Sales 


      ____________________________________________________________________________________

[[elided Yahoo spam]]



From FredeA.Togersen at agrsci.dk  Sat Apr 26 09:21:14 2008
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Sat, 26 Apr 2008 09:21:14 +0200
Subject: [R-sig-Geo] matching shading and contour
References: <305316.43372.qm@web53308.mail.re2.yahoo.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC04E87E8A@DJFPOST01.djf.agrsci.dk>

Thank you for finally (you've asked at the r-help list too) for providing a minimal example. It makes it easier for us to help you.
 
Try using the interp() function from the "akima" package. E.g.

install.packages("akima")
library(akima)
 
dim(P)
 
P.interp <- interp(xyz$x, xyz$y, xyz$z)
 
str(P.interp)
 
mynl <- 20
filled.contour(P.interp$x,P.interp$y,P.interp$z,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=mynl,
   color=cm.colors,
   plot.axes = {
      contour(P.interp$x,P.interp$y,P.interp$z,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=mynl,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })
 
You can play with the settings of interp() together with the settings of nlevels of filled.contour() in order to get something close to what you want:

P.interp <- interp(xyz$x, xyz$y, xyz$z,
                   xo = seq(min(xyz$x), max(xyz$x), length = 100),
                   yo = seq(min(xyz$y), max(xyz$y), length = 100))
 
mynl <- 40, # or 10, 20, 50, .......
filled.contour(P.interp$x,P.interp$y,P.interp$z,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=mynl,
   color=cm.colors,
   plot.axes = {
      contour(P.interp$x,P.interp$y,P.interp$z,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=mynl,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })

regards Frede Aakman T?gersen

________________________________

Fra: r-sig-geo-bounces at stat.math.ethz.ch p? vegne af F. De Sales
Sendt: fr 25-04-2008 21:08
Til: r-sig-geo at stat.math.ethz.ch
Emne: [R-sig-Geo] matching shading and contour



    Hello everyone.
    Once again I need you help. How to make sure that
contour lines and shading match when using the command
filled.contour?
    This is my example:

P = array(0,c(10,5))
P [1,]= c(-0.0708, -0.09906,  0.2346,  0.1556,
-0.1136)
P [2,]= c(-0.1086, -0.07813,  0.4122,  0.3290,
-0.2537)
P [3,]= c(-0.0661, -0.16677,  0.5109,  0.6276,
-0.4118)
P [4,]= c(-0.0728, -0.05032,  0.2441,  0.7046,
-0.8731)
P [5,]= c(-0.0940,  0.00464,  0.0212,  0.3605,
-1.2655)
P [6,]= c(-0.2043, -0.18422, -0.1460,  0.0917,
-1.0035)
P [7,]= c(-0.2263, -0.17598,  0.0318, -0.0685,
-0.8082)
P [8,]= c(-0.3277, -0.16696,  0.2180, -0.0898,
-0.6687)
P [9,]= c(-0.3139, -0.19312,  0.4357, -0.1240,
-0.3028)
P[10,]= c(-0.1368,  0.15187,  0.1775,  0.0379,
-0.0158)
xx = seq(1,10)
yy = seq(1,5)
filled.contour(xx,yy,P,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=20,
   color=cm.colors,
   plot.axes = {
      contour(xx,yy,P,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=20,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })

    You can see that in the center of the plot the
contour lines do no match the shaded pink area.

    Any idea?
    Thank you again for your help.
    F. De Sales


      ____________________________________________________________________________________

[[elided Yahoo spam]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From FredeA.Togersen at agrsci.dk  Sat Apr 26 10:50:54 2008
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Sat, 26 Apr 2008 10:50:54 +0200
Subject: [R-sig-Geo] matching shading and contour
References: <305316.43372.qm@web53308.mail.re2.yahoo.com>
	<C83C5E3DEEE97E498B74729A33F6EAEC04E87E8A@DJFPOST01.djf.agrsci.dk>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC04E87E8B@DJFPOST01.djf.agrsci.dk>

Sorry, I just realised that my copy and pasting wasn't sufficient to understand what I'm doing.
 
My xyz object below is just a dataframe containing your xx, yy, and P. Thus you  can do this instead:
 
P.interp <- interp(xx, yy, P)

Hope that helps ;-)

Frede



________________________________

Fra: r-sig-geo-bounces at stat.math.ethz.ch p? vegne af Frede Aakmann T?gersen
Sendt: l? 26-04-2008 09:21
Til: F. De Sales; r-sig-geo at stat.math.ethz.ch
Emne: Re: [R-sig-Geo] matching shading and contour



Thank you for finally (you've asked at the r-help list too) for providing a minimal example. It makes it easier for us to help you.

Try using the interp() function from the "akima" package. E.g.

install.packages("akima")
library(akima)

dim(P)

P.interp <- interp(xyz$x, xyz$y, xyz$z)

str(P.interp)

mynl <- 20
filled.contour(P.interp$x,P.interp$y,P.interp$z,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=mynl,
   color=cm.colors,
   plot.axes = {
      contour(P.interp$x,P.interp$y,P.interp$z,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=mynl,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })

You can play with the settings of interp() together with the settings of nlevels of filled.contour() in order to get something close to what you want:

P.interp <- interp(xyz$x, xyz$y, xyz$z,
                   xo = seq(min(xyz$x), max(xyz$x), length = 100),
                   yo = seq(min(xyz$y), max(xyz$y), length = 100))

mynl <- 40, # or 10, 20, 50, .......
filled.contour(P.interp$x,P.interp$y,P.interp$z,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=mynl,
   color=cm.colors,
   plot.axes = {
      contour(P.interp$x,P.interp$y,P.interp$z,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=mynl,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })

regards Frede Aakman T?gersen

________________________________

Fra: r-sig-geo-bounces at stat.math.ethz.ch p? vegne af F. De Sales
Sendt: fr 25-04-2008 21:08
Til: r-sig-geo at stat.math.ethz.ch
Emne: [R-sig-Geo] matching shading and contour



    Hello everyone.
    Once again I need you help. How to make sure that
contour lines and shading match when using the command
filled.contour?
    This is my example:

P = array(0,c(10,5))
P [1,]= c(-0.0708, -0.09906,  0.2346,  0.1556,
-0.1136)
P [2,]= c(-0.1086, -0.07813,  0.4122,  0.3290,
-0.2537)
P [3,]= c(-0.0661, -0.16677,  0.5109,  0.6276,
-0.4118)
P [4,]= c(-0.0728, -0.05032,  0.2441,  0.7046,
-0.8731)
P [5,]= c(-0.0940,  0.00464,  0.0212,  0.3605,
-1.2655)
P [6,]= c(-0.2043, -0.18422, -0.1460,  0.0917,
-1.0035)
P [7,]= c(-0.2263, -0.17598,  0.0318, -0.0685,
-0.8082)
P [8,]= c(-0.3277, -0.16696,  0.2180, -0.0898,
-0.6687)
P [9,]= c(-0.3139, -0.19312,  0.4357, -0.1240,
-0.3028)
P[10,]= c(-0.1368,  0.15187,  0.1775,  0.0379,
-0.0158)
xx = seq(1,10)
yy = seq(1,5)
filled.contour(xx,yy,P,ylim=c(2,5),
   zlim=c(-1.5,1.5),nlevels=20,
   color=cm.colors,
   plot.axes = {
      contour(xx,yy,P,add=T, col="grey", ylim=c(2,5),
      zlim=c(-1.5,1.5),nlevels=20,
      drawlabels=F)
      axis(1,1:length(xx))
      axis(2,1:length(yy))
    })

    You can see that in the center of the plot the
contour lines do no match the shaded pink area.

    Any idea?
    Thank you again for your help.
    F. De Sales


      ____________________________________________________________________________________

[[elided Yahoo spam]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From fhds2000 at yahoo.com  Sun Apr 27 05:34:58 2008
From: fhds2000 at yahoo.com (F. De Sales)
Date: Sat, 26 Apr 2008 20:34:58 -0700 (PDT)
Subject: [R-sig-Geo] matching shading and contour
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC04E87E8A@DJFPOST01.djf.agrsci.dk>
Message-ID: <156532.20599.qm@web53308.mail.re2.yahoo.com>

   Dear Frede,
   Thank you very much for helping me with this
matter.
I really appreciate you taking the time to do this.
   I tried your suggestion but I got the following
error message after entering the interp command:

P.interp <- interp( xx,yy,P)

Error in interp.old(x, y, z, xo = xo, yo = yo, ncp =
0, extrap = extrap,  : 
  Lengths of x, y, and z do not match

   Do you know why?  I am kind of a novice to R. 
   Thanks again

   F. DeSales
 
   
--- Frede Aakmann T?gersen <FredeA.Togersen at agrsci.dk>
wrote:

> Thank you for finally (you've asked at the r-help
> list too) for providing a minimal example. It makes
> it easier for us to help you.
>  
> Try using the interp() function from the "akima"
> package. E.g.
> 
> install.packages("akima")
> library(akima)
>  
> dim(P)
>  
> P.interp <- interp(xyz$x, xyz$y, xyz$z)
>  
> str(P.interp)
>  
> mynl <- 20
>
filled.contour(P.interp$x,P.interp$y,P.interp$z,ylim=c(2,5),
>    zlim=c(-1.5,1.5),nlevels=mynl,
>    color=cm.colors,
>    plot.axes = {
>      
> contour(P.interp$x,P.interp$y,P.interp$z,add=T,
> col="grey", ylim=c(2,5),
>       zlim=c(-1.5,1.5),nlevels=mynl,
>       drawlabels=F)
>       axis(1,1:length(xx))
>       axis(2,1:length(yy))
>     })
>  
> You can play with the settings of interp() together
> with the settings of nlevels of filled.contour() in
> order to get something close to what you want:
> 
> P.interp <- interp(xyz$x, xyz$y, xyz$z,
>                    xo = seq(min(xyz$x), max(xyz$x),
> length = 100),
>                    yo = seq(min(xyz$y), max(xyz$y),
> length = 100))
>  
> mynl <- 40, # or 10, 20, 50, .......
>
filled.contour(P.interp$x,P.interp$y,P.interp$z,ylim=c(2,5),
>    zlim=c(-1.5,1.5),nlevels=mynl,
>    color=cm.colors,
>    plot.axes = {
>      
> contour(P.interp$x,P.interp$y,P.interp$z,add=T,
> col="grey", ylim=c(2,5),
>       zlim=c(-1.5,1.5),nlevels=mynl,
>       drawlabels=F)
>       axis(1,1:length(xx))
>       axis(2,1:length(yy))
>     })
> 
> regards Frede Aakman T?gersen
> 
> ________________________________
> 
> Fra: r-sig-geo-bounces at stat.math.ethz.ch p? vegne af
> F. De Sales
> Sendt: fr 25-04-2008 21:08
> Til: r-sig-geo at stat.math.ethz.ch
> Emne: [R-sig-Geo] matching shading and contour
> 
> 
> 
>     Hello everyone.
>     Once again I need you help. How to make sure
> that
> contour lines and shading match when using the
> command
> filled.contour?
>     This is my example:
> 
> P = array(0,c(10,5))
> P [1,]= c(-0.0708, -0.09906,  0.2346,  0.1556,
> -0.1136)
> P [2,]= c(-0.1086, -0.07813,  0.4122,  0.3290,
> -0.2537)
> P [3,]= c(-0.0661, -0.16677,  0.5109,  0.6276,
> -0.4118)
> P [4,]= c(-0.0728, -0.05032,  0.2441,  0.7046,
> -0.8731)
> P [5,]= c(-0.0940,  0.00464,  0.0212,  0.3605,
> -1.2655)
> P [6,]= c(-0.2043, -0.18422, -0.1460,  0.0917,
> -1.0035)
> P [7,]= c(-0.2263, -0.17598,  0.0318, -0.0685,
> -0.8082)
> P [8,]= c(-0.3277, -0.16696,  0.2180, -0.0898,
> -0.6687)
> P [9,]= c(-0.3139, -0.19312,  0.4357, -0.1240,
> -0.3028)
> P[10,]= c(-0.1368,  0.15187,  0.1775,  0.0379,
> -0.0158)
> xx = seq(1,10)
> yy = seq(1,5)
> filled.contour(xx,yy,P,ylim=c(2,5),
>    zlim=c(-1.5,1.5),nlevels=20,
>    color=cm.colors,
>    plot.axes = {
>       contour(xx,yy,P,add=T, col="grey",
> ylim=c(2,5),
>       zlim=c(-1.5,1.5),nlevels=20,
>       drawlabels=F)
>       axis(1,1:length(xx))
>       axis(2,1:length(yy))
>     })
> 
>     You can see that in the center of the plot the
> contour lines do no match the shaded pink area.
> 
>     Any idea?
>     Thank you again for your help.
>     F. De Sales
> 
> 
>      
>
____________________________________________________________________________________
> 
> [[elided Yahoo spam]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 



      ____________________________________________________________________________________

[[elided Yahoo spam]]



From Michael.Haenlein at whu.edu  Mon Apr 28 09:37:33 2008
From: Michael.Haenlein at whu.edu (Haenlein.Michael)
Date: Mon, 28 Apr 2008 09:37:33 +0200
Subject: [R-sig-Geo] Question regarding spdep package
Message-ID: <FCE3439777D52842B1D4831921FCA0D14B766FCB09@EXIDEFIX01.whu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080428/f9486ba0/attachment.pl>

From graham.smith at myotis.co.uk  Mon Apr 28 10:55:30 2008
From: graham.smith at myotis.co.uk (Graham Smith)
Date: Mon, 28 Apr 2008 09:55:30 +0100
Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface plot
Message-ID: <076E91E8-8076-45FD-B90A-17A881C15B8E@myotis.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080428/dc1cd2d0/attachment.pl>

From Roger.Bivand at nhh.no  Mon Apr 28 11:15:22 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 28 Apr 2008 11:15:22 +0200 (CEST)
Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface plot
In-Reply-To: <076E91E8-8076-45FD-B90A-17A881C15B8E@myotis.co.uk>
References: <076E91E8-8076-45FD-B90A-17A881C15B8E@myotis.co.uk>
Message-ID: <Pine.LNX.4.64.0804281110460.30242@reclus.nhh.no>

On Mon, 28 Apr 2008, Graham Smith wrote:

> With help from Marcelino. I have produced a smoothed surface plot of
> water depths (depths as marks) in spatstat, but the default colours
> are oranges and reds. How do I change these to blues.
>
> Can I redifne the colours in terrain.colors() or topo.colors(), or do
> I need to use rainbow(). Or is its something different all together.

They are built-in, don't try to change them. Look at ?colorRampPalette and 
at ?brewer.pal in RColorBrewer, I guess that something like:

library(RColorBrewer)
bl5 <- brewer.pal(5, "Blues")
mypal <- colorRampPalette(bl5)


then use mypal(n) to get n blues. You may need rev(bl5) to get them the 
other way.

Roger

>
> I have tried the options I listed above , but can't get a syntax that
> works, and haven't found the help any help at all (not for me anyway).
>
> Can anyone help.
>
> Many thanks,
>
> Graham
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From adrian at maths.uwa.edu.au  Tue Apr 29 10:27:59 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Tue, 29 Apr 2008 16:27:59 +0800 (WST)
Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface plot
In-Reply-To: <mailman.9.1209376805.2119.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1209376805.2119.r-sig-geo@stat.math.ethz.ch>
Message-ID: <41679.130.95.98.17.1209457679.squirrel@130.95.98.17>

Graham Smith <graham.smith at myotis.co.uk> writes:

> I have produced a smoothed surface plot of
> water depths (depths as marks) in spatstat, but the default colours
> are oranges and reds. How do I change these to blues.

> Can I redifne the colours in terrain.colors() or topo.colors(), or do
> I need to use rainbow(). Or is its something different all together.

Yes, you can do all of these things. It is not true that the colours are
hard-wired.

> I have tried the options I listed above , but can't get a syntax that
> works, and haven't found the help any help at all (not for me anyway).

I presume that you are using smooth.ppp to smooth a marked point pattern,
yielding a pixel image (object of class "im") which you now want to
display in your chosen colours. So the relevant help file is
               help(plot.im)
The help file explains that the argument 'col' determines the colours that
will be used. See the examples in the help file, or example(plot.im).

Here is an example of the whole process, starting from a marked point
pattern and finishing with a colour image:

      library(spatstat)
      data(longleaf)
      Z <- smooth.ppp(longleaf)
      plot(Z)
      plot(Z, col=topo.colors(256))

Adrian Baddeley



From graham.smith at myotis.co.uk  Tue Apr 29 20:59:48 2008
From: graham.smith at myotis.co.uk (Graham Smith)
Date: Tue, 29 Apr 2008 19:59:48 +0100
Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface plot
In-Reply-To: <41679.130.95.98.17.1209457679.squirrel@130.95.98.17>
References: <mailman.9.1209376805.2119.r-sig-geo@stat.math.ethz.ch>
	<41679.130.95.98.17.1209457679.squirrel@130.95.98.17>
Message-ID: <31010290-858C-4392-9959-6D6B94389CD4@myotis.co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080429/cbf37f07/attachment.pl>

From Michael.Haenlein at whu.edu  Tue Apr 29 21:47:18 2008
From: Michael.Haenlein at whu.edu (Haenlein.Michael)
Date: Tue, 29 Apr 2008 21:47:18 +0200
Subject: [R-sig-Geo] Question regarding spdep package
Message-ID: <FCE3439777D52842B1D4831921FCA0D14B766FCB0B@EXIDEFIX01.whu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080429/971866c1/attachment.pl>

From hilton at meteo.psu.edu  Tue Apr 29 23:48:07 2008
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Tue, 29 Apr 2008 17:48:07 -0400
Subject: [R-sig-Geo] gstat variogram & great circle distance
Message-ID: <20080429214807.GA985@Tim.local>

Hello,

I am trying to use gstat to compute a semivariogram for data whose coordinates are latitude/longitude pairs.  I would like to use the great circle distance between pairs.  The documentation implies that gstat can do this, but I am not having any success.  If anyone could suggest the correct syntax, I would greatly appreciate it.

Here is a sample of my data (see output from dump below):


> foo
            z        lon      lat
1  -1.9582483 -125.29228 49.87217
2  -1.9158902  -82.15560 48.21670
3   4.2221176  -98.52472 55.90583
4   3.2335693  -99.94833 56.63583
5   1.1203839 -104.69174 53.91626
6   0.3461385  -79.42083 39.06333
7   1.1258993 -105.10053 48.30788
8  23.5179123  -88.29187 40.00610
9   3.0519159  -72.17148 42.53776
10  3.2026143 -121.55694 44.44889
11 -2.1094711  -89.34765 46.24202

I can calculate a variogram:

>coordinates(foo) <- ~lon+lat
>variogram(z~1, foo)
   np      dist       gamma dir.hor dir.ver   id
1   1  1.599865   0.4886139       0       0 var1
2   2  5.545490   1.1163957       0       0 var1
3   4  6.712018  86.6319381       0       0 var1
4   1  8.038953   3.6606156       0       0 var1
5   3  9.422337  91.0816908       0       0 var1
6   2 10.149322 164.1162183       0       0 var1
7   2 11.868366   7.6772788       0       0 var1
8   1 13.326965  20.0445076       0       0 var1
9   1 14.846073  14.2740402       0       0 var1
10  1 15.887767   5.2338108       0       0 var1
11  3 16.792331  72.2669527       0       0 var1
12  2 17.828085  16.0787636       0       0 var1

The distances are clearly not great circle distances, though.  Setting the "projected" flag to "false" gives me this error:

> variogram(z~1, foo, projected=FALSE)
Error in variogram.default(y, locations, X, trend.beta = beta, grid = grid,  :
  formal argument "projected" matched by multiple actual arguments

Thanks in advance for any help,
Tim

==================
`foo` <-
structure(list(z = c(-1.95824831109744, -1.91589016435630, 4.22211761150161,
3.23356929459598, 1.12038389231868, 0.34613850821113, 1.12589932643631,
23.5179122516170, 3.05191586902680, 3.20261431141517, -2.10947106854739
), lon = c(-125.29228, -82.1556, -98.524722, -99.948333, -104.691741,
-79.420833, -105.100533, -88.291867, -72.171478, -121.556944,
-89.34765), lat = c(49.87217, 48.2167, 55.905833, 56.635833,
53.916264, 39.063333, 48.307883, 40.0061, 42.537756, 44.448889,
46.242017)), .Names = c("z", "lon", "lat"), row.names = c(NA,
-11L), class = "data.frame")



From jsebastiantello at yahoo.com  Wed Apr 30 02:41:33 2008
From: jsebastiantello at yahoo.com (J. Sebastian Tello)
Date: Tue, 29 Apr 2008 17:41:33 -0700 (PDT)
Subject: [R-sig-Geo] Geographic distance from Coordinates
Message-ID: <869928.8652.qm@web39606.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080429/13f9ee2e/attachment.pl>

From hkreft at ucsd.edu  Wed Apr 30 06:04:06 2008
From: hkreft at ucsd.edu (hkreft at ucsd.edu)
Date: Tue, 29 Apr 2008 21:04:06 -0700 (PDT)
Subject: [R-sig-Geo] maptools: appending data to SpatialPolygonsDataFrame
Message-ID: <60974.66.27.67.30.1209528246.squirrel@acs-webmail.ucsd.edu>

Dear all,

I am just starting to use the library maptools. Specifically, I want to
use it as a quick way to map results from various multivariate analyses
(e.g. cluster analyses) directly in R.
I encountered problems appending newly generated data (cluster
memberships) to the SpatialPolygonsDataFrame object. Unfortunately, the
documentation is not really helpful.

But I am sure that this is an easy question for you.

Thanks in advance,

Holger


The code so far:

> > my.polys <- readShapePoly("Z://mypoly.shp",IDvar="ID",verbose=T)
> > plot(my.polys)



From edzer.pebesma at uni-muenster.de  Wed Apr 30 07:42:36 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 30 Apr 2008 07:42:36 +0200
Subject: [R-sig-Geo] gstat variogram & great circle distance
In-Reply-To: <20080429214807.GA985@Tim.local>
References: <20080429214807.GA985@Tim.local>
Message-ID: <481806CC.9000907@uni-muenster.de>

Timothy, for some reason the projected argument was not meant to be set 
by users at this level of abstraction; I'll look into it. The following 
seems to work:

 > proj4string(foo)=CRS("+longlat")
 > proj4string(foo)
[1] "+longlat"
 > variogram(z~1,foo)
  np      dist        gamma dir.hor dir.ver   id
1  1  177.7815   0.48861387       0       0 var1
2  2  614.0040   1.11639574       0       0 var1
3  3  715.8402 115.50300578       0       0 var1
4  1  829.6047   0.01873678       0       0 var1
5  1  893.0483   3.66061567       0       0 var1
6  1  992.9436 268.46555052       0       0 var1
7  4 1095.7359  83.25299050       0       0 var1
8  1 1274.4497  12.33954872       0       0 var1
9  1 1357.4796   3.01500925       0       0 var1

--
Edzer


Timothy W. Hilton wrote:
> Hello,
>
> I am trying to use gstat to compute a semivariogram for data whose coordinates are latitude/longitude pairs.  I would like to use the great circle distance between pairs.  The documentation implies that gstat can do this, but I am not having any success.  If anyone could suggest the correct syntax, I would greatly appreciate it.
>
> Here is a sample of my data (see output from dump below):
>
>
>   
>> foo
>>     
>             z        lon      lat
> 1  -1.9582483 -125.29228 49.87217
> 2  -1.9158902  -82.15560 48.21670
> 3   4.2221176  -98.52472 55.90583
> 4   3.2335693  -99.94833 56.63583
> 5   1.1203839 -104.69174 53.91626
> 6   0.3461385  -79.42083 39.06333
> 7   1.1258993 -105.10053 48.30788
> 8  23.5179123  -88.29187 40.00610
> 9   3.0519159  -72.17148 42.53776
> 10  3.2026143 -121.55694 44.44889
> 11 -2.1094711  -89.34765 46.24202
>
> I can calculate a variogram:
>
>   
>> coordinates(foo) <- ~lon+lat
>> variogram(z~1, foo)
>>     
>    np      dist       gamma dir.hor dir.ver   id
> 1   1  1.599865   0.4886139       0       0 var1
> 2   2  5.545490   1.1163957       0       0 var1
> 3   4  6.712018  86.6319381       0       0 var1
> 4   1  8.038953   3.6606156       0       0 var1
> 5   3  9.422337  91.0816908       0       0 var1
> 6   2 10.149322 164.1162183       0       0 var1
> 7   2 11.868366   7.6772788       0       0 var1
> 8   1 13.326965  20.0445076       0       0 var1
> 9   1 14.846073  14.2740402       0       0 var1
> 10  1 15.887767   5.2338108       0       0 var1
> 11  3 16.792331  72.2669527       0       0 var1
> 12  2 17.828085  16.0787636       0       0 var1
>
> The distances are clearly not great circle distances, though.  Setting the "projected" flag to "false" gives me this error:
>
>   
>> variogram(z~1, foo, projected=FALSE)
>>     
> Error in variogram.default(y, locations, X, trend.beta = beta, grid = grid,  :
>   formal argument "projected" matched by multiple actual arguments
>
> Thanks in advance for any help,
> Tim
>
> ==================
> `foo` <-
> structure(list(z = c(-1.95824831109744, -1.91589016435630, 4.22211761150161,
> 3.23356929459598, 1.12038389231868, 0.34613850821113, 1.12589932643631,
> 23.5179122516170, 3.05191586902680, 3.20261431141517, -2.10947106854739
> ), lon = c(-125.29228, -82.1556, -98.524722, -99.948333, -104.691741,
> -79.420833, -105.100533, -88.291867, -72.171478, -121.556944,
> -89.34765), lat = c(49.87217, 48.2167, 55.905833, 56.635833,
> 53.916264, 39.063333, 48.307883, 40.0061, 42.537756, 44.448889,
> 46.242017)), .Names = c("z", "lon", "lat"), row.names = c(NA,
> -11L), class = "data.frame")
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Wed Apr 30 07:45:48 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 30 Apr 2008 07:45:48 +0200
Subject: [R-sig-Geo] Geographic distance from Coordinates
In-Reply-To: <869928.8652.qm@web39606.mail.mud.yahoo.com>
References: <869928.8652.qm@web39606.mail.mud.yahoo.com>
Message-ID: <4818078C.2060902@uni-muenster.de>

You may want to look at spDistsN1 in package sp:
     The function returns a vector of distances between a matrix of 2D
     points and a single 2D point, using Euclidean or Great Circle
     distance (WGS84 ellipsoid) methods.
--
Edzer

J. Sebastian Tello wrote:
> Hi everybody,
> Could anyone please point into a reference where I could find how to make accurate calculations of distance between two points based on their geographic coordinates? I need to write some R code that includes this transformation, but i am not sure how to do it.
> Thanks in advance for any help!
>
> Sebastian
>
>  J. Sebasti?n Tello
>
>
> Department of Biological Sciences
> 285 Life Sciences Building
> Louisiana State University
> Baton Rouge, LA, 70803
> (225) 578-4284 (office and lab.)
>
>
>
> ----- Original Message ----
> From: "r-sig-geo-request at stat.math.ethz.ch" <r-sig-geo-request at stat.math.ethz.ch>
> To: r-sig-geo at stat.math.ethz.ch
> Sent: Tuesday, April 29, 2008 5:00:02 AM
> Subject: R-sig-Geo Digest, Vol 56, Issue 26
>
> Send R-sig-Geo mailing list submissions to
>     r-sig-geo at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
>     r-sig-geo-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
>     r-sig-geo-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
>
>
> Today's Topics:
>
>    1. Changing colour gradient in Spatstat surface plot
>       (adrian at maths.uwa.edu.au)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 29 Apr 2008 16:27:59 +0800 (WST)
> From: adrian at maths.uwa.edu.au
> Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface plot
> To: r-sig-geo at stat.math.ethz.ch
> Cc: r.turner at auckland.ac.nz, adrian at maths.uwa.edu.au
> Message-ID: <41679.130.95.98.17.1209457679.squirrel at 130.95.98.17>
> Content-Type: text/plain;charset=iso-8859-1
>
> Graham Smith <graham.smith at myotis.co.uk> writes:
>
>   
>> I have produced a smoothed surface plot of
>> water depths (depths as marks) in spatstat, but the default colours
>> are oranges and reds. How do I change these to blues.
>>     
>
>   
>> Can I redifne the colours in terrain.colors() or topo.colors(), or do
>> I need to use rainbow(). Or is its something different all together.
>>     
>
> Yes, you can do all of these things. It is not true that the colours are
> hard-wired.
>
>   
>> I have tried the options I listed above , but can't get a syntax that
>> works, and haven't found the help any help at all (not for me anyway).
>>     
>
> I presume that you are using smooth.ppp to smooth a marked point pattern,
> yielding a pixel image (object of class "im") which you now want to
> display in your chosen colours. So the relevant help file is
>                help(plot.im)
> The help file explains that the argument 'col' determines the colours that
> will be used. See the examples in the help file, or example(plot.im).
>
> Here is an example of the whole process, starting from a marked point
> pattern and finishing with a colour image:
>
>       library(spatstat)
>       data(longleaf)
>       Z <- smooth.ppp(longleaf)
>       plot(Z)
>       plot(Z, col=topo.colors(256))
>
> Adrian Baddeley
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 56, Issue 26
> *****************************************
>
>
>
>       ____________________________________________________________________________________
>
> [[elided Yahoo spam]]
> =Ahu06i62sR8HDtDypao8Wcj9tAcJ
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From marcelino.delacruz at upm.es  Wed Apr 30 09:47:30 2008
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Wed, 30 Apr 2008 09:47:30 +0200
Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface  plot
In-Reply-To: <31010290-858C-4392-9959-6D6B94389CD4@myotis.co.uk>
References: <mailman.9.1209376805.2119.r-sig-geo@stat.math.ethz.ch>
	<41679.130.95.98.17.1209457679.squirrel@130.95.98.17>
	<31010290-858C-4392-9959-6D6B94389CD4@myotis.co.uk>
Message-ID: <200804300747.m3U7lfPD008899@smtp.upm.es>

Maybe this synthesis of both replies can help you:


library(RColorBrewer)
bl5 <- brewer.pal(5, "Blues")
mypal <- colorRampPalette(bl5)

  library(spatstat)
  data(longleaf)
  Z <- smooth.ppp(longleaf)
  plot(Z)
  plot(Z, col=mypal(12))

#or

plot(Z, col=rev(mypal(12)))



Regards,


Marcelino


At 20:59 29/04/2008, Graham Smith wrote:
>Adrian
>
>Thanks for the reply
>
> > Here is an example of the whole process, starting from a marked point
> > pattern and finishing with a colour image:
> >
> >       library(spatstat)
> >       data(longleaf)
> >       Z <- smooth.ppp(longleaf)
> >       plot(Z)
> >       plot(Z, col=topo.colors(256))
>
>This is what I did, but I couldn't find, and still can't find,
>anything in the help for plot.im or topo,colors that explains how to
>change the colours to graduated blue, am  being really dim here.
>
>However, in another post it was suggested I use rColorbrewer to set
>up the colours , but it worries me that I cannot find the bit in the
>help you have sent me to.
>
>Graham
>         [[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es



From hilton at meteo.psu.edu  Wed Apr 30 15:44:01 2008
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Wed, 30 Apr 2008 09:44:01 -0400
Subject: [R-sig-Geo] gstat variogram & great circle distance
In-Reply-To: <481806CC.9000907@uni-muenster.de>
References: <20080429214807.GA985@Tim.local> <481806CC.9000907@uni-muenster.de>
Message-ID: <20080430134401.GB1760@Tim.local>

This works great, Edzer.  I expected there was a simple solution.  Many thanks!

-Tim

On Wed, Apr 2008, 30 at 07:42:36AM +0200, Edzer Pebesma wrote:
> Timothy, for some reason the projected argument was not meant to be set 
> by users at this level of abstraction; I'll look into it. The following 
> seems to work:
> 
> > proj4string(foo)=CRS("+longlat")
> > proj4string(foo)
> [1] "+longlat"
> > variogram(z~1,foo)
>  np      dist        gamma dir.hor dir.ver   id
> 1  1  177.7815   0.48861387       0       0 var1
> 2  2  614.0040   1.11639574       0       0 var1
> 3  3  715.8402 115.50300578       0       0 var1
> 4  1  829.6047   0.01873678       0       0 var1
> 5  1  893.0483   3.66061567       0       0 var1
> 6  1  992.9436 268.46555052       0       0 var1
> 7  4 1095.7359  83.25299050       0       0 var1
> 8  1 1274.4497  12.33954872       0       0 var1
> 9  1 1357.4796   3.01500925       0       0 var1
> 
> --
> Edzer
> 
> 
> Timothy W. Hilton wrote:
> >Hello,
> >
> >I am trying to use gstat to compute a semivariogram for data whose 
> >coordinates are latitude/longitude pairs.  I would like to use the great 
> >circle distance between pairs.  The documentation implies that gstat can 
> >do this, but I am not having any success.  If anyone could suggest the 
> >correct syntax, I would greatly appreciate it.
> >
> >Here is a sample of my data (see output from dump below):
> >
> >
> >  
> >>foo
> >>    
> >            z        lon      lat
> >1  -1.9582483 -125.29228 49.87217
> >2  -1.9158902  -82.15560 48.21670
> >3   4.2221176  -98.52472 55.90583
> >4   3.2335693  -99.94833 56.63583
> >5   1.1203839 -104.69174 53.91626
> >6   0.3461385  -79.42083 39.06333
> >7   1.1258993 -105.10053 48.30788
> >8  23.5179123  -88.29187 40.00610
> >9   3.0519159  -72.17148 42.53776
> >10  3.2026143 -121.55694 44.44889
> >11 -2.1094711  -89.34765 46.24202
> >
> >I can calculate a variogram:
> >
> >  
> >>coordinates(foo) <- ~lon+lat
> >>variogram(z~1, foo)
> >>    
> >   np      dist       gamma dir.hor dir.ver   id
> >1   1  1.599865   0.4886139       0       0 var1
> >2   2  5.545490   1.1163957       0       0 var1
> >3   4  6.712018  86.6319381       0       0 var1
> >4   1  8.038953   3.6606156       0       0 var1
> >5   3  9.422337  91.0816908       0       0 var1
> >6   2 10.149322 164.1162183       0       0 var1
> >7   2 11.868366   7.6772788       0       0 var1
> >8   1 13.326965  20.0445076       0       0 var1
> >9   1 14.846073  14.2740402       0       0 var1
> >10  1 15.887767   5.2338108       0       0 var1
> >11  3 16.792331  72.2669527       0       0 var1
> >12  2 17.828085  16.0787636       0       0 var1
> >
> >The distances are clearly not great circle distances, though.  Setting the 
> >"projected" flag to "false" gives me this error:
> >
> >  
> >>variogram(z~1, foo, projected=FALSE)
> >>    
> >Error in variogram.default(y, locations, X, trend.beta = beta, grid = 
> >grid,  :
> >  formal argument "projected" matched by multiple actual arguments
> >
> >Thanks in advance for any help,
> >Tim
> >
> >==================
> >`foo` <-
> >structure(list(z = c(-1.95824831109744, -1.91589016435630, 
> >4.22211761150161,
> >3.23356929459598, 1.12038389231868, 0.34613850821113, 1.12589932643631,
> >23.5179122516170, 3.05191586902680, 3.20261431141517, -2.10947106854739
> >), lon = c(-125.29228, -82.1556, -98.524722, -99.948333, -104.691741,
> >-79.420833, -105.100533, -88.291867, -72.171478, -121.556944,
> >-89.34765), lat = c(49.87217, 48.2167, 55.905833, 56.635833,
> >53.916264, 39.063333, 48.307883, 40.0061, 42.537756, 44.448889,
> >46.242017)), .Names = c("z", "lon", "lat"), row.names = c(NA,
> >-11L), class = "data.frame")
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at stat.math.ethz.ch
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >  
>



From hilton at meteo.psu.edu  Wed Apr 30 17:44:45 2008
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Wed, 30 Apr 2008 11:44:45 -0400
Subject: [R-sig-Geo] gstat variogram & great circle distance
In-Reply-To: <481806CC.9000907@uni-muenster.de>
References: <20080429214807.GA985@Tim.local> <481806CC.9000907@uni-muenster.de>
Message-ID: <20080430154445.GA2434@Tim.local>

Hi Edzer,

I am still having some trouble with the great distance calculations in 'variogram'.  Your suggestion below works, but the distances are not correct (at least, not in kilometers, meters, or miles).  I do not have proj.4 or gdal libraries installed, nor do I have the R packages proj4 or rgdal.  It seems like I should not need them, as I am not doing a projection.  Given that I am setting the 'proj4string' attribute in order to achieve a great cicle distance calculation, though, I wonder if not having those packages installed is a problem.

An example (dump output for foo is below):

> foo
           z        lon      lat
1 -8.2920352  -68.74028 45.20407
2  0.3962574 -157.40894 70.46961
3 -5.3976371  -89.97919 46.08268
> coordinates(foo) <- ~lon+lat
> proj4string(foo)=CRS("+longlat")
> variogram(z~1, foo, cloud=T, cutoff=10000)
      dist    gamma dir.hor dir.ver   id left right
1 9880.046 37.74321       0       0 var1    2     1
2 2366.200  4.18877       0       0 var1    3     1

The distance from 1 to 2 is 5299 km, and from 3 to 1 is 1650 km.  I'm not sure what the 9880.046 and 2366.200 represent.  The ratio of the variogram$dist values to the correct distances in km are not the same, so those values cannot both be correct distances in any units.

Perhaps I am missing a package that gstat needs?

Many thanks for your help.

Cheers,
Tim

=======
foo <-
structure(list(z = c(-8.29203519866722, 0.396257381218808, -5.39763713302683), lon = c(-68.740278, -157.408944, -89.97919), lat = c(45.20407,70.469611, 46.08268)), .Names = c("z", "lon", "lat"), class = "data.frame", row.names = c(NA,3L))
=======

On Wed, Apr 2008, 30 at 07:42:36AM +0200, Edzer Pebesma wrote:
> Timothy, for some reason the projected argument was not meant to be set 
> by users at this level of abstraction; I'll look into it. The following 
> seems to work:
> 
> > proj4string(foo)=CRS("+longlat")
> > proj4string(foo)
> [1] "+longlat"
> > variogram(z~1,foo)
>  np      dist        gamma dir.hor dir.ver   id
> 1  1  177.7815   0.48861387       0       0 var1
> 2  2  614.0040   1.11639574       0       0 var1
> 3  3  715.8402 115.50300578       0       0 var1
> 4  1  829.6047   0.01873678       0       0 var1
> 5  1  893.0483   3.66061567       0       0 var1
> 6  1  992.9436 268.46555052       0       0 var1
> 7  4 1095.7359  83.25299050       0       0 var1
> 8  1 1274.4497  12.33954872       0       0 var1
> 9  1 1357.4796   3.01500925       0       0 var1
> 
> --
> Edzer
> 
> 
> Timothy W. Hilton wrote:
> >Hello,
> >
> >I am trying to use gstat to compute a semivariogram for data whose 
> >coordinates are latitude/longitude pairs.  I would like to use the great 
> >circle distance between pairs.  The documentation implies that gstat can 
> >do this, but I am not having any success.  If anyone could suggest the 
> >correct syntax, I would greatly appreciate it.
> >
> >Here is a sample of my data (see output from dump below):
> >
> >
> >  
> >>foo
> >>    
> >            z        lon      lat
> >1  -1.9582483 -125.29228 49.87217
> >2  -1.9158902  -82.15560 48.21670
> >3   4.2221176  -98.52472 55.90583
> >4   3.2335693  -99.94833 56.63583
> >5   1.1203839 -104.69174 53.91626
> >6   0.3461385  -79.42083 39.06333
> >7   1.1258993 -105.10053 48.30788
> >8  23.5179123  -88.29187 40.00610
> >9   3.0519159  -72.17148 42.53776
> >10  3.2026143 -121.55694 44.44889
> >11 -2.1094711  -89.34765 46.24202
> >
> >I can calculate a variogram:
> >
> >  
> >>coordinates(foo) <- ~lon+lat
> >>variogram(z~1, foo)
> >>    
> >   np      dist       gamma dir.hor dir.ver   id
> >1   1  1.599865   0.4886139       0       0 var1
> >2   2  5.545490   1.1163957       0       0 var1
> >3   4  6.712018  86.6319381       0       0 var1
> >4   1  8.038953   3.6606156       0       0 var1
> >5   3  9.422337  91.0816908       0       0 var1
> >6   2 10.149322 164.1162183       0       0 var1
> >7   2 11.868366   7.6772788       0       0 var1
> >8   1 13.326965  20.0445076       0       0 var1
> >9   1 14.846073  14.2740402       0       0 var1
> >10  1 15.887767   5.2338108       0       0 var1
> >11  3 16.792331  72.2669527       0       0 var1
> >12  2 17.828085  16.0787636       0       0 var1
> >
> >The distances are clearly not great circle distances, though.  Setting the 
> >"projected" flag to "false" gives me this error:
> >
> >  
> >>variogram(z~1, foo, projected=FALSE)
> >>    
> >Error in variogram.default(y, locations, X, trend.beta = beta, grid = 
> >grid,  :
> >  formal argument "projected" matched by multiple actual arguments
> >
> >Thanks in advance for any help,
> >Tim
> >
> >==================
> >`foo` <-
> >structure(list(z = c(-1.95824831109744, -1.91589016435630, 
> >4.22211761150161,
> >3.23356929459598, 1.12038389231868, 0.34613850821113, 1.12589932643631,
> >23.5179122516170, 3.05191586902680, 3.20261431141517, -2.10947106854739
> >), lon = c(-125.29228, -82.1556, -98.524722, -99.948333, -104.691741,
> >-79.420833, -105.100533, -88.291867, -72.171478, -121.556944,
> >-89.34765), lat = c(49.87217, 48.2167, 55.905833, 56.635833,
> >53.916264, 39.063333, 48.307883, 40.0061, 42.537756, 44.448889,
> >46.242017)), .Names = c("z", "lon", "lat"), row.names = c(NA,
> >-11L), class = "data.frame")
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at stat.math.ethz.ch
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >  
>



From yud at mail.montclair.edu  Wed Apr 30 23:02:14 2008
From: yud at mail.montclair.edu (Danlin Yu)
Date: Wed, 30 Apr 2008 17:02:14 -0400
Subject: [R-sig-Geo] Geographic distance from Coordinates
In-Reply-To: <869928.8652.qm@web39606.mail.mud.yahoo.com>
References: <869928.8652.qm@web39606.mail.mud.yahoo.com>
Message-ID: <4818DE56.6070406@mail.montclair.edu>

Sebastian:

I assume you were thinking of calculating distances of points recorded 
with longitude and latitude? If that's the case, then it's an arc 
distance of a Great Circle. This article on wikipedia summarizes what 
the formula are, and you can code the formula in R very reasonably: 
http://en.wikipedia.org/wiki/Great-circle_distance.

If the coordinates are projected, then regular Euclidean distance would 
apply.

Hope this helps.

Cheers,
Dr. Danlin Yu

J. Sebastian Tello wrote:
> Hi everybody,
> Could anyone please point into a reference where I could find how to make accurate calculations of distance between two points based on their geographic coordinates? I need to write some R code that includes this transformation, but i am not sure how to do it.
> Thanks in advance for any help!
>
> Sebastian
>
>  J. Sebasti?n Tello
>
>
> Department of Biological Sciences
> 285 Life Sciences Building
> Louisiana State University
> Baton Rouge, LA, 70803
> (225) 578-4284 (office and lab.)
>
>
>
> ----- Original Message ----
> From: "r-sig-geo-request at stat.math.ethz.ch" <r-sig-geo-request at stat.math.ethz.ch>
> To: r-sig-geo at stat.math.ethz.ch
> Sent: Tuesday, April 29, 2008 5:00:02 AM
> Subject: R-sig-Geo Digest, Vol 56, Issue 26
>
> Send R-sig-Geo mailing list submissions to
>     r-sig-geo at stat.math.ethz.ch
>
> To subscribe or unsubscribe via the World Wide Web, visit
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
>     r-sig-geo-request at stat.math.ethz.ch
>
> You can reach the person managing the list at
>     r-sig-geo-owner at stat.math.ethz.ch
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
>
>
> Today's Topics:
>
>    1. Changing colour gradient in Spatstat surface plot
>       (adrian at maths.uwa.edu.au)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 29 Apr 2008 16:27:59 +0800 (WST)
> From: adrian at maths.uwa.edu.au
> Subject: [R-sig-Geo] Changing colour gradient in Spatstat surface plot
> To: r-sig-geo at stat.math.ethz.ch
> Cc: r.turner at auckland.ac.nz, adrian at maths.uwa.edu.au
> Message-ID: <41679.130.95.98.17.1209457679.squirrel at 130.95.98.17>
> Content-Type: text/plain;charset=iso-8859-1
>
> Graham Smith <graham.smith at myotis.co.uk> writes:
>
>   
>> I have produced a smoothed surface plot of
>> water depths (depths as marks) in spatstat, but the default colours
>> are oranges and reds. How do I change these to blues.
>>     
>
>   
>> Can I redifne the colours in terrain.colors() or topo.colors(), or do
>> I need to use rainbow(). Or is its something different all together.
>>     
>
> Yes, you can do all of these things. It is not true that the colours are
> hard-wired.
>
>   
>> I have tried the options I listed above , but can't get a syntax that
>> works, and haven't found the help any help at all (not for me anyway).
>>     
>
> I presume that you are using smooth.ppp to smooth a marked point pattern,
> yielding a pixel image (object of class "im") which you now want to
> display in your chosen colours. So the relevant help file is
>                help(plot.im)
> The help file explains that the argument 'col' determines the colours that
> will be used. See the examples in the help file, or example(plot.im).
>
> Here is an example of the whole process, starting from a marked point
> pattern and finishing with a colour image:
>
>       library(spatstat)
>       data(longleaf)
>       Z <- smooth.ppp(longleaf)
>       plot(Z)
>       plot(Z, col=topo.colors(256))
>
> Adrian Baddeley
>
>
>
> ------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> End of R-sig-Geo Digest, Vol 56, Issue 26
> *****************************************
>
>
>
>       ____________________________________________________________________________________
>
> [[elided Yahoo spam]]
> =Ahu06i62sR8HDtDypao8Wcj9tAcJ
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu



