From r@i@1290 m@iii@g oii @im@com  Tue May  9 19:01:11 2023
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Tue, 9 May 2023 17:01:11 +0000 (UTC)
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
Message-ID: <1461120448.6176960.1683651671652@mail.yahoo.com>

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
? ? CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)?? ? IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)? ? IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)? ? IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)? ? MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)? ? HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)? ? MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)? ? GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)? ? GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
? ? >CanESMRCP8.5PL
? ? ? ? get3.teratons? ?pland20? ? X1? ? ? 0.4542249 13.252426? ? X2? ? ? 0.4626662? 3.766658? ? X3? ? ? 0.4715780? 2.220986? ? X4? ? ? 0.4809204? 8.495072? ? X5? ? ? 0.4901427 10.206458? ? X6? ? ? 0.4993126 10.942797? ? X7? ? ? 0.5088599? 6.592956? ? X8? ? ? 0.5187588? 2.435796? ? X9? ? ? 0.5286758? 2.275836? ? X10? ? ?0.5389284? 5.051706? ? X11? ? ?0.5496212? 8.313389? ? X12? ? ?0.5600628? 9.007722? ? X13? ? ?0.5708608 11.905644? ? X14? ? ?0.5819234? 6.126022? ? X15? ? ?0.5926283? 9.883264? ? X16? ? ?0.6042306? 7.699696? ? X17? ? ?0.6159752? 5.614193? ? X18? ? ?0.6274483? 6.681527? ? X19? ? ?0.6394011 10.112812? ? X20? ? ?0.6519496? 8.721810? ? X21? ? ?0.6646344 10.315931? ? X22? ? ?0.6773436 11.372490? ? X23? ? ?0.6903203? 8.662169? ? X24? ? ?0.7036479 10.106109? ? X25? ? ?0.7180955 10.990867? ? X26? ? ?0.7322746 13.491778? ? X27? ? ?0.7459771 17.256650? ? X28? ? ?0.7604589 12.040960? ? X29? ? ?0.7753096 10.638796? ? X30? ? ?0.7898374? 7.889500? ? X31? ? ?0.8047258 11.757174? ? X32? ? ?0.8204160 15.060151? ? X33? ? ?0.8359387? 9.822078? ? X34? ? ?0.8510721 11.388695? ? X35? ? ?0.8661237 10.271567? ? X36? ? ?0.8815913 13.224285? ? X37? ? ?0.8984146 15.584782? ? X38? ? ?0.9154501? 9.320024? ? X39? ? ?0.9324529? 9.187128? ? X40? ? ?0.9497379 12.919805? ? X41? ? ?0.9672824 15.190318? ? X42? ? ?0.9854439 12.098606? ? X43? ? ?1.0041460 16.758629? ? X44? ? ?1.0241779 17.435182? ? X45? ? ?1.0451656 15.323428? ? X46? ? ?1.0663605 18.292109? ? X47? ? ?1.0868977 12.625429? ? X48? ? ?1.1079376 17.318583? ? X49? ? ?1.1295719 14.056624? ? X50? ? ?1.1516720 18.239445? ? X51? ? ?1.1736696 16.312087? ? X52? ? ?1.1963065 18.683315? ? X53? ? ?1.2195753 20.364835? ? X54? ? ?1.2425277 14.337167? ? X55? ? ?1.2653873 16.072449? ? X56? ? ?1.2888002 14.870248? ? X57? ? ?1.3126799 18.431717? ? X58? ? ?1.3362459 19.873449? ? X59? ? ?1.3593610 17.278361? ? X60? ? ?1.3833589 18.532887? ? X61? ? ?1.4083234 16.178170? ? X62? ? ?1.4328881 17.689810? ? X63? ? ?1.4572568 21.395131? ? X64? ? ?1.4821021 20.154886? ? X65? ? ?1.5072721 15.655971? ? X66? ? ?1.5325393 21.692028? ? X67? ? ?1.5581797 23.258303? ? X68? ? ?1.5842384 23.802459? ? X69? ? ?1.6108635 15.824673? ? X70? ? ?1.6365393 19.016228? ? X71? ? ?1.6618322 20.957593? ? X72? ? ?1.6876948 19.105363? ? X73? ? ?1.7134712 19.759288? ? X74? ? ?1.7392598 27.315595? ? X75? ? ?1.7652725 24.882263? ? X76? ? ?1.7913807 25.813408? ? X77? ? ?1.8173818 23.658997? ? X78? ? ?1.8434211 24.223432? ? X79? ? ?1.8695911 23.560818? ? X80? ? ?1.8960611 28.057708? ? X81? ? ?1.9228969 26.996265? ? X82? ? ?1.9493552 26.659719? ? X83? ? ?1.9759324 22.723687? ? X84? ? ?2.0026666 30.977267? ? X85? ? ?2.0290137 29.384326? ? X86? ? ?2.0549359 24.840383? ? X87? ? ?2.0811679 26.952620? ? X88? ? ?2.1081763 29.894790? ? X89? ? ?2.1349227 25.224040? ? X90? ? ?2.1613017 27.722623
? ? >IPSLLRRCP8.5PL
? ? ? ? get6.teratons? ?pland21? ? X1? ? ? 0.5300411? 8.128827? ? X2? ? ? 0.5401701? 6.683660? ? X3? ? ? 0.5503503 12.344974? ? X4? ? ? 0.5607762 11.322411? ? X5? ? ? 0.5714146 14.250646? ? X6? ? ? 0.5825357 10.013592? ? X7? ? ? 0.5937966? 9.437394? ? X8? ? ? 0.6051673? 8.138396? ? X9? ? ? 0.6168960? 9.767765? ? X10? ? ?0.6290367? 8.166579? ? X11? ? ?0.6413864 12.307348? ? X12? ? ?0.6539184 12.623931? ? X13? ? ?0.6667360 11.182448? ? X14? ? ?0.6800060 12.585040? ? X15? ? ?0.6935350 13.408614? ? X16? ? ?0.7071757? 9.352335? ? X17? ? ?0.7211951 12.743725? ? X18? ? ?0.7356089 11.625612? ? X19? ? ?0.7502665 10.240418? ? X20? ? ?0.7650959 12.394282? ? X21? ? ?0.7800845 16.963066? ? X22? ? ?0.7953119 16.380090? ? X23? ? ?0.8107459 10.510501? ? X24? ? ?0.8260236 12.645911? ? X25? ? ?0.8414439 14.134851? ? X26? ? ?0.8572960 18.924963? ? X27? ? ?0.8732313 17.849050? ? X28? ? ?0.8892344 10.941533? ? X29? ? ?0.9057380 12.034925? ? X30? ? ?0.9223530 15.897904? ? X31? ? ?0.9391578 19.707692? ? X32? ? ?0.9563358 16.690375? ? X33? ? ?0.9738711 18.098571? ? X34? ? ?0.9916517 16.588447? ? X35? ? ?1.0096934 16.125172? ? X36? ? ?1.0279473 19.108647? ? X37? ? ?1.0463864 16.972994? ? X38? ? ?1.0653421 22.869403? ? X39? ? ?1.0842487 21.228874? ? X40? ? ?1.1035309 25.509754? ? X41? ? ?1.1230403 15.579367? ? X42? ? ?1.1426743 21.259726? ? X43? ? ?1.1626806 26.061262? ? X44? ? ?1.1833831 21.918530? ? X45? ? ?1.2045888 22.369094? ? X46? ? ?1.2262981 21.480456? ? X47? ? ?1.2481395 20.503543? ? X48? ? ?1.2703019 27.717028? ? X49? ? ?1.2929382 26.295449? ? X50? ? ?1.3157745 28.271455? ? X51? ? ?1.3390449 31.595651? ? X52? ? ?1.3626052 26.188018? ? X53? ? ?1.3863833 26.326999? ? X54? ? ?1.4102701 26.902272? ? X55? ? ?1.4343871 25.308764? ? X56? ? ?1.4584666 23.789699? ? X57? ? ?1.4831504 26.916504? ? X58? ? ?1.5080384 32.921638? ? X59? ? ?1.5331210 29.753267? ? X60? ? ?1.5582794 29.567720? ? X61? ? ?1.5832585 31.454097? ? X62? ? ?1.6085002 26.602191? ? X63? ? ?1.6339502 35.873728? ? X64? ? ?1.6594560 34.222654? ? X65? ? ?1.6851070 36.290959? ? X66? ? ?1.7109757 31.623912? ? X67? ? ?1.7368503 31.965520? ? X68? ? ?1.7626750 41.490310? ? X69? ? ?1.7883216 35.645934? ? X70? ? ?1.8141292 35.639422? ? X71? ? ?1.8405670 37.085608? ? X72? ? ?1.8672313 44.812777? ? X73? ? ?1.8939987 40.044602? ? X74? ? ?1.9208222 37.834526? ? X75? ? ?1.9478806 44.497335? ? X76? ? ?1.9750195 39.839740? ? X77? ? ?2.0024118 38.300529? ? X78? ? ?2.0302205 52.116649? ? X79? ? ?2.0581589 59.189047? ? X80? ? ?2.0861536 51.559857? ? X81? ? ?2.1141780 43.305779? ? X82? ? ?2.1421791 47.950074? ? X83? ? ?2.1703249 46.252149? ? X84? ? ?2.1985953 47.536605? ? X85? ? ?2.2266540 49.422466? ? X86? ? ?2.2547762 44.577399? ? X87? ? ?2.2827062 49.720523? ? X88? ? ?2.3102098 47.138244? ? X89? ? ?2.3379090 51.882832? ? X90? ? ?2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Tue May  9 20:23:24 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Tue, 9 May 2023 18:23:24 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <1461120448.6176960.1683651671652@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
Message-ID: <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From r@i@1290 m@iii@g oii @im@com  Wed May 10 06:52:05 2023
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Wed, 10 May 2023 04:52:05 +0000 (UTC)
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
Message-ID: <1268989022.258398.1683694325460@mail.yahoo.com>

Hi Alex and everyone,
My apologies for the confusion! Let me try to simplify here.

My dataframes are structured in the following way: an x column and y column, like this:
x? ? ? ? y0? ? ? ? 00.2? ? ?27?0.4? ? ?310.6? ? ?320.8? ? ?391.0? ? ?43
1.2? ? ?341.4? ? ?25

Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.??
I hope that this is clearer!
Thanks,
-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

 #yiv7713285102 P {margin-top:0;margin-bottom:0;}I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.
Best Regards,AlexFrom: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
??? CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)???? IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)??? IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)??? IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)??? MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)??? HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)??? MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)??? GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)??? GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
??? >CanESMRCP8.5PL
??????? get3.teratons?? pland20??? X1????? 0.4542249 13.252426??? X2????? 0.4626662? 3.766658??? X3????? 0.4715780? 2.220986??? X4????? 0.4809204? 8.495072??? X5????? 0.4901427 10.206458??? X6????? 0.4993126 10.942797??? X7????? 0.5088599? 6.592956??? X8????? 0.5187588? 2.435796??? X9????? 0.5286758? 2.275836??? X10???? 0.5389284? 5.051706??? X11???? 0.5496212? 8.313389??? X12???? 0.5600628? 9.007722??? X13???? 0.5708608 11.905644??? X14???? 0.5819234? 6.126022??? X15???? 0.5926283? 9.883264??? X16???? 0.6042306? 7.699696??? X17???? 0.6159752? 5.614193??? X18???? 0.6274483? 6.681527??? X19???? 0.6394011 10.112812??? X20???? 0.6519496? 8.721810??? X21???? 0.6646344 10.315931??? X22???? 0.6773436 11.372490??? X23???? 0.6903203? 8.662169??? X24???? 0.7036479 10.106109??? X25???? 0.7180955 10.990867??? X26???? 0.7322746 13.491778??? X27???? 0.7459771 17.256650??? X28???? 0.7604589 12.040960??? X29???? 0.7753096 10.638796??? X30???? 0.7898374? 7.889500??? X31???? 0.8047258 11.757174??? X32???? 0.8204160 15.060151??? X33???? 0.8359387? 9.822078??? X34???? 0.8510721 11.388695??? X35???? 0.8661237 10.271567??? X36???? 0.8815913 13.224285??? X37???? 0.8984146 15.584782??? X38???? 0.9154501? 9.320024??? X39???? 0.9324529? 9.187128??? X40???? 0.9497379 12.919805??? X41???? 0.9672824 15.190318??? X42???? 0.9854439 12.098606??? X43???? 1.0041460 16.758629??? X44???? 1.0241779 17.435182??? X45???? 1.0451656 15.323428??? X46???? 1.0663605 18.292109??? X47???? 1.0868977 12.625429??? X48???? 1.1079376 17.318583??? X49???? 1.1295719 14.056624??? X50???? 1.1516720 18.239445??? X51???? 1.1736696 16.312087??? X52???? 1.1963065 18.683315??? X53???? 1.2195753 20.364835??? X54???? 1.2425277 14.337167??? X55???? 1.2653873 16.072449??? X56???? 1.2888002 14.870248??? X57???? 1.3126799 18.431717??? X58???? 1.3362459 19.873449??? X59???? 1.3593610 17.278361??? X60???? 1.3833589 18.532887??? X61???? 1.4083234 16.178170??? X62???? 1.4328881 17.689810??? X63???? 1.4572568 21.395131??? X64???? 1.4821021 20.154886??? X65???? 1.5072721 15.655971??? X66???? 1.5325393 21.692028??? X67???? 1.5581797 23.258303??? X68???? 1.5842384 23.802459??? X69???? 1.6108635 15.824673??? X70???? 1.6365393 19.016228??? X71???? 1.6618322 20.957593??? X72???? 1.6876948 19.105363??? X73???? 1.7134712 19.759288??? X74???? 1.7392598 27.315595??? X75???? 1.7652725 24.882263??? X76???? 1.7913807 25.813408??? X77???? 1.8173818 23.658997??? X78???? 1.8434211 24.223432??? X79???? 1.8695911 23.560818??? X80???? 1.8960611 28.057708??? X81???? 1.9228969 26.996265??? X82???? 1.9493552 26.659719??? X83???? 1.9759324 22.723687??? X84???? 2.0026666 30.977267??? X85???? 2.0290137 29.384326??? X86???? 2.0549359 24.840383??? X87???? 2.0811679 26.952620??? X88???? 2.1081763 29.894790??? X89???? 2.1349227 25.224040??? X90???? 2.1613017 27.722623
??? >IPSLLRRCP8.5PL
??????? get6.teratons?? pland21??? X1????? 0.5300411? 8.128827??? X2????? 0.5401701? 6.683660??? X3????? 0.5503503 12.344974??? X4????? 0.5607762 11.322411??? X5????? 0.5714146 14.250646??? X6????? 0.5825357 10.013592??? X7????? 0.5937966? 9.437394??? X8????? 0.6051673? 8.138396??? X9????? 0.6168960? 9.767765??? X10???? 0.6290367? 8.166579??? X11???? 0.6413864 12.307348??? X12???? 0.6539184 12.623931??? X13???? 0.6667360 11.182448??? X14???? 0.6800060 12.585040??? X15???? 0.6935350 13.408614??? X16???? 0.7071757? 9.352335??? X17???? 0.7211951 12.743725??? X18???? 0.7356089 11.625612??? X19???? 0.7502665 10.240418??? X20???? 0.7650959 12.394282??? X21???? 0.7800845 16.963066??? X22???? 0.7953119 16.380090??? X23???? 0.8107459 10.510501??? X24???? 0.8260236 12.645911??? X25???? 0.8414439 14.134851??? X26???? 0.8572960 18.924963??? X27???? 0.8732313 17.849050??? X28???? 0.8892344 10.941533??? X29???? 0.9057380 12.034925??? X30???? 0.9223530 15.897904??? X31???? 0.9391578 19.707692??? X32???? 0.9563358 16.690375??? X33???? 0.9738711 18.098571??? X34???? 0.9916517 16.588447??? X35???? 1.0096934 16.125172??? X36???? 1.0279473 19.108647??? X37???? 1.0463864 16.972994??? X38???? 1.0653421 22.869403??? X39???? 1.0842487 21.228874??? X40???? 1.1035309 25.509754??? X41???? 1.1230403 15.579367??? X42???? 1.1426743 21.259726??? X43???? 1.1626806 26.061262??? X44???? 1.1833831 21.918530??? X45???? 1.2045888 22.369094??? X46???? 1.2262981 21.480456??? X47???? 1.2481395 20.503543??? X48???? 1.2703019 27.717028??? X49???? 1.2929382 26.295449??? X50???? 1.3157745 28.271455??? X51???? 1.3390449 31.595651??? X52???? 1.3626052 26.188018??? X53???? 1.3863833 26.326999??? X54???? 1.4102701 26.902272??? X55???? 1.4343871 25.308764??? X56???? 1.4584666 23.789699??? X57???? 1.4831504 26.916504??? X58???? 1.5080384 32.921638??? X59???? 1.5331210 29.753267??? X60???? 1.5582794 29.567720??? X61???? 1.5832585 31.454097??? X62???? 1.6085002 26.602191??? X63???? 1.6339502 35.873728??? X64???? 1.6594560 34.222654??? X65???? 1.6851070 36.290959??? X66???? 1.7109757 31.623912??? X67???? 1.7368503 31.965520??? X68???? 1.7626750 41.490310??? X69???? 1.7883216 35.645934??? X70???? 1.8141292 35.639422??? X71???? 1.8405670 37.085608??? X72???? 1.8672313 44.812777??? X73???? 1.8939987 40.044602??? X74???? 1.9208222 37.834526??? X75???? 1.9478806 44.497335??? X76???? 1.9750195 39.839740??? X77???? 2.0024118 38.300529??? X78???? 2.0302205 52.116649??? X79???? 2.0581589 59.189047??? X80???? 2.0861536 51.559857??? X81???? 2.1141780 43.305779??? X82???? 2.1421791 47.950074??? X83???? 2.1703249 46.252149??? X84???? 2.1985953 47.536605??? X85???? 2.2266540 49.422466??? X86???? 2.2547762 44.577399??? X87???? 2.2827062 49.720523??? X88???? 2.3102098 47.138244??? X89???? 2.3379090 51.882832??? X90???? 2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
??????? [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From r@i@1290 m@iii@g oii @im@com  Wed May 10 14:13:09 2023
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Wed, 10 May 2023 12:13:09 +0000 (UTC)
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
Message-ID: <925605636.359028.1683720789392@mail.yahoo.com>

Hi Alex and everyone,
My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:



Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.??
I hope that this is clearer!
Thanks,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

 #yiv7769615370 P {margin-top:0;margin-bottom:0;}I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.
Best Regards,AlexFrom: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
??? CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)???? IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)??? IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)??? IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)??? MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)??? HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)??? MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)??? GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)??? GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
??? >CanESMRCP8.5PL
??????? get3.teratons?? pland20??? X1????? 0.4542249 13.252426??? X2????? 0.4626662? 3.766658??? X3????? 0.4715780? 2.220986??? X4????? 0.4809204? 8.495072??? X5????? 0.4901427 10.206458??? X6????? 0.4993126 10.942797??? X7????? 0.5088599? 6.592956??? X8????? 0.5187588? 2.435796??? X9????? 0.5286758? 2.275836??? X10???? 0.5389284? 5.051706??? X11???? 0.5496212? 8.313389??? X12???? 0.5600628? 9.007722??? X13???? 0.5708608 11.905644??? X14???? 0.5819234? 6.126022??? X15???? 0.5926283? 9.883264??? X16???? 0.6042306? 7.699696??? X17???? 0.6159752? 5.614193??? X18???? 0.6274483? 6.681527??? X19???? 0.6394011 10.112812??? X20???? 0.6519496? 8.721810??? X21???? 0.6646344 10.315931??? X22???? 0.6773436 11.372490??? X23???? 0.6903203? 8.662169??? X24???? 0.7036479 10.106109??? X25???? 0.7180955 10.990867??? X26???? 0.7322746 13.491778??? X27???? 0.7459771 17.256650??? X28???? 0.7604589 12.040960??? X29???? 0.7753096 10.638796??? X30???? 0.7898374? 7.889500??? X31???? 0.8047258 11.757174??? X32???? 0.8204160 15.060151??? X33???? 0.8359387? 9.822078??? X34???? 0.8510721 11.388695??? X35???? 0.8661237 10.271567??? X36???? 0.8815913 13.224285??? X37???? 0.8984146 15.584782??? X38???? 0.9154501? 9.320024??? X39???? 0.9324529? 9.187128??? X40???? 0.9497379 12.919805??? X41???? 0.9672824 15.190318??? X42???? 0.9854439 12.098606??? X43???? 1.0041460 16.758629??? X44???? 1.0241779 17.435182??? X45???? 1.0451656 15.323428??? X46???? 1.0663605 18.292109??? X47???? 1.0868977 12.625429??? X48???? 1.1079376 17.318583??? X49???? 1.1295719 14.056624??? X50???? 1.1516720 18.239445??? X51???? 1.1736696 16.312087??? X52???? 1.1963065 18.683315??? X53???? 1.2195753 20.364835??? X54???? 1.2425277 14.337167??? X55???? 1.2653873 16.072449??? X56???? 1.2888002 14.870248??? X57???? 1.3126799 18.431717??? X58???? 1.3362459 19.873449??? X59???? 1.3593610 17.278361??? X60???? 1.3833589 18.532887??? X61???? 1.4083234 16.178170??? X62???? 1.4328881 17.689810??? X63???? 1.4572568 21.395131??? X64???? 1.4821021 20.154886??? X65???? 1.5072721 15.655971??? X66???? 1.5325393 21.692028??? X67???? 1.5581797 23.258303??? X68???? 1.5842384 23.802459??? X69???? 1.6108635 15.824673??? X70???? 1.6365393 19.016228??? X71???? 1.6618322 20.957593??? X72???? 1.6876948 19.105363??? X73???? 1.7134712 19.759288??? X74???? 1.7392598 27.315595??? X75???? 1.7652725 24.882263??? X76???? 1.7913807 25.813408??? X77???? 1.8173818 23.658997??? X78???? 1.8434211 24.223432??? X79???? 1.8695911 23.560818??? X80???? 1.8960611 28.057708??? X81???? 1.9228969 26.996265??? X82???? 1.9493552 26.659719??? X83???? 1.9759324 22.723687??? X84???? 2.0026666 30.977267??? X85???? 2.0290137 29.384326??? X86???? 2.0549359 24.840383??? X87???? 2.0811679 26.952620??? X88???? 2.1081763 29.894790??? X89???? 2.1349227 25.224040??? X90???? 2.1613017 27.722623
??? >IPSLLRRCP8.5PL
??????? get6.teratons?? pland21??? X1????? 0.5300411? 8.128827??? X2????? 0.5401701? 6.683660??? X3????? 0.5503503 12.344974??? X4????? 0.5607762 11.322411??? X5????? 0.5714146 14.250646??? X6????? 0.5825357 10.013592??? X7????? 0.5937966? 9.437394??? X8????? 0.6051673? 8.138396??? X9????? 0.6168960? 9.767765??? X10???? 0.6290367? 8.166579??? X11???? 0.6413864 12.307348??? X12???? 0.6539184 12.623931??? X13???? 0.6667360 11.182448??? X14???? 0.6800060 12.585040??? X15???? 0.6935350 13.408614??? X16???? 0.7071757? 9.352335??? X17???? 0.7211951 12.743725??? X18???? 0.7356089 11.625612??? X19???? 0.7502665 10.240418??? X20???? 0.7650959 12.394282??? X21???? 0.7800845 16.963066??? X22???? 0.7953119 16.380090??? X23???? 0.8107459 10.510501??? X24???? 0.8260236 12.645911??? X25???? 0.8414439 14.134851??? X26???? 0.8572960 18.924963??? X27???? 0.8732313 17.849050??? X28???? 0.8892344 10.941533??? X29???? 0.9057380 12.034925??? X30???? 0.9223530 15.897904??? X31???? 0.9391578 19.707692??? X32???? 0.9563358 16.690375??? X33???? 0.9738711 18.098571??? X34???? 0.9916517 16.588447??? X35???? 1.0096934 16.125172??? X36???? 1.0279473 19.108647??? X37???? 1.0463864 16.972994??? X38???? 1.0653421 22.869403??? X39???? 1.0842487 21.228874??? X40???? 1.1035309 25.509754??? X41???? 1.1230403 15.579367??? X42???? 1.1426743 21.259726??? X43???? 1.1626806 26.061262??? X44???? 1.1833831 21.918530??? X45???? 1.2045888 22.369094??? X46???? 1.2262981 21.480456??? X47???? 1.2481395 20.503543??? X48???? 1.2703019 27.717028??? X49???? 1.2929382 26.295449??? X50???? 1.3157745 28.271455??? X51???? 1.3390449 31.595651??? X52???? 1.3626052 26.188018??? X53???? 1.3863833 26.326999??? X54???? 1.4102701 26.902272??? X55???? 1.4343871 25.308764??? X56???? 1.4584666 23.789699??? X57???? 1.4831504 26.916504??? X58???? 1.5080384 32.921638??? X59???? 1.5331210 29.753267??? X60???? 1.5582794 29.567720??? X61???? 1.5832585 31.454097??? X62???? 1.6085002 26.602191??? X63???? 1.6339502 35.873728??? X64???? 1.6594560 34.222654??? X65???? 1.6851070 36.290959??? X66???? 1.7109757 31.623912??? X67???? 1.7368503 31.965520??? X68???? 1.7626750 41.490310??? X69???? 1.7883216 35.645934??? X70???? 1.8141292 35.639422??? X71???? 1.8405670 37.085608??? X72???? 1.8672313 44.812777??? X73???? 1.8939987 40.044602??? X74???? 1.9208222 37.834526??? X75???? 1.9478806 44.497335??? X76???? 1.9750195 39.839740??? X77???? 2.0024118 38.300529??? X78???? 2.0302205 52.116649??? X79???? 2.0581589 59.189047??? X80???? 2.0861536 51.559857??? X81???? 2.1141780 43.305779??? X82???? 2.1421791 47.950074??? X83???? 2.1703249 46.252149??? X84???? 2.1985953 47.536605??? X85???? 2.2266540 49.422466??? X86???? 2.2547762 44.577399??? X87???? 2.2827062 49.720523??? X88???? 2.3102098 47.138244??? X89???? 2.3379090 51.882832??? X90???? 2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
??????? [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Wed May 10 16:31:12 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Wed, 10 May 2023 14:31:12 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <925605636.359028.1683720789392@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
Message-ID: <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From r@i@1290 m@iii@g oii @im@com  Wed May 10 19:40:10 2023
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Wed, 10 May 2023 17:40:10 +0000 (UTC)
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
Message-ID: <1699277172.546804.1683740410098@mail.yahoo.com>

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!?
What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible??
Thanks, again!
-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

#yiv9338178727 P {margin-top:0;margin-bottom:0;}So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.
#Base Rdf<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),? ? ? ? ? ? ? ? y= c(0,27,31,32,39,34,25))df$abs_diff<- abs(df$x-1)
df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1#> [1] 39mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1#> [1] 36.5
#tidyverse
rm(list=ls())library(dplyr)
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),? ? ? ? ? ? ? ? y= c(0,27,31,32,39,34,25))df<- df %>% mutate(abs_diff = abs(x-1))
df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1#> [1] 39
df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1#> [1] 36.5From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?Hi Alex and everyone,
My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:



Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.??
I hope that this is clearer!
Thanks,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

<!--#yiv9338178727 #yiv9338178727x_yiv7769615370 p {margin-top:0;margin-bottom:0;}-->I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.
Best Regards,AlexFrom: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
??? CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)???? IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)??? IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)??? IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)??? MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)??? HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)??? MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)??? GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)??? GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
??? >CanESMRCP8.5PL
??????? get3.teratons?? pland20??? X1????? 0.4542249 13.252426??? X2????? 0.4626662? 3.766658??? X3????? 0.4715780? 2.220986??? X4????? 0.4809204? 8.495072??? X5????? 0.4901427 10.206458??? X6????? 0.4993126 10.942797??? X7????? 0.5088599? 6.592956??? X8????? 0.5187588? 2.435796??? X9????? 0.5286758? 2.275836??? X10???? 0.5389284? 5.051706??? X11???? 0.5496212? 8.313389??? X12???? 0.5600628? 9.007722??? X13???? 0.5708608 11.905644??? X14???? 0.5819234? 6.126022??? X15???? 0.5926283? 9.883264??? X16???? 0.6042306? 7.699696??? X17???? 0.6159752? 5.614193??? X18???? 0.6274483? 6.681527??? X19???? 0.6394011 10.112812??? X20???? 0.6519496? 8.721810??? X21???? 0.6646344 10.315931??? X22???? 0.6773436 11.372490??? X23???? 0.6903203? 8.662169??? X24???? 0.7036479 10.106109??? X25???? 0.7180955 10.990867??? X26???? 0.7322746 13.491778??? X27???? 0.7459771 17.256650??? X28???? 0.7604589 12.040960??? X29???? 0.7753096 10.638796??? X30???? 0.7898374? 7.889500??? X31???? 0.8047258 11.757174??? X32???? 0.8204160 15.060151??? X33???? 0.8359387? 9.822078??? X34???? 0.8510721 11.388695??? X35???? 0.8661237 10.271567??? X36???? 0.8815913 13.224285??? X37???? 0.8984146 15.584782??? X38???? 0.9154501? 9.320024??? X39???? 0.9324529? 9.187128??? X40???? 0.9497379 12.919805??? X41???? 0.9672824 15.190318??? X42???? 0.9854439 12.098606??? X43???? 1.0041460 16.758629??? X44???? 1.0241779 17.435182??? X45???? 1.0451656 15.323428??? X46???? 1.0663605 18.292109??? X47???? 1.0868977 12.625429??? X48???? 1.1079376 17.318583??? X49???? 1.1295719 14.056624??? X50???? 1.1516720 18.239445??? X51???? 1.1736696 16.312087??? X52???? 1.1963065 18.683315??? X53???? 1.2195753 20.364835??? X54???? 1.2425277 14.337167??? X55???? 1.2653873 16.072449??? X56???? 1.2888002 14.870248??? X57???? 1.3126799 18.431717??? X58???? 1.3362459 19.873449??? X59???? 1.3593610 17.278361??? X60???? 1.3833589 18.532887??? X61???? 1.4083234 16.178170??? X62???? 1.4328881 17.689810??? X63???? 1.4572568 21.395131??? X64???? 1.4821021 20.154886??? X65???? 1.5072721 15.655971??? X66???? 1.5325393 21.692028??? X67???? 1.5581797 23.258303??? X68???? 1.5842384 23.802459??? X69???? 1.6108635 15.824673??? X70???? 1.6365393 19.016228??? X71???? 1.6618322 20.957593??? X72???? 1.6876948 19.105363??? X73???? 1.7134712 19.759288??? X74???? 1.7392598 27.315595??? X75???? 1.7652725 24.882263??? X76???? 1.7913807 25.813408??? X77???? 1.8173818 23.658997??? X78???? 1.8434211 24.223432??? X79???? 1.8695911 23.560818??? X80???? 1.8960611 28.057708??? X81???? 1.9228969 26.996265??? X82???? 1.9493552 26.659719??? X83???? 1.9759324 22.723687??? X84???? 2.0026666 30.977267??? X85???? 2.0290137 29.384326??? X86???? 2.0549359 24.840383??? X87???? 2.0811679 26.952620??? X88???? 2.1081763 29.894790??? X89???? 2.1349227 25.224040??? X90???? 2.1613017 27.722623
??? >IPSLLRRCP8.5PL
??????? get6.teratons?? pland21??? X1????? 0.5300411? 8.128827??? X2????? 0.5401701? 6.683660??? X3????? 0.5503503 12.344974??? X4????? 0.5607762 11.322411??? X5????? 0.5714146 14.250646??? X6????? 0.5825357 10.013592??? X7????? 0.5937966? 9.437394??? X8????? 0.6051673? 8.138396??? X9????? 0.6168960? 9.767765??? X10???? 0.6290367? 8.166579??? X11???? 0.6413864 12.307348??? X12???? 0.6539184 12.623931??? X13???? 0.6667360 11.182448??? X14???? 0.6800060 12.585040??? X15???? 0.6935350 13.408614??? X16???? 0.7071757? 9.352335??? X17???? 0.7211951 12.743725??? X18???? 0.7356089 11.625612??? X19???? 0.7502665 10.240418??? X20???? 0.7650959 12.394282??? X21???? 0.7800845 16.963066??? X22???? 0.7953119 16.380090??? X23???? 0.8107459 10.510501??? X24???? 0.8260236 12.645911??? X25???? 0.8414439 14.134851??? X26???? 0.8572960 18.924963??? X27???? 0.8732313 17.849050??? X28???? 0.8892344 10.941533??? X29???? 0.9057380 12.034925??? X30???? 0.9223530 15.897904??? X31???? 0.9391578 19.707692??? X32???? 0.9563358 16.690375??? X33???? 0.9738711 18.098571??? X34???? 0.9916517 16.588447??? X35???? 1.0096934 16.125172??? X36???? 1.0279473 19.108647??? X37???? 1.0463864 16.972994??? X38???? 1.0653421 22.869403??? X39???? 1.0842487 21.228874??? X40???? 1.1035309 25.509754??? X41???? 1.1230403 15.579367??? X42???? 1.1426743 21.259726??? X43???? 1.1626806 26.061262??? X44???? 1.1833831 21.918530??? X45???? 1.2045888 22.369094??? X46???? 1.2262981 21.480456??? X47???? 1.2481395 20.503543??? X48???? 1.2703019 27.717028??? X49???? 1.2929382 26.295449??? X50???? 1.3157745 28.271455??? X51???? 1.3390449 31.595651??? X52???? 1.3626052 26.188018??? X53???? 1.3863833 26.326999??? X54???? 1.4102701 26.902272??? X55???? 1.4343871 25.308764??? X56???? 1.4584666 23.789699??? X57???? 1.4831504 26.916504??? X58???? 1.5080384 32.921638??? X59???? 1.5331210 29.753267??? X60???? 1.5582794 29.567720??? X61???? 1.5832585 31.454097??? X62???? 1.6085002 26.602191??? X63???? 1.6339502 35.873728??? X64???? 1.6594560 34.222654??? X65???? 1.6851070 36.290959??? X66???? 1.7109757 31.623912??? X67???? 1.7368503 31.965520??? X68???? 1.7626750 41.490310??? X69???? 1.7883216 35.645934??? X70???? 1.8141292 35.639422??? X71???? 1.8405670 37.085608??? X72???? 1.8672313 44.812777??? X73???? 1.8939987 40.044602??? X74???? 1.9208222 37.834526??? X75???? 1.9478806 44.497335??? X76???? 1.9750195 39.839740??? X77???? 2.0024118 38.300529??? X78???? 2.0302205 52.116649??? X79???? 2.0581589 59.189047??? X80???? 2.0861536 51.559857??? X81???? 2.1141780 43.305779??? X82???? 2.1421791 47.950074??? X83???? 2.1703249 46.252149??? X84???? 2.1985953 47.536605??? X85???? 2.2266540 49.422466??? X86???? 2.2547762 44.577399??? X87???? 2.2827062 49.720523??? X88???? 2.3102098 47.138244??? X89???? 2.3379090 51.882832??? X90???? 2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
??????? [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
	[[alternative HTML version deleted]]


From r@i@1290 m@iii@g oii @im@com  Mon May 15 22:44:32 2023
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Mon, 15 May 2023 20:44:32 +0000 (UTC)
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
Message-ID: <1080156635.2542836.1684183472927@mail.yahoo.com>

Hi Alexander and everyone,
I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:
ExtractFirstMin<- function(df){? df$abs_diff<- abs(df$x-1)? min_rate<- df$y[which.min(df$abs_diff)]? return(min_rate)} #Get first y value of closest to x=1
Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:
dataframe1
dataframe2dataframe3dataframe4dataframe5dataframe6dataframe7dataframe8dataframe9dataframe10
Thus, using your example above, using the first dataframe listed there, would this become:
ExtractFirstMin<- function(dataframe1){??dataframe1$abs_diff<- abs(dataframe1$x-1)? min_rate<-?dataframe1$y[which.min(dataframe1$abs_diff)]? return(min_rate)} #Get first y value of closest to x=1
df_list<- list(dataframe1,?dataframe2,?dataframe3,?dataframe4,?dataframe5,?dataframe6,?dataframe7,?dataframe8,?dataframe9,?dataframe10)
# Apply function across listsapply(df_list, ExtractFirstMin)

Am I doing this correctly?
Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?Hi Alexander,
Many thanks for sharing this! It was really helpful!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

<!--#yiv5116260421 #yiv5116260421x_yiv4839490444 p {margin-top:0;margin-bottom:0;}-->One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.?
#Generate dataset.seed(5)for (i in 1:10) {? assign(x = paste0("df", i), ? ? ? ? ?value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),? ? ? ? ? ? ? ? ? ? ? ? ? ? y= rnorm(n = 10, mean = 30, sd = 1)))? } # Create 10 Data Frames
# Define Functions (two versions based on how you want to deal with ties)ExtractFirstMin<- function(df){? df$abs_diff<- abs(df$x-1)? min_rate<- df$y[which.min(df$abs_diff)]? return(min_rate)} #Get first y value of closest to x=1
ExtractAvgMin<- function(df){? df$abs_diff<- abs(df$x-1)? min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])? return(min_rate)} #Average all y values that are closest to x=1
# Put all dataframes into a listdf_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)
# Apply function across listsapply(df_list, ExtractFirstMin)#> ?[1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190#> ?[9] 31.57229 31.33907
sapply(df_list, ExtractAvgMin)#> ?[1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190#> ?[9] 31.57229 31.33907From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?Hi Alexander,

Thank you so much for taking the time to outline these suggestions!?
What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible??
Thanks, again!
-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

<!--#yiv5116260421 #yiv5116260421x_yiv4839490444 #yiv5116260421x_yiv4839490444x_yiv9338178727 p {margin-top:0;margin-bottom:0;}-->So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.
#Base Rdf<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),? ? ? ? ? ? ? ? y= c(0,27,31,32,39,34,25))df$abs_diff<- abs(df$x-1)
df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1#> [1] 39mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1#> [1] 36.5
#tidyverse
rm(list=ls())library(dplyr)
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),? ? ? ? ? ? ? ? y= c(0,27,31,32,39,34,25))df<- df %>% mutate(abs_diff = abs(x-1))
df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1#> [1] 39
df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1#> [1] 36.5From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?Hi Alex and everyone,
My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:



Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.??
I hope that this is clearer!
Thanks,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

<!--#yiv5116260421 #yiv5116260421x_yiv4839490444 #yiv5116260421x_yiv4839490444x_yiv9338178727 #yiv5116260421x_yiv4839490444x_yiv9338178727x_yiv7769615370 p {margin-top:0;margin-bottom:0;}-->I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.
Best Regards,AlexFrom: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R?I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
??? CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)???? IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)??? IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)??? IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)??? MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)??? HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)??? MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)??? GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)??? GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
??? >CanESMRCP8.5PL
??????? get3.teratons?? pland20??? X1????? 0.4542249 13.252426??? X2????? 0.4626662? 3.766658??? X3????? 0.4715780? 2.220986??? X4????? 0.4809204? 8.495072??? X5????? 0.4901427 10.206458??? X6????? 0.4993126 10.942797??? X7????? 0.5088599? 6.592956??? X8????? 0.5187588? 2.435796??? X9????? 0.5286758? 2.275836??? X10???? 0.5389284? 5.051706??? X11???? 0.5496212? 8.313389??? X12???? 0.5600628? 9.007722??? X13???? 0.5708608 11.905644??? X14???? 0.5819234? 6.126022??? X15???? 0.5926283? 9.883264??? X16???? 0.6042306? 7.699696??? X17???? 0.6159752? 5.614193??? X18???? 0.6274483? 6.681527??? X19???? 0.6394011 10.112812??? X20???? 0.6519496? 8.721810??? X21???? 0.6646344 10.315931??? X22???? 0.6773436 11.372490??? X23???? 0.6903203? 8.662169??? X24???? 0.7036479 10.106109??? X25???? 0.7180955 10.990867??? X26???? 0.7322746 13.491778??? X27???? 0.7459771 17.256650??? X28???? 0.7604589 12.040960??? X29???? 0.7753096 10.638796??? X30???? 0.7898374? 7.889500??? X31???? 0.8047258 11.757174??? X32???? 0.8204160 15.060151??? X33???? 0.8359387? 9.822078??? X34???? 0.8510721 11.388695??? X35???? 0.8661237 10.271567??? X36???? 0.8815913 13.224285??? X37???? 0.8984146 15.584782??? X38???? 0.9154501? 9.320024??? X39???? 0.9324529? 9.187128??? X40???? 0.9497379 12.919805??? X41???? 0.9672824 15.190318??? X42???? 0.9854439 12.098606??? X43???? 1.0041460 16.758629??? X44???? 1.0241779 17.435182??? X45???? 1.0451656 15.323428??? X46???? 1.0663605 18.292109??? X47???? 1.0868977 12.625429??? X48???? 1.1079376 17.318583??? X49???? 1.1295719 14.056624??? X50???? 1.1516720 18.239445??? X51???? 1.1736696 16.312087??? X52???? 1.1963065 18.683315??? X53???? 1.2195753 20.364835??? X54???? 1.2425277 14.337167??? X55???? 1.2653873 16.072449??? X56???? 1.2888002 14.870248??? X57???? 1.3126799 18.431717??? X58???? 1.3362459 19.873449??? X59???? 1.3593610 17.278361??? X60???? 1.3833589 18.532887??? X61???? 1.4083234 16.178170??? X62???? 1.4328881 17.689810??? X63???? 1.4572568 21.395131??? X64???? 1.4821021 20.154886??? X65???? 1.5072721 15.655971??? X66???? 1.5325393 21.692028??? X67???? 1.5581797 23.258303??? X68???? 1.5842384 23.802459??? X69???? 1.6108635 15.824673??? X70???? 1.6365393 19.016228??? X71???? 1.6618322 20.957593??? X72???? 1.6876948 19.105363??? X73???? 1.7134712 19.759288??? X74???? 1.7392598 27.315595??? X75???? 1.7652725 24.882263??? X76???? 1.7913807 25.813408??? X77???? 1.8173818 23.658997??? X78???? 1.8434211 24.223432??? X79???? 1.8695911 23.560818??? X80???? 1.8960611 28.057708??? X81???? 1.9228969 26.996265??? X82???? 1.9493552 26.659719??? X83???? 1.9759324 22.723687??? X84???? 2.0026666 30.977267??? X85???? 2.0290137 29.384326??? X86???? 2.0549359 24.840383??? X87???? 2.0811679 26.952620??? X88???? 2.1081763 29.894790??? X89???? 2.1349227 25.224040??? X90???? 2.1613017 27.722623
??? >IPSLLRRCP8.5PL
??????? get6.teratons?? pland21??? X1????? 0.5300411? 8.128827??? X2????? 0.5401701? 6.683660??? X3????? 0.5503503 12.344974??? X4????? 0.5607762 11.322411??? X5????? 0.5714146 14.250646??? X6????? 0.5825357 10.013592??? X7????? 0.5937966? 9.437394??? X8????? 0.6051673? 8.138396??? X9????? 0.6168960? 9.767765??? X10???? 0.6290367? 8.166579??? X11???? 0.6413864 12.307348??? X12???? 0.6539184 12.623931??? X13???? 0.6667360 11.182448??? X14???? 0.6800060 12.585040??? X15???? 0.6935350 13.408614??? X16???? 0.7071757? 9.352335??? X17???? 0.7211951 12.743725??? X18???? 0.7356089 11.625612??? X19???? 0.7502665 10.240418??? X20???? 0.7650959 12.394282??? X21???? 0.7800845 16.963066??? X22???? 0.7953119 16.380090??? X23???? 0.8107459 10.510501??? X24???? 0.8260236 12.645911??? X25???? 0.8414439 14.134851??? X26???? 0.8572960 18.924963??? X27???? 0.8732313 17.849050??? X28???? 0.8892344 10.941533??? X29???? 0.9057380 12.034925??? X30???? 0.9223530 15.897904??? X31???? 0.9391578 19.707692??? X32???? 0.9563358 16.690375??? X33???? 0.9738711 18.098571??? X34???? 0.9916517 16.588447??? X35???? 1.0096934 16.125172??? X36???? 1.0279473 19.108647??? X37???? 1.0463864 16.972994??? X38???? 1.0653421 22.869403??? X39???? 1.0842487 21.228874??? X40???? 1.1035309 25.509754??? X41???? 1.1230403 15.579367??? X42???? 1.1426743 21.259726??? X43???? 1.1626806 26.061262??? X44???? 1.1833831 21.918530??? X45???? 1.2045888 22.369094??? X46???? 1.2262981 21.480456??? X47???? 1.2481395 20.503543??? X48???? 1.2703019 27.717028??? X49???? 1.2929382 26.295449??? X50???? 1.3157745 28.271455??? X51???? 1.3390449 31.595651??? X52???? 1.3626052 26.188018??? X53???? 1.3863833 26.326999??? X54???? 1.4102701 26.902272??? X55???? 1.4343871 25.308764??? X56???? 1.4584666 23.789699??? X57???? 1.4831504 26.916504??? X58???? 1.5080384 32.921638??? X59???? 1.5331210 29.753267??? X60???? 1.5582794 29.567720??? X61???? 1.5832585 31.454097??? X62???? 1.6085002 26.602191??? X63???? 1.6339502 35.873728??? X64???? 1.6594560 34.222654??? X65???? 1.6851070 36.290959??? X66???? 1.7109757 31.623912??? X67???? 1.7368503 31.965520??? X68???? 1.7626750 41.490310??? X69???? 1.7883216 35.645934??? X70???? 1.8141292 35.639422??? X71???? 1.8405670 37.085608??? X72???? 1.8672313 44.812777??? X73???? 1.8939987 40.044602??? X74???? 1.9208222 37.834526??? X75???? 1.9478806 44.497335??? X76???? 1.9750195 39.839740??? X77???? 2.0024118 38.300529??? X78???? 2.0302205 52.116649??? X79???? 2.0581589 59.189047??? X80???? 2.0861536 51.559857??? X81???? 2.1141780 43.305779??? X82???? 2.1421791 47.950074??? X83???? 2.1703249 46.252149??? X84???? 2.1985953 47.536605??? X85???? 2.2266540 49.422466??? X86???? 2.2547762 44.577399??? X87???? 2.2827062 49.720523??? X88???? 2.3102098 47.138244??? X89???? 2.3379090 51.882832??? X90???? 2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
??????? [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Tue May 16 17:42:18 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Tue, 16 May 2023 15:42:18 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <1080156635.2542836.1684183472927@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1080156635.2542836.1684183472927@mail.yahoo.com>
Message-ID: <BN0PR08MB734111692272FE7631EFAD44C6799@BN0PR08MB7341.namprd08.prod.outlook.com>

The only spot you'll need to change the names for is when putting all of your dataframes in a list as that is based on the names you gave them in your script when reading in the data. In the function, you don't need to change the input to "dataframe1", and naming it that way could be confusing since you are applying the function to more than just dataframe1 (you're applying it to all 10 of your dataframes). I named the argument df to indicate that you should supply your dataframe as the input to the function, but you could name it anything you want. For example, you could call it "mydata" and define the function this way if you wanted to.

ExtractFirstMin<- function(mydata){
  mydata$abs_diff<- abs(mydata$x-1)
  min_rate<- mydata$y[which.min(mydata$abs_diff)]
  return(min_rate)
}

#The function has its own environment of variables that is separate from the global environment of variables you've defined in your script.
#When we supply one of your dataframes to the function, we are assigning that information to a variable in the function's environment called "mydata". Functions allow you to generalize your code so that you're not required to name your variables a certain way. Note here, we do assume that "mydata" has a "$x" and "$y" slot though.

#Without generalizing the code using a function, we'd need to copy and paste the code over and over again and make sure to change the name of the dataframe each time. This is very time consuming and error prone. Here's an example for the first 3 dataframes.

min_rate<- rep(NA_real_, 10) #initialize empty vector
df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]

df3$abs_diff<- abs(df3$x-1)
min_rate[3]<- df3$y[which.min(df3$abs_diff)]

print(min_rate)
#>  [1] 29.40269 32.21546 30.75330       NA       NA       NA       NA       NA
#>  [9]       NA       NA

#With the function defined we can run that it for each individual dataframe, which is less error prone than copying and pasting but still fairly repetitive
ExtractFirstMin(mydata = df1) # You can explicitly say "mydata ="
#> [1] 29.40269
ExtractFirstMin(df2) # Or equivalently it will be based on the order arguments when you defined the function. Since there is just one argument, then what you supply is assigned to "mydata"
#> [1] 32.21546
ExtractFirstMin(df3)
#> [1] 30.7533

# Rather than manually typing out to tun the function on eeach dataframe and bringing it together, we can instead use sapply.
# Sapply takes a list of inputs and a function as arguments. It then applies the function to every element in the list and returns a vector (i.e. goes through each dataframe in your list, applies the function to each one individually, and then records the result for each one in a single variable).
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907


________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Monday, May 15, 2023 4:44 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander and everyone,

I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:

dataframe1
dataframe2
dataframe3
dataframe4
dataframe5
dataframe6
dataframe7
dataframe8
dataframe9
dataframe10

Thus, using your example above, using the first dataframe listed there, would this become:

ExtractFirstMin<- function(dataframe1){
  dataframe1$abs_diff<- abs(dataframe1$x-1)
  min_rate<- dataframe1$y[which.min(dataframe1$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

# Apply function across list
sapply(df_list, ExtractFirstMin)


Am I doing this correctly?

Thanks, again!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Many thanks for sharing this! It was really helpful!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            y= rnorm(n = 10, mean = 30, sd = 1)))
  } # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

ExtractAvgMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])
  return(min_rate)
} #Average all y values that are closest to x=1

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907

sapply(df_list, ExtractAvgMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!

What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible?

Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Tue May 16 20:03:25 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Tue, 16 May 2023 18:03:25 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <558028105.2963024.1684255604973@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1080156635.2542836.1684183472927@mail.yahoo.com>
 <BN0PR08MB734111692272FE7631EFAD44C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <558028105.2963024.1684255604973@mail.yahoo.com>
Message-ID: <BN0PR08MB7341E962274D859C9465DE01C6799@BN0PR08MB7341.namprd08.prod.outlook.com>

sapply goes element by element in your list, where each element is one of your dataframes. So mydata starts out as dataframe1, then dataframe2, then dataframe3, etc. It is never all of them at once. It goes through the list sequentially. So, at the end of the sapply call, you have a vector of length 10 where the first element corresponds to the rate closest to x=1 in dataframe 1, and the tenth element corresponds to the rate closest to x=1 in dataframe 10. If your columns are not named x and y, then the function should be edited accordingly based on the names. It does assume the "x" and "y" have the same name across dataframes. For example, if x was actually "Time" and y was "Rate", you could use

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(Time = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            Rate= rnorm(n = 10, mean = 30, sd = 1)))
} # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$Time-1)
  min_rate<- df$Rate[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 12:46 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Wow, thank you so very much for taking the time to articulate this answer! It really gives a good understanding of what is going on at each stage in the coding!

And sorry if I missed this previously, but the object "mydata" is defined based on the incorporation of all dataframes? Since it is designed to swiftly obtain the first minimum at y = ~1 across each dataframe, "mydata" must take into account "dataframe1" to dataframe10", correct?

Also, the "x" is simply replaced with the name of the x-column and the "y" with the y-column name, if I understand correctly?

Again, sorry if I overlooked this, but that would be all, and thank you so very much, once again for your help and time with this! Much appreciated!

~Trav.~


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 11:42 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

The only spot you'll need to change the names for is when putting all of your dataframes in a list as that is based on the names you gave them in your script when reading in the data. In the function, you don't need to change the input to "dataframe1", and naming it that way could be confusing since you are applying the function to more than just dataframe1 (you're applying it to all 10 of your dataframes). I named the argument df to indicate that you should supply your dataframe as the input to the function, but you could name it anything you want. For example, you could call it "mydata" and define the function this way if you wanted to.

ExtractFirstMin<- function(mydata){
  mydata$abs_diff<- abs(mydata$x-1)
  min_rate<- mydata$y[which.min(mydata$abs_diff)]
  return(min_rate)
}

#The function has its own environment of variables that is separate from the global environment of variables you've defined in your script.
#When we supply one of your dataframes to the function, we are assigning that information to a variable in the function's environment called "mydata". Functions allow you to generalize your code so that you're not required to name your variables a certain way. Note here, we do assume that "mydata" has a "$x" and "$y" slot though.

#Without generalizing the code using a function, we'd need to copy and paste the code over and over again and make sure to change the name of the dataframe each time. This is very time consuming and error prone. Here's an example for the first 3 dataframes.

min_rate<- rep(NA_real_, 10) #initialize empty vector
df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]

df3$abs_diff<- abs(df3$x-1)
min_rate[3]<- df3$y[which.min(df3$abs_diff)]

print(min_rate)
#>  [1] 29.40269 32.21546 30.75330       NA       NA       NA       NA       NA
#>  [9]       NA       NA

#With the function defined we can run that it for each individual dataframe, which is less error prone than copying and pasting but still fairly repetitive
ExtractFirstMin(mydata = df1) # You can explicitly say "mydata ="
#> [1] 29.40269
ExtractFirstMin(df2) # Or equivalently it will be based on the order arguments when you defined the function. Since there is just one argument, then what you supply is assigned to "mydata"
#> [1] 32.21546
ExtractFirstMin(df3)
#> [1] 30.7533

# Rather than manually typing out to tun the function on eeach dataframe and bringing it together, we can instead use sapply.
# Sapply takes a list of inputs and a function as arguments. It then applies the function to every element in the list and returns a vector (i.e. goes through each dataframe in your list, applies the function to each one individually, and then records the result for each one in a single variable).
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907


________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Monday, May 15, 2023 4:44 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander and everyone,

I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:

dataframe1
dataframe2
dataframe3
dataframe4
dataframe5
dataframe6
dataframe7
dataframe8
dataframe9
dataframe10

Thus, using your example above, using the first dataframe listed there, would this become:

ExtractFirstMin<- function(dataframe1){
  dataframe1$abs_diff<- abs(dataframe1$x-1)
  min_rate<- dataframe1$y[which.min(dataframe1$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

# Apply function across list
sapply(df_list, ExtractFirstMin)


Am I doing this correctly?

Thanks, again!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Many thanks for sharing this! It was really helpful!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            y= rnorm(n = 10, mean = 30, sd = 1)))
  } # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

ExtractAvgMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])
  return(min_rate)
} #Average all y values that are closest to x=1

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907

sapply(df_list, ExtractAvgMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!

What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible?

Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Wed May 17 01:38:18 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Tue, 16 May 2023 23:38:18 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <838234018.3123333.1684274302143@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1080156635.2542836.1684183472927@mail.yahoo.com>
 <BN0PR08MB734111692272FE7631EFAD44C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <558028105.2963024.1684255604973@mail.yahoo.com>
 <BN0PR08MB7341E962274D859C9465DE01C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <838234018.3123333.1684274302143@mail.yahoo.com>
Message-ID: <BN0PR08MB734195EAE7DC0D493F73AB2BC6799@BN0PR08MB7341.namprd08.prod.outlook.com>

It's not clear to me why that would be happening. Are you getting that with your real data or the example data generated in the code I sent? The only reasons I can think of for that happening is if you're trying to access the zeroeth element of a vector which would require which.min(df2$abs_diff) to somehow evaluating to zero (which I don't see how it could) or if your dataframe is zero rows.
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 5:58:22 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,
Thank you so much, once again! Very, very helpful explanations.

I experimented with this method:

df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]


For the first dataframe, it correctly returned the first y-value where x = ~1. However, for dataframe2 to dataframe9, I strangely received: "numeric(0)".  Everything is correctly placed. It does not appear to be an error per se, but is there a way around that to avoid that message and see the correct value?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 2:03 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

sapply goes element by element in your list, where each element is one of your dataframes. So mydata starts out as dataframe1, then dataframe2, then dataframe3, etc. It is never all of them at once. It goes through the list sequentially. So, at the end of the sapply call, you have a vector of length 10 where the first element corresponds to the rate closest to x=1 in dataframe 1, and the tenth element corresponds to the rate closest to x=1 in dataframe 10. If your columns are not named x and y, then the function should be edited accordingly based on the names. It does assume the "x" and "y" have the same name across dataframes. For example, if x was actually "Time" and y was "Rate", you could use

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(Time = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            Rate= rnorm(n = 10, mean = 30, sd = 1)))
} # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$Time-1)
  min_rate<- df$Rate[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 12:46 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Wow, thank you so very much for taking the time to articulate this answer! It really gives a good understanding of what is going on at each stage in the coding!

And sorry if I missed this previously, but the object "mydata" is defined based on the incorporation of all dataframes? Since it is designed to swiftly obtain the first minimum at y = ~1 across each dataframe, "mydata" must take into account "dataframe1" to dataframe10", correct?

Also, the "x" is simply replaced with the name of the x-column and the "y" with the y-column name, if I understand correctly?

Again, sorry if I overlooked this, but that would be all, and thank you so very much, once again for your help and time with this! Much appreciated!

~Trav.~


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 11:42 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

The only spot you'll need to change the names for is when putting all of your dataframes in a list as that is based on the names you gave them in your script when reading in the data. In the function, you don't need to change the input to "dataframe1", and naming it that way could be confusing since you are applying the function to more than just dataframe1 (you're applying it to all 10 of your dataframes). I named the argument df to indicate that you should supply your dataframe as the input to the function, but you could name it anything you want. For example, you could call it "mydata" and define the function this way if you wanted to.

ExtractFirstMin<- function(mydata){
  mydata$abs_diff<- abs(mydata$x-1)
  min_rate<- mydata$y[which.min(mydata$abs_diff)]
  return(min_rate)
}

#The function has its own environment of variables that is separate from the global environment of variables you've defined in your script.
#When we supply one of your dataframes to the function, we are assigning that information to a variable in the function's environment called "mydata". Functions allow you to generalize your code so that you're not required to name your variables a certain way. Note here, we do assume that "mydata" has a "$x" and "$y" slot though.

#Without generalizing the code using a function, we'd need to copy and paste the code over and over again and make sure to change the name of the dataframe each time. This is very time consuming and error prone. Here's an example for the first 3 dataframes.

min_rate<- rep(NA_real_, 10) #initialize empty vector
df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]

df3$abs_diff<- abs(df3$x-1)
min_rate[3]<- df3$y[which.min(df3$abs_diff)]

print(min_rate)
#>  [1] 29.40269 32.21546 30.75330       NA       NA       NA       NA       NA
#>  [9]       NA       NA

#With the function defined we can run that it for each individual dataframe, which is less error prone than copying and pasting but still fairly repetitive
ExtractFirstMin(mydata = df1) # You can explicitly say "mydata ="
#> [1] 29.40269
ExtractFirstMin(df2) # Or equivalently it will be based on the order arguments when you defined the function. Since there is just one argument, then what you supply is assigned to "mydata"
#> [1] 32.21546
ExtractFirstMin(df3)
#> [1] 30.7533

# Rather than manually typing out to tun the function on eeach dataframe and bringing it together, we can instead use sapply.
# Sapply takes a list of inputs and a function as arguments. It then applies the function to every element in the list and returns a vector (i.e. goes through each dataframe in your list, applies the function to each one individually, and then records the result for each one in a single variable).
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907


________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Monday, May 15, 2023 4:44 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander and everyone,

I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:

dataframe1
dataframe2
dataframe3
dataframe4
dataframe5
dataframe6
dataframe7
dataframe8
dataframe9
dataframe10

Thus, using your example above, using the first dataframe listed there, would this become:

ExtractFirstMin<- function(dataframe1){
  dataframe1$abs_diff<- abs(dataframe1$x-1)
  min_rate<- dataframe1$y[which.min(dataframe1$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

# Apply function across list
sapply(df_list, ExtractFirstMin)


Am I doing this correctly?

Thanks, again!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Many thanks for sharing this! It was really helpful!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            y= rnorm(n = 10, mean = 30, sd = 1)))
  } # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

ExtractAvgMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])
  return(min_rate)
} #Average all y values that are closest to x=1

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907

sapply(df_list, ExtractAvgMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!

What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible?

Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From @|||ch @end|ng |rom u@|@edu  Wed May 17 04:24:07 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Wed, 17 May 2023 02:24:07 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <2099361082.3183274.1684283389595@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1080156635.2542836.1684183472927@mail.yahoo.com>
 <BN0PR08MB734111692272FE7631EFAD44C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <558028105.2963024.1684255604973@mail.yahoo.com>
 <BN0PR08MB7341E962274D859C9465DE01C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <838234018.3123333.1684274302143@mail.yahoo.com>
 <BN0PR08MB734195EAE7DC0D493F73AB2BC6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <2099361082.3183274.1684283389595@mail.yahoo.com>
Message-ID: <BN0PR08MB7341E756C05ACB9F98519523C67E9@BN0PR08MB7341.namprd08.prod.outlook.com>

I believe you didn't clear your environment and that's why df1 works. All should evaluate to "numeric(0) with the current code. You call df2$abs_diff, but you never defined that variable. You assigned that result to an object called diff2 which is not used anywhere else in your code. If you type in df2$abs_diff, you'll see it evaluates to NULL and that caries through the rest of your code. numeric(0) means that it's a variable of type numeric but it's empty (zero in length).

set.seed(5)
df2<- data.frame(em= rnorm(10), pct=rnorm(10))

diff2 <- abs(df2$em-1) #You defined diff2
df2$abs_diff #This was never defined so it evalues to NULL
#> NULL

which.min(df2$abs_diff) #can't find position of min since df2$abs_diff was never defined
#> integer(0)

df2$pct[which.min(df2$abs_diff)] #cannot subset df2$pct since which.min(df2$abs_diff) evaluates to integer(0)
#> numeric(0)

________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 8:29 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

I am receiving that for my real data, which is, indeed, odd. It works just fine with my very first dataframe, but for all other dataframes, it returns "numeric(0)". I did the following to organize each dataframe accordingly (note that I renamed my dataframes to "df1" through to "df10" for simplicity):

diff1 <- abs(df1$em-1)
w1 <- df1$pct[which.min(df1$abs_diff)]

diff2 <- abs(df2$em-1)
w2 <- df2$pct[which.min(df2$abs_diff)]

diff3 <- abs(df3$em-1)
w3 <- df3$pct[which.min(df3$abs_diff)]

diff4 <- abs(df4$em-1)
w4 <- df4$pct[which.min(df4$abs_diff)]

diff5 <- abs(df5$em-1)
w5 <- df5$pct[which.min(df5$abs_diff)]

diff6 <- abs(df6$em-1)
w6 <- df6$pct[which.min(df6$abs_diff)]

diff7 <- abs(df7$em-1)
w7 <- df7$pct[which.min(df7$abs_diff)]

diff8 <- abs(df8$em-1)
w8 <- df8$pct[which.min(df8$abs_diff)]

diff9 <- abs(df9$em-1)
w9 <- df9$pct[which.min(df9$abs_diff)]

diff10 <- abs(df10$em-1)
w10 <- df10$pct[which.min(df10$abs_diff)]

This is what object "df2" looks like (the first 21 rows are displayed - there are 140 rows in total). All dataframes are structured the same way, including "df1" (which, as mentioned previously, worked just fine). All begin with "0.000000000" in the first row. "em" is my x-column name, and "pct" is my y-column name, as shown in the image below:

[df2.jpg]

What could make the other dataframes so different from "df1" to cause "numeric(0)"? Essentially, why would "df1" be fine, and not the other 9 dataframes? Unless my code for the other dataframes is flawed somehow?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Sent: Tue, May 16, 2023 7:38 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

It's not clear to me why that would be happening. Are you getting that with your real data or the example data generated in the code I sent? The only reasons I can think of for that happening is if you're trying to access the zeroeth element of a vector which would require which.min(df2$abs_diff) to somehow evaluating to zero (which I don't see how it could) or if your dataframe is zero rows.
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 5:58:22 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,
Thank you so much, once again! Very, very helpful explanations.

I experimented with this method:

df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]


For the first dataframe, it correctly returned the first y-value where x = ~1. However, for dataframe2 to dataframe9, I strangely received: "numeric(0)".  Everything is correctly placed. It does not appear to be an error per se, but is there a way around that to avoid that message and see the correct value?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 2:03 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

sapply goes element by element in your list, where each element is one of your dataframes. So mydata starts out as dataframe1, then dataframe2, then dataframe3, etc. It is never all of them at once. It goes through the list sequentially. So, at the end of the sapply call, you have a vector of length 10 where the first element corresponds to the rate closest to x=1 in dataframe 1, and the tenth element corresponds to the rate closest to x=1 in dataframe 10. If your columns are not named x and y, then the function should be edited accordingly based on the names. It does assume the "x" and "y" have the same name across dataframes. For example, if x was actually "Time" and y was "Rate", you could use

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(Time = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            Rate= rnorm(n = 10, mean = 30, sd = 1)))
} # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$Time-1)
  min_rate<- df$Rate[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 12:46 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Wow, thank you so very much for taking the time to articulate this answer! It really gives a good understanding of what is going on at each stage in the coding!

And sorry if I missed this previously, but the object "mydata" is defined based on the incorporation of all dataframes? Since it is designed to swiftly obtain the first minimum at y = ~1 across each dataframe, "mydata" must take into account "dataframe1" to dataframe10", correct?

Also, the "x" is simply replaced with the name of the x-column and the "y" with the y-column name, if I understand correctly?

Again, sorry if I overlooked this, but that would be all, and thank you so very much, once again for your help and time with this! Much appreciated!

~Trav.~


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 11:42 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

The only spot you'll need to change the names for is when putting all of your dataframes in a list as that is based on the names you gave them in your script when reading in the data. In the function, you don't need to change the input to "dataframe1", and naming it that way could be confusing since you are applying the function to more than just dataframe1 (you're applying it to all 10 of your dataframes). I named the argument df to indicate that you should supply your dataframe as the input to the function, but you could name it anything you want. For example, you could call it "mydata" and define the function this way if you wanted to.

ExtractFirstMin<- function(mydata){
  mydata$abs_diff<- abs(mydata$x-1)
  min_rate<- mydata$y[which.min(mydata$abs_diff)]
  return(min_rate)
}

#The function has its own environment of variables that is separate from the global environment of variables you've defined in your script.
#When we supply one of your dataframes to the function, we are assigning that information to a variable in the function's environment called "mydata". Functions allow you to generalize your code so that you're not required to name your variables a certain way. Note here, we do assume that "mydata" has a "$x" and "$y" slot though.

#Without generalizing the code using a function, we'd need to copy and paste the code over and over again and make sure to change the name of the dataframe each time. This is very time consuming and error prone. Here's an example for the first 3 dataframes.

min_rate<- rep(NA_real_, 10) #initialize empty vector
df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]

df3$abs_diff<- abs(df3$x-1)
min_rate[3]<- df3$y[which.min(df3$abs_diff)]

print(min_rate)
#>  [1] 29.40269 32.21546 30.75330       NA       NA       NA       NA       NA
#>  [9]       NA       NA

#With the function defined we can run that it for each individual dataframe, which is less error prone than copying and pasting but still fairly repetitive
ExtractFirstMin(mydata = df1) # You can explicitly say "mydata ="
#> [1] 29.40269
ExtractFirstMin(df2) # Or equivalently it will be based on the order arguments when you defined the function. Since there is just one argument, then what you supply is assigned to "mydata"
#> [1] 32.21546
ExtractFirstMin(df3)
#> [1] 30.7533

# Rather than manually typing out to tun the function on eeach dataframe and bringing it together, we can instead use sapply.
# Sapply takes a list of inputs and a function as arguments. It then applies the function to every element in the list and returns a vector (i.e. goes through each dataframe in your list, applies the function to each one individually, and then records the result for each one in a single variable).
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907


________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Monday, May 15, 2023 4:44 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander and everyone,

I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:

dataframe1
dataframe2
dataframe3
dataframe4
dataframe5
dataframe6
dataframe7
dataframe8
dataframe9
dataframe10

Thus, using your example above, using the first dataframe listed there, would this become:

ExtractFirstMin<- function(dataframe1){
  dataframe1$abs_diff<- abs(dataframe1$x-1)
  min_rate<- dataframe1$y[which.min(dataframe1$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

# Apply function across list
sapply(df_list, ExtractFirstMin)


Am I doing this correctly?

Thanks, again!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Many thanks for sharing this! It was really helpful!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            y= rnorm(n = 10, mean = 30, sd = 1)))
  } # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

ExtractAvgMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])
  return(min_rate)
} #Average all y values that are closest to x=1

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907

sapply(df_list, ExtractAvgMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!

What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible?

Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20230517/ad2ac98f/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: df2.jpg
Type: image/jpeg
Size: 67856 bytes
Desc: df2.jpg
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20230517/ad2ac98f/attachment.jpg>

From @|||ch @end|ng |rom u@|@edu  Wed May 17 16:16:44 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Wed, 17 May 2023 14:16:44 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <555613555.3250293.1684293215264@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1080156635.2542836.1684183472927@mail.yahoo.com>
 <BN0PR08MB734111692272FE7631EFAD44C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <558028105.2963024.1684255604973@mail.yahoo.com>
 <BN0PR08MB7341E962274D859C9465DE01C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <838234018.3123333.1684274302143@mail.yahoo.com>
 <BN0PR08MB734195EAE7DC0D493F73AB2BC6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <2099361082.3183274.16 84283389595@mail.yahoo.com>
 <BN0PR08MB7341E756C05ACB9F98519523C67E9@BN0PR08MB7341.namprd08.prod.outlook.com>
 <555613555.3250293.1684293215264@mail.yahoo.com>
Message-ID: <BN0PR08MB73419EC122A08DE4A96D8F72C67E9@BN0PR08MB7341.namprd08.prod.outlook.com>

Awesome, glad you were able to get the result you needed. Just to be clear though, you shouldn't need to manually copy the code "df$pct[which.min(df$abs_diff)]" repeatedly for each dataframe. That I sent just to explain what internally was happening when using sapply and the function. If you replace "$x" with "$em" and $y" with "$pct" you can automatically iterate through as many dataframes as you want as long as they are in df_list.

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$em-1)
  min_rate<- df$pct[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
w<- sapply(df_list, ExtractFirstMin)
w
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 11:13 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Oh, wow...you are absolutely right - I cannot believe that I did not notice that previously! Thank you so much, yet again, including for the insight on what "numeric(0)" signifies! Indeed, it all works just fine now!

I am now able to flexibly achieve the goal of deriving the range of these values across the 10 dataframes using the "range" function!

I cannot thank you enough, including for your tireless efforts to explain everything step-by-step throughout all of this, though I do apologize for the time spent on this!



-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 10:24 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I believe you didn't clear your environment and that's why df1 works. All should evaluate to "numeric(0) with the current code. You call df2$abs_diff, but you never defined that variable. You assigned that result to an object called diff2 which is not used anywhere else in your code. If you type in df2$abs_diff, you'll see it evaluates to NULL and that caries through the rest of your code. numeric(0) means that it's a variable of type numeric but it's empty (zero in length).

set.seed(5)
df2<- data.frame(em= rnorm(10), pct=rnorm(10))

diff2 <- abs(df2$em-1) #You defined diff2
df2$abs_diff #This was never defined so it evalues to NULL
#> NULL

which.min(df2$abs_diff) #can't find position of min since df2$abs_diff was never defined
#> integer(0)

df2$pct[which.min(df2$abs_diff)] #cannot subset df2$pct since which.min(df2$abs_diff) evaluates to integer(0)
#> numeric(0)

________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 8:29 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

I am receiving that for my real data, which is, indeed, odd. It works just fine with my very first dataframe, but for all other dataframes, it returns "numeric(0)". I did the following to organize each dataframe accordingly (note that I renamed my dataframes to "df1" through to "df10" for simplicity):

diff1 <- abs(df1$em-1)
w1 <- df1$pct[which.min(df1$abs_diff)]

diff2 <- abs(df2$em-1)
w2 <- df2$pct[which.min(df2$abs_diff)]

diff3 <- abs(df3$em-1)
w3 <- df3$pct[which.min(df3$abs_diff)]

diff4 <- abs(df4$em-1)
w4 <- df4$pct[which.min(df4$abs_diff)]

diff5 <- abs(df5$em-1)
w5 <- df5$pct[which.min(df5$abs_diff)]

diff6 <- abs(df6$em-1)
w6 <- df6$pct[which.min(df6$abs_diff)]

diff7 <- abs(df7$em-1)
w7 <- df7$pct[which.min(df7$abs_diff)]

diff8 <- abs(df8$em-1)
w8 <- df8$pct[which.min(df8$abs_diff)]

diff9 <- abs(df9$em-1)
w9 <- df9$pct[which.min(df9$abs_diff)]

diff10 <- abs(df10$em-1)
w10 <- df10$pct[which.min(df10$abs_diff)]

This is what object "df2" looks like (the first 21 rows are displayed - there are 140 rows in total). All dataframes are structured the same way, including "df1" (which, as mentioned previously, worked just fine). All begin with "0.000000000" in the first row. "em" is my x-column name, and "pct" is my y-column name, as shown in the image below:

[df2.jpg]

What could make the other dataframes so different from "df1" to cause "numeric(0)"? Essentially, why would "df1" be fine, and not the other 9 dataframes? Unless my code for the other dataframes is flawed somehow?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Sent: Tue, May 16, 2023 7:38 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

It's not clear to me why that would be happening. Are you getting that with your real data or the example data generated in the code I sent? The only reasons I can think of for that happening is if you're trying to access the zeroeth element of a vector which would require which.min(df2$abs_diff) to somehow evaluating to zero (which I don't see how it could) or if your dataframe is zero rows.
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 5:58:22 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,
Thank you so much, once again! Very, very helpful explanations.

I experimented with this method:

df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]


For the first dataframe, it correctly returned the first y-value where x = ~1. However, for dataframe2 to dataframe9, I strangely received: "numeric(0)".  Everything is correctly placed. It does not appear to be an error per se, but is there a way around that to avoid that message and see the correct value?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 2:03 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

sapply goes element by element in your list, where each element is one of your dataframes. So mydata starts out as dataframe1, then dataframe2, then dataframe3, etc. It is never all of them at once. It goes through the list sequentially. So, at the end of the sapply call, you have a vector of length 10 where the first element corresponds to the rate closest to x=1 in dataframe 1, and the tenth element corresponds to the rate closest to x=1 in dataframe 10. If your columns are not named x and y, then the function should be edited accordingly based on the names. It does assume the "x" and "y" have the same name across dataframes. For example, if x was actually "Time" and y was "Rate", you could use

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(Time = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            Rate= rnorm(n = 10, mean = 30, sd = 1)))
} # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$Time-1)
  min_rate<- df$Rate[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 12:46 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Wow, thank you so very much for taking the time to articulate this answer! It really gives a good understanding of what is going on at each stage in the coding!

And sorry if I missed this previously, but the object "mydata" is defined based on the incorporation of all dataframes? Since it is designed to swiftly obtain the first minimum at y = ~1 across each dataframe, "mydata" must take into account "dataframe1" to dataframe10", correct?

Also, the "x" is simply replaced with the name of the x-column and the "y" with the y-column name, if I understand correctly?

Again, sorry if I overlooked this, but that would be all, and thank you so very much, once again for your help and time with this! Much appreciated!

~Trav.~


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 11:42 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

The only spot you'll need to change the names for is when putting all of your dataframes in a list as that is based on the names you gave them in your script when reading in the data. In the function, you don't need to change the input to "dataframe1", and naming it that way could be confusing since you are applying the function to more than just dataframe1 (you're applying it to all 10 of your dataframes). I named the argument df to indicate that you should supply your dataframe as the input to the function, but you could name it anything you want. For example, you could call it "mydata" and define the function this way if you wanted to.

ExtractFirstMin<- function(mydata){
  mydata$abs_diff<- abs(mydata$x-1)
  min_rate<- mydata$y[which.min(mydata$abs_diff)]
  return(min_rate)
}

#The function has its own environment of variables that is separate from the global environment of variables you've defined in your script.
#When we supply one of your dataframes to the function, we are assigning that information to a variable in the function's environment called "mydata". Functions allow you to generalize your code so that you're not required to name your variables a certain way. Note here, we do assume that "mydata" has a "$x" and "$y" slot though.

#Without generalizing the code using a function, we'd need to copy and paste the code over and over again and make sure to change the name of the dataframe each time. This is very time consuming and error prone. Here's an example for the first 3 dataframes.

min_rate<- rep(NA_real_, 10) #initialize empty vector
df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]

df3$abs_diff<- abs(df3$x-1)
min_rate[3]<- df3$y[which.min(df3$abs_diff)]

print(min_rate)
#>  [1] 29.40269 32.21546 30.75330       NA       NA       NA       NA       NA
#>  [9]       NA       NA

#With the function defined we can run that it for each individual dataframe, which is less error prone than copying and pasting but still fairly repetitive
ExtractFirstMin(mydata = df1) # You can explicitly say "mydata ="
#> [1] 29.40269
ExtractFirstMin(df2) # Or equivalently it will be based on the order arguments when you defined the function. Since there is just one argument, then what you supply is assigned to "mydata"
#> [1] 32.21546
ExtractFirstMin(df3)
#> [1] 30.7533

# Rather than manually typing out to tun the function on eeach dataframe and bringing it together, we can instead use sapply.
# Sapply takes a list of inputs and a function as arguments. It then applies the function to every element in the list and returns a vector (i.e. goes through each dataframe in your list, applies the function to each one individually, and then records the result for each one in a single variable).
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907


________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Monday, May 15, 2023 4:44 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander and everyone,

I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:

dataframe1
dataframe2
dataframe3
dataframe4
dataframe5
dataframe6
dataframe7
dataframe8
dataframe9
dataframe10

Thus, using your example above, using the first dataframe listed there, would this become:

ExtractFirstMin<- function(dataframe1){
  dataframe1$abs_diff<- abs(dataframe1$x-1)
  min_rate<- dataframe1$y[which.min(dataframe1$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

# Apply function across list
sapply(df_list, ExtractFirstMin)


Am I doing this correctly?

Thanks, again!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Many thanks for sharing this! It was really helpful!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            y= rnorm(n = 10, mean = 30, sd = 1)))
  } # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

ExtractAvgMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])
  return(min_rate)
} #Average all y values that are closest to x=1

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907

sapply(df_list, ExtractAvgMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!

What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible?

Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From @@mue||er @end|ng |rom |wu@de  Wed May 17 17:50:36 2023
From: @@mue||er @end|ng |rom |wu@de (=?iso-8859-1?Q?Andr=E9_M=FCller?=)
Date: Wed, 17 May 2023 15:50:36 +0000
Subject: [R-sig-Geo] Handling 3D geospatial (building) data in R
Message-ID: <6daa26f1a5a6460687be9558c7f162fb@iwu.de>

Dear all,

recently, I finished a study on clustering building blocks and combining blocks to city districts of similar urban morphology.
The basis was 3D CityGML building data and additional 2d cadastral data from Germany and the application of unsupervised (and supervised) machine learning algorithms to this GIS data.
After importing a CityGML data set to a PostgreSQL/PostGIS database via 3DCity-Importer-Exporter (https://github.com/3dcitydb) and pre-processing it, the dataset consisted of 2D building footprint polygons and additional variables, e.g. the building height and the type a the roof. Some data processing was done directly in PostGIS, but the major part using R/PostGIS database connections (packages DBI, RPostgres and RPostgreSQL) and r packages for spatial analysis (packages sf, sp, foot, lwgeom) and non-spatial data analysis (stats, cluster, fcp, klaR)


However, at the moment I am looking for a possibility to derive some additional information from the 3D representations of the buildings by analyzing the surfaces (polygons or multipolygons) and solids.
PostGIS itself has at least a basic function for 3d area calculation: https://postgis.net/docs/ST_3DArea.html. Commercial software like FME from SAFE is allowing for CityGML reading, writing and analysis. ESRI delivers (commercial) possibilities for 3D data analyses as well.
Do you know packages which can handle 3D geospatial data in R or do you have any other suggestions on free / open source solutions which easily can be integrated into an R based data analysis?


Any feedback is appreciated.
Many thanks in advance an best regards
Andr?

***********************************************
Andr? M?ller

IWU - Institut Wohnen und Umwelt GmbH
Rheinstra?e 65
64295 Darmstadt

Institute for Housing and Environment -
Research institution of the State of Hesse and the City of Darmstadt

Telefon: +49 6151 2904-18
E-Mail: a.mueller at iwu.de<mailto:a.mueller at iwu.de>
Internet: www.iwu.de<http://www.iwu.de/>

Registergericht Darmstadt HRB 1649
Gesch?ftsf?hrerin: Dr. Monika Meyer
***********************************************
EG2050:E4Q<https://www.iwu.de/forschung/energie/e4q/> - Einbindung erneuerbarer Energietr?ger in
die Energieversorgung vernetzter Quartiere (Projektseite)
Ergebnisbrosch?re E4Q<https://www.iwu.de/fileadmin/publikationen/energie/2022_IWU-TUD_MuellerEtKoert_E4Q-Ergebnisbroschuere.pdf>

Mein Profil auf researchgate.net<https://www.researchgate.net/profile/Andre-Mueller-4>

IWU-Newsletter Energie<https://www.iwu.de/aktuell/newsletter/>
***********************************************
[cid:image001.png at 01D91392.362026D0]


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20230517/d90138b0/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 6124 bytes
Desc: image001.png
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20230517/d90138b0/attachment.png>

From @|||ch @end|ng |rom u@|@edu  Thu May 18 16:23:58 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Thu, 18 May 2023 14:23:58 +0000
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at
 specific x value across several time series in R
In-Reply-To: <1626241313.3247434.1684353383224@mail.yahoo.com>
References: <1461120448.6176960.1683651671652.ref@mail.yahoo.com>
 <1461120448.6176960.1683651671652@mail.yahoo.com>
 <BN0PR08MB734177C66E72426E264B9FC4C6769@BN0PR08MB7341.namprd08.prod.outlook.com>
 <925605636.359028.1683720789392@mail.yahoo.com>
 <BN0PR08MB7341753AF82EDDCA4BB016A5C6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1699277172.546804.1683740410098@mail.yahoo.com>
 <BN0PR08MB73415442901A190A199E5B3FC6779@BN0PR08MB7341.namprd08.prod.outlook.com>
 <699694933.809963.1683778632082@mail.yahoo.com>
 <BN0PR08MB73417B17D96211030BC2D722C6749@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1080156635.2542836.1684183472927@mail.yahoo.com>
 <BN0PR08MB734111692272FE7631EFAD44C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <558028105.2963024.1684255604973@mail.yahoo.com>
 <BN0PR08MB7341E962274D859C9465DE01C6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <838234018.3123333.1684274302143@mail.yahoo.com>
 <BN0PR08MB734195EAE7DC0D493F73AB2BC6799@BN0PR08MB7341.namprd08.prod.outlook.com>
 <2099361082.3183274.16 84283389595@mail.yahoo.com>
 <BN0PR08MB7341E756C05ACB9F98519523C67E9@BN0PR08MB7341.namprd08.prod.outlook.com>
 <555613555.3250293.1684293215264@mail.yahoo.com>
 <BN0PR08MB73419EC122A08DE4A96D8F72C67E9@BN0PR08MB7341.namprd08.prod.outlook.com>
 <1626241313.3247434.1684353383224@mail.yahoo.com>
Message-ID: <BN0PR08MB73419B377D0F00EC2A22879FC67F9@BN0PR08MB7341.namprd08.prod.outlook.com>

"df" is not an object, but is an input to a function (known as a function argument). If you run the code for the "ExtractFirstMin" function definition with a clear environment you'll notice there's no error event though there's no object df. What will happen after you run the code is a new variable called "ExtactFirstMin" will be defined. This is new variable in your environent is actually a function. It works just like any built in R function such as "mean", "range", "min", etc, but it only exists because you defined it. When you supply an input to the function it is substituted for "df" in that function code. When you use "sapply" you input a list of all your data frames as well as the function to apply to them. So when you do sapply(df_list, ExtactFirstMin), you are applying that ExtractFirstMin function across all of your dataframes.  You should only need to edit the right side of the following line of code to put your dataframes in the list by substituting the names of your dataframes:

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

You do not need the code block to create 10 data frames. Since I don't have your data, I needed to generate data with a similar structure to run the code on, but you can run the code on your real data.

Here are some resources on functions and iteration that may help clarify a few things.
https://r4ds.had.co.nz/functions.html
https://r-coder.com/sapply-function-r/

________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 17, 2023 3:56 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Yes, you're right - that approach would be much faster and much less subject to error. The method that I was using worked as intended, but I am more than happy to try to learn this arguably more effective way. My only question in that regard is the defining of the object "df" in:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$em-1)
  min_rate<- df$pct[which.min(df$abs_diff)]
  return(min_rate)
}

Is object "df" in your example above coming from this?

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(Time = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            Rate= rnorm(n = 10, mean = 30, sd = 1)))
} # Create 10 Data Frames

If so, how would I approach placing all 10 of my dataframes (i.e. df1, df2, df3, df4...df10) in that command?

Thanks, again, and sorry if I missed this previously in your explanation! In any case, at least I am able to obtain the results that I was looking for!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 17, 2023 10:16 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Awesome, glad you were able to get the result you needed. Just to be clear though, you shouldn't need to manually copy the code "df$pct[which.min(df$abs_diff)]" repeatedly for each dataframe. That I sent just to explain what internally was happening when using sapply and the function. If you replace "$x" with "$em" and $y" with "$pct" you can automatically iterate through as many dataframes as you want as long as they are in df_list.

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$em-1)
  min_rate<- df$pct[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
w<- sapply(df_list, ExtractFirstMin)
w
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 11:13 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Oh, wow...you are absolutely right - I cannot believe that I did not notice that previously! Thank you so much, yet again, including for the insight on what "numeric(0)" signifies! Indeed, it all works just fine now!

I am now able to flexibly achieve the goal of deriving the range of these values across the 10 dataframes using the "range" function!

I cannot thank you enough, including for your tireless efforts to explain everything step-by-step throughout all of this, though I do apologize for the time spent on this!



-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 10:24 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I believe you didn't clear your environment and that's why df1 works. All should evaluate to "numeric(0) with the current code. You call df2$abs_diff, but you never defined that variable. You assigned that result to an object called diff2 which is not used anywhere else in your code. If you type in df2$abs_diff, you'll see it evaluates to NULL and that caries through the rest of your code. numeric(0) means that it's a variable of type numeric but it's empty (zero in length).

set.seed(5)
df2<- data.frame(em= rnorm(10), pct=rnorm(10))

diff2 <- abs(df2$em-1) #You defined diff2
df2$abs_diff #This was never defined so it evalues to NULL
#> NULL

which.min(df2$abs_diff) #can't find position of min since df2$abs_diff was never defined
#> integer(0)

df2$pct[which.min(df2$abs_diff)] #cannot subset df2$pct since which.min(df2$abs_diff) evaluates to integer(0)
#> numeric(0)

________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 8:29 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

I am receiving that for my real data, which is, indeed, odd. It works just fine with my very first dataframe, but for all other dataframes, it returns "numeric(0)". I did the following to organize each dataframe accordingly (note that I renamed my dataframes to "df1" through to "df10" for simplicity):

diff1 <- abs(df1$em-1)
w1 <- df1$pct[which.min(df1$abs_diff)]

diff2 <- abs(df2$em-1)
w2 <- df2$pct[which.min(df2$abs_diff)]

diff3 <- abs(df3$em-1)
w3 <- df3$pct[which.min(df3$abs_diff)]

diff4 <- abs(df4$em-1)
w4 <- df4$pct[which.min(df4$abs_diff)]

diff5 <- abs(df5$em-1)
w5 <- df5$pct[which.min(df5$abs_diff)]

diff6 <- abs(df6$em-1)
w6 <- df6$pct[which.min(df6$abs_diff)]

diff7 <- abs(df7$em-1)
w7 <- df7$pct[which.min(df7$abs_diff)]

diff8 <- abs(df8$em-1)
w8 <- df8$pct[which.min(df8$abs_diff)]

diff9 <- abs(df9$em-1)
w9 <- df9$pct[which.min(df9$abs_diff)]

diff10 <- abs(df10$em-1)
w10 <- df10$pct[which.min(df10$abs_diff)]

This is what object "df2" looks like (the first 21 rows are displayed - there are 140 rows in total). All dataframes are structured the same way, including "df1" (which, as mentioned previously, worked just fine). All begin with "0.000000000" in the first row. "em" is my x-column name, and "pct" is my y-column name, as shown in the image below:

[df2.jpg]

What could make the other dataframes so different from "df1" to cause "numeric(0)"? Essentially, why would "df1" be fine, and not the other 9 dataframes? Unless my code for the other dataframes is flawed somehow?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Sent: Tue, May 16, 2023 7:38 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

It's not clear to me why that would be happening. Are you getting that with your real data or the example data generated in the code I sent? The only reasons I can think of for that happening is if you're trying to access the zeroeth element of a vector which would require which.min(df2$abs_diff) to somehow evaluating to zero (which I don't see how it could) or if your dataframe is zero rows.
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 5:58:22 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,
Thank you so much, once again! Very, very helpful explanations.

I experimented with this method:

df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]


For the first dataframe, it correctly returned the first y-value where x = ~1. However, for dataframe2 to dataframe9, I strangely received: "numeric(0)".  Everything is correctly placed. It does not appear to be an error per se, but is there a way around that to avoid that message and see the correct value?

Thanks, again,

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 2:03 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

sapply goes element by element in your list, where each element is one of your dataframes. So mydata starts out as dataframe1, then dataframe2, then dataframe3, etc. It is never all of them at once. It goes through the list sequentially. So, at the end of the sapply call, you have a vector of length 10 where the first element corresponds to the rate closest to x=1 in dataframe 1, and the tenth element corresponds to the rate closest to x=1 in dataframe 10. If your columns are not named x and y, then the function should be edited accordingly based on the names. It does assume the "x" and "y" have the same name across dataframes. For example, if x was actually "Time" and y was "Rate", you could use

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(Time = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            Rate= rnorm(n = 10, mean = 30, sd = 1)))
} # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$Time-1)
  min_rate<- df$Rate[which.min(df$abs_diff)]
  return(min_rate)
}

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Tuesday, May 16, 2023 12:46 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Wow, thank you so very much for taking the time to articulate this answer! It really gives a good understanding of what is going on at each stage in the coding!

And sorry if I missed this previously, but the object "mydata" is defined based on the incorporation of all dataframes? Since it is designed to swiftly obtain the first minimum at y = ~1 across each dataframe, "mydata" must take into account "dataframe1" to dataframe10", correct?

Also, the "x" is simply replaced with the name of the x-column and the "y" with the y-column name, if I understand correctly?

Again, sorry if I overlooked this, but that would be all, and thank you so very much, once again for your help and time with this! Much appreciated!

~Trav.~


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 16, 2023 11:42 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

The only spot you'll need to change the names for is when putting all of your dataframes in a list as that is based on the names you gave them in your script when reading in the data. In the function, you don't need to change the input to "dataframe1", and naming it that way could be confusing since you are applying the function to more than just dataframe1 (you're applying it to all 10 of your dataframes). I named the argument df to indicate that you should supply your dataframe as the input to the function, but you could name it anything you want. For example, you could call it "mydata" and define the function this way if you wanted to.

ExtractFirstMin<- function(mydata){
  mydata$abs_diff<- abs(mydata$x-1)
  min_rate<- mydata$y[which.min(mydata$abs_diff)]
  return(min_rate)
}

#The function has its own environment of variables that is separate from the global environment of variables you've defined in your script.
#When we supply one of your dataframes to the function, we are assigning that information to a variable in the function's environment called "mydata". Functions allow you to generalize your code so that you're not required to name your variables a certain way. Note here, we do assume that "mydata" has a "$x" and "$y" slot though.

#Without generalizing the code using a function, we'd need to copy and paste the code over and over again and make sure to change the name of the dataframe each time. This is very time consuming and error prone. Here's an example for the first 3 dataframes.

min_rate<- rep(NA_real_, 10) #initialize empty vector
df1$abs_diff<- abs(df1$x-1)
min_rate[1]<- df1$y[which.min(df1$abs_diff)]

df2$abs_diff<- abs(df2$x-1)
min_rate[2]<- df2$y[which.min(df2$abs_diff)]

df3$abs_diff<- abs(df3$x-1)
min_rate[3]<- df3$y[which.min(df3$abs_diff)]

print(min_rate)
#>  [1] 29.40269 32.21546 30.75330       NA       NA       NA       NA       NA
#>  [9]       NA       NA

#With the function defined we can run that it for each individual dataframe, which is less error prone than copying and pasting but still fairly repetitive
ExtractFirstMin(mydata = df1) # You can explicitly say "mydata ="
#> [1] 29.40269
ExtractFirstMin(df2) # Or equivalently it will be based on the order arguments when you defined the function. Since there is just one argument, then what you supply is assigned to "mydata"
#> [1] 32.21546
ExtractFirstMin(df3)
#> [1] 30.7533

# Rather than manually typing out to tun the function on eeach dataframe and bringing it together, we can instead use sapply.
# Sapply takes a list of inputs and a function as arguments. It then applies the function to every element in the list and returns a vector (i.e. goes through each dataframe in your list, applies the function to each one individually, and then records the result for each one in a single variable).
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907


________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Monday, May 15, 2023 4:44 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander and everyone,

I hope that all is well! Just to follow up with this, I recently was able to try the following code that you had kindly previously shared:

ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

Just to be clear, do I simply replace the "df" in that code with the name of my individual dataframes? For example, here is the name of my 10 dataframes, which are successfully placed in a list (i.e. df_list), as you showed previously:

dataframe1
dataframe2
dataframe3
dataframe4
dataframe5
dataframe6
dataframe7
dataframe8
dataframe9
dataframe10

Thus, using your example above, using the first dataframe listed there, would this become:

ExtractFirstMin<- function(dataframe1){
  dataframe1$abs_diff<- abs(dataframe1$x-1)
  min_rate<- dataframe1$y[which.min(dataframe1$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

df_list<- list(dataframe1, dataframe2, dataframe3, dataframe4, dataframe5, dataframe6, dataframe7, dataframe8, dataframe9, dataframe10)

# Apply function across list
sapply(df_list, ExtractFirstMin)


Am I doing this correctly?

Thanks, again!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thu, May 11, 2023 1:48 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Sure thing. Glad I could help!
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Thursday, May 11, 2023 12:17:12 AM
To: Alexander Ilich <ailich at usf.edu>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Many thanks for sharing this! It was really helpful!


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 2:05 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

One way to do this would be to put all your dataframes in a list, make one of the code implementation I put earlier into a function, and then use sapply to apply it across all the data frames.

#Generate data
set.seed(5)
for (i in 1:10) {
  assign(x = paste0("df", i),
         value = data.frame(x = sort(rnorm(n = 10, mean = 1, sd = 0.1)),
                            y= rnorm(n = 10, mean = 30, sd = 1)))
  } # Create 10 Data Frames

# Define Functions (two versions based on how you want to deal with ties)
ExtractFirstMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- df$y[which.min(df$abs_diff)]
  return(min_rate)
} #Get first y value of closest to x=1

ExtractAvgMin<- function(df){
  df$abs_diff<- abs(df$x-1)
  min_rate<- mean(df$y[df$abs_diff==min(df$abs_diff)])
  return(min_rate)
} #Average all y values that are closest to x=1

# Put all dataframes into a list
df_list<- list(df1,df2,df3,df4,df5,df6,df7,df8,df9,df10)

# Apply function across list
sapply(df_list, ExtractFirstMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907

sapply(df_list, ExtractAvgMin)
#>  [1] 29.40269 32.21546 30.75330 30.12109 30.38361 28.64928 30.45568 29.66190
#>  [9] 31.57229 31.33907
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 1:40 PM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alexander,

Thank you so much for taking the time to outline these suggestions!

What if I wanted to only isolate the y-value at x = 1.0 across all of my 10 dataframes? That way, I could quickly see what the highest and lowest y-value is at x = 1.0? That said, in reality, not all x values are precisely 1.0 (it can be something like 0.99 to 1.02), but the idea is to target the y-value at x = ~1.0. Is that at all possible?

Thanks, again!

-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Wed, May 10, 2023 10:31 am
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

So using your data but removing x=1, 0.8 and 1.2 would be equally close. Two potential options are to choose the y value corresponding to the first minimum difference (in this case x=0.8, y=39), or average the y values for all that are equally close (in this case average the y values for x=0.8 and x=1.2). I think the easiest wayodo that would to first calculate a column of the absolute value of differences between x and 1 and then subset the dataframe to the minimum of that column to extract the y values. Here's a base R and tidyverse implementation to do that.

#Base R
df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df$abs_diff<- abs(df$x-1)

df$y[which.min(df$abs_diff)] #Get first y value of closest to x=1
#> [1] 39
mean(df$y[df$abs_diff==min(df$abs_diff)]) #Average all y values that are closest to x=1
#> [1] 36.5

#tidyverse
rm(list=ls())
library(dplyr)

df<- data.frame(x=c(0,0.2,0.4,0.6,0.8,1.2,1.4),
                y= c(0,27,31,32,39,34,25))
df<- df %>% mutate(abs_diff = abs(x-1))

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% head(1) #Get first y value of closest to x=1
#> [1] 39

df %>% filter(abs_diff==min(abs_diff)) %>% pull(y) %>% mean() #Average all y values that are closest to x=1
#> [1] 36.5
________________________________
From: rain1290 at aim.com <rain1290 at aim.com>
Sent: Wednesday, May 10, 2023 8:13 AM
To: Alexander Ilich <ailich at usf.edu>; r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

Hi Alex and everyone,

My apologies for the confusion and this double message (I just noticed that the example dataset appeared distorted)! Let me try to simplify here again.

My dataframes are structured in the following way: an x column and y column, like this:

[X]


Now, let's say that I want to determine the rate of increase at about x = 1.0, relative to the beginning of the period (i.e. 0 at the beginning). We can see clearly here that the answer would be y = 43. My question is would it be possible to quickly determine the value at around x = 1.0 across the 10 dataframes that I have like this without having to manually check them? The idea is to determine the range of values for y at around x = 1.0 across all dataframes. Note that it's not perfectly x = 1.0 in all dataframes - some could be 0.99 or 1.01.

I hope that this is clearer!

Thanks,


-----Original Message-----
From: Alexander Ilich <ailich at usf.edu>
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>; rain1290 at aim.com <rain1290 at aim.com>
Sent: Tue, May 9, 2023 2:23 pm
Subject: Re: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I'm currently having a bit of difficultly following. Rather than using your actual data, perhaps you could include code to generate a smaller dataset with the same structure with clear definitions of what is contained within each (r faq - How to make a great R reproducible example - Stack Overflow<https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example>). You can design that dataset to be small with a known answer and the describe how you got to that answer and then others could help determine some code to accomplish that task.

Best Regards,
Alex
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of rain1290--- via R-sig-Geo <r-sig-geo at r-project.org>
Sent: Tuesday, May 9, 2023 1:01 PM
To: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Finding the highest and lowest rates of increase at specific x value across several time series in R

I would like to attempt to determine the difference between the highest and lowest rates of increase across a series of dataframes at a specified x value. As shown below, the dataframes have basic x and y columns, with emissions values in the x column, and precipitation values in the y column. Among the dataframes, the idea would be to determine the highest and lowest rates of precipitation increase at "approximately" 1 Terratons of emissions (TtC) relative to the first value of each time series. For example, I want to figure out which dataframe has the highest increase at 1 TtC, and which dataframe has the lowest increase at 1 TtC. at However, I am not sure if there is a way to quickly achieve this? Here are the dataframes that I created, followed by an example of how each dataframe is structured:
#Dataframe objects created:
    CanESMRCP8.5PL<-data.frame(get3.teratons, pland20)     IPSLLRRCP8.5PL<-data.frame(get6.teratons, pland21)    IPSLMRRCP8.5PL<-data.frame(get9.teratons, pland22)    IPSLLRBRCP8.5PL<-data.frame(get12.teratons, pland23)    MIROCRCP8.5PL<-data.frame(get15.teratons, pland24)    HadGEMRCP8.5PL<-data.frame(get18.teratons, pland25)    MPILRRCP8.5PL<-data.frame(get21.teratons, pland26)    GFDLGRCP8.5PL<-data.frame(get27.teratons, pland27)    GFDLMRCP8.5PL<-data.frame(get30.teratons, pland28)
#Example of what each of these look like:
    >CanESMRCP8.5PL
        get3.teratons   pland20    X1      0.4542249 13.252426    X2      0.4626662  3.766658    X3      0.4715780  2.220986    X4      0.4809204  8.495072    X5      0.4901427 10.206458    X6      0.4993126 10.942797    X7      0.5088599  6.592956    X8      0.5187588  2.435796    X9      0.5286758  2.275836    X10     0.5389284  5.051706    X11     0.5496212  8.313389    X12     0.5600628  9.007722    X13     0.5708608 11.905644    X14     0.5819234  6.126022    X15     0.5926283  9.883264    X16     0.6042306  7.699696    X17     0.6159752  5.614193    X18     0.6274483  6.681527    X19     0.6394011 10.112812    X20     0.6519496  8.721810    X21     0.6646344 10.315931    X22     0.6773436 11.372490    X23     0.6903203  8.662169    X24     0.7036479 10.106109    X25     0.7180955 10.990867    X26     0.7322746 13.491778    X27     0.7459771 17.256650    X28     0.7604589 12.040960    X29     0.7753096 10.638796    X30     0.7898374  7.889500    X31     0.8047258 11.757174    X32     0.8204160 15.060151    X33     0.8359387  9.822078    X34     0.8510721 11.388695    X35     0.8661237 10.271567    X36     0.8815913 13.224285    X37     0.8984146 15.584782    X38     0.9154501  9.320024    X39     0.9324529  9.187128    X40     0.9497379 12.919805    X41     0.9672824 15.190318    X42     0.9854439 12.098606    X43     1.0041460 16.758629    X44     1.0241779 17.435182    X45     1.0451656 15.323428    X46     1.0663605 18.292109    X47     1.0868977 12.625429    X48     1.1079376 17.318583    X49     1.1295719 14.056624    X50     1.1516720 18.239445    X51     1.1736696 16.312087    X52     1.1963065 18.683315    X53     1.2195753 20.364835    X54     1.2425277 14.337167    X55     1.2653873 16.072449    X56     1.2888002 14.870248    X57     1.3126799 18.431717    X58     1.3362459 19.873449    X59     1.3593610 17.278361    X60     1.3833589 18.532887    X61     1.4083234 16.178170    X62     1.4328881 17.689810    X63     1.4572568 21.395131    X64     1.4821021 20.154886    X65     1.5072721 15.655971    X66     1.5325393 21.692028    X67     1.5581797 23.258303    X68     1.5842384 23.802459    X69     1.6108635 15.824673    X70     1.6365393 19.016228    X71     1.6618322 20.957593    X72     1.6876948 19.105363    X73     1.7134712 19.759288    X74     1.7392598 27.315595    X75     1.7652725 24.882263    X76     1.7913807 25.813408    X77     1.8173818 23.658997    X78     1.8434211 24.223432    X79     1.8695911 23.560818    X80     1.8960611 28.057708    X81     1.9228969 26.996265    X82     1.9493552 26.659719    X83     1.9759324 22.723687    X84     2.0026666 30.977267    X85     2.0290137 29.384326    X86     2.0549359 24.840383    X87     2.0811679 26.952620    X88     2.1081763 29.894790    X89     2.1349227 25.224040    X90     2.1613017 27.722623
    >IPSLLRRCP8.5PL
        get6.teratons   pland21    X1      0.5300411  8.128827    X2      0.5401701  6.683660    X3      0.5503503 12.344974    X4      0.5607762 11.322411    X5      0.5714146 14.250646    X6      0.5825357 10.013592    X7      0.5937966  9.437394    X8      0.6051673  8.138396    X9      0.6168960  9.767765    X10     0.6290367  8.166579    X11     0.6413864 12.307348    X12     0.6539184 12.623931    X13     0.6667360 11.182448    X14     0.6800060 12.585040    X15     0.6935350 13.408614    X16     0.7071757  9.352335    X17     0.7211951 12.743725    X18     0.7356089 11.625612    X19     0.7502665 10.240418    X20     0.7650959 12.394282    X21     0.7800845 16.963066    X22     0.7953119 16.380090    X23     0.8107459 10.510501    X24     0.8260236 12.645911    X25     0.8414439 14.134851    X26     0.8572960 18.924963    X27     0.8732313 17.849050    X28     0.8892344 10.941533    X29     0.9057380 12.034925    X30     0.9223530 15.897904    X31     0.9391578 19.707692    X32     0.9563358 16.690375    X33     0.9738711 18.098571    X34     0.9916517 16.588447    X35     1.0096934 16.125172    X36     1.0279473 19.108647    X37     1.0463864 16.972994    X38     1.0653421 22.869403    X39     1.0842487 21.228874    X40     1.1035309 25.509754    X41     1.1230403 15.579367    X42     1.1426743 21.259726    X43     1.1626806 26.061262    X44     1.1833831 21.918530    X45     1.2045888 22.369094    X46     1.2262981 21.480456    X47     1.2481395 20.503543    X48     1.2703019 27.717028    X49     1.2929382 26.295449    X50     1.3157745 28.271455    X51     1.3390449 31.595651    X52     1.3626052 26.188018    X53     1.3863833 26.326999    X54     1.4102701 26.902272    X55     1.4343871 25.308764    X56     1.4584666 23.789699    X57     1.4831504 26.916504    X58     1.5080384 32.921638    X59     1.5331210 29.753267    X60     1.5582794 29.567720    X61     1.5832585 31.454097    X62     1.6085002 26.602191    X63     1.6339502 35.873728    X64     1.6594560 34.222654    X65     1.6851070 36.290959    X66     1.7109757 31.623912    X67     1.7368503 31.965520    X68     1.7626750 41.490310    X69     1.7883216 35.645934    X70     1.8141292 35.639422    X71     1.8405670 37.085608    X72     1.8672313 44.812777    X73     1.8939987 40.044602    X74     1.9208222 37.834526    X75     1.9478806 44.497335    X76     1.9750195 39.839740    X77     2.0024118 38.300529    X78     2.0302205 52.116649    X79     2.0581589 59.189047    X80     2.0861536 51.559857    X81     2.1141780 43.305779    X82     2.1421791 47.950074    X83     2.1703249 46.252149    X84     2.1985953 47.536605    X85     2.2266540 49.422466    X86     2.2547762 44.577399    X87     2.2827062 49.720523    X88     2.3102098 47.138244    X89     2.3379090 51.882832    X90     2.3656370 51.413472
Etc...
Any help with this would be greatly appreciated!
Thanks,
        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7Cb59e2f81076143e9b0a408db50af0b78%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638192484981183656%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=iwGeEZIJDfmhJ5TkfQxq5htErTGihLIrl7T5nJ6fIC0%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From m||uj|@b @end|ng |rom gm@||@com  Sat May 20 01:19:53 2023
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Sat, 20 May 2023 01:19:53 +0200
Subject: [R-sig-Geo] Merge dataframe with NetCDF file
Message-ID: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>

Dear all,

I am struggling to convert a dataframe with 49 years of data for 259,200
coordinates. How can I convert this dataset into a NetCDF file with the
following attributes;

class      : RasterBrick
dimensions : 360, 720, 259200, 10  (nrow, ncol, ncell, nlayers)
resolution : 0.5, 0.5  (x, y)
extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
crs        : +proj=longlat +datum=WGS84 +no_defs
year ()    : 1971, 1972, ..., 2019
varname    : fs

Any help will be highly appreciated.

Best,

Milu

	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sat May 20 01:35:47 2023
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 19 May 2023 16:35:47 -0700
Subject: [R-sig-Geo] Merge dataframe with NetCDF file
In-Reply-To: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>
References: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>
Message-ID: <C8D7746C-BE39-49DC-8BD5-B37E28C41844@noaa.gov>

Hi Milu:

One of the best ways to get help is to give some description of what you have tried and what it was that had you stuck.  It looks like you already have the data in a raster brick,  have you Googled "writing RasterBrick to netcdf"?

 I assume nrow is latitude, ncol is longitude,  but what is ncell and nlayers?   I can't match up either of those values with the number of years you show  And what is actual name of the other dimension,  and does it have units?  ls what is the long name of "fs" and what are its units?

Thanks,

-Roy

> On May 19, 2023, at 4:19 PM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear all,
> 
> I am struggling to convert a dataframe with 49 years of data for 259,200
> coordinates. How can I convert this dataset into a NetCDF file with the
> following attributes;
> 
> class      : RasterBrick
> dimensions : 360, 720, 259200, 10  (nrow, ncol, ncell, nlayers)
> resolution : 0.5, 0.5  (x, y)
> extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> crs        : +proj=longlat +datum=WGS84 +no_defs
> year ()    : 1971, 1972, ..., 2019
> varname    : fs
> 
> Any help will be highly appreciated.
> 
> Best,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From @|||ch @end|ng |rom u@|@edu  Sat May 20 02:27:49 2023
From: @|||ch @end|ng |rom u@|@edu (Alexander Ilich)
Date: Sat, 20 May 2023 00:27:49 +0000
Subject: [R-sig-Geo] Merge dataframe with NetCDF file
In-Reply-To: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>
References: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>
Message-ID: <BN0PR08MB7341824ABCC46ABEB29BDD94C67D9@BN0PR08MB7341.namprd08.prod.outlook.com>

The WriteRaster should be able to do it (https://stackoverflow.com/questions/50026442/writing-r-raster-stack-to-netcdf). Also, if practical, I'd recommend switching from the raster package to the terra package which has replaced it and is written by the same author. The syntax is almost identical so it's an easy transition. terra has a writeCDF function which may work (https://rdrr.io/cran/terra/man/writeCDF.html).

Best Regards,
Alex

________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Miluji Sb <milujisb at gmail.com>
Sent: Friday, May 19, 2023 7:19 PM
To: R-sig-geo mailing list <r-sig-geo at r-project.org>
Subject: [R-sig-Geo] Merge dataframe with NetCDF file

[You don't often get email from milujisb at gmail.com. Learn why this is important at https://aka.ms/LearnAboutSenderIdentification ]

Dear all,

I am struggling to convert a dataframe with 49 years of data for 259,200
coordinates. How can I convert this dataset into a NetCDF file with the
following attributes;

class      : RasterBrick
dimensions : 360, 720, 259200, 10  (nrow, ncol, ncell, nlayers)
resolution : 0.5, 0.5  (x, y)
extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
crs        : +proj=longlat +datum=WGS84 +no_defs
year ()    : 1971, 1972, ..., 2019
varname    : fs

Any help will be highly appreciated.

Best,

Milu

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7C0f7d47bd46514adffc8408db58bf9b44%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638201387342113041%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=4%2FySAN%2BWpf4VPnWpJ464WBHBud2bZ0vVz4aV3k1pLHI%3D&reserved=0<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
[EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize the sender and know the content is safe.

	[[alternative HTML version deleted]]


From m||uj|@b @end|ng |rom gm@||@com  Sat May 20 22:51:30 2023
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Sat, 20 May 2023 22:51:30 +0200
Subject: [R-sig-Geo] Merge dataframe with NetCDF file
In-Reply-To: <BN0PR08MB7341824ABCC46ABEB29BDD94C67D9@BN0PR08MB7341.namprd08.prod.outlook.com>
References: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>
 <BN0PR08MB7341824ABCC46ABEB29BDD94C67D9@BN0PR08MB7341.namprd08.prod.outlook.com>
Message-ID: <CAMLwc7MRkNgzg+ELYSEjU6DbdWf-C2KOwzF4eBHpWTrUHfcKBw@mail.gmail.com>

Apologies. I actually do not have a raster yet.

I have created a rasterlayer but when I want to import by data (wide format
and 49 variables), I get the following error.

Error in setValues(x, v) : values must be numeric, logical or factor
In addition: Warning message:
In v[] <- value :
  number of items to replace is not a multiple of replacement length
Error in .local(x, i = i, j = j, ..., value) :

cannot replace values on this raster (it is too large

class      : RasterLayer
dimensions : 360, 720, 259200  (nrow, ncol, ncell)
resolution : 0.5, 0.5  (x, y)
extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
crs        : +proj=longlat +datum=WGS84 +no_defs


What I have is data for 49 years at grid cells (0.5??0.5?) which I would
like to write as a NetCDF file. Any help will be greatly appreciated.
Thanks!

Best,

Milu


On Sat, May 20, 2023 at 2:27?AM Alexander Ilich <ailich at usf.edu> wrote:

> The WriteRaster should be able to do it (
> https://stackoverflow.com/questions/50026442/writing-r-raster-stack-to-netcdf).
> Also, if practical, I'd recommend switching from the raster package to the
> terra package which has replaced it and is written by the same author. The
> syntax is almost identical so it's an easy transition. terra has a writeCDF
> function which may work (https://rdrr.io/cran/terra/man/writeCDF.html).
>
> Best Regards,
> Alex
>
> ------------------------------
> *From:* R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Miluji
> Sb <milujisb at gmail.com>
> *Sent:* Friday, May 19, 2023 7:19 PM
> *To:* R-sig-geo mailing list <r-sig-geo at r-project.org>
> *Subject:* [R-sig-Geo] Merge dataframe with NetCDF file
>
> [You don't often get email from milujisb at gmail.com. Learn why this is
> important at https://aka.ms/LearnAboutSenderIdentification ]
>
> Dear all,
>
> I am struggling to convert a dataframe with 49 years of data for 259,200
> coordinates. How can I convert this dataset into a NetCDF file with the
> following attributes;
>
> class      : RasterBrick
> dimensions : 360, 720, 259200, 10  (nrow, ncol, ncell, nlayers)
> resolution : 0.5, 0.5  (x, y)
> extent     : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
> crs        : +proj=longlat +datum=WGS84 +no_defs
> year ()    : 1971, 1972, ..., 2019
> varname    : fs
>
> Any help will be highly appreciated.
>
> Best,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
>
> https://nam04.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&data=05%7C01%7Cailich%40usf.edu%7C0f7d47bd46514adffc8408db58bf9b44%7C741bf7dee2e546df8d6782607df9deaa%7C0%7C0%7C638201387342113041%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=4%2FySAN%2BWpf4VPnWpJ464WBHBud2bZ0vVz4aV3k1pLHI%3D&reserved=0
> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> [EXTERNAL EMAIL] DO NOT CLICK links or attachments unless you recognize
> the sender and know the content is safe.
>

	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sat May 20 23:40:57 2023
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Sat, 20 May 2023 14:40:57 -0700
Subject: [R-sig-Geo] Merge dataframe with NetCDF file
In-Reply-To: <CAMLwc7MRkNgzg+ELYSEjU6DbdWf-C2KOwzF4eBHpWTrUHfcKBw@mail.gmail.com>
References: <CAMLwc7NeR=iFBCuBV5YzXuO118O_VODf87d3Vj8frXMH9WrKCQ@mail.gmail.com>
 <BN0PR08MB7341824ABCC46ABEB29BDD94C67D9@BN0PR08MB7341.namprd08.prod.outlook.com>
 <CAMLwc7MRkNgzg+ELYSEjU6DbdWf-C2KOwzF4eBHpWTrUHfcKBw@mail.gmail.com>
Message-ID: <17D74C36-6CC6-4689-A072-A7BC0CCA231B@noaa.gov>

You have it  what sense?  Is it your R workspace?  If so,  assume what you have is called "obj",  what is the result of str(obj).  Also have you googled writing netcdf files from R?  There are any number of online tutorials.  Have you looked at the packages ncdf4 or RNetCDF?  Also,  who is your target audience?  Just dumping data to netcdf is not that hard,  creating netcdf files that others can understand by following a convention,  like the CF convention,  takes some thought and work,  As I said in my first reply,  you are likely to get more help when you can show the effort you have put into solving this,  and where you got stuck.

-Roy

> On May 20, 2023, at 1:51 PM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> What I have is data for 49 years at grid cells (0.5??0.5?) which I would
> like to write as a NetCDF file. Any help will be greatly appreciated.
> Thanks!

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From @ervety@p@r@ec|| @end|ng |rom gm@||@com  Wed May 24 09:49:11 2023
From: @ervety@p@r@ec|| @end|ng |rom gm@||@com (=?UTF-8?Q?se=C3=A7il_servetyapar?=)
Date: Wed, 24 May 2023 10:49:11 +0300
Subject: [R-sig-Geo] =?utf-8?b?8J+ZjyBUaGFuayB5b3U=?=
Message-ID: <CAHnCAr=jYhnK-qS+YKyehmVggLFP5EEvS9ZT0k4BkrYMR70hfA@mail.gmail.com>

Hello... I got your mail.? I felt that I was being watched. I think you
understand my problem on your part. I also have a problem with security.? I've
been searching, unfortunately I haven't been successful yet. I am getting
useful information. ?

Merhaba...Mailinizi ald?m.? ?zlendi?imi hissettim sizin taraf?n?zdan
sorunumu anlad???n?z? d???n?yorum. G?venlik konusun da problemim var.
?Ara?t?r?yorum maalesef hen?z ba?ar?l? olamad?m. Faydal? bilgiler
ediniyorum.?

	[[alternative HTML version deleted]]


From je|une@ @end|ng |rom gm@||@com  Fri May 26 18:25:34 2023
From: je|une@ @end|ng |rom gm@||@com (Jose Funes)
Date: Fri, 26 May 2023 12:25:34 -0400
Subject: [R-sig-Geo] Estimate impacts from a spgm - spatial panel regression
 model
In-Reply-To: <mailman.29258.5.1684663202.15457.r-sig-geo@r-project.org>
References: <mailman.29258.5.1684663202.15457.r-sig-geo@r-project.org>
Message-ID: <CAG1eJiH2SX9jirFUXk=uojs_bDV30QhESqD3rcDegXO8M5g0TQ@mail.gmail.com>

Hi,
I would like to estimate the impacts of a spatial lag model output. It used
to work, but it does not work anymore. I used to work fine with the impacts
function in the spdep package, but it seems the function does not work any
longer. The second option was to load the spatialreg library and use the
impacts function, but I get an error message "object type not recognized".
Please advise.

Jose Funes
Economic geographer
DC Office of Planning
1100 4th Street SW, 20024

	[[alternative HTML version deleted]]


From jo@|@h@p@rry @end|ng |rom gm@||@com  Fri May 26 20:14:09 2023
From: jo@|@h@p@rry @end|ng |rom gm@||@com (Josiah Parry)
Date: Fri, 26 May 2023 14:14:09 -0400
Subject: [R-sig-Geo] 
 Estimate impacts from a spgm - spatial panel regression model
In-Reply-To: <CAG1eJiH2SX9jirFUXk=uojs_bDV30QhESqD3rcDegXO8M5g0TQ@mail.gmail.com>
References: <mailman.29258.5.1684663202.15457.r-sig-geo@r-project.org>
 <CAG1eJiH2SX9jirFUXk=uojs_bDV30QhESqD3rcDegXO8M5g0TQ@mail.gmail.com>
Message-ID: <CAL3ufUJsuWNeXfXTUEdohGK7Gedc2my3honrHa8Dm0BNPqgr7g@mail.gmail.com>

Jose have you built the model that you want impacts for using the
spatialreg package? Additionally, it would be great if you provided a
reproducible example for folks to try and replicate the behavior you are
experiencing.

On Fri, May 26, 2023 at 12:26?PM Jose Funes <jefunes at gmail.com> wrote:

> Hi,
> I would like to estimate the impacts of a spatial lag model output. It used
> to work, but it does not work anymore. I used to work fine with the impacts
> function in the spdep package, but it seems the function does not work any
> longer. The second option was to load the spatialreg library and use the
> impacts function, but I get an error message "object type not recognized".
> Please advise.
>
> Jose Funes
> Economic geographer
> DC Office of Planning
> 1100 4th Street SW, 20024
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Fri May 26 20:34:54 2023
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Fri, 26 May 2023 18:34:54 +0000
Subject: [R-sig-Geo] 
 Estimate impacts from a spgm - spatial panel regression model
In-Reply-To: <CAL3ufUJsuWNeXfXTUEdohGK7Gedc2my3honrHa8Dm0BNPqgr7g@mail.gmail.com>
References: <mailman.29258.5.1684663202.15457.r-sig-geo@r-project.org>
 <CAG1eJiH2SX9jirFUXk=uojs_bDV30QhESqD3rcDegXO8M5g0TQ@mail.gmail.com>
 <CAL3ufUJsuWNeXfXTUEdohGK7Gedc2my3honrHa8Dm0BNPqgr7g@mail.gmail.com>
Message-ID: <OSWP279MB04711AFE395E04A33466CE14EE479@OSWP279MB0471.NORP279.PROD.OUTLOOK.COM>

I think the example is using the splm package to fit a GMM model. It is now some years since spdep was split, with model fitting functions and methods moving to spatialreg. The latter has also been updated several times since then, so knowledge of versions of R and packages is essential, in addition to a reproducible example. Specifically, https://github.com/r-spatial/spatialreg/pull/16 changed impacts methods for sphet GMM, and other changes in impacts methods may have occurred: https://github.com/r-spatial/spatialreg/commits/main/R/impacts.R gives full details. Provide a fully reproducible example, best with built-in data, or raise an issue if you can see how any changes have impacted splm in ways that the splm maintainer did not anticipate.

Hope this clarifies,

Roger

--
Roger Bivand
Emeritus Professor
Norwegian School of Economics
Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
Roger.Bivand at nhh.no

________________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Josiah Parry <josiah.parry at gmail.com>
Sent: 26 May 2023 20:14
To: Jose Funes
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo]  Estimate impacts from a spgm - spatial panel regression model

Jose have you built the model that you want impacts for using the
spatialreg package? Additionally, it would be great if you provided a
reproducible example for folks to try and replicate the behavior you are
experiencing.

On Fri, May 26, 2023 at 12:26?PM Jose Funes <jefunes at gmail.com> wrote:

> Hi,
> I would like to estimate the impacts of a spatial lag model output. It used
> to work, but it does not work anymore. I used to work fine with the impacts
> function in the spdep package, but it seems the function does not work any
> longer. The second option was to load the spatialreg library and use the
> impacts function, but I get an error message "object type not recognized".
> Please advise.
>
> Jose Funes
> Economic geographer
> DC Office of Planning
> 1100 4th Street SW, 20024
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From je|une@ @end|ng |rom gm@||@com  Sat May 27 16:58:04 2023
From: je|une@ @end|ng |rom gm@||@com (Jose Funes)
Date: Sat, 27 May 2023 10:58:04 -0400
Subject: [R-sig-Geo] 
 Estimate impacts from a spgm - spatial panel regression model
In-Reply-To: <OSWP279MB04711AFE395E04A33466CE14EE479@OSWP279MB0471.NORP279.PROD.OUTLOOK.COM>
References: <mailman.29258.5.1684663202.15457.r-sig-geo@r-project.org>
 <CAG1eJiH2SX9jirFUXk=uojs_bDV30QhESqD3rcDegXO8M5g0TQ@mail.gmail.com>
 <CAL3ufUJsuWNeXfXTUEdohGK7Gedc2my3honrHa8Dm0BNPqgr7g@mail.gmail.com>
 <OSWP279MB04711AFE395E04A33466CE14EE479@OSWP279MB0471.NORP279.PROD.OUTLOOK.COM>
Message-ID: <CAG1eJiG8s=m11_aLB3StHT2aGzbbsvKEOGnOTJZ6dfALqZ6Tug@mail.gmail.com>

Thanks Professor Bivand and Josiah. See below, basic info and code:

# Rstudio version and PC info

platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          4
minor          1.2
year           2021
month          11
day            01
svn rev        81115
language       R
version.string R version 4.1.2 (2021-11-01)



####### code #####

# Load necessary libraries
library(tigris)
library(splm)
library(spdep)
library(Matrix)
library(plm)

# census tracts
dc_tracts_2018 <- tracts(state="DC",cb=TRUE, year=2018)
dc_tracts_2018$row.id <- 1:179

# Spatial matrix
coords <- coordinates(dc_tracts_2018)
DC.knn_7 <- knearneigh(coords, k=7)
DC7_nb <- knn2nb(DC.knn_7)
DCknn_7 <- nb2listw(DC7_nb, style="W")

# reproducible example
set.seed(123)
df2010 <- data.frame(
  y = rnorm(179),
  x = rnorm(179, mean=2),
  x2 = rnorm(179, mean = 3),
  year=2010,
  row.id = 1:179
)

df2015 <- data.frame(
  y = rnorm(179),
  x = rnorm(179, mean=2.5),
  x2 = rnorm(179, mean = 3),
  year=2015,
  row.id = 1:179
)

df2020 <- data.frame(
  y = rnorm(179),
  x = rnorm(179, mean=1.5),
  x2 = rnorm(179, mean = 3.5),
  year=2020,
  row.id = 1:179
)


# drop geom
st_geometry(dc_tracts_2018) <- NULL

#list of data frame
df <- list(df2010,df2015,df2020)

for (i in seq_along(df)) {
  df[[i]] <- merge(df[[i]], dc_tracts_2018, by = "row.id")

}

df2010 <- df[1]
df2015 <- df[2]
df2020 <- df[3]

# merging
panel_dc_2010_2020 <- rbind(df2010[[1]], df2015[[1]], df2020[[1]])

#### setting lag variables
panel_dc_2010_2020.pd<-pdata.frame(panel_dc_2010_2020, index=c("GEOID","year"))

# lag variables
panel_dc_2010_2020.pd$lag_x <- slag(panel_dc_2010_2020.pd$x,listw=DCknn_7)
panel_dc_2010_2020.pd$lag_x2 <- slag(panel_dc_2010_2020.pd$x2,listw=DCknn_7)

## impacts
time1 <- length(unique(panel_dc_2010_2020$year))
s.lwtracts <- kronecker(Diagonal(time), listw2dgCMatrix(DCknn_7))
trMatc <- trW(s.lwtracts, type = "mult")

Error in trW(s.lwtracts, type = "mult") : could not find function "trW"

# durbin
model_fix_durbin <- spgm(y ~ x + x2 +lag_x + lag_x2,
data=panel_dc_2010_2020.pd, listw = DCknn_7, model = "within",lag =
TRUE,spatial.error = FALSE,moments="fullweights",method="ec2sls")

# estimating impacts
impacts(model_fix_durbin,tr=trMatc, R=200)

Error in impacts(model_fix_durbin, tr = a, R = 200) :
  could not find function "impacts"




On Fri, May 26, 2023 at 2:34?PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> I think the example is using the splm package to fit a GMM model. It is
> now some years since spdep was split, with model fitting functions and
> methods moving to spatialreg. The latter has also been updated several
> times since then, so knowledge of versions of R and packages is essential,
> in addition to a reproducible example. Specifically,
> https://github.com/r-spatial/spatialreg/pull/16 changed impacts methods
> for sphet GMM, and other changes in impacts methods may have occurred:
> https://github.com/r-spatial/spatialreg/commits/main/R/impacts.R gives
> full details. Provide a fully reproducible example, best with built-in
> data, or raise an issue if you can see how any changes have impacted splm
> in ways that the splm maintainer did not anticipate.
>
> Hope this clarifies,
>
> Roger
>
> --
> Roger Bivand
> Emeritus Professor
> Norwegian School of Economics
> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
> Roger.Bivand at nhh.no
>
> ________________________________________
> From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Josiah
> Parry <josiah.parry at gmail.com>
> Sent: 26 May 2023 20:14
> To: Jose Funes
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo]  Estimate impacts from a spgm - spatial panel
> regression model
>
> Jose have you built the model that you want impacts for using the
> spatialreg package? Additionally, it would be great if you provided a
> reproducible example for folks to try and replicate the behavior you are
> experiencing.
>
> On Fri, May 26, 2023 at 12:26?PM Jose Funes <jefunes at gmail.com> wrote:
>
> > Hi,
> > I would like to estimate the impacts of a spatial lag model output. It
> used
> > to work, but it does not work anymore. I used to work fine with the
> impacts
> > function in the spdep package, but it seems the function does not work
> any
> > longer. The second option was to load the spatialreg library and use the
> > impacts function, but I get an error message "object type not
> recognized".
> > Please advise.
> >
> > Jose Funes
> > Economic geographer
> > DC Office of Planning
> > 1100 4th Street SW, 20024
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From je|une@ @end|ng |rom gm@||@com  Sat May 27 17:37:13 2023
From: je|une@ @end|ng |rom gm@||@com (Jose Funes)
Date: Sat, 27 May 2023 11:37:13 -0400
Subject: [R-sig-Geo] 
 Estimate impacts from a spgm - spatial panel regression model
In-Reply-To: <CAG1eJiG8s=m11_aLB3StHT2aGzbbsvKEOGnOTJZ6dfALqZ6Tug@mail.gmail.com>
References: <mailman.29258.5.1684663202.15457.r-sig-geo@r-project.org>
 <CAG1eJiH2SX9jirFUXk=uojs_bDV30QhESqD3rcDegXO8M5g0TQ@mail.gmail.com>
 <CAL3ufUJsuWNeXfXTUEdohGK7Gedc2my3honrHa8Dm0BNPqgr7g@mail.gmail.com>
 <OSWP279MB04711AFE395E04A33466CE14EE479@OSWP279MB0471.NORP279.PROD.OUTLOOK.COM>
 <CAG1eJiG8s=m11_aLB3StHT2aGzbbsvKEOGnOTJZ6dfALqZ6Tug@mail.gmail.com>
Message-ID: <CAG1eJiEUY6iOUW+y1QoqHo=b6d7YKbkuKevfTsGFHhyC180koQ@mail.gmail.com>

Thanks, Professor Bivand and Josiah. The previous code had the variable
time mistyped instead of time1. The code below corrects that. See below,
basic info and code:

# Rstudio version and PC info

platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          4
minor          1.2
year           2021
month          11
day            01
svn rev        81115
language       R
version.string R version 4.1.2 (2021-11-01)



####### code #####

# Load necessary libraries
library(tigris)
library(splm)
library(spdep)
library(Matrix)
library(plm)


# Load necessary libraries
library(tigris)
library(splm)
library(spdep)
library(Matrix)
library(plm)

# census tracts
dc_tracts_2018 <- tracts(state="DC",cb=TRUE, year=2018)
dc_tracts_2018$row.id <- 1:179

# Spatial matrix
coords <- coordinates(dc_tracts_2018)
DC.knn_7 <- knearneigh(coords, k=7)
DC7_nb <- knn2nb(DC.knn_7)
DCknn_7 <- nb2listw(DC7_nb, style="W")

# reproducible example
set.seed(123)
df2010 <- data.frame(
  y = rnorm(179),
  x = rnorm(179, mean=2),
  x2 = rnorm(179, mean = 3),
  year=2010,
  row.id = 1:179
)

df2015 <- data.frame(
  y = rnorm(179),
  x = rnorm(179, mean=2.5),
  x2 = rnorm(179, mean = 3),
  year=2015,
  row.id = 1:179
)

df2020 <- data.frame(
  y = rnorm(179),
  x = rnorm(179, mean=1.5),
  x2 = rnorm(179, mean = 3.5),
  year=2020,
  row.id = 1:179
)


# drop geom
st_geometry(dc_tracts_2018) <- NULL

#list of data frame
df <- list(df2010,df2015,df2020)

for (i in seq_along(df)) {
  df[[i]] <- merge(df[[i]], dc_tracts_2018, by = "row.id")

}

df2010 <- df[1]
df2015 <- df[2]
df2020 <- df[3]

# merging
panel_dc_2010_2020 <- rbind(df2010[[1]], df2015[[1]], df2020[[1]])

#### setting lag variables
panel_dc_2010_2020.pd<-pdata.frame(panel_dc_2010_2020,
index=c("GEOID","year"))

# lag variables
panel_dc_2010_2020.pd$lag_x <- slag(panel_dc_2010_2020.pd$x,listw=DCknn_7)
panel_dc_2010_2020.pd$lag_x2 <- slag(panel_dc_2010_2020.pd$x2,listw=DCknn_7)

## impacts
time1 <- length(unique(panel_dc_2010_2020$year))
s.lwtracts <- kronecker(Diagonal(time1), listw2dgCMatrix(DCknn_7))
trMatc <- trW(s.lwtracts, type = "mult")

Error in trW(s.lwtracts, type = "mult") : could not find function "trW"

# durbing
model_fix_durbin <- spgm(y ~ x + x2 +lag_x + lag_x2,
data=panel_dc_2010_2020.pd, listw = DCknn_7, model = "within",lag =
TRUE,spatial.error = FALSE,moments="fullweights",method="ec2sls")

# estimating impacts
impacts(model_fix_durbin,tr=trMatc, R=200)

Error in impacts(model_fix_durbin, tr = a, R = 200) :
  could not find function "impacts"


On Sat, May 27, 2023 at 10:58?AM Jose Funes <jefunes at gmail.com> wrote:

> Thanks Professor Bivand and Josiah. See below, basic info and code:
>
> # Rstudio version and PC info
>
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          4
> minor          1.2
> year           2021
> month          11
> day            01
> svn rev        81115
> language       R
> version.string R version 4.1.2 (2021-11-01)
>
>
>
> ####### code #####
>
> # Load necessary libraries
> library(tigris)
> library(splm)
> library(spdep)
> library(Matrix)
> library(plm)
>
> # census tracts
> dc_tracts_2018 <- tracts(state="DC",cb=TRUE, year=2018)
> dc_tracts_2018$row.id <- 1:179
>
> # Spatial matrix
> coords <- coordinates(dc_tracts_2018)
> DC.knn_7 <- knearneigh(coords, k=7)
> DC7_nb <- knn2nb(DC.knn_7)
> DCknn_7 <- nb2listw(DC7_nb, style="W")
>
> # reproducible example
> set.seed(123)
> df2010 <- data.frame(
>   y = rnorm(179),
>   x = rnorm(179, mean=2),
>   x2 = rnorm(179, mean = 3),
>   year=2010,
>   row.id = 1:179
> )
>
> df2015 <- data.frame(
>   y = rnorm(179),
>   x = rnorm(179, mean=2.5),
>   x2 = rnorm(179, mean = 3),
>   year=2015,
>   row.id = 1:179
> )
>
> df2020 <- data.frame(
>   y = rnorm(179),
>   x = rnorm(179, mean=1.5),
>   x2 = rnorm(179, mean = 3.5),
>   year=2020,
>   row.id = 1:179
> )
>
>
> # drop geom
> st_geometry(dc_tracts_2018) <- NULL
>
> #list of data frame
> df <- list(df2010,df2015,df2020)
>
> for (i in seq_along(df)) {
>   df[[i]] <- merge(df[[i]], dc_tracts_2018, by = "row.id")
>
> }
>
> df2010 <- df[1]
> df2015 <- df[2]
> df2020 <- df[3]
>
> # merging
> panel_dc_2010_2020 <- rbind(df2010[[1]], df2015[[1]], df2020[[1]])
>
> #### setting lag variables
> panel_dc_2010_2020.pd<-pdata.frame(panel_dc_2010_2020, index=c("GEOID","year"))
>
> # lag variables
> panel_dc_2010_2020.pd$lag_x <- slag(panel_dc_2010_2020.pd$x,listw=DCknn_7)
> panel_dc_2010_2020.pd$lag_x2 <- slag(panel_dc_2010_2020.pd$x2,listw=DCknn_7)
>
> ## impacts
> time1 <- length(unique(panel_dc_2010_2020$year))
> s.lwtracts <- kronecker(Diagonal(time), listw2dgCMatrix(DCknn_7))
> trMatc <- trW(s.lwtracts, type = "mult")
>
> Error in trW(s.lwtracts, type = "mult") : could not find function "trW"
>
> # durbin
> model_fix_durbin <- spgm(y ~ x + x2 +lag_x + lag_x2,
> data=panel_dc_2010_2020.pd, listw = DCknn_7, model = "within",lag =
> TRUE,spatial.error = FALSE,moments="fullweights",method="ec2sls")
>
> # estimating impacts
> impacts(model_fix_durbin,tr=trMatc, R=200)
>
> Error in impacts(model_fix_durbin, tr = a, R = 200) :
>   could not find function "impacts"
>
>
>
>
> On Fri, May 26, 2023 at 2:34?PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> I think the example is using the splm package to fit a GMM model. It is
>> now some years since spdep was split, with model fitting functions and
>> methods moving to spatialreg. The latter has also been updated several
>> times since then, so knowledge of versions of R and packages is essential,
>> in addition to a reproducible example. Specifically,
>> https://github.com/r-spatial/spatialreg/pull/16 changed impacts methods
>> for sphet GMM, and other changes in impacts methods may have occurred:
>> https://github.com/r-spatial/spatialreg/commits/main/R/impacts.R gives
>> full details. Provide a fully reproducible example, best with built-in
>> data, or raise an issue if you can see how any changes have impacted splm
>> in ways that the splm maintainer did not anticipate.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>> --
>> Roger Bivand
>> Emeritus Professor
>> Norwegian School of Economics
>> Postboks 3490 Ytre Sandviken, 5045 Bergen, Norway
>> Roger.Bivand at nhh.no
>>
>> ________________________________________
>> From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Josiah
>> Parry <josiah.parry at gmail.com>
>> Sent: 26 May 2023 20:14
>> To: Jose Funes
>> Cc: r-sig-geo at r-project.org
>> Subject: Re: [R-sig-Geo]  Estimate impacts from a spgm - spatial panel
>> regression model
>>
>> Jose have you built the model that you want impacts for using the
>> spatialreg package? Additionally, it would be great if you provided a
>> reproducible example for folks to try and replicate the behavior you are
>> experiencing.
>>
>> On Fri, May 26, 2023 at 12:26?PM Jose Funes <jefunes at gmail.com> wrote:
>>
>> > Hi,
>> > I would like to estimate the impacts of a spatial lag model output. It
>> used
>> > to work, but it does not work anymore. I used to work fine with the
>> impacts
>> > function in the spdep package, but it seems the function does not work
>> any
>> > longer. The second option was to load the spatialreg library and use the
>> > impacts function, but I get an error message "object type not
>> recognized".
>> > Please advise.
>> >
>> > Jose Funes
>> > Economic geographer
>> > DC Office of Planning
>> > 1100 4th Street SW, 20024
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Tue May 30 20:56:18 2023
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher Ryan)
Date: Tue, 30 May 2023 14:56:18 -0400
Subject: [R-sig-Geo] multiplicity-correction in p-values from sparr risk()
 and tolerance() functions?
Message-ID: <CAM+rpYkbS1oEqop+G9grm76sZTyE2BaDNHzeWfA6YZcvVSyRUA@mail.gmail.com>

In the sparr package, risk() includes a logical argument for tolerance. If
tolerance = TRUE, a pixel image of p-values is produced. Alternatively, the
tolerance() function does something similar, but with more granular control
of options. So basically one p-value for every pixel. Are these p-values,
as produced, corrected in any way for multiplicity?

Thanks for any insights.

--Chris Ryan

	[[alternative HTML version deleted]]


From kev|n @end|ng |rom zembower@org  Wed May 31 22:02:39 2023
From: kev|n @end|ng |rom zembower@org (=?UTF-8?Q?Kevin_Zembower?=)
Date: Wed, 31 May 2023 20:02:39 +0000
Subject: [R-sig-Geo] Mapping census tracts with leaflet(): "sf layer has
 inconsistent datum" error
References: <5a45b608-91b2-3aaf-5d39-d50c6b57c136@zembower.org>
Message-ID: <010001887367c22b-cfdf7f66-7212-4fe4-8dd5-001439a110f8-000000@email.amazonses.com>

Hello, all. Newbie to sf, tidycensus and the tidyverse here.

First off, is this the appropriate list to ask this question? If not, 
let me know and I'll go away.

I'm trying to map census blocks for my neighborhood to a base map. I'm 
using tidycensus to get the geometry of the census blocks, and leaflet 
to map them to the OSM base maps. Mostly, this is going really well, and 
I'm very pleased with the speed of development (I just started this 
morning) and results.

However, I get this error:

  Warning message:
sf layer has inconsistent datum (+proj=longlat +datum=NAD83 +no_defs).
Need '+proj=longlat +datum=WGS84'

I think I need to use st_transform, but can't get it to work.

Here's a reproducible example, with some commented out lines of what 
I've tried:

## Reproducible example:
library(tidyverse)
library(tidycensus)
library(leaflet)
library(sf)

rw_blocks <- c(3000, 3001, 3002, 3005, 3006, 3007, 3008, 3009, 3010, 3011)

rw_pop <- get_decennial(
     geography = "block",
     variables = "P1_001N",
     year = 2020,
     state = "MD",
     county = "Baltimore city",
     geometry = TRUE
) %>%
     filter(substr(GEOID, 6, 11) == "271101" &
            substr(GEOID, 12, 15) %in% rw_blocks
            ) ## %>% st_transform('+proj=longlat +datum=WGS8')

(rw_pop_map <- rw_pop %>%
     leaflet() %>%
      ## st_transform('+proj=longlat +datum=WGS8') %>%
     fitBounds(-76.616, 39.352, -76.610, 39.346) %>%
     addTiles() %>%
     addPolygons()
     )
## Error occurs when executing above block

Can anyone offer me a hint as to how to resolve this error?

Thanks so much for any advice and guidance.

-Kevin


