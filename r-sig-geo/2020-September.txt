From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep  1 02:25:32 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 1 Sep 2020 12:25:32 +1200
Subject: [R-sig-Geo] Could you please unsubscribe me?
In-Reply-To: <CAEMP_RurMvt1TyMk8rZQBkTSTG0kaoneiBXJVx6Qz1Zkk+rLrw@mail.gmail.com>
References: <CAEMP_RurMvt1TyMk8rZQBkTSTG0kaoneiBXJVx6Qz1Zkk+rLrw@mail.gmail.com>
Message-ID: <20200901122532.122a48c6@rolf-Latitude-E7470>


On Mon, 31 Aug 2020 10:07:15 -0400
Scott Haag <scottmhaag at gmail.com> wrote:

> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

You have to unsubscribe yourself.  (As in the popular epithet "Go
unsubscribe yourself! :-) )  No-one can do it for you! :-)

See (click on) the link above and then scroll to the bottom of the page
and click on the "Unsubscribe or edit options" button.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Sep  1 12:20:33 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 1 Sep 2020 12:20:33 +0200
Subject: [R-sig-Geo] Could you please unsubscribe me?
In-Reply-To: <20200901122532.122a48c6@rolf-Latitude-E7470>
References: <CAEMP_RurMvt1TyMk8rZQBkTSTG0kaoneiBXJVx6Qz1Zkk+rLrw@mail.gmail.com>
 <20200901122532.122a48c6@rolf-Latitude-E7470>
Message-ID: <alpine.LFD.2.23.451.2009011215060.407925@reclus.nhh.no>

On Tue, 1 Sep 2020, Rolf Turner wrote:

>
> On Mon, 31 Aug 2020 10:07:15 -0400
> Scott Haag <scottmhaag at gmail.com> wrote:
>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> You have to unsubscribe yourself.  (As in the popular epithet "Go
> unsubscribe yourself! :-) )  No-one can do it for you! :-)

Thanks, Rolf! A very small addition - if a subscriber no longer has access 
to their subscribed email, it is possible to email the list owner (address 
on list page), for a manual delete. If subscribers simply go away, and 
their email handler also denies knowing them, the server will count 
bounces and on reaching a threshold will delete automatically.

>
> See (click on) the link above and then scroll to the bottom of the page
> and click on the "Unsubscribe or edit options" button.
>

This is exactly what I wrote to the first of yesterday's two unsubscribe 
messages, and should always be followed when possible. The same page lets 
subscribers update their email addresses.

Best wishes,

Roger
list admin.

> cheers,
>
> Rolf Turner
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From m@tteo @end|ng |rom m@tt|uzz|@com  Wed Sep  2 14:25:23 2020
From: m@tteo @end|ng |rom m@tt|uzz|@com (Matteo Mattiuzzi)
Date: Wed, 2 Sep 2020 14:25:23 +0200
Subject: [R-sig-Geo] convert from any spatial* classes to a specific
 character string
Message-ID: <CADcazozCt_ueK8zOS7YxhRsQDRXxkQFndv-rsDhefPXVSRaKFQ@mail.gmail.com>

Dear list,

I have recently submitted a little R package to CRAN (now waiting for
approval) https://github.com/MatMatt/clmsapi.
The package is a R client for downloading data from the Copernicus Land
Monitoring Service (https://cryo.land.copernicus.eu/finder/).

The API expects a parameter called 'geometry' with the following formatting
(character):
'POLYGON((lon+lat,lon+lat,lon+lat, ... ))' # commas are replaced with ascii
'%2C' in the query string
or
'POINT(lon+lat)'
see also here:
https://cryo.land.copernicus.eu/resto/api/collections/HRSI/describe.xml

I could expect users to prepare the geometry parameter as it is needed by
the API, but I would prefer to improve the user friendliness by adding some
functionalities (similar as in the MODIS package) that can convert from
different spatial extent objects/classes to the needed character string (in
clmsapi::composeUrl).

What is the best way to implement that? What are the classes I should
consider as input for the geometry parameter? (i.e. well established and
well supplied with conversion-functions).

Thanks and kind regards, Matteo

	[[alternative HTML version deleted]]


From rob00x @end|ng |rom gm@||@com  Wed Sep  2 17:25:13 2020
From: rob00x @end|ng |rom gm@||@com (Robin Lovelace)
Date: Wed, 2 Sep 2020 16:25:13 +0100
Subject: [R-sig-Geo] convert from any spatial* classes to a specific
 character string
In-Reply-To: <CADcazozCt_ueK8zOS7YxhRsQDRXxkQFndv-rsDhefPXVSRaKFQ@mail.gmail.com>
References: <CADcazozCt_ueK8zOS7YxhRsQDRXxkQFndv-rsDhefPXVSRaKFQ@mail.gmail.com>
Message-ID: <CAF16KkWjq1tncQz-FuNAG33WoqG_X5-gVe=gdw-FRQ8ySGgxCg@mail.gmail.com>

Does this help? The approach covers sf, sp and maybe other classes that can
be converted into sf objects.

``` r
library(spData)
library(sf)
#> Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 7.0.0
x_sf = rmapshaper::ms_simplify(lnd[1:3, ], 0.01)
#> Registered S3 method overwritten by 'geojsonlint':
#>   method         from
#>   print.location dplyr
x_sp = sf::as_Spatial(x_sf)
geo_to_char = function(x) {
  if(!is(object = x, class2 = "sf")) {
    x = sf::st_as_sf(x)
  }
  sf::st_as_text(sf::st_geometry(x))
}
geo_to_char(x_sf)
#> [1] "POLYGON ((-0.3306791 51.32901, -0.3305339 51.34842, -0.3086951
51.37545, -0.3177201 51.39367, -0.3096538 51.40001, -0.3060304 51.42123,
-0.2866189 51.42017, -0.2540906 51.43729, -0.2446848 51.40423, -0.2474248
51.39758, -0.2387446 51.38609, -0.2608406 51.37956, -0.2854616 51.36425,
-0.3039032 51.34325, -0.3057101 51.33541, -0.3193073 51.32781, -0.3306791
51.32901))"



#> [2] "POLYGON ((-0.0785486 51.41985, -0.0689427 51.40418, -0.0427724
51.38945, -0.0369519 51.37701, -0.0053322 51.35268, 0.0022661 51.32914,
-0.0251301 51.33861, -0.0379184 51.33871, -0.0478549 51.32651, -0.0641537
51.31863, -0.0848293 51.31587, -0.0943518 51.29936, -0.1243197 51.28676,
-0.1373403 51.30078, -0.155344 51.30128, -0.1619055 51.31963, -0.1444548
51.32648, -0.1475475 51.33878, -0.1275566 51.34745, -0.1169191 51.34575,
-0.1233396 51.37119, -0.1337986 51.39127, -0.1245223 51.39741, -0.1324811
51.40841, -0.1126856 51.42324, -0.0785486 51.41985))"

#> [3] "POLYGON ((0.0022661 51.32914, -0.0053322 51.35268, -0.0369519
51.37701, -0.0427724 51.38945, -0.0689427 51.40418, -0.0785486 51.41985,
-0.0748669 51.4258, -0.0436909 51.42291, -0.0301069 51.42565, -0.0105455
51.41355, 0.0254105 51.42899, 0.0398142 51.44099, 0.0585966 51.42459,
0.0753431 51.43199, 0.1124939 51.41317, 0.134136 51.41385, 0.1488766
51.40848, 0.1598909 51.39465, 0.1498092 51.39087, 0.1532098 51.37804,
0.1362526 51.34555, 0.1166538 51.3413, 0.1202182 51.33214, 0.1047428
51.32734, 0.0850008 51.31602, 0.0856654 51.29309, 0.0584828 51.28936,
0.0457041 51.29401, 0.0328814 51.30752, 0.0149821 51.29179, 0.0022661
51.32914))"
geo_to_char(x_sp)
#> [1] "POLYGON ((-0.3306791 51.32901, -0.3305339 51.34842, -0.3086951
51.37545, -0.3177201 51.39367, -0.3096538 51.40001, -0.3060304 51.42123,
-0.2866189 51.42017, -0.2540906 51.43729, -0.2446848 51.40423, -0.2474248
51.39758, -0.2387446 51.38609, -0.2608406 51.37956, -0.2854616 51.36425,
-0.3039032 51.34325, -0.3057101 51.33541, -0.3193073 51.32781, -0.3306791
51.32901))"



#> [2] "POLYGON ((-0.0785486 51.41985, -0.0689427 51.40418, -0.0427724
51.38945, -0.0369519 51.37701, -0.0053322 51.35268, 0.0022661 51.32914,
-0.0251301 51.33861, -0.0379184 51.33871, -0.0478549 51.32651, -0.0641537
51.31863, -0.0848293 51.31587, -0.0943518 51.29936, -0.1243197 51.28676,
-0.1373403 51.30078, -0.155344 51.30128, -0.1619055 51.31963, -0.1444548
51.32648, -0.1475475 51.33878, -0.1275566 51.34745, -0.1169191 51.34575,
-0.1233396 51.37119, -0.1337986 51.39127, -0.1245223 51.39741, -0.1324811
51.40841, -0.1126856 51.42324, -0.0785486 51.41985))"

#> [3] "POLYGON ((0.0022661 51.32914, -0.0053322 51.35268, -0.0369519
51.37701, -0.0427724 51.38945, -0.0689427 51.40418, -0.0785486 51.41985,
-0.0748669 51.4258, -0.0436909 51.42291, -0.0301069 51.42565, -0.0105455
51.41355, 0.0254105 51.42899, 0.0398142 51.44099, 0.0585966 51.42459,
0.0753431 51.43199, 0.1124939 51.41317, 0.134136 51.41385, 0.1488766
51.40848, 0.1598909 51.39465, 0.1498092 51.39087, 0.1532098 51.37804,
0.1362526 51.34555, 0.1166538 51.3413, 0.1202182 51.33214, 0.1047428
51.32734, 0.0850008 51.31602, 0.0856654 51.29309, 0.0584828 51.28936,
0.0457041 51.29401, 0.0328814 51.30752, 0.0149821 51.29179, 0.0022661
51.32914))"
```

<sup>Created on 2020-09-02 by the [reprex package](
https://reprex.tidyverse.org) (v0.3.0)</sup>

On Wed, Sep 2, 2020 at 1:25 PM Matteo Mattiuzzi <matteo at mattiuzzi.com>
wrote:

> Dear list,
>
> I have recently submitted a little R package to CRAN (now waiting for
> approval) https://github.com/MatMatt/clmsapi.
> The package is a R client for downloading data from the Copernicus Land
> Monitoring Service (https://cryo.land.copernicus.eu/finder/).
>
> The API expects a parameter called 'geometry' with the following formatting
> (character):
> 'POLYGON((lon+lat,lon+lat,lon+lat, ... ))' # commas are replaced with ascii
> '%2C' in the query string
> or
> 'POINT(lon+lat)'
> see also here:
> https://cryo.land.copernicus.eu/resto/api/collections/HRSI/describe.xml
>
> I could expect users to prepare the geometry parameter as it is needed by
> the API, but I would prefer to improve the user friendliness by adding some
> functionalities (similar as in the MODIS package) that can convert from
> different spatial extent objects/classes to the needed character string (in
> clmsapi::composeUrl).
>
> What is the best way to implement that? What are the classes I should
> consider as input for the geometry parameter? (i.e. well established and
> well supplied with conversion-functions).
>
> Thanks and kind regards, Matteo
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From rob00x @end|ng |rom gm@||@com  Thu Sep  3 22:37:25 2020
From: rob00x @end|ng |rom gm@||@com (Robin Lovelace)
Date: Thu, 3 Sep 2020 21:37:25 +0100
Subject: [R-sig-Geo] convert from any spatial* classes to a specific
 character string
In-Reply-To: <CAF16KkWjq1tncQz-FuNAG33WoqG_X5-gVe=gdw-FRQ8ySGgxCg@mail.gmail.com>
References: <CADcazozCt_ueK8zOS7YxhRsQDRXxkQFndv-rsDhefPXVSRaKFQ@mail.gmail.com>
 <CAF16KkWjq1tncQz-FuNAG33WoqG_X5-gVe=gdw-FRQ8ySGgxCg@mail.gmail.com>
Message-ID: <CAF16KkUoqw-BkwNnc=yvZbNZp--EgZS_5-hqYvnn048jNt7-0g@mail.gmail.com>

Update on this, it has been implemented:
https://github.com/MatMatt/clmsapi/commit/bf7996006a96b31cc8e150b81f56c64e7da695ce

Thanks Matteo for the response to me (which may have been intended for the
list).

Robin

On Wed, Sep 2, 2020 at 4:25 PM Robin Lovelace <rob00x at gmail.com> wrote:

> Does this help? The approach covers sf, sp and maybe other classes that
> can be converted into sf objects.
>
> ``` r
> library(spData)
> library(sf)
> #> Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 7.0.0
> x_sf = rmapshaper::ms_simplify(lnd[1:3, ], 0.01)
> #> Registered S3 method overwritten by 'geojsonlint':
> #>   method         from
> #>   print.location dplyr
> x_sp = sf::as_Spatial(x_sf)
> geo_to_char = function(x) {
>   if(!is(object = x, class2 = "sf")) {
>     x = sf::st_as_sf(x)
>   }
>   sf::st_as_text(sf::st_geometry(x))
> }
> geo_to_char(x_sf)
> #> [1] "POLYGON ((-0.3306791 51.32901, -0.3305339 51.34842, -0.3086951
> 51.37545, -0.3177201 51.39367, -0.3096538 51.40001, -0.3060304 51.42123,
> -0.2866189 51.42017, -0.2540906 51.43729, -0.2446848 51.40423, -0.2474248
> 51.39758, -0.2387446 51.38609, -0.2608406 51.37956, -0.2854616 51.36425,
> -0.3039032 51.34325, -0.3057101 51.33541, -0.3193073 51.32781, -0.3306791
> 51.32901))"
>
>
>
> #> [2] "POLYGON ((-0.0785486 51.41985, -0.0689427 51.40418, -0.0427724
> 51.38945, -0.0369519 51.37701, -0.0053322 51.35268, 0.0022661 51.32914,
> -0.0251301 51.33861, -0.0379184 51.33871, -0.0478549 51.32651, -0.0641537
> 51.31863, -0.0848293 51.31587, -0.0943518 51.29936, -0.1243197 51.28676,
> -0.1373403 51.30078, -0.155344 51.30128, -0.1619055 51.31963, -0.1444548
> 51.32648, -0.1475475 51.33878, -0.1275566 51.34745, -0.1169191 51.34575,
> -0.1233396 51.37119, -0.1337986 51.39127, -0.1245223 51.39741, -0.1324811
> 51.40841, -0.1126856 51.42324, -0.0785486 51.41985))"
>
> #> [3] "POLYGON ((0.0022661 51.32914, -0.0053322 51.35268, -0.0369519
> 51.37701, -0.0427724 51.38945, -0.0689427 51.40418, -0.0785486 51.41985,
> -0.0748669 51.4258, -0.0436909 51.42291, -0.0301069 51.42565, -0.0105455
> 51.41355, 0.0254105 51.42899, 0.0398142 51.44099, 0.0585966 51.42459,
> 0.0753431 51.43199, 0.1124939 51.41317, 0.134136 51.41385, 0.1488766
> 51.40848, 0.1598909 51.39465, 0.1498092 51.39087, 0.1532098 51.37804,
> 0.1362526 51.34555, 0.1166538 51.3413, 0.1202182 51.33214, 0.1047428
> 51.32734, 0.0850008 51.31602, 0.0856654 51.29309, 0.0584828 51.28936,
> 0.0457041 51.29401, 0.0328814 51.30752, 0.0149821 51.29179, 0.0022661
> 51.32914))"
> geo_to_char(x_sp)
> #> [1] "POLYGON ((-0.3306791 51.32901, -0.3305339 51.34842, -0.3086951
> 51.37545, -0.3177201 51.39367, -0.3096538 51.40001, -0.3060304 51.42123,
> -0.2866189 51.42017, -0.2540906 51.43729, -0.2446848 51.40423, -0.2474248
> 51.39758, -0.2387446 51.38609, -0.2608406 51.37956, -0.2854616 51.36425,
> -0.3039032 51.34325, -0.3057101 51.33541, -0.3193073 51.32781, -0.3306791
> 51.32901))"
>
>
>
> #> [2] "POLYGON ((-0.0785486 51.41985, -0.0689427 51.40418, -0.0427724
> 51.38945, -0.0369519 51.37701, -0.0053322 51.35268, 0.0022661 51.32914,
> -0.0251301 51.33861, -0.0379184 51.33871, -0.0478549 51.32651, -0.0641537
> 51.31863, -0.0848293 51.31587, -0.0943518 51.29936, -0.1243197 51.28676,
> -0.1373403 51.30078, -0.155344 51.30128, -0.1619055 51.31963, -0.1444548
> 51.32648, -0.1475475 51.33878, -0.1275566 51.34745, -0.1169191 51.34575,
> -0.1233396 51.37119, -0.1337986 51.39127, -0.1245223 51.39741, -0.1324811
> 51.40841, -0.1126856 51.42324, -0.0785486 51.41985))"
>
> #> [3] "POLYGON ((0.0022661 51.32914, -0.0053322 51.35268, -0.0369519
> 51.37701, -0.0427724 51.38945, -0.0689427 51.40418, -0.0785486 51.41985,
> -0.0748669 51.4258, -0.0436909 51.42291, -0.0301069 51.42565, -0.0105455
> 51.41355, 0.0254105 51.42899, 0.0398142 51.44099, 0.0585966 51.42459,
> 0.0753431 51.43199, 0.1124939 51.41317, 0.134136 51.41385, 0.1488766
> 51.40848, 0.1598909 51.39465, 0.1498092 51.39087, 0.1532098 51.37804,
> 0.1362526 51.34555, 0.1166538 51.3413, 0.1202182 51.33214, 0.1047428
> 51.32734, 0.0850008 51.31602, 0.0856654 51.29309, 0.0584828 51.28936,
> 0.0457041 51.29401, 0.0328814 51.30752, 0.0149821 51.29179, 0.0022661
> 51.32914))"
> ```
>
> <sup>Created on 2020-09-02 by the [reprex package](
> https://reprex.tidyverse.org) (v0.3.0)</sup>
>
> On Wed, Sep 2, 2020 at 1:25 PM Matteo Mattiuzzi <matteo at mattiuzzi.com>
> wrote:
>
>> Dear list,
>>
>> I have recently submitted a little R package to CRAN (now waiting for
>> approval) https://github.com/MatMatt/clmsapi.
>> The package is a R client for downloading data from the Copernicus Land
>> Monitoring Service (https://cryo.land.copernicus.eu/finder/).
>>
>> The API expects a parameter called 'geometry' with the following
>> formatting
>> (character):
>> 'POLYGON((lon+lat,lon+lat,lon+lat, ... ))' # commas are replaced with
>> ascii
>> '%2C' in the query string
>> or
>> 'POINT(lon+lat)'
>> see also here:
>> https://cryo.land.copernicus.eu/resto/api/collections/HRSI/describe.xml
>>
>> I could expect users to prepare the geometry parameter as it is needed by
>> the API, but I would prefer to improve the user friendliness by adding
>> some
>> functionalities (similar as in the MODIS package) that can convert from
>> different spatial extent objects/classes to the needed character string
>> (in
>> clmsapi::composeUrl).
>>
>> What is the best way to implement that? What are the classes I should
>> consider as input for the geometry parameter? (i.e. well established and
>> well supplied with conversion-functions).
>>
>> Thanks and kind regards, Matteo
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From m@tteo @end|ng |rom m@tt|uzz|@com  Fri Sep  4 11:55:05 2020
From: m@tteo @end|ng |rom m@tt|uzz|@com (Matteo Mattiuzzi)
Date: Fri, 4 Sep 2020 11:55:05 +0200
Subject: [R-sig-Geo] convert from any spatial* classes to a specific
 character string
In-Reply-To: <CAF16KkWjq1tncQz-FuNAG33WoqG_X5-gVe=gdw-FRQ8ySGgxCg@mail.gmail.com>
References: <CADcazozCt_ueK8zOS7YxhRsQDRXxkQFndv-rsDhefPXVSRaKFQ@mail.gmail.com>
 <CAF16KkWjq1tncQz-FuNAG33WoqG_X5-gVe=gdw-FRQ8ySGgxCg@mail.gmail.com>
Message-ID: <CADcazoyo4AgpT1Ruha9HCqn6V0VOsO_ujVr5vAoEpyXQykUYsg@mail.gmail.com>

 Dear Robin, thanks a lot I have implemented your suggestion: see:
?clmsapi::geo2char Kind regards, Matteo

Am Mi., 2. Sept. 2020 um 17:25 Uhr schrieb Robin Lovelace <rob00x at gmail.com
>:

> Does this help? The approach covers sf, sp and maybe other classes that
> can be converted into sf objects.
>
> ``` r
> library(spData)
> library(sf)
> #> Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 7.0.0
> x_sf = rmapshaper::ms_simplify(lnd[1:3, ], 0.01)
> #> Registered S3 method overwritten by 'geojsonlint':
> #>   method         from
> #>   print.location dplyr
> x_sp = sf::as_Spatial(x_sf)
> geo_to_char = function(x) {
>   if(!is(object = x, class2 = "sf")) {
>     x = sf::st_as_sf(x)
>   }
>   sf::st_as_text(sf::st_geometry(x))
> }
> geo_to_char(x_sf)
> #> [1] "POLYGON ((-0.3306791 51.32901, -0.3305339 51.34842, -0.3086951
> 51.37545, -0.3177201 51.39367, -0.3096538 51.40001, -0.3060304 51.42123,
> -0.2866189 51.42017, -0.2540906 51.43729, -0.2446848 51.40423, -0.2474248
> 51.39758, -0.2387446 51.38609, -0.2608406 51.37956, -0.2854616 51.36425,
> -0.3039032 51.34325, -0.3057101 51.33541, -0.3193073 51.32781, -0.3306791
> 51.32901))"
>
>
>
> #> [2] "POLYGON ((-0.0785486 51.41985, -0.0689427 51.40418, -0.0427724
> 51.38945, -0.0369519 51.37701, -0.0053322 51.35268, 0.0022661 51.32914,
> -0.0251301 51.33861, -0.0379184 51.33871, -0.0478549 51.32651, -0.0641537
> 51.31863, -0.0848293 51.31587, -0.0943518 51.29936, -0.1243197 51.28676,
> -0.1373403 51.30078, -0.155344 51.30128, -0.1619055 51.31963, -0.1444548
> 51.32648, -0.1475475 51.33878, -0.1275566 51.34745, -0.1169191 51.34575,
> -0.1233396 51.37119, -0.1337986 51.39127, -0.1245223 51.39741, -0.1324811
> 51.40841, -0.1126856 51.42324, -0.0785486 51.41985))"
>
> #> [3] "POLYGON ((0.0022661 51.32914, -0.0053322 51.35268, -0.0369519
> 51.37701, -0.0427724 51.38945, -0.0689427 51.40418, -0.0785486 51.41985,
> -0.0748669 51.4258, -0.0436909 51.42291, -0.0301069 51.42565, -0.0105455
> 51.41355, 0.0254105 51.42899, 0.0398142 51.44099, 0.0585966 51.42459,
> 0.0753431 51.43199, 0.1124939 51.41317, 0.134136 51.41385, 0.1488766
> 51.40848, 0.1598909 51.39465, 0.1498092 51.39087, 0.1532098 51.37804,
> 0.1362526 51.34555, 0.1166538 51.3413, 0.1202182 51.33214, 0.1047428
> 51.32734, 0.0850008 51.31602, 0.0856654 51.29309, 0.0584828 51.28936,
> 0.0457041 51.29401, 0.0328814 51.30752, 0.0149821 51.29179, 0.0022661
> 51.32914))"
> geo_to_char(x_sp)
> #> [1] "POLYGON ((-0.3306791 51.32901, -0.3305339 51.34842, -0.3086951
> 51.37545, -0.3177201 51.39367, -0.3096538 51.40001, -0.3060304 51.42123,
> -0.2866189 51.42017, -0.2540906 51.43729, -0.2446848 51.40423, -0.2474248
> 51.39758, -0.2387446 51.38609, -0.2608406 51.37956, -0.2854616 51.36425,
> -0.3039032 51.34325, -0.3057101 51.33541, -0.3193073 51.32781, -0.3306791
> 51.32901))"
>
>
>
> #> [2] "POLYGON ((-0.0785486 51.41985, -0.0689427 51.40418, -0.0427724
> 51.38945, -0.0369519 51.37701, -0.0053322 51.35268, 0.0022661 51.32914,
> -0.0251301 51.33861, -0.0379184 51.33871, -0.0478549 51.32651, -0.0641537
> 51.31863, -0.0848293 51.31587, -0.0943518 51.29936, -0.1243197 51.28676,
> -0.1373403 51.30078, -0.155344 51.30128, -0.1619055 51.31963, -0.1444548
> 51.32648, -0.1475475 51.33878, -0.1275566 51.34745, -0.1169191 51.34575,
> -0.1233396 51.37119, -0.1337986 51.39127, -0.1245223 51.39741, -0.1324811
> 51.40841, -0.1126856 51.42324, -0.0785486 51.41985))"
>
> #> [3] "POLYGON ((0.0022661 51.32914, -0.0053322 51.35268, -0.0369519
> 51.37701, -0.0427724 51.38945, -0.0689427 51.40418, -0.0785486 51.41985,
> -0.0748669 51.4258, -0.0436909 51.42291, -0.0301069 51.42565, -0.0105455
> 51.41355, 0.0254105 51.42899, 0.0398142 51.44099, 0.0585966 51.42459,
> 0.0753431 51.43199, 0.1124939 51.41317, 0.134136 51.41385, 0.1488766
> 51.40848, 0.1598909 51.39465, 0.1498092 51.39087, 0.1532098 51.37804,
> 0.1362526 51.34555, 0.1166538 51.3413, 0.1202182 51.33214, 0.1047428
> 51.32734, 0.0850008 51.31602, 0.0856654 51.29309, 0.0584828 51.28936,
> 0.0457041 51.29401, 0.0328814 51.30752, 0.0149821 51.29179, 0.0022661
> 51.32914))"
> ```
>
> <sup>Created on 2020-09-02 by the [reprex package](
> https://reprex.tidyverse.org) (v0.3.0)</sup>
>
> On Wed, Sep 2, 2020 at 1:25 PM Matteo Mattiuzzi <matteo at mattiuzzi.com>
> wrote:
>
>> Dear list,
>>
>> I have recently submitted a little R package to CRAN (now waiting for
>> approval) https://github.com/MatMatt/clmsapi.
>> The package is a R client for downloading data from the Copernicus Land
>> Monitoring Service (https://cryo.land.copernicus.eu/finder/).
>>
>> The API expects a parameter called 'geometry' with the following
>> formatting
>> (character):
>> 'POLYGON((lon+lat,lon+lat,lon+lat, ... ))' # commas are replaced with
>> ascii
>> '%2C' in the query string
>> or
>> 'POINT(lon+lat)'
>> see also here:
>> https://cryo.land.copernicus.eu/resto/api/collections/HRSI/describe.xml
>>
>> I could expect users to prepare the geometry parameter as it is needed by
>> the API, but I would prefer to improve the user friendliness by adding
>> some
>> functionalities (similar as in the MODIS package) that can convert from
>> different spatial extent objects/classes to the needed character string
>> (in
>> clmsapi::composeUrl).
>>
>> What is the best way to implement that? What are the classes I should
>> consider as input for the geometry parameter? (i.e. well established and
>> well supplied with conversion-functions).
>>
>> Thanks and kind regards, Matteo
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@  Tue Sep  8 18:33:08 2020
From: ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@ (Julian M. Burgos)
Date: Tue, 08 Sep 2020 16:33:08 +0000
Subject: [R-sig-Geo] stars analogous of raster::aggregate
Message-ID: <xgz363sw7nf.fsf@hafogvatn.is>

Dear all,

The raster package has the raster::aggregate function that can be used to reduce the resolution of a raster by aggregating cells by a specific factor. For example, this reduces the resolution of the L7_ETMs.tif raster by a factor of 10:

library(raster)

rst1 <-  raster(system.file("tif/L7_ETMs.tif", package = "stars"))

rst2 <- aggregate(rst1, fact = 10, fun = mean)

> res(rst1)
[1] 28.5 28.5

> res(rst2)
[1] 285 285

I am trying to do the same thing with a stars object.  The stars package has the stars::aggregate function, but for spatial aggregation it takes an object of class sf or sfc, so it is meant to be used for aggregation over polygons.  I could do something like this:

library(stars)
st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
  slice(band, 1)
grid <- st_make_grid(st_bbox(st1) %>%
                     st_as_sfc(),
                     cellsize = 285)

st2 <- aggregate(st1, grid, mean)

But the resulting st2 object is not a raster (i.e. does not X and Y dimensions), but instead has a single dimension and contains the geometries of the grid polygons.

> st1
stars object with 2 dimensions and 1 attribute
attribute(s):
  L7_ETMs.tif
 Min.   : 47.00
 1st Qu.: 67.00
 Median : 78.00
 Mean   : 79.15
 3rd Qu.: 89.00
 Max.   :255.00
dimension(s):
  from  to  offset delta                       refsys point values
x    1 349  288776  28.5 UTM Zone 25, Southern Hem... FALSE   NULL [x]
y    1 352 9120761 -28.5 UTM Zone 25, Southern Hem... FALSE   NULL [y]
> st2
stars object with 1 dimensions and 1 attribute
attribute(s):
  L7_ETMs.tif
 Min.   : 57.76
 1st Qu.: 69.22
 Median : 79.04
 Mean   : 79.09
 3rd Qu.: 87.63
 Max.   :123.51
dimension(s):
         from   to offset delta                       refsys point
geometry    1 1260     NA    NA UTM Zone 25, Southern Hem... FALSE
                                                                    values
geometry POLYGON ((288776.3 9110729,...,...,POLYGON ((298466.3 9120704,...
>

So I am stuck, wondering if perhaps st_apply is the answer.  What would be the best way to replicate what the raster::aggregate function does using stars?  Any ideas?

Many thanks,

Julian

--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
  Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
www.hafogvatn.is
S?mi/Telephone : +354-5752037
Netfang/Email: julian.burgos at hafogvatn.is
rr


From t@v|b@r @end|ng |rom gm@||@com  Tue Sep  8 20:47:17 2020
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 8 Sep 2020 21:47:17 +0300
Subject: [R-sig-Geo] stars analogous of raster::aggregate
In-Reply-To: <xgz363sw7nf.fsf@hafogvatn.is>
References: <xgz363sw7nf.fsf@hafogvatn.is>
Message-ID: <e11451b4-e418-7985-e37b-f7d00e8c0858@gmail.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200908/f7858679/attachment.html>

From edzer@pebe@m@ @end|ng |rom un|-muen@ter@de  Tue Sep  8 22:24:53 2020
From: edzer@pebe@m@ @end|ng |rom un|-muen@ter@de (Edzer Pebesma)
Date: Tue, 8 Sep 2020 22:24:53 +0200
Subject: [R-sig-Geo] stars analogous of raster::aggregate
In-Reply-To: <e11451b4-e418-7985-e37b-f7d00e8c0858@gmail.com>
References: <xgz363sw7nf.fsf@hafogvatn.is>
 <e11451b4-e418-7985-e37b-f7d00e8c0858@gmail.com>
Message-ID: <78878cf0-ee65-3e8b-42fd-a74d1daa729b@uni-muenster.de>



On 9/8/20 8:47 PM, Micha Silver wrote:
> 
> On 08/09/2020 19:33, Julian M. Burgos wrote:
>> Dear all,
>>
>> The raster package has the raster::aggregate function that can be used to reduce the resolution of a raster by aggregating cells by a specific factor. For example, this reduces the resolution of the L7_ETMs.tif raster by a factor of 10:
>>
>> library(raster)
>>
>> rst1 <-  raster(system.file("tif/L7_ETMs.tif", package = "stars"))
>>
>> rst2 <- aggregate(rst1, fact = 10, fun = mean)
>>
>>> res(rst1)
>> [1] 28.5 28.5
>>
>>> res(rst2)
>> [1] 285 285
>>
>> I am trying to do the same thing with a stars object.  The stars package has the stars::aggregate function, but for spatial aggregation it takes an object of class sf or sfc, so it is meant to be used for aggregation over polygons.  I could do something like this:
> 
> Probably st_warp() is what you want:
> 
> 
> l7_file = system.file("tif/L7_ETMs.tif", package = "stars")
> l7 = read_stars(l7_file)
> 
> l7_lowres = st_warp(src = l7, cellsize = c(90, 90), crs = st_crs(l7))
> 
> 
> stars::st_dimensions(l7)
>  ???? from? to? offset delta?????????????????????? refsys point values
> x?????? 1 349? 288776? 28.5 +proj=utm +zone=25 +south... FALSE NULL [x]
> y?????? 1 352 9120761 -28.5 +proj=utm +zone=25 +south... FALSE NULL [y]
> band??? 1?? 6????? NA??? NA?????????????????????????? NA??? NA NULL
> 
> 
> stars::st_dimensions(l7_lowres)
>  ???? from? to? offset delta?????????????????????? refsys point values
> x?????? 1 111? 288776??? 90 +proj=utm +zone=25 +south...??? NA NULL [x]
> y?????? 1 112 9120761?? -90 +proj=utm +zone=25 +south...??? NA NULL [y]
> band??? 1?? 6????? NA??? NA?????????????????????????? NA??? NA NULL

Yes; if you want to get similar behaviour as raster, choose a cell size 
that is an exact multiple of the origin's cell size, use_gdal = TRUE, 
and method = "average"; this currently seems to only work for single 
band rasters; along these lines:

library(stars)
# Loading required package: abind
# Loading required package: sf
# Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 7.0.0
l7_file = system.file("tif/L7_ETMs.tif", package = "stars")
l7 = read_stars(l7_file)
(dest = st_as_stars(st_bbox(l7), dx = 90, dy = 90))
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#     values
#  Min.   :0
#  1st Qu.:0
#  Median :0
#  Mean   :0
#  3rd Qu.:0
#  Max.   :0
# dimension(s):
#   from  to  offset delta                       refsys point values x/y
# x    1 111  288776    90 UTM Zone 25, Southern Hem...    NA   NULL [x]
# y    1 112 9120761   -90 UTM Zone 25, Southern Hem...    NA   NULL [y]
(l7_lowres = st_warp(src = l7[,,,1], dest = dest, use_gdal = TRUE, 
method = "average"))
# stars object with 2 dimensions and 1 attribute
# attribute(s):
#  file14bb5c7321dc.tif
#  Min.   : 56.81
#  1st Qu.: 68.75
#  Median : 79.00
#  Mean   : 79.25
#  3rd Qu.: 88.62
#  Max.   :207.44
# dimension(s):
#   from  to  offset delta                       refsys point values x/y
# x    1 111  288776    90 UTM Zone 25, Southern Hem... FALSE   NULL [x]
# y    1 112 9120761   -90 UTM Zone 25, Southern Hem... FALSE   NULL [y]

> 
> 
> -- 
> Micha Silver
> Ben Gurion Univ.
> Sde Boker, Remote Sensing Lab
> cell: +972-523-665918
> https://orcid.org/0000-0002-1128-1325
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48149 Muenster, Germany
Phone: +49 251 8333081


From ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@  Wed Sep  9 13:10:52 2020
From: ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@ (Julian M. Burgos)
Date: Wed, 09 Sep 2020 11:10:52 +0000
Subject: [R-sig-Geo] stars analogous of raster::aggregate
In-Reply-To: <78878cf0-ee65-3e8b-42fd-a74d1daa729b@uni-muenster.de>
References: <xgz363sw7nf.fsf@hafogvatn.is>
 <e11451b4-e418-7985-e37b-f7d00e8c0858@gmail.com>
 <78878cf0-ee65-3e8b-42fd-a74d1daa729b@uni-muenster.de>
Message-ID: <xgz8sdjb3yb.fsf@hafogvatn.is>

Thanks Edzer and Micha, this was very helpful.  st_warp with use_gdal=TRUE worked like a charm.

My best,

Julian


Edzer Pebesma writes:

> On 9/8/20 8:47 PM, Micha Silver wrote:
>> On 08/09/2020 19:33, Julian M. Burgos wrote:
>>> Dear all,
>>>
>>> The raster package has the raster::aggregate function that can be used to reduce the resolution of a raster by aggregating cells by a specific factor. For example, this reduces the resolution of the L7_ETMs.tif raster by a factor of 10:
>>>
>>> library(raster)
>>>
>>> rst1 <-  raster(system.file("tif/L7_ETMs.tif", package = "stars"))
>>>
>>> rst2 <- aggregate(rst1, fact = 10, fun = mean)
>>>
>>>> res(rst1)
>>> [1] 28.5 28.5
>>>
>>>> res(rst2)
>>> [1] 285 285
>>>
>>> I am trying to do the same thing with a stars object.  The stars package has the stars::aggregate function, but for spatial aggregation it takes an object of class sf or sfc, so it is meant to be used for aggregation over polygons.  I could do something like this:
>> Probably st_warp() is what you want:
>>
>> l7_file = system.file("tif/L7_ETMs.tif", package = "stars")
>> l7 = read_stars(l7_file)
>> l7_lowres = st_warp(src = l7, cellsize = c(90, 90), crs =
>> st_crs(l7))
>>
>> stars::st_dimensions(l7)
>>       from  to  offset delta                       refsys point values
>> x       1 349  288776  28.5 +proj=utm +zone=25 +south... FALSE NULL [x]
>> y       1 352 9120761 -28.5 +proj=utm +zone=25 +south... FALSE NULL [y]
>> band    1   6      NA    NA                           NA    NA NULL
>>
>> stars::st_dimensions(l7_lowres)
>>       from  to  offset delta                       refsys point values
>> x       1 111  288776    90 +proj=utm +zone=25 +south...    NA NULL [x]
>> y       1 112 9120761   -90 +proj=utm +zone=25 +south...    NA NULL [y]
>> band    1   6      NA    NA                           NA    NA NULL
>
> Yes; if you want to get similar behaviour as raster, choose a cell
> size that is an exact multiple of the origin's cell size, use_gdal =
> TRUE, and method = "average"; this currently seems to only work for
> single band rasters; along these lines:
>
> library(stars)
> # Loading required package: abind
> # Loading required package: sf
> # Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 7.0.0
> l7_file = system.file("tif/L7_ETMs.tif", package = "stars")
> l7 = read_stars(l7_file)
> (dest = st_as_stars(st_bbox(l7), dx = 90, dy = 90))
> # stars object with 2 dimensions and 1 attribute
> # attribute(s):
> #     values
> #  Min.   :0
> #  1st Qu.:0
> #  Median :0
> #  Mean   :0
> #  3rd Qu.:0
> #  Max.   :0
> # dimension(s):
> #   from  to  offset delta                       refsys point values x/y
> # x    1 111  288776    90 UTM Zone 25, Southern Hem...    NA   NULL [x]
> # y    1 112 9120761   -90 UTM Zone 25, Southern Hem...    NA   NULL [y]
> (l7_lowres = st_warp(src = l7[,,,1], dest = dest, use_gdal = TRUE,
> method = "average"))
> # stars object with 2 dimensions and 1 attribute
> # attribute(s):
> #  file14bb5c7321dc.tif
> #  Min.   : 56.81
> #  1st Qu.: 68.75
> #  Median : 79.00
> #  Mean   : 79.25
> #  3rd Qu.: 88.62
> #  Max.   :207.44
> # dimension(s):
> #   from  to  offset delta                       refsys point values x/y
> # x    1 111  288776    90 UTM Zone 25, Southern Hem... FALSE   NULL [x]
> # y    1 112 9120761   -90 UTM Zone 25, Southern Hem... FALSE   NULL [y]
>
>>
>> -- Micha Silver
>> Ben Gurion Univ.
>> Sde Boker, Remote Sensing Lab
>> cell: +972-523-665918
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Forcid.org%2F0000-0002-1128-1325&amp;data=02%7C01%7C%7Cb8b83838082f41ad457c08d854354350%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C637351935026744294&amp;sdata=K5kMOHf6dka1eNJrVRZsgDe0UmxTEhBRU40C%2FPpRXVE%3D&amp;reserved=0
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&amp;data=02%7C01%7C%7Cb8b83838082f41ad457c08d854354350%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C637351935026744294&amp;sdata=KwymhTSAHdcBDVffZHhp2xZ%2BQUzDKh%2B%2BN2DP1yLtGY4%3D&amp;reserved=0
>>


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
  Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
www.hafogvatn.is
S?mi/Telephone : +354-5752037
Netfang/Email: julian.burgos at hafogvatn.is


From edzer@pebe@m@ @end|ng |rom un|-muen@ter@de  Wed Sep  9 22:43:09 2020
From: edzer@pebe@m@ @end|ng |rom un|-muen@ter@de (Edzer Pebesma)
Date: Wed, 9 Sep 2020 22:43:09 +0200
Subject: [R-sig-Geo] stars analogous of raster::aggregate
In-Reply-To: <xgz8sdjb3yb.fsf@hafogvatn.is>
References: <xgz363sw7nf.fsf@hafogvatn.is>
 <e11451b4-e418-7985-e37b-f7d00e8c0858@gmail.com>
 <78878cf0-ee65-3e8b-42fd-a74d1daa729b@uni-muenster.de>
 <xgz8sdjb3yb.fsf@hafogvatn.is>
Message-ID: <4a3289c9-6cde-732e-100f-fb86d49a2d63@uni-muenster.de>

It now also works for multi-band rasters (fixed in sf when installed 
from github): https://github.com/r-spatial/stars/issues/320

On 9/9/20 1:10 PM, Julian M. Burgos wrote:
> Thanks Edzer and Micha, this was very helpful.  st_warp with use_gdal=TRUE worked like a charm.
> 
> My best,
> 
> Julian
> 
> 
> Edzer Pebesma writes:
> 
>> On 9/8/20 8:47 PM, Micha Silver wrote:
>>> On 08/09/2020 19:33, Julian M. Burgos wrote:
>>>> Dear all,
>>>>
>>>> The raster package has the raster::aggregate function that can be used to reduce the resolution of a raster by aggregating cells by a specific factor. For example, this reduces the resolution of the L7_ETMs.tif raster by a factor of 10:
>>>>
>>>> library(raster)
>>>>
>>>> rst1 <-  raster(system.file("tif/L7_ETMs.tif", package = "stars"))
>>>>
>>>> rst2 <- aggregate(rst1, fact = 10, fun = mean)
>>>>
>>>>> res(rst1)
>>>> [1] 28.5 28.5
>>>>
>>>>> res(rst2)
>>>> [1] 285 285
>>>>
>>>> I am trying to do the same thing with a stars object.  The stars package has the stars::aggregate function, but for spatial aggregation it takes an object of class sf or sfc, so it is meant to be used for aggregation over polygons.  I could do something like this:
>>> Probably st_warp() is what you want:
>>>
>>> l7_file = system.file("tif/L7_ETMs.tif", package = "stars")
>>> l7 = read_stars(l7_file)
>>> l7_lowres = st_warp(src = l7, cellsize = c(90, 90), crs =
>>> st_crs(l7))
>>>
>>> stars::st_dimensions(l7)
>>>        from  to  offset delta                       refsys point values
>>> x       1 349  288776  28.5 +proj=utm +zone=25 +south... FALSE NULL [x]
>>> y       1 352 9120761 -28.5 +proj=utm +zone=25 +south... FALSE NULL [y]
>>> band    1   6      NA    NA                           NA    NA NULL
>>>
>>> stars::st_dimensions(l7_lowres)
>>>        from  to  offset delta                       refsys point values
>>> x       1 111  288776    90 +proj=utm +zone=25 +south...    NA NULL [x]
>>> y       1 112 9120761   -90 +proj=utm +zone=25 +south...    NA NULL [y]
>>> band    1   6      NA    NA                           NA    NA NULL
>>
>> Yes; if you want to get similar behaviour as raster, choose a cell
>> size that is an exact multiple of the origin's cell size, use_gdal =
>> TRUE, and method = "average"; this currently seems to only work for
>> single band rasters; along these lines:
>>
>> library(stars)
>> # Loading required package: abind
>> # Loading required package: sf
>> # Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 7.0.0
>> l7_file = system.file("tif/L7_ETMs.tif", package = "stars")
>> l7 = read_stars(l7_file)
>> (dest = st_as_stars(st_bbox(l7), dx = 90, dy = 90))
>> # stars object with 2 dimensions and 1 attribute
>> # attribute(s):
>> #     values
>> #  Min.   :0
>> #  1st Qu.:0
>> #  Median :0
>> #  Mean   :0
>> #  3rd Qu.:0
>> #  Max.   :0
>> # dimension(s):
>> #   from  to  offset delta                       refsys point values x/y
>> # x    1 111  288776    90 UTM Zone 25, Southern Hem...    NA   NULL [x]
>> # y    1 112 9120761   -90 UTM Zone 25, Southern Hem...    NA   NULL [y]
>> (l7_lowres = st_warp(src = l7[,,,1], dest = dest, use_gdal = TRUE,
>> method = "average"))
>> # stars object with 2 dimensions and 1 attribute
>> # attribute(s):
>> #  file14bb5c7321dc.tif
>> #  Min.   : 56.81
>> #  1st Qu.: 68.75
>> #  Median : 79.00
>> #  Mean   : 79.25
>> #  3rd Qu.: 88.62
>> #  Max.   :207.44
>> # dimension(s):
>> #   from  to  offset delta                       refsys point values x/y
>> # x    1 111  288776    90 UTM Zone 25, Southern Hem... FALSE   NULL [x]
>> # y    1 112 9120761   -90 UTM Zone 25, Southern Hem... FALSE   NULL [y]
>>
>>>
>>> -- Micha Silver
>>> Ben Gurion Univ.
>>> Sde Boker, Remote Sensing Lab
>>> cell: +972-523-665918
>>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Forcid.org%2F0000-0002-1128-1325&amp;data=02%7C01%7C%7Cb8b83838082f41ad457c08d854354350%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C637351935026744294&amp;sdata=K5kMOHf6dka1eNJrVRZsgDe0UmxTEhBRU40C%2FPpRXVE%3D&amp;reserved=0
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&amp;data=02%7C01%7C%7Cb8b83838082f41ad457c08d854354350%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C637351935026744294&amp;sdata=KwymhTSAHdcBDVffZHhp2xZ%2BQUzDKh%2B%2BN2DP1yLtGY4%3D&amp;reserved=0
>>>
> 
> 
> --
> Julian Mariano Burgos, PhD
> Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
> Marine and Freshwater Research Institute
> Botnsj?varsvi?s / Demersal Division
>    Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
> www.hafogvatn.is
> S?mi/Telephone : +354-5752037
> Netfang/Email: julian.burgos at hafogvatn.is
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48149 Muenster, Germany
Phone: +49 251 8333081


From r@i@1290 m@iii@g oii @im@com  Fri Sep 11 02:25:26 2020
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Fri, 11 Sep 2020 00:25:26 +0000 (UTC)
Subject: [R-sig-Geo] Calculating return level with return period
References: <2095140618.2811778.1599783926269.ref@mail.yahoo.com>
Message-ID: <2095140618.2811778.1599783926269@mail.yahoo.com>

Hi there,
I am trying to compute return levels for a certain return period (20 years) for my extreme precipitation. Using the block maxima approach, I made the following object:
? ? Gcomb <- c(Gmax[1], Gmax1[1], Gmax2[1], Gmax3[1], Gmax4[1], Gmax5[1], Gmax6[1], Gmax7[1], Gmax8[1],?? ? Gmax[2], Gmax1[2], Gmax2[2], Gmax3[2], Gmax4[2], Gmax5[2], Gmax6[2], Gmax7[2], Gmax8[2], Gmax[3],?? ? Gmax1[3], Gmax2[3], Gmax3[3], Gmax4[3], Gmax5[3], Gmax6[3], Gmax7[3], Gmax8[3], Gmax[4], Gmax1[4],?? ? Gmax2[4], Gmax3[4], Gmax4[4], Gmax5[4], Gmax6[4], Gmax7[4], Gmax8[4], Gmax[5], Gmax1[5], Gmax2[5],?? ? Gmax3[5], Gmax4[5], Gmax5[5], Gmax6[5], Gmax7[5], Gmax8[5], Gmax[6], Gmax1[6], Gmax2[6], Gmax3[6],?? ? Gmax4[6], Gmax5[6], Gmax6[6], Gmax7[6], Gmax8[6], Gmax[7], Gmax1[7], Gmax2[7], Gmax3[7], Gmax4[7],?? ? Gmax5[7], Gmax6[7], Gmax7[7], Gmax8[7])
Now, when I try to compute the return level (a 20-year return level):
? ? return.level.fevd(Gcomb, return.period = 20)
I end up with the following error:
? ? Error: $ operator is invalid for atomic vectors
Why is this error showing up? Is there any way to avoid this?
Thanks, and any help would be greatly appreciated!
	[[alternative HTML version deleted]]


From ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@  Mon Sep 14 16:39:39 2020
From: ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@ (Julian M. Burgos)
Date: Mon, 14 Sep 2020 14:39:39 +0000
Subject: [R-sig-Geo] stars objects and case_when
Message-ID: <xgzo8m8s9qs.fsf@hafogvatn.is>

Dear list,

I am wondering if there is a way to use logical statements to replace values of a stars object, for example the case_when function or some other "tidyverse friendly" approach.  For example, I can do something like this:

st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
  slice(band, 1)

st1[st1 < 100] <- NA
st1[st1 > 100 & st1 < 150] <- 2

... and so for.  But I am wondering if there is a way to do this as part of a pipe, looking something like this:

st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
  slice(band, 1) %>%
  mutate(x <- case_when (x<100 ~ NA,
                         x>100 & x<150 ~ 2))

Any ideas?

Takk,

Julian

--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
  Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
www.hafogvatn.is
S?mi/Telephone : +354-5752037
Netfang/Email: julian.burgos at hafogvatn.is


From eg@mp@du @end|ng |rom gm@||@com  Mon Sep 14 17:48:32 2020
From: eg@mp@du @end|ng |rom gm@||@com (Enoch Gyamfi Ampadu)
Date: Mon, 14 Sep 2020 17:48:32 +0200
Subject: [R-sig-Geo] Error image
Message-ID: <CAC4+n+xU+MU24u3WwYH96nfCRsxQEg_+aNBGyN098WE1i07ydg@mail.gmail.com>

Dear List,

Please I am undertaking land cover classification with the support vector
machine but output image have some portions appearing white. I have tried
both the *caret *and *e1071, *yet I got the same error image. Find below
the codes:

Caret package
modFit_svmR1999 <- train(as.factor(class) ~ B1 + B2 + B3 + B4 + B5 + B7,
data = TrainSet1999, method = "svmRadial")

e1071 package
modFit_svmR1999 <- svm(as.factor(class) ~ B1 + B2 + B3 + B4 + B5 + B7, data
= TrainSet1999)

Before running the above codes, I had done all the necessary image staking,
extracting of pixel values and data partitioning. I don't know what I am
not doing right and I will be glad to have some assistance.
Thank you

Best regards,
Enoch

-- 
*Enoch Gyamfi - Ampadu*

*Geography & Environmental Sciences*

*College of Agriculture, Engineering & Science*

*University of KwaZulu-Natal, Westville Campus*

*Private Bag X54001*
*Durban, South Africa **? 4000**.*
*Phone: +27 835 828255*

*email: egampadu at gmail.com <egampadu at gmail.com>*


*skype: enoch.ampadu*
*The highest evidence of nobility is self-control*.

*A simple act of kindness creates an endless ripple*.

	[[alternative HTML version deleted]]


From g@M@rt|ne||| @end|ng |rom gmx@|r  Mon Sep 14 18:40:05 2020
From: g@M@rt|ne||| @end|ng |rom gmx@|r (Gaetan Martinelli)
Date: Mon, 14 Sep 2020 18:40:05 +0200
Subject: [R-sig-Geo] Stack of several Raster
Message-ID: <trinity-35f0ec13-f793-4d99-8cd0-20bce9e9d7b6-1600101605764@3c-app-mailcom-bs04>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200914/7ac108f4/attachment.html>

From b|@|ev||@t @end|ng |rom gm@||@com  Mon Sep 14 19:12:26 2020
From: b|@|ev||@t @end|ng |rom gm@||@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Mon, 14 Sep 2020 19:12:26 +0200
Subject: [R-sig-Geo] Stack of several Raster
In-Reply-To: <trinity-35f0ec13-f793-4d99-8cd0-20bce9e9d7b6-1600101605764@3c-app-mailcom-bs04>
References: <trinity-35f0ec13-f793-4d99-8cd0-20bce9e9d7b6-1600101605764@3c-app-mailcom-bs04>
Message-ID: <a7662584-e4c8-16ac-912b-2d71c2ff43b3@gmail.com>

Dear Ga?tan,

"order of appearance of my different columns corresponding to my 366 
files (1 year) does not make any sense": do you mean that the order of 
the columns in TMAX60 is not what you want? The column order should 
match the order of the layers in your RasterStack. You can check it with:
names(s)
The order of the layers will correspond to the list of file names stored 
in fs. So you should arrange the file names in the appropriate order, 
and then you'll get columns in TMAX60 in the desired order. Maybe not 
list.files() is the best fuction to use. If the file names follow a 
regular pattern, then you can simply create the character vector of the 
file names with paste() or paste0().

HTH,
?kos Bede-FAzekas
Hungarian Academy of Sciences


2020.09.14. 18:40 keltez?ssel, Gaetan Martinelli ?rta:
> Good morning all,
>
>
> I would need some advice to move forward.
> I'm starting to use Rstudio?to manipulate a climate data and intersect 
> with a differents points on my map (table of 1000 points with 6 
> attributes).
> Also, I have several raster.?I have an ASCII file for each day of a 
> year. For 30 years.
>
>
> I tried to use the Stack function and then make the intersection with 
> my 1000 points for one year :
> fs <- list.files(path="N:/Climate-10km/Max_T/1960",
> ? ? ? ? ? ? ? ? ?pattern = "asc$", full.names = TRUE)
> s <- raster::stack(fs)
> TMAX60 <- extract(s, DataPoints)
> I'm stuck just at this part ...
> My intersection is good, but the order of appearance of my different 
> columns corresponding to my 366 files (1 year) does not make any 
> sense. They are out of order.
>
> My goal is to create a table with my 6 points attributes, and add a 
> "Year" column and a "Days" column and finally a "Pixel values" column. 
> For a year at first time?and if possible doing this intersection?for 
> all my years.
> I had the idea to do this for each year and then join my different 
> produced tables.
> In the end, I would have a huge table, but one that will allow me to 
> do my analysis. By calculating this, I will get:
> - 9 attributes (6 attributs points, Year, Day, TMax) and 10 980 000 
> lines (30 years (past) * 366 days * 1000?points).
> Does this seem like a good approach to you ?
> Do you have an idea that could allow me to do this task without going 
> through multiple table operations with "Dplyr" ?
>
> Do you have any advice for a better approach I could take?
>
> Sorry if my English is not always appropriate. I'm not very used to 
> talking in this language yet. I'm working on it. :)
>
> Thank you very much in advance to those who can help me.
>
> Have a good day.
>
> Ga?tan.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From cjohn @end|ng |rom ucd@v|@@edu  Mon Sep 14 20:07:01 2020
From: cjohn @end|ng |rom ucd@v|@@edu (Christian John)
Date: Mon, 14 Sep 2020 11:07:01 -0700
Subject: [R-sig-Geo] proj.db can't be found when rgdal is loaded (sometimes)
Message-ID: <CAOs2R7shvkPMxJOhpcfdLA0ear5RLeKj4wLCW7E+njHvMb7H5w@mail.gmail.com>

Hi there folks,

I am running into problems using sf objects when rgdal has been loaded.
When I run:

Sys.getenv("PROJ_LIB")
library(sf); library(rnaturalearth); library(ggplot2)
Sys.getenv("PROJ_LIB")
ROI1 = ne_countries(returnclass = 'sf') %>%
  st_combine() %>%
  st_buffer(0.5)  %>%
  st_wrap_dateline()
ggplot() + geom_sf(data = ROI1)
library(rgdal)
Sys.getenv("PROJ_LIB")
ROI2 = ne_countries(returnclass = 'sf') %>%
  st_combine() %>%
  st_buffer(0.5)  %>%
  st_wrap_dateline()
ggplot() + geom_sf(data = ROI2)

everything plots fine. The sf startup message is:

Linking to GEOS 3.8.1, GDAL 3.1.2, PROJ 7.1.1

The PROJ_LIB changes upon loading rgdal from "" to
"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/proj".
Loading rgdal generates the message:

Loading required package: sp
rgdal: version: 1.5-16, (SVN revision 1050)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 2.4.2, released 2019/06/28
Path to GDAL shared files:
/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/gdal
GDAL binary built with GEOS: FALSE
Loaded PROJ runtime: Rel. 5.2.0, September 15th, 2018, [PJ_VERSION: 520]
Path to PROJ shared files:
/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/proj
Linking to sp version:1.4-2
Overwritten PROJ_LIB was
/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/proj
Warning message:
package ?rgdal? was built under R version 3.6.2

which explains the update in the PROJ_LIB. Notably, the gdal and proj
runtime in the rgdal startup message are completely different from the sf
versions. If I run:

Sys.getenv("PROJ_LIB")
library(sf); library(rnaturalearth); library(ggplot2)
Sys.getenv("PROJ_LIB")
library(rgdal)
Sys.getenv("PROJ_LIB")
ROI2 = ne_countries(returnclass = 'sf') %>%
  st_combine() %>%
  st_buffer(0.5)  %>%
  st_wrap_dateline()
ggplot() + geom_sf(data = ROI2)

which is the same as above, but without the ROI1 generation and plotting, I
get a stack overflow error upon plotting ROI2. All other messages are the
same, except when I run the ggplot() line, I get:

Error: node stack overflow
In addition: There were 50 or more warnings (use warnings() to see the
first 50)
Error during wrapup: node stack overflow

Warnings 1:50 are all

1: In CPL_crs_from_input(x) :
  GDAL Error 1: PROJ: proj_create_from_database: Cannot find proj.db

So, it seems like loading rgdal before doing anything sf:: related causes
the issue. Any ideas for troubleshooting? Session info can be found below.

Best,
Christian

> sessionInfo()
R version 3.6.1 (2019-07-05)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK:
/Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgdal_1.5-16        sp_1.3-2            ggplot2_3.3.0
rnaturalearth_0.1.0
[5] sf_0.9-5

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.3         rstudioapi_0.10    magrittr_1.5       units_0.6-5

 [5] munsell_0.5.0      tidyselect_0.2.5   colorspace_1.4-1
lattice_0.20-38
 [9] R6_2.4.1           rlang_0.4.2        dplyr_0.8.3        tools_3.6.1

[13] grid_3.6.1         gtable_0.3.0       KernSmooth_2.23-15 e1071_1.7-3

[17] DBI_1.0.0          withr_2.1.2        rgeos_0.5-5        class_7.3-15

[21] assertthat_0.2.1   lifecycle_0.1.0    tibble_2.1.3       crayon_1.3.4

[25] purrr_0.3.3        glue_1.3.1         compiler_3.6.1     pillar_1.4.3

[29] scales_1.1.0       classInt_0.4-2     pkgconfig_2.0.3

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Mon Sep 14 20:45:45 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Mon, 14 Sep 2020 20:45:45 +0200
Subject: [R-sig-Geo] 
 proj.db can't be found when rgdal is loaded (sometimes)
In-Reply-To: <CAOs2R7shvkPMxJOhpcfdLA0ear5RLeKj4wLCW7E+njHvMb7H5w@mail.gmail.com>
References: <CAOs2R7shvkPMxJOhpcfdLA0ear5RLeKj4wLCW7E+njHvMb7H5w@mail.gmail.com>
Message-ID: <alpine.LFD.2.23.451.2009142032010.2172500@reclus.nhh.no>

On Mon, 14 Sep 2020, Christian John via R-sig-Geo wrote:

> Hi there folks,
>
> I am running into problems using sf objects when rgdal has been loaded.
> When I run:

The following is not a reprex. What we need is the output of:

> sf::sf_extSoftVersion()
           GEOS           GDAL         proj.4 GDAL_with_GEOS     USE_PROJ_H
        "3.8.1"        "3.1.3"        "7.1.1"         "true"         "true"
> rgdal::rgdal_extSoftVersion()
           GDAL GDAL_with_GEOS           PROJ             sp
        "3.1.3"         "TRUE"        "7.1.1"        "1.4-4"

(in my case). In your case, the PROJ seen by sf is 7.1.1, by rgdal is 
5.2.0. Loading rgdal after sf resets PROJ_LIB to the pre-PROJ 6 version. 
You appear to have installed rgdal binary from CRAN, but installed sf 
(using homebrew ?) and local GEOS/GDAL/PROJ. Either re-install rgdal to 
match, or re-install sf from CRAN as a binary. Installing CRAM MacOS 
binaries should ensure coherence. If problems persist, report back (and 
perhaps on R-sig-Mac, I have no way to check which GDAL/PROJ versions are 
bundled with CAN MacOS binaries.

We are exploring a shared GDAL/PROJ metadata package, but are stuck on the 
same problem - users do not take steps to keep their R packages cleanly 
built on external software, and package maintainers must expect a 
reasonable amount of insight from users.

This list has been given plenty of information that PROJ < 6 and PROJ >= 6 
are different universes, so mixing packages using both is not supported. 
In this case, sf needs proj.db, but cannot find it once rgdal has been 
loaded, pointing PROJ_LIB to a directory without it.

Roger


>
> Sys.getenv("PROJ_LIB")
> library(sf); library(rnaturalearth); library(ggplot2)
> Sys.getenv("PROJ_LIB")
> ROI1 = ne_countries(returnclass = 'sf') %>%
>  st_combine() %>%
>  st_buffer(0.5)  %>%
>  st_wrap_dateline()
> ggplot() + geom_sf(data = ROI1)
> library(rgdal)
> Sys.getenv("PROJ_LIB")
> ROI2 = ne_countries(returnclass = 'sf') %>%
>  st_combine() %>%
>  st_buffer(0.5)  %>%
>  st_wrap_dateline()
> ggplot() + geom_sf(data = ROI2)
>
> everything plots fine. The sf startup message is:
>
> Linking to GEOS 3.8.1, GDAL 3.1.2, PROJ 7.1.1
>
> The PROJ_LIB changes upon loading rgdal from "" to
> "/Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/proj".
> Loading rgdal generates the message:
>
> Loading required package: sp
> rgdal: version: 1.5-16, (SVN revision 1050)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 2.4.2, released 2019/06/28
> Path to GDAL shared files:
> /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/gdal
> GDAL binary built with GEOS: FALSE
> Loaded PROJ runtime: Rel. 5.2.0, September 15th, 2018, [PJ_VERSION: 520]
> Path to PROJ shared files:
> /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/proj
> Linking to sp version:1.4-2
> Overwritten PROJ_LIB was
> /Library/Frameworks/R.framework/Versions/3.6/Resources/library/rgdal/proj
> Warning message:
> package ?rgdal? was built under R version 3.6.2
>
> which explains the update in the PROJ_LIB. Notably, the gdal and proj
> runtime in the rgdal startup message are completely different from the sf
> versions. If I run:
>
> Sys.getenv("PROJ_LIB")
> library(sf); library(rnaturalearth); library(ggplot2)
> Sys.getenv("PROJ_LIB")
> library(rgdal)
> Sys.getenv("PROJ_LIB")
> ROI2 = ne_countries(returnclass = 'sf') %>%
>  st_combine() %>%
>  st_buffer(0.5)  %>%
>  st_wrap_dateline()
> ggplot() + geom_sf(data = ROI2)
>
> which is the same as above, but without the ROI1 generation and plotting, I
> get a stack overflow error upon plotting ROI2. All other messages are the
> same, except when I run the ggplot() line, I get:
>
> Error: node stack overflow
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
> Error during wrapup: node stack overflow
>
> Warnings 1:50 are all
>
> 1: In CPL_crs_from_input(x) :
>  GDAL Error 1: PROJ: proj_create_from_database: Cannot find proj.db
>
> So, it seems like loading rgdal before doing anything sf:: related causes
> the issue. Any ideas for troubleshooting? Session info can be found below.
>
> Best,
> Christian
>
>> sessionInfo()
> R version 3.6.1 (2019-07-05)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS Catalina 10.15.6
>
> Matrix products: default
> BLAS:
> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
> LAPACK:
> /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgdal_1.5-16        sp_1.3-2            ggplot2_3.3.0
> rnaturalearth_0.1.0
> [5] sf_0.9-5
>
> loaded via a namespace (and not attached):
> [1] Rcpp_1.0.3         rstudioapi_0.10    magrittr_1.5       units_0.6-5
>
> [5] munsell_0.5.0      tidyselect_0.2.5   colorspace_1.4-1
> lattice_0.20-38
> [9] R6_2.4.1           rlang_0.4.2        dplyr_0.8.3        tools_3.6.1
>
> [13] grid_3.6.1         gtable_0.3.0       KernSmooth_2.23-15 e1071_1.7-3
>
> [17] DBI_1.0.0          withr_2.1.2        rgeos_0.5-5        class_7.3-15
>
> [21] assertthat_0.2.1   lifecycle_0.1.0    tibble_2.1.3       crayon_1.3.4
>
> [25] purrr_0.3.3        glue_1.3.1         compiler_3.6.1     pillar_1.4.3
>
> [29] scales_1.1.0       classInt_0.4-2     pkgconfig_2.0.3
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From edzer@pebe@m@ @end|ng |rom un|-muen@ter@de  Mon Sep 14 20:46:14 2020
From: edzer@pebe@m@ @end|ng |rom un|-muen@ter@de (Edzer Pebesma)
Date: Mon, 14 Sep 2020 20:46:14 +0200
Subject: [R-sig-Geo] stars objects and case_when
In-Reply-To: <xgzo8m8s9qs.fsf@hafogvatn.is>
References: <xgzo8m8s9qs.fsf@hafogvatn.is>
Message-ID: <e9e30c79-5490-d296-bec8-0bc3f97fac8a@uni-muenster.de>

Thank you for pointing to this possibility, I'll add it to the stars 
docs somewhere.

This works but only slightly adapted, e.g. as

out = read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
   slice(band, 1) %>%
   setNames("x") %>%
   mutate(x = case_when (x<100 ~ NA_real_,   x>100 & x<150 ~ 2))

where:
- I uses setNames("x") so that the attribute is renamed to "x", and you 
can use x in the case_when expressions (rather than the lengthy 
"L7_ETMs.tif")
- I chnaged NA into NA_real_ : the first RHS of the formulas need to be 
all of the same type; as typeof(NA) is "logical", it breaks on the 
second RHS which returns a numeric; if you would TRUE or FALSE rather 
than 2 in the second case_when formula, using NA would be the right 
thing to do in the first.

The examples of case_when document the need for typed NA in RHS: this is 
intended behavior.


On 9/14/20 4:39 PM, Julian M. Burgos wrote:
> Dear list,
> 
> I am wondering if there is a way to use logical statements to replace values of a stars object, for example the case_when function or some other "tidyverse friendly" approach.  For example, I can do something like this:
> 
> st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
>    slice(band, 1)
> 
> st1[st1 < 100] <- NA
> st1[st1 > 100 & st1 < 150] <- 2
> 
> ... and so for.  But I am wondering if there is a way to do this as part of a pipe, looking something like this:
> 
> st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
>    slice(band, 1) %>%
>    mutate(x <- case_when (x<100 ~ NA,
>                           x>100 & x<150 ~ 2))
> 
> Any ideas?
> 
> Takk,
> 
> Julian
> 
> --
> Julian Mariano Burgos, PhD
> Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
> Marine and Freshwater Research Institute
> Botnsj?varsvi?s / Demersal Division
>    Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
> www.hafogvatn.is
> S?mi/Telephone : +354-5752037
> Netfang/Email: julian.burgos at hafogvatn.is
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48149 Muenster, Germany
Phone: +49 251 8333081


From j@|mebg27 @end|ng |rom gm@||@com  Mon Sep 14 22:41:43 2020
From: j@|mebg27 @end|ng |rom gm@||@com (=?UTF-8?Q?Jaime_Burbano_Gir=C3=B3n?=)
Date: Mon, 14 Sep 2020 15:41:43 -0500
Subject: [R-sig-Geo] "no applicable method" for focal() function in raster
Message-ID: <CADiqS85dfDSPK9DMB2d0KQ79HpsOJFTzykjrudVyJj7zeH27DQ@mail.gmail.com>

Hi everyone,

I want to apply a moving window (3x3) to estimate conditional entropy
(Nowosad & Stepinsky, 2019) over a heterogeneous landscape:
*entropy=function(r){*




*  entropy=lsm_l_condent(r, neighbourhood = 4, ordered = TRUE, base =
"log2")  return(entropy$value)}w=matrix(1,3,3)result=focal(r, w,
fun=entropy)*

However, I get this error:
*Error in .focal_fun(values(x), w, as.integer(dim(out)), runfun, NAonly) : *
*Evaluation error: no applicable method for 'lsm_l_condent' applied to an
object of class "c('double', 'numeric')".*

But, when I run entropy function in the entire landscape it works:

*> entropy(r)[1] 2.178874*

*r* is a INT4U raster object:






*class      : RasterLayer dimensions : 886, 999, 885114  (nrow, ncol,
ncell)resolution : 300, 300  (x, y)extent     : 934805.7, 1234506, 1006566,
1272366  (xmin, xmax, ymin, ymax)crs        : +proj=tmerc
+lat_0=4.59620041666667 +lon_0=-74.0775079166667 +k=1 +x_0=1000000
+y_0=1000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs values
  : 99, 321113  (min, max)*

There is any idea to solve the "no applicable method" error? Or any idea to
estimate conditional entropy applying a moving window?

Thanks in advance for the help.

Best,

Jaime

	[[alternative HTML version deleted]]


From P|etro_te|@to @end|ng |rom hotm@||@com  Mon Sep 14 22:57:15 2020
From: P|etro_te|@to @end|ng |rom hotm@||@com (Pietro Andre Telatin Paschoalino)
Date: Mon, 14 Sep 2020 20:57:15 +0000
Subject: [R-sig-Geo] Doubt about SPLM function
Message-ID: <BN8PR17MB29809A81F9D9DE488FB3E91582230@BN8PR17MB2980.namprd17.prod.outlook.com>

Hello everyone,

Could someone help me with splm (Spatial Panel Model By Maximum Likelihood) in R?

I want to know if is possible to cluster the standard errors by my individuals (like as in plm function). After a lot of research a found that there are more people with the same doubt, you can see this here, the person has the same problem as me:

https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm

Thank you all.

[https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded]<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>
r - Clustered Standard Errors in Spatial Panel Linear Models (splm) - Stack Overflow<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>
I am running spatial panel models (using splm) of census tracts in the U.S. between 1990 and 2010 with neighbor matrices based upon distance or contiguity. But I also want to cluster the standard e...
stackoverflow.com

Pietro Andre Telatin Paschoalino
Doutorando em Ci?ncias Econ?micas da Universidade Estadual de Maring? - PCE.

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>    Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>

	[[alternative HTML version deleted]]


From ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@  Tue Sep 15 13:51:48 2020
From: ju||@n@burgo@ @end|ng |rom h@|ogv@tn@|@ (Julian M. Burgos)
Date: Tue, 15 Sep 2020 11:51:48 +0000
Subject: [R-sig-Geo] stars objects and case_when
In-Reply-To: <e9e30c79-5490-d296-bec8-0bc3f97fac8a@uni-muenster.de>
References: <xgzo8m8s9qs.fsf@hafogvatn.is>
 <e9e30c79-5490-d296-bec8-0bc3f97fac8a@uni-muenster.de>
Message-ID: <xgzwo0v5kbv.fsf@hafogvatn.is>

Thanks Edzer, I missed that the file name becomes the name of the layer.  This works great.

I should say that I am enjoying converting my raster processing algorithms into the stars package.  It is nice to use tidyverse- and sf-friendly tools.  Thank you (and all your collaborators) for these tools.

My best,

Julian


Edzer Pebesma writes:

> Thank you for pointing to this possibility, I'll add it to the stars
> docs somewhere.
>
> This works but only slightly adapted, e.g. as
>
> out = read_stars(system.file("tif/L7_ETMs.tif", package = "stars")) %>%
>   slice(band, 1) %>%
>   setNames("x") %>%
>   mutate(x = case_when (x<100 ~ NA_real_,   x>100 & x<150 ~ 2))
>
> where:
> - I uses setNames("x") so that the attribute is renamed to "x", and
>   you can use x in the case_when expressions (rather than the lengthy
> "L7_ETMs.tif")
> - I chnaged NA into NA_real_ : the first RHS of the formulas need to
>   be all of the same type; as typeof(NA) is "logical", it breaks on
>  the second RHS which returns a numeric; if you would TRUE or FALSE
> rather than 2 in the second case_when formula, using NA would be the
> right thing to do in the first.
>
> The examples of case_when document the need for typed NA in RHS: this
> is intended behavior.
>
>
> On 9/14/20 4:39 PM, Julian M. Burgos wrote:
>> Dear list,
>> I am wondering if there is a way to use logical statements to
>> replace values of a stars object, for example the case_when function
>> or some other "tidyverse friendly" approach.  For example, I can do
>> something like this:
>> st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars"))
>> %>%
>>    slice(band, 1)
>> st1[st1 < 100] <- NA
>> st1[st1 > 100 & st1 < 150] <- 2
>> ... and so for.  But I am wondering if there is a way to do this as
>> part of a pipe, looking something like this:
>> st1 <- read_stars(system.file("tif/L7_ETMs.tif", package = "stars"))
>> %>%
>>    slice(band, 1) %>%
>>    mutate(x <- case_when (x<100 ~ NA,
>>                           x>100 & x<150 ~ 2))
>> Any ideas?
>> Takk,
>> Julian
>> --
>> Julian Mariano Burgos, PhD
>> Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
>> Marine and Freshwater Research Institute
>> Botnsj?varsvi?s / Demersal Division
>>    Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
>> http://www.hafogvatn.is/
>> S?mi/Telephone : +354-5752037
>> Netfang/Email: julian.burgos at hafogvatn.is
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://eur01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-sig-geo&amp;data=02%7C01%7C%7C46229147e3f34abe731108d858de7a97%7C8e105b94435e4303a61063620dbe162b%7C0%7C1%7C637357059855429791&amp;sdata=rUuCmwP21cqjEr%2BMGcDswcFsG4duKfgkcoNwPSflmeM%3D&amp;reserved=0
>>


--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
  Fornub??ir 5, IS-220 Hafnarfj?r?ur, Iceland
www.hafogvatn.is
S?mi/Telephone : +354-5752037
Netfang/Email: julian.burgos at hafogvatn.is


From P|etro_te|@to @end|ng |rom hotm@||@com  Tue Sep 15 15:18:54 2020
From: P|etro_te|@to @end|ng |rom hotm@||@com (Pietro Andre Telatin Paschoalino)
Date: Tue, 15 Sep 2020 13:18:54 +0000
Subject: [R-sig-Geo] How to cluster the standard errors in the SPLM function?
Message-ID: <BN8PR17MB2980EEA03FE403B8941BB3B882200@BN8PR17MB2980.namprd17.prod.outlook.com>

Hello everyone,

Could someone help me with splm (Spatial Panel Model By Maximum Likelihood) in R?

I want to know if is possible to cluster the standard errors by my individuals (like as in plm function). After a lot of research a found that there are more people with the same doubt, you can see this here, the person has the same problem as me:

https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm

Thank you all.

[https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded]<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>

Pietro Andre Telatin Paschoalino
Doutorando em Ci?ncias Econ?micas da Universidade Estadual de Maring? - PCE.

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>    Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>

	[[alternative HTML version deleted]]


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Sep 15 15:37:39 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 15 Sep 2020 15:37:39 +0200
Subject: [R-sig-Geo] How to cluster the standard errors in the SPLM
 function?
In-Reply-To: <BN8PR17MB2980EEA03FE403B8941BB3B882200@BN8PR17MB2980.namprd17.prod.outlook.com>
References: <BN8PR17MB2980EEA03FE403B8941BB3B882200@BN8PR17MB2980.namprd17.prod.outlook.com>
Message-ID: <alpine.LFD.2.23.451.2009151521170.2179660@reclus.nhh.no>

Please do not repeat messages, it does not help.

Did you provide a reproducible example, perhaps from plm? Did you read the 
code in splm, for example on R-Forge, or check the development version on 
R-Forge https://r-forge.r-project.org/R/?group_id=352, 
install.packages("splm", repos="http://R-Forge.R-project.org")?

Did you reference any articles showing how this approach might be 
implemented? Do you know whether any such code exists? Are you thinking of 
Conley approaches? Such as: 
http://www.trfetzer.com/using-r-to-estimate-spatial-hac-errors-per-conley/ 
? Unfortunately, the dropbox link is now stale.

Please report back on your progress, contact the splm maintainer to offer 
ideas or assistance, and anyway provide a reproducible example and the 
references you are using.

Hope this helps,

Roger

On Tue, 15 Sep 2020, Pietro Andre Telatin Paschoalino wrote:

> Hello everyone,
>
> Could someone help me with splm (Spatial Panel Model By Maximum Likelihood) in R?
>
> I want to know if is possible to cluster the standard errors by my individuals (like as in plm function). After a lot of research a found that there are more people with the same doubt, you can see this here, the person has the same problem as me:
>
> https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm
>
> Thank you all.
>
> [https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded]<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>
>
> Pietro Andre Telatin Paschoalino
> Doutorando em Ci?ncias Econ?micas da Universidade Estadual de Maring? - PCE.
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>    Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From btupper @end|ng |rom b|ge|ow@org  Tue Sep 15 15:45:22 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Tue, 15 Sep 2020 09:45:22 -0400
Subject: [R-sig-Geo] 
 "no applicable method" for focal() function in raster
In-Reply-To: <CADiqS85dfDSPK9DMB2d0KQ79HpsOJFTzykjrudVyJj7zeH27DQ@mail.gmail.com>
References: <CADiqS85dfDSPK9DMB2d0KQ79HpsOJFTzykjrudVyJj7zeH27DQ@mail.gmail.com>
Message-ID: <CALrbzg2+_ghMHG_fy4-yG=WNjquPm7TKs3EyimdRBgKnWgeH7g@mail.gmail.com>

Hello,

Unfortunately your email client formatted your message in HTML so the
content has been scrambled.  Best results experienced when the client is
configured to send plain text.

I think that issues is that lsm_l_condent() is expecting a raster (or
similar input).  See
https://cran.r-project.org/web/packages/landscapemetrics/landscapemetrics.pdf

Raster's focal() function slides along the raster pulling out cell values
(coincident with your focal window) and passes them to the function you
specify.  So as the docs for raster::focal descriibe, that function must be
configured to "take multiple numbers, and return a single number."
 landscapremetrics::lsm_l_condent is not configured that way.

Perhaps you need to create your own version of the function that just
operates on an input of numbers rather than an input of raster-like objects?

Cheers,
Ben

On Mon, Sep 14, 2020 at 4:42 PM Jaime Burbano Gir?n <jaimebg27 at gmail.com>
wrote:

> Hi everyone,
>
> I want to apply a moving window (3x3) to estimate conditional entropy
> (Nowosad & Stepinsky, 2019) over a heterogeneous landscape:
> *entropy=function(r){*
>
>
>
>
> *  entropy=lsm_l_condent(r, neighbourhood = 4, ordered = TRUE, base =
> "log2")  return(entropy$value)}w=matrix(1,3,3)result=focal(r, w,
> fun=entropy)*
>
> However, I get this error:
> *Error in .focal_fun(values(x), w, as.integer(dim(out)), runfun, NAonly) :
> *
> *Evaluation error: no applicable method for 'lsm_l_condent' applied to an
> object of class "c('double', 'numeric')".*
>
> But, when I run entropy function in the entire landscape it works:
>
> *> entropy(r)[1] 2.178874*
>
> *r* is a INT4U raster object:
>
>
>
>
>
>
> *class      : RasterLayer dimensions : 886, 999, 885114  (nrow, ncol,
> ncell)resolution : 300, 300  (x, y)extent     : 934805.7, 1234506, 1006566,
> 1272366  (xmin, xmax, ymin, ymax)crs        : +proj=tmerc
> +lat_0=4.59620041666667 +lon_0=-74.0775079166667 +k=1 +x_0=1000000
> +y_0=1000000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs values
>   : 99, 321113  (min, max)*
>
> There is any idea to solve the "no applicable method" error? Or any idea to
> estimate conditional entropy applying a moving window?
>
> Thanks in advance for the help.
>
> Best,
>
> Jaime
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org

	[[alternative HTML version deleted]]


From p|etro_te|@to @end|ng |rom hotm@||@com  Tue Sep 15 16:11:22 2020
From: p|etro_te|@to @end|ng |rom hotm@||@com (Pietro Andre Telatin Paschoalino)
Date: Tue, 15 Sep 2020 14:11:22 +0000
Subject: [R-sig-Geo] How to cluster the standard errors in the SPLM
 function?
In-Reply-To: <alpine.LFD.2.23.451.2009151521170.2179660@reclus.nhh.no>
References: <BN8PR17MB2980EEA03FE403B8941BB3B882200@BN8PR17MB2980.namprd17.prod.outlook.com>,
 <alpine.LFD.2.23.451.2009151521170.2179660@reclus.nhh.no>
Message-ID: <BN8PR17MB29802770C1C210A7448A725D82200@BN8PR17MB2980.namprd17.prod.outlook.com>

Hello Roger, thank you for your answer.

Yes, from plm I could compute by:

coeftest(x, vcovHC(x, type = ""))

But it does not work with the splm.

I don't find how this approach can be implemented in articles, related to R. But in Stata with the function xsmle, it is possible to estimate the way I want. I don't want to change the software, but it is an option.

Thank you for the idea to use conley SHAC, it is a question that I need to think about.

Again, thank you very much for your help, if I can't solve it for sure I will put a reproducible example.

Pietro Andre Telatin Paschoalino
Doutorando em Ci?ncias Econ?micas da Universidade Estadual de Maring? - PCE.

________________________________
De: Roger Bivand <Roger.Bivand at nhh.no>
Enviado: ter?a-feira, 15 de setembro de 2020 10:37
Para: Pietro Andre Telatin Paschoalino <Pietro_telato at hotmail.com>
Cc: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Assunto: Re: [R-sig-Geo] How to cluster the standard errors in the SPLM function?

Please do not repeat messages, it does not help.

Did you provide a reproducible example, perhaps from plm? Did you read the
code in splm, for example on R-Forge, or check the development version on
R-Forge https://r-forge.r-project.org/R/?group_id=352,
install.packages("splm", repos="http://R-Forge.R-project.org")?

Did you reference any articles showing how this approach might be
implemented? Do you know whether any such code exists? Are you thinking of
Conley approaches? Such as:
http://www.trfetzer.com/using-r-to-estimate-spatial-hac-errors-per-conley/
? Unfortunately, the dropbox link is now stale.

Please report back on your progress, contact the splm maintainer to offer
ideas or assistance, and anyway provide a reproducible example and the
references you are using.

Hope this helps,

Roger

On Tue, 15 Sep 2020, Pietro Andre Telatin Paschoalino wrote:

> Hello everyone,
>
> Could someone help me with splm (Spatial Panel Model By Maximum Likelihood) in R?
>
> I want to know if is possible to cluster the standard errors by my individuals (like as in plm function). After a lot of research a found that there are more people with the same doubt, you can see this here, the person has the same problem as me:
>
> https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm
>
> Thank you all.
>
> [https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded]<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>
>
> Pietro Andre Telatin Paschoalino
> Doutorando em Ci?ncias Econ?micas da Universidade Estadual de Maring? - PCE.
>
> [https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>    Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
>
>        [[alternative HTML version deleted]]
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

[https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>    Virus-free. www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>

	[[alternative HTML version deleted]]


From m@tmo@er @end|ng |rom wu@@c@@t  Tue Sep 15 20:24:02 2020
From: m@tmo@er @end|ng |rom wu@@c@@t (Mathias Moser)
Date: Tue, 15 Sep 2020 20:24:02 +0200
Subject: [R-sig-Geo] How to cluster the standard errors in the SPLM
 function?
In-Reply-To: <alpine.LFD.2.23.451.2009151521170.2179660@reclus.nhh.no>
References: <BN8PR17MB2980EEA03FE403B8941BB3B882200@BN8PR17MB2980.namprd17.prod.outlook.com>
 <alpine.LFD.2.23.451.2009151521170.2179660@reclus.nhh.no>
Message-ID: <7e95d632acb54e788d763d9f1691680c1df2df43.camel@wu.ac.at>

Pietro (and anyone else interested): the Conley SE code is still
available on Darin Christensen's Github: 
https://github.com/darinchristensen/conley-se

BR, Mathias

On Tue, 2020-09-15 at 15:37 +0200, Roger Bivand wrote:
> Please do not repeat messages, it does not help.
> 
> Did you provide a reproducible example, perhaps from plm? Did you
> read the 
> code in splm, for example on R-Forge, or check the development
> version on 
> R-Forge 
> https://r-forge.r-project.org/R/?group_id=352
> , 
> install.packages("splm", repos="
> http://R-Forge.R-project.org
> ")?
> 
> Did you reference any articles showing how this approach might be 
> implemented? Do you know whether any such code exists? Are you
> thinking of 
> Conley approaches? Such as: 
> http://www.trfetzer.com/using-r-to-estimate-spatial-hac-errors-per-conley/
>  
> ? Unfortunately, the dropbox link is now stale.
> 
> Please report back on your progress, contact the splm maintainer to
> offer 
> ideas or assistance, and anyway provide a reproducible example and
> the 
> references you are using.
> 
> Hope this helps,
> 
> Roger
> 
> On Tue, 15 Sep 2020, Pietro Andre Telatin Paschoalino wrote:
> 
> > Hello everyone,
> > 
> > Could someone help me with splm (Spatial Panel Model By Maximum
> > Likelihood) in R?
> > 
> > I want to know if is possible to cluster the standard errors by my
> > individuals (like as in plm function). After a lot of research a
> > found that there are more people with the same doubt, you can see
> > this here, the person has the same problem as me:
> > 
> > https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm
> > 
> > 
> > Thank you all.
> > 
> > [
> > https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded]<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>
> > 
> > 
> > Pietro Andre Telatin Paschoalino
> > Doutorando em Ci?ncias Econ?micas da Universidade Estadual de
> > Maring? - PCE.
> > 
> > [
> > https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
> >     Virus-free. 
> > www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Tue Sep 15 22:52:32 2020
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (ASANTOS)
Date: Tue, 15 Sep 2020 16:52:32 -0400
Subject: [R-sig-Geo] Filtering a set of points in a "ppp" object by distance
 using marks
References: <b29b02a6-ef97-c04c-1326-0b4778f256b7.ref@yahoo.com.br>
Message-ID: <b29b02a6-ef97-c04c-1326-0b4778f256b7@yahoo.com.br>

Dear R-Sig-Geo Members,

I'd like to find any way to filtering a set of points in a "ppp" object by minimum distance just only between different marks. In my example:

#Package
library(spatstat)

#Point process example - ants
data(ants)
ants.ppp<-ppp(x=ants$x,y=ants$y,marks=rep("antNests",length(ants$x)),window=Window(ants))


# Create a artificial point pattern - termites
termites <- rpoispp(0.0005, win=Window(ants))
termites.ppp<-ppp(x=termites$x,y=termites$y,marks=rep("termiNests",length(termites$x)),window=Window(ants))


#Join ants.ppp and termites.ppp
insects.ppp<-superimpose(ants.ppp,termites.ppp)


#If I try to use subset function:

subset(insects.ppp, pairdist(insects.ppp) > 20 & marks=="termiNests")

#Marked planar point pattern: 223 points #marks are of storage type 
?character? #window: polygonal boundary #enclosing rectangle: [-25, 803] 
x [-49, 717] units (one unit = 0.5 feet) #Warning message: #In ppp(X[, 
1], X[, 2], window = win, marks = marx, check = check) : # 70751 out of 
70974 points had NA or NaN coordinate values, and were discarded

Not the desirable result yet, because I'd like to calculate just only the > 20 "termiNests" to "antNests" marks and not the "termiNests" with "termiNests" too.

Please any ideas?

Thanks in advanced,

-- 
Alexandre dos Santos
Geotechnologies and Spatial Statistics applied to Forest Entomology
Instituto Federal de Mato Grosso (IFMT) - Campus Caceres
Caixa Postal 244 (PO Box)
Avenida dos Ramires, s/n - Vila Real
Caceres - MT - CEP 78201-380 (ZIP code)
Phone: (+55) 65 99686-6970 / (+55) 65 3221-2674
Lattes CV: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
ResearchGate: www.researchgate.net/profile/Alexandre_Santos10
Publons: https://publons.com/researcher/3085587/alexandre-dos-santos/
--


	[[alternative HTML version deleted]]


From m@rce||no@de|@cruz @end|ng |rom urjc@e@  Wed Sep 16 09:18:36 2020
From: m@rce||no@de|@cruz @end|ng |rom urjc@e@ (Marcelino de la Cruz Rot)
Date: Wed, 16 Sep 2020 09:18:36 +0200
Subject: [R-sig-Geo] 
 Filtering a set of points in a "ppp" object by distance using marks
In-Reply-To: <b29b02a6-ef97-c04c-1326-0b4778f256b7@yahoo.com.br>
References: <b29b02a6-ef97-c04c-1326-0b4778f256b7.ref@yahoo.com.br>
 <b29b02a6-ef97-c04c-1326-0b4778f256b7@yahoo.com.br>
Message-ID: <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>

Hi Alexandre,

may be this?


ddd <- nndist(insects.ppp, by=factor(insects.ppp$marks))
subset(insects.ppp,? marks=="termiNests" & ddd[,"termiNests"] >20)


Cheers,

Marcelino


El 15/09/2020 a las 22:52, ASANTOS via R-sig-Geo escribi?:
> Dear R-Sig-Geo Members,
>
> I'd like to find any way to filtering a set of points in a "ppp" object by minimum distance just only between different marks. In my example:
>
> #Package
> library(spatstat)
>
> #Point process example - ants
> data(ants)
> ants.ppp<-ppp(x=ants$x,y=ants$y,marks=rep("antNests",length(ants$x)),window=Window(ants))
>
>
> # Create a artificial point pattern - termites
> termites <- rpoispp(0.0005, win=Window(ants))
> termites.ppp<-ppp(x=termites$x,y=termites$y,marks=rep("termiNests",length(termites$x)),window=Window(ants))
>
>
> #Join ants.ppp and termites.ppp
> insects.ppp<-superimpose(ants.ppp,termites.ppp)
>
>
> #If I try to use subset function:
>
> subset(insects.ppp, pairdist(insects.ppp) > 20 & marks=="termiNests")
>
> #Marked planar point pattern: 223 points #marks are of storage type
> ?character? #window: polygonal boundary #enclosing rectangle: [-25, 803]
> x [-49, 717] units (one unit = 0.5 feet) #Warning message: #In ppp(X[,
> 1], X[, 2], window = win, marks = marx, check = check) : # 70751 out of
> 70974 points had NA or NaN coordinate values, and were discarded
>
> Not the desirable result yet, because I'd like to calculate just only the > 20 "termiNests" to "antNests" marks and not the "termiNests" with "termiNests" too.
>
> Please any ideas?
>
> Thanks in advanced,
>

-- 
Marcelino de la Cruz Rot
Depto. de Biolog?a y Geolog?a
F?sica y Qu?mica Inorg?nica
Universidad Rey Juan Carlos
M?stoles Espa?a


From m@rce||no@de|@cruz @end|ng |rom urjc@e@  Wed Sep 16 12:15:23 2020
From: m@rce||no@de|@cruz @end|ng |rom urjc@e@ (Marcelino de la Cruz Rot)
Date: Wed, 16 Sep 2020 12:15:23 +0200
Subject: [R-sig-Geo] 
 Filtering a set of points in a "ppp" object by distance using marks
In-Reply-To: <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>
References: <b29b02a6-ef97-c04c-1326-0b4778f256b7.ref@yahoo.com.br>
 <b29b02a6-ef97-c04c-1326-0b4778f256b7@yahoo.com.br>
 <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>
Message-ID: <98e91cce-deb1-56fb-028d-7b9e6fdeb529@urjc.es>

Sorry, I meant to say

subset(insects.ppp, marks=="termiNests" & ddd[,"antNests"] >20)

El 16/09/2020 a las 9:18, Marcelino de la Cruz Rot escribi?:
> Hi Alexandre,
>
> may be this?
>
>
> ddd <- nndist(insects.ppp, by=factor(insects.ppp$marks))
> subset(insects.ppp,? marks=="termiNests" & ddd[,"termiNests"] >20)
>
>
> Cheers,
>
> Marcelino
>
>
> El 15/09/2020 a las 22:52, ASANTOS via R-sig-Geo escribi?:
>> Dear R-Sig-Geo Members,
>>
>> I'd like to find any way to filtering a set of points in a "ppp" 
>> object by minimum distance just only between different marks. In my 
>> example:
>>
>> #Package
>> library(spatstat)
>>
>> #Point process example - ants
>> data(ants)
>> ants.ppp<-ppp(x=ants$x,y=ants$y,marks=rep("antNests",length(ants$x)),window=Window(ants)) 
>>
>>
>>
>> # Create a artificial point pattern - termites
>> termites <- rpoispp(0.0005, win=Window(ants))
>> termites.ppp<-ppp(x=termites$x,y=termites$y,marks=rep("termiNests",length(termites$x)),window=Window(ants)) 
>>
>>
>>
>> #Join ants.ppp and termites.ppp
>> insects.ppp<-superimpose(ants.ppp,termites.ppp)
>>
>>
>> #If I try to use subset function:
>>
>> subset(insects.ppp, pairdist(insects.ppp) > 20 & marks=="termiNests")
>>
>> #Marked planar point pattern: 223 points #marks are of storage type
>> ?character? #window: polygonal boundary #enclosing rectangle: [-25, 803]
>> x [-49, 717] units (one unit = 0.5 feet) #Warning message: #In ppp(X[,
>> 1], X[, 2], window = win, marks = marx, check = check) : # 70751 out of
>> 70974 points had NA or NaN coordinate values, and were discarded
>>
>> Not the desirable result yet, because I'd like to calculate just only 
>> the > 20 "termiNests" to "antNests" marks and not the "termiNests" 
>> with "termiNests" too.
>>
>> Please any ideas?
>>
>> Thanks in advanced,
>>
>

-- 
Marcelino de la Cruz Rot
Depto. de Biolog?a y Geolog?a
F?sica y Qu?mica Inorg?nica
Universidad Rey Juan Carlos
M?stoles Espa?a


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Wed Sep 16 14:04:13 2020
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (ASANTOS)
Date: Wed, 16 Sep 2020 08:04:13 -0400
Subject: [R-sig-Geo] 
 Filtering a set of points in a "ppp" object by distance using marks
In-Reply-To: <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>
References: <b29b02a6-ef97-c04c-1326-0b4778f256b7.ref@yahoo.com.br>
 <b29b02a6-ef97-c04c-1326-0b4778f256b7@yahoo.com.br>
 <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>
Message-ID: <79bb9b11-5013-2f1c-b599-33964cfd9b3c@yahoo.com.br>

Hi Marcelino,

Thanks, I just make a little change in your code:

ddd <- nndist(insects.ppp, by=factor(insects.ppp$marks))
subset(insects.ppp,? marks=="termiNests" & ddd[,"antNests"] >20)

I put `ddd[,"antNests"] >20` despite `ddd[,"termiNests"] >20` because I 
need "termiNests" mark far 20 units to each "antNests"

Best wishes,

Alexandre

-- 
Alexandre dos Santos
Geotechnologies and Spatial Statistics applied to Forest Entomology
Instituto Federal de Mato Grosso (IFMT) - Campus Caceres
Caixa Postal 244 (PO Box)
Avenida dos Ramires, s/n - Vila Real
Caceres - MT - CEP 78201-380 (ZIP code)
Phone: (+55) 65 99686-6970 / (+55) 65 3221-2674
Lattes CV: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
ResearchGate: www.researchgate.net/profile/Alexandre_Santos10
Publons: https://publons.com/researcher/3085587/alexandre-dos-santos/
--

Em 16/09/2020 03:18, Marcelino de la Cruz Rot escreveu:
> Hi Alexandre,
>
> may be this?
>
>
> ddd <- nndist(insects.ppp, by=factor(insects.ppp$marks))
> subset(insects.ppp,? marks=="termiNests" & ddd[,"termiNests"] >20)
>
>
> Cheers,
>
> Marcelino
>
>
> El 15/09/2020 a las 22:52, ASANTOS via R-sig-Geo escribi?:
>> Dear R-Sig-Geo Members,
>>
>> I'd like to find any way to filtering a set of points in a "ppp" 
>> object by minimum distance just only between different marks. In my 
>> example:
>>
>> #Package
>> library(spatstat)
>>
>> #Point process example - ants
>> data(ants)
>> ants.ppp<-ppp(x=ants$x,y=ants$y,marks=rep("antNests",length(ants$x)),window=Window(ants)) 
>>
>>
>>
>> # Create a artificial point pattern - termites
>> termites <- rpoispp(0.0005, win=Window(ants))
>> termites.ppp<-ppp(x=termites$x,y=termites$y,marks=rep("termiNests",length(termites$x)),window=Window(ants)) 
>>
>>
>>
>> #Join ants.ppp and termites.ppp
>> insects.ppp<-superimpose(ants.ppp,termites.ppp)
>>
>>
>> #If I try to use subset function:
>>
>> subset(insects.ppp, pairdist(insects.ppp) > 20 & marks=="termiNests")
>>
>> #Marked planar point pattern: 223 points #marks are of storage type
>> ?character? #window: polygonal boundary #enclosing rectangle: [-25, 803]
>> x [-49, 717] units (one unit = 0.5 feet) #Warning message: #In ppp(X[,
>> 1], X[, 2], window = win, marks = marx, check = check) : # 70751 out of
>> 70974 points had NA or NaN coordinate values, and were discarded
>>
>> Not the desirable result yet, because I'd like to calculate just only 
>> the > 20 "termiNests" to "antNests" marks and not the "termiNests" 
>> with "termiNests" too.
>>
>> Please any ideas?
>>
>> Thanks in advanced,
>>
>


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Wed Sep 16 14:05:33 2020
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (ASANTOS)
Date: Wed, 16 Sep 2020 08:05:33 -0400
Subject: [R-sig-Geo] 
 Filtering a set of points in a "ppp" object by distance using marks
In-Reply-To: <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>
References: <b29b02a6-ef97-c04c-1326-0b4778f256b7.ref@yahoo.com.br>
 <b29b02a6-ef97-c04c-1326-0b4778f256b7@yahoo.com.br>
 <b8311786-f1eb-2041-b080-1b94e48b25f9@urjc.es>
Message-ID: <014caf78-4cb7-3c8d-21d0-4403f3856f5c@yahoo.com.br>

Hi Marcelino,

Thanks so much, I just make a little change in your code:

ddd <- nndist(insects.ppp, by=factor(insects.ppp$marks))
subset(insects.ppp,? marks=="termiNests" & ddd[,"antNests"] >20)

I put `ddd[,"antNests"] >20` despite `ddd[,"termiNests"] >20` because I 
need "termiNests" mark far 20 units to each "antNests".

Best wishes,

Alexandre

-- 
Alexandre dos Santos
Geotechnologies and Spatial Statistics applied to Forest Entomology
Instituto Federal de Mato Grosso (IFMT) - Campus Caceres
Caixa Postal 244 (PO Box)
Avenida dos Ramires, s/n - Vila Real
Caceres - MT - CEP 78201-380 (ZIP code)
Phone: (+55) 65 99686-6970 / (+55) 65 3221-2674
Lattes CV: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
ResearchGate: www.researchgate.net/profile/Alexandre_Santos10
Publons: https://publons.com/researcher/3085587/alexandre-dos-santos/
--

Em 16/09/2020 03:18, Marcelino de la Cruz Rot escreveu:
> Hi Alexandre,
>
> may be this?
>
>
> ddd <- nndist(insects.ppp, by=factor(insects.ppp$marks))
> subset(insects.ppp,? marks=="termiNests" & ddd[,"termiNests"] >20)
>
>
> Cheers,
>
> Marcelino
>
>
> El 15/09/2020 a las 22:52, ASANTOS via R-sig-Geo escribi?:
>> Dear R-Sig-Geo Members,
>>
>> I'd like to find any way to filtering a set of points in a "ppp" 
>> object by minimum distance just only between different marks. In my 
>> example:
>>
>> #Package
>> library(spatstat)
>>
>> #Point process example - ants
>> data(ants)
>> ants.ppp<-ppp(x=ants$x,y=ants$y,marks=rep("antNests",length(ants$x)),window=Window(ants)) 
>>
>>
>>
>> # Create a artificial point pattern - termites
>> termites <- rpoispp(0.0005, win=Window(ants))
>> termites.ppp<-ppp(x=termites$x,y=termites$y,marks=rep("termiNests",length(termites$x)),window=Window(ants)) 
>>
>>
>>
>> #Join ants.ppp and termites.ppp
>> insects.ppp<-superimpose(ants.ppp,termites.ppp)
>>
>>
>> #If I try to use subset function:
>>
>> subset(insects.ppp, pairdist(insects.ppp) > 20 & marks=="termiNests")
>>
>> #Marked planar point pattern: 223 points #marks are of storage type
>> ?character? #window: polygonal boundary #enclosing rectangle: [-25, 803]
>> x [-49, 717] units (one unit = 0.5 feet) #Warning message: #In ppp(X[,
>> 1], X[, 2], window = win, marks = marx, check = check) : # 70751 out of
>> 70974 points had NA or NaN coordinate values, and were discarded
>>
>> Not the desirable result yet, because I'd like to calculate just only 
>> the > 20 "termiNests" to "antNests" marks and not the "termiNests" 
>> with "termiNests" too.
>>
>> Please any ideas?
>>
>> Thanks in advanced,
>>
>


From p|etro_te|@to @end|ng |rom hotm@||@com  Wed Sep 16 14:29:54 2020
From: p|etro_te|@to @end|ng |rom hotm@||@com (Pietro Andre Telatin Paschoalino)
Date: Wed, 16 Sep 2020 12:29:54 +0000
Subject: [R-sig-Geo] How to cluster the standard errors in the SPLM
 function?
In-Reply-To: <7e95d632acb54e788d763d9f1691680c1df2df43.camel@wu.ac.at>
References: <BN8PR17MB2980EEA03FE403B8941BB3B882200@BN8PR17MB2980.namprd17.prod.outlook.com>
 <alpine.LFD.2.23.451.2009151521170.2179660@reclus.nhh.no>,
 <7e95d632acb54e788d763d9f1691680c1df2df43.camel@wu.ac.at>
Message-ID: <BN8PR17MB29804BF45A78884D15AA108282210@BN8PR17MB2980.namprd17.prod.outlook.com>

Thank you a lot Mathias.

I hope this could help more people.

Have a good day.
________________________________
De: R-sig-Geo <r-sig-geo-bounces at r-project.org> em nome de Mathias Moser <matmoser at wu.ac.at>
Enviado: ter?a-feira, 15 de setembro de 2020 15:24
Para: r-sig-geo at r-project.org <r-sig-geo at r-project.org>
Assunto: Re: [R-sig-Geo] How to cluster the standard errors in the SPLM function?

Pietro (and anyone else interested): the Conley SE code is still
available on Darin Christensen's Github:
https://github.com/darinchristensen/conley-se

BR, Mathias

On Tue, 2020-09-15 at 15:37 +0200, Roger Bivand wrote:
> Please do not repeat messages, it does not help.
>
> Did you provide a reproducible example, perhaps from plm? Did you
> read the
> code in splm, for example on R-Forge, or check the development
> version on
> R-Forge
> https://r-forge.r-project.org/R/?group_id=352
> ,
> install.packages("splm", repos="
> http://R-Forge.R-project.org
> ")?
>
> Did you reference any articles showing how this approach might be
> implemented? Do you know whether any such code exists? Are you
> thinking of
> Conley approaches? Such as:
> http://www.trfetzer.com/using-r-to-estimate-spatial-hac-errors-per-conley/
>
> ? Unfortunately, the dropbox link is now stale.
>
> Please report back on your progress, contact the splm maintainer to
> offer
> ideas or assistance, and anyway provide a reproducible example and
> the
> references you are using.
>
> Hope this helps,
>
> Roger
>
> On Tue, 15 Sep 2020, Pietro Andre Telatin Paschoalino wrote:
>
> > Hello everyone,
> >
> > Could someone help me with splm (Spatial Panel Model By Maximum
> > Likelihood) in R?
> >
> > I want to know if is possible to cluster the standard errors by my
> > individuals (like as in plm function). After a lot of research a
> > found that there are more people with the same doubt, you can see
> > this here, the person has the same problem as me:
> >
> > https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm
> >
> >
> > Thank you all.
> >
> > [
> > https://cdn.sstatic.net/Sites/stackoverflow/img/apple-touch-icon at 2.png?v=73d79a89bded]<https://stackoverflow.com/questions/36869932/clustered-standard-errors-in-spatial-panel-linear-models-splm>
> >
> >
> > Pietro Andre Telatin Paschoalino
> > Doutorando em Ci?ncias Econ?micas da Universidade Estadual de
> > Maring? - PCE.
> >
> > [
> > https://ipmcdn.avast.com/images/icons/icon-envelope-tick-round-orange-animated-no-repeat-v1.gif]<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=icon>
> >     Virus-free.
> > www.avast.com<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail&utm_term=link>
> >
> >
> >      [[alternative HTML version deleted]]
> >
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From g@M@rt|ne||| @end|ng |rom gmx@|r  Thu Sep 17 19:28:56 2020
From: g@M@rt|ne||| @end|ng |rom gmx@|r (Gaetan Martinelli)
Date: Thu, 17 Sep 2020 19:28:56 +0200
Subject: [R-sig-Geo] Execute Extract function on several Raster with points
 layer
Message-ID: <trinity-4612335d-5296-4d1f-879b-83ea1be53ae8-1600363736201@3c-app-mailcom-bs02>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200917/853c5ce2/attachment.html>

From b|@|ev||@t @end|ng |rom gm@||@com  Thu Sep 17 19:57:18 2020
From: b|@|ev||@t @end|ng |rom gm@||@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Thu, 17 Sep 2020 19:57:18 +0200
Subject: [R-sig-Geo] 
 Execute Extract function on several Raster with points layer
In-Reply-To: <trinity-4612335d-5296-4d1f-879b-83ea1be53ae8-1600363736201@3c-app-mailcom-bs02>
References: <trinity-4612335d-5296-4d1f-879b-83ea1be53ae8-1600363736201@3c-app-mailcom-bs02>
Message-ID: <d648de0c-c543-d597-46dc-a086dff77536@gmail.com>

Hello Ga?tan,

so as far as I understand, you have 3 main folders:
"Max_T", ? and ?
and in alll the three folders, there are subfolders
"1961", "1962", ... "1970"
In each folder, there are 366 raster files, for which the file naming 
conventions are not known by us, but some of the files are called
"max1961_1.asc", "max1961_2.asc", ... "max1961_366.asc" (in case of 
T_max and year 1961)

In this case, the 10980 layer that belongs to T_max can be read to one 
large RasterStack in this way:
tmax_filenames <- c(outer(X = as.character(1:366), Y = 
as.character(1961:1970), FUN = function(doy, year) paste0("N:/400074 
Conservation des sols et CC/Data/Climate data/Climate-10km/Max_T/", 
year, "/max", year, "_", doy, ".asc")))
tmax_raster <- stack(tmax_filenames)

You can give self-explanatory names to the raster layers:
names(tmax_raster) <- c(outer(X = as.character(1:366), Y = 
as.character(1961:1970), FUN = function(doy, year) paste0(year, "_", doy)))

But if the structure of the rasters are the same (i.e. the cell size, 
extent, projection), then I recommend you to do the raster-vector 
overlay once, save the cell numbers that you are interested in, and then 
in nested for loops (one loop for the climate variable, one for the year 
and one for the day) read the rasters one-by-one, extract the values 
according to the cell numbers, and save the result in a previously 
created data.frame. In this way, you may not encounter memory issues. 
Although, it will take a lot of time...

HTH,
?kos Bede-Fazekas
Hungarian Academy of Sciences

2020.09.17. 19:28 keltez?ssel, Gaetan Martinelli ?rta:
> Hello everyone, R team,
>
> Sorry in advance for this long message. Your help will be invaluable.
>
> For a few days now i?have been blocked to execute a task on R.?I will 
> try to synthesize my problem.
>
> I have several raster.?I have an ASCII file for each day of a year 
> with a single band. For 30 years, and for three climatic variables on 
> grid 10km/10km (T_min, T_max, Precipitation). So?i?have a total around 
> of 32 940?raster files (366days*30years*3variables).
>
> Also, i have a layer of aroud 1000 points.
>
> I tried to use the Stack function and then make the intersection for 
> each raster files with my 1000 points.
> I cannot create an independent matrix for all my files where i?applied 
> the "extract" function, to then concatenate all my matrices in order 
> to have a single table.
>
> I tried this, exemple for 10 years et only T_Max (my files are 
> organized the same for my two other variables)? :
> *#Datapoints*
> Datapoints<-readOGR(dsn="H:/Inventaire/R/final",
> ? ? ? ? ? ? ? ?layer="Centroid_champs")
> Datapoints<- spTransform (Datapoints, CRS ("+init=epsg:4326") ) # 1022 
> points in the data
> st_crs(Datapoints)
> *#Rasters files*
> folders = list(
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1961'), 
> #Each year includes daily data, the names?of my several raster is 
> "max1961_1", "max1961_10", "max1961_100", etc...
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1962'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1963'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1964'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1965'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1966'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1967'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1968'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1969'),
> ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1970')
> )
> files = unlist(sapply(folders, function(folder) {
> ? list.files(folder, full.names=TRUE)
> }))
> files
>
> MET <- lapply(files, raster)
> s <- raster::stack(MET)
>
> output <- list()
> for(i in 1:length(MET)){
> ? output[[i]] <- extract(s, Datapoints)
> ? names(output)[[i]] <- paste("Ann?e", MET[i], sep = "_")
> }
> Also, i tried that :
> p1 <- 1022 (ID of my DataPoints)?; p2 <- 1 (column where there are the 
> values ??extracted from my raster)?; p3 <- 3660? ? ? # 3660matrix (366 
> day* 10 years)
> matlist <- list(array(NA,c(p1,p2,p3)))? # doing a list of independant 
> matrix
>
> for(i in seq_along(MET)){
>
> ? matlist[[i]] <- extract(s, Datapoints)
> }
> But, nothing works...
> I would like my script to perform these actions :
> - For each Raster in my Rasterstack, extract the climatic data values 
> ??and link them to my "Datapoints",
> - Take the name of my file, take the first three characters of the 
> name to get a column of my weather variable, here, "T_Max" (column 
> with my raster values) ; Take the following four characters then 
> report this information in a new?column "Year",?and finally, take the 
> last characters of the file name to create a new column "Day".
> - Concatenate all the independent output matrices corresponding to 
> each intersection made with my different raster files
> In the end, I would have a huge table, but one that will allow me to 
> do my analysis :
> Table with 9 attributes (6 attributs of my points +?Year + Day + 
> T_Max) like this :
> ID Datapoint 	Year 	Day 	T_Max
> 1 	1960 	1 	
> 2 	1960 	1 	
> ?... 	1960 	1 	
> 1022 	1960 	1 	
> 1 	1960 	2 	
> 2 	1960 	2 	
> ?... 	1960 	2 	
> 1022 	1960 	2 	
> ?.. 	?.. 	?.. 	
> 1 	1970 	1 	
> 2 	1970 	1 	
> ?... 	1970 	1 	
> 1022 	1970 	1 	
> 1 	1970 	2 	
> 2 	1970 	2 	
> ?... 	1970 	2 	
> 1022 	1970 	2 	
> ?.. 	?.. 	?.. 	
>
> Could a loop do this task ?
>
> I'm sorry, i?am gradually learning to manipulate R, but this exercise 
> is more difficult than expected...Please feel free to tell me if my 
> question is inappropriate.
>
> Thank you very much in advance for your answers. Your help or your 
> comments will be really appreciated.
>
> Have a good day.
>
> Ga?tan Martinelli
> Water and Agriculture research professional in Quebec.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From g@M@rt|ne||| @end|ng |rom gmx@|r  Thu Sep 17 20:40:44 2020
From: g@M@rt|ne||| @end|ng |rom gmx@|r (Gaetan Martinelli)
Date: Thu, 17 Sep 2020 20:40:44 +0200
Subject: [R-sig-Geo] 
 Execute Extract function on several Raster with points layer
In-Reply-To: <d648de0c-c543-d597-46dc-a086dff77536@gmail.com>
References: <trinity-4612335d-5296-4d1f-879b-83ea1be53ae8-1600363736201@3c-app-mailcom-bs02>
 <d648de0c-c543-d597-46dc-a086dff77536@gmail.com>
Message-ID: <trinity-10de8129-7174-4fdc-95a5-e4d697b45f82-1600368044485@3c-app-mailcom-bs08>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200917/7d8bd218/attachment.html>

From b|@|ev||@t @end|ng |rom gm@||@com  Thu Sep 17 21:20:52 2020
From: b|@|ev||@t @end|ng |rom gm@||@com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Thu, 17 Sep 2020 21:20:52 +0200
Subject: [R-sig-Geo] 
 Execute Extract function on several Raster with points layer
In-Reply-To: <trinity-5d6af910-7136-44f6-abaf-99dfffd71a6d-1600369231235@3c-app-mailcom-bs08>
References: <trinity-4612335d-5296-4d1f-879b-83ea1be53ae8-1600363736201@3c-app-mailcom-bs02>
 <d648de0c-c543-d597-46dc-a086dff77536@gmail.com>
 <trinity-5d6af910-7136-44f6-abaf-99dfffd71a6d-1600369231235@3c-app-mailcom-bs08>
Message-ID: <4abe3717-4f89-4449-3db4-2b7fde32c9d3@gmail.com>

Dear Ga?tan,
(cc r-sig-geo)
please post your mails in this topic to the mailing list.
I don't really know what does 'my "tmax_filesnames" object is a "large 
character"' mean. tmax_filenames is a typical character vector of 3660 
elements, so it should not cause any problem.
Anyway, the error message indicates that one or more of the file names 
are not correct. You should carefully check whether tmax_filenames was 
generated apropriately.
Best wishes,
?kos

2020.09.17. 21:00 keltez?ssel, Gaetan Martinelli ?rta:
> Hello again,
>
> The Stack function doesn't work because my "tmax_filesnames" object is 
> a "large character".
> Here is the error message I received after this line on my script?:
> > tmax_raster <- raster::stack(tmax_filenames)
> Error in .local(.Object, ...) :
> Error in .rasterObjectFromFile(x, band = band, objecttype = 
> "RasterLayer", ?:
> ? Cannot create a RasterLayer object from this file. (file does not exist)
>
> How do I rectify this error?
> I transform my object Large Character?
>
> Thanks again ?kos.
>
> Ga?tan
>
> *Envoy?:*?jeudi 17 septembre 2020 ? 13:57
> *De:*?"Bede-Fazekas ?kos" <bfalevlist at gmail.com>
> *?:*?r-sig-geo at r-project.org
> *Objet:*?Re: [R-sig-Geo] Execute Extract function on several Raster 
> with points layer
> Hello Ga?tan,
>
> so as far as I understand, you have 3 main folders:
> "Max_T", ? and ?
> and in alll the three folders, there are subfolders
> "1961", "1962", ... "1970"
> In each folder, there are 366 raster files, for which the file naming
> conventions are not known by us, but some of the files are called
> "max1961_1.asc", "max1961_2.asc", ... "max1961_366.asc" (in case of
> T_max and year 1961)
>
> In this case, the 10980 layer that belongs to T_max can be read to one
> large RasterStack in this way:
> tmax_filenames <- c(outer(X = as.character(1:366), Y =
> as.character(1961:1970), FUN = function(doy, year) paste0("N:/400074
> Conservation des sols et CC/Data/Climate data/Climate-10km/Max_T/",
> year, "/max", year, "_", doy, ".asc")))
> tmax_raster <- stack(tmax_filenames)
>
> You can give self-explanatory names to the raster layers:
> names(tmax_raster) <- c(outer(X = as.character(1:366), Y =
> as.character(1961:1970), FUN = function(doy, year) paste0(year, "_", 
> doy)))
>
> But if the structure of the rasters are the same (i.e. the cell size,
> extent, projection), then I recommend you to do the raster-vector
> overlay once, save the cell numbers that you are interested in, and then
> in nested for loops (one loop for the climate variable, one for the year
> and one for the day) read the rasters one-by-one, extract the values
> according to the cell numbers, and save the result in a previously
> created data.frame. In this way, you may not encounter memory issues.
> Although, it will take a lot of time...
>
> HTH,
> ?kos Bede-Fazekas
> Hungarian Academy of Sciences
>
> 2020.09.17. 19:28 keltez?ssel, Gaetan Martinelli ?rta:
> > Hello everyone, R team,
> >
> > Sorry in advance for this long message. Your help will be invaluable.
> >
> > For a few days now i?have been blocked to execute a task on R.?I will
> > try to synthesize my problem.
> >
> > I have several raster.?I have an ASCII file for each day of a year
> > with a single band. For 30 years, and for three climatic variables on
> > grid 10km/10km (T_min, T_max, Precipitation). So?i?have a total around
> > of 32 940?raster files (366days*30years*3variables).
> >
> > Also, i have a layer of aroud 1000 points.
> >
> > I tried to use the Stack function and then make the intersection for
> > each raster files with my 1000 points.
> > I cannot create an independent matrix for all my files where i?applied
> > the "extract" function, to then concatenate all my matrices in order
> > to have a single table.
> >
> > I tried this, exemple for 10 years et only T_Max (my files are
> > organized the same for my two other variables)? :
> > *#Datapoints*
> > Datapoints<-readOGR(dsn="H:/Inventaire/R/final",
> > ? ? ? ? ? ? ? ?layer="Centroid_champs")
> > Datapoints<- spTransform (Datapoints, CRS ("+init=epsg:4326") ) # 1022
> > points in the data
> > st_crs(Datapoints)
> > *#Rasters files*
> > folders = list(
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1961'),
> > #Each year includes daily data, the names?of my several raster is
> > "max1961_1", "max1961_10", "max1961_100", etc...
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1962'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1963'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1964'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1965'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1966'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1967'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1968'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1969'),
> > ? file.path('N:','Data','Climate data','Climate-10km','Max_T','1970')
> > )
> > files = unlist(sapply(folders, function(folder) {
> > ? list.files(folder, full.names=TRUE)
> > }))
> > files
> >
> > MET <- lapply(files, raster)
> > s <- raster::stack(MET)
> >
> > output <- list()
> > for(i in 1:length(MET)){
> > ? output[[i]] <- extract(s, Datapoints)
> > ? names(output)[[i]] <- paste("Ann?e", MET[i], sep = "_")
> > }
> > Also, i tried that :
> > p1 <- 1022 (ID of my DataPoints)?; p2 <- 1 (column where there are the
> > values ??extracted from my raster)?; p3 <- 3660 ? ? # 3660matrix (366
> > day* 10 years)
> > matlist <- list(array(NA,c(p1,p2,p3)))? # doing a list of independant
> > matrix
> >
> > for(i in seq_along(MET)){
> >
> > ? matlist[[i]] <- extract(s, Datapoints)
> > }
> > But, nothing works...
> > I would like my script to perform these actions :
> > - For each Raster in my Rasterstack, extract the climatic data values
> > ??and link them to my "Datapoints",
> > - Take the name of my file, take the first three characters of the
> > name to get a column of my weather variable, here, "T_Max" (column
> > with my raster values) ; Take the following four characters then
> > report this information in a new?column "Year",?and finally, take the
> > last characters of the file name to create a new column "Day".
> > - Concatenate all the independent output matrices corresponding to
> > each intersection made with my different raster files
> > In the end, I would have a huge table, but one that will allow me to
> > do my analysis :
> > Table with 9 attributes (6 attributs of my points +?Year + Day +
> > T_Max) like this :
> > ID Datapoint Year Day T_Max
> > 1 1960 1
> > 2 1960 1
> > ?... 1960 1
> > 1022 1960 1
> > 1 1960 2
> > 2 1960 2
> > ?... 1960 2
> > 1022 1960 2
> > ?.. ?.. ?..
> > 1 1970 1
> > 2 1970 1
> > ?... 1970 1
> > 1022 1970 1
> > 1 1970 2
> > 2 1970 2
> > ?... 1970 2
> > 1022 1970 2
> > ?.. ?.. ?..
> >
> > Could a loop do this task ?
> >
> > I'm sorry, i?am gradually learning to manipulate R, but this exercise
> > is more difficult than expected...Please feel free to tell me if my
> > question is inappropriate.
> >
> > Thank you very much in advance for your answers. Your help or your
> > comments will be really appreciated.
> >
> > Have a good day.
> >
> > Ga?tan Martinelli
> > Water and Agriculture research professional in Quebec.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From tzehuey85 @end|ng |rom gm@||@com  Sat Sep 19 10:49:17 2020
From: tzehuey85 @end|ng |rom gm@||@com (TAM TZE HUEY)
Date: Sat, 19 Sep 2020 16:49:17 +0800
Subject: [R-sig-Geo] Apply local spectral histogram on satellite image
Message-ID: <8824B04C-7468-4CD5-938F-C75ADFF715E3@hxcore.ol>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20200919/5282c487/attachment.html>

From hugo@gco@t@ @end|ng |rom gm@||@com  Sun Sep 20 12:44:38 2020
From: hugo@gco@t@ @end|ng |rom gm@||@com (Hugo Costa)
Date: Sun, 20 Sep 2020 11:44:38 +0100
Subject: [R-sig-Geo] raster multicore processing: WriteValues inside foreach
 loop
Message-ID: <CADvFi5odVc5fUwTq-u6Zp-Ho8i9vJJEkANd+6DFLRC+CUtvg6w@mail.gmail.com>

Dear list

with package raster it's possible to process large images in blocks, like
this:

library(raster)

r<- raster(system.file("img", "Rlogo.tiff", package="tiff"))
s <- raster(r)
b <- blockSize(r)
s <- writeStart(s, filename=tempfile(fileext = ".tif"),  overwrite=TRUE)

for (i in 1:b$n){
  v <- getValuesBlock(r, row=b$row[i], nrows=b$nrows[i])
  s <- writeValues(s, v, b$row[i])
}

s <- writeStop(s)
plot(s)

However, I wonder if it's possible to replace the for loop by foreach, like
this:

library(foreach)
cl <- parallel::makeCluster(2)
doSNOW::registerDoSNOW(cl)

r<- raster(system.file("img", "Rlogo.tiff", package="tiff"))
s <- raster(r)
b <- blockSize(r)
s <- writeStart(s, filename=tempfile(fileext = ".tif"),  overwrite=TRUE)

foreach (i=1:b$n, .packages = "raster") %dopar% {
  v <- getValuesBlock(r, row=b$row[i], nrows=b$nrows[i])
  s <- writeValues(s, v, b$row[i])
}
parallel::stopCluster(cl)

s <- writeStop(s)

However, the code above fails with
Error in { : task 1 failed - "Null external pointer

Apparently, the WriteValues inside foreach is not able to write in the tif
file. Is it possible to fix this?
Could foreach be an easier alternative to the multi-core functions
exemplified in the raster vignette here
<https://rspatial.org/raster/pkg/appendix1.html>?

Thanks
Hugo

	[[alternative HTML version deleted]]


From @dee|@@u@| @end|ng |rom gm@||@com  Mon Sep 21 18:58:42 2020
From: @dee|@@u@| @end|ng |rom gm@||@com (Adeela Munawar)
Date: Mon, 21 Sep 2020 21:58:42 +0500
Subject: [R-sig-Geo] unsubscribing R mailing list
Message-ID: <CABGg3O5pVcowT36C3xa8_FQrC0MBTWGzryop6_DFORns0rbqSA@mail.gmail.com>

How to unsubscribe this mailing list?

	[[alternative HTML version deleted]]


From m@rce||no@de|@cruz @end|ng |rom urjc@e@  Mon Sep 21 19:07:51 2020
From: m@rce||no@de|@cruz @end|ng |rom urjc@e@ (Marcelino de la Cruz Rot)
Date: Mon, 21 Sep 2020 19:07:51 +0200
Subject: [R-sig-Geo] unsubscribing R mailing list
In-Reply-To: <CABGg3O5pVcowT36C3xa8_FQrC0MBTWGzryop6_DFORns0rbqSA@mail.gmail.com>
References: <CABGg3O5pVcowT36C3xa8_FQrC0MBTWGzryop6_DFORns0rbqSA@mail.gmail.com>
Message-ID: <2a85ba69-5b1c-b4df-5806-0611c8b64033@urjc.es>

It is very easy:

Go to the end of this web page:

https://stat.ethz.ch/mailman/listinfo/r-sig-geo and unsubscribe yourself 
from the list. Cheers, Marcelino


El 21/09/2020 a las 18:58, Adeela Munawar escribi?:
> How to unsubscribe this mailing list?
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> .


-- 
Marcelino de la Cruz Rot
Depto. de Biolog?a y Geolog?a
F?sica y Qu?mica Inorg?nica
Universidad Rey Juan Carlos
M?stoles Espa?a


From @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br  Tue Sep 22 14:26:11 2020
From: @|ex@ndre@@nto@br @end|ng |rom y@hoo@com@br (ASANTOS)
Date: Tue, 22 Sep 2020 08:26:11 -0400
Subject: [R-sig-Geo] raster: extract() based in a pixel value
References: <98b7c9bb-ba88-4dc0-61bb-16139581cab6.ref@yahoo.com.br>
Message-ID: <98b7c9bb-ba88-4dc0-61bb-16139581cab6@yahoo.com.br>

Dear R-sig-geo Members,

I'd like to use de extract() function using the raster package for 
calculate a proportion of pixel with "1"s values inside a buffer given 
some coordinates in a raster. I try to create a function for this 
without success, in my hypothetical example:

#Package
library(raster)

# Create a raster
ras <- raster(ncol=1000, nrow=1000)
set.seed(0)
values(ras) <- runif(ncell(ras))
values(ras)[values(ras) > 0.5] = 1
values(ras)[values(ras) < 0.5] = NA

# Create some coordinates
pts<-sampleRandom(ras, size=30, xy=TRUE)
pts.df<-as.data.frame(pts)
pts.df$area<-rnorm(30, mean=10)## Here just for create a artificial 
covariate without any direct implication in my question

#Function for extract proportion of 1s values
percentual_1s<- function(x,...) {
 ? leng1<-length(values(x) ==1) # length of 1s pixels values
 ? lengtotal<-length(x) # total length of pixels inside buffer
 ? perc<-(leng1/lengtotal)*100
 ? return(perc)
}

# Extract the desirable proportion in a circular 100000 units buffer
cent_max <- extract(ras, # raster layer
 ??? cbind(pts.df$x,pts.df$y),??? # SPDF with centroids for buffer
 ??? buffer = 100000,???????????? # buffer size
 ??? fun=percentual_1s,?????????? # what to value to extract
 ??? df=TRUE)


Here doesn't work, despite the code look like Ok. My perfect output is:

#??????? x????? y layer????? area?? percentual_1s
#1 -109.26 -43.65???? 1 10.349010?? 23.15
#2?? 93.42 -87.21???? 1? 9.861920?? 45.18
#3?? 57.06? 86.85???? 1? 8.642071?? 74.32
#4 -109.98 -45.63???? 1 10.376485?? 11.56
#5? -92.34? 37.89???? 1 10.375138?? 56.89
#6?? 19.62? 21.51???? 1? 8.963949?? 88.15


Please any ideas or any another package that help in this operation?

Thanks in advanced,


-- 
Alexandre dos Santos
Geotechnologies and Spatial Statistics applied to Forest Entomology
Instituto Federal de Mato Grosso (IFMT) - Campus Caceres
Caixa Postal 244 (PO Box)
Avenida dos Ramires, s/n - Vila Real
Caceres - MT - CEP 78201-380 (ZIP code)
Phone: (+55) 65 99686-6970 / (+55) 65 3221-2674
Lattes CV: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
ResearchGate: www.researchgate.net/profile/Alexandre_Santos10
Publons: https://publons.com/researcher/3085587/alexandre-dos-santos/
--


	[[alternative HTML version deleted]]


From r@|@e|@wuee@t @end|ng |rom gm@||@com  Tue Sep 22 14:44:44 2020
From: r@|@e|@wuee@t @end|ng |rom gm@||@com (=?utf-8?Q?Rafael_W=C3=BCest?=)
Date: Tue, 22 Sep 2020 14:44:44 +0200
Subject: [R-sig-Geo] raster: extract() based in a pixel value
In-Reply-To: <98b7c9bb-ba88-4dc0-61bb-16139581cab6@yahoo.com.br>
References: <98b7c9bb-ba88-4dc0-61bb-16139581cab6.ref@yahoo.com.br>
 <98b7c9bb-ba88-4dc0-61bb-16139581cab6@yahoo.com.br>
Message-ID: <5AFEE009-B285-4920-B4FD-876D7E8C91CE@gmail.com>

Hi there

adapt your function for extraction as follows:

percentual_1s<- function(x,...) {
  leng1<-length(which(x==1))
  lengtotal<-length(x) 
  perc<-(leng1/lengtotal)*100
  return(perc)
}

And add "na.rm = FALSE" in the extract call:

cent_max <- extract(ras, pts[,1:2], buffer = 1000000, fun=percentual_1s, df=TRUE, na.rm = FALSE)

That gives me:

head(cent_max)
  ID    layer
1  1 49.81865
2  2 50.27545
3  3 50.03113
4  4 50.29819
5  5 50.39391
6  6 48.89556

The values I get make sense to me (around 50%).

HTH, Rafi


> On 22 Sep 2020, at 14:26, ASANTOS via R-sig-Geo <r-sig-geo at r-project.org> wrote:
> 
> Dear R-sig-geo Members,
> 
> I'd like to use de extract() function using the raster package for 
> calculate a proportion of pixel with "1"s values inside a buffer given 
> some coordinates in a raster. I try to create a function for this 
> without success, in my hypothetical example:
> 
> #Package
> library(raster)
> 
> # Create a raster
> ras <- raster(ncol=1000, nrow=1000)
> set.seed(0)
> values(ras) <- runif(ncell(ras))
> values(ras)[values(ras) > 0.5] = 1
> values(ras)[values(ras) < 0.5] = NA
> 
> # Create some coordinates
> pts<-sampleRandom(ras, size=30, xy=TRUE)
> pts.df<-as.data.frame(pts)
> pts.df$area<-rnorm(30, mean=10)## Here just for create a artificial 
> covariate without any direct implication in my question
> 
> #Function for extract proportion of 1s values
> percentual_1s<- function(x,...) {
> ? leng1<-length(values(x) ==1) # length of 1s pixels values
> ? lengtotal<-length(x) # total length of pixels inside buffer
> ? perc<-(leng1/lengtotal)*100
> ? return(perc)
> }
> 
> # Extract the desirable proportion in a circular 100000 units buffer
> cent_max <- extract(ras, # raster layer
> ??? cbind(pts.df$x,pts.df$y),??? # SPDF with centroids for buffer
> ??? buffer = 100000,???????????? # buffer size
> ??? fun=percentual_1s,?????????? # what to value to extract
> ??? df=TRUE)
> 
> 
> Here doesn't work, despite the code look like Ok. My perfect output is:
> 
> #??????? x????? y layer????? area?? percentual_1s
> #1 -109.26 -43.65???? 1 10.349010?? 23.15
> #2?? 93.42 -87.21???? 1? 9.861920?? 45.18
> #3?? 57.06? 86.85???? 1? 8.642071?? 74.32
> #4 -109.98 -45.63???? 1 10.376485?? 11.56
> #5? -92.34? 37.89???? 1 10.375138?? 56.89
> #6?? 19.62? 21.51???? 1? 8.963949?? 88.15
> 
> 
> Please any ideas or any another package that help in this operation?
> 
> Thanks in advanced,
> 
> 
> -- 
> Alexandre dos Santos
> Geotechnologies and Spatial Statistics applied to Forest Entomology
> Instituto Federal de Mato Grosso (IFMT) - Campus Caceres
> Caixa Postal 244 (PO Box)
> Avenida dos Ramires, s/n - Vila Real
> Caceres - MT - CEP 78201-380 (ZIP code)
> Phone: (+55) 65 99686-6970 / (+55) 65 3221-2674
> Lattes CV: http://lattes.cnpq.br/1360403201088680
> OrcID: orcid.org/0000-0001-8232-6722
> ResearchGate: www.researchgate.net/profile/Alexandre_Santos10
> Publons: https://publons.com/researcher/3085587/alexandre-dos-santos/
> --
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger@B|v@nd @end|ng |rom nhh@no  Tue Sep 22 15:33:07 2020
From: Roger@B|v@nd @end|ng |rom nhh@no (Roger Bivand)
Date: Tue, 22 Sep 2020 15:33:07 +0200
Subject: [R-sig-Geo] unsubscribing R mailing list
In-Reply-To: <CABGg3O5pVcowT36C3xa8_FQrC0MBTWGzryop6_DFORns0rbqSA@mail.gmail.com>
References: <CABGg3O5pVcowT36C3xa8_FQrC0MBTWGzryop6_DFORns0rbqSA@mail.gmail.com>
Message-ID: <alpine.LFD.2.23.451.2009221528520.40425@reclus.nhh.no>

On Mon, 21 Sep 2020, Adeela Munawar wrote:

> How to unsubscribe this mailing list?

Each mailing list posting has a mimimal footer, which includes a link to 
the list page: https://stat.ethz.ch/mailman/listinfo/r-sig-geo, which in 
turn contains instructions on how to unsubscribe.

List members whose emails stop receiving messages for whatever reason are 
detected by the server and unsubscribed automatically after a grace 
period.

Roger Bivand
List admin.

>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
https://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


