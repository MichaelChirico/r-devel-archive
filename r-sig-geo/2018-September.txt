From dhir@jkh@nn@ @ending from gm@il@com  Sat Sep  1 04:58:24 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Sat, 1 Sep 2018 08:28:24 +0530
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
Message-ID: <CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ@mail.gmail.com>

I am working with shipping data where I get the dynamic parameters of a
ship like its position, speed, heading and rate of turn. I am then trying
to plot this on a leaflet map and trying to colour the polylines based on
the speed, but it always shows up in the same colour. Here?s some sample
data:


structure(list(lat = c(51.88783, 51.8878441, 51.887825, 51.88659,
51.8866959, 51.8874931, 51.89359, 51.8941269, 51.8977051, 51.8994331,
51.90773, 51.91324, 51.91604, 51.9216652, 51.93353, 51.9419365 ), lon
= c(4.28763342, 4.287635, 4.28765154, 4.29007339, 4.29562664,
4.29917, 4.30641174, 4.30561829, 4.29263353, 4.284498, 4.261132,
4.24711847, 4.241075, 4.23262, 4.21523666, 4.1927), rateOfTurn = c(0L,
 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
sogKts = c(0, 0, 0, 2.1, 3.4, 4.6, 3.5, 3.8, 7.4, 7.9, 8.8,      9.1,
9.2, 9.2, 9.3, 9.3), cog = c(15, 15, 15, 122.2, 70.4,      70, 323.2,
315.3, 289.3, 290.9, 303.8, 303.7, 308.9, 324.5,      304.9, 301.4),
heading = c(163, 162, 163, 106, 71, 71, 303,      298, 289, 294, 303,
303, 310, 324, 304, 302), timestamp = c("2018-07-19T05:27:34",
"2018-07-19T05:39:35", "2018-07-19T05:45:34", "2018-07-19T05:57:37",
   "2018-07-19T06:02:48", "2018-07-19T06:04:49",
"2018-07-19T06:12:51",      "2018-07-19T06:13:32",
"2018-07-19T06:19:08", "2018-07-19T06:21:41",
"2018-07-19T06:28:42", "2018-07-19T06:32:50", "2018-07-19T06:34:37",
   "2018-07-19T06:37:41", "2018-07-19T06:43:49", "2018-07-19T06:50:09"
    ), Color = c("red", "red", "red", "red", "orange", "orange",
"orange", "orange", "orange", "orange", "yellow", "yellow",
"yellow", "yellow", "yellow", "yellow")), row.names = 32:47, class =
"data.frame")

This is the code I have tried which doesn?t work:-

map <-  leaflet(x) map <- addTiles(map) for( Color in
levels(as.factor(x$Color))){   map <- addPolylines(map,
lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map

Regards
Dhiraj Khanna
Mob:09873263331

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Sat Sep  1 11:58:26 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sat, 1 Sep 2018 11:58:26 +0200
Subject: [R-sig-Geo] unbalanced panel
In-Reply-To: <CAPHJcdAOkA6d=oYtT+aOJS95apQ48XpvtDQUegQ2N=N3WmAQiw@mail.gmail.com>
References: <CAPHJcdAOkA6d=oYtT+aOJS95apQ48XpvtDQUegQ2N=N3WmAQiw@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1809011148410.2433@reclus.nhh.no>

On Thu, 30 Aug 2018, J?r?mie Juste wrote:

> Hello,
>
> I was wondering if there are any plans to allow the estimation of
> unbalanced panel in spdep or splm. I am not fortunate enough to have
> balanced spatial data and I think this woud be a valuable input to the
> community.

Could you please give us more motivation - are the missing observations 
patterned? Which application area are you considering? What literature are 
you using with regard to estimating unbalanced panels - is the problem 
more temporal than spatial? Is this actually about interpolating or 
imputing the missing values and the carrying through uncertainty? If this 
was the case, then a Bayesian approach might be desirable, to permit the 
imputation uncertainty to be carried through?

>
> Is there a way to compute direct and indirect effects when estimating an
> unbalanced panel spatial durbin model ?

First fit the model! Probably, unless you have a solid micro-model for why 
global spillover is needed, you should keep the spatial process in the 
error (local spillover), simplifying the impacts. In any case, avoiding 
econometric fixed effects may let you use statistical random effects 
models with (separable) temporal and spatial structure.

Roger

>
> Best regards,
> Jeremie Juste
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From Roger@Biv@nd @ending from nhh@no  Sat Sep  1 12:13:35 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sat, 1 Sep 2018 12:13:35 +0200
Subject: [R-sig-Geo] Morans I
In-Reply-To: <D4554399-0016-4384-91FA-F685EE43BEFA@ieu.uzh.ch>
References: <D4554399-0016-4384-91FA-F685EE43BEFA@ieu.uzh.ch>
Message-ID: <alpine.LFD.2.21.1809011204380.2433@reclus.nhh.no>

On Thu, 16 Aug 2018, Dechen Lham wrote:

> hi all,
>
> is the below the correct way to access spatial autocorrelation using 
> morans I in a glm:
>
> #get coordinates first
> coords<-as.matrix(cbind(data$long,data$lat))
>
> #model
> m1 <- glm(response~ predictor1 + predictor 2+ predictor1*predictor2, 
> + family=binomial, data=data)
>
> # Compute Moran's I using residuals of model
> lstw <- nb2listw((knn2nb(knearneigh(coords, k=1))))
>
> moran.test(residuals(m1), lstw)

No, certainly not correct; speculations suggest that using lm.morantest() 
is less unsure, but I cannot find the reference at the moment. When 
testing residuals from a linear model, the whole model output is needed 
(see reference in ?lm.morantest) and this extends to glm models.

Roger

>
>
> Advise from experts using function moran.test will be much appreciated.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From kent3737 @ending from gm@il@com  Sat Sep  1 14:47:53 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Sat, 1 Sep 2018 08:47:53 -0400
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
Message-ID: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>

>
> Message: 5
> Date: Sat, 1 Sep 2018 08:28:24 +0530
> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
> Message-ID:
>         <CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNA
> gVisAw2JBoQ at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> I am working with shipping data where I get the dynamic parameters of a
> ship like its position, speed, heading and rate of turn. I am then trying
> to plot this on a leaflet map and trying to colour the polylines based on
> the speed, but it always shows up in the same colour. Here?s some sample
> data:
>
> <snip>
> This is the code I have tried which doesn?t work:-
>
> map <-  leaflet(x) map <- addTiles(map) for( Color in
> levels(as.factor(x$Color))){   map <- addPolylines(map,
> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>
> Regards
> Dhiraj Khanna
> Mob:09873263331


What are you expecting to see? When I run your code I get a map with three
lines, one red, one orange and one yellow.

Kent

	[[alternative HTML version deleted]]


From dhir@jkh@nn@ @ending from gm@il@com  Sat Sep  1 14:56:55 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Sat, 1 Sep 2018 18:26:55 +0530
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
Message-ID: <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>

@Kent they are appearing as three separate lines. I am hoping to see them
joint with no gaps. The transition from row 4 to row 5 is where the speed
has changed from 2.1 knots to 3.4 knots. I am hoping to see another line
from row 4 to row 5 in red colour. Similarly for the other disjoint points.
Regards

Dhiraj Khanna
Mob:09873263331


On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com> wrote:

> Message: 5
>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>> Message-ID:
>>         <
>> CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> I am working with shipping data where I get the dynamic parameters of a
>> ship like its position, speed, heading and rate of turn. I am then trying
>> to plot this on a leaflet map and trying to colour the polylines based on
>> the speed, but it always shows up in the same colour. Here?s some sample
>> data:
>>
>> <snip>
>> This is the code I have tried which doesn?t work:-
>>
>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>
>> Regards
>> Dhiraj Khanna
>> Mob:09873263331
>
>
> What are you expecting to see? When I run your code I get a map with three
> lines, one red, one orange and one yellow.
>
> Kent
>
>

	[[alternative HTML version deleted]]


From kent3737 @ending from gm@il@com  Sat Sep  1 16:29:43 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Sat, 1 Sep 2018 10:29:43 -0400
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
 <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
Message-ID: <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>

You have to include the points where the colors change in both polylines.
Here is one way:

x$lastColor = dplyr::lag(x$Color)
map <-  leaflet(x)
map <- addTiles(map)
for( Color in
levels(as.factor(x$Color))){
  map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
x$lastColor==Color,], color=~Color) }
map

Kent

On Sat, Sep 1, 2018 at 8:56 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
wrote:

> @Kent they are appearing as three separate lines. I am hoping to see them
> joint with no gaps. The transition from row 4 to row 5 is where the speed
> has changed from 2.1 knots to 3.4 knots. I am hoping to see another line
> from row 4 to row 5 in red colour. Similarly for the other disjoint points.
> Regards
>
> Dhiraj Khanna
> Mob:09873263331
>
>
> On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com> wrote:
>
>> Message: 5
>>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>>> To: r-sig-geo at r-project.org
>>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>>> Message-ID:
>>>         <CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNA
>>> gVisAw2JBoQ at mail.gmail.com>
>>> Content-Type: text/plain; charset="utf-8"
>>>
>>> I am working with shipping data where I get the dynamic parameters of a
>>> ship like its position, speed, heading and rate of turn. I am then trying
>>> to plot this on a leaflet map and trying to colour the polylines based on
>>> the speed, but it always shows up in the same colour. Here?s some sample
>>> data:
>>>
>>> <snip>
>>> This is the code I have tried which doesn?t work:-
>>>
>>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>>
>>> Regards
>>> Dhiraj Khanna
>>> Mob:09873263331
>>
>>
>> What are you expecting to see? When I run your code I get a map with
>> three lines, one red, one orange and one yellow.
>>
>> Kent
>>
>>

	[[alternative HTML version deleted]]


From dhir@jkh@nn@ @ending from gm@il@com  Sat Sep  1 16:36:46 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Sat, 1 Sep 2018 20:06:46 +0530
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
 <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
 <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>
Message-ID: <CANHhK32ti8_YqbT-etchCM+o88+Thg1ndWkUbmg2XZ3DZ3vVYA@mail.gmail.com>

Thank you Kent, that worked like a charm!
Regards

Dhiraj Khanna
Mob:09873263331


On Sat, Sep 1, 2018 at 7:59 PM Kent Johnson <kent3737 at gmail.com> wrote:

> You have to include the points where the colors change in both polylines.
> Here is one way:
>
> x$lastColor = dplyr::lag(x$Color)
> map <-  leaflet(x)
> map <- addTiles(map)
> for( Color in
> levels(as.factor(x$Color))){
>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
> x$lastColor==Color,], color=~Color) }
> map
>
> Kent
>
> On Sat, Sep 1, 2018 at 8:56 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
> wrote:
>
>> @Kent they are appearing as three separate lines. I am hoping to see them
>> joint with no gaps. The transition from row 4 to row 5 is where the speed
>> has changed from 2.1 knots to 3.4 knots. I am hoping to see another line
>> from row 4 to row 5 in red colour. Similarly for the other disjoint points.
>> Regards
>>
>> Dhiraj Khanna
>> Mob:09873263331
>>
>>
>> On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com> wrote:
>>
>>> Message: 5
>>>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>>>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>> To: r-sig-geo at r-project.org
>>>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>>>> Message-ID:
>>>>         <
>>>> CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ at mail.gmail.com>
>>>> Content-Type: text/plain; charset="utf-8"
>>>>
>>>> I am working with shipping data where I get the dynamic parameters of a
>>>> ship like its position, speed, heading and rate of turn. I am then
>>>> trying
>>>> to plot this on a leaflet map and trying to colour the polylines based
>>>> on
>>>> the speed, but it always shows up in the same colour. Here?s some sample
>>>> data:
>>>>
>>>> <snip>
>>>> This is the code I have tried which doesn?t work:-
>>>>
>>>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>>>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>>>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>>>
>>>> Regards
>>>> Dhiraj Khanna
>>>> Mob:09873263331
>>>
>>>
>>> What are you expecting to see? When I run your code I get a map with
>>> three lines, one red, one orange and one yellow.
>>>
>>> Kent
>>>
>>>
>

	[[alternative HTML version deleted]]


From yud @ending from m@il@montcl@ir@edu  Sun Sep  2 09:23:28 2018
From: yud @ending from m@il@montcl@ir@edu (Danlin Yu)
Date: Sun, 2 Sep 2018 15:23:28 +0800
Subject: [R-sig-Geo] A question about the splm package
Message-ID: <CAHvqQWvtuB6Z38QA5B23ZntrPb2=U0WZ+J4NV_USLQa2vbORAQ@mail.gmail.com>

Dear list:

I hope this email finds you all well.

I've been recently using the spml package to estimate my data sets for
spatial panel analysis. During the process of applying the package, I made
a few mistakes and realized that when I was supplying the weight matrix
(through the listw object) to the spml/spgm routines, there is no check or
guarantee that the order of the spatial objects as represented in the listw
object is exactly the same as the order of the spatial objects in the data
set as supplied by the argument data = (please let me know if I was wrong
here).

I made such a mistake the first time when I was using the spml/spgm
routines, and found that when I used the pdata.frame routine to convert my
panel data to plm agreeable format (I suspect even if I didn't do that, it
will get converted within the routines), the order of the spatial object
gets re-ordered based on their alphabetic order of the "name" item supplied
to the "index" argument, but the listw was still in the order as it was
created based on the original order of the map object (the
SpatialPolygonDataFrame).

I tried to make some work around, but I can not be 100% sure if what I did
was right, so I am writing to ask for your advice.

Here is what I did:

#for a listw object, say w.listw, I changed it to a weight matrix using
listw2mat:

w.wmat <-listw2mat(w.listw)

#I then assign the names of the spatial objects that correspond to each row
and column to the weight matrix:

colnames(w.wmat)<-colnames(spatialObject at data$Name)
rownames(w.wmat)<-colnames(spatialObject at data$Name)

#I then re-order the weight matrix to make sure the order of the spatial
objects in the new weight matrix is ordered alphabetically:

w.wmat <- w.wmat[order(rownames(w.wmat)),]
w.wmat<- w.wmat[,order(colnames(w.wmat))]

#And then I either supply this weight matrix to the spml/spgm routines or
change it back to a listw object and supply it to the routines:

w.listw<-mat2listw(w.wmat)

After I've done that the outputs from the routines are different from if I
didn't do it. But I am not entire sure if I did this correctly or maybe I
am missing something.

Thank you in advance.

Best,

Danlin Yu, Ph.D.
Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
Office: CELS 314
Email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Sun Sep  2 21:19:19 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sun, 2 Sep 2018 21:19:19 +0200
Subject: [R-sig-Geo] A question about the splm package
In-Reply-To: <CAHvqQWvtuB6Z38QA5B23ZntrPb2=U0WZ+J4NV_USLQa2vbORAQ@mail.gmail.com>
References: <CAHvqQWvtuB6Z38QA5B23ZntrPb2=U0WZ+J4NV_USLQa2vbORAQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1809022116280.10258@reclus.nhh.no>

On Sun, 2 Sep 2018, Danlin Yu wrote:

> Dear list:
>
> I hope this email finds you all well.
>
> I've been recently using the spml package to estimate my data sets for
> spatial panel analysis. During the process of applying the package, I made
> a few mistakes and realized that when I was supplying the weight matrix
> (through the listw object) to the spml/spgm routines, there is no check or
> guarantee that the order of the spatial objects as represented in the listw
> object is exactly the same as the order of the spatial objects in the data
> set as supplied by the argument data = (please let me know if I was wrong
> here).

Could you please provide a worked example with (built in?) data - such as 
Produc with US states from the maps package? You'd have to work backwards, 
using the maps and the data to create your input, then try to provoke the 
problem.

Roger

>
> I made such a mistake the first time when I was using the spml/spgm
> routines, and found that when I used the pdata.frame routine to convert my
> panel data to plm agreeable format (I suspect even if I didn't do that, it
> will get converted within the routines), the order of the spatial object
> gets re-ordered based on their alphabetic order of the "name" item supplied
> to the "index" argument, but the listw was still in the order as it was
> created based on the original order of the map object (the
> SpatialPolygonDataFrame).
>
> I tried to make some work around, but I can not be 100% sure if what I did
> was right, so I am writing to ask for your advice.
>
> Here is what I did:
>
> #for a listw object, say w.listw, I changed it to a weight matrix using
> listw2mat:
>
> w.wmat <-listw2mat(w.listw)
>
> #I then assign the names of the spatial objects that correspond to each row
> and column to the weight matrix:
>
> colnames(w.wmat)<-colnames(spatialObject at data$Name)
> rownames(w.wmat)<-colnames(spatialObject at data$Name)
>
> #I then re-order the weight matrix to make sure the order of the spatial
> objects in the new weight matrix is ordered alphabetically:
>
> w.wmat <- w.wmat[order(rownames(w.wmat)),]
> w.wmat<- w.wmat[,order(colnames(w.wmat))]
>
> #And then I either supply this weight matrix to the spml/spgm routines or
> change it back to a listw object and supply it to the routines:
>
> w.listw<-mat2listw(w.wmat)
>
> After I've done that the outputs from the routines are different from if I
> didn't do it. But I am not entire sure if I did this correctly or maybe I
> am missing something.
>
> Thank you in advance.
>
> Best,
>
> Danlin Yu, Ph.D.
> Professor of GIS and Urban Geography
> Department of Earth & Environmental Studies
> Montclair State University
> Montclair, NJ, 07043
> Tel: 973-655-4313
> Fax: 973-655-4072
> Office: CELS 314
> Email: yud at mail.montclair.edu
> webpage: csam.montclair.edu/~yu
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From dhir@jkh@nn@ @ending from gm@il@com  Mon Sep  3 04:34:48 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Mon, 3 Sep 2018 08:04:48 +0530
Subject: [R-sig-Geo] Adding great circle routes as polylines in Leaflet
Message-ID: <CANHhK31knXB+8ev2LEQWOa3y+ZaUgkJ5noAV=iX7Z14j_foqZw@mail.gmail.com>

I am trying to add great circle routes between various regions in R. Here?s
the sample data:

structure(list(CommencingRegion = c("RedSea", "EastAfrica", "GulfofMexico",
"FarEast", "RedSea", "GulfofMexico"), LoadRegion = c("RedSea",
"RedSea", "GulfofMexico", "FarEast", "RedSea", "GulfofMexico"
), DischargeRegion = c("NorthWestAfrica", "WestMedditerranean",
"WestCoastLatinAmerica", "AustraliaNewZealand", "WestMedditerranean",
"WestCoastCentralAmerica"), Count = c(1L, 1L, 2L, 1L, 2L, 5L),
    AvgTCE = c(38879.53, 31783.55, 28520.79, 26068.8, 26054.28,
    25883.81), CLon = c(37.8274879335485, 47.0791103099334, -90.9633701509553,
    146.2727573458, 37.8274879335485, -90.9633701509553), CLat =
c(21.4460561443517,
    -12.9570828789565, 25.2035802054683, 47.6530892619773, 21.4460561443517,
    25.2035802054683), LLon = c(37.8274879335485, 37.8274879335485,
    -90.9633701509553, 146.2727573458, 37.8274879335485, -90.9633701509553
    ), LLat = c(21.4460561443517, 21.4460561443517, 25.2035802054683,
    47.6530892619773, 21.4460561443517, 25.2035802054683), DLon =
c(-17.1597117430475,
    7.03639948506481, -73.4238157230412, 151.051220297802, 7.03639948506481,
    255.83509305644), DLat = c(24.2308740597312, 38.8907379374372,
    -25.8934046406896, -25.1880219406131, 38.8907379374372, 21.8130318388702
    )), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"
))

I would like to plot great circle routes between CommencingRegion to
LoadingRegion and then from LoadingRegion to DischargeRegion for every row.
Additionally, every row needs to be in a different color and the thickness
needs to be proportional to AvgTCE. The last 6 variables in the data above
are the coordinates in Lat Long for the commencing, loading and discharging
regions respectively. I am quite clueless on how to go about achieving
this. This is what I have tried and failed:

leaflet() %>%
  addTiles() %>%
  for(i in 1:6){
    addPolylines(data=gcIntermediate(c(ByRoute$CLon[i],ByRoute$CLat[i]),c(ByRoute$LLon[i],ByRoute$CLat[i]),n=100,addStartEnd
= T,sp=T))
  }

Regards
Dhiraj Khanna
Mob:09873263331

	[[alternative HTML version deleted]]


From btupper @ending from bigelow@org  Mon Sep  3 16:57:23 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Mon, 3 Sep 2018 10:57:23 -0400
Subject: [R-sig-Geo] Adding great circle routes as polylines in Leaflet
In-Reply-To: <CANHhK31knXB+8ev2LEQWOa3y+ZaUgkJ5noAV=iX7Z14j_foqZw@mail.gmail.com>
References: <CANHhK31knXB+8ev2LEQWOa3y+ZaUgkJ5noAV=iX7Z14j_foqZw@mail.gmail.com>
Message-ID: <1E08CE03-B71F-4CF8-8C30-C158393BE28C@bigelow.org>

Hi,

Your example is so close to being reproducible, but not quite close enough.  After some noodling around I figured out that you are using geosphere package in addition to leaflet, and that your tibble is assigned to the `ByRoute` variable.  The following gets you closer - you'll want to resolve the warning messages ... 

Warning messages:
1: In .pointsToMatrix(p2) :longitude > 180
2: In .pointsToMatrix(p2) :longitude > 180
3: In .pointsToMatrix(p2) : longitude > 180


... which you can fix in your tibble.

When adding layers to a map, you really want to create a map object, store it in a variable, say 'm', and ad each layer in an iteration enclosing the pipes (rather than within the pipes).  I'm sure that there will be some wrapping issues if you copy-and-paste from this email.  (Also, please put a bit more white space in your code.  They are calorie-free and make life so much easier on us old fellows.)

Cheers,
Ben


library(leaflet)
library(geosphere)
ByRoute = structure(list(CommencingRegion = c("RedSea", "EastAfrica", "GulfofMexico",
                                        "FarEast", "RedSea", "GulfofMexico"), LoadRegion = c("RedSea",
                                                                                             "RedSea", "GulfofMexico", "FarEast", "RedSea", "GulfofMexico"
                                        ), DischargeRegion = c("NorthWestAfrica", "WestMedditerranean",
                                                               "WestCoastLatinAmerica", "AustraliaNewZealand", "WestMedditerranean",
                                                               "WestCoastCentralAmerica"), Count = c(1L, 1L, 2L, 1L, 2L, 5L),
                   AvgTCE = c(38879.53, 31783.55, 28520.79, 26068.8, 26054.28,
                              25883.81), CLon = c(37.8274879335485, 47.0791103099334, -90.9633701509553,
                                                  146.2727573458, 37.8274879335485, -90.9633701509553), CLat =
                       c(21.4460561443517,
                         -12.9570828789565, 25.2035802054683, 47.6530892619773, 21.4460561443517,
                         25.2035802054683), LLon = c(37.8274879335485, 37.8274879335485,
                                                     -90.9633701509553, 146.2727573458, 37.8274879335485, -90.9633701509553
                         ), LLat = c(21.4460561443517, 21.4460561443517, 25.2035802054683,
                                     47.6530892619773, 21.4460561443517, 25.2035802054683), DLon =
                       c(-17.1597117430475,
                         7.03639948506481, -73.4238157230412, 151.051220297802, 7.03639948506481,
                         255.83509305644), DLat = c(24.2308740597312, 38.8907379374372,
                                                    -25.8934046406896, -25.1880219406131, 38.8907379374372, 21.8130318388702
                         )), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"
                         ))



# create the map object
m <- leaflet() %>%
    addTiles() 

# iteratively add each polyline commence-to-load and load-to-destination
for(i in 1:6){
        m <- m %>% 
            addPolylines(data=gcIntermediate(c(ByRoute$CLon[i], ByRoute$CLat[i]), c(ByRoute$LLon[i], ByRoute$CLat[i]),
                                            n=100, addStartEnd = TRUE, sp = TRUE)) %>%
            addPolylines(data=gcIntermediate(c(ByRoute$LLon[i], ByRoute$LLat[i]), c(ByRoute$DLon[i], ByRoute$DLat[i]),
                                             n=100, addStartEnd = TRUE, sp = TRUE))
}        

m      





> On Sep 2, 2018, at 10:34 PM, Dhiraj Khanna <dhirajkhanna at gmail.com> wrote:
> 
> I am trying to add great circle routes between various regions in R. Here?s
> the sample data:
> 
> structure(list(CommencingRegion = c("RedSea", "EastAfrica", "GulfofMexico",
> "FarEast", "RedSea", "GulfofMexico"), LoadRegion = c("RedSea",
> "RedSea", "GulfofMexico", "FarEast", "RedSea", "GulfofMexico"
> ), DischargeRegion = c("NorthWestAfrica", "WestMedditerranean",
> "WestCoastLatinAmerica", "AustraliaNewZealand", "WestMedditerranean",
> "WestCoastCentralAmerica"), Count = c(1L, 1L, 2L, 1L, 2L, 5L),
>    AvgTCE = c(38879.53, 31783.55, 28520.79, 26068.8, 26054.28,
>    25883.81), CLon = c(37.8274879335485, 47.0791103099334, -90.9633701509553,
>    146.2727573458, 37.8274879335485, -90.9633701509553), CLat =
> c(21.4460561443517,
>    -12.9570828789565, 25.2035802054683, 47.6530892619773, 21.4460561443517,
>    25.2035802054683), LLon = c(37.8274879335485, 37.8274879335485,
>    -90.9633701509553, 146.2727573458, 37.8274879335485, -90.9633701509553
>    ), LLat = c(21.4460561443517, 21.4460561443517, 25.2035802054683,
>    47.6530892619773, 21.4460561443517, 25.2035802054683), DLon =
> c(-17.1597117430475,
>    7.03639948506481, -73.4238157230412, 151.051220297802, 7.03639948506481,
>    255.83509305644), DLat = c(24.2308740597312, 38.8907379374372,
>    -25.8934046406896, -25.1880219406131, 38.8907379374372, 21.8130318388702
>    )), row.names = c(NA, -6L), class = c("tbl_df", "tbl", "data.frame"
> ))
> 
> I would like to plot great circle routes between CommencingRegion to
> LoadingRegion and then from LoadingRegion to DischargeRegion for every row.
> Additionally, every row needs to be in a different color and the thickness
> needs to be proportional to AvgTCE. The last 6 variables in the data above
> are the coordinates in Lat Long for the commencing, loading and discharging
> regions respectively. I am quite clueless on how to go about achieving
> this. This is what I have tried and failed:
> 
> leaflet() %>%
>  addTiles() %>%
>  for(i in 1:6){
>    addPolylines(data=gcIntermediate(c(ByRoute$CLon[i],ByRoute$CLat[i]),c(ByRoute$LLon[i],ByRoute$CLat[i]),n=100,addStartEnd
> = T,sp=T))
>  }
> 
> Regards
> Dhiraj Khanna
> Mob:09873263331
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/


From jo@elui@@guil@rcol @ending from icloud@com  Mon Sep  3 17:16:33 2018
From: jo@elui@@guil@rcol @ending from icloud@com (Jose luis Aguilar colmenero)
Date: Mon, 03 Sep 2018 17:16:33 +0200
Subject: [R-sig-Geo] P-Tree
Message-ID: <71E8F246-8991-418D-8930-05D7A7640F97@icloud.com>

Hi,

I?m student PhD of Data science. I need know if exist any package that contains p-tree algorithm.

Thank?s you

Enviado desde mi iPhone

From btupper @ending from bigelow@org  Mon Sep  3 17:43:06 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Mon, 3 Sep 2018 11:43:06 -0400
Subject: [R-sig-Geo] P-Tree
In-Reply-To: <71E8F246-8991-418D-8930-05D7A7640F97@icloud.com>
References: <71E8F246-8991-418D-8930-05D7A7640F97@icloud.com>
Message-ID: <9B337168-46C6-4332-A232-B01F1D6A328E@bigelow.org>

Hi,

Have you explored RSeek.org <http://rseek.org/>?

https://rseek.org/?q=p-tree <https://rseek.org/?q=p-tree>

Cheers,
Ben
> On Sep 3, 2018, at 11:16 AM, Jose luis Aguilar colmenero via R-sig-Geo <r-sig-geo at r-project.org> wrote:
> 
> Hi,
> 
> I?m student PhD of Data science. I need know if exist any package that contains p-tree algorithm.
> 
> Thank?s you
> 
> Enviado desde mi iPhone
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From kent3737 @ending from gm@il@com  Mon Sep  3 18:52:47 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Mon, 3 Sep 2018 12:52:47 -0400
Subject: [R-sig-Geo] Adding great circle routes as polylines in Leaflet
Message-ID: <CAPP0wyia8DHz9YOKW05H+M97oqnpvpN21N9DXFzM4=m1NiWnwg@mail.gmail.com>

>
> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Adding great circle routes as polylines in
>         Leaflet
> Message-ID:
>         <CANHhK31knXB+8ev2LEQWOa3y+ZaUgkJ5noAV=iX7Z14j_foqZw@
> mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> I am trying to add great circle routes between various regions in R.
>
> I would like to plot great circle routes between CommencingRegion to
> LoadingRegion and then from LoadingRegion to DischargeRegion for every row.
> Additionally, every row needs to be in a different color and the thickness
> needs to be proportional to AvgTCE. The last 6 variables in the data above
> are the coordinates in Lat Long for the commencing, loading and discharging
> regions respectively. I am quite clueless on how to go about achieving
> this. This is what I have tried and failed:
>
> leaflet() %>%
>   addTiles() %>%
>   for(i in 1:6){
>     addPolylines(data=gcIntermediate(c(ByRoute$CLon[
> i],ByRoute$CLat[i]),c(ByRoute$LLon[i],ByRoute$CLat[i]),n=100,addStartEnd
> = T,sp=T))
>   }
>
> Here is a (rather clunky) start:
library(leaflet)
library(geosphere)
library(dplyr)

d = byRoute %>%
  rowwise() %>%
  do(leg1=gcIntermediate(c(.$CLon, .$CLat), c(.$LLon, .$LLat), n=50,
addStartEnd=TRUE),
     leg2=gcIntermediate(c(.$LLon, .$LLat), c(.$DLon, .$DLat), n=50,
addStartEnd=TRUE))

colors=palette()
map = leaflet() %>% addTiles()
for (i in seq_len(nrow(d)))
  map = map %>% addPolylines(data=d$leg1[[i]], color=colors[i],
weight=byRoute$AvgTCE[i]/3000-5) %>%
  addPolylines(data=d$leg2[[i]], color=colors[i],
weight=byRoute$AvgTCE[i]/3000-5)
map

You will have to split the great circles using something like
the plot_my_connection function here:
https://www.r-graph-gallery.com/how-to-draw-connecting-routes-on-map-with-r-and-great-circles/

Is this shipping data? Maybe great circles are not the correct route...
Kent


> Regards
> Dhiraj Khanna
> Mob:09873263331

	[[alternative HTML version deleted]]


From dhir@jkh@nn@ @ending from gm@il@com  Tue Sep  4 06:18:44 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Tue, 4 Sep 2018 09:48:44 +0530
Subject: [R-sig-Geo] Adding great circle routes as polylines in Leaflet
In-Reply-To: <CAPP0wyia8DHz9YOKW05H+M97oqnpvpN21N9DXFzM4=m1NiWnwg@mail.gmail.com>
References: <CAPP0wyia8DHz9YOKW05H+M97oqnpvpN21N9DXFzM4=m1NiWnwg@mail.gmail.com>
Message-ID: <CANHhK32z+bnFBTnA7dRoCG8N6SpuRqqUdCoyooZeh99+jsovsA@mail.gmail.com>

Ben and Kent, thank you so much for your replies. Both work!

@Ben next time will make sure the code is more ?calorie-free? :)

@Kent Johnson <kent3737 at gmail.com> I modified the weight for the lines by
using a scaling factor.

myScale <- function(x){(x-min(x))/(max(x)-min(x))}

ByRoute$AvgTCE <- myScale(ByRoute$AvgTCE)*5 + 1

@Kent Johnson <kent3737 at gmail.com> yes, this is shipping data and you are
right, great circle routes are not the best visualization. The problem I am
facing is that I have oil trade happening over a period of time from
various ports that I need to visualize. Over the selected period of time,
there are hundreds of voyages being undertaken by ships. Plotting them all
as gc routes looks ugly. My approach has been to classify these ports into
regions, which I drew using mapedit and saved them as SF polygons. I then
calculated their centroids and those are the coordinates in the ByRoute
dataframe. Would appreciate your comments on any other visualization which
you think might be appropriate.

Regards
Dhiraj Khanna
Mob:09873263331

On Mon, Sep 3, 2018 at 10:22 PM Kent Johnson <kent3737 at gmail.com> wrote:

> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>> To: r-sig-geo at r-project.org
>> Subject: [R-sig-Geo] Adding great circle routes as polylines in
>>         Leaflet
>> Message-ID:
>>         <CANHhK31knXB+8ev2LEQWOa3y+ZaUgkJ5noAV=
>> iX7Z14j_foqZw at mail.gmail.com>
>> Content-Type: text/plain; charset="utf-8"
>>
>> I am trying to add great circle routes between various regions in R.
>>
>> I would like to plot great circle routes between CommencingRegion to
>> LoadingRegion and then from LoadingRegion to DischargeRegion for every
>> row.
>> Additionally, every row needs to be in a different color and the thickness
>> needs to be proportional to AvgTCE. The last 6 variables in the data above
>> are the coordinates in Lat Long for the commencing, loading and
>> discharging
>> regions respectively. I am quite clueless on how to go about achieving
>> this. This is what I have tried and failed:
>>
>> leaflet() %>%
>>   addTiles() %>%
>>   for(i in 1:6){
>>
>> addPolylines(data=gcIntermediate(c(ByRoute$CLon[i],ByRoute$CLat[i]),c(ByRoute$LLon[i],ByRoute$CLat[i]),n=100,addStartEnd
>> = T,sp=T))
>>   }
>>
>> Here is a (rather clunky) start:
> library(leaflet)
> library(geosphere)
> library(dplyr)
>
> d = byRoute %>%
>   rowwise() %>%
>   do(leg1=gcIntermediate(c(.$CLon, .$CLat), c(.$LLon, .$LLat), n=50,
> addStartEnd=TRUE),
>      leg2=gcIntermediate(c(.$LLon, .$LLat), c(.$DLon, .$DLat), n=50,
> addStartEnd=TRUE))
>
> colors=palette()
> map = leaflet() %>% addTiles()
> for (i in seq_len(nrow(d)))
>   map = map %>% addPolylines(data=d$leg1[[i]], color=colors[i],
> weight=byRoute$AvgTCE[i]/3000-5) %>%
>   addPolylines(data=d$leg2[[i]], color=colors[i],
> weight=byRoute$AvgTCE[i]/3000-5)
> map
>
> You will have to split the great circles using something like
> the plot_my_connection function here:
>
> https://www.r-graph-gallery.com/how-to-draw-connecting-routes-on-map-with-r-and-great-circles/
>
> Is this shipping data? Maybe great circles are not the correct route...
> Kent
>
>
>> Regards
>> Dhiraj Khanna
>> Mob:09873263331
>
>

	[[alternative HTML version deleted]]


From jo@elui@@guil@rcol @ending from icloud@com  Tue Sep  4 08:43:01 2018
From: jo@elui@@guil@rcol @ending from icloud@com (Jose luis Aguilar colmenero)
Date: Tue, 04 Sep 2018 08:43:01 +0200
Subject: [R-sig-Geo] P-Tree
In-Reply-To: <9B337168-46C6-4332-A232-B01F1D6A328E@bigelow.org>
References: <71E8F246-8991-418D-8930-05D7A7640F97@icloud.com>
 <9B337168-46C6-4332-A232-B01F1D6A328E@bigelow.org>
Message-ID: <E81C346D-0F27-4046-B020-97D17000F131@icloud.com>

Thank? you.

But, I?m looking for Peano Count Tree algorithm. This seems in decission trees algorithm.


Enviado desde mi iPhone

> El 3 sept 2018, a las 17:43, Ben Tupper <btupper at bigelow.org> escribi?:
> 
> Hi,
> 
> Have you explored RSeek.org?
> 
> https://rseek.org/?q=p-tree
> 
> Cheers,
> Ben
>> On Sep 3, 2018, at 11:16 AM, Jose luis Aguilar colmenero via R-sig-Geo <r-sig-geo at r-project.org> wrote:
>> 
>> Hi,
>> 
>> I?m student PhD of Data science. I need know if exist any package that contains p-tree algorithm.
>> 
>> Thank?s you
>> 
>> Enviado desde mi iPhone
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> Ecological Forecasting: https://eco.bigelow.org/
> 
> 
> 
> 
> 

	[[alternative HTML version deleted]]


From b@gr@eler @ending from 52north@org  Tue Sep  4 09:41:12 2018
From: b@gr@eler @ending from 52north@org (=?UTF-8?Q?Dr._Benedikt_Gr=c3=a4ler?=)
Date: Tue, 4 Sep 2018 09:41:12 +0200
Subject: [R-sig-Geo] spatial-temporal variograms
In-Reply-To: <CACxE24=-63iuy=FYkKsuexhFwdNiHebUgdjjA_y9zXOWcsWQrQ@mail.gmail.com>
References: <CACxE24=-63iuy=FYkKsuexhFwdNiHebUgdjjA_y9zXOWcsWQrQ@mail.gmail.com>
Message-ID: <f72aeb49-6c9a-0d16-0fa9-9968ce25fd11@52north.org>

Dear Erin,

as you say "it depends", but what I have seen so far from several 
studies, I would consider the sum-metric model as a rather flexible and 
useful model that seems to catch the spatio-temporal dependencies quite 
well ("realistic" is an even tougher question).

HTH,

  Ben


On 28.08.2018 23:45, Erin Hodgess wrote:
> Hello everyone!
> 
> Hope you are having a good day.
> 
> This is an opinion question, please:  Typically, we think of the separable
> model for s/t variograms as not realistic.  Which ones are better, as a
> rule, please?  I know the correct answer is "It depends".  But would we
> consider metric, or sum-metric (or some of the others) more realistic,
> please?
> 
> Thanks,
> Erin
> 
> 
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Benedikt Gr?ler
52?North Initiative for Geospatial Open Source Software GmbH
Martin-Luther-King-Weg 24
48155 Muenster, Germany

E-Mail: b.graeler at 52north.org
Fon: +49-(0)-251/396371-39
Fax: +49-(0)-251/396371-11

http://52north.org/
Twitter: @FiveTwoN

General Managers:
Prof. Dr. Albert Remke, Prof. Dr. Andreas Wytzisk-Arens
Local Court Muenster HRB 10849


From kent3737 @ending from gm@il@com  Tue Sep  4 12:25:52 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Tue, 4 Sep 2018 06:25:52 -0400
Subject: [R-sig-Geo] Adding great circle routes as polylines in Leaflet
In-Reply-To: <CANHhK32z+bnFBTnA7dRoCG8N6SpuRqqUdCoyooZeh99+jsovsA@mail.gmail.com>
References: <CAPP0wyia8DHz9YOKW05H+M97oqnpvpN21N9DXFzM4=m1NiWnwg@mail.gmail.com>
 <CANHhK32z+bnFBTnA7dRoCG8N6SpuRqqUdCoyooZeh99+jsovsA@mail.gmail.com>
Message-ID: <CAPP0wyi_JozL=K6_07OgCxjqS13eDdZSbn4DPn6oJkY=6tpZpA@mail.gmail.com>

On Tue, Sep 4, 2018 at 12:18 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
wrote:

> @Kent Johnson <kent3737 at gmail.com> yes, this is shipping data and you are right, great circle routes are not the best visualization. The problem I am facing is that I have oil trade happening over a period of time from various ports that I need to visualize. Over the selected period of time, there are hundreds of voyages being undertaken by ships. Plotting them all as gc routes looks ugly. My approach has been to classify these ports into regions, which I drew using mapedit and saved them as SF polygons. I then calculated their centroids and those are the coordinates in the ByRoute dataframe. Would appreciate your comments on any other visualization which you think might be appropriate.
>
> If your primary interest is to visualize the flows (not the geography)
then a circle plot might work well. Here is an example showing migration
flows:
https://gjabel.wordpress.com/2016/05/18/updated-circular-plots-for-directional-bilateral-migration-data/
made with
https://cran.r-project.org/web/packages/circlize/index.html

Kent


> Regards
> Dhiraj Khanna
>

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Tue Sep  4 12:51:37 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Tue, 4 Sep 2018 12:51:37 +0200
Subject: [R-sig-Geo] Possibly breaking changes in rgeos
Message-ID: <alpine.LFD.2.21.1809041240050.13296@reclus.nhh.no>

In this sf issue (https://github.com/r-spatial/sf/issues/822), it was 
pointed out that error handling in rgeos (and sf) leaked memory at least 
when invalid geometries triggered an exception, leading to an R error, but 
without the GEOS objects being freed/destroyed. An attempt has been made 
to address this problem in rgeos, and is available for testing from 
R-Forge (version 0.4-1):

install.packages("rgeos", repos="http://R-Forge.R-project.org")

Please check whether this version (throwing the R error after freeing 
memory in calling function rather than throwing the R error immediately on 
exception) has missed any important points in your typical workflows - if 
you find any, please write directly to me as maintainer with a small 
reproducible example for adding to tests/leak_by_exception.R. If you find 
anything, also consider using gdb and/or valgrind to backtrack to the 
rgeos C function causing the mayhem.

Grateful for any reports,

Roger
(rgeos maintainer)

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From erinm@hodge@@ @ending from gm@il@com  Tue Sep  4 16:42:27 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Tue, 4 Sep 2018 08:42:27 -0600
Subject: [R-sig-Geo] spatial-temporal variograms
In-Reply-To: <f72aeb49-6c9a-0d16-0fa9-9968ce25fd11@52north.org>
References: <CACxE24=-63iuy=FYkKsuexhFwdNiHebUgdjjA_y9zXOWcsWQrQ@mail.gmail.com>
 <f72aeb49-6c9a-0d16-0fa9-9968ce25fd11@52north.org>
Message-ID: <CACxE24n3r2CUXC78fWcNM=MNUXL0uKsDOaA6Bfnr3MJ91Gq_wA@mail.gmail.com>

Thanks so much!

Exactly what I was looking for.

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Tue, Sep 4, 2018 at 1:41 AM Dr. Benedikt Gr?ler <b.graeler at 52north.org>
wrote:

> Dear Erin,
>
> as you say "it depends", but what I have seen so far from several
> studies, I would consider the sum-metric model as a rather flexible and
> useful model that seems to catch the spatio-temporal dependencies quite
> well ("realistic" is an even tougher question).
>
> HTH,
>
>   Ben
>
>
> On 28.08.2018 23:45, Erin Hodgess wrote:
> > Hello everyone!
> >
> > Hope you are having a good day.
> >
> > This is an opinion question, please:  Typically, we think of the
> separable
> > model for s/t variograms as not realistic.  Which ones are better, as a
> > rule, please?  I know the correct answer is "It depends".  But would we
> > consider metric, or sum-metric (or some of the others) more realistic,
> > please?
> >
> > Thanks,
> > Erin
> >
> >
> > Erin Hodgess, PhD
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Dr. Benedikt Gr?ler
> 52?North Initiative for Geospatial Open Source Software GmbH
> Martin-Luther-King-Weg 24
> 48155 Muenster, Germany
>
> E-Mail: b.graeler at 52north.org
> Fon: +49-(0)-251/396371-39
> Fax: +49-(0)-251/396371-11
>
> http://52north.org/
> Twitter: @FiveTwoN
>
> General Managers:
> Prof. Dr. Albert Remke, Prof. Dr. Andreas Wytzisk-Arens
> Local Court Muenster HRB 10849
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From e@te@rn@88 @ending from gm@il@com  Wed Sep  5 01:56:35 2018
From: e@te@rn@88 @ending from gm@il@com (Erin Stearns)
Date: Tue, 4 Sep 2018 16:56:35 -0700
Subject: [R-sig-Geo] Leaflet map nested in RShiny App - Improving speed &
 portability
Message-ID: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>

Hello all!

I hope this message finds you all well!

I have 2 questions pertaining to the creation of interactive maps via
Leaflet nested inside an RShiny app. One question has to do with
computation while the other has to do with sharing/off-line interactivity.

*Project description:*
I am creating a global map depicting binary malaria risk (at risk, not at
risk) at the Admin 2 level(current state only uses 5 countries and can be
found here <https://erstearns.shinyapps.io/malariarisk5/>).  I am using an
ESRI base map, then a polygons shapefile containing geometry and attributes
(geographical hierarchy & risk).

*Computation question*
As you see, the RShiny app takes quite a bit of time to render. Does anyone
have any suggestions for improving this? As previously said, this version
only contains 5 countries, thus I cannot continue with my current method to
reach a global map. I have considered finding centroids of all Admin 2
polygons and retaining attribute information here, then rasterizing the
malaria risk shapefile for visualization and using the 2 instead of a
single shapefile with polygon boundaries and attributes.

*Sharing the app/offline interactivity*
I am planning to share this with people who likely do not have R installed
on their laptops nor have they ever coded. Does anyone have any suggestions
for the best way to do this while retaining interactivity?

Thank you all, any insight is greatly appreciated.

Best,
Erin

	[[alternative HTML version deleted]]


From tim@@ppelh@n@ @ending from gm@il@com  Wed Sep  5 07:40:26 2018
From: tim@@ppelh@n@ @ending from gm@il@com (Tim Appelhans)
Date: Wed, 5 Sep 2018 07:40:26 +0200
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
Message-ID: <2ecce0fa-ff87-b16b-7cf0-1e41f7a9fd56@gmail.com>

Hi Erin,

a couple of thoughts regarding computation:

1. you could try using the preferCanvas option in leaflet(options = 
leafletOptions(preferCanvas = TRUE) which likely won't help to speed up 
the rendering but should make the map more responsive.

2. simplify your shapes using the rmapshaper package. Your shapes, 
especially coastlines are quite detailed which puts heavy load on the 
browser.

3. maybe use a simpler world file all-together with less details. I am 
especially thinking of small islands and such.

(My personal priority list would be 3, 2, 1)

Regarding sharing I am not sure I understand. Do you mean sharing as in 
hosting it somewhere on a server, or sharing a file (or similar) with 
someone? If the latter, the RInno package may help (though only supports 
windows).

HTH,

Tim


On 09/05/2018 01:56 AM, Erin Stearns wrote:
> Hello all!
>
> I hope this message finds you all well!
>
> I have 2 questions pertaining to the creation of interactive maps via
> Leaflet nested inside an RShiny app. One question has to do with
> computation while the other has to do with sharing/off-line interactivity.
>
> *Project description:*
> I am creating a global map depicting binary malaria risk (at risk, not at
> risk) at the Admin 2 level(current state only uses 5 countries and can be
> found here <https://erstearns.shinyapps.io/malariarisk5/>).  I am using an
> ESRI base map, then a polygons shapefile containing geometry and attributes
> (geographical hierarchy & risk).
>
> *Computation question*
> As you see, the RShiny app takes quite a bit of time to render. Does anyone
> have any suggestions for improving this? As previously said, this version
> only contains 5 countries, thus I cannot continue with my current method to
> reach a global map. I have considered finding centroids of all Admin 2
> polygons and retaining attribute information here, then rasterizing the
> malaria risk shapefile for visualization and using the 2 instead of a
> single shapefile with polygon boundaries and attributes.
>
> *Sharing the app/offline interactivity*
> I am planning to share this with people who likely do not have R installed
> on their laptops nor have they ever coded. Does anyone have any suggestions
> for the best way to do this while retaining interactivity?
>
> Thank you all, any insight is greatly appreciated.
>
> Best,
> Erin
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From rom@n@lu@trik @ending from gm@il@com  Wed Sep  5 08:28:38 2018
From: rom@n@lu@trik @ending from gm@il@com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Wed, 5 Sep 2018 08:28:38 +0200
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
Message-ID: <CAHT1vpg=oZWf=OAk_eYD6hW+2CZrQgJVV9WvWTAop+zZWu8Vtw@mail.gmail.com>

Regarding sharing, you will need to deploy this to a shiny server.
shinyapps.io offer a paid option which has more functionality and may work
for you if you don't have infrastructure capabilities. If you do, and I've
learnt of this just recently, another option is shinyproxy. It offer some
login capabilities, deploying through docker and is "easy" to setup
(provided nothing goes wrong).

Cheers,
Roman

On Wed, Sep 5, 2018 at 1:57 AM Erin Stearns <estearns88 at gmail.com> wrote:

> Hello all!
>
> I hope this message finds you all well!
>
> I have 2 questions pertaining to the creation of interactive maps via
> Leaflet nested inside an RShiny app. One question has to do with
> computation while the other has to do with sharing/off-line interactivity.
>
> *Project description:*
> I am creating a global map depicting binary malaria risk (at risk, not at
> risk) at the Admin 2 level(current state only uses 5 countries and can be
> found here <https://erstearns.shinyapps.io/malariarisk5/>).  I am using an
> ESRI base map, then a polygons shapefile containing geometry and attributes
> (geographical hierarchy & risk).
>
> *Computation question*
> As you see, the RShiny app takes quite a bit of time to render. Does anyone
> have any suggestions for improving this? As previously said, this version
> only contains 5 countries, thus I cannot continue with my current method to
> reach a global map. I have considered finding centroids of all Admin 2
> polygons and retaining attribute information here, then rasterizing the
> malaria risk shapefile for visualization and using the 2 instead of a
> single shapefile with polygon boundaries and attributes.
>
> *Sharing the app/offline interactivity*
> I am planning to share this with people who likely do not have R installed
> on their laptops nor have they ever coded. Does anyone have any suggestions
> for the best way to do this while retaining interactivity?
>
> Thank you all, any insight is greatly appreciated.
>
> Best,
> Erin
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From b@rowling@on @ending from l@nc@@ter@@c@uk  Wed Sep  5 09:48:25 2018
From: b@rowling@on @ending from l@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 5 Sep 2018 08:48:25 +0100
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
Message-ID: <CANVKczPTXQpjvsk9m_Ok22-1Ke8JXf+FArr8r=_ais7uON6DWQ@mail.gmail.com>

On Wed, Sep 5, 2018 at 12:56 AM, Erin Stearns <estearns88 at gmail.com> wrote:

> Hello all!
>
> I hope this message finds you all well!
>
> I have 2 questions pertaining to the creation of interactive maps via
> Leaflet nested inside an RShiny app. One question has to do with
> computation while the other has to do with sharing/off-line interactivity.
>
> *Computation question*
> As you see, the RShiny app takes quite a bit of time to render. Does anyone
> have any suggestions for improving this? As previously said, this version
> only contains 5 countries, thus I cannot continue with my current method to
> reach a global map. I have considered finding centroids of all Admin 2
> polygons and retaining attribute information here, then rasterizing the
> malaria risk shapefile for visualization and using the 2 instead of a
> single shapefile with polygon boundaries and attributes.
>
>
Unless you plan to add any computational functions to this map then I'd
strongly recommend creating it as a standalone web app and not a shiny app.
This will enable you to use lots of useful Leaflet plugins for speeding
things up, such as only showing country outlines at low zoom levels, and
showing subdivisions only at high zoom levels. This *might* be possible
with R's various leaflet packages but I'd go for full javascript control.

A standalone map would take its data from a JSON file or similar, and you
would then be writing R code that generated that. The mapping app itself is
written in HTML and JS with CSS styling. There are plenty of guides to
web-based interactive mapping, starting with Leaflet.


> *Sharing the app/offline interactivity*
> I am planning to share this with people who likely do not have R installed
> on their laptops nor have they ever coded. Does anyone have any suggestions
> for the best way to do this while retaining interactivity?
>
>  Here's the big win of creating a standalone web map. You only have to
distribute the HTML/CSS/JS and they can be viewed directly (or you also
supply a tiny server that runs locally and only has to feed the files on a
localhost port). No need to have a shiny server anywhere, or install R. Its
simple and clean. It also needs no network connectivity, but you'll not get
a base map - but you could include a low or medium resolution basemap
raster in your package.

The only reason to need Shiny here would be if you wanted people to do
something computational, like click on a bunch of polygons and then fit a
linear model to the selection, since that would require a round-trip to the
server for R to compute the fit. (although I suspect there's a JS package
for linear modelling.... you can do ML in JS these days...)



> Thank you all, any insight is greatly appreciated.
>
> Best,
> Erin
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From rob00x @ending from gm@il@com  Wed Sep  5 11:50:55 2018
From: rob00x @ending from gm@il@com (Robin Lovelace)
Date: Wed, 5 Sep 2018 10:50:55 +0100
Subject: [R-sig-Geo] Feedback request and heads-up: open source book
Message-ID: <CAF16KkU=J=cL9VMch-R-OwsekR8nUXPFUouiz7AMjihxqPExrw@mail.gmail.com>

Hi all,

*Summary*

As mentioned on this list already there is a new book project on R-spatial
called Geocomputation with R. It's an open source and publicly accessible
project which can be found in its entirety here:
https://geocompr.robinlovelace.net/

The purpose of this email is to inform you that the book is now mostly
complete and ready for use. It's also to request feedback before it gets
sent to the printers in early October. There's a ~month long window of
opportunity to contribute, alongside others who have kindly helped already,
to the printed version:
https://github.com/robinlovelace/geocompr#contributing

...

*Details*

A major aim of the project is to provide high quality, up-to-date teaching
material free of charge to people around the world. We have been working on
it for over a year. But only in the last month have we got a cohesive draft
of all 15 chapters, so now is a good time to take a look and start using it
for your own teaching/learning: few things will change in the content.
However, we have a deadline at the end of September to submit the final
draft for the physical book.

Each of us is an experienced R user for geographic applications. We have
some development experience. And each chapter (except for 10, 14 and 15)
have undergone a formal process of 'technical review'. But there will still
inevitably be mistakes, parts that are not clear, and a huge amount of room
for improvement.

We are therefore sending this message to ask for feedback. People in the
wider R-spatial community, and especially readers of the r-sig-geo list
messages, have a huge amount of expertise. We would therefore be grateful
for suggestions from you. Especially useful would feedback on:

   - Any key functions or topics we're missing (note the commonly requested
   topic of spatial interpolation is well-covered in other resources, and gets
   a mention in an extended example at ).
   - Any bits of the explanation that are not crystal clear? Please let us
   know. We try to use plain English but there is definitely room for
   improvement in the prose in many sections.
   - Any exercises that don't make sense, are too easy/hard or are
   unhelpful?

We've had loads of support so far from many people in the form of comments,
reviews and suggestions. And the fact that R-spatial exists at all is
thanks to developers like Edzer and Roger who's code underlies much of what
we have written. So the final thing to say is thanks for being part of the
community that has made this possible. We hope the book contributes to the
community.

For info on how to contribute and the book directly via a Pull Request, see
here: https://geocompr.robinlovelace.net/index.html#how-to-contribute but
emails to me on this address are equally appreciated if you spot anything.

Robin, Jakub and Jannes.

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Wed Sep  5 13:00:12 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Wed, 5 Sep 2018 13:00:12 +0200
Subject: [R-sig-Geo] Possibly breaking changes in rgeos
In-Reply-To: <alpine.LFD.2.21.1809041240050.13296@reclus.nhh.no>
References: <alpine.LFD.2.21.1809041240050.13296@reclus.nhh.no>
Message-ID: <alpine.LFD.2.21.1809051256470.4658@reclus.nhh.no>

I have completed reverse dependency checks using rgeos:

rgeos version: 0.4-1, (SVN revision 572)
  GEOS runtime version: 3.7.0rc2-CAPI-1.11.0 2644482d

without seeing any impacts on CRAN packages using rgeos. I can't check 
development versions of these packages or packages not on CRAN - so please 
do check your workflows as advised earlier before rgeos 0.4-1 is submitted 
to CRAN.

Roger

On Tue, 4 Sep 2018, Roger Bivand wrote:

> In this sf issue (https://github.com/r-spatial/sf/issues/822), it was pointed 
> out that error handling in rgeos (and sf) leaked memory at least when invalid 
> geometries triggered an exception, leading to an R error, but without the 
> GEOS objects being freed/destroyed. An attempt has been made to address this 
> problem in rgeos, and is available for testing from R-Forge (version 0.4-1):
>
> install.packages("rgeos", repos="http://R-Forge.R-project.org")
>
> Please check whether this version (throwing the R error after freeing memory 
> in calling function rather than throwing the R error immediately on 
> exception) has missed any important points in your typical workflows - if you 
> find any, please write directly to me as maintainer with a small reproducible 
> example for adding to tests/leak_by_exception.R. If you find anything, also 
> consider using gdb and/or valgrind to backtrack to the rgeos C function 
> causing the mayhem.
>
> Grateful for any reports,
>
> Roger
> (rgeos maintainer)
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From p@trickl @ending from ou@edu  Wed Sep  5 15:38:37 2018
From: p@trickl @ending from ou@edu (Patrick Livingood)
Date: Wed, 5 Sep 2018 08:38:37 -0500
Subject: [R-sig-Geo] gdistance: Can I use multiple inputs?
Message-ID: <CAJR+QnFKvRJJJxC3pcipNc-nNeg8wA6Q4_A3pZKhVTCQHsMhLg@mail.gmail.com>

I am trying to figure out if gdistance can be used on a certain kind of
multiple input problem.

I am trying to calculate a cost distance allowing for both pedestrian and
canoe travel. Currently I have 5 input rasters. One of them is a landtype,
which indicates a cell is land, a river, or a shore (a buffer around the
river).

I would like to do the following:

* If there is movement between two land cells or between and land and shore
cell, you consult the DEM raster and do a Tobler trip (like the example in
the gdistance vignette)

* If there is movement between two river cells, you first consult the
direction of flow raster, and based on the direction of movement you apply
an upstream or a downstream speed based on the flowspeed raster.

* If there is movement between a river and shore cell, you do a Tobler
trip, but also apply an additional fixed time penalty based on another
raster lookup.

I see that gdistance can use a RasterBrick, but only for mahalanobis
distance. And I can't tell if it is possible to use multiple raster inputs
for a transition function.

 (And for actual use, I can collapse the 5 input rasters into 2, but have
described it this way for clarity.)

Any help would be greatly appreciated,


Patrick Livingood

	[[alternative HTML version deleted]]


From dhir@jkh@nn@ @ending from gm@il@com  Wed Sep  5 16:38:50 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Wed, 5 Sep 2018 20:08:50 +0530
Subject: [R-sig-Geo] Adding great circle routes as polylines in Leaflet
In-Reply-To: <CAPP0wyi_JozL=K6_07OgCxjqS13eDdZSbn4DPn6oJkY=6tpZpA@mail.gmail.com>
References: <CAPP0wyia8DHz9YOKW05H+M97oqnpvpN21N9DXFzM4=m1NiWnwg@mail.gmail.com>
 <CANHhK32z+bnFBTnA7dRoCG8N6SpuRqqUdCoyooZeh99+jsovsA@mail.gmail.com>
 <CAPP0wyi_JozL=K6_07OgCxjqS13eDdZSbn4DPn6oJkY=6tpZpA@mail.gmail.com>
Message-ID: <CANHhK30OUPbN8BZFZUeXxFu4uop+VbiQgRS3x5Oq3n3JAn9piA@mail.gmail.com>

Thanks Kent, this looks great!
Hopefully I should be able to convince my client to use this as a
visualization rather than the rather sparse looking current visualization
on a leaflet map.
Regards

Dhiraj Khanna
Mob:09873263331


On Tue, Sep 4, 2018 at 3:55 PM Kent Johnson <kent3737 at gmail.com> wrote:

>
>
> On Tue, Sep 4, 2018 at 12:18 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
> wrote:
>
>> @Kent Johnson <kent3737 at gmail.com> yes, this is shipping data and you are right, great circle routes are not the best visualization. The problem I am facing is that I have oil trade happening over a period of time from various ports that I need to visualize. Over the selected period of time, there are hundreds of voyages being undertaken by ships. Plotting them all as gc routes looks ugly. My approach has been to classify these ports into regions, which I drew using mapedit and saved them as SF polygons. I then calculated their centroids and those are the coordinates in the ByRoute dataframe. Would appreciate your comments on any other visualization which you think might be appropriate.
>>
>> If your primary interest is to visualize the flows (not the geography)
> then a circle plot might work well. Here is an example showing migration
> flows:
>
> https://gjabel.wordpress.com/2016/05/18/updated-circular-plots-for-directional-bilateral-migration-data/
> made with
> https://cran.r-project.org/web/packages/circlize/index.html
>
> Kent
>
>
>> Regards
>> Dhiraj Khanna
>>
>

	[[alternative HTML version deleted]]


From e@te@rn@88 @ending from gm@il@com  Wed Sep  5 19:17:15 2018
From: e@te@rn@88 @ending from gm@il@com (Erin Stearns)
Date: Wed, 5 Sep 2018 10:17:15 -0700
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CANVKczPTXQpjvsk9m_Ok22-1Ke8JXf+FArr8r=_ais7uON6DWQ@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
 <CANVKczPTXQpjvsk9m_Ok22-1Ke8JXf+FArr8r=_ais7uON6DWQ@mail.gmail.com>
Message-ID: <CAFf5Nh8Vj==J1hLRhK-bTsTRW6uX+cP9yaxGGM2Th5szmQP+dA@mail.gmail.com>

Hello all,

Thank you all very much for the great insight!

*McCrea *- thank you very much, I will test using a geojson first, then
test after reducing geometry.

*Tim* - thank you for the great breakdown and recommended priority list.
Ideally, I would like to be able to share the interactive map with
teammates as a file or something akin to it such that they can simply open
it and interact with the map. RInno is a great option, however I run a
linux machine, so will look into further, but may need to find another
option.

*Roman* - the app is currently deployed to shinyapps.io. Thank you for
sharing about ShinyProxy -- so would this method require 1. Internet and 2.
local installation (vs internal server)?

*Barry* - wow, thank you for your response! Sounds like this would be the
best way to solve both issues. I am not as fluent with HTML and JS, but as
you say, there are likely great guides available to take this route.

Thank you all again, this has been hugely helpful. I wish you all the best
and hope I can be of help to you at some point!

Best,
Erin


On Wed, Sep 5, 2018 at 12:48 AM Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

>
>
> On Wed, Sep 5, 2018 at 12:56 AM, Erin Stearns <estearns88 at gmail.com>
> wrote:
>
>> Hello all!
>>
>> I hope this message finds you all well!
>>
>> I have 2 questions pertaining to the creation of interactive maps via
>> Leaflet nested inside an RShiny app. One question has to do with
>> computation while the other has to do with sharing/off-line interactivity.
>>
>> *Computation question*
>> As you see, the RShiny app takes quite a bit of time to render. Does
>> anyone
>> have any suggestions for improving this? As previously said, this version
>> only contains 5 countries, thus I cannot continue with my current method
>> to
>> reach a global map. I have considered finding centroids of all Admin 2
>> polygons and retaining attribute information here, then rasterizing the
>> malaria risk shapefile for visualization and using the 2 instead of a
>> single shapefile with polygon boundaries and attributes.
>>
>>
> Unless you plan to add any computational functions to this map then I'd
> strongly recommend creating it as a standalone web app and not a shiny app.
> This will enable you to use lots of useful Leaflet plugins for speeding
> things up, such as only showing country outlines at low zoom levels, and
> showing subdivisions only at high zoom levels. This *might* be possible
> with R's various leaflet packages but I'd go for full javascript control.
>
> A standalone map would take its data from a JSON file or similar, and you
> would then be writing R code that generated that. The mapping app itself is
> written in HTML and JS with CSS styling. There are plenty of guides to
> web-based interactive mapping, starting with Leaflet.
>
>
>> *Sharing the app/offline interactivity*
>> I am planning to share this with people who likely do not have R installed
>> on their laptops nor have they ever coded. Does anyone have any
>> suggestions
>> for the best way to do this while retaining interactivity?
>>
>>  Here's the big win of creating a standalone web map. You only have to
> distribute the HTML/CSS/JS and they can be viewed directly (or you also
> supply a tiny server that runs locally and only has to feed the files on a
> localhost port). No need to have a shiny server anywhere, or install R. Its
> simple and clean. It also needs no network connectivity, but you'll not get
> a base map - but you could include a low or medium resolution basemap
> raster in your package.
>
> The only reason to need Shiny here would be if you wanted people to do
> something computational, like click on a bunch of polygons and then fit a
> linear model to the selection, since that would require a round-trip to the
> server for R to compute the fit. (although I suspect there's a JS package
> for linear modelling.... you can do ML in JS these days...)
>
>
>
>> Thank you all, any insight is greatly appreciated.
>>
>> Best,
>> Erin
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From mtregli@ @ending from gm@il@com  Wed Sep  5 20:04:09 2018
From: mtregli@ @ending from gm@il@com (Michael Treglia)
Date: Wed, 5 Sep 2018 14:04:09 -0400
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAFf5Nh8Vj==J1hLRhK-bTsTRW6uX+cP9yaxGGM2Th5szmQP+dA@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
 <CANVKczPTXQpjvsk9m_Ok22-1Ke8JXf+FArr8r=_ais7uON6DWQ@mail.gmail.com>
 <CAFf5Nh8Vj==J1hLRhK-bTsTRW6uX+cP9yaxGGM2Th5szmQP+dA@mail.gmail.com>
Message-ID: <CAPKp32sesmR0QPbVih+Y0A-ZPKpef-no=DoypT5AAaq=nNv7zg@mail.gmail.com>

I'll just second Barry's idea in particular, to set up as a standalone
webpage. You could even use QGIS and the QGIS2Web Plugin to create that,
and host via GitHub pages or similar.

>From R, after creating a map via leaflet and similar packages, you can use
htmlwidgets::saveWidget() to export as a standalone .html file if I recall
correctly.

The one thing regarding a standalone webpage is that if you have a lot of
objects (especially complex ones), that can be a lot for a browser to
handle (given the data are part of the html file).  Might be worth some
quick experimentation, and simplifying polygons would help. (You could
always create a quick landing page, even generated via rMarkdown, and
having a link for maps by different regions or countries - then you could
have a folder of .html files you could distribute, and users could just
open the landing page, and navigate from there).

Just some quick thoughts... Hope this helps.
Mike T

On Wed, Sep 5, 2018 at 1:17 PM Erin Stearns <estearns88 at gmail.com> wrote:

> Hello all,
>
> Thank you all very much for the great insight!
>
> *McCrea *- thank you very much, I will test using a geojson first, then
> test after reducing geometry.
>
> *Tim* - thank you for the great breakdown and recommended priority list.
> Ideally, I would like to be able to share the interactive map with
> teammates as a file or something akin to it such that they can simply open
> it and interact with the map. RInno is a great option, however I run a
> linux machine, so will look into further, but may need to find another
> option.
>
> *Roman* - the app is currently deployed to shinyapps.io. Thank you for
> sharing about ShinyProxy -- so would this method require 1. Internet and 2.
> local installation (vs internal server)?
>
> *Barry* - wow, thank you for your response! Sounds like this would be the
> best way to solve both issues. I am not as fluent with HTML and JS, but as
> you say, there are likely great guides available to take this route.
>
> Thank you all again, this has been hugely helpful. I wish you all the best
> and hope I can be of help to you at some point!
>
> Best,
> Erin
>
>
> On Wed, Sep 5, 2018 at 12:48 AM Barry Rowlingson <
> b.rowlingson at lancaster.ac.uk> wrote:
>
> >
> >
> > On Wed, Sep 5, 2018 at 12:56 AM, Erin Stearns <estearns88 at gmail.com>
> > wrote:
> >
> >> Hello all!
> >>
> >> I hope this message finds you all well!
> >>
> >> I have 2 questions pertaining to the creation of interactive maps via
> >> Leaflet nested inside an RShiny app. One question has to do with
> >> computation while the other has to do with sharing/off-line
> interactivity.
> >>
> >> *Computation question*
> >> As you see, the RShiny app takes quite a bit of time to render. Does
> >> anyone
> >> have any suggestions for improving this? As previously said, this
> version
> >> only contains 5 countries, thus I cannot continue with my current method
> >> to
> >> reach a global map. I have considered finding centroids of all Admin 2
> >> polygons and retaining attribute information here, then rasterizing the
> >> malaria risk shapefile for visualization and using the 2 instead of a
> >> single shapefile with polygon boundaries and attributes.
> >>
> >>
> > Unless you plan to add any computational functions to this map then I'd
> > strongly recommend creating it as a standalone web app and not a shiny
> app.
> > This will enable you to use lots of useful Leaflet plugins for speeding
> > things up, such as only showing country outlines at low zoom levels, and
> > showing subdivisions only at high zoom levels. This *might* be possible
> > with R's various leaflet packages but I'd go for full javascript control.
> >
> > A standalone map would take its data from a JSON file or similar, and you
> > would then be writing R code that generated that. The mapping app itself
> is
> > written in HTML and JS with CSS styling. There are plenty of guides to
> > web-based interactive mapping, starting with Leaflet.
> >
> >
> >> *Sharing the app/offline interactivity*
> >> I am planning to share this with people who likely do not have R
> installed
> >> on their laptops nor have they ever coded. Does anyone have any
> >> suggestions
> >> for the best way to do this while retaining interactivity?
> >>
> >>  Here's the big win of creating a standalone web map. You only have to
> > distribute the HTML/CSS/JS and they can be viewed directly (or you also
> > supply a tiny server that runs locally and only has to feed the files on
> a
> > localhost port). No need to have a shiny server anywhere, or install R.
> Its
> > simple and clean. It also needs no network connectivity, but you'll not
> get
> > a base map - but you could include a low or medium resolution basemap
> > raster in your package.
> >
> > The only reason to need Shiny here would be if you wanted people to do
> > something computational, like click on a bunch of polygons and then fit a
> > linear model to the selection, since that would require a round-trip to
> the
> > server for R to compute the fit. (although I suspect there's a JS package
> > for linear modelling.... you can do ML in JS these days...)
> >
> >
> >
> >> Thank you all, any insight is greatly appreciated.
> >>
> >> Best,
> >> Erin
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From e@te@rn@88 @ending from gm@il@com  Thu Sep  6 19:40:59 2018
From: e@te@rn@88 @ending from gm@il@com (Erin Stearns)
Date: Thu, 6 Sep 2018 10:40:59 -0700
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAPKp32sesmR0QPbVih+Y0A-ZPKpef-no=DoypT5AAaq=nNv7zg@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
 <CANVKczPTXQpjvsk9m_Ok22-1Ke8JXf+FArr8r=_ais7uON6DWQ@mail.gmail.com>
 <CAFf5Nh8Vj==J1hLRhK-bTsTRW6uX+cP9yaxGGM2Th5szmQP+dA@mail.gmail.com>
 <CAPKp32sesmR0QPbVih+Y0A-ZPKpef-no=DoypT5AAaq=nNv7zg@mail.gmail.com>
Message-ID: <CAFf5Nh82r1tX7FW42g_QRT4+Rp3K52efLAJt3jj-nCeAOx+Y-Q@mail.gmail.com>

Thank you, Mike! Yes, I have used htmlwidgets, thank you for that! The
issue is the file begins unwieldy given the amount of data contained in my
leaflet app.

Yeah, it seems like there are a number of options, it's just trying to
determine the best is the tricky part.

Thanks again for the ideas - very much appreciated.

Best,
Erin



On Wed, Sep 5, 2018 at 11:02 AM Michael Treglia <mtreglia at gmail.com> wrote:

> I'll just second Barry's idea in particular, to set up as a standalone
> webpage. You could even use QGIS and the QGIS2Web Plugin to create that,
> and host via GitHub pages or similar.
>
> From R, after creating a map via leaflet and similar packages, you can use
> htmlwidgets::saveWidget() to export as a standalone .html file if I recall
> correctly.
>
> The one thing regarding a standalone webpage is that if you have a lot of
> objects (especially complex ones), that can be a lot for a browser to
> handle (given the data are part of the html file).  Might be worth some
> quick experimentation, and simplifying polygons would help. (You could
> always create a quick landing page, even generated via rMarkdown, and
> having a link for maps by different regions or countries - then you could
> have a folder of .html files you could distribute, and users could just
> open the landing page, and navigate from there).
>
> Just some quick thoughts... Hope this helps.
> Mike T
>
> On Wed, Sep 5, 2018 at 1:17 PM Erin Stearns <estearns88 at gmail.com> wrote:
>
>> Hello all,
>>
>> Thank you all very much for the great insight!
>>
>> *McCrea *- thank you very much, I will test using a geojson first, then
>> test after reducing geometry.
>>
>> *Tim* - thank you for the great breakdown and recommended priority list.
>> Ideally, I would like to be able to share the interactive map with
>> teammates as a file or something akin to it such that they can simply open
>> it and interact with the map. RInno is a great option, however I run a
>> linux machine, so will look into further, but may need to find another
>> option.
>>
>> *Roman* - the app is currently deployed to shinyapps.io. Thank you for
>> sharing about ShinyProxy -- so would this method require 1. Internet and
>> 2.
>> local installation (vs internal server)?
>>
>> *Barry* - wow, thank you for your response! Sounds like this would be the
>> best way to solve both issues. I am not as fluent with HTML and JS, but as
>> you say, there are likely great guides available to take this route.
>>
>> Thank you all again, this has been hugely helpful. I wish you all the best
>> and hope I can be of help to you at some point!
>>
>> Best,
>> Erin
>>
>>
>> On Wed, Sep 5, 2018 at 12:48 AM Barry Rowlingson <
>> b.rowlingson at lancaster.ac.uk> wrote:
>>
>> >
>> >
>> > On Wed, Sep 5, 2018 at 12:56 AM, Erin Stearns <estearns88 at gmail.com>
>> > wrote:
>> >
>> >> Hello all!
>> >>
>> >> I hope this message finds you all well!
>> >>
>> >> I have 2 questions pertaining to the creation of interactive maps via
>> >> Leaflet nested inside an RShiny app. One question has to do with
>> >> computation while the other has to do with sharing/off-line
>> interactivity.
>> >>
>> >> *Computation question*
>> >> As you see, the RShiny app takes quite a bit of time to render. Does
>> >> anyone
>> >> have any suggestions for improving this? As previously said, this
>> version
>> >> only contains 5 countries, thus I cannot continue with my current
>> method
>> >> to
>> >> reach a global map. I have considered finding centroids of all Admin 2
>> >> polygons and retaining attribute information here, then rasterizing the
>> >> malaria risk shapefile for visualization and using the 2 instead of a
>> >> single shapefile with polygon boundaries and attributes.
>> >>
>> >>
>> > Unless you plan to add any computational functions to this map then I'd
>> > strongly recommend creating it as a standalone web app and not a shiny
>> app.
>> > This will enable you to use lots of useful Leaflet plugins for speeding
>> > things up, such as only showing country outlines at low zoom levels, and
>> > showing subdivisions only at high zoom levels. This *might* be possible
>> > with R's various leaflet packages but I'd go for full javascript
>> control.
>> >
>> > A standalone map would take its data from a JSON file or similar, and
>> you
>> > would then be writing R code that generated that. The mapping app
>> itself is
>> > written in HTML and JS with CSS styling. There are plenty of guides to
>> > web-based interactive mapping, starting with Leaflet.
>> >
>> >
>> >> *Sharing the app/offline interactivity*
>> >> I am planning to share this with people who likely do not have R
>> installed
>> >> on their laptops nor have they ever coded. Does anyone have any
>> >> suggestions
>> >> for the best way to do this while retaining interactivity?
>> >>
>> >>  Here's the big win of creating a standalone web map. You only have to
>> > distribute the HTML/CSS/JS and they can be viewed directly (or you also
>> > supply a tiny server that runs locally and only has to feed the files
>> on a
>> > localhost port). No need to have a shiny server anywhere, or install R.
>> Its
>> > simple and clean. It also needs no network connectivity, but you'll not
>> get
>> > a base map - but you could include a low or medium resolution basemap
>> > raster in your package.
>> >
>> > The only reason to need Shiny here would be if you wanted people to do
>> > something computational, like click on a bunch of polygons and then fit
>> a
>> > linear model to the selection, since that would require a round-trip to
>> the
>> > server for R to compute the fit. (although I suspect there's a JS
>> package
>> > for linear modelling.... you can do ML in JS these days...)
>> >
>> >
>> >
>> >> Thank you all, any insight is greatly appreciated.
>> >>
>> >> Best,
>> >> Erin
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From @tef@no@@ofi@ @ending from regione@m@rche@it  Mon Sep 10 14:48:09 2018
From: @tef@no@@ofi@ @ending from regione@m@rche@it (Stefano Sofia)
Date: Mon, 10 Sep 2018 12:48:09 +0000
Subject: [R-sig-Geo] Isohyet maps where the inverse distance method does not
 work correctly
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54CED0B7@ESINO.regionemarche.intra>

Dear list users,
I implemented a code for creation of snowfall isohyets through the inverse distance method applied to a Digital Elevation Model.
Within a big area (approximatively 2.000 km2) I use only six stations, I would expect the snowfall esteem getting smaller with higher distances from the stations.
In my case the snowfall values remain constant all over the area.

This is the relevant part of my code (df_prec is the data frame that contains the coordinates of the stations and the snowfall cumulates).
Could somebody be so patient to spot where is my (big) mistake? (Here attached - as exception - the file picture1.pdf is an example of the result.)

Thank you for your attention and your help
Stefano Sofia



## LOADING SHAPEFILE FOR AREA5
Shape_area <- readOGR(dsn="area.shp", layer="area")
Shape_area_projection <- "+init=epsg:32633 +proj=utm +zone=33 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0"
Shape_area <- spTransform(Shape_area, CRS(Shape_area_projection))

## LOADING DEM
area_DEM raster("dem.tif")
area_DEM <- projectRaster(area_DEM, crs = CRS("+init=epsg:32633"))

## EXTRACTING THE ELEVATION VALUES TO MY POINTS
df_prec$ExtractedElevationValues <- extract(x=area_DEM, y=df_prec)

## CREATING A NEW GRID
newgrid <- as(area_DEM, "SpatialGridDataFrame")
newgrid <- raster(newgrid)
names(newgrid) <- "ExtractedElevationValues"

## Inverse Distance Weighted
if (sum(df_prec$Cumulata) > 0)
{
  OK_rain <- gstat(formula=snowfall_cumulate~ExtractedElevationValues, data=df_prec, locations=newgrid)
  rain_rast <- interpolate(newgrid, OK_rain, xyOnly=FALSE, na.rm=FALSE)

} else
{
  rain_rast <- raster(df_prec)*0
}




         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180910/33c01469/attachment.html>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: picture1.pdf
Type: application/pdf
Size: 16587 bytes
Desc: picture1.pdf
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180910/33c01469/attachment.pdf>

From @riel@fuente@di @ending from u@@ch@cl  Mon Sep 10 19:56:49 2018
From: @riel@fuente@di @ending from u@@ch@cl (Ariel Fuentesdi)
Date: Mon, 10 Sep 2018 14:56:49 -0300
Subject: [R-sig-Geo] help: Problem getting centroids inside lists
Message-ID: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>

Hi everyone,

I have a list of coordinates called "ct" and I want to extract the
centroids of each sublist, but it only works when it has only 3 or more
points. In ct$b$two only has one point; in that case, I would rescue that
point as If it were a centroid.

This is what I did:

library(dplyr)
library(geosphere)

ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat = c(-20,
5, 0)),
                    two = data.frame(lon = c(-18, -16, -6), lat = c(-2, 50,
10))),
           b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1, 25,
5)),
                    two = data.frame(lon = c(-90), lat = c(-1))))

coordinates(ct$a$one) <- ~lon+lat
coordinates(ct$a$two) <- ~lon+lat
coordinates(ct$b$one) <- ~lon+lat
coordinates(ct$b$two) <- ~lon+lat

s <- 1:length(ct)
ctply <- list()
for (i in s){
 for (j in 1:length(ct[[i]])) {
  ctply[[i]][j] <- ifelse(test = lengths(ct[[i]][1]) > 2, yes = sapply(X =
ct[[i]][j],
    FUN = function(y) geosphere::centroid(slot(y, "coords"))), no =
ct[[i]][j] )
 }
}

Thanks in advance

Regards,
Ariel

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Mon Sep 10 22:29:40 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 10 Sep 2018 20:29:40 +0000
Subject: [R-sig-Geo] help: Problem getting centroids inside lists
In-Reply-To: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>
References: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>
Message-ID: <374FF6A2-2FAA-40B5-B0C5-116D14D801B1@llnl.gov>

If all of your data frames had enough points then this should work:

myfun1 <- function(le) {
  list(one=geosphere::centroid(coordinates(le$one)),
       two=geosphere::centroid(coordinates(le$two))
       )
}

lapply(ct, myfun1)

To handle the one point case, try the following, which I think works with your example data, but is untested if there just two points.
It also assumes the data frames are named 'one' and 'two', and will ignore any others. To handle other names, I think you
could replace  $one  with  [[1]]  and  $two  with  [[2]]  .

myfun <- function(le) {
  list(one=if (length(le$one)>1) geosphere::centroid(coordinates(le$one)) else coodinates(le$one),
       two=if (length(le$two)>1) geosphere::centroid(coordinates(le$two)) else coordinates(le$two)
       )
}

lapply(ct, myfun)


To see a little bit of what's going on, try

  myfun(ct[[1]])
  myfun1(ct[[1]])
  myfun1(ct[[2]])
  myfun(ct[[2]])



I would also verify that the length method for objects of class SpatialPoints does return the number of points, as it appears to:

> class(ct$a$two)
[1] "SpatialPoints"
attr(,"package")
[1] "sp"

> length(ct$a$one)
[1] 3
> length(ct$a$two)
[1] 3
> length(ct$a$two)
[1] 3
> length(ct$b$two)
[1] 1

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/10/18, 10:56 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <r-sig-geo-bounces at r-project.org on behalf of ariel.fuentesdi at usach.cl> wrote:

    Hi everyone,
    
    I have a list of coordinates called "ct" and I want to extract the
    centroids of each sublist, but it only works when it has only 3 or more
    points. In ct$b$two only has one point; in that case, I would rescue that
    point as If it were a centroid.
    
    This is what I did:
    
    library(dplyr)
    library(geosphere)
    
    ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat = c(-20,
    5, 0)),
                        two = data.frame(lon = c(-18, -16, -6), lat = c(-2, 50,
    10))),
               b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1, 25,
    5)),
                        two = data.frame(lon = c(-90), lat = c(-1))))
    
    coordinates(ct$a$one) <- ~lon+lat
    coordinates(ct$a$two) <- ~lon+lat
    coordinates(ct$b$one) <- ~lon+lat
    coordinates(ct$b$two) <- ~lon+lat
    
    s <- 1:length(ct)
    ctply <- list()
    for (i in s){
     for (j in 1:length(ct[[i]])) {
      ctply[[i]][j] <- ifelse(test = lengths(ct[[i]][1]) > 2, yes = sapply(X =
    ct[[i]][j],
        FUN = function(y) geosphere::centroid(slot(y, "coords"))), no =
    ct[[i]][j] )
     }
    }
    
    Thanks in advance
    
    Regards,
    Ariel
    
    	[[alternative HTML version deleted]]
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From @olinto@l@t @ending from gm@il@com  Wed Sep 12 04:18:25 2018
From: @olinto@l@t @ending from gm@il@com (Antonio Silva)
Date: Tue, 11 Sep 2018 23:18:25 -0300
Subject: [R-sig-Geo] subsetting a spatial polygons
Message-ID: <CAE8g1gPXigMcSZy5_cpYBeDMM2R22d0kKmVboijbu3TMuD-dfA@mail.gmail.com>

Dear list users

I have a SpatialPolygons with several squares. How to subset it to have
only the squares between given latitudes and longitudes?

In the example

library(sp)
library(raster)
grd <-
GridTopology(cellcentre.offset=c(-47.75,-25.416667),cellsize=c(10/60,10/60),cells.dim=c(23,12))
polys <- as.SpatialPolygons.GridTopology(grd)
proj4string(polys) <- CRS("+proj=longlat +datum=WGS84")
plot(polys,axes=T)

How to select only the squares, let's say, between 24-25?S and 45-46?W?

The farthest I went was:

e <- extent(-45.9,-45.1,-24.9,-24.1) # which is not very elegant
mask <- crop(polys,e)
polys2 <- polys[mask,]
plot(polys2,add=T,col="green")

Thanks a lot. Best regards

-- 
Ant?nio Olinto ?vila da Silva
Instituto de Pesca (Fisheries Institute)
S?o Paulo, Brasil

	[[alternative HTML version deleted]]


From tim@@ppelh@n@ @ending from gm@il@com  Wed Sep 12 07:28:44 2018
From: tim@@ppelh@n@ @ending from gm@il@com (Tim Appelhans)
Date: Wed, 12 Sep 2018 07:28:44 +0200
Subject: [R-sig-Geo] subsetting a spatial polygons
In-Reply-To: <CAE8g1gPXigMcSZy5_cpYBeDMM2R22d0kKmVboijbu3TMuD-dfA@mail.gmail.com>
References: <CAE8g1gPXigMcSZy5_cpYBeDMM2R22d0kKmVboijbu3TMuD-dfA@mail.gmail.com>
Message-ID: <c709d0af-6c2a-3fd0-dc2e-ad5b9dfccbb4@gmail.com>

Antonio,

I am not sure why you think that your solution is not very elegant.
In case you want to have more visual control over the subsetting, you 
could try mapedit:

library(mapedit)
myselection = selectFeatures(polys, mode = "draw")

which will let you draw a e.g. rectangle and only return those features 
that intersect it.

Best
Tim


On 09/12/2018 04:18 AM, Antonio Silva wrote:
> Dear list users
>
> I have a SpatialPolygons with several squares. How to subset it to have
> only the squares between given latitudes and longitudes?
>
> In the example
>
> library(sp)
> library(raster)
> grd <-
> GridTopology(cellcentre.offset=c(-47.75,-25.416667),cellsize=c(10/60,10/60),cells.dim=c(23,12))
> polys <- as.SpatialPolygons.GridTopology(grd)
> proj4string(polys) <- CRS("+proj=longlat +datum=WGS84")
> plot(polys,axes=T)
>
> How to select only the squares, let's say, between 24-25?S and 45-46?W?
>
> The farthest I went was:
>
> e <- extent(-45.9,-45.1,-24.9,-24.1) # which is not very elegant
> mask <- crop(polys,e)
> polys2 <- polys[mask,]
> plot(polys2,add=T,col="green")
>
> Thanks a lot. Best regards
>


From md@umner @ending from gm@il@com  Wed Sep 12 10:04:55 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Wed, 12 Sep 2018 18:04:55 +1000
Subject: [R-sig-Geo] subsetting a spatial polygons
In-Reply-To: <c709d0af-6c2a-3fd0-dc2e-ad5b9dfccbb4@gmail.com>
References: <CAE8g1gPXigMcSZy5_cpYBeDMM2R22d0kKmVboijbu3TMuD-dfA@mail.gmail.com>
 <c709d0af-6c2a-3fd0-dc2e-ad5b9dfccbb4@gmail.com>
Message-ID: <CAAcGz98ZZd8FvFJfjprKNCDJEwvcSaGiTFh3UNverw4kcmDfCA@mail.gmail.com>

crop doesn't select it actually cuts on the boundary, for simple shapes I
use coordinates (for centroids in easy matrix) and select with [ using
tests on x and y.

Cheers, Mike

On Wed, Sep 12, 2018, 15:29 Tim Appelhans <tim.appelhans at gmail.com> wrote:

> Antonio,
>
> I am not sure why you think that your solution is not very elegant.
> In case you want to have more visual control over the subsetting, you
> could try mapedit:
>
> library(mapedit)
> myselection = selectFeatures(polys, mode = "draw")
>
> which will let you draw a e.g. rectangle and only return those features
> that intersect it.
>
> Best
> Tim
>
>
> On 09/12/2018 04:18 AM, Antonio Silva wrote:
> > Dear list users
> >
> > I have a SpatialPolygons with several squares. How to subset it to have
> > only the squares between given latitudes and longitudes?
> >
> > In the example
> >
> > library(sp)
> > library(raster)
> > grd <-
> >
> GridTopology(cellcentre.offset=c(-47.75,-25.416667),cellsize=c(10/60,10/60),cells.dim=c(23,12))
> > polys <- as.SpatialPolygons.GridTopology(grd)
> > proj4string(polys) <- CRS("+proj=longlat +datum=WGS84")
> > plot(polys,axes=T)
> >
> > How to select only the squares, let's say, between 24-25?S and 45-46?W?
> >
> > The farthest I went was:
> >
> > e <- extent(-45.9,-45.1,-24.9,-24.1) # which is not very elegant
> > mask <- crop(polys,e)
> > polys2 <- polys[mask,]
> > plot(polys2,add=T,col="green")
> >
> > Thanks a lot. Best regards
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From @olinto@l@t @ending from gm@il@com  Wed Sep 12 15:08:24 2018
From: @olinto@l@t @ending from gm@il@com (Antonio Silva)
Date: Wed, 12 Sep 2018 10:08:24 -0300
Subject: [R-sig-Geo] subsetting a spatial polygons
In-Reply-To: <CAAcGz98ZZd8FvFJfjprKNCDJEwvcSaGiTFh3UNverw4kcmDfCA@mail.gmail.com>
References: <CAE8g1gPXigMcSZy5_cpYBeDMM2R22d0kKmVboijbu3TMuD-dfA@mail.gmail.com>
 <c709d0af-6c2a-3fd0-dc2e-ad5b9dfccbb4@gmail.com>
 <CAAcGz98ZZd8FvFJfjprKNCDJEwvcSaGiTFh3UNverw4kcmDfCA@mail.gmail.com>
Message-ID: <CAE8g1gMkBBo6twdNEm-u=HEe9G3Nk=Z4iEhCZdeRyNNHZMZVCQ@mail.gmail.com>

Thanks Michael and Tim, thanks for the attention

The first thing I did was I try the subsets using subset.

subset(polys,
coordinates(polys)[,1]>=-46 & coordinates(polys)[,1]<=-45 &
coordinates(polys)[,2]>=-25 & coordinates(polys)[,2]<=-24)

But it seems to work only with Spatial*DataFrame objects. Then I (unluckily)
gave up the x-y approach.

With Mike's advice I tried again as

plot(
    polys[
        coordinates(polys)[,1]>=-46 & coordinates(polys)[,1]<=-45 &
        coordinates(polys)[,2]>=-25 & coordinates(polys)[,2]<=-24,]
,add=T,col="green")

and I got what I wanted in a more "elegant" fashion.

Once more thanks a lot for the attention.

-- 
Ant?nio Olinto ?vila da Silva
Instituto de Pesca (Fisheries Institute)
S?o Paulo, Brasil

Em qua, 12 de set de 2018 ?s 05:05, Michael Sumner <mdsumner at gmail.com>
escreveu:

> crop doesn't select it actually cuts on the boundary, for simple shapes I
> use coordinates (for centroids in easy matrix) and select with [ using
> tests on x and y.
>
> Cheers, Mike
>
> On Wed, Sep 12, 2018, 15:29 Tim Appelhans <tim.appelhans at gmail.com> wrote:
>
> > Antonio,
> >
> > I am not sure why you think that your solution is not very elegant.
> > In case you want to have more visual control over the subsetting, you
> > could try mapedit:
> >
> > library(mapedit)
> > myselection = selectFeatures(polys, mode = "draw")
> >
> > which will let you draw a e.g. rectangle and only return those features
> > that intersect it.
> >
> > Best
> > Tim
> >
> >
> > On 09/12/2018 04:18 AM, Antonio Silva wrote:
> > > Dear list users
> > >
> > > I have a SpatialPolygons with several squares. How to subset it to have
> > > only the squares between given latitudes and longitudes?
> > >
> > > In the example
> > >
> > > library(sp)
> > > library(raster)
> > > grd <-
> > >
> >
> GridTopology(cellcentre.offset=c(-47.75,-25.416667),cellsize=c(10/60,10/60),cells.dim=c(23,12))
> > > polys <- as.SpatialPolygons.GridTopology(grd)
> > > proj4string(polys) <- CRS("+proj=longlat +datum=WGS84")
> > > plot(polys,axes=T)
> > >
> > > How to select only the squares, let's say, between 24-25?S and 45-46?W?
> > >
> > > The farthest I went was:
> > >
> > > e <- extent(-45.9,-45.1,-24.9,-24.1) # which is not very elegant
> > > mask <- crop(polys,e)
> > > polys2 <- polys[mask,]
> > > plot(polys2,add=T,col="green")
> > >
> > > Thanks a lot. Best regards
> > >
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From dirty-h@rry-h@ m@ili@g off gmx@de  Wed Sep 12 20:26:56 2018
From: dirty-h@rry-h@ m@ili@g off gmx@de (dirty-h@rry-h@ m@ili@g off gmx@de)
Date: Wed, 12 Sep 2018 20:26:56 +0200
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
Message-ID: <7f95ddd3-3b5d-5850-fa00-49991fac8307@gmx.de>

Hey Erin,

I agree with everybody who answered, but just for completeness and FYI:

Another approach for sharing a Shiny app offline as a (Windows) Desktop 
app might be using Shiny with "R portable".

For further details please check for example:
https://www.r-bloggers.com/deploying-desktop-apps-with-r/

Cheers!

Harry

Ps. If anybody thinks this is a very bad idea, please let me know, 
because I'm planing to develop something like that ... Thanks!


Am 05.09.2018 um 01:56 schrieb Erin Stearns:
> Hello all!
>
> I hope this message finds you all well!
>
> I have 2 questions pertaining to the creation of interactive maps via
> Leaflet nested inside an RShiny app. One question has to do with
> computation while the other has to do with sharing/off-line interactivity.
>
> *Project description:*
> I am creating a global map depicting binary malaria risk (at risk, not at
> risk) at the Admin 2 level(current state only uses 5 countries and can be
> found here <https://erstearns.shinyapps.io/malariarisk5/>).  I am using an
> ESRI base map, then a polygons shapefile containing geometry and attributes
> (geographical hierarchy & risk).
>
> *Computation question*
> As you see, the RShiny app takes quite a bit of time to render. Does anyone
> have any suggestions for improving this? As previously said, this version
> only contains 5 countries, thus I cannot continue with my current method to
> reach a global map. I have considered finding centroids of all Admin 2
> polygons and retaining attribute information here, then rasterizing the
> malaria risk shapefile for visualization and using the 2 instead of a
> single shapefile with polygon boundaries and attributes.
>
> *Sharing the app/offline interactivity*
> I am planning to share this with people who likely do not have R installed
> on their laptops nor have they ever coded. Does anyone have any suggestions
> for the best way to do this while retaining interactivity?
>
> Thank you all, any insight is greatly appreciated.
>
> Best,
> Erin
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Bill@Poling @ending from zeli@@com  Wed Sep 12 20:27:13 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 12 Sep 2018 18:27:13 +0000
Subject: [R-sig-Geo] Help with simple Map of US states to predefined regions
Message-ID: <SN6PR02MB5088A569EEA708609C3D0CDDEA1B0@SN6PR02MB5088.namprd02.prod.outlook.com>

Hi

I have this df with three columns ProviderState, ProviderStateCode, ProviderRegion I wanted to use to create a simple 5 color map

I have reviewed fiftystater pkg and map pkg but not sure how to simply take these three columns and plot a simple 5 color map based on the Region the state is in?

After looking at these and trying to apply these ideas to my data
https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html
https://cran.r-project.org/web/packages/maps/maps.pdf

I found tutorial at: https://uchicagoconsulting.wordpress.com/tag/r-ggplot2-maps-visualization/

I used the tutorial data and subset in my regions

So now I have come up with the 5 segmented maps and my question becomes how to put this all into one map of the US?


install.packages("maps")
library(maps)
library(ggplot2)

#load us map data
all_states <- map_data("state") View(all_states)
#plot all states with ggplot
p <- ggplot()
p <- p + geom_polygon( data=all_states, aes(x=long, y=lat, group = group),colour="white", fill="blue" )
p

#http://sape.inf.usi.ch/quick-reference/ggplot2/colour

#Pacificstates
Pacificstates <- subset(all_states, region %in% c( "alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington") )
p <- ggplot()
p <- p + geom_polygon( data=Pacificstates, aes(x=long, y=lat, group = group),colour="white", fill="deepskyblue4" ) +
  labs(title = "Pacificstates")
p

#Frontierstates
Frontierstates <- subset(all_states, region %in% c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") )
p <- ggplot()
p <- p + geom_polygon( data=Frontierstates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue1" ) +
      labs(title = "FrontierStates")
p

#Midweststates
Midweststates <- subset(all_states, region %in% c( "iowa", "illinois", "indiana", "michigan", "minnesota", "missouri","north dakota", "nebraska", "ohio","south dakota","wisconsin") )
p <- ggplot()
p <- p + geom_polygon( data=Midweststates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue1" ) +
      labs(title = "MidwestStates")
p

#Southernstates
Southernstates <- subset(all_states, region %in% c( "alabama", "arkansas", "florida", "georgia", "kentucky", "louisiana","mississippi"
                                                    ,"north carolina", "south carolina","tennessee","virginia","west virginia") )
p <- ggplot()
p <- p + geom_polygon( data=Southernstates, aes(x=long, y=lat, group = group),colour="white", fill="royalblue2" ) +
  labs(title = "Southernstates")
p

# Northeaststates
Northeaststates <- subset(all_states, region %in% c( "connecticut", "district of columbia", "delaware", "massachusetts", "maryland", "maine","new hampshire"
                                                     , "new jersey", "new york","pennsylvania","rhode island","vermont") )
p <- ggplot()
p <- p + geom_polygon( data=Northeaststates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue4" ) +
  labs(title = "Northeaststates")
p


#here is my my data but not used above

str(Map1)
Classes 'tbl_df', 'tbl' and 'data.frame':    54 obs. of  3 variables:
$ ProviderState    : chr  "ALASKA" "ALABAMA" "ARKANSAS" "ARIZONA" ...
$ ProviderStateCode: chr  "AK" "AL" "AR" "AZ" ...
$ ProviderRegion   : chr  "Pacific" "South" "South" "Pacific" ...
- attr(*, "spec")=List of 2
  ..$ cols   :List of 3
  .. ..$ ProviderState    : list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ ProviderStateCode: list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  .. ..$ ProviderRegion   : list()
  .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
  ..$ default: list()
  .. ..- attr(*, "class")= chr  "collector_guess" "collector"
  ..- attr(*, "class")= chr "col_spec"

dput(Map1)
structure(list(ProviderState = c("ALASKA", "ALABAMA", "ARKANSAS",
"ARIZONA", "CALIFORNIA", "COLORADO", "CONNECTICUT", "DISTRICT OF COLUMBIA",
"DELAWARE", "FLORIDA", "GEORGIA", "GUAM", "HAWAII", "IOWA", "IDAHO",
"ILLINOIS", "INDIANA", "KANSAS", "KENTUCKY", "LOUISIANA", "MASSACHUSETTS",
"MARYLAND", "MAINE", "MICHIGAN", "MINNESOTA", "MISSOURI", "MISSISSIPPI",
"MONTANA", "NORTH CAROLINA", "NORTH DAKOTA", "NEBRASKA", "NEW HAMPSHIRE",
"NEW JERSEY", "NEW MEXICO", "NEVADA", "NEW YORK", "OHIO", "OKLAHOMA",
"OREGON", "PENNSYLVANIA", "PUERTO RICO", "RHODE ISLAND", "SOUTH CAROLINA",
"SOUTH DAKOTA", "TENNESSEE", "TEXAS", "UTAH", "VIRGINIA", "VIRGIN ISLANDS",
"VERMONT", "WASHINGTON", "WISCONSIN", "WEST VIRGINIA", "WYOMING"
), ProviderStateCode = c("AK", "AL", "AR", "AZ", "CA", "CO",
"CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN",
"KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "MT",
"NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
"PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT",
"WA", "WI", "WV", "WY"), ProviderRegion = c("Pacific", "South",
"South", "Pacific", "Pacific", "Frontier", "Northeast", "Northeast",
"Northeast", "South", "South", "Pacific", "Pacific", "Midwest",
"Frontier", "Midwest", "Midwest", "Frontier", "South", "South",
"Northeast", "Northeast", "Northeast", "Midwest", "Midwest",
"Midwest", "South", "Frontier", "South", "Midwest", "Midwest",
"Northeast", "Northeast", "Frontier", "Pacific", "Northeast",
"Midwest", "Frontier", "Pacific", "Northeast", "Northeast", "Northeast",
"South", "Midwest", "South", "Frontier", "Frontier", "South",
"Northeast", "Northeast", "Pacific", "Midwest", "South", "Frontier"
)), row.names = c(NA, -54L), class = c("tbl_df", "tbl", "data.frame"
), spec = structure(list(cols = list(ProviderState = structure(list(), class = c("collector_character",
"collector")), ProviderStateCode = structure(list(), class = c("collector_character",
"collector")), ProviderRegion = structure(list(), class = c("collector_character",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector"))), class = "col_spec"))

Thank you for any suggestions.

WHP






Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From @riel@fuente@di @ending from u@@ch@cl  Wed Sep 12 20:41:31 2018
From: @riel@fuente@di @ending from u@@ch@cl (Ariel Fuentesdi)
Date: Wed, 12 Sep 2018 15:41:31 -0300
Subject: [R-sig-Geo] help: Problem getting centroids inside lists
In-Reply-To: <374FF6A2-2FAA-40B5-B0C5-116D14D801B1@llnl.gov>
References: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>
 <374FF6A2-2FAA-40B5-B0C5-116D14D801B1@llnl.gov>
Message-ID: <CAD0a9KjNqLd9fefuJDA1nDtWbX1ovT+=zfeLiLoQtQ0ZBn5ycA@mail.gmail.com>

I went to a more general approach, that is:

ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
          FUN = function(y) if(length(y)>1) geosphere::centroid(slot(y,
"coords"))
          else sp::coordinates(slot(y, "coords"))))

But now I want to add the case when they are only two elements. The dataset
will be:

ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat = c(-20,
5, 0)),
                    two = data.frame(lon = c(-18, -16), lat = c(-2, 50))),
           b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1, 25,
5)),
                    two = data.frame(lon = c(-90), lat = c(-1))))
coordinates(ct$a$one) <- ~lon+lat
coordinates(ct$a$two) <- ~lon+lat
coordinates(ct$b$one) <- ~lon+lat
coordinates(ct$b$two) <- ~lon+lat

And I did the following but it doesn't work:

ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
                                                FUN = function(y)
if(length(y)>2) geosphere::centroid(slot(y, "coords"))
                                                else if (length(y) == 1)
sp::coordinates(slot(y, "coords"))
                                                else
mean(sp::coordinates(slot(y, "coords")))))

I need the result of each element of the list will be a matrix of two rows
per column (named: one, two). How do I fix it?

Regards,
Ariel

2018-09-10 17:29 GMT-03:00 MacQueen, Don <macqueen1 at llnl.gov>:

> If all of your data frames had enough points then this should work:
>
> myfun1 <- function(le) {
>   list(one=geosphere::centroid(coordinates(le$one)),
>        two=geosphere::centroid(coordinates(le$two))
>        )
> }
>
> lapply(ct, myfun1)
>
> To handle the one point case, try the following, which I think works with
> your example data, but is untested if there just two points.
> It also assumes the data frames are named 'one' and 'two', and will ignore
> any others. To handle other names, I think you
> could replace  $one  with  [[1]]  and  $two  with  [[2]]  .
>
> myfun <- function(le) {
>   list(one=if (length(le$one)>1) geosphere::centroid(coordinates(le$one))
> else coodinates(le$one),
>        two=if (length(le$two)>1) geosphere::centroid(coordinates(le$two))
> else coordinates(le$two)
>        )
> }
>
> lapply(ct, myfun)
>
>
> To see a little bit of what's going on, try
>
>   myfun(ct[[1]])
>   myfun1(ct[[1]])
>   myfun1(ct[[2]])
>   myfun(ct[[2]])
>
>
>
> I would also verify that the length method for objects of class
> SpatialPoints does return the number of points, as it appears to:
>
> > class(ct$a$two)
> [1] "SpatialPoints"
> attr(,"package")
> [1] "sp"
>
> > length(ct$a$one)
> [1] 3
> > length(ct$a$two)
> [1] 3
> > length(ct$a$two)
> [1] 3
> > length(ct$b$two)
> [1] 1
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 9/10/18, 10:56 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <
> r-sig-geo-bounces at r-project.org on behalf of ariel.fuentesdi at usach.cl>
> wrote:
>
>     Hi everyone,
>
>     I have a list of coordinates called "ct" and I want to extract the
>     centroids of each sublist, but it only works when it has only 3 or more
>     points. In ct$b$two only has one point; in that case, I would rescue
> that
>     point as If it were a centroid.
>
>     This is what I did:
>
>     library(dplyr)
>     library(geosphere)
>
>     ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat =
> c(-20,
>     5, 0)),
>                         two = data.frame(lon = c(-18, -16, -6), lat =
> c(-2, 50,
>     10))),
>                b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1,
> 25,
>     5)),
>                         two = data.frame(lon = c(-90), lat = c(-1))))
>
>     coordinates(ct$a$one) <- ~lon+lat
>     coordinates(ct$a$two) <- ~lon+lat
>     coordinates(ct$b$one) <- ~lon+lat
>     coordinates(ct$b$two) <- ~lon+lat
>
>     s <- 1:length(ct)
>     ctply <- list()
>     for (i in s){
>      for (j in 1:length(ct[[i]])) {
>       ctply[[i]][j] <- ifelse(test = lengths(ct[[i]][1]) > 2, yes =
> sapply(X =
>     ct[[i]][j],
>         FUN = function(y) geosphere::centroid(slot(y, "coords"))), no =
>     ct[[i]][j] )
>      }
>     }
>
>     Thanks in advance
>
>     Regards,
>     Ariel
>
>         [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>

	[[alternative HTML version deleted]]


From vij@ylull@ @ending from gm@il@com  Wed Sep 12 22:06:37 2018
From: vij@ylull@ @ending from gm@il@com (Vijay Lulla)
Date: Wed, 12 Sep 2018 16:06:37 -0400
Subject: [R-sig-Geo] help: Problem getting centroids inside lists
In-Reply-To: <CAD0a9KjNqLd9fefuJDA1nDtWbX1ovT+=zfeLiLoQtQ0ZBn5ycA@mail.gmail.com>
References: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>
 <374FF6A2-2FAA-40B5-B0C5-116D14D801B1@llnl.gov>
 <CAD0a9KjNqLd9fefuJDA1nDtWbX1ovT+=zfeLiLoQtQ0ZBn5ycA@mail.gmail.com>
Message-ID: <CAKkiGbsRRoGTxxAsph5c-DznGi3q7hOrCc0gjyYe-SX-60Y_cg@mail.gmail.com>

Maybe the following function is what you're looking for?

getcentroids <- function(x1) {
  getcentroid <- function(x) {
    coords <- slot(x, "coords")
    numrows <- dim(coords)[1]
    ret <- if(numrows == 2) {
      matrix(apply(coords,2,mean), nrow=1)
    } else {
      if(numrows == 1) {
        coords
      } else {
        geosphere::centroid(coords)
      }
    }
    ret
  }

  r <- lapply(x1, function(x) as.data.frame(getcentroid(x)))

  ret <- matrix(unlist(r), ncol=2, byrow=TRUE)
  rownames(ret) <- names(r); colnames(ret) <- c("lon", "lat")

  ret
}

Now call it as lapply(ct, getcentroids)

HTH,
Vijay.

On Wed, Sep 12, 2018 at 2:42 PM Ariel Fuentesdi <ariel.fuentesdi at usach.cl>
wrote:

> I went to a more general approach, that is:
>
> ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
>           FUN = function(y) if(length(y)>1) geosphere::centroid(slot(y,
> "coords"))
>           else sp::coordinates(slot(y, "coords"))))
>
> But now I want to add the case when they are only two elements. The dataset
> will be:
>
> ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat = c(-20,
> 5, 0)),
>                     two = data.frame(lon = c(-18, -16), lat = c(-2, 50))),
>            b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1, 25,
> 5)),
>                     two = data.frame(lon = c(-90), lat = c(-1))))
> coordinates(ct$a$one) <- ~lon+lat
> coordinates(ct$a$two) <- ~lon+lat
> coordinates(ct$b$one) <- ~lon+lat
> coordinates(ct$b$two) <- ~lon+lat
>
> And I did the following but it doesn't work:
>
> ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
>                                                 FUN = function(y)
> if(length(y)>2) geosphere::centroid(slot(y, "coords"))
>                                                 else if (length(y) == 1)
> sp::coordinates(slot(y, "coords"))
>                                                 else
> mean(sp::coordinates(slot(y, "coords")))))
>
> I need the result of each element of the list will be a matrix of two rows
> per column (named: one, two). How do I fix it?
>
> Regards,
> Ariel
>
> 2018-09-10 17:29 GMT-03:00 MacQueen, Don <macqueen1 at llnl.gov>:
>
> > If all of your data frames had enough points then this should work:
> >
> > myfun1 <- function(le) {
> >   list(one=geosphere::centroid(coordinates(le$one)),
> >        two=geosphere::centroid(coordinates(le$two))
> >        )
> > }
> >
> > lapply(ct, myfun1)
> >
> > To handle the one point case, try the following, which I think works with
> > your example data, but is untested if there just two points.
> > It also assumes the data frames are named 'one' and 'two', and will
> ignore
> > any others. To handle other names, I think you
> > could replace  $one  with  [[1]]  and  $two  with  [[2]]  .
> >
> > myfun <- function(le) {
> >   list(one=if (length(le$one)>1) geosphere::centroid(coordinates(le$one))
> > else coodinates(le$one),
> >        two=if (length(le$two)>1) geosphere::centroid(coordinates(le$two))
> > else coordinates(le$two)
> >        )
> > }
> >
> > lapply(ct, myfun)
> >
> >
> > To see a little bit of what's going on, try
> >
> >   myfun(ct[[1]])
> >   myfun1(ct[[1]])
> >   myfun1(ct[[2]])
> >   myfun(ct[[2]])
> >
> >
> >
> > I would also verify that the length method for objects of class
> > SpatialPoints does return the number of points, as it appears to:
> >
> > > class(ct$a$two)
> > [1] "SpatialPoints"
> > attr(,"package")
> > [1] "sp"
> >
> > > length(ct$a$one)
> > [1] 3
> > > length(ct$a$two)
> > [1] 3
> > > length(ct$a$two)
> > [1] 3
> > > length(ct$b$two)
> > [1] 1
> >
> > --
> > Don MacQueen
> > Lawrence Livermore National Laboratory
> > 7000 East Ave., L-627
> > Livermore, CA 94550
> > 925-423-1062
> > Lab cell 925-724-7509
> >
> >
> >
> > ?On 9/10/18, 10:56 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <
> > r-sig-geo-bounces at r-project.org on behalf of ariel.fuentesdi at usach.cl>
> > wrote:
> >
> >     Hi everyone,
> >
> >     I have a list of coordinates called "ct" and I want to extract the
> >     centroids of each sublist, but it only works when it has only 3 or
> more
> >     points. In ct$b$two only has one point; in that case, I would rescue
> > that
> >     point as If it were a centroid.
> >
> >     This is what I did:
> >
> >     library(dplyr)
> >     library(geosphere)
> >
> >     ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat =
> > c(-20,
> >     5, 0)),
> >                         two = data.frame(lon = c(-18, -16, -6), lat =
> > c(-2, 50,
> >     10))),
> >                b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1,
> > 25,
> >     5)),
> >                         two = data.frame(lon = c(-90), lat = c(-1))))
> >
> >     coordinates(ct$a$one) <- ~lon+lat
> >     coordinates(ct$a$two) <- ~lon+lat
> >     coordinates(ct$b$one) <- ~lon+lat
> >     coordinates(ct$b$two) <- ~lon+lat
> >
> >     s <- 1:length(ct)
> >     ctply <- list()
> >     for (i in s){
> >      for (j in 1:length(ct[[i]])) {
> >       ctply[[i]][j] <- ifelse(test = lengths(ct[[i]][1]) > 2, yes =
> > sapply(X =
> >     ct[[i]][j],
> >         FUN = function(y) geosphere::centroid(slot(y, "coords"))), no =
> >     ct[[i]][j] )
> >      }
> >     }
> >
> >     Thanks in advance
> >
> >     Regards,
> >     Ariel
> >
> >         [[alternative HTML version deleted]]
> >
> >     _______________________________________________
> >     R-sig-Geo mailing list
> >     R-sig-Geo at r-project.org
> >     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Vijay Lulla

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu
ORCID: https://orcid.org/0000-0002-0823-2522
Webpage: http://vijaylulla.com

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Wed Sep 12 22:43:05 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 12 Sep 2018 20:43:05 +0000
Subject: [R-sig-Geo] help: Problem getting centroids inside lists
In-Reply-To: <CAD0a9KjNqLd9fefuJDA1nDtWbX1ovT+=zfeLiLoQtQ0ZBn5ycA@mail.gmail.com>
References: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>
 <374FF6A2-2FAA-40B5-B0C5-116D14D801B1@llnl.gov>
 <CAD0a9KjNqLd9fefuJDA1nDtWbX1ovT+=zfeLiLoQtQ0ZBn5ycA@mail.gmail.com>
Message-ID: <1F57D73E-C7C9-4D4B-9EDC-08315A1E3371@llnl.gov>

On any R mailing list, whenever you say "it doesn't work", you should always copy exactly what R command you gave, and any error messages.

First notice:

> ct$a$two
SpatialPoints:
     lon lat
[1,] -18  -2
[2,] -16  50
Coordinate Reference System (CRS) arguments: NA

Then compare these:

> coordinates(ct$a$two)
     lon lat
[1,] -18  -2
[2,] -16  50

> coordinates(slot(ct$a$two,'coords'))
     lon lat
[1,] -18  -2
[2,] -16  50

The results are the same. Why are you using the slot() function? There is no need, and it makes it more difficult to understand.


You have assumed the mean() function will give you what you want when there are two points. It doesn't. Try it and see:

> mean( coordinates(ct$a$two))
[1] 3.5

> mean(coordinates(slot(ct$a$two,'coords')))
 [1] 3.5

Replace the mean() function with a function that will give you the "centroid" of two points, however you want to define that centroid. Perhaps the means of the two columns? R has a function for that.

-----------------
In this bit:

ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
                                                    FUN = function(y)

Using X = s is wrong because you haven't defined or created s anywhere. X should be ct.

Also, X = ct[[x]] is wrong. When the first FUN is executed, it will be supplied automatically with the whole of ct$a, then ct$b. Try

ctply <- lapply(X = s, FUN = function(x) sapply(X = x,
                                                    FUN = function(y)

The whole thing is easier to understand and test if you define the functions outside the lapply and sapply calls.

-Don
--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/12/18, 11:42 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <r-sig-geo-bounces at r-project.org on behalf of ariel.fuentesdi at usach.cl> wrote:

    I went to a more general approach, that is:
    
    ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
              FUN = function(y) if(length(y)>1) geosphere::centroid(slot(y,
    "coords"))
              else sp::coordinates(slot(y, "coords"))))
    
    But now I want to add the case when they are only two elements. The dataset
    will be:
    
    ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat = c(-20,
    5, 0)),
                        two = data.frame(lon = c(-18, -16), lat = c(-2, 50))),
               b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1, 25,
    5)),
                        two = data.frame(lon = c(-90), lat = c(-1))))
    coordinates(ct$a$one) <- ~lon+lat
    coordinates(ct$a$two) <- ~lon+lat
    coordinates(ct$b$one) <- ~lon+lat
    coordinates(ct$b$two) <- ~lon+lat
    
    And I did the following but it doesn't work:
    
    ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
                                                    FUN = function(y)
    if(length(y)>2) geosphere::centroid(slot(y, "coords"))
                                                    else if (length(y) == 1)
    sp::coordinates(slot(y, "coords"))
                                                    else
    mean(sp::coordinates(slot(y, "coords")))))
    
    I need the result of each element of the list will be a matrix of two rows
    per column (named: one, two). How do I fix it?
    
    Regards,
    Ariel
    
    2018-09-10 17:29 GMT-03:00 MacQueen, Don <macqueen1 at llnl.gov>:
    
    > If all of your data frames had enough points then this should work:
    >
    > myfun1 <- function(le) {
    >   list(one=geosphere::centroid(coordinates(le$one)),
    >        two=geosphere::centroid(coordinates(le$two))
    >        )
    > }
    >
    > lapply(ct, myfun1)
    >
    > To handle the one point case, try the following, which I think works with
    > your example data, but is untested if there just two points.
    > It also assumes the data frames are named 'one' and 'two', and will ignore
    > any others. To handle other names, I think you
    > could replace  $one  with  [[1]]  and  $two  with  [[2]]  .
    >
    > myfun <- function(le) {
    >   list(one=if (length(le$one)>1) geosphere::centroid(coordinates(le$one))
    > else coodinates(le$one),
    >        two=if (length(le$two)>1) geosphere::centroid(coordinates(le$two))
    > else coordinates(le$two)
    >        )
    > }
    >
    > lapply(ct, myfun)
    >
    >
    > To see a little bit of what's going on, try
    >
    >   myfun(ct[[1]])
    >   myfun1(ct[[1]])
    >   myfun1(ct[[2]])
    >   myfun(ct[[2]])
    >
    >
    >
    > I would also verify that the length method for objects of class
    > SpatialPoints does return the number of points, as it appears to:
    >
    > > class(ct$a$two)
    > [1] "SpatialPoints"
    > attr(,"package")
    > [1] "sp"
    >
    > > length(ct$a$one)
    > [1] 3
    > > length(ct$a$two)
    > [1] 3
    > > length(ct$a$two)
    > [1] 3
    > > length(ct$b$two)
    > [1] 1
    >
    > --
    > Don MacQueen
    > Lawrence Livermore National Laboratory
    > 7000 East Ave., L-627
    > Livermore, CA 94550
    > 925-423-1062
    > Lab cell 925-724-7509
    >
    >
    >
    > On 9/10/18, 10:56 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <
    > r-sig-geo-bounces at r-project.org on behalf of ariel.fuentesdi at usach.cl>
    > wrote:
    >
    >     Hi everyone,
    >
    >     I have a list of coordinates called "ct" and I want to extract the
    >     centroids of each sublist, but it only works when it has only 3 or more
    >     points. In ct$b$two only has one point; in that case, I would rescue
    > that
    >     point as If it were a centroid.
    >
    >     This is what I did:
    >
    >     library(dplyr)
    >     library(geosphere)
    >
    >     ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat =
    > c(-20,
    >     5, 0)),
    >                         two = data.frame(lon = c(-18, -16, -6), lat =
    > c(-2, 50,
    >     10))),
    >                b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1,
    > 25,
    >     5)),
    >                         two = data.frame(lon = c(-90), lat = c(-1))))
    >
    >     coordinates(ct$a$one) <- ~lon+lat
    >     coordinates(ct$a$two) <- ~lon+lat
    >     coordinates(ct$b$one) <- ~lon+lat
    >     coordinates(ct$b$two) <- ~lon+lat
    >
    >     s <- 1:length(ct)
    >     ctply <- list()
    >     for (i in s){
    >      for (j in 1:length(ct[[i]])) {
    >       ctply[[i]][j] <- ifelse(test = lengths(ct[[i]][1]) > 2, yes =
    > sapply(X =
    >     ct[[i]][j],
    >         FUN = function(y) geosphere::centroid(slot(y, "coords"))), no =
    >     ct[[i]][j] )
    >      }
    >     }
    >
    >     Thanks in advance
    >
    >     Regards,
    >     Ariel
    >
    >         [[alternative HTML version deleted]]
    >
    >     _______________________________________________
    >     R-sig-Geo mailing list
    >     R-sig-Geo at r-project.org
    >     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    >
    >
    >
    
    	[[alternative HTML version deleted]]
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From @riel@fuente@di @ending from u@@ch@cl  Wed Sep 12 23:09:45 2018
From: @riel@fuente@di @ending from u@@ch@cl (Ariel Fuentesdi)
Date: Wed, 12 Sep 2018 18:09:45 -0300
Subject: [R-sig-Geo] help: Problem getting centroids inside lists
In-Reply-To: <1F57D73E-C7C9-4D4B-9EDC-08315A1E3371@llnl.gov>
References: <CAD0a9Kj3O+TSRLKr1Q_GNnYFsiqL+Uo7uoYf_3OypxDVhe2hkw@mail.gmail.com>
 <374FF6A2-2FAA-40B5-B0C5-116D14D801B1@llnl.gov>
 <CAD0a9KjNqLd9fefuJDA1nDtWbX1ovT+=zfeLiLoQtQ0ZBn5ycA@mail.gmail.com>
 <1F57D73E-C7C9-4D4B-9EDC-08315A1E3371@llnl.gov>
Message-ID: <CAD0a9KgXnt6LCJBJWyx9w8A0CBzWZ+yxtrNq6bqBWKUacdBgSg@mail.gmail.com>

I understand, but I said "it doesn't work" because it gave an undesired
solution, but I'll try to be more explicit next time.
And I forgot to say that: s  <- 1: length(ct)

And thank you for your advice, but the answer of Vijay Lulla resolved my
problem.

Regards,
Ariel

2018-09-12 17:43 GMT-03:00 MacQueen, Don <macqueen1 at llnl.gov>:

> On any R mailing list, whenever you say "it doesn't work", you should
> always copy exactly what R command you gave, and any error messages.
>
> First notice:
>
> > ct$a$two
> SpatialPoints:
>      lon lat
> [1,] -18  -2
> [2,] -16  50
> Coordinate Reference System (CRS) arguments: NA
>
> Then compare these:
>
> > coordinates(ct$a$two)
>      lon lat
> [1,] -18  -2
> [2,] -16  50
>
> > coordinates(slot(ct$a$two,'coords'))
>      lon lat
> [1,] -18  -2
> [2,] -16  50
>
> The results are the same. Why are you using the slot() function? There is
> no need, and it makes it more difficult to understand.
>
>
> You have assumed the mean() function will give you what you want when
> there are two points. It doesn't. Try it and see:
>
> > mean( coordinates(ct$a$two))
> [1] 3.5
>
> > mean(coordinates(slot(ct$a$two,'coords')))
>  [1] 3.5
>
> Replace the mean() function with a function that will give you the
> "centroid" of two points, however you want to define that centroid. Perhaps
> the means of the two columns? R has a function for that.
>
> -----------------
> In this bit:
>
> ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
>                                                     FUN = function(y)
>
> Using X = s is wrong because you haven't defined or created s anywhere. X
> should be ct.
>
> Also, X = ct[[x]] is wrong. When the first FUN is executed, it will be
> supplied automatically with the whole of ct$a, then ct$b. Try
>
> ctply <- lapply(X = s, FUN = function(x) sapply(X = x,
>                                                     FUN = function(y)
>
> The whole thing is easier to understand and test if you define the
> functions outside the lapply and sapply calls.
>
> -Don
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
>
> ?On 9/12/18, 11:42 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <
> r-sig-geo-bounces at r-project.org on behalf of ariel.fuentesdi at usach.cl>
> wrote:
>
>     I went to a more general approach, that is:
>
>     ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
>               FUN = function(y) if(length(y)>1) geosphere::centroid(slot(y,
>     "coords"))
>               else sp::coordinates(slot(y, "coords"))))
>
>     But now I want to add the case when they are only two elements. The
> dataset
>     will be:
>
>     ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60), lat =
> c(-20,
>     5, 0)),
>                         two = data.frame(lon = c(-18, -16), lat = c(-2,
> 50))),
>                b = list(one = data.frame(lon = c(-9, -8, -3), lat = c(-1,
> 25,
>     5)),
>                         two = data.frame(lon = c(-90), lat = c(-1))))
>     coordinates(ct$a$one) <- ~lon+lat
>     coordinates(ct$a$two) <- ~lon+lat
>     coordinates(ct$b$one) <- ~lon+lat
>     coordinates(ct$b$two) <- ~lon+lat
>
>     And I did the following but it doesn't work:
>
>     ctply <- lapply(X = s, FUN = function(x) sapply(X = ct[[x]],
>                                                     FUN = function(y)
>     if(length(y)>2) geosphere::centroid(slot(y, "coords"))
>                                                     else if (length(y) ==
> 1)
>     sp::coordinates(slot(y, "coords"))
>                                                     else
>     mean(sp::coordinates(slot(y, "coords")))))
>
>     I need the result of each element of the list will be a matrix of two
> rows
>     per column (named: one, two). How do I fix it?
>
>     Regards,
>     Ariel
>
>     2018-09-10 17:29 GMT-03:00 MacQueen, Don <macqueen1 at llnl.gov>:
>
>     > If all of your data frames had enough points then this should work:
>     >
>     > myfun1 <- function(le) {
>     >   list(one=geosphere::centroid(coordinates(le$one)),
>     >        two=geosphere::centroid(coordinates(le$two))
>     >        )
>     > }
>     >
>     > lapply(ct, myfun1)
>     >
>     > To handle the one point case, try the following, which I think works
> with
>     > your example data, but is untested if there just two points.
>     > It also assumes the data frames are named 'one' and 'two', and will
> ignore
>     > any others. To handle other names, I think you
>     > could replace  $one  with  [[1]]  and  $two  with  [[2]]  .
>     >
>     > myfun <- function(le) {
>     >   list(one=if (length(le$one)>1) geosphere::centroid(
> coordinates(le$one))
>     > else coodinates(le$one),
>     >        two=if (length(le$two)>1) geosphere::centroid(
> coordinates(le$two))
>     > else coordinates(le$two)
>     >        )
>     > }
>     >
>     > lapply(ct, myfun)
>     >
>     >
>     > To see a little bit of what's going on, try
>     >
>     >   myfun(ct[[1]])
>     >   myfun1(ct[[1]])
>     >   myfun1(ct[[2]])
>     >   myfun(ct[[2]])
>     >
>     >
>     >
>     > I would also verify that the length method for objects of class
>     > SpatialPoints does return the number of points, as it appears to:
>     >
>     > > class(ct$a$two)
>     > [1] "SpatialPoints"
>     > attr(,"package")
>     > [1] "sp"
>     >
>     > > length(ct$a$one)
>     > [1] 3
>     > > length(ct$a$two)
>     > [1] 3
>     > > length(ct$a$two)
>     > [1] 3
>     > > length(ct$b$two)
>     > [1] 1
>     >
>     > --
>     > Don MacQueen
>     > Lawrence Livermore National Laboratory
>     > 7000 East Ave., L-627
>     > Livermore, CA 94550
>     > 925-423-1062
>     > Lab cell 925-724-7509
>     >
>     >
>     >
>     > On 9/10/18, 10:56 AM, "R-sig-Geo on behalf of Ariel Fuentesdi" <
>     > r-sig-geo-bounces at r-project.org on behalf of
> ariel.fuentesdi at usach.cl>
>     > wrote:
>     >
>     >     Hi everyone,
>     >
>     >     I have a list of coordinates called "ct" and I want to extract
> the
>     >     centroids of each sublist, but it only works when it has only 3
> or more
>     >     points. In ct$b$two only has one point; in that case, I would
> rescue
>     > that
>     >     point as If it were a centroid.
>     >
>     >     This is what I did:
>     >
>     >     library(dplyr)
>     >     library(geosphere)
>     >
>     >     ct <- list(a = list(one = data.frame(lon = c(-180, -160, -60),
> lat =
>     > c(-20,
>     >     5, 0)),
>     >                         two = data.frame(lon = c(-18, -16, -6), lat =
>     > c(-2, 50,
>     >     10))),
>     >                b = list(one = data.frame(lon = c(-9, -8, -3), lat =
> c(-1,
>     > 25,
>     >     5)),
>     >                         two = data.frame(lon = c(-90), lat = c(-1))))
>     >
>     >     coordinates(ct$a$one) <- ~lon+lat
>     >     coordinates(ct$a$two) <- ~lon+lat
>     >     coordinates(ct$b$one) <- ~lon+lat
>     >     coordinates(ct$b$two) <- ~lon+lat
>     >
>     >     s <- 1:length(ct)
>     >     ctply <- list()
>     >     for (i in s){
>     >      for (j in 1:length(ct[[i]])) {
>     >       ctply[[i]][j] <- ifelse(test = lengths(ct[[i]][1]) > 2, yes =
>     > sapply(X =
>     >     ct[[i]][j],
>     >         FUN = function(y) geosphere::centroid(slot(y, "coords"))),
> no =
>     >     ct[[i]][j] )
>     >      }
>     >     }
>     >
>     >     Thanks in advance
>     >
>     >     Regards,
>     >     Ariel
>     >
>     >         [[alternative HTML version deleted]]
>     >
>     >     _______________________________________________
>     >     R-sig-Geo mailing list
>     >     R-sig-Geo at r-project.org
>     >     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     >
>     >
>     >
>
>         [[alternative HTML version deleted]]
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Thu Sep 13 14:17:26 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 13 Sep 2018 12:17:26 +0000
Subject: [R-sig-Geo] Help with simple Map of US states with predefined
 regions Version 2
Message-ID: <SN6PR02MB508876571896F0FC8BEFB04CEA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>

Hi,

I hope someone can help me finalize this please.

I am coming close to what I need using variations from two ggplot2 tutorials.

This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored

#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1


library(ggplot2)
install.packages("ggalt")
library(ggalt)     # coord_proj
library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
install.packages("ggthemes")
library(ggthemes)  # theme_map
install.packages("rgeos")
library(rgeos)     # centroids
library(dplyr)

# composite map with AK & HI
usa_map <- usa_composite()

# calculate the centroids for each state gCentroid(usa_map, byid=TRUE) %>%
  as.data.frame() %>%
  mutate(state=usa_map at data$iso_3166_2) -> centroids

# make it usable in ggplot2
usa_map <- fortify(usa_map)

View(usa_map)
t1 <- head(usa_map,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

#

  # |long      |lat      | group| order|  region|subregion |
  # |:---------|:--------|-----:|-----:|-------:|:---------|
  # |-87.46201 |30.38968 |     1|     1| alabama|NA        |
  # |-87.48493 |30.37249 |     1|     2| alabama|NA        |
  # |-87.52503 |30.37249 |     1|     3| alabama|NA        |
  # |-87.53076 |30.33239 |     1|     4| alabama|NA        |
  # |-87.57087 |30.32665 |     1|     5| alabama|NA        |

usa_map <- fortify(usa_map)
gg <- ggplot()
gg <- gg + geom_map(data=usa_map, map=usa_map,
                    aes(long, lat, map_id=id),
                    color="#2b2b2b", size=0.1, fill=NA)

gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg




#************************************************************************************************************************************************************************************/

This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :  line 12 did not have 6 elements

When I use newmexico (all one word) it appears white in the map like the other states not in the table statement

#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors

library(ggplot2)

read.table(text="State.Code   region            St_Abbr   Num_Estab  colors
                      1          1   alaska       Ak        13123    #f7931e
                      3          1   arizona      AZ        18053    #f7931e
                      5          1   california   CA       143937    #f7931e
                      2          1   hawaii       HI       123456    #f7931e
                      4          1   nevada       NV       654321    #f7931e
                      6          1   oregon       OR       321456    #f7931e
                      7          1   washington   WA       456123    #f7931e
                      8          2   colorado     CO       987654    #787878
                      9          2   idaho        ID       13549     #787878
                     10          2   kansas       KS       94531     #787878
                     11          2   montana      MT       456321    #787878
                     12          2   new mexico   NM     582310            #787878 <---Not liking new mexico, saying not 6
                     13          2   oklahoma     OK       214567    #787878
                     14          2   texas        TX       675421    #787878
                     15          2   utah         UT       754321    #787878
                     16          2   wyoming      WY       543124    #787878 ",
stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df

usa_map1 <- map_data("state")
t1 <- head(usa_map1,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
View(usa_map1)
#
#   |long      |lat      | group| order|  region|subregion |
#   |:---------|:--------|-----:|-----:|-------:|:---------|
#   |-87.46201 |30.38968 |     1|     1| alabama|NA        |
#   |-87.48493 |30.37249 |     1|     2| alabama|NA        |
#   |-87.52503 |30.37249 |     1|     3| alabama|NA        |
#   |-87.53076 |30.33239 |     1|     4| alabama|NA        |
#   |-87.57087 |30.32665 |     1|     5| alabama|NA        |



gg <- ggplot()
#View(gg)
gg <- gg + geom_map(data=usa_map1, map=usa_map1,
                    aes(long, lat, map_id=region),
                    color="#2b2b2b", size=0.15, fill=NA)

gg <- gg + geom_map(data=df, map=usa_map1,
                    aes(fill=colors, map_id=region),
                    color="#2b2b2b", size=0.15)


gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg


gg <- gg + scale_color_identity()
gg <- gg + coord_map("polyconic")
gg <- gg + ggthemes::theme_map()
gg

#c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") ) #c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))



William H. Poling, Ph.D., MPH




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From Bill@Poling @ending from zeli@@com  Thu Sep 13 20:31:55 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 13 Sep 2018 18:31:55 +0000
Subject: [R-sig-Geo] 
 [R] Help with simple Map of US states with predefined
 regions Version 2
In-Reply-To: <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>
References: <SN6PR02MB5088847E2A3E48B54FAB2C82EA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>
 <E7C8ACD6-49FC-4ECC-9CED-1249F3301A26@dcn.davis.ca.us>
Message-ID: <SN6PR02MB50885E53405A2781213DC21FEA1A0@SN6PR02MB5088.namprd02.prod.outlook.com>

Thank you Jeff.

Cannot seem to get this to work in the fashion I want it to appear no matter how many websites and packages I investigate.

Letting it go for the moment.

Always appreciate your advice Sir!

WHP
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Thursday, September 13, 2018 10:29 AM
To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with simple Map of US states with predefined regions Version 2

Your data appear to be in fixed format, not space-delimited (or delimited by any other special character), so you should use read.fwf to read it in rather that read.table.

?read.fwf

In the future you should try to identify where your errors are or your data don't look right and ask focused questions about that (reproducible) problem rather than spilling your whole script into an email. That is, your error occurred in the single read.table command and the rest of it was working fine.

On September 13, 2018 5:14:33 AM PDT, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>Hi,
>
>I hope someone can help me finalize this please.
>
>I am coming close to what I need using variations from two ggplot2
>tutorials.
>
>This first gives me the map of the US with AK & HI but I cannot figure
>out how to get my 5 regions colored
>
>#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1<https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1>
>
>
>library(ggplot2)
>install.packages("ggalt")
>library(ggalt) # coord_proj
>library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
>install.packages("ggthemes")
>library(ggthemes) # theme_map
>install.packages("rgeos")
>library(rgeos) # centroids
>library(dplyr)
>
># composite map with AK & HI
>usa_map <- usa_composite()
>
># calculate the centroids for each state
>gCentroid(usa_map, byid=TRUE) %>%
> as.data.frame() %>%
> mutate(state=usa_map at data$iso_3166_2) -> centroids
>
># make it usable in ggplot2
>usa_map <- fortify(usa_map)
>
>View(usa_map)
>t1 <- head(usa_map,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>
>#
>
> # |long |lat | group| order| region|subregion |
> # |:---------|:--------|-----:|-----:|-------:|:---------|
> # |-87.46201 |30.38968 | 1| 1| alabama|NA |
> # |-87.48493 |30.37249 | 1| 2| alabama|NA |
> # |-87.52503 |30.37249 | 1| 3| alabama|NA |
> # |-87.53076 |30.33239 | 1| 4| alabama|NA |
> # |-87.57087 |30.32665 | 1| 5| alabama|NA |
>
>usa_map <- fortify(usa_map)
>gg <- ggplot()
>gg <- gg + geom_map(data=usa_map, map=usa_map,
> aes(long, lat, map_id=id),
> color="#2b2b2b", size=0.1, fill=NA)
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>
>
>#************************************************************************************************************************************************************************************/
>
>This second is an alternative (however not liking AK&HI, not coming
>into the map like scenario one above) but also ignoring new Mexico
>(because recognizing a seventh field value) and I suspect it will do
>the same for new York and new jersey etc.. when I add them to the list.
>
>Error in scan(file = file, what = what, sep = sep, quote = quote, dec =
>dec, : line 12 did not have 6 elements
>
>When I use newmexico (all one word) it appears white in the map like
>the other states not in the table statement
>
>#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors<https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors>
>
>library(ggplot2)
>
>read.table(text="State.Code region St_Abbr Num_Estab
>colors
> 1 1 alaska Ak 13123 #f7931e
> 3 1 arizona AZ 18053 #f7931e
> 5 1 california CA 143937 #f7931e
> 2 1 hawaii HI 123456 #f7931e
> 4 1 nevada NV 654321 #f7931e
> 6 1 oregon OR 321456 #f7931e
> 7 1 washington WA 456123 #f7931e
> 8 2 colorado CO 987654 #787878
> 9 2 idaho ID 13549 #787878
> 10 2 kansas KS 94531 #787878
> 11 2 montana MT 456321 #787878
>12 2 new mexico NM 582310 #787878 <---Not
>liking new mexico, saying not 6
> 13 2 oklahoma OK 214567 #787878
> 14 2 texas TX 675421 #787878
> 15 2 utah UT 754321 #787878
> 16 2 wyoming WY 543124 #787878 ",
>stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df
>
>usa_map1 <- map_data("state")
>t1 <- head(usa_map1,n=5)
>knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
>View(usa_map1)
>#
># |long |lat | group| order| region|subregion |
># |:---------|:--------|-----:|-----:|-------:|:---------|
># |-87.46201 |30.38968 | 1| 1| alabama|NA |
># |-87.48493 |30.37249 | 1| 2| alabama|NA |
># |-87.52503 |30.37249 | 1| 3| alabama|NA |
># |-87.53076 |30.33239 | 1| 4| alabama|NA |
># |-87.57087 |30.32665 | 1| 5| alabama|NA |
>
>
>
>gg <- ggplot()
>#View(gg)
>gg <- gg + geom_map(data=usa_map1, map=usa_map1,
> aes(long, lat, map_id=region),
> color="#2b2b2b", size=0.15, fill=NA)
>
>gg <- gg + geom_map(data=df, map=usa_map1,
> aes(fill=colors, map_id=region),
> color="#2b2b2b", size=0.15)
>
>
>gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2)
>gg <- gg + coord_proj(us_laea_proj)
>gg <- gg + theme_map()
>gg
>
>
>gg <- gg + scale_color_identity()
>gg <- gg + coord_map("polyconic")
>gg <- gg + ggthemes::theme_map()
>gg
>
>#c( "colorado", "idaho", "kansas", "montana", "new mexico",
>"oklahoma","texas", "utah", "wyoming") )
>#c("alaska", "arizona", "california", "hawaii", "nevada",
>"oregon","washington"))
>
>
>
>William H. Poling, Ph.D., MPH
>
>
>
>
>Confidentiality Notice This message is sent from Zelis.
>...{{dropped:13}}
>
>______________________________________________
>R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Thu Sep 13 22:40:47 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 13 Sep 2018 20:40:47 +0000
Subject: [R-sig-Geo] Help with simple Map of US states with predefined
 regions Version 2
Message-ID: <64A36997-BF92-4AE3-8167-DD5834FA6516@llnl.gov>

I know this is not a complete solution -- and it's a very different approach -- but it should at least show you a way to reliably get states colored by region.
(I also left out Alaska and Hawaii, since the point here is how to color the regions)

require(sp)
require(rgdal)

## US Census Bureau Tiger file -- polygons of each US State
## try this URL for download
##      https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29

## unzip to working directory ( '.' )
ustf <- readOGR('.', 'tl_2017_us_state', stringsAsFactors=FALSE)

## note, the Tiger file includes 6 additional territories
dim(ustf)
## [1] 56 14

## get rid of the extra six territories  (state.name comes with R)
cus <- subset(ustf, NAME %in% state.name)

## cheap rename
cus$state <- cus$NAME
cus$abb <- cus$STUSPS

## invent ridiculous groupings of states
cus$grp <- 'a'
cus$grp[11:20] <- 'b'
cus$grp[21:30] <- 'c'
cus$grp[31:40] <- 'd'
cus$grp[41:50] <- 'e'

## assign colors to the groups
cus$color <- 'red'
cus$color[cus$grp=='b'] <- 'green'
cus$color[cus$grp=='c'] <- 'blue'
cus$color[cus$grp=='d'] <- 'brown'
cus$color[cus$grp=='e'] <- 'cyan'

## exclude Alaska, Hawaii
cus <- subset(cus, !(state %in% c('Alaska','Hawaii')))

## get rid of extraneous variables (optional)
cus <- cus[ , c('state','REGION','abb', 'grp') ]

## plot colored by regions as defined in the Census Bureau Tiger file
plot(cus, col=cus$REGION, usePolypath=FALSE)

## color "1" is black, looks bad, do this instead
plot(cus, col=as.numeric(cus$REGION)+1, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

## colors specified by a color variable in the data
plot(cus, col=cus$color, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

(my preferred graphics device does not support Polypath, but probably most others do, so one can omit usePolypath=FALSE)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/13/18, 5:17 AM, "R-sig-Geo on behalf of Bill Poling" <r-sig-geo-bounces at r-project.org on behalf of Bill.Poling at zelis.com> wrote:

    Hi,
    
    I hope someone can help me finalize this please.
    
    I am coming close to what I need using variations from two ggplot2 tutorials.
    
    This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored
    
    #https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1
    
    
    library(ggplot2)
    install.packages("ggalt")
    library(ggalt)     # coord_proj
    library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
    install.packages("ggthemes")
    library(ggthemes)  # theme_map
    install.packages("rgeos")
    library(rgeos)     # centroids
    library(dplyr)
    
    # composite map with AK & HI
    usa_map <- usa_composite()
    
    # calculate the centroids for each state gCentroid(usa_map, byid=TRUE) %>%
      as.data.frame() %>%
      mutate(state=usa_map at data$iso_3166_2) -> centroids
    
    # make it usable in ggplot2
    usa_map <- fortify(usa_map)
    
    View(usa_map)
    t1 <- head(usa_map,n=5)
    knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
    
    #
    
      # |long      |lat      | group| order|  region|subregion |
      # |:---------|:--------|-----:|-----:|-------:|:---------|
      # |-87.46201 |30.38968 |     1|     1| alabama|NA        |
      # |-87.48493 |30.37249 |     1|     2| alabama|NA        |
      # |-87.52503 |30.37249 |     1|     3| alabama|NA        |
      # |-87.53076 |30.33239 |     1|     4| alabama|NA        |
      # |-87.57087 |30.32665 |     1|     5| alabama|NA        |
    
    usa_map <- fortify(usa_map)
    gg <- ggplot()
    gg <- gg + geom_map(data=usa_map, map=usa_map,
                        aes(long, lat, map_id=id),
                        color="#2b2b2b", size=0.1, fill=NA)
    
    gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg
    
    
    
    
    #************************************************************************************************************************************************************************************/
    
    This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.
    
    Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :  line 12 did not have 6 elements
    
    When I use newmexico (all one word) it appears white in the map like the other states not in the table statement
    
    #https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors
    
    library(ggplot2)
    
    read.table(text="State.Code   region            St_Abbr   Num_Estab  colors
                          1          1   alaska       Ak        13123    #f7931e
                          3          1   arizona      AZ        18053    #f7931e
                          5          1   california   CA       143937    #f7931e
                          2          1   hawaii       HI       123456    #f7931e
                          4          1   nevada       NV       654321    #f7931e
                          6          1   oregon       OR       321456    #f7931e
                          7          1   washington   WA       456123    #f7931e
                          8          2   colorado     CO       987654    #787878
                          9          2   idaho        ID       13549     #787878
                         10          2   kansas       KS       94531     #787878
                         11          2   montana      MT       456321    #787878
                         12          2   new mexico   NM     582310            #787878 <---Not liking new mexico, saying not 6
                         13          2   oklahoma     OK       214567    #787878
                         14          2   texas        TX       675421    #787878
                         15          2   utah         UT       754321    #787878
                         16          2   wyoming      WY       543124    #787878 ",
    stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df
    
    usa_map1 <- map_data("state")
    t1 <- head(usa_map1,n=5)
    knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
    View(usa_map1)
    #
    #   |long      |lat      | group| order|  region|subregion |
    #   |:---------|:--------|-----:|-----:|-------:|:---------|
    #   |-87.46201 |30.38968 |     1|     1| alabama|NA        |
    #   |-87.48493 |30.37249 |     1|     2| alabama|NA        |
    #   |-87.52503 |30.37249 |     1|     3| alabama|NA        |
    #   |-87.53076 |30.33239 |     1|     4| alabama|NA        |
    #   |-87.57087 |30.32665 |     1|     5| alabama|NA        |
    
    
    
    gg <- ggplot()
    #View(gg)
    gg <- gg + geom_map(data=usa_map1, map=usa_map1,
                        aes(long, lat, map_id=region),
                        color="#2b2b2b", size=0.15, fill=NA)
    
    gg <- gg + geom_map(data=df, map=usa_map1,
                        aes(fill=colors, map_id=region),
                        color="#2b2b2b", size=0.15)
    
    
    gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg
    
    
    gg <- gg + scale_color_identity()
    gg <- gg + coord_map("polyconic")
    gg <- gg + ggthemes::theme_map()
    gg
    
    #c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") ) #c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))
    
    
    
    William H. Poling, Ph.D., MPH
    
    
    
    
    Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From Guy@B@yegn@k @ending from gov@@b@c@  Fri Sep 14 01:31:10 2018
From: Guy@B@yegn@k @ending from gov@@b@c@ (Guy Bayegnak)
Date: Thu, 13 Sep 2018 23:31:10 +0000
Subject: [R-sig-Geo] Kriging and plotting categorical variables
Message-ID: <71D4D04D426B3B488D6C7FE26376FDE73F59813A@EDM-GOA-EXCH122.goa.ds.gov.ab.ca>

Dear all,
I am working with a set of categorical variables labelled: Group1, Group2, Group3,  and Group4. I created a new categorical variables where I replaced the observation Goup1 to Group4 by 1 to 4.  Then I performed Ordinary Kriging on the new variable [1-4].  But the outcome of the kriging ranges only from 2.0 to 3.5. Basically Goup1 is lost.
Please tell me what I am doing wrong. Also please let me know how to do interpolation on categorical variables in general.

Thanks,

Guy Bayegnak, M.Sc. P.Geol,
Supervisor Groundwater Quality
Senior Hydrogeologist
Groundwater Policy | Water Policy Branch | Alberta Environment and Parks | 780 644 8368
7th Floor, Oxbridge Place | 9820 -106 street Edmonton Alberta T5K 2J6 | Canada


This email and any files transmitted with it are confide...{{dropped:10}}


From m@cqueen1 @ending from llnl@gov  Fri Sep 14 01:51:34 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 13 Sep 2018 23:51:34 +0000
Subject: [R-sig-Geo] 
 Help with simple Map of US states to predefined regions
Message-ID: <5CF4B528-72E0-42A1-94DE-49E97A3E7D3B@llnl.gov>

I know this is not a complete solution -- and it's a very different approach -- but it should at least show you one way to reliably get states colored by region.
I also left out Alaska and Hawaii.

require(sp)
require(rgdal)

## US Census Bureau Tiger file -- polygons of each US State
## try this URL for download
##   https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29

ustf <- readOGR('.', 'tl_2017_us_state', stringsAsFactors=FALSE)

## note, the Tiger file includes 6 additional territories
dim(ustf)
## [1] 56 14

## get rid of the extra six territories  (state.name comes with R)
cus <- subset(ustf, NAME %in% state.name)

## cheap rename
cus$state <- cus$NAME
cus$abb <- cus$STUSPS

## invent ridiculous groupings of states
cus$grp <- 'a'
cus$grp[11:20] <- 'b'
cus$grp[21:30] <- 'c'
cus$grp[31:40] <- 'd'
cus$grp[41:50] <- 'e'

## assign colors to the groups
cus$color <- 'red'
cus$color[cus$grp=='b'] <- 'green'
cus$color[cus$grp=='c'] <- 'blue'
cus$color[cus$grp=='d'] <- 'brown'
cus$color[cus$grp=='e'] <- 'cyan'

## exclude Alaska, Hawaii
cus <- subset(cus, !(state %in% c('Alaska','Hawaii')))

## get rid of extraneous variables (optional)
cus <- cus[ , c('state','REGION','abb', 'grp') ]

## plot colored by regions as defined in the Census Bureau Tiger file
plot(cus, col=cus$REGION, usePolypath=FALSE)
## color "1" is black, looks bad, do this instead
plot(cus, col=as.numeric(cus$REGION)+1, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

## colors specified by a color variable in the data
plot(cus, col=cus$color, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/12/18, 11:27 AM, "R-sig-Geo on behalf of Bill Poling" <r-sig-geo-bounces at r-project.org on behalf of Bill.Poling at zelis.com> wrote:

    Hi
    
    I have this df with three columns ProviderState, ProviderStateCode, ProviderRegion I wanted to use to create a simple 5 color map
    
    I have reviewed fiftystater pkg and map pkg but not sure how to simply take these three columns and plot a simple 5 color map based on the Region the state is in?
    
    After looking at these and trying to apply these ideas to my data
    https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html
    https://cran.r-project.org/web/packages/maps/maps.pdf
    
    I found tutorial at: https://uchicagoconsulting.wordpress.com/tag/r-ggplot2-maps-visualization/
    
    I used the tutorial data and subset in my regions
    
    So now I have come up with the 5 segmented maps and my question becomes how to put this all into one map of the US?
    
    
    install.packages("maps")
    library(maps)
    library(ggplot2)
    
    #load us map data
    all_states <- map_data("state") View(all_states)
    #plot all states with ggplot
    p <- ggplot()
    p <- p + geom_polygon( data=all_states, aes(x=long, y=lat, group = group),colour="white", fill="blue" )
    p
    
    #http://sape.inf.usi.ch/quick-reference/ggplot2/colour
    
    #Pacificstates
    Pacificstates <- subset(all_states, region %in% c( "alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington") )
    p <- ggplot()
    p <- p + geom_polygon( data=Pacificstates, aes(x=long, y=lat, group = group),colour="white", fill="deepskyblue4" ) +
      labs(title = "Pacificstates")
    p
    
    #Frontierstates
    Frontierstates <- subset(all_states, region %in% c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") )
    p <- ggplot()
    p <- p + geom_polygon( data=Frontierstates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue1" ) +
          labs(title = "FrontierStates")
    p
    
    #Midweststates
    Midweststates <- subset(all_states, region %in% c( "iowa", "illinois", "indiana", "michigan", "minnesota", "missouri","north dakota", "nebraska", "ohio","south dakota","wisconsin") )
    p <- ggplot()
    p <- p + geom_polygon( data=Midweststates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue1" ) +
          labs(title = "MidwestStates")
    p
    
    #Southernstates
    Southernstates <- subset(all_states, region %in% c( "alabama", "arkansas", "florida", "georgia", "kentucky", "louisiana","mississippi"
                                                        ,"north carolina", "south carolina","tennessee","virginia","west virginia") )
    p <- ggplot()
    p <- p + geom_polygon( data=Southernstates, aes(x=long, y=lat, group = group),colour="white", fill="royalblue2" ) +
      labs(title = "Southernstates")
    p
    
    # Northeaststates
    Northeaststates <- subset(all_states, region %in% c( "connecticut", "district of columbia", "delaware", "massachusetts", "maryland", "maine","new hampshire"
                                                         , "new jersey", "new york","pennsylvania","rhode island","vermont") )
    p <- ggplot()
    p <- p + geom_polygon( data=Northeaststates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue4" ) +
      labs(title = "Northeaststates")
    p
    
    
    #here is my my data but not used above
    
    str(Map1)
    Classes 'tbl_df', 'tbl' and 'data.frame':    54 obs. of  3 variables:
    $ ProviderState    : chr  "ALASKA" "ALABAMA" "ARKANSAS" "ARIZONA" ...
    $ ProviderStateCode: chr  "AK" "AL" "AR" "AZ" ...
    $ ProviderRegion   : chr  "Pacific" "South" "South" "Pacific" ...
    - attr(*, "spec")=List of 2
      ..$ cols   :List of 3
      .. ..$ ProviderState    : list()
      .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
      .. ..$ ProviderStateCode: list()
      .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
      .. ..$ ProviderRegion   : list()
      .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
      ..$ default: list()
      .. ..- attr(*, "class")= chr  "collector_guess" "collector"
      ..- attr(*, "class")= chr "col_spec"
    
    dput(Map1)
    structure(list(ProviderState = c("ALASKA", "ALABAMA", "ARKANSAS",
    "ARIZONA", "CALIFORNIA", "COLORADO", "CONNECTICUT", "DISTRICT OF COLUMBIA",
    "DELAWARE", "FLORIDA", "GEORGIA", "GUAM", "HAWAII", "IOWA", "IDAHO",
    "ILLINOIS", "INDIANA", "KANSAS", "KENTUCKY", "LOUISIANA", "MASSACHUSETTS",
    "MARYLAND", "MAINE", "MICHIGAN", "MINNESOTA", "MISSOURI", "MISSISSIPPI",
    "MONTANA", "NORTH CAROLINA", "NORTH DAKOTA", "NEBRASKA", "NEW HAMPSHIRE",
    "NEW JERSEY", "NEW MEXICO", "NEVADA", "NEW YORK", "OHIO", "OKLAHOMA",
    "OREGON", "PENNSYLVANIA", "PUERTO RICO", "RHODE ISLAND", "SOUTH CAROLINA",
    "SOUTH DAKOTA", "TENNESSEE", "TEXAS", "UTAH", "VIRGINIA", "VIRGIN ISLANDS",
    "VERMONT", "WASHINGTON", "WISCONSIN", "WEST VIRGINIA", "WYOMING"
    ), ProviderStateCode = c("AK", "AL", "AR", "AZ", "CA", "CO",
    "CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN",
    "KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "MT",
    "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
    "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT",
    "WA", "WI", "WV", "WY"), ProviderRegion = c("Pacific", "South",
    "South", "Pacific", "Pacific", "Frontier", "Northeast", "Northeast",
    "Northeast", "South", "South", "Pacific", "Pacific", "Midwest",
    "Frontier", "Midwest", "Midwest", "Frontier", "South", "South",
    "Northeast", "Northeast", "Northeast", "Midwest", "Midwest",
    "Midwest", "South", "Frontier", "South", "Midwest", "Midwest",
    "Northeast", "Northeast", "Frontier", "Pacific", "Northeast",
    "Midwest", "Frontier", "Pacific", "Northeast", "Northeast", "Northeast",
    "South", "Midwest", "South", "Frontier", "Frontier", "South",
    "Northeast", "Northeast", "Pacific", "Midwest", "South", "Frontier"
    )), row.names = c(NA, -54L), class = c("tbl_df", "tbl", "data.frame"
    ), spec = structure(list(cols = list(ProviderState = structure(list(), class = c("collector_character",
    "collector")), ProviderStateCode = structure(list(), class = c("collector_character",
    "collector")), ProviderRegion = structure(list(), class = c("collector_character",
    "collector"))), default = structure(list(), class = c("collector_guess",
    "collector"))), class = "col_spec"))
    
    Thank you for any suggestions.
    
    WHP
    
    
    
    
    
    
    Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From tom@hengl @ending from gm@il@com  Fri Sep 14 07:45:06 2018
From: tom@hengl @ending from gm@il@com (Tomislav Hengl)
Date: Fri, 14 Sep 2018 07:45:06 +0200
Subject: [R-sig-Geo] Kriging and plotting categorical variables
In-Reply-To: <71D4D04D426B3B488D6C7FE26376FDE73F59813A@EDM-GOA-EXCH122.goa.ds.gov.ab.ca>
References: <71D4D04D426B3B488D6C7FE26376FDE73F59813A@EDM-GOA-EXCH122.goa.ds.gov.ab.ca>
Message-ID: <CAC4wKHkMWRfd1ut+k33iFmEkBn2mB5qUXFNik5+mMjj9u+eZNg@mail.gmail.com>

As an efficient alternative to kriging you could try using RF with buffer
distances to classes incorporated into the model:

https://peerj.com/articles/5518/

Also described in:

https://envirometrix.github.io/PredictiveSoilMapping/soilmapping-using-mla.html#spatial-prediction-of-soil-types

New kid in the class.

On Fri, Sep 14, 2018, 01:31 Guy Bayegnak <Guy.Bayegnak at gov.ab.ca> wrote:

> Dear all,
> I am working with a set of categorical variables labelled: Group1, Group2,
> Group3,  and Group4. I created a new categorical variables where I replaced
> the observation Goup1 to Group4 by 1 to 4.  Then I performed Ordinary
> Kriging on the new variable [1-4].  But the outcome of the kriging ranges
> only from 2.0 to 3.5. Basically Goup1 is lost.
> Please tell me what I am doing wrong. Also please let me know how to do
> interpolation on categorical variables in general.
>
> Thanks,
>
> Guy Bayegnak, M.Sc. P.Geol,
> Supervisor Groundwater Quality
> Senior Hydrogeologist
> Groundwater Policy | Water Policy Branch | Alberta Environment and Parks |
> 780 644 8368
> 7th Floor, Oxbridge Place | 9820 -106 street Edmonton Alberta T5K 2J6 |
> Canada
>
>
> This email and any files transmitted with it are confide...{{dropped:10}}
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From bertr@m@o@tendorf @ending from @del@ide@edu@@u  Fri Sep 14 08:33:25 2018
From: bertr@m@o@tendorf @ending from @del@ide@edu@@u (Bertram Ostendorf)
Date: Fri, 14 Sep 2018 06:33:25 +0000
Subject: [R-sig-Geo] st_union crashes RStudio - bug?
Message-ID: <ME1PR01MB08363E5A05F0823ABA7089BFB2190@ME1PR01MB0836.ausprd01.prod.outlook.com>

I am trying to dissolve internal boundaries using sf.  This crashes R in the example geojson map below, a simple map of Australia?s states and territories. I am using a polygon layer that processes fine in other GIS and also works fine using sp (casting to sp and using gUnaryUnion).  I am not after a workaround but I'd like to explore what's different in sf and why this particular layer causes problems.

My questions: Is this a bug in sf? Have others experienced similar issues using simple features?

Thanks

Bertram Ostendorf
Chair for Spatial Environmental Sciences
Director: Spatial Information Group
The University of Adelaide, AUSTRALIA 5005


# Here's my example layer and code:
# Note: Neither ArcGIS ?repair geometry? nor  ?st_is_valid? show any issues.
library(sf)
library(ggplot2)
# read Australia.geojson from dropbox, 15.5Mb
test <- st_read("https://www.dropbox.com/s/060c6lfijyx1e5v/Australia.geojson?dl=1")
st_is_valid(test)

# The next lines work fine, I added them to illustrate what works
ggplot(test) + geom_sf(aes(fill=STATE))
ACT <- test[test$STATE == 'ACT', ]
NSW <- test[test$STATE == 'NSW', ]
ACTandNSW <- test[test$STATE %in% c('NSW','ACT'), ]
noACT <- test[test$STATE != 'ACT', ]
noNSW <- test[test$STATE != 'NSW', ]
noACTandNSW <- test[!test$STATE %in% c('NSW','ACT'), ]
# st_union works ok for most subsets. But note that some internal boundaries are not removed.
ok <- st_union(ACT)
# donut polygons work fine
ok <- st_union(NSW)
# donut polygons (NSW) filled (ACT) work fine
ok <- st_union(ACTandNSW)
# all states except NSW work fine
ok <- st_union(noNSW)
# ok if both ACT and NSW are removed
ok <- st_union(noACTandNSW)
ggplot(ok) + geom_sf()

# Thing go pear-shaped if the hole is filled (ACT in NSW), but only if neighbours of the filled donut polygon are present.
# The two lines below stall R and eventually crash RStudio
crash <- st_union(test)
# Australia without its governing territory kills R
crash <- st_union(noACT)


> sessionInfo()
R version 3.5.1 (2018-07-02)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
  [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252    LC_MONETARY=English_Australia.1252
[4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252

attached base packages:
  [1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] ggplot2_3.0.0 sf_0.6-3

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.18     rstudioapi_0.7   bindr_0.1.1      magrittr_1.5     units_0.6-0      tidyselect_0.2.4 munsell_0.5.0
[8] colorspace_1.3-2 R6_2.2.2         rlang_0.2.2      plyr_1.8.4       dplyr_0.7.6      tools_3.5.1      grid_3.5.1
[15] gtable_0.2.0     e1071_1.7-0      DBI_1.0.0        withr_2.1.2      class_7.3-14     digest_0.6.16    yaml_2.2.0
[22] lazyeval_0.2.1   assertthat_0.2.0 tibble_1.4.2     crayon_1.3.4     bindrcpp_0.2.2   spData_0.2.9.3   purrr_0.2.5
[29] glue_1.3.0       compiler_3.5.1   pillar_1.3.0     scales_1.0.0     classInt_0.2-3   pkgconfig_2.0.2





	[[alternative HTML version deleted]]


From rom@n@lu@trik @ending from gm@il@com  Fri Sep 14 09:31:39 2018
From: rom@n@lu@trik @ending from gm@il@com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Fri, 14 Sep 2018 09:31:39 +0200
Subject: [R-sig-Geo] st_union crashes RStudio - bug?
In-Reply-To: <ME1PR01MB08363E5A05F0823ABA7089BFB2190@ME1PR01MB0836.ausprd01.prod.outlook.com>
References: <ME1PR01MB08363E5A05F0823ABA7089BFB2190@ME1PR01MB0836.ausprd01.prod.outlook.com>
Message-ID: <CAHT1vpjmffS2yyevYrh3se23=Yf=7grKGeqZXYzCvXV22y0Xrg@mail.gmail.com>

Crashes R or Rstudio?

Cheers,
Roman

On Fri, Sep 14, 2018 at 8:33 AM Bertram Ostendorf <
bertram.ostendorf at adelaide.edu.au> wrote:

> I am trying to dissolve internal boundaries using sf.  This crashes R in
> the example geojson map below, a simple map of Australia?s states and
> territories. I am using a polygon layer that processes fine in other GIS
> and also works fine using sp (casting to sp and using gUnaryUnion).  I am
> not after a workaround but I'd like to explore what's different in sf and
> why this particular layer causes problems.
>
> My questions: Is this a bug in sf? Have others experienced similar issues
> using simple features?
>
> Thanks
>
> Bertram Ostendorf
> Chair for Spatial Environmental Sciences
> Director: Spatial Information Group
> The University of Adelaide, AUSTRALIA 5005
>
>
> # Here's my example layer and code:
> # Note: Neither ArcGIS ?repair geometry? nor  ?st_is_valid? show any
> issues.
> library(sf)
> library(ggplot2)
> # read Australia.geojson from dropbox, 15.5Mb
> test <- st_read("
> https://www.dropbox.com/s/060c6lfijyx1e5v/Australia.geojson?dl=1")
> st_is_valid(test)
>
> # The next lines work fine, I added them to illustrate what works
> ggplot(test) + geom_sf(aes(fill=STATE))
> ACT <- test[test$STATE == 'ACT', ]
> NSW <- test[test$STATE == 'NSW', ]
> ACTandNSW <- test[test$STATE %in% c('NSW','ACT'), ]
> noACT <- test[test$STATE != 'ACT', ]
> noNSW <- test[test$STATE != 'NSW', ]
> noACTandNSW <- test[!test$STATE %in% c('NSW','ACT'), ]
> # st_union works ok for most subsets. But note that some internal
> boundaries are not removed.
> ok <- st_union(ACT)
> # donut polygons work fine
> ok <- st_union(NSW)
> # donut polygons (NSW) filled (ACT) work fine
> ok <- st_union(ACTandNSW)
> # all states except NSW work fine
> ok <- st_union(noNSW)
> # ok if both ACT and NSW are removed
> ok <- st_union(noACTandNSW)
> ggplot(ok) + geom_sf()
>
> # Thing go pear-shaped if the hole is filled (ACT in NSW), but only if
> neighbours of the filled donut polygon are present.
> # The two lines below stall R and eventually crash RStudio
> crash <- st_union(test)
> # Australia without its governing territory kills R
> crash <- st_union(noACT)
>
>
> > sessionInfo()
> R version 3.5.1 (2018-07-02)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
>   [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>   LC_MONETARY=English_Australia.1252
> [4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252
>
> attached base packages:
>   [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>   [1] ggplot2_3.0.0 sf_0.6-3
>
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.18     rstudioapi_0.7   bindr_0.1.1      magrittr_1.5
>  units_0.6-0      tidyselect_0.2.4 munsell_0.5.0
> [8] colorspace_1.3-2 R6_2.2.2         rlang_0.2.2      plyr_1.8.4
>  dplyr_0.7.6      tools_3.5.1      grid_3.5.1
> [15] gtable_0.2.0     e1071_1.7-0      DBI_1.0.0        withr_2.1.2
> class_7.3-14     digest_0.6.16    yaml_2.2.0
> [22] lazyeval_0.2.1   assertthat_0.2.0 tibble_1.4.2     crayon_1.3.4
>  bindrcpp_0.2.2   spData_0.2.9.3   purrr_0.2.5
> [29] glue_1.3.0       compiler_3.5.1   pillar_1.3.0     scales_1.0.0
>  classInt_0.2-3   pkgconfig_2.0.2
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From jerome@m@thieu @ending from upmc@fr  Fri Sep 14 09:36:53 2018
From: jerome@m@thieu @ending from upmc@fr (=?UTF-8?Q?J=C3=A9rome_Mathieu?=)
Date: Fri, 14 Sep 2018 09:36:53 +0200
Subject: [R-sig-Geo] 
 Help with simple Map of US states to predefined regions
In-Reply-To: <SN6PR02MB5088A569EEA708609C3D0CDDEA1B0@SN6PR02MB5088.namprd02.prod.outlook.com>
References: <SN6PR02MB5088A569EEA708609C3D0CDDEA1B0@SN6PR02MB5088.namprd02.prod.outlook.com>
Message-ID: <CALEhSiTVxvBm2BVVAe2UcFtkqOR0MXOdmfO7fvVv3RC27XgCsQ@mail.gmail.com>

Hi,

this might help you:

http://socviz.co/maps.html#maps
http://strimas.com/r/tidy-sf/
https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html

Jerome





Le mer. 12 sept. 2018 ? 20:27, Bill Poling <Bill.Poling at zelis.com> a ?crit :
>
> Hi
>
> I have this df with three columns ProviderState, ProviderStateCode,
ProviderRegion I wanted to use to create a simple 5 color map
>
> I have reviewed fiftystater pkg and map pkg but not sure how to simply
take these three columns and plot a simple 5 color map based on the Region
the state is in?
>
> After looking at these and trying to apply these ideas to my data
>
https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html
> https://cran.r-project.org/web/packages/maps/maps.pdf
>
> I found tutorial at:
https://uchicagoconsulting.wordpress.com/tag/r-ggplot2-maps-visualization/
>
> I used the tutorial data and subset in my regions
>
> So now I have come up with the 5 segmented maps and my question becomes
how to put this all into one map of the US?
>
>
> install.packages("maps")
> library(maps)
> library(ggplot2)
>
> #load us map data
> all_states <- map_data("state") View(all_states)
> #plot all states with ggplot
> p <- ggplot()
> p <- p + geom_polygon( data=all_states, aes(x=long, y=lat, group =
group),colour="white", fill="blue" )
> p
>
> #http://sape.inf.usi.ch/quick-reference/ggplot2/colour
>
> #Pacificstates
> Pacificstates <- subset(all_states, region %in% c( "alaska", "arizona",
"california", "hawaii", "nevada", "oregon","washington") )
> p <- ggplot()
> p <- p + geom_polygon( data=Pacificstates, aes(x=long, y=lat, group =
group),colour="white", fill="deepskyblue4" ) +
>   labs(title = "Pacificstates")
> p
>
> #Frontierstates
> Frontierstates <- subset(all_states, region %in% c( "colorado", "idaho",
"kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") )
> p <- ggplot()
> p <- p + geom_polygon( data=Frontierstates, aes(x=long, y=lat, group =
group),colour="white", fill="dodgerblue1" ) +
>       labs(title = "FrontierStates")
> p
>
> #Midweststates
> Midweststates <- subset(all_states, region %in% c( "iowa", "illinois",
"indiana", "michigan", "minnesota", "missouri","north dakota", "nebraska",
"ohio","south dakota","wisconsin") )
> p <- ggplot()
> p <- p + geom_polygon( data=Midweststates, aes(x=long, y=lat, group =
group),colour="white", fill="dodgerblue1" ) +
>       labs(title = "MidwestStates")
> p
>
> #Southernstates
> Southernstates <- subset(all_states, region %in% c( "alabama",
"arkansas", "florida", "georgia", "kentucky", "louisiana","mississippi"
>                                                     ,"north carolina",
"south carolina","tennessee","virginia","west virginia") )
> p <- ggplot()
> p <- p + geom_polygon( data=Southernstates, aes(x=long, y=lat, group =
group),colour="white", fill="royalblue2" ) +
>   labs(title = "Southernstates")
> p
>
> # Northeaststates
> Northeaststates <- subset(all_states, region %in% c( "connecticut",
"district of columbia", "delaware", "massachusetts", "maryland",
"maine","new hampshire"
>                                                      , "new jersey", "new
york","pennsylvania","rhode island","vermont") )
> p <- ggplot()
> p <- p + geom_polygon( data=Northeaststates, aes(x=long, y=lat, group =
group),colour="white", fill="dodgerblue4" ) +
>   labs(title = "Northeaststates")
> p
>
>
> #here is my my data but not used above
>
> str(Map1)
> Classes 'tbl_df', 'tbl' and 'data.frame':    54 obs. of  3 variables:
> $ ProviderState    : chr  "ALASKA" "ALABAMA" "ARKANSAS" "ARIZONA" ...
> $ ProviderStateCode: chr  "AK" "AL" "AR" "AZ" ...
> $ ProviderRegion   : chr  "Pacific" "South" "South" "Pacific" ...
> - attr(*, "spec")=List of 2
>   ..$ cols   :List of 3
>   .. ..$ ProviderState    : list()
>   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
>   .. ..$ ProviderStateCode: list()
>   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
>   .. ..$ ProviderRegion   : list()
>   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
>   ..$ default: list()
>   .. ..- attr(*, "class")= chr  "collector_guess" "collector"
>   ..- attr(*, "class")= chr "col_spec"
>
> dput(Map1)
> structure(list(ProviderState = c("ALASKA", "ALABAMA", "ARKANSAS",
> "ARIZONA", "CALIFORNIA", "COLORADO", "CONNECTICUT", "DISTRICT OF
COLUMBIA",
> "DELAWARE", "FLORIDA", "GEORGIA", "GUAM", "HAWAII", "IOWA", "IDAHO",
> "ILLINOIS", "INDIANA", "KANSAS", "KENTUCKY", "LOUISIANA", "MASSACHUSETTS",
> "MARYLAND", "MAINE", "MICHIGAN", "MINNESOTA", "MISSOURI", "MISSISSIPPI",
> "MONTANA", "NORTH CAROLINA", "NORTH DAKOTA", "NEBRASKA", "NEW HAMPSHIRE",
> "NEW JERSEY", "NEW MEXICO", "NEVADA", "NEW YORK", "OHIO", "OKLAHOMA",
> "OREGON", "PENNSYLVANIA", "PUERTO RICO", "RHODE ISLAND", "SOUTH CAROLINA",
> "SOUTH DAKOTA", "TENNESSEE", "TEXAS", "UTAH", "VIRGINIA", "VIRGIN
ISLANDS",
> "VERMONT", "WASHINGTON", "WISCONSIN", "WEST VIRGINIA", "WYOMING"
> ), ProviderStateCode = c("AK", "AL", "AR", "AZ", "CA", "CO",
> "CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN",
> "KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "MT",
> "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
> "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT",
> "WA", "WI", "WV", "WY"), ProviderRegion = c("Pacific", "South",
> "South", "Pacific", "Pacific", "Frontier", "Northeast", "Northeast",
> "Northeast", "South", "South", "Pacific", "Pacific", "Midwest",
> "Frontier", "Midwest", "Midwest", "Frontier", "South", "South",
> "Northeast", "Northeast", "Northeast", "Midwest", "Midwest",
> "Midwest", "South", "Frontier", "South", "Midwest", "Midwest",
> "Northeast", "Northeast", "Frontier", "Pacific", "Northeast",
> "Midwest", "Frontier", "Pacific", "Northeast", "Northeast", "Northeast",
> "South", "Midwest", "South", "Frontier", "Frontier", "South",
> "Northeast", "Northeast", "Pacific", "Midwest", "South", "Frontier"
> )), row.names = c(NA, -54L), class = c("tbl_df", "tbl", "data.frame"
> ), spec = structure(list(cols = list(ProviderState = structure(list(),
class = c("collector_character",
> "collector")), ProviderStateCode = structure(list(), class =
c("collector_character",
> "collector")), ProviderRegion = structure(list(), class =
c("collector_character",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector"))), class = "col_spec"))
>
> Thank you for any suggestions.
>
> WHP
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Sep 14 09:57:33 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 14 Sep 2018 07:57:33 +0000
Subject: [R-sig-Geo] Help with simple Map of US states with predefined
 regions Version 2 (Solved)
Message-ID: <SN6PR02MB50887A3625E768243B557564EA190@SN6PR02MB5088.namprd02.prod.outlook.com>

Good morning Don, I cannot thank you enough for your support and the trouble you went to.
I am novice useR and the only analyst in the shop asked to learn R and the demands are growing faster than my knowledge intake, lots of laughs!

Best regards

WHP

From: MacQueen, Don <macqueen1 at llnl.gov>
Sent: Thursday, September 13, 2018 4:41 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Help with simple Map of US states with predefined regions Version 2

I know this is not a complete solution -- and it's a very different approach -- but it should at least show you a way to reliably get states colored by region.
(I also left out Alaska and Hawaii, since the point here is how to color the regions)

require(sp)
require(rgdal)

## US Census Bureau Tiger file -- polygons of each US State
## try this URL for download
## https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29<https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2017&layergroup=States+%28and+equivalent%29>

## unzip to working directory ( '.' )
ustf <- readOGR('.', 'tl_2017_us_state', stringsAsFactors=FALSE)

## note, the Tiger file includes 6 additional territories
dim(ustf)
## [1] 56 14

## get rid of the extra six territories (state.name<http://state.name> comes with R)
cus <- subset(ustf, NAME %in% state.name<http://state.name>)

## cheap rename
cus$state <- cus$NAME
cus$abb <- cus$STUSPS

## invent ridiculous groupings of states
cus$grp <- 'a'
cus$grp[11:20] <- 'b'
cus$grp[21:30] <- 'c'
cus$grp[31:40] <- 'd'
cus$grp[41:50] <- 'e'

## assign colors to the groups
cus$color <- 'red'
cus$color[cus$grp=='b'] <- 'green'
cus$color[cus$grp=='c'] <- 'blue'
cus$color[cus$grp=='d'] <- 'brown'
cus$color[cus$grp=='e'] <- 'cyan'

## exclude Alaska, Hawaii
cus <- subset(cus, !(state %in% c('Alaska','Hawaii')))

## get rid of extraneous variables (optional)
cus <- cus[ , c('state','REGION','abb', 'grp') ]

## plot colored by regions as defined in the Census Bureau Tiger file
plot(cus, col=cus$REGION, usePolypath=FALSE)

## color "1" is black, looks bad, do this instead
plot(cus, col=as.numeric(cus$REGION)+1, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

## colors specified by a color variable in the data
plot(cus, col=cus$color, usePolypath=FALSE)
text(coordinates(cus), cus$abb, col='white', cex=0.75)

(my preferred graphics device does not support Polypath, but probably most others do, so one can omit usePolypath=FALSE)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



?On 9/13/18, 5:17 AM, "R-sig-Geo on behalf of Bill Poling" <r-sig-geo-bounces at r-project.org on behalf of Bill.Poling at zelis.com<mailto:r-sig-geo-bounces at r-project.org%20on%20behalf%20of%20Bill.Poling at zelis.com>> wrote:

Hi,

I hope someone can help me finalize this please.

I am coming close to what I need using variations from two ggplot2 tutorials.

This first gives me the map of the US with AK & HI but I cannot figure out how to get my 5 regions colored

#https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1<https://stackoverflow.com/questions/38021188/how-to-draw-u-s-state-map-with-hi-and-ak-with-state-abbreviations-centered-us?rq=1>


library(ggplot2)
install.packages("ggalt")
library(ggalt) # coord_proj
library(albersusa) # devtools::install_github("hrbrmstr/albersusa")
install.packages("ggthemes")
library(ggthemes) # theme_map
install.packages("rgeos")
library(rgeos) # centroids
library(dplyr)

# composite map with AK & HI
usa_map <- usa_composite()

# calculate the centroids for each state gCentroid(usa_map, byid=TRUE) %>%
as.data.frame() %>%
mutate(state=usa_map at data$iso_3166_2) -> centroids

# make it usable in ggplot2
usa_map <- fortify(usa_map)

View(usa_map)
t1 <- head(usa_map,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))

#

# |long |lat | group| order| region|subregion |
# |:---------|:--------|-----:|-----:|-------:|:---------|
# |-87.46201 |30.38968 | 1| 1| alabama|NA |
# |-87.48493 |30.37249 | 1| 2| alabama|NA |
# |-87.52503 |30.37249 | 1| 3| alabama|NA |
# |-87.53076 |30.33239 | 1| 4| alabama|NA |
# |-87.57087 |30.32665 | 1| 5| alabama|NA |

usa_map <- fortify(usa_map)
gg <- ggplot()
gg <- gg + geom_map(data=usa_map, map=usa_map,
aes(long, lat, map_id=id),
color="#2b2b2b", size=0.1, fill=NA)

gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg




#************************************************************************************************************************************************************************************/

This second is an alternative (however not liking AK&HI, not coming into the map like scenario one above) but also ignoring new Mexico (because recognizing a seventh field value) and I suspect it will do the same for new York and new jersey etc.. when I add them to the list.

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 12 did not have 6 elements

When I use newmexico (all one word) it appears white in the map like the other states not in the table statement

#https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors<https://stackoverflow.com/questions/38777732/r-code-to-generating-map-of-us-states-with-specific-colors>

library(ggplot2)

read.table(text="State.Code region St_Abbr Num_Estab colors
1 1 alaska Ak 13123 #f7931e
3 1 arizona AZ 18053 #f7931e
5 1 california CA 143937 #f7931e
2 1 hawaii HI 123456 #f7931e
4 1 nevada NV 654321 #f7931e
6 1 oregon OR 321456 #f7931e
7 1 washington WA 456123 #f7931e
8 2 colorado CO 987654 #787878
9 2 idaho ID 13549 #787878
10 2 kansas KS 94531 #787878
11 2 montana MT 456321 #787878
12 2 new mexico NM 582310 #787878 <---Not liking new mexico, saying not 6
13 2 oklahoma OK 214567 #787878
14 2 texas TX 675421 #787878
15 2 utah UT 754321 #787878
16 2 wyoming WY 543124 #787878 ",
stringsAsFactors=FALSE, header=TRUE, comment.char="") -> df

usa_map1 <- map_data("state")
t1 <- head(usa_map1,n=5)
knitr::kable(t1, row.names=FALSE, align=c("l", "l", "r", "r", "r"))
View(usa_map1)
#
# |long |lat | group| order| region|subregion |
# |:---------|:--------|-----:|-----:|-------:|:---------|
# |-87.46201 |30.38968 | 1| 1| alabama|NA |
# |-87.48493 |30.37249 | 1| 2| alabama|NA |
# |-87.52503 |30.37249 | 1| 3| alabama|NA |
# |-87.53076 |30.33239 | 1| 4| alabama|NA |
# |-87.57087 |30.32665 | 1| 5| alabama|NA |



gg <- ggplot()
#View(gg)
gg <- gg + geom_map(data=usa_map1, map=usa_map1,
aes(long, lat, map_id=region),
color="#2b2b2b", size=0.15, fill=NA)

gg <- gg + geom_map(data=df, map=usa_map1,
aes(fill=colors, map_id=region),
color="#2b2b2b", size=0.15)


gg <- gg + geom_text(data=centroids, aes(x, y, label=state), size=2) gg <- gg + coord_proj(us_laea_proj) gg <- gg + theme_map() gg


gg <- gg + scale_color_identity()
gg <- gg + coord_map("polyconic")
gg <- gg + ggthemes::theme_map()
gg

#c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") ) #c("alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington"))



William H. Poling, Ph.D., MPH




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Sep 14 09:59:10 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 14 Sep 2018 07:59:10 +0000
Subject: [R-sig-Geo] 
 Help with simple Map of US states to predefined regions
In-Reply-To: <CALEhSiTVxvBm2BVVAe2UcFtkqOR0MXOdmfO7fvVv3RC27XgCsQ@mail.gmail.com>
References: <SN6PR02MB5088A569EEA708609C3D0CDDEA1B0@SN6PR02MB5088.namprd02.prod.outlook.com>
 <CALEhSiTVxvBm2BVVAe2UcFtkqOR0MXOdmfO7fvVv3RC27XgCsQ@mail.gmail.com>
Message-ID: <SN6PR02MB50881A07078B89313DD5793EEA190@SN6PR02MB5088.namprd02.prod.outlook.com>

Thank you Jerome, I will peruse and let you know.

Best regards
WHP


From: J?rome Mathieu <jerome.mathieu at upmc.fr>
Sent: Friday, September 14, 2018 3:37 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-sig-geo <r-sig-geo at r-project.org>
Subject: Re: [R-sig-Geo] Help with simple Map of US states to predefined regions

Hi,

this might help you:

http://socviz.co/maps.html#maps<http://socviz.co/maps.html#maps>
http://strimas.com/r/tidy-sf/<http://strimas.com/r/tidy-sf/>
https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html<https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html>

Jerome





Le mer. 12 sept. 2018 ? 20:27, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> a ?crit :
>
> Hi
>
> I have this df with three columns ProviderState, ProviderStateCode, ProviderRegion I wanted to use to create a simple 5 color map
>
> I have reviewed fiftystater pkg and map pkg but not sure how to simply take these three columns and plot a simple 5 color map based on the Region the state is in?
>
> After looking at these and trying to apply these ideas to my data
> https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html<https://cran.r-project.org/web/packages/fiftystater/vignettes/fiftystater.html>
> https://cran.r-project.org/web/packages/maps/maps.pdf<https://cran.r-project.org/web/packages/maps/maps.pdf>
>
> I found tutorial at: https://uchicagoconsulting.wordpress.com/tag/r-ggplot2-maps-visualization/<https://uchicagoconsulting.wordpress.com/tag/r-ggplot2-maps-visualization/>
>
> I used the tutorial data and subset in my regions
>
> So now I have come up with the 5 segmented maps and my question becomes how to put this all into one map of the US?
>
>
> install.packages("maps")
> library(maps)
> library(ggplot2)
>
> #load us map data
> all_states <- map_data("state") View(all_states)
> #plot all states with ggplot
> p <- ggplot()
> p <- p + geom_polygon( data=all_states, aes(x=long, y=lat, group = group),colour="white", fill="blue" )
> p
>
> #http://sape.inf.usi.ch/quick-reference/ggplot2/colour<http://sape.inf.usi.ch/quick-reference/ggplot2/colour>
>
> #Pacificstates
> Pacificstates <- subset(all_states, region %in% c( "alaska", "arizona", "california", "hawaii", "nevada", "oregon","washington") )
> p <- ggplot()
> p <- p + geom_polygon( data=Pacificstates, aes(x=long, y=lat, group = group),colour="white", fill="deepskyblue4" ) +
>   labs(title = "Pacificstates")
> p
>
> #Frontierstates
> Frontierstates <- subset(all_states, region %in% c( "colorado", "idaho", "kansas", "montana", "new mexico", "oklahoma","texas", "utah", "wyoming") )
> p <- ggplot()
> p <- p + geom_polygon( data=Frontierstates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue1" ) +
>       labs(title = "FrontierStates")
> p
>
> #Midweststates
> Midweststates <- subset(all_states, region %in% c( "iowa", "illinois", "indiana", "michigan", "minnesota", "missouri","north dakota", "nebraska", "ohio","south dakota","wisconsin") )
> p <- ggplot()
> p <- p + geom_polygon( data=Midweststates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue1" ) +
>       labs(title = "MidwestStates")
> p
>
> #Southernstates
> Southernstates <- subset(all_states, region %in% c( "alabama", "arkansas", "florida", "georgia", "kentucky", "louisiana","mississippi"
>                                                     ,"north carolina", "south carolina","tennessee","virginia","west virginia") )
> p <- ggplot()
> p <- p + geom_polygon( data=Southernstates, aes(x=long, y=lat, group = group),colour="white", fill="royalblue2" ) +
>   labs(title = "Southernstates")
> p
>
> # Northeaststates
> Northeaststates <- subset(all_states, region %in% c( "connecticut", "district of columbia", "delaware", "massachusetts", "maryland", "maine","new hampshire"
>                                                      , "new jersey", "new york","pennsylvania","rhode island","vermont") )
> p <- ggplot()
> p <- p + geom_polygon( data=Northeaststates, aes(x=long, y=lat, group = group),colour="white", fill="dodgerblue4" ) +
>   labs(title = "Northeaststates")
> p
>
>
> #here is my my data but not used above
>
> str(Map1)
> Classes 'tbl_df', 'tbl' and 'data.frame':    54 obs. of  3 variables:
> $ ProviderState    : chr  "ALASKA" "ALABAMA" "ARKANSAS" "ARIZONA" ...
> $ ProviderStateCode: chr  "AK" "AL" "AR" "AZ" ...
> $ ProviderRegion   : chr  "Pacific" "South" "South" "Pacific" ...
> - attr(*, "spec")=List of 2
>   ..$ cols   :List of 3
>   .. ..$ ProviderState    : list()
>   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
>   .. ..$ ProviderStateCode: list()
>   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
>   .. ..$ ProviderRegion   : list()
>   .. .. ..- attr(*, "class")= chr  "collector_character" "collector"
>   ..$ default: list()
>   .. ..- attr(*, "class")= chr  "collector_guess" "collector"
>   ..- attr(*, "class")= chr "col_spec"
>
> dput(Map1)
> structure(list(ProviderState = c("ALASKA", "ALABAMA", "ARKANSAS",
> "ARIZONA", "CALIFORNIA", "COLORADO", "CONNECTICUT", "DISTRICT OF COLUMBIA",
> "DELAWARE", "FLORIDA", "GEORGIA", "GUAM", "HAWAII", "IOWA", "IDAHO",
> "ILLINOIS", "INDIANA", "KANSAS", "KENTUCKY", "LOUISIANA", "MASSACHUSETTS",
> "MARYLAND", "MAINE", "MICHIGAN", "MINNESOTA", "MISSOURI", "MISSISSIPPI",
> "MONTANA", "NORTH CAROLINA", "NORTH DAKOTA", "NEBRASKA", "NEW HAMPSHIRE",
> "NEW JERSEY", "NEW MEXICO", "NEVADA", "NEW YORK", "OHIO", "OKLAHOMA",
> "OREGON", "PENNSYLVANIA", "PUERTO RICO", "RHODE ISLAND", "SOUTH CAROLINA",
> "SOUTH DAKOTA", "TENNESSEE", "TEXAS", "UTAH", "VIRGINIA", "VIRGIN ISLANDS",
> "VERMONT", "WASHINGTON", "WISCONSIN", "WEST VIRGINIA", "WYOMING"
> ), ProviderStateCode = c("AK", "AL", "AR", "AZ", "CA", "CO",
> "CT", "DC", "DE", "FL", "GA", "GU", "HI", "IA", "ID", "IL", "IN",
> "KS", "KY", "LA", "MA", "MD", "ME", "MI", "MN", "MO", "MS", "MT",
> "NC", "ND", "NE", "NH", "NJ", "NM", "NV", "NY", "OH", "OK", "OR",
> "PA", "PR", "RI", "SC", "SD", "TN", "TX", "UT", "VA", "VI", "VT",
> "WA", "WI", "WV", "WY"), ProviderRegion = c("Pacific", "South",
> "South", "Pacific", "Pacific", "Frontier", "Northeast", "Northeast",
> "Northeast", "South", "South", "Pacific", "Pacific", "Midwest",
> "Frontier", "Midwest", "Midwest", "Frontier", "South", "South",
> "Northeast", "Northeast", "Northeast", "Midwest", "Midwest",
> "Midwest", "South", "Frontier", "South", "Midwest", "Midwest",
> "Northeast", "Northeast", "Frontier", "Pacific", "Northeast",
> "Midwest", "Frontier", "Pacific", "Northeast", "Northeast", "Northeast",
> "South", "Midwest", "South", "Frontier", "Frontier", "South",
> "Northeast", "Northeast", "Pacific", "Midwest", "South", "Frontier"
> )), row.names = c(NA, -54L), class = c("tbl_df", "tbl", "data.frame"
> ), spec = structure(list(cols = list(ProviderState = structure(list(), class = c("collector_character",
> "collector")), ProviderStateCode = structure(list(), class = c("collector_character",
> "collector")), ProviderRegion = structure(list(), class = c("collector_character",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector"))), class = "col_spec"))
>
> Thank you for any suggestions.
>
> WHP
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Sep 14 18:59:52 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 14 Sep 2018 18:59:52 +0200
Subject: [R-sig-Geo] st_union crashes RStudio - bug?
In-Reply-To: <CAHT1vpjmffS2yyevYrh3se23=Yf=7grKGeqZXYzCvXV22y0Xrg@mail.gmail.com>
References: <ME1PR01MB08363E5A05F0823ABA7089BFB2190@ME1PR01MB0836.ausprd01.prod.outlook.com>
 <CAHT1vpjmffS2yyevYrh3se23=Yf=7grKGeqZXYzCvXV22y0Xrg@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1809141852550.11053@reclus.nhh.no>

On Fri, 14 Sep 2018, Roman Lu?trik wrote:

> Crashes R or Rstudio?

I guess the OP will get up sometime soon; of course one should always run 
R in a console, not RStudio when reporting issues of this kind. Further, 
one should run R -d gdb (if possible - see RW FAQ) to trap any important 
information. I can see that crash <- st_union(noACT) is long-running, with 
one thread at 100%, but no obvious memory issues (Fedora 28, sf 0.6-3, 
GEOS 3.7.0). It would further make sense to go the sp/rgeos route to see 
if it is data+GEOS or that the behavious is R-implementation dependent.

Roger

>
> Cheers,
> Roman
>
> On Fri, Sep 14, 2018 at 8:33 AM Bertram Ostendorf <
> bertram.ostendorf at adelaide.edu.au> wrote:
>
>> I am trying to dissolve internal boundaries using sf.  This crashes R in
>> the example geojson map below, a simple map of Australia?s states and
>> territories. I am using a polygon layer that processes fine in other GIS
>> and also works fine using sp (casting to sp and using gUnaryUnion).  I am
>> not after a workaround but I'd like to explore what's different in sf and
>> why this particular layer causes problems.
>>
>> My questions: Is this a bug in sf? Have others experienced similar issues
>> using simple features?
>>
>> Thanks
>>
>> Bertram Ostendorf
>> Chair for Spatial Environmental Sciences
>> Director: Spatial Information Group
>> The University of Adelaide, AUSTRALIA 5005
>>
>>
>> # Here's my example layer and code:
>> # Note: Neither ArcGIS ?repair geometry? nor  ?st_is_valid? show any
>> issues.
>> library(sf)
>> library(ggplot2)
>> # read Australia.geojson from dropbox, 15.5Mb
>> test <- st_read("
>> https://www.dropbox.com/s/060c6lfijyx1e5v/Australia.geojson?dl=1")
>> st_is_valid(test)
>>
>> # The next lines work fine, I added them to illustrate what works
>> ggplot(test) + geom_sf(aes(fill=STATE))
>> ACT <- test[test$STATE == 'ACT', ]
>> NSW <- test[test$STATE == 'NSW', ]
>> ACTandNSW <- test[test$STATE %in% c('NSW','ACT'), ]
>> noACT <- test[test$STATE != 'ACT', ]
>> noNSW <- test[test$STATE != 'NSW', ]
>> noACTandNSW <- test[!test$STATE %in% c('NSW','ACT'), ]
>> # st_union works ok for most subsets. But note that some internal
>> boundaries are not removed.
>> ok <- st_union(ACT)
>> # donut polygons work fine
>> ok <- st_union(NSW)
>> # donut polygons (NSW) filled (ACT) work fine
>> ok <- st_union(ACTandNSW)
>> # all states except NSW work fine
>> ok <- st_union(noNSW)
>> # ok if both ACT and NSW are removed
>> ok <- st_union(noACTandNSW)
>> ggplot(ok) + geom_sf()
>>
>> # Thing go pear-shaped if the hole is filled (ACT in NSW), but only if
>> neighbours of the filled donut polygon are present.
>> # The two lines below stall R and eventually crash RStudio
>> crash <- st_union(test)
>> # Australia without its governing territory kills R
>> crash <- st_union(noACT)
>>
>>
>>> sessionInfo()
>> R version 3.5.1 (2018-07-02)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>>   [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>>   LC_MONETARY=English_Australia.1252
>> [4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252
>>
>> attached base packages:
>>   [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>   [1] ggplot2_3.0.0 sf_0.6-3
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_0.12.18     rstudioapi_0.7   bindr_0.1.1      magrittr_1.5
>>  units_0.6-0      tidyselect_0.2.4 munsell_0.5.0
>> [8] colorspace_1.3-2 R6_2.2.2         rlang_0.2.2      plyr_1.8.4
>>  dplyr_0.7.6      tools_3.5.1      grid_3.5.1
>> [15] gtable_0.2.0     e1071_1.7-0      DBI_1.0.0        withr_2.1.2
>> class_7.3-14     digest_0.6.16    yaml_2.2.0
>> [22] lazyeval_0.2.1   assertthat_0.2.0 tibble_1.4.2     crayon_1.3.4
>>  bindrcpp_0.2.2   spData_0.2.9.3   purrr_0.2.5
>> [29] glue_1.3.0       compiler_3.5.1   pillar_1.3.0     scales_1.0.0
>>  classInt_0.2-3   pkgconfig_2.0.2
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 19:12:50 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 10:12:50 -0700 (PDT)
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
Message-ID: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>

   I need to learn geospatial analyses in R to complement my GIS knowledge.
I've just re-read the subsetting chapter in Hadley's 'Advanced R' without
seeing how to create separate data frames based by extracting all rows for
each site name in the parent data frame in one step. I believe that what I
need to do is create a list of the factor names and feed them to a loop
subsetting each to a new dataframe. Perhaps there's a better way unknown to
me and I need advice, suggestions, and recommendations how to proceed.

   The inclusive data frame has this structure:

str(rainfall)
'data.frame':	113569 obs. of  6 variables:
  $ name    : Factor w/ 58 levels "Blazed Alder",..: 20 20 20 20 20 20 20 ...
  $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
  $ northing: num  199338 199338 199338 199338 199338 ...
  $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
  $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
  $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...

   My goal is to use the monthly mean rainfall at each of the 58 reporting
stations to interpolate/extrapolate rainfall over the entire county for
selected years to show variability. The data points are not evenly
distributed but clustered in more populated areas and dispersed in rural
areas. My geochemical data typically are like this and I need to also learn
how this distribution affects how the data are analyzed.

TIA,

Rich


From j@tnhllrd @ending from gm@il@com  Fri Sep 14 20:03:41 2018
From: j@tnhllrd @ending from gm@il@com (Justin H.)
Date: Fri, 14 Sep 2018 14:03:41 -0400
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
Message-ID: <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>

Hi Rich,

For the sake of example, here's a solution for a simple aggregation.

>aggregate(rainfall, list(rainfall$name), mean)  #This will aggregate all
columns and determine their mean. You're left with 58 rows.
>aggregate( rainfall[, #:#], list(rainfall$name), mean)  #In case you only
want to aggregate over select columns.


I am assuming you want rows with every combination of year and station with
their average precipitations. To aggregate it in that way you will need to
create a new column that represents the year (or month/year if the data are
appropriate for that resolution).

>rainfall.year<-with(rainfall, tapply(prcp, list(name, year), mean))  #This
does the aggregation.
>rainfall.year<-data.frame(as.table(rainfall.year))  #However, you are
given a "wide" data frame. This makes it "long" as you probably want it.

A for-do-done loop option.

for (i in levels(rainfall.year[,#year])) {
print(i)
print(mean(rainfall.year[rainfall.year$year==i,#prcp]))
}

The loop will return the mean rainfall per year, where #year is the number
for the year column and #prcp is for precipitation.
Try running that loop to see that it is properly looping through the factor
you want and then stick in the interpolation function.

I hope that helps!

Cheers,
Justin

On Fri, Sep 14, 2018 at 1:13 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

>    I need to learn geospatial analyses in R to complement my GIS knowledge.
> I've just re-read the subsetting chapter in Hadley's 'Advanced R' without
> seeing how to create separate data frames based by extracting all rows for
> each site name in the parent data frame in one step. I believe that what I
> need to do is create a list of the factor names and feed them to a loop
> subsetting each to a new dataframe. Perhaps there's a better way unknown to
> me and I need advice, suggestions, and recommendations how to proceed.
>
>    The inclusive data frame has this structure:
>
> str(rainfall)
> 'data.frame':   113569 obs. of  6 variables:
>   $ name    : Factor w/ 58 levels "Blazed Alder",..: 20 20 20 20 20 20 20
> ...
>   $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
>   $ northing: num  199338 199338 199338 199338 199338 ...
>   $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
>   $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
>   $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>
>    My goal is to use the monthly mean rainfall at each of the 58 reporting
> stations to interpolate/extrapolate rainfall over the entire county for
> selected years to show variability. The data points are not evenly
> distributed but clustered in more populated areas and dispersed in rural
> areas. My geochemical data typically are like this and I need to also learn
> how this distribution affects how the data are analyzed.
>
> TIA,
>
> Rich
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 20:05:43 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 11:05:43 -0700 (PDT)
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <CAOTTEBN3z=R8wdDr9fcvOwVLeA+wp6hjfkGsywzj-nD2AFupGw@mail.gmail.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAOTTEBN3z=R8wdDr9fcvOwVLeA+wp6hjfkGsywzj-nD2AFupGw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809141104040.27826@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Phil Radtke wrote:

> would something as simple as this do what you need?
> rainfall_by_site <- split(rainfall,rainfall$name)

Phil,

   Yes, it certainly would do the job.

> I found this on stackoverflow by the web search: R create separate data
> frame based on factor
> https://stackoverflow.com/questions/9713294/split-data-frame-based-on-levels-of-a-factor-into-new-data-frames

   Either I missed this hit when I tried the same search string or duckduckgo
missed it.

   Thanks very much.

Regards,

Rich


From j@tnhllrd @ending from gm@il@com  Fri Sep 14 20:10:03 2018
From: j@tnhllrd @ending from gm@il@com (Justin H.)
Date: Fri, 14 Sep 2018 14:10:03 -0400
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
Message-ID: <CAAygbEP5iExP2iFs42mYAUXsFsNRfMh7kpyqyfrdoJkWhYLWZw@mail.gmail.com>

One more thing. Let's still assume you want to interpolate it yearly. The
below code will assign names to the output during the loop.

for (i in levels(rainfall.year[,#year])) {
assign ( paste (i,"interpolation output",sep = "_")
, interpolation_function()
}


Cheers,
Justin

On Fri, Sep 14, 2018 at 2:03 PM Justin H. <jstnhllrd at gmail.com> wrote:

> Hi Rich,
>
> For the sake of example, here's a solution for a simple aggregation.
>
> >aggregate(rainfall, list(rainfall$name), mean)  #This will aggregate all
> columns and determine their mean. You're left with 58 rows.
> >aggregate( rainfall[, #:#], list(rainfall$name), mean)  #In case you only
> want to aggregate over select columns.
>
>
> I am assuming you want rows with every combination of year and station
> with their average precipitations. To aggregate it in that way you will
> need to create a new column that represents the year (or month/year if the
> data are appropriate for that resolution).
>
> >rainfall.year<-with(rainfall, tapply(prcp, list(name, year), mean))
> #This does the aggregation.
> >rainfall.year<-data.frame(as.table(rainfall.year))  #However, you are
> given a "wide" data frame. This makes it "long" as you probably want it.
>
> A for-do-done loop option.
>
> for (i in levels(rainfall.year[,#year])) {
> print(i)
> print(mean(rainfall.year[rainfall.year$year==i,#prcp]))
> }
>
> The loop will return the mean rainfall per year, where #year is the number
> for the year column and #prcp is for precipitation.
> Try running that loop to see that it is properly looping through the
> factor you want and then stick in the interpolation function.
>
> I hope that helps!
>
> Cheers,
> Justin
>
> On Fri, Sep 14, 2018 at 1:13 PM Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
>>    I need to learn geospatial analyses in R to complement my GIS
>> knowledge.
>> I've just re-read the subsetting chapter in Hadley's 'Advanced R' without
>> seeing how to create separate data frames based by extracting all rows for
>> each site name in the parent data frame in one step. I believe that what I
>> need to do is create a list of the factor names and feed them to a loop
>> subsetting each to a new dataframe. Perhaps there's a better way unknown
>> to
>> me and I need advice, suggestions, and recommendations how to proceed.
>>
>>    The inclusive data frame has this structure:
>>
>> str(rainfall)
>> 'data.frame':   113569 obs. of  6 variables:
>>   $ name    : Factor w/ 58 levels "Blazed Alder",..: 20 20 20 20 20 20 20
>> ...
>>   $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
>>   $ northing: num  199338 199338 199338 199338 199338 ...
>>   $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
>>   $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
>>   $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>>
>>    My goal is to use the monthly mean rainfall at each of the 58 reporting
>> stations to interpolate/extrapolate rainfall over the entire county for
>> selected years to show variability. The data points are not evenly
>> distributed but clustered in more populated areas and dispersed in rural
>> areas. My geochemical data typically are like this and I need to also
>> learn
>> how this distribution affects how the data are analyzed.
>>
>> TIA,
>>
>> Rich
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 14 20:17:50 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 11:17:50 -0700 (PDT)
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <CAAygbEP5iExP2iFs42mYAUXsFsNRfMh7kpyqyfrdoJkWhYLWZw@mail.gmail.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
 <CAAygbEP5iExP2iFs42mYAUXsFsNRfMh7kpyqyfrdoJkWhYLWZw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809141117020.27826@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Justin H. wrote:

> One more thing. Let's still assume you want to interpolate it yearly. The
> below code will assign names to the output during the loop.
>
> for (i in levels(rainfall.year[,#year])) {
> assign ( paste (i,"interpolation output",sep = "_")
> , interpolation_function()
> }

Justin,

   Thanks again.

Regards,

Rich


From Roger@Biv@nd @ending from nhh@no  Fri Sep 14 21:19:55 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 14 Sep 2018 19:19:55 +0000
Subject: [R-sig-Geo] st_union crashes RStudio - bug?
In-Reply-To: <alpine.LFD.2.21.1809141852550.11053@reclus.nhh.no>
References: <ME1PR01MB08363E5A05F0823ABA7089BFB2190@ME1PR01MB0836.ausprd01.prod.outlook.com>
 <CAHT1vpjmffS2yyevYrh3se23=Yf=7grKGeqZXYzCvXV22y0Xrg@mail.gmail.com>,
 <alpine.LFD.2.21.1809141852550.11053@reclus.nhh.no>
Message-ID: <CF511784783D0B52.f04f00c8-93d0-4995-abca-d79c9c84bb9f@mail.outlook.com>

(from an airport)

> crash <- st_union(noACT)

completed without error, test also passes. Your problem is not general

There is absolutely no need to use ggplot to display the geometries, by the way.

plot(st_geometry(crash))

shows errant partial boundaries, probably caused by the default precision model and geojson's character representation of numbers.

Roger

Roger Bivand
Norwegian School of Economics
Bergen, Norway




On Fri, Sep 14, 2018 at 7:00 PM +0200, "Roger Bivand" <Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>> wrote:


On Fri, 14 Sep 2018, Roman Lu?trik wrote:

> Crashes R or Rstudio?

I guess the OP will get up sometime soon; of course one should always run
R in a console, not RStudio when reporting issues of this kind. Further,
one should run R -d gdb (if possible - see RW FAQ) to trap any important
information. I can see that crash <- st_union(noACT) is long-running, with
one thread at 100%, but no obvious memory issues (Fedora 28, sf 0.6-3,
GEOS 3.7.0). It would further make sense to go the sp/rgeos route to see
if it is data+GEOS or that the behavious is R-implementation dependent.

Roger

>
> Cheers,
> Roman
>
> On Fri, Sep 14, 2018 at 8:33 AM Bertram Ostendorf <
> bertram.ostendorf at adelaide.edu.au> wrote:
>
>> I am trying to dissolve internal boundaries using sf.  This crashes R in
>> the example geojson map below, a simple map of Australia?s states and
>> territories. I am using a polygon layer that processes fine in other GIS
>> and also works fine using sp (casting to sp and using gUnaryUnion).  I am
>> not after a workaround but I'd like to explore what's different in sf and
>> why this particular layer causes problems.
>>
>> My questions: Is this a bug in sf? Have others experienced similar issues
>> using simple features?
>>
>> Thanks
>>
>> Bertram Ostendorf
>> Chair for Spatial Environmental Sciences
>> Director: Spatial Information Group
>> The University of Adelaide, AUSTRALIA 5005
>>
>>
>> # Here's my example layer and code:
>> # Note: Neither ArcGIS ?repair geometry? nor  ?st_is_valid? show any
>> issues.
>> library(sf)
>> library(ggplot2)
>> # read Australia.geojson from dropbox, 15.5Mb
>> test <- st_read("
>> https://www.dropbox.com/s/060c6lfijyx1e5v/Australia.geojson?dl=1")
>> st_is_valid(test)
>>
>> # The next lines work fine, I added them to illustrate what works
>> ggplot(test) + geom_sf(aes(fill=STATE))
>> ACT <- test[test$STATE == 'ACT', ]
>> NSW <- test[test$STATE == 'NSW', ]
>> ACTandNSW <- test[test$STATE %in% c('NSW','ACT'), ]
>> noACT <- test[test$STATE != 'ACT', ]
>> noNSW <- test[test$STATE != 'NSW', ]
>> noACTandNSW <- test[!test$STATE %in% c('NSW','ACT'), ]
>> # st_union works ok for most subsets. But note that some internal
>> boundaries are not removed.
>> ok <- st_union(ACT)
>> # donut polygons work fine
>> ok <- st_union(NSW)
>> # donut polygons (NSW) filled (ACT) work fine
>> ok <- st_union(ACTandNSW)
>> # all states except NSW work fine
>> ok <- st_union(noNSW)
>> # ok if both ACT and NSW are removed
>> ok <- st_union(noACTandNSW)
>> ggplot(ok) + geom_sf()
>>
>> # Thing go pear-shaped if the hole is filled (ACT in NSW), but only if
>> neighbours of the filled donut polygon are present.
>> # The two lines below stall R and eventually crash RStudio
>> crash <- st_union(test)
>> # Australia without its governing territory kills R
>> crash <- st_union(noACT)
>>
>>
>>> sessionInfo()
>> R version 3.5.1 (2018-07-02)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows >= 8 x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>>   [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>>   LC_MONETARY=English_Australia.1252
>> [4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252
>>
>> attached base packages:
>>   [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>   [1] ggplot2_3.0.0 sf_0.6-3
>>
>> loaded via a namespace (and not attached):
>>   [1] Rcpp_0.12.18     rstudioapi_0.7   bindr_0.1.1      magrittr_1.5
>>  units_0.6-0      tidyselect_0.2.4 munsell_0.5.0
>> [8] colorspace_1.3-2 R6_2.2.2         rlang_0.2.2      plyr_1.8.4
>>  dplyr_0.7.6      tools_3.5.1      grid_3.5.1
>> [15] gtable_0.2.0     e1071_1.7-0      DBI_1.0.0        withr_2.1.2
>> class_7.3-14     digest_0.6.16    yaml_2.2.0
>> [22] lazyeval_0.2.1   assertthat_0.2.0 tibble_1.4.2     crayon_1.3.4
>>  bindrcpp_0.2.2   spData_0.2.9.3   purrr_0.2.5
>> [29] glue_1.3.0       compiler_3.5.1   pillar_1.3.0     scales_1.0.0
>>  classInt_0.2-3   pkgconfig_2.0.2
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Sep 14 22:20:35 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 14 Sep 2018 22:20:35 +0200
Subject: [R-sig-Geo] st_union crashes RStudio - bug?
In-Reply-To: <CF511784783D0B52.f04f00c8-93d0-4995-abca-d79c9c84bb9f@mail.outlook.com>
References: <ME1PR01MB08363E5A05F0823ABA7089BFB2190@ME1PR01MB0836.ausprd01.prod.outlook.com>
 <CAHT1vpjmffS2yyevYrh3se23=Yf=7grKGeqZXYzCvXV22y0Xrg@mail.gmail.com>,
 <alpine.LFD.2.21.1809141852550.11053@reclus.nhh.no>
 <CF511784783D0B52.f04f00c8-93d0-4995-abca-d79c9c84bb9f@mail.outlook.com>
Message-ID: <alpine.LFD.2.21.1809142219120.14723@reclus.nhh.no>

The in-flight analysis shows that the precision model interacts with the
geojson text representation of coordinates. I tried to use st_precision
without success. Using:

library(rgdal)
library(rgeos)
test1 <- readOGR("Australia.geojson")
setScale(4e+4)
crash1 <- gUnaryUnion(test1)
plot(crash1)
length(slot(slot(crash1, "polygons")[[1]], "Polygons"))
areas <- sapply(slot(slot(crash1, "polygons")[[1]], "Polygons"), slot,
"area")
head(sort(areas), n=10)
which(areas < 5e-8)
Pols <- slot(slot(crash1, "polygons")[[1]], "Polygons")
Pols1 <- Pols[-which(areas < 5e-8)]
slot(slot(crash1, "polygons")[[1]], "Polygons") <- Pols1
plot(crash1)

and changing scale to 4e+4 in rgeos notation, most of the remnant boundary
artefacts are removed. You can even remove the three dots in south-east
Australia. So: if you want to operations other than visualisation, avoid
geojson. If you can't avoid geojson, don't be surprised by topological
issues. Further, do use a vector representation suited to your purpose -
this one has far too much detail.

Roger

PS. Not tried on Windows - can someone please check that this doesn't
misbehave on the OP's platform?

On Fri, 14 Sep 2018, Roger Bivand wrote:

> (from an airport)
>
>> crash <- st_union(noACT)
>
> completed without error, test also passes. Your problem is not general
>
> There is absolutely no need to use ggplot to display the geometries, by 
> the way.
>
> plot(st_geometry(crash))
>
> shows errant partial boundaries, probably caused by the default 
> precision model and geojson's character representation of numbers.
>
> Roger
>
> Roger Bivand
> Norwegian School of Economics
> Bergen, Norway
>
>
>
>
> On Fri, Sep 14, 2018 at 7:00 PM +0200, "Roger Bivand" <Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>> wrote:
>
>
> On Fri, 14 Sep 2018, Roman Lu?trik wrote:
>
>> Crashes R or Rstudio?
>
> I guess the OP will get up sometime soon; of course one should always run
> R in a console, not RStudio when reporting issues of this kind. Further,
> one should run R -d gdb (if possible - see RW FAQ) to trap any important
> information. I can see that crash <- st_union(noACT) is long-running, with
> one thread at 100%, but no obvious memory issues (Fedora 28, sf 0.6-3,
> GEOS 3.7.0). It would further make sense to go the sp/rgeos route to see
> if it is data+GEOS or that the behavious is R-implementation dependent.
>
> Roger
>
>>
>> Cheers,
>> Roman
>>
>> On Fri, Sep 14, 2018 at 8:33 AM Bertram Ostendorf <
>> bertram.ostendorf at adelaide.edu.au> wrote:
>>
>>> I am trying to dissolve internal boundaries using sf.  This crashes R in
>>> the example geojson map below, a simple map of Australia?s states and
>>> territories. I am using a polygon layer that processes fine in other GIS
>>> and also works fine using sp (casting to sp and using gUnaryUnion).  I am
>>> not after a workaround but I'd like to explore what's different in sf and
>>> why this particular layer causes problems.
>>>
>>> My questions: Is this a bug in sf? Have others experienced similar issues
>>> using simple features?
>>>
>>> Thanks
>>>
>>> Bertram Ostendorf
>>> Chair for Spatial Environmental Sciences
>>> Director: Spatial Information Group
>>> The University of Adelaide, AUSTRALIA 5005
>>>
>>>
>>> # Here's my example layer and code:
>>> # Note: Neither ArcGIS ?repair geometry? nor  ?st_is_valid? show any
>>> issues.
>>> library(sf)
>>> library(ggplot2)
>>> # read Australia.geojson from dropbox, 15.5Mb
>>> test <- st_read("
>>> https://www.dropbox.com/s/060c6lfijyx1e5v/Australia.geojson?dl=1")
>>> st_is_valid(test)
>>>
>>> # The next lines work fine, I added them to illustrate what works
>>> ggplot(test) + geom_sf(aes(fill=STATE))
>>> ACT <- test[test$STATE == 'ACT', ]
>>> NSW <- test[test$STATE == 'NSW', ]
>>> ACTandNSW <- test[test$STATE %in% c('NSW','ACT'), ]
>>> noACT <- test[test$STATE != 'ACT', ]
>>> noNSW <- test[test$STATE != 'NSW', ]
>>> noACTandNSW <- test[!test$STATE %in% c('NSW','ACT'), ]
>>> # st_union works ok for most subsets. But note that some internal
>>> boundaries are not removed.
>>> ok <- st_union(ACT)
>>> # donut polygons work fine
>>> ok <- st_union(NSW)
>>> # donut polygons (NSW) filled (ACT) work fine
>>> ok <- st_union(ACTandNSW)
>>> # all states except NSW work fine
>>> ok <- st_union(noNSW)
>>> # ok if both ACT and NSW are removed
>>> ok <- st_union(noACTandNSW)
>>> ggplot(ok) + geom_sf()
>>>
>>> # Thing go pear-shaped if the hole is filled (ACT in NSW), but only if
>>> neighbours of the filled donut polygon are present.
>>> # The two lines below stall R and eventually crash RStudio
>>> crash <- st_union(test)
>>> # Australia without its governing territory kills R
>>> crash <- st_union(noACT)
>>>
>>>
>>>> sessionInfo()
>>> R version 3.5.1 (2018-07-02)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows >= 8 x64 (build 9200)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>>   [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>>>   LC_MONETARY=English_Australia.1252
>>> [4] LC_NUMERIC=C                       LC_TIME=English_Australia.1252
>>>
>>> attached base packages:
>>>   [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>>   [1] ggplot2_3.0.0 sf_0.6-3
>>>
>>> loaded via a namespace (and not attached):
>>>   [1] Rcpp_0.12.18     rstudioapi_0.7   bindr_0.1.1      magrittr_1.5
>>>  units_0.6-0      tidyselect_0.2.4 munsell_0.5.0
>>> [8] colorspace_1.3-2 R6_2.2.2         rlang_0.2.2      plyr_1.8.4
>>>  dplyr_0.7.6      tools_3.5.1      grid_3.5.1
>>> [15] gtable_0.2.0     e1071_1.7-0      DBI_1.0.0        withr_2.1.2
>>> class_7.3-14     digest_0.6.16    yaml_2.2.0
>>> [22] lazyeval_0.2.1   assertthat_0.2.0 tibble_1.4.2     crayon_1.3.4
>>>  bindrcpp_0.2.2   spData_0.2.9.3   purrr_0.2.5
>>> [29] glue_1.3.0       compiler_3.5.1   pillar_1.3.0     scales_1.0.0
>>>  classInt_0.2-3   pkgconfig_2.0.2
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From r@hep@rd @ending from @ppl-eco@y@@com  Sat Sep 15 00:19:01 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 15:19:01 -0700 (PDT)
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809141512060.27826@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Justin H. wrote:

> For the sake of example, here's a solution for a simple aggregation.
> rainfall.year<-with(rainfall, tapply(prcp, list(name, year), mean))  #This
> does the aggregation.

Justin,

   The results have sites with 'NA' for the mean precipiation despite having
recorded values some days. For example,

> rainfall.year
                                            0
Blazed Alder                              NA

while

> head(rainfall_by_site[[1]])
              name easting northing   elev   sampdate prcp
7741 Blazed Alder 2393589 196840.8 1112.5 2005-01-01  0.2
7742 Blazed Alder 2393589 196840.8 1112.5 2005-01-02  0.2
7743 Blazed Alder 2393589 196840.8 1112.5 2005-01-03  0.4
7744 Blazed Alder 2393589 196840.8 1112.5 2005-01-04  0.0
7745 Blazed Alder 2393589 196840.8 1112.5 2005-01-05  0.0
7746 Blazed Alder 2393589 196840.8 1112.5 2005-01-06  0.0

   I'll read up on tapply and see if I can identify the reason for the
discrepancy.

Regards,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Sat Sep 15 00:54:15 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 14 Sep 2018 15:54:15 -0700 (PDT)
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <CAAygbEMNaTmUbPDKx3JJKv6z=1NMO+Z=upK+9_S+XOVrKF35xg@mail.gmail.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
 <alpine.LNX.2.20.1809141512060.27826@salmo.appl-ecosys.com>
 <CAAygbEMNaTmUbPDKx3JJKv6z=1NMO+Z=upK+9_S+XOVrKF35xg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809141543080.27826@salmo.appl-ecosys.com>

On Fri, 14 Sep 2018, Justin H. wrote:

> I'm not sure how it handles your date format. It's probably grouping
> things weirdly. If you can split out that column into two columns, one for
> year and one for month. I'd have to tinker with it later as I can't think
> of code off the top of my head. It should play nicer then.

Justin,

   The rainfall data.frame structure:
'data.frame':   113569 obs. of  6 variables:
  $ name    : Factor w/ 58 levels "Blazed Alder",..: 20 20 20 20 20 20 20 20 ...
  $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
  $ northing: num  199338 199338 199338 199338 199338 ...
  $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
  $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
  $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...

After splitting by name (only the first one shown):
str(rainfall_by_site)
List of 58
  $ Blazed Alder                 :'data.frame':      4900 obs. of  6 variables:
   ..$ name    : Factor w/ 58 levels "Blazed Alder",..: 1 1 1 1 1 1 1 1 1 1 ...
   ..$ easting : num [1:4900] 2393589 2393589 2393589 2393589 2393589 ...
   ..$ northing: num [1:4900] 196841 196841 196841 196841 196841 ...
   ..$ elev    : num [1:4900] 1112 1112 1112 1112 1112 ...
   ..$ sampdate: Date[1:4900], format: "2005-01-01" "2005-01-02" ...
   ..$ prcp    : num [1:4900] 0.2 0.2 0.4 0 0 0 0.1 0.1 0.1 0.2 ...

Adding a year column to the end:
     $ year    : num  0 0 0 0 0 0 0 0 0 0 ...

I've not separated the sampdate structure into years and months; I can and
that might make the difference. Will try to find time this weekend to do so.
Otherwise, it'll be next week.

Regards,

Rich


From g@vg712 @ending from gm@il@com  Mon Sep 17 02:15:48 2018
From: g@vg712 @ending from gm@il@com (Gabriel Gaona)
Date: Sun, 16 Sep 2018 19:15:48 -0500
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <alpine.LNX.2.20.1809141543080.27826@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
 <alpine.LNX.2.20.1809141512060.27826@salmo.appl-ecosys.com>
 <CAAygbEMNaTmUbPDKx3JJKv6z=1NMO+Z=upK+9_S+XOVrKF35xg@mail.gmail.com>
 <alpine.LNX.2.20.1809141543080.27826@salmo.appl-ecosys.com>
Message-ID: <CAD-tSQ_Oa0A2LQHyAbLW6T=SbTS+Vkwm+FwdNFzthhvjibjH_w@mail.gmail.com>

An other option is the tydiverse way. I assume when you say " My goal is to
use the monthly mean rainfall at each of the 58 reporting stations..." you
mean you want for each year and station a average value of monthly prcp .
From your input data frame, is like:

library(dplyr)
library(lubridate)
rainfall_yearly <- rainfall %>%
    group_by(name,
        Month = floor_date(sampdate, "month")) %>% #Monthly round down
dates for grouping
    summarise(prcp = sum(prcp, na.rm = TRUE) %>% #calculating monthly prcp
    group_by(name,
        Year = floor_date(Month, "year")) %>% #Yearly round down dates for
grouping
    summarise(prcp = mean(prcp, na.rm = TRUE) #calculating monthly average
per year
_________________________
* Gabriel Gaona*
*Tel?fono*: +593 9 91665888
*Twitter/Hangouts*: gavg712
Loja - Ecuador
https://www.researchgate.net/profile/Gabriel_Gaona


El vie., 14 sept. 2018 a las 17:54, Rich Shepard (<rshepard at appl-ecosys.com>)
escribi?:

> On Fri, 14 Sep 2018, Justin H. wrote:
>
> > I'm not sure how it handles your date format. It's probably grouping
> > things weirdly. If you can split out that column into two columns, one
> for
> > year and one for month. I'd have to tinker with it later as I can't think
> > of code off the top of my head. It should play nicer then.
>
> Justin,
>
>    The rainfall data.frame structure:
> 'data.frame':   113569 obs. of  6 variables:
>   $ name    : Factor w/ 58 levels "Blazed Alder",..: 20 20 20 20 20 20 20
> 20 ...
>   $ easting : num  2370575 2370575 2370575 2370575 2370575 ...
>   $ northing: num  199338 199338 199338 199338 199338 ...
>   $ elev    : num  228 228 228 228 228 228 228 228 228 228 ...
>   $ sampdate: Date, format: "2005-01-01" "2005-01-02" ...
>   $ prcp    : num  0.59 0.08 0.1 0 0 0.02 0.05 0.1 0 0.02 ...
>
> After splitting by name (only the first one shown):
> str(rainfall_by_site)
> List of 58
>   $ Blazed Alder                 :'data.frame':      4900 obs. of  6
> variables:
>    ..$ name    : Factor w/ 58 levels "Blazed Alder",..: 1 1 1 1 1 1 1 1 1
> 1 ...
>    ..$ easting : num [1:4900] 2393589 2393589 2393589 2393589 2393589 ...
>    ..$ northing: num [1:4900] 196841 196841 196841 196841 196841 ...
>    ..$ elev    : num [1:4900] 1112 1112 1112 1112 1112 ...
>    ..$ sampdate: Date[1:4900], format: "2005-01-01" "2005-01-02" ...
>    ..$ prcp    : num [1:4900] 0.2 0.2 0.4 0 0 0 0.1 0.1 0.1 0.2 ...
>
> Adding a year column to the end:
>      $ year    : num  0 0 0 0 0 0 0 0 0 0 ...
>
> I've not separated the sampdate structure into years and months; I can and
> that might make the difference. Will try to find time this weekend to do
> so.
> Otherwise, it'll be next week.
>
> Regards,
>
> Rich
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Mon Sep 17 02:30:32 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Sun, 16 Sep 2018 17:30:32 -0700 (PDT)
Subject: [R-sig-Geo] Subsetting dataframe by all factor levels
In-Reply-To: <CAD-tSQ_Oa0A2LQHyAbLW6T=SbTS+Vkwm+FwdNFzthhvjibjH_w@mail.gmail.com>
References: <alpine.LNX.2.20.1809141009460.27826@salmo.appl-ecosys.com>
 <CAAygbEPHR-bdT3hScQ7QBgSdfOSNRxGHge1VKS+6fFAGS1Kzdw@mail.gmail.com>
 <alpine.LNX.2.20.1809141512060.27826@salmo.appl-ecosys.com>
 <CAAygbEMNaTmUbPDKx3JJKv6z=1NMO+Z=upK+9_S+XOVrKF35xg@mail.gmail.com>
 <alpine.LNX.2.20.1809141543080.27826@salmo.appl-ecosys.com>
 <CAD-tSQ_Oa0A2LQHyAbLW6T=SbTS+Vkwm+FwdNFzthhvjibjH_w@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1809161729130.12847@salmo.appl-ecosys.com>

On Sun, 16 Sep 2018, Gabriel Gaona wrote:

> An other option is the tydiverse way. I assume when you say " My goal is to
> use the monthly mean rainfall at each of the 58 reporting stations..." you
> mean you want for each year and station a average value of monthly prcp .
>> From your input data frame, is like:
>
> library(dplyr)
> library(lubridate)
> rainfall_yearly <- rainfall %>%
>    group_by(name,
>        Month = floor_date(sampdate, "month")) %>% #Monthly round down
> dates for grouping
>    summarise(prcp = sum(prcp, na.rm = TRUE) %>% #calculating monthly prcp
>    group_by(name,
>        Year = floor_date(Month, "year")) %>% #Yearly round down dates for
> grouping
>    summarise(prcp = mean(prcp, na.rm = TRUE) #calculating monthly average
> per year

Gabriel,

   Thank you very much I'm learning a lot from all the responses.

Best regards,

Rich


From mtregli@ @ending from gm@il@com  Thu Sep 20 14:05:01 2018
From: mtregli@ @ending from gm@il@com (Michael Treglia)
Date: Thu, 20 Sep 2018 08:05:01 -0400
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <7f95ddd3-3b5d-5850-fa00-49991fac8307@gmx.de>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
 <7f95ddd3-3b5d-5850-fa00-49991fac8307@gmx.de>
Message-ID: <CAPKp32s0vqFeFT5PSt6P9kTGKq_MxNjZkEmnirRY-t1-p3Yzgw@mail.gmail.com>

As a quick follow up, I just came across this blog post on serving up map
tiles via a GitHub repository, generating tiles via a QGIS plugin.
https://khufkens.com/2018/09/19/github-tile-server/

Not an R solution, but perhaps something that might help in a case like
this.  As explained, the solution would still require an internet
connection, but would otherwise be a lot l lighter than having a ton of
polygons in a single webpage.

Please pardon any typos, this message was sent from a mobile device.

On Wed, Sep 12, 2018, 2:27 PM <dirty-harry-ha at gmx.de> wrote:

> Hey Erin,
>
> I agree with everybody who answered, but just for completeness and FYI:
>
> Another approach for sharing a Shiny app offline as a (Windows) Desktop
> app might be using Shiny with "R portable".
>
> For further details please check for example:
> https://www.r-bloggers.com/deploying-desktop-apps-with-r/
>
> Cheers!
>
> Harry
>
> Ps. If anybody thinks this is a very bad idea, please let me know,
> because I'm planing to develop something like that ... Thanks!
>
>
> Am 05.09.2018 um 01:56 schrieb Erin Stearns:
> > Hello all!
> >
> > I hope this message finds you all well!
> >
> > I have 2 questions pertaining to the creation of interactive maps via
> > Leaflet nested inside an RShiny app. One question has to do with
> > computation while the other has to do with sharing/off-line
> interactivity.
> >
> > *Project description:*
> > I am creating a global map depicting binary malaria risk (at risk, not at
> > risk) at the Admin 2 level(current state only uses 5 countries and can be
> > found here <https://erstearns.shinyapps.io/malariarisk5/>).  I am using
> an
> > ESRI base map, then a polygons shapefile containing geometry and
> attributes
> > (geographical hierarchy & risk).
> >
> > *Computation question*
> > As you see, the RShiny app takes quite a bit of time to render. Does
> anyone
> > have any suggestions for improving this? As previously said, this version
> > only contains 5 countries, thus I cannot continue with my current method
> to
> > reach a global map. I have considered finding centroids of all Admin 2
> > polygons and retaining attribute information here, then rasterizing the
> > malaria risk shapefile for visualization and using the 2 instead of a
> > single shapefile with polygon boundaries and attributes.
> >
> > *Sharing the app/offline interactivity*
> > I am planning to share this with people who likely do not have R
> installed
> > on their laptops nor have they ever coded. Does anyone have any
> suggestions
> > for the best way to do this while retaining interactivity?
> >
> > Thank you all, any insight is greatly appreciated.
> >
> > Best,
> > Erin
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mtregli@ @ending from gm@il@com  Thu Sep 20 14:16:11 2018
From: mtregli@ @ending from gm@il@com (Michael Treglia)
Date: Thu, 20 Sep 2018 08:16:11 -0400
Subject: [R-sig-Geo] 
 Leaflet map nested in RShiny App - Improving speed & portability
In-Reply-To: <CAPKp32sesmR0QPbVih+Y0A-ZPKpef-no=DoypT5AAaq=nNv7zg@mail.gmail.com>
References: <CAFf5Nh8GvOC7Fg79zq0V=1+OBB3kQpBQRmYp_T6hkKWg=mhjsQ@mail.gmail.com>
 <CANVKczPTXQpjvsk9m_Ok22-1Ke8JXf+FArr8r=_ais7uON6DWQ@mail.gmail.com>
 <CAFf5Nh8Vj==J1hLRhK-bTsTRW6uX+cP9yaxGGM2Th5szmQP+dA@mail.gmail.com>
 <CAPKp32sesmR0QPbVih+Y0A-ZPKpef-no=DoypT5AAaq=nNv7zg@mail.gmail.com>
Message-ID: <CAPKp32vJs0v10uMO6_uuxim1dMWckSMgHqPf8SiobDbh23xx1A@mail.gmail.com>

Apologies- looks like that only supports raster tiles, as does the R
package 'tiler'.

Sorry for the multiple messages on this.
Cheers,
Mike

Please pardon any typos, this message was sent from a mobile device.

On Wed, Sep 5, 2018, 2:04 PM Michael Treglia <mtreglia at gmail.com> wrote:

> I'll just second Barry's idea in particular, to set up as a standalone
> webpage. You could even use QGIS and the QGIS2Web Plugin to create that,
> and host via GitHub pages or similar.
>
> From R, after creating a map via leaflet and similar packages, you can use
> htmlwidgets::saveWidget() to export as a standalone .html file if I recall
> correctly.
>
> The one thing regarding a standalone webpage is that if you have a lot of
> objects (especially complex ones), that can be a lot for a browser to
> handle (given the data are part of the html file).  Might be worth some
> quick experimentation, and simplifying polygons would help. (You could
> always create a quick landing page, even generated via rMarkdown, and
> having a link for maps by different regions or countries - then you could
> have a folder of .html files you could distribute, and users could just
> open the landing page, and navigate from there).
>
> Just some quick thoughts... Hope this helps.
> Mike T
>
> On Wed, Sep 5, 2018 at 1:17 PM Erin Stearns <estearns88 at gmail.com> wrote:
>
>> Hello all,
>>
>> Thank you all very much for the great insight!
>>
>> *McCrea *- thank you very much, I will test using a geojson first, then
>> test after reducing geometry.
>>
>> *Tim* - thank you for the great breakdown and recommended priority list.
>> Ideally, I would like to be able to share the interactive map with
>> teammates as a file or something akin to it such that they can simply open
>> it and interact with the map. RInno is a great option, however I run a
>> linux machine, so will look into further, but may need to find another
>> option.
>>
>> *Roman* - the app is currently deployed to shinyapps.io. Thank you for
>> sharing about ShinyProxy -- so would this method require 1. Internet and
>> 2.
>> local installation (vs internal server)?
>>
>> *Barry* - wow, thank you for your response! Sounds like this would be the
>> best way to solve both issues. I am not as fluent with HTML and JS, but as
>> you say, there are likely great guides available to take this route.
>>
>> Thank you all again, this has been hugely helpful. I wish you all the best
>> and hope I can be of help to you at some point!
>>
>> Best,
>> Erin
>>
>>
>> On Wed, Sep 5, 2018 at 12:48 AM Barry Rowlingson <
>> b.rowlingson at lancaster.ac.uk> wrote:
>>
>> >
>> >
>> > On Wed, Sep 5, 2018 at 12:56 AM, Erin Stearns <estearns88 at gmail.com>
>> > wrote:
>> >
>> >> Hello all!
>> >>
>> >> I hope this message finds you all well!
>> >>
>> >> I have 2 questions pertaining to the creation of interactive maps via
>> >> Leaflet nested inside an RShiny app. One question has to do with
>> >> computation while the other has to do with sharing/off-line
>> interactivity.
>> >>
>> >> *Computation question*
>> >> As you see, the RShiny app takes quite a bit of time to render. Does
>> >> anyone
>> >> have any suggestions for improving this? As previously said, this
>> version
>> >> only contains 5 countries, thus I cannot continue with my current
>> method
>> >> to
>> >> reach a global map. I have considered finding centroids of all Admin 2
>> >> polygons and retaining attribute information here, then rasterizing the
>> >> malaria risk shapefile for visualization and using the 2 instead of a
>> >> single shapefile with polygon boundaries and attributes.
>> >>
>> >>
>> > Unless you plan to add any computational functions to this map then I'd
>> > strongly recommend creating it as a standalone web app and not a shiny
>> app.
>> > This will enable you to use lots of useful Leaflet plugins for speeding
>> > things up, such as only showing country outlines at low zoom levels, and
>> > showing subdivisions only at high zoom levels. This *might* be possible
>> > with R's various leaflet packages but I'd go for full javascript
>> control.
>> >
>> > A standalone map would take its data from a JSON file or similar, and
>> you
>> > would then be writing R code that generated that. The mapping app
>> itself is
>> > written in HTML and JS with CSS styling. There are plenty of guides to
>> > web-based interactive mapping, starting with Leaflet.
>> >
>> >
>> >> *Sharing the app/offline interactivity*
>> >> I am planning to share this with people who likely do not have R
>> installed
>> >> on their laptops nor have they ever coded. Does anyone have any
>> >> suggestions
>> >> for the best way to do this while retaining interactivity?
>> >>
>> >>  Here's the big win of creating a standalone web map. You only have to
>> > distribute the HTML/CSS/JS and they can be viewed directly (or you also
>> > supply a tiny server that runs locally and only has to feed the files
>> on a
>> > localhost port). No need to have a shiny server anywhere, or install R.
>> Its
>> > simple and clean. It also needs no network connectivity, but you'll not
>> get
>> > a base map - but you could include a low or medium resolution basemap
>> > raster in your package.
>> >
>> > The only reason to need Shiny here would be if you wanted people to do
>> > something computational, like click on a bunch of polygons and then fit
>> a
>> > linear model to the selection, since that would require a round-trip to
>> the
>> > server for R to compute the fit. (although I suspect there's a JS
>> package
>> > for linear modelling.... you can do ML in JS these days...)
>> >
>> >
>> >
>> >> Thank you all, any insight is greatly appreciated.
>> >>
>> >> Best,
>> >> Erin
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 20 16:29:29 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 20 Sep 2018 07:29:29 -0700 (PDT)
Subject: [R-sig-Geo] Using CRS() method on SpatialPointDataFrame to project
 coordinates
Message-ID: <alpine.LNX.2.20.1809200709270.14962@salmo.appl-ecosys.com>

   I have a SpatialPointsDataFrame with geographic coordinates:

#> str(prcp_sites_ll)
Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame':	58 obs. of  3 variables:
   .. ..$ name     : Factor w/ 58 levels "Blazed Alder",..: 1 2 3 4 5 6 7 8 9 10 ...
   .. ..$ elev     : num [1:58] 1112.5 159.1 162.2 45.4 57.3 ...
   .. ..$ mean_prcp: num [1:58] 0.362 0.155 0.16 0.12 0.128 ...
   ..@ coords.nrs : int [1:2] 2 3
   ..@ coords     : num [1:58, 1:2] -122 -122 -122 -123 -123 ...
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : NULL
   .. .. ..$ : chr [1:2] "easting" "northing"
   ..@ bbox       : num [1:2, 1:2] -122.8 45 -121.7 45.5
   .. ..- attr(*, "dimnames")=List of 2
   .. .. ..$ : chr [1:2] "easting" "northing"
   .. .. ..$ : chr [1:2] "min" "max"
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
   .. .. ..@ projargs: chr NA

and I want to project this using CRS('+init=epsg:2838') to a new SPDF
called prcp_sites_lcc.

   I think the proper syntax would be:

prcp_sites_lcc <- spTransform(prcp_sites_ll,CRS('+init=epsg:2838'))

   Is this correct?

Regards,

Rich


From m@cqueen1 @ending from llnl@gov  Thu Sep 20 17:05:42 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 20 Sep 2018 15:05:42 +0000
Subject: [R-sig-Geo] 
 Using CRS() method on SpatialPointDataFrame to project coordinates
In-Reply-To: <alpine.LNX.2.20.1809200709270.14962@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809200709270.14962@salmo.appl-ecosys.com>
Message-ID: <478D03A4-98EC-4661-A38B-6F0FD85E3615@llnl.gov>

First, it looks like prcp_sites_ll does not have CRS information, because @projargs is NA. You'll need something like

  proj4string(prcp_sites_ll) <- CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0')

That string may have more than is necessary; you could also try

   CRS('+init=epsg:4326')

Otherwise, your spTransform() command looks ok to me.

(have you come across spatialreference.org? I find it useful. Example
   http://spatialreference.org/ref/epsg/wgs-84/
)

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 9/20/18, 7:29 AM, "R-sig-Geo on behalf of Rich Shepard" <r-sig-geo-bounces at r-project.org on behalf of rshepard at appl-ecosys.com> wrote:

       I have a SpatialPointsDataFrame with geographic coordinates:
    
    #> str(prcp_sites_ll)
    Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
       ..@ data       :'data.frame':	58 obs. of  3 variables:
       .. ..$ name     : Factor w/ 58 levels "Blazed Alder",..: 1 2 3 4 5 6 7 8 9 10 ...
       .. ..$ elev     : num [1:58] 1112.5 159.1 162.2 45.4 57.3 ...
       .. ..$ mean_prcp: num [1:58] 0.362 0.155 0.16 0.12 0.128 ...
       ..@ coords.nrs : int [1:2] 2 3
       ..@ coords     : num [1:58, 1:2] -122 -122 -122 -123 -123 ...
       .. ..- attr(*, "dimnames")=List of 2
       .. .. ..$ : NULL
       .. .. ..$ : chr [1:2] "easting" "northing"
       ..@ bbox       : num [1:2, 1:2] -122.8 45 -121.7 45.5
       .. ..- attr(*, "dimnames")=List of 2
       .. .. ..$ : chr [1:2] "easting" "northing"
       .. .. ..$ : chr [1:2] "min" "max"
       ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
       .. .. ..@ projargs: chr NA
    
    and I want to project this using CRS('+init=epsg:2838') to a new SPDF
    called prcp_sites_lcc.
    
       I think the proper syntax would be:
    
    prcp_sites_lcc <- spTransform(prcp_sites_ll,CRS('+init=epsg:2838'))
    
       Is this correct?
    
    Regards,
    
    Rich
    
    _______________________________________________
    R-sig-Geo mailing list
    R-sig-Geo at r-project.org
    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
    


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 20 17:31:21 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 20 Sep 2018 08:31:21 -0700 (PDT)
Subject: [R-sig-Geo] 
 Using CRS() method on SpatialPointDataFrame to project coordinates
In-Reply-To: <478D03A4-98EC-4661-A38B-6F0FD85E3615@llnl.gov>
References: <alpine.LNX.2.20.1809200709270.14962@salmo.appl-ecosys.com>
 <478D03A4-98EC-4661-A38B-6F0FD85E3615@llnl.gov>
Message-ID: <alpine.LNX.2.20.1809200823040.14962@salmo.appl-ecosys.com>

On Thu, 20 Sep 2018, MacQueen, Don wrote:

> First, it looks like prcp_sites_ll does not have CRS information, because
> @projargs is NA.

Don,

   I used coordinates(prcp_sites_ll) <- c('easting','northing') to transform
the original dataframe to a SpatialPointsDataFrame and thought that because lat-lon
was not projected the @projards=NA was expected. Now I have learned that ...

> You'll need something like
>  proj4string(prcp_sites_ll) <- CRS('+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0')
or
>   CRS('+init=epsg:4326')

   I missed this step in my readings.

> Otherwise, your spTransform() command looks ok to me.

   Good to know.

> (have you come across spatialreference.org? I find it useful. Example
>   http://spatialreference.org/ref/epsg/wgs-84/)

   Yes. I frequently use that when working in GRASS since multiple agency
sources use different, and frequently undocumented, projectons on their
shapefiles.

Many thanks,

Rich


From vij@ylull@ @ending from gm@il@com  Thu Sep 20 18:33:46 2018
From: vij@ylull@ @ending from gm@il@com (Vijay Lulla)
Date: Thu, 20 Sep 2018 12:33:46 -0400
Subject: [R-sig-Geo] Consolidated SRS database/list?
Message-ID: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>

Dear list members,
A few years ago Roger Bivand posted a discussion (
https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html ) about
consolidating SRS definitions into a SQLite database and I am wondering if
there has been any development along those lines.  Specifically, is there
any consolidated collection of SRS definitions in R (either a data.frame or
tibble or SQLite backed) that are being used by geospatial packages that
users can use too?  If so, can you please point me to it?  If not, would it
be worthwhile to have this consolidated list/dataframe, maybe as part of
data for one of the core geospatial packages?
Thanks in advance,
Vijay

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Thu Sep 20 19:01:44 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Thu, 20 Sep 2018 19:01:44 +0200
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>

On Thu, 20 Sep 2018, Vijay Lulla wrote:

> Dear list members,
> A few years ago Roger Bivand posted a discussion (
> https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html ) about
> consolidating SRS definitions into a SQLite database and I am wondering if
> there has been any development along those lines.

Rather than trying this just within R, we're hoping that the GDAL 
barn-raising effort:

https://gdalbarn.com/

will take us there and further, and be much better than having a 
non-standard implementation.

When that effort is done, we'll be open for ideas about interfacing it 
through PROJ and GDAL, which now ship with CSV files that we copy into 
Windows and MacOS binary packages (rgdal, sf, lwgeom).

For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file shipped 
with PROJ into the R workspace as a data.frame.

Roger

> Specifically, is there any consolidated collection of SRS definitions in 
> R (either a data.frame or tibble or SQLite backed) that are being used 
> by geospatial packages that users can use too?  If so, can you please 
> point me to it?  If not, would it be worthwhile to have this 
> consolidated list/dataframe, maybe as part of data for one of the core 
> geospatial packages? Thanks in advance, Vijay
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 20 19:38:05 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 20 Sep 2018 10:38:05 -0700 (PDT)
Subject: [R-sig-Geo] Library version mis-match
Message-ID: <alpine.LNX.2.20.1809201017300.14962@salmo.appl-ecosys.com>

   If the r-help list is better suited for this question let me know and I'll
move the thread there.

   Installed here are gdal-2.2.4 and geos-3.7.0

   When I check installed libraries with library() both rgdal and rgeos are
shown as being available:

rgdal                   Bindings for the 'Geospatial' Data Abstraction
                         Library
rgeos                   Interface to Geometry Engine - Open Source
                         ('GEOS')

   However, when I try to use them in an operation with the sp() package the
attempts fail. So I tried re-installing them. rgeos had no problem
re-installing, but rgdal is not happy:

** testing if installed package can be loaded
Error: package or namespace load failed for ?rgdal? in dyn.load(file, DLLpath = DLLpath, ...):
  unable to load shared object '/usr/lib/R/library/rgdal/libs/rgdal.so':
   libgeos-3.6.3.so: cannot open shared object file: No such file or directory
Error: loading failed
Execution halted
ERROR: loading failed
* removing ?/usr/lib/R/library/rgdal?
* restoring previous ?/usr/lib/R/library/rgdal?

The downloaded source packages are in
 	?/tmp/Rtmp22EDOj/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("rgdal") :
   installation of package ?rgdal? had non-zero exit status

   How can I resolve this by having R recognize, and use, geos-3.7.0? Or, do
I need to downgrade geos to the earlier 3.6.3?

Rich


From Roger@Biv@nd @ending from nhh@no  Thu Sep 20 20:37:59 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Thu, 20 Sep 2018 20:37:59 +0200
Subject: [R-sig-Geo] Library version mis-match
In-Reply-To: <alpine.LNX.2.20.1809201017300.14962@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809201017300.14962@salmo.appl-ecosys.com>
Message-ID: <alpine.LFD.2.21.1809202030480.20554@reclus.nhh.no>

On Thu, 20 Sep 2018, Rich Shepard wrote:

>  If the r-help list is better suited for this question let me know and I'll
> move the thread there.

No, this is the right list, but always include the output of 
sessionInfo(), and the startup messages shown by rgdal and rgeos when they 
are attached.

>
>  Installed here are gdal-2.2.4 and geos-3.7.0
>

How many other versions of gdal and/or geos do you have? It looks as 
though libgdal was built against libgeos-3.6.3, but you upgraded libgeos 
later, removing that version. Easiest is having one version only, and 
building everything in lockstep (PROJ and GEOS, then GDAL, then rgdal 
and/or GRASS) and having only one version of each. Both rgdal and rgeos 
may suffer from being installed with the versions shown by gdal-config and 
geos-config, but finding different versions in the dynamic library load 
path. I'm assuming you are neither on Windows nor MacOS - all this is 
sorted out on CRAN in binary rgdal and rgeos (and sf) packages for those 
platforms.

Hope this helps,

Roger

>  When I check installed libraries with library() both rgdal and rgeos are
> shown as being available:
>
> rgdal                   Bindings for the 'Geospatial' Data Abstraction
>                        Library
> rgeos                   Interface to Geometry Engine - Open Source
>                         ('GEOS')
>
>  However, when I try to use them in an operation with the sp() package the
> attempts fail. So I tried re-installing them. rgeos had no problem
> re-installing, but rgdal is not happy:
>
> ** testing if installed package can be loaded
> Error: package or namespace load failed for ?rgdal? in dyn.load(file, DLLpath 
> = DLLpath, ...):
>  unable to load shared object '/usr/lib/R/library/rgdal/libs/rgdal.so':
>  libgeos-3.6.3.so: cannot open shared object file: No such file or directory
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing ?/usr/lib/R/library/rgdal?
> * restoring previous ?/usr/lib/R/library/rgdal?
>
> The downloaded source packages are in
> 	?/tmp/Rtmp22EDOj/downloaded_packages?
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgdal") :
>   installation of package ?rgdal? had non-zero exit status
>
>  How can I resolve this by having R recognize, and use, geos-3.7.0? Or, do
> I need to downgrade geos to the earlier 3.6.3?
>
> Rich
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 20 20:47:38 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 20 Sep 2018 11:47:38 -0700 (PDT)
Subject: [R-sig-Geo] Library version mis-match
In-Reply-To: <alpine.LFD.2.21.1809202030480.20554@reclus.nhh.no>
References: <alpine.LNX.2.20.1809201017300.14962@salmo.appl-ecosys.com>
 <alpine.LFD.2.21.1809202030480.20554@reclus.nhh.no>
Message-ID: <alpine.LNX.2.20.1809201143510.14962@salmo.appl-ecosys.com>

On Thu, 20 Sep 2018, Roger Bivand wrote:

> No, this is the right list, but always include the output of sessionInfo(), 
> and the startup messages shown by rgdal and rgeos when they are attached.

Roger,

   I'll include more information the next time I have an issue.

> How many other versions of gdal and/or geos do you have? It looks as though 
> libgdal was built against libgeos-3.6.3, but you upgraded libgeos later,

   This might well be the issue. geos was upgraded from the summer's 3.6.3 to
the very recent 3.7.0 and when I run weekly upgrades to installed
Slackbuilds.org packages that was upgraded. I'll rebuild gdal and check that
the issue is resolved.

   Not long ago I did rebuild the sequence proj -> geos -> gdal -> grass and
the R upgrade might have missed that.

Many thanks,

Rich


From r@hep@rd @ending from @ppl-eco@y@@com  Thu Sep 20 22:27:38 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Thu, 20 Sep 2018 13:27:38 -0700 (PDT)
Subject: [R-sig-Geo] Library version mis-match [FIXED]
In-Reply-To: <alpine.LNX.2.20.1809201143510.14962@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.1809201017300.14962@salmo.appl-ecosys.com>
 <alpine.LFD.2.21.1809202030480.20554@reclus.nhh.no>
 <alpine.LNX.2.20.1809201143510.14962@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.1809201326320.14962@salmo.appl-ecosys.com>

On Thu, 20 Sep 2018, Rich Shepard wrote:

> This might well be the issue. geos was upgraded from the summer's 3.6.3 to
> the very recent 3.7.0 and when I run weekly upgrades to installed
> Slackbuilds.org packages that was upgraded. I'll rebuild gdal and check that
> the issue is resolved.

   Fixed. Rebuilt/re-installed gdal-2.4.4 and rgdal re-installed without
problems.

Thanks again,

Rich


From vij@ylull@ @ending from gm@il@com  Thu Sep 20 22:47:18 2018
From: vij@ylull@ @ending from gm@il@com (Vijay Lulla)
Date: Thu, 20 Sep 2018 16:47:18 -0400
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
 <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
Message-ID: <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>

Ok, thanks!  While the page provided information about the project and its
funding status I couldn't find the SQLite database.  Do you happen to know
when this will be available?

On Thu, Sep 20, 2018 at 1:02 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>
> > Dear list members,
> > A few years ago Roger Bivand posted a discussion (
> > https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html ) about
> > consolidating SRS definitions into a SQLite database and I am wondering
> if
> > there has been any development along those lines.
>
> Rather than trying this just within R, we're hoping that the GDAL
> barn-raising effort:
>
> https://gdalbarn.com/
>
> will take us there and further, and be much better than having a
> non-standard implementation.
>
> When that effort is done, we'll be open for ideas about interfacing it
> through PROJ and GDAL, which now ship with CSV files that we copy into
> Windows and MacOS binary packages (rgdal, sf, lwgeom).
>
> For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file shipped
> with PROJ into the R workspace as a data.frame.
>
> Roger
>
> > Specifically, is there any consolidated collection of SRS definitions in
> > R (either a data.frame or tibble or SQLite backed) that are being used
> > by geospatial packages that users can use too?  If so, can you please
> > point me to it?  If not, would it be worthwhile to have this
> > consolidated list/dataframe, maybe as part of data for one of the core
> > geospatial packages? Thanks in advance, Vijay
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>


-- 
Vijay Lulla

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu
ORCID: https://orcid.org/0000-0002-0823-2522
Webpage: http://vijaylulla.com

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Sep 21 09:32:15 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 21 Sep 2018 09:32:15 +0200
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
 <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
 <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>
Message-ID: <alpine.LFD.2.21.1809210931090.3575@reclus.nhh.no>

On Thu, 20 Sep 2018, Vijay Lulla wrote:

> Ok, thanks!  While the page provided information about the project and its
> funding status I couldn't find the SQLite database.  Do you happen to know
> when this will be available?

No more than is on that page, plus the time needed to re-write plenty of 
sf, lwgeom, rgdal and sp. At that stage, contributions welcome!

Roger

>
> On Thu, Sep 20, 2018 at 1:02 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>>
>>> Dear list members,
>>> A few years ago Roger Bivand posted a discussion (
>>> https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html ) about
>>> consolidating SRS definitions into a SQLite database and I am wondering
>> if
>>> there has been any development along those lines.
>>
>> Rather than trying this just within R, we're hoping that the GDAL
>> barn-raising effort:
>>
>> https://gdalbarn.com/
>>
>> will take us there and further, and be much better than having a
>> non-standard implementation.
>>
>> When that effort is done, we'll be open for ideas about interfacing it
>> through PROJ and GDAL, which now ship with CSV files that we copy into
>> Windows and MacOS binary packages (rgdal, sf, lwgeom).
>>
>> For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file shipped
>> with PROJ into the R workspace as a data.frame.
>>
>> Roger
>>
>>> Specifically, is there any consolidated collection of SRS definitions in
>>> R (either a data.frame or tibble or SQLite backed) that are being used
>>> by geospatial packages that users can use too?  If so, can you please
>>> point me to it?  If not, would it be worthwhile to have this
>>> consolidated list/dataframe, maybe as part of data for one of the core
>>> geospatial packages? Thanks in advance, Vijay
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From D@vid@GIOVANNINI m@ili@g off ext@ec@europ@@eu  Fri Sep 21 11:52:19 2018
From: D@vid@GIOVANNINI m@ili@g off ext@ec@europ@@eu (D@vid@GIOVANNINI m@ili@g off ext@ec@europ@@eu)
Date: Fri, 21 Sep 2018 09:52:19 +0000
Subject: [R-sig-Geo] RGDAL installation fail after yum upgrade
Message-ID: <8B17ED9FFB25754089C518780EB9916C060FD192@S-DC-ESTC03-B.net1.cec.eu.int>

Dear list members,
I'm tring to install RGDAL on a cluster, but after the update of R packages seems not possible to install it.

Below the error message:

> install.packages("rgdal")
Installing package into '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5'
(as 'lib' is unspecified)
trying URL 'https://cran.stat.unipd.it/src/contrib/rgdal_1.3-4.tar.gz'
Content type 'application/octet-stream' length 1664774 bytes (1.6 MB)
==================================================
downloaded 1.6 MB

* installing *source* package 'rgdal' ...
** package 'rgdal' successfully unpacked and MD5 sums checked
configure: R_HOME: /usr/lib64/R
configure: CC: gcc -m64 -std=gnu99
configure: CXX: g++ -m64
configure: C++11 support available
configure: rgdal: 1.3-4
checking for /usr/bin/svnversion... yes
configure: svn revision: 766
checking for gdal-config... /bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 1.11.4
checking GDAL version >= 1.11.4... yes
checking gdal: linking with --libs only... yes
checking GDAL: /usr/share/gdal/pcs.csv readable... yes
checking proj_api.h presence and usability... yes
./configure: line 2126: test: =: unary operator expected
checking PROJ version >= 4.8.0... yes
checking projects.h presence and usability... yes
/tmp/ccnBOZCl.o: In function `main':
/tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/proj_conf_test2.c:20: undefined reference to `pj_ctx_fclose'
collect2: error: ld returned 1 exit status
./configure: line 2242: ./proj_conf_test2: No such file or directory
checking PROJ.4: epsg found and readable... yes
/tmp/ccu3xNdp.o: In function `main':
/tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/proj_conf_test3.c:20: undefined reference to `pj_ctx_fclose'
collect2: error: ld returned 1 exit status
./configure: line 2301: ./proj_conf_test3: No such file or directory
checking PROJ.4: conus found and readable... yes
configure: Package CPP flags:  -I/usr/include/gdal
configure: Package LIBS:  -L/usr/lib64 -lgdal -lproj
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c gdal-bindings.cpp -o gdal-bindings.o
gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c init.c -o init.o
gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c inverser.c -o inverser.o
gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c local_stubs.c -o local_stubs.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogr_geom.cpp -o ogr_geom.o
gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c ogr_polygons.c -o ogr_polygons.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogr_proj.cpp -o ogr_proj.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogrdrivers.cpp -o ogrdrivers.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogrsource.cpp -o ogrsource.o
ogrsource.cpp: In function 'SEXPREC* ogrReadListColumn(OGRLayer*, SEXP, int, int, int)':
ogrsource.cpp:651:12: warning: unused variable 'DINT_MAX' [-Wunused-variable]
     double DINT_MAX = 2251799813685248.0;
            ^
ogrsource.cpp:652:12: warning: unused variable 'DINT_MIN' [-Wunused-variable]
     double DINT_MIN = -2251799813685248.0;
            ^
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c projectit.cpp -o projectit.o
g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o rgdal.so OGR_write.o gdal-bindings.o init.o inverser.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
installing to /home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs
** R
** data
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
  converting help for package 'rgdal'
    finding HTML links ... done
    CRS-class                               html
    GDALDataset-class                       html
    GDALDriver-class                        html
    GDALMajorObject-class                   html
    GDALRasterBand-class                    html
    GDALReadOnlyDataset-class               html
    GDALReadOnlyDataset-methods             html
    GDALTransientDataset-class              html
    GridsDatums                             html
    RGB2PCT                                 html
    SGDF2PCT                                html
    SpatialGDAL-class                       html
    closeDataset-methods                    html
    displayDataset                          html
    llgrid                                  html
Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:11: file link 'Spatial' in package 'sp' does not exist and so has been treated as a topic
Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:16: file link 'gridat' in package 'sp' does not exist and so has been treated as a topic
Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:17: file link 'gridat' in package 'sp' does not exist and so has been treated as a topic
    make_EPSG                               html
    nor2k                                   html
    projInfo                                html
    project                                 html
    readGDAL                                html
Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/readGDAL.Rd:136: file link 'flipVertical' in package 'sp' does not exist and so has been treated as a topic
    readOGR                                 html
    showWKT                                 html
    spTransform-methods                     html
    wrappers                                html
    writeOGR                                html
** building package indices
** installing vignettes
** testing if installed package can be loaded
Error: package or namespace load failed for 'rgdal' in dyn.load(file, DLLpath = DLLpath, ...):
unable to load shared object '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs/rgdal.so':
  /home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs/rgdal.so: undefined symbol: pj_ctx_fgets
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal'

The downloaded source packages are in
     '/tmp/RtmpXrQsj2/downloaded_packages'
Warning message:
In install.packages("rgdal") :
  installation of package 'rgdal' had non-zero exit status

I have tried several solutions but without any success.

Have you any idea about the problem?

Thanks in advance
David

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Sep 21 12:25:20 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 21 Sep 2018 12:25:20 +0200
Subject: [R-sig-Geo] RGDAL installation fail after yum upgrade
In-Reply-To: <8B17ED9FFB25754089C518780EB9916C060FD192@S-DC-ESTC03-B.net1.cec.eu.int>
References: <8B17ED9FFB25754089C518780EB9916C060FD192@S-DC-ESTC03-B.net1.cec.eu.int>
Message-ID: <alpine.LFD.2.21.1809211213000.3575@reclus.nhh.no>

On Fri, 21 Sep 2018, David.GIOVANNINI at ext.ec.europa.eu wrote:

> Dear list members, I'm tring to install RGDAL on a cluster, but after 
> the update of R packages seems not possible to install it.

On a cluster running which very outdated version of which operating 
system? How did you install PROJ and GDAL, hopefully from source? How did 
you install R, again hopefully from source? If you install from source, 
your upstream binaries should only use the limited resources of your 
outdated platform; if you install binary packages, those packages will 
make brave and possibly untrue assumptions about your platform. It is also 
very possible that you have multiple versions of GDAL and/or PROJ on your 
systems, and that (parts of) configure and install find different 
versions. In particular, at least one version of PROJ does not have 
pj_ctx_* file access functions, needed in several places.

If you can't fix your systems (PROJ 4.8.0 was released in 2012, over 6 
years ago), use a version of rgdal, GDAL and driver software to match your 
vintage. Possibly your compile trains are also very outdated too.

Maintainers cannot be expected to keep current package versions running 
smoothly on ancient platforms (although we try to help) without active 
contributions from interested users. Provide patches to configure.ac that 
work for you and do not have any negative impacts on current systems, or 
keep your systems more up to date.

Roger

>
> Below the error message:
>
>> install.packages("rgdal")
> Installing package into '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5'
> (as 'lib' is unspecified)
> trying URL 'https://cran.stat.unipd.it/src/contrib/rgdal_1.3-4.tar.gz'
> Content type 'application/octet-stream' length 1664774 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
>
> * installing *source* package 'rgdal' ...
> ** package 'rgdal' successfully unpacked and MD5 sums checked
> configure: R_HOME: /usr/lib64/R
> configure: CC: gcc -m64 -std=gnu99
> configure: CXX: g++ -m64
> configure: C++11 support available
> configure: rgdal: 1.3-4
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 766
> checking for gdal-config... /bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 1.11.4
> checking GDAL version >= 1.11.4... yes
> checking gdal: linking with --libs only... yes
> checking GDAL: /usr/share/gdal/pcs.csv readable... yes
> checking proj_api.h presence and usability... yes
> ./configure: line 2126: test: =: unary operator expected
> checking PROJ version >= 4.8.0... yes
> checking projects.h presence and usability... yes
> /tmp/ccnBOZCl.o: In function `main':
> /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/proj_conf_test2.c:20: undefined reference to `pj_ctx_fclose'
> collect2: error: ld returned 1 exit status
> ./configure: line 2242: ./proj_conf_test2: No such file or directory
> checking PROJ.4: epsg found and readable... yes
> /tmp/ccu3xNdp.o: In function `main':
> /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/proj_conf_test3.c:20: undefined reference to `pj_ctx_fclose'
> collect2: error: ld returned 1 exit status
> ./configure: line 2301: ./proj_conf_test3: No such file or directory
> checking PROJ.4: conus found and readable... yes
> configure: Package CPP flags:  -I/usr/include/gdal
> configure: Package LIBS:  -L/usr/lib64 -lgdal -lproj
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c gdal-bindings.cpp -o gdal-bindings.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c init.c -o init.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c inverser.c -o inverser.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c local_stubs.c -o local_stubs.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogr_geom.cpp -o ogr_geom.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c ogr_polygons.c -o ogr_polygons.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogr_proj.cpp -o ogr_proj.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogrsource.cpp -o ogrsource.o
> ogrsource.cpp: In function 'SEXPREC* ogrReadListColumn(OGRLayer*, SEXP, int, int, int)':
> ogrsource.cpp:651:12: warning: unused variable 'DINT_MAX' [-Wunused-variable]
>     double DINT_MAX = 2251799813685248.0;
>            ^
> ogrsource.cpp:652:12: warning: unused variable 'DINT_MIN' [-Wunused-variable]
>     double DINT_MIN = -2251799813685248.0;
>            ^
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c projectit.cpp -o projectit.o
> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o rgdal.so OGR_write.o gdal-bindings.o init.o inverser.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
> installing to /home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs
> ** R
> ** data
> ** inst
> ** byte-compile and prepare package for lazy loading
> ** help
> *** installing help indices
>  converting help for package 'rgdal'
>    finding HTML links ... done
>    CRS-class                               html
>    GDALDataset-class                       html
>    GDALDriver-class                        html
>    GDALMajorObject-class                   html
>    GDALRasterBand-class                    html
>    GDALReadOnlyDataset-class               html
>    GDALReadOnlyDataset-methods             html
>    GDALTransientDataset-class              html
>    GridsDatums                             html
>    RGB2PCT                                 html
>    SGDF2PCT                                html
>    SpatialGDAL-class                       html
>    closeDataset-methods                    html
>    displayDataset                          html
>    llgrid                                  html
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:11: file link 'Spatial' in package 'sp' does not exist and so has been treated as a topic
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:16: file link 'gridat' in package 'sp' does not exist and so has been treated as a topic
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:17: file link 'gridat' in package 'sp' does not exist and so has been treated as a topic
>    make_EPSG                               html
>    nor2k                                   html
>    projInfo                                html
>    project                                 html
>    readGDAL                                html
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/readGDAL.Rd:136: file link 'flipVertical' in package 'sp' does not exist and so has been treated as a topic
>    readOGR                                 html
>    showWKT                                 html
>    spTransform-methods                     html
>    wrappers                                html
>    writeOGR                                html
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> Error: package or namespace load failed for 'rgdal' in dyn.load(file, DLLpath = DLLpath, ...):
> unable to load shared object '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs/rgdal.so':
>  /home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs/rgdal.so: undefined symbol: pj_ctx_fgets
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal'
>
> The downloaded source packages are in
>     '/tmp/RtmpXrQsj2/downloaded_packages'
> Warning message:
> In install.packages("rgdal") :
>  installation of package 'rgdal' had non-zero exit status
>
> I have tried several solutions but without any success.
>
> Have you any idea about the problem?
>
> Thanks in advance
> David
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From D@vid@GIOVANNINI m@ili@g off ext@ec@europ@@eu  Fri Sep 21 15:35:04 2018
From: D@vid@GIOVANNINI m@ili@g off ext@ec@europ@@eu (D@vid@GIOVANNINI m@ili@g off ext@ec@europ@@eu)
Date: Fri, 21 Sep 2018 13:35:04 +0000
Subject: [R-sig-Geo] RGDAL installation fail after yum upgrade
In-Reply-To: <alpine.LFD.2.21.1809211213000.3575@reclus.nhh.no>
References: <8B17ED9FFB25754089C518780EB9916C060FD192@S-DC-ESTC03-B.net1.cec.eu.int>
 <alpine.LFD.2.21.1809211213000.3575@reclus.nhh.no>
Message-ID: <8B17ED9FFB25754089C518780EB9916C060FD21B@S-DC-ESTC03-B.net1.cec.eu.int>

Dear Roger, thanks for your reply.

I know, that this cluster have several problems, at first the pool software.
I'm the maintainer and not the creator, so I have inherited all this problems.

The version of OS is Centos 7.5 and unluckly all the software has been installed
via EPEL repository and not from source.

I have checked all the packages (GDAL v1.11.4, PROJ4 v4.9.1) and seems that 
the minimun required version has been satisfied. But on the system I have two 
version of PROJ4, the version v4.8.0 ( /usr/bin/proj ) and the version v4.9.1
( /usr/local/bin/proj ).

So can I force the use of the new version of PROJ with some parameters during 
the installation of RGDAL?

Thanks in advance for your support.
David

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Friday, September 21, 2018 12:25 PM
To: GIOVANNINI David (JRC-ISPRA-EXT)
Cc: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] RGDAL installation fail after yum upgrade

On Fri, 21 Sep 2018, David.GIOVANNINI at ext.ec.europa.eu wrote:

> Dear list members, I'm tring to install RGDAL on a cluster, but after 
> the update of R packages seems not possible to install it.

On a cluster running which very outdated version of which operating 
system? How did you install PROJ and GDAL, hopefully from source? How did 
you install R, again hopefully from source? If you install from source, 
your upstream binaries should only use the limited resources of your 
outdated platform; if you install binary packages, those packages will 
make brave and possibly untrue assumptions about your platform. It is also 
very possible that you have multiple versions of GDAL and/or PROJ on your 
systems, and that (parts of) configure and install find different 
versions. In particular, at least one version of PROJ does not have 
pj_ctx_* file access functions, needed in several places.

If you can't fix your systems (PROJ 4.8.0 was released in 2012, over 6 
years ago), use a version of rgdal, GDAL and driver software to match your 
vintage. Possibly your compile trains are also very outdated too.

Maintainers cannot be expected to keep current package versions running 
smoothly on ancient platforms (although we try to help) without active 
contributions from interested users. Provide patches to configure.ac that 
work for you and do not have any negative impacts on current systems, or 
keep your systems more up to date.

Roger

>
> Below the error message:
>
>> install.packages("rgdal")
> Installing package into '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5'
> (as 'lib' is unspecified)
> trying URL 'https://cran.stat.unipd.it/src/contrib/rgdal_1.3-4.tar.gz'
> Content type 'application/octet-stream' length 1664774 bytes (1.6 MB)
> ==================================================
> downloaded 1.6 MB
>
> * installing *source* package 'rgdal' ...
> ** package 'rgdal' successfully unpacked and MD5 sums checked
> configure: R_HOME: /usr/lib64/R
> configure: CC: gcc -m64 -std=gnu99
> configure: CXX: g++ -m64
> configure: C++11 support available
> configure: rgdal: 1.3-4
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 766
> checking for gdal-config... /bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 1.11.4
> checking GDAL version >= 1.11.4... yes
> checking gdal: linking with --libs only... yes
> checking GDAL: /usr/share/gdal/pcs.csv readable... yes
> checking proj_api.h presence and usability... yes
> ./configure: line 2126: test: =: unary operator expected
> checking PROJ version >= 4.8.0... yes
> checking projects.h presence and usability... yes
> /tmp/ccnBOZCl.o: In function `main':
> /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/proj_conf_test2.c:20: undefined reference to `pj_ctx_fclose'
> collect2: error: ld returned 1 exit status
> ./configure: line 2242: ./proj_conf_test2: No such file or directory
> checking PROJ.4: epsg found and readable... yes
> /tmp/ccu3xNdp.o: In function `main':
> /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/proj_conf_test3.c:20: undefined reference to `pj_ctx_fclose'
> collect2: error: ld returned 1 exit status
> ./configure: line 2301: ./proj_conf_test3: No such file or directory
> checking PROJ.4: conus found and readable... yes
> configure: Package CPP flags:  -I/usr/include/gdal
> configure: Package LIBS:  -L/usr/lib64 -lgdal -lproj
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c gdal-bindings.cpp -o gdal-bindings.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c init.c -o init.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c inverser.c -o inverser.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c local_stubs.c -o local_stubs.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogr_geom.cpp -o ogr_geom.o
> gcc -m64 -std=gnu99 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic  -c ogr_polygons.c -o ogr_polygons.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogr_proj.cpp -o ogr_proj.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c ogrsource.cpp -o ogrsource.o
> ogrsource.cpp: In function 'SEXPREC* ogrReadListColumn(OGRLayer*, SEXP, int, int, int)':
> ogrsource.cpp:651:12: warning: unused variable 'DINT_MAX' [-Wunused-variable]
>     double DINT_MAX = 2251799813685248.0;
>            ^
> ogrsource.cpp:652:12: warning: unused variable 'DINT_MIN' [-Wunused-variable]
>     double DINT_MIN = -2251799813685248.0;
>            ^
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal -I"/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/sp/include" -I/usr/local/include   -fpic  -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic -c projectit.cpp -o projectit.o
> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o rgdal.so OGR_write.o gdal-bindings.o init.o inverser.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
> installing to /home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs
> ** R
> ** data
> ** inst
> ** byte-compile and prepare package for lazy loading
> ** help
> *** installing help indices
>  converting help for package 'rgdal'
>    finding HTML links ... done
>    CRS-class                               html
>    GDALDataset-class                       html
>    GDALDriver-class                        html
>    GDALMajorObject-class                   html
>    GDALRasterBand-class                    html
>    GDALReadOnlyDataset-class               html
>    GDALReadOnlyDataset-methods             html
>    GDALTransientDataset-class              html
>    GridsDatums                             html
>    RGB2PCT                                 html
>    SGDF2PCT                                html
>    SpatialGDAL-class                       html
>    closeDataset-methods                    html
>    displayDataset                          html
>    llgrid                                  html
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:11: file link 'Spatial' in package 'sp' does not exist and so has been treated as a topic
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:16: file link 'gridat' in package 'sp' does not exist and so has been treated as a topic
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/llgrid.Rd:17: file link 'gridat' in package 'sp' does not exist and so has been treated as a topic
>    make_EPSG                               html
>    nor2k                                   html
>    projInfo                                html
>    project                                 html
>    readGDAL                                html
> Rd warning: /tmp/RtmpCB1M7h/R.INSTALL2c944a1d5bee/rgdal/man/readGDAL.Rd:136: file link 'flipVertical' in package 'sp' does not exist and so has been treated as a topic
>    readOGR                                 html
>    showWKT                                 html
>    spTransform-methods                     html
>    wrappers                                html
>    writeOGR                                html
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> Error: package or namespace load failed for 'rgdal' in dyn.load(file, DLLpath = DLLpath, ...):
> unable to load shared object '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs/rgdal.so':
>  /home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal/libs/rgdal.so: undefined symbol: pj_ctx_fgets
> Error: loading failed
> Execution halted
> ERROR: loading failed
> * removing '/home/alfielo/R/x86_64-redhat-linux-gnu-library/3.5/rgdal'
>
> The downloaded source packages are in
>     '/tmp/RtmpXrQsj2/downloaded_packages'
> Warning message:
> In install.packages("rgdal") :
>  installation of package 'rgdal' had non-zero exit status
>
> I have tried several solutions but without any success.
>
> Have you any idea about the problem?
>
> Thanks in advance
> David
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From r@hep@rd @ending from @ppl-eco@y@@com  Fri Sep 21 16:02:43 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Fri, 21 Sep 2018 07:02:43 -0700 (PDT)
Subject: [R-sig-Geo] RGDAL installation fail after yum upgrade
In-Reply-To: <8B17ED9FFB25754089C518780EB9916C060FD21B@S-DC-ESTC03-B.net1.cec.eu.int>
References: <8B17ED9FFB25754089C518780EB9916C060FD192@S-DC-ESTC03-B.net1.cec.eu.int>
 <alpine.LFD.2.21.1809211213000.3575@reclus.nhh.no>
 <8B17ED9FFB25754089C518780EB9916C060FD21B@S-DC-ESTC03-B.net1.cec.eu.int>
Message-ID: <alpine.LNX.2.20.1809210656220.23530@salmo.appl-ecosys.com>

On Fri, 21 Sep 2018, David.GIOVANNINI at ext.ec.europa.eu wrote:

> I have checked all the packages (GDAL v1.11.4, PROJ4 v4.9.1) and seems
> that the minimun required version has been satisfied. But on the system I
> have two version of PROJ4, the version v4.8.0 ( /usr/bin/proj ) and the
> version v4.9.1 ( /usr/local/bin/proj ).

David,

   This is the cause of many problems: two different versions of software on
the same host.

> So can I force the use of the new version of PROJ with some parameters
> during the installation of RGDAL?

   Take a look at your $PATH; it's likely that /usr/local/bin/ is checked
before usr/bin/. And different applications using, e.g., proj4, may look for
it in either place. This means that one application finds the 4.9.1 version
while another application finds the 4.8.0 version.

   I recommend that you put all core binaries in /usr/bin (which means moving
4.9.1 from /usr/local/bin/ to /usr/bin/ and keeping in the latter only
software developed locally.

   My network runs Slackware so I don't know how difficult it might be for
you to re-organize your CentOS installations, but making the time to do this
will make life easier for you.

Best regards,

Rich


From Roger@Biv@nd @ending from nhh@no  Fri Sep 21 18:52:06 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 21 Sep 2018 18:52:06 +0200
Subject: [R-sig-Geo] RGDAL installation fail after yum upgrade
In-Reply-To: <alpine.LNX.2.20.1809210656220.23530@salmo.appl-ecosys.com>
References: <8B17ED9FFB25754089C518780EB9916C060FD192@S-DC-ESTC03-B.net1.cec.eu.int>
 <alpine.LFD.2.21.1809211213000.3575@reclus.nhh.no>
 <8B17ED9FFB25754089C518780EB9916C060FD21B@S-DC-ESTC03-B.net1.cec.eu.int>
 <alpine.LNX.2.20.1809210656220.23530@salmo.appl-ecosys.com>
Message-ID: <alpine.LFD.2.21.1809211840020.18456@reclus.nhh.no>

On Fri, 21 Sep 2018, Rich Shepard wrote:

> On Fri, 21 Sep 2018, David.GIOVANNINI at ext.ec.europa.eu wrote:
>
>>  I have checked all the packages (GDAL v1.11.4, PROJ4 v4.9.1) and seems
>>  that the minimun required version has been satisfied. But on the system I
>>  have two version of PROJ4, the version v4.8.0 ( /usr/bin/proj ) and the
>>  version v4.9.1 ( /usr/local/bin/proj ).
>
> David,
>
>  This is the cause of many problems: two different versions of software on
> the same host.
>
>>  So can I force the use of the new version of PROJ with some parameters
>>  during the installation of RGDAL?
>
>  Take a look at your $PATH; it's likely that /usr/local/bin/ is checked
> before usr/bin/. And different applications using, e.g., proj4, may look for
> it in either place. This means that one application finds the 4.9.1 version
> while another application finds the 4.8.0 version.

Rich: thanks - having multiple versions is indeed a challenge on platforms 
where R uses dynamically loaded libraries. On Windows and MacOS, most CRAN 
packages with external dependencies are built with static linking (the 
*old* way). However, executables are on the PATH, but dynamically loaded 
libraries - shared objects - are on LD_LIBRARY_PATH. Try:

echo $LD_LIBRARY_PATH

at the shell prompt, then inside R:

Sys.getenv("LD_LIBRARY_PATH")

and you'll see that R may have made modifications on startup. A typical 
trap is also forgetting to run /sbin/ldconfig -v as root after installing 
software in /usr/local/lib (and adding /usr/local/lib to a file in 
/etc/ld.so.conf.d) so that the shared objects are visible.

The easier route is to have just one version of external software 
installed where R can see it; it is harder but possibly on a cluster 
necessary to modify LD_LIBRARY_PATH locally and consistently. Also look at 
closed sf issues on github; there we stepped back from messing with 
LD_LIBRARY_PATH on a general basis.

Hope this helps,

Roger


>
>  I recommend that you put all core binaries in /usr/bin (which means moving
> 4.9.1 from /usr/local/bin/ to /usr/bin/ and keeping in the latter only
> software developed locally.
>
>  My network runs Slackware so I don't know how difficult it might be for
> you to re-organize your CentOS installations, but making the time to do this
> will make life easier for you.
>
> Best regards,
>
> Rich
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From tech_dev @ending from wildintellect@com  Sat Sep 22 07:22:18 2018
From: tech_dev @ending from wildintellect@com (Alex Mandel)
Date: Fri, 21 Sep 2018 22:22:18 -0700
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <alpine.LFD.2.21.1809210931090.3575@reclus.nhh.no>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
 <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
 <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>
 <alpine.LFD.2.21.1809210931090.3575@reclus.nhh.no>
Message-ID: <b943d635-8c7c-d355-5a3b-7fd4befb2e95@wildintellect.com>

QGIS makes one
https://github.com/qgis/QGIS/blob/master/resources/srs.db
There's some script in the build that updates it also, not without issue:
https://issues.qgis.org/issues/17993

I suppose you could also dump out how PostGIS does it to Sqlite, or use
the Spatialite metadata table.
https://www.gaia-gis.it/gaia-sins/spatialite-cookbook/html/metadata.html

But the thread mentioned that goes back to the MetaCRS mailing list is
probably the right place in the community to revive the discussion.

Seems like something to encourage, and a good topic for an OSGeo
sponsored sprint.

Thanks,
Alex

On 09/21/2018 12:32 AM, Roger Bivand wrote:
> On Thu, 20 Sep 2018, Vijay Lulla wrote:
> 
>> Ok, thanks!? While the page provided information about the project and
>> its
>> funding status I couldn't find the SQLite database.? Do you happen to
>> know
>> when this will be available?
> 
> No more than is on that page, plus the time needed to re-write plenty of
> sf, lwgeom, rgdal and sp. At that stage, contributions welcome!
> 
> Roger
> 
>>
>> On Thu, Sep 20, 2018 at 1:02 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>>>
>>>> Dear list members,
>>>> A few years ago Roger Bivand posted a discussion (
>>>> https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html )
>>>> about
>>>> consolidating SRS definitions into a SQLite database and I am wondering
>>> if
>>>> there has been any development along those lines.
>>>
>>> Rather than trying this just within R, we're hoping that the GDAL
>>> barn-raising effort:
>>>
>>> https://gdalbarn.com/
>>>
>>> will take us there and further, and be much better than having a
>>> non-standard implementation.
>>>
>>> When that effort is done, we'll be open for ideas about interfacing it
>>> through PROJ and GDAL, which now ship with CSV files that we copy into
>>> Windows and MacOS binary packages (rgdal, sf, lwgeom).
>>>
>>> For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file shipped
>>> with PROJ into the R workspace as a data.frame.
>>>
>>> Roger
>>>
>>>> Specifically, is there any consolidated collection of SRS
>>>> definitions in
>>>> R (either a data.frame or tibble or SQLite backed) that are being used
>>>> by geospatial packages that users can use too?? If so, can you please
>>>> point me to it?? If not, would it be worthwhile to have this
>>>> consolidated list/dataframe, maybe as part of data for one of the core
>>>> geospatial packages? Thanks in advance, Vijay
>>>>
>>>> ????? [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>> -- 
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>> http://orcid.org/0000-0003-2392-6140
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>
>>
>>
>>
>


From vij@ylull@ @ending from gm@il@com  Sat Sep 22 14:23:13 2018
From: vij@ylull@ @ending from gm@il@com (Vijay Lulla)
Date: Sat, 22 Sep 2018 08:23:13 -0400
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <b943d635-8c7c-d355-5a3b-7fd4befb2e95@wildintellect.com>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
 <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
 <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>
 <alpine.LFD.2.21.1809210931090.3575@reclus.nhh.no>
 <b943d635-8c7c-d355-5a3b-7fd4befb2e95@wildintellect.com>
Message-ID: <CAKkiGbvJrBAPFo8Nsp1RnLUDP9e_+Wr-k+0vtWxSQvue7DSgsQ@mail.gmail.com>

Alex,
Thanks for QGIS's srs.db!  I wasn't aware of it.

I currently use the spatial_ref_sys from PostGIS to create a SRS data frame
but plan to use rgdal::make_EPSG more often.  The reason I brought this up
is because on the lab computers (cannot install stuff on it) where I teach
there is no PostGIS and I didn't know how to lookup EPSG codes for various
SRS definitions from within R.  I hadn't thought of Spatialite metadata as
a viable alternative.  So, thanks for that.  I will look into it and most
likely use it in conjunction with make_EPSG!

Finally, I am really looking forward to the consolidated SRS database from
the gdal barn-raising effort!  This consolidated database will be
invaluable, and of great aid/service, to the geospatial community, IMO.
Thanks,
Vijay.

On Sat, Sep 22, 2018 at 1:22 AM Alex Mandel <tech_dev at wildintellect.com>
wrote:

> QGIS makes one
> https://github.com/qgis/QGIS/blob/master/resources/srs.db
> There's some script in the build that updates it also, not without issue:
> https://issues.qgis.org/issues/17993
>
> I suppose you could also dump out how PostGIS does it to Sqlite, or use
> the Spatialite metadata table.
> https://www.gaia-gis.it/gaia-sins/spatialite-cookbook/html/metadata.html
>
> But the thread mentioned that goes back to the MetaCRS mailing list is
> probably the right place in the community to revive the discussion.
>
> Seems like something to encourage, and a good topic for an OSGeo
> sponsored sprint.
>
> Thanks,
> Alex
>
> On 09/21/2018 12:32 AM, Roger Bivand wrote:
> > On Thu, 20 Sep 2018, Vijay Lulla wrote:
> >
> >> Ok, thanks!  While the page provided information about the project and
> >> its
> >> funding status I couldn't find the SQLite database.  Do you happen to
> >> know
> >> when this will be available?
> >
> > No more than is on that page, plus the time needed to re-write plenty of
> > sf, lwgeom, rgdal and sp. At that stage, contributions welcome!
> >
> > Roger
> >
> >>
> >> On Thu, Sep 20, 2018 at 1:02 PM Roger Bivand <Roger.Bivand at nhh.no>
> wrote:
> >>
> >>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
> >>>
> >>>> Dear list members,
> >>>> A few years ago Roger Bivand posted a discussion (
> >>>> https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html )
> >>>> about
> >>>> consolidating SRS definitions into a SQLite database and I am
> wondering
> >>> if
> >>>> there has been any development along those lines.
> >>>
> >>> Rather than trying this just within R, we're hoping that the GDAL
> >>> barn-raising effort:
> >>>
> >>> https://gdalbarn.com/
> >>>
> >>> will take us there and further, and be much better than having a
> >>> non-standard implementation.
> >>>
> >>> When that effort is done, we'll be open for ideas about interfacing it
> >>> through PROJ and GDAL, which now ship with CSV files that we copy into
> >>> Windows and MacOS binary packages (rgdal, sf, lwgeom).
> >>>
> >>> For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file
> shipped
> >>> with PROJ into the R workspace as a data.frame.
> >>>
> >>> Roger
> >>>
> >>>> Specifically, is there any consolidated collection of SRS
> >>>> definitions in
> >>>> R (either a data.frame or tibble or SQLite backed) that are being used
> >>>> by geospatial packages that users can use too?  If so, can you please
> >>>> point me to it?  If not, would it be worthwhile to have this
> >>>> consolidated list/dataframe, maybe as part of data for one of the core
> >>>> geospatial packages? Thanks in advance, Vijay
> >>>>
> >>>>       [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-Geo mailing list
> >>>> R-sig-Geo at r-project.org
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>>
> >>>
> >>> --
> >>> Roger Bivand
> >>> Department of Economics, Norwegian School of Economics,
> >>> Helleveien 30, N-5045 Bergen, Norway.
> >>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
> >>> http://orcid.org/0000-0003-2392-6140
> >>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >>>
> >>
> >>
> >>
> >
>
>

-- 
Vijay Lulla

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu
ORCID: https://orcid.org/0000-0002-0823-2522
Webpage: http://vijaylulla.com

	[[alternative HTML version deleted]]


From dhir@jkh@nn@ @ending from gm@il@com  Sat Sep 22 18:21:58 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Sat, 22 Sep 2018 21:51:58 +0530
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CANHhK32ti8_YqbT-etchCM+o88+Thg1ndWkUbmg2XZ3DZ3vVYA@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
 <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
 <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>
 <CANHhK32ti8_YqbT-etchCM+o88+Thg1ndWkUbmg2XZ3DZ3vVYA@mail.gmail.com>
Message-ID: <CANHhK313ZmFUqmvVHqG-T2NgAmoNMLAtVFh8G0MPfnScTez5jA@mail.gmail.com>

@Kent Johnson <kent3737 at gmail.com> guess I jumped the gun!

Your code worked like a charm as long as the colours were all in order, ie,
none of them are repeating.
Like I mentioned, I am working with shipping data and the Color variable is
dependent on the ship?s speed. The code that you provided joins all the
line segments which have the same color.
So if red represents a speed less than 3 knots, then it will join all the
points irrespective of the timeline wherever the color is red.

What I am looking for is one continuous path where the same color might
repeat. Here?s a reproducible example:

library(leaflet)
x <- structure(list(lat = c(51.88783, 51.8878441, 51.887825, 51.88659,
 51.8866959, 51.8874931, 51.89359, 51.8941269, 51.8977051, 51.8994331,
 51.90773, 51.91324, 51.91604, 51.9216652, 51.93353, 51.9419365 ),
                     lon = c(4.28763342, 4.287635, 4.28765154,
4.29007339, 4.29562664,  4.29917, 4.30641174, 4.30561829, 4.29263353,
4.284498, 4.261132,  4.24711847, 4.241075, 4.23262, 4.21523666,
4.1927),
                     rateOfTurn = c(0L,  0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
                     sogKts = c(0, 0, 0, 2.1, 3.4, 4.6, 3.5, 3.8, 7.4,
7.9, 8.8,9.1, 9.2, 9.2, 0.3, 0.4),
                     cog = c(15, 15, 15, 122.2, 70.4,      70, 323.2,
315.3, 289.3, 290.9, 303.8, 303.7, 308.9, 324.5, 304.9, 301.4),
                     heading = c(163, 162, 163, 106, 71, 71, 303,
298, 289, 294, 303, 303, 310, 324, 304, 302),
                     timestamp =
c("2018-07-19T05:27:34","2018-07-19T05:39:35", "2018-07-19T05:45:34",
"2018-07-19T05:57:37",
                                   "2018-07-19T06:02:48",
"2018-07-19T06:04:49", "2018-07-19T06:12:51", "2018-07-19T06:13:32",
                                   "2018-07-19T06:19:08",
"2018-07-19T06:21:41",      "2018-07-19T06:28:42",
"2018-07-19T06:32:50",
                                   "2018-07-19T06:34:37",
"2018-07-19T06:37:41", "2018-07-19T06:43:49", "2018-07-19T06:50:09"),
                     Color = c("red", "red", "red", "red", "orange",
"orange","orange", "orange", "orange", "orange", "yellow", "yellow",
                               "yellow", "yellow", "red", "red")),
row.names = 32:47, class = "data.frame")

#Kent's code

x$lastColor = dplyr::lag(x$Color)
map <-  leaflet(x)
map <- addTiles(map)
for( Color in
     levels(as.factor(x$Color))){
  map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
x$lastColor==Color,], color=~Color) }
map

As you can see, the last two observations are again in red color. But when
the map renders, it joins the last two observations with the first three.

I am not sure what to do here? Inserting a row of NAs would help? But I am
also using another javascript plugin (polylineDecorator) for adding arrows
to the direction of travel and that is intolerant to NAs.
Appreciate some help here.


Regards
Dhiraj Khanna
Mob:09873263331

On Sat, Sep 1, 2018 at 8:06 PM Dhiraj Khanna <dhirajkhanna at gmail.com> wrote:

> Thank you Kent, that worked like a charm!
> Regards
>
> Dhiraj Khanna
> Mob:09873263331
>
>
> On Sat, Sep 1, 2018 at 7:59 PM Kent Johnson <kent3737 at gmail.com> wrote:
>
>> You have to include the points where the colors change in both polylines.
>> Here is one way:
>>
>> x$lastColor = dplyr::lag(x$Color)
>> map <-  leaflet(x)
>> map <- addTiles(map)
>> for( Color in
>> levels(as.factor(x$Color))){
>>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
>> x$lastColor==Color,], color=~Color) }
>> map
>>
>> Kent
>>
>> On Sat, Sep 1, 2018 at 8:56 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
>> wrote:
>>
>>> @Kent they are appearing as three separate lines. I am hoping to see
>>> them joint with no gaps. The transition from row 4 to row 5 is where the
>>> speed has changed from 2.1 knots to 3.4 knots. I am hoping to see another
>>> line from row 4 to row 5 in red colour. Similarly for the other disjoint
>>> points.
>>> Regards
>>>
>>> Dhiraj Khanna
>>> Mob:09873263331
>>>
>>>
>>> On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com> wrote:
>>>
>>>> Message: 5
>>>>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>>>>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>>> To: r-sig-geo at r-project.org
>>>>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>>>>> Message-ID:
>>>>>         <
>>>>> CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ at mail.gmail.com>
>>>>> Content-Type: text/plain; charset="utf-8"
>>>>>
>>>>> I am working with shipping data where I get the dynamic parameters of a
>>>>> ship like its position, speed, heading and rate of turn. I am then
>>>>> trying
>>>>> to plot this on a leaflet map and trying to colour the polylines based
>>>>> on
>>>>> the speed, but it always shows up in the same colour. Here?s some
>>>>> sample
>>>>> data:
>>>>>
>>>>> <snip>
>>>>> This is the code I have tried which doesn?t work:-
>>>>>
>>>>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>>>>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>>>>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>>>>
>>>>> Regards
>>>>> Dhiraj Khanna
>>>>> Mob:09873263331
>>>>
>>>>
>>>> What are you expecting to see? When I run your code I get a map with
>>>> three lines, one red, one orange and one yellow.
>>>>
>>>> Kent
>>>>
>>>>
>>

	[[alternative HTML version deleted]]


From tech_dev @ending from wildintellect@com  Sat Sep 22 19:08:58 2018
From: tech_dev @ending from wildintellect@com (Alex Mandel)
Date: Sat, 22 Sep 2018 10:08:58 -0700
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <CAKkiGbvJrBAPFo8Nsp1RnLUDP9e_+Wr-k+0vtWxSQvue7DSgsQ@mail.gmail.com>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
 <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
 <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>
 <alpine.LFD.2.21.1809210931090.3575@reclus.nhh.no>
 <b943d635-8c7c-d355-5a3b-7fd4befb2e95@wildintellect.com>
 <CAKkiGbvJrBAPFo8Nsp1RnLUDP9e_+Wr-k+0vtWxSQvue7DSgsQ@mail.gmail.com>
Message-ID: <0abef0fd-b4b2-bd13-7afa-aaf9db238776@wildintellect.com>

Though it requires Internet what about hitting the epsg.io API described
on https://github.com/klokantech/epsg.io

Thanks,
Alex

On 09/22/2018 05:23 AM, Vijay Lulla wrote:
> Alex,
> Thanks for QGIS's srs.db!  I wasn't aware of it.
> 
> I currently use the spatial_ref_sys from PostGIS to create a SRS data frame
> but plan to use rgdal::make_EPSG more often.  The reason I brought this up
> is because on the lab computers (cannot install stuff on it) where I teach
> there is no PostGIS and I didn't know how to lookup EPSG codes for various
> SRS definitions from within R.  I hadn't thought of Spatialite metadata as
> a viable alternative.  So, thanks for that.  I will look into it and most
> likely use it in conjunction with make_EPSG!
> 
> Finally, I am really looking forward to the consolidated SRS database from
> the gdal barn-raising effort!  This consolidated database will be
> invaluable, and of great aid/service, to the geospatial community, IMO.
> Thanks,
> Vijay.
> 
> On Sat, Sep 22, 2018 at 1:22 AM Alex Mandel <tech_dev at wildintellect.com>
> wrote:
> 
>> QGIS makes one
>> https://github.com/qgis/QGIS/blob/master/resources/srs.db
>> There's some script in the build that updates it also, not without issue:
>> https://issues.qgis.org/issues/17993
>>
>> I suppose you could also dump out how PostGIS does it to Sqlite, or use
>> the Spatialite metadata table.
>> https://www.gaia-gis.it/gaia-sins/spatialite-cookbook/html/metadata.html
>>
>> But the thread mentioned that goes back to the MetaCRS mailing list is
>> probably the right place in the community to revive the discussion.
>>
>> Seems like something to encourage, and a good topic for an OSGeo
>> sponsored sprint.
>>
>> Thanks,
>> Alex
>>
>> On 09/21/2018 12:32 AM, Roger Bivand wrote:
>>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>>>
>>>> Ok, thanks!  While the page provided information about the project and
>>>> its
>>>> funding status I couldn't find the SQLite database.  Do you happen to
>>>> know
>>>> when this will be available?
>>>
>>> No more than is on that page, plus the time needed to re-write plenty of
>>> sf, lwgeom, rgdal and sp. At that stage, contributions welcome!
>>>
>>> Roger
>>>
>>>>
>>>> On Thu, Sep 20, 2018 at 1:02 PM Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>>>
>>>>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>>>>>
>>>>>> Dear list members,
>>>>>> A few years ago Roger Bivand posted a discussion (
>>>>>> https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html )
>>>>>> about
>>>>>> consolidating SRS definitions into a SQLite database and I am
>> wondering
>>>>> if
>>>>>> there has been any development along those lines.
>>>>>
>>>>> Rather than trying this just within R, we're hoping that the GDAL
>>>>> barn-raising effort:
>>>>>
>>>>> https://gdalbarn.com/
>>>>>
>>>>> will take us there and further, and be much better than having a
>>>>> non-standard implementation.
>>>>>
>>>>> When that effort is done, we'll be open for ideas about interfacing it
>>>>> through PROJ and GDAL, which now ship with CSV files that we copy into
>>>>> Windows and MacOS binary packages (rgdal, sf, lwgeom).
>>>>>
>>>>> For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file
>> shipped
>>>>> with PROJ into the R workspace as a data.frame.
>>>>>
>>>>> Roger
>>>>>
>>>>>> Specifically, is there any consolidated collection of SRS
>>>>>> definitions in
>>>>>> R (either a data.frame or tibble or SQLite backed) that are being used
>>>>>> by geospatial packages that users can use too?  If so, can you please
>>>>>> point me to it?  If not, would it be worthwhile to have this
>>>>>> consolidated list/dataframe, maybe as part of data for one of the core
>>>>>> geospatial packages? Thanks in advance, Vijay
>>>>>>
>>>>>>       [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>>> http://orcid.org/0000-0003-2392-6140
>>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>>
>>>>
>>>>
>>>>
>>>
>>
>>
>


From kent3737 @ending from gm@il@com  Sat Sep 22 20:00:43 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Sat, 22 Sep 2018 14:00:43 -0400
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CANHhK313ZmFUqmvVHqG-T2NgAmoNMLAtVFh8G0MPfnScTez5jA@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
 <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
 <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>
 <CANHhK32ti8_YqbT-etchCM+o88+Thg1ndWkUbmg2XZ3DZ3vVYA@mail.gmail.com>
 <CANHhK313ZmFUqmvVHqG-T2NgAmoNMLAtVFh8G0MPfnScTez5jA@mail.gmail.com>
Message-ID: <CAPP0wyjbPoWhc0cLtkJhrqurOKaMKTw5ZC4TUqnzC6KNGLMotw@mail.gmail.com>

Your problem is not really a leaflet problem, it is about identifying runs
in your data. This should help: https://stackoverflow.com/q/43875716/80626

Kent

On Sat, Sep 22, 2018 at 12:22 PM Dhiraj Khanna <dhirajkhanna at gmail.com>
wrote:

> @Kent Johnson <kent3737 at gmail.com> guess I jumped the gun!
>
> Your code worked like a charm as long as the colours were all in order,
> ie, none of them are repeating.
> Like I mentioned, I am working with shipping data and the Color variable
> is dependent on the ship?s speed. The code that you provided joins all the
> line segments which have the same color.
> So if red represents a speed less than 3 knots, then it will join all the
> points irrespective of the timeline wherever the color is red.
>
> What I am looking for is one continuous path where the same color might
> repeat. Here?s a reproducible example:
>
> library(leaflet)
> x <- structure(list(lat = c(51.88783, 51.8878441, 51.887825, 51.88659,  51.8866959, 51.8874931, 51.89359, 51.8941269, 51.8977051, 51.8994331,  51.90773, 51.91324, 51.91604, 51.9216652, 51.93353, 51.9419365 ),
>                      lon = c(4.28763342, 4.287635, 4.28765154, 4.29007339, 4.29562664,  4.29917, 4.30641174, 4.30561829, 4.29263353, 4.284498, 4.261132,  4.24711847, 4.241075, 4.23262, 4.21523666, 4.1927),
>                      rateOfTurn = c(0L,  0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
>                      sogKts = c(0, 0, 0, 2.1, 3.4, 4.6, 3.5, 3.8, 7.4, 7.9, 8.8,9.1, 9.2, 9.2, 0.3, 0.4),
>                      cog = c(15, 15, 15, 122.2, 70.4,      70, 323.2, 315.3, 289.3, 290.9, 303.8, 303.7, 308.9, 324.5, 304.9, 301.4),
>                      heading = c(163, 162, 163, 106, 71, 71, 303,      298, 289, 294, 303, 303, 310, 324, 304, 302),
>                      timestamp = c("2018-07-19T05:27:34","2018-07-19T05:39:35", "2018-07-19T05:45:34", "2018-07-19T05:57:37",
>                                    "2018-07-19T06:02:48", "2018-07-19T06:04:49", "2018-07-19T06:12:51", "2018-07-19T06:13:32",
>                                    "2018-07-19T06:19:08", "2018-07-19T06:21:41",      "2018-07-19T06:28:42", "2018-07-19T06:32:50",
>                                    "2018-07-19T06:34:37",      "2018-07-19T06:37:41", "2018-07-19T06:43:49", "2018-07-19T06:50:09"),
>                      Color = c("red", "red", "red", "red", "orange", "orange","orange", "orange", "orange", "orange", "yellow", "yellow",
>                                "yellow", "yellow", "red", "red")), row.names = 32:47, class = "data.frame")
>
> #Kent's code
>
> x$lastColor = dplyr::lag(x$Color)
> map <-  leaflet(x)
> map <- addTiles(map)
> for( Color in
>      levels(as.factor(x$Color))){
>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color | x$lastColor==Color,], color=~Color) }
> map
>
> As you can see, the last two observations are again in red color. But when
> the map renders, it joins the last two observations with the first three.
>
> I am not sure what to do here? Inserting a row of NAs would help? But I am
> also using another javascript plugin (polylineDecorator) for adding
> arrows to the direction of travel and that is intolerant to NAs.
> Appreciate some help here.
>
>
> Regards
> Dhiraj Khanna
> Mob:09873263331
>
> On Sat, Sep 1, 2018 at 8:06 PM Dhiraj Khanna <dhirajkhanna at gmail.com>
> wrote:
>
>> Thank you Kent, that worked like a charm!
>> Regards
>>
>> Dhiraj Khanna
>> Mob:09873263331
>>
>>
>> On Sat, Sep 1, 2018 at 7:59 PM Kent Johnson <kent3737 at gmail.com> wrote:
>>
>>> You have to include the points where the colors change in both
>>> polylines. Here is one way:
>>>
>>> x$lastColor = dplyr::lag(x$Color)
>>> map <-  leaflet(x)
>>> map <- addTiles(map)
>>> for( Color in
>>> levels(as.factor(x$Color))){
>>>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
>>> x$lastColor==Color,], color=~Color) }
>>> map
>>>
>>> Kent
>>>
>>> On Sat, Sep 1, 2018 at 8:56 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
>>> wrote:
>>>
>>>> @Kent they are appearing as three separate lines. I am hoping to see
>>>> them joint with no gaps. The transition from row 4 to row 5 is where the
>>>> speed has changed from 2.1 knots to 3.4 knots. I am hoping to see another
>>>> line from row 4 to row 5 in red colour. Similarly for the other disjoint
>>>> points.
>>>> Regards
>>>>
>>>> Dhiraj Khanna
>>>> Mob:09873263331
>>>>
>>>>
>>>> On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com> wrote:
>>>>
>>>>> Message: 5
>>>>>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>>>>>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>>>> To: r-sig-geo at r-project.org
>>>>>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>>>>>> Message-ID:
>>>>>>         <
>>>>>> CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ at mail.gmail.com>
>>>>>> Content-Type: text/plain; charset="utf-8"
>>>>>>
>>>>>> I am working with shipping data where I get the dynamic parameters of
>>>>>> a
>>>>>> ship like its position, speed, heading and rate of turn. I am then
>>>>>> trying
>>>>>> to plot this on a leaflet map and trying to colour the polylines
>>>>>> based on
>>>>>> the speed, but it always shows up in the same colour. Here?s some
>>>>>> sample
>>>>>> data:
>>>>>>
>>>>>> <snip>
>>>>>> This is the code I have tried which doesn?t work:-
>>>>>>
>>>>>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>>>>>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>>>>>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>>>>>
>>>>>> Regards
>>>>>> Dhiraj Khanna
>>>>>> Mob:09873263331
>>>>>
>>>>>
>>>>> What are you expecting to see? When I run your code I get a map with
>>>>> three lines, one red, one orange and one yellow.
>>>>>
>>>>> Kent
>>>>>
>>>>>
>>>

	[[alternative HTML version deleted]]


From kent3737 @ending from gm@il@com  Sun Sep 23 15:42:19 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Sun, 23 Sep 2018 09:42:19 -0400
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CAPP0wyjbPoWhc0cLtkJhrqurOKaMKTw5ZC4TUqnzC6KNGLMotw@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
 <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
 <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>
 <CANHhK32ti8_YqbT-etchCM+o88+Thg1ndWkUbmg2XZ3DZ3vVYA@mail.gmail.com>
 <CANHhK313ZmFUqmvVHqG-T2NgAmoNMLAtVFh8G0MPfnScTez5jA@mail.gmail.com>
 <CAPP0wyjbPoWhc0cLtkJhrqurOKaMKTw5ZC4TUqnzC6KNGLMotw@mail.gmail.com>
Message-ID: <CAPP0wyj6oH-T=y2L1kTnBryyQpnu9XtHtXOpNuLg13trMcuhRw@mail.gmail.com>

Another approach is to draw individual line segments instead of polylines.
Here is one way; maybe there is a more elegant way to construct the
segments but this works...

library(tidyverse)
library(sf)
x = x %>% mutate(lat2=lead(lat, default=tail(lat, 1)),
                 lon2=lead(lon, default=tail(lon, 1))) %>%
  mutate(segment = st_sfc(crs=4326,
              pmap(.,
                 function(lat, lon, lat2, lon2, ...)
                   st_linestring(matrix(c(lon, lat, lon2, lat2),
                                        byrow=TRUE, ncol=2)))))

leaflet(x$segment) %>%
  addTiles() %>%
  addPolylines(color=x$Color)

Kent

On Sat, Sep 22, 2018 at 2:00 PM Kent Johnson <kent3737 at gmail.com> wrote:

> Your problem is not really a leaflet problem, it is about identifying runs
> in your data. This should help: https://stackoverflow.com/q/43875716/80626
>
> Kent
>
> On Sat, Sep 22, 2018 at 12:22 PM Dhiraj Khanna <dhirajkhanna at gmail.com>
> wrote:
>
>> @Kent Johnson <kent3737 at gmail.com> guess I jumped the gun!
>>
>> Your code worked like a charm as long as the colours were all in order,
>> ie, none of them are repeating.
>> Like I mentioned, I am working with shipping data and the Color variable
>> is dependent on the ship?s speed. The code that you provided joins all the
>> line segments which have the same color.
>> So if red represents a speed less than 3 knots, then it will join all the
>> points irrespective of the timeline wherever the color is red.
>>
>> What I am looking for is one continuous path where the same color might
>> repeat. Here?s a reproducible example:
>>
>> library(leaflet)
>> x <- structure(list(lat = c(51.88783, 51.8878441, 51.887825, 51.88659,  51.8866959, 51.8874931, 51.89359, 51.8941269, 51.8977051, 51.8994331,  51.90773, 51.91324, 51.91604, 51.9216652, 51.93353, 51.9419365 ),
>>                      lon = c(4.28763342, 4.287635, 4.28765154, 4.29007339, 4.29562664,  4.29917, 4.30641174, 4.30561829, 4.29263353, 4.284498, 4.261132,  4.24711847, 4.241075, 4.23262, 4.21523666, 4.1927),
>>                      rateOfTurn = c(0L,  0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
>>                      sogKts = c(0, 0, 0, 2.1, 3.4, 4.6, 3.5, 3.8, 7.4, 7.9, 8.8,9.1, 9.2, 9.2, 0.3, 0.4),
>>                      cog = c(15, 15, 15, 122.2, 70.4,      70, 323.2, 315.3, 289.3, 290.9, 303.8, 303.7, 308.9, 324.5, 304.9, 301.4),
>>                      heading = c(163, 162, 163, 106, 71, 71, 303,      298, 289, 294, 303, 303, 310, 324, 304, 302),
>>                      timestamp = c("2018-07-19T05:27:34","2018-07-19T05:39:35", "2018-07-19T05:45:34", "2018-07-19T05:57:37",
>>                                    "2018-07-19T06:02:48", "2018-07-19T06:04:49", "2018-07-19T06:12:51", "2018-07-19T06:13:32",
>>                                    "2018-07-19T06:19:08", "2018-07-19T06:21:41",      "2018-07-19T06:28:42", "2018-07-19T06:32:50",
>>                                    "2018-07-19T06:34:37",      "2018-07-19T06:37:41", "2018-07-19T06:43:49", "2018-07-19T06:50:09"),
>>                      Color = c("red", "red", "red", "red", "orange", "orange","orange", "orange", "orange", "orange", "yellow", "yellow",
>>                                "yellow", "yellow", "red", "red")), row.names = 32:47, class = "data.frame")
>>
>> #Kent's code
>>
>> x$lastColor = dplyr::lag(x$Color)
>> map <-  leaflet(x)
>> map <- addTiles(map)
>> for( Color in
>>      levels(as.factor(x$Color))){
>>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color | x$lastColor==Color,], color=~Color) }
>> map
>>
>> As you can see, the last two observations are again in red color. But
>> when the map renders, it joins the last two observations with the first
>> three.
>>
>> I am not sure what to do here? Inserting a row of NAs would help? But I
>> am also using another javascript plugin (polylineDecorator) for adding
>> arrows to the direction of travel and that is intolerant to NAs.
>> Appreciate some help here.
>>
>>
>> Regards
>> Dhiraj Khanna
>> Mob:09873263331
>>
>> On Sat, Sep 1, 2018 at 8:06 PM Dhiraj Khanna <dhirajkhanna at gmail.com>
>> wrote:
>>
>>> Thank you Kent, that worked like a charm!
>>> Regards
>>>
>>> Dhiraj Khanna
>>> Mob:09873263331
>>>
>>>
>>> On Sat, Sep 1, 2018 at 7:59 PM Kent Johnson <kent3737 at gmail.com> wrote:
>>>
>>>> You have to include the points where the colors change in both
>>>> polylines. Here is one way:
>>>>
>>>> x$lastColor = dplyr::lag(x$Color)
>>>> map <-  leaflet(x)
>>>> map <- addTiles(map)
>>>> for( Color in
>>>> levels(as.factor(x$Color))){
>>>>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
>>>> x$lastColor==Color,], color=~Color) }
>>>> map
>>>>
>>>> Kent
>>>>
>>>> On Sat, Sep 1, 2018 at 8:56 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>> wrote:
>>>>
>>>>> @Kent they are appearing as three separate lines. I am hoping to see
>>>>> them joint with no gaps. The transition from row 4 to row 5 is where the
>>>>> speed has changed from 2.1 knots to 3.4 knots. I am hoping to see another
>>>>> line from row 4 to row 5 in red colour. Similarly for the other disjoint
>>>>> points.
>>>>> Regards
>>>>>
>>>>> Dhiraj Khanna
>>>>> Mob:09873263331
>>>>>
>>>>>
>>>>> On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Message: 5
>>>>>>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>>>>>>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>>>>> To: r-sig-geo at r-project.org
>>>>>>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>>>>>>> Message-ID:
>>>>>>>         <
>>>>>>> CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ at mail.gmail.com>
>>>>>>> Content-Type: text/plain; charset="utf-8"
>>>>>>>
>>>>>>> I am working with shipping data where I get the dynamic parameters
>>>>>>> of a
>>>>>>> ship like its position, speed, heading and rate of turn. I am then
>>>>>>> trying
>>>>>>> to plot this on a leaflet map and trying to colour the polylines
>>>>>>> based on
>>>>>>> the speed, but it always shows up in the same colour. Here?s some
>>>>>>> sample
>>>>>>> data:
>>>>>>>
>>>>>>> <snip>
>>>>>>> This is the code I have tried which doesn?t work:-
>>>>>>>
>>>>>>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>>>>>>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>>>>>>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>>>>>>
>>>>>>> Regards
>>>>>>> Dhiraj Khanna
>>>>>>> Mob:09873263331
>>>>>>
>>>>>>
>>>>>> What are you expecting to see? When I run your code I get a map with
>>>>>> three lines, one red, one orange and one yellow.
>>>>>>
>>>>>> Kent
>>>>>>
>>>>>>
>>>>

	[[alternative HTML version deleted]]


From dhir@jkh@nn@ @ending from gm@il@com  Tue Sep 25 07:50:19 2018
From: dhir@jkh@nn@ @ending from gm@il@com (Dhiraj Khanna)
Date: Tue, 25 Sep 2018 11:20:19 +0530
Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
In-Reply-To: <CAPP0wyj6oH-T=y2L1kTnBryyQpnu9XtHtXOpNuLg13trMcuhRw@mail.gmail.com>
References: <CAPP0wyi19s2iNdk_ycd=+toFKu9EkLxetVpDwRj+r__r8P8cdQ@mail.gmail.com>
 <CANHhK31q05Ccq9JAL=Ls4UzitmbUibP-Mh4vbvdkKnC=otWmbg@mail.gmail.com>
 <CAPP0wyi6ZsU01pPmsQvvi06gRkhLPossYxyftybgYJOH2WDpRA@mail.gmail.com>
 <CANHhK32ti8_YqbT-etchCM+o88+Thg1ndWkUbmg2XZ3DZ3vVYA@mail.gmail.com>
 <CANHhK313ZmFUqmvVHqG-T2NgAmoNMLAtVFh8G0MPfnScTez5jA@mail.gmail.com>
 <CAPP0wyjbPoWhc0cLtkJhrqurOKaMKTw5ZC4TUqnzC6KNGLMotw@mail.gmail.com>
 <CAPP0wyj6oH-T=y2L1kTnBryyQpnu9XtHtXOpNuLg13trMcuhRw@mail.gmail.com>
Message-ID: <CANHhK32NNzPtceAVbc7hRMXmmQGXsLG8ZcFZZ+Q6a_Gj_msk0A@mail.gmail.com>

@Kent Johnson <kent3737 at gmail.com> thank you so much for this. It does take
a bit of time to compute, but works nonetheless. Thanks again, appreciate!
Regards

Dhiraj Khanna
Mob:09873263331


On Sun, Sep 23, 2018 at 7:12 PM Kent Johnson <kent3737 at gmail.com> wrote:

> Another approach is to draw individual line segments instead of polylines.
> Here is one way; maybe there is a more elegant way to construct the
> segments but this works...
>
> library(tidyverse)
> library(sf)
> x = x %>% mutate(lat2=lead(lat, default=tail(lat, 1)),
>                  lon2=lead(lon, default=tail(lon, 1))) %>%
>   mutate(segment = st_sfc(crs=4326,
>               pmap(.,
>                  function(lat, lon, lat2, lon2, ...)
>                    st_linestring(matrix(c(lon, lat, lon2, lat2),
>                                         byrow=TRUE, ncol=2)))))
>
> leaflet(x$segment) %>%
>   addTiles() %>%
>   addPolylines(color=x$Color)
>
> Kent
>
> On Sat, Sep 22, 2018 at 2:00 PM Kent Johnson <kent3737 at gmail.com> wrote:
>
>> Your problem is not really a leaflet problem, it is about identifying
>> runs in your data. This should help:
>> https://stackoverflow.com/q/43875716/80626
>>
>> Kent
>>
>> On Sat, Sep 22, 2018 at 12:22 PM Dhiraj Khanna <dhirajkhanna at gmail.com>
>> wrote:
>>
>>> @Kent Johnson <kent3737 at gmail.com> guess I jumped the gun!
>>>
>>> Your code worked like a charm as long as the colours were all in order,
>>> ie, none of them are repeating.
>>> Like I mentioned, I am working with shipping data and the Color
>>> variable is dependent on the ship?s speed. The code that you provided joins
>>> all the line segments which have the same color.
>>> So if red represents a speed less than 3 knots, then it will join all
>>> the points irrespective of the timeline wherever the color is red.
>>>
>>> What I am looking for is one continuous path where the same color might
>>> repeat. Here?s a reproducible example:
>>>
>>> library(leaflet)
>>> x <- structure(list(lat = c(51.88783, 51.8878441, 51.887825, 51.88659,  51.8866959, 51.8874931, 51.89359, 51.8941269, 51.8977051, 51.8994331,  51.90773, 51.91324, 51.91604, 51.9216652, 51.93353, 51.9419365 ),
>>>                      lon = c(4.28763342, 4.287635, 4.28765154, 4.29007339, 4.29562664,  4.29917, 4.30641174, 4.30561829, 4.29263353, 4.284498, 4.261132,  4.24711847, 4.241075, 4.23262, 4.21523666, 4.1927),
>>>                      rateOfTurn = c(0L,  0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L),
>>>                      sogKts = c(0, 0, 0, 2.1, 3.4, 4.6, 3.5, 3.8, 7.4, 7.9, 8.8,9.1, 9.2, 9.2, 0.3, 0.4),
>>>                      cog = c(15, 15, 15, 122.2, 70.4,      70, 323.2, 315.3, 289.3, 290.9, 303.8, 303.7, 308.9, 324.5, 304.9, 301.4),
>>>                      heading = c(163, 162, 163, 106, 71, 71, 303,      298, 289, 294, 303, 303, 310, 324, 304, 302),
>>>                      timestamp = c("2018-07-19T05:27:34","2018-07-19T05:39:35", "2018-07-19T05:45:34", "2018-07-19T05:57:37",
>>>                                    "2018-07-19T06:02:48", "2018-07-19T06:04:49", "2018-07-19T06:12:51", "2018-07-19T06:13:32",
>>>                                    "2018-07-19T06:19:08", "2018-07-19T06:21:41",      "2018-07-19T06:28:42", "2018-07-19T06:32:50",
>>>                                    "2018-07-19T06:34:37",      "2018-07-19T06:37:41", "2018-07-19T06:43:49", "2018-07-19T06:50:09"),
>>>                      Color = c("red", "red", "red", "red", "orange", "orange","orange", "orange", "orange", "orange", "yellow", "yellow",
>>>                                "yellow", "yellow", "red", "red")), row.names = 32:47, class = "data.frame")
>>>
>>> #Kent's code
>>>
>>> x$lastColor = dplyr::lag(x$Color)
>>> map <-  leaflet(x)
>>> map <- addTiles(map)
>>> for( Color in
>>>      levels(as.factor(x$Color))){
>>>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color | x$lastColor==Color,], color=~Color) }
>>> map
>>>
>>> As you can see, the last two observations are again in red color. But
>>> when the map renders, it joins the last two observations with the first
>>> three.
>>>
>>> I am not sure what to do here? Inserting a row of NAs would help? But I
>>> am also using another javascript plugin (polylineDecorator) for adding
>>> arrows to the direction of travel and that is intolerant to NAs.
>>> Appreciate some help here.
>>>
>>>
>>> Regards
>>> Dhiraj Khanna
>>> Mob:09873263331
>>>
>>> On Sat, Sep 1, 2018 at 8:06 PM Dhiraj Khanna <dhirajkhanna at gmail.com>
>>> wrote:
>>>
>>>> Thank you Kent, that worked like a charm!
>>>> Regards
>>>>
>>>> Dhiraj Khanna
>>>> Mob:09873263331
>>>>
>>>>
>>>> On Sat, Sep 1, 2018 at 7:59 PM Kent Johnson <kent3737 at gmail.com> wrote:
>>>>
>>>>> You have to include the points where the colors change in both
>>>>> polylines. Here is one way:
>>>>>
>>>>> x$lastColor = dplyr::lag(x$Color)
>>>>> map <-  leaflet(x)
>>>>> map <- addTiles(map)
>>>>> for( Color in
>>>>> levels(as.factor(x$Color))){
>>>>>   map <- addPolylines(map,lng=~lon,lat=~lat,data=x[x$Color==Color |
>>>>> x$lastColor==Color,], color=~Color) }
>>>>> map
>>>>>
>>>>> Kent
>>>>>
>>>>> On Sat, Sep 1, 2018 at 8:56 AM, Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> @Kent they are appearing as three separate lines. I am hoping to see
>>>>>> them joint with no gaps. The transition from row 4 to row 5 is where the
>>>>>> speed has changed from 2.1 knots to 3.4 knots. I am hoping to see another
>>>>>> line from row 4 to row 5 in red colour. Similarly for the other disjoint
>>>>>> points.
>>>>>> Regards
>>>>>>
>>>>>> Dhiraj Khanna
>>>>>> Mob:09873263331
>>>>>>
>>>>>>
>>>>>> On Sat, Sep 1, 2018 at 6:17 PM Kent Johnson <kent3737 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Message: 5
>>>>>>>> Date: Sat, 1 Sep 2018 08:28:24 +0530
>>>>>>>> From: Dhiraj Khanna <dhirajkhanna at gmail.com>
>>>>>>>> To: r-sig-geo at r-project.org
>>>>>>>> Subject: [R-sig-Geo] Adding colour to polylines in Leaflet
>>>>>>>> Message-ID:
>>>>>>>>         <
>>>>>>>> CANHhK329-Y7hPJD9gSOs24mSqGkrjC481oQspNAgVisAw2JBoQ at mail.gmail.com>
>>>>>>>> Content-Type: text/plain; charset="utf-8"
>>>>>>>>
>>>>>>>> I am working with shipping data where I get the dynamic parameters
>>>>>>>> of a
>>>>>>>> ship like its position, speed, heading and rate of turn. I am then
>>>>>>>> trying
>>>>>>>> to plot this on a leaflet map and trying to colour the polylines
>>>>>>>> based on
>>>>>>>> the speed, but it always shows up in the same colour. Here?s some
>>>>>>>> sample
>>>>>>>> data:
>>>>>>>>
>>>>>>>> <snip>
>>>>>>>> This is the code I have tried which doesn?t work:-
>>>>>>>>
>>>>>>>> map <-  leaflet(x) map <- addTiles(map) for( Color in
>>>>>>>> levels(as.factor(x$Color))){   map <- addPolylines(map,
>>>>>>>> lng=~lon,lat=~lat,data=x[x$Color==Color,], color=~Color) } map
>>>>>>>>
>>>>>>>> Regards
>>>>>>>> Dhiraj Khanna
>>>>>>>> Mob:09873263331
>>>>>>>
>>>>>>>
>>>>>>> What are you expecting to see? When I run your code I get a map with
>>>>>>> three lines, one red, one orange and one yellow.
>>>>>>>
>>>>>>> Kent
>>>>>>>
>>>>>>>
>>>>>

	[[alternative HTML version deleted]]


From @lex@ndre@@nto@br @ending from y@hoo@com@br  Wed Sep 26 03:49:16 2018
From: @lex@ndre@@nto@br @ending from y@hoo@com@br (ASANTOS)
Date: Tue, 25 Sep 2018 21:49:16 -0400
Subject: [R-sig-Geo] Identify hotspots (centroid/geometric center when CSR
 distance is not satisfied) using K-Ripley approach
Message-ID: <169a915e-8ec4-455d-5fd0-d63a3c6682f9@yahoo.com.br>

Dear R-sig-geo Members,

 ??? ??? I've like to identify hotspots points (centroid/geometric 
center of distances(r) when CSR is not satisfied), in my study case, 
centroids with points around 0.75 radius. This thinking in the map 
representation, for this objective I make:

#Package
library(spatstat)
library(sp)
library(cluster)
library(lattice)

#Swedishpines's data set in spatstat package
data(swedishpines)
plot(swedishpines)

#CSR with K-Ripley test
csr_pines <- envelope(swedishpines, Kest, nsim=99)
plot(csr_pines)
# r=0.75 is outside CSR assumption, than:

##Create matrix distance of all points
coords<-cbind(swedishpines$x,swedishpines$y)
res<-spDists(coords)
res <- data.frame(res)

# Cluster 0.75m distances
clusters <- as.hclust(agnes(res, diss = T))
coords$group <- cutree(clusters, h=0.75) ## Radius 0.75
#

#Visualization of centroids with points around 0.75 radius
xyplot(x~y, group = group, data = coords)
points(swedishpines$x,swedishpines$y, pch=16)
#

Doesn't work, please any ideas or new approaches?

Thanks in advanced,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/


From erinm@hodge@@ @ending from gm@il@com  Wed Sep 26 05:02:45 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Tue, 25 Sep 2018 21:02:45 -0600
Subject: [R-sig-Geo] spatial temporal data
Message-ID: <CACxE24mDc2aAVYEtcrrq6z=qCChTJFOYSrD-a345kj+gC9-t4A@mail.gmail.com>

Hello everyone:

Could someone recommend a good source for spatial temporal data from the
"real world", please?

I have been using the Irish wind data for something that I'm working on,
and would like to have a nice data set for extra practice.

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From te@3rd @ending from gm@il@com  Wed Sep 26 07:25:58 2018
From: te@3rd @ending from gm@il@com (Thomas Adams)
Date: Wed, 26 Sep 2018 01:25:58 -0400
Subject: [R-sig-Geo] spatial temporal data
In-Reply-To: <CACxE24mDc2aAVYEtcrrq6z=qCChTJFOYSrD-a345kj+gC9-t4A@mail.gmail.com>
References: <CACxE24mDc2aAVYEtcrrq6z=qCChTJFOYSrD-a345kj+gC9-t4A@mail.gmail.com>
Message-ID: <CAGxgkWj89AEUXE1pF6y9bAQ3q4NwHrcBD8EK3wq12RfQTzGwyw@mail.gmail.com>

Hi Erin,

Are you interested in point or gridded data and does location or variable
type matter? What are you doing?

Tom

On Tue, Sep 25, 2018 at 11:03 PM Erin Hodgess <erinm.hodgess at gmail.com>
wrote:

> Hello everyone:
>
> Could someone recommend a good source for spatial temporal data from the
> "real world", please?
>
> I have been using the Irish wind data for something that I'm working on,
> and would like to have a nice data set for extra practice.
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From erinm@hodge@@ @ending from gm@il@com  Wed Sep 26 08:35:55 2018
From: erinm@hodge@@ @ending from gm@il@com (Erin Hodgess)
Date: Wed, 26 Sep 2018 00:35:55 -0600
Subject: [R-sig-Geo] spatial temporal data
In-Reply-To: <CAGxgkWj89AEUXE1pF6y9bAQ3q4NwHrcBD8EK3wq12RfQTzGwyw@mail.gmail.com>
References: <CACxE24mDc2aAVYEtcrrq6z=qCChTJFOYSrD-a345kj+gC9-t4A@mail.gmail.com>
 <CAGxgkWj89AEUXE1pF6y9bAQ3q4NwHrcBD8EK3wq12RfQTzGwyw@mail.gmail.com>
Message-ID: <CACxE24mNLwwOq+u2Rpzv-nJ+S2ufX=eQgxcUfuBWzqaTG0M_Bg@mail.gmail.com>

Hi!

I?m testing out a faster Kriging function that I developed.

Location doesn?t matter.  I need it to be ?regular?, in the sense of having
n locations with m observations and a total size of n*m.

Thanks,
Erin

On Tue, Sep 25, 2018 at 11:26 PM Thomas Adams <tea3rd at gmail.com> wrote:

> Hi Erin,
>
> Are you interested in point or gridded data and does location or variable
> type matter? What are you doing?
>
> Tom
>
> On Tue, Sep 25, 2018 at 11:03 PM Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>
>> Hello everyone:
>>
>> Could someone recommend a good source for spatial temporal data from the
>> "real world", please?
>>
>> I have been using the Irish wind data for something that I'm working on,
>> and would like to have a nice data set for extra practice.
>>
>> Thanks,
>> Erin
>>
>>
>> Erin Hodgess, PhD
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From Virgilio@Gomez @ending from uclm@e@  Wed Sep 26 18:30:34 2018
From: Virgilio@Gomez @ending from uclm@e@ (Virgilio Gomez Rubio)
Date: Wed, 26 Sep 2018 16:30:34 +0000
Subject: [R-sig-Geo] SPDE book for Bayesian spatio-temporal modeling
References: <CAKhTKgZ4vAGa5eVrO7_aN1o0gMe+y8kA4C-VGKUeXNa_wuQJBQ@mail.gmail.com>
Message-ID: <6360A597-DADF-474F-93F3-CBEC0FB4F0C6@uclm.es>

Dear all,

I am happy to announce the forthcoming book ?Advanced Spatial Modeling with Stochastic Partial Differential Equations Using R and INLA?. We have a web page at  http://www.r-inla.org/spde-book with more information, R code and datasets, and a online (free) Gitbook version. We hope that this will be a useful resource to those of you interested in Bayesian spatial and spatio-temporal modeling. We?d like to thank CRC for agreeing to have a free version of the book on-line.

Best,

Virgilio

	[[alternative HTML version deleted]]


From r@hep@rd @ending from @ppl-eco@y@@com  Wed Sep 26 18:39:01 2018
From: r@hep@rd @ending from @ppl-eco@y@@com (Rich Shepard)
Date: Wed, 26 Sep 2018 09:39:01 -0700 (PDT)
Subject: [R-sig-Geo] SPDE book for Bayesian spatio-temporal modeling
In-Reply-To: <6360A597-DADF-474F-93F3-CBEC0FB4F0C6@uclm.es>
References: <CAKhTKgZ4vAGa5eVrO7_aN1o0gMe+y8kA4C-VGKUeXNa_wuQJBQ@mail.gmail.com>
 <6360A597-DADF-474F-93F3-CBEC0FB4F0C6@uclm.es>
Message-ID: <alpine.LNX.2.20.1809260938140.8678@salmo.appl-ecosys.com>

On Wed, 26 Sep 2018, Virgilio Gomez Rubio wrote:

> I am happy to announce the forthcoming book ?Advanced Spatial Modeling
> with Stochastic Partial Differential Equations Using R and INLA?. We have
> a web page at  http://www.r-inla.org/spde-book with more information, R
> code and datasets, and a online (free) Gitbook version. We hope that this
> will be a useful resource to those of you interested in Bayesian spatial
> and spatio-temporal modeling. We?d like to thank CRC for agreeing to have
> a free version of the book on-line.

Virgilio,

   Looks interesting. Perhaps I can afford the dead tree edition when it
comes out. :-)

Best regards,

Rich


From @lex@ndre@@nto@br @ending from y@hoo@com@br  Wed Sep 26 22:25:44 2018
From: @lex@ndre@@nto@br @ending from y@hoo@com@br (ASANTOS)
Date: Wed, 26 Sep 2018 16:25:44 -0400
Subject: [R-sig-Geo] Create Kernel image results in *tif format
Message-ID: <e6642ab3-be15-af54-ae08-99b8ebbb7c28@yahoo.com.br>

Dear R-sig-geo Members,

 ??? I've like to create Kernel image results as *tif using an object of 
density() function output in spatstat package. But in my example, 
doesn't work when I try:

#Packages
library(spatstat)
library(raster)
library(rgdal)


#Swedishpines's data set in spatstat package
data(swedishpines)
plot(swedishpines)

#CSR with K-Ripley test
csr_pines <- envelope(swedishpines, Kest, nsim=99)
plot(csr_pines)
# r=0.75 is outside CSR

#Kernel representation using 0.75 as bandwidth
d_pines<-density(swedishpines, bw=0.75)
plot(d_pines)

#Create TIFF image
r_pines <- as(d_pines, "SpatialPixelsDataFrame")
writeGDAL(r_pines, "Pines.tif")
#

> r_pines <- as(d_pines, "SpatialPixelsDataFrame") Error in as(d_pines, 
"SpatialPixelsDataFrame") : no method or default for coercing ?im? to 
?SpatialPixelsDataFrame?

Please any ideas for corrected this?

Thanks in advanced,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================


	[[alternative HTML version deleted]]


From flobetz @ending from web@de  Thu Sep 27 10:01:27 2018
From: flobetz @ending from web@de (Florian Betz)
Date: Thu, 27 Sep 2018 10:01:27 +0200
Subject: [R-sig-Geo] Create Kernel image results in *tif format
In-Reply-To: <e6642ab3-be15-af54-ae08-99b8ebbb7c28@yahoo.com.br>
References: <e6642ab3-be15-af54-ae08-99b8ebbb7c28@yahoo.com.br>
Message-ID: <b229809b-83bf-8c78-3f42-80d92a749236@web.de>

Dear Alexandre,

instead of converting the image to a SpatialPixelDataFrame converting to 
a raster object might be an alternative.

r_pines<-raster(d_pines)
writeRaster(r_pines, "Pines.tif")

Regards,
Florian

Am 26.09.2018 um 22:25 schrieb ASANTOS via R-sig-Geo:
> Dear R-sig-geo Members,
>
>   ??? I've like to create Kernel image results as *tif using an object of
> density() function output in spatstat package. But in my example,
> doesn't work when I try:
>
> #Packages
> library(spatstat)
> library(raster)
> library(rgdal)
>
>
> #Swedishpines's data set in spatstat package
> data(swedishpines)
> plot(swedishpines)
>
> #CSR with K-Ripley test
> csr_pines <- envelope(swedishpines, Kest, nsim=99)
> plot(csr_pines)
> # r=0.75 is outside CSR
>
> #Kernel representation using 0.75 as bandwidth
> d_pines<-density(swedishpines, bw=0.75)
> plot(d_pines)
>
> #Create TIFF image
> r_pines <- as(d_pines, "SpatialPixelsDataFrame")
> writeGDAL(r_pines, "Pines.tif")
> #
>
>> r_pines <- as(d_pines, "SpatialPixelsDataFrame") Error in as(d_pines,
> "SpatialPixelsDataFrame") : no method or default for coercing ?im? to
> ?SpatialPixelsDataFrame?
>
> Please any ideas for corrected this?
>
> Thanks in advanced,
>
> Alexandre
>

-- 
Florian Betz
Gartenstra?e 13
86152 Augsburg, Deutschland

Tel.: 0176 20344096
Mail: flobetz at web.de


From rub@k @ending from m@th@@@u@dk  Thu Sep 27 10:51:30 2018
From: rub@k @ending from m@th@@@u@dk (Ege Rubak)
Date: Thu, 27 Sep 2018 10:51:30 +0200
Subject: [R-sig-Geo] Create Kernel image results in *tif format
In-Reply-To: <b229809b-83bf-8c78-3f42-80d92a749236@web.de>
References: <e6642ab3-be15-af54-ae08-99b8ebbb7c28@yahoo.com.br>
 <b229809b-83bf-8c78-3f42-80d92a749236@web.de>
Message-ID: <a6a53587-de4e-8b18-a49c-323af79f9318@math.aau.dk>

Dear Alexandre,

Indeed the solution by Florian below is very nice. If you really want to 
go the other direction you can use `as.SpatialGridDataFrame.im()` from 
the `maptools` package.

By the way, based on what you write, I think you mean to use the value 
7.5 (=0.75m) rather than 0.75 (=0.075 m) for your kernel bandwidth. 
Furthermore, the argument to set the standard deviation of the 
(isotropic Gaussian) smoothing kernel in `density.ppp()` is `sigma`, so 
you probably want:
     d_pines <- density(swedishpines, sigma = 7.5)

If you like to work in meters rather than decimeters you can rescale the 
point pattern:
     pines <- rescale(swedishpines, s = 10, unitname = "m")
     d_pines <- density(pines, sigma = 0.75)

Regards,
Ege


On 09/27/2018 10:01 AM, Florian Betz wrote:
> Dear Alexandre,
> 
> instead of converting the image to a SpatialPixelDataFrame converting to 
> a raster object might be an alternative.
> 
> r_pines<-raster(d_pines)
> writeRaster(r_pines, "Pines.tif")
> 
> Regards,
> Florian
> 
> Am 26.09.2018 um 22:25 schrieb ASANTOS via R-sig-Geo:
>> Dear R-sig-geo Members,
>>
>> ? ??? I've like to create Kernel image results as *tif using an object of
>> density() function output in spatstat package. But in my example,
>> doesn't work when I try:
>>
>> #Packages
>> library(spatstat)
>> library(raster)
>> library(rgdal)
>>
>>
>> #Swedishpines's data set in spatstat package
>> data(swedishpines)
>> plot(swedishpines)
>>
>> #CSR with K-Ripley test
>> csr_pines <- envelope(swedishpines, Kest, nsim=99)
>> plot(csr_pines)
>> # r=0.75 is outside CSR
>>
>> #Kernel representation using 0.75 as bandwidth
>> d_pines<-density(swedishpines, bw=0.75)
>> plot(d_pines)
>>
>> #Create TIFF image
>> r_pines <- as(d_pines, "SpatialPixelsDataFrame")
>> writeGDAL(r_pines, "Pines.tif")
>> #
>>
>>> r_pines <- as(d_pines, "SpatialPixelsDataFrame") Error in as(d_pines,
>> "SpatialPixelsDataFrame") : no method or default for coercing ?im? to
>> ?SpatialPixelsDataFrame?
>>
>> Please any ideas for corrected this?
>>
>> Thanks in advanced,
>>
>> Alexandre
>>
>


From @lex@ndre@@nto@br @ending from y@hoo@com@br  Thu Sep 27 14:22:06 2018
From: @lex@ndre@@nto@br @ending from y@hoo@com@br (ASANTOS)
Date: Thu, 27 Sep 2018 08:22:06 -0400
Subject: [R-sig-Geo] Create Kernel image results in *tif format
In-Reply-To: <b229809b-83bf-8c78-3f42-80d92a749236@web.de>
References: <e6642ab3-be15-af54-ae08-99b8ebbb7c28@yahoo.com.br>
 <b229809b-83bf-8c78-3f42-80d92a749236@web.de>
Message-ID: <3b061398-532d-8fa9-bb0a-b3af1b38d23c@yahoo.com.br>

Thank you very much Florian,

Solve my problem!!

Best wishes,

Alexandre

-- 
======================================================================
Alexandre dos Santos
Prote??o Florestal
IFMT - Instituto Federal de Educa??o, Ci?ncia e Tecnologia de Mato Grosso
Campus C?ceres
Caixa Postal 244
Avenida dos Ramires, s/n
Bairro: Distrito Industrial
C?ceres - MT                      CEP: 78.200-000
Fone: (+55) 65 99686-6970 (VIVO) (+55) 65 3221-2674 (FIXO)

         alexandre.santos at cas.ifmt.edu.br
Lattes: http://lattes.cnpq.br/1360403201088680
OrcID: orcid.org/0000-0001-8232-6722
Researchgate: www.researchgate.net/profile/Alexandre_Santos10
LinkedIn: br.linkedin.com/in/alexandre-dos-santos-87961635
Mendeley:www.mendeley.com/profiles/alexandre-dos-santos6/
======================================================================

Em 27/09/2018 04:01, Florian Betz escreveu:
> Dear Alexandre,
>
> instead of converting the image to a SpatialPixelDataFrame converting 
> to a raster object might be an alternative.
>
> r_pines<-raster(d_pines)
> writeRaster(r_pines, "Pines.tif")
>
> Regards,
> Florian
>
> Am 26.09.2018 um 22:25 schrieb ASANTOS via R-sig-Geo:
>> Dear R-sig-geo Members,
>>
>> ? ??? I've like to create Kernel image results as *tif using an 
>> object of
>> density() function output in spatstat package. But in my example,
>> doesn't work when I try:
>>
>> #Packages
>> library(spatstat)
>> library(raster)
>> library(rgdal)
>>
>>
>> #Swedishpines's data set in spatstat package
>> data(swedishpines)
>> plot(swedishpines)
>>
>> #CSR with K-Ripley test
>> csr_pines <- envelope(swedishpines, Kest, nsim=99)
>> plot(csr_pines)
>> # r=0.75 is outside CSR
>>
>> #Kernel representation using 0.75 as bandwidth
>> d_pines<-density(swedishpines, bw=0.75)
>> plot(d_pines)
>>
>> #Create TIFF image
>> r_pines <- as(d_pines, "SpatialPixelsDataFrame")
>> writeGDAL(r_pines, "Pines.tif")
>> #
>>
>>> r_pines <- as(d_pines, "SpatialPixelsDataFrame") Error in as(d_pines,
>> "SpatialPixelsDataFrame") : no method or default for coercing ?im? to
>> ?SpatialPixelsDataFrame?
>>
>> Please any ideas for corrected this?
>>
>> Thanks in advanced,
>>
>> Alexandre
>>
>


From brun@e@ti @ending from gm@il@com  Thu Sep 27 20:09:09 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Thu, 27 Sep 2018 20:09:09 +0200
Subject: [R-sig-Geo] Subsample (and or aggregation) of spatio temporal data
 (by using spatio temporal grid)
Message-ID: <CAFnjcD0TS0cJOrGW2yzpcdmx+90NN2SE2FKk0MWFrQBc8+8bSw@mail.gmail.com>

Hi,
I would like to know of it exists some function or method to subsumple (by
which I mean define a spatio temporal or a general 3D grid and substitute
all data which fall in one grid cell (in this case one grid cube, with
defined dimensions), with a reference data from the ones which fall in the
cube itself or with their mean,...)
Is it be possible to do such process?
If yes, it could be useful use a spatio temporal or a general 3D grid or
also other methods can be used?

Kind regards.

	[[alternative HTML version deleted]]


From j@chon7 @ending from gm@il@com  Thu Sep 27 21:35:43 2018
From: j@chon7 @ending from gm@il@com (Justin Schon)
Date: Thu, 27 Sep 2018 15:35:43 -0400
Subject: [R-sig-Geo] Question about HSAR package
Message-ID: <CAGH4ugJQEG14+jECxmGpoF0=T68FGcocA5UKDGRxO810zEmUPw@mail.gmail.com>

Dear all,

I am receiving the error "not an S4 object" when I attempt to estimate the
hierarchal spatial auto-regressive model from the HSAR package. I have
attempted several ways of creating the lower level matrix and higher level
matrix. Rather than asking if members of this list can help with the code,
I am first wondering if anyone can explain why this error would appear.

I am including the code that estimates the model, as well as the error,
below:

> HSAR.model1<- hsar(Count_ ~ ndc_pres_3
+                    + volatility + turnout_21
+                    + volatili_1 + X20160526_6
+                    + DENSITY_RD + Count_3
+                    + MEAN + pov_p_2008
+                    + gini_2008 + ferat_2008
+                    + Count_4 + literacy
+                    + grid_perCa, data=constit, W=W.constit,
+                    M=W.dist, Delta = Delta.mat,
+                    burnin = 5000, Nsim = 10000,
+                    thinning = 1, parameters.start = NULL)
Error in hsar(Count_ ~ ndc_pres_3 + volatility + turnout_21 + volatili_1 +
:
  not an S4 object


Again, I am not looking for advice with the code right now. I am wondering
what kinds of problems could cause this error message.

As a note, I receive the same error message when I try to estimate an sar
model and when I simplify the model down to one independent variable.

I greatly appreciate any ideas that members of this list might have.

Thank you,

Justin





-- 
Justin Schon
Post-Doctoral Researcher on Environmental Change and Migration
MURI Migration Research Team: http://murimigration.org/
University of Florida
Fellow, Initiative for Sustainable Energy Policy (ISEP)

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Thu Sep 27 21:57:05 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Thu, 27 Sep 2018 19:57:05 +0000
Subject: [R-sig-Geo] Question about HSAR package
In-Reply-To: <CAGH4ugJQEG14+jECxmGpoF0=T68FGcocA5UKDGRxO810zEmUPw@mail.gmail.com>
References: <CAGH4ugJQEG14+jECxmGpoF0=T68FGcocA5UKDGRxO810zEmUPw@mail.gmail.com>
Message-ID: <CF511784783D0B52.9393b71e-5822-4a91-915f-a8dd0be853e7@mail.outlook.com>

This code tells nothing, the problem is in your construction of W, M and/or Delta. Pleaseng show this code too, best as a reproducible example. Tip: sometimes running traceback() after an error shows where it happens.

Roger Bivand
Norwegian School of Economics
Bergen, Norway

Fra: Justin Schon
Sendt: torsdag 27. september, 21.36
Emne: [R-sig-Geo] Question about HSAR package
Til: r-sig-geo at r-project.org


Dear all, I am receiving the error "not an S4 object" when I attempt to estimate the hierarchal spatial auto-regressive model from the HSAR package. I have attempted several ways of creating the lower level matrix and higher level matrix. Rather than asking if members of this list can help with the code, I am first wondering if anyone can explain why this error would appear. I am including the code that estimates the model, as well as the error, below: > HSAR.model1

	[[alternative HTML version deleted]]


From j@chon7 @ending from gm@il@com  Thu Sep 27 22:08:56 2018
From: j@chon7 @ending from gm@il@com (Justin Schon)
Date: Thu, 27 Sep 2018 16:08:56 -0400
Subject: [R-sig-Geo] Question about HSAR package
In-Reply-To: <CF511784783D0B52.9393b71e-5822-4a91-915f-a8dd0be853e7@mail.outlook.com>
References: <CAGH4ugJQEG14+jECxmGpoF0=T68FGcocA5UKDGRxO810zEmUPw@mail.gmail.com>
 <CF511784783D0B52.9393b71e-5822-4a91-915f-a8dd0be853e7@mail.outlook.com>
Message-ID: <CAGH4ugLX1C=BGOvt4EWBW+A44anEWKn9BVjuQ7yS9=HYD-+_7A@mail.gmail.com>

Ok, it's helpful to know that I need to zoom in on those three things.

I created the Random Effects Matrix by hand in Excel, so I read that into R
and put the matrix into the format recommended here:
https://cran.r-project.org/web/packages/HSAR/vignettes/hsar.html

Below, I show how I made W, M, and Delta.mat, before I try to estimate the
model. Hopefully this helps.


constit<- readShapeSpatial("Population
Weighted/Constituencies_2008/20170209_Constit")
constit.nb<- poly2nb(constit, row.names = constit$X20160526_5)
ghana.constit.weights.binary<- nb2listw(constit.nb, style="B", zero.policy
= TRUE)

W.constit<- listw2mat(ghana.constit.weights.binary)
W.constit <- W.constit / rowSums(W.constit)
W.constit <- as(W.constit,"dgCMatrix")


dist2008<- readShapeSpatial("Population Weighted/Districts_2008/Volta
Variable/20170226_Districts")
dist2008.nb<- poly2nb(dist2008, row.names = dist2008$DIST_2008)
ghana.dist2008.weights.binary<- nb2listw(dist2008.nb, style="B",
zero.policy=T)

W.dist<- listw2mat(ghana.dist2008.weights.binary)
W.dist <- W.dist / rowSums(W.dist)
W.dist <- as(W.dist,"dgCMatrix")


Delta<- read.csv("Random Effects Matrix_Ghana.csv",
                 header = T, row.names = 1)
Delta.mat<- as.matrix(Delta)
Delta.mat <- as(Delta.mat,"dgCMatrix")


> HSAR.model1<- hsar(Count_ ~ ndc_pres_3
+                    + volatility + turnout_21
+                    + volatili_1 + X20160526_6
+                    + DENSITY_RD + Count_3
+                    + MEAN + pov_p_2008
+                    + gini_2008 + ferat_2008
+                    + Count_4 + literacy
+                    + grid_perCa, data=constit, W=W.constit,
+                    M=W.dist, Delta = Delta.mat,
+                    burnin = 5000, Nsim = 10000,
+                    thinning = 1, parameters.start = NULL)
Error in hsar(Count_ ~ ndc_pres_3 + volatility + turnout_21 + volatili_1 +
:
  not an S4 object







On Thu, Sep 27, 2018 at 3:57 PM Roger Bivand <Roger.Bivand at nhh.no> wrote:

> This code tells nothing, the problem is in your construction of W, M
> and/or Delta. Pleaseng show this code too, best as a reproducible example.
> Tip: sometimes running traceback() after an error shows where it happens.
>
> Roger Bivand
> Norwegian School of Economics
> Bergen, Norway
>
> Fra: Justin Schon
> Sendt: torsdag 27. september, 21.36
> Emne: [R-sig-Geo] Question about HSAR package
> Til: r-sig-geo at r-project.org
>
>
> Dear all, I am receiving the error "not an S4 object" when I attempt to
> estimate the hierarchal spatial auto-regressive model from the HSAR
> package. I have attempted several ways of creating the lower level matrix
> and higher level matrix. Rather than asking if members of this list can
> help with the code, I am first wondering if anyone can explain why this
> error would appear. I am including the code that estimates the model, as
> well as the error, below: > HSAR.model1
>


-- 
Justin Schon
Post-Doctoral Researcher on Environmental Change and Migration
MURI Migration Research Team: http://murimigration.org/
University of Florida
Fellow, Initiative for Sustainable Energy Policy (ISEP)

	[[alternative HTML version deleted]]


From m@rtin@hulenyi @ending from vl@d@@gov@@k  Sat Sep 29 00:28:42 2018
From: m@rtin@hulenyi @ending from vl@d@@gov@@k (=?iso-8859-2?Q?Hul=E9nyi_Martin?=)
Date: Fri, 28 Sep 2018 22:28:42 +0000
Subject: [R-sig-Geo] spgm
Message-ID: <1eacb0179d5746ac9360f91bfe34fd92@UVEX2.uvsr.sk>

Dear all,


I would like to ask if there is a possibility to apply something similiar to the "impacts" from spdep package for SAR regressions using the spgm function from the  splm package.


Best regards,


Martin Hul?nyi ?


[eco.jpg]       Pred vytla?en?m tohto mailu zv?te pros?m vplyv na ?ivotn? prostredie. ?akujeme.
Please consider the environment before printing this e-mail. Thanks

	[[alternative HTML version deleted]]


From r@pdorn@@ @ending from gm@il@com  Sat Sep 29 00:52:03 2018
From: r@pdorn@@ @ending from gm@il@com (Rubem Dornas)
Date: Fri, 28 Sep 2018 19:52:03 -0300
Subject: [R-sig-Geo] Linear referencing in R
Message-ID: <CAB1EwuYW-iiE3W0r6D6g6cH8q3+0hfpJGNTNJ4UtkCoikmPzLA@mail.gmail.com>

Hi, people! I hope I'll be not to speculative in my question and that you
can comprehend my problem.

Well, I have a railroad shapefile and I have two csv files corresponding to
the topography in each side of the railroad. The csv are organized in this
way:

ID_topo, from_km, to_km, height
1, 0, 1.91, 15
2, 1.91, 2.23, -3

I created a point shapefile for each meter of the railroad and then I
proceeded with a join (not spatial) between the from_km of the topography
data frame and the km mark (km_calc) from the point railroad.

My goal is to create shapefiles for each of the railroadside topography.
The issue is that when I try to make a new line shapefile from topography
based on the points of the railroad, what I get is a line that has doesn't
follow the curvature of the railroad. Using the example of the csv above,
what I get are several straight lines linked by the from_km to to_km. (Here
is a link to a print screen from QGIS:
https://www.dropbox.com/s/erfsst8pasoqj64/Captura%20de%20tela%202018-09-28%2019.49.47.png?dl=0
<http://Image>)

Maybe it is a little bit difficult to me to explain exactly the problem,
but any doubts, please ask. The files and the script I'm using are on the
following github: https://github.com/rdornas/raileco

Thank you very much indeed in advance!

*Rubem A. P. Dornas*
Celular: (31) 99642-5102
PPG An?lise e Modelagem de Sistemas Ambientais
Instituto de Geoci?ncias - Universidade Federal de Minas Gerais
Curr?culo Lattes: http://lattes.cnpq.br/7197154832267712

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Sat Sep 29 14:11:50 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sat, 29 Sep 2018 14:11:50 +0200
Subject: [R-sig-Geo] Consolidated SRS database/list?
In-Reply-To: <0abef0fd-b4b2-bd13-7afa-aaf9db238776@wildintellect.com>
References: <CAKkiGbtvkBCe5+wMEmtvYZr5aeAmeLZPrtM2F_Y_B8otRyzV9g@mail.gmail.com>
 <alpine.LFD.2.21.1809201856170.19929@reclus.nhh.no>
 <CAKkiGbsQD6JS+uduM6HemMFbx8XUjPJhMJC6sdKB3qExs_=GTw@mail.gmail.com>
 <alpine.LFD.2.21.1809210931090.3575@reclus.nhh.no>
 <b943d635-8c7c-d355-5a3b-7fd4befb2e95@wildintellect.com>
 <CAKkiGbvJrBAPFo8Nsp1RnLUDP9e_+Wr-k+0vtWxSQvue7DSgsQ@mail.gmail.com>
 <0abef0fd-b4b2-bd13-7afa-aaf9db238776@wildintellect.com>
Message-ID: <alpine.LFD.2.21.1809291408130.16108@reclus.nhh.no>

This blog:

https://erouault.blogspot.com/2018/09/srs-barn-raising-4th-report.html

gives the status on the proposed generic db to ship with PROJ and be used 
by software using PROJ.

Roger

On Sat, 22 Sep 2018, Alex Mandel wrote:

> Though it requires Internet what about hitting the epsg.io API described
> on https://github.com/klokantech/epsg.io
>
> Thanks,
> Alex
>
> On 09/22/2018 05:23 AM, Vijay Lulla wrote:
>> Alex,
>> Thanks for QGIS's srs.db!  I wasn't aware of it.
>>
>> I currently use the spatial_ref_sys from PostGIS to create a SRS data frame
>> but plan to use rgdal::make_EPSG more often.  The reason I brought this up
>> is because on the lab computers (cannot install stuff on it) where I teach
>> there is no PostGIS and I didn't know how to lookup EPSG codes for various
>> SRS definitions from within R.  I hadn't thought of Spatialite metadata as
>> a viable alternative.  So, thanks for that.  I will look into it and most
>> likely use it in conjunction with make_EPSG!
>>
>> Finally, I am really looking forward to the consolidated SRS database from
>> the gdal barn-raising effort!  This consolidated database will be
>> invaluable, and of great aid/service, to the geospatial community, IMO.
>> Thanks,
>> Vijay.
>>
>> On Sat, Sep 22, 2018 at 1:22 AM Alex Mandel <tech_dev at wildintellect.com>
>> wrote:
>>
>>> QGIS makes one
>>> https://github.com/qgis/QGIS/blob/master/resources/srs.db
>>> There's some script in the build that updates it also, not without issue:
>>> https://issues.qgis.org/issues/17993
>>>
>>> I suppose you could also dump out how PostGIS does it to Sqlite, or use
>>> the Spatialite metadata table.
>>> https://www.gaia-gis.it/gaia-sins/spatialite-cookbook/html/metadata.html
>>>
>>> But the thread mentioned that goes back to the MetaCRS mailing list is
>>> probably the right place in the community to revive the discussion.
>>>
>>> Seems like something to encourage, and a good topic for an OSGeo
>>> sponsored sprint.
>>>
>>> Thanks,
>>> Alex
>>>
>>> On 09/21/2018 12:32 AM, Roger Bivand wrote:
>>>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>>>>
>>>>> Ok, thanks!  While the page provided information about the project and
>>>>> its
>>>>> funding status I couldn't find the SQLite database.  Do you happen to
>>>>> know
>>>>> when this will be available?
>>>>
>>>> No more than is on that page, plus the time needed to re-write plenty of
>>>> sf, lwgeom, rgdal and sp. At that stage, contributions welcome!
>>>>
>>>> Roger
>>>>
>>>>>
>>>>> On Thu, Sep 20, 2018 at 1:02 PM Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>>>
>>>>>> On Thu, 20 Sep 2018, Vijay Lulla wrote:
>>>>>>
>>>>>>> Dear list members,
>>>>>>> A few years ago Roger Bivand posted a discussion (
>>>>>>> https://stat.ethz.ch/pipermail/r-sig-geo/2015-August/023204.html )
>>>>>>> about
>>>>>>> consolidating SRS definitions into a SQLite database and I am
>>> wondering
>>>>>> if
>>>>>>> there has been any development along those lines.
>>>>>>
>>>>>> Rather than trying this just within R, we're hoping that the GDAL
>>>>>> barn-raising effort:
>>>>>>
>>>>>> https://gdalbarn.com/
>>>>>>
>>>>>> will take us there and further, and be much better than having a
>>>>>> non-standard implementation.
>>>>>>
>>>>>> When that effort is done, we'll be open for ideas about interfacing it
>>>>>> through PROJ and GDAL, which now ship with CSV files that we copy into
>>>>>> Windows and MacOS binary packages (rgdal, sf, lwgeom).
>>>>>>
>>>>>> For now, if it helps, rgdal::make_EPSG() reads the EPSG CSV file
>>> shipped
>>>>>> with PROJ into the R workspace as a data.frame.
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>> Specifically, is there any consolidated collection of SRS
>>>>>>> definitions in
>>>>>>> R (either a data.frame or tibble or SQLite backed) that are being used
>>>>>>> by geospatial packages that users can use too?  If so, can you please
>>>>>>> point me to it?  If not, would it be worthwhile to have this
>>>>>>> consolidated list/dataframe, maybe as part of data for one of the core
>>>>>>> geospatial packages? Thanks in advance, Vijay
>>>>>>>
>>>>>>>       [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Roger Bivand
>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
>>>>>> http://orcid.org/0000-0003-2392-6140
>>>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>
>>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From Roger@Biv@nd @ending from nhh@no  Sat Sep 29 14:52:18 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Sat, 29 Sep 2018 14:52:18 +0200
Subject: [R-sig-Geo] spgm
In-Reply-To: <1eacb0179d5746ac9360f91bfe34fd92@UVEX2.uvsr.sk>
References: <1eacb0179d5746ac9360f91bfe34fd92@UVEX2.uvsr.sk>
Message-ID: <alpine.LFD.2.21.1809291433540.16108@reclus.nhh.no>

On Sat, 29 Sep 2018, Hul?nyi Martin wrote:

> Dear all,
>
>
> I would like to ask if there is a possibility to apply something 
> similiar to the "impacts" from spdep package for SAR regressions using 
> the spgm function from the splm package.
>

A reprex would have helped. Here is mine:

data(Produc, package = "plm")
data(usaww) # dense row-standardised weights matrix
GM <- spgm(log(gsp)~log(pcap)+log(pc)+log(emp)+unemp, data=Produc,
   listw = usaww, moments="fullweights", lag=TRUE, spatial.error = FALSE)
class(GM)
?impacts.stsls # spdep method for stsls objects
head(Produc)
length(unique(Produc$year)) # T
big <- kronecker(diag(length(unique(Produc$year))), usaww)
listw <- mat2listw(big, style="W")
tr <- trW(as(listw, "CsparseMatrix"), m=100)
impacts(GM, listw=listw)
impacts(GM, tr=tr)
summary(impacts(GM, tr=tr, R=1000), zstats=TRUE, short=TRUE)

The splm:::impacts.splm() method cannot dispatch on stsls objects, so they 
try to use the spdep:::impacts.stsls() method, but there the data rows are 
n x T but listw is only of n rows. Looking inside splm:::impacts.splm(), 
you see that a sparse kronecker product matrix is constructed - either do 
the same if your n x T is large, or follow the above using a dense 
kronecker product and cast back to listw representation to create the 
trace vector.

Hope this clarifies,

Roger

>
> Best regards,
>
>
> Martin Hul???nyi ?
>
>
> [eco.jpg]       Pred vytla???en???m tohto mailu zv???te pros???m vplyv na ???ivotn??? prostredie. ???akujeme.
> Please consider the environment before printing this e-mail. Thanks
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From kent3737 @ending from gm@il@com  Sun Sep 30 03:17:42 2018
From: kent3737 @ending from gm@il@com (Kent Johnson)
Date: Sat, 29 Sep 2018 21:17:42 -0400
Subject: [R-sig-Geo] Linear referencing in R
In-Reply-To: <mailman.26917.5.1538215201.61047.r-sig-geo@r-project.org>
References: <mailman.26917.5.1538215201.61047.r-sig-geo@r-project.org>
Message-ID: <CAPP0wygVnLzik0tt8D+P5M2xLTGtPK=AYBOs4HwK+oQUF2XoPQ@mail.gmail.com>

You need to snip out the sections of the railroad file rather than
connecting the endpoints. Maybe this is closer to what you want?

segments = topoESQ_comp %>%
  filter(to_km <= 871) %>%
  purrr::pmap(function(from_km, to_km, ...) {
    st_linestring(do.call(rbind,
Estacas_1m$geometry[((1000*from_km):(1000*to_km))+1]))
}) %>%
  st_sfc

Kent Johnson


> Date: Fri, 28 Sep 2018 19:52:03 -0300
> From: Rubem Dornas <rapdornas at gmail.com>
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Linear referencing in R
> Hi, people! I hope I'll be not to speculative in my question and that you
> can comprehend my problem.
>
> Well, I have a railroad shapefile and I have two csv files corresponding to
> the topography in each side of the railroad. The csv are organized in this
> way:
>
> ID_topo, from_km, to_km, height
> 1, 0, 1.91, 15
> 2, 1.91, 2.23, -3
>
> I created a point shapefile for each meter of the railroad and then I
> proceeded with a join (not spatial) between the from_km of the topography
> data frame and the km mark (km_calc) from the point railroad.
>
> My goal is to create shapefiles for each of the railroadside topography.
> The issue is that when I try to make a new line shapefile from topography
> based on the points of the railroad, what I get is a line that has doesn't
> follow the curvature of the railroad. Using the example of the csv above,
> what I get are several straight lines linked by the from_km to to_km. (Here
> is a link to a print screen from QGIS:
>
> https://www.dropbox.com/s/erfsst8pasoqj64/Captura%20de%20tela%202018-09-28%2019.49.47.png?dl=0
> <http://Image>)
>
>

	[[alternative HTML version deleted]]


