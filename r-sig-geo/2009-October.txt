From folopez at ivic.ve  Thu Oct  1 05:25:51 2009
From: folopez at ivic.ve (=?ISO-8859-1?Q?Freddy_L=F3pez?=)
Date: Wed, 30 Sep 2009 22:55:51 -0430
Subject: [R-sig-Geo] Creating borders.-
Message-ID: <cac512fc0909302025p6c87cefl63333bc415f6395b@mail.gmail.com>

Hello folks,

I'm working with geostatistics data and I'm using mainly geoR library.
Now, in some examples, is useful to use the 'borders' to delimitate
our kriging process, e.g., in the krige.conv() function. To steal a
Ribeiro & Diggle's example
(http://leg.ufpr.br/geoR/tutorials/aula050819.R), we have some lines
such as


>Ksat.in <- krige.conv(Ksat, loc=grid0, borders=Ksat$borders,krige=krige.control(obj=Ksat.ef))
>image(Ksat.in, col=gray(seq(1, 0.1, l=21)))


in which is nice to have Ksat$borders because we can have our
prediction inside of these borders (and it looks better).

Now, suppose we have an object of the class geodata but it has not got borders.

We can visualisate I'm saying with a little modification of latter example


> Ksat.in <- krige.conv(coords=Ksat$coords,data=Ksat$data, loc=grid0,krige=krige.control(obj=Ksat.ef))
> image(Ksat.in, col=gray(seq(1, 0.1, l=21)))


which looks as an rectangle with no reference to something.

That's my problem: I have an object of the class geodata (indeed, is a
worked shapefile, because I'm treating with counties) and I have done
all good up to the kriging stage because I don't know how to extract
or create borders. I mean, I can get a rectangular kriging, but it is
not the aim.

Again, excuse my clumsy english.

Thanks.

--
'qu? importa la tristeza si hubo en el tiempo
alguien que se dijo feliz,'

JL Borges


From freddy.vate01 at gmail.com  Thu Oct  1 05:39:40 2009
From: freddy.vate01 at gmail.com (=?ISO-8859-1?Q?Freddy_L=F3pez?=)
Date: Wed, 30 Sep 2009 23:09:40 -0430
Subject: [R-sig-Geo] Creating borders.-
Message-ID: <cac512fc0909302039l32fc1cf6s623dd617c1943e38@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20090930/3e2c7b11/attachment.pl>

From tom.gottfried at wzw.tum.de  Thu Oct  1 12:37:45 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Thu, 1 Oct 2009 12:37:45 +0200
Subject: [R-sig-Geo] Creating borders.-
Message-ID: <441EEB69-B42B-4C8E-823E-34D04949C7B6@wzw.tum.de>

Hi Freddy,

to add borders to an object of class geodata just add them as an  
element to the list (class geodata basically is a list):

obj$borders <- border.polygon

border.polygon here must match coordinates as described in ?polygon,  
if I remember correctly.

regards,
Tom


From Pilar.Tugores at ba.ieo.es  Thu Oct  1 17:32:36 2009
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Thu, 1 Oct 2009 17:32:36 +0200
Subject: [R-sig-Geo] curious about 4D interpolations
In-Reply-To: <441EEB69-B42B-4C8E-823E-34D04949C7B6@wzw.tum.de>
References: <441EEB69-B42B-4C8E-823E-34D04949C7B6@wzw.tum.de>
Message-ID: <0838E01493845742A4D4039EA34EB1C18CD5B2@ieopalma2.ba.ieo.es>


Dear list,
I just was wondering about sofware to perform 4D interpolations.
I've never tried and I'm probably not going to try it in the short time or but I was asked to give (informal) advice about it and also I was curious.
I have heard GRASS gis can do that and also I've heard about EONFUSION which is a Miriax software. I would like to know if anybody has tried 4D interpolations with this or other softwares and what was your impression. Is it user friendly? Is it flexible? Nice layouts? Is it really interpolating in 4D or it just allow 4D representations?
Thanks a lot!
Cheers,
Pilar

M? Pilar Tugores Ferr?
PhD Student
Instituto Espa?ol de Oceanograf?a
Centro Oceanogr?fico de Baleares
Muelle de Poniente s/n
07015 Palma de Mallorca
Baleares, Espa?a
Telf.: (34) 971 133759


La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.


From tom.gottfried at wzw.tum.de  Thu Oct  1 21:25:12 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Thu, 1 Oct 2009 21:25:12 +0200
Subject: [R-sig-Geo] Creating borders.-
In-Reply-To: <cac512fc0910011120iae060ecya26f29eff3d8e80@mail.gmail.com>
References: <441EEB69-B42B-4C8E-823E-34D04949C7B6@wzw.tum.de>
	<cac512fc0910011120iae060ecya26f29eff3d8e80@mail.gmail.com>
Message-ID: <83955A8D-373D-4F05-BE8F-4C15548A5E4F@wzw.tum.de>

Hi Freddy,

from where do you want to extract the information to which spatial  
extent you want to interpolate? A shapefile with field borders? You  
could also digitalize any polygon with locator(). Anyhow the borders  
are not a priori in your data.

regards,
Tom

Am 01.10.2009 um 20:20 schrieb Freddy L?pez:

> Thanks for your answer, Tom.
>
> Yes, each geodata object is basically a list, and I can add the border
> as you mention but, I haven't got these borders. I just have got a
> geodata object with coordinates and data but with no borders. My
> question is if I can extract or create a border with a object with
> these features.
>
> Again, thanks you.
>
>
> On Thu, Oct 1, 2009 at 06:07, Tom Gottfried  
> <tom.gottfried at wzw.tum.de> wrote:
>> Hi Freddy,
>>
>> to add borders to an object of class geodata just add them as an  
>> element to
>> the list (class geodata basically is a list):
>>
>> obj$borders <- border.polygon
>>
>> border.polygon here must match coordinates as described in ? 
>> polygon, if I
>> remember correctly.
>>
>> regards,
>> Tom
>>
>
>
>
> -- 
> 'qu? importa la tristeza si hubo en el tiempo
> alguien que se dijo feliz,'
>
> JL Borges


From wwwhsd at gmail.com  Thu Oct  1 21:41:17 2009
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Thu, 1 Oct 2009 16:41:17 -0300
Subject: [R-sig-Geo] Creating borders.-
In-Reply-To: <cac512fc0909302039l32fc1cf6s623dd617c1943e38@mail.gmail.com>
References: <cac512fc0909302039l32fc1cf6s623dd617c1943e38@mail.gmail.com>
Message-ID: <da79af330910011241o19b9ac58ud875dbbbf7194544@mail.gmail.com>

Try the chull function to create a border.


On Thu, Oct 1, 2009 at 12:39 AM, Freddy L?pez <freddy.vate01 at gmail.com> wrote:
> Hello folks,
>
> I'm working with geostatistics data and I'm using mainly geoR library.
> Now, in some examples, is useful to use the 'borders' to delimitate
> our kriging process, e.g., in the krige.conv() function. To steal a
> Ribeiro & Diggle's example
> (http://leg.ufpr.br/geoR/tutorials/aula050819.R), we have some lines
> such as
>
>
>>Ksat.in <- krige.conv(Ksat, loc=grid0, borders=Ksat$borders,krige=
> krige.control(obj=Ksat.ef))
>>image(Ksat.in, col=gray(seq(1, 0.1, l=21)))
>
>
> in which is nice to have Ksat$borders because we can have our
> prediction inside of these borders (and it looks better).
>
> Now, suppose we have an object of the class geodata but it has not got
> borders.
>
> We can visualisate I'm saying with a little modification of latter example
>
>
>> Ksat.in <- krige.conv(coords=Ksat$coords,data=Ksat$data,
> loc=grid0,krige=krige.control(obj=Ksat.ef))
>> image(Ksat.in, col=gray(seq(1, 0.1, l=21)))
>
>
> which looks as an rectangle with no reference to something.
>
> That's my problem: I have an object of the class geodata (indeed, is a
> worked shapefile, because I'm treating with counties) and I have done
> all good up to the kriging stage because I don't know how to extract
> or create borders. I mean, I can get a rectangular kriging, but it is
> not the aim.
>
> Again, excuse my clumsy english.
>
> Thanks.
>
>
> --
> 'qu? importa la tristeza si hubo en el tiempo
> alguien que se dijo feliz,'
>
> JL Borges
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



-- 
Henrique Dallazuanna
Curitiba-Paran?-Brasil
25? 25' 40" S 49? 16' 22" O


From pierre.roudier at gmail.com  Fri Oct  2 01:39:17 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Fri, 2 Oct 2009 09:39:17 +1000
Subject: [R-sig-Geo] Creating borders.-
In-Reply-To: <da79af330910011241o19b9ac58ud875dbbbf7194544@mail.gmail.com>
References: <cac512fc0909302039l32fc1cf6s623dd617c1943e38@mail.gmail.com> 
	<da79af330910011241o19b9ac58ud875dbbbf7194544@mail.gmail.com>
Message-ID: <e4178da60910011639p53f12d9cja314a39b401b3d44@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091002/0b05e5c1/attachment.pl>

From macq at llnl.gov  Fri Oct  2 06:52:33 2009
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 1 Oct 2009 21:52:33 -0700
Subject: [R-sig-Geo] Put polygon points in correct order
In-Reply-To: <alpine.LRH.2.00.0909211113460.8279@reclus.nhh.no>
References: <OFCC0D647C.E994D1F4-ONC1257638.002CAF8C-C1257638.002CE03C@bdpnet.dk>
	<alpine.LRH.2.00.0909211113460.8279@reclus.nhh.no>
Message-ID: <p06240800c6eb329bfd86@[192.168.11.5]>

I have a set of points that form a polygon, except that they are in 
the wrong order. For example, source into R the object "tmpsub" given 
below. Then do

plot(tmpsub)
polygon(tmpsub)

You will see that although the points define a polygon, they are in 
the wrong order.

I need an algorithm to put them in the correct order. It's not 
obvious to me how to do this.
(They will then be used to build a SpatialPolygons object.)

Suggestions, or pointers to algorithms, would be much appreciated.

-Don



## defines a two column matrix
tmpsub <-
structure(c(-337.739799897238, 184.995108083333, 191.915187666667,
191.915187666667, 185.349158666667, 185.326133441305, -21.0945178333333,
-21.2232635, -132.491705916667, -132.620451583333, -339.418178666667,
-387.149289912409, -413.426281562044, -414.136470525547, -338.146251430657,
-337.739799897238, -338.613951361612, -283.102594633440, -283.102594633440,
-182.623434321894, -182.623434321894, -126.691537012447, -128.515403229060,
-40.3618694261276, -40.3618694261276, 42.9280211325047, 44.1439319435797,
129.865644124362, 129.865644124362, 185.815172793583, -338.613951361612,
126.309002505437, 107.131313166667, 107.195686, 87.8194631666667,
87.8194631666667, -172.925954755075, -173.0192575, -223.745050166667,
-223.745050166667, -172.890511833333, -172.890511833333, -172.631459722628,
-173.164101445255, -115.816342642336, -116.171437124088, 126.309002505437,
226.049864194626, 226.049864194626, 195.140131470985, 195.329505335223,
225.119320206559, 225.119320206559, 195.329505335223, 195.937460740761,
225.119320206559, 225.727275612096, 196.545416146298, 195.329505335223,
225.727275612096, 225.734458758671, 226.049864194626), .Dim = c(31L,
2L))



p.s.
I'm actually trying to solve a bigger problem, which is to take two 
adjacent polygons and combine them into a single polygon that 
outlines both of them. Kind of like a convex hull, but I need it to 
trace the outlines of the polygons. The above re-ordering is part of 
one way to solve my bigger problem. But if anyone has suggestions for 
the bigger problem, that would even better.
-- 
---------------------------------
Don MacQueen
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062
macq at llnl.gov


From b.rowlingson at lancaster.ac.uk  Fri Oct  2 09:27:06 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 2 Oct 2009 08:27:06 +0100
Subject: [R-sig-Geo] Put polygon points in correct order
In-Reply-To: <p06240800c6eb329bfd86@192.168.11.5>
References: <OFCC0D647C.E994D1F4-ONC1257638.002CAF8C-C1257638.002CE03C@bdpnet.dk>
	<alpine.LRH.2.00.0909211113460.8279@reclus.nhh.no>
	<p06240800c6eb329bfd86@192.168.11.5>
Message-ID: <d8ad40b50910020027n357a260dh1f0628fecb87cc53@mail.gmail.com>

On Fri, Oct 2, 2009 at 5:52 AM, Don MacQueen <macq at llnl.gov> wrote:
> I have a set of points that form a polygon, except that they are in the
> wrong order. For example, source into R the object "tmpsub" given below.
> Then do
>
> plot(tmpsub)
> polygon(tmpsub)
>
> You will see that although the points define a polygon, they are in the
> wrong order.
>
> I need an algorithm to put them in the correct order. It's not obvious to me
> how to do this.
> (They will then be used to build a SpatialPolygons object.)
>
> Suggestions, or pointers to algorithms, would be much appreciated.

 For the points you gave us I can see several ways of making a
non-self-intersecting polygon. Along the top, for example, you could
either have squares or triangles. Do you have any other constraints?
It looks to me like you only want horizontal and vertical lines in
your polygons. Is that so? That might make a unique  solution
possible...

Barry


From breitbach at uni-mainz.de  Fri Oct  2 09:44:15 2009
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Fri, 2 Oct 2009 09:44:15 +0200
Subject: [R-sig-Geo] Determine the location of the actual R-file
Message-ID: <6634A5A114BA554C927CF724BA5040410162413BEC46@EXCHANGE-02.zdv.uni-mainz.de>

Dear community,

this time my question has something to do with with spatial context but not in the sense we discuss it usually here. I tried to find out if it is possible to ask R for the location (path) of the R-file from which I send the code. What I want to ensure is, that the R code works, no matter where I move the folder with all the necesssary files to. There are some ways to code the location relative to an environment variable (like R.home) but I need the location independent of the directory where R is installed since this is not equal on every users' maschine.

Is there a way to ask R for the path of the r-file from which the line is sent?

I hope that you have some ideas for me ...
Cheers,

Nils

From p.hiemstra at geo.uu.nl  Fri Oct  2 10:23:49 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 02 Oct 2009 10:23:49 +0200
Subject: [R-sig-Geo] Determine the location of the actual R-file
In-Reply-To: <6634A5A114BA554C927CF724BA5040410162413BEC46@EXCHANGE-02.zdv.uni-mainz.de>
References: <6634A5A114BA554C927CF724BA5040410162413BEC46@EXCHANGE-02.zdv.uni-mainz.de>
Message-ID: <4AC5B895.4010102@geo.uu.nl>

Hi Nils,

Getting the current working directory is done using getwd().

I have some comments inline below:

Breitbach, Nils wrote:
> Dear community,
>
> this time my question has something to do with with spatial context but not in the sense we discuss it usually here. I tried to find out if it is possible to ask R for the location (path) of the R-file from which I send the code.
What do you mean by "send the code". You mean that you want to use 
source() to load some functions? But obviously you can't source() a file 
if you don't know where it is located. And a better alternative to 
source might be writing an R-package. I'm confused...
>  What I want to ensure is, that the R code works, no matter where I move the folder with all the necesssary files to. There are some ways to code the location relative to an environment variable (like R.home) but I need the location independent of the directory where R is installed since this is not equal on every users' maschine.
>   
My suggestion would be to wrap the code in an R-package. A user can 
install the R-package and load it easily using library() and you don't 
have to worry about getting the path to the code.
> Is there a way to ask R for the path of the r-file from which the line is sent?
>   
Probably if you use an R-package construction this is not necessary.

cheers,
Paul
> I hope that you have some ideas for me ...
> Cheers,
>
> Nils
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From b.rowlingson at lancaster.ac.uk  Fri Oct  2 10:56:36 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 2 Oct 2009 09:56:36 +0100
Subject: [R-sig-Geo] Determine the location of the actual R-file
In-Reply-To: <6634A5A114BA554C927CF724BA5040410162413BEC46@EXCHANGE-02.zdv.uni-mainz.de>
References: <6634A5A114BA554C927CF724BA5040410162413BEC46@EXCHANGE-02.zdv.uni-mainz.de>
Message-ID: <d8ad40b50910020156u2673e2f4t48e782299402a4d7@mail.gmail.com>

On Fri, Oct 2, 2009 at 8:44 AM, Breitbach, Nils <breitbach at uni-mainz.de> wrote:
> Dear community,
>
> this time my question has something to do with with spatial context but not in the sense we discuss it usually here. I tried to find out if it is possible to ask R for the location (path) of the R-file from which I send the code.

 If you've a question which isn't to do with the usual R-sig-geo
spatial context, then it's probably better asked on the R-help mailing
list. I recall a similar question on there a few weeks back, where the
user was running R from a script or a batch file or something, and you
could get the path to the script from the command arguments. I can't
recall the details, you'll have to search the archives!

Barry


From jonas.vonruette at env.ethz.ch  Fri Oct  2 11:30:38 2009
From: jonas.vonruette at env.ethz.ch (=?iso-8859-1?Q?von_R=FCtte__Jonas?=)
Date: Fri, 2 Oct 2009 11:30:38 +0200
Subject: [R-sig-Geo] Importing ESRI Shapefile into RSAGA
Message-ID: <370425B9919B8F4C926A49EFE292FDA39CAD21@EX7.d.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091002/664a0e01/attachment.pl>

From p.hiemstra at geo.uu.nl  Fri Oct  2 11:54:12 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 02 Oct 2009 11:54:12 +0200
Subject: [R-sig-Geo] Importing ESRI Shapefile into RSAGA
In-Reply-To: <370425B9919B8F4C926A49EFE292FDA39CAD21@EX7.d.ethz.ch>
References: <370425B9919B8F4C926A49EFE292FDA39CAD21@EX7.d.ethz.ch>
Message-ID: <4AC5CDC4.2040200@geo.uu.nl>

Hi,

A quick google showed that SAGA supports the GDAL library for data 
import and export. This library should (specifically the OGR part) 
supports ESRI shapefile (http://www.gdal.org/ogr/drv_shapefile.html). So 
I think you must be more specific on which commands you used to try and 
load the shapefile, which version of RSAGA, R, SAGA you are using. If 
you have GDAL installed, if so, which version. Check if that version 
supports shapefiles, if not, get a version that does.

cheers,
Paul

von R?tte Jonas wrote:
> Hello!
>
>  
>
> I have a more general problem
>
> Is there a way to import ESRI shapfiles into RSAGA? 
>
> And if yes how can I then import it to SAGA GIS since it seems to not support the ESRI format.
>
>  
>
> Thanks in advance
>
>  
>
> Jonas 
>
> Soil and Terrestrial Environmental Physics 
>
> ETH Zurich 
>
>
>
>  
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From hengl at spatial-analyst.net  Fri Oct  2 12:10:16 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Fri, 2 Oct 2009 12:10:16 +0200
Subject: [R-sig-Geo] Importing ESRI Shapefile into RSAGA
In-Reply-To: <370425B9919B8F4C926A49EFE292FDA39CAD21@EX7.d.ethz.ch>
References: <370425B9919B8F4C926A49EFE292FDA39CAD21@EX7.d.ethz.ch>
Message-ID: <836935DC3610494CAFDEB4B3060DF17F@pcibed193>


Jonas,

SAGA (GUI) can read and write shape files. This is the native vector format it uses. Maybe this is
confusing, but RSAGA is NOT a GIS package under R, but only a link to send things from R to SAGA and
back.

Here are some examples:

http://spatial-analyst.net/wiki/index.php?title=Export_maps_to_GE#Polygon_maps 

HTH,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of von R?tte Jonas
> Sent: Friday, October 02, 2009 11:31 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Importing ESRI Shapefile into RSAGA
> 
> Hello!
> 
> 
> 
> I have a more general problem
> 
> Is there a way to import ESRI shapfiles into RSAGA?
> 
> And if yes how can I then import it to SAGA GIS since it seems to not support the ESRI format.
> 
> 
> 
> Thanks in advance
> 
> 
> 
> Jonas
> 
> Soil and Terrestrial Environmental Physics
> 
> ETH Zurich
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From nikko at hailmail.net  Fri Oct  2 18:09:52 2009
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Fri, 02 Oct 2009 09:09:52 -0700
Subject: [R-sig-Geo]  Put polygon points in correct order
In-Reply-To: <mailman.17.1254477603.13788.r-sig-geo@stat.math.ethz.ch>
References: <mailman.17.1254477603.13788.r-sig-geo@stat.math.ethz.ch>
Message-ID: <1254499792.25409.1337756419@webmail.messagingengine.com>

Hi Don,
If your polygons are all convex, then there is hope. If not
then it can only be done with added constraints, there is
not enough information in the coordinates alone to order them
except up to an approximation. If they are convex, just
compute the convex hull. If not, you could try computing the convex hull
and project points onto the closest edge (perpendicular distance), that
would give you an ordering but it would be approximate.

Nicholas 

 
> Message: 6
> Date: Thu, 1 Oct 2009 21:52:33 -0700
> From: Don MacQueen <macq at llnl.gov>
> Subject: [R-sig-Geo] Put polygon points in correct order
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <p06240800c6eb329bfd86@[192.168.11.5]>
> Content-Type: text/plain; charset="us-ascii" ; format="flowed"
> 
> I have a set of points that form a polygon, except that they are in 
> the wrong order. For example, source into R the object "tmpsub" given 
> below. Then do
> 
> plot(tmpsub)
> polygon(tmpsub)
> 
> You will see that although the points define a polygon, they are in 
> the wrong order.
> 
> I need an algorithm to put them in the correct order. It's not 
> obvious to me how to do this.
> (They will then be used to build a SpatialPolygons object.)
> 
> Suggestions, or pointers to algorithms, would be much appreciated.
> 
> -Don
> 
> 
> 
> ## defines a two column matrix
> tmpsub <-
> structure(c(-337.739799897238, 184.995108083333, 191.915187666667,
> 191.915187666667, 185.349158666667, 185.326133441305, -21.0945178333333,
> -21.2232635, -132.491705916667, -132.620451583333, -339.418178666667,
> -387.149289912409, -413.426281562044, -414.136470525547,
> -338.146251430657,
> -337.739799897238, -338.613951361612, -283.102594633440,
> -283.102594633440,
> -182.623434321894, -182.623434321894, -126.691537012447,
> -128.515403229060,
> -40.3618694261276, -40.3618694261276, 42.9280211325047, 44.1439319435797,
> 129.865644124362, 129.865644124362, 185.815172793583, -338.613951361612,
> 126.309002505437, 107.131313166667, 107.195686, 87.8194631666667,
> 87.8194631666667, -172.925954755075, -173.0192575, -223.745050166667,
> -223.745050166667, -172.890511833333, -172.890511833333,
> -172.631459722628,
> -173.164101445255, -115.816342642336, -116.171437124088,
> 126.309002505437,
> 226.049864194626, 226.049864194626, 195.140131470985, 195.329505335223,
> 225.119320206559, 225.119320206559, 195.329505335223, 195.937460740761,
> 225.119320206559, 225.727275612096, 196.545416146298, 195.329505335223,
> 225.727275612096, 225.734458758671, 226.049864194626), .Dim = c(31L,
> 2L))
> 
> 
> 
> p.s.
> I'm actually trying to solve a bigger problem, which is to take two 
> adjacent polygons and combine them into a single polygon that 
> outlines both of them. Kind of like a convex hull, but I need it to 
> trace the outlines of the polygons. The above re-ordering is part of 
> one way to solve my bigger problem. But if anyone has suggestions for 
> the bigger problem, that would even better.
> -- 
> ---------------------------------
> Don MacQueen
> Lawrence Livermore National Laboratory
> Livermore, CA, USA
> 925-423-1062
> macq at llnl.gov
> 
> 
> 
> ------------------------------
> 
> Message: 7
> Date: Fri, 2 Oct 2009 08:27:06 +0100
> From: Barry Rowlingson <b.rowlingson at lancaster.ac.uk>
> Subject: Re: [R-sig-Geo] Put polygon points in correct order
> To: Don MacQueen <macq at llnl.gov>
> Cc: r-sig-geo at stat.math.ethz.ch
> Message-ID:
> 	<d8ad40b50910020027n357a260dh1f0628fecb87cc53 at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
> 
> On Fri, Oct 2, 2009 at 5:52 AM, Don MacQueen <macq at llnl.gov> wrote:
> > I have a set of points that form a polygon, except that they are in the
> > wrong order. For example, source into R the object "tmpsub" given below.
> > Then do
> >
> > plot(tmpsub)
> > polygon(tmpsub)
> >
> > You will see that although the points define a polygon, they are in the
> > wrong order.
> >
> > I need an algorithm to put them in the correct order. It's not obvious to me
> > how to do this.
> > (They will then be used to build a SpatialPolygons object.)
> >
> > Suggestions, or pointers to algorithms, would be much appreciated.
> 
>  For the points you gave us I can see several ways of making a
> non-self-intersecting polygon. Along the top, for example, you could
> either have squares or triangles. Do you have any other constraints?
> It looks to me like you only want horizontal and vertical lines in
> your polygons. Is that so? That might make a unique  solution
> possible...
> 
> Barry
> 
> 
>


From maurizio at staffmail.ed.ac.uk  Sat Oct  3 00:32:25 2009
From: maurizio at staffmail.ed.ac.uk (Maurizio Mencuccini)
Date: Sat, 03 Oct 2009 00:32:25 +0200
Subject: [R-sig-Geo] how to test for effect of spatial scale
Message-ID: <4AC67F79.4020809@staffmail.ed.ac.uk>

Hi there,

I have a dataset consisting of measurements of tree size taken in more 
than 200 forest plots along a regular grid within a forest. For each 
plot, i can build summary statistics such as frequency distributions of 
such characters (e.g., height, diameters, etc).
I have the expectation that such distribution would conform to a 
theoretical distribution at a very large spatial scale and indeed if I 
aggregate all data for all plots, my empirical curve fits the expected 
curve rather well.
My objective is to detect at what spatial scale would such a theoretical 
prediction begin to break down, i.e., if I begin to disaggregate the 
data to include all the (n-1) plots close to each other, all the (n-2), 
etc., down to statistics collected independently for each plot, when 
does the mean distribution calculated for all possible combinations at 
that scale begin to depart significantly from the expected curve.
I cannot figure out how to approach the problem. It is not point 
pattern, nor does it seem to be geostatistics (building a semi variogram 
would help but only partially). The question is really about data 
aggregation at different spatial scales for plots that are close to each 
other.

Any help appreciated.

thanks
Maurizio Mencuccini
school of Geosciences
University of Edinburgh (UK)

-- 
The University of Edinburgh is a charitable body, registered in
Scotland, with registration number SC005336.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: maurizio.vcf
Type: text/x-vcard
Size: 357 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091003/731bf58c/attachment.vcf>

From mdsumner at gmail.com  Sun Oct  4 05:18:10 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 4 Oct 2009 14:18:10 +1100
Subject: [R-sig-Geo] curious about 4D interpolations
In-Reply-To: <522664f80910032015l16a1aa64u3e33d8a591b868f0@mail.gmail.com>
References: <441EEB69-B42B-4C8E-823E-34D04949C7B6@wzw.tum.de>
	<0838E01493845742A4D4039EA34EB1C18CD5B2@ieopalma2.ba.ieo.es>
	<522664f80910032015l16a1aa64u3e33d8a591b868f0@mail.gmail.com>
Message-ID: <522664f80910032018g4e1ccf9fwe6c00ddaeae2fc91@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091004/341fecbe/attachment.pl>

From Allen.McIlwee at sa.gov.au  Sun Oct  4 09:44:35 2009
From: Allen.McIlwee at sa.gov.au (McIlwee, Allen (DEH))
Date: Sun, 4 Oct 2009 18:14:35 +1030
Subject: [R-sig-Geo] Appending numerous polygons to a single shapefile
Message-ID: <ADEB8CB61863F9468ECD0626B7B1C042199F6C30BB@EMSCM005.sagemsmrd01.sa.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091004/523eca63/attachment.pl>

From jmblanco at ub.edu  Sun Oct  4 20:12:44 2009
From: jmblanco at ub.edu (=?ISO-8859-1?Q?=22Jos=E9_M=2E_Blanco_Moreno=22?=)
Date: Sun, 04 Oct 2009 20:12:44 +0200
Subject: [R-sig-Geo] doubt with readGDAL
Message-ID: <4AC8E59C.605@ub.edu>

Dear R-users community,
I have been trying to figure out on my own, but no way...
I am trying to read and decimate a geotiff:

library(maptools)
library(spatial)
library(sp)
library(rgdal)

download.file(url='http://srtm.geog.kcl.ac.uk/portal/srtm41/srtm_data_arcascii/srtm_37_04.zip',destfile='srtm_37_04.zip')
shell('unzip -o srtm_37_04.zip')
cata <- 
readGDAL('srtm_37_04.tif',offset=c(2900,0),region.dim=c(2600,5000),output.dim=c(260,500))
cata2 <- cata
cata2 at data$band1 <- ifelse(is.na(cata2 at data$band1),-1,cata2 at data$band1)
cata2 at data$band1 <- 
c(50,100,250,500,1000,1500,2000,3000)[cut(cata at data$band1,c(0,50,100,250,500,1000,1500,2000,3000))]
image(cata2,col=gray(seq(.9,0.6,length=9)))
contour(cata2,add=T,levels=c(0,50,100,250,500,1000,1500,2000,3000),col=gray(.7),drawlabels=F)
axis(1)
axis(2)

But the coordinates don't come out: they are translated in the y-axis *a 
lot*; bbox(cata) returns:
            min        max
x -4.166183e-04   5.000417
y -1.577894e+01 -10.778109

While in the non-decimated version they are:
            min      max
x -0.0004166183  4.16625
y 40.4170835754 42.58375

Could anyone indicate a workaround to preserve the coordinates of the grid?
Thank you for any information on this issue (which I suppose is 
generated by my own incompetence).

Jos? M.

sessionInfo()
R version 2.8.1 (2008-12-22)
i386-pc-mingw32

locale:
LC_COLLATE=Spanish_Spain.1252;LC_CTYPE=Spanish_Spain.1252;LC_MONETARY=Spanish_Spain.1252;LC_NUMERIC=C;LC_TIME=Spanish_Spain.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    

other attached packages:
[1] rgdal_0.6-8     spatial_7.2-47  maptools_0.7-25 sp_0.9-37       
foreign_0.8-36

loaded via a namespace (and not attached):
[1] grid_2.8.1      lattice_0.17-25


-- 
---------------------------------------
Jos? M. Blanco-Moreno

Dept. de Biologia Vegetal (Bot?nica)
Facultat de Biologia
Universitat de Barcelona
Av. Diagonal 645
08028 Barcelona
SPAIN
---------------------------------------

http://www.ub.edu/agroecologia/

phone: (+34) 934 039 863
fax: (+34) 934 112 842


From Roger.Bivand at nhh.no  Sun Oct  4 20:13:08 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 4 Oct 2009 20:13:08 +0200 (CEST)
Subject: [R-sig-Geo] Appending numerous polygons to a single shapefile
In-Reply-To: <ADEB8CB61863F9468ECD0626B7B1C042199F6C30BB@EMSCM005.sagemsmrd01.sa.gov.au>
References: <ADEB8CB61863F9468ECD0626B7B1C042199F6C30BB@EMSCM005.sagemsmrd01.sa.gov.au>
Message-ID: <alpine.LRH.2.00.0910042005120.27982@reclus.nhh.no>

On Sun, 4 Oct 2009, McIlwee, Allen (DEH) wrote:

> Hi all
>
> I have a script that plots alpha hulls, which I am using to investigate 
> the timing & extent of range size collapses for hundreds of plant 
> species across South Australia.
>
> I'm sure this must be an easy question for most - but I am having 
> trouble generating a shapefile that contains all the remaining triangles 
> for a species, given a particular alpha value. The script below will 
> give me a separate shapefile for every polygon, but I don't fancy 
> piecing these together manually in ArcGIS.
>
> Is there an easy way to join together consecutive polygons so that the 
> last item is the union of them all?
>
> Thanks
> Allen
>
> alpha1a<-data.frame(xx, yy)
> alpha1b<-rbind(alpha1a,alpha1a[1,])
> alpha1c<-Polygon(alpha1b)
> alpha1d<-Polygons(list(alpha1c),"1")
> alpha1e<-SpatialPolygons(list(alpha1d),1:1)
> alpha1_data<-data.frame(cbind(alpha1a))
> alpha1_df<-SpatialPolygonsDataFrame(alpha1e,alpha1_data)
> writeOGR(alpha1_df,"c:/R/AlphaHulls/Shapefiles",paste(this.sp,"alpha1",i,sep=" "),"ESRI Shapefile")
>
> I can provide more detail on other parts of the script if need be?

If they do not overlap, you could simply build a SpatialPolygons object 
from a list of the Polygons objects, one for each alpha hull. If you need 
polygon union as such, see unionSpatialPolygons() in maptools, or the 
interface there to gpclib polygon handling. The gpclib package could also 
handle overlaps.

Hope this helps,

Roger

>
> Allen McIlwee
> NatureLinks Policy Support Officer
> Nature Conservation Branch
>
> Department for Environment and Heritage
> Richmond Rd, KESWICK
> T: 61+ 8+ 8124 4733
> F: 61+ 8+ 8463 4818
> E: allen.mcilwee at sa.gov.au
> M: 0427 255 367
> A: GPO Box 1047, Adelaide, SA, 5001 AUSTRALIA
>
> <http://www.environment.sa.gov.au>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Sun Oct  4 20:34:17 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 4 Oct 2009 19:34:17 +0100
Subject: [R-sig-Geo] doubt with readGDAL
In-Reply-To: <4AC8E59C.605@ub.edu>
References: <4AC8E59C.605@ub.edu>
Message-ID: <d8ad40b50910041134x1c86c4d5haa899860e7859674@mail.gmail.com>

2009/10/4 "Jos? M. Blanco Moreno" <jmblanco at ub.edu>:
> Dear R-users community,
> I have been trying to figure out on my own, but no way...
> I am trying to read and decimate a geotiff:
>
> library(maptools)
> library(spatial)
> library(sp)
> library(rgdal)
>
> download.file(url='http://srtm.geog.kcl.ac.uk/portal/srtm41/srtm_data_arcascii/srtm_37_04.zip',destfile='srtm_37_04.zip')
> shell('unzip -o srtm_37_04.zip')
> cata <-
> readGDAL('srtm_37_04.tif',offset=c(2900,0),region.dim=c(2600,5000),output.dim=c(260,500))
> cata2 <- cata
> cata2 at data$band1 <- ifelse(is.na(cata2 at data$band1),-1,cata2 at data$band1)
> cata2 at data$band1 <-
> c(50,100,250,500,1000,1500,2000,3000)[cut(cata at data$band1,c(0,50,100,250,500,1000,1500,2000,3000))]
> image(cata2,col=gray(seq(.9,0.6,length=9)))
> contour(cata2,add=T,levels=c(0,50,100,250,500,1000,1500,2000,3000),col=gray(.7),drawlabels=F)
> axis(1)
> axis(2)
>
> But the coordinates don't come out: they are translated in the y-axis *a
> lot*; bbox(cata) returns:
> ? ? ? ? ? min ? ? ? ?max
> x -4.166183e-04 ? 5.000417
> y -1.577894e+01 -10.778109
>
> While in the non-decimated version they are:
> ? ? ? ? ? min ? ? ?max
> x -0.0004166183 ?4.16625
> y 40.4170835754 42.58375
>
> Could anyone indicate a workaround to preserve the coordinates of the grid?
> Thank you for any information on this issue (which I suppose is generated by
> my own incompetence).

 I just cut and pasted your example - firstly there's no tiff in that
zip, there's a .asc (Arc GRID) file instead. I read that in with
readGDAL, and got:

> bbox(cata)
            min        max
x -4.166183e-04   5.000417
y -1.577894e+01 -10.778109
> bbox(cata2)
            min        max
x -4.166183e-04   5.000417
y -1.577894e+01 -10.778109

 which looks okay. So maybe its to do with the tiff file which you
must have made somehow - projections maybe?

Barry


From Roger.Bivand at nhh.no  Sun Oct  4 21:44:22 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 4 Oct 2009 21:44:22 +0200 (CEST)
Subject: [R-sig-Geo] doubt with readGDAL
In-Reply-To: <4AC8E59C.605@ub.edu>
References: <4AC8E59C.605@ub.edu>
Message-ID: <alpine.LRH.2.00.0910042132190.27982@reclus.nhh.no>

On Sun, 4 Oct 2009, "Jos? M. Blanco Moreno" wrote:

> Dear R-users community,
> I have been trying to figure out on my own, but no way...
> I am trying to read and decimate a geotiff:
>
> library(maptools)
> library(spatial)
> library(sp)
> library(rgdal)
>
> download.file(url='http://srtm.geog.kcl.ac.uk/portal/srtm41/srtm_data_arcascii/srtm_37_04.zip',destfile='srtm_37_04.zip')
> shell('unzip -o srtm_37_04.zip')
> cata <- 
> readGDAL('srtm_37_04.tif',offset=c(2900,0),region.dim=c(2600,5000),output.dim=c(260,500))
> cata2 <- cata
> cata2 at data$band1 <- ifelse(is.na(cata2 at data$band1),-1,cata2 at data$band1)
> cata2 at data$band1 <- 
> c(50,100,250,500,1000,1500,2000,3000)[cut(cata at data$band1,c(0,50,100,250,500,1000,1500,2000,3000))]
> image(cata2,col=gray(seq(.9,0.6,length=9)))
> contour(cata2,add=T,levels=c(0,50,100,250,500,1000,1500,2000,3000),col=gray(.7),drawlabels=F)
> axis(1)
> axis(2)
>
> But the coordinates don't come out: they are translated in the y-axis *a 
> lot*; bbox(cata) returns:
>           min        max
> x -4.166183e-04   5.000417
> y -1.577894e+01 -10.778109
>
> While in the non-decimated version they are:
>           min      max
> x -0.0004166183  4.16625
> y 40.4170835754 42.58375

Thanks for a clear report - the y range and the cell sizes were wrong when 
all three of offset=, region.dim= and output.dim= were used together. With 
current rgdal 0.6-18, using the Arc ASCII file (not GTiff), I see for the 
undecimated subscene:

> gridparameters(catb)
   cellcentre.offset     cellsize cells.dim
x      4.839851e-08 0.0008333333      5000
y      4.041750e+01 0.0008333333      2600
> bbox(catb)
             min      max
x -0.0004166183  4.16625
y 40.4170835754 42.58375

but for the decimated subscene:

> gridparameters(cata)
   cellcentre.offset   cellsize cells.dim
x       0.004584215 0.01000167       500
y     -15.769325078 0.01923397       260
> bbox(cata)
             min        max
x -4.166183e-04   5.000417
y -1.577894e+01 -10.778109


In forthcoming 0.6-19 (committed to the sourceforge rgdal repository) and 
the undecimated subscene:

> gridparameters(catb)
   cellcentre.offset     cellsize cells.dim
x      4.839851e-08 0.0008333333      5000
y      4.041750e+01 0.0008333333      2600
> bbox(catb)
             min      max
x -0.0004166183  4.16625
y 40.4170835754 42.58375

with the decimated subscene now corresponding:

> gridparameters(cata)
   cellcentre.offset    cellsize cells.dim
x       0.003750048 0.008333333       500
y      40.421250242 0.008333333       260
> bbox(cata)
             min      max
x -0.0004166183  4.16625
y 40.4170835754 42.58375

This is with this subscene on this data set - I would be very grateful if 
anyone could check from a source install after checking out from 
sourceforge for other, including Southern hemisphere decimated subscenes 
(there is a sign wrinkle). I'll wait for feedback before submitting to 
CRAN.

Again, thanks for a helpful report!

Roger

>
> Could anyone indicate a workaround to preserve the coordinates of the grid?
> Thank you for any information on this issue (which I suppose is generated by 
> my own incompetence).
>
> Jos? M.
>
> sessionInfo()
> R version 2.8.1 (2008-12-22)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Spanish_Spain.1252;LC_CTYPE=Spanish_Spain.1252;LC_MONETARY=Spanish_Spain.1252;LC_NUMERIC=C;LC_TIME=Spanish_Spain.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base 
> other attached packages:
> [1] rgdal_0.6-8     spatial_7.2-47  maptools_0.7-25 sp_0.9-37 
> foreign_0.8-36
>
> loaded via a namespace (and not attached):
> [1] grid_2.8.1      lattice_0.17-25
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From b.rowlingson at lancaster.ac.uk  Sun Oct  4 21:56:27 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 4 Oct 2009 20:56:27 +0100
Subject: [R-sig-Geo] doubt with readGDAL
In-Reply-To: <alpine.LRH.2.00.0910042132190.27982@reclus.nhh.no>
References: <4AC8E59C.605@ub.edu>
	<alpine.LRH.2.00.0910042132190.27982@reclus.nhh.no>
Message-ID: <d8ad40b50910041256l7cf3af1ey6f81be7419816acb@mail.gmail.com>

2009/10/4 Roger Bivand <Roger.Bivand at nhh.no>:

> Thanks for a clear report - the y range and the cell sizes were wrong when
> all three of offset=, region.dim= and output.dim= were used together. With
> current rgdal 0.6-18, using the Arc ASCII file (not GTiff), I see for the
> undecimated subscene:
>
>> gridparameters(catb)
>
> ?cellcentre.offset ? ? cellsize cells.dim
> x ? ? ?4.839851e-08 0.0008333333 ? ? ?5000
> y ? ? ?4.041750e+01 0.0008333333 ? ? ?2600
>>
>> bbox(catb)
>
> ? ? ? ? ? ?min ? ? ?max
> x -0.0004166183 ?4.16625
> y 40.4170835754 42.58375
>
> but for the decimated subscene:
>
>> gridparameters(cata)
>
> ?cellcentre.offset ? cellsize cells.dim
> x ? ? ? 0.004584215 0.01000167 ? ? ? 500
> y ? ? -15.769325078 0.01923397 ? ? ? 260
>>
>> bbox(cata)
>
> ? ? ? ? ? ?min ? ? ? ?max
> x -4.166183e-04 ? 5.000417
> y -1.577894e+01 -10.778109
>
>
> In forthcoming 0.6-19 (committed to the sourceforge rgdal repository) and
> the undecimated subscene:

 I'm using: Rgdal=0.6-18 with R=2.9.2, sp=0.9-37and I don't see this
problem (see my previous post).

Barry


From Roger.Bivand at nhh.no  Sun Oct  4 22:26:35 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 4 Oct 2009 22:26:35 +0200 (CEST)
Subject: [R-sig-Geo] doubt with readGDAL
In-Reply-To: <d8ad40b50910041256l7cf3af1ey6f81be7419816acb@mail.gmail.com>
References: <4AC8E59C.605@ub.edu>
	<alpine.LRH.2.00.0910042132190.27982@reclus.nhh.no>
	<d8ad40b50910041256l7cf3af1ey6f81be7419816acb@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0910042218370.27982@reclus.nhh.no>

On Sun, 4 Oct 2009, Barry Rowlingson wrote:

> 2009/10/4 Roger Bivand <Roger.Bivand at nhh.no>:
>
>> Thanks for a clear report - the y range and the cell sizes were wrong when
>> all three of offset=, region.dim= and output.dim= were used together. With
>> current rgdal 0.6-18, using the Arc ASCII file (not GTiff), I see for the
>> undecimated subscene:
>>
>>> gridparameters(catb)
>>
>> ?cellcentre.offset ? ? cellsize cells.dim
>> x ? ? ?4.839851e-08 0.0008333333 ? ? ?5000
>> y ? ? ?4.041750e+01 0.0008333333 ? ? ?2600
>>>
>>> bbox(catb)
>>
>> ? ? ? ? ? ?min ? ? ?max
>> x -0.0004166183 ?4.16625
>> y 40.4170835754 42.58375
>>
>> but for the decimated subscene:
>>
>>> gridparameters(cata)
>>
>> ?cellcentre.offset ? cellsize cells.dim
>> x ? ? ? 0.004584215 0.01000167 ? ? ? 500
>> y ? ? -15.769325078 0.01923397 ? ? ? 260
>>>
>>> bbox(cata)
>>
>> ? ? ? ? ? ?min ? ? ? ?max
>> x -4.166183e-04 ? 5.000417
>> y -1.577894e+01 -10.778109
>>
>>
>> In forthcoming 0.6-19 (committed to the sourceforge rgdal repository) and
>> the undecimated subscene:
>
> I'm using: Rgdal=0.6-18 with R=2.9.2, sp=0.9-37and I don't see this
> problem (see my previous post).

The area is a 5 degree by 5 degree part of the Mediteranean coast, as:

> GDALinfo("srtm_37_04.asc")
rows        6001
columns     6001
bands       1
origin.x        -0.0004166183
origin.y        39.99958
res.x       0.0008333333
res.y       0.0008333333
oblique.x   0
oblique.y   0
driver      AAIGrid
projection  +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
file        srtm_37_04.asc
apparent band summary:
   GDType        Bmin       Bmax
1  Int32 -2147483648 2147483647

indicates - filled out by running gdalinfo on the file:

> system("gdalinfo srtm_37_04.asc")
Driver: AAIGrid/Arc/Info ASCII Grid
Files: srtm_37_04.asc
        srtm_37_04.prj
Size is 6001, 6001
Coordinate System is:
GEOGCS["WGS 84",
     DATUM["WGS_1984",
         SPHEROID["WGS 84",6378137,298.257223563,
             AUTHORITY["EPSG","7030"]],
         TOWGS84[0,0,0,0,0,0,0],
         AUTHORITY["EPSG","6326"]],
     PRIMEM["Greenwich",0,
         AUTHORITY["EPSG","8901"]],
     UNIT["degree",0.0174532925199433,
         AUTHORITY["EPSG","9108"]],
     AUTHORITY["EPSG","4326"]]
Origin = (-0.000416618268153,45.000416908780309)
Pixel Size = (0.000833333333333,-0.000833333333333)
Corner Coordinates:
Upper Left  (  -0.0004166,  45.0004169) (  0d 0'1.50"W, 45d 0'1.50"N)
Lower Left  (  -0.0004166,  39.9995836) (  0d 0'1.50"W, 39d59'58.50"N)
Upper Right (   5.0004167,  45.0004169) (  5d 0'1.50"E, 45d 0'1.50"N)
Lower Right (   5.0004167,  39.9995836) (  5d 0'1.50"E, 39d59'58.50"N)
Center      (   2.5000000,  42.5000002) (  2d30'0.00"E, 42d30'0.00"N)
Band 1 Block=6001x1 Type=Int32, ColorInterp=Undefined
   NoData Value=-9999

The "logic" in readGDAL() was shot when both subscene selection and 
decimation were used. Try dropping the decimation, and you'll see the 
difference; cata and cata2 in the bug report have the same grid 
parameters.

Roger


>
> Barry
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From jmblanco at ub.edu  Sun Oct  4 23:08:12 2009
From: jmblanco at ub.edu (=?ISO-8859-15?Q?Jos=E9_Manuel_Blanco_Moreno?=)
Date: Sun, 04 Oct 2009 23:08:12 +0200
Subject: [R-sig-Geo] doubt with readGDAL
In-Reply-To: <alpine.LRH.2.00.0910042218370.27982@reclus.nhh.no>
References: <4AC8E59C.605@ub.edu>
	<alpine.LRH.2.00.0910042132190.27982@reclus.nhh.no>
	<d8ad40b50910041256l7cf3af1ey6f81be7419816acb@mail.gmail.com>
	<alpine.LRH.2.00.0910042218370.27982@reclus.nhh.no>
Message-ID: <4AC90EBC.3070606@ub.edu>

Thank you very much for the info, and excuse my confusion: I have copied 
and pasted different chunks of code while trying both the ascii file and 
the geotiff, which can be obtained with:
download.file(url='http://srtm.geog.kcl.ac.uk/portal/srtm41/srtm_data_geotiff/srtm_37_04.zip',destfile='srtm_37_04_tif.zip')
However, I get exactly the same problem with both files when I set up 
the output.dim argument.

Jos? M.


From MarburgA at landcareresearch.co.nz  Mon Oct  5 01:14:05 2009
From: MarburgA at landcareresearch.co.nz (Anna Marburg)
Date: Mon, 5 Oct 2009 12:14:05 +1300
Subject: [R-sig-Geo] how to test for effect of spatial scale
In-Reply-To: <mailman.15.1254564003.24339.r-sig-geo@stat.math.ethz.ch>
References: <mailman.15.1254564003.24339.r-sig-geo@stat.math.ethz.ch>
Message-ID: <4550E4F1-3DBC-4983-937D-877A09763607@landcareresearch.co.nz>

Dear Maurizio -

it sounds as though your data are what my spatial stats teacher called
"lattice" data.

The particular analysis you propose - repeatedly aggregating different
blocks of data together and then comparing across scales; sounds like
the "grieg-smith" approach to testing for spatial randomness; and the
"two term local quadrat variance (TTLQV)" approach for identifying
patches.

For more a general background on lattice (aka areal) data, try chapter
9 in Bivand et al (2009) Applied spatial data analysis with R and
section 2.6 in Fortin and Dale (2005) Spatial Analysis: A guide for
Ecologists.

It may also be that the spatially explicit nature of your data is a
red herring in this case and what you're really after is something
like rarefaction or bootstrapping.

Cheers,

Anna

> [...]
> My objective is to detect at what spatial scale would such a
> theoretical
> prediction begin to break down, i.e., if I begin to disaggregate the
> data to include all the (n-1) plots close to each other, all the
> (n-2),
> etc., down to statistics collected independently for each plot, when
> does the mean distribution calculated for all possible combinations at
> that scale begin to depart significantly from the expected curve.
> I cannot figure out how to approach the problem. It is not point
> pattern, nor does it seem to be geostatistics (building a semi
> variogram
> would help but only partially). The question is really about data
> aggregation at different spatial scales for plots that are close to
> each
> other.
>
> Any help appreciated.
>
> thanks
> Maurizio Mencuccini
> school of Geosciences
> University of Edinburgh (UK)

Dr. Anna E.  Marburg

Postdoctoral researcher
Ecosystem Processes Team
Landcare Research
P O Box 40
Lincoln 7640
NEW ZEALAND

phone + 64  3 321 9729
MarbugA at landcareresearch.co.nz




Please consider the environment before printing this email
Warning:  This electronic message together with any attachments is confidential. If you receive it in error: (i) you must not read, use, disclose, copy or retain it; (ii) please contact the sender immediately by reply email and then delete the emails.
The views expressed in this email may not be those of Landcare Research New Zealand Limited. http://www.landcareresearch.co.nz


From Roger.Bivand at nhh.no  Mon Oct  5 15:55:37 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 5 Oct 2009 15:55:37 +0200 (CEST)
Subject: [R-sig-Geo] doubt with readGDAL
In-Reply-To: <4AC90EBC.3070606@ub.edu>
References: <4AC8E59C.605@ub.edu>
	<alpine.LRH.2.00.0910042132190.27982@reclus.nhh.no>
	<d8ad40b50910041256l7cf3af1ey6f81be7419816acb@mail.gmail.com>
	<alpine.LRH.2.00.0910042218370.27982@reclus.nhh.no>
	<4AC90EBC.3070606@ub.edu>
Message-ID: <alpine.LRH.2.00.0910051553440.2952@reclus.nhh.no>

On Sun, 4 Oct 2009, Jos? Manuel Blanco Moreno wrote:

> Thank you very much for the info, and excuse my confusion: I have copied and 
> pasted different chunks of code while trying both the ascii file and the 
> geotiff, which can be obtained with:
> download.file(url='http://srtm.geog.kcl.ac.uk/portal/srtm41/srtm_data_geotiff/srtm_37_04.zip',destfile='srtm_37_04_tif.zip')
> However, I get exactly the same problem with both files when I set up the 
> output.dim argument.

Fixed rgdal submitted to CRAN, should appear soon. There was a similar 
problem in the Eastings - in both cases the offset was being multiplied by 
the decimated (coarser) cell resolution rather than by the appropriate 
value. The offset is now rescaled by the degree of decimation.

Roger

>
> Jos? M.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From enrico.guastaldi at gmail.com  Mon Oct  5 18:04:27 2009
From: enrico.guastaldi at gmail.com (Enrico Guastaldi)
Date: Mon, 5 Oct 2009 18:04:27 +0200
Subject: [R-sig-Geo] AI-GEOSTATS: Interpolation of measures with
	measurement errors
In-Reply-To: <B75D14CABA98774E938782E38A29368035D8368611@EXCHANGEMB.campus.aston.ac.uk>
References: <7ce8d7d30909280554w7c5bbd38l4555e650e6dbedaf@mail.gmail.com>
	<B75D14CABA98774E938782E38A29368035D8368611@EXCHANGEMB.campus.aston.ac.uk>
Message-ID: <7ce8d7d30910050904p48ba36a5nc20ad213e13d3b5f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091005/feb0a7a1/attachment.pl>

From harryk at cal.berkeley.edu  Tue Oct  6 19:22:44 2009
From: harryk at cal.berkeley.edu (Harry Kim)
Date: Tue, 6 Oct 2009 10:22:44 -0700
Subject: [R-sig-Geo] Determining a coordinate given another coordinate,
	a great circle 	distance, and an angle
Message-ID: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>

Dear R-sig-geoers,

      I am stuck with a problem and i was hoping if you could help me.
Suppose i am given a coordinate in lat/long (say 25 lat 35 long) and a
great circle distance (say 10km). Also assume that i am given an angle
with respect to latitude (an angle from the x-axis say 30 degrees).
What would be the best way to determine a coordinate 10kms away from
25 lat 35 long with a given angle (30 degrees)?

     I think in euclidean space, I can use tangent of the given angle
and combine with the Pythagorean theorem to find the target
coordinate.

Thank you very much in advance,
Harry


From hengl at spatial-analyst.net  Wed Oct  7 10:36:14 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Wed, 7 Oct 2009 10:36:14 +0200
Subject: [R-sig-Geo] Determining a coordinate given another coordinate,
	a great circle 	distance, and an angle
In-Reply-To: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>
References: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>
Message-ID: <EA739A8014FC4B43B2B0F798AB5B8F95@pcibed193>


Hi Harry,

The key issue is that you need to select the (Euclidean) coordinate system. For example, to
represent the whole world, there are many possiblities
(http://www.radicalcartography.net/?projectionref). If you are working with the great circle
distance, make sure that the geographic coordinate system uses a sphere. Say if you want to use some
equidistant coordinate system with center at 0,0 longlat (Lambert Azimuthal Equal-Area), you could
then get the coordinates by using:

> P1 <- data.frame(E=35, N=25)
> lambda <- 60  # azimuth!
> dist12 <- 300000
> coordinates(P1) <- ~E+N
> proj4string(P1) <- CRS("+proj=longlat +datum=WGS84")
> P1.xy <- spTransform(P1, CRS("+proj=laea +lat_0 +lon_0 +x_0 +y_0"))
> P2.xy <- data.frame(E=P1.xy at coords[1,1]+dist12*sin(lambda),
N=P1.xy at coords[1,2]+dist12*cos(lambda))
> coordinates(P2.xy) <- ~E+N
> proj4string(P2.xy) <- P1.xy at proj4string
> P2 <- spTransform(P2.xy, CRS("+proj=longlat +datum=WGS84"))
> P12 <- rbind(P1, P2)
> P12
SpatialPoints:
            E      N
[1,] 35.00000 25.000
[2,] 33.55488 22.554
Coordinate Reference System (CRS) arguments:
+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0

> load(file=url("http://spatial-analyst.net/DATA/worldborders.RData"))
> spplot(worldborders["NAME"], colorkey=FALSE, col.regions=rep(grey(0.5),
length(levels(worldborders$NAME))), sp.layout=list("sp.points", P12, pch="+", col="red", cex=3))

But I would consider using the UTM or which ever coordinate system is of your interest; then you
also need to convert the GCD to distance in the local system. For example, to represent the whole of
USA (contiguous 48-state area) I typically use:

+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83
+units=m +no_defs

See also:

http://spatial-analyst.net/DATA/usgrids5km.zip 

cheers,

T. Hengl
http://spatial-accuracy.org/FromGEOSTAT2009 

PS: I never got any photos from your trip to the Pyramids!




> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Harry Kim
> Sent: Tuesday, October 06, 2009 7:23 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Determining a coordinate given another coordinate,a great circle distance,
> and an angle
> 
> Dear R-sig-geoers,
> 
>       I am stuck with a problem and i was hoping if you could help me.
> Suppose i am given a coordinate in lat/long (say 25 lat 35 long) and a
> great circle distance (say 10km). Also assume that i am given an angle
> with respect to latitude (an angle from the x-axis say 30 degrees).
> What would be the best way to determine a coordinate 10kms away from
> 25 lat 35 long with a given angle (30 degrees)?
> 
>      I think in euclidean space, I can use tangent of the given angle
> and combine with the Pythagorean theorem to find the target
> coordinate.
> 
> Thank you very much in advance,
> Harry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ageel_bushara at yahoo.com  Wed Oct  7 10:40:21 2009
From: ageel_bushara at yahoo.com (ageel bushara)
Date: Wed, 7 Oct 2009 01:40:21 -0700 (PDT)
Subject: [R-sig-Geo] Discharge and rainfall time series in one plot
Message-ID: <262069.25987.qm@web35806.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091007/8dcadbdd/attachment.pl>

From enrico.guastaldi at gmail.com  Wed Oct  7 11:47:55 2009
From: enrico.guastaldi at gmail.com (Enrico Guastaldi)
Date: Wed, 7 Oct 2009 11:47:55 +0200
Subject: [R-sig-Geo] AI-GEOSTATS: Interpolation of measures with
	measurement errors
In-Reply-To: <B75D14CABA98774E938782E38A29368035D8368983@EXCHANGEMB.campus.aston.ac.uk>
References: <7ce8d7d30909280554w7c5bbd38l4555e650e6dbedaf@mail.gmail.com>
	<B75D14CABA98774E938782E38A29368035D8368611@EXCHANGEMB.campus.aston.ac.uk>
	<7ce8d7d30910050904p48ba36a5nc20ad213e13d3b5f@mail.gmail.com>
	<B75D14CABA98774E938782E38A29368035D8368983@EXCHANGEMB.campus.aston.ac.uk>
Message-ID: <7ce8d7d30910070247w1298157cr84a4e15b7fb776b5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091007/d5cedddb/attachment.pl>

From jim at bitwrit.com.au  Wed Oct  7 12:39:51 2009
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 07 Oct 2009 21:39:51 +1100
Subject: [R-sig-Geo] Discharge and rainfall time series in one plot
In-Reply-To: <262069.25987.qm@web35806.mail.mud.yahoo.com>
References: <262069.25987.qm@web35806.mail.mud.yahoo.com>
Message-ID: <4ACC6FF7.4050004@bitwrit.com.au>

On 10/07/2009 07:40 PM, ageel bushara wrote:
> Dear list members,
> I want to plot discharge time series and rainfall time series in the same plot. The discharge in m3/s in the main y-axis and the time (every 15 minutes having a form 01-07-1997 10:15:00) in the main x-axis. The rainfall (mm) is in the secondary y-axis and the time in the secondary x-axis. How can I do it and which package shall I use.
>    
Hi Ageel,
You can do this with the twoord.plot function in the plotrix package.

Jim


From vetter at pik-potsdam.de  Wed Oct  7 13:59:59 2009
From: vetter at pik-potsdam.de (Tobias Vetter)
Date: Wed, 07 Oct 2009 13:59:59 +0200
Subject: [R-sig-Geo] Discharge and rainfall time series in one plot
In-Reply-To: <4ACC6FF7.4050004@bitwrit.com.au>
References: <262069.25987.qm@web35806.mail.mud.yahoo.com>
	<4ACC6FF7.4050004@bitwrit.com.au>
Message-ID: <4ACC82BF.8010101@pik-potsdam.de>

You can also use the
par(new)=T
command.

example:
plot(runif(10))
par(new=T)
barplot(runif(10),ylim=c(10,0),yaxt="n")
axis(4)

> On 10/07/2009 07:40 PM, ageel bushara wrote:
>> Dear list members,
>> I want to plot discharge time series and rainfall time series in the 
>> same plot. The discharge in m3/s in the main y-axis and the time 
>> (every 15 minutes having a form 01-07-1997 10:15:00) in the main 
>> x-axis. The rainfall (mm) is in the secondary y-axis and the time in 
>> the secondary x-axis. How can I do it and which package shall I use.
>>    
> Hi Ageel,
> You can do this with the twoord.plot function in the plotrix package.
>
> Jim
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Wed Oct  7 19:47:15 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 7 Oct 2009 10:47:15 -0700
Subject: [R-sig-Geo] Determining a coordinate given another coordinate,
	a 	great circle distance, and an angle
In-Reply-To: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>
References: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>
Message-ID: <dc22b2570910071047w5120150dw6ce78b68191f3ff2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091007/f5276aff/attachment.pl>

From pierre.roudier at gmail.com  Thu Oct  8 07:47:54 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Thu, 8 Oct 2009 16:47:54 +1100
Subject: [R-sig-Geo] Finding to which Voronoi/Dirichlet a point belongs to
Message-ID: <e4178da60910072247y35e3bdb8x24ac51939f18a6a8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091008/e268eabb/attachment.pl>

From harryk at cal.berkeley.edu  Thu Oct  8 08:27:13 2009
From: harryk at cal.berkeley.edu (Harry Kim)
Date: Wed, 7 Oct 2009 23:27:13 -0700
Subject: [R-sig-Geo] Determining a coordinate given another coordinate,
	a 	great circle distance, and an angle
In-Reply-To: <EA739A8014FC4B43B2B0F798AB5B8F95@pcibed193>
References: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>
	<EA739A8014FC4B43B2B0F798AB5B8F95@pcibed193>
Message-ID: <91b8161f0910072327x62c605e2icfc12150a9040dae@mail.gmail.com>

Hey Tom!

     It's great to hear from you :).  I did think about using a UTM
projection but the region of interest (Turkey) is too big. It requires
6 UTM zones to cover it and if the point is around the boundary i
thought that it would create some problems. I wasn't aware of other
distance/area preserving projections. I will take a look at the zip
file on your website. For some reason radicalcartography website isn't
working for me.

Thanks again for the detailed code tom!
Hope things are going well for you.

P.S: The pyramids were awesome but i thought Petra was better :-D.
http://www.facebook.com/cardboy?ref=profile#/album.php?aid=2477670&id=1204683&op=6
http://www.facebook.com/cardboy?ref=profile#/album.php?aid=2481932&id=1204683&op=6

On Wed, Oct 7, 2009 at 1:36 AM, Tomislav Hengl
<hengl at spatial-analyst.net> wrote:
>
> Hi Harry,
>
> The key issue is that you need to select the (Euclidean) coordinate system. For example, to
> represent the whole world, there are many possiblities
> (http://www.radicalcartography.net/?projectionref). If you are working with the great circle
> distance, make sure that the geographic coordinate system uses a sphere. Say if you want to use some
> equidistant coordinate system with center at 0,0 longlat (Lambert Azimuthal Equal-Area), you could
> then get the coordinates by using:
>
>> P1 <- data.frame(E=35, N=25)
>> lambda <- 60 ?# azimuth!
>> dist12 <- 300000
>> coordinates(P1) <- ~E+N
>> proj4string(P1) <- CRS("+proj=longlat +datum=WGS84")
>> P1.xy <- spTransform(P1, CRS("+proj=laea +lat_0 +lon_0 +x_0 +y_0"))
>> P2.xy <- data.frame(E=P1.xy at coords[1,1]+dist12*sin(lambda),
> N=P1.xy at coords[1,2]+dist12*cos(lambda))
>> coordinates(P2.xy) <- ~E+N
>> proj4string(P2.xy) <- P1.xy at proj4string
>> P2 <- spTransform(P2.xy, CRS("+proj=longlat +datum=WGS84"))
>> P12 <- rbind(P1, P2)
>> P12
> SpatialPoints:
> ? ? ? ? ? ?E ? ? ?N
> [1,] 35.00000 25.000
> [2,] 33.55488 22.554
> Coordinate Reference System (CRS) arguments:
> +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>
>> load(file=url("http://spatial-analyst.net/DATA/worldborders.RData"))
>> spplot(worldborders["NAME"], colorkey=FALSE, col.regions=rep(grey(0.5),
> length(levels(worldborders$NAME))), sp.layout=list("sp.points", P12, pch="+", col="red", cex=3))
>
> But I would consider using the UTM or which ever coordinate system is of your interest; then you
> also need to convert the GCD to distance in the local system. For example, to represent the whole of
> USA (contiguous 48-state area) I typically use:
>
> +proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83
> +units=m +no_defs
>
> See also:
>
> http://spatial-analyst.net/DATA/usgrids5km.zip
>
> cheers,
>
> T. Hengl
> http://spatial-accuracy.org/FromGEOSTAT2009
>
> PS: I never got any photos from your trip to the Pyramids!
>
>
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Harry Kim
>> Sent: Tuesday, October 06, 2009 7:23 PM
>> To: r-sig-geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] Determining a coordinate given another coordinate,a great circle distance,
>> and an angle
>>
>> Dear R-sig-geoers,
>>
>> ? ? ? I am stuck with a problem and i was hoping if you could help me.
>> Suppose i am given a coordinate in lat/long (say 25 lat 35 long) and a
>> great circle distance (say 10km). Also assume that i am given an angle
>> with respect to latitude (an angle from the x-axis say 30 degrees).
>> What would be the best way to determine a coordinate 10kms away from
>> 25 lat 35 long with a given angle (30 degrees)?
>>
>> ? ? ?I think in euclidean space, I can use tangent of the given angle
>> and combine with the Pythagorean theorem to find the target
>> coordinate.
>>
>> Thank you very much in advance,
>> Harry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From harryk at cal.berkeley.edu  Thu Oct  8 08:29:56 2009
From: harryk at cal.berkeley.edu (Harry Kim)
Date: Wed, 7 Oct 2009 23:29:56 -0700
Subject: [R-sig-Geo] Determining a coordinate given another coordinate,
	a 	great circle distance, and an angle
In-Reply-To: <dc22b2570910071047w5120150dw6ce78b68191f3ff2@mail.gmail.com>
References: <91b8161f0910061022m7125c71fu9646c262f7dd8a0e@mail.gmail.com>
	<dc22b2570910071047w5120150dw6ce78b68191f3ff2@mail.gmail.com>
Message-ID: <91b8161f0910072329g927d1aam33d48d7c29e74593@mail.gmail.com>

Hi Robert,

       Thank you so much! I just tested the code and it works
beautifully. This is exactly what I wanted to do. I had  a feeling
that it could be calculated analytically but I kept messing up my
calculations.

Thanks again!
Harry

On Wed, Oct 7, 2009 at 10:47 AM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Harry, I think you are after something like the function below (I did not
> test it much). Robert
> # based on code at http://www.movable-type.co.uk/scripts/latlong.html
> # ? 2002-2009 Chris Veness
> # license: LPGL; without any warranty express or implied
> # R version by R Hijmans
> # calculate destination point given start point, initial bearing (deg) and
> distance (km)
> # ? see http://williams.best.vwh.net/avform.htm#LL
> destPoint <- function(lon, lat, bearing, d, dms=FALSE, R=6378137) {
> # bearing in degrees
> # d in meters
> # R=earth's mean radius in m
> RadDeg <- pi / 180
>
> lat1 = lat * RadDeg
> lon1 = lon * RadDeg
> brng = bearing * RadDeg
> lat2 <- asin( sin(lat1) * cos(d/R) + cos(lat1) * sin(d/R) * cos(brng) )
> lon2 <- lon1 + atan2(sin(brng) * sin(d/R) * cos(lat1), cos(d/R) - sin(lat1)
> * sin(lat2))
> lon2 <- (lon2 + pi) %% ( 2 * pi) - pi; # normalise to -180...+180
> if (is.nan(lat2) | is.nan(lon2)) return(NULL)
> return ( (cbind(lon2, lat2)) / RadDeg )
> }
> destPoint(35, 25, 30, 100000)
>
>
>
>
>
> On Tue, Oct 6, 2009 at 10:22 AM, Harry Kim <harryk at cal.berkeley.edu> wrote:
>>
>> Dear R-sig-geoers,
>>
>> ? ? ?I am stuck with a problem and i was hoping if you could help me.
>> Suppose i am given a coordinate in lat/long (say 25 lat 35 long) and a
>> great circle distance (say 10km). Also assume that i am given an angle
>> with respect to latitude (an angle from the x-axis say 30 degrees).
>> What would be the best way to determine a coordinate 10kms away from
>> 25 lat 35 long with a given angle (30 degrees)?
>>
>> ? ? I think in euclidean space, I can use tangent of the given angle
>> and combine with the Pythagorean theorem to find the target
>> coordinate.
>>
>> Thank you very much in advance,
>> Harry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From jochen at hunter.cuny.edu  Thu Oct  8 17:37:13 2009
From: jochen at hunter.cuny.edu (Jochen Albrecht)
Date: Thu, 08 Oct 2009 11:37:13 -0400
Subject: [R-sig-Geo] where to tweak memory allocation settings
Message-ID: <4ACE0729.3080103@hunter.cuny.edu>

Fellow spatial statisticians:
I am trying to align a bunch of world-wide datasets at 0.1 degree 
resolution. I figured that the easiest way to do that is to create a 
dataset where the rownames form the index that allows to relate all my 
variable-sized point datasets to. I therefore created a shapefile base 
dataset that contains appr. 6.5 million points and had hoped that I 
could read this into R to then link all my other data to. Unfortunately, 
I ran into memory allocation problems (see error messages attached to 
this email).
My hunch is that these can be overcome by just changing some settings 
(hopefully without having to recompile R sources). Do you have 
suggestions what these are and what the practically hard limit is? 6.5 
million points is large but not uncommon these days, so I figured that 
this should be doable without embarking on major efforts.
Alternatively, would it save me a lot of memory space if I tried to read 
this into a SpatialPixel or SpatialGrid structure?
Cheers,
     Jochen

 > basepoints = readOGR(".", "basepoints")
OGR data source with driver: ESRI Shapefile
Source: ".", layer: "basepoints"
with  3465355  rows and  7  columns
Feature type: wkbPoint with 2 dimensions
Warning in data.frame(dlist) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in data.frame(dlist) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in data.frame(dlist) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in data.frame(dlist) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
  Reached total allocation of 1535Mb: see help(memory.size)
Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
  Reached total allocation of 1535Mb: see help(memory.size)
Error: cannot allocate vector of size 13.2 Mb


From cc157 at duke.edu  Thu Oct  8 18:13:23 2009
From: cc157 at duke.edu (Corrie Curtice)
Date: Thu, 8 Oct 2009 12:13:23 -0400
Subject: [R-sig-Geo] location points that span UTM zones
Message-ID: <33debc420910080913g60373621u10d61273fc9a4617@mail.gmail.com>

Hello,

I have some location data points that span two UTM zones.  I'm using
the points to estimate home ranges, using a couple of home range tools
(NNCH, HRT for ArcGIS).   Can I just project them to the left most
zone, and run the home range tools on that data set?  I'm curious to
know what the negative impacts of this might be.  These are points
around the west coast of Mexico, so UTM 12/13 and 13/14.

Thanks,

Corrie


From r.hijmans at gmail.com  Thu Oct  8 18:15:01 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 8 Oct 2009 09:15:01 -0700
Subject: [R-sig-Geo] where to tweak memory allocation settings
In-Reply-To: <4ACE0729.3080103@hunter.cuny.edu>
References: <4ACE0729.3080103@hunter.cuny.edu>
Message-ID: <dc22b2570910080915h104abd9bx98a70b1a5f0147fa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091008/dd8575b3/attachment.pl>

From NTGLOVER at mactec.com  Thu Oct  8 18:42:35 2009
From: NTGLOVER at mactec.com (Glover, Tim)
Date: Thu, 8 Oct 2009 12:42:35 -0400
Subject: [R-sig-Geo] location points that span UTM zones
In-Reply-To: <33debc420910080913g60373621u10d61273fc9a4617@mail.gmail.com>
References: <33debc420910080913g60373621u10d61273fc9a4617@mail.gmail.com>
Message-ID: <99204592228B314BB5F1CCFD449B75530B2AB0F5@LS-E.mactec.com>

UTM projects a spherical globe onto a cylinder.  Zones are chosen to
achieve a certain level of accuracy of distances between points.  This
accuracy decreases as you stray from the zone, but is not too bad as
long as you're not too far past the edges of the zone.  "Too bad" and
"too far" are inter-dependent and also depend on your uses of the data.
If you need cm-size accuracy, you don't want to extend half-way into the
next zone, for instance. There is a mathematical relationship between
accuracy and distance from the central meridian of the zone.    



Tim Glover 
Senior Environmental Scientist - Geochemistry 
Geoscience Department Atlanta Area 
MACTEC Engineering and Consulting, Inc. 
Kennesaw, Georgia, USA 
Office 770-421-3310 
Fax 770-421-3486 
Email ntglover at mactec.com 
Web www.mactec.com 
 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Corrie Curtice
Sent: Thursday, October 08, 2009 12:13 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] location points that span UTM zones

Hello,

I have some location data points that span two UTM zones.  I'm using
the points to estimate home ranges, using a couple of home range tools
(NNCH, HRT for ArcGIS).   Can I just project them to the left most
zone, and run the home range tools on that data set?  I'm curious to
know what the negative impacts of this might be.  These are points
around the west coast of Mexico, so UTM 12/13 and 13/14.

Thanks,

Corrie

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Oct  8 20:18:32 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 8 Oct 2009 20:18:32 +0200 (CEST)
Subject: [R-sig-Geo] where to tweak memory allocation settings
In-Reply-To: <4ACE0729.3080103@hunter.cuny.edu>
References: <4ACE0729.3080103@hunter.cuny.edu>
Message-ID: <alpine.LRH.2.00.0910082002470.20773@reclus.nhh.no>

On Thu, 8 Oct 2009, Jochen Albrecht wrote:

> Fellow spatial statisticians:
> I am trying to align a bunch of world-wide datasets at 0.1 degree resolution. 
> I figured that the easiest way to do that is to create a dataset where the 
> rownames form the index that allows to relate all my variable-sized point 
> datasets to. I therefore created a shapefile base dataset that contains appr. 
> 6.5 million points and had hoped that I could read this into R to then link 
> all my other data to. Unfortunately, I ran into memory allocation problems 
> (see error messages attached to this email).

You have not reported sessionInfo() or your operating system (Windows?). 
See the R for Windows FAQ for memory management there. In fact the problem 
isn't the number of points (here 3.5 million, presumably the raster cells 
with data, not 6.5 million for global coverage), it is 
likely the combination of character columns and their conversion into 
factor form - do they contain long character strings?

> My hunch is that these can be overcome by just changing some settings 
> (hopefully without having to recompile R sources). Do you have suggestions 
> what these are and what the practically hard limit is? 6.5 million points is 
> large but not uncommon these days, so I figured that this should be doable 
> without embarking on major efforts.
> Alternatively, would it save me a lot of memory space if I tried to read this 
> into a SpatialPixel or SpatialGrid structure?

To read into a SpatialPixelDataFrame object, you still need points, or go 
through a SpatialGridDataFrame. For a SpatialGridDataFrame, store the data 
as a multiband GeoTiff for example. If however there is something odd - 
long character strings as attributes, the problem will be the same. One 
advantage of going through a SpatialGridDataFrame is that the 3.5 million 
row names fo not get generated and do not take up space - readOGR() always 
generates feature IDs from the input geometry FIDs. If the support is grid 
support, use a gridded representation, as in Robert's suggestion for 
using the raster package.

Hope this helps,

Roger

> Cheers,
>    Jochen
>
>> basepoints = readOGR(".", "basepoints")
> OGR data source with driver: ESRI Shapefile
> Source: ".", layer: "basepoints"
> with  3465355  rows and  7  columns
> Feature type: wkbPoint with 2 dimensions
> Warning in data.frame(dlist) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in data.frame(dlist) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in data.frame(dlist) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in data.frame(dlist) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Warning in as.data.frame.integer(x[[i]], optional = TRUE) :
> Reached total allocation of 1535Mb: see help(memory.size)
> Error: cannot allocate vector of size 13.2 Mb
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From enrico.crema at gmail.com  Fri Oct  9 01:23:33 2009
From: enrico.crema at gmail.com (Enrico R. Crema)
Date: Fri, 9 Oct 2009 00:23:33 +0100
Subject: [R-sig-Geo] Simulating Two Surfaces with a user-defined
	Cross-Correlation Index
Message-ID: <E6BFF28E-6734-48E4-86CB-0A9A04BFE3C4@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091009/543344e4/attachment.pl>

From gianni.lavaredo at gmail.com  Fri Oct  9 06:45:51 2009
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Thu, 8 Oct 2009 21:45:51 -0700
Subject: [R-sig-Geo] split random a data.frame to create two data.frame
Message-ID: <518dff330910082145g8ab756ay65330c3e5f87a588@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091008/483da216/attachment.pl>

From r.hijmans at gmail.com  Fri Oct  9 06:53:05 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 8 Oct 2009 21:53:05 -0700
Subject: [R-sig-Geo] split random a data.frame to create two data.frame
In-Reply-To: <518dff330910082145g8ab756ay65330c3e5f87a588@mail.gmail.com>
References: <518dff330910082145g8ab756ay65330c3e5f87a588@mail.gmail.com>
Message-ID: <dc22b2570910082153l1e4e2276re608d1d9b12f2924@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091008/e37516a2/attachment.pl>

From wilfried.thuiller at ujf-grenoble.fr  Fri Oct  9 07:00:55 2009
From: wilfried.thuiller at ujf-grenoble.fr (Wilfried Thuiller)
Date: Fri, 09 Oct 2009 07:00:55 +0200
Subject: [R-sig-Geo] split random a data.frame to create two data.frame
In-Reply-To: <dc22b2570910082153l1e4e2276re608d1d9b12f2924@mail.gmail.com>
References: <518dff330910082145g8ab756ay65330c3e5f87a588@mail.gmail.com>
	<dc22b2570910082153l1e4e2276re608d1d9b12f2924@mail.gmail.com>
Message-ID: <4ACEC387.5040701@ujf-grenoble.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091009/2c21e37b/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Oct  9 08:49:02 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 09 Oct 2009 08:49:02 +0200
Subject: [R-sig-Geo] Simulating Two Surfaces with a
 user-defined	Cross-Correlation Index
In-Reply-To: <E6BFF28E-6734-48E4-86CB-0A9A04BFE3C4@gmail.com>
References: <E6BFF28E-6734-48E4-86CB-0A9A04BFE3C4@gmail.com>
Message-ID: <4ACEDCDE.2080609@uni-muenster.de>

Enrico, try

library(gstat)
demo(cosimulation)

First part is on Gaussian simulation, the second on indicator simulations.

Best regards,

Enrico R. Crema wrote:
> Dear All,
> Is there any R function capable a set of two raster maps with a user- 
> defined spatial cross-correlation index (between the two rasters)?
> Many Thanks,
> Enrico Crema
> ---------------------------------------
> Enrico R. Crema
> PhD Candidate
> Institute of Archaeology, UCL
> AHRC Centre for the Evolution of Cultural Diversity, UCL
> http://www.cecd.ucl.ac.uk/people/?go1=91
> +44 7899093191
> e.crema at ucl.ac.uk
> enrico.crema at gmail.com
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From enrico.crema at gmail.com  Fri Oct  9 10:41:58 2009
From: enrico.crema at gmail.com (Enrico R. Crema)
Date: Fri, 9 Oct 2009 09:41:58 +0100
Subject: [R-sig-Geo] Simulating Two Surfaces with a
	user-defined	Cross-Correlation Index
In-Reply-To: <4ACEDCDE.2080609@uni-muenster.de>
References: <E6BFF28E-6734-48E4-86CB-0A9A04BFE3C4@gmail.com>
	<4ACEDCDE.2080609@uni-muenster.de>
Message-ID: <BFE4C526-8B71-4CBC-BAAA-2978A1A92C55@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091009/0517f073/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Oct  9 11:40:03 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 09 Oct 2009 11:40:03 +0200
Subject: [R-sig-Geo] Simulating Two Surfaces with a
 user-defined	Cross-Correlation Index
In-Reply-To: <BFE4C526-8B71-4CBC-BAAA-2978A1A92C55@gmail.com>
References: <E6BFF28E-6734-48E4-86CB-0A9A04BFE3C4@gmail.com>
	<4ACEDCDE.2080609@uni-muenster.de>
	<BFE4C526-8B71-4CBC-BAAA-2978A1A92C55@gmail.com>
Message-ID: <4ACF04F3.1070909@uni-muenster.de>

If the variables are spatially uncorrelated, it is a special case of
what I provided, and you could specify the variography in terms of pure
nuggets, and/or use a neighbourhood of 1 (or 0?).

As an alternative, fill the grids with data generated with function
rmvnorm in package mvtnorm.

I find it however hard to understand what you mean by a spatial
cross-correlation index, especially the word spatial, when you do not
want to address spatial autocorrelation of the variables themselves.
--
Edzer

Enrico R. Crema wrote:
> Many Thanks,
> But I guess explained very badly (sorry for this!!) what I need. I am
> building an Agent Based Simulation and part of the model requires
> series of two randomly generated raster maps, having a spatial
> cross-correlation index ranging from -1 to +1. Clearly If I can
> specify autocorrelation of each that will be even better, but at this
> stage I just need two randomly generated surfaces with a
> user-specified Cross-Correlation Index. Sorry again for the bad
> explanation!
>
> Enrico
>
> ---------------------------------------
> Enrico R. Crema
> PhD Candidate
> Institute of Archaeology, UCL
> AHRC Centre for the Evolution of Cultural Diversity, UCL
> http://www.cecd.ucl.ac.uk/people/?go1=91
> +44 7899093191
> e.crema at ucl.ac.uk
> enrico.crema at gmail.com
>
>
>
>
>
>
>
> On 9 Oct 2009, at 07:49, Edzer Pebesma wrote:
>
>> Enrico, try
>>
>> library(gstat)
>> demo(cosimulation)
>>
>> First part is on Gaussian simulation, the second on indicator
>> simulations.
>>
>> Best regards,
>>
>> Enrico R. Crema wrote:
>>> Dear All,
>>> Is there any R function capable a set of two raster maps with a user-
>>> defined spatial cross-correlation index (between the two rasters)?
>>> Many Thanks,
>>> Enrico Crema
>>> ---------------------------------------
>>> Enrico R. Crema
>>> PhD Candidate
>>> Institute of Archaeology, UCL
>>> AHRC Centre for the Evolution of Cultural Diversity, UCL
>>> http://www.cecd.ucl.ac.uk/people/?go1=91
>>> +44 7899093191
>>> e.crema at ucl.ac.uk
>>> enrico.crema at gmail.com
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> -- 
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster
>> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
>> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
>> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>>
>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From enrico.crema at gmail.com  Sun Oct 11 18:23:01 2009
From: enrico.crema at gmail.com (Enrico R. Crema)
Date: Sun, 11 Oct 2009 17:23:01 +0100
Subject: [R-sig-Geo] Simulating Two Surfaces with a
	user-defined	Cross-Correlation Index
In-Reply-To: <4ACF04F3.1070909@uni-muenster.de>
References: <E6BFF28E-6734-48E4-86CB-0A9A04BFE3C4@gmail.com>
	<4ACEDCDE.2080609@uni-muenster.de>
	<BFE4C526-8B71-4CBC-BAAA-2978A1A92C55@gmail.com>
	<4ACF04F3.1070909@uni-muenster.de>
Message-ID: <689EEFC7-1EF4-455E-8136-D17811470419@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091011/1e32fab8/attachment.pl>

From John.Carson at shawgrp.com  Mon Oct 12 15:35:04 2009
From: John.Carson at shawgrp.com (Carson, John)
Date: Mon, 12 Oct 2009 08:35:04 -0500
Subject: [R-sig-Geo] Problem with gstat variogram estimation
Message-ID: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>

I have found anomalous behavior in gstat's variogram estimation. I have listed 3 example variograms below for small data sets.  In order to better estimate the nugget effect, I slightly perturbed the locations (by 1 foot increments) of duplicate results. The empirical variograms?are given below.  

Before I did this (I averaged duplicate values initially), a Gaussian model with 0 nugget was selected for the second variogram and pure nugget models for the first and third. I am using the candidate model list ('Nug', 'Exp', 'Sph', 'Gau', 'Mat', 'Cir', 'Lin', 'Bes') and selecting the model based on SSErr for preliminary testing purposes.?Afterward, the pure nugget models had the lowest SSErr and were selected.  Note that the variogram fits are completely controlled by the short range variance, because even the original pure nugget models are substantially different in the estimate of the nugget.  The fitted models are listed below.  Just by inspection, based on the numbers of pairs in these examples, a pure nugget model should be about halfway between the empirical semivariance of the last lag and the average of the other lags. However, the fitted nuggets are almost identical to the semivariance of the first last (dist = 1.4).  

It seems to me that this must be due to a bug in the GSTAT code.  I pointed this out to Edzer Pebesma, and he asked me to post it here.

The variograms are 

tmp.vgm
[[1]]
? np?????? dist????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.14174537?????? 0?????? 0 PC1
2? 2? 44.742603 6.70989788?????? 0?????? 0 PC1
3? 2? 57.707880 1.76351594?????? 0?????? 0 PC1
4? 4? 59.987678 1.52197310?????? 0?????? 0 PC1
5? 3? 71.512518 1.21348268?????? 0?????? 0 PC1
6? 1? 84.852877 0.05381849?????? 0?????? 0 PC1
7? 1? 97.266495 1.21827622?????? 0?????? 0 PC1
8? 3 112.237133 5.07947925?????? 0?????? 0 PC1
9 18 121.478856 1.93707676?????? 0?????? 0 PC1

[[2]]
? np?????? dist????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.09725079?????? 0?????? 0 PC2
2? 2? 44.742603 0.33598072?????? 0?????? 0 PC2
3? 2? 57.707880 0.39088727?????? 0?????? 0 PC2
4? 4? 59.987678 0.87315735?????? 0?????? 0 PC2
5? 3? 71.512518 0.14944845?????? 0?????? 0 PC2
6? 1? 84.852877 0.19809863?????? 0?????? 0 PC2
7? 1? 97.266495 0.63557814?????? 0?????? 0 PC2
8? 3 112.237133 1.92063948?????? 0?????? 0 PC2
9 18 121.478856 0.65468693?????? 0 ??????0 PC2

[[3]]
? np?????? dist?????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.035250817?????? 0?????? 0 PC3
2? 2? 44.742603 0.105299796?????? 0?????? 0 PC3
3? 2? 57.707880 0.020245674?????? 0?????? 0 PC3
4? 4? 59.987678 0.124159836?????? 0?????? 0 PC3
5? 3? 71.512518 0.008112554?????? 0?????? 0 PC3
6? 1? 84.852877 0.034337591?????? 0?????? 0 PC3
7? 1? 97.266495 0.053879459?????? 0?????? 0 PC3
8? 3 112.237133 0.021922987?????? 0?????? 0 PC3
9 18 121.478856 0.085270969?????? 0?????? 0 PC3


But the fitted models are:

tmp.vgm.fit
[[1]]
? model???? psill range
1?? Nug 0.1483120???? 0

[[2]]
? model????? psill range
1?? Nug 0.09849419???? 0

[[3]]
? model????? psill range
1?? Nug 0.03535234???? 0




John H. Carson Jr., PhD
Senior Statistician
Applied Sciences & Engineering 
Shaw Environmental & Infrastructure
16406 US Rte 224 East
Findlay, OH 45840
Phone 419-425-6156
Fax 419-425-6085
john.carson at shawgrp.com

http://www.shawgrp.com/
Shaw(tm) a world of Solutions(tm)

?

****Internet Email Confidentiality Footer****
Privileged/Confidential Information may be contained in this
message. If you are not the addressee indicated in this message (or
responsible for delivery of the message to such person), you may
not copy or deliver this message to anyone. In such case, you
should destroy this message and notify the sender by reply email.
Please advise immediately if you or your employer do not consent to
Internet email for messages of this kind. Opinions, conclusions and
other information in this message that do not relate to the
official business of The Shaw Group Inc. or its subsidiaries shall
be understood as neither given nor endorsed by it.
______________________________________ The Shaw Group Inc.
http://www.shawgrp.com


From fanfaar at gmail.com  Mon Oct 12 15:55:18 2009
From: fanfaar at gmail.com (Arnout Standaert)
Date: Mon, 12 Oct 2009 15:55:18 +0200
Subject: [R-sig-Geo] Average kriging surface over region
Message-ID: <879ceaf00910120655h7f7e656l45edee0e8fe19c4d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091012/f1583c33/attachment.pl>

From Thierry.ONKELINX at inbo.be  Mon Oct 12 16:22:41 2009
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 12 Oct 2009 16:22:41 +0200
Subject: [R-sig-Geo] Problem with gstat variogram estimation
In-Reply-To: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
References: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
Message-ID: <2E9C414912813E4EB981326983E0A10406C30C7A@inboexch.inbo.be>

Dear John,

Isn't your problem rather a result from the unstable empirical variograms? Mainly due to the very low number of pairs per bin. Furthermore have a look at the weights that each bin gets in the fit.variogram() function. The default is N/h^2. In your case the first bin gets a weight of 2 whereas the other bins have weights ranging from 1e-3 tot 1e-4! Hence no surprise that the nugget is nearly identical to the semivariance of the first bin.

In this case I would not trust the results for fit.variogram(). Not because of bugs in gstat, but because I don't trust empirical variogram with that low number of pairs per bin.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Carson, John
Verzonden: maandag 12 oktober 2009 15:35
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] Problem with gstat variogram estimation

I have found anomalous behavior in gstat's variogram estimation. I have listed 3 example variograms below for small data sets.  In order to better estimate the nugget effect, I slightly perturbed the locations (by 1 foot increments) of duplicate results. The empirical variograms?are given below.  

Before I did this (I averaged duplicate values initially), a Gaussian model with 0 nugget was selected for the second variogram and pure nugget models for the first and third. I am using the candidate model list ('Nug', 'Exp', 'Sph', 'Gau', 'Mat', 'Cir', 'Lin', 'Bes') and selecting the model based on SSErr for preliminary testing purposes.?Afterward, the pure nugget models had the lowest SSErr and were selected.  Note that the variogram fits are completely controlled by the short range variance, because even the original pure nugget models are substantially different in the estimate of the nugget.  The fitted models are listed below.  Just by inspection, based on the numbers of pairs in these examples, a pure nugget model should be about halfway between the empirical semivariance of the last lag and the average of the other lags. However, the fitted nuggets are almost identical to the semivariance of the first last (dist = 1.4).  

It seems to me that this must be due to a bug in the GSTAT code.  I pointed this out to Edzer Pebesma, and he asked me to post it here.

The variograms are 

tmp.vgm
[[1]]
? np?????? dist????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.14174537?????? 0?????? 0 PC1
2? 2? 44.742603 6.70989788?????? 0?????? 0 PC1
3? 2? 57.707880 1.76351594?????? 0?????? 0 PC1
4? 4? 59.987678 1.52197310?????? 0?????? 0 PC1
5? 3? 71.512518 1.21348268?????? 0?????? 0 PC1
6? 1? 84.852877 0.05381849?????? 0?????? 0 PC1
7? 1? 97.266495 1.21827622?????? 0?????? 0 PC1
8? 3 112.237133 5.07947925?????? 0?????? 0 PC1
9 18 121.478856 1.93707676?????? 0?????? 0 PC1

[[2]]
? np?????? dist????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.09725079?????? 0?????? 0 PC2
2? 2? 44.742603 0.33598072?????? 0?????? 0 PC2
3? 2? 57.707880 0.39088727?????? 0?????? 0 PC2
4? 4? 59.987678 0.87315735?????? 0?????? 0 PC2
5? 3? 71.512518 0.14944845?????? 0?????? 0 PC2
6? 1? 84.852877 0.19809863?????? 0?????? 0 PC2
7? 1? 97.266495 0.63557814?????? 0?????? 0 PC2
8? 3 112.237133 1.92063948?????? 0?????? 0 PC2
9 18 121.478856 0.65468693?????? 0 ??????0 PC2

[[3]]
? np?????? dist?????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.035250817?????? 0?????? 0 PC3
2? 2? 44.742603 0.105299796?????? 0?????? 0 PC3
3? 2? 57.707880 0.020245674?????? 0?????? 0 PC3
4? 4? 59.987678 0.124159836?????? 0?????? 0 PC3
5? 3? 71.512518 0.008112554?????? 0?????? 0 PC3
6? 1? 84.852877 0.034337591?????? 0?????? 0 PC3
7? 1? 97.266495 0.053879459?????? 0?????? 0 PC3
8? 3 112.237133 0.021922987?????? 0?????? 0 PC3
9 18 121.478856 0.085270969?????? 0?????? 0 PC3


But the fitted models are:

tmp.vgm.fit
[[1]]
? model???? psill range
1?? Nug 0.1483120???? 0

[[2]]
? model????? psill range
1?? Nug 0.09849419???? 0

[[3]]
? model????? psill range
1?? Nug 0.03535234???? 0




John H. Carson Jr., PhD
Senior Statistician
Applied Sciences & Engineering
Shaw Environmental & Infrastructure
16406 US Rte 224 East
Findlay, OH 45840
Phone 419-425-6156
Fax 419-425-6085
john.carson at shawgrp.com

http://www.shawgrp.com/
Shaw(tm) a world of Solutions(tm)

?

****Internet Email Confidentiality Footer**** Privileged/Confidential Information may be contained in this message. If you are not the addressee indicated in this message (or responsible for delivery of the message to such person), you may not copy or deliver this message to anyone. In such case, you should destroy this message and notify the sender by reply email.
Please advise immediately if you or your employer do not consent to Internet email for messages of this kind. Opinions, conclusions and other information in this message that do not relate to the official business of The Shaw Group Inc. or its subsidiaries shall be understood as neither given nor endorsed by it.
______________________________________ The Shaw Group Inc.
http://www.shawgrp.com

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.


From p.hiemstra at geo.uu.nl  Mon Oct 12 16:21:05 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 12 Oct 2009 16:21:05 +0200
Subject: [R-sig-Geo] Average kriging surface over region
In-Reply-To: <879ceaf00910120655h7f7e656l45edee0e8fe19c4d@mail.gmail.com>
References: <879ceaf00910120655h7f7e656l45edee0e8fe19c4d@mail.gmail.com>
Message-ID: <4AD33B51.1080803@geo.uu.nl>

Arnout Standaert wrote:
> Dear list,
>
> I'm into the process of learning R's geospatial framework. Currently I'm
> studying scripts that perform a kriging operation on heavy metal
> measurements on a EU scale, see this link:
>
> http://eusoils.jrc.ec.europa.eu/foregshmc/
>
> Now, I would like to derive averages of the fitted model surface for the EU
> member countries. So: take the intersection of the country boundaries and
> the interpolated surface, and derive an average value for that.
> Could someone provide me with some pointers to get started? What R lib would
> be suited for this?
>
> Thanks a bunch,
> Frans
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Hi,

You can use a polygon as a newdata object in the call to krige. This 
will give you predictions per polygon. Or alternatively, look at the 
overlay() function.

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From edzer.pebesma at uni-muenster.de  Mon Oct 12 16:38:04 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 12 Oct 2009 16:38:04 +0200
Subject: [R-sig-Geo] Problem with gstat variogram estimation
In-Reply-To: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
References: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
Message-ID: <4AD33F4C.9010905@uni-muenster.de>

John, thanks for sharing this with r-sig-geo.

As Thierry mentioned, the default model fitting procedure (fit.variogram
in package gstat) uses weighted least squares, with weights proportional
to N_h/(h^2). This explains why the first lag gets so much weight.

For pure nugget models, this of course makes little sense; for other
models it often does. Argument fit.method gives you somewhat more
control. Give it value 1 to have N_h weights; give it value 6 to do
unweighted averaging (I agree that this information should be in the
fit.variogram documentation). The SSErr values will be uncomparable
accross different weighting schemes, as you might expect.
--
Edzer

Carson, John wrote:
> I have found anomalous behavior in gstat's variogram estimation. I have listed 3 example variograms below for small data sets.  In order to better estimate the nugget effect, I slightly perturbed the locations (by 1 foot increments) of duplicate results. The empirical variograms are given below.  
>
> Before I did this (I averaged duplicate values initially), a Gaussian model with 0 nugget was selected for the second variogram and pure nugget models for the first and third. I am using the candidate model list ('Nug', 'Exp', 'Sph', 'Gau', 'Mat', 'Cir', 'Lin', 'Bes') and selecting the model based on SSErr for preliminary testing purposes. Afterward, the pure nugget models had the lowest SSErr and were selected.  Note that the variogram fits are completely controlled by the short range variance, because even the original pure nugget models are substantially different in the estimate of the nugget.  The fitted models are listed below.  Just by inspection, based on the numbers of pairs in these examples, a pure nugget model should be about halfway between the empirical semivariance of the last lag and the average of the other lags. However, the fitted nuggets are almost identical to the semivariance of the first last (dist = 1.4).  
>
> It seems to me that this must be due to a bug in the GSTAT code.  I pointed this out to Edzer Pebesma, and he asked me to post it here.
>
> The variograms are 
>
> tmp.vgm
> [[1]]
>   np       dist      gamma dir.hor dir.ver  id
> 1  4   1.414214 0.14174537       0       0 PC1
> 2  2  44.742603 6.70989788       0       0 PC1
> 3  2  57.707880 1.76351594       0       0 PC1
> 4  4  59.987678 1.52197310       0       0 PC1
> 5  3  71.512518 1.21348268       0       0 PC1
> 6  1  84.852877 0.05381849       0       0 PC1
> 7  1  97.266495 1.21827622       0       0 PC1
> 8  3 112.237133 5.07947925       0       0 PC1
> 9 18 121.478856 1.93707676       0       0 PC1
>
> [[2]]
>   np       dist      gamma dir.hor dir.ver  id
> 1  4   1.414214 0.09725079       0       0 PC2
> 2  2  44.742603 0.33598072       0       0 PC2
> 3  2  57.707880 0.39088727       0       0 PC2
> 4  4  59.987678 0.87315735       0       0 PC2
> 5  3  71.512518 0.14944845       0       0 PC2
> 6  1  84.852877 0.19809863       0       0 PC2
> 7  1  97.266495 0.63557814       0       0 PC2
> 8  3 112.237133 1.92063948       0       0 PC2
> 9 18 121.478856 0.65468693       0       0 PC2
>
> [[3]]
>   np       dist       gamma dir.hor dir.ver  id
> 1  4   1.414214 0.035250817       0       0 PC3
> 2  2  44.742603 0.105299796       0       0 PC3
> 3  2  57.707880 0.020245674       0       0 PC3
> 4  4  59.987678 0.124159836       0       0 PC3
> 5  3  71.512518 0.008112554       0       0 PC3
> 6  1  84.852877 0.034337591       0       0 PC3
> 7  1  97.266495 0.053879459       0       0 PC3
> 8  3 112.237133 0.021922987       0       0 PC3
> 9 18 121.478856 0.085270969       0       0 PC3
>
>
> But the fitted models are:
>
> tmp.vgm.fit
> [[1]]
>   model     psill range
> 1   Nug 0.1483120     0
>
> [[2]]
>   model      psill range
> 1   Nug 0.09849419     0
>
> [[3]]
>   model      psill range
> 1   Nug 0.03535234     0
>
>
>
>
> John H. Carson Jr., PhD
> Senior Statistician
> Applied Sciences & Engineering 
> Shaw Environmental & Infrastructure
> 16406 US Rte 224 East
> Findlay, OH 45840
> Phone 419-425-6156
> Fax 419-425-6085
> john.carson at shawgrp.com
>
> http://www.shawgrp.com/
> Shaw(tm) a world of Solutions(tm)
>
>  
>
> ****Internet Email Confidentiality Footer****
> Privileged/Confidential Information may be contained in this
> message. If you are not the addressee indicated in this message (or
> responsible for delivery of the message to such person), you may
> not copy or deliver this message to anyone. In such case, you
> should destroy this message and notify the sender by reply email.
> Please advise immediately if you or your employer do not consent to
> Internet email for messages of this kind. Opinions, conclusions and
> other information in this message that do not relate to the
> official business of The Shaw Group Inc. or its subsidiaries shall
> be understood as neither given nor endorsed by it.
> ______________________________________ The Shaw Group Inc.
> http://www.shawgrp.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From p.hiemstra at geo.uu.nl  Mon Oct 12 16:41:15 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 12 Oct 2009 16:41:15 +0200
Subject: [R-sig-Geo] Problem with gstat variogram estimation
In-Reply-To: <4AD33F4C.9010905@uni-muenster.de>
References: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
	<4AD33F4C.9010905@uni-muenster.de>
Message-ID: <4AD3400B.8050309@geo.uu.nl>

Edzer Pebesma wrote:
> John, thanks for sharing this with r-sig-geo.
>
> As Thierry mentioned, the default model fitting procedure (fit.variogram
> in package gstat) uses weighted least squares, with weights proportional
> to N_h/(h^2). This explains why the first lag gets so much weight.
>
> For pure nugget models, this of course makes little sense; for other
> models it often does. Argument fit.method gives you somewhat more
> control. Give it value 1 to have N_h weights; give it value 6 to do
> unweighted averaging (I agree that this information should be in the
>   
It is listed in the gstat documentation:

http://www.gstat.org/gstat.pdf

on page 42, in the middle.

cheers,
Paul
> fit.variogram documentation). The SSErr values will be uncomparable
> accross different weighting schemes, as you might expect.
> --
> Edzer
>
> Carson, John wrote:
>   
>> I have found anomalous behavior in gstat's variogram estimation. I have listed 3 example variograms below for small data sets.  In order to better estimate the nugget effect, I slightly perturbed the locations (by 1 foot increments) of duplicate results. The empirical variograms are given below.  
>>
>> Before I did this (I averaged duplicate values initially), a Gaussian model with 0 nugget was selected for the second variogram and pure nugget models for the first and third. I am using the candidate model list ('Nug', 'Exp', 'Sph', 'Gau', 'Mat', 'Cir', 'Lin', 'Bes') and selecting the model based on SSErr for preliminary testing purposes. Afterward, the pure nugget models had the lowest SSErr and were selected.  Note that the variogram fits are completely controlled by the short range variance, because even the original pure nugget models are substantially different in the estimate of the nugget.  The fitted models are listed below.  Just by inspection, based on the numbers of pairs in these examples, a pure nugget model should be about halfway between the empirical semivariance of the last lag and the average of the other lags. However, the fitted nuggets are almost identical to the semivariance of the first last (dist = 1.4).  
>>
>> It seems to me that this must be due to a bug in the GSTAT code.  I pointed this out to Edzer Pebesma, and he asked me to post it here.
>>
>> The variograms are 
>>
>> tmp.vgm
>> [[1]]
>>   np       dist      gamma dir.hor dir.ver  id
>> 1  4   1.414214 0.14174537       0       0 PC1
>> 2  2  44.742603 6.70989788       0       0 PC1
>> 3  2  57.707880 1.76351594       0       0 PC1
>> 4  4  59.987678 1.52197310       0       0 PC1
>> 5  3  71.512518 1.21348268       0       0 PC1
>> 6  1  84.852877 0.05381849       0       0 PC1
>> 7  1  97.266495 1.21827622       0       0 PC1
>> 8  3 112.237133 5.07947925       0       0 PC1
>> 9 18 121.478856 1.93707676       0       0 PC1
>>
>> [[2]]
>>   np       dist      gamma dir.hor dir.ver  id
>> 1  4   1.414214 0.09725079       0       0 PC2
>> 2  2  44.742603 0.33598072       0       0 PC2
>> 3  2  57.707880 0.39088727       0       0 PC2
>> 4  4  59.987678 0.87315735       0       0 PC2
>> 5  3  71.512518 0.14944845       0       0 PC2
>> 6  1  84.852877 0.19809863       0       0 PC2
>> 7  1  97.266495 0.63557814       0       0 PC2
>> 8  3 112.237133 1.92063948       0       0 PC2
>> 9 18 121.478856 0.65468693       0       0 PC2
>>
>> [[3]]
>>   np       dist       gamma dir.hor dir.ver  id
>> 1  4   1.414214 0.035250817       0       0 PC3
>> 2  2  44.742603 0.105299796       0       0 PC3
>> 3  2  57.707880 0.020245674       0       0 PC3
>> 4  4  59.987678 0.124159836       0       0 PC3
>> 5  3  71.512518 0.008112554       0       0 PC3
>> 6  1  84.852877 0.034337591       0       0 PC3
>> 7  1  97.266495 0.053879459       0       0 PC3
>> 8  3 112.237133 0.021922987       0       0 PC3
>> 9 18 121.478856 0.085270969       0       0 PC3
>>
>>
>> But the fitted models are:
>>
>> tmp.vgm.fit
>> [[1]]
>>   model     psill range
>> 1   Nug 0.1483120     0
>>
>> [[2]]
>>   model      psill range
>> 1   Nug 0.09849419     0
>>
>> [[3]]
>>   model      psill range
>> 1   Nug 0.03535234     0
>>
>>
>>
>>
>> John H. Carson Jr., PhD
>> Senior Statistician
>> Applied Sciences & Engineering 
>> Shaw Environmental & Infrastructure
>> 16406 US Rte 224 East
>> Findlay, OH 45840
>> Phone 419-425-6156
>> Fax 419-425-6085
>> john.carson at shawgrp.com
>>
>> http://www.shawgrp.com/
>> Shaw(tm) a world of Solutions(tm)
>>
>>  
>>
>> ****Internet Email Confidentiality Footer****
>> Privileged/Confidential Information may be contained in this
>> message. If you are not the addressee indicated in this message (or
>> responsible for delivery of the message to such person), you may
>> not copy or deliver this message to anyone. In such case, you
>> should destroy this message and notify the sender by reply email.
>> Please advise immediately if you or your employer do not consent to
>> Internet email for messages of this kind. Opinions, conclusions and
>> other information in this message that do not relate to the
>> official business of The Shaw Group Inc. or its subsidiaries shall
>> be understood as neither given nor endorsed by it.
>> ______________________________________ The Shaw Group Inc.
>> http://www.shawgrp.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>>     
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Mon Oct 12 16:57:04 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 12 Oct 2009 16:57:04 +0200
Subject: [R-sig-Geo] Finding to which Voronoi/Dirichlet a point belongs
 to
In-Reply-To: <e4178da60910072247y35e3bdb8x24ac51939f18a6a8@mail.gmail.com>
References: <e4178da60910072247y35e3bdb8x24ac51939f18a6a8@mail.gmail.com>
Message-ID: <4AD343C0.5040203@geo.uu.nl>

Hi Pierre,

When you load the output of tripack into a SpatialPolygons object (see 
the sp-pacakge on CRAN), you can use the overlay() function.

cheers,
Paul

Pierre Roudier wrote:
> Dear list,
>
> I am trying to use the Voronoi tesselation of a point pattern to predict
> values of a second one.
>
> This is what it looks like:
>
> I got a first population of points :
>
> x <- runif(100)
> y <- runif(100)
> my.data.set <- data.frame(cbind(x,y))
>
> The second population is a subsample of the first one:
>
> spl.data.set <- my.data.set[1:20,]
> spl.data.set$z <- rnorm(20)
>
> plot(my.data.set$x,my.data.set$y)
> points(spl.data.set$x,spl.data.set$y,pch='+',col='red')
>
> I want to interpolate the values of my.data.set using the tesselation of
> spl.data.set:
>
> require(spatstat)
> spl.ppp <-
> as.ppp(spl.data.set,c(range(my.data.set$x),range(my.data.set$y)),marks=spl.data.set$z)
> spl.dir <- dirichlet(spl.ppp)
> plot(spl.dir,add=TRUE)
>
> To do that, I have to identify, for which point of my.data.set, to which
> voronoi tile it belongs to.
>
> Using spatstat, I can just extract to which tile belongs each point, using
> an ugly double loop, and without possibility to find back the value of the
> center of each voronoi cell:
>
> require(spatstat)
> tiles.id <- vector(mode="numeric",length=nrow(my.data.set))
> spl.tiles <- tiles(spl.dir)
> for (i.pt in 1:nrow(my.data.set)) {
>    for (i.tile in 1:length(spl.tiles)){
>       curr.tile <-spl.tiles[[i.tile]]
>       if ( inside.owin(my.data.set$x[i.pt],my.data.set$y[i.pt],curr.tile) )
> {
>          tiles.id[i.pt] <- i.tile
>       }
>    }
> }
>
> Using tripack, I would know how to retrieve the centre of a tile and go back
> to the original value (using cells() function), but unfortunately it misses
> an equivalent to inside.owin().
>
> Does any spatstat/tripack/other package user has an idea about it?
>
> Thanks,
>
> Pierre
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From John.Carson at shawgrp.com  Mon Oct 12 18:24:08 2009
From: John.Carson at shawgrp.com (Carson, John)
Date: Mon, 12 Oct 2009 11:24:08 -0500
Subject: [R-sig-Geo] Problem with gstat variogram estimation
In-Reply-To: <2E9C414912813E4EB981326983E0A10406C30C7A@inboexch.inbo.be>
References: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
	<2E9C414912813E4EB981326983E0A10406C30C7A@inboexch.inbo.be>
Message-ID: <79911294E2D6B14087F5AC36345A50BB02A8C713@entbtrxmb01.shawgrp.com>

Dear Thierry,

Thank you.  You're right.  I have small data sets, which are problematic. I need to use the duplicate pair data, but the default weighting in gstat for variograms doesn't work well with closely spaced data.  

I am looking now at REML instead.  

Best wishes,
John


John H. Carson Jr., PhD
Senior Statistician
Applied Sciences & Engineering 
Shaw Environmental & Infrastructure
16406 US Rte 224 East
Findlay, OH 45840
Phone 419-425-6156
Fax 419-425-6085
john.carson at shawgrp.com
 
http://www.shawgrp.com/
Shaw(tm) a world of Solutions(tm)
 
 

-----Original Message-----
From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: Monday, October 12, 2009 10:23 AM
To: Carson, John; r-sig-geo at stat.math.ethz.ch
Subject: RE: [R-sig-Geo] Problem with gstat variogram estimation

Dear John,

Isn't your problem rather a result from the unstable empirical variograms? Mainly due to the very low number of pairs per bin. Furthermore have a look at the weights that each bin gets in the fit.variogram() function. The default is N/h^2. In your case the first bin gets a weight of 2 whereas the other bins have weights ranging from 1e-3 tot 1e-4! Hence no surprise that the nugget is nearly identical to the semivariance of the first bin.

In this case I would not trust the results for fit.variogram(). Not because of bugs in gstat, but because I don't trust empirical variogram with that low number of pairs per bin.

HTH,

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics, methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Carson, John
Verzonden: maandag 12 oktober 2009 15:35
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] Problem with gstat variogram estimation

I have found anomalous behavior in gstat's variogram estimation. I have listed 3 example variograms below for small data sets.  In order to better estimate the nugget effect, I slightly perturbed the locations (by 1 foot increments) of duplicate results. The empirical variograms?are given below.  

Before I did this (I averaged duplicate values initially), a Gaussian model with 0 nugget was selected for the second variogram and pure nugget models for the first and third. I am using the candidate model list ('Nug', 'Exp', 'Sph', 'Gau', 'Mat', 'Cir', 'Lin', 'Bes') and selecting the model based on SSErr for preliminary testing purposes.?Afterward, the pure nugget models had the lowest SSErr and were selected.  Note that the variogram fits are completely controlled by the short range variance, because even the original pure nugget models are substantially different in the estimate of the nugget.  The fitted models are listed below.  Just by inspection, based on the numbers of pairs in these examples, a pure nugget model should be about halfway between the empirical semivariance of the last lag and the average of the other lags. However, the fitted nuggets are almost identical to the semivariance of the first last (dist = 1.4).  

It seems to me that this must be due to a bug in the GSTAT code.  I pointed this out to Edzer Pebesma, and he asked me to post it here.

The variograms are 

tmp.vgm
[[1]]
? np?????? dist????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.14174537?????? 0?????? 0 PC1
2? 2? 44.742603 6.70989788?????? 0?????? 0 PC1
3? 2? 57.707880 1.76351594?????? 0?????? 0 PC1
4? 4? 59.987678 1.52197310?????? 0?????? 0 PC1
5? 3? 71.512518 1.21348268?????? 0?????? 0 PC1
6? 1? 84.852877 0.05381849?????? 0?????? 0 PC1
7? 1? 97.266495 1.21827622?????? 0?????? 0 PC1
8? 3 112.237133 5.07947925?????? 0?????? 0 PC1
9 18 121.478856 1.93707676?????? 0?????? 0 PC1

[[2]]
? np?????? dist????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.09725079?????? 0?????? 0 PC2
2? 2? 44.742603 0.33598072?????? 0?????? 0 PC2
3? 2? 57.707880 0.39088727?????? 0?????? 0 PC2
4? 4? 59.987678 0.87315735?????? 0?????? 0 PC2
5? 3? 71.512518 0.14944845?????? 0?????? 0 PC2
6? 1? 84.852877 0.19809863?????? 0?????? 0 PC2
7? 1? 97.266495 0.63557814?????? 0?????? 0 PC2
8? 3 112.237133 1.92063948?????? 0?????? 0 PC2
9 18 121.478856 0.65468693?????? 0 ??????0 PC2

[[3]]
? np?????? dist?????? gamma dir.hor dir.ver? id
1? 4?? 1.414214 0.035250817?????? 0?????? 0 PC3
2? 2? 44.742603 0.105299796?????? 0?????? 0 PC3
3? 2? 57.707880 0.020245674?????? 0?????? 0 PC3
4? 4? 59.987678 0.124159836?????? 0?????? 0 PC3
5? 3? 71.512518 0.008112554?????? 0?????? 0 PC3
6? 1? 84.852877 0.034337591?????? 0?????? 0 PC3
7? 1? 97.266495 0.053879459?????? 0?????? 0 PC3
8? 3 112.237133 0.021922987?????? 0?????? 0 PC3
9 18 121.478856 0.085270969?????? 0?????? 0 PC3


But the fitted models are:

tmp.vgm.fit
[[1]]
? model???? psill range
1?? Nug 0.1483120???? 0

[[2]]
? model????? psill range
1?? Nug 0.09849419???? 0

[[3]]
? model????? psill range
1?? Nug 0.03535234???? 0




John H. Carson Jr., PhD
Senior Statistician
Applied Sciences & Engineering
Shaw Environmental & Infrastructure
16406 US Rte 224 East
Findlay, OH 45840
Phone 419-425-6156
Fax 419-425-6085
john.carson at shawgrp.com

http://www.shawgrp.com/
Shaw(tm) a world of Solutions(tm)

?

****Internet Email Confidentiality Footer**** Privileged/Confidential Information may be contained in this message. If you are not the addressee indicated in this message (or responsible for delivery of the message to such person), you may not copy or deliver this message to anyone. In such case, you should destroy this message and notify the sender by reply email.
Please advise immediately if you or your employer do not consent to Internet email for messages of this kind. Opinions, conclusions and other information in this message that do not relate to the official business of The Shaw Group Inc. or its subsidiaries shall be understood as neither given nor endorsed by it.
______________________________________ The Shaw Group Inc.
http://www.shawgrp.com

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Druk dit bericht a.u.b. niet onnodig af.
Please do not print this message unnecessarily.

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer 
en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is
door een geldig ondertekend document. The views expressed in  this message 
and any annex are purely those of the writer and may not be regarded as stating 
an official position of INBO, as long as the message is not confirmed by a duly 
signed document.


From John.Carson at shawgrp.com  Mon Oct 12 18:33:14 2009
From: John.Carson at shawgrp.com (Carson, John)
Date: Mon, 12 Oct 2009 11:33:14 -0500
Subject: [R-sig-Geo] Problem with gstat variogram estimation
In-Reply-To: <4AD33F4C.9010905@uni-muenster.de>
References: <79911294E2D6B14087F5AC36345A50BB02A8C59A@entbtrxmb01.shawgrp.com>
	<4AD33F4C.9010905@uni-muenster.de>
Message-ID: <79911294E2D6B14087F5AC36345A50BB02A8C723@entbtrxmb01.shawgrp.com>

Edzer,

Thank you.  I am now looking at REML since I have small data sets and I really need to use the duplicate data.

In the follow on I will need to accommodate adaptive sampling weights.  The first stage selection is systematic (with some minor modifications).  The second stage is sampling areas adjacent to any primary location that exceeds a threshold for one of the variables of interest.  Another reason, for example, that one might weight would be to reflect the number of (physical) component samples in a composite soil sample.  This may vary from laboratory result to laboratory result.  Is there any way to accommodate this in gstat?

Thanks,
John

John H. Carson Jr., PhD
Senior Statistician
Applied Sciences & Engineering 
Shaw Environmental & Infrastructure
16406 US Rte 224 East
Findlay, OH 45840
Phone 419-425-6156
Fax 419-425-6085
john.carson at shawgrp.com
 
http://www.shawgrp.com/
Shaw(tm) a world of Solutions(tm)
 
 

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: Monday, October 12, 2009 10:38 AM
To: Carson, John
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Problem with gstat variogram estimation

John, thanks for sharing this with r-sig-geo.

As Thierry mentioned, the default model fitting procedure (fit.variogram
in package gstat) uses weighted least squares, with weights proportional
to N_h/(h^2). This explains why the first lag gets so much weight.

For pure nugget models, this of course makes little sense; for other
models it often does. Argument fit.method gives you somewhat more
control. Give it value 1 to have N_h weights; give it value 6 to do
unweighted averaging (I agree that this information should be in the
fit.variogram documentation). The SSErr values will be uncomparable
accross different weighting schemes, as you might expect.
--
Edzer

Carson, John wrote:
> I have found anomalous behavior in gstat's variogram estimation. I have listed 3 example variograms below for small data sets.  In order to better estimate the nugget effect, I slightly perturbed the locations (by 1 foot increments) of duplicate results. The empirical variograms are given below.  
>
> Before I did this (I averaged duplicate values initially), a Gaussian model with 0 nugget was selected for the second variogram and pure nugget models for the first and third. I am using the candidate model list ('Nug', 'Exp', 'Sph', 'Gau', 'Mat', 'Cir', 'Lin', 'Bes') and selecting the model based on SSErr for preliminary testing purposes. Afterward, the pure nugget models had the lowest SSErr and were selected.  Note that the variogram fits are completely controlled by the short range variance, because even the original pure nugget models are substantially different in the estimate of the nugget.  The fitted models are listed below.  Just by inspection, based on the numbers of pairs in these examples, a pure nugget model should be about halfway between the empirical semivariance of the last lag and the average of the other lags. However, the fitted nuggets are almost identical to the semivariance of the first last (dist = 1.4).  
>
> It seems to me that this must be due to a bug in the GSTAT code.  I pointed this out to Edzer Pebesma, and he asked me to post it here.
>
> The variograms are 
>
> tmp.vgm
> [[1]]
>   np       dist      gamma dir.hor dir.ver  id
> 1  4   1.414214 0.14174537       0       0 PC1
> 2  2  44.742603 6.70989788       0       0 PC1
> 3  2  57.707880 1.76351594       0       0 PC1
> 4  4  59.987678 1.52197310       0       0 PC1
> 5  3  71.512518 1.21348268       0       0 PC1
> 6  1  84.852877 0.05381849       0       0 PC1
> 7  1  97.266495 1.21827622       0       0 PC1
> 8  3 112.237133 5.07947925       0       0 PC1
> 9 18 121.478856 1.93707676       0       0 PC1
>
> [[2]]
>   np       dist      gamma dir.hor dir.ver  id
> 1  4   1.414214 0.09725079       0       0 PC2
> 2  2  44.742603 0.33598072       0       0 PC2
> 3  2  57.707880 0.39088727       0       0 PC2
> 4  4  59.987678 0.87315735       0       0 PC2
> 5  3  71.512518 0.14944845       0       0 PC2
> 6  1  84.852877 0.19809863       0       0 PC2
> 7  1  97.266495 0.63557814       0       0 PC2
> 8  3 112.237133 1.92063948       0       0 PC2
> 9 18 121.478856 0.65468693       0       0 PC2
>
> [[3]]
>   np       dist       gamma dir.hor dir.ver  id
> 1  4   1.414214 0.035250817       0       0 PC3
> 2  2  44.742603 0.105299796       0       0 PC3
> 3  2  57.707880 0.020245674       0       0 PC3
> 4  4  59.987678 0.124159836       0       0 PC3
> 5  3  71.512518 0.008112554       0       0 PC3
> 6  1  84.852877 0.034337591       0       0 PC3
> 7  1  97.266495 0.053879459       0       0 PC3
> 8  3 112.237133 0.021922987       0       0 PC3
> 9 18 121.478856 0.085270969       0       0 PC3
>
>
> But the fitted models are:
>
> tmp.vgm.fit
> [[1]]
>   model     psill range
> 1   Nug 0.1483120     0
>
> [[2]]
>   model      psill range
> 1   Nug 0.09849419     0
>
> [[3]]
>   model      psill range
> 1   Nug 0.03535234     0
>
>
>
>
> John H. Carson Jr., PhD
> Senior Statistician
> Applied Sciences & Engineering 
> Shaw Environmental & Infrastructure
> 16406 US Rte 224 East
> Findlay, OH 45840
> Phone 419-425-6156
> Fax 419-425-6085
> john.carson at shawgrp.com
>
> http://www.shawgrp.com/
> Shaw(tm) a world of Solutions(tm)
>
>  
>
> ****Internet Email Confidentiality Footer****
> Privileged/Confidential Information may be contained in this
> message. If you are not the addressee indicated in this message (or
> responsible for delivery of the message to such person), you may
> not copy or deliver this message to anyone. In such case, you
> should destroy this message and notify the sender by reply email.
> Please advise immediately if you or your employer do not consent to
> Internet email for messages of this kind. Opinions, conclusions and
> other information in this message that do not relate to the
> official business of The Shaw Group Inc. or its subsidiaries shall
> be understood as neither given nor endorsed by it.
> ______________________________________ The Shaw Group Inc.
> http://www.shawgrp.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From moor0554 at umn.edu  Mon Oct 12 22:52:50 2009
From: moor0554 at umn.edu (Christopher T. Moore)
Date: 12 Oct 2009 15:52:50 -0500
Subject: [R-sig-Geo] Question about under/over/between arguments in
	library(classInt)
In-Reply-To: <Gophermail.2.0.0910121400040.1557@vs-a.tc.umn.edu>
References: <Gophermail.2.0.0910121400040.1557@vs-a.tc.umn.edu>
Message-ID: <Gophermail.2.0.0910121552500.834@vs-w.tc.umn.edu>

Greetings,

Has anyone else noticed a change in the behavior of the under/over/between 
arguments in the classInt package?

I utilized those arguments with classInt_0.1-9, but I haven't had any 
success with subsequent versions. I read the old and new help guides but 
couldn't see a change to the way those arguments must be submitted to the 
classIntervals() and findColours() functions. Perhaps I've overlooked a 
change?

In the meantime, I have gone back to using classInt_0.1-9. Below is a 
reproducible example.

Please let me know if you have any insights that would allow me to use the 
under/over/between legend arguments with the most recent version. Thanks.

Regards,
Chris

--
Christopher T. Moore, M.P.P.
Doctoral Student
Quantitative Methods in Education
University of Minnesota
44.9785?N, 93.2396?W
moor0554 at umn.edu
http://umn.edu/~moor0554



> ########################################
> utils:::menuInstallPkgs()
--- Please select a CRAN mirror for use in this session ---
trying URL 
'http://probability.ca/cran/bin/windows/contrib/2.9/classInt_0.1-12.zip'
Content type 'application/zip' length 73875 bytes (72 Kb)
opened URL
downloaded 72 Kb
package 'classInt' successfully unpacked and MD5 sums checked
> plotvar <- 1:9
> nclr <- 3
> library(RColorBrewer)
> plotclr=brewer.pal(nclr,"Blues")
> library(classInt)
Loading required package: class
Loading required package: e1071
> (class <- classIntervals(plotvar, nclr, style="quantile"))
style: quantile
  one of 28 possible partitions of this variable into 3 classes
       [1,3.666667) [3.666667,6.333333)        [6.333333,9] 
                  3                   3                   3 
> (colcode <- findColours(class, plotclr, digits=3, between="to", 
> under="<", over=">="))
[1] "#DEEBF7" "#DEEBF7" "#DEEBF7" "#9ECAE1" "#9ECAE1" "#9ECAE1" "#3182BD" 
"#3182BD" "#3182BD"
attr(,"palette")
[1] "#DEEBF7" "#9ECAE1" "#3182BD"
attr(,"table")
       [1,3.666667) [3.666667,6.333333)        [6.333333,9] 
                  3                   3                   3 
> sessionInfo()
R version 2.9.2 (2009-08-24) 
i386-pc-mingw32 
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
other attached packages:
[1] classInt_0.1-12 e1071_1.5-19 class_7.2-48 RColorBrewer_1.0-2


> utils:::menuInstallLocal()
package 'classInt' successfully unpacked and MD5 sums checked
updating HTML package descriptions
> plotvar <- 1:9
> nclr <- 3
> library(RColorBrewer)
> plotclr=brewer.pal(nclr,"Blues")
> library(classInt)
Loading required package: class
Loading required package: e1071
> (class <- classIntervals(plotvar, nclr, style="quantile"))
style: quantile
  one of 28 possible partitions of this variable into 3 classes
     under 3.666667 3.666667 - 6.333333       over 6.333333 
                  3                   3                   3 
> (colcode <- findColours(class, plotclr, digits=3, between="to", 
> under="<", over=">="))
[1] "#DEEBF7" "#DEEBF7" "#DEEBF7" "#9ECAE1" "#9ECAE1" "#9ECAE1" "#3182BD" 
"#3182BD" "#3182BD"
attr(,"palette")
[1] "#DEEBF7" "#9ECAE1" "#3182BD"
attr(,"table")
      < 3.67 3.67 to 6.33      >= 6.33 
           3            3            3 
> sessionInfo()
R version 2.9.2 (2009-08-24) 
i386-pc-mingw32 
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
other attached packages:
[1] classInt_0.1-9 e1071_1.5-19 class_7.2-48 RColorBrewer_1.0-2
> ########################################


From pierre.roudier at gmail.com  Tue Oct 13 02:01:42 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Tue, 13 Oct 2009 11:01:42 +1100
Subject: [R-sig-Geo] Finding to which Voronoi/Dirichlet a point belongs
	to
In-Reply-To: <4AD343C0.5040203@geo.uu.nl>
References: <e4178da60910072247y35e3bdb8x24ac51939f18a6a8@mail.gmail.com> 
	<4AD343C0.5040203@geo.uu.nl>
Message-ID: <e4178da60910121701o115c7341u75b301ef3f42d0d4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091013/fa00438e/attachment.pl>

From gianni.lavaredo at gmail.com  Tue Oct 13 03:42:42 2009
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Mon, 12 Oct 2009 18:42:42 -0700
Subject: [R-sig-Geo] problem to set-up RANDOMFOREST
Message-ID: <518dff330910121842g7defa84fk353be6450ea6315f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091012/e89aec59/attachment.pl>

From r.hijmans at gmail.com  Tue Oct 13 05:51:59 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 12 Oct 2009 20:51:59 -0700
Subject: [R-sig-Geo] problem to set-up RANDOMFOREST
In-Reply-To: <518dff330910121842g7defa84fk353be6450ea6315f@mail.gmail.com>
References: <518dff330910121842g7defa84fk353be6450ea6315f@mail.gmail.com>
Message-ID: <dc22b2570910122051w6f8711f2t5efbe300cffecc2d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091012/8ebe2eda/attachment.pl>

From peron at cebc.cnrs.fr  Tue Oct 13 16:00:55 2009
From: peron at cebc.cnrs.fr (Peron Clara)
Date: Tue, 13 Oct 2009 16:00:55 +0200
Subject: [R-sig-Geo] NSIDC Sea-ice Projection
Message-ID: <4AD48817.6010200@cebc.cnrs.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091013/fbdce3cb/attachment.pl>

From saldanha.plangeo at gmail.com  Tue Oct 13 16:09:10 2009
From: saldanha.plangeo at gmail.com (Raphael Saldanha)
Date: Tue, 13 Oct 2009 11:09:10 -0300
Subject: [R-sig-Geo] GWR and NAs
Message-ID: <c85849370910130709j1f58ccc9sb4b80531cc1caa30@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091013/f1dffbbc/attachment.pl>

From yud at mail.montclair.edu  Tue Oct 13 16:24:55 2009
From: yud at mail.montclair.edu (Danlin Yu)
Date: Tue, 13 Oct 2009 10:24:55 -0400
Subject: [R-sig-Geo] GWR and NAs
In-Reply-To: <c85849370910130709j1f58ccc9sb4b80531cc1caa30@mail.gmail.com>
References: <c85849370910130709j1f58ccc9sb4b80531cc1caa30@mail.gmail.com>
Message-ID: <4AD48DB7.2080606@mail.montclair.edu>

Raphael Saldanha:

Based on the output you provided, apparently these NAs are either 
ignored or treated as zeros. When you got a CV score as zero, you shall 
be aware that there is definitely a problem (all the adaptive qs produce 
the same 0, that means you are basically regression the dependent 
variable on itself, no independent variables participate in the 
regression (correct me if I am wrong).

I would suggest you investigate your data by exploring it with maps, and 
see if it is possible to ether interpolate those NAs or pick them out 
before you conduct a GWR analysis.

Hope this helps,

Danlin

Raphael Saldanha ??:
> Hi!
>
> I'm trying to use GWR with a dataset who has a lot of NAs. How spgwr
> considers NAs?
>
> As a test, I'm having the following results:
>
>   
>> g.adapt.gauss.00 <- gwr.sel(pib00 ~ cv00 + le00 + ma00 + ou00, data=dados,
>>     
> adapt=TRUE, coords=cbind(dados$x, dados$y))
> Adaptive q: 0.381966 CV score: 0
> Adaptive q: 0.618034 CV score: 0
> Adaptive q: 0.763932 CV score: 0
> Adaptive q: 0.854102 CV score: 0
> Adaptive q: 0.90983 CV score: 0
> Adaptive q: 0.944272 CV score: 0
> Adaptive q: 0.9655581 CV score: 0
> Adaptive q: 0.9787138 CV score: 0
> Adaptive q: 0.9868444 CV score: 0
> Adaptive q: 0.9918694 CV score: 0
> Adaptive q: 0.994975 CV score: 0
> Adaptive q: 0.9968944 CV score: 0
> Adaptive q: 0.9980806 CV score: 0
> Adaptive q: 0.9988138 CV score: 0
> Adaptive q: 0.9992669 CV score: 0
> Adaptive q: 0.9995469 CV score: 0
> Adaptive q: 0.99972 CV score: 0
> Adaptive q: 0.999827 CV score: 0
> Adaptive q: 0.999893 CV score: 0
> Adaptive q: 0.9999339 CV score: 0
> Adaptive q: 0.9999339 CV score: 0
> Houve 50 ou mais avisos (use warnings() para ver os primeiros 50)
>
>   
>> res.adpt.00 <- gwr(pib00 ~ cv00 + le00 + ma00 + ou00, data=dados,
>>     
> adapt=g.adapt.gauss.00, coords=cbind(dados$x, dados$y))
> Erro em gwr(pib00 ~ cv00 + le00 + ma00 + ou00, data = dados, adapt =
> g.adapt.gauss.00,  :
>   new data matrix rows mismatch
>
>
>
> Regards,
>
> Raphael Saldanha
> BRAZIL
> saldanha.plangeo at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From tom.gottfried at wzw.tum.de  Tue Oct 13 17:34:36 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Tue, 13 Oct 2009 17:34:36 +0200
Subject: [R-sig-Geo] passing SQL through readOGR()
Message-ID: <4AD49E0C.3000404@wzw.tum.de>

Hi list,

is there a way to pass any SQL-statement through readOGR (as with the -sql Option to ogr2ogr). I
want to import a subset of a large dataset from PostGIS into R. I know it's possible with for
example RODBC and then coercing the resulting data.frame to an sp-class, but I wonder if I can do it
directly through readOGR().

Thanks!
Tom


From b.rowlingson at lancaster.ac.uk  Tue Oct 13 17:47:58 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 13 Oct 2009 16:47:58 +0100
Subject: [R-sig-Geo] passing SQL through readOGR()
In-Reply-To: <4AD49E0C.3000404@wzw.tum.de>
References: <4AD49E0C.3000404@wzw.tum.de>
Message-ID: <d8ad40b50910130847q27365e2avfe8fa1048ddad1da@mail.gmail.com>

On Tue, Oct 13, 2009 at 4:34 PM, Tom Gottfried <tom.gottfried at wzw.tum.de> wrote:
> Hi list,
>
> is there a way to pass any SQL-statement through readOGR (as with the -sql Option to ogr2ogr). I
> want to import a subset of a large dataset from PostGIS into R. I know it's possible with for
> example RODBC and then coercing the resulting data.frame to an sp-class, but I wonder if I can do it
> directly through readOGR().

 If you cant get the sql into readOGR directly (and I anticipate a
post from Roger telling you how to do that to appear about three
seconds after I hit 'send') then you might be able to do it with the
OGR virtual driver:

http://www.gdal.org/ogr/drv_vrt.html

There's an example there with some SQL embedded in the XML.

Barry

3...2...1....


From Roger.Bivand at nhh.no  Tue Oct 13 20:05:17 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 13 Oct 2009 20:05:17 +0200 (CEST)
Subject: [R-sig-Geo] passing SQL through readOGR()
In-Reply-To: <4AD49E0C.3000404@wzw.tum.de>
References: <4AD49E0C.3000404@wzw.tum.de>
Message-ID: <alpine.LRH.2.00.0910132004240.30959@reclus.nhh.no>

On Tue, 13 Oct 2009, Tom Gottfried wrote:

> Hi list,
>
> is there a way to pass any SQL-statement through readOGR (as with the 
> -sql Option to ogr2ogr). I want to import a subset of a large dataset 
> from PostGIS into R. I know it's possible with for example RODBC and 
> then coercing the resulting data.frame to an sp-class, but I wonder if I 
> can do it directly through readOGR().

No, not implemented. Please use ogr2ogr externally for this, implementing 
it internally would be duplicating code.

Roger

>
> Thanks!
> Tom
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From gianni.lavaredo at gmail.com  Wed Oct 14 01:59:03 2009
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Tue, 13 Oct 2009 16:59:03 -0700
Subject: [R-sig-Geo] select a row in a data.frame
Message-ID: <518dff330910131659kc0a9fa5o6a94fefc7eaf46e2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091013/1b49482f/attachment.pl>

From dan.putler at sauder.ubc.ca  Wed Oct 14 02:55:33 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Tue, 13 Oct 2009 17:55:33 -0700
Subject: [R-sig-Geo] select a row in a data.frame
In-Reply-To: <21880_1255478382_1255478382_518dff330910131659kc0a9fa5o6a94fefc7eaf46e2@mail.gmail.com>
References: <21880_1255478382_1255478382_518dff330910131659kc0a9fa5o6a94fefc7eaf46e2@mail.gmail.com>
Message-ID: <1255481733.13732.19.camel@whitebox>

Hi Gianni,

First the chide, you are asking a general (very beginner) R question on
the Geospatial Special Interest Group mailing list, which isn't the
right list for your question. The closest to the correct list is R-Help,
but this is really something one learns from books on R, which there are
a number of, and often available in online in PDF (start with An
Introduction to R, http://cran.r-project.org/doc/manuals/R-intro.pdf).

Now the answer to your question:

BestResult_R <- newData[newData$result == max(newData$result), ]

Dan Putler

On Tue, 2009-10-13 at 16:59 -0700, gianni lavaredo wrote:
> thanks for help,
> 
> I have a data.frame "newData" with 7 columns and 91 rows. i wish to find the
> row in the second column "X" with the max value and save all 7 values (=all
> columns) in a new data.frame
> 
>  # max value result for row
>  Max.Result <- max(newData$result)
>  select the row with the max value
>  row <- which(Max.Result  == max(Max.Result ))
>  BestResult_R <- newData[row,]
> 
> but I have a same problems to set right the code.
> 
> thanks
> 
> Gianni
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From miguez at illinois.edu  Wed Oct 14 03:40:14 2009
From: miguez at illinois.edu (Fernando Miguez)
Date: Tue, 13 Oct 2009 21:40:14 -0400
Subject: [R-sig-Geo] select a row in a data.frame
In-Reply-To: <1255481733.13732.19.camel@whitebox>
References: <21880_1255478382_1255478382_518dff330910131659kc0a9fa5o6a94fefc7eaf46e2@mail.gmail.com>
	<1255481733.13732.19.camel@whitebox>
Message-ID: <4AD52BFE.3060206@illinois.edu>

Hi Gianni,

See also which.max

Fernando

Dan Putler wrote:
> Hi Gianni,
> 
> First the chide, you are asking a general (very beginner) R question on
> the Geospatial Special Interest Group mailing list, which isn't the
> right list for your question. The closest to the correct list is R-Help,
> but this is really something one learns from books on R, which there are
> a number of, and often available in online in PDF (start with An
> Introduction to R, http://cran.r-project.org/doc/manuals/R-intro.pdf).
> 
> Now the answer to your question:
> 
> BestResult_R <- newData[newData$result == max(newData$result), ]
> 
> Dan Putler
> 
> On Tue, 2009-10-13 at 16:59 -0700, gianni lavaredo wrote:
>> thanks for help,
>>
>> I have a data.frame "newData" with 7 columns and 91 rows. i wish to find the
>> row in the second column "X" with the max value and save all 7 values (=all
>> columns) in a new data.frame
>>
>>  # max value result for row
>>  Max.Result <- max(newData$result)
>>  select the row with the max value
>>  row <- which(Max.Result  == max(Max.Result ))
>>  BestResult_R <- newData[row,]
>>
>> but I have a same problems to set right the code.
>>
>> thanks
>>
>> Gianni
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Fernando E. Miguez
Energy Biosciences Institute
http://netfiles.uiuc.edu/miguez/www/


From Adrian.Baddeley at csiro.au  Wed Oct 14 12:58:59 2009
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Wed, 14 Oct 2009 18:58:59 +0800
Subject: [R-sig-Geo] Finding to which Voronoi/Dirichlet a point belongs
Message-ID: <4AD5AEF3.8000609@csiro.au>

Pierre Roudier wrote:

> >> I am trying to use the Voronoi tesselation of a point pattern to predict
> >> values of a second one. [ ...]  To do that, I have to identify, for which point of my.data.set, to which voronoi tile it belongs to.
>   

> >> Using spatstat, I can just extract to which tile belongs each point, using
> >> an ugly double loop, 
There is no need for a loop. In spatstat, if X is a point pattern and Z 
is a tessellation, then cut(X,Z) produces a marked point pattern in 
which each point of X is marked by the tile of Z which contains it. See 
help(cut.ppp)

In the special case of a Voronoi/Dirichlet tessellation, you can also 
use the fact that the tiles are determined by which of the tile centres 
is closest. Thus if X and Y are point patterns, then   
nncross(X,Y)$which   produces a vector of integers specifying which 
point of Y is nearest to each given point of X. Thus, X[i] lies in the 
tile around nncross(X,Y)$which[i].

Adrian Baddeley


From R.Catarino at MARLAB.AC.UK  Wed Oct 14 14:47:05 2009
From: R.Catarino at MARLAB.AC.UK (Rui Catarino)
Date: Wed, 14 Oct 2009 13:47:05 +0100
Subject: [R-sig-Geo] Multiple polygons
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C581202722F47@mail4.marlab.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091014/c5ea56ca/attachment.pl>

From Roger.Bivand at nhh.no  Wed Oct 14 15:30:09 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 14 Oct 2009 15:30:09 +0200 (CEST)
Subject: [R-sig-Geo] Multiple polygons
In-Reply-To: <A0F8DAFB525DED4ABAF6841BB11C581202722F47@mail4.marlab.ac.uk>
References: <A0F8DAFB525DED4ABAF6841BB11C581202722F47@mail4.marlab.ac.uk>
Message-ID: <alpine.LRH.2.00.0910141516050.1696@reclus.nhh.no>

On Wed, 14 Oct 2009, Rui Catarino wrote:

> Hello to all,
>
> This is my first attempt to use GIS tools in R so I'm sorry if my 
> question is to na?ve, but the truth is that I've spent several hours 
> looking in forum's and packages for a solution with no joy.
>
> What I'm trying to achieve is to create multiple polygons (around 150) 
> based in a table with (x,y) coordinates. This table also as two extra 
> fields one which will be the code (numeric value) for each polygon. The 
> second field is the numeric order in which the points in each polygon 
> should be joined.
>

What do the input data look like? Is there a list of +/-150 data.frame 
objects, or a single data.frame object (read with read.table()). If the 
latter, use split() first to make a list of data.frames, where the list 
components will take the name of the ID column values (assumed all 
identical for coordinates belonging to the same polygon).

Once you've got the list, say lst, you'll use lapply() to build a list of 
Polygons objects, each built of a list with a single Polygon object. This 
needs the coordinates in the right order and closed, so something like:

crds <- cbind(obj$x, obj$y)
crds <- crds[obj$order,]
crds <- rbind(crds, crds[1,])

should get them re-ordered, and then ring-closed. Insert the names as ID 
as appropriate. If this seems obscure, provide a very simple example data 
set on a website - it is actually quite straightforward if the data are 
cleanly organised.

Hope this helps,

Roger

>
>
> Thanks in advance
>
> Rui
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From R.Catarino at MARLAB.AC.UK  Wed Oct 14 16:54:56 2009
From: R.Catarino at MARLAB.AC.UK (Rui Catarino)
Date: Wed, 14 Oct 2009 15:54:56 +0100
Subject: [R-sig-Geo] Multiple polygons
In-Reply-To: <alpine.LRH.2.00.0910141516050.1696@reclus.nhh.no>
References: <A0F8DAFB525DED4ABAF6841BB11C581202722F47@mail4.marlab.ac.uk>
	<alpine.LRH.2.00.0910141516050.1696@reclus.nhh.no>
Message-ID: <A0F8DAFB525DED4ABAF6841BB11C581202722F4F@mail4.marlab.ac.uk>

Hello again,

Thank you for such a quick reply.
 
You were right, it seems a bit obscure so following your suggestion I
attach a small example of what looks like my table. The list is in excel
format and I usually use the package xlsReadWrite to read the excel
files.

Once again thank you for your trouble
Rui  

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: 14 October 2009 14:30
To: Rui Catarino
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Multiple polygons

On Wed, 14 Oct 2009, Rui Catarino wrote:

> Hello to all,
>
> This is my first attempt to use GIS tools in R so I'm sorry if my 
> question is to na?ve, but the truth is that I've spent several hours 
> looking in forum's and packages for a solution with no joy.
>
> What I'm trying to achieve is to create multiple polygons (around 150)

> based in a table with (x,y) coordinates. This table also as two extra 
> fields one which will be the code (numeric value) for each polygon.
The 
> second field is the numeric order in which the points in each polygon 
> should be joined.
>

What do the input data look like? Is there a list of +/-150 data.frame 
objects, or a single data.frame object (read with read.table()). If the 
latter, use split() first to make a list of data.frames, where the list 
components will take the name of the ID column values (assumed all 
identical for coordinates belonging to the same polygon).

Once you've got the list, say lst, you'll use lapply() to build a list
of 
Polygons objects, each built of a list with a single Polygon object.
This 
needs the coordinates in the right order and closed, so something like:

crds <- cbind(obj$x, obj$y)
crds <- crds[obj$order,]
crds <- rbind(crds, crds[1,])

should get them re-ordered, and then ring-closed. Insert the names as ID

as appropriate. If this seems obscure, provide a very simple example
data 
set on a website - it is actually quite straightforward if the data are 
cleanly organised.

Hope this helps,

Roger

>
>
> Thanks in advance
>
> Rui
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


______________________________________________________________________
This email has been scanned by the MessageLabs Email Security System.
For more information please visit http://www.messagelabs.com/email 
______________________________________________________________________
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Example.xls
Type: application/vnd.ms-excel
Size: 16384 bytes
Desc: Example.xls
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091014/2149d2de/attachment.xls>

From p.hiemstra at geo.uu.nl  Wed Oct 14 17:58:23 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 14 Oct 2009 17:58:23 +0200
Subject: [R-sig-Geo] Strange behavior of spsample when sampling from Sgrid
Message-ID: <4AD5F51F.2000706@geo.uu.nl>

Dear list,

I spotted the following behavior when using overlay to sample from a 
SpatialPixels or SpatialGrid. The following illustrates my point:

  library(sp)
  data(meuse.grid)
  gridded(meuse.grid) = ~x+y
  meuse2 = spsample(meuse.grid,
                    type = "regular",
                    cellsize = c(40, 40),
                    offset = c(0.5,0.5))
  spplot(meuse.grid, "dist",
                sp.layout = list("sp.points", meuse2[1:20,]))

It seems that when using a grid as input for spsample it samples from 
left bottom to right top instead of from left top to right bottom. When 
using the following command to use overlay to extract data from 'meuse' 
and plotting the result illustrates my problem:

  meuse.grid$dist_from_meuse2 = meuse.grid$dist[overlay(meuse.grid, meuse2)]
  spplot(meuse.grid, c("dist", "dist_from_meuse2"))

Transforming meuse2 to SpatialPixels, to SpatialGrid and back to 
SpatialPixels restores the order in meuse2 to 'top-left to bottom right'.

  gridded(meuse2) = TRUE
  fullgrid(meuse2) = TRUE
  fullgrid(meuse2) = FALSE

  val = meuse.grid$dist[overlay(meuse.grid, meuse2)]
  meuse.grid$dist_from_meuse2_pt2 = val[!is.na(val)]
  spplot(meuse.grid, c("dist", "dist_from_meuse2",
                                "dist_from_meuse2_pt2"))

But this is ofcourse not ideal. Is there a way to force spsample to 
always sample from top left to bottom right?

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Wed Oct 14 18:01:19 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 14 Oct 2009 18:01:19 +0200
Subject: [R-sig-Geo] Strange behavior of spsample when sampling from
	Sgrid
In-Reply-To: <4AD5F51F.2000706@geo.uu.nl>
References: <4AD5F51F.2000706@geo.uu.nl>
Message-ID: <4AD5F5CF.5020202@geo.uu.nl>

...and in addition:

 > sessionInfo()
R version 2.9.2 (2009-08-24)
i486-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] sp_0.9-44

loaded via a namespace (and not attached):
[1] grid_2.9.2      lattice_0.17-20 tools_2.9.2


Paul Hiemstra wrote:
> Dear list,
>
> I spotted the following behavior when using overlay to sample from a 
> SpatialPixels or SpatialGrid. The following illustrates my point:
>
>  library(sp)
>  data(meuse.grid)
>  gridded(meuse.grid) = ~x+y
>  meuse2 = spsample(meuse.grid,
>                    type = "regular",
>                    cellsize = c(40, 40),
>                    offset = c(0.5,0.5))
>  spplot(meuse.grid, "dist",
>                sp.layout = list("sp.points", meuse2[1:20,]))
>
> It seems that when using a grid as input for spsample it samples from 
> left bottom to right top instead of from left top to right bottom. 
> When using the following command to use overlay to extract data from 
> 'meuse' and plotting the result illustrates my problem:
>
>  meuse.grid$dist_from_meuse2 = meuse.grid$dist[overlay(meuse.grid, 
> meuse2)]
>  spplot(meuse.grid, c("dist", "dist_from_meuse2"))
>
> Transforming meuse2 to SpatialPixels, to SpatialGrid and back to 
> SpatialPixels restores the order in meuse2 to 'top-left to bottom right'.
>
>  gridded(meuse2) = TRUE
>  fullgrid(meuse2) = TRUE
>  fullgrid(meuse2) = FALSE
>
>  val = meuse.grid$dist[overlay(meuse.grid, meuse2)]
>  meuse.grid$dist_from_meuse2_pt2 = val[!is.na(val)]
>  spplot(meuse.grid, c("dist", "dist_from_meuse2",
>                                "dist_from_meuse2_pt2"))
>
> But this is ofcourse not ideal. Is there a way to force spsample to 
> always sample from top left to bottom right?
>
> cheers,
> Paul
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From tom.gottfried at wzw.tum.de  Wed Oct 14 18:20:31 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Wed, 14 Oct 2009 18:20:31 +0200
Subject: [R-sig-Geo] plot points in grid-plot with sp.layout
Message-ID: <4AD5FA4F.4010504@wzw.tum.de>

Hi list,

the last plot in the following code ends up with error messages in the plot:

data(meuse.grid)
data(meuse)
coordinates(meuse.grid) <- ~x+y
coordinates(meuse) <- ~x+y
meuse.grid <- as(as(meuse.grid, "SpatialPixelsDataFrame"),
    "SpatialGridDataFrame")

spplot(meuse) # works
spplot(meuse, sp.layout=list(sp.points,
    meuse, col="red")) # works

spplot(meuse.grid) # works
spplot(meuse.grid, sp.layout=list(sp.points, meuse)) # does not work


What can I do to make the points being plotted on top of the grid?

Thanks in advance!!

Tom


From Roger.Bivand at nhh.no  Wed Oct 14 21:26:20 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 14 Oct 2009 21:26:20 +0200 (CEST)
Subject: [R-sig-Geo] Multiple polygons
In-Reply-To: <A0F8DAFB525DED4ABAF6841BB11C581202722F4F@mail4.marlab.ac.uk>
References: <A0F8DAFB525DED4ABAF6841BB11C581202722F47@mail4.marlab.ac.uk>
	<alpine.LRH.2.00.0910141516050.1696@reclus.nhh.no>
	<A0F8DAFB525DED4ABAF6841BB11C581202722F4F@mail4.marlab.ac.uk>
Message-ID: <alpine.LRH.2.00.0910142113020.2325@reclus.nhh.no>

On Wed, 14 Oct 2009, Rui Catarino wrote:

> Hello again,
>
> Thank you for such a quick reply.
>
> You were right, it seems a bit obscure so following your suggestion I
> attach a small example of what looks like my table. The list is in excel
> format and I usually use the package xlsReadWrite to read the excel
> files.

After converting to CSV (no Excel here):

Example.df <- read.csv("Example.csv")
ldf <- split(Example.df, Example.df$Polygon_n)
# split into list on polygon ID
lpls <- lapply(ldf, function(x) {
   crds <- cbind(x$Long, x$Lat)
   crds <- crds[x$order,]
   crds <- rbind(crds, crds[1,])
   ID <- as.character(unique(x$Polygon_n))
   Polygons(list(Polygon(crds)), ID=ID)
})
# lapply to make a list of Polygons objects
lvdf <- lapply(ldf, function(x) {
   rn <- as.character(unique(x$Polygon_n))
   StartDate <- strptime(unique(as.character(x$StartDate)), format="%m/%d/%Y")
   CloseDate <- strptime(unique(as.character(x$CloseDate)), format="%m/%d/%Y")
   AnalysisDate <- strptime(unique(as.character(x$AnalysisDate)),
     format="%m/%d/%Y")
   data.frame(StartDate=StartDate, CloseDate=CloseDate,
     AnalysisDate=AnalysisDate, row.names=rn)
})
vdf <- do.call("rbind", lvdf)
# lapply to extract the unique values and make them into POSIXlt objects 
# as they are dates, then do.call("rbind", ...) to stick the n single
# line data.frames together
spdf <- SpatialPolygonsDataFrame(SpatialPolygons(lpls,
   proj4string=CRS("+proj=longlat +datum=WGS84")), data=vdf)
# assemble the list of Polygons objects and matching data.frame
# as a SpatialPolygonsDataFrame

All the *apply() functions are really user friendly and save very much 
more time than that needed to learn them. Think of lapply() and sapply() 
like a for loop along a vector, usually along a list, doing something to 
each component - here custom functions. Starting on a small, 
representative example usually helps to get the incantation right.

Note that the orders were all redundant here, so adjustment may be needed 
there.

Hope this helps,

Roger


>
> Once again thank you for your trouble
> Rui
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: 14 October 2009 14:30
> To: Rui Catarino
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Multiple polygons
>
> On Wed, 14 Oct 2009, Rui Catarino wrote:
>
>> Hello to all,
>>
>> This is my first attempt to use GIS tools in R so I'm sorry if my
>> question is to na?ve, but the truth is that I've spent several hours
>> looking in forum's and packages for a solution with no joy.
>>
>> What I'm trying to achieve is to create multiple polygons (around 150)
>
>> based in a table with (x,y) coordinates. This table also as two extra
>> fields one which will be the code (numeric value) for each polygon.
> The
>> second field is the numeric order in which the points in each polygon
>> should be joined.
>>
>
> What do the input data look like? Is there a list of +/-150 data.frame
> objects, or a single data.frame object (read with read.table()). If the
> latter, use split() first to make a list of data.frames, where the list
> components will take the name of the ID column values (assumed all
> identical for coordinates belonging to the same polygon).
>
> Once you've got the list, say lst, you'll use lapply() to build a list
> of
> Polygons objects, each built of a list with a single Polygon object.
> This
> needs the coordinates in the right order and closed, so something like:
>
> crds <- cbind(obj$x, obj$y)
> crds <- crds[obj$order,]
> crds <- rbind(crds, crds[1,])
>
> should get them re-ordered, and then ring-closed. Insert the names as ID
>
> as appropriate. If this seems obscure, provide a very simple example
> data
> set on a website - it is actually quite straightforward if the data are
> cleanly organised.
>
> Hope this helps,
>
> Roger
>
>>
>>
>> Thanks in advance
>>
>> Rui
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mudiver1200 at yahoo.com  Thu Oct 15 00:19:00 2009
From: mudiver1200 at yahoo.com (Tim Clark)
Date: Wed, 14 Oct 2009 15:19:00 -0700 (PDT)
Subject: [R-sig-Geo] Scale bar in base plot
Message-ID: <996840.35127.qm@web36107.mail.mud.yahoo.com>

Dear List,

I am trying to place a scal bar in a plot and can't find a function to do it with base graphics.  Is there one?  I have mfrow = c(3,3) and would like to place the scale bar in the last pannel. An example of what I am wanting follows.  

Thanks!

x <- 0:12
y <- sin(pi/5 * x)
op <- par(mfrow = c(3,3), mar = .1+ c(2,2,3,1))
for (tp in c("p","l","b",  "c","o","h",  "s","S")) {
   plot(y ~ x, type = tp,
        main = paste("plot(*, type = \"",tp,"\")",sep=""))
   if(tp == "S") {
      lines(x,y, type = "s", col = "red", lty = 2)
      mtext("lines(*, type = \"s\", ...)", col = "red", cex=.8)
   }
}

#Plot a scale bar in the bottom right pannel
plot.new()
legend("topleft",legend=c("Scale Bar"))

par(op)




Tim Clark
Department of Zoology 
University of Hawaii


From p.hiemstra at geo.uu.nl  Thu Oct 15 10:33:37 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 15 Oct 2009 10:33:37 +0200
Subject: [R-sig-Geo] plot points in grid-plot with sp.layout
In-Reply-To: <4AD5FA4F.4010504@wzw.tum.de>
References: <4AD5FA4F.4010504@wzw.tum.de>
Message-ID: <4AD6DE61.7040305@geo.uu.nl>

Tom Gottfried wrote:
> Hi list,
>
> the last plot in the following code ends up with error messages in the plot:
>
> data(meuse.grid)
> data(meuse)
> coordinates(meuse.grid) <- ~x+y
> coordinates(meuse) <- ~x+y
> meuse.grid <- as(as(meuse.grid, "SpatialPixelsDataFrame"),
>     "SpatialGridDataFrame")
>
> spplot(meuse) # works
> spplot(meuse, sp.layout=list(sp.points,
>     meuse, col="red")) # works
>
> spplot(meuse.grid) # works
> spplot(meuse.grid, sp.layout=list(sp.points, meuse)) # does not work
>   
works:				  ___________
spplot(meuse.grid, sp.layout=list("sp.points", meuse))

use quotes around sp.points. Or else it will look for the R object sp.points, which is not present.

cheers,
Paul

>
> What can I do to make the points being plotted on top of the grid?
>
> Thanks in advance!!
>
> Tom
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Thu Oct 15 11:47:29 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 15 Oct 2009 11:47:29 +0200
Subject: [R-sig-Geo] plot points in grid-plot with sp.layout
In-Reply-To: <4AD6DE61.7040305@geo.uu.nl>
References: <4AD5FA4F.4010504@wzw.tum.de> <4AD6DE61.7040305@geo.uu.nl>
Message-ID: <4AD6EFB1.4050301@geo.uu.nl>

Paul Hiemstra wrote:
> Tom Gottfried wrote:
>> Hi list,
>>
>> the last plot in the following code ends up with error messages in 
>> the plot:
>>
>> data(meuse.grid)
>> data(meuse)
>> coordinates(meuse.grid) <- ~x+y
>> coordinates(meuse) <- ~x+y
>> meuse.grid <- as(as(meuse.grid, "SpatialPixelsDataFrame"),
>>     "SpatialGridDataFrame")
>>
>> spplot(meuse) # works
>> spplot(meuse, sp.layout=list(sp.points,
>>     meuse, col="red")) # works
>>
>> spplot(meuse.grid) # works
>> spplot(meuse.grid, sp.layout=list(sp.points, meuse)) # does not work
>>   
> works:                  ___________
> spplot(meuse.grid, sp.layout=list("sp.points", meuse))
>
> use quotes around sp.points. Or else it will look for the R object 
> sp.points, which is not present.
>
> cheers,
> Paul
in addition:

look at:

http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:spatial_data_visualization

for some more info.

cheers,
Paul
>
>>
>> What can I do to make the points being plotted on top of the grid?
>>
>> Thanks in advance!!
>>
>> Tom
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From r.j.forsyth at newcastle.ac.uk  Thu Oct 15 12:28:23 2009
From: r.j.forsyth at newcastle.ac.uk (Rob Forsyth)
Date: Thu, 15 Oct 2009 11:28:23 +0100
Subject: [R-sig-Geo] Very basic figure question
Message-ID: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>

A complete geo-tyro demonstrating ignorance here: please be tolerant!

I have a large dataset comprising the results of a questionnaire from  
UK respondents. I am interested in geographic variation in responses  
and have built mixed-effect models incorporating County/Unitary  
Authority/Local Authority (a level of local government in the UK) as a  
factor-level random effect in lme4. Extracting the intercept of the  
random effects I can generate a normalised 0-1 score for each local  
authority. I would like to illustrate the results of this analysis and  
generate a map showing LAs coloured using this normalised score to set  
gray scale.

We have campus access to ArcGIS and related programmes but I have no  
knowledge of these whatsoever and wondered if for this limited task I  
could work within R? Are there any suitable public domain map objects  
and how would I go about this?

Thank you


From bgr at bgs.ac.uk  Thu Oct 15 12:52:39 2009
From: bgr at bgs.ac.uk (Rawlins, Barry G)
Date: Thu, 15 Oct 2009 11:52:39 +0100
Subject: [R-sig-Geo] Overlay command in package sp (NAs not permitted in row
	index)
Message-ID: <28C15D104A882F47954DEE56148152CC0A2BAA7661@nerckwmb1.ad.nerc.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091015/bb887f39/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Thu Oct 15 12:56:25 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 15 Oct 2009 11:56:25 +0100
Subject: [R-sig-Geo] Very basic figure question
In-Reply-To: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>
References: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>
Message-ID: <d8ad40b50910150356m6e04f33cs61edd20e8ec6ad8c@mail.gmail.com>

On Thu, Oct 15, 2009 at 11:28 AM, Rob Forsyth
<r.j.forsyth at newcastle.ac.uk> wrote:
> A complete geo-tyro demonstrating ignorance here: please be tolerant!
>
> I have a large dataset comprising the results of a questionnaire from UK
> respondents. I am interested in geographic variation in responses and have
> built mixed-effect models incorporating County/Unitary Authority/Local
> Authority (a level of local government in the UK) as a factor-level random
> effect in lme4. Extracting the intercept of the random effects I can
> generate a normalised 0-1 score for each local authority. I would like to
> illustrate the results of this analysis and generate a map showing LAs
> coloured using this normalised score to set gray scale.
>
> We have campus access to ArcGIS and related programmes but I have no
> knowledge of these whatsoever and wondered if for this limited task I could
> work within R? Are there any suitable public domain map objects and how
> would I go about this?

You certainly can draw coloured maps in R using the sp package and
various other things to help you get the data, such as the rgdal
package for reading shapefiles. However, getting the boundary data is
another problem...

 UK boundary data in the public domain? Ooh, I nearly laughed myself
off my chair! Are you american? No, UK border data is copyright,
controlled, restricted and if you want it you probably end up with an
MI5 file. Academics can get access to various boundary data sets via
ukborders. but we academics already have MI5 files as dangerous
intellectual subversives anyway:

http://edina.ac.uk/ukborders/

Barry


From jamel.marseille at gmail.com  Thu Oct 15 14:31:26 2009
From: jamel.marseille at gmail.com (abed abduallah)
Date: Thu, 15 Oct 2009 14:31:26 +0200
Subject: [R-sig-Geo] maps with R
Message-ID: <8c4426cc0910150531h39d111b6g3892bea7425c70a3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091015/e13c2737/attachment.pl>

From p.hiemstra at geo.uu.nl  Thu Oct 15 14:38:22 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 15 Oct 2009 14:38:22 +0200
Subject: [R-sig-Geo] maps with R
In-Reply-To: <8c4426cc0910150531h39d111b6g3892bea7425c70a3@mail.gmail.com>
References: <8c4426cc0910150531h39d111b6g3892bea7425c70a3@mail.gmail.com>
Message-ID: <4AD717BE.9050905@geo.uu.nl>

abed abduallah wrote:
> Dear
> Just i want to know how to make maps of chinese provinces with R, thanks in
> advance
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Hi,

What kind of maps: grids, polygons, points? Does it need to be 
interpolated or not? How did you store the data? You need to more 
thoroughly describe the  problem you want to solve, and probably search 
more yourself, before we can help you deal with it.

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Thu Oct 15 14:41:12 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 15 Oct 2009 14:41:12 +0200
Subject: [R-sig-Geo] Very basic figure question
In-Reply-To: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>
References: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>
Message-ID: <4AD71868.3060205@geo.uu.nl>

Rob Forsyth wrote:
> A complete geo-tyro demonstrating ignorance here: please be tolerant!
>
> I have a large dataset comprising the results of a questionnaire from 
> UK respondents. I am interested in geographic variation in responses 
> and have built mixed-effect models incorporating County/Unitary 
> Authority/Local Authority (a level of local government in the UK) as a 
> factor-level random effect in lme4. Extracting the intercept of the 
> random effects I can generate a normalised 0-1 score for each local 
> authority. I would like to illustrate the results of this analysis and 
> generate a map showing LAs coloured using this normalised score to set 
> gray scale.
>
> We have campus access to ArcGIS and related programmes but I have no 
> knowledge of these whatsoever and wondered if for this limited task I 
> could work within R?
I would rather say that for this limited problem you could use ArcGIS 
:), for more complex ones use R ;).

cheers,
Paul
> Are there any suitable public domain map objects and how would I go 
> about this?
>
> Thank you
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From bibiko at eva.mpg.de  Thu Oct 15 15:10:44 2009
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Thu, 15 Oct 2009 15:10:44 +0200
Subject: [R-sig-Geo] maps with R
In-Reply-To: <4AD717BE.9050905@geo.uu.nl>
References: <8c4426cc0910150531h39d111b6g3892bea7425c70a3@mail.gmail.com>
	<4AD717BE.9050905@geo.uu.nl>
Message-ID: <5F177A50-CB59-49E5-8D75-04FE60651F0E@eva.mpg.de>


>> Just i want to know how to make maps of chinese provinces with R

Maybe look at http://ciesin.org/

and

look for "China GIS" at

http://www.ciesin.columbia.edu/eidata/resources.jsp


you get

http://sedac.ciesin.columbia.edu/china/

and

http://sedac.ciesin.columbia.edu/china/admin/bnd9071/bnd9071.html
http://sedac.ciesin.columbia.edu/china/admin/bnd90/bnd90.html

Then you can use the libraries "RArcInfo", "sp", "maptools", and  
"rgdal" to convert that e00 file


Maybe this helps.

Cheers

Hans-J?rg

PS Also please read CIESIN's data policies.

**********************************************************
Hans-Joerg Bibiko
Max Planck Institute for Evolutionary Anthropology
Department of Linguistics
Deutscher Platz 6     phone:   +49 (0) 341 3550 341
D-04103 Leipzig       fax:     +49 (0) 341 3550 333
Germany               e-mail:  bibiko[AT]eva.mpg.de


From dr.a.gomeztagle.jr at gmail.com  Thu Oct 15 16:05:08 2009
From: dr.a.gomeztagle.jr at gmail.com (=?ISO-8859-1?Q?Alberto_G=F3mez=2DTagle?=)
Date: Thu, 15 Oct 2009 09:05:08 -0500
Subject: [R-sig-Geo] Zonal anisotropy
Message-ID: <b7e08a410910150705u5423c376vd70ce3dbe4cc9340@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091015/c6cfd1cd/attachment.pl>

From albin.blaschka at gmail.com  Thu Oct 15 17:03:34 2009
From: albin.blaschka at gmail.com (Albin Blaschka)
Date: Thu, 15 Oct 2009 17:03:34 +0200
Subject: [R-sig-Geo] Very basic figure question
In-Reply-To: <d8ad40b50910150356m6e04f33cs61edd20e8ec6ad8c@mail.gmail.com>
References: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>
	<d8ad40b50910150356m6e04f33cs61edd20e8ec6ad8c@mail.gmail.com>
Message-ID: <4AD739C6.9050700@standortsanalyse.net>


 >  UK boundary data in the public domain? Ooh, I nearly laughed myself
 > off my chair! Are you american? No, UK border data is copyright,
 > controlled, restricted and if you want it you probably end up with an
 > MI5 file. Academics can get access to various boundary data sets via
 > ukborders. but we academics already have MI5 files as dangerous
 > intellectual subversives anyway:
 >
 > http://edina.ac.uk/ukborders/
 >


Hello!

Very basic borders can be found here...
GADM database of Global Administrative Areas - http://www.gadm.org/

Maybe data found here: http://www.geonames.org could also be helpfull

kind regards,
Albin

-- 
---------------------------------------------------------------------
| Albin Blaschka, Mag. rer.nat - Salzburg, Austria
| http://www.albinblaschka.info   http://www.thinkanimal.info
| It's hard to live in the mountains, hard, but not hopeless!


From bibiko at eva.mpg.de  Thu Oct 15 17:20:55 2009
From: bibiko at eva.mpg.de (=?iso-8859-1?Q?Hans-J=F6rg_Bibiko?=)
Date: Thu, 15 Oct 2009 17:20:55 +0200
Subject: [R-sig-Geo] maps with R
In-Reply-To: <5F177A50-CB59-49E5-8D75-04FE60651F0E@eva.mpg.de>
References: <8c4426cc0910150531h39d111b6g3892bea7425c70a3@mail.gmail.com>
	<4AD717BE.9050905@geo.uu.nl>
	<5F177A50-CB59-49E5-8D75-04FE60651F0E@eva.mpg.de>
Message-ID: <950CAC4A-FCCE-42F2-B24B-5ABF313B0E00@eva.mpg.de>


Or simply go to http://www.gadm.org/country

select China and format R.

Cheers,

Hans-J?rg

**********************************************************
Hans-Joerg Bibiko
Max Planck Institute for Evolutionary Anthropology
Department of Linguistics
Deutscher Platz 6     phone:   +49 (0) 341 3550 341
D-04103 Leipzig       fax:     +49 (0) 341 3550 333
Germany               e-mail:  bibiko[AT]eva.mpg.de


From hengl at spatial-analyst.net  Fri Oct 16 09:53:14 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Fri, 16 Oct 2009 09:53:14 +0200
Subject: [R-sig-Geo] Including SAGA grid as GDAL-supported format
Message-ID: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>


Dear r-sig-geo,

I would like to initiate the processes of registering the SAGA grid  
format under GDAL (the SAGA 2.0.4 source code is available for  
download here  
http://sourceforge.net/projects/saga-gis/files/SAGA%20-%202.0/SAGA%202.0.4/saga_2.0.4_src.zip/download).

Do I have to follow some formal procedure, or do I have to prepare the  
GDAL driver myself (as explained at  
http://www.gdal.org/gdal_drivertut.html)? Any help/suggestions are  
welcome (apparently it should not be too complicated).

SAGA grid consists of tree types of files:
1. "*.sgrd" - the header file with name, data format, XLL, YLL, rows  
columns, cell size, z-factor and no data value;
2. "*.sdat" - the raw data file;
3. "*.hgrd" - the history file;

Here are some examples hot to read and write the SAGA grids to R:

> library(gstat)
> library(RSAGA)
> library(spatstat)

> data(meuse.grid)
> coordinates(meuse.grid) <- ~x+y
> gridded(meuse.grid) <- TRUE
> proj4string(meuse.grid) = CRS("+init=epsg:28992")

# write to SAGA grid format;
> write.asciigrid(meuse.grid["soil"], "meuse_soil.asc")
> rsaga.esri.to.sgrd(in.grids="meuse_soil.asc",  
> out.sgrd="meuse_soil.sgrd", in.path=getwd())

# read SAGA grid format:
> sgrd <- matrix((unlist(strsplit(readLines(file("meuse_soil.sgrd")),  
> split="\t= "))), ncol=2, byrow=T)
> sgrd
       [,1]              [,2]
  [1,] "NAME"            "meuse_soil"
  [2,] "DESCRIPTION"     "UNIT"
  [3,] "DATAFILE_OFFSET" "0"
  [4,] "DATAFORMAT"      "FLOAT"
  [5,] "BYTEORDER_BIG"   "FALSE"
  [6,] "POSITION_XMIN"   "178460.0000000000"
  [7,] "POSITION_YMIN"   "329620.0000000000"
  [8,] "CELLCOUNT_X"     "78"
  [9,] "CELLCOUNT_Y"     "104"
[10,] "CELLSIZE"        "40.0000000000"
[11,] "Z_FACTOR"        "1.000000"
[12,] "NODATA_VALUE"    "-9999.000000"
[13,] "TOPTOBOTTOM"     "FALSE"

# read the raw data: 4bit, numeric (FLOAT), byte order small;
> sdat <- readBin("meuse_soil.sdat", what="numeric", size=4,  
> n=as.integer(sgrd[8,2])*as.integer(sgrd[9,2]))
> sdat.sp <- as.im(list(x=seq(from=as.integer(sgrd[6,2]),  
> length.out=as.integer(sgrd[8,2]), by=as.integer(sgrd[10,2])),  
> y=seq(from=as.integer(sgrd[7,2]), length.out=as.integer(sgrd[9,2]),  
> by=as.integer(sgrd[10,2])), z=matrix(sdat,  
> nrow=as.integer(sgrd[8,2]), ncol=as.integer(sgrd[9,2]))))
> sdat.sp <- as(sdat.sp, "SpatialGridDataFrame")
# replace the mask value with NA's:
> sdat.sp at data[[1]] <-  
> ifelse(sdat.sp at data[[1]]==as.integer(sgrd[12,2]), NA,  
> sdat.sp at data[[1]])
> spplot(sdat.sp)


Of course, it would be much easier to have this in a single line:

> meuse.grid <- readGDAL("meuse_soil.sgrd")

or

> writeGDAL(meuse.grid["soil"], "meuse_soil.sgrd", "SAGA")



PS: A new version of SAGA has just been released few days ago.


thank you,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/

Connected discussion:  
https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080130/cd5c3748/attachment.pl


From Roger.Bivand at nhh.no  Fri Oct 16 11:06:13 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 16 Oct 2009 11:06:13 +0200 (CEST)
Subject: [R-sig-Geo] Including SAGA grid as GDAL-supported format
In-Reply-To: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
References: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
Message-ID: <alpine.LRH.2.00.0910161050360.12919@reclus.nhh.no>

On Fri, 16 Oct 2009, Tomislav Hengl wrote:

>
> Dear r-sig-geo,
>
> I would like to initiate the processes of registering the SAGA grid format 
> under GDAL (the SAGA 2.0.4 source code is available for download here 
> http://sourceforge.net/projects/saga-gis/files/SAGA%20-%202.0/SAGA%202.0.4/saga_2.0.4_src.zip/download).
>
> Do I have to follow some formal procedure, or do I have to prepare the GDAL 
> driver myself (as explained at http://www.gdal.org/gdal_drivertut.html)? Any 
> help/suggestions are welcome (apparently it should not be too complicated).

Tom,

Writing a read-only driver would be the first step. Once that works, it 
could be extended to copy creation, and finally to direct creation if 
justified. If SAGA I/O has a separate I/O library, it could be shipped 
with the driver as in the pcraster driver, but I don't see one in the 
source tree. Writing a driver for SAGA rasters would permit lots of other 
software to interact with SAGA, not just in R, so would be more robust.

You'd develop on a local copy of the GDAL source, and once done submit a 
file archive of the directory to Frank Warmerdam or other GDAL people. 
Maybe ask on the GDAL developers' list if they have seen questions about 
SAGA rasters before. Are SAGA rasters similar to any existing supported 
formats (Erdas?, IDRISI?, ILWIS?) - could an existing driver be copied and 
modified?

Roger

>
> SAGA grid consists of tree types of files:
> 1. "*.sgrd" - the header file with name, data format, XLL, YLL, rows columns, 
> cell size, z-factor and no data value;
> 2. "*.sdat" - the raw data file;
> 3. "*.hgrd" - the history file;
>
> Here are some examples hot to read and write the SAGA grids to R:
>
>> library(gstat)
>> library(RSAGA)
>> library(spatstat)
>
>> data(meuse.grid)
>> coordinates(meuse.grid) <- ~x+y
>> gridded(meuse.grid) <- TRUE
>> proj4string(meuse.grid) = CRS("+init=epsg:28992")
>
> # write to SAGA grid format;
>> write.asciigrid(meuse.grid["soil"], "meuse_soil.asc")
>> rsaga.esri.to.sgrd(in.grids="meuse_soil.asc", out.sgrd="meuse_soil.sgrd", 
>> in.path=getwd())
>
> # read SAGA grid format:
>> sgrd <- matrix((unlist(strsplit(readLines(file("meuse_soil.sgrd")), 
>> split="\t= "))), ncol=2, byrow=T)
>> sgrd
>     [,1]              [,2]
> [1,] "NAME"            "meuse_soil"
> [2,] "DESCRIPTION"     "UNIT"
> [3,] "DATAFILE_OFFSET" "0"
> [4,] "DATAFORMAT"      "FLOAT"
> [5,] "BYTEORDER_BIG"   "FALSE"
> [6,] "POSITION_XMIN"   "178460.0000000000"
> [7,] "POSITION_YMIN"   "329620.0000000000"
> [8,] "CELLCOUNT_X"     "78"
> [9,] "CELLCOUNT_Y"     "104"
> [10,] "CELLSIZE"        "40.0000000000"
> [11,] "Z_FACTOR"        "1.000000"
> [12,] "NODATA_VALUE"    "-9999.000000"
> [13,] "TOPTOBOTTOM"     "FALSE"
>
> # read the raw data: 4bit, numeric (FLOAT), byte order small;
>> sdat <- readBin("meuse_soil.sdat", what="numeric", size=4, 
>> n=as.integer(sgrd[8,2])*as.integer(sgrd[9,2]))
>> sdat.sp <- as.im(list(x=seq(from=as.integer(sgrd[6,2]), 
>> length.out=as.integer(sgrd[8,2]), by=as.integer(sgrd[10,2])), 
>> y=seq(from=as.integer(sgrd[7,2]), length.out=as.integer(sgrd[9,2]), 
>> by=as.integer(sgrd[10,2])), z=matrix(sdat, nrow=as.integer(sgrd[8,2]), 
>> ncol=as.integer(sgrd[9,2]))))
>> sdat.sp <- as(sdat.sp, "SpatialGridDataFrame")
> # replace the mask value with NA's:
>> sdat.sp at data[[1]] <- ifelse(sdat.sp at data[[1]]==as.integer(sgrd[12,2]), NA, 
>> sdat.sp at data[[1]])
>> spplot(sdat.sp)
>
>
> Of course, it would be much easier to have this in a single line:
>
>> meuse.grid <- readGDAL("meuse_soil.sgrd")
>
> or
>
>> writeGDAL(meuse.grid["soil"], "meuse_soil.sgrd", "SAGA")
>
>
>
> PS: A new version of SAGA has just been released few days ago.
>
>
> thank you,
>
> T. Hengl
> http://home.medewerker.uva.nl/t.hengl/
>
> Connected discussion: 
> https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080130/cd5c3748/attachment.pl
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Fri Oct 16 11:06:17 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 16 Oct 2009 11:06:17 +0200
Subject: [R-sig-Geo] Including SAGA grid as GDAL-supported format
In-Reply-To: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
References: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
Message-ID: <4AD83789.7060904@uni-muenster.de>

Tom, the idea is that you write (or find someone else to write) the
required driver for gdal, in C++, and contribute this to the gdal
project. If Frank Warmerdam then accepts it (which he usually will), the
next version of gdal will have the support, and calls like

meuse.grid <- readGDAL("meuse_soil.sgrd")

will work out of the box. In addition, all other things that rely upon
gdal will be able to read and write the grids as well. In essense, the
whole process has nothing to do with R, but will become available to R
(in due time, once gdal versions get released and updated), automatically.

Best regards,
--
Edzer

Tomislav Hengl wrote:
>
> Dear r-sig-geo,
>
> I would like to initiate the processes of registering the SAGA grid
> format under GDAL (the SAGA 2.0.4 source code is available for
> download here
> http://sourceforge.net/projects/saga-gis/files/SAGA%20-%202.0/SAGA%202.0.4/saga_2.0.4_src.zip/download).
>
>
> Do I have to follow some formal procedure, or do I have to prepare the
> GDAL driver myself (as explained at
> http://www.gdal.org/gdal_drivertut.html)? Any help/suggestions are
> welcome (apparently it should not be too complicated).
>
> SAGA grid consists of tree types of files:
> 1. "*.sgrd" - the header file with name, data format, XLL, YLL, rows
> columns, cell size, z-factor and no data value;
> 2. "*.sdat" - the raw data file;
> 3. "*.hgrd" - the history file;
>
> Here are some examples hot to read and write the SAGA grids to R:
>
>> library(gstat)
>> library(RSAGA)
>> library(spatstat)
>
>> data(meuse.grid)
>> coordinates(meuse.grid) <- ~x+y
>> gridded(meuse.grid) <- TRUE
>> proj4string(meuse.grid) = CRS("+init=epsg:28992")
>
> # write to SAGA grid format;
>> write.asciigrid(meuse.grid["soil"], "meuse_soil.asc")
>> rsaga.esri.to.sgrd(in.grids="meuse_soil.asc",
>> out.sgrd="meuse_soil.sgrd", in.path=getwd())
>
> # read SAGA grid format:
>> sgrd <- matrix((unlist(strsplit(readLines(file("meuse_soil.sgrd")),
>> split="\t= "))), ncol=2, byrow=T)
>> sgrd
>       [,1]              [,2]
>  [1,] "NAME"            "meuse_soil"
>  [2,] "DESCRIPTION"     "UNIT"
>  [3,] "DATAFILE_OFFSET" "0"
>  [4,] "DATAFORMAT"      "FLOAT"
>  [5,] "BYTEORDER_BIG"   "FALSE"
>  [6,] "POSITION_XMIN"   "178460.0000000000"
>  [7,] "POSITION_YMIN"   "329620.0000000000"
>  [8,] "CELLCOUNT_X"     "78"
>  [9,] "CELLCOUNT_Y"     "104"
> [10,] "CELLSIZE"        "40.0000000000"
> [11,] "Z_FACTOR"        "1.000000"
> [12,] "NODATA_VALUE"    "-9999.000000"
> [13,] "TOPTOBOTTOM"     "FALSE"
>
> # read the raw data: 4bit, numeric (FLOAT), byte order small;
>> sdat <- readBin("meuse_soil.sdat", what="numeric", size=4,
>> n=as.integer(sgrd[8,2])*as.integer(sgrd[9,2]))
>> sdat.sp <- as.im(list(x=seq(from=as.integer(sgrd[6,2]),
>> length.out=as.integer(sgrd[8,2]), by=as.integer(sgrd[10,2])),
>> y=seq(from=as.integer(sgrd[7,2]), length.out=as.integer(sgrd[9,2]),
>> by=as.integer(sgrd[10,2])), z=matrix(sdat,
>> nrow=as.integer(sgrd[8,2]), ncol=as.integer(sgrd[9,2]))))
>> sdat.sp <- as(sdat.sp, "SpatialGridDataFrame")
> # replace the mask value with NA's:
>> sdat.sp at data[[1]] <-
>> ifelse(sdat.sp at data[[1]]==as.integer(sgrd[12,2]), NA, sdat.sp at data[[1]])
>> spplot(sdat.sp)
>
>
> Of course, it would be much easier to have this in a single line:
>
>> meuse.grid <- readGDAL("meuse_soil.sgrd")
>
> or
>
>> writeGDAL(meuse.grid["soil"], "meuse_soil.sgrd", "SAGA")
>
>
>
> PS: A new version of SAGA has just been released few days ago.
>
>
> thank you,
>
> T. Hengl
> http://home.medewerker.uva.nl/t.hengl/
>
> Connected discussion:
> https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080130/cd5c3748/attachment.pl
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From brenning at uwaterloo.ca  Fri Oct 16 14:30:24 2009
From: brenning at uwaterloo.ca (Alexander Brenning)
Date: Fri, 16 Oct 2009 08:30:24 -0400
Subject: [R-sig-Geo] Including SAGA grid as GDAL-supported format
In-Reply-To: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
References: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
Message-ID: <4AD86760.7080105@uwaterloo.ca>

Hi,

a GDAL interface to SAGA grids would of course be very welcome. Right 
now the easiest (but indirect) way of importing SAGA grids is with

   read.sgrd("mysagagrid")

which uses rsaga.sgrd.to.esri (to a tempfile()) and then read.ascii.grid

In the next RSAGA release I will consider using readBin() in read.sgrd() 
  in order to read the SAGA grid file directly as you suggested.

Cheers
  Alex




Tomislav Hengl wrote:
> Dear r-sig-geo,
> 
> I would like to initiate the processes of registering the SAGA grid  
> format under GDAL (the SAGA 2.0.4 source code is available for  
> download here  
> http://sourceforge.net/projects/saga-gis/files/SAGA%20-%202.0/SAGA%202.0.4/saga_2.0.4_src.zip/download).
> 
> Do I have to follow some formal procedure, or do I have to prepare the  
> GDAL driver myself (as explained at  
> http://www.gdal.org/gdal_drivertut.html)? Any help/suggestions are  
> welcome (apparently it should not be too complicated).
> 
> SAGA grid consists of tree types of files:
> 1. "*.sgrd" - the header file with name, data format, XLL, YLL, rows  
> columns, cell size, z-factor and no data value;
> 2. "*.sdat" - the raw data file;
> 3. "*.hgrd" - the history file;
> 
> Here are some examples hot to read and write the SAGA grids to R:
> 
>> library(gstat)
>> library(RSAGA)
>> library(spatstat)
> 
>> data(meuse.grid)
>> coordinates(meuse.grid) <- ~x+y
>> gridded(meuse.grid) <- TRUE
>> proj4string(meuse.grid) = CRS("+init=epsg:28992")
> 
> # write to SAGA grid format;
>> write.asciigrid(meuse.grid["soil"], "meuse_soil.asc")
>> rsaga.esri.to.sgrd(in.grids="meuse_soil.asc",  
>> out.sgrd="meuse_soil.sgrd", in.path=getwd())
> 
> # read SAGA grid format:
>> sgrd <- matrix((unlist(strsplit(readLines(file("meuse_soil.sgrd")),  
>> split="\t= "))), ncol=2, byrow=T)
>> sgrd
>        [,1]              [,2]
>   [1,] "NAME"            "meuse_soil"
>   [2,] "DESCRIPTION"     "UNIT"
>   [3,] "DATAFILE_OFFSET" "0"
>   [4,] "DATAFORMAT"      "FLOAT"
>   [5,] "BYTEORDER_BIG"   "FALSE"
>   [6,] "POSITION_XMIN"   "178460.0000000000"
>   [7,] "POSITION_YMIN"   "329620.0000000000"
>   [8,] "CELLCOUNT_X"     "78"
>   [9,] "CELLCOUNT_Y"     "104"
> [10,] "CELLSIZE"        "40.0000000000"
> [11,] "Z_FACTOR"        "1.000000"
> [12,] "NODATA_VALUE"    "-9999.000000"
> [13,] "TOPTOBOTTOM"     "FALSE"
> 
> # read the raw data: 4bit, numeric (FLOAT), byte order small;
>> sdat <- readBin("meuse_soil.sdat", what="numeric", size=4,  
>> n=as.integer(sgrd[8,2])*as.integer(sgrd[9,2]))
>> sdat.sp <- as.im(list(x=seq(from=as.integer(sgrd[6,2]),  
>> length.out=as.integer(sgrd[8,2]), by=as.integer(sgrd[10,2])),  
>> y=seq(from=as.integer(sgrd[7,2]), length.out=as.integer(sgrd[9,2]),  
>> by=as.integer(sgrd[10,2])), z=matrix(sdat,  
>> nrow=as.integer(sgrd[8,2]), ncol=as.integer(sgrd[9,2]))))
>> sdat.sp <- as(sdat.sp, "SpatialGridDataFrame")
> # replace the mask value with NA's:
>> sdat.sp at data[[1]] <-  
>> ifelse(sdat.sp at data[[1]]==as.integer(sgrd[12,2]), NA,  
>> sdat.sp at data[[1]])
>> spplot(sdat.sp)
> 
> 
> Of course, it would be much easier to have this in a single line:
> 
>> meuse.grid <- readGDAL("meuse_soil.sgrd")
> 
> or
> 
>> writeGDAL(meuse.grid["soil"], "meuse_soil.sgrd", "SAGA")
> 
> 
> 
> PS: A new version of SAGA has just been released few days ago.
> 
> 
> thank you,
> 
> T. Hengl
> http://home.medewerker.uva.nl/t.hengl/
> 
> Connected discussion:  
> https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080130/cd5c3748/attachment.pl
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Alexander Brenning
brenning at uwaterloo.ca - T +1-519-888-4567 ext 35783
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/


From emmanuel.poizot at cnam.fr  Fri Oct 16 14:52:15 2009
From: emmanuel.poizot at cnam.fr (Poizot Emmanuel)
Date: Fri, 16 Oct 2009 14:52:15 +0200
Subject: [R-sig-Geo] Export of an irregular grid
Message-ID: <4AD86C7F.7080900@cnam.fr>

Dear all,

after interpolation with the gstat package, I created a grid of class 
SpatialGridDataFrame.
The grid is not regular. I tried to export it with write.asciigrid 
function but didn't succed, I suppose because of the non-regularity of 
my grid.
How can I turn around that problem ?

------------------------------------------------
Emmanuel Poizot
Cnam/Intechmer
B.P. 324
50103 Cherbourg Cedex

Phone (Direct) : (00 33)(0)233887342
Fax : (00 33)(0)233887339
------------------------------------------------

-------------- next part --------------
A non-text attachment was scrubbed...
Name: emmanuel_poizot.vcf
Type: text/x-vcard
Size: 316 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091016/271a2090/attachment.vcf>

From Henk.Sierdsema at sovon.nl  Fri Oct 16 16:19:02 2009
From: Henk.Sierdsema at sovon.nl (Henk Sierdsema)
Date: Fri, 16 Oct 2009 16:19:02 +0200
Subject: [R-sig-Geo] Very basic figure question
In-Reply-To: <00816895-9FB9-439A-A623-2F443249BBDE@newcastle.ac.uk>
Message-ID: <F7A3EE6B27F4D54B9CCAAB767F1B5AA3019523AA@mail.sovon.nl>

Hi Rob, 

You could start with the maps available within R. Here is some text taken from page 88-89 from the ASDAR-book:
" It is often attractive to make use of the spatial databases in the maps (comm: and also the mapdata) package. They can be converted to sp class objects using functions such as map2SpatialPolygons in the maptools package. An alternative source of coastlines is the Rgshhs function in maptools, interfacing binary databases of varying resolution distributed by the 'Global Self-consistent, Hierarchical, High-resolution Shoreline Database' project.1212 http://www.soest.hawaii.edu/wessel/gshhs/gshhs.html.4.2 <http://www.soest.hawaii.edu/wessel/gshhs/gshhs.html.4.2>  Vector File Formats 89. The best resolution databases are rather large, and so maptools ships only with the coarse resolution one; users can install and use higher resolution databases locally. Figures 2.3 and 2.7, among others in earlier chapters, have been made using these sources."

Alternatively you could make use of the maps provided through the FAO  (http://www.fao.org/geonetwork/srv/en/main.home <http://www.fao.org/geonetwork/srv/en/main.home>  ). Here you can download for example shorelines and a basic map with country borders (but good enough for reference purposes). 

Henk

 

 

Henk Sierdsema 

SOVON Vogelonderzoek Nederland / SOVON Dutch Centre for Field Ornithology 

Rijksstraatweg 178 
6573 DG  Beek-Ubbergen 
The Netherlands 
tel: +31 (0)24 6848145 
fax: +31 (0)24 6848122 



 

-----Oorspronkelijk bericht----- 
Van: r-sig-geo-bounces at stat.math.ethz.ch 
[mailto:r-sig-geo-bounces at stat.math.ethz.ch <mailto:r-sig-geo-bounces at stat.math.ethz.ch> ]Namens Rob Forsyth 
Verzonden: donderdag 15 oktober 2009 12:28 
Aan: r-sig-geo at stat.math.ethz.ch 
Onderwerp: [R-sig-Geo] Very basic figure question 


 

A complete geo-tyro demonstrating ignorance here: please be tolerant! 

I have a large dataset comprising the results of a questionnaire from  
UK respondents. I am interested in geographic variation in responses  
and have built mixed-effect models incorporating County/Unitary  
Authority/Local Authority (a level of local government in the UK) as a  
factor-level random effect in lme4. Extracting the intercept of the  
random effects I can generate a normalised 0-1 score for each local  
authority. I would like to illustrate the results of this analysis and  
generate a map showing LAs coloured using this normalised score to set  
gray scale. 

We have campus access to ArcGIS and related programmes but I have no  
knowledge of these whatsoever and wondered if for this limited task I  
could work within R? Are there any suitable public domain map objects  
and how would I go about this? 

Thank you 

_______________________________________________ 
R-sig-Geo mailing list 
R-sig-Geo at stat.math.ethz.ch 
https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>  


From r.hijmans at gmail.com  Fri Oct 16 19:58:51 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 16 Oct 2009 10:58:51 -0700
Subject: [R-sig-Geo] Export of an irregular grid
In-Reply-To: <4AD86C7F.7080900@cnam.fr>
References: <4AD86C7F.7080900@cnam.fr>
Message-ID: <dc22b2570910161058i4704987agd64b9c18249af23e@mail.gmail.com>

Emmanuel, It depends on your reason for exporting. You can use
write.table with the DF of the SGDF object if you want ascii data to
analyze elsewhere. Alternatively you can use rgdal to write the data
to a geotiff file, if your purpose is display in a mapping program.
Robert

On Fri, Oct 16, 2009 at 5:52 AM, Poizot Emmanuel
<emmanuel.poizot at cnam.fr> wrote:
> Dear all,
>
> after interpolation with the gstat package, I created a grid of class
> SpatialGridDataFrame.
> The grid is not regular. I tried to export it with write.asciigrid function
> but didn't succed, I suppose because of the non-regularity of my grid.
> How can I turn around that problem ?
>
> ------------------------------------------------
> Emmanuel Poizot
> Cnam/Intechmer
> B.P. 324
> 50103 Cherbourg Cedex
>
> Phone (Direct) : (00 33)(0)233887342
> Fax : (00 33)(0)233887339
> ------------------------------------------------
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From sunshineabove at gmail.com  Fri Oct 16 21:36:44 2009
From: sunshineabove at gmail.com (Sunny)
Date: Fri, 16 Oct 2009 15:36:44 -0400
Subject: [R-sig-Geo] Load point shape file
Message-ID: <c9800cf0910161236j6526f266w8a2bfec9d2dd3d04@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091016/72e62156/attachment.pl>

From yud at mail.montclair.edu  Fri Oct 16 21:42:33 2009
From: yud at mail.montclair.edu (Danlin Yu)
Date: Fri, 16 Oct 2009 15:42:33 -0400
Subject: [R-sig-Geo] Load point shape file
In-Reply-To: <c9800cf0910161236j6526f266w8a2bfec9d2dd3d04@mail.gmail.com>
References: <c9800cf0910161236j6526f266w8a2bfec9d2dd3d04@mail.gmail.com>
Message-ID: <4AD8CCA9.5040506@mail.montclair.edu>

Sunny:

For the first case, you probably shall set the path to where you store 
your shapefiles in the R main menu. In addition, as the warning message 
indicates, the readShapeSpatial function probably is better for spatial 
data management than read.shape. For the second case, other than setting 
the path, you also need to load the package (after installing it) by 
using library(rgdal).

Hope this helps,

Cheers,
Dr. Danlin Yu

Sunny ??:
> I am trying to load my point shape file to R. I searched for hours and found
> there are two ways, one is read.shape and the other one is readOGR. I tried
> both but but can't do it successfully. Any help is appreciate.
>
>   
>> x <- read.shape(system.file("test.shp", package="maptools")[1])
>>     
> Error in getinfo.shape(filen) : Error opening SHP file
> In addition: Warning message:
> use readShapeSpatial:
> objects other than Spatial objects defined in the sp package are deprecated
>
>
>   
>> install.packages('rgdal')
>> self<-readOGR(".","test")
>>     
> Error: could not find function "readOGR"
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From ashton at msu.edu  Fri Oct 16 23:36:18 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Fri, 16 Oct 2009 17:36:18 -0400
Subject: [R-sig-Geo] Load point shape file
In-Reply-To: <4AD8CCA9.5040506@mail.montclair.edu>
References: <c9800cf0910161236j6526f266w8a2bfec9d2dd3d04@mail.gmail.com>
	<4AD8CCA9.5040506@mail.montclair.edu>
Message-ID: <200910161736.18085.ashton@msu.edu>

I think it's better not to specify the .shp extension, too:

Assuming that test.shp, test.shx, and test.dbf are in your working directory 
(see setwd() for more on that):
library(maptools)
spdat <- readShapeSpatial('test')

On Friday 16 October 2009 15:42:33 Danlin Yu wrote:
> Sunny:
> 
> For the first case, you probably shall set the path to where you store
> your shapefiles in the R main menu. In addition, as the warning message
> indicates, the readShapeSpatial function probably is better for spatial
> data management than read.shape. For the second case, other than setting
> the path, you also need to load the package (after installing it) by
> using library(rgdal).
> 
> Hope this helps,
> 
> Cheers,
> Dr. Danlin Yu
> 
> Sunny ??:
> > I am trying to load my point shape file to R. I searched for hours and
> > found there are two ways, one is read.shape and the other one is readOGR.
> > I tried both but but can't do it successfully. Any help is appreciate.
> >
> >> x <- read.shape(system.file("test.shp", package="maptools")[1])
> >
> > Error in getinfo.shape(filen) : Error opening SHP file
> > In addition: Warning message:
> > use readShapeSpatial:
> > objects other than Spatial objects defined in the sp package are
> > deprecated
> >
> >> install.packages('rgdal')
> >> self<-readOGR(".","test")
> >
> > Error: could not find function "readOGR"
> >
> > 	[[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From hengl at spatial-analyst.net  Sat Oct 17 10:28:00 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Sat, 17 Oct 2009 10:28:00 +0200
Subject: [R-sig-Geo] Including SAGA grid as GDAL-supported format
In-Reply-To: <alpine.LRH.2.00.0910161050360.12919@reclus.nhh.no>
References: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
	<alpine.LRH.2.00.0910161050360.12919@reclus.nhh.no>
Message-ID: <BA08D070AECA4A8F93CBEE37E7654E8F@pcibed193>


> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Friday, October 16, 2009 11:06 AM
> To: Tomislav Hengl
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Including SAGA grid as GDAL-supported format
> 
> On Fri, 16 Oct 2009, Tomislav Hengl wrote:
> 
> >
> > Dear r-sig-geo,
> >
> > I would like to initiate the processes of registering the SAGA grid format
> > under GDAL (the SAGA 2.0.4 source code is available for download here
> > http://sourceforge.net/projects/saga-gis/files/SAGA%20-
> %202.0/SAGA%202.0.4/saga_2.0.4_src.zip/download).
> >
> > Do I have to follow some formal procedure, or do I have to prepare the GDAL
> > driver myself (as explained at http://www.gdal.org/gdal_drivertut.html)? Any
> > help/suggestions are welcome (apparently it should not be too complicated).
> 
> Tom,
> 
> Writing a read-only driver would be the first step. Once that works, it
> could be extended to copy creation, and finally to direct creation if
> justified. If SAGA I/O has a separate I/O library, it could be shipped
> with the driver as in the pcraster driver, but I don't see one in the
> source tree. Writing a driver for SAGA rasters would permit lots of other
> software to interact with SAGA, not just in R, so would be more robust.
> 
> You'd develop on a local copy of the GDAL source, and once done submit a
> file archive of the directory to Frank Warmerdam or other GDAL people.
> Maybe ask on the GDAL developers' list if they have seen questions about
> SAGA rasters before. Are SAGA rasters similar to any existing supported
> formats (Erdas?, IDRISI?, ILWIS?) - could an existing driver be copied and
> modified?

Roger,

I've got an reply from FW who suggested that I should used the existing "raw file + ascii header"
drivers as a template:

http://svn.osgeo.org/gdal/trunk/gdal/frmts/raw/genbindataset.cpp

We could try adopting this to see it will work with SAGA grids also.

Apparently Volker Wichmann started implementing the SAGA driver himself (this summer), but then
never finished (he might send me his code).

Thanks for your suggestions and clarifications.

Tom

> 
> Roger
> 
> >


From Roger.Bivand at nhh.no  Sat Oct 17 11:31:09 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 17 Oct 2009 11:31:09 +0200 (CEST)
Subject: [R-sig-Geo] Including SAGA grid as GDAL-supported format
In-Reply-To: <BA08D070AECA4A8F93CBEE37E7654E8F@pcibed193>
References: <20091016095314.j5du0l14gs4o8k0c@spatial-analyst.net>
	<alpine.LRH.2.00.0910161050360.12919@reclus.nhh.no>
	<BA08D070AECA4A8F93CBEE37E7654E8F@pcibed193>
Message-ID: <alpine.LRH.2.00.0910171123390.21024@reclus.nhh.no>

On Sat, 17 Oct 2009, Tomislav Hengl wrote:

>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Friday, October 16, 2009 11:06 AM
>> To: Tomislav Hengl
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] Including SAGA grid as GDAL-supported format
>>
>> On Fri, 16 Oct 2009, Tomislav Hengl wrote:
>>
>>>
>>> Dear r-sig-geo,
>>>
>>> I would like to initiate the processes of registering the SAGA grid format
>>> under GDAL (the SAGA 2.0.4 source code is available for download here
>>> http://sourceforge.net/projects/saga-gis/files/SAGA%20-
>> %202.0/SAGA%202.0.4/saga_2.0.4_src.zip/download).
>>>
>>> Do I have to follow some formal procedure, or do I have to prepare the GDAL
>>> driver myself (as explained at http://www.gdal.org/gdal_drivertut.html)? Any
>>> help/suggestions are welcome (apparently it should not be too complicated).
>>
>> Tom,
>>
>> Writing a read-only driver would be the first step. Once that works, it
>> could be extended to copy creation, and finally to direct creation if
>> justified. If SAGA I/O has a separate I/O library, it could be shipped
>> with the driver as in the pcraster driver, but I don't see one in the
>> source tree. Writing a driver for SAGA rasters would permit lots of other
>> software to interact with SAGA, not just in R, so would be more robust.
>>
>> You'd develop on a local copy of the GDAL source, and once done submit a
>> file archive of the directory to Frank Warmerdam or other GDAL people.
>> Maybe ask on the GDAL developers' list if they have seen questions about
>> SAGA rasters before. Are SAGA rasters similar to any existing supported
>> formats (Erdas?, IDRISI?, ILWIS?) - could an existing driver be copied and
>> modified?
>
> Roger,
>
> I've got an reply from FW who suggested that I should used the existing "raw file + ascii header"
> drivers as a template:
>
> http://svn.osgeo.org/gdal/trunk/gdal/frmts/raw/genbindataset.cpp
>
> We could try adopting this to see it will work with SAGA grids also.

Unfortunately, this driver does not support creation by copying or 
directly, so maybe another in the raw directory, such as pnmdataset.cpp?

Getting it working first without the spatial reference system would be a 
start.

Roger

>
> Apparently Volker Wichmann started implementing the SAGA driver himself 
> (this summer), but then never finished (he might send me his code).
>
> Thanks for your suggestions and clarifications.
>
> Tom
>
>>
>> Roger
>>
>>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From eboyd3 at tigers.lsu.edu  Sat Oct 17 16:46:56 2009
From: eboyd3 at tigers.lsu.edu (Ezra Boyd)
Date: Sat, 17 Oct 2009 09:46:56 -0500
Subject: [R-sig-Geo] Getting started with Open Source GIS
Message-ID: <d0248ce60910170746h1f51ff29na73891039c870d5a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091017/ea399f85/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sat Oct 17 17:13:53 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 17 Oct 2009 16:13:53 +0100
Subject: [R-sig-Geo] Getting started with Open Source GIS
In-Reply-To: <d0248ce60910170746h1f51ff29na73891039c870d5a@mail.gmail.com>
References: <d0248ce60910170746h1f51ff29na73891039c870d5a@mail.gmail.com>
Message-ID: <d8ad40b50910170813h467d64a9q7d1b2ebbd7acd58d@mail.gmail.com>

On Sat, Oct 17, 2009 at 3:46 PM, Ezra Boyd <eboyd3 at tigers.lsu.edu> wrote:

> Will I be able to complete the tasks described above using the the Open
> Source GIS without a bunch of time consuming complications? ?Or, should I
> fork over some cash to extend my Arcview license?

 What's Arcview going to get you? You will be able to do all your
statistics in R - get a copy of Applied Spatial Data Analysis in R,
which will tell you the basics and more about manipulating spatial
data in R. Remember that statistics is never plug and play - even if
there's statistics functions in Arcview, you still need to check
diagnostics and other assumptions before your conclusion is valid. I
don't think Arcview or other ESRI products will give you that
flexibility.

 Once your stats are done and checked and you want to make pretty
maps, then you can create shapefiles from R and load them into Qgis
for mapping with any other layers of information you want to put in.
It is even possible to make publication-quality maps in R using the sp
package and friends (as in the ASDAR book).

 I wouldn't worry about GRASS - it's great for hardcore spatial
analysis (buffer this, overlay with that, compute watersheds, clip to
river buffers, count population in areas,...) but if you need to go
outside the boxes given you're going to have to start writing in C...
It's nice to know the power of GRASS is there, but I try and avoid
using it!

Barry


From dylan.beaudette at gmail.com  Sat Oct 17 19:12:58 2009
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sat, 17 Oct 2009 10:12:58 -0700
Subject: [R-sig-Geo] Getting started with Open Source GIS
In-Reply-To: <d8ad40b50910170813h467d64a9q7d1b2ebbd7acd58d@mail.gmail.com>
References: <d0248ce60910170746h1f51ff29na73891039c870d5a@mail.gmail.com>
	<d8ad40b50910170813h467d64a9q7d1b2ebbd7acd58d@mail.gmail.com>
Message-ID: <3c5546140910171012y70df6383jb1dbc08dd1330f8d@mail.gmail.com>

On Sat, Oct 17, 2009 at 8:13 AM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Sat, Oct 17, 2009 at 3:46 PM, Ezra Boyd <eboyd3 at tigers.lsu.edu> wrote:
>
>> Will I be able to complete the tasks described above using the the Open
>> Source GIS without a bunch of time consuming complications? ?Or, should I
>> fork over some cash to extend my Arcview license?
>
> ?What's Arcview going to get you? You will be able to do all your
> statistics in R - get a copy of Applied Spatial Data Analysis in R,
> which will tell you the basics and more about manipulating spatial
> data in R. Remember that statistics is never plug and play - even if
> there's statistics functions in Arcview, you still need to check
> diagnostics and other assumptions before your conclusion is valid. I
> don't think Arcview or other ESRI products will give you that
> flexibility.
>
> ?Once your stats are done and checked and you want to make pretty
> maps, then you can create shapefiles from R and load them into Qgis
> for mapping with any other layers of information you want to put in.
> It is even possible to make publication-quality maps in R using the sp
> package and friends (as in the ASDAR book).


Good points so far, but I wouldn't be that quick to relegate GRASS to
obscure C-based tasks. I find the the combination of GRASS+R is an
efficient setup, as the two packages are very much complimentary.
Also, you are going to need GRASS if you would like to work with data
sets that won't fit into memory.

Cheers,
Dylan


> ?I wouldn't worry about GRASS - it's great for hardcore spatial
> analysis (buffer this, overlay with that, compute watersheds, clip to
> river buffers, count population in areas,...) but if you need to go
> outside the boxes given you're going to have to start writing in C...
> It's nice to know the power of GRASS is there, but I try and avoid
> using it!
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From friendly at yorku.ca  Sat Oct 17 19:23:54 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 17 Oct 2009 13:23:54 -0400
Subject: [R-sig-Geo] Guerry data: making a package
Message-ID: <4AD9FDAA.7020807@yorku.ca>

Hi

Several years ago I sought & received help (thanks!) from people on this 
list regarding map and data
files associated with my article, A.M. Guerry's Moral Statistics of 
France: Challenges for multivariate spatial analysis,
that appeared in Statistical Science, 2007, 22,368-399.  As 
supplementary materials for that article, I prepared
http://www.math.yorku.ca/SCS/Gallery/guerry/

and also included map and data files for R at
http://www.math.yorku.ca/SCS/Gallery/guerry/maps.html#R
but these were really just a sketch that required more work to make them 
fully usable.

Now I'd like to make an R package including the gfrance1 map and the 
guerry data, and other things,
but I found that something in maptools or other packages had changed, so 
that a script that worked
for me with these map files back in Aug, 2008 does so no longer:

 > library(sp)
 > library(maptools)
 > gfrance <- readShapeSpatial("gfrance1")
Error in read.shape(filen = fn, verbose = verbose, repair = repair) :
  File size and implied file size differ, consider trying repair=TRUE

I get the same error with readShapePoly().

Once I can get that sorted out, it's not exactly clear to me exactly how 
to prepare map files
(SpatialPolygonsDataFrame) for a package with appropriate 
documentation.  Using
another version of the Guerry map and data (omitting Corsica) provided 
by Stephane Dray, I *could* read it
successfully, then tried

 > cd("dray")
 > gfrance85 <- readShapePoly("gfrance1")
 > save(gfrance85, file="gfrance85.rda")
 > prompt(gfrance85)
Created file named 'gfrance85.Rd'.
Edit the file and move it to the appropriate directory.

There is no prompt method for SpatialPolygonsDataFrame objects, so 
prompt() just
dumps the entire results of str(gfrance85); I can of course edit out the 
@ polygons list.
Is this the recommended way to include such objects in packages? 

Thanks,
-Michael


-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From rpruner at ufl.edu  Sat Oct 17 21:19:24 2009
From: rpruner at ufl.edu (Raya A. Pruner)
Date: Sat, 17 Oct 2009 15:19:24 -0400 (EDT)
Subject: [R-sig-Geo] help using irregular polygons R with spatstat package
Message-ID: <672950713.277941255807164227.JavaMail.osg@osgjas01.cns.ufl.edu>

I'm trying to test for conspecific attraction with snowy plovers, 
in other words, aggregation in response to successful nest fates.  
I have nest locations, fates, and polygons of potential nesting 
habitat.  The polygons of potential habitat are from barrier 
islands in Florida.  Most of the polygons are ~7km in length and 
200-300m wide.  All data was read into R as shapefiles created 
with ArcMap 9.2.

I have loaded the following libraries in R: sp, rgdal, spatstat, 
and maptools.

I've used essentially the following code (substituting my actual 
files):

boundary=readOGR(dsn="polygon.shp",layer= "polygon")
nests=readOGR(dsn="nest.location.shp", layer="nest.location")
boundary.owin=as(as(boundary,"SpatialPolygons"),"owin")
nests.points=as(nests,"SpatialPoints")
nests.ppp=as.ppp(nests.points,W=boundary.owin)

All script works fine except for the last line.  When I run this 
one, I get the following error:

Error in as.ppp.SpatialPoints(nest.points, W = boundary.owin) :
  unused argument(s) (W = list(type = "polygonal", xrange = 
c(252580.626188745,.........

Does anyone know what this error message means?  And suggestions 
on what I can/should do????

Thanks!
Raya


--
Raya A Pruner - Graduate Student
University of Florida
Department of Wildlife Ecology and Conservation
PO Box 110430
Gainesville, FL 32611-0430
352-214-3262


From adrian at maths.uwa.edu.au  Mon Oct 19 09:22:32 2009
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Mon, 19 Oct 2009 15:22:32 +0800
Subject: [R-sig-Geo] help using irregular polygons R with spatstat package
Message-ID: <4ADC13B8.6070101@maths.uwa.edu.au>

Raya A. Pruner <rpruner at ufl.edu>  writes:

> I have loaded the following libraries in R: sp, rgdal, spatstat, 
> and maptools. 

> I've used essentially the following code (substituting my actual 
> files):

> boundary=readOGR(dsn="polygon.shp",layer= "polygon")
> nests=readOGR(dsn="nest.location.shp", layer="nest.location")
> boundary.owin=as(as(boundary,"SpatialPolygons"),"owin")
> nests.points=as(nests,"SpatialPoints")
> nests.ppp=as.ppp(nests.points,W=boundary.owin)

> All script works fine except for the last line.  When I run this 
> one, I get the following error:

> Error in as.ppp.SpatialPoints(nest.points, W = boundary.owin) :
>  unused argument(s) (W = list(type = "polygonal", xrange = 
> c(252580.626188745,.........

> Does anyone know what this error message means?  And suggestions 
> on what I can/should do????

This means that 'W' was not a recognised argument of 'as.ppp.SpatialPoints'. 

When you tried to convert the object 'nests.points' (of class "SpatialPoints") 
to the class "ppp" using the generic command 'as.ppp', the method 'as.ppp.SpatialPoints'
from the library 'maptools' was invoked. This function (which you can inspect by typing
its name) has only one argument, X. There is currently no facility to specify the window
by a second argument W.

The easiest way to get what you want is to use the 'ppp' command in spatstat.

nests.ppp <- ppp(nests.points[,1], nests.points[,2], window=boundary.owin)

Alternatively you could use the following modified version of 'as.ppp.SpatialPoints' 
which does behave as you wanted.

as.ppp.SpatialPoints <- function (X, W=NULL)
{
    require(spatstat)
    bb <- bbox(X)
    colnames(bb) <- NULL
    if(is.null(W)) W = owin(bb[1, ], bb[2, ])
    cc = coordinates(X)
    return(ppp(cc[, 1], cc[, 2], window = W, marks = NULL, check = FALSE))
}


regards
Adrian Baddeley


From marco.helbich at gmx.at  Mon Oct 19 09:32:38 2009
From: marco.helbich at gmx.at (Marco Helbich)
Date: Mon, 19 Oct 2009 09:32:38 +0200
Subject: [R-sig-Geo] Getting started with Open Source GIS
Message-ID: <20091019073238.220970@gmx.net>

Dear Ezra!

Additionally to the already mentioned things, you can have a look at SAGA GIS for some geospatial operations. For geocoding purposes tom hengl used google maps. Here you can see his example: http://spatial-analyst.net/wiki/index.php?title=Mapping_research_hot-spots

hope it helps!
marco helbich


-- 
GRATIS f?r alle GMX-Mitglieder: Die maxdome Movie-FLAT!


From Roger.Bivand at nhh.no  Mon Oct 19 10:09:37 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 19 Oct 2009 10:09:37 +0200 (CEST)
Subject: [R-sig-Geo] help using irregular polygons R with spatstat
 package
In-Reply-To: <4ADC13B8.6070101@maths.uwa.edu.au>
References: <4ADC13B8.6070101@maths.uwa.edu.au>
Message-ID: <alpine.LRH.2.00.0910190940010.4987@reclus.nhh.no>

On Mon, 19 Oct 2009, Adrian Baddeley wrote:

> Raya A. Pruner <rpruner at ufl.edu>  writes:
>
>> I have loaded the following libraries in R: sp, rgdal, spatstat, and 
>> maptools. 
>
>> I've used essentially the following code (substituting my actual files):
>
>> boundary=readOGR(dsn="polygon.shp",layer= "polygon")
>> nests=readOGR(dsn="nest.location.shp", layer="nest.location")
>> boundary.owin=as(as(boundary,"SpatialPolygons"),"owin")
>> nests.points=as(nests,"SpatialPoints")
>> nests.ppp=as.ppp(nests.points,W=boundary.owin)
>
>> All script works fine except for the last line.  When I run this one, I get 
>> the following error:
>
>> Error in as.ppp.SpatialPoints(nest.points, W = boundary.owin) :
>>  unused argument(s) (W = list(type = "polygonal", xrange = 
>> c(252580.626188745,.........
>
>> Does anyone know what this error message means?  And suggestions on what I 
>> can/should do????
>
> This means that 'W' was not a recognised argument of 
> 'as.ppp.SpatialPoints'. When you tried to convert the object 
> 'nests.points' (of class "SpatialPoints") to the class "ppp" using the 
> generic command 'as.ppp', the method 'as.ppp.SpatialPoints' from the 
> library 'maptools' was invoked. This function (which you can inspect by 
> typing its name) has only one argument, X. There is currently no 
> facility to specify the window by a second argument W.
>
> The easiest way to get what you want is to use the 'ppp' command in spatstat.
>
> nests.ppp <- ppp(nests.points[,1], nests.points[,2], window=boundary.owin)

Yes, this is the easiest. But you can also say:

nests.ppp <- as(nests.points, "ppp")
nests.ppp$window <- boundary.owin

This will not check the window for appropriateness. The function
as.ppp.SpatialPoints() is user-visible as an S3 method, but is really an 
S4 coercion method, which does not admit extra arguments. The sp classes 
are S4, while spatstat classes are S3. The following:

window.ppp <- function(x, ...) {
   stopifnot(inherits(x, "ppp"))
   x$window
}

"window<-.ppp" <- function(x, ..., value) {
   stopifnot(inherits(x, "ppp"))
   stopifnot(inherits(value, "owin"))
   x$window <- value
}

use the generics defined in the stats package, and the replacement method 
could be extended to include checking from the ppp() function to make sure 
that the new window is appropriate.

Then the inadequate:

nests.ppp$window <- boundary.owin

could become:

window(nests.ppp) <- boundary.owin

Best wishes,

Roger

>
> Alternatively you could use the following modified version of 
> 'as.ppp.SpatialPoints' which does behave as you wanted.
>
> as.ppp.SpatialPoints <- function (X, W=NULL)
> {
>   require(spatstat)
>   bb <- bbox(X)
>   colnames(bb) <- NULL
>   if(is.null(W)) W = owin(bb[1, ], bb[2, ])
>   cc = coordinates(X)
>   return(ppp(cc[, 1], cc[, 2], window = W, marks = NULL, check = FALSE))
> }
>
>
> regards
> Adrian Baddeley
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tom.gottfried at wzw.tum.de  Mon Oct 19 13:19:06 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Mon, 19 Oct 2009 13:19:06 +0200
Subject: [R-sig-Geo] Getting started with Open Source GIS
In-Reply-To: <d0248ce60910170746h1f51ff29na73891039c870d5a@mail.gmail.com>
References: <d0248ce60910170746h1f51ff29na73891039c870d5a@mail.gmail.com>
Message-ID: <4ADC4B2A.30604@wzw.tum.de>

Ezra,

this post on the GRASS-Announce list may be of interest for you too:
http://n2.nabble.com/Arramagong-GISVM-GeoSpatial-Live-DVD-and-Virtual-Machine-available-td3834441.html

regards,
Tom


From John.Carson at shawgrp.com  Mon Oct 19 15:47:42 2009
From: John.Carson at shawgrp.com (Carson, John)
Date: Mon, 19 Oct 2009 08:47:42 -0500
Subject: [R-sig-Geo] variogram estimation with adaptive sampling weights
Message-ID: <79911294E2D6B14087F5AC36345A50BB02B20BC7@entbtrxmb01.shawgrp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091019/feec81f3/attachment.pl>

From Virgilio.Gomez at uclm.es  Mon Oct 19 16:10:22 2009
From: Virgilio.Gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Mon, 19 Oct 2009 10:10:22 -0400
Subject: [R-sig-Geo] variogram estimation with adaptive sampling weights
In-Reply-To: <79911294E2D6B14087F5AC36345A50BB02B20BC7@entbtrxmb01.shawgrp.com>
References: <79911294E2D6B14087F5AC36345A50BB02B20BC7@entbtrxmb01.shawgrp.com>
Message-ID: <1255961422.3321.50.camel@Virgilio-Gomez>

Hi John,

Not sure how to address your initial question but it looks like what you
are doing is similar to preferential sampling. If so, you may want to
look at the paper Geostatistical Inference under Preferential Sampling.
The authors provide provide code and data at
http://www.lancs.ac.uk/~diggle/

Hope this helps.

Virgilio 

El lun, 19-10-2009 a las 08:47 -0500, Carson, John escribi?: 
> Dear r-sig-geostat members,
> 
>  
> 
> I have a spatial soil sampling design which will be used for a
> moderately large number of areas.  The first or primary stage is
> systematic.  Any primary locations observed to exceed one or more
> thresholds (it's a multivariable problem) will trigger (composite)
> sample collection in the 4 adjacent grid areas.  So the sampling is
> adaptive cluster sampling, and I use sampling weights for
> Horvitz-Thompson estimation (prop to 1/(prob of selection)).  I know
> that variograms estimated with this kind of clustered data can be
> biased.  I would like to directly incorporate sampling weights into the
> variogram estimation.  I have used gstat and geoR previously and don't
> see an easy way to use external weights.  
> 
>  
> 
> Does anyone know how to use external weights for variogram estimation in
> these packages?  Or are there other libraries that would work better?
> 
>  
> 
> Thanks in advance,
> 
> John   
> 
>  
> 
> John H. Carson Jr., PhD
> 
> Senior Statistician
> 
> Applied Sciences & Engineering 
> 
> Shaw Environmental & Infrastructure
> 
> 16406 US Rte 224 East
> 
> Findlay, OH 45840
> 
> Phone 419-425-6156
> 
> Fax 419-425-6085
> 
> john.carson at shawgrp.com
> 
>  
> 
> http://www.shawgrp.com/ <http://www.shawgrp.com/> 
> 
> Shaw(tm) a world of Solutions(tm) <http://www.shawgrp.com/> 
> 
>  
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
> 
>  
> 
> 
> 
> ****Internet Email Confidentiality Footer****
> Privileged/Confidential Information may be contained in this
> message. If you are not the addressee indicated in this message (or
> responsible for delivery of the message to such person), you may
> not copy or deliver this message to anyone. In such case, you
> should destroy this message and notify the sender by reply email.
> Please advise immediately if you or your employer do not consent to
> Internet email for messages of this kind. Opinions, conclusions and
> other information in this message that do not relate to the
> official business of The Shaw Group Inc. or its subsidiaries shall
> be understood as neither given nor endorsed by it.
> ______________________________________ The Shaw Group Inc.
> http://www.shawgrp.com  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From John.Carson at shawgrp.com  Mon Oct 19 16:30:55 2009
From: John.Carson at shawgrp.com (Carson, John)
Date: Mon, 19 Oct 2009 09:30:55 -0500
Subject: [R-sig-Geo] variogram estimation with adaptive sampling weights
In-Reply-To: <1255961422.3321.50.camel@Virgilio-Gomez>
References: <79911294E2D6B14087F5AC36345A50BB02B20BC7@entbtrxmb01.shawgrp.com>
	<1255961422.3321.50.camel@Virgilio-Gomez>
Message-ID: <79911294E2D6B14087F5AC36345A50BB02B20C33@entbtrxmb01.shawgrp.com>

Hi Virgilio,

Thanks for the reference.  I'll definitely give this a good look.  This type of sampling (preferential sampling) is known as adaptive sampling in classical sampling theory.  It is a difficult area but has a good body of literature.  For instance,


Thompson, S.K. (2002) Sampling: Second Ed. John Wiley and Sons. New York. 367 pp.

Thompson, S.K. and G.A.F. Seber (1996) Adaptive Sampling. John Wiley and Sons. New York. 265 pp.


Best,
John


John H. Carson Jr., PhD
Senior Statistician
Applied Sciences & Engineering 
Shaw Environmental & Infrastructure
16406 US Rte 224 East
Findlay, OH 45840
Phone 419-425-6156
Fax 419-425-6085
john.carson at shawgrp.com
 
http://www.shawgrp.com/
Shaw(tm) a world of Solutions(tm)
 
To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher
The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
-----Original Message-----
From: Virgilio G?mez-Rubio [mailto:Virgilio.Gomez at uclm.es] 
Sent: Monday, October 19, 2009 10:10 AM
To: Carson, John
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] variogram estimation with adaptive sampling weights

Hi John,

Not sure how to address your initial question but it looks like what you
are doing is similar to preferential sampling. If so, you may want to
look at the paper Geostatistical Inference under Preferential Sampling.
The authors provide provide code and data at
http://www.lancs.ac.uk/~diggle/

Hope this helps.

Virgilio 

El lun, 19-10-2009 a las 08:47 -0500, Carson, John escribi?: 
> Dear r-sig-geostat members,
> 
>  
> 
> I have a spatial soil sampling design which will be used for a
> moderately large number of areas.  The first or primary stage is
> systematic.  Any primary locations observed to exceed one or more
> thresholds (it's a multivariable problem) will trigger (composite)
> sample collection in the 4 adjacent grid areas.  So the sampling is
> adaptive cluster sampling, and I use sampling weights for
> Horvitz-Thompson estimation (prop to 1/(prob of selection)).  I know
> that variograms estimated with this kind of clustered data can be
> biased.  I would like to directly incorporate sampling weights into the
> variogram estimation.  I have used gstat and geoR previously and don't
> see an easy way to use external weights.  
> 
>  
> 
> Does anyone know how to use external weights for variogram estimation in
> these packages?  Or are there other libraries that would work better?
> 
>  
> 
> Thanks in advance,
> 
> John   
> 
>  
> 
> John H. Carson Jr., PhD
> 
> Senior Statistician
> 
> Applied Sciences & Engineering 
> 
> Shaw Environmental & Infrastructure
> 
> 16406 US Rte 224 East
> 
> Findlay, OH 45840
> 
> Phone 419-425-6156
> 
> Fax 419-425-6085
> 
> john.carson at shawgrp.com
> 
>  
> 
> http://www.shawgrp.com/ <http://www.shawgrp.com/> 
> 
> Shaw(tm) a world of Solutions(tm) <http://www.shawgrp.com/> 
> 
>  
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
> 
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
> 
>  
> 
> 
> 
> ****Internet Email Confidentiality Footer****
> Privileged/Confidential Information may be contained in this
> message. If you are not the addressee indicated in this message (or
> responsible for delivery of the message to such person), you may
> not copy or deliver this message to anyone. In such case, you
> should destroy this message and notify the sender by reply email.
> Please advise immediately if you or your employer do not consent to
> Internet email for messages of this kind. Opinions, conclusions and
> other information in this message that do not relate to the
> official business of The Shaw Group Inc. or its subsidiaries shall
> be understood as neither given nor endorsed by it.
> ______________________________________ The Shaw Group Inc.
> http://www.shawgrp.com  
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

****Internet Email Confidentiality Footer****
Privileged/Confidential Information may be contained in this
message. If you are not the addressee indicated in this message (or
responsible for delivery of the message to such person), you may
not copy or deliver this message to anyone. In such case, you
should destroy this message and notify the sender by reply email.
Please advise immediately if you or your employer do not consent to
Internet email for messages of this kind. Opinions, conclusions and
other information in this message that do not relate to the
official business of The Shaw Group Inc. or its subsidiaries shall
be understood as neither given nor endorsed by it.
______________________________________ The Shaw Group Inc.
http://www.shawgrp.com


From carlos.uni2 at gmail.com  Mon Oct 19 17:00:48 2009
From: carlos.uni2 at gmail.com (Carlos Hernandez)
Date: Mon, 19 Oct 2009 17:00:48 +0200
Subject: [R-sig-Geo] google insight map to shapefile
Message-ID: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091019/2364f227/attachment.pl>

From przemek83 at gmail.com  Tue Oct 20 12:07:43 2009
From: przemek83 at gmail.com (Przemek Jura)
Date: Tue, 20 Oct 2009 18:07:43 +0800
Subject: [R-sig-Geo] how to combine data with shapefile file for GWR
Message-ID: <1454c4320910200307p27e92b29q8920c2bc743dd8df@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091020/6b57139b/attachment.pl>

From Roger.Bivand at nhh.no  Tue Oct 20 12:46:55 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 20 Oct 2009 12:46:55 +0200 (CEST)
Subject: [R-sig-Geo] how to combine data with shapefile file for GWR
In-Reply-To: <1454c4320910200307p27e92b29q8920c2bc743dd8df@mail.gmail.com>
References: <1454c4320910200307p27e92b29q8920c2bc743dd8df@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0910201241200.8480@reclus.nhh.no>

On Tue, 20 Oct 2009, Przemek Jura wrote:

> Dear subscribers,I am newbie in geographical analysis (especially in R),
> please be understanding.
> In my analysis I would like to conduct geographically weighted regression.
> The region I analyse has 16 provinces which are defined in shp file (16
> polygons). However, data set (in separate data source) is stratified by
> different variables like: year, gender, age group and of course region what
> gives around 4000 records. Here is my problem: is it possible to  combine
> regions in shp with the region variable in my data set (in both have the
> same names)? When I used spCbind function it takes only first 16 matching
> criteria records form a data set.Is it possible to conduct GWR taking into
> account all the listed variables?

Please think through your research problem carefully. If you have 4000 
observations, but no separate spatial support for them (either 4000 
polygons if say census tracts, or 4000 points if say patients), then you 
can only model this data after aggregation to the 16 provinces. Then you 
have areal spatial support, but for very few aggregate observations, so 
GWR will not get you very far. If you want to use spatial methods on the 
whole data set, you need appropriate spatial support.

Hope this helps,

Roger

> Thank you in advance!
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From p.hiemstra at geo.uu.nl  Tue Oct 20 12:51:28 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 20 Oct 2009 12:51:28 +0200
Subject: [R-sig-Geo] Export of an irregular grid
In-Reply-To: <4AD86C7F.7080900@cnam.fr>
References: <4AD86C7F.7080900@cnam.fr>
Message-ID: <4ADD9630.8010109@geo.uu.nl>

Poizot Emmanuel wrote:
> Dear all,
Hi Emmanuel,
>
> after interpolation with the gstat package, I created a grid of class 
> SpatialGridDataFrame.
> The grid is not regular. 
How did you construct a SGDF then? Why is the grid not regular? Why not 
make it regular? If the outcome is a SpatialPointsDataFrame, dump it as 
an ascii file using write.table (like Robert suggested). But how to 
export the data also depends on what you want to do with it afterwards.
> I tried to export it with write.asciigrid function but didn't succed, 
> I suppose because of the non-regularity of my grid.
What error did you get? Look at the output of traceback() right after 
the error.
> How can I turn around that problem ?
Provide use with more info (also look at sessionInfo()) and maybe a 
reproducible example.

cheers,
Paul
>
> ------------------------------------------------
> Emmanuel Poizot
> Cnam/Intechmer
> B.P. 324
> 50103 Cherbourg Cedex
>
> Phone (Direct) : (00 33)(0)233887342
> Fax : (00 33)(0)233887339
> ------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Tue Oct 20 12:56:07 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 20 Oct 2009 12:56:07 +0200
Subject: [R-sig-Geo] variogram estimation with adaptive sampling weights
In-Reply-To: <79911294E2D6B14087F5AC36345A50BB02B20BC7@entbtrxmb01.shawgrp.com>
References: <79911294E2D6B14087F5AC36345A50BB02B20BC7@entbtrxmb01.shawgrp.com>
Message-ID: <4ADD9747.2030600@geo.uu.nl>

Hi John,

I recently wrote a variogram fitting routine using the R function 
optim(). It works together with gstat. It is quite straightforward to 
write you own goal function for optim(), including the weights to use in 
the fitting. Send me an e-mail offlist if you need the code and some 
examples.

cheers,
Paul

Carson, John wrote:
> Dear r-sig-geostat members,
>
>  
>
> I have a spatial soil sampling design which will be used for a
> moderately large number of areas.  The first or primary stage is
> systematic.  Any primary locations observed to exceed one or more
> thresholds (it's a multivariable problem) will trigger (composite)
> sample collection in the 4 adjacent grid areas.  So the sampling is
> adaptive cluster sampling, and I use sampling weights for
> Horvitz-Thompson estimation (prop to 1/(prob of selection)).  I know
> that variograms estimated with this kind of clustered data can be
> biased.  I would like to directly incorporate sampling weights into the
> variogram estimation.  I have used gstat and geoR previously and don't
> see an easy way to use external weights.  
>
>  
>
> Does anyone know how to use external weights for variogram estimation in
> these packages?  Or are there other libraries that would work better?
>
>  
>
> Thanks in advance,
>
> John   
>
>  
>
> John H. Carson Jr., PhD
>
> Senior Statistician
>
> Applied Sciences & Engineering 
>
> Shaw Environmental & Infrastructure
>
> 16406 US Rte 224 East
>
> Findlay, OH 45840
>
> Phone 419-425-6156
>
> Fax 419-425-6085
>
> john.carson at shawgrp.com
>
>  
>
> http://www.shawgrp.com/ <http://www.shawgrp.com/> 
>
> Shaw(tm) a world of Solutions(tm) <http://www.shawgrp.com/> 
>
>  
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to
> say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of
> data.
> ~ John Tukey
>
>  
>
>
>
> ****Internet Email Confidentiality Footer****
> Privileged/Confidential Information may be contained in this
> message. If you are not the addressee indicated in this message (or
> responsible for delivery of the message to such person), you may
> not copy or deliver this message to anyone. In such case, you
> should destroy this message and notify the sender by reply email.
> Please advise immediately if you or your employer do not consent to
> Internet email for messages of this kind. Opinions, conclusions and
> other information in this message that do not relate to the
> official business of The Shaw Group Inc. or its subsidiaries shall
> be understood as neither given nor endorsed by it.
> ______________________________________ The Shaw Group Inc.
> http://www.shawgrp.com  
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From michael.denslow at gmail.com  Tue Oct 20 14:52:29 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Tue, 20 Oct 2009 08:52:29 -0400
Subject: [R-sig-Geo] google insight map to shapefile
In-Reply-To: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>
References: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>
Message-ID: <b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com>

Hi Carlos,


On Mon, Oct 19, 2009 at 11:00 AM, Carlos Hernandez
<carlos.uni2 at gmail.com> wrote:
> Dear all,I'm using Google Insight data and I would like to "translate" the
> US map (with metro divisions) to a shape file.
>
> The maps i'm interested in appears in the following link (after clicking on
> "Metro" on the top right of the US map).
>
> http://www.google.com/insights/search/?hl=en-US#q=coldplay&geo=US&cmpt=q
>
> Do you have any advice on how to transform this map to a shape file? Is
> there a simple way to do this?

There may be a way to take the shapefile all at once but why not just
download the csv file (top of the page) and bind it to the existing
attribute table of a metro area file?

I would be interested to know how you end up doing it,
Michael

> Best regards,
> Carlos
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From ogbos.okike at gmail.com  Tue Oct 20 15:02:44 2009
From: ogbos.okike at gmail.com (ogbos okike)
Date: Tue, 20 Oct 2009 15:02:44 +0200
Subject: [R-sig-Geo] Marking Locations on Geophysical map
Message-ID: <43b418580910200602l2ee17d56k34c4ab3a85379d84@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091020/535be111/attachment.pl>

From carlos.uni2 at gmail.com  Tue Oct 20 15:11:20 2009
From: carlos.uni2 at gmail.com (Carlos Hernandez)
Date: Tue, 20 Oct 2009 15:11:20 +0200
Subject: [R-sig-Geo] google insight map to shapefile
In-Reply-To: <b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com>
References: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>
	<b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com>
Message-ID: <46e779e50910200611t5cda95e4w23801ed1f4412e38@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091020/cfd61233/attachment.pl>

From michael.denslow at gmail.com  Tue Oct 20 16:56:20 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Tue, 20 Oct 2009 10:56:20 -0400
Subject: [R-sig-Geo] google insight map to shapefile
In-Reply-To: <46e779e50910200611t5cda95e4w23801ed1f4412e38@mail.gmail.com>
References: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>
	<b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com>
	<46e779e50910200611t5cda95e4w23801ed1f4412e38@mail.gmail.com>
Message-ID: <b440a3f80910200756x2b2ce215tbdb96281299195a2@mail.gmail.com>

Hi Carlos,


On Tue, Oct 20, 2009 at 9:11 AM, Carlos Hernandez <carlos.uni2 at gmail.com> wrote:
> Hi Michael, Thanks!
>
> What i'm aiming at is to replicate the US map (by metro regions) just like
> shown in the link but i need to plot my own data.
>
> I'm not sure i understand your idea. Is there a simple way to replicate the
> map?

I probably should have thought a bit more before I replied since I
have not done this before. I was just trying to think of a way that I
might do it. I do not know how to directly download that file from
Google.

Making maps like this in R is fairly easy since there are some nice
examples such as,
http://cran.r-project.org/web/packages/spdep/vignettes/sids.pdf

I am not aware of metro area files in R, though there are state and
county files in the maps package. But, I was thinking that you could
locate a metro regions shape file of the US and map the colors based
on the attributes in provided in the csv file on the Google page.
For example, Top metros for cold play, Harrisonburg = 100, etc. etc.

I am not sure how many you need to do so this may not be very efficient,
Sorry I couldn't help more,
Michael


> Best regards,
> Carlos
>
>
> On Tue, Oct 20, 2009 at 2:52 PM, Michael Denslow <michael.denslow at gmail.com>
> wrote:
>>
>> Hi Carlos,
>>
>>
>> On Mon, Oct 19, 2009 at 11:00 AM, Carlos Hernandez
>> <carlos.uni2 at gmail.com> wrote:
>> > Dear all,I'm using Google Insight data and I would like to "translate"
>> > the
>> > US map (with metro divisions) to a shape file.
>> >
>> > The maps i'm interested in appears in the following link (after clicking
>> > on
>> > "Metro" on the top right of the US map).
>> >
>> > http://www.google.com/insights/search/?hl=en-US#q=coldplay&geo=US&cmpt=q
>> >
>> > Do you have any advice on how to transform this map to a shape file? Is
>> > there a simple way to do this?
>>
>> There may be a way to take the shapefile all at once but why not just
>> download the csv file (top of the page) and bind it to the existing
>> attribute table of a metro area file?
>>
>> I would be interested to know how you end up doing it,
>> Michael
>>
>> > Best regards,
>> > Carlos
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at stat.math.ethz.ch
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>>
>>
>> --
>> Michael Denslow
>>
>> Graduate Student & Adjunct Instructor
>> I.W. Carpenter Jr. Herbarium [BOON]
>> Department of Biology
>> Appalachian State University
>> Boone, North Carolina U.S.A.
>> -- AND --
>> Communications Manager
>> Southeast Regional Network of Expertise and Collections
>> sernec.org
>>
>> 36.214177, -81.681480 +/- 3103 meters
>
>



-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From b.rowlingson at lancaster.ac.uk  Tue Oct 20 17:21:02 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 20 Oct 2009 16:21:02 +0100
Subject: [R-sig-Geo] google insight map to shapefile
In-Reply-To: <b440a3f80910200756x2b2ce215tbdb96281299195a2@mail.gmail.com>
References: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>
	<b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com>
	<46e779e50910200611t5cda95e4w23801ed1f4412e38@mail.gmail.com>
	<b440a3f80910200756x2b2ce215tbdb96281299195a2@mail.gmail.com>
Message-ID: <d8ad40b50910200821i2baa6d94j519b808104ed7935@mail.gmail.com>

On Tue, Oct 20, 2009 at 3:56 PM, Michael Denslow
<michael.denslow at gmail.com> wrote:

> I probably should have thought a bit more before I replied since I
> have not done this before. I was just trying to think of a way that I
> might do it. I do not know how to directly download that file from
> Google.
>

 A few minutes work with the 'firebug' debugger in Firefox has lead me
to the XML file of that map data. A little bit of manipulation could
easily get it into R as an sp object and hence you could use it as a
base for your data once you've matched up some numeric codes for the
areas.

However, I'm not sure whether the google terms of reference would
allow you to do anything with the data.

  I'm also a bit unsure what the coordinate system is here - it
doesn't seem to overlay nicely with a US shapefile that should be in
WGS84 coords.

Barry


From r.hijmans at gmail.com  Tue Oct 20 18:37:32 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 20 Oct 2009 09:37:32 -0700
Subject: [R-sig-Geo] Marking Locations on Geophysical map
In-Reply-To: <43b418580910200602l2ee17d56k34c4ab3a85379d84@mail.gmail.com>
References: <43b418580910200602l2ee17d56k34c4ab3a85379d84@mail.gmail.com>
Message-ID: <dc22b2570910200937p72a2b6f2h416a596409667ec7@mail.gmail.com>

Ogbos,
I cannot see the map (access denied), but you can accomplish this by
creating a point for each symbol location. You can use the "click"
function (raster package) to make this interactive. Then add the
points to the map using points( ). For different symbols, have a look
at the cex argument under ?points. You could also add text using a
point with  text(c(x,y), 'hello world'). Also see ?arrows.
Robert

On Tue, Oct 20, 2009 at 6:02 AM, ogbos okike <ogbos.okike at gmail.com> wrote:
> Good day all. Attached please find a distribution of latitude and longitude
> lightning activity on world map. This plot was done using raster package.
>
> My headache now is how to use a symbol, say star, to mark or identify a
> country, e.g. South Africa or USA, on the plot.
>
> Thank you.
>
>
> URL:
> http://docs.google.com/Doc?docid=0AfJ5_yv8GrERZGY3NmhuMnNfMWZtcGhjc2d3&hl=en
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alobolistas at gmail.com  Tue Oct 20 19:07:28 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 20 Oct 2009 19:07:28 +0200
Subject: [R-sig-Geo] raster calc
Message-ID: <4ADDEE50.7090808@gmail.com>

I think that the line
*2) |x| is a RasterLayer object; |fun| is a function
in the help page of calc
should be
**2) |x| is a RasterStack object; |fun| is a function*



Anyway, if I want to add 2 rasters (i.e a + b) using the rast package, 
should
I make a raster stack  with them and use calc ?
An example with more than one raster in the help  page would be  very 
helpful.

Thanks

 Agus
-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091020/80af2b18/attachment.vcf>

From kharouba at zoology.ubc.ca  Tue Oct 20 19:38:07 2009
From: kharouba at zoology.ubc.ca (Heather Kharouba)
Date: Tue, 20 Oct 2009 10:38:07 -0700 (PDT)
Subject: [R-sig-Geo] Counting number of points per pixel in a grid
Message-ID: <02dd979db2e91f5e8f9db9c4f0171504.squirrel@webmail.zoology.ubc.ca>

Hi,

I would like to count the number of points per pixel in a grid(there are
thousands of points and thousands of pixels). I have a list of occurrence
points and a grid with a given cell size. Ideally I'd like them saved to
one file where there is a column listing the pixel number and one listing
number of points for that pixel. I've tried overlay (sp package) but it
just spits out a list of all the points in my list with NA value attached
to each point and it doesn't provide a count:

this is my code so far:
grid=readGDAL("mask50")
proj4string(grid)=CRS("+proj=lcc")
x1<-read.csv(file.choose(),header=TRUE,sep=",", na.strings="");
proj4string(x1)=CRS("+proj=lcc")
o<-overlay(grid, x1)
o
NA.33354  (49.71, -97.91)    NA
NA.33355   (50.7, -98.03)    NA
NA.33356  (56.35, -94.66)    NA
NA.33357    (50.83, -100)    NA
NA.33358  (49.36, -96.11)    NA

I'm wondering whether I need to set up a loop for each pixel.
I've also had no luck with count.points.id (adehabitat package). When I
use this function, I get a summary of my grid. Any thoughts would be much
appreciated!

Thanks,
Heather Kharouba


From alobolistas at gmail.com  Tue Oct 20 19:42:28 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 20 Oct 2009 19:42:28 +0200
Subject: [R-sig-Geo] raster package: RGB tif files
Message-ID: <4ADDF684.4050804@gmail.com>

I want to use package raster to apply a linear function
to each band of an RGB tif file.

I thought that
 > st <- stackFromFiles("SDIM1246_L1.TIF")

would make a raster stack with the 3 bands, but
 > nlayers(st)
[1] 1

Then I've tried:

a  <- raster("SDIM1246_L1.TIF")

and str(a) indicates that there are 3 bands, but, then, how
can I use calc() on each of them?

Thanks

Agus



-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091020/98f5fc8c/attachment.vcf>

From Roger.Bivand at nhh.no  Tue Oct 20 20:53:06 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 20 Oct 2009 20:53:06 +0200 (CEST)
Subject: [R-sig-Geo] Counting number of points per pixel in a grid
In-Reply-To: <02dd979db2e91f5e8f9db9c4f0171504.squirrel@webmail.zoology.ubc.ca>
References: <02dd979db2e91f5e8f9db9c4f0171504.squirrel@webmail.zoology.ubc.ca>
Message-ID: <alpine.LRH.2.00.0910202037570.8480@reclus.nhh.no>

On Tue, 20 Oct 2009, Heather Kharouba wrote:

> Hi,
>
> I would like to count the number of points per pixel in a grid(there are
> thousands of points and thousands of pixels). I have a list of occurrence
> points and a grid with a given cell size. Ideally I'd like them saved to
> one file where there is a column listing the pixel number and one listing
> number of points for that pixel. I've tried overlay (sp package) but it
> just spits out a list of all the points in my list with NA value attached
> to each point and it doesn't provide a count:
>
> this is my code so far:
> grid=readGDAL("mask50")
> proj4string(grid)=CRS("+proj=lcc")
> x1<-read.csv(file.choose(),header=TRUE,sep=",", na.strings="");

# here you seem to be missing a coordinates(x1) <- whatever

> proj4string(x1)=CRS("+proj=lcc")
> o<-overlay(grid, x1)
> o

This is a SpatialPointsDataFrame, with the input coordinates of x1, the 
row names of grid, and the values of grid (all visible are NA, which maybe 
is reasonable for a mask).

> NA.33354  (49.71, -97.91)    NA
> NA.33355   (50.7, -98.03)    NA
> NA.33356  (56.35, -94.66)    NA
> NA.33357    (50.83, -100)    NA
> NA.33358  (49.36, -96.11)    NA
>
> I'm wondering whether I need to set up a loop for each pixel.
> I've also had no luck with count.points.id (adehabitat package). When I
> use this function, I get a summary of my grid. Any thoughts would be much
> appreciated!

No, saying summary(o) would show that you get a summary of the grid values 
at the points in x1.

If you just want the grid cell indices for each point, coerce first:

o <- overlay(as(grid, "SpatialGrid"), x1)

>From that you can work out how many points there are in each grid cell, 
most likely table(o) gets most of the way there, with the table being the 
counts and as.integer(names(table(o))) being the indices. Then:

tab <- table(o)
grid$counts <- as.integer(NA) 
grid$counts[as.integer(names(tab))] <- tab

summary(grid)

Hope this helps,

Roger

PS. Your point coordinate values look geographic (in Canada?), not 
projected, and probably (lat, long), not the required (long, lat); 
"+proj=lcc" values would be in metres.

>
> Thanks,
> Heather Kharouba
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From carlos.uni2 at gmail.com  Tue Oct 20 21:01:32 2009
From: carlos.uni2 at gmail.com (Carlos Hernandez)
Date: Tue, 20 Oct 2009 21:01:32 +0200
Subject: [R-sig-Geo] google insight map to shapefile
In-Reply-To: <d8ad40b50910200821i2baa6d94j519b808104ed7935@mail.gmail.com>
References: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com>
	<b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com>
	<46e779e50910200611t5cda95e4w23801ed1f4412e38@mail.gmail.com>
	<b440a3f80910200756x2b2ce215tbdb96281299195a2@mail.gmail.com>
	<d8ad40b50910200821i2baa6d94j519b808104ed7935@mail.gmail.com>
Message-ID: <46e779e50910201201u34cf13fdg629711e226a4cdb0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091020/f0beac94/attachment.pl>

From p.hiemstra at geo.uu.nl  Tue Oct 20 22:20:19 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 20 Oct 2009 22:20:19 +0200
Subject: [R-sig-Geo] Counting number of points per pixel in a grid
In-Reply-To: <02dd979db2e91f5e8f9db9c4f0171504.squirrel@webmail.zoology.ubc.ca>
References: <02dd979db2e91f5e8f9db9c4f0171504.squirrel@webmail.zoology.ubc.ca>
Message-ID: <4ADE1B83.9020203@geo.uu.nl>

Hi Heather,

Be sure to take a look a the raster package, in particular the 
pointsToRaster function. Does exactly what you want and is very fast. 
Going from sp-grids to raster-objects is very easy.

cheers,
Paul

Heather Kharouba schreef:
> Hi,
>
> I would like to count the number of points per pixel in a grid(there are
> thousands of points and thousands of pixels). I have a list of occurrence
> points and a grid with a given cell size. Ideally I'd like them saved to
> one file where there is a column listing the pixel number and one listing
> number of points for that pixel. I've tried overlay (sp package) but it
> just spits out a list of all the points in my list with NA value attached
> to each point and it doesn't provide a count:
>
> this is my code so far:
> grid=readGDAL("mask50")
> proj4string(grid)=CRS("+proj=lcc")
> x1<-read.csv(file.choose(),header=TRUE,sep=",", na.strings="");
> proj4string(x1)=CRS("+proj=lcc")
> o<-overlay(grid, x1)
> o
> NA.33354  (49.71, -97.91)    NA
> NA.33355   (50.7, -98.03)    NA
> NA.33356  (56.35, -94.66)    NA
> NA.33357    (50.83, -100)    NA
> NA.33358  (49.36, -96.11)    NA
>
> I'm wondering whether I need to set up a loop for each pixel.
> I've also had no luck with count.points.id (adehabitat package). When I
> use this function, I get a summary of my grid. Any thoughts would be much
> appreciated!
>
> Thanks,
> Heather Kharouba
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From pierre.roudier at gmail.com  Wed Oct 21 00:03:58 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Wed, 21 Oct 2009 09:03:58 +1100
Subject: [R-sig-Geo] google insight map to shapefile
In-Reply-To: <d8ad40b50910200821i2baa6d94j519b808104ed7935@mail.gmail.com>
References: <46e779e50910190800m76b071fbw194728ae58949eae@mail.gmail.com> 
	<b440a3f80910200552m2425a05bqbdaa5c83cfc33c40@mail.gmail.com> 
	<46e779e50910200611t5cda95e4w23801ed1f4412e38@mail.gmail.com> 
	<b440a3f80910200756x2b2ce215tbdb96281299195a2@mail.gmail.com> 
	<d8ad40b50910200821i2baa6d94j519b808104ed7935@mail.gmail.com>
Message-ID: <e4178da60910201503y18b71de1qd1efc9c437f8fe05@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091021/225b654c/attachment.pl>

From vkepoglu at gmail.com  Wed Oct 21 09:31:10 2009
From: vkepoglu at gmail.com (Volkan Kepoglu)
Date: Wed, 21 Oct 2009 10:31:10 +0300
Subject: [R-sig-Geo] Spatstat package: help generating random point pattern
	with different window
Message-ID: <8b5938320910210031l370c3cdcjf58f3d4623129b1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091021/311ef534/attachment.pl>

From Adrian.Baddeley at csiro.au  Wed Oct 21 11:10:58 2009
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Wed, 21 Oct 2009 17:10:58 +0800
Subject: [R-sig-Geo] Spatstat package: help generating random point
 pattern with different window
In-Reply-To: <8b5938320910210031l370c3cdcjf58f3d4623129b1@mail.gmail.com>
References: <8b5938320910210031l370c3cdcjf58f3d4623129b1@mail.gmail.com>
Message-ID: <4ADED022.4050605@csiro.au>

Volkan Kepoglu wrote:
> I loaded spatstat, maptools, rgdal packages.
> I want to generate random point pattern with different window derived 
> from polygon shp file.
> but i can not pass new owin argument to rpoispp
>
> > spdf = readOGR(dsn="polygon.shp",layer= "polygon")
> > sp_owin = as(as(spdf,"SpatialPolygons"),"owin")
> > grpp = rpoispp(100000, win=sp_owin) # this does not work

The last line instructs spatstat to generate a Poisson process with an 
**intensity** equal to 100000,
that is, a density of 100000 points ***PER UNIT AREA**.

Your polygonal window sp_owin has an area of 11857425 square units.

This means the expected number of points in the simulated pattern is 
100000 * 11857425 = 1.185743e+12.
That is more than a trillion points.

For a Poisson process, the actual number of points generated is a 
Poisson random variable with mean equal to 1.2 trillion:
      v <- 100000 * 11857425
      n <- rpois(1, v)
      x <- runif(n)
The error message is coming from 'runif' which is refusing to generate 
more than a trillion random numbers:
      Error in runif(n) : invalid arguments
      In addition: Warning message:
      In runif(n) : NAs introduced by coercion

If you wanted to generate approximately 100000 points, set lambda = 
100000/area.owin(sp_owin) in the call to rpoispp.
If you wanted to generate exactly 100000 points, use runifpoint(100000, 
win=sp_owin).

Adrian Baddeley


From stubben at lanl.gov  Wed Oct 21 22:33:52 2009
From: stubben at lanl.gov (stubben)
Date: Wed, 21 Oct 2009 14:33:52 -0600
Subject: [R-sig-Geo] subset SpatialPolygonsDataFrame using negative index?
In-Reply-To: <7F5B301C-E690-4309-95B1-548D2EE618BB@lanl.gov>
References: <7F5B301C-E690-4309-95B1-548D2EE618BB@lanl.gov>
Message-ID: <F80F6D5F-2778-4A1D-A380-E9DCE857FA54@lanl.gov>

I loaded a county map of New Mexico from  census.gov

nm <- readShapePoly("co35_d00.shp", proj4string=CRS("+proj=longlat"))

This map has 34 counties because Sandoval county occurs twice (which  
is funny since there is one missing in the maps database).   I'd like  
to remove the extra polygon which is very small, but a negative index  
doesn't work

# remove 13th row
n<-which(nm2 at data$AREA<0.0005)
n
[1] 13

# using negative index
nm1<-nm[-n,]
# only one county displayed on map
plot(nm1)
## because  plotOrder =1?
str(nm1,2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame':	33 obs. of  9 variables:
   ..@ polygons   :List of 33
   ..@ plotOrder  : int 1
   ..@ bbox       : num [1:2, 1:2] -109.1 31.3 -103 37
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots



##  this works, but I'm just wondering why the negative index doesn't  
work?  Am I doing something wrong?

nm2<-nm[c(1:12,14:34),]
plot(nm2)
str(nm2,2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame':	33 obs. of  9 variables:
   ..@ polygons   :List of 33
   ..@ plotOrder  : int [1:33] 22 23 28 2 25 3 9 12 24 14 ...
   ..@ bbox       : num [1:2, 1:2] -109.1 31.3 -103 37
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots



Thanks,

Chris Stubben


>


From MarburgA at landcareresearch.co.nz  Wed Oct 21 23:32:40 2009
From: MarburgA at landcareresearch.co.nz (Anna Marburg)
Date: Thu, 22 Oct 2009 10:32:40 +1300
Subject: [R-sig-Geo] Counting number of points per pixel in a grid
Message-ID: <E8755AA1-DE84-4E43-9FAF-D997413A0463@landcareresearch.co.nz>

Hello Heather -

The first thing to do is explore your data and make sure that your
grid and points have imported correctly.

Different spatial packages have slightly different classes, so its
always a good idea to use class() to make sure that your object is
what you think it is. plot(), summary() and str() are also often
helpful.


If you are still unable to get overlay to work, try the "quadratcount"
function in the spatstat package (you will need to define your points
as a spatial point pattern first).

You can specify either the number of pixels you want to divide your
study area into, provide 2 vectors of break-points, or format your
grid as a "tesselation".

The drawback is that with thousands of pixels, it may be quite slow.
Try it on a subset of the data first, to see if it does what you want.

Others will probably have more efficient suggestions.

HTH,

Anna

~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Dr. Anna E. Marburg
Postdoctoral researcher
Ecosystem Processes Team
Landcare Research
P O Box 40
Lincoln 7640
NEW ZEALAND

phone + 64  3 321 9729
MarbugA at landcareresearch.co.nz

~~~~~~~~~~~~~~~~~~~~~~~~~~~~




Please consider the environment before printing this email
Warning:  This electronic message together with any attachments is confidential. If you receive it in error: (i) you must not read, use, disclose, copy or retain it; (ii) please contact the sender immediately by reply email and then delete the emails.
The views expressed in this email may not be those of Landcare Research New Zealand Limited. http://www.landcareresearch.co.nz


From Adrian.Baddeley at csiro.au  Thu Oct 22 03:56:07 2009
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Thu, 22 Oct 2009 09:56:07 +0800
Subject: [R-sig-Geo] Counting points in a pixel grid
Message-ID: <57DC18C299094D4299F837570C5DF1C502BECFF1E4@EXWA-MBX01.nexus.csiro.au>

Heather Kharouba <kharouba at zoology.ubc.ca> writes:

> I would like to count the number of points per pixel in a grid(there are
> thousands of points and thousands of pixels). I have a list of occurrence
> points and a grid with a given cell size. Ideally I'd like them saved to
> one file where there is a column listing the pixel number and one listing
> number of points for that pixel. 

Try 'pixellate.ppp' in the library 'spatstat'. 

First convert your point coordinates to a point pattern X (object of class "ppp") using ppp() or as.ppp().

Then, for example if you want square pixels of side length 3 units,
        Z <- pixellate(X, eps=3)
You can specify the exact coordinates of the pixel centres by 
        Z <- pixellate(X, xy=list(x=xcoord, y=ycoord))
where xcoord and ycoord are vectors of the pixel coordinates.

The result Z is an integer valued pixel image (object of class "im"). 
Use 'as.data.frame' to convert it to the format you wanted.
To write to an output file in the desired format,

      sink("results.txt")
     as.data.frame(Z)
     sink()


Adrian Baddeley




   


From Roger.Bivand at nhh.no  Thu Oct 22 10:38:39 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 22 Oct 2009 10:38:39 +0200 (CEST)
Subject: [R-sig-Geo] subset SpatialPolygonsDataFrame using negative
 index?
In-Reply-To: <F80F6D5F-2778-4A1D-A380-E9DCE857FA54@lanl.gov>
References: <7F5B301C-E690-4309-95B1-548D2EE618BB@lanl.gov>
	<F80F6D5F-2778-4A1D-A380-E9DCE857FA54@lanl.gov>
Message-ID: <alpine.LRH.2.00.0910221031030.17903@reclus.nhh.no>

On Wed, 21 Oct 2009, stubben wrote:

> I loaded a county map of New Mexico from  census.gov
>
> nm <- readShapePoly("co35_d00.shp", proj4string=CRS("+proj=longlat"))
>
> This map has 34 counties because Sandoval county occurs twice (which is funny 
> since there is one missing in the maps database).   I'd like to remove the 
> extra polygon which is very small, but a negative index doesn't work

No, the negative index doesn't work, I'll try to commit a fix to sp. In 
fact, I'd rather do:

nm <- readShapePoly("co35_d00.shp", proj4string=CRS("+proj=longlat"))
nm1 <- unionSpatialPolygons(nm, nm$COUNTY)
df <- as(nm, "data.frame")[-13,]
row.names(df) <- df$COUNTY
nm2 <- SpatialPolygonsDataFrame(nm1, df)

which makes a multipolygon for Sandoval and drops the attributes for the 
second member polygon.

Hope this helps,

Roger

>
> # remove 13th row
> n<-which(nm2 at data$AREA<0.0005)
> n
> [1] 13
>
> # using negative index
> nm1<-nm[-n,]
> # only one county displayed on map
> plot(nm1)
> ## because  plotOrder =1?
> str(nm1,2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
> ..@ data       :'data.frame':	33 obs. of  9 variables:
> ..@ polygons   :List of 33
> ..@ plotOrder  : int 1
> ..@ bbox       : num [1:2, 1:2] -109.1 31.3 -103 37
> .. ..- attr(*, "dimnames")=List of 2
> ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>
>
>
> ##  this works, but I'm just wondering why the negative index doesn't work? 
> Am I doing something wrong?
>
> nm2<-nm[c(1:12,14:34),]
> plot(nm2)
> str(nm2,2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
> ..@ data       :'data.frame':	33 obs. of  9 variables:
> ..@ polygons   :List of 33
> ..@ plotOrder  : int [1:33] 22 23 28 2 25 3 9 12 24 14 ...
> ..@ bbox       : num [1:2, 1:2] -109.1 31.3 -103 37
> .. ..- attr(*, "dimnames")=List of 2
> ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>
>
>
> Thanks,
>
> Chris Stubben
>
>
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From julien.farlin at tudor.lu  Thu Oct 22 13:55:50 2009
From: julien.farlin at tudor.lu (julien.farlin at tudor.lu)
Date: Thu, 22 Oct 2009 13:55:50 +0200
Subject: [R-sig-Geo] kriging discontinuities
Message-ID: <OF1EAAB6FD.43E8E0DF-ONC1257657.003A4D83-C1257657.0041862F@tudor.lu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091022/87530bfb/attachment.pl>

From jaime.garcia at uni-bonn.de  Fri Oct 23 11:03:01 2009
From: jaime.garcia at uni-bonn.de (Jaime R. Garcia Marquez)
Date: Fri, 23 Oct 2009 11:03:01 +0200
Subject: [R-sig-Geo] Overwrite flag in writeRAST6 is not working...
Message-ID: <op.u18wrbgq5hcodf@jaimer>

Dear list,

I am running R within a GRASS session. I am trying to convert a  
SpatialGridDataFrame to a raster GRASS format using the writeRAST6  
function. Because the script is inside a for loop I am using the overwrite  
flag to create always a temporal Grass raster file, but it does not work.   
Here is the code:


> class(f)
[1] "SpatialGridDataFrame"
attr(,"package")
[1] "sp"

I would like to create a Grass raster file "temp" which is already there  
 from the first run of the loop

> system("g.list rast")
----------------------------------------------
raster files available in mapset jaime:
glc200_all glc_mode   r_grid     rich_amp   rich_bat   rich_svm   rsr_amp
rsr_bat    rsr_veg    soil_all   soil_mode  temp       wwf_ecos   wwf_mode


----------------------------------------------

> writeRAST6(x=f, vname="temp", zcol=colum[i],flags="overwrite")
Error: option <output>: <temp> exists.
Warning message:
In is.na(pt[, "keydesc_count"]) :
   is.na() applied to non-(list or vector) of type 'NULL'


> writeRAST6(x=f, vname="temp", zcol=colum[i],flags="o")
Error: option <output>: <temp> exists.
Warning message:
In is.na(pt[, "keydesc_count"]) :
   is.na() applied to non-(list or vector) of type 'NULL'


> writeRAST6(x=f, vname="temp", zcol=colum[i], overwrite=TRUE)
Error: option <output>: <temp> exists.
Warning message:
In is.na(pt[, "keydesc_count"]) :
   is.na() applied to non-(list or vector) of type 'NULL'

What I can do is to write at the beginning of the for loop a line to  
delete the file "temp" (system(g.remove rast=temp)) but the overwrite  
possibility is more elegant....

I'd appreciate any help.

Jaime

I am using GRASS 6.2.3

> sessionInfo()
R version 2.9.2 (2009-08-24)
x86_64-pc-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] RColorBrewer_1.0-2 spdep_0.4-36       Matrix_0.999375-30  
lattice_0.17-26
  [5] spam_0.15-4        boot_1.2-40        tripack_1.3-3      ncf_1.1-3
  [9] spgrass6_0.6-8     XML_2.6-0          classInt_0.1-11     
maptools_0.7-25
[13] foreign_0.8-38     e1071_1.5-19       class_7.2-48       rgdal_0.6-17
[17] sp_0.9-43

loaded via a namespace (and not attached):
[1] grid_2.9.2  tools_2.9.2


From Roger.Bivand at nhh.no  Fri Oct 23 15:24:21 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Oct 2009 15:24:21 +0200 (CEST)
Subject: [R-sig-Geo] Overwrite flag in writeRAST6 is not working...
In-Reply-To: <op.u18wrbgq5hcodf@jaimer>
References: <op.u18wrbgq5hcodf@jaimer>
Message-ID: <alpine.LRH.2.00.0910231519080.31851@reclus.nhh.no>

On Fri, 23 Oct 2009, Jaime R. Garcia Marquez wrote:

> Dear list,
>
> I am running R within a GRASS session. I am trying to convert a 
> SpatialGridDataFrame to a raster GRASS format using the writeRAST6 function. 
> Because the script is inside a for loop I am using the overwrite flag to 
> create always a temporal Grass raster file, but it does not work.  Here is 
> the code:

Does not work for you with which version of GRASS, R, spgrass6, XML?

In spearfish:

library(spgrass6)
f <- readRAST6("elevation.dem", useGDAL=TRUE, plugin=FALSE)
writeRAST6(x=f, vname="temp", zcol=1, flags="overwrite")
writeRAST6(x=f, vname="temp", zcol=1, flags="overwrite")
writeRAST6(x=f, vname="temp", zcol=1, flags="overwrite")
writeRAST6(x=f, vname="temp", zcol=1, overwrite=TRUE)
writeRAST6(x=f, vname="temp", zcol=1, overwrite=TRUE)

all work, but

writeRAST6(x=f, vname="temp", zcol=1, flags="o")

doesn't, because the -o flag means something different (override 
projection),

for me with:

> execGRASS("g.version")
GRASS 6.4.0RC5 (2009)
> sessionInfo()
R version 2.9.2 (2009-08-24)
x86_64-unknown-linux-gnu

locale:
LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] spgrass6_0.6-9 XML_2.6-0      rgdal_0.6-19   sp_0.9-45

loaded via a namespace (and not attached):
[1] grid_2.9.2      lattice_0.17-26

Roger

>
>
>> class(f)
> [1] "SpatialGridDataFrame"
> attr(,"package")
> [1] "sp"
>
> I would like to create a Grass raster file "temp" which is already there from 
> the first run of the loop
>
>> system("g.list rast")
> ----------------------------------------------
> raster files available in mapset jaime:
> glc200_all glc_mode   r_grid     rich_amp   rich_bat   rich_svm   rsr_amp
> rsr_bat    rsr_veg    soil_all   soil_mode  temp       wwf_ecos   wwf_mode
>
>
> ----------------------------------------------
>
>> writeRAST6(x=f, vname="temp", zcol=colum[i],flags="overwrite")
> Error: option <output>: <temp> exists.
> Warning message:
> In is.na(pt[, "keydesc_count"]) :
> is.na() applied to non-(list or vector) of type 'NULL'
>
>
>> writeRAST6(x=f, vname="temp", zcol=colum[i],flags="o")
> Error: option <output>: <temp> exists.
> Warning message:
> In is.na(pt[, "keydesc_count"]) :
> is.na() applied to non-(list or vector) of type 'NULL'
>
>
>> writeRAST6(x=f, vname="temp", zcol=colum[i], overwrite=TRUE)
> Error: option <output>: <temp> exists.
> Warning message:
> In is.na(pt[, "keydesc_count"]) :
> is.na() applied to non-(list or vector) of type 'NULL'
>
> What I can do is to write at the beginning of the for loop a line to delete 
> the file "temp" (system(g.remove rast=temp)) but the overwrite possibility is 
> more elegant....
>
> I'd appreciate any help.
>
> Jaime
>
> I am using GRASS 6.2.3
>
>> sessionInfo()
> R version 2.9.2 (2009-08-24)
> x86_64-pc-linux-gnu
>
> locale:
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_US.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=C;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_US.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_US.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] RColorBrewer_1.0-2 spdep_0.4-36       Matrix_0.999375-30 lattice_0.17-26
> [5] spam_0.15-4        boot_1.2-40        tripack_1.3-3      ncf_1.1-3
> [9] spgrass6_0.6-8     XML_2.6-0          classInt_0.1-11    maptools_0.7-25
> [13] foreign_0.8-38     e1071_1.5-19       class_7.2-48       rgdal_0.6-17
> [17] sp_0.9-43
>
> loaded via a namespace (and not attached):
> [1] grid_2.9.2  tools_2.9.2
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From joe2yuzo at gmail.com  Fri Oct 23 17:15:36 2009
From: joe2yuzo at gmail.com (Joe Abrams)
Date: Fri, 23 Oct 2009 11:15:36 -0400
Subject: [R-sig-Geo] Space-time cluster analysis
Message-ID: <a03570f40910230815u34c7b644gf17b9a34a70a3d18@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091023/b33321bb/attachment.pl>

From mtb954 at gmail.com  Fri Oct 23 21:00:29 2009
From: mtb954 at gmail.com (Mark Na)
Date: Fri, 23 Oct 2009 13:00:29 -0600
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
Message-ID: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091023/c09b884c/attachment.pl>

From dan.putler at sauder.ubc.ca  Fri Oct 23 21:11:14 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Fri, 23 Oct 2009 12:11:14 -0700
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <1714_1256324483_1256324483_e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
References: <1714_1256324483_1256324483_e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
Message-ID: <1256325074.7016.88.camel@whitebox>

Hi Mark,

The natural way to do something like this in R is using the RGDAL
package to take advantage of the OGR library. At this time OGR has the
ability to read .mdb personal geodatabase files, but not write them, and
since R's functionality in this area is dependent on what the GDAL/OGR
library can do, I don't think you can avoid the third step in your
workflow. You could have R write out shapefile sets, which might be an
improvement over your current workflow.

Dan

On Fri, 2009-10-23 at 13:00 -0600, Mark Na wrote:
> Hello,
> I would like to write spatial data to an ESRI personal geodatabase (.mdb)
> and I wonder if anyone has experience with this.
> 
> My workflow, at present, is as follows:
> 
> 1. Read spatial data into R (from a .csv file).
> 
> 2. Manipulate the data in various ways.
> 
> 3. Export the data from R as a .csv file, import that into ArcGIS, add XY,
> save the data as a table in an existing personal geodatabase (.mdb).
> 
> I would like to automate step 3 by creating the .mdb in R and saving various
> dataframes as tables within the .mdb, so nothing has to be done in ArcGIS.
> 
> I would appreciate any help you might be able to provide with this.
> 
> Many thanks, Mark
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From csfowler at u.washington.edu  Fri Oct 23 21:17:59 2009
From: csfowler at u.washington.edu (Chris Fowler)
Date: Fri, 23 Oct 2009 12:17:59 -0700
Subject: [R-sig-Geo] basic polyfon shapefile subsetting
Message-ID: <4AE20167.3010109@u.washington.edu>

I swore I would figure this out without going to the list, but I just 
don't understand the data structure well enough to make this work. Easy 
pickings for many of you on this list.

I have an ArcGIS shapefile "base.shp" that has 23034 polygons (U.S. 
census tracts). I want to end up with a subset of this file that has no 
'islands' and a neighbor list to accompany it. What am I doing wrong?

baseShp<-readShapePoly("Export_Output.shp")	#read in a shapefile
Q1B<-poly2nb(baseShp, row.names = baseShp$FIPS)	#1st order Queen
summary(Q1B)	#731 with 0 neighbors we need to remove these
x<-card(Q1B)	#create a vector with the number of neighbors
baseShp$numNeighbors<-x	#assign that vector as an additional data column
length(baseShp$numNeighbors)	#check to make sure all 23034 have value
summary(baseShp$numNeighbors)	#...and that those values are what I 		
				#expect
submap <- baseShp[baseShp$attr.data$numNeighbors >=1] #pull out those
				# with at least 1 neighbor
plot(submap)		#something plots....
length(submap$numNeighbors)  #0, no data transferred
subm<-as.data.frame(submap)  # convert to data frame for easier looking
str(subm)  #we still have 23034 observations and now we have no data


So, why doesn't my subseting code bring data with it and why doesn't it 
actually do the subsetting?

Thanks in advance,

Chris


From Roger.Bivand at nhh.no  Fri Oct 23 21:24:09 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Oct 2009 21:24:09 +0200 (CEST)
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>

On Fri, 23 Oct 2009, Mark Na wrote:

> Hello,
> I would like to write spatial data to an ESRI personal geodatabase (.mdb)
> and I wonder if anyone has experience with this.
>
> My workflow, at present, is as follows:
>
> 1. Read spatial data into R (from a .csv file).
>
> 2. Manipulate the data in various ways.
>
> 3. Export the data from R as a .csv file, import that into ArcGIS, add XY,
> save the data as a table in an existing personal geodatabase (.mdb).
>
> I would like to automate step 3 by creating the .mdb in R and saving various
> dataframes as tables within the .mdb, so nothing has to be done in ArcGIS.
>
> I would appreciate any help you might be able to provide with this.

This format is not available to others than ArcGIS license holders, who 
also run on Windows and have an Access license (it is an undocumented, 
custom Access database file). If you want to rebuild rgdal from source 
yourself with the Pgeo driver, or ensure that an Access DLL is visible to 
the driver, feel free to do so - hints are included in the README.windows 
file installed with rgdal. Since the Pgeo driver is read only, this only 
gets you so far. The format is closed (and very muddled, as browsing such 
a file will show), and best avoided in its entirety. Simply saving a few 
hundred point coordinates may run you up to hundreds of Kb.

Roger

>
> Many thanks, Mark
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Fri Oct 23 21:28:52 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Oct 2009 21:28:52 +0200 (CEST)
Subject: [R-sig-Geo] basic polyfon shapefile subsetting
In-Reply-To: <4AE20167.3010109@u.washington.edu>
References: <4AE20167.3010109@u.washington.edu>
Message-ID: <alpine.LRH.2.00.0910232125090.31851@reclus.nhh.no>

On Fri, 23 Oct 2009, Chris Fowler wrote:

> I swore I would figure this out without going to the list, but I just don't 
> understand the data structure well enough to make this work. Easy pickings 
> for many of you on this list.
>
> I have an ArcGIS shapefile "base.shp" that has 23034 polygons (U.S. census 
> tracts). I want to end up with a subset of this file that has no 'islands' 
> and a neighbor list to accompany it. What am I doing wrong?
>
> baseShp<-readShapePoly("Export_Output.shp")	#read in a shapefile
> Q1B<-poly2nb(baseShp, row.names = baseShp$FIPS)	#1st order Queen
> summary(Q1B)	#731 with 0 neighbors we need to remove these
> x<-card(Q1B)	#create a vector with the number of neighbors
> baseShp$numNeighbors<-x	#assign that vector as an additional data column
> length(baseShp$numNeighbors)	#check to make sure all 23034 have value
> summary(baseShp$numNeighbors)	#...and that those values are what I
> 				#expect
> submap <- baseShp[baseShp$attr.data$numNeighbors >=1] #pull out those
> 				# with at least 1 neighbor

Use

baseShp[baseShp$numNeighbors >=1, ]

There are two mistakes, one the missing comma, the other the use of a 
non-existing column, which will result in baseShp[NULL >=1] being 
evaluated.

Roger

> plot(submap)		#something plots....
> length(submap$numNeighbors)  #0, no data transferred
> subm<-as.data.frame(submap)  # convert to data frame for easier looking
> str(subm)  #we still have 23034 observations and now we have no data
>
>
> So, why doesn't my subseting code bring data with it and why doesn't it 
> actually do the subsetting?
>
> Thanks in advance,
>
> Chris
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mtb954 at gmail.com  Fri Oct 23 21:29:31 2009
From: mtb954 at gmail.com (Mark Na)
Date: Fri, 23 Oct 2009 13:29:31 -0600
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
Message-ID: <e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091023/fd94a9c5/attachment.pl>

From Roger.Bivand at nhh.no  Fri Oct 23 21:47:09 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Oct 2009 21:47:09 +0200 (CEST)
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>

On Fri, 23 Oct 2009, Mark Na wrote:

> Hi Dan & Roger,
> Thanks for your comments. What do you know about ESRI's new "file
> geodatabase" file structure -- is it any more open (or integrable with R)
> than the personal geodatabase?

The last slide on:

http://gis.esri.com/library/userconf/pug07/papers/workshops/file-gdb.pdf

says that it is using an open API with GDAL, ODBC, but no details. I guess 
someone with access to ArcGIS would need to create various things in the 
file folder and see what they are. I'm afraid that they are not intended 
for inter-operation.

Roger

>
> Mark
>
>
>
> On Fri, Oct 23, 2009 at 1:24 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Fri, 23 Oct 2009, Mark Na wrote:
>>
>>  Hello,
>>> I would like to write spatial data to an ESRI personal geodatabase (.mdb)
>>> and I wonder if anyone has experience with this.
>>>
>>> My workflow, at present, is as follows:
>>>
>>> 1. Read spatial data into R (from a .csv file).
>>>
>>> 2. Manipulate the data in various ways.
>>>
>>> 3. Export the data from R as a .csv file, import that into ArcGIS, add XY,
>>> save the data as a table in an existing personal geodatabase (.mdb).
>>>
>>> I would like to automate step 3 by creating the .mdb in R and saving
>>> various
>>> dataframes as tables within the .mdb, so nothing has to be done in ArcGIS.
>>>
>>> I would appreciate any help you might be able to provide with this.
>>>
>>
>> This format is not available to others than ArcGIS license holders, who
>> also run on Windows and have an Access license (it is an undocumented,
>> custom Access database file). If you want to rebuild rgdal from source
>> yourself with the Pgeo driver, or ensure that an Access DLL is visible to
>> the driver, feel free to do so - hints are included in the README.windows
>> file installed with rgdal. Since the Pgeo driver is read only, this only
>> gets you so far. The format is closed (and very muddled, as browsing such a
>> file will show), and best avoided in its entirety. Simply saving a few
>> hundred point coordinates may run you up to hundreds of Kb.
>>
>> Roger
>>
>>
>>
>>> Many thanks, Mark
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From dan.putler at sauder.ubc.ca  Fri Oct 23 21:56:13 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Fri, 23 Oct 2009 12:56:13 -0700
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
Message-ID: <1256327773.7016.92.camel@whitebox>

Hi Roger,

A bit off-topic, but what do you think will be the real replacement for
the shapefile as the de facto standard vector file format? SpatialLite?

Dan

On Fri, 2009-10-23 at 21:47 +0200, Roger Bivand wrote:
> On Fri, 23 Oct 2009, Mark Na wrote:
> 
> > Hi Dan & Roger,
> > Thanks for your comments. What do you know about ESRI's new "file
> > geodatabase" file structure -- is it any more open (or integrable with R)
> > than the personal geodatabase?
> 
> The last slide on:
> 
> http://gis.esri.com/library/userconf/pug07/papers/workshops/file-gdb.pdf
> 
> says that it is using an open API with GDAL, ODBC, but no details. I guess 
> someone with access to ArcGIS would need to create various things in the 
> file folder and see what they are. I'm afraid that they are not intended 
> for inter-operation.
> 
> Roger
> 
> >
> > Mark
> >
> >
> >
> > On Fri, Oct 23, 2009 at 1:24 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> >
> >> On Fri, 23 Oct 2009, Mark Na wrote:
> >>
> >>  Hello,
> >>> I would like to write spatial data to an ESRI personal geodatabase (.mdb)
> >>> and I wonder if anyone has experience with this.
> >>>
> >>> My workflow, at present, is as follows:
> >>>
> >>> 1. Read spatial data into R (from a .csv file).
> >>>
> >>> 2. Manipulate the data in various ways.
> >>>
> >>> 3. Export the data from R as a .csv file, import that into ArcGIS, add XY,
> >>> save the data as a table in an existing personal geodatabase (.mdb).
> >>>
> >>> I would like to automate step 3 by creating the .mdb in R and saving
> >>> various
> >>> dataframes as tables within the .mdb, so nothing has to be done in ArcGIS.
> >>>
> >>> I would appreciate any help you might be able to provide with this.
> >>>
> >>
> >> This format is not available to others than ArcGIS license holders, who
> >> also run on Windows and have an Access license (it is an undocumented,
> >> custom Access database file). If you want to rebuild rgdal from source
> >> yourself with the Pgeo driver, or ensure that an Access DLL is visible to
> >> the driver, feel free to do so - hints are included in the README.windows
> >> file installed with rgdal. Since the Pgeo driver is read only, this only
> >> gets you so far. The format is closed (and very muddled, as browsing such a
> >> file will show), and best avoided in its entirety. Simply saving a few
> >> hundred point coordinates may run you up to hundreds of Kb.
> >>
> >> Roger
> >>
> >>
> >>
> >>> Many thanks, Mark
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at stat.math.ethz.ch
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>>
> >> --
> >> Roger Bivand
> >> Economic Geography Section, Department of Economics, Norwegian School of
> >> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> >> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> >> e-mail: Roger.Bivand at nhh.no
> >>
> >>
> >
> >
> >
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From Roger.Bivand at nhh.no  Fri Oct 23 22:05:21 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Oct 2009 22:05:21 +0200 (CEST)
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <1256327773.7016.92.camel@whitebox>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
	<1256327773.7016.92.camel@whitebox>
Message-ID: <alpine.LRH.2.00.0910232203260.31851@reclus.nhh.no>

On Fri, 23 Oct 2009, Dan Putler wrote:

> Hi Roger,
>
> A bit off-topic, but what do you think will be the real replacement for
> the shapefile as the de facto standard vector file format? SpatialLite?

Perhaps unfortunately, shapefiles will be around for a long time. The only 
alternatives in volume are probably KML, but are restricted in many ways. 
We'll have to wait and see, I guess.

Roger

>
> Dan
>
> On Fri, 2009-10-23 at 21:47 +0200, Roger Bivand wrote:
>> On Fri, 23 Oct 2009, Mark Na wrote:
>>
>>> Hi Dan & Roger,
>>> Thanks for your comments. What do you know about ESRI's new "file
>>> geodatabase" file structure -- is it any more open (or integrable with R)
>>> than the personal geodatabase?
>>
>> The last slide on:
>>
>> http://gis.esri.com/library/userconf/pug07/papers/workshops/file-gdb.pdf
>>
>> says that it is using an open API with GDAL, ODBC, but no details. I guess
>> someone with access to ArcGIS would need to create various things in the
>> file folder and see what they are. I'm afraid that they are not intended
>> for inter-operation.
>>
>> Roger
>>
>>>
>>> Mark
>>>
>>>
>>>
>>> On Fri, Oct 23, 2009 at 1:24 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>
>>>> On Fri, 23 Oct 2009, Mark Na wrote:
>>>>
>>>>  Hello,
>>>>> I would like to write spatial data to an ESRI personal geodatabase (.mdb)
>>>>> and I wonder if anyone has experience with this.
>>>>>
>>>>> My workflow, at present, is as follows:
>>>>>
>>>>> 1. Read spatial data into R (from a .csv file).
>>>>>
>>>>> 2. Manipulate the data in various ways.
>>>>>
>>>>> 3. Export the data from R as a .csv file, import that into ArcGIS, add XY,
>>>>> save the data as a table in an existing personal geodatabase (.mdb).
>>>>>
>>>>> I would like to automate step 3 by creating the .mdb in R and saving
>>>>> various
>>>>> dataframes as tables within the .mdb, so nothing has to be done in ArcGIS.
>>>>>
>>>>> I would appreciate any help you might be able to provide with this.
>>>>>
>>>>
>>>> This format is not available to others than ArcGIS license holders, who
>>>> also run on Windows and have an Access license (it is an undocumented,
>>>> custom Access database file). If you want to rebuild rgdal from source
>>>> yourself with the Pgeo driver, or ensure that an Access DLL is visible to
>>>> the driver, feel free to do so - hints are included in the README.windows
>>>> file installed with rgdal. Since the Pgeo driver is read only, this only
>>>> gets you so far. The format is closed (and very muddled, as browsing such a
>>>> file will show), and best avoided in its entirety. Simply saving a few
>>>> hundred point coordinates may run you up to hundreds of Kb.
>>>>
>>>> Roger
>>>>
>>>>
>>>>
>>>>> Many thanks, Mark
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>> --
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>
>>>
>>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Fri Oct 23 22:09:17 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 23 Oct 2009 21:09:17 +0100
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <1256327773.7016.92.camel@whitebox>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
	<1256327773.7016.92.camel@whitebox>
Message-ID: <d8ad40b50910231309j3acf926fwd253e0593521c7ec@mail.gmail.com>

On Fri, Oct 23, 2009 at 8:56 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> Hi Roger,
>
> A bit off-topic, but what do you think will be the real replacement for
> the shapefile as the de facto standard vector file format? SpatialLite?
>

 Some thoughts on that here:

http://moreati.org.uk/blog/2009/03/01/shapefile-20-manifesto/
http://www.spatialdbadvisor.com/blog/121/the-shapefile-manifesto/

SpatialLite is very nice looking - I might start working with it as my
default file-based GIS data storage. For database storage I'm using
PostGIS.

Barry


From hakim.abdi at uni-muenster.de  Sat Oct 24 19:59:31 2009
From: hakim.abdi at uni-muenster.de (Hakim Abdi)
Date: Sat, 24 Oct 2009 19:59:31 +0200
Subject: [R-sig-Geo] inquiry on suitable packages
In-Reply-To: <mailman.13.1256378403.26717.r-sig-geo@stat.math.ethz.ch>
References: <mailman.13.1256378403.26717.r-sig-geo@stat.math.ethz.ch>
Message-ID: <4AE34083.6050309@uni-muenster.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091024/5ee9d656/attachment.pl>

From dan.putler at sauder.ubc.ca  Sat Oct 24 21:36:41 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Sat, 24 Oct 2009 12:36:41 -0700
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <4AE2C8D6.4050101@uni-muenster.de>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
	<1256327773.7016.92.camel@whitebox>
	<d8ad40b50910231309j3acf926fwd253e0593521c7ec@mail.gmail.com>
	<4AE2C8D6.4050101@uni-muenster.de>
Message-ID: <1256413001.12454.53.camel@whitebox>

Hi Edzer,

I've sent an email on this topic to the gdal-dev mailing list. I would
argue that the "standard" build of GDAL/OGR on Windows is what Frank W.
releases in FWTools, so I asked about whether the two drivers are
included in the current Windows FWTools build of the GDAL/OGR library.
My guess is that the active people on this thread are also on the
gdal-dev list, but I'll still provide a summary to what I here back to
this list.

Dan

On Sat, 2009-10-24 at 11:28 +0200, Edzer Pebesma wrote:
> I tend to also favour those two -- postgis for the data base,
> spatialLite for the file-based exchange -- as the way forward. Do
> "standard" gdal/ogr installations on windows (whatever that means) come
> with support for sqlite and postgis, so that ogr2ogr takes you from one
> to another?
> --
> Edzer
> 
> Barry Rowlingson wrote:
> > On Fri, Oct 23, 2009 at 8:56 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> >   
> >> Hi Roger,
> >>
> >> A bit off-topic, but what do you think will be the real replacement for
> >> the shapefile as the de facto standard vector file format? SpatialLite?
> >>
> >>     
> >
> >  Some thoughts on that here:
> >
> > http://moreati.org.uk/blog/2009/03/01/shapefile-20-manifesto/
> > http://www.spatialdbadvisor.com/blog/121/the-shapefile-manifesto/
> >
> > SpatialLite is very nice looking - I might start working with it as my
> > default file-based GIS data storage. For database storage I'm using
> > PostGIS.
> >
> > Barry
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >   
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From Roger.Bivand at nhh.no  Sat Oct 24 23:52:48 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 24 Oct 2009 23:52:48 +0200 (CEST)
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <1256413001.12454.53.camel@whitebox>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
	<1256327773.7016.92.camel@whitebox>
	<d8ad40b50910231309j3acf926fwd253e0593521c7ec@mail.gmail.com>
	<4AE2C8D6.4050101@uni-muenster.de>
	<1256413001.12454.53.camel@whitebox>
Message-ID: <alpine.LRH.2.00.0910242342420.10009@reclus.nhh.no>

On Sat, 24 Oct 2009, Dan Putler wrote:

> Hi Edzer,
>
> I've sent an email on this topic to the gdal-dev mailing list. I would
> argue that the "standard" build of GDAL/OGR on Windows is what Frank W.
> releases in FWTools, so I asked about whether the two drivers are
> included in the current Windows FWTools build of the GDAL/OGR library.

No, the OSGEO4W build is what is intended to be provided. While 
spatialLite involves very limited external dependencies, PostGIS involves 
very extensive dependencies and versioning challenges, and running a 
PostgreSQL server is not anything working researchers want or need to do, 
in my experience. It may be that users should be encouraged to learn SQL 
and database administration, but I don't think that this is considered a 
key priority.

Building rgdal for Windows automatically is hard, and users owe a big debt 
of gratitude to Uwe Ligges for the extensive help he offers. As built, 
rgdal on Windows will work for the read-only Pgeo driver if the user has 
an Access license and appropriate DLL. The package does include detailed 
instructions for those who need to use other drivers, both via FWTools and 
OSGEO4W. This is very extensive web of dependencies is not, however, 
anything that most users need to be confronted with. "Dependency Hell" is 
so-called for good reason, hard to install, hard to manage and maintain, 
and certainly not portable.

> My guess is that the active people on this thread are also on the
> gdal-dev list, but I'll still provide a summary to what I here back to
> this list.

You may find that the overlap is rather limited ...

Roger

>
> Dan
>
> On Sat, 2009-10-24 at 11:28 +0200, Edzer Pebesma wrote:
>> I tend to also favour those two -- postgis for the data base,
>> spatialLite for the file-based exchange -- as the way forward. Do
>> "standard" gdal/ogr installations on windows (whatever that means) come
>> with support for sqlite and postgis, so that ogr2ogr takes you from one
>> to another?
>> --
>> Edzer
>>
>> Barry Rowlingson wrote:
>>> On Fri, Oct 23, 2009 at 8:56 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
>>>
>>>> Hi Roger,
>>>>
>>>> A bit off-topic, but what do you think will be the real replacement for
>>>> the shapefile as the de facto standard vector file format? SpatialLite?
>>>>
>>>>
>>>
>>>  Some thoughts on that here:
>>>
>>> http://moreati.org.uk/blog/2009/03/01/shapefile-20-manifesto/
>>> http://www.spatialdbadvisor.com/blog/121/the-shapefile-manifesto/
>>>
>>> SpatialLite is very nice looking - I might start working with it as my
>>> default file-based GIS data storage. For database storage I'm using
>>> PostGIS.
>>>
>>> Barry
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From dan.putler at sauder.ubc.ca  Sun Oct 25 00:34:49 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Sat, 24 Oct 2009 15:34:49 -0700
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <alpine.LRH.2.00.0910242342420.10009@reclus.nhh.no>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
	<1256327773.7016.92.camel@whitebox>
	<d8ad40b50910231309j3acf926fwd253e0593521c7ec@mail.gmail.com>
	<4AE2C8D6.4050101@uni-muenster.de> <1256413001.12454.53.camel@whitebox>
	<alpine.LRH.2.00.0910242342420.10009@reclus.nhh.no>
Message-ID: <1256423689.17045.13.camel@whitebox>

The response I got from the gdal-dev list is that starting in GDAL/OGR
1.6.0 there is a read-only driver or SpatiaLite files, and that there is
currently a working read and write driver for SpatiaLite in the GDAL/OGR
1.7.0 SVN. OSGEO4W currently has the default install GDAL/OGR 1.5.4, but
GDAL/OGR 1.6.0 as an advanced install option. Eventually the SpatialLite
read/write capability for GDAL/OGR will make it to OSGEO4W, so it is
something of a moot point now.

Dan

On Sat, 2009-10-24 at 23:52 +0200, Roger Bivand wrote:
> On Sat, 24 Oct 2009, Dan Putler wrote:
> 
> > Hi Edzer,
> >
> > I've sent an email on this topic to the gdal-dev mailing list. I would
> > argue that the "standard" build of GDAL/OGR on Windows is what Frank W.
> > releases in FWTools, so I asked about whether the two drivers are
> > included in the current Windows FWTools build of the GDAL/OGR library.
> 
> No, the OSGEO4W build is what is intended to be provided. While 
> spatialLite involves very limited external dependencies, PostGIS involves 
> very extensive dependencies and versioning challenges, and running a 
> PostgreSQL server is not anything working researchers want or need to do, 
> in my experience. It may be that users should be encouraged to learn SQL 
> and database administration, but I don't think that this is considered a 
> key priority.
> 
> Building rgdal for Windows automatically is hard, and users owe a big debt 
> of gratitude to Uwe Ligges for the extensive help he offers. As built, 
> rgdal on Windows will work for the read-only Pgeo driver if the user has 
> an Access license and appropriate DLL. The package does include detailed 
> instructions for those who need to use other drivers, both via FWTools and 
> OSGEO4W. This is very extensive web of dependencies is not, however, 
> anything that most users need to be confronted with. "Dependency Hell" is 
> so-called for good reason, hard to install, hard to manage and maintain, 
> and certainly not portable.
> 
> > My guess is that the active people on this thread are also on the
> > gdal-dev list, but I'll still provide a summary to what I here back to
> > this list.
> 
> You may find that the overlap is rather limited ...
> 
> Roger
> 
> >
> > Dan
> >
> > On Sat, 2009-10-24 at 11:28 +0200, Edzer Pebesma wrote:
> >> I tend to also favour those two -- postgis for the data base,
> >> spatialLite for the file-based exchange -- as the way forward. Do
> >> "standard" gdal/ogr installations on windows (whatever that means) come
> >> with support for sqlite and postgis, so that ogr2ogr takes you from one
> >> to another?
> >> --
> >> Edzer
> >>
> >> Barry Rowlingson wrote:
> >>> On Fri, Oct 23, 2009 at 8:56 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> >>>
> >>>> Hi Roger,
> >>>>
> >>>> A bit off-topic, but what do you think will be the real replacement for
> >>>> the shapefile as the de facto standard vector file format? SpatialLite?
> >>>>
> >>>>
> >>>
> >>>  Some thoughts on that here:
> >>>
> >>> http://moreati.org.uk/blog/2009/03/01/shapefile-20-manifesto/
> >>> http://www.spatialdbadvisor.com/blog/121/the-shapefile-manifesto/
> >>>
> >>> SpatialLite is very nice looking - I might start working with it as my
> >>> default file-based GIS data storage. For database storage I'm using
> >>> PostGIS.
> >>>
> >>> Barry
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at stat.math.ethz.ch
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>
> >
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From matzke at berkeley.edu  Sun Oct 25 02:45:29 2009
From: matzke at berkeley.edu (Nick Matzke)
Date: Sat, 24 Oct 2009 18:45:29 -0700
Subject: [R-sig-Geo] 3D variogram model
Message-ID: <4AE3ADB9.2030105@berkeley.edu>


Hi all,

I am trying to figure out if I can get 3-D kriging to work in the R 
gstat package.  The demo given here:

# =================================================
# Edzer J. Pebesma, Richard N.M. Duin (2005) Spatio-temporal mapping of
# sea floor sediment pollution in the North Sea.  In: Ph. Renard, and
# R. Froidevaux, eds. Proceedings GeoENV 2004 -- Fifth European Conference
# on Geostatistics for Environmental Applications; Springer.
#

# Run the demo:
demo(pcb)
#==================================================



...doesn't really do full 3D kriging as far as I can tell, it just 
models the cross-variograms between data from different years.  I would 
eventually like to do a kriging prediction map for e.g. any one of, say, 
100 or 1000 different years, so I don't think the cross-kriging approach 
will work.

Anyway, for now, I am just seeing if I can get a simple 3D kriging to 
work with the pcb dataset.  In an attempt to make it work, I rescaled 
the "year" data to the approximate dimensions of the x and y data, and 
then I added 1% variability in all the locations to see if that would 
avoid the singularity problem, which I gather (?) can be caused by 
points too close together.

But still, no luck.  I basically just want to fit a variogram model 
which captures the variability in space (xy) and time (rescaled_year).

Here's what I've got, below, any comments/help VERY appreciated.

(PS: Does anyone have a bit of code that will calculate an empirical 
variogram in the third dimension?  The gstat variogram() function 
evidently won't do it, even when beta=90 is specified.

Thanks!
Nick

====================
data(pcb)

# rescale year to similar units as space
(horiz_range = max(pcb$x) - min(pcb$x))
(vert_range = max(pcb$year) - min(pcb$year))
(range_ratio = horiz_range / vert_range)
pcb$rescaled_year = (pcb$year -  min(pcb$year)) * range_ratio

# add a little noise to the data locations in case there are overlapping 
points
pcb$x = as.double(pcb$x + runif(length(pcb$x), -0.01*horiz_range, 
0.01*horiz_range))
pcb$y = as.double(pcb$y + runif(length(pcb$y), -0.01*horiz_range, 
0.01*horiz_range))
pcb$rescaled_year = as.double(pcb$rescaled_year + 
runif(length(pcb$rescaled_year), -0.01*vert_range, 0.01*vert_range))

# do a 2D variogram for various years
v3gm = NULL
v4gm = NULL

# get residuals after factoring out depth
pcb$res=residuals(lm(log(PCB138)~rescaled_year+depth, pcb))


# Get a variogram of the residuals by location, after factoring out any 
year correlation
v3 = variogram(res ~ rescaled_year, ~x+y, pcb, dX=.1, 
bound=c(0,1000,3000,5000,(1:16)*10000))

v3gm = vgm(.224,"Sph",17247,.08)
print(plot(v3, model = v3gm, plot.numbers = TRUE))

(v3gm.f <- fit.variogram(v3, v3gm, fit.ranges=FALSE))
print(plot(v3, model = v3gm.f, plot.numbers = TRUE))

print.data.frame(v3gm)
print.data.frame(v3gm.f)


# do the 3D variogram
v4 = variogram(res ~ 1, ~x+y+rescaled_year, pcb, dX=.5)
print(plot(v4, model = vgm(.224,"Exp",17247,.08), plot.numbers = TRUE))


# 3-dimensional model with nugget component and sill component

#
v4gm = vgm(0.3, "Sph", 2000, anis=c(0, 90, 0, 1, 1), add.to=v3gm)

print.data.frame(v3gm)
print.data.frame(v4gm)

(v4gm.f <- fit.variogram(v4, v4gm, fit.sills=TRUE, fit.ranges=TRUE))
print.data.frame(v4gm.f)
print(plot(v4, model = v4gm.f, plot.numbers = TRUE))
====================



-- 
====================================================
Nicholas J. Matzke
Ph.D. Student, Graduate Student Researcher
Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264
Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
3060 VLSB #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. When people 
thought the earth was spherical, they were wrong. But if you think that 
thinking the earth is spherical is just as wrong as thinking the earth 
is flat, then your view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The Skeptical Inquirer, 
14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm


From Roger.Bivand at nhh.no  Sun Oct 25 12:14:42 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 25 Oct 2009 12:14:42 +0100 (CET)
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <1256423689.17045.13.camel@whitebox>
References: <e40d78ce0910231200yc869adag262e094de12d866@mail.gmail.com>
	<alpine.LRH.2.00.0910232116070.31851@reclus.nhh.no>
	<e40d78ce0910231229i4d9fc82m8639b1f25ed679b@mail.gmail.com>
	<10807_1256327279_1256327279_alpine.LRH.2.00.0910232142580.31851@reclus.nhh.no>
	<1256327773.7016.92.camel@whitebox>
	<d8ad40b50910231309j3acf926fwd253e0593521c7ec@mail.gmail.com>
	<4AE2C8D6.4050101@uni-muenster.de>
	<1256413001.12454.53.camel@whitebox>
	<alpine.LRH.2.00.0910242342420.10009@reclus.nhh.no>
	<1256423689.17045.13.camel@whitebox>
Message-ID: <alpine.LRH.2.00.0910251209080.17634@reclus.nhh.no>

On Sat, 24 Oct 2009, Dan Putler wrote:

> The response I got from the gdal-dev list is that starting in GDAL/OGR
> 1.6.0 there is a read-only driver or SpatiaLite files, and that there is
> currently a working read and write driver for SpatiaLite in the GDAL/OGR
> 1.7.0 SVN. OSGEO4W currently has the default install GDAL/OGR 1.5.4, but
> GDAL/OGR 1.6.0 as an advanced install option. Eventually the SpatialLite
> read/write capability for GDAL/OGR will make it to OSGEO4W, so it is
> something of a moot point now.

Dan,

I agree that something more robust than shapefiles would be an advance, 
but this possible alternative does depend on relatively many users having 
access to read and write functionality.

With regard to spatial objects and SQLite, had you considered giving the 
CRAN SQLiteMap package a trial run?

http://cran.r-project.org/package=SQLiteMap

It is using a different set of extensions from SpatiaLite, but has been 
available for some time and does run cross-platform for R users. I haven't 
used it myself, but it is self-contained (no dependencies other than those 
on CRAN).

Hope this helps,

Roger

>
> Dan
>
> On Sat, 2009-10-24 at 23:52 +0200, Roger Bivand wrote:
>> On Sat, 24 Oct 2009, Dan Putler wrote:
>>
>>> Hi Edzer,
>>>
>>> I've sent an email on this topic to the gdal-dev mailing list. I would
>>> argue that the "standard" build of GDAL/OGR on Windows is what Frank W.
>>> releases in FWTools, so I asked about whether the two drivers are
>>> included in the current Windows FWTools build of the GDAL/OGR library.
>>
>> No, the OSGEO4W build is what is intended to be provided. While
>> spatialLite involves very limited external dependencies, PostGIS involves
>> very extensive dependencies and versioning challenges, and running a
>> PostgreSQL server is not anything working researchers want or need to do,
>> in my experience. It may be that users should be encouraged to learn SQL
>> and database administration, but I don't think that this is considered a
>> key priority.
>>
>> Building rgdal for Windows automatically is hard, and users owe a big debt
>> of gratitude to Uwe Ligges for the extensive help he offers. As built,
>> rgdal on Windows will work for the read-only Pgeo driver if the user has
>> an Access license and appropriate DLL. The package does include detailed
>> instructions for those who need to use other drivers, both via FWTools and
>> OSGEO4W. This is very extensive web of dependencies is not, however,
>> anything that most users need to be confronted with. "Dependency Hell" is
>> so-called for good reason, hard to install, hard to manage and maintain,
>> and certainly not portable.
>>
>>> My guess is that the active people on this thread are also on the
>>> gdal-dev list, but I'll still provide a summary to what I here back to
>>> this list.
>>
>> You may find that the overlap is rather limited ...
>>
>> Roger
>>
>>>
>>> Dan
>>>
>>> On Sat, 2009-10-24 at 11:28 +0200, Edzer Pebesma wrote:
>>>> I tend to also favour those two -- postgis for the data base,
>>>> spatialLite for the file-based exchange -- as the way forward. Do
>>>> "standard" gdal/ogr installations on windows (whatever that means) come
>>>> with support for sqlite and postgis, so that ogr2ogr takes you from one
>>>> to another?
>>>> --
>>>> Edzer
>>>>
>>>> Barry Rowlingson wrote:
>>>>> On Fri, Oct 23, 2009 at 8:56 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
>>>>>
>>>>>> Hi Roger,
>>>>>>
>>>>>> A bit off-topic, but what do you think will be the real replacement for
>>>>>> the shapefile as the de facto standard vector file format? SpatialLite?
>>>>>>
>>>>>>
>>>>>
>>>>>  Some thoughts on that here:
>>>>>
>>>>> http://moreati.org.uk/blog/2009/03/01/shapefile-20-manifesto/
>>>>> http://www.spatialdbadvisor.com/blog/121/the-shapefile-manifesto/
>>>>>
>>>>> SpatialLite is very nice looking - I might start working with it as my
>>>>> default file-based GIS data storage. For database storage I'm using
>>>>> PostGIS.
>>>>>
>>>>> Barry
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Sun Oct 25 23:15:15 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 25 Oct 2009 23:15:15 +0100
Subject: [R-sig-Geo] 3D variogram model
In-Reply-To: <4AE3ADB9.2030105@berkeley.edu>
References: <4AE3ADB9.2030105@berkeley.edu>
Message-ID: <4AE4CDF3.50206@uni-muenster.de>

Nick, thanks for bringing this up! I uploaded a script and the (large)
resulting pdf to

http://ifgi.uni-muenster.de/~epebe_01/pcb/

I used it for a workshop about a year ago, just before geoenv 2008. It's
supposed to more or less do what you had in mind. The variography in
continuous space-time is hard to infer for this particular data set, I
think, and what I did below is rather quick and dirty, and builds upon
the earlier 2004 work which was already heavy on the side of
assumptions. I'll add this script to the demo section of the next gstat
R package.

A few more comments to your script are inline, below.

Nick Matzke wrote:
>
> Hi all,
>
> I am trying to figure out if I can get 3-D kriging to work in the R
> gstat package.  The demo given here:
>
> # =================================================
> # Edzer J. Pebesma, Richard N.M. Duin (2005) Spatio-temporal mapping of
> # sea floor sediment pollution in the North Sea.  In: Ph. Renard, and
> # R. Froidevaux, eds. Proceedings GeoENV 2004 -- Fifth European
> Conference
> # on Geostatistics for Environmental Applications; Springer.
> #
>
> # Run the demo:
> demo(pcb)
> #==================================================
>
>
>
> ...doesn't really do full 3D kriging as far as I can tell, it just
> models the cross-variograms between data from different years.  I
> would eventually like to do a kriging prediction map for e.g. any one
> of, say, 100 or 1000 different years, so I don't think the
> cross-kriging approach will work.
>
> Anyway, for now, I am just seeing if I can get a simple 3D kriging to
> work with the pcb dataset.  In an attempt to make it work, I rescaled
> the "year" data to the approximate dimensions of the x and y data, and
> then I added 1% variability in all the locations to see if that would
> avoid the singularity problem, which I gather (?) can be caused by
> points too close together.
>
> But still, no luck.  I basically just want to fit a variogram model
> which captures the variability in space (xy) and time (rescaled_year).
>
> Here's what I've got, below, any comments/help VERY appreciated.
>
> (PS: Does anyone have a bit of code that will calculate an empirical
> variogram in the third dimension?  The gstat variogram() function
> evidently won't do it, even when beta=90 is specified.
after your:
data(pcb)

# rescale year to similar units as space
(horiz_range = max(pcb$x) - min(pcb$x))
(vert_range = max(pcb$year) - min(pcb$year))
(range_ratio = horiz_range / vert_range)
pcb$rescaled_year = (pcb$year -  min(pcb$year)) * range_ratio

coordinates(pcb)=~x+y+rescaled_year
variogram(PCB138~1,pcb,beta=90,tol.ver=1) # or any small value

However you won't see much, as this data set doesn't time-replicated
locations.

>
> Thanks!
> Nick
>
> ====================
>
> # add a little noise to the data locations in case there are
> overlapping points
> pcb$x = as.double(pcb$x + runif(length(pcb$x), -0.01*horiz_range,
> 0.01*horiz_range))
> pcb$y = as.double(pcb$y + runif(length(pcb$y), -0.01*horiz_range,
> 0.01*horiz_range))
> pcb$rescaled_year = as.double(pcb$rescaled_year +
> runif(length(pcb$rescaled_year), -0.01*vert_range, 0.01*vert_range))
This wouldn't be needed for 3D kriging.
>
> # do a 2D variogram for various years
> v3gm = NULL
> v4gm = NULL
>
> # get residuals after factoring out depth
> pcb$res=residuals(lm(log(PCB138)~rescaled_year+depth, pcb))
>
>
> # Get a variogram of the residuals by location, after factoring out
> any year correlation
> v3 = variogram(res ~ rescaled_year, ~x+y, pcb, dX=.1,
> bound=c(0,1000,3000,5000,(1:16)*10000))
You don't factor year correlation out here; you just exclude (dX=.1)
point pairs from different years. So it's spatial correlation only that
ends up in this v3 variogram.
>
> v3gm = vgm(.224,"Sph",17247,.08)
> print(plot(v3, model = v3gm, plot.numbers = TRUE))
>
> (v3gm.f <- fit.variogram(v3, v3gm, fit.ranges=FALSE))
> print(plot(v3, model = v3gm.f, plot.numbers = TRUE))
>
> print.data.frame(v3gm)
> print.data.frame(v3gm.f)
>
>
> # do the 3D variogram
> v4 = variogram(res ~ 1, ~x+y+rescaled_year, pcb, dX=.5)
> print(plot(v4, model = vgm(.224,"Exp",17247,.08), plot.numbers = TRUE))
This variogram computes distances in 3D, which is correct provided that
you took care (and knew) the appropriate xy vs t anisotropy in advance.
I don't think the dX makes sense in this case.
>
>
> # 3-dimensional model with nugget component and sill component
>
> #
> v4gm = vgm(0.3, "Sph", 2000, anis=c(0, 90, 0, 1, 1), add.to=v3gm)
as both anisotropy ratios are 1, this model is isotropic after all, and
the 0,90,0 could be anything.
>
> print.data.frame(v3gm)
> print.data.frame(v4gm)
>
> (v4gm.f <- fit.variogram(v4, v4gm, fit.sills=TRUE, fit.ranges=TRUE))
> print.data.frame(v4gm.f)
> print(plot(v4, model = v4gm.f, plot.numbers = TRUE))
> ====================

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From ktsolis at nps.edu  Mon Oct 26 06:02:49 2009
From: ktsolis at nps.edu (Kristen Tsolis)
Date: Sun, 25 Oct 2009 22:02:49 -0700
Subject: [R-sig-Geo] Seeking Spatial Statistics
	Specialist--Visiting/Sabbatical
Message-ID: <4AE52D79.4000506@nps.edu>

CORE Lab
U.S. Naval Post Graduate School


Position Description:

The candidate for this position will have a Ph.D. in a social science 
discipline that would make extensive use of geospatial statistics (such 
as Geography, Regional Planning, Political Science/Policy Analysis, 
etc.). The ideal candidate would be engaged in the following:

Analysis of datasets that combine geospatial, and non-geospatial 
components (esp. socio-economic-political datasets at the sub-national 
level).

Analysis of non-homogenous datasets and provide input in the 
homogenization process (mush-ups)

Use of commercial geographic information systems (ArcGIS, or similar), 
as well as expert use of open-source applications for the analysis of 
spatial data (GeoDa, STARS, R-geo, etc). Software expertise for remote 
sensing (such as Erdas, Imagine, or ENVI) is desirable.

Support for and/or supervise the design and implementation of spatial 
and non-spatial data collection and processing:
o       identifying and coding spatial variables related to the research;
o       merging/joining a-spatial data/spreadsheets with spatial data;
o       formatting data to prepare for geospatial analysis;

Advise on data analysis system design and architecture (schema design 
and flowcharting).

Provide support for and/or supervise the design and implementation of 
spatial and non-spatial data collection and processing.

Please send a vita to Karen Flaherty, Executive Assistant,
klflaher at nps.edu, 831-656-2932.


From dampage at gmail.com  Mon Oct 26 12:00:15 2009
From: dampage at gmail.com (Sarath Udayasiri)
Date: Mon, 26 Oct 2009 17:00:15 +0600
Subject: [R-sig-Geo] ADDING POINTS
Message-ID: <fda471500910260400h4f781613y4aa8df0c1467ae0d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091026/b4b24c8e/attachment.pl>

From tankisothejane at yahoo.com  Mon Oct 26 12:56:36 2009
From: tankisothejane at yahoo.com (TANKISO THEJANE)
Date: Mon, 26 Oct 2009 04:56:36 -0700 (PDT)
Subject: [R-sig-Geo] Univeral kriging
Message-ID: <444927.12003.qm@web46408.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091026/e8d905e3/attachment.pl>

From hengl at spatial-analyst.net  Mon Oct 26 13:16:36 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Mon, 26 Oct 2009 13:16:36 +0100
Subject: [R-sig-Geo] inquiry on suitable packages
In-Reply-To: <4AE34083.6050309@uni-muenster.de>
References: <mailman.13.1256378403.26717.r-sig-geo@stat.math.ethz.ch>
	<4AE34083.6050309@uni-muenster.de>
Message-ID: <20091026131636.1027y220gokokggg@spatial-analyst.net>


Hakim,

There are plenty of (SDM) algorithms that generate species  
distribution maps given occurrence (or density) records and  
environmental maps. For a systematic review, see e.g. Tsoar et al.  
2007 [http://dx.doi.org/10.1111/j.1472-4642.2007.00346.x].

In R, you can try using the adehabitat package that can be used to  
generate Habitat Suitability Index maps using methods such as madifa  
and/or enfa (read more about ecology-analysis packages via the  
"Environmetrics" views). Here are some simple examples:

http://spatial-analyst.net/scripts/bei.R

I myselft have recently been testing MaxEnt  
[http://www.cs.princeton.edu/~schapire/maxent/] and discovered that it  
has several advantages over competition (GARP, ENFA):
- it accepts both categorical and continuous predictors;
- it allows cross-validation;
- it is fast(est);

In short, MaxEnt should be high on your list because it is also the  
most used SDM by biologists at the moment.

There is no package for R to use MaxEnt, but there is probably no need  
for this neither. The whole algorithm comes in a single ".jar" file  
that can be run via batch commands (i.e. from R). Here are some  
examples using the global environmental layers:

http://spatial-analyst.net/scripts/worldmaps.R

Note also that there is also a R mailing list for ecology  
(R-sig-ecology) where you will probably be able to get much more  
feedback.


HTH,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/


Quoting Hakim Abdi <hakim.abdi at uni-muenster.de>:

> Dear All:
>
> I have a set of nine independent variables (extracted Landsat TM band
> DNs, land surface temperature, and NDVI) and a set of eight response
> variables (presence/absence breeding season survey of eight bird
> species). I'm doing a small exercise to try to find a model that best
> fits the relationship between the independent variables and species
> occurrence and then apply that model to another set of independent
> variables from another time period (and even from another area) and see
> what the distribution might be at that time (or place).
>
> I am currently working with the packages BIOMOD Gstat and spatstat. I'm
> wondering if there are any others I'm not aware of that could further
> help me?
>
> Thanks in advance for your time and assistance.
>
> Hakim
>
> --
>
> Mit freundlichen Gr??en/Regards
> __________________________________
> Abdulhakim M. Abdi
> Erasmus Mundus Master's Programme in
> Geospatial Technologies
>
> Institut f?r Geoinformatik
> Universit?t M?nster
> 32U 5755408.16mN, 404463.35mE
> ifgi.uni-muenster.de
>
> Instituto Superior de Estat?stica e Gest?o de Informa??o
> Universidade Nova de Lisboa
> 29S 4287095.5mN, 486099.7mE
> www.isegi.unl.pt
>
> www.geospatialtechnologist.com
> www.hakimabdi.com
>
>
> 	[[alternative HTML version deleted]]
>
>


From ashton at msu.edu  Mon Oct 26 14:15:40 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Mon, 26 Oct 2009 09:15:40 -0400
Subject: [R-sig-Geo] Univeral kriging
In-Reply-To: <444927.12003.qm@web46408.mail.sp1.yahoo.com>
References: <444927.12003.qm@web46408.mail.sp1.yahoo.com>
Message-ID: <200910260915.40730.ashton@msu.edu>

Hi there,

good routines already exist in several R libraries for doing this. They will 
save you trouble in developing bug-free and efficient code. Check out gstat and 
maybe fields.

If you still want to implement kriging manually, these scripts, which I 
developed for a class exercise, might be a useful starting place. They are not 
there permanently, probably through the end of 2009:
http://www.msu.edu/~ashton/classes/866/notes/lect18/manual_krig.R
http://www.msu.edu/~ashton/classes/866/notes/lect18/covmodels.R

yours,

Ashton

On Monday 26 October 2009 07:56:36 TANKISO THEJANE wrote:
> R geo-helpers
>  
> i am new to r and would like you to help me as i am trying to go through
>  basic steps. I need to compute a predicted value at point (3,3) and its
>  variance given la set of locations and value. i want to make the code
>  generic for any size such that i would be able to estimate universal krige
>  at each point of grid (0,..,6) (0,..6). 
> the code
>  
> g = function(h) { return(0.1+3*(1-exp(-h/4)))}## variogram of exponential
>  form x = rbind(c(1,1),c(2,5),c(4,1),c(5,4))##4 observed locations
> x = rbind(x,c(3,3))  # Row five is the point at which we want to estimate.
> d = sqrt(x[,1]^2+x[,2]^2)##distance of the locations from the origin
> s = c(1,9,5,12)## values at the corresponding 4 locations
> ## pairsv = pair semivariogram
> pairsv = function(i,j) {
>   p1 = x[i,]
>   p2 = x[j,]
>   d = sqrt(sum((p1-p2)^2))
>   return(g(d))
> }
> G = matrix(0,4,4)
> for(i in 1:4) for(j in 1:4) G[i,j] = pairsv(i,j)
> X = matrix(0,4,3)
> for(i in 1:4) for(j in 1:3) X[i,j] = d[i]^(j-1)
> ##Asymmetric matrix
> Gu = rbind(cbind(G,X), cbind(t(X),matrix(0,3,3)))
> x
> gu = (1:7)*0
> gu
> for(i in 1:4) gu[i] = pairsv(i,5)
> for(i in 1:3) gu[i+4] = d[5]^(i-1)
> lu = inv(Gu) %*% gu
> 
>  
>  
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From edzer.pebesma at uni-muenster.de  Mon Oct 26 14:34:55 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 26 Oct 2009 14:34:55 +0100
Subject: [R-sig-Geo] Univeral kriging
In-Reply-To: <444927.12003.qm@web46408.mail.sp1.yahoo.com>
References: <444927.12003.qm@web46408.mail.sp1.yahoo.com>
Message-ID: <4AE5A57F.4070809@uni-muenster.de>

Tankiso,

Here is some tips:
- make your code such that cut and paste works for us; for me, the ^2
below is vanished (and interpreted as superscript right away, I don't
know why)
- you didn't test your code, as the function inv does not exist
- your code doesn't compute the kriging variance
- the code is very hard to read, and uncommented, so we have to guess
what you want (first order linear trend in the coordinates?)
- use functions if you want to make something generic
- write and use functions such that matrices are allowed, e.g. for g()
you can pass a matrix vector; don't write loops over the individual elements
- If you want to solve Ax=b, write solve(A,b) instead of solve(A) %*% b.
- if you want to find out if your code works, don't post it here but
compare your output with that obtained from packages that do universal
kriging such as fields, geoR or gstat.
--
Edzer

TANKISO THEJANE wrote:
> R geo-helpers
>  
> i am new to r and would like you to help me as i am trying to go through basic steps. I need to compute a predicted value at point (3,3) and its variance given la set of locations and value. i want to make the code generic for any size such that i would be able to estimate universal krige at each point of grid (0,..,6) (0,..6).
>  
> the code
>  
> g = function(h) { return(0.1+3*(1-exp(-h/4)))}## variogram of exponential form
> x = rbind(c(1,1),c(2,5),c(4,1),c(5,4))##4 observed locations 
> x = rbind(x,c(3,3))  # Row five is the point at which we want to estimate.
> d = sqrt(x[,1]^2+x[,2]^2)##distance of the locations from the origin
> s = c(1,9,5,12)## values at the corresponding 4 locations
> ## pairsv = pair semivariogram
> pairsv = function(i,j) {
>   p1 = x[i,]
>   p2 = x[j,]
>   d = sqrt(sum((p1-p2)^2))
>   return(g(d))
> }
> G = matrix(0,4,4)
> for(i in 1:4) for(j in 1:4) G[i,j] = pairsv(i,j)
> X = matrix(0,4,3)
> for(i in 1:4) for(j in 1:3) X[i,j] = d[i]^(j-1)
> ##Asymmetric matrix 
> Gu = rbind(cbind(G,X), cbind(t(X),matrix(0,3,3)))
> x
> gu = (1:7)*0
> gu
> for(i in 1:4) gu[i] = pairsv(i,5)
> for(i in 1:3) gu[i+4] = d[5]^(i-1)
> lu = inv(Gu) %*% gu
>
>  
>  
>
>
>       
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From juantomas.sayago at gmail.com  Mon Oct 26 16:48:29 2009
From: juantomas.sayago at gmail.com (Juan Tomas Sayago)
Date: Mon, 26 Oct 2009 10:48:29 -0500
Subject: [R-sig-Geo] Spatial Panel data models
Message-ID: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091026/887ac0b3/attachment.pl>

From p.hiemstra at geo.uu.nl  Mon Oct 26 16:53:09 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 26 Oct 2009 16:53:09 +0100
Subject: [R-sig-Geo] Spatial Panel data models
In-Reply-To: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>
References: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>
Message-ID: <4AE5C5E5.2010003@geo.uu.nl>

Juan Tomas Sayago wrote:
> Hi group,
> Does anyone knows of applications of spatial panel data models in R.
> Thanks
> Juan
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Hi,

I'm not sure what spatial panel data models are, but that may be my 
problem :). A start to look for packages to do anything spatial in R is 
the Spatial Task View.

http://cran.r-project.org/web/views/Spatial.html

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Mon Oct 26 16:54:53 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 26 Oct 2009 16:54:53 +0100
Subject: [R-sig-Geo] Spatial Panel data models
In-Reply-To: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>
References: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>
Message-ID: <4AE5C64D.50504@geo.uu.nl>

in addition:

please search the archives of this mailing list, I typed this into google:

R-sig-geo spatial panel data model

and got:

https://stat.ethz.ch/pipermail/r-sig-geo/2006-August/001237.html

as the first hit.

cheers,
Paul

Juan Tomas Sayago wrote:
> Hi group,
> Does anyone knows of applications of spatial panel data models in R.
> Thanks
> Juan
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From hi_ono2001 at ybb.ne.jp  Mon Oct 26 17:49:02 2009
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Tue, 27 Oct 2009 01:49:02 +0900 (JST)
Subject: [R-sig-Geo] Spatial Panel data models
In-Reply-To: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>
Message-ID: <20091026164902.93320.qmail@web10502.mail.ogk.yahoo.co.jp>

Hello.

--- Juan Tomas Sayago <juantomas.sayago at gmail.com> wrote:

> Does anyone knows of applications of spatial panel
> data models in R.

 There's one package named "splm" available from
R-Forge(http://r-forge.r-project.org/projects/splm/).

 And introduction document as follows.


http://www.agrocampus-ouest.fr/math/useR-2009//slides/Millo+Piras.pdf

 Sorry I've never used this.


 I hope this info will help you.

 Regards.


From hi_ono2001 at ybb.ne.jp  Mon Oct 26 18:28:00 2009
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Tue, 27 Oct 2009 02:28:00 +0900 (JST)
Subject: [R-sig-Geo] Create ESRI personal geodatabase (.mdb) in R?
In-Reply-To: <alpine.LRH.2.00.0910251209080.17634@reclus.nhh.no>
Message-ID: <20091026172801.62002.qmail@web10512.mail.ogk.yahoo.co.jp>

Hello.

 I think it's good idea for R to use SpatiaLite instead of
dealing with shapefiles directly.

 SpatiaLite has functions of Raster GIS and routing, so
these functions will enrich spatial analyses in R. 

 It'll be better SQLite/SpatiaLite embedded within R as
internal DB.

 I hope some day R will be running with SpatiaLite and
Grass GIS on iPhone, Android and Nokia 900 for field
working.


 Regards.

--- Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Sat, 24 Oct 2009, Dan Putler wrote:
> 
> > The response I got from the gdal-dev list is that
> starting in GDAL/OGR
> > 1.6.0 there is a read-only driver or SpatiaLite
> files, and that there is
> > currently a working read and write driver for
> SpatiaLite in the GDAL/OGR
> > 1.7.0 SVN. OSGEO4W currently has the default
> install GDAL/OGR 1.5.4, but
> > GDAL/OGR 1.6.0 as an advanced install option.
> Eventually the SpatialLite
> > read/write capability for GDAL/OGR will make it to
> OSGEO4W, so it is
> > something of a moot point now.
> 
> Dan,
> 
> I agree that something more robust than shapefiles
> would be an advance, 
> but this possible alternative does depend on
> relatively many users having 
> access to read and write functionality.
> 
> With regard to spatial objects and SQLite, had you
> considered giving the 
> CRAN SQLiteMap package a trial run?
> 
> http://cran.r-project.org/package=SQLiteMap
> 
> It is using a different set of extensions from
> SpatiaLite, but has been 
> available for some time and does run cross-platform
> for R users. I haven't 
> used it myself, but it is self-contained (no
> dependencies other than those 
> on CRAN).
>


From Virgilio.Gomez at uclm.es  Tue Oct 27 03:48:43 2009
From: Virgilio.Gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Mon, 26 Oct 2009 22:48:43 -0400
Subject: [R-sig-Geo] Space-time cluster analysis
In-Reply-To: <a03570f40910230815u34c7b644gf17b9a34a70a3d18@mail.gmail.com>
References: <a03570f40910230815u34c7b644gf17b9a34a70a3d18@mail.gmail.com>
Message-ID: <1256611723.3365.25.camel@Virgilio-Gomez>

Hi Joe,


> I am using space-time cluster analysis to search for areas/times of high
> disease incidence.  My data is aggregated by geographic areas with known
> background population numbers.  So under the null hypothesis, the number of
> cases in a given location/time period is Poisson distributed, dependent on
> the number of person-years.

Some of the code in DCluster and spatclus may be adapted to detect
clusters in space and time. I am planning to add a space-time version of
the spatial scan statistic but there is no code at the moment. However,
it should not be difficult to implement. Basically, you need to
aggregate data over a temporal window and then perform a spatial test.

Hope this helps.

Virgilio


From matzke at berkeley.edu  Tue Oct 27 05:58:25 2009
From: matzke at berkeley.edu (Nick Matzke)
Date: Mon, 26 Oct 2009 21:58:25 -0700
Subject: [R-sig-Geo] Fwd:  3D variogram model
In-Reply-To: <25d4d3af0910262133i33abe4afp584546960b01e34a@mail.gmail.com>
References: <4AE3ADB9.2030105@berkeley.edu> <4AE4CDF3.50206@uni-muenster.de>
	<25d4d3af0910262133i33abe4afp584546960b01e34a@mail.gmail.com>
Message-ID: <4AE67DF1.9080709@berkeley.edu>

Dr. Pebesma,

Thanks so much for your help!!  I understand the pcb dataset is not a 
great one for this, but it is extremely useful to see an example of the 
basic procedure implemented.  Thanks again!

Nick


Nick Matzke wrote:
> 
> 
> ---------- Forwarded message ----------
> From: *Edzer Pebesma* <edzer.pebesma at uni-muenster.de 
> <mailto:edzer.pebesma at uni-muenster.de>>
> Date: Sun, Oct 25, 2009 at 3:15 PM
> Subject: Re: [R-sig-Geo] 3D variogram model
> To: matzke at berkeley.edu <mailto:matzke at berkeley.edu>
> Cc: r-sig-geo at stat.math.ethz.ch <mailto:r-sig-geo at stat.math.ethz.ch>, 
> gstat-info at geo.uu.nl <mailto:gstat-info at geo.uu.nl>
> 
> 
> Nick, thanks for bringing this up! I uploaded a script and the (large)
> resulting pdf to
> 
> http://ifgi.uni-muenster.de/~epebe_01/pcb/ 
> <http://ifgi.uni-muenster.de/%7Eepebe_01/pcb/>
> 
> I used it for a workshop about a year ago, just before geoenv 2008. It's
> supposed to more or less do what you had in mind. The variography in
> continuous space-time is hard to infer for this particular data set, I
> think, and what I did below is rather quick and dirty, and builds upon
> the earlier 2004 work which was already heavy on the side of
> assumptions. I'll add this script to the demo section of the next gstat
> R package.
> 
> A few more comments to your script are inline, below.
> 
> Nick Matzke wrote:
>  >
>  > Hi all,
>  >
>  > I am trying to figure out if I can get 3-D kriging to work in the R
>  > gstat package.  The demo given here:
>  >
>  > # =================================================
>  > # Edzer J. Pebesma, Richard N.M. Duin (2005) Spatio-temporal mapping of
>  > # sea floor sediment pollution in the North Sea.  In: Ph. Renard, and
>  > # R. Froidevaux, eds. Proceedings GeoENV 2004 -- Fifth European
>  > Conference
>  > # on Geostatistics for Environmental Applications; Springer.
>  > #
>  >
>  > # Run the demo:
>  > demo(pcb)
>  > #==================================================
>  >
>  >
>  >
>  > ...doesn't really do full 3D kriging as far as I can tell, it just
>  > models the cross-variograms between data from different years.  I
>  > would eventually like to do a kriging prediction map for e.g. any one
>  > of, say, 100 or 1000 different years, so I don't think the
>  > cross-kriging approach will work.
>  >
>  > Anyway, for now, I am just seeing if I can get a simple 3D kriging to
>  > work with the pcb dataset.  In an attempt to make it work, I rescaled
>  > the "year" data to the approximate dimensions of the x and y data, and
>  > then I added 1% variability in all the locations to see if that would
>  > avoid the singularity problem, which I gather (?) can be caused by
>  > points too close together.
>  >
>  > But still, no luck.  I basically just want to fit a variogram model
>  > which captures the variability in space (xy) and time (rescaled_year).
>  >
>  > Here's what I've got, below, any comments/help VERY appreciated.
>  >
>  > (PS: Does anyone have a bit of code that will calculate an empirical
>  > variogram in the third dimension?  The gstat variogram() function
>  > evidently won't do it, even when beta=90 is specified.
> after your:
> data(pcb)
> 
> # rescale year to similar units as space
> (horiz_range = max(pcb$x) - min(pcb$x))
> (vert_range = max(pcb$year) - min(pcb$year))
> (range_ratio = horiz_range / vert_range)
> pcb$rescaled_year = (pcb$year -  min(pcb$year)) * range_ratio
> 
> coordinates(pcb)=~x+y+rescaled_year
> variogram(PCB138~1,pcb,beta=90,tol.ver=1) # or any small value
> 
> However you won't see much, as this data set doesn't time-replicated
> locations.
> 
>  >
>  > Thanks!
>  > Nick
>  >
>  > ====================
>  >
>  > # add a little noise to the data locations in case there are
>  > overlapping points
>  > pcb$x = as.double(pcb$x + runif(length(pcb$x), -0.01*horiz_range,
>  > 0.01*horiz_range))
>  > pcb$y = as.double(pcb$y + runif(length(pcb$y), -0.01*horiz_range,
>  > 0.01*horiz_range))
>  > pcb$rescaled_year = as.double(pcb$rescaled_year +
>  > runif(length(pcb$rescaled_year), -0.01*vert_range, 0.01*vert_range))
> This wouldn't be needed for 3D kriging.
>  >
>  > # do a 2D variogram for various years
>  > v3gm = NULL
>  > v4gm = NULL
>  >
>  > # get residuals after factoring out depth
>  > pcb$res=residuals(lm(log(PCB138)~rescaled_year+depth, pcb))
>  >
>  >
>  > # Get a variogram of the residuals by location, after factoring out
>  > any year correlation
>  > v3 = variogram(res ~ rescaled_year, ~x+y, pcb, dX=.1,
>  > bound=c(0,1000,3000,5000,(1:16)*10000))
> You don't factor year correlation out here; you just exclude (dX=.1)
> point pairs from different years. So it's spatial correlation only that
> ends up in this v3 variogram.
>  >
>  > v3gm = vgm(.224,"Sph",17247,.08)
>  > print(plot(v3, model = v3gm, plot.numbers = TRUE))
>  >
>  > (v3gm.f <- fit.variogram(v3, v3gm, fit.ranges=FALSE))
>  > print(plot(v3, model = v3gm.f, plot.numbers = TRUE))
>  >
>  > print.data.frame(v3gm)
>  > print.data.frame(v3gm.f)
>  >
>  >
>  > # do the 3D variogram
>  > v4 = variogram(res ~ 1, ~x+y+rescaled_year, pcb, dX=.5)
>  > print(plot(v4, model = vgm(.224,"Exp",17247,.08), plot.numbers = TRUE))
> This variogram computes distances in 3D, which is correct provided that
> you took care (and knew) the appropriate xy vs t anisotropy in advance.
> I don't think the dX makes sense in this case.
>  >
>  >
>  > # 3-dimensional model with nugget component and sill component
>  >
>  > #
>  > v4gm = vgm(0.3, "Sph", 2000, anis=c(0, 90, 0, 1, 1), add.to 
> <http://add.to>=v3gm)
> as both anisotropy ratios are 1, this model is isotropic after all, and
> the 0,90,0 could be anything.
>  >
>  > print.data.frame(v3gm)
>  > print.data.frame(v4gm)
>  >
>  > (v4gm.f <- fit.variogram(v4, v4gm, fit.sills=TRUE, fit.ranges=TRUE))
>  > print.data.frame(v4gm.f)
>  > print(plot(v4, model = v4gm.f, plot.numbers = TRUE))
>  > ====================
> 
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de 
> <mailto:e.pebesma at wwu.de>
> 
> 

-- 
====================================================
Nicholas J. Matzke
Ph.D. Student, Graduate Student Researcher
Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264
Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
3060 VLSB #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. When people 
thought the earth was spherical, they were wrong. But if you think that 
thinking the earth is spherical is just as wrong as thinking the earth 
is flat, then your view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The Skeptical Inquirer, 
14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm


From alobolistas at gmail.com  Tue Oct 27 10:22:43 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 27 Oct 2009 10:22:43 +0100
Subject: [R-sig-Geo] Confusing error message by raster package
Message-ID: <4AE6BBE3.3040802@gmail.com>

Hi!

I entered
 > r1 <- raster("SDIM160.tif", band=1)
Error in .rasterObjectFromFile(x, band = band, values = values, proj = 
proj,  :
   Cannot create RasterLayer object. There is a '.gri' file but no 
'.grd' file. GDAL does not recognize the '.gri' file

I was very confused by the error message, after all the problem was that 
the file simply does not exist, it was misspelled:

 > r1 <- raster("SDIM0160.tif", band=1)
CPL Warning 1: TIFFReadDirectory:Unknown field with tag 37717 (0x9355) 
encountered

The error message in rgdal is correct:

 > readGDAL("SDIM160.tif")
CPL ERROR 4: `SDIM160.tif' does not exist in the file system,
and is not recognised as a supported dataset name.

Error in .local(.Object, ...) :
   `SDIM160.tif' does not exist in the file system,
and is not recognised as a supported dataset name.


Could the error message be modified?

Thanks

Agus


From alobolistas at gmail.com  Tue Oct 27 11:44:24 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 27 Oct 2009 11:44:24 +0100
Subject: [R-sig-Geo] raster package: overlay changes geometry
Message-ID: <4AE6CF08.5020200@gmail.com>

Hi!

I've done:
r1 <- raster("SDIM0160.tif",band=1)
r2 <- raster("SDIM0160.tif",band=2)
r3 <- raster("SDIM0160.tif",band=3)
f <- function(x,y,z,coefs=calcoefs) coefs[1,1]*x+coefs[1,2]*y+coefs[1,3]*z
overlay(r1,r2,r3,fun=f,filename="SDIM0160_miL1.tif"filetype='GTiff')

The problem is that the resulting raster does not have the same geometry 
as the input one.

Input:
$ gdalinfo SDIM0160.tif
Warning 1: TIFFReadDirectory:Unknown field with tag 37717 (0x9355) 
encountered
Driver: GTiff/GeoTIFF
Files: SDIM0160.tif
Size is 2640, 1760
Coordinate System is `'
Metadata:
   TIFFTAG_SOFTWARE=SIGMA PhotoPro 2.4.0.3198
   TIFFTAG_DATETIME=2009:09:22 15:56:48
   TIFFTAG_XRESOLUTION=180
   TIFFTAG_YRESOLUTION=180
   TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
Image Structure Metadata:
   INTERLEAVE=PIXEL
Corner Coordinates:
Upper Left  (    0.0,    0.0)
Lower Left  (    0.0, 1760.0)
Upper Right ( 2640.0,    0.0)
Lower Right ( 2640.0, 1760.0)
Center      ( 1320.0,  880.0)
Band 1 Block=2640x1 Type=Byte, ColorInterp=Red
Band 2 Block=2640x1 Type=Byte, ColorInterp=Green
Band 3 Block=2640x1 Type=Byte, ColorInterp=Blue

Output:
$ gdalinfo SDIM0160_miL1.tif
Driver: GTiff/GeoTIFF
Files: SDIM0160_miL1.tif
Size is 2640, 1760
Coordinate System is `'
Origin = (0.000000000000000,1761.000000000000000)
Pixel Size = (1.000000000000000,-1.000000000000000)
Image Structure Metadata:
   INTERLEAVE=BAND
Corner Coordinates:
Upper Left  (       0.000,    1761.000)
Lower Left  (   0.0000000,   1.0000000)
Upper Right (    2640.000,    1761.000)
Lower Right (    2640.000,       1.000)
Center      (    1320.000,     881.000)
Band 1 Block=2640x1 Type=Float32, ColorInterp=Gray


Could this be fixed?

Thanks,

Agus


From juantomas.sayago at gmail.com  Tue Oct 27 11:51:06 2009
From: juantomas.sayago at gmail.com (Juan Tomas Sayago)
Date: Tue, 27 Oct 2009 05:51:06 -0500
Subject: [R-sig-Geo] Spatial Panel data models
In-Reply-To: <20091026164902.93320.qmail@web10502.mail.ogk.yahoo.co.jp>
References: <3364ce110910260848p5ecf7b64oeb8e9f92ea51f18e@mail.gmail.com>
	<20091026164902.93320.qmail@web10502.mail.ogk.yahoo.co.jp>
Message-ID: <3364ce110910270351t4deff34fk2e4ffc3216560eb7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091027/462681a1/attachment.pl>

From carson.farmer at gmail.com  Tue Oct 27 16:24:01 2009
From: carson.farmer at gmail.com (Carson Farmer)
Date: Tue, 27 Oct 2009 15:24:01 +0000
Subject: [R-sig-Geo] double stochastic weights matrix
Message-ID: <94b3c8440910270824u6cc4685ao2d2352f7bfdefaf7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091027/871f3dac/attachment.pl>

From r.hijmans at gmail.com  Tue Oct 27 18:04:59 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 27 Oct 2009 10:04:59 -0700
Subject: [R-sig-Geo] raster package: overlay changes geometry
In-Reply-To: <4AE6CF08.5020200@gmail.com>
References: <4AE6CF08.5020200@gmail.com>
Message-ID: <dc22b2570910271004x279dba0ds963947443324d2f3@mail.gmail.com>

Hi Agus,

This is probably caused by unexpected values in your input TIF file.
The Upper Left Y is lower then the Lower Left Y...

Upper Left  (    0.0,    0.0)
Lower Left  (    0.0, 1760.0)
Upper Right ( 2640.0,    0.0)
Lower Right ( 2640.0, 1760.0)

I do not know if this is "legal" (I sure hope not); but it would be
useful to have your input file (if you can send it off-list) to see
how to best catch this (and either deal with it correctly or give an
error).

I cannot reproduce this problem with other files
Here is an example that works fine:

library(raster)
fn1 <- system.file("pictures/Rlogo.jpg", package="rgdal")
b <- brick(fn1)
b <- readAll(b)
# create a three band TIF file as in your example
b2 <- writeRaster(b, filename='input.tif', filetype='GTiff', overwrite=TRUE)


fn2 <- 'input.tif'
r1 <- raster(fn2,band=1)
r2 <- raster(fn2,band=2)
r3 <- raster(fn2,band=3)
f <- function(x,y,z,coefs= t(matrix(1:3)))
coefs[1,1]*x+coefs[1,2]*y+coefs[1,3]*z
o <- overlay(r1,r2,r3,fun=f,filename="test.tif", filetype='GTiff',
overwrite=TRUE, progress='tcltk')

extent(b)
extent(b2)
extent(r1)
extent(o)

GDALinfo(fn1)
GDALinfo(fn2)
GDALinfo('test.tif')

# By the way, this would be more efficient

b <- brick(fn1)
overlay(b,fun=f,filename="test.tif", filetype='GTiff', overwrite=TRUE)

Robert


On Tue, Oct 27, 2009 at 3:44 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> I've done:
> r1 <- raster("SDIM0160.tif",band=1)
> r2 <- raster("SDIM0160.tif",band=2)
> r3 <- raster("SDIM0160.tif",band=3)
> f <- function(x,y,z,coefs=calcoefs) coefs[1,1]*x+coefs[1,2]*y+coefs[1,3]*z
> overlay(r1,r2,r3,fun=f,filename="SDIM0160_miL1.tif"filetype='GTiff')
>
> The problem is that the resulting raster does not have the same geometry as
> the input one.
>
> Input:
> $ gdalinfo SDIM0160.tif
> Warning 1: TIFFReadDirectory:Unknown field with tag 37717 (0x9355)
> encountered
> Driver: GTiff/GeoTIFF
> Files: SDIM0160.tif
> Size is 2640, 1760
> Coordinate System is `'
> Metadata:
> ?TIFFTAG_SOFTWARE=SIGMA PhotoPro 2.4.0.3198
> ?TIFFTAG_DATETIME=2009:09:22 15:56:48
> ?TIFFTAG_XRESOLUTION=180
> ?TIFFTAG_YRESOLUTION=180
> ?TIFFTAG_RESOLUTIONUNIT=2 (pixels/inch)
> Image Structure Metadata:
> ?INTERLEAVE=PIXEL
> Corner Coordinates:
> Upper Left ?( ? ?0.0, ? ?0.0)
> Lower Left ?( ? ?0.0, 1760.0)
> Upper Right ( 2640.0, ? ?0.0)
> Lower Right ( 2640.0, 1760.0)
> Center ? ? ?( 1320.0, ?880.0)
> Band 1 Block=2640x1 Type=Byte, ColorInterp=Red
> Band 2 Block=2640x1 Type=Byte, ColorInterp=Green
> Band 3 Block=2640x1 Type=Byte, ColorInterp=Blue
>
> Output:
> $ gdalinfo SDIM0160_miL1.tif
> Driver: GTiff/GeoTIFF
> Files: SDIM0160_miL1.tif
> Size is 2640, 1760
> Coordinate System is `'
> Origin = (0.000000000000000,1761.000000000000000)
> Pixel Size = (1.000000000000000,-1.000000000000000)
> Image Structure Metadata:
> ?INTERLEAVE=BAND
> Corner Coordinates:
> Upper Left ?( ? ? ? 0.000, ? ?1761.000)
> Lower Left ?( ? 0.0000000, ? 1.0000000)
> Upper Right ( ? ?2640.000, ? ?1761.000)
> Lower Right ( ? ?2640.000, ? ? ? 1.000)
> Center ? ? ?( ? ?1320.000, ? ? 881.000)
> Band 1 Block=2640x1 Type=Float32, ColorInterp=Gray
>
>
> Could this be fixed?
>
> Thanks,
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From dampage at gmail.com  Tue Oct 27 18:18:13 2009
From: dampage at gmail.com (Sarath Udayasiri)
Date: Tue, 27 Oct 2009 22:48:13 +0530
Subject: [R-sig-Geo] ADVICE..
Message-ID: <fda471500910271018t6f1cd8d5nf4fd66dea4342c75@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091027/83bbbe71/attachment.pl>

From dampage at gmail.com  Tue Oct 27 18:23:02 2009
From: dampage at gmail.com (Sarath Udayasiri)
Date: Tue, 27 Oct 2009 22:53:02 +0530
Subject: [R-sig-Geo] FEW MORE DOUBTS
Message-ID: <fda471500910271023t63907928i25226d8161cac559@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091027/a01f6622/attachment.pl>

From Roger.Bivand at nhh.no  Tue Oct 27 19:08:06 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 27 Oct 2009 19:08:06 +0100 (CET)
Subject: [R-sig-Geo] double stochastic weights matrix
In-Reply-To: <94b3c8440910270824u6cc4685ao2d2352f7bfdefaf7@mail.gmail.com>
References: <94b3c8440910270824u6cc4685ao2d2352f7bfdefaf7@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0910271901390.9975@reclus.nhh.no>

On Tue, 27 Oct 2009, Carson Farmer wrote:

> Hi list,
>
> Does anyone know of a package/function that will compute double 
> stochastic matrices? In case my terminology is wrong: What I am looking 
> for is a function to take an input (weights) matrix, and output a new 
> matrix with row and column sums equal to some specified value (or as 
> close to this as possible given some maximum number of iterations or 
> other parameter). This would likely be an iterative function, with some 
> sort of balancing term to avoid drift. Does anyone know of an 
> implementation of this? Perhaps I should pose this question to the 
> general R mailing list?

Google on Biproportional or Biproportionate matrices - refered to in 
Haggett, Cliff & Frey (1977), p. 125, originally Bacharach (1970). There 
are papers on algorithms, mostly related to input-output modelling, 
including RAS updating.

Roger

>
> Cheers,
>
> Carson
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tom.gottfried at wzw.tum.de  Wed Oct 28 12:57:18 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Wed, 28 Oct 2009 12:57:18 +0100
Subject: [R-sig-Geo] ADVICE..
In-Reply-To: <fda471500910271018t6f1cd8d5nf4fd66dea4342c75@mail.gmail.com>
References: <fda471500910271018t6f1cd8d5nf4fd66dea4342c75@mail.gmail.com>
Message-ID: <4AE8319E.4000802@wzw.tum.de>

Two things that might help you (and us):

http://www.r-project.org/posting-guide.html

http://www.springer.com/public+health/epidemiology/book/978-0-387-78170-9

regards,
Tom


From simplemorgs at mighty.co.za  Wed Oct 28 14:13:45 2009
From: simplemorgs at mighty.co.za (simplemorgs at mighty.co.za)
Date: Wed, 28 Oct 2009 15:13:45 +0200 (SAST)
Subject: [R-sig-Geo] Spatiotemporal data analysis
Message-ID: <64211.146.230.128.30.1256735625.squirrel@www.mighty.co.za>

Hi,
I am interested to know if anyone is aware of or have developed any
software which can analyse both spatial and temporal  animal movements
with regard to environmental variables.

I am wanting to see which environmental variables ( I have about 20 of
them) influence different settling periods of a population of recently
released animals. The model I am looking for would ultimatley need to
identify different periods based on the animals changes in selection or
influence of variables on their locations over time since release. All
location data is spaced by a day or more, thereby removing factors of
autocorrelation.

Any help or suggestions would be greatly appreciated.

Regards
Simon Morgan

PhD candidate, University of KwaZulu-Natal.


------------------------------------------------------------------------------
South Africa's premier free email service - www.webmail.co.za
------------------------------------------------------------------------------
For super low premiums, click here http://home.webmail.co.za/dd.pwm


From carson.farmer at gmail.com  Wed Oct 28 14:38:26 2009
From: carson.farmer at gmail.com (Carson Farmer)
Date: Wed, 28 Oct 2009 13:38:26 +0000
Subject: [R-sig-Geo] Spatiotemporal data analysis
In-Reply-To: <64211.146.230.128.30.1256735625.squirrel@www.mighty.co.za>
References: <64211.146.230.128.30.1256735625.squirrel@www.mighty.co.za>
Message-ID: <94b3c8440910280638o1ad9529dhb6a2e0aa05f1a520@mail.gmail.com>

You might want to have a look at the adehabitat: Analysis of habitat
selection by animals plus more.

Carson

On Wed, Oct 28, 2009 at 1:13 PM, <simplemorgs at mighty.co.za> wrote:
>
> Hi,
> I am interested to know if anyone is aware of or have developed any
> software which can analyse both spatial and temporal ?animal movements
> with regard to environmental variables.
>
> I am wanting to see which environmental variables ( I have about 20 of
> them) influence different settling periods of a population of recently
> released animals. The model I am looking for would ultimatley need to
> identify different periods based on the animals changes in selection or
> influence of variables on their locations over time since release. All
> location data is spaced by a day or more, thereby removing factors of
> autocorrelation.
>
> Any help or suggestions would be greatly appreciated.
>
> Regards
> Simon Morgan
>
> PhD candidate, University of KwaZulu-Natal.
>
>
> ------------------------------------------------------------------------------
> South Africa's premier free email service - www.webmail.co.za
> ------------------------------------------------------------------------------
> For super low premiums, click here http://home.webmail.co.za/dd.pwm
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



--
Carson Farmer
National Centre for Geocomputation
John Hume Building,
National University of Ireland, Maynooth,
Maynooth,
Co. Kildare,
Ireland.
www.carsonfarmer.com


From mudiver1200 at yahoo.com  Wed Oct 28 22:44:00 2009
From: mudiver1200 at yahoo.com (Tim Clark)
Date: Wed, 28 Oct 2009 14:44:00 -0700 (PDT)
Subject: [R-sig-Geo] Speed filter vmask() in argosfilter package
Message-ID: <147694.30855.qm@web36107.mail.mud.yahoo.com>

Dear List,

I am trying to filter animal tracking data based on speed using the vmask() function in argosfilter.  However, when I check the filtered data against speed that I compute in the adehabitat package it shows that the filter is not working correctly.  The vmask() function requires coordinates in long/lat while adehabitat requires it in UTM.  I would greatly appreciate it if someone could check my work and let me know what I am doing wrong.  I have included an example below using data from adehabitat.

Thanks,

Tim


library(argosfilter)
library(adehabitat)

#Data
data(puechabon)
locs <- puechabon$locs   #Dataframe with location and date for individual animal over time

#Adehabitat package
  #Variables
    xy <- locs[,c("X","Y")]  #Locations in UTM
    id<- as.character(locs$Name)
    da <- as.character(locs$Date)
    da <- as.POSIXct(strptime(as.character(locs$Date),"%y%m%d"))
  #Create ltraj
    tr1 <- as.ltraj(xy,date = da, id = id)

  #Calculate speed
      sp1<-lapply(ltr,function (l){l$dist/l$dt})            #Compute speed in m/sec
  #Unlist
    sp2<-round(unlist(sp1,recursive = TRUE),2)


#Argosfilter package
    #Transform coordinates to long/lat
      library(rgdal)
      SP.utm<-data.frame(locs[,c("X")],locs[,c("Y")])
      SP.utm<-SpatialPoints(SP.utm,proj4string=CRS("+proj=utm +zone=31 +ellps=WGS84"))
      SP.ll<-spTransform(SP.utm, CRS("+proj=longlat +ellps=WGS84"))
      SP.ll<-data.frame(SP.ll)
      names(SP.ll)<-c("lon","lat")

      lon<- SP.ll$lon
      lat<- SP.ll$lat

    #filter by speed
      mfilter<-vmask(lat,lon,dtime=da,vmax=1)
      filtered<- locs[mfilter!=c("removed"),]

#Adehabitat package
    #Create ltraj
    xy <- filtered[,c("X","Y")]
    id<- as.character(filtered$Name)
    da <- as.character(filtered$Date)
    da <- as.POSIXct(strptime(as.character(filtered$Date),"%y%m%d"))
    tr1 <- as.ltraj(xy,date = da, id = id)

    #Calculate speed
        sp3<-lapply(ltr,function (l){l$dist/l$dt})            #Compute speed in m/sec
      #Unlist
        sp4<-round(unlist(sp1,recursive = TRUE),2)

#Check data
  quantile(sp2, probs = seq(.5, 1, 0.1), na.rm = TRUE)
  quantile(sp4, probs = seq(.5, 1, 0.1), na.rm = TRUE)





Tim Clark
Department of Zoology 
University of Hawaii


From tankisothejane at yahoo.com  Thu Oct 29 01:52:19 2009
From: tankisothejane at yahoo.com (TANKISO THEJANE)
Date: Wed, 28 Oct 2009 17:52:19 -0700 (PDT)
Subject: [R-sig-Geo] Univeral kriging
Message-ID: <535765.49762.qm@web46402.mail.sp1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091028/cdc7e1d2/attachment.pl>

From mdsumner at gmail.com  Thu Oct 29 02:15:45 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 29 Oct 2009 12:15:45 +1100
Subject: [R-sig-Geo] Speed filter vmask() in argosfilter package
In-Reply-To: <147694.30855.qm@web36107.mail.mud.yahoo.com>
References: <147694.30855.qm@web36107.mail.mud.yahoo.com>
Message-ID: <522664f80910281815p41a1e85ek1a9ffe84687f8be6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091029/135558a0/attachment.pl>

From mdsumner at gmail.com  Thu Oct 29 02:22:28 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 29 Oct 2009 12:22:28 +1100
Subject: [R-sig-Geo] Speed filter vmask() in argosfilter package
In-Reply-To: <522664f80910281815p41a1e85ek1a9ffe84687f8be6@mail.gmail.com>
References: <147694.30855.qm@web36107.mail.mud.yahoo.com>
	<522664f80910281815p41a1e85ek1a9ffe84687f8be6@mail.gmail.com>
Message-ID: <522664f80910281822r88b44dcyc90759d7d918e2d6@mail.gmail.com>

Sorry all, I didn't notice I was sending RTF emails. Hopefully this
will rectify:



On Thu, Oct 29, 2009 at 12:15 PM, Michael Sumner <mdsumner at gmail.com> wrote:
> I don't see "ltr" defined in your code. Is that meant to be "tr1"
> throughout?
>
>
>
> On Thu, Oct 29, 2009 at 8:44 AM, Tim Clark <mudiver1200 at yahoo.com> wrote:
>>
>> Dear List,
>>
>> I am trying to filter animal tracking data based on speed using the
>> vmask() function in argosfilter. ?However, when I check the filtered data
>> against speed that I compute in the adehabitat package it shows that the
>> filter is not working correctly. ?The vmask() function requires coordinates
>> in long/lat while adehabitat requires it in UTM. ?I would greatly appreciate
>> it if someone could check my work and let me know what I am doing wrong. ?I
>> have included an example below using data from adehabitat.
>>
>> Thanks,
>>
>> Tim
>>
>>
>> library(argosfilter)
>> library(adehabitat)
>>
>> #Data
>> data(puechabon)
>> locs <- puechabon$locs ? #Dataframe with location and date for individual
>> animal over time
>>
>> #Adehabitat package
>> ?#Variables
>> ? ?xy <- locs[,c("X","Y")] ?#Locations in UTM
>> ? ?id<- as.character(locs$Name)
>> ? ?da <- as.character(locs$Date)
>> ? ?da <- as.POSIXct(strptime(as.character(locs$Date),"%y%m%d"))
>> ?#Create ltraj
>> ? ?tr1 <- as.ltraj(xy,date = da, id = id)
>>
>> ?#Calculate speed
>> ? ? ?sp1<-lapply(ltr,function (l){l$dist/l$dt}) ? ? ? ? ? ?#Compute speed
>> in m/sec
>> ?#Unlist
>> ? ?sp2<-round(unlist(sp1,recursive = TRUE),2)
>>
>>
>> #Argosfilter package
>> ? ?#Transform coordinates to long/lat
>> ? ? ?library(rgdal)
>> ? ? ?SP.utm<-data.frame(locs[,c("X")],locs[,c("Y")])
>> ? ? ?SP.utm<-SpatialPoints(SP.utm,proj4string=CRS("+proj=utm +zone=31
>> +ellps=WGS84"))
>> ? ? ?SP.ll<-spTransform(SP.utm, CRS("+proj=longlat +ellps=WGS84"))
>> ? ? ?SP.ll<-data.frame(SP.ll)
>> ? ? ?names(SP.ll)<-c("lon","lat")
>>
>> ? ? ?lon<- SP.ll$lon
>> ? ? ?lat<- SP.ll$lat
>>
>> ? ?#filter by speed
>> ? ? ?mfilter<-vmask(lat,lon,dtime=da,vmax=1)
>> ? ? ?filtered<- locs[mfilter!=c("removed"),]
>>
>> #Adehabitat package
>> ? ?#Create ltraj
>> ? ?xy <- filtered[,c("X","Y")]
>> ? ?id<- as.character(filtered$Name)
>> ? ?da <- as.character(filtered$Date)
>> ? ?da <- as.POSIXct(strptime(as.character(filtered$Date),"%y%m%d"))
>> ? ?tr1 <- as.ltraj(xy,date = da, id = id)
>>
>> ? ?#Calculate speed
>> ? ? ? ?sp3<-lapply(ltr,function (l){l$dist/l$dt}) ? ? ? ? ? ?#Compute
>> speed in m/sec
>> ? ? ?#Unlist
>> ? ? ? ?sp4<-round(unlist(sp1,recursive = TRUE),2)
>>
>> #Check data
>> ?quantile(sp2, probs = seq(.5, 1, 0.1), na.rm = TRUE)
>> ?quantile(sp4, probs = seq(.5, 1, 0.1), na.rm = TRUE)
>>
>>
>>
>>
>>
>> Tim Clark
>> Department of Zoology
>> University of Hawaii
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From schlather at math.uni-goettingen.de  Thu Oct 29 05:49:45 2009
From: schlather at math.uni-goettingen.de (Martin Schlather)
Date: Thu, 29 Oct 2009 05:49:45 +0100
Subject: [R-sig-Geo] Spring School on Space-Time Modelling
Message-ID: <4AE91EE9.4030405@math.uni-goettingen.de>

Dear all,

An international Spring School on

   "Advances and Challenges in Space-Time Modelling of Natural Events"

will be held

    17-21 March 2010 in Toledo (Spain),

jointly organised by the University of Goettingen and
the University of Castilla la Mancha.

This Spring School addresses mainly to young researchers
(Master students, PhD students, PostDoc researchers) in academics,
extra-universitary research and industry, who are interested to
learn about recent developments, new methods and applications
in spatial statistics and to exchange their ideas and results
with colleagues.

The lecturers and subjects will be:
  1. Denis Allard: Non-Gaussian Random Fields
  2. Marc Genton: Multivariate Random Fields
  3. Tilmann Gneiting: Space-time Geostatistics
  4. Finn Lindgren: Markov Random Fields
  5. Werner Mueller: Spatial Design
  6. Maria Dolores Ruiz Medina: Simulations of Random Fields
  7. Paulo Ribeiro: Model-Based Geostatistics
  8. Martin Schlather: Spatial Extreme Value Processes
  9. Thordis Thorarisdottir: Space-time point processes

For further information see
http://www.stochastik.math.uni-goettingen.de/spatial_toledo_jones/

We look forward to seeing you in Toledo!

On behalf of the Organising Committee,
Martin Schlather

-- 
Prof. Dr. Martin Schlather
Institut f?r Mathematische Stochastik & Zentrum f?r Statistik
Georg-August-Universit?t G?ttingen
Goldschmidtstr. 7, 5.111
D -- 37077 G?ttingen

schlather at math.uni-goettingen.de
http://www.stochastik.math.uni-goettingen.de/~schlather
http://zfs.uni-goettingen.de/
phone: +49 (0)551 39 17 2131       fax : +49 (0)551 39 13 505


From michael.denslow at gmail.com  Thu Oct 29 14:38:03 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Thu, 29 Oct 2009 09:38:03 -0400
Subject: [R-sig-Geo] help with args to CRS(), spTransform
Message-ID: <b440a3f80910290638m3dba08fev4677578ed37e50f1@mail.gmail.com>

Dear List,

I am attending to transform a set of points that are originally in
latitude longitude (unprojected) to a Lambert Conformal Conic
projection.
I am a bit confused about the arguments to CRS and would appreciate any help.

I have an old file that contains point distances that were measured
with the following projection information. This is from ArcMap which I
no longer use. I need to use this old file to compare with my new
distances.

Projected Coordinate System: NAD_1983_StatePlane_North_Carolina_FIPS_3200
Projection: Lambert_Conformal_Conic
False_Easting: 609601.22000000
False_Northing: 0.00000000
Central_Meridian: -79.00000000
Standard_Parallel_1: 34.33333333
Standard_Parallel_2: 36.16666667
Latitude_Of_Origin: 33.75000000
Linear Unit: Meter

Geographic Coordinate System: GCS_North_American_1983
Datum: D_North_American_1983
Prime Meridian: Greenwich
Angular Unit: Degree

I would like the new point distance measurements that I am doing in
SPATSTAT to be comparable to the old ones that used the projection
above (in meters?).

Here is what I have attempted...

library(sp)
library(rgdal)
# dput(herb.sp) I hope this works I have never used dput() before!

new("SpatialPoints"
    , coords = structure(c(-81.6809, -78.9455, -77.879, -83.1031, -78.6634,
-79.057, 36.2147, 35.9982, 34.227, 35.2571, 35.7853, 35.9097), .Dim = c(6L,
2L), .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
    , bbox = structure(c(-83.1031, 34.227, -77.879, 36.2147), .Dim = c(2L,
2L), .Dimnames = list(NULL, c("min", "max")))
    , proj4string = new("CRS"
    , projargs = " +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
)
)

herb.lcc <- spTransform(herb.sp,CRS("+proj=lcc"))


I am not sure that this contains all of the arguments needed. I tried
looking at the PROG.4 manual here:
ftp://ftp.remotesensing.org/proj/OF90-284.pdf , but I am still unclear
how to proceed.

Any help would be most appreciated!
Thanks again,
Michael



-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From Roger.Bivand at nhh.no  Thu Oct 29 22:17:38 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 29 Oct 2009 22:17:38 +0100 (CET)
Subject: [R-sig-Geo] help with args to CRS(), spTransform
In-Reply-To: <b440a3f80910290638m3dba08fev4677578ed37e50f1@mail.gmail.com>
References: <b440a3f80910290638m3dba08fev4677578ed37e50f1@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0910292213130.21186@reclus.nhh.no>

On Thu, 29 Oct 2009, Michael Denslow wrote:

> Dear List,
>
> I am attending to transform a set of points that are originally in
> latitude longitude (unprojected) to a Lambert Conformal Conic
> projection.
> I am a bit confused about the arguments to CRS and would appreciate any help.

Use one of the EPSG references, www.spatialreference.org, or the built in 
one:

library(rgdal)
EPSG <- make_EPSG()
EPSG[grep("North Carolina", EPSG$note),]

The second one looks promising, so try:

CRS("+init=epsg:3358")

checking on:

http://www.spatialreference.org/ref/epsg/3358/

Hope this helps,

Roger

>
> I have an old file that contains point distances that were measured
> with the following projection information. This is from ArcMap which I
> no longer use. I need to use this old file to compare with my new
> distances.
>
> Projected Coordinate System: NAD_1983_StatePlane_North_Carolina_FIPS_3200
> Projection: Lambert_Conformal_Conic
> False_Easting: 609601.22000000
> False_Northing: 0.00000000
> Central_Meridian: -79.00000000
> Standard_Parallel_1: 34.33333333
> Standard_Parallel_2: 36.16666667
> Latitude_Of_Origin: 33.75000000
> Linear Unit: Meter
>
> Geographic Coordinate System: GCS_North_American_1983
> Datum: D_North_American_1983
> Prime Meridian: Greenwich
> Angular Unit: Degree
>
> I would like the new point distance measurements that I am doing in
> SPATSTAT to be comparable to the old ones that used the projection
> above (in meters?).
>
> Here is what I have attempted...
>
> library(sp)
> library(rgdal)
> # dput(herb.sp) I hope this works I have never used dput() before!
>
> new("SpatialPoints"
>    , coords = structure(c(-81.6809, -78.9455, -77.879, -83.1031, -78.6634,
> -79.057, 36.2147, 35.9982, 34.227, 35.2571, 35.7853, 35.9097), .Dim = c(6L,
> 2L), .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>    , bbox = structure(c(-83.1031, 34.227, -77.879, 36.2147), .Dim = c(2L,
> 2L), .Dimnames = list(NULL, c("min", "max")))
>    , proj4string = new("CRS"
>    , projargs = " +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
> )
> )
>
> herb.lcc <- spTransform(herb.sp,CRS("+proj=lcc"))
>
>
> I am not sure that this contains all of the arguments needed. I tried
> looking at the PROG.4 manual here:
> ftp://ftp.remotesensing.org/proj/OF90-284.pdf , but I am still unclear
> how to proceed.
>
> Any help would be most appreciated!
> Thanks again,
> Michael
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From michael.denslow at gmail.com  Fri Oct 30 00:57:59 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Thu, 29 Oct 2009 19:57:59 -0400
Subject: [R-sig-Geo] help with args to CRS(), spTransform
In-Reply-To: <alpine.LRH.2.00.0910292213130.21186@reclus.nhh.no>
References: <b440a3f80910290638m3dba08fev4677578ed37e50f1@mail.gmail.com>
	<alpine.LRH.2.00.0910292213130.21186@reclus.nhh.no>
Message-ID: <b440a3f80910291657t760b58bfjdc5486ad0878f469@mail.gmail.com>

Hi Roger,

>> Dear List,
>>
>> I am attending to transform a set of points that are originally in
>> latitude longitude (unprojected) to a Lambert Conformal Conic
>> projection.
>> I am a bit confused about the arguments to CRS and would appreciate any
>> help.
>
> Use one of the EPSG references, www.spatialreference.org, or the built in
> one:

Great to know about this site.

>
> library(rgdal)
> EPSG <- make_EPSG()
> EPSG[grep("North Carolina", EPSG$note),]
>
> The second one looks promising, so try:
>
> CRS("+init=epsg:3358")
>
> checking on:
>
> http://www.spatialreference.org/ref/epsg/3358/
>
> Hope this helps,


Fantastic, just what I was looking for.

Thank you again,

Michael

>
> Roger
>
>>
>> I have an old file that contains point distances that were measured
>> with the following projection information. This is from ArcMap which I
>> no longer use. I need to use this old file to compare with my new
>> distances.
>>
>> Projected Coordinate System: NAD_1983_StatePlane_North_Carolina_FIPS_3200
>> Projection: Lambert_Conformal_Conic
>> False_Easting: 609601.22000000
>> False_Northing: 0.00000000
>> Central_Meridian: -79.00000000
>> Standard_Parallel_1: 34.33333333
>> Standard_Parallel_2: 36.16666667
>> Latitude_Of_Origin: 33.75000000
>> Linear Unit: Meter
>>
>> Geographic Coordinate System: GCS_North_American_1983
>> Datum: D_North_American_1983
>> Prime Meridian: Greenwich
>> Angular Unit: Degree
>>
>> I would like the new point distance measurements that I am doing in
>> SPATSTAT to be comparable to the old ones that used the projection
>> above (in meters?).
>>
>> Here is what I have attempted...
>>
>> library(sp)
>> library(rgdal)
>> # dput(herb.sp) I hope this works I have never used dput() before!
>>
>> new("SpatialPoints"
>> ? , coords = structure(c(-81.6809, -78.9455, -77.879, -83.1031, -78.6634,
>> -79.057, 36.2147, 35.9982, 34.227, 35.2571, 35.7853, 35.9097), .Dim =
>> c(6L,
>> 2L), .Dimnames = list(NULL, c("coords.x1", "coords.x2")))
>> ? , bbox = structure(c(-83.1031, 34.227, -77.879, 36.2147), .Dim = c(2L,
>> 2L), .Dimnames = list(NULL, c("min", "max")))
>> ? , proj4string = new("CRS"
>> ? , projargs = " +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0"
>> )
>> )
>>
>> herb.lcc <- spTransform(herb.sp,CRS("+proj=lcc"))
>>
>>
>> I am not sure that this contains all of the arguments needed. I tried
>> looking at the PROG.4 manual here:
>> ftp://ftp.remotesensing.org/proj/OF90-284.pdf , but I am still unclear
>> how to proceed.
>>
>> Any help would be most appreciated!
>> Thanks again,
>> Michael
>>
>>
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From pota0011 at umn.edu  Fri Oct 30 04:34:11 2009
From: pota0011 at umn.edu (pota0011 at umn.edu)
Date: 29 Oct 2009 22:34:11 -0500
Subject: [R-sig-Geo] write.sn2gwt and lost region.id
Message-ID: <Gophermail.2.0.0910292234110.4646@vs-a.tc.umn.edu>

Hi,
I wanted to confirm that there is still no straightforward way to pass 
region.id values to a GWT file when using write.sn2gwt, as this post from 
two years ago suggests:
http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg02209.html

GeoDa needs the particular region.id values to, for example, make 
histograms from weight files. It seems that these are passed fine for GAL 
files with write.nb.gal, but not GWT files. Does anyone know of a 
work-around?

Thanks,
John


From friendly at yorku.ca  Fri Oct 30 14:59:59 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 30 Oct 2009 09:59:59 -0400
Subject: [R-sig-Geo] John Snow's cholera data/map: a more sp-ish way?
Message-ID: <4AEAF15F.2090203@yorku.ca>

Hi

In a new package, HistData, on R-Forge, I have a collection of 
historical data sets, some map-related,
including the map and data related to John Snow's famous map of the 1854 
cholera outbreak in London.
https://r-forge.r-project.org/projects/histdata/

I have two examples in example(Snow) that re-create the map of deaths, 
one showing Theissen polygon
boundaries around the water pumps, the other showing  bivariate density 
contours, but they are entirely
done using base graphics and ordinary data frames.  I'm wondering if 
anyone is willing to help me show
a more sp-ish way to organize the data and map info and make these and 
other plots.
More generally, I would welcome any other contributions to this project.

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From Roger.Bivand at nhh.no  Fri Oct 30 15:16:45 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Oct 2009 15:16:45 +0100 (CET)
Subject: [R-sig-Geo] write.sn2gwt and lost region.id
In-Reply-To: <Gophermail.2.0.0910292234110.4646@vs-a.tc.umn.edu>
References: <Gophermail.2.0.0910292234110.4646@vs-a.tc.umn.edu>
Message-ID: <alpine.LRH.2.00.0910301439420.25398@reclus.nhh.no>

On Fri, 29 Oct 2009, pota0011 at umn.edu wrote:

> Hi,
> I wanted to confirm that there is still no straightforward way to pass 
> region.id values to a GWT file when using write.sn2gwt, as this post from two 
> years ago suggests:
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg02209.html
>
> GeoDa needs the particular region.id values to, for example, make histograms 
> from weight files. It seems that these are passed fine for GAL files with 
> write.nb.gal, but not GWT files. Does anyone know of a work-around?

I'll try to implement this - which version of GeoDa and/or OpenGeoDa are 
you using? I think the revision works for classic GeoDa, but OpenGeoDa 
cannot open GWT files that it itself has created when the IDs are not 1, 
..., N.

Best wishes,

Roger

>
> Thanks,
> John
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Fri Oct 30 15:25:40 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Oct 2009 15:25:40 +0100 (CET)
Subject: [R-sig-Geo] John Snow's cholera data/map: a more sp-ish way?
In-Reply-To: <4AEAF15F.2090203@yorku.ca>
References: <4AEAF15F.2090203@yorku.ca>
Message-ID: <alpine.LRH.2.00.0910301519580.25612@reclus.nhh.no>

On Fri, 30 Oct 2009, Michael Friendly wrote:

> Hi
>
> In a new package, HistData, on R-Forge, I have a collection of historical 
> data sets, some map-related,
> including the map and data related to John Snow's famous map of the 1854 
> cholera outbreak in London.
> https://r-forge.r-project.org/projects/histdata/
>
> I have two examples in example(Snow) that re-create the map of deaths, one 
> showing Theissen polygon
> boundaries around the water pumps, the other showing  bivariate density 
> contours, but they are entirely
> done using base graphics and ordinary data frames.  I'm wondering if anyone 
> is willing to help me show
> a more sp-ish way to organize the data and map info and make these and other 
> plots.
> More generally, I would welcome any other contributions to this project.

Michael,

This is good news. I'm sorry that I didn't respond to your message about 
the Guerry dataset from almost two weeks ago, I ought to have done. I'll 
try to get back to you on both that question:

https://stat.ethz.ch/pipermail/r-sig-geo/2009-October/006673.html

and this one. I encourage others to join in, because the R-forge package 
has the potential to become a valuable resource.

Best wishes,

Roger

>
> -Michael
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Fri Oct 30 15:59:02 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Oct 2009 15:59:02 +0100 (CET)
Subject: [R-sig-Geo] Guerry data: making a package
In-Reply-To: <4AD9FDAA.7020807@yorku.ca>
References: <4AD9FDAA.7020807@yorku.ca>
Message-ID: <alpine.LRH.2.00.0910301540070.25612@reclus.nhh.no>

On Sat, 17 Oct 2009, Michael Friendly wrote:

> Hi
>
> Several years ago I sought & received help (thanks!) from people on this list 
> regarding map and data
> files associated with my article, A.M. Guerry's Moral Statistics of France: 
> Challenges for multivariate spatial analysis,
> that appeared in Statistical Science, 2007, 22,368-399.  As supplementary 
> materials for that article, I prepared
> http://www.math.yorku.ca/SCS/Gallery/guerry/
>
> and also included map and data files for R at
> http://www.math.yorku.ca/SCS/Gallery/guerry/maps.html#R
> but these were really just a sketch that required more work to make them 
> fully usable.
>
> Now I'd like to make an R package including the gfrance1 map and the guerry 
> data, and other things,
> but I found that something in maptools or other packages had changed, so that 
> a script that worked
> for me with these map files back in Aug, 2008 does so no longer:
>
>> library(sp)
>> library(maptools)
>> gfrance <- readShapeSpatial("gfrance1")
> Error in read.shape(filen = fn, verbose = verbose, repair = repair) :
> File size and implied file size differ, consider trying repair=TRUE
>
> I get the same error with readShapePoly().

readShapeSpatial() is a wrapper for readShapePoly() and others, choosing 
on shape type. The message suggests that the *.shx file is not as 
expected.

With a freshly downloaded copy from your website, I cannot reproduce the 
problem, and gfrance1.shp reads correctly on:

> sessionInfo()
R version 2.10.0 (2009-10-26)
i686-pc-linux-gnu

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] maptools_0.7-26 foreign_0.8-38  sp_0.9-44

loaded via a namespace (and not attached):
[1] grid_2.10.0     lattice_0.17-26



>
> Once I can get that sorted out, it's not exactly clear to me exactly how to 
> prepare map files
> (SpatialPolygonsDataFrame) for a package with appropriate documentation. 
> Using
> another version of the Guerry map and data (omitting Corsica) provided by 
> Stephane Dray, I *could* read it
> successfully, then tried
>
>> cd("dray")
>> gfrance85 <- readShapePoly("gfrance1")
>> save(gfrance85, file="gfrance85.rda")
>> prompt(gfrance85)
> Created file named 'gfrance85.Rd'.
> Edit the file and move it to the appropriate directory.
>
> There is no prompt method for SpatialPolygonsDataFrame objects, so 
> prompt() just dumps the entire results of str(gfrance85); I can of 
> course edit out the @ polygons list. Is this the recommended way to 
> include such objects in packages?

The prompt method for data either identifies data.frame objects or dumps 
the object. For me,

prompt(as(gfrance, "data.frame"), name="gfrance")

looks easier to edit, adding the class details.

Hope this helps,

Roger

> Thanks, -Michael
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From friendly at yorku.ca  Fri Oct 30 17:42:27 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 30 Oct 2009 12:42:27 -0400
Subject: [R-sig-Geo] Guerry data: making a package
In-Reply-To: <alpine.LRH.2.00.0910301540070.25612@reclus.nhh.no>
References: <4AD9FDAA.7020807@yorku.ca>
	<alpine.LRH.2.00.0910301540070.25612@reclus.nhh.no>
Message-ID: <4AEB1773.2080208@yorku.ca>

Thanks, Roger

I was able to sort out my problems with reading the Guerry data/map with 
the help of Stephane Dray.
There is now an R-Forge project, Guerry, containing what we have 
assembled so far.
https://r-forge.r-project.org/projects/guerry/

In the .Rd files for the SpatialPolygonsDataFrames, gfrance & gfrance85 
included in the package, I
note that no PROJ4 information is provided, because we weren't sure 
exactly what to specify.

On my web page, I noted that you had earlier suggested
The projection here seems to be France ED50 EuroLambert, Lambert Conic 
Conformal with parameters set for continental France. Roger says: In 
PROJ.4 this is:

+proj=lcc +lat_1=46.8 +lat_0=46.8
+lon_0=2.337229166666667 +k_0=0.99987742 +x_0=600000 +y_0=2200000
+ellps=intl +units=m 

Given that:

 > slot(gfrance,"proj4string")
CRS arguments: NA

what can I specify to make this more spatial-friendly in a package?  I 
don't know what a lot of
that stuff means, but if I'm creating a package, I'd like it to be 
minimally sufficient for others to
use in different contexts.

-Michael


Roger Bivand wrote:
> On Sat, 17 Oct 2009, Michael Friendly wrote:
>
>> Hi
>>
>> Several years ago I sought & received help (thanks!) from people on 
>> this list regarding map and data
>> files associated with my article, A.M. Guerry's Moral Statistics of 
>> France: Challenges for multivariate spatial analysis,
>> that appeared in Statistical Science, 2007, 22,368-399.  As 
>> supplementary materials for that article, I prepared
>> http://www.math.yorku.ca/SCS/Gallery/guerry/
>>
>> and also included map and data files for R at
>> http://www.math.yorku.ca/SCS/Gallery/guerry/maps.html#R
>> but these were really just a sketch that required more work to make 
>> them fully usable.
>>
>> Now I'd like to make an R package including the gfrance1 map and the 
>> guerry data, and other things,
>> but I found that something in maptools or other packages had changed, 
>> so that a script that worked
>> for me with these map files back in Aug, 2008 does so no longer:
>>
>>> library(sp)
>>> library(maptools)
>>> gfrance <- readShapeSpatial("gfrance1")
>> Error in read.shape(filen = fn, verbose = verbose, repair = repair) :
>> File size and implied file size differ, consider trying repair=TRUE
>>
>> I get the same error with readShapePoly().
>
> readShapeSpatial() is a wrapper for readShapePoly() and others, 
> choosing on shape type. The message suggests that the *.shx file is 
> not as expected.
>
> With a freshly downloaded copy from your website, I cannot reproduce 
> the problem, and gfrance1.shp reads correctly on:
>
>> sessionInfo()
> R version 2.10.0 (2009-10-26)
> i686-pc-linux-gnu
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] maptools_0.7-26 foreign_0.8-38  sp_0.9-44
>
> loaded via a namespace (and not attached):
> [1] grid_2.10.0     lattice_0.17-26
>
>
>
>>
>> Once I can get that sorted out, it's not exactly clear to me exactly 
>> how to prepare map files
>> (SpatialPolygonsDataFrame) for a package with appropriate 
>> documentation. Using
>> another version of the Guerry map and data (omitting Corsica) 
>> provided by Stephane Dray, I *could* read it
>> successfully, then tried
>>
>>> cd("dray")
>>> gfrance85 <- readShapePoly("gfrance1")
>>> save(gfrance85, file="gfrance85.rda")
>>> prompt(gfrance85)
>> Created file named 'gfrance85.Rd'.
>> Edit the file and move it to the appropriate directory.
>>
>> There is no prompt method for SpatialPolygonsDataFrame objects, so 
>> prompt() just dumps the entire results of str(gfrance85); I can of 
>> course edit out the @ polygons list. Is this the recommended way to 
>> include such objects in packages?
>
> The prompt method for data either identifies data.frame objects or 
> dumps the object. For me,
>
> prompt(as(gfrance, "data.frame"), name="gfrance")
>
> looks easier to edit, adding the class details.
>
> Hope this helps,
>
> Roger
>
>> Thanks, -Michael
>>
>>
>>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From dray at biomserv.univ-lyon1.fr  Fri Oct 30 18:36:49 2009
From: dray at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?St=E9phane_Dray?=)
Date: Fri, 30 Oct 2009 18:36:49 +0100
Subject: [R-sig-Geo] John Snow's cholera data/map: a more sp-ish way?
In-Reply-To: <alpine.LRH.2.00.0910301519580.25612@reclus.nhh.no>
References: <4AEAF15F.2090203@yorku.ca>
	<alpine.LRH.2.00.0910301519580.25612@reclus.nhh.no>
Message-ID: <4AEB2431.1000609@biomserv.univ-lyon1.fr>

Hi Michael,

I tried to play with the streets and transform them into a spatialLines by:

l1=split(Snow.streets[,3:4],as.factor(Snow.streets[,1]))
Ll1=lapply(l1,Line)
Lsl1=Lines(Ll1,paste("Street",1:length(Ll1)))
Snow.streets.sp=SpatialLines(list(Lsl1))
plot(Snow.streets.sp)

For the pumps:

spp=SpatialPoints(Snow.pumps[,3:4])
Snow.pumps.sp=SpatialPointsDataFrame(spp,Snow.pumps[,1:2])
plot(Snow.pumps.sp,add=T,col='red',pch=20)

For the deaths:

Snow.death.sp = SpatialPoints(Snow.deaths[,2:3])
plot(Snow.death.sp,add= T, col ='blue')

For polygons, I think that it should be a little bit more complicated.. 
but I have no time today to have a look at it.

Is it correct Roger?

Cheers.


Roger Bivand wrote:
> On Fri, 30 Oct 2009, Michael Friendly wrote:
>
>> Hi
>>
>> In a new package, HistData, on R-Forge, I have a collection of 
>> historical data sets, some map-related,
>> including the map and data related to John Snow's famous map of the 
>> 1854 cholera outbreak in London.
>> https://r-forge.r-project.org/projects/histdata/
>>
>> I have two examples in example(Snow) that re-create the map of 
>> deaths, one showing Theissen polygon
>> boundaries around the water pumps, the other showing  bivariate 
>> density contours, but they are entirely
>> done using base graphics and ordinary data frames.  I'm wondering if 
>> anyone is willing to help me show
>> a more sp-ish way to organize the data and map info and make these 
>> and other plots.
>> More generally, I would welcome any other contributions to this project.
>
> Michael,
>
> This is good news. I'm sorry that I didn't respond to your message 
> about the Guerry dataset from almost two weeks ago, I ought to have 
> done. I'll try to get back to you on both that question:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2009-October/006673.html
>
> and this one. I encourage others to join in, because the R-forge 
> package has the potential to become a valuable resource.
>
> Best wishes,
>
> Roger
>
>>
>> -Michael
>>
>>
>

-- 
St?phane DRAY (dray at biomserv.univ-lyon1.fr )
Laboratoire BBE-CNRS-UMR-5558, Univ. C. Bernard - Lyon I
43, Bd du 11 Novembre 1918, 69622 Villeurbanne Cedex, France
Tel: 33 4 72 43 27 57       Fax: 33 4 72 43 13 88
http://pbil.univ-lyon1.fr/members/dray/


From murray_richardson at carleton.ca  Fri Oct 30 18:59:34 2009
From: murray_richardson at carleton.ca (Murray Richardson)
Date: Fri, 30 Oct 2009 13:59:34 -0400
Subject: [R-sig-Geo] gstat memory
Message-ID: <4AEB2986.4070305@carleton.ca>

Hello R-SIG-GEO list,

I know this has come up before but I am having an ongoing memory problem 
with the gstat package (gstat out of dynamic memory) that I can't seem 
to solve.

I am using R to interpolate DEMs from LiDAR xyz point files and mosaic 
them together via RSAGA.  The script uses a loop to load in each xyz 
point file, and interpolate over a regular lattice of points using idw 
from gstat.  Although large, the computational requirements within each 
iteration of the loop should be well within my system's ability so it 
seems like it is a cumulative effect (note I can restart the process at 
the last loop that triggered the error and the iteration is 
successful).  I am removing temp objects and running gc() at the end of 
every loop.

It proceeds normally for about 5-10 iterations and physical memory use 
on my system (VISTA 64 bit, 12GB RAM) gradually increases over time 
until I get the "gstat out of memory" error. Here is the relevant 
portion of the loop:

...

   path<-"E:/LidarData/1_Ground_First_Return/UTM17/"
   filen<-paste(path, centre_tile$TILECODE, ".xyz", sep="")
   xyzi<-read.table(filen, sep=",", header=F)
   names(xyzi)<-c("x","y","z","i")

   for(j in 1:length(tile_group_names)){
       filen<-paste(path, tile_group_names[j], ".xyz", sep="")
       tmp_xyzi<-read.table(filen, sep=",", header=F)
       names(tmp_xyzi)<-c("x","y","z","i")
       xyzi<-rbind(xyzi,tmp_xyzi)

   }
       coordinates(xyzi)=~x+y
   # note grid_coords is just the regular lattice that is created from 
the current tile coordinates
   coordinates(grid_coords)=~x+y

   # do the interpolation
   interp<-idw(z~1, xyzi, grid_coords, nmax=4,maxdist=2, idp=1.0)

   names(interp)<-c("z","var")
   slot(interp,"data")<-data.frame(slot(interp,"data"))
   finalSPntsDF<-SpatialPointsDataFrame(interp, data.frame(interp$z),
               proj4string = CRS(as.character(NA)), match.ID = TRUE)


   finalSPDF<-SpatialPixelsDataFrame(finalSPntsDF, data.frame(interp$z), 
tolerance = sqrt(.Machine$double.eps),
     proj4string = CRS(as.character(NA)))

... 
On a related note - I have tried using the 64 bit version of Revolution 
but unfortunately the gstat package has not been ported.  Has anyone 
contemplated or begun a 64 bit port of this package?

Thanks

Murray


From alobolistas at gmail.com  Fri Oct 30 19:04:20 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 30 Oct 2009 19:04:20 +0100
Subject: [R-sig-Geo] rgdal binary for MAC OS 10.5 ?
Message-ID: <4AEB2AA4.9050905@gmail.com>

Hi!

Is there a binary version of rgdal for MAC OS 10.5 ? We could
not locate any with the Mac GUI for R.
Otherwise, is it very difficult to compile? Are there directions
anywhere?

Thanks!

Agus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091030/ce26981b/attachment.vcf>

From michael.denslow at gmail.com  Fri Oct 30 19:14:43 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Fri, 30 Oct 2009 14:14:43 -0400
Subject: [R-sig-Geo] rgdal binary for MAC OS 10.5 ?
In-Reply-To: <4AEB2AA4.9050905@gmail.com>
References: <4AEB2AA4.9050905@gmail.com>
Message-ID: <b440a3f80910301114i300b4a7djd9672502d389d2aa@mail.gmail.com>

Hi Agus,

On Fri, Oct 30, 2009 at 2:04 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> Is there a binary version of rgdal for MAC OS 10.5 ? We could
> not locate any with the Mac GUI for R.
> Otherwise, is it very difficult to compile? Are there directions
> anywhere?
>
> Thanks!
>
> Agus

Check out
http://www.kyngchaos.com/software:frameworks
to find a binary zip file for rgdal. It may not be the very latest version.
It is under the GDAL section.

There is a read me file that explains what to do to install it from the GUI.
I have GRASS on my machine so already had the frameworks that it needs.
The whole thing is a little confusing but if I can do it I am sure that you can.

Let me know how it goes...
Michael

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From mtognelli at lab.cricyt.edu.ar  Fri Oct 30 19:49:33 2009
From: mtognelli at lab.cricyt.edu.ar (Marcelo Tognelli)
Date: Fri, 30 Oct 2009 11:49:33 -0700
Subject: [R-sig-Geo] Spatial analysis question
Message-ID: <7111a5b70910301149x1abdb4a2hf41bf63b17dfbea2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091030/f221f360/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Oct 30 19:55:02 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 30 Oct 2009 19:55:02 +0100
Subject: [R-sig-Geo] gstat memory
In-Reply-To: <4AEB2986.4070305@carleton.ca>
References: <4AEB2986.4070305@carleton.ca>
Message-ID: <4AEB3686.4030000@uni-muenster.de>

Murray Richardson wrote:
> Hello R-SIG-GEO list,
>
> I know this has come up before but I am having an ongoing memory
> problem with the gstat package (gstat out of dynamic memory) that I
> can't seem to solve.
>
> I am using R to interpolate DEMs from LiDAR xyz point files and mosaic
> them together via RSAGA.  The script uses a loop to load in each xyz
> point file, and interpolate over a regular lattice of points using idw
> from gstat.  Although large, the computational requirements within
> each iteration of the loop should be well within my system's ability
> so it seems like it is a cumulative effect (note I can restart the
> process at the last loop that triggered the error and the iteration is
> successful).  I am removing temp objects and running gc() at the end
> of every loop.
>
> It proceeds normally for about 5-10 iterations and physical memory use
> on my system (VISTA 64 bit, 12GB RAM) gradually increases over time
> until I get the "gstat out of memory" error. Here is the relevant
> portion of the loop:
>
> ...
>
>   path<-"E:/LidarData/1_Ground_First_Return/UTM17/"
>   filen<-paste(path, centre_tile$TILECODE, ".xyz", sep="")
>   xyzi<-read.table(filen, sep=",", header=F)
>   names(xyzi)<-c("x","y","z","i")
>
>   for(j in 1:length(tile_group_names)){
>       filen<-paste(path, tile_group_names[j], ".xyz", sep="")
>       tmp_xyzi<-read.table(filen, sep=",", header=F)
>       names(tmp_xyzi)<-c("x","y","z","i")
>       xyzi<-rbind(xyzi,tmp_xyzi)
>
>   }
>       coordinates(xyzi)=~x+y
>   # note grid_coords is just the regular lattice that is created from
> the current tile coordinates
>   coordinates(grid_coords)=~x+y
>
>   # do the interpolation
>   interp<-idw(z~1, xyzi, grid_coords, nmax=4,maxdist=2, idp=1.0)
>
>   names(interp)<-c("z","var")
>   slot(interp,"data")<-data.frame(slot(interp,"data"))
>   finalSPntsDF<-SpatialPointsDataFrame(interp, data.frame(interp$z),
>               proj4string = CRS(as.character(NA)), match.ID = TRUE)
>
>
>   finalSPDF<-SpatialPixelsDataFrame(finalSPntsDF,
> data.frame(interp$z), tolerance = sqrt(.Machine$double.eps),
>     proj4string = CRS(as.character(NA)))
I'd say it has to be a memory leak. Note that gstat was originally not
written as a library; most of it was written before 1995, when R had not
been released as open source. Finding memory leaks is a nice challenge,
but little rewarding now that RAM is so cheap.
>
> ... On a related note - I have tried using the 64 bit version of
> Revolution but unfortunately the gstat package has not been ported. 
> Has anyone contemplated or begun a 64 bit port of this package?
Routinely, and out of the box, for over 5 years. However, not under
windows. I even missed that windows already comes as a 64 bit port,
these days!

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From friendly at yorku.ca  Fri Oct 30 20:19:51 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 30 Oct 2009 15:19:51 -0400
Subject: [R-sig-Geo] John Snow's cholera data/map: a more sp-ish way?
In-Reply-To: <4AEB2431.1000609@biomserv.univ-lyon1.fr>
References: <4AEAF15F.2090203@yorku.ca>
	<alpine.LRH.2.00.0910301519580.25612@reclus.nhh.no>
	<4AEB2431.1000609@biomserv.univ-lyon1.fr>
Message-ID: <4AEB3C57.9000302@yorku.ca>

Thanks, Stephane

This has most of the pieces.  The Snow.polygons aren't really polygons 
-- just a set of line segments
defining the boundaries of the Theissen/Voroni polygons giving the 
boundaries of the regions of deaths
"nearest" to each pump.  I was just including here what I got from Waldo 
Tobler, but there may have
been something more sophisticated than just Euclidean distance used here.
There may be a more sp-ish way to calculate these directly, or do 
something similar, from the Snow.deaths
and Snow.pumps.  The visual goal is to show the concentration of deaths 
around the Broad Street pump.

For the HistData package, I'd like to simplify this a bit, complete it, 
at least with a title and mapscale,
and consider if I should include some Spatial objects in the package 
directly or else leave this to the
example.

Why don't I get a title using main= below?
# streets
l1=split(Snow.streets[,c("x","y")],as.factor(Snow.streets[,"street"]))
Ll1=lapply(l1,Line)
Lsl1=Lines(Ll1,paste("Street",1:length(Ll1)))
Snow.streets.sp=SpatialLines(list(Lsl1))
plot(Snow.streets.sp, main="Snow's Cholera Map of London")

-Michael


St?phane Dray wrote:
> Hi Michael,
>
> I tried to play with the streets and transform them into a 
> spatialLines by:
>
> l1=split(Snow.streets[,3:4],as.factor(Snow.streets[,1]))
> Ll1=lapply(l1,Line)
> Lsl1=Lines(Ll1,paste("Street",1:length(Ll1)))
> Snow.streets.sp=SpatialLines(list(Lsl1))
> plot(Snow.streets.sp)
>
> For the pumps:
>
> spp=SpatialPoints(Snow.pumps[,3:4])
> Snow.pumps.sp=SpatialPointsDataFrame(spp,Snow.pumps[,1:2])
> plot(Snow.pumps.sp,add=T,col='red',pch=20)
>
> For the deaths:
>
> Snow.death.sp = SpatialPoints(Snow.deaths[,2:3])
> plot(Snow.death.sp,add= T, col ='blue')
>
> For polygons, I think that it should be a little bit more 
> complicated.. but I have no time today to have a look at it.
>
> Is it correct Roger?
>
> Cheers.
>
>
> Roger Bivand wrote:
>> On Fri, 30 Oct 2009, Michael Friendly wrote:
>>
>>> Hi
>>>
>>> In a new package, HistData, on R-Forge, I have a collection of 
>>> historical data sets, some map-related,
>>> including the map and data related to John Snow's famous map of the 
>>> 1854 cholera outbreak in London.
>>> https://r-forge.r-project.org/projects/histdata/
>>>
>>> I have two examples in example(Snow) that re-create the map of 
>>> deaths, one showing Theissen polygon
>>> boundaries around the water pumps, the other showing  bivariate 
>>> density contours, but they are entirely
>>> done using base graphics and ordinary data frames.  I'm wondering if 
>>> anyone is willing to help me show
>>> a more sp-ish way to organize the data and map info and make these 
>>> and other plots.
>>> More generally, I would welcome any other contributions to this 
>>> project.
>>
>> Michael,
>>
>> This is good news. I'm sorry that I didn't respond to your message 
>> about the Guerry dataset from almost two weeks ago, I ought to have 
>> done. I'll try to get back to you on both that question:
>>
>> https://stat.ethz.ch/pipermail/r-sig-geo/2009-October/006673.html
>>
>> and this one. I encourage others to join in, because the R-forge 
>> package has the potential to become a valuable resource.
>>
>> Best wishes,
>>
>> Roger
>>
>>>
>>> -Michael
>>>
>>>
>>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From pota0011 at umn.edu  Fri Oct 30 20:41:20 2009
From: pota0011 at umn.edu (pota0011 at umn.edu)
Date: 30 Oct 2009 14:41:20 -0500
Subject: [R-sig-Geo] write.sn2gwt and lost region.id
In-Reply-To: <alpine.LRH.2.00.0910301439420.25398@reclus.nhh.no>
References: <Gophermail.2.0.0910292234110.4646@vs-a.tc.umn.edu>
	<alpine.LRH.2.00.0910301439420.25398@reclus.nhh.no>
Message-ID: <Gophermail.2.0.0910301441200.10647@vs-w.tc.umn.edu>

I'm mostly working with classic GeoDa. It uses the legacy GWT format when 
creating/opening GWT files with Rec_Num 1,..N IDs. However, write.sn2gwt 
always uses the new format with the "shpfile" and "ind" fields, even though 
it doesn't pass region.ids. So it seems to me that one has to edit the 
header file to the old format by deleting everything by the number of IDs, 
before classic GeoDa can read the file. It would be great if write.sn2gwt 
could either pass the region.ids or alternatively have an option for 
creating the GWT file in legacy format. At least that's how I'm 
understanding things; let me know if there is something I'm missing.

Thanks,
John

On Oct 30 2009, Roger Bivand wrote:

>On Fri, 29 Oct 2009, pota0011 at umn.edu wrote:
>
>> Hi,
>> I wanted to confirm that there is still no straightforward way to pass 
>> region.id values to a GWT file when using write.sn2gwt, as this post 
>> from two
>> years ago suggests:
>> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg02209.html
>>
>> GeoDa needs the particular region.id values to, for example, make 
>> histograms
>> from weight files. It seems that these are passed fine for GAL files 
>> with
>> write.nb.gal, but not GWT files. Does anyone know of a work-around?
>
>I'll try to implement this - which version of GeoDa and/or OpenGeoDa are 
>you using? I think the revision works for classic GeoDa, but OpenGeoDa 
>cannot open GWT files that it itself has created when the IDs are not 1, 
>..., N.
>
>Best wishes,
>
>Roger
>
>>
>> Thanks,
>> John
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>


From mudiver1200 at yahoo.com  Fri Oct 30 22:41:19 2009
From: mudiver1200 at yahoo.com (Tim Clark)
Date: Fri, 30 Oct 2009 14:41:19 -0700 (PDT)
Subject: [R-sig-Geo] Speed filter vmask() in argosfilter package
In-Reply-To: <522664f80910281815p41a1e85ek1a9ffe84687f8be6@mail.gmail.com>
Message-ID: <493296.39395.qm@web36104.mail.mud.yahoo.com>

Michael,

Thanks!  I totally missed that. Now it works great.

Aloha,

Tim


Tim Clark
Department of Zoology 
University of Hawaii


--- On Wed, 10/28/09, Michael Sumner <mdsumner at gmail.com> wrote:

> From: Michael Sumner <mdsumner at gmail.com>
> Subject: Re: [R-sig-Geo] Speed filter vmask() in argosfilter package
> To: "Tim Clark" <mudiver1200 at yahoo.com>
> Cc: r-sig-geo at stat.math.ethz.ch
> Date: Wednesday, October 28, 2009, 3:15 PM
> I don't see "ltr"
> defined in your code. Is that meant to be "tr1"
> throughout? 
> ?
> 
> 
> ?
> On Thu, Oct 29, 2009 at 8:44 AM,
> Tim Clark <mudiver1200 at yahoo.com>
> wrote:
> 
> Dear
> List,
> 
> I am trying to filter animal tracking data based on speed
> using the vmask() function in argosfilter. ?However, when I
> check the filtered data against speed that I compute in the
> adehabitat package it shows that the filter is not working
> correctly. ?The vmask() function requires coordinates in
> long/lat while adehabitat requires it in UTM. ?I would
> greatly appreciate it if someone could check my work and let
> me know what I am doing wrong. ?I have included an example
> below using data from adehabitat.
> 
> 
> Thanks,
> 
> Tim
> 
> 
> library(argosfilter)
> library(adehabitat)
> 
> #Data
> data(puechabon)
> locs <- puechabon$locs ? #Dataframe with location and
> date for individual animal over time
> 
> #Adehabitat package
> 
> ?#Variables
> ? ?xy <- locs[,c("X","Y")]
> ?#Locations in UTM
> ? ?id<- as.character(locs$Name)
> ? ?da <- as.character(locs$Date)
> ? ?da <-
> as.POSIXct(strptime(as.character(locs$Date),"%y%m%d"))
> 
> ?#Create ltraj
> ? ?tr1 <- as.ltraj(xy,date = da, id = id)
> 
> ?#Calculate speed
> ? ? ?sp1<-lapply(ltr,function (l){l$dist/l$dt}) ? ?
> ? ? ? ?#Compute speed in m/sec
> ?#Unlist
> ? ?sp2<-round(unlist(sp1,recursive = TRUE),2)
> 
> 
> 
> #Argosfilter package
> ? ?#Transform coordinates to long/lat
> ? ? ?library(rgdal)
> ? ?
> ?SP.utm<-data.frame(locs[,c("X")],locs[,c("Y")])
> ? ?
> ?SP.utm<-SpatialPoints(SP.utm,proj4string=CRS("+proj=utm
> +zone=31 +ellps=WGS84"))
> 
> ? ? ?SP.ll<-spTransform(SP.utm,
> CRS("+proj=longlat +ellps=WGS84"))
> ? ? ?SP.ll<-data.frame(SP.ll)
> ? ?
> ?names(SP.ll)<-c("lon","lat")
> 
> ? ? ?lon<- SP.ll$lon
> ? ? ?lat<- SP.ll$lat
> 
> 
> ? ?#filter by speed
> ? ? ?mfilter<-vmask(lat,lon,dtime=da,vmax=1)
> ? ? ?filtered<-
> locs[mfilter!=c("removed"),]
> 
> #Adehabitat package
> ? ?#Create ltraj
> ? ?xy <- filtered[,c("X","Y")]
> 
> ? ?id<- as.character(filtered$Name)
> ? ?da <- as.character(filtered$Date)
> ? ?da <-
> as.POSIXct(strptime(as.character(filtered$Date),"%y%m%d"))
> ? ?tr1 <- as.ltraj(xy,date = da, id = id)
> 
> 
> ? ?#Calculate speed
> ? ? ? ?sp3<-lapply(ltr,function (l){l$dist/l$dt}) ?
> ? ? ? ? ?#Compute speed in m/sec
> ? ? ?#Unlist
> ? ? ? ?sp4<-round(unlist(sp1,recursive = TRUE),2)
> 
> #Check data
> ?quantile(sp2, probs = seq(.5, 1, 0.1), na.rm = TRUE)
> 
> ?quantile(sp4, probs = seq(.5, 1, 0.1), na.rm = TRUE)
> 
> 
> 
> 
> 
> Tim Clark
> Department of Zoology
> University of Hawaii
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 





From debeaudette at ucdavis.edu  Fri Oct 30 23:15:45 2009
From: debeaudette at ucdavis.edu (Dylan Beaudette)
Date: Fri, 30 Oct 2009 15:15:45 -0700
Subject: [R-sig-Geo] gstat memory
In-Reply-To: <4AEB2986.4070305@carleton.ca>
References: <4AEB2986.4070305@carleton.ca>
Message-ID: <200910301515.45787.dylan.beaudette@gmail.com>

On Friday 30 October 2009, Murray Richardson wrote:
> Hello R-SIG-GEO list,
>
> I know this has come up before but I am having an ongoing memory problem
> with the gstat package (gstat out of dynamic memory) that I can't seem
> to solve.
>
> I am using R to interpolate DEMs from LiDAR xyz point files and mosaic
> them together via RSAGA.  The script uses a loop to load in each xyz
> point file, and interpolate over a regular lattice of points using idw
> from gstat.  Although large, the computational requirements within each
> iteration of the loop should be well within my system's ability so it
> seems like it is a cumulative effect (note I can restart the process at
> the last loop that triggered the error and the iteration is
> successful).  I am removing temp objects and running gc() at the end of
> every loop.
>
> It proceeds normally for about 5-10 iterations and physical memory use
> on my system (VISTA 64 bit, 12GB RAM) gradually increases over time
> until I get the "gstat out of memory" error. Here is the relevant
> portion of the loop:
>

Hi,

If you aren't constrained to using R/SAGA, GRASS should be able to most of the 
interpolation in a single pass. Check out the modules v.surf.rst and 
v.surf.idw. I have head that people have routinely used v.surf.rst to 
interpolate point clouds 10-60Gb in size.

Cheers,
Dylan


>
>    path<-"E:/LidarData/1_Ground_First_Return/UTM17/"
>    filen<-paste(path, centre_tile$TILECODE, ".xyz", sep="")
>    xyzi<-read.table(filen, sep=",", header=F)
>    names(xyzi)<-c("x","y","z","i")
>
>    for(j in 1:length(tile_group_names)){
>        filen<-paste(path, tile_group_names[j], ".xyz", sep="")
>        tmp_xyzi<-read.table(filen, sep=",", header=F)
>        names(tmp_xyzi)<-c("x","y","z","i")
>        xyzi<-rbind(xyzi,tmp_xyzi)
>
>    }
>        coordinates(xyzi)=~x+y
>    # note grid_coords is just the regular lattice that is created from
> the current tile coordinates
>    coordinates(grid_coords)=~x+y
>
>    # do the interpolation
>    interp<-idw(z~1, xyzi, grid_coords, nmax=4,maxdist=2, idp=1.0)
>
>    names(interp)<-c("z","var")
>    slot(interp,"data")<-data.frame(slot(interp,"data"))
>    finalSPntsDF<-SpatialPointsDataFrame(interp, data.frame(interp$z),
>                proj4string = CRS(as.character(NA)), match.ID = TRUE)
>
>
>    finalSPDF<-SpatialPixelsDataFrame(finalSPntsDF, data.frame(interp$z),
> tolerance = sqrt(.Machine$double.eps),
>      proj4string = CRS(as.character(NA)))
>
> ...
> On a related note - I have tried using the 64 bit version of Revolution
> but unfortunately the gstat package has not been ported.  Has anyone
> contemplated or begun a 64 bit port of this package?
>
> Thanks
>
> Murray
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341


