From Thomas.Adams at noaa.gov  Mon May  1 13:56:20 2006
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Mon, 01 May 2006 07:56:20 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
 needed
In-Reply-To: <Pine.LNX.4.44.0604282119500.23449-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604282119500.23449-100000@reclus.nhh.no>
Message-ID: <4455F764.8050807@noaa.gov>

Roger,

This is what the summary() command gives me before/after I use 
fullgrid(dem) <- FALSE


dem<-readFLOAT6sp("ohrfc.dem")
 > summary(dem)
Object of class SpatialGridDataFrame
Coordinates:
min max
coords.x1 -351000 675000
coords.x2 -486000 486000
Is projected: TRUE
proj4string : [+proj=lcc +lat_0=39.0000000000 +lat_1=60.0000000000 
+lat_2=30.0000000000 +lon_0=-86.0000000000 +x_0=0.0000000000 
+y_0=0.0000000000 +a=6378137 +rf=298.257223563 +no_defs 
+towgs84=0.000,0.000,0.000]
Number of points: 2
Grid attributes:
cellcentre.offset cellsize cells.dim
1 -346500 9000 114
2 -481500 9000 108
Data attributes:
ohrfc.dem
Min. : 0.0
1st Qu.: 183.0
Median : 244.0
Mean : 302.2
3rd Qu.: 335.0
Max. :1707.1
NA's :1513.0
=============================================
 > fullgrid(dem)<-FALSE
 > summary(dem)
Object of class SpatialPixelsDataFrame
Coordinates:
min max
s1 -351000 675000
s2 -432000 468000
Is projected: TRUE
proj4string : [+proj=lcc +lat_0=39.0000000000 +lat_1=60.0000000000 
+lat_2=30.0000000000 +lon_0=-86.0000000000 +x_0=0.0000000000 
+y_0=0.0000000000 +a=6378137 +rf=298.257223563 +no_defs 
+towgs84=0.000,0.000,0.000]
Number of points: 10799
Data attributes:
ohrfc.dem
Min. : 0.0
1st Qu.: 183.0
Median : 244.0
Mean : 302.2
3rd Qu.: 335.0
Max. :1707.1

 > names(dem)
[1] "ohrfc.dem"


Regards,
Tom




Roger Bivand wrote:
> On Fri, 28 Apr 2006, Thomas Adams wrote:
>
>   
>> Roger,
>>
>> Your suggestion:
>>
>> fullgrid(dem) <- FALSE
>>
>> did turn dem into class type SpatialGridDataFrame, but when I tried:
>>
>> z <- predict(UK_fit,newdata=dem)
>>
>> I got an error:
>>
>> Error in model.frame(... :
>> invalid variable type.
>>
>> I think I should restate the problem:
>>
>> I have a file 'temps' which has class SpatialPointsDataFrame read from 
>> GRASS 6.1, that looks like:
>>
>> coordinates cat x y z temp name
>> 1 (-341460, -2154.42) 1 -90.05 38.90 166 63 ALN
>> 2 (-198769, 301388) 2 -88.47 41.77 215 67 ARR
>> 3 (-334899, -40321) 3 -89.95 38.55 140 66 BLV
>> 4 (-240028, 163910) 4 -88.92 40.48 268 69 BMI
>> 5 (-187957, 114806) 5 -88.27 40.04 229 64 CMI
>> 6 (-351730, -37305.9) 6 -90.15 38.57 126 65 CPS
>> 7 (-242424, 98244.7) 7 -88.92 39.87 204 66 DEC
>> 8 (-179844, 315889) 8 -88.24 41.91 232 69 DPA
>> 9 (-136093, -24538.2) 9 -87.61 38.76 131 68 LWV
>> 10 (-278964, -126152) 10 -89.25 37.78 125 66 MDH
>> 11 (-140792, 302011) 11 -87.75 41.79 187 73 MDW
>> 12 (-364737, 274189) 12 -90.51 41.45 180 73 MLI
>> 13 (-190503, 54493.9) 13 -88.28 39.48 219 64 MTO
>>
>> and I have a a file 'dem' which has class SpatialGridDataFrame which 
>> just consists of grid of elevation values read from GRASS 6.1 using 
>> dem<-readFLOAT6sp(). (Sorry, I know I'm repeating myself).
>>
>> What I want to do is to use the grid of elevation values ('dem') as a 
>> proxy in the spatial interpolation of the 'temp' values in my 'temps' 
>> file that are located at the coordinates in parentheses(). Notice that 
>> the temps file also has 'z' values of elevations. So, is this what you 
>> already understood? Converting 'dem' to a SpatialPixelsDataFrame seemed 
>> to only leave me with the grid locations and not the elevation values ? 
>> is this right.
>>     
>
> What does:
>
> summary(dem) 
>
> say before and after doing
>
> fullgrid(dem) <- FALSE?
>
> Afterwards it should be a SpatialPixelsDataFrame with 
>
> names(dem)
>
> being "z". Saying summary(dem) will give you an idea of what is inside, 
> str() should too.
>
> Roger
>
> PS. This is usually a one-off thing, once it works, you note down how, and 
> then it just does from then on.
>
>
>   
>> Thanks again for your help!
>>
>> Regards,
>> Tom
>>
>>
>> Roger Bivand wrote:
>>     
>>> On Fri, 28 Apr 2006, Thomas Adams wrote:
>>>
>>>   
>>>       
>>>> Roger,
>>>>
>>>> This got me further along, but I am encountering a problem with:
>>>>
>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>>
>>>> The gstat step works for me, where I have:
>>>>
>>>> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
>>>>
>>>> temps has class SpatialPointsDataFrame:
>>>>
>>>>               coordinates cat      x     y    z temp name
>>>> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
>>>> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
>>>> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
>>>> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
>>>> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
>>>> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
>>>> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
>>>> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
>>>> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
>>>> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
>>>> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
>>>> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
>>>> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
>>>>
>>>> and dem has class SpatialGridDataFrame and just consists of grid values.
>>>>     
>>>>         
>>> I think 
>>>
>>> fullgrid(dem) <- FALSE
>>>
>>> should make a SpatialPixelsDataFrame, but you'll have to make sure the 
>>> name of the dem variable is the same as in the formula.
>>>
>>> Roger
>>>
>>>   
>>>       
>>>> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
>>>> example):
>>>>
>>>> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
>>>>
>>>> I have nothing like meuse.grid, so this does not work. I can use 
>>>> image(dem), which produces a plot of elevation values. My point is that 
>>>> meuse.grid and my dem files have very different structures.
>>>>
>>>> I'm not sure where to go to from here.
>>>>
>>>> Regards,
>>>> Tom
>>>>
>>>>
>>>> Roger Bivand wrote:
>>>>     
>>>>         
>>>>> On Thu, 27 Apr 2006, Thomas Adams wrote:
>>>>>
>>>>>   
>>>>>       
>>>>>           
>>>>>> List:
>>>>>>
>>>>>> I can not seem to work out the syntax for using R/gstat within a GRASS 
>>>>>> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
>>>>>> grid) and point data for temperature; theoretically, the temperatures 
>>>>>> should relate to elevation. So, I am trying to spatially interpolate the 
>>>>>> temperature data based on the elevations at the grid points. How do I 
>>>>>> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
>>>>>> have no trouble reading in my elevation data (DEM) from GRASS and I have 
>>>>>> no problem doing ordinary kriging of my temperature data using 
>>>>>> GRASS/R/gstat.
>>>>>>     
>>>>>>         
>>>>>>             
>>>>> What do the data look like? Do you have temperature and elevation at the
>>>>> observation points and elevation over the grid? If temperature is the 
>>>>> variable for which you want to interpolate, then the formula argument in 
>>>>> the gstat() function would be temp ~ elev, data=pointsdata (if a 
>>>>> SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
>>>>> step would need a SpatialGridDataFrame object as newdata, with elev as 
>>>>> (one of) the columns in the data slot.
>>>>>
>>>>> An example for the Meuse bank data in Burrough and McDonnell:
>>>>>
>>>>> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
>>>>> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
>>>>>   nugget=1))
>>>>> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
>>>>>   model=uefitted)
>>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>>>
>>>>> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
>>>>> with flood frequencies in Fldf (actually a factor, but works neatly).
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>   
>>>>>       
>>>>>           
>>>>>> Regards,
>>>>>> Tom
>>>>>>
>>>>>>
>>>>>>     
>>>>>>         
>>>>>>             
>>>>>   
>>>>>       
>>>>>           
>>>>     
>>>>         
>>>   
>>>       
>>
>>     
>
>   


-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033



From Anja.Matatko at alta4.com  Tue May  2 13:19:36 2006
From: Anja.Matatko at alta4.com (Anja Matatko)
Date: Tue, 2 May 2006 13:19:36 +0200
Subject: [R-sig-Geo] Regression analysis: how to convert shapefiles to
	listw-objects?
Message-ID: <8EDE8442902FB941AB8BE96FC8CE168A398826@srvdc.alta4.local>

Roger and list, 

thanks for your help with importing my shapefiles. 

As I don't want to use only the lm() command for regression analysis but
also more complex ones as lm.morantest() and others, it seems that I
need a listw-object instead of my shapefile. 

What I think I should do is:
- create polylist or Spatial Polygons
- use poly2nb()
- use nb2listw ()

My results: 
> abo_object_neu <- readShapePoly ("abo_poly",
proj4string=CRS(as.character (NA)), verbose=FALSE)
> summary(abo_object_neu)
Object of class SpatialPolygonsDataFrame
Coordinates:
       min     max
r1 2508089 2644341
r2 5442170 5640160
Is projected: NA 
proj4string : [NA]
Data attributes: (several attributes, I deleted them here)


I thought "SpatialPolygonsDataFrame" should be one of these
"SpatialPolygon"-objects to serve as input for poly2nb, but trying this
function, the answer was: 

> abo_nb <- poly2nb(abo_object_neu, row.names=NULL,
snap=sqrt(.Machine$double.eps), queen=TRUE)
Error in poly2nb(abo_object_neu, row.names = NULL, snap =
sqrt(.Machine$double.eps),  : 
        Not a polygon list


My question: what is going wrong, are there other functions to do this
conversion from shapefile to listw-object? Is there a direct shapefile
to listw-conversion-function? I really tried to find it in help files,
but had no success. 

Thanks, Anja

> sessionInfo()
Version 2.3.0 (2006-04-24) 
i386-pc-mingw32 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
"datasets"  "base"     

other attached packages:
   spdep     boot  SparseM maptools       sp  foreign  tripack       PK 
"0.3-22" "1.2-24"   "0.68" "0.5-11" "0.8-14" "0.8-15" "1.2-10"   "0.03"



From Roger.Bivand at nhh.no  Tue May  2 13:40:38 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 May 2006 13:40:38 +0200 (CEST)
Subject: [R-sig-Geo] Regression analysis: how to convert shapefiles to
 listw-objects?
In-Reply-To: <8EDE8442902FB941AB8BE96FC8CE168A398826@srvdc.alta4.local>
Message-ID: <Pine.LNX.4.44.0605021338520.19564-100000@reclus.nhh.no>

On Tue, 2 May 2006, Anja Matatko wrote:

> Roger and list, 
> 
> thanks for your help with importing my shapefiles. 
> 
> As I don't want to use only the lm() command for regression analysis but
> also more complex ones as lm.morantest() and others, it seems that I
> need a listw-object instead of my shapefile. 
> 
> What I think I should do is:
> - create polylist or Spatial Polygons
> - use poly2nb()
> - use nb2listw ()
> 
> My results: 
> > abo_object_neu <- readShapePoly ("abo_poly",
> proj4string=CRS(as.character (NA)), verbose=FALSE)
> > summary(abo_object_neu)
> Object of class SpatialPolygonsDataFrame
> Coordinates:
>        min     max
> r1 2508089 2644341
> r2 5442170 5640160
> Is projected: NA 
> proj4string : [NA]
> Data attributes: (several attributes, I deleted them here)
> 
> 
> I thought "SpatialPolygonsDataFrame" should be one of these
> "SpatialPolygon"-objects to serve as input for poly2nb, but trying this
> function, the answer was: 
> 
> > abo_nb <- poly2nb(abo_object_neu, row.names=NULL,
> snap=sqrt(.Machine$double.eps), queen=TRUE)
> Error in poly2nb(abo_object_neu, row.names = NULL, snap =
> sqrt(.Machine$double.eps),  : 
>         Not a polygon list

I'll correct this in the next release, you need to cast the object 
explicitly:

abo_nb <- poly2nb(as(abo_object_neu, "SpatialPolygons"))

should do the trick.

Roger

> 
> 
> My question: what is going wrong, are there other functions to do this
> conversion from shapefile to listw-object? Is there a direct shapefile
> to listw-conversion-function? I really tried to find it in help files,
> but had no success. 
> 
> Thanks, Anja
> 
> > sessionInfo()
> Version 2.3.0 (2006-04-24) 
> i386-pc-mingw32 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets"  "base"     
> 
> other attached packages:
>    spdep     boot  SparseM maptools       sp  foreign  tripack       PK 
> "0.3-22" "1.2-24"   "0.68" "0.5-11" "0.8-14" "0.8-15" "1.2-10"   "0.03"
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Thu May  4 23:00:14 2006
From: zev at zevross.com (Zev Ross)
Date: Thu, 04 May 2006 17:00:14 -0400
Subject: [R-sig-Geo] write.asciigrid
Message-ID: <445A6B5E.2090609@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060504/7d8f00c7/attachment.html>

From Roger.Bivand at nhh.no  Fri May  5 10:34:57 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 May 2006 10:34:57 +0200 (CEST)
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <445A6B5E.2090609@zevross.com>
Message-ID: <Pine.LNX.4.44.0605051008070.23022-100000@reclus.nhh.no>

On Thu, 4 May 2006, Zev Ross wrote:

> Hi All,
> 
> I'd like to write the results of a kriging call to an ascii grid using
> GSTAT -- but I would like to write BOTH the predictions and the variances
> to grids. Is there a more elegant (and less dangerous) way to do it than
> what I have below?
> 

Dangerous for whom? Elegant, would be nice but life is short? The answer 
depends on the software that is going to read the output grids, and how it 
treats locales, etc., since both predictions and variances will be 
floating point.

> 
> depth_uk <- krige(DEPTH~slope.asc, depth, slope, vgm_depth_r)
> 
> #? write the predictions
> 
> write.asciigrid(depth_uk "c:/junk/rk/predictions.asc")
> 
> # replace predictions with variances and then write the variances
> 
> depth_uk$var1.pred<-depth_uk$var1.var
> write.asciigrid(depth_uk, "c:/junk/rk/.asc")
> 

If the software on the other side reads GeoTiff, my preference would be:

library(rgdal)
writeGDAL(depth_uk, "depth_uk.tif")

which I have seen work with ENVI, but not with ArcGIS 9.1; this preserves 
coordinate reference system metadata if set.

In a forthcoming release of rgdal, you should be able to pass options= to 
writeGDAL() - specifically INTERLEAVE=PIXEL, see:

http://grass.itc.it/grass61/manuals/html61_user/r.out.gdal.html

and I have seen this help with ArcGIS 9.1, although it wasn't predictable
(the legend scale showed correct values but the visualisation was wrong
sometimes - I tried on a Wednesday if that helps!). ArcGIS only accepted 
single band GeoTiff files, it thought 3-band were coloured images. ENVI 
simply read the GDAL-generated GeoTiffs (with 4 bands in the case we 
tried - point pattern kernel densities at different bandwidths) correctly 
without making any assumptions.

Depending on your locales, the ASCII grid route is being maintained in the 
maptools package and functions in the sp package will be deprecated. So

library(maptools)
writeAsciiGrid(depth_uk, "preds.txt", attr="var1.pred", dec=<your choice>)
writeAsciiGrid(depth_uk, "vars.txt", attr="var1.var", dec=<your choice>)

should get the values into ArcGIS 9.1 through the Toolbox (it is very 
sensitive to the "."/"," dec= setting). [The intention is to gather 
input/output functions in maptools and rgdal, freeing the other packages 
from having often older, duplicate copies of functions that do not get 
maintained.]

Again, how to do it does depend on what software is going to read the 
output ASCII grids, and what assumptions (often undocumented) it makes 
about the files.

Please let us know how you get on,

Roger

> PS this sample code comes from Tomislav Hengl's page
> (http://spatial-analyst.net/regkriging.php)
> 

Nice link!

> Zev
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From abunn at whrc.org  Fri May  5 16:10:18 2006
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 5 May 2006 10:10:18 -0400
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <Pine.LNX.4.44.0605051008070.23022-100000@reclus.nhh.no>
Message-ID: <NEBBIPHDAMMOKDKPOFFIKEMBEDAA.abunn@whrc.org>

I second Roger's recommendation for using rgdal. I've been writing to and
fro from img files with few problems. The only problem I have with ArcGIS is
that the statistics have had to be recalculated in Arc for floats to get the
display to work correctly. But, Arc has a batch statistics tool that doesn't
crash often (when a tool works reliably in Arc I'm surprised and pleased
beyond reason). Keep up the good work Roger, Tim, Edzer and all the
rest. -Andy



From Roger.Bivand at nhh.no  Fri May  5 16:40:14 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 May 2006 16:40:14 +0200 (CEST)
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIKEMBEDAA.abunn@whrc.org>
Message-ID: <Pine.LNX.4.44.0605051618240.11059-100000@reclus.nhh.no>

On Fri, 5 May 2006, Andy Bunn wrote:

> I second Roger's recommendation for using rgdal. I've been writing to and
> fro from img files with few problems. The only problem I have with ArcGIS is
> that the statistics have had to be recalculated in Arc for floats to get the
> display to work correctly. But, Arc has a batch statistics tool that doesn't
> crash often (when a tool works reliably in Arc I'm surprised and pleased
> beyond reason). Keep up the good work Roger, Tim, Edzer and all the
> rest. -Andy

Thanks for this input, Andy. Could you please flesh it out a little, 
perhaps a run through from SpatialPixels/GridDataFrame to inside ArcGIS 
(version?)? I'll try too, but if you have a well-trodden path ...

Roger

> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From abunn at whrc.org  Fri May  5 17:23:59 2006
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 5 May 2006 11:23:59 -0400
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <Pine.LNX.4.44.0605051618240.11059-100000@reclus.nhh.no>
Message-ID: <NEBBIPHDAMMOKDKPOFFICEMEEDAA.abunn@whrc.org>

> > I second Roger's recommendation for using rgdal. I've been
> writing to and
> > fro from img files with few problems. The only problem I have
> with ArcGIS is
> > that the statistics have had to be recalculated in Arc for
> floats to get the
> > display to work correctly. But, Arc has a batch statistics tool
> that doesn't
> > crash often (when a tool works reliably in Arc I'm surprised and pleased
> > beyond reason). Keep up the good work Roger, Tim, Edzer and all the
> > rest. -Andy
>
> Thanks for this input, Andy. Could you please flesh it out a little,
> perhaps a run through from SpatialPixels/GridDataFrame to inside ArcGIS
> (version?)? I'll try too, but if you have a well-trodden path ...

    library(sp)
    library(rgdal)
    data(meuse.grid)
    coordinates(meuse.grid) = c("x", "y") # promote to
SpatialPointsDataFrame
    gridded(meuse.grid) <- TRUE # promote to SpatialPixelsDataFrame
    image(meuse.grid["dist"])
    writeGDAL(meuse.grid,"c:/data/research/tmp/meuse.grid.img",
driver="HFA")

Arc can display this img file without issue if the statistics are
reclaculated using the Calculate Statistics under Raster. Note the lack of
projcetion however!

-Andy



From Roger.Bivand at nhh.no  Fri May  5 18:29:29 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 May 2006 18:29:29 +0200 (CEST)
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <NEBBIPHDAMMOKDKPOFFICEMEEDAA.abunn@whrc.org>
Message-ID: <Pine.LNX.4.44.0605051826100.11059-100000@reclus.nhh.no>

On Fri, 5 May 2006, Andy Bunn wrote:

> > > I second Roger's recommendation for using rgdal. I've been
> > writing to and
> > > fro from img files with few problems. The only problem I have
> > with ArcGIS is
> > > that the statistics have had to be recalculated in Arc for
> > floats to get the
> > > display to work correctly. But, Arc has a batch statistics tool
> > that doesn't
> > > crash often (when a tool works reliably in Arc I'm surprised and pleased
> > > beyond reason). Keep up the good work Roger, Tim, Edzer and all the
> > > rest. -Andy
> >
> > Thanks for this input, Andy. Could you please flesh it out a little,
> > perhaps a run through from SpatialPixels/GridDataFrame to inside ArcGIS
> > (version?)? I'll try too, but if you have a well-trodden path ...
> 
>     library(sp)
>     library(rgdal)
>     data(meuse.grid)
>     coordinates(meuse.grid) = c("x", "y") # promote to
> SpatialPointsDataFrame
>     gridded(meuse.grid) <- TRUE # promote to SpatialPixelsDataFrame
>     image(meuse.grid["dist"])
>     writeGDAL(meuse.grid,"c:/data/research/tmp/meuse.grid.img",
> driver="HFA")
> 
> Arc can display this img file without issue if the statistics are
> reclaculated using the Calculate Statistics under Raster. Note the lack of
> projcetion however!

Which ArcGIS version, please, and the exact (TM) steps you took - I've got 
a kriging prediction *.img, but haven't got any further (sorry, my Arc 
abilities are limited) - I don't "see" any Calculate Statistics or Raster 
anywhere (and Arc just crashed, probably latency to the license server).

Roger

> 
> -Andy
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From abunn at whrc.org  Fri May  5 18:54:58 2006
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 5 May 2006 12:54:58 -0400
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <Pine.LNX.4.44.0605051826100.11059-100000@reclus.nhh.no>
Message-ID: <NEBBIPHDAMMOKDKPOFFIAEMGEDAA.abunn@whrc.org>

> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Friday, May 05, 2006 12:29 PM
> To: Andy Bunn
> Cc: Zev Ross; r-sig-geo at stat.math.ethz.ch
> Subject: RE: [R-sig-Geo] write.asciigrid
>
>
> On Fri, 5 May 2006, Andy Bunn wrote:
>
> > > > I second Roger's recommendation for using rgdal. I've been
> > > writing to and
> > > > fro from img files with few problems. The only problem I have
> > > with ArcGIS is
> > > > that the statistics have had to be recalculated in Arc for
> > > floats to get the
> > > > display to work correctly. But, Arc has a batch statistics tool
> > > that doesn't
> > > > crash often (when a tool works reliably in Arc I'm
> surprised and pleased
> > > > beyond reason). Keep up the good work Roger, Tim, Edzer and all the
> > > > rest. -Andy
> > >
> > > Thanks for this input, Andy. Could you please flesh it out a little,
> > > perhaps a run through from SpatialPixels/GridDataFrame to
> inside ArcGIS
> > > (version?)? I'll try too, but if you have a well-trodden path ...
> >
> >     library(sp)
> >     library(rgdal)
> >     data(meuse.grid)
> >     coordinates(meuse.grid) = c("x", "y") # promote to
> > SpatialPointsDataFrame
> >     gridded(meuse.grid) <- TRUE # promote to SpatialPixelsDataFrame
> >     image(meuse.grid["dist"])
> >     writeGDAL(meuse.grid,"c:/data/research/tmp/meuse.grid.img",
> > driver="HFA")
> >
> > Arc can display this img file without issue if the statistics are
> > reclaculated using the Calculate Statistics under Raster. Note
> the lack of
> > projcetion however!
>
> Which ArcGIS version, please, and the exact (TM) steps you took -
> I've got
> a kriging prediction *.img, but haven't got any further (sorry, my Arc
> abilities are limited) - I don't "see" any Calculate Statistics or Raster
> anywhere (and Arc just crashed, probably latency to the license server).

It's ArcGIS 9.1 (Build 750). The statistics tool is in ArcToolbox | Data
Management Tools | Raster | Calculate Statistics (There is also a Batch
Calculate Statistics tool). This can be scripted too and done from R using
system (?). Scripts can be written in any COM-compliant scripting language
(Python, JScript, or VBScript) and run directly from within the scripting
application. Here is a script example that could be wrapped into an sp
function, I suppose:

    from win32com.client import Dispatch
    gp = Dispatch('esriGeoprocessing.GpDispatch.1')
    gp.workspace = "c:/data/research/tmp"
    # calculate stats with skip factor of 1,1, and ignore value of 0
    gp.CalculateStatistics("meuse.grid.img","1","1","0")

-Andy

> Roger
>
> >
> > -Andy
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



From tkobayas at indiana.edu  Mon May  8 09:16:19 2006
From: tkobayas at indiana.edu (tkobayas at indiana.edu)
Date: Mon,  8 May 2006 03:16:19 -0400
Subject: [R-sig-Geo] making hypothetical density data
Message-ID: <20060508031619.0avn2rbm68084wsk@webmail.iu.edu>

Dear R users:

I have been trying to create hypothetical data that describe a series 
of spatial distributions of employment density, single-center, 
duo-centers, etc. Here is a function I worked on, but have no idea to 
randomize clusters of employment. First, I must apologize for my little 
knowledge of R. Second, I apprecaite if anyone could kindly give me 
advice. Also, I have been searching a code to store subdata, such as 
coefficients in SPGWR, within a function.

Greatest thanks in advance.

------------------------------------
Takatsugu Kobayashi
PhD Student
Indiana University, Dept. Geography



From Roger.Bivand at nhh.no  Mon May  8 10:29:24 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 8 May 2006 10:29:24 +0200 (CEST)
Subject: [R-sig-Geo] making hypothetical density data
In-Reply-To: <20060508031619.0avn2rbm68084wsk@webmail.iu.edu>
Message-ID: <Pine.LNX.4.44.0605081027160.3618-100000@reclus.nhh.no>

On Mon, 8 May 2006 tkobayas at indiana.edu wrote:

> Dear R users:
> 
> I have been trying to create hypothetical data that describe a series 
> of spatial distributions of employment density, single-center, 
> duo-centers, etc. Here is a function I worked on, but have no idea to 
> randomize clusters of employment. First, I must apologize for my little 
> knowledge of R. Second, I apprecaite if anyone could kindly give me 
> advice. Also, I have been searching a code to store subdata, such as 
> coefficients in SPGWR, within a function.

If you attached code to your message, not the general instruction for all 
R mailing lists:

"... most binary e-mail attachments are not accepted, i.e., they are 
removed from the posting completely. As an exception, we allow 
application/pdf, application/postscript, and image/png (and x-tar and 
gzip on R-devel). You can use text/plain as well, or simply paste text 
into your message instead."

Helping will be easier if we can see your example code (please keep it 
very short, just enough to show your problem).

> 
> Greatest thanks in advance.
> 
> ------------------------------------
> Takatsugu Kobayashi
> PhD Student
> Indiana University, Dept. Geography
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hi_ono2001 at yahoo.co.jp  Tue May  9 12:03:24 2006
From: hi_ono2001 at yahoo.co.jp (Hisaji ONO)
Date: Tue, 9 May 2006 19:03:24 +0900 (JST)
Subject: [R-sig-Geo] How to improve calculation time of spatial weight
	matrices on spdep
Message-ID: <20060509100324.62399.qmail@web10702.mail.bbt.yahoo.co.jp>

Hello.

 Currently, among GeoComputaion community in Japan,
GeoDa's calculation speed of  spatial weight matrices of
polygons are highly evaluated.

 Any idea to improve this of spdep?



 Regards.



From Roger.Bivand at nhh.no  Tue May  9 13:20:44 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 9 May 2006 13:20:44 +0200 (CEST)
Subject: [R-sig-Geo] How to improve calculation time of spatial weight
 matrices on spdep
In-Reply-To: <20060509100324.62399.qmail@web10702.mail.bbt.yahoo.co.jp>
Message-ID: <Pine.LNX.4.44.0605091237200.4706-100000@reclus.nhh.no>

Hisaji:

On Tue, 9 May 2006, Hisaji ONO wrote:

> Hello.
> 
>  Currently, among GeoComputaion community in Japan,
> GeoDa's calculation speed of  spatial weight matrices of
> polygons are highly evaluated.
> 
>  Any idea to improve this of spdep?
> 

At present poly2nb() uses two steps, first to try to find candidate 
neighbours using bounding boxes, then to check candidates for  
boundary points within a snap distance. Both steps are in C, but the main 
loop is in R. To go faster, it would mean moving everything to C, avoiding 
the (n*(n-1))/2 loop in R. Profiling the function would show where time is 
being used - I can try to do that. 

On a map of all the US counties, Rprof() shows that there may be a way to 
reduce time by simplifying as.double() calls - because numeric data in R 
can be at least integer or double, it needs coercing before being passed 
to C. I'll try to do something with this, but it may be that there are 
other ways (passing a whole SpatialPolygons object to C, because the 
coordinates there are known to be of storage mode "double").

Speed is - I think - not so important, because the neighbour lists only
need to be made once for each set of polygons, and the function does work
even with very large numbers of polygons. Then the output list can be
stored as an R object, or written out as a GAL file. Do you have examples 
where speed matters more, or are there particular kinds of configurations 
of sets of polygons that are a problem?

Best wishes,

Roger

> 
> 
>  Regards.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Tue May  9 14:12:28 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 9 May 2006 14:12:28 +0200 (CEST)
Subject: [R-sig-Geo] How to improve calculation time of spatial weight
 matrices on spdep
In-Reply-To: <20060509100324.62399.qmail@web10702.mail.bbt.yahoo.co.jp>
Message-ID: <Pine.LNX.4.44.0605091410010.4706-100000@reclus.nhh.no>

On Tue, 9 May 2006, Hisaji ONO wrote:

> Hello.
> 
>  Currently, among GeoComputaion community in Japan,
> GeoDa's calculation speed of  spatial weight matrices of
> polygons are highly evaluated.
> 
>  Any idea to improve this of spdep?
> 

Further to my previous message, the next release of spdep will have time 
savings like from 1000 seconds reduced to 300 seconds on a 3500 polygon 
data set. Thanks for pointing this out, with Rprof(), it wasn't difficult 
to find a cheap way to economise (only check storage mode once per 
polygon).

Roger

> 
> 
>  Regards.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Tue May  9 23:21:05 2006
From: zev at zevross.com (Zev Ross)
Date: Tue, 09 May 2006 17:21:05 -0400
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <Pine.LNX.4.44.0605051008070.23022-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605051008070.23022-100000@reclus.nhh.no>
Message-ID: <446107C1.9060705@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060509/265bd9f9/attachment.html>

From Roger.Bivand at nhh.no  Wed May 10 10:03:13 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 May 2006 10:03:13 +0200 (CEST)
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <446107C1.9060705@zevross.com>
Message-ID: <Pine.LNX.4.44.0605100959010.5583-100000@reclus.nhh.no>

On Tue, 9 May 2006, Zev Ross wrote:

> Hi Roger and Andy,
> 
> Thanks for the help. I'm using ArcGIS 9.1. writeGDAL works as promised.
> The one odd behavior was the initial display in ArcGIS once I first added
> the two bands. Using the "stretched" classification, the map initially
> looked all black. Under properties, I changed the symbology to
> "Classified" and it looked fine -- then I changed back to "Stretched" and
> again it looked fine. Quirky behavior like this from ArcGIS is nothing
> new.

Did you do the:

ArcToolbox | Data Management Tools | Raster | Calculate Statistics

trick too? I think that is what Arc (sometimes) does on the fly when 
changing symbology (dreadful term!). But when NAs are present, it can get 
stuck.

> 
> I tried the suggested write ascii command from maptools on my own data
> set and it didn't work initially due to the fact that my grid cells
> apparently are not perfect squares (perhaps this is a rounding issue). No
> need to keep fiddling with that, though, as writeGDAL does the trick.
> Thanks again,
> 

Yes, they need to be equal for the Arc ASCII grid route to work. If they 
are, it works (when the decimal point in FLOAT is correct too).

Roger

> Zev
> 
> Roger Bivand wrote:
> 
>  On Thu, 4 May 2006, Zev Ross wrote:
> 
>   
> 
>  Hi All,
> 
> I'd like to write the results of a kriging call to an ascii grid using
> GSTAT -- but I would like to write BOTH the predictions and the variances
> to grids. Is there a more elegant (and less dangerous) way to do it than
> what I have below?
> 
>     
> 
>  Dangerous for whom? Elegant, would be nice but life is short? The answer 
> depends on the software that is going to read the output grids, and how it 
> treats locales, etc., since both predictions and variances will be 
> floating point.
> 
>   
> 
>  depth_uk <- krige(DEPTH~slope.asc, depth, slope, vgm_depth_r)
> 
> #? write the predictions
> 
> write.asciigrid(depth_uk "c:/junk/rk/predictions.asc")
> 
> # replace predictions with variances and then write the variances
> 
> depth_uk$var1.pred<-depth_uk$var1.var
> write.asciigrid(depth_uk, "c:/junk/rk/.asc")
> 
>     
> 
>  If the software on the other side reads GeoTiff, my preference would be:
> 
> library(rgdal)
> writeGDAL(depth_uk, "depth_uk.tif")
> 
> which I have seen work with ENVI, but not with ArcGIS 9.1; this preserves 
> coordinate reference system metadata if set.
> 
> In a forthcoming release of rgdal, you should be able to pass options= to 
> writeGDAL() - specifically INTERLEAVE=PIXEL, see:
> 
> http://grass.itc.it/grass61/manuals/html61_user/r.out.gdal.html
> 
> and I have seen this help with ArcGIS 9.1, although it wasn't predictable
> (the legend scale showed correct values but the visualisation was wrong
> sometimes - I tried on a Wednesday if that helps!). ArcGIS only accepted 
> single band GeoTiff files, it thought 3-band were coloured images. ENVI 
> simply read the GDAL-generated GeoTiffs (with 4 bands in the case we 
> tried - point pattern kernel densities at different bandwidths) correctly 
> without making any assumptions.
> 
> Depending on your locales, the ASCII grid route is being maintained in the 
> maptools package and functions in the sp package will be deprecated. So
> 
> library(maptools)
> writeAsciiGrid(depth_uk, "preds.txt", attr="var1.pred", dec=<your choice>)
> writeAsciiGrid(depth_uk, "vars.txt", attr="var1.var", dec=<your choice>)
> 
> should get the values into ArcGIS 9.1 through the Toolbox (it is very 
> sensitive to the "."/"," dec= setting). [The intention is to gather 
> input/output functions in maptools and rgdal, freeing the other packages 
> from having often older, duplicate copies of functions that do not get 
> maintained.]
> 
> Again, how to do it does depend on what software is going to read the 
> output ASCII grids, and what assumptions (often undocumented) it makes 
> about the files.
> 
> Please let us know how you get on,
> 
> Roger
> 
>   
> 
>  PS this sample code comes from Tomislav Hengl's page
> (http://spatial-analyst.net/regkriging.php)
> 
>     
> 
>  Nice link!
> 
>   
> 
>  Zev
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 
>     
> 
> 
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Wed May 10 15:23:15 2006
From: zev at zevross.com (Zev Ross)
Date: Wed, 10 May 2006 09:23:15 -0400
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <Pine.LNX.4.44.0605100959010.5583-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605100959010.5583-100000@reclus.nhh.no>
Message-ID: <4461E943.8020602@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060510/d0b92283/attachment.html>

From Roger.Bivand at nhh.no  Wed May 10 15:38:10 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 10 May 2006 15:38:10 +0200 (CEST)
Subject: [R-sig-Geo] write.asciigrid
In-Reply-To: <4461E943.8020602@zevross.com>
Message-ID: <Pine.LNX.4.44.0605101535500.13256-100000@reclus.nhh.no>

On Wed, 10 May 2006, Zev Ross wrote:

> Hi Roger,
> 
> No, I didn't use the calculate statistics trick. I just opened the
> rasters and when they didn't display properly, I simply changed to
> "Stretched" and then back to "Classified" and it looked fine. I should
> mention though, that I added each band separately rather than adding both
> bands at once. Zev

Me too - it seems that on occasion with more than a single band, Arc 
things it is a 3-band image and tries to apply RGB with curious results. 
ENVI reads writeGDAL() GeoTiffs, including multiple FLOAT bands, right 
first time. On single bands, the "Compute Statistics" trick helped for me.

Roger

> 
> Roger Bivand wrote:
> 
>  On Tue, 9 May 2006, Zev Ross wrote:
> 
>   
> 
>  Hi Roger and Andy,
> 
> Thanks for the help. I'm using ArcGIS 9.1. writeGDAL works as promised.
> The one odd behavior was the initial display in ArcGIS once I first added
> the two bands. Using the "stretched" classification, the map initially
> looked all black. Under properties, I changed the symbology to
> "Classified" and it looked fine -- then I changed back to "Stretched" and
> again it looked fine. Quirky behavior like this from ArcGIS is nothing
> new.
>     
> 
>  Did you do the:
> 
> ArcToolbox | Data Management Tools | Raster | Calculate Statistics
> 
> trick too? I think that is what Arc (sometimes) does on the fly when 
> changing symbology (dreadful term!). But when NAs are present, it can get 
> stuck.
> 
>   
> 
>  I tried the suggested write ascii command from maptools on my own data
> set and it didn't work initially due to the fact that my grid cells
> apparently are not perfect squares (perhaps this is a rounding issue). No
> need to keep fiddling with that, though, as writeGDAL does the trick.
> Thanks again,
> 
>     
> 
>  Yes, they need to be equal for the Arc ASCII grid route to work. If they 
> are, it works (when the decimal point in FLOAT is correct too).
> 
> Roger
> 
>   
> 
>  Zev
> 
> Roger Bivand wrote:
> 
>  On Thu, 4 May 2006, Zev Ross wrote:
> 
>   
> 
>  Hi All,
> 
> I'd like to write the results of a kriging call to an ascii grid using
> GSTAT -- but I would like to write BOTH the predictions and the variances
> to grids. Is there a more elegant (and less dangerous) way to do it than
> what I have below?
> 
>     
> 
>  Dangerous for whom? Elegant, would be nice but life is short? The answer 
> depends on the software that is going to read the output grids, and how it 
> treats locales, etc., since both predictions and variances will be 
> floating point.
> 
>   
> 
>  depth_uk <- krige(DEPTH~slope.asc, depth, slope, vgm_depth_r)
> 
> #? write the predictions
> 
> write.asciigrid(depth_uk "c:/junk/rk/predictions.asc")
> 
> # replace predictions with variances and then write the variances
> 
> depth_uk$var1.pred<-depth_uk$var1.var
> write.asciigrid(depth_uk, "c:/junk/rk/.asc")
> 
>     
> 
>  If the software on the other side reads GeoTiff, my preference would be:
> 
> library(rgdal)
> writeGDAL(depth_uk, "depth_uk.tif")
> 
> which I have seen work with ENVI, but not with ArcGIS 9.1; this preserves 
> coordinate reference system metadata if set.
> 
> In a forthcoming release of rgdal, you should be able to pass options= to 
> writeGDAL() - specifically INTERLEAVE=PIXEL, see:
> 
> http://grass.itc.it/grass61/manuals/html61_user/r.out.gdal.html
> 
> and I have seen this help with ArcGIS 9.1, although it wasn't predictable
> (the legend scale showed correct values but the visualisation was wrong
> sometimes - I tried on a Wednesday if that helps!). ArcGIS only accepted 
> single band GeoTiff files, it thought 3-band were coloured images. ENVI 
> simply read the GDAL-generated GeoTiffs (with 4 bands in the case we 
> tried - point pattern kernel densities at different bandwidths) correctly 
> without making any assumptions.
> 
> Depending on your locales, the ASCII grid route is being maintained in the 
> maptools package and functions in the sp package will be deprecated. So
> 
> library(maptools)
> writeAsciiGrid(depth_uk, "preds.txt", attr="var1.pred", dec=<your choice>)
> writeAsciiGrid(depth_uk, "vars.txt", attr="var1.var", dec=<your choice>)
> 
> should get the values into ArcGIS 9.1 through the Toolbox (it is very 
> sensitive to the "."/"," dec= setting). [The intention is to gather 
> input/output functions in maptools and rgdal, freeing the other packages 
> from having often older, duplicate copies of functions that do not get 
> maintained.]
> 
> Again, how to do it does depend on what software is going to read the 
> output ASCII grids, and what assumptions (often undocumented) it makes 
> about the files.
> 
> Please let us know how you get on,
> 
> Roger
> 
>   
> 
>  PS this sample code comes from Tomislav Hengl's page
> (http://spatial-analyst.net/regkriging.php)
> 
>     
> 
>  Nice link!
> 
>   
> 
>  Zev
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 
>     
> 
> 
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 
>     
> 
> 
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From FAGUIRRN at grupobavaria.com  Thu May 11 17:09:54 2006
From: FAGUIRRN at grupobavaria.com (Francisco Javier Aguirre Navarro)
Date: Thu, 11 May 2006 10:09:54 -0500
Subject: [R-sig-Geo] Importing and Handling  DXF Map files in R
Message-ID: <FA24292AD76FB14EBCD7B205C0C6001D01E9C526@cll94exch1.grupobavaria.com>



Hello, I am a newby in the filed of spatial data analysis, could you please point me to the right libraries/functions in R  that allow me to import DXF maps  and analize spatial data related to these maps ?
I would appreciaiate any internet references or books  that may give a good hands-on introduction to spatial data analysis, I have good knowledge of classical statistical methods.
 I need to analyze about 75000 data points scattered on a map area and I'd like to construct a "density" map of my variable of interest and eventually see how these densities change in time.

Thank you very much for your help.

Francisco J. Aguirre
Bavaria, Bogota -  Colombia.




NOTA CONFIDENCIAL: 			
La informacion contenida en este correo-electronico y cualquier archivo adjunto son originados por SABMIller o alguna de sus compa?ias subsidiarias; es de uso privilegiado y/o confidencial y solo puede ser utilizada por la persona, entidad o compa?ia a la cual esta dirigido. Si usted ha recibido este mensaje por error favor destruirlo y avisar al remitente. Si usted no es el destinatario no debera revelar, copiar o distribuir o tomar cualquier accion basado en los contenidos del mensaje. Cualquier retencion, diseminacion o distribucion total o parcial no autorizada de este mensaje esta estrictamente prohibida y sancionada por la ley.			
Las observaciones y opiniones expresadas en este mensaje de correo electronico pueden no necesariamente ser aquellos de la Administracion o Directivos de SabMiller.			
			
CONFIDENTIAL NOTE: 			
The information in this E-mail and any attachments transmitted are originated by SABMiller or any of its subsidiaries companies, is intended to be privileged and/or confidential and only for use of the individual, entity or company to whom it is addressed. If you have received this e-mail in error please destroy it and contact the sender. If you are not the addressee you may not disclose, copy, distribute or take any action based on the contents hereof. Any total o partial unauthorized retention, dissemination, distribution or copying of this message is strictly prohibited and sanctioned by law.			
The views and opinions expressed in this e-mail message may ...{{dropped}}



From cavallini at faunalia.it  Thu May 11 17:31:50 2006
From: cavallini at faunalia.it (Paolo Cavallini)
Date: Thu, 11 May 2006 17:31:50 +0200
Subject: [R-sig-Geo] Importing and Handling  DXF Map files in R
In-Reply-To: <FA24292AD76FB14EBCD7B205C0C6001D01E9C526@cll94exch1.grupobavaria.com>
References: <FA24292AD76FB14EBCD7B205C0C6001D01E9C526@cll94exch1.grupobavaria.com>
Message-ID: <200605111731.51627.cavallini@faunalia.it>

one possible way is passing through GRASS GIS (you need latest version from 
CVS, though).
pc

At 17:09, gioved? 11 maggio 2006, Francisco Javier Aguirre Navarro has 
probably written:
> Hello, I am a newby in the filed of spatial data analysis, could you please
> point me to the right libraries/functions in R  that allow me to import DXF
> maps  and analize spatial data related to these maps ? I would appreciaiate
> any internet references or books  that may give a good hands-on
> introduction to spatial data analysis, I have good knowledge of classical
> statistical methods. I need to analyze about 75000 data points scattered on
> a map area and I'd like to construct a "density" map of my variable of
> interest and eventually see how these densities change in time.
>
> Thank you very much for your help.
>
> Francisco J. Aguirre
> Bavaria, Bogota -  Colombia.
-- 
Paolo Cavallini
email+jabber: cavallini at faunalia.it
www.faunalia.it
Piazza Garibaldi 5 - 56025 Pontedera (PI), Italy   Tel: (+39)348-3801953



From Roger.Bivand at nhh.no  Thu May 11 18:54:15 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 May 2006 18:54:15 +0200 (CEST)
Subject: [R-sig-Geo] Importing and Handling  DXF Map files in R
In-Reply-To: <200605111731.51627.cavallini@faunalia.it>
Message-ID: <Pine.LNX.4.44.0605111840350.16897-100000@reclus.nhh.no>

On Thu, 11 May 2006, Paolo Cavallini wrote:

> one possible way is passing through GRASS GIS (you need latest version from 
> CVS, though).
> pc

Agreed, converting from DXF through OGR (as in the rgdal package for R) is 
not possible (http://www.remotesensing.org/gdal/ogr/drv_dxfdwg.html). 
Depending on platform, there may be converters available, but not 
unemcumbered. Since the data are said to be points, I wonder if Francisco 
or the originator of the data if not him, can dump it as ASCII from the 
CAD software - since there is no topology. 

A very good book that I certainly recommend is Bailey & Gatrell's 
Interactive Spatial Data Analysis - their treatment of point pattern 
analysis is easy to follow (including kernel densities), and most of their 
point pattern examples are replicated in the examples of the splancs 
package for R. I'm not sure how kernel2d scales for 70K points, though, 
and feel that you may find the hexbin package in bioconductor an 
alternative: it is something else, but is designed for lots of data:

http://www.bioconductor.org/repository/devel/vignette/hexagon_binning.pdf

and there seems to be a smoother there too.

Please let the list know how you decide to extract the point coordinates, 
others will benefit from your experience.

Hope this helps,

Roger

> 
> At 17:09, gioved? 11 maggio 2006, Francisco Javier Aguirre Navarro has 
> probably written:
> > Hello, I am a newby in the filed of spatial data analysis, could you please
> > point me to the right libraries/functions in R  that allow me to import DXF
> > maps  and analize spatial data related to these maps ? I would appreciaiate
> > any internet references or books  that may give a good hands-on
> > introduction to spatial data analysis, I have good knowledge of classical
> > statistical methods. I need to analyze about 75000 data points scattered on
> > a map area and I'd like to construct a "density" map of my variable of
> > interest and eventually see how these densities change in time.
> >
> > Thank you very much for your help.
> >
> > Francisco J. Aguirre
> > Bavaria, Bogota -  Colombia.
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From White.Denis at epamail.epa.gov  Thu May 11 19:06:01 2006
From: White.Denis at epamail.epa.gov (White.Denis at epamail.epa.gov)
Date: Thu, 11 May 2006 10:06:01 -0700
Subject: [R-sig-Geo] t-test with autocorrelation correction
In-Reply-To: <Pine.LNX.4.44.0605111840350.16897-100000@reclus.nhh.no>
Message-ID: <OF9F4ED29C.AA589BA7-ON8825716B.005D6535-8825716B.005DEF87@epamail.epa.gov>

Has anyone implemented a t-test with the effective sample size
correction proposed by Dale and Fortin, Ecoscience 9(2):162-167, 2002,
using a discussion by Cressie, 1993, page 15?

thanks,
Denis



From Roger.Bivand at nhh.no  Thu May 11 19:25:45 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 May 2006 19:25:45 +0200 (CEST)
Subject: [R-sig-Geo] Importing and Handling  DXF Map files in R
In-Reply-To: <Pine.LNX.4.44.0605111840350.16897-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.44.0605111919450.16897-100000@reclus.nhh.no>

On Thu, 11 May 2006, Roger Bivand wrote:

> On Thu, 11 May 2006, Paolo Cavallini wrote:
> 
> > one possible way is passing through GRASS GIS (you need latest version from 
> > CVS, though).
> > pc
> 
> Agreed, converting from DXF through OGR (as in the rgdal package for R) is 
> not possible (http://www.remotesensing.org/gdal/ogr/drv_dxfdwg.html). 
> Depending on platform, there may be converters available, but not 
> unemcumbered. Since the data are said to be points, I wonder if Francisco 
> or the originator of the data if not him, can dump it as ASCII from the 
> CAD software - since there is no topology. 
> 
> A very good book that I certainly recommend is Bailey & Gatrell's 
> Interactive Spatial Data Analysis - their treatment of point pattern 
> analysis is easy to follow (including kernel densities), and most of their 
> point pattern examples are replicated in the examples of the splancs 
> package for R. I'm not sure how kernel2d scales for 70K points, though, 
> and feel that you may find the hexbin package in bioconductor an 
> alternative: it is something else, but is designed for lots of data:
> 
> http://www.bioconductor.org/repository/devel/vignette/hexagon_binning.pdf
> 
> and there seems to be a smoother there too.

Replying to my own question, kernel2d() scales brilliantly:

set.seed(1)
cores <- cbind(x=runif(300), y=runif(300))
out <- do.call("rbind", lapply(1:300, function(i) 
  cbind(x=cores[i,1]+rnorm(200, 0, runif(1, 0.001, 0.02)), 
  y=cores[i,2]+rnorm(200, 0, runif(1, 0.001, 0.02)))))
plot(out, pch=".")
plot(hexbin(out))
image(kernel2d(out, bboxx(bbox(out)), h0=0.05, 50, 50), 
  col=grey(99:1/100))

plot(hexbin()) 1.4 seconds 
image(kernel2d()) 1.0 seconds

and the new spkernel2d() wrapper makes it convenient to stack up kernel 
densities in a SpatialGridDataFrame and display with spplot().

> 
> Please let the list know how you decide to extract the point coordinates, 
> others will benefit from your experience.
> 
> Hope this helps,
> 
> Roger
> 
> > 
> > At 17:09, gioved? 11 maggio 2006, Francisco Javier Aguirre Navarro has 
> > probably written:
> > > Hello, I am a newby in the filed of spatial data analysis, could you please
> > > point me to the right libraries/functions in R  that allow me to import DXF
> > > maps  and analize spatial data related to these maps ? I would appreciaiate
> > > any internet references or books  that may give a good hands-on
> > > introduction to spatial data analysis, I have good knowledge of classical
> > > statistical methods. I need to analyze about 75000 data points scattered on
> > > a map area and I'd like to construct a "density" map of my variable of
> > > interest and eventually see how these densities change in time.
> > >
> > > Thank you very much for your help.
> > >
> > > Francisco J. Aguirre
> > > Bavaria, Bogota -  Colombia.
> > 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Thu May 11 21:06:30 2006
From: zev at zevross.com (Zev Ross)
Date: Thu, 11 May 2006 15:06:30 -0400
Subject: [R-sig-Geo] bubble vs plot.map -- gstat, maptools
Message-ID: <44638B36.2030307@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060511/e0f7b6a9/attachment.html>

From Roger.Bivand at nhh.no  Thu May 11 22:08:16 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 May 2006 22:08:16 +0200 (CEST)
Subject: [R-sig-Geo] bubble vs plot.map -- gstat, maptools
In-Reply-To: <44638B36.2030307@zevross.com>
Message-ID: <Pine.LNX.4.44.0605112158170.16897-100000@reclus.nhh.no>

On Thu, 11 May 2006, Zev Ross wrote:

> Hi All,
> 
> I've got another question for the group. I'm using the bubble function in
> GSTAT to plot the residuals from a krige.cv object. I'd like to place on
> top the outlines of my counties of interest (or even better I'd like to
> plot them in the reverse order). What I'm finding is that even if I
> eliminate the key and eliminate the "asp" call from the bubble function,
> my two plots don't align as they do under more traditional plotting
> circumstances
> 
> Here's the idea:
> 
> kcv28<-krige.cv(avg.pm25~1,pm.all28, vFitRaw, nmax=dim(pm.all28)[1],
> ??? ?nfold=dim(pm.all28)[1])
> bubble(kcv28, "residual", do.sqrt=F)
> map.nyc<-read.shape("D:/junk/counties/all_counties.shp", dbf.data=T)
> plot(map.nyc, add=T, fg="transparent", ol="gray50")

Well, bubble() uses lattice graphics, and the plot() methods are most 
often base graphics:

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1])
xx$crude <- (1000*xx$SID74)/xx$BIR74
out <- bubble(pts, "crude")
plot(xx, axes=TRUE)
symbols(out$panel.args[[1]], circles=out$panel.args.common$cex/10, 
  bg=out$panel.args.common$col, inches=FALSE, add=TRUE)

is pretty close (with a kludgy cex/10 size factor), or

plot(xx, axes=TRUE)
points(out$panel.args[[1]], cex=out$panel.args.common$cex, 
  col=out$panel.args.common$col, pch=out$panel.args.common$pch)

using points(). See

str(out)

to pick out the guts of the bubble lattice plot object. The plot() 
method used here, symbols() and points() are all in base grahics.

Also see a recent paper in JSS by Susumu Tanimura, Chusi Kuroiwa, and 
Tsutomu Mizota, including some legend code:

http://www.jstatsoft.org/

Volume 15, 2006, Issue 5 

Roger

> 
> Any suggestions? Zev
> 
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Thu May 11 23:15:49 2006
From: zev at zevross.com (Zev Ross)
Date: Thu, 11 May 2006 17:15:49 -0400
Subject: [R-sig-Geo] bubble vs plot.map -- gstat, maptools
In-Reply-To: <Pine.LNX.4.44.0605112158170.16897-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605112158170.16897-100000@reclus.nhh.no>
Message-ID: <4463A985.8050000@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060511/73640ea0/attachment.html>

From colinr23 at gmail.com  Fri May 12 04:33:16 2006
From: colinr23 at gmail.com (Colin Robertson)
Date: Thu, 11 May 2006 19:33:16 -0700
Subject: [R-sig-Geo] arConnect
Message-ID: <29b801df0605111933s67c9a489y55d21b5256bfc91b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060511/3c18ab43/attachment.pl>

From Roger.Bivand at nhh.no  Fri May 12 09:16:31 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 May 2006 09:16:31 +0200 (CEST)
Subject: [R-sig-Geo] bubble vs plot.map -- gstat, maptools
In-Reply-To: <4463A985.8050000@zevross.com>
Message-ID: <Pine.LNX.4.44.0605120859500.17533-100000@reclus.nhh.no>

On Thu, 11 May 2006, Zev Ross wrote:

> Hi Roger,
> 
> Wow, thanks again for the quick turnaround. Any suggestions in your code
> in how to get the legend scaled properly to match the "kludgy" scaling of
> the symbols?



> 
> The code below looks pretty good (http://www.zevross.com/temp/test.pdf),
> but the legend scaling is not really appropriate. Thoughts? 

This is because the symbols(..., inches=FALSE) is plotting in user display 
units, but legend() is plotting in font size units - you'd need to fake a 
legend with symbols(..., inches=FALSE) in user display space to get them 
to match.

When I chose the points() route, the cex in the bubbles and the legend are 
the same (as far as heads-up measuring is accurate). The legend bubbles in 
bubbles() also overlap, but this can be alleviated, as you saw, with 
y.intersp=. My reading of the JSS paper and accompanying function 
ProportionalSymbolMap() is that they use symbols, and work hard on the 
legend. The function needs generalising to take other input objects than 
point type old-style Map objects, but that isn't hard. It does have the 
nice quality of plotting big bubbles before small ones, with a border, so 
that overplotted bubbles are distinguished.

Roger

PS. my code was missing:

pts <- SpatialPointsDataFrame(coordinates(xx), as(xx, "data.frame"))

and my legend is:

legend("bottomleft", legend=out$legend$right$args$key$text[[1]], 
  pt.cex=out$legend$right$args$key$points$cex,
  pch=out$legend$right$args$key$points$pch, 
  col=out$legend$right$args$key$points$col,bty="n", y.intersp=1.2) 

> 
> Zev
> 
> 
> par(pty="s")
> map.nyc<-read.shape("D:/junk/all_counties.shp", dbf.data=T)
> out<-bubble(kcv.wint, "residual", do.sqrt=T, col=c(3,2), main="C.V.
> Residuals")
> plot(map.nyc, axes=T)
> 
> 
> ?symbols(out$panel.args[[1]], circles=out$panel.args.common$cex*2000,
> ? bg=out$panel.args.common$col, inches=F, add=TRUE)
> 
> ?
> ?legend(650000, 4470000, legend=out$legend$right$args$key$text[[1]],
> ???? pt.cex=out$legend$right$args$key$points$cex, pch=16,
> ???? col=out$legend$right$args$key$points$col,bty="n", y.intersp=1
> ???? )
> ????
> 
> 
> Roger Bivand wrote:
> 
>  On Thu, 11 May 2006, Zev Ross wrote:
> 
>   
> 
>  Hi All,
> 
> I've got another question for the group. I'm using the bubble function in
> GSTAT to plot the residuals from a krige.cv object. I'd like to place on
> top the outlines of my counties of interest (or even better I'd like to
> plot them in the reverse order). What I'm finding is that even if I
> eliminate the key and eliminate the "asp" call from the bubble function,
> my two plots don't align as they do under more traditional plotting
> circumstances
> 
> Here's the idea:
> 
> kcv28<-krige.cv(avg.pm25~1,pm.all28, vFitRaw, nmax=dim(pm.all28)[1],
> ??? ?nfold=dim(pm.all28)[1])
> bubble(kcv28, "residual", do.sqrt=F)
> map.nyc<-read.shape("D:/junk/counties/all_counties.shp", dbf.data=T)
> plot(map.nyc, add=T, fg="transparent", ol="gray50")
>     
> 
>  Well, bubble() uses lattice graphics, and the plot() methods are most 
> often base graphics:
> 
> library(maptools)
> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1])
> xx$crude <- (1000*xx$SID74)/xx$BIR74
> out <- bubble(pts, "crude")
> plot(xx, axes=TRUE)
> symbols(out$panel.args[[1]], circles=out$panel.args.common$cex/10, 
>   bg=out$panel.args.common$col, inches=FALSE, add=TRUE)
> 
> is pretty close (with a kludgy cex/10 size factor), or
> 
> plot(xx, axes=TRUE)
> points(out$panel.args[[1]], cex=out$panel.args.common$cex, 
>   col=out$panel.args.common$col, pch=out$panel.args.common$pch)
> 
> using points(). See
> 
> str(out)
> 
> to pick out the guts of the bubble lattice plot object. The plot() 
> method used here, symbols() and points() are all in base grahics.
> 
> Also see a recent paper in JSS by Susumu Tanimura, Chusi Kuroiwa, and 
> Tsutomu Mizota, including some legend code:
> 
> http://www.jstatsoft.org/
> 
> Volume 15, 2006, Issue 5 
> 
> Roger
> 
>   
> 
>  Any suggestions? Zev
> 
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 
>     
> 
> 
> --
> Zev Ross
> ZevRoss Spatial Analysis
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri May 12 20:53:35 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 May 2006 20:53:35 +0200 (CEST)
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <15f8e67d0605120948s28f2a2bdqcc263cd24edced96@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0605122038150.18453-100000@reclus.nhh.no>

On Fri, 12 May 2006, Xiaohua Dai wrote:

> Sorry, I did not make my question clear. Since I have a point theme
> with many points, some of them may clump together. the problems here
> are:

A more specific follow-up after my reply directly to R-help.

I'm assuming you have a running R, and that convex hulls are what you 
want.

Take a random data set:

set.seed(1)
xy <- matrix(runif(500, 0, 10), ncol=2)
xy_clusts <- hclust(dist(xy), method="complete")
# complete linkage hierarchical clustering
plot(xy_clusts)
# shows the clustering tree
cl_10 <- cutree(xy_clusts, 10)
cl_20 <- cutree(xy_clusts, 20)
cl_30 <- cutree(xy_clusts, 30)
# cut the tree - the objects contain the memberships
which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
# construct convex hull polygons for each cluster
plot(xy)
res <- lapply(chulls_cl_10, polygon)
# and repeat for cl_20 and cl_30
which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
plot(xy)
res <- lapply(chulls_cl_20, polygon)
which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
plot(xy)
res <- lapply(chulls_cl_30, polygon)

If you need the list of convex hulls out as a shapefile, we can do that, 
if you need a raster, I'd suggest using kernel density with different 
bandwidths for a start, and NA out the densities below a chosen threshold.

Hope this helps,

Roger Bivand

PS. Use package maptools, function readShapePoints() to read your 
shapefile, and coordinates() of the input object to extract the 
coordinates. If need be, project from geographical coordinates using 
transform methods in package rgdal.


> 1.  how to find clumps in a point theme?
> 2.  the convex-hull extension I found only deal with all the points in
> a theme at each time?  how to make each convex hull around each point
> clump automatically?
> 
> Thanks.
> 
> Xiaohua
> 
> 
> 
> On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > Xiaohua,
> >
> > That would be one way to do it. There are others.
> > Try searching ArcScripts for "convex hull"
> > http://arcscripts.esri.com/
> >
> > For example:
> > http://arcscripts.esri.com/details.asp?dbid=14535
> > or
> > http://arcscripts.esri.com/details.asp?dbid=12084
> >
> > Bob
> >
> >
> > -----Original Message-----
> > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > Sent: Friday, May 12, 2006 2:33 AM
> > To: ESRI-L at esri.com
> > Subject: [ESRI-L] outline polygons of point clumps
> >
> > Dear all,
> >
> > How to generate one outline polygon for each point clump? Are there
> > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > had a quick look at the package adehabitat and did not find the
> > function.
> >
> > To my knowledge, I could do it as follows: 1) make a grid map of my
> > study area with cell values = 0; 2) assign 1 to the cells containing
> > at least one point; 3) convert the 1-value cells into polygons.
> >
> > Am I right?
> >
> > Thanks
> > Xiaohua
> >
> >
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri May 12 21:15:15 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 May 2006 21:15:15 +0200 (CEST)
Subject: [R-sig-Geo] arConnect
In-Reply-To: <29b801df0605111933s67c9a489y55d21b5256bfc91b@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0605122105560.18453-100000@reclus.nhh.no>

On Thu, 11 May 2006, Colin Robertson wrote:

> Hello List,
> 
> Does anyone know if the arcGIS extension called ArConnect (
> http://www.gisvet.org/Documents/GisVet04/RegularPaper/Tait.pdf )
> is released or available anywhere.  I've had a hard time finding anything
> but this one paper.  I'm looking for the most comprehensive tools for kernel
> density estimated surfaces (with cross validation bandwidth selection and
> the boundary correction).

I think the answer is negative - the project was promising, but it is 
difficult to find subsequent references. If you need to integrate with 
ArcGIS, you may find the code at:

http://www.nicholas.duke.edu/geospatial/software/

of use. From there, you can try to see which kernel density functions in R 
suit you best. If you visit http://www.spatstat.org/, you can find plenty 
of information (ksmooth.ppp), and there are alternatives like kernel2d() 
and mse2d() in splancs, but you'll need to look around to find a function 
to meet your needs.

Roger


> 
> Thanks,
> 
> Colin
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From zev at zevross.com  Fri May 12 21:30:38 2006
From: zev at zevross.com (Zev Ross)
Date: Fri, 12 May 2006 15:30:38 -0400
Subject: [R-sig-Geo] bubble vs plot.map -- gstat, maptools
In-Reply-To: <Pine.LNX.4.44.0605120859500.17533-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605120859500.17533-100000@reclus.nhh.no>
Message-ID: <4464E25E.6080309@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060512/bb1954a0/attachment.html>

From ecoinformatics at gmail.com  Fri May 12 22:00:20 2006
From: ecoinformatics at gmail.com (Xiaohua Dai)
Date: Fri, 12 May 2006 22:00:20 +0200
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <Pine.LNX.4.44.0605122038150.18453-100000@reclus.nhh.no>
References: <15f8e67d0605120948s28f2a2bdqcc263cd24edced96@mail.gmail.com>
	<Pine.LNX.4.44.0605122038150.18453-100000@reclus.nhh.no>
Message-ID: <15f8e67d0605121300k6e131958mde3242bf9966fff1@mail.gmail.com>

Hi Roger,

Thank you for your kindly help. It is exactly what I want. I will try
to understand your programming.  I think the program should be useful
in many fields as you indicated.

I did not expect the problem can be solved so easily. Again, R is very
powerful with so many good functions. I am quite interested in lapply
and tapply. I will find some references/websites on their
applications.

Also thanks to remind me of the post guide.

Best wishes
Xiaohua

On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 12 May 2006, Xiaohua Dai wrote:
>
> > Sorry, I did not make my question clear. Since I have a point theme
> > with many points, some of them may clump together. the problems here
> > are:
>
> A more specific follow-up after my reply directly to R-help.
>
> I'm assuming you have a running R, and that convex hulls are what you
> want.
>
> Take a random data set:
>
> set.seed(1)
> xy <- matrix(runif(500, 0, 10), ncol=2)
> xy_clusts <- hclust(dist(xy), method="complete")
> # complete linkage hierarchical clustering
> plot(xy_clusts)
> # shows the clustering tree
> cl_10 <- cutree(xy_clusts, 10)
> cl_20 <- cutree(xy_clusts, 20)
> cl_30 <- cutree(xy_clusts, 30)
> # cut the tree - the objects contain the memberships
> which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> # construct convex hull polygons for each cluster
> plot(xy)
> res <- lapply(chulls_cl_10, polygon)
> # and repeat for cl_20 and cl_30
> which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
> chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
> plot(xy)
> res <- lapply(chulls_cl_20, polygon)
> which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
> chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
> plot(xy)
> res <- lapply(chulls_cl_30, polygon)
>
> If you need the list of convex hulls out as a shapefile, we can do that,
> if you need a raster, I'd suggest using kernel density with different
> bandwidths for a start, and NA out the densities below a chosen threshold.
>
> Hope this helps,
>
> Roger Bivand
>
> PS. Use package maptools, function readShapePoints() to read your
> shapefile, and coordinates() of the input object to extract the
> coordinates. If need be, project from geographical coordinates using
> transform methods in package rgdal.
>
>
> > 1.  how to find clumps in a point theme?
> > 2.  the convex-hull extension I found only deal with all the points in
> > a theme at each time?  how to make each convex hull around each point
> > clump automatically?
> >
> > Thanks.
> >
> > Xiaohua
> >
> >
> >
> > On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > > Xiaohua,
> > >
> > > That would be one way to do it. There are others.
> > > Try searching ArcScripts for "convex hull"
> > > http://arcscripts.esri.com/
> > >
> > > For example:
> > > http://arcscripts.esri.com/details.asp?dbid=14535
> > > or
> > > http://arcscripts.esri.com/details.asp?dbid=12084
> > >
> > > Bob
> > >
> > >
> > > -----Original Message-----
> > > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > > Sent: Friday, May 12, 2006 2:33 AM
> > > To: ESRI-L at esri.com
> > > Subject: [ESRI-L] outline polygons of point clumps
> > >
> > > Dear all,
> > >
> > > How to generate one outline polygon for each point clump? Are there
> > > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > > had a quick look at the package adehabitat and did not find the
> > > function.
> > >
> > > To my knowledge, I could do it as follows: 1) make a grid map of my
> > > study area with cell values = 0; 2) assign 1 to the cells containing
> > > at least one point; 3) convert the 1-value cells into polygons.
> > >
> > > Am I right?
> > >
> > > Thanks
> > > Xiaohua
> > >
> > >
> >
> >
> >
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



From Roger.Bivand at nhh.no  Fri May 12 22:40:54 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 May 2006 22:40:54 +0200 (CEST)
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <15f8e67d0605121300k6e131958mde3242bf9966fff1@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0605122236470.18453-100000@reclus.nhh.no>

On Fri, 12 May 2006, Xiaohua Dai wrote:

> Hi Roger,
> 
> Thank you for your kindly help. It is exactly what I want. I will try
> to understand your programming.  I think the program should be useful
> in many fields as you indicated.
> 
> I did not expect the problem can be solved so easily. Again, R is very
> powerful with so many good functions. I am quite interested in lapply
> and tapply. I will find some references/websites on their
> applications.

Note that using a different method= argument to hclust, or a different
metric to dist(), you will get different clusters, as well as getting
different numbers for different cutree() values. If you have specific
range distances (from an off-list message, the points are rhino), you
could also use other methods to create your own clusters where the first
nearest neighbour distance is less than your empirically observed range -
there should be a literature on this among ecologists, which others on the
list may be able to help with. Is there anything in the adehabitat
package, or others?

Roger

> 
> Also thanks to remind me of the post guide.
> 
> Best wishes
> Xiaohua
> 
> On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > On Fri, 12 May 2006, Xiaohua Dai wrote:
> >
> > > Sorry, I did not make my question clear. Since I have a point theme
> > > with many points, some of them may clump together. the problems here
> > > are:
> >
> > A more specific follow-up after my reply directly to R-help.
> >
> > I'm assuming you have a running R, and that convex hulls are what you
> > want.
> >
> > Take a random data set:
> >
> > set.seed(1)
> > xy <- matrix(runif(500, 0, 10), ncol=2)
> > xy_clusts <- hclust(dist(xy), method="complete")
> > # complete linkage hierarchical clustering
> > plot(xy_clusts)
> > # shows the clustering tree
> > cl_10 <- cutree(xy_clusts, 10)
> > cl_20 <- cutree(xy_clusts, 20)
> > cl_30 <- cutree(xy_clusts, 30)
> > # cut the tree - the objects contain the memberships
> > which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> > chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> > # construct convex hull polygons for each cluster
> > plot(xy)
> > res <- lapply(chulls_cl_10, polygon)
> > # and repeat for cl_20 and cl_30
> > which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
> > chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
> > plot(xy)
> > res <- lapply(chulls_cl_20, polygon)
> > which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
> > chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
> > plot(xy)
> > res <- lapply(chulls_cl_30, polygon)
> >
> > If you need the list of convex hulls out as a shapefile, we can do that,
> > if you need a raster, I'd suggest using kernel density with different
> > bandwidths for a start, and NA out the densities below a chosen threshold.
> >
> > Hope this helps,
> >
> > Roger Bivand
> >
> > PS. Use package maptools, function readShapePoints() to read your
> > shapefile, and coordinates() of the input object to extract the
> > coordinates. If need be, project from geographical coordinates using
> > transform methods in package rgdal.
> >
> >
> > > 1.  how to find clumps in a point theme?
> > > 2.  the convex-hull extension I found only deal with all the points in
> > > a theme at each time?  how to make each convex hull around each point
> > > clump automatically?
> > >
> > > Thanks.
> > >
> > > Xiaohua
> > >
> > >
> > >
> > > On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > > > Xiaohua,
> > > >
> > > > That would be one way to do it. There are others.
> > > > Try searching ArcScripts for "convex hull"
> > > > http://arcscripts.esri.com/
> > > >
> > > > For example:
> > > > http://arcscripts.esri.com/details.asp?dbid=14535
> > > > or
> > > > http://arcscripts.esri.com/details.asp?dbid=12084
> > > >
> > > > Bob
> > > >
> > > >
> > > > -----Original Message-----
> > > > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > > > Sent: Friday, May 12, 2006 2:33 AM
> > > > To: ESRI-L at esri.com
> > > > Subject: [ESRI-L] outline polygons of point clumps
> > > >
> > > > Dear all,
> > > >
> > > > How to generate one outline polygon for each point clump? Are there
> > > > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > > > had a quick look at the package adehabitat and did not find the
> > > > function.
> > > >
> > > > To my knowledge, I could do it as follows: 1) make a grid map of my
> > > > study area with cell values = 0; 2) assign 1 to the cells containing
> > > > at least one point; 3) convert the 1-value cells into polygons.
> > > >
> > > > Am I right?
> > > >
> > > > Thanks
> > > > Xiaohua
> > > >
> > > >
> > >
> > >
> > >
> >
> > --
> > Roger Bivand
> > Economic Geography Section, Department of Economics, Norwegian School of
> > Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> > Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> > e-mail: Roger.Bivand at nhh.no
> >
> >
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ecoinformatics at gmail.com  Fri May 12 23:47:56 2006
From: ecoinformatics at gmail.com (Xiaohua Dai)
Date: Fri, 12 May 2006 23:47:56 +0200
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <Pine.LNX.4.44.0605122236470.18453-100000@reclus.nhh.no>
References: <15f8e67d0605121300k6e131958mde3242bf9966fff1@mail.gmail.com>
	<Pine.LNX.4.44.0605122236470.18453-100000@reclus.nhh.no>
Message-ID: <15f8e67d0605121447o35213a2bqc45553badfb91213@mail.gmail.com>

My idea is to use your procedure to obtain food-tree patches of
rhinos, then relate the patches to rhino movement pattern. For
example, rhinos may move more slowly in food patches than outside the
patches. I forgot one thing, could you also tell me how to write these
hulls into a polygon shape file? write.polylistShape {maptools} or
convert.to.shapefile {shapefiles}?

Thanks
Xiaohua

On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 12 May 2006, Xiaohua Dai wrote:
>
> > Hi Roger,
> >
> > Thank you for your kindly help. It is exactly what I want. I will try
> > to understand your programming.  I think the program should be useful
> > in many fields as you indicated.
> >
> > I did not expect the problem can be solved so easily. Again, R is very
> > powerful with so many good functions. I am quite interested in lapply
> > and tapply. I will find some references/websites on their
> > applications.
>
> Note that using a different method= argument to hclust, or a different
> metric to dist(), you will get different clusters, as well as getting
> different numbers for different cutree() values. If you have specific
> range distances (from an off-list message, the points are rhino), you
> could also use other methods to create your own clusters where the first
> nearest neighbour distance is less than your empirically observed range -
> there should be a literature on this among ecologists, which others on the
> list may be able to help with. Is there anything in the adehabitat
> package, or others?
>
> Roger
>
> >
> > Also thanks to remind me of the post guide.
> >
> > Best wishes
> > Xiaohua
> >
> > On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > > On Fri, 12 May 2006, Xiaohua Dai wrote:
> > >
> > > > Sorry, I did not make my question clear. Since I have a point theme
> > > > with many points, some of them may clump together. the problems here
> > > > are:
> > >
> > > A more specific follow-up after my reply directly to R-help.
> > >
> > > I'm assuming you have a running R, and that convex hulls are what you
> > > want.
> > >
> > > Take a random data set:
> > >
> > > set.seed(1)
> > > xy <- matrix(runif(500, 0, 10), ncol=2)
> > > xy_clusts <- hclust(dist(xy), method="complete")
> > > # complete linkage hierarchical clustering
> > > plot(xy_clusts)
> > > # shows the clustering tree
> > > cl_10 <- cutree(xy_clusts, 10)
> > > cl_20 <- cutree(xy_clusts, 20)
> > > cl_30 <- cutree(xy_clusts, 30)
> > > # cut the tree - the objects contain the memberships
> > > which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> > > chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> > > # construct convex hull polygons for each cluster
> > > plot(xy)
> > > res <- lapply(chulls_cl_10, polygon)
> > > # and repeat for cl_20 and cl_30
> > > which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
> > > chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
> > > plot(xy)
> > > res <- lapply(chulls_cl_20, polygon)
> > > which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
> > > chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
> > > plot(xy)
> > > res <- lapply(chulls_cl_30, polygon)
> > >
> > > If you need the list of convex hulls out as a shapefile, we can do that,
> > > if you need a raster, I'd suggest using kernel density with different
> > > bandwidths for a start, and NA out the densities below a chosen threshold.
> > >
> > > Hope this helps,
> > >
> > > Roger Bivand
> > >
> > > PS. Use package maptools, function readShapePoints() to read your
> > > shapefile, and coordinates() of the input object to extract the
> > > coordinates. If need be, project from geographical coordinates using
> > > transform methods in package rgdal.
> > >
> > >
> > > > 1.  how to find clumps in a point theme?
> > > > 2.  the convex-hull extension I found only deal with all the points in
> > > > a theme at each time?  how to make each convex hull around each point
> > > > clump automatically?
> > > >
> > > > Thanks.
> > > >
> > > > Xiaohua
> > > >
> > > >
> > > >
> > > > On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > > > > Xiaohua,
> > > > >
> > > > > That would be one way to do it. There are others.
> > > > > Try searching ArcScripts for "convex hull"
> > > > > http://arcscripts.esri.com/
> > > > >
> > > > > For example:
> > > > > http://arcscripts.esri.com/details.asp?dbid=14535
> > > > > or
> > > > > http://arcscripts.esri.com/details.asp?dbid=12084
> > > > >
> > > > > Bob
> > > > >
> > > > >
> > > > > -----Original Message-----
> > > > > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > > > > Sent: Friday, May 12, 2006 2:33 AM
> > > > > To: ESRI-L at esri.com
> > > > > Subject: [ESRI-L] outline polygons of point clumps
> > > > >
> > > > > Dear all,
> > > > >
> > > > > How to generate one outline polygon for each point clump? Are there
> > > > > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > > > > had a quick look at the package adehabitat and did not find the
> > > > > function.
> > > > >
> > > > > To my knowledge, I could do it as follows: 1) make a grid map of my
> > > > > study area with cell values = 0; 2) assign 1 to the cells containing
> > > > > at least one point; 3) convert the 1-value cells into polygons.
> > > > >
> > > > > Am I right?
> > > > >
> > > > > Thanks
> > > > > Xiaohua
> > > > >
> > > > >
> > > >
> > > >
> > > >
> > >
> > > --
> > > Roger Bivand
> > > Economic Geography Section, Department of Economics, Norwegian School of
> > > Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> > > Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> > > e-mail: Roger.Bivand at nhh.no
> > >



From Thomas.Adams at noaa.gov  Sat May 13 02:34:04 2006
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Fri, 12 May 2006 20:34:04 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
In-Reply-To: <Pine.LNX.4.44.0604282119500.23449-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0604282119500.23449-100000@reclus.nhh.no>
Message-ID: <4465297C.80900@noaa.gov>

Roger,

I have made considerable progress in what I was trying to do with gstat 
& Universal Kriging using R. I was fortunate enough to find a detailed 
example of what I was trying to do: http://spatial-analyst.net/RKguide.php.

I exported from GRASS my elevation grid, "gtopo30.dem", and temperature 
point file, "temps.txt", to ascii files to assure I followed a parallel 
path with my data.

So, with my data, following Tomislav Hengl's example, I have:

 > temps<-read.delim("temps.txt",sep=" ")
 > summary(temps)

cat lon lat z T name
Min. : 1.00 Min. :-90.05 Min. :35.82 Min. : 99.0 Min. :61.00 AGC : 1
1st Qu.: 31.75 1st Qu.:-86.63 1st Qu.:38.27 1st Qu.: 197.0 1st Qu.:64.00 
AID : 1
Median : 60.50 Median :-84.06 Median :40.09 Median : 255.5 Median :66.00 
ALN : 1
Mean : 60.37 Mean :-84.14 Mean :39.86 Mean : 314.2 Mean :66.83 AOH : 1
3rd Qu.: 89.25 3rd Qu.:-81.47 3rd Qu.:41.58 3rd Qu.: 360.0 3rd Qu.:69.00 
AOO : 1
Max. :118.00 Max. :-78.32 Max. :42.49 Max. :1155.0 Max. :73.00 ARB : 1
(Other):110
X Y
Min. :-341460 Min. :-342057
1st Qu.: -53847 1st Qu.: -71919
Median : 163999 Median : 119784
Mean : 154474 Mean : 99916
3rd Qu.: 371950 3rd Qu.: 282632
Max. : 632335 Max. : 398186

 > library(sp)
 > dem<-read.asciigrid("gtopo30.dem")
 > class(dem)
[1] "SpatialGridDataFrame"
attr(,"package")
[1] "sp"
 > image(dem)
 > points(Y ~ X, data=temps)
 > class(temps)
[1] "data.frame"
 > coordinates(temps)=~X+Y
 > dem.ov=overlay(dem,temps)
 > summary(dem.ov)

Object of class SpatialPointsDataFrame
Coordinates:
min max
X -341459.8 632334.6
Y -342056.9 398185.9
Is projected: NA
proj4string : [NA]
Number of points: 116
Data attributes:
gtopo30.dem
Min. : 115.3
1st Qu.: 196.9
Median : 245.4
Mean : 306.9
3rd Qu.: 331.0
Max. :1064.5

 > temps$gtopo30.dem=dem.ov$gtopo30.dem
 > library(lattice)
 > plot(T~gtopo30.dem, as.data.frame(temps))
 > abline(lm(T~gtopo30.dem, as.data.frame(temps)))
 > library(gstat)

 > vgm <- vgm(psill=8,model="Exp",range=600000,nugget=3.8)
 > vgm_temps_r<-fit.variogram(variogram(T~gtopo30.dem,temps), model=vgm)
 > plot(variogram(T~gtopo30.dem,temps),main = "fitted by gstat")
 > temps_uk<-krige(T~gtopo30.dem,temps,dem, vgm_temps_r)
[using universal kriging]
 > library(lattice)
 > trellis.par.set(sp.theme())
 > spplot(temps_uk,"var1.pred", main="Universal kriging predictions 
TEMPERATURE")


Which works perfectly on my Macintosh running Mac OS X 10.4 and using R 
2.2.1. (see attachment, temperatures in deg. F) However, following the 
*identical* steps with the identical data on Linux, at the step:

temps_uk<-krige(T~gtopo30.dem,temps,dem, vgm_temps_r)

I get the error:

Error in eval(expr, envir, enclos) : object "gtopo30.dem" not found

This has me baffled; any thoughts? I could send you my files if you 
would like to see what happens for you?

Regards,
Tom

BTW, the grid spacing on my DEM is coarse (9 km) and I will probably do 
my final analyses at 1-km.


Roger Bivand wrote:
> On Fri, 28 Apr 2006, Thomas Adams wrote:
>
>   
>> Roger,
>>
>> Your suggestion:
>>
>> fullgrid(dem) <- FALSE
>>
>> did turn dem into class type SpatialGridDataFrame, but when I tried:
>>
>> z <- predict(UK_fit,newdata=dem)
>>
>> I got an error:
>>
>> Error in model.frame(... :
>> invalid variable type.
>>
>> I think I should restate the problem:
>>
>> I have a file 'temps' which has class SpatialPointsDataFrame read from 
>> GRASS 6.1, that looks like:
>>
>> coordinates cat x y z temp name
>> 1 (-341460, -2154.42) 1 -90.05 38.90 166 63 ALN
>> 2 (-198769, 301388) 2 -88.47 41.77 215 67 ARR
>> 3 (-334899, -40321) 3 -89.95 38.55 140 66 BLV
>> 4 (-240028, 163910) 4 -88.92 40.48 268 69 BMI
>> 5 (-187957, 114806) 5 -88.27 40.04 229 64 CMI
>> 6 (-351730, -37305.9) 6 -90.15 38.57 126 65 CPS
>> 7 (-242424, 98244.7) 7 -88.92 39.87 204 66 DEC
>> 8 (-179844, 315889) 8 -88.24 41.91 232 69 DPA
>> 9 (-136093, -24538.2) 9 -87.61 38.76 131 68 LWV
>> 10 (-278964, -126152) 10 -89.25 37.78 125 66 MDH
>> 11 (-140792, 302011) 11 -87.75 41.79 187 73 MDW
>> 12 (-364737, 274189) 12 -90.51 41.45 180 73 MLI
>> 13 (-190503, 54493.9) 13 -88.28 39.48 219 64 MTO
>>
>> and I have a a file 'dem' which has class SpatialGridDataFrame which 
>> just consists of grid of elevation values read from GRASS 6.1 using 
>> dem<-readFLOAT6sp(). (Sorry, I know I'm repeating myself).
>>
>> What I want to do is to use the grid of elevation values ('dem') as a 
>> proxy in the spatial interpolation of the 'temp' values in my 'temps' 
>> file that are located at the coordinates in parentheses(). Notice that 
>> the temps file also has 'z' values of elevations. So, is this what you 
>> already understood? Converting 'dem' to a SpatialPixelsDataFrame seemed 
>> to only leave me with the grid locations and not the elevation values ? 
>> is this right.
>>     
>
> What does:
>
> summary(dem) 
>
> say before and after doing
>
> fullgrid(dem) <- FALSE?
>
> Afterwards it should be a SpatialPixelsDataFrame with 
>
> names(dem)
>
> being "z". Saying summary(dem) will give you an idea of what is inside, 
> str() should too.
>
> Roger
>
> PS. This is usually a one-off thing, once it works, you note down how, and 
> then it just does from then on.
>
>
>   
>> Thanks again for your help!
>>
>> Regards,
>> Tom
>>
>>
>> Roger Bivand wrote:
>>     
>>> On Fri, 28 Apr 2006, Thomas Adams wrote:
>>>
>>>   
>>>       
>>>> Roger,
>>>>
>>>> This got me further along, but I am encountering a problem with:
>>>>
>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>>
>>>> The gstat step works for me, where I have:
>>>>
>>>> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
>>>>
>>>> temps has class SpatialPointsDataFrame:
>>>>
>>>>               coordinates cat      x     y    z temp name
>>>> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
>>>> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
>>>> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
>>>> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
>>>> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
>>>> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
>>>> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
>>>> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
>>>> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
>>>> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
>>>> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
>>>> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
>>>> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
>>>>
>>>> and dem has class SpatialGridDataFrame and just consists of grid values.
>>>>     
>>>>         
>>> I think 
>>>
>>> fullgrid(dem) <- FALSE
>>>
>>> should make a SpatialPixelsDataFrame, but you'll have to make sure the 
>>> name of the dem variable is the same as in the formula.
>>>
>>> Roger
>>>
>>>   
>>>       
>>>> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
>>>> example):
>>>>
>>>> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
>>>>
>>>> I have nothing like meuse.grid, so this does not work. I can use 
>>>> image(dem), which produces a plot of elevation values. My point is that 
>>>> meuse.grid and my dem files have very different structures.
>>>>
>>>> I'm not sure where to go to from here.
>>>>
>>>> Regards,
>>>> Tom
>>>>
>>>>
>>>> Roger Bivand wrote:
>>>>     
>>>>         
>>>>> On Thu, 27 Apr 2006, Thomas Adams wrote:
>>>>>
>>>>>   
>>>>>       
>>>>>           
>>>>>> List:
>>>>>>
>>>>>> I can not seem to work out the syntax for using R/gstat within a GRASS 
>>>>>> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
>>>>>> grid) and point data for temperature; theoretically, the temperatures 
>>>>>> should relate to elevation. So, I am trying to spatially interpolate the 
>>>>>> temperature data based on the elevations at the grid points. How do I 
>>>>>> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
>>>>>> have no trouble reading in my elevation data (DEM) from GRASS and I have 
>>>>>> no problem doing ordinary kriging of my temperature data using 
>>>>>> GRASS/R/gstat.
>>>>>>     
>>>>>>         
>>>>>>             
>>>>> What do the data look like? Do you have temperature and elevation at the
>>>>> observation points and elevation over the grid? If temperature is the 
>>>>> variable for which you want to interpolate, then the formula argument in 
>>>>> the gstat() function would be temp ~ elev, data=pointsdata (if a 
>>>>> SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
>>>>> step would need a SpatialGridDataFrame object as newdata, with elev as 
>>>>> (one of) the columns in the data slot.
>>>>>
>>>>> An example for the Meuse bank data in Burrough and McDonnell:
>>>>>
>>>>> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
>>>>> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
>>>>>   nugget=1))
>>>>> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
>>>>>   model=uefitted)
>>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>>>
>>>>> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
>>>>> with flood frequencies in Fldf (actually a factor, but works neatly).
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>   
>>>>>       
>>>>>           
>>>>>> Regards,
>>>>>> Tom
>>>>>>
>>>>>>
>>>>>>     
>>>>>>         
>>>>>>             
>>>>>   
>>>>>       
>>>>>           
>>>>     
>>>>         
>>>   
>>>       
>>
>>     
>
>   


-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033

-------------- next part --------------
A non-text attachment was scrubbed...
Name: UK temps.png
Type: image/png
Size: 123800 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060512/88016ae8/attachment.png>

From Roger.Bivand at nhh.no  Sat May 13 10:16:47 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 13 May 2006 10:16:47 +0200 (CEST)
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
In-Reply-To: <4465297C.80900@noaa.gov>
Message-ID: <Pine.LNX.4.44.0605131011400.19126-100000@reclus.nhh.no>

Thomas:

Please do:

sessionInfo()

on both machines, and see if any of the package versions are different.

It often also helps to name function arguments explicitly, to be sure that 
they are being understood correctly inside the functions. Depending on the 
class of the data= arugment, as far as I recall different versions of the 
gstat package treat the locations= argument differently.

Roger


On Fri, 12 May 2006, Thomas Adams wrote:

> Roger,
> 
> I have made considerable progress in what I was trying to do with gstat 
> & Universal Kriging using R. I was fortunate enough to find a detailed 
> example of what I was trying to do: http://spatial-analyst.net/RKguide.php.
> 
> I exported from GRASS my elevation grid, "gtopo30.dem", and temperature 
> point file, "temps.txt", to ascii files to assure I followed a parallel 
> path with my data.
> 
> So, with my data, following Tomislav Hengl's example, I have:
> 
>  > temps<-read.delim("temps.txt",sep=" ")
>  > summary(temps)
> 
> cat lon lat z T name
> Min. : 1.00 Min. :-90.05 Min. :35.82 Min. : 99.0 Min. :61.00 AGC : 1
> 1st Qu.: 31.75 1st Qu.:-86.63 1st Qu.:38.27 1st Qu.: 197.0 1st Qu.:64.00 
> AID : 1
> Median : 60.50 Median :-84.06 Median :40.09 Median : 255.5 Median :66.00 
> ALN : 1
> Mean : 60.37 Mean :-84.14 Mean :39.86 Mean : 314.2 Mean :66.83 AOH : 1
> 3rd Qu.: 89.25 3rd Qu.:-81.47 3rd Qu.:41.58 3rd Qu.: 360.0 3rd Qu.:69.00 
> AOO : 1
> Max. :118.00 Max. :-78.32 Max. :42.49 Max. :1155.0 Max. :73.00 ARB : 1
> (Other):110
> X Y
> Min. :-341460 Min. :-342057
> 1st Qu.: -53847 1st Qu.: -71919
> Median : 163999 Median : 119784
> Mean : 154474 Mean : 99916
> 3rd Qu.: 371950 3rd Qu.: 282632
> Max. : 632335 Max. : 398186
> 
>  > library(sp)
>  > dem<-read.asciigrid("gtopo30.dem")
>  > class(dem)
> [1] "SpatialGridDataFrame"
> attr(,"package")
> [1] "sp"
>  > image(dem)
>  > points(Y ~ X, data=temps)
>  > class(temps)
> [1] "data.frame"
>  > coordinates(temps)=~X+Y
>  > dem.ov=overlay(dem,temps)
>  > summary(dem.ov)
> 
> Object of class SpatialPointsDataFrame
> Coordinates:
> min max
> X -341459.8 632334.6
> Y -342056.9 398185.9
> Is projected: NA
> proj4string : [NA]
> Number of points: 116
> Data attributes:
> gtopo30.dem
> Min. : 115.3
> 1st Qu.: 196.9
> Median : 245.4
> Mean : 306.9
> 3rd Qu.: 331.0
> Max. :1064.5
> 
>  > temps$gtopo30.dem=dem.ov$gtopo30.dem
>  > library(lattice)
>  > plot(T~gtopo30.dem, as.data.frame(temps))
>  > abline(lm(T~gtopo30.dem, as.data.frame(temps)))
>  > library(gstat)
> 
>  > vgm <- vgm(psill=8,model="Exp",range=600000,nugget=3.8)
>  > vgm_temps_r<-fit.variogram(variogram(T~gtopo30.dem,temps), model=vgm)
>  > plot(variogram(T~gtopo30.dem,temps),main = "fitted by gstat")
>  > temps_uk<-krige(T~gtopo30.dem,temps,dem, vgm_temps_r)
> [using universal kriging]
>  > library(lattice)
>  > trellis.par.set(sp.theme())
>  > spplot(temps_uk,"var1.pred", main="Universal kriging predictions 
> TEMPERATURE")
> 
> 
> Which works perfectly on my Macintosh running Mac OS X 10.4 and using R 
> 2.2.1. (see attachment, temperatures in deg. F) However, following the 
> *identical* steps with the identical data on Linux, at the step:
> 
> temps_uk<-krige(T~gtopo30.dem,temps,dem, vgm_temps_r)
> 
> I get the error:
> 
> Error in eval(expr, envir, enclos) : object "gtopo30.dem" not found
> 
> This has me baffled; any thoughts? I could send you my files if you 
> would like to see what happens for you

> 
> Regards,
> Tom
> 
> BTW, the grid spacing on my DEM is coarse (9 km) and I will probably do 
> my final analyses at 1-km.
> 
> 
> Roger Bivand wrote:
> > On Fri, 28 Apr 2006, Thomas Adams wrote:
> >
> >   
> >> Roger,
> >>
> >> Your suggestion:
> >>
> >> fullgrid(dem) <- FALSE
> >>
> >> did turn dem into class type SpatialGridDataFrame, but when I tried:
> >>
> >> z <- predict(UK_fit,newdata=dem)
> >>
> >> I got an error:
> >>
> >> Error in model.frame(... :
> >> invalid variable type.
> >>
> >> I think I should restate the problem:
> >>
> >> I have a file 'temps' which has class SpatialPointsDataFrame read from 
> >> GRASS 6.1, that looks like:
> >>
> >> coordinates cat x y z temp name
> >> 1 (-341460, -2154.42) 1 -90.05 38.90 166 63 ALN
> >> 2 (-198769, 301388) 2 -88.47 41.77 215 67 ARR
> >> 3 (-334899, -40321) 3 -89.95 38.55 140 66 BLV
> >> 4 (-240028, 163910) 4 -88.92 40.48 268 69 BMI
> >> 5 (-187957, 114806) 5 -88.27 40.04 229 64 CMI
> >> 6 (-351730, -37305.9) 6 -90.15 38.57 126 65 CPS
> >> 7 (-242424, 98244.7) 7 -88.92 39.87 204 66 DEC
> >> 8 (-179844, 315889) 8 -88.24 41.91 232 69 DPA
> >> 9 (-136093, -24538.2) 9 -87.61 38.76 131 68 LWV
> >> 10 (-278964, -126152) 10 -89.25 37.78 125 66 MDH
> >> 11 (-140792, 302011) 11 -87.75 41.79 187 73 MDW
> >> 12 (-364737, 274189) 12 -90.51 41.45 180 73 MLI
> >> 13 (-190503, 54493.9) 13 -88.28 39.48 219 64 MTO
> >>
> >> and I have a a file 'dem' which has class SpatialGridDataFrame which 
> >> just consists of grid of elevation values read from GRASS 6.1 using 
> >> dem<-readFLOAT6sp(). (Sorry, I know I'm repeating myself).
> >>
> >> What I want to do is to use the grid of elevation values ('dem') as a 
> >> proxy in the spatial interpolation of the 'temp' values in my 'temps' 
> >> file that are located at the coordinates in parentheses(). Notice that 
> >> the temps file also has 'z' values of elevations. So, is this what you 
> >> already understood? Converting 'dem' to a SpatialPixelsDataFrame seemed 
> >> to only leave me with the grid locations and not the elevation values ? 
> >> is this right.
> >>     
> >
> > What does:
> >
> > summary(dem) 
> >
> > say before and after doing
> >
> > fullgrid(dem) <- FALSE?
> >
> > Afterwards it should be a SpatialPixelsDataFrame with 
> >
> > names(dem)
> >
> > being "z". Saying summary(dem) will give you an idea of what is inside, 
> > str() should too.
> >
> > Roger
> >
> > PS. This is usually a one-off thing, once it works, you note down how, and 
> > then it just does from then on.
> >
> >
> >   
> >> Thanks again for your help!
> >>
> >> Regards,
> >> Tom
> >>
> >>
> >> Roger Bivand wrote:
> >>     
> >>> On Fri, 28 Apr 2006, Thomas Adams wrote:
> >>>
> >>>   
> >>>       
> >>>> Roger,
> >>>>
> >>>> This got me further along, but I am encountering a problem with:
> >>>>
> >>>> z <- predict(UK_fit, newdata=BMcD_SPx)
> >>>>
> >>>> The gstat step works for me, where I have:
> >>>>
> >>>> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
> >>>>
> >>>> temps has class SpatialPointsDataFrame:
> >>>>
> >>>>               coordinates cat      x     y    z temp name
> >>>> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
> >>>> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
> >>>> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
> >>>> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
> >>>> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
> >>>> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
> >>>> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
> >>>> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
> >>>> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
> >>>> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
> >>>> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
> >>>> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
> >>>> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
> >>>>
> >>>> and dem has class SpatialGridDataFrame and just consists of grid values.
> >>>>     
> >>>>         
> >>> I think 
> >>>
> >>> fullgrid(dem) <- FALSE
> >>>
> >>> should make a SpatialPixelsDataFrame, but you'll have to make sure the 
> >>> name of the dem variable is the same as in the formula.
> >>>
> >>> Roger
> >>>
> >>>   
> >>>       
> >>>> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
> >>>> example):
> >>>>
> >>>> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
> >>>>
> >>>> I have nothing like meuse.grid, so this does not work. I can use 
> >>>> image(dem), which produces a plot of elevation values. My point is that 
> >>>> meuse.grid and my dem files have very different structures.
> >>>>
> >>>> I'm not sure where to go to from here.
> >>>>
> >>>> Regards,
> >>>> Tom
> >>>>
> >>>>
> >>>> Roger Bivand wrote:
> >>>>     
> >>>>         
> >>>>> On Thu, 27 Apr 2006, Thomas Adams wrote:
> >>>>>
> >>>>>   
> >>>>>       
> >>>>>           
> >>>>>> List:
> >>>>>>
> >>>>>> I can not seem to work out the syntax for using R/gstat within a GRASS 
> >>>>>> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
> >>>>>> grid) and point data for temperature; theoretically, the temperatures 
> >>>>>> should relate to elevation. So, I am trying to spatially interpolate the 
> >>>>>> temperature data based on the elevations at the grid points. How do I 
> >>>>>> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
> >>>>>> have no trouble reading in my elevation data (DEM) from GRASS and I have 
> >>>>>> no problem doing ordinary kriging of my temperature data using 
> >>>>>> GRASS/R/gstat.
> >>>>>>     
> >>>>>>         
> >>>>>>             
> >>>>> What do the data look like? Do you have temperature and elevation at the
> >>>>> observation points and elevation over the grid? If temperature is the 
> >>>>> variable for which you want to interpolate, then the formula argument in 
> >>>>> the gstat() function would be temp ~ elev, data=pointsdata (if a 
> >>>>> SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
> >>>>> step would need a SpatialGridDataFrame object as newdata, with elev as 
> >>>>> (one of) the columns in the data slot.
> >>>>>
> >>>>> An example for the Meuse bank data in Burrough and McDonnell:
> >>>>>
> >>>>> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
> >>>>> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
> >>>>>   nugget=1))
> >>>>> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
> >>>>>   model=uefitted)
> >>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
> >>>>>
> >>>>> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
> >>>>> with flood frequencies in Fldf (actually a factor, but works neatly).
> >>>>>
> >>>>> Hope this helps,
> >>>>>
> >>>>> Roger
> >>>>>
> >>>>>   
> >>>>>       
> >>>>>           
> >>>>>> Regards,
> >>>>>> Tom
> >>>>>>
> >>>>>>
> >>>>>>     
> >>>>>>         
> >>>>>>             
> >>>>>   
> >>>>>       
> >>>>>           
> >>>>     
> >>>>         
> >>>   
> >>>       
> >>
> >>     
> >
> >   
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat May 13 10:38:41 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 13 May 2006 10:38:41 +0200 (CEST)
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <15f8e67d0605121447o35213a2bqc45553badfb91213@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0605131017040.19126-100000@reclus.nhh.no>

On Fri, 12 May 2006, Xiaohua Dai wrote:

> My idea is to use your procedure to obtain food-tree patches of
> rhinos, then relate the patches to rhino movement pattern. For
> example, rhinos may move more slowly in food patches than outside the
> patches. I forgot one thing, could you also tell me how to write these
> hulls into a polygon shape file? write.polylistShape {maptools} or
> convert.to.shapefile {shapefiles}?

set.seed(1)
xy <- matrix(runif(500, 0, 10), ncol=2)
xy_clusts <- hclust(dist(xy), method="complete")
cl_10 <- cutree(xy_clusts, 10)
which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
# so far as before - now:

n <- length(chulls_cl_10)
library(sp)
polygons <- lapply(1:n, function(i) {
  chulls_cl_10[[i]] <- rbind(chulls_cl_10[[i]], chulls_cl_10[[i]][1,])
# the convex hulls do not join first and last points, so we copy here
  Polygons(list(Polygon(coords=chulls_cl_10[[i]])), ID=i) })
out <- SpatialPolygonsDataFrame(SpatialPolygons(polygons),
  data=data.frame(ID=1:n))
plot(out)
# note standard-violating intersecting polygons!
tempfile <- tempfile()
library(maptools)
writePolyShape(out, tempfile)
in_again <- readShapePoly(tempfile)
plot(in_again, border="blue", add=TRUE)

The trick is to construct a SpatialPolygons object defined in the sp 
package, and write it and a single data field out to a shapefile. The 
shapefile is strictly wrong, because the polygons can intersect, but at 
least it's something to start with.

Roger


> 
> Thanks
> Xiaohua
> 
> On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > On Fri, 12 May 2006, Xiaohua Dai wrote:
> >
> > > Hi Roger,
> > >
> > > Thank you for your kindly help. It is exactly what I want. I will try
> > > to understand your programming.  I think the program should be useful
> > > in many fields as you indicated.
> > >
> > > I did not expect the problem can be solved so easily. Again, R is very
> > > powerful with so many good functions. I am quite interested in lapply
> > > and tapply. I will find some references/websites on their
> > > applications.
> >
> > Note that using a different method= argument to hclust, or a different
> > metric to dist(), you will get different clusters, as well as getting
> > different numbers for different cutree() values. If you have specific
> > range distances (from an off-list message, the points are rhino), you
> > could also use other methods to create your own clusters where the first
> > nearest neighbour distance is less than your empirically observed range -
> > there should be a literature on this among ecologists, which others on the
> > list may be able to help with. Is there anything in the adehabitat
> > package, or others?
> >
> > Roger
> >
> > >
> > > Also thanks to remind me of the post guide.
> > >
> > > Best wishes
> > > Xiaohua
> > >
> > > On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > > > On Fri, 12 May 2006, Xiaohua Dai wrote:
> > > >
> > > > > Sorry, I did not make my question clear. Since I have a point theme
> > > > > with many points, some of them may clump together. the problems here
> > > > > are:
> > > >
> > > > A more specific follow-up after my reply directly to R-help.
> > > >
> > > > I'm assuming you have a running R, and that convex hulls are what you
> > > > want.
> > > >
> > > > Take a random data set:
> > > >
> > > > set.seed(1)
> > > > xy <- matrix(runif(500, 0, 10), ncol=2)
> > > > xy_clusts <- hclust(dist(xy), method="complete")
> > > > # complete linkage hierarchical clustering
> > > > plot(xy_clusts)
> > > > # shows the clustering tree
> > > > cl_10 <- cutree(xy_clusts, 10)
> > > > cl_20 <- cutree(xy_clusts, 20)
> > > > cl_30 <- cutree(xy_clusts, 30)
> > > > # cut the tree - the objects contain the memberships
> > > > which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> > > > chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> > > > # construct convex hull polygons for each cluster
> > > > plot(xy)
> > > > res <- lapply(chulls_cl_10, polygon)
> > > > # and repeat for cl_20 and cl_30
> > > > which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
> > > > chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
> > > > plot(xy)
> > > > res <- lapply(chulls_cl_20, polygon)
> > > > which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
> > > > chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
> > > > plot(xy)
> > > > res <- lapply(chulls_cl_30, polygon)
> > > >
> > > > If you need the list of convex hulls out as a shapefile, we can do that,
> > > > if you need a raster, I'd suggest using kernel density with different
> > > > bandwidths for a start, and NA out the densities below a chosen threshold.
> > > >
> > > > Hope this helps,
> > > >
> > > > Roger Bivand
> > > >
> > > > PS. Use package maptools, function readShapePoints() to read your
> > > > shapefile, and coordinates() of the input object to extract the
> > > > coordinates. If need be, project from geographical coordinates using
> > > > transform methods in package rgdal.
> > > >
> > > >
> > > > > 1.  how to find clumps in a point theme?
> > > > > 2.  the convex-hull extension I found only deal with all the points in
> > > > > a theme at each time?  how to make each convex hull around each point
> > > > > clump automatically?
> > > > >
> > > > > Thanks.
> > > > >
> > > > > Xiaohua
> > > > >
> > > > >
> > > > >
> > > > > On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > > > > > Xiaohua,
> > > > > >
> > > > > > That would be one way to do it. There are others.
> > > > > > Try searching ArcScripts for "convex hull"
> > > > > > http://arcscripts.esri.com/
> > > > > >
> > > > > > For example:
> > > > > > http://arcscripts.esri.com/details.asp?dbid=14535
> > > > > > or
> > > > > > http://arcscripts.esri.com/details.asp?dbid=12084
> > > > > >
> > > > > > Bob
> > > > > >
> > > > > >
> > > > > > -----Original Message-----
> > > > > > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > > > > > Sent: Friday, May 12, 2006 2:33 AM
> > > > > > To: ESRI-L at esri.com
> > > > > > Subject: [ESRI-L] outline polygons of point clumps
> > > > > >
> > > > > > Dear all,
> > > > > >
> > > > > > How to generate one outline polygon for each point clump? Are there
> > > > > > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > > > > > had a quick look at the package adehabitat and did not find the
> > > > > > function.
> > > > > >
> > > > > > To my knowledge, I could do it as follows: 1) make a grid map of my
> > > > > > study area with cell values = 0; 2) assign 1 to the cells containing
> > > > > > at least one point; 3) convert the 1-value cells into polygons.
> > > > > >
> > > > > > Am I right?
> > > > > >
> > > > > > Thanks
> > > > > > Xiaohua
> > > > > >
> > > > > >
> > > > >
> > > > >
> > > > >
> > > >
> > > > --
> > > > Roger Bivand
> > > > Economic Geography Section, Department of Economics, Norwegian School of
> > > > Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> > > > Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> > > > e-mail: Roger.Bivand at nhh.no
> > > >
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ecoinformatics at gmail.com  Sat May 13 10:52:02 2006
From: ecoinformatics at gmail.com (Xiaohua Dai)
Date: Sat, 13 May 2006 10:52:02 +0200
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <Pine.LNX.4.44.0605131017040.19126-100000@reclus.nhh.no>
References: <15f8e67d0605121447o35213a2bqc45553badfb91213@mail.gmail.com>
	<Pine.LNX.4.44.0605131017040.19126-100000@reclus.nhh.no>
Message-ID: <15f8e67d0605130152o3b3e5717k1933694cb31cc910@mail.gmail.com>

Thanks. How about merging the intersected hulls to make a new hull? Is
it easy to do that? It seems that I have to decide how many hulls I
needed at first?

Regards
Xiaohua

On 5/13/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Fri, 12 May 2006, Xiaohua Dai wrote:
>
> > My idea is to use your procedure to obtain food-tree patches of
> > rhinos, then relate the patches to rhino movement pattern. For
> > example, rhinos may move more slowly in food patches than outside the
> > patches. I forgot one thing, could you also tell me how to write these
> > hulls into a polygon shape file? write.polylistShape {maptools} or
> > convert.to.shapefile {shapefiles}?
>
> set.seed(1)
> xy <- matrix(runif(500, 0, 10), ncol=2)
> xy_clusts <- hclust(dist(xy), method="complete")
> cl_10 <- cutree(xy_clusts, 10)
> which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> # so far as before - now:
>
> n <- length(chulls_cl_10)
> library(sp)
> polygons <- lapply(1:n, function(i) {
>  chulls_cl_10[[i]] <- rbind(chulls_cl_10[[i]], chulls_cl_10[[i]][1,])
> # the convex hulls do not join first and last points, so we copy here
>  Polygons(list(Polygon(coords=chulls_cl_10[[i]])), ID=i) })
> out <- SpatialPolygonsDataFrame(SpatialPolygons(polygons),
>  data=data.frame(ID=1:n))
> plot(out)
> # note standard-violating intersecting polygons!
> tempfile <- tempfile()
> library(maptools)
> writePolyShape(out, tempfile)
> in_again <- readShapePoly(tempfile)
> plot(in_again, border="blue", add=TRUE)
>
> The trick is to construct a SpatialPolygons object defined in the sp
> package, and write it and a single data field out to a shapefile. The
> shapefile is strictly wrong, because the polygons can intersect, but at
> least it's something to start with.
>
> Roger
>
>
> >
> > Thanks
> > Xiaohua
> >
> > On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > > On Fri, 12 May 2006, Xiaohua Dai wrote:
> > >
> > > > Hi Roger,
> > > >
> > > > Thank you for your kindly help. It is exactly what I want. I will try
> > > > to understand your programming.  I think the program should be useful
> > > > in many fields as you indicated.
> > > >
> > > > I did not expect the problem can be solved so easily. Again, R is very
> > > > powerful with so many good functions. I am quite interested in lapply
> > > > and tapply. I will find some references/websites on their
> > > > applications.
> > >
> > > Note that using a different method= argument to hclust, or a different
> > > metric to dist(), you will get different clusters, as well as getting
> > > different numbers for different cutree() values. If you have specific
> > > range distances (from an off-list message, the points are rhino), you
> > > could also use other methods to create your own clusters where the first
> > > nearest neighbour distance is less than your empirically observed range -
> > > there should be a literature on this among ecologists, which others on the
> > > list may be able to help with. Is there anything in the adehabitat
> > > package, or others?
> > >
> > > Roger
> > >
> > > >
> > > > Also thanks to remind me of the post guide.
> > > >
> > > > Best wishes
> > > > Xiaohua
> > > >
> > > > On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > > > > On Fri, 12 May 2006, Xiaohua Dai wrote:
> > > > >
> > > > > > Sorry, I did not make my question clear. Since I have a point theme
> > > > > > with many points, some of them may clump together. the problems here
> > > > > > are:
> > > > >
> > > > > A more specific follow-up after my reply directly to R-help.
> > > > >
> > > > > I'm assuming you have a running R, and that convex hulls are what you
> > > > > want.
> > > > >
> > > > > Take a random data set:
> > > > >
> > > > > set.seed(1)
> > > > > xy <- matrix(runif(500, 0, 10), ncol=2)
> > > > > xy_clusts <- hclust(dist(xy), method="complete")
> > > > > # complete linkage hierarchical clustering
> > > > > plot(xy_clusts)
> > > > > # shows the clustering tree
> > > > > cl_10 <- cutree(xy_clusts, 10)
> > > > > cl_20 <- cutree(xy_clusts, 20)
> > > > > cl_30 <- cutree(xy_clusts, 30)
> > > > > # cut the tree - the objects contain the memberships
> > > > > which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> > > > > chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> > > > > # construct convex hull polygons for each cluster
> > > > > plot(xy)
> > > > > res <- lapply(chulls_cl_10, polygon)
> > > > > # and repeat for cl_20 and cl_30
> > > > > which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
> > > > > chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
> > > > > plot(xy)
> > > > > res <- lapply(chulls_cl_20, polygon)
> > > > > which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
> > > > > chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
> > > > > plot(xy)
> > > > > res <- lapply(chulls_cl_30, polygon)
> > > > >
> > > > > If you need the list of convex hulls out as a shapefile, we can do that,
> > > > > if you need a raster, I'd suggest using kernel density with different
> > > > > bandwidths for a start, and NA out the densities below a chosen threshold.
> > > > >
> > > > > Hope this helps,
> > > > >
> > > > > Roger Bivand
> > > > >
> > > > > PS. Use package maptools, function readShapePoints() to read your
> > > > > shapefile, and coordinates() of the input object to extract the
> > > > > coordinates. If need be, project from geographical coordinates using
> > > > > transform methods in package rgdal.
> > > > >
> > > > >
> > > > > > 1.  how to find clumps in a point theme?
> > > > > > 2.  the convex-hull extension I found only deal with all the points in
> > > > > > a theme at each time?  how to make each convex hull around each point
> > > > > > clump automatically?
> > > > > >
> > > > > > Thanks.
> > > > > >
> > > > > > Xiaohua
> > > > > >
> > > > > >
> > > > > >
> > > > > > On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > > > > > > Xiaohua,
> > > > > > >
> > > > > > > That would be one way to do it. There are others.
> > > > > > > Try searching ArcScripts for "convex hull"
> > > > > > > http://arcscripts.esri.com/
> > > > > > >
> > > > > > > For example:
> > > > > > > http://arcscripts.esri.com/details.asp?dbid=14535
> > > > > > > or
> > > > > > > http://arcscripts.esri.com/details.asp?dbid=12084
> > > > > > >
> > > > > > > Bob
> > > > > > >
> > > > > > >
> > > > > > > -----Original Message-----
> > > > > > > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > > > > > > Sent: Friday, May 12, 2006 2:33 AM
> > > > > > > To: ESRI-L at esri.com
> > > > > > > Subject: [ESRI-L] outline polygons of point clumps
> > > > > > >
> > > > > > > Dear all,
> > > > > > >
> > > > > > > How to generate one outline polygon for each point clump? Are there
> > > > > > > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > > > > > > had a quick look at the package adehabitat and did not find the
> > > > > > > function.
> > > > > > >
> > > > > > > To my knowledge, I could do it as follows: 1) make a grid map of my
> > > > > > > study area with cell values = 0; 2) assign 1 to the cells containing
> > > > > > > at least one point; 3) convert the 1-value cells into polygons.
> > > > > > >
> > > > > > > Am I right?
> > > > > > >
> > > > > > > Thanks
> > > > > > > Xiaohua
> > > > > > >



From Roger.Bivand at nhh.no  Sat May 13 11:07:52 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 13 May 2006 11:07:52 +0200 (CEST)
Subject: [R-sig-Geo] [R] [ESRI-L] outline polygons of point clumps
In-Reply-To: <15f8e67d0605130152o3b3e5717k1933694cb31cc910@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0605131102200.19126-100000@reclus.nhh.no>

On Sat, 13 May 2006, Xiaohua Dai wrote:

> Thanks. How about merging the intersected hulls to make a new hull? Is
> it easy to do that? It seems that I have to decide how many hulls I
> needed at first?

Yes, deciding the cluster criteria and numbers comes first. Then there are
tricks in the gpclib and (off-CRAN) r-spatial sourceforge repository spgpc
packages for doing things to Polygons objects and lists of Polygons
objects (see CRAN -> "Task Views" -> Spatial for the link). I don't think
we have an intersection checker yet, but it wouldn't be difficult to
write. Alternately, we could cut out the intersection from both, because
we know that no points lie inside it - the polygons would still touch as
the two points on each side of the intersection (if the should be one
cluster under the chosen cluster criteria, the cluster algorithm would
have joined them).

Roger


> 
> Regards
> Xiaohua
> 
> On 5/13/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > On Fri, 12 May 2006, Xiaohua Dai wrote:
> >
> > > My idea is to use your procedure to obtain food-tree patches of
> > > rhinos, then relate the patches to rhino movement pattern. For
> > > example, rhinos may move more slowly in food patches than outside the
> > > patches. I forgot one thing, could you also tell me how to write these
> > > hulls into a polygon shape file? write.polylistShape {maptools} or
> > > convert.to.shapefile {shapefiles}?
> >
> > set.seed(1)
> > xy <- matrix(runif(500, 0, 10), ncol=2)
> > xy_clusts <- hclust(dist(xy), method="complete")
> > cl_10 <- cutree(xy_clusts, 10)
> > which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> > chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> > # so far as before - now:
> >
> > n <- length(chulls_cl_10)
> > library(sp)
> > polygons <- lapply(1:n, function(i) {
> >  chulls_cl_10[[i]] <- rbind(chulls_cl_10[[i]], chulls_cl_10[[i]][1,])
> > # the convex hulls do not join first and last points, so we copy here
> >  Polygons(list(Polygon(coords=chulls_cl_10[[i]])), ID=i) })
> > out <- SpatialPolygonsDataFrame(SpatialPolygons(polygons),
> >  data=data.frame(ID=1:n))
> > plot(out)
> > # note standard-violating intersecting polygons!
> > tempfile <- tempfile()
> > library(maptools)
> > writePolyShape(out, tempfile)
> > in_again <- readShapePoly(tempfile)
> > plot(in_again, border="blue", add=TRUE)
> >
> > The trick is to construct a SpatialPolygons object defined in the sp
> > package, and write it and a single data field out to a shapefile. The
> > shapefile is strictly wrong, because the polygons can intersect, but at
> > least it's something to start with.
> >
> > Roger
> >
> >
> > >
> > > Thanks
> > > Xiaohua
> > >
> > > On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > > > On Fri, 12 May 2006, Xiaohua Dai wrote:
> > > >
> > > > > Hi Roger,
> > > > >
> > > > > Thank you for your kindly help. It is exactly what I want. I will try
> > > > > to understand your programming.  I think the program should be useful
> > > > > in many fields as you indicated.
> > > > >
> > > > > I did not expect the problem can be solved so easily. Again, R is very
> > > > > powerful with so many good functions. I am quite interested in lapply
> > > > > and tapply. I will find some references/websites on their
> > > > > applications.
> > > >
> > > > Note that using a different method= argument to hclust, or a different
> > > > metric to dist(), you will get different clusters, as well as getting
> > > > different numbers for different cutree() values. If you have specific
> > > > range distances (from an off-list message, the points are rhino), you
> > > > could also use other methods to create your own clusters where the first
> > > > nearest neighbour distance is less than your empirically observed range -
> > > > there should be a literature on this among ecologists, which others on the
> > > > list may be able to help with. Is there anything in the adehabitat
> > > > package, or others?
> > > >
> > > > Roger
> > > >
> > > > >
> > > > > Also thanks to remind me of the post guide.
> > > > >
> > > > > Best wishes
> > > > > Xiaohua
> > > > >
> > > > > On 5/12/06, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > > > > > On Fri, 12 May 2006, Xiaohua Dai wrote:
> > > > > >
> > > > > > > Sorry, I did not make my question clear. Since I have a point theme
> > > > > > > with many points, some of them may clump together. the problems here
> > > > > > > are:
> > > > > >
> > > > > > A more specific follow-up after my reply directly to R-help.
> > > > > >
> > > > > > I'm assuming you have a running R, and that convex hulls are what you
> > > > > > want.
> > > > > >
> > > > > > Take a random data set:
> > > > > >
> > > > > > set.seed(1)
> > > > > > xy <- matrix(runif(500, 0, 10), ncol=2)
> > > > > > xy_clusts <- hclust(dist(xy), method="complete")
> > > > > > # complete linkage hierarchical clustering
> > > > > > plot(xy_clusts)
> > > > > > # shows the clustering tree
> > > > > > cl_10 <- cutree(xy_clusts, 10)
> > > > > > cl_20 <- cutree(xy_clusts, 20)
> > > > > > cl_30 <- cutree(xy_clusts, 30)
> > > > > > # cut the tree - the objects contain the memberships
> > > > > > which_cl_10 <- tapply(1:nrow(xy), cl_10, function(i) xy[i,])
> > > > > > chulls_cl_10 <- lapply(which_cl_10, function(x) x[chull(x),])
> > > > > > # construct convex hull polygons for each cluster
> > > > > > plot(xy)
> > > > > > res <- lapply(chulls_cl_10, polygon)
> > > > > > # and repeat for cl_20 and cl_30
> > > > > > which_cl_20 <- tapply(1:nrow(xy), cl_20, function(i) xy[i,])
> > > > > > chulls_cl_20 <- lapply(which_cl_20, function(x) x[chull(x),])
> > > > > > plot(xy)
> > > > > > res <- lapply(chulls_cl_20, polygon)
> > > > > > which_cl_30 <- tapply(1:nrow(xy), cl_30, function(i) xy[i,])
> > > > > > chulls_cl_30 <- lapply(which_cl_30, function(x) x[chull(x),])
> > > > > > plot(xy)
> > > > > > res <- lapply(chulls_cl_30, polygon)
> > > > > >
> > > > > > If you need the list of convex hulls out as a shapefile, we can do that,
> > > > > > if you need a raster, I'd suggest using kernel density with different
> > > > > > bandwidths for a start, and NA out the densities below a chosen threshold.
> > > > > >
> > > > > > Hope this helps,
> > > > > >
> > > > > > Roger Bivand
> > > > > >
> > > > > > PS. Use package maptools, function readShapePoints() to read your
> > > > > > shapefile, and coordinates() of the input object to extract the
> > > > > > coordinates. If need be, project from geographical coordinates using
> > > > > > transform methods in package rgdal.
> > > > > >
> > > > > >
> > > > > > > 1.  how to find clumps in a point theme?
> > > > > > > 2.  the convex-hull extension I found only deal with all the points in
> > > > > > > a theme at each time?  how to make each convex hull around each point
> > > > > > > clump automatically?
> > > > > > >
> > > > > > > Thanks.
> > > > > > >
> > > > > > > Xiaohua
> > > > > > >
> > > > > > >
> > > > > > >
> > > > > > > On 5/12/06, Bob Booth <bbooth at esri.com> wrote:
> > > > > > > > Xiaohua,
> > > > > > > >
> > > > > > > > That would be one way to do it. There are others.
> > > > > > > > Try searching ArcScripts for "convex hull"
> > > > > > > > http://arcscripts.esri.com/
> > > > > > > >
> > > > > > > > For example:
> > > > > > > > http://arcscripts.esri.com/details.asp?dbid=14535
> > > > > > > > or
> > > > > > > > http://arcscripts.esri.com/details.asp?dbid=12084
> > > > > > > >
> > > > > > > > Bob
> > > > > > > >
> > > > > > > >
> > > > > > > > -----Original Message-----
> > > > > > > > From: ESRI-L [mailto:ESRI-L at esri.com] On Behalf Of Xiaohua Dai
> > > > > > > > Sent: Friday, May 12, 2006 2:33 AM
> > > > > > > > To: ESRI-L at esri.com
> > > > > > > > Subject: [ESRI-L] outline polygons of point clumps
> > > > > > > >
> > > > > > > > Dear all,
> > > > > > > >
> > > > > > > > How to generate one outline polygon for each point clump? Are there
> > > > > > > > any present functions in ArcView, ArcGIS, R or some freewares? I just
> > > > > > > > had a quick look at the package adehabitat and did not find the
> > > > > > > > function.
> > > > > > > >
> > > > > > > > To my knowledge, I could do it as follows: 1) make a grid map of my
> > > > > > > > study area with cell values = 0; 2) assign 1 to the cells containing
> > > > > > > > at least one point; 3) convert the 1-value cells into polygons.
> > > > > > > >
> > > > > > > > Am I right?
> > > > > > > >
> > > > > > > > Thanks
> > > > > > > > Xiaohua
> > > > > > > >
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From e.pebesma at geo.uu.nl  Mon May 15 10:25:29 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Mon, 15 May 2006 10:25:29 +0200
Subject: [R-sig-Geo] bubble vs plot.map -- gstat, maptools
In-Reply-To: <4463A985.8050000@zevross.com>
References: <Pine.LNX.4.44.0605112158170.16897-100000@reclus.nhh.no>
	<4463A985.8050000@zevross.com>
Message-ID: <44683AF9.5050409@geo.uu.nl>

Yes, thoughts. It looks like you now get the legend values out of
the graphics file produced by the bubble() command. Bubble has
a key.entries argument, which uses by default:
   key.entries = quantile(data[,zcol])
i.e. the 5 default quantiles (min, q25, med, q75, max).

You may want to provide more sensible values there.
--
Edzer

Zev Ross wrote:
> Hi Roger,
>
> Wow, thanks again for the quick turnaround. Any suggestions in your 
> code in how to get the legend scaled properly to match the "kludgy" 
> scaling of the symbols?
>
> The code below looks pretty good 
> (http://www.zevross.com/temp/test.pdf), but the legend scaling is not 
> really appropriate. Thoughts?
>
> Zev
>
>
> par(pty="s")
> map.nyc<-read.shape("D:/junk/all_counties.shp", dbf.data=T)
> out<-bubble(kcv.wint, "residual", do.sqrt=T, col=c(3,2), main="C.V. 
> Residuals")
> plot(map.nyc, axes=T)
>
>
>  symbols(out$panel.args[[1]], circles=out$panel.args.common$cex*2000,
>   bg=out$panel.args.common$col, inches=F, add=TRUE)
>
>  
>  legend(650000, 4470000, legend=out$legend$right$args$key$text[[1]],
>      pt.cex=out$legend$right$args$key$points$cex, pch=16,
>      col=out$legend$right$args$key$points$col,bty="n", y.intersp=1
>      )
>     
>
>
> Roger Bivand wrote:
>> On Thu, 11 May 2006, Zev Ross wrote:
>>
>>   
>>> Hi All,
>>>
>>> I've got another question for the group. I'm using the bubble function in
>>> GSTAT to plot the residuals from a krige.cv object. I'd like to place on
>>> top the outlines of my counties of interest (or even better I'd like to
>>> plot them in the reverse order). What I'm finding is that even if I
>>> eliminate the key and eliminate the "asp" call from the bubble function,
>>> my two plots don't align as they do under more traditional plotting
>>> circumstances
>>>
>>> Here's the idea:
>>>
>>> kcv28<-krige.cv(avg.pm25~1,pm.all28, vFitRaw, nmax=dim(pm.all28)[1],
>>>      nfold=dim(pm.all28)[1])
>>> bubble(kcv28, "residual", do.sqrt=F)
>>> map.nyc<-read.shape("D:/junk/counties/all_counties.shp", dbf.data=T)
>>> plot(map.nyc, add=T, fg="transparent", ol="gray50")
>>>     
>>
>> Well, bubble() uses lattice graphics, and the plot() methods are most 
>> often base graphics:
>>
>> library(maptools)
>> xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1])
>> xx$crude <- (1000*xx$SID74)/xx$BIR74
>> out <- bubble(pts, "crude")
>> plot(xx, axes=TRUE)
>> symbols(out$panel.args[[1]], circles=out$panel.args.common$cex/10, 
>>   bg=out$panel.args.common$col, inches=FALSE, add=TRUE)
>>
>> is pretty close (with a kludgy cex/10 size factor), or
>>
>> plot(xx, axes=TRUE)
>> points(out$panel.args[[1]], cex=out$panel.args.common$cex, 
>>   col=out$panel.args.common$col, pch=out$panel.args.common$pch)
>>
>> using points(). See
>>
>> str(out)
>>
>> to pick out the guts of the bubble lattice plot object. The plot() 
>> method used here, symbols() and points() are all in base grahics.
>>
>> Also see a recent paper in JSS by Susumu Tanimura, Chusi Kuroiwa, and 
>> Tsutomu Mizota, including some legend code:
>>
>> http://www.jstatsoft.org/
>>
>> Volume 15, 2006, Issue 5 
>>
>> Roger
>>
>>   
>>> Any suggestions? Zev
>>>
>>> --
>>> Zev Ross
>>> ZevRoss Spatial Analysis
>>> 303 Fairmount Ave
>>> Ithaca, NY 14850
>>> (607) 277-0004 (phone)
>>> (866) 877-3690 (fax toll-free)
>>> zev at zevross.com
>>> www.zevross.com
>>>
>>>
>>>     
>>
>>   
>
> -- 
> Zev Ross
> *ZevRoss Spatial Analysis*
> 303 Fairmount Ave
> Ithaca, NY 14850
> (607) 277-0004 (phone)
> (866) 877-3690 (fax toll-free)
> zev at zevross.com
> www.zevross.com
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Thomas.Adams at noaa.gov  Mon May 15 21:47:14 2006
From: Thomas.Adams at noaa.gov (Thomas Adams)
Date: Mon, 15 May 2006 15:47:14 -0400
Subject: [R-sig-Geo] Example of universal kriging with R/gstat in GRASS
In-Reply-To: <Pine.LNX.4.44.0605131011400.19126-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605131011400.19126-100000@reclus.nhh.no>
Message-ID: <4468DAC2.20203@noaa.gov>

Roger,

That did it! The sessionInfo() command identified that I had older 
versions than what were available on CRAN, namely:

lattice -- 0.13-8
gstat -- 0.9-29 (was older: 0.9-17)
sp -- 0.8-14 (was older: 0.8-8)

On my Mac, I have:

lattice -- 0.11-8
gstat -- 0.9-21
sp -- 0.7-10

which works?

BTW, I also updated to R v. 2.3 on Linux. Thanks again for your help!

Regards,
Tom



Roger Bivand wrote:
> Thomas:
>
> Please do:
>
> sessionInfo()
>
> on both machines, and see if any of the package versions are different.
>
> It often also helps to name function arguments explicitly, to be sure that 
> they are being understood correctly inside the functions. Depending on the 
> class of the data= arugment, as far as I recall different versions of the 
> gstat package treat the locations= argument differently.
>
> Roger
>
>
> On Fri, 12 May 2006, Thomas Adams wrote:
>
>   
>> Roger,
>>
>> I have made considerable progress in what I was trying to do with gstat 
>> & Universal Kriging using R. I was fortunate enough to find a detailed 
>> example of what I was trying to do: http://spatial-analyst.net/RKguide.php.
>>
>> I exported from GRASS my elevation grid, "gtopo30.dem", and temperature 
>> point file, "temps.txt", to ascii files to assure I followed a parallel 
>> path with my data.
>>
>> So, with my data, following Tomislav Hengl's example, I have:
>>
>>  > temps<-read.delim("temps.txt",sep=" ")
>>  > summary(temps)
>>
>> cat lon lat z T name
>> Min. : 1.00 Min. :-90.05 Min. :35.82 Min. : 99.0 Min. :61.00 AGC : 1
>> 1st Qu.: 31.75 1st Qu.:-86.63 1st Qu.:38.27 1st Qu.: 197.0 1st Qu.:64.00 
>> AID : 1
>> Median : 60.50 Median :-84.06 Median :40.09 Median : 255.5 Median :66.00 
>> ALN : 1
>> Mean : 60.37 Mean :-84.14 Mean :39.86 Mean : 314.2 Mean :66.83 AOH : 1
>> 3rd Qu.: 89.25 3rd Qu.:-81.47 3rd Qu.:41.58 3rd Qu.: 360.0 3rd Qu.:69.00 
>> AOO : 1
>> Max. :118.00 Max. :-78.32 Max. :42.49 Max. :1155.0 Max. :73.00 ARB : 1
>> (Other):110
>> X Y
>> Min. :-341460 Min. :-342057
>> 1st Qu.: -53847 1st Qu.: -71919
>> Median : 163999 Median : 119784
>> Mean : 154474 Mean : 99916
>> 3rd Qu.: 371950 3rd Qu.: 282632
>> Max. : 632335 Max. : 398186
>>
>>  > library(sp)
>>  > dem<-read.asciigrid("gtopo30.dem")
>>  > class(dem)
>> [1] "SpatialGridDataFrame"
>> attr(,"package")
>> [1] "sp"
>>  > image(dem)
>>  > points(Y ~ X, data=temps)
>>  > class(temps)
>> [1] "data.frame"
>>  > coordinates(temps)=~X+Y
>>  > dem.ov=overlay(dem,temps)
>>  > summary(dem.ov)
>>
>> Object of class SpatialPointsDataFrame
>> Coordinates:
>> min max
>> X -341459.8 632334.6
>> Y -342056.9 398185.9
>> Is projected: NA
>> proj4string : [NA]
>> Number of points: 116
>> Data attributes:
>> gtopo30.dem
>> Min. : 115.3
>> 1st Qu.: 196.9
>> Median : 245.4
>> Mean : 306.9
>> 3rd Qu.: 331.0
>> Max. :1064.5
>>
>>  > temps$gtopo30.dem=dem.ov$gtopo30.dem
>>  > library(lattice)
>>  > plot(T~gtopo30.dem, as.data.frame(temps))
>>  > abline(lm(T~gtopo30.dem, as.data.frame(temps)))
>>  > library(gstat)
>>
>>  > vgm <- vgm(psill=8,model="Exp",range=600000,nugget=3.8)
>>  > vgm_temps_r<-fit.variogram(variogram(T~gtopo30.dem,temps), model=vgm)
>>  > plot(variogram(T~gtopo30.dem,temps),main = "fitted by gstat")
>>  > temps_uk<-krige(T~gtopo30.dem,temps,dem, vgm_temps_r)
>> [using universal kriging]
>>  > library(lattice)
>>  > trellis.par.set(sp.theme())
>>  > spplot(temps_uk,"var1.pred", main="Universal kriging predictions 
>> TEMPERATURE")
>>
>>
>> Which works perfectly on my Macintosh running Mac OS X 10.4 and using R 
>> 2.2.1. (see attachment, temperatures in deg. F) However, following the 
>> *identical* steps with the identical data on Linux, at the step:
>>
>> temps_uk<-krige(T~gtopo30.dem,temps,dem, vgm_temps_r)
>>
>> I get the error:
>>
>> Error in eval(expr, envir, enclos) : object "gtopo30.dem" not found
>>
>> This has me baffled; any thoughts? I could send you my files if you 
>> would like to see what happens for you?
>>
>> Regards,
>> Tom
>>
>> BTW, the grid spacing on my DEM is coarse (9 km) and I will probably do 
>> my final analyses at 1-km.
>>
>>
>> Roger Bivand wrote:
>>     
>>> On Fri, 28 Apr 2006, Thomas Adams wrote:
>>>
>>>   
>>>       
>>>> Roger,
>>>>
>>>> Your suggestion:
>>>>
>>>> fullgrid(dem) <- FALSE
>>>>
>>>> did turn dem into class type SpatialGridDataFrame, but when I tried:
>>>>
>>>> z <- predict(UK_fit,newdata=dem)
>>>>
>>>> I got an error:
>>>>
>>>> Error in model.frame(... :
>>>> invalid variable type.
>>>>
>>>> I think I should restate the problem:
>>>>
>>>> I have a file 'temps' which has class SpatialPointsDataFrame read from 
>>>> GRASS 6.1, that looks like:
>>>>
>>>> coordinates cat x y z temp name
>>>> 1 (-341460, -2154.42) 1 -90.05 38.90 166 63 ALN
>>>> 2 (-198769, 301388) 2 -88.47 41.77 215 67 ARR
>>>> 3 (-334899, -40321) 3 -89.95 38.55 140 66 BLV
>>>> 4 (-240028, 163910) 4 -88.92 40.48 268 69 BMI
>>>> 5 (-187957, 114806) 5 -88.27 40.04 229 64 CMI
>>>> 6 (-351730, -37305.9) 6 -90.15 38.57 126 65 CPS
>>>> 7 (-242424, 98244.7) 7 -88.92 39.87 204 66 DEC
>>>> 8 (-179844, 315889) 8 -88.24 41.91 232 69 DPA
>>>> 9 (-136093, -24538.2) 9 -87.61 38.76 131 68 LWV
>>>> 10 (-278964, -126152) 10 -89.25 37.78 125 66 MDH
>>>> 11 (-140792, 302011) 11 -87.75 41.79 187 73 MDW
>>>> 12 (-364737, 274189) 12 -90.51 41.45 180 73 MLI
>>>> 13 (-190503, 54493.9) 13 -88.28 39.48 219 64 MTO
>>>>
>>>> and I have a a file 'dem' which has class SpatialGridDataFrame which 
>>>> just consists of grid of elevation values read from GRASS 6.1 using 
>>>> dem<-readFLOAT6sp(). (Sorry, I know I'm repeating myself).
>>>>
>>>> What I want to do is to use the grid of elevation values ('dem') as a 
>>>> proxy in the spatial interpolation of the 'temp' values in my 'temps' 
>>>> file that are located at the coordinates in parentheses(). Notice that 
>>>> the temps file also has 'z' values of elevations. So, is this what you 
>>>> already understood? Converting 'dem' to a SpatialPixelsDataFrame seemed 
>>>> to only leave me with the grid locations and not the elevation values ? 
>>>> is this right.
>>>>     
>>>>         
>>> What does:
>>>
>>> summary(dem) 
>>>
>>> say before and after doing
>>>
>>> fullgrid(dem) <- FALSE?
>>>
>>> Afterwards it should be a SpatialPixelsDataFrame with 
>>>
>>> names(dem)
>>>
>>> being "z". Saying summary(dem) will give you an idea of what is inside, 
>>> str() should too.
>>>
>>> Roger
>>>
>>> PS. This is usually a one-off thing, once it works, you note down how, and 
>>> then it just does from then on.
>>>
>>>
>>>   
>>>       
>>>> Thanks again for your help!
>>>>
>>>> Regards,
>>>> Tom
>>>>
>>>>
>>>> Roger Bivand wrote:
>>>>     
>>>>         
>>>>> On Fri, 28 Apr 2006, Thomas Adams wrote:
>>>>>
>>>>>   
>>>>>       
>>>>>           
>>>>>> Roger,
>>>>>>
>>>>>> This got me further along, but I am encountering a problem with:
>>>>>>
>>>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>>>>
>>>>>> The gstat step works for me, where I have:
>>>>>>
>>>>>> UK_fit<-gstat(formula=temps$temp~dem,data=temps,model=efitted)
>>>>>>
>>>>>> temps has class SpatialPointsDataFrame:
>>>>>>
>>>>>>               coordinates cat      x     y    z temp name
>>>>>> 1     (-341460, -2154.42)   1 -90.05 38.90  166   63  ALN
>>>>>> 2       (-198769, 301388)   2 -88.47 41.77  215   67  ARR
>>>>>> 3       (-334899, -40321)   3 -89.95 38.55  140   66  BLV
>>>>>> 4       (-240028, 163910)   4 -88.92 40.48  268   69  BMI
>>>>>> 5       (-187957, 114806)   5 -88.27 40.04  229   64  CMI
>>>>>> 6     (-351730, -37305.9)   6 -90.15 38.57  126   65  CPS
>>>>>> 7      (-242424, 98244.7)   7 -88.92 39.87  204   66  DEC
>>>>>> 8       (-179844, 315889)   8 -88.24 41.91  232   69  DPA
>>>>>> 9     (-136093, -24538.2)   9 -87.61 38.76  131   68  LWV
>>>>>> 10     (-278964, -126152)  10 -89.25 37.78  125   66  MDH
>>>>>> 11      (-140792, 302011)  11 -87.75 41.79  187   73  MDW
>>>>>> 12      (-364737, 274189)  12 -90.51 41.45  180   73  MLI
>>>>>> 13     (-190503, 54493.9)  13 -88.28 39.48  219   64  MTO
>>>>>>
>>>>>> and dem has class SpatialGridDataFrame and just consists of grid values.
>>>>>>     
>>>>>>         
>>>>>>             
>>>>> I think 
>>>>>
>>>>> fullgrid(dem) <- FALSE
>>>>>
>>>>> should make a SpatialPixelsDataFrame, but you'll have to make sure the 
>>>>> name of the dem variable is the same as in the formula.
>>>>>
>>>>> Roger
>>>>>
>>>>>   
>>>>>       
>>>>>           
>>>>>> I tried to create a SpatialPixelsDataFrame for predict(), but with (for 
>>>>>> example):
>>>>>>
>>>>>> m = SpatialPixelsDataFrame(points=meuse.grid[c("x","y")],data=meuse.grid)
>>>>>>
>>>>>> I have nothing like meuse.grid, so this does not work. I can use 
>>>>>> image(dem), which produces a plot of elevation values. My point is that 
>>>>>> meuse.grid and my dem files have very different structures.
>>>>>>
>>>>>> I'm not sure where to go to from here.
>>>>>>
>>>>>> Regards,
>>>>>> Tom
>>>>>>
>>>>>>
>>>>>> Roger Bivand wrote:
>>>>>>     
>>>>>>         
>>>>>>             
>>>>>>> On Thu, 27 Apr 2006, Thomas Adams wrote:
>>>>>>>
>>>>>>>   
>>>>>>>       
>>>>>>>           
>>>>>>>               
>>>>>>>> List:
>>>>>>>>
>>>>>>>> I can not seem to work out the syntax for using R/gstat within a GRASS 
>>>>>>>> 6.1 session to do universal kriging. I have a DEM (elevation data on a 
>>>>>>>> grid) and point data for temperature; theoretically, the temperatures 
>>>>>>>> should relate to elevation. So, I am trying to spatially interpolate the 
>>>>>>>> temperature data based on the elevations at the grid points. How do I 
>>>>>>>> setup the gstat command in R/gstat (and using spgrass6, of course)? I 
>>>>>>>> have no trouble reading in my elevation data (DEM) from GRASS and I have 
>>>>>>>> no problem doing ordinary kriging of my temperature data using 
>>>>>>>> GRASS/R/gstat.
>>>>>>>>     
>>>>>>>>         
>>>>>>>>             
>>>>>>>>                 
>>>>>>> What do the data look like? Do you have temperature and elevation at the
>>>>>>> observation points and elevation over the grid? If temperature is the 
>>>>>>> variable for which you want to interpolate, then the formula argument in 
>>>>>>> the gstat() function would be temp ~ elev, data=pointsdata (if a 
>>>>>>> SpatialPointsDataFrame no need for location= ~ x + y). Then the predict() 
>>>>>>> step would need a SpatialGridDataFrame object as newdata, with elev as 
>>>>>>> (one of) the columns in the data slot.
>>>>>>>
>>>>>>> An example for the Meuse bank data in Burrough and McDonnell:
>>>>>>>
>>>>>>> cvgm <- variogram(Zn ~ Fldf, data=BMcD, width=100, cutoff=1000)
>>>>>>> uefitted <- fit.variogram(cvgm, vgm(psill=1, model="Exp", range=100, 
>>>>>>>   nugget=1))
>>>>>>> UK_fit <- gstat(id="UK_fit", formula = Zn ~ Fldf, data = BMcD, 
>>>>>>>   model=uefitted)
>>>>>>> z <- predict(UK_fit, newdata=BMcD_SPx)
>>>>>>>
>>>>>>> where BMcD_SPx is a SpatialPixelsDataFrame (the grid has ragged edges) 
>>>>>>> with flood frequencies in Fldf (actually a factor, but works neatly).
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>   
>>>>>>>       
>>>>>>>           
>>>>>>>               
>>>>>>>> Regards,
>>>>>>>> Tom
>>>>>>>>
>>>>>>>>
>>>>>>>>     
>>>>>>>>         
>>>>>>>>             
>>>>>>>>                 
>>>>>>>   
>>>>>>>       
>>>>>>>           
>>>>>>>               
>>>>>>     
>>>>>>         
>>>>>>             
>>>>>   
>>>>>       
>>>>>           
>>>>     
>>>>         
>>>   
>>>       
>>
>>     
>
>   


-- 
Thomas E Adams
National Weather Service
Ohio River Forecast Center
1901 South State Route 134
Wilmington, OH 45177

EMAIL:	thomas.adams at noaa.gov

VOICE:	937-383-0528
FAX:	937-383-0033



From christoph.hofer at env.ethz.ch  Tue May 16 10:35:43 2006
From: christoph.hofer at env.ethz.ch (Christoph Hofer)
Date: Tue, 16 May 2006 10:35:43 +0200
Subject: [R-sig-Geo] Fast calculation of block-block covariance
Message-ID: <F23DF92A-7462-499C-AFB9-C2B110D9497B@env.ethz.ch>

Dear all

I'm a Ph.D. student in Environmental Sciences at the ETH Zurich and   
new to this list, but I have searched for an answer to my problem in  
the list archives and couldn't find anything.

I have the following problem:
I want to calculate the block-block covariance C(B1,B2) among two  
blocks  of arbitrary  shaped polygons (non-rectangular). In the gstat  
package the block-block covariance is calculated by discretizing the  
blocks by points (via the command  "nblockdiscr" one can choose the  
number of points in the polygon).
I wrote R code with the function integrate, but to calculate the  
block-block covariance a quad integral of the covariance function has  
to be calculated and  therefore even for polygons with a few vertices  
my code is  very slow.

Is there a fast solution (algorithm, package or function in R, aside  
from the gstat solution) to calculate the block-block covariance of  
arbitrary shaped polygons?

Best regards

Christoph Hofer



From e.pebesma at geo.uu.nl  Tue May 16 10:59:01 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Tue, 16 May 2006 10:59:01 +0200
Subject: [R-sig-Geo] Fast calculation of block-block covariance
In-Reply-To: <F23DF92A-7462-499C-AFB9-C2B110D9497B@env.ethz.ch>
References: <F23DF92A-7462-499C-AFB9-C2B110D9497B@env.ethz.ch>
Message-ID: <44699455.8060702@geo.uu.nl>

Christoph,

package spatialCovariance (on CRAN) seems to do this, by reading
it's description. Please share with us whether it did what you wanted
or not; I acknowledge that this is a problem that other packages could
benefit from a fast solution to this problem.

Bests,
--
Edzer

Christoph Hofer wrote:
> Dear all
>
> I'm a Ph.D. student in Environmental Sciences at the ETH Zurich and   
> new to this list, but I have searched for an answer to my problem in  
> the list archives and couldn't find anything.
>
> I have the following problem:
> I want to calculate the block-block covariance C(B1,B2) among two  
> blocks  of arbitrary  shaped polygons (non-rectangular). In the gstat  
> package the block-block covariance is calculated by discretizing the  
> blocks by points (via the command  "nblockdiscr" one can choose the  
> number of points in the polygon).
> I wrote R code with the function integrate, but to calculate the  
> block-block covariance a quad integral of the covariance function has  
> to be calculated and  therefore even for polygons with a few vertices  
> my code is  very slow.
>
> Is there a fast solution (algorithm, package or function in R, aside  
> from the gstat solution) to calculate the block-block covariance of  
> arbitrary shaped polygons?
>
> Best regards
>
> Christoph Hofer
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From christoph.hofer at env.ethz.ch  Tue May 16 13:43:06 2006
From: christoph.hofer at env.ethz.ch (Christoph Hofer)
Date: Tue, 16 May 2006 13:43:06 +0200
Subject: [R-sig-Geo] Fast calculation of block-block covariance
In-Reply-To: <44699455.8060702@geo.uu.nl>
References: <F23DF92A-7462-499C-AFB9-C2B110D9497B@env.ethz.ch>
	<44699455.8060702@geo.uu.nl>
Message-ID: <0E015D5E-09D3-4318-A6E6-F2D87C00DBB2@env.ethz.ch>

Thank you, for the fast replay. I will  read up on
this package of David Clifford and will inform you
if it provide a solution to my problem.


Best regards

Christoph



Am 16.05.2006 um 10:59 schrieb Edzer J. Pebesma:

> Christoph,
>
> package spatialCovariance (on CRAN) seems to do this, by reading
> it's description. Please share with us whether it did what you wanted
> or not; I acknowledge that this is a problem that other packages could
> benefit from a fast solution to this problem.
>
> Bests,
> --
> Edzer
>
> Christoph Hofer wrote:
>> Dear all
>>
>> I'm a Ph.D. student in Environmental Sciences at the ETH Zurich  
>> and   new to this list, but I have searched for an answer to my  
>> problem in  the list archives and couldn't find anything.
>>
>> I have the following problem:
>> I want to calculate the block-block covariance C(B1,B2) among two   
>> blocks  of arbitrary  shaped polygons (non-rectangular). In the  
>> gstat  package the block-block covariance is calculated by  
>> discretizing the  blocks by points (via the command  "nblockdiscr"  
>> one can choose the  number of points in the polygon).
>> I wrote R code with the function integrate, but to calculate the   
>> block-block covariance a quad integral of the covariance function  
>> has  to be calculated and  therefore even for polygons with a few  
>> vertices  my code is  very slow.
>>
>> Is there a fast solution (algorithm, package or function in R,  
>> aside  from the gstat solution) to calculate the block-block  
>> covariance of  arbitrary shaped polygons?
>>
>> Best regards
>>
>> Christoph Hofer
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>



From mwgrant2001 at yahoo.com  Tue May 16 14:11:06 2006
From: mwgrant2001 at yahoo.com (Michael Grant)
Date: Tue, 16 May 2006 05:11:06 -0700 (PDT)
Subject: [R-sig-Geo] Importing and Handling  DXF Map files in R
In-Reply-To: <FA24292AD76FB14EBCD7B205C0C6001D01E9C526@cll94exch1.grupobavaria.com>
Message-ID: <20060516121106.46021.qmail@web52009.mail.yahoo.com>

No know GRASS or wanting to struggle with getting it onto my (ugh!) windows
machine--the old terminal emulation bugaboo--I tackled this problem in a low
tech manner by running my dxf (ascii!) thru DXF2XYZ. Info on DXF2XYZ can now be
found at 

http://www.brightergraphics.co.uk/guthrie/dxf2xyz.htm

I do not know if this is new code or a modernization of the old (US) BLM code
dxf2xyz.c for DOS. But it does the job nicely.

Quoting the developers:

"DXF2XYZ 2.0 converts a DXF file to an XYZ file, ie a comma delimited text file
containing just xyz coordinates.

It can be useful for extracting the raw XYZ coordinates from a DXF file
containing say contours or other elevation entities.

...

(1) This utility is under development, and capabilities are fairly limited, but
will improve with time. The current version will extract the XYZ coordinates
from the following DXF entity types:
POINT, LINE, POLYLINE / VERTEX, LWPOLYLINE

(2) Although the software is not officially supported, you are welcome to
direct any queries/suggestions to Paul Guthrie pguthrie at guthcad.com.au "

So it does not get everything but you do get the map. I all found that had to
do a little post processing of the DXF2XYZ output to get polygons to close up
in R. Its been a couple of years but, if I remember right, the DXF2XYZ output
numbers the entities its translates. So I just read thru the output lines by
line checking the and by entity and if an entity needed closing up I did so by
adding another line segment connecting the last point with the first point. 

I can not remember if I did this in R, BASIC, or FORTRAN but it was
straight-forward.

It has worked very nicely.

HTH

Regards,
Michael Grant

PS Then there is the time I just went looking for points in a dxf...cut and
paste the whole thing into EXCEL, sorted, ... I can't remember why I had to do
it that way... it was a horrible experience :O).

--- Francisco Javier Aguirre Navarro <FAGUIRRN at grupobavaria.com> wrote:

> 
> 
> Hello, I am a newby in the filed of spatial data analysis, could you please
> point me to the right libraries/functions in R  that allow me to import DXF
> maps  and analize spatial data related to these maps ?
> I would appreciaiate any internet references or books  that may give a good
> hands-on introduction to spatial data analysis, I have good knowledge of
> classical statistical methods.
>  I need to analyze about 75000 data points scattered on a map area and I'd
> like to construct a "density" map of my variable of interest and eventually
> see how these densities change in time.
> 
> Thank you very much for your help.
> 
> Francisco J. Aguirre
> Bavaria, Bogota -  Colombia.
> 
> 
> 
> 
> NOTA CONFIDENCIAL: 			
> La informacion contenida en este correo-electronico y cualquier archivo
> adjunto son originados por SABMIller o alguna de sus compa?ias subsidiarias;
> es de uso privilegiado y/o confidencial y solo puede ser utilizada por la
> persona, entidad o compa?ia a la cual esta dirigido. Si usted ha recibido
> este mensaje por error favor destruirlo y avisar al remitente. Si usted no es
> el destinatario no debera revelar, copiar o distribuir o tomar cualquier
> accion basado en los contenidos del mensaje. Cualquier retencion,
> diseminacion o distribucion total o parcial no autorizada de este mensaje
> esta estrictamente prohibida y sancionada por la ley.			
> Las observaciones y opiniones expresadas en este mensaje de correo
> electronico pueden no necesariamente ser aquellos de la Administracion o
> Directivos de SabMiller.			
> 			
> CONFIDENTIAL NOTE: 			
> The information in this E-mail and any attachments transmitted are originated
> by SABMiller or any of its subsidiaries companies, is intended to be
> privileged and/or confidential and only for use of the individual, entity or
> company to whom it is addressed. If you have received this e-mail in error
> please destroy it and contact the sender. If you are not the addressee you
> may not disclose, copy, distribute or take any action based on the contents
> hereof. Any total o partial unauthorized retention, dissemination,
> distribution or copying of this message is strictly prohibited and sanctioned
> by law.			
> The views and opinions expressed in this e-mail message may ...{{dropped}}
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From zev at zevross.com  Wed May 17 23:37:35 2006
From: zev at zevross.com (Zev Ross)
Date: Wed, 17 May 2006 17:37:35 -0400
Subject: [R-sig-Geo] GSTAT fit.variogram method
Message-ID: <446B979F.3090401@zevross.com>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060517/7960c40d/attachment.html>

From colinr23 at gmail.com  Thu May 18 20:04:06 2006
From: colinr23 at gmail.com (Colin Robertson)
Date: Thu, 18 May 2006 11:04:06 -0700
Subject: [R-sig-Geo] 3D KDE
Message-ID: <446cb71a.6ade1fc2.51af.fffffe7e@mx.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060518/4fc03468/attachment.pl>

From e.pebesma at geo.uu.nl  Fri May 19 09:30:17 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Fri, 19 May 2006 09:30:17 +0200
Subject: [R-sig-Geo] GSTAT fit.variogram method
In-Reply-To: <446B979F.3090401@zevross.com>
References: <446B979F.3090401@zevross.com>
Message-ID: <446D7409.3020401@geo.uu.nl>

Zev Ross wrote:
> Hi All,
>
> Can anyone tell me what GSTAT variogram fit method most closely 
> resembles that used in S-PLUS. I'd like to try to come as close as I 
> can to matching some analysis that was done with the variogram.fit 
> function in S-PLUS.
>
> In S-PLUS the WLS function used is |objective.fun <- function(y,yh,n) 
> sum(n*(y/yh-1)^2) |
This is little informatitve without knowign what y, yh and n are.
>
> The GSTAT fit methods are in Table 4.2 of the manual and I'm not sure 
> that any are a perfect match. Based on the formulas and my own output 
> it looks like fit method 2 comes closest.
I agree. I think they both try to do what Noel Cressie suggested  a long 
time ago in:
N. Cressie.  Fitting variogram models by weighted least squares.
/ Mathematical Geology/, 17(5):563-586, 1985.
--
Edzer



From karl.sommer at dpi.vic.gov.au  Mon May 22 01:30:14 2006
From: karl.sommer at dpi.vic.gov.au (karl.sommer at dpi.vic.gov.au)
Date: Mon, 22 May 2006 09:30:14 +1000
Subject: [R-sig-Geo] GSTAT
Message-ID: <OF0219BF5B.02BE0B49-ONCA257175.00800B22-CA257175.00811C4A@nre.vic.gov.au>

Hello list

In the gstat R package tutorial that accompanies the latest version of
GSTAT 0.9-29 it is pointed out that the function coordinates, when assigned
(on the left-hand side of an = or <- sign) promotes the data.frame meuse
into a SpatialPointsDataFrame.  Is there a function that does the opposite
ie. demote the same data set from SpatialPointsDataFrame back to a
data.frame?

Regards

Karl Sommer



From mdsumner at utas.edu.au  Mon May 22 04:06:47 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 22 May 2006 12:06:47 +1000
Subject: [R-sig-Geo] GSTAT
In-Reply-To: <OF0219BF5B.02BE0B49-ONCA257175.00800B22-CA257175.00811C4A@nre.vic.gov.au>
References: <OF0219BF5B.02BE0B49-ONCA257175.00800B22-CA257175.00811C4A@nre.vic.gov.au>
Message-ID: <44711CB7.3020305@utas.edu.au>

karl.sommer at dpi.vic.gov.au wrote:
> Hello list
>
> In the gstat R package tutorial that accompanies the latest version of
> GSTAT 0.9-29 it is pointed out that the function coordinates, when assigned
> (on the left-hand side of an = or <- sign) promotes the data.frame meuse
> into a SpatialPointsDataFrame.  Is there a function that does the opposite
> ie. demote the same data set from SpatialPointsDataFrame back to a
> data.frame?
>   
The inverse is to use as.data.frame, which has a methods for 
SpatialPointsDataFrame, and restores the coordinates as they were 
originally stored, and returns a normal data.frame:

data(meuse)
coordinates(meuse) <- c("x", "y")
## coordinates(meuse) <- ~x+y  ## another way

names(meuse)  ## x, y now treated as intrinsic data, rather than attributes

## now replace meuse with data.frame version

meuse <- as.data.frame(meuse)

names(meuse)



From karl.sommer at dpi.vic.gov.au  Thu May 25 06:55:47 2006
From: karl.sommer at dpi.vic.gov.au (karl.sommer at dpi.vic.gov.au)
Date: Thu, 25 May 2006 14:55:47 +1000
Subject: [R-sig-Geo]  problems loading spproj library for transform()
Message-ID: <OFA19DD4A0.D397EAC0-ONCA257179.0018D48D-CA257179.001B1461@nre.vic.gov.au>

Hello list

I have been trying to do a projection conversion from lat lon to a UTM grid

I followed an example in the April discussion list provided by Roger Bivand
and adapted it to my own data.
Everythings seemd to work well up until the transform() method which failed
to execute.  The failure seems due to a problem
with loading the "spproj package" but I can't make sense of the error
messages which are listed below.
Re-installing spproj did not make a difference.  I am working on a Windows
system

Any hints would be appreciated

Regards

Karl

# import of shape file
wingem38 <- readOGR(dsn = "em38/wing_em38.shp", layer="wing_em38",
verbose=T)

read all EPSG definitions into memory
EPSG <- make_EPSG()

# extract possible options for UTM zone -54
EPSG[grep("UTM zone 54S", EPSG$note), 1:2]

# gives 4 options, select WGS 84 and assign to variable
utm54S <- CRS("+init=epsg:32754")
showWKT(CRSargs(utm54S))

# If shapefiles have a *.prj file already, readOGR() will pick it up.
# If not, need to assign the input coordinate reference system
# to the Spatial object(s):

my_ll <- CRS("+proj=lonlat +datum=WGS84")
proj4string(wingem38) <- my_ll

em38utm <- transform(wingem38,  utm54S)


Loading required package: spproj
Error in importIntoEnv(impenv, impnames, ns, impvars) :
      objects 'Sline', 'Sring', 'Srings', 'SpatialRings',
'getSRpolygonsSlot', 'getSringsIDSlot', 'getSringsSringsSlot',
'getSringCoordsSlot' are not exported by 'namespace:sp'
r-sig-geo at stat.math.ethz.chError in transform(wingem38, utm54S) : for using
(coordinate) transform on objects deriving from Spatial, library spproj is
required



From mdsumner at utas.edu.au  Thu May 25 07:08:11 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 25 May 2006 15:08:11 +1000
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <OFA19DD4A0.D397EAC0-ONCA257179.0018D48D-CA257179.001B1461@nre.vic.gov.au>
References: <OFA19DD4A0.D397EAC0-ONCA257179.0018D48D-CA257179.001B1461@nre.vic.gov.au>
Message-ID: <44753BBB.3050206@utas.edu.au>

Hello

I have the same problem, I've been meaning to explore further before 
posting, but since spproj is not on CRAN I don't think I've missed 
something obvious. This seems to be related to rgdal 0.4-4:

## using data from ?project example

library(rgdal)

## project works OK
  data(state)
  res <- project(cbind(state.center$x, state.center$y), "+proj=lcc 
+lat_1=48 +lat_2=33 +lon_0=-100")
  res1 <- project(res, "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100", 
inv=TRUE)

## but transform does not

res <- SpatialPoints(res, CRS("+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100"))

sessionInfo()
#Version 2.3.0 (2006-04-24)
#i386-pc-mingw32

#attached base packages:
#[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
#[7] "base"    

#other attached packages:
#   rgdal   pixmap    abind       sp
# "0.4-4"  "0.4-4"  "1.1-0" "0.8-14"


transform(res, CRS("+proj=longlat"))
#Loading required package: spproj
#Error in transform(res, CRS("+proj=longlat")) :
#        for using (coordinate) transform on objects deriving from 
Spatial, library spproj is required
#In addition: Warning message:
#there is no package called 'spproj' in: library(package, lib.loc = 
lib.loc, character.only = TRUE, logical = TRUE,



From Roger.Bivand at nhh.no  Thu May 25 07:16:08 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 25 May 2006 07:16:08 +0200 (CEST)
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <OFA19DD4A0.D397EAC0-ONCA257179.0018D48D-CA257179.001B1461@nre.vic.gov.au>
Message-ID: <Pine.LNX.4.44.0605250712340.2188-100000@reclus.nhh.no>

On Thu, 25 May 2006 karl.sommer at dpi.vic.gov.au wrote:

> Hello list
> 
> I have been trying to do a projection conversion from lat lon to a UTM grid
> 
> I followed an example in the April discussion list provided by Roger Bivand
> and adapted it to my own data.

In situations like this, the output of sessionInfo() usually helps. I 
think you have old copies of one or more of rgdal, sp, or spproj. Because 
all of spproj is included in rgdal, it isn't needed at all. My guess is 
that you can totally remove spproj, but check the versions first. 

Roger

> Everythings seemd to work well up until the transform() method which failed
> to execute.  The failure seems due to a problem
> with loading the "spproj package" but I can't make sense of the error
> messages which are listed below.
> Re-installing spproj did not make a difference.  I am working on a Windows
> system
> 
> Any hints would be appreciated
> 
> Regards
> 
> Karl
> 
> # import of shape file
> wingem38 <- readOGR(dsn = "em38/wing_em38.shp", layer="wing_em38",
> verbose=T)
> 
> read all EPSG definitions into memory
> EPSG <- make_EPSG()
> 
> # extract possible options for UTM zone -54
> EPSG[grep("UTM zone 54S", EPSG$note), 1:2]
> 
> # gives 4 options, select WGS 84 and assign to variable
> utm54S <- CRS("+init=epsg:32754")
> showWKT(CRSargs(utm54S))
> 
> # If shapefiles have a *.prj file already, readOGR() will pick it up.
> # If not, need to assign the input coordinate reference system
> # to the Spatial object(s):
> 
> my_ll <- CRS("+proj=lonlat +datum=WGS84")
> proj4string(wingem38) <- my_ll
> 
> em38utm <- transform(wingem38,  utm54S)
> 
> 
> Loading required package: spproj
> Error in importIntoEnv(impenv, impnames, ns, impvars) :
>       objects 'Sline', 'Sring', 'Srings', 'SpatialRings',
> 'getSRpolygonsSlot', 'getSringsIDSlot', 'getSringsSringsSlot',
> 'getSringCoordsSlot' are not exported by 'namespace:sp'
> r-sig-geo at stat.math.ethz.chError in transform(wingem38, utm54S) : for using
> (coordinate) transform on objects deriving from Spatial, library spproj is
> required
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Tom.Mulholland at dpi.wa.gov.au  Thu May 25 07:14:07 2006
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Thu, 25 May 2006 13:14:07 +0800
Subject: [R-sig-Geo] problems loading spproj library for transform()
Message-ID: <4702645135092E4497088F71D9C8F51A0224E54F@afhex01.dpi.wa.gov.au>

I'm sure Roger or someone will come up with exactly what is going on. A couple of weeks ago I had some problems with spproj. I can't recall all the things that I did but it seemed to be associated with me installing 2.3. I noted that when I tried to update my packages that the sp repository didn't have the correct sub-directories. I can't recall what caused me to compile the sp packages under 2.3, but I did. It solved one problem but then I think it caused another. Eventually I only got a resolution once I removed R completely and reinstalled the packages (2.2) on the 2.3 base. My system is working OK now, but I haven't tried updating the packages for a while.

Sorry I can't remember the specifics, but it was one of those cases where I tried so many things that it all got a bit confused.

The main point is, what versions are you using? and have you done anything related to the sp packages that may have inadvertently caused this issue?

It may or may not be a side issue but I don't really understand if I should be removing spproj as I note that Roger has said that the functionality has moved to Rgdal. It was in a thread about WGS84 to UTM, if my memory serves me. Another of the things to do on the list of "things to get right in R."

Tom

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch]On Behalf Of
> karl.sommer at dpi.vic.gov.au
> Sent: Thursday, 25 May 2006 12:56 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] problems loading spproj library for transform()
> 
> 
> Hello list
> 
> I have been trying to do a projection conversion from lat lon 
> to a UTM grid
> 
> I followed an example in the April discussion list provided 
> by Roger Bivand
> and adapted it to my own data.
> Everythings seemd to work well up until the transform() 
> method which failed
> to execute.  The failure seems due to a problem
> with loading the "spproj package" but I can't make sense of the error
> messages which are listed below.
> Re-installing spproj did not make a difference.  I am working 
> on a Windows
> system
> 
> Any hints would be appreciated
> 
> Regards
> 
> Karl
> 
> # import of shape file
> wingem38 <- readOGR(dsn = "em38/wing_em38.shp", layer="wing_em38",
> verbose=T)
> 
> read all EPSG definitions into memory
> EPSG <- make_EPSG()
> 
> # extract possible options for UTM zone -54
> EPSG[grep("UTM zone 54S", EPSG$note), 1:2]
> 
> # gives 4 options, select WGS 84 and assign to variable
> utm54S <- CRS("+init=epsg:32754")
> showWKT(CRSargs(utm54S))
> 
> # If shapefiles have a *.prj file already, readOGR() will pick it up.
> # If not, need to assign the input coordinate reference system
> # to the Spatial object(s):
> 
> my_ll <- CRS("+proj=lonlat +datum=WGS84")
> proj4string(wingem38) <- my_ll
> 
> em38utm <- transform(wingem38,  utm54S)
> 
> 
> Loading required package: spproj
> Error in importIntoEnv(impenv, impnames, ns, impvars) :
>       objects 'Sline', 'Sring', 'Srings', 'SpatialRings',
> 'getSRpolygonsSlot', 'getSringsIDSlot', 'getSringsSringsSlot',
> 'getSringCoordsSlot' are not exported by 'namespace:sp'
> r-sig-geo at stat.math.ethz.chError in transform(wingem38, 
> utm54S) : for using
> (coordinate) transform on objects deriving from Spatial, 
> library spproj is
> required
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Thu May 25 07:35:11 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 25 May 2006 07:35:11 +0200 (CEST)
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <44753BBB.3050206@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0605250733030.2188-100000@reclus.nhh.no>

On Thu, 25 May 2006, Michael Sumner wrote:

> Hello
> 
> I have the same problem, I've been meaning to explore further before 
> posting, but since spproj is not on CRAN I don't think I've missed 
> something obvious. This seems to be related to rgdal 0.4-4:
> 

We are half way through changing the relations between sp and rgdal, 
spproj is retired because it is all in rgdal. The transform method is to 
be named spTransform - could you please see if spTransform() in rgdal 4.4 
helps?

Roger

> ## using data from ?project example
> 
> library(rgdal)
> 
> ## project works OK
>   data(state)
>   res <- project(cbind(state.center$x, state.center$y), "+proj=lcc 
> +lat_1=48 +lat_2=33 +lon_0=-100")
>   res1 <- project(res, "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100", 
> inv=TRUE)
> 
> ## but transform does not
> 
> res <- SpatialPoints(res, CRS("+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100"))
> 
> sessionInfo()
> #Version 2.3.0 (2006-04-24)
> #i386-pc-mingw32
> 
> #attached base packages:
> #[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> #[7] "base"    
> 
> #other attached packages:
> #   rgdal   pixmap    abind       sp
> # "0.4-4"  "0.4-4"  "1.1-0" "0.8-14"
> 
> 
> transform(res, CRS("+proj=longlat"))
> #Loading required package: spproj
> #Error in transform(res, CRS("+proj=longlat")) :
> #        for using (coordinate) transform on objects deriving from 
> Spatial, library spproj is required
> #In addition: Warning message:
> #there is no package called 'spproj' in: library(package, lib.loc = 
> lib.loc, character.only = TRUE, logical = TRUE,
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu May 25 07:41:32 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 25 May 2006 07:41:32 +0200 (CEST)
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <44753BBB.3050206@utas.edu.au>
Message-ID: <Pine.LNX.4.44.0605250740200.2188-100000@reclus.nhh.no>

On Thu, 25 May 2006, Michael Sumner wrote:

> Hello
> 
> I have the same problem, I've been meaning to explore further before 
> posting, but since spproj is not on CRAN I don't think I've missed 
> something obvious. This seems to be related to rgdal 0.4-4:
> 

In rgdal, try running example("spTransform-methods") - if it works, use 
spTransform() instead of transform().

Sorry for the muddle.

Roger

> ## using data from ?project example
> 
> library(rgdal)
> 
> ## project works OK
>   data(state)
>   res <- project(cbind(state.center$x, state.center$y), "+proj=lcc 
> +lat_1=48 +lat_2=33 +lon_0=-100")
>   res1 <- project(res, "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100", 
> inv=TRUE)
> 
> ## but transform does not
> 
> res <- SpatialPoints(res, CRS("+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100"))
> 
> sessionInfo()
> #Version 2.3.0 (2006-04-24)
> #i386-pc-mingw32
> 
> #attached base packages:
> #[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> #[7] "base"    
> 
> #other attached packages:
> #   rgdal   pixmap    abind       sp
> # "0.4-4"  "0.4-4"  "1.1-0" "0.8-14"
> 
> 
> transform(res, CRS("+proj=longlat"))
> #Loading required package: spproj
> #Error in transform(res, CRS("+proj=longlat")) :
> #        for using (coordinate) transform on objects deriving from 
> Spatial, library spproj is required
> #In addition: Warning message:
> #there is no package called 'spproj' in: library(package, lib.loc = 
> lib.loc, character.only = TRUE, logical = TRUE,
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mdsumner at utas.edu.au  Thu May 25 07:59:55 2006
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Thu, 25 May 2006 15:59:55 +1000
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <Pine.LNX.4.44.0605250740200.2188-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605250740200.2188-100000@reclus.nhh.no>
Message-ID: <447547DB.2060509@utas.edu.au>

Thanks Roger, it certainly does work using spTransform.

I had not noticed this 8)  Below is my revised example.

Cheers, Mike.

Note:  "transform" has been renamed to "spTransform" in rgdal 0.4-4

## using data from ?project example

library(rgdal)

## project works OK
 data(state)
 res <- project(cbind(state.center$x, state.center$y), "+proj=lcc 
+lat_1=48 +lat_2=33 +lon_0=-100")
 res1 <- project(res, "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100", 
inv=TRUE)

## and "transform" has been renamed to "spTransform"

res <- SpatialPoints(res, CRS("+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100"))

spTransform(res, CRS("+proj=longlat"))

sessionInfo()
#Version 2.3.0 (2006-04-24)
#i386-pc-mingw32

#attached base packages:
#[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
#[7] "base"   
#other attached packages:
#   rgdal   pixmap    abind       sp
# "0.4-4"  "0.4-4"  "1.1-0" "0.8-14"



From karl.sommer at dpi.vic.gov.au  Thu May 25 09:31:17 2006
From: karl.sommer at dpi.vic.gov.au (karl.sommer at dpi.vic.gov.au)
Date: Thu, 25 May 2006 17:31:17 +1000
Subject: [R-sig-Geo] problems loading spproj library for transform()
Message-ID: <OFC3087CA6.A8457815-ONCA257179.00220D77-CA257179.00295108@nre.vic.gov.au>


thanks for the prompt reply

the method spTransform() worked

I now have an attribute file of class SpatiaPointsDataFrame with EM38
readings.  I also have a separate shape file of class
SpatialPolygonsDataFrame which I imported form an ESRI shape file using the
readOGR() method of rgdal.  I would like to superpose the two files in a
plot but so far have not been successful in lining them up satisfactorily.
I am not sure if the misalignement is due to my misguided plotting method

p1 <- spplot(x, c("var"))  #attribute data
p2 <- spplot (x2)  # shapefile

print(p1, split = c(1,1,1,1), more = TRUE)
print(p2, split = c(1,1,1,1), more = FALSE)

or due to the fact that the projections of the two files differ.  I am not
sure how to extract projection information from the shape file.

any hints would be appreciated

Karl



|---------+----------------------------------->
|         |           Roger.Bivand at nhh.no     |
|         |           Sent by:                |
|         |           r-sig-geo-bounces at stat.m|
|         |           ath.ethz.ch             |
|         |                                   |
|         |                                   |
|         |           25/05/2006 15:41        |
|         |           Please respond to       |
|         |           Roger.Bivand            |
|         |                                   |
|---------+----------------------------------->
  >------------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                              |
  |       To:       mdsumner at utas.edu.au                                                                                         |
  |       cc:       r-sig-geo at stat.math.ethz.ch                                                                                  |
  |       Subject:  Re: [R-sig-Geo] problems loading spproj library for transform()                                              |
  >------------------------------------------------------------------------------------------------------------------------------|




On Thu, 25 May 2006, Michael Sumner wrote:

> Hello
>
> I have the same problem, I've been meaning to explore further before
> posting, but since spproj is not on CRAN I don't think I've missed
> something obvious. This seems to be related to rgdal 0.4-4:
>

In rgdal, try running example("spTransform-methods") - if it works, use
spTransform() instead of transform().

Sorry for the muddle.

Roger

> ## using data from ?project example
>
> library(rgdal)
>
> ## project works OK
>   data(state)
>   res <- project(cbind(state.center$x, state.center$y), "+proj=lcc
> +lat_1=48 +lat_2=33 +lon_0=-100")
>   res1 <- project(res, "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100",
> inv=TRUE)
>
> ## but transform does not
>
> res <- SpatialPoints(res, CRS("+proj=lcc +lat_1=48 +lat_2=33 +lon_0
=-100"))
>
> sessionInfo()
> #Version 2.3.0 (2006-04-24)
> #i386-pc-mingw32
>
> #attached base packages:
> #[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
"datasets"
> #[7] "base"
>
> #other attached packages:
> #   rgdal   pixmap    abind       sp
> # "0.4-4"  "0.4-4"  "1.1-0" "0.8-14"
>
>
> transform(res, CRS("+proj=longlat"))
> #Loading required package: spproj
> #Error in transform(res, CRS("+proj=longlat")) :
> #        for using (coordinate) transform on objects deriving from
> Spatial, library spproj is required
> #In addition: Warning message:
> #there is no package called 'spproj' in: library(package, lib.loc =
> lib.loc, character.only = TRUE, logical = TRUE,
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Fri May 26 00:59:34 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 26 May 2006 00:59:34 +0200 (CEST)
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <OFC3087CA6.A8457815-ONCA257179.00220D77-CA257179.00295108@nre.vic.gov.au>
Message-ID: <Pine.LNX.4.44.0605260052040.2740-100000@reclus.nhh.no>

On Thu, 25 May 2006 karl.sommer at dpi.vic.gov.au wrote:

> 
> thanks for the prompt reply
> 
> the method spTransform() worked
> 
> I now have an attribute file of class SpatiaPointsDataFrame with EM38
> readings.  I also have a separate shape file of class
> SpatialPolygonsDataFrame which I imported form an ESRI shape file using the
> readOGR() method of rgdal.  I would like to superpose the two files in a
> plot but so far have not been successful in lining them up satisfactorily.
> I am not sure if the misalignement is due to my misguided plotting method
> 
> p1 <- spplot(x, c("var"))  #attribute data
> p2 <- spplot (x2)  # shapefile
> 
> print(p1, split = c(1,1,1,1), more = TRUE)
> print(p2, split = c(1,1,1,1), more = FALSE)

Th spplot() methods use lattice graphics, so I am not confident that you 
can validly overplot. Can you try first with base graphics, possibly using 
xlim= and ylim= to zoom in and locator() to check coordinates? 

Shapefiles do not themselves have projection information, it is in a 
separate *.prj file. If you don't have one, you may need to establish it 
yourself. It is not used for plotting Spatial* objects beyond 
conditionally stretching the y axis aspect when is.projected() is TRUE. If 
the objects have been created by spTransform(), the projection information 
has been set, and can be accessed by proj4string().

Roger

> 
> or due to the fact that the projections of the two files differ.  I am not
> sure how to extract projection information from the shape file.
> 
> any hints would be appreciated
> 
> Karl
> 
> 
> 
> |---------+----------------------------------->
> |         |           Roger.Bivand at nhh.no     |
> |         |           Sent by:                |
> |         |           r-sig-geo-bounces at stat.m|
> |         |           ath.ethz.ch             |
> |         |                                   |
> |         |                                   |
> |         |           25/05/2006 15:41        |
> |         |           Please respond to       |
> |         |           Roger.Bivand            |
> |         |                                   |
> |---------+----------------------------------->
>   >------------------------------------------------------------------------------------------------------------------------------|
>   |                                                                                                                              |
>   |       To:       mdsumner at utas.edu.au                                                                                         |
>   |       cc:       r-sig-geo at stat.math.ethz.ch                                                                                  |
>   |       Subject:  Re: [R-sig-Geo] problems loading spproj library for transform()                                              |
>   >------------------------------------------------------------------------------------------------------------------------------|
> 
> 
> 
> 
> On Thu, 25 May 2006, Michael Sumner wrote:
> 
> > Hello
> >
> > I have the same problem, I've been meaning to explore further before
> > posting, but since spproj is not on CRAN I don't think I've missed
> > something obvious. This seems to be related to rgdal 0.4-4:
> >
> 
> In rgdal, try running example("spTransform-methods") - if it works, use
> spTransform() instead of transform().
> 
> Sorry for the muddle.
> 
> Roger
> 
> > ## using data from ?project example
> >
> > library(rgdal)
> >
> > ## project works OK
> >   data(state)
> >   res <- project(cbind(state.center$x, state.center$y), "+proj=lcc
> > +lat_1=48 +lat_2=33 +lon_0=-100")
> >   res1 <- project(res, "+proj=lcc +lat_1=48 +lat_2=33 +lon_0=-100",
> > inv=TRUE)
> >
> > ## but transform does not
> >
> > res <- SpatialPoints(res, CRS("+proj=lcc +lat_1=48 +lat_2=33 +lon_0
> =-100"))
> >
> > sessionInfo()
> > #Version 2.3.0 (2006-04-24)
> > #i386-pc-mingw32
> >
> > #attached base packages:
> > #[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets"
> > #[7] "base"
> >
> > #other attached packages:
> > #   rgdal   pixmap    abind       sp
> > # "0.4-4"  "0.4-4"  "1.1-0" "0.8-14"
> >
> >
> > transform(res, CRS("+proj=longlat"))
> > #Loading required package: spproj
> > #Error in transform(res, CRS("+proj=longlat")) :
> > #        for using (coordinate) transform on objects deriving from
> > Spatial, library spproj is required
> > #In addition: Warning message:
> > #there is no package called 'spproj' in: library(package, lib.loc =
> > lib.loc, character.only = TRUE, logical = TRUE,
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From abunn at whrc.org  Fri May 26 17:32:26 2006
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 26 May 2006 11:32:26 -0400
Subject: [R-sig-Geo] masking z values (extract or subset on a 3-d array)
In-Reply-To: <OFA19DD4A0.D397EAC0-ONCA257179.0018D48D-CA257179.001B1461@nre.vic.gov.au>
Message-ID: <NEBBIPHDAMMOKDKPOFFIOEFCEEAA.abunn@whrc.org>

This is driving me nuts. I have a 3-D array that holds x,y,z coordinates
from multiple experiments. I need to clean the data before making it sp
objects. I want to set all z-values < 0 to 0. In a 2-D matrix this is
trivial e.g., x[,x[1,]<0] <- 0. But I'm stumped on how to do this on a 3-D
array without a loop. Given an array:

  foo <- array(rnorm(24), dim=c(4,3,2))
  dimnames(foo) <- list(NULL,c('x','y','z'),c('Experiment1','Experiment2'))
  foo[,'z',]

How can I set foo[,'z',]<0 to 0?


Thanks, Andy



From Morten.Sickel at nrpa.no  Fri May 26 17:55:58 2006
From: Morten.Sickel at nrpa.no (Morten Sickel)
Date: Fri, 26 May 2006 17:55:58 +0200
Subject: [R-sig-Geo] problems loading spproj library for transform()
Message-ID: <2326C830ADA651438DC694248E5FEF60809E52@mailix.NRPA.LOCAL>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060526/89095cc6/attachment.pl>

From Roger.Bivand at nhh.no  Sat May 27 01:07:10 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 27 May 2006 01:07:10 +0200 (CEST)
Subject: [R-sig-Geo] masking z values (extract or subset on a 3-d array)
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIOEFCEEAA.abunn@whrc.org>
Message-ID: <Pine.LNX.4.44.0605270106170.3541-100000@reclus.nhh.no>

On Fri, 26 May 2006, Andy Bunn wrote:

> This is driving me nuts. I have a 3-D array that holds x,y,z coordinates
> from multiple experiments. I need to clean the data before making it sp
> objects. I want to set all z-values < 0 to 0. In a 2-D matrix this is
> trivial e.g., x[,x[1,]<0] <- 0. But I'm stumped on how to do this on a 3-D
> array without a loop. Given an array:
> 
>   foo <- array(rnorm(24), dim=c(4,3,2))
>   dimnames(foo) <- list(NULL,c('x','y','z'),c('Experiment1','Experiment2'))
>   foo[,'z',]
> 
> How can I set foo[,'z',]<0 to 0?

a <- array(rnorm(64), c(4,4,4))
inds <- which(a < 0, arr.ind=TRUE)
a[inds] <- 0

should do it.

Roger

> 
> 
> Thanks, Andy
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sat May 27 01:08:33 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 27 May 2006 01:08:33 +0200 (CEST)
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <2326C830ADA651438DC694248E5FEF60809E52@mailix.NRPA.LOCAL>
Message-ID: <Pine.LNX.4.44.0605270107260.3541-100000@reclus.nhh.no>

On Fri, 26 May 2006, Morten Sickel wrote:

> I have had the same problems after reading the R-news issue with the
> article on geoprocessing. Then I went to the website mentioned in the
> article, downloaded the software, installed it and it (at least the
> projection stuff) didn't work. Maybe someone could put up a message on
> that website, telling new users that the software is now available on
> cran through the rgdal library ... Remember, the pdf-version of R-news
> will not go away, and users who reads that article will probably follow
> the same tracks as I did, since the packages mentioned are not available
> on cran.

Morten,

OK, thanks, I'll update R-geo and try to update R-spatial directly.

Roger

> 
> Morten
> 
> (Hey, this is just a friendly advice, not to complain, I am overly impressed with what I've seen so far, at last I may be able to throw out ArcView from my PC)
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From abunn at whrc.org  Sat May 27 02:35:31 2006
From: abunn at whrc.org (Andy Bunn)
Date: Fri, 26 May 2006 20:35:31 -0400
Subject: [R-sig-Geo] masking z values (extract or subset on a 3-d array)
In-Reply-To: <Pine.LNX.4.44.0605270106170.3541-100000@reclus.nhh.no>
Message-ID: <000101c68125$77b40f60$0300a8c0@BasementPC>

> > This is driving me nuts. I have a 3-D array that holds x,y,z 
> > coordinates from multiple experiments. I need to clean the 
> data before 
> > making it sp objects. I want to set all z-values < 0 to 0. In a 2-D 
> > matrix this is trivial e.g., x[,x[1,]<0] <- 0. But I'm 
> stumped on how 
> > to do this on a 3-D array without a loop. Given an array:
> > 
> >   foo <- array(rnorm(24), dim=c(4,3,2))
> >   dimnames(foo) <- 
> list(NULL,c('x','y','z'),c('Experiment1','Experiment2'))
> >   foo[,'z',]
> > 
> > How can I set foo[,'z',]<0 to 0?
> 
> a <- array(rnorm(64), c(4,4,4))
> inds <- which(a < 0, arr.ind=TRUE)
> a[inds] <- 0
> 

Thanks, but I'm looking to set only the values from one dimension to zero.
As above, I just want to set the 'z' values to 0 if they are less than one.
This works:

  foo <- array(rnorm(24), dim=c(4,3,2))
  dimnames(foo) <-list(NULL,c('x','y','z'),c('Experiment1','Experiment2'))
  foo[,'z',]
  #How can I set foo[,'z',]<0 to 0
  for(i in 1:2){
    foo[foo[,'z',i]<0,'z',i] = 0
  }
  foo

But it seems like one should be able to do this with apply or just '['. I'm
at a loss.

-A



From tkeitt at gmail.com  Sat May 27 03:27:55 2006
From: tkeitt at gmail.com (Tim Keitt)
Date: Fri, 26 May 2006 20:27:55 -0500
Subject: [R-sig-Geo] masking z values (extract or subset on a 3-d array)
In-Reply-To: <000101c68125$77b40f60$0300a8c0@BasementPC>
References: <Pine.LNX.4.44.0605270106170.3541-100000@reclus.nhh.no>
	<000101c68125$77b40f60$0300a8c0@BasementPC>
Message-ID: <6262c54c0605261827h7bce43a5le1117f5b5b7adf78@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060526/14f32f09/attachment.pl>

From abunn at nova.whrc.org  Sat May 27 20:57:21 2006
From: abunn at nova.whrc.org (Andy Bunn)
Date: Sat, 27 May 2006 14:57:21 -0400
Subject: [R-sig-Geo] masking z values (extract or subset on a 3-d array)
Message-ID: <200605271457.AA8061084@nova.whrc.org>

>Andy,
>
>Maybe this is confusing because the data really ought to be in a dataframe
>with factors coding for treatments?

Can't argue with that logic...it's the principle of the thing you understand. 

>
>Here's one solution:
>
>foo[,'z',] <- sapply(foo[,'z',], function(x) max(c(x, 0)))
>

Thanks! -A


>THK
>
>On 5/26/06, Andy Bunn <abunn at whrc.org> wrote:
>>
>> > > This is driving me nuts. I have a 3-D array that holds x,y,z
>> > > coordinates from multiple experiments. I need to clean the
>> > data before
>> > > making it sp objects. I want to set all z-values < 0 to 0. In a 2-D
>> > > matrix this is trivial e.g., x[,x[1,]<0] <- 0. But I'm
>> > stumped on how
>> > > to do this on a 3-D array without a loop. Given an array:
>> > >
>> > >   foo <- array(rnorm(24), dim=c(4,3,2))
>> > >   dimnames(foo) <-
>> > list(NULL,c('x','y','z'),c('Experiment1','Experiment2'))
>> > >   foo[,'z',]
>> > >
>> > > How can I set foo[,'z',]<0 to 0?
>> >
>> > a <- array(rnorm(64), c(4,4,4))
>> > inds <- which(a < 0, arr.ind=TRUE)
>> > a[inds] <- 0
>> >
>>
>> Thanks, but I'm looking to set only the values from one dimension to zero.
>> As above, I just want to set the 'z' values to 0 if they are less than
>> one.
>> This works:
>>
>>   foo <- array(rnorm(24), dim=c(4,3,2))
>>   dimnames(foo) <-list(NULL,c('x','y','z'),c('Experiment1','Experiment2'))
>>   foo[,'z',]
>>   #How can I set foo[,'z',]<0 to 0
>>   for(i in 1:2){
>>     foo[foo[,'z',i]<0,'z',i] = 0
>>   }
>>   foo
>>
>> But it seems like one should be able to do this with apply or just '['.
>> I'm
>> at a loss.
>>
>> -A
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
>-- 
>Timothy H. Keitt
>http://www.keittlab.org/
>
>



From massimosisasha at yahoo.it  Mon May 29 01:04:24 2006
From: massimosisasha at yahoo.it (massimosisasha)
Date: Mon, 29 May 2006 01:04:24 +0200
Subject: [R-sig-Geo] maptools packages :  shp2SLDF (R-Grass)
Message-ID: <02C84668-432B-42D4-8550-51CCC4E91A1F@yahoo.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060529/3a2a302e/attachment.pl>

From e.pebesma at geo.uu.nl  Mon May 29 10:41:09 2006
From: e.pebesma at geo.uu.nl (Edzer J. Pebesma)
Date: Mon, 29 May 2006 10:41:09 +0200
Subject: [R-sig-Geo] problems loading spproj library for transform()
In-Reply-To: <Pine.LNX.4.44.0605260052040.2740-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605260052040.2740-100000@reclus.nhh.no>
Message-ID: <447AB3A5.80107@geo.uu.nl>

Roger Bivand wrote:
> On Thu, 25 May 2006 karl.sommer at dpi.vic.gov.au wrote:
>
>   
>> thanks for the prompt reply
>>
>> the method spTransform() worked
>>
>> I now have an attribute file of class SpatiaPointsDataFrame with EM38
>> readings.  I also have a separate shape file of class
>> SpatialPolygonsDataFrame which I imported form an ESRI shape file using the
>> readOGR() method of rgdal.  I would like to superpose the two files in a
>> plot but so far have not been successful in lining them up satisfactorily.
>> I am not sure if the misalignement is due to my misguided plotting method
>>
>> p1 <- spplot(x, c("var"))  #attribute data
>> p2 <- spplot (x2)  # shapefile
>>
>> print(p1, split = c(1,1,1,1), more = TRUE)
>> print(p2, split = c(1,1,1,1), more = FALSE)
>>     
>
> Th spplot() methods use lattice graphics, so I am not confident that you 
> can validly overplot. Can you try first with base graphics, possibly using 
> xlim= and ylim= to zoom in and locator() to check coordinates? 
>   
>
I can confirm that you cannot validly overplot using the print() method
for trellis objects (as you do): axes tics, axes labels, titles, everything
plays a role in determining the size before gets done.

Alternatively to base plot, you could try to use the sp.layout argument
to spplot, which is exactly designed to plot more than one "thing" in
a single map. See examples on the r-spatial.sourceforge.net gallery.

Bests,
--
Edzer



From Roger.Bivand at nhh.no  Mon May 29 17:09:00 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 29 May 2006 17:09:00 +0200 (CEST)
Subject: [R-sig-Geo] maptools packages :  shp2SLDF (R-Grass)
In-Reply-To: <02C84668-432B-42D4-8550-51CCC4E91A1F@yahoo.it>
Message-ID: <Pine.LNX.4.44.0605291704110.22390-100000@reclus.nhh.no>

On Mon, 29 May 2006, massimosisasha wrote:

> hi, i'm tring to do the various example on :
> 
> http://skagit.meas.ncsu.edu/~helena/publwork/GRASSnews_vol3.pdf
> 
>   until  to pag.14
> i have not problems
>   but at :
> 
> Using the spgrass6 package with
> vector data...
> 
> at the  line :
>    > streams <- shp2SLDF(res, proj4string = p4s)
> 
> i've this error message :
> 
> Errore: non trovo la funzione "shp2SLDF"
> 
> ??? why ???
> i've read the maptools pdf but i have not find the    shp2SLDF   
> command :-(

I'm travelling and not able to give an authoritative answer now, but 
please try maptools function readShapeLines() which if I remember 
correctly includes the function you mention, but saves the step of first 
reading the shape object. The GRASS-News note was written a year ago, and 
the sp/maptools/rgdal combination on the R side has developed strongly. 
You may also consider readOGR() in rgdal to read shapefiles into 
appropriate Spatial* objects.

Roger

> 
> can you hel me ?
> thanks!
> Massimo.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Realtime_Quotes_joshing at gmail.com  Mon May 29 23:08:54 2006
From: Realtime_Quotes_joshing at gmail.com (Monica Mccauley)
Date: Mon, 29 May 2006 15:08:54 -0600
Subject: [R-sig-Geo] CTBG Deploys World's Only Fully Rotating Well
	Fishing Tools - Ref. g06816
Message-ID: <130016850459.XAA13898Gilt_Fund_holdback@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060529/e45de429/attachment.pl>

From Luisr at frs.fo  Tue May 30 12:03:51 2006
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Tue, 30 May 2006 11:03:51 +0100
Subject: [R-sig-Geo] geoR mailing list
Message-ID: <s47c26a0.057@ffdata.setur.fo>

Dear all geoR members,

Do you get my e-mail to the list?
I say this because my own e-mails do not come up in the mail traffic.

I am just wondering what it is going on.

Can someone please reply to this e-mail?

Thank you in advance

Best,
Luis



From maechler at stat.math.ethz.ch  Tue May 30 14:02:51 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 30 May 2006 14:02:51 +0200
Subject: [R-sig-Geo] geoR mailing list
In-Reply-To: <s47c26a0.057@ffdata.setur.fo>
References: <s47c26a0.057@ffdata.setur.fo>
Message-ID: <17532.13419.725740.717400@stat.math.ethz.ch>

Yes, it got to the list.

If other e-mails of yours do not,
they probably are filtered -- for one or the other reason.

I'm the site-administrator of these R mailing lists,
so you may want to contact me -- IF really needed, for a
particular case -- where I could check our spam filters.

The most common case of non-spam e-mail being filtered as spam
is "HTMLified" mail, i.e., from people who don't care to follow
the posting guide.  In those cases, I do leave the mail in the
filter, disappeared from the sender's point of view -- as deserved :-)

Martin Maechler, ETH Zurich

>>>>> "Luis" == Luis Ridao Cruz <Luisr at frs.fo>
>>>>>     on Tue, 30 May 2006 11:03:51 +0100 writes:

    Luis> Dear all geoR members,

    Luis> Do you get my e-mail to the list?
    Luis> I say this because my own e-mails do not come up in the mail traffic.

    Luis> I am just wondering what it is going on.

    Luis> Can someone please reply to this e-mail?

    Luis> Thank you in advance

    Luis> Best,
    Luis> Luis

    Luis> _______________________________________________
    Luis> R-sig-Geo mailing list
    Luis> R-sig-Geo at stat.math.ethz.ch
    Luis> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From paulojus at est.ufpr.br  Tue May 30 14:40:32 2006
From: paulojus at est.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Tue, 30 May 2006 09:40:32 -0300 (BRT)
Subject: [R-sig-Geo] geoR mailing list
In-Reply-To: <s47c26a0.057@ffdata.setur.fo>
References: <s47c26a0.057@ffdata.setur.fo>
Message-ID: <Pine.LNX.4.63.0605300939520.11701@est.ufpr.br>

Luis

There is no geoR mailing list but
R-SIG-GEO list

have you checked this:
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


On Tue, 30 May 2006, Luis Ridao Cruz wrote:

> Date: Tue, 30 May 2006 11:03:51 +0100
> From: Luis Ridao Cruz <Luisr at frs.fo>
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] geoR mailing list
> 
> Dear all geoR members,
>
> Do you get my e-mail to the list?
> I say this because my own e-mails do not come up in the mail traffic.
>
> I am just wondering what it is going on.
>
> Can someone please reply to this e-mail?
>
> Thank you in advance
>
> Best,
> Luis
>
>
>

Paulo Justiniano Ribeiro Jr
LEG (Laborat?rio de Estat?stica e Geoinforma??o)
Departamento de Estat?stica
Universidade Federal do Paran?
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus at est.ufpr.br
http://www.est.ufpr.br/~paulojus

From patrick.giraudoux at univ-fcomte.fr  Wed May 31 07:37:52 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 31 May 2006 07:37:52 +0200
Subject: [R-sig-Geo] Computing polygon area with decimal degree coordinates
Message-ID: <447D2BB0.9060007@univ-fcomte.fr>

Dear Listers,

The function areapl() of the package splancs computes polygon areas  in 
the coordinate units. This means in square meters when using UTM or 
Lambert projections but in "square degrees" when using longlat degrees.

Does anybody knows a R function (or an algorithm) to compute the area 
directly (without projecting or projecting internally), eg in square 
meters, of a polygon whose node coordinates are given in decimal degrees?

Thanks for any hint,

Patrick



From Roger.Bivand at nhh.no  Wed May 31 09:03:17 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 31 May 2006 09:03:17 +0200 (CEST)
Subject: [R-sig-Geo] Computing polygon area with decimal degree
	coordinates
In-Reply-To: <447D2BB0.9060007@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0605310855180.5324-100000@reclus.nhh.no>

On Wed, 31 May 2006, Patrick Giraudoux wrote:

> Dear Listers,
> 
> The function areapl() of the package splancs computes polygon areas  in 
> the coordinate units. This means in square meters when using UTM or 
> Lambert projections but in "square degrees" when using longlat degrees.
> 
> Does anybody knows a R function (or an algorithm) to compute the area 
> directly (without projecting or projecting internally), eg in square 
> meters, of a polygon whose node coordinates are given in decimal degrees?

I think it could be done internally in the sp/src/Rcentroid.c function if 
Area2() was rewritten to call sp_gcdist() on each of the four segments in:

  area = (b[0] - a[0]) * (c[1] - a[1]) - (c[0] - a[0]) * (b[1] - a[1]);

but it would only be acceptable for larger areas. As it is, the area of 
SpatialPolygons objects is really only used to create the plot order (to 
plot larger polygons before smaller ones). In fact we only have the 
measurement at the Polygon object level sensibly - above that we don't 
really know whether multiple polygons in a Polygons object are holes or 
not, so summing the component Polygon object areas in a Polygons object 
may be wrong.

Roger

> 
> Thanks for any hint,
> 
> Patrick
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From patrick.giraudoux at univ-fcomte.fr  Wed May 31 09:13:31 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 31 May 2006 09:13:31 +0200
Subject: [R-sig-Geo] Computing polygon area with decimal degree
	coordinates
In-Reply-To: <Pine.LNX.4.44.0605310855180.5324-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0605310855180.5324-100000@reclus.nhh.no>
Message-ID: <447D421B.8010601@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060531/370f1517/attachment.pl>

From didier.leibovici at teledetection.fr  Wed May 31 09:14:31 2006
From: didier.leibovici at teledetection.fr (didier leibovici)
Date: Wed, 31 May 2006 09:14:31 +0200
Subject: [R-sig-Geo] raster to polygons
Message-ID: <447D4257.6060901@teledetection.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060531/1227118b/attachment.pl>

From Roger.Bivand at nhh.no  Wed May 31 09:27:09 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 31 May 2006 09:27:09 +0200 (CEST)
Subject: [R-sig-Geo] Computing polygon area with decimal degree
	coordinates
In-Reply-To: <447D421B.8010601@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0605310921360.5324-100000@reclus.nhh.no>

On Wed, 31 May 2006, Patrick Giraudoux wrote:

> Well, thinking about it, I realize this question was a bit weird/silly 
> in the real world... Decimal degree coordinates does not tell us 
> anything about the ellipsoid/datum they refer to and this must be done 
> within a CRS framework. If we want a reasonable precision on small 
> areas, sound mathematics to get reasonable projections in an euclidean 
> space are likely unavoidable (which is easy within rgdal and 
> sptranform()). Except if one think that the earth is a perfect sphere. 
> Would even be easier if still flat...

The Great Circle distance in sp assumes WGS84, and is probably OK for 
provinces, and maybe larger counties where the area should just be an 
order of magnitude, and should preserve the rank order of the polygons. 
But it cannot be accurate anyway, because it is limited to the straight 
line segments of the points on the polygon boundary - if they are thinned, 
you will get a different area, the same if they increase in detail, such 
as along a river bank. 

But it could be done (roughly), if the spTransform() route seems
unhelpful, or if the data are at a continental scale, where projection
will lead to big errors away from the map centre.

Roger

> 
> 
> Roger Bivand a ?crit :
> > On Wed, 31 May 2006, Patrick Giraudoux wrote:
> >
> >   
> >> Dear Listers,
> >>
> >> The function areapl() of the package splancs computes polygon areas  in 
> >> the coordinate units. This means in square meters when using UTM or 
> >> Lambert projections but in "square degrees" when using longlat degrees.
> >>
> >> Does anybody knows a R function (or an algorithm) to compute the area 
> >> directly (without projecting or projecting internally), eg in square 
> >> meters, of a polygon whose node coordinates are given in decimal degrees?
> >>     
> >
> > I think it could be done internally in the sp/src/Rcentroid.c function if 
> > Area2() was rewritten to call sp_gcdist() on each of the four segments in:
> >
> >   area = (b[0] - a[0]) * (c[1] - a[1]) - (c[0] - a[0]) * (b[1] - a[1]);
> >
> > but it would only be acceptable for larger areas. As it is, the area of 
> > SpatialPolygons objects is really only used to create the plot order (to 
> > plot larger polygons before smaller ones). In fact we only have the 
> > measurement at the Polygon object level sensibly - above that we don't 
> > really know whether multiple polygons in a Polygons object are holes or 
> > not, so summing the component Polygon object areas in a Polygons object 
> > may be wrong.
> >
> > Roger
> >
> >   
> >> Thanks for any hint,
> >>
> >> Patrick
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >>     
> >
> >   
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed May 31 09:31:09 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 31 May 2006 09:31:09 +0200 (CEST)
Subject: [R-sig-Geo] raster to polygons
In-Reply-To: <447D4257.6060901@teledetection.fr>
Message-ID: <Pine.LNX.4.44.0605310927361.5324-100000@reclus.nhh.no>

On Wed, 31 May 2006, didier leibovici wrote:

> Hi,
> I can't find a function allowing to transform a raster grid to a polygon 
> 'shapefile' (sp class or other)

Could you look in the sp package at:

?as.SpatialPolygons.GridTopology

and see if it does what you need (for coarse grids)? It only makes 
rectangular polygons, if you need to merge polygons based on an attribute 
value, that can be done too, quite inefficiently, but it works.

Roger

> thanks
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ari.jolma at tkk.fi  Wed May 31 09:43:13 2006
From: ari.jolma at tkk.fi (Ari Jolma)
Date: Wed, 31 May 2006 10:43:13 +0300
Subject: [R-sig-Geo] raster to polygons
In-Reply-To: <447D4257.6060901@teledetection.fr>
References: <447D4257.6060901@teledetection.fr>
Message-ID: <447D4911.9020307@tkk.fi>

didier leibovici kirjoitti:
> Hi,
> I can't find a function allowing to transform a raster grid to a polygon 
> 'shapefile' (sp class or other)

I just posted on gdal-dev this example:
http://map.hut.fi/PerlForGeoinformatics/scripts/r2v.pl

It converts a grid to a layer of polygons, currently it is even a bit
too meticulous, each vertex which belongs to the polygons border is
stored, even those that are on a straight line.

The code requires GDAL and its Perl interface, which is included in the
latest relieses.

Regards,

Ari

> thanks
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Prof. Ari Jolma
Kartografia ja Geoinformatiikka / Cartography and Geoinformatics
Teknillinen Korkeakoulu / Helsinki University of Technology
tel: +358 9 451 3886 address: POBox 1200, 02015 TKK, Finland
Email: ari.jolma at tkk.fi URL: http://www.tkk.fi/~jolma



From tkeitt at gmail.com  Wed May 31 14:33:27 2006
From: tkeitt at gmail.com (Tim Keitt)
Date: Wed, 31 May 2006 07:33:27 -0500
Subject: [R-sig-Geo] Computing polygon area with decimal degree
	coordinates
In-Reply-To: <447D2BB0.9060007@univ-fcomte.fr>
References: <447D2BB0.9060007@univ-fcomte.fr>
Message-ID: <6262c54c0605310533p3d48b900jb735219e946aa02b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060531/7d157015/attachment.pl>

From patrick.giraudoux at univ-fcomte.fr  Wed May 31 14:55:43 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Wed, 31 May 2006 14:55:43 +0200
Subject: [R-sig-Geo] Computing polygon area with decimal degree
	coordinates
In-Reply-To: <6262c54c0605310533p3d48b900jb735219e946aa02b@mail.gmail.com>
References: <447D2BB0.9060007@univ-fcomte.fr>
	<6262c54c0605310533p3d48b900jb735219e946aa02b@mail.gmail.com>
Message-ID: <447D924F.4000704@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20060531/59a1347d/attachment.pl>

