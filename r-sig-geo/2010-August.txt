From p.hiemstra at geo.uu.nl  Sun Aug  1 10:53:06 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sun, 01 Aug 2010 10:53:06 +0200
Subject: [R-sig-Geo] add legend to plot(spatialpolygonsdataframe)
In-Reply-To: <AANLkTi=ROi4mu5trMuGH2mYBthb8hMMbaHewWSEAYFPW@mail.gmail.com>
References: <AANLkTi=ROi4mu5trMuGH2mYBthb8hMMbaHewWSEAYFPW@mail.gmail.com>
Message-ID: <4C5535F2.5040300@geo.uu.nl>

On 07/28/2010 10:28 AM, Paulo Eduardo Cardoso wrote:
> How can one compose a plot, adding legend, title, and axis titles to a
> plot of spatial object like a spatialpolygonsdataframe?
> Any comment will be appreciated
> Paulo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    
Hi Paulo,

I would take a look at spplot. This wrapper around a few functions from 
lattice plots spatial data quite nicely. See:

http://rwiki.sciviews.org/doku.php?id=tips:spatial-data:spatial_data_visualization

for some more information.

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From elaine.kuo.tw at gmail.com  Sun Aug  1 13:57:30 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Sun, 1 Aug 2010 19:57:30 +0800
Subject: [R-sig-Geo] error in errorsarlm
In-Reply-To: <alpine.LRH.2.00.1007302053580.22750@reclus.nhh.no>
References: <AANLkTintGvKs7Y9AXUOLUeYPZwWtj2fH5ugltwhK-jm1@mail.gmail.com>
	<alpine.LRH.2.00.1007162144300.19802@reclus.nhh.no>
	<AANLkTik9muDJNtOG4lyJXl2Fk96c3CRDJAZ6dNJDntvq@mail.gmail.com>
	<alpine.LRH.2.00.1007171534310.22601@reclus.nhh.no>
	<AANLkTinWLIBpZQBFjANAgXkfXudfoUmGg8YGek3zD4R4@mail.gmail.com>
	<alpine.LRH.2.00.1007201614260.18432@reclus.nhh.no>
	<AANLkTik_BYkRFUMMC-Vr-UY0UfhOyJZ6HJfg98BDpndt@mail.gmail.com>
	<alpine.LRH.2.00.1007302053580.22750@reclus.nhh.no>
Message-ID: <AANLkTimu=m7w2HiBNzfd-uvriokEPe+sy4BYVyh=ESRD@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100801/a77b62b0/attachment.pl>

From nikhil.list at gmail.com  Sun Aug  1 15:19:10 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Sun, 1 Aug 2010 09:19:10 -0400
Subject: [R-sig-Geo] error in errorsarlm
In-Reply-To: <AANLkTimu=m7w2HiBNzfd-uvriokEPe+sy4BYVyh=ESRD@mail.gmail.com>
References: <AANLkTintGvKs7Y9AXUOLUeYPZwWtj2fH5ugltwhK-jm1@mail.gmail.com>
	<alpine.LRH.2.00.1007162144300.19802@reclus.nhh.no>
	<AANLkTik9muDJNtOG4lyJXl2Fk96c3CRDJAZ6dNJDntvq@mail.gmail.com>
	<alpine.LRH.2.00.1007171534310.22601@reclus.nhh.no>
	<AANLkTinWLIBpZQBFjANAgXkfXudfoUmGg8YGek3zD4R4@mail.gmail.com>
	<alpine.LRH.2.00.1007201614260.18432@reclus.nhh.no>
	<AANLkTik_BYkRFUMMC-Vr-UY0UfhOyJZ6HJfg98BDpndt@mail.gmail.com>
	<alpine.LRH.2.00.1007302053580.22750@reclus.nhh.no>
	<AANLkTimu=m7w2HiBNzfd-uvriokEPe+sy4BYVyh=ESRD@mail.gmail.com>
Message-ID: <43E158B7-281C-4C5E-9B9E-7ACA2FAFAC82@gmail.com>

example(errorsarlm)

Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 1, 2010, at 7:57 AM, elaine kuo wrote:

> Dear Dr. Bivand and list
>
> Thank you for the patience.
>
> Only one question remains
>
>
>
>>>
>>> 2. great distance circle
>>>
>>> => longlat = TRUE returns no valid observation ...
>>>   similar error messages have been researched in the archived mail
>>>   but no identical case found...
>>>  Please kindly suggest when longlat=TRUE,
>>>  whether the unit of both longitude and latitude is degree.decimal..
>>>  (confused with the manual explanation "measured in kilometer")
>>>
>>
>> The threshold is in km when longlat=TRUE, but the coordinates are in
>> decimal degrees. Please state the representation of your  
>> coordinates - are
>> they in decimal degrees or not?
>
>
> =>  Yes, mine are in decimal degrees.
>
>>
>> No, simply that you are including too many neighbours leading to  
>> too much
>> smoothing for many observations.
>>
>> Please try everything on small examples until you understand what  
>> you are
>> doing. Best, use publically available small examples, and include  
>> complete
>> verbatim code (or post code on a website), max. 10 lines.
>
>
> => please advise any publicly available small examples to try  
> errosarlm...
>
>     I have none at hand.. :P Thank you.
>
> Elaine
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Sun Aug  1 16:00:59 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 1 Aug 2010 16:00:59 +0200 (CEST)
Subject: [R-sig-Geo] error in errorsarlm
In-Reply-To: <43E158B7-281C-4C5E-9B9E-7ACA2FAFAC82@gmail.com>
References: <AANLkTintGvKs7Y9AXUOLUeYPZwWtj2fH5ugltwhK-jm1@mail.gmail.com>
	<alpine.LRH.2.00.1007162144300.19802@reclus.nhh.no>
	<AANLkTik9muDJNtOG4lyJXl2Fk96c3CRDJAZ6dNJDntvq@mail.gmail.com>
	<alpine.LRH.2.00.1007171534310.22601@reclus.nhh.no>
	<AANLkTinWLIBpZQBFjANAgXkfXudfoUmGg8YGek3zD4R4@mail.gmail.com>
	<alpine.LRH.2.00.1007201614260.18432@reclus.nhh.no>
	<AANLkTik_BYkRFUMMC-Vr-UY0UfhOyJZ6HJfg98BDpndt@mail.gmail.com>
	<alpine.LRH.2.00.1007302053580.22750@reclus.nhh.no>
	<AANLkTimu=m7w2HiBNzfd-uvriokEPe+sy4BYVyh=ESRD@mail.gmail.com>
	<43E158B7-281C-4C5E-9B9E-7ACA2FAFAC82@gmail.com>
Message-ID: <alpine.LRH.2.00.1008011544090.5518@reclus.nhh.no>

On Sun, 1 Aug 2010, Nikhil Kaza wrote:

> example(errorsarlm)

Right!

Or any other available dataset that mirrors the application case, which 
seems to be ecological, but crucially has point or cell support in decimal 
degrees with very large differences in distances between observations. You 
are right that packages include lots of example data sets, and that they 
are the place to start. In addition, the case is large, but the example 
should not be, so that all the other problems can be eliminated first 
before trying to scale up to moderate N (about 4000 if I recall 
correctly).

The main problem is that the spatial process is conceptualised as 
contagious in distance, and that the distance threshold is chosen to 
ensure that all observations have at least one neighbour. This doesn't 
seem helpful as many observations then have "too many" neighbours to make 
sense. If the coordinates of the observations can be projected to the 
plane, a graph-based neighbour scheme can be used, which represents the 
spatial process as contagious in contiguity (neighbouring observations are 
neighbours irrespective of distance).

So the first step is to think through how "neighbouring" observations can 
influence each other in terms appropriate to the subject domain.

Roger

>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
> On Aug 1, 2010, at 7:57 AM, elaine kuo wrote:
>
>> Dear Dr. Bivand and list
>> 
>> Thank you for the patience.
>> 
>> Only one question remains
>> 
>> 
>> 
>>>> 
>>>> 2. great distance circle
>>>> 
>>>> => longlat = TRUE returns no valid observation ...
>>>>  similar error messages have been researched in the archived mail
>>>>  but no identical case found...
>>>> Please kindly suggest when longlat=TRUE,
>>>> whether the unit of both longitude and latitude is degree.decimal..
>>>> (confused with the manual explanation "measured in kilometer")
>>>> 
>>> 
>>> The threshold is in km when longlat=TRUE, but the coordinates are in
>>> decimal degrees. Please state the representation of your coordinates - are
>>> they in decimal degrees or not?
>> 
>> 
>> =>  Yes, mine are in decimal degrees.
>> 
>>> 
>>> No, simply that you are including too many neighbours leading to too much
>>> smoothing for many observations.
>>> 
>>> Please try everything on small examples until you understand what you are
>>> doing. Best, use publically available small examples, and include complete
>>> verbatim code (or post code on a website), max. 10 lines.
>> 
>> 
>> => please advise any publicly available small examples to try errosarlm...
>>
>>    I have none at hand.. :P Thank you.
>> 
>> Elaine
>>
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Rafael.Lata at ait.ac.at  Mon Aug  2 10:54:35 2010
From: Rafael.Lata at ait.ac.at (Lata Rafael)
Date: Mon, 2 Aug 2010 10:54:35 +0200
Subject: [R-sig-Geo] (no subject)
Message-ID: <03DD2D3DC948ED4795830164EA3F302ED80A081685@MAILBOX.arc.local>

Dear all,

 

I have a problem converting a large binary sparse weight matrix (62025 *

62025) of class dgTMatrix to listw.

 

First I create a sparse weight matrix with the code: 

 

###weightsparse###

Wmatrix<-as_dgRMatrix_listw(Reg255.listw)

 

Since I want to model spatial autocorrelation in spatial interaction data (Poisson Spatial Interaction Model with the Moran eigenvector GLM filtering  approach)I used the kronecker product and the identity Matrix to represent network spatial autocorrelation between origin?destination dyads:

 

 

I<-as_dsCMatrix_I(255)

Wo<-kronecker(I,Wmatrix)

Wd<-kronecker(Wmatrix,I)

Wod<-Wo+Wd

 

I tried to convert this sparse matrix (Wod) to a matrix but I got an error (too many elements).

 

Is there a function that creates a listw object from a sparse matrix?

 

Thank you in advance.

 

Best regards

Rafael


From alaios at yahoo.com  Mon Aug  2 12:25:18 2010
From: alaios at yahoo.com (Alaios)
Date: Mon, 2 Aug 2010 03:25:18 -0700 (PDT)
Subject: [R-sig-Geo] grf and RasterLayer
Message-ID: <686119.93589.qm@web120112.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100802/cbf45f48/attachment.pl>

From Roger.Bivand at nhh.no  Mon Aug  2 18:47:40 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 2 Aug 2010 18:47:40 +0200 (CEST)
Subject: [R-sig-Geo] spautolm variable selection
In-Reply-To: <AANLkTi=xNUTSPypOkYund9Rjf5a2a6U-_JLse8AGojX0@mail.gmail.com>
References: <AANLkTi=xNUTSPypOkYund9Rjf5a2a6U-_JLse8AGojX0@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008021844240.9268@reclus.nhh.no>

On Sun, 25 Jul 2010, Peter Larson wrote:

> Hello,
>
> Is there any way to iterate spautolm to run through all possible
> models using a set of covariates and choose the one with the lowest
> AIC?

No, there are no step or update facilities for spautolm.

Since the choice of RHS variables (and their functional forms) will affect 
the spatial parameter, this would be rather tricky anyway, as dropping 
variables might well increase autocorrelation in the residual. You could 
look at ways of using Spatial Filtering for this purpose, but the 
functions used for this do not support variable selection either - you'd 
need to write your own.

Roger

>
> Thanks,
>
> pete
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Aug  2 18:56:32 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 2 Aug 2010 18:56:32 +0200 (CEST)
Subject: [R-sig-Geo] shared boundary lengths ?
In-Reply-To: <1C19E50585A98643871CAFD72AE1976C150DE96C88@exvic-mbx03.nexus.csiro.au>
References: <1C19E50585A98643871CAFD72AE1976C150DE96C88@exvic-mbx03.nexus.csiro.au>
Message-ID: <alpine.LRH.2.00.1008021848020.9268@reclus.nhh.no>

On Mon, 26 Jul 2010, Toby.Patterson at csiro.au wrote:

> Hi, Apologies up front if this has been covered somewhere already -- I 
> have seen some discussion of a similar problem on the list, but it 
> doesn't quite seem to cover what I'm after.
>
> Also I'm new to the spatial side of R, so I might not quite use the 
> correct lingo!
>
> My problem is this:
>
> For a set of polygons (a SpatialPolygonsDataFrame) with shared 
> boundaries (i.e. with no overlapping regions or gaps between them), I 
> need to know the length of shared adjacent boundaries. Note, in this 
> case all polygons will have a boundary shared with at least one other 
> polygon.
>
> So I'm after a square symmetric matrix with diagonals zero. The i,j th 
> entry would then be the length (in some appropriate coordinate system) 
> of the boundary between polygon i and j.
>
> Also - I'm not sure if sufficient information is stored in the 
> SpatialPolygonsDataFrame class actually allow these shared lengths to be 
> calculated. I'm sure someone can quickly clear that up for me. Possibly 
> this can only be done in GIS systems?

Indeed, only in topological GIS, because the nodes and arcs must be 
identified and the topology built. The only provision in R-spatial is 
using vect2neigh() in the spgrass6 interface to GRASS6. You would need to 
install GRASS first, export the polygons to GRASS, then read off the 
neighbours and the boundary lengths with the function. As far as I'm 
aware, it doesn't work on Windows because of the inadequacy of cmd.exe 
(script variable quoting) for running v.db.addtable, but on other 
platforms works fine. The function is described in:

https://stat.ethz.ch/pipermail/r-sig-geo/2005-October/000616.html

and on its help page.

Hope this helps,

Roger

>
> Any help would be much appreciated as this it seems quite a fiddly one 
> to write myself.
>
> Thanks,
> Toby
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Aug  2 19:09:03 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 2 Aug 2010 19:09:03 +0200 (CEST)
Subject: [R-sig-Geo] writeOGR error: problem with GDAL (libgdal1- 1.7.0)
In-Reply-To: <F7A3EE6B27F4D54B9CCAAB767F1B5AA301952928@SOVON1.SOVON.local>
References: <F7A3EE6B27F4D54B9CCAAB767F1B5AA3FDBBE9@SOVON1.SOVON.local>
	<AD51AB79BC327C40AB2C7EB75D57A3C4051326@TOLAR.valuta.nhh.no>
	<F7A3EE6B27F4D54B9CCAAB767F1B5AA301952928@SOVON1.SOVON.local>
Message-ID: <alpine.LRH.2.00.1008021858260.9268@reclus.nhh.no>

On Fri, 23 Jul 2010, Henk Sierdsema wrote:

> Hi Roger,
>
> You're right of course: replacing the library with an older version 
> works, but it's definitely not chique. So I looked into the problem a 
> little bit deeper, following up on the remarks of Agus. It turns out, 
> that the latest version of rgdal works fine with variable-names up to 10 
> characters, but crashes on longer variable-names. The problem appears 
> apparently both on a Linux- (Ubuntu 9) and Windows-platforms (XP, Win7).

There are no "crashes". What it does depends on the GDAL version and the 
OGR driver chosen:

> library(rgdal)
Loading required package: sp
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
Path to GDAL shared files: /usr/local/share/gdal
Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
Path to PROJ.4 shared files: (autodetected)
> names(cities)
[1] "NAME"       "COUNTRY"    "POPULATION" "CAPITAL"
> cities$ABCDEFGHIJKLMNOPQRSTUVWXYZ <- NA
> names(cities)
[1] "NAME"                       "COUNTRY"
[3] "POPULATION"                 "CAPITAL"
[5] "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
> writeOGR(cities, tempdir(), "cities", driver="ESRI Shapefile")
Warning message:
In writeOGR(cities, tempdir(), "cities", driver = "ESRI Shapefile") :
         Non-fatal GDAL Error 6: Normalized/laundered field name: 
'ABCDEFGHIJKLMNOPQRSTUVWXYZ' to 'ABCDEFGHIJ'
> ogrInfo(tempdir(), "cities")
Source: "/tmp/Rtmp2NjEC9", layer: "cities"
Driver: ESRI Shapefile number of rows 606
Feature type: wkbPoint with 2 dimensions
+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
Number of fields: 5
         name type length typeName
1       NAME    4     80   String
2    COUNTRY    4     80   String
3 POPULATION    2     24     Real
4    CAPITAL    4     80   String
5 ABCDEFGHIJ    2     11     Real

This OGR driver does not permit longer names (as the base DBF III 
unwritten spec. does not either, this is not unexpected); however other 
drivers may:

> tf <- tempfile()
> writeOGR(cities, tf, "cities", driver="GML")
> ogrInfo(tf, "cities")
Source: "/tmp/Rtmp2NjEC9/file66334873", layer: "cities"
Driver: GML number of rows 606
Feature type: wkbPoint with 2 dimensions
NA
Number of fields: 5
                         name type length typeName
1                       NAME    4      0   String
2                    COUNTRY    4      0   String
3                 POPULATION    2     33     Real
4                    CAPITAL    4      0   String
5 ABCDEFGHIJKLMNOPQRSTUVWXYZ    0     16  Integer
> tf <- tempfile()
> writeOGR(cities, tf, "cities", driver="MapInfo File")
> ogrInfo(tf, "cities")
Source: "/tmp/Rtmp2NjEC9/file19495cff", layer: "cities"
Driver: MapInfo File number of rows 606
Feature type: wkbPoint with 2 dimensions
+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
Number of fields: 5
                         name type length typeName
1                       NAME    4    254   String
2                    COUNTRY    4    254   String
3                 POPULATION    2      0     Real
4                    CAPITAL    4    254   String
5 ABCDEFGHIJKLMNOPQRSTUVWXYZ    0      0  Integer

OK?

Roger





>
> Henk
>
>
> ________________________________
>
> Van: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Verzonden: wo 21-7-2010 23:17
> Aan: Henk Sierdsema; Agustin Lobo; r-sig-geo at stat.math.ethz.ch
> Onderwerp: SV: [R-sig-Geo] writeOGR error: problem with GDAL (libgdal1- 1.7.0)
>
>
> Success is of course in the eye of the beholder. You are free to change your own installation in arguably bad ways, but please do not advise others to do so on the list. Lots of peoiple may be misled by your suggestion. It would be possible to rebuild (guessing that you are using Windows) to rebuild an older source rgdal for newer R in order to retain previous behaviour, but messing with an installed library of R packages is always a questionable idea.
>
> Roger
>
> PS. Since the original posting was made (two months ago), rgdal has been revised, including IIRC changed messages in this case.
>
> --- Roger Bivand, NHH, Helleveien 30, N-5045 Bergen, Roger.Bivand at nhh.no
>
> ________________________________
>
> Fra: r-sig-geo-bounces at stat.math.ethz.ch p? vegne av Henk Sierdsema
> Sendt: on 2010-07-21 13:17
> Til: Agustin Lobo; r-sig-geo at stat.math.ethz.ch
> Emne: Re: [R-sig-Geo] writeOGR error: problem with GDAL (libgdal1- 1.7.0)
>
>
>
> Hi Augustin,
>
> I've encountered the same problem after an update of the rgdal-package. I have resolved the problem by removing the rgal-folder in the library and replacing it by an older version of November 2009. You can download that version of www.sovon.nl/temp/rgdal_nov_2009.zip
>
> Success!
>
> Henk
>
>
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch]Namens Agustin Lobo
> Verzonden: vrijdag 21 mei 2010 7:39
> Aan: r-sig-geo at stat.math.ethz.ch
> Onderwerp: [R-sig-Geo] writeOGR error: problem with GDAL (libgdal1-
> 1.7.0)
>
>
>
> I'm getting this error using a command and an object that
> used to work few months ago
>
>> writeOGR(Montseny20090409shtotspols, dsn="Montseny20090409tots2",
>> layer="Montseny20090409shtots2",driver="ESRI Shapefile")
> Error in writeOGR(Montseny20090409shtotspols, dsn = "Montseny20090409tots2",
> :
>
>        GDAL Error 1: Invalid index : -1
> Calls: writeOGR -> .Call
> In addition: Warning messages:
> 1: In writeOGR(Montseny20090409shtotspols, dsn = "Montseny20090409tots2",  :
>
>        Non-fatal GDAL Error 6: Normalized/laundered field name: 'coords.x1.1' to
> 'coords.x1.'
> 2: In writeOGR(Montseny20090409shtotspols, dsn = "Montseny20090409tots2",  :
>
>        Non-fatal GDAL Error 6: Normalized/laundered field name: 'coords.x2.1' to
> 'coords.x2.'
>
> Both the Error and Warnings are new, and are actually related: if I do:
>> names(Montseny20090409shtotspols at data)[31]<-"UTMX"
>> names(Montseny20090409shtotspols at data)[32]<-"UTMY"
>
> writeOGR() works fine.
>
> Could a more explicit error message, linking the error to the problem with
> the names, be issued by writeOGR() ? Initially I even thought I could have a
> disk problem!
>
> I recently upgraded from ubuntu 9.04 to 9.10 and to libgdal1-1.7.0.
> R version 2.11.0 (2010-04-22)
> Package: rgdal
> Version: 0.6-27
> Date: 2010-05-11
>
> Thanks
>
> Agus
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeOGR-error-problem-with-GDAL-libgdal1-1-7-0-tp5082811p5082811.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From r.hijmans at gmail.com  Mon Aug  2 20:25:41 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 2 Aug 2010 11:25:41 -0700
Subject: [R-sig-Geo] grf and RasterLayer
In-Reply-To: <686119.93589.qm@web120112.mail.ne1.yahoo.com>
References: <686119.93589.qm@web120112.mail.ne1.yahoo.com>
Message-ID: <AANLkTinBNanqrOHFV-jPrK4vzFSn16DWKQoqaHOVJJAP@mail.gmail.com>

Alaios,

> Do you know how I can have not fixed resolution in a RasterLayer?

That is not directly possible. Perhaps you can have a set of
RasterLayers at different resolutions; and then for a given area (grid
cell at the lowest resolution) use the values of the RasterLayer that
has non-NA values; or devise some other scheme like that. Can't help
you with the geoR question.

Robert



On Mon, Aug 2, 2010 at 3:25 AM, Alaios <alaios at yahoo.com> wrote:
> ?Hello.
> I am pretty new to R and to geoR as well.
>
>
> ? A) I would like to implement an area of X*X ?km that would be used to
> "Simulate" an
>
> area map (eg. city's area, suburban area).
>
> -X would be a parameter so I do not want it to be fixed
> -In this map I would like to place users (people), thus I do not know in advance
>
> if in one place there would be one,two, or more users..
> -I would also like to not have fixed resolution in my map and specify it as a
> parameter during run-time. In my X*X area I would like sometimes to have
> resolution of 1Km and others resolution of 10 meters. As resolution increases (1
>
> km->100m->10m) less users would be found in the same "place".
>
> Do you know how I can have not fixed resolution in a RasterLayer?
>
>
>
> ? B)I also need some help regarding grf()
>
> According to the geoR short manual grf() takes the following arguments
>
>
>
> ? ?* n number of points (spatial locations) in each simulations.
> ? ?* grid optional. An n ? 2 matrix with coordinates of the simulated data.
> ? ?* nx optional. Number of points in the X direction.
> ? ?* ny optional. Number of points in the Y direction.
>
> What I want to create is a matrix (at least this is a matlab in matrix) that
> contains values created from grf(). The array is of dimensions x*y so the grf()
> needs to create a x*y map.
>
> If you see the parameters again you will notice that there is a n (n number of
> points) and nx and ny also.
>
> If I put nx=400 and ny=200 (this is just an example) the grf() will return
> values for 400 cells (for some reason picks the highest values of nx and ny). If
> I try something like n=x*y I get the message that the RandomField package must
> be used. Really do you what the parameter n is about (number of points))?
>
> I would like to thank you in advance for your help
>
> Best Regards
> Alex.
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From kerryr at sccwrp.org  Mon Aug  2 22:25:23 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Mon, 02 Aug 2010 13:25:23 -0700
Subject: [R-sig-Geo] quick question re: fit.variogram in gstat
Message-ID: <4C5729B3.1050304@sccwrp.org>

Hi all. I have what I hope is a quick question concerning the use of 
"fit.variogram" in"gstat".  If you assume a a Spherical model for the 
variogram and the estimated range is say 200m and then you switch models 
to a Gaussian but want to keep the range fixed at 200m, would you 
specify 200 for the range parameter or 200/sqrt(3)?

Thanks,
Kerry

**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From jianfeng.mao at gmail.com  Tue Aug  3 10:43:04 2010
From: jianfeng.mao at gmail.com (Mao Jianfeng)
Date: Tue, 3 Aug 2010 16:43:04 +0800
Subject: [R-sig-Geo] how to do randomly sampling in raster layer
Message-ID: <AANLkTi=UrTwNpsf+_qN4Us_qQauxNST1vsy47DJqYDiT@mail.gmail.com>

Dear r-sig-geoers,

I want to randomly sample n points from regions of a raster layers,
the cells denoted as "NA" is not
included in this sampling process. And, I want to got the longitude
and latitude of the sampled points.

I checked the manual of raster package, I found several functions is
relative to my purpose. I tried them all, but I failed.

Can it can be done by raster functionalities. Could you please refer
me to the right direction?

I expect to hearing from you. Your helps are very valuable for a
Chinese who can not reach helps nearby.

Best,

Sincerely,
Mao Jian-Feng


From caspar.hallmann at gmail.com  Tue Aug  3 11:15:55 2010
From: caspar.hallmann at gmail.com (caspar hallmann)
Date: Tue, 3 Aug 2010 11:15:55 +0200
Subject: [R-sig-Geo] how to do randomly sampling in raster layer
In-Reply-To: <AANLkTi=UrTwNpsf+_qN4Us_qQauxNST1vsy47DJqYDiT@mail.gmail.com>
References: <AANLkTi=UrTwNpsf+_qN4Us_qQauxNST1vsy47DJqYDiT@mail.gmail.com>
Message-ID: <AANLkTikAs=MVXA4GLGm2iF1Opzmf1xc3JPQaPh+6A-rH@mail.gmail.com>

Dear Mao,

You can use function rpoint from spatstat, after converting your
raster object into a pixel image.

consider the following:

library(raster)
library(spatstat)
library(maptools)
library(sp)

# An arbitrary raster
r <- raster(system.file("external/test.grd", package="raster"))
# plot it
image(r)

# convert to SpatialGridDataFrame
r.spgrd<-as(r,"SpatialGridDataFrame")
r.spgrd$constant<-ifelse(is.na(r.spgrd[[1]]),NA,1)
# ...this to ensure an equal weight to each non-NA cell

# convert to im
r.im<-as.im(r.spgrd["constant"])

# sample points according to constant
r.points<-rpoint(100,r.im)

# plot the random points
points(r.points)

#..to get the coordinates
as.data.frame(r.points)

Good Luck!
Caspar


On Tue, Aug 3, 2010 at 10:43 AM, Mao Jianfeng <jianfeng.mao at gmail.com> wrote:
> Dear r-sig-geoers,
>
> I want to randomly sample n points from regions of a raster layers,
> the cells denoted as "NA" is not
> included in this sampling process. And, I want to got the longitude
> and latitude of the sampled points.
>
> I checked the manual of raster package, I found several functions is
> relative to my purpose. I tried them all, but I failed.
>
> Can it can be done by raster functionalities. Could you please refer
> me to the right direction?
>
> I expect to hearing from you. Your helps are very valuable for a
> Chinese who can not reach helps nearby.
>
> Best,
>
> Sincerely,
> Mao Jian-Feng
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jacobvanetten at yahoo.com  Tue Aug  3 11:53:17 2010
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Tue, 3 Aug 2010 09:53:17 +0000 (GMT)
Subject: [R-sig-Geo] how to do randomly sampling in raster layer
In-Reply-To: <AANLkTikAs=MVXA4GLGm2iF1Opzmf1xc3JPQaPh+6A-rH@mail.gmail.com>
Message-ID: <121156.54465.qm@web29705.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100803/279b8bad/attachment.pl>

From p.hiemstra at geo.uu.nl  Tue Aug  3 11:51:55 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 03 Aug 2010 11:51:55 +0200
Subject: [R-sig-Geo] how to do randomly sampling in raster layer
In-Reply-To: <AANLkTikAs=MVXA4GLGm2iF1Opzmf1xc3JPQaPh+6A-rH@mail.gmail.com>
References: <AANLkTi=UrTwNpsf+_qN4Us_qQauxNST1vsy47DJqYDiT@mail.gmail.com>
	<AANLkTikAs=MVXA4GLGm2iF1Opzmf1xc3JPQaPh+6A-rH@mail.gmail.com>
Message-ID: <4C57E6BB.5000907@geo.uu.nl>

On 08/03/2010 11:15 AM, caspar hallmann wrote:
> Dear Mao,
>
> You can use function rpoint from spatstat, after converting your
> raster object into a pixel image.
>
> consider the following:
>
> library(raster)
> library(spatstat)
> library(maptools)
> library(sp)
>
> # An arbitrary raster
> r<- raster(system.file("external/test.grd", package="raster"))
> # plot it
> image(r)
>
> # convert to SpatialGridDataFrame
> r.spgrd<-as(r,"SpatialGridDataFrame")
>    
I would consider converting it to SpatialPointsDF instead.

r.spgrd<-as(r,"SpatialPointsDataFrame")

Now you can eliminate the NA value:

r.spgrd = r.spgrd[!is.na(r.spgrd[[1]]),]

In stead of rpoint you can also use sample:

selectedPoints = sample(1:length(r.spgrd[[1]]), 1000)
r.sampled = r.spgrd[selectedPoints,]

cheers,
Paul
> r.spgrd$constant<-ifelse(is.na(r.spgrd[[1]]),NA,1)
> # ...this to ensure an equal weight to each non-NA cell
>
> # convert to im
> r.im<-as.im(r.spgrd["constant"])
>
> # sample points according to constant
> r.points<-rpoint(100,r.im)
>
> # plot the random points
> points(r.points)
>
> #..to get the coordinates
> as.data.frame(r.points)
>
> Good Luck!
> Caspar
>
>
> On Tue, Aug 3, 2010 at 10:43 AM, Mao Jianfeng<jianfeng.mao at gmail.com>  wrote:
>    
>> Dear r-sig-geoers,
>>
>> I want to randomly sample n points from regions of a raster layers,
>> the cells denoted as "NA" is not
>> included in this sampling process. And, I want to got the longitude
>> and latitude of the sampled points.
>>
>> I checked the manual of raster package, I found several functions is
>> relative to my purpose. I tried them all, but I failed.
>>
>> Can it can be done by raster functionalities. Could you please refer
>> me to the right direction?
>>
>> I expect to hearing from you. Your helps are very valuable for a
>> Chinese who can not reach helps nearby.
>>
>> Best,
>>
>> Sincerely,
>> Mao Jian-Feng
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>      
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From ssefick at gmail.com  Tue Aug  3 14:19:11 2010
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 3 Aug 2010 07:19:11 -0500
Subject: [R-sig-Geo] SpatialPointsDataFrame into GRASS problems
Message-ID: <AANLkTing5jLK7mfphNpctLEKK_tKc4_t58fMaUNh5nGh@mail.gmail.com>

I am new to sp objects and this seems more convienint than qgis ->
shapefile -> import into GRASS.  I am having a problem getting the
data from a spatial points dataframe into grass.  Below is the code.
Any help would be appreciated.

z <- (dput(ftbr_UTM)
structure(list(site = c("Jennie_Creek_Main_Stem", "Jennie_Creek_Main_Stem",
"Wolf_Pit_Creek_Main_Stem", "Wolf_Pit_Creek_Main_Stem",
"Little_Rockfish_Main_Stem_North",
"Little_Rockfish_Main_Stem_North", "Big_Muddy_Creek_Main_Stem",
"Big_Muddy_Creek_Main_Stem", "Flat_Creek_Main_Stem", "Flat_Creek_Main_Stem",
"little_river_tributary", "little_river_tributary", "Hector_Creek_Main_Stem",
"Hector_Creek_Main_Stem", "Juniper_Creek_Main_Stem", "Juniper_Creek_Main_Stem",
"Field_Branch_Main_Stem", "Field_Branch_Main_Stem", "Gum_Branch_Main_Stem",
"Gum_Branch_Main_Stem"), base = c("ftbr", "ftbr", "ftbr", "ftbr",
"ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr",
"ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr"
), creek = c("jcms", "jcms", "wpms", "wpms", "lrf1", "lrf1",
"bmcm", "bmcm", "fcms", "fcms", "lrtb", "lrtb", "hcms", "hcms",
"jpms", "jpms", "fbms", "fbms", "gbms", "gbms"), date = c("06/20/2010",
"06/20/2010", "06/20/2010", "06/20/2010", "06/18/2010", "06/18/2010",
"06/18/2010", "06/18/2010", "06/21/2010", "06/21/2010", "06/22/2010",
"06/22/2010", "06/22/2010", "06/22/2010", "06/21/2010", "06/21/2010",
"06/19/2010", "06/19/2010", "06/19/2010", "06/19/2010"), elevation_m = c(101,
101, 81, 81, 59, 59, 75, 75, 73, 73, 55, 55, 55, 55, 88, 88,
77, 77, 87, 87), x = c(652159, 652040, 651646, 651533, 674147,
674116, 635466, 635326, 665726, 665676, 675295, 675362, 673098,
673159, 658917, 658918, 655613, 655464, 651748, 651553), y = c(3887647,
3887758, 3886986, 3886870, 3893724, 3893581, 3876272, 3876145,
3893886, 3893742, 3895529, 3895663, 3895076, 3895261, 3882474,
3882663, 3881587, 3881591, 3884249, 3884280), station = c(1,
6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6), notes_ = c(NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA)), .Names = c("site", "base", "creek", "date", "elevation_m",
"x", "y", "station", "notes_"), class = "data.frame", row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16", "17", "18", "19", "20")))


utm2points <- function(data, x_coord="x", y_coord="y", coord_string=NULL){

#utm 17
#+proj=utm +zone=17 +ellps=GRS80 +units=m +no_defs

#utm 16
#+proj=utm +zone=16 +ellps=GRS80 +units=m +no_defs

require(rgdal)

#get x y
coord <- c(x_coord, y_coord)
x_y <- data[,charmatch(coord, colnames(data))]

#get everything else
dater <- data[,-charmatch(coord, colnames(data))]

#make Spatial Data Frame
Point_vector <- SpatialPointsDataFrame(x_y, dater, proj4string =
CRS(coord_string))
return(Point_vector)
}


z <- utm2points(ftbr_UTM, coord_string="+proj=utm +zone=17
+ellps=GRS80 +units=m +no_defs")


#and then I try to import this into GRASS with

writeVECT6(z, "ftbr_2010_sampling_points")

#and get the following error

Error in writeOGR(SDF, dsn = rtmpfl1, layer = shname, driver = "ESRI
Shapefile") :

	GDAL Error 1: Invalid index : -1
In addition: Warning message:
In writeOGR(SDF, dsn = rtmpfl1, layer = shname, driver = "ESRI Shapefile") :

	Non-fatal GDAL Error 6: Normalized/laundered field name:
'elevation_m' to 'elevation_'




-- 
Stephen Sefick
____________________________________
| Auburn University? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? |
| Department of Biological Sciences? ? ? ? ?? |
| 331 Funchess Hall? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? |
| Auburn, Alabama? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? |
| 36849? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? |
|___________________________________|
| sas0025 at auburn.edu? ? ? ? ? ? ? ? ? ? ? ? ? ?? |
| http://www.auburn.edu/~sas0025? ? ? ? ? ?? |
|___________________________________|

Let's not spend our time and resources thinking about things that are
so little or so large that all they really do for us is puff us up and
make us feel like gods.? We are mammals, and have not exhausted the
annoying little problems of being mammals.

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -K. Mullis


From Roger.Bivand at nhh.no  Tue Aug  3 14:34:27 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Aug 2010 14:34:27 +0200 (CEST)
Subject: [R-sig-Geo] SpatialPointsDataFrame into GRASS problems
In-Reply-To: <AANLkTing5jLK7mfphNpctLEKK_tKc4_t58fMaUNh5nGh@mail.gmail.com>
References: <AANLkTing5jLK7mfphNpctLEKK_tKc4_t58fMaUNh5nGh@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008031430150.12380@reclus.nhh.no>

On Tue, 3 Aug 2010, stephen sefick wrote:

> I am new to sp objects and this seems more convienint than qgis ->
> shapefile -> import into GRASS.  I am having a problem getting the
> data from a spatial points dataframe into grass.  Below is the code.
> Any help would be appreciated.

Please provide the data as an RData file, not as a broken dput. Please 
provide this (and your code, simplified if possible - there may be other 
problems in creating the SpatialPointsDataFrame) on a web server if 
possible. Please also indicate how your GRASS location is defined (output 
of gmeta6() for example).

Note that the OGR Shapefile driver does not permit variable names of over 
10-11 characters.

Roger

>
> z <- (dput(ftbr_UTM)
> structure(list(site = c("Jennie_Creek_Main_Stem", "Jennie_Creek_Main_Stem",
> "Wolf_Pit_Creek_Main_Stem", "Wolf_Pit_Creek_Main_Stem",
> "Little_Rockfish_Main_Stem_North",
> "Little_Rockfish_Main_Stem_North", "Big_Muddy_Creek_Main_Stem",
> "Big_Muddy_Creek_Main_Stem", "Flat_Creek_Main_Stem", "Flat_Creek_Main_Stem",
> "little_river_tributary", "little_river_tributary", "Hector_Creek_Main_Stem",
> "Hector_Creek_Main_Stem", "Juniper_Creek_Main_Stem", "Juniper_Creek_Main_Stem",
> "Field_Branch_Main_Stem", "Field_Branch_Main_Stem", "Gum_Branch_Main_Stem",
> "Gum_Branch_Main_Stem"), base = c("ftbr", "ftbr", "ftbr", "ftbr",
> "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr",
> "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr", "ftbr"
> ), creek = c("jcms", "jcms", "wpms", "wpms", "lrf1", "lrf1",
> "bmcm", "bmcm", "fcms", "fcms", "lrtb", "lrtb", "hcms", "hcms",
> "jpms", "jpms", "fbms", "fbms", "gbms", "gbms"), date = c("06/20/2010",
> "06/20/2010", "06/20/2010", "06/20/2010", "06/18/2010", "06/18/2010",
> "06/18/2010", "06/18/2010", "06/21/2010", "06/21/2010", "06/22/2010",
> "06/22/2010", "06/22/2010", "06/22/2010", "06/21/2010", "06/21/2010",
> "06/19/2010", "06/19/2010", "06/19/2010", "06/19/2010"), elevation_m = c(101,
> 101, 81, 81, 59, 59, 75, 75, 73, 73, 55, 55, 55, 55, 88, 88,
> 77, 77, 87, 87), x = c(652159, 652040, 651646, 651533, 674147,
> 674116, 635466, 635326, 665726, 665676, 675295, 675362, 673098,
> 673159, 658917, 658918, 655613, 655464, 651748, 651553), y = c(3887647,
> 3887758, 3886986, 3886870, 3893724, 3893581, 3876272, 3876145,
> 3893886, 3893742, 3895529, 3895663, 3895076, 3895261, 3882474,
> 3882663, 3881587, 3881591, 3884249, 3884280), station = c(1,
> 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6), notes_ = c(NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA)), .Names = c("site", "base", "creek", "date", "elevation_m",
> "x", "y", "station", "notes_"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
> "14", "15", "16", "17", "18", "19", "20")))
>
>
> utm2points <- function(data, x_coord="x", y_coord="y", coord_string=NULL){
>
> #utm 17
> #+proj=utm +zone=17 +ellps=GRS80 +units=m +no_defs
>
> #utm 16
> #+proj=utm +zone=16 +ellps=GRS80 +units=m +no_defs
>
> require(rgdal)
>
> #get x y
> coord <- c(x_coord, y_coord)
> x_y <- data[,charmatch(coord, colnames(data))]
>
> #get everything else
> dater <- data[,-charmatch(coord, colnames(data))]
>
> #make Spatial Data Frame
> Point_vector <- SpatialPointsDataFrame(x_y, dater, proj4string =
> CRS(coord_string))
> return(Point_vector)
> }
>
>
> z <- utm2points(ftbr_UTM, coord_string="+proj=utm +zone=17
> +ellps=GRS80 +units=m +no_defs")
>
>
> #and then I try to import this into GRASS with
>
> writeVECT6(z, "ftbr_2010_sampling_points")
>
> #and get the following error
>
> Error in writeOGR(SDF, dsn = rtmpfl1, layer = shname, driver = "ESRI
> Shapefile") :
>
> 	GDAL Error 1: Invalid index : -1
> In addition: Warning message:
> In writeOGR(SDF, dsn = rtmpfl1, layer = shname, driver = "ESRI Shapefile") :
>
> 	Non-fatal GDAL Error 6: Normalized/laundered field name:
> 'elevation_m' to 'elevation_'
>
>
>
>
> -- 
> Stephen Sefick
> ____________________________________
> | Auburn University? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? |
> | Department of Biological Sciences? ? ? ? ?? |
> | 331 Funchess Hall? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? |
> | Auburn, Alabama? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?? |
> | 36849? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? |
> |___________________________________|
> | sas0025 at auburn.edu? ? ? ? ? ? ? ? ? ? ? ? ? ?? |
> | http://www.auburn.edu/~sas0025? ? ? ? ? ?? |
> |___________________________________|
>
> Let's not spend our time and resources thinking about things that are
> so little or so large that all they really do for us is puff us up and
> make us feel like gods.? We are mammals, and have not exhausted the
> annoying little problems of being mammals.
>
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -K. Mullis
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From r.hijmans at gmail.com  Tue Aug  3 18:55:03 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 3 Aug 2010 09:55:03 -0700
Subject: [R-sig-Geo] how to do randomly sampling in raster layer
In-Reply-To: <4C57E6BB.5000907@geo.uu.nl>
References: <AANLkTi=UrTwNpsf+_qN4Us_qQauxNST1vsy47DJqYDiT@mail.gmail.com>
	<AANLkTikAs=MVXA4GLGm2iF1Opzmf1xc3JPQaPh+6A-rH@mail.gmail.com>
	<4C57E6BB.5000907@geo.uu.nl>
Message-ID: <AANLkTim6MUWWSMA_C6W7Zizhag4-kphY8+Mf569fZ7dM@mail.gmail.com>

Dear Mao,

If r is a RasterLayer, you can also do

library(dismo)
xy <- randomPoints(r, n=100)

plot(r)
points(xy)


Best, Robert



On Tue, Aug 3, 2010 at 2:51 AM, Paul Hiemstra <p.hiemstra at geo.uu.nl> wrote:
> On 08/03/2010 11:15 AM, caspar hallmann wrote:
>>
>> Dear Mao,
>>
>> You can use function rpoint from spatstat, after converting your
>> raster object into a pixel image.
>>
>> consider the following:
>>
>> library(raster)
>> library(spatstat)
>> library(maptools)
>> library(sp)
>>
>> # An arbitrary raster
>> r<- raster(system.file("external/test.grd", package="raster"))
>> # plot it
>> image(r)
>>
>> # convert to SpatialGridDataFrame
>> r.spgrd<-as(r,"SpatialGridDataFrame")
>>
>
> I would consider converting it to SpatialPointsDF instead.
>
> r.spgrd<-as(r,"SpatialPointsDataFrame")
>
> Now you can eliminate the NA value:
>
> r.spgrd = r.spgrd[!is.na(r.spgrd[[1]]),]
>
> In stead of rpoint you can also use sample:
>
> selectedPoints = sample(1:length(r.spgrd[[1]]), 1000)
> r.sampled = r.spgrd[selectedPoints,]
>
> cheers,
> Paul
>>
>> r.spgrd$constant<-ifelse(is.na(r.spgrd[[1]]),NA,1)
>> # ...this to ensure an equal weight to each non-NA cell
>>
>> # convert to im
>> r.im<-as.im(r.spgrd["constant"])
>>
>> # sample points according to constant
>> r.points<-rpoint(100,r.im)
>>
>> # plot the random points
>> points(r.points)
>>
>> #..to get the coordinates
>> as.data.frame(r.points)
>>
>> Good Luck!
>> Caspar
>>
>>
>> On Tue, Aug 3, 2010 at 10:43 AM, Mao Jianfeng<jianfeng.mao at gmail.com>
>> ?wrote:
>>
>>>
>>> Dear r-sig-geoers,
>>>
>>> I want to randomly sample n points from regions of a raster layers,
>>> the cells denoted as "NA" is not
>>> included in this sampling process. And, I want to got the longitude
>>> and latitude of the sampled points.
>>>
>>> I checked the manual of raster package, I found several functions is
>>> relative to my purpose. I tried them all, but I failed.
>>>
>>> Can it can be done by raster functionalities. Could you please refer
>>> me to the right direction?
>>>
>>> I expect to hearing from you. Your helps are very valuable for a
>>> Chinese who can not reach helps nearby.
>>>
>>> Best,
>>>
>>> Sincerely,
>>> Mao Jian-Feng
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
> --
> Drs. Paul Hiemstra
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone: ?+3130 253 5773
> http://intamap.geo.uu.nl/~paul
> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From m.fairbrother at bristol.ac.uk  Tue Aug  3 22:48:17 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 3 Aug 2010 21:48:17 +0100
Subject: [R-sig-Geo] suppressing axes/border/box when using spplot?
Message-ID: <B20D29FA-7A1E-47E8-92BA-F32151668AEB@bristol.ac.uk>

Dear all,

I'm fairly new to the spatial functions in R, and have a simple question for which my archive searches have not turned up an answer.

When plotting using spplot, how can I suppress a "box" from appearing around the plot? (Maybe I should instead be calling it the border, or the axes.)

Using just "plot", I'm talking about the difference between "plot(1:10)" and "plot(1:10, axes=F)".

Many thanks in advance for any help anyone can offer.
- Malcolm


> sessionInfo()
R version 2.9.2 (2009-08-24) 
x86_64-apple-darwin9.8.0 

locale:
en_GB.UTF-8/en_GB.UTF-8/C/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RColorBrewer_1.0-2 sp_0.9-44          lpSolve_5.6.4     Matrix_0.999375-31 lattice_0.17-26   

loaded via a namespace (and not attached):
[1] grid_2.9.2  tools_2.9.2


From gblanchet.list at gmail.com  Tue Aug  3 22:57:11 2010
From: gblanchet.list at gmail.com (Guillaume Blanchet)
Date: Tue, 03 Aug 2010 14:57:11 -0600
Subject: [R-sig-Geo] Automatically count independent group of points
Message-ID: <4C5882A7.6010009@gmail.com>

  Hi !

I am currently working on a wombling (boundary detection) function and I 
have come across a nag. Hopefully you will be able to give me a hand on 
this.

Following is a small example to explain what I want to do using the 
spdep package.

xy<-expand.grid(1:4,1:2)
nbobj<-cell2nb(4,2,"rook")

links<-listw2sn(nb2listw(nbobj))
links.new<-links[-c(4,6,15,17),]

nbobj.new<-sn2listw(links.new)$neighbours

plot(nbobj.new,xy)

"nbobj.new" has two separate groups of points links between each other. 
Is there a way to automatically counts the number of independent 
(non-linked) groups of sites ?

Thanks in advance !

Guillaume Blanchet


From nikhil.list at gmail.com  Wed Aug  4 05:34:25 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Tue, 3 Aug 2010 23:34:25 -0400
Subject: [R-sig-Geo] Automatically count independent group of points
In-Reply-To: <4C5882A7.6010009@gmail.com>
References: <4C5882A7.6010009@gmail.com>
Message-ID: <1363B05C-F35C-4253-A436-C48FB88A12D4@gmail.com>


This may be a overkill. but no.clusters in igraph package might work.

require(igraph)
nbobj <- cell2nb(4,2,"rook")
nb.mat <- nb2mat(nbobj)
no.clusters(graph.adjacency(nb.mat))


Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 3, 2010, at 4:57 PM, Guillaume Blanchet wrote:

> Hi !
>
> I am currently working on a wombling (boundary detection) function  
> and I have come across a nag. Hopefully you will be able to give me  
> a hand on this.
>
> Following is a small example to explain what I want to do using the  
> spdep package.
>
> xy<-expand.grid(1:4,1:2)
> nbobj<-cell2nb(4,2,"rook")
>
> links<-listw2sn(nb2listw(nbobj))
> links.new<-links[-c(4,6,15,17),]
>
> nbobj.new<-sn2listw(links.new)$neighbours
>
> plot(nbobj.new,xy)
>
> "nbobj.new" has two separate groups of points links between each  
> other. Is there a way to automatically counts the number of  
> independent (non-linked) groups of sites ?
>
> Thanks in advance !
>
> Guillaume Blanchet
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sjmyers at syr.edu  Wed Aug  4 05:57:41 2010
From: sjmyers at syr.edu (Seth J Myers)
Date: Wed, 4 Aug 2010 03:57:41 +0000
Subject: [R-sig-Geo] computing the hat matrix for gwr in spgwr?
Message-ID: <266CBFBFD14254478D52158AE6BF90171033E31B@BL2PRD0103MB038.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100804/6fd33a93/attachment.pl>

From sjmyers at syr.edu  Wed Aug  4 06:20:04 2010
From: sjmyers at syr.edu (Seth J Myers)
Date: Wed, 4 Aug 2010 04:20:04 +0000
Subject: [R-sig-Geo] regarding hat matrix of gwr question
Message-ID: <266CBFBFD14254478D52158AE6BF90171033E327@BL2PRD0103MB038.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100804/25038356/attachment.pl>

From nikhil.list at gmail.com  Wed Aug  4 12:27:44 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 4 Aug 2010 06:27:44 -0400
Subject: [R-sig-Geo] plot overlay two spatialpolygons.
Message-ID: <D7FE4D12-9FCA-4B56-8458-24FA1E30586F@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100804/0428e223/attachment.pl>

From mdsumner at gmail.com  Wed Aug  4 12:35:56 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 4 Aug 2010 20:35:56 +1000
Subject: [R-sig-Geo] plot overlay two spatialpolygons.
In-Reply-To: <D7FE4D12-9FCA-4B56-8458-24FA1E30586F@gmail.com>
References: <D7FE4D12-9FCA-4B56-8458-24FA1E30586F@gmail.com>
Message-ID: <AANLkTim7COc1nRmzMxymjMJ+7bMLzNtjEL3cCbcaSnXZ@mail.gmail.com>

Try add = TRUE with the second plot:

library(sp)
## plot of SpatialPolygonsDataFrame, using grey shades
library(maptools)
nc1 <- readShapePoly(system.file("shapes/sids.shp", package="maptools")
[1], proj4string=CRS("+proj=longlat +datum=NAD27"))
names(nc1)
rrt <- nc1$SID74/nc1$BIR74
brks <- quantile(rrt, seq(0,1,1/7))
cols <- grey((length(brks):2)/length(brks))
dens <- (2:length(brks))*3
plot(nc1, col=cols[findInterval(rrt, brks, all.inside=TRUE)])


## plot of SpatialPolygonsDataFrame, using line densities

nc <- readShapePoly(system.file("shapes/sids.shp", package="maptools")
[1], proj4string=CRS("+proj=longlat +datum=NAD27"))
names(nc)
rrt <- nc$SID74/nc$BIR74
brks <- quantile(rrt, seq(0,1,1/7))
cols <- grey((length(brks):2)/length(brks))
dens <- (2:length(brks))*3
plot(nc, density=dens[findInterval(rrt, brks, all.inside=TRUE)], add = TRUE)


On Wed, Aug 4, 2010 at 8:27 PM, Nikhil Kaza <nikhil.list at gmail.com> wrote:
> How can I overlay two spatialpolygons and plot them? The following
> produces two maps since a new plot is called. I understand that if it
> is any other type, we can simply call lines or points and overlay them
> on polygons.
>
> e.g.
> library(sp)
>
> ## plot of SpatialPolygonsDataFrame, using grey shades
> library(maptools)
> nc1 <- readShapePoly(system.file("shapes/sids.shp", package="maptools")
> [1], proj4string=CRS("+proj=longlat +datum=NAD27"))
> names(nc1)
> rrt <- nc1$SID74/nc1$BIR74
> brks <- quantile(rrt, seq(0,1,1/7))
> cols <- grey((length(brks):2)/length(brks))
> dens <- (2:length(brks))*3
> plot(nc1, col=cols[findInterval(rrt, brks, all.inside=TRUE)])
>
> library(sp)
>
> ## plot of SpatialPolygonsDataFrame, using line densities
> library(maptools)
> nc <- readShapePoly(system.file("shapes/sids.shp", package="maptools")
> [1], proj4string=CRS("+proj=longlat +datum=NAD27"))
> names(nc)
> rrt <- nc$SID74/nc$BIR74
> brks <- quantile(rrt, seq(0,1,1/7))
> cols <- grey((length(brks):2)/length(brks))
> dens <- (2:length(brks))*3
> plot(nc, density=dens[findInterval(rrt, brks, all.inside=TRUE)])
>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From gblanchet.list at gmail.com  Wed Aug  4 15:59:13 2010
From: gblanchet.list at gmail.com (Guillaume Blanchet)
Date: Wed, 04 Aug 2010 07:59:13 -0600
Subject: [R-sig-Geo] Automatically count independent group of points
In-Reply-To: <1363B05C-F35C-4253-A436-C48FB88A12D4@gmail.com>
References: <4C5882A7.6010009@gmail.com>
	<1363B05C-F35C-4253-A436-C48FB88A12D4@gmail.com>
Message-ID: <4C597231.30709@gmail.com>

  Thanks Nikhil !!

That is solving my problem !!

Have a good day !

Guillaume Blanchet

Le 10-08-03 21:34, Nikhil Kaza a ?crit :
>
> This may be a overkill. but no.clusters in igraph package might work.
>
> require(igraph)
> nbobj <- cell2nb(4,2,"rook")
> nb.mat <- nb2mat(nbobj)
> no.clusters(graph.adjacency(nb.mat))
>
>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
> On Aug 3, 2010, at 4:57 PM, Guillaume Blanchet wrote:
>
>> Hi !
>>
>> I am currently working on a wombling (boundary detection) function 
>> and I have come across a nag. Hopefully you will be able to give me a 
>> hand on this.
>>
>> Following is a small example to explain what I want to do using the 
>> spdep package.
>>
>> xy<-expand.grid(1:4,1:2)
>> nbobj<-cell2nb(4,2,"rook")
>>
>> links<-listw2sn(nb2listw(nbobj))
>> links.new<-links[-c(4,6,15,17),]
>>
>> nbobj.new<-sn2listw(links.new)$neighbours
>>
>> plot(nbobj.new,xy)
>>
>> "nbobj.new" has two separate groups of points links between each 
>> other. Is there a way to automatically counts the number of 
>> independent (non-linked) groups of sites ?
>>
>> Thanks in advance !
>>
>> Guillaume Blanchet
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From Roger.Bivand at nhh.no  Wed Aug  4 16:08:52 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Aug 2010 16:08:52 +0200 (CEST)
Subject: [R-sig-Geo] Automatically count independent group of points
In-Reply-To: <4C597231.30709@gmail.com>
References: <4C5882A7.6010009@gmail.com>
	<1363B05C-F35C-4253-A436-C48FB88A12D4@gmail.com>
	<4C597231.30709@gmail.com>
Message-ID: <alpine.LRH.2.00.1008041607360.19229@reclus.nhh.no>

On Wed, 4 Aug 2010, Guillaume Blanchet wrote:

>
> Thanks Nikhil !!
>
> That is solving my problem !!

Maybe n.comp.nb() in spdep? This returns the number of clusters and 
cluster IDs for the observations, in your case:

> n.comp.nb(nbobj.new)
$nc
[1] 2

$comp.id
[1] 1 1 2 2 1 1 2 2

Hope this helps,

Roger


>
> Have a good day !
>
> Guillaume Blanchet
>
> Le 10-08-03 21:34, Nikhil Kaza a ?crit :
>> 
>> This may be a overkill. but no.clusters in igraph package might work.
>> 
>> require(igraph)
>> nbobj <- cell2nb(4,2,"rook")
>> nb.mat <- nb2mat(nbobj)
>> no.clusters(graph.adjacency(nb.mat))
>> 
>> 
>> Nikhil Kaza
>> Asst. Professor,
>> City and Regional Planning
>> University of North Carolina
>> 
>> nikhil.list at gmail.com
>> 
>> On Aug 3, 2010, at 4:57 PM, Guillaume Blanchet wrote:
>> 
>>> Hi !
>>> 
>>> I am currently working on a wombling (boundary detection) function and I 
>>> have come across a nag. Hopefully you will be able to give me a hand on 
>>> this.
>>> 
>>> Following is a small example to explain what I want to do using the spdep 
>>> package.
>>> 
>>> xy<-expand.grid(1:4,1:2)
>>> nbobj<-cell2nb(4,2,"rook")
>>> 
>>> links<-listw2sn(nb2listw(nbobj))
>>> links.new<-links[-c(4,6,15,17),]
>>> 
>>> nbobj.new<-sn2listw(links.new)$neighbours
>>> 
>>> plot(nbobj.new,xy)
>>> 
>>> "nbobj.new" has two separate groups of points links between each other. Is 
>>> there a way to automatically counts the number of independent (non-linked) 
>>> groups of sites ?
>>> 
>>> Thanks in advance !
>>> 
>>> Guillaume Blanchet
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Wed Aug  4 16:49:58 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Aug 2010 16:49:58 +0200 (CEST)
Subject: [R-sig-Geo] computing the hat matrix for gwr in spgwr?
In-Reply-To: <266CBFBFD14254478D52158AE6BF90171033E31B@BL2PRD0103MB038.prod.exchangelabs.com>
References: <266CBFBFD14254478D52158AE6BF90171033E31B@BL2PRD0103MB038.prod.exchangelabs.com>
Message-ID: <alpine.LRH.2.00.1008041648200.19229@reclus.nhh.no>

On Wed, 4 Aug 2010, Seth J Myers wrote:

> Hi,
>
> I'm trying to calculate the hat matrix for gwr by hand using matrix 
> manipulation in R.  The hope is that once I get it to match the output 
> that gwr gives, I can do the matrix algebra row-/column-wise.  This will 
> allow me to estimate the effective number of parameter using the trace 
> of the hat matrix on a data set that is too large to do this using the 
> computer resources I have using gwr as is.  The first row of the hat 
> matrix described on page 55 of fotheringham et als gwr book.  It is the 
> hat matrix multiplied by a distance-based weighting function.  The code 
> below returns 4.661219 for the trace while gwr returns 3.400793. 
> Anything jump out to anyone?  Thanks, Seth Myers

w[j,j] <- exp((-0.5) * ((dist/bw)^2)) matches gwr.Gauss()
w[j,j]<-exp(-((dist/bw)^2)) matches gwr.gauss()

gwr.Gauss() became default from spgwr 0.5. Otherwise OK.

Hope this helps,

Roger

>
> library(spgwr)
> data(columbus)
> bw=10
> crime.gwr<-gwr(crime~income, data=columbus, coords=cbind(columbus$x,columbus$y), bandwidth=bw,gweight=gwr.Gauss,longlat=FALSE,hatmatrix=TRUE)
> v1.gwr<-crime.gwr$results$v1 #what I am trying to calculate by hand, the trace of the S (or hat) matrix)
> xmat<-mat.or.vec(nrow(columbus),2)
> coor<-mat.or.vec(nrow(columbus),2)
> xmat[ ,1]<-1
> xmat[ ,2]<-columbus$income
> coor[ ,1]<-columbus$x
> coor[ ,2]<-columbus$y
> #creating matrices for use in following loops
> xtw<-mat.or.vec(2,nrow(columbus))
> w<-mat.or.vec(nrow(columbus),nrow(columbus))
> xrow<-mat.or.vec(1,2)
> smat<-mat.or.vec(nrow(columbus),nrow(columbus))
> for (i in 1:nrow(columbus)){
> print(i)
> for (j in 1:nrow(columbus)){
> dist<-( (coor[i,1]-coor[j,1])^2 + (coor[i,2]-coor[j,2])^2)^.5 #finding distances between observations
> w[j,j]<-exp(-((dist/bw)^2))#computing weight matrix for observation i
> }
> xtw<-t(xmat)%*%w #finding crossproduct of transpose of x matrix and w matrix
> xtwx<-xtw%*%xmat #finding crossproduct of above and x matrix
>
> xtwx.inv<-solve(xtwx) #finding inverse of above
>
> xrow<-xmat[i, ] #getting row i of x matrix
> x.xtwx.inv<-xrow%*%xtwx.inv # crossproduct of above and inverse of xtwx
> temp<-x.xtwx.inv%*%xtw #crossproduct of above and xtw
> smat[i, ]<-temp#populate row i of S matrix
> }
> mytry<-sum(diag(smat))#my try at calculating the trace of the S (or hat) matrix
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From patrick.giraudoux at univ-fcomte.fr  Thu Aug  5 10:02:33 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 05 Aug 2010 10:02:33 +0200
Subject: [R-sig-Geo] image, SpatialGridDataFrame, transparency
In-Reply-To: <mailman.9.1280829602.16587.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1280829602.16587.r-sig-geo@stat.math.ethz.ch>
Message-ID: <4C5A7019.50802@univ-fcomte.fr>

Hi,

I was wondering if it is possible to manage color transparency with 
image.SpatialGridDataFrame ? Eg to export png that could be imported 
into Google Earth in the way indicated in Bivand et al. pp 97-98 
(functions kmlOverlay and GE_SpatialGrid of maptools). If yes how ?

Patrick


From Roger.Bivand at nhh.no  Thu Aug  5 11:59:57 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Aug 2010 11:59:57 +0200 (CEST)
Subject: [R-sig-Geo] image, SpatialGridDataFrame, transparency
In-Reply-To: <4C5A7019.50802@univ-fcomte.fr>
References: <mailman.9.1280829602.16587.r-sig-geo@stat.math.ethz.ch>
	<4C5A7019.50802@univ-fcomte.fr>
Message-ID: <alpine.LRH.2.00.1008051146290.22382@reclus.nhh.no>

On Thu, 5 Aug 2010, Patrick Giraudoux wrote:

> Hi,
>
> I was wondering if it is possible to manage color transparency with 
> image.SpatialGridDataFrame ? Eg to export png that could be imported into 
> Google Earth in the way indicated in Bivand et al. pp 97-98 (functions 
> kmlOverlay and GE_SpatialGrid of maptools). If yes how ?

NAs are set transparent by default (on output devices supporting 
transparency). Other values may be given an alpha of less than 1 - here a 
single value for all:

library(sp)
data(meuse.grid)
coordinates(meuse.grid) = c("x", "y")
gridded(meuse.grid) = TRUE
image(meuse.grid["dist"], col=heat.colors(12),
  main = "Distance to river Meuse")
image(meuse.grid["dist"], col=heat.colors(12, alpha=0.5),
  main = "Distance to river Meuse")

By setting the col= vector manually, it is possible to assign a different 
alpha value for each element, but it may be difficult to obtain a 
satisfactory visual impression consistently across output devices. See 
col2rgb() and rgb(). See also the colorspace package for a sophisticated 
treatment, and the use of hcl palettes, and the hsv() function. All of 
these can help in constructing a colour vector to pass to 
image.SpatialGridDataFrame().

Hope this helps,

Roger

>
> Patrick
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From patrick.giraudoux at univ-fcomte.fr  Thu Aug  5 12:03:17 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 05 Aug 2010 12:03:17 +0200
Subject: [R-sig-Geo] image, SpatialGridDataFrame, transparency
In-Reply-To: <alpine.LRH.2.00.1008051146290.22382@reclus.nhh.no>
References: <mailman.9.1280829602.16587.r-sig-geo@stat.math.ethz.ch>
	<4C5A7019.50802@univ-fcomte.fr>
	<alpine.LRH.2.00.1008051146290.22382@reclus.nhh.no>
Message-ID: <4C5A8C65.5060802@univ-fcomte.fr>

Great !

Thanks !

Patrick

Roger Bivand a ?crit :
> On Thu, 5 Aug 2010, Patrick Giraudoux wrote:
>
>> Hi,
>>
>> I was wondering if it is possible to manage color transparency with 
>> image.SpatialGridDataFrame ? Eg to export png that could be imported 
>> into Google Earth in the way indicated in Bivand et al. pp 97-98 
>> (functions kmlOverlay and GE_SpatialGrid of maptools). If yes how ?
>
> NAs are set transparent by default (on output devices supporting 
> transparency). Other values may be given an alpha of less than 1 - 
> here a single value for all:
>
> library(sp)
> data(meuse.grid)
> coordinates(meuse.grid) = c("x", "y")
> gridded(meuse.grid) = TRUE
> image(meuse.grid["dist"], col=heat.colors(12),
>  main = "Distance to river Meuse")
> image(meuse.grid["dist"], col=heat.colors(12, alpha=0.5),
>  main = "Distance to river Meuse")
>
> By setting the col= vector manually, it is possible to assign a 
> different alpha value for each element, but it may be difficult to 
> obtain a satisfactory visual impression consistently across output 
> devices. See col2rgb() and rgb(). See also the colorspace package for 
> a sophisticated treatment, and the use of hcl palettes, and the hsv() 
> function. All of these can help in constructing a colour vector to 
> pass to image.SpatialGridDataFrame().
>
> Hope this helps,
>
> Roger
>
>>
>> Patrick
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From blanc.laetitia.esr34 at gmail.com  Thu Aug  5 17:16:34 2010
From: blanc.laetitia.esr34 at gmail.com (Laetitia Blanc)
Date: Thu, 5 Aug 2010 08:16:34 -0700 (PDT)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
Message-ID: <1281021394833-5376909.post@n2.nabble.com>


hi,

i would like to know how to clip a map ("france") that i loaded with the
function readShapePoly. Now, it's a SpatialPolygonsDataFrame. 

I want to clip the map "france" according to specific coordinates in order
to obtain a new map corresponding to a specific part of the original map
(for example the eastern part of France).

Can someone help me ?
thanks
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5376909.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Thu Aug  5 17:55:04 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Aug 2010 17:55:04 +0200 (CEST)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <1281021394833-5376909.post@n2.nabble.com>
References: <1281021394833-5376909.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>

On Thu, 5 Aug 2010, Laetitia Blanc wrote:

>
> hi,
>
> i would like to know how to clip a map ("france") that i loaded with the
> function readShapePoly. Now, it's a SpatialPolygonsDataFrame.
>
> I want to clip the map "france" according to specific coordinates in order
> to obtain a new map corresponding to a specific part of the original map
> (for example the eastern part of France).
>
> Can someone help me ?

The answer is no, you cannot clip such an object in the way you want. You 
can subset to choose (manually) the member Polygons objects in your 
subset, but you cannot change their borders by clipping. Typically, 
clipping for display is done simply by using the xlim= and ylim= arguments 
to plotting functions, and for most cases this is sufficient, because the 
clipped objects are not needed for analysis.

It may be, before long, that you will be able to clip using an object 
describing your clipping window and the input object, using rgeos, now in 
development on R-Forge. The output object will, however, have to be 
without attributes, because the attributes of clipped Polygons objects 
cannot be assumed to be unchanged.

Hope this helps,

Roger

> thanks
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From blanc.laetitia.esr34 at gmail.com  Thu Aug  5 18:06:47 2010
From: blanc.laetitia.esr34 at gmail.com (Laetitia Blanc)
Date: Thu, 5 Aug 2010 09:06:47 -0700 (PDT)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
Message-ID: <1281024407951-5377129.post@n2.nabble.com>


Thank you for your answer...so quick.

i needed to clip my map because i have realised a  Kernel Density Estimation
for successive years. 

I have then animated this KDE. Thus, we can see the evolution of density
estimation running from year to year.

 I wanted to insert a map in the background in order to situate this
analysis. It only concern one part of France so i tried to clip the map in
order to match with the window of the KDE...but it doesn't work.

Do you know how i can have a fixed map and add a KDE animated on it ? 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5377129.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Thu Aug  5 18:17:16 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Aug 2010 18:17:16 +0200 (CEST)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <1281024407951-5377129.post@n2.nabble.com>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
	<1281024407951-5377129.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>

On Thu, 5 Aug 2010, Laetitia Blanc wrote:

>
> Thank you for your answer...so quick.
>
> i needed to clip my map because i have realised a  Kernel Density Estimation
> for successive years.
>
> I have then animated this KDE. Thus, we can see the evolution of density
> estimation running from year to year.
>
> I wanted to insert a map in the background in order to situate this
> analysis. It only concern one part of France so i tried to clip the map in
> order to match with the window of the KDE...but it doesn't work.
>
> Do you know how i can have a fixed map and add a KDE animated on it ?
>

Did you try to use the xlim= and ylim= arguments to your plotting commands 
as I suggested? You do not need the clipped polygons for analysis, so this 
route should work.

Roger


-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.m.krug at gmail.com  Thu Aug  5 18:23:54 2010
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Thu, 05 Aug 2010 18:23:54 +0200
Subject: [R-sig-Geo] Determine angle between polyline segments
In-Reply-To: <4C52EE47.8030708@ase-research.org>
References: <4C528056.3010406@gmail.com> <4C52EE47.8030708@ase-research.org>
Message-ID: <4C5AE59A.5050701@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


Thanks a lot Nikhil

The functions seem to do what I need, but I am looking into the package
adehabitat as suggested by Mathieu and it seems to be ideal for the purpose.

Thanks a lot,
Rainer


On 30/07/10 17:22, Mathieu Basille wrote:
> Hello,
> 
> Have you considered using the 'adehabitat' package? It presents classes
> and tools for the analysis of trajectories, and automagically computes
> absolute and relative angles. I'm not that familiar with polylines (in
> ArcGIS or sp) so that I don't have a working example at hand, but you'd
> have to extract coordinates of the polylines to build a ltraj object
> (using as.ltraj), keeping the ID of the line as the ID of the ltraj, and
> with 'typeII = FALSE' which means that you don't have the exact date.
> 
> In the end, an object of class ltraj is a list with a data frame for
> each element of the list (for you a line), which gives you both kind of
> angles among other variables (dx, dy, dist, etc.).
> 
> Hope this helps,
> Mathieu.
> 
> 
> Le 30/07/2010 03:33, Rainer M Krug a ?crit :
> Hi
> 
> a friend of mine wants (needs?) to determine the angle between segments
> in an ESRI polyline (line vector feature). As there does not seem to be
> an easy way in ArcGIS 9.2, I thought about askeng here:
> 
> Is there way of calculating these angles between the different line
> segments in R (after importing the line feature into R)?
> 
> Thanks,
> 
> Rainer
> 
>>
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

- -- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Natural Sciences Building
Office Suite 2039
Stellenbosch University
Main Campus, Merriman Avenue
Stellenbosch
South Africa

Tel:        +33 - (0)9 53 10 27 44
Cell:       +27 - (0)8 39 47 90 42
Fax (SA):   +27 - (0)8 65 16 27 82
Fax (D) :   +49 - (0)3 21 21 25 22 44
Fax (FR):   +33 - (0)9 58 10 27 44
email:      Rainer at krugs.de

Skype:      RMkrug
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)
Comment: Using GnuPG with Mozilla - http://enigmail.mozdev.org/

iEYEARECAAYFAkxa5ZkACgkQoYgNqgF2egpMbgCeMlPf346ToUfWsoWKkY0TiboO
OVsAn36YYFOrWk25g8uC9lEs4N0TVevt
=HRWJ
-----END PGP SIGNATURE-----


From r.hijmans at gmail.com  Thu Aug  5 18:41:20 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 5 Aug 2010 09:41:20 -0700
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <1281021394833-5376909.post@n2.nabble.com>
References: <1281021394833-5376909.post@n2.nabble.com>
Message-ID: <AANLkTimsjibhjSjNdAjcEmQ7E7=XiawEKuSDYpZ1ikUy@mail.gmail.com>

Laetitia,

If it is just for display, the below could work:

library(sp)
library(maptools)
library(gpclib) # non-commerical use only
library(PBSmapping)

a = SpatialPolygons2PolySet(france)
b = SpatialPolygons2PolySet(box)

intersect = joinPolys(a, b, "INT")
## a necessary hack because for
## PolySet2SpatialPolygons projection
## LL or UTM and not missing
attr(intersect, "projection") = "UTM"
attr(intersect, "zone") = "12"
##
francebox = PolySet2SpatialPolygons(intersect)
francebox at proj4string = france at proj4string


Robert

On Thu, Aug 5, 2010 at 8:16 AM, Laetitia Blanc
<blanc.laetitia.esr34 at gmail.com> wrote:
>
> hi,
>
> i would like to know how to clip a map ("france") that i loaded with the
> function readShapePoly. Now, it's a SpatialPolygonsDataFrame.
>
> I want to clip the map "france" according to specific coordinates in order
> to obtain a new map corresponding to a specific part of the original map
> (for example the eastern part of France).
>
> Can someone help me ?
> thanks
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5376909.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From blanc.laetitia.esr34 at gmail.com  Thu Aug  5 19:58:52 2010
From: blanc.laetitia.esr34 at gmail.com (Laetitia Blanc)
Date: Thu, 5 Aug 2010 10:58:52 -0700 (PDT)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
	<1281024407951-5377129.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>
Message-ID: <1281031132439-5377623.post@n2.nabble.com>


Roger Bivand,

i tried the method with xlim and ylim and it works when i just plot my map
alone. What i try to do is to insert this map in my animation. Here is the
code of my animation :

pres.ani <- function() 
{ 
for (i in 1:length(unique(d$an))) { 
image(res[,,i],xlab='',ylab='',main=unique(d$an)[i]) 
contour(res[,,i],add=T) 
#points(d3[[i]]) 
Sys.sleep(.5) 
} 

} 
ani.start(interval=.5,title = "movie presence lynx", outdir = getwd()) 

pres.ani() 
ani.stop() 

res[,,i] is my KDE. When i create this animation, the x and y axes range of
the window is 0:1. How can i put my map (coordinate system : Lambert II) as
a background  in this animation ?
I hope it's enough clear...

Thank you for your help.

-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5377623.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Thu Aug  5 20:38:07 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Aug 2010 20:38:07 +0200 (CEST)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <1281031132439-5377623.post@n2.nabble.com>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
	<1281024407951-5377129.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>
	<1281031132439-5377623.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008052035060.23086@reclus.nhh.no>

On Thu, 5 Aug 2010, Laetitia Blanc wrote:

>
> Roger Bivand,
>
> i tried the method with xlim and ylim and it works when i just plot my map
> alone. What i try to do is to insert this map in my animation. Here is the
> code of my animation :
>
> pres.ani <- function()
> {
> for (i in 1:length(unique(d$an))) {
> image(res[,,i],xlab='',ylab='',main=unique(d$an)[i])
> contour(res[,,i],add=T)
> #points(d3[[i]])
> Sys.sleep(.5)
> }
>
> }
> ani.start(interval=.5,title = "movie presence lynx", outdir = getwd())
>
> pres.ani()
> ani.stop()
>
> res[,,i] is my KDE. When i create this animation, the x and y axes range of
> the window is 0:1. How can i put my map (coordinate system : Lambert II) as
> a background  in this animation ?
> I hope it's enough clear...

Can the KDE be run with the correct coordinates in the specified 
projection on the input data, so that thw window matches the outlines? Can 
you re-write the code making res to generate a SpatialGridDataFrame? The 
input points must have a projection. Without a shared projection (CRS, 
coordinate reference system) this is not possible.

Roger

>
> Thank you for your help.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Aug  5 20:56:11 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Aug 2010 20:56:11 +0200 (CEST)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <AANLkTimsjibhjSjNdAjcEmQ7E7=XiawEKuSDYpZ1ikUy@mail.gmail.com>
References: <1281021394833-5376909.post@n2.nabble.com>
	<AANLkTimsjibhjSjNdAjcEmQ7E7=XiawEKuSDYpZ1ikUy@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008052038130.23086@reclus.nhh.no>

On Thu, 5 Aug 2010, Robert J. Hijmans wrote:

> Laetitia,
>
> If it is just for display, the below could work:
>
> library(sp)
> library(maptools)
> library(gpclib) # non-commerical use only

Not only non-commercial, but in fact excluding contract research. Please 
read the actual license terms:

http://en.wikipedia.org/wiki/General_Polygon_Clipper

copies the University of Manchester description of non-commercial:

"Non-commercial use: GPC may be used free of charge, without a licence, in 
any application which is strictly non-commercial (examples: hobbyist, 
academic research or teaching)."

On the website:

http://www.cs.man.ac.uk/~toby/alan/software/#Licensing

it is more restricted still:

"Non-commercial use of GPC (for example: private / hobbyist / education) 
GPC is free for non-commercial use only. We invite non-commercial users to 
make a voluntary donation towards the upkeep of GPC."

<rant>
The gpclib package should be avoided, and will be replaced by rgeos 
shortly. The PBSmapping authors claim to have received permission to 
bundle GPC under GPL, but the license constraints are not made manifest in 
the license of PBSmapping - this mess also needs attention.

That the University of Manchester has arguably hijacked the intellectual 
property of an employee is appears scandalous, and is in itself good 
enough reason to avoid GPC, despite its being a nice piece of work. As I 
mentioned, the R interface to GEOS should be available shortly, and 
hopefully PBSmapping will switch to that code.
</rant>

Roger

> library(PBSmapping)
>
> a = SpatialPolygons2PolySet(france)
> b = SpatialPolygons2PolySet(box)
>
> intersect = joinPolys(a, b, "INT")
> ## a necessary hack because for
> ## PolySet2SpatialPolygons projection
> ## LL or UTM and not missing
> attr(intersect, "projection") = "UTM"
> attr(intersect, "zone") = "12"
> ##
> francebox = PolySet2SpatialPolygons(intersect)
> francebox at proj4string = france at proj4string
>
>
> Robert
>
> On Thu, Aug 5, 2010 at 8:16 AM, Laetitia Blanc
> <blanc.laetitia.esr34 at gmail.com> wrote:
>>
>> hi,
>>
>> i would like to know how to clip a map ("france") that i loaded with the
>> function readShapePoly. Now, it's a SpatialPolygonsDataFrame.
>>
>> I want to clip the map "france" according to specific coordinates in order
>> to obtain a new map corresponding to a specific part of the original map
>> (for example the eastern part of France).
>>
>> Can someone help me ?
>> thanks
>> --
>> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5376909.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From blanc.laetitia.esr34 at gmail.com  Fri Aug  6 11:35:39 2010
From: blanc.laetitia.esr34 at gmail.com (Laetitia Blanc)
Date: Fri, 6 Aug 2010 02:35:39 -0700 (PDT)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.1008052035060.23086@reclus.nhh.no>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
	<1281024407951-5377129.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>
	<1281031132439-5377623.post@n2.nabble.com>
	<alpine.LRH.2.00.1008052035060.23086@reclus.nhh.no>
Message-ID: <1281087339929-5379892.post@n2.nabble.com>




Can the KDE be run with the correct coordinates in the specified 
projection on the input data, so that thw window matches the outlines? Can 
you re-write the code making res to generate a SpatialGridDataFrame? The 
input points must have a projection. Without a shared projection (CRS, 
coordinate reference system) this is not possible.

Roger

>I have taken into account your advice.
>I have loaded my input data with the correct CRS (lambert II) in order to
match with the map :

d <- read.csv('total.csv', header = TRUE) #, sep = ",", quote="\"",
dec=".",fill = TRUE, comment.char="", ...)

d <- d[-(1:10),]

d2 <- data.frame (d)
spd2 <- d2

#transformation into SpatialPointDataFrame
coordinates ( spd2 ) <- ~ x + y
proj4string ( spd2 ) <- CRS("+init=epsg:27572")

>Then, i have realised my KDE :

source("stkde2.txt")

res <- array(0,c(20,20,length(unique(spd2$an)))) # cr?er 30
(length(unique(d$an))) tableaux de 20x20.
for (i in 1:length(unique(spd2$an))) { 
spd3 <- subset(spd2,spd2$an == 1979+i) # r?sum? en conservant que 1973+i o?
i=30 donc en gardant que 2009
lynxkde<-stkde(xlong=spd3$x, ylat=spd3$y, ztime=spd3$an,
xgrids=20,ygrids=20,bwmethod="cv.ml") 
res[,,i] <- lynxkde$dens
} 

>At that moment, the window where the KDE is running has te correct unit
(meters) (xrange : >from 823 000 to 981 000 ; yrange : from 2 079 500 to 2
305 500)

>But then, when i create my animation, the window has the x and y ranges :
0:1. I think the >probleme comes from my animation. Moreover, when i try to
insert my map in my animation, i still >have an alternation between the map
and the kernel >rather than the kernel ON the map (like
>overlay/superposition...) :


library(animation)
library(MASS)

# create a HTML page from my animation :
pres.ani <- function() 
{ 
for (i in 1:length(unique(spd2$an))) { 
image(res[,,i],xlab='',ylab='',main=unique(spd2$an)[i]) 
contour(res[,,i],add=T) 
plot(france,xlim=range(823000:981000),ylim=range(2079500:2305500),add=TRUE) 
Sys.sleep(.5) 
} 

} 
ani.start(interval=.5,title = "movie presence lynx", outdir = getwd()) 

pres.ani() 
ani.stop() 

>I think i must solve the problem by changing my animation but i don't know
how. Do you have an >idea ? Do you think that it can be because i have
spatial objects ?
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5379892.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From pinaud at cebc.cnrs.fr  Fri Aug  6 12:10:54 2010
From: pinaud at cebc.cnrs.fr (Pinaud David)
Date: Fri, 06 Aug 2010 12:10:54 +0200
Subject: [R-sig-Geo] How to calculate time spent on a world grid with
	circumpolar trips
Message-ID: <4C5BDFAE.80903@cebc.cnrs.fr>

Dear all,
I want to calculate a grid of time spent per cell with albatross data. 
The goal is then to relate this to fisheries data set on a 1x1? grid.
I use the trip package with tripGrid(), but have some problems with 
birds crossing the date line.
Usually I use a projection to do that but here I need to keep the 1x1? 
grid in order to relate density tu some data (fisheries...).
I've tried with recenter() and nowrapSpatialLines(), without success.
Here a code:

library(trip)
library(maps)   # to draw world maps

d <- data.frame(x=c(seq(50, 180, 10), seq(-170, 50, 10)), y=rnorm(n=37, 
m=-50, sd=3), tms=Sys.time()-(37:1*60*60*24), id=rep(1, 37))  # an example
coordinates(d) <- ~x+y
tr <- trip(d, c("tms", "id"))
proj4string(at) <- CRS("+proj=longlat +ellps=WGS84")

map('world')
plot(tr, add=T)
points(coordinates(tr), t="l")

# grid
grid.base <- expand.grid(Long=seq(-180, 180, by=1), Lat=seq(-70, -15, 
by=1))   # tab coords
coordinates(grid.base) <- ~ Long + Lat
proj4string(grid.base) <- CRS("+proj=longlat +ellps=WGS84")
gt <- makeGridTopology(grid.base, cellsize = c(1, 1))  # def grid topo

# time spent per cell
tppc <- tripGrid(tr, grid = gt)
tppc01 <- tppc               # a copy for pres/abs
tppc01 at data$z <- ifelse(tppc at data$z > 0, 1, 0)

image(tppc, col=rev(heat.colors(500)))  # seems ok
map('world', add=T)
points(coordinates(tr), t="l")

# but with presence/absence:
image(tppc01, col=c("white", "green"))
map('world', add=T)
points(coordinates(tr), t="l", col="blue")

Some ideas ?


Many thanks for your time.
David

-- 
***************************************************
David PINAUD
Ing?nieur de Recherche "Analyses spatiales"

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
79360 Villiers-en-Bois, France 
poste 485
Tel: +33 (0)5.49.09.35.58
Fax: +33 (0)5.49.09.65.26
http://www.cebc.cnrs.fr/

***************************************************




__________ Information from ESET Mail Security, version of virus signature database 5346 (20100806) __________

The message was checked by ESET Mail Security.
http://www.eset.com

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pinaud.vcf
Type: text/x-vcard
Size: 324 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100806/5b71eb28/attachment.vcf>

From Roger.Bivand at nhh.no  Fri Aug  6 13:13:43 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 6 Aug 2010 13:13:43 +0200 (CEST)
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <1281087339929-5379892.post@n2.nabble.com>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
	<1281024407951-5377129.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>
	<1281031132439-5377623.post@n2.nabble.com>
	<alpine.LRH.2.00.1008052035060.23086@reclus.nhh.no>
	<1281087339929-5379892.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008061253330.27878@reclus.nhh.no>

On Fri, 6 Aug 2010, Laetitia Blanc wrote:

>
>
>
> Can the KDE be run with the correct coordinates in the specified 
> projection on the input data, so that thw window matches the outlines? Can 
> you re-write the code making res to generate a SpatialGridDataFrame? The 
> input points must have a projection. Without a shared projection (CRS, 
> coordinate reference system) this is not possible.
>
> Roger
>
>> I have taken into account your advice.
>> I have loaded my input data with the correct CRS (lambert II) in order to
> match with the map :
>
> d <- read.csv('total.csv', header = TRUE) #, sep = ",", quote="\"",
> dec=".",fill = TRUE, comment.char="", ...)
>
> d <- d[-(1:10),]
>
> d2 <- data.frame (d)
> spd2 <- d2
>
> #transformation into SpatialPointDataFrame
> coordinates ( spd2 ) <- ~ x + y
> proj4string ( spd2 ) <- CRS("+init=epsg:27572")
>
>> Then, i have realised my KDE :
>
> source("stkde2.txt")
>
> res <- array(0,c(20,20,length(unique(spd2$an)))) # cr?er 30
> (length(unique(d$an))) tableaux de 20x20.
> for (i in 1:length(unique(spd2$an))) { 
> spd3 <- subset(spd2,spd2$an == 1979+i) # r?sum? en conservant que 1973+i o?
> i=30 donc en gardant que 2009
> lynxkde<-stkde(xlong=spd3$x, ylat=spd3$y, ztime=spd3$an,
> xgrids=20,ygrids=20,bwmethod="cv.ml") 
> res[,,i] <- lynxkde$dens
> } 
>
>> At that moment, the window where the KDE is running has te correct unit
> (meters) (xrange : >from 823 000 to 981 000 ; yrange : from 2 079 500 to 2
> 305 500)

No, this is a misunderstanding. Until you get this right, please forget 
the simulation, make sure everything is correct for a single period 
first. I am pretty sure that lynxkde$dens is a matrix, and if you 
take the trouble to read help(image), you'll see that if the first 
argument is a matrix, then the window is set to 0,1. You need to pass the 
cell centres of the xgrids and ygrids to the image call. Beware that if 
the spd3$x and spd3$y change by i, the grid will be different each time, 
evenj though it is 20x20, it will start somewhere else, and have a 
different cell dimension.

I think that you are using a function from the stam package - you need to 
adapt it to pass the x.seq and y.seq values now generated internally in as 
arguments, which will permit you to make sure that you have full control 
of the location of the output grids. If you then pass the same x.seq and 
y.seq to image() as the first two arguments, and the matrix as the third 
argument, it will use them to specify its axes, giving you the correct 
window. You need to be sure that your x.seq and y.seq contain all of the 
xlong and xlat for all periods. If stkde took a GridTopology object as a 
grid definition, the output could easily be used to create a 
SpatialGridDataFrame object, which would be very easy to plot in register 
with your boundaries, but this is something for the package maintainer.

Hope this helps,

Roger

PS. CC-ing the stam maintainer.

>
>> But then, when i create my animation, the window has the x and y ranges :
> 0:1. I think the >probleme comes from my animation. Moreover, when i try to
> insert my map in my animation, i still >have an alternation between the map
> and the kernel >rather than the kernel ON the map (like
>> overlay/superposition...) :
>
>
> library(animation)
> library(MASS)
>
> # create a HTML page from my animation :
> pres.ani <- function() 
> { 
> for (i in 1:length(unique(spd2$an))) { 
> image(res[,,i],xlab='',ylab='',main=unique(spd2$an)[i]) 
> contour(res[,,i],add=T) 
> plot(france,xlim=range(823000:981000),ylim=range(2079500:2305500),add=TRUE) 
> Sys.sleep(.5) 
> } 
>
> } 
> ani.start(interval=.5,title = "movie presence lynx", outdir = getwd()) 
>
> pres.ani() 
> ani.stop() 
>
>> I think i must solve the problem by changing my animation but i don't know
> how. Do you have an >idea ? Do you think that it can be because i have
> spatial objects ?
> -- 
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/clip-a-SpatialPolygonsDataFrame-tp5376909p5379892.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From e.pebesma at gmail.com  Fri Aug  6 13:14:46 2010
From: e.pebesma at gmail.com (Edzer Pebesma)
Date: Fri, 06 Aug 2010 13:14:46 +0200
Subject: [R-sig-Geo] gpclib and IPR
In-Reply-To: <alpine.LRH.2.00.1008052038130.23086@reclus.nhh.no>
References: <1281021394833-5376909.post@n2.nabble.com>	<AANLkTimsjibhjSjNdAjcEmQ7E7=XiawEKuSDYpZ1ikUy@mail.gmail.com>
	<alpine.LRH.2.00.1008052038130.23086@reclus.nhh.no>
Message-ID: <4C5BEEA6.1040907@uni-muenster.de>



On 08/05/2010 08:56 PM, Roger Bivand wrote:
 ...

> <rant>
> The gpclib package should be avoided, and will be replaced by rgeos
> shortly. The PBSmapping authors claim to have received permission to
> bundle GPC under GPL, but the license constraints are not made manifest
> in the license of PBSmapping - this mess also needs attention.
> 
> That the University of Manchester has arguably hijacked the intellectual
> property of an employee is appears scandalous, and is in itself good
> enough reason to avoid GPC, despite its being a nice piece of work. As I
> mentioned, the R interface to GEOS should be available shortly, and
> hopefully PBSmapping will switch to that code.
> </rant>

Sorry this is a bit off-topic, but not irrelevant.

I believe that in many universities in western Europe (in any case
Netherlands and Germany), universities simply have this property. The
question is how they deal with it, and what they allow employees. It
varies where the real power about it lies and whether it's managed -- it
seems in the UK and the Netherlands some kind of management layer has
it, whereas in Germany it ultimately seems to be in the hands of the
professors.
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From nuncio.m at gmail.com  Fri Aug  6 13:23:26 2010
From: nuncio.m at gmail.com (nuncio m)
Date: Fri, 6 Aug 2010 16:53:26 +0530
Subject: [R-sig-Geo] spatial autocorrelation
Message-ID: <AANLkTin4WkQ+1UGXgiiFL2Y_0vYLKmRYRTt1-oF6s-Go@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100806/a7089b2b/attachment.pl>

From Roger.Bivand at nhh.no  Fri Aug  6 13:37:17 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 6 Aug 2010 13:37:17 +0200 (CEST)
Subject: [R-sig-Geo] gpclib and IPR
In-Reply-To: <4C5BEEA6.1040907@uni-muenster.de>
References: <1281021394833-5376909.post@n2.nabble.com>
	<AANLkTimsjibhjSjNdAjcEmQ7E7=XiawEKuSDYpZ1ikUy@mail.gmail.com>
	<alpine.LRH.2.00.1008052038130.23086@reclus.nhh.no>
	<4C5BEEA6.1040907@uni-muenster.de>
Message-ID: <alpine.LRH.2.00.1008061320330.27878@reclus.nhh.no>

On Fri, 6 Aug 2010, Edzer Pebesma wrote:

>
>
> On 08/05/2010 08:56 PM, Roger Bivand wrote:
> ...
>
>> <rant>
>> The gpclib package should be avoided, and will be replaced by rgeos
>> shortly. The PBSmapping authors claim to have received permission to
>> bundle GPC under GPL, but the license constraints are not made manifest
>> in the license of PBSmapping - this mess also needs attention.
>>
>> That the University of Manchester has arguably hijacked the intellectual
>> property of an employee is appears scandalous, and is in itself good
>> enough reason to avoid GPC, despite its being a nice piece of work. As I
>> mentioned, the R interface to GEOS should be available shortly, and
>> hopefully PBSmapping will switch to that code.
>> </rant>
>
> Sorry this is a bit off-topic, but not irrelevant.
>
> I believe that in many universities in western Europe (in any case
> Netherlands and Germany), universities simply have this property. The
> question is how they deal with it, and what they allow employees. It
> varies where the real power about it lies and whether it's managed -- it
> seems in the UK and the Netherlands some kind of management layer has
> it, whereas in Germany it ultimately seems to be in the hands of the
> professors.

Yes, it is a power question, really, although IIRC there are issues with 
GPC involving the author Alan Murta moving from the university: "Since 
leaving the University of Manchester I have worked as Senior Graphics 
Programmer at Elixir Studios and am now Senior Tools Programmer and Shader 
Technology Manager at TT Games" (http://www.cs.man.ac.uk/~toby/alan/). The 
code was last updated in 1999 (2.31), with a small memory leak fixed in 
2004 (2.32), so it is not under active maintenance by its "owner".

Curiously, when we publish papers, it is generally the author who signs 
copyright over to the journal, not the institution. And as open access 
publication progresses, maybe more clarity will enter the copyright of 
code too?

Once we get rgeos out there, at least I'll not be obliged to advise people 
to avoid GPC any more! Anyone who can help with testing rgeos (from the 
svn source on R-Forge for now) will move the release date closer!

Roger

>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From nikhil.list at gmail.com  Fri Aug  6 14:38:11 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Fri, 6 Aug 2010 08:38:11 -0400
Subject: [R-sig-Geo] Help converting neighbor list to vector
In-Reply-To: <DAC82C09-5CB4-4B4A-AE96-3054B68C1DA5@utsa.edu>
References: <DAC82C09-5CB4-4B4A-AE96-3054B68C1DA5@utsa.edu>
Message-ID: <B5137E12-DA2E-40F8-AC8E-AA54F10EADD6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100806/a20f194e/attachment.pl>

From epistat at gmail.com  Fri Aug  6 16:46:58 2010
From: epistat at gmail.com (zhijie zhang)
Date: Fri, 6 Aug 2010 10:46:58 -0400
Subject: [R-sig-Geo] clip a SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.1008061253330.27878@reclus.nhh.no>
References: <1281021394833-5376909.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051748590.23086@reclus.nhh.no>
	<1281024407951-5377129.post@n2.nabble.com>
	<alpine.LRH.2.00.1008051815520.23086@reclus.nhh.no>
	<1281031132439-5377623.post@n2.nabble.com>
	<alpine.LRH.2.00.1008052035060.23086@reclus.nhh.no>
	<1281087339929-5379892.post@n2.nabble.com>
	<alpine.LRH.2.00.1008061253330.27878@reclus.nhh.no>
Message-ID: <AANLkTi=dV6+Hp0PYzBk7YMVTT2jZwKJo0SenNUjR=ein@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100806/0f925167/attachment.pl>

From lufile at 126.com  Sat Aug  7 00:27:29 2010
From: lufile at 126.com (lu)
Date: Sat, 7 Aug 2010 06:27:29 +0800 (CST)
Subject: [R-sig-Geo] =?gbk?q?How_to_read_ArcGIS_map=A3=A8access_and_SQL_Se?=
 =?gbk?q?rver_format=29_into_R=3F?=
Message-ID: <16c1863.215.12a49841d37.Coremail.lufile@126.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100807/c4a427a8/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Sat Aug  7 01:09:59 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 7 Aug 2010 00:09:59 +0100
Subject: [R-sig-Geo]
	=?utf-8?q?How_to_read_ArcGIS_map=EF=BC=88access_and_S?=
	=?utf-8?q?QL_Server_format=29_into_R=3F?=
In-Reply-To: <16c1863.215.12a49841d37.Coremail.lufile@126.com>
References: <16c1863.215.12a49841d37.Coremail.lufile@126.com>
Message-ID: <AANLkTi=CXbFC+RFx_veCMqGBPZPS_VWPJdo1oPk_OvXB@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100807/e558e01c/attachment.pl>

From patrick.giraudoux at univ-fcomte.fr  Sat Aug  7 10:56:14 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 07 Aug 2010 10:56:14 +0200
Subject: [R-sig-Geo] kml and points
Message-ID: <4C5D1FAE.3070204@univ-fcomte.fr>

Dear All,

I have just discovered  the fantastic possibilities given with 
kmlPolygon, klmLine and kmlOverlay (package maptools) to project spatial 
objects into google earth.

Does anyone knows if a function equivalent has been written to create a 
kml file of "points" ? If not, is there a technical reason not to have 
done it or a workaround which would make such function unecessary ?

Patrick


From Roger.Bivand at nhh.no  Sat Aug  7 11:15:06 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 7 Aug 2010 11:15:06 +0200 (CEST)
Subject: [R-sig-Geo] kml and points
In-Reply-To: <4C5D1FAE.3070204@univ-fcomte.fr>
References: <4C5D1FAE.3070204@univ-fcomte.fr>
Message-ID: <alpine.LRH.2.00.1008071102420.31336@reclus.nhh.no>

On Sat, 7 Aug 2010, Patrick Giraudoux wrote:

> Dear All,
>
> I have just discovered  the fantastic possibilities given with kmlPolygon, 
> klmLine and kmlOverlay (package maptools) to project spatial objects into 
> google earth.
>
> Does anyone knows if a function equivalent has been written to create a kml 
> file of "points" ? If not, is there a technical reason not to have done it or 
> a workaround which would make such function unecessary ?

Would the KML driver for writeOGR() in rgdal be enough? The variables (or 
a subset of the variables) in the SpatialPointsDataFrame are displayed in 
the bubble on clicking. You do not, I think, get a choice of point symbol.

td <- tempdir()
data(meuse)
coordinates(meuse) <- c("x", "y")
proj4string(meuse) <- CRS("+init=epsg:28992")
meuse_ll <- spTransform(meuse, CRS("+proj=longlat +datum=WGS84"))
writeOGR(meuse_ll, paste(td, "meuse.kml", sep="/"), "zinc", "KML")
file.show(paste(td, "meuse.kml", sep="/"))

See http://www.gdal.org/ogr/drv_kml.html, and note the section on encoding 
if on Windows.

Roger

>
> Patrick
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From patrick.giraudoux at univ-fcomte.fr  Sat Aug  7 11:21:45 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 07 Aug 2010 11:21:45 +0200
Subject: [R-sig-Geo] kml and points
In-Reply-To: <alpine.LRH.2.00.1008071102420.31336@reclus.nhh.no>
References: <4C5D1FAE.3070204@univ-fcomte.fr>
	<alpine.LRH.2.00.1008071102420.31336@reclus.nhh.no>
Message-ID: <4C5D25A9.7040803@univ-fcomte.fr>

Roger Bivand a ?crit :
> On Sat, 7 Aug 2010, Patrick Giraudoux wrote:
>
>> Dear All,
>>
>> I have just discovered  the fantastic possibilities given with 
>> kmlPolygon, klmLine and kmlOverlay (package maptools) to project 
>> spatial objects into google earth.
>>
>> Does anyone knows if a function equivalent has been written to create 
>> a kml file of "points" ? If not, is there a technical reason not to 
>> have done it or a workaround which would make such function unecessary ?
>
> Would the KML driver for writeOGR() in rgdal be enough? The variables 
> (or a subset of the variables) in the SpatialPointsDataFrame are 
> displayed in the bubble on clicking. You do not, I think, get a choice 
> of point symbol.
>
> td <- tempdir()
> data(meuse)
> coordinates(meuse) <- c("x", "y")
> proj4string(meuse) <- CRS("+init=epsg:28992")
> meuse_ll <- spTransform(meuse, CRS("+proj=longlat +datum=WGS84"))
> writeOGR(meuse_ll, paste(td, "meuse.kml", sep="/"), "zinc", "KML")
> file.show(paste(td, "meuse.kml", sep="/"))
>
> See http://www.gdal.org/ogr/drv_kml.html, and note the section on 
> encoding if on Windows.
>
> Roger
>


Sure, likely to be exactly what I need. I was not aware of this kml 
driver in rdgal (I was ready to write down a  function...).

Thanks a lot,

Patrick




>>
>> Patrick
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From mazatlanmexico at yahoo.com  Sat Aug  7 19:10:38 2010
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sat, 7 Aug 2010 10:10:38 -0700 (PDT)
Subject: [R-sig-Geo] kml and points
In-Reply-To: <alpine.LRH.2.00.1008071102420.31336@reclus.nhh.no>
References: <4C5D1FAE.3070204@univ-fcomte.fr>
	<alpine.LRH.2.00.1008071102420.31336@reclus.nhh.no>
Message-ID: <424811.21115.qm@web56604.mail.re3.yahoo.com>

Can google earth be open from R along with the meuse.kml overlayed on top of it?
?
Felipe D. Carrillo
Supervisory Fishery Biologist
Department of the Interior
US Fish & Wildlife Service
California, USA



----- Original Message ----
> From: Roger Bivand <Roger.Bivand at nhh.no>
> To: Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr>
> Cc: r-sig-geo at stat.math.ethz.ch
> Sent: Sat, August 7, 2010 2:15:06 AM
> Subject: Re: [R-sig-Geo] kml and points
> 
> On Sat, 7 Aug 2010, Patrick Giraudoux wrote:
> 
> > Dear All,
> > 
> > I have just discovered? the fantastic possibilities given with kmlPolygon, 
>klmLine and kmlOverlay (package maptools) to project spatial objects into google 
>earth.
> > 
> > Does anyone knows if a function equivalent has been written to create a kml 
>file of "points" ? If not, is there a technical reason not to have done it or a 
>workaround which would make such function unecessary ?
> 
> Would the KML driver for writeOGR() in rgdal be enough? The variables (or a 
>subset of the variables) in the SpatialPointsDataFrame are displayed in the 
>bubble on clicking. You do not, I think, get a choice of point symbol.
> 
> td <- tempdir()
> data(meuse)
> coordinates(meuse) <- c("x", "y")
> proj4string(meuse) <- CRS("+init=epsg:28992")
> meuse_ll <- spTransform(meuse, CRS("+proj=longlat +datum=WGS84"))
> writeOGR(meuse_ll, paste(td, "meuse.kml", sep="/"), "zinc", "KML")
> file.show(paste(td, "meuse.kml", sep="/"))
> 
> See http://www.gdal.org/ogr/drv_kml.html, and note the section on encoding if 
>on Windows.
> 
> Roger
> 
> > 
> > Patrick
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > 
> 
> -- Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 





From patrick.giraudoux at univ-fcomte.fr  Sat Aug  7 19:22:10 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 07 Aug 2010 19:22:10 +0200
Subject: [R-sig-Geo] kml and points
In-Reply-To: <424811.21115.qm@web56604.mail.re3.yahoo.com>
References: <4C5D1FAE.3070204@univ-fcomte.fr>
	<alpine.LRH.2.00.1008071102420.31336@reclus.nhh.no>
	<424811.21115.qm@web56604.mail.re3.yahoo.com>
Message-ID: <4C5D9642.1080705@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100807/48fbbe36/attachment.pl>

From moshersteven at gmail.com  Sat Aug  7 21:51:10 2010
From: moshersteven at gmail.com (steven mosher)
Date: Sat, 7 Aug 2010 12:51:10 -0700
Subject: [R-sig-Geo] spatial autocorrelation
In-Reply-To: <AANLkTin4WkQ+1UGXgiiFL2Y_0vYLKmRYRTt1-oF6s-Go@mail.gmail.com>
References: <AANLkTin4WkQ+1UGXgiiFL2Y_0vYLKmRYRTt1-oF6s-Go@mail.gmail.com>
Message-ID: <AANLkTinruXfA-yMufiBLTisv8yMU5fSyvF981d5=wQRO@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100807/7ac58941/attachment.pl>

From rrasterr at gmail.com  Sun Aug  8 14:46:45 2010
From: rrasterr at gmail.com (rras terr)
Date: Sun, 8 Aug 2010 14:46:45 +0200
Subject: [R-sig-Geo] Problems with writeGDAL (gridded function)
Message-ID: <AANLkTinBmf9hbOHWMPjABQoso40KDKY84kVTi_=bco8N@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100808/18838954/attachment.pl>

From S.elMesslaki at student.TUDelft.NL  Sun Aug  8 23:15:24 2010
From: S.elMesslaki at student.TUDelft.NL (Sabira el Messlaki)
Date: Sun, 8 Aug 2010 23:15:24 +0200
Subject: [R-sig-Geo] your mail
References: <3154E0B9605B3140AFAD0A3A97DA29CF832415@SRV603.tudelft.net>
	<alpine.LRH.2.00.1008061523150.27878@reclus.nhh.no>
Message-ID: <3154E0B9605B3140AFAD0A3A97DA29CF832418@SRV603.tudelft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100808/91e932b3/attachment.pl>

From pierre.roudier at gmail.com  Mon Aug  9 01:57:58 2010
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Mon, 9 Aug 2010 11:57:58 +1200
Subject: [R-sig-Geo] Problems with writeGDAL (gridded function)
In-Reply-To: <AANLkTinBmf9hbOHWMPjABQoso40KDKY84kVTi_=bco8N@mail.gmail.com>
References: <AANLkTinBmf9hbOHWMPjABQoso40KDKY84kVTi_=bco8N@mail.gmail.com>
Message-ID: <AANLkTi=sjmvnEHVDz9SjaXDcy2_uyA+wCzMmu2Cc+y2H@mail.gmail.com>

Hi Ana,

Your post is missing some details, like your sessionInfo() output, and
the way you are reading your data.

>From what I understand, you are using the (excellent) raster package
to read your data, that's why the class of your data is "RasterLayer".

The writeGDAL() function from the rgdal package is not able to cope
with that class AFAIK. You have to translate your object from the
RasterLayer class to an sp class (typically SpatialPixelsDataFrame for
raster data), as follows:

library(raster)
library(rgdal)
data(drg) # Loading some sample data
class(drg) # drg is a "RasterLayer" object
writeGDAL(drg, "foo.tif", drivername="GTiff") # You get an error
because writeGDAL can't  deal with RasterLayer objects
drg.sp <- as(drg, "SpatialPixelsDataFrame") # Converting the
RasterLayer object to a SpatialPixelsDataFrame object
class(drg.sp)
writeGDAL(drg.sp, "foo.tif", drivername="GTiff") # This should work

Hope this help,

Pierre

2010/8/9 rras terr <rrasterr at gmail.com>:
> I all,
>
> I am having problems in exporting data using writeGDAL & create2GDAL:
>
> Error in function (classes, fdef, mtable) ?:
> unable to find an inherited method for function "gridded", for signature
> "RasterLayer"
> Calls: writeGDAL -> create2GDAL -> stopifnot -> gridded -> <Anonymous>
>
> --
> rgdal version: 0.6-28
> --
>
> Any suggestion?
>
> Thanks in advance,
> Ana
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From pierre.roudier at gmail.com  Mon Aug  9 02:01:58 2010
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Mon, 9 Aug 2010 12:01:58 +1200
Subject: [R-sig-Geo] Problems with writeGDAL (gridded function)
In-Reply-To: <AANLkTi=sjmvnEHVDz9SjaXDcy2_uyA+wCzMmu2Cc+y2H@mail.gmail.com>
References: <AANLkTinBmf9hbOHWMPjABQoso40KDKY84kVTi_=bco8N@mail.gmail.com> 
	<AANLkTi=sjmvnEHVDz9SjaXDcy2_uyA+wCzMmu2Cc+y2H@mail.gmail.com>
Message-ID: <AANLkTimbU2amnxni=yC+7COpdFRADvZ8250hifTvESwO@mail.gmail.com>

Sorry for posting again,

Reading through the raster reference manual, I just realised you can
actually use the raster package internal function for writing rasters,
writeRaster() :

library(raster)
data(drg) # Loading some sample data
class(drg) # drg is a "RasterLayer" object
writeRaster(drg, "bar.tif") # No class conversion needed

This is more straightforward, and it's using GDAL as well for most formats,

Pierre

2010/8/9 Pierre Roudier <pierre.roudier at gmail.com>:
> Hi Ana,
>
> Your post is missing some details, like your sessionInfo() output, and
> the way you are reading your data.
>
> From what I understand, you are using the (excellent) raster package
> to read your data, that's why the class of your data is "RasterLayer".
>
> The writeGDAL() function from the rgdal package is not able to cope
> with that class AFAIK. You have to translate your object from the
> RasterLayer class to an sp class (typically SpatialPixelsDataFrame for
> raster data), as follows:
>
> library(raster)
> library(rgdal)
> data(drg) # Loading some sample data
> class(drg) # drg is a "RasterLayer" object
> writeGDAL(drg, "foo.tif", drivername="GTiff") # You get an error
> because writeGDAL can't ?deal with RasterLayer objects
> drg.sp <- as(drg, "SpatialPixelsDataFrame") # Converting the
> RasterLayer object to a SpatialPixelsDataFrame object
> class(drg.sp)
> writeGDAL(drg.sp, "foo.tif", drivername="GTiff") # This should work
>
> Hope this help,
>
> Pierre
>
> 2010/8/9 rras terr <rrasterr at gmail.com>:
>> I all,
>>
>> I am having problems in exporting data using writeGDAL & create2GDAL:
>>
>> Error in function (classes, fdef, mtable) ?:
>> unable to find an inherited method for function "gridded", for signature
>> "RasterLayer"
>> Calls: writeGDAL -> create2GDAL -> stopifnot -> gridded -> <Anonymous>
>>
>> --
>> rgdal version: 0.6-28
>> --
>>
>> Any suggestion?
>>
>> Thanks in advance,
>> Ana
>>
>> ? ? ? ?[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From Bjarke.Christensen at sydbank.dk  Mon Aug  9 09:25:24 2010
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Mon, 9 Aug 2010 09:25:24 +0200
Subject: [R-sig-Geo] kml and points
In-Reply-To: <mailman.9.1281261604.19468.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1281261604.19468.r-sig-geo@stat.math.ethz.ch>
Message-ID: <OFC039A80A.DBC3F5D9-ONC125777A.00288350-C125777A.0028C6FA@bdpnet.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100809/08fc079a/attachment.pl>

From Roger.Bivand at nhh.no  Mon Aug  9 14:06:05 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Aug 2010 14:06:05 +0200 (CEST)
Subject: [R-sig-Geo] your mail
In-Reply-To: <3154E0B9605B3140AFAD0A3A97DA29CF832418@SRV603.tudelft.net>
References: <3154E0B9605B3140AFAD0A3A97DA29CF832415@SRV603.tudelft.net>
	<alpine.LRH.2.00.1008061523150.27878@reclus.nhh.no>
	<3154E0B9605B3140AFAD0A3A97DA29CF832418@SRV603.tudelft.net>
Message-ID: <alpine.LRH.2.00.1008091401260.8838@reclus.nhh.no>

On Sun, 8 Aug 2010, Sabira el Messlaki wrote:

> Dear Roger,
>
> What do you mean by using correlation= argument to lme() to fit a model
> including within-group correlations?

You do need to read the help page to look for the specification og 
"argument". Reading the book refered to on the help page may be a good 
idea too.

>
> I tried it like this: model3.fit <- lme(y ~ 
> x3+x5+x7+x9+LnBankt500+Perceelkwaliteit+LnNS_Afstand+PGebouwd+LogoBedrijf+Bouwjaar_cat4+LnBanIndDistr500, 
> random = ~1|GebID ,correlation=argument, datashab, method = "REML")
>
> But this does not seem to work. What is the reason that nobody developed 
> a moran's I for an lme object?
>

You have specified a random group effect. Consequently, the standard 
OLS relationship between the projection matrix of the included variables 
and the residuals does not hold. You can calculate Moran's I, but there is 
no theory to tell you whether it is significant or not. The formulae for 
the expectation and variance of the statistic need changing, and if they 
are not changed, the results will be misleading.

Roger

>
>
>
> -----Oorspronkelijk bericht-----
> Van: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Verzonden: vr 6-8-2010 15:30
> Aan: Sabira el Messlaki
> Onderwerp: Re: your mail
>
> On Fri, 6 Aug 2010, Sabira el Messlaki wrote:
>
>>
>> Dear Roger,
>
>> How do I test the Moran's I in residuals of an lme object. I have done a
>> multilevel analysis and now I want to know if there is still spatial
>> autocorrelation.
>
> Briefly, you have the opportunty to develop a test from the ground up
> yourself, as there are only tests for linear model residuals available. If
> you want to try to use a regular Moran's I on the residuals data frame
> columns from the fitted model, the significance tests will most likely be
> wrong.
>
> Could you try using the correlation= argument to lme() to fit a model
> including within-group correlations, typically based on inter-observation
> distance? If the fit of lme() with and without this argument is the same,
> it would suggest that there is no residual within-group autocorrelation
> for your correlation scheme.
>
> Hope this helps,
>
> Roger
>
>>
>> Thank you in advance
>>
>> Sabira
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kerryr at sccwrp.org  Mon Aug  9 17:06:28 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Mon, 09 Aug 2010 08:06:28 -0700
Subject: [R-sig-Geo] quick question re: fit.variogram in gstat
In-Reply-To: <4C5729B3.1050304@sccwrp.org>
References: <4C5729B3.1050304@sccwrp.org>
Message-ID: <4C601974.4050705@sccwrp.org>

I have a follow up question regarding the range parameter specified for 
the gaussian variogram model in gstat.. 

First, thank you to Jaime Grion who riplied...

 Dear Kerry, if you write in the option model "Gau" you just have to 
specify 200 [for the range].

However, when I fit the variogram and the fitted value returns "200" as 
the range parameter, the variogram looks like the true range exceeds 
200.  Is the returned range parameter the "practical range" = the value 
at which this model reaches 95% of its asymptotic value or the value 
where spatial correlation ceases to exist?.  In Bivand, et. al's book 
"Applied Spatial Data Analysis with R", the authors state that the 
practical range for the gaussian variogram model is sqrt(3)*a where a is 
the range parameter for most other models.  So my question remains.  Is 
the fit giving me the range or the practical range?

Thanks,
Kerry

Kerry Ritter wrote:
> Hi all. I have what I hope is a quick question concerning the use of 
> "fit.variogram" in"gstat".  If you assume a a Spherical model for the 
> variogram and the estimated range is say 200m and then you switch 
> models to a Gaussian but want to keep the range fixed at 200m, would 
> you specify 200 for the range parameter or 200/sqrt(3)?
>
> Thanks,
> Kerry
>
> **********************
> Kerry Ritter, Ph.D.
> statistician
> Southern California Coastal Water Research Project
> 3535 Harbor Blvd., Suite 110
>
> work: 714-755-3210
> cell: 714-420-3346
> fax:  714-755-3299
>
> email: kerryr at sccwrp.org
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From Andy.Bunn at wwu.edu  Tue Aug 10 04:40:14 2010
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 9 Aug 2010 19:40:14 -0700
Subject: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
Message-ID: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>

I have a SpatialGridDataFrame with 325 variables in the @ data slot. I want to drop the first layer. Seems simple enough. Any help? Thanks, Andy

> str(monthly.sp)
Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
  ..@ data       :'data.frame':	8060 obs. of  325 variables:
  .. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
  .. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
  .. and so on


From mdsumner at gmail.com  Tue Aug 10 08:28:18 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 10 Aug 2010 16:28:18 +1000
Subject: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
In-Reply-To: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>
References: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>
Message-ID: <AANLkTi=j9jvzrP-dGuY=2XhgUQ_rCCXZOwNOehqTLNbB@mail.gmail.com>

Do you mean "layer" as in the first column in the data.frame?

Does this do what you want?  The negative index means "everything but
these indexes".

monthly.sp <- monthly.sp[,-1]



On Tue, Aug 10, 2010 at 12:40 PM, Andy Bunn <Andy.Bunn at wwu.edu> wrote:
> I have a SpatialGridDataFrame with 325 variables in the @ data slot. I want to drop the first layer. Seems simple enough. Any help? Thanks, Andy
>
>> str(monthly.sp)
> Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
> ?..@ data ? ? ? :'data.frame': 8060 obs. of ?325 variables:
> ?.. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
> ?.. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
> ?.. and so on
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From mdsumner at gmail.com  Tue Aug 10 10:53:53 2010
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 10 Aug 2010 18:53:53 +1000
Subject: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
In-Reply-To: <web-5105363@be2.uni-bonn.de>
References: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>
	<AANLkTi=j9jvzrP-dGuY=2XhgUQ_rCCXZOwNOehqTLNbB@mail.gmail.com>
	<web-5105363@be2.uni-bonn.de>
Message-ID: <AANLkTim3ckywwq=Rp_WD_2ZYoJ0N5q6bHYxtMp=08m_r@mail.gmail.com>

Gah  - I was mixed up with SpatialPointsDataFrame.

My suggestion should have been this:

monthly.sp <- monthly.sp[,,-1]

Thanks Jaime, I didn't know there was 3 index extract methods for SGDF.

Cheers, Mike.

On Tue, Aug 10, 2010 at 6:24 PM, Jaime R. Garcia Marquez
<jaime.garcia at uni-bonn.de> wrote:
> I think with 'SpatialGridDataFrames' you should do
>
> monthly.sp <- monthly.sp[,,-1]
>
> Note the two commas in the index[].
> First index rows, second columns, and third variables.
>
> HTH
>
> On Tue, 10 Aug 2010 16:28:18 +1000
> ?Michael Sumner <mdsumner at gmail.com> wrote:
>>
>> Do you mean "layer" as in the first column in the data.frame?
>>
>> Does this do what you want? ?The negative index means "everything but
>> these indexes".
>>
>> monthly.sp <- monthly.sp[,-1]
>>
>>
>>
>> On Tue, Aug 10, 2010 at 12:40 PM, Andy Bunn <Andy.Bunn at wwu.edu> wrote:
>>>
>>> I have a SpatialGridDataFrame with 325 variables in the @ data slot. I
>>> want to drop the first layer. Seems simple enough. Any help? Thanks, Andy
>>>
>>>> str(monthly.sp)
>>>
>>> Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
>>> ?..@ data ? ? ? :'data.frame': 8060 obs. of ?325 variables:
>>> ?.. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
>>> ?.. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
>>> ?.. and so on
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>> --
>> Michael Sumner
>> Institute for Marine and Antarctic Studies, University of Tasmania
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From kadraamrane at hotmail.fr  Tue Aug 10 15:06:07 2010
From: kadraamrane at hotmail.fr (kad)
Date: Tue, 10 Aug 2010 06:06:07 -0700 (PDT)
Subject: [R-sig-Geo] Error autoKrige
Message-ID: <1281445567867-5392938.post@n2.nabble.com>


Dear all,
I want to do 10 kriging maps with packages automap.So ,I use
autofitvariogram for fitting the experimental variogram then I use the
command autokrige.
I have this error:

In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
  An error has occured during variogram fitting. Used:
        nugget: 0
        model:  Ste
        psill:  1.13727235894792
        range:  6.5336666581637
        kappa:  10
  as initial guess. This particular variogram fit is not taken into account. 
Gstat error:
Error in fit.variogram(experimental_variogram, model = vgm(psill = psill,  : 
  fit.method 7 will not work with zero distance semivariances; use another
fit.method value

I change the option fit.method =7 by differents number betwen 1 and 6 but I
have always this error.
Do you can help me 

KAD

 

  
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p5392938.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From e.pebesma at gmail.com  Tue Aug 10 15:26:21 2010
From: e.pebesma at gmail.com (Edzer Pebesma)
Date: Tue, 10 Aug 2010 15:26:21 +0200
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <1281445567867-5392938.post@n2.nabble.com>
References: <1281445567867-5392938.post@n2.nabble.com>
Message-ID: <4C61537D.2020203@uni-muenster.de>

Could you please verify (with zerodist) whether you have duplicate
observations in your data set (i.e., multiple observations sharing a
common spatial location)?

On 08/10/2010 03:06 PM, kad wrote:
> 
> Dear all,
> I want to do 10 kriging maps with packages automap.So ,I use
> autofitvariogram for fitting the experimental variogram then I use the
> command autokrige.
> I have this error:
> 
> In getModel(initial_sill - initial_nugget, m, initial_range,  ... :
>   An error has occured during variogram fitting. Used:
>         nugget: 0
>         model:  Ste
>         psill:  1.13727235894792
>         range:  6.5336666581637
>         kappa:  10
>   as initial guess. This particular variogram fit is not taken into account. 
> Gstat error:
> Error in fit.variogram(experimental_variogram, model = vgm(psill = psill,  : 
>   fit.method 7 will not work with zero distance semivariances; use another
> fit.method value
> 
> I change the option fit.method =7 by differents number betwen 1 and 6 but I
> have always this error.
> Do you can help me 
> 
> KAD
> 
>  
> 
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From kadraamrane at hotmail.fr  Tue Aug 10 17:09:47 2010
From: kadraamrane at hotmail.fr (kad)
Date: Tue, 10 Aug 2010 08:09:47 -0700 (PDT)
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <4C61537D.2020203@uni-muenster.de>
References: <1281445567867-5392938.post@n2.nabble.com>
	<4C61537D.2020203@uni-muenster.de>
Message-ID: <1281452987970-5393442.post@n2.nabble.com>


Yes I have some duplicate observations.
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p5393442.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From e.pebesma at gmail.com  Tue Aug 10 20:34:56 2010
From: e.pebesma at gmail.com (Edzer Pebesma)
Date: Tue, 10 Aug 2010 20:34:56 +0200
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <1281452987970-5393442.post@n2.nabble.com>
References: <1281445567867-5392938.post@n2.nabble.com>	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
Message-ID: <4C619BD0.3040906@uni-muenster.de>

Then an easy way out might be to remove these first. See ?zerodist for
some inspiration on how to do this.

On 08/10/2010 05:09 PM, kad wrote:
> 
> Yes I have some duplicate observations.

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From e.pebesma at gmail.com  Tue Aug 10 20:40:57 2010
From: e.pebesma at gmail.com (Edzer Pebesma)
Date: Tue, 10 Aug 2010 20:40:57 +0200
Subject: [R-sig-Geo] quick question re: fit.variogram in gstat
In-Reply-To: <4C601974.4050705@sccwrp.org>
References: <4C5729B3.1050304@sccwrp.org> <4C601974.4050705@sccwrp.org>
Message-ID: <4C619D39.7040209@uni-muenster.de>

What you see is the range parameter; as the Gaussian model reaches the
sill asymptotically, the value sqrt(3) * a is often used as the
"effective range", or distance value where 95% of the (partial) sill is
reached. Just plot the curve of 1-exp(-(h/a)^2) to see why this is so.

On 08/09/2010 05:06 PM, Kerry Ritter wrote:
> I have a follow up question regarding the range parameter specified for
> the gaussian variogram model in gstat..
> First, thank you to Jaime Grion who riplied...
> 
> Dear Kerry, if you write in the option model "Gau" you just have to
> specify 200 [for the range].
> 
> However, when I fit the variogram and the fitted value returns "200" as
> the range parameter, the variogram looks like the true range exceeds
> 200.  Is the returned range parameter the "practical range" = the value
> at which this model reaches 95% of its asymptotic value or the value
> where spatial correlation ceases to exist?.  In Bivand, et. al's book
> "Applied Spatial Data Analysis with R", the authors state that the
> practical range for the gaussian variogram model is sqrt(3)*a where a is
> the range parameter for most other models.  So my question remains.  Is
> the fit giving me the range or the practical range?
> 
> Thanks,
> Kerry
> 
> Kerry Ritter wrote:
>> Hi all. I have what I hope is a quick question concerning the use of
>> "fit.variogram" in"gstat".  If you assume a a Spherical model for the
>> variogram and the estimated range is say 200m and then you switch
>> models to a Gaussian but want to keep the range fixed at 200m, would
>> you specify 200 for the range parameter or 200/sqrt(3)?
>>
>> Thanks,
>> Kerry
>>
>> **********************
>> Kerry Ritter, Ph.D.
>> statistician
>> Southern California Coastal Water Research Project
>> 3535 Harbor Blvd., Suite 110
>>
>> work: 714-755-3210
>> cell: 714-420-3346
>> fax:  714-755-3299
>>
>> email: kerryr at sccwrp.org
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Andy.Bunn at wwu.edu  Tue Aug 10 21:02:02 2010
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Tue, 10 Aug 2010 12:02:02 -0700
Subject: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
In-Reply-To: <AANLkTi=j9jvzrP-dGuY=2XhgUQ_rCCXZOwNOehqTLNbB@mail.gmail.com>
References: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>
	<AANLkTi=j9jvzrP-dGuY=2XhgUQ_rCCXZOwNOehqTLNbB@mail.gmail.com>
Message-ID: <7E6EA3F4372E474F8F3F850DD262FDA903558721D7@ExchMailbox3.univ.dir.wwu.edu>

> -----Original Message-----
> From: Michael Sumner [mailto:mdsumner at gmail.com]
> Sent: Monday, August 09, 2010 11:28 PM
> To: Andy Bunn
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
> 
> Do you mean "layer" as in the first column in the data.frame?
> 
> Does this do what you want?  The negative index means "everything but
> these indexes".
> 
> monthly.sp <- monthly.sp[,-1]

I was a bit hasty. The SpatialGridDataFrame contains 325 separate grids each with 155 cols and 52 rows. E.g., if it were an array I'd think it would have dimensions of 52, 155, 325 and I'd want to do something like: monthly.sp[,,-1]. When I'm done I want the object to have 324 variables with 8060 obs and keep the cells.dim at 155 by 52.


> 
> 
> 
> On Tue, Aug 10, 2010 at 12:40 PM, Andy Bunn <Andy.Bunn at wwu.edu> wrote:
> > I have a SpatialGridDataFrame with 325 variables in the @ data slot.
> I want to drop the first layer. Seems simple enough. Any help? Thanks,
> Andy
> >
> >> str(monthly.sp)
> > Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
> > ?..@ data ? ? ? :'data.frame': 8060 obs. of ?325 variables:
> > ?.. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
> > ?.. ..$ values: num [1:8060] 127.5 31.9 127.5 127.5 231.1 ...
> > ?.. and so on
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> 
> 
> --
> Michael Sumner
> Institute for Marine and Antarctic Studies, University of Tasmania
> Hobart, Australia
> e-mail: mdsumner at gmail.com


From landis at isciences.com  Tue Aug 10 21:55:41 2010
From: landis at isciences.com (Matthew Landis)
Date: Tue, 10 Aug 2010 15:55:41 -0400
Subject: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
In-Reply-To: <7E6EA3F4372E474F8F3F850DD262FDA903558721D7@ExchMailbox3.univ.dir.wwu.edu>
References: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>	<AANLkTi=j9jvzrP-dGuY=2XhgUQ_rCCXZOwNOehqTLNbB@mail.gmail.com>
	<7E6EA3F4372E474F8F3F850DD262FDA903558721D7@ExchMailbox3.univ.dir.wwu.edu>
Message-ID: <4C61AEBD.2040502@isciences.com>

  Andy - how about these two options

monthly.sp at data <- monthly.sp at data[-1,]

or (cheating with the help of raster package)

monthly.stack <- as(monthly.sp, 'RasterStack')
monthly.stack <- dropLayer(monthly.stack, 1)
monthly.sp <- as(monthly.stack, 'SpatialGridDataFrame')

Apologies if these are nonsense - I don't have time to actually test 
these out on a toy example at the moment.

Matt

On 8/10/2010 3:02 PM, Andy Bunn wrote:
> I was a bit hasty. The SpatialGridDataFrame contains 325 separate grids each with 155 cols and 52 rows. E.g., if it were an array I'd think it would have dimensions of 52, 155, 325 and I'd want to do something like: monthly.sp[,,-1]. When I'm done I want the object to have 324 variables with 8060 obs and keep the cells.dim at 155 by 52.
>

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~
Matthew Landis, Ph.D.
Research Scientist
ISciences, LLC
61 Main St. Suite 200
Burlington VT 05401
802.864.2999
~~~~~~~~~~~~~~~~~~~~~~~~~~


From Andy.Bunn at wwu.edu  Tue Aug 10 21:57:11 2010
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Tue, 10 Aug 2010 12:57:11 -0700
Subject: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
In-Reply-To: <4C61AEBD.2040502@isciences.com>
References: <7E6EA3F4372E474F8F3F850DD262FDA9035587219A@ExchMailbox3.univ.dir.wwu.edu>
	<AANLkTi=j9jvzrP-dGuY=2XhgUQ_rCCXZOwNOehqTLNbB@mail.gmail.com>
	<7E6EA3F4372E474F8F3F850DD262FDA903558721D7@ExchMailbox3.univ.dir.wwu.edu>
	<4C61AEBD.2040502@isciences.com>
Message-ID: <7E6EA3F4372E474F8F3F850DD262FDA903558721E5@ExchMailbox3.univ.dir.wwu.edu>



> -----Original Message-----
> From: Matthew Landis [mailto:landis at isciences.com]
> Sent: Tuesday, August 10, 2010 12:56 PM
> To: r-sig-geo at stat.math.ethz.ch; Andy Bunn
> Subject: Re: [R-sig-Geo] drop layer/band from SpatialGridDataFrame
> 
>   Andy - how about these two options
> 
> monthly.sp at data <- monthly.sp at data[-1,]
> 
> or (cheating with the help of raster package)
> 
> monthly.stack <- as(monthly.sp, 'RasterStack')
> monthly.stack <- dropLayer(monthly.stack, 1)
> monthly.sp <- as(monthly.stack, 'SpatialGridDataFrame')

Great. Thanks! Done.

> 
> Apologies if these are nonsense - I don't have time to actually test
> these out on a toy example at the moment.
> 
> Matt
> 
> On 8/10/2010 3:02 PM, Andy Bunn wrote:
> > I was a bit hasty. The SpatialGridDataFrame contains 325 separate
> grids each with 155 cols and 52 rows. E.g., if it were an array I'd
> think it would have dimensions of 52, 155, 325 and I'd want to do
> something like: monthly.sp[,,-1]. When I'm done I want the object to
> have 324 variables with 8060 obs and keep the cells.dim at 155 by 52.
> >
> 
> --
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
> Matthew Landis, Ph.D.
> Research Scientist
> ISciences, LLC
> 61 Main St. Suite 200
> Burlington VT 05401
> 802.864.2999
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
> 


From Scott.Waichler at pnl.gov  Wed Aug 11 06:47:46 2010
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Tue, 10 Aug 2010 21:47:46 -0700
Subject: [R-sig-Geo] Directional variograms with 3D data
Message-ID: <A632B3F93D861843A3C966F3962C3F8401080DD39972@EMAIL05.pnl.gov>

Hello,

I have a dataset with coordinates in x, y, z.  I would like to generate directional variograms, including ones for distinct horizontal and vertical directions, and fit models to them.  Apparently geoR does not accept 3D coordinates, so I am left with (?) gstat.  I have trouble understanding and applying the 5-parameter version of anis in gstat's vgm(), so I thought I would try generating one direction at a time, as below with a data frame called "han":

th.vg1 <- variogram(th ~ 1, han, alpha=0, tol.hor = 90, beta=0, tol.vert=30) # within 30 deg of horizontal  
th.vg2 <- variogram(th ~ 1, han, alpha=0, tol.hor = 90, beta=90, tol.vert=30) # within 30 deg of vertical

th.vg1 and th.vg2 are identical; both are omnidirectional.  What do I need to do to to get distinct horizontal and vertical directions?

Scott Waichler
Pacific Northwest National Laboratory
P.O. Box 999, Richland, WA  99352
scott.waichler at pnl.gov
509-372-4423, 509-341-4051 (cell)


From p.hiemstra at geo.uu.nl  Wed Aug 11 10:02:58 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 11 Aug 2010 10:02:58 +0200
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <1281452987970-5393442.post@n2.nabble.com>
References: <1281445567867-5392938.post@n2.nabble.com>	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
Message-ID: <4C625932.2030900@geo.uu.nl>

On 08/10/2010 05:09 PM, kad wrote:
> Yes I have some duplicate observations.
>    
Which version of automap are you using? In my version (1.0-7) autoKrige 
deletes any duplicate observations (and provides a warning). Could you 
provide a self contained example that we can run on our machines that 
duplicates the problem?

regards,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From kadraamrane at hotmail.fr  Wed Aug 11 17:42:47 2010
From: kadraamrane at hotmail.fr (kad)
Date: Wed, 11 Aug 2010 08:42:47 -0700 (PDT)
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <4C625932.2030900@geo.uu.nl>
References: <1281445567867-5392938.post@n2.nabble.com>
	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
	<4C625932.2030900@geo.uu.nl>
Message-ID: <1281541367592-5412713.post@n2.nabble.com>


I use automap 1.0-7 with version R 2.11.0. My data 
http://r-sig-geo.2731867.n2.nabble.com/file/n5412713/k.txt k.txt 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p5412713.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From e.pebesma at gmail.com  Wed Aug 11 22:18:05 2010
From: e.pebesma at gmail.com (Edzer Pebesma)
Date: Wed, 11 Aug 2010 22:18:05 +0200
Subject: [R-sig-Geo] Directional variograms with 3D data
In-Reply-To: <A632B3F93D861843A3C966F3962C3F8401080DD39972@EMAIL05.pnl.gov>
References: <A632B3F93D861843A3C966F3962C3F8401080DD39972@EMAIL05.pnl.gov>
Message-ID: <4C63057D.2080301@uni-muenster.de>

This is expected -- tol.vert is ignored because it should be tol.ver
(see docs).

The reason why you don't (can't!) get a warning is that it get absorbed
by the ... , which just passes on things not known (and hence accepts
anything).

On 08/11/2010 06:47 AM, Waichler, Scott R wrote:
> Hello,
> 
> I have a dataset with coordinates in x, y, z.  I would like to generate directional variograms, including ones for distinct horizontal and vertical directions, and fit models to them.  Apparently geoR does not accept 3D coordinates, so I am left with (?) gstat.  I have trouble understanding and applying the 5-parameter version of anis in gstat's vgm(), so I thought I would try generating one direction at a time, as below with a data frame called "han":
> 
> th.vg1 <- variogram(th ~ 1, han, alpha=0, tol.hor = 90, beta=0, tol.vert=30) # within 30 deg of horizontal  
> th.vg2 <- variogram(th ~ 1, han, alpha=0, tol.hor = 90, beta=90, tol.vert=30) # within 30 deg of vertical
> 
> th.vg1 and th.vg2 are identical; both are omnidirectional.  What do I need to do to to get distinct horizontal and vertical directions?
> 
> Scott Waichler
> Pacific Northwest National Laboratory
> P.O. Box 999, Richland, WA  99352
> scott.waichler at pnl.gov
> 509-372-4423, 509-341-4051 (cell)
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From p.hiemstra at geo.uu.nl  Thu Aug 12 11:24:06 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 12 Aug 2010 11:24:06 +0200
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <1281541367592-5412713.post@n2.nabble.com>
References: <1281445567867-5392938.post@n2.nabble.com>	<4C61537D.2020203@uni-muenster.de>	<1281452987970-5393442.post@n2.nabble.com>	<4C625932.2030900@geo.uu.nl>
	<1281541367592-5412713.post@n2.nabble.com>
Message-ID: <4C63BDB6.2010206@geo.uu.nl>

On 08/11/2010 05:42 PM, kad wrote:
> I use automap 1.0-7 with version R 2.11.0. My data
> http://r-sig-geo.2731867.n2.nabble.com/file/n5412713/k.txt k.txt
>    
That's your data, not an example of R code using the data, resulting in 
your error.

regards,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From elaine.kuo.tw at gmail.com  Thu Aug 12 13:05:23 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Thu, 12 Aug 2010 19:05:23 +0800
Subject: [R-sig-Geo] error in errorsarlm
In-Reply-To: <alpine.LRH.2.00.1008011544090.5518@reclus.nhh.no>
References: <AANLkTintGvKs7Y9AXUOLUeYPZwWtj2fH5ugltwhK-jm1@mail.gmail.com>
	<alpine.LRH.2.00.1007162144300.19802@reclus.nhh.no>
	<AANLkTik9muDJNtOG4lyJXl2Fk96c3CRDJAZ6dNJDntvq@mail.gmail.com>
	<alpine.LRH.2.00.1007171534310.22601@reclus.nhh.no>
	<AANLkTinWLIBpZQBFjANAgXkfXudfoUmGg8YGek3zD4R4@mail.gmail.com>
	<alpine.LRH.2.00.1007201614260.18432@reclus.nhh.no>
	<AANLkTik_BYkRFUMMC-Vr-UY0UfhOyJZ6HJfg98BDpndt@mail.gmail.com>
	<alpine.LRH.2.00.1007302053580.22750@reclus.nhh.no>
	<AANLkTimu=m7w2HiBNzfd-uvriokEPe+sy4BYVyh=ESRD@mail.gmail.com>
	<43E158B7-281C-4C5E-9B9E-7ACA2FAFAC82@gmail.com>
	<alpine.LRH.2.00.1008011544090.5518@reclus.nhh.no>
Message-ID: <AANLkTin=37DiqV7djubsppht44YLq5o5Nvgk3VDDm45c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100812/2fa22c7e/attachment.pl>

From elaine.kuo.tw at gmail.com  Thu Aug 12 13:12:50 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Thu, 12 Aug 2010 19:12:50 +0800
Subject: [R-sig-Geo] identical p-value of lm.LMtests (spdep)
Message-ID: <AANLkTimfcN4bETYV=vKPAO5CLOmL4ucQ_6cXtCTy_VAq@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100812/1a198baf/attachment.pl>

From Roger.Bivand at nhh.no  Thu Aug 12 14:02:20 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Aug 2010 14:02:20 +0200 (CEST)
Subject: [R-sig-Geo] error in errorsarlm
In-Reply-To: <AANLkTin=37DiqV7djubsppht44YLq5o5Nvgk3VDDm45c@mail.gmail.com>
References: <AANLkTintGvKs7Y9AXUOLUeYPZwWtj2fH5ugltwhK-jm1@mail.gmail.com>
	<alpine.LRH.2.00.1007162144300.19802@reclus.nhh.no>
	<AANLkTik9muDJNtOG4lyJXl2Fk96c3CRDJAZ6dNJDntvq@mail.gmail.com>
	<alpine.LRH.2.00.1007171534310.22601@reclus.nhh.no>
	<AANLkTinWLIBpZQBFjANAgXkfXudfoUmGg8YGek3zD4R4@mail.gmail.com>
	<alpine.LRH.2.00.1007201614260.18432@reclus.nhh.no>
	<AANLkTik_BYkRFUMMC-Vr-UY0UfhOyJZ6HJfg98BDpndt@mail.gmail.com>
	<alpine.LRH.2.00.1007302053580.22750@reclus.nhh.no>
	<AANLkTimu=m7w2HiBNzfd-uvriokEPe+sy4BYVyh=ESRD@mail.gmail.com>
	<43E158B7-281C-4C5E-9B9E-7ACA2FAFAC82@gmail.com>
	<alpine.LRH.2.00.1008011544090.5518@reclus.nhh.no>
	<AANLkTin=37DiqV7djubsppht44YLq5o5Nvgk3VDDm45c@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008121355050.7894@reclus.nhh.no>

On Thu, 12 Aug 2010, elaine kuo wrote:

> Dear List,
>
>
>
> Eventually computing lagsarlm and errorsarlm become successful,
>
> Using the code below. (maybe knearneigh helps to solve some issue.)
>
> (ref. An Introduction to Spatial Regression Analysis in R, Luc Anselin,
> 2003)

Or more recently Bivand et al. (2008) Applied Spatial Data Analysis with R 
(Springer), ch. 9-10, (see www.asdar-book.org).

I am concerned that you still do not know what you are doing!

You continue to use lat as your x dimension and lon as your y dimension, 
this is very confused and most likely wrong. In addition, because you do 
not work on this thread regularly (gaps of days or weeks), it is difficult 
to tell whether you are still working in decimal degrees, in which case 
your whole analysis is compromised - you should use cbind(lon, lat) then 
longlat=TRUE in all the neighbour finding steps to use Great Circle 
distances.

As I said at the beiginning of the thread, your use of arguments in 
functions is sloppy, and the reason why things now work is because you 
have changed some arguments. Whether the changes were appropriate or not 
is a very different question.

Roger

>
>
> Elaine
>
>
>
>
> code
>
>
>
> rm(list=ls())
>
> datam <-read.csv("c:/migration/Mig_ratio_20100808.csv",header=T,
> row.names=1)
>
>
>
> library(ncf)
>
> library(spdep)
>
>
>
>    # get the upper bound
>
>      up <- knearneigh(cbind(datam$lat,datam$lon))
>
>      upknn <- knn2nb(up)
>
>      updist1 <- nbdists(upknn,cbind(datam$lat,datam$lon))
>
>      updist1
>
>      updistvec <- unlist(updist1)
>
>      updistvec
>
>      upmaxd <- max(updistvec)
>
>      upmaxd
>
>
>
> # Define coordinates, neighbours, and spatial weights
>
>      coords<-cbind(datam$lat,datam$lon)
>
>      coords<-as.matrix(coords)
>
>
>
>    # Define neighbourhood (here distance 8)
>
>      nb8<-dnearneigh(coords,0,8.12)
>
>      summary(nb8)
>
>
>
>      #length(nb8)
>
>      #sum(card(nb8))
>
>
>
>    # Spatial weights, illustrated with coding style "W" (row standardized)
>
>      nb8.w<-nb2listw(nb8, glist=NULL, style="W")
>
>
>
>
>
>    # std model
>
>       datam.sd<-scale(datam)
>
>       datam.std<-as.data.frame(datam.sd)
>
>       summary (datam.std)
>
>       mean(datam.std)
>
>
>
>          # obtain standard deviation
>
>          sd(datam.std)
>
>
>
>       mig.std <-lm(datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>
>       summary(mig.std)
>
>
>
> # Spatial SAR error model
>
>    mignb8.err <- errorsarlm(datam.std$S ~ datam.std$coast +
> datam.std$topo_var +datam.std$prec_ran, data = datam.std, listw=nb8.w,
> na.action=na.omit, method="Matrix", zero.policy=TRUE)
>
>    summary(mignb8.err)
>
>
>
>
>
> # Spatial SAR lag model
>
>     mignb8.lag <- lagsarlm(datam.std$S ~ datam.std$coast +
> datam.std$topo_var +datam.std$prec_ran, data = datam.std, data=datam.std,
> listw=nb8.w, na.action=na.omit, method="Matrix", zero.policy=TRUE)
>
>     summary(mignb8.lag)
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Aug 12 14:06:52 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Aug 2010 14:06:52 +0200 (CEST)
Subject: [R-sig-Geo] identical p-value of lm.LMtests (spdep)
In-Reply-To: <AANLkTimfcN4bETYV=vKPAO5CLOmL4ucQ_6cXtCTy_VAq@mail.gmail.com>
References: <AANLkTimfcN4bETYV=vKPAO5CLOmL4ucQ_6cXtCTy_VAq@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008121402270.7894@reclus.nhh.no>

On Thu, 12 Aug 2010, elaine kuo wrote:

> Dear List,
>
> I wanna know if lag or error model is better to examine a spatial regression
> model.
> However, the results of their p-values are the same, which shows no
> difference between the models in the aspect.
> Please kindly help and thanks.

Given the possible errors in your construction of spatial weights in your 
other thread on this list, and the very high levels of residual 
correlation found here, I would not even start trying to consider this 
question. Unless you fully understand what the lag model does, and are an 
econometrician, avoid it. It makes little sense in other fields than 
spatial econometrics, and its interpretation is non-standard. So stay with 
errorsarlm() for error SAR models, or spautolm() for a wider selection of 
error models.

Roger

>
> Elaine
>
>
> code
>
> rm(list=ls())
> datam <-read.csv("c:/migration/Mig_ratio_20100808.csv",header=T,
> row.names=1)
>
> library(ncf)
> library(spdep)
>
>    # get the upper bound
>      up <- knearneigh(cbind(datam$lat,datam$lon))
>      upknn <- knn2nb(up)
>      updist1 <- nbdists(upknn,cbind(datam$lat,datam$lon))
>      updist1
>      updistvec <- unlist(updist1)
>      updistvec
>      upmaxd <- max(updistvec)
>      upmaxd
>
>    # Define coordinates, neighbours, and spatial weights
>      coords<-cbind(datam$lat,datam$lon)
>      coords<-as.matrix(coords)
>
>    # Define neighbourhood (here distance 8)
>      nb8<-dnearneigh(coords,0,8.12)
>      summary(nb8)
>
>      #length(nb8)
>      #sum(card(nb8))
>
>    # Spatial weights, illustrated with coding style "W" (row standardized)
>      nb8.w<-nb2listw(nb8, glist=NULL, style="W")
>
>    # std model
>       datam.sd<-scale(datam)
>       datam.std<-as.data.frame(datam.sd)
>       summary (datam.std)
>       mean(datam.std)
>
>          # obtain standard deviation
>          sd(datam.std)
>
>       mig.std <-lm( datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>       summary(mig.std)
>
>       mig.lagrange
> <-lm.LMtests(mig.std,nb8.w,test=c("LMerr","RLMerr","LMlag","RLMlag","SARMA"))
>
>       print(mig.lagrange)
>
>
>
>        Lagrange multiplier diagnostics for spatial dependence
>
>
>
> data:
>
> model: lm(formula = datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>
> weights: nb8.w
>
>
>
> LMerr = 79589.91, df = 1, p-value < 2.2e-16
>
>
>
>
>
>        Lagrange multiplier diagnostics for spatial dependence
>
>
>
> data:
>
> model: lm(formula = datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>
> weights: nb8.w
>
>
>
> RLMerr = 68943.02, df = 1, p-value < 2.2e-16
>
>
>
>
>
>        Lagrange multiplier diagnostics for spatial dependence
>
>
>
> data:
>
> model: lm(formula = datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>
> weights: nb8.w
>
>
>
> LMlag = 13000.91, df = 1, p-value < 2.2e-16
>
>
>
>
>
>        Lagrange multiplier diagnostics for spatial dependence
>
>
>
> data:
>
> model: lm(formula = datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>
> weights: nb8.w
>
>
>
> RLMlag = 2354.020, df = 1, p-value < 2.2e-16
>
>
>
>
>
>        Lagrange multiplier diagnostics for spatial dependence
>
>
>
> data:
>
> model: lm(formula = datam.std$S ~ datam.std$coast + datam.std$topo_var
> +datam.std$prec_ran, data = datam.std)
>
> weights: nb8.w
>
>
>
> SARMA = 81943.93, df = 2, p-value < 2.2e-16
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From breitbach at uni-mainz.de  Thu Aug 12 15:25:14 2010
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Thu, 12 Aug 2010 13:25:14 +0000
Subject: [R-sig-Geo] Spatial Autocorrelation for point data
In-Reply-To: <E7F1EF063B11DA4DAD16374549B879E82AD860A5@e14mdb-02.zdv.Uni-Mainz.DE>
References: <E7F1EF063B11DA4DAD16374549B879E82AD860A5@e14mdb-02.zdv.Uni-Mainz.DE>
Message-ID: <E7F1EF063B11DA4DAD16374549B879E82AD860B9@e14mdb-02.zdv.Uni-Mainz.DE>

Dear Community,

I hope that my question is not misplaced here, but I do not know where (and whom) to ask other than here. My problem concerns methodical issues as well as the search for the right R function.

For a quite some time I work with spatial data and I was now asked to test my data for spatial autocorrelation. The more I read on that topic, the more uncertain I am if this kind of analyses is really made for my kind of data. I work on plots distributed over a study area of not more than 30 x 30 km. These plots are point data in the sense of point coordinates. Two locations are at least 4 km apart but not evenly distributed over the area. For these plots I have data on species richness and habitat. So far I did all my analyses using vector data sets (in the form of shape files) and never used raster data. So far I have often been told simply to use Moran's I for my analyses of spatial autocorrelation because everybody else is using it. And hey, never touch a running system so why should we use something different. But I am unaware if this kind of analysis really works with data that are not organised in grid cells (i.e. raster data). I mean, it works and I get values but are these values reliable, when I use point data with no information in between? My Moran's I correlograms follow a zig zack pattern in my trials.

I will probably never come to the level that I fully understand the underlying mathematics behind the latest statistical methods but I hope that I at least come to a level that enables me to judge what method should be used for a particular kind of data and/or problem. For many analyses it has been stated that they are mainly for the analysis of global data or should be applied on larger spatial scales. So which kind of analysis is best for my small spatial data set and how can I get meaningful results for my analysis of spatial autocorrelation with R? Should I use Moran's I or Geary C or something completely different? Is it necessary to transform my data into raster data or do the test also work with point data? How many neighbours should I choose? (I tried 2 and 4 so far)

Cheers,

Nils


From kadraamrane at hotmail.fr  Thu Aug 12 18:10:26 2010
From: kadraamrane at hotmail.fr (kad)
Date: Thu, 12 Aug 2010 09:10:26 -0700 (PDT)
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <4C63BDB6.2010206@geo.uu.nl>
References: <1281445567867-5392938.post@n2.nabble.com>
	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
	<4C625932.2030900@geo.uu.nl>
	<1281541367592-5412713.post@n2.nabble.com>
	<4C63BDB6.2010206@geo.uu.nl>
Message-ID: <1281629426609-5416771.post@n2.nabble.com>



that's my code R,I hope that I understood your request.
KAD 
  

http://r-sig-geo.2731867.n2.nabble.com/file/n5416771/codeR.R codeR.R 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p5416771.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From elaine.kuo.tw at gmail.com  Fri Aug 13 00:09:59 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Fri, 13 Aug 2010 06:09:59 +0800
Subject: [R-sig-Geo] identical p-value of lm.LMtests (spdep)
In-Reply-To: <alpine.LRH.2.00.1008121402270.7894@reclus.nhh.no>
References: <AANLkTimfcN4bETYV=vKPAO5CLOmL4ucQ_6cXtCTy_VAq@mail.gmail.com>
	<alpine.LRH.2.00.1008121402270.7894@reclus.nhh.no>
Message-ID: <AANLkTinAgs27=2JFOX4oVJgf8Wu-CqwriWzqArqBsTat@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100813/2ac22f7b/attachment.pl>

From p.hiemstra at geo.uu.nl  Fri Aug 13 09:50:10 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 13 Aug 2010 09:50:10 +0200
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <1281629426609-5416771.post@n2.nabble.com>
References: <1281445567867-5392938.post@n2.nabble.com>	<4C61537D.2020203@uni-muenster.de>	<1281452987970-5393442.post@n2.nabble.com>	<4C625932.2030900@geo.uu.nl>	<1281541367592-5412713.post@n2.nabble.com>	<4C63BDB6.2010206@geo.uu.nl>
	<1281629426609-5416771.post@n2.nabble.com>
Message-ID: <4C64F932.3060003@geo.uu.nl>

On 08/12/2010 06:10 PM, kad wrote:
>
> that's my code R,I hope that I understood your request.
> KAD
>
>
> http://r-sig-geo.2731867.n2.nabble.com/file/n5416771/codeR.R codeR.R
>    
Hi,

 From which package are the functions EchanAlea and EchanX? And the 
Parcelle object is not created in the script. I can't run the script 
myself to see what goes wrong.

cheers,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From patrick.giraudoux at univ-fcomte.fr  Fri Aug 13 14:10:48 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 13 Aug 2010 14:10:48 +0200
Subject: [R-sig-Geo] subsetting a SpatialGridDataFrame
	image.SpatialGridDataFrame
Message-ID: <4C653648.1060908@univ-fcomte.fr>

  Hi,

I am trying to subset a SpatialGridDataFrame object as following:

idx<-ChinaTempUTM47 at data[,1]>10 # select elements of column1  whose 
values are > 10
idx[is.na(idx)]<-FALSE # make a vector of class "logical" (replacing NA 
by FALSE)

and this gives:

ChinaTempUTM47[idx,]
Error in ChinaTempUTM47[idx, ] : (subscript) logical subscript too long

However,

 > length(idx)
[1] 13536
 > nrow(ChinaTempUTM47 at data)
[1] 13536


So, I canot sort out what happens.

Any hint welcome

Patrick


From Roger.Bivand at nhh.no  Fri Aug 13 14:31:06 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 13 Aug 2010 14:31:06 +0200 (CEST)
Subject: [R-sig-Geo] subsetting a SpatialGridDataFrame
 image.SpatialGridDataFrame
In-Reply-To: <4C653648.1060908@univ-fcomte.fr>
References: <4C653648.1060908@univ-fcomte.fr>
Message-ID: <alpine.LRH.2.00.1008131423230.12074@reclus.nhh.no>

On Fri, 13 Aug 2010, Patrick Giraudoux wrote:

>
> Hi,
>
> I am trying to subset a SpatialGridDataFrame object as following:
>
> idx<-ChinaTempUTM47 at data[,1]>10 # select elements of column1  whose values 
> are > 10
> idx[is.na(idx)]<-FALSE # make a vector of class "logical" (replacing NA by 
> FALSE)
>
> and this gives:
>
> ChinaTempUTM47[idx,]
> Error in ChinaTempUTM47[idx, ] : (subscript) logical subscript too long
>
> However,
>
>> length(idx)
> [1] 13536
>> nrow(ChinaTempUTM47 at data)
> [1] 13536
>

This was discussed in:

https://stat.ethz.ch/pipermail/r-sig-geo/2010-August/008973.html

Use one of the solutions suggested there, and note that the "[" method for 
SpatialGridDataFrame takes [ row, col, band, ...], like an array but not 
like a data.frame; see ?"SpatialGridDataFrame-class". You could also 
coerce to SpatialPixelsDataFrame, which then behaves like a data.frame, 
not an array.

Hope this helps,

Roger

>
> So, I canot sort out what happens.
>
> Any hint welcome
>
> Patrick
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From nikhil.list at gmail.com  Fri Aug 13 14:30:04 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Fri, 13 Aug 2010 08:30:04 -0400
Subject: [R-sig-Geo] subsetting a SpatialGridDataFrame
	image.SpatialGridDataFrame
In-Reply-To: <4C653648.1060908@univ-fcomte.fr>
References: <4C653648.1060908@univ-fcomte.fr>
Message-ID: <54E2B5E7-4EC9-4279-B1BA-B873815D4936@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100813/1045f7ec/attachment.pl>

From patrick.giraudoux at univ-fcomte.fr  Fri Aug 13 15:33:16 2010
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 13 Aug 2010 15:33:16 +0200
Subject: [R-sig-Geo] subsetting a SpatialGridDataFrame
	image.SpatialGridDataFrame
In-Reply-To: <alpine.LRH.2.00.1008131423230.12074@reclus.nhh.no>
References: <4C653648.1060908@univ-fcomte.fr>
	<alpine.LRH.2.00.1008131423230.12074@reclus.nhh.no>
Message-ID: <4C65499C.5070400@univ-fcomte.fr>

  Thank you both, that is very clear now. SpatialPixelsDataFrame objects 
can be "indexed" as a data frame, but not SpatialGridDataFrame where 
row, col, band must be specified (thanks also not to have written, 
please read the doc, which was all what I deserved..)

Actually, my question was simplified  with regard to what I intend to 
do: to display pixels selected on their value. With the meuse example 
and after your explanations, this gives:

data(meuse.grid)
coordinates(meuse.grid)<-~x+y
gridded(meuse.grid)<-TRUE
names(meuse.grid at data)

idx<-meuse.grid at data$dist<0.1
image(meuse.grid[idx,],useRasterImage=F)

... and it works well.

Well, looks like if a similar selection was quite hard to achieve 
straightfully  with a SpatialGridDataFrame, as long as each row and col 
number should be identified according to the criterion (eg 
meuse.grid at data$dist<0.1). Then I suppose that the simplest way is to 
coerce SpatialGridDataFrame to SpatialPixelsDataFrame. Agreed ?

Patrick



Le 13/08/2010 14:31, Roger Bivand a ?crit :
> On Fri, 13 Aug 2010, Patrick Giraudoux wrote:
>
>>
>> Hi,
>>
>> I am trying to subset a SpatialGridDataFrame object as following:
>>
>> idx<-ChinaTempUTM47 at data[,1]>10 # select elements of column1  whose 
>> values are > 10
>> idx[is.na(idx)]<-FALSE # make a vector of class "logical" (replacing 
>> NA by FALSE)
>>
>> and this gives:
>>
>> ChinaTempUTM47[idx,]
>> Error in ChinaTempUTM47[idx, ] : (subscript) logical subscript too long
>>
>> However,
>>
>>> length(idx)
>> [1] 13536
>>> nrow(ChinaTempUTM47 at data)
>> [1] 13536
>>
>
> This was discussed in:
>
> https://stat.ethz.ch/pipermail/r-sig-geo/2010-August/008973.html
>
> Use one of the solutions suggested there, and note that the "[" method 
> for SpatialGridDataFrame takes [ row, col, band, ...], like an array 
> but not like a data.frame; see ?"SpatialGridDataFrame-class". You 
> could also coerce to SpatialPixelsDataFrame, which then behaves like a 
> data.frame, not an array.
>
> Hope this helps,
>
> Roger
>
>>
>> So, I canot sort out what happens.
>>
>> Any hint welcome
>>
>> Patrick
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From b.rowlingson at lancaster.ac.uk  Fri Aug 13 16:37:22 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 13 Aug 2010 15:37:22 +0100
Subject: [R-sig-Geo] polygon adjacency testing
Message-ID: <AANLkTinpkEFw+zErBZV-9_LRXHE5qKrtLqiPBe-XG_X+@mail.gmail.com>

I've used poly2nb from spdep quite a bit, and occasionally it's shown
up some errors in polygon data sets. For example, in the scottish data
distributed with rgdal you'll see some rather wacky adjacencies:

library(rgdal)
scot=readOGR(system.file("vectors",package="rgdal"),"scot_BNG")

library(spdep)
nb = poly2nb(scot)

plot(scot)
plot(nb,coordinates(scot),add=TRUE,col="blue")

There are some adjacency lines that go right across scotland (these
would be clearer if you could choose different colours for each
adjacency line, but it seems the plot method only uses the first
colour of the col vector). Further investigation shows them to be due
to slivers adjacent to areas remote from the main area, but in the
same feature.

 Anyway, inspection of this kind of adjacency line map shows that in
general, the adjacency lines drawn between centroids tend not to cross
over one another if the data is well-behaved. So I started thinking
about how to test if a set of line segments overlap.

 The rgeos LinesIntersection function almost works, except it counts
two lines as intersecting if they start or end at the same point.
Since so many adjacency lines do this, it might be hard to filter out
false positives, although maybe it could be done since you know the
polygon feature id and there's no point testing the intersection of
lines with the same polygon feature id... hmmm thinking out loud here
but maybe it will work...

 So anyway, anyone got an easy way of going from nb and
coordinates(scot) to something that can be fed to
rgeos:LinesIntersection to see which adjacency lines cross?

Barry

-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From SRuiter at nscr.nl  Fri Aug 13 16:51:16 2010
From: SRuiter at nscr.nl (Stijn Ruiter)
Date: Fri, 13 Aug 2010 16:51:16 +0200
Subject: [R-sig-Geo] extract only some polygons from shp-file
Message-ID: <6F935AB43360774EB2A937510A67E5D30CECC965C3@exchsvr1.arthur.nscr.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100813/0895a633/attachment.pl>

From werner at wirtschaft.uni-kassel.de  Fri Aug 13 17:08:24 2010
From: werner at wirtschaft.uni-kassel.de (Alexander Werner)
Date: Fri, 13 Aug 2010 17:08:24 +0200
Subject: [R-sig-Geo] extract only some polygons from shp-file
In-Reply-To: <6F935AB43360774EB2A937510A67E5D30CECC965C3@exchsvr1.arthur.nscr.nl>
References: <6F935AB43360774EB2A937510A67E5D30CECC965C3@exchsvr1.arthur.nscr.nl>
Message-ID: <4C655FE8.6040304@wirtschaft.uni-kassel.de>

Dear Stijn,

you may try something like

Map_City=Map_Complete[Map_Complete$City_variable==CityValue,]

Alexander

Stijn Ruiter schrieb:
> Dear all,
> I am new to spatial data handling/modeling in R. Could you please help me with the following?
> I have a shp-file of class 'SpatialPolygonsDataFrame', so it contains additional variables. I would like to select only those spatial objects that have a certain score on one of these additional variables. To be more precise, I have polygons of neighborhoods. These neighborhoods belong to different cities (which is recorded in one of the additional variables). I'd like to select only those polygons belonging to a single city and keep all additional variables for those polygons.
> Thanks in advance,
> Stijn
>
> --
>
> Stijn Ruiter
> Senior Researcher
> Netherlands Institute for the Study of Crime and Law Enforcement NSCR
>
> Postal address:
> PO Box 71304
> 1008 BH AMSTERDAM
>
> Visiting address:
> De Boelelaan 1105
> Room 2D38
> 1081 HV AMSTERDAM
>
> Office phone: +31 (0) 20 5985427
> Phone secretary: +31 (0) 20 5985239
> Fax secretary: +31 (0)20 5983975
>
> Web site: stijnruiter.nl<http://www.stijnruiter.nl/>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>   

-- 
Dipl.-?k. Alexander Werner
_______________________________________________
Universit?t Kassel
Fachbereich Wirtschaftswissenschaften
Fachgebiet Empirische Wirtschaftsforschung
Nora-Platiel-Str. 4
34109 Kassel

Tel.: 0561 / 804 - 3044
werner at wirtschaft.uni-kassel.de
http://cms.uni-kassel.de/unicms/index.php?id=fb7_ivwl_eckey


From kadraamrane at hotmail.fr  Fri Aug 13 17:11:58 2010
From: kadraamrane at hotmail.fr (kad)
Date: Fri, 13 Aug 2010 08:11:58 -0700 (PDT)
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <4C64F932.3060003@geo.uu.nl>
References: <1281445567867-5392938.post@n2.nabble.com>
	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
	<4C625932.2030900@geo.uu.nl>
	<1281541367592-5412713.post@n2.nabble.com>
	<4C63BDB6.2010206@geo.uu.nl>
	<1281629426609-5416771.post@n2.nabble.com>
	<4C64F932.3060003@geo.uu.nl>
Message-ID: <1281712318233-5420382.post@n2.nabble.com>


Excuse me,here's the data that you lack.
The first is the data Parcelle,and the second are  the functions.
I execut  the  SIMULATION  script then I do the kriging.
Thanks

. http://r-sig-geo.2731867.n2.nabble.com/file/n5420382/donneesStage.csv
donneesStage.csv 
http://r-sig-geo.2731867.n2.nabble.com/file/n5420382/SIMULATIONS_%282%29.R
SIMULATIONS_%282%29.R 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p5420382.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From kadraamrane at hotmail.fr  Fri Aug 13 17:14:43 2010
From: kadraamrane at hotmail.fr (kad)
Date: Fri, 13 Aug 2010 08:14:43 -0700 (PDT)
Subject: [R-sig-Geo] Error autoKrige
In-Reply-To: <4C64F932.3060003@geo.uu.nl>
References: <1281445567867-5392938.post@n2.nabble.com>
	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
	<4C625932.2030900@geo.uu.nl>
	<1281541367592-5412713.post@n2.nabble.com>
	<4C63BDB6.2010206@geo.uu.nl>
	<1281629426609-5416771.post@n2.nabble.com>
	<4C64F932.3060003@geo.uu.nl>
Message-ID: <1281712483086-5420396.post@n2.nabble.com>


Excuse me,here's the data that you lack.
The first is the data Parcelle,and the second are  the functions.
I execut  the  SIMULATION  script then I do the kriging.
http://r-sig-geo.2731867.n2.nabble.com/file/n5420396/donneesStage.csv
donneesStage.csv 

http://r-sig-geo.2731867.n2.nabble.com/file/n5420396/SIMULATIONS_%282%29.R
SIMULATIONS_%282%29.R 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p5420396.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From nikhil.list at gmail.com  Fri Aug 13 17:59:31 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Fri, 13 Aug 2010 11:59:31 -0400
Subject: [R-sig-Geo] polygon adjacency testing
In-Reply-To: <AANLkTinpkEFw+zErBZV-9_LRXHE5qKrtLqiPBe-XG_X+@mail.gmail.com>
References: <AANLkTinpkEFw+zErBZV-9_LRXHE5qKrtLqiPBe-XG_X+@mail.gmail.com>
Message-ID: <1DF060F2-5ED1-4826-9E59-7CA57C7CFD5D@gmail.com>


I havent looked at poly2nb code, but would eliminating polygons from  
the polygon list based on area, perimeter  or ratio of these two,  
before constructing the neighbour list work? This would be similar,  
not identical, to eliminate in ArcInfo.
http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?TopicName=Eliminate%20%28Data%20Management%29

Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 13, 2010, at 10:37 AM, Barry Rowlingson wrote:

> I've used poly2nb from spdep quite a bit, and occasionally it's shown
> up some errors in polygon data sets. For example, in the scottish data
> distributed with rgdal you'll see some rather wacky adjacencies:
>
> library(rgdal)
> scot=readOGR(system.file("vectors",package="rgdal"),"scot_BNG")
>
> library(spdep)
> nb = poly2nb(scot)
>
> plot(scot)
> plot(nb,coordinates(scot),add=TRUE,col="blue")
>
> There are some adjacency lines that go right across scotland (these
> would be clearer if you could choose different colours for each
> adjacency line, but it seems the plot method only uses the first
> colour of the col vector). Further investigation shows them to be due
> to slivers adjacent to areas remote from the main area, but in the
> same feature.
>
> Anyway, inspection of this kind of adjacency line map shows that in
> general, the adjacency lines drawn between centroids tend not to cross
> over one another if the data is well-behaved. So I started thinking
> about how to test if a set of line segments overlap.
>
> The rgeos LinesIntersection function almost works, except it counts
> two lines as intersecting if they start or end at the same point.
> Since so many adjacency lines do this, it might be hard to filter out
> false positives, although maybe it could be done since you know the
> polygon feature id and there's no point testing the intersection of
> lines with the same polygon feature id... hmmm thinking out loud here
> but maybe it will work...
>
> So anyway, anyone got an easy way of going from nb and
> coordinates(scot) to something that can be fed to
> rgeos:LinesIntersection to see which adjacency lines cross?
>
> Barry
>
> -- 
> blog: http://geospaced.blogspot.com/
> web: http://www.maths.lancs.ac.uk/~rowlings
> web: http://www.rowlingson.com/
> twitter: http://twitter.com/geospacedman
> pics: http://www.flickr.com/photos/spacedman
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From b.rowlingson at lancaster.ac.uk  Fri Aug 13 18:14:41 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 13 Aug 2010 17:14:41 +0100
Subject: [R-sig-Geo] polygon adjacency testing
In-Reply-To: <1DF060F2-5ED1-4826-9E59-7CA57C7CFD5D@gmail.com>
References: <AANLkTinpkEFw+zErBZV-9_LRXHE5qKrtLqiPBe-XG_X+@mail.gmail.com>
	<1DF060F2-5ED1-4826-9E59-7CA57C7CFD5D@gmail.com>
Message-ID: <AANLkTinTgUgLHp42idCJCoBZB3gBaKYrF-zmD+fPyJqm@mail.gmail.com>

On Fri, Aug 13, 2010 at 4:59 PM, Nikhil Kaza <nikhil.list at gmail.com> wrote:
>
> I havent looked at poly2nb code, but would eliminating polygons from the
> polygon list based on area, perimeter ?or ratio of these two, before
> constructing the neighbour list work? This would be similar, not identical,
> to eliminate in ArcInfo.
> http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?TopicName=Eliminate%20%28Data%20Management%29

 That's okay for general cleanups of slivers etc, but it wont catch
other problems that might manifest themselves via adjacency. My
substantive problem uses polygon adjacency in its model, so I was
hoping for a way of assessing the correctness of the adjacency graph.

 I'm pretty sure I can do it with LinesIntersections from rgeos now,
its just a bit of a grind to get rid of all the intersections from
coincident endpoints. nb2lines is also useful.

Barry


From edzer.pebesma at uni-muenster.de  Sat Aug 14 12:05:49 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 14 Aug 2010 12:05:49 +0200
Subject: [R-sig-Geo] subsetting a
	SpatialGridDataFrame	image.SpatialGridDataFrame
In-Reply-To: <4C65499C.5070400@univ-fcomte.fr>
References: <4C653648.1060908@univ-fcomte.fr>	<alpine.LRH.2.00.1008131423230.12074@reclus.nhh.no>
	<4C65499C.5070400@univ-fcomte.fr>
Message-ID: <4C666A7D.6030000@uni-muenster.de>



On 08/13/2010 03:33 PM, Patrick Giraudoux wrote:
>  Thank you both, that is very clear now. SpatialPixelsDataFrame objects
> can be "indexed" as a data frame, but not SpatialGridDataFrame where
> row, col, band must be specified (thanks also not to have written,
> please read the doc, which was all what I deserved..)
> 
> Actually, my question was simplified  with regard to what I intend to
> do: to display pixels selected on their value. With the meuse example
> and after your explanations, this gives:
> 
> data(meuse.grid)
> coordinates(meuse.grid)<-~x+y
> gridded(meuse.grid)<-TRUE
> names(meuse.grid at data)
> 
> idx<-meuse.grid at data$dist<0.1
> image(meuse.grid[idx,],useRasterImage=F)
> 
> ... and it works well.
> 
> Well, looks like if a similar selection was quite hard to achieve
> straightfully  with a SpatialGridDataFrame, as long as each row and col
> number should be identified according to the criterion (eg
> meuse.grid at data$dist<0.1). Then I suppose that the simplest way is to
> coerce SpatialGridDataFrame to SpatialPixelsDataFrame. Agreed ?

Yes.  You can obtain a similar picture from a SpatialGridDataFrame by
the following construct:

fullgrid(meuse.grid) = TRUE
class(meuse.grid) # now SpatialGridDataFrame
meuse.grid$part.a.sel = meuse.grid$part.a
meuse.grid$part.a.sel[meuse.grid$dist >= 0.1] = NA
image(meuse.grid[,,"part.a.sel"],useRasterImage=F)

As it shows, no selection takes place, but masking by setting the
deselected grid cells to NA. SpatialGridDataFrame's always store the
full grid; only after selecting a subset of rows/cols a smaller object
is obtained, but as a new (full) grid, not a set of pixels like
SpatialPixelsDataFrame.

> 
> Patrick
> 
> 
> 
> Le 13/08/2010 14:31, Roger Bivand a ?crit :
>> On Fri, 13 Aug 2010, Patrick Giraudoux wrote:
>>
>>>
>>> Hi,
>>>
>>> I am trying to subset a SpatialGridDataFrame object as following:
>>>
>>> idx<-ChinaTempUTM47 at data[,1]>10 # select elements of column1  whose
>>> values are > 10
>>> idx[is.na(idx)]<-FALSE # make a vector of class "logical" (replacing
>>> NA by FALSE)
>>>
>>> and this gives:
>>>
>>> ChinaTempUTM47[idx,]
>>> Error in ChinaTempUTM47[idx, ] : (subscript) logical subscript too long
>>>
>>> However,
>>>
>>>> length(idx)
>>> [1] 13536
>>>> nrow(ChinaTempUTM47 at data)
>>> [1] 13536
>>>
>>
>> This was discussed in:
>>
>> https://stat.ethz.ch/pipermail/r-sig-geo/2010-August/008973.html
>>
>> Use one of the solutions suggested there, and note that the "[" method
>> for SpatialGridDataFrame takes [ row, col, band, ...], like an array
>> but not like a data.frame; see ?"SpatialGridDataFrame-class". You
>> could also coerce to SpatialPixelsDataFrame, which then behaves like a
>> data.frame, not an array.
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> So, I canot sort out what happens.
>>>
>>> Any hint welcome
>>>
>>> Patrick
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From hilton at meteo.psu.edu  Sat Aug 14 19:51:25 2010
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Sat, 14 Aug 2010 10:51:25 -0700
Subject: [R-sig-Geo] geoR likfit: confusing AIC results?
Message-ID: <20100814175125.GA16892@Tim.local>

Dear R-sig-geo readers,

I am trying to use geoR's likfit to determine whether some spatial
fields are better described by an exponential semivariogram or a pure
nugget semivariogram.  To investigate the frequency of a 'false
positive', where my test picks the exponential semivariogram when
there is in fact no spatial correlation in the field, I ran the
following experiment:

I used geoR's grf function to create ten different Gaussian random
fields (GRFs) with phi = 0.0, sigmasq = 0.001, and nugget = 3.0.  For
each GRF I use geoR's likfit to fit 50 exponential covariance models
and 50 pure nugget covariance models.  Within each set of 50 models, I
chose the lowest AIC (as reported by likfit) as the "best" fit.

Because the GRFs were generated with no spatial correlation, I
expected the best-fit pure nugget AIC to be lower than the best-fit
exponential AIC in the majority of cases.  Across my ten experiements,
though, the best-fit exponential AIC was lower eight times, and the
best-fit pure nugget AIC was lower only once (the other was a tie).

This concerns me, as it suggests than many of my fields that I had
concluded *do* have spatial structure in fact may not.

Am I misusing the AIC result from likfit to choose a covariance
structure?  I will greatly appreciate any advice the list can offer.

A more detailed description of my experiment, code, and results follow
below.

many thanks,
Tim

--

Timothy W. Hilton
PhD Candidate, Department of Meteorology
The Pennsylvania State University
503 Walker Building, University Park, PA   16802
hilton at meteo.psu.edu

==================================================

For each of the ten GRFs, I used likfit to estimate parameters for
exponential covariance model 50 times.  Each likfit began with initial
covariance parameters drawn randomly from uniform distributions within
(0,10) for sigmasq, (0,1000) for phi, and (0,10) for the nugget.  To
estimate the pure nugget parameters, I again ran likfit 50 times with
initial covariance parameters of phi = 0.0, sigmasq = 0.001, and
nugget = 3.0.

==================================================

Resulting AIC for best-fit model for each of the ten GRFs.
Exponential (exp) is less than pure nugget (PN) in eight of ten cases.

         PN      exp
1  251.9389 251.6512
2  276.7283 276.3321
3  252.2566 252.2566
4  227.2106 227.2106
5  251.4253 251.4252
6  268.3910 268.3910
7  259.6977 257.8298
8  254.6102 247.9796
9  262.4842 262.0296
10 258.1551 257.4813

==================================================

The R code I used.  It took about ten minutes to complete on my
notebook computer.

#----------------------------------------------------------------------
getGRFRealizations <- function(nsim=1) {
                               
  phi <- 0.0
  sigmasq <- 0.001
  nug <- 3.0
  
  realizations <- grf(n=65,
                      xlims=c(0, 6000),
                      ylims=c(0, 6000),
                      nsim=nsim,
                      cov.model='pure.nugget',
                      cov.pars=c(sigmasq, phi),
                      nugget=nug)
  return(realizations)
}

#----------------------------------------------------------------------
# performs likfit for a Gaussian Random Field (fld) multiple times
# with initial covariance parameters drawn from a uniform distribution
# within a window.  Returns the fit with the lowest AIC.
multi.likfit <- function(nfits=50, data, coords, cov.model) {

  if (cov.model == 'exponential')
    pars <- c(runif(n=1, min=0, max=10),
              runif(n=1, min=0, max=1000))
  else
    pars <- c(0.001, 0.0)  ## for pure nugget

  # estimate one fit
  best.so.far <- likfit(data=data,
                        coords=coords,
                        cov.model=cov.model,
                        ini.cov.pars=pars,
                        nugget=runif(n=1, min=0, max=10),
                        messages=FALSE)
  # do the rest of the fits, keep the lowest AIC
  for (i in 2:nfits) {
    this.fit <- likfit(data=data,
                       coords=coords,
                       cov.model=cov.model,
                       ini.cov.pars=pars,
                       nugget=runif(n=1, min=0, max=10),
                       messages=FALSE)
    if (this.fit$AIC < best.so.far$AIC)
      best.so.far <- this.fit
  }
  return(best.so.far)
}
    
#----------------------------------------------------------------------
fitGRFRealizations <- function(nsim=5, nfits=50) {

  #allocate lists to hold the covariance model fits
  fits.list.exp <- vector(mode='list', length=nsim) #for exponential fits
  fits.list.PN <- vector(mode='list', length=nsim)  #for pure nugget fits
  #generate random field realizations
  flds <- getGRFRealizations(nsim=nsim)

  #fit covariance model to each of the random fields
  for (i in 1:nsim) {
    fits.list.exp[[i]] <- multi.likfit(nfits=50,
                                       data=flds$data[, i],
                                       coords=flds$coords,
                                       cov.model='exponential')
    fits.list.PN[[i]] <- multi.likfit(nfits=50,
                                      data=flds$data[, i],
                                      coords=flds$coords,
                                      cov.model='pure.nugget')
    cat('.')  # crude progress bar
  }
  cat('\n')
  return(list(exponential=fits.list.exp, pure.nugget=fits.list.PN))
}

#----------------------------------------------------------------------
gatherFits <- function(fits.list) {
  phi <- unlist(lapply(fits.list, function(x) x[['phi']]))
  sigmasq <- unlist(lapply(fits.list, function(x) x[['sigmasq']]))
  nugget <- unlist(lapply(fits.list, function(x) x[['nugget']]))
  pRange <- unlist(lapply(fits.list, function(x) x[['practicalRange']]))
  AIC <- unlist(lapply(fits.list, function(x) x[['AIC']]))
  df <- data.frame(phi=phi, sigmasq=sigmasq, nugget=nugget, pRange=pRange, AIC=AIC)
  return(df)
}

result <- fitGRFRealizations(nsim=10)
df <- data.frame(PN.AIC=unlist(lapply(result[['pure.nugget']], function(x) x$AIC)),
                 exp.AIC=unlist(lapply(result[['exponential']], function(x) x$AIC)))


From paulojus at c3sl.ufpr.br  Sat Aug 14 22:26:07 2010
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Sat, 14 Aug 2010 17:26:07 -0300 (BRT)
Subject: [R-sig-Geo] geoR likfit: confusing AIC results?
In-Reply-To: <20100814175125.GA16892@Tim.local>
References: <20100814175125.GA16892@Tim.local>
Message-ID: <alpine.DEB.2.00.1008141646220.19485@macalan.c3sl.ufpr.br>

Dear Thimothy

I will have a ore detailed look at your study to inspect this better.

However, I'd like to points some issues I've detected in a first glence to 
you code:

1. your area is of the size 6000x6000
This is related with distances and order of magnitude of the parameters, 
in particular to phi.
Since you total variances are around 3 the maximization may need some 
tunung for dealing with different oreders or magnitude

    1.a a simple suggestion would be replace 6000 by 6 and see whether it
        change the estimates
    1.b an alternative would be to pass values of fnscale to the optimizer 
(optim) through the appropriated ... mechanism

2. Notice that summary() on a likfit object (or elements of the list) 
already give you the fit and likelihood values for the pure nugget 
(independence) model such that you do not need to run the maximizer over 
it

best
P.J.



Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
VOIP: (+55) (41) (3361 3600) 1053 1066
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus

On Sat, 14 Aug 2010, Timothy W. Hilton wrote:

> Dear R-sig-geo readers,
>
> I am trying to use geoR's likfit to determine whether some spatial
> fields are better described by an exponential semivariogram or a pure
> nugget semivariogram.  To investigate the frequency of a 'false
> positive', where my test picks the exponential semivariogram when
> there is in fact no spatial correlation in the field, I ran the
> following experiment:
>
> I used geoR's grf function to create ten different Gaussian random
> fields (GRFs) with phi = 0.0, sigmasq = 0.001, and nugget = 3.0.  For
> each GRF I use geoR's likfit to fit 50 exponential covariance models
> and 50 pure nugget covariance models.  Within each set of 50 models, I
> chose the lowest AIC (as reported by likfit) as the "best" fit.
>
> Because the GRFs were generated with no spatial correlation, I
> expected the best-fit pure nugget AIC to be lower than the best-fit
> exponential AIC in the majority of cases.  Across my ten experiements,
> though, the best-fit exponential AIC was lower eight times, and the
> best-fit pure nugget AIC was lower only once (the other was a tie).
>
> This concerns me, as it suggests than many of my fields that I had
> concluded *do* have spatial structure in fact may not.
>
> Am I misusing the AIC result from likfit to choose a covariance
> structure?  I will greatly appreciate any advice the list can offer.
>
> A more detailed description of my experiment, code, and results follow
> below.
>
> many thanks,
> Tim
>
> --
>
> Timothy W. Hilton
> PhD Candidate, Department of Meteorology
> The Pennsylvania State University
> 503 Walker Building, University Park, PA   16802
> hilton at meteo.psu.edu
>
> ==================================================
>
> For each of the ten GRFs, I used likfit to estimate parameters for
> exponential covariance model 50 times.  Each likfit began with initial
> covariance parameters drawn randomly from uniform distributions within
> (0,10) for sigmasq, (0,1000) for phi, and (0,10) for the nugget.  To
> estimate the pure nugget parameters, I again ran likfit 50 times with
> initial covariance parameters of phi = 0.0, sigmasq = 0.001, and
> nugget = 3.0.
>
> ==================================================
>
> Resulting AIC for best-fit model for each of the ten GRFs.
> Exponential (exp) is less than pure nugget (PN) in eight of ten cases.
>
>         PN      exp
> 1  251.9389 251.6512
> 2  276.7283 276.3321
> 3  252.2566 252.2566
> 4  227.2106 227.2106
> 5  251.4253 251.4252
> 6  268.3910 268.3910
> 7  259.6977 257.8298
> 8  254.6102 247.9796
> 9  262.4842 262.0296
> 10 258.1551 257.4813
>
> ==================================================
>
> The R code I used.  It took about ten minutes to complete on my
> notebook computer.
>
> #----------------------------------------------------------------------
> getGRFRealizations <- function(nsim=1) {
>
>  phi <- 0.0
>  sigmasq <- 0.001
>  nug <- 3.0
>
>  realizations <- grf(n=65,
>                      xlims=c(0, 6000),
>                      ylims=c(0, 6000),
>                      nsim=nsim,
>                      cov.model='pure.nugget',
>                      cov.pars=c(sigmasq, phi),
>                      nugget=nug)
>  return(realizations)
> }
>
> #----------------------------------------------------------------------
> # performs likfit for a Gaussian Random Field (fld) multiple times
> # with initial covariance parameters drawn from a uniform distribution
> # within a window.  Returns the fit with the lowest AIC.
> multi.likfit <- function(nfits=50, data, coords, cov.model) {
>
>  if (cov.model == 'exponential')
>    pars <- c(runif(n=1, min=0, max=10),
>              runif(n=1, min=0, max=1000))
>  else
>    pars <- c(0.001, 0.0)  ## for pure nugget
>
>  # estimate one fit
>  best.so.far <- likfit(data=data,
>                        coords=coords,
>                        cov.model=cov.model,
>                        ini.cov.pars=pars,
>                        nugget=runif(n=1, min=0, max=10),
>                        messages=FALSE)
>  # do the rest of the fits, keep the lowest AIC
>  for (i in 2:nfits) {
>    this.fit <- likfit(data=data,
>                       coords=coords,
>                       cov.model=cov.model,
>                       ini.cov.pars=pars,
>                       nugget=runif(n=1, min=0, max=10),
>                       messages=FALSE)
>    if (this.fit$AIC < best.so.far$AIC)
>      best.so.far <- this.fit
>  }
>  return(best.so.far)
> }
>
> #----------------------------------------------------------------------
> fitGRFRealizations <- function(nsim=5, nfits=50) {
>
>  #allocate lists to hold the covariance model fits
>  fits.list.exp <- vector(mode='list', length=nsim) #for exponential fits
>  fits.list.PN <- vector(mode='list', length=nsim)  #for pure nugget fits
>  #generate random field realizations
>  flds <- getGRFRealizations(nsim=nsim)
>
>  #fit covariance model to each of the random fields
>  for (i in 1:nsim) {
>    fits.list.exp[[i]] <- multi.likfit(nfits=50,
>                                       data=flds$data[, i],
>                                       coords=flds$coords,
>                                       cov.model='exponential')
>    fits.list.PN[[i]] <- multi.likfit(nfits=50,
>                                      data=flds$data[, i],
>                                      coords=flds$coords,
>                                      cov.model='pure.nugget')
>    cat('.')  # crude progress bar
>  }
>  cat('\n')
>  return(list(exponential=fits.list.exp, pure.nugget=fits.list.PN))
> }
>
> #----------------------------------------------------------------------
> gatherFits <- function(fits.list) {
>  phi <- unlist(lapply(fits.list, function(x) x[['phi']]))
>  sigmasq <- unlist(lapply(fits.list, function(x) x[['sigmasq']]))
>  nugget <- unlist(lapply(fits.list, function(x) x[['nugget']]))
>  pRange <- unlist(lapply(fits.list, function(x) x[['practicalRange']]))
>  AIC <- unlist(lapply(fits.list, function(x) x[['AIC']]))
>  df <- data.frame(phi=phi, sigmasq=sigmasq, nugget=nugget, pRange=pRange, AIC=AIC)
>  return(df)
> }
>
> result <- fitGRFRealizations(nsim=10)
> df <- data.frame(PN.AIC=unlist(lapply(result[['pure.nugget']], function(x) x$AIC)),
>                 exp.AIC=unlist(lapply(result[['exponential']], function(x) x$AIC)))
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From hilton at meteo.psu.edu  Sun Aug 15 23:03:16 2010
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Sun, 15 Aug 2010 14:03:16 -0700
Subject: [R-sig-Geo] geoR likfit: confusing AIC results?
In-Reply-To: <alpine.DEB.2.00.1008141646220.19485@macalan.c3sl.ufpr.br>
References: <20100814175125.GA16892@Tim.local>
	<alpine.DEB.2.00.1008141646220.19485@macalan.c3sl.ufpr.br>
Message-ID: <20100815210316.GA27197@Tim.local>

Dear P.J.,

Thanks very much for such a helpful (and fast!) response.  I need to
increase my understanding of the optimization issues surrounding the
distances and orders of magnitude of the parameters.  If you are able to
spare another few moments, your advice raised two questions for me.

> 1. your area is of the size 6000x6000
> This is related with distances and order of magnitude of the
> parameters, in particular to phi.
> Since you total variances are around 3 the maximization may need
> some tunung for dealing with different oreders or magnitude
> 
>    1.a a simple suggestion would be replace 6000 by 6 and see whether it
>        change the estimates

I reduced the size of my area from 6000x6000 to 6x6, and it did indeed
change the estimates -- now the pure nugget AIC is less than or equal to
the exponential AIC in six of ten cases.  In two of the four cases where
the exponential AIC was lower, the AIC values did not differ until the
10th or 11th decimal place.  I expect this is more in the range of
floating point error, making the AIC values practically equal.

One question related to this: the difference between the exponential
loglik and the pure nugget loglik is greater than 1e-14 in only two of
the ten cases.  Because the exponential model has three estimated
parameters (sigmasq, phi, tausq) to the pure nugget's one (tausq),
shouldn't the pure nugget AIC be lower in all of those cases where the
loglik values are essentially equal?

>    1.b an alternative would be to pass values of fnscale to the
> optimizer (optim) through the appropriated ... mechanism

I will look into this also.  Thanks!

> 2. Notice that summary() on a likfit object (or elements of the
> list) already give you the fit and likelihood values for the pure
> nugget (independence) model such that you do not need to run the
> maximizer over it

Ah, very helpful.  Is this in the "nospatial" element of the list
reported by likfit?  I wasn't sure what that represented, exactly.

Again, thank you for taking the time to respond to my question, and
thank your for providing geoR to the R community.

Cheers,
Tim

--

Timothy W. Hilton
PhD Candidate, Department of Meteorology
The Pennsylvania State University
503 Walker Building, University Park, PA   16802
hilton at meteo.psu.edu


From m.fairbrother at bristol.ac.uk  Mon Aug 16 01:19:26 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 16 Aug 2010 00:19:26 +0100
Subject: [R-sig-Geo] two problems when trying to use "impacts"
In-Reply-To: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
References: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
Message-ID: <6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>

Good evening,

I'm trying to use "impacts" from package spdep, to get the impacts of unit changes in the independent variables, based on a fitted "lagsarlm" model. However, I'm running into two problems:

First, when I call "impacts", I get an error message that my weights are not row-standardised, when in fact they are. I can deal with this problem by coercing obj$listw_style to "W", but I'm wondering why this is happening at all.

Second, when I try to run simulations to generate estimates of the uncertainties for the estimates of the impacts, "impacts" seems not to acknowledge "R", and simply returns the estimates without any uncertainty. Can anyone tell me what I'm doing wrong (i.e., how I can get a series of simulations instead)?

The code I'm using is below.

Many thanks in advance for any assistance.

- Malcolm


> oxw <- oxw/apply(oxw, 1, sum) # this is the weights matrix

> table(apply(oxw, 1, sum)==1, useNA="always") # confirming rows sum to 1
TRUE <NA> 
  48    0 

> oxw.listw <- mat2listw(as.matrix(oxw)) # seems OK

> lagmod <- lagsarlm(ben95 ~ rskpovpc +wage95 + instcoad + ipcfold + teitrend + match, data=ox, listw=oxw.listw, method="eigen", tol.solve=1.0e-11) # seems OK

> impacts(lagmod, listw=oxw.listw)
Error in impacts.sarlm(lagmod, listw = oxw.listw) : 
  Only row-standardised weights supported

> lagmod$listw_style <- "W" # coercing to a different "style"

> impacts(lagmod, listw=oxw.listw) # results make sense
Impact measures (lag, exact):
             Direct     Indirect        Total
rskpovpc   3.953047   3.81574967   7.76879705
wage95    -0.027922  -0.02695221  -0.05487421
instcoad   1.566704   1.51228867   3.07899227
ipcfold  487.134198 470.21499459 957.34919259
teitrend   2.654201   2.56201450   5.21621501
match     -5.894235  -5.68951544 -11.58375015

> impacts(lagmod, R=100, listw=oxw.listw) # doesn't run sims...
Impact measures (lag, exact):
             Direct     Indirect        Total
rskpovpc   3.953047   3.81574967   7.76879705
wage95    -0.027922  -0.02695221  -0.05487421
instcoad   1.566704   1.51228867   3.07899227
ipcfold  487.134198 470.21499459 957.34919259
teitrend   2.654201   2.56201450   5.21621501
match     -5.894235  -5.68951544 -11.58375015


From ggrothendieck at gmail.com  Mon Aug 16 02:36:03 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 15 Aug 2010 20:36:03 -0400
Subject: [R-sig-Geo] Trouble installing rgdal
Message-ID: <AANLkTineqbjXCTOQLC9EDVa-TzByPaZoOmrLr1UfAKsH@mail.gmail.com>

I am having trouble install rgdal. I am using
Red Hat Enterprise Linux Server release 5.5 (Tikanga)
and having the problem shown below when I try to install
rgdal.

I have previously installed rgdal including building gdal
from source so I am not new to this but have not previouly
installed it on this particular machine.

I built gdal 1.7.2 from source (couldn't get it going otherwise) using
this configure command:
./configure --with-sqlite3=internal --without-libtool
--without-ld-shared --with-expat=/usr/local/lib

These commands all run ok so I assume gdal did get installed:

gdal_translate --version
gdalwarp --formats
gdal-config --version

All the switches on the above configure seemed to be essential
or else it would not build or run.  Maybe the problem is that
I had to configure it using --without-ld-shared but rgdal uses
-shared in its build.  How can I change that?  Or is there something
else I can do?


> install.packages("rgdal")
...snip...
checking proj_api.h presence... yes
checking for proj_api.h... yes
checking for pj_init_plus in -lproj... yes
./proj_conf_test: error while loading shared libraries: libproj.so.0:
wrong ELF class: ELFCLASS32
./proj_conf_test: error while loading shared libraries: libproj.so.0:
wrong ELF class: ELFCLASS32
Package CPP flags: -I/usr/local/include
Package LIBS: /usr/local/lib/libgdal.a -Linternal/lib -lsqlite3
-L/usr/local/lib/lib -lexpat -lgif -ljpeg -ltiff -lpng -lz -lm -lrt
-ldl -L/usr/kerberos/lib64 -lcurl -ldl -lgssapi_krb5 -lkrb5 -lk5crypto
-lcom_err -lidn -lssl -lcrypto -lz
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c OGR_write.cpp -o
OGR_write.o
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c gdal-bindings.cpp -o
gdal-bindings.o
gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GetRasterData(SEXPREC*,
SEXPREC*, SEXPREC*, SEXPREC*)?:
gdal-bindings.cpp:1016: warning: unused variable ?offset?
gcc -m64 -std=gnu99 -I/usr/include/R -I/usr/local/include
-I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -O2
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c local_stubs.c -o
local_stubs.o
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c ogr_geom.cpp -o
ogr_geom.o
gcc -m64 -std=gnu99 -I/usr/include/R -I/usr/local/include
-I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -O2
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c ogr_polygons.c -o
ogr_polygons.o
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c ogr_proj.cpp -o
ogr_proj.o
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c ogrdrivers.cpp -o
ogrdrivers.o
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c ogrsource.cpp -o
ogrsource.o
g++ -m64 -I/usr/include/R -I/usr/local/include -I/usr/local/include
-I"/usr/lib64/R/library/sp/include"   -fpic  -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m64 -mtune=generic -c projectit.cpp -o
projectit.o
projectit.cpp: In function ?SEXPREC* projInfo(SEXPREC*)?:
projectit.cpp:301: warning: ?ans? may be used uninitialized in this function
g++ -m64 -shared -L/usr/local/lib64 -o rgdal.so OGR_write.o
gdal-bindings.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o
ogrdrivers.o ogrsource.o projectit.o /usr/local/lib/libgdal.a
-Linternal/lib -lsqlite3 -L/usr/local/lib/lib -lexpat -lgif -ljpeg
-ltiff -lpng -lz -lm -lrt -ldl -L/usr/kerberos/lib64 -lcurl -ldl
-lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lidn -lssl -lcrypto -lz
-lproj -L/usr/lib64/R/lib -lR
/usr/bin/ld: /usr/local/lib/libgdal.a(genbindataset.o): relocation
R_X86_64_32 against `a local symbol' can not be used when making a
shared object; recompile with -fPIC
/usr/local/lib/libgdal.a: could not read symbols: Bad value
collect2: ld returned 1 exit status
make: *** [rgdal.so] Error 1
ERROR: compilation failed for package ?rgdal?
* removing ?/usr/lib64/R/library/rgdal?

The downloaded packages are in
        ?/tmp/RtmpglHU18/downloaded_packages?
Updating HTML index of packages in '.Library'
Warning message:
In install.packages("rgdal") :
  installation of package 'rgdal' had non-zero exit status


From ggrothendieck at gmail.com  Mon Aug 16 03:49:05 2010
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 15 Aug 2010 21:49:05 -0400
Subject: [R-sig-Geo] Trouble installing rgdal
In-Reply-To: <AANLkTineqbjXCTOQLC9EDVa-TzByPaZoOmrLr1UfAKsH@mail.gmail.com>
References: <AANLkTineqbjXCTOQLC9EDVa-TzByPaZoOmrLr1UfAKsH@mail.gmail.com>
Message-ID: <AANLkTik6QNK7SJ_FP93zczFEBr7q28kjvCXv8pikGj+O@mail.gmail.com>

On Sun, Aug 15, 2010 at 8:36 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> I am having trouble install rgdal. I am using
> Red Hat Enterprise Linux Server release 5.5 (Tikanga)
> and having the problem shown below when I try to install
> rgdal.
>

I found a different set of configure switches that worked.  In case
anyone has the same problem this is what I used
(and also I recompiled expat and sqlite and followed instructions
under Setting System Library Path in
http://docs.djangoproject.com/en/dev/ref/contrib/gis/install/
)

download and detar proj and gdal.

For proj-4.7.0 :
 ./configure --enable-shared --disable-static
--libdir=/usr/local/lib64 --with-expat=/usr/local/lib
make
make install

For gdal-1.7.2 :
./configure --enable-shared --disable-static --libdir=/usr/local/lib64
--with-expat=/usr/local/lib -with-sqlite3=/usr/local/lib
make
make install

These are not the same switches I used last time so it seems it can
vary a lot from one system to another.


From Roger.Bivand at nhh.no  Mon Aug 16 10:02:38 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 16 Aug 2010 10:02:38 +0200 (CEST)
Subject: [R-sig-Geo] two problems when trying to use "impacts"
In-Reply-To: <6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>
References: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
	<6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>
Message-ID: <alpine.LRH.2.00.1008160955260.23740@reclus.nhh.no>

On Mon, 16 Aug 2010, Malcolm Fairbrother wrote:

> Good evening,
>
> I'm trying to use "impacts" from package spdep, to get the impacts of 
> unit changes in the independent variables, based on a fitted "lagsarlm" 
> model. However, I'm running into two problems:
>
> First, when I call "impacts", I get an error message that my weights are 
> not row-standardised, when in fact they are. I can deal with this 
> problem by coercing obj$listw_style to "W", but I'm wondering why this 
> is happening at all.

You are creating the listw object with mat2listw(). This does not try to 
set the correct style, but assigns "M". To be sure that row 
standardisation is imposed, do:

oxw.listw0 <- mat2listw(as.matrix(oxw))
oxw.listw <- nb2listw(oxw.listw0$neighbours, glist=oxw.listw0$weights,
  style="W")

which also does sanity checks.

>
> Second, when I try to run simulations to generate estimates of the 
> uncertainties for the estimates of the impacts, "impacts" seems not to 
> acknowledge "R", and simply returns the estimates without any 
> uncertainty. Can anyone tell me what I'm doing wrong (i.e., how I can 
> get a series of simulations instead)?

No, please note the difference between the print() and summary() methods 
for objects returned by impacts() methods - see the ?impacts help page, 
and especially the eamples at the foot. You need:

imps <- impacts(lagmod, R=100, listw=oxw.listw)
summary(imps)

possibly with additional arguments to summary(), to have the simulations 
printed.

Hope this helps,

Roger


>
> The code I'm using is below.
>
> Many thanks in advance for any assistance.
>
> - Malcolm
>
>
>> oxw <- oxw/apply(oxw, 1, sum) # this is the weights matrix
>
>> table(apply(oxw, 1, sum)==1, useNA="always") # confirming rows sum to 1
> TRUE <NA>
>  48    0
>
>> oxw.listw <- mat2listw(as.matrix(oxw)) # seems OK
>
>> lagmod <- lagsarlm(ben95 ~ rskpovpc +wage95 + instcoad + ipcfold + teitrend + match, data=ox, listw=oxw.listw, method="eigen", tol.solve=1.0e-11) # seems OK
>
>> impacts(lagmod, listw=oxw.listw)
> Error in impacts.sarlm(lagmod, listw = oxw.listw) :
>  Only row-standardised weights supported
>
>> lagmod$listw_style <- "W" # coercing to a different "style"
>
>> impacts(lagmod, listw=oxw.listw) # results make sense
> Impact measures (lag, exact):
>             Direct     Indirect        Total
> rskpovpc   3.953047   3.81574967   7.76879705
> wage95    -0.027922  -0.02695221  -0.05487421
> instcoad   1.566704   1.51228867   3.07899227
> ipcfold  487.134198 470.21499459 957.34919259
> teitrend   2.654201   2.56201450   5.21621501
> match     -5.894235  -5.68951544 -11.58375015
>
>> impacts(lagmod, R=100, listw=oxw.listw) # doesn't run sims...
> Impact measures (lag, exact):
>             Direct     Indirect        Total
> rskpovpc   3.953047   3.81574967   7.76879705
> wage95    -0.027922  -0.02695221  -0.05487421
> instcoad   1.566704   1.51228867   3.07899227
> ipcfold  487.134198 470.21499459 957.34919259
> teitrend   2.654201   2.56201450   5.21621501
> match     -5.894235  -5.68951544 -11.58375015
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From a.mosnier at gmail.com  Mon Aug 16 19:05:03 2010
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Mon, 16 Aug 2010 13:05:03 -0400
Subject: [R-sig-Geo] Best distance for a semi-variogram calculation
Message-ID: <AANLkTi=7wnBF6RFPCAK-htFBaoG1uF+_xM8XQsX9e+7z@mail.gmail.com>

Dear geoUseRs,

New in the world of variograms, I ask for some advices !

My general question is :
Is there a methodology to find the best distance to be used as a limit
for the calculation of a semi-variogram ?

Here is an example that is problematic for me :
I have a 300 km by 300 km grid regularly spaced points containing
water current speed.
I first tested for spatial trend making a linear model between current
speed value and coordinates.
As there were a high effect, I removed this trend making my variogram
on the residuals of the model.
I calculated the semi-variogram on my variable from 0 to 300 km.
The variance first increase, attain a local maximum then decrease, and
re-increase acquiring a wave form, never really converging to a sill
value ...

1) do you have ever met such a pattern ? And if yes what was the reason of it ?

2) I agree that value of points located at 300 km from each other are
certainly not linked but how to know if there is no sill in the
semi-variogram ? Do I have to consider the distance where the first
decrease occurred in the semi-variance plot as the limit of the range
?

3) With that kind of shape what kind of variogram model would you
recommend to fit on it ?


From m.fairbrother at bristol.ac.uk  Mon Aug 16 20:06:23 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 16 Aug 2010 19:06:23 +0100
Subject: [R-sig-Geo] lagsarlm with simulated data
In-Reply-To: <alpine.LRH.2.00.1008160955260.23740@reclus.nhh.no>
References: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
	<6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>
	<alpine.LRH.2.00.1008160955260.23740@reclus.nhh.no>
Message-ID: <713461DB-2E2F-4DDE-8C53-7F6A66A83D46@bristol.ac.uk>

Dear list,

I am running some simulations, trying to use lagsarlm (from the spdep package) to recover the parameters used to generate the data. In a basic simulation I am running, I am finding that I am able to recover rho almost perfectly, and all but one of the betas perfectly. However, the beta attached to the constant is substantially biased, for reasons I cannot understand.

The code I am using is below. The spatial weights matrix is from the 48 contiguous U.S. states (rows sum to 1). Can anyone see where I am going wrong? Or is the biased B0 coefficient somehow a consequence of the particular neighbourhood structure I'm using? Any help or tips would be much appreciated.

- Malcolm


> n <- dim(W)[1] # sample size
> Bs <- c(2, 5, 3, -2) # vector of Beta coefficients
> rho <- 0.2 # set autocorrelation coefficient
> bres <- matrix(NA, nrow=1000, ncol=5)
> for (i in 1:1000) {
+ e <- rnorm(n, mean=0, sd=4)
+ X1 <- rnorm(n, 4, 2) # create some independent variables
+ X2 <- rnorm(n, 2, 2)
+ X3 <- rnorm(n, -3, 1)
+ X <- cbind(rep(1, n), X1, X2, X3)
+ y <- (solve(diag(n)-rho*W)) %*% ((X%*%Bs)+e) # generate lagged Ys
+ data <- as.data.frame(cbind(y, X))
+ lagmod <- lagsarlm(y ~ X1 + X2 + X3, data=data, oxw.listw1)
+ bres[i,] <- coefficients(lagmod)
+ }
> apply(bres, 2, mean)
[1]  0.1876292  2.6275783  4.9897827  3.0060831 -1.9883803
> apply(bres, 2, median)
[1]  0.1907057  2.4000895  4.9887496  3.0043258 -2.0076960


From Roger.Bivand at nhh.no  Mon Aug 16 20:53:55 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 16 Aug 2010 20:53:55 +0200 (CEST)
Subject: [R-sig-Geo] lagsarlm with simulated data
In-Reply-To: <713461DB-2E2F-4DDE-8C53-7F6A66A83D46@bristol.ac.uk>
References: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
	<6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>
	<alpine.LRH.2.00.1008160955260.23740@reclus.nhh.no>
	<713461DB-2E2F-4DDE-8C53-7F6A66A83D46@bristol.ac.uk>
Message-ID: <alpine.LRH.2.00.1008162047580.24862@reclus.nhh.no>

On Mon, 16 Aug 2010, Malcolm Fairbrother wrote:

> Dear list,
>
> I am running some simulations, trying to use lagsarlm (from the spdep 
> package) to recover the parameters used to generate the data. In a basic 
> simulation I am running, I am finding that I am able to recover rho 
> almost perfectly, and all but one of the betas perfectly. However, the 
> beta attached to the constant is substantially biased, for reasons I 
> cannot understand.
>
> The code I am using is below. The spatial weights matrix is from the 48 
> contiguous U.S. states (rows sum to 1). Can anyone see where I am going 
> wrong? Or is the biased B0 coefficient somehow a consequence of the 
> particular neighbourhood structure I'm using? Any help or tips would be 
> much appreciated.

Malcolm,

You didn't set a seed, so I can't reproduce this exactly, but I think that 
the mean of e will be added to your constant, won't it?

n <- 48
e <- matrix(rnorm(n*1000, mean=0, sd=4), 1000, n)
summary(apply(e, 1, mean))

Could you do a scale(e, center=TRUE, scale=FALSE) to force it to mean 
zero?

Hope this helps,

Roger

>
> - Malcolm
>
>
>> n <- dim(W)[1] # sample size
>> Bs <- c(2, 5, 3, -2) # vector of Beta coefficients
>> rho <- 0.2 # set autocorrelation coefficient
>> bres <- matrix(NA, nrow=1000, ncol=5)
>> for (i in 1:1000) {
> + e <- rnorm(n, mean=0, sd=4)
> + X1 <- rnorm(n, 4, 2) # create some independent variables
> + X2 <- rnorm(n, 2, 2)
> + X3 <- rnorm(n, -3, 1)
> + X <- cbind(rep(1, n), X1, X2, X3)
> + y <- (solve(diag(n)-rho*W)) %*% ((X%*%Bs)+e) # generate lagged Ys
> + data <- as.data.frame(cbind(y, X))
> + lagmod <- lagsarlm(y ~ X1 + X2 + X3, data=data, oxw.listw1)
> + bres[i,] <- coefficients(lagmod)
> + }
>> apply(bres, 2, mean)
> [1]  0.1876292  2.6275783  4.9897827  3.0060831 -1.9883803
>> apply(bres, 2, median)
> [1]  0.1907057  2.4000895  4.9887496  3.0043258 -2.0076960
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From m.fairbrother at bristol.ac.uk  Tue Aug 17 14:37:54 2010
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Tue, 17 Aug 2010 13:37:54 +0100
Subject: [R-sig-Geo] lagsarlm with simulated data
In-Reply-To: <alpine.LRH.2.00.1008162047580.24862@reclus.nhh.no>
References: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
	<6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>
	<alpine.LRH.2.00.1008160955260.23740@reclus.nhh.no>
	<713461DB-2E2F-4DDE-8C53-7F6A66A83D46@bristol.ac.uk>
	<alpine.LRH.2.00.1008162047580.24862@reclus.nhh.no>
Message-ID: <7329C44A-01D0-4BB2-A980-4C7366F85C4F@bristol.ac.uk>

Dear Roger (and any other interested parties),

Thanks very much for responding. I tried adding the scale() argument you suggested, but that didn't seem to make any difference. I've set a seed, and to make it even more easily reproducible, I've loosely followed code from: http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg00799.html. The contiguities (in addition to the data) are now generated directly using the code below.

I'm still getting consistent upward bias for the Intercept, and otherwise perfect recoveries of the data-generating parameters. I tried reversing the sign of rho, and that didn't make any difference.

Any ideas? Sorry to bother you with this, but I'd like to know why the simulation is generating this result.

Thanks again,
Malcolm


library(spdep)
sims <- 1000 # set number of simulations
rho <- 0.2 # set autocorrelation coefficient
Bs <- c(2, 5, 3, -2) # set a vector of betas
nb7rt <- cell2nb(7, 7, torus=TRUE) # generate contiguities
listw <- nb2listw(nb7rt)
mat <- nb2mat(nb7rt) # create contiguity matrix
set.seed(20100817)
e <- matrix(rnorm(sims*length(nb7rt)), nrow=length(nb7rt)) # create random errors
e <- scale(e, center=TRUE, scale=FALSE) # constrain mean of errors to zero
X0 <- matrix(1, ncol=sims, nrow=length(nb7rt)) # create Intercept
X1 <- matrix(rnorm(sims*length(nb7rt), 4, 2), nrow=length(nb7rt)) # generate some covariates
X2 <- matrix(rnorm(sims*length(nb7rt), 2, 2), nrow=length(nb7rt))
X3 <- matrix(rnorm(sims*length(nb7rt), -3, 1), nrow=length(nb7rt))
Xbe <- X0*Bs[1]+X1*Bs[2]+X2*Bs[3]+X3*Bs[4]+e
y <- solve(diag(length(nb7rt)) - rho*mat) %*% Xbe # generate lagged y data
lag_res1 <- lapply(1:sims, function(i) lagsarlm(y[,i] ~ X1[,i] + X2[,i] + X3[,i], listw=listw)) # fit the model
apply(do.call("rbind", lapply(lag_res1, coefficients)), 2, mean) # mean estimates are excellent, except Int
apply(do.call("rbind", lapply(lag_res1, coefficients)), 2, var) # variance is also a lot higher for Int





On 16 Aug 2010, at 19:53, Roger Bivand wrote:

> On Mon, 16 Aug 2010, Malcolm Fairbrother wrote:
> 
>> Dear list,
>> 
>> I am running some simulations, trying to use lagsarlm (from the spdep package) to recover the parameters used to generate the data. In a basic simulation I am running, I am finding that I am able to recover rho almost perfectly, and all but one of the betas perfectly. However, the beta attached to the constant is substantially biased, for reasons I cannot understand.
>> 
>> The code I am using is below. The spatial weights matrix is from the 48 contiguous U.S. states (rows sum to 1). Can anyone see where I am going wrong? Or is the biased B0 coefficient somehow a consequence of the particular neighbourhood structure I'm using? Any help or tips would be much appreciated.
> 
> Malcolm,
> 
> You didn't set a seed, so I can't reproduce this exactly, but I think that the mean of e will be added to your constant, won't it?
> 
> n <- 48
> e <- matrix(rnorm(n*1000, mean=0, sd=4), 1000, n)
> summary(apply(e, 1, mean))
> 
> Could you do a scale(e, center=TRUE, scale=FALSE) to force it to mean zero?
> 
> Hope this helps,
> 
> Roger
> 
>> 
>> - Malcolm
>> 
>> 
>>> n <- dim(W)[1] # sample size
>>> Bs <- c(2, 5, 3, -2) # vector of Beta coefficients
>>> rho <- 0.2 # set autocorrelation coefficient
>>> bres <- matrix(NA, nrow=1000, ncol=5)
>>> for (i in 1:1000) {
>> + e <- rnorm(n, mean=0, sd=4)
>> + X1 <- rnorm(n, 4, 2) # create some independent variables
>> + X2 <- rnorm(n, 2, 2)
>> + X3 <- rnorm(n, -3, 1)
>> + X <- cbind(rep(1, n), X1, X2, X3)
>> + y <- (solve(diag(n)-rho*W)) %*% ((X%*%Bs)+e) # generate lagged Ys
>> + data <- as.data.frame(cbind(y, X))
>> + lagmod <- lagsarlm(y ~ X1 + X2 + X3, data=data, oxw.listw1)
>> + bres[i,] <- coefficients(lagmod)
>> + }
>>> apply(bres, 2, mean)
>> [1]  0.1876292  2.6275783  4.9897827  3.0060831 -1.9883803
>>> apply(bres, 2, median)
>> [1]  0.1907057  2.4000895  4.9887496  3.0043258 -2.0076960
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 


From kvormoor at uni-bonn.de  Tue Aug 17 15:06:30 2010
From: kvormoor at uni-bonn.de (Klaus Vormoor)
Date: Tue, 17 Aug 2010 06:06:30 -0700 (PDT)
Subject: [R-sig-Geo] spRbind for spplot
Message-ID: <1282050390945-5431975.post@n2.nabble.com>


Dear all,

I have an object (rtopObj3) including the SpatialPolygonDataFrames with
runoff observations ($observations, "QNORM_12_4") for 100 gauged catchments
and with predictions ($predictions, "var1.pred") for more than ungauged
2,000 catchments. So far, I only can plot either the observations or the
predictions individually:

> spplot(rtopObj3$observations, "QNORM_12_4", col.regions = bpy.colors())
> spplot(rtopObj3$predictions, "var1.pred", col.regions = bpy.colors())

I want to create one map showing both. I tried the sp.layout argument
without success. But since I also want to have both information combined for
writing a shp-file, it may be more reasonable to use spRbind and do the plot
later on. I unsuccessfully tried:

> observation = rtopObj3$observations
> prediction = rtopObj3$predictions
> rtopObj4 <- spRbind(observation, prediction)
Error in rbind(deparse.level, ...) : 
  numbers of columns of arguments do not match

Does anyone know a way out?
Thanks for every advice,

Klaus
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spRbind-for-spplot-tp5431975p5431975.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mayeul.kauffmann at jrc.ec.europa.eu  Tue Aug 17 15:47:01 2010
From: mayeul.kauffmann at jrc.ec.europa.eu (Mayeul KAUFFMANN)
Date: Tue, 17 Aug 2010 15:47:01 +0200
Subject: [R-sig-Geo] Temporal marked point process with time-varying
	covariates
Message-ID: <001401cb3e12$ab6ea640$024bf2c0$@kauffmann@jrc.ec.europa.eu>

Dear spatial statisticians and R users,

I am trying to model a temporal marked point process with time-varying
covariates and I am looking for the most appropriate function among several
ones.
(The events are violent events, such as fightings, in African countries). I want
to model both the time/location of the events and at least one of the mark (the
intensity of the event, measured for example by the number of persons killed).

Events are collected over a few years. The time-resolution of the events is the
day, while the covariates vary more slowly. The events have latitude and
longitude, while the covariates are raster data (1km x 1km grid).

I had a look at the following packages but I'm not sure I found the right
solution yet:
spatstat
splancs
PtProcess

spatstat seems to have the correct object to handle my dependant variables (the
ppx class: 2D space + time) but if I'm correct the ppm() model fitting function
cannot handle this (it only works with ppp). Am I missing something? I saw at
http://www.spatstat.org/  that this branch is in development. Any news /
schedule on that?

PtProcess does allow to estimate a time dependent marked point process (using
etas_spatial()  ). However, apparently, only the history of the point process
itself can be taken into account (there are marks but they are no covariates:
there is no data for locations without events). One workaround might be to
include in the point process dummy events with (near-)zero intensity for all (or
sampled) time-space cells and to attach the covariates as marks. What do you
think?

splancs does not seem to support this but has a nice space-time kernel smoothing
function (kernel3d) and ability to display the result (kerview). I could
transform the point process into a time-varying surface, but do not know how to
model it either.

The main aim is to measure the impact of the covariates on the point process.
Ideally, the model should allow for time and space autocorelation among events
(clustering is likely), similar to what the etas_spatial() function permits.

Thanks for any comment!
Regards,

Mayeul KAUFFMANN

PS: for reference, some messages I found close to my problem:
https://stat.ethz.ch/pipermail/r-sig-geo/2010-March/007909.html
https://stat.ethz.ch/pipermail/r-sig-geo/2009-September/006438.html
https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091023/b33321bb/attachmen
t.pl

_____________________________________________________
Dr. Mayeul KAUFFMANN, Conflict Specialist
European Commission, Joint Research Centre (JRC)
Institute for the Protection and Security of the Citizen (IPSC)
Global Security and Crisis Management - ISFEREA
Via E. Fermi 2749 - I-21027 Ispra (VA), ITALY
Phone: (+39) 033278 5071
http://isferea.jrc.ec.europa.eu/Staff/Pages/Kauffmann-Mayeul.aspx

(Office: building 48c, 1st floor, room 123. TP: 483)


From scionforbai at gmail.com  Tue Aug 17 18:18:58 2010
From: scionforbai at gmail.com (Scionforbai)
Date: Tue, 17 Aug 2010 18:18:58 +0200
Subject: [R-sig-Geo] Best distance for a semi-variogram calculation
In-Reply-To: <AANLkTi=7wnBF6RFPCAK-htFBaoG1uF+_xM8XQsX9e+7z@mail.gmail.com>
References: <AANLkTi=7wnBF6RFPCAK-htFBaoG1uF+_xM8XQsX9e+7z@mail.gmail.com>
Message-ID: <AANLkTiknxh51LRRALcD0x+3jeUaD67ksA0zOCSBuRHkX@mail.gmail.com>

> Is there a methodology to find the best distance to be used as a limit
> for the calculation of a semi-variogram ?

General practitioner rule: the half of the squared domain diagonal

> Here is an example that is problematic for me :
> I have a 300 km by 300 km grid regularly spaced points containing
> water current speed.
> I first tested for spatial trend making a linear model between current
> speed value and coordinates.

That is fine. Maybe you need to remove not a linear trend, but a
polynomial one instead (that is a linear model of a combination of the
higher order of the coordinates).

> As there were a high effect, I removed this trend making my variogram
> on the residuals of the model.
> I calculated the semi-variogram on my variable from 0 to 300 km.

Yours is a very easy example :)

  > sqrt(2)*300/2
  [1] 212.1320

That should be the maximum lag distance at which it makes sense to
calculate the experimental variogram.

> The variance first increase, attain a local maximum then decrease, and
> re-increase acquiring a wave form, never really converging to a sill
> value ...

> 1) do you have ever met such a pattern ? And if yes what was the reason of it ?

If I understand correctly the form of the empirical semi-variogram,
this can be an "hole effect", which you get for example in stratified
or periodic fields.
Are you calculating directional variograms, or isotropic? Look at the
image() or contour plot of the residuals, do you see stratifications
(= bands) or evident anisotropies?
Remember the special case of linear model of variogram: it is
unbounded, never reaching a sill. It actually means that the variance
of underlying random function is not stationary, but varies in space;
in this case the covariance of the RF is not defined, and this is not
an order-2 stationary function, but a IRF-0.

> 2) I agree that value of points located at 300 km from each other are
> certainly not linked but how to know if there is no sill in the
> semi-variogram ? Do I have to consider the distance where the first
> decrease occurred in the semi-variance plot as the limit of the range
> ?

Inferring the variogram model from an experimental one can be tricky.
As I mentioned, try directional variograms. You can also try to play
around with the number of lags, as in seq(0,212,length=12) and
seq(0,212,length=8), for example.

> 3) With that kind of shape what kind of variogram model would you
> recommend to fit on it ?

"The spherical model is the geostatistician's best friend" :)
First try to observe the features of your field, then try to model
those features after opportune manipulation (trend filtering,
considering anisotropy and so on). Only after those step you can think
of "complicated" variogram model, like the nested
linear+hole+nugget+spherical.

Good luck,

Scion


From Roger.Bivand at nhh.no  Tue Aug 17 19:54:34 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 17 Aug 2010 19:54:34 +0200 (CEST)
Subject: [R-sig-Geo] lagsarlm with simulated data
In-Reply-To: <7329C44A-01D0-4BB2-A980-4C7366F85C4F@bristol.ac.uk>
References: <mailman.5.1281866402.18516.r-sig-geo@stat.math.ethz.ch>
	<6D8FE0A1-7135-4DBC-B32E-A7E615634B48@bristol.ac.uk>
	<alpine.LRH.2.00.1008160955260.23740@reclus.nhh.no>
	<713461DB-2E2F-4DDE-8C53-7F6A66A83D46@bristol.ac.uk>
	<alpine.LRH.2.00.1008162047580.24862@reclus.nhh.no>
	<7329C44A-01D0-4BB2-A980-4C7366F85C4F@bristol.ac.uk>
Message-ID: <alpine.LRH.2.00.1008171932350.28027@reclus.nhh.no>

On Tue, 17 Aug 2010, Malcolm Fairbrother wrote:

> Dear Roger (and any other interested parties),
>
> Thanks very much for responding. I tried adding the scale() argument you 
> suggested, but that didn't seem to make any difference. I've set a seed, 
> and to make it even more easily reproducible, I've loosely followed code 
> from: 
> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg00799.html. 
> The contiguities (in addition to the data) are now generated directly 
> using the code below.
>
> I'm still getting consistent upward bias for the Intercept, and 
> otherwise perfect recoveries of the data-generating parameters. I tried 
> reversing the sign of rho, and that didn't make any difference.
>
> Any ideas? Sorry to bother you with this, but I'd like to know why the 
> simulation is generating this result.

Malcolm,

The reproducible code does make life easier, thanks. I don't have a 
solution, but see also:

Xbe <- X0*Bs[1]+X1*Bs[2]+X2*Bs[3]+X3*Bs[4]+e
y <- Xbe
lm_res1 <- lapply(1:sims, function(i) lm(y[,i] ~ X1[,i] + X2[,i] +
  X3[,i]))
apply(do.call("rbind", lapply(lm_res1, coefficients)), 2, mean)
apply(do.call("rbind", lapply(lm_res1, coefficients)), 2, var)

which exhibits somewhat similar traits in the variance of the intercept. 
I've also tried an intercept-only scenario without more light appearing, 
and a fixed X scenario. The intercept appears to "soak up" other variance. 
In the lag case, this gets diffused/smoothed through (I - \rho W)^{-1} in 
addition.

Other ideas, anyone?

Roger


>
> Thanks again,
> Malcolm
>
>
> library(spdep)
> sims <- 1000 # set number of simulations
> rho <- 0.2 # set autocorrelation coefficient
> Bs <- c(2, 5, 3, -2) # set a vector of betas
> nb7rt <- cell2nb(7, 7, torus=TRUE) # generate contiguities
> listw <- nb2listw(nb7rt)
> mat <- nb2mat(nb7rt) # create contiguity matrix
> set.seed(20100817)
> e <- matrix(rnorm(sims*length(nb7rt)), nrow=length(nb7rt)) # create random errors
> e <- scale(e, center=TRUE, scale=FALSE) # constrain mean of errors to zero
> X0 <- matrix(1, ncol=sims, nrow=length(nb7rt)) # create Intercept
> X1 <- matrix(rnorm(sims*length(nb7rt), 4, 2), nrow=length(nb7rt)) # generate some covariates
> X2 <- matrix(rnorm(sims*length(nb7rt), 2, 2), nrow=length(nb7rt))
> X3 <- matrix(rnorm(sims*length(nb7rt), -3, 1), nrow=length(nb7rt))
> Xbe <- X0*Bs[1]+X1*Bs[2]+X2*Bs[3]+X3*Bs[4]+e
> y <- solve(diag(length(nb7rt)) - rho*mat) %*% Xbe # generate lagged y data
> lag_res1 <- lapply(1:sims, function(i) lagsarlm(y[,i] ~ X1[,i] + X2[,i] + X3[,i], listw=listw)) # fit the model
> apply(do.call("rbind", lapply(lag_res1, coefficients)), 2, mean) # mean estimates are excellent, except Int
> apply(do.call("rbind", lapply(lag_res1, coefficients)), 2, var) # variance is also a lot higher for Int
>
>
>
>
>
> On 16 Aug 2010, at 19:53, Roger Bivand wrote:
>
>> On Mon, 16 Aug 2010, Malcolm Fairbrother wrote:
>>
>>> Dear list,
>>>
>>> I am running some simulations, trying to use lagsarlm (from the spdep package) to recover the parameters used to generate the data. In a basic simulation I am running, I am finding that I am able to recover rho almost perfectly, and all but one of the betas perfectly. However, the beta attached to the constant is substantially biased, for reasons I cannot understand.
>>>
>>> The code I am using is below. The spatial weights matrix is from the 48 contiguous U.S. states (rows sum to 1). Can anyone see where I am going wrong? Or is the biased B0 coefficient somehow a consequence of the particular neighbourhood structure I'm using? Any help or tips would be much appreciated.
>>
>> Malcolm,
>>
>> You didn't set a seed, so I can't reproduce this exactly, but I think that the mean of e will be added to your constant, won't it?
>>
>> n <- 48
>> e <- matrix(rnorm(n*1000, mean=0, sd=4), 1000, n)
>> summary(apply(e, 1, mean))
>>
>> Could you do a scale(e, center=TRUE, scale=FALSE) to force it to mean zero?
>>
>> Hope this helps,
>>
>> Roger
>>
>>>
>>> - Malcolm
>>>
>>>
>>>> n <- dim(W)[1] # sample size
>>>> Bs <- c(2, 5, 3, -2) # vector of Beta coefficients
>>>> rho <- 0.2 # set autocorrelation coefficient
>>>> bres <- matrix(NA, nrow=1000, ncol=5)
>>>> for (i in 1:1000) {
>>> + e <- rnorm(n, mean=0, sd=4)
>>> + X1 <- rnorm(n, 4, 2) # create some independent variables
>>> + X2 <- rnorm(n, 2, 2)
>>> + X3 <- rnorm(n, -3, 1)
>>> + X <- cbind(rep(1, n), X1, X2, X3)
>>> + y <- (solve(diag(n)-rho*W)) %*% ((X%*%Bs)+e) # generate lagged Ys
>>> + data <- as.data.frame(cbind(y, X))
>>> + lagmod <- lagsarlm(y ~ X1 + X2 + X3, data=data, oxw.listw1)
>>> + bres[i,] <- coefficients(lagmod)
>>> + }
>>>> apply(bres, 2, mean)
>>> [1]  0.1876292  2.6275783  4.9897827  3.0060831 -1.9883803
>>>> apply(bres, 2, median)
>>> [1]  0.1907057  2.4000895  4.9887496  3.0043258 -2.0076960
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From p.hiemstra at geo.uu.nl  Tue Aug 17 20:21:43 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 17 Aug 2010 20:21:43 +0200
Subject: [R-sig-Geo] spRbind for spplot
In-Reply-To: <1282050390945-5431975.post@n2.nabble.com>
References: <1282050390945-5431975.post@n2.nabble.com>
Message-ID: <4C6AD337.7060208@geo.uu.nl>

Dear Klaus,

You need to be more specific as to what you want exactly. From what I 
understand both your runoff and predictions are attributes that you want 
to use to fill the polygons. My first idea would be to make to plots 
next to each other, which is quite simple in spplot:

spplot(data, c("attribute1", "attribute2"))

If your attributes are not part of the same polygons set you can add one 
as a new attribute to the other:

plot_poly = rtopObj3$observations
plot_poly$predictions = rtopObj3$predictions$var1.pred
spplot(plot_poly, c("observations", "predictions"))

Is this satisfactory for you, and what do you mean by one map showing 
both? To show the results in one figure a scatterplot of observerd vs 
modeled is also a good idea.

regards,
Paul

On 08/17/2010 03:06 PM, Klaus Vormoor wrote:
> Dear all,
>
> I have an object (rtopObj3) including the SpatialPolygonDataFrames with
> runoff observations ($observations, "QNORM_12_4") for 100 gauged catchments
> and with predictions ($predictions, "var1.pred") for more than ungauged
> 2,000 catchments. So far, I only can plot either the observations or the
> predictions individually:
>
>    
>> spplot(rtopObj3$observations, "QNORM_12_4", col.regions = bpy.colors())
>> spplot(rtopObj3$predictions, "var1.pred", col.regions = bpy.colors())
>>      
> I want to create one map showing both. I tried the sp.layout argument
> without success. But since I also want to have both information combined for
> writing a shp-file, it may be more reasonable to use spRbind and do the plot
> later on. I unsuccessfully tried:
>
>    
>> observation = rtopObj3$observations
>> prediction = rtopObj3$predictions
>> rtopObj4<- spRbind(observation, prediction)
>>      
> Error in rbind(deparse.level, ...) :
>    numbers of columns of arguments do not match
>
> Does anyone know a way out?
> Thanks for every advice,
>
> Klaus
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From Roger.Bivand at nhh.no  Wed Aug 18 09:21:17 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Aug 2010 09:21:17 +0200 (CEST)
Subject: [R-sig-Geo] Temporal marked point process with time-varying
 covariates
In-Reply-To: <001401cb3e12$ab6ea640$024bf2c0$@kauffmann@jrc.ec.europa.eu>
References: <001401cb3e12$ab6ea640$024bf2c0$@kauffmann@jrc.ec.europa.eu>
Message-ID: <alpine.LRH.2.00.1008180918460.1659@reclus.nhh.no>

On Tue, 17 Aug 2010, Mayeul KAUFFMANN wrote:

> Dear spatial statisticians and R users,

The following is posted for David Harte:
----------------------------------------------------
Attached is my response to a question raised on your list. My response
to the list was rejected as I am not a member.

David Harte

Dear Mayeul

The structure of the PtProcess package is based on the conditional
intensity function (i.e. is history dependent), and if the user can
specify their ground intensity function, then they can use the provided
framework within the package to fit the model, simulate, and do various
other things. Processes that are just time varying, with no explicit
dependence on the history, can obviously be included with a null history.

I understand that the models fitted by spatstat are somewhat different,
and have no natural definition of past history and are based on a
Papangelou conditional intensity (i.e. conditional on the spatial
locations of other points, with no time ordering).

A marked point process has a structure where the conditional intensity
function is the product of the ground intensity function and the mark
distributions. What sort of functional relationship are you proposing
for your data? Can you write an equation for your ground intensity
function? Can you specify a spatial mark distribution? In particular,
can the spatial distribution be separated from the ground intensity as a
mark? There is no reason why other covariates cannot be part of the
defined ground intensity function, or the mark distribution.

I do not think that the ETAS model will have any relevance for your
situation. The spatial ETAS model is slightly peculiar as it does not
satisfy the simple product of the ground intensity and spatial mark
required for it to be a marked point process. It is a "compounded" mark
point processes, i.e. I mean here the sum of many marked point
processes; which makes it rather interesting. See the cited paper below
for further information.

If you can write an equation that represents your ground intensity
function in terms of your covariates and any other information, and also
for a spatial mark distribution, then I suggest that you look at the
code for the simple time varying conditional intensity functions (see
manual page for simple_gif, it will list the various functions). These
are just non-homogeneous Poisson processes that are various functions of
time. However, given your specification of your conditional intensity as
a function of the covariates, you should be able to mimic the required
structure, and write your own ground intensity function. Similarly, you
will also need to specify your spatial mark distribution. You also
mentioned the magnitude of the event. Is this independent of space? If
not, then it will be part of a spatial-magnitude mark. If independent,
then the spatial-magnitude density would be the product of the two
densities.

I have recently published further explanation about the package in the
Journal of Statistical Software, see: http://www.jstatsoft.org/v35/i08/

Good luck

David Harte



-- 
David Harte
Statistics Research Associates Ltd
PO Box 12 649
Thorndon
Wellington
NEW ZEALAND

Tel:    +64-4-473 1760
Email:  david at statsresearch.co.nz
Web:    www.statsresearch.co.nz

----------------------------------------------------
>
> I am trying to model a temporal marked point process with time-varying
> covariates and I am looking for the most appropriate function among several
> ones.
> (The events are violent events, such as fightings, in African countries). I want
> to model both the time/location of the events and at least one of the mark (the
> intensity of the event, measured for example by the number of persons killed).
>
> Events are collected over a few years. The time-resolution of the events is the
> day, while the covariates vary more slowly. The events have latitude and
> longitude, while the covariates are raster data (1km x 1km grid).
>
> I had a look at the following packages but I'm not sure I found the right
> solution yet:
> spatstat
> splancs
> PtProcess
>
> spatstat seems to have the correct object to handle my dependant variables (the
> ppx class: 2D space + time) but if I'm correct the ppm() model fitting function
> cannot handle this (it only works with ppp). Am I missing something? I saw at
> http://www.spatstat.org/  that this branch is in development. Any news /
> schedule on that?
>
> PtProcess does allow to estimate a time dependent marked point process (using
> etas_spatial()  ). However, apparently, only the history of the point process
> itself can be taken into account (there are marks but they are no covariates:
> there is no data for locations without events). One workaround might be to
> include in the point process dummy events with (near-)zero intensity for all (or
> sampled) time-space cells and to attach the covariates as marks. What do you
> think?
>
> splancs does not seem to support this but has a nice space-time kernel smoothing
> function (kernel3d) and ability to display the result (kerview). I could
> transform the point process into a time-varying surface, but do not know how to
> model it either.
>
> The main aim is to measure the impact of the covariates on the point process.
> Ideally, the model should allow for time and space autocorelation among events
> (clustering is likely), similar to what the etas_spatial() function permits.
>
> Thanks for any comment!
> Regards,
>
> Mayeul KAUFFMANN
>
> PS: for reference, some messages I found close to my problem:
> https://stat.ethz.ch/pipermail/r-sig-geo/2010-March/007909.html
> https://stat.ethz.ch/pipermail/r-sig-geo/2009-September/006438.html
> https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091023/b33321bb/attachmen
> t.pl
>
> _____________________________________________________
> Dr. Mayeul KAUFFMANN, Conflict Specialist
> European Commission, Joint Research Centre (JRC)
> Institute for the Protection and Security of the Citizen (IPSC)
> Global Security and Crisis Management - ISFEREA
> Via E. Fermi 2749 - I-21027 Ispra (VA), ITALY
> Phone: (+39) 033278 5071
> http://isferea.jrc.ec.europa.eu/Staff/Pages/Kauffmann-Mayeul.aspx
>
> (Office: building 48c, 1st floor, room 123. TP: 483)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kvormoor at uni-bonn.de  Wed Aug 18 11:03:46 2010
From: kvormoor at uni-bonn.de (Klaus Vormoor)
Date: Wed, 18 Aug 2010 11:03:46 +0200
Subject: [R-sig-Geo] spRbind for spplot
In-Reply-To: <4C6AD337.7060208@geo.uu.nl>
References: <1282050390945-5431975.post@n2.nabble.com>
	<4C6AD337.7060208@geo.uu.nl>
Message-ID: <web-5153658@be2.uni-bonn.de>

Dear Paul,

thanks for your answer. I guess, your second advice is 
pricipially that what I want. But so far it did not work. 
I try a more precise explaination:

For an area I have in total 2200 catchments (nor = 
readOGR(shp)). 100 of them have observations for five days 
(rtopObj3$observations). I am only interested in the 
attributes for one day ("QNORM_12_4"). 
rtopObj3$observations holds spatial information only for 
these 100 catchments. rtopObj3$predicions holds spatial 
information only for the remaining 2100 catchments with 
predictions (rtopObj3$predictions$var1.pred).

When I try
> plot_poly = rtopObj3$observations
> plot_poly$predictions = rtopObj3$predictions$var1.pred
> spplot(plot_poly, c("observations", "predictions"))
it does not work since the replacement has 2100 rows and 
the data has 100.

I would like to create a new object (e.g. plot_poly) which 
holds the spatial information of all catchment-polygons 
(nor) as well as the attributes of both 
observations$QNORM_12_4 and predictions$var1.pred to the 
corresponding areas. Therefore, I thought spRbind might be 
a propper solution.

I hope this is more specific and not even more 
cryptical...

Best regards,
Klaus




On Tue, 17 Aug 2010 20:21:43 +0200
  Paul Hiemstra <p.hiemstra at geo.uu.nl> wrote:
> Dear Klaus,
> 
> You need to be more specific as to what you want 
>exactly. From what I understand both your runoff and 
>predictions are attributes that you want to use to fill 
>the polygons. My first idea would be to make to plots 
>next to each other, which is quite simple in spplot:
> 
> spplot(data, c("attribute1", "attribute2"))
> 
> If your attributes are not part of the same polygons set 
>you can add one as a new attribute to the other:
> 
> plot_poly = rtopObj3$observations
> plot_poly$predictions = rtopObj3$predictions$var1.pred
> spplot(plot_poly, c("observations", "predictions"))
> 
> Is this satisfactory for you, and what do you mean by 
>one map showing both? To show the results in one figure a 
>scatterplot of observerd vs modeled is also a good idea.
> 
> regards,
> Paul
> 
> On 08/17/2010 03:06 PM, Klaus Vormoor wrote:
>> Dear all,
>>
>> I have an object (rtopObj3) including the 
>>SpatialPolygonDataFrames with
>> runoff observations ($observations, "QNORM_12_4") for 
>>100 gauged catchments
>> and with predictions ($predictions, "var1.pred") for 
>>more than ungauged
>> 2,000 catchments. So far, I only can plot either the 
>>observations or the
>> predictions individually:
>>
>>    
>>> spplot(rtopObj3$observations, "QNORM_12_4", col.regions 
>>>= bpy.colors())
>>> spplot(rtopObj3$predictions, "var1.pred", col.regions = 
>>>bpy.colors())
>>>      
>> I want to create one map showing both. I tried the 
>>sp.layout argument
>> without success. But since I also want to have both 
>>information combined for
>> writing a shp-file, it may be more reasonable to use 
>>spRbind and do the plot
>> later on. I unsuccessfully tried:
>>
>>    
>>> observation = rtopObj3$observations
>>> prediction = rtopObj3$predictions
>>> rtopObj4<- spRbind(observation, prediction)
>>>      
>> Error in rbind(deparse.level, ...) :
>>    numbers of columns of arguments do not match
>>
>> Does anyone know a way out?
>> Thanks for every advice,
>>
>> Klaus
>>    
> 
> 
> -- 
> Drs. Paul Hiemstra
> Department of Physical Geography
>Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone:  +3130 253 5773
> http://intamap.geo.uu.nl/~paul
> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From p.hiemstra at geo.uu.nl  Wed Aug 18 11:25:40 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 18 Aug 2010 11:25:40 +0200
Subject: [R-sig-Geo] spRbind for spplot
In-Reply-To: <web-5153658@be2.uni-bonn.de>
References: <1282050390945-5431975.post@n2.nabble.com>
	<4C6AD337.7060208@geo.uu.nl> <web-5153658@be2.uni-bonn.de>
Message-ID: <4C6BA714.4030100@geo.uu.nl>

On 08/18/2010 11:03 AM, Klaus Vormoor wrote:
> Dear Paul,
>
> thanks for your answer. I guess, your second advice is pricipially 
> that what I want. But so far it did not work. I try a more precise 
> explaination:
>
> For an area I have in total 2200 catchments (nor = readOGR(shp)). 100 
> of them have observations for five days (rtopObj3$observations). I am 
> only interested in the attributes for one day ("QNORM_12_4"). 
> rtopObj3$observations holds spatial information only for these 100 
> catchments. rtopObj3$predicions holds spatial information only for the 
> remaining 2100 catchments with predictions 
> (rtopObj3$predictions$var1.pred).
>
> When I try
>> plot_poly = rtopObj3$observations
>> plot_poly$predictions = rtopObj3$predictions$var1.pred
>> spplot(plot_poly, c("observations", "predictions"))
> it does not work since the replacement has 2100 rows and the data has 
> 100.
>
> I would like to create a new object (e.g. plot_poly) which holds the 
> spatial information of all catchment-polygons (nor) as well as the 
> attributes of both observations$QNORM_12_4 and predictions$var1.pred 
> to the corresponding areas. Therefore, I thought spRbind might be a 
> propper solution.
>
> I hope this is more specific and not even more cryptical...
>
> Best regards,
> Klaus
>
>
>
>
> On Tue, 17 Aug 2010 20:21:43 +0200
>  Paul Hiemstra <p.hiemstra at geo.uu.nl> wrote:
>> Dear Klaus,
>>
>> You need to be more specific as to what you want exactly. From what I 
>> understand both your runoff and predictions are attributes that you 
>> want to use to fill the polygons. My first idea would be to make to 
>> plots next to each other, which is quite simple in spplot:
>>
>> spplot(data, c("attribute1", "attribute2"))
>>
>> If your attributes are not part of the same polygons set you can add 
>> one as a new attribute to the other:
>>
>> plot_poly = rtopObj3$observations
>> plot_poly$predictions = rtopObj3$predictions$var1.pred
>> spplot(plot_poly, c("observations", "predictions"))
>>
>> Is this satisfactory for you, and what do you mean by one map showing 
>> both? To show the results in one figure a scatterplot of observerd vs 
>> modeled is also a good idea.
>>
>> regards,
>> Paul
>>
>> On 08/17/2010 03:06 PM, Klaus Vormoor wrote:
>>> Dear all,
>>>
>>> I have an object (rtopObj3) including the SpatialPolygonDataFrames with
>>> runoff observations ($observations, "QNORM_12_4") for 100 gauged 
>>> catchments
>>> and with predictions ($predictions, "var1.pred") for more than ungauged
>>> 2,000 catchments. So far, I only can plot either the observations or 
>>> the
>>> predictions individually:
>>>
>>>> spplot(rtopObj3$observations, "QNORM_12_4", col.regions = 
>>>> bpy.colors())
>>>> spplot(rtopObj3$predictions, "var1.pred", col.regions = bpy.colors())
>>> I want to create one map showing both. I tried the sp.layout argument
>>> without success. But since I also want to have both information 
>>> combined for
>>> writing a shp-file, it may be more reasonable to use spRbind and do 
>>> the plot
>>> later on. I unsuccessfully tried:
>>>
>>>> observation = rtopObj3$observations
>>>> prediction = rtopObj3$predictions
You need to make a subset of the prediction that includes only the 100 
observed catchments. Maybe even better, create a prediction object of 
only the 100 observed catchments.

cheers,
Paul
>>>> rtopObj4<- spRbind(observation, prediction)
>>> Error in rbind(deparse.level, ...) :
>>>    numbers of columns of arguments do not match
>>>
>>> Does anyone know a way out?
>>> Thanks for every advice,
>>>
>>> Klaus
>>
>>
>> -- 
>> Drs. Paul Hiemstra
>> Department of Physical Geography
>> Faculty of Geosciences
>> University of Utrecht
>> Heidelberglaan 2
>> P.O. Box 80.115
>> 3508 TC Utrecht
>> Phone:  +3130 253 5773
>> http://intamap.geo.uu.nl/~paul
>> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From b.rowlingson at lancaster.ac.uk  Wed Aug 18 11:56:51 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 18 Aug 2010 10:56:51 +0100
Subject: [R-sig-Geo] Spatial data tower of babel
Message-ID: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>

Hi,

 Recently while teaching at SFU I hit the problem that infects R when
many people work on similar projects - the multitude of data formats
for similar data. The sp project was partly an attempt to give a
standard format for spatial data but its widespread non-use in older
packages causes trouble.

 So for example I taught the students all about 'sp' objects, and then
they had to use spatstat and splancs for some point-process stuff,
then geoR for some kriging, none of which use sp objects.

 So I figured maybe we need a whole load of 'as' functions that can
convert between the various spatial data formats (there are more in
CRAN, I am sure) to help us all out on this. Some of these functions
may already exist, indeed I just found something about converting
fairly raw x-y coordinate objects to SpatialPolygons hidden away in
the SpatialEpi package (polygons2spatial.polygons).

 Would it be a good idea to stick all the conversions we can think of
into a single package, "spBabel" say (or spConversion to avoid any
cultural reference), so people have a one-stop shop? And if we find
routines stuck in other packages (such as polygons2spatial.polygons)
we rip them out and bundle them?

 Yes, its a matter of time and effort and we're all busy, but I'd like
to put it out as a proposal. It might make a nice intern or GSOC
project, but we're a bit late for that, so maybe if anyone has a PhD
student starting who needs to get up to speed with R packages and
spatial data it would be a good introduction for them. Once its all
set up (on R-forge or similar) contributing shouldn't be a problem.

 Okay, that's my one crazy idea for the day done.

Barry


-- 
blog: http://geospaced.blogspot.com/
web: http://www.maths.lancs.ac.uk/~rowlings
web: http://www.rowlingson.com/
twitter: http://twitter.com/geospacedman
pics: http://www.flickr.com/photos/spacedman


From evion12000 at gmail.com  Wed Aug 18 13:08:26 2010
From: evion12000 at gmail.com (=?iso-8859-1?Q?David_M=E9ndez?=)
Date: Wed, 18 Aug 2010 06:38:26 -0430
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 84, Issue 18
Message-ID: <4c6bbf2e.c68de50a.1b66.01fd@mx.google.com>



Enviado desde mi HTC

----- Mensaje original -----
De: r-sig-geo-request at stat.math.ethz.ch
Enviado: Mi?rcoles, 18 de Agosto de 2010 05:30 a.m.
Para: r-sig-geo at stat.math.ethz.ch
Asunto: R-sig-Geo Digest, Vol 84, Issue 18

Send R-sig-Geo mailing list submissions to
	r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
	r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. Re: lagsarlm with simulated data (Malcolm Fairbrother)
   2. spRbind for spplot (Klaus Vormoor)
   3. Temporal marked point process with time-varying	covariates
      (Mayeul KAUFFMANN)
   4. Re: Best distance for a semi-variogram calculation (Scionforbai)
   5. Re: lagsarlm with simulated data (Roger Bivand)
   6. Re: spRbind for spplot (Paul Hiemstra)
   7. Re: Temporal marked point process with time-varying
      covariates (Roger Bivand)
   8. Re: spRbind for spplot (Klaus Vormoor)
   9. Re: spRbind for spplot (Paul Hiemstra)
  10. Spatial data tower of babel (Barry Rowlingson)


----------------------------------------------------------------------

Message: 1
Date: Tue, 17 Aug 2010 13:37:54 +0100
From: Malcolm Fairbrother <m.fairbrother at bristol.ac.uk>
To: Roger.Bivand at nhh.no
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] lagsarlm with simulated data
Message-ID: <7329C44A-01D0-4BB2-A980-4C7366F85C4F at bristol.ac.uk>
Content-Type: text/plain; charset=us-ascii

Dear Roger (and any other interested parties),

Thanks very much for responding. I tried adding the scale() argument you suggested, but that didn't seem to make any difference. I've set a seed, and to make it even more easily reproducible, I've loosely followed code from: http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg00799.html. The contiguities (in addition to the data) are now generated directly using the code below.

I'm still getting consistent upward bias for the Intercept, and otherwise perfect

[No se incluye el mensaje original entero]

From jon.skoien at jrc.ec.europa.eu  Wed Aug 18 14:37:46 2010
From: jon.skoien at jrc.ec.europa.eu (Jon Olav Skoien)
Date: Wed, 18 Aug 2010 14:37:46 +0200
Subject: [R-sig-Geo] spRbind for spplot
In-Reply-To: <web-5153658@be2.uni-bonn.de>
References: <1282050390945-5431975.post@n2.nabble.com>	<4C6AD337.7060208@geo.uu.nl>
	<web-5153658@be2.uni-bonn.de>
Message-ID: <4C6BD41A.4090506@jrc.ec.europa.eu>

Hi Klaus,

> When I try
>> plot_poly = rtopObj3$observations
>> plot_poly$predictions = rtopObj3$predictions$var1.pred
>> spplot(plot_poly, c("observations", "predictions"))
> it does not work since the replacement has 2100 rows and the data has 
> 100.
>
> I would like to create a new object (e.g. plot_poly) which holds the 
> spatial information of all catchment-polygons (nor) as well as the 
> attributes of both observations$QNORM_12_4 and predictions$var1.pred 
> to the corresponding areas. Therefore, I thought spRbind might be a 
> propper solution.
Following up on Pauls suggestion, I think the best is first to make sure 
that you have the same column names in both objects:

observations$var1.pred = NA
predictions$QNORM_12_4 = NA
obs = observations[,c("QNORM_12_4","var1.pred")]
pred = predictions[,c("QNORM_12_4","var1.pred")]
# Now both objects should just contain columns for observations and 
predictions

Then you most likely have to make sure that you have different polygon 
IDs in the two objects. You can try without first, but will most likely 
get an error. If the following does not work, try a larger number:
pred = spChFIDs(pred,as.character(1000+c(1:dim(pred)[1])))

You can then combine the objects:
plot_poly = spRbind(obs,pred)

spplot(plot_poly,c("QNORM_12_4","var1.pred"))

Hope this works!
Jon


From gavin.simpson at ucl.ac.uk  Wed Aug 18 19:49:33 2010
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 18 Aug 2010 18:49:33 +0100
Subject: [R-sig-Geo] Convert SpatialGridDataFrame to polygons...?
In-Reply-To: <alpine.LRH.2.00.1007152055370.12918@reclus.nhh.no>
References: <1279193294.26456.16.camel@localhost>
	<2C1F0E483039ED4CBE03BCC5740635923F8506@exchange-be3.lancs.local>
	<alpine.LRH.2.00.1007152055370.12918@reclus.nhh.no>
Message-ID: <1282153773.2352.100.camel@desktop.localdomain>

On Thu, 2010-07-15 at 21:06 +0200, Roger Bivand wrote:
> On Thu, 15 Jul 2010, Crowe, Andrew wrote:
> 
> > Gavin
> >
> > Gavin
> >
> > You can convert the raster grid to a polygon grid by coercing the 
> > SpatialGridDataFrame to a SpatialPixelsDataFrame then from that to a 
> > SpatialPolygonsDataFrame.
> >
> > You should then be able to recode the polygon data for each particular 
> > depth class and union them using unionSpatialPolygons.  This then needs 
> > joining with a data frame created from the depth classes to create a 
> > SpatialPolygonsDataFrame for output to a shapefile using writePolyShape

A little belatedly as I didn't get chance to work through the
suggestions from Andrew and Roger before I had to leave for an extended
fieldwork trip that I have just returned from...

Thanks Roger and Andrew for your suggestions. Roger asked me to let you
know how I got on, so here goes.

Roger's solution was what I had in mind when I was thinking how to do
things. And it worked nicely for some of the sites I needed to apply
this to. But for most sites it didn't work because many of the contour
lines produced from the grid were open lines, not closed lines. I view
this as a feature of the data I had to do this for (lake bathymetry data
where we don't have an accurate lake outline (0m depth) or indeed for
some sites even data over the entire lake).

I next tried Andrew's suggestion and this worked for all the sites I
needed to apply it to as it basically turns the grid into a series of
polygons and we then union the cell polygons that belong to same depth
interval. The only downside is that, as Roger mentioned, it produces
"jagged" sets of polygons, and these polygons are quite complex; some
depth classes are represented by numerous individual polygons
representing single pixels in the original grid. C'est la vie.

Finally, I've begun using the sp stack and related packages more and
more recently and I now have a reasonable working feel for what can be
done and how to achieve some fairly complex (for me, anyway) results. I
have been struck by how powerful and easy to use all this is. This is
due to the authors and maintainers of the various spatial R packages. As
it is easy to overlook this fact when deadlines loom etc; here's a BIG
thank you to you all, from me, for all the hard work!

G

> In addition, you can massage the output of contourLines() to make a less 
> jagged version:
> 
> library(maptools)
> data(volcano)
> x2 <- ContourLines2SLDF(contourLines(volcano))
> # volcano is a regular "image" style object, SpatialGridDataFrame
> # objects can be coerced with as.image.SpatialGridDataFrame()
> # we don't (yet) have contourLines() for sp objects
> x3 <- x2[(as.character(x2$level) > "140" & as.character(x2$level) <
>   "170"),]
> cx3 <- coordinates(x3)
> str(cx3)
> crds <- rbind(cx3[[1]][[1]], c(NA, NA), cx3[[2]][[1]], c(NA, NA),
>    cx3[[2]][[2]], c(NA, NA), cx3[[1]][[2]])
> # this could be automated in a loop
> colnames(crds) <- c("x", "y")
> pols <- map2SpatialPolygons(as.data.frame(crds), IDs=rep("1", 4))
> # number of IDs like input polygons
> pls <- slot(pols, "polygons")
> gpclibPermit()
> pls1 <- lapply(pls, checkPolygonsHoles)
> slot(pols, "polygons") <- pls1
> plot(pols, col="grey", pbg="yellow")
> 
> Both the use of checkPolygonsHoles() and unionSpatialPolygons require the 
> use of gpclib with its bad licence. We're at mid-term with the GSoC rgeos 
> project now, which provides similar facilities.
> 
> Using the contour lines may give a visually more pleasing, and maybe more 
> helpful rendering than the blocky polygonised raster cells (which anyway 
> will have been interpolated).
> 
> Please let us know how you get on,
> 
> Roger
> 
> 
> >
> > Hope that helps
> >
> > Andrew
> >
> > Dr Andrew Crowe
> >
> > Lancaster Environment Centre
> > Lancaster University
> > Lancaster    LA1 4YQ
> > UK
> >
> > Tel: +44 (0)1524 595879
> >
> > ________________________________
> >
> > From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Gavin Simpson
> > Sent: Thu 15/07/2010 12:28 PM
> > To: r-sig-geo at stat.math.ethz.ch
> > Subject: [R-sig-Geo] Convert SpatialGridDataFrame to polygons...?
> >
> >
> >
> > Dear list,
> >
> > I have been given a set of ASCII grids which I read into R using
> > readAsciiGrid(). The grids represent an interpolated water depth data
> > set for a set of lakes; each grid represents a separate lake. For some
> > reason I have been asked to convert this gridded data into a set of
> > polygons. For example; given the gridded data, I want to generate a
> > polygon that covers the area of the lake (from the grid) that is 1-2m
> > deep say. I would then need to write out this polygon as an ESRI shape
> > file.
> >
> > Are there tools in R to do this sort of conversion?
> >
> > It is a bit more complex that the simple example, as lakes can have
> > multiple basins (areas of deeper water). Say a lake has two deep areas
> > so a cross section through the lakes might look like a W, for such a
> > lake I would require an object that contained two polygons representing
> > the area of the lake between 4 and 5 meters say in *each* of the basins.
> > These would then be read out into a shape file. My GIS colleague
> > indicates that ArcGIS/ArcMAP has a function to polygonise a raster grid
> > in such a way. Is there something similar in the R spatial software
> > stack?
> >
> > An alternative approach would be to contour (at appropriate depth
> > intervals) the interpolated grid and convert the set of contours into
> > polygons for individual lakes. Is there a function to do this?
> >
> > As you can see, this is very much a look-see at the moment. We are
> > evaluating whether it would be quicker to work out how to do this in R
> > as opposed to doing it by hand in ArcGIS.
> >
> > Any suggestions would be most gratefully received indeed!
> >
> > All the best,
> >
> > Gavin
> > --
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> > Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
> > ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
> > Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
> > Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
> > UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk <http://www.freshwaters.org.uk/>
> > %~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 

-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
 Dr. Gavin Simpson             [t] +44 (0)20 7679 0522
 ECRC, UCL Geography,          [f] +44 (0)20 7679 0565
 Pearson Building,             [e] gavin.simpsonATNOSPAMucl.ac.uk
 Gower Street, London          [w] http://www.ucl.ac.uk/~ucfagls/
 UK. WC1E 6BT.                 [w] http://www.freshwaters.org.uk
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%


From mayeul.kauffmann at jrc.ec.europa.eu  Wed Aug 18 19:56:38 2010
From: mayeul.kauffmann at jrc.ec.europa.eu (Mayeul KAUFFMANN)
Date: Wed, 18 Aug 2010 19:56:38 +0200
Subject: [R-sig-Geo] Temporal marked point process with time-varying
	covariates
In-Reply-To: <4C6B0523.2040904@statsresearch.co.nz>
References: <001401cb3e12$ab6ea640$024bf2c0$%kauffmann@jrc.ec.europa.eu>
	<4C6B0523.2040904@statsresearch.co.nz>
Message-ID: <000601cb3efe$b5133020$1f399060$@kauffmann@jrc.ec.europa.eu>

Dear David,
Thanks a lot for your prompt and detailed answer!

You wrote:
"I do not think that the ETAS model will have any relevance for your
situation. The spatial ETAS model is slightly peculiar [...]"
What I find very interesting in an epidemic-type model like the spatial ETAS
model is the analogy that is possible to make between earthquakes and violent
events: earthquakes are likely to be followed by aftershocks shortly after and
in the vicinity. Similarly, violence fuels violence locally: a victory by an
armed group may trigger a retaliatory action by another armed group, soon after
and in the same area. For the other etas_gif function, "spatial coordinates of
the events are not taken into account" whereas the non-etas models do not take
into account the history of the point process. Can I mimic this time-space
dependence among events without the spatial ETAS model, or (sorry to insist),
can I use the spatial ETAS model for my purpose?

You also wrote:
"What sort of functional relationship are you proposing for your data? Can you
write an equation for your ground intensity function?" and "There is no reason
why other covariates cannot be part of the defined ground intensity function, or
the mark distribution."
OK, great. I am trying to do this with R but I'm not sure how to program it. In
all pages of the PtProcess package manual where the "data" parameter is
mentioned, it is a dataframe containing data about the (potentially marked)
point process. I need to take into account the value of covariates even in
places where there are no events. In the earthquake field, for example, one
might want to use the type of soil as a covariate: in this case, how to have one
of the gif be dependent on the covariates? You seem to imply that it should not
be too difficult: "given your specification of your conditional intensity as a
function of the covariates, you should be able to mimic the required structure,
and write your own ground intensity function."
For instance, starting from the conditional intensity function given (again) in
help(etas_spatial):
lambda(t,x,y|Ht) = mu + A SUM_{i: ti < t} exp{beta(Mi-Mo)} g(x-xi, y-yi) f(t-ti)
then I might consider trying to introduce the covariates here (is it what you
suggested?), in a simplistic way:
lambda(t,x,y|Ht) = h(a1.Z1 + a2.Z2 + ...) + mu + A SUM_{i: ti < t}
exp{beta(Mi-Mo)} g(x-xi, y-yi) f(t-ti) (equation 1)
where my h(.) function would be a monotonous function of a linear combination of
the Z1, Z2,... covariates, those covariates being measured at (t, x, y). (I
might also consider a multiplicative influence of h() on lambda instead of the
above additive one).
Then, if the above makes sense, I have to modify the following part of the
etas_normal0() R function:
ci <- mu + A * sum(exp(beta * Mi) * omori * spatial)
by adding a term that would be dependent on (xj, yj, tj), namely that will
search for the values of the covariates at (xj, yj, tj). 
(By the way: the i index in your source code is j index [hence previous events]
in equations 4 to 8 of Ogata(2006) paper, and your xj is simply x in the same
paper [hence current point-time], am I correct?)
Finally, I will have to add the a1, a2... coefficients of the linear model into
the "params" vector.
Last not least, there is no room for the covariates themselves in the function
parameters (if I am correct this is true for all functions of the package??). Do
I have to make my function search for those values globally (outside of the
scope of the function) ???

I hope I did not write too many inaccuracies above, and I thank you again for
your time!
I have some colleagues who work on environmental spatial statistics and I agree
with your assessment in your JSS paper that this package may be used in many
fields.
Best regards,
Mayeul 




_____________________________________________________
Dr. Mayeul KAUFFMANN, Conflict Specialist
European Commission, Joint Research Centre (JRC)
Institute for the Protection and Security of the Citizen (IPSC)
Global Security and Crisis Management - ISFEREA
Via E. Fermi 2749 - I-21027 Ispra (VA), ITALY
Phone: (+39) 033278 5071
http://isferea.jrc.ec.europa.eu/Staff/Pages/Kauffmann-Mayeul.aspx

(Office: building 48c, 1st floor, room 123. TP: 483)


From Roger.Bivand at nhh.no  Wed Aug 18 21:05:19 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Aug 2010 21:05:19 +0200 (CEST)
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>

On Wed, 18 Aug 2010, Barry Rowlingson wrote:

> Hi,
>
> Recently while teaching at SFU I hit the problem that infects R when
> many people work on similar projects - the multitude of data formats
> for similar data. The sp project was partly an attempt to give a
> standard format for spatial data but its widespread non-use in older
> packages causes trouble.
>
> So for example I taught the students all about 'sp' objects, and then
> they had to use spatstat and splancs for some point-process stuff,
> then geoR for some kriging, none of which use sp objects.
>
> So I figured maybe we need a whole load of 'as' functions that can
> convert between the various spatial data formats (there are more in
> CRAN, I am sure) to help us all out on this. Some of these functions
> may already exist, indeed I just found something about converting
> fairly raw x-y coordinate objects to SpatialPolygons hidden away in
> the SpatialEpi package (polygons2spatial.polygons).

Barry,

I think that spatstat is well provided for, mostly in maptools, but also 
in the spatstat vignette on using shapefiles. Of course, the available 
functionalities sp <-> spatstat classes could probably be documented more 
fully, and the coercion functions updated, but I think that they do most 
of what is needed.

I agree that there may be others out there, and like you come across them 
from time to time. Sometimes the CRAN reverse dependencies show who they 
might be. Since splancs is largely pre-S3 (right?) and doesn't use 
classes, coercion isn't an option, so documentation and a wrapper function 
or two might be sensible. I started on this, but only got as far as the 
spkernel2d() that uses a call to GridTopology() to set up the output grid.

geoR does use S3 classes, so might be closer, and does depend on sp. There 
is a method for coercing a SpatialPointsDataFrame to "geodata". The 
borders component of a "geodata" object is harder to introduce. Taking the 
coordinates() of a SpatialPixels object to pass to locations= is OK, as 
are the subsetting of data frame columns for the trend.d= and trend.l= 
arguments. I guess Paulo would need to move to a formula= data= interface 
to likfit(), krige.bayes() and krige.conv(), at least, to permit sp 
objects to be used "closer" to the actual core.

Probably a good deal could be done by documentation, and by communicating 
better about what already is there.

Useful topic!

Best wishes,

Roger

>
> Would it be a good idea to stick all the conversions we can think of
> into a single package, "spBabel" say (or spConversion to avoid any
> cultural reference), so people have a one-stop shop? And if we find
> routines stuck in other packages (such as polygons2spatial.polygons)
> we rip them out and bundle them?
>
> Yes, its a matter of time and effort and we're all busy, but I'd like
> to put it out as a proposal. It might make a nice intern or GSOC
> project, but we're a bit late for that, so maybe if anyone has a PhD
> student starting who needs to get up to speed with R packages and
> spatial data it would be a good introduction for them. Once its all
> set up (on R-forge or similar) contributing shouldn't be a problem.
>
> Okay, that's my one crazy idea for the day done.
>
> Barry
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed Aug 18 22:06:15 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Aug 2010 22:06:15 +0200 (CEST)
Subject: [R-sig-Geo] polygon adjacency testing
In-Reply-To: <AANLkTinTgUgLHp42idCJCoBZB3gBaKYrF-zmD+fPyJqm@mail.gmail.com>
References: <AANLkTinpkEFw+zErBZV-9_LRXHE5qKrtLqiPBe-XG_X+@mail.gmail.com>
	<1DF060F2-5ED1-4826-9E59-7CA57C7CFD5D@gmail.com>
	<AANLkTinTgUgLHp42idCJCoBZB3gBaKYrF-zmD+fPyJqm@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008182126460.4275@reclus.nhh.no>

On Fri, 13 Aug 2010, Barry Rowlingson wrote:

> On Fri, Aug 13, 2010 at 4:59 PM, Nikhil Kaza <nikhil.list at gmail.com> wrote:
>>
>> I havent looked at poly2nb code, but would eliminating polygons from the
>> polygon list based on area, perimeter ?or ratio of these two, before
>> constructing the neighbour list work? This would be similar, not identical,
>> to eliminate in ArcInfo.
>> http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?TopicName=Eliminate%20%28Data%20Management%29
>
> That's okay for general cleanups of slivers etc, but it wont catch
> other problems that might manifest themselves via adjacency. My
> substantive problem uses polygon adjacency in its model, so I was
> hoping for a way of assessing the correctness of the adjacency graph.
>
> I'm pretty sure I can do it with LinesIntersections from rgeos now,
> its just a bit of a grind to get rid of all the intersections from
> coincident endpoints. nb2lines is also useful.

Barry,

The input shapefile is the one on Lance Waller's website:

http://www.sph.emory.edu/~lwaller/ch9index.htm

which may have been "doctored" to link the Hebrides, Orkney and Shetland 
to the mainland, with unforeseen consequences. poly2nb() should *not* link 
these islands unless they are contiguous! After examination in Saga, 
zooming in close, the slivers do seem to have been "added" to generate 
contiguities for non-contiguous polygons, but that someone's enthusiasm 
has run away with them. Did you try identifying the extraneous slivers, 
seeing if they are duplicated, if so delete the "foreign" one, if not do 
union on them with the contiguous big polygon? They are tiny, so accessing 
the area slot of the Polygon objects should show which is which.

Best wishes,

Roger

>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From breitbach at uni-mainz.de  Thu Aug 19 13:12:36 2010
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Thu, 19 Aug 2010 11:12:36 +0000
Subject: [R-sig-Geo] Error using gpclib fuctions
Message-ID: <E7F1EF063B11DA4DAD16374549B879E82AD9B01A@e14mdb-02.zdv.Uni-Mainz.DE>

Dear Community,

trying to get through the examples from "Applied Spatial Data Analysis with R" I got problems with the gpclib package. 

The library was loaded correctly:

> library(gpclib)
General Polygon Clipper Library for R (version 1.5-1)
	Type 'class ? gpc.poly' for help

... but then when I tried to use the unionSpatialPolygons function I recieved the following error message:

> nc90.temp_spndf <- unionSpatialPolygons(nc90_spndf, IDs = paste(nc90_spndf$ST, nc90_spndf$CO, sep="_"))
Error: isTRUE(gpclibPermitStatus()) is not TRUE

I am aware that GPC is not generally free but free for academic research, which is hopefully what I am doing here. Do I have to place a licence file somewhere to satisfy the gpclibPermitStatus function? Or do I need to install the GPC software in addition to the package?

Cheers,

Nils Breitbach

From nikhil.list at gmail.com  Thu Aug 19 13:15:54 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Thu, 19 Aug 2010 07:15:54 -0400
Subject: [R-sig-Geo] Error using gpclib fuctions
In-Reply-To: <E7F1EF063B11DA4DAD16374549B879E82AD9B01A@e14mdb-02.zdv.Uni-Mainz.DE>
References: <E7F1EF063B11DA4DAD16374549B879E82AD9B01A@e14mdb-02.zdv.Uni-Mainz.DE>
Message-ID: <D733F7D7-2D19-4CE7-AA5E-74928C97A501@gmail.com>


Just issue the command once in the session.

gpclibPermit()

Alternatively, you could wait for the rgeos package.

Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 19, 2010, at 7:12 AM, Breitbach, Nils wrote:

> Dear Community,
>
> trying to get through the examples from "Applied Spatial Data  
> Analysis with R" I got problems with the gpclib package.
>
> The library was loaded correctly:
>
>> library(gpclib)
> General Polygon Clipper Library for R (version 1.5-1)
> 	Type 'class ? gpc.poly' for help
>
> ... but then when I tried to use the unionSpatialPolygons function I  
> recieved the following error message:
>
>> nc90.temp_spndf <- unionSpatialPolygons(nc90_spndf, IDs =  
>> paste(nc90_spndf$ST, nc90_spndf$CO, sep="_"))
> Error: isTRUE(gpclibPermitStatus()) is not TRUE
>
> I am aware that GPC is not generally free but free for academic  
> research, which is hopefully what I am doing here. Do I have to  
> place a licence file somewhere to satisfy the gpclibPermitStatus  
> function? Or do I need to install the GPC software in addition to  
> the package?
>
> Cheers,
>
> Nils Breitbach
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From haenlein at escpeurope.eu  Thu Aug 19 17:23:19 2010
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Thu, 19 Aug 2010 17:23:19 +0200
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
Message-ID: <AANLkTik4sTwED=m_XDOgUfGifZeP0352Tx5mDtK8Gqvf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100819/614ec0ef/attachment.pl>

From Rafael.Lata at ait.ac.at  Thu Aug 19 19:32:34 2010
From: Rafael.Lata at ait.ac.at (Lata Rafael)
Date: Thu, 19 Aug 2010 19:32:34 +0200
Subject: [R-sig-Geo] From Sparse Matrix to Listw
Message-ID: <03DD2D3DC948ED4795830164EA3F302ED80A16497B@MAILBOX.arc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100819/a9fdd8e0/attachment.pl>

From yud at mail.montclair.edu  Thu Aug 19 20:35:54 2010
From: yud at mail.montclair.edu (Danlin Yu)
Date: Thu, 19 Aug 2010 14:35:54 -0400
Subject: [R-sig-Geo] Codes or programs that implement models in the paper
 "Spatial Modeling With Spatially Varying Coefficient Processes"
Message-ID: <4C6D798A.8040300@mail.montclair.edu>

  Hi, list:

Hopefully this is appropriate here.

I am recently reading the paper "Spatial Modeling With Spatially Varying 
Coefficient Processes" by Alan E. Gelfand, Hyon-Jung Kim, C.F. Sirmans, 
and Sudipto Banerjee, published in Journal of the American Statistical 
Association, 2003, 387-396. The ideas presented in the paper are very 
interesting. Yet I searched a while on the web (and within R archives) 
and trying to locate some codes or routines that implement their model 
without much luck. If anyone has any leads, I would greatly appreciate it.

Thanks in advance.

Best,
Danlin Yu

-- 
___________________________________________
Danlin Yu, Ph.D.
Associate Professor of GIS and Urban Geography
Department of Earth&  Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From Roger.Bivand at nhh.no  Thu Aug 19 23:41:10 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Aug 2010 23:41:10 +0200 (CEST)
Subject: [R-sig-Geo] From Sparse Matrix to Listw
In-Reply-To: <03DD2D3DC948ED4795830164EA3F302ED80A16497B@MAILBOX.arc.local>
References: <03DD2D3DC948ED4795830164EA3F302ED80A16497B@MAILBOX.arc.local>
Message-ID: <alpine.LRH.2.00.1008192337210.8813@reclus.nhh.no>

On Thu, 19 Aug 2010, Lata Rafael wrote:

> Dear all,
>
> I have a problem converting a large binary sparse weight matrix (62025 *
> 62025) of class dgT to listw

You mean in package Matrix, and as described in ?"TsparseMatrix-class"?

>
> Is there a function that creates a listw object from a sparse matrix?

>From the description, you should be able to work out how to convert such 
an object into a "spatial.neighbours" object (see listw2sn), then use 
sn2listw() to go the other way. Watch the attributes, as they need to be 
correct. Also note that the input object uses 0-base indices, but the sn 
object uses 1-base indices.

Hope this helps,

Roger

>
> Thank you in advance.
>
>
>
> Best regards
>
>
>
> Rafael Lata
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Aug 19 23:53:59 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Aug 2010 23:53:59 +0200 (CEST)
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
In-Reply-To: <AANLkTik4sTwED=m_XDOgUfGifZeP0352Tx5mDtK8Gqvf@mail.gmail.com>
References: <AANLkTik4sTwED=m_XDOgUfGifZeP0352Tx5mDtK8Gqvf@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008192346380.8813@reclus.nhh.no>

On Thu, 19 Aug 2010, Michael Haenlein wrote:

> Dear all,
>
> this is probably a very stupid question -- in case it is I apologize in
> advance.
>
> I'm not very familiar with spatial statistics, although I have used the
> spdep package previously (specifically the moran.mc and moran.test
> functions) in a different context.
>
> I have a dataset with roughly 150,000 records where each record corresponds
> to a person. For each record (person) I have a series of continuous
> variables (x1, x2, x3, ...) -- for example how much money the person earns
> or how often s/he buys shampoo - and a ZIP Code where the person is living.
> The ZIP Codes are all five digit and stem from the US (e.g., 10022, 92506,
> 43614).
>
> I'd like to calculate Moran's I for each of my continuous variables in order
> to identify for which measures there is spatial autocorrelation.
>
> Is there a convenient/ automatic way to convert my list of ZIP codes into an
> listw object which I can use as an input for moran.mc or moran.test?

The first thing is to get the locations of the zip codes (about 30,000?) - 
they are published as shapefiles by state (US Census ZCTA), so a polygon 
representation is possible, but you could also look for a point 
representation. Next make a neighbour list (nb) object to the zip code 
entities for which you have observations. Then you could use nb2blocknb() 
in spdep to "block up" observations where more than one belongs to the 
same zip code, which effectively makes all the observations in a zip code 
neighbours, and adds all the observations in neighbouring zip codes too. 
It was written for housing data with only a postcode but no geocoded 
address.

Hope this helps,

Roger

>
> Thanks very much for your help in advance,
>
> Michael
>
>
>
>
> Michael Haenlein
> Associate Professor of Marketing
> ESCP Europe
> Paris, France
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From haenlein at escpeurope.eu  Fri Aug 20 18:47:12 2010
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Fri, 20 Aug 2010 18:47:12 +0200
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
Message-ID: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100820/5c99b89e/attachment.pl>

From sharon.i.odonnell at gmail.com  Fri Aug 20 19:06:36 2010
From: sharon.i.odonnell at gmail.com (Sharon O'Donnell)
Date: Fri, 20 Aug 2010 13:06:36 -0400
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
In-Reply-To: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>
References: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>
Message-ID: <AANLkTimr1iwzh_eiO6DZ7B2eunZzPp0y3tq8XJkMqSUn@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100820/2580a370/attachment.pl>

From nikhil.list at gmail.com  Fri Aug 20 19:56:56 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Fri, 20 Aug 2010 13:56:56 -0400
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
In-Reply-To: <AANLkTimr1iwzh_eiO6DZ7B2eunZzPp0y3tq8XJkMqSUn@mail.gmail.com>
References: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>
	<AANLkTimr1iwzh_eiO6DZ7B2eunZzPp0y3tq8XJkMqSUn@mail.gmail.com>
Message-ID: <CD554C9C-F900-4CB1-9975-25C912C10DF0@gmail.com>

The national files for the zipcodes seems greyed out. I would caution  
against creating nb lists for each state separate and then creating a  
US wide neighbour list because, there will some zip codes in Alabama  
who are neighbours to  zipcodes in GA, MS, TN. I would merge them  
first into one big file and then construct the poly list.  you may run  
into memory issues for this operation, depending on your set up.


Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 20, 2010, at 1:06 PM, Sharon O'Donnell wrote:

> Check out
>
> http://www2.census.gov/cgi-bin/shapefiles2009/national-files - left  
> hand
> side has national - level data.
>
> All 5 digit zipcode files are based on 2002 data but zipcode  
> boundaries
> change less frequently than tracts and blockgroups, there may be  
> some issues
> in correctly mapping out areas in high growth regions of the U.S.  
> with new
> zipcodes.
>
> Sharon
>
> On Fri, Aug 20, 2010 at 12:47 PM, Michael Haenlein
> <haenlein at escpeurope.eu>wrote:
>
>> Thanks very much for your reply, Roger!
>>
>> I have downloaded the shape files from the US Census ZCTA webpage.  
>> In case
>> anyone else is interested in obtaining them the URL is:
>> http://www.census.gov/geo/www/cob/z52000.html#shp
>>
>> I also managed to import those files into R and to convert them into
>> a neighbour list:
>>
>> Alabama <-readShapePoly("c:/111/zt01_d00")
>> Alaska <-readShapePoly("c:/111/zt02_d00")
>> Arizona <-readShapePoly("c:/111/zt04_d00")
>> ...
>>
>> Alabama.nb <- poly2nb(Alabama)
>> Alaska.nb <- poly2nb(Alaska)
>> Arizona.nb  <- poly2nb(Arizona)
>> ...
>>
>> The problem is that instead of having one neighbour list I now have  
>> 52 ones
>> (one for each state).
>> Is there a way to combine all of them into one large neighbour list  
>> which I
>> can then use as an input for my analysis?
>>
>>
>>
>>
>> -----Original Message-----
>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>> Sent: Thursday, August 19, 2010 23:54
>> To: Michael Haenlein
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] Moran's I based on ZIP Code data
>>
>> On Thu, 19 Aug 2010, Michael Haenlein wrote:
>>
>> The first thing is to get the locations of the zip codes (about  
>> 30,000?) -
>> they are published as shapefiles by state (US Census ZCTA), so a  
>> polygon
>> representation is possible, but you could also look for a point
>> representation. Next make a neighbour list (nb) object to the zip  
>> code
>> entities for which you have observations. Then you could use  
>> nb2blocknb()
>> in
>> spdep to "block up" observations where more than one belongs to the  
>> same
>> zip
>> code, which effectively makes all the observations in a zip code
>> neighbours,
>> and adds all the observations in neighbouring zip codes too.
>> It was written for housing data with only a postcode but no geocoded
>> address.
>>
>> Hope this helps,
>>
>> Roger
>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian  
>> School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Sat Aug 21 00:33:41 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 21 Aug 2010 00:33:41 +0200 (CEST)
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
In-Reply-To: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>
References: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008210027400.13067@reclus.nhh.no>

On Fri, 20 Aug 2010, Michael Haenlein wrote:

> Thanks very much for your reply, Roger!
>
> I have downloaded the shape files from the US Census ZCTA webpage. In case
> anyone else is interested in obtaining them the URL is:
> http://www.census.gov/geo/www/cob/z52000.html#shp
>
> I also managed to import those files into R and to convert them into
> a neighbour list:
>
> Alabama <-readShapePoly("c:/111/zt01_d00")
> Alaska <-readShapePoly("c:/111/zt02_d00")
> Arizona <-readShapePoly("c:/111/zt04_d00")
> ...
>
> Alabama.nb <- poly2nb(Alabama)
> Alaska.nb <- poly2nb(Alaska)
> Arizona.nb  <- poly2nb(Arizona)
> ...
>
> The problem is that instead of having one neighbour list I now have 52 ones
> (one for each state).
> Is there a way to combine all of them into one large neighbour list which I
> can then use as an input for my analysis?
>

Combine the imported SpatialPolygonsDataFrames, possibly after filtering 
out the ones with no hits, and possibly after checking for ZIP uniqueness. 
If not unique (if a ZIP crosses a state boundary or if the input maps 
assign a single ZIP code to multiple Polygons objects) use 
unionSpatialPolygons in maptools (usual warning about gpclib) or 
gUnionCascade() in rgeos. If you can install rgeos, you can also speed up 
the poly2nb() step for the whole map by providing a GEOS-generated list of 
candidate neighbours.

It is feasible, but perhaps tedious - there are a lot of polygons!

Good luck!

Roger

>
>
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Thursday, August 19, 2010 23:54
> To: Michael Haenlein
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Moran's I based on ZIP Code data
>
> On Thu, 19 Aug 2010, Michael Haenlein wrote:
>
> The first thing is to get the locations of the zip codes (about 30,000?) -
> they are published as shapefiles by state (US Census ZCTA), so a polygon
> representation is possible, but you could also look for a point
> representation. Next make a neighbour list (nb) object to the zip code
> entities for which you have observations. Then you could use nb2blocknb() in
> spdep to "block up" observations where more than one belongs to the same zip
> code, which effectively makes all the observations in a zip code neighbours,
> and adds all the observations in neighbouring zip codes too.
> It was written for housing data with only a postcode but no geocoded
> address.
>
> Hope this helps,
>
> Roger
>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kerryr at sccwrp.org  Sat Aug 21 00:45:09 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Fri, 20 Aug 2010 15:45:09 -0700
Subject: [R-sig-Geo] anisotropic models vs. detrending
Message-ID: <4C6F0575.7090805@sccwrp.org>

Hi. I was wondering which model you would tend to choose given similar 
cross validation results. 
1. An isotropic model with linear trend
2. An anisotropic model
Assume linear trend is ~x + y + I(x*y), where x,y are spatial coordinates.

I have read papers that argue that unless you know how to interpret the 
linear trend (from a phyiscal/geographical/biological point of view) it 
is better NOT to detrend the data prior to fitting a variogram.  On the 
other hand, one must ultimately assume stationarity. So I am not sure 
which way to go.  How do you decide?

Thanks,
Kerry

-- 
**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From ashton at msu.edu  Sat Aug 21 01:10:11 2010
From: ashton at msu.edu (Ashton Shortridge)
Date: Fri, 20 Aug 2010 19:10:11 -0400
Subject: [R-sig-Geo] anisotropic models vs. detrending
In-Reply-To: <4C6F0575.7090805@sccwrp.org>
References: <4C6F0575.7090805@sccwrp.org>
Message-ID: <201008201910.11982.ashton@msu.edu>


On 2010-08-20, Kerry Ritter, wrote:
> Hi. I was wondering which model you would tend to choose given similar
> cross validation results.
> 1. An isotropic model with linear trend
> 2. An anisotropic model
> Assume linear trend is ~x + y + I(x*y), where x,y are spatial coordinates.
> 
> I have read papers that argue that unless you know how to interpret the
> linear trend (from a phyiscal/geographical/biological point of view) it
> is better NOT to detrend the data prior to fitting a variogram.  On the
> other hand, one must ultimately assume stationarity. So I am not sure
> which way to go.  How do you decide?
> 
> Thanks,
> Kerry

Hi Kerry,

If your goal with this model is to develop predictions within the extents of 
your existing data (that is, not extrapolating), then either approach probably 
produces about the same result. These alternatives do employ very different 
conceptual models of the process you are trying to capture, so from that 
perspective it might be best to go with the model that best fits your 
understanding, but from a utilitarian perspective, either will work.

I find it is often difficult in practice to fit an anisotropic model well - the 
lack of sufficient data in different directions can make the variograms noisy. 
Low-order trends like yours are simple to fit. Using OLS to fit a trend surface 
to spatially autocorrelated observations can be problematic, but universal 
kriging is a more robust alternative (though this frequently seems to make 
little difference in practice).

Of course, you can use both to develop predictions, or prediction surfaces, 
and take the difference of the two to see how much your choice matters. In the 
end, perhaps employ the method that you find simplest to explain!

Yours,

Ashton

-----
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From jochen at hunter.cuny.edu  Sat Aug 21 01:23:56 2010
From: jochen at hunter.cuny.edu (Jochen Albrecht)
Date: Fri, 20 Aug 2010 19:23:56 -0400
Subject: [R-sig-Geo] Moran's I based on ZIP Code data
In-Reply-To: <CD554C9C-F900-4CB1-9975-25C912C10DF0@gmail.com>
References: <AANLkTino-QaVtO47J5v+OzWXy=RCeW2rrn0SUy-=fhmy@mail.gmail.com>
	<AANLkTimr1iwzh_eiO6DZ7B2eunZzPp0y3tq8XJkMqSUn@mail.gmail.com>
	<CD554C9C-F900-4CB1-9975-25C912C10DF0@gmail.com>
Message-ID: <4C6F0E8C.7080708@hunter.cuny.edu>


Nikhil has a point here. The combined shapefile is > 1 GB.
As I am into working with national census datasets (and would eventually 
like to do the same for tracts and blocks), I created a neighbor list 
and then a weights list. The latter required using the zero.policy=TRUE 
switch as we are working with many islands that have no topological 
neighbors. I uploaded the two as R objects to 
http:giscience.hunter.cuny.edu/zcta/zcta.nb.R and 
http://giscience.hunter.cuny.edu/zcta/zcta.w.R.
Cheers,
    Jochen


Nikhil Kaza wrote:
> The national files for the zipcodes seems greyed out. I would caution 
> against creating nb lists for each state separate and then creating a 
> US wide neighbour list because, there will some zip codes in Alabama 
> who are neighbours to  zipcodes in GA, MS, TN. I would merge them 
> first into one big file and then construct the poly list.  you may run 
> into memory issues for this operation, depending on your set up.
>
>
> Nikhil Kaza
> Asst. Professor,
> City and Regional Planning
> University of North Carolina
>
> nikhil.list at gmail.com
>
> On Aug 20, 2010, at 1:06 PM, Sharon O'Donnell wrote:
>
>> Check out
>>
>> http://www2.census.gov/cgi-bin/shapefiles2009/national-files - left hand
>> side has national - level data.
>>
>> All 5 digit zipcode files are based on 2002 data but zipcode boundaries
>> change less frequently than tracts and blockgroups, there may be some 
>> issues
>> in correctly mapping out areas in high growth regions of the U.S. 
>> with new
>> zipcodes.
>>
>> Sharon
>>
>> On Fri, Aug 20, 2010 at 12:47 PM, Michael Haenlein
>> <haenlein at escpeurope.eu>wrote:
>>
>>> Thanks very much for your reply, Roger!
>>>
>>> I have downloaded the shape files from the US Census ZCTA webpage. 
>>> In case
>>> anyone else is interested in obtaining them the URL is:
>>> http://www.census.gov/geo/www/cob/z52000.html#shp
>>>
>>> I also managed to import those files into R and to convert them into
>>> a neighbour list:
>>>
>>> Alabama <-readShapePoly("c:/111/zt01_d00")
>>> Alaska <-readShapePoly("c:/111/zt02_d00")
>>> Arizona <-readShapePoly("c:/111/zt04_d00")
>>> ...
>>>
>>> Alabama.nb <- poly2nb(Alabama)
>>> Alaska.nb <- poly2nb(Alaska)
>>> Arizona.nb  <- poly2nb(Arizona)
>>> ...
>>>
>>> The problem is that instead of having one neighbour list I now have 
>>> 52 ones
>>> (one for each state).
>>> Is there a way to combine all of them into one large neighbour list 
>>> which I
>>> can then use as an input for my analysis?
>>>
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
>>> Sent: Thursday, August 19, 2010 23:54
>>> To: Michael Haenlein
>>> Cc: r-sig-geo at stat.math.ethz.ch
>>> Subject: Re: [R-sig-Geo] Moran's I based on ZIP Code data
>>>
>>> On Thu, 19 Aug 2010, Michael Haenlein wrote:
>>>
>>> The first thing is to get the locations of the zip codes (about 
>>> 30,000?) -
>>> they are published as shapefiles by state (US Census ZCTA), so a 
>>> polygon
>>> representation is possible, but you could also look for a point
>>> representation. Next make a neighbour list (nb) object to the zip code
>>> entities for which you have observations. Then you could use 
>>> nb2blocknb()
>>> in
>>> spdep to "block up" observations where more than one belongs to the 
>>> same
>>> zip
>>> code, which effectively makes all the observations in a zip code
>>> neighbours,
>>> and adds all the observations in neighbouring zip codes too.
>>> It was written for housing data with only a postcode but no geocoded
>>> address.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>
>>> -- 
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian 
>>> School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From breitbach at uni-mainz.de  Sun Aug 22 18:54:02 2010
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Sun, 22 Aug 2010 16:54:02 +0000
Subject: [R-sig-Geo] Choosing the right nb2listw-style
Message-ID: <E7F1EF063B11DA4DAD16374549B879E82AD9E3C1@e14mdb-02.zdv.Uni-Mainz.DE>

Dear Community,

to be able to evaluate the spatial autocorrelation within may data I am forced with the question of how to correctly choose the neighbours for my data. My study plots (points) are not evenly distributed over my study area (approx. 30 x 30 km in size) and also the land-use type is not evenly distributed over the study area and therefore I want to evaluate the spatial autocorrelation for this data set. To finally calculate the Moran's I or plot variograms/correlograms I now need to calculate the neighbourhood relationships of my study plots. For the given characteristic of my data (especially their non-even distribution) I am now somewhat uncertain about the right style (W,  B, C, U or S) of the  nb2listw() object that suits best for my kind of data.

Can anyone recommend the "right" style for my kind of data?

Thanks for help!
Regards,

Nils

_________________________________________________________

Nils Breitbach, Dipl.-Biol.
Institut f?r Zoologie, Abt. 5: ?kologie
J.-J.-Becher-Weg 13
Johannes Gutenberg-Universit?t
55128 Mainz
Germany

phone: +49 6131 39-22718
fax:   +49 6131 39-23731
WWW: www.community-ecology.uni-mainz.de/126_ENG_HTML.php
_________________________________________________________ x k,

From moshersteven at gmail.com  Sun Aug 22 21:14:04 2010
From: moshersteven at gmail.com (steven mosher)
Date: Sun, 22 Aug 2010 12:14:04 -0700
Subject: [R-sig-Geo] NetCDF and raster on MAC
Message-ID: <AANLkTi=g1XG3jVvgPKv6UOmtO8hv=zRdke0rkxBvdqCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100822/5ab4ef14/attachment.pl>

From r.hijmans at gmail.com  Mon Aug 23 01:04:15 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sun, 22 Aug 2010 16:04:15 -0700
Subject: [R-sig-Geo] NetCDF and raster on MAC
In-Reply-To: <AANLkTi=g1XG3jVvgPKv6UOmtO8hv=zRdke0rkxBvdqCQ@mail.gmail.com>
References: <AANLkTi=g1XG3jVvgPKv6UOmtO8hv=zRdke0rkxBvdqCQ@mail.gmail.com>
Message-ID: <AANLkTim94O0+ZTZqj7DcWVHC+Pm8GT6s8c0Aioo_aztK@mail.gmail.com>

Steven,

The current version of raster (1.3-11 on CRAN) uses 'ncdf' rather then
'RNetCDF'.  The 'ncdf' package is available for OSX.

Then, for a single layer:

r = raster('file.nc')
r = raster('file.nc', band=10)

For all layers:

b = brick('file.nc')

You may get a warning about the variable that was selected. You can
avoid that by explicitly setting the variable you want with the
varname="  " argument, e.g.,

b = brick('file.nc', varname='temperature')

I cannot copy to r-sig-mac, as I am not subscribed to it (that's why
it is bad practice to send a single message to two mailing lists).

Hth, Robert


On Sun, Aug 22, 2010 at 12:14 PM, steven mosher <moshersteven at gmail.com> wrote:
> I'm looking for some examples of how to read a NetCDF file with raster
> directly. The manual is a bit
> terse on the matter. The dats in question is a 3D (lon,lat,time) 72*36, 161
> "bands"
>
> On the MAC I get a request to load RNetCDF, which is not available in
> Binary. I found a few mails
> on geting RNetCDF onto the MAC (and udunits as well)
>
> Failing a direct method, I suppose, I can just read the file into an array
> and the turn that into a multi band
> raster..
>
> TIA
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From moshersteven at gmail.com  Mon Aug 23 01:27:06 2010
From: moshersteven at gmail.com (steven mosher)
Date: Sun, 22 Aug 2010 16:27:06 -0700
Subject: [R-sig-Geo] NetCDF and raster on MAC
In-Reply-To: <AANLkTi=_ATkKOK0b4TnzZBqF12v8hO0fAs2M_VHpMfAV@mail.gmail.com>
References: <AANLkTi=g1XG3jVvgPKv6UOmtO8hv=zRdke0rkxBvdqCQ@mail.gmail.com>
	<AANLkTi=_ATkKOK0b4TnzZBqF12v8hO0fAs2M_VHpMfAV@mail.gmail.com>
Message-ID: <AANLkTik_zV-z0dAYrqd6Xjw38dXVmb9sYso6j14Asa4f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100822/26c6c541/attachment.pl>

From r.hijmans at gmail.com  Mon Aug 23 01:31:00 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sun, 22 Aug 2010 16:31:00 -0700
Subject: [R-sig-Geo] NetCDF and raster on MAC
In-Reply-To: <AANLkTik_zV-z0dAYrqd6Xjw38dXVmb9sYso6j14Asa4f@mail.gmail.com>
References: <AANLkTi=g1XG3jVvgPKv6UOmtO8hv=zRdke0rkxBvdqCQ@mail.gmail.com>
	<AANLkTi=_ATkKOK0b4TnzZBqF12v8hO0fAs2M_VHpMfAV@mail.gmail.com>
	<AANLkTik_zV-z0dAYrqd6Xjw38dXVmb9sYso6j14Asa4f@mail.gmail.com>
Message-ID: <AANLkTinJ14_yOKC5mMJ7OWjXzBo_AYfJaN_MvpfQgDP1@mail.gmail.com>

Dear Steven, Thank you. You are using version 1.3-4. You need 1.3-11
(form CRAN) or higher (from R-Forge). Best, Robert

On Sun, Aug 22, 2010 at 4:27 PM, steven mosher <moshersteven at gmail.com> wrote:
> Thanks Robert.
> raster has been a great tool for me and others working on the same problem.
>
> I had tried what you suggested that which lead to the error message. see
> below
> ??seafile<-"HadSST2_1850on.nc"
>
> ??nc = open.ncdf(seafile, write = FALSE)
> ??names(nc)
> ?[1] "id" ? ? ? ? ? "ndims" ? ? ? ?"natts" ? ? ? ?"unlimdimid" ? "filename"
> ? ? "varid2Rindex" "writable" ? ? "dim" ? ? ? ? ?"nvars"
> [10] "var"
> ??TIME<-get.var.ncdf(nc,'time')
> ??SST<-get.var.ncdf(nc,'sst')
> ??lon<-get.var.ncdf(nc,'lon')
> ??lat<-get.var.ncdf(nc,'lat')
> ??dim(SST)
> [1] ? 72 ? 36 1927
> ?b<-brick(seafile,varname='sst')
> Loading required package: RNetCDF
> Error in .rasterObjectFromCDF(x, type = objecttype, band = band, ...) :
> ??You need to install the RNetCDF package first
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> x86_64-apple-darwin9.8.0
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/C/C/en_US.UTF-8/en_US.UTF-8
> attached base packages:
> [1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
> other attached packages:
> [1] ncdf_1.6 ? ? ? ? ?uncompress_1.33 ? R.utils_1.4.4 ? ? R.oo_1.7.3
> ?R.methodsS3_1.2.0 zoo_1.6-3 ? ? ? ? maps_2.1-4 ? ? ? ?raster_1.3-4
> [9] sp_0.9-66
> loaded via a namespace (and not attached):
> [1] grid_2.11.1 ? ?lattice_0.18-8 tools_2.11.1
>
> On Sun, Aug 22, 2010 at 4:02 PM, Robert J. Hijmans <r.hijmans at gmail.com>
> wrote:
>>
>> Steven,
>>
>> The current version of raster (1.3-11 on CRAN) uses 'ncdf' rather then
>> 'RNetCDF'. ?The 'ncdf' package is available for OSX.
>>
>> Then, for a single layer:
>>
>> r = raster('file.nc')
>> r = raster('file.nc', band=10)
>>
>> For all layers:
>>
>> b = brick('file.nc')
>>
>> You may get a warning about the variable that was selected. You can
>> avoid that by explicitly setting the variable you want with the
>> varname=" ?" argument, e.g.,
>>
>> b = brick('file.nc', varname='temperature')
>>
>> Hth, Robert
>>
>>
>> On Sun, Aug 22, 2010 at 12:14 PM, steven mosher <moshersteven at gmail.com>
>> wrote:
>> > I'm looking for some examples of how to read a NetCDF file with raster
>> > directly. The manual is a bit
>> > terse on the matter. The dats in question is a 3D (lon,lat,time) 72*36,
>> > 161
>> > "bands"
>> >
>> > On the MAC I get a request to load RNetCDF, which is not available in
>> > Binary. I found a few mails
>> > on geting RNetCDF onto the MAC (and udunits as well)
>> >
>> > Failing a direct method, I suppose, I can just read the file into an
>> > array
>> > and the turn that into a multi band
>> > raster..
>> >
>> > TIA
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at stat.math.ethz.ch
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>
>


From kadraamrane at hotmail.fr  Mon Aug 23 07:43:46 2010
From: kadraamrane at hotmail.fr (kad)
Date: Sun, 22 Aug 2010 22:43:46 -0700 (PDT)
Subject: [R-sig-Geo] warnings
Message-ID: <1282542226167-5451499.post@n2.nabble.com>


Dear all,
I see two  warnings and I dont know what I must do.
I want to make a ordinary kriging.
I use the package automap for my report .do you help me?Thanks
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/warnings-tp5451499p5451499.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From kadraamrane at hotmail.fr  Mon Aug 23 07:49:52 2010
From: kadraamrane at hotmail.fr (kad)
Date: Sun, 22 Aug 2010 22:49:52 -0700 (PDT)
Subject: [R-sig-Geo] warnings()
Message-ID: <1282542592291-5451513.post@n2.nabble.com>


Dear all, 
I see two  warnings and I dont know what I must do. 
I want to make a ordinary kriging. 
I use the package automap for my report .do you help me?Thanks



1) In fit.variogram(object, model, fit.sills = fit.sills,  ... :
  valeur d'argument hors intervalle dans 'bessel_k'

2) In autofitVariogram(ANGAR ~ 1, r) :
  Some models where removed for being either NULL or having a negative
sill/range/nugget, 
        set verbose == TRUE for more information


-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/warnings-tp5451513p5451513.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Mon Aug 23 08:15:31 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Aug 2010 08:15:31 +0200 (CEST)
Subject: [R-sig-Geo] Choosing the right nb2listw-style
In-Reply-To: <E7F1EF063B11DA4DAD16374549B879E82AD9E3C1@e14mdb-02.zdv.Uni-Mainz.DE>
References: <E7F1EF063B11DA4DAD16374549B879E82AD9E3C1@e14mdb-02.zdv.Uni-Mainz.DE>
Message-ID: <alpine.LRH.2.00.1008230759150.23687@reclus.nhh.no>

On Sun, 22 Aug 2010, Breitbach, Nils wrote:

> Dear Community,
>
> to be able to evaluate the spatial autocorrelation within may data I am 
> forced with the question of how to correctly choose the neighbours for 
> my data. My study plots (points) are not evenly distributed over my 
> study area (approx. 30 x 30 km in size) and also the land-use type is 
> not evenly distributed over the study area and therefore I want to 
> evaluate the spatial autocorrelation for this data set. To finally 
> calculate the Moran's I or plot variograms/correlograms I now need to 
> calculate the neighbourhood relationships of my study plots. For the 
> given characteristic of my data (especially their non-even distribution) 
> I am now somewhat uncertain about the right style (W, B, C, U or S) of 
> the nb2listw() object that suits best for my kind of data.
>
> Can anyone recommend the "right" style for my kind of data?

Typically, varying sub-discipline communities have different prefered 
flavours, both of the neighbour list object, for using general weights (or 
not) - including inverse distance weighting, and for using 
row-standardisation (W), raw (binary or general - B), or standardised raw 
(C - sum to n, U - sum to 1). There isn't a tradition dor using variance 
stabilising (S) although there probably should be. It seems sensible to 
see what others in your field use, and choose among those. The same for 
schemes for finding the neighbours to start with. Using an approach which 
is unusual in your field will attract referees' attention to your choice - 
they will want to know why you are doing something different. Since you 
are in ecology, look at papers using weights there, and unless you can see 
that the modal scheme is suboptimal for you, go with the stream.

Note however that some of the graph-based neighbour schemes advanced early 
on by Sokal in ecology are little used, and probably deserve more 
exposure, especially when the distances between observations differ a lot 
- leading to observations in dense parts of the study area having many 
neighbours in schemes using a distance threshold. Try to think about the 
plausibility of the science in the implied spatial process - could 
observations realistically influence each other at that distance? It may 
not matter if the weights are only "mopping up" unwanted spatial 
autocorrelation, but if the dependencies have a substantive 
interpretation, it isn't wise to imply mutual dependence that isn't 
scientifically plausible (think of natural boundaries that organisms 
cannot "cross" as well as distances). But no, no "right" scheme as such - 
it's up to you! Pay attention to the inhomogeneity of your setting too, as 
it may induce apparent dependency if not modelled.

Hope this helps,

Roger

>
> Thanks for help!
> Regards,
>
> Nils
>
> _________________________________________________________
>
> Nils Breitbach, Dipl.-Biol.
> Institut f?r Zoologie, Abt. 5: ?kologie
> J.-J.-Becher-Weg 13
> Johannes Gutenberg-Universit?t
> 55128 Mainz
> Germany
>
> phone: +49 6131 39-22718
> fax:   +49 6131 39-23731
> WWW: www.community-ecology.uni-mainz.de/126_ENG_HTML.php
> _________________________________________________________ x k,
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From breitbach at uni-mainz.de  Mon Aug 23 14:59:56 2010
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Mon, 23 Aug 2010 12:59:56 +0000
Subject: [R-sig-Geo] Choosing the right nb2listw-style
In-Reply-To: <alpine.LRH.2.00.1008230759150.23687@reclus.nhh.no>
References: <E7F1EF063B11DA4DAD16374549B879E82AD9E3C1@e14mdb-02.zdv.Uni-Mainz.DE>,
	<alpine.LRH.2.00.1008230759150.23687@reclus.nhh.no>
Message-ID: <E7F1EF063B11DA4DAD16374549B879E82AD9E4AD@e14mdb-02.zdv.Uni-Mainz.DE>

Dear Roger, dear Community,

thanks for the detailed answer to my question(s)! It helped a lot, but on the other hand cause some more uncertainties for me.

Why do some functions for the Moran's I test require detailed knoledge of creating neighbours and weighting them like the moran.test() function while others do not like the Moran.I() function? The moran.test() function from the spdep package requires a listw object, where you have to create a weighted neighbourhood matrix with all the preliminary considerations, while the Moran.I() function sipmly works with a ad hoc created distance matrix (e.g. done with the dist() function) as it was done here: http://www.ats.ucla.edu/stat/r/faq/morans_i.htm (even though Moran.I expects "a matrix of weights" looking closer to the help files for the function). Can the distances itself be considered as weights? The method with the Moran.I() function seems much simpler and requires a lot less knoledge and preliminary considerations ...

Thanks for help in this difficult field!
Regards,

Nils


________________________________________
Von: Roger Bivand [Roger.Bivand at nhh.no]
Gesendet: Montag, 23. August 2010 08:15
Bis: Breitbach, Nils
Cc: r-sig-geo at stat.math.ethz.ch
Betreff: Re: [R-sig-Geo] Choosing the right nb2listw-style

On Sun, 22 Aug 2010, Breitbach, Nils wrote:

> Dear Community,
>
> to be able to evaluate the spatial autocorrelation within may data I am
> forced with the question of how to correctly choose the neighbours for
> my data. My study plots (points) are not evenly distributed over my
> study area (approx. 30 x 30 km in size) and also the land-use type is
> not evenly distributed over the study area and therefore I want to
> evaluate the spatial autocorrelation for this data set. To finally
> calculate the Moran's I or plot variograms/correlograms I now need to
> calculate the neighbourhood relationships of my study plots. For the
> given characteristic of my data (especially their non-even distribution)
> I am now somewhat uncertain about the right style (W, B, C, U or S) of
> the nb2listw() object that suits best for my kind of data.
>
> Can anyone recommend the "right" style for my kind of data?

Typically, varying sub-discipline communities have different prefered
flavours, both of the neighbour list object, for using general weights (or
not) - including inverse distance weighting, and for using
row-standardisation (W), raw (binary or general - B), or standardised raw
(C - sum to n, U - sum to 1). There isn't a tradition dor using variance
stabilising (S) although there probably should be. It seems sensible to
see what others in your field use, and choose among those. The same for
schemes for finding the neighbours to start with. Using an approach which
is unusual in your field will attract referees' attention to your choice -
they will want to know why you are doing something different. Since you
are in ecology, look at papers using weights there, and unless you can see
that the modal scheme is suboptimal for you, go with the stream.

Note however that some of the graph-based neighbour schemes advanced early
on by Sokal in ecology are little used, and probably deserve more
exposure, especially when the distances between observations differ a lot
- leading to observations in dense parts of the study area having many
neighbours in schemes using a distance threshold. Try to think about the
plausibility of the science in the implied spatial process - could
observations realistically influence each other at that distance? It may
not matter if the weights are only "mopping up" unwanted spatial
autocorrelation, but if the dependencies have a substantive
interpretation, it isn't wise to imply mutual dependence that isn't
scientifically plausible (think of natural boundaries that organisms
cannot "cross" as well as distances). But no, no "right" scheme as such -
it's up to you! Pay attention to the inhomogeneity of your setting too, as
it may induce apparent dependency if not modelled.

Hope this helps,

Roger

>
> Thanks for help!
> Regards,
>
> Nils
>
> _________________________________________________________
>
> Nils Breitbach, Dipl.-Biol.
> Institut f?r Zoologie, Abt. 5: ?kologie
> J.-J.-Becher-Weg 13
> Johannes Gutenberg-Universit?t
> 55128 Mainz
> Germany
>
> phone: +49 6131 39-22718
> fax:   +49 6131 39-23731
> WWW: www.community-ecology.uni-mainz.de/126_ENG_HTML.php
> _________________________________________________________ x k,
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From nikhil.list at gmail.com  Mon Aug 23 15:23:10 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Mon, 23 Aug 2010 09:23:10 -0400
Subject: [R-sig-Geo] Choosing the right nb2listw-style
In-Reply-To: <E7F1EF063B11DA4DAD16374549B879E82AD9E4AD@e14mdb-02.zdv.Uni-Mainz.DE>
References: <E7F1EF063B11DA4DAD16374549B879E82AD9E3C1@e14mdb-02.zdv.Uni-Mainz.DE>,
	<alpine.LRH.2.00.1008230759150.23687@reclus.nhh.no>
	<E7F1EF063B11DA4DAD16374549B879E82AD9E4AD@e14mdb-02.zdv.Uni-Mainz.DE>
Message-ID: <7811DA1A-B217-44D2-B807-33B71967660E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100823/39c72247/attachment.pl>

From Roger.Bivand at nhh.no  Mon Aug 23 15:51:03 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Aug 2010 15:51:03 +0200 (CEST)
Subject: [R-sig-Geo] Choosing the right nb2listw-style
In-Reply-To: <E7F1EF063B11DA4DAD16374549B879E82AD9E4AD@e14mdb-02.zdv.Uni-Mainz.DE>
References: <E7F1EF063B11DA4DAD16374549B879E82AD9E3C1@e14mdb-02.zdv.Uni-Mainz.DE>,
	<alpine.LRH.2.00.1008230759150.23687@reclus.nhh.no>
	<E7F1EF063B11DA4DAD16374549B879E82AD9E4AD@e14mdb-02.zdv.Uni-Mainz.DE>
Message-ID: <alpine.LRH.2.00.1008231547330.24570@reclus.nhh.no>

On Mon, 23 Aug 2010, Breitbach, Nils wrote:

> Dear Roger, dear Community,
>
> thanks for the detailed answer to my question(s)! It helped a lot, but 
> on the other hand cause some more uncertainties for me.
>
> Why do some functions for the Moran's I test require detailed knoledge 
> of creating neighbours and weighting them like the moran.test() function 
> while others do not like the Moran.I() function? The moran.test() 
> function from the spdep package requires a listw object, where you have 
> to create a weighted neighbourhood matrix with all the preliminary 
> considerations, while the Moran.I() function sipmly works with a ad hoc 
> created distance matrix (e.g. done with the dist() function) as it was 
> done here: http://www.ats.ucla.edu/stat/r/faq/morans_i.htm (even though 
> Moran.I expects "a matrix of weights" looking closer to the help files 
> for the function). Can the distances itself be considered as weights? 
> The method with the Moran.I() function seems much simpler and requires a 
> lot less knoledge and preliminary considerations ...

The functions in spdep are for spatial data, those in ape (please give 
package names) are mainly for phylogenetics and evolution. In using 
matrices rather than lists, the ape function creates difficulties with 
large data sets. Horses for courses, really.

Roger

>
> Thanks for help in this difficult field!
> Regards,
>
> Nils
>
>
> ________________________________________
> Von: Roger Bivand [Roger.Bivand at nhh.no]
> Gesendet: Montag, 23. August 2010 08:15
> Bis: Breitbach, Nils
> Cc: r-sig-geo at stat.math.ethz.ch
> Betreff: Re: [R-sig-Geo] Choosing the right nb2listw-style
>
> On Sun, 22 Aug 2010, Breitbach, Nils wrote:
>
>> Dear Community,
>>
>> to be able to evaluate the spatial autocorrelation within may data I am
>> forced with the question of how to correctly choose the neighbours for
>> my data. My study plots (points) are not evenly distributed over my
>> study area (approx. 30 x 30 km in size) and also the land-use type is
>> not evenly distributed over the study area and therefore I want to
>> evaluate the spatial autocorrelation for this data set. To finally
>> calculate the Moran's I or plot variograms/correlograms I now need to
>> calculate the neighbourhood relationships of my study plots. For the
>> given characteristic of my data (especially their non-even distribution)
>> I am now somewhat uncertain about the right style (W, B, C, U or S) of
>> the nb2listw() object that suits best for my kind of data.
>>
>> Can anyone recommend the "right" style for my kind of data?
>
> Typically, varying sub-discipline communities have different prefered
> flavours, both of the neighbour list object, for using general weights (or
> not) - including inverse distance weighting, and for using
> row-standardisation (W), raw (binary or general - B), or standardised raw
> (C - sum to n, U - sum to 1). There isn't a tradition dor using variance
> stabilising (S) although there probably should be. It seems sensible to
> see what others in your field use, and choose among those. The same for
> schemes for finding the neighbours to start with. Using an approach which
> is unusual in your field will attract referees' attention to your choice -
> they will want to know why you are doing something different. Since you
> are in ecology, look at papers using weights there, and unless you can see
> that the modal scheme is suboptimal for you, go with the stream.
>
> Note however that some of the graph-based neighbour schemes advanced early
> on by Sokal in ecology are little used, and probably deserve more
> exposure, especially when the distances between observations differ a lot
> - leading to observations in dense parts of the study area having many
> neighbours in schemes using a distance threshold. Try to think about the
> plausibility of the science in the implied spatial process - could
> observations realistically influence each other at that distance? It may
> not matter if the weights are only "mopping up" unwanted spatial
> autocorrelation, but if the dependencies have a substantive
> interpretation, it isn't wise to imply mutual dependence that isn't
> scientifically plausible (think of natural boundaries that organisms
> cannot "cross" as well as distances). But no, no "right" scheme as such -
> it's up to you! Pay attention to the inhomogeneity of your setting too, as
> it may induce apparent dependency if not modelled.
>
> Hope this helps,
>
> Roger
>
>>
>> Thanks for help!
>> Regards,
>>
>> Nils
>>
>> _________________________________________________________
>>
>> Nils Breitbach, Dipl.-Biol.
>> Institut f?r Zoologie, Abt. 5: ?kologie
>> J.-J.-Becher-Weg 13
>> Johannes Gutenberg-Universit?t
>> 55128 Mainz
>> Germany
>>
>> phone: +49 6131 39-22718
>> fax:   +49 6131 39-23731
>> WWW: www.community-ecology.uni-mainz.de/126_ENG_HTML.php
>> _________________________________________________________ x k,
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From thi_veloso at yahoo.com.br  Mon Aug 23 16:26:23 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Mon, 23 Aug 2010 07:26:23 -0700 (PDT)
Subject: [R-sig-Geo] Mapping multiple attributes at once
Message-ID: <359802.90139.qm@web54302.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100823/8170e021/attachment.pl>

From gildemir at gmail.com  Mon Aug 23 17:11:28 2010
From: gildemir at gmail.com (Francisco Silva)
Date: Mon, 23 Aug 2010 12:11:28 -0300
Subject: [R-sig-Geo] help to use GMerrorsar () spdep
Message-ID: <AANLkTiky35OZbo5LoGy9Q9q1Q+=RgohCXsiaXBT+jdef@mail.gmail.com>

Hi Folks,

I am trying to work with spatial logit model and I stopped my research
in a Paper of Pinkse that make estimation of spatial models by GMM.
I search in R communite and I find that GMerrorsar function in spdep
package is used to it,  but I have tryied so many times to make my
model by this function and i did not figure it out.
Some body knows how to work with this function?
If so, can send me an example?

I will be very glad for help.
Thanks in advance,
Francisco Gildemir Ferreira da Silva


From kerryr at sccwrp.org  Mon Aug 23 17:33:01 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Mon, 23 Aug 2010 08:33:01 -0700
Subject: [R-sig-Geo] anisotropic models vs. detrending
In-Reply-To: <201008201910.11982.ashton@msu.edu>
References: <4C6F0575.7090805@sccwrp.org> <201008201910.11982.ashton@msu.edu>
Message-ID: <4C7294AD.7020107@sccwrp.org>

Thank you for your perspective. I should state that I intend to use the 
variogram model, not for prediction, but for understanding the spatial 
variability.  My end goal is to create the best sample spacing for a new 
design based on the variogram.  In the anisotropic case I would create a 
rectangular grid with stations in one direction closer than in the 
other.  In the other "trend" case I would create a square grid.  This is 
the question I am trying to answer.  Do you have any advice in this context?
Thanks,
Kerry

Ashton Shortridge wrote:
> On 2010-08-20, Kerry Ritter, wrote:
>   
>> Hi. I was wondering which model you would tend to choose given similar
>> cross validation results.
>> 1. An isotropic model with linear trend
>> 2. An anisotropic model
>> Assume linear trend is ~x + y + I(x*y), where x,y are spatial coordinates.
>>
>> I have read papers that argue that unless you know how to interpret the
>> linear trend (from a phyiscal/geographical/biological point of view) it
>> is better NOT to detrend the data prior to fitting a variogram.  On the
>> other hand, one must ultimately assume stationarity. So I am not sure
>> which way to go.  How do you decide?
>>
>> Thanks,
>> Kerry
>>     
>
> Hi Kerry,
>
> If your goal with this model is to develop predictions within the extents of 
> your existing data (that is, not extrapolating), then either approach probably 
> produces about the same result. These alternatives do employ very different 
> conceptual models of the process you are trying to capture, so from that 
> perspective it might be best to go with the model that best fits your 
> understanding, but from a utilitarian perspective, either will work.
>
> I find it is often difficult in practice to fit an anisotropic model well - the 
> lack of sufficient data in different directions can make the variograms noisy. 
> Low-order trends like yours are simple to fit. Using OLS to fit a trend surface 
> to spatially autocorrelated observations can be problematic, but universal 
> kriging is a more robust alternative (though this frequently seems to make 
> little difference in practice).
>
> Of course, you can use both to develop predictions, or prediction surfaces, 
> and take the difference of the two to see how much your choice matters. In the 
> end, perhaps employ the method that you find simplest to explain!
>
> Yours,
>
> Ashton
>
> -----
> Ashton Shortridge
> Associate Professor			ashton at msu.edu
> Dept of Geography			http://www.msu.edu/~ashton
> 235 Geography Building		ph (517) 432-3561
> Michigan State University		fx (517) 432-1671
>
>   


-- 
**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From kerryr at sccwrp.org  Mon Aug 23 17:45:17 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Mon, 23 Aug 2010 08:45:17 -0700
Subject: [R-sig-Geo] gstat fit.variogram, attr(fit.1,"SSErr")
Message-ID: <4C72978D.5000300@sccwrp.org>

Hi. I am using library "gstat" in R.  My question is why do I get 
different SSErr's when I fit the variogram model using fit.variogram 
than when I fix the parameters in fit.variogram using the exact same 
parameters obtained from the first fit.  My expectation is that these 
would be the same.  What is SSErr actually calculating?
Thanks,
Kerry

-- 
**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From r.hijmans at gmail.com  Mon Aug 23 18:25:21 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 23 Aug 2010 09:25:21 -0700
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <359802.90139.qm@web54302.mail.re2.yahoo.com>
References: <359802.90139.qm@web54302.mail.re2.yahoo.com>
Message-ID: <AANLkTi=d5gq3n7ygS0pMaEbXgyD5x58N+pLW9Pc95mCY@mail.gmail.com>

Dear Thiago,

If you are using (basic) 'plot' you can pass a vector with the
required sizes, i.e. your variable, perhaps after a transformation, as
cex argument. Same approach works for col.

plot(1:10, cex=c(1:5,1:5), col=rep(c('red', 'blue'), each=5), pch=20)

Robert

On Mon, Aug 23, 2010 at 7:26 AM, Thiago Veloso <thi_veloso at yahoo.com.br> wrote:
> ??Dear SIG colleagues,
> ??In my present study I need to plot a map containing two different attributes of some localities.????I?figured out that a convenient and didactic way would be via something like bubble plots. For example,?the size of the circle would be proportional to a certain range of values (4 categories) and its inner colors (also 4 categories) would be proportional?to the p-values of a statistical test.
> ??Is it possible to implement that idea using SIG tools in R? Any suggestions on how to do it??
> ??Thanks in advance and best wishes,
> ??Thiago.
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From kerryr at sccwrp.org  Mon Aug 23 20:04:08 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Mon, 23 Aug 2010 11:04:08 -0700
Subject: [R-sig-Geo] geoR- "likfit" not estimating range parameters
Message-ID: <4C72B818.3060103@sccwrp.org>

Hi. I am using the library "geoR" and am having trouble getting REML 
estimates for the range and  different from those specified in the 
intial values.

My statement is....

reml.fit=likfit(SDmatchC.geo, ini=c(100,2020), fix.nugget = FALSE, 
nugget = 5,  fix.psiA = FALSE, psiA = 90, fix.psiR = FALSE, psiR = 1.4,
       cov.model = "gaussian", lik.method = "REML")

The results is
 > reml.fit
likfit: estimated model parameters:
      beta      tausq    sigmasq        phi       psiA       psiR
"  41.513" "  12.083" " 267.910" "2019.996" "   5.806" "   5.998"
Practical Range with cor=0.05 for asymptotic range: 3496.247

Note that if I replace 2020 with 3020, I get "3019.99" for phi.  So it 
is not really estimating the
range parameters.

What am I missing?

Thanks,
Kerry


-- 


**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From scionforbai at gmail.com  Mon Aug 23 20:34:34 2010
From: scionforbai at gmail.com (Scionforbai)
Date: Mon, 23 Aug 2010 20:34:34 +0200
Subject: [R-sig-Geo] anisotropic models vs. detrending
In-Reply-To: <4C7294AD.7020107@sccwrp.org>
References: <4C6F0575.7090805@sccwrp.org> <201008201910.11982.ashton@msu.edu>
	<4C7294AD.7020107@sccwrp.org>
Message-ID: <AANLkTi=mKZ642sHPUKfgPWMQHx0UfwMRiRtOqJNZ=pqd@mail.gmail.com>

> My end goal is to create the best sample spacing for a new
> design based on the variogram. ?In the anisotropic case I would create a
> rectangular grid with stations in one direction closer than in the other.
> ?In the other "trend" case I would create a square grid. ?This is the
> question I am trying to answer.

Are there phenomenological reasons/analoga to assume an external
drift, a trend or variogram anisotropy? In case of anisotropy, do you
already know the principal axes? Otherwise you cannot design a
sampling oriented in the right way, and this discussion would be
rather pointless.
Furthermore, a kriging of the residuals doesn't imply that those are
isotropic in geostatistical meaning, in my humble opinion. So, just
find the model which best fits your problem.

After all, estimation variance (which you want to minimize for the
sampling design) depends on data locations and spatial model, so noone
can easily say what is better between kriging with external drift or
for example with zonal anisotropy with linear model. This is actually
a typical exercise for undergrads.

Scion
Thr


From Roger.Bivand at nhh.no  Mon Aug 23 21:28:30 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Aug 2010 21:28:30 +0200 (CEST)
Subject: [R-sig-Geo] help to use GMerrorsar () spdep
In-Reply-To: <AANLkTiky35OZbo5LoGy9Q9q1Q+=RgohCXsiaXBT+jdef@mail.gmail.com>
References: <AANLkTiky35OZbo5LoGy9Q9q1Q+=RgohCXsiaXBT+jdef@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008232124350.25364@reclus.nhh.no>

On Mon, 23 Aug 2010, Francisco Silva wrote:

> Hi Folks,
>
> I am trying to work with spatial logit model and I stopped my research
> in a Paper of Pinkse that make estimation of spatial models by GMM.
> I search in R communite and I find that GMerrorsar function in spdep
> package is used to it,  but I have tryied so many times to make my
> model by this function and i did not figure it out.
> Some body knows how to work with this function?
> If so, can send me an example?

example(GMerrorsar)
?GMerrorsar # examples at end

but note that this function is *not* for fitting spatial logit models, for 
which no functions are available in R. It is for fitting spatial error 
models with a continuous dependent variable, and may be used as an 
alternative to maximum likelihood.

Had you shown the code you were using for this function, it would have 
been easier to see what you are doing wrong.

Hope this helps,

Roger

>
> I will be very glad for help.
> Thanks in advance,
> Francisco Gildemir Ferreira da Silva
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From kadraamrane at hotmail.fr  Tue Aug 24 01:46:54 2010
From: kadraamrane at hotmail.fr (kad)
Date: Mon, 23 Aug 2010 16:46:54 -0700 (PDT)
Subject: [R-sig-Geo] warnings in fit.variogram and autofitVariogram
Message-ID: <1282607214057-5454757.post@n2.nabble.com>


Dear all,
yesterday I posted two messages by mistake,excuse me everybody.
I see two warnings and I dont know what I must do.
 I want to make a ordinary kriging.
 I use the package automap for my report .do you help me?Thanks

1) In fit.variogram(object, model, fit.sills = fit.sills, ... :
 valeur d'argument hors intervalle dans 'bessel_k'

2) In autofitVariogram(ANGAR ~ 1, r) :> Some models where removed for being
either NULL or having a negative> sill/range/nugget,> set verbose == TRUE
for more information
My code is: http://r-sig-geo.2731867.n2.nabble.com/file/n5454757/mycodeR
mycodeR  

when I do verbose=TRUE I see this:
http://r-sig-geo.2731867.n2.nabble.com/file/n5454757/error error 
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/warnings-in-fit-variogram-and-autofitVariogram-tp5454757p5454757.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From pierre.roudier at gmail.com  Tue Aug 24 09:07:24 2010
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Tue, 24 Aug 2010 19:07:24 +1200
Subject: [R-sig-Geo] warnings in fit.variogram and autofitVariogram
In-Reply-To: <1282607214057-5454757.post@n2.nabble.com>
References: <1282607214057-5454757.post@n2.nabble.com>
Message-ID: <AANLkTi=DtSmVP7BxrvswsshA+ArD3DyMz2unybccc0-6@mail.gmail.com>

Hello Kad,

The best thing to do is probably to actually *read* those warnings.

It is not that clear what models you tried to fit, but basically I
guess you tested the full range of models available through gstat (see
vgm()). One of them (the bessel model) does not fit using the tested
parameters. It has been excluded.

The second warning is related to that : some models have been excluded
because they had a negative sill and/or range and/or nugget value
fitted.

Now I suggest you to try to dig a bit more the doc and understand what
the autoKrige function is actually doing (i.e. computing an
experimental semi-variogram, then fitting a model, then use it in a
kriging routine).

Pierre

2010/8/24 kad <kadraamrane at hotmail.fr>:
>
> Dear all,
> yesterday I posted two messages by mistake,excuse me everybody.
> I see two warnings and I dont know what I must do.
> ?I want to make a ordinary kriging.
> ?I use the package automap for my report .do you help me?Thanks
>
> 1) In fit.variogram(object, model, fit.sills = fit.sills, ... :
> ?valeur d'argument hors intervalle dans 'bessel_k'
>
> 2) In autofitVariogram(ANGAR ~ 1, r) :> Some models where removed for being
> either NULL or having a negative> sill/range/nugget,> set verbose == TRUE
> for more information
> My code is: http://r-sig-geo.2731867.n2.nabble.com/file/n5454757/mycodeR
> mycodeR
>
> when I do verbose=TRUE I see this:
> http://r-sig-geo.2731867.n2.nabble.com/file/n5454757/error error
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/warnings-in-fit-variogram-and-autofitVariogram-tp5454757p5454757.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From mayeul.kauffmann at jrc.ec.europa.eu  Tue Aug 24 09:59:18 2010
From: mayeul.kauffmann at jrc.ec.europa.eu (Mayeul KAUFFMANN)
Date: Tue, 24 Aug 2010 09:59:18 +0200
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <AANLkTi=d5gq3n7ygS0pMaEbXgyD5x58N+pLW9Pc95mCY@mail.gmail.com>
References: <359802.90139.qm@web54302.mail.re2.yahoo.com>
	<AANLkTi=d5gq3n7ygS0pMaEbXgyD5x58N+pLW9Pc95mCY@mail.gmail.com>
Message-ID: <000301cb4362$41014790$c303d6b0$@kauffmann@jrc.ec.europa.eu>

I you want a more advanced example, you may want to have a look at this US
election map:
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=113
(source code here: http://www.ai.rug.nl/~hedderik/R/US2004/ )
Mayeul

_____________________________________________________
Dr. Mayeul KAUFFMANN, Conflict Specialist
European Commission, Joint Research Centre (JRC)
Institute for the Protection and Security of the Citizen (IPSC)
Global Security and Crisis Management - ISFEREA
Via E. Fermi 2749 - I-21027 Ispra (VA), ITALY
Phone: (+39) 033278 5071
http://isferea.jrc.ec.europa.eu/Staff/Pages/Kauffmann-Mayeul.aspx

(Office: building 48c, 1st floor, room 123. TP: 483)

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Robert J. Hijmans
Sent: Monday, August 23, 2010 6:25 PM
To: Thiago Veloso
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Mapping multiple attributes at once

Dear Thiago,

If you are using (basic) 'plot' you can pass a vector with the
required sizes, i.e. your variable, perhaps after a transformation, as
cex argument. Same approach works for col.

plot(1:10, cex=c(1:5,1:5), col=rep(c('red', 'blue'), each=5), pch=20)

Robert

On Mon, Aug 23, 2010 at 7:26 AM, Thiago Veloso <thi_veloso at yahoo.com.br> wrote:
> ??Dear SIG colleagues,
> ??In my present study I need to plot a map containing two different attributes
of some localities.????I?figured out that a convenient and didactic way would be
via something like bubble plots. For example,?the size of the circle would be
proportional to a certain range of values (4 categories) and its inner colors
(also 4 categories) would be proportional?to the p-values of a statistical test.
> ??Is it possible to implement that idea using SIG tools in R? Any suggestions
on how to do it??
> ??Thanks in advance and best wishes,
> ??Thiago.
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From pierre.roudier at gmail.com  Tue Aug 24 11:52:06 2010
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Tue, 24 Aug 2010 21:52:06 +1200
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <359802.90139.qm@web54302.mail.re2.yahoo.com>
References: <359802.90139.qm@web54302.mail.re2.yahoo.com>
Message-ID: <AANLkTi=g3fC2yN3pbOX34Gn8pSOPMqVbPgt5kF5zspKE@mail.gmail.com>

Hi Thiago,

My weapon of choice for that would be to use the ggplot2 library.

Here is a quick example. I *hope* it is reproducible (I on't have R
installed on the machine I am posting from):

# here is a sample data frame with locations, a categorical variable
and a continuous variable
dat <- data.frame(x=runif(5), y=runif(5), category=letters(5),
continuous=runif(5))

# You may want to do some spatial analysis on that data.frame
library(sp)
coordinates(dat) <- ~x+y

# Some spatial analysis here

# Now you want to plot it
library(ggplot2)
df <- as.data.frame(dat) # backtransforms dat into a data.frame object
my.plot <- ggplot(data=df, aes(x=x, y=y)) +
geom_point(aes(size=category, fill=continuous))
print(my.plot)

For more info on theggplot2 options see http://had.co.nz/ggplot2/

HTH,

Pierre

2010/8/24 Thiago Veloso <thi_veloso at yahoo.com.br>:
> ??Dear SIG colleagues,
> ??In my present study I need to plot a map containing two different attributes of some localities.????I?figured out that a convenient and didactic way would be via something like bubble plots. For example,?the size of the circle would be proportional to a certain range of values (4 categories) and its inner colors (also 4 categories) would be proportional?to the p-values of a statistical test.
> ??Is it possible to implement that idea using SIG tools in R? Any suggestions on how to do it??
> ??Thanks in advance and best wishes,
> ??Thiago.
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From a.songhurst08 at imperial.ac.uk  Tue Aug 24 15:00:39 2010
From: a.songhurst08 at imperial.ac.uk (Songhurst, Anna)
Date: Tue, 24 Aug 2010 14:00:39 +0100
Subject: [R-sig-Geo] Function for subsampling spatial data
Message-ID: <F16A2812496279439E9C2D528CD1F712367CC53E1F@ICEXM4.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/418a47fb/attachment.pl>

From p.hiemstra at geo.uu.nl  Tue Aug 24 15:13:37 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 24 Aug 2010 15:13:37 +0200
Subject: [R-sig-Geo] Function for subsampling spatial data
In-Reply-To: <F16A2812496279439E9C2D528CD1F712367CC53E1F@ICEXM4.ic.ac.uk>
References: <F16A2812496279439E9C2D528CD1F712367CC53E1F@ICEXM4.ic.ac.uk>
Message-ID: <4C73C581.8030509@geo.uu.nl>

Hi Anna,

Take a look at spDists from the sp-package. After that you probably need 
to classify the resulting distances into a few classes, comparable to 
the bins for a sample variogram.

cheers,
Paul

On 08/24/2010 03:00 PM, Songhurst, Anna wrote:
> Hi,
>
>
>
> I am looking for a function that subsamples spatial data such that points are beyond a specific distance apart (i.e. all points 1km away from each other; all points 3km away from each other etc.). Does anybody know if such a function already exists and if so where I might find it?
>
> Thank you!
>
> Anna Songhurst
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From p.hiemstra at geo.uu.nl  Tue Aug 24 15:21:34 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 24 Aug 2010 15:21:34 +0200
Subject: [R-sig-Geo] gstat fit.variogram, attr(fit.1,"SSErr")
In-Reply-To: <4C72978D.5000300@sccwrp.org>
References: <4C72978D.5000300@sccwrp.org>
Message-ID: <4C73C75E.4080608@geo.uu.nl>

On 08/23/2010 05:45 PM, Kerry Ritter wrote:
> Hi. I am using library "gstat" in R.  My question is why do I get 
> different SSErr's when I fit the variogram model using fit.variogram 
> than when I fix the parameters in fit.variogram using the exact same 
> parameters obtained from the first fit.  My expectation is that these 
> would be the same.  What is SSErr actually calculating?
> Thanks,
> Kerry
>

Hi Kerry,

The following example illustrates that fit.variogram is sensitive to the 
start parameters you use for Gauss-Newton fitting:

data(meuse)
vgm1 <- variogram(log(zinc)~1, ~x+y, meuse)
v1 = fit.variogram(vgm1, vgm(1,"Sph",300,1))

# Use fit above as initial guess
v2 = fit.variogram(vgm1, v1)

v1
#  model     psill    range
#1   Nug 0.0506555   0.0000
#2   Sph 0.5906009 896.9702

v2
#   model      psill   range
# 1   Nug 0.05066039   0.000
# 2   Sph 0.59060578 897.006

So the difference in SSerr is caused by a different fit by 
fit.variogram, which in turn is caused by a different initial variogram 
model guess.

regards,
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From thi_veloso at yahoo.com.br  Tue Aug 24 15:58:11 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Tue, 24 Aug 2010 06:58:11 -0700 (PDT)
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <AANLkTi=d5gq3n7ygS0pMaEbXgyD5x58N+pLW9Pc95mCY@mail.gmail.com>
Message-ID: <749938.98527.qm@web54302.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/6eabf50c/attachment.pl>

From thi_veloso at yahoo.com.br  Tue Aug 24 16:24:21 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Tue, 24 Aug 2010 07:24:21 -0700 (PDT)
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <000301cb4362$41014790$c303d6b0$@kauffmann@jrc.ec.europa.eu>
Message-ID: <173779.68741.qm@web54305.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/3608cf4e/attachment.pl>

From p.hiemstra at geo.uu.nl  Tue Aug 24 16:25:26 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 24 Aug 2010 16:25:26 +0200
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <749938.98527.qm@web54302.mail.re2.yahoo.com>
References: <749938.98527.qm@web54302.mail.re2.yahoo.com>
Message-ID: <4C73D656.3000201@geo.uu.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/6afd2a52/attachment.pl>

From S.elMesslaki at student.TUDelft.NL  Tue Aug 24 16:38:27 2010
From: S.elMesslaki at student.TUDelft.NL (Sabira el Messlaki)
Date: Tue, 24 Aug 2010 16:38:27 +0200
Subject: [R-sig-Geo] knn2nb
Message-ID: <3154E0B9605B3140AFAD0A3A97DA29CF832420@SRV603.tudelft.net>

Dear list members,

I want to plot a neighbours list of class nb. I thought that the plot would show 8 neighbour lines. But this is not the case for my plot. Did I do something wrong?

col.knn2nb<-knn2nb(knearneigh(coords, k=8, longlat=F))

plot(coords, border="grey")
plot(col.knn2nb, coords, xlim=NULL, ylim=NULL, add=TRUE)

Thanks in advance

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/d6e3902c/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: knn.jpeg
Type: image/jpeg
Size: 28959 bytes
Desc: knn.jpeg
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/d6e3902c/attachment.jpeg>

From landis at isciences.com  Tue Aug 24 16:47:34 2010
From: landis at isciences.com (Matthew Landis)
Date: Tue, 24 Aug 2010 10:47:34 -0400
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <4C73D656.3000201@geo.uu.nl>
References: <749938.98527.qm@web54302.mail.re2.yahoo.com>
	<4C73D656.3000201@geo.uu.nl>
Message-ID: <4C73DB86.7090708@isciences.com>

  I've been following this topic with some interest, since this is 
something I might like to do fairly often.  I'm not that familiar with 
ggplot2, but it looks really useful.  Is there a way to overplot (or 
underplot) a shapefile (e.g. of coastlines) with the approach suggested 
by Paul?

Matt

On 8/24/2010 10:25 AM, Paul Hiemstra wrote:
> In addition to the reply by Pierre Roudier, take a look at the ggplot2
> pacakge. An example:
>


-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~
Matthew Landis, Ph.D.
Research Scientist
ISciences, LLC
61 Main St. Suite 200
Burlington VT 05401
802.864.2999
~~~~~~~~~~~~~~~~~~~~~~~~~~


From jonathan.bearak at nyu.edu  Tue Aug 24 16:51:57 2010
From: jonathan.bearak at nyu.edu (Jonathan Marc Bearak)
Date: Tue, 24 Aug 2010 10:51:57 -0400
Subject: [R-sig-Geo] Converting State Plane Coordinates
Message-ID: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>

Hi,

I'm new to GIS and have been trying to convert latitude and longitude to/from state plane coordinates.

I've tried using the project() program from the proj4 library to convert lat/lng to FIPS 3104 (New York State Long Island).

No matter how I go about this, however, the coordinates come out wrong.  E.g., 
		  	"+proj=lcc +lat_1=40.66666666666666 +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000 +y_0=0 +units=ft +no_defs +datum=NAD83",
		  	"+proj=lcc +a=6378137 +es=.0066943800229 +lon_0=-74 +lat_1=41d2 +lat_2=40d40 +lat_0=40d10 +x_0=300000 +y_0=0 +units=ft +no_defs +datum=NAD83", 

E.g., if I try the inverse, to convert 1062791, 209606.6 to lat/lng, project() prints:  43.04762 -76.89626.  The correct coordinates, however, are: 40.7416495 -073.7165681.

I've been reading the mailing lists and searching Google and R project PDFs and manual pages without any luck for an embarrassingly long number of hours without any luck.

Thanks for any help.

Best,
Jonathan

From villers.alexandre at gmail.com  Tue Aug 24 17:06:27 2010
From: villers.alexandre at gmail.com (Alexandre Villers)
Date: Tue, 24 Aug 2010 17:06:27 +0200
Subject: [R-sig-Geo] Converting State Plane Coordinates
In-Reply-To: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>
References: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>
Message-ID: <4C73DFF3.60807@gmail.com>

Hello,

Have a look at spTransform (in rgdal package) and the EPSG code of the 
desired projection (this is to me the easiest way not to mess with 
digits and various copy errors that can be made while writing the 
projection properties) at www.spatialreference.org

then, you just have to do something like this

library(rgdal)

data<-read.table ("mydata.txt", h=T, sep=",") #your original dataset
coordinates(data)<-~ X + Y # where X and Y stand for the name of your 
lat/lon columns
proj4string(data)<-CRS("+init=epsg:4326")  #if your coordinates are in WGS84
data.proj<-spTransfrom(data, 
CRS("+init=epsg:the.correct.epsg.number.of.your.projection")

HTH

Alex


Le 24/08/2010 16:51, Jonathan Marc Bearak a ?crit :
> Hi,
>
> I'm new to GIS and have been trying to convert latitude and longitude to/from state plane coordinates.
>
> I've tried using the project() program from the proj4 library to convert lat/lng to FIPS 3104 (New York State Long Island).
>
> No matter how I go about this, however, the coordinates come out wrong.  E.g.,
> 		  	"+proj=lcc +lat_1=40.66666666666666 +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000 +y_0=0 +units=ft +no_defs +datum=NAD83",
> 		  	"+proj=lcc +a=6378137 +es=.0066943800229 +lon_0=-74 +lat_1=41d2 +lat_2=40d40 +lat_0=40d10 +x_0=300000 +y_0=0 +units=ft +no_defs +datum=NAD83",
>
> E.g., if I try the inverse, to convert 1062791, 209606.6 to lat/lng, project() prints:  43.04762 -76.89626.  The correct coordinates, however, are: 40.7416495 -073.7165681.
>
> I've been reading the mailing lists and searching Google and R project PDFs and manual pages without any luck for an embarrassingly long number of hours without any luck.
>
> Thanks for any help.
>
> Best,
> Jonathan
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From thi_veloso at yahoo.com.br  Tue Aug 24 17:22:05 2010
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Tue, 24 Aug 2010 08:22:05 -0700 (PDT)
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <4C73DB86.7090708@isciences.com>
Message-ID: <466503.59281.qm@web54307.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/a2f70526/attachment.pl>

From Roger.Bivand at nhh.no  Tue Aug 24 17:52:42 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Aug 2010 17:52:42 +0200 (CEST)
Subject: [R-sig-Geo] knn2nb
In-Reply-To: <3154E0B9605B3140AFAD0A3A97DA29CF832420@SRV603.tudelft.net>
References: <3154E0B9605B3140AFAD0A3A97DA29CF832420@SRV603.tudelft.net>
Message-ID: <alpine.LRH.2.00.1008241748280.31561@reclus.nhh.no>

On Tue, 24 Aug 2010, Sabira el Messlaki wrote:

> Dear list members,
>
> I want to plot a neighbours list of class nb. I thought that the plot 
> would show 8 neighbour lines. But this is not the case for my plot. Did 
> I do something wrong?
>
> col.knn2nb<-knn2nb(knearneigh(coords, k=8, longlat=F))
>
> plot(coords, border="grey")
> plot(col.knn2nb, coords, xlim=NULL, ylim=NULL, add=TRUE)

But:

table(card(col.knn2nb))
table(sapply(col.knn2nb, anyDuplicated))
table(sapply(1:length(col.knn2nb), function(i) i %in% col.knn2nb[i]))

show that each has eight unique neighbours, and that there are no 
self-neighbours. So perhaps neighbours in the same direction have lines 
that superimpose?

Roger

>
> Thanks in advance
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue Aug 24 17:58:48 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Aug 2010 17:58:48 +0200 (CEST)
Subject: [R-sig-Geo] Converting State Plane Coordinates
In-Reply-To: <4C73DFF3.60807@gmail.com>
References: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>
	<4C73DFF3.60807@gmail.com>
Message-ID: <alpine.LRH.2.00.1008241757080.31561@reclus.nhh.no>

On Tue, 24 Aug 2010, Alexandre Villers wrote:

> Hello,
>
> Have a look at spTransform (in rgdal package) and the EPSG code of the 
> desired projection (this is to me the easiest way not to mess with digits and 
> various copy errors that can be made while writing the projection properties) 
> at www.spatialreference.org
>
> then, you just have to do something like this
>
> library(rgdal)
>
> data<-read.table ("mydata.txt", h=T, sep=",") #your original dataset
> coordinates(data)<-~ X + Y # where X and Y stand for the name of your lat/lon 
> columns
> proj4string(data)<-CRS("+init=epsg:4326")  #if your coordinates are in WGS84
> data.proj<-spTransfrom(data, 
> CRS("+init=epsg:the.correct.epsg.number.of.your.projection")

Looks like:

http://spatialreference.org/ref/epsg/32118/

but has some different parameters. Search on "New York" in this site for 
alternatives.

Roger

>
> HTH
>
> Alex
>
>
> Le 24/08/2010 16:51, Jonathan Marc Bearak a ?crit :
>> Hi,
>> 
>> I'm new to GIS and have been trying to convert latitude and longitude 
>> to/from state plane coordinates.
>> 
>> I've tried using the project() program from the proj4 library to convert 
>> lat/lng to FIPS 3104 (New York State Long Island).
>> 
>> No matter how I go about this, however, the coordinates come out wrong. 
>> E.g.,
>> 		  	"+proj=lcc +lat_1=40.66666666666666 
>> +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000 
>> +y_0=0 +units=ft +no_defs +datum=NAD83",
>> 		  	"+proj=lcc +a=6378137 +es=.0066943800229 +lon_0=-74 
>> +lat_1=41d2 +lat_2=40d40 +lat_0=40d10 +x_0=300000 +y_0=0 +units=ft +no_defs 
>> +datum=NAD83",
>> 
>> E.g., if I try the inverse, to convert 1062791, 209606.6 to lat/lng, 
>> project() prints:  43.04762 -76.89626.  The correct coordinates, however, 
>> are: 40.7416495 -073.7165681.
>> 
>> I've been reading the mailing lists and searching Google and R project PDFs 
>> and manual pages without any luck for an embarrassingly long number of 
>> hours without any luck.
>> 
>> Thanks for any help.
>> 
>> Best,
>> Jonathan
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From villers.alexandre at gmail.com  Tue Aug 24 18:32:00 2010
From: villers.alexandre at gmail.com (Alexandre Villers)
Date: Tue, 24 Aug 2010 18:32:00 +0200
Subject: [R-sig-Geo] Converting State Plane Coordinates
In-Reply-To: <alpine.LRH.2.00.1008241757080.31561@reclus.nhh.no>
References: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>	<4C73DFF3.60807@gmail.com>
	<alpine.LRH.2.00.1008241757080.31561@reclus.nhh.no>
Message-ID: <4C73F400.40600@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/dab2c23d/attachment.pl>

From Roger.Bivand at nhh.no  Tue Aug 24 19:45:15 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Aug 2010 19:45:15 +0200 (CEST)
Subject: [R-sig-Geo] Converting State Plane Coordinates
In-Reply-To: <4C73F400.40600@gmail.com>
References: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>
	<4C73DFF3.60807@gmail.com>
	<alpine.LRH.2.00.1008241757080.31561@reclus.nhh.no>
	<4C73F400.40600@gmail.com>
Message-ID: <alpine.LRH.2.00.1008241942110.32280@reclus.nhh.no>

On Tue, 24 Aug 2010, Alexandre Villers wrote:

> Hey,
>
> There is an ESRI code (ESRI:102318 
> <http://spatialreference.org/ref/esri/102318/>) corresponding to the 
> requested projection... However, I doubt CRS will take an ESRI code (Roger 
> ?).

CRS("+init=esri:102318")

but the ESRI version doesn't give a +datum=, so WGS84 will be assumed. The 
difference is the reversal of the +lat1= and +lat2= values, so probably 
not drastic.

Roger

> Jonathan, have a look at the rgdal and sp packages help pages for the "How 
> To" in CRS()
>
> Best regards
>
> Alex
>
> Le 24/08/2010 17:58, Roger Bivand a ?crit :
>> On Tue, 24 Aug 2010, Alexandre Villers wrote:
>> 
>>> Hello,
>>> 
>>> Have a look at spTransform (in rgdal package) and the EPSG code of the 
>>> desired projection (this is to me the easiest way not to mess with digits 
>>> and various copy errors that can be made while writing the projection 
>>> properties) at www.spatialreference.org
>>> 
>>> then, you just have to do something like this
>>> 
>>> library(rgdal)
>>> 
>>> data<-read.table ("mydata.txt", h=T, sep=",") #your original dataset
>>> coordinates(data)<-~ X + Y # where X and Y stand for the name of your 
>>> lat/lon columns
>>> proj4string(data)<-CRS("+init=epsg:4326")  #if your coordinates are in 
>>> WGS84
>>> data.proj<-spTransfrom(data, 
>>> CRS("+init=epsg:the.correct.epsg.number.of.your.projection")
>> 
>> Looks like:
>> 
>> http://spatialreference.org/ref/epsg/32118/
>> 
>> but has some different parameters. Search on "New York" in this site for 
>> alternatives.
>> 
>> Roger
>> 
>>> 
>>> HTH
>>> 
>>> Alex
>>> 
>>> 
>>> Le 24/08/2010 16:51, Jonathan Marc Bearak a ?crit :
>>>> Hi,
>>>> 
>>>> I'm new to GIS and have been trying to convert latitude and longitude 
>>>> to/from state plane coordinates.
>>>> 
>>>> I've tried using the project() program from the proj4 library to convert 
>>>> lat/lng to FIPS 3104 (New York State Long Island).
>>>> 
>>>> No matter how I go about this, however, the coordinates come out wrong. 
>>>> E.g.,
>>>>               "+proj=lcc +lat_1=40.66666666666666 
>>>> +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000 
>>>> +y_0=0 +units=ft +no_defs +datum=NAD83",
>>>>               "+proj=lcc +a=6378137 +es=.0066943800229 +lon_0=-74 
>>>> +lat_1=41d2 +lat_2=40d40 +lat_0=40d10 +x_0=300000 +y_0=0 +units=ft 
>>>> +no_defs +datum=NAD83",
>>>> 
>>>> E.g., if I try the inverse, to convert 1062791, 209606.6 to lat/lng, 
>>>> project() prints:  43.04762 -76.89626.  The correct coordinates, however, 
>>>> are: 40.7416495 -073.7165681.
>>>> 
>>>> I've been reading the mailing lists and searching Google and R project 
>>>> PDFs and manual pages without any luck for an embarrassingly long number 
>>>> of hours without any luck.
>>>> 
>>>> Thanks for any help.
>>>> 
>>>> Best,
>>>> Jonathan
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>> 
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>> 
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From dan.putler at sauder.ubc.ca  Tue Aug 24 19:54:56 2010
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Tue, 24 Aug 2010 10:54:56 -0700
Subject: [R-sig-Geo] Converting State Plane Coordinates
In-Reply-To: <1200_1282671931_1282671931_alpine.LRH.2.00.1008241942110.32280@reclus.nhh.no>
References: <35BE6059-C5EB-42FB-B271-469EF75C329A@nyu.edu>	<4C73DFF3.60807@gmail.com>	<alpine.LRH.2.00.1008241757080.31561@reclus.nhh.no>	<4C73F400.40600@gmail.com>
	<1200_1282671931_1282671931_alpine.LRH.2.00.1008241942110.32280@reclus.nhh.no>
Message-ID: <4C740770.8000808@sauder.ubc.ca>

Roger,

This won't really matter since they are very close, but given the data 
source and a North America based company, my guess is the underlying 
datum is NAD83.

Dan

On 08/24/2010 10:45 AM, Roger Bivand wrote:
> On Tue, 24 Aug 2010, Alexandre Villers wrote:
>
>    
>> Hey,
>>
>> There is an ESRI code (ESRI:102318
>> <http://spatialreference.org/ref/esri/102318/>) corresponding to the
>> requested projection... However, I doubt CRS will take an ESRI code (Roger
>> ?).
>>      
> CRS("+init=esri:102318")
>
> but the ESRI version doesn't give a +datum=, so WGS84 will be assumed. The
> difference is the reversal of the +lat1= and +lat2= values, so probably
> not drastic.
>
> Roger
>
>    
>> Jonathan, have a look at the rgdal and sp packages help pages for the "How
>> To" in CRS()
>>
>> Best regards
>>
>> Alex
>>
>> Le 24/08/2010 17:58, Roger Bivand a ?crit :
>>      
>>> On Tue, 24 Aug 2010, Alexandre Villers wrote:
>>>
>>>        
>>>> Hello,
>>>>
>>>> Have a look at spTransform (in rgdal package) and the EPSG code of the
>>>> desired projection (this is to me the easiest way not to mess with digits
>>>> and various copy errors that can be made while writing the projection
>>>> properties) at www.spatialreference.org
>>>>
>>>> then, you just have to do something like this
>>>>
>>>> library(rgdal)
>>>>
>>>> data<-read.table ("mydata.txt", h=T, sep=",") #your original dataset
>>>> coordinates(data)<-~ X + Y # where X and Y stand for the name of your
>>>> lat/lon columns
>>>> proj4string(data)<-CRS("+init=epsg:4326")  #if your coordinates are in
>>>> WGS84
>>>> data.proj<-spTransfrom(data,
>>>> CRS("+init=epsg:the.correct.epsg.number.of.your.projection")
>>>>          
>>> Looks like:
>>>
>>> http://spatialreference.org/ref/epsg/32118/
>>>
>>> but has some different parameters. Search on "New York" in this site for
>>> alternatives.
>>>
>>> Roger
>>>
>>>        
>>>> HTH
>>>>
>>>> Alex
>>>>
>>>>
>>>> Le 24/08/2010 16:51, Jonathan Marc Bearak a ?crit :
>>>>          
>>>>> Hi,
>>>>>
>>>>> I'm new to GIS and have been trying to convert latitude and longitude
>>>>> to/from state plane coordinates.
>>>>>
>>>>> I've tried using the project() program from the proj4 library to convert
>>>>> lat/lng to FIPS 3104 (New York State Long Island).
>>>>>
>>>>> No matter how I go about this, however, the coordinates come out wrong.
>>>>> E.g.,
>>>>>                "+proj=lcc +lat_1=40.66666666666666
>>>>> +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000
>>>>> +y_0=0 +units=ft +no_defs +datum=NAD83",
>>>>>                "+proj=lcc +a=6378137 +es=.0066943800229 +lon_0=-74
>>>>> +lat_1=41d2 +lat_2=40d40 +lat_0=40d10 +x_0=300000 +y_0=0 +units=ft
>>>>> +no_defs +datum=NAD83",
>>>>>
>>>>> E.g., if I try the inverse, to convert 1062791, 209606.6 to lat/lng,
>>>>> project() prints:  43.04762 -76.89626.  The correct coordinates, however,
>>>>> are: 40.7416495 -073.7165681.
>>>>>
>>>>> I've been reading the mailing lists and searching Google and R project
>>>>> PDFs and manual pages without any luck for an embarrassingly long number
>>>>> of hours without any luck.
>>>>>
>>>>> Thanks for any help.
>>>>>
>>>>> Best,
>>>>> Jonathan
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>            
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>          
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>        
>


From Greg.Snow at imail.org  Tue Aug 24 21:43:13 2010
From: Greg.Snow at imail.org (Greg Snow)
Date: Tue, 24 Aug 2010 13:43:13 -0600
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <466503.59281.qm@web54307.mail.re2.yahoo.com>
References: <4C73DB86.7090708@isciences.com>
	<466503.59281.qm@web54307.mail.re2.yahoo.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC633B8EB615@LP-EXMBVS10.CO.IHC.COM>

I don't know ggplot2 well enough to answer about that, but you can use the symbols function to add symbols to an existing plot (which could be the map plotted using maps or maptools/sp etc.).  For even more control/options you could look at my.symbols or subplot in the TeachingDemos package (the help page for subplot shows an example of plotting barcharts onto a map).

For general plotting on maps interest (possibly for when you don't have a shapefile) there is the RGoogleMaps package which will help you get a map (bitmap image, not shapefile) from google or openstreetmaps plot it as the background of a plot, then add points.

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Thiago Veloso
> Sent: Tuesday, August 24, 2010 9:22 AM
> To: r-sig-geo at stat.math.ethz.ch; Matthew Landis
> Subject: Re: [R-sig-Geo] Mapping multiple attributes at once
> 
> ??Hello, Matthew.
> ??Just a superb complement of yours.
> ??I was about to ask the same question to Pierre and Paul, after
> thanking them for the useful and functional tip. I managed to follow
> the ggplot examples, but a next step would involve plotting my interest
> points over a shape file (state contour).
> ??Is that possible?
> ??Best wishes,
> ??Thiago.
> 
> --- On Tue, 24/8/10, Matthew Landis <landis at isciences.com> wrote:
> 
> From: Matthew Landis <landis at isciences.com>
> Subject: Re: [R-sig-Geo] Mapping multiple attributes at once
> To: r-sig-geo at stat.math.ethz.ch
> Date: Tuesday, 24 August, 2010, 11:47
> 
>  I've been following this topic with some interest, since this is
> something I might like to do fairly often.? I'm not that familiar with
> ggplot2, but it looks really useful.? Is there a way to overplot (or
> underplot) a shapefile (e.g. of coastlines) with the approach suggested
> by Paul?
> 
> Matt
> 
> On 8/24/2010 10:25 AM, Paul Hiemstra wrote:
> > In addition to the reply by Pierre Roudier, take a look at the
> ggplot2
> > pacakge. An example:
> >
> 
> 
> -- ~~~~~~~~~~~~~~~~~~~~~~~~~~
> Matthew Landis, Ph.D.
> Research Scientist
> ISciences, LLC
> 61 Main St. Suite 200
> Burlington VT 05401
> 802.864.2999
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]


From ricardorodot02 at gmail.com  Tue Aug 24 23:21:42 2010
From: ricardorodot02 at gmail.com (=?ISO-8859-1?Q?Ricardo_Rodr=EDguez?=)
Date: Tue, 24 Aug 2010 16:21:42 -0500
Subject: [R-sig-Geo] matrix distances
Message-ID: <AANLkTi=resP7JhjOwCs25Aq=P72bZjSXSQyF3UhK72WX@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/9edb6633/attachment.pl>

From ricardorodot02 at gmail.com  Tue Aug 24 23:42:03 2010
From: ricardorodot02 at gmail.com (=?ISO-8859-1?Q?Ricardo_Rodr=EDguez?=)
Date: Tue, 24 Aug 2010 16:42:03 -0500
Subject: [R-sig-Geo] operations with grassgis
Message-ID: <AANLkTik4Qceue8RyvoEyPSSj7Vh=knRZu9c-gzFhkdQe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/76e546df/attachment.pl>

From pierre.roudier at gmail.com  Wed Aug 25 00:17:36 2010
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Wed, 25 Aug 2010 10:17:36 +1200
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <466503.59281.qm@web54307.mail.re2.yahoo.com>
References: <4C73DB86.7090708@isciences.com>
	<466503.59281.qm@web54307.mail.re2.yahoo.com>
Message-ID: <AANLkTi=6ZgTbYR6kL6R83vi3GXpvhcBR-Tt3sVdP+0me@mail.gmail.com>

Hello Thiago,

First, I owe you and the list a reproducible example (my first example
does not run properly - my bad):

dat <- data.frame(x=runif(50), y=runif(50),
category=sample(letters[1:3], size=50, replace=TRUE),
continuous=runif(50))
# You may want to do some spatial analysis on that data.frame
library(sp)
coordinates(dat) <- ~x+y
# Some spatial analysis here

# Now you want to plot it
library(ggplot2)
df <- as.data.frame(dat) # backtransforms dat into a data.frame object
(ggplot2 does not handle sp objects)
# Here I chose to plot the continuous variable with the size of the
bubbles, and the categorical variable with the colours
my.plot <- ggplot(data=df, aes(x=x, y=y)) +
geom_point(aes(size=continuous, colour=category)) + coord-equal()
print(my.plot)

Second, about plotting a shape file: yes, it is possible. Consider
this blog entry for example:
http://blog.revolutionanalytics.com/2009/11/choropleth-challenge-result.html

Basically, you want to use either geom_path() for simple state
boundaries, or geom_polygon() for polygons (e.g. you want to map some
attribute by state).

Sorry I haven't much experience with this. That could be a good
question on the ggplot2 mailing list
(http://groups.google.com/group/ggplot2).

Pierre


2010/8/25 Thiago Veloso <thi_veloso at yahoo.com.br>:
> ??Hello, Matthew.
> ??Just a superb complement of yours.
> ??I was about to ask the same question to Pierre and Paul, after thanking them for the useful and functional tip. I managed to follow the ggplot examples, but a next step would involve plotting my interest points over a shape file (state contour).
> ??Is that possible?
> ??Best wishes,
> ??Thiago.
>
> --- On Tue, 24/8/10, Matthew Landis <landis at isciences.com> wrote:
>
> From: Matthew Landis <landis at isciences.com>
> Subject: Re: [R-sig-Geo] Mapping multiple attributes at once
> To: r-sig-geo at stat.math.ethz.ch
> Date: Tuesday, 24 August, 2010, 11:47
>
> ?I've been following this topic with some interest, since this is something I might like to do fairly often.? I'm not that familiar with ggplot2, but it looks really useful.? Is there a way to overplot (or underplot) a shapefile (e.g. of coastlines) with the approach suggested by Paul?
>
> Matt
>
> On 8/24/2010 10:25 AM, Paul Hiemstra wrote:
>> In addition to the reply by Pierre Roudier, take a look at the ggplot2
>> pacakge. An example:
>>
>
>
> -- ~~~~~~~~~~~~~~~~~~~~~~~~~~
> Matthew Landis, Ph.D.
> Research Scientist
> ISciences, LLC
> 61 Main St. Suite 200
> Burlington VT 05401
> 802.864.2999
> ~~~~~~~~~~~~~~~~~~~~~~~~~~
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From S.elMesslaki at student.TUDelft.NL  Wed Aug 25 00:20:57 2010
From: S.elMesslaki at student.TUDelft.NL (Sabira el Messlaki)
Date: Wed, 25 Aug 2010 00:20:57 +0200
Subject: [R-sig-Geo] knn2nb
References: <3154E0B9605B3140AFAD0A3A97DA29CF832420@SRV603.tudelft.net>
	<alpine.LRH.2.00.1008241748280.31561@reclus.nhh.no>
Message-ID: <3154E0B9605B3140AFAD0A3A97DA29CF832422@SRV603.tudelft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100825/0a2df74d/attachment.pl>

From djmuser at gmail.com  Wed Aug 25 00:55:51 2010
From: djmuser at gmail.com (Dennis Murphy)
Date: Tue, 24 Aug 2010 15:55:51 -0700
Subject: [R-sig-Geo] Mapping multiple attributes at once
In-Reply-To: <AANLkTi=6ZgTbYR6kL6R83vi3GXpvhcBR-Tt3sVdP+0me@mail.gmail.com>
References: <4C73DB86.7090708@isciences.com>
	<466503.59281.qm@web54307.mail.re2.yahoo.com>
	<AANLkTi=6ZgTbYR6kL6R83vi3GXpvhcBR-Tt3sVdP+0me@mail.gmail.com>
Message-ID: <AANLkTikyhOVNr50Hm1dmqXv3OE22aPX50yMPdDup72rW@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100824/664bdc35/attachment.pl>

From Roger.Bivand at nhh.no  Wed Aug 25 09:28:38 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Aug 2010 09:28:38 +0200 (CEST)
Subject: [R-sig-Geo] operations with grassgis
In-Reply-To: <AANLkTik4Qceue8RyvoEyPSSj7Vh=knRZu9c-gzFhkdQe@mail.gmail.com>
References: <AANLkTik4Qceue8RyvoEyPSSj7Vh=knRZu9c-gzFhkdQe@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008250916530.2149@reclus.nhh.no>

On Tue, 24 Aug 2010, Ricardo Rodr?guez wrote:

> hi all am new to the use of R-cran, I have a question that you can carry
> objects grassgis calculations or the results of a particular process.
> thanks for the help and attention

Please first read the "Spatial" task view on your CRAN mirror carefully, 
and follow up references in the links given there.

The file included with spgrass6 is also at:

http://www.osgeo.org/ojs/index.php/journal/issue/view/17

showing the status of the interface some years ago. There is also a 
captured session at:

http://spatial.nhh.no/wun09/wun_grass.swf

again using R within an existing GRASS location. Documentation on using R 
with temporary GRASS locations is less user-friendly, because this 
approach has been added more recently. See also the statsgrass list 
archives:

http://grass.osgeo.org/statsgrass/index.php

Hope this helps,

Roger

>
> Ricardo Rodr?guez
> Univalle
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From dorothea.lemke at uni-muenster.de  Wed Aug 25 10:43:48 2010
From: dorothea.lemke at uni-muenster.de (Dorothea Lemke)
Date: Wed, 25 Aug 2010 10:43:48 +0200 (CEST)
Subject: [R-sig-Geo] SpatialGridDataFrame to SpatialPixelDataFrame
Message-ID: <permail-20100825084348f7e55a9d00007ef9-dlemk_01@message-id.uni-muenster.de>

Dear list,

I have problems to coerce a SpatialGridDataFrame object to a
SpatialPixelDataFrame. I 've calculated a kerneldensity (splancs) and I want
to convert the results from the SpatialGridDataFrame to a
SpatialPixelDataFrame.

My R-code:

>library (maptools)
>library (splancs)
>library (rgdal)

> kcasesC67m<-spkernel2d(cases, pRBMS, h0=3500, gt)
> kcontrolsC67m<-spkernel2d(controls, pRBMS, h0=3500, gt)
> df<-data.frame(kcasesC67m=kcasesC67m, kcontrolsC67m=kcontrolsC67m)
> spkratio<-SpatialGridDataFrame(gt, data = df)
> spkratioP<-as(spkratio, "SpatialPixelDataFrame")

But I get the error message: "No methods and no standards to convert
SpatialGridDataFrame in SpatialPixelDataFrame".

Many thanks for your help
Dorothea


From roman.lustrik at gmail.com  Wed Aug 25 12:05:04 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Wed, 25 Aug 2010 12:05:04 +0200
Subject: [R-sig-Geo] SpatialGridDataFrame to SpatialPixelDataFrame
In-Reply-To: <permail-20100825084348f7e55a9d00007ef9-dlemk_01@message-id.uni-muenster.de>
References: <permail-20100825084348f7e55a9d00007ef9-dlemk_01@message-id.uni-muenster.de>
Message-ID: <AANLkTi=iaY70VFEFeFGW5DLuvuQ9ZnF2oJxv0vyvfeso@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100825/d42fb420/attachment.pl>

From nikhil.list at gmail.com  Wed Aug 25 12:05:40 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Wed, 25 Aug 2010 06:05:40 -0400
Subject: [R-sig-Geo] SpatialGridDataFrame to SpatialPixelDataFrame
In-Reply-To: <permail-20100825084348f7e55a9d00007ef9-dlemk_01@message-id.uni-muenster.de>
References: <permail-20100825084348f7e55a9d00007ef9-dlemk_01@message-id.uni-muenster.de>
Message-ID: <7E43F750-0914-463F-A664-7FA44421AA6C@gmail.com>

You have a typo.

It is SpatialPixelsDataFrame. note the s

Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 25, 2010, at 4:43 AM, Dorothea Lemke wrote:

> Dear list,
>
> I have problems to coerce a SpatialGridDataFrame object to a
> SpatialPixelDataFrame. I 've calculated a kerneldensity (splancs)  
> and I want
> to convert the results from the SpatialGridDataFrame to a
> SpatialPixelDataFrame.
>
> My R-code:
>
>> library (maptools)
>> library (splancs)
>> library (rgdal)
>
>> kcasesC67m<-spkernel2d(cases, pRBMS, h0=3500, gt)
>> kcontrolsC67m<-spkernel2d(controls, pRBMS, h0=3500, gt)
>> df<-data.frame(kcasesC67m=kcasesC67m, kcontrolsC67m=kcontrolsC67m)
>> spkratio<-SpatialGridDataFrame(gt, data = df)
>> spkratioP<-as(spkratio, "SpatialPixelDataFrame")
>
> But I get the error message: "No methods and no standards to convert
> SpatialGridDataFrame in SpatialPixelDataFrame".
>
> Many thanks for your help
> Dorothea
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Wed Aug 25 14:33:58 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 25 Aug 2010 14:33:58 +0200
Subject: [R-sig-Geo] Workshop on handling and analyzing spatio-temporal data
 in R, 21-22 Mar 2011
Message-ID: <4C750DB6.7090003@uni-muenster.de>

Dear all,

The institute for geoinformatics of the university of M?nster is happy
to announce a two-day workshop on handling and analyzing
spatio-temporal data in R. You'll find the full announcement and
description on http://www.opengeostatistics.org/

Workshop goals are: (1) to meet other R users/developers who work with
spatio-temporal data and need classes and methods for storing,
manipulating, analyzing and visualising spatio-temporal data, (2) to set
up bi-lateral and common research/development agendas, (3) to write and
test code. The form will be a mix of informal presentations, open
discussions, and break-out sessions in smaller groups.

The workshop will be held the two days before the spatial statistics
conference, http://www.spatialstatisticsconference.com/ -- I'm sending
this message now for those who want to attend both: the deadline for
abstracts to the spatial statistics conference is on Sept 21.

Please redistribute this message.

With best regards,

Katharina, Daniel, Edzer (local organizers)
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Wed Aug 25 14:53:33 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 25 Aug 2010 14:53:33 +0200
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
	<alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>
Message-ID: <4C75124D.50000@uni-muenster.de>

Barry, what exactly did you try out before you posted?

Your claim is not completely true: geoR has a function
as.geodata.SpatialPointsDataFrame, so you can do, for instance:

library(geoR)
data(meuse) # from sp
coordinates(meuse) = ~x+y
krige.bayes(as.geodata(meuse, "zinc"))

and its locations argument can be a SpatialPoints object.

Best regards,

On 08/18/2010 09:05 PM, Roger Bivand wrote:
> On Wed, 18 Aug 2010, Barry Rowlingson wrote:
> 
>> Hi,
>>
>> Recently while teaching at SFU I hit the problem that infects R when
>> many people work on similar projects - the multitude of data formats
>> for similar data. The sp project was partly an attempt to give a
>> standard format for spatial data but its widespread non-use in older
>> packages causes trouble.
>>
>> So for example I taught the students all about 'sp' objects, and then
>> they had to use spatstat and splancs for some point-process stuff,
>> then geoR for some kriging, none of which use sp objects.
>>
>> So I figured maybe we need a whole load of 'as' functions that can
>> convert between the various spatial data formats (there are more in
>> CRAN, I am sure) to help us all out on this. Some of these functions
>> may already exist, indeed I just found something about converting
>> fairly raw x-y coordinate objects to SpatialPolygons hidden away in
>> the SpatialEpi package (polygons2spatial.polygons).
> 
> Barry,
> 
> I think that spatstat is well provided for, mostly in maptools, but also
> in the spatstat vignette on using shapefiles. Of course, the available
> functionalities sp <-> spatstat classes could probably be documented
> more fully, and the coercion functions updated, but I think that they do
> most of what is needed.
> 
> I agree that there may be others out there, and like you come across
> them from time to time. Sometimes the CRAN reverse dependencies show who
> they might be. Since splancs is largely pre-S3 (right?) and doesn't use
> classes, coercion isn't an option, so documentation and a wrapper
> function or two might be sensible. I started on this, but only got as
> far as the spkernel2d() that uses a call to GridTopology() to set up the
> output grid.
> 
> geoR does use S3 classes, so might be closer, and does depend on sp.
> There is a method for coercing a SpatialPointsDataFrame to "geodata".
> The borders component of a "geodata" object is harder to introduce.
> Taking the coordinates() of a SpatialPixels object to pass to locations=
> is OK, as are the subsetting of data frame columns for the trend.d= and
> trend.l= arguments. I guess Paulo would need to move to a formula= data=
> interface to likfit(), krige.bayes() and krige.conv(), at least, to
> permit sp objects to be used "closer" to the actual core.
> 
> Probably a good deal could be done by documentation, and by
> communicating better about what already is there.
> 
> Useful topic!
> 
> Best wishes,
> 
> Roger
> 
>>
>> Would it be a good idea to stick all the conversions we can think of
>> into a single package, "spBabel" say (or spConversion to avoid any
>> cultural reference), so people have a one-stop shop? And if we find
>> routines stuck in other packages (such as polygons2spatial.polygons)
>> we rip them out and bundle them?
>>
>> Yes, its a matter of time and effort and we're all busy, but I'd like
>> to put it out as a proposal. It might make a nice intern or GSOC
>> project, but we're a bit late for that, so maybe if anyone has a PhD
>> student starting who needs to get up to speed with R packages and
>> spatial data it would be a good introduction for them. Once its all
>> set up (on R-forge or similar) contributing shouldn't be a problem.
>>
>> Okay, that's my one crazy idea for the day done.
>>
>> Barry
>>
>>
>>
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From jeremy.raw at dot.gov  Wed Aug 25 16:55:09 2010
From: jeremy.raw at dot.gov (jeremy.raw at dot.gov)
Date: Wed, 25 Aug 2010 10:55:09 -0400
Subject: [R-sig-Geo] matrix distances
In-Reply-To: <AANLkTi=resP7JhjOwCs25Aq=P72bZjSXSQyF3UhK72WX@mail.gmail.com>
References: <AANLkTi=resP7JhjOwCs25Aq=P72bZjSXSQyF3UhK72WX@mail.gmail.com>
Message-ID: <B3C9A56C0E6FBF48A7D3ED79E9A7A9C00344ED37@OSTMAIL03VS3.ad.dot.gov>

There are a two ways that I am aware of to generate a matrix of point-to-point distances computed by traversing a network of roads:

1. One well-tested and reasonably fast solution is the igraph package on CRAN, using the shortest.paths function

2. There is a more specialized (and still experimental) package on R-Forge called travelr (of which I am the primary author) that is designed to support traffic assignment applications (http://r-forge.r-project.org/projects/travelr).  There is more setup involved than with igraph, but the tradeoff is that it is easier to get at the results that typically matter for travel demand models.

Neither of these approaches works seamlessly with R spatial objects (it's on the agenda for travelr), but it's straightforward to make the conversion.  The gdistance package (also on R-forge) uses igraph to develop shortest paths across a grid, and illustrates the basic steps needed to make a structure of coordinates ready for analysis through igraph.

Jeremy Raw, P.E., AICP
FHWA Office of Planning
jeremy.raw at dot.gov
(202) 366-0986

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Ricardo Rodr?guez
Sent: Tuesday, August 24, 2010 5:22 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] matrix distances

Hello everyone I am new to the use of R-cran, I have a question in which way can create arrays of distances (Euclidian and Into network) a network of roads with space objects.

thanks for your attention

Ricardo Rodr?guez
Univalle

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Wed Aug 25 17:00:53 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 25 Aug 2010 16:00:53 +0100
Subject: [R-sig-Geo] matrix distances
In-Reply-To: <B3C9A56C0E6FBF48A7D3ED79E9A7A9C00344ED37@OSTMAIL03VS3.ad.dot.gov>
References: <AANLkTi=resP7JhjOwCs25Aq=P72bZjSXSQyF3UhK72WX@mail.gmail.com>
	<B3C9A56C0E6FBF48A7D3ED79E9A7A9C00344ED37@OSTMAIL03VS3.ad.dot.gov>
Message-ID: <AANLkTimMqXZOySZB05HtQU48fWBWGWSXxU2RXRsQWvGi@mail.gmail.com>

On Wed, Aug 25, 2010 at 3:55 PM,  <jeremy.raw at dot.gov> wrote:
> There are a two ways that I am aware of to generate a matrix of point-to-point distances computed by traversing a network of roads:
>
> 1. One well-tested and reasonably fast solution is the igraph package on CRAN, using the shortest.paths function
>
> 2. There is a more specialized (and still experimental) package on R-Forge called travelr (of which I am the primary author) that is designed to support traffic assignment applications (http://r-forge.r-project.org/projects/travelr). ?There is more setup involved than with igraph, but the tradeoff is that it is easier to get at the results that typically matter for travel demand models.
>
> Neither of these approaches works seamlessly with R spatial objects (it's on the agenda for travelr), but it's straightforward to make the conversion. ?The gdistance package (also on R-forge) uses igraph to develop shortest paths across a grid, and illustrates the basic steps needed to make a structure of coordinates ready for analysis through igraph.

 Someone I know did write some python scripts that used http calls to
Google Maps to first lookup locations from UK postcodes and then use
google maps routing to compute both driving distance and crow-flies
distance. This involved lots of reverse engineering of google's http
interface for sending queries and then scraping the response. And was
probably against the google T+Cs, which might explain why every so
often the response was 'hey, are you a robot? fill in this captcha to
prove you arent'.

 No, wasn't me, honest guv.

Barry


From jorgy.porgee at gmail.com  Wed Aug 25 17:28:33 2010
From: jorgy.porgee at gmail.com (Jorgy Porgee)
Date: Wed, 25 Aug 2010 17:28:33 +0200
Subject: [R-sig-Geo] Label only 2 (min & max) contour lines using Lattice's
	contourplot() ?
Message-ID: <AANLkTimDFg6RsikFZt=2qOHf8dDTWG=qLqKku69ci7Ak@mail.gmail.com>

Good day all, I hope someone can help.

I'm new to the contourplot() function and because the contour plots
I'm making have very close contour lines, I'd like to label only the
minimum and maximum values. Is there a straight forward way of doing
this?

Thus far, I've tried setting the labels argument i.e contourplot(...,
labels=list(cex=0.8,labels=c(minValue,maxValue), ...) but with no luck
- all contour lines are still labelled which leads to unsightly,
overlapping text.

Kindly advise on how to get around this..

Thanking you in advance,

Jorge.


From b.rowlingson at lancaster.ac.uk  Wed Aug 25 21:00:13 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 25 Aug 2010 20:00:13 +0100
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <4C75124D.50000@uni-muenster.de>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
	<alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>
	<4C75124D.50000@uni-muenster.de>
Message-ID: <AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>

On Wed, Aug 25, 2010 at 1:53 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Barry, what exactly did you try out before you posted?
>
> Your claim is not completely true: geoR has a function
> as.geodata.SpatialPointsDataFrame, so you can do, for instance:
>
> library(geoR)
> data(meuse) # from sp
> coordinates(meuse) = ~x+y
> krige.bayes(as.geodata(meuse, "zinc"))
>
> and its locations argument can be a SpatialPoints object.

Well, I didnt claim these functions didnt exist, nor did I point out
that some are trivial - ie to get from a SpatialPointsDataFrame to a
set of locations for, say, splancs' K-function, you just do
coordinates(foo). What I was hoping for was that we could create a
single point where these conversions could be collected, which would
be an almost authoritative source of conversions.

 geoR has SpatialPointsDataFrame to geodata - but does it have the
other way round too? Or is that in sp? It doesn't matter too much,
since students will find them either way, but does
as.sp(as.geodata('meuse","zinc")) get you back where you started?
That's what students may expect. Conversion is a big headache for new
users and anything that makes it easier is a plus. Imagine doing
vignette(spBabel) and getting a whole list of what formats can be
converted together with caveats and restrictions - sounds good to me.

 Obviously the problems are in maintainance and keeping conversions up
to date with any changes in the format in the main package, as well as
that this package would probably depend on all the other packages...

  Idle coffee-time thoughts...

Barry


From r.hijmans at gmail.com  Wed Aug 25 21:10:40 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 25 Aug 2010 12:10:40 -0700
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
	<alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>
	<4C75124D.50000@uni-muenster.de>
	<AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>
Message-ID: <AANLkTi=ZrJUA4qKJ7Y_pFdBzmMSj6usJiOut_Yet0T=h@mail.gmail.com>

I think that such a package would be very useful. It could have a
single function like

convert(x, 'AnotherClass')

The package would only need to depend on sp, all the other packages
would be "suggested" such that you do not need to install the packages
you do not use.

Robert


On Wed, Aug 25, 2010 at 12:00 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Wed, Aug 25, 2010 at 1:53 PM, Edzer Pebesma
> <edzer.pebesma at uni-muenster.de> wrote:
>> Barry, what exactly did you try out before you posted?
>>
>> Your claim is not completely true: geoR has a function
>> as.geodata.SpatialPointsDataFrame, so you can do, for instance:
>>
>> library(geoR)
>> data(meuse) # from sp
>> coordinates(meuse) = ~x+y
>> krige.bayes(as.geodata(meuse, "zinc"))
>>
>> and its locations argument can be a SpatialPoints object.
>
> Well, I didnt claim these functions didnt exist, nor did I point out
> that some are trivial - ie to get from a SpatialPointsDataFrame to a
> set of locations for, say, splancs' K-function, you just do
> coordinates(foo). What I was hoping for was that we could create a
> single point where these conversions could be collected, which would
> be an almost authoritative source of conversions.
>
> ?geoR has SpatialPointsDataFrame to geodata - but does it have the
> other way round too? Or is that in sp? It doesn't matter too much,
> since students will find them either way, but does
> as.sp(as.geodata('meuse","zinc")) get you back where you started?
> That's what students may expect. Conversion is a big headache for new
> users and anything that makes it easier is a plus. Imagine doing
> vignette(spBabel) and getting a whole list of what formats can be
> converted together with caveats and restrictions - sounds good to me.
>
> ?Obviously the problems are in maintainance and keeping conversions up
> to date with any changes in the format in the main package, as well as
> that this package would probably depend on all the other packages...
>
> ?Idle coffee-time thoughts...
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jtm6 at u.washington.edu  Wed Aug 25 21:10:27 2010
From: jtm6 at u.washington.edu (jtm6 at u.washington.edu)
Date: Wed, 25 Aug 2010 12:10:27 -0700 (PDT)
Subject: [R-sig-Geo] Using SEVs in GAMs
Message-ID: <alpine.LRH.2.01.1008251210270.3256@hymn32.u.washington.edu>

Hello,

Can anybody give an explanation of why spatial eigenvectors (SEVs) such those produced by ME() in package "spdep" can not be used in general additive models (gams)and only in linear models? I think I understand  generally why (the SEVs are orthogonal and linearly independent) but I would love to hear from a more knowledgeable person.

many thanks in advance,
James


From edzer.pebesma at uni-muenster.de  Wed Aug 25 22:03:29 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 25 Aug 2010 22:03:29 +0200
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <AANLkTi=ZrJUA4qKJ7Y_pFdBzmMSj6usJiOut_Yet0T=h@mail.gmail.com>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>	<alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>	<4C75124D.50000@uni-muenster.de>	<AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>
	<AANLkTi=ZrJUA4qKJ7Y_pFdBzmMSj6usJiOut_Yet0T=h@mail.gmail.com>
Message-ID: <4C757711.7090207@uni-muenster.de>

... and this convert function would then loop over all possible classes
of x, and for each possibility over all values for "AnotherClass"?
Sounds like the n-to-n solution we tried to avoid when we started sp.

Coercion is formally done in S4 by using as(), as in

as(x, "AnotherClass")

and this coercion is automatic when AnotherClass is a superclass for x,
and can otherwise be specified by setAs. Informally in S3, it's
typically done by functions like as.AnotherClass.ThisClass, which is
called when, in

as.AnotherClass(x)

x is of class "ThisClass".

Problems I see with having a package that provides all these functions
is authorship: will each class author of package X update this package
each time she/he changes a class definition (S4) or the assumptions
implicitly made about it (S3)? Also, for S4 classes I believe "suggest:"
only will not do.

I would rather ask package authors to call for explicit coercion, e.g.
the first line in krige.bayes (geoR) should be

if (class(data) != "geodata")
  data = as.geodata(data)

so that anyone passing it data of a new class will only have to provide
an as.geodata.MyNewClass function to make this work (provided that
package is loaded, which seems reasonable - some function will need to
create the MyNewClass objects).

Not dissimilar to Barry's 10 years old idea that coordinates(x) should
return the spatial coordinates of object x, whatever x is.

Why does

library(sp)
data(meuse)
coordinates(meuse) = ~x+y
plot(log(zinc) ~ sqrt(dist), meuse)

work? sp doesn't provide the plot method used here, and this method
doesn't know nor imports the Spatial* classes. Somewhere meuse gets
transformed to a data.frame, for which sp indeed provides methods.


On 08/25/2010 09:10 PM, Robert J. Hijmans wrote:
> I think that such a package would be very useful. It could have a
> single function like
> 
> convert(x, 'AnotherClass')
> 
> The package would only need to depend on sp, all the other packages
> would be "suggested" such that you do not need to install the packages
> you do not use.
> 
> Robert
> 
> 
> On Wed, Aug 25, 2010 at 12:00 PM, Barry Rowlingson
> <b.rowlingson at lancaster.ac.uk> wrote:
>> On Wed, Aug 25, 2010 at 1:53 PM, Edzer Pebesma
>> <edzer.pebesma at uni-muenster.de> wrote:
>>> Barry, what exactly did you try out before you posted?
>>>
>>> Your claim is not completely true: geoR has a function
>>> as.geodata.SpatialPointsDataFrame, so you can do, for instance:
>>>
>>> library(geoR)
>>> data(meuse) # from sp
>>> coordinates(meuse) = ~x+y
>>> krige.bayes(as.geodata(meuse, "zinc"))
>>>
>>> and its locations argument can be a SpatialPoints object.
>>
>> Well, I didnt claim these functions didnt exist, nor did I point out
>> that some are trivial - ie to get from a SpatialPointsDataFrame to a
>> set of locations for, say, splancs' K-function, you just do
>> coordinates(foo). What I was hoping for was that we could create a
>> single point where these conversions could be collected, which would
>> be an almost authoritative source of conversions.
>>
>>  geoR has SpatialPointsDataFrame to geodata - but does it have the
>> other way round too? Or is that in sp? It doesn't matter too much,
>> since students will find them either way, but does
>> as.sp(as.geodata('meuse","zinc")) get you back where you started?
>> That's what students may expect. Conversion is a big headache for new
>> users and anything that makes it easier is a plus. Imagine doing
>> vignette(spBabel) and getting a whole list of what formats can be
>> converted together with caveats and restrictions - sounds good to me.
>>
>>  Obviously the problems are in maintainance and keeping conversions up
>> to date with any changes in the format in the main package, as well as
>> that this package would probably depend on all the other packages...
>>
>>  Idle coffee-time thoughts...
>>
>> Barry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From r.hijmans at gmail.com  Wed Aug 25 22:18:54 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 25 Aug 2010 13:18:54 -0700
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <4C757711.7090207@uni-muenster.de>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
	<alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>
	<4C75124D.50000@uni-muenster.de>
	<AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>
	<AANLkTi=ZrJUA4qKJ7Y_pFdBzmMSj6usJiOut_Yet0T=h@mail.gmail.com>
	<4C757711.7090207@uni-muenster.de>
Message-ID: <AANLkTi=y5gWdJA0zsQ0E1=rag+QNJdT7wh4o-yRsC+JF@mail.gmail.com>

Rather something like this in the simplest form; i.e. using an S4
method for inheritance, and passing it on to other packages as much as
possible.

setMethod('convert', signature(x='ANY', class='character'),
function(x, class, ...) {
       y <- try( as(x, class), silent=TRUE )
       if (class(y) == 'try-error') { stop('sorry')    } else {  return(y) }
} )

And adding more methods for classes that do not have as methods. Most
objects could be coerced into an sp object, and then into whatever is
requested. Perhaps there is a lot of ugly nitty-gritty there. Perhaps
you are right about dependencies and S4.

Still, I think this could be a step forward from the current situation
where many no standard coercion functions exist that might be hard to
find or remember.

Robert


On Wed, Aug 25, 2010 at 1:03 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> ... and this convert function would then loop over all possible classes
> of x, and for each possibility over all values for "AnotherClass"?
> Sounds like the n-to-n solution we tried to avoid when we started sp.
>
> Coercion is formally done in S4 by using as(), as in
>
> as(x, "AnotherClass")
>
> and this coercion is automatic when AnotherClass is a superclass for x,
> and can otherwise be specified by setAs. Informally in S3, it's
> typically done by functions like as.AnotherClass.ThisClass, which is
> called when, in
>
> as.AnotherClass(x)
>
> x is of class "ThisClass".
>
> Problems I see with having a package that provides all these functions
> is authorship: will each class author of package X update this package
> each time she/he changes a class definition (S4) or the assumptions
> implicitly made about it (S3)? Also, for S4 classes I believe "suggest:"
> only will not do.
>
> I would rather ask package authors to call for explicit coercion, e.g.
> the first line in krige.bayes (geoR) should be
>
> if (class(data) != "geodata")
> ?data = as.geodata(data)
>
> so that anyone passing it data of a new class will only have to provide
> an as.geodata.MyNewClass function to make this work (provided that
> package is loaded, which seems reasonable - some function will need to
> create the MyNewClass objects).
>
> Not dissimilar to Barry's 10 years old idea that coordinates(x) should
> return the spatial coordinates of object x, whatever x is.
>
> Why does
>
> library(sp)
> data(meuse)
> coordinates(meuse) = ~x+y
> plot(log(zinc) ~ sqrt(dist), meuse)
>
> work? sp doesn't provide the plot method used here, and this method
> doesn't know nor imports the Spatial* classes. Somewhere meuse gets
> transformed to a data.frame, for which sp indeed provides methods.
>
>
> On 08/25/2010 09:10 PM, Robert J. Hijmans wrote:
>> I think that such a package would be very useful. It could have a
>> single function like
>>
>> convert(x, 'AnotherClass')
>>
>> The package would only need to depend on sp, all the other packages
>> would be "suggested" such that you do not need to install the packages
>> you do not use.
>>
>> Robert
>>
>>
>> On Wed, Aug 25, 2010 at 12:00 PM, Barry Rowlingson
>> <b.rowlingson at lancaster.ac.uk> wrote:
>>> On Wed, Aug 25, 2010 at 1:53 PM, Edzer Pebesma
>>> <edzer.pebesma at uni-muenster.de> wrote:
>>>> Barry, what exactly did you try out before you posted?
>>>>
>>>> Your claim is not completely true: geoR has a function
>>>> as.geodata.SpatialPointsDataFrame, so you can do, for instance:
>>>>
>>>> library(geoR)
>>>> data(meuse) # from sp
>>>> coordinates(meuse) = ~x+y
>>>> krige.bayes(as.geodata(meuse, "zinc"))
>>>>
>>>> and its locations argument can be a SpatialPoints object.
>>>
>>> Well, I didnt claim these functions didnt exist, nor did I point out
>>> that some are trivial - ie to get from a SpatialPointsDataFrame to a
>>> set of locations for, say, splancs' K-function, you just do
>>> coordinates(foo). What I was hoping for was that we could create a
>>> single point where these conversions could be collected, which would
>>> be an almost authoritative source of conversions.
>>>
>>> ?geoR has SpatialPointsDataFrame to geodata - but does it have the
>>> other way round too? Or is that in sp? It doesn't matter too much,
>>> since students will find them either way, but does
>>> as.sp(as.geodata('meuse","zinc")) get you back where you started?
>>> That's what students may expect. Conversion is a big headache for new
>>> users and anything that makes it easier is a plus. Imagine doing
>>> vignette(spBabel) and getting a whole list of what formats can be
>>> converted together with caveats and restrictions - sounds good to me.
>>>
>>> ?Obviously the problems are in maintainance and keeping conversions up
>>> to date with any changes in the format in the main package, as well as
>>> that this package would probably depend on all the other packages...
>>>
>>> ?Idle coffee-time thoughts...
>>>
>>> Barry
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 ?http://ifgi.uni-muenster.de
> http://www.52north.org/geostatistics ? ? ?e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From elaine.kuo.tw at gmail.com  Thu Aug 26 00:39:21 2010
From: elaine.kuo.tw at gmail.com (elaine kuo)
Date: Thu, 26 Aug 2010 06:39:21 +0800
Subject: [R-sig-Geo] Monte Carlo simulation and random habitat selection
Message-ID: <AANLkTim0io=VdKH3VuLGfeyJQU+RJU4OSkELnh4REcfT@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100826/5a433492/attachment.pl>

From r.turner at auckland.ac.nz  Thu Aug 26 02:28:02 2010
From: r.turner at auckland.ac.nz (Turner Rolf)
Date: Thu, 26 Aug 2010 12:28:02 +1200
Subject: [R-sig-Geo] Monte Carlo simulation and random habitat selection
In-Reply-To: <AANLkTim0io=VdKH3VuLGfeyJQU+RJU4OSkELnh4REcfT@mail.gmail.com>
References: <AANLkTim0io=VdKH3VuLGfeyJQU+RJU4OSkELnh4REcfT@mail.gmail.com>
Message-ID: <2FECBA36D6EF8645A9D736633F186F815EF87E6753@foedmail02n>



Elaine Kuo wrote:

Dear List,

I am trying to predict species distributions using MADIFA (Calenge et al.
2008).
However, the codes (Monte Carlo simulation) are not familiar to me,
and they seem unavailable in package adehabitat.
(similar to the response from the authors)

Please kindly help and thank you in advance.

Elaine

In this paper, it says that

1. At  each  step  of  the  process,  we  simulated  a
random  habitat  use  by  the  chamois  by  generating  a
uniform distribution of 400 points over the study area.

=> Please kindly suggest any code or package that can perform the
randomization.

     The runifpoint() function in the spatstat package will do this for you.

2.  We repeated this simulation
500 times to derive a distribution of eigenvalues under
the  hypothesis  of  random  habitat  use.

=> Please kindly suggest any code or package that can perform the
repetition.

     Just use  a for-loop!

     E.g.
     result <- numeric(500) 
     for(i in 1:500) {
           X <- runifpoint(500,win=W) # Where W is an object of class "owin" specifying the habitat area.
           <code from the adehabitat package>
           result[i] <- <largest eigenvalue of the MADIFA for X>
    }


3. We  finally
compared the first eigenvalue of the MADIFA of the
observed 400 chamois groups to this simulated distri-
bution to derive a P value.

=> Is this a chi-square test ? Or any other suitable tests ?

      No this is ***NOT*** a chi-squared test!  It is a Monte Carlo test!!!

      Compare the observed statistic with the simulated statistics.  The p-value is
      
      (1 + sum(result >= Stat))/501

      where "Stat" is the largest eignenvalue of the MADIFA for the real data set.

      Note that if you want a "nice round p-value" you should do 99 or 999 simulations
      rather than 500 such.  But this is a bit anal-compulsive!

      Note also that I have no idea what the adehabitat package does what "MADIFA"
      means, so I may have got the jargon a bit wrong in the foregoing --- but the general
      idea is there.

                cheers,

                      Rolf Turner
######################################################################
Attention: 
This e-mail message is privileged and confidential. If you are not the 
intended recipient please delete the message and notify the sender. 
Any views or opinions presented are solely those of the author.

This e-mail has been scanned and cleared by MailMarshal 
www.marshalsoftware.com
######################################################################


From koday at processtrends.com  Thu Aug 26 03:34:05 2010
From: koday at processtrends.com (dkod)
Date: Wed, 25 Aug 2010 18:34:05 -0700 (PDT)
Subject: [R-sig-Geo] SpatialGridDataFrame Help
Message-ID: <1282786446000-5463824.post@n2.nabble.com>


I am trying to develop simple tools to download and plot climate data based
on global grid of 2 degrees. Here's a link to the source image 
http://data.giss.nasa.gov/work/gistemp/NMAPS/tmp_GHCN_GISS_HR2SST_1200km_Anom07_2010_2010_1951_1980/GHCN_GISS_HR2SST_1200km_Anom07_2010_2010_1951_1980.gif
link 

NASA provides a 5 column text file for each image of monthly global
temperature anomalies. I have downloaded a sample data file that can be
viewed  http://processtrends.com/Files/global_lota_map_07_36.txt here .

I have been using Bivand et al's Applied Spatial Data Analysis With R to try
to speed up my learning curve, however, I am stumped and need some help.

Here's my script so far:

#################################################################
### Read GISS global temp anom for month by 2 degree grid
  library(fields);library(mapproj)
  library(sp); library(rgdal)

# Step 1: Read source data file
  link <- "http://processtrends.com/Files/global_lota_map_07_36.txt"
  rdf <- read.table(link, skip = 1, header=T)
  a_rdf <- data.frame(rdf[,c(1,2,5)])
  names(a_rdf) <- c("i", "j","anom")
  a_rdf$anom[a_rdf$anom==9999.0000] <- NA         # convert all 9999.0000 to
NA

## Step 2: Setup sp() classes for GridTopology & SpatialGrid 
  grd <- GridTopology(cellcentre.offset=c(-179,-89), cellsize=c(2,2), 
   cells.dim=c(180,90))
  gr_sp <- SpatialGrid(grid=grd, proj4string = CRS(as.character(NA)))
  a_rdf_sp <- SpatialGridDataFrame(grd, a_rdf)
 
## Step 4: Create SpatialGridDataFrame
  fullgrid(a_rdf_sp) <- T
  slot(a_rdf_sp, "grid")
 
## Step 5: Generate Plot
  image.plot(a_rdf_sp["anom"])
 
##############################################################

It runs without error mesages until the image.plot() command. here's the
error message I get

  > image.plot(a_rdf_sp["anom"])
     Error in if (del == 0 && to == 0) return(to) : 
     missing value where TRUE/FALSE needed
  > 

I'm not clear how to best establish a SpatialGridDataFrame for global data
series from 2 or 5 degree files. I'd like to be able to plot using mercator
or other projection.

I'd also like to be able to add land forms.

I'd appreciate any help in correcting/improving this script. My goal is a
clear, easy to follow R script that can be used by R users to download and
work with global climate data files from NASA, NOAA and other agencies.

D Kelly O'Day
http://chartsgraphs.wordpress.com
http://processtrends.com




-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/SpatialGridDataFrame-Help-tp5463824p5463824.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Adrian.Baddeley at csiro.au  Thu Aug 26 06:25:24 2010
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Thu, 26 Aug 2010 12:25:24 +0800
Subject: [R-sig-Geo] Function for subsampling spatial data
Message-ID: <4C75ECB4.60503@csiro.au>

Dear Anna

If I understand correctly, you want to select a subset of points in a 
point pattern so that the selected points are all separated from one 
another by a specified distance.

There could be more than one way to select such a subset. So this is not 
a well-defined task.

However here is one way to do it. In addition to the 'spatstat' package 
we need the package 'gcolor'. In the example I use the dataset 'redwood' 
for demonstration, and I chose the threshold distance to be 0.11 units.

       library(spatstat)
       library(gcolor)
       data(redwood)
       close <- (pairdist(redwood) <= 0.11)
       tag <- ineq(close)
       tag <- factor(tag)
       X <- redwood %mark% tag
       Y <- split(X)
       plot(Y)

On the fourth line, we use spatstat to calculate the distance between 
all pairs of points in the point pattern 'redwood', and then create a 
logical matrix 'close' whose entries are TRUE if the corresponding pair 
of points is closer than the threshold distance of 0.11 units.

Now imagine that we draw a straight line between each pair of points in 
the redwood pattern that lie closer than 0.11 units apart. Then we have 
a graph or network, and we want to select a subset of points so that any 
two points in the subset are not joined directly by a line. Well this 
would be equivalent to attaching a colour to each point in the redwood 
pattern, such that any two points that are joined by a line must have 
different colours. This can be accomplished by a 'graph colouring 
algorithm'. The package 'gcolor' provides this.

On the fifth line we use 'gcolor' to produce a colouring of the graph 
represented by the matrix 'close'.  The function 'ineq' computes a graph 
colouring. The result is a vector of integers representing the colours 
of each point. There are 7 colours.

In the subsequent lines we convert the integers to a factor, attach this 
to the redwood pattern as a mark, and then (as you guessed) use 
split.ppp to separate the differently coloured points.

In the split pattern Y, each component Y[[1]], Y[[2]] etc is a subset of 
the kind you were wanting. There are 7 components.

I hope this is what you were seeking

best wishes
Adrian Baddeley



On 24/08/10 20:52, Songhurst, Anna wrote:
> Dear Dr Baddeley and Dr Turner,
>
> I am a Ph.D. student at Imperial College London. I am looking for a
> function that subsamples spatial data such that points are beyond a
> specific distance apart (i.e. all points 1km away from each other; all
> points 3km away from each other etc.). Do you know if such a function
> already exists and if so where I might find it? I wondered if the
> split.ppp function could do this?
>
> Thank you and Kind Regards,
>
> Anna
>


From jonathan.bearak at nyu.edu  Thu Aug 26 08:31:19 2010
From: jonathan.bearak at nyu.edu (Jonathan Marc Bearak)
Date: Thu, 26 Aug 2010 02:31:19 -0400 (EDT)
Subject: [R-sig-Geo] Converting State Plane Coordinates
In-Reply-To: <4C740770.8000808@sauder.ubc.ca>
Message-ID: <bbbf4bed-8899-6f3e-c462-e1281b9946e4@me.com>

Hi,

Thanks for all the helpful comments I've received through this list.

Aside from solving the original issue, I've learned some incidentally useful things just by observing some of the code snippets.

As it turns out, I may have been calculating everything correctly -- but in a far less elegant way than by the methods suggested on this list, and I'm glad to know the proper way to handle this now regardless -- but making one fundamental error that hadn't occurred to me previously (as I'd thought it must have been my code, having no experience with GIS before now). ?I had been checking, as a test case, to see whether a school was in a school attendance area using its geocoded address. ?As I'm a Mac user, I quickly grabbed the test coordinates from geocoder.us, to avoid going back to the office, as all the GIS software seems to be Windows-based. ?However, the coordinates that site generates are not sufficiently accurate, unlike Google Maps or Mappoint.

Regarding the datum, yes, it's NAD83.

Thanks,
Jonathan
Jonathan Marc Bearak
PhD Candidate in Sociology
Institute of Education Sciences Predoctoral Fellow
New York University
jonathan.bearak at nyu.edu




On 24 Aug, 2010,at 01:54 PM, Dan Putler <dan.putler at sauder.ubc.ca> wrote:

Roger,

This won't really matter since they are very close, but given the data 
source and a North America based company, my guess is the underlying 
datum is NAD83.

Dan

On 08/24/2010 10:45 AM, Roger Bivand wrote:
> On Tue, 24 Aug 2010, Alexandre Villers wrote:
>
> 
>> Hey,
>>
>> There is an ESRI code (ESRI:102318
>> <http://spatialreference.org/ref/esri/102318/&gt;) corresponding to the
>> requested projection... However, I doubt CRS will take an ESRI code (Roger
>> ?).
>> 
> CRS("+init=esri:102318")
>
> but the ESRI version doesn't give a +datum=, so WGS84 will be assumed. The
> difference is the reversal of the +lat1= and +lat2= values, so probably
> not drastic.
>
> Roger
>
> 
>> Jonathan, have a look at the rgdal and sp packages help pages for the "How
>> To" in CRS()
>>
>> Best regards
>>
>> Alex
>>
>> Le 24/08/2010 17:58, Roger Bivand a ?crit :
>> 
>>> On Tue, 24 Aug 2010, Alexandre Villers wrote:
>>>
>>> 
>>>> Hello,
>>>>
>>>> Have a look at spTransform (in rgdal package) and the EPSG code of the
>>>> desired projection (this is to me the easiest way not to mess with digits
>>>> and various copy errors that can be made while writing the projection
>>>> properties) at www.spatialreference.org
>>>>
>>>> then, you just have to do something like this
>>>>
>>>> library(rgdal)
>>>>
>>>> data<-read.table ("mydata.txt", h=T, sep=",") #your original dataset
>>>> coordinates(data)<-~ X + Y # where X and Y stand for the name of your
>>>> lat/lon columns
>>>> proj4string(data)<-CRS("+init=epsg:4326") #if your coordinates are in
>>>> WGS84
>>>> data.proj<-spTransfrom(data,
>>>> CRS("+init=epsg:the.correct.epsg.number.of.your.projection")
>>>> 
>>> Looks like:
>>>
>>> http://spatialreference.org/ref/epsg/32118/
>>>
>>> but has some different parameters. Search on "New York" in this site for
>>> alternatives.
>>>
>>> Roger
>>>
>>> 
>>>> HTH
>>>>
>>>> Alex
>>>>
>>>>
>>>> Le 24/08/2010 16:51, Jonathan Marc Bearak a ?crit :
>>>> 
>>>>> Hi,
>>>>>
>>>>> I'm new to GIS and have been trying to convert latitude and longitude
>>>>> to/from state plane coordinates.
>>>>>
>>>>> I've tried using the project() program from the proj4 library to convert
>>>>> lat/lng to FIPS 3104 (New York State Long Island).
>>>>>
>>>>> No matter how I go about this, however, the coordinates come out wrong.
>>>>> E.g.,
>>>>> "+proj=lcc +lat_1=40.66666666666666
>>>>> +lat_2=41.03333333333333 +lat_0=40.16666666666666 +lon_0=-74 +x_0=300000
>>>>> +y_0=0 +units=ft +no_defs +datum=NAD83",
>>>>> "+proj=lcc +a=6378137 +es=.0066943800229 +lon_0=-74
>>>>> +lat_1=41d2 +lat_2=40d40 +lat_0=40d10 +x_0=300000 +y_0=0 +units=ft
>>>>> +no_defs +datum=NAD83",
>>>>>
>>>>> E.g., if I try the inverse, to convert 1062791, 209606.6 to lat/lng,
>>>>> project() prints: 43.04762 -76.89626. The correct coordinates, however,
>>>>> are: 40.7416495 -073.7165681.
>>>>>
>>>>> I've been reading the mailing lists and searching Google and R project
>>>>> PDFs and manual pages without any luck for an embarrassingly long number
>>>>> of hours without any luck.
>>>>>
>>>>> Thanks for any help.
>>>>>
>>>>> Best,
>>>>> Jonathan
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>> 
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>> 
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> 
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100826/6a517ad0/attachment.html>

From Roger.Bivand at nhh.no  Thu Aug 26 08:43:35 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 08:43:35 +0200 (CEST)
Subject: [R-sig-Geo] SpatialGridDataFrame Help
In-Reply-To: <1282786446000-5463824.post@n2.nabble.com>
References: <1282786446000-5463824.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008260817080.5792@reclus.nhh.no>

On Wed, 25 Aug 2010, dkod wrote:

>
> I am trying to develop simple tools to download and plot climate data based
> on global grid of 2 degrees. Here's a link to the source image
> http://data.giss.nasa.gov/work/gistemp/NMAPS/tmp_GHCN_GISS_HR2SST_1200km_Anom07_2010_2010_1951_1980/GHCN_GISS_HR2SST_1200km_Anom07_2010_2010_1951_1980.gif
> link
>
> NASA provides a 5 column text file for each image of monthly global
> temperature anomalies. I have downloaded a sample data file that can be
> viewed  http://processtrends.com/Files/global_lota_map_07_36.txt here .
>
> I have been using Bivand et al's Applied Spatial Data Analysis With R to try
> to speed up my learning curve, however, I am stumped and need some help.
>
> Here's my script so far:
>
> #################################################################
> ### Read GISS global temp anom for month by 2 degree grid
>  library(fields);library(mapproj)
>  library(sp); library(rgdal)
>
> # Step 1: Read source data file
>  link <- "http://processtrends.com/Files/global_lota_map_07_36.txt"
>  rdf <- read.table(link, skip = 1, header=T)
>  a_rdf <- data.frame(rdf[,c(1,2,5)])
>  names(a_rdf) <- c("i", "j","anom")
>  a_rdf$anom[a_rdf$anom==9999.0000] <- NA         # convert all 9999.0000 to
> NA
>
> ## Step 2: Setup sp() classes for GridTopology & SpatialGrid
>  grd <- GridTopology(cellcentre.offset=c(-179,-89), cellsize=c(2,2),
>   cells.dim=c(180,90))
>  gr_sp <- SpatialGrid(grid=grd, proj4string = CRS(as.character(NA)))
>  a_rdf_sp <- SpatialGridDataFrame(grd, a_rdf)
>
> ## Step 4: Create SpatialGridDataFrame
>  fullgrid(a_rdf_sp) <- T
>  slot(a_rdf_sp, "grid")
>
> ## Step 5: Generate Plot
>  image.plot(a_rdf_sp["anom"])
>
> ##############################################################
>
> It runs without error mesages until the image.plot() command. here's the
> error message I get
>
>  > image.plot(a_rdf_sp["anom"])
>     Error in if (del == 0 && to == 0) return(to) :
>     missing value where TRUE/FALSE needed
>  >

Well, either use the image() method in sp for this class of object, since 
you have taken trouble to create it, or coerce the object to the input 
required by image.plot() in the fields package:

library(sp)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
gridded(meuse.grid) <- TRUE
fullgrid(meuse.grid) <- TRUE
mg1 <- as.image.SpatialGridDataFrame(meuse.grid["dist"])
library(fields)
image.plot(mg1)

This has relevance for another current thread on conversion between 
classes. If package authors and maintainers do not wish to provide 
coercion to or from sp, it would not be in the spirit of the R project to 
jump in boots first. Documentation of possible routes is of essence here, 
and could happily be done on the R Wiki site under spatial data - for 
instance, an interested person could post the code above as an answer to 
the sp -> fields question for this class and that function. Agreed, the 
routes that exist could also be made a little more consistent, but since 
not all the targets for conversion are S3 or S4 classes ("image" is not a 
class, the output is a list with x, y, z components), it is hard to 
find a consistent definition of consistent!

The relationship between spatstat and sp can serve as an example of how to 
handle things pragmatically and with respect for the value of different 
ways to represent data; coercion methods have been added as needed to 
maptools, and work satisfactorily.

Data representations do differ, and there are often good, substantive 
reasons for the differences, based on different literatures in different 
disciplines or traditions. Giving users the impression that this is not 
the case blinds them to the potential misconceptions involved (in 
GIScience - ontological mismatch). So exposing users to the discomfort of 
having to think through which representations may differ does have a real 
motivation - say in drilling down to say matrix <-> graph representations, 
as in Adrian Baddeley's post this morning, where thinking through 
representations yielded fruitful insights.

Roger

>
> I'm not clear how to best establish a SpatialGridDataFrame for global data
> series from 2 or 5 degree files. I'd like to be able to plot using mercator
> or other projection.
>
> I'd also like to be able to add land forms.
>
> I'd appreciate any help in correcting/improving this script. My goal is a
> clear, easy to follow R script that can be used by R users to download and
> work with global climate data files from NASA, NOAA and other agencies.
>
> D Kelly O'Day
> http://chartsgraphs.wordpress.com
> http://processtrends.com
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From dorothea.lemke at uni-muenster.de  Thu Aug 26 09:33:52 2010
From: dorothea.lemke at uni-muenster.de (Dorothea Lemke)
Date: Thu, 26 Aug 2010 09:33:52 +0200 (CEST)
Subject: [R-sig-Geo] Plotting SpatialPixelDataFrame
Message-ID: <permail-20100826073352f7e55a9d000065b2-dlemk_01@message-id.uni-muenster.de>

Dear list,

I've a problem with plotting a numeric object in a SpatialPixelsDataFrame.
I've done 2 Kerneldensity estimations with the package splancs and I've
calculated the relative risk by taking the ratio of this two intensities. When
I use the spplot() function I get one window with 3 graphics on the same
scale. But I want to plot the graphics with seperate scales. How can I do
this?

My Rcode is:

  > kcasesC67m<-spkernel2d(cases, pRBMS, h0=3500, gt)
  > kcontrolsC67m<-spkernel2d (controls, pRBMS, h0=3500, gt)
  > df0<-data.frame (kcasesC67m = kcasesC67m, kcontrolsC67m = kcontrolsC67m)
  > spkratio0<-SpatialGridDataFrame (gt,  data = df0)
  > spkratio<-as(spkratio0, "SpatialPixelsDataFrame")
  > spkratio$kratio<-spkratio$kcasesC67m/spkratio$kcontrolsC67m
  > is.na(spkratio$kratio)<-!is.finite(spkratio$kratio)

Many thanks for your help

Dorothea


From Roger.Bivand at nhh.no  Thu Aug 26 10:00:34 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 10:00:34 +0200 (CEST)
Subject: [R-sig-Geo] Plotting SpatialPixelDataFrame
In-Reply-To: <permail-20100826073352f7e55a9d000065b2-dlemk_01@message-id.uni-muenster.de>
References: <permail-20100826073352f7e55a9d000065b2-dlemk_01@message-id.uni-muenster.de>
Message-ID: <alpine.LRH.2.00.1008260958430.6290@reclus.nhh.no>

On Thu, 26 Aug 2010, Dorothea Lemke wrote:

> Dear list,
>
> I've a problem with plotting a numeric object in a SpatialPixelsDataFrame.
> I've done 2 Kerneldensity estimations with the package splancs and I've
> calculated the relative risk by taking the ratio of this two intensities. When
> I use the spplot() function I get one window with 3 graphics on the same
> scale. But I want to plot the graphics with seperate scales. How can I do
> this?

Save the three output objects of spplot, then see:

library(lattice)
?plot.trellis

especially the more= and split= arguments.

Hope this helps,

Roger

>
> My Rcode is:
>
>  > kcasesC67m<-spkernel2d(cases, pRBMS, h0=3500, gt)
>  > kcontrolsC67m<-spkernel2d (controls, pRBMS, h0=3500, gt)
>  > df0<-data.frame (kcasesC67m = kcasesC67m, kcontrolsC67m = kcontrolsC67m)
>  > spkratio0<-SpatialGridDataFrame (gt,  data = df0)
>  > spkratio<-as(spkratio0, "SpatialPixelsDataFrame")
>  > spkratio$kratio<-spkratio$kcasesC67m/spkratio$kcontrolsC67m
>  > is.na(spkratio$kratio)<-!is.finite(spkratio$kratio)
>
> Many thanks for your help
>
> Dorothea
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Adrian.Baddeley at csiro.au  Thu Aug 26 10:17:58 2010
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Thu, 26 Aug 2010 16:17:58 +0800
Subject: [R-sig-Geo] Temporal marked point process with time-varying
	covariates
In-Reply-To: <001401cb3e12$ab6ea640$024bf2c0$@kauffmann@jrc.ec.europa.eu>
References: <001401cb3e12$ab6ea640$024bf2c0$@kauffmann@jrc.ec.europa.eu>
Message-ID: <57DC18C299094D4299F837570C5DF1C52B1F575369@EXWA-MBX01.nexus.csiro.au>

Mayeul KAUFFMANN wrote:
 
> I am trying to model a temporal marked point process with time-varying
> covariates and I am looking for the most appropriate function among several
> ones. [ ...] I had a look at the following packages 
>    spatstat
>    splancs
>    PtProcess
> spatstat seems to have the correct object to handle my dependant variables (the
> ppx class: 2D space + time) but if I'm correct the ppm() model fitting function
> cannot handle this (it only works with ppp). Am I missing something? I saw at
> http://www.spatstat.org/  that this branch is in development. Any news /
> schedule on that?

Yes, the class 'ppx' in spatstat will support space-time point pattern data with any number of space and time dimensions. 

Currently the model-fitting function will only handle two-dimensional point patterns (class 'ppp'). However ppm will soon be able to handle ppx objects. We have code, but it is not ready for release yet. 

Due to some bad experiences in the past, I am reluctant to release spatstat code that involves original research until the research papers have been published. 

Just to clarify something: 'spatstat' is **not** committed to a particular definition of the conditional intensity. If the points are in time or space-time, where time is one-dimensional, then the natural definition of the conditional intensity is one which looks at the 'past'. However if the points are in m-dimensional Euclidean space, then the most appropriate definition of the conditional intensity is something different (usually the Papangelou conditional intensity). In spatstat, the type of conditional intensity is determined by the 'interaction' argument to ppm (or actually by 'interaction$family'), and thus can be different from model to model. Currently ppm deals with two-dimensional point patterns and the interactions mostly use the Papangelou conditional intensity, but the package design does not make any such assumptions. [We also have code for fitting models that use the directed conditional intensity in two-dimensional time, and this will be released shortly.]

Adrian Baddeley


From gianni.lavaredo at gmail.com  Thu Aug 26 14:29:42 2010
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Thu, 26 Aug 2010 14:29:42 +0200
Subject: [R-sig-Geo] Help to know Swedish projection (proj4string(myfile) <-
	CRS(""))
Message-ID: <AANLkTinLmdssRWwir7SYx-KRMwKfK=sCLvSXuAVzWdCJ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100826/284452ae/attachment.pl>

From bart at njn.nl  Thu Aug 26 14:45:00 2010
From: bart at njn.nl (bart)
Date: Thu, 26 Aug 2010 14:45:00 +0200
Subject: [R-sig-Geo] Help to know Swedish projection
 (proj4string(myfile) <-	CRS(""))
In-Reply-To: <AANLkTinLmdssRWwir7SYx-KRMwKfK=sCLvSXuAVzWdCJ@mail.gmail.com>
References: <AANLkTinLmdssRWwir7SYx-KRMwKfK=sCLvSXuAVzWdCJ@mail.gmail.com>
Message-ID: <4C7661CC.4060505@njn.nl>

Seems there are rather a lot of varieties on these systems

http://spatialreference.org/ref/?search=RT90

If you find the right one there click on the proj4 there is the right 
string if i'm not mistaken
http://spatialreference.org/ref/epsg/3022/proj4/

maybe the epsg code it self can be used as well if i read the CRS help

On 08/26/2010 02:29 PM, gianni lavaredo wrote:
> Dear Resercher,
>
> i am working on data from Sweden in RT 90 system and SWEREF 99 (TM) system.
> I wish to use the proj4string but I can not find the right CRS. Thanks for
> helping me and suggestion website to have a list
>
> Gianni
>
> proj4string(mydata)<- CRS("?????")
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From Roger.Bivand at nhh.no  Thu Aug 26 14:47:23 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 14:47:23 +0200 (CEST)
Subject: [R-sig-Geo] Help to know Swedish projection
 (proj4string(myfile) <- CRS(""))
In-Reply-To: <AANLkTinLmdssRWwir7SYx-KRMwKfK=sCLvSXuAVzWdCJ@mail.gmail.com>
References: <AANLkTinLmdssRWwir7SYx-KRMwKfK=sCLvSXuAVzWdCJ@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008261436480.9223@reclus.nhh.no>

On Thu, 26 Aug 2010, gianni lavaredo wrote:

> Dear Resercher,
>
> i am working on data from Sweden in RT 90 system and SWEREF 99 (TM) system.
> I wish to use the proj4string but I can not find the right CRS. Thanks for
> helping me and suggestion website to have a list

Google "RT 90 system and SWEREF 99 (TM)" gives you:

http://www.lantmateriet.se/upload/filer/kartor/geodesi_gps_och_detaljmatning/Referenssystem/Oversikt_eng.pdf

See also:

http://spatialreference.org/ref/epsg/3006/

and search output for RT90 and SWEREF99. Grids & Datums (August 2004):

http://www.asprs.org/resources/GRIDS/

for suggestions for a +towgs84= parameter set to do datum transformation.

Almost always http://spatialreference.org and Grids & Datums (if available 
for the country of interest) yield useful results.

Roger

PS. It is always useful to verify the correctness of CRS definitions by 
transforming to geographical coordinates in WGS84 datum and overlaying a 
display on a known map, shuch as Google Earth.

>
> Gianni
>
> proj4string(mydata) <- CRS("?????")
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From sven at cancer.dk  Thu Aug 26 14:50:09 2010
From: sven at cancer.dk (Sven Schmiedel)
Date: Thu, 26 Aug 2010 14:50:09 +0200
Subject: [R-sig-Geo] splitting a map into areas by number of addresses
Message-ID: <2e7e124c00010d59@cancer.dk>

Dear list,

I have the following problem: I have around 1,000,000 addresses of a country and want now to split the area in artificial "administrative units" with exactly 1,000 addresses per unit.

As I did not find a direct way to do this, my idea was to chose randomly 1,000 addresses, use the voronoi tessellation (from library PBSmapping) for these and look how many addresses are found in each piece this mosaic. However, the result is not stable and the number of addresses varies quite a lot from unit to unit.

Hence, I would like to know if there is a procedure/package that is incorporating a function that is able to do this splitting with a fixed number of addresses. If anyone has another program or an methodological approach to this problem I would be happy about this information.

Best wishes,

Sven Schmiedel
______________

PhD student, MSE in Epidemiology
Institute of Cancer Epidemiology
Danish Cancer Society
Copenhagen,
Denmark


From koday at processtrends.com  Thu Aug 26 14:54:45 2010
From: koday at processtrends.com (dkod)
Date: Thu, 26 Aug 2010 05:54:45 -0700 (PDT)
Subject: [R-sig-Geo] SpatialGridDataFrame Help
In-Reply-To: <1282786446000-5463824.post@n2.nabble.com>
References: <1282786446000-5463824.post@n2.nabble.com>
Message-ID: <1282827285979-5465477.post@n2.nabble.com>


Roger

Thank you for your quick and helpful response.

I now have image/plot() working. I need some help in how to go from
rectangular grid representation to a mercator (or other) projection. Since
my source grid is 2 degree long/lat based, I'd like to use a projection. 


How do I get a proper projection? Here's the line I used:

 gr_sp <- SpatialGrid(grid=grd, proj4string = CRS(as.character(NA))) 

Sorry for such a basic question. 


-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/SpatialGridDataFrame-Help-tp5463824p5465477.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From roman.lustrik at gmail.com  Thu Aug 26 15:03:34 2010
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Thu, 26 Aug 2010 15:03:34 +0200
Subject: [R-sig-Geo] scoping issue with xyValues?
Message-ID: <AANLkTinSCO4iRqVdt8gi1iF7PDmWT9+5KiUsnFS1b4cG@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100826/b7779fa9/attachment.pl>

From Roger.Bivand at nhh.no  Thu Aug 26 15:07:30 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 15:07:30 +0200 (CEST)
Subject: [R-sig-Geo] SpatialGridDataFrame Help
In-Reply-To: <1282827285979-5465477.post@n2.nabble.com>
References: <1282786446000-5463824.post@n2.nabble.com>
	<1282827285979-5465477.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008261503200.9223@reclus.nhh.no>

On Thu, 26 Aug 2010, dkod wrote:

>
> Roger
>
> Thank you for your quick and helpful response.
>
> I now have image/plot() working. I need some help in how to go from
> rectangular grid representation to a mercator (or other) projection. Since
> my source grid is 2 degree long/lat based, I'd like to use a projection.
>
>
> How do I get a proper projection? Here's the line I used:
>
> gr_sp <- SpatialGrid(grid=grd, proj4string = CRS(as.character(NA)))

No, much more work needed. If the input is in decimal degrees, 
geographical coordinates, and a known datum, you must warp (interpolate) 
to a planar projection. You might do this by projecting the input as a 
SpatialPointsDataFrame from +proj=longlat and known +datum to your target 
projection, then interpolate using your chosen interpolator to a grid 
defined in the target projection. A grid in geographical coordinates will 
effectively never be a grid in projected coordinates.

Roger

>
> Sorry for such a basic question.
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From jamesbond6 at gmail.com  Thu Aug 26 15:38:26 2010
From: jamesbond6 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Kwieci=F1ski?=)
Date: Thu, 26 Aug 2010 15:38:26 +0200
Subject: [R-sig-Geo] problem with edit.nb
Message-ID: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>

Hi all,

I am just about to finish my thesis. The spatial model I want to use
there is an extension of some work I did back in April. I used R 2.9.2
then and in order to include 3 additional administrative areas for
Poland, I edited the shp files (the borders aren't perfectly aligned).
Then in R I created the nb class object and edited it with edit.nb
adding three new connections. Everything worked perfect, I had no
regions with no links and I generated weight matrices with no
problems.

However, I'd been doing exactly the same thing entire night in R 2.11
and it did not work (I use the same code I did 4 months ago) and I
have no idea what is the reason for it. I've been looking for some
other way to do it, I tried nb2mat and editing the matrix, but I
surrendered having no idea where and what values I should use.

Before editing nb object R claims that regions 377 and 378 have no
links. However in edit.nb the 378 and 379 are visible as having no
links (378 and 379 are cities added on top of bigger shapes, whereas
377 was just split from a bigger shape into two smaller ones and only
the link between these two parts is missing). I connect the circles,
quit and in the new object there are some new links - the overall
number has increased - but 377 and 378 are still listed as having no
links. Editing nb again shows the links, so they have been saved for
sure.

I am not an advanced R user and most of my code was based on my
professor's book. However, I think I have spent enough time with
spatial models and those matrices in order to call this problem really
weird. Especially since it worked perfectly last time...

I can attach shp files and my code if it will be of any help in order
to properly investigate this problem. I would really appreciate some
help, I need to finish the project over the weekend.

Thanks in advance, best regards,
Michal Kwiecinski
University of Warsaw student


From nikhil.list at gmail.com  Thu Aug 26 16:07:34 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Thu, 26 Aug 2010 10:07:34 -0400
Subject: [R-sig-Geo] splitting a map into areas by number of addresses
In-Reply-To: <2e7e124c00010d59@cancer.dk>
References: <2e7e124c00010d59@cancer.dk>
Message-ID: <785FF814-B442-4269-8588-2A8F868A57A4@gmail.com>

Look at

knearneigh in spdep

Once you figured out the neighbours, you may be able to an algorithm  
to efficiently partition the dataset.


Nikhil Kaza
Asst. Professor,
City and Regional Planning
University of North Carolina

nikhil.list at gmail.com

On Aug 26, 2010, at 8:50 AM, Sven Schmiedel wrote:

> Dear list,
>
> I have the following problem: I have around 1,000,000 addresses of a  
> country and want now to split the area in artificial "administrative  
> units" with exactly 1,000 addresses per unit.
>
> As I did not find a direct way to do this, my idea was to chose  
> randomly 1,000 addresses, use the voronoi tessellation (from library  
> PBSmapping) for these and look how many addresses are found in each  
> piece this mosaic. However, the result is not stable and the number  
> of addresses varies quite a lot from unit to unit.
>
> Hence, I would like to know if there is a procedure/package that is  
> incorporating a function that is able to do this splitting with a  
> fixed number of addresses. If anyone has another program or an  
> methodological approach to this problem I would be happy about this  
> information.
>
> Best wishes,
>
> Sven Schmiedel
> ______________
>
> PhD student, MSE in Epidemiology
> Institute of Cancer Epidemiology
> Danish Cancer Society
> Copenhagen,
> Denmark
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Aug 26 16:13:07 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 16:13:07 +0200 (CEST)
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>

On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:

> Hi all,
>
> I am just about to finish my thesis. The spatial model I want to use
> there is an extension of some work I did back in April. I used R 2.9.2
> then and in order to include 3 additional administrative areas for
> Poland, I edited the shp files (the borders aren't perfectly aligned).
> Then in R I created the nb class object and edited it with edit.nb
> adding three new connections. Everything worked perfect, I had no
> regions with no links and I generated weight matrices with no
> problems.
>
> However, I'd been doing exactly the same thing entire night in R 2.11
> and it did not work (I use the same code I did 4 months ago) and I
> have no idea what is the reason for it. I've been looking for some
> other way to do it, I tried nb2mat and editing the matrix, but I
> surrendered having no idea where and what values I should use.
>
> Before editing nb object R claims that regions 377 and 378 have no
> links. However in edit.nb the 378 and 379 are visible as having no
> links (378 and 379 are cities added on top of bigger shapes, whereas
> 377 was just split from a bigger shape into two smaller ones and only
> the link between these two parts is missing). I connect the circles,
> quit and in the new object there are some new links - the overall
> number has increased - but 377 and 378 are still listed as having no
> links. Editing nb again shows the links, so they have been saved for
> sure.
>
> I am not an advanced R user and most of my code was based on my
> professor's book. However, I think I have spent enough time with
> spatial models and those matrices in order to call this problem really
> weird. Especially since it worked perfectly last time...
>
> I can attach shp files and my code if it will be of any help in order
> to properly investigate this problem. I would really appreciate some
> help, I need to finish the project over the weekend.

Maybe you are using the wrong indices, as FIDs are 0-base but nb objects 
are 1-base. So you may be editing the wrong ones. If this doesn't resolve 
the problem, zip the shapefile and post a link to it, don't attach the 
shapefile, as it would be sent to 1700 people.

Hope this helps,

Roger

>
> Thanks in advance, best regards,
> Michal Kwiecinski
> University of Warsaw student
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From b.rowlingson at lancaster.ac.uk  Thu Aug 26 16:23:02 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 26 Aug 2010 15:23:02 +0100
Subject: [R-sig-Geo] splitting a map into areas by number of addresses
In-Reply-To: <2e7e124c00010d59@cancer.dk>
References: <2e7e124c00010d59@cancer.dk>
Message-ID: <AANLkTikZXTve_Bj+Vi=ZrOZoxRqQkyxVqUwP24T8joh6@mail.gmail.com>

On Thu, Aug 26, 2010 at 1:50 PM, Sven Schmiedel <sven at cancer.dk> wrote:
> Dear list,
>
> I have the following problem: I have around 1,000,000 addresses of a country and want now to split the area in artificial "administrative units" with exactly 1,000 addresses per unit.
>
> As I did not find a direct way to do this, my idea was to chose randomly 1,000 addresses, use the voronoi tessellation (from library PBSmapping) for these and look how many addresses are found in each piece this mosaic. However, the result is not stable and the number of addresses varies quite a lot from unit to unit.
>
> Hence, I would like to know if there is a procedure/package that is incorporating a function that is able to do this splitting with a fixed number of addresses. If anyone has another program or an methodological approach to this problem I would be happy about this information.

 Hmmm as stated this doesn't look particularly well-defined.

 Do the administrative units have to be compact and connected? If not,
then just do sample(1000,1000000,TRUE) and job done.

 Do you have point locations for each address, or areas? You didn't say.

 With point locations you could do the voronoi tesselation of all
1000000 and then take the graph and partition it into 1000 connected
sub-graphs [waves hands] somehow. That would ensure all addresses in
an admin unit were neighbours, but you could have an admin unit that
was a linear feature of addresses.

 I can think of various heuristics for making more compact sets, which
involve growing units by adding the next nearest address that
minimizes the 'spread', possibly by adding the next unit as the one
nearest the centroid of the current unit. You might want to grow all
1000 simultaneously from 1000 seeds (spread across the area) or grow
one to full size, and then another, but that might form lots of
'islands' of less than 1000 addresses that would be impossible to form
into admin units.

Barry


From mayeul.kauffmann at jrc.ec.europa.eu  Thu Aug 26 17:47:46 2010
From: mayeul.kauffmann at jrc.ec.europa.eu (Mayeul KAUFFMANN)
Date: Thu, 26 Aug 2010 17:47:46 +0200
Subject: [R-sig-Geo] Temporal marked point process with time-varying
	covariates
In-Reply-To: <57DC18C299094D4299F837570C5DF1C52B1F575369@EXWA-MBX01.nexus.csiro.au>
References: <001401cb3e12$ab6ea640$024bf2c0$@kauffmann@jrc.ec.europa.eu>
	<57DC18C299094D4299F837570C5DF1C52B1F575369@EXWA-MBX01.nexus.csiro.au>
Message-ID: <000d01cb4536$07dbb1a0$179314e0$@kauffmann@jrc.ec.europa.eu>

Thanks a lot!
The authors of the RLadyBug package are also about to release functions to
estimate a temporal marked point process with time-varying covariates and both
time and space correlation (probably in a few weeks).
They informed me by private e-mail but stated they were not opposed to my
putting this piece of information here.
Best regards,
Mayeul

_____________________________________________________
Dr. Mayeul KAUFFMANN, Conflict Specialist
European Commission, Joint Research Centre (JRC)
Institute for the Protection and Security of the Citizen (IPSC)
Global Security and Crisis Management - ISFEREA
Via E. Fermi 2749 - I-21027 Ispra (VA), ITALY
Phone: (+39) 033278 5071
http://isferea.jrc.ec.europa.eu/Staff/Pages/Kauffmann-Mayeul.aspx

(Office: building 48c, 1st floor, room 123. TP: 483)

-----Original Message-----
From: Adrian.Baddeley at csiro.au [mailto:Adrian.Baddeley at csiro.au] 
Sent: Thursday, August 26, 2010 10:18 AM
To: mayeul.kauffmann at jrc.ec.europa.eu; r-sig-geo at stat.math.ethz.ch
Subject: RE: Temporal marked point process with time-varying covariates

Mayeul KAUFFMANN wrote:
 
> I am trying to model a temporal marked point process with time-varying
> covariates and I am looking for the most appropriate function among several
> ones. [ ...] I had a look at the following packages 
>    spatstat
>    splancs
>    PtProcess
> spatstat seems to have the correct object to handle my dependant variables
(the
> ppx class: 2D space + time) but if I'm correct the ppm() model fitting
function
> cannot handle this (it only works with ppp). Am I missing something? I saw at
> http://www.spatstat.org/  that this branch is in development. Any news /
> schedule on that?

Yes, the class 'ppx' in spatstat will support space-time point pattern data with
any number of space and time dimensions. 

Currently the model-fitting function will only handle two-dimensional point
patterns (class 'ppp'). However ppm will soon be able to handle ppx objects. We
have code, but it is not ready for release yet. 

Due to some bad experiences in the past, I am reluctant to release spatstat code
that involves original research until the research papers have been published. 

Just to clarify something: 'spatstat' is **not** committed to a particular
definition of the conditional intensity. If the points are in time or
space-time, where time is one-dimensional, then the natural definition of the
conditional intensity is one which looks at the 'past'. However if the points
are in m-dimensional Euclidean space, then the most appropriate definition of
the conditional intensity is something different (usually the Papangelou
conditional intensity). In spatstat, the type of conditional intensity is
determined by the 'interaction' argument to ppm (or actually by
'interaction$family'), and thus can be different from model to model. Currently
ppm deals with two-dimensional point patterns and the interactions mostly use
the Papangelou conditional intensity, but the package design does not make any
such assumptions. [We also have code for fitting models that use the directed
conditional intensity in two-dimensional time, and this will be released
shortly.]

Adrian Baddeley


From r.hijmans at gmail.com  Thu Aug 26 19:04:06 2010
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 26 Aug 2010 10:04:06 -0700
Subject: [R-sig-Geo] scoping issue with xyValues?
In-Reply-To: <AANLkTinSCO4iRqVdt8gi1iF7PDmWT9+5KiUsnFS1b4cG@mail.gmail.com>
References: <AANLkTinSCO4iRqVdt8gi1iF7PDmWT9+5KiUsnFS1b4cG@mail.gmail.com>
Message-ID: <AANLkTi==1dzvraWbrNH=AWEU_Fdy13StHn80O_34sQyN@mail.gmail.com>

Hi Roman,

> I noticed that in xyValues.R there is no method for
> signature(object="RasterLayer",
> xy="vector"). Could this be a problem?

There is a signature(object="Raster", xy="vector"), and RasterLayer
inherits from Raster. However, that function does not have a 'buffer'
argument (an oversight, perhaps). I believe that is what causes your
grief (I need to look into this more carefully). You can probably fix
this by using the "..." argument in your function declaration; as
these will be passed on. At least in the example below test1, using
the dots, works, while test2 does not.

library(raster)
test1 = function(r, xy, ...) {  return( xyValues(r, xy, ...) ) }
test2 = function(r, xy, buffer, fun) { return( xyValues(r, xy,
buffer=buffer, fun=fun) )}

r = raster()
r[] = 1:ncell(r)
xy = c(0,0)

xyValues(r, c(0,0), buffer=100000, fun=mean)
test1(r, c(0,0), buffer=100000, fun=mean)
test2(r, c(0,0), buffer=100000, fun=mean)

Best, Robert

On Thu, Aug 26, 2010 at 6:03 AM, Roman Lu?trik <roman.lustrik at gmail.com> wrote:
> I have a function (that is within a function and everything wrapped in a
> wrapper function) that uses raster::xyValues. When I run the wrapper
> function and try to pass xy arguments as a vector (of 2, as mentioned in the
> documentation), I get an error that the buffer argument (I call it
> effect.distance) doesn't exist. At this point I should note that the object
> is a RasterLayer. After some debugging I found that argument for buffer was
> not being passed to xyValues local environment (unlike arguments for
> objectand xy that had no trouble traversing).
>
> How I made this work:
> Either I created an effect.distance variable in the global environment or
> coerced the vector of two to a matrix (with two columns).
>
> I noticed that in xyValues.R there is no method for
> signature(object="RasterLayer",
> xy="vector"). Could this be a problem?
>
>
> Cheers,
> Roman
>
>
>
>
> --
> In God we trust, all others bring data.
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jamesbond6 at gmail.com  Thu Aug 26 19:47:06 2010
From: jamesbond6 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Kwieci=F1ski?=)
Date: Thu, 26 Aug 2010 19:47:06 +0200
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
Message-ID: <AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>

2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>
>> Hi all,
>>
>> I am just about to finish my thesis. The spatial model I want to use
>> there is an extension of some work I did back in April. I used R 2.9.2
>> then and in order to include 3 additional administrative areas for
>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>> Then in R I created the nb class object and edited it with edit.nb
>> adding three new connections. Everything worked perfect, I had no
>> regions with no links and I generated weight matrices with no
>> problems.
>>
>> However, I'd been doing exactly the same thing entire night in R 2.11
>> and it did not work (I use the same code I did 4 months ago) and I
>> have no idea what is the reason for it. I've been looking for some
>> other way to do it, I tried nb2mat and editing the matrix, but I
>> surrendered having no idea where and what values I should use.
>>
>> Before editing nb object R claims that regions 377 and 378 have no
>> links. However in edit.nb the 378 and 379 are visible as having no
>> links (378 and 379 are cities added on top of bigger shapes, whereas
>> 377 was just split from a bigger shape into two smaller ones and only
>> the link between these two parts is missing). I connect the circles,
>> quit and in the new object there are some new links - the overall
>> number has increased - but 377 and 378 are still listed as having no
>> links. Editing nb again shows the links, so they have been saved for
>> sure.
>>
>> I am not an advanced R user and most of my code was based on my
>> professor's book. However, I think I have spent enough time with
>> spatial models and those matrices in order to call this problem really
>> weird. Especially since it worked perfectly last time...
>>
>> I can attach shp files and my code if it will be of any help in order
>> to properly investigate this problem. I would really appreciate some
>> help, I need to finish the project over the weekend.
>
> Maybe you are using the wrong indices, as FIDs are 0-base but nb objects are
> 1-base. So you may be editing the wrong ones. If this doesn't resolve the
> problem, zip the shapefile and post a link to it, don't attach the
> shapefile, as it would be sent to 1700 people.


I must admit I did not understand your hint (I do not know what "base"
is, assuming FID is Field ID - header in shp file). How is it possible
I edited some other layer of information by function edit.nb? Could
you please clarify what should I do to check it?

Thank you for prompt reply,
Michal


From Roger.Bivand at nhh.no  Thu Aug 26 20:01:55 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 20:01:55 +0200 (CEST)
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
	<AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>

On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:

> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>
>>> Hi all,
>>>
>>> I am just about to finish my thesis. The spatial model I want to use
>>> there is an extension of some work I did back in April. I used R 2.9.2
>>> then and in order to include 3 additional administrative areas for
>>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>>> Then in R I created the nb class object and edited it with edit.nb
>>> adding three new connections. Everything worked perfect, I had no
>>> regions with no links and I generated weight matrices with no
>>> problems.
>>>
>>> However, I'd been doing exactly the same thing entire night in R 2.11
>>> and it did not work (I use the same code I did 4 months ago) and I
>>> have no idea what is the reason for it. I've been looking for some
>>> other way to do it, I tried nb2mat and editing the matrix, but I
>>> surrendered having no idea where and what values I should use.
>>>
>>> Before editing nb object R claims that regions 377 and 378 have no
>>> links. However in edit.nb the 378 and 379 are visible as having no
>>> links (378 and 379 are cities added on top of bigger shapes, whereas
>>> 377 was just split from a bigger shape into two smaller ones and only
>>> the link between these two parts is missing). I connect the circles,
>>> quit and in the new object there are some new links - the overall
>>> number has increased - but 377 and 378 are still listed as having no
>>> links. Editing nb again shows the links, so they have been saved for
>>> sure.
>>>
>>> I am not an advanced R user and most of my code was based on my
>>> professor's book. However, I think I have spent enough time with
>>> spatial models and those matrices in order to call this problem really
>>> weird. Especially since it worked perfectly last time...
>>>
>>> I can attach shp files and my code if it will be of any help in order
>>> to properly investigate this problem. I would really appreciate some
>>> help, I need to finish the project over the weekend.
>>
>> Maybe you are using the wrong indices, as FIDs are 0-base but nb objects are
>> 1-base. So you may be editing the wrong ones. If this doesn't resolve the
>> problem, zip the shapefile and post a link to it, don't attach the
>> shapefile, as it would be sent to 1700 people.
>
>
> I must admit I did not understand your hint (I do not know what "base"
> is, assuming FID is Field ID - header in shp file). How is it possible
> I edited some other layer of information by function edit.nb? Could
> you please clarify what should I do to check it?

Google "0-based" gets you to Wikipedia:

"0 (zero-based indexing)
     The first element of the array is indexed by subscript of 0.
1 (one-based indexing)
     The first element of the array is indexed by subscript of 1."

So the FIDs in the shapefile are 0, ..., (n-1), and identify the 
observations, so are set in the region.id attribute of the nb object. Then 
if print(nb) says that "377" and "378" have no neighbours, and the 
region.id values are from the shapefile:

which(card(nb) == 0)

will likely say 378 379, and

attr(nb, "region.id")[which(card(nb) == 0)]

will say "377" "378".

The indices used internally in edit.nb are the 1-based indices. They 
probably should be the ones stored in the region.id attribute, but this 
would involve an extra level of indexing. If you don't understand, put the 
shapefile on a website and post the link.

Roger

>
> Thank you for prompt reply,
> Michal
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From jamesbond6 at gmail.com  Thu Aug 26 20:39:47 2010
From: jamesbond6 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Kwieci=F1ski?=)
Date: Thu, 26 Aug 2010 20:39:47 +0200
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
	<AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
	<alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>
Message-ID: <AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>

2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>
>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>>
>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>
>>>> Hi all,
>>>>
>>>> I am just about to finish my thesis. The spatial model I want to use
>>>> there is an extension of some work I did back in April. I used R 2.9.2
>>>> then and in order to include 3 additional administrative areas for
>>>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>>>> Then in R I created the nb class object and edited it with edit.nb
>>>> adding three new connections. Everything worked perfect, I had no
>>>> regions with no links and I generated weight matrices with no
>>>> problems.
>>>>
>>>> However, I'd been doing exactly the same thing entire night in R 2.11
>>>> and it did not work (I use the same code I did 4 months ago) and I
>>>> have no idea what is the reason for it. I've been looking for some
>>>> other way to do it, I tried nb2mat and editing the matrix, but I
>>>> surrendered having no idea where and what values I should use.
>>>>
>>>> Before editing nb object R claims that regions 377 and 378 have no
>>>> links. However in edit.nb the 378 and 379 are visible as having no
>>>> links (378 and 379 are cities added on top of bigger shapes, whereas
>>>> 377 was just split from a bigger shape into two smaller ones and only
>>>> the link between these two parts is missing). I connect the circles,
>>>> quit and in the new object there are some new links - the overall
>>>> number has increased - but 377 and 378 are still listed as having no
>>>> links. Editing nb again shows the links, so they have been saved for
>>>> sure.
>>>>
>>>> I am not an advanced R user and most of my code was based on my
>>>> professor's book. However, I think I have spent enough time with
>>>> spatial models and those matrices in order to call this problem really
>>>> weird. Especially since it worked perfectly last time...
>>>>
>>>> I can attach shp files and my code if it will be of any help in order
>>>> to properly investigate this problem. I would really appreciate some
>>>> help, I need to finish the project over the weekend.
>>>
>>> Maybe you are using the wrong indices, as FIDs are 0-base but nb objects
>>> are
>>> 1-base. So you may be editing the wrong ones. If this doesn't resolve the
>>> problem, zip the shapefile and post a link to it, don't attach the
>>> shapefile, as it would be sent to 1700 people.
>>
>>
>> I must admit I did not understand your hint (I do not know what "base"
>> is, assuming FID is Field ID - header in shp file). How is it possible
>> I edited some other layer of information by function edit.nb? Could
>> you please clarify what should I do to check it?
>
> Google "0-based" gets you to Wikipedia:
>
> "0 (zero-based indexing)
> ? ?The first element of the array is indexed by subscript of 0.
> 1 (one-based indexing)
> ? ?The first element of the array is indexed by subscript of 1."
>
> So the FIDs in the shapefile are 0, ..., (n-1), and identify the
> observations, so are set in the region.id attribute of the nb object. Then
> if print(nb) says that "377" and "378" have no neighbours, and the region.id
> values are from the shapefile:
>
> which(card(nb) == 0)
>
> will likely say 378 379, and
>
> attr(nb, "region.id")[which(card(nb) == 0)]
>
> will say "377" "378".
>
> The indices used internally in edit.nb are the 1-based indices. They
> probably should be the ones stored in the region.id attribute, but this
> would involve an extra level of indexing. If you don't understand, put the
> shapefile on a website and post the link.
>
Ok, now I understand. This is true in my case - it explains why I see
different numbers in listing of "no-links regions" and on the map in
edit.nb. That brings me only to the main question: why, even after
connecting the nodes (and verifying they are connected with plot.nb),
the print(nb) still says that those two regions remain unconnected?

http://home.elka.pw.edu.pl/~mkwiecin/edit.nb-problem.rar

I uploaded here the code I use, maps and two screens explaining where
to look for the missing links in question.

Thanks,
Michal


From jamesbond6 at gmail.com  Thu Aug 26 20:54:17 2010
From: jamesbond6 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Kwieci=F1ski?=)
Date: Thu, 26 Aug 2010 20:54:17 +0200
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
	<AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
	<alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>
	<AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>
Message-ID: <AANLkTinaRiKqLq082NHLjY6zfCzLroN2XpnT6eFmj8sq@mail.gmail.com>

2010/8/26 Micha? Kwieci?ski <jamesbond6 at gmail.com>:
> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>
>>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>
>>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> I am just about to finish my thesis. The spatial model I want to use
>>>>> there is an extension of some work I did back in April. I used R 2.9.2
>>>>> then and in order to include 3 additional administrative areas for
>>>>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>>>>> Then in R I created the nb class object and edited it with edit.nb
>>>>> adding three new connections. Everything worked perfect, I had no
>>>>> regions with no links and I generated weight matrices with no
>>>>> problems.
>>>>>
>>>>> However, I'd been doing exactly the same thing entire night in R 2.11
>>>>> and it did not work (I use the same code I did 4 months ago) and I
>>>>> have no idea what is the reason for it. I've been looking for some
>>>>> other way to do it, I tried nb2mat and editing the matrix, but I
>>>>> surrendered having no idea where and what values I should use.
>>>>>
>>>>> Before editing nb object R claims that regions 377 and 378 have no
>>>>> links. However in edit.nb the 378 and 379 are visible as having no
>>>>> links (378 and 379 are cities added on top of bigger shapes, whereas
>>>>> 377 was just split from a bigger shape into two smaller ones and only
>>>>> the link between these two parts is missing). I connect the circles,
>>>>> quit and in the new object there are some new links - the overall
>>>>> number has increased - but 377 and 378 are still listed as having no
>>>>> links. Editing nb again shows the links, so they have been saved for
>>>>> sure.
>>>>>
>>>>> I am not an advanced R user and most of my code was based on my
>>>>> professor's book. However, I think I have spent enough time with
>>>>> spatial models and those matrices in order to call this problem really
>>>>> weird. Especially since it worked perfectly last time...
>>>>>
>>>>> I can attach shp files and my code if it will be of any help in order
>>>>> to properly investigate this problem. I would really appreciate some
>>>>> help, I need to finish the project over the weekend.
>>>>
>>>> Maybe you are using the wrong indices, as FIDs are 0-base but nb objects
>>>> are
>>>> 1-base. So you may be editing the wrong ones. If this doesn't resolve the
>>>> problem, zip the shapefile and post a link to it, don't attach the
>>>> shapefile, as it would be sent to 1700 people.
>>>
>>>
>>> I must admit I did not understand your hint (I do not know what "base"
>>> is, assuming FID is Field ID - header in shp file). How is it possible
>>> I edited some other layer of information by function edit.nb? Could
>>> you please clarify what should I do to check it?
>>
>> Google "0-based" gets you to Wikipedia:
>>
>> "0 (zero-based indexing)
>> ? ?The first element of the array is indexed by subscript of 0.
>> 1 (one-based indexing)
>> ? ?The first element of the array is indexed by subscript of 1."
>>
>> So the FIDs in the shapefile are 0, ..., (n-1), and identify the
>> observations, so are set in the region.id attribute of the nb object. Then
>> if print(nb) says that "377" and "378" have no neighbours, and the region.id
>> values are from the shapefile:
>>
>> which(card(nb) == 0)
>>
>> will likely say 378 379, and
>>
>> attr(nb, "region.id")[which(card(nb) == 0)]
>>
>> will say "377" "378".
>>
>> The indices used internally in edit.nb are the 1-based indices. They
>> probably should be the ones stored in the region.id attribute, but this
>> would involve an extra level of indexing. If you don't understand, put the
>> shapefile on a website and post the link.
>>
> Ok, now I understand. This is true in my case - it explains why I see
> different numbers in listing of "no-links regions" and on the map in
> edit.nb. That brings me only to the main question: why, even after
> connecting the nodes (and verifying they are connected with plot.nb),
> the print(nb) still says that those two regions remain unconnected?
>
> http://home.elka.pw.edu.pl/~mkwiecin/edit.nb-problem.rar
>
> I uploaded here the code I use, maps and two screens explaining where
> to look for the missing links in question.

Ok, I did what I should have done at the very beginning (I even gave
myself a hint to do that on the beginning of my first message...).
Anyway, installed R 2.9.2 again and it appears to be working correctly
- no missing links after edit.nb().

I do not know what author of this (
https://stat.ethz.ch/pipermail/r-sig-geo/2010-July/008908.html )
message meant, but I suppose he had the same problem.

I will continue working on 2.9.2 version, so by now I am grateful for
your help Roger, but I don't think it is necessary to investigate in
hurry why edit.nb does not work in 2.11.

Thank you again,
Michal


From koday at processtrends.com  Thu Aug 26 20:59:22 2010
From: koday at processtrends.com (dkod)
Date: Thu, 26 Aug 2010 11:59:22 -0700 (PDT)
Subject: [R-sig-Geo] SpatialGridDataFrame Help
In-Reply-To: <1282786446000-5463824.post@n2.nabble.com>
References: <1282786446000-5463824.post@n2.nabble.com>
Message-ID: <1282849162246-5466791.post@n2.nabble.com>


Roger

Could you give me a hint on how I can add a landform background to my grid
plot? 

How do I use the maps packages'   world coordinates to show the landforms.

Thanks again

Kelly O'Day
-- 
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/SpatialGridDataFrame-Help-tp5463824p5466791.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Thu Aug 26 21:02:53 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 21:02:53 +0200 (CEST)
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <AANLkTinaRiKqLq082NHLjY6zfCzLroN2XpnT6eFmj8sq@mail.gmail.com>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
	<AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
	<alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>
	<AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>
	<AANLkTinaRiKqLq082NHLjY6zfCzLroN2XpnT6eFmj8sq@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008262100190.9967@reclus.nhh.no>

On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:

> 2010/8/26 Micha? Kwieci?ski <jamesbond6 at gmail.com>:
>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>
>>>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>>
>>>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> I am just about to finish my thesis. The spatial model I want to use
>>>>>> there is an extension of some work I did back in April. I used R 2.9.2
>>>>>> then and in order to include 3 additional administrative areas for
>>>>>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>>>>>> Then in R I created the nb class object and edited it with edit.nb
>>>>>> adding three new connections. Everything worked perfect, I had no
>>>>>> regions with no links and I generated weight matrices with no
>>>>>> problems.
>>>>>>
>>>>>> However, I'd been doing exactly the same thing entire night in R 2.11
>>>>>> and it did not work (I use the same code I did 4 months ago) and I
>>>>>> have no idea what is the reason for it. I've been looking for some
>>>>>> other way to do it, I tried nb2mat and editing the matrix, but I
>>>>>> surrendered having no idea where and what values I should use.
>>>>>>
>>>>>> Before editing nb object R claims that regions 377 and 378 have no
>>>>>> links. However in edit.nb the 378 and 379 are visible as having no
>>>>>> links (378 and 379 are cities added on top of bigger shapes, whereas
>>>>>> 377 was just split from a bigger shape into two smaller ones and only
>>>>>> the link between these two parts is missing). I connect the circles,
>>>>>> quit and in the new object there are some new links - the overall
>>>>>> number has increased - but 377 and 378 are still listed as having no
>>>>>> links. Editing nb again shows the links, so they have been saved for
>>>>>> sure.
>>>>>>
>>>>>> I am not an advanced R user and most of my code was based on my
>>>>>> professor's book. However, I think I have spent enough time with
>>>>>> spatial models and those matrices in order to call this problem really
>>>>>> weird. Especially since it worked perfectly last time...
>>>>>>
>>>>>> I can attach shp files and my code if it will be of any help in order
>>>>>> to properly investigate this problem. I would really appreciate some
>>>>>> help, I need to finish the project over the weekend.
>>>>>
>>>>> Maybe you are using the wrong indices, as FIDs are 0-base but nb objects
>>>>> are
>>>>> 1-base. So you may be editing the wrong ones. If this doesn't resolve the
>>>>> problem, zip the shapefile and post a link to it, don't attach the
>>>>> shapefile, as it would be sent to 1700 people.
>>>>
>>>>
>>>> I must admit I did not understand your hint (I do not know what "base"
>>>> is, assuming FID is Field ID - header in shp file). How is it possible
>>>> I edited some other layer of information by function edit.nb? Could
>>>> you please clarify what should I do to check it?
>>>
>>> Google "0-based" gets you to Wikipedia:
>>>
>>> "0 (zero-based indexing)
>>> ? ?The first element of the array is indexed by subscript of 0.
>>> 1 (one-based indexing)
>>> ? ?The first element of the array is indexed by subscript of 1."
>>>
>>> So the FIDs in the shapefile are 0, ..., (n-1), and identify the
>>> observations, so are set in the region.id attribute of the nb object. Then
>>> if print(nb) says that "377" and "378" have no neighbours, and the region.id
>>> values are from the shapefile:
>>>
>>> which(card(nb) == 0)
>>>
>>> will likely say 378 379, and
>>>
>>> attr(nb, "region.id")[which(card(nb) == 0)]
>>>
>>> will say "377" "378".
>>>
>>> The indices used internally in edit.nb are the 1-based indices. They
>>> probably should be the ones stored in the region.id attribute, but this
>>> would involve an extra level of indexing. If you don't understand, put the
>>> shapefile on a website and post the link.
>>>
>> Ok, now I understand. This is true in my case - it explains why I see
>> different numbers in listing of "no-links regions" and on the map in
>> edit.nb. That brings me only to the main question: why, even after
>> connecting the nodes (and verifying they are connected with plot.nb),
>> the print(nb) still says that those two regions remain unconnected?
>>
>> http://home.elka.pw.edu.pl/~mkwiecin/edit.nb-problem.rar
>>
>> I uploaded here the code I use, maps and two screens explaining where
>> to look for the missing links in question.
>
> Ok, I did what I should have done at the very beginning (I even gave
> myself a hint to do that on the beginning of my first message...).
> Anyway, installed R 2.9.2 again and it appears to be working correctly
> - no missing links after edit.nb().
>
> I do not know what author of this (
> https://stat.ethz.ch/pipermail/r-sig-geo/2010-July/008908.html )
> message meant, but I suppose he had the same problem.
>
> I will continue working on 2.9.2 version, so by now I am grateful for
> your help Roger, but I don't think it is necessary to investigate in
> hurry why edit.nb does not work in 2.11.

Wrong. Display in edit.nb() was broken when the input nb included 
no-neighbour observations. I a separate reply I'll explain that you need 
to fix your broken shapefile.

Roger

>
> Thank you again,
> Michal
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Thu Aug 26 21:19:05 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 21:19:05 +0200 (CEST)
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
	<AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
	<alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>
	<AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008262047270.9967@reclus.nhh.no>

On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:

> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>
>>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>
>>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> I am just about to finish my thesis. The spatial model I want to use
>>>>> there is an extension of some work I did back in April. I used R 2.9.2
>>>>> then and in order to include 3 additional administrative areas for
>>>>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>>>>> Then in R I created the nb class object and edited it with edit.nb
>>>>> adding three new connections. Everything worked perfect, I had no
>>>>> regions with no links and I generated weight matrices with no
>>>>> problems.
>>>>>
>>>>> However, I'd been doing exactly the same thing entire night in R 2.11
>>>>> and it did not work (I use the same code I did 4 months ago) and I
>>>>> have no idea what is the reason for it. I've been looking for some
>>>>> other way to do it, I tried nb2mat and editing the matrix, but I
>>>>> surrendered having no idea where and what values I should use.
>>>>>
>>>>> Before editing nb object R claims that regions 377 and 378 have no
>>>>> links. However in edit.nb the 378 and 379 are visible as having no
>>>>> links (378 and 379 are cities added on top of bigger shapes, whereas
>>>>> 377 was just split from a bigger shape into two smaller ones and only
>>>>> the link between these two parts is missing). I connect the circles,
>>>>> quit and in the new object there are some new links - the overall
>>>>> number has increased - but 377 and 378 are still listed as having no
>>>>> links. Editing nb again shows the links, so they have been saved for
>>>>> sure.
>>>>>
>>>>> I am not an advanced R user and most of my code was based on my
>>>>> professor's book. However, I think I have spent enough time with
>>>>> spatial models and those matrices in order to call this problem really
>>>>> weird. Especially since it worked perfectly last time...
>>>>>
>>>>> I can attach shp files and my code if it will be of any help in order
>>>>> to properly investigate this problem. I would really appreciate some
>>>>> help, I need to finish the project over the weekend.
>>>>
>>>> Maybe you are using the wrong indices, as FIDs are 0-base but nb objects
>>>> are
>>>> 1-base. So you may be editing the wrong ones. If this doesn't resolve the
>>>> problem, zip the shapefile and post a link to it, don't attach the
>>>> shapefile, as it would be sent to 1700 people.
>>>
>>>
>>> I must admit I did not understand your hint (I do not know what "base"
>>> is, assuming FID is Field ID - header in shp file). How is it possible
>>> I edited some other layer of information by function edit.nb? Could
>>> you please clarify what should I do to check it?
>>
>> Google "0-based" gets you to Wikipedia:
>>
>> "0 (zero-based indexing)
>> ? ?The first element of the array is indexed by subscript of 0.
>> 1 (one-based indexing)
>> ? ?The first element of the array is indexed by subscript of 1."
>>
>> So the FIDs in the shapefile are 0, ..., (n-1), and identify the
>> observations, so are set in the region.id attribute of the nb object. Then
>> if print(nb) says that "377" and "378" have no neighbours, and the region.id
>> values are from the shapefile:
>>
>> which(card(nb) == 0)
>>
>> will likely say 378 379, and
>>
>> attr(nb, "region.id")[which(card(nb) == 0)]
>>
>> will say "377" "378".
>>
>> The indices used internally in edit.nb are the 1-based indices. They
>> probably should be the ones stored in the region.id attribute, but this
>> would involve an extra level of indexing. If you don't understand, put the
>> shapefile on a website and post the link.
>>
> Ok, now I understand. This is true in my case - it explains why I see
> different numbers in listing of "no-links regions" and on the map in
> edit.nb. That brings me only to the main question: why, even after
> connecting the nodes (and verifying they are connected with plot.nb),
> the print(nb) still says that those two regions remain unconnected?
>
> http://home.elka.pw.edu.pl/~mkwiecin/edit.nb-problem.rar
>
> I uploaded here the code I use, maps and two screens explaining where
> to look for the missing links in question.

Good, now the underlying problem is clear. 1-based units 90 and 379 (to 
take that case first) share no boundaries with any polygon. You need to 
add the 379 polygon to 90 as a hole first. Then poly2nb() will work 
properly. As it is, 379 has no boundaries with any observation, because it 
is simply dropped on top of the map. 378 also seems to have been dropped, 
but not on 377, it landed on 249. For the first case, try:

pols <- slot(pow, "polygons")
p90 <- pols[[90]]
p379 <- pols[[379]]
crds379 <- slot(slot(p379, "Polygons")[[1]], "coords")
crds379
rcrds379 <- crds379[nrow(crds379):1,]
Pl379 <- Polygon(rcrds379)
slot(p90, "Polygons") <- list(slot(p90, "Polygons")[[1]], Pl379)
pols[[90]] <- p90
slot(pow, "polygons") <- pols
pow.nb<-poly2nb(pow)
pow.nb

Once you find out where 377 should be (it lies on 249), do the same, and 
you will be able to work from your repaired shapefile.

Roger


>
> Thanks,
> Michal
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Thu Aug 26 21:25:14 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Aug 2010 21:25:14 +0200 (CEST)
Subject: [R-sig-Geo] SpatialGridDataFrame Help
In-Reply-To: <1282849162246-5466791.post@n2.nabble.com>
References: <1282786446000-5463824.post@n2.nabble.com>
	<1282849162246-5466791.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1008262119570.9967@reclus.nhh.no>

On Thu, 26 Aug 2010, dkod wrote:

>
> Roger
>
> Could you give me a hint on how I can add a landform background to my grid
> plot?
>
> How do I use the maps packages'   world coordinates to show the landforms.

See map2SpatialLines() in maptools, work out whether to transform, or at 
least to assign the correct CRS. Note that image.plot() - if you are still 
using that function - does not stretch the Northings (y-axis), so if you 
are away from the Equator, your output will look flattened. Plotting 
functions in the sp and maps packages do stretch when the data are known 
to be in geographical coordinates.

Roger

>
> Thanks again
>
> Kelly O'Day
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From jamesbond6 at gmail.com  Thu Aug 26 23:02:45 2010
From: jamesbond6 at gmail.com (=?ISO-8859-2?Q?Micha=B3_Kwieci=F1ski?=)
Date: Thu, 26 Aug 2010 23:02:45 +0200
Subject: [R-sig-Geo] problem with edit.nb
In-Reply-To: <alpine.LRH.2.00.1008262047270.9967@reclus.nhh.no>
References: <AANLkTimZbK_ae+Jx_ykTsDYZLRLiHUBqEUnxFAxPTDQR@mail.gmail.com>
	<alpine.LRH.2.00.1008261610360.9223@reclus.nhh.no>
	<AANLkTi=OCL7_HSfecQD36=ENCGGatoiZDBjzoyjDToD7@mail.gmail.com>
	<alpine.LRH.2.00.1008261950340.9967@reclus.nhh.no>
	<AANLkTikRJMwnfVXqdG89+fjtacDEL8qsPZXUpB=aqyw1@mail.gmail.com>
	<alpine.LRH.2.00.1008262047270.9967@reclus.nhh.no>
Message-ID: <AANLkTin0Xk82NZ-tM4=vRLxC2ko740hn=0Nq1gpDC0vE@mail.gmail.com>

2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>
>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>>
>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>
>>>> 2010/8/26 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>>
>>>>> On Thu, 26 Aug 2010, Micha? Kwieci?ski wrote:
>>>>>
>>>>>> Hi all,
>>>>>>
>>>>>> I am just about to finish my thesis. The spatial model I want to use
>>>>>> there is an extension of some work I did back in April. I used R 2.9.2
>>>>>> then and in order to include 3 additional administrative areas for
>>>>>> Poland, I edited the shp files (the borders aren't perfectly aligned).
>>>>>> Then in R I created the nb class object and edited it with edit.nb
>>>>>> adding three new connections. Everything worked perfect, I had no
>>>>>> regions with no links and I generated weight matrices with no
>>>>>> problems.
>>>>>>
>>>>>> However, I'd been doing exactly the same thing entire night in R 2.11
>>>>>> and it did not work (I use the same code I did 4 months ago) and I
>>>>>> have no idea what is the reason for it. I've been looking for some
>>>>>> other way to do it, I tried nb2mat and editing the matrix, but I
>>>>>> surrendered having no idea where and what values I should use.
>>>>>>
>>>>>> Before editing nb object R claims that regions 377 and 378 have no
>>>>>> links. However in edit.nb the 378 and 379 are visible as having no
>>>>>> links (378 and 379 are cities added on top of bigger shapes, whereas
>>>>>> 377 was just split from a bigger shape into two smaller ones and only
>>>>>> the link between these two parts is missing). I connect the circles,
>>>>>> quit and in the new object there are some new links - the overall
>>>>>> number has increased - but 377 and 378 are still listed as having no
>>>>>> links. Editing nb again shows the links, so they have been saved for
>>>>>> sure.
>>>>>>
>>>>>> I am not an advanced R user and most of my code was based on my
>>>>>> professor's book. However, I think I have spent enough time with
>>>>>> spatial models and those matrices in order to call this problem really
>>>>>> weird. Especially since it worked perfectly last time...
>>>>>>
>>>>>> I can attach shp files and my code if it will be of any help in order
>>>>>> to properly investigate this problem. I would really appreciate some
>>>>>> help, I need to finish the project over the weekend.
>>>>>
>>>>> Maybe you are using the wrong indices, as FIDs are 0-base but nb
>>>>> objects
>>>>> are
>>>>> 1-base. So you may be editing the wrong ones. If this doesn't resolve
>>>>> the
>>>>> problem, zip the shapefile and post a link to it, don't attach the
>>>>> shapefile, as it would be sent to 1700 people.
>>>>
>>>>
>>>> I must admit I did not understand your hint (I do not know what "base"
>>>> is, assuming FID is Field ID - header in shp file). How is it possible
>>>> I edited some other layer of information by function edit.nb? Could
>>>> you please clarify what should I do to check it?
>>>
>>> Google "0-based" gets you to Wikipedia:
>>>
>>> "0 (zero-based indexing)
>>> ? ?The first element of the array is indexed by subscript of 0.
>>> 1 (one-based indexing)
>>> ? ?The first element of the array is indexed by subscript of 1."
>>>
>>> So the FIDs in the shapefile are 0, ..., (n-1), and identify the
>>> observations, so are set in the region.id attribute of the nb object.
>>> Then
>>> if print(nb) says that "377" and "378" have no neighbours, and the
>>> region.id
>>> values are from the shapefile:
>>>
>>> which(card(nb) == 0)
>>>
>>> will likely say 378 379, and
>>>
>>> attr(nb, "region.id")[which(card(nb) == 0)]
>>>
>>> will say "377" "378".
>>>
>>> The indices used internally in edit.nb are the 1-based indices. They
>>> probably should be the ones stored in the region.id attribute, but this
>>> would involve an extra level of indexing. If you don't understand, put
>>> the
>>> shapefile on a website and post the link.
>>>
>> Ok, now I understand. This is true in my case - it explains why I see
>> different numbers in listing of "no-links regions" and on the map in
>> edit.nb. That brings me only to the main question: why, even after
>> connecting the nodes (and verifying they are connected with plot.nb),
>> the print(nb) still says that those two regions remain unconnected?
>>
>> http://home.elka.pw.edu.pl/~mkwiecin/edit.nb-problem.rar
>>
>> I uploaded here the code I use, maps and two screens explaining where
>> to look for the missing links in question.
>
> Good, now the underlying problem is clear. 1-based units 90 and 379 (to take
> that case first) share no boundaries with any polygon. You need to add the
> 379 polygon to 90 as a hole first. Then poly2nb() will work properly. As it
> is, 379 has no boundaries with any observation, because it is simply dropped
> on top of the map. 378 also seems to have been dropped, but not on 377, it
> landed on 249. For the first case, try:
>
> pols <- slot(pow, "polygons")
> p90 <- pols[[90]]
> p379 <- pols[[379]]
> crds379 <- slot(slot(p379, "Polygons")[[1]], "coords")
> crds379
> rcrds379 <- crds379[nrow(crds379):1,]
> Pl379 <- Polygon(rcrds379)
> slot(p90, "Polygons") <- list(slot(p90, "Polygons")[[1]], Pl379)
> pols[[90]] <- p90
> slot(pow, "polygons") <- pols
> pow.nb<-poly2nb(pow)
> pow.nb
>
> Once you find out where 377 should be (it lies on 249), do the same, and you
> will be able to work from your repaired shapefile.

I used this code twice for 378 and 379, added missing link between 377
and 257 and it worked fine under 2.11.1, thanks. Now the pow.nb object
looks the same as after editing with edit.nb() in 2.9.2.

I realised the way I created those three additional polygons was
rather unprofessional and simple. I did it for the first time and I
used fGIS and MS Access. Since it worked fine in 2.9.2, I didn't
expect it to mess anything up later, my bad. By the way, I also did
not realise one is able to manipulate polys within R so easily.

Thank you Roger,
Michal


From tomas.zelinsky at tuke.sk  Fri Aug 27 13:43:31 2010
From: tomas.zelinsky at tuke.sk (Tomas Zelinsky)
Date: Fri, 27 Aug 2010 13:43:31 +0200
Subject: [R-sig-Geo] European Union NUTS2, NUTS3 regions (SHP format)
Message-ID: <4C77A4E3.6020704@tuke.sk>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100827/f724ceeb/attachment.html>

From gianni.lavaredo at gmail.com  Fri Aug 27 15:16:57 2010
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Fri, 27 Aug 2010 15:16:57 +0200
Subject: [R-sig-Geo] Help to convert a Polygon in SpatialPolygonsDataFrame
Message-ID: <AANLkTiktSqyiuXEYoPjTw0CrNw2yOdaWDQiMjpH=QYVk@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100827/02ed85d7/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Fri Aug 27 15:35:13 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 27 Aug 2010 14:35:13 +0100
Subject: [R-sig-Geo] European Union NUTS2, NUTS3 regions (SHP format)
In-Reply-To: <4C77A4E3.6020704@tuke.sk>
References: <4C77A4E3.6020704@tuke.sk>
Message-ID: <AANLkTi=H2gqJnDRg0SkqhHXrbSjU12t4nWNSUP_+A1+e@mail.gmail.com>

2010/8/27 Tomas Zelinsky <tomas.zelinsky at tuke.sk>:
> Hello,
>
> you probably know administrative maps of the EU and their availability (both
> SHP and GDB) via
> http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco/popups/references/administrative_units_statistical_units_1
> .
>
> Basically there are three administrative levels in one map (NUTS 1, 2 and 3
> levels).
>
> 1. Is there any possibility how to make NUTS3 level borderlines invisible if
> my aim is to e.g. analyze NUTS2 level?
>
> 2. Or is it possible to make e.g. NUTS1 level borderlines thicker than the
> other?

 Looking at NUTS_RG_60M_2006.SHP there's a STAT_LEVL_ variable which I
guess is the NUTS level code - this is probably documented in the
meta-data somewhere. So you can do:

 require(rgdal)
 s = readOGR(".","NUTS_RG_60M_2006")
 plot(s[s$STAT_LEVL_==0,])
 plot(s[s$STAT_LEVL_==1,])

 and so on. You might also want to extract just the polygons for a
particular level into a new object:

 n2 = s[s$STAT_LEVL_==2,]

 You can use lwd=X in plot for sp objects to change the line width.

Barry


From nikhil.list at gmail.com  Fri Aug 27 15:56:01 2010
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Fri, 27 Aug 2010 09:56:01 -0400
Subject: [R-sig-Geo] splitting a map into areas by number of addresses
In-Reply-To: <AANLkTikZXTve_Bj+Vi=ZrOZoxRqQkyxVqUwP24T8joh6@mail.gmail.com>
References: <2e7e124c00010d59@cancer.dk>
	<AANLkTikZXTve_Bj+Vi=ZrOZoxRqQkyxVqUwP24T8joh6@mail.gmail.com>
Message-ID: <1B0E0AA2-134E-41F8-8228-514E6006C169@gmail.com>



On Aug 26, 2010, at 10:23 AM, Barry Rowlingson wrote:

> On Thu, Aug 26, 2010 at 1:50 PM, Sven Schmiedel <sven at cancer.dk>  
> wrote:
>> Dear list,
>>
>> I have the following problem: I have around 1,000,000 addresses of  
>> a country and want now to split the area in artificial  
>> "administrative units" with exactly 1,000 addresses per unit.
>>
>> As I did not find a direct way to do this, my idea was to chose  
>> randomly 1,000 addresses, use the voronoi tessellation (from  
>> library PBSmapping) for these and look how many addresses are found  
>> in each piece this mosaic. However, the result is not stable and  
>> the number of addresses varies quite a lot from unit to unit.
>>
>> Hence, I would like to know if there is a procedure/package that is  
>> incorporating a function that is able to do this splitting with a  
>> fixed number of addresses. If anyone has another program or an  
>> methodological approach to this problem I would be happy about this  
>> information.
>
> Hmmm as stated this doesn't look particularly well-defined.
>
> Do the administrative units have to be compact and connected? If not,
> then just do sample(1000,1000000,TRUE) and job done.
>
> Do you have point locations for each address, or areas? You didn't  
> say.
>
> With point locations you could do the voronoi tesselation of all
> 1000000 and then take the graph and partition it into 1000 connected
> sub-graphs [waves hands] somehow. That would ensure all addresses in
> an admin unit were neighbours, but you could have an admin unit that
> was a linear feature of addresses.
>
> I can think of various heuristics for making more compact sets, which
> involve growing units by adding the next nearest address that
> minimizes the 'spread', possibly by adding the next unit as the one
> nearest the centroid of the current unit. You might want to grow all
> 1000 simultaneously from 1000 seeds (spread across the area) or grow
> one to full size, and then another, but that might form lots of
> 'islands' of less than 1000 addresses that would be impossible to form
> into admin units.
>
> Barry
>

Graph partitioning is NP-complete. However, heuristics exist that work  
in a resonable time for real world graphs. see http://en.wikipedia.org/wiki/Kernighan%E2%80%93Lin_algorithm 
. But I doubt if this would work for your situation.
Another idea, is to create 1000 clusters (not sure how you would  
ensure exactly 1000 points in each).  Find the centeroid of those  
clusters and then create the Voronoi tessellation.

> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From kerryr at sccwrp.org  Fri Aug 27 16:22:13 2010
From: kerryr at sccwrp.org (Kerry Ritter)
Date: Fri, 27 Aug 2010 07:22:13 -0700
Subject: [R-sig-Geo] goodness of fit for anisotropic model in 4 directions
Message-ID: <4C77CA15.2050502@sccwrp.org>

HI I am looking for a goodness of fit measure in the case of an 
anisotropic variogram model fit in 4 directions.  I want to be able to 
compare between different fitting algorithms, so a measure that is 
independent of the fitting method is key.  I also want to compare 
between different models (ie. anisotropic with linear trend vs 
anisotropic).  Does anyone know if such a measure exists in one of the R 
libraries?  Three seems to be a measure "SSErr" in gstat using 
fit.variogram that may work when all parameters are fixed, but I do not 
know how the statistic is calculated.  Can someone provide me with a 
formula for this computation in the case of fitting a variogram in 4 
directions? Alternatively can you help me with a different goodness of 
fit formula that I could program myself in R?
Thanks,
Kerry

-- 
**********************
Kerry Ritter, Ph.D.
statistician
Southern California Coastal Water Research Project
3535 Harbor Blvd., Suite 110

work: 714-755-3210
cell: 714-420-3346
fax:  714-755-3299

email: kerryr at sccwrp.org


From Jan.Quets at ua.ac.be  Fri Aug 27 18:29:12 2010
From: Jan.Quets at ua.ac.be (Quets Jan)
Date: Fri, 27 Aug 2010 18:29:12 +0200
Subject: [R-sig-Geo] uniform weighterd (non-Gaussian) kernel in density.ppp
Message-ID: <88D678F82D1A1447BD5C643160FFCBC20C15B4@xmail07.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100827/6306c59b/attachment.pl>

From Roger.Bivand at nhh.no  Fri Aug 27 18:39:00 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 27 Aug 2010 18:39:00 +0200 (CEST)
Subject: [R-sig-Geo] Help to convert a Polygon in
 SpatialPolygonsDataFrame
In-Reply-To: <AANLkTiktSqyiuXEYoPjTw0CrNw2yOdaWDQiMjpH=QYVk@mail.gmail.com>
References: <AANLkTiktSqyiuXEYoPjTw0CrNw2yOdaWDQiMjpH=QYVk@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1008271837400.12637@reclus.nhh.no>

On Fri, 27 Aug 2010, gianni lavaredo wrote:

> dear Researcher,
>
> it's friday afternoon i am starting to be tired. I don't rememeber the
> method to convert a polygon class in a SpatialPolygonsDataFrame to use
> overlay later. Sorry for destrub with this simple question.
>
> thanks in advance Gianni
>
>
>
> mywindow <- owin(mydata at bbox[1,],mydata at bbox[2,])
>        plot(mywindow, border="red")
>        points(centroid.owin(mywindow),pch=19,cex = 0.7)
>        xy.centr <- as.matrix(data.frame(centroid.owin(mywindow)))
>        # create a circle with the radius equal 1/2 the side of square area
>        big =  disc(radius=100, centre=xy.centr[1,], npoly=4)
>        vert <- vertices(big)
>        # square of 200 x 200 m side
>        r <- as.rectangle(big)
>        plot(r, add=T)
>        vert.r.xy <- as.matrix(data.frame(vertices(r)))
>        vert.r.xy.poligon <- rbind(vert.r.xy,vert.r.xy[1,])
>        p <- Polygon(vert.r.xy.poligon, hole=as.logical(NA))

SP <- SpatialPolygons(list(Polygons(list(p), ID="1")))

should do it.

Roger

> ---------------------------
> overlay
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From yan_boulanger at hotmail.com  Fri Aug 27 19:08:50 2010
From: yan_boulanger at hotmail.com (Yan Boulanger)
Date: Fri, 27 Aug 2010 17:08:50 +0000
Subject: [R-sig-Geo] Fragstats in R?
Message-ID: <SNT124-W120EDF6BE4D4E626BB93C08D860@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100827/b3675d60/attachment.pl>

From yan_boulanger at hotmail.com  Fri Aug 27 19:11:30 2010
From: yan_boulanger at hotmail.com (Yan Boulanger)
Date: Fri, 27 Aug 2010 17:11:30 +0000
Subject: [R-sig-Geo] Fragstats in R?
In-Reply-To: <SNT124-W120EDF6BE4D4E626BB93C08D860@phx.gbl>
References: <SNT124-W120EDF6BE4D4E626BB93C08D860@phx.gbl>
Message-ID: <SNT124-W59A8009DFAA1209676B5C68D860@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100827/85e1b659/attachment.pl>

From tom.kurkowski at alaska.edu  Fri Aug 27 20:41:14 2010
From: tom.kurkowski at alaska.edu (Tom Kurkowski)
Date: Fri, 27 Aug 2010 10:41:14 -0800
Subject: [R-sig-Geo] Read/Write/Compress GeoTIFFs LZW
Message-ID: <AANLkTi=nh0E=gRUY8kN_jayXcopDQb-pwcuoX1hNDUMa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100827/b555a53c/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Fri Aug 27 21:45:46 2010
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 27 Aug 2010 20:45:46 +0100
Subject: [R-sig-Geo] Help to convert a Polygon in
	SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.1008271837400.12637@reclus.nhh.no>
References: <AANLkTiktSqyiuXEYoPjTw0CrNw2yOdaWDQiMjpH=QYVk@mail.gmail.com>
	<alpine.LRH.2.00.1008271837400.12637@reclus.nhh.no>
Message-ID: <AANLkTinACrXxb3qqOPBcr1QEtRFaKvmr1S9Sv3w85Kwc@mail.gmail.com>

On Fri, Aug 27, 2010 at 5:39 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> SP <- SpatialPolygons(list(Polygons(list(p), ID="1")))

 This is Exhibit A in my forthcoming case for a spatial data
translation package!

Barry


From wdmccoy at geo.umass.edu  Sat Aug 28 02:33:41 2010
From: wdmccoy at geo.umass.edu (William McCoy)
Date: Fri, 27 Aug 2010 20:33:41 -0400
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
Message-ID: <4C785965.90405@geo.umass.edu>

I am using spgrass6, but I can't seem to initiate a grass session.  I 
managed to do this correctly months ago, but can't seem to now.  Here is 
my code and sessionInfo:

 > library(spgrass6)
Loading required package: sp
Loading required package: rgdal
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
Path to GDAL shared files: /usr/local/share/gdal
Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
Path to PROJ.4 shared files: (autodetected)
Loading required package: XML
GRASS GIS interface loaded with GRASS version: (GRASS not running)
 > loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home = 
tempdir())
g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
Error in if (file.exists(file) == FALSE) if (!missing(asText) && asText 
==  :
   argument is of length zero
Error in parseGRASS(cmd) : g.region not parsed

 > sessionInfo()
R version 2.11.1 (2010-05-31)
i386-redhat-linux-gnu

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] spgrass6_0.6-19 XML_3.1-1       rgdal_0.6-28    sp_0.9-66

loaded via a namespace (and not attached):
[1] grid_2.11.1    lattice_0.18-8 tools_2.11.1


Any ideas about what I am doing wrong?

Thanks, Bill

-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA 01003


From tomas.zelinsky at tuke.sk  Sat Aug 28 11:38:44 2010
From: tomas.zelinsky at tuke.sk (Tomas Zelinsky)
Date: Sat, 28 Aug 2010 11:38:44 +0200
Subject: [R-sig-Geo] European Union NUTS2, NUTS3 regions (SHP format)
In-Reply-To: <AANLkTi=H2gqJnDRg0SkqhHXrbSjU12t4nWNSUP_+A1+e@mail.gmail.com>
References: <4C77A4E3.6020704@tuke.sk>
	<AANLkTi=H2gqJnDRg0SkqhHXrbSjU12t4nWNSUP_+A1+e@mail.gmail.com>
Message-ID: <4C78D924.9010006@tuke.sk>

Thank you Barry for your help. It works now. I'm just still not sure how 
to use different widths of lines for different statistical levels. 
Hopefully I'll figure it out soon.

Thanks again.

Tomas




Barry Rowlingson  wrote / nap?sal(a):
> 2010/8/27 Tomas Zelinsky <tomas.zelinsky at tuke.sk>:
>   
>> Hello,
>>
>> you probably know administrative maps of the EU and their availability (both
>> SHP and GDB) via
>> http://epp.eurostat.ec.europa.eu/portal/page/portal/gisco/popups/references/administrative_units_statistical_units_1
>> .
>>
>> Basically there are three administrative levels in one map (NUTS 1, 2 and 3
>> levels).
>>
>> 1. Is there any possibility how to make NUTS3 level borderlines invisible if
>> my aim is to e.g. analyze NUTS2 level?
>>
>> 2. Or is it possible to make e.g. NUTS1 level borderlines thicker than the
>> other?
>>     
>
>  Looking at NUTS_RG_60M_2006.SHP there's a STAT_LEVL_ variable which I
> guess is the NUTS level code - this is probably documented in the
> meta-data somewhere. So you can do:
>
>  require(rgdal)
>  s = readOGR(".","NUTS_RG_60M_2006")
>  plot(s[s$STAT_LEVL_==0,])
>  plot(s[s$STAT_LEVL_==1,])
>
>  and so on. You might also want to extract just the polygons for a
> particular level into a new object:
>
>  n2 = s[s$STAT_LEVL_==2,]
>
>  You can use lwd=X in plot for sp objects to change the line width.
>
> Barry
>


From Roger.Bivand at nhh.no  Sat Aug 28 11:41:09 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Aug 2010 11:41:09 +0200 (CEST)
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <4C785965.90405@geo.umass.edu>
References: <4C785965.90405@geo.umass.edu>
Message-ID: <alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>

On Fri, 27 Aug 2010, William McCoy wrote:

> I am using spgrass6, but I can't seem to initiate a grass session.  I managed 
> to do this correctly months ago, but can't seem to now.  Here is my code and 
> sessionInfo:

Something has happened to your GRASS installation and/or the 
LD_LIBRARY_PATH environment variable. The GRASS binary modules are being 
found, but the libraries (shared objects) they call are not. Try to set 
debug(initGRASS), then step through looking at what is in environment 
variables, etc. After the if () for conditionally setting the PATH, look 
at:

Sys.getenv("PATH")
list.files(Sys.getenv("PATH"))

and similarly for LD_LIBRARY_PATH:

Sys.getenv("LD_LIBRARY_PATH")
list.files(Sys.getenv("LD_LIBRARY_PATH"))

I suspect that the test:

eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
grep(basename(Sys.getenv("GISBASE")), eLDPATH)

is not empty, so the LD_LIBRARY_PATH does not get edited to include the 
actual locations of the *.so files.

Have you changed the definitions of these environment variables in a 
.bashrc or similar between this working and no longer working? Before 
starting R, say:

echo $PATH
echo $LD_LIBRARY_PATH

to see if that sheds any light on things.

Hope this helps,

Roger


>
>> library(spgrass6)
> Loading required package: sp
> Loading required package: rgdal
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
> Path to GDAL shared files: /usr/local/share/gdal
> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
> Path to PROJ.4 shared files: (autodetected)
> Loading required package: XML
> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home = tempdir())
> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
> g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
> Error in if (file.exists(file) == FALSE) if (!missing(asText) && asText ==  :
>  argument is of length zero
> Error in parseGRASS(cmd) : g.region not parsed
>
>> sessionInfo()
> R version 2.11.1 (2010-05-31)
> i386-redhat-linux-gnu
>
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=C              LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] spgrass6_0.6-19 XML_3.1-1       rgdal_0.6-28    sp_0.9-66
>
> loaded via a namespace (and not attached):
> [1] grid_2.11.1    lattice_0.18-8 tools_2.11.1
>
>
> Any ideas about what I am doing wrong?
>
> Thanks, Bill
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wdmccoy at geo.umass.edu  Sat Aug 28 18:40:38 2010
From: wdmccoy at geo.umass.edu (William McCoy)
Date: Sat, 28 Aug 2010 12:40:38 -0400
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
References: <4C785965.90405@geo.umass.edu>
	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
Message-ID: <4C793C06.1080600@geo.umass.edu>

Roger,

I think your suspicions are correct.  Here is the output from debug 
after the PATH setting if():

Browse[2]> Sys.getenv("PATH")
 
 
 
                                        PATH
"/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts" 

Browse[2]> list.files(Sys.getenv("PATH"))
character(0)
Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
 
 
                                 LD_LIBRARY_PATH
"/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib" 

Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
character(0)


Since I last used spgrass6 many months ago, I have installed grass64svn 
along with grass63, which was long ago installed as a fedora rpm.  So my 
PATH looks like this:


[wdmccoy at boreas ~]$ echo $PATH
/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin


But my LD_LIBRARY_PATH looks like this:

[wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH


I.e., there is nothing in LD_LIBRARY_PATH.  The reason grass64 works by 
itself (outside of R) is because I have a grass64.conf file in 
/etc/ld.so.conf.d and that .conf file contains:

/usr/local/grass-6.4.0svn/lib


What do you recommend?


Thanks, Bill


On 08/28/2010 05:41 AM, Roger Bivand wrote:
> On Fri, 27 Aug 2010, William McCoy wrote:
>
>> I am using spgrass6, but I can't seem to initiate a grass session. I
>> managed to do this correctly months ago, but can't seem to now. Here
>> is my code and sessionInfo:
>
> Something has happened to your GRASS installation and/or the
> LD_LIBRARY_PATH environment variable. The GRASS binary modules are being
> found, but the libraries (shared objects) they call are not. Try to set
> debug(initGRASS), then step through looking at what is in environment
> variables, etc. After the if () for conditionally setting the PATH, look
> at:
>
> Sys.getenv("PATH")
> list.files(Sys.getenv("PATH"))
>
> and similarly for LD_LIBRARY_PATH:
>
> Sys.getenv("LD_LIBRARY_PATH")
> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>
> I suspect that the test:
>
> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>
> is not empty, so the LD_LIBRARY_PATH does not get edited to include the
> actual locations of the *.so files.
>
> Have you changed the definitions of these environment variables in a
> .bashrc or similar between this working and no longer working? Before
> starting R, say:
>
> echo $PATH
> echo $LD_LIBRARY_PATH
>
> to see if that sheds any light on things.
>
> Hope this helps,
>
> Roger
>
>
>>
>>> library(spgrass6)
>> Loading required package: sp
>> Loading required package: rgdal
>> Geospatial Data Abstraction Library extensions to R successfully loaded
>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>> Path to GDAL shared files: /usr/local/share/gdal
>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>> Path to PROJ.4 shared files: (autodetected)
>> Loading required package: XML
>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>> tempdir())
>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>> g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>> asText == :
>> argument is of length zero
>> Error in parseGRASS(cmd) : g.region not parsed
>>
>>> sessionInfo()
>> R version 2.11.1 (2010-05-31)
>> i386-redhat-linux-gnu
>>
>> locale:
>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats graphics grDevices utils datasets methods base
>>
>> other attached packages:
>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>
>>
>> Any ideas about what I am doing wrong?
>>
>> Thanks, Bill
>>
>>
>


-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA 01003


From edzer.pebesma at uni-muenster.de  Sat Aug 28 18:53:13 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sat, 28 Aug 2010 18:53:13 +0200
Subject: [R-sig-Geo] goodness of fit for anisotropic model in 4
	directions
In-Reply-To: <4C77CA15.2050502@sccwrp.org>
References: <4C77CA15.2050502@sccwrp.org>
Message-ID: <4C793EF9.3060007@uni-muenster.de>

the SSErr attribute is the (weighted) sum of squared errors minimized by
the procedure called for. So if weights are Nh, then SSErr is

sum_i Nh_i (gammaModel_i - gammaSample_i)^2

or see the second equation on page 66 of the longer reference manual for
gstat, http://gstat.org/gstat.pdf for a properly formatted version.

This implies, that this SSErr depends on the weights chosen, and cannot
be compared accross different weighting schemes.

For comparing the quality of a particular variogram, I would use cross
validation (krige.cv) on kriging predictions to compare various
variogram models. The aestetics of the fit is usually seen as less
important compared to how well the variogram worked for spatial prediction.

On 08/27/2010 04:22 PM, Kerry Ritter wrote:
> HI I am looking for a goodness of fit measure in the case of an
> anisotropic variogram model fit in 4 directions.  I want to be able to
> compare between different fitting algorithms, so a measure that is
> independent of the fitting method is key.  I also want to compare
> between different models (ie. anisotropic with linear trend vs
> anisotropic).  Does anyone know if such a measure exists in one of the R
> libraries?  Three seems to be a measure "SSErr" in gstat using
> fit.variogram that may work when all parameters are fixed, but I do not
> know how the statistic is calculated.  Can someone provide me with a
> formula for this computation in the case of fitting a variogram in 4
> directions? Alternatively can you help me with a different goodness of
> fit formula that I could program myself in R?
> Thanks,
> Kerry
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Roger.Bivand at nhh.no  Sat Aug 28 19:15:51 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Aug 2010 19:15:51 +0200 (CEST)
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <4C793C06.1080600@geo.umass.edu>
References: <4C785965.90405@geo.umass.edu>
	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
	<4C793C06.1080600@geo.umass.edu>
Message-ID: <alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>

On Sat, 28 Aug 2010, William McCoy wrote:

> Roger,
>
> I think your suspicions are correct.  Here is the output from debug after the 
> PATH setting if():
>
> Browse[2]> Sys.getenv("PATH")
>
>
>
>                                       PATH
> "/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts" 
> Browse[2]> list.files(Sys.getenv("PATH"))
> character(0)
> Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
>
>
>                                LD_LIBRARY_PATH
> "/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib" 
> Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
> character(0)
>
>
> Since I last used spgrass6 many months ago, I have installed grass64svn along 
> with grass63, which was long ago installed as a fedora rpm.  So my PATH looks 
> like this:
>
>
> [wdmccoy at boreas ~]$ echo $PATH
> /usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin
>
>
> But my LD_LIBRARY_PATH looks like this:
>
> [wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH
>
>
> I.e., there is nothing in LD_LIBRARY_PATH.  The reason grass64 works by 
> itself (outside of R) is because I have a grass64.conf file in 
> /etc/ld.so.conf.d and that .conf file contains:
>
> /usr/local/grass-6.4.0svn/lib
>
>
> What do you recommend?

This is a bit difficult to say, but trying to set LD_LIBRARY_PATH before 
starting R to the correct value:

export LD_LIBRARY_PATH=/usr/local/grass-6.4.0svn/lib

and/or ensuring that ldconfig was run, might help.

Have you tried using gisBase = "/usr/local/grass-6.4.0svn" without the 
terminating "/"?

Hope this goes in the right direction,

Roger

>
>
> Thanks, Bill
>
>
> On 08/28/2010 05:41 AM, Roger Bivand wrote:
>> On Fri, 27 Aug 2010, William McCoy wrote:
>> 
>>> I am using spgrass6, but I can't seem to initiate a grass session. I
>>> managed to do this correctly months ago, but can't seem to now. Here
>>> is my code and sessionInfo:
>> 
>> Something has happened to your GRASS installation and/or the
>> LD_LIBRARY_PATH environment variable. The GRASS binary modules are being
>> found, but the libraries (shared objects) they call are not. Try to set
>> debug(initGRASS), then step through looking at what is in environment
>> variables, etc. After the if () for conditionally setting the PATH, look
>> at:
>> 
>> Sys.getenv("PATH")
>> list.files(Sys.getenv("PATH"))
>> 
>> and similarly for LD_LIBRARY_PATH:
>> 
>> Sys.getenv("LD_LIBRARY_PATH")
>> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>> 
>> I suspect that the test:
>> 
>> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
>> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>> 
>> is not empty, so the LD_LIBRARY_PATH does not get edited to include the
>> actual locations of the *.so files.
>> 
>> Have you changed the definitions of these environment variables in a
>> .bashrc or similar between this working and no longer working? Before
>> starting R, say:
>> 
>> echo $PATH
>> echo $LD_LIBRARY_PATH
>> 
>> to see if that sheds any light on things.
>> 
>> Hope this helps,
>> 
>> Roger
>> 
>> 
>>> 
>>>> library(spgrass6)
>>> Loading required package: sp
>>> Loading required package: rgdal
>>> Geospatial Data Abstraction Library extensions to R successfully loaded
>>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>>> Path to GDAL shared files: /usr/local/share/gdal
>>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>>> Path to PROJ.4 shared files: (autodetected)
>>> Loading required package: XML
>>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>>> tempdir())
>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol: G__no_gisinit
>>> g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
>>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>>> asText == :
>>> argument is of length zero
>>> Error in parseGRASS(cmd) : g.region not parsed
>>> 
>>>> sessionInfo()
>>> R version 2.11.1 (2010-05-31)
>>> i386-redhat-linux-gnu
>>> 
>>> locale:
>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>> 
>>> attached base packages:
>>> [1] stats graphics grDevices utils datasets methods base
>>> 
>>> other attached packages:
>>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>> 
>>> 
>>> Any ideas about what I am doing wrong?
>>> 
>>> Thanks, Bill
>>> 
>>> 
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wdmccoy at geo.umass.edu  Sat Aug 28 19:44:49 2010
From: wdmccoy at geo.umass.edu (William McCoy)
Date: Sat, 28 Aug 2010 13:44:49 -0400
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>
References: <4C785965.90405@geo.umass.edu>
	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
	<4C793C06.1080600@geo.umass.edu>
	<alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>
Message-ID: <4C794B11.2010808@geo.umass.edu>

On 08/28/2010 01:15 PM, Roger Bivand wrote:
> On Sat, 28 Aug 2010, William McCoy wrote:
>
>> Roger,
>>
>> I think your suspicions are correct. Here is the output from debug
>> after the PATH setting if():
>>
>> Browse[2]> Sys.getenv("PATH")
>>
>>
>>
>> PATH
>> "/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts"
>> Browse[2]> list.files(Sys.getenv("PATH"))
>> character(0)
>> Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
>>
>>
>> LD_LIBRARY_PATH
>> "/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib"
>> Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>> character(0)
>>
>>
>> Since I last used spgrass6 many months ago, I have installed
>> grass64svn along with grass63, which was long ago installed as a
>> fedora rpm. So my PATH looks like this:
>>
>>
>> [wdmccoy at boreas ~]$ echo $PATH
>> /usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin
>>
>>
>>
>> But my LD_LIBRARY_PATH looks like this:
>>
>> [wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH
>>
>>
>> I.e., there is nothing in LD_LIBRARY_PATH. The reason grass64 works by
>> itself (outside of R) is because I have a grass64.conf file in
>> /etc/ld.so.conf.d and that .conf file contains:
>>
>> /usr/local/grass-6.4.0svn/lib
>>
>>
>> What do you recommend?
>
> This is a bit difficult to say, but trying to set LD_LIBRARY_PATH before
> starting R to the correct value:
>
> export LD_LIBRARY_PATH=/usr/local/grass-6.4.0svn/lib
>
> and/or ensuring that ldconfig was run, might help.
>
> Have you tried using gisBase = "/usr/local/grass-6.4.0svn" without the
> terminating "/"?
>
> Hope this goes in the right direction,
>
> Roger
>

Yes, I had already tried gisBase = "/usr/local/grass-6.4.0svn" without 
the terminating "/".  In fact, that's what I had used when I did the 
debugging on initGRASS().  So that doesn't seem to help.

I think ldconfig is always run on startup, but I ran it again just now 
and it made no difference.  And setting and exporting LD_LIBRARY_PATH 
doesn't help either.

I should also mention that I had tried to use my grass63 installation 
for gisBase a couple of times and that gave me the same results.

In case I didn't mention it, this is all being done on Fedora 13.  The 
last time that I used spgrass6 successfully was on Fedora 12 on the same 
computer.

Any other ideas?


Thanks, Bill


>>
>>
>> Thanks, Bill
>>
>>
>> On 08/28/2010 05:41 AM, Roger Bivand wrote:
>>> On Fri, 27 Aug 2010, William McCoy wrote:
>>>
>>>> I am using spgrass6, but I can't seem to initiate a grass session. I
>>>> managed to do this correctly months ago, but can't seem to now. Here
>>>> is my code and sessionInfo:
>>>
>>> Something has happened to your GRASS installation and/or the
>>> LD_LIBRARY_PATH environment variable. The GRASS binary modules are being
>>> found, but the libraries (shared objects) they call are not. Try to set
>>> debug(initGRASS), then step through looking at what is in environment
>>> variables, etc. After the if () for conditionally setting the PATH, look
>>> at:
>>>
>>> Sys.getenv("PATH")
>>> list.files(Sys.getenv("PATH"))
>>>
>>> and similarly for LD_LIBRARY_PATH:
>>>
>>> Sys.getenv("LD_LIBRARY_PATH")
>>> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>
>>> I suspect that the test:
>>>
>>> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
>>> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>>>
>>> is not empty, so the LD_LIBRARY_PATH does not get edited to include the
>>> actual locations of the *.so files.
>>>
>>> Have you changed the definitions of these environment variables in a
>>> .bashrc or similar between this working and no longer working? Before
>>> starting R, say:
>>>
>>> echo $PATH
>>> echo $LD_LIBRARY_PATH
>>>
>>> to see if that sheds any light on things.
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>
>>>>
>>>>> library(spgrass6)
>>>> Loading required package: sp
>>>> Loading required package: rgdal
>>>> Geospatial Data Abstraction Library extensions to R successfully loaded
>>>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>>>> Path to GDAL shared files: /usr/local/share/gdal
>>>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>>>> Path to PROJ.4 shared files: (autodetected)
>>>> Loading required package: XML
>>>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>>>> tempdir())
>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>> G__no_gisinit
>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>> G__no_gisinit
>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>> G__no_gisinit
>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>> G__no_gisinit
>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>> G__no_gisinit
>>>> g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
>>>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>>>> asText == :
>>>> argument is of length zero
>>>> Error in parseGRASS(cmd) : g.region not parsed
>>>>
>>>>> sessionInfo()
>>>> R version 2.11.1 (2010-05-31)
>>>> i386-redhat-linux-gnu
>>>>
>>>> locale:
>>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats graphics grDevices utils datasets methods base
>>>>
>>>> other attached packages:
>>>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>>>
>>>>
>>>> Any ideas about what I am doing wrong?
>>>>
>>>> Thanks, Bill
>>>>
>>>>
>>>
>>
>>
>>
>


-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA 01003


From Roger.Bivand at nhh.no  Sat Aug 28 19:57:53 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Aug 2010 19:57:53 +0200 (CEST)
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <4C794B11.2010808@geo.umass.edu>
References: <4C785965.90405@geo.umass.edu>
	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
	<4C793C06.1080600@geo.umass.edu>
	<alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>
	<4C794B11.2010808@geo.umass.edu>
Message-ID: <alpine.LRH.2.00.1008281950420.17134@reclus.nhh.no>

On Sat, 28 Aug 2010, William McCoy wrote:

> On 08/28/2010 01:15 PM, Roger Bivand wrote:
>> On Sat, 28 Aug 2010, William McCoy wrote:
>> 
>>> Roger,
>>> 
>>> I think your suspicions are correct. Here is the output from debug
>>> after the PATH setting if():
>>> 
>>> Browse[2]> Sys.getenv("PATH")
>>> 
>>> 
>>> 
>>> PATH
>>> "/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts"
>>> Browse[2]> list.files(Sys.getenv("PATH"))
>>> character(0)
>>> Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
>>> 
>>> 
>>> LD_LIBRARY_PATH
>>> "/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib"
>>> Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>> character(0)
>>> 
>>> 
>>> Since I last used spgrass6 many months ago, I have installed
>>> grass64svn along with grass63, which was long ago installed as a
>>> fedora rpm. So my PATH looks like this:
>>> 
>>> 
>>> [wdmccoy at boreas ~]$ echo $PATH
>>> /usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin
>>> 
>>> 
>>> 
>>> But my LD_LIBRARY_PATH looks like this:
>>> 
>>> [wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH
>>> 
>>> 
>>> I.e., there is nothing in LD_LIBRARY_PATH. The reason grass64 works by
>>> itself (outside of R) is because I have a grass64.conf file in
>>> /etc/ld.so.conf.d and that .conf file contains:
>>> 
>>> /usr/local/grass-6.4.0svn/lib
>>> 
>>> 
>>> What do you recommend?
>> 
>> This is a bit difficult to say, but trying to set LD_LIBRARY_PATH before
>> starting R to the correct value:
>> 
>> export LD_LIBRARY_PATH=/usr/local/grass-6.4.0svn/lib
>> 
>> and/or ensuring that ldconfig was run, might help.
>> 
>> Have you tried using gisBase = "/usr/local/grass-6.4.0svn" without the
>> terminating "/"?
>> 
>> Hope this goes in the right direction,
>> 
>> Roger
>> 
>
> Yes, I had already tried gisBase = "/usr/local/grass-6.4.0svn" without the 
> terminating "/".  In fact, that's what I had used when I did the debugging on 
> initGRASS().  So that doesn't seem to help.
>
> I think ldconfig is always run on startup, but I ran it again just now and it 
> made no difference.  And setting and exporting LD_LIBRARY_PATH doesn't help 
> either.
>
> I should also mention that I had tried to use my grass63 installation for 
> gisBase a couple of times and that gave me the same results.
>
> In case I didn't mention it, this is all being done on Fedora 13.  The last 
> time that I used spgrass6 successfully was on Fedora 12 on the same computer.
>
> Any other ideas?

Trying ldd on GRASS modules when running GRASS outside R to work out which 
shared object library they are using. I run Fedora 13 (among others) so I 
doubt that it is the system, rather some changes in your installed 
software that occurred at around the same time. Using ldd may help. When I 
type:

> ldd /home/rsb/topics/grass/g64_rc6/grass-6.4.0RC6/bin/g.region

I see an extra directory level before the /bin, /lib, etc., both in the 
input and the output, but your mileage may vary.

Roger

PS: Could I suggest moving this thread to statsgrass, which is 
specifically for the R/GRASS interface? Could you summarise there to 
attract attention from GRASS people (who are not too busy with FOSS4G in 
Barcelona)?

>
>
> Thanks, Bill
>
>
>>> 
>>> 
>>> Thanks, Bill
>>> 
>>> 
>>> On 08/28/2010 05:41 AM, Roger Bivand wrote:
>>>> On Fri, 27 Aug 2010, William McCoy wrote:
>>>> 
>>>>> I am using spgrass6, but I can't seem to initiate a grass session. I
>>>>> managed to do this correctly months ago, but can't seem to now. Here
>>>>> is my code and sessionInfo:
>>>> 
>>>> Something has happened to your GRASS installation and/or the
>>>> LD_LIBRARY_PATH environment variable. The GRASS binary modules are being
>>>> found, but the libraries (shared objects) they call are not. Try to set
>>>> debug(initGRASS), then step through looking at what is in environment
>>>> variables, etc. After the if () for conditionally setting the PATH, look
>>>> at:
>>>> 
>>>> Sys.getenv("PATH")
>>>> list.files(Sys.getenv("PATH"))
>>>> 
>>>> and similarly for LD_LIBRARY_PATH:
>>>> 
>>>> Sys.getenv("LD_LIBRARY_PATH")
>>>> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>> 
>>>> I suspect that the test:
>>>> 
>>>> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
>>>> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>>>> 
>>>> is not empty, so the LD_LIBRARY_PATH does not get edited to include the
>>>> actual locations of the *.so files.
>>>> 
>>>> Have you changed the definitions of these environment variables in a
>>>> .bashrc or similar between this working and no longer working? Before
>>>> starting R, say:
>>>> 
>>>> echo $PATH
>>>> echo $LD_LIBRARY_PATH
>>>> 
>>>> to see if that sheds any light on things.
>>>> 
>>>> Hope this helps,
>>>> 
>>>> Roger
>>>> 
>>>> 
>>>>> 
>>>>>> library(spgrass6)
>>>>> Loading required package: sp
>>>>> Loading required package: rgdal
>>>>> Geospatial Data Abstraction Library extensions to R successfully loaded
>>>>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>>>>> Path to GDAL shared files: /usr/local/share/gdal
>>>>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>>>>> Path to PROJ.4 shared files: (autodetected)
>>>>> Loading required package: XML
>>>>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>>>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>>>>> tempdir())
>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>> G__no_gisinit
>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>> G__no_gisinit
>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>> G__no_gisinit
>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>> G__no_gisinit
>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>> G__no_gisinit
>>>>> g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
>>>>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>>>>> asText == :
>>>>> argument is of length zero
>>>>> Error in parseGRASS(cmd) : g.region not parsed
>>>>> 
>>>>>> sessionInfo()
>>>>> R version 2.11.1 (2010-05-31)
>>>>> i386-redhat-linux-gnu
>>>>> 
>>>>> locale:
>>>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>>>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>>>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>> 
>>>>> attached base packages:
>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>> 
>>>>> other attached packages:
>>>>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>>>> 
>>>>> loaded via a namespace (and not attached):
>>>>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>>>> 
>>>>> 
>>>>> Any ideas about what I am doing wrong?
>>>>> 
>>>>> Thanks, Bill
>>>>> 
>>>>> 
>>>> 
>>> 
>>> 
>>> 
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From wdmccoy at geo.umass.edu  Sat Aug 28 20:09:02 2010
From: wdmccoy at geo.umass.edu (William McCoy)
Date: Sat, 28 Aug 2010 14:09:02 -0400
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <alpine.LRH.2.00.1008281950420.17134@reclus.nhh.no>
References: <4C785965.90405@geo.umass.edu>
	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
	<4C793C06.1080600@geo.umass.edu>
	<alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>
	<4C794B11.2010808@geo.umass.edu>
	<alpine.LRH.2.00.1008281950420.17134@reclus.nhh.no>
Message-ID: <4C7950BE.3090701@geo.umass.edu>

On 08/28/2010 01:57 PM, Roger Bivand wrote:
> On Sat, 28 Aug 2010, William McCoy wrote:
>
>> On 08/28/2010 01:15 PM, Roger Bivand wrote:
>>> On Sat, 28 Aug 2010, William McCoy wrote:
>>>
>>>> Roger,
>>>>
>>>> I think your suspicions are correct. Here is the output from debug
>>>> after the PATH setting if():
>>>>
>>>> Browse[2]> Sys.getenv("PATH")
>>>>
>>>>
>>>>
>>>> PATH
>>>> "/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts"
>>>>
>>>> Browse[2]> list.files(Sys.getenv("PATH"))
>>>> character(0)
>>>> Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
>>>>
>>>>
>>>> LD_LIBRARY_PATH
>>>> "/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib"
>>>>
>>>> Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>> character(0)
>>>>
>>>>
>>>> Since I last used spgrass6 many months ago, I have installed
>>>> grass64svn along with grass63, which was long ago installed as a
>>>> fedora rpm. So my PATH looks like this:
>>>>
>>>>
>>>> [wdmccoy at boreas ~]$ echo $PATH
>>>> /usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin
>>>>
>>>>
>>>>
>>>>
>>>> But my LD_LIBRARY_PATH looks like this:
>>>>
>>>> [wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH
>>>>
>>>>
>>>> I.e., there is nothing in LD_LIBRARY_PATH. The reason grass64 works by
>>>> itself (outside of R) is because I have a grass64.conf file in
>>>> /etc/ld.so.conf.d and that .conf file contains:
>>>>
>>>> /usr/local/grass-6.4.0svn/lib
>>>>
>>>>
>>>> What do you recommend?
>>>
>>> This is a bit difficult to say, but trying to set LD_LIBRARY_PATH before
>>> starting R to the correct value:
>>>
>>> export LD_LIBRARY_PATH=/usr/local/grass-6.4.0svn/lib
>>>
>>> and/or ensuring that ldconfig was run, might help.
>>>
>>> Have you tried using gisBase = "/usr/local/grass-6.4.0svn" without the
>>> terminating "/"?
>>>
>>> Hope this goes in the right direction,
>>>
>>> Roger
>>>
>>
>> Yes, I had already tried gisBase = "/usr/local/grass-6.4.0svn" without
>> the terminating "/". In fact, that's what I had used when I did the
>> debugging on initGRASS(). So that doesn't seem to help.
>>
>> I think ldconfig is always run on startup, but I ran it again just now
>> and it made no difference. And setting and exporting LD_LIBRARY_PATH
>> doesn't help either.
>>
>> I should also mention that I had tried to use my grass63 installation
>> for gisBase a couple of times and that gave me the same results.
>>
>> In case I didn't mention it, this is all being done on Fedora 13. The
>> last time that I used spgrass6 successfully was on Fedora 12 on the
>> same computer.
>>
>> Any other ideas?
>
> Trying ldd on GRASS modules when running GRASS outside R to work out
> which shared object library they are using. I run Fedora 13 (among
> others) so I doubt that it is the system, rather some changes in your
> installed software that occurred at around the same time. Using ldd may
> help. When I type:
>
>> ldd /home/rsb/topics/grass/g64_rc6/grass-6.4.0RC6/bin/g.region
>
> I see an extra directory level before the /bin, /lib, etc., both in the
> input and the output, but your mileage may vary.
>
> Roger
>
> PS: Could I suggest moving this thread to statsgrass, which is
> specifically for the R/GRASS interface? Could you summarise there to
> attract attention from GRASS people (who are not too busy with FOSS4G in
> Barcelona)?
>

I will try summarizing this issue in a message to statsgrass this afternoon.

With regard to ldd, I don't see the extra directory level:

[wdmccoy at boreas ~]$ ldd /usr/local/grass-6.4.0svn/bin/g.region
         linux-gate.so.1 =>  (0x0036c000)
         libgrass_vect.so => 
/usr/local/grass-6.4.0svn/lib/libgrass_vect.so (0x00110000)
         libgrass_dbmibase.so => 
/usr/local/grass-6.4.0svn/lib/libgrass_dbmibase.so (0x00f52000)
...


Thanks, Bill


>>
>>
>> Thanks, Bill
>>
>>
>>>>
>>>>
>>>> Thanks, Bill
>>>>
>>>>
>>>> On 08/28/2010 05:41 AM, Roger Bivand wrote:
>>>>> On Fri, 27 Aug 2010, William McCoy wrote:
>>>>>
>>>>>> I am using spgrass6, but I can't seem to initiate a grass session. I
>>>>>> managed to do this correctly months ago, but can't seem to now. Here
>>>>>> is my code and sessionInfo:
>>>>>
>>>>> Something has happened to your GRASS installation and/or the
>>>>> LD_LIBRARY_PATH environment variable. The GRASS binary modules are
>>>>> being
>>>>> found, but the libraries (shared objects) they call are not. Try to
>>>>> set
>>>>> debug(initGRASS), then step through looking at what is in environment
>>>>> variables, etc. After the if () for conditionally setting the PATH,
>>>>> look
>>>>> at:
>>>>>
>>>>> Sys.getenv("PATH")
>>>>> list.files(Sys.getenv("PATH"))
>>>>>
>>>>> and similarly for LD_LIBRARY_PATH:
>>>>>
>>>>> Sys.getenv("LD_LIBRARY_PATH")
>>>>> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>>>
>>>>> I suspect that the test:
>>>>>
>>>>> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
>>>>> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>>>>>
>>>>> is not empty, so the LD_LIBRARY_PATH does not get edited to include
>>>>> the
>>>>> actual locations of the *.so files.
>>>>>
>>>>> Have you changed the definitions of these environment variables in a
>>>>> .bashrc or similar between this working and no longer working? Before
>>>>> starting R, say:
>>>>>
>>>>> echo $PATH
>>>>> echo $LD_LIBRARY_PATH
>>>>>
>>>>> to see if that sheds any light on things.
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Roger
>>>>>
>>>>>
>>>>>>
>>>>>>> library(spgrass6)
>>>>>> Loading required package: sp
>>>>>> Loading required package: rgdal
>>>>>> Geospatial Data Abstraction Library extensions to R successfully
>>>>>> loaded
>>>>>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>>>>>> Path to GDAL shared files: /usr/local/share/gdal
>>>>>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>>>>>> Path to PROJ.4 shared files: (autodetected)
>>>>>> Loading required package: XML
>>>>>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>>>>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>>>>>> tempdir())
>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>> G__no_gisinit
>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>> G__no_gisinit
>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>> G__no_gisinit
>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>> G__no_gisinit
>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>> G__no_gisinit
>>>>>> g.region: symbol lookup error: g.region: undefined symbol: G__gisinit
>>>>>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>>>>>> asText == :
>>>>>> argument is of length zero
>>>>>> Error in parseGRASS(cmd) : g.region not parsed
>>>>>>
>>>>>>> sessionInfo()
>>>>>> R version 2.11.1 (2010-05-31)
>>>>>> i386-redhat-linux-gnu
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>>>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>>>>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>>>>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>>>>>
>>>>>>
>>>>>> Any ideas about what I am doing wrong?
>>>>>>
>>>>>> Thanks, Bill
>>>>>>
>>>>>>
>>>>>
>>>>
>>>>
>>>>
>>>
>>
>>
>>
>


-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA 01003


From ricardorodot02 at gmail.com  Sat Aug 28 20:25:11 2010
From: ricardorodot02 at gmail.com (=?ISO-8859-1?Q?Ricardo_Rodr=EDguez?=)
Date: Sat, 28 Aug 2010 13:25:11 -0500
Subject: [R-sig-Geo] read wfs o xml
Message-ID: <AANLkTi=LTT4tgSjqtvGo2YiMrLgHM0e_ijoQF3MwTYTO@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100828/c1ded4d6/attachment.pl>

From ricardorodot02 at gmail.com  Sat Aug 28 21:25:53 2010
From: ricardorodot02 at gmail.com (=?ISO-8859-1?Q?Ricardo_Rodr=EDguez?=)
Date: Sat, 28 Aug 2010 14:25:53 -0500
Subject: [R-sig-Geo] matrix of attributes
Message-ID: <AANLkTinhRW+ULipUmp5zdqkr0P8RxrBr=QOH4Sy=pZFj@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100828/225a03ab/attachment.pl>

From g_arun12784 at yahoo.com  Sun Aug 29 15:31:46 2010
From: g_arun12784 at yahoo.com (G.ARUN KUMAR)
Date: Sun, 29 Aug 2010 19:01:46 +0530 (IST)
Subject: [R-sig-Geo] Contour Plot - Map
Message-ID: <624899.96294.qm@web94705.mail.in2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100829/8f464cad/attachment.pl>

From wdmccoy at geo.umass.edu  Sun Aug 29 18:32:14 2010
From: wdmccoy at geo.umass.edu (William McCoy)
Date: Sun, 29 Aug 2010 12:32:14 -0400
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <4C7950BE.3090701@geo.umass.edu>
References: <4C785965.90405@geo.umass.edu>	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>	<4C793C06.1080600@geo.umass.edu>	<alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>	<4C794B11.2010808@geo.umass.edu>	<alpine.LRH.2.00.1008281950420.17134@reclus.nhh.no>
	<4C7950BE.3090701@geo.umass.edu>
Message-ID: <4C7A8B8E.40300@geo.umass.edu>

Since this issue was first brought up on this list and then continued on 
grass-stats and grass-dev, I think I should summarize what has been 
found out so far regarding this issue.

As mentioned below, I have grass63 installed on this computer along with 
the grass64svn that I was trying to access via initGRASS() in spgrass6. 
  Apparently, the grass63 libraries were being accessed before the 
grass64svn libraries were found and, hence, the symbol lookup error.

I have found that if I modify initGRASS() to prepend the grass64svn 
directories, rather than append them, to PATH and LD_LIBRARY_PATH, the 
error does not occur.  I don't know if this is the best solution, but it 
works temporarily and at least we know the source of the problem.  See 
here for more details on the source of the problem and the temporary "fix":

http://lists.osgeo.org/pipermail/grass-stats/2010-August/001268.html

Thanks to Roger Bivand, Markus Neteler, and Glynn Clements (in 
chronological order) for sorting this out.


Bill


On 08/28/2010 02:09 PM, William McCoy wrote:
> On 08/28/2010 01:57 PM, Roger Bivand wrote:
>> On Sat, 28 Aug 2010, William McCoy wrote:
>>
>>> On 08/28/2010 01:15 PM, Roger Bivand wrote:
>>>> On Sat, 28 Aug 2010, William McCoy wrote:
>>>>
>>>>> Roger,
>>>>>
>>>>> I think your suspicions are correct. Here is the output from debug
>>>>> after the PATH setting if():
>>>>>
>>>>> Browse[2]> Sys.getenv("PATH")
>>>>>
>>>>>
>>>>>
>>>>> PATH
>>>>> "/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts"
>>>>>
>>>>>
>>>>> Browse[2]> list.files(Sys.getenv("PATH"))
>>>>> character(0)
>>>>> Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
>>>>>
>>>>>
>>>>> LD_LIBRARY_PATH
>>>>> "/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib"
>>>>>
>>>>>
>>>>> Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>>> character(0)
>>>>>
>>>>>
>>>>> Since I last used spgrass6 many months ago, I have installed
>>>>> grass64svn along with grass63, which was long ago installed as a
>>>>> fedora rpm. So my PATH looks like this:
>>>>>
>>>>>
>>>>> [wdmccoy at boreas ~]$ echo $PATH
>>>>> /usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> But my LD_LIBRARY_PATH looks like this:
>>>>>
>>>>> [wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH
>>>>>
>>>>>
>>>>> I.e., there is nothing in LD_LIBRARY_PATH. The reason grass64 works by
>>>>> itself (outside of R) is because I have a grass64.conf file in
>>>>> /etc/ld.so.conf.d and that .conf file contains:
>>>>>
>>>>> /usr/local/grass-6.4.0svn/lib
>>>>>
>>>>>
>>>>> What do you recommend?
>>>>
>>>> This is a bit difficult to say, but trying to set LD_LIBRARY_PATH
>>>> before
>>>> starting R to the correct value:
>>>>
>>>> export LD_LIBRARY_PATH=/usr/local/grass-6.4.0svn/lib
>>>>
>>>> and/or ensuring that ldconfig was run, might help.
>>>>
>>>> Have you tried using gisBase = "/usr/local/grass-6.4.0svn" without the
>>>> terminating "/"?
>>>>
>>>> Hope this goes in the right direction,
>>>>
>>>> Roger
>>>>
>>>
>>> Yes, I had already tried gisBase = "/usr/local/grass-6.4.0svn" without
>>> the terminating "/". In fact, that's what I had used when I did the
>>> debugging on initGRASS(). So that doesn't seem to help.
>>>
>>> I think ldconfig is always run on startup, but I ran it again just now
>>> and it made no difference. And setting and exporting LD_LIBRARY_PATH
>>> doesn't help either.
>>>
>>> I should also mention that I had tried to use my grass63 installation
>>> for gisBase a couple of times and that gave me the same results.
>>>
>>> In case I didn't mention it, this is all being done on Fedora 13. The
>>> last time that I used spgrass6 successfully was on Fedora 12 on the
>>> same computer.
>>>
>>> Any other ideas?
>>
>> Trying ldd on GRASS modules when running GRASS outside R to work out
>> which shared object library they are using. I run Fedora 13 (among
>> others) so I doubt that it is the system, rather some changes in your
>> installed software that occurred at around the same time. Using ldd may
>> help. When I type:
>>
>>> ldd /home/rsb/topics/grass/g64_rc6/grass-6.4.0RC6/bin/g.region
>>
>> I see an extra directory level before the /bin, /lib, etc., both in the
>> input and the output, but your mileage may vary.
>>
>> Roger
>>
>> PS: Could I suggest moving this thread to statsgrass, which is
>> specifically for the R/GRASS interface? Could you summarise there to
>> attract attention from GRASS people (who are not too busy with FOSS4G in
>> Barcelona)?
>>
>
> I will try summarizing this issue in a message to statsgrass this
> afternoon.
>
> With regard to ldd, I don't see the extra directory level:
>
> [wdmccoy at boreas ~]$ ldd /usr/local/grass-6.4.0svn/bin/g.region
> linux-gate.so.1 => (0x0036c000)
> libgrass_vect.so => /usr/local/grass-6.4.0svn/lib/libgrass_vect.so
> (0x00110000)
> libgrass_dbmibase.so =>
> /usr/local/grass-6.4.0svn/lib/libgrass_dbmibase.so (0x00f52000)
> ...
>
>
> Thanks, Bill
>
>
>>>
>>>
>>> Thanks, Bill
>>>
>>>
>>>>>
>>>>>
>>>>> Thanks, Bill
>>>>>
>>>>>
>>>>> On 08/28/2010 05:41 AM, Roger Bivand wrote:
>>>>>> On Fri, 27 Aug 2010, William McCoy wrote:
>>>>>>
>>>>>>> I am using spgrass6, but I can't seem to initiate a grass session. I
>>>>>>> managed to do this correctly months ago, but can't seem to now. Here
>>>>>>> is my code and sessionInfo:
>>>>>>
>>>>>> Something has happened to your GRASS installation and/or the
>>>>>> LD_LIBRARY_PATH environment variable. The GRASS binary modules are
>>>>>> being
>>>>>> found, but the libraries (shared objects) they call are not. Try to
>>>>>> set
>>>>>> debug(initGRASS), then step through looking at what is in environment
>>>>>> variables, etc. After the if () for conditionally setting the PATH,
>>>>>> look
>>>>>> at:
>>>>>>
>>>>>> Sys.getenv("PATH")
>>>>>> list.files(Sys.getenv("PATH"))
>>>>>>
>>>>>> and similarly for LD_LIBRARY_PATH:
>>>>>>
>>>>>> Sys.getenv("LD_LIBRARY_PATH")
>>>>>> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>>>>
>>>>>> I suspect that the test:
>>>>>>
>>>>>> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
>>>>>> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>>>>>>
>>>>>> is not empty, so the LD_LIBRARY_PATH does not get edited to include
>>>>>> the
>>>>>> actual locations of the *.so files.
>>>>>>
>>>>>> Have you changed the definitions of these environment variables in a
>>>>>> .bashrc or similar between this working and no longer working? Before
>>>>>> starting R, say:
>>>>>>
>>>>>> echo $PATH
>>>>>> echo $LD_LIBRARY_PATH
>>>>>>
>>>>>> to see if that sheds any light on things.
>>>>>>
>>>>>> Hope this helps,
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>
>>>>>>>
>>>>>>>> library(spgrass6)
>>>>>>> Loading required package: sp
>>>>>>> Loading required package: rgdal
>>>>>>> Geospatial Data Abstraction Library extensions to R successfully
>>>>>>> loaded
>>>>>>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>>>>>>> Path to GDAL shared files: /usr/local/share/gdal
>>>>>>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>>>>>>> Path to PROJ.4 shared files: (autodetected)
>>>>>>> Loading required package: XML
>>>>>>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>>>>>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>>>>>>> tempdir())
>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>> G__no_gisinit
>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>> G__no_gisinit
>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>> G__no_gisinit
>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>> G__no_gisinit
>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>> G__no_gisinit
>>>>>>> g.region: symbol lookup error: g.region: undefined symbol:
>>>>>>> G__gisinit
>>>>>>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>>>>>>> asText == :
>>>>>>> argument is of length zero
>>>>>>> Error in parseGRASS(cmd) : g.region not parsed
>>>>>>>
>>>>>>>> sessionInfo()
>>>>>>> R version 2.11.1 (2010-05-31)
>>>>>>> i386-redhat-linux-gnu
>>>>>>>
>>>>>>> locale:
>>>>>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>>>>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>>>>>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>>>>>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>>>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>>>
>>>>>>> attached base packages:
>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>
>>>>>>> other attached packages:
>>>>>>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>>>>>>
>>>>>>> loaded via a namespace (and not attached):
>>>>>>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>>>>>>
>>>>>>>
>>>>>>> Any ideas about what I am doing wrong?
>>>>>>>
>>>>>>> Thanks, Bill
>>>>>>>
>>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>
>>>
>>
>
>


-- 
William D. McCoy
Geosciences
University of Massachusetts
Amherst, MA 01003


From Roger.Bivand at nhh.no  Sun Aug 29 19:37:31 2010
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 29 Aug 2010 19:37:31 +0200 (CEST)
Subject: [R-sig-Geo] can't initiate Grass with initGRASS()
In-Reply-To: <4C7A8B8E.40300@geo.umass.edu>
References: <4C785965.90405@geo.umass.edu>
	<alpine.LRH.2.00.1008281131270.16481@reclus.nhh.no>
	<4C793C06.1080600@geo.umass.edu>
	<alpine.LRH.2.00.1008281909190.17134@reclus.nhh.no>
	<4C794B11.2010808@geo.umass.edu>
	<alpine.LRH.2.00.1008281950420.17134@reclus.nhh.no>
	<4C7950BE.3090701@geo.umass.edu> <4C7A8B8E.40300@geo.umass.edu>
Message-ID: <alpine.LRH.2.00.1008291935430.22682@reclus.nhh.no>

On Sun, 29 Aug 2010, William McCoy wrote:

> Since this issue was first brought up on this list and then continued on 
> grass-stats and grass-dev, I think I should summarize what has been found out 
> so far regarding this issue.
>
> As mentioned below, I have grass63 installed on this computer along with the 
> grass64svn that I was trying to access via initGRASS() in spgrass6. 
> Apparently, the grass63 libraries were being accessed before the grass64svn 
> libraries were found and, hence, the symbol lookup error.
>
> I have found that if I modify initGRASS() to prepend the grass64svn 
> directories, rather than append them, to PATH and LD_LIBRARY_PATH, the error 
> does not occur.  I don't know if this is the best solution, but it works 
> temporarily and at least we know the source of the problem.  See here for 
> more details on the source of the problem and the temporary "fix":
>
> http://lists.osgeo.org/pipermail/grass-stats/2010-August/001268.html
>
> Thanks to Roger Bivand, Markus Neteler, and Glynn Clements (in chronological 
> order) for sorting this out.
>

I will most likely adopt this ordering in the next release of spgrass6, as 
it then matches the ordeing that GRASS itself uses on startup. When there 
are multiple installations of interfaced software components, it can 
happen.

Roger

>
> Bill
>
>
> On 08/28/2010 02:09 PM, William McCoy wrote:
>> On 08/28/2010 01:57 PM, Roger Bivand wrote:
>>> On Sat, 28 Aug 2010, William McCoy wrote:
>>> 
>>>> On 08/28/2010 01:15 PM, Roger Bivand wrote:
>>>>> On Sat, 28 Aug 2010, William McCoy wrote:
>>>>> 
>>>>>> Roger,
>>>>>> 
>>>>>> I think your suspicions are correct. Here is the output from debug
>>>>>> after the PATH setting if():
>>>>>> 
>>>>>> Browse[2]> Sys.getenv("PATH")
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> PATH
>>>>>> "/usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin:/usr/local/grass-6.4.0svn/bin:/usr/local/grass-6.4.0svn/scripts"
>>>>>> 
>>>>>> 
>>>>>> Browse[2]> list.files(Sys.getenv("PATH"))
>>>>>> character(0)
>>>>>> Browse[2]> Sys.getenv("LD_LIBRARY_PATH")
>>>>>> 
>>>>>> 
>>>>>> LD_LIBRARY_PATH
>>>>>> "/usr/lib/R/lib:/usr/local/lib:/usr/lib/jvm/jre/lib/i386/server:/usr/lib/jvm/jre/lib/i386:/usr/lib/jvm/java/lib/i386:/usr/java/packages/lib/i386:/lib:/usr/lib:/usr/local/grass-6.4.0svn/lib"
>>>>>> 
>>>>>> 
>>>>>> Browse[2]> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>>>> character(0)
>>>>>> 
>>>>>> 
>>>>>> Since I last used spgrass6 many months ago, I have installed
>>>>>> grass64svn along with grass63, which was long ago installed as a
>>>>>> fedora rpm. So my PATH looks like this:
>>>>>> 
>>>>>> 
>>>>>> [wdmccoy at boreas ~]$ echo $PATH
>>>>>> /usr/local/texlive/2009/bin/i386-linux:/usr/lib/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/lib/ccache:/usr/local/bin:/usr/bin:/bin:/usr/local/sbin:/usr/sbin:/sbin:/home/wdmccoy/bin
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> But my LD_LIBRARY_PATH looks like this:
>>>>>> 
>>>>>> [wdmccoy at boreas ~]$ echo $LD_LIBRARY_PATH
>>>>>> 
>>>>>> 
>>>>>> I.e., there is nothing in LD_LIBRARY_PATH. The reason grass64 works by
>>>>>> itself (outside of R) is because I have a grass64.conf file in
>>>>>> /etc/ld.so.conf.d and that .conf file contains:
>>>>>> 
>>>>>> /usr/local/grass-6.4.0svn/lib
>>>>>> 
>>>>>> 
>>>>>> What do you recommend?
>>>>> 
>>>>> This is a bit difficult to say, but trying to set LD_LIBRARY_PATH
>>>>> before
>>>>> starting R to the correct value:
>>>>> 
>>>>> export LD_LIBRARY_PATH=/usr/local/grass-6.4.0svn/lib
>>>>> 
>>>>> and/or ensuring that ldconfig was run, might help.
>>>>> 
>>>>> Have you tried using gisBase = "/usr/local/grass-6.4.0svn" without the
>>>>> terminating "/"?
>>>>> 
>>>>> Hope this goes in the right direction,
>>>>> 
>>>>> Roger
>>>>> 
>>>> 
>>>> Yes, I had already tried gisBase = "/usr/local/grass-6.4.0svn" without
>>>> the terminating "/". In fact, that's what I had used when I did the
>>>> debugging on initGRASS(). So that doesn't seem to help.
>>>> 
>>>> I think ldconfig is always run on startup, but I ran it again just now
>>>> and it made no difference. And setting and exporting LD_LIBRARY_PATH
>>>> doesn't help either.
>>>> 
>>>> I should also mention that I had tried to use my grass63 installation
>>>> for gisBase a couple of times and that gave me the same results.
>>>> 
>>>> In case I didn't mention it, this is all being done on Fedora 13. The
>>>> last time that I used spgrass6 successfully was on Fedora 12 on the
>>>> same computer.
>>>> 
>>>> Any other ideas?
>>> 
>>> Trying ldd on GRASS modules when running GRASS outside R to work out
>>> which shared object library they are using. I run Fedora 13 (among
>>> others) so I doubt that it is the system, rather some changes in your
>>> installed software that occurred at around the same time. Using ldd may
>>> help. When I type:
>>> 
>>>> ldd /home/rsb/topics/grass/g64_rc6/grass-6.4.0RC6/bin/g.region
>>> 
>>> I see an extra directory level before the /bin, /lib, etc., both in the
>>> input and the output, but your mileage may vary.
>>> 
>>> Roger
>>> 
>>> PS: Could I suggest moving this thread to statsgrass, which is
>>> specifically for the R/GRASS interface? Could you summarise there to
>>> attract attention from GRASS people (who are not too busy with FOSS4G in
>>> Barcelona)?
>>> 
>> 
>> I will try summarizing this issue in a message to statsgrass this
>> afternoon.
>> 
>> With regard to ldd, I don't see the extra directory level:
>> 
>> [wdmccoy at boreas ~]$ ldd /usr/local/grass-6.4.0svn/bin/g.region
>> linux-gate.so.1 => (0x0036c000)
>> libgrass_vect.so => /usr/local/grass-6.4.0svn/lib/libgrass_vect.so
>> (0x00110000)
>> libgrass_dbmibase.so =>
>> /usr/local/grass-6.4.0svn/lib/libgrass_dbmibase.so (0x00f52000)
>> ...
>> 
>> 
>> Thanks, Bill
>> 
>> 
>>>> 
>>>> 
>>>> Thanks, Bill
>>>> 
>>>> 
>>>>>> 
>>>>>> 
>>>>>> Thanks, Bill
>>>>>> 
>>>>>> 
>>>>>> On 08/28/2010 05:41 AM, Roger Bivand wrote:
>>>>>>> On Fri, 27 Aug 2010, William McCoy wrote:
>>>>>>> 
>>>>>>>> I am using spgrass6, but I can't seem to initiate a grass session. I
>>>>>>>> managed to do this correctly months ago, but can't seem to now. Here
>>>>>>>> is my code and sessionInfo:
>>>>>>> 
>>>>>>> Something has happened to your GRASS installation and/or the
>>>>>>> LD_LIBRARY_PATH environment variable. The GRASS binary modules are
>>>>>>> being
>>>>>>> found, but the libraries (shared objects) they call are not. Try to
>>>>>>> set
>>>>>>> debug(initGRASS), then step through looking at what is in environment
>>>>>>> variables, etc. After the if () for conditionally setting the PATH,
>>>>>>> look
>>>>>>> at:
>>>>>>> 
>>>>>>> Sys.getenv("PATH")
>>>>>>> list.files(Sys.getenv("PATH"))
>>>>>>> 
>>>>>>> and similarly for LD_LIBRARY_PATH:
>>>>>>> 
>>>>>>> Sys.getenv("LD_LIBRARY_PATH")
>>>>>>> list.files(Sys.getenv("LD_LIBRARY_PATH"))
>>>>>>> 
>>>>>>> I suspect that the test:
>>>>>>> 
>>>>>>> eLDPATH <- Sys.getenv("LD_LIBRARY_PATH")
>>>>>>> grep(basename(Sys.getenv("GISBASE")), eLDPATH)
>>>>>>> 
>>>>>>> is not empty, so the LD_LIBRARY_PATH does not get edited to include
>>>>>>> the
>>>>>>> actual locations of the *.so files.
>>>>>>> 
>>>>>>> Have you changed the definitions of these environment variables in a
>>>>>>> .bashrc or similar between this working and no longer working? Before
>>>>>>> starting R, say:
>>>>>>> 
>>>>>>> echo $PATH
>>>>>>> echo $LD_LIBRARY_PATH
>>>>>>> 
>>>>>>> to see if that sheds any light on things.
>>>>>>> 
>>>>>>> Hope this helps,
>>>>>>> 
>>>>>>> Roger
>>>>>>> 
>>>>>>> 
>>>>>>>> 
>>>>>>>>> library(spgrass6)
>>>>>>>> Loading required package: sp
>>>>>>>> Loading required package: rgdal
>>>>>>>> Geospatial Data Abstraction Library extensions to R successfully
>>>>>>>> loaded
>>>>>>>> Loaded GDAL runtime: GDAL 1.7.2, released 2010/04/23
>>>>>>>> Path to GDAL shared files: /usr/local/share/gdal
>>>>>>>> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>>>>>>>> Path to PROJ.4 shared files: (autodetected)
>>>>>>>> Loading required package: XML
>>>>>>>> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>>>>>>>>> loc <- initGRASS(gisBase = "/usr/local/grass-6.4.0svn/", home =
>>>>>>>>> tempdir())
>>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>>> G__no_gisinit
>>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>>> G__no_gisinit
>>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>>> G__no_gisinit
>>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>>> G__no_gisinit
>>>>>>>> g.gisenv: symbol lookup error: g.gisenv: undefined symbol:
>>>>>>>> G__no_gisinit
>>>>>>>> g.region: symbol lookup error: g.region: undefined symbol:
>>>>>>>> G__gisinit
>>>>>>>> Error in if (file.exists(file) == FALSE) if (!missing(asText) &&
>>>>>>>> asText == :
>>>>>>>> argument is of length zero
>>>>>>>> Error in parseGRASS(cmd) : g.region not parsed
>>>>>>>> 
>>>>>>>>> sessionInfo()
>>>>>>>> R version 2.11.1 (2010-05-31)
>>>>>>>> i386-redhat-linux-gnu
>>>>>>>> 
>>>>>>>> locale:
>>>>>>>> [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C
>>>>>>>> [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>>>>>>> [5] LC_MONETARY=C LC_MESSAGES=en_US.UTF-8
>>>>>>>> [7] LC_PAPER=en_US.UTF-8 LC_NAME=C
>>>>>>>> [9] LC_ADDRESS=C LC_TELEPHONE=C
>>>>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>>>> 
>>>>>>>> attached base packages:
>>>>>>>> [1] stats graphics grDevices utils datasets methods base
>>>>>>>> 
>>>>>>>> other attached packages:
>>>>>>>> [1] spgrass6_0.6-19 XML_3.1-1 rgdal_0.6-28 sp_0.9-66
>>>>>>>> 
>>>>>>>> loaded via a namespace (and not attached):
>>>>>>>> [1] grid_2.11.1 lattice_0.18-8 tools_2.11.1
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Any ideas about what I am doing wrong?
>>>>>>>> 
>>>>>>>> Thanks, Bill
>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>>> 
>>>> 
>>> 
>> 
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From hhamidghorbani at gmail.com  Sun Aug 29 23:32:19 2010
From: hhamidghorbani at gmail.com (Hamid Ghorbani)
Date: Mon, 30 Aug 2010 02:02:19 +0430
Subject: [R-sig-Geo] (no subject)
Message-ID: <AANLkTikM3bcPoFizA-7adH0xJBKLfNCs5ZoFw2f+A=9r@mail.gmail.com>

Dear researcher,
Doing CSR test (based on Ripley K-function)  for an observed
homogeneous point process in a Window W with intensity \lambda(=n/a) ,
we accept the null hypothesis of CSR if  sup|\sqrt(\hat{K(t)}/\pi
-t|)<=c  for t<=t_0 (c is unknown) which yields
max(0,(t-c)^2<=\hat{K}(t)<=\pi(c+t)^2 (**)
The problem is understanding the details of  what Ripley has done
successfully based on simulation in ( [ref 1]) and (ref [2], p. 46) to
obtain the unknown factor c.
One of facts we have is that \hat{K}(t) converges  to a homogeneous
PPP of rate 2\pi*t *n^2 /a   ( [ref 1]).
(ref [2], p. 46)  has mentioned with no details(!) that "simulation
based on equation (**) shows c=1.45*\sqrt(a./n)" . My question is how?
Ripley  in ( [ref 1]), speaks also  about ?first exit time
distribution?  of a homogeneous Poisson point process (PPP) from
moving boundary max(0,(t-c)^2<=\hat{K}(t)<=\pi(c+t)^2 . I don?t know
whether or not this fact has been used in simulation to obtain the
factor c. If yes how?
Sorry for disturb with this long (unrelated) question.
Yours,
Hamid
[1] Ripley, B.D. (1979) Tests of ?randomness? for spatial point
patterns. J. Roy. Statist. Soc. B
41, 368?374.
[2] Ripley, B.D. (1991) Statistical Inference for Spatial Processes.
Cambridge University Press, Cambridge.


From Adrian.Baddeley at csiro.au  Mon Aug 30 05:38:30 2010
From: Adrian.Baddeley at csiro.au (Adrian Baddeley)
Date: Mon, 30 Aug 2010 11:38:30 +0800
Subject: [R-sig-Geo] uniform weighted (non-Gaussian) kernel in density.ppp
Message-ID: <4C7B27B6.5000406@csiro.au>

Jan Quets <Jan.Quets at ua.ac.be> heeft geschreven:

> is it possible to define a circular kernel within the function density.ppp(),
> that assigns uniform weights to every point inside the kernel.

I will add a suitable function to the next version of spatstat. 

This is not feasible using the current algorithm in density.ppp, which is based on the Fast Fourier Transform. To use the FFT we need a kernel which has finite bandwidth in the frequency domain. The uniform kernel on a disc has a sharp cliff at the circular boundary, so it has infinite frequency.

To compute the convolution with a uniform kernel requires a separate, slower algorithm (identical to the 'scan statistic' and implemented in non-R software like SatSCAN). This algorithm is already implemented in C inside spatstat, and requires only an R interface, which I will add in the next version of spatstat.


Adrian Baddeley


From Virgilio.Gomez at uclm.es  Mon Aug 30 10:24:52 2010
From: Virgilio.Gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Mon, 30 Aug 2010 10:24:52 +0200
Subject: [R-sig-Geo] Spatial data tower of babel
In-Reply-To: <AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>
References: <AANLkTikm45REAjiyR0tYYtjJ4c1Ge3KU0ksHAa2b+Ebs@mail.gmail.com>
	<alpine.LRH.2.00.1008182047040.4275@reclus.nhh.no>
	<4C75124D.50000@uni-muenster.de>
	<AANLkTi=VLAiSYQT-s3SwLLCcwBrjA1BkHhE33FsSobm9@mail.gmail.com>
Message-ID: <1283156692.2714.13.camel@Virgilio-Gomez>

Hi,

>  geoR has SpatialPointsDataFrame to geodata - but does it have the
> other way round too? Or is that in sp? It doesn't matter too much,
> since students will find them either way, but does
> as.sp(as.geodata('meuse","zinc")) get you back where you started?

But the problem is that this is not always possible. PPP objects (in
spatstat) store not only the coordinates (and marks) but also the
boundary. So, they are a mix of SpatialPoints and SpatialPolygons...

> That's what students may expect. Conversion is a big headache for new
> users and anything that makes it easier is a plus. Imagine doing
> vignette(spBabel) and getting a whole list of what formats can be
> converted together with caveats and restrictions - sounds good to me.

Yes, that would be handy. 

>  Obviously the problems are in maintainance and keeping conversions up
> to date with any changes in the format in the main package, as well as
> that this package would probably depend on all the other packages...

I am a bit with Edzer regarding a spBabel package. I would prefer to
have all these sp<->other_format in the package that provides the new
classes. The main reason is that the developer of the package will be
responsible for them, so that if any change is made to the S4 classes
the conversion functions will be updated and it will not break
compatibility with other packages/spBabel.

Well, just my two cents...

Virgilio


From gianni.lavaredo at gmail.com  Mon Aug 30 15:43:39 2010
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Mon, 30 Aug 2010 15:43:39 +0200
Subject: [R-sig-Geo] Help to Evaluation Digital Terrain Model (DTM)
Message-ID: <AANLkTikyPfyaCyoRCUrxstuVKOHG9f3Uot=sf9Q+g9Xt@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100830/73c81d1c/attachment.pl>

From gianni.lavaredo at gmail.com  Mon Aug 30 15:54:18 2010
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Mon, 30 Aug 2010 15:54:18 +0200
Subject: [R-sig-Geo] Help to Evaluation Digital Terrain Model (DTM)
Message-ID: <AANLkTi=Jhrh7d8WSa6qdtf7gLz+VU-DD_=+NbJUH5aCp@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100830/4567d37e/attachment.pl>

From p.hiemstra at geo.uu.nl  Mon Aug 30 16:27:00 2010
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 30 Aug 2010 16:27:00 +0200
Subject: [R-sig-Geo] Help to Evaluation Digital Terrain Model (DTM)
In-Reply-To: <AANLkTi=Jhrh7d8WSa6qdtf7gLz+VU-DD_=+NbJUH5aCp@mail.gmail.com>
References: <AANLkTi=Jhrh7d8WSa6qdtf7gLz+VU-DD_=+NbJUH5aCp@mail.gmail.com>
Message-ID: <4C7BBFB4.6020402@geo.uu.nl>

On 08/30/2010 03:54 PM, gianni lavaredo wrote:
> Dear Researchers,
>
> sorry for the first email but i have connection problem
>
> I am writing a code to evaluate several interpolation methods to create a
> DEM from LiDAR points. I read in bibliography several papers and methods,
> but same methods I didn't find inside the library:
>    
Hi Gianni,

I'm not sure what you tried when you looked, but you could try this in 
an R session:

??'idw'
??'spline'
??'nearest neighbor'

Or google it:

"r nearest neighbor"
"r thin plate spline"

This got me a lot of results that should be helpful to you. In addition, 
I see no kriging type interpolations, any reason to exclude them?

cheers,
Paul
> Methods
> Inverse distance weighted = library RSAGA
> completely regularised spline =  ??
> thin plate splines = library RSAGA
> splines with tension = ??
> inverse quadratic = ??
> natural neighbour = library RSAGA (there is a problem)
> Nearest Neighbour = library RSAGA
> Modifed Quadratic Shepard = library RSAGA
> Multilevel B-Spline Interpolation = library RSAGA
>
> are there another library with the missing interpolation methods?
>
> thanks in advance
> Gianni
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>    


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 253 5773
http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From mudrak at iastate.edu  Mon Aug 30 18:31:48 2010
From: mudrak at iastate.edu (Mudrak, Erika [EEOBS])
Date: Mon, 30 Aug 2010 11:31:48 -0500
Subject: [R-sig-Geo] gstat: choice of inverse distance power in idw()
	function
Message-ID: <1E7ADA3325202A43BC5B52A5A9A843EF0377B5D54D@EXITS713.its.iastate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100830/57509359/attachment.pl>

From tomas.zelinsky at tuke.sk  Mon Aug 30 20:23:43 2010
From: tomas.zelinsky at tuke.sk (Tomas Zelinsky)
Date: Mon, 30 Aug 2010 20:23:43 +0200
Subject: [R-sig-Geo] Different widths for different administrative
 boundaries with spplot() function
Message-ID: <4C7BF72F.3090901@tuke.sk>


Hello friends,

I tried to create thematic maps using spplot() function for the NUTS2 
and NUTS3 administrative levels of the EU. In the maps I'm using, the 
lower level areas are subdivisions of the parent areas. Is it possible 
to make the country borderlines (i.e. NUTS1 level) thicker than the 
lower levels (regional) borderlines?

Thanks.

Tomas


From jesse.whittington2 at gmail.com  Mon Aug 30 20:35:57 2010
From: jesse.whittington2 at gmail.com (Jesse Whittington)
Date: Mon, 30 Aug 2010 12:35:57 -0600
Subject: [R-sig-Geo] Cluster identification using space-time permutations
Message-ID: <AANLkTikNE0UyCNyWjinY34_xSq_KFYyt=ZGmfnmHb+rM@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100830/69eed1af/attachment.pl>

From Virgilio.Gomez at uclm.es  Mon Aug 30 20:51:05 2010
From: Virgilio.Gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Mon, 30 Aug 2010 20:51:05 +0200
Subject: [R-sig-Geo] Cluster identification using space-time permutations
In-Reply-To: <AANLkTikNE0UyCNyWjinY34_xSq_KFYyt=ZGmfnmHb+rM@mail.gmail.com>
References: <AANLkTikNE0UyCNyWjinY34_xSq_KFYyt=ZGmfnmHb+rM@mail.gmail.com>
Message-ID: <1283194265.2456.16.camel@Virgilio-Gomez>

Dear Jesse,

You can look at the functions in the DCluster package for the (purely)
spatial scan statistic. You could start from there. I have also some
other code for spatio-temporal clustering that I have not yet released
(and I believe that the permutation algorithm may not be tuned) but I
will be happy to share it with you.

Best,

Virgilio

El lun, 30-08-2010 a las 12:35 -0600, Jesse Whittington escribi?:
> We've been using the SatScan space-time permutation scan statistic to
> identify potential predation sites (ie clusters) from wolf GPS data. Are
> there functions that I could use in R to run this cluster analysis?
> 
> Here's the reference:
> 
> Kulldorff et al. 2005 A Space?Time Permutation Scan Statistic for Disease
> Outbreak Detection
> http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.0020059
> 
> I've searched the RSiteSearch many times without luck.  Any help would be
> greatly appreciated!
> 
> Jesse Whittington
> Wildlife Biologist
> Banff National Park
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ricardorodot02 at gmail.com  Mon Aug 30 23:42:24 2010
From: ricardorodot02 at gmail.com (=?ISO-8859-1?Q?Ricardo_Rodr=EDguez?=)
Date: Mon, 30 Aug 2010 16:42:24 -0500
Subject: [R-sig-Geo] creating network road
Message-ID: <AANLkTi=2cSAOvhkQ_zR-5=HUYSze8Ur2uwj6JUUerQNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100830/0cda5f8b/attachment.pl>

From jeremy.raw at dot.gov  Tue Aug 31 15:38:47 2010
From: jeremy.raw at dot.gov (jeremy.raw at dot.gov)
Date: Tue, 31 Aug 2010 09:38:47 -0400
Subject: [R-sig-Geo] creating network road
In-Reply-To: <AANLkTi=2cSAOvhkQ_zR-5=HUYSze8Ur2uwj6JUUerQNQ@mail.gmail.com>
References: <AANLkTi=2cSAOvhkQ_zR-5=HUYSze8Ur2uwj6JUUerQNQ@mail.gmail.com>
Message-ID: <B3C9A56C0E6FBF48A7D3ED79E9A7A9C00344F603@OSTMAIL03VS3.ad.dot.gov>

Discussing either igraph or travelr in detail here is probably off-topic.

igraph has its own active discussion list:
(http://lists.nongnu.org/mailman/listinfo/igraph-help).

Travelr has irregular support available at this time; questions have the best chance of being answered if directed to the travelr discussion list:
(http://lists.r-forge.r-project.org/mailman/listinfo/travelr-discussion).

Questions related to these packages would be better directed to one of those two resource lists.  Both packages contain some references to books and articles describing the structures and operations, and igraph has a gradually developing help page.

That said, here's a basic review of how to start constructing a graph or network for analysis in these packages:

To use spatial data as a network in either of these packages, the data must be disassembled into suitable structures that can be used to construct the internal representations used in each package (the representations are different but closely related).

For analysis by either igraph or travelr, a road network is conceptually simply a graph, and often a directed graph.  To use either of these packages, it is easiest to start with a tabular representation of the network as vertices (in the language of graphs) or nodes (in the language of highway modeling), plus edges (igraph) or links (travelr).

The vertices (nodes) are stored as a vector of numbers from 0 to N-1 (igraph) or 1 to N (travelr).  The travelr package further identifies the first Z nodes (Z <= N) as "zones", which are the sources and sinks of flows assigned over the network.

The roads themselves are modeled as edges (links):  at a minimum, this is a matrix or data frame with one row per edge and two columns indicating which vertices are connected by each edge.  travelr wants the links (edges) to be directed, so there should be a link (edge) for each direction of travel (thus, a link from A to B, and another link from B to A, unless the facility is "one way").  In addition, for routing applications, both packages will work with a vector of edge weights (igraph) or costs (travelr) which are used to construct shortest paths across the network between nodes of interest.  In igraph, the weights are stored as a graph attribute, in travelr, the weights are kept as a vector within an assignment set structure (a classed list; see the travelr documentation -- this is more complex to set up, but greatly facilitates coding the applications to which travelr was designed to be applied).

>From those basic elements, one constructs a graph (highway network) and both packages have instructions for doing this.  Then there are various functions for building shortest paths with weights and (in the case of travelr) performing additional operations on the links associated with the shortest paths.

Igraph is well-developed theoretically and is (once one gets over certain quirks, such as zero-based vertex numbering) very usable.  Travelr is a work in progress and is probably best ignored unless one is ready to read the code in detail (the lower-level functions have been much more extensively tested than the higher-level ones).  Travelr requires more work to set up and process networks, but can be used directly for certain types of analyses that would require considerably more coding in igraph.

I hope that helps.

Jeremy Raw, P.E., AICP
FHWA Office of Planning
jeremy.raw at dot.gov
(202) 366-0986


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Ricardo Rodr?guez
Sent: Monday, August 30, 2010 5:42 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] creating network road

hello, how to create a network of roads, I am looking igraph and Travelr packages but I'm not sure how to enter the network and how to create these packages or other of R, since only the documented functions of the same but File no treatment, someone I could respect or arientar ahy books treat the topic.

thanks for the help and time

Ricardo Rodr?guez
Univalle

	[[alternative HTML version deleted]]


From breitbach at uni-mainz.de  Tue Aug 31 16:52:18 2010
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Tue, 31 Aug 2010 14:52:18 +0000
Subject: [R-sig-Geo] Inverse Distance Matrix
Message-ID: <E7F1EF063B11DA4DAD16374549B879E82ADC5186@e14mdb-02.zdv.Uni-Mainz.DE>

Dear Community,

to pass general weights to a listw object (function nb2listw from the spdep package) for a later Moran's I Test and I decided to follow the recommendation of using the inverse distances as equivalent. I am still not sure how to correctly calculate the inverse distances. I have often seen that it was done by just applying >> 1 / distances << [one divided by distance for all distances]. However I found another form of calculation in "Applied Spatial Analysis with R" where they used >> 1 / (distance / 1000) << [one divided by (distance divided by 1000 for all distances)]. I suppose there is no difference between the two methods since the relation remains the same. Is there any technical reason for the second solution? Most of such functions expect values between 0 and 1 but in this case the values for the latter solution are greater than the original values, which suggests that it would also work with the original values. Unfortunately I found nothing in the help file of the nb2listw function about the range of accepted or preferred values for the glist argument.

Any ideas?

Regards,

Nils

From jesse.whittington2 at gmail.com  Tue Aug 31 16:55:15 2010
From: jesse.whittington2 at gmail.com (Jesse Whittington)
Date: Tue, 31 Aug 2010 08:55:15 -0600
Subject: [R-sig-Geo] Cluster identification using space-time permutations
In-Reply-To: <1283194265.2456.16.camel@Virgilio-Gomez>
References: <AANLkTikNE0UyCNyWjinY34_xSq_KFYyt=ZGmfnmHb+rM@mail.gmail.com>
	<1283194265.2456.16.camel@Virgilio-Gomez>
Message-ID: <AANLkTinTEU2tY8iNVGKK+X1Si5E6xs8tyZO5n4Ojd8xF@mail.gmail.com>

Hi Virgilio,

I tried your DCluster package earlier with the aid of Roger's book
Applied Spatial Data Analysis with R. I'd still like to try your code
for spatio-temporal clustering.  It's probably OK if the algorithm is
not fully tuned as I expect to get false positives.

Thanks for your help,

Jesse


2010/8/30 Virgilio G?mez-Rubio <Virgilio.Gomez at uclm.es>
>
> Dear Jesse,
>
> You can look at the functions in the DCluster package for the (purely)
> spatial scan statistic. You could start from there. I have also some
> other code for spatio-temporal clustering that I have not yet released
> (and I believe that the permutation algorithm may not be tuned) but I
> will be happy to share it with you.
>
> Best,
>
> Virgilio
>
> El lun, 30-08-2010 a las 12:35 -0600, Jesse Whittington escribi?:
> > We've been using the SatScan space-time permutation scan statistic to
> > identify potential predation sites (ie clusters) from wolf GPS data. Are
> > there functions that I could use in R to run this cluster analysis?
> >
> > Here's the reference:
> >
> > Kulldorff et al. 2005 A Space Time Permutation Scan Statistic for Disease
> > Outbreak Detection
> > http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.0020059
> >
> > I've searched the RSiteSearch many times without luck. ?Any help would be
> > greatly appreciated!
> >
> > Jesse Whittington
> > Wildlife Biologist
> > Banff National Park
> >
> > ? ? ? [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From folopez at ivic.gob.ve  Tue Aug 31 18:22:49 2010
From: folopez at ivic.gob.ve (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Tue, 31 Aug 2010 11:22:49 -0500
Subject: [R-sig-Geo] About plotting maximum data over a region.-
Message-ID: <AANLkTiniZPHikxEKsO5CdKf2NLBsxhCnRoJJp-eRuJFB@mail.gmail.com>

Dear ALL,

Perhaps my problem does not belong exactly to this list... I apologize for this.

My situation is the following:

I have a dataset with 26 sites (columns) whose values are annual
maximum since 1960 up to 1999 (40 rows) and I want to plotting it.? Of
course I have also the coordinates from each site.

I have seen one example similar to what I am looking for (function
simmaxstab() in SpatialExtremes):

>filled.contour(x, y, log(data[,,1]), color.palette = terrain.colors)

But at first glance it does not work to my data. The error that it report is:

> filled.contour(coor2[,1], coor2[,2], nueva2)
Error en filled.contour(coor2[, 1], coor2[, 2], nueva2) :
? increasing 'x' and 'y' values expected

Can anybody help me to plot my particular dataset?

Thanks in advance.

Cheers!

--
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From gianni.lavaredo at gmail.com  Tue Aug 31 20:55:32 2010
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Tue, 31 Aug 2010 20:55:32 +0200
Subject: [R-sig-Geo] Problem to Save a SpatialPolygonsDataFrame in a
 shape-file (GDAL Error 1: Invalid index : -1)
Message-ID: <AANLkTink=fsT1KnuyeLzp8qeJRziU5gnvNRauk2GQ_QR@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20100831/035201f7/attachment.pl>

From edzer.pebesma at uni-muenster.de  Tue Aug 31 21:10:33 2010
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 31 Aug 2010 21:10:33 +0200
Subject: [R-sig-Geo] Problem to Save a SpatialPolygonsDataFrame in a
 shape-file (GDAL Error 1: Invalid index : -1)
In-Reply-To: <AANLkTink=fsT1KnuyeLzp8qeJRziU5gnvNRauk2GQ_QR@mail.gmail.com>
References: <AANLkTink=fsT1KnuyeLzp8qeJRziU5gnvNRauk2GQ_QR@mail.gmail.com>
Message-ID: <4C7D53A9.5020803@uni-muenster.de>

You're hiding some context in which this happens, I can't see whether it
is i that is -1 or something else. Please try to reproduce the error
message with a fixed file name, or even better in some way someone else
can reproduce it.

On 08/31/2010 08:55 PM, gianni lavaredo wrote:
> Dear reseearchers,
> 
> I have a problem to save a SpatialPolygonsDataFrame in a shape file
> my SpatialPolygonsDataFrame = sub.area.SPDF
> 
> thanks in Advance
> Gianni
> 
>> writeOGR(sub.area.SPDF,".", paste("Sub_Area",rand.patch[[i]],sep=""),
> driver="ESRI Shapefile")
> Error in writeOGR(sub.area.SPDF, ".", paste("Sub_Area", rand.patch[[i]],  :
> 
>         GDAL Error 1: Invalid index : -1
> In addition: Warning message:
> In writeOGR(sub.area.SPDF, ".", paste("Sub_Area", rand.patch[[i]],  :
>         Non-fatal GDAL Error 6: Normalized/laundered field name:
> 'rep.0..length.IDs..' to 'rep.0..len'
> 
> 
> # Attribute
> 
>> class(sub.area.SPDF)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> str(sub.area.SPDF)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>   ..@ data       :'data.frame': 1 obs. of  1 variable:
>   .. ..$ rep.0..length.IDs..: num 0
>   ..@ polygons   :List of 1
>   .. ..$ :Formal class 'Polygons' [package "sp"] with 5 slots
>   .. .. .. ..@ Polygons :List of 1
>   .. .. .. .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>   .. .. .. .. .. .. ..@ labpt  : num [1:2] 1669500 7112500
>   .. .. .. .. .. .. ..@ area   : num 40000
>   .. .. .. .. .. .. ..@ hole   : logi FALSE
>   .. .. .. .. .. .. ..@ ringDir: int 1
>   .. .. .. .. .. .. ..@ coords : num [1:5, 1:2] 1669400 1669400 1669600
> 1669600 1669400 ...
>   .. .. .. ..@ plotOrder: int 1
>   .. .. .. ..@ labpt    : num [1:2] 1669500 7112500
>   .. .. .. ..@ ID       : chr "1"
>   .. .. .. ..@ area     : num 40000
>   ..@ plotOrder  : int 1
>   ..@ bbox       : num [1:2, 1:2] 1669400 7112400 1669600 7112600
>   .. ..- attr(*, "dimnames")=List of 2
>   .. .. ..$ : chr [1:2] "x" "y"
>   .. .. ..$ : chr [1:2] "min" "max"
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>   .. .. ..@ projargs: chr NA
>>
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>> sub.area.SPDF
> An object of class "SpatialPolygonsDataFrame"
> Slot "data":
>   rep.0..length.IDs..
> 1                   0
> 
> Slot "polygons":
> [[1]]
> An object of class "Polygons"
> Slot "Polygons":
> [[1]]
> An object of class "Polygon"
> Slot "labpt":
> [1] 1669500 7112500
> 
> Slot "area":
> [1] 40000
> 
> Slot "hole":
> [1] FALSE
> 
> Slot "ringDir":
> [1] 1
> 
> Slot "coords":
>         [,1]    [,2]
> [1,] 1669400 7112400
> [2,] 1669400 7112600
> [3,] 1669600 7112600
> [4,] 1669600 7112400
> [5,] 1669400 7112400
> 
> 
> 
> Slot "plotOrder":
> [1] 1
> 
> Slot "labpt":
> [1] 1669500 7112500
> 
> Slot "ID":
> [1] "1"
> 
> Slot "area":
> [1] 40000
> 
> 
> 
> Slot "plotOrder":
> [1] 1
> 
> Slot "bbox":
>       min     max
> x 1669400 1669600
> y 7112400 7112600
> 
> Slot "proj4string":
> CRS arguments: NA
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From ashton at msu.edu  Tue Aug 31 21:13:14 2010
From: ashton at msu.edu (Ashton Shortridge)
Date: Tue, 31 Aug 2010 15:13:14 -0400
Subject: [R-sig-Geo] About plotting maximum data over a region.-
In-Reply-To: <AANLkTiniZPHikxEKsO5CdKf2NLBsxhCnRoJJp-eRuJFB@mail.gmail.com>
References: <AANLkTiniZPHikxEKsO5CdKf2NLBsxhCnRoJJp-eRuJFB@mail.gmail.com>
Message-ID: <201008311513.14771.ashton@msu.edu>

On 2010-08-31, Freddy L?pez, wrote:
> Dear ALL,
> 
> Perhaps my problem does not belong exactly to this list... I apologize for
> this.
> 
> My situation is the following:
> 
> I have a dataset with 26 sites (columns) whose values are annual
> maximum since 1960 up to 1999 (40 rows) and I want to plotting it.  Of
> course I have also the coordinates from each site.
> 
> I have seen one example similar to what I am looking for (function
> 
> simmaxstab() in SpatialExtremes):
> >filled.contour(x, y, log(data[,,1]), color.palette = terrain.colors)
> 
> But at first glance it does not work to my data. The error that it report is:
> > filled.contour(coor2[,1], coor2[,2], nueva2)
> 
> Error en filled.contour(coor2[, 1], coor2[, 2], nueva2) :
>   increasing 'x' and 'y' values expected
> 
> Can anybody help me to plot my particular dataset?
> 
> Thanks in advance.

Hi Freddy,

Your problem is that filled.contour assumes a matrix input - essentially a 
whole field of z-values. I suspect what you have are scattered locations with 
z-values for each one. You have two options:

1. Interpolate your scattered points to a grid, and plot that, maybe with 
filled.contour. Interpolation methods are very numerous in R and beyond the 
scope of this answer, but maybe idw() in the gstat package would be a place to 
start.

2. Plot the point locations directly, and color them according to their z-
value. Maybe something like this would work:
par(pty="s")  # square plotting region
plot(coor2[,1], coor2[,2], main="Locations")  # Just the locations
plot(coor2[,1], coor2[,2], main="Nueva2 at my Locations", 
     col=rainbow(n=10, start=0.50, end=0.65)[cut(nueva2,10)], pch=19)
points(coor2[,1], coor2[,2], pch=1, cex=1.1)  # draws a black outline

Hope this helps,

Ashton

-----
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


