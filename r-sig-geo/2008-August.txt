From Alexander.Herr at csiro.au  Fri Aug  1 01:51:29 2008
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Fri, 1 Aug 2008 09:51:29 +1000
Subject: [R-sig-Geo] accumulate gridcells to a specific value
References: <mailman.9.1217412002.21993.r-sig-geo@stat.math.ethz.ch>
	<9ED523708FAD8448BDE5EC41B83E7024177797@exactn2-cbr.nexus.csiro.au>
	<d8ad40b50807310208v6e5fb3f9x3e42bd1f95813969@mail.gmail.com>
Message-ID: <9ED523708FAD8448BDE5EC41B83E7024177799@exactn2-cbr.nexus.csiro.au>

Hi Barry,

> Can you explain a bit more about your problem?
> * What are the inputs? Just a grid of values or are there some
starting points?

Inputs is a floating grid. Starting point is 1) the highest values in
the grid. Once first accumulation achieved, exclude this area and 2)
find highest value on grid for next starting points and so on.

> * What are the outputs? A list of grid cells that add up to your
accumulated value?

outputs: accumulation areas where sum of grid points (within areas) is a
given value.


Does that clarify?
Cheers
Herry

-----Original Message-----
From: b.rowlingson at googlemail.com [mailto:b.rowlingson at googlemail.com]
On Behalf Of Barry Rowlingson
Sent: Thursday, July 31, 2008 7:09 PM
To: Herr, Alexander Herr - Herry (CSE, Gungahlin)
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] accumulate gridcells to a specific value

2008/7/31  <Alexander.Herr at csiro.au>:

> I am trying to accumulate gridcells to a specific value. This means I 
> need to extent the nearest neighbours (or search radius) to a size so 
> that the sum of gridcell values reaches the desired value (or stops if

> sum value of gridcells/radius goes beyond a specific size). It should 
> start with the highest gridcell value then next remaining highest etc.
>
> Of course this could also work with points/polygons or on a matrix.
>
> Rather than re-inventing the wheel I was wondering if anyone has or 
> knows of a tool/script.

 It's not totally clear what you want to do, but it sounds like the sort
of raster operation that GRASS GIS does.

 http://grass.itc.it/

 Can you explain a bit more about your problem?

 * What are the inputs? Just a grid of values or are there some starting
points?
 * What are the outputs? A list of grid cells that add up to your
accumulated value?

 I ask this because this week I wrote some code that did something very
similar, namely:

 Given a grid of resource values and a number of population centres,
compute the areas on the grid that allocate a given resource total to
each population centre by minimising the distance from each centre, and
not allowing any grid square to be allocated to more than one centre.

 It basically grows areas out from the centres, by finding the minimum
centre-resource cell distance for unallocated cells and allocating that
cell to that centre.

 This was written in Python and used gdal to read grids. Took me a day
to write and a day to document.

 I'll have to start charging for this :)

Barry



From moliver at udel.edu  Fri Aug  1 16:04:39 2008
From: moliver at udel.edu (Matt Oliver)
Date: Fri, 1 Aug 2008 10:04:39 -0400
Subject: [R-sig-Geo] Fwd:  ncdf file with non-equally spaced grid
In-Reply-To: <200807312320.m6VNKCRH011231@corinna.its.utas.edu.au>
References: <200807312320.m6VNKCRH011231@corinna.its.utas.edu.au>
Message-ID: <6d4aad460808010704w113225c3l4a25cfdc93aa3d2a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080801/637a7615/attachment.pl>

From Maxime.Pauwels at univ-lille1.fr  Fri Aug  1 17:07:47 2008
From: Maxime.Pauwels at univ-lille1.fr (Maxime Pauwels)
Date: Fri, 01 Aug 2008 17:07:47 +0200
Subject: [R-sig-Geo] chronolgy of drawing of sp.layout
Message-ID: <489326C3.1070707@univ-lille1.fr>

Hello,

I'm using R and the sp package for only a few days. I have already
resolved numerous basical questions but the following one resists:
I'd like to plot spatial data with attributes and to highlight a few
points on the plot corresponding to samples locations ("pop" below).

Here is my script:

library(sp)
library(lattice) # required for trellis.par.set():
trellis.par.set(sp.theme()) # sets color ramp to bpy.colors()
data <- read.table("rdataNssSS.txt", header=T)
class(data)
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
coordinates(data) <- ~gridlong+gridlat
spplot(data, c("gridr"), scales=list(draw=T),cuts=20, regions=T,
main="rvalues", xlab = "longitude (dec.)", ylab="latitude(dec.)",
key.space="right")
#samples location
coordpop <- read.table("coordpop.txt", header=T)
x <- coordpop$long
y <- coordpop$lat
pop <- SpatialPoints(list(x,y))
class(pop)
#[1] "SpatialPoints"
#attr(,"package")
#[1] "sp"
poppoints = list("sp.points", pop, pch=21, col="black", fill="black")
spplot(data, c("gridr"), scales=list(draw=T),cuts=20, regions=T,
main="rvalues", xlab = "longitude (dec.)", ylab="latitude(dec.)",
key.space="right", sp.layout=list(poppoints))


the problem is that, as explained in the sp package manual, sp.layout
item is drawn first, before the plot of point in "data". Given that pop
points are included in data, I can't see them anymore at the end of spplot.

Does anyone have a solution to reverse this?

Max





-- 
Maxime Pauwels
Post-Doc
Laboratoire de G?n?tique et Evolution des Populations V?g?tales
UMR CNRS 8016
Batiment SN2			Tel  : +33 3 20 43 40 76
Universite de LILLE 1		Fax  : +33 3 20 43 69 79
59655 Villeneuve d'Ascq Cedex	email: maxime.pauwels at univ-lille1.fr
FRANCE				http://www.univ-lille1.fr/gepv

?Impose ta chance, serre ton bonheur et va vers ton risque. A te 
regarder, ils s?habitueront.?
Ren? Char



From Maxime.Pauwels at univ-lille1.fr  Mon Aug  4 10:45:35 2008
From: Maxime.Pauwels at univ-lille1.fr (Maxime Pauwels)
Date: Mon, 04 Aug 2008 10:45:35 +0200
Subject: [R-sig-Geo] chronolgy of drawing of sp.layout
In-Reply-To: <1217608133.23745.41.camel@fh-vrubio>
References: <489326C3.1070707@univ-lille1.fr>
	<1217608133.23745.41.camel@fh-vrubio>
Message-ID: <4896C1AF.7010000@univ-lille1.fr>

Virgilio Gomez-Rubio a ?crit :

Virgilio,

Many thanks for your help.
I tried a comparable solution using alpha. The result is interesting but 
the quality of the plot is markedly lower (colored pixels are apparent). 
I read on the site that panel function could be used. Unfortunately, i'm 
not familiar with such functions.

Best regards,

max


> Maxime,
>
> You can use transparencies to show the points in the layout. For
> example,
>
> library(sp)
> spp<-SpatialPoints(matrix(runif(100), ncol=2))
> sppd<-SpatialPointsDataFrame(spp, data.frame(VAL=c(rep("a", 25),
> rep("b", 25))))
>
> spplot(sppd, pch=19, col.regions=c("#11223355",  "#ff223355"),
> sp.layout=list("sp.points", spp, col.region="yellow"))
>
>
> The transparency is in the "55" bit of "#11223355" and "#ff223355".
>
> Best regards,
>
> Virgilio
>
>
> On Fri, 2008-08-01 at 17:07 +0200, Maxime Pauwels wrote:
>   
>> Hello,
>>
>> I'm using R and the sp package for only a few days. I have already
>> resolved numerous basical questions but the following one resists:
>> I'd like to plot spatial data with attributes and to highlight a few
>> points on the plot corresponding to samples locations ("pop" below).
>>
>> Here is my script:
>>
>> library(sp)
>> library(lattice) # required for trellis.par.set():
>> trellis.par.set(sp.theme()) # sets color ramp to bpy.colors()
>> data <- read.table("rdataNssSS.txt", header=T)
>> class(data)
>> [1] "SpatialPointsDataFrame"
>> attr(,"package")
>> [1] "sp"
>> coordinates(data) <- ~gridlong+gridlat
>> spplot(data, c("gridr"), scales=list(draw=T),cuts=20, regions=T,
>> main="rvalues", xlab = "longitude (dec.)", ylab="latitude(dec.)",
>> key.space="right")
>> #samples location
>> coordpop <- read.table("coordpop.txt", header=T)
>> x <- coordpop$long
>> y <- coordpop$lat
>> pop <- SpatialPoints(list(x,y))
>> class(pop)
>> #[1] "SpatialPoints"
>> #attr(,"package")
>> #[1] "sp"
>> poppoints = list("sp.points", pop, pch=21, col="black", fill="black")
>> spplot(data, c("gridr"), scales=list(draw=T),cuts=20, regions=T,
>> main="rvalues", xlab = "longitude (dec.)", ylab="latitude(dec.)",
>> key.space="right", sp.layout=list(poppoints))
>>
>>
>> the problem is that, as explained in the sp package manual, sp.layout
>> item is drawn first, before the plot of point in "data". Given that pop
>> points are included in data, I can't see them anymore at the end of spplot.
>>
>> Does anyone have a solution to reverse this?
>>
>> Max
>>
>>
>>
>>
>>
>>     
>
>
>   


-- 
Maxime Pauwels
Post-Doc
Laboratoire de G?n?tique et Evolution des Populations V?g?tales 
UMR CNRS 8016 
Batiment SN2			Tel  : +33 3 20 43 40 76
Universite de LILLE 1		Fax  : +33 3 20 43 69 79
59655 Villeneuve d'Ascq Cedex	email: maxime.pauwels at univ-lille1.fr
FRANCE				http://www.univ-lille1.fr/gepv

?Impose ta chance, serre ton bonheur et va vers ton risque. A te regarder, ils s?habitueront.?
Ren? Char



From ezhangym at gmail.com  Mon Aug  4 13:02:47 2008
From: ezhangym at gmail.com (Yumin ZHANG)
Date: Mon, 4 Aug 2008 20:02:47 +0900
Subject: [R-sig-Geo] How to use Rmap in R 2.7.1 ?
Message-ID: <73799c2c0808040402m29735a2ah7bbee529d78064e0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080804/cf67b066/attachment.pl>

From Roger.Bivand at nhh.no  Mon Aug  4 13:11:22 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 4 Aug 2008 13:11:22 +0200 (CEST)
Subject: [R-sig-Geo] How to use Rmap in R 2.7.1 ?
In-Reply-To: <73799c2c0808040402m29735a2ah7bbee529d78064e0@mail.gmail.com>
References: <73799c2c0808040402m29735a2ah7bbee529d78064e0@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0808041310140.6818@reclus.nhh.no>

On Mon, 4 Aug 2008, Yumin ZHANG wrote:

> Hello,
> The Windows binary of Rmap
> (Rmap_1.1.0.zip<http://spatial.nhh.no/R/Devel/Rmap_1.1.0.zip>)
> can not be used.
> Could you give me some information?
>

Most of the functionality of the Rmap package moved to rgdal some years 
ago, please try rgdal instead. It is maintained, but Rmap is not.

Roger

>                                                                      ZHANG
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From aloboaleu at gmail.com  Tue Aug  5 13:38:36 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Tue, 05 Aug 2008 13:38:36 +0200
Subject: [R-sig-Geo] reading tiff with jump?
Message-ID: <48983BBC.6060804@gmail.com>

Hi!

is it possible to read a tiff file with readGDAL but just keeping
one pixel every p columns and q lines? That is,
a systematic sampling at reading. This is good to save memory
and still be able of displaying and performing
statistics. As images are large,
reading in the entire image and then sampling is not
an alternative.
If this is not contemplated in the readGDAL function,
is there any way to just read in one line, perform
the sampling and then go on with the next line?

I think I did this with binary images few years
ago, but using tiff would be much better for
practical reasons.

Thanks

Agus


-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Tue Aug  5 14:04:15 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 Aug 2008 14:04:15 +0200 (CEST)
Subject: [R-sig-Geo] reading tiff with jump?
In-Reply-To: <48983BBC.6060804@gmail.com>
References: <48983BBC.6060804@gmail.com>
Message-ID: <Pine.LNX.4.64.0808051358300.22972@reclus.nhh.no>

On Tue, 5 Aug 2008, Agustin Lobo wrote:

> Hi!
>
> is it possible to read a tiff file with readGDAL but just keeping
> one pixel every p columns and q lines? That is,
> a systematic sampling at reading. This is good to save memory
> and still be able of displaying and performing
> statistics. As images are large,
> reading in the entire image and then sampling is not
> an alternative.
> If this is not contemplated in the readGDAL function,
> is there any way to just read in one line, perform
> the sampling and then go on with the next line?
>
> I think I did this with binary images few years
> ago, but using tiff would be much better for
> practical reasons.

Look at the offset=, band= and region.dim= arguments to readGDAL() - you 
could capture the GDALinfo() output to set the frame if need be. It may be 
more efficient to use GDAL.open()/GDAL.close() and getRasterData() at a 
lower level if you are taking many samples - loop over different values of 
offset= with region.dim=c(1,1). Note that offset= may be from the NW 
corner, not the SW corner, and that the arguments are (often) ordered
(y, x).

Roger

>
> Thanks
>
> Agus
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ashton at msu.edu  Tue Aug  5 15:52:21 2008
From: ashton at msu.edu (Ashton Shortridge)
Date: Tue, 5 Aug 2008 09:52:21 -0400
Subject: [R-sig-Geo] reading tiff with jump?
In-Reply-To: <Pine.LNX.4.64.0808051358300.22972@reclus.nhh.no>
References: <48983BBC.6060804@gmail.com>
	<Pine.LNX.4.64.0808051358300.22972@reclus.nhh.no>
Message-ID: <200808050952.21255.ashton@msu.edu>

On Tuesday 05 August 2008, Roger Bivand wrote:
> On Tue, 5 Aug 2008, Agustin Lobo wrote:
> > Hi!
> >
> > is it possible to read a tiff file with readGDAL but just keeping
> > one pixel every p columns and q lines? That is,
> > a systematic sampling at reading. This is good to save memory
> > and still be able of displaying and performing
> > statistics. As images are large,
> > reading in the entire image and then sampling is not
> > an alternative.
> > If this is not contemplated in the readGDAL function,
> > is there any way to just read in one line, perform
> > the sampling and then go on with the next line?
> >
> > I think I did this with binary images few years
> > ago, but using tiff would be much better for
> > practical reasons.
>
> Look at the offset=, band= and region.dim= arguments to readGDAL() - you
> could capture the GDALinfo() output to set the frame if need be. It may be
> more efficient to use GDAL.open()/GDAL.close() and getRasterData() at a
> lower level if you are taking many samples - loop over different values of
> offset= with region.dim=c(1,1). Note that offset= may be from the NW
> corner, not the SW corner, and that the arguments are (often) ordered
> (y, x).
>
> Roger

I'll just add to that: opening raster files is fairly expensive, so if you are 
sampling many locations over many tiffs you will see great speed improvements 
if you order your sampling by tiff to minimize the opens.

Yours,

Ashton

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671



From v.gomezrubio at imperial.ac.uk  Tue Aug  5 18:52:50 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Tue, 05 Aug 2008 17:52:50 +0100
Subject: [R-sig-Geo] e-Workshop on spatial stats with R: FULL
Message-ID: <1217955170.18518.17.camel@fh-vrubio>

Dear all,

Sorry for any cross-posting. It seems that the e-Workshop on spatial
stats with R has had a high demand and it is now full. Hence, no more
bookings will be accepted. However, see below for other options to
benefit from it.

Best regards,

Virgilio



                                 URGENT

                 e-Workshop on Spatial Statistics in R


                              Spring 2009


Organized by the Worldwide Universities Network Global GISc Academy and
            the RGS/IBG Quantitative Methods Research Group


I regret that we have now filled as many places as we dare allow on the
scheduled workshop on Spatial Statistics in R that was recently
advertised by way of this bulletin. Too many risks too high a load on
the server that we use, not to mention the presenters themselves, and
would spoil things for all concerned, so with regret I will now cease to
take registrations. In setting up the Workshop series I had absolutely
no idea that it would prove to be so popular. I have every confidence
that it will prove a landmark event in the development and application
of spatial methods using R. 


Disappointed? There are two possible silver linings to this cloud.
First, we in WUN will record all the Workshop presentations and make
them available for download and playback using the Marratech? system as
soon as we can after each presentation. You can see what this involves
by visiting our website at


                   www.wun.ac.uk/ggisa/seminars.html


Second, I am already working on a possible repeat a little later in the
year.


Dave Unwin

WUN Global GISc Academy



From alessandro.montaghi at unifi.it  Tue Aug  5 19:47:49 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 5 Aug 2008 10:47:49 -0700
Subject: [R-sig-Geo] LIDAR Problem in R (THANKS for HELP)
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAFti/hvLEJ5HsT8OXG12vvfCgAAAEAAAAGRVA+A+vHlFrFMVyQJ6j5wBAAAAAA==@unifi.it>

 

Hi All,

 

I am a PhD student in forestry science and I am working with LiDAR data set
(huge data set). I am a brand-new in R and geostatistic (SORRY, my
background it?s in forestry) but I wish improve my skill for improve myself.
I wish to develop a methodology to processing a large data-set of points
(typical in LiDAR) but there is a problem with memory. I had created a
subsample data-base but the semivariogram is periodic shape and I am not to
able to try a fit the model. This is a maximum of two weeks of work (day bay
day) SORRY. Is there a geostatistical user I am very happy to listen his
suggests. Data format is X, Y and Z (height to create the DEM) in txt format

I have this questions:

 

1.       After the random selection (10000 points) and fit.semivariogram
model is it possible to use all LiDAR points? Because the new LiDAR power is
to use huge number of points (X;Y; Z value) to create a very high resolution
map of DEM and VEGETATION. The problem is the memory, but we can use a
cluster-linux network to improve the capacity of R

 

2.       Is it possible to improve the memory capacity?

 

3.       The data has a trend and the qqplot shows a Gaussian trend. Is it
possible to normalize the data (i.e. with log)?

 

4.       When I use this R code ?subground.uk = krige(log(Z)~X+Y, subground,
new.grid, v.fit, nmax=40)? to appear an Error massage: Error in eval(expr,
envir, enclos) : oggetto "X" non trovato

 

I send you a report and attach the image to explain better. 

 

all procedure is write in R-software and to improve in gstat . The number of
points of GROUND data-set (4x2 km) is 5,459,916.00. The random sub- set from
original data-set is 10000 (R code is:  > samplerows
<-sample(1:nrow(testground),size=10000,replace=FALSE) > subground
<-testground[samplerows,])

 

1.       Original data-set Histogram: show two populations;

2.       original data-set density plot: show again two populations of data;

3.        Original data-set Boxplot: show there aren?t outlayers un the
data-set (the classification with terrascan is good and therefore there
isn?t a problem with original data)

4.        ordinary kriging: show a trend in the space (hypothesis: the
points are very close in the space)

5.       de-trend dataset with:  v <- variogram (log(Z)~X+Y, subground,
cutoff=1800, width=100))

6.       map of semi-variogram: show an anisotropy in the space (0? is Nord=
135? major radius 45? minus radius)

7.       semi-variogram with anisotropy (0?, 45?, 90?, 135?), shows a  best
shape is from 135?

8. semi-variogram fit with Gaussian Model. R code is (see the fig): 

> v = variogram(Z~X+Y, subground, cutoff=1800, width=200, alpha=c(135))

> v.fit = fit.variogram(v, vgm(psill = 1, model="Gau", range=1800, nugget=
0, anis=c(135, 0.5)))

 

R code:

 

testground2 <-
read.table(file="c:/work_LIDAR_USA/R_kriging_new_set/ground_26841492694149_x
yz.txt", header=T)

class (testground2)

coordinates (testground2)=~X+Y # this makes testground a
SpatialPointsDataFrame

class (testground2)

str(as.data.frame(testground))

 

hist(testground$Z,nclass=20) #this makes a histogram

plot(density(testground$Z)) #this makes a plot density

boxplot(testground$Z)#this makes a boxplot

 

samplerows<-sample(1:nrow(testground),size=10000,replace=FALSE) #select n.
points from all data-base

subground <-testground[samplerows,]

hist(subground$Z,nclass=20) #this makes a histogram

plot(density(subground$Z)) #this makes a plot density

boxplot(subground$Z)#this makes a boxplot

spplot(subground["Z"], col.regions=bpy.colors(), at = seq(850,1170,10))

 

library(maptools)

library(gstat)

plot(variogram(Z~1, subground)) #Ordinary Kriging (without detrend)

# if there is a trend we must use a detrend fuction Z~X+Y

x11(); plot(variogram(log(Z)~X+Y, subground, cutoff=1800, width=80))
#Universal Kriging (with detrend)

x11(); plot(variogram(log(Z)~X+Y, subground, cutoff=1800, width=80, map=T))

x11(); plot(variogram(log(Z)~X+Y, subground, cutoff=1800, width=80,
alpha=c(0, 45, 90, 135)))

v = variogram(log(Z)~X+Y, subground, cutoff=1800, width=80, alpha=c(135,
45))

v.fit = fit.variogram(v, vgm(psill = 1, model="Gau", range=1800, nugget= 0,
anis=c(135, 0.5)))

plot(v, v.fit, plot.nu=F, pch="+")

# create the new grid

new.grid <- spsample(subground, type="regular", cellsize=c(1,1))

gridded(new.grid) <- TRUE

fullgrid(new.grid) <- TRUE

new.grid at grid

#using Universal Kriging

subground.uk = krige(log(Z)~X+Y, subground, new.grid, v.fit, nmax=40)
#ERROR

 

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080805/ba81f3e5/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fig9.jpg
Type: image/jpeg
Size: 50934 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080805/ba81f3e5/attachment.jpg>

From moliver at udel.edu  Tue Aug  5 21:02:12 2008
From: moliver at udel.edu (Matt Oliver)
Date: Tue, 5 Aug 2008 15:02:12 -0400
Subject: [R-sig-Geo] LIDAR Problem in R (THANKS for HELP)
In-Reply-To: <!&!AAAAAAAAAAAYAAAAAAAAAFti/hvLEJ5HsT8OXG12vvfCgAAAEAAAAGRVA+A+vHlFrFMVyQJ6j5wBAAAAAA==@unifi.it>
References: <!&!AAAAAAAAAAAYAAAAAAAAAFti/hvLEJ5HsT8OXG12vvfCgAAAEAAAAGRVA+A+vHlFrFMVyQJ6j5wBAAAAAA==@unifi.it>
Message-ID: <6d4aad460808051202i34935c64gbfeba902ea4c6c04@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080805/efb2b3f2/attachment.pl>

From alessandro.montaghi at unifi.it  Tue Aug  5 21:40:38 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 5 Aug 2008 12:40:38 -0700
Subject: [R-sig-Geo] R:  LIDAR Problem in R (THANKS for HELP)
In-Reply-To: <6d4aad460808051202i34935c64gbfeba902ea4c6c04@mail.gmail.com>
References: <!&!AAAAAAAAAAAYAAAAAAAAAFti/hvLEJ5HsT8OXG12vvfCgAAAEAAAAGRVA+A+vHlFrFMVyQJ6j5wBAAAAAA==@unifi.it>
	<6d4aad460808051202i34935c64gbfeba902ea4c6c04@mail.gmail.com>
Message-ID: <004301c8f733$2478abe0$6d6a03a0$@montaghi@unifi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080805/633a01c7/attachment.pl>

From ajt180 at psu.edu  Tue Aug  5 22:00:18 2008
From: ajt180 at psu.edu (Adam Terando)
Date: Tue, 5 Aug 2008 16:00:18 -0400
Subject: [R-sig-Geo] R:  LIDAR Problem in R (THANKS for HELP)
In-Reply-To: 004301c8f733$2478abe0$6d6a03a0$@montaghi
References: <!&!AAAAAAAAAAAYAAAAAAAAAFti/hvLEJ5HsT8OXG12vvfCgAAAEAAAAGRVA+A+vHlFrFMVyQJ
	6j5wBAAAAAA==@unifi.it>
	<6d4aad460808051202i34935c64gbfeba902ea4c6c04@mail.gmail.com>
	<004301c8f733$2478abe0$6d6a03a0$@montaghi>
Message-ID: <1217966418l.712818l.0l@psu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080805/a5645e42/attachment.pl>

From alessandro.montaghi at unifi.it  Tue Aug  5 22:17:23 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Tue, 5 Aug 2008 13:17:23 -0700
Subject: [R-sig-Geo] R:  R:  LIDAR Problem in R (THANKS for HELP)
In-Reply-To: <1217966418l.712818l.0l@psu.edu>
References: <!&!AAAAAAAAAAAYAAAAAAAAAFti/hvLEJ5HsT8OXG12vvfCgAAAEAAAAGRVA+A+vHlFrFMVyQJ	6j5wBAAAAAA==@unifi.it>	<6d4aad460808051202i34935c64gbfeba902ea4c6c04@mail.gmail.com>	<004301c8f733$2478abe0$6d6a03a0$@montaghi>
	<1217966418l.712818l.0l@psu.edu>
Message-ID: <006501c8f738$4683c850$d38b58f0$@montaghi@unifi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080805/a3381ffb/attachment.pl>

From Agustin.Lobo at ija.csic.es  Tue Aug  5 23:32:49 2008
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Tue, 05 Aug 2008 23:32:49 +0200
Subject: [R-sig-Geo] reading tiff with jump?
In-Reply-To: <200808050952.21255.ashton@msu.edu>
References: <48983BBC.6060804@gmail.com>
	<Pine.LNX.4.64.0808051358300.22972@reclus.nhh.no>
	<200808050952.21255.ashton@msu.edu>
Message-ID: <4898C701.4050509@ija.csic.es>

Thanks to your input,
this is what I'm doing and I think it's ok:

require(rgdal)
fname <- 
"/media/SWISNIFE1/GEODATABOLIVIAmini/geotif/p233_r070_ETM_20010825.tif"
GDALinfo(fname=fname)

output of GDALinfo:
rows        3736
columns     5108
bands       6
ll.x        694431
ll.y        8410014
res.x       28.5
res.y       28.5
oblique.x   0
oblique.y   0
driver      GTiff
projection  +proj=utm +zone=19 +south +ellps=WGS84 +datum=WGS84 +units=m 
+no_defs
file 
/media/SWISNIFE1/GEODATABOLIVIAmini/geotif/p233_r070_ETM_20010825.tif

I go on with reading band 4 with subsampling:

ima <- readGDAL(fname=fname, offset=c(0,0),band=4,output.dim=c(373,510))
str(ima)
image(ima)
imamat <- t(as.matrix(ima)) #put Northernmost line as first row
imamat[imamat==0]<-NA

Then use the following to plot the matrix with correct orientation:

mirot <- function(x) t(x[nrow(x):1,])
x11()
image(mirot(imamat))

Regards,

Agus

Ashton Shortridge wrote:
> On Tuesday 05 August 2008, Roger Bivand wrote:
>> On Tue, 5 Aug 2008, Agustin Lobo wrote:
>>> Hi!
>>>
>>> is it possible to read a tiff file with readGDAL but just keeping
>>> one pixel every p columns and q lines? That is,
>>> a systematic sampling at reading. This is good to save memory
>>> and still be able of displaying and performing
>>> statistics. As images are large,
>>> reading in the entire image and then sampling is not
>>> an alternative.
>>> If this is not contemplated in the readGDAL function,
>>> is there any way to just read in one line, perform
>>> the sampling and then go on with the next line?
>>>
>>> I think I did this with binary images few years
>>> ago, but using tiff would be much better for
>>> practical reasons.
>> Look at the offset=, band= and region.dim= arguments to readGDAL() - you
>> could capture the GDALinfo() output to set the frame if need be. It may be
>> more efficient to use GDAL.open()/GDAL.close() and getRasterData() at a
>> lower level if you are taking many samples - loop over different values of
>> offset= with region.dim=c(1,1). Note that offset= may be from the NW
>> corner, not the SW corner, and that the arguments are (often) ordered
>> (y, x).
>>
>> Roger
> 
> I'll just add to that: opening raster files is fairly expensive, so if you are 
> sampling many locations over many tiffs you will see great speed improvements 
> if you order your sampling by tiff to minimize the opens.
> 
> Yours,
> 
> Ashton
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From mdsumner at utas.edu.au  Wed Aug  6 11:53:46 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Wed, 06 Aug 2008 19:53:46 +1000
Subject: [R-sig-Geo] ncdf file with non-equally spaced grid
In-Reply-To: <6d4aad460808051705x1be5b2f6ya919a318aabfbdf1@mail.gmail.com>
References: <200807312320.m6VNKCRH011231@corinna.its.utas.edu.au>
	<6d4aad460808051705x1be5b2f6ya919a318aabfbdf1@mail.gmail.com>
Message-ID: <489974AA.1070803@utas.edu.au>

With FWTools installed, you can do this with the resulting out.tif

gdalwarp out.tif ll.tif -t_srs "+proj=longlat"

That will reproject the result to longlat. I suggest you check the 
result carefully, and do find out the datum you should use.

I've realized that trying to extract the stuff from the netCDF directly 
as I do below results in the image being flipped vertically, because of 
the way it is stored internally. I don't know how to do this otherwise 
without using the VRT driver.

I'll try to put together an example, but I suggest you explore the 
command line utilities for GDAL - most easily installed with FWTools.

http://www.gdal.org/gdal_utilities.html

I've left my partially worked, and "upside-down" example below.

HTH

Cheers, Mike.



To convert with gdalwarp directly from the netcdf file, using the 
bounding box previously computed in R you will have to reference the 
subdatasets individually (I'm not how to do this with all the SDS as 
bands without using VRT virtual driver format):

          min      max
coords.x1 -8572928 -7012092
coords.x2  4138050  5750943

## first convert the netCDF SDS to the known projection
gdal_translate NETCDF:"20071003.276.0237.n17.nc":mcsst merc-MCSST.tif 
-a_srs "+proj=merc"  -a_ullr -8572928 5750943 -7012092 4138050

## now convert that to longlat
gdalwarp merc-MCSST.tif longlat-MCSST.tif -t_srs "+proj=longlat"



gdalwarp out.tif Matt Oliver wrote:
> Michael, thanks for this example!
>
> One minor question, how would I take the mercator projected ncdf and make it
> a longlat projection for the geotiff
>
> (I guess I am wondering at which step I need to do the conversion)
>
> Thanks in advance
>
> Matt
>
> On Thu, Jul 31, 2008 at 7:20 PM, Michael Sumner <mdsumner at utas.edu.au>wrote:
>
>   
>> The file really is in Mercator - see the gdalinfo output below - and you
>> can restore this within a small fudge by reprojecting the bottom corner
>> and finding an appropriate cell size.
>>
>> You could use expand.grid(x = lon, y = lat) and work directly with a
>> SpatialPixelsDataFrame and specify a tolerance for the grid, but that can
>> be unwieldy for large datasets and I'm more comfortable with the approach
>> below.
>>
>> You'll need to check carefully as to whether this is appropriate, but
>> with the generated TIFF file
>> you can easily gdalwarp it to longlat if need be.
>>
>> I think that PROJ.4 will effectively assume your datum is WGS84, but you
>> should check this with the data source and specify it.
>>
>> I'm very interested to hear about alternative approaches to this.
>>
>> HTH
>>
>> Cheers, Mike.
>>
>> require(ncdf)
>> f <- open.ncdf("20071003.276.0237.n17.nc")
>> lon <- get.var.ncdf(f, "lon")
>> lat <- get.var.ncdf(f, "lat")
>> mcsst <- get.var.ncdf(f, "mcsst")
>>
>> ## check the overall alignment
>> image(lon, lat, mcsst)
>>
>>
>> ## get rgdal for reprojecting and file I/O
>> library(rgdal)
>> ## get the bottom left corner (not sure if this is cell centre or corner
>> - assume centre)
>> cc.offset <- as.vector(project(matrix(c(min(lon), min(lat)), nrow = 1),
>> "+proj=merc"))
>>
>>
>> ## reproject one column for latitudes
>> xy.col <- as.matrix(expand.grid(x = min(lon), y = lat))
>> xy.col.merc <- project(xy.col, "+proj=merc")
>>
>> ## within metres, seems OK
>> range(diff(xy.col.merc[,2]))
>> mean(range(diff(xy.col.merc[,2])))
>>
>>
>> xy.row <- as.matrix(expand.grid(x = lon, y = min(lat)))
>> xy.row.merc <- project(xy.row, "+proj=merc")
>>
>> ## again, not exact but only within metres
>> range(diff(xy.row.merc[,1]))
>>
>> ## generate Mercator grid topology
>> gt <- GridTopology(cc.offset, c(mean(range(diff(xy.row.merc[,1]))),
>> mean(range(diff(xy.col.merc[,2])))), dim(mcsst))
>>
>>
>> ## flip vertically to get from image() to SGDF alignment
>> d <- SpatialGridDataFrame(gt, data.frame(mcsst =
>> as.vector(mcsst[,ncol(mcsst):1])), CRS("+proj=merc"))
>>
>> ## write out to check in GIS (I haven't checked very carefully, but it
>> seems fine)
>> writeGDAL(d, "out.tif")
>>
>> sessionInfo()
>>
>> R version 2.7.1 (2008-06-23)
>> i386-pc-mingw32
>>
>> locale:
>>
>> LC_COLLATE=English_Australia.1252;LC_CTYPE=English_Australia.1252;LC_MONETARY=English_Australia.1252;LC_NUMERIC=C;LC_TIME=English_Australia.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] rgdal_0.5-24 sp_0.9-24    ncdf_1.6
>>
>> loaded via a namespace (and not attached):
>> [1] grid_2.7.1     lattice_0.17-8 tools_2.7.1
>>
>>
>>
>> NETCDF file with subdatasets
>>
>> C:\temp\DATA\misc\netCDF\R-sig-geo>gdalinfo 20071003.276.0237.n17.nc
>> Driver: netCDF/Network Common Data Format
>> Files: 20071003.276.0237.n17.nc
>> Size is 512, 512
>> Coordinate System is `'
>> Metadata:
>>  NC_GLOBAL#Conventions=CF-1.0
>>  NC_GLOBAL#creator_name=Matthew Oliver
>>  NC_GLOBAL#creator_email=moliver at udel.edu
>>  NC_GLOBAL#institution=Rutgers University Coastal Ocean Observation
>> Laboratory (RU-COOL) http://rucool.marine.rutgers.edu  NC_GLOBAL#url=
>> http://marine.rutgers.edu/cool/sat_data  NC_GLOBAL#source=satellite
>> radiometer observation NOAA/POES AVHRR instrument
>>  NC_GLOBAL#groundstation=RU-COOL L-band receiver at Rutgers University,
>> New Jersey, USA
>>  NC_GLOBAL#summary=MCSST calculation and image navigation by TeraScan
>> software; Regridded to Mercator lon/lat projection for RU-COOL bigbight
>> subregion
>>  NC_GLOBAL#history=
>> Subdatasets:
>>  SUBDATASET_1_NAME=NETCDF:"20071003.276.0237.n17.nc":mcsst
>>  SUBDATASET_1_DESC=[1x1222x1183] mcsst (32-bit floating-point)
>>  SUBDATASET_2_NAME=NETCDF:"20071003.276.0237.n17.nc":landmask
>>  SUBDATASET_2_DESC=[1222x1183] landmask (16-bit integer)
>>  SUBDATASET_3_NAME=NETCDF:"20071003.276.0237.n17.nc":cloud_mask
>>  SUBDATASET_3_DESC=[1x1222x1183] cloud_mask (16-bit integer)
>> Corner Coordinates:
>> Upper Left  (    0.0,    0.0)
>> Lower Left  (    0.0,  512.0)
>> Upper Right (  512.0,    0.0)
>> Lower Right (  512.0,  512.0)
>> Center      (  256.0,  256.0)
>>
>> SUBDATASET within the file
>>
>> C:\temp\DATA\misc\netCDF\R-sig-geo>gdalinfo
>> NETCDF:"20071003.276.0237.n17.nc":mcsst
>> Warning 1: Latitude grid not spaced evenly.
>> Seting projection for grid spacing is within 0.1 degrees threshold.
>>
>> Driver: netCDF/Network Common Data Format
>> Files: none associated
>> Size is 1183, 1222
>> Coordinate System is `'
>> Origin = (-77.011923944889588,46.008670050818644)
>> Pixel Size = (0.011854481576058,-0.009016432203688)
>> Metadata:
>>  NC_GLOBAL#Conventions=CF-1.0
>>  NC_GLOBAL#creator_name=Matthew Oliver
>>  NC_GLOBAL#creator_email=moliver at udel.edu
>>  NC_GLOBAL#institution=Rutgers University Coastal Ocean Observation
>> Laboratory (RU-COOL) http://rucool.marine.rutgers.edu  NC_GLOBAL#url=
>> http://marine.rutgers.edu/cool/sat_data  NC_GLOBAL#source=satellite
>> radiometer observation NOAA/POES AVHRR instrument
>>  NC_GLOBAL#groundstation=RU-COOL L-band receiver at Rutgers University,
>> New Jersey, USA
>>  NC_GLOBAL#summary=MCSST calculation and image navigation by TeraScan
>> software; Regridded to Mercator lon/lat projection for RU-COOL bigbight
>> subregion
>>  NC_GLOBAL#history=
>>  mcsst#units=Celsius
>>  mcsst#missing_value=-9.990000e+002
>>  mcsst#long_name=Multichannel Sea Surface Temperature
>>  mcsst#_FillValue=-9.990000e+002
>>  time#units=seconds since 1970-01-01 00:00:00
>>  time#long_name=Time
>>  lon#units=degrees_east
>>  lon#long_name=Longitude
>>  lat#units=degrees_north
>>  lat#long_name=Latitude
>> Corner Coordinates:
>> Upper Left  ( -77.0119239,  46.0086701)
>> Lower Left  ( -77.0119239,  34.9905899)
>> Upper Right ( -62.9880722,  46.0086701)
>> Lower Right ( -62.9880722,  34.9905899)
>> Center      ( -69.9999981,  40.4996300)
>> Band 1 Block=1183x1 Type=Float32, ColorInterp=Undefined
>>  NoData Value=-999
>>  Metadata:
>>    NETCDF_VARNAME=mcsst
>>    NETCDF_DIMENSION_time=1191379020
>>    NETCDF_time_units=seconds since 1970-01-01 00:00:00
>>
>>
>>
>>
>>
>>
>>
>> ==============Original message text===============
>> On Fri, 01 Aug 2008 7:31:49 +1000 "Matt Oliver" wrote:
>>
>> Sorry, dlat is what changes
>>
>> an example file can be found at
>>
>> http://www.ocean.udel.edu/CMS/moliver/20071003.276.0237.n17.nc
>> use
>>
>> require(ncdf)
>>
>> f <- open.ncdf("20071003.276.0237.n17.nc"<
>> http://www.ocean.udel.edu/CMS/moliver/20071003.276.0237.n17.nc>)
>>
>> lon <- get.var.ncdf(f, "lon")
>>
>> lat <- get.var.ncdf(f, "lat")
>>
>>
>>
>> Thanks in advance
>>
>> Matt
>>
>>
>>
>>
>>
>>
>> On Thu, Jul 31, 2008 at 5:03 PM, Michael Sumner <mdsumner at utas.edu.au
>>     
>>> wrote:
>>>       
>>> You can use gdalwarp in FWTools to re-grid the data with control points
>>> (perhaps with with some effort), but as you say that will interpolate to
>>>       
>> a
>>     
>>> regular grid.
>>>
>>> Is it definitely dlon that increases? Can you post a link to an example
>>> file?
>>>
>>> Some netCDF files I've seen are actually using Mercator, but store the
>>> pixel coordinates as lon/lat.
>>>
>>> There are totally irregular grids as well though, so as a raster you
>>>       
>> would
>>     
>>> have to resample it in some way. Otherwise you can interpret the data as
>>>       
>> a
>>     
>>> SpatialPointsDataFrame and use it as you would in Matlab. Note that the
>>> image() function will handle irregular (but xy locked) grid spacings, so
>>>       
>> you
>>     
>>> can jig a function to plot these things as an image pretty easily.
>>>
>>> Cheers, Mike.
>>>
>>>
>>> Matt Oliver wrote:
>>>
>>>       
>>>> Hi All, I have CF compliant ncdf files of sea surface temperature. The
>>>> lon,
>>>> lat grid is known but not equally spaced (ie dlon increases). Is there a
>>>> clean way to get this matrix ported over to a geo-tiff or some other
>>>>         
>> file
>>     
>>>> that Arc will read? I have talked with some arc users that tell me that
>>>> the
>>>> grid needs to be equally spaced. I guess I could interpolate to an
>>>>         
>> equally
>>     
>>>> spaced grid, but I would rather preserve the original grid if possible.
>>>>
>>>> Thanks in advance
>>>>
>>>> Matt
>>>>
>>>>
>>>>
>>>>
>>>>         
>>>       
>> --
>> Matthew J. Oliver
>> Assistant Professor
>> College of Marine and Earth Studies
>> University of Delaware
>> 700 Pilottown Rd.
>> Lewes, DE, 19958
>> 302-645-4079
>> http://www.ocean.udel.edu/people/profile.aspx?moliver===========End of
>> original message text===========
>>
>>
>>
>> If it wasn't backed-up, then it wasn't important. ~ Anon sysadmin
>>
>> Mike Sumner (Phd. Candidate)
>> http://www.antcrc.utas.edu.au/~mdsumner/<http://www.antcrc.utas.edu.au/%7Emdsumner/>
>> http://www.zoo.utas.edu.au/awru/  IASOS/AWRU
>> University of Tasmania
>> Private Bag 80
>> Hobart Tasmania 7001
>> AUSTRALIA
>> Email: mdsumner at utas.edu.au
>> Phone: 03 6226 1752 (W)
>>       0408599921   (M)
>> Fax:   03 6226 2745
>>
>>
>>
>>
>>
>>
>>
>>
>>     
>
>
>



From alessandro.montaghi at unifi.it  Wed Aug  6 22:52:20 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Wed, 6 Aug 2008 13:52:20 -0700
Subject: [R-sig-Geo] eliminate outlays
Message-ID: <006e01c8f806$5304e0e0$f90ea2a0$@montaghi@unifi.it>

Hi All,

 

After a normalization of my data-set with:

 

testground$Z<-qnorm((rank(testground$Z)-0.375)/(sum(!is.na(testground$Z))+0.
25)) #normalize

 

In boxplot appear outlays  value (see fig). After this I wish eliminate this
outlays to processing the data with kriging model. There is suggestion
please?

 

Thank you a lot

 

Ale

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080806/4b556aca/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Senza titolo-1.jpg
Type: image/jpeg
Size: 29433 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080806/4b556aca/attachment.jpg>

From aloboaleu at gmail.com  Wed Aug  6 22:54:55 2008
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Wed, 06 Aug 2008 22:54:55 +0200
Subject: [R-sig-Geo] Hans Rosling presentations
Message-ID: <489A0F9F.8080305@gmail.com>

This is a bit off-topic, but these 2 videos
are an extraordinary example of the use of
interactive statistical graphics:

http://video.google.com/videoplay?docid=4237353244338529080&sourceid=searchfeed

http://www.ted.com/index.php/talks/hans_rosling_reveals_new_insights_on_poverty.html


...and a master piece of how to communicate a very important message to 
the public.

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From alessandro.montaghi at unifi.it  Wed Aug  6 22:55:32 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Wed, 6 Aug 2008 13:55:32 -0700
Subject: [R-sig-Geo] errata correge fig - eliminate outlays
Message-ID: <007801c8f806$c563bf80$502b3e80$@montaghi@unifi.it>

Sorry this is the corret fig

 

Ale

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080806/e3b77979/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Senza titolo-1.jpg
Type: image/jpeg
Size: 29433 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080806/e3b77979/attachment.jpg>

From wwwhsd at gmail.com  Wed Aug  6 23:08:25 2008
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 6 Aug 2008 18:08:25 -0300
Subject: [R-sig-Geo] eliminate outlays
In-Reply-To: <-8947049477532988638@unknownmsgid>
References: <-8947049477532988638@unknownmsgid>
Message-ID: <da79af330808061408n1ed252e0s4b4c0276cf80c93f@mail.gmail.com>

Try this:

set.seed(123)
x <- rnorm(100)
bp <- boxplot(x)
boxplot(x[!x == bp$out])

On Wed, Aug 6, 2008 at 5:52 PM, Alessandro <alessandro.montaghi at unifi.it> wrote:
> Hi All,
>
>
>
> After a normalization of my data-set with:
>
>
>
> testground$Z<-qnorm((rank(testground$Z)-0.375)/(sum(!is.na(testground$Z))+0.25))
> #normalize
>
>
>
> In boxplot appear outlays  value (see fig). After this I wish eliminate this
> outlays to processing the data with kriging model. There is suggestion
> please?
>
>
>
> Thank you a lot
>
>
>
> Ale
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



-- 
Henrique Dallazuanna
Curitiba-Paran?-Brasil
25? 25' 40" S 49? 16' 22" O



From dsb at vt.edu  Wed Aug  6 23:21:40 2008
From: dsb at vt.edu (David S. Bieri)
Date: Wed, 6 Aug 2008 17:21:40 -0400
Subject: [R-sig-Geo] Hans Rosling presentations
In-Reply-To: <489A0F9F.8080305@gmail.com>
References: <489A0F9F.8080305@gmail.com>
Message-ID: <BA2773A3C63541C19BD3744F253BF9C2@DSB>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080806/4d1d7116/attachment.pl>

From giohappy at gmail.com  Thu Aug  7 00:34:26 2008
From: giohappy at gmail.com (G. Allegri)
Date: Thu, 7 Aug 2008 00:34:26 +0200
Subject: [R-sig-Geo] Hans Rosling presentations
In-Reply-To: <BA2773A3C63541C19BD3744F253BF9C2@DSB>
References: <489A0F9F.8080305@gmail.com> <BA2773A3C63541C19BD3744F253BF9C2@DSB>
Message-ID: <e12429640808061534w67044f07o1239c3dd912c38b7@mail.gmail.com>

An Open Source version of GapMinder (completely developed from scratch
with Flex + AS3) is almost complete and coming out.
We're working on it... and will let you know when it will be ready :)

Giovanni

2008/8/6 David S. Bieri <dsb at vt.edu>:
> A beta online version of this software can be found here:
>
>
>
> http://www.gapminder.org/world/#$majorMode=chart$
>
>
>
> rgds,
> David
>
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Agustin Lobo
> Sent: Wednesday, August 06, 2008 4:55 PM
> To: sig-geo; mart? orta; Jaime Paneque Galvez; Ana Catarina Luz;
> Alexander.Rincon at uab.cat
> Subject: [R-sig-Geo] Hans Rosling presentations
>
>
>
> This is a bit off-topic, but these 2 videos
>
> are an extraordinary example of the use of
>
> interactive statistical graphics:
>
>
>
> http://video.google.com/videoplay?docid=4237353244338529080&sourceid=searchf
> eed
>
>
>
> http://www.ted.com/index.php/talks/hans_rosling_reveals_new_insights_on_pove
> rty.html
>
>
>
>
>
> ...and a master piece of how to communicate a very important message to
>
> the public.
>
>
>
> Agus
>
>
>
> --
>
> Dr. Agustin Lobo
>
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>
> LLuis Sole Sabaris s/n
>
> 08028 Barcelona
>
> Spain
>
> Tel. 34 934095410
>
> Fax. 34 934110012
>
> email: Agustin.Lobo at ija.csic.es
>
> http://www.ija.csic.es/gt/obster
>
>
>
> _______________________________________________
>
> R-sig-Geo mailing list
>
> R-sig-Geo at stat.math.ethz.ch
>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>        [[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



From alessandro.montaghi at unifi.it  Thu Aug  7 19:50:58 2008
From: alessandro.montaghi at unifi.it (Alessandro)
Date: Thu, 7 Aug 2008 10:50:58 -0700
Subject: [R-sig-Geo] stationary test
Message-ID: <001c01c8f8b6$26eb4bb0$74c1e310$@montaghi@unifi.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080807/ef7776ab/attachment.pl>

From neild at email.unc.edu  Thu Aug  7 21:37:09 2008
From: neild at email.unc.edu (Neil Davis)
Date: Thu, 07 Aug 2008 15:37:09 -0400
Subject: [R-sig-Geo] custom projection (SpatialPolygon)
Message-ID: <489B4EE5.10002@email.unc.edu>

I have a dataset which uses a custom projection, and I would like to 
import shape files to add maps to the plots.  I was able to import the 
shape file using maptools as both a SpatialLine, and SpatialPolygon, 
however I'm not sure how I can modify the coordinates to my custom map 
projection.  I have converted the standard R maps to my map projection, 
but the spatial objects are a little out of my understanding, as I am 
not sure how to get the coordinate values out of and then back into the 
spatial objects.

Does anyone know how I might be able to modify the coordinates of the 
spatial objects to my projection.

Thanks,

Neil Davis
Research Associate
Institute for the Environment - UNC Chapel Hill



From Roger.Bivand at nhh.no  Thu Aug  7 21:47:07 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 7 Aug 2008 21:47:07 +0200 (CEST)
Subject: [R-sig-Geo] custom projection (SpatialPolygon)
In-Reply-To: <489B4EE5.10002@email.unc.edu>
References: <489B4EE5.10002@email.unc.edu>
Message-ID: <Pine.LNX.4.64.0808072143450.4152@reclus.nhh.no>

On Thu, 7 Aug 2008, Neil Davis wrote:

> I have a dataset which uses a custom projection, and I would like to import 
> shape files to add maps to the plots.  I was able to import the shape file 
> using maptools as both a SpatialLine, and SpatialPolygon, however I'm not 
> sure how I can modify the coordinates to my custom map projection.  I have 
> converted the standard R maps to my map projection, but the spatial objects 
> are a little out of my understanding, as I am not sure how to get the 
> coordinate values out of and then back into the spatial objects.
>
> Does anyone know how I might be able to modify the coordinates of the spatial 
> objects to my projection.

If you cannot design a custom PROJ.4 description (especially the x and y 
offsets may be helpful) and use spTransform() methods in rgdal, you could 
look at elide() methods in the maptools package, which do allow some 
offsetting and perhaps even rotation (you need the angle) and some 
scaling. But the you lose the portability of a PROJ.4 description.

Hope this helps,

Roger

>
> Thanks,
>
> Neil Davis
> Research Associate
> Institute for the Environment - UNC Chapel Hill
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From milton.ruser at gmail.com  Thu Aug  7 22:28:47 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 7 Aug 2008 17:28:47 -0300
Subject: [R-sig-Geo] spgrass6 not running.
Message-ID: <3aaf1a030808071328j267ae036t1099fd03ded20b4d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080807/163a74da/attachment.pl>

From giohappy at gmail.com  Fri Aug  8 00:46:23 2008
From: giohappy at gmail.com (G. Allegri)
Date: Fri, 8 Aug 2008 00:46:23 +0200
Subject: [R-sig-Geo] stationary test
In-Reply-To: <844596504405625748@unknownmsgid>
References: <844596504405625748@unknownmsgid>
Message-ID: <e12429640808071546y7b0c2d64n9d085cf3a27941d0@mail.gmail.com>

kpss.test() from tseries package could be useful.
http://cran.r-project.org/web/packages/tseries/index.html

2008/8/7 Alessandro <alessandro.montaghi at unifi.it>:
> Hi All,
>
>
>
> is there un code to do a stationary test in R? because I have a data-base
> and I wish to know there is or not a stationary in my data-set.
>
>
>
> Alessandro
>
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Fri Aug  8 10:49:27 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 Aug 2008 10:49:27 +0200 (CEST)
Subject: [R-sig-Geo] spgrass6 not running.
In-Reply-To: <3aaf1a030808071328j267ae036t1099fd03ded20b4d@mail.gmail.com>
References: <3aaf1a030808071328j267ae036t1099fd03ded20b4d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0808081042110.6826@reclus.nhh.no>

On Thu, 7 Aug 2008, milton ruser wrote:

> Dear all,
>
> I am running native wingrass (6.3.0) and R (2.7.1)
> under a windows XP environment.
>
> When I try to load spgrass6 library I get and message
> that GRASS is not running.
>> require(spgrass6)
> Loading required package: spgrass6
> Loading required package: sp
> Loading required package: rgdal
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.5.2, released 2008/05/29
> GDAL_DATA: C:/ARQUIV~1/R/R-27~1.1/library/rgdal/gdal
> Loaded PROJ.4 runtime: Rel. 4.6.0, 21 Dec 2007
> PROJ_LIB: C:/ARQUIV~1/R/R-27~1.1/library/rgdal/proj
> GRASS GIS interface loaded with GRASS version: (GRASS not running)
>
> After that, when I try to run gmeta6() I get another error message.
>
>> gmeta6()
> Error in system(paste(paste("g.region", .addexe(), sep = ""), "-g3"),  :
>  g.region not found
>
> What I am doing wrong? I tryed fly over the spgrass6_0.3.pdf
> help doc file, but I can?t get advice there.

Please see my reply on the GRASS statistics list:

http://lists.osgeo.org/pipermail/grass-stats/2008-July/000833.html

verbatim:

"On my native Windows GRASS, 6.3.0 release, TclTk (wish) interface, I 
enter the full path to R - either "C:/Program Files/R/R-2.7.1/bin/R" 
(command line) or "C:/Program Files/R/R-2.7.1/bin/Rgui", and click either 
"Run" or "Run (background)", in the window named "Output - GIS.m", bottom 
pane.

You can find the correct path for your R in the properties of the R 
desktop icon. Use quotes if the path contains blanks, and forward slashes 
to avoid back slashes in the path being misinterpreted.

I have R_LIBS set as a user specific environment variable, so don't need 
to add this."

Refer to the other list link for the original question.

Native GRASS for windows is very new, but all the documentation applies 
once you find out how to start R in the right place. The Cygwin port is 
much more like OSX and Unix/Linux. Another version of native GRASS ships 
with QGIS for Windows. Since there are so many varieties, documenting how 
to proceed is far from easy.

Roger

>
> Any help are welcome.
>
>
> Kind regards,
>
> miltinho astronauta
> brazil
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From murray.richardson at utoronto.ca  Fri Aug  8 18:41:27 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Fri, 08 Aug 2008 12:41:27 -0400
Subject: [R-sig-Geo] read shapefile, iterate through rows in attribute table,
 update attribute table
Message-ID: <489C7737.6010909@utoronto.ca>

Hello users,

I am using R to create some scripts that involve a combination of SAGA 
functions (via RSAGA) and R processes. I need to read a polygon 
shapefile into R, interate through each polygon feature in the attribute 
table, convert it to its own shapefile, and do some processing on that 
individual polygon shapefile in SAGA.  I will then need to update the 
row's attributes (in the original shapefile) with the results of the 
SAGA process. 

I'm primarily looking on advice on how to read and iterate through the 
shapefile rows, converting each one into a temporary shapefile.  I also 
appreciate advice on updating records in a shapefile attribute table. 

Thanks in advance.

Murray Richardson



From Roger.Bivand at nhh.no  Fri Aug  8 18:51:06 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 Aug 2008 18:51:06 +0200 (CEST)
Subject: [R-sig-Geo] read shapefile,
 iterate through rows in attribute table, update attribute table
In-Reply-To: <489C7737.6010909@utoronto.ca>
References: <489C7737.6010909@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0808081847350.6826@reclus.nhh.no>

On Fri, 8 Aug 2008, Murray Richardson wrote:

> Hello users,
>
> I am using R to create some scripts that involve a combination of SAGA 
> functions (via RSAGA) and R processes. I need to read a polygon shapefile 
> into R, interate through each polygon feature in the attribute table, convert 
> it to its own shapefile, and do some processing on that individual polygon 
> shapefile in SAGA.  I will then need to update the row's attributes (in the 
> original shapefile) with the results of the SAGA process. 
> I'm primarily looking on advice on how to read and iterate through the 
> shapefile rows, converting each one into a temporary shapefile.  I also 
> appreciate advice on updating records in a shapefile attribute table. 
> Thanks in advance.

If the shapefile is read into a SpatialPolygonsDataFrame, then the [ 
subset operator works just as for other R objects. Something like:

for (i in 1:length(slot(x, "polygons"))) {
   tmpx <- x[i,]
   # do something with tmpx
}

will extract each Polygons object in turn as a (multi)-geometry with its 
vector of attributes.

Roger

>
> Murray Richardson
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From T.Hengl at uva.nl  Fri Aug  8 19:15:30 2008
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Fri, 8 Aug 2008 19:15:30 +0200
Subject: [R-sig-Geo] stationary test
In-Reply-To: <001c01c8f8b6$26eb4bb0$74c1e310$@montaghi@unifi.it>
Message-ID: <DF4D69086D114CD9A8F425C2DB9C0F29@pcibed193>


Dear Alessandro,

If I understand correctly, you have densely collected LiDAR data and would like to see if the
population/variogram parameters of your target variable (elevation) differ drastically in different
part of the area. In the case of elevation data and larger areas - I am sure they do.

In order to do something like this, you would need a tool that can estimate these parameters locally
i.e. in a moving window (Haas, 1990). This would then allow you to map the parameters over the whole
area of interest and then do statistical comparison for the purpose of stratification (Lloyd and
Atkinson, 1998) or localized prediction (Walter et al., 2001).

As far as I know, such analysis is not available in R, but you might try to try playing with a small
tool Budiman Minasny developed few years ago (Bishop et al. 2006):
http://www.usyd.edu.au/su/agric/acpa/software/digeman.htm

I imagine that something like this could be easily either run from R (it is distributed as windows
*.exe) or even implemented as a package (Budi works mainly in Matlab). I find Digeman extremely
interesting (it actually produces maps of variogram parameters!), but have not much time to test it.

See also: http://www.usyd.edu.au/su/agric/acpa/vesper/vesper.html 


all the best,

T. Hengl
http://spatial-analyst.net 


References:

Bishop, T.F.A., Minasny, B., McBratney, A.B., 2006. Uncertainty analysis for soil-terrain models.
International Journal of Geographical Information Science 20, 117-134.
Lloyd, C.D., Atkinson, P.M., 1998. Scale and the spatial structure of landform: optimizing sampling
strategies with geostatistics. In: Proceedings of the Third International Conference on
GeoComputation, University of Bristol, UK, 17?19 September 1998. University of Bristol, Bristol, UK,
16pp.
Haas, T. C., 1990. Kriging and automated semivariogram modelling within a moving window. Atmospheric
Environment 24A: 1759?1769.
Walter, C., McBratney, A. B., Donuaoui, A., Minasny, B., 2001. Spatial prediction of topsoil
salinity in the Chelif valley, Algeria, using local ordinary kriging with local variograms versus
whole-area variogram. Australian Journal of Soil Research 39: 259?272.




-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Alessandro
Sent: donderdag 7 augustus 2008 19:51
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] stationary test

Hi All,

 

is there un code to do a stationary test in R? because I have a data-base
and I wish to know there is or not a stationary in my data-set.

 

Alessandro 


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: UserGuide.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080808/419758eb/attachment.txt>

From adjemian at primal.ucdavis.edu  Sun Aug 10 00:23:03 2008
From: adjemian at primal.ucdavis.edu (adjemian)
Date: Sat, 09 Aug 2008 15:23:03 -0700
Subject: [R-sig-Geo] How to Import Distance Band .gwt Matrix
Message-ID: <489e18c7.175.4a5e.133920574@primal.ucdavis.edu>

List, 

I'm having some trouble importing a Geoda generated distance
band weight matrix into R for use with the spdep regression
tools.  The "read.gwt2nb" function does not work, and even
when I try to import a manually created version of the
matrix, I cannot seem to get it into the right format to
avoid frame errors when attempting to estimate lag/error
models.  Once I import the data in properly, I intend to
perform a test of the common factor hypothesis, which is
unavailable in Geoda.

Up to this point, I've tried to use "mat2listw", but the
program returns a faulty "matrix not standardized" warning,
and then produces the frame errors after regression
commands.  So, I have two questions:

1) Is there a pre-packaged "read.gwt2..." function that
imports distance based weight matrices into R for use with
spdep?
2) Failing that, how can I import a distance band weight
matrix into R (for use with spdep) while avoiding frame
errors?

Thanks in advance for your help!
-Mike Adjemian



From Roger.Bivand at nhh.no  Sun Aug 10 11:43:16 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 10 Aug 2008 11:43:16 +0200 (CEST)
Subject: [R-sig-Geo] How to Import Distance Band .gwt Matrix
In-Reply-To: <489e18c7.175.4a5e.133920574@primal.ucdavis.edu>
References: <489e18c7.175.4a5e.133920574@primal.ucdavis.edu>
Message-ID: <Pine.LNX.4.64.0808101135230.9603@reclus.nhh.no>

On Sat, 9 Aug 2008, adjemian wrote:

> List,
>
> I'm having some trouble importing a Geoda generated distance
> band weight matrix into R for use with the spdep regression
> tools.  The "read.gwt2nb" function does not work, and even
> when I try to import a manually created version of the
> matrix, I cannot seem to get it into the right format to
> avoid frame errors when attempting to estimate lag/error
> models.

In general, it is sensible to include the verbatim command and error 
messages from your console. The output of sessionInfo() is also helpful, 
as it shows what platform you are using, and what the versions of loaded 
packages are.

My guess is that you need to pay attention to the arguments to 
read.gwt2nb(). Have you tried the example provided on the help page? Note 
that the function only reads the neighbour links into an nb object, and 
you have to retrieve the distances as shown in the example. It may help to 
copy preceding commands in your question too, so that the origin og the 
values given to the arguments is made plain. str() of those objects may 
also help, if not too bulky.

I think that the errors in the model fitting functions will go away when 
the weights are read in correctly. Once they are imported, it may be 
interesting to re-create them with dnearneigh() and nbdist() within R, 
just for safety's sake.

Hope this helps,

Roger

> Once I import the data in properly, I intend to
> perform a test of the common factor hypothesis, which is
> unavailable in Geoda.
>
> Up to this point, I've tried to use "mat2listw", but the
> program returns a faulty "matrix not standardized" warning,
> and then produces the frame errors after regression
> commands.  So, I have two questions:
>
> 1) Is there a pre-packaged "read.gwt2..." function that
> imports distance based weight matrices into R for use with
> spdep?
> 2) Failing that, how can I import a distance band weight
> matrix into R (for use with spdep) while avoiding frame
> errors?
>
> Thanks in advance for your help!
> -Mike Adjemian
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From edzer.pebesma at uni-muenster.de  Mon Aug 11 15:45:25 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 11 Aug 2008 15:45:25 +0200
Subject: [R-sig-Geo] chronolgy of drawing of sp.layout
In-Reply-To: <489326C3.1070707@univ-lille1.fr>
References: <489326C3.1070707@univ-lille1.fr>
Message-ID: <48A04275.6090202@uni-muenster.de>



Maxime Pauwels wrote:
> Hello,
>
> I'm using R and the sp package for only a few days. I have already
> resolved numerous basical questions but the following one resists:
> I'd like to plot spatial data with attributes and to highlight a few
> points on the plot corresponding to samples locations ("pop" below).
>
> Here is my script:
>
> library(sp)
> library(lattice) # required for trellis.par.set():
> trellis.par.set(sp.theme()) # sets color ramp to bpy.colors()
> data <- read.table("rdataNssSS.txt", header=T)
> class(data)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
> coordinates(data) <- ~gridlong+gridlat
> spplot(data, c("gridr"), scales=list(draw=T),cuts=20, regions=T,
> main="rvalues", xlab = "longitude (dec.)", ylab="latitude(dec.)",
> key.space="right")
> #samples location
> coordpop <- read.table("coordpop.txt", header=T)
> x <- coordpop$long
> y <- coordpop$lat
> pop <- SpatialPoints(list(x,y))
> class(pop)
> #[1] "SpatialPoints"
> #attr(,"package")
> #[1] "sp"
> poppoints = list("sp.points", pop, pch=21, col="black", fill="black")
> spplot(data, c("gridr"), scales=list(draw=T),cuts=20, regions=T,
> main="rvalues", xlab = "longitude (dec.)", ylab="latitude(dec.)",
> key.space="right", sp.layout=list(poppoints))
>
>
> the problem is that, as explained in the sp package manual, sp.layout
> item is drawn first, before the plot of point in "data". Given that pop
> points are included in data, I can't see them anymore at the end of 
> spplot.
>
> Does anyone have a solution to reverse this?
Have you tried

spplot(...,
    sp.layout=list(poppoints, first=FALSE))

?
--
Edzer
>
> Max
>
>
>
>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From edzer.pebesma at uni-muenster.de  Mon Aug 11 16:03:54 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 11 Aug 2008 16:03:54 +0200
Subject: [R-sig-Geo] How to estimate variables of a given vgm model?
In-Reply-To: <86DBA0678E017341B449A62F258E29561548B7@IS-EX-BEV3.unimelb.edu.au>
References: <86DBA0678E017341B449A62F258E29561548B7@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <48A046CA.90100@uni-muenster.de>

function variogramLine in package gstat computes semivariances for a 
(regular) set of distances.
--
Edzer

Yong Li wrote:
> Hi ALL,
>
> How can I calculate the corresponding semivariance or distance if a vgm
> model (model, nug, psill, range are known) and a value of either
> semivariance or distance are given?
> I am using gstat R package.
>
> Regards
>
> Yong
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From Daniel.Rainham at dal.ca  Mon Aug 11 20:53:12 2008
From: Daniel.Rainham at dal.ca (Daniel Rainham)
Date: Mon, 11 Aug 2008 15:53:12 -0300
Subject: [R-sig-Geo] kernel2D to shape
Message-ID: <20080811155312.1zhjyzhz2ocoocgo@my4.dal.ca>

Hello,

I have collected GPS data on individuals (humans) at one second intervals for
approximately seven days. The file is read into R and the coordinates are
converted from decimal degrees to UTM. I then calculate two measures: 1.
Minimum convex polygon (using the ASPACE packge) 2. Kernel density estimate
(using SPLANCS, kernel2d function)

The first measure, MCP, can be output to a shapefile using makeshapes in the
ASPACE package for further analysis in a GIS package.

I would like to be able to do the same with the KDE, either as a raster (grid if
using ArcGIS), or would also be happy with polyline contours if possible in
.shp format. Why? Because I would like to extract information from other layers
in the GIS that correspond to the boundaries and intensities of the KDE
surface.

Is this currently possible from within R? If so, can anyone share with me the
process or code to achieve the conversion?

Thanks in advance for your help. I can send my full R code if required.

Daniel Rainham
Dalhousie University



From ryan.anderson at ntsg.umt.edu  Mon Aug 11 21:40:28 2008
From: ryan.anderson at ntsg.umt.edu (Ryan Anderson)
Date: Mon, 11 Aug 2008 13:40:28 -0600 (MDT)
Subject: [R-sig-Geo] Plotting polygons on top of a levelplot
Message-ID: <45867.10.8.104.111.1218483628.squirrel@secure.ntsg.umt.edu>

I have some gridded spatial data that I want to plot with a vector overlay
on top.  The following reproducible code makes a figure similar to the one
I am ultimately trying to produce:

library(sp)
library(fields)
data(meuse.grid)
data(meuse.riv)
coords <- SpatialPixels(SpatialPoints(meuse.grid[, c("x","y")]))
spdf <- SpatialPixelsDataFrame(coords, meuse.grid)
fullgrid(spdf)<-TRUE
river<-SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
par(mar = c(5,5,5,8), col.axis = 1)
ramp = heat.colors(400)
image(spdf, "dist", axes = TRUE, col = ramp)
plot(river, add = TRUE)
zvals<-spdf$dist
zvals<-zvals[!is.na(zvals)]
image.plot(zlim = c(min(zvals), max(zvals)), nlevel = 256, legend.only =
TRUE, col = ramp)

I need more control over the legend and the color ramp than I know how to
achieve with this code.  I can create the plot I want with levelplot by
setting the 'at' component 'colorkey', but when I try to overlay the
vector file I get an error.  Here is a simplified version of the code I
tried:

#try a levelplot
library(lattice)
x11()
par(mar = c(5,5,5,8))
x<-spdf$x
y<-spdf$y
z<-spdf$dist
levelplot(z~x+y)
plot(river, add = TRUE)
#Gives Error in polygon(x = x, y = y, border = border, col = col, lty =
#lty,  :
#  plot.new has not been called yet

I need to either find a way to control the mapping of data values to the
color ramp more precisely in my call to image or image.plot or to find a
way to plot a ploygon over the top of a levelplot.

My color ramp goals more specifically: my grid contains both positive and
negative values, and they are not necessarily symmetrically distributed
around zero.  I want to plot them so that zero is white, negative values
are symbolized with a ramp from white to blue (with darker shades for
lower values) and positive values are symbolized with a ramp from white to
red (with darker shades for higher values).

Thanks for your help!



From edzer.pebesma at uni-muenster.de  Mon Aug 11 21:54:26 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 11 Aug 2008 21:54:26 +0200
Subject: [R-sig-Geo] Plotting polygons on top of a levelplot
In-Reply-To: <45867.10.8.104.111.1218483628.squirrel@secure.ntsg.umt.edu>
References: <45867.10.8.104.111.1218483628.squirrel@secure.ntsg.umt.edu>
Message-ID: <48A098F2.8070103@uni-muenster.de>

Ryan, you're probably looking for something like

spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)

spplot is a wrapper around lattice functions for spatial data, and tries 
to pass on all the lattice controls.
--
Edzer

Ryan Anderson wrote:
> I have some gridded spatial data that I want to plot with a vector overlay
> on top.  The following reproducible code makes a figure similar to the one
> I am ultimately trying to produce:
>
> library(sp)
> library(fields)
> data(meuse.grid)
> data(meuse.riv)
> coords <- SpatialPixels(SpatialPoints(meuse.grid[, c("x","y")]))
> spdf <- SpatialPixelsDataFrame(coords, meuse.grid)
> fullgrid(spdf)<-TRUE
> river<-SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
> par(mar = c(5,5,5,8), col.axis = 1)
> ramp = heat.colors(400)
> image(spdf, "dist", axes = TRUE, col = ramp)
> plot(river, add = TRUE)
> zvals<-spdf$dist
> zvals<-zvals[!is.na(zvals)]
> image.plot(zlim = c(min(zvals), max(zvals)), nlevel = 256, legend.only =
> TRUE, col = ramp)
>
> I need more control over the legend and the color ramp than I know how to
> achieve with this code.  I can create the plot I want with levelplot by
> setting the 'at' component 'colorkey', but when I try to overlay the
> vector file I get an error.  Here is a simplified version of the code I
> tried:
>
> #try a levelplot
> library(lattice)
> x11()
> par(mar = c(5,5,5,8))
> x<-spdf$x
> y<-spdf$y
> z<-spdf$dist
> levelplot(z~x+y)
> plot(river, add = TRUE)
> #Gives Error in polygon(x = x, y = y, border = border, col = col, lty =
> #lty,  :
> #  plot.new has not been called yet
>
> I need to either find a way to control the mapping of data values to the
> color ramp more precisely in my call to image or image.plot or to find a
> way to plot a ploygon over the top of a levelplot.
>
> My color ramp goals more specifically: my grid contains both positive and
> negative values, and they are not necessarily symmetrically distributed
> around zero.  I want to plot them so that zero is white, negative values
> are symbolized with a ramp from white to blue (with darker shades for
> lower values) and positive values are symbolized with a ramp from white to
> red (with darker shades for higher values).
>
> Thanks for your help!
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From ryan.anderson at ntsg.umt.edu  Mon Aug 11 22:15:05 2008
From: ryan.anderson at ntsg.umt.edu (Ryan Anderson)
Date: Mon, 11 Aug 2008 14:15:05 -0600 (MDT)
Subject: [R-sig-Geo] Plotting polygons on top of a levelplot
In-Reply-To: <48A098F2.8070103@uni-muenster.de>
References: <45867.10.8.104.111.1218483628.squirrel@secure.ntsg.umt.edu>
	<48A098F2.8070103@uni-muenster.de>
Message-ID: <49475.10.8.104.111.1218485705.squirrel@secure.ntsg.umt.edu>

That likely gives me the control over the color ramp that I am looking
for, but I still have trouble plotting the vector layer over the top of
the resulting image plot.
If I do:
 spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)
 plot(river, add = TRUE)
I still get the plot.new has not been called yet error after I attempt to
add the river data.  What am I doing wrong?

Thanks,
Ryan


> Ryan, you're probably looking for something like
>
> spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)
>
> spplot is a wrapper around lattice functions for spatial data, and tries
> to pass on all the lattice controls.
> --
> Edzer
>
> Ryan Anderson wrote:
>> I have some gridded spatial data that I want to plot with a vector
>> overlay
>> on top.  The following reproducible code makes a figure similar to the
>> one
>> I am ultimately trying to produce:
>>
>> library(sp)
>> library(fields)
>> data(meuse.grid)
>> data(meuse.riv)
>> coords <- SpatialPixels(SpatialPoints(meuse.grid[, c("x","y")]))
>> spdf <- SpatialPixelsDataFrame(coords, meuse.grid)
>> fullgrid(spdf)<-TRUE
>> river<-SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
>> par(mar = c(5,5,5,8), col.axis = 1)
>> ramp = heat.colors(400)
>> image(spdf, "dist", axes = TRUE, col = ramp)
>> plot(river, add = TRUE)
>> zvals<-spdf$dist
>> zvals<-zvals[!is.na(zvals)]
>> image.plot(zlim = c(min(zvals), max(zvals)), nlevel = 256, legend.only =
>> TRUE, col = ramp)
>>
>> I need more control over the legend and the color ramp than I know how
>> to
>> achieve with this code.  I can create the plot I want with levelplot by
>> setting the 'at' component 'colorkey', but when I try to overlay the
>> vector file I get an error.  Here is a simplified version of the code I
>> tried:
>>
>> #try a levelplot
>> library(lattice)
>> x11()
>> par(mar = c(5,5,5,8))
>> x<-spdf$x
>> y<-spdf$y
>> z<-spdf$dist
>> levelplot(z~x+y)
>> plot(river, add = TRUE)
>> #Gives Error in polygon(x = x, y = y, border = border, col = col, lty =
>> #lty,  :
>> #  plot.new has not been called yet
>>
>> I need to either find a way to control the mapping of data values to the
>> color ramp more precisely in my call to image or image.plot or to find a
>> way to plot a ploygon over the top of a levelplot.
>>
>> My color ramp goals more specifically: my grid contains both positive
>> and
>> negative values, and they are not necessarily symmetrically distributed
>> around zero.  I want to plot them so that zero is white, negative values
>> are symbolized with a ramp from white to blue (with darker shades for
>> lower values) and positive values are symbolized with a ramp from white
>> to
>> red (with darker shades for higher values).
>>
>> Thanks for your help!
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster,
> Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
>
>



From edzer.pebesma at uni-muenster.de  Mon Aug 11 23:21:57 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 11 Aug 2008 23:21:57 +0200
Subject: [R-sig-Geo] Plotting polygons on top of a levelplot
In-Reply-To: <49475.10.8.104.111.1218485705.squirrel@secure.ntsg.umt.edu>
References: <45867.10.8.104.111.1218483628.squirrel@secure.ntsg.umt.edu>
	<48A098F2.8070103@uni-muenster.de>
	<49475.10.8.104.111.1218485705.squirrel@secure.ntsg.umt.edu>
Message-ID: <48A0AD75.1070102@uni-muenster.de>

No, it's me, I only read half of your question. Try something like

spplot(spdf["dist"], sp.layout=list("sp.polygons", river))

or the incremental build, in lattice style, of

spplot(spdf["dist"])
library(lattice)
spplot(spdf["dist"])
trellis.focus("panel", 1, 1)
sp.polygons(river)
trellis.unfocus()

which will put the river on the foreground. This can be obtained in a 
single pass with

spplot(spdf["dist"], sp.layout=list("sp.polygons", river, first=FALSE))

I slowly get the feeling that spplot needs a bit more documentation, or 
examples.
--
Edzer

Ryan Anderson wrote:
> That likely gives me the control over the color ramp that I am looking
> for, but I still have trouble plotting the vector layer over the top of
> the resulting image plot.
> If I do:
>  spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)
>  plot(river, add = TRUE)
> I still get the plot.new has not been called yet error after I attempt to
> add the river data.  What am I doing wrong?
>
> Thanks,
> Ryan
>
>
>   
>> Ryan, you're probably looking for something like
>>
>> spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)
>>
>> spplot is a wrapper around lattice functions for spatial data, and tries
>> to pass on all the lattice controls.
>> --
>> Edzer
>>
>> Ryan Anderson wrote:
>>     
>>> I have some gridded spatial data that I want to plot with a vector
>>> overlay
>>> on top.  The following reproducible code makes a figure similar to the
>>> one
>>> I am ultimately trying to produce:
>>>
>>> library(sp)
>>> library(fields)
>>> data(meuse.grid)
>>> data(meuse.riv)
>>> coords <- SpatialPixels(SpatialPoints(meuse.grid[, c("x","y")]))
>>> spdf <- SpatialPixelsDataFrame(coords, meuse.grid)
>>> fullgrid(spdf)<-TRUE
>>> river<-SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
>>> par(mar = c(5,5,5,8), col.axis = 1)
>>> ramp = heat.colors(400)
>>> image(spdf, "dist", axes = TRUE, col = ramp)
>>> plot(river, add = TRUE)
>>> zvals<-spdf$dist
>>> zvals<-zvals[!is.na(zvals)]
>>> image.plot(zlim = c(min(zvals), max(zvals)), nlevel = 256, legend.only =
>>> TRUE, col = ramp)
>>>
>>> I need more control over the legend and the color ramp than I know how
>>> to
>>> achieve with this code.  I can create the plot I want with levelplot by
>>> setting the 'at' component 'colorkey', but when I try to overlay the
>>> vector file I get an error.  Here is a simplified version of the code I
>>> tried:
>>>
>>> #try a levelplot
>>> library(lattice)
>>> x11()
>>> par(mar = c(5,5,5,8))
>>> x<-spdf$x
>>> y<-spdf$y
>>> z<-spdf$dist
>>> levelplot(z~x+y)
>>> plot(river, add = TRUE)
>>> #Gives Error in polygon(x = x, y = y, border = border, col = col, lty =
>>> #lty,  :
>>> #  plot.new has not been called yet
>>>
>>> I need to either find a way to control the mapping of data values to the
>>> color ramp more precisely in my call to image or image.plot or to find a
>>> way to plot a ploygon over the top of a levelplot.
>>>
>>> My color ramp goals more specifically: my grid contains both positive
>>> and
>>> negative values, and they are not necessarily symmetrically distributed
>>> around zero.  I want to plot them so that zero is white, negative values
>>> are symbolized with a ramp from white to blue (with darker shades for
>>> lower values) and positive values are symbolized with a ramp from white
>>> to
>>> red (with darker shades for higher values).
>>>
>>> Thanks for your help!
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>       
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi), University of M?nster,
>> Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
>> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
>>
>>
>>     
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From mdsumner at utas.edu.au  Mon Aug 11 23:42:59 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Tue, 12 Aug 2008 07:42:59 +1000
Subject: [R-sig-Geo] kernel2D to shape
In-Reply-To: <20080811155312.1zhjyzhz2ocoocgo@my4.dal.ca>
References: <20080811155312.1zhjyzhz2ocoocgo@my4.dal.ca>
Message-ID: <48A0B263.4070208@utas.edu.au>

Hello,

The spatial support in R gives you many options, one I know is to use 
contourLines() with an image() grid, and then converting that to a 
SpatialLinesDataFrame with ContourLines2SLDF() in the maptools package.

The SLDF can then be written to shapefile with writeOGR() in rgdal 
package. For example:

library(splancs)
library(rgdal)
library(maptools)
data(bodmin)
img <- kernel2d(as.points(bodmin), bodmin$poly, h0=2, nx=100, ny=100)
img.contours <- ContourLines2SLDF(contourLines(img))
writeOGR(img.contours, "contours.shp", "contours", "ESRI Shapefile")

# check the result
tst <- readOGR("contours.shp", "contours")
image(img)
plot(tst, add = TRUE)

HTH

Cheers, Mike.


Daniel Rainham wrote:
> Hello,
>
> I have collected GPS data on individuals (humans) at one second intervals for
> approximately seven days. The file is read into R and the coordinates are
> converted from decimal degrees to UTM. I then calculate two measures: 1.
> Minimum convex polygon (using the ASPACE packge) 2. Kernel density estimate
> (using SPLANCS, kernel2d function)
>
> The first measure, MCP, can be output to a shapefile using makeshapes in the
> ASPACE package for further analysis in a GIS package.
>
> I would like to be able to do the same with the KDE, either as a raster (grid if
> using ArcGIS), or would also be happy with polyline contours if possible in
> .shp format. Why? Because I would like to extract information from other layers
> in the GIS that correspond to the boundaries and intensities of the KDE
> surface.
>
> Is this currently possible from within R? If so, can anyone share with me the
> process or code to achieve the conversion?
>
> Thanks in advance for your help. I can send my full R code if required.
>
> Daniel Rainham
> Dalhousie University
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> No virus found in this incoming message.
> Checked by AVG - http://www.avg.com 
> Version: 8.0.138 / Virus Database: 270.6.0/1604 - Release Date: 8/11/2008 5:50 AM
>
>
>
>



From lescroel at cebc.cnrs.fr  Tue Aug 12 14:30:20 2008
From: lescroel at cebc.cnrs.fr (Amelie LESCROEL)
Date: Tue, 12 Aug 2008 14:30:20 +0200
Subject: [R-sig-Geo] [R] Unexpected parameter problem using
	rsaga.geoprocessor() {RSAGA}
Message-ID: <48A1825C.8030309@cebc.cnrs.fr>

Dear Alex, Thanks a lot for your quick and efficient answer. I did not 
think about "double double-quoting" the path '""', as "simple" 
double-quoting "" usually works in R for paths containing spaces. Now, 
it works perfectly well and I was able to process my grids from within R 
in the same way as I processed them in SAGA: > 
rsaga.geoprocessor("io_grid", 4, list(GRID="199710.sgrd", 
FILE_DATA='"C:/Documents and Settings/lescroel/Mes 
documents/pub/DATASETS/seaice/polar-stereo/nasateam/final-gsfc/south/monthly/nt_199710_f13_v01_s.bin"', 
NX=316, NY=332, DXY=25, XMIN=-3950, YMIN=-3950, DATA_OFFSET=300, 
TOPDOWN=1)) > rsaga.geoprocessor("grid_calculus", 1, 
list(INPUT="199710.sgrd", RESULT="SIC_DATA_OCT_97.sgrd", 
FORMUL="a*0.4")) > rsaga.geoprocessor("grid_tools", 15, 
list(INPUT="SIC_DATA_OCT_97.sgrd", RESULT="SIC_OCT97_wo_Land.sgrd", 
METHOD=1, MIN=101, MAX=101.6, RNEW=-99999, ROPERATOR=0)) > 
rsaga.geoprocessor("grid_calculus", 1, 
list(INPUT="SIC_OCT98_wo_Land.sgrd;Crozier_lat.sgrd;Crozier_lon.sgrd", 
RESULT="FORAGING_AREA_OCT97.sgrd", FORMUL="a*b*c")) I'm encountering a 
new problem though: now, I would like to work with the last obtained 
grid "FORAGING_AREA_OCT97.sgrd" in R for performing basic statistics 
(like obtaining the mean value of all cells). I was not able to find a 
way to transform or read the .sgrd file into a R object (matrix or data 
frame) that I could easily manipulate. I tried the following: > oct97 <- 
read.sgrd("C:/Documents and 
Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sgrd") Erreur dans 
read.sgrd("C:/Documents and 
Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sgrd") : error converting 
the SAGA sgrd file to a temporary ASCII grid file > oct97 <- 
read.Rd.grid("C:/Documents and 
Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sdat") Erreur : mauvais 
num?ro magique de restauration de fichier (le fichier est peut ?tre 
corrompu) -- aucune donn?e charg?e ## Translation of the error message 
"Error: wrong file restoring magic number (the file may be corrupted) - 
no data loaded" De plus : Warning message: file 
'FORAGING_AREA_OCT97.sdat' has magic number '?O???' Use of save versions 
prior to 2 is deprecated Could you or someone else help me again? Many 
thanks, Am?lie PS: I'm posting this message to the R-sig-geo list this 
time! Message: 140 Date: Tue, 12 Aug 2008 03:02:03 -0400 From: Alexander 
Brenning <brenning at fesmail.uwaterloo.ca> Subject: Re: [R] Unexpected 
parameter problem using rsaga.geoprocessor() {RSAGA} To: Am?lie Lescro?l 
<lescroel_cebc at no-log.org> Cc: r-help at R-project.org Message-ID: 
<48A1356B.10404 at fes.uwaterloo.ca> Content-Type: text/plain; 
charset=windows-1252; format=flowed Dear Amelie, > Le service Beep n'est 
pas lanc?. this can be fixed by passing an additional argument beep.off 
= FALSE to the rsaga.geoprocessor function; the most recent RSAGA 
release on CRAN does not cause this problem any more, I recommend you to 
update the package in your installation. The beep.off thing was an 
attempt to stop SAGA from beeping each time a module has been executed. 
 > Unexpected parameter 'and' If a file path or file name contains 
spaces as in "Documents and Settings", you would have to double quote 
it, e.g., '"My Folder"' rather than "My Folder" This will make sure that 
SAGA knows that the space does not separate different arguments. After 
all, RSAGA uses the SAGA command line interface. However, it is always a 
good idea to use the setwd() function to change the working directory. 
This will keep the path short. I hope this helps. Alex P.S.: You might 
wish to consider the R-sig-geo list for questions regarding spatial/GIS 
support in R. Am?lie Lescro?l wrote:

> > Hello,
> > I discovered SAGA, an interesting free GIS, a few days ago and now, I 
> > would like to use it from within R 2.6.2 using the RSAGA package. I read 
> > the documentation for this package and thought that I understood it 
> > correctly for trying to call some of the SAGA modules. For getting the 
> > information on the usage of and arguments required by the SAGA command 
> > line "Import Binary Raw Data" module, I used:
> > 
> >  > rsaga.get.usage("io_grid", 4)
> > SAGA CMD 2.0.3
> > library path: C:/Progra~1/saga_vc/modules
> > library name: io_grid
> > module name : Import Binary Raw Data
> > Usage: 4 [-GRID <str>] [-FILE_DATA <str>] [-NX <num>] [-NY <num>] [-DXY 
> > <str>] [-XMIN <str>] [-YMIN <str>] [-UNIT <str>] [-ZFACTOR <str>] 
> > [-NODATA <str>] [-DATA_OFFSET <num>] [-LINE_OFFSET <num>] [-LINE_ENDSET 
> > <num>] [-DATA_TYPE <num>] [-BYTEORDER_BIG <num>] [-TOPDOWN <num>]
> > -GRID:<str> Grid
> > Data Object (optional output)
> > -FILE_DATA:<str> Raw Data File
> > File path
> > -NX:<num> Cell Count (X)
> > Integer
> > -NY:<num> Cell Count (Y)
> > Integer
> > -DXY:<str> Cell Size
> > Floating point
> > -XMIN:<str> Left Border (X)
> > Floating point
> > -YMIN:<str> Lower Border (Y)
> > Floating point
> > -UNIT:<str> Unit Name
> > Text
> > -ZFACTOR:<str> Z Multiplier
> > Floating point
> > -NODATA:<str> No Data Value
> > Floating point
> > -DATA_OFFSET:<num> Data Offset (Bytes)
> > Integer
> > -LINE_OFFSET:<num> Line Offset (Bytes)
> > Integer
> > -LINE_ENDSET:<num> Line Endset (Bytes)
> > Integer
> > -DATA_TYPE:<num> Data Type
> > Choice
> > Available Choices:
> > [0] 1 Byte Integer (unsigned)
> > [1] 1 Byte Integer (signed)
> > [2] 2 Byte Integer (unsigned)
> > [3] 2 Byte Integer (signed)
> > [4] 4 Byte Integer (unsigned)
> > [5] 4 Byte Integer (signed)
> > [6] 4 Byte Floating Point
> > [7] 8 Byte Floating Point
> > -BYTEORDER_BIG:<num> Byte Order
> > Choice
> > Available Choices:
> > [0] Little Endian (Intel)
> > [1] Big Endian (Motorola)
> > -TOPDOWN:<num> Line Order
> > Choice
> > Available Choices:
> > [0] Bottom to Top
> > [1] Top to Bottom
> > 
> > Then, I wrote the following command for importing a grid of binary raw 
> > data while specifying the parameters I usually enter under SAGA:
> > 
> >  > rsaga.geoprocessor("io_grid", 4, list(GRID="199710.sgrd", 
> > FILE_DATA="C:/Documents and Settings/lescroel/Mes 
> > documents/pub/DATASETS/seaice/polar-stereo/nasateam/final-gsfc/south/monthly/nt_199710_f13_v01_s.bin", 
> > NX=316, NY=332, DXY=25, XMIN=-3950, DATA_OFFSET=300, TOPDOWN=1))
> > 
> > and I got:
> > 
> > Le service Beep n'est pas lanc?.
> > 
> > Vous obtiendrez une aide suppl?mentaire en entrant NET HELPMSG 3521.
> > 
> > 
> > C:\Documents and 
> > Settings\lescroel\Bureau>C:\Progra~1\saga_vc\saga_cmd.exe io_grid 4 
> > -silent -GRID 199710.sgrd -FILE_DATA C:\Documents and 
> > Settings\lescroel\Mes 
> > documents\pub\DATASETS\seaice\polar-stereo\nasateam\final-gsfc\south\monthly\nt_199710_f13_v01_s.bin 
> > -NX 316 -NY 332 -DXY 25 -XMIN -3950 -DATA_OFFSET 300 -TOPDOWN 1
> > 
> > SAGA CMD 2.0.3
> > library path: C:/Progra~1/saga_vc/modules
> > library name: io_grid
> > module name : Import Binary Raw Data
> > author : (c) 2003 by O.Conrad
> > 
> > error: executing module [Import Binary Raw Data]
> > Usage: -silent [-GRID <str>] [-FILE_DATA <str>] [-NX <num>] [-NY <num>] 
> > [-DXY <str>] [-XMIN <str>] [-YMIN <str>] [-UNIT <str>] [-ZFACTOR <str>] 
> > [-NODATA <str>] [-DATA_OFFSET <num>] [-LINE_OFFSET <num>] [-LINE_ENDSET 
> > <num>] [-DATA_TYPE <num>] [-BYTEORDER_BIG <num>] [-TOPDOWN <num>]
> > -GRID:<str> Grid
> > Data Object (optional output)
> > -FILE_DATA:<str> Raw Data File
> > File path
> > -NX:<num> Cell Count (X)
> > Integer
> > -NY:<num> Cell Count (Y)
> > Integer
> > -DXY:<str> Cell Size
> > Floating point
> > -XMIN:<str> Left Border (X)
> > Floating point
> > -YMIN:<str> Lower Border (Y)
> > Floating point
> > -UNIT:<str> Unit Name
> > Text
> > -ZFACTOR:<str> Z Multiplier
> > Floating point
> > -NODATA:<str> No Data Value
> > Floating point
> > -DATA_OFFSET:<num> Data Offset (Bytes)
> > Integer
> > -LINE_OFFSET:<num> Line Offset (Bytes)
> > Integer
> > -LINE_ENDSET:<num> Line Endset (Bytes)
> > Integer
> > -DATA_TYPE:<num> Data Type
> > Choice
> > Available Choices:
> > [0] 1 Byte Integer (unsigned)
> > [1] 1 Byte Integer (signed)
> > [2] 2 Byte Integer (unsigned)
> > [3] 2 Byte Integer (signed)
> > [4] 4 Byte Integer (unsigned)
> > [5] 4 Byte Integer (signed)
> > [6] 4 Byte Floating Point
> > [7] 8 Byte Floating Point
> > -BYTEORDER_BIG:<num> Byte Order
> > Choice
> > Available Choices:
> > [0] Little Endian (Intel)
> > [1] Big Endian (Motorola)
> > -TOPDOWN:<num> Line Order
> > Choice
> > Available Choices:
> > [0] Bottom to Top
> > [1] Top to Bottom
> > Unexpected parameter 'and'
> > 
> > Could someone already using the RSAGA package provide some help in 
> > telling me what I did wrong?
> > Thanks for your help,
> > 
> > Am?lie
>   

-- Alexander Brenning brenning at uwaterloo.ca - T +1-519-888-4567 ext 
35783 Department of Geography and Environmental Management University of 
Waterloo 200 University Ave. W - Waterloo, ON - Canada N2L 3G1 
http://www.fes.uwaterloo.ca/geography/faculty/brenning/

-- 

-------------------------------------------------------------------------------------------------------------------------------- 

*Am?lie Lescro?l*
Postdoc - Seabird ecology
Centre d?Etudes Biologiques de Chiz? ? 79360 Villiers en Bois ? France

*_http://www.cebc.cnrs.fr/Fidentite/lescroel/lescroel.htm_*

*_http://www.cebc.cnrs.fr/ecomm/En_ecomm/En_index.html_*

*_http://www.penguinscience.com_* <http://www.penguinscience.com/>
-------------------------------------------------------------------------------------------------------------------------------- 

/"You have to have the debate and you have to have people thinking 
creatively, and then, ultimately, you'll come down to the truth"/





__________ Information from ESET Mail Security, version of virus signature database 3348 (20080812) __________

The message was checked by ESET Mail Security.
http://www.eset.com


    part000.txt - is OK



From E.O.Folmer at rug.nl  Tue Aug 12 15:57:18 2008
From: E.O.Folmer at rug.nl (Eelke Folmer)
Date: Tue, 12 Aug 2008 15:57:18 +0200
Subject: [R-sig-Geo] panel figure with multiple spplot objects
Message-ID: <200808121357.m7CDvfRL002131@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080812/57f44737/attachment.pl>

From lescroel at cebc.cnrs.fr  Tue Aug 12 16:17:39 2008
From: lescroel at cebc.cnrs.fr (Amelie LESCROEL)
Date: Tue, 12 Aug 2008 16:17:39 +0200
Subject: [R-sig-Geo] [R] Unexpected parameter problem using
	rsaga.geoprocessor() {RSAGA}
In-Reply-To: <48A18E66.6020408@fes.uwaterloo.ca>
References: <48A1825C.8030309@cebc.cnrs.fr> <48A18E66.6020408@fes.uwaterloo.ca>
Message-ID: <48A19B83.8080408@cebc.cnrs.fr>

Dear Alex,
Thanks again for your help. I'll seriously think about using setwd(), I 
promise! I also succeeded circumventing the problem by using the 
following code:

library(RSAGA)
library(rgdal)
rsaga.geoprocessor("io_grid", 4, list(GRID="grid1.sgrd", 
FILE_DATA='"C:/.../nt_200602_f13_v01_s.bin"', NX=316, NY=332, DXY=25, 
XMIN=-3950, YMIN=-3950, DATA_OFFSET=300, TOPDOWN=1))
rsaga.geoprocessor("grid_calculus", 1, list(INPUT="grid1.sgrd", 
RESULT="grid2.sgrd", FORMUL="a*0.4"))
rsaga.geoprocessor("grid_tools", 15, list(INPUT="grid2.sgrd", 
RESULT="grid3.sgrd", METHOD=1, MIN=101, MAX=101.6, RNEW=-99999, 
ROPERATOR=0))
rsaga.geoprocessor("grid_calculus", 1, 
list(INPUT="grid3.sgrd;Crozier_lat.sgrd;Crozier_lon.sgrd", 
RESULT="grid4.sgrd", FORMUL="a*b*c"))
rsaga.sgrd.to.esri(in.sgrds="grid4.sgrd", out.grids="grid4.asc")
x1 <- new("GDALReadOnlyDataset", "grid4.asc")
x2 <- getRasterTable(x1)
data <- x2$band1[!is.na(x2$band1)]
mean(data)

Best regards,

Am?lie

Alexander Brenning a ?crit :
> Hi Amelie,
>
> 1) Problem with spaces in file/folder names: Same problem as before, 
> use '"my file"' style double quotes for file names with spaces. I will 
> fix this in the next version for the wrapper functions, but not for 
> the low-level rsaga.geoprocessor (which doesn't know if an argument is 
> a filename or some other character string).
>
> So for example...
>
> my.grid.matrix = read.sgrd('"my file"', return.header = FALSE)
>
> ...will return the grid matrix (without the header).
> Again, in your case using the setwd() function to go to the working 
> directory from the beginning also helps and makes the code more readable.
>
> 2) read.Rd.grid
>
>> read.Rd.grid("C:/Documents and 
>> Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sdat") Erreur : mauvais
>
> A .sdat file is not a .Rd file, so I would be surprised if it worked.
>
> I hope this helps...
>  Alex
>
>
>
> Amelie LESCROEL wrote:
>> Dear Alex, Thanks a lot for your quick and efficient answer. I did
>> not think about "double double-quoting" the path '""', as "simple" 
>> double-quoting "" usually works in R for paths containing spaces.
>> Now, it works perfectly well and I was able to process my grids from
>> within R in the same way as I processed them in SAGA: > 
>> rsaga.geoprocessor("io_grid", 4, list(GRID="199710.sgrd", 
>> FILE_DATA='"C:/Documents and Settings/lescroel/Mes 
>> documents/pub/DATASETS/seaice/polar-stereo/nasateam/final-gsfc/south/monthly/nt_199710_f13_v01_s.bin"', 
>>
>>  NX=316, NY=332, DXY=25, XMIN=-3950, YMIN=-3950, DATA_OFFSET=300, 
>> TOPDOWN=1)) > rsaga.geoprocessor("grid_calculus", 1, 
>> list(INPUT="199710.sgrd", RESULT="SIC_DATA_OCT_97.sgrd", 
>> FORMUL="a*0.4")) > rsaga.geoprocessor("grid_tools", 15, 
>> list(INPUT="SIC_DATA_OCT_97.sgrd", RESULT="SIC_OCT97_wo_Land.sgrd", 
>> METHOD=1, MIN=101, MAX=101.6, RNEW=-99999, ROPERATOR=0)) > 
>> rsaga.geoprocessor("grid_calculus", 1, 
>> list(INPUT="SIC_OCT98_wo_Land.sgrd;Crozier_lat.sgrd;Crozier_lon.sgrd",
>>  RESULT="FORAGING_AREA_OCT97.sgrd", FORMUL="a*b*c")) I'm encountering
>> a new problem though: now, I would like to work with the last
>> obtained grid "FORAGING_AREA_OCT97.sgrd" in R for performing basic
>> statistics (like obtaining the mean value of all cells). I was not
>> able to find a way to transform or read the .sgrd file into a R
>> object (matrix or data frame) that I could easily manipulate. I tried
>> the following: > oct97 <- read.sgrd("C:/Documents and 
>> Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sgrd") Erreur dans 
>> read.sgrd("C:/Documents and 
>> Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sgrd") : error
>> converting the SAGA sgrd file to a temporary ASCII grid file > oct97
>> <- read.Rd.grid("C:/Documents and 
>> Settings/lescroel/Bureau/FORAGING_AREA_OCT97.sdat") Erreur : mauvais
>>  num?ro magique de restauration de fichier (le fichier est peut ?tre
>>  corrompu) -- aucune donn?e charg?e ## Translation of the error
>> message "Error: wrong file restoring magic number (the file may be
>> corrupted) - no data loaded" De plus : Warning message: file 
>> 'FORAGING_AREA_OCT97.sdat' has magic number '?O???' Use of save
>> versions prior to 2 is deprecated Could you or someone else help me
>> again? Many thanks, Am?lie PS: I'm posting this message to the
>> R-sig-geo list this time! Message: 140 Date: Tue, 12 Aug 2008
>> 03:02:03 -0400 From: Alexander Brenning
>> <brenning at fesmail.uwaterloo.ca> Subject: Re: [R] Unexpected parameter
>> problem using rsaga.geoprocessor() {RSAGA} To: Am?lie Lescro?l 
>> <lescroel_cebc at no-log.org> Cc: r-help at R-project.org Message-ID: 
>> <48A1356B.10404 at fes.uwaterloo.ca> Content-Type: text/plain; 
>> charset=windows-1252; format=flowed Dear Amelie, > Le service Beep
>> n'est pas lanc?. this can be fixed by passing an additional argument
>> beep.off = FALSE to the rsaga.geoprocessor function; the most recent
>> RSAGA release on CRAN does not cause this problem any more, I
>> recommend you to update the package in your installation. The
>> beep.off thing was an attempt to stop SAGA from beeping each time a
>> module has been executed.
>>> Unexpected parameter 'and' If a file path or file name contains
>> spaces as in "Documents and Settings", you would have to double quote
>>  it, e.g., '"My Folder"' rather than "My Folder" This will make sure
>> that SAGA knows that the space does not separate different arguments.
>> After all, RSAGA uses the SAGA command line interface. However, it is
>> always a good idea to use the setwd() function to change the working
>> directory. This will keep the path short. I hope this helps. Alex
>> P.S.: You might wish to consider the R-sig-geo list for questions
>> regarding spatial/GIS support in R. Am?lie Lescro?l wrote:
>>
>>>> Hello, I discovered SAGA, an interesting free GIS, a few days ago
>>>> and now,
>>> I > would like to use it from within R 2.6.2 using the RSAGA
>>> package. I read > the documentation for this package and thought
>>> that I understood it > correctly for trying to call some of the
>>> SAGA modules. For getting the > information on the usage of and
>>> arguments required by the SAGA command > line "Import Binary Raw
>>> Data" module, I used:
>>>>>> rsaga.get.usage("io_grid", 4)
>>>> SAGA CMD 2.0.3 library path: C:/Progra~1/saga_vc/modules library
>>>> name: io_grid module name : Import Binary Raw Data Usage: 4
>>>> [-GRID <str>] [-FILE_DATA <str>] [-NX <num>] [-NY <num>]
>>> [-DXY > <str>] [-XMIN <str>] [-YMIN <str>] [-UNIT <str>] [-ZFACTOR
>>>  <str>] > [-NODATA <str>] [-DATA_OFFSET <num>] [-LINE_OFFSET <num>]
>>>  [-LINE_ENDSET > <num>] [-DATA_TYPE <num>] [-BYTEORDER_BIG <num>] 
>>> [-TOPDOWN <num>]
>>>> -GRID:<str> Grid Data Object (optional output) -FILE_DATA:<str>
>>>> Raw Data File File path -NX:<num> Cell Count (X) Integer -NY:<num> 
>>>> Cell Count (Y) Integer -DXY:<str> Cell Size Floating
>>>> point -XMIN:<str> Left Border (X) Floating point -YMIN:<str>
>>>> Lower Border (Y) Floating point -UNIT:<str> Unit Name Text 
>>>> -ZFACTOR:<str> Z Multiplier Floating point -NODATA:<str> No Data
>>>> Value Floating point -DATA_OFFSET:<num> Data Offset (Bytes) Integer 
>>>> -LINE_OFFSET:<num> Line Offset (Bytes) Integer -LINE_ENDSET:<num> 
>>>> Line Endset (Bytes) Integer -DATA_TYPE:<num>
>>>> Data Type Choice Available Choices: [0] 1 Byte Integer (unsigned)
>>>>  [1] 1 Byte Integer (signed) [2] 2 Byte Integer (unsigned) [3] 2
>>>> Byte Integer (signed) [4] 4 Byte Integer (unsigned) [5] 4 Byte
>>>> Integer (signed) [6] 4 Byte Floating Point [7] 8 Byte Floating
>>>> Point -BYTEORDER_BIG:<num> Byte Order Choice Available Choices: [0] 
>>>> Little Endian (Intel) [1] Big Endian (Motorola) -TOPDOWN:<num> Line 
>>>> Order Choice Available Choices: [0] Bottom to
>>>> Top [1] Top to Bottom
>>>>> Then, I wrote the following command for importing a grid of
>>>>> binary
>>> raw > data while specifying the parameters I usually enter under
>>> SAGA:
>>>>>> rsaga.geoprocessor("io_grid", 4, list(GRID="199710.sgrd", >
>>> FILE_DATA="C:/Documents and Settings/lescroel/Mes > 
>>> documents/pub/DATASETS/seaice/polar-stereo/nasateam/final-gsfc/south/monthly/nt_199710_f13_v01_s.bin", 
>>>
>>>
>>>> NX=316, NY=332, DXY=25, XMIN=-3950, DATA_OFFSET=300, TOPDOWN=1))
>>>>> and I got: Le service Beep n'est pas lanc?. Vous obtiendrez une
>>>>> aide suppl?mentaire en entrant NET HELPMSG 3521.
>>>>>> C:\Documents and >
>>> Settings\lescroel\Bureau>C:\Progra~1\saga_vc\saga_cmd.exe io_grid 4
>>> > -silent -GRID 199710.sgrd -FILE_DATA C:\Documents and > 
>>> Settings\lescroel\Mes > 
>>> documents\pub\DATASETS\seaice\polar-stereo\nasateam\final-gsfc\south\monthly\nt_199710_f13_v01_s.bin 
>>>
>>>
>>>> -NX 316 -NY 332 -DXY 25 -XMIN -3950 -DATA_OFFSET 300 -TOPDOWN 1
>>>>> SAGA CMD 2.0.3
>>>> library path: C:/Progra~1/saga_vc/modules library name: io_grid 
>>>> module name : Import Binary Raw Data author : (c) 2003 by
>>>> O.Conrad
>>>>> error: executing module [Import Binary Raw Data]
>>>> Usage: -silent [-GRID <str>] [-FILE_DATA <str>] [-NX <num>] [-NY
>>>>
>>> <num>] > [-DXY <str>] [-XMIN <str>] [-YMIN <str>] [-UNIT <str>] 
>>> [-ZFACTOR <str>] > [-NODATA <str>] [-DATA_OFFSET <num>]
>>> [-LINE_OFFSET <num>] [-LINE_ENDSET > <num>] [-DATA_TYPE <num>]
>>> [-BYTEORDER_BIG <num>] [-TOPDOWN <num>]
>>>> -GRID:<str> Grid Data Object (optional output) -FILE_DATA:<str>
>>>> Raw Data File File path -NX:<num> Cell Count (X) Integer -NY:<num> 
>>>> Cell Count (Y) Integer -DXY:<str> Cell Size Floating
>>>> point -XMIN:<str> Left Border (X) Floating point -YMIN:<str>
>>>> Lower Border (Y) Floating point -UNIT:<str> Unit Name Text 
>>>> -ZFACTOR:<str> Z Multiplier Floating point -NODATA:<str> No Data
>>>> Value Floating point -DATA_OFFSET:<num> Data Offset (Bytes) Integer 
>>>> -LINE_OFFSET:<num> Line Offset (Bytes) Integer -LINE_ENDSET:<num> 
>>>> Line Endset (Bytes) Integer -DATA_TYPE:<num>
>>>> Data Type Choice Available Choices: [0] 1 Byte Integer (unsigned)
>>>>  [1] 1 Byte Integer (signed) [2] 2 Byte Integer (unsigned) [3] 2
>>>> Byte Integer (signed) [4] 4 Byte Integer (unsigned) [5] 4 Byte
>>>> Integer (signed) [6] 4 Byte Floating Point [7] 8 Byte Floating
>>>> Point -BYTEORDER_BIG:<num> Byte Order Choice Available Choices: [0] 
>>>> Little Endian (Intel) [1] Big Endian (Motorola) -TOPDOWN:<num> Line 
>>>> Order Choice Available Choices: [0] Bottom to
>>>> Top [1] Top to Bottom Unexpected parameter 'and'
>>>>> Could someone already using the RSAGA package provide some help
>>>>> in
>>>> telling me what I did wrong? Thanks for your help,
>>>>> Am?lie
>>>
>>
>> -- Alexander Brenning
>> Department of Geography and Environmental Management University
>> of Waterloo 200 University Ave. W - Waterloo, ON - Canada N2L 3G1 
>> http://www.fes.uwaterloo.ca/geography/faculty/brenning/
>>
>



__________ Information from ESET Mail Security, version of virus signature database 3349 (20080812) __________

The message was checked by ESET Mail Security.
http://www.eset.com


    part000.txt - is OK



From mao.loecher at gmail.com  Tue Aug 12 16:22:07 2008
From: mao.loecher at gmail.com (Markus Loecher)
Date: Tue, 12 Aug 2008 10:22:07 -0400
Subject: [R-sig-Geo] US census shape files
Message-ID: <3827b1320808120722h1ac1347fn798b8b1ecd291bf4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080812/5500b32a/attachment.pl>

From munroe.9 at osu.edu  Tue Aug 12 16:38:26 2008
From: munroe.9 at osu.edu (Darla Munroe)
Date: Tue, 12 Aug 2008 10:38:26 -0400
Subject: [R-sig-Geo] US census shape files
In-Reply-To: <3827b1320808120722h1ac1347fn798b8b1ecd291bf4@mail.gmail.com>
References: <3827b1320808120722h1ac1347fn798b8b1ecd291bf4@mail.gmail.com>
Message-ID: <001101c8fc89$14c98790$3e5c96b0$@9@osu.edu>

http://www.census.gov/geo/www/cob/bdy_files.html

DM

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Markus Loecher
Sent: Tuesday, August 12, 2008 10:22 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] US census shape files

Hello,
(I apologize if this is a rather trivial question)
I have been searching the US census Web site for shapefiles that describe
the boundaries of the census blocks polygons used but have been unsuccessful
so far.

Might anyone be able to point me in the right direction ?

Thanks !

Markus

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From andrew.niccolai at yale.edu  Tue Aug 12 16:50:48 2008
From: andrew.niccolai at yale.edu (Andrew Niccolai)
Date: Tue, 12 Aug 2008 10:50:48 -0400
Subject: [R-sig-Geo] US census shape files
In-Reply-To: <3827b1320808120722h1ac1347fn798b8b1ecd291bf4@mail.gmail.com>
References: <3827b1320808120722h1ac1347fn798b8b1ecd291bf4@mail.gmail.com>
Message-ID: <000601c8fc8a$ed6c8e20$c845aa60$@niccolai@yale.edu>

I haven't looked at this site in years but as I recall the US Census blocks
can be found as TIGER files at the following website:
http://www.census.gov/geo/www/tiger/

I have not brought these files into R, but I have converted them in ArcGIS
therefore I'm sure they can be formatted for use in R.

Good luck

Andrew Niccolai
Doctoral Candidate
Yale School of Forestry


 
-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Markus Loecher
Sent: Tuesday, August 12, 2008 10:22 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] US census shape files

Hello,
(I apologize if this is a rather trivial question)
I have been searching the US census Web site for shapefiles that describe
the boundaries of the census blocks polygons used but have been unsuccessful
so far.

Might anyone be able to point me in the right direction ?

Thanks !

Markus

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From ddepew at sciborg.uwaterloo.ca  Tue Aug 12 17:16:29 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Tue, 12 Aug 2008 11:16:29 -0400
Subject: [R-sig-Geo] gstat error
Message-ID: <48A1A94D.9090303@scimail.uwaterloo.ca>

Hi
I'm trying to run some universal kriging, and have not experienced this 
error before.
I've removed duplicate data locations using the remove.duplicates 
command. The data set runs fine if the formula is set as ordinary 
kriging, but adding in a predictor (which is already known at each grid 
location)
gives

"lufactor.c", line 207: singular matrix in function m_inverse()
Error in predict.gstat

Any ideas?



From ddepew at sciborg.uwaterloo.ca  Tue Aug 12 17:27:10 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Tue, 12 Aug 2008 11:27:10 -0400
Subject: [R-sig-Geo] gstat error...resolved?
Message-ID: <48A1ABCE.1090906@scimail.uwaterloo.ca>

 > I think I know what the issue is....I have some NA cells in the 
prediction grid. trying to do UK with NA cells may be the problem. IS 
there a way to exclude these or remove them? I think they are present 
due to transect spacing and the short range of the original OK done for 
the covariate...


Hi
I'm trying to run some universal kriging, and have not experienced this 
error before.
I've removed duplicate data locations using the remove.duplicates 
command. The data set runs fine if the formula is set as ordinary 
kriging, but adding in a predictor (which is already known at each grid 
location)
gives

"lufactor.c", line 207: singular matrix in function m_inverse()
Error in predict.gstat

Any ideas?



From p.hiemstra at geo.uu.nl  Tue Aug 12 17:56:35 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 12 Aug 2008 17:56:35 +0200
Subject: [R-sig-Geo] panel figure with multiple spplot objects
In-Reply-To: <200808121357.m7CDvfRL002131@hypatia.math.ethz.ch>
References: <200808121357.m7CDvfRL002131@hypatia.math.ethz.ch>
Message-ID: <48A1B2B3.8080203@geo.uu.nl>

Hi Eelke,

You can exploit the fact that you can save spplot plots to R-objects 
like this:

library(gstat)
data(meuse)
coordinates(meuse) =~ x+y
data(meuse.grid)
gridded(meuse.grid) =~ x+y
p1 = spplot(meuse, "copper")
p2 = spplot(meuse, "zinc")
p3 = spplot(meuse.grid, "dist")
# Make a composite plot:
# see ?print.trellis for more details
print(p1, position = c(0,.5,.5,1),more=T)
print(p2, position = c(.5,.5,1,1),more = T)
print(p3, position = c(0,0,1,.5))

This method allows you to combine all lattice plots (e.g. xyplot, 
dotplot, etc) including spplot in one composite image.

cheers,
Paul


Eelke Folmer wrote:
> I am trying to make a panel-figure with multiple sp-plots. Doing par(mfrow=)
> does not work here because spplot is a wrapper for lattice (right?). I tried
> getting around this by exporting the resulting plots to jpg or tif and then
> importing it with rgdal. Due to the large size of jpg-s this is not a good
> way, even though the principle does work (for one layer of RGB). I would
> believe that this is a common operation that shouldn't be so hard if one
> only knew how. Any recommendations?
>
>
> Thanks in advance, Eelke
>
>
>  
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From p.hiemstra at geo.uu.nl  Tue Aug 12 18:12:26 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 12 Aug 2008 18:12:26 +0200
Subject: [R-sig-Geo] Plotting polygons on top of a levelplot
In-Reply-To: <48A0AD75.1070102@uni-muenster.de>
References: <45867.10.8.104.111.1218483628.squirrel@secure.ntsg.umt.edu>	<48A098F2.8070103@uni-muenster.de>	<49475.10.8.104.111.1218485705.squirrel@secure.ntsg.umt.edu>
	<48A0AD75.1070102@uni-muenster.de>
Message-ID: <48A1B66A.7040507@geo.uu.nl>

Edzer Pebesma wrote:
> No, it's me, I only read half of your question. Try something like
>
> spplot(spdf["dist"], sp.layout=list("sp.polygons", river))
>
> or the incremental build, in lattice style, of
>
> spplot(spdf["dist"])
> library(lattice)
> spplot(spdf["dist"])
> trellis.focus("panel", 1, 1)
> sp.polygons(river)
> trellis.unfocus()
>
> which will put the river on the foreground. This can be obtained in a 
> single pass with
>
> spplot(spdf["dist"], sp.layout=list("sp.polygons", river, first=FALSE))
Edzer,

The first = argument is not documented when I type ?sp.polygons or 
?panel.gridplot. You can only see it if you look at the source code of 
panel.gridplot. A very flexible way of adding layout objects is to 
define the panel function directly like (as shown on the R Wiki 
(http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:spatial_data_visualization)):

spplot(grid_object, "layer_to_plot",
    panel = function(...) {
        panel.gridplot(...)
        sp.polygons(polygon_object)
        sp.points(point_object)
    }

That was my solution to draw the polygons on top of the grid. I started 
a Spatial Data Visualization topic a the R Wiki (see the link above), 
maybe if people keep expanding that with useful topics and examples that 
would provide a place that makes plotting spatial objects a more 
accessible topic.

cheers,
Paul
>
> I slowly get the feeling that spplot needs a bit more documentation, 
> or examples.
> -- 
> Edzer
>
> Ryan Anderson wrote:
>> That likely gives me the control over the color ramp that I am looking
>> for, but I still have trouble plotting the vector layer over the top of
>> the resulting image plot.
>> If I do:
>>  spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)
>>  plot(river, add = TRUE)
>> I still get the plot.new has not been called yet error after I 
>> attempt to
>> add the river data.  What am I doing wrong?
>>
>> Thanks,
>> Ryan
>>
>>
>>  
>>> Ryan, you're probably looking for something like
>>>
>>> spplot(spdf["dist"],col.regions=heat.colors(400), at = 0:10/10)
>>>
>>> spplot is a wrapper around lattice functions for spatial data, and 
>>> tries
>>> to pass on all the lattice controls.
>>> -- 
>>> Edzer
>>>
>>> Ryan Anderson wrote:
>>>    
>>>> I have some gridded spatial data that I want to plot with a vector
>>>> overlay
>>>> on top.  The following reproducible code makes a figure similar to the
>>>> one
>>>> I am ultimately trying to produce:
>>>>
>>>> library(sp)
>>>> library(fields)
>>>> data(meuse.grid)
>>>> data(meuse.riv)
>>>> coords <- SpatialPixels(SpatialPoints(meuse.grid[, c("x","y")]))
>>>> spdf <- SpatialPixelsDataFrame(coords, meuse.grid)
>>>> fullgrid(spdf)<-TRUE
>>>> river<-SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv"))) 
>>>>
>>>> par(mar = c(5,5,5,8), col.axis = 1)
>>>> ramp = heat.colors(400)
>>>> image(spdf, "dist", axes = TRUE, col = ramp)
>>>> plot(river, add = TRUE)
>>>> zvals<-spdf$dist
>>>> zvals<-zvals[!is.na(zvals)]
>>>> image.plot(zlim = c(min(zvals), max(zvals)), nlevel = 256, 
>>>> legend.only =
>>>> TRUE, col = ramp)
>>>>
>>>> I need more control over the legend and the color ramp than I know how
>>>> to
>>>> achieve with this code.  I can create the plot I want with 
>>>> levelplot by
>>>> setting the 'at' component 'colorkey', but when I try to overlay the
>>>> vector file I get an error.  Here is a simplified version of the 
>>>> code I
>>>> tried:
>>>>
>>>> #try a levelplot
>>>> library(lattice)
>>>> x11()
>>>> par(mar = c(5,5,5,8))
>>>> x<-spdf$x
>>>> y<-spdf$y
>>>> z<-spdf$dist
>>>> levelplot(z~x+y)
>>>> plot(river, add = TRUE)
>>>> #Gives Error in polygon(x = x, y = y, border = border, col = col, 
>>>> lty =
>>>> #lty,  :
>>>> #  plot.new has not been called yet
>>>>
>>>> I need to either find a way to control the mapping of data values 
>>>> to the
>>>> color ramp more precisely in my call to image or image.plot or to 
>>>> find a
>>>> way to plot a ploygon over the top of a levelplot.
>>>>
>>>> My color ramp goals more specifically: my grid contains both positive
>>>> and
>>>> negative values, and they are not necessarily symmetrically 
>>>> distributed
>>>> around zero.  I want to plot them so that zero is white, negative 
>>>> values
>>>> are symbolized with a ramp from white to blue (with darker shades for
>>>> lower values) and positive values are symbolized with a ramp from 
>>>> white
>>>> to
>>>> red (with darker shades for higher values).
>>>>
>>>> Thanks for your help!
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>       
>>> -- 
>>> Edzer Pebesma
>>> Institute for Geoinformatics (ifgi), University of M?nster,
>>> Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
>>> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
>>>
>>>
>>>     
>>
>>   
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From edzer.pebesma at uni-muenster.de  Tue Aug 12 20:17:22 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 Aug 2008 20:17:22 +0200
Subject: [R-sig-Geo] gstat error
In-Reply-To: <48A1A94D.9090303@scimail.uwaterloo.ca>
References: <48A1A94D.9090303@scimail.uwaterloo.ca>
Message-ID: <48A1D3B2.5080605@uni-muenster.de>

Is it possible that you're using kriging in a local neighbourhood where 
the predictor is constant?
--
Edzer

Dave Depew wrote:
> Hi
> I'm trying to run some universal kriging, and have not experienced 
> this error before.
> I've removed duplicate data locations using the remove.duplicates 
> command. The data set runs fine if the formula is set as ordinary 
> kriging, but adding in a predictor (which is already known at each 
> grid location)
> gives
>
> "lufactor.c", line 207: singular matrix in function m_inverse()
> Error in predict.gstat
>
> Any ideas?
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From ddepew at sciborg.uwaterloo.ca  Tue Aug 12 20:58:56 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Tue, 12 Aug 2008 14:58:56 -0400
Subject: [R-sig-Geo] gstat error
In-Reply-To: <48A1D3B2.5080605@uni-muenster.de>
References: <48A1A94D.9090303@scimail.uwaterloo.ca>
	<48A1D3B2.5080605@uni-muenster.de>
Message-ID: <48A1DD70.1090607@scimail.uwaterloo.ca>

I suppose it might be, although I expanded the neighborhood just to be 
sure. I wonder if it isn;t the NA values that are in the grid

Edzer Pebesma wrote:
> Is it possible that you're using kriging in a local neighbourhood 
> where the predictor is constant?
> -- 
> Edzer
>
> Dave Depew wrote:
>> Hi
>> I'm trying to run some universal kriging, and have not experienced 
>> this error before.
>> I've removed duplicate data locations using the remove.duplicates 
>> command. The data set runs fine if the formula is set as ordinary 
>> kriging, but adding in a predictor (which is already known at each 
>> grid location)
>> gives
>>
>> "lufactor.c", line 207: singular matrix in function m_inverse()
>> Error in predict.gstat
>>
>> Any ideas?
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Tue Aug 12 21:06:16 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 Aug 2008 21:06:16 +0200
Subject: [R-sig-Geo] gstat error
In-Reply-To: <48A1DD70.1090607@scimail.uwaterloo.ca>
References: <48A1A94D.9090303@scimail.uwaterloo.ca>
	<48A1D3B2.5080605@uni-muenster.de>
	<48A1DD70.1090607@scimail.uwaterloo.ca>
Message-ID: <48A1DF28.1040208@uni-muenster.de>



Dave Depew wrote:
> I suppose it might be, although I expanded the neighborhood just to be 
> sure. I wonder if it isn;t the NA values that are in the grid
I'd expect a different error message, or that the location gets ignored.

To select non-missing valued pixels, you can select cells if the grid is 
a SpatialPixelsDataFrame, using e.g.

 > data(meuse.grid)
 > coordinates(meuse.grid) = ~x+y
 > gridded(meuse.grid)=TRUE
 > class(meuse.grid)
[1] "SpatialPixelsDataFrame"
attr(,"package")
[1] "sp"
 > summary(meuse.grid[meuse.grid$dist < 0.5, ])

where you replace the row selection with the is.na() on the appropriate 
column.
--
Edzer

>
> Edzer Pebesma wrote:
>> Is it possible that you're using kriging in a local neighbourhood 
>> where the predictor is constant?
>> -- 
>> Edzer
>>
>> Dave Depew wrote:
>>> Hi
>>> I'm trying to run some universal kriging, and have not experienced 
>>> this error before.
>>> I've removed duplicate data locations using the remove.duplicates 
>>> command. The data set runs fine if the formula is set as ordinary 
>>> kriging, but adding in a predictor (which is already known at each 
>>> grid location)
>>> gives
>>>
>>> "lufactor.c", line 207: singular matrix in function m_inverse()
>>> Error in predict.gstat
>>>
>>> Any ideas?
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From edzer.pebesma at uni-muenster.de  Tue Aug 12 22:23:46 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 Aug 2008 22:23:46 +0200
Subject: [R-sig-Geo] specifying different colors for vector map as
	background
In-Reply-To: <Pine.LNX.4.64.0807312123040.28744@reclus.nhh.no>
References: <48920ACE.3040508@ipicyt.edu.mx>
	<Pine.LNX.4.64.0807312123040.28744@reclus.nhh.no>
Message-ID: <48A1F152.8080603@uni-muenster.de>

After getting the data from Jaime offline, I got this working, following 
Roger's suggestion.

Code is on cvs and will be in the next release.
--
Edzer

Roger Bivand wrote:
> On Thu, 31 Jul 2008, Jaime Carrera wrote:
>
>> Hi,
>> I'm trying to create a spplot with a vector map on the background. It 
>> works fine if I don't want the polygon map to be filled, but what I 
>> do want to is to have the polygons filled with different colors. The 
>> following command plots the polygon map fine, filling each polygon 
>> with its respective color:
>>
>> plot(avi,axes=FALSE,lty=0,col=rgb(avi$r/255,avi$g/255,avi$b/255))
>>
>> Now I try to do this on ssplot, but it doesn't work, as all polygons 
>> are filled with the first color found:
>>
>> basemap<-list("sp.polygons",avi,fill=rgb(avi$r/255,avi$g/255,avi$b/255),lty=1) 
>>
>> spplot(wells2001sp,c("May","Jun"),as.table=TRUE,sp.layout=list(basemap))
>>
>> Is there a way around it?
>
> Not for spplot in the current code. The fill= argument in 
> "sp.polygons" is passed through to the internal function sp.polygon3 
> without being indexed, so grid.polygon gets given the whole fill 
> vector each time, and takes the first value. We can try to add the 
> functionality at some time in the future - or others could help - type 
> sp.polygons at the prompt to see the code. fill= is being passed in 
> the ... arguments, and needs to be conditioned on, and fill=fill[i] 
> passed to sp.polygon3.
>
> The sp code is on the r-spatial sourceforge site - patches welcome!
>
> Roger
>
> PS: This is a first cut:
>
> sp.polygons = function(obj, col = 1, fill="transparent", ...) {
>     sp.polygon3 = function(x, col, fill, ...) {
>         cc = slot(x, "coords")
>         grid.polygon(cc[,1], cc[,2], default.units = "native",
>             gp = gpar(col = col, fill = fill, ...))
>         panel.lines(cc, col = col, ...)
>     }
>     if (is.character(obj))
>         obj = get(obj)
>     if (!is(obj, "SpatialPolygons"))
>         stop(paste("object extending class SpatialPolygons",
>             "expected; got class", class(obj)))
>     else
>         obj = as(obj, "SpatialPolygons")
>     pls = slot(obj, "polygons")
>        pO <- slot(obj, "plotOrder")
>     if (length(fill) != length(pO)) fill <- rep(fill[1], length(pO))
>        for (i in pO) {
>            Srs <- slot(pls[[i]], "Polygons")
>            pOi <- slot(pls[[i]], "plotOrder")
>            for (j in pOi)
>             sp.polygon3(Srs[[j]], col = col, fill = fill[i], ...)
>     }
> }
>
>
>
>
>>
>> Thanks,
>>
>> Jaime
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From Alexander.Herr at csiro.au  Wed Aug 13 01:08:26 2008
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Wed, 13 Aug 2008 09:08:26 +1000
Subject: [R-sig-Geo] accumulate gridcells to a specific value - summary
References: <mailman.9.1217412002.21993.r-sig-geo@stat.math.ethz.ch>
	<9ED523708FAD8448BDE5EC41B83E7024177797@exactn2-cbr.nexus.csiro.au>
	<d8ad40b50807310208v6e5fb3f9x3e42bd1f95813969@mail.gmail.com>
	<9ED523708FAD8448BDE5EC41B83E7024177799@exactn2-cbr.nexus.csiro.au>
	<5383fa5e0808011012y3066d2c0ld2a496e146ecc4ea@mail.gmail.com>
Message-ID: <9ED523708FAD8448BDE5EC41B83E70243DE5BF@exactn2-cbr.nexus.csiro.au>

Hi list,

Attached code from Barry Rowling to estimate variable radii based on a given allocation value (ie matrix cell sums). The code will calculate the radii of circles that sum to a given value. It starts from the hightest value in a matrix, than second highest etc. and excludes values already allocated to a circle. The output is a matrix of circles/semi-circles and dataframe of result. See circle_allocate.r for a trial.

Cheers
Herry



-----Original Message-----
From: Matthew Perry [mailto:perrygeo at gmail.com] 
Sent: Saturday, August 02, 2008 3:12 AM
To: Herr, Alexander Herr - Herry (CSE, Gungahlin)
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] accumulate gridcells to a specific value

This might be what you're looking for ...

http://grass.itc.it/grass62/manuals/html62_user/r.cost.html

On Thu, Jul 31, 2008 at 4:51 PM,  <Alexander.Herr at csiro.au> wrote:
> Hi Barry,
>
>> Can you explain a bit more about your problem?
>> * What are the inputs? Just a grid of values or are there some
> starting points?
>
> Inputs is a floating grid. Starting point is 1) the highest values in 
> the grid. Once first accumulation achieved, exclude this area and 2) 
> find highest value on grid for next starting points and so on.
>
>> * What are the outputs? A list of grid cells that add up to your
> accumulated value?
>
> outputs: accumulation areas where sum of grid points (within areas) is 
> a given value.
>
>
> Does that clarify?
> Cheers
> Herry
>
> -----Original Message-----
> From: b.rowlingson at googlemail.com [mailto:b.rowlingson at googlemail.com]
> On Behalf Of Barry Rowlingson
> Sent: Thursday, July 31, 2008 7:09 PM
> To: Herr, Alexander Herr - Herry (CSE, Gungahlin)
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] accumulate gridcells to a specific value
>
> 2008/7/31  <Alexander.Herr at csiro.au>:
>
>> I am trying to accumulate gridcells to a specific value. This means I 
>> need to extent the nearest neighbours (or search radius) to a size so 
>> that the sum of gridcell values reaches the desired value (or stops 
>> if
>
>> sum value of gridcells/radius goes beyond a specific size). It should 
>> start with the highest gridcell value then next remaining highest etc.
>>
>> Of course this could also work with points/polygons or on a matrix.
>>
>> Rather than re-inventing the wheel I was wondering if anyone has or 
>> knows of a tool/script.
>
>  It's not totally clear what you want to do, but it sounds like the 
> sort of raster operation that GRASS GIS does.
>
>  http://grass.itc.it/
>
>  Can you explain a bit more about your problem?
>
>  * What are the inputs? Just a grid of values or are there some 
> starting points?
>  * What are the outputs? A list of grid cells that add up to your 
> accumulated value?
>
>  I ask this because this week I wrote some code that did something 
> very similar, namely:
>
>  Given a grid of resource values and a number of population centres, 
> compute the areas on the grid that allocate a given resource total to 
> each population centre by minimising the distance from each centre, 
> and not allowing any grid square to be allocated to more than one centre.
>
>  It basically grows areas out from the centres, by finding the minimum 
> centre-resource cell distance for unallocated cells and allocating 
> that cell to that centre.
>
>  This was written in Python and used gdal to read grids. Took me a day 
> to write and a day to document.
>
>  I'll have to start charging for this :)
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



--
???`?.?. , . .???`?.. ><((((?>`?.??.???`?.?.???`?...?><((((?>
"The best way to predict the future is to invent it." -- Alan Kay Matthew T. Perry http://www.perrygeo.net


-------------- next part --------------
A non-text attachment was scrubbed...
Name: variable_radius.zip
Type: application/x-zip-compressed
Size: 2065 bytes
Desc: variable_radius.zip
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080813/a97fda83/attachment.bin>

From murray.richardson at utoronto.ca  Wed Aug 13 15:44:54 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Wed, 13 Aug 2008 09:44:54 -0400
Subject: [R-sig-Geo] merge sliver polygons
Message-ID: <48A2E556.3040305@utoronto.ca>

Hello again r.sig.geo list,

Thanks Roger, for help on my previous question regarding iterating 
through a shapefile.

I'm sure once I receive my copy of  "Applied Spatial Data Analysis with 
R" I will find answers to simple questions like this on my own, but in 
the meantime....

Is it possible to merge sliver polygons that fall below a certain 
threshold area with adjacent neighbours (e.g. perhaps using  
unionSpatialPolygons but without aggregating any  polygons?).  If a 
sliver shares edges with more than one polygon, it doesn't really matter 
which one it merges with, but if I had to choose a rule I would have it 
merge with the largest one.

Thanks in advance,

Murray Richardson



From Roger.Bivand at nhh.no  Wed Aug 13 16:26:23 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 13 Aug 2008 16:26:23 +0200 (CEST)
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <48A2E556.3040305@utoronto.ca>
References: <48A2E556.3040305@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>

On Wed, 13 Aug 2008, Murray Richardson wrote:

> Hello again r.sig.geo list,
>
> Thanks Roger, for help on my previous question regarding iterating through a 
> shapefile.
>
> I'm sure once I receive my copy of  "Applied Spatial Data Analysis with R" I 
> will find answers to simple questions like this on my own, but in the 
> meantime....
>
> Is it possible to merge sliver polygons that fall below a certain threshold 
> area with adjacent neighbours (e.g. perhaps using  unionSpatialPolygons but 
> without aggregating any  polygons?).  If a sliver shares edges with more than 
> one polygon, it doesn't really matter which one it merges with, but if I had 
> to choose a rule I would have it merge with the largest one.

Not such a simple question ...

Both the Polygon and Polygons objects in the SpatialPolygons object have 
"area" slots, with different roles. The Polygon objects have a correct 
naive area in the geometry of the coordinates taken as planar. The 
Polygons objects use the "gross" area of Polygon objects belonging to 
them, but "only" to provide the plot order (plot from largest to smallest 
to avoid over-painting).

If you "trust" the area slot of the Polygons objects (beware of hole 
Polygon objects), you can first find your candidate slivers by retrieving 
the areas by:

Polygons_areas <- sapply(slot(SPobj, "polygons"),
   function(x) slot(x, "area"))

and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to find 
the neighbours (rook criterion). Next use the output object to identify 
the largest neighbours of the sliver candidates, and build a "new 
Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm assuming you 
wouldn't have asked if there was useful data in the slivers!

Hope this helps,

Roger

>
> Thanks in advance,
>
> Murray Richardson
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ihcover-junk at yahoo.com  Wed Aug 13 17:14:52 2008
From: ihcover-junk at yahoo.com (Ian Harrison)
Date: Wed, 13 Aug 2008 15:14:52 +0000 (UTC)
Subject: [R-sig-Geo] converting SRTM data to filled contour plot
Message-ID: <loom.20080813T144152-413@post.gmane.org>

Hello,

I'm looking for advice on the best way to use NASA's SRTM data to produce a
filled contour plot. I've been tinkering with this over the past week or so, and
I think I'm almost there, but there are still a couple of roadblocks.

So far, I've been using a small, 7KB file of SRTM data that's in bil format.
Basically the commands that I run are:
x<-readGDAL('./44193054/44193054/44193054.bil')
contour(x, drawlabels=FALSE, col=1:5)

This produces a contour plot of the data, but there's still a couple of
problems: 1) The contours aren't filled. If I try filled.contour(), the function
complains about the format of x. I get the error "Non-numeric argument to
mathematical function". I haven't figured out how to extract the relevant data
from x and pass it to filled.contour(). 2) If I use a larger file, I quickly run
into memory problems. I haven't found the exact filesize where this occurs, but
I'd like to be able to use data files that are at least 80MB in size. Do I need
to break the files into smaller chunks, or is there another way?

So my questions are: 1) How can I create a filled contour plot of the data? 2)
How should I get around the memory problem? 

I'm an amateur with very little experience with the sp package or mapping in
general (but I do have experience with R), so I may be making some basic
mistakes. For example, I'm not sure I'm using the best data format, and I know
there are others available. I'm hoping that I'm trying to do something that's
very common and that there's an easy solution. Any help would be greatly
appreciated.

Thanks,
Ian



From miguez at illinois.edu  Wed Aug 13 22:51:59 2008
From: miguez at illinois.edu (Fernando Miguez)
Date: Wed, 13 Aug 2008 15:51:59 -0500
Subject: [R-sig-Geo] Map layer
Message-ID: <48A3496F.6040509@illinois.edu>

Hi all,

I would like to be able to do the following

map('state','illinois')
points(x,y)

Up to this point everything is fine. However, some of the points fall 
outside the Illinois map boundaries. What I would like to do is to add a 
layer where the inside of the Illinois polygon is transparent (so that 
the points can be seen) but the points outside the boundary are covered 
so they are not seen. I thought that using some variation of map with 
its arguments would work, but I haven't been able to figure it out. I 
see that it is quite possible that I'm using the wrong tools all 
together ... let me know.

Any help is appreciated. Thanks.

Fernando

-- 
Fernando E. Miguez
Energy Biosciences Institute
https://netfiles.uiuc.edu/miguez/www



From Philip.Lane at newcastle.edu.au  Thu Aug 14 06:14:43 2008
From: Philip.Lane at newcastle.edu.au (Philip Lane)
Date: Thu, 14 Aug 2008 14:14:43 +1000
Subject: [R-sig-Geo] error message using BRugs package - multivariate
 distribution	must have more than one component
Message-ID: <48A43DD2.C273.0098.0@newcastle.edu.au>


Hi there,

I am trying to compare two hierarchical models  - one with a spatial term (using a car.normal function) and one without the term. I am trying to do this using the BRugs package in R.

I can get the non-spatial model to run in R using the BRugs package, but when
I try to add the CAR term to model the possible spatial association, I get an error message
multivariate distribution must have more than one component. 

I can get both models to work in WinBugs itself, I just want to call them from R, without
going through the CODA package to bring in the parameters I am interested in.

I am hoping to get a lead when the asdar book comes out next month, but I thought I might be fortunate to get some help from the list as well. I have attached the two models, data files, and R commands to the end of this email. 

One more thing - the error message has changed with the release of R 2.7.1 - when running the R code for the model with the CAR term, the model will not compile, with the error message
"logical expression contains too many operators" - I can work around this by using an older version of R, but I'd rather not.

Any help would be appreciated, as well as any tips or suggestions as to other approaches I could consider.

Cheers,


Philip.





#R code for non spatial lga analysis works
# lgas nonspatial using bugs command
# setwd("C:/Rwork/brugsfit/lga_sp")
model.file <- ("lga_ns3.bug")
#file.show(model.file) 
lgans <- read.table("lgas_ns_data2.txt", header=TRUE)
N <- nrow(lgans)
dlga <- lgans$dlga
drugs <- lgans$drugs
maliciouspd <- lgans$maliciouspd
personalviolence <- lgans$personalviolence
assault <- lgans$assault
theft <- lgans$theft

data <- list("N", "dlga", "theft", "assault", "drugs", "personalviolence", "maliciouspd")
inits <- function(){ 
list(mulga = rnorm(N, 0, 100), taulga = rnorm(1, 0, 100), 
mulgaerr = rnorm(N, 0, 100)) } 
parameters <- c("mulga", "theft", "beta0", "maliciouspd", "drugs", "assault", "personalviolence")
lgans1.sim <- bugs(data, inits, parameters, model.file,	
	n.chains=3, n.iter=9000, 
	program="OpenBUGS",working.directory="C:/Rwork/brugsfit/lga/")


# where the file 'lga_ns3.bug' is the following
model
	{
		
                for (i in 1 : N) {
		dlga[i] ~ dnorm(mulga[i], taulga)
		mulga[i] <- beta0 + theft[i] + drugs[i] + assault[i] + personalviolence[i] + maliciouspd[i] + mulgaerror[i]
		mulgaerr[i] ~ dunif(0,10)		
		mulgaerror[i] <-  pow(mulgaerr[i], -2) 
		}
	beta0 ~  dnorm(0, 0.00001)
	taulga ~ dunif(0,10)
	sigma <- sqrt(1 /  taulga) 
}

# and the file 'lgas_ns_data2.txt' is the following
dlga	assault	personalviolence	theft	drugs	maliciouspd
-1.308690894	-1.902542937	3.108024792	-1.908211249	-1.236057587	-2.029887038
0.192953031	-0.904543369	-0.168098513	-0.882832347	-0.771429408	-1.272027964
-0.742608421	-0.865276115	-0.977619891	-0.836548675	-0.485808832	-0.700348878
-0.830741022	0.989810005	0.406419865	1.189752862	2.548549645	1.020948188
0.948859566	0.288408929	-0.161014806	0.653297195	-0.694454275	0.31069764
0.511586279	0.871016672	-0.033402987	1.562855456	0.078507236	0.420099579
-1.257845163	-1.098227294	-0.759990924	-0.86449525	-0.562803883	-0.754887637
-1.356146909	-0.011072993	-0.256779458	-0.66885098	-0.217201319	-0.396837197
0.226850185	1.660304858	0.146284286	0.389135584	1.405311729	1.374473092
1.433588869	0.268211733	-0.193027654	0.522926518	-0.396927871	-0.170071478
0.331931362	0.841021781	-0.423071952	0.86942456	-0.052876539	0.608529601
0.426843394	-0.415227213	-0.49603507	-0.344025594	0.397721409	0.497197973
1.423419723	0.278115943	-0.191687687	0.317571921	-0.012530303	1.092114118


# but R code for spatial analysis falls over
setwd("C:/Rwork/brugsfit/lga_sp")
model.file <- ("lgatry2.bug")
#file.show(model.file) 
lgasp <- read.table("lgasp_data2.txt", header=TRUE)
N <- nrow(lgasp)
dlga <- lgasp$dlga
drugs <- lgasp$drugs
maliciouspd <- lgasp$maliciouspd
personalviolence <- lgasp$personalviolence
assault <- lgasp$assault
theft <- lgasp$theft
num=c(4,6,3,3,2,5,3,2,3,4,4,6,5)
adj=c(5,6,10,13,
	3,4,6,11,12,13,
	4,12,2,
	3,11,2,
	1,10,
	1,2,10,11,13,
	8,9,12,
	7,12,
	7,12,13,
	1,5,6,11,
	2,4,6,10,
	2,3,7,8,9,13,
	1,2,6,9,12)


data <- list("N", "dlga", "num", "adj", "theft", "assault", "drugs", "personalviolence", "maliciouspd") 
inits <- function(){ 
list(mulga = rnorm(N, 0, 100), taulga = rnorm(1, 0, 100), b=runif(N,0,10),
mulgaerror = rnorm(N, 0, 100), taulgacar=rnorm(1,0,100)) } 
parameters <- c("mulga", "theft", "maliciouspd", "drugs", "b", "assault", "personalviolence")
lgasp1.sim <- bugs(data, inits, parameters, model.file,debug=TRUE,	
	n.chains=3, n.iter=5000, program="OpenBUGS",
working.directory="C:/Rwork/brugsfit/lga_sp/")



# this is the file 'lgatry2.bug'
model
	{
		
                for (i in 1 : N) {
		dlga[i] ~ dnorm(mulga[i], taulga)
		mulga[i] <- beta0 + theft[i] + b[i] + drugs[i] + assault[i] + 
		personalviolence[i] + maliciouspd[i] + mulgaerror[i]
		mulgaerr[i] ~ dunif(0,10)		
		mulgaerror[i] <-  pow(mulgaerr[i], -2) 
		b[i] ~ car.normal(adj[], weights[], num[], taulgacar)
		}

for(k in 1:50)   {
		weights[k] <- 1}

	beta0 ~  dnorm(0, 0.00001)
	taulga ~ dunif(0,10)
	sigma <- sqrt(1 /  taulga) 
	sigmalgacar ~ dunif(0,10)
	taulgacar<- 1/(sigmalgacar*sigmalgacar)
}


#the file for the data 'lgasp_data2.txt'is the same as for the nonspatial ie
dlga	assault	personalviolence	theft	drugs	maliciouspd
-1.308690894	-1.902542937	3.108024792	-1.908211249	-1.236057587	-2.029887038
0.192953031	-0.904543369	-0.168098513	-0.882832347	-0.771429408	-1.272027964
-0.742608421	-0.865276115	-0.977619891	-0.836548675	-0.485808832	-0.700348878
-0.830741022	0.989810005	0.406419865	1.189752862	2.548549645	1.020948188
0.948859566	0.288408929	-0.161014806	0.653297195	-0.694454275	0.31069764
0.511586279	0.871016672	-0.033402987	1.562855456	0.078507236	0.420099579
-1.257845163	-1.098227294	-0.759990924	-0.86449525	-0.562803883	-0.754887637
-1.356146909	-0.011072993	-0.256779458	-0.66885098	-0.217201319	-0.396837197
0.226850185	1.660304858	0.146284286	0.389135584	1.405311729	1.374473092
1.433588869	0.268211733	-0.193027654	0.522926518	-0.396927871	-0.170071478
0.331931362	0.841021781	-0.423071952	0.86942456	-0.052876539	0.608529601
0.426843394	-0.415227213	-0.49603507	-0.344025594	0.397721409	0.497197973
1.423419723	0.278115943	-0.191687687	0.317571921	-0.012530303	1.092114118



From p.hiemstra at geo.uu.nl  Thu Aug 14 09:55:58 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 14 Aug 2008 09:55:58 +0200
Subject: [R-sig-Geo] Map layer
In-Reply-To: <48A3496F.6040509@illinois.edu>
References: <48A3496F.6040509@illinois.edu>
Message-ID: <48A3E50E.2080201@geo.uu.nl>

Hi Fernando,

If you use the sp classes for spatial data you can use the spplot 
function to make very nice plots. See 
http://cran.r-project.org/doc/Rnews/Rnews_2005-2.pdf for more 
information on sp. See 
http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:import_export 
for information on how to import your data into sp-classes.

In regard to your problem with the points outside the map. If your data 
is stored in sp objects you can use the overlay() function from the 
sp-package to determine which points are outside the polygon, see 
?overlay for more details. Those points can be deleted from the 
sp-object and they will not appear in the plot.

hth,

Paul

Fernando Miguez wrote:
> Hi all,
>
> I would like to be able to do the following
>
> map('state','illinois')
> points(x,y)
>
> Up to this point everything is fine. However, some of the points fall 
> outside the Illinois map boundaries. What I would like to do is to add 
> a layer where the inside of the Illinois polygon is transparent (so 
> that the points can be seen) but the points outside the boundary are 
> covered so they are not seen. I thought that using some variation of 
> map with its arguments would work, but I haven't been able to figure 
> it out. I see that it is quite possible that I'm using the wrong tools 
> all together ... let me know.
>
> Any help is appreciated. Thanks.
>
> Fernando
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From Roger.Bivand at nhh.no  Thu Aug 14 11:28:11 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 14 Aug 2008 11:28:11 +0200 (CEST)
Subject: [R-sig-Geo] Map layer
In-Reply-To: <48A3E50E.2080201@geo.uu.nl>
References: <48A3496F.6040509@illinois.edu> <48A3E50E.2080201@geo.uu.nl>
Message-ID: <Pine.LNX.4.64.0808141120050.25886@reclus.nhh.no>

On Thu, 14 Aug 2008, Paul Hiemstra wrote:

> Hi Fernando,
>
> If you use the sp classes for spatial data you can use the spplot function to 
> make very nice plots. See 
> http://cran.r-project.org/doc/Rnews/Rnews_2005-2.pdf for more information on 
> sp. See 
> http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:import_export 
> for information on how to import your data into sp-classes.
>
> In regard to your problem with the points outside the map. If your data is 
> stored in sp objects you can use the overlay() function from the sp-package 
> to determine which points are outside the polygon, see ?overlay for more 
> details. Those points can be deleted from the sp-object and they will not 
> appear in the plot.

In fact, there was a bug in the interface function map2SpatialPolygons() 
in the maptools package - it failed for map objects with only one closed 
polygon. From 0.7-15 (submitted to CRAN, may take a little while because 
both Kurt Hornik (CRAN) and Uwe Ligges (Windows binary packages) are at 
the excellent useR! conference in Dortmund - I am too), this works:

library(maps)
library(sp)
library(maptools)
ill <- map('state','illinois', plot=FALSE, fill=TRUE)
ill_SP <- map2SpatialPolygons(ill, IDs=ill$names,
   proj4string=CRS("+proj=longlat"))
plot(ill_SP)
# next two lines to generate some random points on the bounding
# box of Illinois
SG <- Sobj_SpatialGrid(ill_SP)$SG
pts <- spsample(SG, n=500, type="random")
plot(pts, add=TRUE)
o <- overlay(pts, ill_SP)
plot(pts[!is.na(o),], col="red", add=TRUE)

Hope this helps,

Roger

PS. The useR conference has lots of excellent talks, and surprisingly many 
are spatial. Next year's conference will be in Rennes, France, and in 
2010, it will probably be in North America.

>
> hth,
>
> Paul
>
> Fernando Miguez wrote:
>>  Hi all,
>>
>>  I would like to be able to do the following
>>
>>  map('state','illinois')
>>  points(x,y)
>>
>>  Up to this point everything is fine. However, some of the points fall
>>  outside the Illinois map boundaries. What I would like to do is to add a
>>  layer where the inside of the Illinois polygon is transparent (so that the
>>  points can be seen) but the points outside the boundary are covered so
>>  they are not seen. I thought that using some variation of map with its
>>  arguments would work, but I haven't been able to figure it out. I see that
>>  it is quite possible that I'm using the wrong tools all together ... let
>>  me know.
>>
>>  Any help is appreciated. Thanks.
>>
>>  Fernando
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From miguez at illinois.edu  Thu Aug 14 14:02:17 2008
From: miguez at illinois.edu (Fernando Miguez)
Date: Thu, 14 Aug 2008 07:02:17 -0500
Subject: [R-sig-Geo] Map layer
In-Reply-To: <Pine.LNX.4.64.0808141120050.25886@reclus.nhh.no>
References: <48A3496F.6040509@illinois.edu> <48A3E50E.2080201@geo.uu.nl>
	<Pine.LNX.4.64.0808141120050.25886@reclus.nhh.no>
Message-ID: <48A41EC9.5070701@illinois.edu>

Hi Paul and Roger,

Thanks so much for your help. I will definitely like to attend the next 
useR! conference!

Fernando

Roger Bivand wrote:
> On Thu, 14 Aug 2008, Paul Hiemstra wrote:
> 
>> Hi Fernando,
>>
>> If you use the sp classes for spatial data you can use the spplot 
>> function to make very nice plots. See 
>> http://cran.r-project.org/doc/Rnews/Rnews_2005-2.pdf for more 
>> information on sp. See 
>> http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:import_export 
>> for information on how to import your data into sp-classes.
>>
>> In regard to your problem with the points outside the map. If your 
>> data is stored in sp objects you can use the overlay() function from 
>> the sp-package to determine which points are outside the polygon, see 
>> ?overlay for more details. Those points can be deleted from the 
>> sp-object and they will not appear in the plot.
> 
> In fact, there was a bug in the interface function map2SpatialPolygons() 
> in the maptools package - it failed for map objects with only one closed 
> polygon. From 0.7-15 (submitted to CRAN, may take a little while because 
> both Kurt Hornik (CRAN) and Uwe Ligges (Windows binary packages) are at 
> the excellent useR! conference in Dortmund - I am too), this works:
> 
> library(maps)
> library(sp)
> library(maptools)
> ill <- map('state','illinois', plot=FALSE, fill=TRUE)
> ill_SP <- map2SpatialPolygons(ill, IDs=ill$names,
>   proj4string=CRS("+proj=longlat"))
> plot(ill_SP)
> # next two lines to generate some random points on the bounding
> # box of Illinois
> SG <- Sobj_SpatialGrid(ill_SP)$SG
> pts <- spsample(SG, n=500, type="random")
> plot(pts, add=TRUE)
> o <- overlay(pts, ill_SP)
> plot(pts[!is.na(o),], col="red", add=TRUE)
> 
> Hope this helps,
> 
> Roger
> 
> PS. The useR conference has lots of excellent talks, and surprisingly 
> many are spatial. Next year's conference will be in Rennes, France, and 
> in 2010, it will probably be in North America.
> 
>>
>> hth,
>>
>> Paul
>>
>> Fernando Miguez wrote:
>>>  Hi all,
>>>
>>>  I would like to be able to do the following
>>>
>>>  map('state','illinois')
>>>  points(x,y)
>>>
>>>  Up to this point everything is fine. However, some of the points fall
>>>  outside the Illinois map boundaries. What I would like to do is to 
>>> add a
>>>  layer where the inside of the Illinois polygon is transparent (so 
>>> that the
>>>  points can be seen) but the points outside the boundary are covered so
>>>  they are not seen. I thought that using some variation of map with its
>>>  arguments would work, but I haven't been able to figure it out. I 
>>> see that
>>>  it is quite possible that I'm using the wrong tools all together ... 
>>> let
>>>  me know.
>>>
>>>  Any help is appreciated. Thanks.
>>>
>>>  Fernando
>>>
>>
>>
>>
> 

-- 
Fernando E. Miguez
Energy Biosciences Institute
http://netfiles.uiuc.edu/miguez/www/



From murray.richardson at utoronto.ca  Fri Aug 15 18:51:24 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Fri, 15 Aug 2008 12:51:24 -0400
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
Message-ID: <48A5B40C.3040608@utoronto.ca>

Thanks for this Roger.

One other thing now...if I use unionSpatialPolygons as a dissolve tool, 
is there a way to then explode distinct polygons back to individual 
polygons?  i.e. once all the slivers are gone and I have polygons merged 
based on attributes, the result is a multipart polygon for each ID I 
used for the merge, but I need them back as separate polys.

Thanks

Murray



Roger Bivand wrote:
> On Wed, 13 Aug 2008, Murray Richardson wrote:
>
>> Hello again r.sig.geo list,
>>
>> Thanks Roger, for help on my previous question regarding iterating 
>> through a shapefile.
>>
>> I'm sure once I receive my copy of  "Applied Spatial Data Analysis 
>> with R" I will find answers to simple questions like this on my own, 
>> but in the meantime....
>>
>> Is it possible to merge sliver polygons that fall below a certain 
>> threshold area with adjacent neighbours (e.g. perhaps using  
>> unionSpatialPolygons but without aggregating any  polygons?).  If a 
>> sliver shares edges with more than one polygon, it doesn't really 
>> matter which one it merges with, but if I had to choose a rule I 
>> would have it merge with the largest one.
>
> Not such a simple question ...
>
> Both the Polygon and Polygons objects in the SpatialPolygons object 
> have "area" slots, with different roles. The Polygon objects have a 
> correct naive area in the geometry of the coordinates taken as planar. 
> The Polygons objects use the "gross" area of Polygon objects belonging 
> to them, but "only" to provide the plot order (plot from largest to 
> smallest to avoid over-painting).
>
> If you "trust" the area slot of the Polygons objects (beware of hole 
> Polygon objects), you can first find your candidate slivers by 
> retrieving the areas by:
>
> Polygons_areas <- sapply(slot(SPobj, "polygons"),
>   function(x) slot(x, "area"))
>
> and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to 
> find the neighbours (rook criterion). Next use the output object to 
> identify the largest neighbours of the sliver candidates, and build a 
> "new Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
> assuming you wouldn't have asked if there was useful data in the slivers!
>
> Hope this helps,
>
> Roger
>
>>
>> Thanks in advance,
>>
>> Murray Richardson
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>



From Roger.Bivand at nhh.no  Fri Aug 15 19:20:55 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 15 Aug 2008 19:20:55 +0200 (CEST)
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <48A5B40C.3040608@utoronto.ca>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48A5B40C.3040608@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0808151919350.29938@reclus.nhh.no>

On Fri, 15 Aug 2008, Murray Richardson wrote:

> Thanks for this Roger.
>
> One other thing now...if I use unionSpatialPolygons as a dissolve tool, is 
> there a way to then explode distinct polygons back to individual polygons? 
> i.e. once all the slivers are gone and I have polygons merged based on 
> attributes, the result is a multipart polygon for each ID I used for the 
> merge, but I need them back as separate polys.

Each unique ID value should give a separate Polygons object, so look at 
the ID vector before going into unionSpatialPolygons() to make sure it 
does what you want.

Roger

>
> Thanks
>
> Murray
>
>
>
> Roger Bivand wrote:
>>  On Wed, 13 Aug 2008, Murray Richardson wrote:
>> 
>> >  Hello again r.sig.geo list,
>> > 
>> >  Thanks Roger, for help on my previous question regarding iterating 
>> >  through a shapefile.
>> > 
>> >  I'm sure once I receive my copy of  "Applied Spatial Data Analysis with 
>> >  R" I will find answers to simple questions like this on my own, but in 
>> >  the meantime....
>> > 
>> >  Is it possible to merge sliver polygons that fall below a certain 
>> >  threshold area with adjacent neighbours (e.g. perhaps using 
>> >  unionSpatialPolygons but without aggregating any  polygons?).  If a 
>> >  sliver shares edges with more than one polygon, it doesn't really matter 
>> >  which one it merges with, but if I had to choose a rule I would have it 
>> >  merge with the largest one.
>>
>>  Not such a simple question ...
>>
>>  Both the Polygon and Polygons objects in the SpatialPolygons object have
>>  "area" slots, with different roles. The Polygon objects have a correct
>>  naive area in the geometry of the coordinates taken as planar. The
>>  Polygons objects use the "gross" area of Polygon objects belonging to
>>  them, but "only" to provide the plot order (plot from largest to smallest
>>  to avoid over-painting).
>>
>>  If you "trust" the area slot of the Polygons objects (beware of hole
>>  Polygon objects), you can first find your candidate slivers by retrieving
>>  the areas by:
>>
>>  Polygons_areas <- sapply(slot(SPobj, "polygons"),
>>    function(x) slot(x, "area"))
>>
>>  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to find
>>  the neighbours (rook criterion). Next use the output object to identify
>>  the largest neighbours of the sliver candidates, and build a "new
>>  Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm assuming you
>>  wouldn't have asked if there was useful data in the slivers!
>>
>>  Hope this helps,
>>
>>  Roger
>> 
>> > 
>> >  Thanks in advance,
>> > 
>> >  Murray Richardson
>> > 
>>> _______________________________________________
>> >  R-sig-Geo mailing list
>> >  R-sig-Geo at stat.math.ethz.ch
>> >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > 
>> > 
>> 
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From murray.richardson at utoronto.ca  Fri Aug 15 20:07:52 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Fri, 15 Aug 2008 14:07:52 -0400
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <Pine.LNX.4.64.0808151919350.29938@reclus.nhh.no>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48A5B40C.3040608@utoronto.ca>
	<Pine.LNX.4.64.0808151919350.29938@reclus.nhh.no>
Message-ID: <48A5C5F8.1040300@utoronto.ca>

Oh maybe I've misunderstood the function.

I am using unionSpatialPolygons to dissolve boundaries between adjacent 
polygons that have a similar attribute (I use cut to classify the ID 
into say, 10 different categories), i.e.:

x<-readShapePoly("up1polys", IDvar="ID")
slopes<-slot(x[(1:length(slot(x, "polygons"))),3], "data")
breaks<-c(0,5,10,20,30,40,50,60,70,100)
ID <- cut(slopes[,1], breaks)
sptmp <- unionSpatialPolygons(x, ID)
newID<-data.frame(c(1:length(slot(sptmp, "polygons"))))
merged<-SpatialPolygonsDataFrame(sptmp, data=newID, match.ID=FALSE)
writePolyShape(merged, "up1merged", factor2char = TRUE, max_nchar=254)

So I am just using unionSpatialPolygons as a dissolve tool but I would 
like non-adjacent polys within the same slope class to be separate 
polygons when I'm done.

Thanks again

Murray


Roger Bivand wrote:
> On Fri, 15 Aug 2008, Murray Richardson wrote:
>
>> Thanks for this Roger.
>>
>> One other thing now...if I use unionSpatialPolygons as a dissolve 
>> tool, is there a way to then explode distinct polygons back to 
>> individual polygons? i.e. once all the slivers are gone and I have 
>> polygons merged based on attributes, the result is a multipart 
>> polygon for each ID I used for the merge, but I need them back as 
>> separate polys.
>
> Each unique ID value should give a separate Polygons object, so look 
> at the ID vector before going into unionSpatialPolygons() to make sure 
> it does what you want.
>
> Roger
>
>>
>> Thanks
>>
>> Murray
>>
>>
>>
>> Roger Bivand wrote:
>>>  On Wed, 13 Aug 2008, Murray Richardson wrote:
>>>
>>> >  Hello again r.sig.geo list,
>>> > >  Thanks Roger, for help on my previous question regarding 
>>> iterating >  through a shapefile.
>>> > >  I'm sure once I receive my copy of  "Applied Spatial Data 
>>> Analysis with >  R" I will find answers to simple questions like 
>>> this on my own, but in >  the meantime....
>>> > >  Is it possible to merge sliver polygons that fall below a 
>>> certain >  threshold area with adjacent neighbours (e.g. perhaps 
>>> using >  unionSpatialPolygons but without aggregating any  
>>> polygons?).  If a >  sliver shares edges with more than one polygon, 
>>> it doesn't really matter >  which one it merges with, but if I had 
>>> to choose a rule I would have it >  merge with the largest one.
>>>
>>>  Not such a simple question ...
>>>
>>>  Both the Polygon and Polygons objects in the SpatialPolygons object 
>>> have
>>>  "area" slots, with different roles. The Polygon objects have a correct
>>>  naive area in the geometry of the coordinates taken as planar. The
>>>  Polygons objects use the "gross" area of Polygon objects belonging to
>>>  them, but "only" to provide the plot order (plot from largest to 
>>> smallest
>>>  to avoid over-painting).
>>>
>>>  If you "trust" the area slot of the Polygons objects (beware of hole
>>>  Polygon objects), you can first find your candidate slivers by 
>>> retrieving
>>>  the areas by:
>>>
>>>  Polygons_areas <- sapply(slot(SPobj, "polygons"),
>>>    function(x) slot(x, "area"))
>>>
>>>  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to 
>>> find
>>>  the neighbours (rook criterion). Next use the output object to 
>>> identify
>>>  the largest neighbours of the sliver candidates, and build a "new
>>>  Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
>>> assuming you
>>>  wouldn't have asked if there was useful data in the slivers!
>>>
>>>  Hope this helps,
>>>
>>>  Roger
>>>
>>> > >  Thanks in advance,
>>> > >  Murray Richardson
>>> >
>>>> _______________________________________________
>>> >  R-sig-Geo mailing list
>>> >  R-sig-Geo at stat.math.ethz.ch
>>> >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > >
>>
>



From rroa at udec.cl  Sat Aug 16 01:35:43 2008
From: rroa at udec.cl (Ruben Roa Ureta)
Date: Fri, 15 Aug 2008 19:35:43 -0400 (CLT)
Subject: [R-sig-Geo] Error in geoR likfit()
Message-ID: <3490.190.20.214.212.1218843343.squirrel@webmail.udec.cl>

ComRades:

I am getting the error message
Error in ldots[[which(MET)]] : attempt to select less than one element
when I try to fit the geostatistical model with the likfit() function of
geoR.
I have tried with old data for which likfit() successfully maximised the
likelihood in previous versions of geoR, and yet the current version
fails.
I have tried in Windows Vista and Windows XP (I haven't tried in Linux
systems) and the problem occurs in both systems.
Below I show the issue with simulated data.
Does anybody know a solution?
Thanks in advance
Ruben

x <- rnorm(50,5,2) # eastings
y <- rnorm(50,25,3) # northings
z <- rnorm(50,350,35) # data
v <- c(rep(1,25),rep(2,25)) # two different areas
w <- data.frame(cbind(x,y,z,v)) # put all together
w1 <- subset(w,v == 1) # use data fron one area
w1.geo <- as.geodata(w1,coords.col=1:2,data.col=3) # create geodata object
summary(w1.geo) # everything looks normal
#Number of data points: 25
#
#Coordinates summary
#           x        y
#min 1.233673 15.82129
#max 8.464283 34.30390
#
#Distance summary
#       min        max
# 0.2962488 19.5670141
#
#Data summary
#   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
#  296.1   336.3   345.5   351.9   366.5   422.1
plot(w1.geo) # so far so good
plot(w1.geo,lambda=0.1) #ditto
w1.geo.vc<-variog(w1.geo,option="cloud",max.dist=summary(w1.geo)$distances.summary[2],lambda=lambda)
#variog: computing omnidirectional variogram
plot(w1.geo.vc)
w1.geo.lf<-likfit(w1.geo,cov.model="matern",ini.cov.pars=c(2,0.03),kappa=1,fix.kappa=FALSE,nugget=0.01,lambda=lambda,fix.lambda=FALSE,hessian=TRUE)
# here the error in likfit()
#Error in ldots[[which(MET)]] : attempt to select less than one element
sessionInfo()
#R version 2.6.2 (2008-02-08)
#i386-pc-mingw32
#
#locale:
#LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
States.1252;LC_MONETARY=English_United
States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
#
#attached base packages:
#[1] stats     graphics  grDevices utils     datasets  methods   base
#
#other attached packages:
#[1] geoR_1.6-21 sp_0.9-25
#
#loaded via a namespace (and not attached):
#[1] grid_2.6.2     lattice_0.17-4 tools_2.6.2



From murray.richardson at utoronto.ca  Sat Aug 16 02:39:39 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Fri, 15 Aug 2008 20:39:39 -0400
Subject: [R-sig-Geo] problem with RSAGA grid_gridding module
Message-ID: <48A621CB.2010502@utoronto.ca>

Hello,

I am having a problem using the grid to shapes module, as follows:

rsaga.geoprocessor("grid_gridding", 3, list(GRID="tmpPolyGrid.sgrd", 
INPUT="tmp", FIELD=1, TARGET_TYPE=2, GRID_GRID="filled.sgrd"))

This causes saga_cmd to crash on windows xp.  I can't, for the life of 
me, figure out what's going on.  I need the output extents to match the 
extents of "filled.sgrd".  RSAGA works great for everything else I have 
tried, but not this.

Any advice?

Thanks

Murray



From paulojus at c3sl.ufpr.br  Sat Aug 16 04:05:25 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 15 Aug 2008 23:05:25 -0300 (BRT)
Subject: [R-sig-Geo]
 =?iso-8859-1?q?Strange_error_message_from_geoR=B4s_li?=
 =?iso-8859-1?q?kfit_=28=29_lik=2E______max=2E_func=2E?=
In-Reply-To: <1804.190.20.214.212.1218814428.squirrel@webmail.udec.cl>
References: <1804.190.20.214.212.1218814428.squirrel@webmail.udec.cl>
Message-ID: <Pine.LNX.4.58.0808152303430.2292@talisker.c3sl.ufpr.br>

Ruben

it is a bug
I will upload a new version of geoR.
Meanwhile please download the version with the fix from the geoR web page
at
www.leg.ufpr.br/geoR


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Fri, 15 Aug 2008, Ruben Roa Ureta wrote:

> ComRades:
>
> I am geeting the error message
> Error in ldots[[which(MET)]] : attempt to select less than one element
> when I try to fit the geostatistical model with the likfit() function of
> geoR.
> I have tried with old data for which likfit() successfully maximised the
> likelihood in previous versions of geoR, and yet the current version
> fails.
> I have tried in Windows Vista and Windows XP (I haven't tried in Linux
> systems) and the problem occurs in both systems.
> Below I show the issue with simulated data.
> Is it a geoR bug?
> Does anybody know a solution?
> Thanks in advance
> Ruben
>
> x <- rnorm(50,5,2) # eastings
> y <- rnorm(50,25,3) # northings
> z <- rnorm(50,350,35) # data
> v <- c(rep(1,25),rep(2,25)) # two different areas
> w <- data.frame(cbind(x,y,z,v)) # put all together
> w1 <- subset(w,v == 1) # use data fron one area
> w1.geo <- as.geodata(w1,coords.col=1:2,data.col=3) # create geodata object
> summary(w1.geo) # everything looks normal
> #Number of data points: 25
> #
> #Coordinates summary
> #           x        y
> #min 1.233673 15.82129
> #max 8.464283 34.30390
> #
> #Distance summary
> #       min        max
> # 0.2962488 19.5670141
> #
> #Data summary
> #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> #  296.1   336.3   345.5   351.9   366.5   422.1
> plot(w1.geo) # so far so good
> plot(w1.geo,lambda=0.1) #ditto
> w1.geo.vc<-variog(w1.geo,option="cloud",max.dist=summary(w1.geo)$distances.summary[2],lambda=lambda)
> #variog: computing omnidirectional variogram
> plot(w1.geo.vc)
> w1.geo.lf<-likfit(w1.geo,cov.model="matern",ini.cov.pars=c(2,0.03),kappa=1,fix.kappa=FALSE,nugget=0.01,lambda=lambda,fix.lambda=FALSE,hessian=TRUE)
> # here the error in likfit()
> #Error in ldots[[which(MET)]] : attempt to select less than one element
> sessionInfo()
> #R version 2.6.2 (2008-02-08)
> #i386-pc-mingw32
> #
> #locale:
> #LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> #
> #attached base packages:
> #[1] stats     graphics  grDevices utils     datasets  methods   base
> #
> #other attached packages:
> #[1] geoR_1.6-21 sp_0.9-25
> #
> #loaded via a namespace (and not attached):
> #[1] grid_2.6.2     lattice_0.17-4 tools_2.6.2
>
>



From v.gomezrubio at imperial.ac.uk  Sat Aug 16 10:47:05 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Sat, 16 Aug 2008 09:47:05 +0100
Subject: [R-sig-Geo] error message using BRugs package -
	multivariate	distribution	must have more than one component
In-Reply-To: <48A43DD2.C273.0098.0@newcastle.edu.au>
References: <48A43DD2.C273.0098.0@newcastle.edu.au>
Message-ID: <1218876425.30020.21.camel@fh-vrubio>

Philip,

I have checked the code that you have sent and your problem is that you
have not written the car.normal in the right way. You should remove the
line where you specify the car.normal and replace it  (outside the 1:N
loop) by

b[1:N] ~ car.normal(adj[], weights[], num[], taulgacar)

This is the right way of specifying a car normal in WinBUGS and not giving a
distribution to each b[i].

> I am hoping to get a lead when the asdar book comes out next month, 
> but I thought I might be fortunate to get some help from the list as well. 
> I have attached the two models, data files, and R commands to the end of this email. 

In addition, I would remove the term 'mulga' and 'mulgaerror' (perhaps
you mean 'mulgaerr') from  inits because they are not stochastic nodes.
You should also set the initial values for 'sigmalgacar' and not
'taulgacar'.

Given that your problem is not R related, I believe that this other
reference might be more appropriate in your case:

Disease Mapping with WinBUGS and MLwiN 
By Andrew B. Lawson, William J. Browne, Carmen L. Vidal Rodeiro
Published by John Wiley and Sons, 2003 ISBN 0470856041, 9780470856048
292 pages 


They show how to fit many types of spatial model using WinBUGS and
provide lots of examples. They do not show how to use the output to make
maps with R though. Furthermore, if you like hard stuff, you can check
the book by Banerjee et al. which also provides many examples.

Best regards,

Virgilio

P.S: This is the WB code for the new model. I would suggest that you
increase the range of values in the prior for taulga because it seems
too narrow.

model
        {

                for (i in 1 : N) {
                dlga[i] ~ dnorm(mulga[i], taulga)
                mulga[i] <- beta0 + theft[i] + b[i] + drugs[i] +
assault[i] + personalviolence[i] + maliciouspd[i] + mulgaerror[i]
                mulgaerr[i] ~ dunif(0,10)
                mulgaerror[i] <-  pow(mulgaerr[i], -2)
                }

for(k in 1:50)   {
                weights[k] <- 1}

        b[1:N] ~ car.normal(adj[], weights[], num[], taulgacar)

        beta0 ~  dnorm(0, 0.00001)
        taulga ~ dunif(0,10)
        sigma <- sqrt(1 /  taulga)
        sigmalgacar ~ dunif(0,10)
        taulgacar<- 1/(sigmalgacar*sigmalgacar)
}



From Roger.Bivand at nhh.no  Sat Aug 16 22:45:07 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 16 Aug 2008 22:45:07 +0200 (CEST)
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <48A5C5F8.1040300@utoronto.ca>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48A5B40C.3040608@utoronto.ca>
	<Pine.LNX.4.64.0808151919350.29938@reclus.nhh.no>
	<48A5C5F8.1040300@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0808162236590.1469@reclus.nhh.no>

On Fri, 15 Aug 2008, Murray Richardson wrote:

> Oh maybe I've misunderstood the function.
>
> I am using unionSpatialPolygons to dissolve boundaries between adjacent 
> polygons that have a similar attribute (I use cut to classify the ID into 
> say, 10 different categories), i.e.:
>
> x<-readShapePoly("up1polys", IDvar="ID")
> slopes<-slot(x[(1:length(slot(x, "polygons"))),3], "data")
> breaks<-c(0,5,10,20,30,40,50,60,70,100)
> ID <- cut(slopes[,1], breaks)
> sptmp <- unionSpatialPolygons(x, ID)
> newID<-data.frame(c(1:length(slot(sptmp, "polygons"))))
> merged<-SpatialPolygonsDataFrame(sptmp, data=newID, match.ID=FALSE)
> writePolyShape(merged, "up1merged", factor2char = TRUE, max_nchar=254)
>
> So I am just using unionSpatialPolygons as a dissolve tool but I would like 
> non-adjacent polys within the same slope class to be separate polygons when 
> I'm done.

The ID argument groups all, both contiguous and so merged, and 
non-contiguous, Polygon objects in the same Polygons object. So if you 
don't want them merged, only set the same ID values for the slivers to be 
joined, merge the polygons, then go on and do the other things.

Your assignment to slopes is very strange. What does names(x) say? If the 
third one is "slopes", why not just say x$slopes? The object does behave 
just like a data.frame, after all. I think that you need to do things 
strictly step by step, do the slivers first, then associate the correct 
attributes with the output polygons.

Roger

>
> Thanks again
>
> Murray
>
>
> Roger Bivand wrote:
>>  On Fri, 15 Aug 2008, Murray Richardson wrote:
>> 
>> >  Thanks for this Roger.
>> > 
>> >  One other thing now...if I use unionSpatialPolygons as a dissolve tool, 
>> >  is there a way to then explode distinct polygons back to individual 
>> >  polygons? i.e. once all the slivers are gone and I have polygons merged 
>> >  based on attributes, the result is a multipart polygon for each ID I 
>> >  used for the merge, but I need them back as separate polys.
>>
>>  Each unique ID value should give a separate Polygons object, so look at
>>  the ID vector before going into unionSpatialPolygons() to make sure it
>>  does what you want.
>>
>>  Roger
>> 
>> > 
>> >  Thanks
>> > 
>> >  Murray
>> > 
>> > 
>> > 
>> >  Roger Bivand wrote:
>> > >   On Wed, 13 Aug 2008, Murray Richardson wrote:
>> > > 
>> > > >   Hello again r.sig.geo list,
>> > > > >   Thanks Roger, for help on my previous question regarding 
>> > > iterating >   through a shapefile.
>> > > > >   I'm sure once I receive my copy of  "Applied Spatial Data 
>> > >  Analysis with >  R" I will find answers to simple questions like this 
>> > >  on my own, but in >  the meantime....
>> > > > >   Is it possible to merge sliver polygons that fall below a 
>> > >  certain >  threshold area with adjacent neighbours (e.g. perhaps using 
>> > >  >  unionSpatialPolygons but without aggregating any  polygons?).  If a 
>> > >  >  sliver shares edges with more than one polygon, it doesn't really 
>> > >  matter >  which one it merges with, but if I had to choose a rule I 
>> > >  would have it >  merge with the largest one.
>> > > 
>> > >   Not such a simple question ...
>> > > 
>> > >  Both the Polygon and Polygons objects in the SpatialPolygons object 
>> > >  have
>> > >   "area" slots, with different roles. The Polygon objects have a 
>> > >   correct
>> > >   naive area in the geometry of the coordinates taken as planar. The
>> > >   Polygons objects use the "gross" area of Polygon objects belonging to
>> > >   them, but "only" to provide the plot order (plot from largest to 
>> > >  smallest
>> > >   to avoid over-painting).
>> > > 
>> > >   If you "trust" the area slot of the Polygons objects (beware of hole
>> > >   Polygon objects), you can first find your candidate slivers by 
>> > >  retrieving
>> > >   the areas by:
>> > > 
>> > >   Polygons_areas <- sapply(slot(SPobj, "polygons"),
>> > >     function(x) slot(x, "area"))
>> > > 
>> > >  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to 
>> > >  find
>> > >  the neighbours (rook criterion). Next use the output object to 
>> > >  identify
>> > >   the largest neighbours of the sliver candidates, and build a "new
>> > >   Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
>> > >  assuming you
>> > >   wouldn't have asked if there was useful data in the slivers!
>> > > 
>> > >   Hope this helps,
>> > > 
>> > >   Roger
>> > > 
>> > > > >   Thanks in advance,
>> > > > >   Murray Richardson
>> > > > 
>>>>> _______________________________________________
>> > > >   R-sig-Geo mailing list
>> > > >   R-sig-Geo at stat.math.ethz.ch
>> > > >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > > 
>> > 
>> 
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ajblist-geo at yahoo.de  Mon Aug 18 02:58:15 2008
From: ajblist-geo at yahoo.de (ajblist-geo at yahoo.de)
Date: Mon, 18 Aug 2008 00:58:15 +0000 (GMT)
Subject: [R-sig-Geo] problem with RSAGA grid_gridding module
Message-ID: <178016.40578.qm@web24001.mail.ird.yahoo.com>

Dear Murray,

this seems to be a known bug in SAGA GIS, not in the RSAGA front-end:

http://www.saga-gis.uni-goettingen.de/html/index.php?module=pnForum&func=viewtopic&topic=346

Volker Wiechmann, one of the SAGA developers posted this in response to a user's note:

"I am able to reproduce your error (the shapes in your zip are somewhat
corrupted, but the batch file is ok). The problem arises as soon as you
use a grid system or a grid as final extent/resolution destination. I
had a quick look at the source but could not find something
"suspicious". And I don't have the time to look in detail ... so please
file a bug report on sourceforge.
The module runs fine when you use a user specified extent/resolution.
So maybe this is a workaround for you until the bug is fixed."

The situation described above (grid used as target extent) seems to fit your problem description, so specify a fixed extent and resolution instead as a workaround.

I hope this will help.

Cheers
 Alex





----- Urspr?ngliche Mail ----
Von: Murray Richardson <murray.richardson at utoronto.ca>
An: r-sig-geo at stat.math.ethz.ch
Gesendet: Freitag, den 15. August 2008, 20:39:39 Uhr
Betreff: [R-sig-Geo] problem with RSAGA grid_gridding module

Hello,

I am having a problem using the grid to shapes module, as follows:

rsaga.geoprocessor("grid_gridding", 3, list(GRID="tmpPolyGrid.sgrd", 
INPUT="tmp", FIELD=1, TARGET_TYPE=2, GRID_GRID="filled.sgrd"))

This causes saga_cmd to crash on windows xp.  I can't, for the life of 
me, figure out what's going on.  I need the output extents to match the 
extents of "filled.sgrd".  RSAGA works great for everything else I have 
tried, but not this.

Any advice?

Thanks

Murray

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




-- 
Alexander Brenning (brenning -at- uwaterloo.ca)
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/

__________________________________________________
Do You Yahoo!?
Sie sind Spam 
mails. 
http://mail.yahoo.com



From murray.richardson at utoronto.ca  Mon Aug 18 04:35:27 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Sun, 17 Aug 2008 22:35:27 -0400
Subject: [R-sig-Geo] SpatialPolygons to SpatialGrid
In-Reply-To: <Pine.LNX.4.64.0808162236590.1469@reclus.nhh.no>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48A5B40C.3040608@utoronto.ca>
	<Pine.LNX.4.64.0808151919350.29938@reclus.nhh.no>
	<48A5C5F8.1040300@utoronto.ca>
	<Pine.LNX.4.64.0808162236590.1469@reclus.nhh.no>
Message-ID: <48A8DFEF.8080909@utoronto.ca>

Thanks again Roger - I see about the slopes assignment.  I'm just 
learning how to work with these spatial objects.  That should make them 
very nice to work with actually, glad to realize this.

I don't suppose there is any way to go from SpatialPolygons to a 
SpatialGrid is there?  I'm having a problem using the shapes to  grid 
function in SAGA via RSAGA geoprocessor, although most functions are 
working very well for me otherwise.  There is a problem with the SAGA 
source code it seems.  Essentially I need a relatively rapid conversion 
from a shapefile to a SpatialGridDataFrame (i.e. something not too 
computationally intensive) as I am having to do some expensive 
formatting to make things work via RSAGA.

Thanks again,

Murray


Roger Bivand wrote:
> On Fri, 15 Aug 2008, Murray Richardson wrote:
>
>> Oh maybe I've misunderstood the function.
>>
>> I am using unionSpatialPolygons to dissolve boundaries between 
>> adjacent polygons that have a similar attribute (I use cut to 
>> classify the ID into say, 10 different categories), i.e.:
>>
>> x<-readShapePoly("up1polys", IDvar="ID")
>> slopes<-slot(x[(1:length(slot(x, "polygons"))),3], "data")
>> breaks<-c(0,5,10,20,30,40,50,60,70,100)
>> ID <- cut(slopes[,1], breaks)
>> sptmp <- unionSpatialPolygons(x, ID)
>> newID<-data.frame(c(1:length(slot(sptmp, "polygons"))))
>> merged<-SpatialPolygonsDataFrame(sptmp, data=newID, match.ID=FALSE)
>> writePolyShape(merged, "up1merged", factor2char = TRUE, max_nchar=254)
>>
>> So I am just using unionSpatialPolygons as a dissolve tool but I 
>> would like non-adjacent polys within the same slope class to be 
>> separate polygons when I'm done.
>
> The ID argument groups all, both contiguous and so merged, and 
> non-contiguous, Polygon objects in the same Polygons object. So if you 
> don't want them merged, only set the same ID values for the slivers to 
> be joined, merge the polygons, then go on and do the other things.
>
> Your assignment to slopes is very strange. What does names(x) say? If 
> the third one is "slopes", why not just say x$slopes? The object does 
> behave just like a data.frame, after all. I think that you need to do 
> things strictly step by step, do the slivers first, then associate the 
> correct attributes with the output polygons.
>
> Roger
>
>>
>> Thanks again
>>
>> Murray
>>
>>
>> Roger Bivand wrote:
>>>  On Fri, 15 Aug 2008, Murray Richardson wrote:
>>>
>>> >  Thanks for this Roger.
>>> > >  One other thing now...if I use unionSpatialPolygons as a 
>>> dissolve tool, >  is there a way to then explode distinct polygons 
>>> back to individual >  polygons? i.e. once all the slivers are gone 
>>> and I have polygons merged >  based on attributes, the result is a 
>>> multipart polygon for each ID I >  used for the merge, but I need 
>>> them back as separate polys.
>>>
>>>  Each unique ID value should give a separate Polygons object, so 
>>> look at
>>>  the ID vector before going into unionSpatialPolygons() to make sure it
>>>  does what you want.
>>>
>>>  Roger
>>>
>>> > >  Thanks
>>> > >  Murray
>>> > > > >  Roger Bivand wrote:
>>> > >   On Wed, 13 Aug 2008, Murray Richardson wrote:
>>> > > > > >   Hello again r.sig.geo list,
>>> > > > >   Thanks Roger, for help on my previous question regarding > 
>>> > iterating >   through a shapefile.
>>> > > > >   I'm sure once I receive my copy of  "Applied Spatial Data 
>>> > >  Analysis with >  R" I will find answers to simple questions 
>>> like this > >  on my own, but in >  the meantime....
>>> > > > >   Is it possible to merge sliver polygons that fall below a 
>>> > >  certain >  threshold area with adjacent neighbours (e.g. 
>>> perhaps using > >  >  unionSpatialPolygons but without aggregating 
>>> any  polygons?).  If a > >  >  sliver shares edges with more than 
>>> one polygon, it doesn't really > >  matter >  which one it merges 
>>> with, but if I had to choose a rule I > >  would have it >  merge 
>>> with the largest one.
>>> > > > >   Not such a simple question ...
>>> > > > >  Both the Polygon and Polygons objects in the 
>>> SpatialPolygons object > >  have
>>> > >   "area" slots, with different roles. The Polygon objects have a 
>>> > >   correct
>>> > >   naive area in the geometry of the coordinates taken as planar. 
>>> The
>>> > >   Polygons objects use the "gross" area of Polygon objects 
>>> belonging to
>>> > >   them, but "only" to provide the plot order (plot from largest 
>>> to > >  smallest
>>> > >   to avoid over-painting).
>>> > > > >   If you "trust" the area slot of the Polygons objects 
>>> (beware of hole
>>> > >   Polygon objects), you can first find your candidate slivers by 
>>> > >  retrieving
>>> > >   the areas by:
>>> > > > >   Polygons_areas <- sapply(slot(SPobj, "polygons"),
>>> > >     function(x) slot(x, "area"))
>>> > > > >  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in 
>>> spdep to > >  find
>>> > >  the neighbours (rook criterion). Next use the output object to 
>>> > >  identify
>>> > >   the largest neighbours of the sliver candidates, and build a "new
>>> > >   Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
>>> > >  assuming you
>>> > >   wouldn't have asked if there was useful data in the slivers!
>>> > > > >   Hope this helps,
>>> > > > >   Roger
>>> > > > > > >   Thanks in advance,
>>> > > > >   Murray Richardson
>>> > > >
>>>>>> _______________________________________________
>>> > > >   R-sig-Geo mailing list
>>> > > >   R-sig-Geo at stat.math.ethz.ch
>>> > > >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > > > > >
>>
>



From edzer.pebesma at uni-muenster.de  Mon Aug 18 10:32:04 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 18 Aug 2008 10:32:04 +0200
Subject: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
In-Reply-To: <8BD19F29B0E16E4F88277A997CD872C204499694@mail.agso.gov.au>
References: <8BD19F29B0E16E4F88277A997CD872C204499694@mail.agso.gov.au>
Message-ID: <48A93384.9020808@uni-muenster.de>

Hi Jin,

Which differences do you exactly refer to? I'd say that what happens in 
demo(cokriging) is ordinary cokriging. As it says:
...
[using ordinary cokriging]

Best regards,
--
Edzer

Jin.Li at ga.gov.au wrote:
> Hi All,
>
>  
>
> I am going to compare a few spatial interpolation techniques including
> kriging with an external drift (KED) and ordinary co-kriging (OCK) (such as
> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
> Evaluation.) to interpolate marine sediment data (mud content in this case)
> using bathymetry as a secondary variable. However, it seems that the ordinary
> cokriging in gstat as shown in demo(cokriging) is different from the OCK we
> planned to use. Is it possible to do such OCK in gstat? Any comments and
> example? Thanks.
>
>  
>
> As to KED, I tried 
>
>   
>> vgm1 <- variogram(sqrt(mud)~bathy, data.file.dev)
>>     
>
>   
>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>     
>
>   
>> # plot(vgm1, model.1)
>>     
>
>   
>> coordinates(data.file.pred) = ~LON+LAT
>>     
>
>   
>> mud.ok <- krige(sqrt(mud)~bathy, data.file.dev, data.file.pred, model =
>>     
> model.1)
>
> [using universal kriging]
>
>  
>
>   
>> vgm1 <- variogram(sqrt(mud)~LON+LAT, data.file.dev)
>>     
>
>   
>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>     
>
>   
>> # plot(vgm1, model.1)
>>     
>
>   
>> coordinates(data.file.pred) = ~LON+LAT
>>     
>
>   
>> mud.ok <- krige(sqrt(mud)~LON+LAT, data.file.dev, data.file.pred, model =
>>     
> model.1)
>
> [using universal kriging]
>
>  
>
> Both of them are UK. But the first one seems regression kriging. Is it
> identical to KED in this case? If not, any comments and examples of KED are
> appreciated.
>
>  
>
> Cheers,
>
>  
>
> Jin
>
> --------------------------------------------
>
> Jin Li, PhD
>
> Spatial Modeller/
>
> Computational Statistician
>
> Marine & Coastal Environment
>
> Geoscience Australia
>
>
>
> Ph: 61 (02) 6249 9899
>
> Fax: 61 (02) 6249 9956
>
> email: jin.li at ga.gov.au <mailto:jin.li at ga.gov.au> 
>
> --------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From edzer.pebesma at uni-muenster.de  Mon Aug 18 11:30:46 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 18 Aug 2008 11:30:46 +0200
Subject: [R-sig-Geo] error from universal kriging with krige()
In-Reply-To: <64114.217.233.91.197.1216831013.squirrel@mail.fr.bfs.de>
References: <64114.217.233.91.197.1216831013.squirrel@mail.fr.bfs.de>
Message-ID: <48A94146.50203@uni-muenster.de>

Is it a recent R/gstat version? If yes, could you provide me with a 
reproducable example?
--
Edzer

Sven Burbeck wrote:
> Hello,
>
> when I try to apply universal kriging by krige() I produce the following
> error:
>   
>> myVg_2 <- variogram(log10(M_BL) ~  GEO_UNIT - 1, data = myBlt_utm)
>> myVgm <- vgm(psill = 0.05,model = "Sph",range = 25000,nugget = 0.1)
>> myVgmf <- fit.variogram(object = myVg_2,model = myVgm,fit.sills = TRUE,
>>     
> fit.ranges = TRUE,fit.method = 7)
>   
>> myBlt_grid_UK <- krige(log10(M_BL) ~  GEO_UNIT - 1, locations =
>>     
> myBlt_utm, newdata = myPointGrid_utm, model = myVgmf)
> Error in gstat.formula.predict(d$formula, newdata, na.action = na.action,  :
>   NROW(locs) != NROW(X): this should not occur
> In addition: Warning messages:
> 1: 'newdata' had 2701 rows but variable(s) found have 911 rows
> 2: 'newdata' had 2701 rows but variable(s) found have 911 rows
>
>
> I know there was a posting about this error. There it was a coordinate
> problem but still I don't know how to solve the problem.
>
> Can anybody give me a hint?
>
> Thanks in advance,
> Sven
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From wroberts at csir.co.za  Mon Aug 18 14:47:27 2008
From: wroberts at csir.co.za (Wesley Roberts)
Date: Mon, 18 Aug 2008 14:47:27 +0200
Subject: [R-sig-Geo] variogram question
Message-ID: <48A98B8302000073000102D6@pta-emo.csir.co.za>

Dear r-sig-geo users,

I am currently analyzing some Lidar data we have collected over our study area. I am interested in identifying the range of the semi-variogram as this value will determine the width of pseudo-flight lines I intend to use to sample the lidar data. Our point density is upwards of 5 points per square meter captured over even-aged managed Eucalyptus plantations with an espacement of 2 meters between trees and 3 meters between rows. 

I have imported an x,y,z data set containing canopy height and coordinates and successfully run the experimental variogram using the "variogram" module in gstat. 

cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)

I have also managed to fit several models using the 

cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))

command as suggested by the gstat manual. I would like to fit the various models "Sph, Exp..." etc without having to specify the nugget psill and range. Essentially I would like an objective method to measure and record these values as I will be running several hundred variograms. Is it possible to perform this type of analysis using gstat?

Many thanks for all your help and suggestions
Wesley

Wesley Roberts MSc.
Researcher
Earth Observation (Ecosystems)
Natural Resources and the Environment
CSIR
Tel: +27 (21) 888-2490
Fax: +27 (21) 888-2490

"To know the road ahead, ask those coming back."
- Chinese proverb

-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.



From murray.richardson at utoronto.ca  Mon Aug 18 16:57:26 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Mon, 18 Aug 2008 10:57:26 -0400
Subject: [R-sig-Geo] problem with RSAGA grid_gridding module
Message-ID: <48A98DD6.9010002@utoronto.ca>

Aha yes, thanks, Alex.  I thought I had tried that option but must have 
used it incorrectly, that is a good enough workaround for me right now.

Thanks for the tip, I guess I missed that thread in SAGA archives too.

cheers

Murray



From edzer.pebesma at uni-muenster.de  Mon Aug 18 17:49:51 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 18 Aug 2008 17:49:51 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48A98B8302000073000102D6@pta-emo.csir.co.za>
References: <48A98B8302000073000102D6@pta-emo.csir.co.za>
Message-ID: <48A99A1F.5080308@uni-muenster.de>

In general: no, in special cases: yes.

Fitting variograms involves non-linear regression for most models (Sph, 
Exp, Gau, ...) for the range parameter, so you need starting values. 
Given the initial range, linear regression is sufficient to find the 
nugget/sill component(s), as they are linear. In principle, gstat could 
be made simpler in that respect, I'd say.

For an initial range, you could use some heuristics (20% of the longest 
distance in your data?), but it is often not so hard to think of cases 
where this would fail.

Another issue is automatic values for the width and cutoff.

You could have a look at package automap, by Paul Hiemstra, which tries 
to do some of these heuristics--good or bad, who will tell.
--
Edzer

Wesley Roberts wrote:
> Dear r-sig-geo users,
>
> I am currently analyzing some Lidar data we have collected over our study area. I am interested in identifying the range of the semi-variogram as this value will determine the width of pseudo-flight lines I intend to use to sample the lidar data. Our point density is upwards of 5 points per square meter captured over even-aged managed Eucalyptus plantations with an espacement of 2 meters between trees and 3 meters between rows. 
>
> I have imported an x,y,z data set containing canopy height and coordinates and successfully run the experimental variogram using the "variogram" module in gstat. 
>
> cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)
>
> I have also managed to fit several models using the 
>
> cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))
>
> command as suggested by the gstat manual. I would like to fit the various models "Sph, Exp..." etc without having to specify the nugget psill and range. Essentially I would like an objective method to measure and record these values as I will be running several hundred variograms. Is it possible to perform this type of analysis using gstat?
>
> Many thanks for all your help and suggestions
> Wesley
>
> Wesley Roberts MSc.
> Researcher
> Earth Observation (Ecosystems)
> Natural Resources and the Environment
> CSIR
> Tel: +27 (21) 888-2490
> Fax: +27 (21) 888-2490
>
> "To know the road ahead, ask those coming back."
> - Chinese proverb
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From Roger.Bivand at nhh.no  Mon Aug 18 18:27:14 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 18 Aug 2008 18:27:14 +0200 (CEST)
Subject: [R-sig-Geo] SpatialPolygons to SpatialGrid
In-Reply-To: <48A8DFEF.8080909@utoronto.ca>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48A5B40C.3040608@utoronto.ca>
	<Pine.LNX.4.64.0808151919350.29938@reclus.nhh.no>
	<48A5C5F8.1040300@utoronto.ca>
	<Pine.LNX.4.64.0808162236590.1469@reclus.nhh.no>
	<48A8DFEF.8080909@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0808181815450.8830@reclus.nhh.no>

On Sun, 17 Aug 2008, Murray Richardson wrote:

> Thanks again Roger - I see about the slopes assignment.  I'm just learning 
> how to work with these spatial objects.  That should make them very nice to 
> work with actually, glad to realize this.
>
> I don't suppose there is any way to go from SpatialPolygons to a SpatialGrid 
> is there?  I'm having a problem using the shapes to  grid function in SAGA 
> via RSAGA geoprocessor, although most functions are working very well for me 
> otherwise.  There is a problem with the SAGA source code it seems. 
> Essentially I need a relatively rapid conversion from a shapefile to a 
> SpatialGridDataFrame (i.e. something not too computationally intensive) as I 
> am having to do some expensive formatting to make things work via RSAGA.

Did your subsequent message indicate that you had found a work-around?

If not, this reply copied from a recent posting to the statsgrass list may 
be relevant, using overlay() to assign grid cell centres to polygons:

library(sp)
library(maptools)
polyg <- readShapeSpatial(system.file("shapes/sids.shp",
  package="maptools")[1],  IDvar="FIPSNO",
  proj4string=CRS("+proj=longlat +ellps=clrk66"))
# the SpatialGrid is created here - if you already have one, just use it
grd <- Sobj_SpatialGrid(polyg)$SG
d <- overlay(grd, polyg)
# d contains the indices of the Polygons object into which each cell
# centre falls, or NA
summary(d)
names(polyg)
v <- polyg$SID74[d]
# use d to index the variable of interest
# if grd had been a SpatialGridDataFrame, just assign "[[<-" or "$<-",
# grd[["SID74"]] <- polyg[["SID74"]][d]
# or:
grdd <- SpatialGridDataFrame(grid=slot(grd, "grid"),
  data=data.frame(SID74=v), proj4string=CRS(proj4string(grd)))
summary(grdd)
image(grdd)
spplot(polyg, "SID74")

Roger

>
> Thanks again,
>
> Murray
>
>
> Roger Bivand wrote:
>>  On Fri, 15 Aug 2008, Murray Richardson wrote:
>> 
>> >  Oh maybe I've misunderstood the function.
>> > 
>> >  I am using unionSpatialPolygons to dissolve boundaries between adjacent 
>> >  polygons that have a similar attribute (I use cut to classify the ID 
>> >  into say, 10 different categories), i.e.:
>> > 
>> >  x<-readShapePoly("up1polys", IDvar="ID")
>> >  slopes<-slot(x[(1:length(slot(x, "polygons"))),3], "data")
>> >  breaks<-c(0,5,10,20,30,40,50,60,70,100)
>> >  ID <- cut(slopes[,1], breaks)
>> >  sptmp <- unionSpatialPolygons(x, ID)
>> >  newID<-data.frame(c(1:length(slot(sptmp, "polygons"))))
>> >  merged<-SpatialPolygonsDataFrame(sptmp, data=newID, match.ID=FALSE)
>> >  writePolyShape(merged, "up1merged", factor2char = TRUE, max_nchar=254)
>> > 
>> >  So I am just using unionSpatialPolygons as a dissolve tool but I would 
>> >  like non-adjacent polys within the same slope class to be separate 
>> >  polygons when I'm done.
>>
>>  The ID argument groups all, both contiguous and so merged, and
>>  non-contiguous, Polygon objects in the same Polygons object. So if you
>>  don't want them merged, only set the same ID values for the slivers to be
>>  joined, merge the polygons, then go on and do the other things.
>>
>>  Your assignment to slopes is very strange. What does names(x) say? If the
>>  third one is "slopes", why not just say x$slopes? The object does behave
>>  just like a data.frame, after all. I think that you need to do things
>>  strictly step by step, do the slivers first, then associate the correct
>>  attributes with the output polygons.
>>
>>  Roger
>> 
>> > 
>> >  Thanks again
>> > 
>> >  Murray
>> > 
>> > 
>> >  Roger Bivand wrote:
>> > >   On Fri, 15 Aug 2008, Murray Richardson wrote:
>> > > 
>> > > >   Thanks for this Roger.
>> > > > >   One other thing now...if I use unionSpatialPolygons as a 
>> > >  dissolve tool, >  is there a way to then explode distinct polygons 
>> > >  back to individual >  polygons? i.e. once all the slivers are gone and 
>> > >  I have polygons merged >  based on attributes, the result is a 
>> > >  multipart polygon for each ID I >  used for the merge, but I need them 
>> > >  back as separate polys.
>> > > 
>> > >  Each unique ID value should give a separate Polygons object, so look 
>> > >  at
>> > >   the ID vector before going into unionSpatialPolygons() to make sure 
>> > >   it
>> > >   does what you want.
>> > > 
>> > >   Roger
>> > > 
>> > > > >   Thanks
>> > > > >   Murray
>> > > > > > >   Roger Bivand wrote:
>> > > > >    On Wed, 13 Aug 2008, Murray Richardson wrote:
>> > > > > > > >    Hello again r.sig.geo list,
>> > > > > > >    Thanks Roger, for help on my previous question regarding > 
>> > > > iterating >    through a shapefile.
>> > > > > > >    I'm sure once I receive my copy of  "Applied Spatial Data 
>> > > > >   Analysis with >  R" I will find answers to simple questions 
>> > >  like this > >  on my own, but in >  the meantime....
>> > > > > > >    Is it possible to merge sliver polygons that fall below a 
>> > > > > certain >   threshold area with adjacent neighbours (e.g. 
>> > >  perhaps using > >  >  unionSpatialPolygons but without aggregating any 
>> > >  polygons?).  If a > >  >  sliver shares edges with more than one 
>> > >  polygon, it doesn't really > >  matter >  which one it merges with, 
>> > >  but if I had to choose a rule I > >  would have it >  merge with the 
>> > >  largest one.
>> > > > > > >   Not such a simple question ...
>> > > > > > >   Both the Polygon and Polygons objects in the 
>> > >  SpatialPolygons object > >  have
>> > > > >    "area" slots, with different roles. The Polygon objects have a 
>> > > > >    correct
>> > > > >    naive area in the geometry of the coordinates taken as planar. 
>> > >  The
>> > > > >    Polygons objects use the "gross" area of Polygon objects 
>> > >  belonging to
>> > > > >    them, but "only" to provide the plot order (plot from largest 
>> > > to > >   smallest
>> > > > >    to avoid over-painting).
>> > > > > > >    If you "trust" the area slot of the Polygons objects 
>> > >  (beware of hole
>> > > > >   Polygon objects), you can first find your candidate slivers by 
>> > > > >   retrieving
>> > > > >    the areas by:
>> > > > > > >    Polygons_areas <- sapply(slot(SPobj, "polygons"),
>> > > > >      function(x) slot(x, "area"))
>> > > > > > >   and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in 
>> > >  spdep to > >  find
>> > > > >   the neighbours (rook criterion). Next use the output object to 
>> > > > >   identify
>> > > > >    the largest neighbours of the sliver candidates, and build a 
>> > > > >    "new
>> > > > >    Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
>> > > > >   assuming you
>> > > > >    wouldn't have asked if there was useful data in the slivers!
>> > > > > > >    Hope this helps,
>> > > > > > >    Roger
>> > > > > > > > >    Thanks in advance,
>> > > > > > >    Murray Richardson
>> > > > > > 
>>>>>>> _______________________________________________
>> > > > > >    R-sig-Geo mailing list
>> > > > > >    R-sig-Geo at stat.math.ethz.ch
>> > > > > >    https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > > > > > 
>> > 
>> 
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From edzer.pebesma at uni-muenster.de  Mon Aug 18 18:31:13 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 18 Aug 2008 18:31:13 +0200
Subject: [R-sig-Geo] [Gstat-info] retrieving gammas from a variogram
	model
In-Reply-To: <487BD140.2000805@geo.uu.nl>
References: <200807141506.49261.ashton@msu.edu> <487BD140.2000805@geo.uu.nl>
Message-ID: <48A9A3D1.1020503@uni-muenster.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080818/9c760375/attachment.pl>

From paulojus at c3sl.ufpr.br  Mon Aug 18 19:07:38 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Mon, 18 Aug 2008 14:07:38 -0300 (BRT)
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48A99A1F.5080308@uni-muenster.de>
References: <48A98B8302000073000102D6@pta-emo.csir.co.za>
	<48A99A1F.5080308@uni-muenster.de>
Message-ID: <Pine.LNX.4.58.0808181402120.17006@macalan.c3sl.ufpr.br>

A possible extension of Edzer thoughts on this is to consider a initial
search for the non-linear range parameters.

For instance, take a grid of (20 say) values for this parameters within a
reasonable range for the given problem, e.g. between 0 and the maximum
distance.
Evaluate the objective funcion (least squares, wighted least squares etc)
for such values. Use the best one as the initial value for the fitting
algorithm.

This is what variofit() does in geoR whan initial values are not provided,
but the same ideia holds for other variogram fitting functions
using other packages such as gstat and therefore can be made automatic.

P.J.


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Mon, 18 Aug 2008, Edzer Pebesma wrote:

> In general: no, in special cases: yes.
>
> Fitting variograms involves non-linear regression for most models (Sph,
> Exp, Gau, ...) for the range parameter, so you need starting values.
> Given the initial range, linear regression is sufficient to find the
>
nugget/sill component(s), as they are linear. In principle, gstat could
> be made simpler in that respect, I'd say.
>
> For an initial range, you could use some heuristics (20% of the longest
> distance in your data?), but it is often not so hard to think of cases
> where this would fail.
>
> Another issue is automatic values for the width and cutoff.
>
> You could have a look at package automap, by Paul Hiemstra, which tries
> to do some of these heuristics--good or bad, who will tell.
> --
> Edzer
>
> Wesley Roberts wrote:
> > Dear r-sig-geo users,
> >
> > I am currently analyzing some Lidar data we have collected over our study area. I am interested in identifying the range of the semi-variogram as this value will determine the width of pseudo-flight lines I intend to use to sample the lidar data. Our point density is upwards of 5 points per square meter captured over even-aged managed Eucalyptus plantations with an espacement of 2 meters between trees and 3 meters between rows.
> >
> > I have imported an x,y,z data set containing canopy height and coordinates and successfully run the experimental variogram using the "variogram" module in gstat.
> >
> > cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)
> >
> > I have also managed to fit several models using the
> >
> > cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))
> >
> > command as suggested by the gstat manual.
> I would like to fit the various models "Sph, Exp..." etc without having
to specify the nugget psill and range. Essentially I would like an objective method to measure and record these values as I will be running several hundred variograms. Is it possible to perform this type of analysis using gstat?
> >
> > Many thanks for all your help and suggestions
> > Wesley
> >
> > Wesley Roberts MSc.
> > Researcher
> > Earth Observation (Ecosystems)
> > Natural Resources and the Environment
> > CSIR
> > Tel: +27 (21) 888-2490
> > Fax: +27 (21) 888-2490
> >
> > "To know the road ahead, ask those coming back."
> > - Chinese proverb
> >
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster,
> Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From p.hiemstra at geo.uu.nl  Mon Aug 18 23:21:41 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 18 Aug 2008 23:21:41 +0200
Subject: [R-sig-Geo] [Gstat-info] retrieving gammas from a variogram
	model
In-Reply-To: <48A9A3D1.1020503@uni-muenster.de>
References: <200807141506.49261.ashton@msu.edu> <487BD140.2000805@geo.uu.nl>
	<48A9A3D1.1020503@uni-muenster.de>
Message-ID: <48A9E7E5.2030208@geo.uu.nl>

Thanks,

A good way of incorporating it.

Paul

Edzer Pebesma schreef:
> (I'm adding r-sig-geo to this thread)
>
> Paul/Ashton,
>
> I included your code, Paul; I also added the option (with the same 
> argument name) to variogramLine so you can now also do e.g. a
>
> variogramLine(vgm(1, "Sph", 1, anis=c(0, 0.5)), dir = 
> c(1/sqrt(c(2,2)),0), dist_vector = c(0, 0.1, 0.5, 1, 2))
>
> (that is, irregular distances at a given direction and anisotropic model)
> --
> Edzer
>
>
> Paul Hiemstra wrote:
>> Hi Ashton,
>>
>> I had the same problem and also tried your workaround. But the 
>> problem that that is really slow. To get past this I delved into te 
>> C-source code of gstat and reworked one of the C-functions to get 
>> what I wanted. This solution works much faster (few orders of 
>> magnitude).
>>
>> In order to get this working you need to reinstall gstat with one 
>> modified .c file (s.c, located in the src directory of the source 
>> version of the gstat package). I added the modified .c file as an 
>> attachment (hope that is possible on the mailing list). Once you 
>> replaced s.c you install gstat to get the new C-function available. 
>> The new C-function accepts a vector of distances as input and returns 
>> a vector of gammas. An example providing an R-wrapper function:
>>
>> getGammas = function(dist_vector, varModel, covariance = FALSE) {
>> # dist_vector is the input vector with distances
>> # varModel is the variogram model
>> # covariance is a logical to choose for semivariances (FALSE)
>> # or for covariances (TRUE)
>>   .Call("gstat_init", as.integer(0))
>>    gstat:::load.variogram.model(varModel)
>>    ret = .Call("get_covariance_list", as.integer(c(0,0)), 
>> as.integer(covariance), as.numeric(dist_vector))[[2]]
>>    .Call("gstat_exit", 0)
>>   ret   }
>> library(gstat)
>> data(meuse)
>> vgm1 <- variogram(log(zinc)~1, ~x+y, meuse)
>> m = fit.variogram(vgm1, vgm(1,"Sph",300,1))
>> getGammas(seq(1,1000, 100), varModel = m)
>>
>> It is experimental code but it works very well for me, much faster 
>> than the workaround with variogramLine. Please let me know what you 
>> think of this solution.
>>
>> cheers and hth,
>> Paul
>>
>> Ashton Shortridge wrote:
>>> I have a vector of lags for which I'd like to calculate covariances, 
>>> given a variogram (covariance) model. variogramLines() almost seems 
>>> to do this; however, it generates a table of distances and 
>>> covariances for a sequence of values between user-specified min and 
>>> max distances - the user can't pass a vector of h-values.
>>>
>>> I was hoping I could simply modify the R wrapper code for 
>>> variogramLines to do what I wished, but it seems that the relevant 
>>> code is called from elsewhere.
>>>
>>> My current workaround is to call variogramLines for each lag value, 
>>> specifying an npoints of two. For example, using a vgm object for an 
>>> omnidirectional variogram called testmod, and interested in the 
>>> covariance for a distance of 15, I run:
>>> gstat.covar <- variogramLine(testmod, 15, 2, covariance=TRUE)
>>>
>>> and then grab the second row in gstat.covar. This is tedious, and 
>>> I'm guessing a better way is out there!
>>>
>>> Thanks for any help,
>>>
>>> Ashton
>>>
>>>
>>>   
>>
>>
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> Gstat-info mailing list
>> Gstat-info at geo.uu.nl
>> http://mailman.geo.uu.nl/mailman/listinfo/gstat-info
>
> -- 
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster,
> Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
> 8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



From jgalkows at akamai.com  Mon Aug 18 23:44:52 2008
From: jgalkows at akamai.com (Galkowski, Jan)
Date: Mon, 18 Aug 2008 17:44:52 -0400
Subject: [R-sig-Geo] sm.sphere
In-Reply-To: <mailman.6.1219053603.734.r-sig-geo@stat.math.ethz.ch>
References: <mailman.6.1219053603.734.r-sig-geo@stat.math.ethz.ch>
Message-ID: <76EB4827B2104D40AE7E43AA5D8582EA038D8D19@MAVS1.kendall.corp.akamai.com>

In the sm package, the Description for sm.sphere promises "The angle of
view may be altered.", and the Value writeup says "... a list containing
the value of the smoothing parameter and the rotation angles of the
displayed plot."  Yet, if I invoke this in combinations of TRUE, FALSE
settings for "hidden" and "sphim", I get a decorated sphere, but no
controls to rotate it.

Is there something a matter with the implementation for Windows?  

Thanks,

 - Jan Galkowski
   Akamai Technologies, inc
   Cambridge, MA, USA

 



From p.hiemstra at geo.uu.nl  Tue Aug 19 00:05:41 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 19 Aug 2008 00:05:41 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48A99A1F.5080308@uni-muenster.de>
References: <48A98B8302000073000102D6@pta-emo.csir.co.za>
	<48A99A1F.5080308@uni-muenster.de>
Message-ID: <48A9F235.1090204@geo.uu.nl>

Hi,

The package Edzer was talking about, automap, can be downloaded from 
http://intamap.geo.uu.nl/~paul/Downloads.html. It makes a few practical, 
somewhat arbitrary assumptions about initial starting values.

- initial nugget is lowest semivariance found in the sample variogram
- initial sill is the mean of the maximum and the median semivariance 
value in the sample variogram
- initial range is 0.1 times the diameter of the area.

These settings work for me and, no garantee that it will work on all 
data. After installing the package try demo(automap) for a demonstration.

hth and cheers,
Paul

Edzer Pebesma schreef:
> In general: no, in special cases: yes.
>
> Fitting variograms involves non-linear regression for most models 
> (Sph, Exp, Gau, ...) for the range parameter, so you need starting 
> values. Given the initial range, linear regression is sufficient to 
> find the nugget/sill component(s), as they are linear. In principle, 
> gstat could be made simpler in that respect, I'd say.
>
> For an initial range, you could use some heuristics (20% of the 
> longest distance in your data?), but it is often not so hard to think 
> of cases where this would fail.
>
> Another issue is automatic values for the width and cutoff.
>
> You could have a look at package automap, by Paul Hiemstra, which 
> tries to do some of these heuristics--good or bad, who will tell.
> -- 
> Edzer
>
> Wesley Roberts wrote:
>> Dear r-sig-geo users,
>>
>> I am currently analyzing some Lidar data we have collected over our 
>> study area. I am interested in identifying the range of the 
>> semi-variogram as this value will determine the width of 
>> pseudo-flight lines I intend to use to sample the lidar data. Our 
>> point density is upwards of 5 points per square meter captured over 
>> even-aged managed Eucalyptus plantations with an espacement of 2 
>> meters between trees and 3 meters between rows.
>> I have imported an x,y,z data set containing canopy height and 
>> coordinates and successfully run the experimental variogram using the 
>> "variogram" module in gstat.
>> cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)
>>
>> I have also managed to fit several models using the
>> cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))
>>
>> command as suggested by the gstat manual. I would like to fit the 
>> various models "Sph, Exp..." etc without having to specify the nugget 
>> psill and range. Essentially I would like an objective method to 
>> measure and record these values as I will be running several hundred 
>> variograms. Is it possible to perform this type of analysis using gstat?
>>
>> Many thanks for all your help and suggestions
>> Wesley
>>
>> Wesley Roberts MSc.
>> Researcher
>> Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2490
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>   
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



From p.hiemstra at geo.uu.nl  Tue Aug 19 00:08:15 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 19 Aug 2008 00:08:15 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48A99A1F.5080308@uni-muenster.de>
References: <48A98B8302000073000102D6@pta-emo.csir.co.za>
	<48A99A1F.5080308@uni-muenster.de>
Message-ID: <48A9F2CF.40509@geo.uu.nl>

...in addition, any feedback on the package would be more than welcome!

Paul

Edzer Pebesma schreef:
> In general: no, in special cases: yes.
>
> Fitting variograms involves non-linear regression for most models 
> (Sph, Exp, Gau, ...) for the range parameter, so you need starting 
> values. Given the initial range, linear regression is sufficient to 
> find the nugget/sill component(s), as they are linear. In principle, 
> gstat could be made simpler in that respect, I'd say.
>
> For an initial range, you could use some heuristics (20% of the 
> longest distance in your data?), but it is often not so hard to think 
> of cases where this would fail.
>
> Another issue is automatic values for the width and cutoff.
>
> You could have a look at package automap, by Paul Hiemstra, which 
> tries to do some of these heuristics--good or bad, who will tell.
> -- 
> Edzer
>
> Wesley Roberts wrote:
>> Dear r-sig-geo users,
>>
>> I am currently analyzing some Lidar data we have collected over our 
>> study area. I am interested in identifying the range of the 
>> semi-variogram as this value will determine the width of 
>> pseudo-flight lines I intend to use to sample the lidar data. Our 
>> point density is upwards of 5 points per square meter captured over 
>> even-aged managed Eucalyptus plantations with an espacement of 2 
>> meters between trees and 3 meters between rows.
>> I have imported an x,y,z data set containing canopy height and 
>> coordinates and successfully run the experimental variogram using the 
>> "variogram" module in gstat.
>> cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)
>>
>> I have also managed to fit several models using the
>> cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))
>>
>> command as suggested by the gstat manual. I would like to fit the 
>> various models "Sph, Exp..." etc without having to specify the nugget 
>> psill and range. Essentially I would like an objective method to 
>> measure and record these values as I will be running several hundred 
>> variograms. Is it possible to perform this type of analysis using gstat?
>>
>> Many thanks for all your help and suggestions
>> Wesley
>>
>> Wesley Roberts MSc.
>> Researcher
>> Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2490
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>   
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



From Roger.Bivand at nhh.no  Tue Aug 19 09:01:21 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 19 Aug 2008 09:01:21 +0200 (CEST)
Subject: [R-sig-Geo] sm.sphere
In-Reply-To: <76EB4827B2104D40AE7E43AA5D8582EA038D8D19@MAVS1.kendall.corp.akamai.com>
References: <mailman.6.1219053603.734.r-sig-geo@stat.math.ethz.ch>
	<76EB4827B2104D40AE7E43AA5D8582EA038D8D19@MAVS1.kendall.corp.akamai.com>
Message-ID: <Pine.LNX.4.64.0808190858510.11135@reclus.nhh.no>

On Mon, 18 Aug 2008, Galkowski, Jan wrote:

> In the sm package, the Description for sm.sphere promises "The angle of
> view may be altered.", and the Value writeup says "... a list containing
> the value of the smoothing parameter and the rotation angles of the
> displayed plot."  Yet, if I invoke this in combinations of TRUE, FALSE
> settings for "hidden" and "sphim", I get a decorated sphere, but no
> controls to rotate it.
>
> Is there something a matter with the implementation for Windows?

Assuming that you run example(sm.sphere), you get the behaviour you 
describe. If you then do:

sm.sphere(lat, long, sphim=TRUE, kappa=15, panel=TRUE)

adding panel=TRUE, you should see the control panel. You didn't quote the 
command you gave, so perhaps this was what you did - I've only tried on a 
Linux platform.

Hope this helps,

Roger

>
> Thanks,
>
> - Jan Galkowski
>   Akamai Technologies, inc
>   Cambridge, MA, USA
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From wroberts at csir.co.za  Tue Aug 19 13:15:34 2008
From: wroberts at csir.co.za (Wesley Roberts)
Date: Tue, 19 Aug 2008 13:15:34 +0200
Subject: [R-sig-Geo] variogram question
Message-ID: <48AAC7770200007300010329@pta-emo.csir.co.za>

Dear Paul and the rest of the users who replied to my question,

Firstly many thanks for all your input, reading your emails this morning improved my mood exponentially. 

I have installed automap and am getting to know the program nicely, it is so easy to run it is almost unfair. I do have one question regarding the choice of models (Exp, Sph, Gau, Mat). I have experimented with each one individually as well as all models (selection based on residual sum of squares) and have found that the Matern family of models returns the lowest residual sum of squares and produces a semivariogram that models the Experimental semivariogram very well (Visually). However, the range returned by the Mat model is almost twice that of the Sph model (Mat = 6.25 m, Sph = 3,27 m). This would not ordinarily be a problem but a colleague of mine ran a similar analysis last year and returned a range of +- 3.5 meters (He was using a surface and not point data). We are working in managed Eucalyptus plantations where espacement is 2 meters between trees and 3 meters between rows indicating that a range of +- 3 meters is more likely than 6 meters. I guess this is where we get to make "informed" decisions regarding model choice based on "expert knowledge". I just want to make sure my decision is correct. 

My gut tells me go with the Mat model as it describes the semi-variance better than the rest. I am interested in quantifying the distance at which all variability is captured in the Lidar data. Am I making the correct choice?

Paul, I am not sure if I have any constructive comments, other than, a real layman was able to get automap up and running in less than 1 hour and is now making some significant progress, many thanks!

Kind regards,
Wesley

>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 08/19/08 12:32 AM >>>
...in addition, any feedback on the package would be more than welcome!

Paul

Edzer Pebesma schreef:
> In general: no, in special cases: yes.
>
> Fitting variograms involves non-linear regression for most models 
> (Sph, Exp, Gau, ...) for the range parameter, so you need starting 
> values. Given the initial range, linear regression is sufficient to 
> find the nugget/sill component(s), as they are linear. In principle, 
> gstat could be made simpler in that respect, I'd say.
>
> For an initial range, you could use some heuristics (20% of the 
> longest distance in your data?), but it is often not so hard to think 
> of cases where this would fail.
>
> Another issue is automatic values for the width and cutoff.
>
> You could have a look at package automap, by Paul Hiemstra, which 
> tries to do some of these heuristics--good or bad, who will tell.
> -- 
> Edzer
>
> Wesley Roberts wrote:
>> Dear r-sig-geo users,
>>
>> I am currently analyzing some Lidar data we have collected over our 
>> study area. I am interested in identifying the range of the 
>> semi-variogram as this value will determine the width of 
>> pseudo-flight lines I intend to use to sample the lidar data. Our 
>> point density is upwards of 5 points per square meter captured over 
>> even-aged managed Eucalyptus plantations with an espacement of 2 
>> meters between trees and 3 meters between rows.
>> I have imported an x,y,z data set containing canopy height and 
>> coordinates and successfully run the experimental variogram using the 
>> "variogram" module in gstat.
>> cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)
>>
>> I have also managed to fit several models using the
>> cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))
>>
>> command as suggested by the gstat manual. I would like to fit the 
>> various models "Sph, Exp..." etc without having to specify the nugget 
>> psill and range. Essentially I would like an objective method to 
>> measure and record these values as I will be running several hundred 
>> variograms. Is it possible to perform this type of analysis using gstat?
>>
>> Many thanks for all your help and suggestions
>> Wesley
>>
>> Wesley Roberts MSc.
>> Researcher
>> Earth Observation (Ecosystems)
>> Natural Resources and the Environment
>> CSIR
>> Tel: +27 (21) 888-2490
>> Fax: +27 (21) 888-2490
>>
>> "To know the road ahead, ask those coming back."
>> - Chinese proverb
>>
>>   
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



-- 
This message is subject to the CSIR's copyright terms and conditions, e-mail legal notice, and implemented Open Document Format (ODF) standard. 
The full disclaimer details can be found at http://www.csir.co.za/disclaimer.html.

This message has been scanned for viruses and dangerous content by MailScanner, 
and is believed to be clean.  MailScanner thanks Transtec Computers for their support.



From hunghao.chang at gmail.com  Tue Aug 19 14:19:44 2008
From: hunghao.chang at gmail.com (Hung-Hao Chang)
Date: Tue, 19 Aug 2008 20:19:44 +0800
Subject: [R-sig-Geo] Limited dependent variable in R
Message-ID: <969fee680808190519j6d6ee08cx41cc9a6277b4f9dc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080819/de364ddb/attachment.pl>

From christian.salas at yale.edu  Tue Aug 19 17:30:05 2008
From: christian.salas at yale.edu (Christian Salas)
Date: Tue, 19 Aug 2008 11:30:05 -0400
Subject: [R-sig-Geo] a simple correlogram
Message-ID: <48AAE6FD.3050003@yale.edu>

hi there,

Sorry if this is too simple and silly.

I just want to produce a correlogram using the following example, x and 
y coord. are measured in m (i know that does not matter now, but keep 
reading). I already have checked the sp.correlogram(), correlog(), and 
similar functions in different packages (spdep, ncf) , but none of them 
do what i want, which is very simple.

   x        y       z
111.03    10.7       7
118.11    0.28     1.2
165.36    0.36     8.4
   282.9     0.3     7.5
303.29   13.32    12.2
319.28    3.88     6.2
     447       9       6
   445.5    18.3    13.8
   445.5    12.1     7.1
467.64     1.2     4.7
   485.4    14.1     4.4
    2.98   23.95    11.7
      15   35.78    23.5
130.21    23.6    14.1
   213.5   23.22    21.5
233.57   28.76    35.4
   482.3    20.5       6
   69.73   45.21     7.5
    69.8   50.49    10.2
   76.65    45.5    21.5

t1 <- read.table("datann.txt", header=TRUE)
head(t1)
plot(t1$x,t1$y)

I do only want the correlation to be computed by grouping the distances 
between all pairs of trees into 1m classes, and then being able to save 
that and plot the correlation (r) versus distance, very plain :)

i know that i could do a loop, and compute things, but i wonder if there 
are something already prepared, or at least to select points within a 
certain range of distance.

thanks for your help

c
-- 
-------------------------------------------------------------------------------
Christian Salas                     E-mail:christian.salas at yale.edu
PhD student                         http://environment.yale.edu/salas
School of Forestry and Environmental Studies
Yale University                     Tel: +1-(203)-432 5126
360 Prospect St                     Fax:+1-(203)-432 3809
New Haven, CT 06511-2189            Office: Room 35, Marsh Hall
USA

Yale Biometrics Lab                  http://environment.yale.edu/biometrics



From murray.richardson at utoronto.ca  Tue Aug 19 21:43:09 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Tue, 19 Aug 2008 15:43:09 -0400
Subject: [R-sig-Geo] add,
	delete columns in spatial data frame data slot before spRbind
Message-ID: <48AB224D.9060804@utoronto.ca>

Hello again users,

I'm having trouble figuring out how to format the data slot in spatial 
SpatialPolygonsDataFrames.  I need to use spRbind to combine polygons 
from different shapefiles but encounter the problem of having different 
numbers of columns, and also non-unique IDs.  If the polygons come from 
different shapefile sources and have different columns in the dbf, what 
is the best way to format them to use spRbind?

Can't seem to find some info on this.

Thanks for any help.

Murray



From Roger.Bivand at nhh.no  Tue Aug 19 22:00:29 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 19 Aug 2008 22:00:29 +0200 (CEST)
Subject: [R-sig-Geo] add,
 delete columns in spatial data frame data slot before spRbind
In-Reply-To: <48AB224D.9060804@utoronto.ca>
References: <48AB224D.9060804@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0808192156080.12941@reclus.nhh.no>

On Tue, 19 Aug 2008, Murray Richardson wrote:

> Hello again users,
>
> I'm having trouble figuring out how to format the data slot in spatial 
> SpatialPolygonsDataFrames.  I need to use spRbind to combine polygons from 
> different shapefiles but encounter the problem of having different numbers of 
> columns, and also non-unique IDs.  If the polygons come from different 
> shapefile sources and have different columns in the dbf, what is the best way 
> to format them to use spRbind?
>
> Can't seem to find some info on this.

See rbind for data frames - it cannot be done by design. The columns of 
the data frames to be stacked must have the same names and types of data 
for the same names. If they differ, you'll have to create a combined data 
frame with NAs and copy across. In addition, you must have unique IDs, so 
perhaps start there, insert the relevant IDs into the combined data frame, 
and rebuild the whole object. Probably you should drop as many columns 
from your input data as possible to reduce the work to be done.

Roger

>
> Thanks for any help.
>
> Murray
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From p.hiemstra at geo.uu.nl  Wed Aug 20 09:43:38 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 20 Aug 2008 09:43:38 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48AAC7770200007300010329@pta-emo.csir.co.za>
References: <48AAC7770200007300010329@pta-emo.csir.co.za>
Message-ID: <48ABCB2A.5080802@geo.uu.nl>

Hi Wesley,

Good to know that the package helped you.

A note the choice between the different variogram models. At this stage 
I do this by computing the sums of squares between the model and the 
sample variogram and choose the one with the smallest SS. This is a 
rather crude way of selecting between the models. But my package is 
about automatic interpolation and this makes it more automatic. I would 
like to invest some time in improving this part of automap.

cheers,
Paul

Wesley Roberts wrote:
> Dear Paul and the rest of the users who replied to my question,
>
> Firstly many thanks for all your input, reading your emails this morning improved my mood exponentially. 
>
> I have installed automap and am getting to know the program nicely, it is so easy to run it is almost unfair. I do have one question regarding the choice of models (Exp, Sph, Gau, Mat). I have experimented with each one individually as well as all models (selection based on residual sum of squares) and have found that the Matern family of models returns the lowest residual sum of squares and produces a semivariogram that models the Experimental semivariogram very well (Visually). However, the range returned by the Mat model is almost twice that of the Sph model (Mat = 6.25 m, Sph = 3,27 m). This would not ordinarily be a problem but a colleague of mine ran a similar analysis last year and returned a range of +- 3.5 meters (He was using a surface and not point data). We are working in managed Eucalyptus plantations where espacement is 2 meters between trees and 3 meters between rows indicating that a range of +- 3 meters is more likely than 6 meters. I guess this is where we get to make "informed" decisions regarding model choice based on "expert knowledge". I just want to make sure my decision is correct. 
>
> My gut tells me go with the Mat model as it describes the semi-variance better than the rest. I am interested in quantifying the distance at which all variability is captured in the Lidar data. Am I making the correct choice?
>
> Paul, I am not sure if I have any constructive comments, other than, a real layman was able to get automap up and running in less than 1 hour and is now making some significant progress, many thanks!
>
> Kind regards,
> Wesley
>
>   
>>>> Paul Hiemstra <p.hiemstra at geo.uu.nl> 08/19/08 12:32 AM >>>
>>>>         
> ...in addition, any feedback on the package would be more than welcome!
>
> Paul
>
> Edzer Pebesma schreef:
>   
>> In general: no, in special cases: yes.
>>
>> Fitting variograms involves non-linear regression for most models 
>> (Sph, Exp, Gau, ...) for the range parameter, so you need starting 
>> values. Given the initial range, linear regression is sufficient to 
>> find the nugget/sill component(s), as they are linear. In principle, 
>> gstat could be made simpler in that respect, I'd say.
>>
>> For an initial range, you could use some heuristics (20% of the 
>> longest distance in your data?), but it is often not so hard to think 
>> of cases where this would fail.
>>
>> Another issue is automatic values for the width and cutoff.
>>
>> You could have a look at package automap, by Paul Hiemstra, which 
>> tries to do some of these heuristics--good or bad, who will tell.
>> -- 
>> Edzer
>>
>> Wesley Roberts wrote:
>>     
>>> Dear r-sig-geo users,
>>>
>>> I am currently analyzing some Lidar data we have collected over our 
>>> study area. I am interested in identifying the range of the 
>>> semi-variogram as this value will determine the width of 
>>> pseudo-flight lines I intend to use to sample the lidar data. Our 
>>> point density is upwards of 5 points per square meter captured over 
>>> even-aged managed Eucalyptus plantations with an espacement of 2 
>>> meters between trees and 3 meters between rows.
>>> I have imported an x,y,z data set containing canopy height and 
>>> coordinates and successfully run the experimental variogram using the 
>>> "variogram" module in gstat.
>>> cpy.pts2 <- variogram(dbl_5 ~ 1, cutoff=50, width=2, D)
>>>
>>> I have also managed to fit several models using the
>>> cpy.pts2.fit <- fit.variogram(cpy.pts2, model = vgm(2, "Sph", 4, 5))
>>>
>>> command as suggested by the gstat manual. I would like to fit the 
>>> various models "Sph, Exp..." etc without having to specify the nugget 
>>> psill and range. Essentially I would like an objective method to 
>>> measure and record these values as I will be running several hundred 
>>> variograms. Is it possible to perform this type of analysis using gstat?
>>>
>>> Many thanks for all your help and suggestions
>>> Wesley
>>>
>>> Wesley Roberts MSc.
>>> Researcher
>>> Earth Observation (Ecosystems)
>>> Natural Resources and the Environment
>>> CSIR
>>> Tel: +27 (21) 888-2490
>>> Fax: +27 (21) 888-2490
>>>
>>> "To know the road ahead, ask those coming back."
>>> - Chinese proverb
>>>
>>>   
>>>       
>
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone: 	+31302535773
Fax:	+31302531145
http://intamap.geo.uu.nl/~paul



From giohappy at gmail.com  Wed Aug 20 18:27:17 2008
From: giohappy at gmail.com (G. Allegri)
Date: Wed, 20 Aug 2008 18:27:17 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48ABCB2A.5080802@geo.uu.nl>
References: <48AAC7770200007300010329@pta-emo.csir.co.za>
	<48ABCB2A.5080802@geo.uu.nl>
Message-ID: <e12429640808200927y4d1a624fqbef11604e1c4620e@mail.gmail.com>

> At this stage I do
> this by computing the sums of squares between the model and the sample
> variogram and choose the one with the smallest SS. This is a rather crude
> way of selecting between the models.

Thanks Paul for automap. I'm planning to try it in the next occasion.
What are the major drawbacks in using simply SS in model selection? I
mean, I know there are lot of more sofiticated methods, but is this
good for some situation, or is in general a poor selection method?

thanks,
Giovanni



From fieldsh at mail.med.upenn.edu  Wed Aug 20 20:44:00 2008
From: fieldsh at mail.med.upenn.edu (Samuel Field)
Date: Wed, 20 Aug 2008 14:44:00 -0400 (EDT)
Subject: [R-sig-Geo] Spatial Error Model - ANOVA table
In-Reply-To: <550873422.1432851219257418752.JavaMail.root@zm-mbx-modv.zimbra.upenn.edu>
Message-ID: <1133611150.1437261219257840505.JavaMail.root@zm-mbx-modv.zimbra.upenn.edu>

List,

Is it possible to decompose the variance of an outcome into trend, signal and noise components using a SAR model - analogous to what one would get with an OLS model? This doesn't seem to be straight forward. With OLS, we decompose Y into two non-overlapping components

Y = fit + error

R-square is based on the idea that the total sum of squares of y is partition neatly into two quantities - sum of square model and sum of square error.  


With the spatial error model Y is broken up into three components

Y = trend + signal + noise  


where trend = Xbeta
      signal = labmdaWy - lambdaWXbeta
      noise = Y - (trend + signal)

You would think that the total sum of square would also fit neatly into these three buckets, in which case you could easily calcluate the proportion of the total sum of squares contributed by each.  However, I have not found this to be the case.   The sum of squares from each of the three components do not add up to the total sum of squares of Y.  Possibly becase the signal component involves an infinite expansion when you substitue Y into lambdaWYy

Y = Xbeta + lambda(Xbeta + labmda(Xbeta + lambda(..) - labmdaWXbeta + u) - lambdaWXbeta + u) - labmdaWXbeta + u.


I know that the predict.errorsarlm() function uses the obeserved Y vector in its calculation of signal, but why doesn't the sum of squares (i.e. sum((signal - mean(Y))^2), sum((u^2)), and sum((XB - mean(Y))^2) add up to the total sum of squares? (i.e. sum((Y - mean(Y))?


Any help would be greatly appreciated.  Here is some example code in case that is helpful.  Please note that the example below does not "isolate" the signal component, but combines it with the trend component.


#creating data
library(spdep)

#sample size
n <- 200

#coordinates

x_coord <- runif(n,0,10)
y_coord <- runif(n,0,10)


## w matrix and row normalized

w_raw <- matrix(nrow=length(x_coord),ncol=length(x_coord),1)

for(i in 1:length(x_coord)){for(j in 1:length(x_coord)) 
{w_raw[i,j]<- 1/(sqrt((x_coord[i]-x_coord[j])^2 + (y_coord[i]-y_coord[j])^2))^2}}


diag(w_raw) <- rep(0,n)


row_sum <- rep(1,length(x_coord))
for(i in 1:length(x_coord))  
        {row_sum[i] <- sum(w_raw[i,]) }

w <- matrix(nrow=length(x_coord),ncol=length(x_coord),1)

for(i in 1:length(x_coord)){for(j in 1:length(x_coord)) 
        {w[i,j] <- w_raw[i,j]/row_sum[i]}}

x <- rbinom(n,1,.5)
                     
parms <- c(12.4,2)
w.listw <- mat2listw(w)

e <- rnorm(n,0,1)
p <- .6

y <- parms[1] + parms[2]*x + (solve(diag(n)- p*w))%*%e 

sim.data <- as.data.frame(cbind(y,x))
names(sim.data) <- c("y","x")
error.mod <- errorsarlm(y~x,data = sim.data,w.listw)

summary(error.mod)

X <- as.matrix(cbind(rep(1,length(sim.data$y)),sim.data$x))


trend <- X%*%coef(error.mod)[-1]
signal <-  error.mod$lambda*w%*%sim.data$y - error.mod$lambda*w%*%X%*%coef(error.mod)[-1]
fit <- trend + signal
error <-  sim.data$y - fit


SST <- sum((sim.data$y - mean(sim.data$y))^2)
SSE <- sum(error^2)
SSM <- sum(((trend + signal)- mean(sim.data$y))^2)


SSE + SSM
SST


Samuel H. Field, Ph.D.
Philadelphia VA Medical Center



From friendly at yorku.ca  Wed Aug 20 21:24:06 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 20 Aug 2008 15:24:06 -0400
Subject: [R-sig-Geo] merging a data.frame with a map
Message-ID: <48AC6F56.8050109@yorku.ca>

This may be a simple question, but I'm a newbie with the maptools and sp 
packages.
I have a set of shapefiles for Ontario "Forward sortation areas", the 
first 3 characters
of the postal code (FSA), that I can subset to give a map of Toronto. 
[My cudos to
the team that put maptools and sp together! This part is a lot more 
straight-forward
than when I last looked.]

I have other data attributes
for these areas in a separate file, that I'd like to display on the map, 
but I don't know
how to merge this with the map object.  I'm not sure if this matters, 
but to display the
map in Toronto-centric terms, I also have to rotate it slightly so that 
the conventional
northern boundary line is horizontal. I used elide() for this, all I 
could find in the help/examples
for rotation.
In the end, I'd like to write out a new shapefile
containing the rotated coordinates together with the data attributes 
from my data file.
I show the steps I've done so far below.

# using readShapeSpatial

 > ontario 
<-readShapeSpatial("ForwardSortationAreas_JUL07_ON_region.shp", 
IDvar="FSA", proj4string=CRS("+proj=longlat +datum=NAD83") )
 > toronto <- ontario[ontario$F=="M",]
 > summary(toronto)
Object of class SpatialPolygonsDataFrame
Coordinates:
   min max
r1 -80 -79
r2  44  44
Is projected: FALSE
proj4string : [+proj=longlat +datum=NAD83]
Data attributes:
      FSA            FSA_NAME  F        PR    
 M1B    : 1   TORONTO    :48   K:  0   35:102 
 M1C    : 1   NORTH YORK :22   L:  0          
 M1E    : 1   SCARBOROUGH:17   M:102          
 M1G    : 1   ETOBICOKE  :12   N:  0          
 M1H    : 1   EAST YORK  : 3   P:  0          
 M1J    : 1   ACTON      : 0                  
 (Other):96   (Other)    : 0                  
 >

# plot with spplot, rotate so Steeles Ave. is horizontal
torontoR <- elide(toronto, rotate=12.7)
spplot(torontoR, zcol="FSA", colorkey=FALSE)

In the associated data file, the first column is FSA.  I've used that as 
the rownames attribute,
but I could just use it as a separate column if that makes it easier to 
merge with the map

 > # read the attribute file
 > crime <- read.csv("Provincial-edited.csv", row.names=1)
 > crime[,9:12] <- crime[,9:12]*100
 > # Toronto subset
 > crimeTO <- crime[substr(rownames(crime),1,1)=="M",]
 > str(crimeTO)
'data.frame':   102 obs. of  13 variables:
$ Area                      : Factor w/ 209 levels "Acton","Ajax",..: 
166 166 166 166 166 166 166 166 166 166 ...
$ Total.Jail.Cost           : int  159807 69755 284576 164400 24035 
86526 269514 140899 138122 119962 ...
$ Ontario.Rank              : int  107 239 37 104 340 204 40 123 129 147 
...
$ Number.of.Inmates         : int  10 2 11 5 3 7 13 6 3 3 ...
$ Inmates.per.10K           : num  1.6 0.6 2.4 1.8 1.4 2 2.8 2.2 1.4 1.4 
...
$ Total.Days.Sentenced      : int  1496 653 2664 1539 225 810 2523 1319 
1293 1123 ...
$ Population                : int  64632 35695 46757 28458 23511 35005 
47224 27825 22138 21122 ...
$ Median.Household.Income   : int  65479 91372 58015 45150 51433 48425 
46191 44522 59426 58962 ...
$ Low.Income                : num  17 7 21 30 23 29 27 29 19 16 ...
$ Unemployed                : num  5 3 6 9 6 8 7 7 5 5 ...
$ Completed.University      : num  17 26 18 15 23 15 13 20 20 22 ...
$ Single.Female.Parent.Homes: num  20 12 21 20 16 22 22 21 18 16 ...
$ Public.Housing.Units      : int  496 NA 1226 521 149 173 743 685 295 
124 ...
 >
 > head(crimeTO)
          Area Total.Jail.Cost Ontario.Rank Number.of.Inmates 
Inmates.per.10K Total.Days.Sentenced Population
M1B Scarborough          159807          107                
10             1.6                 1496      64632
M1C Scarborough           69755          239                 
2             0.6                  653      35695
M1E Scarborough          284576           37                
11             2.4                 2664      46757
M1G Scarborough          164400          104                 
5             1.8                 1539      28458
M1H Scarborough           24035          340                 
3             1.4                  225      23511
M1J Scarborough           86526          204                 
7             2.0                  810      35005
   Median.Household.Income Low.Income Unemployed Completed.University 
Single.Female.Parent.Homes
M1B                   65479         17          5                   
17                         20
M1C                   91372          7          3                   
26                         12
M1E                   58015         21          6                   
18                         21
M1G                   45150         30          9                   
15                         20
M1H                   51433         23          6                   
23                         16
M1J                   48425         29          8                   
15                         22
   Public.Housing.Units
M1B                  496
M1C                   NA
M1E                 1226
M1G                  521
M1H                  149
M1J                  173
 >

So, I now want to merge torontoR with crimeTO using FSA (or 
rownames(crimeTO)) as the area ID
and write new files so I can avoid doing these steps in future.

Can someone help?

-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From Roger.Bivand at nhh.no  Wed Aug 20 22:13:13 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 20 Aug 2008 22:13:13 +0200 (CEST)
Subject: [R-sig-Geo] merging a data.frame with a map
In-Reply-To: <48AC6F56.8050109@yorku.ca>
References: <48AC6F56.8050109@yorku.ca>
Message-ID: <Pine.LNX.4.64.0808202148370.17549@reclus.nhh.no>

On Wed, 20 Aug 2008, Michael Friendly wrote:

> This may be a simple question, but I'm a newbie with the maptools and sp 
> packages. I have a set of shapefiles for Ontario "Forward sortation 
> areas", the first 3 characters of the postal code (FSA), that I can 
> subset to give a map of Toronto. [My cudos to the team that put maptools 
> and sp together! This part is a lot more straight-forward than when I 
> last looked.]
>
> I have other data attributes for these areas in a separate file, that 
> I'd like to display on the map, but I don't know how to merge this with 
> the map object.  I'm not sure if this matters, but to display the map in 
> Toronto-centric terms, I also have to rotate it slightly so that the 
> conventional northern boundary line is horizontal. I used elide() for 
> this, all I could find in the help/examples for rotation. In the end, 
> I'd like to write out a new shapefile containing the rotated coordinates 
> together with the data attributes from my data file. I show the steps 
> I've done so far below.
>
> # using readShapeSpatial
>
>>  ontario 
> <-readShapeSpatial("ForwardSortationAreas_JUL07_ON_region.shp", IDvar="FSA", 
> proj4string=CRS("+proj=longlat +datum=NAD83") )
>>  toronto <- ontario[ontario$F=="M",]
>>  summary(toronto)
> Object of class SpatialPolygonsDataFrame
> Coordinates:
>  min max
> r1 -80 -79
> r2  44  44
> Is projected: FALSE
> proj4string : [+proj=longlat +datum=NAD83]
> Data attributes:
>      FSA            FSA_NAME  F        PR    M1B    : 1   TORONTO    :48 
> K:  0   35:102 M1C    : 1   NORTH YORK :22   L:  0          M1E    : 1 
> SCARBOROUGH:17   M:102          M1G    : 1   ETOBICOKE  :12   N:  0 
> M1H    : 1   EAST YORK  : 3   P:  0          M1J    : 1   ACTON      : 0 
> (Other):96   (Other)    : 0 
>> 
>
> # plot with spplot, rotate so Steeles Ave. is horizontal
> torontoR <- elide(toronto, rotate=12.7)
> spplot(torontoR, zcol="FSA", colorkey=FALSE)
>
> In the associated data file, the first column is FSA.  I've used that as 
> the rownames attribute, but I could just use it as a separate column if 
> that makes it easier to merge with the map

Have a look at ?"spCbind-methods" in maptools. That should "quasi-cbind" 
the SpatialPolygonsDataFrame torontoR with the data frame crimeTO, if the 
row names of crimeTO and the Polygons ID slots of torontoR match exactly. 
If they don't match, it won't know how to align the geometries and the 
data frame rows.

Try:

tor_ID <- sapply(slot(torontoR, "polygons"), function(x) slot(x, "ID"))
cri_ID <- row.names(crimeTO)
length(tor_ID)
length(cri_ID)
mm <- match(tor_ID, cri_ID)
length(mm)
any(is.na(mm))
all.equal(sort(tor_ID), sort(cri_ID))

The row order of crimeTO is arbitrary (if I remember correctly), but the 
match must be exact. If your geometries and the data in the csv file are 
from the same period (same FSA keys), it ought to be OK. In other 
jurisdictions, one does see counties or municipalities merging or 
splitting as geometries over time (new FIPS entering, old ones being 
retired), hence the stress on exact matching. Many data collection 
services now grasp why changing aggregations over time should be avoided 
if possible, fortunately, though obviously other concerns (like falling 
population) must also be accommodated.

So, if the IDs look OK:

torontoR2 <- spCbind(torontoR, crimeTO)
spplot(torontoR2, "Inmates.per.10K")
writeSpatialShape(torontoR2, "RotatedToronto")

(untried, but it shouldn't be too far from the mark).

Hope this helps,

Roger

PS: in the fullness of time, and following an innovation in S4 methods 
made last week in R's development version, the oddish spCbind and spRbind 
methods may become just regular cbind and rbind, but not quite yet ...

>
>>  # read the attribute file
>>  crime <- read.csv("Provincial-edited.csv", row.names=1)
>>  crime[,9:12] <- crime[,9:12]*100
>>  # Toronto subset
>>  crimeTO <- crime[substr(rownames(crime),1,1)=="M",]
>>  str(crimeTO)
> 'data.frame':   102 obs. of  13 variables:
> $ Area                      : Factor w/ 209 levels "Acton","Ajax",..: 166 166 
> 166 166 166 166 166 166 166 166 ...
> $ Total.Jail.Cost           : int  159807 69755 284576 164400 24035 86526 
> 269514 140899 138122 119962 ...
> $ Ontario.Rank              : int  107 239 37 104 340 204 40 123 129 147 ...
> $ Number.of.Inmates         : int  10 2 11 5 3 7 13 6 3 3 ...
> $ Inmates.per.10K           : num  1.6 0.6 2.4 1.8 1.4 2 2.8 2.2 1.4 1.4 ...
> $ Total.Days.Sentenced      : int  1496 653 2664 1539 225 810 2523 1319 1293 
> 1123 ...
> $ Population                : int  64632 35695 46757 28458 23511 35005 47224 
> 27825 22138 21122 ...
> $ Median.Household.Income   : int  65479 91372 58015 45150 51433 48425 46191 
> 44522 59426 58962 ...
> $ Low.Income                : num  17 7 21 30 23 29 27 29 19 16 ...
> $ Unemployed                : num  5 3 6 9 6 8 7 7 5 5 ...
> $ Completed.University      : num  17 26 18 15 23 15 13 20 20 22 ...
> $ Single.Female.Parent.Homes: num  20 12 21 20 16 22 22 21 18 16 ...
> $ Public.Housing.Units      : int  496 NA 1226 521 149 173 743 685 295 124 
> ...
>>
>>  head(crimeTO)
>         Area Total.Jail.Cost Ontario.Rank Number.of.Inmates Inmates.per.10K 
> Total.Days.Sentenced Population
> M1B Scarborough          159807          107                10 
> 1.6                 1496      64632
> M1C Scarborough           69755          239                 2 
> 0.6                  653      35695
> M1E Scarborough          284576           37                11 
> 2.4                 2664      46757
> M1G Scarborough          164400          104                 5 
> 1.8                 1539      28458
> M1H Scarborough           24035          340                 3 
> 1.4                  225      23511
> M1J Scarborough           86526          204                 7 
> 2.0                  810      35005
>  Median.Household.Income Low.Income Unemployed Completed.University 
> Single.Female.Parent.Homes
> M1B                   65479         17          5                   17 
> 20
> M1C                   91372          7          3                   26 
> 12
> M1E                   58015         21          6                   18 
> 21
> M1G                   45150         30          9                   15 
> 20
> M1H                   51433         23          6                   23 
> 16
> M1J                   48425         29          8                   15 
> 22
>  Public.Housing.Units
> M1B                  496
> M1C                   NA
> M1E                 1226
> M1G                  521
> M1H                  149
> M1J                  173
>> 
>
> So, I now want to merge torontoR with crimeTO using FSA (or 
> rownames(crimeTO)) as the area ID and write new files so I can avoid 
> doing these steps in future.
>
> Can someone help?
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From p.hiemstra at geo.uu.nl  Wed Aug 20 23:15:23 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 20 Aug 2008 23:15:23 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <e12429640808200927y4d1a624fqbef11604e1c4620e@mail.gmail.com>
References: <48AAC7770200007300010329@pta-emo.csir.co.za>	
	<48ABCB2A.5080802@geo.uu.nl>
	<e12429640808200927y4d1a624fqbef11604e1c4620e@mail.gmail.com>
Message-ID: <48AC896B.3000409@geo.uu.nl>

Hi,

There will certainly be situations when the SS method will select an 
appropriate model. But there are also situations when it will not make a 
well thought over decision. For example if there is not a lot of data on 
short range variability the SS method will not be able to fit the model 
that shows the appropriate short range behaviour.

You spoke of more sophisticated methods of automatically choosing 
between models, what kind of methods did you have in mind?

cheers,
Paul

G. Allegri schreef:
>> At this stage I do
>> this by computing the sums of squares between the model and the sample
>> variogram and choose the one with the smallest SS. This is a rather crude
>> way of selecting between the models.
>>     
>
> Thanks Paul for automap. I'm planning to try it in the next occasion.
> What are the major drawbacks in using simply SS in model selection? I
> mean, I know there are lot of more sofiticated methods, but is this
> good for some situation, or is in general a poor selection method?
>
> thanks,
> Giovanni
>



From giohappy at gmail.com  Thu Aug 21 00:09:12 2008
From: giohappy at gmail.com (G. Allegri)
Date: Thu, 21 Aug 2008 00:09:12 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <48AC896B.3000409@geo.uu.nl>
References: <48AAC7770200007300010329@pta-emo.csir.co.za>
	<48ABCB2A.5080802@geo.uu.nl>
	<e12429640808200927y4d1a624fqbef11604e1c4620e@mail.gmail.com>
	<48AC896B.3000409@geo.uu.nl>
Message-ID: <e12429640808201509r8ae7329i81788cb71abbe493@mail.gmail.com>

> You spoke of more sophisticated methods of automatically choosing between models, what kind of methods did you have in mind?

Here's a list I gathered some time ago. Many of them are just buzzwords form me!

? Adjusted R-squared (Wherry 1931)
? Bootstrap (Efron 1979)
? Cross-validation (Stone 1974; Geisser 1975)
    ? Generalized cross-validation (GCV) (Craven and Wahba 1979)
    ? k-fold cross-validation
    ? Leave-one-out cross-validation
? Jacknife
? Linear regression
? Shibata's model selector (sms) (Shibata 1981)
? Signal-to-noise ratio
? Test set validation
? Akaike information criterion (AIC)
   ? AIC (Akaike 1973)
   ? AICc (Hurvich and Tsai 1989)
   ? QAIC (Lebreton, et al. 1992)
   ? QAICc (Lebreton, et al. 1992)
   ? AICW (Wilks 1995)
? CAT (Parzen 1974, 1977)
? CP (Mallow's Cp) (Mallows 1973)
? Deviance information criterion (DIC) (Spiegelhalter, et al. 2002)
? FIC (Wei 1992)
? Final prediction error (FPE) (Akaike 1969)
? FPE? (Bhansali and Downham 1977)
? FPEC (de Luna 1998)
? FPER (Larsen and Hansen 1994)
? GM (Geweke and Meese 1981)
? Generalized prediction error (GPE) (Moody 1991, 1992)
? Hannan and Quinn Criterion (HQ) (Hannan and Quinn 1979)
? KIC (Cavanaugh 1999)
? KICc (Cavanaugh 2004)
? Minimum description length (MDL) (Rissanen 1978)
? Minimum message length (MML) (Wallace and Boulton 1968)
? Predicted squared error (PSE) (Barron 1984)
? PRESS (Allen 1974)
? Schwarz criterion (also Schwarz information criterion (SIC) or
Bayesian information criterion (BIC) or Schwarz-Bayesian information
criterion) (Schwarz 1978)
? Structural risk minimization (SRM) (Vapnik and Chervonenkis 1974)
? TIC (Takeuchi's information criterion) (Takeuchi 1976)
? VC-dimension (Vapnik and Chervonekis 1968, 1971; Vapnik 1979)

From massimo.ventrucci at unibo.it  Thu Aug 21 00:19:29 2008
From: massimo.ventrucci at unibo.it (Massimo Ventrucci)
Date: Thu, 21 Aug 2008 00:19:29 +0200
Subject: [R-sig-Geo] plot a variable in a SpatialPolygons object
Message-ID: <2023742A9DC9514DAC068ABFE73E9E6F11E09A@EXBK03.personale.dir.unibo.it>

Roger,
sorry if I reply so late to your, instead, really quick suggestion at my problem,
actually I revised the question and I am not yet able to do that plot. I try to explain clearly my problem. 
 
I need to plot a map, for instance, in the same way I can plot it with winbugs from the mapping tool menu. So I need to plot a value for each region of my map and to colour regions characterized by higher values. I have the map in a Spatial Polygons object, I do not have it in shape file unfortunately. So I am working with package "sp". Moreover I can not use the spplot because I do not have a SpatialPolygonsDataFrame object, just a SpatialPolygons. In other words I do not have a value for each x-y coords, but I would need a value for each region, hence for each polygon belonging to the list of polygons. 
 
 
Please, any suggestion about which is the easiest way to do it, if any? 
Thank you very much in advance
- massimo
 
Massimo Ventrucci
Ph.D Student in Statistics
Dipartimento di Scienze Statistiche
Universit? degli studi di Bologna
Via Belle Arti 41
40126 Bologna-Italy
_____________________________________

Phone +39(051)264182 (office)
Fax     +39(051)232153
E-mail massimo.ventrucci at unibo.it

On Mon, 28 Jul 2008, Massimo Ventrucci wrote:

> Dear all,

> sorry my question seems to me quite basic and perhaps is already posted 
> but at a first sight I did not find it. Basically I have a map of 
> contiguous areas in the form of a SpatialPolygons object. In all areas I 
> need to display the value of a binary value (e.g. to color the areas 
> corresponding to value 1). I have to say in a guide to the package 
> "spdep" I found the code to do a map (it was a map of probabilities 
> buillt by using plot coomand after having used probmap command), but in 
> that case the plot is done starting from an object of class polylist if 
> I say well. Instead I need to do a plot starting from a SpatialPolygons 
> object because I do not have the map in other formats.

I'm planning to update the now very obsolete vignette in spdep soon. The 
easiest way to plot a variable from a SpatialPolygonsDataFrame object is 
the spplot method in the sp package (which spdep loads). Just try:

spplot(my_SpolDF, "myvar")

for a first cut.

Base graphics methods, such as plot(), are also available. The best online 
guide may be one of the units at:

http://www.bias-project.org.uk/ASDARcourse/

either "Vizualising Spatial Data" for the description, or your choice of 
the worked examples. There are also code examples and figures on the ASDAR 
book website: www.asdar-book.org; though this is still under construction, 
most things are there.

Roger

>
> Moreover, in future I will also need to plot values graduated by colors.
>
> Please, can you help me?
> thanks in advance
> massimo
>
> Massimo Ventrucci
> Ph.D Student in Statistics
> Dipartimento di Scienze Statistiche
> Universit? degli studi di Bologna
> Via Belle Arti 41
> 40126 Bologna-Italy
> _____________________________________
>
> Phone +39(051)264182 (office)
> Fax     +39(051)232153
> E-mail massimo.ventrucci at unibo.it <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> 



From Roger.Bivand at nhh.no  Thu Aug 21 08:41:00 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 Aug 2008 08:41:00 +0200 (CEST)
Subject: [R-sig-Geo] plot a variable in a SpatialPolygons object
In-Reply-To: <2023742A9DC9514DAC068ABFE73E9E6F11E09A@EXBK03.personale.dir.unibo.it>
References: <2023742A9DC9514DAC068ABFE73E9E6F11E09A@EXBK03.personale.dir.unibo.it>
Message-ID: <Pine.LNX.4.64.0808210827400.19605@reclus.nhh.no>

On Thu, 21 Aug 2008, Massimo Ventrucci wrote:

> Roger,

> sorry if I reply so late to your, instead, really quick suggestion at my 
> problem, actually I revised the question and I am not yet able to do 
> that plot. I try to explain clearly my problem.
>
> I need to plot a map, for instance, in the same way I can plot it with 
> winbugs from the mapping tool menu. So I need to plot a value for each 
> region of my map and to colour regions characterized by higher values. I 
> have the map in a Spatial Polygons object, I do not have it in shape 
> file unfortunately. So I am working with package "sp". Moreover I can 
> not use the spplot because I do not have a SpatialPolygonsDataFrame 
> object, just a SpatialPolygons. In other words I do not have a value for 
> each x-y coords, but I would need a value for each region, hence for 
> each polygon belonging to the list of polygons.

Say SP is your SpatialPolygons object, and var is a numeric vector. Is

length(var) == length(slot(SP, "polygons"))

Are the values in var ordered in the same order as the polygons in SP? If 
so, you may define the class interval break points and a colour palette as 
say:

brks <- quantiles(var, seq(0, 1, 1/7))
cols <- grey.colors(length(brks)-1, 0.4, 0.9)
plot(SP, col=cols[findInterval(var, brks, all.inside=TRUE))

If the lengths agree, but the order doesn't, look at and identify the ID 
values in the SpatialPolygons object:

IDs <- sapply(slot(SP, "polygons"), function(x) slot(x, "ID"))
plot(SP)
text(coordinates(SP), labels=IDs, cex=0.7)

Next add the matching IDs values to the values in var as a vector of 
names, and:

names(var) <- IDs_in_correct_order
SPDF <- SpataialPolygonsDataFrame(SP, as.data.frame(var)))

to make a SpatialPolygonsDataFrame. Then you can either:

spplot(SPDF, "var")

or

plot(SPDF, col=cols[findInterval(SPDF$var, brks, all.inside=TRUE))

(untried but should work).

Hope this helps,

Roger

>
>
> Please, any suggestion about which is the easiest way to do it, if any?
> Thank you very much in advance
> - massimo
>
> Massimo Ventrucci
> Ph.D Student in Statistics
> Dipartimento di Scienze Statistiche
> Universit? degli studi di Bologna
> Via Belle Arti 41
> 40126 Bologna-Italy
> _____________________________________
>
> Phone +39(051)264182 (office)
> Fax     +39(051)232153
> E-mail massimo.ventrucci at unibo.it
>
> On Mon, 28 Jul 2008, Massimo Ventrucci wrote:
>
>> Dear all,
>
>> sorry my question seems to me quite basic and perhaps is already posted
>> but at a first sight I did not find it. Basically I have a map of
>> contiguous areas in the form of a SpatialPolygons object. In all areas I
>> need to display the value of a binary value (e.g. to color the areas
>> corresponding to value 1). I have to say in a guide to the package
>> "spdep" I found the code to do a map (it was a map of probabilities
>> buillt by using plot coomand after having used probmap command), but in
>> that case the plot is done starting from an object of class polylist if
>> I say well. Instead I need to do a plot starting from a SpatialPolygons
>> object because I do not have the map in other formats.
>
> I'm planning to update the now very obsolete vignette in spdep soon. The
> easiest way to plot a variable from a SpatialPolygonsDataFrame object is
> the spplot method in the sp package (which spdep loads). Just try:
>
> spplot(my_SpolDF, "myvar")
>
> for a first cut.
>
> Base graphics methods, such as plot(), are also available. The best online
> guide may be one of the units at:
>
> http://www.bias-project.org.uk/ASDARcourse/
>
> either "Vizualising Spatial Data" for the description, or your choice of
> the worked examples. There are also code examples and figures on the ASDAR
> book website: www.asdar-book.org; though this is still under construction,
> most things are there.
>
> Roger
>
>>
>> Moreover, in future I will also need to plot values graduated by colors.
>>
>> Please, can you help me?
>> thanks in advance
>> massimo
>>
>> Massimo Ventrucci
>> Ph.D Student in Statistics
>> Dipartimento di Scienze Statistiche
>> Universit? degli studi di Bologna
>> Via Belle Arti 41
>> 40126 Bologna-Italy
>> _____________________________________
>>
>> Phone +39(051)264182 (office)
>> Fax     +39(051)232153
>> E-mail massimo.ventrucci at unibo.it <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From edzer.pebesma at uni-muenster.de  Thu Aug 21 13:07:29 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 21 Aug 2008 13:07:29 +0200
Subject: [R-sig-Geo] [Gstat-info] LOCAL universal kriging with GLOBAL
 reg. coeff. estimation
In-Reply-To: <979A09F0C174824C867BB4185FF2E654CEEEAB@scomp0041.wurnet.nl>
References: <979A09F0C174824C867BB4185FF2E654CEEEAB@scomp0041.wurnet.nl>
Message-ID: <48AD4C71.6060401@uni-muenster.de>

Good question, I'll include r-sig-geo as well.

actually the prediction equations you end up with are kind of funny, and 
I've never seen them written out. Two different covariance matrices 
being inversed.

Package gstat can do the two-step approach: global BLUE, then simple 
kriging of residual, but that ignores the correlation of both terms, 
when added.

I'm quite sure that if you do Gaussian simulation however with gstat, 
the trend is fitted globally (and simulated from the corresponding GLS 
mean & covariance), whereas the kriging is done locally, so that should 
result in realisations that have the variance you want. You just have to 
compute the average and variance, to get estimates of the kriging mean 
and variance you're looking for. Also, it might be computationally 
demanding, both in time and space (memory).
--
Edzer

Vasat, Radim wrote:
> Dear all,
>
> My question is how to performe LOCAL universal kriging with 
> estimation of regression coefficients from the whole area 
> (GLOBAL estimation) at once.
>
> For large data (I have more than 8000 records) is computationaly too 
> demanding to handle with all the data for UK prediction. Hence,
> I prefer to do it LOCALLY (namx=100), but the reg. coeff. 
> would be estimated only with limited data in this case (not all
> data are included).
>
> To estimate the reg. coeff. first (with BLUE=TRUE) and then perform 
> the simple kriging with beta equals to the reg. coeff. and nmax=100
> might be the 
> solution. But the reg. coeff. estimation error is not included into the
> final kriging variance in this case.
>
> Anybody knows how to join these two requirements (LOCAL UK and GLOBAL
> estinmation of reg. coeff.) into one prediction???
>
> I will appreciate any coments!
> Radim
>
> _______________________________________________
> Gstat-info mailing list
> Gstat-info at geo.uu.nl
> http://mailman.geo.uu.nl/mailman/listinfo/gstat-info
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From Roger.Bivand at nhh.no  Thu Aug 21 14:12:30 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 21 Aug 2008 14:12:30 +0200 (CEST)
Subject: [R-sig-Geo] Spatial Error Model - ANOVA table
In-Reply-To: <1133611150.1437261219257840505.JavaMail.root@zm-mbx-modv.zimbra.upenn.edu>
References: <1133611150.1437261219257840505.JavaMail.root@zm-mbx-modv.zimbra.upenn.edu>
Message-ID: <Pine.LNX.4.64.0808202236520.17549@reclus.nhh.no>

On Wed, 20 Aug 2008, Samuel Field wrote:

> List,
>
> Is it possible to decompose the variance of an outcome into trend, 
> signal and noise components using a SAR model - analogous to what one 
> would get with an OLS model? This doesn't seem to be straight forward. 
> With OLS, we decompose Y into two non-overlapping components
>
> Y = fit + error
>
> R-square is based on the idea that the total sum of squares of y is 
> partition neatly into two quantities - sum of square model and sum of 
> square error.
>
>
> With the spatial error model Y is broken up into three components
>
> Y = trend + signal + noise
>
>
> where trend = Xbeta
>      signal = labmdaWy - lambdaWXbeta
>      noise = Y - (trend + signal)
>
> You would think that the total sum of square would also fit neatly into 
> these three buckets, in which case you could easily calcluate the 
> proportion of the total sum of squares contributed by each.

In fact, I think it is easier to think of this in generalised least 
squares terms. For fitting the coefficients, we can abstract from the 
covariance matrix of the observations, by first finding lambda by line 
search, then using lm() to fit I(y - lambda * wy) ~ I(x - lambda * WX). 
You can see this by looking at the lm.target component of the sarlm object 
returned by errorsarlm.

By the way, your error, trend, and signal components agree with those from 
predict.sarlm():

#set.seed(1)
pred <- predict(error.mod)
all.equal(c(fit), unclass(pred), check.attributes=FALSE)
all.equal(c(signal), attr(pred, "signal"), check.attributes=FALSE)
all.equal(c(trend), attr(pred, "trend"), check.attributes=FALSE)
all.equal(err1, c(error), check.attributes=FALSE)
all.equal(residuals(error.mod), c(error), check.attributes=FALSE)

anova(error.mod$lm.target)
crossprod(fitted(error.mod$lm.target)) + 
crossprod(residuals(error.mod$lm.target))
crossprod(error.mod$lm.target$model$"I(y - lambda * wy)")

However, it is more difficult to get back to the untransformed space of 
the original model in terms of the response; the fitted values, 
residuals, etc., are possible, but the variance/covariance components are 
harder because of the autocorrelation. There is a discussion on pp. 
563-564 in Cressie (1993), and sections 6.2.2 and 6.2.3 (pp. 335-348) in 
Schabenburger and Gotway (2005) are relevant here. Current practice is 
typically to use the log-likelihood value and derivatives to assess how 
the model is doing. I found looking at lm.gls() in MASS instructive for 
following some of these issues up.

Not really an answer, but maybe others can help re-frame the question to 
shed more light on the issues involved.

Roger

> However, I have not found this to be the case.  The sum of squares from 
> each of the three components do not add up to the total sum of squares 
> of Y.  Possibly becase the signal component involves an infinite 
> expansion when you substitue Y into lambdaWYy
>
> Y = Xbeta + lambda(Xbeta + labmda(Xbeta + lambda(..) - labmdaWXbeta + u) 
> - lambdaWXbeta + u) - labmdaWXbeta + u.
>
>
> I know that the predict.errorsarlm() function uses the obeserved Y 
> vector in its calculation of signal, but why doesn't the sum of squares 
> (i.e. sum((signal - mean(Y))^2), sum((u^2)), and sum((XB - mean(Y))^2) 
> add up to the total sum of squares? (i.e. sum((Y - mean(Y))?
>
>
> Any help would be greatly appreciated.  Here is some example code in 
> case that is helpful.  Please note that the example below does not 
> "isolate" the signal component, but combines it with the trend 
> component.
>
>
> #creating data
> library(spdep)
>
> #sample size
> n <- 200
>
> #coordinates
>
> x_coord <- runif(n,0,10)
> y_coord <- runif(n,0,10)
>
>
> ## w matrix and row normalized
>
> w_raw <- matrix(nrow=length(x_coord),ncol=length(x_coord),1)
>
> for(i in 1:length(x_coord)){for(j in 1:length(x_coord))
> {w_raw[i,j]<- 1/(sqrt((x_coord[i]-x_coord[j])^2 + (y_coord[i]-y_coord[j])^2))^2}}
>
>
> diag(w_raw) <- rep(0,n)
>
>
> row_sum <- rep(1,length(x_coord))
> for(i in 1:length(x_coord))
>        {row_sum[i] <- sum(w_raw[i,]) }
>
> w <- matrix(nrow=length(x_coord),ncol=length(x_coord),1)
>
> for(i in 1:length(x_coord)){for(j in 1:length(x_coord))
>        {w[i,j] <- w_raw[i,j]/row_sum[i]}}
>
> x <- rbinom(n,1,.5)
>
> parms <- c(12.4,2)
> w.listw <- mat2listw(w)
>
> e <- rnorm(n,0,1)
> p <- .6
>
> y <- parms[1] + parms[2]*x + (solve(diag(n)- p*w))%*%e
>
> sim.data <- as.data.frame(cbind(y,x))
> names(sim.data) <- c("y","x")
> error.mod <- errorsarlm(y~x,data = sim.data,w.listw)
>
> summary(error.mod)
>
> X <- as.matrix(cbind(rep(1,length(sim.data$y)),sim.data$x))
>
>
> trend <- X%*%coef(error.mod)[-1]
> signal <-  error.mod$lambda*w%*%sim.data$y - error.mod$lambda*w%*%X%*%coef(error.mod)[-1]
> fit <- trend + signal
> error <-  sim.data$y - fit
>
>
> SST <- sum((sim.data$y - mean(sim.data$y))^2)
> SSE <- sum(error^2)
> SSM <- sum(((trend + signal)- mean(sim.data$y))^2)
>
>
> SSE + SSM
> SST
>
>
> Samuel H. Field, Ph.D.
> Philadelphia VA Medical Center
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Pilar.Tugores at ba.ieo.es  Thu Aug 21 16:05:38 2008
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Thu, 21 Aug 2008 16:05:38 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <e12429640808201509r8ae7329i81788cb71abbe493@mail.gmail.com>
Message-ID: <0838E01493845742A4D4039EA34EB1C12C5A6F@ieopalma2.ba.ieo.es>


I would add Ordinary Least Squares (It may be the same as your SS), Weighted Least Squares, Maximum Likelihood and Restricted Maximum Likelihood.
These four methods are available in the function likfit of the package geoR.
I've been using it a little bit and I think sometimes one method works better than the other one but I don't know the clues for making an a priori decision!


M? Pilar Tugores Ferr?

Becaria FPI - PhD Student

Ac?stica de Pesquer?as

I.E.O. - Centro Oceanogr?fico de Baleares 

Muelle de Poniente s/n

07015 Palma de Mallorca (Espa?a)

Tel.: (34) 971 401561


-----Mensaje original-----
De: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] En nombre de G. Allegri
Enviado el: 21 August 2008 00:09
Para: Paul Hiemstra
CC: r-sig-geo at stat.math.ethz.ch
Asunto: Re: [R-sig-Geo] variogram question

> You spoke of more sophisticated methods of automatically choosing between models, what kind of methods did you have in mind?

Here's a list I gathered some time ago. Many of them are just buzzwords form me!

? Adjusted R-squared (Wherry 1931)
? Bootstrap (Efron 1979)
? Cross-validation (Stone 1974; Geisser 1975)
    ? Generalized cross-validation (GCV) (Craven and Wahba 1979)
    ? k-fold cross-validation
    ? Leave-one-out cross-validation
? Jacknife
? Linear regression
? Shibata's model selector (sms) (Shibata 1981)
? Signal-to-noise ratio
? Test set validation
? Akaike information criterion (AIC)
   ? AIC (Akaike 1973)
   ? AICc (Hurvich and Tsai 1989)
   ? QAIC (Lebreton, et al. 1992)
   ? QAICc (Lebreton, et al. 1992)
   ? AICW (Wilks 1995)
? CAT (Parzen 1974, 1977)
? CP (Mallow's Cp) (Mallows 1973)
? Deviance information criterion (DIC) (Spiegelhalter, et al. 2002)
? FIC (Wei 1992)
? Final prediction error (FPE) (Akaike 1969)
? FPE? (Bhansali and Downham 1977)
? FPEC (de Luna 1998)
? FPER (Larsen and Hansen 1994)
? GM (Geweke and Meese 1981)
? Generalized prediction error (GPE) (Moody 1991, 1992)
? Hannan and Quinn Criterion (HQ) (Hannan and Quinn 1979)
? KIC (Cavanaugh 1999)
? KICc (Cavanaugh 2004)
? Minimum description length (MDL) (Rissanen 1978)
? Minimum message length (MML) (Wallace and Boulton 1968)
? Predicted squared error (PSE) (Barron 1984)
? PRESS (Allen 1974)
? Schwarz criterion (also Schwarz information criterion (SIC) or
Bayesian information criterion (BIC) or Schwarz-Bayesian information
criterion) (Schwarz 1978)
? Structural risk minimization (SRM) (Vapnik and Chervonenkis 1974)
? TIC (Takeuchi's information criterion) (Takeuchi 1976)
? VC-dimension (Vapnik and Chervonekis 1968, 1971; Vapnik 1979)
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.

From T.Hengl at uva.nl  Thu Aug 21 17:34:01 2008
From: T.Hengl at uva.nl (Tomislav Hengl)
Date: Thu, 21 Aug 2008 17:34:01 +0200
Subject: [R-sig-Geo] [Gstat-info] LOCAL universal kriging with GLOBAL
	reg. coeff.estimation
In-Reply-To: <48AD4C71.6060401@uni-muenster.de>
Message-ID: <635F946AC8DA41A39D3C02EA71CFE2ED@pcibed193>


Dear Radim, Edzer,

I was thinking about the same problem few years ago (I assume that you work with auxiliary maps and
not only coordinates). 

I think (have a feeling) that local and global Universal kriging should be treated as two things
(especially if you put a very narrow search radius). This is because, in the case of KED algorithm,
both regression and kriging part of predictions are solved at the same time. Hence, if we limit the
search window, but keep a constant variogram model, we could obtain very different predictions then
if we use a global (regression-kriging) model. Only if the variogram of residuals if absolutely
stationary (constant), then we can limit the search window to fit the KED weights. In fact, I am
confident that software packages should not allow UK/KED predictions with a limited search radius,
because this conflicts the model assumptions (a bit deeper discussion about this problem can be
found in my lecture notes section 2.2 "Localized versus local models").

In the case of regression-kriging, this is less problematic because it is computationally cheap to
fit the regression part, and then you are allowed to limit the search radius to interpolate the
residuals (we still cheat but not so much). But then the problem is that we do not have an estimate
of the RK kriging variance (you could estimate the OLS prediction variance and then OK-residuals
prediction variance and then add them together - both can be done in gstat - but then you completely
ignore correlation of the two terms; although this is often insignificant).

If gstat already does something like this (global GLS simulations of trend with local kriging), then
this would be a legitime solution. But I still can not run much geostatistics with big datasets
(>>1000 points, >>10^6 grids) in R+gstat (on standard PCs), not to mention geostatistical
simulations (that are computationally much more demanding than predictions)... if you would have to
do it 100 times, this would really take a lot of processing.

One alternative is to run UK/KED in SAGA software (I have tested it - it runs about 5-10 times
faster than R+gstat and has no memory limit problems), which is possible through R also, e.g.:

rsaga.get.usage("geostatistics_kriging", 3)
rsaga.geoprocessor(lib="geostatistics_kriging", module=3,
param=list(GRIDS="DEM.sgrd;SLOPE.sgrd;PLANC.sgrd;TWI.sgrd;SINS.sgrd;SMU1.sgrd;SMU3.sgrd;SMU4.sgrd;SM
U9.sgrd", GRID="SOLUM_rk.sgrd", SHAPES="baranja.shp", FIELD=0, MODEL=1, NUGGET=0, SILL=200,
RANGE=500, INTERPOL=0))

see also http://geomorphometry.org/view_scripts.asp?id=24 

But the last version of SAGA had some bug in this module, so I remember that I did not get correct
results (I did not test the most recent version of SAGA).

I personally think that we should simply think about implementing local RK (regressions/variograms
in moving window; maps of regression coefficients, variogram parameters, R-square etc.), and this
would then solve this problem (+give us much more insight into the data).


Tom Hengl
http://spatial-analyst.net 


-----Original Message-----
From: gstat-info-bounces at geo.uu.nl [mailto:gstat-info-bounces at geo.uu.nl] On Behalf Of Edzer Pebesma
Sent: donderdag 21 augustus 2008 13:07
To: Vasat, Radim
Cc: Gstat-info at geo.uu.nl; sig-geo
Subject: Re: [Gstat-info] LOCAL universal kriging with GLOBAL reg. coeff.estimation

Good question, I'll include r-sig-geo as well.

actually the prediction equations you end up with are kind of funny, and 
I've never seen them written out. Two different covariance matrices 
being inversed.

Package gstat can do the two-step approach: global BLUE, then simple 
kriging of residual, but that ignores the correlation of both terms, 
when added.

I'm quite sure that if you do Gaussian simulation however with gstat, 
the trend is fitted globally (and simulated from the corresponding GLS 
mean & covariance), whereas the kriging is done locally, so that should 
result in realisations that have the variance you want. You just have to 
compute the average and variance, to get estimates of the kriging mean 
and variance you're looking for. Also, it might be computationally 
demanding, both in time and space (memory).
--
Edzer

Vasat, Radim wrote:
> Dear all,
>
> My question is how to performe LOCAL universal kriging with 
> estimation of regression coefficients from the whole area 
> (GLOBAL estimation) at once.
>
> For large data (I have more than 8000 records) is computationaly too 
> demanding to handle with all the data for UK prediction. Hence,
> I prefer to do it LOCALLY (namx=100), but the reg. coeff. 
> would be estimated only with limited data in this case (not all
> data are included).
>
> To estimate the reg. coeff. first (with BLUE=TRUE) and then perform 
> the simple kriging with beta equals to the reg. coeff. and nmax=100
> might be the 
> solution. But the reg. coeff. estimation error is not included into the
> final kriging variance in this case.
>
> Anybody knows how to join these two requirements (LOCAL UK and GLOBAL
> estinmation of reg. coeff.) into one prediction???
>
> I will appreciate any coments!
> Radim
>
> _______________________________________________
> Gstat-info mailing list
> Gstat-info at geo.uu.nl
> http://mailman.geo.uu.nl/mailman/listinfo/gstat-info
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/

_______________________________________________
Gstat-info mailing list
Gstat-info at geo.uu.nl
http://mailman.geo.uu.nl/mailman/listinfo/gstat-info



From Pilar.Tugores at ba.ieo.es  Thu Aug 21 19:30:11 2008
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Thu, 21 Aug 2008 19:30:11 +0200
Subject: [R-sig-Geo] =?iso-8859-1?q?=5BSpam=5D=3A_how_to_get_numerical_val?=
	=?iso-8859-1?q?ues_of_a_variogram?=
In-Reply-To: <Pine.LNX.4.64.0808202236520.17549@reclus.nhh.no>
Message-ID: <0838E01493845742A4D4039EA34EB1C12C5A79@ieopalma2.ba.ieo.es>



Hello everybody!

For sure it is very simple, but I can't find the way.
How could I obtain the numerical values of a experimental semivariogram or variogram? Is it any function that makes this in geoR or gstat (or out of them)?
Thanks!
Pilar
 

M? Pilar Tugores Ferr?

Becaria FPI - PhD Student

Ac?stica de Pesquer?as

I.E.O. - Centro Oceanogr?fico de Baleares 

Muelle de Poniente s/n

07015 Palma de Mallorca (Espa?a)

Tel.: (34) 971 401561



La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.



From edzer.pebesma at uni-muenster.de  Fri Aug 22 08:26:31 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 22 Aug 2008 08:26:31 +0200
Subject: [R-sig-Geo] [Spam]: how to get numerical values of a variogram
In-Reply-To: <0838E01493845742A4D4039EA34EB1C12C5A79@ieopalma2.ba.ieo.es>
References: <0838E01493845742A4D4039EA34EB1C12C5A79@ieopalma2.ba.ieo.es>
Message-ID: <48AE5C17.9060101@uni-muenster.de>

 > # gstat:
 > library(gstat)
 > data(meuse)
 > coordinates(meuse)=~x+y
 > v = variogram(zinc~1, meuse, cutoff= 1500, width=100)
 > v$gamma
 [1]  37096.27  72732.59  79850.78 105605.91 117984.59 133647.42 142229.89
 [8] 152057.17 170659.29 159000.66 173061.81 171477.48 159297.84 173958.50
[15] 150212.24
 > # geoR
 > library(geoR)
 > v2 = variog(as.geodata(meuse["zinc"]), breaks = 0:15 * 100)
variog: computing omnidirectional variogram
 > v2$v
 [1]  37096.27  71711.29  80532.62 105605.91 117984.59 133647.42 142229.89
 [8] 152057.17 170659.29 159000.66 173061.81 171477.48 159297.84 173958.50
[15] 150212.24
 > plot(v2$v, v$gamma)

The minor difference seem to be due to point pairs with a distance equal 
to a bin boundary, which are then assigned to different bin:

 > v2$n
 [1]  52 262 382 430 475 503 525 565 535 530 487 483 431 419 427
 > v$np
 [1]  52 263 381 430 475 503 525 565 535 530 487 483 431 419 427
--
Edzer

Pilar Tugores Ferra wrote:
> Hello everybody!
>
> For sure it is very simple, but I can't find the way.
> How could I obtain the numerical values of a experimental semivariogram or variogram? Is it any function that makes this in geoR or gstat (or out of them)?
> Thanks!
> Pilar
>  
>
> M? Pilar Tugores Ferr?
>
> Becaria FPI - PhD Student
>
> Ac?stica de Pesquer?as
>
> I.E.O. - Centro Oceanogr?fico de Baleares 
>
> Muelle de Poniente s/n
>
> 07015 Palma de Mallorca (Espa?a)
>
> Tel.: (34) 971 401561
>
>
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From giohappy at gmail.com  Fri Aug 22 15:27:59 2008
From: giohappy at gmail.com (G. Allegri)
Date: Fri, 22 Aug 2008 15:27:59 +0200
Subject: [R-sig-Geo] variogram question
In-Reply-To: <0838E01493845742A4D4039EA34EB1C12C5A6F@ieopalma2.ba.ieo.es>
References: <e12429640808201509r8ae7329i81788cb71abbe493@mail.gmail.com>
	<0838E01493845742A4D4039EA34EB1C12C5A6F@ieopalma2.ba.ieo.es>
Message-ID: <e12429640808220627j10bd8b6ame7cedd25ac10651a@mail.gmail.com>

I forgot to add another important class of model parameters
estimators: maximum a posteriori (MAP)

2008/8/21 Pilar Tugores Ferra <Pilar.Tugores at ba.ieo.es>:
>
> I would add Ordinary Least Squares (It may be the same as your SS), Weighted Least Squares, Maximum Likelihood and Restricted Maximum Likelihood.
> These four methods are available in the function likfit of the package geoR.
> I've been using it a little bit and I think sometimes one method works better than the other one but I don't know the clues for making an a priori decision!
>
>
> M? Pilar Tugores Ferr?
>
> Becaria FPI - PhD Student
>
> Ac?stica de Pesquer?as
>
> I.E.O. - Centro Oceanogr?fico de Baleares
>
> Muelle de Poniente s/n
>
> 07015 Palma de Mallorca (Espa?a)
>
> Tel.: (34) 971 401561
>
>
> -----Mensaje original-----
> De: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] En nombre de G. Allegri
> Enviado el: 21 August 2008 00:09
> Para: Paul Hiemstra
> CC: r-sig-geo at stat.math.ethz.ch
> Asunto: Re: [R-sig-Geo] variogram question
>
>> You spoke of more sophisticated methods of automatically choosing between models, what kind of methods did you have in mind?
>
> Here's a list I gathered some time ago. Many of them are just buzzwords form me!
>
> ? Adjusted R-squared (Wherry 1931)
> ? Bootstrap (Efron 1979)
> ? Cross-validation (Stone 1974; Geisser 1975)
>    ? Generalized cross-validation (GCV) (Craven and Wahba 1979)
>    ? k-fold cross-validation
>    ? Leave-one-out cross-validation
> ? Jacknife
> ? Linear regression
> ? Shibata's model selector (sms) (Shibata 1981)
> ? Signal-to-noise ratio
> ? Test set validation
> ? Akaike information criterion (AIC)
>   ? AIC (Akaike 1973)
>   ? AICc (Hurvich and Tsai 1989)
>   ? QAIC (Lebreton, et al. 1992)
>   ? QAICc (Lebreton, et al. 1992)
>   ? AICW (Wilks 1995)
> ? CAT (Parzen 1974, 1977)
> ? CP (Mallow's Cp) (Mallows 1973)
> ? Deviance information criterion (DIC) (Spiegelhalter, et al. 2002)
> ? FIC (Wei 1992)
> ? Final prediction error (FPE) (Akaike 1969)
> ? FPE? (Bhansali and Downham 1977)
> ? FPEC (de Luna 1998)
> ? FPER (Larsen and Hansen 1994)
> ? GM (Geweke and Meese 1981)
> ? Generalized prediction error (GPE) (Moody 1991, 1992)
> ? Hannan and Quinn Criterion (HQ) (Hannan and Quinn 1979)
> ? KIC (Cavanaugh 1999)
> ? KICc (Cavanaugh 2004)
> ? Minimum description length (MDL) (Rissanen 1978)
> ? Minimum message length (MML) (Wallace and Boulton 1968)
> ? Predicted squared error (PSE) (Barron 1984)
> ? PRESS (Allen 1974)
> ? Schwarz criterion (also Schwarz information criterion (SIC) or
> Bayesian information criterion (BIC) or Schwarz-Bayesian information
> criterion) (Schwarz 1978)
> ? Structural risk minimization (SRM) (Vapnik and Chervonenkis 1974)
> ? TIC (Takeuchi's information criterion) (Takeuchi 1976)
> ? VC-dimension (Vapnik and Chervonekis 1968, 1971; Vapnik 1979)
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.
>

From fieldsh at mail.med.upenn.edu  Fri Aug 22 17:43:47 2008
From: fieldsh at mail.med.upenn.edu (Samuel Field)
Date: Fri, 22 Aug 2008 11:43:47 -0400 (EDT)
Subject: [R-sig-Geo] smothing surface/volume in 3D
In-Reply-To: <956614480.602991219419640521.JavaMail.root@zm-mbx-modv.zimbra.upenn.edu>
Message-ID: <303645058.604591219419827282.JavaMail.root@zm-mbx-modv.zimbra.upenn.edu>

List,

I have a set of locations in three dimensional space.  Each location has a continously scaled attribute and I would like to shade or color the volume between these locations using a simple smoother.  At the moment, I am simply using the cloud() function and coloring and sizing the points based on the value of the attribute, but I would like to think of these locations as sampling from a continously scaled "latent" attribute. I would like something simple to use if possible, since what I need it for is simply illustrative. Although I imagine that shading a volume in 3D isn't very striaght forward! There is an example below.  



#creating data
library(spdep)
library(RColorBrewer)


#sample size
n <- 200

#coordinates

x_coord <- runif(n,0,10)
y_coord <- runif(n,0,10)
z_coord <- runif(n,0,10)


## w matrix and row normalized

w_raw <- matrix(nrow=length(x_coord),ncol=length(x_coord),1)

for(i in 1:length(x_coord)){for(j in 1:length(x_coord)) 
{w_raw[i,j]<- 1/(sqrt((x_coord[i]-x_coord[j])^2 + (y_coord[i]-y_coord[j])^2 + (z_coord[i]-z_coord[j])^2 ))^3}}


diag(w_raw) <- rep(0,n)


row_sum <- rep(1,length(x_coord))
for(i in 1:length(x_coord))  
        {row_sum[i] <- sum(w_raw[i,]) }

w <- matrix(nrow=length(x_coord),ncol=length(x_coord),1)

for(i in 1:length(x_coord)){for(j in 1:length(x_coord)) 
        {w[i,j] <- w_raw[i,j]/row_sum[i]}}

x <- rbinom(n,1,.5)
                     
parms <- c(12.4,0)
w.listw <- mat2listw(w)

e <- rnorm(n,0,1)
p <- .6

y <- parms[1] + parms[2]*x + (solve(diag(n)- p*w))%*%e 

sim.data <- as.data.frame(cbind(y,x,x_coord,y_coord,z_coord))
names(sim.data) <- c("y","x","x_coord","y_coord","z_coord")
error.mod <- errorsarlm(y~x,data = sim.data,w.listw)

summary(error.mod)



brks <- quantile(y, probs=seq(0,1,.20),na.rm=TRUE)
cols <- brewer.pal(length(brks)-1, "YlOrRd")
size <- seq(1:length(cols))/3

cloud(z_coord~x_coord*y_coord,col=cols[findInterval(y,brks,all.inside=TRUE)],
pch=8,cex=size[findInterval(y,brks,all.inside=TRUE)])



From Jin.Li at ga.gov.au  Mon Aug 25 08:34:16 2008
From: Jin.Li at ga.gov.au (Jin.Li at ga.gov.au)
Date: Mon, 25 Aug 2008 16:34:16 +1000
Subject: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
Message-ID: <8BD19F29B0E16E4F88277A997CD872C2044996FE@mail.agso.gov.au>

Hi Edzer,

It is true that demo(cokriging) shows that it is using ordinary cokriging,
but if we examine its formula, it kriges multiple primary variables without
secondary information. The ordinary co-kriging (OCK) I mentioned (such as
those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
Evaluation.) interpolates one primary variable using one or more secondary
variables to improve the estimations. I guess that is the key difference.

In demo(examples), the multivariate kriging as shown in ex11.cmd claims it is
using ordinary cokriging, but it actually has no difference with that in
demo(cokriging), i.e. it kriges multiple primary variables without secondary
information.

I thought multiple kriging in ex10.cmd in demo(examples) was the one I was
after. After a further check, it is the ordinary kriging.  I hope this
explanation is clear enough. 

Thanks a lot for any further suggestions.

Best wishes,
Jin

-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: Monday, 18 August 2008 6:32
To: Li Jin
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]

Hi Jin,

Which differences do you exactly refer to? I'd say that what happens in 
demo(cokriging) is ordinary cokriging. As it says:
...
[using ordinary cokriging]

Best regards,
--
Edzer

Jin.Li at ga.gov.au wrote:
> Hi All,
>
>  
>
> I am going to compare a few spatial interpolation techniques including
> kriging with an external drift (KED) and ordinary co-kriging (OCK) (such as
> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
> Evaluation.) to interpolate marine sediment data (mud content in this case)
> using bathymetry as a secondary variable. However, it seems that the
ordinary
> cokriging in gstat as shown in demo(cokriging) is different from the OCK we
> planned to use. Is it possible to do such OCK in gstat? Any comments and
> example? Thanks.
>
>  
>
> As to KED, I tried 
>
>   
>> vgm1 <- variogram(sqrt(mud)~bathy, data.file.dev)
>>     
>
>   
>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>     
>
>   
>> # plot(vgm1, model.1)
>>     
>
>   
>> coordinates(data.file.pred) = ~LON+LAT
>>     
>
>   
>> mud.ok <- krige(sqrt(mud)~bathy, data.file.dev, data.file.pred, model =
>>     
> model.1)
>
> [using universal kriging]
>
>  
>
>   
>> vgm1 <- variogram(sqrt(mud)~LON+LAT, data.file.dev)
>>     
>
>   
>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>     
>
>   
>> # plot(vgm1, model.1)
>>     
>
>   
>> coordinates(data.file.pred) = ~LON+LAT
>>     
>
>   
>> mud.ok <- krige(sqrt(mud)~LON+LAT, data.file.dev, data.file.pred, model =
>>     
> model.1)
>
> [using universal kriging]
>
>  
>
> Both of them are UK. But the first one seems regression kriging. Is it
> identical to KED in this case? If not, any comments and examples of KED are
> appreciated.
>
>  
>
> Cheers,
>
>  
>
> Jin
>
> --------------------------------------------
>
> Jin Li, PhD
>
> Spatial Modeller/
>
> Computational Statistician
>
> Marine & Coastal Environment
>
> Geoscience Australia
>
>
>
> Ph: 61 (02) 6249 9899
>
> Fax: 61 (02) 6249 9956
>
> email: jin.li at ga.gov.au <mailto:jin.li at ga.gov.au> 
>
> --------------------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From edzer.pebesma at uni-muenster.de  Mon Aug 25 09:06:33 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 25 Aug 2008 09:06:33 +0200
Subject: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
In-Reply-To: <8BD19F29B0E16E4F88277A997CD872C2044996FE@mail.agso.gov.au>
References: <8BD19F29B0E16E4F88277A997CD872C2044996FE@mail.agso.gov.au>
Message-ID: <48B259F9.1050200@uni-muenster.de>

Hi Jin,

Jin.Li at ga.gov.au wrote:
> Hi Edzer,
>
> It is true that demo(cokriging) shows that it is using ordinary cokriging,
> but if we examine its formula, it kriges multiple primary variables without
> secondary information. The ordinary co-kriging (OCK) I mentioned (such as
> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
> Evaluation.) interpolates one primary variable using one or more secondary
> variables to improve the estimations. I guess that is the key difference.
>   
Ordinary cokriging and multivariate kriging (as e.g. described in the 
original papers by Don Myers in Math Geol, or in Noel Cressie's book, or 
Ver Hoef and Cressie MG) are mathematically equivalent. If you would 
constrain multivariate kriging to kriging of the first variable only 
(the Goovaerts formulation), you end up with exactly the same values 
(and gain a little CPU wise).
> In demo(examples), the multivariate kriging as shown in ex11.cmd claims it is
> using ordinary cokriging, but it actually has no difference with that in
> demo(cokriging), i.e. it kriges multiple primary variables without secondary
> information.
>   
It uses the "secondary" information for the first because a cross 
variogram is defined.
> I thought multiple kriging in ex10.cmd in demo(examples) was the one I was
> after. After a further check, it is the ordinary kriging.  I hope this
> explanation is clear enough. 
>   
No, this "multiple" kriging kriges each variable completely 
independenlty, as no cross variogram is defined. It was introduced in 
gstat stand-alone to speed up multiple kriging settings (think of 
several indicators derived from the same variable) as it re-uses the 
neighbourhood selection. I wasn't aware of it, but it seems to work in 
the R package as well (set up a cokriging gstat object, but don't define 
cross variograms).
> Thanks a lot for any further suggestions.
>
> Best wishes,
> Jin
>
> -----Original Message-----
> From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
> Sent: Monday, 18 August 2008 6:32
> To: Li Jin
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
>
> Hi Jin,
>
> Which differences do you exactly refer to? I'd say that what happens in 
> demo(cokriging) is ordinary cokriging. As it says:
> ...
> [using ordinary cokriging]
>
> Best regards,
> --
> Edzer
>
> Jin.Li at ga.gov.au wrote:
>   
>> Hi All,
>>
>>  
>>
>> I am going to compare a few spatial interpolation techniques including
>> kriging with an external drift (KED) and ordinary co-kriging (OCK) (such as
>> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
>> Evaluation.) to interpolate marine sediment data (mud content in this case)
>> using bathymetry as a secondary variable. However, it seems that the
>>     
> ordinary
>   
>> cokriging in gstat as shown in demo(cokriging) is different from the OCK we
>> planned to use. Is it possible to do such OCK in gstat? Any comments and
>> example? Thanks.
>>
>>  
>>
>> As to KED, I tried 
>>
>>   
>>     
>>> vgm1 <- variogram(sqrt(mud)~bathy, data.file.dev)
>>>     
>>>       
>>   
>>     
>>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>>     
>>>       
>>   
>>     
>>> # plot(vgm1, model.1)
>>>     
>>>       
>>   
>>     
>>> coordinates(data.file.pred) = ~LON+LAT
>>>     
>>>       
>>   
>>     
>>> mud.ok <- krige(sqrt(mud)~bathy, data.file.dev, data.file.pred, model =
>>>     
>>>       
>> model.1)
>>
>> [using universal kriging]
>>
>>  
>>
>>   
>>     
>>> vgm1 <- variogram(sqrt(mud)~LON+LAT, data.file.dev)
>>>     
>>>       
>>   
>>     
>>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>>     
>>>       
>>   
>>     
>>> # plot(vgm1, model.1)
>>>     
>>>       
>>   
>>     
>>> coordinates(data.file.pred) = ~LON+LAT
>>>     
>>>       
>>   
>>     
>>> mud.ok <- krige(sqrt(mud)~LON+LAT, data.file.dev, data.file.pred, model =
>>>     
>>>       
>> model.1)
>>
>> [using universal kriging]
>>
>>  
>>
>> Both of them are UK. But the first one seems regression kriging. Is it
>> identical to KED in this case? If not, any comments and examples of KED are
>> appreciated.
>>
>>  
>>
>> Cheers,
>>
>>  
>>
>> Jin
>>
>> --------------------------------------------
>>
>> Jin Li, PhD
>>
>> Spatial Modeller/
>>
>> Computational Statistician
>>
>> Marine & Coastal Environment
>>
>> Geoscience Australia
>>
>>
>>
>> Ph: 61 (02) 6249 9899
>>
>> Fax: 61 (02) 6249 9956
>>
>> email: jin.li at ga.gov.au <mailto:jin.li at ga.gov.au> 
>>
>> --------------------------------------------
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>>     
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From milton.ruser at gmail.com  Mon Aug 25 21:42:55 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 25 Aug 2008 16:42:55 -0300
Subject: [R-sig-Geo] creating hexagons around points
Message-ID: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080825/108e4a0a/attachment.pl>

From Greg.Snow at imail.org  Mon Aug 25 22:05:57 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Mon, 25 Aug 2008 14:05:57 -0600
Subject: [R-sig-Geo] creating hexagons around points
In-Reply-To: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
References: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC612F55E883@LP-EXMBVS10.CO.IHC.COM>

The last example in the help for my.symbols in the TeachingDemos package shows one way to plot hexagons around points.  Turning that into a shape file is a bit more of a challenge.

Hope this helps,

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
(801) 408-8111



> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of milton ruser
> Sent: Monday, August 25, 2008 1:43 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] creating hexagons around points
>
> Dear all,
>
> I have a set of XY (utm) coordinates and I need to create
> hexagons around the points and save if as Shape file.
> I found some examples that subdivide an area on hexagonal
> regions (very interesting, provided by Roger Bivand), but I
> don?t found how to create a hexagon around a midpoint.
>
> Any help are welcome.
>
> Miltinho Astronauta
> Brazil
>
>         [[alternative HTML version deleted]]
>
>



From milton.ruser at gmail.com  Tue Aug 26 01:57:56 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 25 Aug 2008 20:57:56 -0300
Subject: [R-sig-Geo] creating hexagons around points
In-Reply-To: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
References: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
Message-ID: <3aaf1a030808251657x3db1f9f8sbcc514874b95f002@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080825/8d7ecaf5/attachment.pl>

From saburq at gmail.com  Tue Aug 26 02:08:41 2008
From: saburq at gmail.com (shoaib)
Date: Tue, 26 Aug 2008 10:08:41 +1000
Subject: [R-sig-Geo] creating hexagons around points
In-Reply-To: <3aaf1a030808251657x3db1f9f8sbcc514874b95f002@mail.gmail.com>
References: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
	<3aaf1a030808251657x3db1f9f8sbcc514874b95f002@mail.gmail.com>
Message-ID: <b8b84f110808251708u1fb74832o61e68de22dc2691d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080826/74ab0cdc/attachment.pl>

From Jin.Li at ga.gov.au  Tue Aug 26 07:20:06 2008
From: Jin.Li at ga.gov.au (Jin.Li at ga.gov.au)
Date: Tue, 26 Aug 2008 15:20:06 +1000
Subject: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
Message-ID: <8BD19F29B0E16E4F88277A997CD872C204499700@mail.agso.gov.au>

Hi Edzer,
Thank you very much for the clarification.
In my current study, I am going to use a few variables like bathymetry,
distance to coastline, as secondary information to interpolate one primary
variable (e.g. mud content). To get the estimations as from OCK for only one
primary variable, I guess I need to feed all these primary and secondary
variables in the multivariate kriging as in the ex11.cmd in demo(examples),
retain the prediction and associate se for the primary variable and treat the
prediction and associate se for the secondary variables as redundant
information. Am I right? Or any further suggestions? 
Thanks,
Jin


-----Original Message-----
From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
Sent: Monday, 25 August 2008 5:07
To: Li Jin
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]

Hi Jin,

Jin.Li at ga.gov.au wrote:
> Hi Edzer,
>
> It is true that demo(cokriging) shows that it is using ordinary cokriging,
> but if we examine its formula, it kriges multiple primary variables without
> secondary information. The ordinary co-kriging (OCK) I mentioned (such as
> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
> Evaluation.) interpolates one primary variable using one or more secondary
> variables to improve the estimations. I guess that is the key difference.
>   
Ordinary cokriging and multivariate kriging (as e.g. described in the 
original papers by Don Myers in Math Geol, or in Noel Cressie's book, or 
Ver Hoef and Cressie MG) are mathematically equivalent. If you would 
constrain multivariate kriging to kriging of the first variable only 
(the Goovaerts formulation), you end up with exactly the same values 
(and gain a little CPU wise).
> In demo(examples), the multivariate kriging as shown in ex11.cmd claims it
is
> using ordinary cokriging, but it actually has no difference with that in
> demo(cokriging), i.e. it kriges multiple primary variables without
secondary
> information.
>   
It uses the "secondary" information for the first because a cross 
variogram is defined.
> I thought multiple kriging in ex10.cmd in demo(examples) was the one I was
> after. After a further check, it is the ordinary kriging.  I hope this
> explanation is clear enough. 
>   
No, this "multiple" kriging kriges each variable completely 
independenlty, as no cross variogram is defined. It was introduced in 
gstat stand-alone to speed up multiple kriging settings (think of 
several indicators derived from the same variable) as it re-uses the 
neighbourhood selection. I wasn't aware of it, but it seems to work in 
the R package as well (set up a cokriging gstat object, but don't define 
cross variograms).
> Thanks a lot for any further suggestions.
>
> Best wishes,
> Jin
>
> -----Original Message-----
> From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
> Sent: Monday, 18 August 2008 6:32
> To: Li Jin
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
>
> Hi Jin,
>
> Which differences do you exactly refer to? I'd say that what happens in 
> demo(cokriging) is ordinary cokriging. As it says:
> ...
> [using ordinary cokriging]
>
> Best regards,
> --
> Edzer
>
> Jin.Li at ga.gov.au wrote:
>   
>> Hi All,
>>
>>  
>>
>> I am going to compare a few spatial interpolation techniques including
>> kriging with an external drift (KED) and ordinary co-kriging (OCK) (such
as
>> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
>> Evaluation.) to interpolate marine sediment data (mud content in this
case)
>> using bathymetry as a secondary variable. However, it seems that the
>>     
> ordinary
>   
>> cokriging in gstat as shown in demo(cokriging) is different from the OCK
we
>> planned to use. Is it possible to do such OCK in gstat? Any comments and
>> example? Thanks.
>>
>>  
>>
>> As to KED, I tried 
>>
>>   
>>     
>>> vgm1 <- variogram(sqrt(mud)~bathy, data.file.dev)
>>>     
>>>       
>>   
>>     
>>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>>     
>>>       
>>   
>>     
>>> # plot(vgm1, model.1)
>>>     
>>>       
>>   
>>     
>>> coordinates(data.file.pred) = ~LON+LAT
>>>     
>>>       
>>   
>>     
>>> mud.ok <- krige(sqrt(mud)~bathy, data.file.dev, data.file.pred, model =
>>>     
>>>       
>> model.1)
>>
>> [using universal kriging]
>>
>>  
>>
>>   
>>     
>>> vgm1 <- variogram(sqrt(mud)~LON+LAT, data.file.dev)
>>>     
>>>       
>>   
>>     
>>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>>     
>>>       
>>   
>>     
>>> # plot(vgm1, model.1)
>>>     
>>>       
>>   
>>     
>>> coordinates(data.file.pred) = ~LON+LAT
>>>     
>>>       
>>   
>>     
>>> mud.ok <- krige(sqrt(mud)~LON+LAT, data.file.dev, data.file.pred, model =
>>>     
>>>       
>> model.1)
>>
>> [using universal kriging]
>>
>>  
>>
>> Both of them are UK. But the first one seems regression kriging. Is it
>> identical to KED in this case? If not, any comments and examples of KED
are
>> appreciated.
>>
>>  
>>
>> Cheers,
>>
>>  
>>
>> Jin
>>
>> --------------------------------------------
>>
>> Jin Li, PhD
>>
>> Spatial Modeller/
>>
>> Computational Statistician
>>
>> Marine & Coastal Environment
>>
>> Geoscience Australia
>>
>>
>>
>> Ph: 61 (02) 6249 9899
>>
>> Fax: 61 (02) 6249 9956
>>
>> email: jin.li at ga.gov.au <mailto:jin.li at ga.gov.au> 
>>
>> --------------------------------------------
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>>     
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From sburbeck at bfs.de  Tue Aug 26 08:28:31 2008
From: sburbeck at bfs.de (Sven Burbeck)
Date: Tue, 26 Aug 2008 08:28:31 +0200 (CEST)
Subject: [R-sig-Geo] local Universal Kriging with krige()
Message-ID: <44584.134.92.10.8.1219732111.squirrel@mail.fr.bfs.de>

Dear all,
I have a problem when trying to perform local Universal kriging with krige().
The background:
For model definition I have to use a larger dataset since this is the only
one available with sufficient information. However, the interpolation
should only be performed for a smaller subset and as local UK (although I
use the global datset for model definition, I know that the data has local
differences).

MyExample:
myResult <- krige(log(myValue) ~ GEO_UNIT - 1,

locations = myGlobalDataset,

newdata = myPredictionGrid_1000_utm,

model = myVgmf,

nmax = Inf,

nmin = 0,

maxdist = 18000,

indicators = FALSE,

na.action = na.pass,

debug.level = -1)

I get the following error:
"solve.c", line 87: singular matrix in function Usolve()
"lufactor.c", line 207: singular matrix in function m_inverse()
Fehler in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
  m_inverse

When "maxdist = Inf" everything works well.

Any hint where the problem could be would be welcome.

Sven



From edzer.pebesma at uni-muenster.de  Tue Aug 26 08:36:19 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 26 Aug 2008 08:36:19 +0200
Subject: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
In-Reply-To: <8BD19F29B0E16E4F88277A997CD872C204499700@mail.agso.gov.au>
References: <8BD19F29B0E16E4F88277A997CD872C204499700@mail.agso.gov.au>
Message-ID: <48B3A463.6060204@uni-muenster.de>

Jin, you are right. A suggestion (or my usual question here) is to 
carefully look at the neighbourhood selection settings for the secondary 
variable(s), when they come as coverage rather than points.

A typical answer is "use collocated cokriging". To find out how to do 
that, look into the help of function gstat and search for the "merge" 
parameter.
--
Edzer

Jin.Li at ga.gov.au wrote:
> Hi Edzer,
> Thank you very much for the clarification.
> In my current study, I am going to use a few variables like bathymetry,
> distance to coastline, as secondary information to interpolate one primary
> variable (e.g. mud content). To get the estimations as from OCK for only one
> primary variable, I guess I need to feed all these primary and secondary
> variables in the multivariate kriging as in the ex11.cmd in demo(examples),
> retain the prediction and associate se for the primary variable and treat the
> prediction and associate se for the secondary variables as redundant
> information. Am I right? Or any further suggestions? 
> Thanks,
> Jin
>
>
> -----Original Message-----
> From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
> Sent: Monday, 25 August 2008 5:07
> To: Li Jin
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
>
> Hi Jin,
>
> Jin.Li at ga.gov.au wrote:
>   
>> Hi Edzer,
>>
>> It is true that demo(cokriging) shows that it is using ordinary cokriging,
>> but if we examine its formula, it kriges multiple primary variables without
>> secondary information. The ordinary co-kriging (OCK) I mentioned (such as
>> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
>> Evaluation.) interpolates one primary variable using one or more secondary
>> variables to improve the estimations. I guess that is the key difference.
>>   
>>     
> Ordinary cokriging and multivariate kriging (as e.g. described in the 
> original papers by Don Myers in Math Geol, or in Noel Cressie's book, or 
> Ver Hoef and Cressie MG) are mathematically equivalent. If you would 
> constrain multivariate kriging to kriging of the first variable only 
> (the Goovaerts formulation), you end up with exactly the same values 
> (and gain a little CPU wise).
>   
>> In demo(examples), the multivariate kriging as shown in ex11.cmd claims it
>>     
> is
>   
>> using ordinary cokriging, but it actually has no difference with that in
>> demo(cokriging), i.e. it kriges multiple primary variables without
>>     
> secondary
>   
>> information.
>>   
>>     
> It uses the "secondary" information for the first because a cross 
> variogram is defined.
>   
>> I thought multiple kriging in ex10.cmd in demo(examples) was the one I was
>> after. After a further check, it is the ordinary kriging.  I hope this
>> explanation is clear enough. 
>>   
>>     
> No, this "multiple" kriging kriges each variable completely 
> independenlty, as no cross variogram is defined. It was introduced in 
> gstat stand-alone to speed up multiple kriging settings (think of 
> several indicators derived from the same variable) as it re-uses the 
> neighbourhood selection. I wasn't aware of it, but it seems to work in 
> the R package as well (set up a cokriging gstat object, but don't define 
> cross variograms).
>   
>> Thanks a lot for any further suggestions.
>>
>> Best wishes,
>> Jin
>>
>> -----Original Message-----
>> From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de] 
>> Sent: Monday, 18 August 2008 6:32
>> To: Li Jin
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] UK, KED or OCK? [SEC=UNCLASSIFIED]
>>
>> Hi Jin,
>>
>> Which differences do you exactly refer to? I'd say that what happens in 
>> demo(cokriging) is ordinary cokriging. As it says:
>> ...
>> [using ordinary cokriging]
>>
>> Best regards,
>> --
>> Edzer
>>
>> Jin.Li at ga.gov.au wrote:
>>   
>>     
>>> Hi All,
>>>
>>>  
>>>
>>> I am going to compare a few spatial interpolation techniques including
>>> kriging with an external drift (KED) and ordinary co-kriging (OCK) (such
>>>       
> as
>   
>>> those defined in: Goovaerts, 1997. Geostatistics for Natural Resources
>>> Evaluation.) to interpolate marine sediment data (mud content in this
>>>       
> case)
>   
>>> using bathymetry as a secondary variable. However, it seems that the
>>>     
>>>       
>> ordinary
>>   
>>     
>>> cokriging in gstat as shown in demo(cokriging) is different from the OCK
>>>       
> we
>   
>>> planned to use. Is it possible to do such OCK in gstat? Any comments and
>>> example? Thanks.
>>>
>>>  
>>>
>>> As to KED, I tried 
>>>
>>>   
>>>     
>>>       
>>>> vgm1 <- variogram(sqrt(mud)~bathy, data.file.dev)
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> # plot(vgm1, model.1)
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> coordinates(data.file.pred) = ~LON+LAT
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> mud.ok <- krige(sqrt(mud)~bathy, data.file.dev, data.file.pred, model =
>>>>     
>>>>       
>>>>         
>>> model.1)
>>>
>>> [using universal kriging]
>>>
>>>  
>>>
>>>   
>>>     
>>>       
>>>> vgm1 <- variogram(sqrt(mud)~LON+LAT, data.file.dev)
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> model.1 <- fit.variogram(vgm1,vgm(1,"Sph",5,1))
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> # plot(vgm1, model.1)
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> coordinates(data.file.pred) = ~LON+LAT
>>>>     
>>>>       
>>>>         
>>>   
>>>     
>>>       
>>>> mud.ok <- krige(sqrt(mud)~LON+LAT, data.file.dev, data.file.pred, model =
>>>>     
>>>>       
>>>>         
>>> model.1)
>>>
>>> [using universal kriging]
>>>
>>>  
>>>
>>> Both of them are UK. But the first one seems regression kriging. Is it
>>> identical to KED in this case? If not, any comments and examples of KED
>>>       
> are
>   
>>> appreciated.
>>>
>>>  
>>>
>>> Cheers,
>>>
>>>  
>>>
>>> Jin
>>>
>>> --------------------------------------------
>>>
>>> Jin Li, PhD
>>>
>>> Spatial Modeller/
>>>
>>> Computational Statistician
>>>
>>> Marine & Coastal Environment
>>>
>>> Geoscience Australia
>>>
>>>
>>>
>>> Ph: 61 (02) 6249 9899
>>>
>>> Fax: 61 (02) 6249 9956
>>>
>>> email: jin.li at ga.gov.au <mailto:jin.li at ga.gov.au> 
>>>
>>> --------------------------------------------
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>   
>>>     
>>>       
>>   
>>     
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From edzer.pebesma at uni-muenster.de  Tue Aug 26 08:41:21 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 26 Aug 2008 08:41:21 +0200
Subject: [R-sig-Geo] local Universal Kriging with krige()
In-Reply-To: <44584.134.92.10.8.1219732111.squirrel@mail.fr.bfs.de>
References: <44584.134.92.10.8.1219732111.squirrel@mail.fr.bfs.de>
Message-ID: <48B3A591.5010604@uni-muenster.de>

Hi Sven,

I assume that GEO_UNIT is a categorical variable. Without having seen 
your data, my guess is that the error arises when you run into a 
location where the local neighbourhood selection does not contain all 
the GEO_UNIT levels anymore, so it can't estimate all of the trend 
parameters from that selection. Do you have a specific reason why you 
want to  make these parameters neighbourhood dependent?

Best wishes,
--
Edzer

Sven Burbeck wrote:
> Dear all,
> I have a problem when trying to perform local Universal kriging with krige().
> The background:
> For model definition I have to use a larger dataset since this is the only
> one available with sufficient information. However, the interpolation
> should only be performed for a smaller subset and as local UK (although I
> use the global datset for model definition, I know that the data has local
> differences).
>
> MyExample:
> myResult <- krige(log(myValue) ~ GEO_UNIT - 1,
>
> locations = myGlobalDataset,
>
> newdata = myPredictionGrid_1000_utm,
>
> model = myVgmf,
>
> nmax = Inf,
>
> nmin = 0,
>
> maxdist = 18000,
>
> indicators = FALSE,
>
> na.action = na.pass,
>
> debug.level = -1)
>
> I get the following error:
> "solve.c", line 87: singular matrix in function Usolve()
> "lufactor.c", line 207: singular matrix in function m_inverse()
> Fehler in predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>   m_inverse
>
> When "maxdist = Inf" everything works well.
>
> Any hint where the problem could be would be welcome.
>
> Sven
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From gerald.jurasinski at uni-rostock.de  Tue Aug 26 12:07:43 2008
From: gerald.jurasinski at uni-rostock.de (Gerald Jurasinski)
Date: Tue, 26 Aug 2008 12:07:43 +0200
Subject: [R-sig-Geo] creating hexagons around points
In-Reply-To: <b8b84f110808251708u1fb74832o61e68de22dc2691d@mail.gmail.com>
References: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
	<3aaf1a030808251657x3db1f9f8sbcc514874b95f002@mail.gmail.com>
	<b8b84f110808251708u1fb74832o61e68de22dc2691d@mail.gmail.com>
Message-ID: <ED6CB0A0-A99D-434A-8E94-5AD7133BB721@uni-rostock.de>

Yes, that's a long time problem I had. Would be great if you could  
share the code.
Thanks in advance!
??????????????????

Dr. Gerald Jurasinski
Landscape Ecology and Site Evaluation
Faculty of Agricultural and Environmental Sciences
University of Rostock
Germany


Am 26.08.2008 um 02:08 schrieb shoaib:

> Miltinho
>
> can you please post your code for others?
>
> cheers
> Shoaib
>
> On Tue, Aug 26, 2008 at 9:57 AM, milton ruser  
> <milton.ruser at gmail.com>wrote:
>
>> Dear All,
>>
>> Case someone need it, now I have a code for this. The output is  
>> both visual
>> and a shape file (thanks to Roger Bivand, off course! and a old  
>> help by
>> Barry Rowlingson (2004))
>>
>> Kind regards,
>>
>> miltinho astronauta
>> Brazil
>>
>>
>> On 8/25/08, milton ruser <milton.ruser at gmail.com> wrote:
>>>
>>> Dear all,
>>>
>>> I have a set of XY (utm) coordinates and I need to create hexagons
>>> around the points and save if as Shape file.
>>> I found some examples that subdivide an area on hexagonal regions
>>> (very interesting, provided by Roger Bivand), but I don?t found
>>> how to create a hexagon around a midpoint.
>>>
>>> Any help are welcome.
>>>
>>> Miltinho Astronauta
>>> Brazil
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From friendly at yorku.ca  Tue Aug 26 14:22:10 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 26 Aug 2008 08:22:10 -0400
Subject: [R-sig-Geo] spplot: labels on maps / variables on different scales
Message-ID: <48B3F572.40903@yorku.ca>

Two short questions about working with maps:

1.  I'm reading a shapefile with character labels for the regions 
(FSA).  I can add the labels using plot(),
but when I try the same thing using spplot(), the labels are in the 
wrong positions -- they all seem to be
shrunk somewhat in toward the center of the map.  What am I doing wrong?

library(maptools)
# using readShapeSpatial
ontario <-readShapeSpatial("ForwardSortationAreas_JUL07_ON_region.shp", 
IDvar="FSA", proj4string=CRS("+proj=longlat +datum=NAD83") )
toronto <- ontario[ontario$F=="M",]
summary(toronto)
# this works OK
plot(toronto)
text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)

# this doesn't work-- labels in wrong position
spplot(toronto,"FSA_NAME", colorkey=FALSE)
text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)

2. I have a bunch of attribute variables for the geographic regions, all 
on different scales.  Id like to
produce a set of comparative maps in the same figure (say with spplot()) 
with each attribute shaded
by its quantiles, e.g., 5 classes each.  Do I have to precompute these 
first, or is there something I can do in the call
to spplot() to have this done, using the variables in the 
SpatialPolygonsDataFrame?

 > toronto <- spCbind(toronto, crimeTO)
 > summary(toronto)
Object of class SpatialPolygonsDataFrame
Coordinates:
         min       max
r1 -79.63925 -79.11484
r2  43.58103  43.85547
Is projected: FALSE
proj4string : [+proj=longlat +datum=NAD83]
Data attributes:
      FSA            FSA_NAME  F        PR               Area      
Jail.Cost           Rank     
 M1B    : 1   TORONTO    :48   K:  0   35:102   Toronto    :39   Min.   
:     0   Min.   :  6.0 
 M1C    : 1   NORTH YORK :22   L:  0            North York :24   1st 
Qu.:  3205   1st Qu.:126.8 
 M1E    : 1   SCARBOROUGH:17   M:102            Scarborough:17   Median 
: 42249   Median :296.5 
 M1G    : 1   ETOBICOKE  :12   N:  0            Etobicoke  :12   Mean   
: 84991   Mean   :259.7 
 M1H    : 1   EAST YORK  : 3   P:  0            East York  : 5   3rd 
Qu.:139404   3rd Qu.:406.0 
 M1J    : 1   ACTON      : 0                    York       : 5   Max.   
:506339   Max.   :413.0 
 (Other):96   (Other)    : 0                    (Other)    : 
0                                  
    Inmates       Inmates.per.10K Days.Sentenced     Population    
Household.Income
 Min.   : 0.000   Min.   :0.000   Min.   :   0.0   Min.   :    0   
Min.   : 35129 
 1st Qu.: 1.000   1st Qu.:0.325   1st Qu.:  30.0   1st Qu.:15857   1st 
Qu.: 48438 
 Median : 3.000   Median :1.000   Median : 395.5   Median :23564   
Median : 58015 
 Mean   : 3.559   Mean   :1.180   Mean   : 795.6   Mean   :25161   
Mean   : 62123 
 3rd Qu.: 5.000   3rd Qu.:1.800   3rd Qu.:1305.0   3rd Qu.:34878   3rd 
Qu.: 66259 
 Max.   :15.000   Max.   :4.300   Max.   :4740.0   Max.   :66878   
Max.   :127669 
                                                                   
NA's   :     5 
   Low.Income      Unemployed      University     Female.Homes   
Public.Housing
 Min.   : 6.00   Min.   :2.000   Min.   : 8.00   Min.   : 8.00   Min.   
:   2 
 1st Qu.:15.00   1st Qu.:4.000   1st Qu.:20.00   1st Qu.:13.00   1st 
Qu.: 234 
 Median :20.00   Median :5.000   Median :28.00   Median :16.00   Median 
: 685 
 Mean   :20.05   Mean   :5.412   Mean   :31.31   Mean   :16.16   Mean   
: 995 
 3rd Qu.:25.00   3rd Qu.:7.000   3rd Qu.:45.00   3rd Qu.:19.00   3rd 
Qu.:1276 
 Max.   :41.00   Max.   :9.000   Max.   :64.00   Max.   :30.00   Max.   
:9289 
 NA's   : 5.00   NA's   :5.000   NA's   : 5.00   NA's   : 5.00   NA's   
:  27 
 >

-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From edzer.pebesma at uni-muenster.de  Tue Aug 26 14:45:21 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 26 Aug 2008 14:45:21 +0200
Subject: [R-sig-Geo] spplot: labels on maps / variables on different
	scales
In-Reply-To: <48B3F572.40903@yorku.ca>
References: <48B3F572.40903@yorku.ca>
Message-ID: <48B3FAE1.1070506@uni-muenster.de>



Michael Friendly wrote:
> Two short questions about working with maps:
>
> 1.  I'm reading a shapefile with character labels for the regions 
> (FSA).  I can add the labels using plot(),
> but when I try the same thing using spplot(), the labels are in the 
> wrong positions -- they all seem to be
> shrunk somewhat in toward the center of the map.  What am I doing wrong?
>
> library(maptools)
> # using readShapeSpatial
> ontario 
> <-readShapeSpatial("ForwardSortationAreas_JUL07_ON_region.shp", 
> IDvar="FSA", proj4string=CRS("+proj=longlat +datum=NAD83") )
> toronto <- ontario[ontario$F=="M",]
> summary(toronto)
> # this works OK
> plot(toronto)
> text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)
>
> # this doesn't work-- labels in wrong position
> spplot(toronto,"FSA_NAME", colorkey=FALSE)
> text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)
Right: text() works with base graphics, not with lattice on which spplot 
is built.

Something like this should work:
spplot(toronto,"FSA_NAME", colorkey=FALSE,
    sp.layout = list("sp.text", coordinates(toronto), 
as.character(toronto$FSA), cex=0.4))

>
> 2. I have a bunch of attribute variables for the geographic regions, 
> all on different scales.  Id like to
> produce a set of comparative maps in the same figure (say with 
> spplot()) with each attribute shaded
> by its quantiles, e.g., 5 classes each.  Do I have to precompute these 
> first, or is there something I can do in the call
> to spplot() to have this done, using the variables in the 
> SpatialPolygonsDataFrame?
What exactly did you mean by "all on different scales"? They have 
different polygon structures?
--
Edzer
>
> > toronto <- spCbind(toronto, crimeTO)
> > summary(toronto)
> Object of class SpatialPolygonsDataFrame
> Coordinates:
>         min       max
> r1 -79.63925 -79.11484
> r2  43.58103  43.85547
> Is projected: FALSE
> proj4string : [+proj=longlat +datum=NAD83]
> Data attributes:
>      FSA            FSA_NAME  F        PR               Area      
> Jail.Cost           Rank     M1B    : 1   TORONTO    :48   K:  0   
> 35:102   Toronto    :39   Min.   :     0   Min.   :  6.0 M1C    : 1   
> NORTH YORK :22   L:  0            North York :24   1st Qu.:  3205   
> 1st Qu.:126.8 M1E    : 1   SCARBOROUGH:17   M:102            
> Scarborough:17   Median : 42249   Median :296.5 M1G    : 1   
> ETOBICOKE  :12   N:  0            Etobicoke  :12   Mean   : 84991   
> Mean   :259.7 M1H    : 1   EAST YORK  : 3   P:  0            East 
> York  : 5   3rd Qu.:139404   3rd Qu.:406.0 M1J    : 1   ACTON      : 
> 0                    York       : 5   Max.   :506339   Max.   :413.0 
> (Other):96   (Other)    : 0                    (Other)    : 
> 0                                     Inmates       Inmates.per.10K 
> Days.Sentenced     Population    Household.Income
> Min.   : 0.000   Min.   :0.000   Min.   :   0.0   Min.   :    0   
> Min.   : 35129 1st Qu.: 1.000   1st Qu.:0.325   1st Qu.:  30.0   1st 
> Qu.:15857   1st Qu.: 48438 Median : 3.000   Median :1.000   Median : 
> 395.5   Median :23564   Median : 58015 Mean   : 3.559   Mean   
> :1.180   Mean   : 795.6   Mean   :25161   Mean   : 62123 3rd Qu.: 
> 5.000   3rd Qu.:1.800   3rd Qu.:1305.0   3rd Qu.:34878   3rd Qu.: 
> 66259 Max.   :15.000   Max.   :4.300   Max.   :4740.0   Max.   
> :66878   Max.   :127669 
>                                                                   
> NA's   :     5   Low.Income      Unemployed      University     
> Female.Homes   Public.Housing
> Min.   : 6.00   Min.   :2.000   Min.   : 8.00   Min.   : 8.00   Min.   
> :   2 1st Qu.:15.00   1st Qu.:4.000   1st Qu.:20.00   1st Qu.:13.00   
> 1st Qu.: 234 Median :20.00   Median :5.000   Median :28.00   Median 
> :16.00   Median : 685 Mean   :20.05   Mean   :5.412   Mean   :31.31   
> Mean   :16.16   Mean   : 995 3rd Qu.:25.00   3rd Qu.:7.000   3rd 
> Qu.:45.00   3rd Qu.:19.00   3rd Qu.:1276 Max.   :41.00   Max.   
> :9.000   Max.   :64.00   Max.   :30.00   Max.   :9289 NA's   : 5.00   
> NA's   :5.000   NA's   : 5.00   NA's   : 5.00   NA's   :  27 >
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From friendly at yorku.ca  Tue Aug 26 16:50:12 2008
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 26 Aug 2008 10:50:12 -0400
Subject: [R-sig-Geo] spplot: labels on maps / variables on different
	scales
In-Reply-To: <48B3FAE1.1070506@uni-muenster.de>
References: <48B3F572.40903@yorku.ca> <48B3FAE1.1070506@uni-muenster.de>
Message-ID: <48B41824.7090307@yorku.ca>

Edzer Pebesma wrote:
>
>
> Michael Friendly wrote:
>> Two short questions about working with maps:
>>
>> 1.  I'm reading a shapefile with character labels for the regions 
>> (FSA).  I can add the labels using plot(),
>> but when I try the same thing using spplot(), the labels are in the 
>> wrong positions -- they all seem to be
>> shrunk somewhat in toward the center of the map.  What am I doing wrong?
>>
>> # this doesn't work-- labels in wrong position
>> spplot(toronto,"FSA_NAME", colorkey=FALSE)
>> text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)
> Right: text() works with base graphics, not with lattice on which 
> spplot is built.
>
> Something like this should work:
> spplot(toronto,"FSA_NAME", colorkey=FALSE,
>    sp.layout = list("sp.text", coordinates(toronto), 
> as.character(toronto$FSA), cex=0.4))
>
Great!  Now I also know where to look to generalize this.
>>
>> 2. I have a bunch of attribute variables for the geographic regions, 
>> all on different scales.  Id like to
>> produce a set of comparative maps in the same figure (say with 
>> spplot()) with each attribute shaded
>> by its quantiles, e.g., 5 classes each.  Do I have to precompute 
>> these first, or is there something I can do in the call
>> to spplot() to have this done, using the variables in the 
>> SpatialPolygonsDataFrame?
> What exactly did you mean by "all on different scales"? They have 
> different polygon structures?
No - some of the attribute values are percents, some are quantitative & 
positively skewed, like Income. If I do

spplot(toronto, c("Household.Income","Unemployed","University"))
a single scale is applied to all three, so the two % variables are 
shaded uniformly in the lowest range.
What I'd like is to apply a function to take each of these and recode 
into quantiles for that variable.

It's partly that my data variables are now in the map object and, from 
the help, I only know how to refer to
zcol= names of these, rather than some transformations on the underlying 
data.

-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From edzer.pebesma at uni-muenster.de  Tue Aug 26 17:21:24 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 26 Aug 2008 17:21:24 +0200
Subject: [R-sig-Geo] spplot: labels on maps / variables on different
	scales
In-Reply-To: <48B41824.7090307@yorku.ca>
References: <48B3F572.40903@yorku.ca> <48B3FAE1.1070506@uni-muenster.de>
	<48B41824.7090307@yorku.ca>
Message-ID: <48B41F74.8080408@uni-muenster.de>



Michael Friendly wrote:
> Edzer Pebesma wrote:
>>
>>
>> Michael Friendly wrote:
>>> Two short questions about working with maps:
>>>
>>> 1.  I'm reading a shapefile with character labels for the regions 
>>> (FSA).  I can add the labels using plot(),
>>> but when I try the same thing using spplot(), the labels are in the 
>>> wrong positions -- they all seem to be
>>> shrunk somewhat in toward the center of the map.  What am I doing 
>>> wrong?
>>>
>>> # this doesn't work-- labels in wrong position
>>> spplot(toronto,"FSA_NAME", colorkey=FALSE)
>>> text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)
>> Right: text() works with base graphics, not with lattice on which 
>> spplot is built.
>>
>> Something like this should work:
>> spplot(toronto,"FSA_NAME", colorkey=FALSE,
>>    sp.layout = list("sp.text", coordinates(toronto), 
>> as.character(toronto$FSA), cex=0.4))
>>
> Great!  Now I also know where to look to generalize this.
>>>
>>> 2. I have a bunch of attribute variables for the geographic regions, 
>>> all on different scales.  Id like to
>>> produce a set of comparative maps in the same figure (say with 
>>> spplot()) with each attribute shaded
>>> by its quantiles, e.g., 5 classes each.  Do I have to precompute 
>>> these first, or is there something I can do in the call
>>> to spplot() to have this done, using the variables in the 
>>> SpatialPolygonsDataFrame?
>> What exactly did you mean by "all on different scales"? They have 
>> different polygon structures?
> No - some of the attribute values are percents, some are quantitative 
> & positively skewed, like Income. If I do
>
> spplot(toronto, c("Household.Income","Unemployed","University"))
> a single scale is applied to all three, so the two % variables are 
> shaded uniformly in the lowest range.
> What I'd like is to apply a function to take each of these and recode 
> into quantiles for that variable.
>
> It's partly that my data variables are now in the map object and, from 
> the help, I only know how to refer to
> zcol= names of these, rather than some transformations on the 
> underlying data.
>
I see what you mean; yes this needs precomputation. Something like a 
formula interface that gets evaluated would indeed be nice too!

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From milton.ruser at gmail.com  Tue Aug 26 17:30:31 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Tue, 26 Aug 2008 12:30:31 -0300
Subject: [R-sig-Geo] creating hexagons around points
In-Reply-To: <ED6CB0A0-A99D-434A-8E94-5AD7133BB721@uni-rostock.de>
References: <3aaf1a030808251242h30233f0dgcec43fbfc74b54e1@mail.gmail.com>
	<3aaf1a030808251657x3db1f9f8sbcc514874b95f002@mail.gmail.com>
	<b8b84f110808251708u1fb74832o61e68de22dc2691d@mail.gmail.com>
	<ED6CB0A0-A99D-434A-8E94-5AD7133BB721@uni-rostock.de>
Message-ID: <3aaf1a030808260830q54742159ia8a6ff772e7f9e4e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080826/5698b8cf/attachment.pl>

From ddepew at sciborg.uwaterloo.ca  Tue Aug 26 19:03:23 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Tue, 26 Aug 2008 13:03:23 -0400
Subject: [R-sig-Geo] kriging question
Message-ID: <48B4375B.1010601@scimail.uwaterloo.ca>

Hi all,
A question for the more experienced geostats users....

I have a data set containing 2-3 variables relating to submerged plant 
characteristics inferred from acoustic survey.
The distribution of the % cover variable is bounded (0-100) and highly 
left skewed (many 0's). The transect spacing is quite even, and I can't 
seem to notice much difference between a run of ordinary kriging and a 
variant of RK using a zeroinflated glm of the %cover residuals.
None of the other co-variates show much correlation with the data (i.e. 
bottom depth, x and y). Is this a possible reason why OK and RK seem to 
give more or less the same predictions?

my second question relates to transformation of the target variable...in 
this case zero inflated distributions are difficult to transform. Is it 
really a requirement of kriging that the data be transformed? or just 
that it will generally perform better with a target variable with a 
distribution close to normal?


Thanks,

Dave



From edzer.pebesma at uni-muenster.de  Tue Aug 26 20:44:48 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 26 Aug 2008 20:44:48 +0200
Subject: [R-sig-Geo] kriging question
In-Reply-To: <48B4375B.1010601@scimail.uwaterloo.ca>
References: <48B4375B.1010601@scimail.uwaterloo.ca>
Message-ID: <48B44F20.4090304@uni-muenster.de>

Hi Dave,

Dave Depew wrote:
> Hi all,
> A question for the more experienced geostats users....
>
> I have a data set containing 2-3 variables relating to submerged plant 
> characteristics inferred from acoustic survey.
> The distribution of the % cover variable is bounded (0-100) and highly 
> left skewed (many 0's). The transect spacing is quite even, and I 
> can't seem to notice much difference between a run of ordinary kriging 
> and a variant of RK using a zeroinflated glm of the %cover residuals.
> None of the other co-variates show much correlation with the data 
> (i.e. bottom depth, x and y). Is this a possible reason why OK and RK 
> seem to give more or less the same predictions?
Well, yes, if there's not much of a trend, then RK will essentially 
simplify to OK.
>
> my second question relates to transformation of the target 
> variable...in this case zero inflated distributions are difficult to 
> transform. Is it really a requirement of kriging that the data be 
> transformed? or just that it will generally perform better with a 
> target variable with a distribution close to normal?
>
I believe the argument is along the following lines: kriging is the BLUP 
in any case, but in case the data are normally distributed (around the 
trend), the BLUP (or more exactly the BLP, simple kriging) coincides 
with the conditional expectation, making it the best possible predictor. 
In other cases, meaning when data are not normally distributed, it is 
still the best linear predictor, but it may very well be that there are 
other, better, non-linear predictors that give a result much closer to 
the best predictor under those circumstances.

If there is a transformation for that data that makes them multivariate 
Gaussian, then transforming and kriging on that scale is the way to go. 
A catch that has gotten very little attention is that transformation 
typically looks at marginal distributions, and not at multivariate 
distributions, the latter being pretty hard to check with only one 
realisation of the random field.

Cressie's book is a good source to read this stuff; I've lost my copy 
when I moved jobs in the spring.
--
Edzer

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From ddepew at sciborg.uwaterloo.ca  Tue Aug 26 21:51:06 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Tue, 26 Aug 2008 15:51:06 -0400
Subject: [R-sig-Geo] kriging question
In-Reply-To: <48B44F20.4090304@uni-muenster.de>
References: <48B4375B.1010601@scimail.uwaterloo.ca>
	<48B44F20.4090304@uni-muenster.de>
Message-ID: <48B45EAA.8010004@scimail.uwaterloo.ca>

Thanks Edzer,

I've requested Cressie's book from our library (just waiting on it).
My main concern was the many 0 counts. I also was not enthusiastic about 
odd transformations which then require appropriate back-transforms (I 
imagine the back transform of the kriging variance gets messy)

I've tried several linear and non-linear combinations....they all do not 
improve on predictions generated by using OK with the untransformed 
data. I am confident that the resultant grid outputs do capture the 
spatial structure quite well. I've also tried a 10 fold cross validation 
of the kriging model - this seems to give reasonable estimates for mean 
error, mean squared prediction error and mean square normalized error. I 
had interpreted this that the variogram model chosen was doing a 
reasonable job.

Edzer Pebesma wrote:
> Hi Dave,
>
> Dave Depew wrote:
>> Hi all,
>> A question for the more experienced geostats users....
>>
>> I have a data set containing 2-3 variables relating to submerged 
>> plant characteristics inferred from acoustic survey.
>> The distribution of the % cover variable is bounded (0-100) and 
>> highly left skewed (many 0's). The transect spacing is quite even, 
>> and I can't seem to notice much difference between a run of ordinary 
>> kriging and a variant of RK using a zeroinflated glm of the %cover 
>> residuals.
>> None of the other co-variates show much correlation with the data 
>> (i.e. bottom depth, x and y). Is this a possible reason why OK and RK 
>> seem to give more or less the same predictions?
> Well, yes, if there's not much of a trend, then RK will essentially 
> simplify to OK.
>>
>> my second question relates to transformation of the target 
>> variable...in this case zero inflated distributions are difficult to 
>> transform. Is it really a requirement of kriging that the data be 
>> transformed? or just that it will generally perform better with a 
>> target variable with a distribution close to normal?
>>
> I believe the argument is along the following lines: kriging is the 
> BLUP in any case, but in case the data are normally distributed 
> (around the trend), the BLUP (or more exactly the BLP, simple kriging) 
> coincides with the conditional expectation, making it the best 
> possible predictor. In other cases, meaning when data are not normally 
> distributed, it is still the best linear predictor, but it may very 
> well be that there are other, better, non-linear predictors that give 
> a result much closer to the best predictor under those circumstances.
>
> If there is a transformation for that data that makes them 
> multivariate Gaussian, then transforming and kriging on that scale is 
> the way to go. A catch that has gotten very little attention is that 
> transformation typically looks at marginal distributions, and not at 
> multivariate distributions, the latter being pretty hard to check with 
> only one realisation of the random field.
>
> Cressie's book is a good source to read this stuff; I've lost my copy 
> when I moved jobs in the spring.
> -- 
> Edzer
>



From edzer.pebesma at uni-muenster.de  Tue Aug 26 22:39:55 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 26 Aug 2008 22:39:55 +0200
Subject: [R-sig-Geo] kriging question
In-Reply-To: <48B45EAA.8010004@scimail.uwaterloo.ca>
References: <48B4375B.1010601@scimail.uwaterloo.ca>
	<48B44F20.4090304@uni-muenster.de>
	<48B45EAA.8010004@scimail.uwaterloo.ca>
Message-ID: <48B46A1B.3070108@uni-muenster.de>

Dave,

Transformation to a continuous distribution when the data follow a 
discrete distribution is always messy, and the back-transform may get worse.

While you're at the library, try to pick up Diggle & Ribeiro's 
Model-based geostatistics; they describe a model-based approach that 
extends glm models. It seems the most appropriate way for your kind of 
data. I'm not sure whether the accompanying software (packages 
geoR/geoRglm) supports zero-inflated Poissons. In case it does, it 
remains to be seen whether prediction will actually improve substantially.
--
Edzer

Dave Depew wrote:
> Thanks Edzer,
>
> I've requested Cressie's book from our library (just waiting on it).
> My main concern was the many 0 counts. I also was not enthusiastic 
> about odd transformations which then require appropriate 
> back-transforms (I imagine the back transform of the kriging variance 
> gets messy)
>
> I've tried several linear and non-linear combinations....they all do 
> not improve on predictions generated by using OK with the 
> untransformed data. I am confident that the resultant grid outputs do 
> capture the spatial structure quite well. I've also tried a 10 fold 
> cross validation of the kriging model - this seems to give reasonable 
> estimates for mean error, mean squared prediction error and mean 
> square normalized error. I had interpreted this that the variogram 
> model chosen was doing a reasonable job.
>
> Edzer Pebesma wrote:
>> Hi Dave,
>>
>> Dave Depew wrote:
>>> Hi all,
>>> A question for the more experienced geostats users....
>>>
>>> I have a data set containing 2-3 variables relating to submerged 
>>> plant characteristics inferred from acoustic survey.
>>> The distribution of the % cover variable is bounded (0-100) and 
>>> highly left skewed (many 0's). The transect spacing is quite even, 
>>> and I can't seem to notice much difference between a run of ordinary 
>>> kriging and a variant of RK using a zeroinflated glm of the %cover 
>>> residuals.
>>> None of the other co-variates show much correlation with the data 
>>> (i.e. bottom depth, x and y). Is this a possible reason why OK and 
>>> RK seem to give more or less the same predictions?
>> Well, yes, if there's not much of a trend, then RK will essentially 
>> simplify to OK.
>>>
>>> my second question relates to transformation of the target 
>>> variable...in this case zero inflated distributions are difficult to 
>>> transform. Is it really a requirement of kriging that the data be 
>>> transformed? or just that it will generally perform better with a 
>>> target variable with a distribution close to normal?
>>>
>> I believe the argument is along the following lines: kriging is the 
>> BLUP in any case, but in case the data are normally distributed 
>> (around the trend), the BLUP (or more exactly the BLP, simple 
>> kriging) coincides with the conditional expectation, making it the 
>> best possible predictor. In other cases, meaning when data are not 
>> normally distributed, it is still the best linear predictor, but it 
>> may very well be that there are other, better, non-linear predictors 
>> that give a result much closer to the best predictor under those 
>> circumstances.
>>
>> If there is a transformation for that data that makes them 
>> multivariate Gaussian, then transforming and kriging on that scale is 
>> the way to go. A catch that has gotten very little attention is that 
>> transformation typically looks at marginal distributions, and not at 
>> multivariate distributions, the latter being pretty hard to check 
>> with only one realisation of the random field.
>>
>> Cressie's book is a good source to read this stuff; I've lost my copy 
>> when I moved jobs in the spring.
>> -- 
>> Edzer
>>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From ashton at msu.edu  Wed Aug 27 22:21:31 2008
From: ashton at msu.edu (Ashton Shortridge)
Date: Wed, 27 Aug 2008 16:21:31 -0400
Subject: [R-sig-Geo] kriging question
In-Reply-To: <48B46A1B.3070108@uni-muenster.de>
References: <48B4375B.1010601@scimail.uwaterloo.ca>
	<48B45EAA.8010004@scimail.uwaterloo.ca>
	<48B46A1B.3070108@uni-muenster.de>
Message-ID: <200808271621.31381.ashton@msu.edu>

Hi Sarah,

This looks interesting and relevant:
http://www.leg.ufpr.br/mbgbook/

On Tuesday 26 August 2008, Edzer Pebesma wrote:
> Diggle & Ribeiro



-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671



From Pilar.Tugores at ba.ieo.es  Thu Aug 28 14:24:19 2008
From: Pilar.Tugores at ba.ieo.es (Pilar Tugores Ferra)
Date: Thu, 28 Aug 2008 14:24:19 +0200
Subject: [R-sig-Geo] kriging question
In-Reply-To: <200808271621.31381.ashton@msu.edu>
Message-ID: <0838E01493845742A4D4039EA34EB1C12C5B3D@ieopalma2.ba.ieo.es>


Hi Dave and everybody,
I also work with acoustic data collected in parallel equidistant transects(in my case fish density)and we also have zero inflated data. 
"Playing" with Arcgis I saw that performing a cell declustering previous to an ordinary kriging improved substantially the predictions.
I supposed it occurs because in some sense the data is clustered in one axis of the 2D.
Don't you thing it's better this option than transforming the data?
I would appreciate your opinions.
Pilar


M? Pilar Tugores Ferr?

Becaria FPI - PhD Student

Ac?stica de Pesquer?as

I.E.O. - Centro Oceanogr?fico de Baleares 

Muelle de Poniente s/n

07015 Palma de Mallorca (Espa?a)

Tel.: (34) 971 401561


-----Mensaje original-----
De: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] En nombre de Ashton Shortridge
Enviado el: 27 August 2008 22:22
Para: r-sig-geo at stat.math.ethz.ch
Asunto: Re: [R-sig-Geo] kriging question

Hi Sarah,

This looks interesting and relevant:
http://www.leg.ufpr.br/mbgbook/

On Tuesday 26 August 2008, Edzer Pebesma wrote:
> Diggle & Ribeiro



-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

La informaci?n contenida en este e-mail y sus ficheros adjuntos es totalmente confidencial y no deber?a ser usado si no fuera usted alguno de los destinatarios. Si ha recibido este e-mail por error, por favor avise al remitente y b?rrelo de su buz?n o de cualquier otro medio de almacenamiento.   This email is confidential and should not be used by anyone who is not the original intended  recipient. If you have received this e-mail in  error please inform the sender and delete it from  your mailbox or any other storage mechanism.



From milton.ruser at gmail.com  Thu Aug 28 16:17:33 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 28 Aug 2008 11:17:33 -0300
Subject: [R-sig-Geo] addin a shapefile on earth google navigator
Message-ID: <3aaf1a030808280717i11240690r7da9adbaebd42e2b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080828/537c79ff/attachment.pl>

From Roger.Bivand at nhh.no  Fri Aug 29 08:54:59 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 29 Aug 2008 08:54:59 +0200 (CEST)
Subject: [R-sig-Geo] addin a shapefile on earth google navigator
In-Reply-To: <3aaf1a030808280717i11240690r7da9adbaebd42e2b@mail.gmail.com>
References: <3aaf1a030808280717i11240690r7da9adbaebd42e2b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0808290849410.14383@reclus.nhh.no>

On Thu, 28 Aug 2008, milton ruser wrote:

> Dear all,
>
> I have a shape file with the boundaries of an area of interest
> and I would like "upload" it on earth google natigator.
> How can I do that? A example is very welcome.

If the SpatialPolygonsDataFrame or SpatialLinesDataFrame object (from 
either readOGR() in rgdal or readShapeSpatial() in maptools) is in 
geographical coordinates, writeOGR(..., driver="KML") is all you need to 
output the border lines. If the PROJ4 string is known and the coordinates 
are projected, use spTransform() in rgdal to get to geographical 
coordinates. If unknown, find the correct PROJ4 string.

This just gets you the borders. If you want to do an image overlay, see 
GE_SpatialGrid() in maptools to create metadata for a PNG device to plot 
to.

Hope this helps,

Roger

>
> All the best,
>
> miltinho astronauta
> brazil
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From N.A.Batchelor at sms.ed.ac.uk  Fri Aug 29 10:18:52 2008
From: N.A.Batchelor at sms.ed.ac.uk (Nicola Batchelor)
Date: Fri, 29 Aug 2008 09:18:52 +0100
Subject: [R-sig-Geo] Prediction locations for kriging in geoR
Message-ID: <000c01c909af$e084dbe0$21de4e98@VCS126114>

Hi, 

Im using geoR and I'm trying to do some predictions, based on an external
trend, using ordinary kriging.

 

However, I seem to be getting some strange results from my kriging, which I
think must have something to do with a problem with my prediction points. 

I have my geodata object (called nicola), my prediction points (predpoints,
imported from a csv containing only the x and y coordinated of the
prediction locations) and my covariate data at each of the prediction points
(covars, imported from a csv containing the x and y coordinates of the
prediction locations, plus the values of the two covariates I want to use at
each of the prediction locations). 

>predpoints<-read.csv(file="C:\\Documents and Settings\\s9901315\\My 
+ Documents\\Uni\\Data\\Work\\Case control study\\Full study area\\R\\Files
for analysis\\Prediction 
+ points\\predpoints.csv", header=FALSE, sep=",") 

>covars<-read.csv(file="C:\\Documents and Settings\\s9901315\\My 
+ Documents\\Uni\\Data\\Work\\Case control study\\Full study area\\R\\Files
for analysis\\Covariate 
+ data\\covars.csv", header=TRUE, sep=",") 

The final model is defined using "OTUBOIDIST" and "LSTPHAN" as external
covariates: 

>mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
trend=~OTUBOIDIST + 
+ LSTPHAN) 

and then I carry out the kriging using the model "mlx2", prediction points
"predpoints", and covariate data "covars" : 

>kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~OTUBOIDIST +
LSTPHAN, 
+ trend.l=~covars$otuboidist + covars$lstphan) 

>krige<-krige.conv(nicola, loc=predpoints, krige=kcontrol) 

Then I view it using the image function: 

>image(krige, col=gray(seq(1, 0.2, l=100))) 

The resulting image is clearly wrong with a regular stepped line appearing
diagonally across the image, and the predicted values do not coincide with
the actual observed data at all.  I've included the predicted data image, as
well as the predicted image overlaid with the data points.

 

Can anyone give me any pointers of why this may be going wrong?  I've tried
the same thing many times having changed everything I can think of that
might be causing the problem. 

Thanks in advance, 

Nicola

 





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/4c868514/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 36113 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/4c868514/attachment.jpe>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 17791 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/4c868514/attachment-0001.jpe>

From Thierry.ONKELINX at inbo.be  Fri Aug 29 10:51:40 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 29 Aug 2008 10:51:40 +0200
Subject: [R-sig-Geo] Prediction locations for kriging in geoR
In-Reply-To: <000c01c909af$e084dbe0$21de4e98@VCS126114>
References: <000c01c909af$e084dbe0$21de4e98@VCS126114>
Message-ID: <2E9C414912813E4EB981326983E0A104054769A6@inboexch.inbo.be>


Dear Nicola,

I think that since the covars contains the locations of the predpoints
you don't need two dataframes. Futhermore make sure that the names of
the covars are identical (including capitalisation).

mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
trend=~OTUBOIDIST + LSTPHAN)
kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~OTUBOIDIST
+ LSTPHAN, trend.l=~OTUBOIDIST + LSTPHAN)
krige<-krige.conv(nicola, loc=covars, krige=kcontrol)

Does that work?

HTH,

Thierry
------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey




________________________________

Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Nicola Batchelor
Verzonden: vrijdag 29 augustus 2008 10:19
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] Prediction locations for kriging in geoR



Hi,

Im using geoR and I'm trying to do some predictions, based on an
external trend, using ordinary kriging.



However, I seem to be getting some strange results from my kriging,
which I think must have something to do with a problem with my
prediction points.

I have my geodata object (called nicola), my prediction points
(predpoints, imported from a csv containing only the x and y coordinated
of the prediction locations) and my covariate data at each of the
prediction points (covars, imported from a csv containing the x and y
coordinates of the prediction locations, plus the values of the two
covariates I want to use at each of the prediction locations).

>predpoints<-read.csv(file="C:\\Documents and Settings\\s9901315\\My
+ Documents\\Uni\\Data\\Work\\Case control study\\Full study
area\\R\\Files for analysis\\Prediction
+ points\\predpoints.csv", header=FALSE, sep=",")

>covars<-read.csv(file="C:\\Documents and Settings\\s9901315\\My
+ Documents\\Uni\\Data\\Work\\Case control study\\Full study
area\\R\\Files for analysis\\Covariate
+ data\\covars.csv", header=TRUE, sep=",")

The final model is defined using "OTUBOIDIST" and "LSTPHAN" as external
covariates:

>mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
trend=~OTUBOIDIST +
+ LSTPHAN)

and then I carry out the kriging using the model "mlx2", prediction
points "predpoints", and covariate data "covars" :

>kcontrol<-krige.control(obj.m=mlx2, type.krige="ok",
trend.d=~OTUBOIDIST + LSTPHAN,
+ trend.l=~covars$otuboidist + covars$lstphan)

>krige<-krige.conv(nicola, loc=predpoints, krige=kcontrol)

Then I view it using the image function:

>image(krige, col=gray(seq(1, 0.2, l=100)))

The resulting image is clearly wrong with a regular stepped line
appearing diagonally across the image, and the predicted values do not
coincide with the actual observed data at all.  I've included the
predicted data image, as well as the predicted image overlaid with the
data points.



Can anyone give me any pointers of why this may be going wrong?  I've
tried the same thing many times having changed everything I can think of
that might be causing the problem.

Thanks in advance,

Nicola



 



Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in  this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/eab0e3cf/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 17791 bytes
Desc: image001.jpg
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/eab0e3cf/attachment.jpe>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 36113 bytes
Desc: image002.jpg
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/eab0e3cf/attachment-0001.jpe>

From N.A.Batchelor at sms.ed.ac.uk  Fri Aug 29 11:55:27 2008
From: N.A.Batchelor at sms.ed.ac.uk (Nicola Batchelor)
Date: Fri, 29 Aug 2008 10:55:27 +0100
Subject: [R-sig-Geo] Prediction locations for kriging in geoR
In-Reply-To: <2E9C414912813E4EB981326983E0A104054769A6@inboexch.inbo.be>
References: <000c01c909af$e084dbe0$21de4e98@VCS126114>
	<2E9C414912813E4EB981326983E0A104054769A6@inboexch.inbo.be>
Message-ID: <002601c909bd$65b1f480$21de4e98@VCS126114>

Hi Thierry,

 

Thanks for the suggestions.  I hadn't tried that previously, but no it
doesn't make any difference unfortunately.

I removed the separate predpoints dataframe from it and tried using the x
and y values from the covars for the prediction, but got the following:

 

> kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~otuboidist +
lstphan, trend.l=~covars$otuboidist + covars$lstphan) 

 

> krige<-krige.conv(nicola, loc=covars, krige=kcontrol)

 

krige.conv: model with mean defined by covariates provided by the user

krige.conv: Kriging performed using global neighbourhood 

Warning message:

locations provided with a matrix or data-frame with more than 2 columns.
Only the first two columns used as coordinates in:
.check.locations(locations) 

 

> image(krige, col=gray(seq(1, 0.2, l=100)))

 

Error in image.kriging(krige, col = gray(seq(1, 0.2, l = 100))) : 

        locations must be a matrix or data-frame with two columns

 

Removing the prediction locations from the covariate dataframe made no
difference.

Also, changing the covariate names didn't make any difference - I still got
the odd prediction results.

 

I'm thinking perhaps it's my prediction grid.I created it in Arc as a shape
file with points for each prediction locations, and then saved the points as
a .csv file.  Perhaps the problem has something to do with this?  But I'm
really a total novice to both geostatistics and to R, so I could be very
wrong!

 

Thanks,

Nicola

 

  _____  

From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be] 
Sent: 29 August 2008 09:52
To: Nicola Batchelor; r-sig-geo at stat.math.ethz.ch
Subject: RE: [R-sig-Geo] Prediction locations for kriging in geoR

 

Dear Nicola,

 

I think that since the covars contains the locations of the predpoints you
don't need two dataframes. Futhermore make sure that the names of the covars
are identical (including capitalisation).

 

mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
trend=~OTUBOIDIST + LSTPHAN) 
kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~OTUBOIDIST +
LSTPHAN, trend.l=~OTUBOIDIST + LSTPHAN) 
krige<-krige.conv(nicola, loc=covars, krige=kcontrol)

 

Does that work?

 

HTH,

 

Thierry

----------------------------------------------------------------------------
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than
asking him to perform a post-mortem examination: he may be able to say what
the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

 

 

  _____  

Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Nicola Batchelor
Verzonden: vrijdag 29 augustus 2008 10:19
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] Prediction locations for kriging in geoR

Hi, 

Im using geoR and I'm trying to do some predictions, based on an external
trend, using ordinary kriging.

 

However, I seem to be getting some strange results from my kriging, which I
think must have something to do with a problem with my prediction points. 

I have my geodata object (called nicola), my prediction points (predpoints,
imported from a csv containing only the x and y coordinated of the
prediction locations) and my covariate data at each of the prediction points
(covars, imported from a csv containing the x and y coordinates of the
prediction locations, plus the values of the two covariates I want to use at
each of the prediction locations). 

>predpoints<-read.csv(file="C:\\Documents and Settings\\s9901315\\My 
+ Documents\\Uni\\Data\\Work\\Case control study\\Full study area\\R\\Files
for analysis\\Prediction 
+ points\\predpoints.csv", header=FALSE, sep=",") 

>covars<-read.csv(file="C:\\Documents and Settings\\s9901315\\My 
+ Documents\\Uni\\Data\\Work\\Case control study\\Full study area\\R\\Files
for analysis\\Covariate 
+ data\\covars.csv", header=TRUE, sep=",") 

The final model is defined using "OTUBOIDIST" and "LSTPHAN" as external
covariates: 

>mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
trend=~OTUBOIDIST + 
+ LSTPHAN) 

and then I carry out the kriging using the model "mlx2", prediction points
"predpoints", and covariate data "covars" : 

>kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~OTUBOIDIST +
LSTPHAN, 
+ trend.l=~covars$otuboidist + covars$lstphan) 

>krige<-krige.conv(nicola, loc=predpoints, krige=kcontrol) 

Then I view it using the image function: 

>image(krige, col=gray(seq(1, 0.2, l=100))) 

The resulting image is clearly wrong with a regular stepped line appearing
diagonally across the image, and the predicted values do not coincide with
the actual observed data at all.  I've included the predicted data image, as
well as the predicted image overlaid with the data points.

 

Can anyone give me any pointers of why this may be going wrong?  I've tried
the same thing many times having changed everything I can think of that
might be causing the problem. 

Thanks in advance, 

Nicola

 



Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
en binden het INBO onder geen enkel beding, zolang dit bericht niet
bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the
writer and may not be regarded as stating an official position of INBO, as
long as the message is not confirmed by a duly signed document
	


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/a8c7e235/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 17791 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/a8c7e235/attachment.jpe>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 36113 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/a8c7e235/attachment-0001.jpe>

From p.vanbreugel at gmail.com  Fri Aug 29 12:03:50 2008
From: p.vanbreugel at gmail.com (Paulo van Breugel)
Date: Fri, 29 Aug 2008 13:03:50 +0300
Subject: [R-sig-Geo] Use of formula in spplot function
Message-ID: <48B7C986.8020203@gmail.com>

Dear all,

I am exploring the options of plotting data using the sp package. It is, 
after some trial and error, not too difficult to produce nice looking 
maps combining polygon, line and grid data with spplot. One thing I 
haven't been able to figure out though is the use of the argument 
'formula' in the spplot.grid function. Does anyone has a good example 
explaining its use?

Best regards

Paulo van Breugel



From paulojus at c3sl.ufpr.br  Fri Aug 29 14:57:53 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 29 Aug 2008 09:57:53 -0300 (BRT)
Subject: [R-sig-Geo] Prediction locations for kriging in geoR
In-Reply-To: <002601c909bd$65b1f480$21de4e98@VCS126114>
References: <000c01c909af$e084dbe0$21de4e98@VCS126114>
	<2E9C414912813E4EB981326983E0A104054769A6@inboexch.inbo.be>
	<002601c909bd$65b1f480$21de4e98@VCS126114>
Message-ID: <Pine.LNX.4.58.0808290951140.1092@macalan.c3sl.ufpr.br>

Dear Nicola

In principle your original code looks OK to me.
geoR as it is now does not require covariates been speeled the same way
at data and prediction objects.
If you could send me data and prediction locations (or a subset of then)
with the commands I can look at it more carefully

Regarding preditions at data locations they do not need to coincide with
the data for every case. In summary:

- if the nugget parameter $ \tau^2 = 0 $ observed and predicted values
will coincide

- if the nugget parameter $ \tau^2 > 0 $ observed and predicted values
will coincide of this parameter is regarded as microscale variation,
but not if regarded as measurement error.

For the latter this is controlled by the argument "micro.scale"
in krige.control().
It defaults to 0, and can take values between 0 and the value of the
nugget.
The default corresponds to assume the nugget is measurement error
variance


Best
P.J.



Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Fri, 29 Aug 2008, Nicola Batchelor wrote:

> Hi Thierry,
>
>
>
> Thanks for the suggestions.  I hadn't tried that previously, but no it
> doesn't make any difference unfortunately.
>
> I removed the separate predpoints dataframe from it and tried using the x
> and y values from the covars for the prediction, but got the following:
>
>
>
> > kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~otuboidist +
> lstphan, trend.l=~covars$otuboidist + covars$lstphan)
>
>
>
> > krige<-krige.conv(nicola, loc=covars, krige=kcontrol)
>
>
>
> krige.conv: model with mean defined by covariates provided by the user
>
> krige.conv: Kriging performed using global neighbourhood
>
> Warning message:
>
> locations provided with a matrix or data-frame with more than 2 columns.
> Only the first two columns used as coordinates in:
> .check.locations(locations)
>
>
>
> > image(krige, col=gray(seq(1, 0.2, l=100)))
>
>
>
> Error in image.kriging(krige, col = gray(seq(1, 0.2, l = 100))) :
>
>         locations must be a matrix or data-frame with two columns
>
>
>
> Removing the prediction locations from the covariate dataframe made no
> difference.
>
> Also, changing the covariate names didn't make any difference - I still got
> the odd prediction results.
>
>
>
> I'm thinking perhaps it's my prediction grid.I created it in Arc as a shape
> file with points for each prediction locations, and then saved the points as
> a .csv file.  Perhaps the problem has something to do with this?  But I'm
> really a total novice to both geostatistics and to R, so I could be very
> wrong!
>
>
>
> Thanks,
>
> Nicola
>
>
>
>   _____
>
> From: ONKELINX, Thierry [mailto:Thierry.ONKELINX at inbo.be]
> Sent: 29 August 2008 09:52
> To: Nicola Batchelor; r-sig-geo at stat.math.ethz.ch
> Subject: RE: [R-sig-Geo] Prediction locations for kriging in geoR
>
>
>
> Dear Nicola,
>
>
>
> I think that since the covars contains the locations of the predpoints you
> don't need two dataframes. Futhermore make sure that the names of the covars
> are identical (including capitalisation).
>
>
>
> mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
> trend=~OTUBOIDIST + LSTPHAN)
> kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~OTUBOIDIST +
> LSTPHAN, trend.l=~OTUBOIDIST + LSTPHAN)
> krige<-krige.conv(nicola, loc=covars, krige=kcontrol)
>
>
>
> Does that work?
>
>
>
> HTH,
>
>
>
> Thierry
>
> ----------------------------------------------------------------------------
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than
> asking him to perform a post-mortem examination: he may be able to say what
> the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
>
>
>
>   _____
>
> Van: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Nicola Batchelor
> Verzonden: vrijdag 29 augustus 2008 10:19
> Aan: r-sig-geo at stat.math.ethz.ch
> Onderwerp: [R-sig-Geo] Prediction locations for kriging in geoR
>
> Hi,
>
> Im using geoR and I'm trying to do some predictions, based on an external
> trend, using ordinary kriging.
>
>
>
> However, I seem to be getting some strange results from my kriging, which I
> think must have something to do with a problem with my prediction points.
>
> I have my geodata object (called nicola), my prediction points (predpoints,
> imported from a csv containing only the x and y coordinated of the
> prediction locations) and my covariate data at each of the prediction points
> (covars, imported from a csv containing the x and y coordinates of the
> prediction locations, plus the values of the two covariates I want to use at
> each of the prediction locations).
>
> >predpoints<-read.csv(file="C:\\Documents and Settings\\s9901315\\My
> + Documents\\Uni\\Data\\Work\\Case control study\\Full study area\\R\\Files
> for analysis\\Prediction
> + points\\predpoints.csv", header=FALSE, sep=",")
>
> >covars<-read.csv(file="C:\\Documents and Settings\\s9901315\\My
> + Documents\\Uni\\Data\\Work\\Case control study\\Full study area\\R\\Files
> for analysis\\Covariate
> + data\\covars.csv", header=TRUE, sep=",")
>
> The final model is defined using "OTUBOIDIST" and "LSTPHAN" as external
> covariates:
>
> >mlx2<-likfit(nicola, cov.model="mat", kap=0.5, ini=c(0.6, 20), nug=0.3,
> trend=~OTUBOIDIST +
> + LSTPHAN)
>
> and then I carry out the kriging using the model "mlx2", prediction points
> "predpoints", and covariate data "covars" :
>
> >kcontrol<-krige.control(obj.m=mlx2, type.krige="ok", trend.d=~OTUBOIDIST +
> LSTPHAN,
> + trend.l=~covars$otuboidist + covars$lstphan)
>
> >krige<-krige.conv(nicola, loc=predpoints, krige=kcontrol)
>
> Then I view it using the image function:
>
> >image(krige, col=gray(seq(1, 0.2, l=100)))
>
> The resulting image is clearly wrong with a regular stepped line appearing
> diagonally across the image, and the predicted values do not coincide with
> the actual observed data at all.  I've included the predicted data image, as
> well as the predicted image overlaid with the data points.
>
>
>
> Can anyone give me any pointers of why this may be going wrong?  I've tried
> the same thing many times having changed everything I can think of that
> might be causing the problem.
>
> Thanks in advance,
>
> Nicola
>
>
>
>
>
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer
> en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document
>
>
>
>



From john.callahan at udel.edu  Fri Aug 29 15:38:06 2008
From: john.callahan at udel.edu (John Callahan)
Date: Fri, 29 Aug 2008 09:38:06 -0400
Subject: [R-sig-Geo] Getting started with RGeo
Message-ID: <48B7FBBE.4000907@udel.edu>

I am just getting started using R for spatial analysis.  I am long-time 
user of basic statistics through ESRI products, some SPSS, and a few 
other code snippets here and there.  However, I love what I see in R so 
far.  And there's a growing attraction to R in my organization, for geo 
and non-geo purposes.  I'm also looking into using R through some of the 
GIS software I'm more familiar with, like Quantum GIS, GRASS, and SAGA. 


I just downloaded R 2.7.2 and getting the basics going there.  For 
spatial analysis, which packages do I start with?  Looking through the 
list at http://lib.stat.cmu.edu/R/CRAN/ and reading 
http://www.sal.uiuc.edu/tools/tools-sum/rgeo/r-spatial-projects, there 
are so many.  And my gut feeling tells me that some functions in these 
packages are duplicated in others.  Maybe some packages are obsolete now 
with support pushed toward a newer, richer package. 


The analysis I'll be doing are relatively common techniques. Things 
like: interpolations/kriging, contour and DEM creation from points, 
hillshade/aspect creation, spatial autocorrelation, regression, PCA, 
cluster/hot-spot analysis, plotting/mapping, and basic grid algebra as 
well.  I'm sure I'll get into more as I work through.  Which packages do 
you recommend I start with?


- John

****************************************
John Callahan
Geospatial Application Developer

Delaware Geological Survey
University of Delaware
227 Academy St, Newark DE 19716-7501
Tel: (302) 831-3584  

Email: john.callahan at udel.edu
http://www.dgs.udel.edu



From yud at mail.montclair.edu  Fri Aug 29 15:51:12 2008
From: yud at mail.montclair.edu (Danlin Yu)
Date: Fri, 29 Aug 2008 09:51:12 -0400
Subject: [R-sig-Geo] Getting started with RGeo
In-Reply-To: <48B7FBBE.4000907@udel.edu>
References: <48B7FBBE.4000907@udel.edu>
Message-ID: <48B7FED0.8050706@mail.montclair.edu>

John:

Depending on what datasets you have and what type of analysis you'll 
most likely to conduct, there are many choices.

Personally, I started almost the same as you around 4 years ago, and 
choose SPDEP as my get-in package. Why not take a look at?

Good luck.

Best,
Danlin

John Callahan wrote:
> I am just getting started using R for spatial analysis.  I am 
> long-time user of basic statistics through ESRI products, some SPSS, 
> and a few other code snippets here and there.  However, I love what I 
> see in R so far.  And there's a growing attraction to R in my 
> organization, for geo and non-geo purposes.  I'm also looking into 
> using R through some of the GIS software I'm more familiar with, like 
> Quantum GIS, GRASS, and SAGA.
>
> I just downloaded R 2.7.2 and getting the basics going there.  For 
> spatial analysis, which packages do I start with?  Looking through the 
> list at http://lib.stat.cmu.edu/R/CRAN/ and reading 
> http://www.sal.uiuc.edu/tools/tools-sum/rgeo/r-spatial-projects, there 
> are so many.  And my gut feeling tells me that some functions in these 
> packages are duplicated in others.  Maybe some packages are obsolete 
> now with support pushed toward a newer, richer package.
>
> The analysis I'll be doing are relatively common techniques. Things 
> like: interpolations/kriging, contour and DEM creation from points, 
> hillshade/aspect creation, spatial autocorrelation, regression, PCA, 
> cluster/hot-spot analysis, plotting/mapping, and basic grid algebra as 
> well.  I'm sure I'll get into more as I work through.  Which packages 
> do you recommend I start with?
>
>
> - John
>
> ****************************************
> John Callahan
> Geospatial Application Developer
>
> Delaware Geological Survey
> University of Delaware
> 227 Academy St, Newark DE 19716-7501
> Tel: (302) 831-3584 
> Email: john.callahan at udel.edu
> http://www.dgs.udel.edu
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu



From paulojus at c3sl.ufpr.br  Fri Aug 29 16:33:14 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 29 Aug 2008 11:33:14 -0300 (BRT)
Subject: [R-sig-Geo] Getting started with RGeo
In-Reply-To: <48B7FBBE.4000907@udel.edu>
References: <48B7FBBE.4000907@udel.edu>
Message-ID: <Pine.LNX.4.58.0808291132150.7862@bowmore.c3sl.ufpr.br>

Roger Bivand have already put a lot of information on this on the
description of the CRAN task view:

http://cran-r.c3sl.ufpr.br/web/views/Spatial.html

this is certainly the first place to look at!


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Fri, 29 Aug 2008, John Callahan wrote:

> I am just getting started using R for spatial analysis.  I am long-time
> user of basic statistics through ESRI products, some SPSS, and a few
> other code snippets here and there.  However, I love what I see in R so
> far.  And there's a growing attraction to R in my organization, for geo
> and non-geo purposes.  I'm also looking into using R through some of the
> GIS software I'm more familiar with, like Quantum GIS, GRASS, and SAGA.
>
>
> I just downloaded R 2.7.2 and getting the basics going there.  For
> spatial analysis, which packages do I start with?  Looking through the
> list at http://lib.stat.cmu.edu/R/CRAN/ and reading
> http://www.sal.uiuc.edu/tools/tools-sum/rgeo/r-spatial-projects, there
> are so many.  And my gut feeling tells me that some functions in these
> packages are duplicated in others.  Maybe some packages are obsolete now
> with support pushed toward a newer, richer package.
>
>
> The analysis I'll be doing are relatively common techniques. Things
> like: interpolations/kriging, contour and DEM creation from points,
> hillshade/aspect creation, spatial autocorrelation, regression, PCA,
> cluster/hot-spot analysis, plotting/mapping, and basic grid algebra as
> well.  I'm sure I'll get into more as I work through.  Which packages do
> you recommend I start with?
>
>
> - John
>
> ****************************************
> John Callahan
> Geospatial Application Developer
>
> Delaware Geological Survey
> University of Delaware
> 227 Academy St, Newark DE 19716-7501
> Tel: (302) 831-3584
>
> Email: john.callahan at udel.edu
> http://www.dgs.udel.edu
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From arosa at ist.utl.pt  Fri Aug 29 17:07:27 2008
From: arosa at ist.utl.pt (Rosa Trancoso)
Date: Fri, 29 Aug 2008 15:07:27 +0000
Subject: [R-sig-Geo] plot projected map
Message-ID: <ec30342f0808290807o12f2c1c6pa02140ecba73ef96@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/3f982e22/attachment.pl>

From dylan.beaudette at gmail.com  Fri Aug 29 17:52:26 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Fri, 29 Aug 2008 08:52:26 -0700
Subject: [R-sig-Geo] plot projected map
In-Reply-To: <ec30342f0808290807o12f2c1c6pa02140ecba73ef96@mail.gmail.com>
References: <ec30342f0808290807o12f2c1c6pa02140ecba73ef96@mail.gmail.com>
Message-ID: <200808290852.26867.dylan.beaudette@gmail.com>

On Friday 29 August 2008, Rosa Trancoso wrote:
> Hello,
>
> I have the same problem as Costas Douvis, reported in
> https://stat.ethz.ch/pipermail/r-sig-geo/2008-June/003713.html
>
> I have a matrix of values, a matrix of latitudes and a matrix of
> longitudes. The map is "rectangular" in the Lambert projection. So I did
> the following:
>
> library(sp)
> df <- data.frame(lat=as.numeric(xlat), lon=as.numeric(xlon),
> z=as.numeric(hgt))
> coordinates(df) <- ~lon+lat         # SpatialPointsDataFrame
> proj4string(df) <- CRS("+proj=lcc +a=637000 +lat_1=30 +lat_2=60 +lat_0=40
> +lon_0=-7.5")
> spplot(df, scales=list(draw=TRUE))
>
> But the map is no projected (it should be a rectangle),
>
> As I want to have lat/lon on the axis of the map, and automatically produce
> lots of maps, converting everything to lcc is not straightforward.
>
> I am missing something? Any other packages?
>

I don't often perform spatial transforms in R, but it looks like there is a 
fundamental flaw in your code, and it should look something like this:

1. setup SpatialPointsDataFrame
2. assign the CRS as 'proj=lonlat datum=...'
3. invoke the projection method, with the target projection = "+proj=lcc 
+a=637000 +lat_1=30 +lat_2=60 +lat_0=40 +lon_0=-7.5"

4. the result should be in the target projection.

Cheers,

Dylan


-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From arosa at ist.utl.pt  Fri Aug 29 18:39:51 2008
From: arosa at ist.utl.pt (Rosa Trancoso)
Date: Fri, 29 Aug 2008 16:39:51 +0000
Subject: [R-sig-Geo] plot projected map
In-Reply-To: <200808290852.26867.dylan.beaudette@gmail.com>
References: <ec30342f0808290807o12f2c1c6pa02140ecba73ef96@mail.gmail.com>
	<200808290852.26867.dylan.beaudette@gmail.com>
Message-ID: <ec30342f0808290939s23324875q2ae03a4b997b630b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080829/945c54bf/attachment.pl>

From p.hiemstra at geo.uu.nl  Fri Aug 29 20:30:57 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Fri, 29 Aug 2008 20:30:57 +0200
Subject: [R-sig-Geo] Use of formula in spplot function
In-Reply-To: <48B7C986.8020203@gmail.com>
References: <48B7C986.8020203@gmail.com>
Message-ID: <48B84061.8070408@geo.uu.nl>

Paulo van Breugel schreef:
> Dear all,
>
> I am exploring the options of plotting data using the sp package. It 
> is, after some trial and error, not too difficult to produce nice 
> looking maps combining polygon, line and grid data with spplot. One 
> thing I haven't been able to figure out though is the use of the 
> argument 'formula' in the spplot.grid function. Does anyone has a good 
> example explaining its use?
>
> Best regards
>
> Paulo van Breugel
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
Hi,

I've been using spplot a lot over the past two years and I've never used 
the formula argument. Why do you want to use it? If you are determined 
to use it, the documentation of spplot says :

formula     optional; may be useful to plot a transformed value. 
Defaults to z~x+y for single and z~x+y|name for multiple attributes; use 
e.g. exp(x)~x+y|name to plot the exponent of the z-variable

Why the formula argument looks like this can be traced back to the fact 
that the lattice function levelplot is used to make the plots. See 
?levelplot for extra information (see the x argument).

cheers and good luck!
Paul

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:     +31302535773
Fax:    +31302531145
http://intamap.geo.uu.nl/~paul



From v.gomezrubio at imperial.ac.uk  Fri Aug 29 21:36:12 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Fri, 29 Aug 2008 20:36:12 +0100
Subject: [R-sig-Geo] Getting started with RGeo
In-Reply-To: <48B7FBBE.4000907@udel.edu>
References: <48B7FBBE.4000907@udel.edu>
Message-ID: <1220038572.8078.1.camel@fh-vrubio>

Hi,

You can check this course materials

http://www.bias-project.org.uk/ASDARcourse/

and start with the packages that you think that will be of most interest
to you. It really depends on what you want to do (geostatistics, point
patterns, GIS, etc.).

Good luck!

Virgilio



