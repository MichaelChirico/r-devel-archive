From Roger.Bivand at nhh.no  Sun Nov  1 11:20:04 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 1 Nov 2009 11:20:04 +0100 (CET)
Subject: [R-sig-Geo] write.sn2gwt and lost region.id
In-Reply-To: <Gophermail.2.0.0910301441200.10647@vs-w.tc.umn.edu>
References: <Gophermail.2.0.0910292234110.4646@vs-a.tc.umn.edu>
	<alpine.LRH.2.00.0910301439420.25398@reclus.nhh.no>
	<Gophermail.2.0.0910301441200.10647@vs-w.tc.umn.edu>
Message-ID: <alpine.LRH.2.00.0911011114160.31553@reclus.nhh.no>

On Fri, 30 Oct 2009, pota0011 at umn.edu wrote:

> I'm mostly working with classic GeoDa. It uses the legacy GWT format when 
> creating/opening GWT files with Rec_Num 1,..N IDs. However, write.sn2gwt 
> always uses the new format with the "shpfile" and "ind" fields, even though 
> it doesn't pass region.ids. So it seems to me that one has to edit the header 
> file to the old format by deleting everything by the number of IDs, before 
> classic GeoDa can read the file. It would be great if write.sn2gwt could 
> either pass the region.ids or alternatively have an option for creating the 
> GWT file in legacy format. At least that's how I'm understanding things; let 
> me know if there is something I'm missing.

OK, I understand. Please try pre-release spdep_0.4.51 from R-forge:

install.packages("spdep", repos="http://R-Forge.R-project.org")

once you see that version number on:

https://r-forge.r-project.org/R/?group_id=182

at the foot of the page, and last change something like today. Let me know 
if it solves your problem - added legacy= argument; you could set 
legacy=TRUE to only get the number of observations on the first line.

Hope this helps,

Roger

PS. The release will also have impacts components for spatial lag and 
spatial Durbin models, for each power of the weights matrix, for those 
users who might need this kind of detail.

>
> Thanks, on:
> John
>
> On Oct 30 2009, Roger Bivand wrote:
>
>> On Fri, 29 Oct 2009, pota0011 at umn.edu wrote:
>> 
>>> Hi,
>>> I wanted to confirm that there is still no straightforward way to pass 
>>> region.id values to a GWT file when using write.sn2gwt, as this post from 
>>> two
>>> years ago suggests:
>>> http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg02209.html
>>> 
>>> GeoDa needs the particular region.id values to, for example, make 
>>> histograms
>>> from weight files. It seems that these are passed fine for GAL files with
>>> write.nb.gal, but not GWT files. Does anyone know of a work-around?
>> 
>> I'll try to implement this - which version of GeoDa and/or OpenGeoDa are 
>> you using? I think the revision works for classic GeoDa, but OpenGeoDa 
>> cannot open GWT files that it itself has created when the IDs are not 1, 
>> ..., N.
>> 
>> Best wishes,
>> 
>> Roger
>> 
>>> 
>>> Thanks,
>>> John
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From spluque at gmail.com  Mon Nov  2 21:05:17 2009
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 02 Nov 2009 14:05:17 -0600
Subject: [R-sig-Geo] flip SpatialGridDataFrame across axis
Message-ID: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>

Hi,

After importing a grid with readGDAL(), a `SpatialGridDataFrame' object
is produced that looks correct, except the y-axis is flipped upside
down, despite the note in the "Value" section in ?readGDAL.  So I need
to flip the grid across the horizontal axis, and searching the archives
points to an old reference to elide() in maptools.  However, this
doesn't take a `SpatialGridDataFrame', so I'd appreciate any suggestions
for better alternatives.  Thanks.

Cheers,

-- 
Seb


From mdw at purdue.edu  Mon Nov  2 21:19:58 2009
From: mdw at purdue.edu (Mark Daniel Ward)
Date: Mon, 02 Nov 2009 15:19:58 -0500
Subject: [R-sig-Geo] need a Windows binary for Rcartogram from omegahat
In-Reply-To: <46E4D06F-BD41-4F8F-8BF5-C5D42D1DA656@r-project.org>
References: <1256096662.4ade83965898f@webmail.purdue.edu>
	<46E4D06F-BD41-4F8F-8BF5-C5D42D1DA656@r-project.org>
Message-ID: <4AEF3EEE.2070808@purdue.edu>

Greetings!  I'm about to have a lab for my students using the Rcartogram 
library.

I cannot get the Rcartogram library installed on the Windows PC's, 
because they do not have the fftw library pre-installed.  To compile 
from source, the students also appear to need to have several auxiliary 
pieces of software installed (such as basics, including perl and bash 
and gcc).  This is perhaps too much to expect from my students.  (I have 
these on my Mac, but they will not have them on their Windows computers.)

Has anyone already built a Windows binary of the Rcartogram library that 
includes the fftw as part of the installation?  I checked earlier in the 
year on the mailing lists, and the answer was negative, but I'm very 
eager to know if anyone can help in this regard.  We are failing 
miserably at building the Windows source for Rcartogram.

Thank you in advance for any quick advice that you can offer.  I 
appreciate it very much.

P.S.  The computer staff already installed the fftw library for me on 
the Mac OS X lab computers using the following commands, suggested 
kindly to me on the R for Mac mailing list:
curl -O http://r.research.att.com/libs/fftw-3.2.2-darwin9-bin4.tar.gz
sudo tar fvxz fftw-3.2.2-darwin9-bin4.tar.gz -C /
Afterwards, I am able to successfully install the Rcartogram library 
from source using:
install.packages("Rcartogram", repos = "http://www.omegahat.org/R", type 
= "source")

Mark


From tech_dev at wildintellect.com  Mon Nov  2 21:34:12 2009
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Mon, 02 Nov 2009 12:34:12 -0800
Subject: [R-sig-Geo] need a Windows binary for Rcartogram from omegahat
In-Reply-To: <4AEF3EEE.2070808@purdue.edu>
References: <1256096662.4ade83965898f@webmail.purdue.edu>	<46E4D06F-BD41-4F8F-8BF5-C5D42D1DA656@r-project.org>
	<4AEF3EEE.2070808@purdue.edu>
Message-ID: <4AEF4244.6080708@wildintellect.com>

Mark Daniel Ward wrote:
> Greetings!  I'm about to have a lab for my students using the Rcartogram
> library.
> 
> I cannot get the Rcartogram library installed on the Windows PC's,
> because they do not have the fftw library pre-installed.  To compile
> from source, the students also appear to need to have several auxiliary
> pieces of software installed (such as basics, including perl and bash
> and gcc).  This is perhaps too much to expect from my students.  (I have
> these on my Mac, but they will not have them on their Windows computers.)
> 
> Has anyone already built a Windows binary of the Rcartogram library that
> includes the fftw as part of the installation?  I checked earlier in the
> year on the mailing lists, and the answer was negative, but I'm very
> eager to know if anyone can help in this regard.  We are failing
> miserably at building the Windows source for Rcartogram.
> 
> Thank you in advance for any quick advice that you can offer.  I
> appreciate it very much.
> 
> P.S.  The computer staff already installed the fftw library for me on
> the Mac OS X lab computers using the following commands, suggested
> kindly to me on the R for Mac mailing list:
> curl -O http://r.research.att.com/libs/fftw-3.2.2-darwin9-bin4.tar.gz
> sudo tar fvxz fftw-3.2.2-darwin9-bin4.tar.gz -C /
> Afterwards, I am able to successfully install the Rcartogram library
> from source using:
> install.packages("Rcartogram", repos = "http://www.omegahat.org/R", type
> = "source")
> 
> Mark
> 


As an indirect answer/back-up plan if you can't get the windows mess
built you could try the latest Live GIS DVD/Virtual Machine from OSGeo.
http://download.osgeo.org/livedvd/

VirtualBox, VMWarePlayer etc are all available for free to run the vm on
a windows desktop.

R is already installed, and if you can do the library install once on
the vm before giving it to the students or provide a script to the
install I can help you make sure it works.

Alex


From mdsumner at gmail.com  Mon Nov  2 21:40:59 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 3 Nov 2009 07:40:59 +1100
Subject: [R-sig-Geo] flip SpatialGridDataFrame across axis
In-Reply-To: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>
References: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>
Message-ID: <522664f80911021240t549348fbra208152741795abd@mail.gmail.com>

Hi Sebastian, I think the "north-south" note is referring to
possibly-rotated grids (using the transform values supported by many
formats) - not to "north vs. south" in orientation.

You can easily flip a grid by reverting it (one band at a time) to an
xyz image and using indexing. I find this approach the least confusing
and easily repeatable.

library(rgdal)
data(meuse.grid)
coordinates(meuse.grid) <- ~x+y
gridded(meuse.grid) <- TRUE
fullgrid(meuse.grid) <- TRUE
image(meuse.grid[3])

## note this method only works on single bands at once
x1 <- as.image.SpatialGridDataFrame(meuse.grid[3])

## reverse the Y by indexing in to the (image) xyz list
x1$z <- x1$z[,ncol(x1$z):1]

## convert to SGDF
flipY <- image2Grid(x1, p4 = as.character(proj4string(meuse.grid)))
contour(flipY, add = TRUE)

It would not be difficult to adapt this to flip each band
sequentially, and use the internal arrangement of the
SpatialGrid/Pixels classes directly - but this is enough for me.

Regards, Mike.

On Tue, Nov 3, 2009 at 7:05 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
> Hi,
>
> After importing a grid with readGDAL(), a `SpatialGridDataFrame' object
> is produced that looks correct, except the y-axis is flipped upside
> down, despite the note in the "Value" section in ?readGDAL. ?So I need
> to flip the grid across the horizontal axis, and searching the archives
> points to an old reference to elide() in maptools. ?However, this
> doesn't take a `SpatialGridDataFrame', so I'd appreciate any suggestions
> for better alternatives. ?Thanks.
>
> Cheers,
>
> --
> Seb
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From spluque at gmail.com  Mon Nov  2 21:49:54 2009
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 02 Nov 2009 14:49:54 -0600
Subject: [R-sig-Geo] flip SpatialGridDataFrame across axis
In-Reply-To: <522664f80911021240t549348fbra208152741795abd@mail.gmail.com>
	(Michael Sumner's message of "Tue, 3 Nov 2009 07:40:59 +1100")
References: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>
	<522664f80911021240t549348fbra208152741795abd@mail.gmail.com>
Message-ID: <87tyxcird9.fsf@kolob.sebmags.homelinux.org>

On Tue, 3 Nov 2009 07:40:59 +1100,
Michael Sumner <mdsumner at gmail.com> wrote:

> Hi Sebastian, I think the "north-south" note is referring to
> possibly-rotated grids (using the transform values supported by many
> formats) - not to "north vs. south" in orientation.

> You can easily flip a grid by reverting it (one band at a time) to an
> xyz image and using indexing. I find this approach the least confusing
> and easily repeatable.

[...]

Thanks for the quick reply Mike!!


Cheers,

-- 
Seb


From mdw at purdue.edu  Mon Nov  2 21:53:15 2009
From: mdw at purdue.edu (Mark Daniel Ward)
Date: Mon,  2 Nov 2009 15:53:15 -0500
Subject: [R-sig-Geo] need a Windows binary for Rcartogram from omegahat
In-Reply-To: <4AEF4244.6080708@wildintellect.com>
References: <1256096662.4ade83965898f@webmail.purdue.edu>
	<46E4D06F-BD41-4F8F-8BF5-C5D42D1DA656@r-project.org>
	<4AEF3EEE.2070808@purdue.edu> <4AEF4244.6080708@wildintellect.com>
Message-ID: <1257195195.4aef46bb552fa@webmail.purdue.edu>

Dear Alex,

Thank you for your suggestion.  I would be pleased to know more.  This is not an
"optimal" solution, but it might satisfy the students who are on Windows
machines.  I'll send you a PM.

Mark



Quoting Alex Mandel <tech_dev at wildintellect.com>:

> Mark Daniel Ward wrote:
> > Greetings!  I'm about to have a lab for my students using the Rcartogram
> > library.
> > 
> > I cannot get the Rcartogram library installed on the Windows PC's,
> > because they do not have the fftw library pre-installed.  To compile
> > from source, the students also appear to need to have several auxiliary
> > pieces of software installed (such as basics, including perl and bash
> > and gcc).  This is perhaps too much to expect from my students.  (I have
> > these on my Mac, but they will not have them on their Windows computers.)
> > 
> > Has anyone already built a Windows binary of the Rcartogram library that
> > includes the fftw as part of the installation?  I checked earlier in the
> > year on the mailing lists, and the answer was negative, but I'm very
> > eager to know if anyone can help in this regard.  We are failing
> > miserably at building the Windows source for Rcartogram.
> > 
> > Thank you in advance for any quick advice that you can offer.  I
> > appreciate it very much.
> > 
> > P.S.  The computer staff already installed the fftw library for me on
> > the Mac OS X lab computers using the following commands, suggested
> > kindly to me on the R for Mac mailing list:
> > curl -O http://r.research.att.com/libs/fftw-3.2.2-darwin9-bin4.tar.gz
> > sudo tar fvxz fftw-3.2.2-darwin9-bin4.tar.gz -C /
> > Afterwards, I am able to successfully install the Rcartogram library
> > from source using:
> > install.packages("Rcartogram", repos = "http://www.omegahat.org/R", type
> > = "source")
> > 
> > Mark
> > 
> 
> 
> As an indirect answer/back-up plan if you can't get the windows mess
> built you could try the latest Live GIS DVD/Virtual Machine from OSGeo.
> http://download.osgeo.org/livedvd/
> 
> VirtualBox, VMWarePlayer etc are all available for free to run the vm on
> a windows desktop.
> 
> R is already installed, and if you can do the library install once on
> the vm before giving it to the students or provide a script to the
> install I can help you make sure it works.
> 
> Alex
>


From mdsumner at gmail.com  Mon Nov  2 22:45:13 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 3 Nov 2009 08:45:13 +1100
Subject: [R-sig-Geo] flip SpatialGridDataFrame across axis
In-Reply-To: <87tyxcird9.fsf@kolob.sebmags.homelinux.org>
References: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>
	<522664f80911021240t549348fbra208152741795abd@mail.gmail.com>
	<87tyxcird9.fsf@kolob.sebmags.homelinux.org>
Message-ID: <522664f80911021345v4c65f4dftf28e9b6f9a5a1a33@mail.gmail.com>

It would be nice if the "[" methods on ?'SpatialGridDataFrame-class'
could perform the same indexing orientation, but that uses the
row/column values for [i,j,...]  to obtain the subsetted cells which
are regridded via SpatialPixels - so the direction is lost. I'm not
sure it's a good idea to modify that - given that the indexing could
be used to subset at the same time - which is probably why the authors
have written it that way.  ;)

But, I've been meaning to try something like this for ages, and this
seems to work:

flipHorizontal <- function(x) {
	if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
SpatialGridDataFrame")
	grd <- getGridTopology(x)
	idx = 1:prod(grd at cells.dim[1:2])
	m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
TRUE)[,grd at cells.dim[1]:1]
	idx = as.vector(t(m))
	x at data <- x at data[idx, TRUE, drop = FALSE]
	x
}

flipVertical <- function(x) {
	if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
SpatialGridDataFrame")
	grd <- getGridTopology(x)
	idx = 1:prod(grd at cells.dim[1:2])
	m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
TRUE)[grd at cells.dim[2]:1, ]
	idx = as.vector(t(m))
	x at data <- x at data[idx, TRUE, drop = FALSE]
	x
}

The approach there is stolen from 'subs.SpatialGridDataFrame' in
sp/R/SpatialGridDataFrame-methods.R - so thanks as ever to the
authors!

Cheers, Mike.

On Tue, Nov 3, 2009 at 7:49 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
> On Tue, 3 Nov 2009 07:40:59 +1100,
> Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Hi Sebastian, I think the "north-south" note is referring to
>> possibly-rotated grids (using the transform values supported by many
>> formats) - not to "north vs. south" in orientation.
>
>> You can easily flip a grid by reverting it (one band at a time) to an
>> xyz image and using indexing. I find this approach the least confusing
>> and easily repeatable.
>
> [...]
>
> Thanks for the quick reply Mike!!
>
>
> Cheers,
>
> --
> Seb
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From mdsumner at gmail.com  Mon Nov  2 22:56:23 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 3 Nov 2009 08:56:23 +1100
Subject: [R-sig-Geo] Fwd:  flip SpatialGridDataFrame across axis
In-Reply-To: <522664f80911021345v4c65f4dftf28e9b6f9a5a1a33@mail.gmail.com>
References: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>
	<522664f80911021240t549348fbra208152741795abd@mail.gmail.com>
	<87tyxcird9.fsf@kolob.sebmags.homelinux.org>
	<522664f80911021345v4c65f4dftf28e9b6f9a5a1a33@mail.gmail.com>
Message-ID: <522664f80911021356n735ab071j323b2dd0b6a05c1@mail.gmail.com>

Ergh, sorry for the update -  a pox on Gmail for sabotaging my
attempts at plain text!  I've attached the functions in a text file to
avoid [ampersand] to " at " conversion ...




---------- Forwarded message ----------
From: Michael Sumner <mdsumner at gmail.com>
Date: Tue, Nov 3, 2009 at 8:45 AM
Subject: Re: [R-sig-Geo] flip SpatialGridDataFrame across axis
To: r-sig-geo at stat.math.ethz.ch


It would be nice if the "[" methods on ?'SpatialGridDataFrame-class'
could perform the same indexing orientation, but that uses the
row/column values for [i,j,...] ?to obtain the subsetted cells which
are regridded via SpatialPixels - so the direction is lost. I'm not
sure it's a good idea to modify that - given that the indexing could
be used to subset at the same time - which is probably why the authors
have written it that way. ?;)

But, I've been meaning to try something like this for ages, and this
seems to work:

flipHorizontal <- function(x) {
? ? ? ?if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
SpatialGridDataFrame")
? ? ? ?grd <- getGridTopology(x)
? ? ? ?idx = 1:prod(grd at cells.dim[1:2])
? ? ? ?m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
TRUE)[,grd at cells.dim[1]:1]
? ? ? ?idx = as.vector(t(m))
? ? ? ?x at data <- x at data[idx, TRUE, drop = FALSE]
? ? ? ?x
}

flipVertical <- function(x) {
? ? ? ?if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
SpatialGridDataFrame")
? ? ? ?grd <- getGridTopology(x)
? ? ? ?idx = 1:prod(grd at cells.dim[1:2])
? ? ? ?m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
TRUE)[grd at cells.dim[2]:1, ]
? ? ? ?idx = as.vector(t(m))
? ? ? ?x at data <- x at data[idx, TRUE, drop = FALSE]
? ? ? ?x
}

The approach there is stolen from 'subs.SpatialGridDataFrame' in
sp/R/SpatialGridDataFrame-methods.R - so thanks as ever to the
authors!

Cheers, Mike.

On Tue, Nov 3, 2009 at 7:49 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
> On Tue, 3 Nov 2009 07:40:59 +1100,
> Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Hi Sebastian, I think the "north-south" note is referring to
>> possibly-rotated grids (using the transform values supported by many
>> formats) - not to "north vs. south" in orientation.
>
>> You can easily flip a grid by reverting it (one band at a time) to an
>> xyz image and using indexing. I find this approach the least confusing
>> and easily repeatable.
>
> [...]
>
> Thanks for the quick reply Mike!!
>
>
> Cheers,
>
> --
> Seb
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: flipSGDF.R
Type: application/octet-stream
Size: 694 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091103/04a86c36/attachment.obj>

From efbustos at uc.cl  Mon Nov  2 23:22:16 2009
From: efbustos at uc.cl (Eduardo Bustos)
Date: Mon, 2 Nov 2009 19:22:16 -0300
Subject: [R-sig-Geo] Various Variograms of gstat package together in a
	single page
Message-ID: <640918380911021422l19e65fe6lfb7f2375f0f88a48@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091102/d01485b5/attachment.pl>

From edzer.pebesma at uni-muenster.de  Tue Nov  3 08:08:32 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 03 Nov 2009 08:08:32 +0100
Subject: [R-sig-Geo] Various Variograms of gstat package together in a
 single page
In-Reply-To: <640918380911021422l19e65fe6lfb7f2375f0f88a48@mail.gmail.com>
References: <640918380911021422l19e65fe6lfb7f2375f0f88a48@mail.gmail.com>
Message-ID: <4AEFD6F0.5000702@uni-muenster.de>


Eduardo Bustos wrote:
> Dear List:
>
> I need  your help. I'm a new user in R ( round two weeks...) and I'm trying
> to make several interpolations in R with Gstat package.
>
> Initially, I have a workbook in MSExcel, with several sheets, which were
> imported using xlsReadWrite package in a list in R (45 data frame in one
> object (class=list))
>
>   
>> d <- as.list(length(z))
>> for (i in 1:length(z))
>>     
> +d[[i]] <- read.xls('Tablas_puntos.xls', colNames=TRUE, sheet = i)
>
> Later, the data frames were convert to explicity-spatial,using the sp
> package (I have followed the instructions of the tecnical note of D.G
> Rossiter --> http://www.itc.nl/~rossiter/teach/R/R_ck.pdf).
>
> Finally, I create an object (list) with 45 variograms for each one of the
> data sets.
>
>   
>> v.d.temp <- as.list(length(z))
>> for(i in 1:length(z))
>>     
> +v.d.temp[[i]] <- variogram(TempC ~1, data= d.temp[[i]], cutoff=25000,
> width=200)
>
> At this point, everything works OK:
>
>  - The final question: How to putt several of these variogram graphics
> together in a single page ?
>
> I tried with par(mfrow=c(n,m)) in  together with loops (see code below), but
> it didn't work.....or I don't know how....and I`ve read the subjects about
> this topic in this mail list (and the answers of Ezder Pebesma), but I stil
> cannot make it work.
>
>   
>> par(mfrow=c(2,2))
>> for (i in 1:4)
>>     
> +print (plot ( v.d.temp [ [ i ] ]   ) )
>   
Untried:

par(mfrow=c(2,2))
for (i in 1:4) {
  v = v.d.temp[[i]]
 
plot(gamma~dist,v,xlim=c(0,max(v$dist)),ylim=c(0,max(v$gamma),xlab="distance",
ylab="semivariance")
}
> In advance, thank you very much.
>
> Eduardo.
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Tue Nov  3 09:13:33 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 03 Nov 2009 09:13:33 +0100
Subject: [R-sig-Geo] Fwd:  flip SpatialGridDataFrame across axis
In-Reply-To: <522664f80911021356n735ab071j323b2dd0b6a05c1@mail.gmail.com>
References: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>	<522664f80911021240t549348fbra208152741795abd@mail.gmail.com>	<87tyxcird9.fsf@kolob.sebmags.homelinux.org>	<522664f80911021345v4c65f4dftf28e9b6f9a5a1a33@mail.gmail.com>
	<522664f80911021356n735ab071j323b2dd0b6a05c1@mail.gmail.com>
Message-ID: <4AEFE62D.4010104@uni-muenster.de>

Michael, to be hounest, it even surprised me, being the author, that

data(meuse.grid)
gridded(meuse.grid) = ~x+y
fullgrid(meuse.grid) = TRUE
image(meuse.grid[104:1,])

would not flip the image. It just works hard to not destroy the spatial
location of all individual pixels -- it will select all rows in reverse
order, but in the end put everything back in place. What you do is kind
of more like image analysis, as it  moves the location of pixels, right?

Do you mind if we add your flipXxx functions to sp?
--
Edzer

Michael Sumner wrote:
> Ergh, sorry for the update -  a pox on Gmail for sabotaging my
> attempts at plain text!  I've attached the functions in a text file to
> avoid [ampersand] to " at " conversion ...
>
>
>
>
> ---------- Forwarded message ----------
> From: Michael Sumner <mdsumner at gmail.com>
> Date: Tue, Nov 3, 2009 at 8:45 AM
> Subject: Re: [R-sig-Geo] flip SpatialGridDataFrame across axis
> To: r-sig-geo at stat.math.ethz.ch
>
>
> It would be nice if the "[" methods on ?'SpatialGridDataFrame-class'
> could perform the same indexing orientation, but that uses the
> row/column values for [i,j,...]  to obtain the subsetted cells which
> are regridded via SpatialPixels - so the direction is lost. I'm not
> sure it's a good idea to modify that - given that the indexing could
> be used to subset at the same time - which is probably why the authors
> have written it that way.  ;)
>
> But, I've been meaning to try something like this for ages, and this
> seems to work:
>
> flipHorizontal <- function(x) {
>        if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
> SpatialGridDataFrame")
>        grd <- getGridTopology(x)
>        idx = 1:prod(grd at cells.dim[1:2])
>        m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
> TRUE)[,grd at cells.dim[1]:1]
>        idx = as.vector(t(m))
>        x at data <- x at data[idx, TRUE, drop = FALSE]
>        x
> }
>
> flipVertical <- function(x) {
>        if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
> SpatialGridDataFrame")
>        grd <- getGridTopology(x)
>        idx = 1:prod(grd at cells.dim[1:2])
>        m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
> TRUE)[grd at cells.dim[2]:1, ]
>        idx = as.vector(t(m))
>        x at data <- x at data[idx, TRUE, drop = FALSE]
>        x
> }
>
> The approach there is stolen from 'subs.SpatialGridDataFrame' in
> sp/R/SpatialGridDataFrame-methods.R - so thanks as ever to the
> authors!
>
> Cheers, Mike.
>
> On Tue, Nov 3, 2009 at 7:49 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
>   
>> On Tue, 3 Nov 2009 07:40:59 +1100,
>> Michael Sumner <mdsumner at gmail.com> wrote:
>>
>>     
>>> Hi Sebastian, I think the "north-south" note is referring to
>>> possibly-rotated grids (using the transform values supported by many
>>> formats) - not to "north vs. south" in orientation.
>>>       
>>> You can easily flip a grid by reverting it (one band at a time) to an
>>> xyz image and using indexing. I find this approach the least confusing
>>> and easily repeatable.
>>>       
>> [...]
>>
>> Thanks for the quick reply Mike!!
>>
>>
>> Cheers,
>>
>> --
>> Seb
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>> ------------------------------------------------------------------------
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From mdsumner at gmail.com  Tue Nov  3 09:32:36 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 3 Nov 2009 19:32:36 +1100
Subject: [R-sig-Geo] Fwd: flip SpatialGridDataFrame across axis
In-Reply-To: <4AEFE62D.4010104@uni-muenster.de>
References: <87y6moitfm.fsf@kolob.sebmags.homelinux.org>
	<522664f80911021240t549348fbra208152741795abd@mail.gmail.com>
	<87tyxcird9.fsf@kolob.sebmags.homelinux.org>
	<522664f80911021345v4c65f4dftf28e9b6f9a5a1a33@mail.gmail.com>
	<522664f80911021356n735ab071j323b2dd0b6a05c1@mail.gmail.com>
	<4AEFE62D.4010104@uni-muenster.de>
Message-ID: <522664f80911030032kec535cbrd124bb656e6649ca@mail.gmail.com>

Hi Edzer, no problem at all - Robert's approach is much less verbose,
but I think this explicit method is easier to understand and share as
it exposes the underlying indexing.

I agree there's a sense that it is image processing, but in the "GIS
raster" sense (image, DEM, data, etc.)  it's a useful way of
correcting broken or incomplete metadata - and with the range of
orientation conventions and ways of storing those it's handy to have.

Do you think it belongs as a method in the maptools elide family - at
least eventually?  I guess that depends on future support for rasters
there.  Given the terminology used there it's probably better to call
the functions "reflectHorizontal/Vertical" rather than flip, even if
they exist as standalones for now?

Regards, Mike.

On Tue, Nov 3, 2009 at 7:13 PM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Michael, to be hounest, it even surprised me, being the author, that
>
> data(meuse.grid)
> gridded(meuse.grid) = ~x+y
> fullgrid(meuse.grid) = TRUE
> image(meuse.grid[104:1,])
>
> would not flip the image. It just works hard to not destroy the spatial
> location of all individual pixels -- it will select all rows in reverse
> order, but in the end put everything back in place. What you do is kind
> of more like image analysis, as it ?moves the location of pixels, right?
>
> Do you mind if we add your flipXxx functions to sp?
> --
> Edzer
>
> Michael Sumner wrote:
>> Ergh, sorry for the update - ?a pox on Gmail for sabotaging my
>> attempts at plain text! ?I've attached the functions in a text file to
>> avoid [ampersand] to " at " conversion ...
>>
>>
>>
>>
>> ---------- Forwarded message ----------
>> From: Michael Sumner <mdsumner at gmail.com>
>> Date: Tue, Nov 3, 2009 at 8:45 AM
>> Subject: Re: [R-sig-Geo] flip SpatialGridDataFrame across axis
>> To: r-sig-geo at stat.math.ethz.ch
>>
>>
>> It would be nice if the "[" methods on ?'SpatialGridDataFrame-class'
>> could perform the same indexing orientation, but that uses the
>> row/column values for [i,j,...] ?to obtain the subsetted cells which
>> are regridded via SpatialPixels - so the direction is lost. I'm not
>> sure it's a good idea to modify that - given that the indexing could
>> be used to subset at the same time - which is probably why the authors
>> have written it that way. ?;)
>>
>> But, I've been meaning to try something like this for ages, and this
>> seems to work:
>>
>> flipHorizontal <- function(x) {
>> ? ? ? ?if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
>> SpatialGridDataFrame")
>> ? ? ? ?grd <- getGridTopology(x)
>> ? ? ? ?idx = 1:prod(grd at cells.dim[1:2])
>> ? ? ? ?m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
>> TRUE)[,grd at cells.dim[1]:1]
>> ? ? ? ?idx = as.vector(t(m))
>> ? ? ? ?x at data <- x at data[idx, TRUE, drop = FALSE]
>> ? ? ? ?x
>> }
>>
>> flipVertical <- function(x) {
>> ? ? ? ?if (!inherits(x, "SpatialGridDataFrame")) stop("x must be a
>> SpatialGridDataFrame")
>> ? ? ? ?grd <- getGridTopology(x)
>> ? ? ? ?idx = 1:prod(grd at cells.dim[1:2])
>> ? ? ? ?m = matrix(idx, grd at cells.dim[2], grd at cells.dim[1], byrow =
>> TRUE)[grd at cells.dim[2]:1, ]
>> ? ? ? ?idx = as.vector(t(m))
>> ? ? ? ?x at data <- x at data[idx, TRUE, drop = FALSE]
>> ? ? ? ?x
>> }
>>
>> The approach there is stolen from 'subs.SpatialGridDataFrame' in
>> sp/R/SpatialGridDataFrame-methods.R - so thanks as ever to the
>> authors!
>>
>> Cheers, Mike.
>>
>> On Tue, Nov 3, 2009 at 7:49 AM, Sebastian P. Luque <spluque at gmail.com> wrote:
>>
>>> On Tue, 3 Nov 2009 07:40:59 +1100,
>>> Michael Sumner <mdsumner at gmail.com> wrote:
>>>
>>>
>>>> Hi Sebastian, I think the "north-south" note is referring to
>>>> possibly-rotated grids (using the transform values supported by many
>>>> formats) - not to "north vs. south" in orientation.
>>>>
>>>> You can easily flip a grid by reverting it (one band at a time) to an
>>>> xyz image and using indexing. I find this approach the least confusing
>>>> and easily repeatable.
>>>>
>>> [...]
>>>
>>> Thanks for the quick reply Mike!!
>>>
>>>
>>> Cheers,
>>>
>>> --
>>> Seb
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>> ------------------------------------------------------------------------
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>
>


From p.hiemstra at geo.uu.nl  Tue Nov  3 09:53:06 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 03 Nov 2009 09:53:06 +0100
Subject: [R-sig-Geo] Various Variograms of gstat package together in a
 single page
In-Reply-To: <4AEFD6F0.5000702@uni-muenster.de>
References: <640918380911021422l19e65fe6lfb7f2375f0f88a48@mail.gmail.com>
	<4AEFD6F0.5000702@uni-muenster.de>
Message-ID: <4AEFEF72.30207@geo.uu.nl>

Hi Eduardo,

Please also take a look at the archive of r-sig-geo, there are earlier 
questions that have been answered on variograms in plots:

http://www.mail-archive.com/r-sig-geo at stat.math.ethz.ch/msg05795.html

cheers,
Paul

Edzer Pebesma wrote:
> Eduardo Bustos wrote:
>   
>> Dear List:
>>
>> I need  your help. I'm a new user in R ( round two weeks...) and I'm trying
>> to make several interpolations in R with Gstat package.
>>
>> Initially, I have a workbook in MSExcel, with several sheets, which were
>> imported using xlsReadWrite package in a list in R (45 data frame in one
>> object (class=list))
>>
>>   
>>     
>>> d <- as.list(length(z))
>>> for (i in 1:length(z))
>>>     
>>>       
>> +d[[i]] <- read.xls('Tablas_puntos.xls', colNames=TRUE, sheet = i)
>>
>> Later, the data frames were convert to explicity-spatial,using the sp
>> package (I have followed the instructions of the tecnical note of D.G
>> Rossiter --> http://www.itc.nl/~rossiter/teach/R/R_ck.pdf).
>>
>> Finally, I create an object (list) with 45 variograms for each one of the
>> data sets.
>>
>>   
>>     
>>> v.d.temp <- as.list(length(z))
>>> for(i in 1:length(z))
>>>     
>>>       
>> +v.d.temp[[i]] <- variogram(TempC ~1, data= d.temp[[i]], cutoff=25000,
>> width=200)
>>
>> At this point, everything works OK:
>>
>>  - The final question: How to putt several of these variogram graphics
>> together in a single page ?
>>
>> I tried with par(mfrow=c(n,m)) in  together with loops (see code below), but
>> it didn't work.....or I don't know how....and I`ve read the subjects about
>> this topic in this mail list (and the answers of Ezder Pebesma), but I stil
>> cannot make it work.
>>
>>   
>>     
>>> par(mfrow=c(2,2))
>>> for (i in 1:4)
>>>     
>>>       
>> +print (plot ( v.d.temp [ [ i ] ]   ) )
>>   
>>     
> Untried:
>
> par(mfrow=c(2,2))
> for (i in 1:4) {
>   v = v.d.temp[[i]]
>  
> plot(gamma~dist,v,xlim=c(0,max(v$dist)),ylim=c(0,max(v$gamma),xlab="distance",
> ylab="semivariance")
> }
>   
>> In advance, thank you very much.
>>
>> Eduardo.
>>
>>   
>>     
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From hengl at spatial-analyst.net  Tue Nov  3 10:43:38 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 3 Nov 2009 10:43:38 +0100
Subject: [R-sig-Geo] Spatial analysis question
In-Reply-To: <7111a5b70910301149x1abdb4a2hf41bf63b17dfbea2@mail.gmail.com>
References: <7111a5b70910301149x1abdb4a2hf41bf63b17dfbea2@mail.gmail.com>
Message-ID: <57561E43F813490089B2ED78235B62EB@pcibed193>


Marcelo,

Surprisingly, I could not find any function in the spatstat package (or splancs package) that
specifically derives cross-correlations between multiple point processes:

> data(lansing)
> plot(split(lansing))  # distribution of occurrence records for five+1 species;
> plot(density(split(lansing)), ribbon = FALSE)
# fit stationary marked Poisson process with different intensity for each species:
> lansing.ppm <- ppm(lansing, ~marks, Poisson())
> summary(lansing.ppm)

...but this does not say anything about which species are most correlated (and which are negatively
correlated). See also "Mark correlation function" in PART V. MARKED POINT PATTERNS:

Baddeley, A., 2008. Analysing spatial point patterns in R. CSIRO, Canberra, Australia.
http://www.csiro.au/files/files/pn0y.pdf 


I guess that there is no reason NOT to do what you suggest:

> dens.lansing <- density(split(lansing))
> dens.lansing.sp <- as(dens.lansing[[1]], "SpatialGridDataFrame")
> names(dens.lansing.sp)[1] <- names(dens.lansing)[1]
> for(i in 2:length(dens.lansing)) {
  dens.lansing.sp at data[names(dens.lansing)[i]] <- as(dens.lansing[[i]], "SpatialGridDataFrame")$v
}
> spplot(dens.lansing.sp, col.regions=grey(rev(seq(0,1,0.025))))
> round(cor(log1p(dens.lansing.sp at data[names(dens.lansing)]), use="complete.obs"), 2)
         blackoak hickory maple  misc redoak whiteoak
blackoak     1.00    0.55 -0.73 -0.64  -0.51     0.23
hickory      0.55    1.00 -0.84 -0.63  -0.52    -0.27
maple       -0.73   -0.84  1.00  0.75   0.50    -0.09
misc        -0.64   -0.63  0.75  1.00   0.70     0.09
redoak      -0.51   -0.52  0.50  0.70   1.00     0.25
whiteoak     0.23   -0.27 -0.09  0.09   0.25     1.00

# PCA:
> sp.formula <- as.formula(paste("~", paste("log1p(", names(dens.lansing), ")", collapse="+"),
sep=""))
> PCA.sp <- prcomp(sp.formula, scale=TRUE, dens.lansing.sp at data)
> biplot(PCA.sp, arrow.len=0.1, xlabs=rep(".", length(PCA.sp$x[,1])), main="PCA biplot",
ylabs=names(dens.lansing))

which clearly shows that the most positively correlated species are "hickory" and "blackoak", while
the most 'competing' species are "maple"/"redoak" and "hickory".


HTH

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Marcelo Tognelli
> Sent: Friday, October 30, 2009 7:50 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Spatial analysis question
> 
> Dear List,
> 
> I have probability maps of the distribution of 4 species of venomous snakes
> (raster files output from species distribution modeling software) and point
> locality data with information on snake bite events (most of them without
> the id of the species involved in the accident). I would like to run an
> analysis to see what species correlates best with snake bite events. My idea
> is to generate a kernel density raster from the point event data and then do
> some kind of spatial correlation against the species distribution maps.
> I would greatly appreciate any suggestions on the type of analysis that I
> can perform with these data and on the software and/or R package to run it.
> 
> Thanks in advance,
> 
> Marcelo
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Tue Nov  3 11:33:36 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 03 Nov 2009 11:33:36 +0100
Subject: [R-sig-Geo] spatstat
Message-ID: <4AF00700.1050606@gmail.com>

Why is not spatstat on the repositories? Why do we
have to download the gz file and install from the local file?
Thanks

Agus


From Roger.Bivand at nhh.no  Tue Nov  3 11:44:07 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Nov 2009 11:44:07 +0100 (CET)
Subject: [R-sig-Geo] spatstat
In-Reply-To: <4AF00700.1050606@gmail.com>
References: <4AF00700.1050606@gmail.com>
Message-ID: <alpine.LRH.2.00.0911031136370.20722@reclus.nhh.no>

On Tue, 3 Nov 2009, Agustin Lobo wrote:

> Why is not spatstat on the repositories? Why do we
> have to download the gz file and install from the local file?

Agus,

Please try CRAN alternative mirrors, maybe yours is down or stale. The 
package is vital for many people and is certainly available at the hub 
repository.

When reporting apparent package absences, please say which repository you 
tried:

> options("repos")
$repos
                           CRAN
"http://cran.at.r-project.org"

(I'm in Vienna today), and sessionInfo(), as the

> options("pkgType")
$pkgType
[1] "source"

depends on your system.

Roger

> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Tue Nov  3 12:01:46 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 03 Nov 2009 12:01:46 +0100
Subject: [R-sig-Geo] spatstat
In-Reply-To: <alpine.LRH.2.00.0911031136370.20722@reclus.nhh.no>
References: <4AF00700.1050606@gmail.com>
	<alpine.LRH.2.00.0911031136370.20722@reclus.nhh.no>
Message-ID: <4AF00D9A.5020308@gmail.com>

It is on the Austrian repository now (I always use it so don't have
to scroll down), but it was not there earlier this morning, have 
upgraded to R2.10 and have been updating packages.
Anyway, problem solved!

Agus

Roger Bivand wrote:
> On Tue, 3 Nov 2009, Agustin Lobo wrote:
> 
>> Why is not spatstat on the repositories? Why do we
>> have to download the gz file and install from the local file?
> 
> Agus,
> 
> Please try CRAN alternative mirrors, maybe yours is down or stale. The 
> package is vital for many people and is certainly available at the hub 
> repository.
> 
> When reporting apparent package absences, please say which repository 
> you tried:
> 
>> options("repos")
> $repos
>                           CRAN
> "http://cran.at.r-project.org"
> 
> (I'm in Vienna today), and sessionInfo(), as the
> 
>> options("pkgType")
> $pkgType
> [1] "source"
> 
> depends on your system.
> 
> Roger
> 
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From edzer.pebesma at uni-muenster.de  Tue Nov  3 15:11:00 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 03 Nov 2009 15:11:00 +0100
Subject: [R-sig-Geo] gstat memory
In-Reply-To: <4AEB2986.4070305@carleton.ca>
References: <4AEB2986.4070305@carleton.ca>
Message-ID: <4AF039F4.9010005@uni-muenster.de>

Dear Murray and list,

repairing the memory leaks turned out to be a more fun job than I
thought it would be. Memory leakage mainly took place in the
neighbourhood search algorithm (nsearch.c) which uses a quadtree for 2
and octtree (octree?) for 3-dimensional data. As you can guess, the code
is full with recursion, and was contributed by Steve Joyce, someone much
cleverder than I am, back in 1997, so that was a nice puzzle. But the
leaks should be gone now.

gstat_0.9-64 now propagates through CRAN.

In my enthousiasm, I removed any other memory leak I could. This meant
several code changes at the c level that looked as if back then I made
them to resolve a bug -- of course we didn't have valgrind then. In
other words, I might have introduced new problems. If you encounter
anything unexpected, then please let me know.

Whenever this stabilizes, I will start calling increase gstat's version
number to 1.0_0

Best regards,
--
Edzer


Murray Richardson wrote:
> Hello R-SIG-GEO list,
>
> I know this has come up before but I am having an ongoing memory
> problem with the gstat package (gstat out of dynamic memory) that I
> can't seem to solve.
>
> I am using R to interpolate DEMs from LiDAR xyz point files and mosaic
> them together via RSAGA.  The script uses a loop to load in each xyz
> point file, and interpolate over a regular lattice of points using idw
> from gstat.  Although large, the computational requirements within
> each iteration of the loop should be well within my system's ability
> so it seems like it is a cumulative effect (note I can restart the
> process at the last loop that triggered the error and the iteration is
> successful).  I am removing temp objects and running gc() at the end
> of every loop.
>
> It proceeds normally for about 5-10 iterations and physical memory use
> on my system (VISTA 64 bit, 12GB RAM) gradually increases over time
> until I get the "gstat out of memory" error. Here is the relevant
> portion of the loop:
>
> ...
>
>   path<-"E:/LidarData/1_Ground_First_Return/UTM17/"
>   filen<-paste(path, centre_tile$TILECODE, ".xyz", sep="")
>   xyzi<-read.table(filen, sep=",", header=F)
>   names(xyzi)<-c("x","y","z","i")
>
>   for(j in 1:length(tile_group_names)){
>       filen<-paste(path, tile_group_names[j], ".xyz", sep="")
>       tmp_xyzi<-read.table(filen, sep=",", header=F)
>       names(tmp_xyzi)<-c("x","y","z","i")
>       xyzi<-rbind(xyzi,tmp_xyzi)
>
>   }
>       coordinates(xyzi)=~x+y
>   # note grid_coords is just the regular lattice that is created from
> the current tile coordinates
>   coordinates(grid_coords)=~x+y
>
>   # do the interpolation
>   interp<-idw(z~1, xyzi, grid_coords, nmax=4,maxdist=2, idp=1.0)
>
>   names(interp)<-c("z","var")
>   slot(interp,"data")<-data.frame(slot(interp,"data"))
>   finalSPntsDF<-SpatialPointsDataFrame(interp, data.frame(interp$z),
>               proj4string = CRS(as.character(NA)), match.ID = TRUE)
>
>
>   finalSPDF<-SpatialPixelsDataFrame(finalSPntsDF,
> data.frame(interp$z), tolerance = sqrt(.Machine$double.eps),
>     proj4string = CRS(as.character(NA)))
>
> ... On a related note - I have tried using the 64 bit version of
> Revolution but unfortunately the gstat package has not been ported. 
> Has anyone contemplated or begun a 64 bit port of this package?
>
> Thanks
>
> Murray
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From mtognelli at lab.cricyt.edu.ar  Tue Nov  3 17:31:12 2009
From: mtognelli at lab.cricyt.edu.ar (Marcelo Tognelli)
Date: Tue, 3 Nov 2009 08:31:12 -0800
Subject: [R-sig-Geo] Spatial analysis question
Message-ID: <7111a5b70911030831o3cad3ff7s13cb6f2814c5647@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091103/ad9c839c/attachment.pl>

From rpaolo1967 at gmail.com  Tue Nov  3 22:35:33 2009
From: rpaolo1967 at gmail.com (Paolo Ramoni Perazzi)
Date: Tue, 3 Nov 2009 17:35:33 -0400
Subject: [R-sig-Geo] About correlograms
Message-ID: <61a8d8c90911031335y34925c1bh2cad0dc3e8be57ab@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091103/48a1a383/attachment.pl>

From mdw at purdue.edu  Tue Nov  3 23:26:48 2009
From: mdw at purdue.edu (Mark Daniel Ward)
Date: Tue, 03 Nov 2009 17:26:48 -0500
Subject: [R-sig-Geo] need a Windows binary for Rcartogram from omegahat
In-Reply-To: <1257266524.763.1343366009@webmail.messagingengine.com>
References: <1257266524.763.1343366009@webmail.messagingengine.com>
Message-ID: <4AF0AE28.8040900@purdue.edu>

Dear All,
I did not realize that there was a compiled version of the Rcartogram 
library, with the fftw included, ready for use with R for Windows 2.9:
http://www.omegahat.org/R/bin/windows/contrib/2.9/
Nicholas Lewin-Koh pointed this out to me.  I'm very thankful to know 
this.  Thank you to everyone who sent suggestions.  Thank you to Duncan 
for making and maintaining this library too!  My students have enjoyed 
working with it, and they are eager to try it now on their own.
Mark



Nicholas Lewin-Koh wrote:
> Isn't this what you are looking for?
> http://www.omegahat.org/R/bin/windows/contrib/2.9/
>
> Nicholas
>
>


From Adrian.Baddeley at csiro.au  Wed Nov  4 05:10:58 2009
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Wed, 4 Nov 2009 12:10:58 +0800
Subject: [R-sig-Geo] Spatial analysis question
Message-ID: <57DC18C299094D4299F837570C5DF1C502C4BB7D46@EXWA-MBX01.nexus.csiro.au>

Marcelo Tognelli <mtognelli at lab.cricyt.edu.ar> writes:

> I have probability maps of the distribution of 4 species of venomous snakes
> (raster files output from species distribution modeling software) and point
> locality data with information on snake bite events (most of them without
> the id of the species involved in the accident). I would like to run an
> analysis to see what species correlates best with snake bite events. 

> My idea is to generate a kernel density raster from the point event data and then do
> some kind of spatial correlation against the species distribution maps.

You don't need to smooth the point event data to obtain a correlation. The correlation between a 
point process and a random field is well-defined. In the 'spatstat' package, if X is a point pattern
and Z is a pixel image, then the sample correlation can be computed by

      Xp <- pixellate(X, W=as.owin(Z))
     
      cor(as.vector(as.matrix(Z)), as.vector(as.matrix(Xp)), use="pairwise.complete.obs")

However, the interpretation of correlations in a spatially-inhomogeneous dataset is beset with problems.

Probably the best way to analyse these data is to regard the snake bite events as a point process 'response'
and the species distribution data as the 'covariates' that may be used to explain the response. 
This is similar to many standard analyses in spatial epidemiology.

The very simplest statistical assumption would be that each species has a different intrinsic probability 
of biting (the probability that in a particular confrontation a particular snake will bite). 
In that case the intensity of snake bites (number of snake bites per unit area, in the survey period) 
would be proportional to p1 * a1 + p2 * a2 + p3 * a3 + p4 * a4 where p1, p2..p4 are the (unknown) bite probabilities of each species, and a1, a2...a4 are the (known) spatially-varying densities of abundance for the 4 species. Assuming snakes act independently of each other (!) the snake bites are a Poisson process with this intensity. 

Unfortunately this model cannot (yet) be fitted in 'spatstat' because it is linear and the current implementation
of 'ppm' is restricted to canonical (loglinear) models. The following hack would work.
        objfun <- function(beta, X, Z1, Z2, Z3, Z4) {
             p <- exp(beta)
             inten <- eval.im(p[1] * Z1 + p[2]* Z2 + p[3]*Z3 + p[4] * Z4)
             -sum(log(inten[X])) + summary(inten)$integral
        }
        op <- optim(rep(0,4), objfun, X=bites, Z1=species1, Z2=species2, Z3=species3, Z4=species4)
        p <- exp(op$par)

where 'bites' is your point pattern of snake bites, and species1, .., species4 are pixel images of the 
distributions of the 4 snakes. The result 'p' gives maximum likelihood estimates of the relative biting propensities for the 4 species (these are not normalised so only their relative values makes sense). 
By tweaking the call to 'eval.im' you can try different kinds of models.

There's an issue here about the 'opportunity' or 'exposure' to snake bite. If the density of people
(or visits by people) is not uniform across the study region then this could affect the observed
distribution of snake bites.

"Tomislav Hengl" <hengl at spatial-analyst.net> writes:

> Surprisingly, I could not find any function in the spatstat package (or splancs package) that
> specifically derives cross-correlations between multiple point processes.

The Mark Connection Function 'markconnect' does exactly this, e.g.
              data(lansing)
              plot(alltypes(lansing, markconnect))
(But this is for correlations between different points, not between points and spatial variables.)

> # fit stationary marked Poisson process with different intensity for each species:
> lansing.ppm <- ppm(lansing, ~marks, Poisson())
> summary(lansing.ppm)
> ...but this does not say anything about which species are most correlated 
> (and which are negatively correlated).

Of course not - the fitted model assumes they are NOT correlated. 

Adrian Baddeley

From chris at coolbytes.co.uk  Wed Nov  4 13:41:44 2009
From: chris at coolbytes.co.uk (Chris)
Date: Wed, 4 Nov 2009 12:41:44 -0000
Subject: [R-sig-Geo] Jencks' natural breaks
Message-ID: <00e201ca5d4c$2afc5cc0$80f51640$@co.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091104/5c89708c/attachment.pl>

From a.crowe at lancaster.ac.uk  Wed Nov  4 13:55:35 2009
From: a.crowe at lancaster.ac.uk (Crowe, Andrew)
Date: Wed, 4 Nov 2009 12:55:35 -0000
Subject: [R-sig-Geo] Jencks' natural breaks
References: <00e201ca5d4c$2afc5cc0$80f51640$@co.uk>
Message-ID: <BB501CE635E5144CA5E30956E5E32C5201A6F7C0@exchange-be5.lancs.local>

Chris
 
Check out the ClassInt package.
 
Andrew
 
Dr Andrew Crowe
 
Lancaster Environment Centre
Lancaster University
Lancaster    LA1 4YQ
UK
 
Tel: +44 (0)1524 595879

________________________________

From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Chris
Sent: Wed 04/11/2009 12:41 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Jencks' natural breaks



I am looking to execute this calculation in a software package I am building
but need help with pseudo code.



Can anyone point me in the right direction for a programming routine that
uses this method to work on a set of data?



The data is used in a mapping program. Data such as GDP will be used. The
resulting breaks will then be used to highlight the countries on a world map
giving them colour ranges.



Thanks,

Chris.






        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From clement.tisseuil at gmail.com  Wed Nov  4 13:53:48 2009
From: clement.tisseuil at gmail.com (=?UTF-8?Q?Cl=C3=A9ment_Tisseuil?=)
Date: Wed, 4 Nov 2009 13:53:48 +0100
Subject: [R-sig-Geo] Hydrological distance between sites
Message-ID: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091104/66bf5d04/attachment.pl>

From cara.tobin at epfl.ch  Wed Nov  4 14:28:48 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Wed, 4 Nov 2009 14:28:48 +0100
Subject: [R-sig-Geo] Help importing ascii DTM with no data values for
 Kriging with External Drift
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8AD@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091104/63009fe4/attachment.pl>

From edzer.pebesma at uni-muenster.de  Wed Nov  4 14:51:43 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 04 Nov 2009 14:51:43 +0100
Subject: [R-sig-Geo] Help importing ascii DTM with no data values for
 Kriging with External Drift
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8AD@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8AD@REX2.intranet.epfl.ch>
Message-ID: <4AF186EF.4070601@uni-muenster.de>



Tobin Cara wrote:
> Hello,
>
> I am having problems with kriging an ascii file DTM from ArcGIS which has many -9999 (no data) values. Do these normally have to be removed first? I want to make the elevation DTM the predictor base for kriging with external drift.
>
>   
the nodata values should be automatically converted, as the header
defines them.
> My code is the following:
> elev <- read.asciigrid("elev.asc", as.image=FALSE, plot.image=TRUE)
> str(elev)
> elev_ked <- krige(meanRain~Zloc, locations=meanRain, newdata=elev, model=fitted_vario)
>   
This assumes that something called Zloc is available both in meanRain
and in elev, which is unlikely in your case.

Try to make a habit of using the formulation

elev_ked <- krige(meanRain~Zloc, meanRain, elev, fitted_vario)

i.e., without named arguments.

> Error in model.frame.default(terms.f, newdata, na.action = na.action) :
>   object is not a matrix
> In addition: Warning message:
> 'newdata' had 550448 rows but variable(s) found have 1 rows
>
> My data file meanRain has X Y Z coordinates and Precipitation values (4 columns).
>
> Thank you so much for your time and help!
>
> Cara
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From ssefick at gmail.com  Wed Nov  4 14:57:59 2009
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 4 Nov 2009 07:57:59 -0600
Subject: [R-sig-Geo] Hydrological distance between sites
In-Reply-To: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com>
References: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com>
Message-ID: <c502a9e10911040557n55f2cdf2l730c19d8ade9dcec@mail.gmail.com>

How do you mean?  Like distance from confluence to an upstream site,
or overland between two sites.  I would reckon that GRASS may be
better suited for this.
regards,

Stephen

2009/11/4 Cl?ment Tisseuil <clement.tisseuil at gmail.com>:
> Dear r-sig-geo list members,
>
> Does anyone know if some R functions exist to calculate some hydrological
> distances between sites? By hydrological distances, I mean for example the
> 'real' distance that separates two sites throughout the river network
> connexions.
>
> Thanks in advance
>
> Clem
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Stephen Sefick

Let's not spend our time and resources thinking about things that are
so little or so large that all they really do for us is puff us up and
make us feel like gods.  We are mammals, and have not exhausted the
annoying little problems of being mammals.

								-K. Mullis


From alobolistas at gmail.com  Wed Nov  4 21:11:59 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 04 Nov 2009 21:11:59 +0100
Subject: [R-sig-Geo] Problem with writeOGR()
Message-ID: <4AF1E00F.50505@gmail.com>

I'm puzzled with this:

 > class(gpsori1)
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
 > writeOGR(gpsori1, dsn="CAST20090907", 
layer="CAST20090907gps1",driver="ESRI Shapefile")
Error in writeOGR(gpsori1, dsn = "CAST20090907", layer = 
"CAST20090907gps1",  :
  unknown data type

Am I doing something wrong or is there a recent change that I'm not 
aware of?

Thanks

Agus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 251 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091104/3bc59930/attachment.vcf>

From mdsumner at gmail.com  Wed Nov  4 23:13:16 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 5 Nov 2009 09:13:16 +1100
Subject: [R-sig-Geo] Problem with writeOGR()
In-Reply-To: <4AF1E00F.50505@gmail.com>
References: <4AF1E00F.50505@gmail.com>
Message-ID: <522664f80911041413v5a1f99f4vf836bbb5fcd10066@mail.gmail.com>

Hi Agustin, you will need to determine which columns in the data frame
are causing problems.

Can you run this and let us know what you see?

summary(gpsori1)

For example, you cannot write POSIXct columns to SHP and would need to
convert to text, or numeri:

library(rgdal)
d <- data.frame(x = 1:10, y = 1:10, z = 1:10)
coordinates(d) <- ~x+y

## OK
writeOGR(d, ".", "test", "ESRI Shapefile")
unlink("test.shp")

d$z <- Sys.time() + 1:10
## not OK
writeOGR(d, ".", "test", "ESRI Shapefile")


Regards, Mike.



On Thu, Nov 5, 2009 at 7:11 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I'm puzzled with this:
>
>> class(gpsori1)
> [1] "SpatialPointsDataFrame"
> attr(,"package")
> [1] "sp"
>> writeOGR(gpsori1, dsn="CAST20090907",
>> layer="CAST20090907gps1",driver="ESRI Shapefile")
> Error in writeOGR(gpsori1, dsn = "CAST20090907", layer = "CAST20090907gps1",
> ?:
> ?unknown data type
>
> Am I doing something wrong or is there a recent change that I'm not aware
> of?
>
> Thanks
>
> Agus
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From mtognelli at lab.cricyt.edu.ar  Wed Nov  4 23:42:43 2009
From: mtognelli at lab.cricyt.edu.ar (Marcelo Tognelli)
Date: Wed, 4 Nov 2009 14:42:43 -0800
Subject: [R-sig-Geo]  Spatial analysis question
Message-ID: <7111a5b70911041442j239b1367o5908b7850914d35a@mail.gmail.com>

Adrian,

Thanks for providing a better alternative for analyzing the data. You
are right in that the density of people exposed to snake bites is not
uniform across the study area. I've been thinking about either
incorporating human population density as a covariate in the model or
correcting snake bite counts by population density.

Marcelo

Marcelo Tognelli <mtognelli at lab.cricyt.edu.ar> writes:

> I have probability maps of the distribution of 4 species of venomous snakes
> (raster files output from species distribution modeling software) and point
> locality data with information on snake bite events (most of them without
> the id of the species involved in the accident). I would like to run an
> analysis to see what species correlates best with snake bite events.

> My idea is to generate a kernel density raster from the point event data and then do
> some kind of spatial correlation against the species distribution maps.

You don't need to smooth the point event data to obtain a correlation.
The correlation between a
point process and a random field is well-defined. In the 'spatstat'
package, if X is a point pattern
and Z is a pixel image, then the sample correlation can be computed by

      Xp <- pixellate(X, W=as.owin(Z))

      cor(as.vector(as.matrix(Z)), as.vector(as.matrix(Xp)),
use="pairwise.complete.obs")

However, the interpretation of correlations in a
spatially-inhomogeneous dataset is beset with problems.

Probably the best way to analyse these data is to regard the snake
bite events as a point process 'response'
and the species distribution data as the 'covariates' that may be used
to explain the response.
This is similar to many standard analyses in spatial epidemiology.

The very simplest statistical assumption would be that each species
has a different intrinsic probability
of biting (the probability that in a particular confrontation a
particular snake will bite).
In that case the intensity of snake bites (number of snake bites per
unit area, in the survey period)
would be proportional to p1 * a1 + p2 * a2 + p3 * a3 + p4 * a4 where
p1, p2..p4 are the (unknown) bite probabilities of each species, and
a1, a2...a4 are the (known) spatially-varying densities of abundance
for the 4 species. Assuming snakes act independently of each other (!)
the snake bites are a Poisson process with this intensity.

Unfortunately this model cannot (yet) be fitted in 'spatstat' because
it is linear and the current implementation
of 'ppm' is restricted to canonical (loglinear) models. The following
hack would work.
        objfun <- function(beta, X, Z1, Z2, Z3, Z4) {
             p <- exp(beta)
             inten <- eval.im(p[1] * Z1 + p[2]* Z2 + p[3]*Z3 + p[4] * Z4)
             -sum(log(inten[X])) + summary(inten)$integral
        }
        op <- optim(rep(0,4), objfun, X=bites, Z1=species1,
Z2=species2, Z3=species3, Z4=species4)
        p <- exp(op$par)

where 'bites' is your point pattern of snake bites, and species1, ..,
species4 are pixel images of the
distributions of the 4 snakes. The result 'p' gives maximum likelihood
estimates of the relative biting propensities for the 4 species (these
are not normalised so only their relative values makes sense).
By tweaking the call to 'eval.im' you can try different kinds of models.

There's an issue here about the 'opportunity' or 'exposure' to snake
bite. If the density of people
(or visits by people) is not uniform across the study region then this
could affect the observed
distribution of snake bites.

"Tomislav Hengl" <hengl at spatial-analyst.net> writes:

> Surprisingly, I could not find any function in the spatstat package (or splancs package) that
> specifically derives cross-correlations between multiple point processes.

The Mark Connection Function 'markconnect' does exactly this, e.g.
              data(lansing)
              plot(alltypes(lansing, markconnect))
(But this is for correlations between different points, not between
points and spatial variables.)

> # fit stationary marked Poisson process with different intensity for each species:
> lansing.ppm <- ppm(lansing, ~marks, Poisson())
> summary(lansing.ppm)
> ...but this does not say anything about which species are most correlated
> (and which are negatively correlated).

Of course not - the fitted model assumes they are NOT correlated.

Adrian Baddeley
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mdsumner at gmail.com  Thu Nov  5 00:07:00 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 5 Nov 2009 10:07:00 +1100
Subject: [R-sig-Geo] Problem with writeOGR()
In-Reply-To: <4AF2019B.4020403@gmail.com>
References: <4AF1E00F.50505@gmail.com>
	<522664f80911041413v5a1f99f4vf836bbb5fcd10066@mail.gmail.com>
	<4AF2019B.4020403@gmail.com>
Message-ID: <522664f80911041507h7a01b8a2yec48ea751f205dc4@mail.gmail.com>

My guess is that it's the logical column.

Try

gpsori1$UTM.Ch <- as.character(gpsori1$UTM.Ch)
writeOGR(gpsori1, dsn="MATA20090729",
layer="MATA20090729gps1",driver="ESRI Shapefile")


On Thu, Nov 5, 2009 at 9:35 AM, Agustin Lobo <aloboaleu at gmail.com> wrote:
> Thanks,
> No POSIXct fields:
>> summary(gpsori1)
> Object of class SpatialPointsDataFrame
> Coordinates:
> ? ? ? ? ? ? ?min ? ? max
> coords.x1 ?453020 ?457145
> coords.x2 4623500 4625866
> Is projected: NA
> proj4string : [NA]
> Number of points: 2096
> Data attributes:
> ? ? ? No ? ? ? ? ? ?UTM.Zone ? UTM.Ch ? ? ? ? ? UTM.East
> ?Min. ? : ? 1.0 ? Min. ? :31 ? Mode:logical ? Min. ? :453020
> ?1st Qu.: 524.8 ? 1st Qu.:31 ? TRUE:2096 ? ? ?1st Qu.:453601
> ?Median :1048.5 ? Median :31 ? NA's:0 ? ? ? ? Median :454140
> ?Mean ? :1048.5 ? Mean ? :31 ? ? ? ? ? ? ? ? ?Mean ? :454418
> ?3rd Qu.:1572.2 ? 3rd Qu.:31 ? ? ? ? ? ? ? ? ?3rd Qu.:455120
> ?Max. ? :2096.0 ? Max. ? :31 ? ? ? ? ? ? ? ? ?Max. ? :457145
>
> ? UTM.North ? ? ? ? ?Altitude ? ? ? ? ? ?Date ? ? ? ? ? ?Time
> ?Min. ? :4623500 ? Min. ? :1648 ? 2009/07/29:2095 ? 08:49:04: ? 3
> ?1st Qu.:4624886 ? 1st Qu.:1795 ? 2009/07/30: ? 1 ? 08:49:05: ? 2
> ?Median :4625170 ? Median :1821 ? ? ? ? ? ? ? ? ? ? 08:49:06: ? 2
> ?Mean ? :4625068 ? Mean ? :1835 ? ? ? ? ? ? ? ? ? ? 08:49:07: ? 2
> ?3rd Qu.:4625338 ? 3rd Qu.:1885 ? ? ? ? ? ? ? ? ? ? 08:49:08: ? 2
> ?Max. ? :4625866 ? Max. ? :1952 ? ? ? ? ? ? ? ? ? ? 08:49:09: ? 2
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?(Other) :2083
>> str(gpsori1)
> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
> ?..@ data ? ? ? :'data.frame': 2096 obs. of ?8 variables:
> ?.. ..$ No ? ? ? : int [1:2096] 1 2 3 4 5 6 7 8 9 10 ...
> ?.. ..$ UTM.Zone : int [1:2096] 31 31 31 31 31 31 31 31 31 31 ...
> ?.. ..$ UTM.Ch ? : logi [1:2096] TRUE TRUE TRUE TRUE TRUE TRUE ...
> ?.. ..$ UTM.East : int [1:2096] 453245 453245 453245 453245 453245 453245
> 453245 453245 453245 453245 ...
> ?.. ..$ UTM.North: int [1:2096] 4625338 4625338 4625338 4625338 4625338
> 4625338 4625338 4625338 4625338 4625338 ...
> ?.. ..$ Altitude : num [1:2096] 1648 1648 1648 1648 1648 ...
> ?.. ..$ Date ? ? : Factor w/ 2 levels "2009/07/29","2009/07/30": 1 1 1 1 1 1
> 1 1 1 1 ...
> ?.. ..$ Time ? ? : Factor w/ 1452 levels "08:23:05","08:23:07",..: 1 2 3 4 5
> 6 7 8 9 10 ...
> ?..@ coords.nrs : num(0)
> ?..@ coords ? ? : num [1:2096, 1:2] 453245 453245 453245 453245 453245 ...
> ?.. ..- attr(*, "dimnames")=List of 2
> ?.. .. ..$ : NULL
> ?.. .. ..$ : chr [1:2] "coords.x1" "coords.x2"
> ?..@ bbox ? ? ? : num [1:2, 1:2] 453020 4623500 457145 4625866
> ?.. ..- attr(*, "dimnames")=List of 2
> ?.. .. ..$ : chr [1:2] "coords.x1" "coords.x2"
> ?.. .. ..$ : chr [1:2] "min" "max"
> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> ?.. .. ..@ projargs: chr NA
>> class(gpsori1$Date)
> [1] "factor"
>> class(gpsori1$Time)
> [1] "factor"
>
> After your message I thought it could be because of the factors, but the
> following does not work either:
>
>> gpsori1 ?<-
>> read.table("MATA20090729/MATA20090729_1.csv",sep=",",header=T,stringsAsFactors
>> =F)> coordinates(gpsori1) <- cbind(gpsori1$UTM.East, gpsori1$UTM.North)
>> writeOGR(gpsori1, dsn="MATA20090729",
>> layer="MATA20090729gps1",driver="ESRI Shapefile")
> Error in writeOGR(gpsori1, dsn = "MATA20090729", layer = "MATA20090729gps1",
> ?:
> ?unknown data type
>
>> summary(gpsori1)
> Object of class SpatialPointsDataFrame
> Coordinates:
> ? ? ? ? ? ? ?min ? ? max
> coords.x1 ?453020 ?457145
> coords.x2 4623500 4625866
> Is projected: NA
> proj4string : [NA]
> Number of points: 2096
> Data attributes:
> ? ? ? No ? ? ? ? ? ?UTM.Zone ? UTM.Ch ? ? ? ? ? UTM.East
> ?Min. ? : ? 1.0 ? Min. ? :31 ? Mode:logical ? Min. ? :453020
> ?1st Qu.: 524.8 ? 1st Qu.:31 ? TRUE:2096 ? ? ?1st Qu.:453601
> ?Median :1048.5 ? Median :31 ? NA's:0 ? ? ? ? Median :454140
> ?Mean ? :1048.5 ? Mean ? :31 ? ? ? ? ? ? ? ? ?Mean ? :454418
> ?3rd Qu.:1572.2 ? 3rd Qu.:31 ? ? ? ? ? ? ? ? ?3rd Qu.:455120
> ?Max. ? :2096.0 ? Max. ? :31 ? ? ? ? ? ? ? ? ?Max. ? :457145
> ? UTM.North ? ? ? ? ?Altitude ? ? ? ?Date ? ? ? ? ? ? ? Time
> ?Min. ? :4623500 ? Min. ? :1648 ? Length:2096 ? ? ? ?Length:2096
> ?1st Qu.:4624886 ? 1st Qu.:1795 ? Class :character ? Class :character
> ?Median :4625170 ? Median :1821 ? Mode ?:character ? Mode ?:character
> ?Mean ? :4625068 ? Mean ? :1835
> ?3rd Qu.:4625338 ? 3rd Qu.:1885
> ?Max. ? :4625866 ? Max. ? :1952
>
> Perhaps the NA for proj4string ?
>
> Agus
>
>
> Michael Sumner wrote:
>>
>> Hi Agustin, you will need to determine which columns in the data frame
>> are causing problems.
>>
>> Can you run this and let us know what you see?
>>
>> summary(gpsori1)
>>
>> For example, you cannot write POSIXct columns to SHP and would need to
>> convert to text, or numeri:
>>
>> library(rgdal)
>> d <- data.frame(x = 1:10, y = 1:10, z = 1:10)
>> coordinates(d) <- ~x+y
>>
>> ## OK
>> writeOGR(d, ".", "test", "ESRI Shapefile")
>> unlink("test.shp")
>>
>> d$z <- Sys.time() + 1:10
>> ## not OK
>> writeOGR(d, ".", "test", "ESRI Shapefile")
>>
>>
>> Regards, Mike.
>>
>>
>>
>> On Thu, Nov 5, 2009 at 7:11 AM, Agustin Lobo <alobolistas at gmail.com>
>> wrote:
>>>
>>> I'm puzzled with this:
>>>
>>>> class(gpsori1)
>>>
>>> [1] "SpatialPointsDataFrame"
>>> attr(,"package")
>>> [1] "sp"
>>>>
>>>> writeOGR(gpsori1, dsn="CAST20090907",
>>>> layer="CAST20090907gps1",driver="ESRI Shapefile")
>>>
>>> Error in writeOGR(gpsori1, dsn = "CAST20090907", layer =
>>> "CAST20090907gps1",
>>> ?:
>>> ?unknown data type
>>>
>>> Am I doing something wrong or is there a recent change that I'm not aware
>>> of?
>>>
>>> Thanks
>>>
>>> Agus
>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>
> --
> Dr. Agustin Lobo
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
> LLuis Sole Sabaris s/n
> 08028 Barcelona
> Spain
> Tel. 34 934095410
> Fax. 34 934110012
> email: Agustin.Lobo at ija.csic.es
> http://www.ija.csic.es/gt/obster
>


From BRWIN338 at aol.com  Thu Nov  5 08:19:52 2009
From: BRWIN338 at aol.com (BRWIN338 at aol.com)
Date: Thu, 5 Nov 2009 02:19:52 EST
Subject: [R-sig-Geo] Merging two spatial polygon objects
Message-ID: <d34.5bb6f730.3823d698@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/0fca7083/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov  5 12:06:04 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2009 12:06:04 +0100 (CET)
Subject: [R-sig-Geo] Merging two spatial polygon objects
In-Reply-To: <d34.5bb6f730.3823d698@aol.com>
References: <d34.5bb6f730.3823d698@aol.com>
Message-ID: <alpine.LRH.2.00.0911051201040.32299@reclus.nhh.no>

On Thu, 5 Nov 2009, BRWIN338 at aol.com wrote:

> Good Evening
>
> I have two spatial polygon objects. The first  "StMaps50"  contains state
> level map data for the 50 US states.  The second  "CAMaps" contains
> provincial and territorial polygons  for Canada.  I would like to merge these two
> objects into a  single Canada-US spatial polygon object that I could then write
> to a  shapefile.  The data fields in the @data component have been
> constructed  with identical fields.  I have tried using the  maptools   "spRbind"
> function but get the following error  message:

With recent versions of sp, you can say:

rownames(StMaps50)
rownames(CAMaps)

By default, the IDs for each Polygons object, corresponding to each row in 
the data.frame object in the "data" slot, are the feature IDs read in form 
file. In the case of shapefiles, these usually run from "0" to say n-1. So 
they will be the same. Use the spChFIDs() method in maptools to change the 
IDs of at least one of your objects to disambiguate them (say paste "US" 
in front of the US ones and "CAN" in front of the Canadian ones). I'm also 
assuming the the coordinate reference systems are identical.

Hope this helps,

Roger

>
>> spRbind(StMaps50,CAMaps)
> Error in spRbind(as(obj,  "SpatialPolygons"), as(x, "SpatialPolygons")) :
> non-unique polygon  IDs
>
> I have attached additional information below.
> Any suggestions would be appreciated.
>
> Joe
>
> ##################################################
>>  class(StMaps50)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1]  "sp"
>
>> _StMaps50 at data[1:5_ (mailto:StMaps50 at data[1:5) ,]
> ctry        sname sabbr sfips  pfips
> 1   US   Washington     WA    53    NA
> 2    US      Montana    MT     30    NA
> 3    US        Maine     ME    23    NA
> 4   US North  Dakota    ND    38     NA
> 5   US South Dakota    SD     46    NA
>
>> class(CAMaps)
> [1]  "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
>> _CAMaps at data_ (mailto:CAMaps at data)
> ctry                  sname sabbr sfips pfips
> 0     CA                Alberta   ALB    61  CA01
> 1     CA      British Columbia    BCL    62  CA02
> 2     CA               Manitoba   MNT    63  CA03
> 3     CA         New Brunswick    NBR    64  CA04
> 4     CA           Nova  Scotia   NSC    65  CA07
> 5    CA  Northwest Territories   NTR    66   CA06
> 6     CA           Newfoundland   NWF    67   CA05
> 7     CA                Ontario   ONT    68  CA08
> 8     CA  Prince Edward Island   PEI    69   CA09
> 9     CA                 Quebec   QUE    70  CA10
> 10    CA           Saskatchewan   SSK    71  CA11
> 11    CA       Yukon Territory    YTR    72  CA12
>>
> ################################################
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Thu Nov  5 12:12:39 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 05 Nov 2009 12:12:39 +0100
Subject: [R-sig-Geo] Problem with writeOGR()
In-Reply-To: <522664f80911041507h7a01b8a2yec48ea751f205dc4@mail.gmail.com>
References: <4AF1E00F.50505@gmail.com>	
	<522664f80911041413v5a1f99f4vf836bbb5fcd10066@mail.gmail.com>	
	<4AF2019B.4020403@gmail.com>
	<522664f80911041507h7a01b8a2yec48ea751f205dc4@mail.gmail.com>
Message-ID: <4AF2B327.1070206@gmail.com>

Thanks, that was it.
The problem comes from the csv input file having a column with "T"
from the utm zone (31T). Just setting:
 > gpsori1[,3]<-"T"

solves the problem and I can go on:
 > coordinates(gpsori1) <- cbind(gpsori1$UTM.East, gpsori1$UTM.North)
 > writeOGR(gpsori1, dsn="THOME20090729", layer="THOME20090729gps1",driver="ESRI 
Shapefile")

Agus

Michael Sumner wrote:
> My guess is that it's the logical column.
> 
> Try
> 
> gpsori1$UTM.Ch <- as.character(gpsori1$UTM.Ch)
> writeOGR(gpsori1, dsn="MATA20090729",
> layer="MATA20090729gps1",driver="ESRI Shapefile")
> 
> 
> On Thu, Nov 5, 2009 at 9:35 AM, Agustin Lobo <aloboaleu at gmail.com> wrote:
>> Thanks,
>> No POSIXct fields:
>>> summary(gpsori1)
>> Object of class SpatialPointsDataFrame
>> Coordinates:
>>              min     max
>> coords.x1  453020  457145
>> coords.x2 4623500 4625866
>> Is projected: NA
>> proj4string : [NA]
>> Number of points: 2096
>> Data attributes:
>>       No            UTM.Zone   UTM.Ch           UTM.East
>>  Min.   :   1.0   Min.   :31   Mode:logical   Min.   :453020
>>  1st Qu.: 524.8   1st Qu.:31   TRUE:2096      1st Qu.:453601
>>  Median :1048.5   Median :31   NA's:0         Median :454140
>>  Mean   :1048.5   Mean   :31                  Mean   :454418
>>  3rd Qu.:1572.2   3rd Qu.:31                  3rd Qu.:455120
>>  Max.   :2096.0   Max.   :31                  Max.   :457145
>>
>>   UTM.North          Altitude            Date            Time
>>  Min.   :4623500   Min.   :1648   2009/07/29:2095   08:49:04:   3
>>  1st Qu.:4624886   1st Qu.:1795   2009/07/30:   1   08:49:05:   2
>>  Median :4625170   Median :1821                     08:49:06:   2
>>  Mean   :4625068   Mean   :1835                     08:49:07:   2
>>  3rd Qu.:4625338   3rd Qu.:1885                     08:49:08:   2
>>  Max.   :4625866   Max.   :1952                     08:49:09:   2
>>                                                    (Other) :2083
>>> str(gpsori1)
>> Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
>>  ..@ data       :'data.frame': 2096 obs. of  8 variables:
>>  .. ..$ No       : int [1:2096] 1 2 3 4 5 6 7 8 9 10 ...
>>  .. ..$ UTM.Zone : int [1:2096] 31 31 31 31 31 31 31 31 31 31 ...
>>  .. ..$ UTM.Ch   : logi [1:2096] TRUE TRUE TRUE TRUE TRUE TRUE ...
>>  .. ..$ UTM.East : int [1:2096] 453245 453245 453245 453245 453245 453245
>> 453245 453245 453245 453245 ...
>>  .. ..$ UTM.North: int [1:2096] 4625338 4625338 4625338 4625338 4625338
>> 4625338 4625338 4625338 4625338 4625338 ...
>>  .. ..$ Altitude : num [1:2096] 1648 1648 1648 1648 1648 ...
>>  .. ..$ Date     : Factor w/ 2 levels "2009/07/29","2009/07/30": 1 1 1 1 1 1
>> 1 1 1 1 ...
>>  .. ..$ Time     : Factor w/ 1452 levels "08:23:05","08:23:07",..: 1 2 3 4 5
>> 6 7 8 9 10 ...
>>  ..@ coords.nrs : num(0)
>>  ..@ coords     : num [1:2096, 1:2] 453245 453245 453245 453245 453245 ...
>>  .. ..- attr(*, "dimnames")=List of 2
>>  .. .. ..$ : NULL
>>  .. .. ..$ : chr [1:2] "coords.x1" "coords.x2"
>>  ..@ bbox       : num [1:2, 1:2] 453020 4623500 457145 4625866
>>  .. ..- attr(*, "dimnames")=List of 2
>>  .. .. ..$ : chr [1:2] "coords.x1" "coords.x2"
>>  .. .. ..$ : chr [1:2] "min" "max"
>>  ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>>  .. .. ..@ projargs: chr NA
>>> class(gpsori1$Date)
>> [1] "factor"
>>> class(gpsori1$Time)
>> [1] "factor"
>>
>> After your message I thought it could be because of the factors, but the
>> following does not work either:
>>
>>> gpsori1  <-
>>> read.table("MATA20090729/MATA20090729_1.csv",sep=",",header=T,stringsAsFactors
>>> =F)> coordinates(gpsori1) <- cbind(gpsori1$UTM.East, gpsori1$UTM.North)
>>> writeOGR(gpsori1, dsn="MATA20090729",
>>> layer="MATA20090729gps1",driver="ESRI Shapefile")
>> Error in writeOGR(gpsori1, dsn = "MATA20090729", layer = "MATA20090729gps1",
>>  :
>>  unknown data type
>>
>>> summary(gpsori1)
>> Object of class SpatialPointsDataFrame
>> Coordinates:
>>              min     max
>> coords.x1  453020  457145
>> coords.x2 4623500 4625866
>> Is projected: NA
>> proj4string : [NA]
>> Number of points: 2096
>> Data attributes:
>>       No            UTM.Zone   UTM.Ch           UTM.East
>>  Min.   :   1.0   Min.   :31   Mode:logical   Min.   :453020
>>  1st Qu.: 524.8   1st Qu.:31   TRUE:2096      1st Qu.:453601
>>  Median :1048.5   Median :31   NA's:0         Median :454140
>>  Mean   :1048.5   Mean   :31                  Mean   :454418
>>  3rd Qu.:1572.2   3rd Qu.:31                  3rd Qu.:455120
>>  Max.   :2096.0   Max.   :31                  Max.   :457145
>>   UTM.North          Altitude        Date               Time
>>  Min.   :4623500   Min.   :1648   Length:2096        Length:2096
>>  1st Qu.:4624886   1st Qu.:1795   Class :character   Class :character
>>  Median :4625170   Median :1821   Mode  :character   Mode  :character
>>  Mean   :4625068   Mean   :1835
>>  3rd Qu.:4625338   3rd Qu.:1885
>>  Max.   :4625866   Max.   :1952
>>
>> Perhaps the NA for proj4string ?
>>
>> Agus
>>
>>
>> Michael Sumner wrote:
>>> Hi Agustin, you will need to determine which columns in the data frame
>>> are causing problems.
>>>
>>> Can you run this and let us know what you see?
>>>
>>> summary(gpsori1)
>>>
>>> For example, you cannot write POSIXct columns to SHP and would need to
>>> convert to text, or numeri:
>>>
>>> library(rgdal)
>>> d <- data.frame(x = 1:10, y = 1:10, z = 1:10)
>>> coordinates(d) <- ~x+y
>>>
>>> ## OK
>>> writeOGR(d, ".", "test", "ESRI Shapefile")
>>> unlink("test.shp")
>>>
>>> d$z <- Sys.time() + 1:10
>>> ## not OK
>>> writeOGR(d, ".", "test", "ESRI Shapefile")
>>>
>>>
>>> Regards, Mike.
>>>
>>>
>>>
>>> On Thu, Nov 5, 2009 at 7:11 AM, Agustin Lobo <alobolistas at gmail.com>
>>> wrote:
>>>> I'm puzzled with this:
>>>>
>>>>> class(gpsori1)
>>>> [1] "SpatialPointsDataFrame"
>>>> attr(,"package")
>>>> [1] "sp"
>>>>> writeOGR(gpsori1, dsn="CAST20090907",
>>>>> layer="CAST20090907gps1",driver="ESRI Shapefile")
>>>> Error in writeOGR(gpsori1, dsn = "CAST20090907", layer =
>>>> "CAST20090907gps1",
>>>>  :
>>>>  unknown data type
>>>>
>>>> Am I doing something wrong or is there a recent change that I'm not aware
>>>> of?
>>>>
>>>> Thanks
>>>>
>>>> Agus
>>>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>> --
>> Dr. Agustin Lobo
>> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
>> LLuis Sole Sabaris s/n
>> 08028 Barcelona
>> Spain
>> Tel. 34 934095410
>> Fax. 34 934110012
>> email: Agustin.Lobo at ija.csic.es
>> http://www.ija.csic.es/gt/obster
>>
> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: alobolistas.vcf
Type: text/x-vcard
Size: 260 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/96b3e832/attachment.vcf>

From edalaze at gmail.com  Thu Nov  5 12:23:06 2009
From: edalaze at gmail.com (Eda Laze)
Date: Thu, 5 Nov 2009 12:23:06 +0100
Subject: [R-sig-Geo] Post the email address
Message-ID: <c7730d730911050323oded29bena079bac338257324@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/91d83efd/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov  5 12:32:30 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2009 12:32:30 +0100 (CET)
Subject: [R-sig-Geo] Merging two spatial polygon objects
In-Reply-To: <alpine.LRH.2.00.0911051201040.32299@reclus.nhh.no>
References: <d34.5bb6f730.3823d698@aol.com>
	<alpine.LRH.2.00.0911051201040.32299@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.0911051231160.32299@reclus.nhh.no>

On Thu, 5 Nov 2009, Roger Bivand wrote:

> On Thu, 5 Nov 2009, BRWIN338 at aol.com wrote:
>
>> Good Evening
>> 
>> I have two spatial polygon objects. The first  "StMaps50"  contains state
>> level map data for the 50 US states.  The second  "CAMaps" contains
>> provincial and territorial polygons  for Canada.  I would like to merge 
>> these two
>> objects into a  single Canada-US spatial polygon object that I could then 
>> write
>> to a  shapefile.  The data fields in the @data component have been
>> constructed  with identical fields.  I have tried using the  maptools 
>> "spRbind"
>> function but get the following error  message:
>
> With recent versions of sp, you can say:
>
> rownames(StMaps50)
> rownames(CAMaps)

Sorry, on checking:

row.names(StMaps50)
row.names(CAMaps)

(rownames() is a method for matrices, row.names() for data.frames and 
friends).

Roger

>
> By default, the IDs for each Polygons object, corresponding to each row in 
> the data.frame object in the "data" slot, are the feature IDs read in form 
> file. In the case of shapefiles, these usually run from "0" to say n-1. So 
> they will be the same. Use the spChFIDs() method in maptools to change the 
> IDs of at least one of your objects to disambiguate them (say paste "US" in 
> front of the US ones and "CAN" in front of the Canadian ones). I'm also 
> assuming the the coordinate reference systems are identical.
>
> Hope this helps,
>
> Roger
>
>> 
>>> spRbind(StMaps50,CAMaps)
>> Error in spRbind(as(obj,  "SpatialPolygons"), as(x, "SpatialPolygons")) :
>> non-unique polygon  IDs
>> 
>> I have attached additional information below.
>> Any suggestions would be appreciated.
>> 
>> Joe
>> 
>> ##################################################
>>>  class(StMaps50)
>> [1] "SpatialPolygonsDataFrame"
>> attr(,"package")
>> [1]  "sp"
>> 
>>> _StMaps50 at data[1:5_ (mailto:StMaps50 at data[1:5) ,]
>> ctry        sname sabbr sfips  pfips
>> 1   US   Washington     WA    53    NA
>> 2    US      Montana    MT     30    NA
>> 3    US        Maine     ME    23    NA
>> 4   US North  Dakota    ND    38     NA
>> 5   US South Dakota    SD     46    NA
>> 
>>> class(CAMaps)
>> [1]  "SpatialPolygonsDataFrame"
>> attr(,"package")
>> [1] "sp"
>> 
>>> _CAMaps at data_ (mailto:CAMaps at data)
>> ctry                  sname sabbr sfips pfips
>> 0     CA                Alberta   ALB    61  CA01
>> 1     CA      British Columbia    BCL    62  CA02
>> 2     CA               Manitoba   MNT    63  CA03
>> 3     CA         New Brunswick    NBR    64  CA04
>> 4     CA           Nova  Scotia   NSC    65  CA07
>> 5    CA  Northwest Territories   NTR    66   CA06
>> 6     CA           Newfoundland   NWF    67   CA05
>> 7     CA                Ontario   ONT    68  CA08
>> 8     CA  Prince Edward Island   PEI    69   CA09
>> 9     CA                 Quebec   QUE    70  CA10
>> 10    CA           Saskatchewan   SSK    71  CA11
>> 11    CA       Yukon Territory    YTR    72  CA12
>>> 
>> ################################################
>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edalaze at gmail.com  Thu Nov  5 14:27:26 2009
From: edalaze at gmail.com (Eda Laze)
Date: Thu, 5 Nov 2009 14:27:26 +0100
Subject: [R-sig-Geo] hat matrix in gwr
Message-ID: <c7730d730911050527l6f7eff8fxa78f0521c0acaab3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/37d79189/attachment.pl>

From BRWIN338 at aol.com  Thu Nov  5 14:52:18 2009
From: BRWIN338 at aol.com (BRWIN338 at aol.com)
Date: Thu, 5 Nov 2009 08:52:18 EST
Subject: [R-sig-Geo] Merging two spatial polygon objects
Message-ID: <c3f.5c8b7ddb.38243292@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/883ca0e3/attachment.pl>

From Joshua.Myers at norfolk.gov  Thu Nov  5 14:54:37 2009
From: Joshua.Myers at norfolk.gov (Myers, Joshua)
Date: Thu, 5 Nov 2009 08:54:37 -0500
Subject: [R-sig-Geo] hat matrix in gwr
In-Reply-To: <c7730d730911050527l6f7eff8fxa78f0521c0acaab3@mail.gmail.com>
References: <c7730d730911050527l6f7eff8fxa78f0521c0acaab3@mail.gmail.com>
Message-ID: <9B075A4C00AC004191F2A8C73EB78E62976F91@MAILC-EVS.norfolk.gov>

>From my experience, 3055 observations should not make anything crash or
freeze, although it may take a while to complete the run.  

A few thoughts:

I would make sure you are running the most up-to-date version of spgwr
(and dependent packages) and R.  

Also, I am not an R expert, but it may be that storing the hat matrix is
taking up a lot of memory and causing R to freeze.  It is a long-shot,
but start a clean workspace and try the gwr run again.  Roger, though,
is the one that is more likely to know what is wrong than anyone else.

In addition, make sure you aren't over-fitting your models.  Too many
variables in gwr can cause many problems, not the least of which is the
time it takes to complete the run.


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Eda Laze
Sent: Thursday, November 05, 2009 8:27 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] hat matrix in gwr

Hello,

I am currently using *gwr to make a spatial analysis. Dataset has 3055
observations. As read, this is a considerable number for gwr R to run.
 However, so far, I have suceeded to get local R2 (SDF), etc.

The problem is to get "hatmatrix". When I add "hatmatrix=TRUE" to the
code
(which I get localR2 with), R freezes. I must get hat matrix to
calculate
Moran'I and AICc to compare models.

Could be this a case of large number of observations, or do I miss
anything
else. Furthermore, I could get once AICc with the same dataset and code,
but
not anylonger.

Any feedback is more than welcome. Thank you.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Nov  5 15:13:21 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2009 15:13:21 +0100 (CET)
Subject: [R-sig-Geo] hat matrix in gwr
In-Reply-To: <c7730d730911050527l6f7eff8fxa78f0521c0acaab3@mail.gmail.com>
References: <c7730d730911050527l6f7eff8fxa78f0521c0acaab3@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0911051447550.32299@reclus.nhh.no>

On Thu, 5 Nov 2009, Eda Laze wrote:

> Hello,
>
> I am currently using *gwr to make a spatial analysis. Dataset has 3055
> observations. As read, this is a considerable number for gwr R to run.
> However, so far, I have suceeded to get local R2 (SDF), etc.
>
> The problem is to get "hatmatrix". When I add "hatmatrix=TRUE" to the code
> (which I get localR2 with), R freezes. I must get hat matrix to calculate
> Moran'I and AICc to compare models.
>
> Could be this a case of large number of observations, or do I miss anything
> else. Furthermore, I could get once AICc with the same dataset and code, but
> not anylonger.
>
> Any feedback is more than welcome. Thank you.

Without more information, feedback will not be forthcoming. You should 
provide your sessionInfo() with package version and platform details, 
and the package version of what you claim worked "before". If you inspect 
the CVS source by browsing on sourceforge:

http://r-spatial.cvs.sourceforge.net/viewvc/r-spatial/spgwr/

or the ChangeLog on:

http://cran.r-project.org/web/packages/spgwr/ChangeLog

you will see that a number of changes were made in June this year to bring 
gwr() more into line with GWR3 and the forthcoming GWR4. Since then, if 
hatmatrix=TRUE, a number of extra steps followed, but the computation of 
the hatmatrix was unchanged.

You have not included your verbatim code either, so it is possible that 
you are mistaken if the arguments are not named, and have changed order 
between releases.

You may also find that you should not be using all of your data to fit the 
GWR model with hat matrix, a sample may be sufficient.

You may consider avoiding using GWR in any case, as its appropriateness is 
questionable given many results on forcing problems in coefficient 
estimates (the local coefficients are highly correlated, magnifying any 
collinearity problems in the input data.

Finally, R does not "freeze", what may happen is that your computer starts 
using virtual memory (a temporary disk area) and runs very slowly - 
depending on OS, this may vary. When hatmatrix=TRUE, operations on nxn 
matrices are carried out, so you do need to provide the necessary 
resources and on Windows try to set memory resources to make best use of 
what you have. If you really need a hatmatrix with a 3K by 3K size, get 
more RAM or a different OS, it isn't a good idea, and all bets are off 
test results anyway (for collinear GWR output).

So, run without hatmatrix and check the correlation of the local 
coefficients with cor() and pairs() first.

Hope this helps,

Roger
>
> 	[[alternative HTML version deleted]]

And *do* follow the R posting guide and send messages "text only", you 
should change the settings of your email client. There are many offenders 
here. There are two reasons for "test only" - HTML mail is harder to scan 
for spam (hence the deletion), and HTML mail is much larger in size, so 
increasing the burden on server capacity, that is, the CO2 footprint of 
this list.

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cara.tobin at epfl.ch  Thu Nov  5 16:50:25 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Thu, 5 Nov 2009 16:50:25 +0100
Subject: [R-sig-Geo] Writing ascii grid after kriging
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8B3@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/6144960d/attachment.pl>

From mwkimpel at gmail.com  Thu Nov  5 18:14:28 2009
From: mwkimpel at gmail.com (Mark Kimpel)
Date: Thu, 5 Nov 2009 12:14:28 -0500
Subject: [R-sig-Geo] need to create US map with colors by state
Message-ID: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/e6c3699e/attachment.pl>

From alobolistas at gmail.com  Thu Nov  5 19:18:44 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 05 Nov 2009 19:18:44 +0100
Subject: [R-sig-Geo] [GRASS-stats] R packages and GRASS
In-Reply-To: <680907.28304.qm@web56604.mail.re3.yahoo.com>
References: <680907.28304.qm@web56604.mail.re3.yahoo.com>
Message-ID: <4AF31704.1020107@gmail.com>

There is no menu for R in grass. As I've said, in order to use grass from R 
(through R package spgrass6), the best option is  to start R from the grass 
console. Perhaps the problem is that you don't know what the grass console is? 
Then you must get a bit familiar with grass first.

Here (http://grass.itc.it/statsgrass/grass6_r_install.html) it's also pretty clear:

"Usage
You need to start R in a GRASS terminal to make best use of the interface."

Agus

Felipe Carrillo wrote:
> I looked in the help files and I can't find a way to open R from any of the menu options. I wanted to use GRASS from R but it's ok to open R from GRASS for now so I can get familiar with the program but I eventually want to automate GRASS from R. I tried the commands below in GRASS and they seem to work ok, but I don't know how to interact with R yet.
> # set region:
>  g.region rast=elevation.dem
>  
>  # extract some random points from an elevation dataset
>  v.random out=rs n=300
>  
>  # create attribute table:
>  v.db.addtable map=rs columns="elev double"
>  
>  # extract raster data at points
>  v.what.rast vect=rs rast=elevation.dem column=elev
>  
>  # simple display:
>  d.rast elevation.dem
>  d.vect rs size=4
> 
> 
> --- On Thu, 11/5/09, Agustin Lobo <alobolistas at gmail.com> wrote:
> 
>> From: Agustin Lobo <alobolistas at gmail.com>
>> Subject: Re: [GRASS-stats] R packages and GRASS
>> To: "Felipe Carrillo" <mazatlanmexico at yahoo.com>
>> Date: Thursday, November 5, 2009, 8:58 AM
>> (Disregard the attachment, it was
>> just my signature,
>> I was not aware of sending it, just changed the settings
>> of this account)
>>
>> Are you starting R from within the grass console?
>> Agus
>>
>> Felipe Carrillo wrote:
>>> Agustin:
>>> I get the message below while trying to execute from
>> R
>>>> system("g.region rast=elevation.dem") 
>>> Warning message:
>>> In system("g.region rast=elevation.dem") : g.region
>> not found
>>> On the same note, Would you mind sending me the
>> attachment on a different format? This is a government
>> computer and I don't have outlook to open it. Just copy and
>> paste onto notepad or word if you don't mind. Thanks
>>>
>>> Felipe D. Carrillo  Supervisory Fishery
>> Biologist  Department of the Interior  US Fish
>> & Wildlife Service  California, USA
>>>
>>> --- On Thu, 11/5/09, Agustin Lobo <alobolistas at gmail.com>
>> wrote:
>>>> From: Agustin Lobo <alobolistas at gmail.com>
>>>> Subject: Re: [GRASS-stats] R packages and GRASS
>>>> To: "Felipe Carrillo" <mazatlanmexico at yahoo.com>
>>>> Cc: "GRASS STATS" <grass-stats at lists.osgeo.org>
>>>> Date: Thursday, November 5, 2009, 8:04 AM
>>>> which error? we don't see it. Note
>>>> you must start R from within
>>>> the grass console. Actually it's better if, from
>> the grass
>>>> console,
>>>> you launch xterm & and can start R from the
>> new
>>>> terminal.
>>>>
>>>> Agus
>>>>
>>>> Felipe Carrillo wrote:
>>>>> Hi all:
>>>>> I'm brand new to GRASS and this list and just
>> wanted
>>>> to see if someone could point out to what I need
>> to
>>>> synchronize R and GRASS. I already downloaded
>> GRASS 6.3,
>>>> spgrass6 and dependencies and at my first attempt
>> something
>>>> is happening but I can't quite see a way to import
>> data into
>>>> R or run commands from R. I ran into the code
>> below
>>>> yesterday but I can't figure out how to run it
>> from R. I
>>>> tried: system("g.region rast=elevation.dem") but I
>> get an
>>>> error message. Thanks
>>>>> # set region:
>>>>> g.region rast=elevation.dem
>>>>>
>>>>> # extract some random points from an
>> elevation
>>>> dataset
>>>>> v.random out=rs n=300
>>>>>
>>>>> # create attribute table:
>>>>> v.db.addtable map=rs columns="elev double"
>>>>>
>>>>> # extract raster data at points
>>>>> v.what.rast vect=rs rast=elevation.dem
>> column=elev
>>>>> # simple display:
>>>>> d.rast elevation.dem
>>>>> d.vect rs size=4
>>>>>
>>>>> # start R
>>>>> R
>>>>>
>>>>>
>>>>> Felipe D. Carrillo  Supervisory Fishery
>>>> Biologist  Department of the Interior 
>> US Fish
>>>> & Wildlife Service  California, USA
>>>>>     
>>>>    
>> _______________________________________________
>>>>> grass-stats mailing list
>>>>> grass-stats at lists.osgeo.org
>>>>> http://lists.osgeo.org/mailman/listinfo/grass-stats
>>>>>
>>>>>     
>>>
>>>        
> 
> 
>       
>


From Greg.Snow at imail.org  Thu Nov  5 19:49:51 2009
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 5 Nov 2009 11:49:51 -0700
Subject: [R-sig-Geo] need to create US map with colors by state
In-Reply-To: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>
References: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F518DD9A@LP-EXMBVS10.CO.IHC.COM>

The help page for state.vbm in the TeachingDemos package shows an example of doing this.  The procedure is similar for other maps that can be imported and plotted using the sp and maptools packages.  The tricky part is to make sure that your color specifications line up properly with the data and the polygons, this is most important when a single state is made up of multiple polygons (one advantage of state.vbm is that it is 1 polygon per state).

Hope this helps,

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Mark Kimpel
> Sent: Thursday, November 05, 2009 10:14 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] need to create US map with colors by state
> 
> I need to do something quite simple, but a search of the "CRAN Task
> View:
> Analysis of Spatial Data" has not revealed to me the best way to do
> this.
> What I would like to do is plot a map of the U.S. with each state's
> color
> corresponding to heatmap colors of a population statistic. For example,
> dark
> red could be a state with the highest number of H1N1 cases, pink with
> an
> intermediate number, and white with no cases. An ability to overlay the
> center of the state with the actual statistic would be nice but not
> necessary.
> 
> Is there a straightforward method to accomplish this? A vignette
> perhaps?
> 
> Thanks,
> 
> Mark
> 
> Mark W. Kimpel MD  ** Neuroinformatics ** Dept. of Psychiatry
> Indiana University School of Medicine
> 
> 15032 Hunter Court, Westfield, IN  46074
> 
> (317) 490-5129 Work, & Mobile & VoiceMail
> (317) 399-1219 Skype No Voicemail please
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From ggrothendieck at gmail.com  Thu Nov  5 20:00:06 2009
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 5 Nov 2009 14:00:06 -0500
Subject: [R-sig-Geo] need to create US map with colors by state
In-Reply-To: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>
References: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>
Message-ID: <971536df0911051100w155c5381r99209ff5a496791c@mail.gmail.com>

Try this:

library(help = maps)

# show polygon names in order
map("state", fill = TRUE, plot = FALSE, names = TRUE)

# make first polygon have color 1, second 2, etc.
map("state", fill = TRUE, col = 1:63)


On Thu, Nov 5, 2009 at 12:14 PM, Mark Kimpel <mwkimpel at gmail.com> wrote:
> I need to do something quite simple, but a search of the "CRAN Task View:
> Analysis of Spatial Data" has not revealed to me the best way to do this.
> What I would like to do is plot a map of the U.S. with each state's color
> corresponding to heatmap colors of a population statistic. For example, dark
> red could be a state with the highest number of H1N1 cases, pink with an
> intermediate number, and white with no cases. An ability to overlay the
> center of the state with the actual statistic would be nice but not
> necessary.
>
> Is there a straightforward method to accomplish this? A vignette perhaps?
>
> Thanks,
>
> Mark
>
> Mark W. Kimpel MD ?** Neuroinformatics ** Dept. of Psychiatry
> Indiana University School of Medicine
>
> 15032 Hunter Court, Westfield, IN ?46074
>
> (317) 490-5129 Work, & Mobile & VoiceMail
> (317) 399-1219 Skype No Voicemail please
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Henk.Sierdsema at sovon.nl  Thu Nov  5 20:38:10 2009
From: Henk.Sierdsema at sovon.nl (Henk Sierdsema)
Date: Thu, 5 Nov 2009 20:38:10 +0100
Subject: [R-sig-Geo] need to create US map with colors by state
References: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>
Message-ID: <F7A3EE6B27F4D54B9CCAAB767F1B5AA301952421@mail.sovon.nl>

Hi Mark,
 
The 'ASDAR'-book (Bivand et al, Applied Spatial Data Analysis with R http://www.asdar-book.org/) contains a lot of examples of desease mapping and modelling. From the website you can also download example data sets and scripts.
 
Here is an (extended) example from page 91 onwards from disease mapping in Scotland.getwd()

library(maptools)
library(rgdal)
library(RColorBrewer)
scot_dat <- read.table("scotland.dat", skip = 1) 
                                ## from http://www.sph.emory.edu/~lwaller/book/ch2/scotland.dat <http://www.sph.emory.edu/~lwaller/book/ch2/scotland.dat> 
names(scot_dat) <- c("District", "Observed", "Expected","PcAFF", "Latitude", "Longitude")
scot_dat$District
scot_LL <- readOGR(".", "scot")  # from http://www.sph.emory.edu/~lwaller/book/ch9/scot.shp <http://www.sph.emory.edu/~lwaller/book/ch9/scot.shp>  ,
                                 # http://www.sph.emory.edu/~lwaller/book/ch9/scot.shx <http://www.sph.emory.edu/~lwaller/book/ch9/scot.shx>   and
                                 # http://www.sph.emory.edu/~lwaller/book/ch9/scot.dbf <http://www.sph.emory.edu/~lwaller/book/ch9/scot.dbf> 
                                 
scot_dat1 <- scot_dat[match(scot_LL$ID, scot_dat$District), ]
row.names(scot_dat1) <- sapply(slot(scot_LL, "polygons"),function(x) slot(x, "ID"))
scot_LLa <- spCbind(scot_LL, scot_dat1)
all.equal(scot_LLa$ID, scot_LLa$District)
str(scot_LLa at data <mailto:scot_LLa at data> )
rw.colors <- colorRampPalette(c("white","red"))
spplot(scot_LLa, "Observed", col.regions=rw.colors(100000), main='number of cases of Scottish Lip cancer' )

 
The most important line here is 'scot_LLa <- spCbind(scot_LL, scot_dat1)' where you can combine your spatial polygones (like a shape imported with 'readShapePoly() or readOGR() ) with a dataframe containing information on the deseases.  

Success,
 
Henk
 
 
 
 
 

________________________________

Van: r-sig-geo-bounces at stat.math.ethz.ch namens Mark Kimpel
Verzonden: do 5-11-2009 18:14
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] need to create US map with colors by state



I need to do something quite simple, but a search of the "CRAN Task View:
Analysis of Spatial Data" has not revealed to me the best way to do this.
What I would like to do is plot a map of the U.S. with each state's color
corresponding to heatmap colors of a population statistic. For example, dark
red could be a state with the highest number of H1N1 cases, pink with an
intermediate number, and white with no cases. An ability to overlay the
center of the state with the actual statistic would be nice but not
necessary.

Is there a straightforward method to accomplish this? A vignette perhaps?

Thanks,

Mark

Mark W. Kimpel MD  ** Neuroinformatics ** Dept. of Psychiatry
Indiana University School of Medicine

15032 Hunter Court, Westfield, IN  46074

(317) 490-5129 Work, & Mobile & VoiceMail
(317) 399-1219 Skype No Voicemail please

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Nov  5 21:04:46 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2009 21:04:46 +0100 (CET)
Subject: [R-sig-Geo] need to create US map with colors by state
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC62F518DD9A@LP-EXMBVS10.CO.IHC.COM>
References: <6b93d1830911050914w42e6b80dv7b911d1ffd7ecc2c@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC62F518DD9A@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <alpine.LRH.2.00.0911051954450.32299@reclus.nhh.no>

On Thu, 5 Nov 2009, Greg Snow wrote:

> The help page for state.vbm in the TeachingDemos package shows an 
> example of doing this.  The procedure is similar for other maps that can 
> be imported and plotted using the sp and maptools packages.  The tricky 
> part is to make sure that your color specifications line up properly 
> with the data and the polygons, this is most important when a single 
> state is made up of multiple polygons (one advantage of state.vbm is 
> that it is 1 polygon per state).

Right. This is a data representation question, followed by a projection 
question (and maybe the offsetting of Hawaii and Alaska). An extended 
example (could someone maybe adapt as a movie?):

library(XML)
tf <- tempfile()
# grab some data
download.file("http://www.cdc.gov/flu/weekly/flureport.xml", tf)
tr0 <- xmlTreeParse(tf)
Chld <- xmlChildren(xmlRoot(tr0))
names(Chld)
# choose the most recent week
caption <- xmlAttrs(Chld[[56]])["subtitle"]
t56 <- xmlChildren(Chld[[56]])
names(t56)
# extract the states by abbreviation and activity level
abbrev <- character(length(t56))
label <- character(length(t56))
for (i in 1:length(t56)) {
   here <- xmlChildren(t56[[i]])
   abbrev[i] <- xmlValue(here[["abbrev"]])
   label[i] <- xmlValue(here[["label"]])
}
# get boundaries from the maps package
library(maps)
library(maptools)
sts <- map("state", fill=TRUE, plot=FALSE)
# convert to spatial polygons combining polygons with the same
# first name component
IDs <- sapply(strsplit(sts$names, ":"), function(x) x[1])
sp_sts <- map2SpatialPolygons(sts, IDs=IDs,
  proj4string=CRS("+proj=longlat +datum=WGS84"))
# match names and their abbreviations
data(state)
o <- match(row.names(sp_sts), tolower(state.name))
ABBs <- state.abb[o]
# add DC as we have a polygon but no abbreviation
ABBs[is.na(ABBs)] <- "DC"
# match the CDC and maps abbreviations
oo <- match(ABBs, abbrev)
# re-order the labels
label42 <- label[oo]
# change the SpatialPolygons names to their abbreviations
sp_sts1 <- spChFIDs(sp_sts, ABBs)
# make a SpatialPolygonsDataFrame
df <- data.frame(row.names=ABBs, label=factor(label42))
spdf <- SpatialPolygonsDataFrame(sp_sts1, df)
# and plot (could use better palette)
spplot(spdf, "label", main=caption)
# zooming in on DC to check if OK.
spplot(spdf, "label", xlim=c(-85, -75), ylim=c(35, 41), main=caption)

which match the display on:

http://www.cdc.gov/h1n1flu/updates/us/

for the states and entities for which there were boundaries in the source 
used. Other boundaries may be found as shapefiles on the US Census site.

To get to the projection used on the CDC webpage, use spTransform() in 
the rgdal package.

Access to US data continues to please, and lead to envy!

Roger

>
> Hope this helps,
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From rusers.sh at gmail.com  Fri Nov  6 01:16:10 2009
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 6 Nov 2009 08:16:10 +0800
Subject: [R-sig-Geo] Correcting errors in the loops
Message-ID: <a835c81e0911051616y198e6584xad2de91527c57255@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091106/49465939/attachment.pl>

From gianni.lavaredo at gmail.com  Fri Nov  6 03:50:41 2009
From: gianni.lavaredo at gmail.com (gianni lavaredo)
Date: Thu, 5 Nov 2009 18:50:41 -0800
Subject: [R-sig-Geo] ratio 1:1 of dimension X and Y axes in a plot
Message-ID: <518dff330911051850h1af88611l39d63b1613886e92@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091105/5c12180a/attachment.pl>

From pierre.roudier at gmail.com  Fri Nov  6 03:54:52 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Fri, 6 Nov 2009 13:54:52 +1100
Subject: [R-sig-Geo] ratio 1:1 of dimension X and Y axes in a plot
In-Reply-To: <518dff330911051850h1af88611l39d63b1613886e92@mail.gmail.com>
References: <518dff330911051850h1af88611l39d63b1613886e92@mail.gmail.com>
Message-ID: <e4178da60911051854y3dc01fd1lb26f042cf767d20b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091106/6fa3d4cf/attachment.pl>

From breitbach at uni-mainz.de  Sat Nov  7 19:30:04 2009
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Sat, 7 Nov 2009 19:30:04 +0100
Subject: [R-sig-Geo] Distance from given coordinate to margin of kernel
Message-ID: <6634A5A114BA554C927CF724BA504041019B815359AB@EXCHANGE-02.zdv.uni-mainz.de>

Dear Community,

this time I have a rather difficult problem to solve and I failed so far ... I now hope that there is a solution slumbering somewhere here ...

Situation:
I have several polygons which represent seperated areas of one 95 % UD-Kernel homerange calculation. Now I need to find the radius of the smallest possible circle that is able to enclose all areas of this homerange. I was already able calculate the centroid of all points inside all included areas of the homerange as the center for the circle. I now need to calculate the maximum distance from the centroid to the most distant bit of margin from any of the polygons. Any ideas about that? I later have to do it for many homeranges that can include several polygons.

I did about the same for MCPs before, but it is relatively easy in that case because the margins of MCPs are definded by points/coordinates. So it is simply a calculation of the distance from the centroid to most distant point of the points that enclose the MCP area. In the case of the kernel the margins or contour lines do not usually correspond with point.

I hope that any of you has an idea about that ...?!

Cheers,

Nils

From alobolistas at gmail.com  Mon Nov  9 08:01:08 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Mon, 09 Nov 2009 08:01:08 +0100
Subject: [R-sig-Geo] metatdata
Message-ID: <4AF7BE34.9030005@gmail.com>

Hi!
Is anyone thinking on designing metadata for R spatial objects?
I've seen there are metadata facilities in Bioconductor for genomics,
perhaps we could get some inspiration from them?

Agus


From Roger.Bivand at nhh.no  Mon Nov  9 09:29:08 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Nov 2009 09:29:08 +0100 (CET)
Subject: [R-sig-Geo] metatdata
In-Reply-To: <4AF7BE34.9030005@gmail.com>
References: <4AF7BE34.9030005@gmail.com>
Message-ID: <alpine.LRH.2.00.0911090903160.27617@reclus.nhh.no>

On Mon, 9 Nov 2009, Agustin Lobo wrote:

> Hi!
> Is anyone thinking on designing metadata for R spatial objects?
> I've seen there are metadata facilities in Bioconductor for genomics,
> perhaps we could get some inspiration from them?

You are welcome to try, naturally. The S3 data.frame object on which they 
are based has no such facility built in. comment() can be used to set and 
get metadata on arbitrary objects, such as S3 data.frame and *lm fit 
objects. Sometimes modifications on that object will inherit the comment 
attribute, sometimes not. The S language metadata system is called 
history(), really - saving journals allows analyses to be reconstructed. I 
don't know anyone who updated comments manually. But comment() could be 
used to add metadata to the data.frame in the data slot, with it being up 
to the user to set and update this.

Bioconductor metadata is most often calibration data that are used in 
analysis rather than a lineage paper-trail, I believe. Then it does make 
sense to package two kinds of data - the calibration metadata and 
observations made with that instrument, by giving each set of 
observations a pointer to the appropriate calibration constants.

Timestamping of R objects has been discussed on R lists many times without 
any change being introduced - the processing and storage overheads were 
seen as too large to make sense. So the current recommendation is to use 
comment() updated manually. It seems to work on Spatial* objects, even 
though attributes (like the comment) are S3 and slots (the contents of the 
object) are S4.

In fact the Spatial class in some ways is the minimal metadata for the 
Spatial* family - a bounding box and a coordinate reference system. These 
are consistently updated for all operations on the family, and the history 
mechanism is used for lineage.

Hope this helps,

Roger

>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Mon Nov  9 10:39:10 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 9 Nov 2009 09:39:10 +0000
Subject: [R-sig-Geo] metatdata
In-Reply-To: <4AF7BE34.9030005@gmail.com>
References: <4AF7BE34.9030005@gmail.com>
Message-ID: <d8ad40b50911090139h5624f52al4ab976bebc131a1a@mail.gmail.com>

On Mon, Nov 9, 2009 at 7:01 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
> Is anyone thinking on designing metadata for R spatial objects?
> I've seen there are metadata facilities in Bioconductor for genomics,
> perhaps we could get some inspiration from them?

 I think you need to give us some examples of what you'd like to do. A
lot of work on metadata is data-type-agnostic, so is a general R
question anyway and hence something for R-dev - for example
implementing Dublin Core metadata for all R objects. This already
seems to be implemented for the tm packages:

http://finzi.psych.upenn.edu/R/library/tm/html/meta.html

 As Roger has said, it's tricky to keep attributes and metadata stuck
to R objects once you start manipulating them, assuming that's what
you want to do. It may be that you just want a set of classes for
handling spatial metadata (and this I think is a prerequisite to being
able to store them attached to R objects anyway). I've just had a look
at the OGC web site and there's a few standards for metadata there -
mostly in conjunction with catalogue service design. Check that out.

 I find the best thing anyone can do when saying 'can we do something
with X' is to give a 'user story' - including (fictional) transcripts,
example:

# fred wants to identify himself as the creator of this map:
 map = readOGR("foo.shp")
 metadata(map,"author")="Fred Foo"

 - that's an example of tightly-coupled metadata, the kind that R will
probably drop if you do map2=map1[1:10,]

# fred wants to keep track of who is the creator of this map:
 map = readOGR("foo.shp")
 mapMetadata=DublinCore(author="Fred Foo",...)

 - that's an example of loosely-coupled metadata, stored in a separate
object and subject to formal constraints on structure. Any updates are
the responsibility of the user.

Barry


From cara.tobin at epfl.ch  Mon Nov  9 11:37:02 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Mon, 9 Nov 2009 11:37:02 +0100
Subject: [R-sig-Geo] Kriging with External Drift, multivariate experience?
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8BE@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091109/f662b635/attachment.pl>

From edzer.pebesma at uni-muenster.de  Mon Nov  9 11:42:00 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 09 Nov 2009 11:42:00 +0100
Subject: [R-sig-Geo] Kriging with External Drift,
	multivariate experience?
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8BE@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8BE@REX2.intranet.epfl.ch>
Message-ID: <4AF7F1F8.2090307@uni-muenster.de>



Tobin Cara wrote:
> Hello,
>
> Thank you all for your previous help. I began using R 2 weeks ago, and I am getting somewhere finally. I have been able to run universal kriging with a Digital Elevation Model trend. Now, does anyone have experience with kriging more than one trend variable?
>
> I assume you have to have the other variables defined at the same locations as the original grid and then at the new grid. However, can more than one new grid be defined?
>
> For example,
>
> elev_ked <- krige(meanPrec~Z+LAM, meanPrec, newdata=elev, fitted_vario)
>
> In this example, I want to krig the mean Precipitation relative to the elevation Z and a Limited Area Model (LAM). There is only one way to define the newdata that I know and in this case I am interpolating back to the Digital Elevation Model 'elev'. If I want to interpolate back to the LAM grid, I presume I change to newdata=LAM?
>
> However, is there an approach that uses the entire newdata grid of elev and a LAM grid for interpolation? 
yes; make them into a single object, e.g. by

elev$LAM = LAM[[1]]

which only make sense if elev and LAM have the same topology (grid
structure).
> Do they have to be at the same resolution?
>   
Yes.
> Thank you so much!
>
> Cara
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From cara.tobin at epfl.ch  Mon Nov  9 12:18:07 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Mon, 9 Nov 2009 12:18:07 +0100
Subject: [R-sig-Geo] grid error for kriging
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C1@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091109/040a44e8/attachment.pl>

From Roger.Bivand at nhh.no  Mon Nov  9 12:27:38 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Nov 2009 12:27:38 +0100 (CET)
Subject: [R-sig-Geo] grid error for kriging
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C1@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C1@REX2.intranet.epfl.ch>
Message-ID: <alpine.LRH.2.00.0911091220080.28414@reclus.nhh.no>

On Mon, 9 Nov 2009, Tobin Cara wrote:

> Hello,
>
> Has anyone ever used a DTM as their grid for interpolation and come 
> across this error. My DTM has pixels 100 m by 100 m, so I really do not 
> understand this error as it is regular. Also, this only happens when I 
> am doing multiple iterations in time.
>
>
>
> Code:
> list_ked[[i]] <- krige(Prec00[,i]~Zloc, locations=DataCoord, newdata=elev, model = fitted_vario)
> [using universal kriging]
>

Please do check the arguments to the formula carefully. If Prec00 is a 
SpatialGridDataFrame, you are not asking for it's i'th variable here. It's 
a design decision that you need Prec00[,,i] to get the variable, or get it 
by name:

library(sp)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
str(meuse.grid[,1])
gridded(meuse.grid) <- TRUE
str(meuse.grid[,1])
fullgrid(meuse.grid) <- TRUE
str(meuse.grid[,1])
str(meuse.grid[,,1])

Maybe helping some users to subset by row and column has removed the 
otherwise prevalent semantic link to data.frame objects, and maybe this 
(tricky) side of the "[" operator on SpatialGridDataFrame objects should 
be reversed?

Roger

>
>
> Error:
> suggested tolerance minimum: 0.25
> Error in points2grid(points, tolerance, round, fuzz.tol) :
> dimension 1 : coordinate intervals are not constant
>
>
> I can rescale the DTM to be less refined (now it is 100 m2 for a 6,000 
> km2 area) if needed.
>
> Thank you again,
>
> Cara
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From karl at huftis.org  Mon Nov  9 12:48:41 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 9 Nov 2009 12:48:41 +0100
Subject: [R-sig-Geo] Finding polygons corresponding to points
Message-ID: <MPG.2562200667fcf4a989699@news.gmane.org>

Dear list members

I have a collection of polygons (a SpatialPolygonsDataFrame object, but 
I can easily convert it to different formats), and a collection of 
coordinate points. Each point corresponds to (at most) one polygon.

For each point, I need to find the corresponding polygon. You can think 
of the points as positions of for example earthquakes, and the polygons 
as state or country borders. For each earthquake, I need to calculate 
the state/country where the earthquake occured.

There are a number of functions to check if a point is inside a given 
polygon, e.g., point.in.polygon, and I *could* write a double loop that 
for each point checks each polygon. But as I have very many points (tens 
of thousands) and hundreds of polygons, this may be quite slow.

Is there an easier and more efficient way of / existing function for 
doing this? As each point is only inside (at most) one polygon, and the 
number of points inside each polygon varies a great deal (for example, 
most earthquakes occur in California), there clearly is much room for 
optimisation.

-- 
Karl Ove Hufthammer


From Roger.Bivand at nhh.no  Mon Nov  9 13:27:16 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Nov 2009 13:27:16 +0100 (CET)
Subject: [R-sig-Geo] Finding polygons corresponding to points
In-Reply-To: <MPG.2562200667fcf4a989699@news.gmane.org>
References: <MPG.2562200667fcf4a989699@news.gmane.org>
Message-ID: <alpine.LRH.2.00.0911091313150.28414@reclus.nhh.no>

On Mon, 9 Nov 2009, Karl Ove Hufthammer wrote:

> Dear list members
>
> I have a collection of polygons (a SpatialPolygonsDataFrame object, but
> I can easily convert it to different formats), and a collection of
> coordinate points. Each point corresponds to (at most) one polygon.
>
> For each point, I need to find the corresponding polygon. You can think
> of the points as positions of for example earthquakes, and the polygons
> as state or country borders. For each earthquake, I need to calculate
> the state/country where the earthquake occured.
>
> There are a number of functions to check if a point is inside a given
> polygon, e.g., point.in.polygon, and I *could* write a double loop that
> for each point checks each polygon. But as I have very many points (tens
> of thousands) and hundreds of polygons, this may be quite slow.
>
> Is there an easier and more efficient way of / existing function for
> doing this? As each point is only inside (at most) one polygon, and the
> number of points inside each polygon varies a great deal (for example,
> most earthquakes occur in California), there clearly is much room for
> optimisation.

Try the relevant overlay() methods in sp. They ought to be fast enough:

library(maptools)
data(wrld_simpl)
class(wrld_simpl)
length(row.names(wrld_simpl))
system.time(pts <- spsample(wrld_simpl, n=20000, type="random"))
class(pts)
system.time(o <- overlay(pts, wrld_simpl))
range(o)

The o vector says which Polygons object the points fall, 1 isn't included 
here as it didn't take any hits in spsample (Antigua and Barbuda). 
Generating the point samples also involves a lot of point-in-polygon too, 
so making the example takes twice as long for me (10s) than doing the 
overlay (4s).

Roger

>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From karl at huftis.org  Mon Nov  9 13:55:21 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 9 Nov 2009 13:55:21 +0100
Subject: [R-sig-Geo] Finding polygons corresponding to points
References: <MPG.2562200667fcf4a989699@news.gmane.org>
	<alpine.LRH.2.00.0911091313150.28414@reclus.nhh.no>
Message-ID: <MPG.25622fa681a8c89598969a@news.gmane.org>

On Mon, 9 Nov 2009 13:27:16 +0100 (CET) Roger Bivand 
<Roger.Bivand at nhh.no> wrote:

> > For each point, I need to find the corresponding polygon. You can think
> > of the points as positions of for example earthquakes, and the polygons
> > as state or country borders. For each earthquake, I need to calculate
> > the state/country where the earthquake occured.
>
> Try the relevant overlay() methods in sp. They ought to be fast enough:

Wonderful. Thank you so much.

-- 
Karl Ove Hufthammer


From cara.tobin at epfl.ch  Mon Nov  9 15:27:03 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Mon, 9 Nov 2009 15:27:03 +0100
Subject: [R-sig-Geo] RE :  grid error for kriging
In-Reply-To: <alpine.LRH.2.00.0911091220080.28414@reclus.nhh.no>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C1@REX2.intranet.epfl.ch>,
	<alpine.LRH.2.00.0911091220080.28414@reclus.nhh.no>
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C3@REX2.intranet.epfl.ch>

Dear Roger,

My Prec00 is a data frame as I imported it as a matrix from a text file. It has 32 rows (one for each precipitation station) and 72 columns (72 hours of data at each station). I interpolated by importing a second matrix with just the X, Y, and Z of the original data and iterated for each column. I had no problem doing this when I used a simpler grid (data_v) with more X, Y and Z values, imported as a text file(not a spatial DTM).

list_ked <- vector("list",72)
 
for(i in 1:72){
 list_ked[[i]] <- krige(Prec00[,i]~Z, locations=DataCoord, newdata=data_v, model = fitted_vario)
}

My successful KED code without iterating with the DTM 'elev' (where I used the mean of Prec00 over 72 hours) was:

elev_ked <- krige(meanPrec~Z, meanPrec, newdata=elev, fitted_vario)

The difference in the data frame for the mean is I have the X, Y, and Z associated with each meanPrec value at each station in the same matrix (32 rows by 4 cols: X, Y, Z, meanPrec).

So, when mixing a spatial data frame 'elev' with 2 matrices defining the original data, there seems to be a problem. Calling Prec00 gives me only the precipitation for a time step because its a separate matrix from the coordinates.

Any ideas?

Cheers

________________________________________
De : Roger Bivand [Roger.Bivand at nhh.no]
Date d'envoi : lundi, 9. novembre 2009 12:27
? : Tobin Cara
Cc : r-sig-geo at stat.math.ethz.ch
Objet : Re: [R-sig-Geo] grid error for kriging

On Mon, 9 Nov 2009, Tobin Cara wrote:

> Hello,
>
> Has anyone ever used a DTM as their grid for interpolation and come
> across this error. My DTM has pixels 100 m by 100 m, so I really do not
> understand this error as it is regular. Also, this only happens when I
> am doing multiple iterations in time.
>
>
>
> Code:
> list_ked[[i]] <- krige(Prec00[,i]~Zloc, locations=DataCoord, newdata=elev, model = fitted_vario)
> [using universal kriging]
>

Please do check the arguments to the formula carefully. If Prec00 is a
SpatialGridDataFrame, you are not asking for it's i'th variable here. It's
a design decision that you need Prec00[,,i] to get the variable, or get it
by name:

library(sp)
data(meuse.grid)
coordinates(meuse.grid) <- c("x", "y")
str(meuse.grid[,1])
gridded(meuse.grid) <- TRUE
str(meuse.grid[,1])
fullgrid(meuse.grid) <- TRUE
str(meuse.grid[,1])
str(meuse.grid[,,1])

Maybe helping some users to subset by row and column has removed the
otherwise prevalent semantic link to data.frame objects, and maybe this
(tricky) side of the "[" operator on SpatialGridDataFrame objects should
be reversed?

Roger

>
>
> Error:
> suggested tolerance minimum: 0.25
> Error in points2grid(points, tolerance, round, fuzz.tol) :
> dimension 1 : coordinate intervals are not constant
>
>
> I can rescale the DTM to be less refined (now it is 100 m2 for a 6,000
> km2 area) if needed.
>
> Thank you again,
>
> Cara
>
>
>
>
>
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

--
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Mon Nov  9 15:45:50 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Nov 2009 15:45:50 +0100 (CET)
Subject: [R-sig-Geo] RE :  grid error for kriging
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C3@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8C1@REX2.intranet.epfl.ch>,
	<alpine.LRH.2.00.0911091220080.28414@reclus.nhh.no>
	<EDB94195DABE64488928DD39E53B8FC68BDFD3E8C3@REX2.intranet.epfl.ch>
Message-ID: <alpine.LRH.2.00.0911091534040.29543@reclus.nhh.no>

On Mon, 9 Nov 2009, Tobin Cara wrote:

> Dear Roger,
>
> My Prec00 is a data frame as I imported it as a matrix from a text file. 
> It has 32 rows (one for each precipitation station) and 72 columns (72 
> hours of data at each station). I interpolated by importing a second 
> matrix with just the X, Y, and Z of the original data and iterated for 
> each column. I had no problem doing this when I used a simpler grid 
> (data_v) with more X, Y and Z values, imported as a text file(not a 
> spatial DTM).
>
> list_ked <- vector("list",72)
>
> for(i in 1:72){
> list_ked[[i]] <- krige(Prec00[,i]~Z, locations=DataCoord, newdata=data_v, model = fitted_vario)
> }
>
> My successful KED code without iterating with the DTM 'elev' (where I 
> used the mean of Prec00 over 72 hours) was:
>
> elev_ked <- krige(meanPrec~Z, meanPrec, newdata=elev, fitted_vario)
>
> The difference in the data frame for the mean is I have the X, Y, and Z 
> associated with each meanPrec value at each station in the same matrix 
> (32 rows by 4 cols: X, Y, Z, meanPrec).
>
> So, when mixing a spatial data frame 'elev' with 2 matrices defining the 
> original data, there seems to be a problem. Calling Prec00 gives me only 
> the precipitation for a time step because its a separate matrix from the 
> coordinates.

Did you check the class of Prec00? If it wasn't a SpatialGridDataFrame, it 
wouldn't have given you that error message. Please do use class() and 
str() to check (and double-check) the class of objects. You may believe 
that it is a data.frame, but that doesn't seem likely.

You didn't provide the output of traceback() following the original error. 
It helps a lot in disentangling the causes of an apparent 
misunderstanding. The newdata= argument could also be the source of the 
problem. You would be well advised to use gstat() and predict() instead of 
krige(), then you see which step is problematic. Setting things up with a 
single input Spatial*DataFrame as the data= argument (not locations=), and 
a single Spatial*DataFrame as the newdata= argument in predict() is also 
preferable, because then the data and their locations are kept together.

Simplify first, please. The error you reported came from wrong syntax in 
subsetting a SpatialGridDataFrame, whatever you may have intended.

Roger


>
> Any ideas?
>
> Cheers
>
> ________________________________________
> De : Roger Bivand [Roger.Bivand at nhh.no]
> Date d'envoi : lundi, 9. novembre 2009 12:27
> ? : Tobin Cara
> Cc : r-sig-geo at stat.math.ethz.ch
> Objet : Re: [R-sig-Geo] grid error for kriging
>
> On Mon, 9 Nov 2009, Tobin Cara wrote:
>
>> Hello,
>>
>> Has anyone ever used a DTM as their grid for interpolation and come
>> across this error. My DTM has pixels 100 m by 100 m, so I really do not
>> understand this error as it is regular. Also, this only happens when I
>> am doing multiple iterations in time.
>>
>>
>>
>> Code:
>> list_ked[[i]] <- krige(Prec00[,i]~Zloc, locations=DataCoord, newdata=elev, model = fitted_vario)
>> [using universal kriging]
>>
>
> Please do check the arguments to the formula carefully. If Prec00 is a
> SpatialGridDataFrame, you are not asking for it's i'th variable here. It's
> a design decision that you need Prec00[,,i] to get the variable, or get it
> by name:
>
> library(sp)
> data(meuse.grid)
> coordinates(meuse.grid) <- c("x", "y")
> str(meuse.grid[,1])
> gridded(meuse.grid) <- TRUE
> str(meuse.grid[,1])
> fullgrid(meuse.grid) <- TRUE
> str(meuse.grid[,1])
> str(meuse.grid[,,1])
>
> Maybe helping some users to subset by row and column has removed the
> otherwise prevalent semantic link to data.frame objects, and maybe this
> (tricky) side of the "[" operator on SpatialGridDataFrame objects should
> be reversed?
>
> Roger
>
>>
>>
>> Error:
>> suggested tolerance minimum: 0.25
>> Error in points2grid(points, tolerance, round, fuzz.tol) :
>> dimension 1 : coordinate intervals are not constant
>>
>>
>> I can rescale the DTM to be less refined (now it is 100 m2 for a 6,000
>> km2 area) if needed.
>>
>> Thank you again,
>>
>> Cara
>>
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From blair.christian at gmail.com  Mon Nov  9 15:53:24 2009
From: blair.christian at gmail.com (Blair Christian)
Date: Mon, 9 Nov 2009 09:53:24 -0500
Subject: [R-sig-Geo] metadata
Message-ID: <6c35a4fc0911090653o431337aat6ebea6082e904f68@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091109/1d1e0726/attachment.pl>

From Roger.Bivand at nhh.no  Mon Nov  9 16:23:36 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 9 Nov 2009 16:23:36 +0100 (CET)
Subject: [R-sig-Geo] metadata
In-Reply-To: <6c35a4fc0911090653o431337aat6ebea6082e904f68@mail.gmail.com>
References: <6c35a4fc0911090653o431337aat6ebea6082e904f68@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0911091613450.29543@reclus.nhh.no>

On Mon, 9 Nov 2009, Blair Christian wrote:

> Hi All,
>
> I have a couple of comments here.  I'm working on some S4 classes for
> spatiotemporal data, basically extending Spatial, and I would like to
> include some metadata sooner or later.  I wrote some functions to get data
> off of webpages (like spatiotemporal ozone data from the EPA's air
> explorer), and I wanted to somehow encode this origin of the data into the
> object, so I thought a metadata object would be one way to do this.
>
> My very first go was something like this:
>
> setClass("stMetadata",
>         representation(title="character",
>                        url="character",
>                        creator="character",
>                        contact="character",
>                        description="character"
>                        ))
>
>
> Other things that I think ought to be in there are units of observations (eg
> ozone in ppm), units of spatial data (eg northing/easting, lat/long,
> Dorsey?),  temporal periodicity (eg daily, weekly, hourly, etc), and perhaps
> something about data range (is this a subset of a larger set? what are the
> temporal/spatial bounds, etc).
>
> Anyhow, those are some of the thoughts I have.  Of course, it's much easier
> to do this when you are using scripts to create data sets than to try to
> convince a hurried user to fill out yet another form when all they want to
> do is "one simple thing"....
>
> Thoughts?

In fact, comment() is pretty robust, but only accepts character vectors, 
nothing else. Using write.dcf() and read.dcf, one can get from:

com0 <- list(title="mytitle", url="myurl")
com1 <- capture.output(write.dcf(com0))
comment(meuse) <- com1
com2 <- as.list(data.frame(read.dcf(textConnection(comment(meuse))),
   stringsAsFactors=FALSE))
all.equal(com0, com2)

com3 <- as.list(data.frame(read.dcf(textConnection(comment(meuse[1:5,
   1:3]))), stringsAsFactors=FALSE))
all.equal(com0, com3)

and back out again. comment and comment<- are not methods, though, so a 
wrapper setup might be needed. I don't think that S4 classes can be packed 
into the comment easily.

Roger

> Blair
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From rpruner at ufl.edu  Mon Nov  9 21:05:10 2009
From: rpruner at ufl.edu (Raya A. Pruner)
Date: Mon, 9 Nov 2009 15:05:10 -0500 (EST)
Subject: [R-sig-Geo] underlying covariate data using R package  'spatstat'
Message-ID: <1159537468.181931257797110040.JavaMail.osg@osgjas01.cns.ufl.edu>

I have another question for everyone related to the spatstat 
package and model fitting.

A brief background on my question of interest: We are interested 
in the spatial aggregation of snowy plover nests on a barrier 
island system in response to nest fates.  We hypothesize a greater 
level of aggregation in response to a positive nest fate.  Given 
this, we are also interested in underlying covariates.  So we have 
data for human activity, predator activity, and prey availability. 
 We would like to see how these covariates influence the 
aggregation of nests as well.  Currently I have been trying to 
create a list of images, but was unsuccessful.  So I used based on 
what I have been able to figure out and did each separately.  This 
was the only way I could figure out in associating a continuous 
covariate with a pixel inmage:

nests.extra <- read.csv("CIE 2009 covariates.csv", header = T)
extra.chop <- subset(nests.extra, select = c(Id, 
X,Y,Tracks,Predator_T, Invert_Tra))


covH.ppp <- ppp(extra.chop[,2], extra.chop[,3], marks 
=extra.chop[,4],window = area1)
human.act=density.ppp(covH.ppp)
human.act

covP.ppp <- ppp(extra.chop[,2], extra.chop[,3], marks 
=extra.chop[,5]_T,window = area1)
predator.act=density.ppp(covP.ppp)
predator.act

covI.ppp <- ppp(extra.chop[,2], extra.chop[,3], marks 
=extra.chop[,6],window = area1)
invert.act=density.ppp(covI.ppp)
invert.act

using this allows me to fit models such as this using multiple 
covariate:
cov2.cord.model=ppm(nestsF.ppp, ~x+y+Tracks+Pred, covariates = 
list(Tracks=human.act,Pred=predator.act ))

However, I don???t think it is working right.  I tried to plot 
human.act and it doesn???t seem to relate to the data provided in 
plotting covH.ppp.  The way that I collected the covariate data 
was systematic by counting human and predator tracks every 500m 
linearly along the beach.  So I want to be able to look at how the 
human intensity value effects nesting aggregation and not the 
density of covariate points themselves which is what I think it is 
doing currently.  I am interested in the value behind the point.  
If anyone has any insight on this, please let me know!

Cheers!!!
Raya


--
Raya A Pruner - Graduate Student
University of Florida
Department of Wildlife Ecology and Conservation
PO Box 110430
Gainesville, FL 32611-0430
352-214-3262


From shaofei.chen at utdallas.edu  Tue Nov 10 02:49:02 2009
From: shaofei.chen at utdallas.edu (Chen, Shaofei)
Date: Mon, 9 Nov 2009 19:49:02 -0600
Subject: [R-sig-Geo] How to create a SpatialPolygonsDataFrame object
Message-ID: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091109/d6e514fa/attachment.pl>

From Roger.Bivand at nhh.no  Tue Nov 10 09:20:12 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 10 Nov 2009 09:20:12 +0100 (CET)
Subject: [R-sig-Geo] How to create a SpatialPolygonsDataFrame object
In-Reply-To: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>
References: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>
Message-ID: <alpine.LRH.2.00.0911100916420.32469@reclus.nhh.no>

On Mon, 9 Nov 2009, Chen, Shaofei wrote:

> Hello everyone,
>
> I can read polygon shape files into SpatialPolygonsDataFrame objects 
> using maptools library. But how to create a SpatialPolygonsDataFrame 
> object, for example, a 400 by 400 polygon? Thank you in advance!

Something like:

library(sp)
crds <- cbind(x=c(0, 0, 400, 400, 0), y=c(0, 400, 400, 0, 0))
# str(crds)
Pl <- Polygon(crds)
# str(Pl)
ID <- "400x400"
Pls <- Polygons(list(Pl), ID=ID)
# str(Pls)
SPls <- SpatialPolygons(list(Pls))
# str(SPls)
df <- data.frame(value=1, row.names=ID)
# str(df)
SPDF <- SpatialPolygonsDataFrame(SPls, df)
# str(SPDF)

Uncomment the # str() lines to follow the development of the structure of 
the object.

Hope this helps,

Roger

>
> Best,
> Shaofei
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From marcelino.delacruz at upm.es  Tue Nov 10 11:56:08 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Tue, 10 Nov 2009 11:56:08 +0100
Subject: [R-sig-Geo] underlying covariate data using R package 'spatstat'
In-Reply-To: <1159537468.181931257797110040.JavaMail.osg@osgjas01.cns.uf l.edu>
References: <1159537468.181931257797110040.JavaMail.osg@osgjas01.cns.ufl.edu>
Message-ID: <200911101056.nAAAuGbJ005074@edison.ccupm.upm.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091110/dea16d1d/attachment.pl>

From ageel_bushara at yahoo.com  Tue Nov 10 20:14:04 2009
From: ageel_bushara at yahoo.com (ageel bushara)
Date: Tue, 10 Nov 2009 11:14:04 -0800 (PST)
Subject: [R-sig-Geo] Multiple predictors for external drift kriging
Message-ID: <609781.59617.qm@web35805.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091110/752d4704/attachment.pl>

From Roger.Bivand at nhh.no  Tue Nov 10 20:38:02 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 10 Nov 2009 20:38:02 +0100 (CET)
Subject: [R-sig-Geo] Multiple predictors for external drift kriging
In-Reply-To: <609781.59617.qm@web35805.mail.mud.yahoo.com>
References: <609781.59617.qm@web35805.mail.mud.yahoo.com>
Message-ID: <alpine.LRH.2.00.0911102032040.1229@reclus.nhh.no>

On Tue, 10 Nov 2009, ageel bushara wrote:

> Dear list members,
>
> I'm doing spatial interpolation of soil moisture using kriging with external drift following the example given by Tom Hengl (http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide). When I used one predictor (in my case gradient or cos_aspect, see below) it works fine for me, but when I used multiple predictors (gradient +cos_aspect), still I'm able to have the the experimental variogram as well as the fitted theoretical variogram, however, I'm not able to have the kriged soil moisture. here is the code
>
> # import and define the input variables
>
> library(sp)
> library(lattice)
> trellis.par.set(sp.theme()) # plots the final predictions using blue-pink-yellow legend
>
> water <- read.csv("water_content.txt") # table with x,y coordinates,and z is? soil moisture
> str(water)
> coordinates(water)=~x+y?? # this makes depth a SpatialPointsDataFrame
> str(water)
>
> cos_aspect = read.asciigrid("cos_aspect.asc")? # reads ArcInfo Ascii raster map
> str(cos_aspect)
> spplot(cos_aspect, scales=list(draw=T), sp.layout=list("sp.points", water, pch="+"))
> gradient= read.asciigrid("gradient.asc")
> str(gradient)
> spplot(gradient, scales=list(draw=T), sp.layout=list("sp.points", water, pch="+"))
>
> #Plot the xy graph target versus predictor:
>
> cos_aspect.ov = overlay(cos_aspect, water)? # create grid-points overlay
> str(cos_aspect.ov at data)
> water$cos_aspect.asc = cos_aspect.ov$cos_aspect.asc?
>
> gradient.ov = overlay(gradient, water)
> water$gradient.asc= gradient.ov$gradient.asc
>
> lm.depth <- lm(z~ gradient.asc+cos_aspect.asc, as.data.frame(water))
>
> summary(lm.depth)
>
> plot(z~ gradient.asc+cos_aspect.asc, as.data.frame(water))
> abline(lm(z~ gradient.asc, as.data.frame(water)))
> abline(lm(z~ cos_aspect.asc, as.data.frame(water)))
>
> #Fit the variogram model of the residuals:
>
> library(gstat)
> null.vgm <- vgm(var(water$z), "Sph", sqrt(areaSpatialGrid(cos_aspect))/4, nugget=0) #initial parameters
> vgm_depth_r <- fit.variogram(variogram(z~ cos_aspect.asc+ gradient.asc, water), model=null.vgm)
> plot(variogram(z~ gradient.asc+cos_aspect.asc,water), vgm_depth_r, main="fitted by gstat")
> # It works fine till here
> # Run uk in gstat:
>
> depth_uk <- krige(z~ cos_aspect.asc+gradient.asc, locations=water, newdata=cos_aspect, model=vgm_depth_r)
>
>
>
> the problem it seems mainly in newdata, here is the error given by R:
> Error in eval(expr, envir, enclos) : object 'gradient.asc' not found. if i assigned the? newdata= gradient then the R error message is :
> Error in eval(expr, envir, enclos) : object 'cos_aspect.asc' not found

You probably need to think through what you are doing. You should use a 
Spatial*DataFrame for newdata that includes "cos_aspect.asc" and 
"gradient.asc" among the values returned by the names() method. Since each 
of your two SpatialGridDataFrame objects have single variables, you should 
review what a SpatialGridDataFrame is - a data.frame with a description of 
the GridTopology. Assuming that your two objects share their GridTopology 
values, maybe cbind() them? Then check that the names() output includes 
the names of variables on the RHS in the formula. Don't think of objects 
as grids, think of them as data.frames, then you see what is going on.

Try with lm() and predict() first, then with gstat() and predict() - the 
newdata= argument works in exactly the same way.

Hope this helps,

Roger

>
> as I understand that newdata is the grid where it does the interpolations
> How can I obtained the kriged soil moisture?, what is wrong here?,
> Thanks,
> Ageel
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From hengl at spatial-analyst.net  Tue Nov 10 21:07:20 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 10 Nov 2009 21:07:20 +0100
Subject: [R-sig-Geo] Multiple predictors for external drift kriging
In-Reply-To: <alpine.LRH.2.00.0911102032040.1229@reclus.nhh.no>
References: <609781.59617.qm@web35805.mail.mud.yahoo.com>
	<alpine.LRH.2.00.0911102032040.1229@reclus.nhh.no>
Message-ID: <4AF9C7F8.40401@spatial-analyst.net>

Roger Bivand wrote:
> On Tue, 10 Nov 2009, ageel bushara wrote:
> 
>> Dear list members,
>>
>> I'm doing spatial interpolation of soil moisture using kriging with 
>> external drift following the example given by Tom Hengl 
>> (http://spatial-analyst.net/wiki/index.php?title=Regression-kriging_guide). 
>> When I used one predictor (in my case gradient or cos_aspect, see 
>> below) it works fine for me, but when I used multiple predictors 
>> (gradient +cos_aspect), still I'm able to have the the experimental 
>> variogram as well as the fitted theoretical variogram, however, I'm 
>> not able to have the kriged soil moisture. here is the code
>>
>> # import and define the input variables
>>
>> library(sp)
>> library(lattice)
>> trellis.par.set(sp.theme()) # plots the final predictions using 
>> blue-pink-yellow legend
>>
>> water <- read.csv("water_content.txt") # table with x,y 
>> coordinates,and z is? soil moisture
>> str(water)
>> coordinates(water)=~x+y?? # this makes depth a SpatialPointsDataFrame
>> str(water)
>>
>> cos_aspect = read.asciigrid("cos_aspect.asc")? # reads ArcInfo Ascii 
>> raster map
>> str(cos_aspect)
>> spplot(cos_aspect, scales=list(draw=T), sp.layout=list("sp.points", 
>> water, pch="+"))
>> gradient= read.asciigrid("gradient.asc")
>> str(gradient)
>> spplot(gradient, scales=list(draw=T), sp.layout=list("sp.points", 
>> water, pch="+"))
>>
>> #Plot the xy graph target versus predictor:
>>
>> cos_aspect.ov = overlay(cos_aspect, water)? # create grid-points overlay
>> str(cos_aspect.ov at data)
>> water$cos_aspect.asc = cos_aspect.ov$cos_aspect.asc?
>>
>> gradient.ov = overlay(gradient, water)
>> water$gradient.asc= gradient.ov$gradient.asc
>>
>> lm.depth <- lm(z~ gradient.asc+cos_aspect.asc, as.data.frame(water))
>>
>> summary(lm.depth)
>>
>> plot(z~ gradient.asc+cos_aspect.asc, as.data.frame(water))
>> abline(lm(z~ gradient.asc, as.data.frame(water)))
>> abline(lm(z~ cos_aspect.asc, as.data.frame(water)))
>>
>> #Fit the variogram model of the residuals:
>>
>> library(gstat)
>> null.vgm <- vgm(var(water$z), "Sph", 
>> sqrt(areaSpatialGrid(cos_aspect))/4, nugget=0) #initial parameters
>> vgm_depth_r <- fit.variogram(variogram(z~ cos_aspect.asc+ 
>> gradient.asc, water), model=null.vgm)
>> plot(variogram(z~ gradient.asc+cos_aspect.asc,water), vgm_depth_r, 
>> main="fitted by gstat")
>> # It works fine till here
>> # Run uk in gstat:
>>
>> depth_uk <- krige(z~ cos_aspect.asc+gradient.asc, locations=water, 
>> newdata=cos_aspect, model=vgm_depth_r)
>>
>>
>>
>> the problem it seems mainly in newdata, here is the error given by R:
>> Error in eval(expr, envir, enclos) : object 'gradient.asc' not found. 
>> if i assigned the? newdata= gradient then the R error message is :
>> Error in eval(expr, envir, enclos) : object 'cos_aspect.asc' not found
> 
> You probably need to think through what you are doing. You should use a 
> Spatial*DataFrame for newdata that includes "cos_aspect.asc" and 
> "gradient.asc" among the values returned by the names() method. Since 
> each of your two SpatialGridDataFrame objects have single variables, you 
> should review what a SpatialGridDataFrame is - a data.frame with a 
> description of the GridTopology. Assuming that your two objects share 
> their GridTopology values, maybe cbind() them? Then check that the 
> names() output includes the names of variables on the RHS in the 
> formula. Don't think of objects as grids, think of them as data.frames, 
> then you see what is going on.
> 
> Try with lm() and predict() first, then with gstat() and predict() - the 
> newdata= argument works in exactly the same way.
> 
> Hope this helps,
> 
> Roger

Hi Ageel,

Roger is right. You should read all rasters to a single (multilayer) 
grid e.g.:

 > grids <- readGDAL("cos_aspect.asc")
 > names(grids) <- "cos_aspect.asc"
 > grids$gradient.asc <- readGDAL("gradient.asc")$band1
...

Then overlay, filter the NA's, and then you can fit a variogram and run 
predictions e.g.:

depth_uk <- krige(z~ cos_aspect.asc+gradient.asc, locations=water, 
newdata=grids, model=vgm_depth_r)
...


Here are some more examples:

http://geomorphometry.org/content/some-examples-rsaga
http://spatial-analyst.net/scripts/meuse.R


all the best,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/

> 
>>
>> as I understand that newdata is the grid where it does the interpolations
>> How can I obtained the kriged soil moisture?, what is wrong here?,
>> Thanks,
>> Ageel
>>
>>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>>
>


From edzer.pebesma at uni-muenster.de  Wed Nov 11 09:16:37 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 11 Nov 2009 09:16:37 +0100
Subject: [R-sig-Geo] Multiple predictors for external drift kriging
In-Reply-To: <4AF9C7F8.40401@spatial-analyst.net>
References: <609781.59617.qm@web35805.mail.mud.yahoo.com>	<alpine.LRH.2.00.0911102032040.1229@reclus.nhh.no>
	<4AF9C7F8.40401@spatial-analyst.net>
Message-ID: <4AFA72E5.8020806@uni-muenster.de>

Tomislav Hengl wrote:
>
> depth_uk <- krige(z~ cos_aspect.asc+gradient.asc, locations=water,
> newdata=grids, model=vgm_depth_r)
although this of course works, I always endorse to use e.g.

depth_uk <- krige(z~ cos_aspect.asc+gradient.asc, water, grids,
vgm_depth_r)

i.e., without named arguments; the "locations" remains from an attempt
to be pre-sp compatibel while using generic methods at the same time; it
should have been named "data". Changing this now would, I'm afraid,
break too much what's already out there.

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From clement.tisseuil at gmail.com  Wed Nov 11 17:34:43 2009
From: clement.tisseuil at gmail.com (=?UTF-8?Q?Cl=C3=A9ment_Tisseuil?=)
Date: Wed, 11 Nov 2009 17:34:43 +0100
Subject: [R-sig-Geo]  Hydrological distance between sites
In-Reply-To: <8f656ccd0911110832p1bc05b90j4c847355c0458bf3@mail.gmail.com>
References: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com> 
	<4AFAE29C.9020207@alumni.uv.es>
	<8f656ccd0911110832p1bc05b90j4c847355c0458bf3@mail.gmail.com>
Message-ID: <8f656ccd0911110834r1013adf9w618ac03454d2130d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091111/340cc1ef/attachment.pl>

From famuvie at alumni.uv.es  Wed Nov 11 18:15:10 2009
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Wed, 11 Nov 2009 18:15:10 +0100
Subject: [R-sig-Geo] Hydrological distance between sites
In-Reply-To: <8f656ccd0911110834r1013adf9w618ac03454d2130d@mail.gmail.com>
References: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com>
	<4AFAE29C.9020207@alumni.uv.es>	<8f656ccd0911110832p1bc05b90j4c847355c0458bf3@mail.gmail.com>
	<8f656ccd0911110834r1013adf9w618ac03454d2130d@mail.gmail.com>
Message-ID: <4AFAF11E.9010908@alumni.uv.es>

Sorry Cl?ment, please use the attached fixed version instead.
I thaught I had the latest version on the web.

Bests,
   facu.-


Cl?ment Tisseuil escribi?:
> Thank you very much Facu,
>
> It is exactly what I was looking for!
>
>
> Le 11 novembre 2009 17:13, Facundo Mu??oz <famuvie at alumni.uv.es> a ??crit :
>
> That is more like a geographical operation.
>   
>> I wrote a little GRASS script suited to do this.
>> http://www.geeitema.org/doc/guenmap//docs/v.costdist.mat.zip
>>
>> You have to provide a "cost" surface with zeroes over land regions, and
>> with a constant value over water equal to the raster resolution you are
>> working with.
>> You then can provide a vector map of "source" sites and one or more maps
>> with "end" sites, and the script computes all hydrological distances from
>> all the source sites to all the end sites and store the values in the data
>> tables.
>> Of course you can use the same map for 'source' and 'end'. In this case you
>> get all the distances between the sites.
>>
>> Hope it helps.
>> ?'acu.-
>>
>> Cl??ment Tisseuil escribi??:
>>
>>     
>>> Dear r-sig-geo list members,
>>>
>>> Does anyone know if some R functions exist to calculate some hydrological
>>> distances between sites? By hydrological distances, I mean for example the
>>> 'real' distance that separates two sites throughout the river network
>>> connexions.
>>>
>>> Thanks in advance
>>>
>>> Clem
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>>       
>
> 	[[alternative HTML version deleted]]
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091111/794cb369/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: v.costdist.mat.zip
Type: application/zip
Size: 3800 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091111/794cb369/attachment.zip>

From famuvie at alumni.uv.es  Wed Nov 11 18:51:11 2009
From: famuvie at alumni.uv.es (=?ISO-8859-1?Q?Facundo_Mu=F1oz?=)
Date: Wed, 11 Nov 2009 18:51:11 +0100
Subject: [R-sig-Geo] Hydrological distance between sites
In-Reply-To: <4AFAF11E.9010908@alumni.uv.es>
References: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com>	<4AFAE29C.9020207@alumni.uv.es>	<8f656ccd0911110832p1bc05b90j4c847355c0458bf3@mail.gmail.com>	<8f656ccd0911110834r1013adf9w618ac03454d2130d@mail.gmail.com>
	<4AFAF11E.9010908@alumni.uv.es>
Message-ID: <4AFAF98F.1010108@alumni.uv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091111/3fcf4f96/attachment.pl>

From clement.tisseuil at gmail.com  Wed Nov 11 19:17:51 2009
From: clement.tisseuil at gmail.com (=?UTF-8?Q?Cl=C3=A9ment_Tisseuil?=)
Date: Wed, 11 Nov 2009 19:17:51 +0100
Subject: [R-sig-Geo] Hydrological distance between sites
In-Reply-To: <4AFAF98F.1010108@alumni.uv.es>
References: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com> 
	<4AFAE29C.9020207@alumni.uv.es>
	<8f656ccd0911110832p1bc05b90j4c847355c0458bf3@mail.gmail.com> 
	<8f656ccd0911110834r1013adf9w618ac03454d2130d@mail.gmail.com> 
	<4AFAF11E.9010908@alumni.uv.es> <4AFAF98F.1010108@alumni.uv.es>
Message-ID: <8f656ccd0911111017t22ae6456t85ec9dd8c2999f96@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091111/93405cf7/attachment.pl>

From jgarcia at ija.csic.es  Wed Nov 11 20:06:24 2009
From: jgarcia at ija.csic.es (jgarcia at ija.csic.es)
Date: Wed, 11 Nov 2009 20:06:24 +0100 (CET)
Subject: [R-sig-Geo] rectangular subsetting/clipping of sp objects (grids)
Message-ID: <54401.86.0.54.218.1257966384.squirrel@paleo.ija.csic.es>

Hello, I am interested in subsetting/clipping rectangular areas of
imported spatial datasets (mostly raster) of sp classes.
While this is extremely easy to do with normal matrixes, I'm wondering if
there is a straigth way to do this for spatial objects (mostly
SpatialGridDataFrame objects).

In the list I've found a thread about clipping, but I just need simple
rectangular clipping from a specified bounding boxes I may require. The
point is to remove big imported objects from the workspace to save memory
and just work with the clipped areas.

Perhaps there is a simple way to do it? I mean something like:

n <- 4189000
s <- 4185000
w <- 655000
e <- 650000
mybbox <- matrix(c(e,s,w,n),ncol=2,dimnames=list(c("x","y"),c("min","max")))
x       <- readGDAL(myasciigrd)
bbox(x) <- mybbox

and obtain the clipping? Thanks you for your help.

Best regards,
Javier
---


From shaofei.chen at utdallas.edu  Thu Nov 12 04:20:59 2009
From: shaofei.chen at utdallas.edu (Chen, Shaofei)
Date: Wed, 11 Nov 2009 21:20:59 -0600
Subject: [R-sig-Geo] sample.Spatial question
References: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>
	<alpine.LRH.2.00.0911100916420.32469@reclus.nhh.no>
Message-ID: <71F98E52CFA34E62BA36A71D2582B6EC@shaofei>

Dear list members,

Thanks to Dr. Bivand's quick reply on my last question about creating a 
specific polygon. My next question follows that one.
After creating a polygon, I want to sample inside the polygon, I used 
sample.Spatial in sp library. I want to sample 23 points in a hexagonal 
structure.

library(sp)
crds <- cbind(x=c(0, 0, 400, 400, 0), y=c(0, 400, 400, 0, 0))
Pl <- Polygon(crds)
ID <- "400x400"
Pls <- Polygons(list(Pl), ID=ID)
SPls <- SpatialPolygons(list(Pls))
df <- data.frame(value=1, row.names=ID)
SPDF <- SpatialPolygonsDataFrame(SPls, df)
plot(SPDF)
rand.points <- sample.Spatial(SPDF,n=23,type="hexagonal")
plot(rand.points, add=T)


According to my imagination, the point pattern should look like this:

+   +  +  +  +
   +  +  +  +
+   +  +  +  +
   +  +  +  +
+   +  +  +  +

However, everytime, the results are not 23 points, they usually come up with 
16 points.
I changed to regular sampling structure with a specified offset c(0.5,0.5). 
It can give consistent results for 4x4=16 or 5x5=25... points. But for other 
number of points, for example, 20 points, it cannot give a 4x5 point 
pattern. Also offset option is not for other sampling type.

I just wonder why this happens. I look at the source code,  I think it may 
because that the it defines the first point randomly (of course, it uses 
"area = prod(apply(bb, 1, diff))/n" to define the stratum), and then 
construct the following samples.  In this way, some points may be out of the 
boundary.

Is it possible that I can get exactly number of points that I want for 
sampling?  And also I want the offset for hexagon is available, so that I 
can make sure that the sampling points locating in the centroid of the 
hexagon. I checked the archives of the list, Dr. Bivand has provided codes 
that not utilize sample.Spatial  for creating hexagons and centroids (I have 
done it with 23 points in 400 by 400 polygon), but it may not be easy in 
unregular polygon with defined number of points.

Thank you in advance!

Best,
Shaofei


From edzer.pebesma at uni-muenster.de  Thu Nov 12 10:48:53 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Nov 2009 10:48:53 +0100
Subject: [R-sig-Geo] sample.Spatial question
In-Reply-To: <71F98E52CFA34E62BA36A71D2582B6EC@shaofei>
References: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>	<alpine.LRH.2.00.0911100916420.32469@reclus.nhh.no>
	<71F98E52CFA34E62BA36A71D2582B6EC@shaofei>
Message-ID: <4AFBDA05.1020307@uni-muenster.de>

This is not a full answer. To start of with, I'd suggest to use spsample
rather than sample.Spatial (maybe we should not make the latter
available to usage).

rand.points <- spsample(SPDF,n=23,type="hexagonal")
plot(rand.points, add=T,col='red')

The pattern you sketch below (nice ascii art!) might not fit in a square
area.

I'm afraid we overlooked this, and need to modify the documentation to
state that only for a limited number of sampling methods for square
regions the sample size is guaranteed the requested number. And exclude
the hexagonal...
--
Edzer


Chen, Shaofei wrote:
> Dear list members,
>
> Thanks to Dr. Bivand's quick reply on my last question about creating
> a specific polygon. My next question follows that one.
> After creating a polygon, I want to sample inside the polygon, I used
> sample.Spatial in sp library. I want to sample 23 points in a
> hexagonal structure.
>
> library(sp)
> crds <- cbind(x=c(0, 0, 400, 400, 0), y=c(0, 400, 400, 0, 0))
> Pl <- Polygon(crds)
> ID <- "400x400"
> Pls <- Polygons(list(Pl), ID=ID)
> SPls <- SpatialPolygons(list(Pls))
> df <- data.frame(value=1, row.names=ID)
> SPDF <- SpatialPolygonsDataFrame(SPls, df)
> plot(SPDF)
> rand.points <- sample.Spatial(SPDF,n=23,type="hexagonal")
> plot(rand.points, add=T)
>
>
> According to my imagination, the point pattern should look like this:
>
> +   +  +  +  +
>   +  +  +  +
> +   +  +  +  +
>   +  +  +  +
> +   +  +  +  +
>
> However, everytime, the results are not 23 points, they usually come
> up with 16 points.
> I changed to regular sampling structure with a specified offset
> c(0.5,0.5). It can give consistent results for 4x4=16 or 5x5=25...
> points. But for other number of points, for example, 20 points, it
> cannot give a 4x5 point pattern. Also offset option is not for other
> sampling type.
>
> I just wonder why this happens. I look at the source code,  I think it
> may because that the it defines the first point randomly (of course,
> it uses "area = prod(apply(bb, 1, diff))/n" to define the stratum),
> and then construct the following samples.  In this way, some points
> may be out of the boundary.
>
> Is it possible that I can get exactly number of points that I want for
> sampling?  And also I want the offset for hexagon is available, so
> that I can make sure that the sampling points locating in the centroid
> of the hexagon. I checked the archives of the list, Dr. Bivand has
> provided codes that not utilize sample.Spatial  for creating hexagons
> and centroids (I have done it with 23 points in 400 by 400 polygon),
> but it may not be easy in unregular polygon with defined number of
> points.
>
> Thank you in advance!
>
> Best,
> Shaofei
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From Roger.Bivand at nhh.no  Thu Nov 12 11:08:22 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 12 Nov 2009 11:08:22 +0100 (CET)
Subject: [R-sig-Geo] sample.Spatial question
In-Reply-To: <4AFBDA05.1020307@uni-muenster.de>
References: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>
	<alpine.LRH.2.00.0911100916420.32469@reclus.nhh.no>
	<71F98E52CFA34E62BA36A71D2582B6EC@shaofei>
	<4AFBDA05.1020307@uni-muenster.de>
Message-ID: <alpine.LRH.2.00.0911121058350.20374@reclus.nhh.no>

On Thu, 12 Nov 2009, Edzer Pebesma wrote:

> This is not a full answer. To start of with, I'd suggest to use spsample
> rather than sample.Spatial (maybe we should not make the latter
> available to usage).
>
> rand.points <- spsample(SPDF,n=23,type="hexagonal")
> plot(rand.points, add=T,col='red')
>
> The pattern you sketch below (nice ascii art!) might not fit in a square
> area.
>
> I'm afraid we overlooked this, and need to modify the documentation to
> state that only for a limited number of sampling methods for square
> regions the sample size is guaranteed the requested number. And exclude
> the hexagonal...

Yes, the outcome reported is based on the cellsize= argument not being 
given, so it defaults to:

area = prod(apply(bb, 1, diff))/n
dx = sqrt(area)/(sqrt(3)/2)

If you use:

rand.points <- spsample(SPDF, cellsize=80, offset=c(0.3, 0.6),
   type="hexagonal")

then

dim(coordinates(rand.points))

is

[1] 23  2

but it needs some playing around with both cellsize= and offset=. Using 
cellsize= rather than n= may be sensible. For sample.Polygon which is the 
method being used here, offset= defaults to runif(2), so should be set to 
a known value to anchor the grid.

Roger

> --
> Edzer
>
>
> Chen, Shaofei wrote:
>> Dear list members,
>>
>> Thanks to Dr. Bivand's quick reply on my last question about creating
>> a specific polygon. My next question follows that one.
>> After creating a polygon, I want to sample inside the polygon, I used
>> sample.Spatial in sp library. I want to sample 23 points in a
>> hexagonal structure.
>>
>> library(sp)
>> crds <- cbind(x=c(0, 0, 400, 400, 0), y=c(0, 400, 400, 0, 0))
>> Pl <- Polygon(crds)
>> ID <- "400x400"
>> Pls <- Polygons(list(Pl), ID=ID)
>> SPls <- SpatialPolygons(list(Pls))
>> df <- data.frame(value=1, row.names=ID)
>> SPDF <- SpatialPolygonsDataFrame(SPls, df)
>> plot(SPDF)
>> rand.points <- sample.Spatial(SPDF,n=23,type="hexagonal")
>> plot(rand.points, add=T)
>>
>>
>> According to my imagination, the point pattern should look like this:
>>
>> +   +  +  +  +
>>   +  +  +  +
>> +   +  +  +  +
>>   +  +  +  +
>> +   +  +  +  +
>>
>> However, everytime, the results are not 23 points, they usually come
>> up with 16 points.
>> I changed to regular sampling structure with a specified offset
>> c(0.5,0.5). It can give consistent results for 4x4=16 or 5x5=25...
>> points. But for other number of points, for example, 20 points, it
>> cannot give a 4x5 point pattern. Also offset option is not for other
>> sampling type.
>>
>> I just wonder why this happens. I look at the source code,  I think it
>> may because that the it defines the first point randomly (of course,
>> it uses "area = prod(apply(bb, 1, diff))/n" to define the stratum),
>> and then construct the following samples.  In this way, some points
>> may be out of the boundary.
>>
>> Is it possible that I can get exactly number of points that I want for
>> sampling?  And also I want the offset for hexagon is available, so
>> that I can make sure that the sampling points locating in the centroid
>> of the hexagon. I checked the archives of the list, Dr. Bivand has
>> provided codes that not utilize sample.Spatial  for creating hexagons
>> and centroids (I have done it with 23 points in 400 by 400 polygon),
>> but it may not be easy in unregular polygon with defined number of
>> points.
>>
>> Thank you in advance!
>>
>> Best,
>> Shaofei
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From cara.tobin at epfl.ch  Thu Nov 12 12:33:10 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Thu, 12 Nov 2009 12:33:10 +0100
Subject: [R-sig-Geo] Variance unchanging with krige in gstat with iterations
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CA@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091112/1423f70c/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Nov 12 12:40:24 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 12 Nov 2009 12:40:24 +0100
Subject: [R-sig-Geo] Variance unchanging with krige in gstat with
	iterations
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CA@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CA@REX2.intranet.epfl.ch>
Message-ID: <4AFBF428.30502@uni-muenster.de>

This is a property of (linear) kriging -- if the observation locations
and variogram model do not change, kriging variances will not change
either. They're independent of observed values. To understand why, try
to understand the equations used to compute them.
--
Edzer

Tobin Cara wrote:
> Hello,
>
> I am performing kriging with an external drift and ordinary kriging in a loop to have predicted values at each time step.
>
> The predicted values are changing reasonably, however, the variance is not changing after the first time step.
>
> Here is my simple for loop:
>
> # KED
> list_ked <- vector("list",72)
>
> for(i in 1:72){
>  list_ked[[i]] <- krige(Prec00[,i]~Z, locations=DataCoord, newdata=elev, model = fitted_vario)
> }
>
> # OK
> list_ok <- vector("list",72)
>
> for(i in 1:72){
>      list_ok[[i]] <- krige(Prec00[,i]~1, DataCoord, newdata=coord_points, model = fitted_vario)
> }
>
> Would anyone know the solution?
>
> Thank you very much,
>
> Cara
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From p.hiemstra at geo.uu.nl  Thu Nov 12 12:45:56 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 12 Nov 2009 12:45:56 +0100
Subject: [R-sig-Geo] Variance unchanging with krige in gstat with
	iterations
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CA@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CA@REX2.intranet.epfl.ch>
Message-ID: <4AFBF574.6080802@geo.uu.nl>

Hi Tobin,

This is to be expected. the kriging variance only depends on the 
variogram and the distribution of the observations. If these don't 
change, that the kriging variance remains constant. You can have a look 
at the kriging variance equations in any textbook [1] or alternatively 
in one of my papers [2]. An interesting discussion on this can be found 
on the AI-Geostats mailing list [3].

cheers,
Paul

[1] e.g. @BOOK{Christensen1996,
  title = {Plane Answers to Complex Questions: The Theory of Linear Models},
  publisher = {Springer, New York},
  year = {1996},
  author = {Ronald Christensen},
  edition = {Second},
  note = {496p},
  owner = {hiemstra},
  timestamp = {2007.10.19}
}
[2] http://intamap.geo.uu.nl/~paul/files/PHiemstra_CandG_paper.pdf, eq (4)
[3] http://www.mail-archive.com/ai-geostats at jrc.it/msg02890.html

Tobin Cara wrote:
> Hello,
>
> I am performing kriging with an external drift and ordinary kriging in a loop to have predicted values at each time step.
>
> The predicted values are changing reasonably, however, the variance is not changing after the first time step.
>
> Here is my simple for loop:
>
> # KED
> list_ked <- vector("list",72)
>
> for(i in 1:72){
>  list_ked[[i]] <- krige(Prec00[,i]~Z, locations=DataCoord, newdata=elev, model = fitted_vario)
> }
>
> # OK
> list_ok <- vector("list",72)
>
> for(i in 1:72){
>      list_ok[[i]] <- krige(Prec00[,i]~1, DataCoord, newdata=coord_points, model = fitted_vario)
> }
>
> Would anyone know the solution?
>
> Thank you very much,
>
> Cara
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From Bjarke.Christensen at sydbank.dk  Thu Nov 12 13:58:54 2009
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Thu, 12 Nov 2009 13:58:54 +0100
Subject: [R-sig-Geo] spatstat::dirichlet - distinct points get merged
Message-ID: <OFC11185E2.F8C415E4-ONC125766B.0036DBCC-C125766C.00474F91@bdpnet.dk>


Hi,

I am using spatstat to make a dirichlet tesselation of a set pf point
patterns. From my understanding, the number of tiles should equal the
number of points - but this is not my result.

I find that a small share of my points, often two or three pr. thousand
points, seem to get merged or removed from the dataset when running
dirichlet (from the spatstat package). For example: I run dirichlet on a
point pattern with 1992 points, but the dirichlet tesselation only contains
1987 tiles. When I convert the tesselation to a SpatialPolygons and do
point overlay, some of the tiles - not necessarily at the edges or anything
like that - contain two points.

My data are in UTM and units are in meters, so the window is a few hundred
thousand meters on each axis, but the closest points are only a few meters
apart. (I removed duplicate points using unique.data.frame on the
coordinates before constructing the ppp object.). The polygons containing
two points tend to have the points relatively close together, so I was
wondering if dirichlet() perhaps did any sort of rounding of the
coordinates? However, the issue is not unique to my data as the following
sample code shows.

Here is some sample code - I can also post sample data if necessary.
> set.seed(10)
> pkt <- runifpoint(10000)
> dcl <- dirichlet(pkt)
> dcl$n
[1] 9998

Thanks in advance for any comments!
Bjarke Christensen


From cara.tobin at epfl.ch  Thu Nov 12 14:37:39 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Thu, 12 Nov 2009 14:37:39 +0100
Subject: [R-sig-Geo] RE : Variance unchanging with krige in gstat with
 iterations
In-Reply-To: <4AFBF574.6080802@geo.uu.nl>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CA@REX2.intranet.epfl.ch>,
	<4AFBF574.6080802@geo.uu.nl>
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8CB@REX2.intranet.epfl.ch>

Ah yes, thank you. Sorry for being new to this field. I appreciate your help.

________________________________________
De : Paul Hiemstra [p.hiemstra at geo.uu.nl]
Date d'envoi : jeudi, 12. novembre 2009 12:45
? : Tobin Cara
Cc : r-sig-geo at stat.math.ethz.ch
Objet : Re: [R-sig-Geo] Variance unchanging with krige in gstat with iterations

Hi Tobin,

This is to be expected. the kriging variance only depends on the
variogram and the distribution of the observations. If these don't
change, that the kriging variance remains constant. You can have a look
at the kriging variance equations in any textbook [1] or alternatively
in one of my papers [2]. An interesting discussion on this can be found
on the AI-Geostats mailing list [3].

cheers,
Paul

[1] e.g. @BOOK{Christensen1996,
  title = {Plane Answers to Complex Questions: The Theory of Linear Models},
  publisher = {Springer, New York},
  year = {1996},
  author = {Ronald Christensen},
  edition = {Second},
  note = {496p},
  owner = {hiemstra},
  timestamp = {2007.10.19}
}
[2] http://intamap.geo.uu.nl/~paul/files/PHiemstra_CandG_paper.pdf, eq (4)
[3] http://www.mail-archive.com/ai-geostats at jrc.it/msg02890.html

Tobin Cara wrote:
> Hello,
>
> I am performing kriging with an external drift and ordinary kriging in a loop to have predicted values at each time step.
>
> The predicted values are changing reasonably, however, the variance is not changing after the first time step.
>
> Here is my simple for loop:
>
> # KED
> list_ked <- vector("list",72)
>
> for(i in 1:72){
>  list_ked[[i]] <- krige(Prec00[,i]~Z, locations=DataCoord, newdata=elev, model = fitted_vario)
> }
>
> # OK
> list_ok <- vector("list",72)
>
> for(i in 1:72){
>      list_ok[[i]] <- krige(Prec00[,i]~1, DataCoord, newdata=coord_points, model = fitted_vario)
> }
>
> Would anyone know the solution?
>
> Thank you very much,
>
> Cara
>
>       [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


--
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul

From alobolistas at gmail.com  Thu Nov 12 15:51:24 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 12 Nov 2009 15:51:24 +0100
Subject: [R-sig-Geo] subseting an spatial polygons data frame
Message-ID: <4AFC20EC.3060706@gmail.com>

I want to discard few polygons from an
sp. poly. DF. I'm trying things such as:
 > str(x,max.level=2)
Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
   ..@ data       :'data.frame':	42 obs. of  9 variables:
   ..@ polygons   :List of 42
   ..@ plotOrder  : int [1:42] 32 35 38 1 8 29 33 26 27 31 ...
   ..@ bbox       : num [1:2, 1:2] 437951 4605986 459732 4633538
   .. ..- attr(*, "dimnames")=List of 2
   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
 >
 > x <- subset(x,row.names(x)!="1")
Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) :
   undefined columns selected

but the output of row.names(x)!="1"
is correct, what am I doing wrong?  Is subset() (from maptools) not 
appropriate for objects of type  SPDF ?

Thanks

Agus


From alobolistas at gmail.com  Thu Nov 12 18:19:28 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 12 Nov 2009 18:19:28 +0100
Subject: [R-sig-Geo] subseting an spatial polygons data frame
In-Reply-To: <4AFC20EC.3060706@gmail.com>
References: <4AFC20EC.3060706@gmail.com>
Message-ID: <4AFC43A0.2080202@gmail.com>

Answering to myself:

This works fine:

plot(x[x at data$CODI_EQP!=413,])
plot(x[row.names(x)==20,])

Agus

Agustin Lobo wrote:
> I want to discard few polygons from an
> sp. poly. DF. I'm trying things such as:
>  > str(x,max.level=2)
> Formal class 'SpatialPolygonsDataFrame' [package "sp"] with 5 slots
>   ..@ data       :'data.frame':    42 obs. of  9 variables:
>   ..@ polygons   :List of 42
>   ..@ plotOrder  : int [1:42] 32 35 38 1 8 29 33 26 27 31 ...
>   ..@ bbox       : num [1:2, 1:2] 437951 4605986 459732 4633538
>   .. ..- attr(*, "dimnames")=List of 2
>   ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
>  >
>  > x <- subset(x,row.names(x)!="1")
> Error in `[.data.frame`(x at data, i, j, ..., drop = FALSE) :
>   undefined columns selected
> 
> but the output of row.names(x)!="1"
> is correct, what am I doing wrong?  Is subset() (from maptools) not 
> appropriate for objects of type  SPDF ?
> 
> Thanks
> 
> Agus
>


From Rosi.Siber at eawag.ch  Fri Nov 13 10:39:43 2009
From: Rosi.Siber at eawag.ch (Siber Rosi)
Date: Fri, 13 Nov 2009 10:39:43 +0100
Subject: [R-sig-Geo] 3d-Shapefile in R
Message-ID: <B422D84F52D1C049B0D1B522E618C17701A18875DDB5@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091113/8355212f/attachment.pl>

From Roger.Bivand at nhh.no  Fri Nov 13 11:06:40 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 13 Nov 2009 11:06:40 +0100 (CET)
Subject: [R-sig-Geo] 3d-Shapefile in R
In-Reply-To: <B422D84F52D1C049B0D1B522E618C17701A18875DDB5@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>
References: <B422D84F52D1C049B0D1B522E618C17701A18875DDB5@EAW-EXC-MAIL.eawag.wroot.emp-eaw.ch>
Message-ID: <alpine.LRH.2.00.0911131056220.24433@reclus.nhh.no>

On Fri, 13 Nov 2009, Siber Rosi wrote:

> Dear list,
>
> I would like to have the z-values of a river shapefile in R (sp). So 
> that I have at the end a list of x,y and z-coordinates, for which I do 
> further analysis.

> Is there a way of importing a 3d-shapefile direct in R?

Yes, but only for points. The objects used to represent lines and polygons 
are 2D. To move forward, a Line3D representation with downstream Lines3D 
and SpatialLines3D classes would be needed. However, analysis on 3D lines 
may be hard to do - so something more like GPX track_points might be more 
useful, or the representation of sequences of points from the trip or 
adehabitat (ltraj class) packages. Just being able to read the data is 
only the first step, finding an adequate representation with convenient 
analysis tools is probably harder.

Using the Z dimension in shapefiles is arguably not a portable way of 
representing this, using points with a constant lineID and sequence 
numbers increasing downstream, with elevation at the points, may be easier 
to handle. (Untried) Convert to say GPX and read as track_points, trying 
to retain the necessary attributes.

Hope this helps,

Roger

> When I was using the readOGR command,  the following message appear.
> ****************
> riv_CH <- readOGR(".", "riverz")
> OGR data source with driver: ESRI Shapefile
> Source: ".", layer: "riverz"
> with 13 features and 13 fields
> Feature type: wkbLineString with 3 dimensions
> Warnmeldung:
> In readOGR(".", "riverz") : Z-dimension discarded
> *****************
>
> Do you have any suggestion for handling the z-dimension?
>
> Thanks a lot in advance, Rosi
>
> ???
> Rosi Siber
> Swiss Federal Institute of Aquatic Science and Technology (Eawag)
> Siam
> Ueberlandstrasse 133
> 8600 Duebendorf
> Switzerland
> Phone: +41 (0)44 823 5566
> Fax:   +41 (0)44 823 5375
> rosi.siber at eawag.ch
> http://www.eawag.ch/~siberros
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From famuvie at alumni.uv.es  Fri Nov 13 16:19:04 2009
From: famuvie at alumni.uv.es (=?UTF-8?B?RmFjdW5kbyBNdcOxb3o=?=)
Date: Fri, 13 Nov 2009 16:19:04 +0100
Subject: [R-sig-Geo] Hydrological distance between sites
In-Reply-To: <8f656ccd0911111017t22ae6456t85ec9dd8c2999f96@mail.gmail.com>
References: <8f656ccd0911040453o58bdfd79ia31f42bccc8ab00f@mail.gmail.com>
	<4AFAE29C.9020207@alumni.uv.es>
	<8f656ccd0911110832p1bc05b90j4c847355c0458bf3@mail.gmail.com>
	<8f656ccd0911110834r1013adf9w618ac03454d2130d@mail.gmail.com>
	<4AFAF11E.9010908@alumni.uv.es> <4AFAF98F.1010108@alumni.uv.es>
	<8f656ccd0911111017t22ae6456t85ec9dd8c2999f96@mail.gmail.com>
Message-ID: <4AFD78E8.4080003@alumni.uv.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091113/b5f8b8a9/attachment.pl>

From seanpor at acm.org  Fri Nov 13 16:54:45 2009
From: seanpor at acm.org (Sean O'Riordain)
Date: Fri, 13 Nov 2009 15:54:45 +0000
Subject: [R-sig-Geo] sub-selecting spatial data by distance from a different
	point(set)
Message-ID: <8ed68eed0911130754h65f2af68rf2668af1a77e34e3@mail.gmail.com>

Good afternoon,

Apologies if this seems a basic question but I'm quite new to spatial
analysis (1 week now!) and I'm reading and learning as fast as I can.
I've read the Spatial Data task view, "Analysing spatial point
patterns in R" by Bradley and I've ordered "Applied Spatial Data
Analysis with R" - but it hasn't arrived yet...  I've looked and
searched - but I'm guessing that I'm not using the right buzzwords...

I have a data.frame (call it A) of about 2 million X,Y points each
with info with various characteristics, numeric and factor.  I have a
separate much smaller data.frame (call it B) of say 500 rows of X,Y
and I'd like to be able to pull a subset of A, so that for each B[i,]
I will get all rows from A that are within a given straight line
distance (i.e. within a short 'as the crow flies' radius).

Could somebody please give me some starting hints please?

Thanks in advance,
Sean O'Riordain


From p.hiemstra at geo.uu.nl  Sat Nov 14 12:11:19 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 14 Nov 2009 12:11:19 +0100
Subject: [R-sig-Geo] sub-selecting spatial data by distance from a
 different point(set)
In-Reply-To: <8ed68eed0911130754h65f2af68rf2668af1a77e34e3@mail.gmail.com>
References: <8ed68eed0911130754h65f2af68rf2668af1a77e34e3@mail.gmail.com>
Message-ID: <4AFE9057.7020403@geo.uu.nl>

Hi Sean,

Take a look at the spDistsN1 function to calculate the distances from a 
single point to all other points. You can then make the subset based on 
the distance. What could also be an options is to build a polygon that 
has the radius around the point you are taking the distance from, and 
then use overlay to find which points are in the radius polygon. This 
might be faster when using a large dataset. I'm not sure how nto make 
the polygon, but it should be possible. But you could first take a look 
at spDistsN1.

cheers,
Paul

Sean O'Riordain wrote:
> Good afternoon,
>
> Apologies if this seems a basic question but I'm quite new to spatial
> analysis (1 week now!) and I'm reading and learning as fast as I can.
> I've read the Spatial Data task view, "Analysing spatial point
> patterns in R" by Bradley and I've ordered "Applied Spatial Data
> Analysis with R" - but it hasn't arrived yet...  I've looked and
> searched - but I'm guessing that I'm not using the right buzzwords...
>
> I have a data.frame (call it A) of about 2 million X,Y points each
> with info with various characteristics, numeric and factor.  I have a
> separate much smaller data.frame (call it B) of say 500 rows of X,Y
> and I'd like to be able to pull a subset of A, so that for each B[i,]
> I will get all rows from A that are within a given straight line
> distance (i.e. within a short 'as the crow flies' radius).
>
> Could somebody please give me some starting hints please?
>
> Thanks in advance,
> Sean O'Riordain
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Sat Nov 14 12:19:06 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 14 Nov 2009 12:19:06 +0100
Subject: [R-sig-Geo] sub-selecting spatial data by distance from a
 different point(set)
In-Reply-To: <4AFE9057.7020403@geo.uu.nl>
References: <8ed68eed0911130754h65f2af68rf2668af1a77e34e3@mail.gmail.com>
	<4AFE9057.7020403@geo.uu.nl>
Message-ID: <4AFE922A.9070208@geo.uu.nl>

Sorry forgot: spDistsN1 is from the sp package.

cheers,
Paul

Paul Hiemstra wrote:
> Hi Sean,
>
> Take a look at the spDistsN1 function to calculate the distances from 
> a single point to all other points. You can then make the subset based 
> on the distance. What could also be an options is to build a polygon 
> that has the radius around the point you are taking the distance from, 
> and then use overlay to find which points are in the radius polygon. 
> This might be faster when using a large dataset. I'm not sure how nto 
> make the polygon, but it should be possible. But you could first take 
> a look at spDistsN1.
>
> cheers,
> Paul
>
> Sean O'Riordain wrote:
>> Good afternoon,
>>
>> Apologies if this seems a basic question but I'm quite new to spatial
>> analysis (1 week now!) and I'm reading and learning as fast as I can.
>> I've read the Spatial Data task view, "Analysing spatial point
>> patterns in R" by Bradley and I've ordered "Applied Spatial Data
>> Analysis with R" - but it hasn't arrived yet...  I've looked and
>> searched - but I'm guessing that I'm not using the right buzzwords...
>>
>> I have a data.frame (call it A) of about 2 million X,Y points each
>> with info with various characteristics, numeric and factor.  I have a
>> separate much smaller data.frame (call it B) of say 500 rows of X,Y
>> and I'd like to be able to pull a subset of A, so that for each B[i,]
>> I will get all rows from A that are within a given straight line
>> distance (i.e. within a short 'as the crow flies' radius).
>>
>> Could somebody please give me some starting hints please?
>>
>> Thanks in advance,
>> Sean O'Riordain
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>
>


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From Roger.Bivand at nhh.no  Sat Nov 14 16:31:10 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 14 Nov 2009 16:31:10 +0100 (CET)
Subject: [R-sig-Geo] sub-selecting spatial data by distance from a
 different point(set)
In-Reply-To: <4AFE9057.7020403@geo.uu.nl>
References: <8ed68eed0911130754h65f2af68rf2668af1a77e34e3@mail.gmail.com>
	<4AFE9057.7020403@geo.uu.nl>
Message-ID: <alpine.LRH.2.00.0911141622240.28815@reclus.nhh.no>

On Sat, 14 Nov 2009, Paul Hiemstra wrote:

> Hi Sean,
>
> Take a look at the spDistsN1 function to calculate the distances from a 
> single point to all other points. You can then make the subset based on the 
> distance. What could also be an options is to build a polygon that has the 
> radius around the point you are taking the distance from, and then use 
> overlay to find which points are in the radius polygon. This might be faster 
> when using a large dataset. I'm not sure how nto make the polygon, but it 
> should be possible. But you could first take a look at spDistsN1.

In fact spDistsN1() in a loop over the coordinates of B runs (for me) 
faster than building and searching a quadtree in A, and (to machine 
precision) gets the same results. So allocate an empty list, and step 
through:

dn <- vector(mode="list", length=nrow(B))
for (i in 1:nrow(B)) {
   dn[[i]] <- which(spDists(A, B[i,]) <= threshold)
}

where A is a 2M by 2 matrix and B is a 500 by 2 matrix. dn will be a list 
of 500 vectors of point IDs in A. For me on a laptop (with A 2M points 
from runif() and B 500 points from runif()), this search took under 5 
minutes, with # neighbours between 7000 and 16000.

Roger

>
> cheers,
> Paul
>
> Sean O'Riordain wrote:
>> Good afternoon,
>> 
>> Apologies if this seems a basic question but I'm quite new to spatial
>> analysis (1 week now!) and I'm reading and learning as fast as I can.
>> I've read the Spatial Data task view, "Analysing spatial point
>> patterns in R" by Bradley and I've ordered "Applied Spatial Data
>> Analysis with R" - but it hasn't arrived yet...  I've looked and
>> searched - but I'm guessing that I'm not using the right buzzwords...
>> 
>> I have a data.frame (call it A) of about 2 million X,Y points each
>> with info with various characteristics, numeric and factor.  I have a
>> separate much smaller data.frame (call it B) of say 500 rows of X,Y
>> and I'd like to be able to pull a subset of A, so that for each B[i,]
>> I will get all rows from A that are within a given straight line
>> distance (i.e. within a short 'as the crow flies' radius).
>> 
>> Could somebody please give me some starting hints please?
>> 
>> Thanks in advance,
>> Sean O'Riordain
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From seanpor at acm.org  Sat Nov 14 17:26:16 2009
From: seanpor at acm.org (Sean O'Riordain)
Date: Sat, 14 Nov 2009 16:26:16 +0000
Subject: [R-sig-Geo] sub-selecting spatial data by distance from a
	different point(set)
In-Reply-To: <alpine.LRH.2.00.0911141622240.28815@reclus.nhh.no>
References: <8ed68eed0911130754h65f2af68rf2668af1a77e34e3@mail.gmail.com>
	<4AFE9057.7020403@geo.uu.nl>
	<alpine.LRH.2.00.0911141622240.28815@reclus.nhh.no>
Message-ID: <8ed68eed0911140826r6a4afa9eu2cf7824937cce67c@mail.gmail.com>

Thank you very much Roger and Paul.

Kind regards,
Sean


On Sat, Nov 14, 2009 at 3:31 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Sat, 14 Nov 2009, Paul Hiemstra wrote:
>
>> Hi Sean,
>>
>> Take a look at the spDistsN1 function to calculate the distances from a
>> single point to all other points. You can then make the subset based on the
>> distance. What could also be an options is to build a polygon that has the
>> radius around the point you are taking the distance from, and then use
>> overlay to find which points are in the radius polygon. This might be faster
>> when using a large dataset. I'm not sure how nto make the polygon, but it
>> should be possible. But you could first take a look at spDistsN1.
>
> In fact spDistsN1() in a loop over the coordinates of B runs (for me) faster
> than building and searching a quadtree in A, and (to machine precision) gets
> the same results. So allocate an empty list, and step through:
>
> dn <- vector(mode="list", length=nrow(B))
> for (i in 1:nrow(B)) {
> ?dn[[i]] <- which(spDists(A, B[i,]) <= threshold)
> }
>
> where A is a 2M by 2 matrix and B is a 500 by 2 matrix. dn will be a list of
> 500 vectors of point IDs in A. For me on a laptop (with A 2M points from
> runif() and B 500 points from runif()), this search took under 5 minutes,
> with # neighbours between 7000 and 16000.
>
> Roger
>
>>
>> cheers,
>> Paul
>>
>> Sean O'Riordain wrote:
>>>
>>> Good afternoon,
>>>
>>> Apologies if this seems a basic question but I'm quite new to spatial
>>> analysis (1 week now!) and I'm reading and learning as fast as I can.
>>> I've read the Spatial Data task view, "Analysing spatial point
>>> patterns in R" by Bradley and I've ordered "Applied Spatial Data
>>> Analysis with R" - but it hasn't arrived yet... ?I've looked and
>>> searched - but I'm guessing that I'm not using the right buzzwords...
>>>
>>> I have a data.frame (call it A) of about 2 million X,Y points each
>>> with info with various characteristics, numeric and factor. ?I have a
>>> separate much smaller data.frame (call it B) of say 500 rows of X,Y
>>> and I'd like to be able to pull a subset of A, so that for each B[i,]
>>> I will get all rows from A that are within a given straight line
>>> distance (i.e. within a short 'as the crow flies' radius).
>>>
>>> Could somebody please give me some starting hints please?
>>>
>>> Thanks in advance,
>>> Sean O'Riordain
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>


From Ervan.Rutishauser at ecofog.gf  Sun Nov 15 13:57:27 2009
From: Ervan.Rutishauser at ecofog.gf (Ervan Rutishauser)
Date: Sun, 15 Nov 2009 09:57:27 -0300
Subject: [R-sig-Geo] Multitype point pattern analysis
Message-ID: <D45C8CF4C5CB2A41956F98C65F093A3A533130880E@funguti.ecofog.gf>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091115/34bcf247/attachment.pl>

From virginia at dpi.inpe.br  Sun Nov 15 15:52:32 2009
From: virginia at dpi.inpe.br (Virginia)
Date: Sun, 15 Nov 2009 12:52:32 -0200
Subject: [R-sig-Geo] help in gwr use
Message-ID: <4B0015B0.4040503@dpi.inpe.br>


Please,

I am having problems running gwr.
I've istalled it and loaded it but when I run the gwr.sel I received the 
error message
Erro: n?o foi posss?vel encontrar a fun??o "gwr.sel"  (it's not possible 
to find the gwr.sel function).
What I am doing wrong?
Thanks,

Virginia


From yud at mail.montclair.edu  Sun Nov 15 16:05:06 2009
From: yud at mail.montclair.edu (Danlin Yu)
Date: Sun, 15 Nov 2009 10:05:06 -0500
Subject: [R-sig-Geo] help in gwr use
In-Reply-To: <4B0015B0.4040503@dpi.inpe.br>
References: <4B0015B0.4040503@dpi.inpe.br>
Message-ID: <4B0018A2.6070706@mail.montclair.edu>

Virgina:

It's quite hard to address your question if you just ask generally. Can 
you specify how you ran the package?

Based on the error message you give, I suspect that you didn't load the 
package. After you installed the package, did you try to load the 
package to R via "library(spgwr)"?

Cheers,
Dr. Danlin Yu

Virginia ??:
>
> Please,
>
> I am having problems running gwr.
> I've istalled it and loaded it but when I run the gwr.sel I received 
> the error message
> Erro: n?o foi posss?vel encontrar a fun??o "gwr.sel" (it's not 
> possible to find the gwr.sel function).
> What I am doing wrong?
> Thanks,
>
> Virginia
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor of GIS and Urban Geography
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu


From tomfool at as220.org  Sun Nov 15 17:19:51 2009
From: tomfool at as220.org (Tom Sgouros)
Date: Sun, 15 Nov 2009 11:19:51 -0500
Subject: [R-sig-Geo] newbie questions
Message-ID: <7124.1258301991@as220.org>


Hello all:

I'm trying to make some simple maps of election results and I am having
some trouble.  I'm hoping to use Grass (or QGis) to make the maps, but
apparently this requires getting my data into the shape files, and I
can't figure out how to do that.  I've found read.shape and that's
great, and I thought that by editing the resulting att.data data frame I
could do what I need.  Unfortunatly, if I use merge to combine my data
with the existing data, the data frame comes out sorted by the join
column and the output dbf file (done with write.dbf) doesn't work
properly with the shapefile because it's no longer sorted the same as
the outlines.

I tried preserving the original order of the data frame and re-sorting
the data frame before writing it out, and that worked, but the resulting
dbf file causes a seg fault in Grass when I try to read it with the rest
of the shape data.  Plus it seems a ridiculous amount of work for what
must be a fairly routine operation.

So here's my question: I have some data I want to add to a shape file
(the SHP, DBF, etc).  Can I use R maptools to do that easily, and if so,
how?

Many thanks in advance for the help,

 -tom


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From Roger.Bivand at nhh.no  Sun Nov 15 19:52:48 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 15 Nov 2009 19:52:48 +0100 (CET)
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <7124.1258301991@as220.org>
References: <7124.1258301991@as220.org>
Message-ID: <alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>

On Sun, 15 Nov 2009, Tom Sgouros wrote:

>
> Hello all:
>
> I'm trying to make some simple maps of election results and I am having
> some trouble.  I'm hoping to use Grass (or QGis) to make the maps, but
> apparently this requires getting my data into the shape files, and I
> can't figure out how to do that.  I've found read.shape and that's

Please do not use read.shape(), it is deprecated, and will become 
unavailable at the user-visible level at the next maptools release.

Do use readShapeSpatial() (or better readOGR() in rgdal) to create a 
SpatialPolygonsDataFrame, paying attention to the ID= argument. Then use 
spCbind() and if necessary spChFIDs() to ensure that your data are being 
associated with the correct Polygons object inside the 
SpatialPolygonsDataFrame. Then use writeSpatialShape() (or writeOGR()) to 
write the shapefile.

> great, and I thought that by editing the resulting att.data data frame I
> could do what I need.  Unfortunatly, if I use merge to combine my data
> with the existing data, the data frame comes out sorted by the join
> column and the output dbf file (done with write.dbf) doesn't work
> properly with the shapefile because it's no longer sorted the same as
> the outlines.

Using merge() without reading the help file usually has this outcome - 
there are arguments controlling sorting.

Hope this helps,

Roger

PS. Did you read the Spatial task view on CRAN, or, say, the page on the R 
wiki entitled "Getting spatial data into and out of R":

http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:import_export


>
> I tried preserving the original order of the data frame and re-sorting
> the data frame before writing it out, and that worked, but the resulting
> dbf file causes a seg fault in Grass when I try to read it with the rest
> of the shape data.  Plus it seems a ridiculous amount of work for what
> must be a fairly routine operation.
>
> So here's my question: I have some data I want to add to a shape file
> (the SHP, DBF, etc).  Can I use R maptools to do that easily, and if so,
> how?
>
> Many thanks in advance for the help,
>
> -tom
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From jochen at hunter.cuny.edu  Sun Nov 15 20:22:23 2009
From: jochen at hunter.cuny.edu (Jochen Albrecht)
Date: Sun, 15 Nov 2009 14:22:23 -0500
Subject: [R-sig-Geo] spdep neighbor generation and subsequent regression
	analysis
In-Reply-To: <a413fd8c0909131205l27d22b23i6741f894ef7222f0@mail.gmail.com>
References: <a413fd8c0909131205l27d22b23i6741f894ef7222f0@mail.gmail.com>
Message-ID: <4B0054EF.6070907@hunter.cuny.edu>

Hello:
On first sight, this is about read.gal[2,3] and read.gwt2nb, but in the 
long run, it is about strategies for working with very large datasets.
Here is the background. With Robert Hijmans' support, we generated a 
comprehensive database of world-wide green house gas emissions (GHGs) 
and a wide range of explanatory variables. The point file now contains 
(depending on source) between 1.4 and 2.1 million locations, all on a 
0.1 degree grid. We would like to run a bunch of spatial regression 
models on this very large dataset. In the end, we would like to 
determine which (set of) variable(s) have what kind of effect on GHGs in 
what part of the world. The variables are physical, economic, 
demographic, and geographic (e.g. distance from ocean) in nature.
This procedure usually starts with creating a spatial weights matrix, 
which we tried in R but lead to an endless process (we tried it 
repeatedly on machines with 4 GM RAM and Xeon processors; it did not 
bail, just kept running at about 50% CPU time using between 300 and 2100 
MB of memory for more than a week until we killed the process).
GeoDA ran for about six hours and then produced a file with a good 5 
million records, 99% of which contained zero neighbors. This is where 
the immediate question comes into play. The read.gal function did not 
like the file produced by GeoDA. There is some GeoDA documentation that 
suggests that we should use read.gal2 or read.gal3 but these are not 
part of the spdep distribution, nor could I find them anywhere. As it 
happens, the file generated had a .gwt extension, so I tried 
read.get2nb. It seemed to accept the input but then completely killed 
the whole R process (I kept screen shots just for Roger). My guess is 
that (a) the matrix was too big, or (b) it was too sparse, or (c) it was 
a corrupt product of GeoDA in the first place.
Which brings me back to the bigger picture and the following questions:
1) Is there something inherently wrong with our approach?
2) Can anybody think of alternative ways to create a spatial regression 
model for the above mentioned questions?
3) Would it be worthwhile to move onto a Linux machine and recompile all 
the different packages?
Cheers,
     Jochen


From Adrian.Baddeley at csiro.au  Sun Nov 15 22:23:38 2009
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Mon, 16 Nov 2009 05:23:38 +0800
Subject: [R-sig-Geo] sub-selecting spatial data by distance from a different
 (point) set
Message-ID: <57DC18C299094D4299F837570C5DF1C502C9344DB0@EXWA-MBX01.nexus.csiro.au>

"Sean O'Riordain" seanpor at acm.org<mailto:seanpor at acm.org> writes:

> I've read the Spatial Data task view, "Analysing spatial point
> patterns in R" by Bradley

      who?!?!    :-)

> I have a data.frame (call it A) of about 2 million X,Y points each
> with info with various characteristics, numeric and factor.  I have a
> separate much smaller data.frame (call it B) of say 500 rows of X,Y
> and I'd like to be able to pull a subset of A, so that for each B[i,]
> I will get all rows from A that are within a given straight line
> distance (i.e. within a short 'as the crow flies' radius).

    In the package spatstat you can use the function closepairs() to do this.

Convert the data frames to objects of class 'ppp'. Then closepairs(A, B, r)
will return a list of all pairs i,j such that A[i] and B[j] are within a distance r.
The return value is a list containing vectors named i, j, d (and a few other things).

regards
Adrian Baddeley


From tomfool at as220.org  Mon Nov 16 01:05:42 2009
From: tomfool at as220.org (tom sgouros)
Date: Sun, 15 Nov 2009 19:05:42 -0500
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no> 
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
Message-ID: <9643.1258329942@as220.org>



Roger Bivand <Roger.Bivand at nhh.no> wrote:

> > I'm trying to make some simple maps of election results and I am having
> > some trouble.  I'm hoping to use Grass (or QGis) to make the maps, but
> > apparently this requires getting my data into the shape files, and I
> > can't figure out how to do that.  I've found read.shape and that's
> 
> Please do not use read.shape(), it is deprecated, and will become
> unavailable at the user-visible level at the next maptools release.

Where is the introduction that explains all this?  Is there one
somewhere?   (And thank you for the assistance.)

> Do use readShapeSpatial() (or better readOGR() in rgdal) to create a
> SpatialPolygonsDataFrame, paying attention to the ID= argument. Then
> use spCbind() and if necessary spChFIDs() to ensure that your data are
> being associated with the correct Polygons object inside the
> SpatialPolygonsDataFrame. Then use writeSpatialShape() (or writeOGR())
> to write the shapefile.

Thank you very much for all that, it gives me a lot to try.

> > great, and I thought that by editing the resulting att.data data frame I
> > could do what I need.  Unfortunatly, if I use merge to combine my data
> > with the existing data, the data frame comes out sorted by the join
> > column and the output dbf file (done with write.dbf) doesn't work
> > properly with the shapefile because it's no longer sorted the same as
> > the outlines.
> 
> Using merge() without reading the help file usually has this outcome - 
> there are arguments controlling sorting.

Thank you for the help, but no thank you for the snide.  What the help
file says (on my system) is that if you do sort=FALSE, the output order
is unspecified, which is approximately zero help for someone trying to
figure out why the output map looks so funny.

> PS. Did you read the Spatial task view on CRAN, or, say, the page on
> the R wiki entitled "Getting spatial data into and out of R":
> 
> http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:import_export
> 

Yes.  I can't say I found those pages very helpful since they are mostly
written in a language I don't understand, and where I do understand what
they're saying, they're saying things like this: 

 "Use a GIS if you're trying to do the following:

    - specialized GIS tasks"

In the nicest and most constructive way I can think of, I have to say
that this isn't very helpful to the person who has data they want to map
and wants to get on with it.  I have been a R user (and fan) for years
and am more or less familiar with much of it, but I haven't used it for
spatial data, and I find the available documentation for people who are
starting from zero like me is fairly wanting.

Many thanks,

 -tom


> 
> >
> > I tried preserving the original order of the data frame and re-sorting
> > the data frame before writing it out, and that worked, but the resulting
> > dbf file causes a seg fault in Grass when I try to read it with the rest
b> > of the shape data.  Plus it seems a ridiculous amount of work for what
> > must be a fairly routine operation.
> >
> > So here's my question: I have some data I want to add to a shape file
> > (the SHP, DBF, etc).  Can I use R maptools to do that easily, and if so,
> > how?
> >
> > Many thanks in advance for the help,
> >
> > -tom
> >
> >
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From saldanha.plangeo at gmail.com  Mon Nov 16 02:03:45 2009
From: saldanha.plangeo at gmail.com (Raphael Saldanha)
Date: Sun, 15 Nov 2009 23:03:45 -0200
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <9643.1258329942@as220.org>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no> 
	<9643.1258329942@as220.org>
Message-ID: <c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091115/7eb2b8d6/attachment.pl>

From tomfool at as220.org  Mon Nov 16 04:30:02 2009
From: tomfool at as220.org (tom sgouros)
Date: Sun, 15 Nov 2009 22:30:02 -0500
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com> 
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
Message-ID: <22498.1258342202@as220.org>


Raphael Saldanha <saldanha.plangeo at gmail.com> wrote:

> Hi Tom!
> 
> I'm a geographer and R enthusiast too, but what I can say is: R is a great
> software to statistics. The final production of maps, although it's
> possible, it's simple and faster made with GIS softwares, like GRASS,
> Quantum GIS or ArcGIS.

This is exactly my quandary.  I have some data I want to map, and I have
no idea how to do it and none of the introductions I've found speak to
what I thought was a pretty simple task.

I first thought maybe I should use a GIS, since it's geographic data,
but all the GIS documentation I can find is about how to analyze data
that's already available.  There are no end of Grass examples using this
North Carolina dataset that comes with the installation, but I don't
live in North Carolina and I don't want to analyze their data.  I want
to analyze mine, but I can't figure out how to get it in, and that's
what I'm using R for.

If you are telling me there is a simpler way to do this, I am all ears
(eyes), especially if it uses grass or qgis which I can afford, and not
Arc, which I can't.

Queries of GIS guys told me that what I need to do is to get my data
into a shape file first and then a GIS can help me display it, so I
turned to R for that.  Was I wrong there, too?

Most of the data I want to map is not currently in any format at all.
It's just numbers I have.  I have shape files for the geography and I
want to apply my numbers to those shapes and draw maps in color, and I
also would very much like to draw the 3d kind where the geographic area
is raised up according to some value.  (I don't know if there's a name
for this.)  I tried to use a spreadsheet to get my data attached to the
shapes, but as soon as I realized I needed to do a join of my data and
the shape file data I began to look for alternatives.

I know that I'm working at a very low level here, but in addition to
Roger's advice before about how to get R to cooperate, I would be
grateful for any advice such as you've provided about what exactly R is
good for in my task and what a GIS is good for.  Your note advances me
down the field quite a bit, but if there's more, I'd be interested to
know it.

Many thanks,

 -tom



> 
> My tip is: organize data with spreadsheet and GIS softwares, import (as
> shapefile, if possible) in R and make your statistical analysis and
> statistical columns of data, export to another shapefile and manipulate the
> final map in GIS softwares.
> 
> I repeat, it's possible make all these steps in R, and generate great maps,
> but the most simple way is above. Personally, I use R to make the final maps
> only when I have to produce a long series of simple maps.
> 
> I think the best way is the integration of GIS software with R, each one
> with his specialty.
> 
> 
> King regards,
> 
> Raphael Saldanha
> BRAZIL
> saldanha.plangeo at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From dan.putler at sauder.ubc.ca  Mon Nov 16 04:40:18 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Sun, 15 Nov 2009 19:40:18 -0800
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <19904_1258342273_1258342273_22498.1258342202@as220.org>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<19904_1258342273_1258342273_22498.1258342202@as220.org>
Message-ID: <1258342818.6809.58.camel@whitebox>

Tom,

Er, what exactly is your data? Do you have data that is linked to zip
codes and you want to do a "thematic" (choropleth) map of the data? Do
you have point data (say a lat/lon values), and want to plot the points?
Given what you've said, hard to figure out how to get you going in the
right direction.

Dan

On Sun, 2009-11-15 at 22:30 -0500, tom sgouros wrote:
> Raphael Saldanha <saldanha.plangeo at gmail.com> wrote:
> 
> > Hi Tom!
> > 
> > I'm a geographer and R enthusiast too, but what I can say is: R is a great
> > software to statistics. The final production of maps, although it's
> > possible, it's simple and faster made with GIS softwares, like GRASS,
> > Quantum GIS or ArcGIS.
> 
> This is exactly my quandary.  I have some data I want to map, and I have
> no idea how to do it and none of the introductions I've found speak to
> what I thought was a pretty simple task.
> 
> I first thought maybe I should use a GIS, since it's geographic data,
> but all the GIS documentation I can find is about how to analyze data
> that's already available.  There are no end of Grass examples using this
> North Carolina dataset that comes with the installation, but I don't
> live in North Carolina and I don't want to analyze their data.  I want
> to analyze mine, but I can't figure out how to get it in, and that's
> what I'm using R for.
> 
> If you are telling me there is a simpler way to do this, I am all ears
> (eyes), especially if it uses grass or qgis which I can afford, and not
> Arc, which I can't.
> 
> Queries of GIS guys told me that what I need to do is to get my data
> into a shape file first and then a GIS can help me display it, so I
> turned to R for that.  Was I wrong there, too?
> 
> Most of the data I want to map is not currently in any format at all.
> It's just numbers I have.  I have shape files for the geography and I
> want to apply my numbers to those shapes and draw maps in color, and I
> also would very much like to draw the 3d kind where the geographic area
> is raised up according to some value.  (I don't know if there's a name
> for this.)  I tried to use a spreadsheet to get my data attached to the
> shapes, but as soon as I realized I needed to do a join of my data and
> the shape file data I began to look for alternatives.
> 
> I know that I'm working at a very low level here, but in addition to
> Roger's advice before about how to get R to cooperate, I would be
> grateful for any advice such as you've provided about what exactly R is
> good for in my task and what a GIS is good for.  Your note advances me
> down the field quite a bit, but if there's more, I'd be interested to
> know it.
> 
> Many thanks,
> 
>  -tom
> 
> 
> 
> > 
> > My tip is: organize data with spreadsheet and GIS softwares, import (as
> > shapefile, if possible) in R and make your statistical analysis and
> > statistical columns of data, export to another shapefile and manipulate the
> > final map in GIS softwares.
> > 
> > I repeat, it's possible make all these steps in R, and generate great maps,
> > but the most simple way is above. Personally, I use R to make the final maps
> > only when I have to produce a long series of simple maps.
> > 
> > I think the best way is the integration of GIS software with R, each one
> > with his specialty.
> > 
> > 
> > King regards,
> > 
> > Raphael Saldanha
> > BRAZIL
> > saldanha.plangeo at gmail.com
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > 
> 
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From tomfool at as220.org  Mon Nov 16 05:18:26 2009
From: tomfool at as220.org (tom sgouros)
Date: Sun, 15 Nov 2009 23:18:26 -0500
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <1258342818.6809.58.camel@whitebox> 
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<19904_1258342273_1258342273_22498.1258342202@as220.org>
	<1258342818.6809.58.camel@whitebox>
Message-ID: <25494.1258345106@as220.org>


Dan Putler <dan.putler at sauder.ubc.ca> wrote:

> Tom,
> 
> Er, what exactly is your data? Do you have data that is linked to zip
> codes and you want to do a "thematic" (choropleth) map of the data? Do
> you have point data (say a lat/lon values), and want to plot the points?
> Given what you've said, hard to figure out how to get you going in the
> right direction.

The data is mostly from past elections, so it's vote totals or
demographic data within some district.

Google tells me that choropleth is the name of precisely the kind of
thing I'm trying to make, thank you for expanding my vocabulary today.

Is there a name for the bar graph kind of thing?  (Here's an example:
http://www.turbosquid.com/FullPreview/Index.cfm/ID/346428 )

Thank you,

 -tom

> 
> On Sun, 2009-11-15 at 22:30 -0500, tom sgouros wrote:
> > Raphael Saldanha <saldanha.plangeo at gmail.com> wrote:
> > 
> > > Hi Tom!
> > > 
> > > I'm a geographer and R enthusiast too, but what I can say is: R is a great
> > > software to statistics. The final production of maps, although it's
> > > possible, it's simple and faster made with GIS softwares, like GRASS,
> > > Quantum GIS or ArcGIS.
> > 
> > This is exactly my quandary.  I have some data I want to map, and I have
> > no idea how to do it and none of the introductions I've found speak to
> > what I thought was a pretty simple task.
> > 
> > I first thought maybe I should use a GIS, since it's geographic data,
> > but all the GIS documentation I can find is about how to analyze data
> > that's already available.  There are no end of Grass examples using this
> > North Carolina dataset that comes with the installation, but I don't
> > live in North Carolina and I don't want to analyze their data.  I want
> > to analyze mine, but I can't figure out how to get it in, and that's
> > what I'm using R for.
> > 
> > If you are telling me there is a simpler way to do this, I am all ears
> > (eyes), especially if it uses grass or qgis which I can afford, and not
> > Arc, which I can't.
> > 
> > Queries of GIS guys told me that what I need to do is to get my data
> > into a shape file first and then a GIS can help me display it, so I
> > turned to R for that.  Was I wrong there, too?
> > 
> > Most of the data I want to map is not currently in any format at all.
> > It's just numbers I have.  I have shape files for the geography and I
> > want to apply my numbers to those shapes and draw maps in color, and I
> > also would very much like to draw the 3d kind where the geographic area
> > is raised up according to some value.  (I don't know if there's a name
> > for this.)  I tried to use a spreadsheet to get my data attached to the
> > shapes, but as soon as I realized I needed to do a join of my data and
> > the shape file data I began to look for alternatives.
> > 
> > I know that I'm working at a very low level here, but in addition to
> > Roger's advice before about how to get R to cooperate, I would be
> > grateful for any advice such as you've provided about what exactly R is
> > good for in my task and what a GIS is good for.  Your note advances me
> > down the field quite a bit, but if there's more, I'd be interested to
> > know it.
> > 
> > Many thanks,
> > 
> >  -tom
> > 
> > 
> > 
> > > 
> > > My tip is: organize data with spreadsheet and GIS softwares, import (as
> > > shapefile, if possible) in R and make your statistical analysis and
> > > statistical columns of data, export to another shapefile and manipulate the
> > > final map in GIS softwares.
> > > 
> > > I repeat, it's possible make all these steps in R, and generate great maps,
> > > but the most simple way is above. Personally, I use R to make the final maps
> > > only when I have to produce a long series of simple maps.
> > > 
> > > I think the best way is the integration of GIS software with R, each one
> > > with his specialty.
> > > 
> > > 
> > > King regards,
> > > 
> > > Raphael Saldanha
> > > BRAZIL
> > > saldanha.plangeo at gmail.com
> > > 
> > > 	[[alternative HTML version deleted]]
> > > 
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at stat.math.ethz.ch
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > 
> > 
> > 
> -- 
> Dan Putler
> Sauder School of Business
> University of British Columbia
> 


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From tomfool at as220.org  Mon Nov 16 05:27:57 2009
From: tomfool at as220.org (tom sgouros)
Date: Sun, 15 Nov 2009 23:27:57 -0500
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <25494.1258345106@as220.org> 
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<19904_1258342273_1258342273_22498.1258342202@as220.org>
	<1258342818.6809.58.camel@whitebox> <25494.1258345106@as220.org>
Message-ID: <25908.1258345677@as220.org>


tom sgouros <tomfool at as220.org> wrote:

> 
> Dan Putler <dan.putler at sauder.ubc.ca> wrote:

> > Er, what exactly is your data? Do you have data that is linked to zip
> > codes and you want to do a "thematic" (choropleth) map of the data? Do
> > you have point data (say a lat/lon values), and want to plot the points?
> > Given what you've said, hard to figure out how to get you going in the
> > right direction.
> 
> The data is mostly from past elections, so it's vote totals or
> demographic data within some district.

I should have also said that I have both SHP files and E00 files to
describe the boundaries of the districts, but have no feeling about
which I should prefer or why and I wonder if anyone else does.  The SHP
files come with an XML description that seems not to be used by grass.
The E00 files maybe come with a description of their own projection,
while I had to identify a projection to specify it to grass, but
otherwise I don't know why one would be better or worse.

Thanks,

 -tom


> 
> Google tells me that choropleth is the name of precisely the kind of
> thing I'm trying to make, thank you for expanding my vocabulary today.
> 
> Is there a name for the bar graph kind of thing?  (Here's an example:
> http://www.turbosquid.com/FullPreview/Index.cfm/ID/346428 )
> 
> Thank you,
> 
>  -tom
> 
> > 
> > On Sun, 2009-11-15 at 22:30 -0500, tom sgouros wrote:
> > > Raphael Saldanha <saldanha.plangeo at gmail.com> wrote:
> > > 
> > > > Hi Tom!
> > > > 
> > > > I'm a geographer and R enthusiast too, but what I can say is: R is a great
> > > > software to statistics. The final production of maps, although it's
> > > > possible, it's simple and faster made with GIS softwares, like GRASS,
> > > > Quantum GIS or ArcGIS.
> > > 
> > > This is exactly my quandary.  I have some data I want to map, and I have
> > > no idea how to do it and none of the introductions I've found speak to
> > > what I thought was a pretty simple task.
> > > 
> > > I first thought maybe I should use a GIS, since it's geographic data,
> > > but all the GIS documentation I can find is about how to analyze data
> > > that's already available.  There are no end of Grass examples using this
> > > North Carolina dataset that comes with the installation, but I don't
> > > live in North Carolina and I don't want to analyze their data.  I want
> > > to analyze mine, but I can't figure out how to get it in, and that's
> > > what I'm using R for.
> > > 
> > > If you are telling me there is a simpler way to do this, I am all ears
> > > (eyes), especially if it uses grass or qgis which I can afford, and not
> > > Arc, which I can't.
> > > 
> > > Queries of GIS guys told me that what I need to do is to get my data
> > > into a shape file first and then a GIS can help me display it, so I
> > > turned to R for that.  Was I wrong there, too?
> > > 
> > > Most of the data I want to map is not currently in any format at all.
> > > It's just numbers I have.  I have shape files for the geography and I
> > > want to apply my numbers to those shapes and draw maps in color, and I
> > > also would very much like to draw the 3d kind where the geographic area
> > > is raised up according to some value.  (I don't know if there's a name
> > > for this.)  I tried to use a spreadsheet to get my data attached to the
> > > shapes, but as soon as I realized I needed to do a join of my data and
> > > the shape file data I began to look for alternatives.
> > > 
> > > I know that I'm working at a very low level here, but in addition to
> > > Roger's advice before about how to get R to cooperate, I would be
> > > grateful for any advice such as you've provided about what exactly R is
> > > good for in my task and what a GIS is good for.  Your note advances me
> > > down the field quite a bit, but if there's more, I'd be interested to
> > > know it.
> > > 
> > > Many thanks,
> > > 
> > >  -tom
> > > 
> > > 
> > > 
> > > > 
> > > > My tip is: organize data with spreadsheet and GIS softwares, import (as
> > > > shapefile, if possible) in R and make your statistical analysis and
> > > > statistical columns of data, export to another shapefile and manipulate the
> > > > final map in GIS softwares.
> > > > 
> > > > I repeat, it's possible make all these steps in R, and generate great maps,
> > > > but the most simple way is above. Personally, I use R to make the final maps
> > > > only when I have to produce a long series of simple maps.
> > > > 
> > > > I think the best way is the integration of GIS software with R, each one
> > > > with his specialty.
> > > > 
> > > > 
> > > > King regards,
> > > > 
> > > > Raphael Saldanha
> > > > BRAZIL
> > > > saldanha.plangeo at gmail.com
> > > > 
> > > > 	[[alternative HTML version deleted]]
> > > > 
> > > > _______________________________________________
> > > > R-sig-Geo mailing list
> > > > R-sig-Geo at stat.math.ethz.ch
> > > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > > 
> > > 
> > > 
> > -- 
> > Dan Putler
> > Sauder School of Business
> > University of British Columbia
> > 
> 
> 
> -- 
>  --------------------------------------------------------
>  Check out "Ten Things You Don't Know About Rhode Island"
>      http://whatcheer.net      http://sgouros.com
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From tech_dev at wildintellect.com  Mon Nov 16 05:29:09 2009
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Sun, 15 Nov 2009 20:29:09 -0800
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <25494.1258345106@as220.org>
References: <7124.1258301991@as220.org>	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>	<9643.1258329942@as220.org>	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>	<19904_1258342273_1258342273_22498.1258342202@as220.org>	<1258342818.6809.58.camel@whitebox>
	<25494.1258345106@as220.org>
Message-ID: <4B00D515.8020406@wildintellect.com>

tom sgouros wrote:
> Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> 
>> Tom,
>>
>> Er, what exactly is your data? Do you have data that is linked to zip
>> codes and you want to do a "thematic" (choropleth) map of the data? Do
>> you have point data (say a lat/lon values), and want to plot the points?
>> Given what you've said, hard to figure out how to get you going in the
>> right direction.
> 
> The data is mostly from past elections, so it's vote totals or
> demographic data within some district.
> 
> Google tells me that choropleth is the name of precisely the kind of
> thing I'm trying to make, thank you for expanding my vocabulary today.
> 
> Is there a name for the bar graph kind of thing?  (Here's an example:
> http://www.turbosquid.com/FullPreview/Index.cfm/ID/346428 )
> 
> Thank you,
> 
>  -tom
> 

It sounds like what you need is a base map of districts from whatever
governmental agency has jurisdiction(Fed, State or County). It will
likely come as a shapefile or other similar format as polygons. You will
then Join your election data to this spatial data set based on some sort
of shared ID key that exists in both.

This could be done easily in either QGIS or R. I would leave GRASS out
of the discussion for now if we're just talking about making a map and
bring it back in if you start wanting to analyze the spatial
relationship between your data and other data sets.

FYI, there are both R and GRASS plugins for QGIS which I think is a good
tool for getting started with GIS.

Most people would call that link you sent a 3D visualization, there are
lots of ways to do that in GRASS(nviz), R and even Google Earth (fairly
common).

Alex


From dan.putler at sauder.ubc.ca  Mon Nov 16 05:32:05 2009
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Sun, 15 Nov 2009 20:32:05 -0800
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <25908.1258345677@as220.org>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<19904_1258342273_1258342273_22498.1258342202@as220.org>
	<1258342818.6809.58.camel@whitebox> <25494.1258345106@as220.org>
	<25908.1258345677@as220.org>
Message-ID: <1258345925.6809.80.camel@whitebox>

I'd go with the shapefiles, the E00 files are ArcInfo export format
files, and it is very likely you would convert to shapefile sets along
the way.

Dan

On Sun, 2009-11-15 at 23:27 -0500, tom sgouros wrote:
> tom sgouros <tomfool at as220.org> wrote:
> 
> > 
> > Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> 
> > > Er, what exactly is your data? Do you have data that is linked to zip
> > > codes and you want to do a "thematic" (choropleth) map of the data? Do
> > > you have point data (say a lat/lon values), and want to plot the points?
> > > Given what you've said, hard to figure out how to get you going in the
> > > right direction.
> > 
> > The data is mostly from past elections, so it's vote totals or
> > demographic data within some district.
> 
> I should have also said that I have both SHP files and E00 files to
> describe the boundaries of the districts, but have no feeling about
> which I should prefer or why and I wonder if anyone else does.  The SHP
> files come with an XML description that seems not to be used by grass.
> The E00 files maybe come with a description of their own projection,
> while I had to identify a projection to specify it to grass, but
> otherwise I don't know why one would be better or worse.
> 
> Thanks,
> 
>  -tom
> 
> 
> > 
> > Google tells me that choropleth is the name of precisely the kind of
> > thing I'm trying to make, thank you for expanding my vocabulary today.
> > 
> > Is there a name for the bar graph kind of thing?  (Here's an example:
> > http://www.turbosquid.com/FullPreview/Index.cfm/ID/346428 )
> > 
> > Thank you,
> > 
> >  -tom
> > 
> > > 
> > > On Sun, 2009-11-15 at 22:30 -0500, tom sgouros wrote:
> > > > Raphael Saldanha <saldanha.plangeo at gmail.com> wrote:
> > > > 
> > > > > Hi Tom!
> > > > > 
> > > > > I'm a geographer and R enthusiast too, but what I can say is: R is a great
> > > > > software to statistics. The final production of maps, although it's
> > > > > possible, it's simple and faster made with GIS softwares, like GRASS,
> > > > > Quantum GIS or ArcGIS.
> > > > 
> > > > This is exactly my quandary.  I have some data I want to map, and I have
> > > > no idea how to do it and none of the introductions I've found speak to
> > > > what I thought was a pretty simple task.
> > > > 
> > > > I first thought maybe I should use a GIS, since it's geographic data,
> > > > but all the GIS documentation I can find is about how to analyze data
> > > > that's already available.  There are no end of Grass examples using this
> > > > North Carolina dataset that comes with the installation, but I don't
> > > > live in North Carolina and I don't want to analyze their data.  I want
> > > > to analyze mine, but I can't figure out how to get it in, and that's
> > > > what I'm using R for.
> > > > 
> > > > If you are telling me there is a simpler way to do this, I am all ears
> > > > (eyes), especially if it uses grass or qgis which I can afford, and not
> > > > Arc, which I can't.
> > > > 
> > > > Queries of GIS guys told me that what I need to do is to get my data
> > > > into a shape file first and then a GIS can help me display it, so I
> > > > turned to R for that.  Was I wrong there, too?
> > > > 
> > > > Most of the data I want to map is not currently in any format at all.
> > > > It's just numbers I have.  I have shape files for the geography and I
> > > > want to apply my numbers to those shapes and draw maps in color, and I
> > > > also would very much like to draw the 3d kind where the geographic area
> > > > is raised up according to some value.  (I don't know if there's a name
> > > > for this.)  I tried to use a spreadsheet to get my data attached to the
> > > > shapes, but as soon as I realized I needed to do a join of my data and
> > > > the shape file data I began to look for alternatives.
> > > > 
> > > > I know that I'm working at a very low level here, but in addition to
> > > > Roger's advice before about how to get R to cooperate, I would be
> > > > grateful for any advice such as you've provided about what exactly R is
> > > > good for in my task and what a GIS is good for.  Your note advances me
> > > > down the field quite a bit, but if there's more, I'd be interested to
> > > > know it.
> > > > 
> > > > Many thanks,
> > > > 
> > > >  -tom
> > > > 
> > > > 
> > > > 
> > > > > 
> > > > > My tip is: organize data with spreadsheet and GIS softwares, import (as
> > > > > shapefile, if possible) in R and make your statistical analysis and
> > > > > statistical columns of data, export to another shapefile and manipulate the
> > > > > final map in GIS softwares.
> > > > > 
> > > > > I repeat, it's possible make all these steps in R, and generate great maps,
> > > > > but the most simple way is above. Personally, I use R to make the final maps
> > > > > only when I have to produce a long series of simple maps.
> > > > > 
> > > > > I think the best way is the integration of GIS software with R, each one
> > > > > with his specialty.
> > > > > 
> > > > > 
> > > > > King regards,
> > > > > 
> > > > > Raphael Saldanha
> > > > > BRAZIL
> > > > > saldanha.plangeo at gmail.com
> > > > > 
> > > > > 	[[alternative HTML version deleted]]
> > > > > 
> > > > > _______________________________________________
> > > > > R-sig-Geo mailing list
> > > > > R-sig-Geo at stat.math.ethz.ch
> > > > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > > > > 
> > > > 
> > > > 
> > > -- 
> > > Dan Putler
> > > Sauder School of Business
> > > University of British Columbia
> > > 
> > 
> > 
> > -- 
> >  --------------------------------------------------------
> >  Check out "Ten Things You Don't Know About Rhode Island"
> >      http://whatcheer.net      http://sgouros.com
> > 
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > 
> 
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia


From tech_dev at wildintellect.com  Mon Nov 16 05:34:26 2009
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Sun, 15 Nov 2009 20:34:26 -0800
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <25908.1258345677@as220.org>
References: <7124.1258301991@as220.org>	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>	<9643.1258329942@as220.org>	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>	<19904_1258342273_1258342273_22498.1258342202@as220.org>	<1258342818.6809.58.camel@whitebox>
	<25494.1258345106@as220.org> <25908.1258345677@as220.org>
Message-ID: <4B00D652.1070001@wildintellect.com>

tom sgouros wrote:
> tom sgouros <tomfool at as220.org> wrote:
> 
>> Dan Putler <dan.putler at sauder.ubc.ca> wrote:
> 
>>> Er, what exactly is your data? Do you have data that is linked to zip
>>> codes and you want to do a "thematic" (choropleth) map of the data? Do
>>> you have point data (say a lat/lon values), and want to plot the points?
>>> Given what you've said, hard to figure out how to get you going in the
>>> right direction.
>> The data is mostly from past elections, so it's vote totals or
>> demographic data within some district.
> 
> I should have also said that I have both SHP files and E00 files to
> describe the boundaries of the districts, but have no feeling about
> which I should prefer or why and I wonder if anyone else does.  The SHP
> files come with an XML description that seems not to be used by grass.
> The E00 files maybe come with a description of their own projection,
> while I had to identify a projection to specify it to grass, but
> otherwise I don't know why one would be better or worse.
> 
> Thanks,
> 
>  -tom

For your purposes the shp will be easier to work with, the E00 file
contains the same information and something called Topology which is
irrelevant to this particular use. The XML file is metadata, none of the
software involved here directly uses it, the projection information is
stored in the .prj file for shapefiles.
SHP is more widely recognized by software and in most cases E00 just
gets converted to it at some point anyways.

Alex


From tech_dev at wildintellect.com  Mon Nov 16 07:55:59 2009
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Sun, 15 Nov 2009 22:55:59 -0800
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <28786.1258348148@as220.org>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<19904_1258342273_1258342273_22498.1258342202@as220.org>
	<1258342818.6809.58.camel@whitebox> <25494.1258345106@as220.org>
	<4B00D515.8020406@wildintellect.com> <28786.1258348148@as220.org>
Message-ID: <4B00F77F.6050608@wildintellect.com>

tom sgouros wrote:
> Alex Mandel <tech_dev at wildintellect.com> wrote:
> 
>> This could be done easily in either QGIS or R. I would leave GRASS out
>> of the discussion for now if we're just talking about making a map and
>> bring it back in if you start wanting to analyze the spatial
>> relationship between your data and other data sets.
> 
> That isn't too far in the future, and is partly why I thought it worth
> taking this task on via a GIS, as a first step.
> 
>> FYI, there are both R and GRASS plugins for QGIS which I think is a good
>> tool for getting started with GIS.
> 
> Let me thank you and ask a still dumber question, if you're willing to
> entertain it.  I've seen exactly this sentence all over the place, but I
> just don't get it.  What is the sense behind having a GRASS (GIS) plugin
> for QGIS (another GIS)?  What do you get?
> 
> And is this related to the fact that GRASS seems to have about seventeen
> different user interfaces?  There's a command line, and dialogs to build
> commands, and a GUI that all come up when I invoke GRASS.
> 
>> Most people would call that link you sent a 3D visualization, there are
>> lots of ways to do that in GRASS(nviz), R and even Google Earth (fairly
>> common).
> 
> Thank you,
> 
>  -tom
> 

You've basically got the answer. QGIS is just way easier to use, and
using GRASS thru QGIS makes it easier to learn GRASS. Personally I was
stumped on how to use GRASS before I learned it through QGIS. I'm now
comfortable using both and I still do my map composition in QGIS(Better
GUI for map making) and processing (depending on need) in GRASS with
stats in R or batch map output.

It's good to realize unlike Arc which is a behemoth of everything(or
tries to be), QGIS/GRASS/R is a combo of applications that work together
to give you a more powerful toolbox. The end result is that each is
better at some features than the others and you should use what's
best(including easiest for you) where appropriate.

As side note QGIS - GRASS feature overlap is very small, that's a large
part of why they work together.

Alex


From karl at huftis.org  Mon Nov 16 10:08:32 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 16 Nov 2009 10:08:32 +0100
Subject: [R-sig-Geo] newbie questions
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
Message-ID: <MPG.256b34f9144fd68a9896a4@news.gmane.org>

On Sun, 15 Nov 2009 19:52:48 +0100 (CET) Roger Bivand 
<Roger.Bivand at nhh.no> wrote:
> Do use readShapeSpatial() (or better readOGR() in rgdal)

Why (or how) is readOGR better?

-- 
Karl Ove Hufthammer


From p.hiemstra at geo.uu.nl  Mon Nov 16 11:41:58 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Nov 2009 11:41:58 +0100
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
References: <7124.1258301991@as220.org>	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
Message-ID: <4B012C76.5080202@geo.uu.nl>

Raphael Saldanha wrote:
> Hi Tom!
>
> I'm a geographer and R enthusiast too, but what I can say is: R is a great
> software to statistics. The final production of maps, although it's
> possible, it's simple and faster made with GIS softwares, like GRASS,
> Quantum GIS or ArcGIS.
>   
Hi,

As you already stated, making the maps in R is quite possible. I make 
all my geographic illustrations for my publications in R. The advantage 
that I don't have do something first in Excel or ArcGIS and then 
something in R and ending in yet another tool. I like the fact that my 
whole workflow is in one versatile tool, R. So for me learning to make 
maps in R payed off. In addition, you can make awesome maps, especially 
of mulitvariate spatial data, in R. In addition, I use linux (Debian) 
and the desktop GIS tools that I tried (svSig, Qgis, and some more) did 
not provide publication quality maps. ArcMap does, but this is not 
available under Linux. If you use Windows this is not a problem 
ofcourse. See the link below for an animation I made using R (and some 
other linux tools):

http://intamap.geo.uu.nl/~paul/Images/animation_25fps.mpg

All of the above is purely my opinion :).

cheers and good luck,
Paul
> My tip is: organize data with spreadsheet and GIS softwares, import (as
> shapefile, if possible) in R and make your statistical analysis and
> statistical columns of data, export to another shapefile and manipulate the
> final map in GIS softwares.
>
> I repeat, it's possible make all these steps in R, and generate great maps,
> but the most simple way is above. Personally, I use R to make the final maps
> only when I have to produce a long series of simple maps.
>
> I think the best way is the integration of GIS software with R, each one
> with his specialty.
>
>
> King regards,
>
> Raphael Saldanha
> BRAZIL
> saldanha.plangeo at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From hengl at spatial-analyst.net  Mon Nov 16 10:49:59 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Mon, 16 Nov 2009 10:49:59 +0100
Subject: [R-sig-Geo] optimizeNetwork function in intamapInteractive package
	(how to use	auxiliary predictors)
Message-ID: <20091116104959.ift0004dcgs88gc4@spatial-analyst.net>


Dear Edzer, Jon, Stephanie, Olivier et al.,

First, let me congratulate you on your new package intamap /  
intamapInteractive that I feel will significantly advance practice of  
geostatistical mapping. Really a great contribution (I knew about SSA  
already in 2000, but was always lacking an operational tool).

My interest at the moment are the sampling optimization algorithms and  
their use in combination with universal kriging / regression-kriging.  
I had no problems to run spatially simulated annealing with your  
package (OK model), but could not grasp how to do the same thing using  
a universal kriging model (auxiliary predictors). Here is the code:

> library(gstat)
> library(RSAGA)
> library(maptools)
> library(intamapInteractive)

# load data:
> data(meuse)
> coordinates(meuse) <- ~x+y
> data(meuse.grid)
> coordinates(meuse.grid) <- ~x+y
> gridded(meuse.grid) <- TRUE

# estimate variograms (OK/UK):
> vt.fit <- fit.variogram(variogram(log1p(zinc)~1, meuse), vgm(1,  
> "Exp", 300, 1))
> vr.fit <- fit.variogram(variogram(log1p(zinc)~sqrt(dist), meuse),  
> vgm(1, "Exp", 300, 1))

# study area of interest:
> write.asciigrid(meuse.grid["mask"], "meuse_mask.asc")
> rsaga.esri.to.sgrd(in.grids="meuse_mask.asc",  
> out.sgrd="meuse_mask.sgrd", in.path=getwd())
# raster to polygon conversion;
> rsaga.geoprocessor(lib="shapes_grid", module=6,  
> param=list(GRID="meuse_mask.sgrd", SHAPES="meuse_mask.shp",  
> CLASS_ALL=1))
> mask <- readShapePoly("meuse_mask.shp",  
> proj4string=CRS(as.character(NA)), force_ring=T)

# prepare observations / predGrid objects:
> observations <- meuse["zinc"]
> attr(observations at coords, "dimnames")[[2]] <- c("x", "y")
> predGrid <- data.frame(meuse.grid["dist"])
> predGrid$dist <- NULL  # predGrid has to be "SpatialPoints" type?
> coordinates(predGrid) <- ~x+y
windows()
# add 20 more points assuming OK model (SSA method):
> optim.ok <- optimizeNetwork(observations, predGrid, candidates=mask,  
> method="ssa", action="add", nDiff=20, model=vt.fit,  
> criterion="MUKV", plot=FALSE, nr_iterations=50, nmax=40)

This works fine. But how do I now optimize samples using universal  
kriging model (with auxiliary predictors e.g. "dist")? I simply could  
not figure out from your examples. I also tried looking at the Package  
source R functions, but could not get it running.

It should be something like this:

> observations <- pts.ov[c("zinc", "dist")]
> predGrid <- data.frame(meuse.grid["dist"])
> coordinates(predGrid) <- ~x+y
> optim.rk <- optimizeNetwork(observations, predGrid, candidates=mask,  
> method="ssa", action="add", nDiff=20, model=vr.fit,  
> criterion="MUKV", plot=FALSE, nr_iterations=50,  
> formula=log1p(zinc)~sqrt(dist), nmax=40)


thanks!

Tom Hengl
http://home.medewerker.uva.nl/t.hengl/


From marcelino.delacruz at upm.es  Mon Nov 16 11:39:28 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Mon, 16 Nov 2009 11:39:28 +0100
Subject: [R-sig-Geo] Multitype point pattern analysis
In-Reply-To: <D45C8CF4C5CB2A41956F98C65F093A3A533130880E@funguti.ecofog.
 gf>
References: <D45C8CF4C5CB2A41956F98C65F093A3A533130880E@funguti.ecofog.gf>
Message-ID: <200911161039.nAGAdO50006265@edison.ccupm.upm.es>

Maybe solutionset can help you. Try the followin example:

data(lansing)
lansing.spl <- split(lansing)
  blackoak <- with (lansing.spl, density.ppp(blackoak))
  hickory <- with (lansing.spl, density.ppp(hickory))
maple <- with (lansing.spl, density.ppp(maple))

# where density of maple is > 500 and density of hickory is > 500?
plot(solutionset(maple>500 & hickory>500))

# Three types case: where density of maple is > 500 and density of 
hickory is > 500 and density of blackoak > 100?
  plot(solutionset(maple>500 & hickory>500 & blackoak>100))

HTH

Marcelino




At 13:57 15/11/2009, Ervan Rutishauser wrote:
>Hi folk,
>
>I am working on tropical forest dynamic trying to find out "patches" 
>of young, adult or suppressed trees. Each tree has XY coordinates 
>and I consider my data as a multitype point pattern (ppt), handling 
>data with spatstat. Actually I consider each mark separately and 
>delineate areas of aggregation (contour(density(ppt)). Then, I 
>superimpose these high-density areas on the same map and look at 
>non-overlapping regions. This is not very satisfying and I would 
>like to go a step further in interpreting areas of e.g. low density 
>of adult trees and high density of suppressed trees. I could not 
>find any reference in the literature dealing with more than 2 types...
>
>Did anyone already deal with similar problem?? Any suggestion will 
>be greatly helpful.
>
>Thanks. Best,
>Ervan
>___________________________________________________________
>
>Ervan Rutishauser
>PhD student
>CIRAD - UMR AMAP
>BP 701
>97387 Kourou Cedex
>tel. 00594.594.32.92.96
>
>
>
>         [[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


***************************************
Marcelino de la Cruz Rot
Depto. Biologia Vegetal
EUIT Agricola
Universidad Politecnica de Madrid
28040-Madrid
SPAIN


From julian at hafro.is  Mon Nov 16 13:38:35 2009
From: julian at hafro.is (Julian Burgos)
Date: Mon, 16 Nov 2009 12:38:35 +0000
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <4B012C76.5080202@geo.uu.nl>
References: <7124.1258301991@as220.org>	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>	<9643.1258329942@as220.org>	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<4B012C76.5080202@geo.uu.nl>
Message-ID: <4B0147CB.5010602@hafro.is>

Hello all,
An alternative to create (possibly simple) shapefiles is the 
"shapefiles" package.

http://cran.r-project.org/web/packages/shapefiles/index.html.

Also the "PBSmapping" package is a very good alternative to make maps 
within R, and to perform basic GIS operations (i.e. overlap of polygons, 
identification of locations within polygons, etc.).

http://cran.r-project.org/web/packages/PBSmapping/index.html

Nevertheless, I do think that is worth while to take a bit of time and 
learn to use the classes and methods for spatial data in the "sp" 
package.  The Bivand et al. book (Applied Spatial Data Analysis with R) 
is a great place to start.
All the best,

Julian

-- 
Julian Mariano Burgos
Hafranns?knastofnunin/Marine Research Institute
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian at hafro.is, jmburgos at u.washington.edu	





Paul Hiemstra wrote:
> Raphael Saldanha wrote:
>> Hi Tom!
>>
>> I'm a geographer and R enthusiast too, but what I can say is: R is a 
>> great
>> software to statistics. The final production of maps, although it's
>> possible, it's simple and faster made with GIS softwares, like GRASS,
>> Quantum GIS or ArcGIS.
>>   
> Hi,
>
> As you already stated, making the maps in R is quite possible. I make 
> all my geographic illustrations for my publications in R. The 
> advantage that I don't have do something first in Excel or ArcGIS and 
> then something in R and ending in yet another tool. I like the fact 
> that my whole workflow is in one versatile tool, R. So for me learning 
> to make maps in R payed off. In addition, you can make awesome maps, 
> especially of mulitvariate spatial data, in R. In addition, I use 
> linux (Debian) and the desktop GIS tools that I tried (svSig, Qgis, 
> and some more) did not provide publication quality maps. ArcMap does, 
> but this is not available under Linux. If you use Windows this is not 
> a problem ofcourse. See the link below for an animation I made using R 
> (and some other linux tools):
>
> http://intamap.geo.uu.nl/~paul/Images/animation_25fps.mpg
>
> All of the above is purely my opinion :).
>
> cheers and good luck,
> Paul
>> My tip is: organize data with spreadsheet and GIS softwares, import (as
>> shapefile, if possible) in R and make your statistical analysis and
>> statistical columns of data, export to another shapefile and 
>> manipulate the
>> final map in GIS softwares.
>>
>> I repeat, it's possible make all these steps in R, and generate great 
>> maps,
>> but the most simple way is above. Personally, I use R to make the 
>> final maps
>> only when I have to produce a long series of simple maps.
>>
>> I think the best way is the integration of GIS software with R, each one
>> with his specialty.
>>
>>
>> King regards,
>>
>> Raphael Saldanha
>> BRAZIL
>> saldanha.plangeo at gmail.com
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>   
>
>


From carson.farmer at gmail.com  Mon Nov 16 14:53:03 2009
From: carson.farmer at gmail.com (Carson Farmer)
Date: Mon, 16 Nov 2009 13:53:03 +0000
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <4B012C76.5080202@geo.uu.nl>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
	<c85849370911151703y3724e2a2r14e13dd90ab5898b@mail.gmail.com>
	<4B012C76.5080202@geo.uu.nl>
Message-ID: <94b3c8440911160553y752dda38tec280f2af72ecb11@mail.gmail.com>

>... In addition, I use linux (Debian) and the desktop GIS tools that
> I tried (svSig, Qgis, and some more) did not provide publication quality
> maps.

I would strongly suggest you take another look at some of these
packages (especially QGIS).
These are relatively young projects, and are growing (changing)
quickly. For example, just
recently, some very advanced symbology enhancements have been made to
the QGIS project,
and will likely be available in the next release (due out next month).
Though of course, for graphs
and other statistical outputs, nothing beats R!

Carson

-- 
Carson J. Q. Farmer
National Centre for Geocomputation
John Hume Building,
National University of Ireland, Maynooth,
Maynooth, Co. Kildare, Ireland.
http://www.carsonfarmer.com


From Roger.Bivand at nhh.no  Mon Nov 16 15:01:55 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 16 Nov 2009 15:01:55 +0100 (CET)
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <MPG.256b34f9144fd68a9896a4@news.gmane.org>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<MPG.256b34f9144fd68a9896a4@news.gmane.org>
Message-ID: <alpine.LRH.2.00.0911161448270.15095@reclus.nhh.no>

On Mon, 16 Nov 2009, Karl Ove Hufthammer wrote:

> On Sun, 15 Nov 2009 19:52:48 +0100 (CET) Roger Bivand
> <Roger.Bivand at nhh.no> wrote:
>> Do use readShapeSpatial() (or better readOGR() in rgdal)
>
> Why (or how) is readOGR better?

Because it uses OGR, with an updated rather than frozen shapelib, and 
reads the *.prj file of the shapefile bundle as well, which 
readShapeSpatial() does not. On the other hand, readShapeSpatial() has 
various extra arguments to tackle out-of-spec shapefile bundles.

With reference to other alternatives, the shapefiles package has not been 
updated for three years, and importShapefile() in PBSmapping is built 
around read.shape() from maptools to read into the classes used in that 
package.

Roger

>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Mon Nov 16 15:17:59 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 16 Nov 2009 15:17:59 +0100 (CET)
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <9643.1258329942@as220.org>
References: <7124.1258301991@as220.org>
	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>
	<9643.1258329942@as220.org>
Message-ID: <alpine.LRH.2.00.0911161502160.15095@reclus.nhh.no>

On Sun, 15 Nov 2009, tom sgouros wrote:

>
>
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>>> I'm trying to make some simple maps of election results and I am having
>>> some trouble.  I'm hoping to use Grass (or QGis) to make the maps, but
>>> apparently this requires getting my data into the shape files, and I
>>> can't figure out how to do that.  I've found read.shape and that's
>>
>> Please do not use read.shape(), it is deprecated, and will become
>> unavailable at the user-visible level at the next maptools release.
>
> Where is the introduction that explains all this?  Is there one
> somewhere?   (And thank you for the assistance.)
>
>> Do use readShapeSpatial() (or better readOGR() in rgdal) to create a
>> SpatialPolygonsDataFrame, paying attention to the ID= argument. Then
>> use spCbind() and if necessary spChFIDs() to ensure that your data are
>> being associated with the correct Polygons object inside the
>> SpatialPolygonsDataFrame. Then use writeSpatialShape() (or writeOGR())
>> to write the shapefile.
>
> Thank you very much for all that, it gives me a lot to try.

OK. Once you've tried this - there are at least two pitfalls, one that the 
shapes (features) occur multiple times for each district that you have 
data for (districcts with multiple islands or parts), the other that the 
polygons/features do not match the data by ID for other reasons. This is 
never simple, never automatic, and rarely obvious.

In GIScience one uses the term "ontology" for different people's views of 
the world, in particular the data and data objects that they use. If you 
are combining boundaries (for a given date) from one source with its 
implicit "view of the world", and election data of different provenance, 
with a different "view of the world", say different IDs for the same 
units, you will always need to spend time working out how to match the 
data to the boundaries. The tools are there, but it isn't going to get 
automatic, and you'll have the same problems matching in a database or a 
GIS. The only exceptions are the trite ones, where the same organisation 
with the same view of the world is the source of the boundaries, the IDs, 
and the data to be assigned.

>
>>> great, and I thought that by editing the resulting att.data data frame I
>>> could do what I need.  Unfortunatly, if I use merge to combine my data
>>> with the existing data, the data frame comes out sorted by the join
>>> column and the output dbf file (done with write.dbf) doesn't work
>>> properly with the shapefile because it's no longer sorted the same as
>>> the outlines.
>>
>> Using merge() without reading the help file usually has this outcome -
>> there are arguments controlling sorting.
>
> Thank you for the help, but no thank you for the snide.  What the help
> file says (on my system) is that if you do sort=FALSE, the output order
> is unspecified, which is approximately zero help for someone trying to
> figure out why the output map looks so funny.
>

With merge(), you always have to try things out until they come right. 
Perhaps reshape() is harder to use, but not by much. Both are powerful, 
but without experimenting, tough.

>> PS. Did you read the Spatial task view on CRAN, or, say, the page on
>> the R wiki entitled "Getting spatial data into and out of R":
>>
>> http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:import_export
>>
>
> Yes.  I can't say I found those pages very helpful since they are mostly
> written in a language I don't understand, and where I do understand what
> they're saying, they're saying things like this:
>
> "Use a GIS if you're trying to do the following:
>
>    - specialized GIS tasks"
>
> In the nicest and most constructive way I can think of, I have to say
> that this isn't very helpful to the person who has data they want to map
> and wants to get on with it.  I have been a R user (and fan) for years
> and am more or less familiar with much of it, but I haven't used it for
> spatial data, and I find the available documentation for people who are
> starting from zero like me is fairly wanting.
>

OK, so perhaps improve the wiki?

Including a code snippet demonstrating your problem and posting a link to 
a simple data set (shape file plus election data) would be a more 
constructive way to proceed, no? The code in Ch 5 in our book on 
www.asdar.org covers a very similar case, and uses the functions and 
methods I suggested. Without your code, it is hard to be more specific 
than pointing you to the tools you need.

Roger

> Many thanks,
>
> -tom
>
>
>>
>>>
>>> I tried preserving the original order of the data frame and re-sorting
>>> the data frame before writing it out, and that worked, but the resulting
>>> dbf file causes a seg fault in Grass when I try to read it with the rest
> b> > of the shape data.  Plus it seems a ridiculous amount of work for what
>>> must be a fairly routine operation.
>>>
>>> So here's my question: I have some data I want to add to a shape file
>>> (the SHP, DBF, etc).  Can I use R maptools to do that easily, and if so,
>>> how?
>>>
>>> Many thanks in advance for the help,
>>>
>>> -tom
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Mon Nov 16 15:37:14 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 16 Nov 2009 15:37:14 +0100
Subject: [R-sig-Geo] newbie questions
In-Reply-To: <alpine.LRH.2.00.0911161502160.15095@reclus.nhh.no>
References: <7124.1258301991@as220.org>	<alpine.LRH.2.00.0911151940270.11027@reclus.nhh.no>	<9643.1258329942@as220.org>
	<alpine.LRH.2.00.0911161502160.15095@reclus.nhh.no>
Message-ID: <4B01639A.6020508@uni-muenster.de>



Roger Bivand wrote:
...
> Including a code snippet demonstrating your problem and posting a link
> to a simple data set (shape file plus election data) would be a more
> constructive way to proceed, no? The code in Ch 5 in our book on
> www.asdar.org covers a very similar case, 
...

The book link Roger meant is: http://www.asdar-book.org

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/


From ashton at msu.edu  Mon Nov 16 16:20:28 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Mon, 16 Nov 2009 10:20:28 -0500
Subject: [R-sig-Geo] newbie questions - maps
In-Reply-To: <94b3c8440911160553y752dda38tec280f2af72ecb11@mail.gmail.com>
References: <7124.1258301991@as220.org> <4B012C76.5080202@geo.uu.nl>
	<94b3c8440911160553y752dda38tec280f2af72ecb11@mail.gmail.com>
Message-ID: <200911161020.28678.ashton@msu.edu>

On Monday 16 November 2009 08:53:03 Carson Farmer wrote:
> >... In addition, I use linux (Debian) and the desktop GIS tools that
> > I tried (svSig, Qgis, and some more) did not provide publication quality
> > maps.
> 
> I would strongly suggest you take another look at some of these
> packages (especially QGIS).
> These are relatively young projects, and are growing (changing)
> quickly. For example, just
> recently, some very advanced symbology enhancements have been made to
> the QGIS project,
> and will likely be available in the next release (due out next month).
> Though of course, for graphs
> and other statistical outputs, nothing beats R!
> 
> Carson
> 

Let me strongly second Carson's points. As a Debian user, I like QGIS and use 
it for my own visualization purposes. Being able to drag and drop a shapefile 
is pretty awesome. I suspect QGIS will continue to improve in its ability to 
render maps. That said, I don't think publication-quality output is what these 
software are about, at least not yet. R on the other hand gives you tremendous 
control. I used it exclusively for all maps, as well as other graphics, in my 
latest article.

The same goes for non-free GIS software, by the way. My cartographer 
colleagues who use ArcGIS generally haul mapping output from there into other 
packages for font and other effect rendering.

Yours,

Ashton

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From hzambran.newsgroups at gmail.com  Mon Nov 16 17:08:25 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Mon, 16 Nov 2009 17:08:25 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
Message-ID: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>

Dear List,

During some OK interpolations of daily precipitation, with the
'automap' library, I got the following error:


[using ordinary kriging]
"chfactor.c", line 130: singular matrix in function LDLfactor()
Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
  LDLfactor


The code I'm using works fine for other days, so I assume that the
distance between the measurement points is no the problem. When
looking at the data that rose the error, I realized that all the
measured values were equal to zero (I can not skip those days in which
all the measured points have the same value in advance, because the
measured value in those points change with time).

According to a traceback that is given below, it seems that the cause
is in the 'predict.gstat' function of the 'gstat' package.

The same error can be risen with:

# Data preparation
data(meuse)
coordinates(meuse) =~ x+y
data(meuse.grid)
gridded(meuse.grid) =~ x+y

meuse$zinc <- meuse$zinc*0
meuse$zinc

# Ordinary kriging, no new_data object
kriging_result = autoKrige(zinc~1, meuse)


traceback()
6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
as.double(as.vector(raw$locations)),
       as.vector(new.X), as.integer(block.cols), as.vector(block),
       as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
       indicators = indicators, na.action = na.action, debug.level =
debug.level)
4: .local(formula, locations, ...)
3: krige(formula, input_data, new_data, variogram_object$var_model,
       block = block, ...)
2: krige(formula, input_data, new_data, variogram_object$var_model,
       block = block, ...)
1: autoKrige(zinc ~ 1, meuse)


I would really appreciate any hint about the possible reason of this
error and if it could be overcome in some way.


Thanks in advance for any help.


Mauricio
-- 
?============================================
Ph.D. Candidate,
University of Trento
Dept. of Civil and Env. Engineering
Trento / Italy
=============================================
Linux user #454569 -- Ubuntu user #17469
=============================================
"Planning is bringing the future into the present
so that you can do something about it now"
(Alan Lakein)


From edzer.pebesma at uni-muenster.de  Mon Nov 16 17:14:49 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 16 Nov 2009 17:14:49 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
Message-ID: <4B017A79.10206@uni-muenster.de>

My guess is that from constant data, the (co)variance is constant and
zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
errors).

Is this a case that autokrige should catch?
--
Edzer

Mauricio Zambrano wrote:
> Dear List,
>
> During some OK interpolations of daily precipitation, with the
> 'automap' library, I got the following error:
>
>
> [using ordinary kriging]
> "chfactor.c", line 130: singular matrix in function LDLfactor()
> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>   LDLfactor
>
>
> The code I'm using works fine for other days, so I assume that the
> distance between the measurement points is no the problem. When
> looking at the data that rose the error, I realized that all the
> measured values were equal to zero (I can not skip those days in which
> all the measured points have the same value in advance, because the
> measured value in those points change with time).
>
> According to a traceback that is given below, it seems that the cause
> is in the 'predict.gstat' function of the 'gstat' package.
>
> The same error can be risen with:
>
> # Data preparation
> data(meuse)
> coordinates(meuse) =~ x+y
> data(meuse.grid)
> gridded(meuse.grid) =~ x+y
>
> meuse$zinc <- meuse$zinc*0
> meuse$zinc
>
> # Ordinary kriging, no new_data object
> kriging_result = autoKrige(zinc~1, meuse)
>
>
> traceback()
> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
> as.double(as.vector(raw$locations)),
>        as.vector(new.X), as.integer(block.cols), as.vector(block),
>        as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>        indicators = indicators, na.action = na.action, debug.level =
> debug.level)
> 4: .local(formula, locations, ...)
> 3: krige(formula, input_data, new_data, variogram_object$var_model,
>        block = block, ...)
> 2: krige(formula, input_data, new_data, variogram_object$var_model,
>        block = block, ...)
> 1: autoKrige(zinc ~ 1, meuse)
>
>
> I would really appreciate any hint about the possible reason of this
> error and if it could be overcome in some way.
>
>
> Thanks in advance for any help.
>
>
> Mauricio
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From p.hiemstra at geo.uu.nl  Mon Nov 16 16:26:12 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 16 Nov 2009 16:26:12 +0100
Subject: [R-sig-Geo] newbie questions - maps
In-Reply-To: <200911161020.28678.ashton@msu.edu>
References: <7124.1258301991@as220.org> <4B012C76.5080202@geo.uu.nl>
	<94b3c8440911160553y752dda38tec280f2af72ecb11@mail.gmail.com>
	<200911161020.28678.ashton@msu.edu>
Message-ID: <4B016F14.70304@geo.uu.nl>

Ashton Shortridge wrote:
> On Monday 16 November 2009 08:53:03 Carson Farmer wrote:
>   
>>> ... In addition, I use linux (Debian) and the desktop GIS tools that
>>> I tried (svSig, Qgis, and some more) did not provide publication quality
>>> maps.
>>>       
>> I would strongly suggest you take another look at some of these
>> packages (especially QGIS).
>> These are relatively young projects, and are growing (changing)
>> quickly. For example, just
>> recently, some very advanced symbology enhancements have been made to
>> the QGIS project,
>> and will likely be available in the next release (due out next month).
>> Though of course, for graphs
>> and other statistical outputs, nothing beats R!
>>
>> Carson
>>     
Let me stress that I like qgis very much. Only at the time I tried to 
make pub. quality maps with qgis (using version 0.9-2) it could not 
export these kind pub. quality maps. Maybe now, or in the close future, 
qgis or other open source tools will support pub. quality maps. I would 
like that, being able to just take the north arrow and drag and drop it 
would be much better than specifying the spatial coordinates. So for me 
R was the best solution at the time (the only btw), but qgis might be a 
better alternative in the future. But not yet (please correct me if I'm 
wrong).

cheers,
Paul
>>     
>
> Let me strongly second Carson's points. As a Debian user, I like QGIS and use 
> it for my own visualization purposes. Being able to drag and drop a shapefile 
> is pretty awesome. I suspect QGIS will continue to improve in its ability to 
> render maps. That said, I don't think publication-quality output is what these 
> software are about, at least not yet. R on the other hand gives you tremendous 
> control. I used it exclusively for all maps, as well as other graphics, in my 
> latest article.
>
> The same goes for non-free GIS software, by the way. My cartographer 
> colleagues who use ArcGIS generally haul mapping output from there into other 
> packages for font and other effect rendering.
>
> Yours,
>
> Ashton
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From Roger.Bivand at nhh.no  Mon Nov 16 19:57:53 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 16 Nov 2009 19:57:53 +0100 (CET)
Subject: [R-sig-Geo] spdep neighbor generation and subsequent regression
 analysis
In-Reply-To: <4B0054EF.6070907@hunter.cuny.edu>
References: <a413fd8c0909131205l27d22b23i6741f894ef7222f0@mail.gmail.com>
	<4B0054EF.6070907@hunter.cuny.edu>
Message-ID: <alpine.LRH.2.00.0911161935590.17149@reclus.nhh.no>

On Sun, 15 Nov 2009, Jochen Albrecht wrote:

> Hello:
> On first sight, this is about read.gal[2,3] and read.gwt2nb, but in the long 
> run, it is about strategies for working with very large datasets.
> Here is the background. With Robert Hijmans' support, we generated a 
> comprehensive database of world-wide green house gas emissions (GHGs) and a 
> wide range of explanatory variables. The point file now contains (depending 
> on source) between 1.4 and 2.1 million locations, all on a 0.1 degree grid. 
> We would like to run a bunch of spatial regression models on this very large 
> dataset. In the end, we would like to determine which (set of) variable(s) 
> have what kind of effect on GHGs in what part of the world. The variables are 
> physical, economic, demographic, and geographic (e.g. distance from ocean) in 
> nature.

If this is like machine learning, why not use such techniques? Do you have 
a realistic spatial process model? I think that very many of the input 
variables are interpolated too, so probably spatial dependence at any 
scale will be induced by the changes in support prior to analysis. The 
results of such analysis would (or should) have large standard errors, so 
perhaps would not take you where you want to go. If you cannot handle the 
varying impacts of spatial scales in the data generating processes on both 
left and right hand sides, any observed residual dependence will certainly 
be spurious (red herring).

Could you try a small subsample across a natural experiment (a clear 
difference in treatment)? Then the difficulty of generating a large 
weights object would go away. It would also let you examine the error 
propagation/change of support problem, which would be intractable with 
many "observations", which you need to do if your results are to be taken 
seriously.

If you need to generate neighbours for very large n, please do describe 
the functions used, as there are many ways of doing this:

> This procedure usually starts with creating a spatial weights matrix, which 
> we tried in R but lead to an endless process (we tried it repeatedly on 
> machines with 4 GM RAM and Xeon processors; it did not bail, just kept 
> running at about 50% CPU time using between 300 and 2100 MB of memory for 
> more than a week until we killed the process).

actually tells us nothing, as you haven't said how exactly you were doing 
this - presumably using point support and a distance criterion? Is the 
object a SpatialPixels object? Was the distance criterion sensible (see 
the GeoDa failure reported below - perhaps not)?

> GeoDA ran for about six hours and then produced a file with a good 5 million 
> records, 99% of which contained zero neighbors. This is where the immediate 
> question comes into play. The read.gal function did not like the file 
> produced by GeoDA. There is some GeoDA documentation that suggests that we 
> should use read.gal2 or read.gal3 but these are not part of the spdep 
> distribution, nor could I find them anywhere. As it happens, the file 
> generated had a .gwt extension, so I tried read.get2nb. It seemed to accept 
> the input but then completely killed the whole R process (I kept screen shots 
> just for Roger). My guess is that (a) the matrix was too big, or (b) it was 
> too sparse, or (c) it was a corrupt product of GeoDA in the first place.

Most likely that.

> Which brings me back to the bigger picture and the following questions:
> 1) Is there something inherently wrong with our approach?

See above.

> 2) Can anybody think of alternative ways to create a spatial regression model 
> for the above mentioned questions?

It can be done, but once you have control of the scale and process issues, 
there is nothing to stop you subsampling. If you go with a 1 degree grid, 
you shouldn't have trouble fitting a model (about 15000 on-land cells), 
but it may be largish for applying say Bayesian Model Averaging, which 
might give you a feel for which variables are in play.

> 3) Would it be worthwhile to move onto a Linux machine and recompile all the 
> different packages?

When working with larger data sets, 64-bit Linux or OSX are still 
currently more viable than Windows, I believe.

Hope this helps,

Roger

> Cheers,
>    Jochen
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From groff at temple.edu  Mon Nov 16 21:50:30 2009
From: groff at temple.edu (Elizabeth Groff)
Date: Mon, 16 Nov 2009 15:50:30 -0500
Subject: [R-sig-Geo] Question about confidence intervals for cross k with
	toroidal shifts
Message-ID: <319308FEB0B5F8408C15C6214674CBC1056C00A2@EXC1VS1.temple>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091116/5a242ae9/attachment.pl>

From hans at sociologi.cjb.net  Tue Nov 17 01:02:49 2009
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Tue, 17 Nov 2009 01:02:49 +0100
Subject: [R-sig-Geo] incompatible projections/coordinate-systems?
Message-ID: <4B01E829.2040206@sociologi.cjb.net>

Hi list,

I'm a newcomer to GIS and r-sig-geo. I have exported some shapefiles
from ArcGIS and succeeded in plotting them with R. But one shapefile has
a different coordinate system, I think, and it does not turn up in the
graph when added to the others. In ArcGIS, this layer had an "unknown"
coordinate system, but rendered at the right location in relation to the
other layers.

I have made a tar-archive with the shape-files and a script to import
them into R and generate a map. The problematic shape is "sdn".

http://sociologi.cjb.net/temp/create-map-data.tbz
http://sociologi.cjb.net/temp/create-map.r

Here is the summary output of a "good" shape, "yta", followed by summary
of the problematic shape "sdn".

> summary(yta)

Object of class SpatialPolygonsDataFrame

Coordinates:

       min       max

r1  303850  344600.1

r2 6388900 6415400.0

Is projected: TRUE 

proj4string :

[+proj=utm +zone=33 +ellps=GRS80 +units=m +no_defs]

Data attributes:

      KKOD         SHAPE_AREA          SHAPE_LEN       

 Min.   :1.000   Min.   :7.812e+05   Min.   :    3530  

 1st Qu.:3.000   1st Qu.:1.125e+06   1st Qu.:    5514  

 Median :5.000   Median :3.006e+06   Median :    9121  

 Mean   :4.941   Mean   :1.272e+09   Mean   :  647692  

 3rd Qu.:7.000   3rd Qu.:1.685e+07   3rd Qu.:   37437  

 Max.   :7.000   Max.   :3.119e+10   Max.   :21081735  



> summary(sdn)

Object of class SpatialPolygonsDataFrame

Coordinates:

       min     max

r1 1247825 1288137

r2 6382086 6422038

Is projected: TRUE 

proj4string :

[+proj=tmerc +lat_0=0 +lon_0=15.80827777777778 +k=1 +x_0=1500000 +y_0=0

+ellps=bessel +units=m +no_defs]

Data attributes:

   SW_MEMBER           NAMN       DISTRIKT       REG_DATUM         DATUM   

 Min.   : 1   10 H?gsbo  : 1   Centrum: 4   1996/01/01:21   2001/09/10:21  

 1st Qu.: 6   11 ?lvsborg: 1   Norr   :10                                  

 Median :11   12 Fr?lunda: 1   V?ster : 7                                  

 Mean   :11   13 Askim   : 1                                               

 3rd Qu.:16   14 Tynnered: 1                                               

 Max.   :21   15 Styrs?  : 1                                               

              (Other)    :15                                               

 OPERAT?r    KVALITET      AREA             PERIMETER    

 eoh:21   Min.   :0   Min.   :  3729696   Min.   :10507  

          1st Qu.:0   1st Qu.:  9113274   1st Qu.:15376  

          Median :0   Median : 16307500   Median :21493  

          Mean   :0   Mean   : 34423248   Mean   :26351  

          3rd Qu.:0   3rd Qu.: 34864909   3rd Qu.:32932  

          Max.   :0   Max.   :198632325   Max.   :64221


From mdsumner at gmail.com  Tue Nov 17 02:21:25 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 17 Nov 2009 12:21:25 +1100
Subject: [R-sig-Geo] incompatible projections/coordinate-systems?
In-Reply-To: <4B01E829.2040206@sociologi.cjb.net>
References: <4B01E829.2040206@sociologi.cjb.net>
Message-ID: <522664f80911161721wc6eb767pc304ce44e1549b6c@mail.gmail.com>

The plot functions do not automatically transform between coordinate
systems, they just assume the space is shared.

yta and vagar share the same PROJ.4 string:

identical(proj4string(yta), proj4string(vagar))
[1] TRUE

so, assuming that all 3 coordinate systems have been recorded
correctly in the .prj files this should be fine:

plot(yta)
plot(vagar, add = TRUE)
sdn.reproj <- spTransform(sdn, CRS(proj4string(vagar)))
plot(sdn.reproj, add = T)

You are expected to ensure the projections are the same when plotting,
or using overlay.

I guess it wouldn't take much for those functions to do the job
on-the-fly, but often the metadata is non-existent or incorrectly
specified and so a manual step like this can save subtle errors. Also,
it's much more work to handle rasters with on-the-fly reprojection -
it takes a lot more options and is not reversible like vector
reprojection often is.

Cheers, Mike.

On Tue, Nov 17, 2009 at 11:02 AM, Hans Ekbrand <hans at sociologi.cjb.net> wrote:
> Hi list,
>
> I'm a newcomer to GIS and r-sig-geo. I have exported some shapefiles
> from ArcGIS and succeeded in plotting them with R. But one shapefile has
> a different coordinate system, I think, and it does not turn up in the
> graph when added to the others. In ArcGIS, this layer had an "unknown"
> coordinate system, but rendered at the right location in relation to the
> other layers.
>
> I have made a tar-archive with the shape-files and a script to import
> them into R and generate a map. The problematic shape is "sdn".
>
> http://sociologi.cjb.net/temp/create-map-data.tbz
> http://sociologi.cjb.net/temp/create-map.r
>
> Here is the summary output of a "good" shape, "yta", followed by summary
> of the problematic shape "sdn".
>
>> summary(yta)
>
> Object of class SpatialPolygonsDataFrame
>
> Coordinates:
>
> ? ? ? min ? ? ? max
>
> r1 ?303850 ?344600.1
>
> r2 6388900 6415400.0
>
> Is projected: TRUE
>
> proj4string :
>
> [+proj=utm +zone=33 +ellps=GRS80 +units=m +no_defs]
>
> Data attributes:
>
> ? ? ?KKOD ? ? ? ? SHAPE_AREA ? ? ? ? ?SHAPE_LEN
>
> ?Min. ? :1.000 ? Min. ? :7.812e+05 ? Min. ? : ? ?3530
>
> ?1st Qu.:3.000 ? 1st Qu.:1.125e+06 ? 1st Qu.: ? ?5514
>
> ?Median :5.000 ? Median :3.006e+06 ? Median : ? ?9121
>
> ?Mean ? :4.941 ? Mean ? :1.272e+09 ? Mean ? : ?647692
>
> ?3rd Qu.:7.000 ? 3rd Qu.:1.685e+07 ? 3rd Qu.: ? 37437
>
> ?Max. ? :7.000 ? Max. ? :3.119e+10 ? Max. ? :21081735
>
>
>
>> summary(sdn)
>
> Object of class SpatialPolygonsDataFrame
>
> Coordinates:
>
> ? ? ? min ? ? max
>
> r1 1247825 1288137
>
> r2 6382086 6422038
>
> Is projected: TRUE
>
> proj4string :
>
> [+proj=tmerc +lat_0=0 +lon_0=15.80827777777778 +k=1 +x_0=1500000 +y_0=0
>
> +ellps=bessel +units=m +no_defs]
>
> Data attributes:
>
> ? SW_MEMBER ? ? ? ? ? NAMN ? ? ? DISTRIKT ? ? ? REG_DATUM ? ? ? ? DATUM
>
> ?Min. ? : 1 ? 10 H?gsbo ?: 1 ? Centrum: 4 ? 1996/01/01:21 ? 2001/09/10:21
>
> ?1st Qu.: 6 ? 11 ?lvsborg: 1 ? Norr ? :10
>
> ?Median :11 ? 12 Fr?lunda: 1 ? V?ster : 7
>
> ?Mean ? :11 ? 13 Askim ? : 1
>
> ?3rd Qu.:16 ? 14 Tynnered: 1
>
> ?Max. ? :21 ? 15 Styrs? ?: 1
>
> ? ? ? ? ? ? ?(Other) ? ?:15
>
> ?OPERAT?r ? ?KVALITET ? ? ?AREA ? ? ? ? ? ? PERIMETER
>
> ?eoh:21 ? Min. ? :0 ? Min. ? : ?3729696 ? Min. ? :10507
>
> ? ? ? ? ?1st Qu.:0 ? 1st Qu.: ?9113274 ? 1st Qu.:15376
>
> ? ? ? ? ?Median :0 ? Median : 16307500 ? Median :21493
>
> ? ? ? ? ?Mean ? :0 ? Mean ? : 34423248 ? Mean ? :26351
>
> ? ? ? ? ?3rd Qu.:0 ? 3rd Qu.: 34864909 ? 3rd Qu.:32932
>
> ? ? ? ? ?Max. ? :0 ? Max. ? :198632325 ? Max. ? :64221
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From macq at llnl.gov  Tue Nov 17 02:43:48 2009
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 16 Nov 2009 17:43:48 -0800
Subject: [R-sig-Geo] How to create a SpatialPolygonsDataFrame object
In-Reply-To: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>
References: <3F6E329CD1E04AA9B60CE4E8BDE9D71B@shaofei>
Message-ID: <p0624080ec727b0064bdc@[128.115.67.9]>

There is a useful example in the help page for the overlay function. See

   help('overlay')

-Don

At 7:49 PM -0600 11/9/09, Chen, Shaofei wrote:
>Hello everyone,
>
>I can read polygon shape files into SpatialPolygonsDataFrame objects 
>using maptools library. But how to create a 
>SpatialPolygonsDataFrame object, for example, a 400 by 400 polygon?
>Thank you in advance!
>
>Best,
>Shaofei
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://*stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062


From hans at sociologi.cjb.net  Tue Nov 17 08:30:57 2009
From: hans at sociologi.cjb.net (Hans Ekbrand)
Date: Tue, 17 Nov 2009 08:30:57 +0100
Subject: [R-sig-Geo] incompatible projections/coordinate-systems?
In-Reply-To: <522664f80911161721wc6eb767pc304ce44e1549b6c@mail.gmail.com>
References: <4B01E829.2040206@sociologi.cjb.net>
	<522664f80911161721wc6eb767pc304ce44e1549b6c@mail.gmail.com>
Message-ID: <20091117073057.GA11032@samir>

On Tue, Nov 17, 2009 at 12:21:25PM +1100, Michael Sumner wrote:
> The plot functions do not automatically transform between coordinate
> systems, they just assume the space is shared.

I see.

> so, assuming that all 3 coordinate systems have been recorded
> correctly in the .prj files this should be fine:
> 
> plot(yta)
> plot(vagar, add = TRUE)
> sdn.reproj <- spTransform(sdn, CRS(proj4string(vagar)))

Michael, you just made my day!

Thanks!

-- 
Hans Ekbrand (http://sociologi.cjb.net) <hans at sociologi.cjb.net>
A. Because it breaks the logical sequence of discussion
Q. Why is top posting bad?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 197 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091117/50cf234d/attachment.bin>

From p.hiemstra at geo.uu.nl  Tue Nov 17 09:22:43 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 17 Nov 2009 09:22:43 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
Message-ID: <4B025D53.2000506@geo.uu.nl>

Mauricio Zambrano wrote:
> Dear List,
>
> During some OK interpolations of daily precipitation, with the
> 'automap' library, I got the following error:
>
>
> [using ordinary kriging]
> "chfactor.c", line 130: singular matrix in function LDLfactor()
> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>   LDLfactor
>
>
> The code I'm using works fine for other days, so I assume that the
> distance between the measurement points is no the problem. When
> looking at the data that rose the error, I realized that all the
> measured values were equal to zero (I can not skip those days in which
> all the measured points have the same value in advance, because the
> measured value in those points change with time).
>
> According to a traceback that is given below, it seems that the cause
> is in the 'predict.gstat' function of the 'gstat' package.
>
> The same error can be risen with:
>
> # Data preparation
> data(meuse)
> coordinates(meuse) =~ x+y
> data(meuse.grid)
> gridded(meuse.grid) =~ x+y
>
> meuse$zinc <- meuse$zinc*0
> meuse$zinc
>   
Try to check before running the interpolation if all the observations 
are zero. If this is the case, then instead of kriging return a grid 
where all the values are constant. Most probably this only occurs with 
all zeros and with e.g. all 4.67. To check if all data is the same use a 
cod structure like:

if(length(unique(meuse$zinc)) != 1) {
    autoKrige
} else {
    return grid with only zeros (or another value is that is constant
}

cheers,
Paul
> # Ordinary kriging, no new_data object
> kriging_result = autoKrige(zinc~1, meuse)
>
>
> traceback()
> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
> as.double(as.vector(raw$locations)),
>        as.vector(new.X), as.integer(block.cols), as.vector(block),
>        as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>        indicators = indicators, na.action = na.action, debug.level =
> debug.level)
> 4: .local(formula, locations, ...)
> 3: krige(formula, input_data, new_data, variogram_object$var_model,
>        block = block, ...)
> 2: krige(formula, input_data, new_data, variogram_object$var_model,
>        block = block, ...)
> 1: autoKrige(zinc ~ 1, meuse)
>
>
> I would really appreciate any hint about the possible reason of this
> error and if it could be overcome in some way.
>
>
> Thanks in advance for any help.
>
>
> Mauricio
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From p.hiemstra at geo.uu.nl  Tue Nov 17 09:53:25 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Tue, 17 Nov 2009 09:53:25 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <4B017A79.10206@uni-muenster.de>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
	<4B017A79.10206@uni-muenster.de>
Message-ID: <4B026485.60507@geo.uu.nl>

Edzer Pebesma wrote:
> My guess is that from constant data, the (co)variance is constant and
> zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
> errors).
>
> Is this a case that autokrige should catch?
>   
I added a check in autoKrige. The output for the example below is now:

kriging_result = autoKrige(zinc~1, meuse)
Error in autoKrige(zinc ~ 1, meuse) :
  All data in attribute 'zinc' is identical and equal to 0
   Can not interpolate this data

A new version of automap with this feature has been uploaded to CRAN.

cheers,
Paul
> --
> Edzer
>
> Mauricio Zambrano wrote:
>   
>> Dear List,
>>
>> During some OK interpolations of daily precipitation, with the
>> 'automap' library, I got the following error:
>>
>>
>> [using ordinary kriging]
>> "chfactor.c", line 130: singular matrix in function LDLfactor()
>> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>>   LDLfactor
>>
>>
>> The code I'm using works fine for other days, so I assume that the
>> distance between the measurement points is no the problem. When
>> looking at the data that rose the error, I realized that all the
>> measured values were equal to zero (I can not skip those days in which
>> all the measured points have the same value in advance, because the
>> measured value in those points change with time).
>>
>> According to a traceback that is given below, it seems that the cause
>> is in the 'predict.gstat' function of the 'gstat' package.
>>
>> The same error can be risen with:
>>
>> # Data preparation
>> data(meuse)
>> coordinates(meuse) =~ x+y
>> data(meuse.grid)
>> gridded(meuse.grid) =~ x+y
>>
>> meuse$zinc <- meuse$zinc*0
>> meuse$zinc
>>
>> # Ordinary kriging, no new_data object
>> kriging_result = autoKrige(zinc~1, meuse)
>>
>>
>> traceback()
>> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
>> as.double(as.vector(raw$locations)),
>>        as.vector(new.X), as.integer(block.cols), as.vector(block),
>>        as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
>> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>        indicators = indicators, na.action = na.action, debug.level =
>> debug.level)
>> 4: .local(formula, locations, ...)
>> 3: krige(formula, input_data, new_data, variogram_object$var_model,
>>        block = block, ...)
>> 2: krige(formula, input_data, new_data, variogram_object$var_model,
>>        block = block, ...)
>> 1: autoKrige(zinc ~ 1, meuse)
>>
>>
>> I would really appreciate any hint about the possible reason of this
>> error and if it could be overcome in some way.
>>
>>
>> Thanks in advance for any help.
>>
>>
>> Mauricio
>>   
>>     
>
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From nick at hamm.org  Tue Nov 17 10:06:26 2009
From: nick at hamm.org (Nick Hamm)
Date: Tue, 17 Nov 2009 10:06:26 +0100
Subject: [R-sig-Geo] Unconditional simulation
Message-ID: <88b3562d0911170106x3226bb31xb17dbd29da18740c@mail.gmail.com>

Dear all

I want to simulate a spatially-correlated random field which follows a
uniform rather than than Gaussian distribution.  Does anybody know a
straight-forward way to do this?

Nick


From Ulrich.Leopold at Tudor.lu  Tue Nov 17 10:52:45 2009
From: Ulrich.Leopold at Tudor.lu (Ulrich Leopold)
Date: Tue, 17 Nov 2009 10:52:45 +0100
Subject: [R-sig-Geo] Spatial interpolation of river network observations
Message-ID: <4B02726D.4050002@Tudor.lu>

Dear all,

I would like to interpolate 17 pollution observations in a storage lake
in 3 dimensions (x,y,z).

As I understand variogram analysis and kriging are not straightforward
as we are dealing with non-euclidean (hydrologic) distances and
down-stream direction.

Could someone point me to some algorithms which can roughly estimate the
3d pollution body accounting for hydrologic distances?

Attached is a file which shows the sampling locations and the storage lake.

Thanks very much.

Best regards,
Ulrich


-- 
______________________________________________________________________

Ulrich Leopold

Resource Centre for Environmental Technologies, Public Research Centre
Henri Tudor, Technoport Schlassgoart, 66 rue de Luxembourg, P.O. BOX
144, L-4002 Esch-sur-Alzette, Luxembourg

tel: +352 42 5591 618
fax: +352 42 5591 555
mobile: +352 691 304813
http://www.crte.lu , http://www.tudor.lu

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Algae_sampling.png
Type: image/png
Size: 61592 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091117/19a14700/attachment.png>

From hzambran.newsgroups at gmail.com  Tue Nov 17 10:54:04 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Tue, 17 Nov 2009 10:54:04 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <4B026485.60507@geo.uu.nl>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
	<4B017A79.10206@uni-muenster.de> <4B026485.60507@geo.uu.nl>
Message-ID: <63d616b0911170154x77168d5boaaaf1c722f693996@mail.gmail.com>

Thank you Edzer for giving a hint about the meaning of the 'LDLfactor'
error, and thank you Paul for adding a check to the 'autoKrige'
function.

Kind regards,

Mauricio

-- 
?============================================
Ph.D. Candidate,
University of Trento
Dept. of Civil and Env. Engineering
Trento / Italy
=============================================
Linux user #454569 -- Ubuntu user #17469
=============================================
"Planning is bringing the future into the present
so that you can do something about it now"
(Alan Lakein)

2009/11/17 Paul Hiemstra <p.hiemstra at geo.uu.nl>:
> Edzer Pebesma wrote:
>>
>> My guess is that from constant data, the (co)variance is constant and
>> zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
>> errors).
>>
>> Is this a case that autokrige should catch?
>>
>
> I added a check in autoKrige. The output for the example below is now:
>
> kriging_result = autoKrige(zinc~1, meuse)
> Error in autoKrige(zinc ~ 1, meuse) :
> ?All data in attribute 'zinc' is identical and equal to 0
> ?Can not interpolate this data
>
> A new version of automap with this feature has been uploaded to CRAN.
>
> cheers,
> Paul
>>
>> --
>> Edzer
>>
>> Mauricio Zambrano wrote:
>>
>>>
>>> Dear List,
>>>
>>> During some OK interpolations of daily precipitation, with the
>>> 'automap' library, I got the following error:
>>>
>>>
>>> [using ordinary kriging]
>>> "chfactor.c", line 130: singular matrix in function LDLfactor()
>>> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>> ?:
>>> ?LDLfactor
>>>
>>>
>>> The code I'm using works fine for other days, so I assume that the
>>> distance between the measurement points is no the problem. When
>>> looking at the data that rose the error, I realized that all the
>>> measured values were equal to zero (I can not skip those days in which
>>> all the measured points have the same value in advance, because the
>>> measured value in those points change with time).
>>>
>>> According to a traceback that is given below, it seems that the cause
>>> is in the 'predict.gstat' function of the 'gstat' package.
>>>
>>> The same error can be risen with:
>>>
>>> # Data preparation
>>> data(meuse)
>>> coordinates(meuse) =~ x+y
>>> data(meuse.grid)
>>> gridded(meuse.grid) =~ x+y
>>>
>>> meuse$zinc <- meuse$zinc*0
>>> meuse$zinc
>>>
>>> # Ordinary kriging, no new_data object
>>> kriging_result = autoKrige(zinc~1, meuse)
>>>
>>>
>>> traceback()
>>> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
>>> as.double(as.vector(raw$locations)),
>>> ? ? ? as.vector(new.X), as.integer(block.cols), as.vector(block),
>>> ? ? ? as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
>>> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>> ? ? ? indicators = indicators, na.action = na.action, debug.level =
>>> debug.level)
>>> 4: .local(formula, locations, ...)
>>> 3: krige(formula, input_data, new_data, variogram_object$var_model,
>>> ? ? ? block = block, ...)
>>> 2: krige(formula, input_data, new_data, variogram_object$var_model,
>>> ? ? ? block = block, ...)
>>> 1: autoKrige(zinc ~ 1, meuse)
>>>
>>>
>>> I would really appreciate any hint about the possible reason of this
>>> error and if it could be overcome in some way.
>>>
>>>
>>> Thanks in advance for any help.
>>>
>>>
>>> Mauricio
>>>
>>
>>
>
>
> --
> Drs. Paul Hiemstra
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone: ?+3130 274 3113 Mon-Tue
> Phone: ?+3130 253 5773 Wed-Fri
> http://intamap.geo.uu.nl/~paul
>
>


From hengl at spatial-analyst.net  Tue Nov 17 11:46:15 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 17 Nov 2009 11:46:15 +0100
Subject: [R-sig-Geo] Unconditional simulation
In-Reply-To: <88b3562d0911170106x3226bb31xb17dbd29da18740c@mail.gmail.com>
References: <88b3562d0911170106x3226bb31xb17dbd29da18740c@mail.gmail.com>
Message-ID: <323A8F84930041F98DE27479CA201B81@pcibed193>


Hi Nick,

Very interesting problem. At first thought, I imagined that you just want to simulate noise  ;)

In the geoR package (http://leg.ufpr.br/geoR/) there is a function to simulate Gaussian Random
Fields (uses actually RandomFields package) using various models e.g.:

> library(geoR)
-------------------------------------------------------------
Analysis of geostatistical data
For an Introduction to geoR go to http://www.leg.ufpr.br/geoR
geoR version 1.6-27 (built on 2009-10-15) is now loaded
-------------------------------------------------------------
> s <- grf(100, grid="reg", cov.pars=c(2, 0.2), cov.model="mat", kappa=1.5)
grf: generating grid  10  *  10  with  100  points
grf: process with  1  covariance structure(s)
grf: nugget effect is: tausq= 0 
grf: covariance model 1 is: matern(sigmasq=2, phi=0.2, kappa = 1.5)
grf: decomposition algorithm used is:  cholesky 
grf: End of simulation procedure. Number of realizations: 1 
> image(s, col=gray(seq(1, 0.2, l=21)))
> hist(s$data)  # normal distribution

You can also simulate a regular point sample with the same spatial structure on top of that using
either Poisson, Bernoulli or binomial models. For example, to simulate a Poisson model, you could
use:

# define your own model, e.g. poisson:
> lambda <- exp(0.5 +s$data)
> y <- rpois(length(s$data), lambda=lambda)
> points(y)
> text(s$coords, label=y, pos=3, offset=0.3)
> hist(y)

For a uniform model, I would then use the Empirical Cumulative Distribution Function (ECDF):

# uniform distribution:
> y.cdf <- ecdf(s$data)
> y <- y.cdf(s$data)
> image(s, col=gray(seq(1, 0.2, l=21)))
> points(y)
> text(s$coords, label=y, pos=3, offset=0.3)
> hist(y)

This would then have the same spatial auto-correlation structure and 'perfectly' uniform
distribution (I might also be wrong - I do not like that a simulated variable has a perfect
histogram).

I am sure that other mathematicians have maybe better ideas.


HTH

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 





> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Nick Hamm
> Sent: Tuesday, November 17, 2009 10:06 AM
> To: r-sig-geo at stat.math.ethz.ch; ai-geostats at jrc.it
> Subject: [R-sig-Geo] Unconditional simulation
> 
> Dear all
> 
> I want to simulate a spatially-correlated random field which follows a
> uniform rather than than Gaussian distribution.  Does anybody know a
> straight-forward way to do this?
> 
> Nick
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From hengl at spatial-analyst.net  Tue Nov 17 11:58:26 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 17 Nov 2009 11:58:26 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <4B026485.60507@geo.uu.nl>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com><4B017A79.10206@uni-muenster.de>
	<4B026485.60507@geo.uu.nl>
Message-ID: <E4F8694C24224D1AAAD5D7854610585D@pcibed193>


Hi Paul, Edzer,

I understand why the singular matrix problem happens and I know that there is not really a
mathematical solution around it:

> x <- matrix(runif(100), nrow=10)
> x.i <- solve(x)
> str(x.i)
 num [1:10, 1:10] 0.8191 -1.0293 0.0826 1.068 -0.2106 ...
# add a 'singular' column
> x[,1:10] <- rep(1, 10)
> x.i <- solve(x)
Error in solve.default(x) : 
  Lapack routine dgesv: system is exactly singular


However, I would very much support if you would integrate an "if" loop to check if it will happen,
and then mask the prediction location using "NA".

I mean, at the moment every time we want to run predictions, even if only at a single prediction
location the model fails, we are not able to generate any output (this is sometimes really
frustrating).

Hence, I would support that you allow us to run predictions for all locations first, and then let
the users judge if one should increase the search radius, remove some too-uniform predictors etc
etc.

I hope you agree with me,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Paul Hiemstra
> Sent: Tuesday, November 17, 2009 9:53 AM
> To: Edzer Pebesma
> Cc: r-sig-geo
> Subject: Re: [R-sig-Geo] 'LDLfactor' error in 'krige' function
> 
> Edzer Pebesma wrote:
> > My guess is that from constant data, the (co)variance is constant and
> > zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
> > errors).
> >
> > Is this a case that autokrige should catch?
> >
> I added a check in autoKrige. The output for the example below is now:
> 
> kriging_result = autoKrige(zinc~1, meuse)
> Error in autoKrige(zinc ~ 1, meuse) :
>   All data in attribute 'zinc' is identical and equal to 0
>    Can not interpolate this data
> 
> A new version of automap with this feature has been uploaded to CRAN.
> 
> cheers,
> Paul
> > --
> > Edzer
> >
> > Mauricio Zambrano wrote:
> >
> >> Dear List,
> >>
> >> During some OK interpolations of daily precipitation, with the
> >> 'automap' library, I got the following error:
> >>
> >>
> >> [using ordinary kriging]
> >> "chfactor.c", line 130: singular matrix in function LDLfactor()
> >> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
> >>   LDLfactor
> >>
> >>
> >> The code I'm using works fine for other days, so I assume that the
> >> distance between the measurement points is no the problem. When
> >> looking at the data that rose the error, I realized that all the
> >> measured values were equal to zero (I can not skip those days in which
> >> all the measured points have the same value in advance, because the
> >> measured value in those points change with time).
> >>
> >> According to a traceback that is given below, it seems that the cause
> >> is in the 'predict.gstat' function of the 'gstat' package.
> >>
> >> The same error can be risen with:
> >>
> >> # Data preparation
> >> data(meuse)
> >> coordinates(meuse) =~ x+y
> >> data(meuse.grid)
> >> gridded(meuse.grid) =~ x+y
> >>
> >> meuse$zinc <- meuse$zinc*0
> >> meuse$zinc
> >>
> >> # Ordinary kriging, no new_data object
> >> kriging_result = autoKrige(zinc~1, meuse)
> >>
> >>
> >> traceback()
> >> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
> >> as.double(as.vector(raw$locations)),
> >>        as.vector(new.X), as.integer(block.cols), as.vector(block),
> >>        as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
> >> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
> >>        indicators = indicators, na.action = na.action, debug.level =
> >> debug.level)
> >> 4: .local(formula, locations, ...)
> >> 3: krige(formula, input_data, new_data, variogram_object$var_model,
> >>        block = block, ...)
> >> 2: krige(formula, input_data, new_data, variogram_object$var_model,
> >>        block = block, ...)
> >> 1: autoKrige(zinc ~ 1, meuse)
> >>
> >>
> >> I would really appreciate any hint about the possible reason of this
> >> error and if it could be overcome in some way.
> >>
> >>
> >> Thanks in advance for any help.
> >>
> >>
> >> Mauricio
> >>
> >>
> >
> >
> 
> 
> --
> Drs. Paul Hiemstra
> Department of Physical Geography
> Faculty of Geosciences
> University of Utrecht
> Heidelberglaan 2
> P.O. Box 80.115
> 3508 TC Utrecht
> Phone:  +3130 274 3113 Mon-Tue
> Phone:  +3130 253 5773 Wed-Fri
> http://intamap.geo.uu.nl/~paul
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sebastiano.trevisani at libero.it  Tue Nov 17 12:00:44 2009
From: sebastiano.trevisani at libero.it (seba)
Date: Tue, 17 Nov 2009 12:00:44 +0100
Subject: [R-sig-Geo] AI-GEOSTATS: Unconditional simulation
In-Reply-To: <88b3562d0911170106x3226bb31xb17dbd29da18740c@mail.gmail.co m>
References: <88b3562d0911170106x3226bb31xb17dbd29da18740c@mail.gmail.com>
Message-ID: <01NG75I1WKK20004YK@mx1.pd.cnr.it>

Hi Nick
One way is to use simulated annealing (see gslib) putting as objective
function your desired variogram and histogram.
(but I guess that by means of some data transformation you can do that
with a simple sequential gaussian simulation approach)
Bye
Sebas

At 10.06 17/11/2009, Nick Hamm wrote:
>Dear all
>
>I want to simulate a spatially-correlated random field which follows a
>uniform rather than than Gaussian distribution.  Does anybody know a
>straight-forward way to do this?
>
>Nick
>+
>+ To post a message to the list, send it to ai-geostats at jrc.ec.europa.eu
>+ To unsubscribe, send email to majordomo@ jrc.ec.europa.eu with no 
>subject and "unsubscribe ai-geostats" in the message body. DO NOT 
>SEND Subscribe/Unsubscribe requests to the list
>+ As a general service to list users, please remember to post a 
>summary of any useful responses to your questions.
>+ Support to the forum can be found at http://www.ai-geostats.org/


From hengl at spatial-analyst.net  Tue Nov 17 12:45:58 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 17 Nov 2009 12:45:58 +0100
Subject: [R-sig-Geo] Spatial interpolation of river network observations
In-Reply-To: <4B02726D.4050002@Tudor.lu>
References: <4B02726D.4050002@Tudor.lu>
Message-ID: <D22E14BD0FC740D4A0D998A3C4591D4D@pcibed193>


Hi Ultrich,

Facundo Mu?oz apparently made a GRASS function to derive distances along streams:

https://stat.ethz.ch/pipermail/r-sig-geo/2009-November/006851.html 

17 observations only? That is really tight for any geostatistical analysis (on top, you want to do 3
dimensions!). I would instead consider fitting a smooth surface (splines) / simulating the flow
processes.


all the best,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 

> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Ulrich Leopold
> Sent: Tuesday, November 17, 2009 10:53 AM
> To: R-sig-geo list; grass-user at lists.osgeo.org
> Subject: [R-sig-Geo] Spatial interpolation of river network observations
> 
> Dear all,
> 
> I would like to interpolate 17 pollution observations in a storage lake
> in 3 dimensions (x,y,z).
> 
> As I understand variogram analysis and kriging are not straightforward
> as we are dealing with non-euclidean (hydrologic) distances and
> down-stream direction.
> 
> Could someone point me to some algorithms which can roughly estimate the
> 3d pollution body accounting for hydrologic distances?
> 
> Attached is a file which shows the sampling locations and the storage lake.
> 
> Thanks very much.
> 
> Best regards,
> Ulrich
> 
> 
> --
> ______________________________________________________________________
> 
> Ulrich Leopold
> 
> Resource Centre for Environmental Technologies, Public Research Centre
> Henri Tudor, Technoport Schlassgoart, 66 rue de Luxembourg, P.O. BOX
> 144, L-4002 Esch-sur-Alzette, Luxembourg
> 
> tel: +352 42 5591 618
> fax: +352 42 5591 555
> mobile: +352 691 304813
> http://www.crte.lu , http://www.tudor.lu


From hzambran.newsgroups at gmail.com  Tue Nov 17 12:42:14 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Tue, 17 Nov 2009 12:42:14 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <E4F8694C24224D1AAAD5D7854610585D@pcibed193>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
	<4B017A79.10206@uni-muenster.de> <4B026485.60507@geo.uu.nl>
	<E4F8694C24224D1AAAD5D7854610585D@pcibed193>
Message-ID: <63d616b0911170342v4ed4468dvd934af38f26ecd52@mail.gmail.com>

Dear Paul and Edzer,


2009/11/17 Tomislav Hengl <hengl at spatial-analyst.net>:
>
> Hi Paul, Edzer,
>
> I understand why the singular matrix problem happens and I know that there is not really a
> mathematical solution around it:
>
>> x <- matrix(runif(100), nrow=10)
>> x.i <- solve(x)
>> str(x.i)
> ?num [1:10, 1:10] 0.8191 -1.0293 0.0826 1.068 -0.2106 ...
> # add a 'singular' column
>> x[,1:10] <- rep(1, 10)
>> x.i <- solve(x)
> Error in solve.default(x) :
> ?Lapack routine dgesv: system is exactly singular
>
>
> However, I would very much support if you would integrate an "if" loop to check if it will happen,
> and then mask the prediction location using "NA".

>
> I mean, at the moment every time we want to run predictions, even if only at a single prediction
> location the model fails, we are not able to generate any output (this is sometimes really
> frustrating).

I agree with Tom that it may be really frustrating not to get any
output, even most when this situation happens within a loop that
involves many time steps. I know that the user can easily get rid of
this manually for a single prediction, but it should be better if the
check could be integrated into the 'krige' or the 'autoKrige'
function, but of course this is your decision.


>
> Hence, I would support that you allow us to run predictions for all locations first, and then let
> the users judge if one should increase the search radius, remove some too-uniform predictors etc
> etc.

In case you could allow us to run the predictions first, it shouldn't
be better to mask the prediction location with the constant value that
caused the error instead of NA ?. Or to have a flag that allow the
user to choose if to get an NA or the constant value ?


Kinds,

Mauricio

-- 
?============================================
Ph.D. Candidate,
Dept. of Civil and Env. Engineering
University of Trento, Italy
=============================================
Linux user #454569 -- Ubuntu user #17469
=============================================
"Planning is bringing the future into the present
so that you can do something about it now"
(Alan Lakein)

>
> I hope you agree with me,
>
> T. Hengl
> http://home.medewerker.uva.nl/t.hengl/
>
>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Paul Hiemstra
>> Sent: Tuesday, November 17, 2009 9:53 AM
>> To: Edzer Pebesma
>> Cc: r-sig-geo
>> Subject: Re: [R-sig-Geo] 'LDLfactor' error in 'krige' function
>>
>> Edzer Pebesma wrote:
>> > My guess is that from constant data, the (co)variance is constant and
>> > zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
>> > errors).
>> >
>> > Is this a case that autokrige should catch?
>> >
>> I added a check in autoKrige. The output for the example below is now:
>>
>> kriging_result = autoKrige(zinc~1, meuse)
>> Error in autoKrige(zinc ~ 1, meuse) :
>> ? All data in attribute 'zinc' is identical and equal to 0
>> ? ?Can not interpolate this data
>>
>> A new version of automap with this feature has been uploaded to CRAN.
>>
>> cheers,
>> Paul
>> > --
>> > Edzer
>> >
>> > Mauricio Zambrano wrote:
>> >
>> >> Dear List,
>> >>
>> >> During some OK interpolations of daily precipitation, with the
>> >> 'automap' library, I got the following error:
>> >>
>> >>
>> >> [using ordinary kriging]
>> >> "chfactor.c", line 130: singular matrix in function LDLfactor()
>> >> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim, ?:
>> >> ? LDLfactor
>> >>
>> >>
>> >> The code I'm using works fine for other days, so I assume that the
>> >> distance between the measurement points is no the problem. When
>> >> looking at the data that rose the error, I realized that all the
>> >> measured values were equal to zero (I can not skip those days in which
>> >> all the measured points have the same value in advance, because the
>> >> measured value in those points change with time).
>> >>
>> >> According to a traceback that is given below, it seems that the cause
>> >> is in the 'predict.gstat' function of the 'gstat' package.
>> >>
>> >> The same error can be risen with:
>> >>
>> >> # Data preparation
>> >> data(meuse)
>> >> coordinates(meuse) =~ x+y
>> >> data(meuse.grid)
>> >> gridded(meuse.grid) =~ x+y
>> >>
>> >> meuse$zinc <- meuse$zinc*0
>> >> meuse$zinc
>> >>
>> >> # Ordinary kriging, no new_data object
>> >> kriging_result = autoKrige(zinc~1, meuse)
>> >>
>> >>
>> >> traceback()
>> >> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
>> >> as.double(as.vector(raw$locations)),
>> >> ? ? ? ?as.vector(new.X), as.integer(block.cols), as.vector(block),
>> >> ? ? ? ?as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
>> >> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>> >> ? ? ? ?indicators = indicators, na.action = na.action, debug.level =
>> >> debug.level)
>> >> 4: .local(formula, locations, ...)
>> >> 3: krige(formula, input_data, new_data, variogram_object$var_model,
>> >> ? ? ? ?block = block, ...)
>> >> 2: krige(formula, input_data, new_data, variogram_object$var_model,
>> >> ? ? ? ?block = block, ...)
>> >> 1: autoKrige(zinc ~ 1, meuse)
>> >>
>> >>
>> >> I would really appreciate any hint about the possible reason of this
>> >> error and if it could be overcome in some way.
>> >>
>> >>
>> >> Thanks in advance for any help.
>> >>
>> >>
>> >> Mauricio
>> >>
>> >>
>> >
>> >
>>
>>
>> --
>> Drs. Paul Hiemstra
>> Department of Physical Geography
>> Faculty of Geosciences
>> University of Utrecht
>> Heidelberglaan 2
>> P.O. Box 80.115
>> 3508 TC Utrecht
>> Phone: ?+3130 274 3113 Mon-Tue
>> Phone: ?+3130 253 5773 Wed-Fri
>> http://intamap.geo.uu.nl/~paul
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Tue Nov 17 13:00:54 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 17 Nov 2009 13:00:54 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <E4F8694C24224D1AAAD5D7854610585D@pcibed193>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com><4B017A79.10206@uni-muenster.de>	<4B026485.60507@geo.uu.nl>
	<E4F8694C24224D1AAAD5D7854610585D@pcibed193>
Message-ID: <4B029076.8000806@uni-muenster.de>

Tom, you can already do this:

library(gstat)
data(meuse)
coordinates(meuse)=~x+y
data(meuse.grid)
gridded(meuse.grid)=~x+y
meuse=meuse[c(1,1:155),] # replicate first observation
pr1 = predict(zinc~1,meuse,meuse.grid,vgm(1, "Exp", 300)) # will break
# the following will generate NA's for cells where the estimated
condition number of the covariance matrix exceeds 1e10:
pr1 = krige(zinc~1,meuse,meuse.grid,vgm(1, "Exp",
300),nmax=30,                 set=list(cn_max=1e10))
# generate a full interpolation as comparison:
pr1$idw = idw(zinc~1,meuse,meuse.grid)[[1]]
# show side by side:
spplot(pr1, c("var1.pred", "idw"), col.regions=bpy.colors())

... missing values are generated for those cells that result in a
singular covariance matrix, given their local neighbourhood of 30
nearest observations.

cn_max referers to the maximum allowed condition number, see
http://en.wikipedia.org/wiki/Condition_number

Two issues are (i) what singularity means when we use floating point
representations for real numbers, and (ii) that condition numbers of
matrices are expensive to evaluate, and an estimate based on the LU
decomposition is used. I threshold to 1e10 here, but that is purely for
illustrational purposes.

Note, for you of interest, that IIRC this thresholding is also done for
singularity of the X matrix, holding the predictors.

All this information didn't make it to the help pages of the krige
function. This help page would cover tens of pages otherwise. For full
documentation, still the "old", gstat stand-alone manual on gstat.org is
needed. I agree that this is not optimal.

With best wishes,
--
Edzer


Tomislav Hengl wrote:
> Hi Paul, Edzer,
>
> I understand why the singular matrix problem happens and I know that there is not really a
> mathematical solution around it:
>
>   
>> x <- matrix(runif(100), nrow=10)
>> x.i <- solve(x)
>> str(x.i)
>>     
>  num [1:10, 1:10] 0.8191 -1.0293 0.0826 1.068 -0.2106 ...
> # add a 'singular' column
>   
>> x[,1:10] <- rep(1, 10)
>> x.i <- solve(x)
>>     
> Error in solve.default(x) : 
>   Lapack routine dgesv: system is exactly singular
>
>
> However, I would very much support if you would integrate an "if" loop to check if it will happen,
> and then mask the prediction location using "NA".
>
> I mean, at the moment every time we want to run predictions, even if only at a single prediction
> location the model fails, we are not able to generate any output (this is sometimes really
> frustrating).
>
> Hence, I would support that you allow us to run predictions for all locations first, and then let
> the users judge if one should increase the search radius, remove some too-uniform predictors etc
> etc.
>
> I hope you agree with me,
>
> T. Hengl
> http://home.medewerker.uva.nl/t.hengl/
>
>
>   
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
>> Of Paul Hiemstra
>> Sent: Tuesday, November 17, 2009 9:53 AM
>> To: Edzer Pebesma
>> Cc: r-sig-geo
>> Subject: Re: [R-sig-Geo] 'LDLfactor' error in 'krige' function
>>
>> Edzer Pebesma wrote:
>>     
>>> My guess is that from constant data, the (co)variance is constant and
>>> zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
>>> errors).
>>>
>>> Is this a case that autokrige should catch?
>>>
>>>       
>> I added a check in autoKrige. The output for the example below is now:
>>
>> kriging_result = autoKrige(zinc~1, meuse)
>> Error in autoKrige(zinc ~ 1, meuse) :
>>   All data in attribute 'zinc' is identical and equal to 0
>>    Can not interpolate this data
>>
>> A new version of automap with this feature has been uploaded to CRAN.
>>
>> cheers,
>> Paul
>>     
>>> --
>>> Edzer
>>>
>>> Mauricio Zambrano wrote:
>>>
>>>       
>>>> Dear List,
>>>>
>>>> During some OK interpolations of daily precipitation, with the
>>>> 'automap' library, I got the following error:
>>>>
>>>>
>>>> [using ordinary kriging]
>>>> "chfactor.c", line 130: singular matrix in function LDLfactor()
>>>> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
>>>>   LDLfactor
>>>>
>>>>
>>>> The code I'm using works fine for other days, so I assume that the
>>>> distance between the measurement points is no the problem. When
>>>> looking at the data that rose the error, I realized that all the
>>>> measured values were equal to zero (I can not skip those days in which
>>>> all the measured points have the same value in advance, because the
>>>> measured value in those points change with time).
>>>>
>>>> According to a traceback that is given below, it seems that the cause
>>>> is in the 'predict.gstat' function of the 'gstat' package.
>>>>
>>>> The same error can be risen with:
>>>>
>>>> # Data preparation
>>>> data(meuse)
>>>> coordinates(meuse) =~ x+y
>>>> data(meuse.grid)
>>>> gridded(meuse.grid) =~ x+y
>>>>
>>>> meuse$zinc <- meuse$zinc*0
>>>> meuse$zinc
>>>>
>>>> # Ordinary kriging, no new_data object
>>>> kriging_result = autoKrige(zinc~1, meuse)
>>>>
>>>>
>>>> traceback()
>>>> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
>>>> as.double(as.vector(raw$locations)),
>>>>        as.vector(new.X), as.integer(block.cols), as.vector(block),
>>>>        as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
>>>> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
>>>>        indicators = indicators, na.action = na.action, debug.level =
>>>> debug.level)
>>>> 4: .local(formula, locations, ...)
>>>> 3: krige(formula, input_data, new_data, variogram_object$var_model,
>>>>        block = block, ...)
>>>> 2: krige(formula, input_data, new_data, variogram_object$var_model,
>>>>        block = block, ...)
>>>> 1: autoKrige(zinc ~ 1, meuse)
>>>>
>>>>
>>>> I would really appreciate any hint about the possible reason of this
>>>> error and if it could be overcome in some way.
>>>>
>>>>
>>>> Thanks in advance for any help.
>>>>
>>>>
>>>> Mauricio
>>>>
>>>>
>>>>         
>>>       
>> --
>> Drs. Paul Hiemstra
>> Department of Physical Geography
>> Faculty of Geosciences
>> University of Utrecht
>> Heidelberglaan 2
>> P.O. Box 80.115
>> 3508 TC Utrecht
>> Phone:  +3130 274 3113 Mon-Tue
>> Phone:  +3130 253 5773 Wed-Fri
>> http://intamap.geo.uu.nl/~paul
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From nick at hamm.org  Tue Nov 17 13:09:41 2009
From: nick at hamm.org (Nick Hamm)
Date: Tue, 17 Nov 2009 13:09:41 +0100
Subject: [R-sig-Geo] Random number seed and unconditional simulation
Message-ID: <88b3562d0911170409y4e32ff8ci1d4d12d5748e3e93@mail.gmail.com>

Dear all

I have a question about the random number seeding in R.

I want to simulate several random fields.  Each RF should have zero
nugget, the same sill but a different range (e.g., 100x100, range: 1
-> 30).  Let's stick with the Gaussian case for now.  I use the
following code

################################
require(geoR)

sigma2 = 10 # Set the sill
s2 = data.frame(phi=1, s2=1, s=1) # phi is the range

for(phi in 1:30)
{

   set.seed(234)
   sim1 = grf(100*100, grid="reg", nx=100, ny=100, xlims=c(1,100),
ylims=c(1,100), cov.model="exponential", cov.pars=c(sigma2, phi),
messages=FALSE)

   image(sim1)
   s2[phi,] = c(phi, var(sim1$data), sd(sim1$data))

}

# Plot the range against  the a priori variance.
plot(s2$phi, s2$s2, ylim=c(0,15))
abline(v=23)

############################

Note that, for each simulation, I use the same random number seed.
This results in a series of images that look like they have the same
"starting point" (sorry, this is not very technical), but with
progressively more spatial structure.  Note that ther is a sudden
change at phi=23.  The logic for using the same random number seed is
that we want to simulate a series of RFs where the differentiating
factor is the range (phi) and not something else.  Hence the observed
similar patterns, but with increasing spatial structure, is a useful
feature.

I have two questions

1) Is this last point true?  What is the effect of fixing every
argument to the function (including the random number seed) and just
varying one (in this case the range (phi))?  Note that Diggle and
Ribeiro do something similar in their examples at the end of the help
for GRF (see below).

2) Why do I get the sudden change at phi=23?  This also occurs for
other random number seeds (e.g, 230, 231, 234, 456, 5683432).  The
change occurs at the same point (phi=23).  Note that there is no
sudden change if I choose the spherical model rather than the
exponential.

If anybody has any thoughts, I would be interested.

best wishes

Nick




Here is the example given in the grf(geoR) help.

## 1-D simulations using the same seed and different noise/signal ratios
##
set.seed(234)
sim11 <- grf(100, ny=1, cov.pars=c(1, 0.25), nug=0)
set.seed(234)
sim12 <- grf(100, ny=1, cov.pars=c(0.75, 0.25), nug=0.25)
set.seed(234)
sim13 <- grf(100, ny=1, cov.pars=c(0.5, 0.25), nug=0.5)
##
par.ori <- par(no.readonly = TRUE)
par(mfrow=c(3,1), mar=c(3,3,.5,.5))
yl <- range(c(sim11$data, sim12$data, sim13$data))
image(sim11, type="l", ylim=yl)
image(sim12, type="l", ylim=yl)
image(sim13, type="l", ylim=yl)
par(par.ori)


From edzer.pebesma at uni-muenster.de  Tue Nov 17 13:16:18 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 17 Nov 2009 13:16:18 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <63d616b0911170342v4ed4468dvd934af38f26ecd52@mail.gmail.com>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>	<4B017A79.10206@uni-muenster.de>
	<4B026485.60507@geo.uu.nl>	<E4F8694C24224D1AAAD5D7854610585D@pcibed193>
	<63d616b0911170342v4ed4468dvd934af38f26ecd52@mail.gmail.com>
Message-ID: <4B029412.4020904@uni-muenster.de>

I just want to point out that "krige" has no problem with constant
observations, as long as it is provided with a valid (i.e. semi negative
definite, or something like that) variogram model. The problem is to
automatically fit such a function from data that are constant, as they
have zero (co)variance; this is done by automap/autofitvariogram and the
like. Replacing an invalid (zero) variogram model with e.g. a
(numerically) small nugget effect would already help, but raise two
issues: (i) what is numerically small, and (ii) is that a realistic
model for your data? Are near-zero prediction variances realistic for
any process with constant measured values?
--
Edzer

Mauricio Zambrano wrote:
> Dear Paul and Edzer,
>
>
> 2009/11/17 Tomislav Hengl <hengl at spatial-analyst.net>:
>   
>> Hi Paul, Edzer,
>>
>> I understand why the singular matrix problem happens and I know that there is not really a
>> mathematical solution around it:
>>
>>     
>>> x <- matrix(runif(100), nrow=10)
>>> x.i <- solve(x)
>>> str(x.i)
>>>       
>>  num [1:10, 1:10] 0.8191 -1.0293 0.0826 1.068 -0.2106 ...
>> # add a 'singular' column
>>     
>>> x[,1:10] <- rep(1, 10)
>>> x.i <- solve(x)
>>>       
>> Error in solve.default(x) :
>>  Lapack routine dgesv: system is exactly singular
>>
>>
>> However, I would very much support if you would integrate an "if" loop to check if it will happen,
>> and then mask the prediction location using "NA".
>>     
>
>   
>> I mean, at the moment every time we want to run predictions, even if only at a single prediction
>> location the model fails, we are not able to generate any output (this is sometimes really
>> frustrating).
>>     
>
> I agree with Tom that it may be really frustrating not to get any
> output, even most when this situation happens within a loop that
> involves many time steps. I know that the user can easily get rid of
> this manually for a single prediction, but it should be better if the
> check could be integrated into the 'krige' or the 'autoKrige'
> function, but of course this is your decision.
>
>
>   
>> Hence, I would support that you allow us to run predictions for all locations first, and then let
>> the users judge if one should increase the search radius, remove some too-uniform predictors etc
>> etc.
>>     
>
> In case you could allow us to run the predictions first, it shouldn't
> be better to mask the prediction location with the constant value that
> caused the error instead of NA ?. Or to have a flag that allow the
> user to choose if to get an NA or the constant value ?
>
>
> Kinds,
>
> Mauricio
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From hengl at spatial-analyst.net  Tue Nov 17 15:01:17 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Tue, 17 Nov 2009 15:01:17 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <4B029076.8000806@uni-muenster.de>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com><4B017A79.10206@uni-muenster.de>	<4B026485.60507@geo.uu.nl>
	<E4F8694C24224D1AAAD5D7854610585D@pcibed193>
	<4B029076.8000806@uni-muenster.de>
Message-ID: <5EDFB2DC6B8C40839C60B533751B3EC6@pcibed193>


Hi Edzer,

Thanks for the info. I was not aware that I can simply set cn_max and the predictions will not break
(and I still do read the gstat manual).

I guess that this is then the solution to our problem. 

For me it enough to generate a map with NA's, then zoom into map to see where the problematic
areas/points are, then either filter the maps, consider using different search radius or threshold.

T. Hengl
http://home.medewerker.uva.nl/t.hengl/

> -----Original Message-----
> From: Edzer Pebesma [mailto:edzer.pebesma at uni-muenster.de]
> Sent: Tuesday, November 17, 2009 1:01 PM
> To: Tomislav Hengl
> Cc: 'r-sig-geo'
> Subject: Re: [R-sig-Geo] 'LDLfactor' error in 'krige' function
> 
> Tom, you can already do this:
> 
> library(gstat)
> data(meuse)
> coordinates(meuse)=~x+y
> data(meuse.grid)
> gridded(meuse.grid)=~x+y
> meuse=meuse[c(1,1:155),] # replicate first observation
> pr1 = predict(zinc~1,meuse,meuse.grid,vgm(1, "Exp", 300)) # will break
> # the following will generate NA's for cells where the estimated
> condition number of the covariance matrix exceeds 1e10:
> pr1 = krige(zinc~1,meuse,meuse.grid,vgm(1, "Exp",
> 300),nmax=30,                 set=list(cn_max=1e10))
> # generate a full interpolation as comparison:
> pr1$idw = idw(zinc~1,meuse,meuse.grid)[[1]]
> # show side by side:
> spplot(pr1, c("var1.pred", "idw"), col.regions=bpy.colors())
> 
> ... missing values are generated for those cells that result in a
> singular covariance matrix, given their local neighbourhood of 30
> nearest observations.
> 
> cn_max referers to the maximum allowed condition number, see
> http://en.wikipedia.org/wiki/Condition_number
> 
> Two issues are (i) what singularity means when we use floating point
> representations for real numbers, and (ii) that condition numbers of
> matrices are expensive to evaluate, and an estimate based on the LU
> decomposition is used. I threshold to 1e10 here, but that is purely for
> illustrational purposes.
> 
> Note, for you of interest, that IIRC this thresholding is also done for
> singularity of the X matrix, holding the predictors.
> 
> All this information didn't make it to the help pages of the krige
> function. This help page would cover tens of pages otherwise. For full
> documentation, still the "old", gstat stand-alone manual on gstat.org is
> needed. I agree that this is not optimal.
> 
> With best wishes,
> --
> Edzer
> 
> 
> Tomislav Hengl wrote:
> > Hi Paul, Edzer,
> >
> > I understand why the singular matrix problem happens and I know that there is not really a
> > mathematical solution around it:
> >
> >
> >> x <- matrix(runif(100), nrow=10)
> >> x.i <- solve(x)
> >> str(x.i)
> >>
> >  num [1:10, 1:10] 0.8191 -1.0293 0.0826 1.068 -0.2106 ...
> > # add a 'singular' column
> >
> >> x[,1:10] <- rep(1, 10)
> >> x.i <- solve(x)
> >>
> > Error in solve.default(x) :
> >   Lapack routine dgesv: system is exactly singular
> >
> >
> > However, I would very much support if you would integrate an "if" loop to check if it will
> happen,
> > and then mask the prediction location using "NA".
> >
> > I mean, at the moment every time we want to run predictions, even if only at a single prediction
> > location the model fails, we are not able to generate any output (this is sometimes really
> > frustrating).
> >
> > Hence, I would support that you allow us to run predictions for all locations first, and then
> let
> > the users judge if one should increase the search radius, remove some too-uniform predictors etc
> > etc.
> >
> > I hope you agree with me,
> >
> > T. Hengl
> > http://home.medewerker.uva.nl/t.hengl/
> >
> >
> >
> >> -----Original Message-----
> >> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On
> Behalf
> >> Of Paul Hiemstra
> >> Sent: Tuesday, November 17, 2009 9:53 AM
> >> To: Edzer Pebesma
> >> Cc: r-sig-geo
> >> Subject: Re: [R-sig-Geo] 'LDLfactor' error in 'krige' function
> >>
> >> Edzer Pebesma wrote:
> >>
> >>> My guess is that from constant data, the (co)variance is constant and
> >>> zero, so the covariance matrix cannot be decomposed (hence: LDLfactor
> >>> errors).
> >>>
> >>> Is this a case that autokrige should catch?
> >>>
> >>>
> >> I added a check in autoKrige. The output for the example below is now:
> >>
> >> kriging_result = autoKrige(zinc~1, meuse)
> >> Error in autoKrige(zinc ~ 1, meuse) :
> >>   All data in attribute 'zinc' is identical and equal to 0
> >>    Can not interpolate this data
> >>
> >> A new version of automap with this feature has been uploaded to CRAN.
> >>
> >> cheers,
> >> Paul
> >>
> >>> --
> >>> Edzer
> >>>
> >>> Mauricio Zambrano wrote:
> >>>
> >>>
> >>>> Dear List,
> >>>>
> >>>> During some OK interpolations of daily precipitation, with the
> >>>> 'automap' library, I got the following error:
> >>>>
> >>>>
> >>>> [using ordinary kriging]
> >>>> "chfactor.c", line 130: singular matrix in function LDLfactor()
> >>>> Error en predict.gstat(g, newdata = newdata, block = block, nsim = nsim,  :
> >>>>   LDLfactor
> >>>>
> >>>>
> >>>> The code I'm using works fine for other days, so I assume that the
> >>>> distance between the measurement points is no the problem. When
> >>>> looking at the data that rose the error, I realized that all the
> >>>> measured values were equal to zero (I can not skip those days in which
> >>>> all the measured points have the same value in advance, because the
> >>>> measured value in those points change with time).
> >>>>
> >>>> According to a traceback that is given below, it seems that the cause
> >>>> is in the 'predict.gstat' function of the 'gstat' package.
> >>>>
> >>>> The same error can be risen with:
> >>>>
> >>>> # Data preparation
> >>>> data(meuse)
> >>>> coordinates(meuse) =~ x+y
> >>>> data(meuse.grid)
> >>>> gridded(meuse.grid) =~ x+y
> >>>>
> >>>> meuse$zinc <- meuse$zinc*0
> >>>> meuse$zinc
> >>>>
> >>>> # Ordinary kriging, no new_data object
> >>>> kriging_result = autoKrige(zinc~1, meuse)
> >>>>
> >>>>
> >>>> traceback()
> >>>> 6: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
> >>>> as.double(as.vector(raw$locations)),
> >>>>        as.vector(new.X), as.integer(block.cols), as.vector(block),
> >>>>        as.vector(bl_weights), as.integer(nsim), as.integer(BLUE))
> >>>> 5: predict.gstat(g, newdata = newdata, block = block, nsim = nsim,
> >>>>        indicators = indicators, na.action = na.action, debug.level =
> >>>> debug.level)
> >>>> 4: .local(formula, locations, ...)
> >>>> 3: krige(formula, input_data, new_data, variogram_object$var_model,
> >>>>        block = block, ...)
> >>>> 2: krige(formula, input_data, new_data, variogram_object$var_model,
> >>>>        block = block, ...)
> >>>> 1: autoKrige(zinc ~ 1, meuse)
> >>>>
> >>>>
> >>>> I would really appreciate any hint about the possible reason of this
> >>>> error and if it could be overcome in some way.
> >>>>
> >>>>
> >>>> Thanks in advance for any help.
> >>>>
> >>>>
> >>>> Mauricio
> >>>>
> >>>>
> >>>>
> >>>
> >> --
> >> Drs. Paul Hiemstra
> >> Department of Physical Geography
> >> Faculty of Geosciences
> >> University of Utrecht
> >> Heidelberglaan 2
> >> P.O. Box 80.115
> >> 3508 TC Utrecht
> >> Phone:  +3130 274 3113 Mon-Tue
> >> Phone:  +3130 253 5773 Wed-Fri
> >> http://intamap.geo.uu.nl/~paul
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> 
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From sebastiano.trevisani at libero.it  Tue Nov 17 15:10:53 2009
From: sebastiano.trevisani at libero.it (seba)
Date: Tue, 17 Nov 2009 15:10:53 +0100
Subject: [R-sig-Geo] limiting the number of variogram models in intamap
Message-ID: <01NG7C5SI1V20005EN@mx1.pd.cnr.it>

Dear list members

I'm using intamap packages and I need some help.
I would like to automatically calculate an anisotropic
variogram with the estimateParameters function limiting the number of 
variogram models
(i.e. I want the fitting of Sperical models).
In particular I tried to add an argument to estimateParameters function
such as  model=c("Sph") but it doesn't work.

Thank you in advance for your help

Sincerely
Sebastiano Trevisani


From j.skoien at geo.uu.nl  Tue Nov 17 15:58:26 2009
From: j.skoien at geo.uu.nl (Jon Olav Skoien)
Date: Tue, 17 Nov 2009 15:58:26 +0100
Subject: [R-sig-Geo] limiting the number of variogram models in intamap
In-Reply-To: <01NG7C5SI1V20005EN@mx1.pd.cnr.it>
References: <01NG7C5SI1V20005EN@mx1.pd.cnr.it>
Message-ID: <4B02BA12.4000701@geo.uu.nl>

Hi,

This is not possible in the version on CRAN now, but has been changed in 
the development version that you can find on one of the links below 
(depending on platform), should be on CRAN soon.
http://www.intamap.org/downloads/intamap_1.3-1.zip
http://www.intamap.org/downloads/intamap_1.3-1.tar.gz

Best wishes,
Jon


seba wrote:
> Dear list members
>
> I'm using intamap packages and I need some help.
> I would like to automatically calculate an anisotropic
> variogram with the estimateParameters function limiting the number of 
> variogram models
> (i.e. I want the fitting of Sperical models).
> In particular I tried to add an argument to estimateParameters function
> such as  model=c("Sph") but it doesn't work.
>
> Thank you in advance for your help
>
> Sincerely
> Sebastiano Trevisani
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From cara.tobin at epfl.ch  Tue Nov 17 19:43:01 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Tue, 17 Nov 2009 19:43:01 +0100
Subject: [R-sig-Geo] Kriging with NA values
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D3@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091117/0ba67794/attachment.pl>

From horacio.samaniego at gmail.com  Tue Nov 17 20:40:21 2009
From: horacio.samaniego at gmail.com (Horacio Samaniego)
Date: Tue, 17 Nov 2009 16:40:21 -0300
Subject: [R-sig-Geo] neighborhood analysis on patch systems
Message-ID: <cde5e0660911171140y2c70995q3117c3213c1dd595@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091117/72f046f3/attachment.pl>

From r.hijmans at gmail.com  Tue Nov 17 20:53:42 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 17 Nov 2009 11:53:42 -0800
Subject: [R-sig-Geo] Kriging with NA values
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D3@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D3@REX2.intranet.epfl.ch>
Message-ID: <dc22b2570911171153g275afaedtffa1b93981c7c42e@mail.gmail.com>

If you are interpolating precipitation you probably should not ignore
the zeros. If you want to log transform your values, perhaps you can
use log(x+1) instead of log(x). Robert

On Tue, Nov 17, 2009 at 10:43 AM, Tobin Cara <cara.tobin at epfl.ch> wrote:
> Hello,
>
> I am taking the log of precipitation values and therefore many are now NA values. I want to continue to krig my precipitation matrix.
>
> Is there a way to ignore these values with kriging.
>
> My attempt with is.nan still gives:
>
> Erreur : dimensions do not match: locations 105 and data 12
> Thank you so much for your time and assistance,
>
> Cara
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From hzambran.newsgroups at gmail.com  Wed Nov 18 13:00:34 2009
From: hzambran.newsgroups at gmail.com (Mauricio Zambrano)
Date: Wed, 18 Nov 2009 13:00:34 +0100
Subject: [R-sig-Geo] 'LDLfactor' error in 'krige' function
In-Reply-To: <4B029412.4020904@uni-muenster.de>
References: <63d616b0911160808q707006f5h32ca7abdfbd00933@mail.gmail.com>
	<4B017A79.10206@uni-muenster.de> <4B026485.60507@geo.uu.nl>
	<E4F8694C24224D1AAAD5D7854610585D@pcibed193>
	<63d616b0911170342v4ed4468dvd934af38f26ecd52@mail.gmail.com>
	<4B029412.4020904@uni-muenster.de>
Message-ID: <63d616b0911180400u37e894a7u680144993a423aff@mail.gmail.com>

2009/11/17 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:
> I just want to point out that "krige" has no problem with constant
> observations, as long as it is provided with a valid (i.e. semi negative
> definite, or something like that) variogram model.

Thanks for make this point clear.

> The problem is to automatically fit such a function from data that are constant, as they
> have zero (co)variance; this is done by automap/autofitvariogram and the
> like. Replacing an invalid (zero) variogram model with e.g. a
> (numerically) small nugget effect would already help, but raise two
> issues: (i) what is numerically small, and (ii) is that a realistic
> model for your data? Are near-zero prediction variances realistic for
> any process with constant measured values?

If all the measured values are constant, the more realistic
representation of the process should be the constant measured value
itself, because those data doesn't have a spatial structure that can
be represented by a variogram (please correct me if I'm wrong).

So, my solution for this case is returning a spatial grid where all
the cells have the same constant measured value, as suggested by Paul.

Kinds,

Mauricio

> --
> Edzer


>
> Mauricio Zambrano wrote:
>> Dear Paul and Edzer,
>>
>>
>> 2009/11/17 Tomislav Hengl <hengl at spatial-analyst.net>:
>>
>>> Hi Paul, Edzer,
>>>
>>> I understand why the singular matrix problem happens and I know that there is not really a
>>> mathematical solution around it:
>>>
>>>
>>>> x <- matrix(runif(100), nrow=10)
>>>> x.i <- solve(x)
>>>> str(x.i)
>>>>
>>> ?num [1:10, 1:10] 0.8191 -1.0293 0.0826 1.068 -0.2106 ...
>>> # add a 'singular' column
>>>
>>>> x[,1:10] <- rep(1, 10)
>>>> x.i <- solve(x)
>>>>
>>> Error in solve.default(x) :
>>> ?Lapack routine dgesv: system is exactly singular
>>>
>>>
>>> However, I would very much support if you would integrate an "if" loop to check if it will happen,
>>> and then mask the prediction location using "NA".
>>>
>>
>>
>>> I mean, at the moment every time we want to run predictions, even if only at a single prediction
>>> location the model fails, we are not able to generate any output (this is sometimes really
>>> frustrating).
>>>
>>
>> I agree with Tom that it may be really frustrating not to get any
>> output, even most when this situation happens within a loop that
>> involves many time steps. I know that the user can easily get rid of
>> this manually for a single prediction, but it should be better if the
>> check could be integrated into the 'krige' or the 'autoKrige'
>> function, but of course this is your decision.
>>
>>
>>
>>> Hence, I would support that you allow us to run predictions for all locations first, and then let
>>> the users judge if one should increase the search radius, remove some too-uniform predictors etc
>>> etc.
>>>
>>
>> In case you could allow us to run the predictions first, it shouldn't
>> be better to mask the prediction location with the constant value that
>> caused the error instead of NA ?. Or to have a flag that allow the
>> user to choose if to get an NA or the constant value ?
>>
>>
>> Kinds,
>>
>> Mauricio
>>
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>
>


From friendly at yorku.ca  Wed Nov 18 15:10:58 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 18 Nov 2009 09:10:58 -0500
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
Message-ID: <4B040072.6030701@yorku.ca>

The Guerry package contains two maps of france (gfrance, gfrance85) 
which are quite detailed and large in size (~900K).
In writing a vignette for the package, there are quite a few figures 
that use the map multiple times in a layout, and
consequently result in huge file sizes for the .PDF files created.  For 
these purposes, the map need not be nearly
so detailed.

I'm wondering if there is a facility to "thin" the map by drawing it at 
a lower density of lines in the polygon regions.
When I was working with SAS, there was a GREDUCE procedure that did this 
nicely.

thanks,
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From pinaud at cebc.cnrs.fr  Wed Nov 18 15:29:53 2009
From: pinaud at cebc.cnrs.fr (Pinaud David)
Date: Wed, 18 Nov 2009 15:29:53 +0100
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <4B040072.6030701@yorku.ca>
References: <4B040072.6030701@yorku.ca>
Message-ID: <4B0404E1.2070801@cebc.cnrs.fr>

Hi Michael,
maybe you should try the function dp() in the package shapefiles that is 
an implementation of the Douglas-Peucker polyLine simplification algorithm.
HTH
David

Michael Friendly a ?crit :
> The Guerry package contains two maps of france (gfrance, gfrance85) 
> which are quite detailed and large in size (~900K).
> In writing a vignette for the package, there are quite a few figures 
> that use the map multiple times in a layout, and
> consequently result in huge file sizes for the .PDF files created.  
> For these purposes, the map need not be nearly
> so detailed.
>
> I'm wondering if there is a facility to "thin" the map by drawing it 
> at a lower density of lines in the polygon regions.
> When I was working with SAS, there was a GREDUCE procedure that did 
> this nicely.
>
> thanks,
> -Michael
>

-- 
***************************************************
David PINAUD
Ing?nieur de Recherche "Analyses spatiales"

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
79360 Villiers-en-Bois, France 
poste 485
Tel: +33 (0)5.49.09.35.58
Fax: +33 (0)5.49.09.65.26
http://www.cebc.cnrs.fr/

***************************************************




__________ Information from ESET Mail Security, version of virus signature database 4618 (20091118) __________

The message was checked by ESET Mail Security.
http://www.eset.com

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pinaud.vcf
Type: text/x-vcard
Size: 324 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091118/1a6518ad/attachment.vcf>

From Roger.Bivand at nhh.no  Wed Nov 18 15:36:54 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Nov 2009 15:36:54 +0100 (CET)
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <4B040072.6030701@yorku.ca>
References: <4B040072.6030701@yorku.ca>
Message-ID: <alpine.LRH.2.00.0911181525560.24471@reclus.nhh.no>

On Wed, 18 Nov 2009, Michael Friendly wrote:

> The Guerry package contains two maps of france (gfrance, gfrance85) which are 
> quite detailed and large in size (~900K).
> In writing a vignette for the package, there are quite a few figures that use 
> the map multiple times in a layout, and
> consequently result in huge file sizes for the .PDF files created.  For these 
> purposes, the map need not be nearly
> so detailed.
>
> I'm wondering if there is a facility to "thin" the map by drawing it at a 
> lower density of lines in the polygon regions.
> When I was working with SAS, there was a GREDUCE procedure that did this 
> nicely.

Not yet - the interface to JTS in the cshapes package only uses line 
generalisation on the built-in data set. I'm looking at ways of 
interfacing GEOS, which does offer this, but it will take a little time to 
complete. For a quicker solution, there are facilities in GRASS in 
v.generalize.

Roger

>
> thanks,
> -Michael
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed Nov 18 15:43:50 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 18 Nov 2009 15:43:50 +0100 (CET)
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <4B0404E1.2070801@cebc.cnrs.fr>
References: <4B040072.6030701@yorku.ca> <4B0404E1.2070801@cebc.cnrs.fr>
Message-ID: <alpine.LRH.2.00.0911181540060.24471@reclus.nhh.no>

On Wed, 18 Nov 2009, Pinaud David wrote:

> Hi Michael,
> maybe you should try the function dp() in the package shapefiles that is an 
> implementation of the Douglas-Peucker polyLine simplification algorithm.

Note that its help page does warn that it is not topology-preserving, that 
is that lines are generalised, but that coincident lines (boundaries of 
neighbouring polygons) may be generalised differently. GEOS offers a 
topology-preserving line generalisation facility, which ought to take 
longer but do better than dp(), because it will not lead to visual 
artefacts (overlapping polygons, interpolygon slivers, etc.).

Roger

> HTH
> David
>
> Michael Friendly a ?crit :
>> The Guerry package contains two maps of france (gfrance, gfrance85) which 
>> are quite detailed and large in size (~900K).
>> In writing a vignette for the package, there are quite a few figures that 
>> use the map multiple times in a layout, and
>> consequently result in huge file sizes for the .PDF files created.  For 
>> these purposes, the map need not be nearly
>> so detailed.
>> 
>> I'm wondering if there is a facility to "thin" the map by drawing it at a 
>> lower density of lines in the polygon regions.
>> When I was working with SAS, there was a GREDUCE procedure that did this 
>> nicely.
>> 
>> thanks,
>> -Michael
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From friendly at yorku.ca  Wed Nov 18 20:18:10 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 18 Nov 2009 14:18:10 -0500
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.0911181540060.24471@reclus.nhh.no>
References: <4B040072.6030701@yorku.ca> <4B0404E1.2070801@cebc.cnrs.fr>
	<alpine.LRH.2.00.0911181540060.24471@reclus.nhh.no>
Message-ID: <4B044872.6020807@yorku.ca>

I think, for my application, I'd be happy with the D-P polyline 
simplification algorithm, because that is what is used
in SAS (worked well), and I don't think there are unusual topologies in 
my map of France that would be so severely
out of whack as to lead to *significant* visual artifacts.  In fact, you 
might well expect some artifacts from any visual
thinning, but it's a matter of the tradeoff in the way the thinned map 
is used in a visualization.  Mark Monmonier's
US Visibility Map might be an extremely thinned, but highly useful example.

For R spatial analysis, I think this is worth pursuing and integrating 
into sp methods.  In SAS, proc greduce works simply
by adding another variable, density, to the (x,y) coordinates of the 
spatial polygons, density %in% 1:5, where density==5
is the full map.  It is then a simple matter to subset the polygon 
outlines by saying

data smallmap;
    set mymap;
    where density<4;

or

proc gmap map=mymap(where=(density<4));
 ...

Meanwhile, I can't see easily how I could use shapefiles::dp() to thin 
my Guerry::gfrance maps, because the documentation is,
shall we say, somewhat thin. 

-Michael



Roger Bivand wrote:
> On Wed, 18 Nov 2009, Pinaud David wrote:
>
>> Hi Michael,
>> maybe you should try the function dp() in the package shapefiles that 
>> is an implementation of the Douglas-Peucker polyLine simplification 
>> algorithm.
>
> Note that its help page does warn that it is not topology-preserving, 
> that is that lines are generalised, but that coincident lines 
> (boundaries of neighbouring polygons) may be generalised differently. 
> GEOS offers a topology-preserving line generalisation facility, which 
> ought to take longer but do better than dp(), because it will not lead 
> to visual artefacts (overlapping polygons, interpolygon slivers, etc.).
>
> Roger
>
>> HTH
>> David
>>
>> Michael Friendly a ?crit :
>>> The Guerry package contains two maps of france (gfrance, gfrance85) 
>>> which are quite detailed and large in size (~900K).
>>> In writing a vignette for the package, there are quite a few figures 
>>> that use the map multiple times in a layout, and
>>> consequently result in huge file sizes for the .PDF files created.  
>>> For these purposes, the map need not be nearly
>>> so detailed.
>>>
>>> I'm wondering if there is a facility to "thin" the map by drawing it 
>>> at a lower density of lines in the polygon regions.
>>> When I was working with SAS, there was a GREDUCE procedure that did 
>>> this nicely.
>>>
>>> thanks,
>>> -Michael
>>>
>>
>>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From zua3 at cornell.edu  Wed Nov 18 22:28:43 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Wed, 18 Nov 2009 16:28:43 -0500
Subject: [R-sig-Geo] Parametric/Non parametric Probability Kriging: get
 misclassification of risks as hazardous (false positive) and safe (false
 negative) in gstat?
Message-ID: <4B04670B.5060102@cornell.edu>

Dear All,

I did OK and Gaussian simulations of 1000 realizations of  my groundwater arsenic data after  Box-cox transformation. From OK, I created a risk map  of probability of exceeding 0.200 ppm of water arsenic by parametric approach. I need help after this analysis to solving following issues:
1)    Is it possible in gstat to get misclassification  of risks as hazardous (false positive) and safe (false negative) as describe by Goovaerts (1997)  from this parametric or non-parametric approach.
II)  After simulation of 1000 realizations of ok, Is it possible to extract prediction variance of each simulations?

I have limited knowledge  in  geostatistic as well as R. 

Thanks 

Zia Ahmed


From pinaud at cebc.cnrs.fr  Thu Nov 19 10:59:01 2009
From: pinaud at cebc.cnrs.fr (Pinaud David)
Date: Thu, 19 Nov 2009 10:59:01 +0100
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <4B044872.6020807@yorku.ca>
References: <4B040072.6030701@yorku.ca> <4B0404E1.2070801@cebc.cnrs.fr>
	<alpine.LRH.2.00.0911181540060.24471@reclus.nhh.no>
	<4B044872.6020807@yorku.ca>
Message-ID: <4B0516E5.2050603@cebc.cnrs.fr>

Hi Michael,
Roger is fully right, this function does not preserve the topology, so 
be aware of that, some problems can occur...
If you want to use shapefiles::dp() just for raw plotting and visual 
simplification, you can try (on the fly):

library(rgdal)
library(shapefiles)

fr <- readOGR("polygonFRA_WGS84.shp", "polygonFRA_WGS84") # a shapefile 
of France with complex topology (holes, islands...) in WGS84 coordinates
pp <- slot(fr, "polygons") # take the polygons
cf <- coordinates(slot(pp[[39]], "Polygons")[[1]])  # extract the 
coordinates of the main polygon ("continental France")
pf <- list(x=cf[,1], y=cf[,2]) # list of coordinates, as dp() needs a 
list and not a matrix or dataframe...
cf1 <- dp(pf, 0.1) # simplification, with a bandwith of 0.1 decimal degree
plot(fr)  # to see the result
points(cf1, col="red", t="l")

HTH
David

Michael Friendly a ?crit :
> I think, for my application, I'd be happy with the D-P polyline 
> simplification algorithm, because that is what is used
> in SAS (worked well), and I don't think there are unusual topologies 
> in my map of France that would be so severely
> out of whack as to lead to *significant* visual artifacts.  In fact, 
> you might well expect some artifacts from any visual
> thinning, but it's a matter of the tradeoff in the way the thinned map 
> is used in a visualization.  Mark Monmonier's
> US Visibility Map might be an extremely thinned, but highly useful 
> example.
>
> For R spatial analysis, I think this is worth pursuing and integrating 
> into sp methods.  In SAS, proc greduce works simply
> by adding another variable, density, to the (x,y) coordinates of the 
> spatial polygons, density %in% 1:5, where density==5
> is the full map.  It is then a simple matter to subset the polygon 
> outlines by saying
>
> data smallmap;
>    set mymap;
>    where density<4;
>
> or
>
> proc gmap map=mymap(where=(density<4));
> ...
>
> Meanwhile, I can't see easily how I could use shapefiles::dp() to thin 
> my Guerry::gfrance maps, because the documentation is,
> shall we say, somewhat thin.
> -Michael
>
>
>
> Roger Bivand wrote:
>> On Wed, 18 Nov 2009, Pinaud David wrote:
>>
>>> Hi Michael,
>>> maybe you should try the function dp() in the package shapefiles 
>>> that is an implementation of the Douglas-Peucker polyLine 
>>> simplification algorithm.
>>
>> Note that its help page does warn that it is not topology-preserving, 
>> that is that lines are generalised, but that coincident lines 
>> (boundaries of neighbouring polygons) may be generalised differently. 
>> GEOS offers a topology-preserving line generalisation facility, which 
>> ought to take longer but do better than dp(), because it will not 
>> lead to visual artefacts (overlapping polygons, interpolygon slivers, 
>> etc.).
>>
>> Roger
>>
>>> HTH
>>> David
>>>
>>> Michael Friendly a ?crit :
>>>> The Guerry package contains two maps of france (gfrance, gfrance85) 
>>>> which are quite detailed and large in size (~900K).
>>>> In writing a vignette for the package, there are quite a few 
>>>> figures that use the map multiple times in a layout, and
>>>> consequently result in huge file sizes for the .PDF files created.  
>>>> For these purposes, the map need not be nearly
>>>> so detailed.
>>>>
>>>> I'm wondering if there is a facility to "thin" the map by drawing 
>>>> it at a lower density of lines in the polygon regions.
>>>> When I was working with SAS, there was a GREDUCE procedure that did 
>>>> this nicely.
>>>>
>>>> thanks,
>>>> -Michael
>>>>
>>>
>>>
>>
>
>

-- 
***************************************************
David PINAUD
Ing?nieur de Recherche "Analyses spatiales"

Centre d'Etudes Biologiques de Chiz? - CNRS UPR1934
79360 Villiers-en-Bois, France 
poste 485
Tel: +33 (0)5.49.09.35.58
Fax: +33 (0)5.49.09.65.26
http://www.cebc.cnrs.fr/

***************************************************




__________ Information from ESET Mail Security, version of virus signature database 4621 (20091119) __________

The message was checked by ESET Mail Security.
http://www.eset.com

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pinaud.vcf
Type: text/x-vcard
Size: 324 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091119/238327bd/attachment.vcf>

From Roger.Bivand at nhh.no  Thu Nov 19 13:02:11 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Nov 2009 13:02:11 +0100 (CET)
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <4B0516E5.2050603@cebc.cnrs.fr>
References: <4B040072.6030701@yorku.ca> <4B0404E1.2070801@cebc.cnrs.fr>
	<alpine.LRH.2.00.0911181540060.24471@reclus.nhh.no>
	<4B044872.6020807@yorku.ca> <4B0516E5.2050603@cebc.cnrs.fr>
Message-ID: <alpine.LRH.2.00.0911191253370.28000@reclus.nhh.no>

On Thu, 19 Nov 2009, Pinaud David wrote:

> Hi Michael,
> Roger is fully right, this function does not preserve the topology, so be 
> aware of that, some problems can occur...
> If you want to use shapefiles::dp() just for raw plotting and visual 
> simplification, you can try (on the fly):
>
> library(rgdal)
> library(shapefiles)
>
> fr <- readOGR("polygonFRA_WGS84.shp", "polygonFRA_WGS84") # a shapefile of 
> France with complex topology (holes, islands...) in WGS84 coordinates
> pp <- slot(fr, "polygons") # take the polygons
> cf <- coordinates(slot(pp[[39]], "Polygons")[[1]])  # extract the coordinates 
> of the main polygon ("continental France")
> pf <- list(x=cf[,1], y=cf[,2]) # list of coordinates, as dp() needs a list 
> and not a matrix or dataframe...
> cf1 <- dp(pf, 0.1) # simplification, with a bandwith of 0.1 decimal degree
> plot(fr)  # to see the result
> points(cf1, col="red", t="l")

This seems to work OK given that slivers are not important:
library(sp)
library(Guerry)
# installed from R-Forge
data(gfrance)
object.size(gfrance)
pls <- slot(gfrance, "polygons")
pls_dp <- vector(mode="list", length=length(pls))
require(shapefiles)
tol <- 2500
minarea <- 500000
for (i in 1:length(pls)) {
   Pls <- slot(pls[[i]], "Polygons")
   Pls_dp <- vector(mode="list", length=length(Pls))
   for (j in 1:length(Pls)) {
     crds <- slot(Pls[[j]], "coords")
     crds_s <- dp(list(x=crds[,1], y=crds[,2]), tolerance=tol)
     crds_s <- do.call("cbind", crds_s)
     if(!identical(crds_s[1,], crds_s[nrow(crds_s),]))
       crds_s <- rbind(crds_s, crds_s[1,])
     Pls_dp[[j]] <- Polygon(crds_s)
   }
   Keep <- logical(length(Pls_dp))
   for (j in 1:length(Pls_dp)) {
     Keep[j] <- TRUE
     if (slot(Pls_dp[[j]], "area") < minarea) Keep[j] <- FALSE
   }
   Pls_dp <- Pls_dp[Keep]
   pls_dp[[i]] <- Polygons(Pls_dp, ID=slot(pls[[i]], "ID"))
}
gfrance_dp <- SpatialPolygonsDataFrame(SpatialPolygons(pls_dp), 
data=slot(gfrance, "data"))
object.size(gfrance_dp)

If this was a function, the input would be an object inheriting from 
SpatialPolygons, the tolerance, and a minimum polygon area. The removal of 
small Polygon objects needs protecting from removing all belonging to a 
given Polygons object. The CRS also needs copying across. The objects are 
rebuilt to correct areas, centroids, plot orders, and the bounding box, 
all of which may change. For figures, the companion thread on R-help is 
relevant, PDF output for choropleth maps is often a good deal larger in 
file size than that of the equivalent PNG device.

I'll ask the shapefiles authors whether I can copy dp() to maptools and 
include suitable methods - this will help in benchmarking the future GEOS 
version.

Hope this helps,

Roger

>
> HTH
> David
>
> Michael Friendly a ?crit :
>> I think, for my application, I'd be happy with the D-P polyline 
>> simplification algorithm, because that is what is used
>> in SAS (worked well), and I don't think there are unusual topologies in my 
>> map of France that would be so severely
>> out of whack as to lead to *significant* visual artifacts.  In fact, you 
>> might well expect some artifacts from any visual
>> thinning, but it's a matter of the tradeoff in the way the thinned map is 
>> used in a visualization.  Mark Monmonier's
>> US Visibility Map might be an extremely thinned, but highly useful example.
>> 
>> For R spatial analysis, I think this is worth pursuing and integrating into 
>> sp methods.  In SAS, proc greduce works simply
>> by adding another variable, density, to the (x,y) coordinates of the 
>> spatial polygons, density %in% 1:5, where density==5
>> is the full map.  It is then a simple matter to subset the polygon outlines 
>> by saying
>> 
>> data smallmap;
>>    set mymap;
>>    where density<4;
>> 
>> or
>> 
>> proc gmap map=mymap(where=(density<4));
>> ...
>> 
>> Meanwhile, I can't see easily how I could use shapefiles::dp() to thin my 
>> Guerry::gfrance maps, because the documentation is,
>> shall we say, somewhat thin.
>> -Michael
>> 
>> 
>> 
>> Roger Bivand wrote:
>>> On Wed, 18 Nov 2009, Pinaud David wrote:
>>> 
>>>> Hi Michael,
>>>> maybe you should try the function dp() in the package shapefiles that is 
>>>> an implementation of the Douglas-Peucker polyLine simplification 
>>>> algorithm.
>>> 
>>> Note that its help page does warn that it is not topology-preserving, that 
>>> is that lines are generalised, but that coincident lines (boundaries of 
>>> neighbouring polygons) may be generalised differently. GEOS offers a 
>>> topology-preserving line generalisation facility, which ought to take 
>>> longer but do better than dp(), because it will not lead to visual 
>>> artefacts (overlapping polygons, interpolygon slivers, etc.).
>>> 
>>> Roger
>>> 
>>>> HTH
>>>> David
>>>> 
>>>> Michael Friendly a ?crit :
>>>>> The Guerry package contains two maps of france (gfrance, gfrance85) 
>>>>> which are quite detailed and large in size (~900K).
>>>>> In writing a vignette for the package, there are quite a few figures 
>>>>> that use the map multiple times in a layout, and
>>>>> consequently result in huge file sizes for the .PDF files created.  For 
>>>>> these purposes, the map need not be nearly
>>>>> so detailed.
>>>>> 
>>>>> I'm wondering if there is a facility to "thin" the map by drawing it at 
>>>>> a lower density of lines in the polygon regions.
>>>>> When I was working with SAS, there was a GREDUCE procedure that did this 
>>>>> nicely.
>>>>> 
>>>>> thanks,
>>>>> -Michael
>>>>> 
>>>> 
>>>> 
>>> 
>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From torleif.lunde at cih.uib.no  Thu Nov 19 13:28:55 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Thu, 19 Nov 2009 13:28:55 +0100
Subject: [R-sig-Geo] Spatial3dArray - coordinates method
In-Reply-To: <4B0516E5.2050603@cebc.cnrs.fr>
References: <4B040072.6030701@yorku.ca> <4B044872.6020807@yorku.ca>
	<4B0516E5.2050603@cebc.cnrs.fr>
Message-ID: <200911191328.55628.torleif.lunde@cih.uib.no>

Hi

To read netcdf data (or any other "gridded" spatial time data) I find it 
convenient to define new classes Spatial3dArray and Spatial4dArray.

 setClass("Spatial3dArray", 
	  representation("Spatial", data = "array", coords = "list", 
			  time = "character", btime = "character"),
	  prototype= list(data = array(NA, c(1,1,1,1)), 
			  bbox=matrix(NA), 
			  proj4string = CRS(as.character(NA)), 
			  coords = list(1,1),
			  time = "posix",
			  btime = "posix"))


##########################################
###################EXAMPLE##################
##########################################

x <- matrix(seq(-10, 10, length = 100), 100, 100, 
	    byrow = FALSE)
y <- matrix(seq(-10, 10, length = 100), 100, 100, 
	    byrow = TRUE)

tm <- 1:10
tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
				    "2002-01-01 15:00:00"), 
			  by="hours", 
			  length.out=10))

z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))

for (i in 1:10) {
z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
}

sin3dA <- new("Spatial3dArray", 
      data = z, 
      coords = list(x, y), 
      bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2, 
      dimnames = list(NULL, c("min","max"))), 
      time = tm.c,
      btime = c(min(tm.c), max(tm.c)))

dimnames(slot(sin3dA, "data")) = list(NULL, 
				      NULL, 
				      slot(sin3dA, "time"), 
				      c("a"))
names(slot(sin3dA, "coords")) <- c("x", "y")


##########################################

for the coordinates method I would like to have two options on how to return 
the coordinates; "list" or default "sp":

coordinates.3dArray <- function (obj, type = "sp") {	
	lat <- slot(obj, "coords")[[1]]
  	long <- slot(obj, "coords")[[2]]
  	if (type == "list") {
    		return(list(long=long, lat=lat))
    	} else if (type == "sp") {
		res <- as.matrix(cbind(c(long), c(lat)))
		dimnames(res) <- list(NULL, c("x1", "x2"))
	} 
}
setMethod("coordinates", signature("Spatial3dArray"), coordinates.3dArray)

This means that the default coordinates method in sp has to include the option 
"..." . Would it be possible to include this in a future release of sp? 

The reason I want to keep the list option is to use a matrix oriented approach 
in spplot, overlay, etc. methods. I also feel having a matrix/array approach 
with these kind of data makes sense. Allowing type = "sp" means overlay() will 
work more or less out of the box (however I would like to return a matrix), 
and still I could get the list/matrix when desired. 


Best wishes
Torleif Markussen Lunde
Centre for International Health
Bjerknes Centre for Climate Research
University of Bergen
Norway


From edzer.pebesma at uni-muenster.de  Thu Nov 19 14:26:35 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 19 Nov 2009 14:26:35 +0100
Subject: [R-sig-Geo] Spatial3dArray - coordinates method
In-Reply-To: <200911191328.55628.torleif.lunde@cih.uib.no>
References: <4B040072.6030701@yorku.ca>
	<4B044872.6020807@yorku.ca>	<4B0516E5.2050603@cebc.cnrs.fr>
	<200911191328.55628.torleif.lunde@cih.uib.no>
Message-ID: <4B05478B.3080800@uni-muenster.de>

No problems; sp in csv now has this, the next release will have it.

Torleif Markussen Lunde wrote:
> Hi
>
> To read netcdf data (or any other "gridded" spatial time data) I find it 
> convenient to define new classes Spatial3dArray and Spatial4dArray.
>
>  setClass("Spatial3dArray", 
> 	  representation("Spatial", data = "array", coords = "list", 
> 			  time = "character", btime = "character"),
> 	  prototype= list(data = array(NA, c(1,1,1,1)), 
> 			  bbox=matrix(NA), 
> 			  proj4string = CRS(as.character(NA)), 
> 			  coords = list(1,1),
> 			  time = "posix",
> 			  btime = "posix"))
>
>
> ##########################################
> ###################EXAMPLE##################
> ##########################################
>
> x <- matrix(seq(-10, 10, length = 100), 100, 100, 
> 	    byrow = FALSE)
> y <- matrix(seq(-10, 10, length = 100), 100, 100, 
> 	    byrow = TRUE)
>
> tm <- 1:10
> tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
> 				    "2002-01-01 15:00:00"), 
> 			  by="hours", 
> 			  length.out=10))
>
> z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))
>
> for (i in 1:10) {
> z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
> }
>
> sin3dA <- new("Spatial3dArray", 
>       data = z, 
>       coords = list(x, y), 
>       bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2, 
>       dimnames = list(NULL, c("min","max"))), 
>       time = tm.c,
>       btime = c(min(tm.c), max(tm.c)))
>
> dimnames(slot(sin3dA, "data")) = list(NULL, 
> 				      NULL, 
> 				      slot(sin3dA, "time"), 
> 				      c("a"))
> names(slot(sin3dA, "coords")) <- c("x", "y")
>
>
> ##########################################
>
> for the coordinates method I would like to have two options on how to return 
> the coordinates; "list" or default "sp":
>
> coordinates.3dArray <- function (obj, type = "sp") {	
> 	lat <- slot(obj, "coords")[[1]]
>   	long <- slot(obj, "coords")[[2]]
>   	if (type == "list") {
>     		return(list(long=long, lat=lat))
>     	} else if (type == "sp") {
> 		res <- as.matrix(cbind(c(long), c(lat)))
> 		dimnames(res) <- list(NULL, c("x1", "x2"))
> 	} 
> }
> setMethod("coordinates", signature("Spatial3dArray"), coordinates.3dArray)
>
> This means that the default coordinates method in sp has to include the option 
> "..." . Would it be possible to include this in a future release of sp? 
>
> The reason I want to keep the list option is to use a matrix oriented approach 
> in spplot, overlay, etc. methods. I also feel having a matrix/array approach 
> with these kind of data makes sense. Allowing type = "sp" means overlay() will 
> work more or less out of the box (however I would like to return a matrix), 
> and still I could get the list/matrix when desired. 
>
>
> Best wishes
> Torleif Markussen Lunde
> Centre for International Health
> Bjerknes Centre for Climate Research
> University of Bergen
> Norway
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From friendly at yorku.ca  Thu Nov 19 14:55:10 2009
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 19 Nov 2009 08:55:10 -0500
Subject: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
In-Reply-To: <alpine.LRH.2.00.0911191253370.28000@reclus.nhh.no>
References: <4B040072.6030701@yorku.ca> <4B0404E1.2070801@cebc.cnrs.fr>
	<alpine.LRH.2.00.0911181540060.24471@reclus.nhh.no>
	<4B044872.6020807@yorku.ca> <4B0516E5.2050603@cebc.cnrs.fr>
	<alpine.LRH.2.00.0911191253370.28000@reclus.nhh.no>
Message-ID: <4B054E3E.4060005@yorku.ca>

Thanks very much for doing the heavy lifting here, Roger.

For use in the Guerry package, I've turned this into a function (rather 
than saving other versions of gfrance).

If you include something like this in sp, I'll withdraw it from Guerry.

thinnedSpatialPoly <- function(SP, tolerance, minarea) {
  if (!require(shapefiles)) stop("shapefiles package is required")
  stopifnot(inherits(SP, "SpatialPolygons"))

    # TODO: determine and set defaults for tolerance, minarea 
    # TODO: suppress warnings: "In Polygon(crds_s) : Non-finite label 
point detected and replaced"
  pls <- slot(SP, "polygons")
  pls_dp <- vector(mode="list", length=length(pls))
  for (i in 1:length(pls)) {
    Pls <- slot(pls[[i]], "Polygons")
    Pls_dp <- vector(mode="list", length=length(Pls))
    for (j in 1:length(Pls)) {
      crds <- slot(Pls[[j]], "coords")
      crds_s <- dp(list(x=crds[,1], y=crds[,2]), tolerance=tolerance)
      crds_s <- do.call("cbind", crds_s)
      if(!identical(crds_s[1,], crds_s[nrow(crds_s),]))
        crds_s <- rbind(crds_s, crds_s[1,])
      Pls_dp[[j]] <- Polygon(crds_s)
    }
    Keep <- logical(length(Pls_dp))
    for (j in 1:length(Pls_dp)) {
      Keep[j] <- TRUE
      if (slot(Pls_dp[[j]], "area") < minarea) Keep[j] <- FALSE
    }
    Pls_dp <- Pls_dp[Keep]
    pls_dp[[i]] <- Polygons(Pls_dp, ID=slot(pls[[i]], "ID"))
  }
    SP_dp <- SpatialPolygons(pls_dp, proj4string=slot(SP, "proj4string"))
  if(inherits(SP, "SpatialPolygonsDataFrame")) {
    data <- slot(SP, "data")
    SP_dp <- SpatialPolygonsDataFrame(SP_dp, data=data)
  }
  SP_dp
}

best,
-Michael


Roger Bivand wrote:
> On Thu, 19 Nov 2009, Pinaud David wrote:
>
>> Hi Michael,
>> Roger is fully right, this function does not preserve the topology, 
>> so be aware of that, some problems can occur...
>> If you want to use shapefiles::dp() just for raw plotting and visual 
>> simplification, you can try (on the fly):
>>
>> library(rgdal)
>> library(shapefiles)
>>
>> fr <- readOGR("polygonFRA_WGS84.shp", "polygonFRA_WGS84") # a 
>> shapefile of France with complex topology (holes, islands...) in 
>> WGS84 coordinates
>> pp <- slot(fr, "polygons") # take the polygons
>> cf <- coordinates(slot(pp[[39]], "Polygons")[[1]])  # extract the 
>> coordinates of the main polygon ("continental France")
>> pf <- list(x=cf[,1], y=cf[,2]) # list of coordinates, as dp() needs a 
>> list and not a matrix or dataframe...
>> cf1 <- dp(pf, 0.1) # simplification, with a bandwith of 0.1 decimal 
>> degree
>> plot(fr)  # to see the result
>> points(cf1, col="red", t="l")
>
> This seems to work OK given that slivers are not important:
> library(sp)
> library(Guerry)
> # installed from R-Forge
> data(gfrance)
> object.size(gfrance)
> pls <- slot(gfrance, "polygons")
> pls_dp <- vector(mode="list", length=length(pls))
> require(shapefiles)
> tol <- 2500
> minarea <- 500000
> for (i in 1:length(pls)) {
>   Pls <- slot(pls[[i]], "Polygons")
>   Pls_dp <- vector(mode="list", length=length(Pls))
>   for (j in 1:length(Pls)) {
>     crds <- slot(Pls[[j]], "coords")
>     crds_s <- dp(list(x=crds[,1], y=crds[,2]), tolerance=tol)
>     crds_s <- do.call("cbind", crds_s)
>     if(!identical(crds_s[1,], crds_s[nrow(crds_s),]))
>       crds_s <- rbind(crds_s, crds_s[1,])
>     Pls_dp[[j]] <- Polygon(crds_s)
>   }
>   Keep <- logical(length(Pls_dp))
>   for (j in 1:length(Pls_dp)) {
>     Keep[j] <- TRUE
>     if (slot(Pls_dp[[j]], "area") < minarea) Keep[j] <- FALSE
>   }
>   Pls_dp <- Pls_dp[Keep]
>   pls_dp[[i]] <- Polygons(Pls_dp, ID=slot(pls[[i]], "ID"))
> }
> gfrance_dp <- SpatialPolygonsDataFrame(SpatialPolygons(pls_dp), 
> data=slot(gfrance, "data"))
> object.size(gfrance_dp)
>
> If this was a function, the input would be an object inheriting from 
> SpatialPolygons, the tolerance, and a minimum polygon area. The 
> removal of small Polygon objects needs protecting from removing all 
> belonging to a given Polygons object. The CRS also needs copying 
> across. The objects are rebuilt to correct areas, centroids, plot 
> orders, and the bounding box, all of which may change. For figures, 
> the companion thread on R-help is relevant, PDF output for choropleth 
> maps is often a good deal larger in file size than that of the 
> equivalent PNG device.
>
> I'll ask the shapefiles authors whether I can copy dp() to maptools 
> and include suitable methods - this will help in benchmarking the 
> future GEOS version.
>
> Hope this helps,
>
> Roger
>
>>
>> HTH
>> David
>>
>> Michael Friendly a ?crit :
>>> I think, for my application, I'd be happy with the D-P polyline 
>>> simplification algorithm, because that is what is used
>>> in SAS (worked well), and I don't think there are unusual topologies 
>>> in my map of France that would be so severely
>>> out of whack as to lead to *significant* visual artifacts.  In fact, 
>>> you might well expect some artifacts from any visual
>>> thinning, but it's a matter of the tradeoff in the way the thinned 
>>> map is used in a visualization.  Mark Monmonier's
>>> US Visibility Map might be an extremely thinned, but highly useful 
>>> example.
>>>
>>> For R spatial analysis, I think this is worth pursuing and 
>>> integrating into sp methods.  In SAS, proc greduce works simply
>>> by adding another variable, density, to the (x,y) coordinates of the 
>>> spatial polygons, density %in% 1:5, where density==5
>>> is the full map.  It is then a simple matter to subset the polygon 
>>> outlines by saying
>>>
>>> data smallmap;
>>>    set mymap;
>>>    where density<4;
>>>
>>> or
>>>
>>> proc gmap map=mymap(where=(density<4));
>>> ...
>>>
>>> Meanwhile, I can't see easily how I could use shapefiles::dp() to 
>>> thin my Guerry::gfrance maps, because the documentation is,
>>> shall we say, somewhat thin.
>>> -Michael
>>>
>>>
>>>
>>> Roger Bivand wrote:
>>>> On Wed, 18 Nov 2009, Pinaud David wrote:
>>>>
>>>>> Hi Michael,
>>>>> maybe you should try the function dp() in the package shapefiles 
>>>>> that is an implementation of the Douglas-Peucker polyLine 
>>>>> simplification algorithm.
>>>>
>>>> Note that its help page does warn that it is not 
>>>> topology-preserving, that is that lines are generalised, but that 
>>>> coincident lines (boundaries of neighbouring polygons) may be 
>>>> generalised differently. GEOS offers a topology-preserving line 
>>>> generalisation facility, which ought to take longer but do better 
>>>> than dp(), because it will not lead to visual artefacts 
>>>> (overlapping polygons, interpolygon slivers, etc.).
>>>>
>>>> Roger
>>>>
>>>>> HTH
>>>>> David
>>>>>
>>>>> Michael Friendly a ?crit :
>>>>>> The Guerry package contains two maps of france (gfrance, 
>>>>>> gfrance85) which are quite detailed and large in size (~900K).
>>>>>> In writing a vignette for the package, there are quite a few 
>>>>>> figures that use the map multiple times in a layout, and
>>>>>> consequently result in huge file sizes for the .PDF files 
>>>>>> created.  For these purposes, the map need not be nearly
>>>>>> so detailed.
>>>>>>
>>>>>> I'm wondering if there is a facility to "thin" the map by drawing 
>>>>>> it at a lower density of lines in the polygon regions.
>>>>>> When I was working with SAS, there was a GREDUCE procedure that 
>>>>>> did this nicely.
>>>>>>
>>>>>> thanks,
>>>>>> -Michael
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>
>>
>>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA


From cara.tobin at epfl.ch  Thu Nov 19 15:16:23 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Thu, 19 Nov 2009 15:16:23 +0100
Subject: [R-sig-Geo] Filling in holes in DTM
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D9@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091119/ed80cf85/attachment.pl>

From milton.ruser at gmail.com  Thu Nov 19 16:04:58 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 19 Nov 2009 10:04:58 -0500
Subject: [R-sig-Geo] Filling in holes in DTM
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D9@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D9@REX2.intranet.epfl.ch>
Message-ID: <3aaf1a030911190704s78a9fa2ah2fb3ee444be9a1e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091119/a619f998/attachment.pl>

From hengl at spatial-analyst.net  Thu Nov 19 16:14:56 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Thu, 19 Nov 2009 16:14:56 +0100
Subject: [R-sig-Geo] Filling in holes in DTM
Message-ID: <4117908DD26B4334AC97EE4600F89019@pcibed193>


Hi Cara, 

There is a very efficient function in SAGA called "Close Gaps" that does exactly that. What makes it
especially efficient is that it allows you to set a mask map. See:

> rsaga.get.usage("grid_tools", 7)
SAGA CMD 2.0.3
library path:   C:/Progra~1/saga_vc/modules
library name:   grid_tools
module name :   Close Gaps
Usage: 7 -INPUT <str> [-MASK <str>] [-RESULT <str>] [-THRESHOLD <str>]
  -INPUT:<str>          Grid
        Grid (input)
  -MASK:<str>           Mask
        Grid (optional input)
  -RESULT:<str>         Changed Grid
        Grid (optional output)
  -THRESHOLD:<str>      Tension Threshold

BR,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Tobin Cara
> Sent: Thursday, November 19, 2009 3:16 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Filling in holes in DTM
> 
> Hello,
> 
> Would anyone know a good way to fill in holes within a DTM? There is no data inside these holes
> and it is affecting my calculations, so I prefer for an interpolation of the nearest neighbors to
> fill in a value or something similar.
> 
> Thank you,
> 
> Cara
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Thu Nov 19 18:09:57 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 19 Nov 2009 18:09:57 +0100
Subject: [R-sig-Geo] execGRASS() for r.mapcalc?
Message-ID: <4B057BE5.8040908@gmail.com>

I'm used to do:
 > cmd = "r.mapcalc 'delme=100'"
 > system(cmd)

and works, but how could I do the equivalent using execGRASS() ?
I've tried:

 > doGRASS(cmd)
Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed

 > execGRASS(cmd)
Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed

I can always use paste() to make any cmd string, but seems to me that 
execGRASS() would be cleaner.

Thanks

Agus


From blair.christian at gmail.com  Thu Nov 19 18:39:15 2009
From: blair.christian at gmail.com (Blair Christian)
Date: Thu, 19 Nov 2009 12:39:15 -0500
Subject: [R-sig-Geo] Lambert projection to lat/long question....
Message-ID: <6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d@mail.gmail.com>

Hi All,

Before trying to reinvent the wheel, I was wondering if the mapproj or
any other library had code to take lambert coordinates (along with the
parameters used to generate them) and convert them to lat long.? I
have grid data in lambert coords, and want to generate the long/lat
grid corners from them.? I noticed mapproj goes long/lat ->
projection, but couldn't find anything to go the other way.  I was
going to use the reference in wolfram mathworld to do the inverse
transform, if anybody has any issues with their version.

http://mathworld.wolfram.com/LambertConformalConicProjection.html

Basically, I want to keep the data stored as grids, but every now and
then I want to create distance matrices or plot them (which I
currently do with an irregular grid class I made up), but don't want
to store polygons all the time when I can just store the basic grid.
All comments welcome.

Thanks,
Blair


From r.hijmans at gmail.com  Thu Nov 19 18:40:44 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 19 Nov 2009 09:40:44 -0800
Subject: [R-sig-Geo] Filling in holes in DTM
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D9@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8D9@REX2.intranet.epfl.ch>
Message-ID: <dc22b2570911190940u62269dbbo2392da32b0019a9d@mail.gmail.com>

Tobin,

In the raster package you can use the focalNA function. It sets the
focal (neighborhood) value, according to a specified function (e.g.
mean), to cells with NA.

raster is available on R-Forge:  install.packages("raster",
repos="http://R-Forge.R-project.org")

Robert

On Thu, Nov 19, 2009 at 6:16 AM, Tobin Cara <cara.tobin at epfl.ch> wrote:
> Hello,
>
> Would anyone know a good way to fill in holes within a DTM? There is no data inside these holes and it is affecting my calculations, so I prefer for an interpolation of the nearest neighbors to fill in a value or something similar.
>
> Thank you,
>
> Cara
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Thu Nov 19 18:44:32 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 19 Nov 2009 09:44:32 -0800
Subject: [R-sig-Geo] Lambert projection to lat/long question....
In-Reply-To: <6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d@mail.gmail.com>
References: <6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d@mail.gmail.com>
Message-ID: <dc22b2570911190944l49cafe4fx7b4367bf7e466e72@mail.gmail.com>

Blair: Have a look at spTransform in rgdal. Robert

On Thu, Nov 19, 2009 at 9:39 AM, Blair Christian
<blair.christian at gmail.com> wrote:
> Hi All,
>
> Before trying to reinvent the wheel, I was wondering if the mapproj or
> any other library had code to take lambert coordinates (along with the
> parameters used to generate them) and convert them to lat long.? I
> have grid data in lambert coords, and want to generate the long/lat
> grid corners from them.? I noticed mapproj goes long/lat ->
> projection, but couldn't find anything to go the other way. ?I was
> going to use the reference in wolfram mathworld to do the inverse
> transform, if anybody has any issues with their version.
>
> http://mathworld.wolfram.com/LambertConformalConicProjection.html
>
> Basically, I want to keep the data stored as grids, but every now and
> then I want to create distance matrices or plot them (which I
> currently do with an irregular grid class I made up), but don't want
> to store polygons all the time when I can just store the basic grid.
> All comments welcome.
>
> Thanks,
> Blair
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Thu Nov 19 18:46:13 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 19 Nov 2009 09:46:13 -0800
Subject: [R-sig-Geo] Lambert projection to lat/long question....
In-Reply-To: <6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d@mail.gmail.com>
References: <6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d@mail.gmail.com>
Message-ID: <dc22b2570911190946w7f5d668bpa233ecb2763f24ad@mail.gmail.com>

Blair, sorry, too quick:

Have a look at spTransform in rgdal and at projectRaster in the raster package.

Robert


On Thu, Nov 19, 2009 at 9:39 AM, Blair Christian
<blair.christian at gmail.com> wrote:
> Hi All,
>
> Before trying to reinvent the wheel, I was wondering if the mapproj or
> any other library had code to take lambert coordinates (along with the
> parameters used to generate them) and convert them to lat long.? I
> have grid data in lambert coords, and want to generate the long/lat
> grid corners from them.? I noticed mapproj goes long/lat ->
> projection, but couldn't find anything to go the other way. ?I was
> going to use the reference in wolfram mathworld to do the inverse
> transform, if anybody has any issues with their version.
>
> http://mathworld.wolfram.com/LambertConformalConicProjection.html
>
> Basically, I want to keep the data stored as grids, but every now and
> then I want to create distance matrices or plot them (which I
> currently do with an irregular grid class I made up), but don't want
> to store polygons all the time when I can just store the basic grid.
> All comments welcome.
>
> Thanks,
> Blair
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alobolistas at gmail.com  Thu Nov 19 18:46:24 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 19 Nov 2009 18:46:24 +0100
Subject: [R-sig-Geo] flags in execGRASS
Message-ID: <4B058470.9000300@gmail.com>

Hi!
The following works:
 > 
doGRASS("r.grow.distance",flags=c("overwrite"),parameters=list(distance="dummyd",input="dummy"))
[1] "r.grow.distance --overwrite distance=dummyd input=dummy"

But using "o" instead of "overwrite" does not
 > 
doGRASS("r.grow.distance",flags=c("o"),parameters=list(distance="dummyd",input="dummy"))
Error in doGRASS("r.grow.distance", flags = c("o"), parameters = list(distance = 
"dummyd",  :
   Invalid flag value: o

despite the fact that the grass manual states:
 > r.grow.distance --help
...(stuff deleted)

Usage:
  r.grow.distance input=name [distance=name] [value=name]
    [metric=string] [--overwrite] [--verbose] [--quiet]

Flags:
  --o   Allow output files to overwrite existing files
  --v   Verbose module output
  --q   Quiet module output
...(stuff deleted)

Could it be possible that execGRASS accept both forms for consistency with the 
grass command? If this is not possible or appropriate, could a note be added to 
the execGRASS manual page?

Thanks

Agus


From blair.christian at gmail.com  Thu Nov 19 18:56:35 2009
From: blair.christian at gmail.com (Blair Christian)
Date: Thu, 19 Nov 2009 12:56:35 -0500
Subject: [R-sig-Geo] Lambert projection to lat/long question....
In-Reply-To: <dc22b2570911190946w7f5d668bpa233ecb2763f24ad@mail.gmail.com>
References: <6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d@mail.gmail.com> 
	<dc22b2570911190946w7f5d668bpa233ecb2763f24ad@mail.gmail.com>
Message-ID: <6c35a4fc0911190956x16b99092w2908ae9e0982765b@mail.gmail.com>

Those are perfect.  I wish I had the time to contribute as much
software as you do, Robert.  Very impressive contributions on the
r-forge pages.

Thanks,
Blair

On Thu, Nov 19, 2009 at 12:46 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Blair, sorry, too quick:
>
> Have a look at spTransform in rgdal and at projectRaster in the raster package.
>
> Robert
>
>
> On Thu, Nov 19, 2009 at 9:39 AM, Blair Christian
> <blair.christian at gmail.com> wrote:
>> Hi All,
>>
>> Before trying to reinvent the wheel, I was wondering if the mapproj or
>> any other library had code to take lambert coordinates (along with the
>> parameters used to generate them) and convert them to lat long.? I
>> have grid data in lambert coords, and want to generate the long/lat
>> grid corners from them.? I noticed mapproj goes long/lat ->
>> projection, but couldn't find anything to go the other way. ?I was
>> going to use the reference in wolfram mathworld to do the inverse
>> transform, if anybody has any issues with their version.
>>
>> http://mathworld.wolfram.com/LambertConformalConicProjection.html
>>
>> Basically, I want to keep the data stored as grids, but every now and
>> then I want to create distance matrices or plot them (which I
>> currently do with an irregular grid class I made up), but don't want
>> to store polygons all the time when I can just store the basic grid.
>> All comments welcome.
>>
>> Thanks,
>> Blair
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From Roger.Bivand at nhh.no  Thu Nov 19 19:26:55 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Nov 2009 19:26:55 +0100 (CET)
Subject: [R-sig-Geo] execGRASS() for r.mapcalc?
In-Reply-To: <4B057BE5.8040908@gmail.com>
References: <4B057BE5.8040908@gmail.com>
Message-ID: <alpine.LRH.2.00.0911191921260.28832@reclus.nhh.no>

On Thu, 19 Nov 2009, Agustin Lobo wrote:

> I'm used to do:
>> cmd = "r.mapcalc 'delme=100'"
>> system(cmd)
>
> and works, but how could I do the equivalent using execGRASS() ?

You cannot. r.mapcalc does not provide an --interface-description XML 
self-definition. You have either to use system() as before (with different 
quoting reimes for different OS), or r.mapcalculator in execGRASS(). This 
problem is shared with other interfaces using --interface-description.

Roger

> I've tried:
>
>> doGRASS(cmd)
> Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed
>
>> execGRASS(cmd)
> Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed
>
> I can always use paste() to make any cmd string, but seems to me that 
> execGRASS() would be cleaner.
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Nov 19 19:34:50 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 19 Nov 2009 19:34:50 +0100 (CET)
Subject: [R-sig-Geo] flags in execGRASS
In-Reply-To: <4B058470.9000300@gmail.com>
References: <4B058470.9000300@gmail.com>
Message-ID: <alpine.LRH.2.00.0911191927160.28832@reclus.nhh.no>

On Thu, 19 Nov 2009, Agustin Lobo wrote:

> Hi!
> The following works:
>> 
> doGRASS("r.grow.distance",flags=c("overwrite"),parameters=list(distance="dummyd",input="dummy"))
> [1] "r.grow.distance --overwrite distance=dummyd input=dummy"
>
> But using "o" instead of "overwrite" does not

Because only "overwrite" is included in

r.grow.distance --interface-description

and that is what the flags are checked against. Unfortunately, many XML 
descriptions are more demanding than the help pages, but for parseGRASS() 
to work, it must use the self-definition without exception. execGRASS() is 
designed for scripting, in which case keeping to tighter limits than the 
help pages is OK. Some commands have both "o" and "overwrite" for 
different things too, so confusion would ensue.

Roger

>> 
> doGRASS("r.grow.distance",flags=c("o"),parameters=list(distance="dummyd",input="dummy"))
> Error in doGRASS("r.grow.distance", flags = c("o"), parameters = 
> list(distance = "dummyd",  :
>  Invalid flag value: o
>
> despite the fact that the grass manual states:
>> r.grow.distance --help
> ...(stuff deleted)
>
> Usage:
> r.grow.distance input=name [distance=name] [value=name]
>   [metric=string] [--overwrite] [--verbose] [--quiet]
>
> Flags:
> --o   Allow output files to overwrite existing files
> --v   Verbose module output
> --q   Quiet module output
> ...(stuff deleted)
>
> Could it be possible that execGRASS accept both forms for consistency with 
> the grass command? If this is not possible or appropriate, could a note be 
> added to the execGRASS manual page?
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mdsumner at gmail.com  Thu Nov 19 20:23:35 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 20 Nov 2009 06:23:35 +1100
Subject: [R-sig-Geo] Spatial3dArray - coordinates method
In-Reply-To: <4B05478B.3080800@uni-muenster.de>
References: <4B040072.6030701@yorku.ca> <4B044872.6020807@yorku.ca>
	<4B0516E5.2050603@cebc.cnrs.fr>
	<200911191328.55628.torleif.lunde@cih.uib.no>
	<4B05478B.3080800@uni-muenster.de>
Message-ID: <522664f80911191123u644807ccx7973ce8f734a0afe@mail.gmail.com>

Wow, this is great - I was thinking about this just yesterday.

Torleif: do you have an opinion on which NetCDF path is the most
useful for R with sp? RNetCDF or ncdf? GDAL is workable but takes
extra effort to build and then reconstruct 3d/4d from 2d bands. (I use
Windows mostly)

I use the RNetCDF package a lot, mainly because that's the one I
learnt to use first - there are binaries for Windows. It has some
problems in terms of R-style but they could be easily fixed.

Regards, Mike.

On Fri, Nov 20, 2009 at 12:26 AM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> No problems; sp in csv now has this, the next release will have it.
>
> Torleif Markussen Lunde wrote:
>> Hi
>>
>> To read netcdf data (or any other "gridded" spatial time data) I find it
>> convenient to define new classes Spatial3dArray and Spatial4dArray.
>>
>> ?setClass("Spatial3dArray",
>> ? ? ? ? representation("Spatial", data = "array", coords = "list",
>> ? ? ? ? ? ? ? ? ? ? ? ? time = "character", btime = "character"),
>> ? ? ? ? prototype= list(data = array(NA, c(1,1,1,1)),
>> ? ? ? ? ? ? ? ? ? ? ? ? bbox=matrix(NA),
>> ? ? ? ? ? ? ? ? ? ? ? ? proj4string = CRS(as.character(NA)),
>> ? ? ? ? ? ? ? ? ? ? ? ? coords = list(1,1),
>> ? ? ? ? ? ? ? ? ? ? ? ? time = "posix",
>> ? ? ? ? ? ? ? ? ? ? ? ? btime = "posix"))
>>
>>
>> ##########################################
>> ###################EXAMPLE##################
>> ##########################################
>>
>> x <- matrix(seq(-10, 10, length = 100), 100, 100,
>> ? ? ? ? ? byrow = FALSE)
>> y <- matrix(seq(-10, 10, length = 100), 100, 100,
>> ? ? ? ? ? byrow = TRUE)
>>
>> tm <- 1:10
>> tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "2002-01-01 15:00:00"),
>> ? ? ? ? ? ? ? ? ? ? ? ? by="hours",
>> ? ? ? ? ? ? ? ? ? ? ? ? length.out=10))
>>
>> z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))
>>
>> for (i in 1:10) {
>> z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
>> }
>>
>> sin3dA <- new("Spatial3dArray",
>> ? ? ? data = z,
>> ? ? ? coords = list(x, y),
>> ? ? ? bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2,
>> ? ? ? dimnames = list(NULL, c("min","max"))),
>> ? ? ? time = tm.c,
>> ? ? ? btime = c(min(tm.c), max(tm.c)))
>>
>> dimnames(slot(sin3dA, "data")) = list(NULL,
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NULL,
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? slot(sin3dA, "time"),
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? c("a"))
>> names(slot(sin3dA, "coords")) <- c("x", "y")
>>
>>
>> ##########################################
>>
>> for the coordinates method I would like to have two options on how to return
>> the coordinates; "list" or default "sp":
>>
>> coordinates.3dArray <- function (obj, type = "sp") {
>> ? ? ? lat <- slot(obj, "coords")[[1]]
>> ? ? ? long <- slot(obj, "coords")[[2]]
>> ? ? ? if (type == "list") {
>> ? ? ? ? ? ? ? return(list(long=long, lat=lat))
>> ? ? ? } else if (type == "sp") {
>> ? ? ? ? ? ? ? res <- as.matrix(cbind(c(long), c(lat)))
>> ? ? ? ? ? ? ? dimnames(res) <- list(NULL, c("x1", "x2"))
>> ? ? ? }
>> }
>> setMethod("coordinates", signature("Spatial3dArray"), coordinates.3dArray)
>>
>> This means that the default coordinates method in sp has to include the option
>> "..." . Would it be possible to include this in a future release of sp?
>>
>> The reason I want to keep the list option is to use a matrix oriented approach
>> in spplot, overlay, etc. methods. I also feel having a matrix/array approach
>> with these kind of data makes sense. Allowing type = "sp" means overlay() will
>> work more or less out of the box (however I would like to return a matrix),
>> and still I could get the list/matrix when desired.
>>
>>
>> Best wishes
>> Torleif Markussen Lunde
>> Centre for International Health
>> Bjerknes Centre for Climate Research
>> University of Bergen
>> Norway
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From torleif.lunde at cih.uib.no  Thu Nov 19 23:34:37 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Thu, 19 Nov 2009 23:34:37 +0100
Subject: [R-sig-Geo] Spatial3dArray - coordinates method
In-Reply-To: <522664f80911191123u644807ccx7973ce8f734a0afe@mail.gmail.com>
References: <4B040072.6030701@yorku.ca> <4B05478B.3080800@uni-muenster.de>
	<522664f80911191123u644807ccx7973ce8f734a0afe@mail.gmail.com>
Message-ID: <200911192334.37645.torleif.lunde@cih.uib.no>

Hi Mike

At the moment I have written wrapper functions around ncdf. As in get.var.ncdf 
you can subset which area to read, and which (continuous) time dimensions you 
want to read. At the moment the functions (to correctly return time, lat and 
long) are limited to output from the WRF-model (http://www.wrf-model.org/), 
but it could easily be modified to other netcdf files as long you know the name 
of lat, long and time. 

If r-forge accepts my application (delivered yesterday) the methods should 
appear there soon as rwrf. 

Since ncdf works "out of the box" on Fedora I landed on that one. I also 
tested it on windows XP, and no problems there either. It is a couple of years 
since I tried RNetCDF, so I should not speak to strongly in favor for any of 
them. Of course the bad thing with both is that they have not been updated for 
a while. Still my impression is that they are both superior to GDALs NetCDF 
support(?). 

If the classes proves to be robust and the quality is sufficient it would be 
natural to include them in the sp package in the future (instead of having to 
dig around to look for sp classes). Currently spplot methods for 
Spatial3dArray only support plotting of single times for levelplot, 
contourplot, and wireframe (unless animation is requested). I have some 
problems with the lattice graphics inside functions (also with print()) that 
needs to be sorted out first. 

Examples:
first convert Spatial3dArray to data.frame
print(levelplot(z~long*lat | time, data = tmp.df, aspect="iso"))
will cause the last time to over plot all frames inside a function. 

What could work is:


for (i in 1:2) {
  if (i == 1) { 
    a <- paste('c(slot(surf, "data")[ , , ', i, ',2])', 
		sep = "")
  } else {
      a <- paste(a, ' + c(slot(surf, "data")[ , , ', i, ',2])', 
		  sep = "")
  }
}

levelplot(parse(text=a)~ 
	    c(slot(surf, "coords")$long) * c(slot(surf, "coords")$lat), 
	    strip = strip.custom(factor.levels=c("time1", "time2")))

where neither parse, print(a, quote = FALSE) or cat works as the z variable. 
Probably this approach is not meant to work. 

There are quite some issues that has to be solved before the class is 
production-ready. 

By the way, if someone has an idea on how to solve the last code snippets I 
would be more than happy.

Best wishes
Torleif


On Thursday 19 November 2009 20:23:35 Michael Sumner wrote:
> Wow, this is great - I was thinking about this just yesterday.
> 
> Torleif: do you have an opinion on which NetCDF path is the most
> useful for R with sp? RNetCDF or ncdf? GDAL is workable but takes
> extra effort to build and then reconstruct 3d/4d from 2d bands. (I use
> Windows mostly)
> 
> I use the RNetCDF package a lot, mainly because that's the one I
> learnt to use first - there are binaries for Windows. It has some
> problems in terms of R-style but they could be easily fixed.
> 
> Regards, Mike.
> 
> On Fri, Nov 20, 2009 at 12:26 AM, Edzer Pebesma
> 
> <edzer.pebesma at uni-muenster.de> wrote:
> > No problems; sp in csv now has this, the next release will have it.
> >
> > Torleif Markussen Lunde wrote:
> >> Hi
> >>
> >> To read netcdf data (or any other "gridded" spatial time data) I find it
> >> convenient to define new classes Spatial3dArray and Spatial4dArray.
> >>
> >>  setClass("Spatial3dArray",
> >>         representation("Spatial", data = "array", coords = "list",
> >>                         time = "character", btime = "character"),
> >>         prototype= list(data = array(NA, c(1,1,1,1)),
> >>                         bbox=matrix(NA),
> >>                         proj4string = CRS(as.character(NA)),
> >>                         coords = list(1,1),
> >>                         time = "posix",
> >>                         btime = "posix"))
> >>
> >>
> >> ##########################################
> >> ###################EXAMPLE##################
> >> ##########################################
> >>
> >> x <- matrix(seq(-10, 10, length = 100), 100, 100,
> >>           byrow = FALSE)
> >> y <- matrix(seq(-10, 10, length = 100), 100, 100,
> >>           byrow = TRUE)
> >>
> >> tm <- 1:10
> >> tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
> >>                                   "2002-01-01 15:00:00"),
> >>                         by="hours",
> >>                         length.out=10))
> >>
> >> z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))
> >>
> >> for (i in 1:10) {
> >> z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
> >> }
> >>
> >> sin3dA <- new("Spatial3dArray",
> >>       data = z,
> >>       coords = list(x, y),
> >>       bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2,
> >>       dimnames = list(NULL, c("min","max"))),
> >>       time = tm.c,
> >>       btime = c(min(tm.c), max(tm.c)))
> >>
> >> dimnames(slot(sin3dA, "data")) = list(NULL,
> >>                                     NULL,
> >>                                     slot(sin3dA, "time"),
> >>                                     c("a"))
> >> names(slot(sin3dA, "coords")) <- c("x", "y")
> >>
> >>
> >> ##########################################
> >>
> >> for the coordinates method I would like to have two options on how to
> >> return the coordinates; "list" or default "sp":
> >>
> >> coordinates.3dArray <- function (obj, type = "sp") {
> >>       lat <- slot(obj, "coords")[[1]]
> >>       long <- slot(obj, "coords")[[2]]
> >>       if (type == "list") {
> >>               return(list(long=long, lat=lat))
> >>       } else if (type == "sp") {
> >>               res <- as.matrix(cbind(c(long), c(lat)))
> >>               dimnames(res) <- list(NULL, c("x1", "x2"))
> >>       }
> >> }
> >> setMethod("coordinates", signature("Spatial3dArray"),
> >> coordinates.3dArray)
> >>
> >> This means that the default coordinates method in sp has to include the
> >> option "..." . Would it be possible to include this in a future release
> >> of sp?
> >>
> >> The reason I want to keep the list option is to use a matrix oriented
> >> approach in spplot, overlay, etc. methods. I also feel having a
> >> matrix/array approach with these kind of data makes sense. Allowing type
> >> = "sp" means overlay() will work more or less out of the box (however I
> >> would like to return a matrix), and still I could get the list/matrix
> >> when desired.
> >>
> >>
> >> Best wishes
> >> Torleif Markussen Lunde
> >> Centre for International Health
> >> Bjerknes Centre for Climate Research
> >> University of Bergen
> >> Norway
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > --
> > Edzer Pebesma
> > Institute for Geoinformatics (ifgi), University of M?nster
> > Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> > 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> > http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


From horning at amnh.org  Fri Nov 20 04:18:42 2009
From: horning at amnh.org (Ned Horning)
Date: Thu, 19 Nov 2009 22:18:42 -0500
Subject: [R-sig-Geo] Problem using mahasuhab
Message-ID: <4B060A92.10103@amnh.org>

Hi - I was wondering if anyone out there can help with my effort to 
create habitat suitability maps using mahasuhab from the adehabitat 
package or another package if there is a better option. I would like to 
compare the resulting maps with some software a colleague is working on.

When I try to import an ascii grid using the import.asc method I get the 
following error:
--
Error in if ((yll[[1]][1] == "yllcenter") | (xll[[1]][1] == 
"YLLCENTER")) corny <- FALSE :
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In import.asc(filename, type = "numeric") : NAs introduced by coercion
2: In import.asc(filename, type = "numeric") : NAs introduced by coercion
--

I am able to read the test ascii grid file that comes with the package 
just fine. I can also read my file using stack() from the raster package 
but I don't know how to convert that RasterStack to an asc or kasc 
object which seems to be necessary to run mahasuhab.

Any pointers?

Ned


From basille at biomserv.univ-lyon1.fr  Fri Nov 20 05:11:48 2009
From: basille at biomserv.univ-lyon1.fr (Mathieu Basille)
Date: Thu, 19 Nov 2009 23:11:48 -0500
Subject: [R-sig-Geo] Problem using mahasuhab
In-Reply-To: <4B060A92.10103@amnh.org>
References: <4B060A92.10103@amnh.org>
Message-ID: <4B061704.10500@biomserv.univ-lyon1.fr>

Hi Ned,

Adehabitat was not meant to import all kind of raster maps. It might be
that your file is not in the right format. Are your file with such a header:

ncols 308
nrows 435
xllcorner 400000
yllcorner 6515000
cellsize 1000
NODATA_value -9999

(whatever the values are)

If yes, then it might be another deeper problem... Can you read it
through rgdal? If yes, you can use it and then convert it to a kasc
class, following this example:

bla <- readGDAL("your_map.asc")
blaK <- spixdf2kasc(bla)

Hope this helps,
Mathieu.


Ned Horning a ?crit :
> Hi - I was wondering if anyone out there can help with my effort to
> create habitat suitability maps using mahasuhab from the adehabitat
> package or another package if there is a better option. I would like to
> compare the resulting maps with some software a colleague is working on.
> 
> When I try to import an ascii grid using the import.asc method I get the
> following error:
> -- 
> Error in if ((yll[[1]][1] == "yllcenter") | (xll[[1]][1] ==
> "YLLCENTER")) corny <- FALSE :
>  missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In import.asc(filename, type = "numeric") : NAs introduced by coercion
> 2: In import.asc(filename, type = "numeric") : NAs introduced by coercion
> -- 
> 
> I am able to read the test ascii grid file that comes with the package
> just fine. I can also read my file using stack() from the raster package
> but I don't know how to convert that RasterStack to an asc or kasc
> object which seems to be necessary to run mahasuhab.
> 
> Any pointers?
> 
> Ned


-- 

~$ whoami
Mathieu Basille, Post-Doc

~$ locate
Laboratoire d'?cologie Comportementale et de Conservation de la Faune
+ Centre d'?tude de la For?t
D?partement de Biologie
Universit? Laval, Qu?bec

~$ info
http://ase-research.org/basille

~$ fortune
``If you can't win by reason, go for volume.''
Calvin, by Bill Watterson.


From horning at amnh.org  Fri Nov 20 05:22:34 2009
From: horning at amnh.org (Ned Horning)
Date: Thu, 19 Nov 2009 23:22:34 -0500
Subject: [R-sig-Geo] Problem using mahasuhab
In-Reply-To: <4B061704.10500@biomserv.univ-lyon1.fr>
References: <4B060A92.10103@amnh.org> <4B061704.10500@biomserv.univ-lyon1.fr>
Message-ID: <4B06198A.5040903@amnh.org>

Mathieu,

Thanks for the help - rgdal / spixdf2kasc seems to have done the trick. 
Here is the header from my ascii grid:
--
ncols    900
nrows    1650
xllcorner    0
yllcorner    0
cellsize    1000
NODATA_value    -9999
--

All the best,

Ned

Mathieu Basille wrote:
> Hi Ned,
>
> Adehabitat was not meant to import all kind of raster maps. It might be
> that your file is not in the right format. Are your file with such a header:
>
> ncols 308
> nrows 435
> xllcorner 400000
> yllcorner 6515000
> cellsize 1000
> NODATA_value -9999
>
> (whatever the values are)
>
> If yes, then it might be another deeper problem... Can you read it
> through rgdal? If yes, you can use it and then convert it to a kasc
> class, following this example:
>
> bla <- readGDAL("your_map.asc")
> blaK <- spixdf2kasc(bla)
>
> Hope this helps,
> Mathieu.
>
>
> Ned Horning a ?crit :
>   
>> Hi - I was wondering if anyone out there can help with my effort to
>> create habitat suitability maps using mahasuhab from the adehabitat
>> package or another package if there is a better option. I would like to
>> compare the resulting maps with some software a colleague is working on.
>>
>> When I try to import an ascii grid using the import.asc method I get the
>> following error:
>> -- 
>> Error in if ((yll[[1]][1] == "yllcenter") | (xll[[1]][1] ==
>> "YLLCENTER")) corny <- FALSE :
>>  missing value where TRUE/FALSE needed
>> In addition: Warning messages:
>> 1: In import.asc(filename, type = "numeric") : NAs introduced by coercion
>> 2: In import.asc(filename, type = "numeric") : NAs introduced by coercion
>> -- 
>>
>> I am able to read the test ascii grid file that comes with the package
>> just fine. I can also read my file using stack() from the raster package
>> but I don't know how to convert that RasterStack to an asc or kasc
>> object which seems to be necessary to run mahasuhab.
>>
>> Any pointers?
>>
>> Ned
>>     
>
>
>


From alan.swanson at umontana.edu  Fri Nov 20 05:54:42 2009
From: alan.swanson at umontana.edu (Alan Swanson)
Date: Thu, 19 Nov 2009 21:54:42 -0700
Subject: [R-sig-Geo] changing the data type of a gdal dataset
Message-ID: <4B062112.3080809@umontana.edu>

Dear R gurus,
I have a function that applies various model prediction functions over a 
set of large image files, producing a single output file with the same 
spatial extent.  Due to memory issues, I'm breaking the input and output 
files into tiles.  I have this working except for one small issue 
regarding data types. 

I create a new gdal transient dataset by copying an existing one using:
handle <- GDAL.open(fullnames[1],read.only=T)
tds <- 
copyDataset(handle,driver=new('GDALDriver','GTiff'),strict=F,options=NULL)
...
putRasterData(tds,t(preds), offset= c(strt[1], 0))
...
saveDataset(tds,outfile.p)
GDAL.close(tds)
      
Which works great, except that my output always needs to be floating 
point, but the input may be byte or integer, in which case the output 
dataset retains the format of the input file.  So I either need to 
change the data type of the new file, or create the new file using:
tds <- new("GDALTransientDataset",driver,dims[1],dims[2], type="Float32")

and then copy the spatial reference information from an existing 
dataset.  I can't figure out how to do either of these.  Your help would 
be much appreciated.
Cheers,
Alan


From yong.li at unimelb.edu.au  Fri Nov 20 12:39:25 2009
From: yong.li at unimelb.edu.au (Yong Li)
Date: Fri, 20 Nov 2009 22:39:25 +1100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
Message-ID: <86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>

Dear all folks,

I was informed in the 6th Digital Earth Conference that there is a better place to acquire high resolution of global DEM developed by ASTER, called GDEM with 30 m resolution, and fantastically free of charge. I tried some here (http://www.gdem.aster.ersdac.or.jp/) and it is really better than SRTM if you are outside USA.
Hope you will enjoy the free meal.
Cheers,

Yong

-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of r-sig-geo-request at stat.math.ethz.ch
Sent: 2009?11?20? 22:00
To: r-sig-geo at stat.math.ethz.ch
Subject: R-sig-Geo Digest, Vol 75, Issue 18

Send R-sig-Geo mailing list submissions to
	r-sig-geo at stat.math.ethz.ch

To subscribe or unsubscribe via the World Wide Web, visit
	https://stat.ethz.ch/mailman/listinfo/r-sig-geo
or, via email, send a message with subject or body 'help' to
	r-sig-geo-request at stat.math.ethz.ch

You can reach the person managing the list at
	r-sig-geo-owner at stat.math.ethz.ch

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-sig-Geo digest..."


Today's Topics:

   1. Re: thinning a SpatialPolygonsDataFrame (Roger Bivand)
   2. Spatial3dArray - coordinates method (Torleif Markussen Lunde)
   3. Re: Spatial3dArray - coordinates method (Edzer Pebesma)
   4. Re: thinning a SpatialPolygonsDataFrame (Michael Friendly)
   5. Filling in holes in DTM (Tobin Cara)
   6. Re: Filling in holes in DTM (milton ruser)
   7. Re: Filling in holes in DTM (Tomislav Hengl)
   8. execGRASS() for r.mapcalc? (Agustin Lobo)
   9. Lambert projection to lat/long question.... (Blair Christian)
  10. Re: Filling in holes in DTM (Robert J. Hijmans)
  11. Re: Lambert projection to lat/long question....
      (Robert J. Hijmans)
  12. Re: Lambert projection to lat/long question....
      (Robert J. Hijmans)
  13. flags in execGRASS (Agustin Lobo)
  14. Re: Lambert projection to lat/long question.... (Blair Christian)
  15. Re: execGRASS() for r.mapcalc? (Roger Bivand)
  16. Re: flags in execGRASS (Roger Bivand)
  17. Re: Spatial3dArray - coordinates method (Michael Sumner)
  18. Re: Spatial3dArray - coordinates method (Torleif Markussen Lunde)
  19. Problem using mahasuhab (Ned Horning)
  20. Re: Problem using mahasuhab (Mathieu Basille)
  21. Re: Problem using mahasuhab (Ned Horning)
  22. changing the data type of a gdal dataset (Alan Swanson)


----------------------------------------------------------------------

Message: 1
Date: Thu, 19 Nov 2009 13:02:11 +0100 (CET)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
To: Pinaud David <pinaud at cebc.cnrs.fr>
Cc: r-sig-geo at stat.math.ethz.ch, Michael Friendly <friendly at yorku.ca>
Message-ID: <alpine.LRH.2.00.0911191253370.28000 at reclus.nhh.no>
Content-Type: text/plain; charset="iso-8859-1"; Format="flowed"

On Thu, 19 Nov 2009, Pinaud David wrote:

> Hi Michael,
> Roger is fully right, this function does not preserve the topology, so be 
> aware of that, some problems can occur...
> If you want to use shapefiles::dp() just for raw plotting and visual 
> simplification, you can try (on the fly):
>
> library(rgdal)
> library(shapefiles)
>
> fr <- readOGR("polygonFRA_WGS84.shp", "polygonFRA_WGS84") # a shapefile of 
> France with complex topology (holes, islands...) in WGS84 coordinates
> pp <- slot(fr, "polygons") # take the polygons
> cf <- coordinates(slot(pp[[39]], "Polygons")[[1]])  # extract the coordinates 
> of the main polygon ("continental France")
> pf <- list(x=cf[,1], y=cf[,2]) # list of coordinates, as dp() needs a list 
> and not a matrix or dataframe...
> cf1 <- dp(pf, 0.1) # simplification, with a bandwith of 0.1 decimal degree
> plot(fr)  # to see the result
> points(cf1, col="red", t="l")

This seems to work OK given that slivers are not important:
library(sp)
library(Guerry)
# installed from R-Forge
data(gfrance)
object.size(gfrance)
pls <- slot(gfrance, "polygons")
pls_dp <- vector(mode="list", length=length(pls))
require(shapefiles)
tol <- 2500
minarea <- 500000
for (i in 1:length(pls)) {
   Pls <- slot(pls[[i]], "Polygons")
   Pls_dp <- vector(mode="list", length=length(Pls))
   for (j in 1:length(Pls)) {
     crds <- slot(Pls[[j]], "coords")
     crds_s <- dp(list(x=crds[,1], y=crds[,2]), tolerance=tol)
     crds_s <- do.call("cbind", crds_s)
     if(!identical(crds_s[1,], crds_s[nrow(crds_s),]))
       crds_s <- rbind(crds_s, crds_s[1,])
     Pls_dp[[j]] <- Polygon(crds_s)
   }
   Keep <- logical(length(Pls_dp))
   for (j in 1:length(Pls_dp)) {
     Keep[j] <- TRUE
     if (slot(Pls_dp[[j]], "area") < minarea) Keep[j] <- FALSE
   }
   Pls_dp <- Pls_dp[Keep]
   pls_dp[[i]] <- Polygons(Pls_dp, ID=slot(pls[[i]], "ID"))
}
gfrance_dp <- SpatialPolygonsDataFrame(SpatialPolygons(pls_dp), 
data=slot(gfrance, "data"))
object.size(gfrance_dp)

If this was a function, the input would be an object inheriting from 
SpatialPolygons, the tolerance, and a minimum polygon area. The removal of 
small Polygon objects needs protecting from removing all belonging to a 
given Polygons object. The CRS also needs copying across. The objects are 
rebuilt to correct areas, centroids, plot orders, and the bounding box, 
all of which may change. For figures, the companion thread on R-help is 
relevant, PDF output for choropleth maps is often a good deal larger in 
file size than that of the equivalent PNG device.

I'll ask the shapefiles authors whether I can copy dp() to maptools and 
include suitable methods - this will help in benchmarking the future GEOS 
version.

Hope this helps,

Roger

>
> HTH
> David
>
> Michael Friendly a ?crit :
>> I think, for my application, I'd be happy with the D-P polyline 
>> simplification algorithm, because that is what is used
>> in SAS (worked well), and I don't think there are unusual topologies in my 
>> map of France that would be so severely
>> out of whack as to lead to *significant* visual artifacts.  In fact, you 
>> might well expect some artifacts from any visual
>> thinning, but it's a matter of the tradeoff in the way the thinned map is 
>> used in a visualization.  Mark Monmonier's
>> US Visibility Map might be an extremely thinned, but highly useful example.
>> 
>> For R spatial analysis, I think this is worth pursuing and integrating into 
>> sp methods.  In SAS, proc greduce works simply
>> by adding another variable, density, to the (x,y) coordinates of the 
>> spatial polygons, density %in% 1:5, where density==5
>> is the full map.  It is then a simple matter to subset the polygon outlines 
>> by saying
>> 
>> data smallmap;
>>    set mymap;
>>    where density<4;
>> 
>> or
>> 
>> proc gmap map=mymap(where=(density<4));
>> ...
>> 
>> Meanwhile, I can't see easily how I could use shapefiles::dp() to thin my 
>> Guerry::gfrance maps, because the documentation is,
>> shall we say, somewhat thin.
>> -Michael
>> 
>> 
>> 
>> Roger Bivand wrote:
>>> On Wed, 18 Nov 2009, Pinaud David wrote:
>>> 
>>>> Hi Michael,
>>>> maybe you should try the function dp() in the package shapefiles that is 
>>>> an implementation of the Douglas-Peucker polyLine simplification 
>>>> algorithm.
>>> 
>>> Note that its help page does warn that it is not topology-preserving, that 
>>> is that lines are generalised, but that coincident lines (boundaries of 
>>> neighbouring polygons) may be generalised differently. GEOS offers a 
>>> topology-preserving line generalisation facility, which ought to take 
>>> longer but do better than dp(), because it will not lead to visual 
>>> artefacts (overlapping polygons, interpolygon slivers, etc.).
>>> 
>>> Roger
>>> 
>>>> HTH
>>>> David
>>>> 
>>>> Michael Friendly a ?crit :
>>>>> The Guerry package contains two maps of france (gfrance, gfrance85) 
>>>>> which are quite detailed and large in size (?900K).
>>>>> In writing a vignette for the package, there are quite a few figures 
>>>>> that use the map multiple times in a layout, and
>>>>> consequently result in huge file sizes for the .PDF files created.  For 
>>>>> these purposes, the map need not be nearly
>>>>> so detailed.
>>>>> 
>>>>> I'm wondering if there is a facility to "thin" the map by drawing it at 
>>>>> a lower density of lines in the polygon regions.
>>>>> When I was working with SAS, there was a GREDUCE procedure that did this 
>>>>> nicely.
>>>>> 
>>>>> thanks,
>>>>> -Michael
>>>>> 
>>>> 
>>>> 
>>> 
>> 
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

------------------------------

Message: 2
Date: Thu, 19 Nov 2009 13:28:55 +0100
From: Torleif Markussen Lunde <torleif.lunde at cih.uib.no>
Subject: [R-sig-Geo] Spatial3dArray - coordinates method
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <200911191328.55628.torleif.lunde at cih.uib.no>
Content-Type: Text/Plain;  charset="iso-8859-15"

Hi

To read netcdf data (or any other "gridded" spatial time data) I find it 
convenient to define new classes Spatial3dArray and Spatial4dArray.

 setClass("Spatial3dArray", 
	  representation("Spatial", data = "array", coords = "list", 
			  time = "character", btime = "character"),
	  prototype= list(data = array(NA, c(1,1,1,1)), 
			  bbox=matrix(NA), 
			  proj4string = CRS(as.character(NA)), 
			  coords = list(1,1),
			  time = "posix",
			  btime = "posix"))


##########################################
###################EXAMPLE##################
##########################################

x <- matrix(seq(-10, 10, length = 100), 100, 100, 
	    byrow = FALSE)
y <- matrix(seq(-10, 10, length = 100), 100, 100, 
	    byrow = TRUE)

tm <- 1:10
tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
				    "2002-01-01 15:00:00"), 
			  by="hours", 
			  length.out=10))

z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))

for (i in 1:10) {
z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
}

sin3dA <- new("Spatial3dArray", 
      data = z, 
      coords = list(x, y), 
      bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2, 
      dimnames = list(NULL, c("min","max"))), 
      time = tm.c,
      btime = c(min(tm.c), max(tm.c)))

dimnames(slot(sin3dA, "data")) = list(NULL, 
				      NULL, 
				      slot(sin3dA, "time"), 
				      c("a"))
names(slot(sin3dA, "coords")) <- c("x", "y")


##########################################

for the coordinates method I would like to have two options on how to return 
the coordinates; "list" or default "sp":

coordinates.3dArray <- function (obj, type = "sp") {	
	lat <- slot(obj, "coords")[[1]]
  	long <- slot(obj, "coords")[[2]]
  	if (type == "list") {
    		return(list(long=long, lat=lat))
    	} else if (type == "sp") {
		res <- as.matrix(cbind(c(long), c(lat)))
		dimnames(res) <- list(NULL, c("x1", "x2"))
	} 
}
setMethod("coordinates", signature("Spatial3dArray"), coordinates.3dArray)

This means that the default coordinates method in sp has to include the option 
"..." . Would it be possible to include this in a future release of sp? 

The reason I want to keep the list option is to use a matrix oriented approach 
in spplot, overlay, etc. methods. I also feel having a matrix/array approach 
with these kind of data makes sense. Allowing type = "sp" means overlay() will 
work more or less out of the box (however I would like to return a matrix), 
and still I could get the list/matrix when desired. 


Best wishes
Torleif Markussen Lunde
Centre for International Health
Bjerknes Centre for Climate Research
University of Bergen
Norway



------------------------------

Message: 3
Date: Thu, 19 Nov 2009 14:26:35 +0100
From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Subject: Re: [R-sig-Geo] Spatial3dArray - coordinates method
To: Torleif Markussen Lunde <torleif.lunde at cih.uib.no>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4B05478B.3080800 at uni-muenster.de>
Content-Type: text/plain; charset=ISO-8859-1

No problems; sp in csv now has this, the next release will have it.

Torleif Markussen Lunde wrote:
> Hi
>
> To read netcdf data (or any other "gridded" spatial time data) I find it 
> convenient to define new classes Spatial3dArray and Spatial4dArray.
>
>  setClass("Spatial3dArray", 
> 	  representation("Spatial", data = "array", coords = "list", 
> 			  time = "character", btime = "character"),
> 	  prototype= list(data = array(NA, c(1,1,1,1)), 
> 			  bbox=matrix(NA), 
> 			  proj4string = CRS(as.character(NA)), 
> 			  coords = list(1,1),
> 			  time = "posix",
> 			  btime = "posix"))
>
>
> ##########################################
> ###################EXAMPLE##################
> ##########################################
>
> x <- matrix(seq(-10, 10, length = 100), 100, 100, 
> 	    byrow = FALSE)
> y <- matrix(seq(-10, 10, length = 100), 100, 100, 
> 	    byrow = TRUE)
>
> tm <- 1:10
> tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
> 				    "2002-01-01 15:00:00"), 
> 			  by="hours", 
> 			  length.out=10))
>
> z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))
>
> for (i in 1:10) {
> z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
> }
>
> sin3dA <- new("Spatial3dArray", 
>       data = z, 
>       coords = list(x, y), 
>       bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2, 
>       dimnames = list(NULL, c("min","max"))), 
>       time = tm.c,
>       btime = c(min(tm.c), max(tm.c)))
>
> dimnames(slot(sin3dA, "data")) = list(NULL, 
> 				      NULL, 
> 				      slot(sin3dA, "time"), 
> 				      c("a"))
> names(slot(sin3dA, "coords")) <- c("x", "y")
>
>
> ##########################################
>
> for the coordinates method I would like to have two options on how to return 
> the coordinates; "list" or default "sp":
>
> coordinates.3dArray <- function (obj, type = "sp") {	
> 	lat <- slot(obj, "coords")[[1]]
>   	long <- slot(obj, "coords")[[2]]
>   	if (type == "list") {
>     		return(list(long=long, lat=lat))
>     	} else if (type == "sp") {
> 		res <- as.matrix(cbind(c(long), c(lat)))
> 		dimnames(res) <- list(NULL, c("x1", "x2"))
> 	} 
> }
> setMethod("coordinates", signature("Spatial3dArray"), coordinates.3dArray)
>
> This means that the default coordinates method in sp has to include the option 
> "..." . Would it be possible to include this in a future release of sp? 
>
> The reason I want to keep the list option is to use a matrix oriented approach 
> in spplot, overlay, etc. methods. I also feel having a matrix/array approach 
> with these kind of data makes sense. Allowing type = "sp" means overlay() will 
> work more or less out of the box (however I would like to return a matrix), 
> and still I could get the list/matrix when desired. 
>
>
> Best wishes
> Torleif Markussen Lunde
> Centre for International Health
> Bjerknes Centre for Climate Research
> University of Bergen
> Norway
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de



------------------------------

Message: 4
Date: Thu, 19 Nov 2009 08:55:10 -0500
From: Michael Friendly <friendly at yorku.ca>
Subject: Re: [R-sig-Geo] thinning a SpatialPolygonsDataFrame
To: Roger.Bivand at nhh.no
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4B054E3E.4060005 at yorku.ca>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Thanks very much for doing the heavy lifting here, Roger.

For use in the Guerry package, I've turned this into a function (rather 
than saving other versions of gfrance).

If you include something like this in sp, I'll withdraw it from Guerry.

thinnedSpatialPoly <- function(SP, tolerance, minarea) {
  if (!require(shapefiles)) stop("shapefiles package is required")
  stopifnot(inherits(SP, "SpatialPolygons"))

    # TODO: determine and set defaults for tolerance, minarea 
    # TODO: suppress warnings: "In Polygon(crds_s) : Non-finite label 
point detected and replaced"
  pls <- slot(SP, "polygons")
  pls_dp <- vector(mode="list", length=length(pls))
  for (i in 1:length(pls)) {
    Pls <- slot(pls[[i]], "Polygons")
    Pls_dp <- vector(mode="list", length=length(Pls))
    for (j in 1:length(Pls)) {
      crds <- slot(Pls[[j]], "coords")
      crds_s <- dp(list(x=crds[,1], y=crds[,2]), tolerance=tolerance)
      crds_s <- do.call("cbind", crds_s)
      if(!identical(crds_s[1,], crds_s[nrow(crds_s),]))
        crds_s <- rbind(crds_s, crds_s[1,])
      Pls_dp[[j]] <- Polygon(crds_s)
    }
    Keep <- logical(length(Pls_dp))
    for (j in 1:length(Pls_dp)) {
      Keep[j] <- TRUE
      if (slot(Pls_dp[[j]], "area") < minarea) Keep[j] <- FALSE
    }
    Pls_dp <- Pls_dp[Keep]
    pls_dp[[i]] <- Polygons(Pls_dp, ID=slot(pls[[i]], "ID"))
  }
    SP_dp <- SpatialPolygons(pls_dp, proj4string=slot(SP, "proj4string"))
  if(inherits(SP, "SpatialPolygonsDataFrame")) {
    data <- slot(SP, "data")
    SP_dp <- SpatialPolygonsDataFrame(SP_dp, data=data)
  }
  SP_dp
}

best,
-Michael


Roger Bivand wrote:
> On Thu, 19 Nov 2009, Pinaud David wrote:
>
>> Hi Michael,
>> Roger is fully right, this function does not preserve the topology, 
>> so be aware of that, some problems can occur...
>> If you want to use shapefiles::dp() just for raw plotting and visual 
>> simplification, you can try (on the fly):
>>
>> library(rgdal)
>> library(shapefiles)
>>
>> fr <- readOGR("polygonFRA_WGS84.shp", "polygonFRA_WGS84") # a 
>> shapefile of France with complex topology (holes, islands...) in 
>> WGS84 coordinates
>> pp <- slot(fr, "polygons") # take the polygons
>> cf <- coordinates(slot(pp[[39]], "Polygons")[[1]])  # extract the 
>> coordinates of the main polygon ("continental France")
>> pf <- list(x=cf[,1], y=cf[,2]) # list of coordinates, as dp() needs a 
>> list and not a matrix or dataframe...
>> cf1 <- dp(pf, 0.1) # simplification, with a bandwith of 0.1 decimal 
>> degree
>> plot(fr)  # to see the result
>> points(cf1, col="red", t="l")
>
> This seems to work OK given that slivers are not important:
> library(sp)
> library(Guerry)
> # installed from R-Forge
> data(gfrance)
> object.size(gfrance)
> pls <- slot(gfrance, "polygons")
> pls_dp <- vector(mode="list", length=length(pls))
> require(shapefiles)
> tol <- 2500
> minarea <- 500000
> for (i in 1:length(pls)) {
>   Pls <- slot(pls[[i]], "Polygons")
>   Pls_dp <- vector(mode="list", length=length(Pls))
>   for (j in 1:length(Pls)) {
>     crds <- slot(Pls[[j]], "coords")
>     crds_s <- dp(list(x=crds[,1], y=crds[,2]), tolerance=tol)
>     crds_s <- do.call("cbind", crds_s)
>     if(!identical(crds_s[1,], crds_s[nrow(crds_s),]))
>       crds_s <- rbind(crds_s, crds_s[1,])
>     Pls_dp[[j]] <- Polygon(crds_s)
>   }
>   Keep <- logical(length(Pls_dp))
>   for (j in 1:length(Pls_dp)) {
>     Keep[j] <- TRUE
>     if (slot(Pls_dp[[j]], "area") < minarea) Keep[j] <- FALSE
>   }
>   Pls_dp <- Pls_dp[Keep]
>   pls_dp[[i]] <- Polygons(Pls_dp, ID=slot(pls[[i]], "ID"))
> }
> gfrance_dp <- SpatialPolygonsDataFrame(SpatialPolygons(pls_dp), 
> data=slot(gfrance, "data"))
> object.size(gfrance_dp)
>
> If this was a function, the input would be an object inheriting from 
> SpatialPolygons, the tolerance, and a minimum polygon area. The 
> removal of small Polygon objects needs protecting from removing all 
> belonging to a given Polygons object. The CRS also needs copying 
> across. The objects are rebuilt to correct areas, centroids, plot 
> orders, and the bounding box, all of which may change. For figures, 
> the companion thread on R-help is relevant, PDF output for choropleth 
> maps is often a good deal larger in file size than that of the 
> equivalent PNG device.
>
> I'll ask the shapefiles authors whether I can copy dp() to maptools 
> and include suitable methods - this will help in benchmarking the 
> future GEOS version.
>
> Hope this helps,
>
> Roger
>
>>
>> HTH
>> David
>>
>> Michael Friendly a ?crit :
>>> I think, for my application, I'd be happy with the D-P polyline 
>>> simplification algorithm, because that is what is used
>>> in SAS (worked well), and I don't think there are unusual topologies 
>>> in my map of France that would be so severely
>>> out of whack as to lead to *significant* visual artifacts.  In fact, 
>>> you might well expect some artifacts from any visual
>>> thinning, but it's a matter of the tradeoff in the way the thinned 
>>> map is used in a visualization.  Mark Monmonier's
>>> US Visibility Map might be an extremely thinned, but highly useful 
>>> example.
>>>
>>> For R spatial analysis, I think this is worth pursuing and 
>>> integrating into sp methods.  In SAS, proc greduce works simply
>>> by adding another variable, density, to the (x,y) coordinates of the 
>>> spatial polygons, density %in% 1:5, where density==5
>>> is the full map.  It is then a simple matter to subset the polygon 
>>> outlines by saying
>>>
>>> data smallmap;
>>>    set mymap;
>>>    where density<4;
>>>
>>> or
>>>
>>> proc gmap map=mymap(where=(density<4));
>>> ...
>>>
>>> Meanwhile, I can't see easily how I could use shapefiles::dp() to 
>>> thin my Guerry::gfrance maps, because the documentation is,
>>> shall we say, somewhat thin.
>>> -Michael
>>>
>>>
>>>
>>> Roger Bivand wrote:
>>>> On Wed, 18 Nov 2009, Pinaud David wrote:
>>>>
>>>>> Hi Michael,
>>>>> maybe you should try the function dp() in the package shapefiles 
>>>>> that is an implementation of the Douglas-Peucker polyLine 
>>>>> simplification algorithm.
>>>>
>>>> Note that its help page does warn that it is not 
>>>> topology-preserving, that is that lines are generalised, but that 
>>>> coincident lines (boundaries of neighbouring polygons) may be 
>>>> generalised differently. GEOS offers a topology-preserving line 
>>>> generalisation facility, which ought to take longer but do better 
>>>> than dp(), because it will not lead to visual artefacts 
>>>> (overlapping polygons, interpolygon slivers, etc.).
>>>>
>>>> Roger
>>>>
>>>>> HTH
>>>>> David
>>>>>
>>>>> Michael Friendly a ?crit :
>>>>>> The Guerry package contains two maps of france (gfrance, 
>>>>>> gfrance85) which are quite detailed and large in size (?900K).
>>>>>> In writing a vignette for the package, there are quite a few 
>>>>>> figures that use the map multiple times in a layout, and
>>>>>> consequently result in huge file sizes for the .PDF files 
>>>>>> created.  For these purposes, the map need not be nearly
>>>>>> so detailed.
>>>>>>
>>>>>> I'm wondering if there is a facility to "thin" the map by drawing 
>>>>>> it at a lower density of lines in the polygon regions.
>>>>>> When I was working with SAS, there was a GREDUCE procedure that 
>>>>>> did this nicely.
>>>>>>
>>>>>> thanks,
>>>>>> -Michael
>>>>>>
>>>>>
>>>>>
>>>>
>>>
>>>
>>
>>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca 
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



------------------------------

Message: 5
Date: Thu, 19 Nov 2009 15:16:23 +0100
From: Tobin Cara <cara.tobin at epfl.ch>
Subject: [R-sig-Geo] Filling in holes in DTM
To: "r-sig-geo at stat.math.ethz.ch" <r-sig-geo at stat.math.ethz.ch>
Message-ID:
	<EDB94195DABE64488928DD39E53B8FC68BDFD3E8D9 at REX2.intranet.epfl.ch>
Content-Type: text/plain

Hello,

Would anyone know a good way to fill in holes within a DTM? There is no data inside these holes and it is affecting my calculations, so I prefer for an interpolation of the nearest neighbors to fill in a value or something similar.

Thank you,

Cara

	[[alternative HTML version deleted]]



------------------------------

Message: 6
Date: Thu, 19 Nov 2009 10:04:58 -0500
From: milton ruser <milton.ruser at gmail.com>
Subject: Re: [R-sig-Geo] Filling in holes in DTM
To: Tobin Cara <cara.tobin at epfl.ch>
Cc: "r-sig-geo at stat.math.ethz.ch" <r-sig-geo at stat.math.ethz.ch>
Message-ID:
	<3aaf1a030911190704s78a9fa2ah2fb3ee444be9a1e3 at mail.gmail.com>
Content-Type: text/plain

Hi Ton

Check r.watershed/r.terraflow/r.flow/r.fill modules on Grass.

cheers
miltinho

On Thu, Nov 19, 2009 at 9:16 AM, Tobin Cara <cara.tobin at epfl.ch> wrote:

> Hello,
>
> Would anyone know a good way to fill in holes within a DTM? There is no
> data inside these holes and it is affecting my calculations, so I prefer for
> an interpolation of the nearest neighbors to fill in a value or something
> similar.
>
> Thank you,
>
> Cara
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]



------------------------------

Message: 7
Date: Thu, 19 Nov 2009 16:14:56 +0100
From: "Tomislav Hengl" <hengl at spatial-analyst.net>
Subject: Re: [R-sig-Geo] Filling in holes in DTM
To: "'r-sig-geo'" <r-sig-geo at stat.math.ethz.ch>
Message-ID: <4117908DD26B4334AC97EE4600F89019 at pcibed193>
Content-Type: text/plain;	charset="windows-1250"


Hi Cara, 

There is a very efficient function in SAGA called "Close Gaps" that does exactly that. What makes it
especially efficient is that it allows you to set a mask map. See:

> rsaga.get.usage("grid_tools", 7)
SAGA CMD 2.0.3
library path:   C:/Progra?1/saga_vc/modules
library name:   grid_tools
module name :   Close Gaps
Usage: 7 -INPUT <str> [-MASK <str>] [-RESULT <str>] [-THRESHOLD <str>]
  -INPUT:<str>          Grid
        Grid (input)
  -MASK:<str>           Mask
        Grid (optional input)
  -RESULT:<str>         Changed Grid
        Grid (optional output)
  -THRESHOLD:<str>      Tension Threshold

BR,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Tobin Cara
> Sent: Thursday, November 19, 2009 3:16 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] Filling in holes in DTM
> 
> Hello,
> 
> Would anyone know a good way to fill in holes within a DTM? There is no data inside these holes
> and it is affecting my calculations, so I prefer for an interpolation of the nearest neighbors to
> fill in a value or something similar.
> 
> Thank you,
> 
> Cara
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



------------------------------

Message: 8
Date: Thu, 19 Nov 2009 18:09:57 +0100
From: Agustin Lobo <alobolistas at gmail.com>
Subject: [R-sig-Geo] execGRASS() for r.mapcalc?
To: sig-geo <r-sig-geo at stat.math.ethz.ch>
Message-ID: <4B057BE5.8040908 at gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

I'm used to do:
 > cmd = "r.mapcalc 'delme=100'"
 > system(cmd)

and works, but how could I do the equivalent using execGRASS() ?
I've tried:

 > doGRASS(cmd)
Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed

 > execGRASS(cmd)
Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed

I can always use paste() to make any cmd string, but seems to me that 
execGRASS() would be cleaner.

Thanks

Agus



------------------------------

Message: 9
Date: Thu, 19 Nov 2009 12:39:15 -0500
From: Blair Christian <blair.christian at gmail.com>
Subject: [R-sig-Geo] Lambert projection to lat/long question....
To: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<6c35a4fc0911190939o1ae8a7eeua800dcaeb4d3f21d at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Hi All,

Before trying to reinvent the wheel, I was wondering if the mapproj or
any other library had code to take lambert coordinates (along with the
parameters used to generate them) and convert them to lat long.? I
have grid data in lambert coords, and want to generate the long/lat
grid corners from them.? I noticed mapproj goes long/lat ->
projection, but couldn't find anything to go the other way.  I was
going to use the reference in wolfram mathworld to do the inverse
transform, if anybody has any issues with their version.

http://mathworld.wolfram.com/LambertConformalConicProjection.html

Basically, I want to keep the data stored as grids, but every now and
then I want to create distance matrices or plot them (which I
currently do with an irregular grid class I made up), but don't want
to store polygons all the time when I can just store the basic grid.
All comments welcome.

Thanks,
Blair



------------------------------

Message: 10
Date: Thu, 19 Nov 2009 09:40:44 -0800
From: "Robert J. Hijmans" <r.hijmans at gmail.com>
Subject: Re: [R-sig-Geo] Filling in holes in DTM
To: Tobin Cara <cara.tobin at epfl.ch>
Cc: "r-sig-geo at stat.math.ethz.ch" <r-sig-geo at stat.math.ethz.ch>
Message-ID:
	<dc22b2570911190940u62269dbbo2392da32b0019a9d at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Tobin,

In the raster package you can use the focalNA function. It sets the
focal (neighborhood) value, according to a specified function (e.g.
mean), to cells with NA.

raster is available on R-Forge:  install.packages("raster",
repos="http://R-Forge.R-project.org")

Robert

On Thu, Nov 19, 2009 at 6:16 AM, Tobin Cara <cara.tobin at epfl.ch> wrote:
> Hello,
>
> Would anyone know a good way to fill in holes within a DTM? There is no data inside these holes and it is affecting my calculations, so I prefer for an interpolation of the nearest neighbors to fill in a value or something similar.
>
> Thank you,
>
> Cara
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



------------------------------

Message: 11
Date: Thu, 19 Nov 2009 09:44:32 -0800
From: "Robert J. Hijmans" <r.hijmans at gmail.com>
Subject: Re: [R-sig-Geo] Lambert projection to lat/long question....
To: Blair Christian <blair.christian at gmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<dc22b2570911190944l49cafe4fx7b4367bf7e466e72 at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Blair: Have a look at spTransform in rgdal. Robert

On Thu, Nov 19, 2009 at 9:39 AM, Blair Christian
<blair.christian at gmail.com> wrote:
> Hi All,
>
> Before trying to reinvent the wheel, I was wondering if the mapproj or
> any other library had code to take lambert coordinates (along with the
> parameters used to generate them) and convert them to lat long.? I
> have grid data in lambert coords, and want to generate the long/lat
> grid corners from them.? I noticed mapproj goes long/lat ->
> projection, but couldn't find anything to go the other way. ?I was
> going to use the reference in wolfram mathworld to do the inverse
> transform, if anybody has any issues with their version.
>
> http://mathworld.wolfram.com/LambertConformalConicProjection.html
>
> Basically, I want to keep the data stored as grids, but every now and
> then I want to create distance matrices or plot them (which I
> currently do with an irregular grid class I made up), but don't want
> to store polygons all the time when I can just store the basic grid.
> All comments welcome.
>
> Thanks,
> Blair
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



------------------------------

Message: 12
Date: Thu, 19 Nov 2009 09:46:13 -0800
From: "Robert J. Hijmans" <r.hijmans at gmail.com>
Subject: Re: [R-sig-Geo] Lambert projection to lat/long question....
To: Blair Christian <blair.christian at gmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<dc22b2570911190946w7f5d668bpa233ecb2763f24ad at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Blair, sorry, too quick:

Have a look at spTransform in rgdal and at projectRaster in the raster package.

Robert


On Thu, Nov 19, 2009 at 9:39 AM, Blair Christian
<blair.christian at gmail.com> wrote:
> Hi All,
>
> Before trying to reinvent the wheel, I was wondering if the mapproj or
> any other library had code to take lambert coordinates (along with the
> parameters used to generate them) and convert them to lat long.? I
> have grid data in lambert coords, and want to generate the long/lat
> grid corners from them.? I noticed mapproj goes long/lat ->
> projection, but couldn't find anything to go the other way. ?I was
> going to use the reference in wolfram mathworld to do the inverse
> transform, if anybody has any issues with their version.
>
> http://mathworld.wolfram.com/LambertConformalConicProjection.html
>
> Basically, I want to keep the data stored as grids, but every now and
> then I want to create distance matrices or plot them (which I
> currently do with an irregular grid class I made up), but don't want
> to store polygons all the time when I can just store the basic grid.
> All comments welcome.
>
> Thanks,
> Blair
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



------------------------------

Message: 13
Date: Thu, 19 Nov 2009 18:46:24 +0100
From: Agustin Lobo <alobolistas at gmail.com>
Subject: [R-sig-Geo] flags in execGRASS
To: sig-geo <r-sig-geo at stat.math.ethz.ch>
Message-ID: <4B058470.9000300 at gmail.com>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hi!
The following works:
 > 
doGRASS("r.grow.distance",flags=c("overwrite"),parameters=list(distance="dummyd",input="dummy"))
[1] "r.grow.distance --overwrite distance=dummyd input=dummy"

But using "o" instead of "overwrite" does not
 > 
doGRASS("r.grow.distance",flags=c("o"),parameters=list(distance="dummyd",input="dummy"))
Error in doGRASS("r.grow.distance", flags = c("o"), parameters = list(distance = 
"dummyd",  :
   Invalid flag value: o

despite the fact that the grass manual states:
 > r.grow.distance --help
...(stuff deleted)

Usage:
  r.grow.distance input=name [distance=name] [value=name]
    [metric=string] [--overwrite] [--verbose] [--quiet]

Flags:
  --o   Allow output files to overwrite existing files
  --v   Verbose module output
  --q   Quiet module output
...(stuff deleted)

Could it be possible that execGRASS accept both forms for consistency with the 
grass command? If this is not possible or appropriate, could a note be added to 
the execGRASS manual page?

Thanks

Agus



------------------------------

Message: 14
Date: Thu, 19 Nov 2009 12:56:35 -0500
From: Blair Christian <blair.christian at gmail.com>
Subject: Re: [R-sig-Geo] Lambert projection to lat/long question....
To: "Robert J. Hijmans" <r.hijmans at gmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID:
	<6c35a4fc0911190956x16b99092w2908ae9e0982765b at mail.gmail.com>
Content-Type: text/plain; charset=ISO-8859-1

Those are perfect.  I wish I had the time to contribute as much
software as you do, Robert.  Very impressive contributions on the
r-forge pages.

Thanks,
Blair

On Thu, Nov 19, 2009 at 12:46 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
> Blair, sorry, too quick:
>
> Have a look at spTransform in rgdal and at projectRaster in the raster package.
>
> Robert
>
>
> On Thu, Nov 19, 2009 at 9:39 AM, Blair Christian
> <blair.christian at gmail.com> wrote:
>> Hi All,
>>
>> Before trying to reinvent the wheel, I was wondering if the mapproj or
>> any other library had code to take lambert coordinates (along with the
>> parameters used to generate them) and convert them to lat long.? I
>> have grid data in lambert coords, and want to generate the long/lat
>> grid corners from them.? I noticed mapproj goes long/lat ->
>> projection, but couldn't find anything to go the other way. ?I was
>> going to use the reference in wolfram mathworld to do the inverse
>> transform, if anybody has any issues with their version.
>>
>> http://mathworld.wolfram.com/LambertConformalConicProjection.html
>>
>> Basically, I want to keep the data stored as grids, but every now and
>> then I want to create distance matrices or plot them (which I
>> currently do with an irregular grid class I made up), but don't want
>> to store polygons all the time when I can just store the basic grid.
>> All comments welcome.
>>
>> Thanks,
>> Blair
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>



------------------------------

Message: 15
Date: Thu, 19 Nov 2009 19:26:55 +0100 (CET)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] execGRASS() for r.mapcalc?
To: Agustin.Lobo at ija.csic.es
Cc: sig-geo <r-sig-geo at stat.math.ethz.ch>
Message-ID: <alpine.LRH.2.00.0911191921260.28832 at reclus.nhh.no>
Content-Type: TEXT/PLAIN; format=flowed; charset=US-ASCII

On Thu, 19 Nov 2009, Agustin Lobo wrote:

> I'm used to do:
>> cmd = "r.mapcalc 'delme=100'"
>> system(cmd)
>
> and works, but how could I do the equivalent using execGRASS() ?

You cannot. r.mapcalc does not provide an --interface-description XML 
self-definition. You have either to use system() as before (with different 
quoting reimes for different OS), or r.mapcalculator in execGRASS(). This 
problem is shared with other interfaces using --interface-description.

Roger

> I've tried:
>
>> doGRASS(cmd)
> Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed
>
>> execGRASS(cmd)
> Error in parseGRASS(cmd) : r.mapcalc 'delme=100' not parsed
>
> I can always use paste() to make any cmd string, but seems to me that 
> execGRASS() would be cleaner.
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



------------------------------

Message: 16
Date: Thu, 19 Nov 2009 19:34:50 +0100 (CET)
From: Roger Bivand <Roger.Bivand at nhh.no>
Subject: Re: [R-sig-Geo] flags in execGRASS
To: Agustin.Lobo at ija.csic.es
Cc: sig-geo <r-sig-geo at stat.math.ethz.ch>
Message-ID: <alpine.LRH.2.00.0911191927160.28832 at reclus.nhh.no>
Content-Type: TEXT/PLAIN; format=flowed; charset=US-ASCII

On Thu, 19 Nov 2009, Agustin Lobo wrote:

> Hi!
> The following works:
>> 
> doGRASS("r.grow.distance",flags=c("overwrite"),parameters=list(distance="dummyd",input="dummy"))
> [1] "r.grow.distance --overwrite distance=dummyd input=dummy"
>
> But using "o" instead of "overwrite" does not

Because only "overwrite" is included in

r.grow.distance --interface-description

and that is what the flags are checked against. Unfortunately, many XML 
descriptions are more demanding than the help pages, but for parseGRASS() 
to work, it must use the self-definition without exception. execGRASS() is 
designed for scripting, in which case keeping to tighter limits than the 
help pages is OK. Some commands have both "o" and "overwrite" for 
different things too, so confusion would ensue.

Roger

>> 
> doGRASS("r.grow.distance",flags=c("o"),parameters=list(distance="dummyd",input="dummy"))
> Error in doGRASS("r.grow.distance", flags = c("o"), parameters = 
> list(distance = "dummyd",  :
>  Invalid flag value: o
>
> despite the fact that the grass manual states:
>> r.grow.distance --help
> ...(stuff deleted)
>
> Usage:
> r.grow.distance input=name [distance=name] [value=name]
>   [metric=string] [--overwrite] [--verbose] [--quiet]
>
> Flags:
> --o   Allow output files to overwrite existing files
> --v   Verbose module output
> --q   Quiet module output
> ...(stuff deleted)
>
> Could it be possible that execGRASS accept both forms for consistency with 
> the grass command? If this is not possible or appropriate, could a note be 
> added to the execGRASS manual page?
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



------------------------------

Message: 17
Date: Fri, 20 Nov 2009 06:23:35 +1100
From: Michael Sumner <mdsumner at gmail.com>
Subject: Re: [R-sig-Geo] Spatial3dArray - coordinates method
To: Torleif Markussen Lunde <torleif.lunde at cih.uib.no>,
	r-sig-geo at stat.math.ethz.ch
Message-ID:
	<522664f80911191123u644807ccx7973ce8f734a0afe at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

Wow, this is great - I was thinking about this just yesterday.

Torleif: do you have an opinion on which NetCDF path is the most
useful for R with sp? RNetCDF or ncdf? GDAL is workable but takes
extra effort to build and then reconstruct 3d/4d from 2d bands. (I use
Windows mostly)

I use the RNetCDF package a lot, mainly because that's the one I
learnt to use first - there are binaries for Windows. It has some
problems in terms of R-style but they could be easily fixed.

Regards, Mike.

On Fri, Nov 20, 2009 at 12:26 AM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> No problems; sp in csv now has this, the next release will have it.
>
> Torleif Markussen Lunde wrote:
>> Hi
>>
>> To read netcdf data (or any other "gridded" spatial time data) I find it
>> convenient to define new classes Spatial3dArray and Spatial4dArray.
>>
>> ?setClass("Spatial3dArray",
>> ? ? ? ? representation("Spatial", data = "array", coords = "list",
>> ? ? ? ? ? ? ? ? ? ? ? ? time = "character", btime = "character"),
>> ? ? ? ? prototype= list(data = array(NA, c(1,1,1,1)),
>> ? ? ? ? ? ? ? ? ? ? ? ? bbox=matrix(NA),
>> ? ? ? ? ? ? ? ? ? ? ? ? proj4string = CRS(as.character(NA)),
>> ? ? ? ? ? ? ? ? ? ? ? ? coords = list(1,1),
>> ? ? ? ? ? ? ? ? ? ? ? ? time = "posix",
>> ? ? ? ? ? ? ? ? ? ? ? ? btime = "posix"))
>>
>>
>> ##########################################
>> ###################EXAMPLE##################
>> ##########################################
>>
>> x <- matrix(seq(-10, 10, length = 100), 100, 100,
>> ? ? ? ? ? byrow = FALSE)
>> y <- matrix(seq(-10, 10, length = 100), 100, 100,
>> ? ? ? ? ? byrow = TRUE)
>>
>> tm <- 1:10
>> tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "2002-01-01 15:00:00"),
>> ? ? ? ? ? ? ? ? ? ? ? ? by="hours",
>> ? ? ? ? ? ? ? ? ? ? ? ? length.out=10))
>>
>> z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))
>>
>> for (i in 1:10) {
>> z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
>> }
>>
>> sin3dA <- new("Spatial3dArray",
>> ? ? ? data = z,
>> ? ? ? coords = list(x, y),
>> ? ? ? bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2,
>> ? ? ? dimnames = list(NULL, c("min","max"))),
>> ? ? ? time = tm.c,
>> ? ? ? btime = c(min(tm.c), max(tm.c)))
>>
>> dimnames(slot(sin3dA, "data")) = list(NULL,
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? NULL,
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? slot(sin3dA, "time"),
>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? c("a"))
>> names(slot(sin3dA, "coords")) <- c("x", "y")
>>
>>
>> ##########################################
>>
>> for the coordinates method I would like to have two options on how to return
>> the coordinates; "list" or default "sp":
>>
>> coordinates.3dArray <- function (obj, type = "sp") {
>> ? ? ? lat <- slot(obj, "coords")[[1]]
>> ? ? ? long <- slot(obj, "coords")[[2]]
>> ? ? ? if (type == "list") {
>> ? ? ? ? ? ? ? return(list(long=long, lat=lat))
>> ? ? ? } else if (type == "sp") {
>> ? ? ? ? ? ? ? res <- as.matrix(cbind(c(long), c(lat)))
>> ? ? ? ? ? ? ? dimnames(res) <- list(NULL, c("x1", "x2"))
>> ? ? ? }
>> }
>> setMethod("coordinates", signature("Spatial3dArray"), coordinates.3dArray)
>>
>> This means that the default coordinates method in sp has to include the option
>> "..." . Would it be possible to include this in a future release of sp?
>>
>> The reason I want to keep the list option is to use a matrix oriented approach
>> in spplot, overlay, etc. methods. I also feel having a matrix/array approach
>> with these kind of data makes sense. Allowing type = "sp" means overlay() will
>> work more or less out of the box (however I would like to return a matrix),
>> and still I could get the list/matrix when desired.
>>
>>
>> Best wishes
>> Torleif Markussen Lunde
>> Centre for International Health
>> Bjerknes Centre for Climate Research
>> University of Bergen
>> Norway
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



------------------------------

Message: 18
Date: Thu, 19 Nov 2009 23:34:37 +0100
From: Torleif Markussen Lunde <torleif.lunde at cih.uib.no>
Subject: Re: [R-sig-Geo] Spatial3dArray - coordinates method
To: Michael Sumner <mdsumner at gmail.com>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <200911192334.37645.torleif.lunde at cih.uib.no>
Content-Type: Text/Plain;  charset="utf-8"

Hi Mike

At the moment I have written wrapper functions around ncdf. As in get.var.ncdf 
you can subset which area to read, and which (continuous) time dimensions you 
want to read. At the moment the functions (to correctly return time, lat and 
long) are limited to output from the WRF-model (http://www.wrf-model.org/), 
but it could easily be modified to other netcdf files as long you know the name 
of lat, long and time. 

If r-forge accepts my application (delivered yesterday) the methods should 
appear there soon as rwrf. 

Since ncdf works "out of the box" on Fedora I landed on that one. I also 
tested it on windows XP, and no problems there either. It is a couple of years 
since I tried RNetCDF, so I should not speak to strongly in favor for any of 
them. Of course the bad thing with both is that they have not been updated for 
a while. Still my impression is that they are both superior to GDALs NetCDF 
support(?). 

If the classes proves to be robust and the quality is sufficient it would be 
natural to include them in the sp package in the future (instead of having to 
dig around to look for sp classes). Currently spplot methods for 
Spatial3dArray only support plotting of single times for levelplot, 
contourplot, and wireframe (unless animation is requested). I have some 
problems with the lattice graphics inside functions (also with print()) that 
needs to be sorted out first. 

Examples:
first convert Spatial3dArray to data.frame
print(levelplot(z?long*lat | time, data = tmp.df, aspect="iso"))
will cause the last time to over plot all frames inside a function. 

What could work is:


for (i in 1:2) {
  if (i == 1) { 
    a <- paste('c(slot(surf, "data")[ , , ', i, ',2])', 
		sep = "")
  } else {
      a <- paste(a, ' + c(slot(surf, "data")[ , , ', i, ',2])', 
		  sep = "")
  }
}

levelplot(parse(text=a)? 
	    c(slot(surf, "coords")$long) * c(slot(surf, "coords")$lat), 
	    strip = strip.custom(factor.levels=c("time1", "time2")))

where neither parse, print(a, quote = FALSE) or cat works as the z variable. 
Probably this approach is not meant to work. 

There are quite some issues that has to be solved before the class is 
production-ready. 

By the way, if someone has an idea on how to solve the last code snippets I 
would be more than happy.

Best wishes
Torleif


On Thursday 19 November 2009 20:23:35 Michael Sumner wrote:
> Wow, this is great - I was thinking about this just yesterday.
> 
> Torleif: do you have an opinion on which NetCDF path is the most
> useful for R with sp? RNetCDF or ncdf? GDAL is workable but takes
> extra effort to build and then reconstruct 3d/4d from 2d bands. (I use
> Windows mostly)
> 
> I use the RNetCDF package a lot, mainly because that's the one I
> learnt to use first - there are binaries for Windows. It has some
> problems in terms of R-style but they could be easily fixed.
> 
> Regards, Mike.
> 
> On Fri, Nov 20, 2009 at 12:26 AM, Edzer Pebesma
> 
> <edzer.pebesma at uni-muenster.de> wrote:
> > No problems; sp in csv now has this, the next release will have it.
> >
> > Torleif Markussen Lunde wrote:
> >> Hi
> >>
> >> To read netcdf data (or any other "gridded" spatial time data) I find it
> >> convenient to define new classes Spatial3dArray and Spatial4dArray.
> >>
> >>  setClass("Spatial3dArray",
> >>         representation("Spatial", data = "array", coords = "list",
> >>                         time = "character", btime = "character"),
> >>         prototype= list(data = array(NA, c(1,1,1,1)),
> >>                         bbox=matrix(NA),
> >>                         proj4string = CRS(as.character(NA)),
> >>                         coords = list(1,1),
> >>                         time = "posix",
> >>                         btime = "posix"))
> >>
> >>
> >> ##########################################
> >> ###################EXAMPLE##################
> >> ##########################################
> >>
> >> x <- matrix(seq(-10, 10, length = 100), 100, 100,
> >>           byrow = FALSE)
> >> y <- matrix(seq(-10, 10, length = 100), 100, 100,
> >>           byrow = TRUE)
> >>
> >> tm <- 1:10
> >> tm.c <- as.character(seq(as.POSIXct("2002-01-01 06:00:00",
> >>                                   "2002-01-01 15:00:00"),
> >>                         by="hours",
> >>                         length.out=10))
> >>
> >> z <- array(NA, c(dim(x)[1], dim(x)[2], length(tm.c), 1))
> >>
> >> for (i in 1:10) {
> >> z[,,i,] <- i * ( sin(sqrt(x^2+y^2)))
> >> }
> >>
> >> sin3dA <- new("Spatial3dArray",
> >>       data = z,
> >>       coords = list(x, y),
> >>       bbox = matrix(c(min(x), min(y), max(x), max(y), 2, 2), 2, 2,
> >>       dimnames = list(NULL, c("min","max"))),
> >>       time = tm.c,
> >>       btime = c(min(tm.c), max(tm.c)))
> >>
> >> dimnames(slot(sin3dA, "data")) = list(NULL,
> >>                                     NULL,
> >>                                     slot(sin3dA, "time"),
> >>                                     c("a"))
> >> names(slot(sin3dA, "coords")) <- c("x", "y")
> >>
> >>
> >> ##########################################
> >>
> >> for the coordinates method I would like to have two options on how to
> >> return the coordinates; "list" or default "sp":
> >>
> >> coordinates.3dArray <- function (obj, type = "sp") {
> >>       lat <- slot(obj, "coords")[[1]]
> >>       long <- slot(obj, "coords")[[2]]
> >>       if (type == "list") {
> >>               return(list(long=long, lat=lat))
> >>       } else if (type == "sp") {
> >>               res <- as.matrix(cbind(c(long), c(lat)))
> >>               dimnames(res) <- list(NULL, c("x1", "x2"))
> >>       }
> >> }
> >> setMethod("coordinates", signature("Spatial3dArray"),
> >> coordinates.3dArray)
> >>
> >> This means that the default coordinates method in sp has to include the
> >> option "..." . Would it be possible to include this in a future release
> >> of sp?
> >>
> >> The reason I want to keep the list option is to use a matrix oriented
> >> approach in spplot, overlay, etc. methods. I also feel having a
> >> matrix/array approach with these kind of data makes sense. Allowing type
> >> = "sp" means overlay() will work more or less out of the box (however I
> >> would like to return a matrix), and still I could get the list/matrix
> >> when desired.
> >>
> >>
> >> Best wishes
> >> Torleif Markussen Lunde
> >> Centre for International Health
> >> Bjerknes Centre for Climate Research
> >> University of Bergen
> >> Norway
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > --
> > Edzer Pebesma
> > Institute for Geoinformatics (ifgi), University of M?nster
> > Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> > 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> > http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 



------------------------------

Message: 19
Date: Thu, 19 Nov 2009 22:18:42 -0500
From: Ned Horning <horning at amnh.org>
Subject: [R-sig-Geo] Problem using mahasuhab
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <4B060A92.10103 at amnh.org>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Hi - I was wondering if anyone out there can help with my effort to 
create habitat suitability maps using mahasuhab from the adehabitat 
package or another package if there is a better option. I would like to 
compare the resulting maps with some software a colleague is working on.

When I try to import an ascii grid using the import.asc method I get the 
following error:
--
Error in if ((yll[[1]][1] == "yllcenter") | (xll[[1]][1] == 
"YLLCENTER")) corny <- FALSE :
  missing value where TRUE/FALSE needed
In addition: Warning messages:
1: In import.asc(filename, type = "numeric") : NAs introduced by coercion
2: In import.asc(filename, type = "numeric") : NAs introduced by coercion
--

I am able to read the test ascii grid file that comes with the package 
just fine. I can also read my file using stack() from the raster package 
but I don't know how to convert that RasterStack to an asc or kasc 
object which seems to be necessary to run mahasuhab.

Any pointers?

Ned



------------------------------

Message: 20
Date: Thu, 19 Nov 2009 23:11:48 -0500
From: Mathieu Basille <basille at biomserv.univ-lyon1.fr>
Subject: Re: [R-sig-Geo] Problem using mahasuhab
To: Ned Horning <horning at amnh.org>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4B061704.10500 at biomserv.univ-lyon1.fr>
Content-Type: text/plain; charset=ISO-8859-1

Hi Ned,

Adehabitat was not meant to import all kind of raster maps. It might be
that your file is not in the right format. Are your file with such a header:

ncols 308
nrows 435
xllcorner 400000
yllcorner 6515000
cellsize 1000
NODATA_value -9999

(whatever the values are)

If yes, then it might be another deeper problem... Can you read it
through rgdal? If yes, you can use it and then convert it to a kasc
class, following this example:

bla <- readGDAL("your_map.asc")
blaK <- spixdf2kasc(bla)

Hope this helps,
Mathieu.


Ned Horning a ?crit :
> Hi - I was wondering if anyone out there can help with my effort to
> create habitat suitability maps using mahasuhab from the adehabitat
> package or another package if there is a better option. I would like to
> compare the resulting maps with some software a colleague is working on.
> 
> When I try to import an ascii grid using the import.asc method I get the
> following error:
> -- 
> Error in if ((yll[[1]][1] == "yllcenter") | (xll[[1]][1] ==
> "YLLCENTER")) corny <- FALSE :
>  missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In import.asc(filename, type = "numeric") : NAs introduced by coercion
> 2: In import.asc(filename, type = "numeric") : NAs introduced by coercion
> -- 
> 
> I am able to read the test ascii grid file that comes with the package
> just fine. I can also read my file using stack() from the raster package
> but I don't know how to convert that RasterStack to an asc or kasc
> object which seems to be necessary to run mahasuhab.
> 
> Any pointers?
> 
> Ned


-- 

?$ whoami
Mathieu Basille, Post-Doc

?$ locate
Laboratoire d'?cologie Comportementale et de Conservation de la Faune
+ Centre d'?tude de la For?t
D?partement de Biologie
Universit? Laval, Qu?bec

?$ info
http://ase-research.org/basille

?$ fortune
``If you can't win by reason, go for volume.''
Calvin, by Bill Watterson.



------------------------------

Message: 21
Date: Thu, 19 Nov 2009 23:22:34 -0500
From: Ned Horning <horning at amnh.org>
Subject: Re: [R-sig-Geo] Problem using mahasuhab
To: Mathieu Basille <basille at biomserv.univ-lyon1.fr>
Cc: r-sig-geo at stat.math.ethz.ch
Message-ID: <4B06198A.5040903 at amnh.org>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Mathieu,

Thanks for the help - rgdal / spixdf2kasc seems to have done the trick. 
Here is the header from my ascii grid:
--
ncols    900
nrows    1650
xllcorner    0
yllcorner    0
cellsize    1000
NODATA_value    -9999
--

All the best,

Ned

Mathieu Basille wrote:
> Hi Ned,
>
> Adehabitat was not meant to import all kind of raster maps. It might be
> that your file is not in the right format. Are your file with such a header:
>
> ncols 308
> nrows 435
> xllcorner 400000
> yllcorner 6515000
> cellsize 1000
> NODATA_value -9999
>
> (whatever the values are)
>
> If yes, then it might be another deeper problem... Can you read it
> through rgdal? If yes, you can use it and then convert it to a kasc
> class, following this example:
>
> bla <- readGDAL("your_map.asc")
> blaK <- spixdf2kasc(bla)
>
> Hope this helps,
> Mathieu.
>
>
> Ned Horning a ?crit :
>   
>> Hi - I was wondering if anyone out there can help with my effort to
>> create habitat suitability maps using mahasuhab from the adehabitat
>> package or another package if there is a better option. I would like to
>> compare the resulting maps with some software a colleague is working on.
>>
>> When I try to import an ascii grid using the import.asc method I get the
>> following error:
>> -- 
>> Error in if ((yll[[1]][1] == "yllcenter") | (xll[[1]][1] ==
>> "YLLCENTER")) corny <- FALSE :
>>  missing value where TRUE/FALSE needed
>> In addition: Warning messages:
>> 1: In import.asc(filename, type = "numeric") : NAs introduced by coercion
>> 2: In import.asc(filename, type = "numeric") : NAs introduced by coercion
>> -- 
>>
>> I am able to read the test ascii grid file that comes with the package
>> just fine. I can also read my file using stack() from the raster package
>> but I don't know how to convert that RasterStack to an asc or kasc
>> object which seems to be necessary to run mahasuhab.
>>
>> Any pointers?
>>
>> Ned
>>     
>
>
>



------------------------------

Message: 22
Date: Thu, 19 Nov 2009 21:54:42 -0700
From: Alan Swanson <alan.swanson at umontana.edu>
Subject: [R-sig-Geo] changing the data type of a gdal dataset
To: r-sig-geo at stat.math.ethz.ch
Message-ID: <4B062112.3080809 at umontana.edu>
Content-Type: text/plain; charset=ISO-8859-1; format=flowed

Dear R gurus,
I have a function that applies various model prediction functions over a 
set of large image files, producing a single output file with the same 
spatial extent.  Due to memory issues, I'm breaking the input and output 
files into tiles.  I have this working except for one small issue 
regarding data types. 

I create a new gdal transient dataset by copying an existing one using:
handle <- GDAL.open(fullnames[1],read.only=T)
tds <- 
copyDataset(handle,driver=new('GDALDriver','GTiff'),strict=F,options=NULL)
...
putRasterData(tds,t(preds), offset= c(strt[1], 0))
...
saveDataset(tds,outfile.p)
GDAL.close(tds)
      
Which works great, except that my output always needs to be floating 
point, but the input may be byte or integer, in which case the output 
dataset retains the format of the input file.  So I either need to 
change the data type of the new file, or create the new file using:
tds <- new("GDALTransientDataset",driver,dims[1],dims[2], type="Float32")

and then copy the spatial reference information from an existing 
dataset.  I can't figure out how to do either of these.  Your help would 
be much appreciated.
Cheers,
Alan



------------------------------

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


End of R-sig-Geo Digest, Vol 75, Issue 18


From b.rowlingson at lancaster.ac.uk  Fri Nov 20 13:09:35 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 20 Nov 2009 12:09:35 +0000
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>

2009/11/20 Yong Li <yong.li at unimelb.edu.au>:
> Dear all folks,
>
> I was informed in the 6th Digital Earth Conference that there is a better place to acquire high resolution of global DEM developed by ASTER, called GDEM with 30 m resolution, and fantastically free of charge. I tried some here (http://www.gdem.aster.ersdac.or.jp/) and it is really better than SRTM if you are outside USA.
> Hope you will enjoy the free meal.

 I just had a look at the tiles near me, and there's quite a bit of
noise and obvious artefacts - unless there really is a 2000m tower
about 180m across that I've not noticed in the middle of the
countryside!

I've not compared with SRTM yet...

Barry


From cara.tobin at epfl.ch  Fri Nov 20 15:06:03 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Fri, 20 Nov 2009 15:06:03 +0100
Subject: [R-sig-Geo] Error, exporting ascii grid generated by DTM grid
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8E7@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091120/213fb028/attachment.pl>

From ashton at msu.edu  Fri Nov 20 15:14:35 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Fri, 20 Nov 2009 09:14:35 -0500
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
Message-ID: <200911200914.35528.ashton@msu.edu>

On Friday 20 November 2009 07:09:35 Barry Rowlingson wrote:
> 2009/11/20 Yong Li <yong.li at unimelb.edu.au>:
> > Dear all folks,
> >
> > I was informed in the 6th Digital Earth Conference that there is a better
> > place to acquire high resolution of global DEM developed by ASTER, called
> > GDEM with 30 m resolution, and fantastically free of charge. I tried some
> > here (http://www.gdem.aster.ersdac.or.jp/) and it is really better than
> > SRTM if you are outside USA. Hope you will enjoy the free meal.
> 
>  I just had a look at the tiles near me, and there's quite a bit of
> noise and obvious artefacts - unless there really is a 2000m tower
> about 180m across that I've not noticed in the middle of the
> countryside!
> 
> I've not compared with SRTM yet...
> 
> Barry
> 

I looked at some here around the North American Great Lakes, and I have to say 
I would be very leery about using it in low relief areas. Visually it looked a 
lot nicer in the California coastal range, so perhaps less vegetation and 
higher relief is important for the sensor.

That said, it's terrific that alternative global medium-resolution DEMs are 
becoming available. Also, I think this ASTER-derived product has captured 
higher latitude locations than SRTM (which gets to about 60N and 60S), so it 
may be not simply the best but the only choice for many regions.

Ashton


-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From hengl at spatial-analyst.net  Fri Nov 20 16:53:15 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Fri, 20 Nov 2009 16:53:15 +0100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <200911200914.35528.ashton@msu.edu>
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch><86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au><d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
	<200911200914.35528.ashton@msu.edu>
Message-ID: <4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193>


Hi all,

FYI: I've run a small comparison between ASTER DEM and LIDAR DEMs (say 'true' topography):

http://geomorphometry.org/content/gdem-quick-assessment 

The 4 case studies can be downloaded from here:

http://geomorphometry.org/system/files/GDEM_assessment.zip 

I'm not too happy with what I've got - GDEM shows very strange patterns in area of low relief and I
definitively think that the 30 m resolution is overoptimistic; it should be degraded to 60-90 m
(this would enhance the data sharing and save them a lot of trouble). The positional accuracy of
GDEM is on the other hand pretty good.

GDEM is a frankestein - once you zoom in and add some shading, you can see the stitches, so have
this in mind (unlike SRTM DEM which is a complete and a consistent project; but also noisy in many
areas). 

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 



> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Ashton Shortridge
> Sent: Friday, November 20, 2009 3:15 PM
> To: r-sig-geo at stat.math.ethz.ch
> Cc: Yong Li
> Subject: Re: [R-sig-Geo] A new ASTER Global DEM data set
> 
> On Friday 20 November 2009 07:09:35 Barry Rowlingson wrote:
> > 2009/11/20 Yong Li <yong.li at unimelb.edu.au>:
> > > Dear all folks,
> > >
> > > I was informed in the 6th Digital Earth Conference that there is a better
> > > place to acquire high resolution of global DEM developed by ASTER, called
> > > GDEM with 30 m resolution, and fantastically free of charge. I tried some
> > > here (http://www.gdem.aster.ersdac.or.jp/) and it is really better than
> > > SRTM if you are outside USA. Hope you will enjoy the free meal.
> >
> >  I just had a look at the tiles near me, and there's quite a bit of
> > noise and obvious artefacts - unless there really is a 2000m tower
> > about 180m across that I've not noticed in the middle of the
> > countryside!
> >
> > I've not compared with SRTM yet...
> >
> > Barry
> >
> 
> I looked at some here around the North American Great Lakes, and I have to say
> I would be very leery about using it in low relief areas. Visually it looked a
> lot nicer in the California coastal range, so perhaps less vegetation and
> higher relief is important for the sensor.
> 
> That said, it's terrific that alternative global medium-resolution DEMs are
> becoming available. Also, I think this ASTER-derived product has captured
> higher latitude locations than SRTM (which gets to about 60N and 60S), so it
> may be not simply the best but the only choice for many regions.
> 
> Ashton
> 
> 
> --
> Ashton Shortridge
> Associate Professor			ashton at msu.edu
> Dept of Geography			http://www.msu.edu/~ashton
> 235 Geography Building		ph (517) 432-3561
> Michigan State University		fx (517) 432-1671
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From karl at huftis.org  Fri Nov 20 17:55:16 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Fri, 20 Nov 2009 17:55:16 +0100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
	<200911200914.35528.ashton@msu.edu>
	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193>
Message-ID: <MPG.2570e861cf3e07479896ad@news.gmane.org>

On Fri, 20 Nov 2009 16:53:15 +0100 Tomislav Hengl <hengl at spatial-
analyst.net> wrote:
> The 4 case studies can be downloaded from here:
> 
> http://geomorphometry.org/system/files/GDEM_assessment.zip 
> 
> GDEM is a frankestein - once you zoom in and add some shading,

The maps with shading look quite nice. Is there an R package/function
which can create similar images?

-- 
Karl Ove Hufthammer


From r.hijmans at gmail.com  Fri Nov 20 18:05:00 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 20 Nov 2009 09:05:00 -0800
Subject: [R-sig-Geo] Error, exporting ascii grid generated by DTM grid
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8E7@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8E7@REX2.intranet.epfl.ch>
Message-ID: <dc22b2570911200905y5d186b46sfd84f54b753afb81@mail.gmail.com>

Shouldn't this:

write.asciigrid(data_int_ked[1], name1)

be:

write.asciigrid(data_int_ked, name1)

I think you are writing a single cell, which in this case could be
interpreted as rectangular (if it covers the full grid)


On Fri, Nov 20, 2009 at 6:06 AM, Tobin Cara <cara.tobin at epfl.ch> wrote:
> Hello,
>
> I am receiving a bizarre error recently:
>
> Erreur dans write.asciigrid(data_int_ked[1], name1) :
> ?Asciigrid does not support grids with non-square cells
>
> I do not understand this as I am putting interpolated data back into the cells of an ascii DTM grid with square cells. Information on the DTM and the file I am trying to write is below:
>
> Thank you in advance for your help,
>
> Cara
>
>> # Bring in GIS elevation
>> elev <- read.asciigrid("val200dtm.asc", as.image=FALSE, plot.image=TRUE)
>> elev <- as.data.frame(elev)
>> names(elev) <- c("Z","X","Y")
>> elev.x <- elev$X
>> elev.y <- elev$Y
>> elev.z <- elev$Z
>> coordinates(elev) <- ~X+Y
>> gridded(elev) = TRUE
>> fullgrid(elev) = TRUE
>> str(elev)
> Formal class 'SpatialGridDataFrame' [package "sp"] with 6 slots
> ?..@ data ? ? ? :'data.frame': 278388 obs. of ?1 variable:
> ?.. ..$ Z: num [1:278388] NA NA NA NA NA NA NA NA NA NA ...
> ?..@ grid ? ? ? :Formal class 'GridTopology' [package "sp"] with 3 slots
> ?.. .. ..@ cellcentre.offset: Named num [1:2] 549720 78673
> ?.. .. .. ..- attr(*, "names")= chr [1:2] "X" "Y"
> ?.. .. ..@ cellsize ? ? ? ? : Named num [1:2] 200 200
> ?.. .. .. ..- attr(*, "names")= chr [1:2] "X" "Y"
> ?.. .. ..@ cells.dim ? ? ? ?: Named int [1:2] 627 444
> ?.. .. .. ..- attr(*, "names")= chr [1:2] "X" "Y"
> ?..@ grid.index : int(0)
> ?..@ coords ? ? : num [1:2, 1:2] 549720 674920 78673 167273
> ?.. ..- attr(*, "dimnames")=List of 2
> ?.. .. ..$ : NULL
> ?.. .. ..$ : chr [1:2] "X" "Y"
> ?..@ bbox ? ? ? : num [1:2, 1:2] 549620 78573 675020 167373
> ?.. ..- attr(*, "dimnames")=List of 2
> ?.. .. ..$ : chr [1:2] "X" "Y"
> ?.. .. ..$ : chr [1:2] "min" "max"
> ?..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slots
> ?.. .. ..@ projargs: chr NA
>
> # Interpolate and write the interpolated data to a file:
> list_ked <- vector("list",5)
> for(i in 1:5){
> ?list_ked[[i]] <- krige(Prec00[,1]~Z, locations=DataCoord, newdata=elev, model = fitted_vario)
> }
> ## Write files
> for(i in 1:5){
> ? ?data_int_ked <- list_ked[[i]]
> ? ?gridded(data_int_ked) = TRUE
> ? ?fullgrid(data_int_ked) = TRUE
> ? ?name1 <- sprintf("KEDelevpred_zeros_hr_%i.asc",i)
> ? ?write.asciigrid(data_int_ked[1], name1)
> }
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Fri Nov 20 18:14:33 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 20 Nov 2009 09:14:33 -0800
Subject: [R-sig-Geo] changing the data type of a gdal dataset
In-Reply-To: <4B062112.3080809@umontana.edu>
References: <4B062112.3080809@umontana.edu>
Message-ID: <dc22b2570911200914h59ed06b2l934ae255db4f01b2@mail.gmail.com>

Alan,
You can have a look at the code in the raster package on R-forge (see
the writeGDAL function). Or perhaps use this package: one of the
primary reasons for developing it was to automate (and hide) block by
block raster processing --- and quite successfully, it is being used
to process raster files that are too large for the leading commercial
gis software. See raster::predict to apply a model to a set or raster
predictors.
Robert

On Thu, Nov 19, 2009 at 8:54 PM, Alan Swanson <alan.swanson at umontana.edu> wrote:
> Dear R gurus,
> I have a function that applies various model prediction functions over a set
> of large image files, producing a single output file with the same spatial
> extent. ?Due to memory issues, I'm breaking the input and output files into
> tiles. ?I have this working except for one small issue regarding data types.
> I create a new gdal transient dataset by copying an existing one using:
> handle <- GDAL.open(fullnames[1],read.only=T)
> tds <-
> copyDataset(handle,driver=new('GDALDriver','GTiff'),strict=F,options=NULL)
> ...
> putRasterData(tds,t(preds), offset= c(strt[1], 0))
> ...
> saveDataset(tds,outfile.p)
> GDAL.close(tds)
> ? ? Which works great, except that my output always needs to be floating
> point, but the input may be byte or integer, in which case the output
> dataset retains the format of the input file. ?So I either need to change
> the data type of the new file, or create the new file using:
> tds <- new("GDALTransientDataset",driver,dims[1],dims[2], type="Float32")
>
> and then copy the spatial reference information from an existing dataset. ?I
> can't figure out how to do either of these. ?Your help would be much
> appreciated.
> Cheers,
> Alan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From horning at amnh.org  Fri Nov 20 18:58:34 2009
From: horning at amnh.org (Ned Horning)
Date: Fri, 20 Nov 2009 12:58:34 -0500
Subject: [R-sig-Geo] Writing an ASCII grid with nodata values
Message-ID: <4B06D8CA.7020202@amnh.org>

I am trying to export a SpatialPixelsDataFrame object with floating 
point values to an ASCII grid file and want to specify a nodata value. I 
tried write.asciigrid from the sp package and I couldn't figure out how 
to output float values. The pixel values exported as integers.

For now I am using the following writeGDAL statement:
--
writeGDAL(sp_hsm_pard, out_pard, drivername="AAIGrid", type="Float32", 
options="DECIMAL_PRECISION=3", "NODATA=-9999")

--
This appears to output the image okay but it is not assigning the proper 
values to NODATA_value. The NODATA_value in the exported file is "1" 
instead of "-9999".

Can someone let me know how to output floating point data to an ESRI 
ASCII grid file and specify a nodata value.

Thanks,

Ned


From p.hiemstra at geo.uu.nl  Sat Nov 21 09:34:27 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Sat, 21 Nov 2009 09:34:27 +0100
Subject: [R-sig-Geo] Writing an ASCII grid with nodata values
In-Reply-To: <4B06D8CA.7020202@amnh.org>
References: <4B06D8CA.7020202@amnh.org>
Message-ID: <4B07A613.6070809@geo.uu.nl>

Hi Ned,

Is it an option to switch to another GDAL format, GTiff for example? 
Check if this exports the NA values correctly. Not really an answer to 
your question, but maybe a helpful suggestion.

cheers and good luck,
Paul

Ned Horning wrote:
> I am trying to export a SpatialPixelsDataFrame object with floating 
> point values to an ASCII grid file and want to specify a nodata value. 
> I tried write.asciigrid from the sp package and I couldn't figure out 
> how to output float values. The pixel values exported as integers.
>
> For now I am using the following writeGDAL statement:
> -- 
> writeGDAL(sp_hsm_pard, out_pard, drivername="AAIGrid", type="Float32", 
> options="DECIMAL_PRECISION=3", "NODATA=-9999")
>
> -- 
> This appears to output the image okay but it is not assigning the 
> proper values to NODATA_value. The NODATA_value in the exported file 
> is "1" instead of "-9999".
>
> Can someone let me know how to output floating point data to an ESRI 
> ASCII grid file and specify a nodata value.
>
> Thanks,
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From alobolistas at gmail.com  Sat Nov 21 14:16:49 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 21 Nov 2009 14:16:49 +0100
Subject: [R-sig-Geo] distance in package raster
Message-ID: <4B07E841.6050709@gmail.com>

Hi

According to the manual page for distance in package raster
"The function calculates the distance to cells of a RasterLayer that are NA."

wouldn't it be better letting the user select the actual value(s)
to be considered as focal pixels? The package is mainly intended to
process large raster layers, so avoiding the need of modifying the
raster prior to run the command would make sense (few users are going
to have the focal points as NA).

Thanks for your attention,

Agus


From alobolistas at gmail.com  Sat Nov 21 14:20:03 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 21 Nov 2009 14:20:03 +0100
Subject: [R-sig-Geo] polygons to grid?
Message-ID: <4B07E903.5000806@gmail.com>

Hi?

Is it possible to perform a vector to raster conversion in R,
from SpatialPolygonsDataFrame to a SpatialGrid (providing the final resolution?

In particular, is it possible to do it using package raster?

(I know this can be done using gdal or grass etc, but I'm trying
to find an "only R" solution)

Thanks

Agus


From b.rowlingson at lancaster.ac.uk  Sat Nov 21 14:36:12 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 21 Nov 2009 13:36:12 +0000
Subject: [R-sig-Geo] polygons to grid?
In-Reply-To: <4B07E903.5000806@gmail.com>
References: <4B07E903.5000806@gmail.com>
Message-ID: <d8ad40b50911210536u4d38385au8ecb10f2bc45402b@mail.gmail.com>

On Sat, Nov 21, 2009 at 1:20 PM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi?
>
> Is it possible to perform a vector to raster conversion in R,
> from SpatialPolygonsDataFrame to a SpatialGrid (providing the final
> resolution?

 If what you want is a raster grid storing the value of some attribute
of polygons sampled at a grid of locations, see help(overlay) and
help("overlay-methods") in package sp. Note the complications that can
happen if your polygons overlap.

 Another possibility is simply to plot your polygons to a png device
with no margins or axes or other decorations. I'd call this a
different class of vector-raster conversion, and might be what you
need if you want a raster representation of the outline of your
polygons. You'd then need to read in the png and set coordinates with
the other various raster handling functions.

Barry


From Roger.Bivand at nhh.no  Sat Nov 21 16:01:25 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 21 Nov 2009 16:01:25 +0100 (CET)
Subject: [R-sig-Geo] Writing an ASCII grid with nodata values
In-Reply-To: <4B07A613.6070809@geo.uu.nl>
References: <4B06D8CA.7020202@amnh.org> <4B07A613.6070809@geo.uu.nl>
Message-ID: <alpine.LRH.2.00.0911211553260.2699@reclus.nhh.no>

On Sat, 21 Nov 2009, Paul Hiemstra wrote:

> Hi Ned,
>
> Is it an option to switch to another GDAL format, GTiff for example? Check if 
> this exports the NA values correctly. Not really an answer to your question, 
> but maybe a helpful suggestion.
>
> cheers and good luck,
> Paul
>
> Ned Horning wrote:
>> I am trying to export a SpatialPixelsDataFrame object with floating point 
>> values to an ASCII grid file and want to specify a nodata value. I tried 
>> write.asciigrid from the sp package and I couldn't figure out how to output 
>> float values. The pixel values exported as integers.
>> 
>> For now I am using the following writeGDAL statement:
>> -- 
>> writeGDAL(sp_hsm_pard, out_pard, drivername="AAIGrid", type="Float32", 
>> options="DECIMAL_PRECISION=3", "NODATA=-9999")

Maybe reading:

> args(writeGDAL)
function (dataset, fname, drivername = "GTiff", type = "Float32",
     mvFlag = NA, options = NULL, copy_drivername = "GTiff")

would help?

You are getting:

dataset=sp_hsm_pard, fname=out_pard, drivername="AAIGrid", type="Float32", 
options="DECIMAL_PRECISION=3", mvFlag="NODATA=-9999"

by argument names and positions, I think, where internally 
as.double("NODATA=-9999") is being coerced to an NA (a warning may have 
been shown.

Perhaps try setting mvFlag=-9999? If you wanted to put it in the options, 
that may work, but as.double(mvFlag) is explicitly set as the no-data 
value on the band(s) being written in create2GDAL() inside writeGDAL().

Hope this helps,

Roger


>> 
>> -- 
>> This appears to output the image okay but it is not assigning the proper 
>> values to NODATA_value. The NODATA_value in the exported file is "1" 
>> instead of "-9999".
>> 
>> Can someone let me know how to output floating point data to an ESRI ASCII 
>> grid file and specify a nodata value.
>> 
>> Thanks,
>> 
>> Ned
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From eboyd3 at tigers.lsu.edu  Sat Nov 21 18:54:46 2009
From: eboyd3 at tigers.lsu.edu (Ezra Boyd)
Date: Sat, 21 Nov 2009 11:54:46 -0600
Subject: [R-sig-Geo] Spatially Weighted T-Test?
Message-ID: <d0248ce60911210954raed2adag70a79c7acfc5ea49@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091121/769a2808/attachment.pl>

From r.hijmans at gmail.com  Sat Nov 21 19:21:51 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 21 Nov 2009 10:21:51 -0800
Subject: [R-sig-Geo] polygons to grid?
In-Reply-To: <4B07E903.5000806@gmail.com>
References: <4B07E903.5000806@gmail.com>
Message-ID: <dc22b2570911211021y34790ecas7f913bafc9d863a@mail.gmail.com>

Agus,

Please see   raster::polygonsToRaster

Let 'p' be a SpatialPolygonsDF. Create an appropriate RasterLayer
object, for example use the extent of the polygons and set the
resolution.

r <- raster(extent(p))
res(r) <- 1

# then:
r <- polygonsToRaster(p, r)   # there are additional arguments to consider

# to coerce into a SPGDF
spg <- as(r, 'SpatialGridDataFrame')


There was a discussion earlier this year, I believe, where there was
also an example to do this entirely in sp (using point in polygon
overlays)

Robert


On Sat, Nov 21, 2009 at 5:20 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi?
>
> Is it possible to perform a vector to raster conversion in R,
> from SpatialPolygonsDataFrame to a SpatialGrid (providing the final
> resolution?
>
> In particular, is it possible to do it using package raster?
>
> (I know this can be done using gdal or grass etc, but I'm trying
> to find an "only R" solution)
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Sat Nov 21 22:05:18 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Sat, 21 Nov 2009 13:05:18 -0800
Subject: [R-sig-Geo] polygons to grid?
In-Reply-To: <4B083F6D.3090809@ija.csic.es>
References: <4B07E903.5000806@gmail.com>
	<dc22b2570911211021y34790ecas7f913bafc9d863a@mail.gmail.com>
	<4B083F6D.3090809@ija.csic.es>
Message-ID: <dc22b2570911211305q49a79a21i446ee6be8c162c9a@mail.gmail.com>

Hi Agus,

In this function, and in all other functions in 'raster', the values
of a new RasterLayer object are written to disk if they cannot be
stored in memory (they are saved in a temporary file that is erased
the next time you load the package). To force writing to disk, and to
a more permanent file, you can provide an argument "filename=  "  (and
"format= " to choose the file format).

Robert

On Sat, Nov 21, 2009 at 11:28 AM, Agustin Lobo <Agustin.Lobo at ija.csic.es> wrote:
> Perfect,
> this is what I do:
> #Equivalent to
> #v.to.rast input=visit output=visitCODEQP use=attr column=CODI_EQP
> visitCODEQP <- raster(extent(visit))
> res(visitCODEQP) <- 100
> visitCODEQP <- polygonsToRaster((spPolys=visit,
> raster=visitCODEQP,field="CODI_EQP")
> [1] "Found 39 regions and ?39 polygons"
> [1] "finished in ?0 minutes, at 0 seconds/row"
>
> Just a concern: is the new raster (visitCODEQP in the example) loaded into
> memory? Potentially, it could be very large.
>
> Thanks a lot!
>
> Agus
>
> Robert J. Hijmans wrote:
>>
>> Agus,
>>
>> Please see ? raster::polygonsToRaster
>>
>> Let 'p' be a SpatialPolygonsDF. Create an appropriate RasterLayer
>> object, for example use the extent of the polygons and set the
>> resolution.
>>
>> r <- raster(extent(p))
>> res(r) <- 1
>>
>> # then:
>> r <- polygonsToRaster(p, r) ? # there are additional arguments to consider
>>
>> # to coerce into a SPGDF
>> spg <- as(r, 'SpatialGridDataFrame')
>>
>>
>> There was a discussion earlier this year, I believe, where there was
>> also an example to do this entirely in sp (using point in polygon
>> overlays)
>>
>> Robert
>>
>>
>> On Sat, Nov 21, 2009 at 5:20 AM, Agustin Lobo <alobolistas at gmail.com>
>> wrote:
>>>
>>> Hi?
>>>
>>> Is it possible to perform a vector to raster conversion in R,
>>> from SpatialPolygonsDataFrame to a SpatialGrid (providing the final
>>> resolution?
>>>
>>> In particular, is it possible to do it using package raster?
>>>
>>> (I know this can be done using gdal or grass etc, but I'm trying
>>> to find an "only R" solution)
>>>
>>> Thanks
>>>
>>> Agus
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>
> --
> Dr. Agustin Lobo
> Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
> LLuis Sole Sabaris s/n
> 08028 Barcelona
> Spain
> Tel. 34 934095410
> Fax. 34 934110012
> email: Agustin.Lobo at ija.csic.es
> http://www.ija.csic.es/gt/obster
>


From horning at amnh.org  Sun Nov 22 03:47:00 2009
From: horning at amnh.org (Ned Horning)
Date: Sat, 21 Nov 2009 21:47:00 -0500
Subject: [R-sig-Geo] Writing an ASCII grid with nodata values
In-Reply-To: <alpine.LRH.2.00.0911211553260.2699@reclus.nhh.no>
References: <4B06D8CA.7020202@amnh.org> <4B07A613.6070809@geo.uu.nl>
	<alpine.LRH.2.00.0911211553260.2699@reclus.nhh.no>
Message-ID: <4B08A624.2030702@amnh.org>

Roger,

Thanks for the note. Using:

options="DECIMAL_PRECISION=3", mvFlag=-9999

did the trick.

All the best,

Ned

Roger Bivand wrote:
> On Sat, 21 Nov 2009, Paul Hiemstra wrote:
>
>> Hi Ned,
>>
>> Is it an option to switch to another GDAL format, GTiff for example? 
>> Check if this exports the NA values correctly. Not really an answer 
>> to your question, but maybe a helpful suggestion.
>>
>> cheers and good luck,
>> Paul
>>
>> Ned Horning wrote:
>>> I am trying to export a SpatialPixelsDataFrame object with floating 
>>> point values to an ASCII grid file and want to specify a nodata 
>>> value. I tried write.asciigrid from the sp package and I couldn't 
>>> figure out how to output float values. The pixel values exported as 
>>> integers.
>>>
>>> For now I am using the following writeGDAL statement:
>>> -- 
>>> writeGDAL(sp_hsm_pard, out_pard, drivername="AAIGrid", 
>>> type="Float32", options="DECIMAL_PRECISION=3", "NODATA=-9999")
>
> Maybe reading:
>
>> args(writeGDAL)
> function (dataset, fname, drivername = "GTiff", type = "Float32",
>     mvFlag = NA, options = NULL, copy_drivername = "GTiff")
>
> would help?
>
> You are getting:
>
> dataset=sp_hsm_pard, fname=out_pard, drivername="AAIGrid", 
> type="Float32", options="DECIMAL_PRECISION=3", mvFlag="NODATA=-9999"
>
> by argument names and positions, I think, where internally 
> as.double("NODATA=-9999") is being coerced to an NA (a warning may 
> have been shown.
>
> Perhaps try setting mvFlag=-9999? If you wanted to put it in the 
> options, that may work, but as.double(mvFlag) is explicitly set as the 
> no-data value on the band(s) being written in create2GDAL() inside 
> writeGDAL().
>
> Hope this helps,
>
> Roger
>
>
>>>
>>> -- 
>>> This appears to output the image okay but it is not assigning the 
>>> proper values to NODATA_value. The NODATA_value in the exported file 
>>> is "1" instead of "-9999".
>>>
>>> Can someone let me know how to output floating point data to an ESRI 
>>> ASCII grid file and specify a nodata value.
>>>
>>> Thanks,
>>>
>>> Ned
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>


From jutesoro at yahoo.com  Sun Nov 22 12:38:53 2009
From: jutesoro at yahoo.com (Julius Tesoro)
Date: Sun, 22 Nov 2009 03:38:53 -0800 (PST)
Subject: [R-sig-Geo] gstat to dem
Message-ID: <560982.54097.qm@web57608.mail.re1.yahoo.com>

Hello R-People,

I always read about importing DEM to R but how about converting R data to DEM? I have an interpolated SpatialPixelsDataFrame generated by gstat and want to export this as a DEM file. Are there tutorials for these?

Advanced thanks for the help.


Cheers,

Julius Tesoro


From Roger.Bivand at nhh.no  Sun Nov 22 14:15:59 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 22 Nov 2009 14:15:59 +0100 (CET)
Subject: [R-sig-Geo] Spatially Weighted T-Test?
In-Reply-To: <d0248ce60911210954raed2adag70a79c7acfc5ea49@mail.gmail.com>
References: <d0248ce60911210954raed2adag70a79c7acfc5ea49@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0911221404250.12854@reclus.nhh.no>

On Sat, 21 Nov 2009, Ezra Boyd wrote:

> Hi Everyone,
>
> I have a spatial dataset (US Counties with basic Census attributes and an
> attribute denoting whether or not the county has a flood protection levee)
> and I used t.test to compare the means between the groups.
>
> All of my variables show clustering and neighborhood effects.  Is there a
> t.test procedure that accounts for spatial correlation?  Is this even
> necessary?

In theory yes, but there are no implementations, because they are not 
really needed. Fit a linear model using the levee factor as the 
independent variable, and test the output object with lm.morantest() in 
the spdep package. If need be, you may also fit a spatial regression 
model. Note that your levee/no_levee variable is itself highly patterned.

It may be sensible to think through how your collection of dependent 
variables are related to each other, as the presence or absence of a levee 
is unlikely to be the only relevant explanatory variable, and missing 
variables will probably increase spatial patterning in the residuals. You 
may even need to restrict your comparison to otherwise similar counties 
near major water bodies of similar topography with and without levees to 
see anything worthwhile.

>
> I've looked through Applied Spatial Data Analysis with R along with many of
> the tutorials and notes available online and I have not found any mention of
> such a procedure.  In Dalgaard (2008) I found the following statement about
> the t.test: 'The t tests are fairly robust against departures from the
> normal distribution' which seems to say that it is not necessary to account
> for spatial effects.

I don't know how you draw this conclusion, the two are unrelated. The 
presence of spatial autocorrelation will have the effect of reducing your 
effective degrees of freedom. Dalgaard's assertion is based on independent 
observations, which you have already stated that you do not have, hence 
the drop in effective n proportional to the strength of positive 
dependence.

Hope this helps,

Roger

> But, I wanted to see what people on the list thought about that?
>
> Thanks,
> Ezra
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From ashton at msu.edu  Sun Nov 22 19:04:51 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Sun, 22 Nov 2009 13:04:51 -0500
Subject: [R-sig-Geo] gstat to dem
In-Reply-To: <560982.54097.qm@web57608.mail.re1.yahoo.com>
References: <560982.54097.qm@web57608.mail.re1.yahoo.com>
Message-ID: <200911221304.51420.ashton@msu.edu>

On Sunday 22 November 2009 06:38:53 Julius Tesoro wrote:
> Hello R-People,
> 
> I always read about importing DEM to R but how about converting R data to
>  DEM? I have an interpolated SpatialPixelsDataFrame generated by gstat and
>  want to export this as a DEM file. Are there tutorials for these?
> 
> Advanced thanks for the help.
> 
> 
> Cheers,
> 
> Julius Tesoro
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
There are several choices. write.asciigrid in the sp package might be all you 
need. Similar functionality is in writeAsciiGrid in maptools. If not, check 
out the rgdal package, which can handle a number of raster data formats.

Yours,

Ashton

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From michael.denslow at gmail.com  Sun Nov 22 19:23:30 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Sun, 22 Nov 2009 13:23:30 -0500
Subject: [R-sig-Geo] strange srtm3 query in geonames package
Message-ID: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>

Dear r-sig-geo and Barry,

I am getting a strange value when doing a query using the function
GNsrtm3 in the geonames package.
Here is the code.

library(geonames)
GNsrtm3(34.63874,-79.10111)  # outside Lumberton North Carolina USA!


   srtm3       lng      lat
1 -32768 -79.10111 34.63874

Warning message:
In readLines(u) :
  incomplete final line found on
'http://ws.geonames.org/srtm3JSON?lat=34.63874&lng=-79.10111'


I think the elevation value should be around 47 meters. The geonames
website says 'ocean areas have been masked as "no data" and have been
assigned a value of -32768'.
http://www.geonames.org/export/web-services.html#srtm3
I tried adjusting the lat, long values to query some nearby cells but
I still get -32768.

Are these kinds of errors common in this dataset? Any suggestions?
I am would actually prefer to get an average elevation for the county
(Robeson) but am settling for the county centroid at this point.


Thanks in advance,
Michael


-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From b.rowlingson at lancaster.ac.uk  Sun Nov 22 20:02:53 2009
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 22 Nov 2009 19:02:53 +0000
Subject: [R-sig-Geo] strange srtm3 query in geonames package
In-Reply-To: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
Message-ID: <d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>

On Sun, Nov 22, 2009 at 6:23 PM, Michael Denslow
<michael.denslow at gmail.com> wrote:
> Dear r-sig-geo and Barry,
>
> I am getting a strange value when doing a query using the function
> GNsrtm3 in the geonames package.
> Here is the code.
>
> library(geonames)
> GNsrtm3(34.63874,-79.10111) ?# outside Lumberton North Carolina USA!
>
>
> ? srtm3 ? ? ? lng ? ? ?lat
> 1 -32768 -79.10111 34.63874
>
> Warning message:
> In readLines(u) :
> ?incomplete final line found on
> 'http://ws.geonames.org/srtm3JSON?lat=34.63874&lng=-79.10111'
>
>
> I think the elevation value should be around 47 meters. The geonames
> website says 'ocean areas have been masked as "no data" and have been
> assigned a value of -32768'.
> http://www.geonames.org/export/web-services.html#srtm3
> I tried adjusting the lat, long values to query some nearby cells but
> I still get -32768.
>
> Are these kinds of errors common in this dataset? Any suggestions?
> I am would actually prefer to get an average elevation for the county
> (Robeson) but am settling for the county centroid at this point.

 I don't really know the details of the srtm3 data set, but I do see
that geonames has two other DEM datasets - ASTER and GTOPO30. There's
a function for GTOPO30 in geonames, but not ASTER. It's easy enough to
write though:

> GNaster=function(lat,lng){return(as.data.frame(geonames:::getJson("astergdemJSON",list(lat=lat,lng=lng))))}

 and I may include it in a new release (as well as getting rid of
those end-of-line warnings). These two services agree with themselves
and with you pretty well for your test location:

> GNgtopo30(34.63874,-79.10111)
  gtopo30       lng      lat
1      46 -79.10111 34.63874

> GNaster(34.63874,-79.10111)
  astergdem       lng      lat
1        47 -79.10111 34.63874

 For an 'average' elevation you might be better off sampling many
locations over your polygon.

Barry


From michael.denslow at gmail.com  Sun Nov 22 20:19:46 2009
From: michael.denslow at gmail.com (Michael Denslow)
Date: Sun, 22 Nov 2009 14:19:46 -0500
Subject: [R-sig-Geo] strange srtm3 query in geonames package
In-Reply-To: <d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>
Message-ID: <b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>

Thanks Barry!

On Sun, Nov 22, 2009 at 2:02 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Sun, Nov 22, 2009 at 6:23 PM, Michael Denslow
> <michael.denslow at gmail.com> wrote:
>> Dear r-sig-geo and Barry,
>>
>> I am getting a strange value when doing a query using the function
>> GNsrtm3 in the geonames package.
>> Here is the code.
>>
>> library(geonames)
>> GNsrtm3(34.63874,-79.10111) ?# outside Lumberton North Carolina USA!
>>
>>
>> ? srtm3 ? ? ? lng ? ? ?lat
>> 1 -32768 -79.10111 34.63874
>>
>> Warning message:
>> In readLines(u) :
>> ?incomplete final line found on
>> 'http://ws.geonames.org/srtm3JSON?lat=34.63874&lng=-79.10111'
>>
>>
>> I think the elevation value should be around 47 meters. The geonames
>> website says 'ocean areas have been masked as "no data" and have been
>> assigned a value of -32768'.
>> http://www.geonames.org/export/web-services.html#srtm3
>> I tried adjusting the lat, long values to query some nearby cells but
>> I still get -32768.
>>
>> Are these kinds of errors common in this dataset? Any suggestions?
>> I am would actually prefer to get an average elevation for the county
>> (Robeson) but am settling for the county centroid at this point.
>
> ?I don't really know the details of the srtm3 data set, but I do see
> that geonames has two other DEM datasets - ASTER and GTOPO30. There's
> a function for GTOPO30 in geonames, but not ASTER. It's easy enough to
> write though:
>
>> GNaster=function(lat,lng){return(as.data.frame(geonames:::getJson("astergdemJSON",list(lat=lat,lng=lng))))}
>
> ?and I may include it in a new release (as well as getting rid of
> those end-of-line warnings). These two services agree with themselves
> and with you pretty well for your test location:

It would be great to have GNaster added.

>
>> GNgtopo30(34.63874,-79.10111)
> ?gtopo30 ? ? ? lng ? ? ?lat
> 1 ? ? ?46 -79.10111 34.63874
>
>> GNaster(34.63874,-79.10111)
> ?astergdem ? ? ? lng ? ? ?lat
> 1 ? ? ? ?47 -79.10111 34.63874
>
> ?For an 'average' elevation you might be better off sampling many
> locations over your polygon.

Sounds like a good idea.

Thanks again for your help!

Michael

>
> Barry
>



-- 
Michael Denslow

Graduate Student & Adjunct Instructor
I.W. Carpenter Jr. Herbarium [BOON]
Department of Biology
Appalachian State University
Boone, North Carolina U.S.A.
-- AND --
Communications Manager
Southeast Regional Network of Expertise and Collections
sernec.org

36.214177, -81.681480 +/- 3103 meters


From p.hiemstra at geo.uu.nl  Mon Nov 23 14:16:35 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 23 Nov 2009 14:16:35 +0100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <MPG.2570e861cf3e07479896ad@news.gmane.org>
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>	<200911200914.35528.ashton@msu.edu>	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193>
	<MPG.2570e861cf3e07479896ad@news.gmane.org>
Message-ID: <4B0A8B33.9010304@geo.uu.nl>

Karl Ove Hufthammer wrote:
> On Fri, 20 Nov 2009 16:53:15 +0100 Tomislav Hengl <hengl at spatial-
> analyst.net> wrote:
>   
>> The 4 case studies can be downloaded from here:
>>
>> http://geomorphometry.org/system/files/GDEM_assessment.zip 
>>
>> GDEM is a frankestein - once you zoom in and add some shading,
>>     
>
> The maps with shading look quite nice. Is there an R package/function
> which can create similar images?
>
>   
A good place to look for these kinds of graphs and how to make them is 
the R graph gallery [1]. Check out this one for example [2].

cheers,
Paul

[1] http://addictedtor.free.fr/graphiques/thumbs.php
[2] http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=27

-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From torleif.lunde at cih.uib.no  Mon Nov 23 14:21:14 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Mon, 23 Nov 2009 14:21:14 +0100
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>
	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>
Message-ID: <200911231421.14216.torleif.lunde@cih.uib.no>

Hi

As previously mentioned I am working on 3D and 4D spatial classes. To get 
things compatible with the other sp-classes I would like to ask for your 
opinion what would be the most suitable bbox methods for Spatial3dArrays and 
Spatial4dArrays.

My first thought was that bbox should return the 2D geographical extent of the 
object. This to comply with other spatial methods. For the 3D case an 
additional slot, btime is added to show the temporal extent of the object. As 
writing the 4D case, I started wondering whether it would be wise to stick to 
this (my conclusion at the moment is yes). In that case a new slot called 
zextent could be added.

To retrieve the extent of the different dimensions one would have three 
functions; bbox(), btime(), and zextent()

The other option is to make a bbox slot as a list. bbox() would still return 
x-y extent, while bbox.full() could return a list of the full extent:

list(bbox = matrix(c(1,1,4,4), 2,2, 
     			dimnames = list(c("long", "lat"), 
		     	c("min", "max"))),
    btime = matrix(c("2002-01-01 06:00:00", "2002-01-01 06:00:00"), 1, 2, 
     			dimnames = list(c("time"), 
		     	c("min", "max"))),
    zextent = matrix(c(512, 1024), 1,2, 
     			dimnames = list(c("masl"), 
		     	c("min", "max"))))

Since bbox is defined as a matrix in Spatial, this would be a bad idea. So, at 
best bbox could be a matrix of min/max of x, y, and z (since they all are 
numeric). bbox() would then return a x, y subset of bbox(), while bbox.full() 
could return a list(xyz, time). 

Any comments on what would be best suitable to be compatible with the other 
Spatial classes?

Best wishes
Torleif
PhD candidate
Centre for International Health
Bjerknes Centre for Climate Research
University of Bergen
Norway


From tomfool at as220.org  Mon Nov 23 14:41:18 2009
From: tomfool at as220.org (tom sgouros)
Date: Mon, 23 Nov 2009 08:41:18 -0500
Subject: [R-sig-Geo] Map labels
Message-ID: <7780.1258983678@as220.org>


Hello all:

Thanks to all your earlier help, I'm now using spplot to generate a map
of about 400 polygons representing about 40 different towns.  In
addition to being able to color the polygons, I would like to label the
plots with a number or the town name. 

Being near the water, there are lots of islands, so each town is
represented by a bunch of polygons.  How do I select only one to be
labeled, and is there a convention for which one would be the best to
use?  I see the labpt slot, in my SpatialPolygonsDataFrame object, but I
don't see a mostAppropriateLabpt or primaryLabpt or anything like that.

In addition to this, I get no errors when I follow the examples at
http://r-spatial.sourceforge.net/gallery/ , but I see no labels, either.

This is what I'm doing.  Are the colors covering my labels?

  spplot(rep.map,zcol="vote02",at=breaks,col.regions=rg,
        layout=list(list("sp.text",getSpPPolygonsLabptSlots(rep.map)[25,],"HERE I AM")))


Many thanks,

 -tom

-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From edzer.pebesma at uni-muenster.de  Mon Nov 23 14:45:16 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 23 Nov 2009 14:45:16 +0100
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <200911231421.14216.torleif.lunde@cih.uib.no>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>
	<200911231421.14216.torleif.lunde@cih.uib.no>
Message-ID: <4B0A91EC.8030504@uni-muenster.de>

Torleif,

sp classes SpatialPoints* SpatialPixels* and SpatialGrid* already allow
3- and higher dimensional data; providing an example with nonsense data:

> library(sp)
> data(meuse)
> meuse$z = rnorm(155)
> coordinates(meuse)=~x+y+z
> summary(as(meuse, "SpatialPoints"))
Object of class SpatialPoints
Coordinates:
            min          max
x 178605.000000 1.813900e+05
y 329714.000000 3.336110e+05
z     -2.168683 3.006463e+00
Is projected: NA
proj4string : [NA]
Number of points: 155

It can be used this way to do 3D interpolation (package gstat), and
several of the sp methods work; obviously, several do ignore everything
beyond x and y.

If you store your time as double, you can even think about adding that
as one of the coordinates.

Chapter 6 of http://www.asdar-book.org/ gives code examples of this
approach, where a third dimension represents (posix) time, and methods
are given to select a certain spatial grid from a
SpatialTimeGridDataFrame based on its posix time (range).

The motivation for your approach becomes stronger when time cannot be
stored as double (numeric); I find it harder to see the motivation to
store z differently from the x and y coordinates, create a separate
bounding box for it and rewrite all methods.
--
Edzer


Torleif Markussen Lunde wrote:
> Hi
>
> As previously mentioned I am working on 3D and 4D spatial classes. To get 
> things compatible with the other sp-classes I would like to ask for your 
> opinion what would be the most suitable bbox methods for Spatial3dArrays and 
> Spatial4dArrays.
>
> My first thought was that bbox should return the 2D geographical extent of the 
> object. This to comply with other spatial methods. For the 3D case an 
> additional slot, btime is added to show the temporal extent of the object. As 
> writing the 4D case, I started wondering whether it would be wise to stick to 
> this (my conclusion at the moment is yes). In that case a new slot called 
> zextent could be added.
>
> To retrieve the extent of the different dimensions one would have three 
> functions; bbox(), btime(), and zextent()
>
> The other option is to make a bbox slot as a list. bbox() would still return 
> x-y extent, while bbox.full() could return a list of the full extent:
>
> list(bbox = matrix(c(1,1,4,4), 2,2, 
>      			dimnames = list(c("long", "lat"), 
> 		     	c("min", "max"))),
>     btime = matrix(c("2002-01-01 06:00:00", "2002-01-01 06:00:00"), 1, 2, 
>      			dimnames = list(c("time"), 
> 		     	c("min", "max"))),
>     zextent = matrix(c(512, 1024), 1,2, 
>      			dimnames = list(c("masl"), 
> 		     	c("min", "max"))))
>
> Since bbox is defined as a matrix in Spatial, this would be a bad idea. So, at 
> best bbox could be a matrix of min/max of x, y, and z (since they all are 
> numeric). bbox() would then return a x, y subset of bbox(), while bbox.full() 
> could return a list(xyz, time). 
>
> Any comments on what would be best suitable to be compatible with the other 
> Spatial classes?
>
> Best wishes
> Torleif
> PhD candidate
> Centre for International Health
> Bjerknes Centre for Climate Research
> University of Bergen
> Norway
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From zua3 at cornell.edu  Mon Nov 23 15:09:09 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Mon, 23 Nov 2009 09:09:09 -0500
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <4B0A91EC.8030504@uni-muenster.de>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>
	<4B0A91EC.8030504@uni-muenster.de>
Message-ID: <4B0A9785.6020604@cornell.edu>

Hi all,

Is it possible in gstat to get misclassification  of risks as hazardous 
(false positive) and safe (false negative) as describe by
Goovaerts (1997)  from parametric or non-parametric probability 
mapping?.  help will appreciated.

Thanks

Zia


-------------- next part --------------
A non-text attachment was scrubbed...
Name: zua3.vcf
Type: text/x-vcard
Size: 281 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/e2f2ebc3/attachment.vcf>

From Roger.Bivand at nhh.no  Mon Nov 23 15:12:42 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Nov 2009 15:12:42 +0100 (CET)
Subject: [R-sig-Geo] Map labels
In-Reply-To: <7780.1258983678@as220.org>
References: <7780.1258983678@as220.org>
Message-ID: <alpine.LRH.2.00.0911231503250.2730@reclus.nhh.no>

On Mon, 23 Nov 2009, tom sgouros wrote:

>
> Hello all:
>
> Thanks to all your earlier help, I'm now using spplot to generate a map
> of about 400 polygons representing about 40 different towns.  In
> addition to being able to color the polygons, I would like to label the
> plots with a number or the town name.
>
> Being near the water, there are lots of islands, so each town is
> represented by a bunch of polygons.  How do I select only one to be
> labeled, and is there a convention for which one would be the best to
> use?  I see the labpt slot, in my SpatialPolygonsDataFrame object, but I
> don't see a mostAppropriateLabpt or primaryLabpt or anything like that.
>
> In addition to this, I get no errors when I follow the examples at
> http://r-spatial.sourceforge.net/gallery/ , but I see no labels, either.
>
> This is what I'm doing.  Are the colors covering my labels?
>
>  spplot(rep.map,zcol="vote02",at=breaks,col.regions=rg,
>        layout=list(list("sp.text",getSpPPolygonsLabptSlots(rep.map)[25,],"HERE I AM")))
>

Thanks for the verbatim code. I think that you need to name the argument 
sp.layout= rather than layout=. Because of the ... argument list, layout= 
doesn't get rejected, but it doesn't get used either. The gallery could do 
with refreshing, more recently you could say:

list("sp.text", coordinates(rep.map), row.names(rep.map))

to put the FID value (feature ID) at the centroid of the largest member 
polygon (Polygon object) of the entity (Polygons object), for each entity 
of the data set.

Use the other arguments to text() as usual to change size, etc.

If overlapping is a problem, use pointLabel() in maptools to provide 
alternative placings for the same set of labels and cex= value (with 
thanks to Tom Short).

Hope this helps,

Roger

>
> Many thanks,
>
> -tom
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From zua3 at cornell.edu  Mon Nov 23 15:15:23 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Mon, 23 Nov 2009 09:15:23 -0500
Subject: [R-sig-Geo] Risks as hazardous (false positive) and safe (false
	negative)
In-Reply-To: <4B0A9785.6020604@cornell.edu>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>	<4B0A91EC.8030504@uni-muenster.de>
	<4B0A9785.6020604@cornell.edu>
Message-ID: <4B0A98FB.5060109@cornell.edu>


Hi all,

Is it possible in gstat to get misclassification  of risks as hazardous 
(false positive) and safe (false negative) as describe by
Goovaerts (1997)  from parametric or non-parametric probability 
mapping?.  help will appreciated.

Thanks

Zia


-------------- next part --------------
A non-text attachment was scrubbed...
Name: zua3.vcf
Type: text/x-vcard
Size: 281 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/1f3878c6/attachment.vcf>

From edzer.pebesma at uni-muenster.de  Mon Nov 23 15:18:27 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 23 Nov 2009 15:18:27 +0100
Subject: [R-sig-Geo] Risks as hazardous (false positive) and safe (false
	negative)
In-Reply-To: <4B0A98FB.5060109@cornell.edu>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>	<4B0A91EC.8030504@uni-muenster.de>
	<4B0A9785.6020604@cornell.edu> <4B0A98FB.5060109@cornell.edu>
Message-ID: <4B0A99B3.9050601@uni-muenster.de>

Dear Zia,

If you mean by Goovaerts (1997) his 483 page book "Geostatistics for
Natural Resource Evaluation", then please give us a bit more precise
detail on what you want (which page? which equation?)
--
Edzer

Zia Ahmed wrote:
>
> Hi all,
>
> Is it possible in gstat to get misclassification  of risks as
> hazardous (false positive) and safe (false negative) as describe by
> Goovaerts (1997)  from parametric or non-parametric probability
> mapping?.  help will appreciated.
>
> Thanks
>
> Zia
>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From tomfool at as220.org  Mon Nov 23 15:45:37 2009
From: tomfool at as220.org (tom sgouros)
Date: Mon, 23 Nov 2009 09:45:37 -0500
Subject: [R-sig-Geo] Map labels
In-Reply-To: <alpine.LRH.2.00.0911231503250.2730@reclus.nhh.no> 
References: <7780.1258983678@as220.org>
	<alpine.LRH.2.00.0911231503250.2730@reclus.nhh.no>
Message-ID: <11475.1258987537@as220.org>


Roger Bivand <Roger.Bivand at nhh.no> wrote:

> > Being near the water, there are lots of islands, so each town is
> > represented by a bunch of polygons.  How do I select only one to be
> > labeled, and is there a convention for which one would be the best to
> > use?  I see the labpt slot, in my SpatialPolygonsDataFrame object, but I
> > don't see a mostAppropriateLabpt or primaryLabpt or anything like that.
> >
> > In addition to this, I get no errors when I follow the examples at
> > http://r-spatial.sourceforge.net/gallery/ , but I see no labels, either.
> >
> > This is what I'm doing.  Are the colors covering my labels?
> >
> >  spplot(rep.map,zcol="vote02",at=breaks,col.regions=rg,
> >        layout=list(list("sp.text",getSpPPolygonsLabptSlots(rep.map)[25,],"HERE I AM")))
> >
> 
> Thanks for the verbatim code. I think that you need to name the
> argument sp.layout= rather than layout=. Because of the ... argument
> list, layout= doesn't get rejected, but it doesn't get used

Thank you, that works perfectly.

> list("sp.text", coordinates(rep.map), row.names(rep.map))
> 
> to put the FID value (feature ID) at the centroid of the largest
> member polygon (Polygon object) of the entity (Polygons object), for
> each entity of the data set.

This doesn't, though.  When I read in my data, the IDvar is supposed to
be the column that is unique for each record, correct?  But there are
several records (closed polygons) for each town.  These are linked by
another variable.  The coordinates(rep.map) gives me a list of 419
coordinates for all the closed shapes, not 75 coordinates for all the
towns.  How do I get the biggest polygons for each town?  I have an Area
attribute, so I guess I can just calculate it.  Is that the right way to
go, or is there some method already existing for this?

I thought maybe my readSpatial... was done wrong, so I changed the IDvar
to point to the iD for each town, but that gives me an error saying that
duplicate row names are not allowed.  Is there a step I needed to take
to link the polygons?

Thank you,

 -tom

-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From torleif.lunde at cih.uib.no  Mon Nov 23 15:57:32 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Mon, 23 Nov 2009 15:57:32 +0100
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <4B0A91EC.8030504@uni-muenster.de>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<200911231421.14216.torleif.lunde@cih.uib.no>
	<4B0A91EC.8030504@uni-muenster.de>
Message-ID: <200911231557.33038.torleif.lunde@cih.uib.no>

Hi Edzer

Thanks for a good answer. I did read the asdar-book, and especially the 
section on time grids. I guess the book (together with the sp source) is a 
must when dealing with the sp-classes.

As far as I understand this means that in SpatialTimeGridDataFrame coordinates 
and time has to be stored several times. That is my main motivation to define a 
new class. Let's take one example where one has a structure similar to 
SpatialPointsDataFrame, while the other has a structure of Spatial3dArray. 

## SpatialPointsDataFrame ##
# (since it takes a long time to convert it to a sppdf, this is omitted)

# Create coordinates
long2 <- seq(35, 48, length.out = 146)
lat2 <- seq(2, 15, length.out = 188)
long <- matrix(long2, length(long2), length(lat2), byrow = FALSE)
lat <- matrix(lat2, length(long2), length(lat2), byrow = TRUE)
long3 <- rep(c(long), 504)
lat3 <- rep(c(lat), 504)
ptc.coord <- cbind(x = long3, y=lat3)

# Create data variable
z <- seq(1, 10000, length.out = dim(ptc.coord)[1])

# Create time
tm <- rep(seq(as.POSIXct("2002-01-01 06:00:00"), 
	  as.POSIXct("2002-01-22 06:00:00"), 
	  length.out = 504), each = dim(long)[1]*dim(long)[2])

# make data.frame
dummy <- as.data.frame(cbind(ptc.coord, z, tm))
# do not run: 
# system.time(coordinates(dummy)=~x+y+tm)

# What is the object size?
objs <- object.size(dummy)
print(objs, quote = FALSE, units = "Mb")
## end spatial points ##

## Spatial3dArray ##

# arrange z as an array
array.data <- array(z, c(length(long2), length(lat2), 504))
# create a time vector
tm2 <- seq(as.POSIXct("2002-01-01 06:00:00"), 
	  as.POSIXct("2002-01-22 06:00:00"), 
	  length.out = 504)

x <- new("Spatial3dArray", 
	  data = array.data, 
	  coords = list(long=long, lat=lat),
	  bbox = matrix(c(min(long),
			  min(lat),
			  max(long),
			  max(lat)), 2, 2, 
	  dimnames = list(c("long", "lat"), c("min","max"))), 
	  time = as.character(tm2),
	  btime = c("2002-01-01 06:00:00", 
			   "2002-01-22 06:00:00"))

dimnames(slot(x, "data"))=list(NULL, 
				NULL, 
				slot(x, "time"))


objs2 <- object.size(x)
print(objs2, quote = FALSE, units = "Mb")

## end Spatial3dArray ##

So, I think it makes sense to have other classes when dealing with time data 
with a certain dimension. Agree?

I have already rewritten overlay, summary, and added spmean, spmax, and spmin 
(with options on which dimensions the method should be applied over). In 
addition binding methods (sp3dAbind equal to cbind for data.frames. Will also 
introduce timeBind, or similar) has been introduced. 

Best wishes
Torleif





On Monday 23 November 2009 14:45:16 Edzer Pebesma wrote:
> Torleif,
> 
> sp classes SpatialPoints* SpatialPixels* and SpatialGrid* already allow
> 
> 3- and higher dimensional data; providing an example with nonsense data:
> > library(sp)
> > data(meuse)
> > meuse$z = rnorm(155)
> > coordinates(meuse)=~x+y+z
> > summary(as(meuse, "SpatialPoints"))
> 
> Object of class SpatialPoints
> Coordinates:
>             min          max
> x 178605.000000 1.813900e+05
> y 329714.000000 3.336110e+05
> z     -2.168683 3.006463e+00
> Is projected: NA
> proj4string : [NA]
> Number of points: 155
> 
> It can be used this way to do 3D interpolation (package gstat), and
> several of the sp methods work; obviously, several do ignore everything
> beyond x and y.
> 
> If you store your time as double, you can even think about adding that
> as one of the coordinates.
> 
> Chapter 6 of http://www.asdar-book.org/ gives code examples of this
> approach, where a third dimension represents (posix) time, and methods
> are given to select a certain spatial grid from a
> SpatialTimeGridDataFrame based on its posix time (range).
> 
> The motivation for your approach becomes stronger when time cannot be
> stored as double (numeric); I find it harder to see the motivation to
> store z differently from the x and y coordinates, create a separate
> bounding box for it and rewrite all methods.
> --
> Edzer
> 
> Torleif Markussen Lunde wrote:
> > Hi
> >
> > As previously mentioned I am working on 3D and 4D spatial classes. To get
> > things compatible with the other sp-classes I would like to ask for your
> > opinion what would be the most suitable bbox methods for Spatial3dArrays
> > and Spatial4dArrays.
> >
> > My first thought was that bbox should return the 2D geographical extent
> > of the object. This to comply with other spatial methods. For the 3D case
> > an additional slot, btime is added to show the temporal extent of the
> > object. As writing the 4D case, I started wondering whether it would be
> > wise to stick to this (my conclusion at the moment is yes). In that case
> > a new slot called zextent could be added.
> >
> > To retrieve the extent of the different dimensions one would have three
> > functions; bbox(), btime(), and zextent()
> >
> > The other option is to make a bbox slot as a list. bbox() would still
> > return x-y extent, while bbox.full() could return a list of the full
> > extent:
> >
> > list(bbox = matrix(c(1,1,4,4), 2,2,
> >      			dimnames = list(c("long", "lat"),
> > 		     	c("min", "max"))),
> >     btime = matrix(c("2002-01-01 06:00:00", "2002-01-01 06:00:00"), 1, 2,
> >      			dimnames = list(c("time"),
> > 		     	c("min", "max"))),
> >     zextent = matrix(c(512, 1024), 1,2,
> >      			dimnames = list(c("masl"),
> > 		     	c("min", "max"))))
> >
> > Since bbox is defined as a matrix in Spatial, this would be a bad idea.
> > So, at best bbox could be a matrix of min/max of x, y, and z (since they
> > all are numeric). bbox() would then return a x, y subset of bbox(), while
> > bbox.full() could return a list(xyz, time).
> >
> > Any comments on what would be best suitable to be compatible with the
> > other Spatial classes?
> >
> > Best wishes
> > Torleif
> > PhD candidate
> > Centre for International Health
> > Bjerknes Centre for Climate Research
> > University of Bergen
> > Norway
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From torleif.lunde at cih.uib.no  Mon Nov 23 16:03:32 2009
From: torleif.lunde at cih.uib.no (Torleif Markussen Lunde)
Date: Mon, 23 Nov 2009 16:03:32 +0100
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <200911231557.33038.torleif.lunde@cih.uib.no>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<4B0A91EC.8030504@uni-muenster.de>
	<200911231557.33038.torleif.lunde@cih.uib.no>
Message-ID: <200911231603.32853.torleif.lunde@cih.uib.no>

Of course, if you decide to use the columns as time, you reduce the space, but 
than, with more than one variable, the structure would be "messy".

Best wishes
Torleif

On Monday 23 November 2009 15:57:32 Torleif Markussen Lunde wrote:
> Hi Edzer
> 
> Thanks for a good answer. I did read the asdar-book, and especially the
> section on time grids. I guess the book (together with the sp source) is a
> must when dealing with the sp-classes.
> 
> As far as I understand this means that in SpatialTimeGridDataFrame
>  coordinates and time has to be stored several times. That is my main
>  motivation to define a new class. Let's take one example where one has a
>  structure similar to SpatialPointsDataFrame, while the other has a
>  structure of Spatial3dArray.
> 
> ## SpatialPointsDataFrame ##
> # (since it takes a long time to convert it to a sppdf, this is omitted)
> 
> # Create coordinates
> long2 <- seq(35, 48, length.out = 146)
> lat2 <- seq(2, 15, length.out = 188)
> long <- matrix(long2, length(long2), length(lat2), byrow = FALSE)
> lat <- matrix(lat2, length(long2), length(lat2), byrow = TRUE)
> long3 <- rep(c(long), 504)
> lat3 <- rep(c(lat), 504)
> ptc.coord <- cbind(x = long3, y=lat3)
> 
> # Create data variable
> z <- seq(1, 10000, length.out = dim(ptc.coord)[1])
> 
> # Create time
> tm <- rep(seq(as.POSIXct("2002-01-01 06:00:00"),
> 	  as.POSIXct("2002-01-22 06:00:00"),
> 	  length.out = 504), each = dim(long)[1]*dim(long)[2])
> 
> # make data.frame
> dummy <- as.data.frame(cbind(ptc.coord, z, tm))
> # do not run:
> # system.time(coordinates(dummy)=~x+y+tm)
> 
> # What is the object size?
> objs <- object.size(dummy)
> print(objs, quote = FALSE, units = "Mb")
> ## end spatial points ##
> 
> ## Spatial3dArray ##
> 
> # arrange z as an array
> array.data <- array(z, c(length(long2), length(lat2), 504))
> # create a time vector
> tm2 <- seq(as.POSIXct("2002-01-01 06:00:00"),
> 	  as.POSIXct("2002-01-22 06:00:00"),
> 	  length.out = 504)
> 
> x <- new("Spatial3dArray",
> 	  data = array.data,
> 	  coords = list(long=long, lat=lat),
> 	  bbox = matrix(c(min(long),
> 			  min(lat),
> 			  max(long),
> 			  max(lat)), 2, 2,
> 	  dimnames = list(c("long", "lat"), c("min","max"))),
> 	  time = as.character(tm2),
> 	  btime = c("2002-01-01 06:00:00",
> 			   "2002-01-22 06:00:00"))
> 
> dimnames(slot(x, "data"))=list(NULL,
> 				NULL,
> 				slot(x, "time"))
> 
> 
> objs2 <- object.size(x)
> print(objs2, quote = FALSE, units = "Mb")
> 
> ## end Spatial3dArray ##
> 
> So, I think it makes sense to have other classes when dealing with time
>  data with a certain dimension. Agree?
> 
> I have already rewritten overlay, summary, and added spmean, spmax, and
>  spmin (with options on which dimensions the method should be applied
>  over). In addition binding methods (sp3dAbind equal to cbind for
>  data.frames. Will also introduce timeBind, or similar) has been
>  introduced.
> 
> Best wishes
> Torleif
> 
> On Monday 23 November 2009 14:45:16 Edzer Pebesma wrote:
> > Torleif,
> >
> > sp classes SpatialPoints* SpatialPixels* and SpatialGrid* already allow
> >
> > 3- and higher dimensional data; providing an example with nonsense data:
> > > library(sp)
> > > data(meuse)
> > > meuse$z = rnorm(155)
> > > coordinates(meuse)=~x+y+z
> > > summary(as(meuse, "SpatialPoints"))
> >
> > Object of class SpatialPoints
> > Coordinates:
> >             min          max
> > x 178605.000000 1.813900e+05
> > y 329714.000000 3.336110e+05
> > z     -2.168683 3.006463e+00
> > Is projected: NA
> > proj4string : [NA]
> > Number of points: 155
> >
> > It can be used this way to do 3D interpolation (package gstat), and
> > several of the sp methods work; obviously, several do ignore everything
> > beyond x and y.
> >
> > If you store your time as double, you can even think about adding that
> > as one of the coordinates.
> >
> > Chapter 6 of http://www.asdar-book.org/ gives code examples of this
> > approach, where a third dimension represents (posix) time, and methods
> > are given to select a certain spatial grid from a
> > SpatialTimeGridDataFrame based on its posix time (range).
> >
> > The motivation for your approach becomes stronger when time cannot be
> > stored as double (numeric); I find it harder to see the motivation to
> > store z differently from the x and y coordinates, create a separate
> > bounding box for it and rewrite all methods.
> > --
> > Edzer
> >
> > Torleif Markussen Lunde wrote:
> > > Hi
> > >
> > > As previously mentioned I am working on 3D and 4D spatial classes. To
> > > get things compatible with the other sp-classes I would like to ask for
> > > your opinion what would be the most suitable bbox methods for
> > > Spatial3dArrays and Spatial4dArrays.
> > >
> > > My first thought was that bbox should return the 2D geographical extent
> > > of the object. This to comply with other spatial methods. For the 3D
> > > case an additional slot, btime is added to show the temporal extent of
> > > the object. As writing the 4D case, I started wondering whether it
> > > would be wise to stick to this (my conclusion at the moment is yes). In
> > > that case a new slot called zextent could be added.
> > >
> > > To retrieve the extent of the different dimensions one would have three
> > > functions; bbox(), btime(), and zextent()
> > >
> > > The other option is to make a bbox slot as a list. bbox() would still
> > > return x-y extent, while bbox.full() could return a list of the full
> > > extent:
> > >
> > > list(bbox = matrix(c(1,1,4,4), 2,2,
> > >      			dimnames = list(c("long", "lat"),
> > > 		     	c("min", "max"))),
> > >     btime = matrix(c("2002-01-01 06:00:00", "2002-01-01 06:00:00"), 1,
> > > 2, dimnames = list(c("time"),
> > > 		     	c("min", "max"))),
> > >     zextent = matrix(c(512, 1024), 1,2,
> > >      			dimnames = list(c("masl"),
> > > 		     	c("min", "max"))))
> > >
> > > Since bbox is defined as a matrix in Spatial, this would be a bad idea.
> > > So, at best bbox could be a matrix of min/max of x, y, and z (since
> > > they all are numeric). bbox() would then return a x, y subset of
> > > bbox(), while bbox.full() could return a list(xyz, time).
> > >
> > > Any comments on what would be best suitable to be compatible with the
> > > other Spatial classes?
> > >
> > > Best wishes
> > > Torleif
> > > PhD candidate
> > > Centre for International Health
> > > Bjerknes Centre for Climate Research
> > > University of Bergen
> > > Norway
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at stat.math.ethz.ch
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Mon Nov 23 16:47:36 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 23 Nov 2009 16:47:36 +0100
Subject: [R-sig-Geo] Risks as hazardous (false positive) and safe (false
	negative)
In-Reply-To: <4B0AA228.4030102@cornell.edu>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>	<4B0A91EC.8030504@uni-muenster.de>
	<4B0A9785.6020604@cornell.edu> <4B0A98FB.5060109@cornell.edu>
	<4B0A99B3.9050601@uni-muenster.de> <4B0AA228.4030102@cornell.edu>
Message-ID: <4B0AAE98.3090506@uni-muenster.de>

(replying to the list)

Well, if you're willing to accept the indicator kriging values as
estimates of these probabilities, you're essentially done. Of course,
the kriged values can be outside [0, 1], so you need to deal with that.

Best regards,
--
Edzer

Zia Ahmed wrote:
> Dear Edzer,
>
> Thanks for your replay. I have done IK of water arsenic using
> quantiles of the data. I want to do   miss classification  of my risk
> that  proposed  by  Goovaerts.
> Two misclassification  of risks are proposed by Goovaerts (1997) based
> on ccdf model F(*u*;z_k |(n)) of Z(*u*)?Z_k .
>
>
> 1.       The risk ?(*u*) of incorrectly classified a location u as
> hazardous (false positive):
>
> ?(*u*) = Prob{Z(*u*) ?z_c |z*_L (u) > Z_c , (n)}
>
>        = F(*u*;z_c |(n))
>
> Where z*_L (u) is the estimator.
>
> 2.       The risk ?(u)  wrongly classified a location u as safe (false
> negative)
>
> ?(*u*) = Prob{Z(*u*) > z_c |z*_L (u) ? Z_c , (n)}
>
>       = 1- F(*u*;z_c |(n))
>
>
>
>
>
> Ref: Goovaerts, P (1997). Geostatistics for Natural Resource
> Evaluation, pp: 259-368
>
>
>
> Zia
>
> Edzer Pebesma wrote:
>> Dear Zia,
>>
>> If you mean by Goovaerts (1997) his 483 page book "Geostatistics for
>> Natural Resource Evaluation", then please give us a bit more precise
>> detail on what you want (which page? which equation?)
>> -- 
>> Edzer
>>
>> Zia Ahmed wrote:
>>  
>>> Hi all,
>>>
>>> Is it possible in gstat to get misclassification  of risks as
>>> hazardous (false positive) and safe (false negative) as describe by
>>> Goovaerts (1997)  from parametric or non-parametric probability
>>> mapping?.  help will appreciated.
>>>
>>> Thanks
>>>
>>> Zia
>>>
>>>
>>>     
>>
>>   
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From karl at huftis.org  Mon Nov 23 17:02:46 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Mon, 23 Nov 2009 17:02:46 +0100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
	<200911200914.35528.ashton@msu.edu>
	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193>
	<MPG.2570e861cf3e07479896ad@news.gmane.org>
	<4B0A8B33.9010304@geo.uu.nl>
Message-ID: <MPG.2574d093e601f9079896ae@news.gmane.org>

On Mon, 23 Nov 2009 14:16:35 +0100 Paul Hiemstra <p.hiemstra at geo.uu.nl> 
wrote:
> > The maps with shading look quite nice. Is there an R package/function
> > which can create similar images?
> >   
> A good place to look for these kinds of graphs and how to make them is 
> the R graph gallery [1]. Check out this one for example [2].

Excellent idea. I have of course used 'persp' many times, but had 
forgotten about its 'shade' option. With it, I can create very good-
looking (and useful!) 3D maps. I use it on a bathymetry (ocean depths)
dataset, and using this shading and 3D visualisation gives a whole new 
perspective (sorry). 

One alternative that I discovered is the hillshading feature of the free 
GIS software SAGA. It's even available in R using the 'RSAGA' package. 
See "http://sourceforge.net/apps/trac/saga-gis/wiki/Climbing%20Mount%
20St.%20Helens" for a nice example of its output. (I didn't manage to 
get it to automatically use 'natural' colours for ocean and 
land/terrain, though.)

-- 
Karl Ove Hufthammer


From zua3 at cornell.edu  Mon Nov 23 17:22:27 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Mon, 23 Nov 2009 11:22:27 -0500
Subject: [R-sig-Geo] Risks as hazardous (false positive) and safe (false
	negative)
In-Reply-To: <4B0AAE98.3090506@uni-muenster.de>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>	<4B0A91EC.8030504@uni-muenster.de>
	<4B0A9785.6020604@cornell.edu> <4B0A98FB.5060109@cornell.edu>
	<4B0A99B3.9050601@uni-muenster.de> <4B0AA228.4030102@cornell.edu>
	<4B0AAE98.3090506@uni-muenster.de>
Message-ID: <4B0AB6C3.40602@cornell.edu>


Thanks!  I may correct the values those are out side [0,1] using pmin 
and pmax function (?).
But  I am sill not clear how I will do this.
 Thanks again

Zia


Edzer Pebesma wrote:
> (replying to the list)
>
> Well, if you're willing to accept the indicator kriging values as
> estimates of these probabilities, you're essentially done. Of course,
> the kriged values can be outside [0, 1], so you need to deal with that.
>
> Best regards,
> --
> Edzer
>
> Zia Ahmed wrote:
>   
>> Dear Edzer,
>>
>> Thanks for your replay. I have done IK of water arsenic using
>> quantiles of the data. I want to do   miss classification  of my risk
>> that  proposed  by  Goovaerts.
>> Two misclassification  of risks are proposed by Goovaerts (1997) based
>> on ccdf model F(*u*;z_k |(n)) of Z(*u*)?Z_k .
>>
>>
>> 1.       The risk ?(*u*) of incorrectly classified a location u as
>> hazardous (false positive):
>>
>> ?(*u*) = Prob{Z(*u*) ?z_c |z*_L (u) > Z_c , (n)}
>>
>>        = F(*u*;z_c |(n))
>>
>> Where z*_L (u) is the estimator.
>>
>> 2.       The risk ?(u)  wrongly classified a location u as safe (false
>> negative)
>>
>> ?(*u*) = Prob{Z(*u*) > z_c |z*_L (u) ? Z_c , (n)}
>>
>>       = 1- F(*u*;z_c |(n))
>>
>>
>>
>>
>>
>> Ref: Goovaerts, P (1997). Geostatistics for Natural Resource
>> Evaluation, pp: 259-368
>>
>>
>>
>> Zia
>>
>> Edzer Pebesma wrote:
>>     
>>> Dear Zia,
>>>
>>> If you mean by Goovaerts (1997) his 483 page book "Geostatistics for
>>> Natural Resource Evaluation", then please give us a bit more precise
>>> detail on what you want (which page? which equation?)
>>> -- 
>>> Edzer
>>>
>>> Zia Ahmed wrote:
>>>  
>>>       
>>>> Hi all,
>>>>
>>>> Is it possible in gstat to get misclassification  of risks as
>>>> hazardous (false positive) and safe (false negative) as describe by
>>>> Goovaerts (1997)  from parametric or non-parametric probability
>>>> mapping?.  help will appreciated.
>>>>
>>>> Thanks
>>>>
>>>> Zia
>>>>
>>>>
>>>>     
>>>>         
>>>   
>>>       
>
>   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/083e46fc/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: zua3.vcf
Type: text/x-vcard
Size: 281 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/083e46fc/attachment.vcf>

From edzer.pebesma at uni-muenster.de  Mon Nov 23 17:33:41 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 23 Nov 2009 17:33:41 +0100
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <200911231603.32853.torleif.lunde@cih.uib.no>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<4B0A91EC.8030504@uni-muenster.de>
	<200911231557.33038.torleif.lunde@cih.uib.no>
	<200911231603.32853.torleif.lunde@cih.uib.no>
Message-ID: <4B0AB965.4070503@uni-muenster.de>

Torleif,

after creating the SpatialPointsDataFrame (90 seconds) with your
commands I get indeed a new object dummy, which is 400+ Mb of size, the
same as the data.frame had. Then, converting it in a grid with

gridded(dummy) = TRUE
fullgrid(dummy) = TRUE

takes again very long, but gives you the object of 100 Mb, of size very
similar to your Spatial3dArray.

The fast way of creating such objects, for which you know the dimensions
ahead of time, with sp classes, is:

library(sp)
# I ignored your offset and cell sizes here:
grd = GridTopology(rep(0,3), rep(1,3), c(146,188,504))
object.size(SpatialGridDataFrame(grd,data.frame(z=rep(0,prod(grd at cells.dim)))))

which produces a similar object in the same amount of time. So far, when
each dimension is regularly discretized, I see little advantage in your
approach, except that it gives meaning (in terms of a reference system)
to the third dimension, being time -- my SpatialTimeGridDataFrame did a
similar thing, although less explicitly.

Your implementation is more general in the sense that it can deal with
regular (and even irregular) time series for irregularly spaced points,
as you store all spatial locations of measurements (once) and assume the
same time discretization (regular or irregular -- you store the times)
holds for each spatial points. That is of course a much more flexible
data structure, useful for many space-time data.

You might also want to read into the arguments that seq and rep have in
addition to those you use. Confusing at first sight, but powerful -- no
need for matrices.
--
Edzer

Torleif Markussen Lunde wrote:
> Of course, if you decide to use the columns as time, you reduce the space, but 
> than, with more than one variable, the structure would be "messy".
>
> Best wishes
> Torleif
>
> On Monday 23 November 2009 15:57:32 Torleif Markussen Lunde wrote:
>   
>> Hi Edzer
>>
>> Thanks for a good answer. I did read the asdar-book, and especially the
>> section on time grids. I guess the book (together with the sp source) is a
>> must when dealing with the sp-classes.
>>
>> As far as I understand this means that in SpatialTimeGridDataFrame
>>  coordinates and time has to be stored several times. That is my main
>>  motivation to define a new class. Let's take one example where one has a
>>  structure similar to SpatialPointsDataFrame, while the other has a
>>  structure of Spatial3dArray.
>>
>> ## SpatialPointsDataFrame ##
>> # (since it takes a long time to convert it to a sppdf, this is omitted)
>>
>> # Create coordinates
>> long2 <- seq(35, 48, length.out = 146)
>> lat2 <- seq(2, 15, length.out = 188)
>> long <- matrix(long2, length(long2), length(lat2), byrow = FALSE)
>> lat <- matrix(lat2, length(long2), length(lat2), byrow = TRUE)
>> long3 <- rep(c(long), 504)
>> lat3 <- rep(c(lat), 504)
>> ptc.coord <- cbind(x = long3, y=lat3)
>>
>> # Create data variable
>> z <- seq(1, 10000, length.out = dim(ptc.coord)[1])
>>
>> # Create time
>> tm <- rep(seq(as.POSIXct("2002-01-01 06:00:00"),
>> 	  as.POSIXct("2002-01-22 06:00:00"),
>> 	  length.out = 504), each = dim(long)[1]*dim(long)[2])
>>
>> # make data.frame
>> dummy <- as.data.frame(cbind(ptc.coord, z, tm))
>> # do not run:
>> # system.time(coordinates(dummy)=~x+y+tm)
>>
>> # What is the object size?
>> objs <- object.size(dummy)
>> print(objs, quote = FALSE, units = "Mb")
>> ## end spatial points ##
>>
>> ## Spatial3dArray ##
>>
>> # arrange z as an array
>> array.data <- array(z, c(length(long2), length(lat2), 504))
>> # create a time vector
>> tm2 <- seq(as.POSIXct("2002-01-01 06:00:00"),
>> 	  as.POSIXct("2002-01-22 06:00:00"),
>> 	  length.out = 504)
>>
>> x <- new("Spatial3dArray",
>> 	  data = array.data,
>> 	  coords = list(long=long, lat=lat),
>> 	  bbox = matrix(c(min(long),
>> 			  min(lat),
>> 			  max(long),
>> 			  max(lat)), 2, 2,
>> 	  dimnames = list(c("long", "lat"), c("min","max"))),
>> 	  time = as.character(tm2),
>> 	  btime = c("2002-01-01 06:00:00",
>> 			   "2002-01-22 06:00:00"))
>>
>> dimnames(slot(x, "data"))=list(NULL,
>> 				NULL,
>> 				slot(x, "time"))
>>
>>
>> objs2 <- object.size(x)
>> print(objs2, quote = FALSE, units = "Mb")
>>
>> ## end Spatial3dArray ##
>>
>> So, I think it makes sense to have other classes when dealing with time
>>  data with a certain dimension. Agree?
>>
>> I have already rewritten overlay, summary, and added spmean, spmax, and
>>  spmin (with options on which dimensions the method should be applied
>>  over). In addition binding methods (sp3dAbind equal to cbind for
>>  data.frames. Will also introduce timeBind, or similar) has been
>>  introduced.
>>
>> Best wishes
>> Torleif
>>
>> On Monday 23 November 2009 14:45:16 Edzer Pebesma wrote:
>>     
>>> Torleif,
>>>
>>> sp classes SpatialPoints* SpatialPixels* and SpatialGrid* already allow
>>>
>>> 3- and higher dimensional data; providing an example with nonsense data:
>>>       
>>>> library(sp)
>>>> data(meuse)
>>>> meuse$z = rnorm(155)
>>>> coordinates(meuse)=~x+y+z
>>>> summary(as(meuse, "SpatialPoints"))
>>>>         
>>> Object of class SpatialPoints
>>> Coordinates:
>>>             min          max
>>> x 178605.000000 1.813900e+05
>>> y 329714.000000 3.336110e+05
>>> z     -2.168683 3.006463e+00
>>> Is projected: NA
>>> proj4string : [NA]
>>> Number of points: 155
>>>
>>> It can be used this way to do 3D interpolation (package gstat), and
>>> several of the sp methods work; obviously, several do ignore everything
>>> beyond x and y.
>>>
>>> If you store your time as double, you can even think about adding that
>>> as one of the coordinates.
>>>
>>> Chapter 6 of http://www.asdar-book.org/ gives code examples of this
>>> approach, where a third dimension represents (posix) time, and methods
>>> are given to select a certain spatial grid from a
>>> SpatialTimeGridDataFrame based on its posix time (range).
>>>
>>> The motivation for your approach becomes stronger when time cannot be
>>> stored as double (numeric); I find it harder to see the motivation to
>>> store z differently from the x and y coordinates, create a separate
>>> bounding box for it and rewrite all methods.
>>> --
>>> Edzer
>>>
>>> Torleif Markussen Lunde wrote:
>>>       
>>>> Hi
>>>>
>>>> As previously mentioned I am working on 3D and 4D spatial classes. To
>>>> get things compatible with the other sp-classes I would like to ask for
>>>> your opinion what would be the most suitable bbox methods for
>>>> Spatial3dArrays and Spatial4dArrays.
>>>>
>>>> My first thought was that bbox should return the 2D geographical extent
>>>> of the object. This to comply with other spatial methods. For the 3D
>>>> case an additional slot, btime is added to show the temporal extent of
>>>> the object. As writing the 4D case, I started wondering whether it
>>>> would be wise to stick to this (my conclusion at the moment is yes). In
>>>> that case a new slot called zextent could be added.
>>>>
>>>> To retrieve the extent of the different dimensions one would have three
>>>> functions; bbox(), btime(), and zextent()
>>>>
>>>> The other option is to make a bbox slot as a list. bbox() would still
>>>> return x-y extent, while bbox.full() could return a list of the full
>>>> extent:
>>>>
>>>> list(bbox = matrix(c(1,1,4,4), 2,2,
>>>>      			dimnames = list(c("long", "lat"),
>>>> 		     	c("min", "max"))),
>>>>     btime = matrix(c("2002-01-01 06:00:00", "2002-01-01 06:00:00"), 1,
>>>> 2, dimnames = list(c("time"),
>>>> 		     	c("min", "max"))),
>>>>     zextent = matrix(c(512, 1024), 1,2,
>>>>      			dimnames = list(c("masl"),
>>>> 		     	c("min", "max"))))
>>>>
>>>> Since bbox is defined as a matrix in Spatial, this would be a bad idea.
>>>> So, at best bbox could be a matrix of min/max of x, y, and z (since
>>>> they all are numeric). bbox() would then return a x, y subset of
>>>> bbox(), while bbox.full() could return a list(xyz, time).
>>>>
>>>> Any comments on what would be best suitable to be compatible with the
>>>> other Spatial classes?
>>>>
>>>> Best wishes
>>>> Torleif
>>>> PhD candidate
>>>> Centre for International Health
>>>> Bjerknes Centre for Climate Research
>>>> University of Bergen
>>>> Norway
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>         
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From cc157 at duke.edu  Mon Nov 23 18:19:25 2009
From: cc157 at duke.edu (Corrie Curtice)
Date: Mon, 23 Nov 2009 12:19:25 -0500
Subject: [R-sig-Geo] Exporting kernel UD homerange to an ESRI shapefile
Message-ID: <33debc420911230919y49304196wec3ab410109ba60b@mail.gmail.com>

Hello,

Sorry, I must be missing something obvious. I have location data for
several turtles in three different areas. I'm interested in the home
range of the population at each area, so I've broken the data out
already by beach name (not by turtle). I'm using the adehabitat
package and running:

xy<-bajaTurtles[,c("x","y")]
id<-bajaTurtles$Beach
bajahr<-kernelUD(xy,id)

I get a nice picture of the home range with contours. I've done this
for each beach  I want to create my maps in ArcMap (I'm not that good
with maps in R yet), so I'd like to export each homerange as an ESRI
shapefile, keeping the contour information so I can color ramp it
appropriately and do some analysis in ArcMap.   This is what I think
I'm supposed to do, from reading
https://wiki.faunalia.it/dokuwiki/doku.php?id=public:animove_howto:

kverBaja<-getverticeshr(bajahr)
spolBaja <- kver2spol(kverBaja)

The above object has 2 slots with coordinates, but only one slot has
an "ID" field, which is the name of the beach. Clearly at this point
I'm missing information, since I would expect each contour to be a
polygon. It doesn't look like getverticieshr takes a list of levels,
just one. Do I need to repeat this and glue them together for all the
levels? Is there a different function to use?  Also, somewhat
unrelated but curious: I don't quite understand why both slots do not
have ID fields?

So now just to see what I have I exported it like this:

# I made up the first field, not sure what else I might want to put in
this dataframe
dfBaja <- data.frame(Beach="Baja",row.names=("Agua Blanca, Baja
California Sur"))
spdfBaja <- SpatialPolygonsDataFrame(spolBaja, dfBaja, match.ID = TRUE)
writeOGR(spdfBaja,paste(td,"R-Output/Shapefiles",sep=""),"bajaUD",
"ESRI Shapefile")

But once I get that into ArcMap it's just a single polygon.

So I have 2 questions:

1. How do I get all the levels for the home range into a shapefile?
2. I'd like to get my projection information into the SpatialPolygon
object, but it's created in the kver2spol function... is there a way
to set the CRS still?

Thanks for any help or pointers.

Corrie

---
Corrie Curtice
Research Associate
Marine Geospatial Ecology Lab
Nicholas School of the Environment, Duke University
http://mgel.env.duke.edu
em: corrie.curtice at duke.edu
ph: 252-504-7538
cell: 978-857-8266


From Roger.Bivand at nhh.no  Mon Nov 23 20:23:01 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Nov 2009 20:23:01 +0100 (CET)
Subject: [R-sig-Geo] Map labels
In-Reply-To: <11475.1258987537@as220.org>
References: <7780.1258983678@as220.org>
	<alpine.LRH.2.00.0911231503250.2730@reclus.nhh.no>
	<11475.1258987537@as220.org>
Message-ID: <alpine.LRH.2.00.0911232012070.3310@reclus.nhh.no>

On Mon, 23 Nov 2009, tom sgouros wrote:

>
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>>> Being near the water, there are lots of islands, so each town is
>>> represented by a bunch of polygons.  How do I select only one to be
>>> labeled, and is there a convention for which one would be the best to
>>> use?  I see the labpt slot, in my SpatialPolygonsDataFrame object, but I
>>> don't see a mostAppropriateLabpt or primaryLabpt or anything like that.
>>>
>>> In addition to this, I get no errors when I follow the examples at
>>> http://r-spatial.sourceforge.net/gallery/ , but I see no labels, either.
>>>
>>> This is what I'm doing.  Are the colors covering my labels?
>>>
>>>  spplot(rep.map,zcol="vote02",at=breaks,col.regions=rg,
>>>        layout=list(list("sp.text",getSpPPolygonsLabptSlots(rep.map)[25,],"HERE I AM")))
>>>
>>
>> Thanks for the verbatim code. I think that you need to name the
>> argument sp.layout= rather than layout=. Because of the ... argument
>> list, layout= doesn't get rejected, but it doesn't get used
>
> Thank you, that works perfectly.
>
>> list("sp.text", coordinates(rep.map), row.names(rep.map))
>>
>> to put the FID value (feature ID) at the centroid of the largest
>> member polygon (Polygon object) of the entity (Polygons object), for
>> each entity of the data set.
>
> This doesn't, though.  When I read in my data, the IDvar is supposed to
> be the column that is unique for each record, correct?  But there are
> several records (closed polygons) for each town.  These are linked by
> another variable.  The coordinates(rep.map) gives me a list of 419
> coordinates for all the closed shapes, not 75 coordinates for all the
> towns.  How do I get the biggest polygons for each town?  I have an Area
> attribute, so I guess I can just calculate it.  Is that the right way to
> go, or is there some method already existing for this?
>
> I thought maybe my readSpatial... was done wrong, so I changed the IDvar
> to point to the iD for each town, but that gives me an error saying that
> duplicate row names are not allowed.  Is there a step I needed to take
> to link the polygons?

Yes, see the unionSpatialPolygons() function in maptools. It uses 
functions in gpclib to dissolve boundaries between member entities if they 
touch, so makes a Polygons object with possibly multiple member Polygon 
objects from multiple Polygons objects with the same ID values (towns for 
you). You then need to drop rows from the data.frame (as(rep.map, 
"data.frame")), and re-assemble using SpatialPolygonsDataFrame() with the 
row.names of the data.frame set to the town IDs used in 
unionSpatialPolygons().

The mess is caused by the underlying data being kept in OGC SFS (simple 
features) form, which does not store well in shapefiles (a similar remark 
could be made about SpatialPolygons objects, which are more like 
shapefiles than like SFS).

The gpclib package should not be used if its license conditions are
inappropriate. A free software alternative is being prepared.

Roger

>
> Thank you,
>
> -tom
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From horning at amnh.org  Mon Nov 23 21:16:25 2009
From: horning at amnh.org (Ned Horning)
Date: Mon, 23 Nov 2009 15:16:25 -0500
Subject: [R-sig-Geo] Overlay of SpatialGrid/Raster and polygons
Message-ID: <4B0AED99.4070302@amnh.org>

Greetings,

I am looking for a way to use R to extract pixel values (currently in a 
large RasterStack object) that fall under polygons (currently a 
SpatialPolygonsDataFrame object). I seem to recall a discussion about 
using overlay to do this but I can't find a method that would work.

Any insight would be appreciated.

Ned


From mdsumner at gmail.com  Mon Nov 23 21:20:34 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 24 Nov 2009 07:20:34 +1100
Subject: [R-sig-Geo] bbox 4-dimensional objects - suitable method?
In-Reply-To: <4B0AB965.4070503@uni-muenster.de>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<4B0A91EC.8030504@uni-muenster.de>
	<200911231557.33038.torleif.lunde@cih.uib.no>
	<200911231603.32853.torleif.lunde@cih.uib.no>
	<4B0AB965.4070503@uni-muenster.de>
Message-ID: <522664f80911231220i26de631q504b3ab908d2849@mail.gmail.com>

I would encourage the idea that higher dimensions (or even the first
two)  are not treated as representing any particular real world
dimensions. There's no reason any axis should be aligned to a
particular type or name (such as or POSIXct, or "X"). This would mean
that bbox() simply returns a 2 row matrix with more columns - as it
does now for the coordinates slot. You can always add further
functions that specially extract the range from the third or fourth
column of the bounding box, and higher level classes that treat time
or elevation as somehow special.

I aim to rewrite the trip classes in this way - trip should really
have time, and potentially Z, temperature, salinity, etc. on the
coordinates, and then treat aggregations of points/lines by ID with a
different mechanism. R doesn't have unit types as such, but it would
be good to aim for this support in the future by keeping unit, name,
and dimension separated and not aligned to particular geometric axes.

NetCDF has a complete separation of the definition of each dimension
(lon, temperature, time, lat, level etc.) that is available for a
particular variable for example, although I think the special X=1,
Y=2, Z=3, Time=4 ordering is encouraged, even if one of the dimensions
is singleton.

Regards, Mike.

On Tue, Nov 24, 2009 at 3:33 AM, Edzer Pebesma
<edzer.pebesma at uni-muenster.de> wrote:
> Torleif,
>
> after creating the SpatialPointsDataFrame (90 seconds) with your
> commands I get indeed a new object dummy, which is 400+ Mb of size, the
> same as the data.frame had. Then, converting it in a grid with
>
> gridded(dummy) = TRUE
> fullgrid(dummy) = TRUE
>
> takes again very long, but gives you the object of 100 Mb, of size very
> similar to your Spatial3dArray.
>
> The fast way of creating such objects, for which you know the dimensions
> ahead of time, with sp classes, is:
>
> library(sp)
> # I ignored your offset and cell sizes here:
> grd = GridTopology(rep(0,3), rep(1,3), c(146,188,504))
> object.size(SpatialGridDataFrame(grd,data.frame(z=rep(0,prod(grd at cells.dim)))))
>
> which produces a similar object in the same amount of time. So far, when
> each dimension is regularly discretized, I see little advantage in your
> approach, except that it gives meaning (in terms of a reference system)
> to the third dimension, being time -- my SpatialTimeGridDataFrame did a
> similar thing, although less explicitly.
>
> Your implementation is more general in the sense that it can deal with
> regular (and even irregular) time series for irregularly spaced points,
> as you store all spatial locations of measurements (once) and assume the
> same time discretization (regular or irregular -- you store the times)
> holds for each spatial points. That is of course a much more flexible
> data structure, useful for many space-time data.
>
> You might also want to read into the arguments that seq and rep have in
> addition to those you use. Confusing at first sight, but powerful -- no
> need for matrices.
> --
> Edzer
>
> Torleif Markussen Lunde wrote:
>> Of course, if you decide to use the columns as time, you reduce the space, but
>> than, with more than one variable, the structure would be "messy".
>>
>> Best wishes
>> Torleif
>>
>> On Monday 23 November 2009 15:57:32 Torleif Markussen Lunde wrote:
>>
>>> Hi Edzer
>>>
>>> Thanks for a good answer. I did read the asdar-book, and especially the
>>> section on time grids. I guess the book (together with the sp source) is a
>>> must when dealing with the sp-classes.
>>>
>>> As far as I understand this means that in SpatialTimeGridDataFrame
>>> ?coordinates and time has to be stored several times. That is my main
>>> ?motivation to define a new class. Let's take one example where one has a
>>> ?structure similar to SpatialPointsDataFrame, while the other has a
>>> ?structure of Spatial3dArray.
>>>
>>> ## SpatialPointsDataFrame ##
>>> # (since it takes a long time to convert it to a sppdf, this is omitted)
>>>
>>> # Create coordinates
>>> long2 <- seq(35, 48, length.out = 146)
>>> lat2 <- seq(2, 15, length.out = 188)
>>> long <- matrix(long2, length(long2), length(lat2), byrow = FALSE)
>>> lat <- matrix(lat2, length(long2), length(lat2), byrow = TRUE)
>>> long3 <- rep(c(long), 504)
>>> lat3 <- rep(c(lat), 504)
>>> ptc.coord <- cbind(x = long3, y=lat3)
>>>
>>> # Create data variable
>>> z <- seq(1, 10000, length.out = dim(ptc.coord)[1])
>>>
>>> # Create time
>>> tm <- rep(seq(as.POSIXct("2002-01-01 06:00:00"),
>>> ? ? ? ?as.POSIXct("2002-01-22 06:00:00"),
>>> ? ? ? ?length.out = 504), each = dim(long)[1]*dim(long)[2])
>>>
>>> # make data.frame
>>> dummy <- as.data.frame(cbind(ptc.coord, z, tm))
>>> # do not run:
>>> # system.time(coordinates(dummy)=~x+y+tm)
>>>
>>> # What is the object size?
>>> objs <- object.size(dummy)
>>> print(objs, quote = FALSE, units = "Mb")
>>> ## end spatial points ##
>>>
>>> ## Spatial3dArray ##
>>>
>>> # arrange z as an array
>>> array.data <- array(z, c(length(long2), length(lat2), 504))
>>> # create a time vector
>>> tm2 <- seq(as.POSIXct("2002-01-01 06:00:00"),
>>> ? ? ? ?as.POSIXct("2002-01-22 06:00:00"),
>>> ? ? ? ?length.out = 504)
>>>
>>> x <- new("Spatial3dArray",
>>> ? ? ? ?data = array.data,
>>> ? ? ? ?coords = list(long=long, lat=lat),
>>> ? ? ? ?bbox = matrix(c(min(long),
>>> ? ? ? ? ? ? ? ? ? ? ? ?min(lat),
>>> ? ? ? ? ? ? ? ? ? ? ? ?max(long),
>>> ? ? ? ? ? ? ? ? ? ? ? ?max(lat)), 2, 2,
>>> ? ? ? ?dimnames = list(c("long", "lat"), c("min","max"))),
>>> ? ? ? ?time = as.character(tm2),
>>> ? ? ? ?btime = c("2002-01-01 06:00:00",
>>> ? ? ? ? ? ? ? ? ? ? ? ? "2002-01-22 06:00:00"))
>>>
>>> dimnames(slot(x, "data"))=list(NULL,
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?NULL,
>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?slot(x, "time"))
>>>
>>>
>>> objs2 <- object.size(x)
>>> print(objs2, quote = FALSE, units = "Mb")
>>>
>>> ## end Spatial3dArray ##
>>>
>>> So, I think it makes sense to have other classes when dealing with time
>>> ?data with a certain dimension. Agree?
>>>
>>> I have already rewritten overlay, summary, and added spmean, spmax, and
>>> ?spmin (with options on which dimensions the method should be applied
>>> ?over). In addition binding methods (sp3dAbind equal to cbind for
>>> ?data.frames. Will also introduce timeBind, or similar) has been
>>> ?introduced.
>>>
>>> Best wishes
>>> Torleif
>>>
>>> On Monday 23 November 2009 14:45:16 Edzer Pebesma wrote:
>>>
>>>> Torleif,
>>>>
>>>> sp classes SpatialPoints* SpatialPixels* and SpatialGrid* already allow
>>>>
>>>> 3- and higher dimensional data; providing an example with nonsense data:
>>>>
>>>>> library(sp)
>>>>> data(meuse)
>>>>> meuse$z = rnorm(155)
>>>>> coordinates(meuse)=~x+y+z
>>>>> summary(as(meuse, "SpatialPoints"))
>>>>>
>>>> Object of class SpatialPoints
>>>> Coordinates:
>>>> ? ? ? ? ? ? min ? ? ? ? ?max
>>>> x 178605.000000 1.813900e+05
>>>> y 329714.000000 3.336110e+05
>>>> z ? ? -2.168683 3.006463e+00
>>>> Is projected: NA
>>>> proj4string : [NA]
>>>> Number of points: 155
>>>>
>>>> It can be used this way to do 3D interpolation (package gstat), and
>>>> several of the sp methods work; obviously, several do ignore everything
>>>> beyond x and y.
>>>>
>>>> If you store your time as double, you can even think about adding that
>>>> as one of the coordinates.
>>>>
>>>> Chapter 6 of http://www.asdar-book.org/ gives code examples of this
>>>> approach, where a third dimension represents (posix) time, and methods
>>>> are given to select a certain spatial grid from a
>>>> SpatialTimeGridDataFrame based on its posix time (range).
>>>>
>>>> The motivation for your approach becomes stronger when time cannot be
>>>> stored as double (numeric); I find it harder to see the motivation to
>>>> store z differently from the x and y coordinates, create a separate
>>>> bounding box for it and rewrite all methods.
>>>> --
>>>> Edzer
>>>>
>>>> Torleif Markussen Lunde wrote:
>>>>
>>>>> Hi
>>>>>
>>>>> As previously mentioned I am working on 3D and 4D spatial classes. To
>>>>> get things compatible with the other sp-classes I would like to ask for
>>>>> your opinion what would be the most suitable bbox methods for
>>>>> Spatial3dArrays and Spatial4dArrays.
>>>>>
>>>>> My first thought was that bbox should return the 2D geographical extent
>>>>> of the object. This to comply with other spatial methods. For the 3D
>>>>> case an additional slot, btime is added to show the temporal extent of
>>>>> the object. As writing the 4D case, I started wondering whether it
>>>>> would be wise to stick to this (my conclusion at the moment is yes). In
>>>>> that case a new slot called zextent could be added.
>>>>>
>>>>> To retrieve the extent of the different dimensions one would have three
>>>>> functions; bbox(), btime(), and zextent()
>>>>>
>>>>> The other option is to make a bbox slot as a list. bbox() would still
>>>>> return x-y extent, while bbox.full() could return a list of the full
>>>>> extent:
>>>>>
>>>>> list(bbox = matrix(c(1,1,4,4), 2,2,
>>>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ?dimnames = list(c("long", "lat"),
>>>>> ? ? ? ? ? ? ? ? ? ?c("min", "max"))),
>>>>> ? ? btime = matrix(c("2002-01-01 06:00:00", "2002-01-01 06:00:00"), 1,
>>>>> 2, dimnames = list(c("time"),
>>>>> ? ? ? ? ? ? ? ? ? ?c("min", "max"))),
>>>>> ? ? zextent = matrix(c(512, 1024), 1,2,
>>>>> ? ? ? ? ? ? ? ? ? ? ? ? ? ?dimnames = list(c("masl"),
>>>>> ? ? ? ? ? ? ? ? ? ?c("min", "max"))))
>>>>>
>>>>> Since bbox is defined as a matrix in Spatial, this would be a bad idea.
>>>>> So, at best bbox could be a matrix of min/max of x, y, and z (since
>>>>> they all are numeric). bbox() would then return a x, y subset of
>>>>> bbox(), while bbox.full() could return a list(xyz, time).
>>>>>
>>>>> Any comments on what would be best suitable to be compatible with the
>>>>> other Spatial classes?
>>>>>
>>>>> Best wishes
>>>>> Torleif
>>>>> PhD candidate
>>>>> Centre for International Health
>>>>> Bjerknes Centre for Climate Research
>>>>> University of Bergen
>>>>> Norway
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at stat.math.ethz.ch
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From tomfool at as220.org  Mon Nov 23 21:40:55 2009
From: tomfool at as220.org (tom sgouros)
Date: Mon, 23 Nov 2009 15:40:55 -0500
Subject: [R-sig-Geo] Map labels
In-Reply-To: <alpine.LRH.2.00.0911232012070.3310@reclus.nhh.no> 
References: <7780.1258983678@as220.org>
	<alpine.LRH.2.00.0911231503250.2730@reclus.nhh.no>
	<11475.1258987537@as220.org>
	<alpine.LRH.2.00.0911232012070.3310@reclus.nhh.no>
Message-ID: <4532.1259008855@as220.org>


Is this another way to say that I've stumbled onto one of the borders
between the set of tasks that R does well and the set of tasks I should
use a GIS for?  Or should I persevere with R on this?

Second question: if I want to just do this assembly myself, so to keep
some control over placement, is there an add-a-Polygon-to-my-Polygons
method, or do you have an example of something like that?

Thanks for the help,

 -tom


Roger Bivand <Roger.Bivand at nhh.no> wrote:

> > This doesn't, though.  When I read in my data, the IDvar is supposed to
> > be the column that is unique for each record, correct?  But there are
> > several records (closed polygons) for each town.  These are linked by
> > another variable.  The coordinates(rep.map) gives me a list of 419
> > coordinates for all the closed shapes, not 75 coordinates for all the
> > towns.  How do I get the biggest polygons for each town?  I have an Area
> > attribute, so I guess I can just calculate it.  Is that the right way to
> > go, or is there some method already existing for this?
> >
> > I thought maybe my readSpatial... was done wrong, so I changed the IDvar
> > to point to the iD for each town, but that gives me an error saying that
> > duplicate row names are not allowed.  Is there a step I needed to take
> > to link the polygons?
> 
> Yes, see the unionSpatialPolygons() function in maptools. It uses
> functions in gpclib to dissolve boundaries between member entities if
> they touch, so makes a Polygons object with possibly multiple member
> Polygon objects from multiple Polygons objects with the same ID values
> (towns for you). You then need to drop rows from the data.frame
> (as(rep.map, "data.frame")), and re-assemble using
> SpatialPolygonsDataFrame() with the row.names of the data.frame set to
> the town IDs used in unionSpatialPolygons().
> 
> The mess is caused by the underlying data being kept in OGC SFS
> (simple features) form, which does not store well in shapefiles (a
> similar remark could be made about SpatialPolygons objects, which are
> more like shapefiles than like SFS).
> 
> The gpclib package should not be used if its license conditions are
> inappropriate. A free software alternative is being prepared.
> 
> Roger
> 
> >
> > Thank you,
> >
> > -tom
> >
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 


-- 
 --------------------------------------------------------
 Check out "Ten Things You Don't Know About Rhode Island"
     http://whatcheer.net      http://sgouros.com


From Roger.Bivand at nhh.no  Mon Nov 23 21:55:41 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Nov 2009 21:55:41 +0100 (CET)
Subject: [R-sig-Geo] Map labels
In-Reply-To: <4532.1259008855@as220.org>
References: <7780.1258983678@as220.org>
	<alpine.LRH.2.00.0911231503250.2730@reclus.nhh.no>
	<11475.1258987537@as220.org>
	<alpine.LRH.2.00.0911232012070.3310@reclus.nhh.no>
	<4532.1259008855@as220.org>
Message-ID: <alpine.LRH.2.00.0911232141430.3310@reclus.nhh.no>

On Mon, 23 Nov 2009, tom sgouros wrote:

>
> Is this another way to say that I've stumbled onto one of the borders
> between the set of tasks that R does well and the set of tasks I should
> use a GIS for?  Or should I persevere with R on this?

Not really, this is a generic problem for shapefiles, which can have 
multiple external and internal (hole) rings in a single entity (as can 
Polygons objects) and OGC SFS, where an entity is an external ring with 
internal rings.

This means that unless a collection of such external rings is seen as an 
entity, there is an ambiguity, which data producers focussed more on 
borders than content resolve by duplicating content, and joining to a 
content table. Most GIS given such a shapefile would face the same 
problem, but might be able to join to a "town-wise" table for symbology. 
In R, the key view of the data is the data.frame, so duplicate rows are 
not an option.

Maybe by this time next year an OGC SFS-compliant set of classes may be 
ready for trying out, but since shapefiles are the most popular way of 
sharing data, and are not OGC SFS compliant (they do not contain 
information on which internal rings belong to which external rings in an 
entity), this isn't easy.

>
> Second question: if I want to just do this assembly myself, so to keep
> some control over placement, is there an add-a-Polygon-to-my-Polygons
> method, or do you have an example of something like that?

?unionSpatialPolygons, followed by SpatialPolygonsDataFrame to re-assemble 
after removing the duplicated rows in the data.frame belonging to the 
object. See the example in ch 5 in our book, code on:

http://www.asdar-book.org/book/cm2_mod.R

around chunk 27 (16-30 is the initial part, 31-36 aggregates into SMSAs). 
The first part should be runnable since the shapefiles are from the US 
Census, the second by downloading the bundle from

http://www.asdar-book.org/bundles/cm2_bundle.zip

Roger

>
> Thanks for the help,
>
> -tom
>
>
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>>> This doesn't, though.  When I read in my data, the IDvar is supposed to
>>> be the column that is unique for each record, correct?  But there are
>>> several records (closed polygons) for each town.  These are linked by
>>> another variable.  The coordinates(rep.map) gives me a list of 419
>>> coordinates for all the closed shapes, not 75 coordinates for all the
>>> towns.  How do I get the biggest polygons for each town?  I have an Area
>>> attribute, so I guess I can just calculate it.  Is that the right way to
>>> go, or is there some method already existing for this?
>>>
>>> I thought maybe my readSpatial... was done wrong, so I changed the IDvar
>>> to point to the iD for each town, but that gives me an error saying that
>>> duplicate row names are not allowed.  Is there a step I needed to take
>>> to link the polygons?
>>
>> Yes, see the unionSpatialPolygons() function in maptools. It uses
>> functions in gpclib to dissolve boundaries between member entities if
>> they touch, so makes a Polygons object with possibly multiple member
>> Polygon objects from multiple Polygons objects with the same ID values
>> (towns for you). You then need to drop rows from the data.frame
>> (as(rep.map, "data.frame")), and re-assemble using
>> SpatialPolygonsDataFrame() with the row.names of the data.frame set to
>> the town IDs used in unionSpatialPolygons().
>>
>> The mess is caused by the underlying data being kept in OGC SFS
>> (simple features) form, which does not store well in shapefiles (a
>> similar remark could be made about SpatialPolygons objects, which are
>> more like shapefiles than like SFS).
>>
>> The gpclib package should not be used if its license conditions are
>> inappropriate. A free software alternative is being prepared.
>>
>> Roger
>>
>>>
>>> Thank you,
>>>
>>> -tom
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.hijmans at gmail.com  Mon Nov 23 22:05:17 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 23 Nov 2009 13:05:17 -0800
Subject: [R-sig-Geo] Overlay of SpatialGrid/Raster and polygons
In-Reply-To: <4B0AED99.4070302@amnh.org>
References: <4B0AED99.4070302@amnh.org>
Message-ID: <dc22b2570911231305s7f8a23d8v25f85b02d0e311e1@mail.gmail.com>

Hi Ned,

Here is an approach to get values from a RasterStack to all cells in
each polygon:

library(raster)
# a polygon
data(meuse.riv)
pol <- SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)), "x")))
# a raster
r1 <- raster(system.file("external/test.ag", package="sp"))
r2 <- sqrt(r1)
# a stack
s <- stack(r1, r2)

# convert the polygon to a RasterLayer
rr <- polygonsToRaster(pol, s)

par(mfrow=c(1,2))
plot(r1)
plot(pol, add=TRUE)
plot(rr)

# extract points that are not NA
pts <- rasterToPoints(rr) # see additional arguments to select a
subset (useful for very large rasters)
# perhaps subsample your points
sampl <- sample(1:length(pts[,1]), min(100, length(pts[,1])))
pts <- pts[sampl,]

v <- xyValues(s, pts[,1:2])
# if you have mutiple polygons, bind the polygon ID to the raster values:
v <- cbind(pts[,3], v)

# You could also sample points with spsample
pts <- spsample(pol, 100,  "random")
# remove duplicate cells
cells <- unique(cellFromXY(s, pts))
v2 <- cellValues(s, cells)

# or sample from a SpGDF if you can create it from the RasterLayer (if
it is not too big)
spdf <- as(rr, 'SpatialGridDataFrame')
pts <- spsample(spdf, 100,  "random")
v3 <- xyValues(s, pts)


For extremely large rasters, rasterToPoints could fail. If so, first
create a RasterLayer with random values with calc and "fun=runif" and
make values F for e.g x > 0.01, overlay that with rr, and try
rasterToPoints again...

Hth, Robert




On Mon, Nov 23, 2009 at 12:16 PM, Ned Horning <horning at amnh.org> wrote:
> Greetings,
>
> I am looking for a way to use R to extract pixel values (currently in a
> large RasterStack object) that fall under polygons (currently a
> SpatialPolygonsDataFrame object). I seem to recall a discussion about using
> overlay to do this but I can't find a method that would work.
>
> Any insight would be appreciated.
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From alan.swanson at umontana.edu  Mon Nov 23 22:18:50 2009
From: alan.swanson at umontana.edu (Alan Swanson)
Date: Mon, 23 Nov 2009 14:18:50 -0700
Subject: [R-sig-Geo] Overlay of SpatialGrid/Raster and polygons
In-Reply-To: <4B0AED99.4070302@amnh.org>
References: <4B0AED99.4070302@amnh.org>
Message-ID: <4B0AFC39.70505@umontana.edu>

Ned, here is how I have done that using the overlay function. Not sure 
if it would work with a rasterstack. 
Alan

xy.locs <- readOGR(poly.shapefile.name,drop_unsupported_fields=T)
img<-readGDAL(image.name)
y<-slot(img,"data")
n.bands <- ncol(y)
bnames <- paste(varname,"_b",1:n.bands,sep="") }
out.frame <- 
as.data.frame(matrix(NA,nrow=nrow(xy.locs),ncol=n.bands,dimnames=list(NULL,bnames)))   

for(m in 1:(n.poly <- length(slot(xy.locs,"polygons")))){
    gc()
    z<-overlay(img,xy.locs[m,])
    for(j in 1:n.bands){
        xx <- mean(y[z==1 & !is.na(z),j],na.rm=T)
        out.frame[m,j] <- xx
        } # end inner loop over bands #
    } # end loop over individual polygons #
  


Ned Horning wrote:
> Greetings,
>
> I am looking for a way to use R to extract pixel values (currently in 
> a large RasterStack object) that fall under polygons (currently a 
> SpatialPolygonsDataFrame object). I seem to recall a discussion about 
> using overlay to do this but I can't find a method that would work.
>
> Any insight would be appreciated.
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From zua3 at cornell.edu  Mon Nov 23 23:08:47 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Mon, 23 Nov 2009 17:08:47 -0500
Subject: [R-sig-Geo] Overlay of SpatialGrid/Raster and polygons
In-Reply-To: <dc22b2570911231305s7f8a23d8v25f85b02d0e311e1@mail.gmail.com>
References: <4B0AED99.4070302@amnh.org>
	<dc22b2570911231305s7f8a23d8v25f85b02d0e311e1@mail.gmail.com>
Message-ID: <4B0B07EF.8070406@cornell.edu>

I  am trying to install "raster" package, but  it is not available  in 
this site.  http://R-Forge.R-project.org .

Zia

Robert J. Hijmans wrote:
> Hi Ned,
>
> Here is an approach to get values from a RasterStack to all cells in
> each polygon:
>
> library(raster)
> # a polygon
> data(meuse.riv)
> pol <- SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)), "x")))
> # a raster
> r1 <- raster(system.file("external/test.ag", package="sp"))
> r2 <- sqrt(r1)
> # a stack
> s <- stack(r1, r2)
>
> # convert the polygon to a RasterLayer
> rr <- polygonsToRaster(pol, s)
>
> par(mfrow=c(1,2))
> plot(r1)
> plot(pol, add=TRUE)
> plot(rr)
>
> # extract points that are not NA
> pts <- rasterToPoints(rr) # see additional arguments to select a
> subset (useful for very large rasters)
> # perhaps subsample your points
> sampl <- sample(1:length(pts[,1]), min(100, length(pts[,1])))
> pts <- pts[sampl,]
>
> v <- xyValues(s, pts[,1:2])
> # if you have mutiple polygons, bind the polygon ID to the raster values:
> v <- cbind(pts[,3], v)
>
> # You could also sample points with spsample
> pts <- spsample(pol, 100,  "random")
> # remove duplicate cells
> cells <- unique(cellFromXY(s, pts))
> v2 <- cellValues(s, cells)
>
> # or sample from a SpGDF if you can create it from the RasterLayer (if
> it is not too big)
> spdf <- as(rr, 'SpatialGridDataFrame')
> pts <- spsample(spdf, 100,  "random")
> v3 <- xyValues(s, pts)
>
>
> For extremely large rasters, rasterToPoints could fail. If so, first
> create a RasterLayer with random values with calc and "fun=runif" and
> make values F for e.g x > 0.01, overlay that with rr, and try
> rasterToPoints again...
>
> Hth, Robert
>
>
>
>
> On Mon, Nov 23, 2009 at 12:16 PM, Ned Horning <horning at amnh.org> wrote:
>   
>> Greetings,
>>
>> I am looking for a way to use R to extract pixel values (currently in a
>> large RasterStack object) that fall under polygons (currently a
>> SpatialPolygonsDataFrame object). I seem to recall a discussion about using
>> overlay to do this but I can't find a method that would work.
>>
>> Any insight would be appreciated.
>>
>> Ned
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/56408ae6/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: zua3.vcf
Type: text/x-vcard
Size: 281 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/56408ae6/attachment.vcf>

From r.hijmans at gmail.com  Mon Nov 23 23:26:21 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 23 Nov 2009 14:26:21 -0800
Subject: [R-sig-Geo] Overlay of SpatialGrid/Raster and polygons
In-Reply-To: <4B0B07EF.8070406@cornell.edu>
References: <4B0AED99.4070302@amnh.org>
	<dc22b2570911231305s7f8a23d8v25f85b02d0e311e1@mail.gmail.com>
	<4B0B07EF.8070406@cornell.edu>
Message-ID: <dc22b2570911231426w6ad01be7q67dc7b7380233a4a@mail.gmail.com>

ZIa,

You can download the source code and install yourself here:
http://r-forge.r-project.org/R/?group_id=294

Or use this: install.packages("raster", repos="http://R-Forge.R-project.org")

But I think you need to have the latest version of R (currently 2.10)
installed for that to work

Robert

On Mon, Nov 23, 2009 at 2:08 PM, Zia Ahmed <zua3 at cornell.edu> wrote:
> I? am trying to install "raster" package, but? it is not available? in this
> site.? http://R-Forge.R-project.org .
>
> Zia
>
> Robert J. Hijmans wrote:
>
> Hi Ned,
>
> Here is an approach to get values from a RasterStack to all cells in
> each polygon:
>
> library(raster)
> # a polygon
> data(meuse.riv)
> pol <- SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)), "x")))
> # a raster
> r1 <- raster(system.file("external/test.ag", package="sp"))
> r2 <- sqrt(r1)
> # a stack
> s <- stack(r1, r2)
>
> # convert the polygon to a RasterLayer
> rr <- polygonsToRaster(pol, s)
>
> par(mfrow=c(1,2))
> plot(r1)
> plot(pol, add=TRUE)
> plot(rr)
>
> # extract points that are not NA
> pts <- rasterToPoints(rr) # see additional arguments to select a
> subset (useful for very large rasters)
> # perhaps subsample your points
> sampl <- sample(1:length(pts[,1]), min(100, length(pts[,1])))
> pts <- pts[sampl,]
>
> v <- xyValues(s, pts[,1:2])
> # if you have mutiple polygons, bind the polygon ID to the raster values:
> v <- cbind(pts[,3], v)
>
> # You could also sample points with spsample
> pts <- spsample(pol, 100,  "random")
> # remove duplicate cells
> cells <- unique(cellFromXY(s, pts))
> v2 <- cellValues(s, cells)
>
> # or sample from a SpGDF if you can create it from the RasterLayer (if
> it is not too big)
> spdf <- as(rr, 'SpatialGridDataFrame')
> pts <- spsample(spdf, 100,  "random")
> v3 <- xyValues(s, pts)
>
>
> For extremely large rasters, rasterToPoints could fail. If so, first
> create a RasterLayer with random values with calc and "fun=runif" and
> make values F for e.g x > 0.01, overlay that with rr, and try
> rasterToPoints again...
>
> Hth, Robert
>
>
>
>
> On Mon, Nov 23, 2009 at 12:16 PM, Ned Horning <horning at amnh.org> wrote:
>
>
> Greetings,
>
> I am looking for a way to use R to extract pixel values (currently in a
> large RasterStack object) that fall under polygons (currently a
> SpatialPolygonsDataFrame object). I seem to recall a discussion about using
> overlay to do this but I can't find a method that would work.
>
> Any insight would be appreciated.
>
> Ned
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From pierre.roudier at gmail.com  Mon Nov 23 23:30:41 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Tue, 24 Nov 2009 09:30:41 +1100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <MPG.2574d093e601f9079896ae@news.gmane.org>
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch> 
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au> 
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com> 
	<200911200914.35528.ashton@msu.edu>
	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193> 
	<MPG.2570e861cf3e07479896ad@news.gmane.org>
	<4B0A8B33.9010304@geo.uu.nl> 
	<MPG.2574d093e601f9079896ae@news.gmane.org>
Message-ID: <e4178da60911231430j617f9cf9h461c60a1f35c0f62@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091124/82fd6ba4/attachment.pl>

From pierre.roudier at gmail.com  Mon Nov 23 23:33:19 2009
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Tue, 24 Nov 2009 09:33:19 +1100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
In-Reply-To: <e4178da60911231430j617f9cf9h461c60a1f35c0f62@mail.gmail.com>
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch> 
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au> 
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com> 
	<200911200914.35528.ashton@msu.edu>
	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193> 
	<MPG.2570e861cf3e07479896ad@news.gmane.org>
	<4B0A8B33.9010304@geo.uu.nl> 
	<MPG.2574d093e601f9079896ae@news.gmane.org>
	<e4178da60911231430j617f9cf9h461c60a1f35c0f62@mail.gmail.com>
Message-ID: <e4178da60911231433x7baa25bbsa2e4d2f284691d16@mail.gmail.com>

Sorry for my previous HTML-formatted message, here it is again:

Another package I find useful for shaded views of spatial data is the rgl
package.

It is most useful because of its ability to zoom and turn the map
interactively.

>From surface3d() help page :

data(volcano)
z <- 2 * volcano
x <- 10 * (1:nrow(z))
y <- 10 * (1:ncol(z))
zlim <- range(y)
zlen <- zlim[2] - zlim[1] + 1
colorlut <- terrain.colors(zlen)
col <- colorlut[ z-zlim[1]+1 ]
library(rgl)
open3d()
surface3d(x, y, z, color=col, back="lines")

Pierre



2009/11/24 Pierre Roudier <pierre.roudier at gmail.com>:
> Another package I find useful for shaded views of spatial data is the rgl
> package.
>
> It is most useful because of its ability to zoom and turn the map
> interactively.
>
> From surface3d() help page :
>
> data(volcano)
> z <- 2 * volcano
> x <- 10 * (1:nrow(z))
> y <- 10 * (1:ncol(z))
> zlim <- range(y)
> zlen <- zlim[2] - zlim[1] + 1
> colorlut <- terrain.colors(zlen)
> col <- colorlut[ z-zlim[1]+1 ]
> library(rgl)
> open3d()
> surface3d(x, y, z, color=col, back="lines")
>
> Pierre
>
> 2009/11/24 Karl Ove Hufthammer <karl at huftis.org>
>>
>> On Mon, 23 Nov 2009 14:16:35 +0100 Paul Hiemstra <p.hiemstra at geo.uu.nl>
>> wrote:
>> > > The maps with shading look quite nice. Is there an R package/function
>> > > which can create similar images?
>> > >
>> > A good place to look for these kinds of graphs and how to make them is
>> > the R graph gallery [1]. Check out this one for example [2].
>>
>> Excellent idea. I have of course used 'persp' many times, but had
>> forgotten about its 'shade' option. With it, I can create very good-
>> looking (and useful!) 3D maps. I use it on a bathymetry (ocean depths)
>> dataset, and using this shading and 3D visualisation gives a whole new
>> perspective (sorry).
>>
>> One alternative that I discovered is the hillshading feature of the free
>> GIS software SAGA. It's even available in R using the 'RSAGA' package.
>> See "http://sourceforge.net/apps/trac/saga-gis/wiki/Climbing%20Mount%
>> 20St.%20Helens" for a nice example of its output. (I didn't manage to
>> get it to automatically use 'natural' colours for ocean and
>> land/terrain, though.)
>>
>> --
>> Karl Ove Hufthammer
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From ashton at msu.edu  Mon Nov 23 23:38:07 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Mon, 23 Nov 2009 17:38:07 -0500
Subject: [R-sig-Geo] strange srtm3 query in geonames package
In-Reply-To: <b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>
	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>
	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>
Message-ID: <200911231738.07746.ashton@msu.edu>

Hi Michael,

there are several SRTM 'holes' over the United States, evidently due to some 
data processing issues on a couple of orbits. Unfortunately for you one of the 
largest is over part of North Carolina. The following URL has some maps of the 
major gaps:
http://www.mission-planning.com/DTED_Part3.htm

There are other US elevation datasets, including NED from seamless.usgs.gov, 
that are better quality and freely available, and might suit your needs.

Ashton

On Sunday 22 November 2009 14:19:46 Michael Denslow wrote:
> Thanks Barry!
> 
> On Sun, Nov 22, 2009 at 2:02 PM, Barry Rowlingson
> 
> <b.rowlingson at lancaster.ac.uk> wrote:
> > On Sun, Nov 22, 2009 at 6:23 PM, Michael Denslow
> >
> > <michael.denslow at gmail.com> wrote:
> >> Dear r-sig-geo and Barry,
> >>
> >> I am getting a strange value when doing a query using the function
> >> GNsrtm3 in the geonames package.
> >> Here is the code.
> >>
> >> library(geonames)
> >> GNsrtm3(34.63874,-79.10111)  # outside Lumberton North Carolina USA!
> >>
> >>
> >>   srtm3       lng      lat
> >> 1 -32768 -79.10111 34.63874
> >>
> >> Warning message:
> >> In readLines(u) :
> >>  incomplete final line found on
> >> 'http://ws.geonames.org/srtm3JSON?lat=34.63874&lng=-79.10111'
> >>
> >>
> >> I think the elevation value should be around 47 meters. The geonames
> >> website says 'ocean areas have been masked as "no data" and have been
> >> assigned a value of -32768'.
> >> http://www.geonames.org/export/web-services.html#srtm3
> >> I tried adjusting the lat, long values to query some nearby cells but
> >> I still get -32768.
> >>
> >> Are these kinds of errors common in this dataset? Any suggestions?
> >> I am would actually prefer to get an average elevation for the county
> >> (Robeson) but am settling for the county centroid at this point.
> >
> >  I don't really know the details of the srtm3 data set, but I do see
> > that geonames has two other DEM datasets - ASTER and GTOPO30. There's
> > a function for GTOPO30 in geonames, but not ASTER. It's easy enough to
> >
> > write though:
> >> GNaster=function(lat,lng){return(as.data.frame(geonames:::getJson("aster
> >>gdemJSON",list(lat=lat,lng=lng))))}
> >
> >  and I may include it in a new release (as well as getting rid of
> > those end-of-line warnings). These two services agree with themselves
> > and with you pretty well for your test location:
> 
> It would be great to have GNaster added.
> 
> >> GNgtopo30(34.63874,-79.10111)
> >
> >  gtopo30       lng      lat
> > 1      46 -79.10111 34.63874
> >
> >> GNaster(34.63874,-79.10111)
> >
> >  astergdem       lng      lat
> > 1        47 -79.10111 34.63874
> >
> >  For an 'average' elevation you might be better off sampling many
> > locations over your polygon.
> 
> Sounds like a good idea.
> 
> Thanks again for your help!
> 
> Michael
> 
> > Barry
> 

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


From zua3 at cornell.edu  Mon Nov 23 23:44:01 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Mon, 23 Nov 2009 17:44:01 -0500
Subject: [R-sig-Geo] How do change projection from geographic coordinate to
 projected coordinate system in R?
In-Reply-To: <4B0AFC39.70505@umontana.edu>
References: <4B0AED99.4070302@amnh.org> <4B0AFC39.70505@umontana.edu>
Message-ID: <4B0B1031.3030308@cornell.edu>

Hi all,

I want project several  several raster(.tif)  and vector (.shp)  files 
in R using rgdal driver. One set of  files are in  geographic coordinate 
system (WGS84) other are in LCC-Bangladesh coordinate system.

.I want to re-project them to EPSG:3104 (Gulshan 303/ BTM).  If some 
help me this regard it will appreciated.

Thanks

Zia

Below I mentioned parameter of LCC-Bangladesh coordinate system:
Projection: Lambert_Conformal_Conic
False_Easting: 2743186.000000
False_Northing: 914395.000000
Central_Meridian: 90.000000
Standard_Parallel_1: 23.176944
Standard_Parallel_2: 28.822770
Latitude_Of_Origin: 26.000000
Linear Unit: Meter (1.000000)

Geographic Coordinate System: GCS_Everest_Bangladesh
Angular Unit: Degree (0.017453292519943299)
Prime Meridian: Greenwich (0.000000000000000000)
Datum: D_Everest_Bangladesh
Spheroid: Everest_Adjustment_1937
 Semimajor Axis: 6377276.344999999700000000
  Semiminor Axis: 6356075.413140240100000000
  Inverse Flattening: 300.801699999999980000



-------------- next part --------------
A non-text attachment was scrubbed...
Name: zua3.vcf
Type: text/x-vcard
Size: 281 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091123/b8a8f59e/attachment.vcf>

From zua3 at cornell.edu  Tue Nov 24 03:26:37 2009
From: zua3 at cornell.edu (Zia Ahmed)
Date: Mon, 23 Nov 2009 21:26:37 -0500
Subject: [R-sig-Geo] Risks as hazardous (false positive) and safe (false
	negative)
In-Reply-To: <4B0AAE98.3090506@uni-muenster.de>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>	<4B0A91EC.8030504@uni-muenster.de>
	<4B0A9785.6020604@cornell.edu> <4B0A98FB.5060109@cornell.edu>
	<4B0A99B3.9050601@uni-muenster.de> <4B0AA228.4030102@cornell.edu>
	<4B0AAE98.3090506@uni-muenster.de>
Message-ID: <4B0B445D.5040003@cornell.edu>

/Dear Edzer,
/
I am trying to do  misclassification following way: could you please 
tell me know whether  I am  statistically correct or wrong!

Thanks again
Zia/

# Load data
#-------------
tala<-read.csv("Tala_data.csv",header=TRUE)
tala.grid<-read.csv("Tala_grid_2.csv",header=TRUE)
# load packages:
#----------------
library(sp)
library(gstat)
library(lattice)
library(geoR)
library(MASS)
library(car)
coordinates(tala) <- ~ x + y       # Observed data
coordinates(tala.grid) <-~ x + y   # Prediction locations

# Box-cox transformation; required pakage- car
tala$was.bc<-box.cox(tala$was, .47)  # Power (lambda)= .47

# Varigram modeling:
#---------------------
v.ok<-variogram(was.bc~1,data=tala)
plot(v.ok, pl=F, pch=20, cex=1, col="Black")
m.ok<-vgm(.06,"Exp",4000,0.02)
(m.ok.f<-fit.variogram(v.ok, m.ok))
attr(m.ok.f,"SSErr") # Sum of Squared Error (SSE)

# Ordinary Kriging
#------------------

ok.was<-krige(was.bc~1,tala,tala.grid, model=m.ok.f, nmax=50)

# Back-and Indicator- transformation of OK prediction:
#-----------------------------------------------------------------------------------------
#Power=0.47
k<-1/0.47                                        
ok.was$was.bt <-((ok.was$var1.pred *0.47+1)^k)

target <- box.cox(0.100,0.47)
ok.was$was.target <- (ok.was$var1.pred>= target)
ok.was$p.target <- pt((-target +ok.was$var1.pred)/sqrt(ok.was$var1.var),
    length(tala$was.bc))
summary(ok.was)
coordinates(ok.was)<-~x+y

# Probability of true indicator
#-----------------------------------------------

plot(coordinates(ok.was), asp = 1, col = ifelse(ok.was$was.target,
"grey", "yellow"),//"Easting (m)", ylab="Northing (m)",//  main = 
"Probability of TRUE indicator",
sub = "Actual indicator: yellow/grey = FALSE/TRUE")
grid()

#-----------------------------------------------------------------
# Probability-of-exceeding 200 ppb ground water As conc.
#--------------------------------------------------------------------
levelplot(p.target~x+y| was.target, main="  (b) Probability > 0.200 mg 
As/L",
              xlab="Easting (m)", ylab="Northing (m)",
              as.data.frame(ok.was), aspect = "iso",at = seq(0, 1, by = 
0.05),
              col.regions=topo.colors,                            
              panel = function(...) {
              panel.levelplot(...)
              panel.abline(h = 0:4*5000 + 545000, v= 0:4*5000 + 2650000,
              col = "light grey")
},
     )

/
Edzer Pebesma wrote:
> (replying to the list)
>
> Well, if you're willing to accept the indicator kriging values as
> estimates of these probabilities, you're essentially done. Of course,
> the kriged values can be outside [0, 1], so you need to deal with that.
>
> Best regards,
> --
> Edzer
>
> Zia Ahmed wrote:
>   
>> Dear Edzer,
>>
>> Thanks for your replay. I have done IK of water arsenic using
>> quantiles of the data. I want to do   miss classification  of my risk
>> that  proposed  by  Goovaerts.
>> Two misclassification  of risks are proposed by Goovaerts (1997) based
>> on ccdf model F(*u*;z_k |(n)) of Z(*u*)?Z_k .
>>
>>
>> 1.       The risk ?(*u*) of incorrectly classified a location u as
>> hazardous (false positive):
>>
>> ?(*u*) = Prob{Z(*u*) ?z_c |z*_L (u) > Z_c , (n)}
>>
>>        = F(*u*;z_c |(n))
>>
>> Where z*_L (u) is the estimator.
>>
>> 2.       The risk ?(u)  wrongly classified a location u as safe (false
>> negative)
>>
>> ?(*u*) = Prob{Z(*u*) > z_c |z*_L (u) ? Z_c , (n)}
>>
>>       = 1- F(*u*;z_c |(n))
>>
>>
>>
>>
>>
>> Ref: Goovaerts, P (1997). Geostatistics for Natural Resource
>> Evaluation, pp: 259-368
>>
>>
>>
>> Zia
>>
>> Edzer Pebesma wrote:
>>     
>>> Dear Zia,
>>>
>>> If you mean by Goovaerts (1997) his 483 page book "Geostatistics for
>>> Natural Resource Evaluation", then please give us a bit more precise
>>> detail on what you want (which page? which equation?)
>>> -- 
>>> Edzer
>>>
>>> Zia Ahmed wrote:
>>>  
>>>       
>>>> Hi all,
>>>>
>>>> Is it possible in gstat to get misclassification  of risks as
>>>> hazardous (false positive) and safe (false negative) as describe by
>>>> Goovaerts (1997)  from parametric or non-parametric probability
>>>> mapping?.  help will appreciated.
>>>>
>>>> Thanks
>>>>
>>>> Zia
>>>>
>>>>
>>>>     
>>>>         
>>>   
>>>       
>
>


From edzer.pebesma at uni-muenster.de  Tue Nov 24 08:47:21 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 24 Nov 2009 08:47:21 +0100
Subject: [R-sig-Geo] Risks as hazardous (false positive) and safe (false
	negative)
In-Reply-To: <4B0B445D.5040003@cornell.edu>
References: <b440a3f80911221023n25e1ada3o68e5ee4e272c9b1a@mail.gmail.com>	<d8ad40b50911221102w64e3edf9nb467f2d11f301682@mail.gmail.com>	<b440a3f80911221119r434a1b6eja0bf48e0550b5bc6@mail.gmail.com>	<200911231421.14216.torleif.lunde@cih.uib.no>	<4B0A91EC.8030504@uni-muenster.de>
	<4B0A9785.6020604@cornell.edu> <4B0A98FB.5060109@cornell.edu>
	<4B0A99B3.9050601@uni-muenster.de> <4B0AA228.4030102@cornell.edu>
	<4B0AAE98.3090506@uni-muenster.de> <4B0B445D.5040003@cornell.edu>
Message-ID: <4B0B8F89.50806@uni-muenster.de>



Zia Ahmed wrote:
> /Dear Edzer,
> /
> I am trying to do  misclassification following way: could you please
> tell me know whether  I am  statistically correct or wrong!
Zia, to do this, I would need your data, a lot of information about your
data, and a lot of time. And then, the answer would be a long one and
not one in the sense of "yes" or "no". I'm sorry, but you either
overestimate my capabilities, or those of statistical methods in
general, or both!
>
> Thanks again
> Zia/
>
> # Load data
> #-------------
> tala<-read.csv("Tala_data.csv",header=TRUE)
> tala.grid<-read.csv("Tala_grid_2.csv",header=TRUE)
> # load packages:
> #----------------
> library(sp)
> library(gstat)
> library(lattice)
> library(geoR)
> library(MASS)
> library(car)
> coordinates(tala) <- ~ x + y       # Observed data
> coordinates(tala.grid) <-~ x + y   # Prediction locations
>
> # Box-cox transformation; required pakage- car
> tala$was.bc<-box.cox(tala$was, .47)  # Power (lambda)= .47
>
> # Varigram modeling:
> #---------------------
> v.ok<-variogram(was.bc~1,data=tala)
> plot(v.ok, pl=F, pch=20, cex=1, col="Black")
> m.ok<-vgm(.06,"Exp",4000,0.02)
> (m.ok.f<-fit.variogram(v.ok, m.ok))
> attr(m.ok.f,"SSErr") # Sum of Squared Error (SSE)
>
> # Ordinary Kriging
> #------------------
>
> ok.was<-krige(was.bc~1,tala,tala.grid, model=m.ok.f, nmax=50)
>
> # Back-and Indicator- transformation of OK prediction:
> #-----------------------------------------------------------------------------------------
>
> #Power=0.47
> k<-1/0.47                                        ok.was$was.bt
> <-((ok.was$var1.pred *0.47+1)^k)
>
> target <- box.cox(0.100,0.47)
> ok.was$was.target <- (ok.was$var1.pred>= target)
> ok.was$p.target <- pt((-target +ok.was$var1.pred)/sqrt(ok.was$var1.var),
>    length(tala$was.bc))
> summary(ok.was)
> coordinates(ok.was)<-~x+y
>
> # Probability of true indicator
> #-----------------------------------------------
>
> plot(coordinates(ok.was), asp = 1, col = ifelse(ok.was$was.target,
> "grey", "yellow"),//"Easting (m)", ylab="Northing (m)",//  main =
> "Probability of TRUE indicator",
> sub = "Actual indicator: yellow/grey = FALSE/TRUE")
> grid()
>
> #-----------------------------------------------------------------
> # Probability-of-exceeding 200 ppb ground water As conc.
> #--------------------------------------------------------------------
> levelplot(p.target~x+y| was.target, main="  (b) Probability > 0.200 mg
> As/L",
>              xlab="Easting (m)", ylab="Northing (m)",
>              as.data.frame(ok.was), aspect = "iso",at = seq(0, 1, by =
> 0.05),
>              col.regions=topo.colors,                           
>              panel = function(...) {
>              panel.levelplot(...)
>              panel.abline(h = 0:4*5000 + 545000, v= 0:4*5000 + 2650000,
>              col = "light grey")
> },
>     )
>
> /
> Edzer Pebesma wrote:
>> (replying to the list)
>>
>> Well, if you're willing to accept the indicator kriging values as
>> estimates of these probabilities, you're essentially done. Of course,
>> the kriged values can be outside [0, 1], so you need to deal with that.
>>
>> Best regards,
>> -- 
>> Edzer
>>
>> Zia Ahmed wrote:
>>  
>>> Dear Edzer,
>>>
>>> Thanks for your replay. I have done IK of water arsenic using
>>> quantiles of the data. I want to do   miss classification  of my risk
>>> that  proposed  by  Goovaerts.
>>> Two misclassification  of risks are proposed by Goovaerts (1997) based
>>> on ccdf model F(*u*;z_k |(n)) of Z(*u*)?Z_k .
>>>
>>>
>>> 1.       The risk ?(*u*) of incorrectly classified a location u as
>>> hazardous (false positive):
>>>
>>> ?(*u*) = Prob{Z(*u*) ?z_c |z*_L (u) > Z_c , (n)}
>>>
>>>        = F(*u*;z_c |(n))
>>>
>>> Where z*_L (u) is the estimator.
>>>
>>> 2.       The risk ?(u)  wrongly classified a location u as safe (false
>>> negative)
>>>
>>> ?(*u*) = Prob{Z(*u*) > z_c |z*_L (u) ? Z_c , (n)}
>>>
>>>       = 1- F(*u*;z_c |(n))
>>>
>>>
>>>
>>>
>>>
>>> Ref: Goovaerts, P (1997). Geostatistics for Natural Resource
>>> Evaluation, pp: 259-368
>>>
>>>
>>>
>>> Zia
>>>
>>> Edzer Pebesma wrote:
>>>    
>>>> Dear Zia,
>>>>
>>>> If you mean by Goovaerts (1997) his 483 page book "Geostatistics for
>>>> Natural Resource Evaluation", then please give us a bit more precise
>>>> detail on what you want (which page? which equation?)
>>>> -- 
>>>> Edzer
>>>>
>>>> Zia Ahmed wrote:
>>>>  
>>>>      
>>>>> Hi all,
>>>>>
>>>>> Is it possible in gstat to get misclassification  of risks as
>>>>> hazardous (false positive) and safe (false negative) as describe by
>>>>> Goovaerts (1997)  from parametric or non-parametric probability
>>>>> mapping?.  help will appreciated.
>>>>>
>>>>> Thanks
>>>>>
>>>>> Zia
>>>>>
>>>>>
>>>>>             
>>>>         
>>
>>   
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From Roger.Bivand at nhh.no  Tue Nov 24 11:15:37 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 24 Nov 2009 11:15:37 +0100 (CET)
Subject: [R-sig-Geo] How do change projection from geographic coordinate
 to projected coordinate system in R?
In-Reply-To: <4B0B1031.3030308@cornell.edu>
References: <4B0AED99.4070302@amnh.org> <4B0AFC39.70505@umontana.edu>
	<4B0B1031.3030308@cornell.edu>
Message-ID: <alpine.LRH.2.00.0911241041350.5936@reclus.nhh.no>

On Mon, 23 Nov 2009, Zia Ahmed wrote:

> Hi all,
>
> I want project several  several raster(.tif)  and vector (.shp)  files in R 
> using rgdal driver. One set of  files are in  geographic coordinate system 
> (WGS84) other are in LCC-Bangladesh coordinate system.
>
> .I want to re-project them to EPSG:3104 (Gulshan 303/ BTM).  If some help me 
> this regard it will appreciated.

For the vector files, make sure that the Spatial*DataFrame objects read 
from the shapefiles have valid coordinate reference system descriptions. 
Then use spTransform() in rgdal to CRS("+init=epsg:3104"). Note that I see 
3106 not 3104 in EPSG. Further, EPSG does not define a datum, so more work 
will be required to establish the actual input and output CRS values.

See http://www.asprs.org/resources/GRIDS/ for March 2008, which includes 
values for a three-parameter +towgs84= transformation for Gulshan (watch 
the signs!). From Cliff Mugnier's description, it looks as though your LCC 
below is "+init=epsg=24375", # Kalianpur 1937 / India zone IIb, which does 
not include a +towgs84= conversion - more searching will be needed. There 
is a +towgs84= for Kalianpur 1975, but the ellipsoid is different from 
yours. I see TOWGS84[214.0, 804.0, 268.0, 0.0, 0.0, 0.0, 0.0] in 
http://apps.who.int/tools/geoserver/srsHelp.do, but you need someone with 
knowledge rather than Google!

Typically, you need to find a ground control point on your vector map, 
transform it to "+proj=longlat +datum=WGS84", and use writeOGR() with the 
"KML" driver to view in Google Earth. Because you can zoom in, you should 
be able to see when the coordinate reference system is adequate. See also 
http://spatialreference.org/.

You cannot project raster data, you have to warp it to a regular grid in 
the target coordinate reference system. This involves interpolation, so 
see for example projectRaster() in the raster package on R-Forge for 
ideas.

>
> Thanks
>
> Zia
>
> Below I mentioned parameter of LCC-Bangladesh coordinate system:
> Projection: Lambert_Conformal_Conic
> False_Easting: 2743186.000000
> False_Northing: 914395.000000
> Central_Meridian: 90.000000
> Standard_Parallel_1: 23.176944
> Standard_Parallel_2: 28.822770
> Latitude_Of_Origin: 26.000000
> Linear Unit: Meter (1.000000)
>
> Geographic Coordinate System: GCS_Everest_Bangladesh
> Angular Unit: Degree (0.017453292519943299)
> Prime Meridian: Greenwich (0.000000000000000000)
> Datum: D_Everest_Bangladesh
> Spheroid: Everest_Adjustment_1937
> Semimajor Axis: 6377276.344999999700000000
> Semiminor Axis: 6356075.413140240100000000
> Inverse Flattening: 300.801699999999980000
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From karl at huftis.org  Tue Nov 24 14:41:59 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Tue, 24 Nov 2009 14:41:59 +0100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
	<200911200914.35528.ashton@msu.edu>
	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193>
	<MPG.2570e861cf3e07479896ad@news.gmane.org>
	<4B0A8B33.9010304@geo.uu.nl>
	<MPG.2574d093e601f9079896ae@news.gmane.org>
	<e4178da60911231430j617f9cf9h461c60a1f35c0f62@mail.gmail.com>
	<e4178da60911231433x7baa25bbsa2e4d2f284691d16@mail.gmail.com>
Message-ID: <MPG.2576010d12d0651a9896b2@news.gmane.org>

On Tue, 24 Nov 2009 09:33:19 +1100 Pierre Roudier 
<pierre.roudier at gmail.com> wrote:
> Sorry for my previous HTML-formatted message, here it is again:
> 
> Another package I find useful for shaded views of spatial data is the rgl
> package.

Thanks for the suggestion. It looks even better than the 'persp' 
solution.

-- 
Karl Ove Hufthammer


From karl at huftis.org  Tue Nov 24 15:38:48 2009
From: karl at huftis.org (Karl Ove Hufthammer)
Date: Tue, 24 Nov 2009 15:38:48 +0100
Subject: [R-sig-Geo] A new ASTER Global DEM data set
References: <mailman.11.1258714803.15108.r-sig-geo@stat.math.ethz.ch>
	<86DBA0678E017341B449A62F258E295602D9D880@IS-EX-BEV3.unimelb.edu.au>
	<d8ad40b50911200409k2d71fedfrfc268b1ef247864e@mail.gmail.com>
	<200911200914.35528.ashton@msu.edu>
	<4E4E7ECB3357401AAE66CD7A7E7443B8@pcibed193>
	<MPG.2570e861cf3e07479896ad@news.gmane.org>
	<4B0A8B33.9010304@geo.uu.nl>
	<MPG.2574d093e601f9079896ae@news.gmane.org>
	<e4178da60911231430j617f9cf9h461c60a1f35c0f62@mail.gmail.com>
	<e4178da60911231433x7baa25bbsa2e4d2f284691d16@mail.gmail.com>
	<MPG.2576010d12d0651a9896b2@news.gmane.org>
Message-ID: <MPG.25760e63992058789896b3@news.gmane.org>

On Tue, 24 Nov 2009 14:41:59 +0100 Karl Ove Hufthammer <karl at huftis.org> 
wrote:
> > Another package I find useful for shaded views of spatial data is the rgl
> > package.
> 
> Thanks for the suggestion. It looks even better than the 'persp' 
> solution.

Just one additional note, for people wanting to use 'persp' and 
'surface3d' for plotting maps: The 'col' argument differs between 
'persp' and 'surface3d'. For 'persp', it specifies the colour of the 
facets, so it should have (nrow-1)*(ncol-1) values. For 'surface3d' it 
specifies the colours of the vertices, so it should have nrow*ncol 
values.

-- 
Karl Ove Hufthammer


From alobolistas at gmail.com  Tue Nov 24 19:09:17 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Tue, 24 Nov 2009 19:09:17 +0100
Subject: [R-sig-Geo] raster package: Problem with installation on Windows
	(Vista)
Message-ID: <4B0C214D.5010604@gmail.com>

I've run the install command as stated in
http://r-forge.r-project.org/R/?group_id=294

from within R on Windows Vista but got an error:
 > install.packages("raster", repos="http://R-Forge.R-project.org")
Warning in install.packages("raster", repos = "http://R-Forge.R-project.org") :
   argument 'lib' is missing: using 'C:\Users\Cel\Documents/R/win-library/2.9'
Warning: unable to access index for repository 
http://R-Forge.R-project.org/bin/windows/contrib/2.9
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
   package ?raster? is not available

Should we just download the zip fie and run a local
installation?

Thanks

Agus


From r.hijmans at gmail.com  Tue Nov 24 20:00:41 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Tue, 24 Nov 2009 11:00:41 -0800
Subject: [R-sig-Geo] raster package: Problem with installation on
	Windows (Vista)
In-Reply-To: <4B0C214D.5010604@gmail.com>
References: <4B0C214D.5010604@gmail.com>
Message-ID: <dc22b2570911241100i6da9d2cene09563cae5e32fc5@mail.gmail.com>

Agus,

R-Forge only builds packages for the current version and the next
(development version of R).  If you are not using the current version
of R, you can do

> install.packages("raster", repos="http://R-Forge.R-project.org")

Otherwise, yes, either download the source and build, or download the
compiled version install.

Robert



On Tue, Nov 24, 2009 at 10:09 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> I've run the install command as stated in
> http://r-forge.r-project.org/R/?group_id=294
>
> from within R on Windows Vista but got an error:
>> install.packages("raster", repos="http://R-Forge.R-project.org")
> Warning in install.packages("raster", repos =
> "http://R-Forge.R-project.org") :
> ?argument 'lib' is missing: using 'C:\Users\Cel\Documents/R/win-library/2.9'
> Warning: unable to access index for repository
> http://R-Forge.R-project.org/bin/windows/contrib/2.9
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
> ?package ?raster? is not available
>
> Should we just download the zip fie and run a local
> installation?
>
> Thanks
>
> Agus
>


From giam at nus.edu.sg  Wed Nov 25 07:21:58 2009
From: giam at nus.edu.sg (Giam Xingli)
Date: Wed, 25 Nov 2009 14:21:58 +0800
Subject: [R-sig-Geo] Converting nb list containing areas with no neighbours
	with nb2WB()
Message-ID: <9BD0FDD497B6464682342F906E323054042720B1@MBX23.stu.nus.edu.sg>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091125/11404040/attachment.html>

From giam at nus.edu.sg  Wed Nov 25 07:52:31 2009
From: giam at nus.edu.sg (Giam Xingli)
Date: Wed, 25 Nov 2009 14:52:31 +0800
Subject: [R-sig-Geo] Converting nb list containing areas with no
	neighbours with nb2WB()
References: <9BD0FDD497B6464682342F906E323054042720B1@MBX23.stu.nus.edu.sg>
Message-ID: <9BD0FDD497B6464682342F906E323054042720B2@MBX23.stu.nus.edu.sg>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091125/57b2b8b7/attachment.html>

From xgiam at princeton.edu  Wed Nov 25 09:09:11 2009
From: xgiam at princeton.edu (Xingli Giam)
Date: Wed, 25 Nov 2009 03:09:11 -0500
Subject: [R-sig-Geo] Converting nb list containing areas with no
	neighbours with nb2WB()
Message-ID: <000001ca6da6$926aec40$b740c4c0$@edu>

Hi everyone,

Thank you in advance for your advice. First I must apologize for sending the
two scrubbed messages in this thread. I thought MS Outlook Web Light sends
messages in plain text format but I was wrong. I have transferred my account
to my new email address and have set the email format to plain text. I hope
everything is fine now. I sincerely apologize for causing inconvenience by
sending multiple unreadable messages to the list. 

I am trying to convert a nb object containing a single area with no
neighbours into a spatial weights list for input into WinBUGS using nb2WB().

When I tried to run the CAR models in WinBUGS using the spatial weights list
via R2WinBUGS, I encountered a WinBUGS trap. The error message was "Index
out of range".

I checked the adjacency matrix of the spatial weights list output object,
and a zero integer was placed at the position corresponding to the area with
no neighbours.

When I re-ran the analysis after I changed my neighbourhood structure such
that all areas had neighbours, the WinBUGS simulation ran fine.

Is there a way to format the spatial weights list object via nb2WB() in a
way that allows WinBUGS to read cases with no neighbours?

In WinBUGS, if we were to enter the adjacency matrix manually it will be:


#Here is where we tell BUGS how to set up the adjacency structure.  For
example, site 1 neighbors sites 19,9, and 5.

adj = c(
19, 9, 5,
10, 7,
12,
28, 20, 18,
19, 12, 1,
                    #Site 6 has no neighbors
17, 16, 13, 10, 2,
and so on.
)


Here are my OS details:
R version 2.10.0 (2009-10-26)
i386-pc-mingw32
locale:
[1] LC_COLLATE=English_Singapore.1252  LC_CTYPE=English_Singapore.1252
LC_MONETARY=English_Singapore.1252
[4] LC_NUMERIC=C                       LC_TIME=English_Singapore.1252   
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base    
other attached packages:
 [1] R2WinBUGS_2.1-16   spdep_0.4-52       nlme_3.1-96        coda_0.13-4
MASS_7.3-3       
 [6] Matrix_0.999375-32 lattice_0.17-26    spam_0.15-5        boot_1.2-41
maptools_0.7-26  
[11] foreign_0.8-38     sp_0.9-47          deldir_0.0-10    
loaded via a namespace (and not attached):
[1] grid_2.10.0  tools_2.10.0

Best,
Xingli Giam
Ph.D. candidate
Department of Ecology and Evolutionary Biology
Princeton University
Princeton, USA


From Virgilio.Gomez at uclm.es  Wed Nov 25 09:27:19 2009
From: Virgilio.Gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Wed, 25 Nov 2009 09:27:19 +0100
Subject: [R-sig-Geo] Converting nb list containing areas with no
 neighbours with nb2WB()
In-Reply-To: <000001ca6da6$926aec40$b740c4c0$@edu>
References: <000001ca6da6$926aec40$b740c4c0$@edu>
Message-ID: <1259137639.3210.11.camel@Virgilio-Gomez>

Hi,


> I checked the adjacency matrix of the spatial weights list output object,
> and a zero integer was placed at the position corresponding to the area with
> no neighbours.

Yes. Probably we need to fix this so that nothing is added when an area
has no neighbours.

> When I re-ran the analysis after I changed my neighbourhood structure such
> that all areas had neighbours, the WinBUGS simulation ran fine.
> 
> Is there a way to format the spatial weights list object via nb2WB() in a
> way that allows WinBUGS to read cases with no neighbours?

It should be done automatically, but probably we forgot to consider the
case of areas with no neighbours.

Could it be possible to see the map that you are using? I'd say that
there is a mismatch between the number of neighbours and the number of
weights, but I would need to check with you data and code.


Best wishes,

Virgilio


From xgiam at princeton.edu  Wed Nov 25 11:11:04 2009
From: xgiam at princeton.edu (Xingli Giam)
Date: Wed, 25 Nov 2009 05:11:04 -0500
Subject: [R-sig-Geo] Converting nb list containing areas with no
	neighbours with nb2WB()
In-Reply-To: <1259137639.3210.11.camel@Virgilio-Gomez>
References: <000001ca6da6$926aec40$b740c4c0$@edu>
	<1259137639.3210.11.camel@Virgilio-Gomez>
Message-ID: <000c01ca6db7$998fa090$ccaee1b0$@edu>

Hi Virgilio,

Thank you for your clear and very quick reply. I really appreciate your help
in looking at my data.

Here is my data and code, I hope it will be clear enough for you:

rm(list=ls())

library(spdep)
library(R2WinBUGS)

S <- c(66.666667,  40.000000,  50.000000,  56.666667, 250.000000,
66.666667, 183.333333,  50.000000,   7.000000, 106.666667,  90.000000,
83.333333, 100.000000,
5.500000, 146.666667, 100.000000, 160.000000,  70.000000, 160.000000,
183.333333,  70.000000, 133.333333, 130.000000,  73.333333,  93.333333,
31.666667,
183.333333, 116.666667, 116.666667, 200.000000, 110.000000, 120.000000,
50.000000,  70.000000, 133.333333, 133.333333, 106.666667,  66.666667,
106.666667,
133.333333,   9.333333,  90.000000,  33.333333,  66.666667, 200.000000,
106.666667,  90.000000,  31.666667, 110.000000,  50.000000, 100.000000,
120.000000,
110.000000, 136.666667,  31.666667,  93.333333,  70.000000, 110.000000,
60.900000, 333.333333, 133.333333,  83.333333,  83.333333, 100.000000,
36.666667,
 66.666667,  86.666667,   7.333333,  53.333333,  50.000000,  96.666667,
100.000000,  60.000000,  33.333333,  60.000000, 183.333333, 133.333333,
116.666667,
126.666667,  50.000000, 166.666667,  50.000000,  12.666667, 100.000000,
50.000000,  66.666667, 143.333333,  83.333333, 126.666667,  73.333333,
45.966667,
 76.666667,  93.333333, 100.000000, 233.333333,  50.000000,  76.666667,
116.666667,  93.333333,  46.666667,  90.000000, 106.666667,  36.666667,
233.333333,
 26.666667,  13.333333, 216.666667,  76.666667, 110.000000, 133.333333,
46.666667,  66.666667,  73.333333,  46.666667,  53.333333, 250.000000,
116.666667,
 66.666667,  53.333333,  26.666667, 133.333333,  26.666667,  23.333333,
70.000000,  66.666667, 116.666667, 100.000000,  66.666667,  90.000000,
100.000000,
150.000000,  50.000000, 166.666667, 200.000000, 200.000000,  50.000000,
300.000000,  63.333333, 150.000000,  11.666667, 136.666667, 116.666667,
126.666667,
 83.333333, 300.000000,  10.666667, 123.333333, 183.333333, 110.000000,
116.666667, 216.666667, 110.000000,   2.666667, 266.666667, 266.666667,
83.333333,
126.666667, 106.666667, 266.666667, 216.666667,  93.333333, 266.666667,
166.666667,  50.000000, 200.000000, 183.333333, 150.000000, 116.666667,
106.666667,
133.333333, 150.000000, 233.333333, 216.666667,  33.333333, 216.666667,
106.666667,  56.666667,  63.333333,  23.333333, 216.666667, 100.000000,
83.333333,
216.666667, 216.666667,  60.000000, 166.666667, 166.666667, 100.000000,
53.333333, 300.000000,  91.666667, 136.666667, 233.333333,  34.466667,
116.666667,
283.333333, 283.333333, 166.666667,  96.666667, 150.000000,  70.000000,
4.000000, 216.666667, 135.000000, 150.000000, 200.000000,  90.000000,
176.666667,
 53.333333, 166.666667,  53.333333,  60.000000,  38.333333,   1.666667,
4.333333,   3.666667,  48.333333,  31.166667,   3.766667,  10.600000,
16.666667,
  5.833333,   1.000000,  25.833333,  20.766667,  16.000000,   4.666667,
5.000000,   1.666667, 116.666667, 200.000000)

A <- c(
   233.222222,   832.888889,   312.222222,   954.000000, 19025.555556,
2971.666667,  1827.777778,   267.444444,     1.555556,   178.666667,
3879.555556,
  1342.333333,  1613.666667,     4.666667, 14959.555556,  2576.000000,
3621.777778,  2141.777778,  3966.666667,  8559.333333, 11054.777778,
13593.111111,
 12867.777778,  8385.777778,   464.444444,  1461.777778,  2427.888889,
8562.222222, 11489.333333, 20980.111111,  4208.777778, 45875.777778,
228.555556,
  2292.111111,  5760.000000,  7244.333333,  2617.333333, 10257.222222,
20988.333333, 27526.000000,    34.444444,  3436.000000,   340.111111,
1975.444444,
 12417.777778, 22108.000000,  3349.555556,   548.000000,   126.777778,
1593.666667,  7449.222222, 59007.444444, 12461.222222, 48021.111111,
114.666667,
 16273.666667, 14228.888889, 22691.777778,   632.888889, 47287.000000,
12786.444444,  7463.555556,  6290.333333,  4897.111111,  4317.555556,
2259.666667,
  3290.777778,    14.888889, 37796.777778,  1758.777778,  5962.888889,
3872.888889,  4236.111111,  1678.555556, 15323.333333, 73588.000000,
13239.777778,
 28167.666667,  7953.888889,   919.222222, 10541.888889,  3925.666667,
60.222222,  4625.444444,   718.888889,  2013.333333, 11629.666667,
1119.888889,
 15027.222222,  7370.222222,   187.555556,  5338.222222,  3425.000000,
5228.111111, 48429.888889,  1866.000000,  4667.777778,  5974.888889,
2502.444444,
  2469.777778,  1586.444444,  1899.666667,   401.111111, 13882.666667,
1191.555556,     3.444444, 24858.222222,  2630.666667,  2505.000000,
5146.000000,
  4067.000000,  1388.888889,   340.666667,   258.444444,  1999.444444,
28698.666667,  8068.666667,  9680.000000,  8467.222222,  1613.888889,
10770.000000,
  2880.666667,  3251.333333, 29182.555556,  2907.888889,  4609.000000,
1721.000000,   451.555556,   285.555556,  3702.444444, 23963.666667,
872.222222,
 12145.000000, 25471.222222, 10025.444444,   530.666667, 20373.111111,
2528.111111,  3546.111111,    10.555556,  9938.888889,  1472.333333,
639.888889,
   230.777778,  8145.000000,     2.777778,  1586.888889,  7508.555556,
1211.111111,  2371.000000, 11340.222222,   336.777778,     2.111111,
16218.111111,
 52904.000000,  1097.888889,  5090.444444, 12722.888889,  6484.333333,
3241.777778,   918.888889, 29827.111111, 26832.555556,   109.555556,
79631.333333,
 11622.000000,  8493.333333,  9811.666667, 15737.222222, 45812.666667,
7389.555556, 27843.444444, 22325.777778,  1112.333333,  8978.444444,
841.888889,
  3114.222222,  1905.888889,   854.444444, 53653.222222,  1944.666667,
2510.777778, 20662.333333, 16510.555556,   833.777778, 19640.000000,
19251.222222,
 10665.111111,   529.555556, 11623.333333,   432.222222,  1246.444444,
18547.888889,   230.111111,  8350.000000, 82961.444444,  1808.222222,
37233.222222,
  5630.555556, 21418.444444,   524.666667,     1.000000, 52227.555556,
12715.888889,  3252.111111,  7660.666667,   549.111111,  3772.666667,
223.777778,
 29452.444444,  7720.222222, 25537.333333,    64.222222,    68.000000,
23.555556,    59.000000,  1285.777778,   746.444444,     3.777778,
119.333333,
    10.666667,    51.111111,    19.777778,   342.555556,   180.000000,
104.222222,   104.777778,    15.777778,    10.333333, 29903.555556,
26650.444444)

x_long <- c(
 146.97,  131.53,  135.88,  126.63,  140.71,  128.14,  146.65,  136.08,
159.09,  153.49,  151.11,  151.42,  165.57,  167.95,  143.25,  139.42,
145.73,  129.35,  155.24,
 148.32,  138.58,  140.60,  121.05,  120.12,  151.03,  166.70,  133.12,
134.16,   29.68,   11.29,   10.20,   21.04,   44.25,    7.41,    8.59,
35.30,   35.83,   21.10,
  -2.71,   38.95,   55.46,  -12.15,   23.37,   30.48,   48.59,   47.03,
32.74,   55.55,    9.16,    6.47,    4.66,   24.46,   39.59,   14.95,
6.54,   40.02,   17.02,
  -9.93,   92.81,  112.82,  113.89,  111.30,   94.31,  102.97,  100.65,
99.71,   93.96,  105.69,   81.42,  113.36,  112.43,  122.98,   82.27,
95.66,   96.06,  114.19,
  98.13,   87.67,  101.55,  122.25,  122.08,   74.89,  120.18,   91.87,
98.94,  124.72,  125.83,  120.94,   92.82,   96.22,   93.32,   73.53,
73.95,  105.21,  100.91,
 102.69,  100.95,   96.88,  105.81,   85.78,  119.01,  101.41,  103.31,
102.28,  105.82,  115.83,  108.12,   77.03,   76.73,  107.36,  116.59,
80.19,   80.83,  120.00,
 101.54,  101.05,  100.22,  102.84,  116.12,   89.33,   99.11,  104.90,
105.10,   80.75,  108.34,  109.41,  109.65,  127.98,  120.62,  121.03,
-51.31,  -50.19,  -39.70,
 -41.85,  -66.43,  -40.89,  -72.04,  -72.66,  -76.01,  -81.70,  -84.67,
-89.61,  -92.80,  -94.19,  -76.97,  -87.06,  -66.22,  -72.12,  -84.96,
-75.44,  -78.26,  -77.38,
 -32.44,  -63.22,  -56.99,  -53.74,  -70.09,  -74.28,  -83.65,  -82.28,
-77.28,  -65.21,  -66.22,  -61.67,  -60.03,  -74.50,  -75.10,  -50.51,
-43.91,  -52.68,  -61.65,
 -75.73,  -66.26,  -42.98,  -77.11,  -96.74,  -61.10,  -92.28,  -55.58,
-52.62,  -35.72,  -36.34,  -73.49,  -90.33,  -66.34,  -69.45,  -63.36,
-68.78,  -73.89,  -48.74,
 -94.94,  -92.28,  -70.32,  -80.39,  -64.96,  -69.17,  -82.77,  -54.90,
-65.46,  -47.11,  -61.21,  -30.32,  -56.78,  -76.19,  -70.41,  -98.21,
-98.39,  -79.52,  -61.03,
 -50.30,  -89.02,  -63.97,  158.22, -157.66, -159.77,  173.02,  179.31,
-155.31, -177.93, -138.98,  142.15,  134.56, -109.34, -172.48, -149.38,
-175.20, -146.36, -144.36,
-171.63,  107.97,  102.87)


y_lat <- c(
 -2.10,  -7.56,  -0.92,  -3.49,  -5.21,   0.65,  -6.08,  -1.72, -31.56,
-11.48,  -5.22,  -5.48, -21.31, -29.04,  -4.28,  -2.79, -17.47,  -3.33,
-5.94,  -8.72,  -7.48,
 -6.23,  -1.97,  -2.42,  -9.95, -15.14,  -1.04,  -2.46,  -1.93,  -0.75,
5.64,  -1.17, -12.18,   5.53,   5.07,   0.00,  -8.26,  -0.30,   7.61,
13.13,  -4.67,  11.23,
-33.98, -30.38, -19.27, -18.60, -26.36, -21.11,   4.23,   5.17,   6.78,
0.96,  -3.94,   1.01,   0.13, -13.60,   0.43,   7.18,  12.53,   1.49,
2.07,   2.04,  26.93,
 11.69,  15.11,  14.32,  21.29, -10.45,  19.93,  -8.02,  -7.59,  10.02,
28.07,  16.88,  20.26,  26.03,  17.76,  24.04,  18.06,  16.82,  16.61,
13.19,  13.77,  25.79,
 -1.36,   7.89,   7.69,  12.68,  22.26,  18.72,   8.00,  17.17,  16.39,
17.75,  23.05,  17.75,  18.58,  26.34,  18.34,  20.23,  10.07,   4.62,
3.11,   4.08,  20.86,
 10.72,  22.15,  10.54,  10.63,  15.23,   0.42,   6.78,   6.98,   5.20,
0.33,  -0.13,  -0.09,  -0.57,   0.05,  22.68,  11.11,  11.68,  10.34,
27.65,  -7.10,  -6.95,
 19.56,  26.48,  22.38,  23.89, -26.65, -30.05, -16.45, -16.90, -15.69,
-3.96,   0.64,   8.80,   4.84,  12.54,  14.05,  15.18,  17.09,  16.65,
5.51,   5.53,   9.99,
  6.26,  10.43,  20.42,  -2.04,   8.34,  -3.86,   4.00,   4.89,  -2.00,
19.09,  -5.35,  10.22,   8.52,  18.18,  -0.54,  -5.88,  16.16,  -8.90,
5.38,   7.75,  -1.12,
 -4.26, -10.02,  -6.00,  -1.52,   1.89,  -2.75,   2.51,  17.82,   9.06,
18.16,   5.72, -23.25,  -8.73,  -8.79, -11.89,  17.10,  18.24,  -3.99,
-6.58,   0.81,  10.74,
-25.75,  18.34,  15.15,  -2.28,  25.66, -23.59, -10.48,   9.11,  -6.16,
5.63,  -3.04,  10.69, -20.50,  -0.20,  -7.38,   8.80,  21.79,  20.64,
-0.53,  14.66,  -5.78,
 19.67,   3.79,   6.88,   1.88, -21.23,   1.83, -16.58,  19.77, -29.27,
-9.78,  26.66,   7.53, -27.13, -13.62, -17.69, -21.17, -16.18, -27.61,
-2.82,  27.93,  26.11)

coords <- cbind(x_long, y_lat)

nb2000 <- dnearneigh(coords, 0, 2000, longlat=T)
nb2000weights <- nb2WB(nb2000)

# find zero integer value in nb2000weights adj matrix
zero.int <- (1:length(nb2000weights$adj))[nb2000weights$adj==0]
zero.int

# testing if nb2000weights adj and weights matrix is of the same length (#
Yes)
length(nb2000weights$adj)
length(nb2000weights$weights)

N=length(A)

d <-  list(sp = S, area_km2 = A, N=N, adj=nb2000weights$adj,
weights=nb2000weights$weights, num=nb2000weights$num)

init1 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
init2 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
init3 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
inits = list(init1,init2,init3)

powerdat1lg.bugs <- bugs(data=d, inits,
model.file="C:/WinBUGS/CARlogcodes/powerbuglnorm.txt",
parameters = c("c", "z", "sp.rep", "b"),
n.chains =3, n.iter = 32500, n.burnin = 7500, n.sims=3000,
bugs.directory ="c:/Program Files/WinBUGS14/", debug=T)

____________________________________________

Here is my WinBUGS model file code
"C:/WinBUGS/CARlogcodes/powerbuglnorm.txt":

model
{
	
	for (i in 1:N) # for each ecoreg in biome 1
	{
	
	S[i] <- c*(pow(area_km2[i] , z)) + b[i]
	
	logS[i] <- log(max(0.001,S[i]))
	
	sp[i] ~ dlnorm(logS[i],prec)
	
	sp.rep [i] <- max(0.001, (c*pow(area_km2[i],z) + b[i]))

	}

	# CAR prior distribution for random effects
	
	b[1:N] ~ car.normal(adj[], weights[], num[], tau)
	
	c ~ dnorm(0,0.0000001)I(0,)   
	                                                 
	z ~ dnorm(0,0.0000001)I(0,)
	                                                  
	prec ~ dgamma(0.001,0.001)

	tau ~ dgamma(0.001,0.001)
	
	}

Many thanks,
Xingli


-----Original Message-----
From: Virgilio G?mez-Rubio [mailto:Virgilio.Gomez at uclm.es] 
Sent: Wednesday, 25 November, 2009 3:27 AM
To: Xingli Giam
Cc: R-sig-Geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Converting nb list containing areas with no
neighbours with nb2WB()

Hi,


> I checked the adjacency matrix of the spatial weights list output object,
> and a zero integer was placed at the position corresponding to the area
with
> no neighbours.

Yes. Probably we need to fix this so that nothing is added when an area
has no neighbours.

> When I re-ran the analysis after I changed my neighbourhood structure such
> that all areas had neighbours, the WinBUGS simulation ran fine.
> 
> Is there a way to format the spatial weights list object via nb2WB() in a
> way that allows WinBUGS to read cases with no neighbours?

It should be done automatically, but probably we forgot to consider the
case of areas with no neighbours.

Could it be possible to see the map that you are using? I'd say that
there is a mismatch between the number of neighbours and the number of
weights, but I would need to check with you data and code.


Best wishes,

Virgilio


From Roger.Bivand at nhh.no  Wed Nov 25 12:19:33 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 25 Nov 2009 12:19:33 +0100 (CET)
Subject: [R-sig-Geo] Converting nb list containing areas with no
 neighbours with nb2WB()
In-Reply-To: <000c01ca6db7$998fa090$ccaee1b0$@edu>
References: <000001ca6da6$926aec40$b740c4c0$@edu>
	<1259137639.3210.11.camel@Virgilio-Gomez>
	<000c01ca6db7$998fa090$ccaee1b0$@edu>
Message-ID: <alpine.LRH.2.00.0911251216330.9258@reclus.nhh.no>

On Wed, 25 Nov 2009, Xingli Giam wrote:

> Hi Virgilio,
>
> Thank you for your clear and very quick reply. I really appreciate your help
> in looking at my data.

The problem is caused by the nb object encoding no-neighbour status with 
an integer vector of length 1 containing 0. Please try this patched 
version:

nb2WB <- function(nb)
{
   	if (!inherits(nb, "nb")) stop("not a neighbours list")
         num <- card(nb)
         if (any(num == 0)) nb[num == 0] <- NULL
         adj <- unlist(nb)
         weights <- rep(1, sum(num))

         list(adj=adj, weights=weights, num=num)
}

It works for me so far, and num now contains the correct 0 for observation 
233. I haven't tried it with WinBUGS though.

Hope this helps,

Roger

>
> Here is my data and code, I hope it will be clear enough for you:
>
> rm(list=ls())
>
> library(spdep)
> library(R2WinBUGS)
>
> S <- c(66.666667,  40.000000,  50.000000,  56.666667, 250.000000,
> 66.666667, 183.333333,  50.000000,   7.000000, 106.666667,  90.000000,
> 83.333333, 100.000000,
> 5.500000, 146.666667, 100.000000, 160.000000,  70.000000, 160.000000,
> 183.333333,  70.000000, 133.333333, 130.000000,  73.333333,  93.333333,
> 31.666667,
> 183.333333, 116.666667, 116.666667, 200.000000, 110.000000, 120.000000,
> 50.000000,  70.000000, 133.333333, 133.333333, 106.666667,  66.666667,
> 106.666667,
> 133.333333,   9.333333,  90.000000,  33.333333,  66.666667, 200.000000,
> 106.666667,  90.000000,  31.666667, 110.000000,  50.000000, 100.000000,
> 120.000000,
> 110.000000, 136.666667,  31.666667,  93.333333,  70.000000, 110.000000,
> 60.900000, 333.333333, 133.333333,  83.333333,  83.333333, 100.000000,
> 36.666667,
> 66.666667,  86.666667,   7.333333,  53.333333,  50.000000,  96.666667,
> 100.000000,  60.000000,  33.333333,  60.000000, 183.333333, 133.333333,
> 116.666667,
> 126.666667,  50.000000, 166.666667,  50.000000,  12.666667, 100.000000,
> 50.000000,  66.666667, 143.333333,  83.333333, 126.666667,  73.333333,
> 45.966667,
> 76.666667,  93.333333, 100.000000, 233.333333,  50.000000,  76.666667,
> 116.666667,  93.333333,  46.666667,  90.000000, 106.666667,  36.666667,
> 233.333333,
> 26.666667,  13.333333, 216.666667,  76.666667, 110.000000, 133.333333,
> 46.666667,  66.666667,  73.333333,  46.666667,  53.333333, 250.000000,
> 116.666667,
> 66.666667,  53.333333,  26.666667, 133.333333,  26.666667,  23.333333,
> 70.000000,  66.666667, 116.666667, 100.000000,  66.666667,  90.000000,
> 100.000000,
> 150.000000,  50.000000, 166.666667, 200.000000, 200.000000,  50.000000,
> 300.000000,  63.333333, 150.000000,  11.666667, 136.666667, 116.666667,
> 126.666667,
> 83.333333, 300.000000,  10.666667, 123.333333, 183.333333, 110.000000,
> 116.666667, 216.666667, 110.000000,   2.666667, 266.666667, 266.666667,
> 83.333333,
> 126.666667, 106.666667, 266.666667, 216.666667,  93.333333, 266.666667,
> 166.666667,  50.000000, 200.000000, 183.333333, 150.000000, 116.666667,
> 106.666667,
> 133.333333, 150.000000, 233.333333, 216.666667,  33.333333, 216.666667,
> 106.666667,  56.666667,  63.333333,  23.333333, 216.666667, 100.000000,
> 83.333333,
> 216.666667, 216.666667,  60.000000, 166.666667, 166.666667, 100.000000,
> 53.333333, 300.000000,  91.666667, 136.666667, 233.333333,  34.466667,
> 116.666667,
> 283.333333, 283.333333, 166.666667,  96.666667, 150.000000,  70.000000,
> 4.000000, 216.666667, 135.000000, 150.000000, 200.000000,  90.000000,
> 176.666667,
> 53.333333, 166.666667,  53.333333,  60.000000,  38.333333,   1.666667,
> 4.333333,   3.666667,  48.333333,  31.166667,   3.766667,  10.600000,
> 16.666667,
>  5.833333,   1.000000,  25.833333,  20.766667,  16.000000,   4.666667,
> 5.000000,   1.666667, 116.666667, 200.000000)
>
> A <- c(
>   233.222222,   832.888889,   312.222222,   954.000000, 19025.555556,
> 2971.666667,  1827.777778,   267.444444,     1.555556,   178.666667,
> 3879.555556,
>  1342.333333,  1613.666667,     4.666667, 14959.555556,  2576.000000,
> 3621.777778,  2141.777778,  3966.666667,  8559.333333, 11054.777778,
> 13593.111111,
> 12867.777778,  8385.777778,   464.444444,  1461.777778,  2427.888889,
> 8562.222222, 11489.333333, 20980.111111,  4208.777778, 45875.777778,
> 228.555556,
>  2292.111111,  5760.000000,  7244.333333,  2617.333333, 10257.222222,
> 20988.333333, 27526.000000,    34.444444,  3436.000000,   340.111111,
> 1975.444444,
> 12417.777778, 22108.000000,  3349.555556,   548.000000,   126.777778,
> 1593.666667,  7449.222222, 59007.444444, 12461.222222, 48021.111111,
> 114.666667,
> 16273.666667, 14228.888889, 22691.777778,   632.888889, 47287.000000,
> 12786.444444,  7463.555556,  6290.333333,  4897.111111,  4317.555556,
> 2259.666667,
>  3290.777778,    14.888889, 37796.777778,  1758.777778,  5962.888889,
> 3872.888889,  4236.111111,  1678.555556, 15323.333333, 73588.000000,
> 13239.777778,
> 28167.666667,  7953.888889,   919.222222, 10541.888889,  3925.666667,
> 60.222222,  4625.444444,   718.888889,  2013.333333, 11629.666667,
> 1119.888889,
> 15027.222222,  7370.222222,   187.555556,  5338.222222,  3425.000000,
> 5228.111111, 48429.888889,  1866.000000,  4667.777778,  5974.888889,
> 2502.444444,
>  2469.777778,  1586.444444,  1899.666667,   401.111111, 13882.666667,
> 1191.555556,     3.444444, 24858.222222,  2630.666667,  2505.000000,
> 5146.000000,
>  4067.000000,  1388.888889,   340.666667,   258.444444,  1999.444444,
> 28698.666667,  8068.666667,  9680.000000,  8467.222222,  1613.888889,
> 10770.000000,
>  2880.666667,  3251.333333, 29182.555556,  2907.888889,  4609.000000,
> 1721.000000,   451.555556,   285.555556,  3702.444444, 23963.666667,
> 872.222222,
> 12145.000000, 25471.222222, 10025.444444,   530.666667, 20373.111111,
> 2528.111111,  3546.111111,    10.555556,  9938.888889,  1472.333333,
> 639.888889,
>   230.777778,  8145.000000,     2.777778,  1586.888889,  7508.555556,
> 1211.111111,  2371.000000, 11340.222222,   336.777778,     2.111111,
> 16218.111111,
> 52904.000000,  1097.888889,  5090.444444, 12722.888889,  6484.333333,
> 3241.777778,   918.888889, 29827.111111, 26832.555556,   109.555556,
> 79631.333333,
> 11622.000000,  8493.333333,  9811.666667, 15737.222222, 45812.666667,
> 7389.555556, 27843.444444, 22325.777778,  1112.333333,  8978.444444,
> 841.888889,
>  3114.222222,  1905.888889,   854.444444, 53653.222222,  1944.666667,
> 2510.777778, 20662.333333, 16510.555556,   833.777778, 19640.000000,
> 19251.222222,
> 10665.111111,   529.555556, 11623.333333,   432.222222,  1246.444444,
> 18547.888889,   230.111111,  8350.000000, 82961.444444,  1808.222222,
> 37233.222222,
>  5630.555556, 21418.444444,   524.666667,     1.000000, 52227.555556,
> 12715.888889,  3252.111111,  7660.666667,   549.111111,  3772.666667,
> 223.777778,
> 29452.444444,  7720.222222, 25537.333333,    64.222222,    68.000000,
> 23.555556,    59.000000,  1285.777778,   746.444444,     3.777778,
> 119.333333,
>    10.666667,    51.111111,    19.777778,   342.555556,   180.000000,
> 104.222222,   104.777778,    15.777778,    10.333333, 29903.555556,
> 26650.444444)
>
> x_long <- c(
> 146.97,  131.53,  135.88,  126.63,  140.71,  128.14,  146.65,  136.08,
> 159.09,  153.49,  151.11,  151.42,  165.57,  167.95,  143.25,  139.42,
> 145.73,  129.35,  155.24,
> 148.32,  138.58,  140.60,  121.05,  120.12,  151.03,  166.70,  133.12,
> 134.16,   29.68,   11.29,   10.20,   21.04,   44.25,    7.41,    8.59,
> 35.30,   35.83,   21.10,
>  -2.71,   38.95,   55.46,  -12.15,   23.37,   30.48,   48.59,   47.03,
> 32.74,   55.55,    9.16,    6.47,    4.66,   24.46,   39.59,   14.95,
> 6.54,   40.02,   17.02,
>  -9.93,   92.81,  112.82,  113.89,  111.30,   94.31,  102.97,  100.65,
> 99.71,   93.96,  105.69,   81.42,  113.36,  112.43,  122.98,   82.27,
> 95.66,   96.06,  114.19,
>  98.13,   87.67,  101.55,  122.25,  122.08,   74.89,  120.18,   91.87,
> 98.94,  124.72,  125.83,  120.94,   92.82,   96.22,   93.32,   73.53,
> 73.95,  105.21,  100.91,
> 102.69,  100.95,   96.88,  105.81,   85.78,  119.01,  101.41,  103.31,
> 102.28,  105.82,  115.83,  108.12,   77.03,   76.73,  107.36,  116.59,
> 80.19,   80.83,  120.00,
> 101.54,  101.05,  100.22,  102.84,  116.12,   89.33,   99.11,  104.90,
> 105.10,   80.75,  108.34,  109.41,  109.65,  127.98,  120.62,  121.03,
> -51.31,  -50.19,  -39.70,
> -41.85,  -66.43,  -40.89,  -72.04,  -72.66,  -76.01,  -81.70,  -84.67,
> -89.61,  -92.80,  -94.19,  -76.97,  -87.06,  -66.22,  -72.12,  -84.96,
> -75.44,  -78.26,  -77.38,
> -32.44,  -63.22,  -56.99,  -53.74,  -70.09,  -74.28,  -83.65,  -82.28,
> -77.28,  -65.21,  -66.22,  -61.67,  -60.03,  -74.50,  -75.10,  -50.51,
> -43.91,  -52.68,  -61.65,
> -75.73,  -66.26,  -42.98,  -77.11,  -96.74,  -61.10,  -92.28,  -55.58,
> -52.62,  -35.72,  -36.34,  -73.49,  -90.33,  -66.34,  -69.45,  -63.36,
> -68.78,  -73.89,  -48.74,
> -94.94,  -92.28,  -70.32,  -80.39,  -64.96,  -69.17,  -82.77,  -54.90,
> -65.46,  -47.11,  -61.21,  -30.32,  -56.78,  -76.19,  -70.41,  -98.21,
> -98.39,  -79.52,  -61.03,
> -50.30,  -89.02,  -63.97,  158.22, -157.66, -159.77,  173.02,  179.31,
> -155.31, -177.93, -138.98,  142.15,  134.56, -109.34, -172.48, -149.38,
> -175.20, -146.36, -144.36,
> -171.63,  107.97,  102.87)
>
>
> y_lat <- c(
> -2.10,  -7.56,  -0.92,  -3.49,  -5.21,   0.65,  -6.08,  -1.72, -31.56,
> -11.48,  -5.22,  -5.48, -21.31, -29.04,  -4.28,  -2.79, -17.47,  -3.33,
> -5.94,  -8.72,  -7.48,
> -6.23,  -1.97,  -2.42,  -9.95, -15.14,  -1.04,  -2.46,  -1.93,  -0.75,
> 5.64,  -1.17, -12.18,   5.53,   5.07,   0.00,  -8.26,  -0.30,   7.61,
> 13.13,  -4.67,  11.23,
> -33.98, -30.38, -19.27, -18.60, -26.36, -21.11,   4.23,   5.17,   6.78,
> 0.96,  -3.94,   1.01,   0.13, -13.60,   0.43,   7.18,  12.53,   1.49,
> 2.07,   2.04,  26.93,
> 11.69,  15.11,  14.32,  21.29, -10.45,  19.93,  -8.02,  -7.59,  10.02,
> 28.07,  16.88,  20.26,  26.03,  17.76,  24.04,  18.06,  16.82,  16.61,
> 13.19,  13.77,  25.79,
> -1.36,   7.89,   7.69,  12.68,  22.26,  18.72,   8.00,  17.17,  16.39,
> 17.75,  23.05,  17.75,  18.58,  26.34,  18.34,  20.23,  10.07,   4.62,
> 3.11,   4.08,  20.86,
> 10.72,  22.15,  10.54,  10.63,  15.23,   0.42,   6.78,   6.98,   5.20,
> 0.33,  -0.13,  -0.09,  -0.57,   0.05,  22.68,  11.11,  11.68,  10.34,
> 27.65,  -7.10,  -6.95,
> 19.56,  26.48,  22.38,  23.89, -26.65, -30.05, -16.45, -16.90, -15.69,
> -3.96,   0.64,   8.80,   4.84,  12.54,  14.05,  15.18,  17.09,  16.65,
> 5.51,   5.53,   9.99,
>  6.26,  10.43,  20.42,  -2.04,   8.34,  -3.86,   4.00,   4.89,  -2.00,
> 19.09,  -5.35,  10.22,   8.52,  18.18,  -0.54,  -5.88,  16.16,  -8.90,
> 5.38,   7.75,  -1.12,
> -4.26, -10.02,  -6.00,  -1.52,   1.89,  -2.75,   2.51,  17.82,   9.06,
> 18.16,   5.72, -23.25,  -8.73,  -8.79, -11.89,  17.10,  18.24,  -3.99,
> -6.58,   0.81,  10.74,
> -25.75,  18.34,  15.15,  -2.28,  25.66, -23.59, -10.48,   9.11,  -6.16,
> 5.63,  -3.04,  10.69, -20.50,  -0.20,  -7.38,   8.80,  21.79,  20.64,
> -0.53,  14.66,  -5.78,
> 19.67,   3.79,   6.88,   1.88, -21.23,   1.83, -16.58,  19.77, -29.27,
> -9.78,  26.66,   7.53, -27.13, -13.62, -17.69, -21.17, -16.18, -27.61,
> -2.82,  27.93,  26.11)
>
> coords <- cbind(x_long, y_lat)
>
> nb2000 <- dnearneigh(coords, 0, 2000, longlat=T)
> nb2000weights <- nb2WB(nb2000)
>
> # find zero integer value in nb2000weights adj matrix
> zero.int <- (1:length(nb2000weights$adj))[nb2000weights$adj==0]
> zero.int
>
> # testing if nb2000weights adj and weights matrix is of the same length (#
> Yes)
> length(nb2000weights$adj)
> length(nb2000weights$weights)
>
> N=length(A)
>
> d <-  list(sp = S, area_km2 = A, N=N, adj=nb2000weights$adj,
> weights=nb2000weights$weights, num=nb2000weights$num)
>
> init1 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
> init2 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
> init3 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
> inits = list(init1,init2,init3)
>
> powerdat1lg.bugs <- bugs(data=d, inits,
> model.file="C:/WinBUGS/CARlogcodes/powerbuglnorm.txt",
> parameters = c("c", "z", "sp.rep", "b"),
> n.chains =3, n.iter = 32500, n.burnin = 7500, n.sims=3000,
> bugs.directory ="c:/Program Files/WinBUGS14/", debug=T)
>
> ____________________________________________
>
> Here is my WinBUGS model file code
> "C:/WinBUGS/CARlogcodes/powerbuglnorm.txt":
>
> model
> {
>
> 	for (i in 1:N) # for each ecoreg in biome 1
> 	{
>
> 	S[i] <- c*(pow(area_km2[i] , z)) + b[i]
>
> 	logS[i] <- log(max(0.001,S[i]))
>
> 	sp[i] ~ dlnorm(logS[i],prec)
>
> 	sp.rep [i] <- max(0.001, (c*pow(area_km2[i],z) + b[i]))
>
> 	}
>
> 	# CAR prior distribution for random effects
>
> 	b[1:N] ~ car.normal(adj[], weights[], num[], tau)
>
> 	c ~ dnorm(0,0.0000001)I(0,)
>
> 	z ~ dnorm(0,0.0000001)I(0,)
>
> 	prec ~ dgamma(0.001,0.001)
>
> 	tau ~ dgamma(0.001,0.001)
>
> 	}
>
> Many thanks,
> Xingli
>
>
> -----Original Message-----
> From: Virgilio G?mez-Rubio [mailto:Virgilio.Gomez at uclm.es]
> Sent: Wednesday, 25 November, 2009 3:27 AM
> To: Xingli Giam
> Cc: R-sig-Geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Converting nb list containing areas with no
> neighbours with nb2WB()
>
> Hi,
>
>
>> I checked the adjacency matrix of the spatial weights list output object,
>> and a zero integer was placed at the position corresponding to the area
> with
>> no neighbours.
>
> Yes. Probably we need to fix this so that nothing is added when an area
> has no neighbours.
>
>> When I re-ran the analysis after I changed my neighbourhood structure such
>> that all areas had neighbours, the WinBUGS simulation ran fine.
>>
>> Is there a way to format the spatial weights list object via nb2WB() in a
>> way that allows WinBUGS to read cases with no neighbours?
>
> It should be done automatically, but probably we forgot to consider the
> case of areas with no neighbours.
>
> Could it be possible to see the map that you are using? I'd say that
> there is a mismatch between the number of neighbours and the number of
> weights, but I would need to check with you data and code.
>
>
> Best wishes,
>
> Virgilio
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From E.Couce.07 at bristol.ac.uk  Wed Nov 25 14:34:31 2009
From: E.Couce.07 at bristol.ac.uk (ElenaC)
Date: Wed, 25 Nov 2009 05:34:31 -0800 (PST)
Subject: [R-sig-Geo] problem reading netcdf file with readGDAL: "no bands in
 dataset"
Message-ID: <1259156071208-4064987.post@n2.nabble.com>


Hi all,

I'm trying to open a netcdf file using the rgdal library, but readGDAL and
GDALinfo don't seem to be able to correctly access the information in the
file. It is probably a stupid mistake because I don't understand what I'm
doing, but I have already spent a long time trying to sort it out and I
could really use some help with it. 

When I try readGDAL, it fails with the error that there are "no bands in
dataset". This is the output I get from GDALinfo:

> GDALinfo(fname)
rows        512 
columns     512 
bands       0 
origin.x        0 
origin.y        1 
res.x       1 
res.y       1 
oblique.x   0 
oblique.y   0 
driver      netCDF 
projection  NA 

Warning messages:
1: In dim(x) : no bands in dataset
2: In GDALinfo(fname) : no bands in dataset



But from opening the file with Panoply, it seems it actually contains four
variables, two of them 360*180 matrices with the geographical info I'm
trying to access (global data with 1 degree spatial resolution), and the two
others called "lat" and "lon" with the latitude and longitude values.

I don't understand why GDALinfo is telling me that the file has 512 rows and
512 columns and that there are "no bands". What can I do to access the
variables I want?

Any help would be greatly appreciated!
Elena
-- 
View this message in context: http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4064987.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From hakim.abdi at uni-muenster.de  Wed Nov 25 14:50:58 2009
From: hakim.abdi at uni-muenster.de (Hakim Abdi)
Date: Wed, 25 Nov 2009 14:50:58 +0100
Subject: [R-sig-Geo] ascii multicollinearity
Message-ID: <2616bc8f0911250550k2ef7670cw621cc680875da8db@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091125/73594467/attachment.pl>

From p.hiemstra at geo.uu.nl  Wed Nov 25 15:16:41 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Wed, 25 Nov 2009 15:16:41 +0100
Subject: [R-sig-Geo] ascii multicollinearity
In-Reply-To: <2616bc8f0911250550k2ef7670cw621cc680875da8db@mail.gmail.com>
References: <2616bc8f0911250550k2ef7670cw621cc680875da8db@mail.gmail.com>
Message-ID: <4B0D3C49.6010001@geo.uu.nl>

Hakim Abdi wrote:
> Dear All:
>
> I tried searching the r-sig-geo forums regarding this issue but was unable
> to find a solution. I have a set of variables in ASCII format and I'm trying
> to see if there's linear inter-correlation amongst some of them. Is there a
> way in R to assess multicollinearity amongst ASCII grids?
>   
Hi,

You can read the asciigrids in to R using rgdal (readGDAL function). A 
handy way to calculate the linear correlation between the variables is 
to combine them into a data.frame (where each grid is a long vector, 
i.e. a column, in the data.frame) and use the cor() function. Do check 
what assumptions are made when calculating the correlation, for example 
what the influence is when the data is spatially correlated.
> Also, each grid contains 1,919,810 cells and is about ~13-14 MB, so far I
> have a total of 10 grids, would that be a problem for R? I'm running 2GBs of
> memory and two Intel dual-core processors @ 1.73GHz each.
>   
doesn't seem like a problem to me, but try and see.

cheers,
Paul
> Thanks for the response.
>
>   
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From alobolistas at gmail.com  Wed Nov 25 18:59:40 2009
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 25 Nov 2009 18:59:40 +0100
Subject: [R-sig-Geo] Error at running TransitionFromRaster (gdistance)
Message-ID: <4B0D708C.1030708@gmail.com>

Hi!

I'm trying to run the example in the help page
of resistanceDistance but:
 > raster <- raster(nrows=18, ncols=36)
 > raster <- setValues(raster,rep(1,ncell(raster)))
 > tr <- TransitionFromRaster(raster,mean,4)
Error in checkSlotAssignment(object, name, value) :
   "bbox" is not a slot in class "Transition"
Calls: TransitionFromRaster ... initialize -> .local -> @<- -> slot<- -> 
checkSlotAssignment

I just installed from Rforge on R 2.10 (ubuntu 9.4)
Version: 1.0
Date: 2008-09-26

Maybe a mismatch between the version of raster and the one of gdistance?
(for raster:Version: 0.9.8-26
Date: 23-November-2009)

Thanks

Agus


From mdsumner at gmail.com  Wed Nov 25 21:27:13 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 26 Nov 2009 07:27:13 +1100
Subject: [R-sig-Geo] problem reading netcdf file with readGDAL: "no
	bands in dataset"
In-Reply-To: <1259156071208-4064987.post@n2.nabble.com>
References: <1259156071208-4064987.post@n2.nabble.com>
Message-ID: <522664f80911251227l14d79e36qbac8f16723c1bb30@mail.gmail.com>

There are a number of reasons why GDAL might not be able to read data
from NetCDF, although it might appear to get some metadata upfront.
The 512x512 thing is a default, and to me means that there are
multiple variables in the file, and GDAL requires direct reference to
only one of them as a "subdataset". The syntax is something like this:

NETCDF:"/path/to/filename.nc":varname

If you use gdalinfo at the command line it will tell you the
subdataset strings you can use - the rgdal bindings don't reconstruct
the output that that utility gives you.

Cheers, Mike.

On Thu, Nov 26, 2009 at 12:34 AM, ElenaC <E.Couce.07 at bristol.ac.uk> wrote:
>
> Hi all,
>
> I'm trying to open a netcdf file using the rgdal library, but readGDAL and
> GDALinfo don't seem to be able to correctly access the information in the
> file. It is probably a stupid mistake because I don't understand what I'm
> doing, but I have already spent a long time trying to sort it out and I
> could really use some help with it.
>
> When I try readGDAL, it fails with the error that there are "no bands in
> dataset". This is the output I get from GDALinfo:
>
>> GDALinfo(fname)
> rows ? ? ? ?512
> columns ? ? 512
> bands ? ? ? 0
> origin.x ? ? ? ?0
> origin.y ? ? ? ?1
> res.x ? ? ? 1
> res.y ? ? ? 1
> oblique.x ? 0
> oblique.y ? 0
> driver ? ? ?netCDF
> projection ?NA
>
> Warning messages:
> 1: In dim(x) : no bands in dataset
> 2: In GDALinfo(fname) : no bands in dataset
>
>
>
> But from opening the file with Panoply, it seems it actually contains four
> variables, two of them 360*180 matrices with the geographical info I'm
> trying to access (global data with 1 degree spatial resolution), and the two
> others called "lat" and "lon" with the latitude and longitude values.
>
> I don't understand why GDALinfo is telling me that the file has 512 rows and
> 512 columns and that there are "no bands". What can I do to access the
> variables I want?
>
> Any help would be greatly appreciated!
> Elena
> --
> View this message in context: http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4064987.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From mdsumner at gmail.com  Wed Nov 25 21:30:39 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 26 Nov 2009 07:30:39 +1100
Subject: [R-sig-Geo] problem reading netcdf file with readGDAL: "no
	bands in dataset"
In-Reply-To: <522664f80911251227l14d79e36qbac8f16723c1bb30@mail.gmail.com>
References: <1259156071208-4064987.post@n2.nabble.com>
	<522664f80911251227l14d79e36qbac8f16723c1bb30@mail.gmail.com>
Message-ID: <522664f80911251230l5664304di7ea2c8cc78f66fdf@mail.gmail.com>

See this page for more information about the GDAL approach to NetCDF:
http://www.gdal.org/frmt_netcdf.html

If you can construct the subdataset name correctly then readGDAL
should be able to return the given variable, as a single band
SpatialGridDataFrame.



On Thu, Nov 26, 2009 at 7:27 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> There are a number of reasons why GDAL might not be able to read data
> from NetCDF, although it might appear to get some metadata upfront.
> The 512x512 thing is a default, and to me means that there are
> multiple variables in the file, and GDAL requires direct reference to
> only one of them as a "subdataset". The syntax is something like this:
>
> NETCDF:"/path/to/filename.nc":varname
>
> If you use gdalinfo at the command line it will tell you the
> subdataset strings you can use - the rgdal bindings don't reconstruct
> the output that that utility gives you.
>
> Cheers, Mike.
>
> On Thu, Nov 26, 2009 at 12:34 AM, ElenaC <E.Couce.07 at bristol.ac.uk> wrote:
>>
>> Hi all,
>>
>> I'm trying to open a netcdf file using the rgdal library, but readGDAL and
>> GDALinfo don't seem to be able to correctly access the information in the
>> file. It is probably a stupid mistake because I don't understand what I'm
>> doing, but I have already spent a long time trying to sort it out and I
>> could really use some help with it.
>>
>> When I try readGDAL, it fails with the error that there are "no bands in
>> dataset". This is the output I get from GDALinfo:
>>
>>> GDALinfo(fname)
>> rows ? ? ? ?512
>> columns ? ? 512
>> bands ? ? ? 0
>> origin.x ? ? ? ?0
>> origin.y ? ? ? ?1
>> res.x ? ? ? 1
>> res.y ? ? ? 1
>> oblique.x ? 0
>> oblique.y ? 0
>> driver ? ? ?netCDF
>> projection ?NA
>>
>> Warning messages:
>> 1: In dim(x) : no bands in dataset
>> 2: In GDALinfo(fname) : no bands in dataset
>>
>>
>>
>> But from opening the file with Panoply, it seems it actually contains four
>> variables, two of them 360*180 matrices with the geographical info I'm
>> trying to access (global data with 1 degree spatial resolution), and the two
>> others called "lat" and "lon" with the latitude and longitude values.
>>
>> I don't understand why GDALinfo is telling me that the file has 512 rows and
>> 512 columns and that there are "no bands". What can I do to access the
>> variables I want?
>>
>> Any help would be greatly appreciated!
>> Elena
>> --
>> View this message in context: http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4064987.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From xgiam at princeton.edu  Thu Nov 26 06:35:44 2009
From: xgiam at princeton.edu (Xingli Giam)
Date: Thu, 26 Nov 2009 00:35:44 -0500
Subject: [R-sig-Geo] Converting nb list containing areas with no
	neighbours with nb2WB()
In-Reply-To: <alpine.LRH.2.00.0911251216330.9258@reclus.nhh.no>
References: <000001ca6da6$926aec40$b740c4c0$@edu>
	<1259137639.3210.11.camel@Virgilio-Gomez>
	<000c01ca6db7$998fa090$ccaee1b0$@edu>
	<alpine.LRH.2.00.0911251216330.9258@reclus.nhh.no>
Message-ID: <009d01ca6e5a$4d9c4780$e8d4d680$@edu>

Hi Roger, your patch is excellent! Thank you for your help!

Your patch works fine with WinBUGS and I attempted to adapt it to the
listw2WB() function. It works well so far.

listw2WB <- function (listw)
{
    if (!inherits(listw, "listw"))
        stop("not listw class object")
    num <- card(listw$neighbours)
    if (any(num == 0)) listw$neighbours[num == 0] <- NULL
    adj <- unlist(listw$neighbours)
    weights <- unlist(listw$weights)
    list(adj = adj, weights = weights, num = num)
}

Thanks, Roger and Virgilio, for your timely advice!

Best regards,
Xingli

-----Original Message-----
From: Roger Bivand [mailto:Roger.Bivand at nhh.no] 
Sent: Wednesday, 25 November, 2009 6:20 AM
To: Xingli Giam
Cc: 'Virgilio G?mez-Rubio'; R-sig-Geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] Converting nb list containing areas with no
neighbours with nb2WB()

On Wed, 25 Nov 2009, Xingli Giam wrote:

> Hi Virgilio,
>
> Thank you for your clear and very quick reply. I really appreciate your
help
> in looking at my data.

The problem is caused by the nb object encoding no-neighbour status with 
an integer vector of length 1 containing 0. Please try this patched 
version:

nb2WB <- function(nb)
{
   	if (!inherits(nb, "nb")) stop("not a neighbours list")
         num <- card(nb)
         if (any(num == 0)) nb[num == 0] <- NULL
         adj <- unlist(nb)
         weights <- rep(1, sum(num))

         list(adj=adj, weights=weights, num=num)
}

It works for me so far, and num now contains the correct 0 for observation 
233. I haven't tried it with WinBUGS though.

Hope this helps,

Roger

>
> Here is my data and code, I hope it will be clear enough for you:
>
> rm(list=ls())
>
> library(spdep)
> library(R2WinBUGS)
>
> S <- c(66.666667,  40.000000,  50.000000,  56.666667, 250.000000,
> 66.666667, 183.333333,  50.000000,   7.000000, 106.666667,  90.000000,
> 83.333333, 100.000000,
> 5.500000, 146.666667, 100.000000, 160.000000,  70.000000, 160.000000,
> 183.333333,  70.000000, 133.333333, 130.000000,  73.333333,  93.333333,
> 31.666667,
> 183.333333, 116.666667, 116.666667, 200.000000, 110.000000, 120.000000,
> 50.000000,  70.000000, 133.333333, 133.333333, 106.666667,  66.666667,
> 106.666667,
> 133.333333,   9.333333,  90.000000,  33.333333,  66.666667, 200.000000,
> 106.666667,  90.000000,  31.666667, 110.000000,  50.000000, 100.000000,
> 120.000000,
> 110.000000, 136.666667,  31.666667,  93.333333,  70.000000, 110.000000,
> 60.900000, 333.333333, 133.333333,  83.333333,  83.333333, 100.000000,
> 36.666667,
> 66.666667,  86.666667,   7.333333,  53.333333,  50.000000,  96.666667,
> 100.000000,  60.000000,  33.333333,  60.000000, 183.333333, 133.333333,
> 116.666667,
> 126.666667,  50.000000, 166.666667,  50.000000,  12.666667, 100.000000,
> 50.000000,  66.666667, 143.333333,  83.333333, 126.666667,  73.333333,
> 45.966667,
> 76.666667,  93.333333, 100.000000, 233.333333,  50.000000,  76.666667,
> 116.666667,  93.333333,  46.666667,  90.000000, 106.666667,  36.666667,
> 233.333333,
> 26.666667,  13.333333, 216.666667,  76.666667, 110.000000, 133.333333,
> 46.666667,  66.666667,  73.333333,  46.666667,  53.333333, 250.000000,
> 116.666667,
> 66.666667,  53.333333,  26.666667, 133.333333,  26.666667,  23.333333,
> 70.000000,  66.666667, 116.666667, 100.000000,  66.666667,  90.000000,
> 100.000000,
> 150.000000,  50.000000, 166.666667, 200.000000, 200.000000,  50.000000,
> 300.000000,  63.333333, 150.000000,  11.666667, 136.666667, 116.666667,
> 126.666667,
> 83.333333, 300.000000,  10.666667, 123.333333, 183.333333, 110.000000,
> 116.666667, 216.666667, 110.000000,   2.666667, 266.666667, 266.666667,
> 83.333333,
> 126.666667, 106.666667, 266.666667, 216.666667,  93.333333, 266.666667,
> 166.666667,  50.000000, 200.000000, 183.333333, 150.000000, 116.666667,
> 106.666667,
> 133.333333, 150.000000, 233.333333, 216.666667,  33.333333, 216.666667,
> 106.666667,  56.666667,  63.333333,  23.333333, 216.666667, 100.000000,
> 83.333333,
> 216.666667, 216.666667,  60.000000, 166.666667, 166.666667, 100.000000,
> 53.333333, 300.000000,  91.666667, 136.666667, 233.333333,  34.466667,
> 116.666667,
> 283.333333, 283.333333, 166.666667,  96.666667, 150.000000,  70.000000,
> 4.000000, 216.666667, 135.000000, 150.000000, 200.000000,  90.000000,
> 176.666667,
> 53.333333, 166.666667,  53.333333,  60.000000,  38.333333,   1.666667,
> 4.333333,   3.666667,  48.333333,  31.166667,   3.766667,  10.600000,
> 16.666667,
>  5.833333,   1.000000,  25.833333,  20.766667,  16.000000,   4.666667,
> 5.000000,   1.666667, 116.666667, 200.000000)
>
> A <- c(
>   233.222222,   832.888889,   312.222222,   954.000000, 19025.555556,
> 2971.666667,  1827.777778,   267.444444,     1.555556,   178.666667,
> 3879.555556,
>  1342.333333,  1613.666667,     4.666667, 14959.555556,  2576.000000,
> 3621.777778,  2141.777778,  3966.666667,  8559.333333, 11054.777778,
> 13593.111111,
> 12867.777778,  8385.777778,   464.444444,  1461.777778,  2427.888889,
> 8562.222222, 11489.333333, 20980.111111,  4208.777778, 45875.777778,
> 228.555556,
>  2292.111111,  5760.000000,  7244.333333,  2617.333333, 10257.222222,
> 20988.333333, 27526.000000,    34.444444,  3436.000000,   340.111111,
> 1975.444444,
> 12417.777778, 22108.000000,  3349.555556,   548.000000,   126.777778,
> 1593.666667,  7449.222222, 59007.444444, 12461.222222, 48021.111111,
> 114.666667,
> 16273.666667, 14228.888889, 22691.777778,   632.888889, 47287.000000,
> 12786.444444,  7463.555556,  6290.333333,  4897.111111,  4317.555556,
> 2259.666667,
>  3290.777778,    14.888889, 37796.777778,  1758.777778,  5962.888889,
> 3872.888889,  4236.111111,  1678.555556, 15323.333333, 73588.000000,
> 13239.777778,
> 28167.666667,  7953.888889,   919.222222, 10541.888889,  3925.666667,
> 60.222222,  4625.444444,   718.888889,  2013.333333, 11629.666667,
> 1119.888889,
> 15027.222222,  7370.222222,   187.555556,  5338.222222,  3425.000000,
> 5228.111111, 48429.888889,  1866.000000,  4667.777778,  5974.888889,
> 2502.444444,
>  2469.777778,  1586.444444,  1899.666667,   401.111111, 13882.666667,
> 1191.555556,     3.444444, 24858.222222,  2630.666667,  2505.000000,
> 5146.000000,
>  4067.000000,  1388.888889,   340.666667,   258.444444,  1999.444444,
> 28698.666667,  8068.666667,  9680.000000,  8467.222222,  1613.888889,
> 10770.000000,
>  2880.666667,  3251.333333, 29182.555556,  2907.888889,  4609.000000,
> 1721.000000,   451.555556,   285.555556,  3702.444444, 23963.666667,
> 872.222222,
> 12145.000000, 25471.222222, 10025.444444,   530.666667, 20373.111111,
> 2528.111111,  3546.111111,    10.555556,  9938.888889,  1472.333333,
> 639.888889,
>   230.777778,  8145.000000,     2.777778,  1586.888889,  7508.555556,
> 1211.111111,  2371.000000, 11340.222222,   336.777778,     2.111111,
> 16218.111111,
> 52904.000000,  1097.888889,  5090.444444, 12722.888889,  6484.333333,
> 3241.777778,   918.888889, 29827.111111, 26832.555556,   109.555556,
> 79631.333333,
> 11622.000000,  8493.333333,  9811.666667, 15737.222222, 45812.666667,
> 7389.555556, 27843.444444, 22325.777778,  1112.333333,  8978.444444,
> 841.888889,
>  3114.222222,  1905.888889,   854.444444, 53653.222222,  1944.666667,
> 2510.777778, 20662.333333, 16510.555556,   833.777778, 19640.000000,
> 19251.222222,
> 10665.111111,   529.555556, 11623.333333,   432.222222,  1246.444444,
> 18547.888889,   230.111111,  8350.000000, 82961.444444,  1808.222222,
> 37233.222222,
>  5630.555556, 21418.444444,   524.666667,     1.000000, 52227.555556,
> 12715.888889,  3252.111111,  7660.666667,   549.111111,  3772.666667,
> 223.777778,
> 29452.444444,  7720.222222, 25537.333333,    64.222222,    68.000000,
> 23.555556,    59.000000,  1285.777778,   746.444444,     3.777778,
> 119.333333,
>    10.666667,    51.111111,    19.777778,   342.555556,   180.000000,
> 104.222222,   104.777778,    15.777778,    10.333333, 29903.555556,
> 26650.444444)
>
> x_long <- c(
> 146.97,  131.53,  135.88,  126.63,  140.71,  128.14,  146.65,  136.08,
> 159.09,  153.49,  151.11,  151.42,  165.57,  167.95,  143.25,  139.42,
> 145.73,  129.35,  155.24,
> 148.32,  138.58,  140.60,  121.05,  120.12,  151.03,  166.70,  133.12,
> 134.16,   29.68,   11.29,   10.20,   21.04,   44.25,    7.41,    8.59,
> 35.30,   35.83,   21.10,
>  -2.71,   38.95,   55.46,  -12.15,   23.37,   30.48,   48.59,   47.03,
> 32.74,   55.55,    9.16,    6.47,    4.66,   24.46,   39.59,   14.95,
> 6.54,   40.02,   17.02,
>  -9.93,   92.81,  112.82,  113.89,  111.30,   94.31,  102.97,  100.65,
> 99.71,   93.96,  105.69,   81.42,  113.36,  112.43,  122.98,   82.27,
> 95.66,   96.06,  114.19,
>  98.13,   87.67,  101.55,  122.25,  122.08,   74.89,  120.18,   91.87,
> 98.94,  124.72,  125.83,  120.94,   92.82,   96.22,   93.32,   73.53,
> 73.95,  105.21,  100.91,
> 102.69,  100.95,   96.88,  105.81,   85.78,  119.01,  101.41,  103.31,
> 102.28,  105.82,  115.83,  108.12,   77.03,   76.73,  107.36,  116.59,
> 80.19,   80.83,  120.00,
> 101.54,  101.05,  100.22,  102.84,  116.12,   89.33,   99.11,  104.90,
> 105.10,   80.75,  108.34,  109.41,  109.65,  127.98,  120.62,  121.03,
> -51.31,  -50.19,  -39.70,
> -41.85,  -66.43,  -40.89,  -72.04,  -72.66,  -76.01,  -81.70,  -84.67,
> -89.61,  -92.80,  -94.19,  -76.97,  -87.06,  -66.22,  -72.12,  -84.96,
> -75.44,  -78.26,  -77.38,
> -32.44,  -63.22,  -56.99,  -53.74,  -70.09,  -74.28,  -83.65,  -82.28,
> -77.28,  -65.21,  -66.22,  -61.67,  -60.03,  -74.50,  -75.10,  -50.51,
> -43.91,  -52.68,  -61.65,
> -75.73,  -66.26,  -42.98,  -77.11,  -96.74,  -61.10,  -92.28,  -55.58,
> -52.62,  -35.72,  -36.34,  -73.49,  -90.33,  -66.34,  -69.45,  -63.36,
> -68.78,  -73.89,  -48.74,
> -94.94,  -92.28,  -70.32,  -80.39,  -64.96,  -69.17,  -82.77,  -54.90,
> -65.46,  -47.11,  -61.21,  -30.32,  -56.78,  -76.19,  -70.41,  -98.21,
> -98.39,  -79.52,  -61.03,
> -50.30,  -89.02,  -63.97,  158.22, -157.66, -159.77,  173.02,  179.31,
> -155.31, -177.93, -138.98,  142.15,  134.56, -109.34, -172.48, -149.38,
> -175.20, -146.36, -144.36,
> -171.63,  107.97,  102.87)
>
>
> y_lat <- c(
> -2.10,  -7.56,  -0.92,  -3.49,  -5.21,   0.65,  -6.08,  -1.72, -31.56,
> -11.48,  -5.22,  -5.48, -21.31, -29.04,  -4.28,  -2.79, -17.47,  -3.33,
> -5.94,  -8.72,  -7.48,
> -6.23,  -1.97,  -2.42,  -9.95, -15.14,  -1.04,  -2.46,  -1.93,  -0.75,
> 5.64,  -1.17, -12.18,   5.53,   5.07,   0.00,  -8.26,  -0.30,   7.61,
> 13.13,  -4.67,  11.23,
> -33.98, -30.38, -19.27, -18.60, -26.36, -21.11,   4.23,   5.17,   6.78,
> 0.96,  -3.94,   1.01,   0.13, -13.60,   0.43,   7.18,  12.53,   1.49,
> 2.07,   2.04,  26.93,
> 11.69,  15.11,  14.32,  21.29, -10.45,  19.93,  -8.02,  -7.59,  10.02,
> 28.07,  16.88,  20.26,  26.03,  17.76,  24.04,  18.06,  16.82,  16.61,
> 13.19,  13.77,  25.79,
> -1.36,   7.89,   7.69,  12.68,  22.26,  18.72,   8.00,  17.17,  16.39,
> 17.75,  23.05,  17.75,  18.58,  26.34,  18.34,  20.23,  10.07,   4.62,
> 3.11,   4.08,  20.86,
> 10.72,  22.15,  10.54,  10.63,  15.23,   0.42,   6.78,   6.98,   5.20,
> 0.33,  -0.13,  -0.09,  -0.57,   0.05,  22.68,  11.11,  11.68,  10.34,
> 27.65,  -7.10,  -6.95,
> 19.56,  26.48,  22.38,  23.89, -26.65, -30.05, -16.45, -16.90, -15.69,
> -3.96,   0.64,   8.80,   4.84,  12.54,  14.05,  15.18,  17.09,  16.65,
> 5.51,   5.53,   9.99,
>  6.26,  10.43,  20.42,  -2.04,   8.34,  -3.86,   4.00,   4.89,  -2.00,
> 19.09,  -5.35,  10.22,   8.52,  18.18,  -0.54,  -5.88,  16.16,  -8.90,
> 5.38,   7.75,  -1.12,
> -4.26, -10.02,  -6.00,  -1.52,   1.89,  -2.75,   2.51,  17.82,   9.06,
> 18.16,   5.72, -23.25,  -8.73,  -8.79, -11.89,  17.10,  18.24,  -3.99,
> -6.58,   0.81,  10.74,
> -25.75,  18.34,  15.15,  -2.28,  25.66, -23.59, -10.48,   9.11,  -6.16,
> 5.63,  -3.04,  10.69, -20.50,  -0.20,  -7.38,   8.80,  21.79,  20.64,
> -0.53,  14.66,  -5.78,
> 19.67,   3.79,   6.88,   1.88, -21.23,   1.83, -16.58,  19.77, -29.27,
> -9.78,  26.66,   7.53, -27.13, -13.62, -17.69, -21.17, -16.18, -27.61,
> -2.82,  27.93,  26.11)
>
> coords <- cbind(x_long, y_lat)
>
> nb2000 <- dnearneigh(coords, 0, 2000, longlat=T)
> nb2000weights <- nb2WB(nb2000)
>
> # find zero integer value in nb2000weights adj matrix
> zero.int <- (1:length(nb2000weights$adj))[nb2000weights$adj==0]
> zero.int
>
> # testing if nb2000weights adj and weights matrix is of the same length (#
> Yes)
> length(nb2000weights$adj)
> length(nb2000weights$weights)
>
> N=length(A)
>
> d <-  list(sp = S, area_km2 = A, N=N, adj=nb2000weights$adj,
> weights=nb2000weights$weights, num=nb2000weights$num)
>
> init1 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
> init2 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
> init3 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
> inits = list(init1,init2,init3)
>
> powerdat1lg.bugs <- bugs(data=d, inits,
> model.file="C:/WinBUGS/CARlogcodes/powerbuglnorm.txt",
> parameters = c("c", "z", "sp.rep", "b"),
> n.chains =3, n.iter = 32500, n.burnin = 7500, n.sims=3000,
> bugs.directory ="c:/Program Files/WinBUGS14/", debug=T)
>
> ____________________________________________
>
> Here is my WinBUGS model file code
> "C:/WinBUGS/CARlogcodes/powerbuglnorm.txt":
>
> model
> {
>
> 	for (i in 1:N) # for each ecoreg in biome 1
> 	{
>
> 	S[i] <- c*(pow(area_km2[i] , z)) + b[i]
>
> 	logS[i] <- log(max(0.001,S[i]))
>
> 	sp[i] ~ dlnorm(logS[i],prec)
>
> 	sp.rep [i] <- max(0.001, (c*pow(area_km2[i],z) + b[i]))
>
> 	}
>
> 	# CAR prior distribution for random effects
>
> 	b[1:N] ~ car.normal(adj[], weights[], num[], tau)
>
> 	c ~ dnorm(0,0.0000001)I(0,)
>
> 	z ~ dnorm(0,0.0000001)I(0,)
>
> 	prec ~ dgamma(0.001,0.001)
>
> 	tau ~ dgamma(0.001,0.001)
>
> 	}
>
> Many thanks,
> Xingli
>
>
> -----Original Message-----
> From: Virgilio G?mez-Rubio [mailto:Virgilio.Gomez at uclm.es]
> Sent: Wednesday, 25 November, 2009 3:27 AM
> To: Xingli Giam
> Cc: R-sig-Geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Converting nb list containing areas with no
> neighbours with nb2WB()
>
> Hi,
>
>
>> I checked the adjacency matrix of the spatial weights list output object,
>> and a zero integer was placed at the position corresponding to the area
> with
>> no neighbours.
>
> Yes. Probably we need to fix this so that nothing is added when an area
> has no neighbours.
>
>> When I re-ran the analysis after I changed my neighbourhood structure
such
>> that all areas had neighbours, the WinBUGS simulation ran fine.
>>
>> Is there a way to format the spatial weights list object via nb2WB() in a
>> way that allows WinBUGS to read cases with no neighbours?
>
> It should be done automatically, but probably we forgot to consider the
> case of areas with no neighbours.
>
> Could it be possible to see the map that you are using? I'd say that
> there is a mismatch between the number of neighbours and the number of
> weights, but I would need to check with you data and code.
>
>
> Best wishes,
>
> Virgilio
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Nov 26 08:45:13 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Nov 2009 08:45:13 +0100 (CET)
Subject: [R-sig-Geo] Converting nb list containing areas with no
 neighbours with nb2WB()
In-Reply-To: <009d01ca6e5a$4d9c4780$e8d4d680$@edu>
References: <000001ca6da6$926aec40$b740c4c0$@edu>
	<1259137639.3210.11.camel@Virgilio-Gomez>
	<000c01ca6db7$998fa090$ccaee1b0$@edu>
	<alpine.LRH.2.00.0911251216330.9258@reclus.nhh.no>
	<009d01ca6e5a$4d9c4780$e8d4d680$@edu>
Message-ID: <alpine.LRH.2.00.0911260844270.12894@reclus.nhh.no>

On Thu, 26 Nov 2009, Xingli Giam wrote:

> Hi Roger, your patch is excellent! Thank you for your help!

Thanks, new release on its way to CRAN.

Roger

>
> Your patch works fine with WinBUGS and I attempted to adapt it to the
> listw2WB() function. It works well so far.
>
> listw2WB <- function (listw)
> {
>    if (!inherits(listw, "listw"))
>        stop("not listw class object")
>    num <- card(listw$neighbours)
>    if (any(num == 0)) listw$neighbours[num == 0] <- NULL
>    adj <- unlist(listw$neighbours)
>    weights <- unlist(listw$weights)
>    list(adj = adj, weights = weights, num = num)
> }
>
> Thanks, Roger and Virgilio, for your timely advice!
>
> Best regards,
> Xingli
>
> -----Original Message-----
> From: Roger Bivand [mailto:Roger.Bivand at nhh.no]
> Sent: Wednesday, 25 November, 2009 6:20 AM
> To: Xingli Giam
> Cc: 'Virgilio G?mez-Rubio'; R-sig-Geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Converting nb list containing areas with no
> neighbours with nb2WB()
>
> On Wed, 25 Nov 2009, Xingli Giam wrote:
>
>> Hi Virgilio,
>>
>> Thank you for your clear and very quick reply. I really appreciate your
> help
>> in looking at my data.
>
> The problem is caused by the nb object encoding no-neighbour status with
> an integer vector of length 1 containing 0. Please try this patched
> version:
>
> nb2WB <- function(nb)
> {
>   	if (!inherits(nb, "nb")) stop("not a neighbours list")
>         num <- card(nb)
>         if (any(num == 0)) nb[num == 0] <- NULL
>         adj <- unlist(nb)
>         weights <- rep(1, sum(num))
>
>         list(adj=adj, weights=weights, num=num)
> }
>
> It works for me so far, and num now contains the correct 0 for observation
> 233. I haven't tried it with WinBUGS though.
>
> Hope this helps,
>
> Roger
>
>>
>> Here is my data and code, I hope it will be clear enough for you:
>>
>> rm(list=ls())
>>
>> library(spdep)
>> library(R2WinBUGS)
>>
>> S <- c(66.666667,  40.000000,  50.000000,  56.666667, 250.000000,
>> 66.666667, 183.333333,  50.000000,   7.000000, 106.666667,  90.000000,
>> 83.333333, 100.000000,
>> 5.500000, 146.666667, 100.000000, 160.000000,  70.000000, 160.000000,
>> 183.333333,  70.000000, 133.333333, 130.000000,  73.333333,  93.333333,
>> 31.666667,
>> 183.333333, 116.666667, 116.666667, 200.000000, 110.000000, 120.000000,
>> 50.000000,  70.000000, 133.333333, 133.333333, 106.666667,  66.666667,
>> 106.666667,
>> 133.333333,   9.333333,  90.000000,  33.333333,  66.666667, 200.000000,
>> 106.666667,  90.000000,  31.666667, 110.000000,  50.000000, 100.000000,
>> 120.000000,
>> 110.000000, 136.666667,  31.666667,  93.333333,  70.000000, 110.000000,
>> 60.900000, 333.333333, 133.333333,  83.333333,  83.333333, 100.000000,
>> 36.666667,
>> 66.666667,  86.666667,   7.333333,  53.333333,  50.000000,  96.666667,
>> 100.000000,  60.000000,  33.333333,  60.000000, 183.333333, 133.333333,
>> 116.666667,
>> 126.666667,  50.000000, 166.666667,  50.000000,  12.666667, 100.000000,
>> 50.000000,  66.666667, 143.333333,  83.333333, 126.666667,  73.333333,
>> 45.966667,
>> 76.666667,  93.333333, 100.000000, 233.333333,  50.000000,  76.666667,
>> 116.666667,  93.333333,  46.666667,  90.000000, 106.666667,  36.666667,
>> 233.333333,
>> 26.666667,  13.333333, 216.666667,  76.666667, 110.000000, 133.333333,
>> 46.666667,  66.666667,  73.333333,  46.666667,  53.333333, 250.000000,
>> 116.666667,
>> 66.666667,  53.333333,  26.666667, 133.333333,  26.666667,  23.333333,
>> 70.000000,  66.666667, 116.666667, 100.000000,  66.666667,  90.000000,
>> 100.000000,
>> 150.000000,  50.000000, 166.666667, 200.000000, 200.000000,  50.000000,
>> 300.000000,  63.333333, 150.000000,  11.666667, 136.666667, 116.666667,
>> 126.666667,
>> 83.333333, 300.000000,  10.666667, 123.333333, 183.333333, 110.000000,
>> 116.666667, 216.666667, 110.000000,   2.666667, 266.666667, 266.666667,
>> 83.333333,
>> 126.666667, 106.666667, 266.666667, 216.666667,  93.333333, 266.666667,
>> 166.666667,  50.000000, 200.000000, 183.333333, 150.000000, 116.666667,
>> 106.666667,
>> 133.333333, 150.000000, 233.333333, 216.666667,  33.333333, 216.666667,
>> 106.666667,  56.666667,  63.333333,  23.333333, 216.666667, 100.000000,
>> 83.333333,
>> 216.666667, 216.666667,  60.000000, 166.666667, 166.666667, 100.000000,
>> 53.333333, 300.000000,  91.666667, 136.666667, 233.333333,  34.466667,
>> 116.666667,
>> 283.333333, 283.333333, 166.666667,  96.666667, 150.000000,  70.000000,
>> 4.000000, 216.666667, 135.000000, 150.000000, 200.000000,  90.000000,
>> 176.666667,
>> 53.333333, 166.666667,  53.333333,  60.000000,  38.333333,   1.666667,
>> 4.333333,   3.666667,  48.333333,  31.166667,   3.766667,  10.600000,
>> 16.666667,
>>  5.833333,   1.000000,  25.833333,  20.766667,  16.000000,   4.666667,
>> 5.000000,   1.666667, 116.666667, 200.000000)
>>
>> A <- c(
>>   233.222222,   832.888889,   312.222222,   954.000000, 19025.555556,
>> 2971.666667,  1827.777778,   267.444444,     1.555556,   178.666667,
>> 3879.555556,
>>  1342.333333,  1613.666667,     4.666667, 14959.555556,  2576.000000,
>> 3621.777778,  2141.777778,  3966.666667,  8559.333333, 11054.777778,
>> 13593.111111,
>> 12867.777778,  8385.777778,   464.444444,  1461.777778,  2427.888889,
>> 8562.222222, 11489.333333, 20980.111111,  4208.777778, 45875.777778,
>> 228.555556,
>>  2292.111111,  5760.000000,  7244.333333,  2617.333333, 10257.222222,
>> 20988.333333, 27526.000000,    34.444444,  3436.000000,   340.111111,
>> 1975.444444,
>> 12417.777778, 22108.000000,  3349.555556,   548.000000,   126.777778,
>> 1593.666667,  7449.222222, 59007.444444, 12461.222222, 48021.111111,
>> 114.666667,
>> 16273.666667, 14228.888889, 22691.777778,   632.888889, 47287.000000,
>> 12786.444444,  7463.555556,  6290.333333,  4897.111111,  4317.555556,
>> 2259.666667,
>>  3290.777778,    14.888889, 37796.777778,  1758.777778,  5962.888889,
>> 3872.888889,  4236.111111,  1678.555556, 15323.333333, 73588.000000,
>> 13239.777778,
>> 28167.666667,  7953.888889,   919.222222, 10541.888889,  3925.666667,
>> 60.222222,  4625.444444,   718.888889,  2013.333333, 11629.666667,
>> 1119.888889,
>> 15027.222222,  7370.222222,   187.555556,  5338.222222,  3425.000000,
>> 5228.111111, 48429.888889,  1866.000000,  4667.777778,  5974.888889,
>> 2502.444444,
>>  2469.777778,  1586.444444,  1899.666667,   401.111111, 13882.666667,
>> 1191.555556,     3.444444, 24858.222222,  2630.666667,  2505.000000,
>> 5146.000000,
>>  4067.000000,  1388.888889,   340.666667,   258.444444,  1999.444444,
>> 28698.666667,  8068.666667,  9680.000000,  8467.222222,  1613.888889,
>> 10770.000000,
>>  2880.666667,  3251.333333, 29182.555556,  2907.888889,  4609.000000,
>> 1721.000000,   451.555556,   285.555556,  3702.444444, 23963.666667,
>> 872.222222,
>> 12145.000000, 25471.222222, 10025.444444,   530.666667, 20373.111111,
>> 2528.111111,  3546.111111,    10.555556,  9938.888889,  1472.333333,
>> 639.888889,
>>   230.777778,  8145.000000,     2.777778,  1586.888889,  7508.555556,
>> 1211.111111,  2371.000000, 11340.222222,   336.777778,     2.111111,
>> 16218.111111,
>> 52904.000000,  1097.888889,  5090.444444, 12722.888889,  6484.333333,
>> 3241.777778,   918.888889, 29827.111111, 26832.555556,   109.555556,
>> 79631.333333,
>> 11622.000000,  8493.333333,  9811.666667, 15737.222222, 45812.666667,
>> 7389.555556, 27843.444444, 22325.777778,  1112.333333,  8978.444444,
>> 841.888889,
>>  3114.222222,  1905.888889,   854.444444, 53653.222222,  1944.666667,
>> 2510.777778, 20662.333333, 16510.555556,   833.777778, 19640.000000,
>> 19251.222222,
>> 10665.111111,   529.555556, 11623.333333,   432.222222,  1246.444444,
>> 18547.888889,   230.111111,  8350.000000, 82961.444444,  1808.222222,
>> 37233.222222,
>>  5630.555556, 21418.444444,   524.666667,     1.000000, 52227.555556,
>> 12715.888889,  3252.111111,  7660.666667,   549.111111,  3772.666667,
>> 223.777778,
>> 29452.444444,  7720.222222, 25537.333333,    64.222222,    68.000000,
>> 23.555556,    59.000000,  1285.777778,   746.444444,     3.777778,
>> 119.333333,
>>    10.666667,    51.111111,    19.777778,   342.555556,   180.000000,
>> 104.222222,   104.777778,    15.777778,    10.333333, 29903.555556,
>> 26650.444444)
>>
>> x_long <- c(
>> 146.97,  131.53,  135.88,  126.63,  140.71,  128.14,  146.65,  136.08,
>> 159.09,  153.49,  151.11,  151.42,  165.57,  167.95,  143.25,  139.42,
>> 145.73,  129.35,  155.24,
>> 148.32,  138.58,  140.60,  121.05,  120.12,  151.03,  166.70,  133.12,
>> 134.16,   29.68,   11.29,   10.20,   21.04,   44.25,    7.41,    8.59,
>> 35.30,   35.83,   21.10,
>>  -2.71,   38.95,   55.46,  -12.15,   23.37,   30.48,   48.59,   47.03,
>> 32.74,   55.55,    9.16,    6.47,    4.66,   24.46,   39.59,   14.95,
>> 6.54,   40.02,   17.02,
>>  -9.93,   92.81,  112.82,  113.89,  111.30,   94.31,  102.97,  100.65,
>> 99.71,   93.96,  105.69,   81.42,  113.36,  112.43,  122.98,   82.27,
>> 95.66,   96.06,  114.19,
>>  98.13,   87.67,  101.55,  122.25,  122.08,   74.89,  120.18,   91.87,
>> 98.94,  124.72,  125.83,  120.94,   92.82,   96.22,   93.32,   73.53,
>> 73.95,  105.21,  100.91,
>> 102.69,  100.95,   96.88,  105.81,   85.78,  119.01,  101.41,  103.31,
>> 102.28,  105.82,  115.83,  108.12,   77.03,   76.73,  107.36,  116.59,
>> 80.19,   80.83,  120.00,
>> 101.54,  101.05,  100.22,  102.84,  116.12,   89.33,   99.11,  104.90,
>> 105.10,   80.75,  108.34,  109.41,  109.65,  127.98,  120.62,  121.03,
>> -51.31,  -50.19,  -39.70,
>> -41.85,  -66.43,  -40.89,  -72.04,  -72.66,  -76.01,  -81.70,  -84.67,
>> -89.61,  -92.80,  -94.19,  -76.97,  -87.06,  -66.22,  -72.12,  -84.96,
>> -75.44,  -78.26,  -77.38,
>> -32.44,  -63.22,  -56.99,  -53.74,  -70.09,  -74.28,  -83.65,  -82.28,
>> -77.28,  -65.21,  -66.22,  -61.67,  -60.03,  -74.50,  -75.10,  -50.51,
>> -43.91,  -52.68,  -61.65,
>> -75.73,  -66.26,  -42.98,  -77.11,  -96.74,  -61.10,  -92.28,  -55.58,
>> -52.62,  -35.72,  -36.34,  -73.49,  -90.33,  -66.34,  -69.45,  -63.36,
>> -68.78,  -73.89,  -48.74,
>> -94.94,  -92.28,  -70.32,  -80.39,  -64.96,  -69.17,  -82.77,  -54.90,
>> -65.46,  -47.11,  -61.21,  -30.32,  -56.78,  -76.19,  -70.41,  -98.21,
>> -98.39,  -79.52,  -61.03,
>> -50.30,  -89.02,  -63.97,  158.22, -157.66, -159.77,  173.02,  179.31,
>> -155.31, -177.93, -138.98,  142.15,  134.56, -109.34, -172.48, -149.38,
>> -175.20, -146.36, -144.36,
>> -171.63,  107.97,  102.87)
>>
>>
>> y_lat <- c(
>> -2.10,  -7.56,  -0.92,  -3.49,  -5.21,   0.65,  -6.08,  -1.72, -31.56,
>> -11.48,  -5.22,  -5.48, -21.31, -29.04,  -4.28,  -2.79, -17.47,  -3.33,
>> -5.94,  -8.72,  -7.48,
>> -6.23,  -1.97,  -2.42,  -9.95, -15.14,  -1.04,  -2.46,  -1.93,  -0.75,
>> 5.64,  -1.17, -12.18,   5.53,   5.07,   0.00,  -8.26,  -0.30,   7.61,
>> 13.13,  -4.67,  11.23,
>> -33.98, -30.38, -19.27, -18.60, -26.36, -21.11,   4.23,   5.17,   6.78,
>> 0.96,  -3.94,   1.01,   0.13, -13.60,   0.43,   7.18,  12.53,   1.49,
>> 2.07,   2.04,  26.93,
>> 11.69,  15.11,  14.32,  21.29, -10.45,  19.93,  -8.02,  -7.59,  10.02,
>> 28.07,  16.88,  20.26,  26.03,  17.76,  24.04,  18.06,  16.82,  16.61,
>> 13.19,  13.77,  25.79,
>> -1.36,   7.89,   7.69,  12.68,  22.26,  18.72,   8.00,  17.17,  16.39,
>> 17.75,  23.05,  17.75,  18.58,  26.34,  18.34,  20.23,  10.07,   4.62,
>> 3.11,   4.08,  20.86,
>> 10.72,  22.15,  10.54,  10.63,  15.23,   0.42,   6.78,   6.98,   5.20,
>> 0.33,  -0.13,  -0.09,  -0.57,   0.05,  22.68,  11.11,  11.68,  10.34,
>> 27.65,  -7.10,  -6.95,
>> 19.56,  26.48,  22.38,  23.89, -26.65, -30.05, -16.45, -16.90, -15.69,
>> -3.96,   0.64,   8.80,   4.84,  12.54,  14.05,  15.18,  17.09,  16.65,
>> 5.51,   5.53,   9.99,
>>  6.26,  10.43,  20.42,  -2.04,   8.34,  -3.86,   4.00,   4.89,  -2.00,
>> 19.09,  -5.35,  10.22,   8.52,  18.18,  -0.54,  -5.88,  16.16,  -8.90,
>> 5.38,   7.75,  -1.12,
>> -4.26, -10.02,  -6.00,  -1.52,   1.89,  -2.75,   2.51,  17.82,   9.06,
>> 18.16,   5.72, -23.25,  -8.73,  -8.79, -11.89,  17.10,  18.24,  -3.99,
>> -6.58,   0.81,  10.74,
>> -25.75,  18.34,  15.15,  -2.28,  25.66, -23.59, -10.48,   9.11,  -6.16,
>> 5.63,  -3.04,  10.69, -20.50,  -0.20,  -7.38,   8.80,  21.79,  20.64,
>> -0.53,  14.66,  -5.78,
>> 19.67,   3.79,   6.88,   1.88, -21.23,   1.83, -16.58,  19.77, -29.27,
>> -9.78,  26.66,   7.53, -27.13, -13.62, -17.69, -21.17, -16.18, -27.61,
>> -2.82,  27.93,  26.11)
>>
>> coords <- cbind(x_long, y_lat)
>>
>> nb2000 <- dnearneigh(coords, 0, 2000, longlat=T)
>> nb2000weights <- nb2WB(nb2000)
>>
>> # find zero integer value in nb2000weights adj matrix
>> zero.int <- (1:length(nb2000weights$adj))[nb2000weights$adj==0]
>> zero.int
>>
>> # testing if nb2000weights adj and weights matrix is of the same length (#
>> Yes)
>> length(nb2000weights$adj)
>> length(nb2000weights$weights)
>>
>> N=length(A)
>>
>> d <-  list(sp = S, area_km2 = A, N=N, adj=nb2000weights$adj,
>> weights=nb2000weights$weights, num=nb2000weights$num)
>>
>> init1 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
>> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
>> init2 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
>> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
>> init3 = list(c=runif(1,0.5,1.5)*12, z=runif(1,0.5,1.5)*0.26,
>> prec=runif(1,0.01,100), tau=1, b=c(rep(0, N)))
>> inits = list(init1,init2,init3)
>>
>> powerdat1lg.bugs <- bugs(data=d, inits,
>> model.file="C:/WinBUGS/CARlogcodes/powerbuglnorm.txt",
>> parameters = c("c", "z", "sp.rep", "b"),
>> n.chains =3, n.iter = 32500, n.burnin = 7500, n.sims=3000,
>> bugs.directory ="c:/Program Files/WinBUGS14/", debug=T)
>>
>> ____________________________________________
>>
>> Here is my WinBUGS model file code
>> "C:/WinBUGS/CARlogcodes/powerbuglnorm.txt":
>>
>> model
>> {
>>
>> 	for (i in 1:N) # for each ecoreg in biome 1
>> 	{
>>
>> 	S[i] <- c*(pow(area_km2[i] , z)) + b[i]
>>
>> 	logS[i] <- log(max(0.001,S[i]))
>>
>> 	sp[i] ~ dlnorm(logS[i],prec)
>>
>> 	sp.rep [i] <- max(0.001, (c*pow(area_km2[i],z) + b[i]))
>>
>> 	}
>>
>> 	# CAR prior distribution for random effects
>>
>> 	b[1:N] ~ car.normal(adj[], weights[], num[], tau)
>>
>> 	c ~ dnorm(0,0.0000001)I(0,)
>>
>> 	z ~ dnorm(0,0.0000001)I(0,)
>>
>> 	prec ~ dgamma(0.001,0.001)
>>
>> 	tau ~ dgamma(0.001,0.001)
>>
>> 	}
>>
>> Many thanks,
>> Xingli
>>
>>
>> -----Original Message-----
>> From: Virgilio G?mez-Rubio [mailto:Virgilio.Gomez at uclm.es]
>> Sent: Wednesday, 25 November, 2009 3:27 AM
>> To: Xingli Giam
>> Cc: R-sig-Geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] Converting nb list containing areas with no
>> neighbours with nb2WB()
>>
>> Hi,
>>
>>
>>> I checked the adjacency matrix of the spatial weights list output object,
>>> and a zero integer was placed at the position corresponding to the area
>> with
>>> no neighbours.
>>
>> Yes. Probably we need to fix this so that nothing is added when an area
>> has no neighbours.
>>
>>> When I re-ran the analysis after I changed my neighbourhood structure
> such
>>> that all areas had neighbours, the WinBUGS simulation ran fine.
>>>
>>> Is there a way to format the spatial weights list object via nb2WB() in a
>>> way that allows WinBUGS to read cases with no neighbours?
>>
>> It should be done automatically, but probably we forgot to consider the
>> case of areas with no neighbours.
>>
>> Could it be possible to see the map that you are using? I'd say that
>> there is a mismatch between the number of neighbours and the number of
>> weights, but I would need to check with you data and code.
>>
>>
>> Best wishes,
>>
>> Virgilio
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From k.lamb at sphsu.mrc.ac.uk  Thu Nov 26 11:46:32 2009
From: k.lamb at sphsu.mrc.ac.uk (Karen Lamb)
Date: Thu, 26 Nov 2009 10:46:32 +0000
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a Poisson
 or Negative Binomial model
Message-ID: <4B0E5C88.8030002@sphsu.mrc.ac.uk>

Hi,

I am currently trying to determine a way of assessing whether or not 
there is spatial autocorrelation present in my model residuals and was 
hoping someone could help me with this.

I have information on counts in over six thousand areas, with around 
half of the areas found to have  a count of zero. I decided to fit a 
Zero-Inflated Poisson model and a Negative Binomial as the data is 
greatly overdispersed. However, neither of these approaches take into 
account the likelihood that there is spatial autocorrelation present in 
the data set.

I have been searching for the last two weeks to find appropriate methods 
to fit a spatial glm model. However, as I am new to spatial statistical 
methodology I am finding it difficult to decide how best to do this. It 
am not sure that any of the existing R functions are particularly 
suitable to my use. I am not interested in prediction as I have data on 
a population. I am interested in assessing the coefficients of variables 
and whether or not the variables are significant in determining outcome. 
I have noticed that a lot of analyses use a Bayesian approach which may 
be the way forward.

My question, however, relates to the glm models I have fitted. I have 
included variables which may explain some of the spatial correlations 
such as urban/rural classification. I would like to see if any residual 
spatial autocorrelation remains in the model but cannot find a way of 
doing this. On searching the R-sig-Geo archives the Morans Test or 
Morans I are mentioned. However, I noticed someone had queried using the 
moran test in R for residuals from a logistic regression and had been 
told that lm.morantest() is available for linear regression but there is 
not an alternative for the glm. Has anyone got any suggestions for how 
to check my residuals? Are there particular plots that can be assessed?

Thanks for your assistance.

Cheers,
Karen


From liov2067 at gmail.com  Thu Nov 26 12:11:43 2009
From: liov2067 at gmail.com (=?ISO-8859-1?Q?Luis_Iv=E1n_Ortiz_Valencia?=)
Date: Thu, 26 Nov 2009 09:11:43 -0200
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a
	Poisson or Negative Binomial model
In-Reply-To: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
References: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
Message-ID: <684e31d40911260311x5d2f36b0m6b32794fafbf020f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091126/4255ac1a/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov 26 12:37:17 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Nov 2009 12:37:17 +0100 (CET)
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a
 Poisson or Negative Binomial model
In-Reply-To: <684e31d40911260311x5d2f36b0m6b32794fafbf020f@mail.gmail.com>
References: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
	<684e31d40911260311x5d2f36b0m6b32794fafbf020f@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0911261225240.13556@reclus.nhh.no>

On Thu, 26 Nov 2009, Luis Iv?n Ortiz Valencia wrote:

> Hi Karen
>
> I am interested in this points too. What variable are you modeling? Counts
> or incidence? did you standardized by population areas?
>
> R has lot of spatial models for spatial models. see at
> http://r-spatial.sourceforge.net/

Rather:

http://cran.r-project.org/view=Spatial

please, the sourceforge site is more for development, and is linked from 
the task view on your nearest CRAN mirror.

While lm.morantest() can be used on glm output objects, no work has been 
done to establish whether this is a sensible idea. It remains problematic 
to simulate spatially dependent discrete variables. However, it is 
possible that if you ignore the "test" of doubtful substance, you could 
track how Moran's I moves when adding variables in an exploratory way. Try 
with a smaller dataset first.

Hope this helps,

Roger

>
> hope this help
>
> ivan
>
> 2009/11/26 Karen Lamb <k.lamb at sphsu.mrc.ac.uk>
>
>> Hi,
>>
>> I am currently trying to determine a way of assessing whether or not there
>> is spatial autocorrelation present in my model residuals and was hoping
>> someone could help me with this.
>>
>> I have information on counts in over six thousand areas, with around half
>> of the areas found to have  a count of zero. I decided to fit a
>> Zero-Inflated Poisson model and a Negative Binomial as the data is greatly
>> overdispersed. However, neither of these approaches take into account the
>> likelihood that there is spatial autocorrelation present in the data set.
>>
>> I have been searching for the last two weeks to find appropriate methods to
>> fit a spatial glm model. However, as I am new to spatial statistical
>> methodology I am finding it difficult to decide how best to do this. It am
>> not sure that any of the existing R functions are particularly suitable to
>> my use. I am not interested in prediction as I have data on a population. I
>> am interested in assessing the coefficients of variables and whether or not
>> the variables are significant in determining outcome. I have noticed that a
>> lot of analyses use a Bayesian approach which may be the way forward.
>>
>> My question, however, relates to the glm models I have fitted. I have
>> included variables which may explain some of the spatial correlations such
>> as urban/rural classification. I would like to see if any residual spatial
>> autocorrelation remains in the model but cannot find a way of doing this. On
>> searching the R-sig-Geo archives the Morans Test or Morans I are mentioned.
>> However, I noticed someone had queried using the moran test in R for
>> residuals from a logistic regression and had been told that lm.morantest()
>> is available for linear regression but there is not an alternative for the
>> glm. Has anyone got any suggestions for how to check my residuals? Are there
>> particular plots that can be assessed?
>>
>> Thanks for your assistance.
>>
>> Cheers,
>> Karen
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From marcelino.delacruz at upm.es  Thu Nov 26 12:54:24 2009
From: marcelino.delacruz at upm.es (Marcelino de la Cruz)
Date: Thu, 26 Nov 2009 12:54:24 +0100
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a
 Poisson or Negative Binomial model
In-Reply-To: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
References: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
Message-ID: <200911261154.nAQBsR8r015203@edison.ccupm.upm.es>

Hi,

You may find useful this:

Dormann et al. 2007. Methods to account for 
spatial autocorrelation in the analysis
of species distributional data: a review. Ecography 30: 609-628,

And the suplementary material with several examples worked in R.

HTH,

Marcelino

At 11:46 26/11/2009, Karen Lamb wrote:
>Hi,
>
>I am currently trying to determine a way of 
>assessing whether or not there is spatial 
>autocorrelation present in my model residuals 
>and was hoping someone could help me with this.
>
>I have information on counts in over six 
>thousand areas, with around half of the areas 
>found to have  a count of zero. I decided to fit 
>a Zero-Inflated Poisson model and a Negative 
>Binomial as the data is greatly overdispersed. 
>However, neither of these approaches take into 
>account the likelihood that there is spatial 
>autocorrelation present in the data set.
>
>I have been searching for the last two weeks to 
>find appropriate methods to fit a spatial glm 
>model. However, as I am new to spatial 
>statistical methodology I am finding it 
>difficult to decide how best to do this. It am 
>not sure that any of the existing R functions 
>are particularly suitable to my use. I am not 
>interested in prediction as I have data on a 
>population. I am interested in assessing the 
>coefficients of variables and whether or not the 
>variables are significant in determining 
>outcome. I have noticed that a lot of analyses 
>use a Bayesian approach which may be the way forward.
>
>My question, however, relates to the glm models 
>I have fitted. I have included variables which 
>may explain some of the spatial correlations 
>such as urban/rural classification. I would like 
>to see if any residual spatial autocorrelation 
>remains in the model but cannot find a way of 
>doing this. On searching the R-sig-Geo archives 
>the Morans Test or Morans I are mentioned. 
>However, I noticed someone had queried using the 
>moran test in R for residuals from a logistic 
>regression and had been told that lm.morantest() 
>is available for linear regression but there is 
>not an alternative for the glm. Has anyone got 
>any suggestions for how to check my residuals? 
>Are there particular plots that can be assessed?
>
>Thanks for your assistance.
>
>Cheers,
>Karen
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at stat.math.ethz.ch
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo

________________________________

Marcelino de la Cruz Rot

Departamento de  Biolog?a Vegetal
E.U.T.I. Agr?cola
Universidad Polit?cnica de Madrid
28040-Madrid
Tel.: 91 336 54 35
Fax: 91 336 56 56
marcelino.delacruz at upm.es
_________________________________ 


From fernando.e.grignola at monsanto.com  Thu Nov 26 14:45:01 2009
From: fernando.e.grignola at monsanto.com (GRIGNOLA, FERNANDO E [AG/6042])
Date: Thu, 26 Nov 2009 14:45:01 +0100
Subject: [R-sig-Geo] Newbie question on shape files and mapping
In-Reply-To: <mailman.13.1259233204.1870.r-sig-geo@stat.math.ethz.ch>
References: <mailman.13.1259233204.1870.r-sig-geo@stat.math.ethz.ch>
Message-ID: <F325707200B59341B8854DC5B46DA0200693E8DD@EA6042EXM01.ea.ds.monsanto.com>

Hello,
I'm working on a project using weather data mostly on the statistical
aspects of it, i.e. environmental classification. I have a bunch of
shape files (*.dbf, *.prj, *.sbn, *.sbx, *.shp, *.shx) from different
world regions and I would like to start using R to do the mapping of
different clusters. So far I've been using "black box" proprietary
software for mapping purposes and, being a big fan of R, I would like to
start using R instead.
Could you please provide me some BASIC information (beginners notes,
libraries, etc.) on shape files, how to read them and query them to
color regions clustering together based on a set variables of interest?
I hope this group can help me out or point me into the right direction.
Thanks in advance,

Fernando



---------------------------------------------------------------------------------------------------------
This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.


All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware". Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying this e-mail or any attachment.


From E.Couce.07 at bristol.ac.uk  Thu Nov 26 14:18:56 2009
From: E.Couce.07 at bristol.ac.uk (ElenaC)
Date: Thu, 26 Nov 2009 05:18:56 -0800 (PST)
Subject: [R-sig-Geo] problem reading netcdf file with readGDAL: "no
 bands in dataset"
In-Reply-To: <522664f80911251230l5664304di7ea2c8cc78f66fdf@mail.gmail.com>
References: <1259156071208-4064987.post@n2.nabble.com>
	<522664f80911251227l14d79e36qbac8f16723c1bb30@mail.gmail.com>
	<522664f80911251230l5664304di7ea2c8cc78f66fdf@mail.gmail.com>
Message-ID: <1259241536098-4071119.post@n2.nabble.com>


Thanks a lot, Mike! 
I have finally managed to select the subdataset, and everything is working
now! 

Cheers,
Elena



Michael Sumner-2 wrote:
> 
> See this page for more information about the GDAL approach to NetCDF:
> http://www.gdal.org/frmt_netcdf.html
> 
> If you can construct the subdataset name correctly then readGDAL
> should be able to return the given variable, as a single band
> SpatialGridDataFrame.
> 
> 
> 
> On Thu, Nov 26, 2009 at 7:27 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>> There are a number of reasons why GDAL might not be able to read data
>> from NetCDF, although it might appear to get some metadata upfront.
>> The 512x512 thing is a default, and to me means that there are
>> multiple variables in the file, and GDAL requires direct reference to
>> only one of them as a "subdataset". The syntax is something like this:
>>
>> NETCDF:"/path/to/filename.nc":varname
>>
>> If you use gdalinfo at the command line it will tell you the
>> subdataset strings you can use - the rgdal bindings don't reconstruct
>> the output that that utility gives you.
>>
>> Cheers, Mike.
>>
>> On Thu, Nov 26, 2009 at 12:34 AM, ElenaC <E.Couce.07 at bristol.ac.uk>
>> wrote:
>>>
>>> Hi all,
>>>
>>> I'm trying to open a netcdf file using the rgdal library, but readGDAL
>>> and
>>> GDALinfo don't seem to be able to correctly access the information in
>>> the
>>> file. It is probably a stupid mistake because I don't understand what
>>> I'm
>>> doing, but I have already spent a long time trying to sort it out and I
>>> could really use some help with it.
>>>
>>> When I try readGDAL, it fails with the error that there are "no bands in
>>> dataset". This is the output I get from GDALinfo:
>>>
>>>> GDALinfo(fname)
>>> rows ? ? ? ?512
>>> columns ? ? 512
>>> bands ? ? ? 0
>>> origin.x ? ? ? ?0
>>> origin.y ? ? ? ?1
>>> res.x ? ? ? 1
>>> res.y ? ? ? 1
>>> oblique.x ? 0
>>> oblique.y ? 0
>>> driver ? ? ?netCDF
>>> projection ?NA
>>>
>>> Warning messages:
>>> 1: In dim(x) : no bands in dataset
>>> 2: In GDALinfo(fname) : no bands in dataset
>>>
>>>
>>>
>>> But from opening the file with Panoply, it seems it actually contains
>>> four
>>> variables, two of them 360*180 matrices with the geographical info I'm
>>> trying to access (global data with 1 degree spatial resolution), and the
>>> two
>>> others called "lat" and "lon" with the latitude and longitude values.
>>>
>>> I don't understand why GDALinfo is telling me that the file has 512 rows
>>> and
>>> 512 columns and that there are "no bands". What can I do to access the
>>> variables I want?
>>>
>>> Any help would be greatly appreciated!
>>> Elena
>>> --
>>> View this message in context:
>>> http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4064987.html
>>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 

-- 
View this message in context: http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4071119.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From p.hiemstra at geo.uu.nl  Thu Nov 26 15:14:24 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 26 Nov 2009 15:14:24 +0100
Subject: [R-sig-Geo] Newbie question on shape files and mapping
In-Reply-To: <F325707200B59341B8854DC5B46DA0200693E8DD@EA6042EXM01.ea.ds.monsanto.com>
References: <mailman.13.1259233204.1870.r-sig-geo@stat.math.ethz.ch>
	<F325707200B59341B8854DC5B46DA0200693E8DD@EA6042EXM01.ea.ds.monsanto.com>
Message-ID: <4B0E8D40.8060007@geo.uu.nl>

Hi,

Check out the spatial task view [1] and the R wiki [2].

cheers,
Paul

[1] http://cran.r-project.org/web/views/Spatial.html
[2] http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data


GRIGNOLA, FERNANDO E [AG/6042] wrote:
> Hello,
> I'm working on a project using weather data mostly on the statistical
> aspects of it, i.e. environmental classification. I have a bunch of
> shape files (*.dbf, *.prj, *.sbn, *.sbx, *.shp, *.shx) from different
> world regions and I would like to start using R to do the mapping of
> different clusters. So far I've been using "black box" proprietary
> software for mapping purposes and, being a big fan of R, I would like to
> start using R instead.
> Could you please provide me some BASIC information (beginners notes,
> libraries, etc.) on shape files, how to read them and query them to
> color regions clustering together based on a set variables of interest?
> I hope this group can help me out or point me into the right direction.
> Thanks in advance,
>
> Fernando
>
>
>
> ---------------------------------------------------------------------------------------------------------
> This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.
>
>
> All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware". Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying this e-mail or any attachment.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From cara.tobin at epfl.ch  Thu Nov 26 16:18:02 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Thu, 26 Nov 2009 16:18:02 +0100
Subject: [R-sig-Geo] Error with KED with 2 external drift factors,
	one iterating in time
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8FD@REX2.intranet.epfl.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091126/82fd30a0/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov 26 21:35:04 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 26 Nov 2009 21:35:04 +0100 (CET)
Subject: [R-sig-Geo] problem reading netcdf file with readGDAL: "no
 bands in dataset"
In-Reply-To: <1259241536098-4071119.post@n2.nabble.com>
References: <1259156071208-4064987.post@n2.nabble.com>
	<522664f80911251227l14d79e36qbac8f16723c1bb30@mail.gmail.com>
	<522664f80911251230l5664304di7ea2c8cc78f66fdf@mail.gmail.com>
	<1259241536098-4071119.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.0911262126410.30181@reclus.nhh.no>

On Thu, 26 Nov 2009, ElenaC wrote:

>
> Thanks a lot, Mike! 
> I have finally managed to select the subdataset, and everything is working
> now!

In the next release of rgdal, dataset metadata and subdataset names and 
descriptions will be reported by GDALinfo() where present, which should 
make it easier to follow the advice on:

http://www.gdal.org/frmt_netcdf.html

Roger

>
> Cheers,
> Elena
>
>
>
> Michael Sumner-2 wrote:
>> 
>> See this page for more information about the GDAL approach to NetCDF:
>> http://www.gdal.org/frmt_netcdf.html
>> 
>> If you can construct the subdataset name correctly then readGDAL
>> should be able to return the given variable, as a single band
>> SpatialGridDataFrame.
>> 
>> 
>> 
>> On Thu, Nov 26, 2009 at 7:27 AM, Michael Sumner <mdsumner at gmail.com>
>> wrote:
>>> There are a number of reasons why GDAL might not be able to read data
>>> from NetCDF, although it might appear to get some metadata upfront.
>>> The 512x512 thing is a default, and to me means that there are
>>> multiple variables in the file, and GDAL requires direct reference to
>>> only one of them as a "subdataset". The syntax is something like this:
>>>
>>> NETCDF:"/path/to/filename.nc":varname
>>>
>>> If you use gdalinfo at the command line it will tell you the
>>> subdataset strings you can use - the rgdal bindings don't reconstruct
>>> the output that that utility gives you.
>>>
>>> Cheers, Mike.
>>>
>>> On Thu, Nov 26, 2009 at 12:34 AM, ElenaC <E.Couce.07 at bristol.ac.uk>
>>> wrote:
>>>>
>>>> Hi all,
>>>>
>>>> I'm trying to open a netcdf file using the rgdal library, but readGDAL
>>>> and
>>>> GDALinfo don't seem to be able to correctly access the information in
>>>> the
>>>> file. It is probably a stupid mistake because I don't understand what
>>>> I'm
>>>> doing, but I have already spent a long time trying to sort it out and I
>>>> could really use some help with it.
>>>>
>>>> When I try readGDAL, it fails with the error that there are "no bands in
>>>> dataset". This is the output I get from GDALinfo:
>>>>
>>>>> GDALinfo(fname)
>>>> rows ? ? ? ?512
>>>> columns ? ? 512
>>>> bands ? ? ? 0
>>>> origin.x ? ? ? ?0
>>>> origin.y ? ? ? ?1
>>>> res.x ? ? ? 1
>>>> res.y ? ? ? 1
>>>> oblique.x ? 0
>>>> oblique.y ? 0
>>>> driver ? ? ?netCDF
>>>> projection ?NA
>>>>
>>>> Warning messages:
>>>> 1: In dim(x) : no bands in dataset
>>>> 2: In GDALinfo(fname) : no bands in dataset
>>>>
>>>>
>>>>
>>>> But from opening the file with Panoply, it seems it actually contains
>>>> four
>>>> variables, two of them 360*180 matrices with the geographical info I'm
>>>> trying to access (global data with 1 degree spatial resolution), and the
>>>> two
>>>> others called "lat" and "lon" with the latitude and longitude values.
>>>>
>>>> I don't understand why GDALinfo is telling me that the file has 512 rows
>>>> and
>>>> 512 columns and that there are "no bands". What can I do to access the
>>>> variables I want?
>>>>
>>>> Any help would be greatly appreciated!
>>>> Elena
>>>> --
>>>> View this message in context:
>>>> http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4064987.html
>>>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> 
>
> -- 
> View this message in context: http://n2.nabble.com/problem-reading-netcdf-file-with-readGDAL-no-bands-in-dataset-tp4064987p4071119.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From roberto.patuelli at usi.ch  Fri Nov 27 01:25:17 2009
From: roberto.patuelli at usi.ch (Roberto Patuelli)
Date: Fri, 27 Nov 2009 01:25:17 +0100
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a
	Poisson
Message-ID: <45CD0F6E4415491F80446E798CEBD3D7@Ciretto>

Dear Karen,

I've also been working on spatial count (glm) models, in particular using 
spatial filtering (Griffith 2003), which helps you incorporating spatial 
autocorrelation in the mean response term.
Michael Tiefelsdorf has written a spatial filtering code in R, which is 
included in spdep. But it is based on a Moran's I minimization criterion 
only, and uses (if I'm not wrong) a linear model.
Instead I've used it on count regressions, by writing my own R code, which 
of course I'm willing to share :) For example, I will soon make the code 
used in this paper (http://ideas.repec.org/p/lug/wpaper/0806.html), which is 
forthcoming on the Annals of Regional Science, public.
See my website for more :))

Cheers
Roberto


********************
Roberto Patuelli, Ph.D.
Istituto Ricerche Economiche (IRE) (Institute for Economic Research)
Universit? della Svizzera Italiana (University of Lugano)
via Maderno 24, CP 4361
CH-6904 Lugano
Switzerland
Phone: +41-(0)58-666-4166
Fax: +39-02-700419665
Email: roberto.patuelli at usi.ch
Homepage: http://www.people.lu.unisi.ch/patuellr


From edzer.pebesma at uni-muenster.de  Fri Nov 27 08:47:29 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 27 Nov 2009 08:47:29 +0100
Subject: [R-sig-Geo] Error with KED with 2 external drift factors,
 one iterating in time
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8FD@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E8FD@REX2.intranet.epfl.ch>
Message-ID: <4B0F8411.9080903@uni-muenster.de>



Tobin Cara wrote:
> Hello,
>
> I am trying to krige temperature relative to an elevation and a forecast grid. The forecast changes hourly.
>
> Everything reads in well until I use the kriging command:
>
> list_ked[[i]] <- krige(Temp00[,i]~Z+COS7, locations=DataCoordhr, newdata=elev, model = fitted_vario)
>   
use

list_ked[[i]] <- krige(Temp00[,i]~Z+COS7, DataCoordhr, elev, fitted_vario)

and make sure that DataCoordhr is of class SpatialPointsDataFrame, e.g. by doing a
coordinates(DataCoordhr) <- ~x+y

or sth like that.


> Error in function (classes, fdef, mtable)  :
>   unable to find an inherited method for function "krige", for signature "formula", "data.frame"
>   
>> trace()
>>     
> Error in methods::.TraceWithMethods(where = <environment>) :
>   element 1 is empty;
>    the part of the args list of 'is.function' being evaluated was:
>    (what)
>
>
>
> I have linked my data coordinates with both Z and COS7 and I have linked two ascii grids elev and COS7 with the following commands:
>
>
>
> COS700 <- read.table("D:\\Krigging R\\COSMO7Temp2000\\COS7_Val_Temp_00_trans.txt")
> COS7hr <- COS700[,i]
>
> DataCoord <- read.delim("TempANZCoord_Elev_Val00.txt")
> DataCoord <- as.matrix(DataCoord)  ## transform into a matrix
> DataCoordhr <- cbind(DataCoord,COS7hr) ## append a new column at the end
> DataCoordhr <- as.data.frame(DataCoordhr) ## backtransform into data frame
> names(DataCoordhr) <- c("X","Y","Z","COS7hr") ## define new names
>
>
>
> #Merge COS7 and elevation into elev
> elev$COS7 = COS7[[1]] #make them into a single object, replace as newdata
>
>
>
> Does anyone have any ideas?
>
>
>
> Thank you in advance,
>
> Cara
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From szollinger at access.uzh.ch  Fri Nov 27 09:39:23 2009
From: szollinger at access.uzh.ch (Stefan Zollinger)
Date: Fri, 27 Nov 2009 09:39:23 +0100
Subject: [R-sig-Geo] Collocated Cokriging of snow height data
Message-ID: <web-21438754@idmailbe2b.unizh.ch>

Hi

I am trying to spatially interpolate snow height data of about 100 stations 
in a mountain range. In addition, I have a large DEM (SRTM, 90 meters 
resolution, 2.5 million cells) which also serves as an interpolation raster 
(just like meuse.grid). As the snow height and the height above sea level 
correlate strongly, I intend to use collocated cokriging to improve the 
estimation, which is why I studied the example in "Applied Spatial Data 
Analysis with R" by Roger Bivand, Edzer Pebesma and Virgilio G?mez-Rubio.

I have the following questions (especially to the authors):

1. Why and how is the new attribute "distn" being calculated? Would it not 
be sufficient to use the existing attribute "dist" for the collocated 
cokriging (as it shows the same variogram-model properties)?

2. How are the two variogram-models "vd.fit" and "vx.fit" being calculated 
out of "v.fit"? I understand that the range and the type of the three models 
remains the same, but how are the sills and nuggets being changed?

3. How would the calculation of "vd.fit" and " vx.fit" change if a trend 
model was used, like "log(zinc) ~ sqrt(dist)"?

Any advice or help will be highly appreciated

Stefan Zollinger


From alan.swanson at umontana.edu  Fri Nov 27 10:14:51 2009
From: alan.swanson at umontana.edu (Alan Swanson)
Date: Fri, 27 Nov 2009 02:14:51 -0700
Subject: [R-sig-Geo] changing the data type of a gdal dataset
In-Reply-To: <dc22b2570911200914h59ed06b2l934ae255db4f01b2@mail.gmail.com>
References: <4B062112.3080809@umontana.edu>
	<dc22b2570911200914h59ed06b2l934ae255db4f01b2@mail.gmail.com>
Message-ID: <4B0F988B.5030601@umontana.edu>

Thanks Robert for your advice.  Due to the details of my situation I 
decided it was easier to tough it out in the rgdal package, but fully 
intend to use the raster package for future projects.  In case anybody 
is interested, I eventually blundered across the answer to my original 
question.  Rather than changing the data type of a copy of a file, I am 
creating a new transient dataset of the desired data type and 
dimensions, then adding spatial reference info gleaned from an existing 
file.  Alan

# get spatial reference info from existing image file
gi <- GDALinfo(infile.name)
dims <- as.vector(gi)[1:2]
ps <- as.vector(gi)[6:7]
ll <- as.vector(gi)[4:5]
pref<-attr(gi,"projection")

# calculate position of upper left corner and get geotransform ala 
http://www.gdal.org/gdal_datamodel.html
ul <- c(ll[1]-ps[1]/2,ll[2]+(dims[1]+.5)*ps[2])
gt<-c(ul[1],ps[1],0,ul[2],0,ps[2])

# create transient dataset to hold output maps, and add spatial 
reference info
tds <- 
new("GDALTransientDataset",new('GDALDriver','GTiff'),rows=dims[1],cols=dims[2],type="Float32")
.Call("RGDAL_SetProject", tds, pref, PACKAGE = "rgdal")
.Call("RGDAL_SetGeoTransform", tds, gt, PACKAGE = "rgdal")
 
# use putRasterData()   in a loop to build the output file

# save the dataset
saveDataset(tds,outfile.name) 
GDAL.close(tds)
   

Robert J. Hijmans wrote:
> Alan,
> You can have a look at the code in the raster package on R-forge (see
> the writeGDAL function). Or perhaps use this package: one of the
> primary reasons for developing it was to automate (and hide) block by
> block raster processing --- and quite successfully, it is being used
> to process raster files that are too large for the leading commercial
> gis software. See raster::predict to apply a model to a set or raster
> predictors.
> Robert
>
> On Thu, Nov 19, 2009 at 8:54 PM, Alan Swanson <alan.swanson at umontana.edu> wrote:
>   
>> Dear R gurus,
>> I have a function that applies various model prediction functions over a set
>> of large image files, producing a single output file with the same spatial
>> extent.  Due to memory issues, I'm breaking the input and output files into
>> tiles.  I have this working except for one small issue regarding data types.
>> I create a new gdal transient dataset by copying an existing one using:
>> handle <- GDAL.open(fullnames[1],read.only=T)
>> tds <-
>> copyDataset(handle,driver=new('GDALDriver','GTiff'),strict=F,options=NULL)
>> ...
>> putRasterData(tds,t(preds), offset= c(strt[1], 0))
>> ...
>> saveDataset(tds,outfile.p)
>> GDAL.close(tds)
>>     Which works great, except that my output always needs to be floating
>> point, but the input may be byte or integer, in which case the output
>> dataset retains the format of the input file.  So I either need to change
>> the data type of the new file, or create the new file using:
>> tds <- new("GDALTransientDataset",driver,dims[1],dims[2], type="Float32")
>>
>> and then copy the spatial reference information from an existing dataset.  I
>> can't figure out how to do either of these.  Your help would be much
>> appreciated.
>> Cheers,
>> Alan
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
>
>


From Mark.Trinder at rpsgroup.com  Fri Nov 27 10:32:57 2009
From: Mark.Trinder at rpsgroup.com (Mark Trinder)
Date: Fri, 27 Nov 2009 09:32:57 -0000
Subject: [R-sig-Geo] add buffer to polygon and determine if points are
	inside or outside
Message-ID: <605F55D8070C094AA2E2A9CBA2767A3C066B5BA6@EXMB1.eur.rpsgroup.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/e0b88f40/attachment.pl>

From Mark.Trinder at rpsgroup.com  Fri Nov 27 11:37:18 2009
From: Mark.Trinder at rpsgroup.com (Mark Trinder)
Date: Fri, 27 Nov 2009 10:37:18 -0000
Subject: [R-sig-Geo] add buffer to polygon and determine if points are
	inside or outside
Message-ID: <605F55D8070C094AA2E2A9CBA2767A3C066B5D30@EXMB1.eur.rpsgroup.com>

Hi all


I am trying to do some simulations of bird distributions overlaid on
polygons (representing windfarms) so that we can estimate survey effort.
Part of this involves the addition of buffers around the polygon at
fixed distances - I thought this would be simple to do from first
principles but have realised that there is more to it. I've searched for
help but haven't found the solution to this. I also want to be able to
determine if a (randomly generated) point, which represents a bird
observation, lies inside or outside the polygon.

Any guidance on this would be greatly appreciated.

thanks

Mark

Ps: re-posted due to technical problems!

This e-mail message and any attached file is the property of the sender and is sent in confidence to the addressee only.
Internet communications are not secure and RPS is not responsible for their abuse by third parties, any alteration or corruption in transmission or for any loss or damage caused by a virus or by other means.
 
Any advice contained in this e-mail is for information purposes only.

RPS Planning and Development Limited, company number: 02947164 (England). Registered office: Centurion Court, 85 Milton Park Abingdon Oxfordshire OX14 4RY.
RPS Group Plc web link: <http://www.rpsgroup.com>


From edalaze at gmail.com  Fri Nov 27 12:51:24 2009
From: edalaze at gmail.com (Eda Laze)
Date: Fri, 27 Nov 2009 12:51:24 +0100
Subject: [R-sig-Geo] local R2
Message-ID: <c7730d730911270351l3277c05aga299180cb7506fe0@mail.gmail.com>

Hello,

I am currectly using gwr in R to get local R2. I have a shape file -
polygon data.
When I write codes as below: case 1 and 2, I get two different Local
R2 values and maps:

case1.adpt<-gwr(FCHA~PAC1+PAC2+PAC6, data=filename,
coords=cbind(filename$X, filename$Y), adapt= 0.01, longlat=TRUE).
case2.adpt<-gwr(FCHA~PAC1+PAC2+PAC6, data=filename,
coords=cbind(filename$X, filename$Y), adapt= 0.01, hatmatrix = TRUE,
se.fit=TRUE). Local R2 have different values from case 1 and map is
different as well.

Furthermore, when I visualize case 1: i.e., local R2 on map, each
polygon has a certain value and responding color while in case 2: map
shows clustering of Local R2 (values) similar to Georgia case study.
However, I wonder why this happen and which is the right way to get
local R2.

I read spgwr manual and update. Though an accurate answer is very welcome.

Thank you.


From Roger.Bivand at nhh.no  Fri Nov 27 13:12:49 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 27 Nov 2009 13:12:49 +0100 (CET)
Subject: [R-sig-Geo] local R2
In-Reply-To: <c7730d730911270351l3277c05aga299180cb7506fe0@mail.gmail.com>
References: <c7730d730911270351l3277c05aga299180cb7506fe0@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0911271307280.4373@reclus.nhh.no>

On Fri, 27 Nov 2009, Eda Laze wrote:

> Hello,
>
> I am currectly using gwr in R to get local R2. I have a shape file -
> polygon data.
> When I write codes as below: case 1 and 2, I get two different Local
> R2 values and maps:
>
> case1.adpt<-gwr(FCHA~PAC1+PAC2+PAC6, data=filename,
> coords=cbind(filename$X, filename$Y), adapt= 0.01, longlat=TRUE).
> case2.adpt<-gwr(FCHA~PAC1+PAC2+PAC6, data=filename,
> coords=cbind(filename$X, filename$Y), adapt= 0.01, hatmatrix = TRUE,
> se.fit=TRUE). Local R2 have different values from case 1 and map is
> different as well.

In the second case, you are not using longlat=TRUE, which will give rather 
different weights. Please only give examples with available data sets, and 
include say the first 5 local R2 values, so that helpers know that they 
are looking at the same thing as you are. Always state the output of 
sessionInfo().

Hope this helps,

Roger

>
> Furthermore, when I visualize case 1: i.e., local R2 on map, each
> polygon has a certain value and responding color while in case 2: map
> shows clustering of Local R2 (values) similar to Georgia case study.
> However, I wonder why this happen and which is the right way to get
> local R2.
>
> I read spgwr manual and update. Though an accurate answer is very welcome.
>
> Thank you.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From jean-paul.kibambe at uclouvain.be  Fri Nov 27 16:01:36 2009
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Fri, 27 Nov 2009 16:01:36 +0100
Subject: [R-sig-Geo] 'Customizing' spsample
Message-ID: <3d1c200dd71a652f8ef5030b98dd0223.squirrel@mmp.sipr-dc.ucl.ac.be>

Hello everybody,

I am using 'spsample' to derive points along a line and it works perfectly
by doing the following :

xx <- readShapeLines("line2",proj4string=CRS("+proj=utm +zone=34
+datum=WGS84"))
sppts <- spsample(xx, n=50, type="random")
plot(sppts)

However, I was wondering if the user can somehow 'customize' the sampling
process, as for example, by separating sampling points by a given
distance. And this distance being in the same units as the line. The 'n'
argument in spsample will therefore vary according with the length of each
line.

Any help is welcome!


Jean-Paul


From cara.tobin at epfl.ch  Fri Nov 27 16:10:38 2009
From: cara.tobin at epfl.ch (Tobin Cara)
Date: Fri, 27 Nov 2009 16:10:38 +0100
Subject: [R-sig-Geo] Still error exporting ascii grid generated by DTM grid,
 please any suggestions?
Message-ID: <EDB94195DABE64488928DD39E53B8FC68BDFD3E900@REX2.intranet.epfl.ch>

Hello,

I am still receiving a bizarre error:

Error in write.asciigrid(data_int_ked[1], name1) : 
  Asciigrid does not support grids with non-square cells

I do not understand this as I am putting interpolated data back into the cells of an ascii DTM grid with square cells. Information on the DTM I am kriging to is below (I have combined two datasets into elev, COS7 and the Z elevation): 

Thank you in advance for your help,

Cara

> summary(elev)
Object of class SpatialGridDataFrame
Coordinates:
        min      max
X 550119.63 674619.6
Y  79073.03 167073.0
Is projected: NA 
proj4string : [NA]
Number of points: 2
Grid attributes:
  cellcentre.offset cellsize cells.dim
X         550369.63      500       249
Y          79323.03      500       176
Data attributes:
       Z              COS7          
 Min.   :  380   Min.   :   -1.510  
 1st Qu.: 1500   1st Qu.:    0.180  
 Median : 2143   Median :    0.630  
 Mean   : 2077   Mean   :    2.083  
 3rd Qu.: 2663   3rd Qu.:    4.190  
 Max.   : 4471   Max.   :    8.730  
 NA's   :22337   NA's   :22337.000  

From rusers.sh at gmail.com  Fri Nov 27 17:40:58 2009
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 27 Nov 2009 11:40:58 -0500
Subject: [R-sig-Geo] convert points into SHP polygons
Message-ID: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/bd30967e/attachment.pl>

From r.hijmans at gmail.com  Fri Nov 27 19:02:43 2009
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 27 Nov 2009 10:02:43 -0800
Subject: [R-sig-Geo] Still error exporting ascii grid generated by DTM
	grid, please any suggestions?
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E900@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E900@REX2.intranet.epfl.ch>
Message-ID: <dc22b2570911271002y76691040x213a19eb6e15787@mail.gmail.com>

Hi Cara,

It would be easier to respond if you provided some information about
"data_int_ked", from the information you provide it is not obvious
what kind of object it is, and what the result of subsetting it with
[1] would be.

class(data_int_ked[1])
summary(data_int_ked[1])
str(data_int_ked[1])

I am guessing that you want to use is data_int_ked[,1]

Hth,

Robert

On Fri, Nov 27, 2009 at 7:10 AM, Tobin Cara <cara.tobin at epfl.ch> wrote:
> Hello,
>
> I am still receiving a bizarre error:
>
> Error in write.asciigrid(data_int_ked[1], name1) :
> ?Asciigrid does not support grids with non-square cells
>
> I do not understand this as I am putting interpolated data back into the cells of an ascii DTM grid with square cells. Information on the DTM I am kriging to is below (I have combined two datasets into elev, COS7 and the Z elevation):
>
> Thank you in advance for your help,
>
> Cara
>
>> summary(elev)
> Object of class SpatialGridDataFrame
> Coordinates:
> ? ? ? ?min ? ? ?max
> X 550119.63 674619.6
> Y ?79073.03 167073.0
> Is projected: NA
> proj4string : [NA]
> Number of points: 2
> Grid attributes:
> ?cellcentre.offset cellsize cells.dim
> X ? ? ? ? 550369.63 ? ? ?500 ? ? ? 249
> Y ? ? ? ? ?79323.03 ? ? ?500 ? ? ? 176
> Data attributes:
> ? ? ? Z ? ? ? ? ? ? ?COS7
> ?Min. ? : ?380 ? Min. ? : ? -1.510
> ?1st Qu.: 1500 ? 1st Qu.: ? ?0.180
> ?Median : 2143 ? Median : ? ?0.630
> ?Mean ? : 2077 ? Mean ? : ? ?2.083
> ?3rd Qu.: 2663 ? 3rd Qu.: ? ?4.190
> ?Max. ? : 4471 ? Max. ? : ? ?8.730
> ?NA's ? :22337 ? NA's ? :22337.000
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From edzer.pebesma at uni-muenster.de  Fri Nov 27 20:04:57 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 27 Nov 2009 20:04:57 +0100
Subject: [R-sig-Geo] [Fwd: Re: RE : Still error exporting ascii grid
 generated by DTM grid, please any suggestions?]
Message-ID: <4B1022D9.5050902@uni-muenster.de>

(problem resolved, see below)
-------------- next part --------------
An embedded message was scrubbed...
From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Subject: Re: RE : [R-sig-Geo] Still error exporting ascii grid generated by
	DTM grid, please any suggestions?
Date: Fri, 27 Nov 2009 20:01:10 +0100
Size: 3662
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/686aa46b/attachment.eml>

From prairie.picker at gmail.com  Fri Nov 27 21:53:24 2009
From: prairie.picker at gmail.com (Tyler Dean Rudolph)
Date: Fri, 27 Nov 2009 15:53:24 -0500
Subject: [R-sig-Geo] Convert kde object into spatial object
Message-ID: <9fb1ae890911271253s162bf75ckfd906e2f4df0e2f7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/6fd667d3/attachment.pl>

From rusers.sh at gmail.com  Fri Nov 27 23:03:35 2009
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 27 Nov 2009 17:03:35 -0500
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
References: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
Message-ID: <a835c81e0911271403vc4ad033h984118ee5d96211d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/b513525d/attachment.pl>

From mdsumner at gmail.com  Fri Nov 27 23:20:59 2009
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 28 Nov 2009 09:20:59 +1100
Subject: [R-sig-Geo] Convert kde object into spatial object
In-Reply-To: <9fb1ae890911271253s162bf75ckfd906e2f4df0e2f7@mail.gmail.com>
References: <9fb1ae890911271253s162bf75ckfd906e2f4df0e2f7@mail.gmail.com>
Message-ID: <522664f80911271420l4f41c807uc77a4c6b79f7052d@mail.gmail.com>

Here's one way:

library(ks)

data(unicef)
H.scv <- Hscv(x=unicef)
fhat <- kde(x=unicef, H=H.scv)
image(fhat$eval.points[[1]], fhat$eval.points[[2]], fhat$estimate)


library(sp)


spkde <- image2Grid(list(x = fhat$eval.points[[1]], y =
fhat$eval.points[[2]], z = fhat$estimate))
contour(spkde, add = TRUE)





On Sat, Nov 28, 2009 at 7:53 AM, Tyler Dean Rudolph
<prairie.picker at gmail.com> wrote:
> ?Is there a way to convert a kde object (ks package) into a spatial object
> (e.g. SpatialPixels, SpatialPolygons) for export into a GIS? ?Alternatively,
> is there a way to generate the 2-D spatial area underneath the 3-D
> utilisation distribution of a kde object? ?I have explored the package
> descriptions and help forums and have not yet found a solution....
>
> Tyler
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From rusers.sh at gmail.com  Sat Nov 28 04:55:31 2009
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 27 Nov 2009 22:55:31 -0500
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <dc22b2570911271559i4c6f65eax361ee201b493e9e7@mail.gmail.com>
References: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
	<a835c81e0911271403vc4ad033h984118ee5d96211d@mail.gmail.com>
	<dc22b2570911271559i4c6f65eax361ee201b493e9e7@mail.gmail.com>
Message-ID: <a835c81e0911271955h2b502306o7b2e237657664e65@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/b11c6345/attachment.pl>

From rusers.sh at gmail.com  Sat Nov 28 05:03:36 2009
From: rusers.sh at gmail.com (rusers.sh)
Date: Fri, 27 Nov 2009 23:03:36 -0500
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <a835c81e0911271955h2b502306o7b2e237657664e65@mail.gmail.com>
References: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
	<a835c81e0911271403vc4ad033h984118ee5d96211d@mail.gmail.com>
	<dc22b2570911271559i4c6f65eax361ee201b493e9e7@mail.gmail.com>
	<a835c81e0911271955h2b502306o7b2e237657664e65@mail.gmail.com>
Message-ID: <a835c81e0911272003y597830bameb505ccb3a28fab2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091127/247d01bb/attachment.pl>

From patrick.giraudoux at univ-fcomte.fr  Sat Nov 28 11:45:42 2009
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 28 Nov 2009 11:45:42 +0100
Subject: [R-sig-Geo] importing file into GRASS via QGIS
Message-ID: <4B10FF56.1010103@univ-fcomte.fr>

Dear all,

I am using QGIS 0.11.0 Metis under windows and struggle to import a 
raster into GRASS. This is an ARCINFO/ESRI grid file in natural 
coordinates (WGS84) whose heading is:

ncols  721
nrows  360
xllcorner  -180
yllcorner  -90
cellsize   0.5
NODATA_value  254

etc....

I do not meet any trouble when importing it from QGIS as a raster, nor 
within R using the package rgdal and the function readGDAL, but when 
using within QGIS the GRASS importation tools (r.in.gdal or r.in.arc), 
something goes wrong. Il looks like the vertical resolution was 
respected (0.5), but the horizontal resolution unexpectedely comes to be 
0.000693481 in decimal degrees (making the map a narrow vertical 
strip...), see the output of r.info below

I get the same result reading a geotif  from QGIS/GRASS with r.in.gdal. 
The geotif file was obtained reading the original ascii raster from R  
(everything OK), then writing it to a geotif with writeGDAL().

Any idea about what may happen ?

Patrick



----------------------------------------------------------------------------+
 | Layer:    tempave                        Date: Sat Nov 28 11:07:22 
2009    |
 | Mapset:   giraudoux                      Login of Creator: 
pgiraudo        |
 | Location: 
ChinaWGS84                                                       |
 | DataBase: U:/Documents and Settings/pgiraudo/Mes 
documents/GIS/grassdata   |
 | Title:     ( tempave 
)                                                     |
 | Timestamp: 
none                                                            |
 |----------------------------------------------------------------------------|
 |                                                                            
|
 |   Type of Map:  raster               Number of Categories: 
255             |
 |   Data Type:    
FCELL                                                      |
 |   Rows:         
360                                                        |
 |   Columns:      
721                                                        |
 |   Total Cells:  
259560                                                     |
 |        Projection: 
Latitude-Longitude                                      |
 |            N:        90N    S:        90S   Res:  
0:30                     |
 |            E:    179:30W    W:       180W   Res: 
0:00:02.496533            |
 |   Range of data:    min = 1.#QNAN0  max = 
1.#QNAN0                         |
 |                                                                            
|
 |   Data 
Description:                                                        |
 |    generated by 
r.in.gdal                                                  |
 |                                                                            
|
 |   
Comments:                                                                |
 |    r.in.gdal -o input="U:\Documents and 
Settings\pgiraudo\Bureau\TEMPER\   |
 |    AT\TEMPAVE.tif" 
output="tempave"                                        |
 |                                                                            
|
 +----------------------------------------------------------------------------+


From jaime.garcia at uni-bonn.de  Sat Nov 28 13:07:56 2009
From: jaime.garcia at uni-bonn.de (Jaime R. Garcia M.)
Date: Sat, 28 Nov 2009 13:07:56 +0100
Subject: [R-sig-Geo] importing file into GRASS via QGIS
In-Reply-To: <4B10FF56.1010103@univ-fcomte.fr>
References: <4B10FF56.1010103@univ-fcomte.fr>
Message-ID: <4B11129C.1050803@uni-bonn.de>

Patrick Giraudoux wrote:
> Dear all,
>
> I am using QGIS 0.11.0 Metis under windows and struggle to import a 
> raster into GRASS. This is an ARCINFO/ESRI grid file in natural 
> coordinates (WGS84) whose heading is:
>
> ncols  721
> nrows  360
> xllcorner  -180
> yllcorner  -90
> cellsize   0.5
> NODATA_value  254
>
> etc....
>
> I do not meet any trouble when importing it from QGIS as a raster, nor 
> within R using the package rgdal and the function readGDAL, but when 
> using within QGIS the GRASS importation tools (r.in.gdal or r.in.arc), 
> something goes wrong. Il looks like the vertical resolution was 
> respected (0.5), but the horizontal resolution unexpectedely comes to 
> be 0.000693481 in decimal degrees (making the map a narrow vertical 
> strip...), see the output of r.info below
>
> I get the same result reading a geotif  from QGIS/GRASS with 
> r.in.gdal. The geotif file was obtained reading the original ascii 
> raster from R  (everything OK), then writing it to a geotif with 
> writeGDAL().
>
> Any idea about what may happen ?
>
> Patrick
>
>
>
> ----------------------------------------------------------------------------+ 
>
> | Layer:    tempave                        Date: Sat Nov 28 11:07:22 
> 2009    |
> | Mapset:   giraudoux                      Login of Creator: 
> pgiraudo        |
> | Location: 
> ChinaWGS84                                                       |
> | DataBase: U:/Documents and Settings/pgiraudo/Mes 
> documents/GIS/grassdata   |
> | Title:     ( tempave 
> )                                                     |
> | Timestamp: 
> none                                                            |
> |----------------------------------------------------------------------------| 
>
> |                                                                            
> |
> |   Type of Map:  raster               Number of Categories: 
> 255             |
> |   Data Type:    
> FCELL                                                      |
> |   Rows:         
> 360                                                        |
> |   Columns:      
> 721                                                        |
> |   Total Cells:  
> 259560                                                     |
> |        Projection: 
> Latitude-Longitude                                      |
> |            N:        90N    S:        90S   Res:  
> 0:30                     |
> |            E:    179:30W    W:       180W   Res: 
> 0:00:02.496533            |
> |   Range of data:    min = 1.#QNAN0  max = 
> 1.#QNAN0                         |
> |                                                                            
> |
> |   Data 
> Description:                                                        |
> |    generated by 
> r.in.gdal                                                  |
> |                                                                            
> |
> |   
> Comments:                                                                
> |
> |    r.in.gdal -o input="U:\Documents and 
> Settings\pgiraudo\Bureau\TEMPER\   |
> |    AT\TEMPAVE.tif" 
> output="tempave"                                        |
> |                                                                            
> |
> +----------------------------------------------------------------------------+ 
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
Dear Patrick,

Maybe the resolution of the current region in GRASS is set to the one 
you are getting when importing rasters. One should set the right 
resolution before importing.

g.region res=0:30
r.in.gdal -o input="U:\Documents and Settings\pgiraudo\Bureau\TEMPER\ 
    AT\TEMPAVE.tif" output="tempave" 

just an idea, hope it helps...

Jaime -R.


From nikhil.list at gmail.com  Sat Nov 28 14:56:24 2009
From: nikhil.list at gmail.com (Nikhil Kaza)
Date: Sat, 28 Nov 2009 08:56:24 -0500
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <a835c81e0911272003y597830bameb505ccb3a28fab2@mail.gmail.com>
References: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
	<a835c81e0911271403vc4ad033h984118ee5d96211d@mail.gmail.com>
	<dc22b2570911271559i4c6f65eax361ee201b493e9e7@mail.gmail.com>
	<a835c81e0911271955h2b502306o7b2e237657664e65@mail.gmail.com>
	<a835c81e0911272003y597830bameb505ccb3a28fab2@mail.gmail.com>
Message-ID: <53451975-DC4F-4668-BDEA-0FA6D9A3A53C@gmail.com>

Look at this website.

http://www.carsonfarmer.com/?p=455

On 27 Nov 2009, at 11:03PM, rusers.sh wrote:

> Dear Robert,
> My method to generate the Voronoi tessellation maybe not better, You  
> can
> show me you method to get it.
>  What i want to get is the the class of SpatialPolygons(sp) based on  
> the
> generated Voronoi tessellation.
>  Any ideas or suggestions are greatly appreciated.
>
> 2009/11/27 rusers.sh <rusers.sh at gmail.com>
>
>>  Yes, what i want is really the Voronoi tessellation that you  
>> showed in
>> the link. I can generate the Voronoi tessellation  (see my codes),  
>> but my
>> problem is how to generate the the class of SpatialPolygons(sp)  
>> based on the
>> generated  Voronoi tessellation? (SHP means shape file of polygon.)
>>  Thanks a lot.
>> ####My code to get the Voronoi tessellation########
>> library(spatstat)
>> win<-owin(c(0,1),c(0,1))
>> pp <- runifpoint(10,win=win)
>> #plot(pp)
>> library(tripack)
>> vm <- voronoi.mosaic(pp$x,pp$y)
>> plot(vm)
>> par(new=T)
>> points(pp$x,pp$y,col='blue')
>> axis(1,xlim=c(0,1)) #1=below
>> axis(2,ylim=c(0,1)) #2=left
>> box(xlim=c(0,1),ylim=c(0,1))
>>
>> 2009/11/27 Robert J. Hijmans <r.hijmans at gmail.com>
>>
>> I think you want a Voronoi tessalation (diagram):
>>> http://en.wikipedia.org/wiki/Voronoi_diagram
>>>
>>> But what are SHP polygons?  Is 'SHP' a class in an R package?
>>>
>>> Robert
>>>
>>> On Fri, Nov 27, 2009 at 2:03 PM, rusers.sh <rusers.sh at gmail.com>  
>>> wrote:
>>>> To make this problem more clear. Suppose i have some points in a
>>> certain
>>>> area (e.g. 10 points in a unit square), how to cut and generate the
>>>> corresponding SHP polygons of containing the points (1 point in 1
>>> polygon,
>>>> maybe the point as their centroid) in this certain area?
>>>> In GeoDa, there is a menu "tools->shape->point  to polygon" to  
>>>> achieve
>>>> that. I wonder how to do that in R. Thanks a lot.
>>>> ##Example##
>>>> win<-owin(c(0,1),c(0,1))
>>>> pp <- runifpoint(10) #generate 10 points
>>>> #i want to change these 10 points into 10 SHP polygons,something  
>>>> like
>>> the
>>>> manipulation in GeoDA, "tools->shape->point  to polygon"
>>>> #plot(pp)
>>>>
>>>> 2009/11/27 rusers.sh <rusers.sh at gmail.com>
>>>>
>>>>> Hi,
>>>>>  I always need to convert between the points and polygons. For
>>> converting
>>>>> the polygons to points, we can use the "get.Pcent(maptools) " to  
>>>>> get
>>> the
>>>>> centroids of the polygons. But for converting points to polygons
>>> (something
>>>>> like GeoDa's "tools->shape->point  to polygon"), i cannot find the
>>>>> corresponding method. I searched in R Site Search with "point to
>>> polygon"
>>>>> and "generate polygon", but still cannot get the answers.
>>>>> Does anybody know how to convert points to the SHP polygons?
>>>>> OR whether we can generate some SHP polygons randomly in R?
>>>>> ##Example##
>>>>> win<-owin(c(0,1),c(0,1))
>>>>> pp <- runifpoint(10) #generate 10 points
>>>>> #i want to change these 10 points into 10 SHP polygons,something  
>>>>> like
>>> the
>>>>> manipulation in GeoDA, "tools->shape->point  to polygon"
>>>>> #plot(pp)
>>>>>  Thanks a lot.
>>>>>
>>>>>
>>>>> --
>>>>> -----------------
>>>>> Jane Chang
>>>>> Queen's
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> -----------------
>>>> Jane Chang
>>>> Queen's
>>>>
>>>>       [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>
>>
>>
>> --
>> -----------------
>> Jane Chang
>> Queen's
>>
>
>
>
> -- 
> -----------------
> Jane Chang
> Queen's
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Sat Nov 28 15:06:14 2009
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 28 Nov 2009 15:06:14 +0100 (CET)
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <a835c81e0911272003y597830bameb505ccb3a28fab2@mail.gmail.com>
References: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
	<a835c81e0911271403vc4ad033h984118ee5d96211d@mail.gmail.com>
	<dc22b2570911271559i4c6f65eax361ee201b493e9e7@mail.gmail.com>
	<a835c81e0911271955h2b502306o7b2e237657664e65@mail.gmail.com>
	<a835c81e0911272003y597830bameb505ccb3a28fab2@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.0911281459040.8597@reclus.nhh.no>

On Fri, 27 Nov 2009, rusers.sh wrote:

> Dear Robert,
> My method to generate the Voronoi tessellation maybe not better, You can
> show me you method to get it.
>  What i want to get is the the class of SpatialPolygons(sp) based on the
> generated Voronoi tessellation.
>  Any ideas or suggestions are greatly appreciated.

In the list archives for March 2007 (search in Nabble, for example), there 
are hints. A more up to date version might be:

set.seed(1)
crds <- cbind(runif(100), runif(100))
library(deldir)
z <- deldir(crds[,1], crds[,2])
w <- tile.list(z)
library(sp)
polys <- vector(mode="list", length=length(w))
for (i in seq(along=polys)) {
   pcrds <- cbind(w[[i]]$x, w[[i]]$y)
   pcrds <- rbind(pcrds, pcrds[1,])
   polys[[i]] <- Polygons(list(Polygon(pcrds)), ID=as.character(i))
}
SP <- SpatialPolygons(polys)
SPDF <- SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
   y=crds[,2], row.names=row.names(SP)))

plot(SPDF)
points(crds, pch=3, col="red")
text(coordinates(SPDF), label=row.names(SPDF))

then export the SpatialPolygonsDataFrame in the usual way.

By the way, to get the centroids (aka label points) for Polygons objects, 
use coordinates() on their enclosing SpatialPolygons object. The (very) 
deprecated maptools function you refered to in an earlier posting will 
cease to be available very shortly.

Hope this helps,

Roger

>
> 2009/11/27 rusers.sh <rusers.sh at gmail.com>
>
>>   Yes, what i want is really the Voronoi tessellation that you showed in
>> the link. I can generate the Voronoi tessellation  (see my codes), but my
>> problem is how to generate the the class of SpatialPolygons(sp) based on the
>> generated  Voronoi tessellation? (SHP means shape file of polygon.)
>>   Thanks a lot.
>> ####My code to get the Voronoi tessellation########
>> library(spatstat)
>> win<-owin(c(0,1),c(0,1))
>> pp <- runifpoint(10,win=win)
>> #plot(pp)
>> library(tripack)
>> vm <- voronoi.mosaic(pp$x,pp$y)
>> plot(vm)
>> par(new=T)
>> points(pp$x,pp$y,col='blue')
>> axis(1,xlim=c(0,1)) #1=below
>> axis(2,ylim=c(0,1)) #2=left
>> box(xlim=c(0,1),ylim=c(0,1))
>>
>> 2009/11/27 Robert J. Hijmans <r.hijmans at gmail.com>
>>
>> I think you want a Voronoi tessalation (diagram):
>>> http://en.wikipedia.org/wiki/Voronoi_diagram
>>>
>>> But what are SHP polygons?  Is 'SHP' a class in an R package?
>>>
>>> Robert
>>>
>>> On Fri, Nov 27, 2009 at 2:03 PM, rusers.sh <rusers.sh at gmail.com> wrote:
>>>>  To make this problem more clear. Suppose i have some points in a
>>> certain
>>>> area (e.g. 10 points in a unit square), how to cut and generate the
>>>> corresponding SHP polygons of containing the points (1 point in 1
>>> polygon,
>>>> maybe the point as their centroid) in this certain area?
>>>>  In GeoDa, there is a menu "tools->shape->point  to polygon" to achieve
>>>> that. I wonder how to do that in R. Thanks a lot.
>>>> ##Example##
>>>> win<-owin(c(0,1),c(0,1))
>>>> pp <- runifpoint(10) #generate 10 points
>>>> #i want to change these 10 points into 10 SHP polygons,something like
>>> the
>>>> manipulation in GeoDA, "tools->shape->point  to polygon"
>>>> #plot(pp)
>>>>
>>>> 2009/11/27 rusers.sh <rusers.sh at gmail.com>
>>>>
>>>>> Hi,
>>>>>   I always need to convert between the points and polygons. For
>>> converting
>>>>> the polygons to points, we can use the "get.Pcent(maptools) " to get
>>> the
>>>>> centroids of the polygons. But for converting points to polygons
>>> (something
>>>>> like GeoDa's "tools->shape->point  to polygon"), i cannot find the
>>>>> corresponding method. I searched in R Site Search with "point to
>>> polygon"
>>>>> and "generate polygon", but still cannot get the answers.
>>>>>  Does anybody know how to convert points to the SHP polygons?
>>>>>  OR whether we can generate some SHP polygons randomly in R?
>>>>> ##Example##
>>>>> win<-owin(c(0,1),c(0,1))
>>>>> pp <- runifpoint(10) #generate 10 points
>>>>> #i want to change these 10 points into 10 SHP polygons,something like
>>> the
>>>>> manipulation in GeoDA, "tools->shape->point  to polygon"
>>>>> #plot(pp)
>>>>>   Thanks a lot.
>>>>>
>>>>>
>>>>> --
>>>>> -----------------
>>>>> Jane Chang
>>>>> Queen's
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> -----------------
>>>> Jane Chang
>>>> Queen's
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>
>>
>>
>> --
>> -----------------
>> Jane Chang
>> Queen's
>>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From tom.gottfried at wzw.tum.de  Sat Nov 28 17:01:51 2009
From: tom.gottfried at wzw.tum.de (Tom Gottfried)
Date: Sat, 28 Nov 2009 17:01:51 +0100
Subject: [R-sig-Geo] importing file into GRASS via QGIS
In-Reply-To: <4B10FF56.1010103@univ-fcomte.fr>
References: <4B10FF56.1010103@univ-fcomte.fr>
Message-ID: <4B11496F.80100@wzw.tum.de>

Hi Patrick,

though this may have no effect on your problem: QGIS 0.11.0 is a very 
old version. Plus it might be more fruitful to ask on GRASS or QGIS 
lists/forums.

Tom


From patrick.giraudoux at univ-fcomte.fr  Sat Nov 28 19:48:15 2009
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 28 Nov 2009 19:48:15 +0100
Subject: [R-sig-Geo] importing file into GRASS via QGIS
In-Reply-To: <4B11129C.1050803@uni-bonn.de>
References: <4B10FF56.1010103@univ-fcomte.fr> <4B11129C.1050803@uni-bonn.de>
Message-ID: <4B11706F.7070408@univ-fcomte.fr>

Jaime R. Garcia M. a ?crit :
> Patrick Giraudoux wrote:
>> Dear all,
>>
>> I am using QGIS 0.11.0 Metis under windows and struggle to import a 
>> raster into GRASS. This is an ARCINFO/ESRI grid file in natural 
>> coordinates (WGS84) whose heading is:
>>
>> ncols  721
>> nrows  360
>> xllcorner  -180
>> yllcorner  -90
>> cellsize   0.5
>> NODATA_value  254
>>
>> etc....
>>
>> I do not meet any trouble when importing it from QGIS as a raster, 
>> nor within R using the package rgdal and the function readGDAL, but 
>> when using within QGIS the GRASS importation tools (r.in.gdal or 
>> r.in.arc), something goes wrong. Il looks like the vertical 
>> resolution was respected (0.5), but the horizontal resolution 
>> unexpectedely comes to be 0.000693481 in decimal degrees (making the 
>> map a narrow vertical strip...), see the output of r.info below
>>
>> I get the same result reading a geotif  from QGIS/GRASS with 
>> r.in.gdal. The geotif file was obtained reading the original ascii 
>> raster from R  (everything OK), then writing it to a geotif with 
>> writeGDAL().
>>
>> Any idea about what may happen ?
>>
>> Patrick
>>
>>
>>
>> ----------------------------------------------------------------------------+ 
>>
>> | Layer:    tempave                        Date: Sat Nov 28 11:07:22 
>> 2009    |
>> | Mapset:   giraudoux                      Login of Creator: 
>> pgiraudo        |
>> | Location: 
>> ChinaWGS84                                                       |
>> | DataBase: U:/Documents and Settings/pgiraudo/Mes 
>> documents/GIS/grassdata   |
>> | Title:     ( tempave 
>> )                                                     |
>> | Timestamp: 
>> none                                                            |
>> |----------------------------------------------------------------------------| 
>>
>> |                                                                            
>> |
>> |   Type of Map:  raster               Number of Categories: 
>> 255             |
>> |   Data Type:    
>> FCELL                                                      |
>> |   Rows:         
>> 360                                                        |
>> |   Columns:      
>> 721                                                        |
>> |   Total Cells:  
>> 259560                                                     |
>> |        Projection: 
>> Latitude-Longitude                                      |
>> |            N:        90N    S:        90S   Res:  
>> 0:30                     |
>> |            E:    179:30W    W:       180W   Res: 
>> 0:00:02.496533            |
>> |   Range of data:    min = 1.#QNAN0  max = 
>> 1.#QNAN0                         |
>> |                                                                            
>> |
>> |   Data 
>> Description:                                                        |
>> |    generated by 
>> r.in.gdal                                                  |
>> |                                                                            
>> |
>> |   
>> Comments:                                                                
>> |
>> |    r.in.gdal -o input="U:\Documents and 
>> Settings\pgiraudo\Bureau\TEMPER\   |
>> |    AT\TEMPAVE.tif" 
>> output="tempave"                                        |
>> |                                                                            
>> |
>> +----------------------------------------------------------------------------+ 
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> Dear Patrick,
>
> Maybe the resolution of the current region in GRASS is set to the one 
> you are getting when importing rasters. One should set the right 
> resolution before importing.
>
> g.region res=0:30
> r.in.gdal -o input="U:\Documents and Settings\pgiraudo\Bureau\TEMPER\ 
>    AT\TEMPAVE.tif" output="tempave"
> just an idea, hope it helps...
>
> Jaime -R.
>

I have just tried with  no success. Next trial will be to consider 
Robert Hijmans' suggestion regarding the number of columns. Will come 
back to the list for a report when done.

Thanks anyway for the hint,

Best,

Patrick


From patrick.giraudoux at univ-fcomte.fr  Sat Nov 28 20:13:58 2009
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sat, 28 Nov 2009 20:13:58 +0100
Subject: [R-sig-Geo] importing file into GRASS via QGIS
In-Reply-To: <dc22b2570911281014tfa826bdla3a2b1b87e481e90@mail.gmail.com>
References: <4B10FF56.1010103@univ-fcomte.fr>
	<dc22b2570911281014tfa826bdla3a2b1b87e481e90@mail.gmail.com>
Message-ID: <4B117676.5090108@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091128/675ab763/attachment.pl>

From jutesoro at yahoo.com  Sat Nov 28 22:40:00 2009
From: jutesoro at yahoo.com (Julius Tesoro)
Date: Sat, 28 Nov 2009 13:40:00 -0800 (PST)
Subject: [R-sig-Geo] extract coordinates from contour lines
Message-ID: <370811.39062.qm@web57615.mail.re1.yahoo.com>

To everyone,

Is there a way to extract coordinates or an equation from a "straight" contour line? 

Thanks.

Cheers

Julius Tesoro


From rusers.sh at gmail.com  Sun Nov 29 04:07:17 2009
From: rusers.sh at gmail.com (rusers.sh)
Date: Sat, 28 Nov 2009 22:07:17 -0500
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <alpine.LRH.2.00.0911281459040.8597@reclus.nhh.no>
References: <a835c81e0911270840l18fff44idd807bc0a92f3014@mail.gmail.com>
	<a835c81e0911271403vc4ad033h984118ee5d96211d@mail.gmail.com>
	<dc22b2570911271559i4c6f65eax361ee201b493e9e7@mail.gmail.com>
	<a835c81e0911271955h2b502306o7b2e237657664e65@mail.gmail.com>
	<a835c81e0911272003y597830bameb505ccb3a28fab2@mail.gmail.com>
	<alpine.LRH.2.00.0911281459040.8597@reclus.nhh.no>
Message-ID: <a835c81e0911281907i7ab2c9a5pdc1a0c34e472f6f9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091128/53c42141/attachment.pl>

From jutesoro at yahoo.com  Sun Nov 29 05:10:26 2009
From: jutesoro at yahoo.com (Julius Tesoro)
Date: Sat, 28 Nov 2009 20:10:26 -0800 (PST)
Subject: [R-sig-Geo] [R] extract coordinates from contour lines
In-Reply-To: <273F65B5-4574-4387-BBB5-248694746FA3@comcast.net>
Message-ID: <685881.47209.qm@web57606.mail.re1.yahoo.com>

Hi I just found the answer. I used contourLines() to extract the z values.

Thanks anyway.

--- On Sun, 11/29/09, David Winsemius <dwinsemius at comcast.net> wrote:

> From: David Winsemius <dwinsemius at comcast.net>
> Subject: Re: [R] extract coordinates from contour lines
> To: "Julius Tesoro" <jutesoro at yahoo.com>
> Cc: r-sig-geo at stat.math.ethz.ch, r-help at r-project.org
> Date: Sunday, November 29, 2009, 6:13 AM
> 
> On Nov 28, 2009, at 4:40 PM, Julius Tesoro wrote:
> 
> > To everyone,
> > 
> > Is there a way to extract coordinates or an equation
> from a "straight" contour line?
> > 
> 
> Can you set up some sort of example to offer a hint about
> what you want?
> 
> --
> David Winsemius, MD
> Heritage Laboratories
> West Hartford, CT
> 
>


From pslarson2 at gmail.com  Sun Nov 29 20:43:53 2009
From: pslarson2 at gmail.com (Pete Larson)
Date: Sun, 29 Nov 2009 14:43:53 -0500
Subject: [R-sig-Geo] Indicator Kriging R/gstat
Message-ID: <4B12CEF9.4070606@gmail.com>

Hello,

I would like to do indicator kriging in R/gstat. I have dichotomous 0/1 
data and have performed ordinary kriging and universal kriging, but get 
predctions that are far from 0 and 1.

Am I doing something wrong? Here is the code I have been using:

#### Ordinary Kriging with krige function #####
# ordinary kriging:
x <- krige(z~1, ~x+y, model = v.fit, data = estand, newd = grd)

### universal block kriging:
uk <- krige(z~x+y+DistHF+RiverDist+RiverDist2, ~x+y, model = v.fit, data 
= estand, newdata =
       grd)

Any help would be appreciated.

Pete


From edzer.pebesma at uni-muenster.de  Sun Nov 29 21:09:50 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 29 Nov 2009 21:09:50 +0100
Subject: [R-sig-Geo] Indicator Kriging R/gstat
In-Reply-To: <4B12CEF9.4070606@gmail.com>
References: <4B12CEF9.4070606@gmail.com>
Message-ID: <4B12D50E.2060808@uni-muenster.de>

Pete, for the universal kriging case I don't believe that indicator
theory allows what you want to do. See also

https://stat.ethz.ch/pipermail/r-sig-geo/2009-May/005701.html

If you disagree, could you please let me know why, or where you found
indications that this can be done?

For ordinary kriging, usually values outside [0,1] are set back to their
nearest allowed value. The degree to which they will be outside [0,1]
also depends on the variogram used -- Gaussian variograms being
notorously suspect.
--
Edzer

Pete Larson wrote:
> Hello,
>
> I would like to do indicator kriging in R/gstat. I have dichotomous
> 0/1 data and have performed ordinary kriging and universal kriging,
> but get predctions that are far from 0 and 1.
>
> Am I doing something wrong? Here is the code I have been using:
>
> #### Ordinary Kriging with krige function #####
> # ordinary kriging:
> x <- krige(z~1, ~x+y, model = v.fit, data = estand, newd = grd)
>
> ### universal block kriging:
> uk <- krige(z~x+y+DistHF+RiverDist+RiverDist2, ~x+y, model = v.fit,
> data = estand, newdata =
>       grd)
>
> Any help would be appreciated.
>
> Pete
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From sdveloz at ucdavis.edu  Sun Nov 29 23:31:57 2009
From: sdveloz at ucdavis.edu (Sam Veloz)
Date: Sun, 29 Nov 2009 16:31:57 -0600
Subject: [R-sig-Geo] plotting vector of direction magnitude
Message-ID: <4B12F65D.9070200@ucdavis.edu>

I have a file of points with x/y coordinates and columns for bearing and 
distance. I would like to make a plot where each point is depicted by an 
arrow and the direction the arrow points is based on the value of 
bearing and the length of the arrow is based on the value of distance. 
Any suggestions on how to do this would be greatly appreciated.
Thanks,
Sam

-- 
****************************************************
Sam Veloz
Postdoctoral Researcher
Department of Environmental Science and Policy
University of California, Davis
sdveloz at ucdavis.edu


From milton.ruser at gmail.com  Mon Nov 30 04:56:27 2009
From: milton.ruser at gmail.com (milton ruser)
Date: Sun, 29 Nov 2009 22:56:27 -0500
Subject: [R-sig-Geo] plotting vector of direction magnitude
In-Reply-To: <4B12F65D.9070200@ucdavis.edu>
References: <4B12F65D.9070200@ucdavis.edu>
Message-ID: <3aaf1a030911291956l773ea621y93c89e19fe374a60@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091129/ede753c7/attachment.pl>

From p.hiemstra at geo.uu.nl  Mon Nov 30 09:53:31 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 30 Nov 2009 09:53:31 +0100
Subject: [R-sig-Geo] Still error exporting ascii grid generated by DTM
 grid, please any suggestions?
In-Reply-To: <EDB94195DABE64488928DD39E53B8FC68BDFD3E900@REX2.intranet.epfl.ch>
References: <EDB94195DABE64488928DD39E53B8FC68BDFD3E900@REX2.intranet.epfl.ch>
Message-ID: <4B13880B.20100@geo.uu.nl>

Hi,

Did you try to export the data using writeGDAL (rgdal-package)? Does 
this generate the same problem?

cheers,
Paul

Tobin Cara wrote:
> Hello,
>
> I am still receiving a bizarre error:
>
> Error in write.asciigrid(data_int_ked[1], name1) : 
>   Asciigrid does not support grids with non-square cells
>
> I do not understand this as I am putting interpolated data back into the cells of an ascii DTM grid with square cells. Information on the DTM I am kriging to is below (I have combined two datasets into elev, COS7 and the Z elevation): 
>
> Thank you in advance for your help,
>
> Cara
>
>   
>> summary(elev)
>>     
> Object of class SpatialGridDataFrame
> Coordinates:
>         min      max
> X 550119.63 674619.6
> Y  79073.03 167073.0
> Is projected: NA 
> proj4string : [NA]
> Number of points: 2
> Grid attributes:
>   cellcentre.offset cellsize cells.dim
> X         550369.63      500       249
> Y          79323.03      500       176
> Data attributes:
>        Z              COS7          
>  Min.   :  380   Min.   :   -1.510  
>  1st Qu.: 1500   1st Qu.:    0.180  
>  Median : 2143   Median :    0.630  
>  Mean   : 2077   Mean   :    2.083  
>  3rd Qu.: 2663   3rd Qu.:    4.190  
>  Max.   : 4471   Max.   :    8.730  
>  NA's   :22337   NA's   :22337.000  
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   


-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From Bjarke.Christensen at sydbank.dk  Mon Nov 30 09:55:28 2009
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Mon, 30 Nov 2009 09:55:28 +0100
Subject: [R-sig-Geo] convert points into SHP polygons
In-Reply-To: <mailman.9.1259492402.11850.r-sig-geo@stat.math.ethz.ch>
Message-ID: <OF432F7A9D.4485C089-ONC125767E.00306786-C125767E.00310673@bdpnet.dk>

Jane (rusers.sh) wrote
>>>>>>  Does anybody know how to convert points to the SHP polygons?
>>>>>>  OR whether we can generate some SHP polygons randomly in R?
>>>>>> ##Example##
>>>>>> win<-owin(c(0,1),c(0,1))
>>>>>> pp <- runifpoint(10) #generate 10 points
>>>>>> #i want to change these 10 points into 10 SHP polygons,something
like

>>  What i want to get is the the class of SpatialPolygons(sp) based on the
>> generated Voronoi tessellation.
>>  Any ideas or suggestions are greatly appreciated.

Here is a quicker solution, (still using the spatstat library):
polys <- as(dirichlet(pp), 'SpatialPolygons')

dirichlet() gives you the Dirichlet/Voronoi tesselation, and as() coerces
it to SpatialPolygons, which can then be exported to a shapefile using
rgdal.

Bjarke Christensen


From p.hiemstra at geo.uu.nl  Mon Nov 30 09:59:12 2009
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Mon, 30 Nov 2009 09:59:12 +0100
Subject: [R-sig-Geo] 'Customizing' spsample
In-Reply-To: <3d1c200dd71a652f8ef5030b98dd0223.squirrel@mmp.sipr-dc.ucl.ac.be>
References: <3d1c200dd71a652f8ef5030b98dd0223.squirrel@mmp.sipr-dc.ucl.ac.be>
Message-ID: <4B138960.60500@geo.uu.nl>

Jean-Paul Kibambe Lubamba wrote:
> Hello everybody,
>
> I am using 'spsample' to derive points along a line and it works perfectly
> by doing the following :
>
> xx <- readShapeLines("line2",proj4string=CRS("+proj=utm +zone=34
> +datum=WGS84"))
> sppts <- spsample(xx, n=50, type="random")
> plot(sppts)
>
> However, I was wondering if the user can somehow 'customize' the sampling
> process, as for example, by separating sampling points by a given
> distance. And this distance being in the same units as the line. The 'n'
> argument in spsample will therefore vary according with the length of each
> line.
>
> Any help is welcome!
>
>
> Jean-Paul
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
Hi Jean-Paul,

My suggestion would be to take the function sample.Line (from sp) as a 
starting point and modify it to your specifications. You can find the 
source in the /R directory (spsample.R) of the source package, which you 
can download from CRAN.

cheers,
Paul

sample.Line
function (x, n, type, offset = runif(1), proj4string = 
CRS(as.character(NA)),
    ...)
{
    offset = offset[1]
    if (missing(n))
        n <- as.integer(NA)
    if (!is.finite(n) || n < 1)
        return(NULL)
    cc = coordinates(x)
    lengths = LineLength(cc, longlat = FALSE, sum = FALSE)
    if (any(abs(lengths) < .Machine$double.eps)) {
        wl <- which(abs(lengths) < .Machine$double.eps)
        cc <- cc[-(wl), ]
        lengths <- lengths[-(wl)]
    }
    csl = c(0, cumsum(lengths))
    maxl = csl[length(csl)]
    if (type == "random")
        pts = runif(n) * maxl
    else if (type == "stratified")
        pts = ((1:n) - runif(n))/n * maxl
    else if (type == "regular")
        pts = ((1:n) - (1 - offset))/n * maxl
    else stop(paste("type", type, "not available for Line"))
    int = findInterval(pts, csl, all.inside = TRUE)
    where = (pts - csl[int])/diff(csl)[int]
    xy = cc[int, , drop = FALSE] + where * (cc[int + 1, , drop = FALSE] -
        cc[int, , drop = FALSE])
    if (nrow(xy) < 1)
        return(NULL)
    SpatialPoints(xy, proj4string)
}
<environment: namespace:sp>



-- 
Drs. Paul Hiemstra
Department of Physical Geography
Faculty of Geosciences
University of Utrecht
Heidelberglaan 2
P.O. Box 80.115
3508 TC Utrecht
Phone:  +3130 274 3113 Mon-Tue
Phone:  +3130 253 5773 Wed-Fri
http://intamap.geo.uu.nl/~paul


From hengl at spatial-analyst.net  Mon Nov 30 13:36:18 2009
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Mon, 30 Nov 2009 13:36:18 +0100
Subject: [R-sig-Geo] Indicator Kriging R/gstat
In-Reply-To: <4B12D50E.2060808@uni-muenster.de>
References: <4B12CEF9.4070606@gmail.com> <4B12D50E.2060808@uni-muenster.de>
Message-ID: <F493D8A83858403EAC69FB4352B49409@pcibed193>


Dear Pete, Edzer,

If this is of any help, few years ago we have played with using auxiliary maps to interpolate
categorical variables (multi-indicators?). The results are reported in:

Hengl T., Toomanian N., Reuter H.I., Malakouti M.J. 2007. Methods to interpolate soil categorical
variables from profile observations: lessons from Iran. Geoderma, 140(4): 417-427.
http://dx.doi.org/10.1016/j.geoderma.2007.04.022 

Experiences were frustrating. Many (most of) classes come in isolated patches; hence getting
something out from the variograms was difficult (close to pure nugget). In addition, if you go ahead
and interpolate the 0/1 values (ignoring binomial properties), you will produce values <0 and >1
i.e. nonsense values.

Then we tried with using memberships and things changed. First, memberships you can simply convert
to logits, then interpolate and back-transform and then none of the values will be outside the 0-1
range. It was also much easier to fit the variograms. But we had a luxury that soils are fuzzy
classes per definition and we had extra data to 'fuzzify' the A, B, C values to memberships (in fact
we discovered that surveyors should have designated memberships from the beginning - this solves all
problems of transition classes etc).

Here is a similar type of approach (fit a GLM with a binomial model, interpolate the residuals using
OK) with the meuse dataset:

> data(meuse)
> coordinates(meuse) <- ~x+y
> data(meuse.grid)
> coordinates(meuse.grid) <- ~x+y
> gridded(meuse.grid) <- TRUE
> fullgrid(meuse.grid) <- TRUE
> meuse.ov <- overlay(meuse.grid, meuse)
> meuse.ov at data <- cbind(meuse.ov at data, meuse[c("zinc", "lime")]@data)
# fit a GLM:
> glm.lime <- glm(lime~dist+ffreq, meuse.ov, family=binomial(link="logit"))
> step.lime <- step(glm.lime)
# check if the predictions are within 0-1 range:
> summary(round(step.lime$fitted.values, 2))
# convert to logits:
> logits.lime <- log(step.lime$fitted.values/(1-step.lime$fitted.values))
# predict at all locations:
> p.glm <- predict(glm.lime, newdata=meuse.grid, type="link", se.fit=T) 
# predictions as logits
> str(p.glm)
# attach spatial reference:
> lime.glm <- as(meuse.grid, "SpatialPointsDataFrame")
> lime.glm$lime <- p.glm$fit
> gridded(lime.glm) <- TRUE
> lime.glm <- as(lime.glm, "SpatialGridDataFrame")
# fit a variogram for residuals:
> lime.ivgm <- vgm(nugget=0, model="Exp", range=sqrt(diff(meuse at bbox["x",])^2 +
diff(meuse at bbox["y",])^2)/4, psill=var(residuals(step.lime)))
> lime.rvgm <- fit.variogram(variogram(residuals(step.lime)~1, meuse.ov), model=lime.ivgm)
# does not work - singular model; fix by hand:
> lime.rvgm <- vgm(nugget=0.6, "Exp", psill=0.2, range=500)
# interpolate residuals (logits):
> lime.rk <- krige(residuals(step.lime)~1, meuse.ov, meuse.grid, lime.rvgm)
# add predicted trend and residuals:
> lime.rk$var1.rk <- lime.glm$lime + lime.rk$var1.pred
# back-transform logits to the original response scale (0,1):
> lime.rk$var1.rko <- exp(lime.rk$var1.rk)/(1+exp(lime.rk$var1.rk))
> spplot(lime.rk["var1.rko"], scales=list(draw=T), at=seq(0.05,1,0.05),
col.regions=grey(rev(seq(0,0.95,0.05))), main="Liming requirements", sp.layout=list("sp.points",
col="black", meuse))
> write.asciigrid(lime.rk["var1.rko"], "lime_rk.asc", na.value=-1)

Another thing you should look at is the geoRglm package (it has a function "binom.krige" to work
with binomial data), but as far as I remember - I could not get it running. Maybe you should dig
into that and then contact the authors if you need more help.

HTH,

T. Hengl
http://home.medewerker.uva.nl/t.hengl/ 



> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf
> Of Edzer Pebesma
> Sent: Sunday, November 29, 2009 9:10 PM
> To: Pete Larson
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] Indicator Kriging R/gstat
> 
> Pete, for the universal kriging case I don't believe that indicator
> theory allows what you want to do. See also
> 
> https://stat.ethz.ch/pipermail/r-sig-geo/2009-May/005701.html
> 
> If you disagree, could you please let me know why, or where you found
> indications that this can be done?
> 
> For ordinary kriging, usually values outside [0,1] are set back to their
> nearest allowed value. The degree to which they will be outside [0,1]
> also depends on the variogram used -- Gaussian variograms being
> notorously suspect.
> --
> Edzer
> 
> Pete Larson wrote:
> > Hello,
> >
> > I would like to do indicator kriging in R/gstat. I have dichotomous
> > 0/1 data and have performed ordinary kriging and universal kriging,
> > but get predctions that are far from 0 and 1.
> >
> > Am I doing something wrong? Here is the code I have been using:
> >
> > #### Ordinary Kriging with krige function #####
> > # ordinary kriging:
> > x <- krige(z~1, ~x+y, model = v.fit, data = estand, newd = grd)
> >
> > ### universal block kriging:
> > uk <- krige(z~x+y+DistHF+RiverDist+RiverDist2, ~x+y, model = v.fit,
> > data = estand, newdata =
> >       grd)
> >
> > Any help would be appreciated.
> >
> > Pete
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi), University of M?nster
> Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
> 8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
> http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From field at mail.fpg.unc.edu  Mon Nov 30 15:10:37 2009
From: field at mail.fpg.unc.edu (Sam Field)
Date: Mon, 30 Nov 2009 09:10:37 -0500
Subject: [R-sig-Geo] Assessing residual spatial autocorrelation in a
 Poisson or Negative Binomial model
In-Reply-To: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
References: <4B0E5C88.8030002@sphsu.mrc.ac.uk>
Message-ID: <4B13D25D.6030208@mail.fpg.unc.edu>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091130/d58f031c/attachment.html>

From edzer.pebesma at uni-muenster.de  Mon Nov 30 16:05:20 2009
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 30 Nov 2009 16:05:20 +0100
Subject: [R-sig-Geo] Collocated Cokriging of snow height data
In-Reply-To: <web-21438754@idmailbe2b.unizh.ch>
References: <web-21438754@idmailbe2b.unizh.ch>
Message-ID: <4B13DF30.5060104@uni-muenster.de>



Stefan Zollinger wrote:
> Hi
>
> I am trying to spatially interpolate snow height data of about 100
> stations in a mountain range. In addition, I have a large DEM (SRTM,
> 90 meters resolution, 2.5 million cells) which also serves as an
> interpolation raster (just like meuse.grid). As the snow height and
> the height above sea level correlate strongly, I intend to use
> collocated cokriging to improve the estimation, which is why I studied
> the example in "Applied Spatial Data Analysis with R" by Roger Bivand,
> Edzer Pebesma and Virgilio G?mez-Rubio.
>
> I have the following questions (especially to the authors):
>
> 1. Why and how is the new attribute "distn" being calculated? Would it
> not be sufficient to use the existing attribute "dist" for the
> collocated cokriging (as it shows the same variogram-model properties)?
it is translated such that it has the same mean as the primary variable,
log(zinc). This is a requirement for collocated (ordinary) cokriging.
>
> 2. How are the two variogram-models "vd.fit" and "vx.fit" being
> calculated out of "v.fit"? I understand that the range and the type of
> the three models remains the same, but how are the sills and nuggets
> being changed?
It is assumed here that dist(n) has the same variogram form as the
primary variable, but scaled with the variance of distn. It should be
noted that in collocted cokriging, only the direct correlation between
zinc and dist is relevant, the (rest of) the distn direct variogram and
cross variogram are ignored in the equations.
>
> 3. How would the calculation of "vd.fit" and " vx.fit" change if a
> trend model was used, like "log(zinc) ~ sqrt(dist)"?
Well, this is a completely different concept: regression instead of
correlation. (Collocated) cokriging assumes zinc and dist are two random
variables, that have a particular (spatial and cross) correlation.
Universal kriging assumes zinc is related to dist through a regression
relationship, implying that dist is non-random but fixed and known, and
zinc is random. It's apples and oranges, really.
>
>
> Any advice or help will be highly appreciated
I can see that this section of the book is indeed very dense;
introductions to collocated cokriging are (IIRC) Pierre Goovaerts book
and perhaps GSLIB literature. Wackernagel's book is also very brief on it.
>
> Stefan Zollinger
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763 http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9 e.pebesma at wwu.de


From sdveloz at ucdavis.edu  Mon Nov 30 16:35:52 2009
From: sdveloz at ucdavis.edu (Samuel Veloz)
Date: Mon, 30 Nov 2009 09:35:52 -0600
Subject: [R-sig-Geo] plotting vector of direction magnitude
In-Reply-To: <4B13622D.1020400@bitwrit.com.au>
References: <4B13622D.1020400@bitwrit.com.au>
Message-ID: <afa5c2d40911300735q6b3fd9b1i3a522269640cc154@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20091130/3ce26fc2/attachment.pl>

From ashton at msu.edu  Mon Nov 30 17:09:41 2009
From: ashton at msu.edu (Ashton Shortridge)
Date: Mon, 30 Nov 2009 11:09:41 -0500
Subject: [R-sig-Geo] Collocated Cokriging of snow height data
In-Reply-To: <4B13DF30.5060104@uni-muenster.de>
References: <web-21438754@idmailbe2b.unizh.ch>
	<4B13DF30.5060104@uni-muenster.de>
Message-ID: <200911301109.41953.ashton@msu.edu>

On Monday 30 November 2009 10:05:20 Edzer Pebesma wrote:
> Stefan Zollinger wrote:
> > > Any advice or help will be highly appreciated
> 
> I can see that this section of the book is indeed very dense;
> introductions to collocated cokriging are (IIRC) Pierre Goovaerts book
> and perhaps GSLIB literature. Wackernagel's book is also very brief on it.

Hi,

I'd second looking at Pierre Goovaerts' Geostatistics for Natural Resources 
Evaluation (1997). Chapter 6 discusses the use of secondary information in 
kriging, and includes a lengthy section on colocated cokriging. As Edzer 
suggests, this is a very rich but difficult section of the geostatistics corpus, 
but it is more and more relevant due to the growing amount of secondary 
geographic information.

Yours,

Ashton

On Monday 30 November 2009 10:05:20 Edzer Pebesma wrote:
> Stefan Zollinger wrote:
> > Hi
> >
> > I am trying to spatially interpolate snow height data of about 100
> > stations in a mountain range. In addition, I have a large DEM (SRTM,
> > 90 meters resolution, 2.5 million cells) which also serves as an
> > interpolation raster (just like meuse.grid). As the snow height and
> > the height above sea level correlate strongly, I intend to use
> > collocated cokriging to improve the estimation, which is why I studied
> > the example in "Applied Spatial Data Analysis with R" by Roger Bivand,
> > Edzer Pebesma and Virgilio G?mez-Rubio.
> >
> > I have the following questions (especially to the authors):
> >
> > 1. Why and how is the new attribute "distn" being calculated? Would it
> > not be sufficient to use the existing attribute "dist" for the
> > collocated cokriging (as it shows the same variogram-model properties)?
> 
> it is translated such that it has the same mean as the primary variable,
> log(zinc). This is a requirement for collocated (ordinary) cokriging.
> 
> > 2. How are the two variogram-models "vd.fit" and "vx.fit" being
> > calculated out of "v.fit"? I understand that the range and the type of
> > the three models remains the same, but how are the sills and nuggets
> > being changed?
> 
> It is assumed here that dist(n) has the same variogram form as the
> primary variable, but scaled with the variance of distn. It should be
> noted that in collocted cokriging, only the direct correlation between
> zinc and dist is relevant, the (rest of) the distn direct variogram and
> cross variogram are ignored in the equations.
> 
> > 3. How would the calculation of "vd.fit" and " vx.fit" change if a
> > trend model was used, like "log(zinc) ~ sqrt(dist)"?
> 
> Well, this is a completely different concept: regression instead of
> correlation. (Collocated) cokriging assumes zinc and dist are two random
> variables, that have a particular (spatial and cross) correlation.
> Universal kriging assumes zinc is related to dist through a regression
> relationship, implying that dist is non-random but fixed and known, and
> zinc is random. It's apples and oranges, really.
> 
> > Any advice or help will be highly appreciated
> 
> I can see that this section of the book is indeed very dense;
> introductions to collocated cokriging are (IIRC) Pierre Goovaerts book
> and perhaps GSLIB literature. Wackernagel's book is also very brief on it.
> 
> > Stefan Zollinger
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Ashton Shortridge
Associate Professor			ashton at msu.edu
Dept of Geography			http://www.msu.edu/~ashton
235 Geography Building		ph (517) 432-3561
Michigan State University		fx (517) 432-1671


