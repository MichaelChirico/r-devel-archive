From ziv@n@k@r@m@n @ending from gm@il@com  Sun Jul  1 02:21:57 2018
From: ziv@n@k@r@m@n @ending from gm@il@com (Zivan Karaman)
Date: Sat, 30 Jun 2018 20:21:57 -0400
Subject: [R-sig-Geo] 
 Converting Map Grid Australia to Geographic coordinates
In-Reply-To: <CANq0wq5RJNnTJuAkVt6ukeusnu78p77fgv4jpU=mzpujDu_vwQ@mail.gmail.com>
References: <CANq0wq5RJNnTJuAkVt6ukeusnu78p77fgv4jpU=mzpujDu_vwQ@mail.gmail.com>
Message-ID: <F132B252-8046-487D-8ACD-A70FFCD0C2F1@gmail.com>

Brian,
You could hava a look at spTransform function in rgdal package.
Regards,
Zivan


> On 30 Jun 2018, at 15:55, Brian Williams <bjw649 at gmail.com> wrote:
> 
> Does anybody know of a package which can convert MGA coordinates to
> Geographic (lat/longs) ?
> 
> Thanks
> 
> Brian
> 
>    [[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From y@l@@@ef@ @ending from gm@il@com  Sun Jul  1 12:05:11 2018
From: y@l@@@ef@ @ending from gm@il@com (Yalemzewod Gelaw)
Date: Sun, 1 Jul 2018 20:05:11 +1000
Subject: [R-sig-Geo] Fwd: Spatiotemporal analysis r command
In-Reply-To: <CAFoeBZ=fS3XyyZ9hSNhtsP5g1bNhs2BHbYru-Pus6fAKy0bsnw@mail.gmail.com>
References: <CAFoeBZ=fS3XyyZ9hSNhtsP5g1bNhs2BHbYru-Pus6fAKy0bsnw@mail.gmail.com>
Message-ID: <CAFoeBZ=E4nvAEzKyJoS4VpmXpg3h-rGe-n70_=H8LV2izK0q2Q@mail.gmail.com>

Hello everyone,
I am planning to do a spatiotemporal distribution of hiv/tb coinfection and
the effects of socio-demographic variables. I have a shapefile for 128
districts.  For this ecological area  analysis I am planning to use
Bayesian Poisson regression analysis.
?I here with looking for your help tutorial/notes/ r commands for the
spatiotemporal analysis and Bayesian Poisson regression.?

?Thank you for any help.?

*Regards, *

Yalem
-- 
Best, Yalemzewod Assefa Gelaw (Yalem)

	[[alternative HTML version deleted]]


From @loboli@t@@ @ending from gm@il@com  Mon Jul  2 13:35:59 2018
From: @loboli@t@@ @ending from gm@il@com (Agustin Lobo)
Date: Mon, 2 Jul 2018 12:35:59 +0100
Subject: [R-sig-Geo] intersections to individual polygons
In-Reply-To: <dcc8724a-c5a9-3cb2-d84d-982a396da17a@auckland.ac.nz>
References: <CAG4NReJodevNNhVeVoodaRejfDjFCb3962NNtBpX5A_2fijDeQ@mail.gmail.com>
 <dcc8724a-c5a9-3cb2-d84d-982a396da17a@auckland.ac.nz>
Message-ID: <CAG4NReKY4dWupSuAZc=s5-OOLCXnkBV2+cHHTVO-9FVc+X_Vjg@mail.gmail.com>

Mimicking your vignette:

require(rgdal)
require(raster)
require(spatstat)
require(rgeos)
require(maptools)

dzfile <-"https://www.dropbox.com/s/xxujcwqy3ec21sa/TDM1_DEM__04_S63W062_epsg32720.zip?dl=0"
download.file(dzfile,"TDM1_DEM__04_S63W062_epsg32720.zip",method="wget")
unzip("TDM1_DEM__04_S63W062_epsg32720.zip")
v <- readOGR(dsn="TDM1_DEM__04_S63W062_epsg32720",
             layer="TDM1_DEM__04_S63W062_epsg32720", stringsAsFactors = FALSE)
plot(v)
p <- slot(v, "polygons")
p2 <- lapply(p, function(x) { SpatialPolygons(list(x)) })
w <- lapply(p2, as.owin) #maptools required

te <- tess(tiles=w)
class(te)
plot.tess(te,do.labels=TRUE)

But this is still the original polygons,
not the mosaic of polygon parts I'm looking for.
Would I need to go doing all possible intersections and then
adding the "A not B" and "B not A" parts for all possible pairs?

Or is there a function in spatstat to convert "te" into a tesselation
of adjacent polygons?

Thanks



On Thu, Jun 28, 2018 at 2:02 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
> On 29/06/18 00:51, Agustin Lobo wrote:
>
>> Given an SpatialPolygons DF with i.e. 2 intersecting polygons, A and
>> ,B,  is there a function
>> that would split the original polygons into "onlyA", "onlyB" and
>> "AintersectingB" polygons?
>
>
> You can do this easily in spatstat by converting your polygons to "owin"
> objects.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From m@uricio@z@mbr@no @ending from ufronter@@cl  Mon Jul  2 18:25:55 2018
From: m@uricio@z@mbr@no @ending from ufronter@@cl (Mauricio Zambrano Bigiarini)
Date: Mon, 2 Jul 2018 12:25:55 -0400
Subject: [R-sig-Geo] Fwd: Spatiotemporal analysis r command
In-Reply-To: <CAFoeBZ=E4nvAEzKyJoS4VpmXpg3h-rGe-n70_=H8LV2izK0q2Q@mail.gmail.com>
References: <CAFoeBZ=fS3XyyZ9hSNhtsP5g1bNhs2BHbYru-Pus6fAKy0bsnw@mail.gmail.com>
 <CAFoeBZ=E4nvAEzKyJoS4VpmXpg3h-rGe-n70_=H8LV2izK0q2Q@mail.gmail.com>
Message-ID: <CAP6VarvUhet=3yRNeBurbuuFCJqyOa1yX-bk-VKpvbn2+gnqaQ@mail.gmail.com>

https://www.r-project.org/posting-guide.html

IHTH




Mauricio Zambrano-Bigiarini, PhD

=====================================
Department of Civil Engineering
Faculty of Engineering and Sciences
Universidad de La Frontera, Temuco, Chile
http://hzambran.github.io/
=====================================
mailto : mauricio.zambrano at ufrontera.cl
work-phone : +56 45 259 2812
=====================================
"Focus is about saying No" (Steve Jobs)
=====================================
Linux user #454569 -- Linux Mint user


On 1 July 2018 at 06:05, Yalemzewod Gelaw <yalassefa at gmail.com> wrote:
> Hello everyone,
> I am planning to do a spatiotemporal distribution of hiv/tb coinfection and
> the effects of socio-demographic variables. I have a shapefile for 128
> districts.  For this ecological area  analysis I am planning to use
> Bayesian Poisson regression analysis.
> I here with looking for your help tutorial/notes/ r commands for the
> spatiotemporal analysis and Bayesian Poisson regression.
>
> Thank you for any help.
>
> *Regards, *
>
> Yalem
> --
> Best, Yalemzewod Assefa Gelaw (Yalem)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
La informaci?n contenida en este correo electr?nico y cualquier anexo o 
respuesta relacionada, puede contener datos e informaci?n confidencial y no 
puede ser usada o difundida por personas distintas a su(s) destinatario(s). 
Si usted no es el destinatario de esta comunicaci?n, le informamos que 
cualquier divulgaci?n, distribuci?n o copia de esta informaci?n constituye 
un delito conforme a la ley chilena. Si lo ha recibido por error, por favor 
borre el mensaje y todos sus anexos y notifique al remitente.


From r@turner @ending from @uckl@nd@@c@nz  Tue Jul  3 03:07:25 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Tue, 3 Jul 2018 13:07:25 +1200
Subject: [R-sig-Geo] intersections to individual polygons
In-Reply-To: <CAG4NReKY4dWupSuAZc=s5-OOLCXnkBV2+cHHTVO-9FVc+X_Vjg@mail.gmail.com>
References: <CAG4NReJodevNNhVeVoodaRejfDjFCb3962NNtBpX5A_2fijDeQ@mail.gmail.com>
 <dcc8724a-c5a9-3cb2-d84d-982a396da17a@auckland.ac.nz>
 <CAG4NReKY4dWupSuAZc=s5-OOLCXnkBV2+cHHTVO-9FVc+X_Vjg@mail.gmail.com>
Message-ID: <432980a8-4a26-c4f6-d78e-9a8efe6a9bf5@auckland.ac.nz>


Agustin:

I have attached a function that I think does what you want.
It returns either a tessellation (if you leave tess=TRUE) or
a list of owin objects otherwise.

I *think* that attachments with .R extensions make it through to the 
list.  The attachment should at least get through to Agustin (who is
the person of central interest!).

It produces all non-empty intersections between sets of tiles
in the tessellation argument "ttt".  If singles=TRUE (the default)
these "intersections" include the tiles themselves.  Otherwise
at least two tiles are involved in each intersection.

E.g.

x1 <- allIntersections(te) # a tessellation
x2 <- allIntersections(te,tess=FALSE) # a list of windows
x3 <- allIntersections(te,singles=FALSE) # tiles themselves omitted.

Note that the code includes a work-around for an infelicity in
in intersect.owin().  This infelicity will very likely be fixed
in a future release of spatstat.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 02/07/18 23:35, Agustin Lobo wrote:
> Mimicking your vignette:
> 
> require(rgdal)
> require(raster)
> require(spatstat)
> require(rgeos)
> require(maptools)
> 
> dzfile <-"https://www.dropbox.com/s/xxujcwqy3ec21sa/TDM1_DEM__04_S63W062_epsg32720.zip?dl=0"
> download.file(dzfile,"TDM1_DEM__04_S63W062_epsg32720.zip",method="wget")
> unzip("TDM1_DEM__04_S63W062_epsg32720.zip")
> v <- readOGR(dsn="TDM1_DEM__04_S63W062_epsg32720",
>               layer="TDM1_DEM__04_S63W062_epsg32720", stringsAsFactors = FALSE)
> plot(v)
> p <- slot(v, "polygons")
> p2 <- lapply(p, function(x) { SpatialPolygons(list(x)) })
> w <- lapply(p2, as.owin) #maptools required
> 
> te <- tess(tiles=w)
> class(te)
> plot.tess(te,do.labels=TRUE)
> 
> But this is still the original polygons,
> not the mosaic of polygon parts I'm looking for.
> Would I need to go doing all possible intersections and then
> adding the "A not B" and "B not A" parts for all possible pairs?
> 
> Or is there a function in spatstat to convert "te" into a tesselation
> of adjacent polygons?
> 
> Thanks
> 
> 
> 
> On Thu, Jun 28, 2018 at 2:02 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> On 29/06/18 00:51, Agustin Lobo wrote:
>>
>>> Given an SpatialPolygons DF with i.e. 2 intersecting polygons, A and
>>> ,B,  is there a function
>>> that would split the original polygons into "onlyA", "onlyB" and
>>> "AintersectingB" polygons?
>>
>>
>> You can do this easily in spatstat by converting your polygons to "owin"
>> objects.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: allIntersections.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180703/1a9b7f2c/attachment.ksh>

From @dri@n@b@ddeley @ending from curtin@edu@@u  Tue Jul  3 05:44:13 2018
From: @dri@n@b@ddeley @ending from curtin@edu@@u (Adrian Baddeley)
Date: Tue, 3 Jul 2018 03:44:13 +0000
Subject: [R-sig-Geo] intersections to individual polygons
In-Reply-To: <432980a8-4a26-c4f6-d78e-9a8efe6a9bf5@auckland.ac.nz>
References: <CAG4NReJodevNNhVeVoodaRejfDjFCb3962NNtBpX5A_2fijDeQ@mail.gmail.com>
 <dcc8724a-c5a9-3cb2-d84d-982a396da17a@auckland.ac.nz>
 <CAG4NReKY4dWupSuAZc=s5-OOLCXnkBV2+cHHTVO-9FVc+X_Vjg@mail.gmail.com>,
 <432980a8-4a26-c4f6-d78e-9a8efe6a9bf5@auckland.ac.nz>
Message-ID: <ME1PR01MB0659A87E19546D901A37A076A4420@ME1PR01MB0659.ausprd01.prod.outlook.com>

Agustin Lobo writes:


>>> Given an SpatialPolygons DF with i.e. 2 intersecting polygons, A and B,
>>> is there a function that would split the original polygons into "onlyA", "onlyB" and
>>> "AintersectingB" polygons?


First convert the SpatialPolygons to spatstat 'owin' objects using as.owin.


If there are two polygons A and B, you can just use intersect.owin and setminus.owin to get what you want:

      AandB <- intersect.owin(A, B )

      AnotB <- setminus.owin(A, B )

      BnotA <- setminus.owin(B, A)


If there are several windows, make a list P containing the windows.

Then call

     Z <- kaleido(P)

     plot(Z, do.col=TRUE)

using the following code. The result Z is a tessellation. Extract the individual pieces as tiles(Z).


      kaleido <- function(P) {

           U <- union.owin(as.solist(P))

            V <- lapply(P, onesplit, U=U)

            Z <- Reduce(intersect.tess, V)

            return(Z)

      }

      onesplit <- function(X, U) tess(tiles=list(A=X, NotA=setminus.owin(U, X)), W=U)



Prof Adrian Baddeley DSc FAA

John Curtin Distinguished Professor

Department of Mathematics and Statistics

Curtin University, Perth, Western Australia



	[[alternative HTML version deleted]]


From chino_tone@ @ending from hotm@il@com  Wed Jul  4 18:14:31 2018
From: chino_tone@ @ending from hotm@il@com (Joelle k. Akram)
Date: Wed, 4 Jul 2018 16:14:31 +0000
Subject: [R-sig-Geo] How to use gstat 'variogram' function for nonlinear
 formulae?
Message-ID: <YQXPR0101MB1397E6F476B341C5994FC30290410@YQXPR0101MB1397.CANPRD01.PROD.OUTLOOK.COM>

Dear all,


For a linear model I use the 'variogram' function in gstat as follows:


coordinates(data) <- c('x','y')
myvario <- variogram(dep~var1+var2+var3, data)

Now, I have the following Nonlinear formula that I want to use in variogram.

dep~ var1*var2^3


My 2 questions are:

i) Can the variogram function in gstat handle nonlinear models as this formula?

ii) What is the syntax to use this nonlinear formulae within the variogram function? is it simply :

myvario <- variogram(dep~ var1*var2^3, data)

Any advice is appeciated.


cheers

Chris Akram



	[[alternative HTML version deleted]]


From edzer@pebe@m@ @ending from uni-muen@ter@de  Wed Jul  4 18:28:21 2018
From: edzer@pebe@m@ @ending from uni-muen@ter@de (Edzer Pebesma)
Date: Wed, 4 Jul 2018 18:28:21 +0200
Subject: [R-sig-Geo] How to use gstat 'variogram' function for nonlinear
 formulae?
In-Reply-To: <YQXPR0101MB1397E6F476B341C5994FC30290410@YQXPR0101MB1397.CANPRD01.PROD.OUTLOOK.COM>
References: <YQXPR0101MB1397E6F476B341C5994FC30290410@YQXPR0101MB1397.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <c44bd54f-c3c9-9845-488f-fdb8376fc164@uni-muenster.de>



On 07/04/2018 06:14 PM, Joelle k. Akram wrote:
> Dear all,
> 
> 
> For a linear model I use the 'variogram' function in gstat as follows:
> 
> 
> coordinates(data) <- c('x','y')
> myvario <- variogram(dep~var1+var2+var3, data)
> 
> Now, I have the following Nonlinear formula that I want to use in variogram.
> 
> dep~ var1*var2^3

This is still a linear model.

> 
> 
> My 2 questions are:
> 
> i) Can the variogram function in gstat handle nonlinear models as this formula?
> 
> ii) What is the syntax to use this nonlinear formulae within the variogram function? is it simply :
> 
> myvario <- variogram(dep~ var1*var2^3, data)

I think that like in other areas of R you'll have to use

myvario <- variogram(dep~ var1*I(var2)^3, data)

Note that the * will be interpreted as indicating you want main effects
and an interaction, not simply the product of var1*var3^3; see ?formula

> 
> Any advice is appeciated.
> 
> 
> cheers
> 
> Chris Akram
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From brun@e@ti @ending from gm@il@com  Thu Jul  5 08:34:00 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Thu, 5 Jul 2018 08:34:00 +0200
Subject: [R-sig-Geo] Kriging and Spatio temporal kriging on air quality data
Message-ID: <CAFnjcD39OL4z24bQMZ42jUbRXWb8i1okd-4B8bzJ6O9izdcVRg@mail.gmail.com>

Hi, I am using kriging and spatio temporal kriging for studying and
analyzing air quality data from mobile sensors.
I would like to ask some question about the following issues:
1) is possible to gave the same values scale to different kriging result
(maps from different measures in the same study area). That is if I have a
kriging map with values in the range of 0-20 and another map with values in
the range of 5-30, can I gave to both the maps a values (and colours) scale
in the range of 0-30, in order to compare the values from the two maps.
2) is there some particular package and or tecnique specifically indicated
to make spatial kriging from air quality data from mobile sensor.

Kind regards.

	[[alternative HTML version deleted]]


From d@ve@gregovich @ending from @l@@k@@gov  Fri Jul  6 18:22:48 2018
From: d@ve@gregovich @ending from @l@@k@@gov (Gregovich, Dave P (DFG))
Date: Fri, 6 Jul 2018 16:22:48 +0000
Subject: [R-sig-Geo] Distance from not NA cells in a raster
Message-ID: <MW2PR0901MB2330CE0B2302911D488BD50EEB470@MW2PR0901MB2330.namprd09.prod.outlook.com>

Hi,
I would like to obtain the distance from all not NA cells in a raster. This works for smaller rasters, but seems difficult for the size of rasters (~ 8000 pixel square)  I am working with.
Below is what I've tried. I would be OK calling other software from R, or using some parallelization, if it might help.
Thanks so much for your help!  If I could just calculate this distance in two hours or less (or so) I would be satisfied.
Dave.

rm(list=ls())
library(raster)

#make raster
rast <- raster(nrow = 8000, ncol = 8000, ext = extent(0,1,0,1))

#generate cells to calculate distance from.
rast[sample(8000^2, 10000)] <- 1

#try two different methods...
dist1 <- gridDistance(rast, origin = 1)#throws an error after x minutes
#'Error: cannot allocate vector of size 3.8 Gb'
dist2 <- distance(rast)#ran all night, R was hung up in the morning and had to force shutdown.

___________________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Division of Wildlife Conservation
802 3rd Street
Douglas, AK 99824
907-465-4291
___________________________________________


	[[alternative HTML version deleted]]


From d@ve@gregovich @ending from @l@@k@@gov  Fri Jul  6 19:47:48 2018
From: d@ve@gregovich @ending from @l@@k@@gov (Gregovich, Dave P (DFG))
Date: Fri, 6 Jul 2018 17:47:48 +0000
Subject: [R-sig-Geo] Distance from not NA cells in a raster
Message-ID: <MW2PR0901MB2330EEE84EA1468C2E501784EB470@MW2PR0901MB2330.namprd09.prod.outlook.com>

Sorry, I forgot to include session info to associate my issue...thanks!
> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

other attached packages:
[1] RSAGA_1.2.0    plyr_1.8.4     shapefiles_0.7 foreign_0.8-69 gstat_1.1-6    rgdal_1.2-16
[7] raster_2.6-7   sp_1.2-5


From: Gregovich, Dave P (DFG)
Sent: Friday, July 06, 2018 8:23 AM
To: 'r-sig-geo at r-project.org'
Subject: Distance from not NA cells in a raster

Hi,
I would like to obtain the distance from all not NA cells in a raster. This works for smaller rasters, but seems difficult for the size of rasters (~ 8000 pixel square)  I am working with.
Below is what I've tried. I would be OK calling other software from R, or using some parallelization, if it might help.
Thanks so much for your help!  If I could just calculate this distance in two hours or less (or so) I would be satisfied.
Dave.

rm(list=ls())
library(raster)

#make raster
rast <- raster(nrow = 8000, ncol = 8000, ext = extent(0,1,0,1))

#generate cells to calculate distance from.
rast[sample(8000^2, 10000)] <- 1

#try two different methods...
dist1 <- gridDistance(rast, origin = 1)#throws an error after x minutes
#'Error: cannot allocate vector of size 3.8 Gb'
dist2 <- distance(rast)#ran all night, R was hung up in the morning and had to force shutdown.

___________________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Division of Wildlife Conservation
802 3rd Street
Douglas, AK 99824
907-465-4291
___________________________________________


	[[alternative HTML version deleted]]


From kn@ik95 @ending from gm@il@com  Fri Jul  6 23:30:43 2018
From: kn@ik95 @ending from gm@il@com (Krushil Naik)
Date: Fri, 6 Jul 2018 17:30:43 -0400
Subject: [R-sig-Geo] geom_contour
Message-ID: <CAM8MRF00Z7M1j5O1dzykvF=7mZ8dQH26U7nK0CjH-fDV_DwaSw@mail.gmail.com>

Hi, I'm trying to generate a contour plot from a data set I have in Excel
showing how a given set of three of the 8 columns/categories are related to
each other. I pulled out three arbitrary columns using the subset function,
but I'm kinda lost with what to do from there.

Lets say I have this subset:

      x       y       z
-------------------------
      7       6      5.3
      1     3.14   4.0
      5      2.7    6.1

How would I plot a contour graph of the subset? Is that even possible?
Thanks.

	[[alternative HTML version deleted]]


From @xel@urbiz @ending from gm@il@com  Sun Jul  8 13:52:27 2018
From: @xel@urbiz @ending from gm@il@com (Axel Urbiz)
Date: Sun, 8 Jul 2018 07:52:27 -0400
Subject: [R-sig-Geo] Spatial clustering with spdep::skater
Message-ID: <A33B7BD8-3D56-4DFC-B034-C48E2FA127E1@gmail.com>

Dear Experts, 

My apologies in advance as this is more a statistical question, rather than an R programming question, but hope you can point me in the right direction. 

I?m working with spdep::skater to fit clusters to spatial data subject to contiguity constraints. This function fits clusters by edge removal from Minimum Spanning Trees. 

In this context, I?d appreciate any pointers on how to tune the number of clusters. What is a sensible criteria to use?

Thanks,
Axel.

From eli@@kr@in@ki @ending from gm@il@com  Mon Jul  9 14:22:32 2018
From: eli@@kr@in@ki @ending from gm@il@com (Elias T Krainski)
Date: Mon, 9 Jul 2018 09:22:32 -0300
Subject: [R-sig-Geo] Spatial clustering with spdep::skater
In-Reply-To: <A33B7BD8-3D56-4DFC-B034-C48E2FA127E1@gmail.com>
References: <A33B7BD8-3D56-4DFC-B034-C48E2FA127E1@gmail.com>
Message-ID: <d4b5e8db-fd17-abf1-75e1-385d73a744dd@gmail.com>

Hi Axel,

The original paper suggests to look at the SSW decay. You can visualize 
it easily as it is returned in the output from skater().

Best,

Elias


On 08/07/18 08:52, Axel Urbiz wrote:
> Dear Experts,
>
> My apologies in advance as this is more a statistical question, rather than an R programming question, but hope you can point me in the right direction.
>
> I?m working with spdep::skater to fit clusters to spatial data subject to contiguity constraints. This function fits clusters by edge removal from Minimum Spanning Trees.
>
> In this context, I?d appreciate any pointers on how to tune the number of clusters. What is a sensible criteria to use?
>
> Thanks,
> Axel.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From W@de@A@W@ll @ending from erdc@dren@mil  Mon Jul  9 15:44:41 2018
From: W@de@A@W@ll @ending from erdc@dren@mil (Wall, Wade A ERDC-RDE-CERL-IL CIV)
Date: Mon, 9 Jul 2018 13:44:41 +0000
Subject: [R-sig-Geo] Memory issues using raster::subs
Message-ID: <C1524BE4BF45454293B8DF38FB9B5ECA011BA5C1BA@MS-EX1VKS.erdc.dren.mil>

Hi all,

I am having issues with using the subs function in the raster package. In the past, I have successfully used the function to reclassify a raster, but now when I try to use it, I am receiving the error " Error: cannot allocate vector of size 2.0 Gb". The code is the same as what I had used before with a larger raster and data.frame. 

For example, this code works:

segments = raster(D:/path/To/InputRaster.tif) ### objects raster
obj_predicted = data.frame(zone,predicted)
filename="D:/path/To/Raster.tif"
subs(segments,obj_predicted,by=1,which=2,filename=filename,progress="text")

The segments raster is of size 71026 by 78701. obj_predicted is a 1,693,839 X 2 column data frame, with each row of the first column of the data frame corresponding to a pixel value in the segments raster. 

However, when I replace the segments raster with another raster that is 14157 by 11923  and the obj_predicted data frame is 6588 x 2, I receive the error message. The crs of both rasters is the same, both data frames are essentially the same etc. 

Sorry that I can't really provide the data to attempt reproduction. Any help would be appreciated. I am going to attempt to process by block, but this seems 

Wade


From Fr@nci@@Freire @ending from @gu@@e  Tue Jul 10 13:20:59 2018
From: Fr@nci@@Freire @ending from @gu@@e (Francis Freire)
Date: Tue, 10 Jul 2018 11:20:59 +0000
Subject: [R-sig-Geo] converting from MSL EGM2008 to RH2000
Message-ID: <11fea5edb1684c7fbfc02515a3043e5c@sgu.se>


Hi,

I am particularly new to R and would like to ask a question. I have looking all over the net for a way to convert the vertical reference system of our z values in our xyz text file from MSL EGM2008 to RH2000 using R. Has anyone done this before or can point me in the right directions?

Best,

Francis

From N@then@H@rp @ending from dot@ny@gov  Tue Jul 10 14:45:36 2018
From: N@then@H@rp @ending from dot@ny@gov (Harp, Nathen (DOT))
Date: Tue, 10 Jul 2018 12:45:36 +0000
Subject: [R-sig-Geo] converting from MSL EGM2008 to RH2000
In-Reply-To: <11fea5edb1684c7fbfc02515a3043e5c@sgu.se>
References: <11fea5edb1684c7fbfc02515a3043e5c@sgu.se>
Message-ID: <MWHPR09MB22568A1C08455F4148FE1F58D15B0@MWHPR09MB2256.namprd09.prod.outlook.com>

I don't believe R has geodetic packages but that is what you need.  See NGS for examples,,
https://www.ngs.noaa.gov/PC_PROD/pc_prod.shtml
________________________________
From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Francis Freire <Francis.Freire at sgu.se>
Sent: Tuesday, July 10, 2018 7:20:59 AM
To: 'r-sig-geo at r-project.org'
Subject: [R-sig-Geo] converting from MSL EGM2008 to RH2000

ATTENTION: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.


Hi,

I am particularly new to R and would like to ask a question. I have looking all over the net for a way to convert the vertical reference system of our z values in our xyz text file from MSL EGM2008 to RH2000 using R. Has anyone done this before or can point me in the right directions?

Best,

Francis
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Tue Jul 10 15:14:09 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Tue, 10 Jul 2018 15:14:09 +0200
Subject: [R-sig-Geo] converting from MSL EGM2008 to RH2000
In-Reply-To: <MWHPR09MB22568A1C08455F4148FE1F58D15B0@MWHPR09MB2256.namprd09.prod.outlook.com>
References: <11fea5edb1684c7fbfc02515a3043e5c@sgu.se>
 <MWHPR09MB22568A1C08455F4148FE1F58D15B0@MWHPR09MB2256.namprd09.prod.outlook.com>
Message-ID: <alpine.LFD.2.21.1807101512000.20776@reclus.nhh.no>

On Tue, 10 Jul 2018, Harp, Nathen (DOT) via R-sig-Geo wrote:

> I don't believe R has geodetic packages but that is what you need.  See NGS for examples,,
> https://www.ngs.noaa.gov/PC_PROD/pc_prod.shtml

While this is currently the case, we hope that PROJ >=5 will make this 
possible - for now please also consider using PROJ command line tools with 
geodetic pipelines, maybe ask on the proj list, and keep everyone 
informed!

Roger

> ________________________________
> From: R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Francis Freire <Francis.Freire at sgu.se>
> Sent: Tuesday, July 10, 2018 7:20:59 AM
> To: 'r-sig-geo at r-project.org'
> Subject: [R-sig-Geo] converting from MSL EGM2008 to RH2000
>
> ATTENTION: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.
>
>
> Hi,
>
> I am particularly new to R and would like to ask a question. I have looking all over the net for a way to convert the vertical reference system of our z values in our xyz text file from MSL EGM2008 to RH2000 using R. Has anyone done this before or can point me in the right directions?
>
> Best,
>
> Francis
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From dechen@lh@m @ending from ieu@uzh@ch  Tue Jul 10 19:46:21 2018
From: dechen@lh@m @ending from ieu@uzh@ch (Dechen Lham)
Date: Tue, 10 Jul 2018 19:46:21 +0200
Subject: [R-sig-Geo] Spatial autocorrelation help
Message-ID: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>

Hello all,

I would like some help in my problem below:

I am running a logistic regression and my best model residuals has spatial autocorrelation  (SAC) when checked as below and also on the raw data of the response type. My response is binary 0 and 1 (type of prey and to be predicted by several predictors). These type of prey are obtained from  a total of  200 locations (where the faecal samples are collected from).   In order to account for this SAC , I used the auto_covdist function from spdep package. But when i use this as a new predictor in my model, and then check for spatial autocorrelation in the residues of the model, there is still spatial autocorrelation,?..could u see if i am doing something wrong please?

#account for SAC in the model using weights
# auto_covariate is a distance weighted covariate
data$response <- as.numeric(data$response)
auto_weight <- autocov_dist(data$prey.type, xy=coords, nbs=1, type="inverse", zero.policy = TRUE,style="W", longlat = TRUE)

m5_auto <- glm(response ~  predictor1 + predictor2 + predictor3 + predictor4 + predictor1:predictor4, weight=auto_weight, family=quasibinomial("logit"), data=data)

# check spatial autocorrelation - first convert data to spatial points dataframe
dat <- SpatialPointsDataFrame(cbind(data$long, data$lat), data)
lstw  <- nb2listw(knn2nb(knearneigh(dat, k = 2)))

# check SAC in model residuals
moran.test(residuals.glm(m5_auto), lstw) # and gives the below:

Moran I test under randomisation

data:  residuals.glm(m5)  
weights: lstw  

Moran I statistic standard deviate = 1.9194, p-value = 0.02747
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
     0.160824328      -0.004608295       0.007428642 

-Someone said its stupid to account for spatial autocorrelation in a logistic regression when you have a significant SAC using moran?s I. So i am now wondering how this can be solved? or does a SAC in a logistic regression be just ignored? 

I am new to spatial statistics and now idea how to move with such. I only know that my data has spatial
 autocorrelation (which i hope to have checked correctly using morans I as above) and now need to account for this in my analysis. Some advice would be greatly appreciated by people who have used to account for SAC in their logistic models.  Is a logistic mixed models an option to consider?especially if your covariates are spatial in nature,?i read somewhere that if you cant account for SAC in glm then you can move to mixed models esp if your covariates are spatial which is expected to digest the SAC. 

Help and advice would be greatly appreciated.


From p@trick@@chr@tz @ending from gm@il@com  Tue Jul 10 20:38:26 2018
From: p@trick@@chr@tz @ending from gm@il@com (Patrick Schratz)
Date: Tue, 10 Jul 2018 20:38:26 +0200
Subject: [R-sig-Geo] Spatial autocorrelation help
In-Reply-To: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>
References: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>
Message-ID: <1531247501.local-c5e9d1a7-7905-v1.2.2-96fb3a99@getmailspring.com>

Hi Dechen,

it is very important to account for SAC in any model. This can be done in various ways. In log.reg it is common to include spatial autocorrelation structures that describe the underlying SAC. To do so, you can use mixed models, e.g. MASS::glmmPQL().
Also have a look at Wood (2017) Generalized Additive Models in R.
I did account for it in my master thesis.Even though the code is not attached, it may help you: https://zenodo.org/record/814262
Cheers, Patrick
On Jul 10 2018, at 7:46 pm, Dechen Lham <dechen.lham at ieu.uzh.ch> wrote:
>
> Hello all,
> I would like some help in my problem below:
> I am running a logistic regression and my best model residuals has spatial autocorrelation (SAC) when checked as below and also on the raw data of the response type. My response is binary 0 and 1 (type of prey and to be predicted by several predictors). These type of prey are obtained from a total of 200 locations (where the faecal samples are collected from). In order to account for this SAC , I used the auto_covdist function from spdep package. But when i use this as a new predictor in my model, and then check for spatial autocorrelation in the residues of the model, there is still spatial autocorrelation,?..could u see if i am doing something wrong please?
> #account for SAC in the model using weights
> # auto_covariate is a distance weighted covariate
> data$response <- as.numeric(data$response)
> auto_weight <- autocov_dist(data$prey.type, xy=coords, nbs=1, type="inverse", zero.policy = TRUE,style="W", longlat = TRUE)
>
> m5_auto <- glm(response ~ predictor1 + predictor2 + predictor3 + predictor4 + predictor1:predictor4, weight=auto_weight, family=quasibinomial("logit"), data=data)
> # check spatial autocorrelation - first convert data to spatial points dataframe
> dat <- SpatialPointsDataFrame(cbind(data$long, data$lat), data)
> lstw <- nb2listw(knn2nb(knearneigh(dat, k = 2)))
>
> # check SAC in model residuals
> moran.test(residuals.glm(m5_auto), lstw) # and gives the below:
>
> Moran I test under randomisation
> data: residuals.glm(m5)
> weights: lstw
>
> Moran I statistic standard deviate = 1.9194, p-value = 0.02747
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic Expectation Variance
> 0.160824328 -0.004608295 0.007428642
>
> -Someone said its stupid to account for spatial autocorrelation in a logistic regression when you have a significant SAC using moran?s I. So i am now wondering how this can be solved? or does a SAC in a logistic regression be just ignored?
> I am new to spatial statistics and now idea how to move with such. I only know that my data has spatial
> autocorrelation (which i hope to have checked correctly using morans I as above) and now need to account for this in my analysis. Some advice would be greatly appreciated by people who have used to account for SAC in their logistic models. Is a logistic mixed models an option to consider?especially if your covariates are spatial in nature,?i read somewhere that if you cant account for SAC in glm then you can move to mixed models esp if your covariates are spatial which is expected to digest the SAC.
>
> Help and advice would be greatly appreciated.
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


	[[alternative HTML version deleted]]


From dechen@lh@m @ending from ieu@uzh@ch  Tue Jul 10 21:57:58 2018
From: dechen@lh@m @ending from ieu@uzh@ch (Dechen Lham)
Date: Tue, 10 Jul 2018 21:57:58 +0200
Subject: [R-sig-Geo] Spatial autocorrelation help
In-Reply-To: <1531247501.local-c5e9d1a7-7905-v1.2.2-96fb3a99@getmailspring.com>
References: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>
 <1531247501.local-c5e9d1a7-7905-v1.2.2-96fb3a99@getmailspring.com>
Message-ID: <E6291F79-3D2E-4DC4-B74B-E8C457648E9A@ieu.uzh.ch>

Hi Patrick

Thank you for your quick response and i went through your thesis and its very useful information. One thing that i was wondering was, you could potentially also use quadratic terms of the predictors which may have non-linear relation with the response variable right? rather than to use GAMM.

Besides i need to still figure out how to check the SAC correctly in my data as there is the global morans I and a local morans I right? Further need to figure out how to plot them correctly to see the patterns. I did make a correlogram of the raw data and from the residuals of the best model but both looked very similar and also after accounting for SAC, the morans I was significant and SAC was not accounted for. So it would be great if you can see I am doing something wrong while accepting for the SAC below?please


regards


> On 10 Jul 2018, at 8:38 PM, Patrick Schratz <patrick.schratz at gmail.com> wrote:
> 
> Hi Dechen,
> 
> it is very important to account for SAC in any model. This can be done in various ways. In log.reg it is common to include spatial autocorrelation structures that describe the underlying SAC. To do so, you can use mixed models, e.g. MASS::glmmPQL().
> 
> Also have a look at Wood (2017) Generalized Additive Models in R.
> 
> I did account for it in my master thesis.Even though the code is not attached, it may help you: https://zenodo.org/record/814262 <https://zenodo.org/record/814262>
> Cheers, Patrick
> On Jul 10 2018, at 7:46 pm, Dechen Lham <dechen.lham at ieu.uzh.ch> wrote:
> 
> Hello all,
> 
> I would like some help in my problem below:
> 
> I am running a logistic regression and my best model residuals has spatial autocorrelation (SAC) when checked as below and also on the raw data of the response type. My response is binary 0 and 1 (type of prey and to be predicted by several predictors). These type of prey are obtained from a total of 200 locations (where the faecal samples are collected from). In order to account for this SAC , I used the auto_covdist function from spdep package. But when i use this as a new predictor in my model, and then check for spatial autocorrelation in the residues of the model, there is still spatial autocorrelation,?..could u see if i am doing something wrong please?
> 
> #account for SAC in the model using weights
> # auto_covariate is a distance weighted covariate
> data$response <- as.numeric(data$response)
> auto_weight <- autocov_dist(data$prey.type, xy=coords, nbs=1, type="inverse", zero.policy = TRUE,style="W", longlat = TRUE)
> 
> m5_auto <- glm(response ~ predictor1 + predictor2 + predictor3 + predictor4 + predictor1:predictor4, weight=auto_weight, family=quasibinomial("logit"), data=data)
> 
> # check spatial autocorrelation - first convert data to spatial points dataframe
> dat <- SpatialPointsDataFrame(cbind(data$long, data$lat), data)
> lstw <- nb2listw(knn2nb(knearneigh(dat, k = 2)))
> 
> # check SAC in model residuals
> moran.test(residuals.glm(m5_auto), lstw) # and gives the below:
> 
> Moran I test under randomisation
> 
> data: residuals.glm(m5)
> weights: lstw
> 
> Moran I statistic standard deviate = 1.9194, p-value = 0.02747
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic Expectation Variance
> 0.160824328 -0.004608295 0.007428642
> 
> -Someone said its stupid to account for spatial autocorrelation in a logistic regression when you have a significant SAC using moran?s I. So i am now wondering how this can be solved? or does a SAC in a logistic regression be just ignored?
> 
> I am new to spatial statistics and now idea how to move with such. I only know that my data has spatial
> autocorrelation (which i hope to have checked correctly using morans I as above) and now need to account for this in my analysis. Some advice would be greatly appreciated by people who have used to account for SAC in their logistic models. Is a logistic mixed models an option to consider?especially if your covariates are spatial in nature,?i read somewhere that if you cant account for SAC in glm then you can move to mixed models esp if your covariates are spatial which is expected to digest the SAC.
> 
> Help and advice would be greatly appreciated.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From orcunmor@li @ending from gm@il@com  Wed Jul 11 19:01:58 2018
From: orcunmor@li @ending from gm@il@com (Orcun Morali)
Date: Wed, 11 Jul 2018 20:01:58 +0300
Subject: [R-sig-Geo] Spatial autocorrelation help
In-Reply-To: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>
References: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>
Message-ID: <f52726f6-a364-fe9d-ff0d-2bdf9b7354b8@gmail.com>

Hi Dechen,

As for measuring spatial autocorrelation, one thing I noticed about your 
output is that you are using the randomization assumption in 
spdep::moran.test. Randomization assumption is not appropriate for 
Moran's I of regression residuals and spdep::lm.morantest is the 
function to correctly calculate moments of the measure for regression 
residuals anyway. Before using lm.morantest though, if I were you, I 
would check whether its inference applies to logistic regression 
residuals as well, since the theory was initially based on the classical 
regression.

As for fitting a spatial logistic model if you need it, McSpatial 
package in R might help you.

Best Regards,

Orcun

On 10/07/18 20:46, Dechen Lham wrote:
> Hello all,
>
> I would like some help in my problem below:
>
> I am running a logistic regression and my best model residuals has spatial autocorrelation  (SAC) when checked as below and also on the raw data of the response type. My response is binary 0 and 1 (type of prey and to be predicted by several predictors). These type of prey are obtained from  a total of  200 locations (where the faecal samples are collected from).   In order to account for this SAC , I used the auto_covdist function from spdep package. But when i use this as a new predictor in my model, and then check for spatial autocorrelation in the residues of the model, there is still spatial autocorrelation,?..could u see if i am doing something wrong please?
>
> #account for SAC in the model using weights
> # auto_covariate is a distance weighted covariate
> data$response <- as.numeric(data$response)
> auto_weight <- autocov_dist(data$prey.type, xy=coords, nbs=1, type="inverse", zero.policy = TRUE,style="W", longlat = TRUE)
>
> m5_auto <- glm(response ~  predictor1 + predictor2 + predictor3 + predictor4 + predictor1:predictor4, weight=auto_weight, family=quasibinomial("logit"), data=data)
>
> # check spatial autocorrelation - first convert data to spatial points dataframe
> dat <- SpatialPointsDataFrame(cbind(data$long, data$lat), data)
> lstw  <- nb2listw(knn2nb(knearneigh(dat, k = 2)))
>
> # check SAC in model residuals
> moran.test(residuals.glm(m5_auto), lstw) # and gives the below:
>
> Moran I test under randomisation
>
> data:  residuals.glm(m5)
> weights: lstw
>
> Moran I statistic standard deviate = 1.9194, p-value = 0.02747
> alternative hypothesis: greater
> sample estimates:
> Moran I statistic       Expectation          Variance
>       0.160824328      -0.004608295       0.007428642
>
> -Someone said its stupid to account for spatial autocorrelation in a logistic regression when you have a significant SAC using moran?s I. So i am now wondering how this can be solved? or does a SAC in a logistic regression be just ignored?
>
> I am new to spatial statistics and now idea how to move with such. I only know that my data has spatial
>   autocorrelation (which i hope to have checked correctly using morans I as above) and now need to account for this in my analysis. Some advice would be greatly appreciated by people who have used to account for SAC in their logistic models.  Is a logistic mixed models an option to consider?especially if your covariates are spatial in nature,?i read somewhere that if you cant account for SAC in glm then you can move to mixed models esp if your covariates are spatial which is expected to digest the SAC.
>
> Help and advice would be greatly appreciated.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From dechen@lh@m @ending from ieu@uzh@ch  Thu Jul 12 13:44:02 2018
From: dechen@lh@m @ending from ieu@uzh@ch (Dechen Lham)
Date: Thu, 12 Jul 2018 13:44:02 +0200
Subject: [R-sig-Geo] Spatial autocorrelation help
In-Reply-To: <f52726f6-a364-fe9d-ff0d-2bdf9b7354b8@gmail.com>
References: <448E53F2-7C18-42A5-BF51-1618EF24712C@ieu.uzh.ch>
 <f52726f6-a364-fe9d-ff0d-2bdf9b7354b8@gmail.com>
Message-ID: <BD916057-E1B1-4E9C-86EA-76E6823EA2EE@ieu.uzh.ch>

Hi Orcun

I am not quite sure if im doing this correctly but I do understand that i first need to check spatial autocorrelation occurs in my data. so i did this below steps and after that checked it again in best model residuals

# Another approach to find SAC by creating neighbors first, then get distances between each point and neighbors, then
# inverse the distance and then check the SAC using mora's I
coord <- cbind(data$long, data$lat)
coords <- coordinates(coord)

# creates a matrix of nn indexes - knearneigh to get nearest neighbors
nn5 <- knearneigh(coords, k=5)  
mi5.nlist <- knn2nb(nn5, row.names = NULL, sym=FALSE)

# creates a sp weights matrix
mi5.sw <- nb2listw(mi5.nlist) 

# cal moran's I using distance as weights
# calculates the distance
mi5.dist <- nbdists(mi5.nlist, coords) 

# now invert the distnace to determine weights (closer =higher)
mi5.dist1 <- lapply(mi5.dist, function(x){ifelse(is.finite(1/x), (1/x), (1/0.001))})
mi5.dist2 <- lapply(mi5.dist, function(x){ifelse(is.finite(1/x^2), (1/x^2), (1/0.001^2))})

# check the distance between the distribution
summary(unlist(mi5.dist1)) 

# now create sp weights matrix weighted on distance
mi5.d1sw <- nb2listw(mi5.nlist, glist=mi5.dist1)
mi5.d2sw <- nb2listw(mi5.nlist, glist=mi5.dist2)

# morans test
moran.test(as.numeric(data$response), mi5.d1sw)
moran.test(as.numeric(data$response), mi5.d2sw)

This first moran?s test gives :
Moran I statistic standard deviate = 2.0328, p-value = 0.02104
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
      0.105850408      -0.004608295       0.002952729 

Second morans test gives:

Moran I statistic standard deviate = 2.3848, p-value = 0.008545
alternative hypothesis: greater
sample estimates:
Moran I statistic       Expectation          Variance 
      0.154097396      -0.004608295       0.004428848 

And both indicates presence of spatial autocorrelation in the raw data.

Should i account for this in all models or if i perform logistic mixed model it is fine??help is much appreciated. Difficult to understand what the problem is and how to solve it



> On 11 Jul 2018, at 7:01 PM, Orcun Morali <orcunmorali at gmail.com> wrote:
> 
> Hi Dechen,
> 
> As for measuring spatial autocorrelation, one thing I noticed about your output is that you are using the randomization assumption in spdep::moran.test. Randomization assumption is not appropriate for Moran's I of regression residuals and spdep::lm.morantest is the function to correctly calculate moments of the measure for regression residuals anyway. Before using lm.morantest though, if I were you, I would check whether its inference applies to logistic regression residuals as well, since the theory was initially based on the classical regression.
> 
> As for fitting a spatial logistic model if you need it, McSpatial package in R might help you.
> 
> Best Regards,
> 
> Orcun
> 
> On 10/07/18 20:46, Dechen Lham wrote:
>> Hello all,
>> 
>> I would like some help in my problem below:
>> 
>> I am running a logistic regression and my best model residuals has spatial autocorrelation  (SAC) when checked as below and also on the raw data of the response type. My response is binary 0 and 1 (type of prey and to be predicted by several predictors). These type of prey are obtained from  a total of  200 locations (where the faecal samples are collected from).   In order to account for this SAC , I used the auto_covdist function from spdep package. But when i use this as a new predictor in my model, and then check for spatial autocorrelation in the residues of the model, there is still spatial autocorrelation,?..could u see if i am doing something wrong please?
>> 
>> #account for SAC in the model using weights
>> # auto_covariate is a distance weighted covariate
>> data$response <- as.numeric(data$response)
>> auto_weight <- autocov_dist(data$prey.type, xy=coords, nbs=1, type="inverse", zero.policy = TRUE,style="W", longlat = TRUE)
>> 
>> m5_auto <- glm(response ~  predictor1 + predictor2 + predictor3 + predictor4 + predictor1:predictor4, weight=auto_weight, family=quasibinomial("logit"), data=data)
>> 
>> # check spatial autocorrelation - first convert data to spatial points dataframe
>> dat <- SpatialPointsDataFrame(cbind(data$long, data$lat), data)
>> lstw  <- nb2listw(knn2nb(knearneigh(dat, k = 2)))
>> 
>> # check SAC in model residuals
>> moran.test(residuals.glm(m5_auto), lstw) # and gives the below:
>> 
>> Moran I test under randomisation
>> 
>> data:  residuals.glm(m5)
>> weights: lstw
>> 
>> Moran I statistic standard deviate = 1.9194, p-value = 0.02747
>> alternative hypothesis: greater
>> sample estimates:
>> Moran I statistic       Expectation          Variance
>>      0.160824328      -0.004608295       0.007428642
>> 
>> -Someone said its stupid to account for spatial autocorrelation in a logistic regression when you have a significant SAC using moran?s I. So i am now wondering how this can be solved? or does a SAC in a logistic regression be just ignored?
>> 
>> I am new to spatial statistics and now idea how to move with such. I only know that my data has spatial
>>  autocorrelation (which i hope to have checked correctly using morans I as above) and now need to account for this in my analysis. Some advice would be greatly appreciated by people who have used to account for SAC in their logistic models.  Is a logistic mixed models an option to consider?especially if your covariates are spatial in nature,?i read somewhere that if you cant account for SAC in glm then you can move to mixed models esp if your covariates are spatial which is expected to digest the SAC.
>> 
>> Help and advice would be greatly appreciated.
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From btupper @ending from bigelow@org  Thu Jul 12 14:12:28 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Thu, 12 Jul 2018 08:12:28 -0400
Subject: [R-sig-Geo] Distance from not NA cells in a raster
In-Reply-To: <MW2PR0901MB2330CE0B2302911D488BD50EEB470@MW2PR0901MB2330.namprd09.prod.outlook.com>
References: <MW2PR0901MB2330CE0B2302911D488BD50EEB470@MW2PR0901MB2330.namprd09.prod.outlook.com>
Message-ID: <F955428E-97F8-4A65-BF3C-C9C80F9733D4@bigelow.org>

Hi,

You may have solved this already, but I get tripped up on the "the distance from all not NA cells in a raster".  Is it the distance each NA cell is from each non-NA cell?  Also, I'm wondering why you want to know the distance to ALL non-NA cells - what is your big-picture purpose for wanting these distances?  

Cheers,
Ben

> On Jul 6, 2018, at 12:22 PM, Gregovich, Dave P (DFG) <dave.gregovich at alaska.gov> wrote:
> 
> Hi,
> I would like to obtain the distance from all not NA cells in a raster. This works for smaller rasters, but seems difficult for the size of rasters (~ 8000 pixel square)  I am working with.
> Below is what I've tried. I would be OK calling other software from R, or using some parallelization, if it might help.
> Thanks so much for your help!  If I could just calculate this distance in two hours or less (or so) I would be satisfied.
> Dave.
> 
> rm(list=ls())
> library(raster)
> 
> #make raster
> rast <- raster(nrow = 8000, ncol = 8000, ext = extent(0,1,0,1))
> 
> #generate cells to calculate distance from.
> rast[sample(8000^2, 10000)] <- 1
> 
> #try two different methods...
> dist1 <- gridDistance(rast, origin = 1)#throws an error after x minutes
> #'Error: cannot allocate vector of size 3.8 Gb'
> dist2 <- distance(rast)#ran all night, R was hung up in the morning and had to force shutdown.
> 
> ___________________________________________
> Dave Gregovich
> Research Analyst
> Alaska Department of Fish and Game
> Division of Wildlife Conservation
> 802 3rd Street
> Douglas, AK 99824
> 907-465-4291
> ___________________________________________
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From bl250604 @ending from muhlenberg@edu  Thu Jul 12 21:00:13 2018
From: bl250604 @ending from muhlenberg@edu (Benjamin Lieberman)
Date: Thu, 12 Jul 2018 15:00:13 -0400
Subject: [R-sig-Geo] How to find all first order neighbors of a collection
 of points
Message-ID: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>

Hi all,

Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair. I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data. 

While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.

There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest. 

Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.

# Create a data frame of 10 voters, picked at random
voter.1 = c(1, -75.52187, 40.62320)
voter.2 = c(2,-75.56373, 40.55216)
voter.3 = c(3,-75.39587, 40.55416)
voter.4 = c(4,-75.42248, 40.64326)
voter.5 = c(5,-75.56654, 40.54948)
voter.6 = c(6,-75.56257, 40.67375)
voter.7 = c(7, -75.51888, 40.59715)
voter.8 = c(8, -75.59879, 40.60014)
voter.9 = c(9, -75.59879, 40.60014)
voter.10 = c(10, -75.50877, 40.53129)

# Bind the vectors together
voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)

# Rename the columns
colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")

# Change the class from a matrix to a data frame
voter.subset = as.data.frame(voter.subset)

# Load in the required packages
library(spdep)
library(sp)

# Set the coordinates
coordinates(voter.subset) = c("Longitude", "Latitude")
coords = coordinates(voter.subset)

# Jitter to ensure no duplicate points
coords = jitter(coords, factor = 1)

# Find the first nearest neighbor of each point
one.nn = knearneigh(coords, k=1)

# Convert the first nearest neighbor to format "nb"
one.nn_nb = knn2nb(one.nn, sym = F)

Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.

Warmest,
Ben
--
Benjamin Lieberman
Muhlenberg College 2019
Mobile: 301.299.8928



	[[alternative HTML version deleted]]


From f@cundo@munoz @ending from cir@d@fr  Fri Jul 13 11:32:04 2018
From: f@cundo@munoz @ending from cir@d@fr (=?UTF-8?Q?Facundo_Mu=c3=b1oz?=)
Date: Fri, 13 Jul 2018 11:32:04 +0200
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
Message-ID: <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>

Dear Benjamin,

I'm not sure how you define "first order neighbors" for a point. The
first thing that comes to my mind is to use their corresponding voronoi
polygons and define neighborhood from there. Following your code:

v <- dismo::voronoi(coords)
par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
plot(coords, type = "n", xlab = NA, ylab = NA)
plot(v, add = TRUE)
text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
plot(coords, type = "n", xlab = NA, ylab = NA)
plot(poly2nb(v), coords, add = TRUE, col = "gray")

?acu.-


On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
> Hi all,
>
> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair. I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data. 
>
> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>
> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest. 
>
> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
>
> # Create a data frame of 10 voters, picked at random
> voter.1 = c(1, -75.52187, 40.62320)
> voter.2 = c(2,-75.56373, 40.55216)
> voter.3 = c(3,-75.39587, 40.55416)
> voter.4 = c(4,-75.42248, 40.64326)
> voter.5 = c(5,-75.56654, 40.54948)
> voter.6 = c(6,-75.56257, 40.67375)
> voter.7 = c(7, -75.51888, 40.59715)
> voter.8 = c(8, -75.59879, 40.60014)
> voter.9 = c(9, -75.59879, 40.60014)
> voter.10 = c(10, -75.50877, 40.53129)
>
> # Bind the vectors together
> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>
> # Rename the columns
> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>
> # Change the class from a matrix to a data frame
> voter.subset = as.data.frame(voter.subset)
>
> # Load in the required packages
> library(spdep)
> library(sp)
>
> # Set the coordinates
> coordinates(voter.subset) = c("Longitude", "Latitude")
> coords = coordinates(voter.subset)
>
> # Jitter to ensure no duplicate points
> coords = jitter(coords, factor = 1)
>
> # Find the first nearest neighbor of each point
> one.nn = knearneigh(coords, k=1)
>
> # Convert the first nearest neighbor to format "nb"
> one.nn_nb = knn2nb(one.nn, sym = F)
>
> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>
> Warmest,
> Ben
> --
> Benjamin Lieberman
> Muhlenberg College 2019
> Mobile: 301.299.8928
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Jul 13 12:11:35 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 13 Jul 2018 12:11:35 +0200
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
Message-ID: <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>

On Fri, 13 Jul 2018, Facundo Mu?oz wrote:

> Dear Benjamin,
>
> I'm not sure how you define "first order neighbors" for a point. The
> first thing that comes to my mind is to use their corresponding voronoi
> polygons and define neighborhood from there. Following your code:

Thanks, the main source of confusion is that "first order neighbors" are 
not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi 
neighbours, or sphere of influence etc. So reading vignette("nb") would be 
a starting point.

Also note that voronoi and other graph-based neighbours should only use 
planar coordinates - including dismo::voronoi, which uses deldir::deldir() 
- just like spdep::tri2nb(). Triangulation can lead to spurious neighbours 
on the convex hull.

>
> v <- dismo::voronoi(coords)
> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
> plot(coords, type = "n", xlab = NA, ylab = NA)
> plot(v, add = TRUE)
> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
> plot(coords, type = "n", xlab = NA, ylab = NA)
> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>
> ?acu.-
>
>
> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>> Hi all,
>>
>> Currently, I am working with U.S. voter data. Below, I included a brief 
>> example of the structure of the data with some reproducible code. My 
>> data set consists of roughly 233,000 (233k) entries, each specifying a 
>> voter and their particular latitude/longitude pair.

Using individual voter data is highly dangerous, and must in every case be 
subject to the strictest privacy rules. Voter data does not in essence 
have position - the only valid voting data that has position is of the 
voting station/precinct, and those data are aggregated to preserve 
anonymity.

Why does position and voter data not have position? Which location should 
you use - residence, workplace, what? What are these locations proxying? 
Nothing valid can be drawn from "just voter data" - you can get 
conclusions from carefully constructed stratified exit polls, but there 
the key gender/age/ethnicity/social class/etc. confounders are handled by 
design. Why should voting decisions be influenced by proximity (they are 
not)? The missing element here is looking carefully at relevant covariates 
at more aggregated levels (in the US typically zoning controlling social 
class positional segregation, etc.).

>> I have been using the spdep package with the hope of creating a CAR 
>> model. To begin the analysis, we need to find all first order neighbors 
>> of every point in the data.
>>
>> While spdep has fantastic commands for finding k nearest neighbors 
>> (knearneigh), and a useful command for finding lag of order 3 or more 
>> (nblag), I have yet to find a method which is suitable for our purposes 
>> (lag = 1, or lag =2). Additionally, I looked into altering the nblag 
>> command to accommodate maxlag = 1 or maxlag = 2, but the command relies 
>> on an nb format, which is problematic as we are looking for the 
>> underlying neighborhood structure.
>>
>> There has been numerous work done with polygons, or data which already 
>> is in ?nb? format, but after reading the literature, it seems that 
>> polygons are not appropriate, nor are distance based neighbor 
>> techniques, due to density fluctuations over the area of interest.
>>
>> Below is some reproducible code I wrote. I would like to note that I am 
>> currently working in R 1.1.453 on a MacBook.

You mean RStudio, there is no such version of R.

>>
>> # Create a data frame of 10 voters, picked at random
>> voter.1 = c(1, -75.52187, 40.62320)
>> voter.2 = c(2,-75.56373, 40.55216)
>> voter.3 = c(3,-75.39587, 40.55416)
>> voter.4 = c(4,-75.42248, 40.64326)
>> voter.5 = c(5,-75.56654, 40.54948)
>> voter.6 = c(6,-75.56257, 40.67375)
>> voter.7 = c(7, -75.51888, 40.59715)
>> voter.8 = c(8, -75.59879, 40.60014)
>> voter.9 = c(9, -75.59879, 40.60014)
>> voter.10 = c(10, -75.50877, 40.53129)
>>

These are in geographical coordinates.

>> # Bind the vectors together
>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>
>> # Rename the columns
>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>
>> # Change the class from a matrix to a data frame
>> voter.subset = as.data.frame(voter.subset)
>>
>> # Load in the required packages
>> library(spdep)
>> library(sp)
>>
>> # Set the coordinates
>> coordinates(voter.subset) = c("Longitude", "Latitude")
>> coords = coordinates(voter.subset)
>>
>> # Jitter to ensure no duplicate points
>> coords = jitter(coords, factor = 1)
>>

jitter does not respect geographical coordinated (decimal degree metric).

>> # Find the first nearest neighbor of each point
>> one.nn = knearneigh(coords, k=1)

See the help page (hint: longlat=TRUE to use Great Circle distances, much 
slower than planar).

>>
>> # Convert the first nearest neighbor to format "nb"
>> one.nn_nb = knn2nb(one.nn, sym = F)
>>
>> Thank you in advance for any help you may offer, and for taking the 
>> time to read this. I have consulted Applied Spatial Data Analysis with 
>> R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the 
>> spdep documentation, and the nb vignette (Bivand, April 3, 2018) from 
>> earlier this year.
>>
>> Warmest,
>> Ben
>> --
>> Benjamin Lieberman
>> Muhlenberg College 2019
>> Mobile: 301.299.8928
>>
>>
>>
>> 	[[alternative HTML version deleted]]

Plain text only, please.

>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From bl250604 @ending from muhlenberg@edu  Fri Jul 13 12:58:25 2018
From: bl250604 @ending from muhlenberg@edu (Benjamin Lieberman)
Date: Fri, 13 Jul 2018 06:58:25 -0400
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
 <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
Message-ID: <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>

Roger anf Facu,

Thank you very much for the help. In terms of the data, I only provided the ID and Lat/Long pairs because they were the only covariates which were necessary. The data set we are using was purchased and contains voter registration information, voter history, and census tract information, after some geocoding took place. The locations are the residents houses, in this instance. 

I have rerun the knn with longlat = T, but I am still hung up on the idea of the first order neighbors. I have reread the vignette and section 5 discusses High-Order Neighbors, but there isn?t any mention of first or second order neighbors, as you mentioned above (?first order neighbors are not defined?). One of the pieces of literature I found said that polygons are problematic to work with, as are tesslations for precisely the reason you mentioned, non-planarity. For this reason, I am hung up on the idea of how to find all first order neighbors for a point, especially as the number of first order neighbors varies from point to point, and such knearneigh would not be appropriate here. 

If this is something that does not seem feasible, maybe another tactic is necessary.

Again, thank you all for the help.

Warmest
--
Benjamin Lieberman
Muhlenberg College 2019
Mobile: 301.299.8928

> On Jul 13, 2018, at 6:11 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
> On Fri, 13 Jul 2018, Facundo Mu?oz wrote:
> 
>> Dear Benjamin,
>> 
>> I'm not sure how you define "first order neighbors" for a point. The
>> first thing that comes to my mind is to use their corresponding voronoi
>> polygons and define neighborhood from there. Following your code:
> 
> Thanks, the main source of confusion is that "first order neighbors" are not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi neighbours, or sphere of influence etc. So reading vignette("nb") would be a starting point.
> 
> Also note that voronoi and other graph-based neighbours should only use planar coordinates - including dismo::voronoi, which uses deldir::deldir() - just like spdep::tri2nb(). Triangulation can lead to spurious neighbours on the convex hull.
> 
>> 
>> v <- dismo::voronoi(coords)
>> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
>> plot(coords, type = "n", xlab = NA, ylab = NA)
>> plot(v, add = TRUE)
>> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
>> plot(coords, type = "n", xlab = NA, ylab = NA)
>> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>> 
>> ?acu.-
>> 
>> 
>> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>>> Hi all,
>>> 
>>> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair.
> 
> Using individual voter data is highly dangerous, and must in every case be subject to the strictest privacy rules. Voter data does not in essence have position - the only valid voting data that has position is of the voting station/precinct, and those data are aggregated to preserve anonymity.
> 
> Why does position and voter data not have position? Which location should you use - residence, workplace, what? What are these locations proxying? Nothing valid can be drawn from "just voter data" - you can get conclusions from carefully constructed stratified exit polls, but there the key gender/age/ethnicity/social class/etc. confounders are handled by design. Why should voting decisions be influenced by proximity (they are not)? The missing element here is looking carefully at relevant covariates at more aggregated levels (in the US typically zoning controlling social class positional segregation, etc.).
> 
>>> I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data.
>>> 
>>> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>>> 
>>> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest.
>>> 
>>> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
> 
> You mean RStudio, there is no such version of R.
> 
>>> 
>>> # Create a data frame of 10 voters, picked at random
>>> voter.1 = c(1, -75.52187, 40.62320)
>>> voter.2 = c(2,-75.56373, 40.55216)
>>> voter.3 = c(3,-75.39587, 40.55416)
>>> voter.4 = c(4,-75.42248, 40.64326)
>>> voter.5 = c(5,-75.56654, 40.54948)
>>> voter.6 = c(6,-75.56257, 40.67375)
>>> voter.7 = c(7, -75.51888, 40.59715)
>>> voter.8 = c(8, -75.59879, 40.60014)
>>> voter.9 = c(9, -75.59879, 40.60014)
>>> voter.10 = c(10, -75.50877, 40.53129)
>>> 
> 
> These are in geographical coordinates.
> 
>>> # Bind the vectors together
>>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>> 
>>> # Rename the columns
>>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>> 
>>> # Change the class from a matrix to a data frame
>>> voter.subset = as.data.frame(voter.subset)
>>> 
>>> # Load in the required packages
>>> library(spdep)
>>> library(sp)
>>> 
>>> # Set the coordinates
>>> coordinates(voter.subset) = c("Longitude", "Latitude")
>>> coords = coordinates(voter.subset)
>>> 
>>> # Jitter to ensure no duplicate points
>>> coords = jitter(coords, factor = 1)
>>> 
> 
> jitter does not respect geographical coordinated (decimal degree metric).
> 
>>> # Find the first nearest neighbor of each point
>>> one.nn = knearneigh(coords, k=1)
> 
> See the help page (hint: longlat=TRUE to use Great Circle distances, much slower than planar).
> 
>>> 
>>> # Convert the first nearest neighbor to format "nb"
>>> one.nn_nb = knn2nb(one.nn, sym = F)
>>> 
>>> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>>> 
>>> Warmest,
>>> Ben
>>> --
>>> Benjamin Lieberman
>>> Muhlenberg College 2019
>>> Mobile: 301.299.8928
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
> 
> Plain text only, please.
> 
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>> 
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>
> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________>
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>

	[[alternative HTML version deleted]]


From bl250604 @ending from muhlenberg@edu  Fri Jul 13 13:16:17 2018
From: bl250604 @ending from muhlenberg@edu (Benjamin Lieberman)
Date: Fri, 13 Jul 2018 07:16:17 -0400
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
 <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
 <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
Message-ID: <BF38A110-FAB9-43F0-B9FC-E09043B0C420@muhlenberg.edu>

All-

I would like to note that as the data is proprietary, and for obvious privacy concerns, the lat/long pairs were randomly generated, and were not taken directly from the data.


--
Benjamin Lieberman
Muhlenberg College 2019 
Mobile: 301.299.8928

> On Jul 13, 2018, at 6:58 AM, Benjamin Lieberman <bl250604 at muhlenberg.edu> wrote:
> 
> Roger anf Facu,
> 
> Thank you very much for the help. In terms of the data, I only provided the ID and Lat/Long pairs because they were the only covariates which were necessary. The data set we are using was purchased and contains voter registration information, voter history, and census tract information, after some geocoding took place. The locations are the residents houses, in this instance. 
> 
> I have rerun the knn with longlat = T, but I am still hung up on the idea of the first order neighbors. I have reread the vignette and section 5 discusses High-Order Neighbors, but there isn?t any mention of first or second order neighbors, as you mentioned above (?first order neighbors are not defined?). One of the pieces of literature I found said that polygons are problematic to work with, as are tesslations for precisely the reason you mentioned, non-planarity. For this reason, I am hung up on the idea of how to find all first order neighbors for a point, especially as the number of first order neighbors varies from point to point, and such knearneigh would not be appropriate here. 
> 
> If this is something that does not seem feasible, maybe another tactic is necessary.
> 
> Again, thank you all for the help.
> 
> Warmest
> --
> Benjamin Lieberman
> Muhlenberg College 2019
> Mobile: 301.299.8928
> 
>> On Jul 13, 2018, at 6:11 AM, Roger Bivand <Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>> wrote:
>> 
>> On Fri, 13 Jul 2018, Facundo Mu?oz wrote:
>> 
>>> Dear Benjamin,
>>> 
>>> I'm not sure how you define "first order neighbors" for a point. The
>>> first thing that comes to my mind is to use their corresponding voronoi
>>> polygons and define neighborhood from there. Following your code:
>> 
>> Thanks, the main source of confusion is that "first order neighbors" are not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi neighbours, or sphere of influence etc. So reading vignette("nb") would be a starting point.
>> 
>> Also note that voronoi and other graph-based neighbours should only use planar coordinates - including dismo::voronoi, which uses deldir::deldir() - just like spdep::tri2nb(). Triangulation can lead to spurious neighbours on the convex hull.
>> 
>>> 
>>> v <- dismo::voronoi(coords)
>>> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>> plot(v, add = TRUE)
>>> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>>> 
>>> ?acu.-
>>> 
>>> 
>>> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>>>> Hi all,
>>>> 
>>>> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair.
>> 
>> Using individual voter data is highly dangerous, and must in every case be subject to the strictest privacy rules. Voter data does not in essence have position - the only valid voting data that has position is of the voting station/precinct, and those data are aggregated to preserve anonymity.
>> 
>> Why does position and voter data not have position? Which location should you use - residence, workplace, what? What are these locations proxying? Nothing valid can be drawn from "just voter data" - you can get conclusions from carefully constructed stratified exit polls, but there the key gender/age/ethnicity/social class/etc. confounders are handled by design. Why should voting decisions be influenced by proximity (they are not)? The missing element here is looking carefully at relevant covariates at more aggregated levels (in the US typically zoning controlling social class positional segregation, etc.).
>> 
>>>> I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data.
>>>> 
>>>> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>>>> 
>>>> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest.
>>>> 
>>>> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
>> 
>> You mean RStudio, there is no such version of R.
>> 
>>>> 
>>>> # Create a data frame of 10 voters, picked at random
>>>> voter.1 = c(1, -75.52187, 40.62320)
>>>> voter.2 = c(2,-75.56373, 40.55216)
>>>> voter.3 = c(3,-75.39587, 40.55416)
>>>> voter.4 = c(4,-75.42248, 40.64326)
>>>> voter.5 = c(5,-75.56654, 40.54948)
>>>> voter.6 = c(6,-75.56257, 40.67375)
>>>> voter.7 = c(7, -75.51888, 40.59715)
>>>> voter.8 = c(8, -75.59879, 40.60014)
>>>> voter.9 = c(9, -75.59879, 40.60014)
>>>> voter.10 = c(10, -75.50877, 40.53129)
>>>> 
>> 
>> These are in geographical coordinates.
>> 
>>>> # Bind the vectors together
>>>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>>> 
>>>> # Rename the columns
>>>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>>> 
>>>> # Change the class from a matrix to a data frame
>>>> voter.subset = as.data.frame(voter.subset)
>>>> 
>>>> # Load in the required packages
>>>> library(spdep)
>>>> library(sp)
>>>> 
>>>> # Set the coordinates
>>>> coordinates(voter.subset) = c("Longitude", "Latitude")
>>>> coords = coordinates(voter.subset)
>>>> 
>>>> # Jitter to ensure no duplicate points
>>>> coords = jitter(coords, factor = 1)
>>>> 
>> 
>> jitter does not respect geographical coordinated (decimal degree metric).
>> 
>>>> # Find the first nearest neighbor of each point
>>>> one.nn = knearneigh(coords, k=1)
>> 
>> See the help page (hint: longlat=TRUE to use Great Circle distances, much slower than planar).
>> 
>>>> 
>>>> # Convert the first nearest neighbor to format "nb"
>>>> one.nn_nb = knn2nb(one.nn, sym = F)
>>>> 
>>>> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>>>> 
>>>> Warmest,
>>>> Ben
>>>> --
>>>> Benjamin Lieberman
>>>> Muhlenberg College 2019
>>>> Mobile: 301.299.8928
>>>> 
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>> 
>> Plain text only, please.
>> 
>>>> 
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>> 
>> 
>> -- 
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>
>> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________>
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>


	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Jul 13 13:26:08 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 13 Jul 2018 13:26:08 +0200
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
 <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
 <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
Message-ID: <alpine.LFD.2.21.1807131319040.15461@reclus.nhh.no>

On Fri, 13 Jul 2018, Benjamin Lieberman wrote:

> Roger anf Facu,
>
> Thank you very much for the help. In terms of the data, I only provided 
> the ID and Lat/Long pairs because they were the only covariates which 
> were necessary. The data set we are using was purchased and contains 
> voter registration information, voter history, and census tract 
> information, after some geocoding took place. The locations are the 
> residents houses, in this instance.
>
> I have rerun the knn with longlat = T, but I am still hung up on the 
> idea of the first order neighbors. I have reread the vignette and 
> section 5 discusses High-Order Neighbors, but there isn?t any mention of 
> first or second order neighbors, as you mentioned above (?first order 
> neighbors are not defined?). One of the pieces of literature I found 
> said that polygons are problematic to work with, as are tesslations for 
> precisely the reason you mentioned, non-planarity. For this reason, I am 
> hung up on the idea of how to find all first order neighbors for a 
> point, especially as the number of first order neighbors varies from 
> point to point, and such knearneigh would not be appropriate here.

So project them, and use Euclidean distances in distance or graph-based 
methods (or knn). You still have not defined "first order neighbors". That 
is your call alone. If you believe that voter behaviour is like a 
contagious disease, define contagion, and from that "first order 
neighbours". If you are simply accounting for missing background 
covariates that have a larger spatial footprint rather than voter-voter 
interaction, it probably doesn't matter much. What is the implied model 
here - that voters behave by observing the behaviour of their proximate 
neighbours (giving similar behaviour for near neighbours) or that voters 
are patched/segregated by residence, and near neighbours behave similarly 
not because of information spillovers between voters, but because the 
voters are subject to aggregate social/economic conditions?

Roger

>
> If this is something that does not seem feasible, maybe another tactic 
> is necessary.
>
> Again, thank you all for the help.
>
> Warmest
> --
> Benjamin Lieberman
> Muhlenberg College 2019
> Mobile: 301.299.8928
>
>> On Jul 13, 2018, at 6:11 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> On Fri, 13 Jul 2018, Facundo Mu?oz wrote:
>>
>>> Dear Benjamin,
>>>
>>> I'm not sure how you define "first order neighbors" for a point. The
>>> first thing that comes to my mind is to use their corresponding voronoi
>>> polygons and define neighborhood from there. Following your code:
>>
>> Thanks, the main source of confusion is that "first order neighbors" are not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi neighbours, or sphere of influence etc. So reading vignette("nb") would be a starting point.
>>
>> Also note that voronoi and other graph-based neighbours should only use planar coordinates - including dismo::voronoi, which uses deldir::deldir() - just like spdep::tri2nb(). Triangulation can lead to spurious neighbours on the convex hull.
>>
>>>
>>> v <- dismo::voronoi(coords)
>>> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>> plot(v, add = TRUE)
>>> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>>>
>>> ?acu.-
>>>
>>>
>>> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>>>> Hi all,
>>>>
>>>> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair.
>>
>> Using individual voter data is highly dangerous, and must in every case be subject to the strictest privacy rules. Voter data does not in essence have position - the only valid voting data that has position is of the voting station/precinct, and those data are aggregated to preserve anonymity.
>>
>> Why does position and voter data not have position? Which location should you use - residence, workplace, what? What are these locations proxying? Nothing valid can be drawn from "just voter data" - you can get conclusions from carefully constructed stratified exit polls, but there the key gender/age/ethnicity/social class/etc. confounders are handled by design. Why should voting decisions be influenced by proximity (they are not)? The missing element here is looking carefully at relevant covariates at more aggregated levels (in the US typically zoning controlling social class positional segregation, etc.).
>>
>>>> I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data.
>>>>
>>>> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>>>>
>>>> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest.
>>>>
>>>> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
>>
>> You mean RStudio, there is no such version of R.
>>
>>>>
>>>> # Create a data frame of 10 voters, picked at random
>>>> voter.1 = c(1, -75.52187, 40.62320)
>>>> voter.2 = c(2,-75.56373, 40.55216)
>>>> voter.3 = c(3,-75.39587, 40.55416)
>>>> voter.4 = c(4,-75.42248, 40.64326)
>>>> voter.5 = c(5,-75.56654, 40.54948)
>>>> voter.6 = c(6,-75.56257, 40.67375)
>>>> voter.7 = c(7, -75.51888, 40.59715)
>>>> voter.8 = c(8, -75.59879, 40.60014)
>>>> voter.9 = c(9, -75.59879, 40.60014)
>>>> voter.10 = c(10, -75.50877, 40.53129)
>>>>
>>
>> These are in geographical coordinates.
>>
>>>> # Bind the vectors together
>>>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>>>
>>>> # Rename the columns
>>>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>>>
>>>> # Change the class from a matrix to a data frame
>>>> voter.subset = as.data.frame(voter.subset)
>>>>
>>>> # Load in the required packages
>>>> library(spdep)
>>>> library(sp)
>>>>
>>>> # Set the coordinates
>>>> coordinates(voter.subset) = c("Longitude", "Latitude")
>>>> coords = coordinates(voter.subset)
>>>>
>>>> # Jitter to ensure no duplicate points
>>>> coords = jitter(coords, factor = 1)
>>>>
>>
>> jitter does not respect geographical coordinated (decimal degree metric).
>>
>>>> # Find the first nearest neighbor of each point
>>>> one.nn = knearneigh(coords, k=1)
>>
>> See the help page (hint: longlat=TRUE to use Great Circle distances, much slower than planar).
>>
>>>>
>>>> # Convert the first nearest neighbor to format "nb"
>>>> one.nn_nb = knn2nb(one.nn, sym = F)
>>>>
>>>> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>>>>
>>>> Warmest,
>>>> Ben
>>>> --
>>>> Benjamin Lieberman
>>>> Muhlenberg College 2019
>>>> Mobile: 301.299.8928
>>>>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>
>> Plain text only, please.
>>
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>
>> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________>
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From Roger@Biv@nd @ending from nhh@no  Fri Jul 13 13:30:12 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 13 Jul 2018 13:30:12 +0200
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <BF38A110-FAB9-43F0-B9FC-E09043B0C420@muhlenberg.edu>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
 <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
 <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
 <BF38A110-FAB9-43F0-B9FC-E09043B0C420@muhlenberg.edu>
Message-ID: <alpine.LFD.2.21.1807131327220.15461@reclus.nhh.no>

On Fri, 13 Jul 2018, Benjamin Lieberman wrote:

> All-
>
> I would like to note that as the data is proprietary, and for obvious 
> privacy concerns, the lat/long pairs were randomly generated, and were 
> not taken directly from the data.

Thanks for the clarification. Note that if the data are a sample, that is 
not a complete listing for one or more study areas, you don't know who the 
first order neighbour (the most proximate other voter) is, because that 
indidivual may not be in the sample. Your fallback then is to treat the 
data as aggregates, unless you rule out local sampling variability.

Roger

>
>
> --
> Benjamin Lieberman
> Muhlenberg College 2019
> Mobile: 301.299.8928
>
>> On Jul 13, 2018, at 6:58 AM, Benjamin Lieberman <bl250604 at muhlenberg.edu> wrote:
>>
>> Roger anf Facu,
>>
>> Thank you very much for the help. In terms of the data, I only provided the ID and Lat/Long pairs because they were the only covariates which were necessary. The data set we are using was purchased and contains voter registration information, voter history, and census tract information, after some geocoding took place. The locations are the residents houses, in this instance.
>>
>> I have rerun the knn with longlat = T, but I am still hung up on the idea of the first order neighbors. I have reread the vignette and section 5 discusses High-Order Neighbors, but there isn?t any mention of first or second order neighbors, as you mentioned above (?first order neighbors are not defined?). One of the pieces of literature I found said that polygons are problematic to work with, as are tesslations for precisely the reason you mentioned, non-planarity. For this reason, I am hung up on the idea of how to find all first order neighbors for a point, especially as the number of first order neighbors varies from point to point, and such knearneigh would not be appropriate here.
>>
>> If this is something that does not seem feasible, maybe another tactic is necessary.
>>
>> Again, thank you all for the help.
>>
>> Warmest
>> --
>> Benjamin Lieberman
>> Muhlenberg College 2019
>> Mobile: 301.299.8928
>>
>>> On Jul 13, 2018, at 6:11 AM, Roger Bivand <Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>> wrote:
>>>
>>> On Fri, 13 Jul 2018, Facundo Mu?oz wrote:
>>>
>>>> Dear Benjamin,
>>>>
>>>> I'm not sure how you define "first order neighbors" for a point. The
>>>> first thing that comes to my mind is to use their corresponding voronoi
>>>> polygons and define neighborhood from there. Following your code:
>>>
>>> Thanks, the main source of confusion is that "first order neighbors" are not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi neighbours, or sphere of influence etc. So reading vignette("nb") would be a starting point.
>>>
>>> Also note that voronoi and other graph-based neighbours should only use planar coordinates - including dismo::voronoi, which uses deldir::deldir() - just like spdep::tri2nb(). Triangulation can lead to spurious neighbours on the convex hull.
>>>
>>>>
>>>> v <- dismo::voronoi(coords)
>>>> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
>>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>>> plot(v, add = TRUE)
>>>> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
>>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>>> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>>>>
>>>> ?acu.-
>>>>
>>>>
>>>> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>>>>> Hi all,
>>>>>
>>>>> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair.
>>>
>>> Using individual voter data is highly dangerous, and must in every case be subject to the strictest privacy rules. Voter data does not in essence have position - the only valid voting data that has position is of the voting station/precinct, and those data are aggregated to preserve anonymity.
>>>
>>> Why does position and voter data not have position? Which location should you use - residence, workplace, what? What are these locations proxying? Nothing valid can be drawn from "just voter data" - you can get conclusions from carefully constructed stratified exit polls, but there the key gender/age/ethnicity/social class/etc. confounders are handled by design. Why should voting decisions be influenced by proximity (they are not)? The missing element here is looking carefully at relevant covariates at more aggregated levels (in the US typically zoning controlling social class positional segregation, etc.).
>>>
>>>>> I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data.
>>>>>
>>>>> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>>>>>
>>>>> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest.
>>>>>
>>>>> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
>>>
>>> You mean RStudio, there is no such version of R.
>>>
>>>>>
>>>>> # Create a data frame of 10 voters, picked at random
>>>>> voter.1 = c(1, -75.52187, 40.62320)
>>>>> voter.2 = c(2,-75.56373, 40.55216)
>>>>> voter.3 = c(3,-75.39587, 40.55416)
>>>>> voter.4 = c(4,-75.42248, 40.64326)
>>>>> voter.5 = c(5,-75.56654, 40.54948)
>>>>> voter.6 = c(6,-75.56257, 40.67375)
>>>>> voter.7 = c(7, -75.51888, 40.59715)
>>>>> voter.8 = c(8, -75.59879, 40.60014)
>>>>> voter.9 = c(9, -75.59879, 40.60014)
>>>>> voter.10 = c(10, -75.50877, 40.53129)
>>>>>
>>>
>>> These are in geographical coordinates.
>>>
>>>>> # Bind the vectors together
>>>>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>>>>
>>>>> # Rename the columns
>>>>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>>>>
>>>>> # Change the class from a matrix to a data frame
>>>>> voter.subset = as.data.frame(voter.subset)
>>>>>
>>>>> # Load in the required packages
>>>>> library(spdep)
>>>>> library(sp)
>>>>>
>>>>> # Set the coordinates
>>>>> coordinates(voter.subset) = c("Longitude", "Latitude")
>>>>> coords = coordinates(voter.subset)
>>>>>
>>>>> # Jitter to ensure no duplicate points
>>>>> coords = jitter(coords, factor = 1)
>>>>>
>>>
>>> jitter does not respect geographical coordinated (decimal degree metric).
>>>
>>>>> # Find the first nearest neighbor of each point
>>>>> one.nn = knearneigh(coords, k=1)
>>>
>>> See the help page (hint: longlat=TRUE to use Great Circle distances, much slower than planar).
>>>
>>>>>
>>>>> # Convert the first nearest neighbor to format "nb"
>>>>> one.nn_nb = knn2nb(one.nn, sym = F)
>>>>>
>>>>> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>>>>>
>>>>> Warmest,
>>>>> Ben
>>>>> --
>>>>> Benjamin Lieberman
>>>>> Muhlenberg College 2019
>>>>> Mobile: 301.299.8928
>>>>>
>>>>>
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>
>>> Plain text only, please.
>>>
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>
>>> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>
>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________>
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From bl250604 @ending from muhlenberg@edu  Fri Jul 13 13:44:50 2018
From: bl250604 @ending from muhlenberg@edu (Benjamin Lieberman)
Date: Fri, 13 Jul 2018 07:44:50 -0400
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <alpine.LFD.2.21.1807131327220.15461@reclus.nhh.no>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
 <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
 <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
 <BF38A110-FAB9-43F0-B9FC-E09043B0C420@muhlenberg.edu>
 <alpine.LFD.2.21.1807131327220.15461@reclus.nhh.no>
Message-ID: <EDF5AB41-4EAA-4619-A2B0-897070A7373A@muhlenberg.edu>

Roger-

Thank you so much for the help. In our case, first order neighbors are all neighbors who are adjacent to a voter. Second order neighbors are then all neighbors who are adjacent to the first order neighbors. Hope that this could clarify what I have been referencing this time.

I will try the method you suggested, thank you.

Best,
Ben
--
Benjamin Lieberman
Muhlenberg College 2019
Mobile: 301.299.8928

> On Jul 13, 2018, at 7:30 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
> On Fri, 13 Jul 2018, Benjamin Lieberman wrote:
> 
>> All-
>> 
>> I would like to note that as the data is proprietary, and for obvious privacy concerns, the lat/long pairs were randomly generated, and were not taken directly from the data.
> 
> Thanks for the clarification. Note that if the data are a sample, that is not a complete listing for one or more study areas, you don't know who the first order neighbour (the most proximate other voter) is, because that indidivual may not be in the sample. Your fallback then is to treat the data as aggregates, unless you rule out local sampling variability.
> 
> Roger
> 
>> 
>> 
>> --
>> Benjamin Lieberman
>> Muhlenberg College 2019
>> Mobile: 301.299.8928
>> 
>>> On Jul 13, 2018, at 6:58 AM, Benjamin Lieberman <bl250604 at muhlenberg.edu> wrote:
>>> 
>>> Roger anf Facu,
>>> 
>>> Thank you very much for the help. In terms of the data, I only provided the ID and Lat/Long pairs because they were the only covariates which were necessary. The data set we are using was purchased and contains voter registration information, voter history, and census tract information, after some geocoding took place. The locations are the residents houses, in this instance.
>>> 
>>> I have rerun the knn with longlat = T, but I am still hung up on the idea of the first order neighbors. I have reread the vignette and section 5 discusses High-Order Neighbors, but there isn?t any mention of first or second order neighbors, as you mentioned above (?first order neighbors are not defined?). One of the pieces of literature I found said that polygons are problematic to work with, as are tesslations for precisely the reason you mentioned, non-planarity. For this reason, I am hung up on the idea of how to find all first order neighbors for a point, especially as the number of first order neighbors varies from point to point, and such knearneigh would not be appropriate here.
>>> 
>>> If this is something that does not seem feasible, maybe another tactic is necessary.
>>> 
>>> Again, thank you all for the help.
>>> 
>>> Warmest
>>> --
>>> Benjamin Lieberman
>>> Muhlenberg College 2019
>>> Mobile: 301.299.8928
>>> 
>>>> On Jul 13, 2018, at 6:11 AM, Roger Bivand <Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> <mailto:Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>>> wrote:
>>>> 
>>>> On Fri, 13 Jul 2018, Facundo Mu?oz wrote:
>>>> 
>>>>> Dear Benjamin,
>>>>> 
>>>>> I'm not sure how you define "first order neighbors" for a point. The
>>>>> first thing that comes to my mind is to use their corresponding voronoi
>>>>> polygons and define neighborhood from there. Following your code:
>>>> 
>>>> Thanks, the main source of confusion is that "first order neighbors" are not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi neighbours, or sphere of influence etc. So reading vignette("nb") would be a starting point.
>>>> 
>>>> Also note that voronoi and other graph-based neighbours should only use planar coordinates - including dismo::voronoi, which uses deldir::deldir() - just like spdep::tri2nb(). Triangulation can lead to spurious neighbours on the convex hull.
>>>> 
>>>>> 
>>>>> v <- dismo::voronoi(coords)
>>>>> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
>>>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>>>> plot(v, add = TRUE)
>>>>> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
>>>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>>>> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>>>>> 
>>>>> ?acu.-
>>>>> 
>>>>> 
>>>>> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>>>>>> Hi all,
>>>>>> 
>>>>>> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair.
>>>> 
>>>> Using individual voter data is highly dangerous, and must in every case be subject to the strictest privacy rules. Voter data does not in essence have position - the only valid voting data that has position is of the voting station/precinct, and those data are aggregated to preserve anonymity.
>>>> 
>>>> Why does position and voter data not have position? Which location should you use - residence, workplace, what? What are these locations proxying? Nothing valid can be drawn from "just voter data" - you can get conclusions from carefully constructed stratified exit polls, but there the key gender/age/ethnicity/social class/etc. confounders are handled by design. Why should voting decisions be influenced by proximity (they are not)? The missing element here is looking carefully at relevant covariates at more aggregated levels (in the US typically zoning controlling social class positional segregation, etc.).
>>>> 
>>>>>> I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data.
>>>>>> 
>>>>>> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>>>>>> 
>>>>>> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest.
>>>>>> 
>>>>>> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
>>>> 
>>>> You mean RStudio, there is no such version of R.
>>>> 
>>>>>> 
>>>>>> # Create a data frame of 10 voters, picked at random
>>>>>> voter.1 = c(1, -75.52187, 40.62320)
>>>>>> voter.2 = c(2,-75.56373, 40.55216)
>>>>>> voter.3 = c(3,-75.39587, 40.55416)
>>>>>> voter.4 = c(4,-75.42248, 40.64326)
>>>>>> voter.5 = c(5,-75.56654, 40.54948)
>>>>>> voter.6 = c(6,-75.56257, 40.67375)
>>>>>> voter.7 = c(7, -75.51888, 40.59715)
>>>>>> voter.8 = c(8, -75.59879, 40.60014)
>>>>>> voter.9 = c(9, -75.59879, 40.60014)
>>>>>> voter.10 = c(10, -75.50877, 40.53129)
>>>>>> 
>>>> 
>>>> These are in geographical coordinates.
>>>> 
>>>>>> # Bind the vectors together
>>>>>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>>>>> 
>>>>>> # Rename the columns
>>>>>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>>>>> 
>>>>>> # Change the class from a matrix to a data frame
>>>>>> voter.subset = as.data.frame(voter.subset)
>>>>>> 
>>>>>> # Load in the required packages
>>>>>> library(spdep)
>>>>>> library(sp)
>>>>>> 
>>>>>> # Set the coordinates
>>>>>> coordinates(voter.subset) = c("Longitude", "Latitude")
>>>>>> coords = coordinates(voter.subset)
>>>>>> 
>>>>>> # Jitter to ensure no duplicate points
>>>>>> coords = jitter(coords, factor = 1)
>>>>>> 
>>>> 
>>>> jitter does not respect geographical coordinated (decimal degree metric).
>>>> 
>>>>>> # Find the first nearest neighbor of each point
>>>>>> one.nn = knearneigh(coords, k=1)
>>>> 
>>>> See the help page (hint: longlat=TRUE to use Great Circle distances, much slower than planar).
>>>> 
>>>>>> 
>>>>>> # Convert the first nearest neighbor to format "nb"
>>>>>> one.nn_nb = knn2nb(one.nn, sym = F)
>>>>>> 
>>>>>> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>>>>>> 
>>>>>> Warmest,
>>>>>> Ben
>>>>>> --
>>>>>> Benjamin Lieberman
>>>>>> Muhlenberg College 2019
>>>>>> Mobile: 301.299.8928
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> Plain text only, please.
>>>> 
>>>>>> 
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>>>>> 
>>>>> 
>>>>> 	[[alternative HTML version deleted]]
>>>>> 
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>>>>> 
>>>> 
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> <mailto:Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>>
>>>> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140> <http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>>
>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________><https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________>>
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>> 
> 
> -- 
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>
> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en>

	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Fri Jul 13 13:56:39 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Fri, 13 Jul 2018 13:56:39 +0200
Subject: [R-sig-Geo] 
 How to find all first order neighbors of a collection of points
In-Reply-To: <EDF5AB41-4EAA-4619-A2B0-897070A7373A@muhlenberg.edu>
References: <16296D3E-B6E1-4C1C-A437-6C6615A84EA5@muhlenberg.edu>
 <ae3039b9-ca41-5332-4230-88675496e5d2@cirad.fr>
 <alpine.LFD.2.21.1807131149002.15461@reclus.nhh.no>
 <C860FAFF-9E8E-443A-A117-0B7C5C35190B@muhlenberg.edu>
 <BF38A110-FAB9-43F0-B9FC-E09043B0C420@muhlenberg.edu>
 <alpine.LFD.2.21.1807131327220.15461@reclus.nhh.no>
 <EDF5AB41-4EAA-4619-A2B0-897070A7373A@muhlenberg.edu>
Message-ID: <alpine.LFD.2.21.1807131355150.15461@reclus.nhh.no>

On Fri, 13 Jul 2018, Benjamin Lieberman wrote:

> Roger-
>
> Thank you so much for the help. In our case, first order neighbors are 
> all neighbors who are adjacent to a voter. Second order neighbors are 
> then all neighbors who are adjacent to the first order neighbors. Hope 
> that this could clarify what I have been referencing this time.

So you need to define what you mean by adjacent for the purposes of your 
study. This depends on knowing the underlying behavioural patterns 
affecting interaction.

Roger

>
> I will try the method you suggested, thank you.
>
> Best,
> Ben
> --
> Benjamin Lieberman
> Muhlenberg College 2019
> Mobile: 301.299.8928
>
>> On Jul 13, 2018, at 7:30 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> On Fri, 13 Jul 2018, Benjamin Lieberman wrote:
>>
>>> All-
>>>
>>> I would like to note that as the data is proprietary, and for obvious privacy concerns, the lat/long pairs were randomly generated, and were not taken directly from the data.
>>
>> Thanks for the clarification. Note that if the data are a sample, that is not a complete listing for one or more study areas, you don't know who the first order neighbour (the most proximate other voter) is, because that indidivual may not be in the sample. Your fallback then is to treat the data as aggregates, unless you rule out local sampling variability.
>>
>> Roger
>>
>>>
>>>
>>> --
>>> Benjamin Lieberman
>>> Muhlenberg College 2019
>>> Mobile: 301.299.8928
>>>
>>>> On Jul 13, 2018, at 6:58 AM, Benjamin Lieberman <bl250604 at muhlenberg.edu> wrote:
>>>>
>>>> Roger anf Facu,
>>>>
>>>> Thank you very much for the help. In terms of the data, I only provided the ID and Lat/Long pairs because they were the only covariates which were necessary. The data set we are using was purchased and contains voter registration information, voter history, and census tract information, after some geocoding took place. The locations are the residents houses, in this instance.
>>>>
>>>> I have rerun the knn with longlat = T, but I am still hung up on the idea of the first order neighbors. I have reread the vignette and section 5 discusses High-Order Neighbors, but there isn?t any mention of first or second order neighbors, as you mentioned above (?first order neighbors are not defined?). One of the pieces of literature I found said that polygons are problematic to work with, as are tesslations for precisely the reason you mentioned, non-planarity. For this reason, I am hung up on the idea of how to find all first order neighbors for a point, especially as the number of first order neighbors varies from point to point, and such knearneigh would not be appropriate here.
>>>>
>>>> If this is something that does not seem feasible, maybe another tactic is necessary.
>>>>
>>>> Again, thank you all for the help.
>>>>
>>>> Warmest
>>>> --
>>>> Benjamin Lieberman
>>>> Muhlenberg College 2019
>>>> Mobile: 301.299.8928
>>>>
>>>>> On Jul 13, 2018, at 6:11 AM, Roger Bivand <Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> <mailto:Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>>> wrote:
>>>>>
>>>>> On Fri, 13 Jul 2018, Facundo Mu?oz wrote:
>>>>>
>>>>>> Dear Benjamin,
>>>>>>
>>>>>> I'm not sure how you define "first order neighbors" for a point. The
>>>>>> first thing that comes to my mind is to use their corresponding voronoi
>>>>>> polygons and define neighborhood from there. Following your code:
>>>>>
>>>>> Thanks, the main source of confusion is that "first order neighbors" are not defined. A k=1 neighbour could be (as below), as could k=6, or voronoi neighbours, or sphere of influence etc. So reading vignette("nb") would be a starting point.
>>>>>
>>>>> Also note that voronoi and other graph-based neighbours should only use planar coordinates - including dismo::voronoi, which uses deldir::deldir() - just like spdep::tri2nb(). Triangulation can lead to spurious neighbours on the convex hull.
>>>>>
>>>>>>
>>>>>> v <- dismo::voronoi(coords)
>>>>>> par(mfrow = c(1, 2), xaxt = "n", yaxt = "n", mgp = c(0, 0, 0))
>>>>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>>>>> plot(v, add = TRUE)
>>>>>> text(x = coords[, 1], y = coords[, 2], labels = voter.subset$Voter.ID)
>>>>>> plot(coords, type = "n", xlab = NA, ylab = NA)
>>>>>> plot(poly2nb(v), coords, add = TRUE, col = "gray")
>>>>>>
>>>>>> ?acu.-
>>>>>>
>>>>>>
>>>>>> On 07/12/2018 09:00 PM, Benjamin Lieberman wrote:
>>>>>>> Hi all,
>>>>>>>
>>>>>>> Currently, I am working with U.S. voter data. Below, I included a brief example of the structure of the data with some reproducible code. My data set consists of roughly 233,000 (233k) entries, each specifying a voter and their particular latitude/longitude pair.
>>>>>
>>>>> Using individual voter data is highly dangerous, and must in every case be subject to the strictest privacy rules. Voter data does not in essence have position - the only valid voting data that has position is of the voting station/precinct, and those data are aggregated to preserve anonymity.
>>>>>
>>>>> Why does position and voter data not have position? Which location should you use - residence, workplace, what? What are these locations proxying? Nothing valid can be drawn from "just voter data" - you can get conclusions from carefully constructed stratified exit polls, but there the key gender/age/ethnicity/social class/etc. confounders are handled by design. Why should voting decisions be influenced by proximity (they are not)? The missing element here is looking carefully at relevant covariates at more aggregated levels (in the US typically zoning controlling social class positional segregation, etc.).
>>>>>
>>>>>>> I have been using the spdep package with the hope of creating a CAR model. To begin the analysis, we need to find all first order neighbors of every point in the data.
>>>>>>>
>>>>>>> While spdep has fantastic commands for finding k nearest neighbors (knearneigh), and a useful command for finding lag of order 3 or more (nblag), I have yet to find a method which is suitable for our purposes (lag = 1, or lag =2). Additionally, I looked into altering the nblag command to accommodate maxlag = 1 or maxlag = 2, but the command relies on an nb format, which is problematic as we are looking for the underlying neighborhood structure.
>>>>>>>
>>>>>>> There has been numerous work done with polygons, or data which already is in ?nb? format, but after reading the literature, it seems that polygons are not appropriate, nor are distance based neighbor techniques, due to density fluctuations over the area of interest.
>>>>>>>
>>>>>>> Below is some reproducible code I wrote. I would like to note that I am currently working in R 1.1.453 on a MacBook.
>>>>>
>>>>> You mean RStudio, there is no such version of R.
>>>>>
>>>>>>>
>>>>>>> # Create a data frame of 10 voters, picked at random
>>>>>>> voter.1 = c(1, -75.52187, 40.62320)
>>>>>>> voter.2 = c(2,-75.56373, 40.55216)
>>>>>>> voter.3 = c(3,-75.39587, 40.55416)
>>>>>>> voter.4 = c(4,-75.42248, 40.64326)
>>>>>>> voter.5 = c(5,-75.56654, 40.54948)
>>>>>>> voter.6 = c(6,-75.56257, 40.67375)
>>>>>>> voter.7 = c(7, -75.51888, 40.59715)
>>>>>>> voter.8 = c(8, -75.59879, 40.60014)
>>>>>>> voter.9 = c(9, -75.59879, 40.60014)
>>>>>>> voter.10 = c(10, -75.50877, 40.53129)
>>>>>>>
>>>>>
>>>>> These are in geographical coordinates.
>>>>>
>>>>>>> # Bind the vectors together
>>>>>>> voter.subset = rbind(voter.1, voter.2, voter.3, voter.4, voter.5, voter.6, voter.7, voter.8, voter.9, voter.10)
>>>>>>>
>>>>>>> # Rename the columns
>>>>>>> colnames(voter.subset) = c("Voter.ID", "Longitude", "Latitude")
>>>>>>>
>>>>>>> # Change the class from a matrix to a data frame
>>>>>>> voter.subset = as.data.frame(voter.subset)
>>>>>>>
>>>>>>> # Load in the required packages
>>>>>>> library(spdep)
>>>>>>> library(sp)
>>>>>>>
>>>>>>> # Set the coordinates
>>>>>>> coordinates(voter.subset) = c("Longitude", "Latitude")
>>>>>>> coords = coordinates(voter.subset)
>>>>>>>
>>>>>>> # Jitter to ensure no duplicate points
>>>>>>> coords = jitter(coords, factor = 1)
>>>>>>>
>>>>>
>>>>> jitter does not respect geographical coordinated (decimal degree metric).
>>>>>
>>>>>>> # Find the first nearest neighbor of each point
>>>>>>> one.nn = knearneigh(coords, k=1)
>>>>>
>>>>> See the help page (hint: longlat=TRUE to use Great Circle distances, much slower than planar).
>>>>>
>>>>>>>
>>>>>>> # Convert the first nearest neighbor to format "nb"
>>>>>>> one.nn_nb = knn2nb(one.nn, sym = F)
>>>>>>>
>>>>>>> Thank you in advance for any help you may offer, and for taking the time to read this. I have consulted Applied Spatial Data Analysis with R (Bivand, Pebesma, Gomez-Rubio), as well as other Sig-Geo threads, the spdep documentation, and the nb vignette (Bivand, April 3, 2018) from earlier this year.
>>>>>>>
>>>>>>> Warmest,
>>>>>>> Ben
>>>>>>> --
>>>>>>> Benjamin Lieberman
>>>>>>> Muhlenberg College 2019
>>>>>>> Mobile: 301.299.8928
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> Plain text only, please.
>>>>>
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>>>>>>
>>>>>>
>>>>>> 	[[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> <mailto:Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>>
>>>>> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140> <http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>>
>>>>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________><https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en_______________________________________________>>
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> <mailto:R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>>
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no>
>> http://orcid.org/0000-0003-2392-6140 <http://orcid.org/0000-0003-2392-6140>
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From @h@lz@@b @ending from gm@il@com  Fri Jul 13 22:23:06 2018
From: @h@lz@@b @ending from gm@il@com (Shabir A.Bangroo)
Date: Fri, 13 Jul 2018 22:23:06 +0200
Subject: [R-sig-Geo] How to use covariate files for regression kriging
Message-ID: <CAHDuK189fW5pOiCT53An4B+w82zY1J1fLso-d-wX0L6StYcFzA@mail.gmail.com>

Hi all,

I am new to R and geostatistics.
I have raster files (NDVI and DEM) and I want to use them as covariates for
regression kriging.
Do I need to project them first to same projected coordinate system
and resample
to same cell size before converting them to txt file for use in r.

Thanks

	[[alternative HTML version deleted]]


From w@ldircj @ending from gm@il@com  Tue Jul 17 16:21:18 2018
From: w@ldircj @ending from gm@il@com (Waldir de Carvalho Junior)
Date: Tue, 17 Jul 2018 11:21:18 -0300
Subject: [R-sig-Geo] colors in AQP plot SoilProfileCollection
Message-ID: <CAFs5Q4K+kSd+RNikoQj01nOTnStrcG5PQd60v7RTmiv9Fikydg@mail.gmail.com>

Hi All
I would like to know how can I change the colors in 'plot' a
SoilProfileCollection .
The colors automatically range from blue to red.
I would like to represent the depth variation in gray scale or another
color scale.
An example of command line is:
plot(CX, name='Horizons', color='pHH20')

thanks in advance

Waldir de Carvalho
Researcher Embrapa Soils - Brazil

	[[alternative HTML version deleted]]


From vij@ylull@ @ending from gm@il@com  Wed Jul 25 23:37:38 2018
From: vij@ylull@ @ending from gm@il@com (Vijay Lulla)
Date: Wed, 25 Jul 2018 17:37:38 -0400
Subject: [R-sig-Geo] Strange behavior when using writeRaster?
Message-ID: <CAKkiGbsD_rh2hRuxGVeV40FieSgUriLrc7winRa_oi20By7waQ@mail.gmail.com>

Consider the following code snippet:

> library(raster)
> r <- raster(nrows=5, ncols=5)
> rf <- writeRaster(r, 'tst123') ## (1)
>
> d <- raster('tst123.grd')
> d[] <- 0
> df <- writeRaster(d, 'tst123', overwrite=TRUE) # We're overwriting
tst123!! (2)
>
> df  ## Shows that datasource is tst123.grd with values 0, 0 (min,max)
> rf  ## Still shows that datasource is tst123.grd with values NA, NA (min,
max)!  Error?
>
> df[] ## Expected
> rf[] ## Unexpected!!  Is this an error?
> rf  ## Should rf reread the data from the file to update its metadata?

Is it possible to keep track of open connections (for e.g., in (1) and (2)
above) and update metadata of files that may have changed?  I am also not
sure why all examples of raster package show examples of assigning value of
writeRaster function when it is intended to be used for side-effects of
writing to a file?  I would not have stumbled upon this if the examples had
simple `writeRaster(d, 'tst123')` instead of the common `df <-
writeRaster(d, 'tst123')` used in the documentation!

Thanks,
Vijay.

	[[alternative HTML version deleted]]


From engli@hchri@topher@ @ending from gm@il@com  Sun Jul 29 06:26:37 2018
From: engli@hchri@topher@ @ending from gm@il@com (chris english)
Date: Sun, 29 Jul 2018 00:26:37 -0400
Subject: [R-sig-Geo] Transform hexagonal to raster - a wife's question
Message-ID: <CAASFQpSJWC5Xw63Tc9D1H+-chLtCoiujMt=KgPsGp0B=59ojwA@mail.gmail.com>

My wife showed me a beading pattern that she was working on that looks to
my eye like a hexagonal grid, its called a peyote stitch, and she needs to
transform it to a loom stitch, essentially a raster. In the beading world
they suggest combining two rows into one. If asked, what have you tried, I
would say I tried to duck, but... In practical application, the two rows
equals one doesn't appear to preserve the desired pattern when beading the
loom, probably something like netting out the half-steps when you're going
from two rows to one = n+1 or n +2 for bead count on the combined row.
40x40 hex grid, OK, I'll get out my graph paper. Summer.

Thank you for your forbearance, and any very general thoughts appreciated,
ie transforms sans datums & etc.

Chris

	[[alternative HTML version deleted]]


From @-morkovin @ending from y@ndex@ru  Mon Jul 30 14:11:24 2018
From: @-morkovin @ending from y@ndex@ru (=?utf-8?B?0JDQvdGC0L7QvSDQnNC+0YDQutC+0LLQuNC9?=)
Date: Mon, 30 Jul 2018 15:11:24 +0300
Subject: [R-sig-Geo] Combining SpatialLines into SpatialPolygons
Message-ID: <3561511532952684@iva7-7c2970ec7645.qloud-c.yandex.net>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20180730/c924cda1/attachment.html>

From btupper @ending from bigelow@org  Mon Jul 30 15:12:33 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Mon, 30 Jul 2018 09:12:33 -0400
Subject: [R-sig-Geo] Transform hexagonal to raster - a wife's question
In-Reply-To: <CAASFQpSJWC5Xw63Tc9D1H+-chLtCoiujMt=KgPsGp0B=59ojwA@mail.gmail.com>
References: <CAASFQpSJWC5Xw63Tc9D1H+-chLtCoiujMt=KgPsGp0B=59ojwA@mail.gmail.com>
Message-ID: <751A41D4-5621-4E60-A242-5F210F700BFC@bigelow.org>

If I were in your shoes I would be doing a hop-skip to ring Sarah Goslee's doorbell.  She's our resident ecology-spatial-textiles guru...

http://www.stringpage.com/ <http://www.stringpage.com/>







> On Jul 29, 2018, at 12:26 AM, chris english <englishchristophera at gmail.com> wrote:
> 
> My wife showed me a beading pattern that she was working on that looks to
> my eye like a hexagonal grid, its called a peyote stitch, and she needs to
> transform it to a loom stitch, essentially a raster. In the beading world
> they suggest combining two rows into one. If asked, what have you tried, I
> would say I tried to duck, but... In practical application, the two rows
> equals one doesn't appear to preserve the desired pattern when beading the
> loom, probably something like netting out the half-steps when you're going
> from two rows to one = n+1 or n +2 for bead count on the combined row.
> 40x40 hex grid, OK, I'll get out my graph paper. Summer.
> 
> Thank you for your forbearance, and any very general thoughts appreciated,
> ie transforms sans datums & etc.
> 
> Chris
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From Roger@Biv@nd @ending from nhh@no  Mon Jul 30 15:37:33 2018
From: Roger@Biv@nd @ending from nhh@no (Roger Bivand)
Date: Mon, 30 Jul 2018 15:37:33 +0200
Subject: [R-sig-Geo] Combining SpatialLines into SpatialPolygons
In-Reply-To: <3561511532952684@iva7-7c2970ec7645.qloud-c.yandex.net>
References: <3561511532952684@iva7-7c2970ec7645.qloud-c.yandex.net>
Message-ID: <alpine.LFD.2.21.1807301532110.19586@reclus.nhh.no>

Please use plain text only, and provide a small reproducible example, 
possibly demonstrating in code and data what you claim about "finding 
solutions". I assume that you have already tried rgeos::gPolygonize(). 
Consider using its example to generate your reproducible example. You may 
find that scaling also matters.

Roger

On Mon, 30 Jul 2018, ????? ???????? wrote:

> ?
> Dear all,
> ?
> I have a kml file with a huge set of lines, which actually depict a grid of
> many rectangles. I want to unite these lines into polygons (i.e., each
> rectangle must be a separate spatial polygon), but I failed to find a
> function which does it directly.
> ?
> I found several solutions on how to convert to polygons a set of isolated
> closed lines. But with my file, these methods can produce nothing more than
> a set of "polygons" with only one line each. The only way I can imagine is
> to convert these lines into a raster and then polygonize it, but this method
> probably would lack accuracy.
> If anyone knows how to deal with such tasks, please help me. Thank you in
> advance!
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
> ? ? ??
> Best regards,
> Anton A. Morkovin
> ?
> Zoological Museum of M.V. Lomonosov Moscow State University
> Russia, 125009 Moscow, Bolshaya Nikitskaya Str. 2.
>  *  Personal page:?http://istina.msu.ru/profile/Anton_Morkovin/
>  *  Bibliography of scientific works?on birds of Russia
>  *  The Birdwatchers union "Birds of Moscow and the Moscow
>     region"?||?Facebook?||?VK?||?Twitter
> ?
> ?
> 
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

From engli@hchri@topher@ @ending from gm@il@com  Mon Jul 30 16:40:53 2018
From: engli@hchri@topher@ @ending from gm@il@com (chris english)
Date: Mon, 30 Jul 2018 10:40:53 -0400
Subject: [R-sig-Geo] Transform hexagonal to raster - a wife's question
In-Reply-To: <751A41D4-5621-4E60-A242-5F210F700BFC@bigelow.org>
References: <CAASFQpSJWC5Xw63Tc9D1H+-chLtCoiujMt=KgPsGp0B=59ojwA@mail.gmail.com>
 <751A41D4-5621-4E60-A242-5F210F700BFC@bigelow.org>
Message-ID: <CAASFQpQo+wiwvYmF6hJv3-mEit7fLNdwN5JD7VGuNjNkK-xrtg@mail.gmail.com>

Thank you Ben!, I'll actually send her directly
to Sarah, http://www.sarahgoslee.com/ .
Dr. Massa, meet Dr. Goslee, Professor of indeterminate studies & weaver,
and writer,
Dr. Goslee, meet Dr. Massa, cognitive neuro research scientist, felter and
loom beader.
Thanks again,
Chris

On Mon, Jul 30, 2018 at 9:12 AM, Ben Tupper <btupper at bigelow.org> wrote:

> If I were in your shoes I would be doing a hop-skip to ring Sarah Goslee's
> doorbell.  She's our resident ecology-spatial-textiles guru...
>
> http://www.stringpage.com/
>
>
>
>
>
>
>
> On Jul 29, 2018, at 12:26 AM, chris english <englishchristophera at gmail.com>
> wrote:
>
> My wife showed me a beading pattern that she was working on that looks to
> my eye like a hexagonal grid, its called a peyote stitch, and she needs to
> transform it to a loom stitch, essentially a raster. In the beading world
> they suggest combining two rows into one. If asked, what have you tried, I
> would say I tried to duck, but... In practical application, the two rows
> equals one doesn't appear to preserve the desired pattern when beading the
> loom, probably something like netting out the half-steps when you're going
> from two rows to one = n+1 or n +2 for bead count on the combined row.
> 40x40 hex grid, OK, I'll get out my graph paper. Summer.
>
> Thank you for your forbearance, and any very general thoughts appreciated,
> ie transforms sans datums & etc.
>
> Chris
>
> [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive
> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>, P.O.
> Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Mon Jul 30 18:53:07 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Mon, 30 Jul 2018 12:53:07 -0400
Subject: [R-sig-Geo] Transform hexagonal to raster - a wife's question
In-Reply-To: <CAASFQpQo+wiwvYmF6hJv3-mEit7fLNdwN5JD7VGuNjNkK-xrtg@mail.gmail.com>
References: <CAASFQpSJWC5Xw63Tc9D1H+-chLtCoiujMt=KgPsGp0B=59ojwA@mail.gmail.com>
 <751A41D4-5621-4E60-A242-5F210F700BFC@bigelow.org>
 <CAASFQpQo+wiwvYmF6hJv3-mEit7fLNdwN5JD7VGuNjNkK-xrtg@mail.gmail.com>
Message-ID: <CAM_vjumKg6E=T3tW+-V7xH+R1h-jqrej2cU+NZBc=+mzq+q+1Q@mail.gmail.com>

Hi!

I nearly didn't open this email thread: glad I did!

I have some odd R tools for weaving, but nothing for beading.

I suspect this is the best way to do it, although the actual result
would depend on the particular pattern.

http://www.bellaonline.com/articles/art61406.asp

Whether it's worth writing R code to perform this task depends a lot
on how many patterns need to be converted.

A more R-geo approach might be to import the original pattern from an
image file, turn it into spatial polygons, then rasterize it,
completely ignoring the hexagonal nature of the original. With some
playing with the raster grid size, you could probably get a decent
approximation.

Sarah


On Mon, Jul 30, 2018 at 10:40 AM, chris english
<englishchristophera at gmail.com> wrote:
> Thank you Ben!, I'll actually send her directly
> to Sarah, http://www.sarahgoslee.com/ .
> Dr. Massa, meet Dr. Goslee, Professor of indeterminate studies & weaver,
> and writer,
> Dr. Goslee, meet Dr. Massa, cognitive neuro research scientist, felter and
> loom beader.
> Thanks again,
> Chris
>
> On Mon, Jul 30, 2018 at 9:12 AM, Ben Tupper <btupper at bigelow.org> wrote:
>
>> If I were in your shoes I would be doing a hop-skip to ring Sarah Goslee's
>> doorbell.  She's our resident ecology-spatial-textiles guru...
>>
>> http://www.stringpage.com/
>>
>>
>>
>>
>>
>>
>>
>> On Jul 29, 2018, at 12:26 AM, chris english <englishchristophera at gmail.com>
>> wrote:
>>
>> My wife showed me a beading pattern that she was working on that looks to
>> my eye like a hexagonal grid, its called a peyote stitch, and she needs to
>> transform it to a loom stitch, essentially a raster. In the beading world
>> they suggest combining two rows into one. If asked, what have you tried, I
>> would say I tried to duck, but... In practical application, the two rows
>> equals one doesn't appear to preserve the desired pattern when beading the
>> loom, probably something like netting out the half-steps when you're going
>> from two rows to one = n+1 or n +2 for bead count on the combined row.
>> 40x40 hex grid, OK, I'll get out my graph paper. Summer.
>>
>> Thank you for your forbearance, and any very general thoughts appreciated,
>> ie transforms sans datums & etc.
>>
>> Chris
>>


From engli@hchri@topher@ @ending from gm@il@com  Mon Jul 30 19:25:30 2018
From: engli@hchri@topher@ @ending from gm@il@com (chris english)
Date: Mon, 30 Jul 2018 13:25:30 -0400
Subject: [R-sig-Geo] Transform hexagonal to raster - a wife's question
In-Reply-To: <CAM_vjumKg6E=T3tW+-V7xH+R1h-jqrej2cU+NZBc=+mzq+q+1Q@mail.gmail.com>
References: <CAASFQpSJWC5Xw63Tc9D1H+-chLtCoiujMt=KgPsGp0B=59ojwA@mail.gmail.com>
 <751A41D4-5621-4E60-A242-5F210F700BFC@bigelow.org>
 <CAASFQpQo+wiwvYmF6hJv3-mEit7fLNdwN5JD7VGuNjNkK-xrtg@mail.gmail.com>
 <CAM_vjumKg6E=T3tW+-V7xH+R1h-jqrej2cU+NZBc=+mzq+q+1Q@mail.gmail.com>
Message-ID: <CAASFQpQv3=TerteqHMZcgN12VHG0cHJ+xLY-zXzcF8hz3LrsBA@mail.gmail.com>

Sarah,

I'll try the R-geo approach suggested for a small, sought after kokopeli,
and duck an integrated raster colorizer (five years to proto-type given my
skills.) I've forwarded all this to Dr Massa. I would say though that things
'loom' tend to work both for fabric and bead. Glad you checked the thread.

Happy summer,
Chris

On Mon, Jul 30, 2018 at 12:53 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi!
>
> I nearly didn't open this email thread: glad I did!
>
> I have some odd R tools for weaving, but nothing for beading.
>
> I suspect this is the best way to do it, although the actual result
> would depend on the particular pattern.
>
> http://www.bellaonline.com/articles/art61406.asp
>
> Whether it's worth writing R code to perform this task depends a lot
> on how many patterns need to be converted.
>
> A more R-geo approach might be to import the original pattern from an
> image file, turn it into spatial polygons, then rasterize it,
> completely ignoring the hexagonal nature of the original. With some
> playing with the raster grid size, you could probably get a decent
> approximation.
>
> Sarah
>
>
> On Mon, Jul 30, 2018 at 10:40 AM, chris english
> <englishchristophera at gmail.com> wrote:
> > Thank you Ben!, I'll actually send her directly
> > to Sarah, http://www.sarahgoslee.com/ .
> > Dr. Massa, meet Dr. Goslee, Professor of indeterminate studies & weaver,
> > and writer,
> > Dr. Goslee, meet Dr. Massa, cognitive neuro research scientist, felter
> and
> > loom beader.
> > Thanks again,
> > Chris
> >
> > On Mon, Jul 30, 2018 at 9:12 AM, Ben Tupper <btupper at bigelow.org> wrote:
> >
> >> If I were in your shoes I would be doing a hop-skip to ring Sarah
> Goslee's
> >> doorbell.  She's our resident ecology-spatial-textiles guru...
> >>
> >> http://www.stringpage.com/
> >>
> >>
> >>
> >>
> >>
> >>
> >>
> >> On Jul 29, 2018, at 12:26 AM, chris english <
> englishchristophera at gmail.com>
> >> wrote:
> >>
> >> My wife showed me a beading pattern that she was working on that looks
> to
> >> my eye like a hexagonal grid, its called a peyote stitch, and she needs
> to
> >> transform it to a loom stitch, essentially a raster. In the beading
> world
> >> they suggest combining two rows into one. If asked, what have you
> tried, I
> >> would say I tried to duck, but... In practical application, the two rows
> >> equals one doesn't appear to preserve the desired pattern when beading
> the
> >> loom, probably something like netting out the half-steps when you're
> going
> >> from two rows to one = n+1 or n +2 for bead count on the combined row.
> >> 40x40 hex grid, OK, I'll get out my graph paper. Summer.
> >>
> >> Thank you for your forbearance, and any very general thoughts
> appreciated,
> >> ie transforms sans datums & etc.
> >>
> >> Chris
> >>
>

	[[alternative HTML version deleted]]


From brun@e@ti @ending from gm@il@com  Tue Jul 31 11:02:28 2018
From: brun@e@ti @ending from gm@il@com (Bruno Sesti)
Date: Tue, 31 Jul 2018 11:02:28 +0200
Subject: [R-sig-Geo] Spatio temporal data modeling and variography -
 function (gstat) variogramST
Message-ID: <CAFnjcD27m32+CZNKbi98xWD7-J7nXrUBbd+fKkCgQCcHyWsPSg@mail.gmail.com>

Hi, I am working with spatio temporal data using spatio temporal kriging.
I saw that the function variogramST also considers days (and months, and
years) to determine temporal lags for the creation of spatio temporal
variogram. I would like to ask if someone could tell me if this is correct
and, if yes, if it would be possible to let the funcrion variogramST
(gstat) to consider only hours, minutes and seconds of the times associated
to each data for the definition of temporal lags.

Kind regards.

	[[alternative HTML version deleted]]


