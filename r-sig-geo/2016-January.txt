From mathieu.rajerison at gmail.com  Mon Jan  4 11:51:13 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 4 Jan 2016 11:51:13 +0100
Subject: [R-sig-Geo] Needing to speed up a process involving calc() and
 cover() raster functions
In-Reply-To: <CANtt_hy5G1PtE3qf-nBDvEjZrxhoR8g0JFhc+nk=evV0hHqwgw@mail.gmail.com>
References: <CAGfc75nOUaZCz1sCb2dGetEsy4yt5VD6ko-zPTm3Q96ZAnOdcA@mail.gmail.com>
	<CANtt_hy5G1PtE3qf-nBDvEjZrxhoR8g0JFhc+nk=evV0hHqwgw@mail.gmail.com>
Message-ID: <CAGfc75nHO8QYchR_RpjiWtkJegbpOUoTptKXZSjjMxeqdMBT4A@mail.gmail.com>

Hi,

And thanks for all the answers.

I've tested Robert's elegant solution successfully.
I haven't yet tested your solution, Banjamin, but it seems a really good
improvement for speeding all this up and I'll soon give it a try. Thanks
for your awesome RSToolbox package

To answer your question "why setting all pixels to 1", it's just that
afterwards, I smooth the result with a mean-shift focal function. This way,
it gives all the extracted pixels the same value/weight.

Thanks again and happy new yeaR

Mathieu


2015-12-25 6:46 GMT+01:00 Robert J. Hijmans <r.hijmans at gmail.com>:

> How about this:
>
> b <- brick(system.file("external/rlogo.grd", package="raster"))
> classified <- b / 255
>
> threshs <- c(.1, .3, .5)
> x <- classified < threshs
> y <- max(x, na.rm=TRUE)
> z <- reclassify(y, cbind(0, NA))
>
>
> Robert
>
>
> On Tue, Dec 22, 2015 at 1:57 AM, Mathieu Rajerison
> <mathieu.rajerison at gmail.com> wrote:
> > Hi,
> >
> >
> > I use RSToolBox to classify a RGB raster.
> >
> > I have a resulting RasterBrick which has as many layer as end members, in
> > my case 3 for different tones of blue.
> >
> > I reclassify each band with calc to extract the pixels which have a small
> > angle mapping value. The threshold used is different depending on the
> > endmember layer.
> >
> > I finally assembly all the bands with the cover function.
> >
> > I needed to increase the memory limit assigned to R to have it worked. I
> > suspect that my code could be optimized, but I don't know in which way.
> >
> > Here is the part of my code, that I think, could be optilmized, if you
> want
> > to have a look and give some advice :
> >
> > # RECLASSIFY
> > # classified is the classified RasterStack
> > # here I change the values of each band to 1 or NA depending on the
> > spectral angle mapping value.
> > # Is calc() slower than reclassify() for this purpose as I have only one
> > threshold value ?
> >
> > threshs = c(.1,.2,.1)
> > for (i in 1:nlayers(classified )) {
> >
> >     clas = classified[[i]]
> >     thresh=threshs[i]
> >
> >     out[[i]] = calc(clas, function(x) {x[x >= thresh] = NA;
> >                                        x[x < thresh] = 1;
> >                                        return(x)})
> >   }
> >
> > # COVERING
> >   r = out[[1]]
> >   for(i in 2:length(out)) {
> >     r = cover(out[[i]], r)   ## I cover by iteration
> >   }
> >
> > plot(r) # r is the final combined raster
> >
> > ================================================================
> > My sessionInfo() :
> >> sessionInfo()
> > R version 3.1.2 (2014-10-31)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> > locale:
> > [1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
> >  LC_MONETARY=French_France.1252
> > [4] LC_NUMERIC=C                   LC_TIME=French_France.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> >  [1] R.utils_2.1.0        R.oo_1.19.0          R.methodsS3_1.7.0
> >  igraph_1.0.1         scatterplot3d_0.3-36
> >  [6] gdalUtils_2.0.1.7    spdep_0.5-88         Matrix_1.2-2
> > maptools_0.8-34      spgrass6_0.8-8
> > [11] XML_3.98-1.3         rgeos_0.3-8          FNN_1.1
> >  rgdal_0.9-2          RStoolbox_0.1.1
> > [16] raster_2.3-40        sp_1.0-17
> >
> > loaded via a namespace (and not attached):
> >  [1] boot_1.3-13        car_2.0-25         caret_6.0-57       coda_0.18-1
> >      codetools_0.2-9    colorspace_1.2-6
> >  [7] deldir_0.1-9       digest_0.6.8       doParallel_1.0.8
>  foreach_1.4.2
> >      foreign_0.8-61     geosphere_1.4-3
> > [13] ggplot2_1.0.1      grid_3.1.2         gtable_0.1.2
> > iterators_1.0.7    lattice_0.20-29    LearnBayes_2.15
> > [19] lme4_1.1-10        magrittr_1.5       MASS_7.3-35
> >  MatrixModels_0.4-1 mgcv_1.8-3         minqa_1.2.4
> > [25] munsell_0.4.2      nlme_3.1-118       nloptr_1.0.4       nnet_7.3-8
> >       parallel_3.1.2     pbkrtest_0.4-2
> > [31] plyr_1.8.3         proto_0.3-10       quantreg_5.19      Rcpp_0.12.0
> >      reshape2_1.4.1     scales_0.2.5
> > [37] SparseM_1.7        splines_3.1.2      stats4_3.1.2
>  stringi_0.5-5
> >      stringr_1.0.0      tools_3.1.2
> >
> > ============================================================
> > Best,
> >
> > Mathieu
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Jan  5 11:09:19 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 05 Jan 2016 10:09:19 +0000
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
Message-ID: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>

Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
string to PROJ.4 used by sp/rgdal?

(Previously I've written out to SHP/PRJ, and read back in with rgdal, but
that's obviously a bit naff.)

(I know you can rgeos::readWKT and wkb::readWKB for *geometry*).

Cheers, Mike.




-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From bob at rudis.net  Tue Jan  5 11:57:42 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 5 Jan 2016 05:57:42 -0500
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
Message-ID: <CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>

This may not be optimal as it uses an external service:

  prj_to_epsg <- function(prj) {

    require(sp)
    require(httr)
    require(jsonlite)

    res <- GET("http://prj2epsg.org/search.json",
               query=list(exact=TRUE,
                          error=TRUE,
                          mode="wkt",
                          terms=prj))

    # one shld prbly do more error checking than this
    stop_for_status(res)

    dat <- fromJSON(content(res, as="text", flatten=TRUE))

    # NOTE: there could be more in dat$codes if prj was ambiguous
    CRS(paste0("+init=epsg:", dat$codes[1, "code"]))

  }

  prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
  prj_to_epsg(prj)
  ## CRS arguments:
  ##  +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
  ## +towgs84=0,0,0

  prj_1 <- 'PROJCS["Transverse_Mercator",
    GEOGCS["GCS_OSGB 1936",
    DATUM["D_OSGB_1936",
    SPHEROID["Airy_1830",6377563.396,299.3249646]],
    PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
    PROJECTION["Transverse_Mercator"],
    PARAMETER["latitude_of_origin",49],
    PARAMETER["central_meridian",-2],
    PARAMETER["scale_factor",0.9996012717],
    PARAMETER["false_easting",400000],
    PARAMETER["false_northing",-100000],
    UNIT["Meter",1]]'
  prj_to_epsg(prj_1)
  ## CRS arguments:
  ##  +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
  ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
  ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894

On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
> string to PROJ.4 used by sp/rgdal?
>
> (Previously I've written out to SHP/PRJ, and read back in with rgdal, but
> that's obviously a bit naff.)
>
> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>
> Cheers, Mike.
>
>
>
>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mdsumner at gmail.com  Tue Jan  5 12:05:23 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 05 Jan 2016 11:05:23 +0000
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
Message-ID: <CAAcGz99G0w+nEDnmVog+d7HTZ9VJum=mfjeV7iaL-c6EcpMdKA@mail.gmail.com>

> On Tue, 5 Jan 2016 at 21:09 Michael Sumner <mdsumner at gmail.com> wrote:

> Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
string to
> PROJ.4 used by sp/rgdal?



I see it in ogr_proj.cpp at line 124:


if (hSRS->exportToProj4(&pszProj4) != OGRERR_NONE) {

Roger, Edzer: could we please expose that functionality from rgdal to input
WKT from R?


Is that feasible? I'll have a look at doing it myself . . . I know it's a
distraction from other goals.


Thank you.


Cheers, Mike.



> (Previously I've written out to SHP/PRJ, and read back in with rgdal, but
that's obviously a
> bit naff.)


> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).



> Cheers, Mike.



-- 

Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Jan  5 12:09:58 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 05 Jan 2016 11:09:58 +0000
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
Message-ID: <CAAcGz9-HLv27s2ePfZQDwvnqYo9cjF15FmR=vEU3+cqNdA+HOQ@mail.gmail.com>

>
>
> On Tue, 5 Jan 2016 at 21:58 boB Rudis <bob at rudis.net> wrote:
> This may not be optimal as it uses an external service:


That is excellent, thanks for the example!

I assume you won't mind if I package it up?  I'll attribute you, and let
you know when it's working.

Cheers, Mike.


> prj_to_epsg <- function(prj) {
>
> require(sp)
> require(httr)
> require(jsonlite)
>
> res <- GET("http://prj2epsg.org/search.json",
> query=list(exact=TRUE,
> error=TRUE,
> mode="wkt",
> terms=prj))
>
> # one shld prbly do more error checking than this
> stop_for_status(res)
>
> dat <- fromJSON(content(res, as="text", flatten=TRUE))
>
> # NOTE: there could be more in dat$codes if prj was ambiguous
> CRS(paste0("+init=epsg:", dat$codes[1, "code"]))
>
> }
>
> prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
> prj_to_epsg(prj)
> ## CRS arguments:
> ## +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
> ## +towgs84=0,0,0
>
> prj_1 <- 'PROJCS["Transverse_Mercator",
> GEOGCS["GCS_OSGB 1936",
> DATUM["D_OSGB_1936",
> SPHEROID["Airy_1830",6377563.396,299.3249646]],
> PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
> PROJECTION["Transverse_Mercator"],
> PARAMETER["latitude_of_origin",49],
> PARAMETER["central_meridian",-2],
> PARAMETER["scale_factor",0.9996012717],
> PARAMETER["false_easting",400000],
> PARAMETER["false_northing",-100000],
> UNIT["Meter",1]]'
> prj_to_epsg(prj_1)
> ## CRS arguments:
> ## +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
> ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
> ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894
>
> On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> > Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
> > string to PROJ.4 used by sp/rgdal?
> >
> > (Previously I've written out to SHP/PRJ, and read back in with rgdal,
but
> > that's obviously a bit naff.)
> >
> > (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
> >
> > Cheers, Mike.
> >
> >
> >
> >
> > --
> > Dr. Michael Sumner
> > Software and Database Engineer
> > Australian Antarctic Division
> > 203 Channel Highway
> > Kingston Tasmania 7050 Australia
> >
> > [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From bob at rudis.net  Tue Jan  5 12:20:11 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 5 Jan 2016 06:20:11 -0500
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
Message-ID: <CAJ4QxaOT8GpjZEub+SgCMp55hxfUc=3u0AuUr8drPHY5Qt65XA@mail.gmail.com>

It's too early I guess as it didn't occur to me that if writing it out
locally was naff using an external service is more so. The
SpatialReference "importFromESRI()" function doesn't seem to be mapped
in rgdal. That would be the function needed to avoid a
write-out/external call.

On Tue, Jan 5, 2016 at 5:57 AM, boB Rudis <bob at rudis.net> wrote:
> This may not be optimal as it uses an external service:
>
>   prj_to_epsg <- function(prj) {
>
>     require(sp)
>     require(httr)
>     require(jsonlite)
>
>     res <- GET("http://prj2epsg.org/search.json",
>                query=list(exact=TRUE,
>                           error=TRUE,
>                           mode="wkt",
>                           terms=prj))
>
>     # one shld prbly do more error checking than this
>     stop_for_status(res)
>
>     dat <- fromJSON(content(res, as="text", flatten=TRUE))
>
>     # NOTE: there could be more in dat$codes if prj was ambiguous
>     CRS(paste0("+init=epsg:", dat$codes[1, "code"]))
>
>   }
>
>   prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
>   prj_to_epsg(prj)
>   ## CRS arguments:
>   ##  +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
>   ## +towgs84=0,0,0
>
>   prj_1 <- 'PROJCS["Transverse_Mercator",
>     GEOGCS["GCS_OSGB 1936",
>     DATUM["D_OSGB_1936",
>     SPHEROID["Airy_1830",6377563.396,299.3249646]],
>     PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
>     PROJECTION["Transverse_Mercator"],
>     PARAMETER["latitude_of_origin",49],
>     PARAMETER["central_meridian",-2],
>     PARAMETER["scale_factor",0.9996012717],
>     PARAMETER["false_easting",400000],
>     PARAMETER["false_northing",-100000],
>     UNIT["Meter",1]]'
>   prj_to_epsg(prj_1)
>   ## CRS arguments:
>   ##  +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
>   ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
>   ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894
>
> On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>> Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
>> string to PROJ.4 used by sp/rgdal?
>>
>> (Previously I've written out to SHP/PRJ, and read back in with rgdal, but
>> that's obviously a bit naff.)
>>
>> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>>
>> Cheers, Mike.
>>
>>
>>
>>
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Tue Jan  5 12:21:51 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 Jan 2016 12:21:51 +0100
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAAcGz99G0w+nEDnmVog+d7HTZ9VJum=mfjeV7iaL-c6EcpMdKA@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAAcGz99G0w+nEDnmVog+d7HTZ9VJum=mfjeV7iaL-c6EcpMdKA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1601051219390.21050@reclus.nhh.no>

On Tue, 5 Jan 2016, Michael Sumner wrote:

>> On Tue, 5 Jan 2016 at 21:09 Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
> string to
>> PROJ.4 used by sp/rgdal?
>
>
>
> I see it in ogr_proj.cpp at line 124:
>
>
> if (hSRS->exportToProj4(&pszProj4) != OGRERR_NONE) {
>
> Roger, Edzer: could we please expose that functionality from rgdal to input
> WKT from R?

That is exposed - the output comes in that of ogrInfo(), but needs the DSN 
and layer too.

I've committed the reverse of showWKT() as showP4() in revision 596 on 
R-Forge - let me know if you need a Windows binary to test.

Roger

>
>
> Is that feasible? I'll have a look at doing it myself . . . I know it's a
> distraction from other goals.
>
>
> Thank you.
>
>
> Cheers, Mike.
>
>
>
>> (Previously I've written out to SHP/PRJ, and read back in with rgdal, but
> that's obviously a
>> bit naff.)
>
>
>> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>
>
>
>> Cheers, Mike.
>
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From dicko.ahmadou at gmail.com  Tue Jan  5 12:24:24 2016
From: dicko.ahmadou at gmail.com (Ahmadou Dicko)
Date: Tue, 5 Jan 2016 11:24:24 +0000
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAAcGz9-HLv27s2ePfZQDwvnqYo9cjF15FmR=vEU3+cqNdA+HOQ@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
	<CAAcGz9-HLv27s2ePfZQDwvnqYo9cjF15FmR=vEU3+cqNdA+HOQ@mail.gmail.com>
Message-ID: <CAP8THHWqjx18+H+MyA4wd=xGYJUxhr_5x5Mbo=8=fp45Xt=nBQ@mail.gmail.com>

You can also use gdalsrsinfo through gdalUtils.

prj_1 <- 'PROJCS["Transverse_Mercator",
    GEOGCS["GCS_OSGB 1936",
    DATUM["D_OSGB_1936",
    SPHEROID["Airy_1830",6377563.396,299.3249646]],
    PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
    PROJECTION["Transverse_Mercator"],
    PARAMETER["latitude_of_origin",49],
    PARAMETER["central_meridian",-2],
    PARAMETER["scale_factor",0.9996012717],
    PARAMETER["false_easting",400000],
    PARAMETER["false_northing",-100000],
    UNIT["Meter",1]]'


prj_to_epsg <- function(prj) {
  file <- tempfile()
  writeLines(prj, file)
  crs <- gdalsrsinfo(file, as.CRS = TRUE)
  unlink(file)
  crs
}

prj_to_epsg(prj_1)
## CRS arguments:
##  +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
## +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs




On Tue, Jan 5, 2016 at 11:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:

> >
> >
> > On Tue, 5 Jan 2016 at 21:58 boB Rudis <bob at rudis.net> wrote:
> > This may not be optimal as it uses an external service:
>
>
> That is excellent, thanks for the example!
>
> I assume you won't mind if I package it up?  I'll attribute you, and let
> you know when it's working.
>
> Cheers, Mike.
>
>
> > prj_to_epsg <- function(prj) {
> >
> > require(sp)
> > require(httr)
> > require(jsonlite)
> >
> > res <- GET("http://prj2epsg.org/search.json",
> > query=list(exact=TRUE,
> > error=TRUE,
> > mode="wkt",
> > terms=prj))
> >
> > # one shld prbly do more error checking than this
> > stop_for_status(res)
> >
> > dat <- fromJSON(content(res, as="text", flatten=TRUE))
> >
> > # NOTE: there could be more in dat$codes if prj was ambiguous
> > CRS(paste0("+init=epsg:", dat$codes[1, "code"]))
> >
> > }
> >
> > prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
> > prj_to_epsg(prj)
> > ## CRS arguments:
> > ## +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
> > ## +towgs84=0,0,0
> >
> > prj_1 <- 'PROJCS["Transverse_Mercator",
> > GEOGCS["GCS_OSGB 1936",
> > DATUM["D_OSGB_1936",
> > SPHEROID["Airy_1830",6377563.396,299.3249646]],
> > PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
> > PROJECTION["Transverse_Mercator"],
> > PARAMETER["latitude_of_origin",49],
> > PARAMETER["central_meridian",-2],
> > PARAMETER["scale_factor",0.9996012717],
> > PARAMETER["false_easting",400000],
> > PARAMETER["false_northing",-100000],
> > UNIT["Meter",1]]'
> > prj_to_epsg(prj_1)
> > ## CRS arguments:
> > ## +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
> > ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
> > ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894
> >
> > On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
> > > Hello, is there any R-level way to convert a WKT/PRJ *coordinate
> system*
> > > string to PROJ.4 used by sp/rgdal?
> > >
> > > (Previously I've written out to SHP/PRJ, and read back in with rgdal,
> but
> > > that's obviously a bit naff.)
> > >
> > > (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
> > >
> > > Cheers, Mike.
> > >
> > >
> > >
> > >
> > > --
> > > Dr. Michael Sumner
> > > Software and Database Engineer
> > > Australian Antarctic Division
> > > 203 Channel Highway
> > > Kingston Tasmania 7050 Australia
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Ahmadou H. DICKO
statistician economist (Ing?nieur Statisticien ?conomiste)
PhD candidate in Climate change economics
Faculty of economics and managment - Cheikh Anta Diop University
West African Science Service Center on Climate Change and Adaptated Land
Use (WASCAL)
Center for Development Research (ZEF) - University of Bonn
email : ahmadou.dicko at ucad.edu.sn
twitter : @dickoah
github : github/dickoa <https://github.com/dickoa>
tel : +221 33 827 55 16
portable: +221 77 123 81 69

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Jan  5 12:28:14 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 5 Jan 2016 22:28:14 +1100
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <alpine.LFD.2.20.1601051219390.21050@reclus.nhh.no>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAAcGz99G0w+nEDnmVog+d7HTZ9VJum=mfjeV7iaL-c6EcpMdKA@mail.gmail.com>
	<alpine.LFD.2.20.1601051219390.21050@reclus.nhh.no>
Message-ID: <CAAcGz9-tUm123qo93qB=ba-pq+MSn84NkR2idhyDEgwNPy=VkQ@mail.gmail.com>

On Tue, 5 Jan 2016 at 22:22 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> On Tue, 5 Jan 2016, Michael Sumner wrote:
>
> >> On Tue, 5 Jan 2016 at 21:09 Michael Sumner <mdsumner at gmail.com> wrote:
> >
> >> Hello, is there any R-level way to convert a WKT/PRJ *coordinate
system*
> > string to
> >> PROJ.4 used by sp/rgdal?
> >
> >
> >
> > I see it in ogr_proj.cpp at line 124:
> >
> >
> > if (hSRS->exportToProj4(&pszProj4) != OGRERR_NONE) {
> >
> > Roger, Edzer: could we please expose that functionality from rgdal to
input
> > WKT from R?
>
> That is exposed - the output comes in that of ogrInfo(), but needs the DSN
> and layer too.
>
> I've committed the reverse of showWKT() as showP4() in revision 596 on
> R-Forge - let me know if you need a Windows binary to test.
>

Brilliant, thanks for the help.

I could definitely use the Windows binary, this is for a Windows-specific
task. No huge rush, just whenever that is possible would be great.

(I'm sorry about the HTML postings, I can't see how to control Google Inbox
just how I need - I've reverted to Gmail in the hope it uses real ">"
characters, and will try to remember to do so for lists).

Cheers, Mike.

>
> Roger
>
> >
> >
> > Is that feasible? I'll have a look at doing it myself . . . I know it's
a
> > distraction from other goals.
> >
> >
> > Thank you.
> >
> >
> > Cheers, Mike.
> >
> >
> >
> >> (Previously I've written out to SHP/PRJ, and read back in with rgdal,
but
> > that's obviously a
> >> bit naff.)
> >
> >
> >> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
> >
> >
> >
> >> Cheers, Mike.
> >
> >
> >
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Tue Jan  5 12:30:30 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 5 Jan 2016 22:30:30 +1100
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAP8THHWqjx18+H+MyA4wd=xGYJUxhr_5x5Mbo=8=fp45Xt=nBQ@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
	<CAAcGz9-HLv27s2ePfZQDwvnqYo9cjF15FmR=vEU3+cqNdA+HOQ@mail.gmail.com>
	<CAP8THHWqjx18+H+MyA4wd=xGYJUxhr_5x5Mbo=8=fp45Xt=nBQ@mail.gmail.com>
Message-ID: <CAAcGz98n0CR+5o5_+TwrVMqb1JiKiu1YhUhRycvn7p+ascrqmw@mail.gmail.com>

On Tue, Jan 5, 2016 at 10:24 PM, Ahmadou Dicko <dicko.ahmadou at gmail.com> wrote:
> You can also use gdalsrsinfo through gdalUtils.
>
> prj_1 <- 'PROJCS["Transverse_Mercator",
>     GEOGCS["GCS_OSGB 1936",
>     DATUM["D_OSGB_1936",
>     SPHEROID["Airy_1830",6377563.396,299.3249646]],
>     PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
>     PROJECTION["Transverse_Mercator"],
>     PARAMETER["latitude_of_origin",49],
>     PARAMETER["central_meridian",-2],
>     PARAMETER["scale_factor",0.9996012717],
>     PARAMETER["false_easting",400000],
>     PARAMETER["false_northing",-100000],
>     UNIT["Meter",1]]'
>
>
> prj_to_epsg <- function(prj) {
>   file <- tempfile()
>   writeLines(prj, file)
>   crs <- gdalsrsinfo(file, as.CRS = TRUE)
>   unlink(file)
>   crs
> }
>
> prj_to_epsg(prj_1)
> ## CRS arguments:
> ##  +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
> ## +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs
>
>

Thanks for the heads-up, it's a good option to know.

All up I've been swamped with solutions in about one hour!

Cheers, Mike.


>
>
> On Tue, Jan 5, 2016 at 11:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>
>> >
>> >
>> > On Tue, 5 Jan 2016 at 21:58 boB Rudis <bob at rudis.net> wrote:
>> > This may not be optimal as it uses an external service:
>>
>>
>> That is excellent, thanks for the example!
>>
>> I assume you won't mind if I package it up?  I'll attribute you, and let
>> you know when it's working.
>>
>> Cheers, Mike.
>>
>>
>> > prj_to_epsg <- function(prj) {
>> >
>> > require(sp)
>> > require(httr)
>> > require(jsonlite)
>> >
>> > res <- GET("http://prj2epsg.org/search.json",
>> > query=list(exact=TRUE,
>> > error=TRUE,
>> > mode="wkt",
>> > terms=prj))
>> >
>> > # one shld prbly do more error checking than this
>> > stop_for_status(res)
>> >
>> > dat <- fromJSON(content(res, as="text", flatten=TRUE))
>> >
>> > # NOTE: there could be more in dat$codes if prj was ambiguous
>> > CRS(paste0("+init=epsg:", dat$codes[1, "code"]))
>> >
>> > }
>> >
>> > prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
>> > prj_to_epsg(prj)
>> > ## CRS arguments:
>> > ## +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
>> > ## +towgs84=0,0,0
>> >
>> > prj_1 <- 'PROJCS["Transverse_Mercator",
>> > GEOGCS["GCS_OSGB 1936",
>> > DATUM["D_OSGB_1936",
>> > SPHEROID["Airy_1830",6377563.396,299.3249646]],
>> > PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
>> > PROJECTION["Transverse_Mercator"],
>> > PARAMETER["latitude_of_origin",49],
>> > PARAMETER["central_meridian",-2],
>> > PARAMETER["scale_factor",0.9996012717],
>> > PARAMETER["false_easting",400000],
>> > PARAMETER["false_northing",-100000],
>> > UNIT["Meter",1]]'
>> > prj_to_epsg(prj_1)
>> > ## CRS arguments:
>> > ## +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
>> > ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
>> > ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894
>> >
>> > On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com>
>> > wrote:
>> > > Hello, is there any R-level way to convert a WKT/PRJ *coordinate
>> > > system*
>> > > string to PROJ.4 used by sp/rgdal?
>> > >
>> > > (Previously I've written out to SHP/PRJ, and read back in with rgdal,
>> but
>> > > that's obviously a bit naff.)
>> > >
>> > > (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>> > >
>> > > Cheers, Mike.
>> > >
>> > >
>> > >
>> > >
>> > > --
>> > > Dr. Michael Sumner
>> > > Software and Database Engineer
>> > > Australian Antarctic Division
>> > > 203 Channel Highway
>> > > Kingston Tasmania 7050 Australia
>> > >
>> > > [[alternative HTML version deleted]]
>> > >
>> > > _______________________________________________
>> > > R-sig-Geo mailing list
>> > > R-sig-Geo at r-project.org
>> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
> --
> Ahmadou H. DICKO
> statistician economist (Ing?nieur Statisticien ?conomiste)
> PhD candidate in Climate change economics
> Faculty of economics and managment - Cheikh Anta Diop University
> West African Science Service Center on Climate Change and Adaptated Land Use
> (WASCAL)
> Center for Development Research (ZEF) - University of Bonn
> email : ahmadou.dicko at ucad.edu.sn
> twitter : @dickoah
> github : github/dickoa
> tel : +221 33 827 55 16
> portable: +221 77 123 81 69



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From bob at rudis.net  Tue Jan  5 12:46:08 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 5 Jan 2016 06:46:08 -0500
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAJ4QxaOT8GpjZEub+SgCMp55hxfUc=3u0AuUr8drPHY5Qt65XA@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
	<CAJ4QxaOT8GpjZEub+SgCMp55hxfUc=3u0AuUr8drPHY5Qt65XA@mail.gmail.com>
Message-ID: <CAJ4QxaP0xsEfZxQUN5ESmtBkWdEyUyE1GKMNwDtg=syJAyKYSQ@mail.gmail.com>

rgdal 1-1.4 (built from rforge) has "showP4" (and "showWKT"):

  prj_1 <- 'PROJCS["Transverse_Mercator",
    GEOGCS["GCS_OSGB 1936",
    DATUM["D_OSGB_1936",
    SPHEROID["Airy_1830",6377563.396,299.3249646]],
    PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
    PROJECTION["Transverse_Mercator"],
    PARAMETER["latitude_of_origin",49],
    PARAMETER["central_meridian",-2],
    PARAMETER["scale_factor",0.9996012717],
    PARAMETER["false_easting",400000],
    PARAMETER["false_northing",-100000],
    UNIT["Meter",1]]'

  showP4(prj_1)
  ## [1] "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000
+y_0=-100000 +datum=OSGB36 +units=m +no_defs "

On Tue, Jan 5, 2016 at 6:20 AM, boB Rudis <bob at rudis.net> wrote:
> It's too early I guess as it didn't occur to me that if writing it out
> locally was naff using an external service is more so. The
> SpatialReference "importFromESRI()" function doesn't seem to be mapped
> in rgdal. That would be the function needed to avoid a
> write-out/external call.
>
> On Tue, Jan 5, 2016 at 5:57 AM, boB Rudis <bob at rudis.net> wrote:
>> This may not be optimal as it uses an external service:
>>
>>   prj_to_epsg <- function(prj) {
>>
>>     require(sp)
>>     require(httr)
>>     require(jsonlite)
>>
>>     res <- GET("http://prj2epsg.org/search.json",
>>                query=list(exact=TRUE,
>>                           error=TRUE,
>>                           mode="wkt",
>>                           terms=prj))
>>
>>     # one shld prbly do more error checking than this
>>     stop_for_status(res)
>>
>>     dat <- fromJSON(content(res, as="text", flatten=TRUE))
>>
>>     # NOTE: there could be more in dat$codes if prj was ambiguous
>>     CRS(paste0("+init=epsg:", dat$codes[1, "code"]))
>>
>>   }
>>
>>   prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
>>   prj_to_epsg(prj)
>>   ## CRS arguments:
>>   ##  +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
>>   ## +towgs84=0,0,0
>>
>>   prj_1 <- 'PROJCS["Transverse_Mercator",
>>     GEOGCS["GCS_OSGB 1936",
>>     DATUM["D_OSGB_1936",
>>     SPHEROID["Airy_1830",6377563.396,299.3249646]],
>>     PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
>>     PROJECTION["Transverse_Mercator"],
>>     PARAMETER["latitude_of_origin",49],
>>     PARAMETER["central_meridian",-2],
>>     PARAMETER["scale_factor",0.9996012717],
>>     PARAMETER["false_easting",400000],
>>     PARAMETER["false_northing",-100000],
>>     UNIT["Meter",1]]'
>>   prj_to_epsg(prj_1)
>>   ## CRS arguments:
>>   ##  +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
>>   ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
>>   ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894
>>
>> On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>> Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
>>> string to PROJ.4 used by sp/rgdal?
>>>
>>> (Previously I've written out to SHP/PRJ, and read back in with rgdal, but
>>> that's obviously a bit naff.)
>>>
>>> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>>>
>>> Cheers, Mike.
>>>
>>>
>>>
>>>
>>> --
>>> Dr. Michael Sumner
>>> Software and Database Engineer
>>> Australian Antarctic Division
>>> 203 Channel Highway
>>> Kingston Tasmania 7050 Australia
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Tue Jan  5 12:50:25 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 Jan 2016 12:50:25 +0100
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAAcGz9-tUm123qo93qB=ba-pq+MSn84NkR2idhyDEgwNPy=VkQ@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAAcGz99G0w+nEDnmVog+d7HTZ9VJum=mfjeV7iaL-c6EcpMdKA@mail.gmail.com>
	<alpine.LFD.2.20.1601051219390.21050@reclus.nhh.no>
	<CAAcGz9-tUm123qo93qB=ba-pq+MSn84NkR2idhyDEgwNPy=VkQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1601051247560.21050@reclus.nhh.no>

On Tue, 5 Jan 2016, Michael Sumner wrote:

> On Tue, 5 Jan 2016 at 22:22 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> On Tue, 5 Jan 2016, Michael Sumner wrote:
>>
>>>> On Tue, 5 Jan 2016 at 21:09 Michael Sumner <mdsumner at gmail.com> wrote:
>>>
>>>> Hello, is there any R-level way to convert a WKT/PRJ *coordinate
> system*
>>> string to
>>>> PROJ.4 used by sp/rgdal?
>>>
>>>
>>>
>>> I see it in ogr_proj.cpp at line 124:
>>>
>>>
>>> if (hSRS->exportToProj4(&pszProj4) != OGRERR_NONE) {
>>>
>>> Roger, Edzer: could we please expose that functionality from rgdal to
> input
>>> WKT from R?
>>
>> That is exposed - the output comes in that of ogrInfo(), but needs the DSN
>> and layer too.
>>
>> I've committed the reverse of showWKT() as showP4() in revision 596 on
>> R-Forge - let me know if you need a Windows binary to test.
>>
>
> Brilliant, thanks for the help.
>
> I could definitely use the Windows binary, this is for a Windows-specific
> task. No huge rush, just whenever that is possible would be great.

On: http://win-builder.r-project.org/w96p7wcx7fi4 for this development 
version.

Roger

>
> (I'm sorry about the HTML postings, I can't see how to control Google Inbox
> just how I need - I've reverted to Gmail in the hope it uses real ">"
> characters, and will try to remember to do so for lists).
>
> Cheers, Mike.
>
>>
>> Roger
>>
>>>
>>>
>>> Is that feasible? I'll have a look at doing it myself . . . I know it's
> a
>>> distraction from other goals.
>>>
>>>
>>> Thank you.
>>>
>>>
>>> Cheers, Mike.
>>>
>>>
>>>
>>>> (Previously I've written out to SHP/PRJ, and read back in with rgdal,
> but
>>> that's obviously a
>>>> bit naff.)
>>>
>>>
>>>> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>>>
>>>
>>>
>>>> Cheers, Mike.
>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue Jan  5 12:58:33 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 5 Jan 2016 12:58:33 +0100
Subject: [R-sig-Geo] WKT coordinate system string (PRJ) to PROJ.4
In-Reply-To: <CAJ4QxaP0xsEfZxQUN5ESmtBkWdEyUyE1GKMNwDtg=syJAyKYSQ@mail.gmail.com>
References: <CAAcGz9-HTm4+aQ_mMQ8s2-ZDGpXBxNyoj7hX2ETBUddA4FyvLQ@mail.gmail.com>
	<CAJ4QxaOh4RU+fv9w8wudYcem7VMY051-hwzCge3vo7uMNF6+_g@mail.gmail.com>
	<CAJ4QxaOT8GpjZEub+SgCMp55hxfUc=3u0AuUr8drPHY5Qt65XA@mail.gmail.com>
	<CAJ4QxaP0xsEfZxQUN5ESmtBkWdEyUyE1GKMNwDtg=syJAyKYSQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1601051250580.21050@reclus.nhh.no>

On Tue, 5 Jan 2016, boB Rudis wrote:

> rgdal 1-1.4 (built from rforge) has "showP4" (and "showWKT"):
>
>  prj_1 <- 'PROJCS["Transverse_Mercator",
>    GEOGCS["GCS_OSGB 1936",
>    DATUM["D_OSGB_1936",
>    SPHEROID["Airy_1830",6377563.396,299.3249646]],
>    PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
>    PROJECTION["Transverse_Mercator"],
>    PARAMETER["latitude_of_origin",49],
>    PARAMETER["central_meridian",-2],
>    PARAMETER["scale_factor",0.9996012717],
>    PARAMETER["false_easting",400000],
>    PARAMETER["false_northing",-100000],
>    UNIT["Meter",1]]'
>
>  showP4(prj_1)
>  ## [1] "+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000
> +y_0=-100000 +datum=OSGB36 +units=m +no_defs "

Thanks for checking. The functions do use morphFromESRI() if requested - 
I'll revisit this so that morphing from on import and to on export are 
settable options for relevant functions, even when there are no arguments. 
I find

http://www.gdal.org/classOGRSpatialReference.html#af91af2639702e2793daf93ffe231b577

http://www.gdal.org/classOGRSpatialReference.html#ad556dfdc04d9ec5f1714fc6b5e0eb6a6

etc. confusing, given the need to set GDAL_FIX_ESRI_WKT in some cases. 
Adding towgs84 values does need attention - contributions welcome!

Roger

>
> On Tue, Jan 5, 2016 at 6:20 AM, boB Rudis <bob at rudis.net> wrote:
>> It's too early I guess as it didn't occur to me that if writing it out
>> locally was naff using an external service is more so. The
>> SpatialReference "importFromESRI()" function doesn't seem to be mapped
>> in rgdal. That would be the function needed to avoid a
>> write-out/external call.
>>
>> On Tue, Jan 5, 2016 at 5:57 AM, boB Rudis <bob at rudis.net> wrote:
>>> This may not be optimal as it uses an external service:
>>>
>>>   prj_to_epsg <- function(prj) {
>>>
>>>     require(sp)
>>>     require(httr)
>>>     require(jsonlite)
>>>
>>>     res <- GET("http://prj2epsg.org/search.json",
>>>                query=list(exact=TRUE,
>>>                           error=TRUE,
>>>                           mode="wkt",
>>>                           terms=prj))
>>>
>>>     # one shld prbly do more error checking than this
>>>     stop_for_status(res)
>>>
>>>     dat <- fromJSON(content(res, as="text", flatten=TRUE))
>>>
>>>     # NOTE: there could be more in dat$codes if prj was ambiguous
>>>     CRS(paste0("+init=epsg:", dat$codes[1, "code"]))
>>>
>>>   }
>>>
>>>   prj <- paste0(readLines("110m_admin_1_states_provinces_shp.prj"))
>>>   prj_to_epsg(prj)
>>>   ## CRS arguments:
>>>   ##  +init=epsg:4326 +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
>>>   ## +towgs84=0,0,0
>>>
>>>   prj_1 <- 'PROJCS["Transverse_Mercator",
>>>     GEOGCS["GCS_OSGB 1936",
>>>     DATUM["D_OSGB_1936",
>>>     SPHEROID["Airy_1830",6377563.396,299.3249646]],
>>>     PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],
>>>     PROJECTION["Transverse_Mercator"],
>>>     PARAMETER["latitude_of_origin",49],
>>>     PARAMETER["central_meridian",-2],
>>>     PARAMETER["scale_factor",0.9996012717],
>>>     PARAMETER["false_easting",400000],
>>>     PARAMETER["false_northing",-100000],
>>>     UNIT["Meter",1]]'
>>>   prj_to_epsg(prj_1)
>>>   ## CRS arguments:
>>>   ##  +init=epsg:27700 +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717
>>>   ## +x_0=400000 +y_0=-100000 +datum=OSGB36 +units=m +no_defs +ellps=airy
>>>   ## +towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894
>>>
>>> On Tue, Jan 5, 2016 at 5:09 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>>> Hello, is there any R-level way to convert a WKT/PRJ *coordinate system*
>>>> string to PROJ.4 used by sp/rgdal?
>>>>
>>>> (Previously I've written out to SHP/PRJ, and read back in with rgdal, but
>>>> that's obviously a bit naff.)
>>>>
>>>> (I know you can rgeos::readWKT and wkb::readWKB for *geometry*).
>>>>
>>>> Cheers, Mike.
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Dr. Michael Sumner
>>>> Software and Database Engineer
>>>> Australian Antarctic Division
>>>> 203 Channel Highway
>>>> Kingston Tasmania 7050 Australia
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From jgrn at illinois.edu  Tue Jan  5 18:07:59 2016
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Tue, 05 Jan 2016 17:07:59 +0000
Subject: [R-sig-Geo] Trouble with 'gdal_grid'
In-Reply-To: <2140f88b20a643c092e647dbafbda6fe@BEHQWINEXC06.sesvanderhave.net>
References: <2140f88b20a643c092e647dbafbda6fe@BEHQWINEXC06.sesvanderhave.net>
Message-ID: <CABG0rfuFYWzawXGj=1PVVhCgk6CaWJfHCtfcYexxFSp8wEg0=w@mail.gmail.com>

Xavier:

It looks like gdalUtils is not finding your install of GDAL -- first
question, are you up to date with the latest gdalUtils?

gdalUtils will only look in "standard" locations for the installs -- if you
have your install in a non-standard location (easy to do with the OSGEO
installer, since you can set the install directory to wherever you want
it), then you can fix it the following two ways:

1) Brute force-- as the error above stated, if you run:
gdal_setInstallation(ignore.full_scan=FALSE)

It will do a brute force search for it on your computer.  This could take
awhile, since it is searching your entire hard drive for any and all valid
gdal installs (technically, it is looking for the folder with "gdalinfo" or
"gdalinfo.exe").

A faster step would be before you run gdal_grid to:
1) Manually search on your computer for "gdal_grid.exe" -- you need to know
what folder it is hiding in.
2) Run:
gdal_setInstallation(search_path="pathto/gdalexecutables",rescan=T)

Note that gdalUtils does NOT use rgdal's install -- rgdal doesn't contain
the executables typically, at any rate.

Hope this helps!  Please let me know if you are still having problems.  I'm
going to cc r-sig-geo in this email (with your contact info removed) so
there is a record of this suggestion.

--j


> Dear Jonathan,
>
>
>
> I am trying to use the R wrapper ?gdal_grid? from the ?gdalUtils? R
> package, in order to perform interpolation on a dataset. But I encounter
> difficulties.
>
>
>
> Running a copy-paste of the example on p 37-38 of the package
> documentation:
>
>
>
> *# We'll pre-check to make sure there is a valid GDAL install*
>
> *# and that raster and rgdal are also installed.*
>
> *# Note this isn't strictly neccessary, as executing the function will*
>
> *# force a search for a valid GDAL install.*
>
> *gdal_setInstallation()*
>
> *valid_install <- !is.null(getOption("gdalUtils_gdalPath"))*
>
> *if(require(raster) && valid_install)*
>
> *{*
>
> *# Create a properly formatted CSV:*
>
> *temporary_dir <- tempdir()*
>
> *tempfname_base <- file.path(temporary_dir,"dem")*
>
> *tempfname_csv <- paste(tempfname_base,".csv",sep="")*
>
> *pts <- data.frame(*
>
> *Easting=c(86943.4,87124.3,86962.4,87077.6),*
>
> *Northing=c(891957,892075,892321,891995),*
>
> *Elevation=c(139.13,135.01,182.04,135.01)*
>
> *)*
>
> *write.csv(pts,file=tempfname_csv,row.names=FALSE)*
>
> *# Now make a matching VRT file*
>
> *tempfname_vrt <- paste(tempfname_base,".vrt",sep="")*
>
> *vrt_header <- c(*
>
> *'<OGRVRTDataSource>',*
>
> *'\t<OGRVRTLayer name="dem">',*
>
> *'\t<SrcDataSource>dem.csv</SrcDataSource>',*
>
> *'\t<GeometryType>wkbPoint</GeometryType>',*
>
> *'\t<GeometryField encoding="PointFromColumns" x="Easting" y="Northing"
> z="Elevation"/>',*
>
> *'\t</OGRVRTLayer>',*
>
> *'\t</OGRVRTDataSource>'*
>
> *)*
>
> *vrt_filecon <- file(tempfname_vrt,"w")*
>
> *writeLines(vrt_header,con=vrt_filecon)*
>
> *close(vrt_filecon)*
>
> *tempfname_tif <- paste(tempfname_base,".tiff",sep="")*
>
> *# Now run gdal_grid:*
>
> *setMinMax(gdal_grid(src_datasource=tempfname_vrt,*
>
> *dst_filename=tempfname_tif,a="invdist:power=2.0:smoothing=1.0",*
>
> *txe=c(85000,89000),tye=c(894000,890000),outsize=c(400,400),*
>
> *of="GTiff",ot="Float64",l="dem",output_Raster=TRUE))*
>
> *}*
>
>
>
> Leads to the following message after the following two lines of code:
>
>
>
> > library(gdalUtils)
>
> > gdal_setInstallation()
>
> Warning messages:
>
> 1: In gdal_setInstallation() :
>
>   No GDAL installation found. Please install 'gdal' before continuing:
>
>         - www.gdal.org (no HDF4 support!)
>
>         - www.trac.osgeo.org/osgeo4w/ (with HDF4 support RECOMMENDED)
>
>         - www.fwtools.maptools.org (with HDF4 support)
>
>
>
> 2: In gdal_setInstallation() : If you think GDAL is installed, please run:
>
> gdal_setInstallation(ignore.full_scan=FALSE)
>
>
>
> However, I do have GDAL installed on my computer. GDAL was installed using
> the option 2 mentioned in the above Warning message (i.e.
> http://trac.osgeo.org/osgeo4w/).
>
>
>
> Also, loading and using the ?rgdal? package is no problem, as shown in the
> small example below:
>
>
>
> > setwd("D:/GIS/Preprocessing/Factories_and_beet_zones")
>
> > ### Subsetting ".csv" file for operating factories of a given year only
>
> > DF <- read.csv(file="Factories.csv", header = TRUE, sep = ";", dec = "," )
>
> > DF2 <- subset(DF, Year == "2013")
>
> > DF3 <- subset(DF2, Operating == "yes")
>
> >
>
> > ### Specifying project CRS
>
> > library(rgdal)
>
> Loading required package: sp
>
> rgdal: version: 1.1-1, (SVN revision 572)
>
>  Geospatial Data Abstraction Library extensions to R successfully loaded
>
>  Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
>
>  Path to GDAL shared files: C:/Users/sauvenier.xavier/Documents/R/win-library/3.2/rgdal/gdal
>
>  GDAL does not use iconv for recoding strings.
>
>  Loaded PROJ.4 runtime: Rel. 4.9.1, 04 March 2015, [PJ_VERSION: 491]
>
>  Path to PROJ.4 shared files: C:/Users/sauvenier.xavier/Documents/R/win-library/3.2/rgdal/proj
>
>  Linking to sp version: 1.2-1
>
> > project_CRS <- CRS("+init=epsg:4326") #WGS84
>
>
>
> I have spent quite some time trying to understand what is going on. But so
> far I have failed.
>
>
>
> My R version is 3.2.2. My platform is a windows 64-bit (Windows Server 2012 Datacenter). And
>
>
>
> Would you have any idea on what I am doing wrong?
>
>
>
> Thanks for any help.
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160105/3fbd87f1/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.gif
Type: image/gif
Size: 4567 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160105/3fbd87f1/attachment.gif>

From hiztirab at yahoo.com  Wed Jan  6 04:40:09 2016
From: hiztirab at yahoo.com (Iztirab Hussain)
Date: Wed, 6 Jan 2016 03:40:09 +0000 (UTC)
Subject: [R-sig-Geo] APHRODITE V1101R2 NetCDF
References: <954720456.567651.1452051609548.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <954720456.567651.1452051609548.JavaMail.yahoo@mail.yahoo.com>

Hi everyoneWould any one like to share the script to handle the above mentioned .nc file in rstudio to get the output in text,csv or xlsx.The dimention of this data set are as below180 x 140 elements for APHROSpatial coverage      :  (MA) 60.0E - 150.0E, 15.0S - 55.0N Spatial resolution    :  0.5 degree and 0.25 degree latitude/longitude
 Temporal coverage     :  January 1, 1951 - December 31, 2007 (57 years)
 Temporal resolution   :  DailyRegardsShakir

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Wed Jan  6 05:54:09 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 6 Jan 2016 15:54:09 +1100
Subject: [R-sig-Geo] APHRODITE V1101R2 NetCDF
In-Reply-To: <954720456.567651.1452051609548.JavaMail.yahoo@mail.yahoo.com>
References: <954720456.567651.1452051609548.JavaMail.yahoo.ref@mail.yahoo.com>
	<954720456.567651.1452051609548.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAcGz9_HaLpvwboZxX+6Q-_PV0qp5pvwwJMusCFdO7mDPy6-1w@mail.gmail.com>

On Wed, Jan 6, 2016 at 2:40 PM, Iztirab Hussain via R-sig-Geo
<r-sig-geo at r-project.org> wrote:
> Hi everyoneWould any one like to share the script to handle the above mentioned .nc file in rstudio to get the output in text,csv or xlsx.The dimention of this data set are as below180 x 140 elements for APHROSpatial coverage      :  (MA) 60.0E - 150.0E, 15.0S - 55.0N Spatial resolution    :  0.5 degree and 0.25 degree latitude/longitude
>  Temporal coverage     :  January 1, 1951 - December 31, 2007 (57 years)
>  Temporal resolution   :  DailyRegardsShakir


I would start with this:

library(ncdf4)  ## note this is now available on Windows via CRAN
(since Dec 2015)
library(raster)

r <- raster("myfile.nc")

## if that works, try
plot(r)

>From there you can do anything you like, including convert to a text
format - but I wouldn't recommend that!  See the help for ?raster and
come back with questions if you can't get what you need. Please read
the posting guidelines and provide details.

(If raster complains about a non-regular grid it's another story, but
still easy enough to deal with using ncdf4 directly or with raster's
cunning tricks. If you need help there you'll need to provide a link
to an exact file specifically so someone can try. )

Cheers, Mike.





>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From madiazl at gmail.com  Wed Jan  6 11:04:05 2016
From: madiazl at gmail.com (Andres Diaz)
Date: Wed, 6 Jan 2016 11:04:05 +0100
Subject: [R-sig-Geo] APHRODITE V1101R2 NetCDF
In-Reply-To: <CAAcGz9_HaLpvwboZxX+6Q-_PV0qp5pvwwJMusCFdO7mDPy6-1w@mail.gmail.com>
References: <954720456.567651.1452051609548.JavaMail.yahoo.ref@mail.yahoo.com>
	<954720456.567651.1452051609548.JavaMail.yahoo@mail.yahoo.com>
	<CAAcGz9_HaLpvwboZxX+6Q-_PV0qp5pvwwJMusCFdO7mDPy6-1w@mail.gmail.com>
Message-ID: <CAMXOh=3E2eB=jaywofOvmHDtbJY1j1p4LQJJyLYtcdGOh0y5DA@mail.gmail.com>

Dear Iztirab,

For the size of your data you can use the package ncdf4 and rdhf5,
nevertheless, I was working with these files some weeks ago, and when the
files have huge quantity of data (I was working in a global scale with file
of 800 millions of elements) the RAM memory collapse. Python in this sense
is a little bit more powerful for the managing of big quantity of data.

If you decide to use python, the library to install is called netCDF4

Best,


Andr?s D?az
Postdoctoral Researcher
Institute for Environmental Studies - IVM
VU University Amsterdam
De Boelelaan 1085 (visiting address)
De Boelelaan 1087 (postal address)
1081 HV Amsterdam, The Netherlands
t: + 31 (0)20 5983232
email: andres.diazloaiza at vu.nl
Office: A602
IVM - Because the Earth matters

2016-01-06 5:54 GMT+01:00 Michael Sumner <mdsumner at gmail.com>:

> On Wed, Jan 6, 2016 at 2:40 PM, Iztirab Hussain via R-sig-Geo
> <r-sig-geo at r-project.org> wrote:
> > Hi everyoneWould any one like to share the script to handle the above
> mentioned .nc file in rstudio to get the output in text,csv or xlsx.The
> dimention of this data set are as below180 x 140 elements for APHROSpatial
> coverage      :  (MA) 60.0E - 150.0E, 15.0S - 55.0N Spatial resolution
> :  0.5 degree and 0.25 degree latitude/longitude
> >  Temporal coverage     :  January 1, 1951 - December 31, 2007 (57 years)
> >  Temporal resolution   :  DailyRegardsShakir
>
>
> I would start with this:
>
> library(ncdf4)  ## note this is now available on Windows via CRAN
> (since Dec 2015)
> library(raster)
>
> r <- raster("myfile.nc")
>
> ## if that works, try
> plot(r)
>
> >From there you can do anything you like, including convert to a text
> format - but I wouldn't recommend that!  See the help for ?raster and
> come back with questions if you can't get what you need. Please read
> the posting guidelines and provide details.
>
> (If raster complains about a non-regular grid it's another story, but
> still easy enough to deal with using ncdf4 directly or with raster's
> cunning tricks. If you need help there you'll need to provide a link
> to an exact file specifically so someone can try. )
>
> Cheers, Mike.
>
>
>
>
>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From hengl at spatial-analyst.net  Wed Jan  6 18:24:51 2016
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Wed, 6 Jan 2016 18:24:51 +0100
Subject: [R-sig-Geo] GEOSTAT 2016 Summer School for PhD students,
 17-24 September 2016, Albacete Spain
Message-ID: <568D4DE3.2090206@spatial-analyst.net>


The GEOSTAT 2016 Summer School for PhD students and R-sig-geo 
enthusiasts will be held this year at the University of Castilla-La 
Mancha, Albacete, Spain in the period 17-24 September (arrive Sunday to 
depart Sunday). The topics include: spatial and spatio-temporal data and 
analysis in R, spatial and spatio-temporal geostatistics, processing 
large rasters using the raster package, CartoDB and gvSIG software 
tutorials, visualization of spatial and spatio-temporal data in Google 
Earth. To register for this summer school please visit:

http://geostat-course.org/2016

Please note the registration deadline: March 1st 2016.

This summer school is limited to 55 participants. Selection of 
candidates is based on a ranking system, which is based on: time of 
registration, solidarity (participants further away from the venue 
receive higher ranking), academic record, and contributions to open 
source projects. The registration costs for the summer school are 
typically between EUR 400 and 500; these cover the actual costs, no 
profits are made. Accommodation will cost ca (EUR 40) per person per 
night (not included in the course fees). The organizers provide no 
funding/scholarships to participants. Participants from ODA-listed 
countries (http://www.oecd.org/dac/stats/daclist), however, can apply 
for a subsidized price for registration costs.

Lecturers:
- Roger Bivand: Representing and handling spatial and spatio-temporal 
data in R: sp, rgdal, maptools packages
- Edzer Pebesma: Handling and analyzing spatio-temporal data with R
- Robert Hijmans: Spatial modeling with environmental data (raster and 
dismo packages)
- Marta Blangiardo: Bayesian spatiotemporal models in R
- Michela Cameletti: Spatio-temporal models for environmental data in R
- Matthias Templ: Robust analysis of compositional data / Small Area 
Estimation
- Jorge Sanz: CartoDB tutorial
- C?sar Mart?nez Izquierdo: gvSIG tutorial
- Virgilio Gomez Rubio: Spatial and Spatiotemporal point process 
analysis in R
- Tomislav Hengl: Automated geostatistics and visualization in 3D+T: 
GSIF and plotKML packages

To register for this Summer school visit:

http://geostat-course.org/register

For more information about GEOSTAT 2016 please write to:
- T. (Tom) Hengl: registrations, website materials
- V. (Virgilio) Gomez Rubio: the official program, local organizer

Local organizing committee: Esteban Alfaro-Cort?s, Jos? Luis 
Alfaro-Navarro, Mar?a Teresa Alonso-Mart?nez, Mat?as G?mez-Mart?nez, 
Noelia Garc?a-Rubio, Virgilio G?mez-Rubio (Chair), Emilio L. Cano, 
Francisco Palm? Perales and Francisco Parre?o-Torres.


From bakht013 at umn.edu  Thu Jan  7 04:58:55 2016
From: bakht013 at umn.edu (Maryia Bakhtsiyarava)
Date: Wed, 6 Jan 2016 21:58:55 -0600
Subject: [R-sig-Geo] specifying time period for splm
Message-ID: <CAKFowAhH-UEJ23SU3x8ja6OhDZxKkZzk6CFMDSDUq1JyJHd=XA@mail.gmail.com>

Hello,

I would be very thankful for any help with my issue. I am relatively new to
R and would greatly appreciate your help.

I am trying to run spatial panel data models using the "splm," package. I
studied the manual and have been closely following the article by G. Millo
and G. Piras in the Journal of Statistical Software titled "splm: Spatial
Panel Data Models in R" to create my own models. What I don't seem to
understand is how R understands that the data are arranged in time series..
I have repeated observations for spatial units for 5 years, however, I have
not found where in the script I need to specify the periods. I looked at
the data Millo used in the article, and even though the data are arranged
by years, there is no explicit mention in the code or article of how to
pass the time periods to R.

Let's assume I have the following:
I construct a spatial weights matrix (sp_weightsm) from the shapefile of my
spatial units.
my formula is: fm1<-y~x1+x2+x3
mod1<-spml(formula = fm2, data = sids, index=NULL, listw=sp_weightsm,
lag=TRUE, spatial.error = "b", model = "within", effect = "individual",
method = "eigen", na.action = na.fail, quiet = TRUE, zero.policy = NULL,
tot.solve = 1e-10, control=list(), legacy=FALSE)

my data has the following structure:
                        Year   X1   X2
Spatial Unit 1  2000   ....   .....
Spatial Unit 1  2001
Spatial Unit 2  2000
Spatial Unit 2  2001
Spatial Unit n  .....

This model runs without errors however I am pretty sure the results are not
meaningful because how would R know the time periods?
So, my question is: How do I pass on the time periods to R? Do I need to
subset my dataset into different parts based on years?

Thank you in advance,
Maria

	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Thu Jan  7 06:52:24 2016
From: tmeeha at gmail.com (Tim Meehan)
Date: Wed, 6 Jan 2016 22:52:24 -0700
Subject: [R-sig-Geo] specifying time period for splm
In-Reply-To: <CAKFowAhH-UEJ23SU3x8ja6OhDZxKkZzk6CFMDSDUq1JyJHd=XA@mail.gmail.com>
References: <CAKFowAhH-UEJ23SU3x8ja6OhDZxKkZzk6CFMDSDUq1JyJHd=XA@mail.gmail.com>
Message-ID: <CAMTWOzqP=B+0gTVjpRrw7squaQMBRzrM2DHnOFejCYCmcPJc2g@mail.gmail.com>

Hi Maryia,

I think you are on the right track.  From the JSS paper (page 3), your data
can be:

1. A data.frame whose first two variables (columns) are the individual and
time indexes. The data should be sorted by individual (Spatial Unit) and
then time (Year), like you have it.  In this case the index argument in the
call to spml should be left to the default value, which it is in your
example.  Note that it isn't clear in your example if the first column
(with Spatial Unit 1) is an actual column in the dataframe or the row
names.  If it is row names, then you can make it a column with
'yourdata$Unit <- row.names(yourdata)', and then move it to the first
column with 'yourdata <- yourdata[,c(4,1,2,3)]'.

The other option is:
?
2. A data.frame and a character vector indicating the indexes variables.
In this case, the indices wouldn't be the first two columns.  They would be
somewhere else in the dataframe.  But you would specify the columns in the
call to spml by adding something like 'index=c("Unit", "Year")'.  But, even
in this case, I would presort the dataframe by Unit and Year to be safe.

One thing that I think is important:

When you import the shapefile to make weights, there is a good chance that
the shapes won't be sorted according to the spatial units column in your
dataset.  That is, the first shape might not actually be Spatial Unit 1,
like in you sorted data from above.  To check, you can create a
SpatialPolygonDataFrame called, say, 'spdf1' and then run something like
'plot(spdf1[1])' to see if R plots Spatial Unit 1 or something else.  If
the shape order is different, you should reorder your
SpatialPolygonDataFrame after creating it from the shapefile but before
making weights.  If this is the case, let me know and I can send along a
code chunk to do this.

Best,
Tim


On Wed, Jan 6, 2016 at 8:58 PM, Maryia Bakhtsiyarava <bakht013 at umn.edu>
wrote:

> Hello,
>
> I would be very thankful for any help with my issue. I am relatively new to
> R and would greatly appreciate your help.
>
> I am trying to run spatial panel data models using the "splm," package. I
> studied the manual and have been closely following the article by G. Millo
> and G. Piras in the Journal of Statistical Software titled "splm: Spatial
> Panel Data Models in R" to create my own models. What I don't seem to
> understand is how R understands that the data are arranged in time series..
> I have repeated observations for spatial units for 5 years, however, I have
> not found where in the script I need to specify the periods. I looked at
> the data Millo used in the article, and even though the data are arranged
> by years, there is no explicit mention in the code or article of how to
> pass the time periods to R.
>
> Let's assume I have the following:
> I construct a spatial weights matrix (sp_weightsm) from the shapefile of my
> spatial units.
> my formula is: fm1<-y~x1+x2+x3
> mod1<-spml(formula = fm2, data = sids, index=NULL, listw=sp_weightsm,
> lag=TRUE, spatial.error = "b", model = "within", effect = "individual",
> method = "eigen", na.action = na.fail, quiet = TRUE, zero.policy = NULL,
> tot.solve = 1e-10, control=list(), legacy=FALSE)
>
> my data has the following structure:
>                         Year   X1   X2
> Spatial Unit 1  2000   ....   .....
> Spatial Unit 1  2001
> Spatial Unit 2  2000
> Spatial Unit 2  2001
> Spatial Unit n  .....
>
> This model runs without errors however I am pretty sure the results are not
> meaningful because how would R know the time periods?
> So, my question is: How do I pass on the time periods to R? Do I need to
> subset my dataset into different parts based on years?
>
> Thank you in advance,
> Maria
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From juantomas.sayago at gmail.com  Thu Jan  7 07:27:08 2016
From: juantomas.sayago at gmail.com (Juan Tomas Sayago Gomez)
Date: Wed, 6 Jan 2016 22:27:08 -0800
Subject: [R-sig-Geo] spml package and impacts calcultion
In-Reply-To: <CAPiOR55d6_WvWQqO+ytHOEM-aiwfrWrK1=FDdW4Xd6kQKS3ZjQ@mail.gmail.com>
References: <CAPiOR57CJ7PFHWTneUm2WdwbwWDA9dTfkT5n6hcibVHXk4xKhA@mail.gmail.com>
	<567B0F78.9030106@uni-muenster.de>
	<alpine.LFD.2.20.1512232333340.20265@reclus.nhh.no>
	<CAPiOR54GduSeE4uc91c7Fd+PRF0-4mUofvFvyTt3bO2R4Y4bAQ@mail.gmail.com>
	<CAPiOR55d6_WvWQqO+ytHOEM-aiwfrWrK1=FDdW4Xd6kQKS3ZjQ@mail.gmail.com>
Message-ID: <CAEOXpND+ks4_upkHDG1RkuP9ETQngRDFd90u0BsAE52LmESJsQ@mail.gmail.com>

There is no methodology to estimate impacts for SEM, because the direct and
indirect impacts are only estimated for values that include the lag of your
dependent variable. However when you estimate SEM or SDEM or SLX, you don't
have to estimate the impacts and your coefficients will be interpreted as
in a regression.
Hope this helps,
Juan

On Mon, Dec 28, 2015 at 11:32 AM, Daniel Furlan Amaral <dfamaral at gmail.com>
wrote:

> Hi,
>
> I would like to present some other questions I can't solve.
>
> 1) I have to estimate a Spatial Durbin Panel Model (SDM) and a Spatial
> Durbin Error Model (SDEM). The problem is that the command *lag.listw* does
> not work for panel datasets and results in an error message:
>
>
>
> *Wx <- lag.listw(W, x)Error in lag.listw(W, x) : object lengths differ*
> Is there any command in spml (or any other package) to create spatial lag
> of regressors automatically? Or I need to do it manually?
>
> 2) Is there any control for heteroskedasticity for Spatial Panel Models in
> splm (or any other package)?
>
> 3) I need the log-Likelihood method for SAR, SEM and SARAR panel models. If
> I follow the method described in
>
> http://r-sig-geo.2731867.n2.nabble.com/spml-and-logLik-help-td7581581.html
>
> , SEM estimations get an error, so I decided to use the option quiet =
> FALSE. Doing this, I got a function value: -34101.08. The value to report
> in the paper should be -ln(34101.08), i.e, 10.43708?
>
> 4) I need to calculate impacts from Spatial Error Model:
>
> *efsem <- spml(fm, data = tb, index = "Cod_mun", listw = W, model =
> "within", spatial.error = "b", lag = FALSE, quiet = FALSE)*
>
>
> *impsem <- impacts(efsem, listw = W, style="W", time = 10)*
> But I receive this error message:
>
>
> *Error in impacts.splm(efsem, listw = W, style = "W", time = 10): object
> type not recognized*
> Does anyone know how to calculate impacts for panel SEM?
>
> Thank you.
>
>
>
> 2015-12-28 11:57 GMT-02:00 Daniel Furlan Amaral <dfamaral at gmail.com>:
>
> > Thank you, Mr. Roger.
> >
> > Best regards,
> >
> > Daniel.
> >
> > 2015-12-23 20:39 GMT-02:00 Roger Bivand <Roger.Bivand at nhh.no>:
> >
> >> On Wed, 23 Dec 2015, Edzer Pebesma wrote:
> >>
> >>
> >>>
> >>> On 23/12/15 22:02, Daniel Furlan Amaral wrote:
> >>>
> >>>> Dear all,
> >>>>
> >>>> Does anyone know about packages or commands to calculate direct,
> >>>> indirect
> >>>> and total impacts? I didn't find it on spml package.
> >>>>
> >>>
> >>> package spdep has impacts methods for some models, see ?impacts :
> >>>
> >>> library(spdep)
> >>>>
> >>> Loading required package: Matrix
> >>>
> >>>> methods(impacts)
> >>>>
> >>> [1] impacts.gmsar* impacts.sarlm* impacts.stsls*
> >>>
> >>>
> >> and model fitting functions in the splm package use those in their own
> >> method:
> >>
> >> library(splm)
> >>> methods(impacts)
> >>>
> >> [1] impacts.gmsar* impacts.sarlm* impacts.splm*  impacts.stsls*
> >>
> >> so use that method in the same way.
> >>
> >> Roger
> >>
> >>
> >>>> Thank you.
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> _______________________________________________
> >>>> R-sig-Geo mailing list
> >>>> R-sig-Geo at r-project.org
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>>
> >>>>
> >>>
> >>>
> >> --
> >> Roger Bivand
> >> Department of Economics, Norwegian School of Economics,
> >> Helleveien 30, N-5045 Bergen, Norway.
> >> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >> e-mail: Roger.Bivand at nhh.no
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Juan Tom?s Sayago G?mez
Graduate Research Assistant
West Virginia University - RRI
886 Chestnut Ridge Road, Room 520
P.O. Box 6825
Morgantown, WV 26506-6825

	[[alternative HTML version deleted]]


From km314 at student.le.ac.uk  Thu Jan  7 21:24:36 2016
From: km314 at student.le.ac.uk (Mistry, Krishan)
Date: Thu, 7 Jan 2016 20:24:36 +0000
Subject: [R-sig-Geo] R Help
Message-ID: <DB5PR06MB13849A3356C08C045F02E36A98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>

Dear Sir/Madame,

I am currently a Masters student at the University of Leicester in the UK studying MSc Geographical Information Science and am having a bit of difficulty with the programme R. I am a new user of the programme and don't have any previous experience in programming. Having looked at various web sites, I wondered if you are able to help me with some trouble i am having in trying to write some code for a mathematical equation.
I have attached the question to this email and it can be seen below. The dataset is a list of polygons with each polygon containing another list within it, of x and y coordinates.

I would really appreciate it, if you could help me with this question.

Question
Create functions to compute the area, centroid and perimeter of a polygon list (as in the format of georgia.polys). The formula for the area of a polygon is

A=0.5*?(x? y???) (x??? y?)      for i until n-1

where A is the polygon area, xi is the ith x-coordinate of the polygon boundary (x[i] in R), yi is the ith ycoordinate of the polygon boundary (y[i] in R) - and n is the number of points used to specify the polygon boundary. The polygon is assumed to be in closed form so that the x1 and y1 take the same value as xn and yn.

Hope to hear from you soon.

Yours sincerely

Krishan Mistry



	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Jan  7 21:31:05 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 7 Jan 2016 15:31:05 -0500
Subject: [R-sig-Geo] R Help
In-Reply-To: <DB5PR06MB13849A3356C08C045F02E36A98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
References: <DB5PR06MB13849A3356C08C045F02E36A98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
Message-ID: <CAM_vjumzWzQQGnK8H_hg+v0N3rK6OWBhkL-DjY2zQEjByMZOJQ@mail.gmail.com>

As you will see below, posting in HTML format made your question unreadable.

However, this looks rather like homework, and if so then you should
look for help from the resources associated with your course.

If it isn't homework, you will get much more assistance if you provide
a reproducible example including data and the code you've tried
already.

Sarah

On Thu, Jan 7, 2016 at 3:24 PM, Mistry, Krishan <km314 at student.le.ac.uk> wrote:
> Dear Sir/Madame,
>
> I am currently a Masters student at the University of Leicester in the UK studying MSc Geographical Information Science and am having a bit of difficulty with the programme R. I am a new user of the programme and don't have any previous experience in programming. Having looked at various web sites, I wondered if you are able to help me with some trouble i am having in trying to write some code for a mathematical equation.
> I have attached the question to this email and it can be seen below. The dataset is a list of polygons with each polygon containing another list within it, of x and y coordinates.
>
> I would really appreciate it, if you could help me with this question.
>
> Question
> Create functions to compute the area, centroid and perimeter of a polygon list (as in the format of georgia.polys). The formula for the area of a polygon is
>
> A=0.5*?(x? y???) (x??? y?)      for i until n-1
>
> where A is the polygon area, xi is the ith x-coordinate of the polygon boundary (x[i] in R), yi is the ith ycoordinate of the polygon boundary (y[i] in R) - and n is the number of points used to specify the polygon boundary. The polygon is assumed to be in closed form so that the x1 and y1 take the same value as xn and yn.
>
> Hope to hear from you soon.
>
> Yours sincerely
>
> Krishan Mistry
>


From sarah.goslee at gmail.com  Thu Jan  7 21:38:53 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 7 Jan 2016 15:38:53 -0500
Subject: [R-sig-Geo] R Help
In-Reply-To: <DB5PR06MB1384F0954D3165B9205667EE98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
References: <DB5PR06MB13849A3356C08C045F02E36A98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
	<CAM_vjumzWzQQGnK8H_hg+v0N3rK6OWBhkL-DjY2zQEjByMZOJQ@mail.gmail.com>
	<DB5PR06MB1384F0954D3165B9205667EE98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
Message-ID: <CAM_vju=e8J13zPRJVsv4DGvNGhfb_c33Wgk9V335OjR1qP0zdw@mail.gmail.com>

You'd get better results if you send your information to the list, and
as plain-text email with data either included or using one of the
built-in datasets in R. I don't necessarily know the answer even
though I know the right way to ask the question.

Sarah

On Thu, Jan 7, 2016 at 3:35 PM, Mistry, Krishan <km314 at student.le.ac.uk> wrote:
> Dear Sarah,
>
> This isn't homework, but in fact optional extra work for a R practical session. I am new to R and haven't done any programming before.  Would you be able to assist me, if i am able to send you the question on a word document along the data that is used.
>
> Kind Regards
> Krishan
>
> ________________________________________
> From: Sarah Goslee <sarah.goslee at gmail.com>
> Sent: 07 January 2016 20:31
> To: Mistry, Krishan
> Cc: r-sig-geo at r-project.org
> Subject: Re: [R-sig-Geo] R Help
>
> As you will see below, posting in HTML format made your question unreadable.
>
> However, this looks rather like homework, and if so then you should
> look for help from the resources associated with your course.
>
> If it isn't homework, you will get much more assistance if you provide
> a reproducible example including data and the code you've tried
> already.
>
> Sarah
>
> On Thu, Jan 7, 2016 at 3:24 PM, Mistry, Krishan <km314 at student.le.ac.uk> wrote:
>> Dear Sir/Madame,
>>
>> I am currently a Masters student at the University of Leicester in the UK studying MSc Geographical Information Science and am having a bit of difficulty with the programme R. I am a new user of the programme and don't have any previous experience in programming. Having looked at various web sites, I wondered if you are able to help me with some trouble i am having in trying to write some code for a mathematical equation.
>> I have attached the question to this email and it can be seen below. The dataset is a list of polygons with each polygon containing another list within it, of x and y coordinates.
>>
>> I would really appreciate it, if you could help me with this question.
>>
>> Question
>> Create functions to compute the area, centroid and perimeter of a polygon list (as in the format of georgia.polys). The formula for the area of a polygon is
>>
>> A=0.5*?(x? y???) (x??? y?)      for i until n-1
>>
>> where A is the polygon area, xi is the ith x-coordinate of the polygon boundary (x[i] in R), yi is the ith ycoordinate of the polygon boundary (y[i] in R) - and n is the number of points used to specify the polygon boundary. The polygon is assumed to be in closed form so that the x1 and y1 take the same value as xn and yn.
>>
>> Hope to hear from you soon.
>>
>> Yours sincerely
>>
>> Krishan Mistry
>>


From bakht013 at umn.edu  Fri Jan  8 02:09:36 2016
From: bakht013 at umn.edu (Maryia Bakhtsiyarava)
Date: Thu, 7 Jan 2016 19:09:36 -0600
Subject: [R-sig-Geo] specifying time period for splm
In-Reply-To: <CAMTWOzqP=B+0gTVjpRrw7squaQMBRzrM2DHnOFejCYCmcPJc2g@mail.gmail.com>
References: <CAKFowAhH-UEJ23SU3x8ja6OhDZxKkZzk6CFMDSDUq1JyJHd=XA@mail.gmail.com>
	<CAMTWOzqP=B+0gTVjpRrw7squaQMBRzrM2DHnOFejCYCmcPJc2g@mail.gmail.com>
Message-ID: <CAKFowAgEQLqFMYUJf6dGkzRRXKqOhqni+aLayK7MjXWbzUEanw@mail.gmail.com>

Hi Tim,

Thank you so much for your answer! It made things so much more clear.
Thanks for suggesting to sort my data - I managed to do that and re-ran my
models.

I have another issue now with one of my models. I conduct a maximum
likelihood estimation with spatial lag, fixed effects and spatial
autocorrelation (akin to the one on top of page 13 of JSS) and I get the
following error: number of items to replace is not a multiple of
replacement length. I did not alter my data in any way after reading them
in, so even though I looked at similar problems posted on StackOverFlow, I
still can't figure out why this happens. Do you know what can cause this
problem? Also, at which point during the estimation process does the
replacement happen?

Best regards,
Maryia




On Wed, Jan 6, 2016 at 11:52 PM, Tim Meehan <tmeeha at gmail.com> wrote:

> Hi Maryia,
>
> I think you are on the right track.  From the JSS paper (page 3), your
> data can be:
>
> 1. A data.frame whose first two variables (columns) are the individual and
> time indexes. The data should be sorted by individual (Spatial Unit) and
> then time (Year), like you have it.  In this case the index argument in the
> call to spml should be left to the default value, which it is in your
> example.  Note that it isn't clear in your example if the first column
> (with Spatial Unit 1) is an actual column in the dataframe or the row
> names.  If it is row names, then you can make it a column with
> 'yourdata$Unit <- row.names(yourdata)', and then move it to the first
> column with 'yourdata <- yourdata[,c(4,1,2,3)]'.
>
> The other option is:
> ?
> 2. A data.frame and a character vector indicating the indexes variables.
> In this case, the indices wouldn't be the first two columns.  They would be
> somewhere else in the dataframe.  But you would specify the columns in the
> call to spml by adding something like 'index=c("Unit", "Year")'.  But, even
> in this case, I would presort the dataframe by Unit and Year to be safe.
>
> One thing that I think is important:
>
> When you import the shapefile to make weights, there is a good chance that
> the shapes won't be sorted according to the spatial units column in your
> dataset.  That is, the first shape might not actually be Spatial Unit 1,
> like in you sorted data from above.  To check, you can create a
> SpatialPolygonDataFrame called, say, 'spdf1' and then run something like
> 'plot(spdf1[1])' to see if R plots Spatial Unit 1 or something else.  If
> the shape order is different, you should reorder your
> SpatialPolygonDataFrame after creating it from the shapefile but before
> making weights.  If this is the case, let me know and I can send along a
> code chunk to do this.
>
> Best,
> Tim
>
>
> On Wed, Jan 6, 2016 at 8:58 PM, Maryia Bakhtsiyarava <bakht013 at umn.edu>
> wrote:
>
>> Hello,
>>
>> I would be very thankful for any help with my issue. I am relatively new
>> to
>> R and would greatly appreciate your help.
>>
>> I am trying to run spatial panel data models using the "splm," package. I
>> studied the manual and have been closely following the article by G. Millo
>> and G. Piras in the Journal of Statistical Software titled "splm: Spatial
>> Panel Data Models in R" to create my own models. What I don't seem to
>> understand is how R understands that the data are arranged in time
>> series..
>> I have repeated observations for spatial units for 5 years, however, I
>> have
>> not found where in the script I need to specify the periods. I looked at
>> the data Millo used in the article, and even though the data are arranged
>> by years, there is no explicit mention in the code or article of how to
>> pass the time periods to R.
>>
>> Let's assume I have the following:
>> I construct a spatial weights matrix (sp_weightsm) from the shapefile of
>> my
>> spatial units.
>> my formula is: fm1<-y~x1+x2+x3
>> mod1<-spml(formula = fm2, data = sids, index=NULL, listw=sp_weightsm,
>> lag=TRUE, spatial.error = "b", model = "within", effect = "individual",
>> method = "eigen", na.action = na.fail, quiet = TRUE, zero.policy = NULL,
>> tot.solve = 1e-10, control=list(), legacy=FALSE)
>>
>> my data has the following structure:
>>                         Year   X1   X2
>> Spatial Unit 1  2000   ....   .....
>> Spatial Unit 1  2001
>> Spatial Unit 2  2000
>> Spatial Unit 2  2001
>> Spatial Unit n  .....
>>
>> This model runs without errors however I am pretty sure the results are
>> not
>> meaningful because how would R know the time periods?
>> So, my question is: How do I pass on the time periods to R? Do I need to
>> subset my dataset into different parts based on years?
>>
>> Thank you in advance,
>> Maria
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>


-- 
Maryia Bakhtsiyarava
Graduate student
Department of Geography, Environment and Society
University of Minnesota, Twin Cities

Research Assistant
TerraPop Project
Minnesota Population Center

414 Social Sciences, 267 19th Ave S, Minneapolis, MN 55455

	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Fri Jan  8 05:49:01 2016
From: tmeeha at gmail.com (Tim Meehan)
Date: Thu, 7 Jan 2016 21:49:01 -0700
Subject: [R-sig-Geo] specifying time period for splm
In-Reply-To: <CAKFowAgEQLqFMYUJf6dGkzRRXKqOhqni+aLayK7MjXWbzUEanw@mail.gmail.com>
References: <CAKFowAhH-UEJ23SU3x8ja6OhDZxKkZzk6CFMDSDUq1JyJHd=XA@mail.gmail.com>
	<CAMTWOzqP=B+0gTVjpRrw7squaQMBRzrM2DHnOFejCYCmcPJc2g@mail.gmail.com>
	<CAKFowAgEQLqFMYUJf6dGkzRRXKqOhqni+aLayK7MjXWbzUEanw@mail.gmail.com>
Message-ID: <CAMTWOzpR0X0V1KJYpuDdoVr0dHktcK2h1=rNGtKKFjdPyt67SA@mail.gmail.com>

I've encountered this error before, but don't remember the problem or
solution.  Sorry to not be helpful.  Good luck.

On Thu, Jan 7, 2016 at 6:09 PM, Maryia Bakhtsiyarava <bakht013 at umn.edu>
wrote:

> Hi Tim,
>
> Thank you so much for your answer! It made things so much more clear.
> Thanks for suggesting to sort my data - I managed to do that and re-ran my
> models.
>
> I have another issue now with one of my models. I conduct a maximum
> likelihood estimation with spatial lag, fixed effects and spatial
> autocorrelation (akin to the one on top of page 13 of JSS) and I get the
> following error: number of items to replace is not a multiple of
> replacement length. I did not alter my data in any way after reading them
> in, so even though I looked at similar problems posted on StackOverFlow, I
> still can't figure out why this happens. Do you know what can cause this
> problem? Also, at which point during the estimation process does the
> replacement happen?
>
> Best regards,
> Maryia
>
>
>
>
> On Wed, Jan 6, 2016 at 11:52 PM, Tim Meehan <tmeeha at gmail.com> wrote:
>
>> Hi Maryia,
>>
>> I think you are on the right track.  From the JSS paper (page 3), your
>> data can be:
>>
>> 1. A data.frame whose first two variables (columns) are the individual
>> and time indexes. The data should be sorted by individual (Spatial Unit)
>> and then time (Year), like you have it.  In this case the index argument in
>> the call to spml should be left to the default value, which it is in your
>> example.  Note that it isn't clear in your example if the first column
>> (with Spatial Unit 1) is an actual column in the dataframe or the row
>> names.  If it is row names, then you can make it a column with
>> 'yourdata$Unit <- row.names(yourdata)', and then move it to the first
>> column with 'yourdata <- yourdata[,c(4,1,2,3)]'.
>>
>> The other option is:
>> ?
>> 2. A data.frame and a character vector indicating the indexes variables.
>> In this case, the indices wouldn't be the first two columns.  They would be
>> somewhere else in the dataframe.  But you would specify the columns in the
>> call to spml by adding something like 'index=c("Unit", "Year")'.  But, even
>> in this case, I would presort the dataframe by Unit and Year to be safe.
>>
>> One thing that I think is important:
>>
>> When you import the shapefile to make weights, there is a good chance
>> that the shapes won't be sorted according to the spatial units column in
>> your dataset.  That is, the first shape might not actually be Spatial Unit
>> 1, like in you sorted data from above.  To check, you can create a
>> SpatialPolygonDataFrame called, say, 'spdf1' and then run something like
>> 'plot(spdf1[1])' to see if R plots Spatial Unit 1 or something else.  If
>> the shape order is different, you should reorder your
>> SpatialPolygonDataFrame after creating it from the shapefile but before
>> making weights.  If this is the case, let me know and I can send along a
>> code chunk to do this.
>>
>> Best,
>> Tim
>>
>>
>> On Wed, Jan 6, 2016 at 8:58 PM, Maryia Bakhtsiyarava <bakht013 at umn.edu>
>> wrote:
>>
>>> Hello,
>>>
>>> I would be very thankful for any help with my issue. I am relatively new
>>> to
>>> R and would greatly appreciate your help.
>>>
>>> I am trying to run spatial panel data models using the "splm," package. I
>>> studied the manual and have been closely following the article by G.
>>> Millo
>>> and G. Piras in the Journal of Statistical Software titled "splm: Spatial
>>> Panel Data Models in R" to create my own models. What I don't seem to
>>> understand is how R understands that the data are arranged in time
>>> series..
>>> I have repeated observations for spatial units for 5 years, however, I
>>> have
>>> not found where in the script I need to specify the periods. I looked at
>>> the data Millo used in the article, and even though the data are arranged
>>> by years, there is no explicit mention in the code or article of how to
>>> pass the time periods to R.
>>>
>>> Let's assume I have the following:
>>> I construct a spatial weights matrix (sp_weightsm) from the shapefile of
>>> my
>>> spatial units.
>>> my formula is: fm1<-y~x1+x2+x3
>>> mod1<-spml(formula = fm2, data = sids, index=NULL, listw=sp_weightsm,
>>> lag=TRUE, spatial.error = "b", model = "within", effect = "individual",
>>> method = "eigen", na.action = na.fail, quiet = TRUE, zero.policy = NULL,
>>> tot.solve = 1e-10, control=list(), legacy=FALSE)
>>>
>>> my data has the following structure:
>>>                         Year   X1   X2
>>> Spatial Unit 1  2000   ....   .....
>>> Spatial Unit 1  2001
>>> Spatial Unit 2  2000
>>> Spatial Unit 2  2001
>>> Spatial Unit n  .....
>>>
>>> This model runs without errors however I am pretty sure the results are
>>> not
>>> meaningful because how would R know the time periods?
>>> So, my question is: How do I pass on the time periods to R? Do I need to
>>> subset my dataset into different parts based on years?
>>>
>>> Thank you in advance,
>>> Maria
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>
>
> --
> Maryia Bakhtsiyarava
> Graduate student
> Department of Geography, Environment and Society
> University of Minnesota, Twin Cities
>
> Research Assistant
> TerraPop Project
> Minnesota Population Center
>
> 414 Social Sciences, 267 19th Ave S, Minneapolis, MN 55455
>

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Fri Jan  8 08:18:14 2016
From: englishchristophera at gmail.com (chris english)
Date: Fri, 8 Jan 2016 09:18:14 +0200
Subject: [R-sig-Geo] R Help
In-Reply-To: <CAM_vju=e8J13zPRJVsv4DGvNGhfb_c33Wgk9V335OjR1qP0zdw@mail.gmail.com>
References: <DB5PR06MB13849A3356C08C045F02E36A98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
	<CAM_vjumzWzQQGnK8H_hg+v0N3rK6OWBhkL-DjY2zQEjByMZOJQ@mail.gmail.com>
	<DB5PR06MB1384F0954D3165B9205667EE98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
	<CAM_vju=e8J13zPRJVsv4DGvNGhfb_c33Wgk9V335OjR1qP0zdw@mail.gmail.com>
Message-ID: <CAASFQpTkuG35ZvTof2VHVJZLh1DrZ+o37XtY4uJBwpsmKEWKHw@mail.gmail.com>

Krishan,

Create functions to compute the area, centroid and perimeter of a polygon
list (as in the format of georgia.polys).
The secret here is the specificity of georgia.polys, which googling leads
us to Cran R "GISTools". Looks like this handles the polygon area calc.
Perimeter can also be referred to as envelope which might lead one to
either "geosphere" or "spatstat". Thence to "rgeos" for centroid, and a
small walking tour of aspects of spatial R.

I'm imagining the idea is to use what has already been validated as correct
code rather than writing the same.
HTH,
Chris

On Thu, Jan 7, 2016 at 10:38 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> You'd get better results if you send your information to the list, and
> as plain-text email with data either included or using one of the
> built-in datasets in R. I don't necessarily know the answer even
> though I know the right way to ask the question.
>
> Sarah
>
> On Thu, Jan 7, 2016 at 3:35 PM, Mistry, Krishan <km314 at student.le.ac.uk>
> wrote:
> > Dear Sarah,
> >
> > This isn't homework, but in fact optional extra work for a R practical
> session. I am new to R and haven't done any programming before.  Would you
> be able to assist me, if i am able to send you the question on a word
> document along the data that is used.
> >
> > Kind Regards
> > Krishan
> >
> > ________________________________________
> > From: Sarah Goslee <sarah.goslee at gmail.com>
> > Sent: 07 January 2016 20:31
> > To: Mistry, Krishan
> > Cc: r-sig-geo at r-project.org
> > Subject: Re: [R-sig-Geo] R Help
> >
> > As you will see below, posting in HTML format made your question
> unreadable.
> >
> > However, this looks rather like homework, and if so then you should
> > look for help from the resources associated with your course.
> >
> > If it isn't homework, you will get much more assistance if you provide
> > a reproducible example including data and the code you've tried
> > already.
> >
> > Sarah
> >
> > On Thu, Jan 7, 2016 at 3:24 PM, Mistry, Krishan <km314 at student.le.ac.uk>
> wrote:
> >> Dear Sir/Madame,
> >>
> >> I am currently a Masters student at the University of Leicester in the
> UK studying MSc Geographical Information Science and am having a bit of
> difficulty with the programme R. I am a new user of the programme and don't
> have any previous experience in programming. Having looked at various web
> sites, I wondered if you are able to help me with some trouble i am having
> in trying to write some code for a mathematical equation.
> >> I have attached the question to this email and it can be seen below.
> The dataset is a list of polygons with each polygon containing another list
> within it, of x and y coordinates.
> >>
> >> I would really appreciate it, if you could help me with this question.
> >>
> >> Question
> >> Create functions to compute the area, centroid and perimeter of a
> polygon list (as in the format of georgia.polys). The formula for the area
> of a polygon is
> >>
> >> A=0.5*?(x? y???) (x??? y?)      for i until n-1
> >>
> >> where A is the polygon area, xi is the ith x-coordinate of the polygon
> boundary (x[i] in R), yi is the ith ycoordinate of the polygon boundary
> (y[i] in R) - and n is the number of points used to specify the polygon
> boundary. The polygon is assumed to be in closed form so that the x1 and y1
> take the same value as xn and yn.
> >>
> >> Hope to hear from you soon.
> >>
> >> Yours sincerely
> >>
> >> Krishan Mistry
> >>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Jan  8 10:42:06 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 8 Jan 2016 10:42:06 +0100
Subject: [R-sig-Geo] R Help
In-Reply-To: <CAASFQpTkuG35ZvTof2VHVJZLh1DrZ+o37XtY4uJBwpsmKEWKHw@mail.gmail.com>
References: <DB5PR06MB13849A3356C08C045F02E36A98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
	<CAM_vjumzWzQQGnK8H_hg+v0N3rK6OWBhkL-DjY2zQEjByMZOJQ@mail.gmail.com>
	<DB5PR06MB1384F0954D3165B9205667EE98F50@DB5PR06MB1384.eurprd06.prod.outlook.com>
	<CAM_vju=e8J13zPRJVsv4DGvNGhfb_c33Wgk9V335OjR1qP0zdw@mail.gmail.com>
	<CAASFQpTkuG35ZvTof2VHVJZLh1DrZ+o37XtY4uJBwpsmKEWKHw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1601081016560.5745@reclus.nhh.no>

On Fri, 8 Jan 2016, chris english wrote:

> Krishan,
>
> Create functions to compute the area, centroid and perimeter of a polygon
> list (as in the format of georgia.polys).
> The secret here is the specificity of georgia.polys, which googling leads
> us to Cran R "GISTools". Looks like this handles the polygon area calc.

Right, the data referred to here are in:

library(GISTools)
data(georgia)

where georgia.polys is a list of matrices of projected boundary 
coordinates. None of this is difficult, all is described in detail in 
Bivand et al. (2013), rather less detail in Brunsdon & Comber (2015).

Recreate the sp class object needed (the classes were designed to make 
things easier):

library(sp)
Pslist <- lapply(seq(along=georgia.polys), function(i)
   Polygons(list(Polygon(georgia.polys[[i]])), ID=as.character(i)))
GP <- SpatialPolygons(Pslist)

The objects inside GP already contain area and centroid values used in 
plotting which are inaccurate in the presence of holes, but we can check 
with rgeos functions to be sure (centroids accessed from the "labpt" slot 
by the coordinates() accessor method):

library(rgeos)
all.equal(coordinates(gCentroid(GP, byid=TRUE)), coordinates(GP),
  check.attributes=FALSE)
all.equal(coordinates(gCentroid(GP, byid=TRUE)), t(sapply(slot(GP,
  "polygons"), slot, "labpt")), check.attributes=FALSE)
all.equal(gArea(GP, byid=TRUE), sapply(slot(GP, "polygons"), slot,
  "area"), check.attributes=FALSE)

This will not be the same if there are interior rings (holes) - in which 
case the rgeos function values should be used.

Perimeter is harder, but here there are only exterior rings, so we can 
use:

gLength(GP, byid=TRUE)

If the perimeter lengths for proximate neighbours are needed, use 
GRASS in conjunction with rgrass7::vect2neigh().

I agree with Sarah that this looks like homework, possibly from chapter 4 
in Brunsdon & Comber (2015). However, I prefer this explanation - it may 
look harder, but steep learning curves are time and cost efficient.

Hope this clarifies,

Roger

> Perimeter can also be referred to as envelope which might lead one to
> either "geosphere" or "spatstat". Thence to "rgeos" for centroid, and a
> small walking tour of aspects of spatial R.
>
> I'm imagining the idea is to use what has already been validated as correct
> code rather than writing the same.
> HTH,
> Chris
>
> On Thu, Jan 7, 2016 at 10:38 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> You'd get better results if you send your information to the list, and
>> as plain-text email with data either included or using one of the
>> built-in datasets in R. I don't necessarily know the answer even
>> though I know the right way to ask the question.
>>
>> Sarah
>>
>> On Thu, Jan 7, 2016 at 3:35 PM, Mistry, Krishan <km314 at student.le.ac.uk>
>> wrote:
>>> Dear Sarah,
>>>
>>> This isn't homework, but in fact optional extra work for a R practical
>> session. I am new to R and haven't done any programming before.  Would you
>> be able to assist me, if i am able to send you the question on a word
>> document along the data that is used.
>>>
>>> Kind Regards
>>> Krishan
>>>
>>> ________________________________________
>>> From: Sarah Goslee <sarah.goslee at gmail.com>
>>> Sent: 07 January 2016 20:31
>>> To: Mistry, Krishan
>>> Cc: r-sig-geo at r-project.org
>>> Subject: Re: [R-sig-Geo] R Help
>>>
>>> As you will see below, posting in HTML format made your question
>> unreadable.
>>>
>>> However, this looks rather like homework, and if so then you should
>>> look for help from the resources associated with your course.
>>>
>>> If it isn't homework, you will get much more assistance if you provide
>>> a reproducible example including data and the code you've tried
>>> already.
>>>
>>> Sarah
>>>
>>> On Thu, Jan 7, 2016 at 3:24 PM, Mistry, Krishan <km314 at student.le.ac.uk>
>> wrote:
>>>> Dear Sir/Madame,
>>>>
>>>> I am currently a Masters student at the University of Leicester in the
>> UK studying MSc Geographical Information Science and am having a bit of
>> difficulty with the programme R. I am a new user of the programme and don't
>> have any previous experience in programming. Having looked at various web
>> sites, I wondered if you are able to help me with some trouble i am having
>> in trying to write some code for a mathematical equation.
>>>> I have attached the question to this email and it can be seen below.
>> The dataset is a list of polygons with each polygon containing another list
>> within it, of x and y coordinates.
>>>>
>>>> I would really appreciate it, if you could help me with this question.
>>>>
>>>> Question
>>>> Create functions to compute the area, centroid and perimeter of a
>> polygon list (as in the format of georgia.polys). The formula for the area
>> of a polygon is
>>>>
>>>> A=0.5*?(x? y???) (x??? y?)      for i until n-1
>>>>
>>>> where A is the polygon area, xi is the ith x-coordinate of the polygon
>> boundary (x[i] in R), yi is the ith ycoordinate of the polygon boundary
>> (y[i] in R) - and n is the number of points used to specify the polygon
>> boundary. The polygon is assumed to be in closed form so that the x1 and y1
>> take the same value as xn and yn.
>>>>
>>>> Hope to hear from you soon.
>>>>
>>>> Yours sincerely
>>>>
>>>> Krishan Mistry
>>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From Rainer at krugs.de  Fri Jan  8 11:39:38 2016
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 08 Jan 2016 11:39:38 +0100
Subject: [R-sig-Geo] Replacement for old overlay() function in package sp
Message-ID: <m28u402w45.fsf@Rainers-MBP.fritz.box>

Hi

I have an old script which uses the overlay() function of the package
sp. I saw that it was removed in commit 1678, but can I safely replace
it with the function over()?

It was used as follow:
--8<---------------cut here---------------start------------->8---
sp <- readShapePoly(...)
grd <- readRAST(...)
grd[[2]] <- overlay(grd, sp)
--8<---------------cut here---------------end--------------->8---

Thanks,

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160108/ac43a6b8/attachment.bin>

From j.alavi at modares.ac.ir  Fri Jan  8 19:52:39 2016
From: j.alavi at modares.ac.ir (Seyed Jalil Alavi)
Date: Fri, 08 Jan 2016 22:22:39 +0330
Subject: [R-sig-Geo] Anisotropy for Cokriging
Message-ID: <WC20160108185239.21858A@modares.ac.ir>

Dear All
?
I am mapping forest site productivity for one of most important species in 
one of the oldest forests in the world, Hyrcanian Forests, Iran.
 
Dear All, I used rose plot function written by Jon Graham 
(http://www.math.umt.edu/graham/stat544/) and found there is an anisotropy 
in the variogram for kriging and I included the anisotropy in variogram 
fitting.

Dear All, I want to investigate the anisotropy for cokriging and if there is 
anisotropy, I want to consider it for cokriging.

I search many textbooks and also in the internet and found NOTHING for 
anisotropy for cokriging.
I would be very grateful if ANYONE can help me how can I study the 
anisotropy for cokriging and include it the model.

 Another question is about argument cressie=T in gstat package. For krige 
function in gstat package there is cressie=T, if there are outliers. For my 
data, it seems there are some outliers and I want to include cressie=T for 
variogram for fitting cokriging. I did not see any argument in gstat 
function.

I would be extremely grateful for any help

Thanks and regards

Jalil

**********************************
Seyed Jalil Alavi, Ph.D
Assistant Professor in Statistical Ecology
Dept. of Forestry
Faculty of Natural Resources
Tarbiat Modares University
P.O.Box 46417-76489
Noor
Mazandaran
Iran
Mobile Phone Number 00989111580097
Tel:0098(122)6253101-3
http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~j.alavi
	[[alternative HTML version deleted]]


From carlosalberto.arnillas at gmail.com  Sat Jan  9 15:15:06 2016
From: carlosalberto.arnillas at gmail.com (Carlos Alberto Arnillas)
Date: Sat, 9 Jan 2016 09:15:06 -0500
Subject: [R-sig-Geo] measuring distances between several patches in an area
Message-ID: <CALpNJaSJ7RVLizqyYdTwWv3RmEfsdv=+ovW78ZOKsK5QRrONeA@mail.gmail.com>

Hello
I have been trying to find a function to measure the distance between
several patches simultaneously.
I tried with the raster packages iterating by every patch, measuring the
distance from there to every single pixel out of the patch (using the
function distance) and then looking for the minimum distance to all the
other patches. but it's extremely time consuming. It is also extremely
inefficient because I'm measuring every distance twice and because I'm
measuring unneeded distances also (if the only way to go from patch A to
patch C crosses patch B, I don't need the distance between patch A and C).
Below is the code I'm using...

Thanks for any advice...

Carlos Alberto


region <- raster(mapFinal) # the landscape map.
patch <- region
biome <- region
biomes <- unique(region)
areas <- area(region)

map.distances <-function (i) {
  dA <- data.frame(biome = integer(0),
                   patch = integer(0),
                   area = numeric(0))
  dD <- data.frame(biome = integer(0),
                   from = integer(0),
                   to = integer(0),
                   dist = numeric(0))
  biome[] <- NA_integer_
  biome[region == i] <- i
  biomeC <- clump(biome, directions=8)
  dA <- rbind(dA, cbind(biome = i,
              zonal(areas, biomeC, 'sum')))
  patches <- as.integer(unique(biomeC))
  for (j in patches[-1]) {
    patch[] <- NA_integer_
    patch[biomeC == j] <- 1L
    dists <- distance(patch)
    d <- zonal(dists, biomeC, "min")
    f <- j > d[,1]
    dD <- rbind(dD, data.frame(from = j,
                   to = d[f,1],
                   dist = d[f,2], biome = i))
  }
  try(save(dD, dA,
      file=paste0("data/toGraph.",i,".RData")), T)
  return(list(edges=dD, vertices=dA))
}

db.distances1 <- lapply (biomes[1], map.distances)

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Sun Jan 10 13:46:37 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 10 Jan 2016 13:46:37 +0100
Subject: [R-sig-Geo] Anisotropy for Cokriging
In-Reply-To: <WC20160108185239.21858A@modares.ac.ir>
References: <WC20160108185239.21858A@modares.ac.ir>
Message-ID: <569252AD.8030402@uni-muenster.de>



On 08/01/16 19:52, Seyed Jalil Alavi wrote:
> Dear All
> ?
> I am mapping forest site productivity for one of most important species in 
> one of the oldest forests in the world, Hyrcanian Forests, Iran.
>  
> Dear All, I used rose plot function written by Jon Graham 
> (http://www.math.umt.edu/graham/stat544/) and found there is an anisotropy 
> in the variogram for kriging and I included the anisotropy in variogram 
> fitting.
> 
> Dear All, I want to investigate the anisotropy for cokriging and if there is 
> anisotropy, I want to consider it for cokriging.
> 
> I search many textbooks and also in the internet and found NOTHING for 
> anisotropy for cokriging.
> I would be very grateful if ANYONE can help me how can I study the 
> anisotropy for cokriging and include it the model.

There's nothing special to it, except that very few people actually do
it. Under the linear model of coregionalisation, the range ellipse (or
ellipsoid) has to be identical for all direct and cross variograms.

> 
>  Another question is about argument cressie=T in gstat package. For krige 
> function in gstat package there is cressie=T, if there are outliers. For my 
> data, it seems there are some outliers and I want to include cressie=T for 
> variogram for fitting cokriging. I did not see any argument in gstat 
> function.

It is only defined (and implemented) for direct variograms, not for
cross variograms.

> 
> I would be extremely grateful for any help
> 
> Thanks and regards
> 
> Jalil
> 
> **********************************
> Seyed Jalil Alavi, Ph.D
> Assistant Professor in Statistical Ecology
> Dept. of Forestry
> Faculty of Natural Resources
> Tarbiat Modares University
> P.O.Box 46417-76489
> Noor
> Mazandaran
> Iran
> Mobile Phone Number 00989111580097
> Tel:0098(122)6253101-3
> http://www.modares.ac.ir/en/Schools/nat/Academic_Staff/~j.alavi
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160110/9fc102d6/attachment.bin>

From km314 at student.le.ac.uk  Mon Jan 11 10:56:53 2016
From: km314 at student.le.ac.uk (Mistry, Krishan)
Date: Mon, 11 Jan 2016 09:56:53 +0000
Subject: [R-sig-Geo] mapcircles help
Message-ID: <DB5PR06MB138412D51BD2570808AFA9A298C90@DB5PR06MB1384.eurprd06.prod.outlook.com>

Dear Sirs/Madame,


I have a spatial polygons data frame and want to map proportional circles on it. I have tried using the map circles function in rCarto as seen below but it doesn't seem to work an continues to show errors. Do I need to convert the spatial polygons data frame to a shapefile if so I would I do this?



mapCircles(shpFile, shpId, df, dfId, var,
          fixedNorm = FALSE, shareOfCircles = 0.02,
          radiusMax = 0.5, valueMax = max(df[, var], na.rm = TRUE),
          lgdRnd = 0, posLeg = "bottomleft",
          circleCol = "#FD8D3C", baseCol = "#FFEDA0",
          title = var, legend = var, author = "author", sources = "sources",
          scalebar = FALSE, scalebarSize, scalebarText,
          northArrow = FALSE, northArrowSize,
          width = NULL, height = NULL, txtCex = NULL)



Any advice is greatly appreciated.


Many Thanks

Krish

	[[alternative HTML version deleted]]


From timothee.giraud at ums-riate.fr  Mon Jan 11 12:17:44 2016
From: timothee.giraud at ums-riate.fr (=?UTF-8?Q?Timoth=c3=a9e_Giraud?=)
Date: Mon, 11 Jan 2016 12:17:44 +0100
Subject: [R-sig-Geo] mapcircles help
In-Reply-To: <DB5PR06MB138412D51BD2570808AFA9A298C90@DB5PR06MB1384.eurprd06.prod.outlook.com>
References: <DB5PR06MB138412D51BD2570808AFA9A298C90@DB5PR06MB1384.eurprd06.prod.outlook.com>
Message-ID: <56938F58.8000103@ums-riate.fr>

Hi,
As maintainer of the rCarto package, my advice would be to switch to the 
cartography package (of which I am also maintainer) and the 
propSymbolsLayer function in it. Examples and the vignette will help you 
through the mapping process.

My turn to ask for an advice:
rCarto was my first package and after a while we decide to build an 
other, better, thematic mapping package (i.e. the cartography package). 
cartography is much more R-ish in its use of the graphic device, offers 
more kinds of maps and has more options to customize the maps.
So my question is: what should I do with rCarto? Remove it from CRAN? 
Deprecate all functions in it? Add a visible comment to incite users to 
switch to cartography?

Any advice is greatly appreciated.
Thanks,
Tim





Le 11/01/2016 10:56, Mistry, Krishan a ?crit :
> Dear Sirs/Madame,
>
>
> I have a spatial polygons data frame and want to map proportional circles on it. I have tried using the map circles function in rCarto as seen below but it doesn't seem to work an continues to show errors. Do I need to convert the spatial polygons data frame to a shapefile if so I would I do this?
>
>
>
> mapCircles(shpFile, shpId, df, dfId, var,
>            fixedNorm =ALSE, shareOfCircles = 0.02,
>            radiusMax =.5, valueMax = max(df[, var], na.rm = TRUE),
>            lgdRnd =, posLeg = "bottomleft",
>            circleCol =#FD8D3C", baseCol = "#FFEDA0",
>            title =ar, legend = var, author = "author", sources = "sources",
>            scalebar =ALSE, scalebarSize, scalebarText,
>            northArrow =ALSE, northArrowSize,
>            width =ULL, height = NULL, txtCex = NULL)
>
>
>
> Any advice is greatly appreciated.
>
>
> Many Thanks
>
> Krish
>
> 	[[alternative HTML version deleted]]
>
>


From englishchristophera at gmail.com  Mon Jan 11 12:41:58 2016
From: englishchristophera at gmail.com (chris english)
Date: Mon, 11 Jan 2016 13:41:58 +0200
Subject: [R-sig-Geo] mapcircles help
In-Reply-To: <56938F58.8000103@ums-riate.fr>
References: <DB5PR06MB138412D51BD2570808AFA9A298C90@DB5PR06MB1384.eurprd06.prod.outlook.com>
	<56938F58.8000103@ums-riate.fr>
Message-ID: <CAASFQpSRvNHTgMOe1K1txEs=WfdT1Cwe3RXG1rJcYoyB1H9X3Q@mail.gmail.com>

Timothee,
Best to ask as new question, perhaps "When to deprecate a package?", as
that will put you in front of the many many package authors and maintainers
that inform this discussion.
My thoughts.
Chris
On Jan 11, 2016 1:19 PM, "Timoth?e Giraud" <timothee.giraud at ums-riate.fr>
wrote:

> Hi,
> As maintainer of the rCarto package, my advice would be to switch to the
> cartography package (of which I am also maintainer) and the
> propSymbolsLayer function in it. Examples and the vignette will help you
> through the mapping process.
>
> My turn to ask for an advice:
> rCarto was my first package and after a while we decide to build an other,
> better, thematic mapping package (i.e. the cartography package).
> cartography is much more R-ish in its use of the graphic device, offers
> more kinds of maps and has more options to customize the maps.
> So my question is: what should I do with rCarto? Remove it from CRAN?
> Deprecate all functions in it? Add a visible comment to incite users to
> switch to cartography?
>
> Any advice is greatly appreciated.
> Thanks,
> Tim
>
>
>
>
>
> Le 11/01/2016 10:56, Mistry, Krishan a ?crit :
>
>> Dear Sirs/Madame,
>>
>>
>> I have a spatial polygons data frame and want to map proportional circles
>> on it. I have tried using the map circles function in rCarto as seen below
>> but it doesn't seem to work an continues to show errors. Do I need to
>> convert the spatial polygons data frame to a shapefile if so I would I do
>> this?
>>
>>
>>
>> mapCircles(shpFile, shpId, df, dfId, var,
>>            fixedNorm =ALSE, shareOfCircles = 0.02,
>>            radiusMax =.5, valueMax = max(df[, var], na.rm = TRUE),
>>            lgdRnd =, posLeg = "bottomleft",
>>            circleCol =#FD8D3C", baseCol = "#FFEDA0",
>>            title =ar, legend = var, author = "author", sources =
>> "sources",
>>            scalebar =ALSE, scalebarSize, scalebarText,
>>            northArrow =ALSE, northArrowSize,
>>            width =ULL, height = NULL, txtCex = NULL)
>>
>>
>>
>> Any advice is greatly appreciated.
>>
>>
>> Many Thanks
>>
>> Krish
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From isubhashmk at outlook.com  Wed Jan 13 10:48:50 2016
From: isubhashmk at outlook.com (Subhash Karemore)
Date: Wed, 13 Jan 2016 09:48:50 +0000
Subject: [R-sig-Geo] Regarding installation of R package rgdal
Message-ID: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>

Hi,

I am trying to install R package 'rgdal' on SUSE Linux Enterprise Server. However it is failing with compilation error.

Errors:
----------
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c OGR_write.cpp -o OGR_write.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [OGR_write.o] Error 127 (ignored)
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c gdal-bindings.cpp -o gdal-bindings.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [gdal-bindings.o] Error 127 (ignored)
gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c init.c -o init.o
gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c local_stubs.c -o local_stubs.o
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_geom.cpp -o ogr_geom.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [ogr_geom.o] Error 127 (ignored)
gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c ogr_polygons.c -o ogr_polygons.o
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_proj.cpp -o ogr_proj.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [ogr_proj.o] Error 127 (ignored)
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrdrivers.cpp -o ogrdrivers.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [ogrdrivers.o] Error 127 (ignored)
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrsource.cpp -o ogrsource.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [ogrsource.o] Error 127 (ignored)
I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c projectit.cpp -o projectit.o
/bin/sh: I/usr/lib64/R/include: No such file or directory
make: [projectit.o] Error 127 (ignored)
-shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/local/lib -lgdal -lproj -L/usr/lib64/R/lib -lR
/bin/sh: line 2: -shared: command not found
make: *** [rgdal.so] Error 127
ERROR: compilation failed for package 'rgdal'
* removing '/usr/lib64/R/library/rgdal'

The downloaded source packages are in
        '/tmp/Rtmpd0WifB/downloaded_packages'
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("rgdal", repos = "http://cran.r-project.org") :
  installation of package 'rgdal' had non-zero exit status

However it got installed successfully on openSUSE. Here is the output:
---------------------------------------------------------------------------------------
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c OGR_write.cpp -o OGR_write.o
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c gdal-bindings.cpp -o gdal-bindings.o
gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c local_stubs.c -o local_stubs.o
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_geom.cpp -o ogr_geom.o
gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c ogr_polygons.c -o ogr_polygons.o
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_proj.cpp -o ogr_proj.o
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrdrivers.cpp -o ogrdrivers.o
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrsource.cpp -o ogrsource.o
g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c projectit.cpp -o projectit.o
g++ -std=c++11 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
installing to /usr/lib64/R/library/rgdal/libs
** R
** data
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded
* DONE (rgdal)

The command I used for installing the package is "install.package('rgdal', repos='http://cran.r-project.org')". I don't know why R package installation is failing on SLES. Even other R packages are getting installed successfully on SLES. It seems that it is not picking gcc compiler on SLES. Could you please let me know, why installation of R package 'rgdal' is failing on SLES? Do I need set anything?

Thanks
Subhash


From edzer.pebesma at uni-muenster.de  Wed Jan 13 10:56:17 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 13 Jan 2016 10:56:17 +0100
Subject: [R-sig-Geo] Regarding installation of R package rgdal
In-Reply-To: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <56961F41.1040704@uni-muenster.de>

To find out, send us the lines that were printed in your console before
the errors occured, those following
* installing *source* package ?rgdal? ...



On 13/01/16 10:48, Subhash Karemore wrote:
> Hi,
> 
> I am trying to install R package 'rgdal' on SUSE Linux Enterprise Server. However it is failing with compilation error.
> 
> Errors:
> ----------
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c OGR_write.cpp -o OGR_write.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [OGR_write.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c gdal-bindings.cpp -o gdal-bindings.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [gdal-bindings.o] Error 127 (ignored)
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c local_stubs.c -o local_stubs.o
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_geom.cpp -o ogr_geom.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogr_geom.o] Error 127 (ignored)
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c ogr_polygons.c -o ogr_polygons.o
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_proj.cpp -o ogr_proj.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogr_proj.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrdrivers.cpp -o ogrdrivers.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogrdrivers.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrsource.cpp -o ogrsource.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogrsource.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c projectit.cpp -o projectit.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [projectit.o] Error 127 (ignored)
> -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/local/lib -lgdal -lproj -L/usr/lib64/R/lib -lR
> /bin/sh: line 2: -shared: command not found
> make: *** [rgdal.so] Error 127
> ERROR: compilation failed for package 'rgdal'
> * removing '/usr/lib64/R/library/rgdal'
> 
> The downloaded source packages are in
>         '/tmp/Rtmpd0WifB/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgdal", repos = "http://cran.r-project.org") :
>   installation of package 'rgdal' had non-zero exit status
> 
> However it got installed successfully on openSUSE. Here is the output:
> ---------------------------------------------------------------------------------------
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c OGR_write.cpp -o OGR_write.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c gdal-bindings.cpp -o gdal-bindings.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c local_stubs.c -o local_stubs.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_geom.cpp -o ogr_geom.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c ogr_polygons.c -o ogr_polygons.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_proj.cpp -o ogr_proj.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrsource.cpp -o ogrsource.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c projectit.cpp -o projectit.o
> g++ -std=c++11 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
> installing to /usr/lib64/R/library/rgdal/libs
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> * DONE (rgdal)
> 
> The command I used for installing the package is "install.package('rgdal', repos='http://cran.r-project.org')". I don't know why R package installation is failing on SLES. Even other R packages are getting installed successfully on SLES. It seems that it is not picking gcc compiler on SLES. Could you please let me know, why installation of R package 'rgdal' is failing on SLES? Do I need set anything?
> 
> Thanks
> Subhash
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160113/ca9a6f2a/attachment.bin>

From Roger.Bivand at nhh.no  Wed Jan 13 10:57:24 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 13 Jan 2016 10:57:24 +0100
Subject: [R-sig-Geo] Regarding installation of R package rgdal
In-Reply-To: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <alpine.LFD.2.20.1601131052080.5601@reclus.nhh.no>

On Wed, 13 Jan 2016, Subhash Karemore wrote:

> Hi,
>

This is a repeat of a mail to me, to which I replied. The guy works for 
Teradata and can afford to solve this using their technicians. The output 
of configure is not included; my conclusion based on guesswork (which I 
sent directly earlier) is that the SLES servers do not have c++11-capable 
g++ versions, while OpenSUSE does.

Corporate subscribers must learn to respect the work put in by the 
community, not just free-ride. This guy is also in a big hurry, and 
doesn't read messages sent.

Roger

> I am trying to install R package 'rgdal' on SUSE Linux Enterprise 
> Server. However it is failing with compilation error.
>
> Errors:
> ----------
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c OGR_write.cpp -o OGR_write.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [OGR_write.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c gdal-bindings.cpp -o gdal-bindings.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [gdal-bindings.o] Error 127 (ignored)
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c local_stubs.c -o local_stubs.o
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_geom.cpp -o ogr_geom.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogr_geom.o] Error 127 (ignored)
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c ogr_polygons.c -o ogr_polygons.o
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_proj.cpp -o ogr_proj.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogr_proj.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrdrivers.cpp -o ogrdrivers.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogrdrivers.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrsource.cpp -o ogrsource.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogrsource.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c projectit.cpp -o projectit.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [projectit.o] Error 127 (ignored)
> -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/local/lib -lgdal -lproj -L/usr/lib64/R/lib -lR
> /bin/sh: line 2: -shared: command not found
> make: *** [rgdal.so] Error 127
> ERROR: compilation failed for package 'rgdal'
> * removing '/usr/lib64/R/library/rgdal'
>
> The downloaded source packages are in
>        '/tmp/Rtmpd0WifB/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgdal", repos = "http://cran.r-project.org") :
>  installation of package 'rgdal' had non-zero exit status
>
> However it got installed successfully on openSUSE. Here is the output:
> ---------------------------------------------------------------------------------------
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c OGR_write.cpp -o OGR_write.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c gdal-bindings.cpp -o gdal-bindings.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c local_stubs.c -o local_stubs.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_geom.cpp -o ogr_geom.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c ogr_polygons.c -o ogr_polygons.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_proj.cpp -o ogr_proj.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrsource.cpp -o ogrsource.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c projectit.cpp -o projectit.o
> g++ -std=c++11 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
> installing to /usr/lib64/R/library/rgdal/libs
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> * DONE (rgdal)
>
> The command I used for installing the package is 
> "install.package('rgdal', repos='http://cran.r-project.org')". I don't 
> know why R package installation is failing on SLES. Even other R 
> packages are getting installed successfully on SLES. It seems that it is 
> not picking gcc compiler on SLES. Could you please let me know, why 
> installation of R package 'rgdal' is failing on SLES? Do I need set 
> anything?
>
> Thanks
> Subhash
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From bfalevlist at gmail.com  Wed Jan 13 11:00:59 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Wed, 13 Jan 2016 11:00:59 +0100
Subject: [R-sig-Geo] Regarding installation of R package rgdal
In-Reply-To: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR01MB0241249FE23FF90C635DA904C5CB0@BM1PR01MB0241.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <5696205B.8030602@gmail.com>

Dear Subhash,

is gdal installed on your system?
Before installing package rgdal, you should download and install this:
software.opensuse.org/ymp/openSUSE:Leap:42.1/standard/gdal.ymp?base=openSUSE%3ALeap%3A42.1&query=gdal

Or if this is not the best link for your operation system, here you can 
find the GDAL-webpage:
https://trac.osgeo.org/gdal/wiki/DownloadingGdalBinaries

Hope this helps,
?kos Bede-Fazekas
Hungarian Academy of Science

2016.01.13. 10:48 keltez?ssel, Subhash Karemore ?rta:
> Hi,
>
> I am trying to install R package 'rgdal' on SUSE Linux Enterprise Server. However it is failing with compilation error.
>
> Errors:
> ----------
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c OGR_write.cpp -o OGR_write.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [OGR_write.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c gdal-bindings.cpp -o gdal-bindings.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [gdal-bindings.o] Error 127 (ignored)
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c local_stubs.c -o local_stubs.o
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_geom.cpp -o ogr_geom.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogr_geom.o] Error 127 (ignored)
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables  -c ogr_polygons.c -o ogr_polygons.o
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogr_proj.cpp -o ogr_proj.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogr_proj.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrdrivers.cpp -o ogrdrivers.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogrdrivers.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c ogrsource.cpp -o ogrsource.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [ogrsource.o] Error 127 (ignored)
> I/usr/lib64/R/include -DNDEBUG -I/usr/local/include -I/usr/local/include -I"/usr/lib64/R/library/sp/include"      -c projectit.cpp -o projectit.o
> /bin/sh: I/usr/lib64/R/include: No such file or directory
> make: [projectit.o] Error 127 (ignored)
> -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/local/lib -lgdal -lproj -L/usr/lib64/R/lib -lR
> /bin/sh: line 2: -shared: command not found
> make: *** [rgdal.so] Error 127
> ERROR: compilation failed for package 'rgdal'
> * removing '/usr/lib64/R/library/rgdal'
>
> The downloaded source packages are in
>          '/tmp/Rtmpd0WifB/downloaded_packages'
> Updating HTML index of packages in '.Library'
> Making 'packages.html' ... done
> Warning message:
> In install.packages("rgdal", repos = "http://cran.r-project.org") :
>    installation of package 'rgdal' had non-zero exit status
>
> However it got installed successfully on openSUSE. Here is the output:
> ---------------------------------------------------------------------------------------
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c OGR_write.cpp -o OGR_write.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c gdal-bindings.cpp -o gdal-bindings.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c local_stubs.c -o local_stubs.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_geom.cpp -o ogr_geom.o
> gcc -std=gnu99 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g  -c ogr_polygons.c -o ogr_polygons.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogr_proj.cpp -o ogr_proj.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c ogrsource.cpp -o ogrsource.o
> g++ -std=c++11 -I/usr/lib64/R/include -DNDEBUG -I/usr/include/gdal -I/usr/local/include -I"/usr/lib64/R/library/sp/include"   -fpic  -fmessage-length=0 -grecord-gcc-switches -O2 -Wall -D_FORTIFY_SOURCE=2 -fstack-protector -funwind-tables -fasynchronous-unwind-tables -g -c projectit.cpp -o projectit.o
> g++ -std=c++11 -shared -L/usr/lib64/R/lib -L/usr/local/lib64 -o rgdal.so OGR_write.o gdal-bindings.o init.o local_stubs.o ogr_geom.o ogr_polygons.o ogr_proj.o ogrdrivers.o ogrsource.o projectit.o -L/usr/lib64 -lgdal -lproj -L/usr/lib64/R/lib -lR
> installing to /usr/lib64/R/library/rgdal/libs
> ** R
> ** data
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> ** testing if installed package can be loaded
> * DONE (rgdal)
>
> The command I used for installing the package is "install.package('rgdal', repos='http://cran.r-project.org')". I don't know why R package installation is failing on SLES. Even other R packages are getting installed successfully on SLES. It seems that it is not picking gcc compiler on SLES. Could you please let me know, why installation of R package 'rgdal' is failing on SLES? Do I need set anything?
>
> Thanks
> Subhash
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From argantonio65 at gmail.com  Wed Jan 13 14:16:13 2016
From: argantonio65 at gmail.com (=?UTF-8?Q?Antonio_Manuel_Moreno_R=C3=B3denas?=)
Date: Wed, 13 Jan 2016 14:16:13 +0100
Subject: [R-sig-Geo] Universal Block Kriging covariate definition for krige
	in gstat
Message-ID: <CAHX-Q66hEYZeq=TZOK11aRnv7SJjJecg+LTNR2PpKsNTte1k6w@mail.gmail.com>

Hello, I would like to rise a question on the use of predict {gstat},

I'm trying to perform the estimation of a spatially distributed variable at
the support scale of a particular area (Block kriging). I have access to an
additional variable, it is known that the variable of interest is
correlated to the new variable. So I would be interested on updating my
estimation by the use of this new information. This could be done by the
use of a kriging with external drift (KED), but with a block support
(Universal Block kriging). Theoretically this is included in the gstat
library as mentioned in the documentation.

The issue comes when I try to perform the prediction:

blockprediction <- predict(gstat(formula=Variabletopredict~additionalVariable,
data=Observed, model=vgm), newdata = shapefile)

The newdata argument should contain the prediction location. In a normal
KED we would include a dataframe with a grid (coordinates in which to
predict) and the values of the covariate (additionalVariable). As I'm
trying to use a universal block kriging, I understood the newdata should be
the region in which I'm interested to know the prediction, hence a polygon.
How could I include in newdata the values of the covariate if its
resolution is finer than my block?

As far as I know, what block kriging does is to predict point values inside
the region (which I could specified with the argument sps.args
discretization), and later average them. But I don't know how to attach the
covariate values to the block of interest (shapefile).

Thanks in advance,
I hope I could explain it properly, but I will give more details if
necessary.
Kind regards,
Antonio

	[[alternative HTML version deleted]]


From ruegdeg at gmail.com  Wed Jan 13 14:18:10 2016
From: ruegdeg at gmail.com (Rob Deg)
Date: Wed, 13 Jan 2016 14:18:10 +0100
Subject: [R-sig-Geo] dismo package- data.frame of fitted function and
	variable values
Message-ID: <CAHdWW5vudjAF0AhX2Ohw9NZ_ezpmOeH+A+M+WbcZgJjQgqWxRA@mail.gmail.com>

Dear R-users,

Iam using the boosted regression trees to model the occurrence of
presence/absence data by using environmental factors.
Iam wondering how its possible to print out the data.frame of fitted
functions and variable values that were used in producing the gbm.plot.
For example, values of fitted functions (y-axis) and SegSumT (x-axis) from
the following plot provided in the dismo package example

======================
library(dismo)
data(Anguilla_train)
Anguilla_train = Anguilla_train[1:200,]
angaus.tc5.lr01 <- gbm.step(data=Anguilla_train, gbm.x = 3:14, gbm.y = 2,
family = "bernoulli", tree.complexity = 5, learning.rate = 0.01,
bag.fraction = 0.5)
gbm.plot(angaus.tc5.lr01)

=========================

Best,

Robert

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Wed Jan 13 14:43:09 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 13 Jan 2016 14:43:09 +0100
Subject: [R-sig-Geo] Universal Block Kriging covariate definition for
 krige in gstat
In-Reply-To: <CAHX-Q66hEYZeq=TZOK11aRnv7SJjJecg+LTNR2PpKsNTte1k6w@mail.gmail.com>
References: <CAHX-Q66hEYZeq=TZOK11aRnv7SJjJecg+LTNR2PpKsNTte1k6w@mail.gmail.com>
Message-ID: <5696546D.6060109@uni-muenster.de>



On 13/01/16 14:16, Antonio Manuel Moreno R?denas wrote:
> Hello, I would like to rise a question on the use of predict {gstat},
> 
> I'm trying to perform the estimation of a spatially distributed variable at
> the support scale of a particular area (Block kriging). I have access to an
> additional variable, it is known that the variable of interest is
> correlated to the new variable. So I would be interested on updating my
> estimation by the use of this new information. This could be done by the
> use of a kriging with external drift (KED), but with a block support
> (Universal Block kriging). Theoretically this is included in the gstat
> library as mentioned in the documentation.
> 
> The issue comes when I try to perform the prediction:
> 
> blockprediction <- predict(gstat(formula=Variabletopredict~additionalVariable,
> data=Observed, model=vgm), newdata = shapefile)
> 
> The newdata argument should contain the prediction location. In a normal
> KED we would include a dataframe with a grid (coordinates in which to
> predict) and the values of the covariate (additionalVariable). As I'm
> trying to use a universal block kriging, I understood the newdata should be
> the region in which I'm interested to know the prediction, hence a polygon.
> How could I include in newdata the values of the covariate if its
> resolution is finer than my block?
> 
> As far as I know, what block kriging does is to predict point values inside
> the region (which I could specified with the argument sps.args
> discretization), and later average them. But I don't know how to attach the
> covariate values to the block of interest (shapefile).

maybe by

shapefile = aggregate(additionalVariable, shapefile, mean)

> 
> Thanks in advance,
> I hope I could explain it properly, but I will give more details if
> necessary.
> Kind regards,
> Antonio
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160113/fd8cb892/attachment.bin>

From argantonio65 at gmail.com  Wed Jan 13 15:07:06 2016
From: argantonio65 at gmail.com (=?UTF-8?Q?Antonio_Manuel_Moreno_R=C3=B3denas?=)
Date: Wed, 13 Jan 2016 15:07:06 +0100
Subject: [R-sig-Geo] Universal Block Kriging covariate definition for
 krige in gstat
In-Reply-To: <5696546D.6060109@uni-muenster.de>
References: <CAHX-Q66hEYZeq=TZOK11aRnv7SJjJecg+LTNR2PpKsNTte1k6w@mail.gmail.com>
	<5696546D.6060109@uni-muenster.de>
Message-ID: <CAHX-Q679eSeQiwvW+a3XKL4Qnwa26kFks8h59SXwkzRvvsSEqw@mail.gmail.com>

Thanks a lot Edzer,

I'm not sure that would work.
In that way I would transfer to the kriging function the averaged value of
the covariate in the block. I'm not sure that would make the kriging behave
correctly.

All the points calculated with the prediction inside the block (and later
averaged to give the block kriging prediction) will have as "drift" the
average of the covariate in the block. Instead of getting the correct
spatial variability inside the block (given by the covariate). At first
sight it doesn't seems correct to me. Am I wrong?

kind regards



On 13 January 2016 at 14:43, Edzer Pebesma <edzer.pebesma at uni-muenster.de>
wrote:

>
>
> On 13/01/16 14:16, Antonio Manuel Moreno R?denas wrote:
> > Hello, I would like to rise a question on the use of predict {gstat},
> >
> > I'm trying to perform the estimation of a spatially distributed variable
> at
> > the support scale of a particular area (Block kriging). I have access to
> an
> > additional variable, it is known that the variable of interest is
> > correlated to the new variable. So I would be interested on updating my
> > estimation by the use of this new information. This could be done by the
> > use of a kriging with external drift (KED), but with a block support
> > (Universal Block kriging). Theoretically this is included in the gstat
> > library as mentioned in the documentation.
> >
> > The issue comes when I try to perform the prediction:
> >
> > blockprediction <-
> predict(gstat(formula=Variabletopredict~additionalVariable,
> > data=Observed, model=vgm), newdata = shapefile)
> >
> > The newdata argument should contain the prediction location. In a normal
> > KED we would include a dataframe with a grid (coordinates in which to
> > predict) and the values of the covariate (additionalVariable). As I'm
> > trying to use a universal block kriging, I understood the newdata should
> be
> > the region in which I'm interested to know the prediction, hence a
> polygon.
> > How could I include in newdata the values of the covariate if its
> > resolution is finer than my block?
> >
> > As far as I know, what block kriging does is to predict point values
> inside
> > the region (which I could specified with the argument sps.args
> > discretization), and later average them. But I don't know how to attach
> the
> > covariate values to the block of interest (shapefile).
>
> maybe by
>
> shapefile = aggregate(additionalVariable, shapefile, mean)
>
> >
> > Thanks in advance,
> > I hope I could explain it properly, but I will give more details if
> > necessary.
> > Kind regards,
> > Antonio
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Wed Jan 13 15:31:03 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 13 Jan 2016 15:31:03 +0100
Subject: [R-sig-Geo] Universal Block Kriging covariate definition for
 krige in gstat
In-Reply-To: <CAHX-Q66xasdUX47Rba4D-oZz_Ok77kvAUMCyuAfxm4+QWYJgpw@mail.gmail.com>
References: <CAHX-Q66hEYZeq=TZOK11aRnv7SJjJecg+LTNR2PpKsNTte1k6w@mail.gmail.com>
	<5696546D.6060109@uni-muenster.de>
	<CAHX-Q66xasdUX47Rba4D-oZz_Ok77kvAUMCyuAfxm4+QWYJgpw@mail.gmail.com>
Message-ID: <56965FA7.9070100@uni-muenster.de>



On 13/01/16 15:01, Antonio Manuel Moreno R?denas wrote:
> Thanks a lot Edzer,
> 
> I'm not sure that would work.
> In that way I would transfer to the kriging function the averaged value
> of the covariate in the block. I'm not sure that would make the kriging
> behave correctly. 
> 
> All the points calculated with the prediction inside the block (and
> later averaged to give the block kriging prediction) will have as
> "drift" the average of the covariate in the block. Instead of getting
> the correct spatial variability inside the block (given by the
> covariate). At first sight it doesn't seems correct to me. Am I wrong?

I think so, when the operations (computing the drift, and block
averaging) are both linear, it does not matter in which order they are
carried out: f(g(x)) = g(f(x)).

It would be easy to verify by computing the universal point kriging
values and aggregating those. Try

> library(sp)
> demo(meuse, ask = FALSE, echo = FALSE)
> library(gstat)
>
> v = vgm(.5, "Sph", 900, .1)
> kr1 = krige(log(zinc)~dist, meuse, meuse.grid, v)
[using universal kriging]
>
> meuse.area$dist = aggregate(meuse.grid["dist"], meuse.area)[[1]]
> kr2 = krige(log(zinc)~dist, meuse, meuse.area, v)
[using universal kriging]
> kr2$kr1 = aggregate(kr1["var1.pred"], meuse.area)[[1]]
>
> kr2$var1.pred
[1] 5.687753
> kr2$kr1
[1] 5.685026
>
> kr2$var1.pred / kr2$kr1
[1] 1.00048
>

My guess is that the difference can be attributed to how the area is
discretized (see ?predict.gstat)

> 
> kind regards
> 
> Antonio Manuel Moreno Rodenas
> 
> /Marie Curie Early Stage Researcher/
> /PhD Candidate/
> 
> *T**U **Delft / Section Sanitary Engineering, office 4.64*____
> 
> *Civil Engineering and Geoscience Faculty *
> 
> T +31 15 278 14 62
> 
> 
> On 13 January 2016 at 14:43, Edzer Pebesma
> <edzer.pebesma at uni-muenster.de <mailto:edzer.pebesma at uni-muenster.de>>
> wrote:
> 
> 
> 
>     On 13/01/16 14:16, Antonio Manuel Moreno R?denas wrote:
>     > Hello, I would like to rise a question on the use of predict {gstat},
>     >
>     > I'm trying to perform the estimation of a spatially distributed variable at
>     > the support scale of a particular area (Block kriging). I have access to an
>     > additional variable, it is known that the variable of interest is
>     > correlated to the new variable. So I would be interested on updating my
>     > estimation by the use of this new information. This could be done by the
>     > use of a kriging with external drift (KED), but with a block support
>     > (Universal Block kriging). Theoretically this is included in the gstat
>     > library as mentioned in the documentation.
>     >
>     > The issue comes when I try to perform the prediction:
>     >
>     > blockprediction <- predict(gstat(formula=Variabletopredict~additionalVariable,
>     > data=Observed, model=vgm), newdata = shapefile)
>     >
>     > The newdata argument should contain the prediction location. In a normal
>     > KED we would include a dataframe with a grid (coordinates in which to
>     > predict) and the values of the covariate (additionalVariable). As I'm
>     > trying to use a universal block kriging, I understood the newdata should be
>     > the region in which I'm interested to know the prediction, hence a polygon.
>     > How could I include in newdata the values of the covariate if its
>     > resolution is finer than my block?
>     >
>     > As far as I know, what block kriging does is to predict point values inside
>     > the region (which I could specified with the argument sps.args
>     > discretization), and later average them. But I don't know how to attach the
>     > covariate values to the block of interest (shapefile).
> 
>     maybe by
> 
>     shapefile = aggregate(additionalVariable, shapefile, mean)
> 
>     >
>     > Thanks in advance,
>     > I hope I could explain it properly, but I will give more details if
>     > necessary.
>     > Kind regards,
>     > Antonio
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-Geo mailing list
>     > R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     >
> 
>     --
>     Edzer Pebesma
>     Institute for Geoinformatics  (ifgi),  University of M?nster
>     Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
>     <tel:%2B49%20251%2083%2033081>
>     Journal of Statistical Software:   http://www.jstatsoft.org/
>     Computers & Geosciences:   http://elsevier.com/locate/cageo/
>     Spatial Statistics Society http://www.spatialstatistics.info
> 
> 
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160113/9cfd9af8/attachment.bin>

From bfalevlist at gmail.com  Wed Jan 13 17:51:49 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Wed, 13 Jan 2016 17:51:49 +0100
Subject: [R-sig-Geo] dismo package- data.frame of fitted function and
 variable values
In-Reply-To: <CAHdWW5vudjAF0AhX2Ohw9NZ_ezpmOeH+A+M+WbcZgJjQgqWxRA@mail.gmail.com>
References: <CAHdWW5vudjAF0AhX2Ohw9NZ_ezpmOeH+A+M+WbcZgJjQgqWxRA@mail.gmail.com>
Message-ID: <569680A5.2040106@gmail.com>

Dear Robert,
here you go the code that you need, based on the source code of 
gbm.plot() function:

gbm.object<-angaus.tc5.lr01
gbm.call <- gbm.object$gbm.call
data <- gbm.call$dataframe
pred.names <- gbm.call$predictor.names
k <- match("SegSumT",pred.names)
pred.data <- data[ , gbm.call$gbm.x[k]]
response.matrix <- gbm::plot.gbm(gbm.object, k, return.grid = TRUE)
predictors <- response.matrix[,1]
if (is.factor(data[,gbm.call$gbm.x[k]])) {
     predictors <- factor(predictors,levels = 
levels(data[,gbm.call$gbm.x[k]]))
}
responses <- response.matrix[,2] - mean(response.matrix[,2])
data.frame(predictors, responses)

Kind regards,
?kos Bede-Fazekas
Hungarian Academy of Sciences

2016.01.13. 14:18 keltez?ssel, Rob Deg ?rta:
> Dear R-users,
>
> Iam using the boosted regression trees to model the occurrence of
> presence/absence data by using environmental factors.
> Iam wondering how its possible to print out the data.frame of fitted
> functions and variable values that were used in producing the gbm.plot.
> For example, values of fitted functions (y-axis) and SegSumT (x-axis) from
> the following plot provided in the dismo package example
>
> ======================
> library(dismo)
> data(Anguilla_train)
> Anguilla_train = Anguilla_train[1:200,]
> angaus.tc5.lr01 <- gbm.step(data=Anguilla_train, gbm.x = 3:14, gbm.y = 2,
> family = "bernoulli", tree.complexity = 5, learning.rate = 0.01,
> bag.fraction = 0.5)
> gbm.plot(angaus.tc5.lr01)
>
> =========================
>
> Best,
>
> Robert
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From sytze.debruin at wur.nl  Thu Jan 14 12:35:39 2016
From: sytze.debruin at wur.nl (Bruin, Sytze de)
Date: Thu, 14 Jan 2016 11:35:39 +0000
Subject: [R-sig-Geo] Universal Block Kriging covariate definition
Message-ID: <f837a5bde8bc484f82aa33c26ae1af85@scomp5295.wurnet.nl>

Antonio Manuel Moreno R?denas wrote: 

> Thanks a lot Edzer, 
> 
> I'm not sure that would work. 
> In that way I would transfer to the kriging function the averaged value 
> of the covariate in the block. I'm not sure that would make the kriging 
> behave correctly. 
> 
> All the points calculated with the prediction inside the block (and 
> later averaged to give the block kriging prediction) will have as 
> "drift" the average of the covariate in the block. Instead of getting 
> the correct spatial variability inside the block (given by the 
> covariate). At first sight it doesn't seems correct to me. Am I wrong? 
I think so, when the operations (computing the drift, and block 
averaging) are both linear, it does not matter in which order they are 
carried out: f(g(x)) = g(f(x)). 

It would be easy to verify by computing the universal point kriging 
values and aggregating those. Try 

> library(sp) 
> demo(meuse, ask = FALSE, echo = FALSE) 
> library(gstat) 
>
> v = vgm(.5, "Sph", 900, .1) 
> kr1 = krige(log(zinc)~dist, meuse, meuse.grid, v) 
[using universal kriging] 
>
> meuse.area$dist = aggregate(meuse.grid["dist"], meuse.area)[[1]] 
> kr2 = krige(log(zinc)~dist, meuse, meuse.area, v) 
[using universal kriging] 
> kr2$kr1 = aggregate(kr1["var1.pred"], meuse.area)[[1]] 
>
> kr2$var1.pred 
[1] 5.687753 
> kr2$kr1 
[1] 5.685026 
>
> kr2$var1.pred / kr2$kr1 
[1] 1.00048 
>

My guess is that the difference can be attributed to how the area is 
discretized (see ?predict.gstat) 

> 
> kind regards 
> 
> Antonio Manuel Moreno Rodenas 
> 
> /Marie Curie Early Stage Researcher/ 
> /PhD Candidate/ 
> 
> *T**U **Delft / Section Sanitary Engineering, office 4.64*____ 
> 
> *Civil Engineering and Geoscience Faculty * 
> 
> T +31 15 278 14 62 
> 
> 
> On 13 January 2016 at 14:43, Edzer Pebesma 
> <[hidden email] <mailto:[hidden email]>>
> wrote: 
> 
> 
> 
> ? ? On 13/01/16 14:16, Antonio Manuel Moreno R?denas wrote: 
> ? ? > Hello, I would like to rise a question on the use of predict {gstat}, 
> ? ? > 
> ? ? > I'm trying to perform the estimation of a spatially distributed variable at 
> ? ? > the support scale of a particular area (Block kriging). I have access to an 
> ? ? > additional variable, it is known that the variable of interest is 
> ? ? > correlated to the new variable. So I would be interested on updating my 
> ? ? > estimation by the use of this new information. This could be done by the 
> ? ? > use of a kriging with external drift (KED), but with a block support 
> ? ? > (Universal Block kriging). Theoretically this is included in the gstat 
> ? ? > library as mentioned in the documentation. 
> ? ? > 
> ? ? > The issue comes when I try to perform the prediction: 
> ? ? > 
> ? ? > blockprediction <- predict(gstat(formula=Variabletopredict~additionalVariable, 
> ? ? > data=Observed, model=vgm), newdata = shapefile) 
> ? ? > 
> ? ? > The newdata argument should contain the prediction location. In a normal 
> ? ? > KED we would include a dataframe with a grid (coordinates in which to 
> ? ? > predict) and the values of the covariate (additionalVariable). As I'm 
> ? ? > trying to use a universal block kriging, I understood the newdata should be 
> ? ? > the region in which I'm interested to know the prediction, hence a polygon. 
> ? ? > How could I include in newdata the values of the covariate if its 
> ? ? > resolution is finer than my block? 
> ? ? > 
> ? ? > As far as I know, what block kriging does is to predict point values inside 
> ? ? > the region (which I could specified with the argument sps.args 
> ? ? > discretization), and later average them. But I don't know how to attach the 
> ? ? > covariate values to the block of interest (shapefile). 
> 
> ? ? maybe by 
> 
> ? ? shapefile = aggregate(additionalVariable, shapefile, mean) 
> 
> ? ? > 
> ? ? > Thanks in advance, 
> ? ? > I hope I could explain it properly, but I will give more details if 
> ? ? > necessary. 
> ? ? > Kind regards, 
> ? ? > Antonio 
> ? ? > 
> ? ? > ? ? ? [[alternative HTML version deleted]] 
> ? ? > 
> ? ? > _______________________________________________ 
> ? ? > R-sig-Geo mailing list 
> ? ? > [hidden email] <mailto:[hidden email]>
> ? ? > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> ? ? > 
> 
> ? ? -- 
> ? ? Edzer Pebesma 
> ? ? Institute for Geoinformatics ?(ifgi), ?University of M?nster 
> ? ? Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081 
> ? ? <tel:%2B49%20251%2083%2033081> 
> ? ? Journal of Statistical Software: ? http://www.jstatsoft.org/
> ? ? Computers & Geosciences: ? http://elsevier.com/locate/cageo/
> ? ? Spatial Statistics Society http://www.spatialstatistics.info
> 
> 

I believe the residual variogram should then be computed using the covariate data at block support. 

Sytze de Bruin
Wageningen University
Laboratory of Geo-Information Science and Remote Sensing 


From sytze.debruin at wur.nl  Thu Jan 14 12:30:51 2016
From: sytze.debruin at wur.nl (Bruin, Sytze de)
Date: Thu, 14 Jan 2016 11:30:51 +0000
Subject: [R-sig-Geo] Universal Block Kriging covariate definition
Message-ID: <1654cda0fe174ed389453d39f078fd38@scomp5295.wurnet.nl>

On 13/01/16 15:01, Antonio Manuel Moreno R?denas wrote:

> Thanks a lot Edzer,
>
> I'm not sure that would work.
> In that way I would transfer to the kriging function the averaged value
> of the covariate in the block. I'm not sure that would make the kriging
> behave correctly.
>
> All the points calculated with the prediction inside the block (and
> later averaged to give the block kriging prediction) will have as
> "drift" the average of the covariate in the block. Instead of getting
> the correct spatial variability inside the block (given by the
> covariate). At first sight it doesn't seems correct to me. Am I wrong?
I think so, when the operations (computing the drift, and block
averaging) are both linear, it does not matter in which order they are
carried out: f(g(x)) = g(f(x)).

It would be easy to verify by computing the universal point kriging
values and aggregating those. Try

> library(sp)
> demo(meuse, ask = FALSE, echo = FALSE)
> library(gstat)
>
> v = vgm(.5, "Sph", 900, .1)
> kr1 = krige(log(zinc)~dist, meuse, meuse.grid, v)
[using universal kriging]
>
> meuse.area$dist = aggregate(meuse.grid["dist"], meuse.area)[[1]]
> kr2 = krige(log(zinc)~dist, meuse, meuse.area, v)
[using universal kriging]
> kr2$kr1 = aggregate(kr1["var1.pred"], meuse.area)[[1]]
>
> kr2$var1.pred
[1] 5.687753
> kr2$kr1
[1] 5.685026
>
> kr2$var1.pred / kr2$kr1
[1] 1.00048
>

My guess is that the difference can be attributed to how the area is
discretized (see ?predict.gstat)

>
> kind regards
>
> Antonio Manuel Moreno Rodenas
>
> /Marie Curie Early Stage Researcher/
> /PhD Candidate/
>
> *T**U **Delft / Section Sanitary Engineering, office 4.64*____
>
> *Civil Engineering and Geoscience Faculty *
>
> T +31 15 278 14 62
>
>
> On 13 January 2016 at 14:43, Edzer Pebesma
> <[hidden email]<http://r-sig-geo.2731867.n2.nabble.com/user/SendEmail.jtp?type=node&node=7589380&i=0> <mailto:[hidden email]<http://r-sig-geo.2731867.n2.nabble.com/user/SendEmail.jtp?type=node&node=7589380&i=1>>>
> wrote:
>
>
>
>     On 13/01/16 14:16, Antonio Manuel Moreno R?denas wrote:
>     > Hello, I would like to rise a question on the use of predict {gstat},
>     >
>     > I'm trying to perform the estimation of a spatially distributed variable at
>     > the support scale of a particular area (Block kriging). I have access to an
>     > additional variable, it is known that the variable of interest is
>     > correlated to the new variable. So I would be interested on updating my
>     > estimation by the use of this new information. This could be done by the
>     > use of a kriging with external drift (KED), but with a block support
>     > (Universal Block kriging). Theoretically this is included in the gstat
>     > library as mentioned in the documentation.
>     >
>     > The issue comes when I try to perform the prediction:
>     >
>     > blockprediction <- predict(gstat(formula=Variabletopredict~additionalVariable,
>     > data=Observed, model=vgm), newdata = shapefile)
>     >
>     > The newdata argument should contain the prediction location. In a normal
>     > KED we would include a dataframe with a grid (coordinates in which to
>     > predict) and the values of the covariate (additionalVariable). As I'm
>     > trying to use a universal block kriging, I understood the newdata should be
>     > the region in which I'm interested to know the prediction, hence a polygon.
>     > How could I include in newdata the values of the covariate if its
>     > resolution is finer than my block?
>     >
>     > As far as I know, what block kriging does is to predict point values inside
>     > the region (which I could specified with the argument sps.args
>     > discretization), and later average them. But I don't know how to attach the
>     > covariate values to the block of interest (shapefile).
>
>     maybe by
>
>     shapefile = aggregate(additionalVariable, shapefile, mean)
>
>     >
>     > Thanks in advance,
>     > I hope I could explain it properly, but I will give more details if
>     > necessary.
>     > Kind regards,
>     > Antonio
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > _______________________________________________
>     > R-sig-Geo mailing list
>     > [hidden email]<http://r-sig-geo.2731867.n2.nabble.com/user/SendEmail.jtp?type=node&node=7589380&i=2> <mailto:[hidden email]<http://r-sig-geo.2731867.n2.nabble.com/user/SendEmail.jtp?type=node&node=7589380&i=3>>
>     > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     >
>
>     --
>     Edzer Pebesma
>     Institute for Geoinformatics  (ifgi),  University of M?nster
>     Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
>     <tel:%2B49%20251%2083%2033081>
>     Journal of Statistical Software:   http://www.jstatsoft.org/
>     Computers & Geosciences:   http://elsevier.com/locate/cageo/
>     Spatial Statistics Society http://www.spatialstatistics.info<http://www.spatialstatistics.info/>
>
>


I believe the residual variogram should then be computed using the covariate data at block support.

Sytze de Bruin
Wageningen University
Laboratory of Geo-Information Science and Remote Sensing


	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Jan 14 12:51:04 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 14 Jan 2016 12:51:04 +0100
Subject: [R-sig-Geo] Universal Block Kriging covariate definition
In-Reply-To: <f837a5bde8bc484f82aa33c26ae1af85@scomp5295.wurnet.nl>
References: <f837a5bde8bc484f82aa33c26ae1af85@scomp5295.wurnet.nl>
Message-ID: <56978BA8.4080907@uni-muenster.de>



On 14/01/16 12:35, Bruin, Sytze de wrote:
> I believe the residual variogram should then be computed using the covariate data at block support. 
> 
> Sytze de Bruin
> Wageningen University
> Laboratory of Geo-Information Science and Remote Sensing 

why?
-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160114/975efef6/attachment.bin>

From agaricha at gmail.com  Fri Jan 15 02:03:52 2016
From: agaricha at gmail.com (Richa Agarwal)
Date: Thu, 14 Jan 2016 17:03:52 -0800
Subject: [R-sig-Geo] Mapping Singapore data
Message-ID: <CAGcE_2jCEyBeFTZJof3ALg6YsR2zgU7jVEpRGoD1koFOp+g=6A@mail.gmail.com>

Hi Guys,

I have some experience with R though relatively new to mapping geo data.

I am trying to plot a heat map for Singapore and was trying to figure out
what would be the best way to start. Reading up online I downloaded a .rds
file from http://www.gadm.org/country. Though sure how to proceed now.

Thanks
Richa

	[[alternative HTML version deleted]]


From bob at rudis.net  Fri Jan 15 06:18:56 2016
From: bob at rudis.net (boB Rudis)
Date: Fri, 15 Jan 2016 00:18:56 -0500
Subject: [R-sig-Geo] Mapping Singapore data
In-Reply-To: <CAGcE_2jCEyBeFTZJof3ALg6YsR2zgU7jVEpRGoD1koFOp+g=6A@mail.gmail.com>
References: <CAGcE_2jCEyBeFTZJof3ALg6YsR2zgU7jVEpRGoD1koFOp+g=6A@mail.gmail.com>
Message-ID: <CAJ4QxaNNoYXOgtgBPz0dFN5jZoE-afzQw38KXWULSfQf_iwfVA@mail.gmail.com>

This can get you started (if you're the ggplot2 sort of person).
raster::getData will pull the data without a manual download. I'm not
sure what you need admin-level-wise, so I went with Admin1.
ggplot2::fortify takes the spatial data and makes it something ggplot2
can work with. It would normally use the polygon id, but you can
substitute other identifiers from the shapefile. i went with the
region name.

i made a dummy data frame for a random choropleth and then proceed to
plot the base map and fill layers.

viridis is a nice scale, but you'd ideally want to cut or cut2 some
levels since it's unlikely you have data that should be on a
continuous scale (just guessing tho).

the projection i chose is a pretty gd one for that region with those
lat/lon boundaries.

library(raster)
library(rgeos)
library(maptools)
library(ggplot2)
library(ggalt)
library(ggthemes)
library(viridis)

sg <- getData(country="SGP", level=1)

sg_map <- fortify(sg, region="NAME_1")

choro_dat <- data.frame(region=sg at data$NAME_1,
                        value=sample(100, nrow(sg at data)),
                        stringsAsFactors=FALSE)

gg <- ggplot()
gg <- gg + geom_map(data=sg_map, map=sg_map,
                    aes(x=long, y=lat, map_id=id),
                    color="#b2b2b200", fill="#ffffff00", size=0.15)
gg <- gg + geom_map(data=choro_dat, map=sg_map,
                    aes(fill=value, map_id=region),
                    color="#b2b2b2", size=0.15)
gg <- gg + coord_proj("+proj=aea +lon_0=103.8474")
gg <- gg + scale_fill_viridis(name="Measure")
gg <- gg + theme_map()
gg <- gg + theme(legend.position="bottom")
gg

On Thu, Jan 14, 2016 at 8:03 PM, Richa Agarwal <agaricha at gmail.com> wrote:
> Hi Guys,
>
> I have some experience with R though relatively new to mapping geo data.
>
> I am trying to plot a heat map for Singapore and was trying to figure out
> what would be the best way to start. Reading up online I downloaded a .rds
> file from http://www.gadm.org/country. Though sure how to proceed now.
>
> Thanks
> Richa
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sytze.debruin at wur.nl  Fri Jan 15 15:00:25 2016
From: sytze.debruin at wur.nl (Bruin, Sytze de)
Date: Fri, 15 Jan 2016 14:00:25 +0000
Subject: [R-sig-Geo] Universal Block Kriging covariate definition
Message-ID: <627b7f7cdc194ccfb575b543f6e50537@scomp5295.wurnet.nl>

On 14/01/16 12:35, Bruin, Sytze de wrote:
> I believe the residual variogram should then be computed using the covariate data at block support.
>
> Sytze de Bruin
> Wageningen University
> Laboratory of Geo-Information Science and Remote Sensing

why?
--
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info<http://www.spatialstatistics.info/>

That believe was a mistake. The residual variogram computed from the covariate data at point support should be used. It doesn't matter that the covariate data are first aggregated over the blocks. The order of the operations is unimportant for the kriging predictions while the residual variogram at point support is the correct model for the computations of point-block and point-point covariances (or semivariances).  Sorry for any confusion caused by my previous post.

Sytze de Bruin
Wageningen University
Laboratory of Geo-Information Science and Remote Sensing


	[[alternative HTML version deleted]]


From lekisoft at gmail.com  Fri Jan 15 18:00:20 2016
From: lekisoft at gmail.com (Amao Abduljamiu)
Date: Fri, 15 Jan 2016 20:00:20 +0300
Subject: [R-sig-Geo] help with 2d- Density plots (ggplot2)
Message-ID: <01be01d14fb6$3890a220$a9b1e660$@gmail.com>

Dear All, 

I need help with 2d- Density plots (ggplot2)...

I'm trying to plot ecological distribution of some species of organisms i'm
studying over the Arabian/Persian Gulf. Here is a sample of code i've tried,

Backround layer

nc <- get_map("Persian Gulf", zoom = 6, maptype = 'terrain', language =
"English")
ncmap <- ggmap(nc,  extent = "device")

Other layers

  ncmap+
    stat_density2d(data=sample.data3, aes(x=long, y=lat, fill=..level..,
alpha=..level..),geom="polygon")+
    geom_point(data=sample.data3, aes(x=long, y=lat))+
    geom_point(aes(x =50.626444, y = 26.044472), color="red", size = 4)+
    scale_fill_gradient(low = "green", high = "red") + scale_alpha(range =
c(0.00, 0.25), guide = FALSE)

but , i will like to use the stat_density2d to show the distributions of
hundreds of species (which are recorded in columns e.g SP1....SPn) over the
water body rather than just displaying latitude and longitude.

Also, is it possible to restrict my heat map to just the water body ? I'll
appreciate any help and recommendations i can get on this please

I will also appreciate any suggestion on alternative way to achieve this.


Here is a link to stackoverflow where I initially asked the question with an
image of what the problem look like. 

http://stackoverflow.com/questions/34569152/ggplot-stat-density2d-plots-for-
ecological-distribution

Sincerely
Amao
-------------------------------------------
Amao Abduljamiu O.
PhD Candidate - Geology
Earth Sciences Department
King Fahd University of Petroleum and Minerals (KFUPM)
Dhahran, Saudi Arabia
P. O. Box 1723?KFUPM, Dhahran 31261 Saudi Arabia
Tel. office?+966 3 860 3240
Mobile:?+966 535467527
Skype: lakesido02
Email:?amao at kfupm.edu.sa
Alt:?lekisoft at gmail.com


From tom.gottfried at o2mail.de  Sat Jan 16 15:50:04 2016
From: tom.gottfried at o2mail.de (Tom Gottfried)
Date: Sat, 16 Jan 2016 15:50:04 +0100
Subject: [R-sig-Geo] Universal Block Kriging covariate definition for
 krige in gstat
In-Reply-To: <56965FA7.9070100@uni-muenster.de>
References: <CAHX-Q66hEYZeq=TZOK11aRnv7SJjJecg+LTNR2PpKsNTte1k6w@mail.gmail.com>
	<5696546D.6060109@uni-muenster.de>
	<CAHX-Q66xasdUX47Rba4D-oZz_Ok77kvAUMCyuAfxm4+QWYJgpw@mail.gmail.com>
	<56965FA7.9070100@uni-muenster.de>
Message-ID: <569A589C.6030506@o2mail.de>

Hi all,

Am 13.01.2016 um 15:31 schrieb Edzer Pebesma:
> I think so, when the operations (computing the drift, and block
> averaging) are both linear, it does not matter in which order they are
> carried out: f(g(x)) = g(f(x)).

... which seems to be one of the messages of this paper:

@article{title = {Spatial aggregation and soil process modelling},
volume = {89},
issn = {0016-7061},
number = {1-2},
journal = {Geoderma},
author = {Heuvelink, G B M and Pebesma, E J},
month = apr,
year = {1999},
pages = {47--65}}


>>     On 13/01/16 14:16, Antonio Manuel Moreno R?denas wrote:
>>     > As far as I know, what block kriging does is to predict point values inside
>>     > the region (which I could specified with the argument sps.args
>>     > discretization), and later average them.

Not really. In case of the prediction of a block, there are no points to
predict at within that block (there could be data points within the
block, but predicting at these is of no point because kriging is exact
in the sense that the prediction at a data point does not deviate from
the actual datum). The calculation of the kriging weights really differs
between point and block kriging. See e.g. the following publication:

@article{title = {Optimal interpolation and isarithmic mapping of soil
properties. {II} {Block} kriging},
	volume = {31},
	issn = {0022-4588},
	number = {2},
	journal = {Journal of Soil Science},
	author = {Burgess, T M and Webster, R},
	year = {1980},
	pages = {333--341},
}

Adding 'debug.level=32' to both calls of `krige' in Edzer's example
illustrates that there is only one occurrence of kriging weights after
the second call, corresponding to only one prediction location (here the
area) in contrast to many prediction locations (on the grid) in the
first call. The grid is even unknown within the second call and thus the
corresponding point predictions are impossible.

Tom

-- 
Tom Gottfried


From thierry.onkelinx at inbo.be  Sat Jan 16 20:18:53 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Sat, 16 Jan 2016 20:18:53 +0100
Subject: [R-sig-Geo] help with 2d- Density plots (ggplot2)
In-Reply-To: <01be01d14fb6$3890a220$a9b1e660$@gmail.com>
References: <01be01d14fb6$3890a220$a9b1e660$@gmail.com>
Message-ID: <CAJuCY5wsq62Pqm-shLrmKZD96ySWmq=fg5WqjTbU5Y6qQ_xuiQ@mail.gmail.com>

Dear Amao,

It's not clear how the "hundreds of species" come into the play. Do you
want a map for each species? Or rather a single map that combines the
species info.

ggplot2() has AFAIK no options to restrict the output of stat_bin2d() to a
polygon.

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-01-15 18:00 GMT+01:00 Amao Abduljamiu <lekisoft at gmail.com>:

> Dear All,
>
> I need help with 2d- Density plots (ggplot2)...
>
> I'm trying to plot ecological distribution of some species of organisms i'm
> studying over the Arabian/Persian Gulf. Here is a sample of code i've
> tried,
>
> Backround layer
>
> nc <- get_map("Persian Gulf", zoom = 6, maptype = 'terrain', language =
> "English")
> ncmap <- ggmap(nc,  extent = "device")
>
> Other layers
>
>   ncmap+
>     stat_density2d(data=sample.data3, aes(x=long, y=lat, fill=..level..,
> alpha=..level..),geom="polygon")+
>     geom_point(data=sample.data3, aes(x=long, y=lat))+
>     geom_point(aes(x =50.626444, y = 26.044472), color="red", size = 4)+
>     scale_fill_gradient(low = "green", high = "red") + scale_alpha(range =
> c(0.00, 0.25), guide = FALSE)
>
> but , i will like to use the stat_density2d to show the distributions of
> hundreds of species (which are recorded in columns e.g SP1....SPn) over the
> water body rather than just displaying latitude and longitude.
>
> Also, is it possible to restrict my heat map to just the water body ? I'll
> appreciate any help and recommendations i can get on this please
>
> I will also appreciate any suggestion on alternative way to achieve this.
>
>
> Here is a link to stackoverflow where I initially asked the question with
> an
> image of what the problem look like.
>
>
> http://stackoverflow.com/questions/34569152/ggplot-stat-density2d-plots-for-
> ecological-distribution
>
> Sincerely
> Amao
> -------------------------------------------
> Amao Abduljamiu O.
> PhD Candidate - Geology
> Earth Sciences Department
> King Fahd University of Petroleum and Minerals (KFUPM)
> Dhahran, Saudi Arabia
> P. O. Box 1723 KFUPM, Dhahran 31261 Saudi Arabia
> Tel. office +966 3 860 3240
> Mobile: +966 535467527
> Skype: lakesido02
> Email: amao at kfupm.edu.sa
> Alt: lekisoft at gmail.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From lekisoft at gmail.com  Sun Jan 17 00:39:05 2016
From: lekisoft at gmail.com (Amao Abduljamiu)
Date: Sun, 17 Jan 2016 02:39:05 +0300
Subject: [R-sig-Geo] help with 2d- Density plots (ggplot2)
In-Reply-To: <CAJuCY5wsq62Pqm-shLrmKZD96ySWmq=fg5WqjTbU5Y6qQ_xuiQ@mail.gmail.com>
References: <01be01d14fb6$3890a220$a9b1e660$@gmail.com>
	<CAJuCY5wsq62Pqm-shLrmKZD96ySWmq=fg5WqjTbU5Y6qQ_xuiQ@mail.gmail.com>
Message-ID: <58B87432-9FA4-4509-A0A5-5A59CBFE6407@gmail.com>

Yes Sir, my plan is to have several maps .i.e a map for each species. 

Sent from my iPad

> On Jan 16, 2016, at 10:18 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be> wrote:
> 
> Dear Amao,
> 
> It's not clear how the "hundreds of species" come into the play. Do you want a map for each species? Or rather a single map that combines the species info.
> 
> ggplot2() has AFAIK no options to restrict the output of stat_bin2d() to a polygon. 
> 
> Best regards,
> 
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest 
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance 
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner 
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. ~ John Tukey
> 
> 2016-01-15 18:00 GMT+01:00 Amao Abduljamiu <lekisoft at gmail.com>:
>> Dear All,
>> 
>> I need help with 2d- Density plots (ggplot2)...
>> 
>> I'm trying to plot ecological distribution of some species of organisms i'm
>> studying over the Arabian/Persian Gulf. Here is a sample of code i've tried,
>> 
>> Backround layer
>> 
>> nc <- get_map("Persian Gulf", zoom = 6, maptype = 'terrain', language =
>> "English")
>> ncmap <- ggmap(nc,  extent = "device")
>> 
>> Other layers
>> 
>>   ncmap+
>>     stat_density2d(data=sample.data3, aes(x=long, y=lat, fill=..level..,
>> alpha=..level..),geom="polygon")+
>>     geom_point(data=sample.data3, aes(x=long, y=lat))+
>>     geom_point(aes(x =50.626444, y = 26.044472), color="red", size = 4)+
>>     scale_fill_gradient(low = "green", high = "red") + scale_alpha(range =
>> c(0.00, 0.25), guide = FALSE)
>> 
>> but , i will like to use the stat_density2d to show the distributions of
>> hundreds of species (which are recorded in columns e.g SP1....SPn) over the
>> water body rather than just displaying latitude and longitude.
>> 
>> Also, is it possible to restrict my heat map to just the water body ? I'll
>> appreciate any help and recommendations i can get on this please
>> 
>> I will also appreciate any suggestion on alternative way to achieve this.
>> 
>> 
>> Here is a link to stackoverflow where I initially asked the question with an
>> image of what the problem look like.
>> 
>> http://stackoverflow.com/questions/34569152/ggplot-stat-density2d-plots-for-
>> ecological-distribution
>> 
>> Sincerely
>> Amao
>> -------------------------------------------
>> Amao Abduljamiu O.
>> PhD Candidate - Geology
>> Earth Sciences Department
>> King Fahd University of Petroleum and Minerals (KFUPM)
>> Dhahran, Saudi Arabia
>> P. O. Box 1723 KFUPM, Dhahran 31261 Saudi Arabia
>> Tel. office +966 3 860 3240
>> Mobile: +966 535467527
>> Skype: lakesido02
>> Email: amao at kfupm.edu.sa
>> Alt: lekisoft at gmail.com
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

	[[alternative HTML version deleted]]


From mariaolbak at gmail.com  Sun Jan 17 21:59:23 2016
From: mariaolbak at gmail.com (Maria Bakhtsiyarava)
Date: Sun, 17 Jan 2016 14:59:23 -0600
Subject: [R-sig-Geo] splm and LogLik, help again!
Message-ID: <CAGJwBADLy3bFqEnDVafwLyY+DMP3YkX8p+5sNWm6tSRo2oMUOw@mail.gmail.com>

Hello everyone,

I want to follow up on one of the previous posts about retrieving Log
Likelihood for models in package "splm". I would really appreciate any help!
I tried the following solution that was posted earlier:

"fixInNamespace("sperrorlm", "splm")
manually add "ll=LL" as an element to the "return" list at the end of the
function so that it reads:
return <- list(coeff = betas, lambda = lambda, s2 = s2, rest.se = rest.se,
        lambda.se = lambda.se, asyvar1 = asyvar1, ll=LL)"

However, after I edited the return object that way and then run my model, I
got this error (the model ran just fine before that.):
 >Error in (function (arg)  : object 'sarpanelerror' not found.

Here is my model: fmL=spml(model,data=dat, listw=sp_weightsm, model =
"within", effect = "time", spatial.error = "b", lag = FALSE, quiet = T)

Is there something else that needs to be edited to obtain the LogLik value?
Or is there an alternative way to get it?

Thank you so much,
Maryia

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Mon Jan 18 09:35:38 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 18 Jan 2016 09:35:38 +0100
Subject: [R-sig-Geo] sp and gstat dev moved to github
Message-ID: <569CA3DA.2050206@uni-muenster.de>

I moved the development trees of sp and gstat to github. Feel free to
send issues or pull requests there. For automatically created windows
binaries, I will update r-forge upon request only.

https://github.com/edzer/sp
https://github.com/edzer/gstat

Best regards,
-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160118/1126e005/attachment.bin>

From thierry.onkelinx at inbo.be  Mon Jan 18 09:35:59 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 18 Jan 2016 09:35:59 +0100
Subject: [R-sig-Geo] help with 2d- Density plots (ggplot2)
In-Reply-To: <58B87432-9FA4-4509-A0A5-5A59CBFE6407@gmail.com>
References: <01be01d14fb6$3890a220$a9b1e660$@gmail.com>
	<CAJuCY5wsq62Pqm-shLrmKZD96ySWmq=fg5WqjTbU5Y6qQ_xuiQ@mail.gmail.com>
	<58B87432-9FA4-4509-A0A5-5A59CBFE6407@gmail.com>
Message-ID: <CAJuCY5xZF2d4ZPs_YMX4r4xk2WbU7zG82ztjp+qB-JqA3Zm_Jw@mail.gmail.com>

Just loop over the species columns and use them to subset the data

nc <- get_map("Persian Gulf", zoom = 6, maptype = 'terrain', language =
"English")
ncmap <- ggmap(nc,  extent = "device")
extra_map <-     geom_point(data=this_species, aes(x=long, y=lat))+
    geom_point(aes(x =50.626444, y = 26.044472), color="red", size = 4)+
    scale_fill_gradient(low = "green", high = "red") + scale_alpha(range =
c(0.00, 0.25), guide = FALSE)

# assuming SP1 is the 3rd column
for (i in 2 + seq_len(n_species)) {
    this_species <- sample.data3[sample.data3[, i] > 0, ]
   p <- ncmap +
    stat_density2d(data=this_species, aes(x=long, y=lat, fill=..level..,
alpha=..level..),geom="polygon") +
    extra_map
    print(p)
}

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-01-17 0:39 GMT+01:00 Amao Abduljamiu <lekisoft at gmail.com>:

> Yes Sir, my plan is to have several maps .i.e a map for each species.
>
> Sent from my iPad
>
> On Jan 16, 2016, at 10:18 PM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
> wrote:
>
> Dear Amao,
>
> It's not clear how the "hundreds of species" come into the play. Do you
> want a map for each species? Or rather a single map that combines the
> species info.
>
> ggplot2() has AFAIK no options to restrict the output of stat_bin2d() to a
> polygon.
>
> Best regards,
>
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2016-01-15 18:00 GMT+01:00 Amao Abduljamiu <lekisoft at gmail.com>:
>
>> Dear All,
>>
>> I need help with 2d- Density plots (ggplot2)...
>>
>> I'm trying to plot ecological distribution of some species of organisms
>> i'm
>> studying over the Arabian/Persian Gulf. Here is a sample of code i've
>> tried,
>>
>> Backround layer
>>
>> nc <- get_map("Persian Gulf", zoom = 6, maptype = 'terrain', language =
>> "English")
>> ncmap <- ggmap(nc,  extent = "device")
>>
>> Other layers
>>
>>   ncmap+
>>     stat_density2d(data=sample.data3, aes(x=long, y=lat, fill=..level..,
>> alpha=..level..),geom="polygon")+
>>     geom_point(data=sample.data3, aes(x=long, y=lat))+
>>     geom_point(aes(x =50.626444, y = 26.044472), color="red", size = 4)+
>>     scale_fill_gradient(low = "green", high = "red") + scale_alpha(range =
>> c(0.00, 0.25), guide = FALSE)
>>
>> but , i will like to use the stat_density2d to show the distributions of
>> hundreds of species (which are recorded in columns e.g SP1....SPn) over
>> the
>> water body rather than just displaying latitude and longitude.
>>
>> Also, is it possible to restrict my heat map to just the water body ? I'll
>> appreciate any help and recommendations i can get on this please
>>
>> I will also appreciate any suggestion on alternative way to achieve this.
>>
>>
>> Here is a link to stackoverflow where I initially asked the question with
>> an
>> image of what the problem look like.
>>
>>
>> http://stackoverflow.com/questions/34569152/ggplot-stat-density2d-plots-for-
>> ecological-distribution
>> <http://stackoverflow.com/questions/34569152/ggplot-stat-density2d-plots-for-ecological-distribution>
>>
>> Sincerely
>> Amao
>> -------------------------------------------
>> Amao Abduljamiu O.
>> PhD Candidate - Geology
>> Earth Sciences Department
>> King Fahd University of Petroleum and Minerals (KFUPM)
>> Dhahran, Saudi Arabia
>> P. O. Box 1723 KFUPM, Dhahran 31261 Saudi Arabia
>> Tel. office +966 3 860 3240
>> Mobile: +966 535467527
>> Skype: lakesido02
>> Email: amao at kfupm.edu.sa
>> Alt: lekisoft at gmail.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From konno_kazuma at mailplus.pl  Mon Jan 18 12:02:43 2016
From: konno_kazuma at mailplus.pl (=?UTF-8?Q?Kamil_Konowalik?=)
Date: Mon, 18 Jan 2016 12:02:43 +0100
Subject: [R-sig-Geo] =?utf-8?q?How_to_speed_up_=22extract=22_function_in_r?=
	=?utf-8?q?aster_package=3F?=
Message-ID: <263e2fa4.5a497f73.569cc653.8e3b4@mailplus.pl>

Dear list members,
I'm trying to extract values for ca. 1000 points from 19 raster files. It is a very simple task - as an output I need a table where each point has additional 19 columns with values derived from those raster files (specifically I'm creating a SWD input file for Maxent). I used extract function but the whole task is running very slow - so far the whole process took 10 days and it is not finished yet. My computer is rather slow (Windows 7 32 bit, intel core duo 2.2 GHz, 3 GB RAM) but currently I need to use this machine. I was wondering whether there is a way to speed up the whole process by using a different command or maybe there is any trick that can speed it up?

Here's the code I'm using:

files <- list.files("C:/GIS/worldclim/biolcimatic_variables_ASCII",pattern='asc',full.names=TRUE)
Grids <- raster::stack(files)
background <- read.csv("C:/GIS/species_background/bg.csv",header=TRUE)
LonLatData2 <- background[,c(2,3)]
var_at_background <- raster::extract(Grids,LonLatData2) #I'm here since 10 days
outfile2 <- as.data.frame(cbind("species",LonLatData2,var_at_background))
colnames(outfile2) <- c("species","longitude","latitude",colnames(var_at_background))
write.csv(outfile2, file="variables_background.csv", append = FALSE, sep = ",", eol = "\n", na = "NA", dec = ".", col.names = TRUE, row.names = FALSE)

I started to use R relatively recently so excuse me if there is something that I missed here but I was searching for an answer without any success.
Best regards,
Kamil 

Wroc?aw University of Environmental and Life Sciences, Poland


From inacio.adrien at gmail.com  Mon Jan 18 13:34:57 2016
From: inacio.adrien at gmail.com (Adrien Inacio)
Date: Mon, 18 Jan 2016 13:34:57 +0100
Subject: [R-sig-Geo] How to import a huge quantity of raster
Message-ID: <CAHN6w5junaVaDeXQ5chUTsNbidicQUv0yJE2WK321hivcMfj2Q@mail.gmail.com>

Dear list members,
I'm trying to analyse a map divided in some 500.000 pixels... so I've to
calculate some indices for each pixels.
This map in Arcgis is a shape file and I have to analyse each pixel in a
raster format.

 For that I need to extract in raster and analyse one pixel after an other.
So, I'm looking for a solution to analyse every pixel by an automatic
method.

I hope one of you have a solution.
Thank you very much for your Help.

Best regards,
Adrien

La Rochelle University, France.

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Mon Jan 18 15:39:44 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 18 Jan 2016 15:39:44 +0100
Subject: [R-sig-Geo] splm and LogLik, help again!
In-Reply-To: <CAGJwBADLy3bFqEnDVafwLyY+DMP3YkX8p+5sNWm6tSRo2oMUOw@mail.gmail.com>
References: <CAGJwBADLy3bFqEnDVafwLyY+DMP3YkX8p+5sNWm6tSRo2oMUOw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1601181522430.7941@reclus.nhh.no>

On Sun, 17 Jan 2016, Maria Bakhtsiyarava wrote:

> Hello everyone,
>
> I want to follow up on one of the previous posts about retrieving Log
> Likelihood for models in package "splm". I would really appreciate any help!
> I tried the following solution that was posted earlier:
>
> "fixInNamespace("sperrorlm", "splm")
> manually add "ll=LL" as an element to the "return" list at the end of the
> function so that it reads:
> return <- list(coeff = betas, lambda = lambda, s2 = s2, rest.se = rest.se,
>        lambda.se = lambda.se, asyvar1 = asyvar1, ll=LL)"
>
> However, after I edited the return object that way and then run my model, I
> got this error (the model ran just fine before that.):
> >Error in (function (arg)  : object 'sarpanelerror' not found.

This error comes in:

     opt <- optimize(sarpanelerror, interval = interval, maximum = TRUE,
         env = env, tol = con$tol.opt)

so I guess you need to use fixInNamespace("sperrorlm", "splm") again to 
prepend splm::: to all non-exported objects in the edited function. I 
can't reproduce this with splm_1.3-7 and R 3.2.3 under Linux. I think 
you'd have to pass the returned value up through spfeml() and spml() too, 
but you probably know that already.

Hope this helps,

Roger

>
> Here is my model: fmL=spml(model,data=dat, listw=sp_weightsm, model =
> "within", effect = "time", spatial.error = "b", lag = FALSE, quiet = T)
>
> Is there something else that needs to be edited to obtain the LogLik value?
> Or is there an alternative way to get it?
>
> Thank you so much,
> Maryia
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From mdsumner at gmail.com  Mon Jan 18 21:59:05 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 18 Jan 2016 20:59:05 +0000
Subject: [R-sig-Geo] How to speed up "extract" function in raster
	package?
In-Reply-To: <263e2fa4.5a497f73.569cc653.8e3b4@mailplus.pl>
References: <263e2fa4.5a497f73.569cc653.8e3b4@mailplus.pl>
Message-ID: <CAAcGz99CZBYRko1E1XML5ZuozaLEZXgJtgxcDvW3n0SDxj0+7g@mail.gmail.com>

On Mon, 18 Jan 2016 at 22:03 Kamil Konowalik <konno_kazuma at mailplus.pl>
wrote:

> Dear list members,
> I'm trying to extract values for ca. 1000 points from 19 raster files. It
> is a very simple task - as an output I need a table where each point has
> additional 19 columns with values derived from those raster files
> (specifically I'm creating a SWD input file for Maxent). I used extract
> function but the whole task is running very slow - so far the whole process
> took 10 days and it is not finished yet. My computer is rather slow
> (Windows 7 32 bit, intel core duo 2.2 GHz, 3 GB RAM) but currently I need
> to use this machine. I was wondering whether there is a way to speed up the
> whole process by using a different command or maybe there is any trick that
> can speed it up?
>
> Here's the code I'm using:
>
> files <-
> list.files("C:/GIS/worldclim/biolcimatic_variables_ASCII",pattern='asc',full.names=TRUE)
> Grids <- raster::stack(files)
> background <- read.csv("C:/GIS/species_background/bg.csv",header=TRUE)
> LonLatData2 <- background[,c(2,3)]
> var_at_background <- raster::extract(Grids,LonLatData2) #I'm here since 10
> days
> outfile2 <- as.data.frame(cbind("species",LonLatData2,var_at_background))
> colnames(outfile2) <-
> c("species","longitude","latitude",colnames(var_at_background))
> write.csv(outfile2, file="variables_background.csv", append = FALSE, sep =
> ",", eol = "\n", na = "NA", dec = ".", col.names = TRUE, row.names = FALSE)
>
>


Probably the best thing to do is get you data out of those .asc files and
into something more sensible, like raster's native .grd format. Please let
us know the dimensions of your raster, the print-out of


Grids


would suffice. Otherwise, try this


files <-
list.files("C:/GIS/worldclim/biolcimatic_variables_ASCII",pattern='asc',full.names=TRUE)
Grids0 <- raster::stack(files)
Grids <- writeRaster(Grids0, "native.grd") ## best if you can put it on a
different physical disk
## Grids <- writeRaster(Grids0, "D:/some/where/native.grd")


## then, proceed as you were


background <- read.csv("C:/GIS/species_background/bg.csv",header=TRUE)
LonLatData2 <- background[,c(2,3)]
var_at_background <- raster::extract(Grids,LonLatData2) #I'm here since 10
days



I include an option to write out to a different physical disk, you should
really do that if you can - if your read and write to the same disk one
process has to wait for the other. Also, if your data can just fit in
memory that would be the fastest all out.


ASC is possibly the worst format to you use for data like these, it's text,
it's bloated, has insufficient metadata, can't be tiled or compressed
internally and really there's no excuse these days.


Neither of these apply to your situation, but if you have to do a lot of
this kind of stuff, note that extract on a single-layer Brick can be much
faster than on a RasterLayer - I don't know why yet, and extract() is also
not suited to internally tiled rasters (common to GeoTIFF) since it scans
line by line which is inefficient when the thing is tiled. .


Cheers, Mike.





> I started to use R relatively recently so excuse me if there is something
> that I missed here but I was searching for an answer without any success.
> Best regards,
> Kamil
>
> Wroc?aw University of Environmental and Life Sciences, Poland
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From inacio.adrien at gmail.com  Tue Jan 19 13:32:42 2016
From: inacio.adrien at gmail.com (Adrien Inacio)
Date: Tue, 19 Jan 2016 13:32:42 +0100
Subject: [R-sig-Geo] Raster analysis in a fishnet
Message-ID: <CAHN6w5gnrZk++7cCkrTLyNX3MVHz96TKutmejx07r4vL_bmAiQ@mail.gmail.com>

Dear list members,
Do you know a way to analyse a raster (I use the SDMTools-classStat) with a
fishnet?
I explain my problem: For a map of the mediterranean sea, I've to extract
landscape indices by cells of 50meters x 50 meters.

For that I've a raster map or a shape map and a fishnet at the good size,
create with arcgis.

And after that I just don't know what I've to do....
Indeed, it's impossible for me to extract and analyse the cells one by one,
so I hope on solution exist in R.

Thank you very much for your Help.

Best regards,
Adrien

	[[alternative HTML version deleted]]


From roman.lustrik at gmail.com  Tue Jan 19 13:35:25 2016
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 19 Jan 2016 13:35:25 +0100
Subject: [R-sig-Geo] Raster analysis in a fishnet
In-Reply-To: <CAHN6w5gnrZk++7cCkrTLyNX3MVHz96TKutmejx07r4vL_bmAiQ@mail.gmail.com>
References: <CAHN6w5gnrZk++7cCkrTLyNX3MVHz96TKutmejx07r4vL_bmAiQ@mail.gmail.com>
Message-ID: <CAHT1vpj9DvrjY7vJLJx_GZRwMdy==cLBT6FaUGi4kwWVyZemCg@mail.gmail.com>

Many operations can be done using package `raster`. It is also accompanied
with a number of vignettes (
https://cran.r-project.org/web/packages/raster/index.html) which you might
want to read first.

Cheers,
Roman

On Tue, Jan 19, 2016 at 1:32 PM, Adrien Inacio <inacio.adrien at gmail.com>
wrote:

> Dear list members,
> Do you know a way to analyse a raster (I use the SDMTools-classStat) with a
> fishnet?
> I explain my problem: For a map of the mediterranean sea, I've to extract
> landscape indices by cells of 50meters x 50 meters.
>
> For that I've a raster map or a shape map and a fishnet at the good size,
> create with arcgis.
>
> And after that I just don't know what I've to do....
> Indeed, it's impossible for me to extract and analyse the cells one by one,
> so I hope on solution exist in R.
>
> Thank you very much for your Help.
>
> Best regards,
> Adrien
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From jaonyango at yahoo.com  Tue Jan 19 21:04:57 2016
From: jaonyango at yahoo.com (Joshua Onyango)
Date: Tue, 19 Jan 2016 20:04:57 +0000 (UTC)
Subject: [R-sig-Geo] Merging regions in a map & plotting values
References: <769679640.6001724.1453233897280.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <769679640.6001724.1453233897280.JavaMail.yahoo@mail.yahoo.com>

HelloI'm new into creating maps in R so any help would be great.I have read a few articles on the internet - mainly blogs on mapping in R which I have tried to follow with no much success. Basically I want to merge merge some English regions from 8 to 5 then show information that relates to disease prevalence, temperature etc
Here is what I have tried but sound like this cant run due to computer memory or must be doing following a wrong approach.?

?
> #Getting theshapefile into working directory

> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",

?????????????? destfile ="lad-region-lookup.zip")> #inzipping theshapefile folder

>unzip("lad-region-lookup.zip", exdir = ".")

> #reading theshapefile in r

> region <-readOGR(".", "England_gor_2011")

OGR data source withdriver: ESRI Shapefile 

Source:".", layer: "England_gor_2011"

with 9 features

It has 2 fields

> # Check theshapefile has loaded correctly

> plot(region)

> 

> lu <-data.frame()

> lu <-rbind(lu, region at data)

> lu$CODE <-as.character(lu$CODE)

> lu$NAME <-as.character(lu$NAME)

> lu$Region <-NA

> name=c("East", "South &S.E","North","North","Midlands","North","SouthWest","Midlands","South & S.E")

> lu$Region <-name

> # Merge lu(LookUp) into polygons,

> region at data$CODE<- as.character(region at data$CODE)

> region at data<- full_join(region at data, lu, by = "CODE")

> # Tidy mergeddata

> region at data<- select(region at data, -NAME.x)

>colnames(region at data) <- c("code", "name","Region")

> 

> # Ensureshapefile row.names and polygon IDs are sensible

>row.names(region) <- row.names(region at data)

> region <-spChFIDs(region, row.names(region))

> 

> # Now thedissolve

> region <-gUnaryUnion(region, id = region at data$Region)

> 

> # If you want torecreate an object with a data frame

> # make sure row namesmatch

>row.names(region) <- as.character(1:length(region))

> 

> # Extract thedata you want (the larger geography)

> lu <-unique(lu$Region)

> lu <-as.data.frame(lu)

> colnames(lu)<- "Region"? # your datawill probably have more than 1 row!

> 

> # And add thedata back in

> region <-SpatialPolygonsDataFrame(region, lu)

> region2 <-merge(region at data, data, by="Region")

> dat2=fortify(region,region="Region")

>names(dat2)[names(dat2)=="id"]<-"Region"

> dat <-merge(dat2, region2, by="Region")

Error: cannotallocate vector of size 904.9 Mb

In addition:Warning messages:

1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone), c(by.x,seq_len(ncx)[-by.x]),? :

? Reached total allocation of 4016Mb: seehelp(memory.size)


?

Any simpler approach will be highly appreciated.
Thanks
Josh
	[[alternative HTML version deleted]]


From bob at rudis.net  Wed Jan 20 02:48:51 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 19 Jan 2016 20:48:51 -0500
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <769679640.6001724.1453233897280.JavaMail.yahoo@mail.yahoo.com>
References: <769679640.6001724.1453233897280.JavaMail.yahoo.ref@mail.yahoo.com>
	<769679640.6001724.1453233897280.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJ4QxaPwAL1Mgqpvhf4j6c+xFTJSAs1smqtQ4wOqeUL=U-Smqw@mail.gmail.com>

I think this might help you out a bit (it's probably worth taking the
time to look it over as it removes much of the redundant code you
had).

library(sp)
library(maptools)
library(rgeos)
library(rgdal)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(ggalt)

URL <- "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
fil <- basename(URL)
if (!file.exists(fil)) download.file(URL, fil)

fils <- unzip(fil)
shp <- grep("shp$", fils, value=TRUE)

region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)

# define new regions
region at data$Region <- c("East", "South &S.E", "North", "North", "Midlands",
                        "North", "SouthWest", "Midlands", "South & S.E")
colnames(region at data) <- c("code", "name","Region")

# dissolve polygons and simplify the shapes
regions <- unionSpatialPolygons(region, region at data$Region)
regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
regions <- gBuffer(regions, byid=TRUE, width=0)

# coord_map and coord_proj will eventually work but this transformation
# will absolutely speed up the calculations

regions <- SpatialPolygonsDataFrame(spTransform(regions,
                                                CRS("+proj=longlat
+ellps=sphere +no_defs")),
                                    data.frame(Region=names(regions),
                                               row.names=names(regions),
                                               stringsAsFactors=FALSE))

eng_map <- fortify(regions, region="Region")

# new projection (good for the UK)
eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"

ggplot() +
  # base map
  geom_map(data=eng_map, map=eng_map,
           aes(x=long, y=lat, map_id=id),
           color=NA, fill=NA, size=0.5) +
  # sample fill of the regions
  geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
           aes(map_id=id, fill=id),
           color="white", size=0.15) +
  scale_fill_brewer(palette="Set2") +
  coord_proj(eng_proj) +
  theme_map()

NOTE: this requires the new ggplot2 (2.0)

On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
<r-sig-geo at r-project.org> wrote:
> HelloI'm new into creating maps in R so any help would be great.I have read a few articles on the internet - mainly blogs on mapping in R which I have tried to follow with no much success. Basically I want to merge merge some English regions from 8 to 5 then show information that relates to disease prevalence, temperature etc
> Here is what I have tried but sound like this cant run due to computer memory or must be doing following a wrong approach.
>
>
>> #Getting theshapefile into working directory
>
>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>
>                destfile ="lad-region-lookup.zip")> #inzipping theshapefile folder
>
>>unzip("lad-region-lookup.zip", exdir = ".")
>
>> #reading theshapefile in r
>
>> region <-readOGR(".", "England_gor_2011")
>
> OGR data source withdriver: ESRI Shapefile
>
> Source:".", layer: "England_gor_2011"
>
> with 9 features
>
> It has 2 fields
>
>> # Check theshapefile has loaded correctly
>
>> plot(region)
>
>>
>
>> lu <-data.frame()
>
>> lu <-rbind(lu, region at data)
>
>> lu$CODE <-as.character(lu$CODE)
>
>> lu$NAME <-as.character(lu$NAME)
>
>> lu$Region <-NA
>
>> name=c("East", "South &S.E","North","North","Midlands","North","SouthWest","Midlands","South & S.E")
>
>> lu$Region <-name
>
>> # Merge lu(LookUp) into polygons,
>
>> region at data$CODE<- as.character(region at data$CODE)
>
>> region at data<- full_join(region at data, lu, by = "CODE")
>
>> # Tidy mergeddata
>
>> region at data<- select(region at data, -NAME.x)
>
>>colnames(region at data) <- c("code", "name","Region")
>
>>
>
>> # Ensureshapefile row.names and polygon IDs are sensible
>
>>row.names(region) <- row.names(region at data)
>
>> region <-spChFIDs(region, row.names(region))
>
>>
>
>> # Now thedissolve
>
>> region <-gUnaryUnion(region, id = region at data$Region)
>
>>
>
>> # If you want torecreate an object with a data frame
>
>> # make sure row namesmatch
>
>>row.names(region) <- as.character(1:length(region))
>
>>
>
>> # Extract thedata you want (the larger geography)
>
>> lu <-unique(lu$Region)
>
>> lu <-as.data.frame(lu)
>
>> colnames(lu)<- "Region"  # your datawill probably have more than 1 row!
>
>>
>
>> # And add thedata back in
>
>> region <-SpatialPolygonsDataFrame(region, lu)
>
>> region2 <-merge(region at data, data, by="Region")
>
>> dat2=fortify(region,region="Region")
>
>>names(dat2)[names(dat2)=="id"]<-"Region"
>
>> dat <-merge(dat2, region2, by="Region")
>
> Error: cannotallocate vector of size 904.9 Mb
>
> In addition:Warning messages:
>
> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone), c(by.x,seq_len(ncx)[-by.x]),  :
>
>   Reached total allocation of 4016Mb: seehelp(memory.size)
>
>
>
>
> Any simpler approach will be highly appreciated.
> Thanks
> Josh
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From bob at rudis.net  Wed Jan 20 03:06:34 2016
From: bob at rudis.net (boB Rudis)
Date: Tue, 19 Jan 2016 21:06:34 -0500
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <CAJ4QxaPwAL1Mgqpvhf4j6c+xFTJSAs1smqtQ4wOqeUL=U-Smqw@mail.gmail.com>
References: <769679640.6001724.1453233897280.JavaMail.yahoo.ref@mail.yahoo.com>
	<769679640.6001724.1453233897280.JavaMail.yahoo@mail.yahoo.com>
	<CAJ4QxaPwAL1Mgqpvhf4j6c+xFTJSAs1smqtQ4wOqeUL=U-Smqw@mail.gmail.com>
Message-ID: <CAJ4QxaPBqhAk5j87hHT+keRxw7RU3UAN5YfKJgtb5AGqpMn2nw@mail.gmail.com>

(just noticed this)

You should probably fix the ""South &S.E" & ""South & S.E" (there's a
space missing in the former), too.

On Tue, Jan 19, 2016 at 8:48 PM, boB Rudis <bob at rudis.net> wrote:
> I think this might help you out a bit (it's probably worth taking the
> time to look it over as it removes much of the redundant code you
> had).
>
> library(sp)
> library(maptools)
> library(rgeos)
> library(rgdal)
> library(dplyr)
> library(ggplot2)
> library(ggthemes)
> library(ggalt)
>
> URL <- "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
> fil <- basename(URL)
> if (!file.exists(fil)) download.file(URL, fil)
>
> fils <- unzip(fil)
> shp <- grep("shp$", fils, value=TRUE)
>
> region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)
>
> # define new regions
> region at data$Region <- c("East", "South &S.E", "North", "North", "Midlands",
>                         "North", "SouthWest", "Midlands", "South & S.E")
> colnames(region at data) <- c("code", "name","Region")
>
> # dissolve polygons and simplify the shapes
> regions <- unionSpatialPolygons(region, region at data$Region)
> regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
> regions <- gBuffer(regions, byid=TRUE, width=0)
>
> # coord_map and coord_proj will eventually work but this transformation
> # will absolutely speed up the calculations
>
> regions <- SpatialPolygonsDataFrame(spTransform(regions,
>                                                 CRS("+proj=longlat
> +ellps=sphere +no_defs")),
>                                     data.frame(Region=names(regions),
>                                                row.names=names(regions),
>                                                stringsAsFactors=FALSE))
>
> eng_map <- fortify(regions, region="Region")
>
> # new projection (good for the UK)
> eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"
>
> ggplot() +
>   # base map
>   geom_map(data=eng_map, map=eng_map,
>            aes(x=long, y=lat, map_id=id),
>            color=NA, fill=NA, size=0.5) +
>   # sample fill of the regions
>   geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
>            aes(map_id=id, fill=id),
>            color="white", size=0.15) +
>   scale_fill_brewer(palette="Set2") +
>   coord_proj(eng_proj) +
>   theme_map()
>
> NOTE: this requires the new ggplot2 (2.0)
>
> On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
> <r-sig-geo at r-project.org> wrote:
>> HelloI'm new into creating maps in R so any help would be great.I have read a few articles on the internet - mainly blogs on mapping in R which I have tried to follow with no much success. Basically I want to merge merge some English regions from 8 to 5 then show information that relates to disease prevalence, temperature etc
>> Here is what I have tried but sound like this cant run due to computer memory or must be doing following a wrong approach.
>>
>>
>>> #Getting theshapefile into working directory
>>
>>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>>
>>                destfile ="lad-region-lookup.zip")> #inzipping theshapefile folder
>>
>>>unzip("lad-region-lookup.zip", exdir = ".")
>>
>>> #reading theshapefile in r
>>
>>> region <-readOGR(".", "England_gor_2011")
>>
>> OGR data source withdriver: ESRI Shapefile
>>
>> Source:".", layer: "England_gor_2011"
>>
>> with 9 features
>>
>> It has 2 fields
>>
>>> # Check theshapefile has loaded correctly
>>
>>> plot(region)
>>
>>>
>>
>>> lu <-data.frame()
>>
>>> lu <-rbind(lu, region at data)
>>
>>> lu$CODE <-as.character(lu$CODE)
>>
>>> lu$NAME <-as.character(lu$NAME)
>>
>>> lu$Region <-NA
>>
>>> name=c("East", "South &S.E","North","North","Midlands","North","SouthWest","Midlands","South & S.E")
>>
>>> lu$Region <-name
>>
>>> # Merge lu(LookUp) into polygons,
>>
>>> region at data$CODE<- as.character(region at data$CODE)
>>
>>> region at data<- full_join(region at data, lu, by = "CODE")
>>
>>> # Tidy mergeddata
>>
>>> region at data<- select(region at data, -NAME.x)
>>
>>>colnames(region at data) <- c("code", "name","Region")
>>
>>>
>>
>>> # Ensureshapefile row.names and polygon IDs are sensible
>>
>>>row.names(region) <- row.names(region at data)
>>
>>> region <-spChFIDs(region, row.names(region))
>>
>>>
>>
>>> # Now thedissolve
>>
>>> region <-gUnaryUnion(region, id = region at data$Region)
>>
>>>
>>
>>> # If you want torecreate an object with a data frame
>>
>>> # make sure row namesmatch
>>
>>>row.names(region) <- as.character(1:length(region))
>>
>>>
>>
>>> # Extract thedata you want (the larger geography)
>>
>>> lu <-unique(lu$Region)
>>
>>> lu <-as.data.frame(lu)
>>
>>> colnames(lu)<- "Region"  # your datawill probably have more than 1 row!
>>
>>>
>>
>>> # And add thedata back in
>>
>>> region <-SpatialPolygonsDataFrame(region, lu)
>>
>>> region2 <-merge(region at data, data, by="Region")
>>
>>> dat2=fortify(region,region="Region")
>>
>>>names(dat2)[names(dat2)=="id"]<-"Region"
>>
>>> dat <-merge(dat2, region2, by="Region")
>>
>> Error: cannotallocate vector of size 904.9 Mb
>>
>> In addition:Warning messages:
>>
>> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone), c(by.x,seq_len(ncx)[-by.x]),  :
>>
>>   Reached total allocation of 4016Mb: seehelp(memory.size)
>>
>>
>>
>>
>> Any simpler approach will be highly appreciated.
>> Thanks
>> Josh
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mdsumner at gmail.com  Wed Jan 20 06:22:35 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 20 Jan 2016 05:22:35 +0000
Subject: [R-sig-Geo] raster package and tiling schemes
Message-ID: <CAAcGz9-G5q2UPZP2EUMPUOMhH1FrsW2KyFtV1SpEzXv0wSu4qQ@mail.gmail.com>

Hi there, does raster or any related package have any built-in  schemes
that allow for easy management of tiles?

Raster itself provides a very powerful platform for building such a scheme,
since we can reasonably easily reclassify analogous RasterLayers at
different resolutions, and map cell values from one raster to another -
being careful with tile overlaps and alignment of course.

Anyone working on such a thing already, or got any grand plans?

I know rgdal and friends provide access to the GDAL tools in various ways,
but I want something in R only.

Cheers, Mike
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Wed Jan 20 13:05:50 2016
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 20 Jan 2016 13:05:50 +0100
Subject: [R-sig-Geo] overlap between HR and polygon (adehabitat)
Message-ID: <CALC46t_NZ36G3A0xq0Eoto85cuBcck6=6ypMGhDg=Xjt8PHChg@mail.gmail.com>

Hello.
I'm estimating some home ranges using the kernelUD function in adehabitatHR.
For each individual, I want to estimate the degree of overlap between the
home range (kernel 95%) and a SpatialPolygonsDataFrame which corresponds to
a protected area. Basically I want to know the degree of protection of each
animal.

Is this something I can do in adehabitatHR as well?

Thank you

David

	[[alternative HTML version deleted]]


From roman.lustrik at gmail.com  Wed Jan 20 13:44:41 2016
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Wed, 20 Jan 2016 13:44:41 +0100
Subject: [R-sig-Geo] overlap between HR and polygon (adehabitat)
In-Reply-To: <CALC46t_NZ36G3A0xq0Eoto85cuBcck6=6ypMGhDg=Xjt8PHChg@mail.gmail.com>
References: <CALC46t_NZ36G3A0xq0Eoto85cuBcck6=6ypMGhDg=Xjt8PHChg@mail.gmail.com>
Message-ID: <CAHT1vpgUonosPv-NDq5c2HM3CogFc7oNpEg8oFStXT05umwkEQ@mail.gmail.com>

If I understand your question, you are after functionality of `rgeos`
package. You can calculate the intersection (gIntersection) between the two
areas and calculate area using `gArea`.

Cheers,
Roman

On Wed, Jan 20, 2016 at 1:05 PM, David Villegas R?os <chirleu at gmail.com>
wrote:

> Hello.
> I'm estimating some home ranges using the kernelUD function in
> adehabitatHR.
> For each individual, I want to estimate the degree of overlap between the
> home range (kernel 95%) and a SpatialPolygonsDataFrame which corresponds to
> a protected area. Basically I want to know the degree of protection of each
> animal.
>
> Is this something I can do in adehabitatHR as well?
>
> Thank you
>
> David
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
In God we trust, all others bring data.

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Wed Jan 20 14:09:36 2016
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Wed, 20 Jan 2016 14:09:36 +0100
Subject: [R-sig-Geo] overlap between HR and polygon (adehabitat)
In-Reply-To: <CAHT1vpgUonosPv-NDq5c2HM3CogFc7oNpEg8oFStXT05umwkEQ@mail.gmail.com>
References: <CALC46t_NZ36G3A0xq0Eoto85cuBcck6=6ypMGhDg=Xjt8PHChg@mail.gmail.com>
	<CAHT1vpgUonosPv-NDq5c2HM3CogFc7oNpEg8oFStXT05umwkEQ@mail.gmail.com>
Message-ID: <CALC46t8diDswVsQLitm70=sxKJc=FHnN6Oem8euGJUaj3dCd_w@mail.gmail.com>

This is what I was looking for, thanks Roman!

David

2016-01-20 13:44 GMT+01:00 Roman Lu?trik <roman.lustrik at gmail.com>:

> If I understand your question, you are after functionality of `rgeos`
> package. You can calculate the intersection (gIntersection) between the two
> areas and calculate area using `gArea`.
>
> Cheers,
> Roman
>
> On Wed, Jan 20, 2016 at 1:05 PM, David Villegas R?os <chirleu at gmail.com>
> wrote:
>
>> Hello.
>> I'm estimating some home ranges using the kernelUD function in
>> adehabitatHR.
>> For each individual, I want to estimate the degree of overlap between the
>> home range (kernel 95%) and a SpatialPolygonsDataFrame which corresponds
>> to
>> a protected area. Basically I want to know the degree of protection of
>> each
>> animal.
>>
>> Is this something I can do in adehabitatHR as well?
>>
>> Thank you
>>
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
> In God we trust, all others bring data.
>

	[[alternative HTML version deleted]]


From jaonyango at yahoo.com  Wed Jan 20 15:27:50 2016
From: jaonyango at yahoo.com (Joshua Onyango)
Date: Wed, 20 Jan 2016 14:27:50 +0000 (UTC)
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <CAJ4QxaPBqhAk5j87hHT+keRxw7RU3UAN5YfKJgtb5AGqpMn2nw@mail.gmail.com>
References: <CAJ4QxaPBqhAk5j87hHT+keRxw7RU3UAN5YfKJgtb5AGqpMn2nw@mail.gmail.com>
Message-ID: <1467885196.4794107.1453300070621.JavaMail.yahoo@mail.yahoo.com>

Thanks Bob for the guidelines.
Josh 

    On Wednesday, 20 January 2016, 2:06, boB Rudis <bob at rudis.net> wrote:
 

 (just noticed this)

You should probably fix the ""South &S.E" & ""South & S.E" (there's a
space missing in the former), too.

On Tue, Jan 19, 2016 at 8:48 PM, boB Rudis <bob at rudis.net> wrote:
> I think this might help you out a bit (it's probably worth taking the
> time to look it over as it removes much of the redundant code you
> had).
>
> library(sp)
> library(maptools)
> library(rgeos)
> library(rgdal)
> library(dplyr)
> library(ggplot2)
> library(ggthemes)
> library(ggalt)
>
> URL <- "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
> fil <- basename(URL)
> if (!file.exists(fil)) download.file(URL, fil)
>
> fils <- unzip(fil)
> shp <- grep("shp$", fils, value=TRUE)
>
> region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)
>
> # define new regions
> region at data$Region <- c("East", "South &S.E", "North", "North", "Midlands",
>? ? ? ? ? ? ? ? ? ? ? ? "North", "SouthWest", "Midlands", "South & S.E")
> colnames(region at data) <- c("code", "name","Region")
>
> # dissolve polygons and simplify the shapes
> regions <- unionSpatialPolygons(region, region at data$Region)
> regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
> regions <- gBuffer(regions, byid=TRUE, width=0)
>
> # coord_map and coord_proj will eventually work but this transformation
> # will absolutely speed up the calculations
>
> regions <- SpatialPolygonsDataFrame(spTransform(regions,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? CRS("+proj=longlat
> +ellps=sphere +no_defs")),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? data.frame(Region=names(regions),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? row.names=names(regions),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? stringsAsFactors=FALSE))
>
> eng_map <- fortify(regions, region="Region")
>
> # new projection (good for the UK)
> eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"
>
> ggplot() +
>? # base map
>? geom_map(data=eng_map, map=eng_map,
>? ? ? ? ? ? aes(x=long, y=lat, map_id=id),
>? ? ? ? ? ? color=NA, fill=NA, size=0.5) +
>? # sample fill of the regions
>? geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
>? ? ? ? ? ? aes(map_id=id, fill=id),
>? ? ? ? ? ? color="white", size=0.15) +
>? scale_fill_brewer(palette="Set2") +
>? coord_proj(eng_proj) +
>? theme_map()
>
> NOTE: this requires the new ggplot2 (2.0)
>
> On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
> <r-sig-geo at r-project.org> wrote:
>> HelloI'm new into creating maps in R so any help would be great.I have read a few articles on the internet - mainly blogs on mapping in R which I have tried to follow with no much success. Basically I want to merge merge some English regions from 8 to 5 then show information that relates to disease prevalence, temperature etc
>> Here is what I have tried but sound like this cant run due to computer memory or must be doing following a wrong approach.
>>
>>
>>> #Getting theshapefile into working directory
>>
>>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>>
>>? ? ? ? ? ? ? ? destfile ="lad-region-lookup.zip")> #inzipping theshapefile folder
>>
>>>unzip("lad-region-lookup.zip", exdir = ".")
>>
>>> #reading theshapefile in r
>>
>>> region <-readOGR(".", "England_gor_2011")
>>
>> OGR data source withdriver: ESRI Shapefile
>>
>> Source:".", layer: "England_gor_2011"
>>
>> with 9 features
>>
>> It has 2 fields
>>
>>> # Check theshapefile has loaded correctly
>>
>>> plot(region)
>>
>>>
>>
>>> lu <-data.frame()
>>
>>> lu <-rbind(lu, region at data)
>>
>>> lu$CODE <-as.character(lu$CODE)
>>
>>> lu$NAME <-as.character(lu$NAME)
>>
>>> lu$Region <-NA
>>
>>> name=c("East", "South &S.E","North","North","Midlands","North","SouthWest","Midlands","South & S.E")
>>
>>> lu$Region <-name
>>
>>> # Merge lu(LookUp) into polygons,
>>
>>> region at data$CODE<- as.character(region at data$CODE)
>>
>>> region at data<- full_join(region at data, lu, by = "CODE")
>>
>>> # Tidy mergeddata
>>
>>> region at data<- select(region at data, -NAME.x)
>>
>>>colnames(region at data) <- c("code", "name","Region")
>>
>>>
>>
>>> # Ensureshapefile row.names and polygon IDs are sensible
>>
>>>row.names(region) <- row.names(region at data)
>>
>>> region <-spChFIDs(region, row.names(region))
>>
>>>
>>
>>> # Now thedissolve
>>
>>> region <-gUnaryUnion(region, id = region at data$Region)
>>
>>>
>>
>>> # If you want torecreate an object with a data frame
>>
>>> # make sure row namesmatch
>>
>>>row.names(region) <- as.character(1:length(region))
>>
>>>
>>
>>> # Extract thedata you want (the larger geography)
>>
>>> lu <-unique(lu$Region)
>>
>>> lu <-as.data.frame(lu)
>>
>>> colnames(lu)<- "Region"? # your datawill probably have more than 1 row!
>>
>>>
>>
>>> # And add thedata back in
>>
>>> region <-SpatialPolygonsDataFrame(region, lu)
>>
>>> region2 <-merge(region at data, data, by="Region")
>>
>>> dat2=fortify(region,region="Region")
>>
>>>names(dat2)[names(dat2)=="id"]<-"Region"
>>
>>> dat <-merge(dat2, region2, by="Region")
>>
>> Error: cannotallocate vector of size 904.9 Mb
>>
>> In addition:Warning messages:
>>
>> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone), c(by.x,seq_len(ncx)[-by.x]),? :
>>
>>? Reached total allocation of 4016Mb: seehelp(memory.size)
>>
>>
>>
>>
>> Any simpler approach will be highly appreciated.
>> Thanks
>> Josh
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

  
	[[alternative HTML version deleted]]


From konno_kazuma at mailplus.pl  Wed Jan 20 15:42:22 2016
From: konno_kazuma at mailplus.pl (=?UTF-8?Q?Kamil_Konowalik?=)
Date: Wed, 20 Jan 2016 15:42:22 +0100
Subject: [R-sig-Geo]
	=?utf-8?q?How_to_speed_up_=22extract=22_function_in_r?=
	=?utf-8?q?aster_package=3F?=
In-Reply-To: <CAAcGz99CZBYRko1E1XML5ZuozaLEZXgJtgxcDvW3n0SDxj0+7g@mail.gmail.com>
References: <263e2fa4.5a497f73.569cc653.8e3b4@mailplus.pl>
	<CAAcGz99CZBYRko1E1XML5ZuozaLEZXgJtgxcDvW3n0SDxj0+7g@mail.gmail.com>
Message-ID: <469c51b.1a5163a8.569f9cce.bb8c6@mailplus.pl>

 Normal 0 21 false false false PL X-NONE X-NONE MicrosoftInternetExplorer4 Hi,thank's Mike and Steve. My rasters were covering whole Europe and each of 19 ASCII files was about 200 MB (ncols 8710, nrows 4754).However when I wanted to quit those very long calculations this morning and try to make it differently - I noticed that apparently they were finished during the night after 13 days... So now I will proceed with my data and when I will have to run this procedure again (and I will have to) I will use your suggestions definitely. 
Best wishes,
Kamil /* Style Definitions */ table.MsoNormalTable{mso-style-name:Standardowy;mso-tstyle-rowband-size:0;mso-tstyle-colband-size:0;mso-style-noshow:yes;mso-style-priority:99;mso-style-qformat:yes;mso-style-parent:"";mso-padding-alt:0cm 5.4pt 0cm 5.4pt;mso-para-margin:0cm;mso-para-margin-bottom:.0001pt;line-height:150%;mso-pagination:widow-orphan;font-size:11.0pt;font-family:"Calibri","sans-serif";mso-ascii-font-family:Calibri;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-fareast-theme-font:minor-fareast;mso-hansi-font-family:Calibri;mso-hansi-theme-font:minor-latin;}
Dnia 18 stycznia 2016 21:59 Michael Sumner &lt;mdsumner at gmail.com&gt; napisa?(a):
On Mon, 18 Jan 2016 at 22:03 Kamil Konowalik &lt;konno_kazuma at mailplus.pl&gt; wrote:Dear list members,
I'm trying to extract values for ca. 1000 points from 19 raster files. It is a very simple task - as an output I need a table where each point has additional 19 columns with values derived from those raster files (specifically I'm creating a SWD input file for Maxent). I used extract function but the whole task is running very slow - so far the whole process took 10 days and it is not finished yet. My computer is rather slow (Windows 7 32 bit, intel core duo 2.2 GHz, 3 GB RAM) but currently I need to use this machine. I was wondering whether there is a way to speed up the whole process by using a different command or maybe there is any trick that can speed it up?
Here's the code I'm using:
files &lt;- list.files("C:/GIS/worldclim/biolcimatic_variables_ASCII",pattern='asc',full.names=TRUE)
Grids &lt;- raster::stack(files)
background &lt;- read.csv("C:/GIS/species_background/bg.csv",header=TRUE)
LonLatData2 &lt;- background[,c(2,3)]
var_at_background &lt;- raster::extract(Grids,LonLatData2) #I'm here since 10 days
outfile2 &lt;- as.data.frame(cbind("species",LonLatData2,var_at_background))
colnames(outfile2) &lt;- c("species","longitude","latitude",colnames(var_at_background))
write.csv(outfile2, file="variables_background.csv", append = FALSE, sep = ",", eol = "\n", na = "NA", dec = ".", col.names = TRUE, row.names = FALSE)
???Probably the best thing to do is get you data out of those .asc files and into something more sensible, like raster's native .grd format. Please let us know the dimensions of your raster, the print-out of??Grids??would suffice. Otherwise, try this??files &lt;- list.files("C:/GIS/worldclim/biolcimatic_variables_ASCII",pattern='asc',full.names=TRUE)Grids0 &lt;- raster::stack(files)Grids &lt;- writeRaster(Grids0, "native.grd") ## best if you can put it on a different physical disk## Grids &lt;- writeRaster(Grids0, "D:/some/where/native.grd")??## then, proceed as you were??background &lt;- read.csv("C:/GIS/species_background/bg.csv",header=TRUE)LonLatData2 &lt;- background[,c(2,3)]var_at_background &lt;- raster::extract(Grids,LonLatData2) #I'm here since 10 days???I include an option to write out to a different physical disk, you should really do that if you can - if your read and write to the same disk one process has to wait for the other. Also, if your data can just fit in memory that would be the fastest all out. ???ASC is possibly the worst format to you use for data like these, it's text, it's bloated, has insufficient metadata, can't be tiled or compressed internally and really there's no excuse these days.???Neither of these apply to your situation, but if you have to do a lot of this kind of stuff, note that extract on a single-layer Brick can be much faster than on a RasterLayer - I don't know why yet, and extract() is also not suited to internally tiled rasters (common to GeoTIFF) since it scans line by line which is inefficient when the thing is tiled. .???Cheers, Mike.?????I started to use R relatively recently so excuse me if there is something that I missed here but I was searching for an answer without any success.
Best regards,
Kamil
Wroc?aw University of Environmental and Life Sciences, Poland
_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo--Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From tech_dev at wildintellect.com  Wed Jan 20 18:00:31 2016
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Wed, 20 Jan 2016 09:00:31 -0800
Subject: [R-sig-Geo] raster package and tiling schemes
In-Reply-To: <CAAcGz9-G5q2UPZP2EUMPUOMhH1FrsW2KyFtV1SpEzXv0wSu4qQ@mail.gmail.com>
References: <CAAcGz9-G5q2UPZP2EUMPUOMhH1FrsW2KyFtV1SpEzXv0wSu4qQ@mail.gmail.com>
Message-ID: <569FBD2F.3060801@wildintellect.com>

On 01/19/2016 09:22 PM, Michael Sumner wrote:
> Hi there, does raster or any related package have any built-in  schemes
> that allow for easy management of tiles?
> 
> Raster itself provides a very powerful platform for building such a scheme,
> since we can reasonably easily reclassify analogous RasterLayers at
> different resolutions, and map cell values from one raster to another -
> being careful with tile overlaps and alignment of course.
> 
> Anyone working on such a thing already, or got any grand plans?
> 
> I know rgdal and friends provide access to the GDAL tools in various ways,
> but I want something in R only.
> 
> Cheers, Mike
> 


What's the goal of tiling? And when you say tiles do you mean multiple
zoom levels like web tiles, or more a raster catalog like a VRT of
multiple rasters next to each other?

If you mean zoom levels, things like pyramids in tiffs are local
equivalent but that's only for viewing data, not really useful for analysis.

If you mean things that are adjacent to each other, I would assume that
if they aren't all the same resolution/scale then you need to go to the
lowest common denominator and resample everything to that to get a
seamless data set. In this case the Raster merge and mosaic functions.
Though if you want to keep the files in pieces, save them all out into
the same resolution/scale, clipped to no longer have overlap, and
gdal_buildvrt.

Or am I missing the point?

-Alex


From jaonyango at yahoo.com  Wed Jan 20 19:55:09 2016
From: jaonyango at yahoo.com (Joshua Onyango)
Date: Wed, 20 Jan 2016 18:55:09 +0000 (UTC)
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <CAJ4QxaPwAL1Mgqpvhf4j6c+xFTJSAs1smqtQ4wOqeUL=U-Smqw@mail.gmail.com>
References: <CAJ4QxaPwAL1Mgqpvhf4j6c+xFTJSAs1smqtQ4wOqeUL=U-Smqw@mail.gmail.com>
Message-ID: <1054731968.6525138.1453316109921.JavaMail.yahoo@mail.yahoo.com>

Hi Bob
Thanks for the help, merging region appear to work now. ?However still stuck on the other bit on merging data with spatial object, ("regions") in this case to be able to plot the data points. I mainly want to plot information such as % disease prevalence in every region, temperature, flock size etc
Thanks advance
Josh 

    On Wednesday, 20 January 2016, 1:49, boB Rudis <bob at rudis.net> wrote:
 

 I think this might help you out a bit (it's probably worth taking the
time to look it over as it removes much of the redundant code you
had).

library(sp)
library(maptools)
library(rgeos)
library(rgdal)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(ggalt)

URL <- "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
fil <- basename(URL)
if (!file.exists(fil)) download.file(URL, fil)

fils <- unzip(fil)
shp <- grep("shp$", fils, value=TRUE)

region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)

# define new regions
region at data$Region <- c("East", "South &S.E", "North", "North", "Midlands",
? ? ? ? ? ? ? ? ? ? ? ? "North", "SouthWest", "Midlands", "South & S.E")
colnames(region at data) <- c("code", "name","Region")

# dissolve polygons and simplify the shapes
regions <- unionSpatialPolygons(region, region at data$Region)
regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
regions <- gBuffer(regions, byid=TRUE, width=0)

# coord_map and coord_proj will eventually work but this transformation
# will absolutely speed up the calculations

regions <- SpatialPolygonsDataFrame(spTransform(regions,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? CRS("+proj=longlat
+ellps=sphere +no_defs")),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? data.frame(Region=names(regions),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? row.names=names(regions),
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? stringsAsFactors=FALSE))

eng_map <- fortify(regions, region="Region")

# new projection (good for the UK)
eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"

ggplot() +
? # base map
? geom_map(data=eng_map, map=eng_map,
? ? ? ? ? aes(x=long, y=lat, map_id=id),
? ? ? ? ? color=NA, fill=NA, size=0.5) +
? # sample fill of the regions
? geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
? ? ? ? ? aes(map_id=id, fill=id),
? ? ? ? ? color="white", size=0.15) +
? scale_fill_brewer(palette="Set2") +
? coord_proj(eng_proj) +
? theme_map()

NOTE: this requires the new ggplot2 (2.0)

On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
<r-sig-geo at r-project.org> wrote:
> HelloI'm new into creating maps in R so any help would be great.I have read a few articles on the internet - mainly blogs on mapping in R which I have tried to follow with no much success. Basically I want to merge merge some English regions from 8 to 5 then show information that relates to disease prevalence, temperature etc
> Here is what I have tried but sound like this cant run due to computer memory or must be doing following a wrong approach.
>
>
>> #Getting theshapefile into working directory
>
>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>
>? ? ? ? ? ? ? ? destfile ="lad-region-lookup.zip")> #inzipping theshapefile folder
>
>>unzip("lad-region-lookup.zip", exdir = ".")
>
>> #reading theshapefile in r
>
>> region <-readOGR(".", "England_gor_2011")
>
> OGR data source withdriver: ESRI Shapefile
>
> Source:".", layer: "England_gor_2011"
>
> with 9 features
>
> It has 2 fields
>
>> # Check theshapefile has loaded correctly
>
>> plot(region)
>
>>
>
>> lu <-data.frame()
>
>> lu <-rbind(lu, region at data)
>
>> lu$CODE <-as.character(lu$CODE)
>
>> lu$NAME <-as.character(lu$NAME)
>
>> lu$Region <-NA
>
>> name=c("East", "South &S.E","North","North","Midlands","North","SouthWest","Midlands","South & S.E")
>
>> lu$Region <-name
>
>> # Merge lu(LookUp) into polygons,
>
>> region at data$CODE<- as.character(region at data$CODE)
>
>> region at data<- full_join(region at data, lu, by = "CODE")
>
>> # Tidy mergeddata
>
>> region at data<- select(region at data, -NAME.x)
>
>>colnames(region at data) <- c("code", "name","Region")
>
>>
>
>> # Ensureshapefile row.names and polygon IDs are sensible
>
>>row.names(region) <- row.names(region at data)
>
>> region <-spChFIDs(region, row.names(region))
>
>>
>
>> # Now thedissolve
>
>> region <-gUnaryUnion(region, id = region at data$Region)
>
>>
>
>> # If you want torecreate an object with a data frame
>
>> # make sure row namesmatch
>
>>row.names(region) <- as.character(1:length(region))
>
>>
>
>> # Extract thedata you want (the larger geography)
>
>> lu <-unique(lu$Region)
>
>> lu <-as.data.frame(lu)
>
>> colnames(lu)<- "Region"? # your datawill probably have more than 1 row!
>
>>
>
>> # And add thedata back in
>
>> region <-SpatialPolygonsDataFrame(region, lu)
>
>> region2 <-merge(region at data, data, by="Region")
>
>> dat2=fortify(region,region="Region")
>
>>names(dat2)[names(dat2)=="id"]<-"Region"
>
>> dat <-merge(dat2, region2, by="Region")
>
> Error: cannotallocate vector of size 904.9 Mb
>
> In addition:Warning messages:
>
> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone), c(by.x,seq_len(ncx)[-by.x]),? :
>
>? Reached total allocation of 4016Mb: seehelp(memory.size)
>
>
>
>
> Any simpler approach will be highly appreciated.
> Thanks
> Josh
>? ? ? ? [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

  
	[[alternative HTML version deleted]]


From bob at rudis.net  Wed Jan 20 20:14:09 2016
From: bob at rudis.net (boB Rudis)
Date: Wed, 20 Jan 2016 14:14:09 -0500
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <1054731968.6525138.1453316109921.JavaMail.yahoo@mail.yahoo.com>
References: <CAJ4QxaPwAL1Mgqpvhf4j6c+xFTJSAs1smqtQ4wOqeUL=U-Smqw@mail.gmail.com>
	<1054731968.6525138.1453316109921.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJ4QxaMh=cKbz=6HiByUpeHQqG-79J0q9wfMYSeLprMPrBVUtA@mail.gmail.com>

That's actually why I did the second `geom_map` the way I did. Add
another column to that data frame and use it for the fill color
(preferably using `cut` to bin values  ahead of time as it's unlikey
you really want to use a continuous color palette.

On Wed, Jan 20, 2016 at 1:55 PM, Joshua Onyango <jaonyango at yahoo.com> wrote:
> Hi Bob
>
> Thanks for the help, merging region appear to work now.  However still stuck
> on the other bit on merging data with spatial object, ("regions") in this
> case to be able to plot the data points. I mainly want to plot information
> such as % disease prevalence in every region, temperature, flock size etc
>
> Thanks advance
>
> Josh
>
>
> On Wednesday, 20 January 2016, 1:49, boB Rudis <bob at rudis.net> wrote:
>
>
> I think this might help you out a bit (it's probably worth taking the
> time to look it over as it removes much of the redundant code you
> had).
>
> library(sp)
> library(maptools)
> library(rgeos)
> library(rgdal)
> library(dplyr)
> library(ggplot2)
> library(ggthemes)
> library(ggalt)
>
> URL <-
> "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
> fil <- basename(URL)
> if (!file.exists(fil)) download.file(URL, fil)
>
> fils <- unzip(fil)
> shp <- grep("shp$", fils, value=TRUE)
>
> region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)
>
> # define new regions
> region at data$Region <- c("East", "South &S.E", "North", "North", "Midlands",
>                         "North", "SouthWest", "Midlands", "South & S.E")
> colnames(region at data) <- c("code", "name","Region")
>
> # dissolve polygons and simplify the shapes
> regions <- unionSpatialPolygons(region, region at data$Region)
> regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
> regions <- gBuffer(regions, byid=TRUE, width=0)
>
> # coord_map and coord_proj will eventually work but this transformation
> # will absolutely speed up the calculations
>
> regions <- SpatialPolygonsDataFrame(spTransform(regions,
>                                                 CRS("+proj=longlat
> +ellps=sphere +no_defs")),
>                                     data.frame(Region=names(regions),
>                                               row.names=names(regions),
>                                               stringsAsFactors=FALSE))
>
> eng_map <- fortify(regions, region="Region")
>
> # new projection (good for the UK)
> eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"
>
> ggplot() +
>   # base map
>   geom_map(data=eng_map, map=eng_map,
>           aes(x=long, y=lat, map_id=id),
>           color=NA, fill=NA, size=0.5) +
>   # sample fill of the regions
>   geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
>           aes(map_id=id, fill=id),
>           color="white", size=0.15) +
>   scale_fill_brewer(palette="Set2") +
>   coord_proj(eng_proj) +
>   theme_map()
>
> NOTE: this requires the new ggplot2 (2.0)
>
> On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
> <r-sig-geo at r-project.org> wrote:
>> HelloI'm new into creating maps in R so any help would be great.I have
>> read a few articles on the internet - mainly blogs on mapping in R which I
>> have tried to follow with no much success. Basically I want to merge merge
>> some English regions from 8 to 5 then show information that relates to
>> disease prevalence, temperature etc
>> Here is what I have tried but sound like this cant run due to computer
>> memory or must be doing following a wrong approach.
>>
>>
>>> #Getting theshapefile into working directory
>>
>>>
>>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>>
>>                destfile ="lad-region-lookup.zip")> #inzipping theshapefile
>> folder
>>
>>>unzip("lad-region-lookup.zip", exdir = ".")
>>
>>> #reading theshapefile in r
>>
>>> region <-readOGR(".", "England_gor_2011")
>>
>> OGR data source withdriver: ESRI Shapefile
>>
>> Source:".", layer: "England_gor_2011"
>>
>> with 9 features
>>
>> It has 2 fields
>>
>>> # Check theshapefile has loaded correctly
>>
>>> plot(region)
>>
>>>
>>
>>> lu <-data.frame()
>>
>>> lu <-rbind(lu, region at data)
>>
>>> lu$CODE <-as.character(lu$CODE)
>>
>>> lu$NAME <-as.character(lu$NAME)
>>
>>> lu$Region <-NA
>>
>>> name=c("East", "South
>>> &S.E","North","North","Midlands","North","SouthWest","Midlands","South &
>>> S.E")
>>
>>> lu$Region <-name
>>
>>> # Merge lu(LookUp) into polygons,
>>
>>> region at data$CODE<- as.character(region at data$CODE)
>>
>>> region at data<- full_join(region at data, lu, by = "CODE")
>>
>>> # Tidy mergeddata
>>
>>> region at data<- select(region at data, -NAME.x)
>>
>>>colnames(region at data) <- c("code", "name","Region")
>>
>>>
>>
>>> # Ensureshapefile row.names and polygon IDs are sensible
>>
>>>row.names(region) <- row.names(region at data)
>>
>>> region <-spChFIDs(region, row.names(region))
>>
>>>
>>
>>> # Now thedissolve
>>
>>> region <-gUnaryUnion(region, id = region at data$Region)
>>
>>>
>>
>>> # If you want torecreate an object with a data frame
>>
>>> # make sure row namesmatch
>>
>>>row.names(region) <- as.character(1:length(region))
>>
>>>
>>
>>> # Extract thedata you want (the larger geography)
>>
>>> lu <-unique(lu$Region)
>>
>>> lu <-as.data.frame(lu)
>>
>>> colnames(lu)<- "Region"  # your datawill probably have more than 1 row!
>>
>>>
>>
>>> # And add thedata back in
>>
>>> region <-SpatialPolygonsDataFrame(region, lu)
>>
>>> region2 <-merge(region at data, data, by="Region")
>>
>>> dat2=fortify(region,region="Region")
>>
>>>names(dat2)[names(dat2)=="id"]<-"Region"
>>
>>> dat <-merge(dat2, region2, by="Region")
>>
>> Error: cannotallocate vector of size 904.9 Mb
>>
>> In addition:Warning messages:
>>
>> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone),
>> c(by.x,seq_len(ncx)[-by.x]),  :
>>
>>  Reached total allocation of 4016Mb: seehelp(memory.size)
>>
>>
>>
>>
>> Any simpler approach will be highly appreciated.
>> Thanks
>> Josh
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


From mathieu.rajerison at gmail.com  Thu Jan 21 13:58:32 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 21 Jan 2016 13:58:32 +0100
Subject: [R-sig-Geo] =?utf-8?q?RStoolbox_loading=2C_Rscript=2C_printing_an?=
	=?utf-8?b?ZCBlIGFjdXRlICjDqSk=?=
Message-ID: <CAGfc75kY+6RS1cE=6KM77f86iCU5XVcMh=k=dvnBn2LLm=TTFg@mail.gmail.com>

Hi,

This post is not spatially-oriented but deals with an excellent spatial R
package named RStoobox for remote sensing.

I have a process that prints advancement operations with cat() functions.
Some contain e acute as it is for french administrations.

I noticed I had problems with the writing of e acutes after loading
RStoolbox package. I noticed the same with igraph as well

If I write an R file with the following lines :

cat("first \U00E9")
require("RStoolbox")
cat(" second \U00E9")

It gives

first ?
second ?

If I load another package like raster, the problem doesn't appear.

To see if there was any change relative to encodings, I wrote an R file
with the following lines which gives the system encoding before and after :

cat("first \U00E9 \n")
cat("--before--\n")
cat(paste("encoding = ", getOption("encoding"), "\n"))
cat(paste("locale = ", Sys.getlocale(), "\n"))
# suppressMessages(suppressWarnings(require("RStoolbox", quietly = TRUE)))
# provoque erreurs accent e aigu
require("RStoolbox")
cat("\n")
cat("--after--\n")
cat(paste("encoding = ", getOption("encoding"),"\n"))
cat(paste("locale = ", Sys.getlocale(), "\n"))
cat(" second \U00E9")

But there isn't any change :

first ?
--before--
encoding =  native.enc
locale =
 LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=
French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
Le chargement a n?cessit? le package : RStoolbox
Message d'avis :
le package 'RStoolbox' a ?t? compil? avec la version R 3.1.3

--after--
encoding =  native.enc
locale =
 LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=
French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
 second ?

So, i wonder where does this come from ? And how to deal with it

Thanks in advance for your answers,

Mathieu

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Jan 21 15:02:28 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 21 Jan 2016 14:02:28 +0000
Subject: [R-sig-Geo] raster package and tiling schemes
In-Reply-To: <569FBD2F.3060801@wildintellect.com>
References: <CAAcGz9-G5q2UPZP2EUMPUOMhH1FrsW2KyFtV1SpEzXv0wSu4qQ@mail.gmail.com>
	<569FBD2F.3060801@wildintellect.com>
Message-ID: <CAAcGz9-i6pX5xDJPp6J_s=-JGTVHVisx-Y_XVgxhm1_+BO0kEQ@mail.gmail.com>

On Thu, 21 Jan 2016 at 04:00 Alex Mandel <tech_dev at wildintellect.com> wrote:

> On 01/19/2016 09:22 PM, Michael Sumner wrote:
> > Hi there, does raster or any related package have any built-in  schemes
> > that allow for easy management of tiles?
> >
> > Raster itself provides a very powerful platform for building such a
> scheme,
> > since we can reasonably easily reclassify analogous RasterLayers at
> > different resolutions, and map cell values from one raster to another -
> > being careful with tile overlaps and alignment of course.
> >
> > Anyone working on such a thing already, or got any grand plans?
> >
> > I know rgdal and friends provide access to the GDAL tools in various
> ways,
> > but I want something in R only.
> >
> > Cheers, Mike
> >
>
>
> What's the goal of tiling? And when you say tiles do you mean multiple
> zoom levels like web tiles, or more a raster catalog like a VRT of
> multiple rasters next to each other?
>
> If you mean zoom levels, things like pyramids in tiffs are local
> equivalent but that's only for viewing data, not really useful for
> analysis.
>
> If you mean things that are adjacent to each other, I would assume that
> if they aren't all the same resolution/scale then you need to go to the
> lowest common denominator and resample everything to that to get a
> seamless data set. In this case the Raster merge and mosaic functions.
> Though if you want to keep the files in pieces, save them all out into
> the same resolution/scale, clipped to no longer have overlap, and
> gdal_buildvrt.
>
> Or am I missing the point?
>
>
Thanks Alex, these are good questions. I just want to be able to do it
arbitrarily for lots of reasons, but right now I want to tile up some
global data sets and allow my code to access them from a website at
different resolutions.

Basic stuff. Stuff that should be basic and on hand. The machinery behind
raster::getData is probably a good place to start, to augment the SRTM with
non-land areas.

I'll get to it, but keen to hear of alternatives. (It's kind of amazing
that there's still no comprehensive global source for bathymetry/topography
data as a service.)

Cheers, Mike


-Alex
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Thu Jan 21 15:04:31 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 21 Jan 2016 15:04:31 +0100
Subject: [R-sig-Geo]
	=?utf-8?q?RStoolbox_loading=2C_Rscript=2C_printing_an?=
	=?utf-8?b?ZCBlIGFjdXRlICjDqSk=?=
In-Reply-To: <56A0E363.4050207@uni-muenster.de>
References: <CAGfc75kY+6RS1cE=6KM77f86iCU5XVcMh=k=dvnBn2LLm=TTFg@mail.gmail.com>
	<56A0E363.4050207@uni-muenster.de>
Message-ID: <CAGfc75mOe1EZ1GJ+McoevPNYht-aLzNgzLz9HsivpWcxczRPKw@mail.gmail.com>

I forgot to tell it's only when calling the script from Rscript that the e
acute isn't printed correctly.

in my case, I'm under Windows

R version 3.1.2 (2014-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252
 LC_MONETARY=French_France.1252
[4] LC_NUMERIC=C                   LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RStoolbox_0.1.1 raster_2.3-40   sp_1.0-17

loaded via a namespace (and not attached):
 [1] car_2.0-25         caret_6.0-57       codetools_0.2-9
 colorspace_1.2-6   digest_0.6.8       doParallel_1.0.8
 [7] foreach_1.4.2      geosphere_1.4-3    ggplot2_1.0.1      grid_3.1.2
      gtable_0.1.2       iterators_1.0.7
[13] lattice_0.20-29    lme4_1.1-10        magrittr_1.5       MASS_7.3-35
     Matrix_1.2-2       MatrixModels_0.4-1
[19] mgcv_1.8-3         minqa_1.2.4        munsell_0.4.2      nlme_3.1-118
      nloptr_1.0.4       nnet_7.3-8
[25] parallel_3.1.2     pbkrtest_0.4-2     plyr_1.8.3         proto_0.3-10
      quantreg_5.19      Rcpp_0.12.0
[31] reshape2_1.4.1     rgeos_0.3-8        scales_0.2.5       SparseM_1.7
     splines_3.1.2      stats4_3.1.2
[37] stringi_0.5-5      stringr_1.0.0      tools_3.1.2        XML_3.98-1.3


2016-01-21 14:55 GMT+01:00 Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> Mathieu, I can't reproduce this on ubuntu 14.04:
>
> >
> > cat("first \U00E9 \n")
> first ?
> > cat("--before--\n")
> --before--
> > cat(paste("encoding = ", getOption("encoding"), "\n"))
> encoding =  native.enc
> > cat(paste("locale = ", Sys.getlocale(), "\n"))
> locale =
>
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C
>
> > # suppressMessages(suppressWarnings(require("RStoolbox", quietly =
> TRUE)))
> > # provoque erreurs accent e aigu
> > require("RStoolbox")
> Loading required package: RStoolbox
> > cat("\n")
>
> > cat("--after--\n")
> --after--
> > cat(paste("encoding = ", getOption("encoding"),"\n"))
> encoding =  native.enc
> > cat(paste("locale = ", Sys.getlocale(), "\n"))
> locale =
>
> LC_CTYPE=en_US.UTF-8;LC_NUMERIC=C;LC_TIME=en_GB.UTF-8;LC_COLLATE=en_US.UTF-8;LC_MONETARY=en_GB.UTF-8;LC_MESSAGES=en_US.UTF-8;LC_PAPER=en_GB.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_GB.UTF-8;LC_IDENTIFICATION=C
>
> > cat(" second \U00E9")
>  second ?> sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.3 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_GB.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_GB.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] RStoolbox_0.1.3
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.2        raster_2.5-2       magrittr_1.5
> splines_3.2.3
>  [5] MASS_7.3-44        doParallel_1.0.10  munsell_0.4.2
> geosphere_1.5-1
>  [9] colorspace_1.2-6   lattice_0.20-33    foreach_1.4.3
> minqa_1.2.4
> [13] stringr_1.0.0      car_2.1-0          plyr_1.8.3
> tools_3.2.3
> [17] parallel_3.2.3     nnet_7.3-11        pbkrtest_0.4-2
> caret_6.0-64
> [21] grid_3.2.3         gtable_0.1.2       nlme_3.1-123       mgcv_1.8-7
>
> [25] quantreg_5.19      rgeos_0.3-15       MatrixModels_0.4-1
> iterators_1.0.8
> [29] lme4_1.1-10        Matrix_1.2-3       nloptr_1.0.4
> reshape2_1.4.1
> [33] ggplot2_2.0.0      codetools_0.2-14   sp_1.2-2
> stringi_1.0-1
> [37] scales_0.3.0       XML_3.98-1.3       stats4_3.2.3       SparseM_1.7
>
> On 21/01/16 13:58, Mathieu Rajerison wrote:
> > Hi,
> >
> > This post is not spatially-oriented but deals with an excellent spatial R
> > package named RStoobox for remote sensing.
> >
> > I have a process that prints advancement operations with cat() functions.
> > Some contain e acute as it is for french administrations.
> >
> > I noticed I had problems with the writing of e acutes after loading
> > RStoolbox package. I noticed the same with igraph as well
> >
> > If I write an R file with the following lines :
> >
> > cat("first \U00E9")
> > require("RStoolbox")
> > cat(" second \U00E9")
> >
> > It gives
> >
> > first ?
> > second ?
> >
> > If I load another package like raster, the problem doesn't appear.
> >
> > To see if there was any change relative to encodings, I wrote an R file
> > with the following lines which gives the system encoding before and
> after :
> >
> > cat("first \U00E9 \n")
> > cat("--before--\n")
> > cat(paste("encoding = ", getOption("encoding"), "\n"))
> > cat(paste("locale = ", Sys.getlocale(), "\n"))
> > # suppressMessages(suppressWarnings(require("RStoolbox", quietly =
> TRUE)))
> > # provoque erreurs accent e aigu
> > require("RStoolbox")
> > cat("\n")
> > cat("--after--\n")
> > cat(paste("encoding = ", getOption("encoding"),"\n"))
> > cat(paste("locale = ", Sys.getlocale(), "\n"))
> > cat(" second \U00E9")
> >
> > But there isn't any change :
> >
> > first ?
> > --before--
> > encoding =  native.enc
> > locale =
> >  LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=
> > French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
> > Le chargement a n?cessit? le package : RStoolbox
> > Message d'avis :
> > le package 'RStoolbox' a ?t? compil? avec la version R 3.1.3
> >
> > --after--
> > encoding =  native.enc
> > locale =
> >  LC_COLLATE=French_France.1252;LC_CTYPE=French_France.1252;LC_MONETARY=
> > French_France.1252;LC_NUMERIC=C;LC_TIME=French_France.1252
> >  second ?
> >
> > So, i wonder where does this come from ? And how to deal with it
> >
> > Thanks in advance for your answers,
> >
> > Mathieu
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>

	[[alternative HTML version deleted]]


From agaricha at gmail.com  Thu Jan 21 19:34:22 2016
From: agaricha at gmail.com (Richa Agarwal)
Date: Thu, 21 Jan 2016 10:34:22 -0800
Subject: [R-sig-Geo] Mapping Singapore data
In-Reply-To: <CAJ4QxaNNoYXOgtgBPz0dFN5jZoE-afzQw38KXWULSfQf_iwfVA@mail.gmail.com>
References: <CAGcE_2jCEyBeFTZJof3ALg6YsR2zgU7jVEpRGoD1koFOp+g=6A@mail.gmail.com>
	<CAJ4QxaNNoYXOgtgBPz0dFN5jZoE-afzQw38KXWULSfQf_iwfVA@mail.gmail.com>
Message-ID: <CAGcE_2jErexE4MDgbkaYUuNn0A5jyLHP3=9wBUy70aO9dfRGeA@mail.gmail.com>

Thanks Bob. Got this to work.

However, the GADM data divides Singapore in just six regions.  I need
Singapore data ideally at postal code level (6 digit) or some aggregation
of postal codes say to 3-4 digits.

Any suggestions?


On Thu, Jan 14, 2016 at 9:18 PM, boB Rudis <bob at rudis.net> wrote:

> This can get you started (if you're the ggplot2 sort of person).
> raster::getData will pull the data without a manual download. I'm not
> sure what you need admin-level-wise, so I went with Admin1.
> ggplot2::fortify takes the spatial data and makes it something ggplot2
> can work with. It would normally use the polygon id, but you can
> substitute other identifiers from the shapefile. i went with the
> region name.
>
> i made a dummy data frame for a random choropleth and then proceed to
> plot the base map and fill layers.
>
> viridis is a nice scale, but you'd ideally want to cut or cut2 some
> levels since it's unlikely you have data that should be on a
> continuous scale (just guessing tho).
>
> the projection i chose is a pretty gd one for that region with those
> lat/lon boundaries.
>
> library(raster)
> library(rgeos)
> library(maptools)
> library(ggplot2)
> library(ggalt)
> library(ggthemes)
> library(viridis)
>
> sg <- getData(country="SGP", level=1)
>
> sg_map <- fortify(sg, region="NAME_1")
>
> choro_dat <- data.frame(region=sg at data$NAME_1,
>                         value=sample(100, nrow(sg at data)),
>                         stringsAsFactors=FALSE)
>
> gg <- ggplot()
> gg <- gg + geom_map(data=sg_map, map=sg_map,
>                     aes(x=long, y=lat, map_id=id),
>                     color="#b2b2b200", fill="#ffffff00", size=0.15)
> gg <- gg + geom_map(data=choro_dat, map=sg_map,
>                     aes(fill=value, map_id=region),
>                     color="#b2b2b2", size=0.15)
> gg <- gg + coord_proj("+proj=aea +lon_0=103.8474")
> gg <- gg + scale_fill_viridis(name="Measure")
> gg <- gg + theme_map()
> gg <- gg + theme(legend.position="bottom")
> gg
>
> On Thu, Jan 14, 2016 at 8:03 PM, Richa Agarwal <agaricha at gmail.com> wrote:
> > Hi Guys,
> >
> > I have some experience with R though relatively new to mapping geo data.
> >
> > I am trying to plot a heat map for Singapore and was trying to figure out
> > what would be the best way to start. Reading up online I downloaded a
> .rds
> > file from http://www.gadm.org/country. Though sure how to proceed now.
> >
> > Thanks
> > Richa
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From agaricha at gmail.com  Thu Jan 21 23:16:03 2016
From: agaricha at gmail.com (Richa Agarwal)
Date: Thu, 21 Jan 2016 14:16:03 -0800
Subject: [R-sig-Geo] using GADM
Message-ID: <CAGcE_2gs9xcZBj_ghxqJp5=G+CTPORdcSbRxP9TKdKMc9ikLOg@mail.gmail.com>

Hi Guys

 I am using data downloaded from GADM for Singapore (level 1). The data I
want to plot for Singapore is by postal code (6 digit). I am wondering how
can I map my data to the 5 regions that are available for Singapore at GADM
 -central, East, North-East, North and West. A Google search on this wasn't
very helpful (or I didn't know the right search terms).

http://www.gadm.org/download

Thanks
Richa

	[[alternative HTML version deleted]]


From hengl at spatial-analyst.net  Fri Jan 22 10:12:38 2016
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Fri, 22 Jan 2016 10:12:38 +0100
Subject: [R-sig-Geo] raster package and tiling schemes
In-Reply-To: <CAAcGz9-i6pX5xDJPp6J_s=-JGTVHVisx-Y_XVgxhm1_+BO0kEQ@mail.gmail.com>
References: <CAAcGz9-G5q2UPZP2EUMPUOMhH1FrsW2KyFtV1SpEzXv0wSu4qQ@mail.gmail.com>
	<569FBD2F.3060801@wildintellect.com>
	<CAAcGz9-i6pX5xDJPp6J_s=-JGTVHVisx-Y_XVgxhm1_+BO0kEQ@mail.gmail.com>
Message-ID: <56A1F286.5000400@spatial-analyst.net>


If this can be of any help, I spend a lot of time tiling and working 
with large rasters in R (usually a combination of R, raster and sp 
packages + GDAL utils and SAGA GIS) so eventually I have made my own 
tiling functions:

http://gsif.r-forge.r-project.org/tile.html

The source code is at:

https://github.com/cran/GSIF/blob/master/R/tile.R

Here is an example of how to combine all these things to plot large 
rasters in parallel (still experimental, but you will get the idea):

http://plotkml.r-forge.r-project.org/plotKML.GDALobj.html
https://github.com/cran/plotKML/blob/master/R/plotKML.GDALobj.R

T. (Tom) Hengl
Researcher @ ISRIC - World Soil Information
Team member Africa Soil Information Services http://africasoils.net
Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
Network: http://profiles.google.com/tom.hengl
Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ


On 21-1-2016 15:02, Michael Sumner wrote:
> On Thu, 21 Jan 2016 at 04:00 Alex Mandel <tech_dev at wildintellect.com> wrote:
>
>> On 01/19/2016 09:22 PM, Michael Sumner wrote:
>>> Hi there, does raster or any related package have any built-in  schemes
>>> that allow for easy management of tiles?
>>>
>>> Raster itself provides a very powerful platform for building such a
>> scheme,
>>> since we can reasonably easily reclassify analogous RasterLayers at
>>> different resolutions, and map cell values from one raster to another -
>>> being careful with tile overlaps and alignment of course.
>>>
>>> Anyone working on such a thing already, or got any grand plans?
>>>
>>> I know rgdal and friends provide access to the GDAL tools in various
>> ways,
>>> but I want something in R only.
>>>
>>> Cheers, Mike
>>>
>>
>> What's the goal of tiling? And when you say tiles do you mean multiple
>> zoom levels like web tiles, or more a raster catalog like a VRT of
>> multiple rasters next to each other?
>>
>> If you mean zoom levels, things like pyramids in tiffs are local
>> equivalent but that's only for viewing data, not really useful for
>> analysis.
>>
>> If you mean things that are adjacent to each other, I would assume that
>> if they aren't all the same resolution/scale then you need to go to the
>> lowest common denominator and resample everything to that to get a
>> seamless data set. In this case the Raster merge and mosaic functions.
>> Though if you want to keep the files in pieces, save them all out into
>> the same resolution/scale, clipped to no longer have overlap, and
>> gdal_buildvrt.
>>
>> Or am I missing the point?
>>
>>
> Thanks Alex, these are good questions. I just want to be able to do it
> arbitrarily for lots of reasons, but right now I want to tile up some
> global data sets and allow my code to access them from a website at
> different resolutions.
>
> Basic stuff. Stuff that should be basic and on hand. The machinery behind
> raster::getData is probably a good place to start, to augment the SRTM with
> non-land areas.
>
> I'll get to it, but keen to hear of alternatives. (It's kind of amazing
> that there's still no comprehensive global source for bathymetry/topography
> data as a service.)
>
> Cheers, Mike
>
>
> -Alex


From cryan at binghamton.edu  Thu Jan 21 16:18:24 2016
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Thu, 21 Jan 2016 10:18:24 -0500
Subject: [R-sig-Geo] geocoding street addresses within R,
	not using any web-based services
Message-ID: <56A0F6C0.5010506@binghamton.edu>

Hello. I'm a longtime R and R-help user, and recent listener on
R-sig-geo. First post here. I use R on both Win 7 and Linux Mint.

Is there a way to geocode street addresses in the US within R on my
local machine, that is, without transmitting the addresses to any
web-based service?  I have about 26,000 street addresses for a certain
type of ambulance call. I'd prefer (so does my Institutional Review
Board) that the addresses remain with me.

So far I have been using ArcGIS to geocode them on my own machine, and
then export the resulting shapefiles of point patterns to R, for
analysis with spatstat. But I'd rather to it all within R if possible.
(I get frustrated with menu-driven ArcGIS.)

My data are street addresses, not lon/lat coordinates. I have street
segment databases for the relevant counties from the US Census Bureau
TIGER shapefiles.

Thanks for any help.

--Chris Ryan
Broome County Health Department and
Binghamton University and
SUNY Upstate Medical University
Binghamton, NY


From thierry.onkelinx at inbo.be  Fri Jan 22 10:50:49 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 22 Jan 2016 10:50:49 +0100
Subject: [R-sig-Geo] geocoding street addresses within R,
 not using any web-based services
In-Reply-To: <56A0F6C0.5010506@binghamton.edu>
References: <56A0F6C0.5010506@binghamton.edu>
Message-ID: <CAJuCY5zt8aKT7+e07BXbXfurbegz=vKg85KtiUyMdn=So=ystw@mail.gmail.com>

Dear Christopher,

Have a look at the rgeos and spgrass6 packages. rgeos provides several GIS
operations. spgrass6 allows to move data from R to GRASS GIS (and vice
versa). You can run GRASS operations from within R.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-01-21 16:18 GMT+01:00 Christopher W. Ryan <cryan at binghamton.edu>:

> Hello. I'm a longtime R and R-help user, and recent listener on
> R-sig-geo. First post here. I use R on both Win 7 and Linux Mint.
>
> Is there a way to geocode street addresses in the US within R on my
> local machine, that is, without transmitting the addresses to any
> web-based service?  I have about 26,000 street addresses for a certain
> type of ambulance call. I'd prefer (so does my Institutional Review
> Board) that the addresses remain with me.
>
> So far I have been using ArcGIS to geocode them on my own machine, and
> then export the resulting shapefiles of point patterns to R, for
> analysis with spatstat. But I'd rather to it all within R if possible.
> (I get frustrated with menu-driven ArcGIS.)
>
> My data are street addresses, not lon/lat coordinates. I have street
> segment databases for the relevant counties from the US Census Bureau
> TIGER shapefiles.
>
> Thanks for any help.
>
> --Chris Ryan
> Broome County Health Department and
> Binghamton University and
> SUNY Upstate Medical University
> Binghamton, NY
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Jan 22 11:02:21 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 22 Jan 2016 10:02:21 +0000
Subject: [R-sig-Geo] raster package and tiling schemes
In-Reply-To: <56A1F286.5000400@spatial-analyst.net>
References: <CAAcGz9-G5q2UPZP2EUMPUOMhH1FrsW2KyFtV1SpEzXv0wSu4qQ@mail.gmail.com>
	<569FBD2F.3060801@wildintellect.com>
	<CAAcGz9-i6pX5xDJPp6J_s=-JGTVHVisx-Y_XVgxhm1_+BO0kEQ@mail.gmail.com>
	<56A1F286.5000400@spatial-analyst.net>
Message-ID: <CAAcGz9__LNRL=Cai7054wGV0Ao_BzMzsCzi_wQr_E0BmvUwFgg@mail.gmail.com>

On Fri, 22 Jan 2016 at 20:13 Tomislav Hengl <hengl at spatial-analyst.net>
wrote:

>
> If this can be of any help, I spend a lot of time tiling and working
> with large rasters in R (usually a combination of R, raster and sp
> packages + GDAL utils and SAGA GIS) so eventually I have made my own
> tiling functions:
>
> http://gsif.r-forge.r-project.org/tile.html
>
> The source code is at:
>
> https://github.com/cran/GSIF/blob/master/R/tile.R
>
> Here is an example of how to combine all these things to plot large
> rasters in parallel (still experimental, but you will get the idea):
>
> http://plotkml.r-forge.r-project.org/plotKML.GDALobj.html
> https://github.com/cran/plotKML/blob/master/R/plotKML.GDALobj.R



Great, that looks good Tom.

Cheers, Mike.



>
>
> T. (Tom) Hengl
> Researcher @ ISRIC - World Soil Information
> Team member Africa Soil Information Services http://africasoils.net
> Url: http://www.wageningenur.nl/en/Persons/dr.-T-Tom-Hengl.htm
> Network: http://profiles.google.com/tom.hengl
> Publications: http://scholar.google.com/citations?user=2oYU7S8AAAAJ
>
>
> On 21-1-2016 15:02, Michael Sumner wrote:
> > On Thu, 21 Jan 2016 at 04:00 Alex Mandel <tech_dev at wildintellect.com>
> wrote:
> >
> >> On 01/19/2016 09:22 PM, Michael Sumner wrote:
> >>> Hi there, does raster or any related package have any built-in  schemes
> >>> that allow for easy management of tiles?
> >>>
> >>> Raster itself provides a very powerful platform for building such a
> >> scheme,
> >>> since we can reasonably easily reclassify analogous RasterLayers at
> >>> different resolutions, and map cell values from one raster to another -
> >>> being careful with tile overlaps and alignment of course.
> >>>
> >>> Anyone working on such a thing already, or got any grand plans?
> >>>
> >>> I know rgdal and friends provide access to the GDAL tools in various
> >> ways,
> >>> but I want something in R only.
> >>>
> >>> Cheers, Mike
> >>>
> >>
> >> What's the goal of tiling? And when you say tiles do you mean multiple
> >> zoom levels like web tiles, or more a raster catalog like a VRT of
> >> multiple rasters next to each other?
> >>
> >> If you mean zoom levels, things like pyramids in tiffs are local
> >> equivalent but that's only for viewing data, not really useful for
> >> analysis.
> >>
> >> If you mean things that are adjacent to each other, I would assume that
> >> if they aren't all the same resolution/scale then you need to go to the
> >> lowest common denominator and resample everything to that to get a
> >> seamless data set. In this case the Raster merge and mosaic functions.
> >> Though if you want to keep the files in pieces, save them all out into
> >> the same resolution/scale, clipped to no longer have overlap, and
> >> gdal_buildvrt.
> >>
> >> Or am I missing the point?
> >>
> >>
> > Thanks Alex, these are good questions. I just want to be able to do it
> > arbitrarily for lots of reasons, but right now I want to tile up some
> > global data sets and allow my code to access them from a website at
> > different resolutions.
> >
> > Basic stuff. Stuff that should be basic and on hand. The machinery behind
> > raster::getData is probably a good place to start, to augment the SRTM
> with
> > non-land areas.
> >
> > I'll get to it, but keen to hear of alternatives. (It's kind of amazing
> > that there's still no comprehensive global source for
> bathymetry/topography
> > data as a service.)
> >
> > Cheers, Mike
> >
> >
> > -Alex
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From tech_dev at wildintellect.com  Fri Jan 22 17:38:14 2016
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Fri, 22 Jan 2016 08:38:14 -0800
Subject: [R-sig-Geo] geocoding street addresses within R,
 not using any web-based services
In-Reply-To: <CAJuCY5zt8aKT7+e07BXbXfurbegz=vKg85KtiUyMdn=So=ystw@mail.gmail.com>
References: <56A0F6C0.5010506@binghamton.edu>
	<CAJuCY5zt8aKT7+e07BXbXfurbegz=vKg85KtiUyMdn=So=ystw@mail.gmail.com>
Message-ID: <56A25AF6.3000102@wildintellect.com>

A local postgis setup could work too, http://postgis.net/docs/Extras.html

Can probably use it from R with RPostgresql

Enjoy,
Alex

On 01/22/2016 01:50 AM, Thierry Onkelinx wrote:
> Dear Christopher,
> 
> Have a look at the rgeos and spgrass6 packages. rgeos provides several GIS
> operations. spgrass6 allows to move data from R to GRASS GIS (and vice
> versa). You can run GRASS operations from within R.
> 
> Best regards,
> 
> Thierry
> 
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> 
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> 
> 2016-01-21 16:18 GMT+01:00 Christopher W. Ryan <cryan at binghamton.edu>:
> 
>> Hello. I'm a longtime R and R-help user, and recent listener on
>> R-sig-geo. First post here. I use R on both Win 7 and Linux Mint.
>>
>> Is there a way to geocode street addresses in the US within R on my
>> local machine, that is, without transmitting the addresses to any
>> web-based service?  I have about 26,000 street addresses for a certain
>> type of ambulance call. I'd prefer (so does my Institutional Review
>> Board) that the addresses remain with me.
>>
>> So far I have been using ArcGIS to geocode them on my own machine, and
>> then export the resulting shapefiles of point patterns to R, for
>> analysis with spatstat. But I'd rather to it all within R if possible.
>> (I get frustrated with menu-driven ArcGIS.)
>>
>> My data are street addresses, not lon/lat coordinates. I have street
>> segment databases for the relevant counties from the US Census Bureau
>> TIGER shapefiles.
>>
>> Thanks for any help.
>>
>> --Chris Ryan
>> Broome County Health Department and
>> Binghamton University and
>> SUNY Upstate Medical University
>> Binghamton, NY
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From rtmelton.pez at gmail.com  Fri Jan 22 18:14:28 2016
From: rtmelton.pez at gmail.com (Ray Melton)
Date: Fri, 22 Jan 2016 09:14:28 -0800
Subject: [R-sig-Geo] geocoding street addresses within R,
 not using any web-based services
In-Reply-To: <56A25AF6.3000102@wildintellect.com>
References: <56A0F6C0.5010506@binghamton.edu>
	<CAJuCY5zt8aKT7+e07BXbXfurbegz=vKg85KtiUyMdn=So=ystw@mail.gmail.com>
	<56A25AF6.3000102@wildintellect.com>
Message-ID: <56A26374.60902@gmail.com>

I can verify that geocoding street addresses in the US with the PostGIS 
TIGER geocoder works, and that you can use RPostgreSQL from R to issue 
the geocoding commands.

I'm running Linux Mint 17.1, and to get the geocoder working, I simply 
went through the steps as outlined in PostGIS in Action, 2nd edition, 
Chapter 8.

Ray


On 01/22/2016 08:38 AM, Alex Mandel wrote:
> A local postgis setup could work too, http://postgis.net/docs/Extras.html
>
> Can probably use it from R with RPostgresql
>
> Enjoy,
> Alex
>
> On 01/22/2016 01:50 AM, Thierry Onkelinx wrote:
>> Dear Christopher,
>>
>> Have a look at the rgeos and spgrass6 packages. rgeos provides several GIS
>> operations. spgrass6 allows to move data from R to GRASS GIS (and vice
>> versa). You can run GRASS operations from within R.
>>
>> Best regards,
>>
>> Thierry
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of data.
>> ~ John Tukey
>>
>> 2016-01-21 16:18 GMT+01:00 Christopher W. Ryan <cryan at binghamton.edu>:
>>
>>> Hello. I'm a longtime R and R-help user, and recent listener on
>>> R-sig-geo. First post here. I use R on both Win 7 and Linux Mint.
>>>
>>> Is there a way to geocode street addresses in the US within R on my
>>> local machine, that is, without transmitting the addresses to any
>>> web-based service?  I have about 26,000 street addresses for a certain
>>> type of ambulance call. I'd prefer (so does my Institutional Review
>>> Board) that the addresses remain with me.
>>>
>>> So far I have been using ArcGIS to geocode them on my own machine, and
>>> then export the resulting shapefiles of point patterns to R, for
>>> analysis with spatstat. But I'd rather to it all within R if possible.
>>> (I get frustrated with menu-driven ArcGIS.)
>>>
>>> My data are street addresses, not lon/lat coordinates. I have street
>>> segment databases for the relevant counties from the US Census Bureau
>>> TIGER shapefiles.
>>>
>>> Thanks for any help.
>>>
>>> --Chris Ryan
>>> Broome County Health Department and
>>> Binghamton University and
>>> SUNY Upstate Medical University
>>> Binghamton, NY
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From jaonyango at yahoo.com  Fri Jan 22 18:32:35 2016
From: jaonyango at yahoo.com (Joshua Onyango)
Date: Fri, 22 Jan 2016 17:32:35 +0000 (UTC)
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <CAJ4QxaMh=cKbz=6HiByUpeHQqG-79J0q9wfMYSeLprMPrBVUtA@mail.gmail.com>
References: <CAJ4QxaMh=cKbz=6HiByUpeHQqG-79J0q9wfMYSeLprMPrBVUtA@mail.gmail.com>
Message-ID: <1168377998.7445976.1453483955085.JavaMail.yahoo@mail.yahoo.com>

Hi Bob,
Still getting the memory error to do with memory after merging the data to plot points as per your suggestions.
What could I be doing wrong is is there a way out to fix this?
Thanks
dat_merge =merge(regions,orf_data,by="Region",duplicateGeoms=TRUE)
eng_map <- fortify(regions, region="Region")
names(eng_map)[names(eng_map)=="id"]<-"Region" 
big_eng = merge(dat_merge, eng_map,by = "Region",duplicateGeoms=TRUE)

Error: cannot allocatevector of size 903.8 Mb
 

    On Wednesday, 20 January 2016, 19:14, boB Rudis <bob at rudis.net> wrote:
 

 That's actually why I did the second `geom_map` the way I did. Add
another column to that data frame and use it for the fill color
(preferably using `cut` to bin values? ahead of time as it's unlikey
you really want to use a continuous color palette.

On Wed, Jan 20, 2016 at 1:55 PM, Joshua Onyango <jaonyango at yahoo.com> wrote:
> Hi Bob
>
> Thanks for the help, merging region appear to work now.? However still stuck
> on the other bit on merging data with spatial object, ("regions") in this
> case to be able to plot the data points. I mainly want to plot information
> such as % disease prevalence in every region, temperature, flock size etc
>
> Thanks advance
>
> Josh
>
>
> On Wednesday, 20 January 2016, 1:49, boB Rudis <bob at rudis.net> wrote:
>
>
> I think this might help you out a bit (it's probably worth taking the
> time to look it over as it removes much of the redundant code you
> had).
>
> library(sp)
> library(maptools)
> library(rgeos)
> library(rgdal)
> library(dplyr)
> library(ggplot2)
> library(ggthemes)
> library(ggalt)
>
> URL <-
> "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
> fil <- basename(URL)
> if (!file.exists(fil)) download.file(URL, fil)
>
> fils <- unzip(fil)
> shp <- grep("shp$", fils, value=TRUE)
>
> region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)
>
> # define new regions
> region at data$Region <- c("East", "South &S.E", "North", "North", "Midlands",
>? ? ? ? ? ? ? ? ? ? ? ? "North", "SouthWest", "Midlands", "South & S.E")
> colnames(region at data) <- c("code", "name","Region")
>
> # dissolve polygons and simplify the shapes
> regions <- unionSpatialPolygons(region, region at data$Region)
> regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
> regions <- gBuffer(regions, byid=TRUE, width=0)
>
> # coord_map and coord_proj will eventually work but this transformation
> # will absolutely speed up the calculations
>
> regions <- SpatialPolygonsDataFrame(spTransform(regions,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? CRS("+proj=longlat
> +ellps=sphere +no_defs")),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? data.frame(Region=names(regions),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? row.names=names(regions),
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? stringsAsFactors=FALSE))
>
> eng_map <- fortify(regions, region="Region")
>
> # new projection (good for the UK)
> eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"
>
> ggplot() +
>? # base map
>? geom_map(data=eng_map, map=eng_map,
>? ? ? ? ? aes(x=long, y=lat, map_id=id),
>? ? ? ? ? color=NA, fill=NA, size=0.5) +
>? # sample fill of the regions
>? geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
>? ? ? ? ? aes(map_id=id, fill=id),
>? ? ? ? ? color="white", size=0.15) +
>? scale_fill_brewer(palette="Set2") +
>? coord_proj(eng_proj) +
>? theme_map()
>
> NOTE: this requires the new ggplot2 (2.0)
>
> On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
> <r-sig-geo at r-project.org> wrote:
>> HelloI'm new into creating maps in R so any help would be great.I have
>> read a few articles on the internet - mainly blogs on mapping in R which I
>> have tried to follow with no much success. Basically I want to merge merge
>> some English regions from 8 to 5 then show information that relates to
>> disease prevalence, temperature etc
>> Here is what I have tried but sound like this cant run due to computer
>> memory or must be doing following a wrong approach.
>>
>>
>>> #Getting theshapefile into working directory
>>
>>>
>>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>>
>>? ? ? ? ? ? ? ? destfile ="lad-region-lookup.zip")> #inzipping theshapefile
>> folder
>>
>>>unzip("lad-region-lookup.zip", exdir = ".")
>>
>>> #reading theshapefile in r
>>
>>> region <-readOGR(".", "England_gor_2011")
>>
>> OGR data source withdriver: ESRI Shapefile
>>
>> Source:".", layer: "England_gor_2011"
>>
>> with 9 features
>>
>> It has 2 fields
>>
>>> # Check theshapefile has loaded correctly
>>
>>> plot(region)
>>
>>>
>>
>>> lu <-data.frame()
>>
>>> lu <-rbind(lu, region at data)
>>
>>> lu$CODE <-as.character(lu$CODE)
>>
>>> lu$NAME <-as.character(lu$NAME)
>>
>>> lu$Region <-NA
>>
>>> name=c("East", "South
>>> &S.E","North","North","Midlands","North","SouthWest","Midlands","South &
>>> S.E")
>>
>>> lu$Region <-name
>>
>>> # Merge lu(LookUp) into polygons,
>>
>>> region at data$CODE<- as.character(region at data$CODE)
>>
>>> region at data<- full_join(region at data, lu, by = "CODE")
>>
>>> # Tidy mergeddata
>>
>>> region at data<- select(region at data, -NAME.x)
>>
>>>colnames(region at data) <- c("code", "name","Region")
>>
>>>
>>
>>> # Ensureshapefile row.names and polygon IDs are sensible
>>
>>>row.names(region) <- row.names(region at data)
>>
>>> region <-spChFIDs(region, row.names(region))
>>
>>>
>>
>>> # Now thedissolve
>>
>>> region <-gUnaryUnion(region, id = region at data$Region)
>>
>>>
>>
>>> # If you want torecreate an object with a data frame
>>
>>> # make sure row namesmatch
>>
>>>row.names(region) <- as.character(1:length(region))
>>
>>>
>>
>>> # Extract thedata you want (the larger geography)
>>
>>> lu <-unique(lu$Region)
>>
>>> lu <-as.data.frame(lu)
>>
>>> colnames(lu)<- "Region"? # your datawill probably have more than 1 row!
>>
>>>
>>
>>> # And add thedata back in
>>
>>> region <-SpatialPolygonsDataFrame(region, lu)
>>
>>> region2 <-merge(region at data, data, by="Region")
>>
>>> dat2=fortify(region,region="Region")
>>
>>>names(dat2)[names(dat2)=="id"]<-"Region"
>>
>>> dat <-merge(dat2, region2, by="Region")
>>
>> Error: cannotallocate vector of size 904.9 Mb
>>
>> In addition:Warning messages:
>>
>> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone),
>> c(by.x,seq_len(ncx)[-by.x]),? :
>>
>>? Reached total allocation of 4016Mb: seehelp(memory.size)
>>
>>
>>
>>
>> Any simpler approach will be highly appreciated.
>> Thanks
>> Josh
>>? ? ? ? [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


  
	[[alternative HTML version deleted]]


From bob at rudis.net  Fri Jan 22 18:47:01 2016
From: bob at rudis.net (boB Rudis)
Date: Fri, 22 Jan 2016 12:47:01 -0500
Subject: [R-sig-Geo] Merging regions in a map & plotting values
In-Reply-To: <1168377998.7445976.1453483955085.JavaMail.yahoo@mail.yahoo.com>
References: <CAJ4QxaMh=cKbz=6HiByUpeHQqG-79J0q9wfMYSeLprMPrBVUtA@mail.gmail.com>
	<1168377998.7445976.1453483955085.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAJ4QxaOOLnfGeOXM4WPO5ODKt_+K5dCmS0iOeEv5jzGxZNM7TQ@mail.gmail.com>

You really don't want to bind the data to the regions. My example
showed how to use a separate data frame. I won't have time to provide
an even simpler example until the weekend and (I realize this is list
anathema) this would work alot better as a Stack Overflow question.

On Fri, Jan 22, 2016 at 12:32 PM, Joshua Onyango <jaonyango at yahoo.com> wrote:
> Hi Bob,
>
> Still getting the memory error to do with memory after merging the data to
> plot points as per your suggestions.
>
> What could I be doing wrong is is there a way out to fix this?
>
> Thanks
>
> dat_merge = merge(regions,orf_data,by="Region",duplicateGeoms=TRUE)
> eng_map <- fortify(regions, region="Region")
> names(eng_map)[names(eng_map)=="id"]<-"Region"
> big_eng = merge(dat_merge, eng_map,by = "Region",duplicateGeoms=TRUE)
>
> Error: cannot allocate vector of size 903.8 Mb
>
>
> On Wednesday, 20 January 2016, 19:14, boB Rudis <bob at rudis.net> wrote:
>
>
> That's actually why I did the second `geom_map` the way I did. Add
> another column to that data frame and use it for the fill color
> (preferably using `cut` to bin values  ahead of time as it's unlikey
> you really want to use a continuous color palette.
>
> On Wed, Jan 20, 2016 at 1:55 PM, Joshua Onyango <jaonyango at yahoo.com> wrote:
>> Hi Bob
>>
>> Thanks for the help, merging region appear to work now.  However still
>> stuck
>> on the other bit on merging data with spatial object, ("regions") in this
>> case to be able to plot the data points. I mainly want to plot information
>> such as % disease prevalence in every region, temperature, flock size etc
>>
>> Thanks advance
>>
>> Josh
>>
>>
>> On Wednesday, 20 January 2016, 1:49, boB Rudis <bob at rudis.net> wrote:
>>
>>
>> I think this might help you out a bit (it's probably worth taking the
>> time to look it over as it removes much of the redundant code you
>> had).
>>
>> library(sp)
>> library(maptools)
>> library(rgeos)
>> library(rgdal)
>> library(dplyr)
>> library(ggplot2)
>> library(ggthemes)
>> library(ggalt)
>>
>> URL <-
>>
>> "http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip"
>> fil <- basename(URL)
>> if (!file.exists(fil)) download.file(URL, fil)
>>
>> fils <- unzip(fil)
>> shp <- grep("shp$", fils, value=TRUE)
>>
>> region <- readOGR(shp, ogrListLayers(shp)[1], stringsAsFactors=FALSE)
>>
>> # define new regions
>> region at data$Region <- c("East", "South &S.E", "North", "North",
>> "Midlands",
>>                        "North", "SouthWest", "Midlands", "South & S.E")
>> colnames(region at data) <- c("code", "name","Region")
>>
>> # dissolve polygons and simplify the shapes
>> regions <- unionSpatialPolygons(region, region at data$Region)
>> regions <- gSimplify(regions, 100, topologyPreserve=TRUE)
>> regions <- gBuffer(regions, byid=TRUE, width=0)
>>
>> # coord_map and coord_proj will eventually work but this transformation
>> # will absolutely speed up the calculations
>>
>> regions <- SpatialPolygonsDataFrame(spTransform(regions,
>>                                                CRS("+proj=longlat
>> +ellps=sphere +no_defs")),
>>                                    data.frame(Region=names(regions),
>>                                              row.names=names(regions),
>>                                              stringsAsFactors=FALSE))
>>
>> eng_map <- fortify(regions, region="Region")
>>
>> # new projection (good for the UK)
>> eng_proj <- "+proj=aea +lat_0=54.55635146083455 +lon_0=-3.076171875"
>>
>> ggplot() +
>>  # base map
>>  geom_map(data=eng_map, map=eng_map,
>>          aes(x=long, y=lat, map_id=id),
>>          color=NA, fill=NA, size=0.5) +
>>  # sample fill of the regions
>>  geom_map(data=data.frame(id=unique(eng_map$id)), map=eng_map,
>>          aes(map_id=id, fill=id),
>>          color="white", size=0.15) +
>>  scale_fill_brewer(palette="Set2") +
>>  coord_proj(eng_proj) +
>>  theme_map()
>>
>> NOTE: this requires the new ggplot2 (2.0)
>>
>> On Tue, Jan 19, 2016 at 3:04 PM, Joshua Onyango via R-sig-Geo
>> <r-sig-geo at r-project.org> wrote:
>>> HelloI'm new into creating maps in R so any help would be great.I have
>>> read a few articles on the internet - mainly blogs on mapping in R which
>>> I
>>> have tried to follow with no much success. Basically I want to merge
>>> merge
>>> some English regions from 8 to 5 then show information that relates to
>>> disease prevalence, temperature etc
>>> Here is what I have tried but sound like this cant run due to computer
>>> memory or must be doing following a wrong approach.
>>>
>>>
>>>> #Getting theshapefile into working directory
>>>
>>>>
>>>>
>>>> download.file("http://census.edina.ac.uk/ukborders/easy_download/prebuilt/shape/England_gor_2011.zip",
>>>
>>>                destfile ="lad-region-lookup.zip")> #inzipping
>>> theshapefile
>>> folder
>>>
>>>>unzip("lad-region-lookup.zip", exdir = ".")
>>>
>>>> #reading theshapefile in r
>>>
>>>> region <-readOGR(".", "England_gor_2011")
>>>
>>> OGR data source withdriver: ESRI Shapefile
>>>
>>> Source:".", layer: "England_gor_2011"
>>>
>>> with 9 features
>>>
>>> It has 2 fields
>>>
>>>> # Check theshapefile has loaded correctly
>>>
>>>> plot(region)
>>>
>>>>
>>>
>>>> lu <-data.frame()
>>>
>>>> lu <-rbind(lu, region at data)
>>>
>>>> lu$CODE <-as.character(lu$CODE)
>>>
>>>> lu$NAME <-as.character(lu$NAME)
>>>
>>>> lu$Region <-NA
>>>
>>>> name=c("East", "South
>>>> &S.E","North","North","Midlands","North","SouthWest","Midlands","South &
>>>> S.E")
>>>
>>>> lu$Region <-name
>>>
>>>> # Merge lu(LookUp) into polygons,
>>>
>>>> region at data$CODE<- as.character(region at data$CODE)
>>>
>>>> region at data<- full_join(region at data, lu, by = "CODE")
>>>
>>>> # Tidy mergeddata
>>>
>>>> region at data<- select(region at data, -NAME.x)
>>>
>>>>colnames(region at data) <- c("code", "name","Region")
>>>
>>>>
>>>
>>>> # Ensureshapefile row.names and polygon IDs are sensible
>>>
>>>>row.names(region) <- row.names(region at data)
>>>
>>>> region <-spChFIDs(region, row.names(region))
>>>
>>>>
>>>
>>>> # Now thedissolve
>>>
>>>> region <-gUnaryUnion(region, id = region at data$Region)
>>>
>>>>
>>>
>>>> # If you want torecreate an object with a data frame
>>>
>>>> # make sure row namesmatch
>>>
>>>>row.names(region) <- as.character(1:length(region))
>>>
>>>>
>>>
>>>> # Extract thedata you want (the larger geography)
>>>
>>>> lu <-unique(lu$Region)
>>>
>>>> lu <-as.data.frame(lu)
>>>
>>>> colnames(lu)<- "Region"  # your datawill probably have more than 1 row!
>>>
>>>>
>>>
>>>> # And add thedata back in
>>>
>>>> region <-SpatialPolygonsDataFrame(region, lu)
>>>
>>>> region2 <-merge(region at data, data, by="Region")
>>>
>>>> dat2=fortify(region,region="Region")
>>>
>>>>names(dat2)[names(dat2)=="id"]<-"Region"
>>>
>>>> dat <-merge(dat2, region2, by="Region")
>>>
>>> Error: cannotallocate vector of size 904.9 Mb
>>>
>>> In addition:Warning messages:
>>>
>>> 1: In`[.data.frame`(x, c(m$xi, if (all.x) m$x.alone),
>>> c(by.x,seq_len(ncx)[-by.x]),  :
>>>
>>>  Reached total allocation of 4016Mb: seehelp(memory.size)
>>>
>>>
>>>
>>>
>>> Any simpler approach will be highly appreciated.
>>> Thanks
>>> Josh
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
>


From junzailinyi at 163.com  Sun Jan 24 04:11:36 2016
From: junzailinyi at 163.com (junzailinyi)
Date: Sun, 24 Jan 2016 11:11:36 +0800
Subject: [R-sig-Geo] =?utf-8?b?KOaXoOS4u+mimCk=?=
Message-ID: <1ade4172.433.152719d924b.Coremail.junzailinyi@163.com>

ailinyi

2016-01-24


junzailinyi 
	[[alternative HTML version deleted]]


From larroque.jeremy at gmail.com  Sun Jan 24 21:58:34 2016
From: larroque.jeremy at gmail.com (Jeremy Larroque)
Date: Sun, 24 Jan 2016 21:58:34 +0100
Subject: [R-sig-Geo] Percentage of forest cover in a set radius for each
	raster cell
Message-ID: <CAGaZB33XfK0OM3y9cN-C8dw9+gs5K4E_v6NE9MDgUgnYfCS6nA@mail.gmail.com>

Dear list members,



I have a forest layer and an empty raster. I would like to compute for each
raster cell the percentage of forest in a set radius around the center of
the cell.

I used the option ?getCover? of the function rasterize but it only returns
the fraction of each grid cell that is covered by the polygons of forest.



Is there a way to do that in R?



The forest data can be downloaded here:
https://drive.google.com/folderview?id=0Bwf27qBU9Q1ONGpxSHFIbE9xRkk&usp=sharing



library(raster)

library(rgdal)



# forest data

forest <- readOGR(dsn = path1, layer = "foretze")



# raster set

Xmin <- c(795800)

Xmax <- c(840200)

Ymin <- c(2143600)

Ymax <- c(2186900)

rr <- raster(nrows=866, ncols=888, crs=CRS("+init=epsg:27572"), xmn=Xmin,
xmx=Xmax, ymn=Ymin, ymx=Ymax)



pforest <- rasterize(forest, rr, getCover=T)





Many thanks!



Jeremy

	[[alternative HTML version deleted]]


From mike_jadoo at yahoo.com  Mon Jan 25 02:25:14 2016
From: mike_jadoo at yahoo.com (Mike Jadoo)
Date: Mon, 25 Jan 2016 01:25:14 +0000 (UTC)
Subject: [R-sig-Geo] Need help with L.I.S.A.  Moran I , Geary C,
 and Getis Ord statistics in R spdep package
References: <1815957286.659655.1453685114376.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1815957286.659655.1453685114376.JavaMail.yahoo@mail.yahoo.com>

 Hello,
I am working on a project on how to explain in R?the steps that is needed to produce the Moran I, Geary C, and Getis Ord.?
?I am using a dataset that has? lat/ long coordinates and it appears I need to convert the lat long variables into a neighbor list (nb) [I used the dnearneigh function to do that]?then convert that table into spatial weights to?make it a?class listw and then use either the localmoran(), localg(), and others.? 
So my questions, using a lat long dataset is the procedure I just explained the correct process before I put these tables into the LISA functions?(currently I am using Luc Anselin paper "Data and Spatial Weights in spdep", to help me)
Any help would be great. 
Best,
Mike Jadoo
	[[alternative HTML version deleted]]


From juantomas.sayago at gmail.com  Mon Jan 25 08:25:55 2016
From: juantomas.sayago at gmail.com (Juan Tomas Sayago Gomez)
Date: Mon, 25 Jan 2016 07:25:55 +0000
Subject: [R-sig-Geo] Need help with L.I.S.A. Moran I , Geary C,
 and Getis Ord statistics in R spdep package
In-Reply-To: <1815957286.659655.1453685114376.JavaMail.yahoo@mail.yahoo.com>
References: <1815957286.659655.1453685114376.JavaMail.yahoo.ref@mail.yahoo.com>
	<1815957286.659655.1453685114376.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAEOXpNCnWrZZQ7kDTVD-sxB4BekyPPCa0xtJbetDjpMFCcyq-w@mail.gmail.com>

Hello Mike
Check this pdf of a lecture:
https://www.dropbox.com/s/lrkhsorbmk6cdhl/Lecture08_SpatialAuto%20copy.pdf?dl=0
<https://www.dropbox.com/s/n80hgextna9jq6n/Lecture08_SpatialAuto.pdf?dl=0>
It will be very helpful. Since it is not mine I will have to take it down
soon so please download it ASAP. I am trying to locate the original course
from where I download these slides but I can't find them.
J

On Sun, Jan 24, 2016 at 8:26 PM Mike Jadoo via R-sig-Geo <
r-sig-geo at r-project.org> wrote:

>  Hello,
> I am working on a project on how to explain in R the steps that is needed
> to produce the Moran I, Geary C, and Getis Ord.
>  I am using a dataset that has  lat/ long coordinates and it appears I
> need to convert the lat long variables into a neighbor list (nb) [I used
> the dnearneigh function to do that] then convert that table into spatial
> weights to make it a class listw and then use either the localmoran(),
> localg(), and others.
> So my questions, using a lat long dataset is the procedure I just
> explained the correct process before I put these tables into the LISA
> functions?(currently I am using Luc Anselin paper "Data and Spatial Weights
> in spdep", to help me)
> Any help would be great.
> Best,
> Mike Jadoo
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From uzzal at gist.ac.kr  Mon Jan 25 11:39:38 2016
From: uzzal at gist.ac.kr (Uzzal)
Date: Mon, 25 Jan 2016 19:39:38 +0900 (KST)
Subject: [R-sig-Geo] How to plot a variogram where the unit of lag distance
	would be in kilometer?
Message-ID: <654667429.1453718378362.JavaMail.root@eunhasu>

I have a dataset contains hourly PM10 concentrations (?g/m3 ) for 1 hour of 83 location. Please download from here. I have plotted semivariogram with these dataset. In semivariogram (Semivariance Vs Distance), the unit of distance is in meter(m) But I want semivariogram in which the unit of distance would be in kilometer(Km). How can I do this?   my R code:seoul032801  coordinates(seoul032801) #variogram modeling
seoul032801_var model032801   #give the parameters
plot(seoul032801_var,model=model032801, col="black", pch=16,cex = 1.3,
     xlab="Distance (m)", ylab = ~ "Semivariance ( " * mu * g^2 / m^3 * ")",
     main=" Semivariogram for 032801") Orpheus 




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160125/07c6c92e/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: bannerBottom.gif
Type: image/gif
Size: 21674 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160125/07c6c92e/attachment.gif>

From ashenkin at ufl.edu  Mon Jan 25 12:58:23 2016
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Mon, 25 Jan 2016 11:58:23 +0000
Subject: [R-sig-Geo] Elevation profiles
Message-ID: <56A60DDF.4070802@ufl.edu>

Hello All,

I've done this in ArcMAP, but further requirements are making it harder 
to do it there, so was hoping I can do it in R.

I have SRTM DEM rasters, and want to create an elevation profile. This 
profile is drawn along a polyline connecting 10 GPS points.  I was able 
to do all that in arcmap.  Now, however, I want to create the profile 
from an average elevation drawn from a swath of arbitrary width, rather 
than by just a line.  I hope this makes sense.

Apologies for not including reproducible code here - I'm hoping there's 
enough here to point me in a direction in terms of packages and 
algorithms regardless.  Thanks in advance.

Allie


From englishchristophera at gmail.com  Mon Jan 25 14:38:31 2016
From: englishchristophera at gmail.com (chris english)
Date: Mon, 25 Jan 2016 15:38:31 +0200
Subject: [R-sig-Geo] Elevation profiles
In-Reply-To: <56A60DDF.4070802@ufl.edu>
References: <56A60DDF.4070802@ufl.edu>
Message-ID: <CAASFQpRiL3kqLuTbSiab+wfsKtN2PhdfM2+Dcx3JuXPyEqdcbQ@mail.gmail.com>

Allie,

Perhaps rgoes, gBuffer (which wouldn't necessarily fit your arbitrary width
criteria but otherwise serve, (perhaps selecting your widths from a random
distribution multiplier)) your polyline and lay it over your DEM, something
like a swath transect? Sorry, just kinda thinking out loud. Or reading
again, do you really want to lay something like an arbitrary polygon on
there that contains the 10 pts?

Chris
And you ask, so how would you do that. Indeed.



On Mon, Jan 25, 2016 at 1:58 PM, Alexander Shenkin <ashenkin at ufl.edu> wrote:

> Hello All,
>
> I've done this in ArcMAP, but further requirements are making it harder to
> do it there, so was hoping I can do it in R.
>
> I have SRTM DEM rasters, and want to create an elevation profile. This
> profile is drawn along a polyline connecting 10 GPS points.  I was able to
> do all that in arcmap.  Now, however, I want to create the profile from an
> average elevation drawn from a swath of arbitrary width, rather than by
> just a line.  I hope this makes sense.
>
> Apologies for not including reproducible code here - I'm hoping there's
> enough here to point me in a direction in terms of packages and algorithms
> regardless.  Thanks in advance.
>
> Allie
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From r-sig-geo at forreststevens.com  Mon Jan 25 15:51:46 2016
From: r-sig-geo at forreststevens.com (Forrest Stevens)
Date: Mon, 25 Jan 2016 14:51:46 +0000
Subject: [R-sig-Geo] Elevation profiles
In-Reply-To: <CAASFQpRiL3kqLuTbSiab+wfsKtN2PhdfM2+Dcx3JuXPyEqdcbQ@mail.gmail.com>
References: <56A60DDF.4070802@ufl.edu>
	<CAASFQpRiL3kqLuTbSiab+wfsKtN2PhdfM2+Dcx3JuXPyEqdcbQ@mail.gmail.com>
Message-ID: <CAEBQMM=De98ZRcJdLn3sFkEmf0MTaDJOhFet-7yau6fEJZVghQ@mail.gmail.com>

Hey Allie, long time, hope things are going well!

Coincidentally I was working on something for a student of mine to do this
so I'll throw my two bits in. Starting from two points which specify a line
perpendicular to your swath and separated by the distance of your swath
width, you can create a series of lines parallel to the starting line
extending for as long as you want your swath.  Then, the most efficient way
to create multiple, touching polygons is to buffer those lines to a
distance that's half the width of the distance between your parallel
lines.  Using these polygons you can then aggregate statistics for your
underlying DEM.

I've posted some reproducible code that does something similar, however, it
creates angled transects along an E-W line.  It should be relatively easy
to change the calculated line end points to use changing Y values, keeping
the lines oriented along your swath instead of the E-W orientation.

https://github.com/ForrestStevens/Scratch/blob/master/swath_slices.R

Hopefully this gives you something to go on, but I'd be interested to know
if Roger or anyone else has a simpler solution!

Sincerely,
Forrest

On Mon, Jan 25, 2016 at 8:39 AM chris english <englishchristophera at gmail.com>
wrote:

> Allie,
>
> Perhaps rgoes, gBuffer (which wouldn't necessarily fit your arbitrary width
> criteria but otherwise serve, (perhaps selecting your widths from a random
> distribution multiplier)) your polyline and lay it over your DEM, something
> like a swath transect? Sorry, just kinda thinking out loud. Or reading
> again, do you really want to lay something like an arbitrary polygon on
> there that contains the 10 pts?
>
> Chris
> And you ask, so how would you do that. Indeed.
>
>
>
> On Mon, Jan 25, 2016 at 1:58 PM, Alexander Shenkin <ashenkin at ufl.edu>
> wrote:
>
> > Hello All,
> >
> > I've done this in ArcMAP, but further requirements are making it harder
> to
> > do it there, so was hoping I can do it in R.
> >
> > I have SRTM DEM rasters, and want to create an elevation profile. This
> > profile is drawn along a polyline connecting 10 GPS points.  I was able
> to
> > do all that in arcmap.  Now, however, I want to create the profile from
> an
> > average elevation drawn from a swath of arbitrary width, rather than by
> > just a line.  I hope this makes sense.
> >
> > Apologies for not including reproducible code here - I'm hoping there's
> > enough here to point me in a direction in terms of packages and
> algorithms
> > regardless.  Thanks in advance.
> >
> > Allie
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From tmeeha at gmail.com  Mon Jan 25 17:20:26 2016
From: tmeeha at gmail.com (Tim Meehan)
Date: Mon, 25 Jan 2016 09:20:26 -0700
Subject: [R-sig-Geo] Percentage of forest cover in a set radius for each
 raster cell
In-Reply-To: <CAGaZB33XfK0OM3y9cN-C8dw9+gs5K4E_v6NE9MDgUgnYfCS6nA@mail.gmail.com>
References: <CAGaZB33XfK0OM3y9cN-C8dw9+gs5K4E_v6NE9MDgUgnYfCS6nA@mail.gmail.com>
Message-ID: <CAMTWOzomMBN5c7CRE8SoeEiO+YKKPk6VmofbsXiBONSfM1u6gg@mail.gmail.com>

you could check out the focal() function in the raster package:

1) turn your forest layer into a layer of 1 (presence) and 0 (absence)
2) use the function to sum the number of ones within a neighborhood of each
focal cell
3) convert the focal sum to an area
4) divide the area by the total possible area of the buffer

best, tim

On Sun, Jan 24, 2016 at 1:58 PM, Jeremy Larroque <larroque.jeremy at gmail.com>
wrote:

> Dear list members,
>
>
>
> I have a forest layer and an empty raster. I would like to compute for each
> raster cell the percentage of forest in a set radius around the center of
> the cell.
>
> I used the option ?getCover? of the function rasterize but it only returns
> the fraction of each grid cell that is covered by the polygons of forest.
>
>
>
> Is there a way to do that in R?
>
>
>
> The forest data can be downloaded here:
>
> https://drive.google.com/folderview?id=0Bwf27qBU9Q1ONGpxSHFIbE9xRkk&usp=sharing
>
>
>
> library(raster)
>
> library(rgdal)
>
>
>
> # forest data
>
> forest <- readOGR(dsn = path1, layer = "foretze")
>
>
>
> # raster set
>
> Xmin <- c(795800)
>
> Xmax <- c(840200)
>
> Ymin <- c(2143600)
>
> Ymax <- c(2186900)
>
> rr <- raster(nrows=866, ncols=888, crs=CRS("+init=epsg:27572"), xmn=Xmin,
> xmx=Xmax, ymn=Ymin, ymx=Ymax)
>
>
>
> pforest <- rasterize(forest, rr, getCover=T)
>
>
>
>
>
> Many thanks!
>
>
>
> Jeremy
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From agaricha at gmail.com  Mon Jan 25 20:12:55 2016
From: agaricha at gmail.com (Richa Agarwal)
Date: Mon, 25 Jan 2016 11:12:55 -0800
Subject: [R-sig-Geo] mapping of administrative areas to postal codes
Message-ID: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>

Hi Guys,

Is there a mapping of administrative areas (as available in shape files at
the GADM website) to postal codes by country? Also is there a source for
more detailed shapefiles. Example for Singapore the detail available on
GADM is just level 1.

http://www.gadm.org/country

Thanks
Richa

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Mon Jan 25 20:50:04 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 25 Jan 2016 20:50:04 +0100
Subject: [R-sig-Geo] mapping of administrative areas to postal codes
In-Reply-To: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>
References: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1601252041470.31546@reclus.nhh.no>

On Mon, 25 Jan 2016, Richa Agarwal wrote:

> Hi Guys,
>
> Is there a mapping of administrative areas (as available in shape files at
> the GADM website) to postal codes by country? Also is there a source for
> more detailed shapefiles. Example for Singapore the detail available on
> GADM is just level 1.

In the US, five-digit zip codes are part of the US Census boundary system, 
and - as public boundaries - are open for download.

In most other countries, the boundaries of postal code areas are not 
public data, even where the postal service is public, and are usually only 
available at substantial cost, and often without permission to publish 
maps based on the boundaries.

In Norway, a Meteorological Office programmer crowd-sourced point 
locations to provide a way of offering weather forecast look-up based on 
postcode - but those are not boundaries, and indeed are just the GPS 
readings of volunteered data.

Even using commercial APIs to give address points probably will not help.

Roger

>
> http://www.gadm.org/country
>
> Thanks
> Richa
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From agaricha at gmail.com  Mon Jan 25 21:43:17 2016
From: agaricha at gmail.com (Richa Agarwal)
Date: Mon, 25 Jan 2016 12:43:17 -0800
Subject: [R-sig-Geo] mapping of administrative areas to postal codes
In-Reply-To: <alpine.LFD.2.20.1601252041470.31546@reclus.nhh.no>
References: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>
	<alpine.LFD.2.20.1601252041470.31546@reclus.nhh.no>
Message-ID: <CAGcE_2iUJ_4t0msN6ES1Ab-_O6kGCPUkeLPCvwV4Gk8eTvaO7g@mail.gmail.com>

Thanks very much Roger.

Guys, Any insights on how can we map postal code in a country to the
administrative areas (for which shape files are available at GADM).
Example: For Singapore for level 1 areas GADM has 5 regions however when I
plot them they don't necessarily match with 5 regions explained on say
Wikipedia

https://en.wikipedia.org/wiki/Administrative_divisions_of_Singapore



On Mon, Jan 25, 2016 at 11:50 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Mon, 25 Jan 2016, Richa Agarwal wrote:
>
> Hi Guys,
>>
>> Is there a mapping of administrative areas (as available in shape files at
>> the GADM website) to postal codes by country? Also is there a source for
>> more detailed shapefiles. Example for Singapore the detail available on
>> GADM is just level 1.
>>
>
> In the US, five-digit zip codes are part of the US Census boundary system,
> and - as public boundaries - are open for download.
>
> In most other countries, the boundaries of postal code areas are not
> public data, even where the postal service is public, and are usually only
> available at substantial cost, and often without permission to publish maps
> based on the boundaries.
>
> In Norway, a Meteorological Office programmer crowd-sourced point
> locations to provide a way of offering weather forecast look-up based on
> postcode - but those are not boundaries, and indeed are just the GPS
> readings of volunteered data.
>
> Even using commercial APIs to give address points probably will not help.
>
> Roger
>
>
>> http://www.gadm.org/country
>>
>> Thanks
>> Richa
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> http://depsy.org/person/434412
>

	[[alternative HTML version deleted]]


From tech_dev at wildintellect.com  Tue Jan 26 00:29:41 2016
From: tech_dev at wildintellect.com (Alex Mandel)
Date: Mon, 25 Jan 2016 15:29:41 -0800
Subject: [R-sig-Geo] mapping of administrative areas to postal codes
In-Reply-To: <CAGcE_2iUJ_4t0msN6ES1Ab-_O6kGCPUkeLPCvwV4Gk8eTvaO7g@mail.gmail.com>
References: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>
	<alpine.LFD.2.20.1601252041470.31546@reclus.nhh.no>
	<CAGcE_2iUJ_4t0msN6ES1Ab-_O6kGCPUkeLPCvwV4Gk8eTvaO7g@mail.gmail.com>
Message-ID: <56A6AFE5.3060200@wildintellect.com>

GADM isn't always as current as you might hope (something we're working
on with interns).

For Singapore we have an update but I don't think it's released yet.
The source however is
https://www.ura.gov.sg/uramaps/?config=config_preopen.xml&preopen=Planning%20Boundaries
It's a little tricky to extract the data.

FYI, US Post Codes from the Census do not 100% match the Postal Service
which does not release their boundaries. Generally in most countries you
have buy access to postal code data.


I'll check up on what needs to be done to push the newer version of GADM
for Singapore to the public service.

Thanks,
Alex

On 01/25/2016 12:43 PM, Richa Agarwal wrote:
> Thanks very much Roger.
> 
> Guys, Any insights on how can we map postal code in a country to the
> administrative areas (for which shape files are available at GADM).
> Example: For Singapore for level 1 areas GADM has 5 regions however when I
> plot them they don't necessarily match with 5 regions explained on say
> Wikipedia
> 
> https://en.wikipedia.org/wiki/Administrative_divisions_of_Singapore
> 
> 
> 
> On Mon, Jan 25, 2016 at 11:50 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
>> On Mon, 25 Jan 2016, Richa Agarwal wrote:
>>
>> Hi Guys,
>>>
>>> Is there a mapping of administrative areas (as available in shape files at
>>> the GADM website) to postal codes by country? Also is there a source for
>>> more detailed shapefiles. Example for Singapore the detail available on
>>> GADM is just level 1.
>>>
>>
>> In the US, five-digit zip codes are part of the US Census boundary system,
>> and - as public boundaries - are open for download.
>>
>> In most other countries, the boundaries of postal code areas are not
>> public data, even where the postal service is public, and are usually only
>> available at substantial cost, and often without permission to publish maps
>> based on the boundaries.
>>
>> In Norway, a Meteorological Office programmer crowd-sourced point
>> locations to provide a way of offering weather forecast look-up based on
>> postcode - but those are not boundaries, and indeed are just the GPS
>> readings of volunteered data.
>>
>> Even using commercial APIs to give address points probably will not help.
>>
>> Roger
>>
>>
>>> http://www.gadm.org/country
>>>
>>> Thanks
>>> Richa
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> http://depsy.org/person/434412
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From SWalbridge at esri.com  Tue Jan 26 01:20:37 2016
From: SWalbridge at esri.com (Shaun Walbridge)
Date: Tue, 26 Jan 2016 00:20:37 +0000
Subject: [R-sig-Geo] mapping of administrative areas to postal codes
In-Reply-To: <56A6AFE5.3060200@wildintellect.com>
References: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>
	<alpine.LFD.2.20.1601252041470.31546@reclus.nhh.no>
	<CAGcE_2iUJ_4t0msN6ES1Ab-_O6kGCPUkeLPCvwV4Gk8eTvaO7g@mail.gmail.com>
	<56A6AFE5.3060200@wildintellect.com>
Message-ID: <6a8d7324257c4aa294de2443122c6e6f@RED-INF-MXMB-P4.esri.com>

You can extract the data fairly easily using the REST API to pull out
what you want. For example, this URL contains the regions:

http://www.arcgis.com/home/item.html?id=0dd32a9c77b8400ebf60261571b9134b

That data can be downloaded directly in the browser, or using something
like cURL. Note that the data is provided under these terms of use:

https://ref.data.gov.sg/common/terms.aspx

The REST API can take a little time to become familiar with. Here's a
bash script which downloads both the regions and detailed admin
areas using cURL, and converts them to Shapefiles with OGR:

https://gist.github.com/scw/f761b6c5fe2508eeb94c

Cheers,
Shaun

-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Alex Mandel
Sent: Monday, January 25, 2016 6:30 PM
To: Richa Agarwal; Roger.Bivand at nhh.no
Cc: R-mailing list
Subject: Re: [R-sig-Geo] mapping of administrative areas to postal codes

GADM isn't always as current as you might hope (something we're working on with interns).

For Singapore we have an update but I don't think it's released yet.
The source however is
https://www.ura.gov.sg/uramaps/?config=config_preopen.xml&preopen=Planning%20Boundaries
It's a little tricky to extract the data.

FYI, US Post Codes from the Census do not 100% match the Postal Service which does not release their boundaries. Generally in most countries you have buy access to postal code data.


I'll check up on what needs to be done to push the newer version of GADM for Singapore to the public service.

Thanks,
Alex

On 01/25/2016 12:43 PM, Richa Agarwal wrote:
> Thanks very much Roger.
> 
> Guys, Any insights on how can we map postal code in a country to the 
> administrative areas (for which shape files are available at GADM).
> Example: For Singapore for level 1 areas GADM has 5 regions however 
> when I plot them they don't necessarily match with 5 regions explained 
> on say Wikipedia
> 
> https://en.wikipedia.org/wiki/Administrative_divisions_of_Singapore
> 
> 
> 
> On Mon, Jan 25, 2016 at 11:50 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
>> On Mon, 25 Jan 2016, Richa Agarwal wrote:
>>
>> Hi Guys,
>>>
>>> Is there a mapping of administrative areas (as available in shape 
>>> files at the GADM website) to postal codes by country? Also is there 
>>> a source for more detailed shapefiles. Example for Singapore the 
>>> detail available on GADM is just level 1.
>>>
>>
>> In the US, five-digit zip codes are part of the US Census boundary 
>> system, and - as public boundaries - are open for download.
>>
>> In most other countries, the boundaries of postal code areas are not 
>> public data, even where the postal service is public, and are usually 
>> only available at substantial cost, and often without permission to 
>> publish maps based on the boundaries.
>>
>> In Norway, a Meteorological Office programmer crowd-sourced point 
>> locations to provide a way of offering weather forecast look-up based 
>> on postcode - but those are not boundaries, and indeed are just the 
>> GPS readings of volunteered data.
>>
>> Even using commercial APIs to give address points probably will not help.
>>
>> Roger
>>
>>
>>> http://www.gadm.org/country
>>>
>>> Thanks
>>> Richa
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics, Helleveien 
>> 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>> http://orcid.org/0000-0003-2392-6140
>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
>> http://depsy.org/person/434412
>>
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From agaricha at gmail.com  Tue Jan 26 02:13:51 2016
From: agaricha at gmail.com (Richa Agarwal)
Date: Mon, 25 Jan 2016 17:13:51 -0800
Subject: [R-sig-Geo] mapping of administrative areas to postal codes
In-Reply-To: <6a8d7324257c4aa294de2443122c6e6f@RED-INF-MXMB-P4.esri.com>
References: <CAGcE_2g5xNVRJ75hncPuyX8_bvNOF9pUR=J9AsPjVghVnXnKPw@mail.gmail.com>
	<alpine.LFD.2.20.1601252041470.31546@reclus.nhh.no>
	<CAGcE_2iUJ_4t0msN6ES1Ab-_O6kGCPUkeLPCvwV4Gk8eTvaO7g@mail.gmail.com>
	<56A6AFE5.3060200@wildintellect.com>
	<6a8d7324257c4aa294de2443122c6e6f@RED-INF-MXMB-P4.esri.com>
Message-ID: <CAGcE_2iOvPoAa-u2ZTm_LmT1T6qpZvxtPu+3DOR6PvC6fX_wEw@mail.gmail.com>

Thanks guys!!
I was able to download the .json file using the .bash script at
https://gist.github.com/scw/f761b6c5fe2508eeb94c

I have demand data by zip code. I would like to figure out how I can map
that data on this file. I understand that since the shape file has only 5
regions I might have to aggregate all my postal code data to 5 regions and
then plot. However, I am not sure what the mapping is from postal cadets to
these regions.



On Mon, Jan 25, 2016 at 4:20 PM, Shaun Walbridge <SWalbridge at esri.com>
wrote:

> You can extract the data fairly easily using the REST API to pull out
> what you want. For example, this URL contains the regions:
>
> http://www.arcgis.com/home/item.html?id=0dd32a9c77b8400ebf60261571b9134b
>
> That data can be downloaded directly in the browser, or using something
> like cURL. Note that the data is provided under these terms of use:
>
> https://ref.data.gov.sg/common/terms.aspx
>
> The REST API can take a little time to become familiar with. Here's a
> bash script which downloads both the regions and detailed admin
> areas using cURL, and converts them to Shapefiles with OGR:
>
> https://gist.github.com/scw/f761b6c5fe2508eeb94c
>
> Cheers,
> Shaun
>
> -----Original Message-----
> From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of
> Alex Mandel
> Sent: Monday, January 25, 2016 6:30 PM
> To: Richa Agarwal; Roger.Bivand at nhh.no
> Cc: R-mailing list
> Subject: Re: [R-sig-Geo] mapping of administrative areas to postal codes
>
> GADM isn't always as current as you might hope (something we're working on
> with interns).
>
> For Singapore we have an update but I don't think it's released yet.
> The source however is
>
> https://www.ura.gov.sg/uramaps/?config=config_preopen.xml&preopen=Planning%20Boundaries
> It's a little tricky to extract the data.
>
> FYI, US Post Codes from the Census do not 100% match the Postal Service
> which does not release their boundaries. Generally in most countries you
> have buy access to postal code data.
>
>
> I'll check up on what needs to be done to push the newer version of GADM
> for Singapore to the public service.
>
> Thanks,
> Alex
>
> On 01/25/2016 12:43 PM, Richa Agarwal wrote:
> > Thanks very much Roger.
> >
> > Guys, Any insights on how can we map postal code in a country to the
> > administrative areas (for which shape files are available at GADM).
> > Example: For Singapore for level 1 areas GADM has 5 regions however
> > when I plot them they don't necessarily match with 5 regions explained
> > on say Wikipedia
> >
> > https://en.wikipedia.org/wiki/Administrative_divisions_of_Singapore
> >
> >
> >
> > On Mon, Jan 25, 2016 at 11:50 AM, Roger Bivand <Roger.Bivand at nhh.no>
> wrote:
> >
> >> On Mon, 25 Jan 2016, Richa Agarwal wrote:
> >>
> >> Hi Guys,
> >>>
> >>> Is there a mapping of administrative areas (as available in shape
> >>> files at the GADM website) to postal codes by country? Also is there
> >>> a source for more detailed shapefiles. Example for Singapore the
> >>> detail available on GADM is just level 1.
> >>>
> >>
> >> In the US, five-digit zip codes are part of the US Census boundary
> >> system, and - as public boundaries - are open for download.
> >>
> >> In most other countries, the boundaries of postal code areas are not
> >> public data, even where the postal service is public, and are usually
> >> only available at substantial cost, and often without permission to
> >> publish maps based on the boundaries.
> >>
> >> In Norway, a Meteorological Office programmer crowd-sourced point
> >> locations to provide a way of offering weather forecast look-up based
> >> on postcode - but those are not boundaries, and indeed are just the
> >> GPS readings of volunteered data.
> >>
> >> Even using commercial APIs to give address points probably will not
> help.
> >>
> >> Roger
> >>
> >>
> >>> http://www.gadm.org/country
> >>>
> >>> Thanks
> >>> Richa
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>>
> >> --
> >> Roger Bivand
> >> Department of Economics, Norwegian School of Economics, Helleveien
> >> 30, N-5045 Bergen, Norway.
> >> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >> e-mail: Roger.Bivand at nhh.no
> >> http://orcid.org/0000-0003-2392-6140
> >> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >> http://depsy.org/person/434412
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From uzzal at gist.ac.kr  Tue Jan 26 18:19:16 2016
From: uzzal at gist.ac.kr (Uzzal)
Date: Wed, 27 Jan 2016 02:19:16 +0900 (KST)
Subject: [R-sig-Geo] How to backtransform the nugget, psill,
	range value obtained from ordinary kriging analysis of
	log-transformed dataset?
Message-ID: <1820397732.1453828756930.JavaMail.root@eunhasu>

I have a dataframe contains hourly PM10 concentrations of 83 measurement sites. Please download from HERE. Using this dataset, I have fitted a model with experimental variogram by ordinary kriging. In exploratory analysis, I found the data was not in normal distribution by checking skewness, histogram and Q-Q plot so I log-transformed the data. I wrote the following code: seoul032813  #exploratory analysisskewness(seoul032813$PM10)
skewness(log10(seoul032813$PM10))hist(seoul032813$PM10) hist(log10(seoul032813$PM10))
qqnorm(seoul030101$PM10,font.main = 1,cex.main = 0.9, main = "Normal Q-Q plot of seoul032813",cex.lab = 0.75);qqline(seoul030101$PM10)
qqnorm(log(seoul030101$PM10),font.main = 1,cex.main = 0.9, main = "Normal Q-Q plot of seoul032813",cex.lab = 0.75);qqline(log(seoul030101$PM10))  #Reprojection
coordinates(seoul032813) seoul032813 at coords <- <a href="mailto:seoul032813 at coords/1000">seoul032813 at coords/1000 #variogram modeling
seoul032813_var From this analysis I got the Range, psill and nugget values. These value are very small due to previous log-transformation of data. I want to get these parameter values in its original form. Also, I got a fitted variogram plot in the last line of my code where semivariance is in log form. I also want to get this plot in its original form. Simply, I want to back transform the variogram parameter values and fitted variogram plot. How can I do this? [Backgroud: Actually, I have many dataset of different hours. Some are in normal distribution and some are not. so, only the dataset which are not in normal distribution I log-transformed them. At last I want to compare Range, sill, nugget of every hour. So, for comparison I need to back transform the sill, range, nugget value obtained from log-transformed dataset] Orpheus  




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160127/332b3cc8/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: bannerBottom.gif
Type: image/gif
Size: 21674 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160127/332b3cc8/attachment.gif>

From uzzal at gist.ac.kr  Wed Jan 27 02:44:29 2016
From: uzzal at gist.ac.kr (Uzzal)
Date: Wed, 27 Jan 2016 10:44:29 +0900 (KST)
Subject: [R-sig-Geo] How to backtransform the nugget, psill,
	range value obtained from ordinary kriging analysis of
	log-transformed dataset using gstat package?
Message-ID: <215813261.1453859069857.JavaMail.root@eunhasu>

I have a dataframe contains hourly PM10 concentrations of 83 measurement sites. Please download from HERE. Using this dataset, I have fitted a model with experimental variogram by ordinary kriging. In exploratory analysis, I found the data was not in normal distribution by checking skewness, histogram and Q-Q plot so I log-transformed the data. I wrote the following code:
library(sp)
library(gstat)
library(rgdal)
library(e1071) 
seoul032813  #exploratory analysisskewness(seoul032813$PM10)
skewness(log10(seoul032813$PM10))hist(seoul032813$PM10) hist(log10(seoul032813$PM10))
qqnorm(seoul030101$PM10,font.main = 1,cex.main = 0.9, main = "Normal Q-Q plot of seoul032813",cex.lab = 0.75);qqline(seoul030101$PM10)
qqnorm(log(seoul030101$PM10),font.main = 1,cex.main = 0.9, main = "Normal Q-Q plot of seoul032813",cex.lab = 0.75);qqline(log(seoul030101$PM10))  #Reprojection
coordinates(seoul032813) seoul032813 at coords <- <a href="mailto:seoul032813 at coords/1000" target="_blank">seoul032813 at coords/1000 #variogram modeling
seoul032813_var From this analysis I got the Range, psill and nugget values. These value are very small due to previous log-transformation of data. I want to get these parameter values in its original form. Also, I got a fitted variogram plot in the last line of my code where semivariance is in log form. I also want to get this plot in its original form. Simply, I want to back transform the variogram parameter values and fitted variogram plot. How can I do this? [Backgroud: Actually, I have many dataset of different hours. Some are in normal distribution and some are not. so, only the dataset which are not in normal distribution I log-transformed them. At last I want to compare Range, sill, nugget of every hour. So, for comparison I need to back transform the sill, range, nugget value obtained from log-transformed dataset] Orpheus  




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160127/f0529dcf/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: bannerBottom.gif
Type: image/gif
Size: 21674 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20160127/f0529dcf/attachment.gif>

From philip.greenwood at unimelb.edu.au  Thu Jan 28 06:03:47 2016
From: philip.greenwood at unimelb.edu.au (Philip Greenwood)
Date: Thu, 28 Jan 2016 05:03:47 +0000
Subject: [R-sig-Geo] rgdal readOGR() problem
Message-ID: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>

I am trying to compute distance spatial weight matrices using rgdal. This works fine in my local test system, but when I deploy my code to our production system I receive the following error when readOGR is executed:

Source: "/tmp/geojson_writer2529085113493086718.json", layer: "OGRGeoJSON"
with 195 features
It has 26 fields, of which 1 list fields
Error : length(fldnms1) == nflds is not TRUE

Any ideas about what the error means?

My local system and the production system are using the same version of rgdal.
Here is the sessionInfo for the system that is having trouble:

> sessionInfo()
R version 3.1.3 (2015-03-09)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS release 6.5 (Final)

locale:
 [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
 [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8
 [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] grid      stats     graphics  grDevices utils     methods   base

other attached packages:
 [1] log4r_0.2          PBSmapping_2.69.76 rgeos_0.3-8        gpclib_1.5-5
 [5] maptools_0.8-36    gdata_2.16.1       RJSONIO_1.3-0      spdep_0.5-88
 [9] Matrix_1.1-5       rgdal_0.9-2        sp_1.1-0           Hmisc_3.16-0
[13] ggplot2_1.0.1      Formula_1.2-1      survival_2.38-1    lattice_0.20-30
[17] psych_1.5.4        classInt_0.1-22

loaded via a namespace (and not attached):
 [1] acepack_1.3-3.3     boot_1.3-15         class_7.3-12
 [4] cluster_2.0.1       coda_0.17-1         colorspace_1.2-6
 [7] deldir_0.1-9        digest_0.6.8        e1071_1.6-4
[10] foreign_0.8-63      gridExtra_0.9.1     gtable_0.1.2
[13] gtools_3.4.2        latticeExtra_0.6-26 LearnBayes_2.15
[16] magrittr_1.5        MASS_7.3-39         mnormt_1.5-2
[19] munsell_0.4.2       nlme_3.1-120        nnet_7.3-9
[22] parallel_3.1.3      plyr_1.8.2          proto_0.3-10
[25] RColorBrewer_1.1-2  Rcpp_0.11.6         reshape2_1.4.1
[28] rpart_4.1-9         scales_0.2.4        splines_3.1

Thanks.
Phil

---
Philip Greenwood
Senior Software Developer
Australian Urban Research Infrastructure Network (AURIN)
Level 2 West, Alice Hoy Building, University of Melbourne
T: +61-(0)3-9035-8549
E: philip.greenwood at unimelb.edu.au


From Roger.Bivand at nhh.no  Thu Jan 28 08:23:30 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 28 Jan 2016 08:23:30 +0100
Subject: [R-sig-Geo] rgdal readOGR() problem
In-Reply-To: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
References: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
Message-ID: <alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>

On Thu, 28 Jan 2016, Philip Greenwood wrote:

> I am trying to compute distance spatial weight matrices using rgdal. 
> This works fine in my local test system, but when I deploy my code to 
> our production system I receive the following error when readOGR is 
> executed:
>
> Source: "/tmp/geojson_writer2529085113493086718.json", layer: "OGRGeoJSON"
> with 195 features
> It has 26 fields, of which 1 list fields
> Error : length(fldnms1) == nflds is not TRUE

Pleaase run traceback() after the error.

Please run ogrInfo() on both systems, and compare the output.

Please check that GDAL is the same version on both systems (I guess it 
isn't - if the file is the same on both systems, it is the only other 
variable element). The GDAL version can be shown by:

getGDALVersionInfo()

and compare with:

getGDALCheckVersion()

to ensure that rgdal was installed using the same version as the GDAL 
shared object that is loaded (this is shown when rgdal is loaded unless 
startup messages are suppressed).

If you check the source code - traceback() shows which function to look in 
- you'll see that this is about the names of list fields (data fields that 
include a list of fields of the same type). Does your input file include 
such list fields?

Hope this helps,

Roger

>
> Any ideas about what the error means?
>
> My local system and the production system are using the same version of 
> rgdal. Here is the sessionInfo for the system that is having trouble:
>
>> sessionInfo()
> R version 3.1.3 (2015-03-09)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Running under: CentOS release 6.5 (Final)
>
> locale:
> [1] LC_CTYPE=en_AU.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_AU.UTF-8        LC_COLLATE=en_AU.UTF-8
> [5] LC_MONETARY=en_AU.UTF-8    LC_MESSAGES=en_AU.UTF-8
> [7] LC_PAPER=en_AU.UTF-8       LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_AU.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] grid      stats     graphics  grDevices utils     methods   base
>
> other attached packages:
> [1] log4r_0.2          PBSmapping_2.69.76 rgeos_0.3-8        gpclib_1.5-5
> [5] maptools_0.8-36    gdata_2.16.1       RJSONIO_1.3-0      spdep_0.5-88
> [9] Matrix_1.1-5       rgdal_0.9-2        sp_1.1-0           Hmisc_3.16-0
> [13] ggplot2_1.0.1      Formula_1.2-1      survival_2.38-1    lattice_0.20-30
> [17] psych_1.5.4        classInt_0.1-22
>
> loaded via a namespace (and not attached):
> [1] acepack_1.3-3.3     boot_1.3-15         class_7.3-12
> [4] cluster_2.0.1       coda_0.17-1         colorspace_1.2-6
> [7] deldir_0.1-9        digest_0.6.8        e1071_1.6-4
> [10] foreign_0.8-63      gridExtra_0.9.1     gtable_0.1.2
> [13] gtools_3.4.2        latticeExtra_0.6-26 LearnBayes_2.15
> [16] magrittr_1.5        MASS_7.3-39         mnormt_1.5-2
> [19] munsell_0.4.2       nlme_3.1-120        nnet_7.3-9
> [22] parallel_3.1.3      plyr_1.8.2          proto_0.3-10
> [25] RColorBrewer_1.1-2  Rcpp_0.11.6         reshape2_1.4.1
> [28] rpart_4.1-9         scales_0.2.4        splines_3.1
>
> Thanks.
> Phil
>
> ---
> Philip Greenwood
> Senior Software Developer
> Australian Urban Research Infrastructure Network (AURIN)
> Level 2 West, Alice Hoy Building, University of Melbourne
> T: +61-(0)3-9035-8549
> E: philip.greenwood at unimelb.edu.au
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From bfalevlist at gmail.com  Sat Jan 30 14:51:12 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Sat, 30 Jan 2016 14:51:12 +0100
Subject: [R-sig-Geo] rgdal 1.1-3 compilation: error of ogrsource.cpp
In-Reply-To: <alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>
References: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
	<alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>
Message-ID: <56ACBFD0.2020106@gmail.com>

Dear List,
please let me know what I'm doing wrong. Installing package rgdal 1.1-3 
with install.packages("rgdal") fails on Ubuntu 14 (gdal version: 2.0.0) 
with this error message during the compilation:
*ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this 
scope.*

The gdal-version info, verbose output of package installation and 
sessionInfo() is provided after my signature.
However the R version is the latest (3.2.3), installation of the package 
failed with similar error message on my previously used R version 
(3.0.2), and therefore I think that the problem is nothing to do with R.
Removing and reinstalling libgdal1-dev, libproj-dev, gdal-bin does not 
solve the problem. Running R as root user produce similar error.

Any help is gratefully appreciated,
?kos Bede-Fazekas
Hungarian Academy of Sciences


----------------
gdal-config --version
2.0.0

ogr2ogr --version
GDAL 2.0.0dev, released 2014/04/16

----------------
configure: CC: gcc -std=gnu99
configure: CXX: g++
configure: rgdal: 1.1-3
checking for /usr/bin/svnversion... yes
configure: svn revision: 594
checking for gdal-config... /usr/local/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 2.0.0
checking GDAL version >= 1.6.3... yes
configure: experimental conditional use of GDAL2
checking for gcc... gcc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking gdal.h usability... yes
checking gdal.h presence... yes
checking for gdal.h... yes
checking gdal: linking with --libs only... yes
checking GDAL: /usr/local/share/gdal/pcs.csv readable... yes
checking proj_api.h usability... yes
checking proj_api.h presence... yes
checking for proj_api.h... yes
checking for pj_init_plus in -lproj... yes
configure: PROJ.4 version: 4.8.0
checking PROJ.4: epsg found and readable... yes
checking PROJ.4: conus found and readable... yes
configure: Package CPP flags:  -I/usr/local/include
configure: Package LIBS:  -L/usr/local/lib -lgdal -lproj
configure: creating ./config.status
config.status: creating src/Makevars
** libs
g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g -c OGR_write.cpp -o 
OGR_write.o
g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g -c gdal-bindings.cpp -o 
gdal-bindings.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c local_stubs.c -o 
local_stubs.o
g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_geom.cpp -o ogr_geom.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c ogr_polygons.c -o 
ogr_polygons.o
g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_proj.cpp -o ogr_proj.o
g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrdrivers.cpp -o 
ogrdrivers.o
g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
-I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
-fstack-protector --param=ssp-buffer-size=4 -Wformat 
-Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrsource.cpp -o 
ogrsource.o
ogrsource.cpp: In function ?SEXPREC* ogrReadColumn(OGRLayer*, SEXP, int, 
int)?:
ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this scope
      case OFTInteger64:
           ^
ogrsource.cpp:470:12: error: ?OFTInteger64? was not declared in this scope
        case OFTInteger64:
             ^
ogrsource.cpp:476:45: error: ?class OGRFeature? has no member named 
?GetFieldAsInteger64?
                  GIntBig nVal64 = poFeature->GetFieldAsInteger64(iField);
                                              ^
ogrsource.cpp: In function ?SEXPREC* ogrReadListColumn(OGRLayer*, SEXP, 
int, int, int)?:
ogrsource.cpp:575:10: error: ?OFTInteger64List? was not declared in this 
scope
      case OFTInteger64List:
           ^
ogrsource.cpp:618:14: error: ?OFTInteger64List? was not declared in this 
scope
          case OFTInteger64List:
               ^
ogrsource.cpp:619:28: error: ?union OGRField? has no member named 
?Integer64List?
            nlist = psField->Integer64List.nCount;
                             ^
ogrsource.cpp:626:32: error: ?union OGRField? has no member named 
?Integer64List?
                        psField->Integer64List.paList[k]);
                                 ^
ogrsource.cpp:629:43: error: ?union OGRField? has no member named 
?Integer64List?
                  GIntBig nVal64 = psField->Integer64List.paList[k];
                                            ^
make: *** [ogrsource.o] Error 1
ERROR: compilation failed for package ?rgdal?
* removing ?/usr/local/lib/R/site-library/rgdal?

The downloaded source packages are in
     ?/tmp/RtmpcN1Gpn/downloaded_packages?
Warning message:
In install.packages("rgdal") :
   installation of package ?rgdal? had non-zero exit status


----------------
 > sessionInfo()
R version 3.2.3 (2015-12-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.3 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

loaded via a namespace (and not attached):
[1] tools_3.2.3


From Roger.Bivand at nhh.no  Sat Jan 30 17:33:56 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 30 Jan 2016 17:33:56 +0100
Subject: [R-sig-Geo] rgdal 1.1-3 compilation: error of ogrsource.cpp
In-Reply-To: <56ACBFD0.2020106@gmail.com>
References: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
	<alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>
	<56ACBFD0.2020106@gmail.com>
Message-ID: <alpine.LFD.2.20.1601301709590.8197@reclus.nhh.no>

On Sat, 30 Jan 2016, Bede-Fazekas ?kos wrote:

> Dear List,
> please let me know what I'm doing wrong. Installing package rgdal 1.1-3 with 
> install.packages("rgdal") fails on Ubuntu 14 (gdal version: 2.0.0) with this 
> error message during the compilation:
> *ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this scope.*
>
> The gdal-version info, verbose output of package installation and 
> sessionInfo() is provided after my signature.

Thanks for a clear report. The GDAL version is declared as 2.0.0. The 
released 2.0.* implement RFC 31:

(https://trac.osgeo.org/gdal/wiki/rfc31_ogr_64)

using long integers for FIDs and allowing them as field values. Since the 
GDAL you are using declares itself as 2.*, the code forks to take 
advantage of the new capability.

How did you install GDAL? Is it possible that the version you have is 
pre-release? The development trunk was named 2.0.0 for quite a long time, 
but implementations of changes happened at different times along the way? 
Is it possible that you have mixed (multiple) GDAL installations, with 1.* 
headers and 2.0 gdal-config?

Roger

> However the R version is the latest (3.2.3), installation of the package 
> failed with similar error message on my previously used R version (3.0.2), 
> and therefore I think that the problem is nothing to do with R.
> Removing and reinstalling libgdal1-dev, libproj-dev, gdal-bin does not solve 
> the problem. Running R as root user produce similar error.
>
> Any help is gratefully appreciated,
> ?kos Bede-Fazekas
> Hungarian Academy of Sciences
>
>
> ----------------
> gdal-config --version
> 2.0.0
>
> ogr2ogr --version
> GDAL 2.0.0dev, released 2014/04/16
>
> ----------------
> configure:  CC: gcc -std=gnu99
> configure:  CXX: g++
> configure:  rgdal: 1.1-3
> checking for /usr/bin/svnversion... yes
> configure:  svn revision: 594
> checking for gdal-config... /usr/local/bin/gdal-config
> checking gdal-config usability... yes
> configure:  GDAL: 2.0.0
> checking GDAL version >= 1.6.3... yes
> configure:  experimental conditional use of GDAL2
> checking for gcc... gcc -std=gnu99
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking gdal.h usability... yes
> checking gdal.h presence... yes
> checking for gdal.h... yes
> checking gdal: linking with --libs only... yes
> checking GDAL: /usr/local/share/gdal/pcs.csv readable... yes
> checking proj_api.h usability... yes
> checking proj_api.h presence... yes
> checking for proj_api.h... yes
> checking for pj_init_plus in -lproj... yes
> configure:  PROJ.4 version: 4.8.0
> checking PROJ.4: epsg found and readable... yes
> checking PROJ.4: conus found and readable... yes
> configure:  Package CPP flags:  -I/usr/local/include
> configure:  Package LIBS:  -L/usr/local/lib -lgdal -lproj
> configure:  creating ./config.status
> config.status: creating src/Makevars
> ** libs
> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g -c OGR_write.cpp -o OGR_write.o
> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g -c gdal-bindings.cpp -o gdal-bindings.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g  -c local_stubs.c -o local_stubs.o
> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g -c ogr_geom.cpp -o ogr_geom.o
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g  -c ogr_polygons.c -o ogr_polygons.o
> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g -c ogr_proj.cpp -o ogr_proj.o
> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g -c ogrdrivers.cpp -o ogrdrivers.o
> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security 
> -D_FORTIFY_SOURCE=2 -g -c ogrsource.cpp -o ogrsource.o
> ogrsource.cpp: In function ?SEXPREC* ogrReadColumn(OGRLayer*, SEXP, int, 
> int)?:
> ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this scope
>     case OFTInteger64:
>          ^
> ogrsource.cpp:470:12: error: ?OFTInteger64? was not declared in this scope
>       case OFTInteger64:
>            ^
> ogrsource.cpp:476:45: error: ?class OGRFeature? has no member named 
> ?GetFieldAsInteger64?
>                 GIntBig nVal64 = poFeature->GetFieldAsInteger64(iField);
>                                             ^
> ogrsource.cpp: In function ?SEXPREC* ogrReadListColumn(OGRLayer*, SEXP, int, 
> int, int)?:
> ogrsource.cpp:575:10: error: ?OFTInteger64List? was not declared in this 
> scope
>     case OFTInteger64List:
>          ^
> ogrsource.cpp:618:14: error: ?OFTInteger64List? was not declared in this 
> scope
>         case OFTInteger64List:
>              ^
> ogrsource.cpp:619:28: error: ?union OGRField? has no member named 
> ?Integer64List?
>           nlist = psField->Integer64List.nCount;
>                            ^
> ogrsource.cpp:626:32: error: ?union OGRField? has no member named 
> ?Integer64List?
>                       psField->Integer64List.paList[k]);
>                                ^
> ogrsource.cpp:629:43: error: ?union OGRField? has no member named 
> ?Integer64List?
>                 GIntBig nVal64 = psField->Integer64List.paList[k];
>                                           ^
> make: *** [ogrsource.o] Error 1
> ERROR: compilation failed for package ?rgdal?
> * removing ?/usr/local/lib/R/site-library/rgdal?
>
> The downloaded source packages are in
>    ?/tmp/RtmpcN1Gpn/downloaded_packages?
> Warning message:
> In install.packages("rgdal") :
>   installation of package ?rgdal? had non-zero exit status
>
>
> ----------------
>>  sessionInfo()
> R version 3.2.3 (2015-12-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.3 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> loaded via a namespace (and not attached):
> [1] tools_3.2.3
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From bfalevlist at gmail.com  Sun Jan 31 12:21:50 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Sun, 31 Jan 2016 12:21:50 +0100
Subject: [R-sig-Geo] rgdal 1.1-3 compilation: error of ogrsource.cpp
In-Reply-To: <alpine.LFD.2.20.1601301709590.8197@reclus.nhh.no>
References: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
	<alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>
	<56ACBFD0.2020106@gmail.com>
	<alpine.LFD.2.20.1601301709590.8197@reclus.nhh.no>
Message-ID: <56ADEE4E.4000500@gmail.com>

Dear Roger,
it is really probable that some gdal versions were mixed. It was long 
time ago when I installed gdal but as far as I remember it was compiled 
from source. I would be very happy if I could uninstall it and start 
again from the base, but don't know how to do it. "make uninstall" 
fails, reinstalling also fails, no other ways I'm aware of.
Thanks for any help,
?kos

2016.01.30. 17:33 keltez?ssel, Roger Bivand ?rta:
> On Sat, 30 Jan 2016, Bede-Fazekas ?kos wrote:
>
>> Dear List,
>> please let me know what I'm doing wrong. Installing package rgdal 
>> 1.1-3 with install.packages("rgdal") fails on Ubuntu 14 (gdal 
>> version: 2.0.0) with this error message during the compilation:
>> *ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this 
>> scope.*
>>
>> The gdal-version info, verbose output of package installation and 
>> sessionInfo() is provided after my signature.
>
> Thanks for a clear report. The GDAL version is declared as 2.0.0. The 
> released 2.0.* implement RFC 31:
>
> (https://trac.osgeo.org/gdal/wiki/rfc31_ogr_64)
>
> using long integers for FIDs and allowing them as field values. Since 
> the GDAL you are using declares itself as 2.*, the code forks to take 
> advantage of the new capability.
>
> How did you install GDAL? Is it possible that the version you have is 
> pre-release? The development trunk was named 2.0.0 for quite a long 
> time, but implementations of changes happened at different times along 
> the way? Is it possible that you have mixed (multiple) GDAL 
> installations, with 1.* headers and 2.0 gdal-config?
>
> Roger
>
>> However the R version is the latest (3.2.3), installation of the 
>> package failed with similar error message on my previously used R 
>> version (3.0.2), and therefore I think that the problem is nothing to 
>> do with R.
>> Removing and reinstalling libgdal1-dev, libproj-dev, gdal-bin does 
>> not solve the problem. Running R as root user produce similar error.
>>
>> Any help is gratefully appreciated,
>> ?kos Bede-Fazekas
>> Hungarian Academy of Sciences
>>
>>
>> ----------------
>> gdal-config --version
>> 2.0.0
>>
>> ogr2ogr --version
>> GDAL 2.0.0dev, released 2014/04/16
>>
>> ----------------
>> configure:  CC: gcc -std=gnu99
>> configure:  CXX: g++
>> configure:  rgdal: 1.1-3
>> checking for /usr/bin/svnversion... yes
>> configure:  svn revision: 594
>> checking for gdal-config... /usr/local/bin/gdal-config
>> checking gdal-config usability... yes
>> configure:  GDAL: 2.0.0
>> checking GDAL version >= 1.6.3... yes
>> configure:  experimental conditional use of GDAL2
>> checking for gcc... gcc -std=gnu99
>> checking whether the C compiler works... yes
>> checking for C compiler default output file name... a.out
>> checking for suffix of executables...
>> checking whether we are cross compiling... no
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc -std=gnu99 accepts -g... yes
>> checking for gcc -std=gnu99 option to accept ISO C89... none needed
>> checking how to run the C preprocessor... gcc -std=gnu99 -E
>> checking for grep that handles long lines and -e... /bin/grep
>> checking for egrep... /bin/grep -E
>> checking for ANSI C header files... yes
>> checking for sys/types.h... yes
>> checking for sys/stat.h... yes
>> checking for stdlib.h... yes
>> checking for string.h... yes
>> checking for memory.h... yes
>> checking for strings.h... yes
>> checking for inttypes.h... yes
>> checking for stdint.h... yes
>> checking for unistd.h... yes
>> checking gdal.h usability... yes
>> checking gdal.h presence... yes
>> checking for gdal.h... yes
>> checking gdal: linking with --libs only... yes
>> checking GDAL: /usr/local/share/gdal/pcs.csv readable... yes
>> checking proj_api.h usability... yes
>> checking proj_api.h presence... yes
>> checking for proj_api.h... yes
>> checking for pj_init_plus in -lproj... yes
>> configure:  PROJ.4 version: 4.8.0
>> checking PROJ.4: epsg found and readable... yes
>> checking PROJ.4: conus found and readable... yes
>> configure:  Package CPP flags:  -I/usr/local/include
>> configure:  Package LIBS:  -L/usr/local/lib -lgdal -lproj
>> configure:  creating ./config.status
>> config.status: creating src/Makevars
>> ** libs
>> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c OGR_write.cpp -o 
>> OGR_write.o
>> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c gdal-bindings.cpp 
>> -o gdal-bindings.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c local_stubs.c -o 
>> local_stubs.o
>> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_geom.cpp -o 
>> ogr_geom.o
>> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c ogr_polygons.c -o 
>> ogr_polygons.o
>> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_proj.cpp -o 
>> ogr_proj.o
>> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrdrivers.cpp -o 
>> ogrdrivers.o
>> g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrsource.cpp -o 
>> ogrsource.o
>> ogrsource.cpp: In function ?SEXPREC* ogrReadColumn(OGRLayer*, SEXP, 
>> int, int)?:
>> ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this 
>> scope
>>     case OFTInteger64:
>>          ^
>> ogrsource.cpp:470:12: error: ?OFTInteger64? was not declared in this 
>> scope
>>       case OFTInteger64:
>>            ^
>> ogrsource.cpp:476:45: error: ?class OGRFeature? has no member named 
>> ?GetFieldAsInteger64?
>>                 GIntBig nVal64 = poFeature->GetFieldAsInteger64(iField);
>>                                             ^
>> ogrsource.cpp: In function ?SEXPREC* ogrReadListColumn(OGRLayer*, 
>> SEXP, int, int, int)?:
>> ogrsource.cpp:575:10: error: ?OFTInteger64List? was not declared in 
>> this scope
>>     case OFTInteger64List:
>>          ^
>> ogrsource.cpp:618:14: error: ?OFTInteger64List? was not declared in 
>> this scope
>>         case OFTInteger64List:
>>              ^
>> ogrsource.cpp:619:28: error: ?union OGRField? has no member named 
>> ?Integer64List?
>>           nlist = psField->Integer64List.nCount;
>>                            ^
>> ogrsource.cpp:626:32: error: ?union OGRField? has no member named 
>> ?Integer64List?
>>                       psField->Integer64List.paList[k]);
>>                                ^
>> ogrsource.cpp:629:43: error: ?union OGRField? has no member named 
>> ?Integer64List?
>>                 GIntBig nVal64 = psField->Integer64List.paList[k];
>>                                           ^
>> make: *** [ogrsource.o] Error 1
>> ERROR: compilation failed for package ?rgdal?
>> * removing ?/usr/local/lib/R/site-library/rgdal?
>>
>> The downloaded source packages are in
>>    ?/tmp/RtmpcN1Gpn/downloaded_packages?
>> Warning message:
>> In install.packages("rgdal") :
>>   installation of package ?rgdal? had non-zero exit status
>>
>>
>> ----------------
>>>  sessionInfo()
>> R version 3.2.3 (2015-12-10)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.3 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.2.3
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>


From Roger.Bivand at nhh.no  Sun Jan 31 13:59:17 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 31 Jan 2016 13:59:17 +0100
Subject: [R-sig-Geo] rgdal 1.1-3 compilation: error of ogrsource.cpp
In-Reply-To: <56ADEE4E.4000500@gmail.com>
References: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
	<alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>
	<56ACBFD0.2020106@gmail.com>
	<alpine.LFD.2.20.1601301709590.8197@reclus.nhh.no>
	<56ADEE4E.4000500@gmail.com>
Message-ID: <alpine.LFD.2.20.1601311348150.12897@reclus.nhh.no>

On Sun, 31 Jan 2016, Bede-Fazekas ?kos wrote:

> Dear Roger,
> it is really probable that some gdal versions were mixed. It was long time 
> ago when I installed gdal but as far as I remember it was compiled from 
> source. I would be very happy if I could uninstall it and start again from 
> the base, but don't know how to do it. "make uninstall" fails, reinstalling 
> also fails, no other ways I'm aware of.

Looking more closely at your report, I see:

>> >  ogr2ogr --version
>> >  GDAL 2.0.0dev, released 2014/04/16

2.0.0 was released in June 2015 (and 2.0.2 has just been released). You 
very likely have installed headers that date from before the revisions 
introducing handling of 64-bit integers, but where the version of GDAL 
declares itself to be 2.0.0. I suggest you use locate from the shell to 
find any ogr_api.h files on your system. You could use

gdal-config --cflags

but this could be misleading if you have multiple gdal-config installed. 
Find out whether any ogr_api.h contains references to GIntBig, and delete 
all prior to that. It may be safest to locate all the *gdal*, *cpl* and 
*ogr* components and remove them, running make install again from a fresh 
source build of GDAL 2.0.2.

Hope this helps,

Roger


> Thanks for any help,
> ?kos
>
> 2016.01.30. 17:33 keltez?ssel, Roger Bivand ?rta:
>>  On Sat, 30 Jan 2016, Bede-Fazekas ?kos wrote:
>> 
>> >  Dear List,
>> >  please let me know what I'm doing wrong. Installing package rgdal 1.1-3 
>> >  with install.packages("rgdal") fails on Ubuntu 14 (gdal version: 2.0.0) 
>> >  with this error message during the compilation:
>> >  *ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this 
>> >  scope.*
>> > 
>> >  The gdal-version info, verbose output of package installation and 
>> >  sessionInfo() is provided after my signature.
>>
>>  Thanks for a clear report. The GDAL version is declared as 2.0.0. The
>>  released 2.0.* implement RFC 31:
>>
>>  (https://trac.osgeo.org/gdal/wiki/rfc31_ogr_64)
>>
>>  using long integers for FIDs and allowing them as field values. Since the
>>  GDAL you are using declares itself as 2.*, the code forks to take
>>  advantage of the new capability.
>>
>>  How did you install GDAL? Is it possible that the version you have is
>>  pre-release? The development trunk was named 2.0.0 for quite a long time,
>>  but implementations of changes happened at different times along the way?
>>  Is it possible that you have mixed (multiple) GDAL installations, with 1.*
>>  headers and 2.0 gdal-config?
>>
>>  Roger
>> 
>> >  However the R version is the latest (3.2.3), installation of the package 
>> >  failed with similar error message on my previously used R version 
>> >  (3.0.2), and therefore I think that the problem is nothing to do with R.
>> >  Removing and reinstalling libgdal1-dev, libproj-dev, gdal-bin does not 
>> >  solve the problem. Running R as root user produce similar error.
>> > 
>> >  Any help is gratefully appreciated,
>> >  ?kos Bede-Fazekas
>> >  Hungarian Academy of Sciences
>> > 
>> > 
>> >  ----------------
>> >  gdal-config --version
>> >  2.0.0
>> > 
>> >  ogr2ogr --version
>> >  GDAL 2.0.0dev, released 2014/04/16
>> > 
>> >  ----------------
>> > configure:   CC: gcc -std=gnu99
>> > configure:   CXX: g++
>> > configure:   rgdal: 1.1-3
>> >  checking for /usr/bin/svnversion... yes
>> >  configure:  svn revision: 594
>> >  checking for gdal-config... /usr/local/bin/gdal-config
>> >  checking gdal-config usability... yes
>> >  configure:  GDAL: 2.0.0
>> >  checking GDAL version >= 1.6.3... yes
>> >  configure:  experimental conditional use of GDAL2
>> >  checking for gcc... gcc -std=gnu99
>> >  checking whether the C compiler works... yes
>> >  checking for C compiler default output file name... a.out
>> >  checking for suffix of executables...
>> >  checking whether we are cross compiling... no
>> >  checking for suffix of object files... o
>> >  checking whether we are using the GNU C compiler... yes
>> >  checking whether gcc -std=gnu99 accepts -g... yes
>> >  checking for gcc -std=gnu99 option to accept ISO C89... none needed
>> >  checking how to run the C preprocessor... gcc -std=gnu99 -E
>> >  checking for grep that handles long lines and -e... /bin/grep
>> >  checking for egrep... /bin/grep -E
>> >  checking for ANSI C header files... yes
>> >  checking for sys/types.h... yes
>> >  checking for sys/stat.h... yes
>> >  checking for stdlib.h... yes
>> >  checking for string.h... yes
>> >  checking for memory.h... yes
>> >  checking for strings.h... yes
>> >  checking for inttypes.h... yes
>> >  checking for stdint.h... yes
>> >  checking for unistd.h... yes
>> >  checking gdal.h usability... yes
>> >  checking gdal.h presence... yes
>> >  checking for gdal.h... yes
>> >  checking gdal: linking with --libs only... yes
>> >  checking GDAL: /usr/local/share/gdal/pcs.csv readable... yes
>> >  checking proj_api.h usability... yes
>> >  checking proj_api.h presence... yes
>> >  checking for proj_api.h... yes
>> >  checking for pj_init_plus in -lproj... yes
>> >  configure:  PROJ.4 version: 4.8.0
>> >  checking PROJ.4: epsg found and readable... yes
>> >  checking PROJ.4: conus found and readable... yes
>> > configure:   Package CPP flags:  -I/usr/local/include
>> > configure:   Package LIBS:  -L/usr/local/lib -lgdal -lproj
>> > configure:   creating ./config.status
>> >  config.status: creating src/Makevars
>> >  ** libs
>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c OGR_write.cpp -o 
>> >  OGR_write.o
>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c gdal-bindings.cpp -o 
>> >  gdal-bindings.o
>> >  gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
>> >  gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c local_stubs.c -o 
>> >  local_stubs.o
>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_geom.cpp -o 
>> >  ogr_geom.o
>> >  gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c ogr_polygons.c -o 
>> >  ogr_polygons.o
>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_proj.cpp -o 
>> >  ogr_proj.o
>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrdrivers.cpp -o 
>> >  ogrdrivers.o
>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG -I/usr/local/include 
>> >  -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 
>> >  -fstack-protector --param=ssp-buffer-size=4 -Wformat 
>> >  -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrsource.cpp -o 
>> >  ogrsource.o
>> >  ogrsource.cpp: In function ?SEXPREC* ogrReadColumn(OGRLayer*, SEXP, int, 
>> >  int)?:
>> >  ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in this 
>> >  scope
>> >      case OFTInteger64:
>> >           ^
>> >  ogrsource.cpp:470:12: error: ?OFTInteger64? was not declared in this 
>> >  scope
>> >        case OFTInteger64:
>> >             ^
>> >  ogrsource.cpp:476:45: error: ?class OGRFeature? has no member named 
>> >  ?GetFieldAsInteger64?
>> >                  GIntBig nVal64 = poFeature->GetFieldAsInteger64(iField);
>> >                                              ^
>> >  ogrsource.cpp: In function ?SEXPREC* ogrReadListColumn(OGRLayer*, SEXP, 
>> >  int, int, int)?:
>> >  ogrsource.cpp:575:10: error: ?OFTInteger64List? was not declared in this 
>> >  scope
>> >      case OFTInteger64List:
>> >           ^
>> >  ogrsource.cpp:618:14: error: ?OFTInteger64List? was not declared in this 
>> >  scope
>> >          case OFTInteger64List:
>> >               ^
>> >  ogrsource.cpp:619:28: error: ?union OGRField? has no member named 
>> >  ?Integer64List?
>> >            nlist = psField->Integer64List.nCount;
>> >                             ^
>> >  ogrsource.cpp:626:32: error: ?union OGRField? has no member named 
>> >  ?Integer64List?
>> >                        psField->Integer64List.paList[k]);
>> >                                 ^
>> >  ogrsource.cpp:629:43: error: ?union OGRField? has no member named 
>> >  ?Integer64List?
>> >                  GIntBig nVal64 = psField->Integer64List.paList[k];
>> >                                            ^
>> >  make: *** [ogrsource.o] Error 1
>> >  ERROR: compilation failed for package ?rgdal?
>> >  * removing ?/usr/local/lib/R/site-library/rgdal?
>> > 
>> >  The downloaded source packages are in
>> >     ?/tmp/RtmpcN1Gpn/downloaded_packages?
>> >  Warning message:
>> >  In install.packages("rgdal") :
>> >    installation of package ?rgdal? had non-zero exit status
>> > 
>> > 
>> >  ----------------
>> > >   sessionInfo()
>> >  R version 3.2.3 (2015-12-10)
>> >  Platform: x86_64-pc-linux-gnu (64-bit)
>> >  Running under: Ubuntu 14.04.3 LTS
>> > 
>> >  locale:
>> >   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> >   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> >   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> >   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>> >   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> >  [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> > 
>> >  attached base packages:
>> >  [1] stats     graphics  grDevices utils     datasets  methods base
>> > 
>> >  loaded via a namespace (and not attached):
>> >  [1] tools_3.2.3
>> > 
>> >  _______________________________________________
>> >  R-sig-Geo mailing list
>> >  R-sig-Geo at r-project.org
>> >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > 
>> > 
>> 
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From bfalevlist at gmail.com  Sun Jan 31 19:03:24 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Sun, 31 Jan 2016 19:03:24 +0100
Subject: [R-sig-Geo] rgdal 1.1-3 compilation: error of ogrsource.cpp
In-Reply-To: <alpine.LFD.2.20.1601311348150.12897@reclus.nhh.no>
References: <43D886B7-BD94-469D-BDD6-3483BF4987E0@unimelb.edu.au>
	<alpine.LFD.2.20.1601280814550.13018@reclus.nhh.no>
	<56ACBFD0.2020106@gmail.com>
	<alpine.LFD.2.20.1601301709590.8197@reclus.nhh.no>
	<56ADEE4E.4000500@gmail.com>
	<alpine.LFD.2.20.1601311348150.12897@reclus.nhh.no>
Message-ID: <56AE4C6C.4000509@gmail.com>

Thank you, Roger!
It is now solved. Hereinafter I just provide information about this 
issue and how it was solved for those who are interested in.
Best wishes,
?kos Bede-Fazekas

Only two ogr_api.h files were situated in my hard drive, and they were 
exactly the same. One was in the directory where gdal were compiled 
from, the other was in
/usr/local/include
Only one line mentioned GIntBig:
GIntBig CPL_DLL OGR_L_GetFeaturesRead( OGRLayerH );
Header of ogr_api.h was:
"$Id: ogr_api.h 28008 2014-11-26 12:41:43Z rouault $"

Deletion (backuping) ogr_api.h, downloading the newest gdal source, 
compiling it, running ldconfig (because of " libgdal.so.20: cannot open 
shared object file: No such file or directory" during installation of 
rgdal package) and install rgdal from R solved the problem:

sudo mv /usr/local/include/ ogr_api.h /usr/local/include/ ogr_api.h.bak
wget -A.gz ?http://download.osgeo.org/gdal/2.0.2/gdal-2.0.2.tar.gz
tar xzf gdal-2.0.2.tar.gz
cd gdal-2.0.2
./configure
sudo make
sudo make install
sudo ldconfig
sudo R
install.packages("rgdal")

2016.01.31. 13:59 keltez?ssel, Roger Bivand ?rta:
> On Sun, 31 Jan 2016, Bede-Fazekas ?kos wrote:
>
>> Dear Roger,
>> it is really probable that some gdal versions were mixed. It was long 
>> time ago when I installed gdal but as far as I remember it was 
>> compiled from source. I would be very happy if I could uninstall it 
>> and start again from the base, but don't know how to do it. "make 
>> uninstall" fails, reinstalling also fails, no other ways I'm aware of.
>
> Looking more closely at your report, I see:
>
>>> >  ogr2ogr --version
>>> >  GDAL 2.0.0dev, released 2014/04/16
>
> 2.0.0 was released in June 2015 (and 2.0.2 has just been released). 
> You very likely have installed headers that date from before the 
> revisions introducing handling of 64-bit integers, but where the 
> version of GDAL declares itself to be 2.0.0. I suggest you use locate 
> from the shell to find any ogr_api.h files on your system. You could use
>
> gdal-config --cflags
>
> but this could be misleading if you have multiple gdal-config 
> installed. Find out whether any ogr_api.h contains references to 
> GIntBig, and delete all prior to that. It may be safest to locate all 
> the *gdal*, *cpl* and *ogr* components and remove them, running make 
> install again from a fresh source build of GDAL 2.0.2.
>
> Hope this helps,
>
> Roger
>
>
>> Thanks for any help,
>> ?kos
>>
>> 2016.01.30. 17:33 keltez?ssel, Roger Bivand ?rta:
>>>  On Sat, 30 Jan 2016, Bede-Fazekas ?kos wrote:
>>>
>>> >  Dear List,
>>> >  please let me know what I'm doing wrong. Installing package rgdal 
>>> 1.1-3 >  with install.packages("rgdal") fails on Ubuntu 14 (gdal 
>>> version: 2.0.0) >  with this error message during the compilation:
>>> >  *ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in 
>>> this >  scope.*
>>> > >  The gdal-version info, verbose output of package installation 
>>> and >  sessionInfo() is provided after my signature.
>>>
>>>  Thanks for a clear report. The GDAL version is declared as 2.0.0. The
>>>  released 2.0.* implement RFC 31:
>>>
>>>  (https://trac.osgeo.org/gdal/wiki/rfc31_ogr_64)
>>>
>>>  using long integers for FIDs and allowing them as field values. 
>>> Since the
>>>  GDAL you are using declares itself as 2.*, the code forks to take
>>>  advantage of the new capability.
>>>
>>>  How did you install GDAL? Is it possible that the version you have is
>>>  pre-release? The development trunk was named 2.0.0 for quite a long 
>>> time,
>>>  but implementations of changes happened at different times along 
>>> the way?
>>>  Is it possible that you have mixed (multiple) GDAL installations, 
>>> with 1.*
>>>  headers and 2.0 gdal-config?
>>>
>>>  Roger
>>>
>>> >  However the R version is the latest (3.2.3), installation of the 
>>> package >  failed with similar error message on my previously used R 
>>> version >  (3.0.2), and therefore I think that the problem is 
>>> nothing to do with R.
>>> >  Removing and reinstalling libgdal1-dev, libproj-dev, gdal-bin 
>>> does not >  solve the problem. Running R as root user produce 
>>> similar error.
>>> > >  Any help is gratefully appreciated,
>>> >  ?kos Bede-Fazekas
>>> >  Hungarian Academy of Sciences
>>> > > >  ----------------
>>> >  gdal-config --version
>>> >  2.0.0
>>> > >  ogr2ogr --version
>>> >  GDAL 2.0.0dev, released 2014/04/16
>>> > >  ----------------
>>> > configure:   CC: gcc -std=gnu99
>>> > configure:   CXX: g++
>>> > configure:   rgdal: 1.1-3
>>> >  checking for /usr/bin/svnversion... yes
>>> >  configure:  svn revision: 594
>>> >  checking for gdal-config... /usr/local/bin/gdal-config
>>> >  checking gdal-config usability... yes
>>> >  configure:  GDAL: 2.0.0
>>> >  checking GDAL version >= 1.6.3... yes
>>> >  configure:  experimental conditional use of GDAL2
>>> >  checking for gcc... gcc -std=gnu99
>>> >  checking whether the C compiler works... yes
>>> >  checking for C compiler default output file name... a.out
>>> >  checking for suffix of executables...
>>> >  checking whether we are cross compiling... no
>>> >  checking for suffix of object files... o
>>> >  checking whether we are using the GNU C compiler... yes
>>> >  checking whether gcc -std=gnu99 accepts -g... yes
>>> >  checking for gcc -std=gnu99 option to accept ISO C89... none needed
>>> >  checking how to run the C preprocessor... gcc -std=gnu99 -E
>>> >  checking for grep that handles long lines and -e... /bin/grep
>>> >  checking for egrep... /bin/grep -E
>>> >  checking for ANSI C header files... yes
>>> >  checking for sys/types.h... yes
>>> >  checking for sys/stat.h... yes
>>> >  checking for stdlib.h... yes
>>> >  checking for string.h... yes
>>> >  checking for memory.h... yes
>>> >  checking for strings.h... yes
>>> >  checking for inttypes.h... yes
>>> >  checking for stdint.h... yes
>>> >  checking for unistd.h... yes
>>> >  checking gdal.h usability... yes
>>> >  checking gdal.h presence... yes
>>> >  checking for gdal.h... yes
>>> >  checking gdal: linking with --libs only... yes
>>> >  checking GDAL: /usr/local/share/gdal/pcs.csv readable... yes
>>> >  checking proj_api.h usability... yes
>>> >  checking proj_api.h presence... yes
>>> >  checking for proj_api.h... yes
>>> >  checking for pj_init_plus in -lproj... yes
>>> >  configure:  PROJ.4 version: 4.8.0
>>> >  checking PROJ.4: epsg found and readable... yes
>>> >  checking PROJ.4: conus found and readable... yes
>>> > configure:   Package CPP flags:  -I/usr/local/include
>>> > configure:   Package LIBS:  -L/usr/local/lib -lgdal -lproj
>>> > configure:   creating ./config.status
>>> >  config.status: creating src/Makevars
>>> >  ** libs
>>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c OGR_write.cpp -o 
>>> >  OGR_write.o
>>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c gdal-bindings.cpp 
>>> -o >  gdal-bindings.o
>>> >  gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
>>> >  gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c local_stubs.c -o 
>>> >  local_stubs.o
>>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_geom.cpp -o >  
>>> ogr_geom.o
>>> >  gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g  -c ogr_polygons.c -o 
>>> >  ogr_polygons.o
>>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogr_proj.cpp -o >  
>>> ogr_proj.o
>>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrdrivers.cpp -o 
>>> >  ogrdrivers.o
>>> >  g++ -std=c++11 -I/usr/share/R/include -DNDEBUG 
>>> -I/usr/local/include > 
>>> -I"/usr/local/lib/R/site-library/sp/include"   -fpic  -g -O2 >  
>>> -fstack-protector --param=ssp-buffer-size=4 -Wformat >  
>>> -Werror=format-security -D_FORTIFY_SOURCE=2 -g -c ogrsource.cpp -o 
>>> >  ogrsource.o
>>> >  ogrsource.cpp: In function ?SEXPREC* ogrReadColumn(OGRLayer*, 
>>> SEXP, int, >  int)?:
>>> >  ogrsource.cpp:413:10: error: ?OFTInteger64? was not declared in 
>>> this >  scope
>>> >      case OFTInteger64:
>>> >           ^
>>> >  ogrsource.cpp:470:12: error: ?OFTInteger64? was not declared in 
>>> this >  scope
>>> >        case OFTInteger64:
>>> >             ^
>>> >  ogrsource.cpp:476:45: error: ?class OGRFeature? has no member 
>>> named >  ?GetFieldAsInteger64?
>>> >                  GIntBig nVal64 = 
>>> poFeature->GetFieldAsInteger64(iField);
>>> >                                              ^
>>> >  ogrsource.cpp: In function ?SEXPREC* ogrReadListColumn(OGRLayer*, 
>>> SEXP, >  int, int, int)?:
>>> >  ogrsource.cpp:575:10: error: ?OFTInteger64List? was not declared 
>>> in this >  scope
>>> >      case OFTInteger64List:
>>> >           ^
>>> >  ogrsource.cpp:618:14: error: ?OFTInteger64List? was not declared 
>>> in this >  scope
>>> >          case OFTInteger64List:
>>> >               ^
>>> >  ogrsource.cpp:619:28: error: ?union OGRField? has no member named 
>>> >  ?Integer64List?
>>> >            nlist = psField->Integer64List.nCount;
>>> >                             ^
>>> >  ogrsource.cpp:626:32: error: ?union OGRField? has no member named 
>>> >  ?Integer64List?
>>> > psField->Integer64List.paList[k]);
>>> >                                 ^
>>> >  ogrsource.cpp:629:43: error: ?union OGRField? has no member named 
>>> >  ?Integer64List?
>>> >                  GIntBig nVal64 = psField->Integer64List.paList[k];
>>> >                                            ^
>>> >  make: *** [ogrsource.o] Error 1
>>> >  ERROR: compilation failed for package ?rgdal?
>>> >  * removing ?/usr/local/lib/R/site-library/rgdal?
>>> > >  The downloaded source packages are in
>>> >     ?/tmp/RtmpcN1Gpn/downloaded_packages?
>>> >  Warning message:
>>> >  In install.packages("rgdal") :
>>> >    installation of package ?rgdal? had non-zero exit status
>>> > > >  ----------------
>>> > >   sessionInfo()
>>> >  R version 3.2.3 (2015-12-10)
>>> >  Platform: x86_64-pc-linux-gnu (64-bit)
>>> >  Running under: Ubuntu 14.04.3 LTS
>>> > >  locale:
>>> >   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>> >   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>> >   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>> >   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>> >   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> >  [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>> > >  attached base packages:
>>> >  [1] stats     graphics  grDevices utils     datasets methods base
>>> > >  loaded via a namespace (and not attached):
>>> >  [1] tools_3.2.3
>>> > >  _______________________________________________
>>> >  R-sig-Geo mailing list
>>> >  R-sig-Geo at r-project.org
>>> >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > >
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From tyler.j.frazier at icloud.com  Sun Jan 31 20:01:50 2016
From: tyler.j.frazier at icloud.com (Tyler Frazier)
Date: Sun, 31 Jan 2016 14:01:50 -0500
Subject: [R-sig-Geo] Tearing of polygons using ggmap & readOGR
Message-ID: <AAD62D6C-EC13-43B2-A702-2904C8629417@icloud.com>

I'm trying to incorporate a simple shapefile of US states with ggmap and keep getting "tearing" of my polygons. I tried changing group=id to group=group which seemed to partially solve the problem, but not entirely.

library(rgdal)

states <- readOGR(dsn="shapefiles", layer="states")

proj4string(states)

[1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"

states <- spTransform(states, CRS("+proj=longlat +datum=WGS84"))

states <- fortify(states)

sstates <- get_map(location = c(-81, 35, -69, 45), zoom = 4, maptype = "watercolor")

sstates <- ggmap(sstates)

sstates <- sstates + geom_polygon(aes(x = long, y = lat, group=group), data = states, color ="white", fill ="orangered4", alpha = .4, size = .2)

Here is an image of the output.

http://pasteboard.co/1d7kiRfw.png <http://pasteboard.co/1d7kiRfw.png>


	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Sun Jan 31 21:35:56 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 31 Jan 2016 21:35:56 +0100
Subject: [R-sig-Geo] Tearing of polygons using ggmap & readOGR
In-Reply-To: <AAD62D6C-EC13-43B2-A702-2904C8629417@icloud.com>
References: <AAD62D6C-EC13-43B2-A702-2904C8629417@icloud.com>
Message-ID: <alpine.LFD.2.20.1601312128360.18713@reclus.nhh.no>

On Sun, 31 Jan 2016, Tyler Frazier wrote:

> I'm trying to incorporate a simple shapefile of US states with ggmap and keep getting "tearing" of my polygons. I tried changing group=id to group=group which seemed to partially solve the problem, but not entirely.
>
> library(rgdal)
>
> states <- readOGR(dsn="shapefiles", layer="states")
>
> proj4string(states)
>
> [1] "+proj=longlat +datum=NAD83 +no_defs +ellps=GRS80 +towgs84=0,0,0"
>
> states <- spTransform(states, CRS("+proj=longlat +datum=WGS84"))

Unnecessary, as you should know from the +towgs84= tag.

>
> states <- fortify(states)

The fortify methods turn data from marine animals with structure into fish 
soup (a data frame adding attribute values spuriously to each coordinate, 
I believe). Unless the objects are exactly as fortify wants them, it 
derails.

Do you know that they were polygons? Where did the shapefile come 
from? Did you plot it? Did you check that it contained what you thought it 
contained (summary())?

Have you considered alternatives (tmap, mapview, ...)?

>
> sstates <- get_map(location = c(-81, 35, -69, 45), zoom = 4, maptype = "watercolor")
>
> sstates <- ggmap(sstates)
>
> sstates <- sstates + geom_polygon(aes(x = long, y = lat, group=group), data = states, color ="white", fill ="orangered4", alpha = .4, size = .2)
>
> Here is an image of the output.
>
> http://pasteboard.co/1d7kiRfw.png <http://pasteboard.co/1d7kiRfw.png>
>

Image posted OK, but posting HTML (unnecessary).

>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


