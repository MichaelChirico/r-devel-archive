From donfouetz at yahoo.fr  Sun Nov  1 18:59:41 2015
From: donfouetz at yahoo.fr (Hermann Pythagore DONFOUET)
Date: Sun, 1 Nov 2015 17:59:41 +0000 (UTC)
Subject: [R-sig-Geo] Standard heteroscedascity versus heteroscedascity in
 spatial econometrics
References: <1400049798.768918.1446400781709.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1400049798.768918.1446400781709.JavaMail.yahoo@mail.yahoo.com>

Dear Sir,
I'm working in spatial econometrics and I read some papers of Kelejian and Prucha (2007, 2010) about integrating heteroscedasticity in spatial econometrics. In spatial data, most often spatial units differ in terms of their shape and size. Thus, the hypothesis of constant innovations is unrealistic in the class of SARAR models (spatial effects in the dependent variable and error term).
But, I don't really understand the main difference between heteroscedascity in spatial econometrics and heteroscedascity in standard econometrics (a-spatial models). Please, do you knowm the main difference?
Thanks in advance and regards
Hermann

	[[alternative HTML version deleted]]


From awbriggs at gmail.com  Sun Nov  1 19:35:30 2015
From: awbriggs at gmail.com (Alan Briggs)
Date: Sun, 1 Nov 2015 13:35:30 -0500
Subject: [R-sig-Geo] Help with as.numeric(rownames(over(SpatialPoints(set1,
 set2, returnList= TRUE)[[1]]))
Message-ID: <CAPPm474TTx4sobtQ18FXg0fxNF7k0xcEpoGqdcNmK9SxdfQevA@mail.gmail.com>

Hello.

Below is a fully repeatable R-Script that I'm having trouble with.
Generally, here's what I'm trying to do:

1) Randomly generate a tile.list()
2) Randomly generate a new point
3) Identify which polygon in the tile.list the new randomly generated point
is in

This works fine MOST of the time. However, occasionally, I get an error
returned:

Error in `[<-.data.frame`(`*tmp*`, list, 3, value = numeric(0)) :
>   replacement has length zero


While troubleshooting, I realized I get numeric(0) returned for certain
sets of new random points when I run the command
as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),vpl,returnList=
TRUE)[[1]])). I thought maybe this was a boundary issue, but the points
don't lie on the edge, nor are they the centroid.

Any help you can provide would be greatly appreciated!

Regards,

Alan

R-Script Below:

### Help Question for  r-sig-geo ###
> rm(list = ls())
> library(deldir)
> library(sp)
> library(plyr)
> side_length = 100
> ## Create random SET of XY coordinates (size = 100x100)
> set.seed(11)
> df = data.frame(matrix(sample(1:100,16,replace=TRUE),nrow=8))
> ## Convert df to SPatialPointsDataFrame
> spdf <- SpatialPointsDataFrame(df,df)
> ## deldir() function creates tesselation (voronoi) plot
> z <- deldir(df,plotit=TRUE,wl='te')
> ## tile.list() creates a list of data for tiles
> zz <- tile.list(deldir(df,plotit=TRUE,wl='te'))
> ## Voronoi Polygons Function
> voronoipolygons = function(layer) {
>   require(deldir)
>   crds = layer at coords
>   z = deldir(crds[,1], crds[,2])
>   w = tile.list(z)
>   polys = vector(mode='list', length=length(w))
>   require(sp)
>   for (i in seq(along=polys)) {
>     pcrds = cbind(w[[i]]$x, w[[i]]$y)
>     pcrds = rbind(pcrds, pcrds[1,])
>     polys[[i]] = Polygons(list(Polygon(pcrds)), ID=as.character(i))
>   }
>   SP = SpatialPolygons(polys)
>   voronoi = SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
>             y=crds[,2], row.names=sapply(slot(SP, 'polygons'),
>             function(x) slot(x, 'ID'))))
> }
> ## Generate SpatialPolygonsDataFrame to use as input for over() function
> vpl <- voronoipolygons(spdf)
> ## Random Walk Function generates North, South East or West movement
> ## with transit from across screen (like PacMan, going out one side,
> ## coming back on the other side) to prevent getting stuck in corner
> random_walk <- function(step_quantity, step_length, plot = FALSE){
>   require(ggplot2)
>
>   walker <- data.frame(matrix(c(0,0), nrow = step_quantity, ncol = 3,
> byrow = T))
>   names(walker)[1]<-paste("x")
>   names(walker)[2]<-paste("y")
>   names(walker)[3]<-paste("which")
>
>   ## Seed random initial starting point
>   walker[1,1:2] <- matrix(sample(1:100,2,replace=TRUE),nrow=1)
>   walker[1,3] <-
> as.numeric(rownames(over(SpatialPoints(walker[1,1:2]),vpl,returnList=
> TRUE)[[1]]))
>
>   where_to <- as.numeric()
>
>   for(i in 2:step_quantity){
>     where_to <- as.numeric()
>     where_to <- walker[i-1,1:2]
>     which_next <- sample(c("bb","dd","ff","hh"),1)
>
>     if (which_next == "bb") {
>       if (walker[i-1,2] == side_length) {where_to[1,2] <- 0
>       } else {where_to[1,2] <- walker[i-1,2]+step_length}
>     }
>
>     else if (which_next == "dd") {
>       if (walker[i-1,1] == 0 ) {where_to[1,1] <- side_length
>       } else {where_to[1,1] <- walker[i-1,1]-step_length}
>     }
>
>     else if (which_next == "ff") {
>       if (walker[i-1,1] == side_length) {where_to[1,1] <- 0
>       } else {where_to[1,1] <- walker[i-1,1]+step_length}
>     }
>     else {
>       if (walker[i-1,2] == 0) {where_to[1,2] <- side_length
>       } else {where_to[1,2] <- walker[i-1,2]-step_length}
>     }
>
>     walker[i,1:2] <- where_to
>   }
>
>   walker[i,3] <- as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),
>                                           vpl,returnList= TRUE)[[1]]))
>
>
>   if(plot){
>   require(ggplot2)
>   p <- ggplot(walker, aes(x = x, y = y))
>   p <- p + geom_path()
>   print(p)
>   }
>
>   return(walker)
> }
> try(transits <- random_walk(5000,1),silent=F)

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Mon Nov  2 11:33:40 2015
From: englishchristophera at gmail.com (chris english)
Date: Mon, 2 Nov 2015 05:33:40 -0500
Subject: [R-sig-Geo] Help with
 as.numeric(rownames(over(SpatialPoints(set1, set2, returnList= TRUE)[[1]]))
In-Reply-To: <CAPPm474TTx4sobtQ18FXg0fxNF7k0xcEpoGqdcNmK9SxdfQevA@mail.gmail.com>
References: <CAPPm474TTx4sobtQ18FXg0fxNF7k0xcEpoGqdcNmK9SxdfQevA@mail.gmail.com>
Message-ID: <CAASFQpTGB+vWk_P04T42G1D8wGB_LRCtJBytqmvA4XeY7GmBOg@mail.gmail.com>

Hi Alan;
As you say, runs most of the time. I took the liberty of cleaning out the
>'s, removed the call to plyr as it doesn't seem to be used, and the
rm(list=ls()) since I wasn't playing in a sandbox. How frequently does it
misbehave?

I'm sorry I can't offer anything more constructive than the clean up.  I'm
interested in identifying self-avoiding random walks SAW which means I'll
first have to figure out how to implement one, then figure out how to test
for one. And means getting my head around your  "which_next <-
sample(c("bb","dd","ff","hh"),1)" logic.

Chris

## reproducible example code
 #rm(list = ls())
 library(deldir)
 library(sp)
 #library(plyr)
 side_length = 100
 ## Create random SET of XY coordinates (size = 100x100)
 set.seed(11)
 df = data.frame(matrix(sample(1:100,16,replace=TRUE),nrow=8))
 ## Convert df to SPatialPointsDataFrame
 spdf <- SpatialPointsDataFrame(df,df)
 ## deldir() function creates tesselation (voronoi) plot
 z <- deldir(df,plotit=TRUE,wl='te')
 ## tile.list() creates a list of data for tiles
 zz <- tile.list(deldir(df,plotit=TRUE,wl='te'))
 ## Voronoi Polygons Function
 voronoipolygons = function(layer) {
   require(deldir)
   crds = layer at coords
   z = deldir(crds[,1], crds[,2])
   w = tile.list(z)
   polys = vector(mode='list', length=length(w))
   require(sp)
   for (i in seq(along=polys)) {
     pcrds = cbind(w[[i]]$x, w[[i]]$y)
     pcrds = rbind(pcrds, pcrds[1,])
     polys[[i]] = Polygons(list(Polygon(pcrds)), ID=as.character(i))
   }
   SP = SpatialPolygons(polys)
   voronoi = SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
             y=crds[,2], row.names=sapply(slot(SP, 'polygons'),
             function(x) slot(x, 'ID'))))
 }
 ## Generate SpatialPolygonsDataFrame to use as input for over() function
 vpl <- voronoipolygons(spdf)
 ## Random Walk Function generates North, South East or West movement
 ## with transit from across screen (like PacMan, going out one side,
 ## coming back on the other side) to prevent getting stuck in corner
 random_walk <- function(step_quantity, step_length, plot = FALSE){
   require(ggplot2)

   walker <- data.frame(matrix(c(0,0), nrow = step_quantity, ncol = 3,
 byrow = T))
   names(walker)[1]<-paste("x")
   names(walker)[2]<-paste("y")
   names(walker)[3]<-paste("which")

   ## Seed random initial starting point
   walker[1,1:2] <- matrix(sample(1:100,2,replace=TRUE),nrow=1)
   walker[1,3] <- as.numeric(rownames(over(SpatialPoints(walker[1,1:2]
),vpl,returnList=TRUE)[[1]]))

  where_to <- as.numeric()

   for(i in 2:step_quantity){
     where_to <- as.numeric()
     where_to <- walker[i-1,1:2]
     which_next <- sample(c("bb","dd","ff","hh"),1)

     if (which_next == "bb") {
       if (walker[i-1,2] == side_length) {where_to[1,2] <- 0
       } else {where_to[1,2] <- walker[i-1,2]+step_length}
     }

     else if (which_next == "dd") {
       if (walker[i-1,1] == 0 ) {where_to[1,1] <- side_length
       } else {where_to[1,1] <- walker[i-1,1]-step_length}
     }

    else if (which_next == "ff") {
       if (walker[i-1,1] == side_length) {where_to[1,1] <- 0
       } else {where_to[1,1] <- walker[i-1,1]+step_length}
     }
     else {
       if (walker[i-1,2] == 0) {where_to[1,2] <- side_length
       } else {where_to[1,2] <- walker[i-1,2]-step_length}
     }

     walker[i,1:2] <- where_to
   }

   walker[i,3] <- as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),
                                           vpl,returnList= TRUE)[[1]]))


   if(plot){
   require(ggplot2)
   p <- ggplot(walker, aes(x = x, y = y))
   p <- p + geom_path()
   print(p)
   }

   return(walker)
 }
 try(transits <- random_walk(5000,1),silent=F)

On Sun, Nov 1, 2015 at 1:35 PM, Alan Briggs <awbriggs at gmail.com> wrote:

> Hello.
>
> Below is a fully repeatable R-Script that I'm having trouble with.
> Generally, here's what I'm trying to do:
>
> 1) Randomly generate a tile.list()
> 2) Randomly generate a new point
> 3) Identify which polygon in the tile.list the new randomly generated point
> is in
>
> This works fine MOST of the time. However, occasionally, I get an error
> returned:
>
> Error in `[<-.data.frame`(`*tmp*`, list, 3, value = numeric(0)) :
> >   replacement has length zero
>
>
> While troubleshooting, I realized I get numeric(0) returned for certain
> sets of new random points when I run the command
> as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),vpl,returnList=
> TRUE)[[1]])). I thought maybe this was a boundary issue, but the points
> don't lie on the edge, nor are they the centroid.
>
> Any help you can provide would be greatly appreciated!
>
> Regards,
>
> Alan
>
> R-Script Below:
>
> ### Help Question for  r-sig-geo ###
> > rm(list = ls())
> > library(deldir)
> > library(sp)
> > library(plyr)
> > side_length = 100
> > ## Create random SET of XY coordinates (size = 100x100)
> > set.seed(11)
> > df = data.frame(matrix(sample(1:100,16,replace=TRUE),nrow=8))
> > ## Convert df to SPatialPointsDataFrame
> > spdf <- SpatialPointsDataFrame(df,df)
> > ## deldir() function creates tesselation (voronoi) plot
> > z <- deldir(df,plotit=TRUE,wl='te')
> > ## tile.list() creates a list of data for tiles
> > zz <- tile.list(deldir(df,plotit=TRUE,wl='te'))
> > ## Voronoi Polygons Function
> > voronoipolygons = function(layer) {
> >   require(deldir)
> >   crds = layer at coords
> >   z = deldir(crds[,1], crds[,2])
> >   w = tile.list(z)
> >   polys = vector(mode='list', length=length(w))
> >   require(sp)
> >   for (i in seq(along=polys)) {
> >     pcrds = cbind(w[[i]]$x, w[[i]]$y)
> >     pcrds = rbind(pcrds, pcrds[1,])
> >     polys[[i]] = Polygons(list(Polygon(pcrds)), ID=as.character(i))
> >   }
> >   SP = SpatialPolygons(polys)
> >   voronoi = SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
> >             y=crds[,2], row.names=sapply(slot(SP, 'polygons'),
> >             function(x) slot(x, 'ID'))))
> > }
> > ## Generate SpatialPolygonsDataFrame to use as input for over() function
> > vpl <- voronoipolygons(spdf)
> > ## Random Walk Function generates North, South East or West movement
> > ## with transit from across screen (like PacMan, going out one side,
> > ## coming back on the other side) to prevent getting stuck in corner
> > random_walk <- function(step_quantity, step_length, plot = FALSE){
> >   require(ggplot2)
> >
> >   walker <- data.frame(matrix(c(0,0), nrow = step_quantity, ncol = 3,
> > byrow = T))
> >   names(walker)[1]<-paste("x")
> >   names(walker)[2]<-paste("y")
> >   names(walker)[3]<-paste("which")
> >
> >   ## Seed random initial starting point
> >   walker[1,1:2] <- matrix(sample(1:100,2,replace=TRUE),nrow=1)
> >   walker[1,3] <-
> > as.numeric(rownames(over(SpatialPoints(walker[1,1:2]),vpl,returnList=
> > TRUE)[[1]]))
> >
> >   where_to <- as.numeric()
> >
> >   for(i in 2:step_quantity){
> >     where_to <- as.numeric()
> >     where_to <- walker[i-1,1:2]
> >     which_next <- sample(c("bb","dd","ff","hh"),1)
> >
> >     if (which_next == "bb") {
> >       if (walker[i-1,2] == side_length) {where_to[1,2] <- 0
> >       } else {where_to[1,2] <- walker[i-1,2]+step_length}
> >     }
> >
> >     else if (which_next == "dd") {
> >       if (walker[i-1,1] == 0 ) {where_to[1,1] <- side_length
> >       } else {where_to[1,1] <- walker[i-1,1]-step_length}
> >     }
> >
> >     else if (which_next == "ff") {
> >       if (walker[i-1,1] == side_length) {where_to[1,1] <- 0
> >       } else {where_to[1,1] <- walker[i-1,1]+step_length}
> >     }
> >     else {
> >       if (walker[i-1,2] == 0) {where_to[1,2] <- side_length
> >       } else {where_to[1,2] <- walker[i-1,2]-step_length}
> >     }
> >
> >     walker[i,1:2] <- where_to
> >   }
> >
> >   walker[i,3] <- as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),
> >                                           vpl,returnList= TRUE)[[1]]))
> >
> >
> >   if(plot){
> >   require(ggplot2)
> >   p <- ggplot(walker, aes(x = x, y = y))
> >   p <- p + geom_path()
> >   print(p)
> >   }
> >
> >   return(walker)
> > }
> > try(transits <- random_walk(5000,1),silent=F)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Mon Nov  2 11:50:42 2015
From: englishchristophera at gmail.com (chris english)
Date: Mon, 2 Nov 2015 05:50:42 -0500
Subject: [R-sig-Geo] Help with
 as.numeric(rownames(over(SpatialPoints(set1, set2, returnList= TRUE)[[1]]))
In-Reply-To: <CAASFQpTGB+vWk_P04T42G1D8wGB_LRCtJBytqmvA4XeY7GmBOg@mail.gmail.com>
References: <CAPPm474TTx4sobtQ18FXg0fxNF7k0xcEpoGqdcNmK9SxdfQevA@mail.gmail.com>
	<CAASFQpTGB+vWk_P04T42G1D8wGB_LRCtJBytqmvA4XeY7GmBOg@mail.gmail.com>
Message-ID: <CAASFQpSiMnXcSqNTTtpskiZbzCxVKqRmrwf3VMUckVu9wLHzNQ@mail.gmail.com>

Alan,

Possibly a nonsensical way of testing but I ran

rep(try(transits <- random_walk(5000,1),silent=F), 100)

and it completed without issue.

Chris

On Mon, Nov 2, 2015 at 5:33 AM, chris english <englishchristophera at gmail.com
> wrote:

> Hi Alan;
> As you say, runs most of the time. I took the liberty of cleaning out the
> >'s, removed the call to plyr as it doesn't seem to be used, and the
> rm(list=ls()) since I wasn't playing in a sandbox. How frequently does it
> misbehave?
>
> I'm sorry I can't offer anything more constructive than the clean up.  I'm
> interested in identifying self-avoiding random walks SAW which means I'll
> first have to figure out how to implement one, then figure out how to test
> for one. And means getting my head around your  "which_next <-
> sample(c("bb","dd","ff","hh"),1)" logic.
>
> Chris
>
> ## reproducible example code
>  #rm(list = ls())
>  library(deldir)
>  library(sp)
>  #library(plyr)
>  side_length = 100
>  ## Create random SET of XY coordinates (size = 100x100)
>  set.seed(11)
>  df = data.frame(matrix(sample(1:100,16,replace=TRUE),nrow=8))
>  ## Convert df to SPatialPointsDataFrame
>  spdf <- SpatialPointsDataFrame(df,df)
>  ## deldir() function creates tesselation (voronoi) plot
>  z <- deldir(df,plotit=TRUE,wl='te')
>  ## tile.list() creates a list of data for tiles
>  zz <- tile.list(deldir(df,plotit=TRUE,wl='te'))
>  ## Voronoi Polygons Function
>  voronoipolygons = function(layer) {
>    require(deldir)
>    crds = layer at coords
>    z = deldir(crds[,1], crds[,2])
>    w = tile.list(z)
>    polys = vector(mode='list', length=length(w))
>    require(sp)
>    for (i in seq(along=polys)) {
>      pcrds = cbind(w[[i]]$x, w[[i]]$y)
>      pcrds = rbind(pcrds, pcrds[1,])
>      polys[[i]] = Polygons(list(Polygon(pcrds)), ID=as.character(i))
>    }
>    SP = SpatialPolygons(polys)
>    voronoi = SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
>              y=crds[,2], row.names=sapply(slot(SP, 'polygons'),
>              function(x) slot(x, 'ID'))))
>  }
>  ## Generate SpatialPolygonsDataFrame to use as input for over() function
>  vpl <- voronoipolygons(spdf)
>  ## Random Walk Function generates North, South East or West movement
>  ## with transit from across screen (like PacMan, going out one side,
>  ## coming back on the other side) to prevent getting stuck in corner
>  random_walk <- function(step_quantity, step_length, plot = FALSE){
>    require(ggplot2)
>
>    walker <- data.frame(matrix(c(0,0), nrow = step_quantity, ncol = 3,
>  byrow = T))
>    names(walker)[1]<-paste("x")
>    names(walker)[2]<-paste("y")
>    names(walker)[3]<-paste("which")
>
>    ## Seed random initial starting point
>    walker[1,1:2] <- matrix(sample(1:100,2,replace=TRUE),nrow=1)
>    walker[1,3] <- as.numeric(rownames(over(SpatialPoints(walker[1,1:2]
> ),vpl,returnList=TRUE)[[1]]))
>
>   where_to <- as.numeric()
>
>    for(i in 2:step_quantity){
>      where_to <- as.numeric()
>      where_to <- walker[i-1,1:2]
>      which_next <- sample(c("bb","dd","ff","hh"),1)
>
>      if (which_next == "bb") {
>        if (walker[i-1,2] == side_length) {where_to[1,2] <- 0
>        } else {where_to[1,2] <- walker[i-1,2]+step_length}
>      }
>
>      else if (which_next == "dd") {
>        if (walker[i-1,1] == 0 ) {where_to[1,1] <- side_length
>        } else {where_to[1,1] <- walker[i-1,1]-step_length}
>      }
>
>     else if (which_next == "ff") {
>        if (walker[i-1,1] == side_length) {where_to[1,1] <- 0
>        } else {where_to[1,1] <- walker[i-1,1]+step_length}
>      }
>      else {
>        if (walker[i-1,2] == 0) {where_to[1,2] <- side_length
>        } else {where_to[1,2] <- walker[i-1,2]-step_length}
>      }
>
>      walker[i,1:2] <- where_to
>    }
>
>    walker[i,3] <- as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),
>                                            vpl,returnList= TRUE)[[1]]))
>
>
>    if(plot){
>    require(ggplot2)
>    p <- ggplot(walker, aes(x = x, y = y))
>    p <- p + geom_path()
>    print(p)
>    }
>
>    return(walker)
>  }
>  try(transits <- random_walk(5000,1),silent=F)
>
> On Sun, Nov 1, 2015 at 1:35 PM, Alan Briggs <awbriggs at gmail.com> wrote:
>
>> Hello.
>>
>> Below is a fully repeatable R-Script that I'm having trouble with.
>> Generally, here's what I'm trying to do:
>>
>> 1) Randomly generate a tile.list()
>> 2) Randomly generate a new point
>> 3) Identify which polygon in the tile.list the new randomly generated
>> point
>> is in
>>
>> This works fine MOST of the time. However, occasionally, I get an error
>> returned:
>>
>> Error in `[<-.data.frame`(`*tmp*`, list, 3, value = numeric(0)) :
>> >   replacement has length zero
>>
>>
>> While troubleshooting, I realized I get numeric(0) returned for certain
>> sets of new random points when I run the command
>> as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),vpl,returnList=
>> TRUE)[[1]])). I thought maybe this was a boundary issue, but the points
>> don't lie on the edge, nor are they the centroid.
>>
>> Any help you can provide would be greatly appreciated!
>>
>> Regards,
>>
>> Alan
>>
>> R-Script Below:
>>
>> ### Help Question for  r-sig-geo ###
>> > rm(list = ls())
>> > library(deldir)
>> > library(sp)
>> > library(plyr)
>> > side_length = 100
>> > ## Create random SET of XY coordinates (size = 100x100)
>> > set.seed(11)
>> > df = data.frame(matrix(sample(1:100,16,replace=TRUE),nrow=8))
>> > ## Convert df to SPatialPointsDataFrame
>> > spdf <- SpatialPointsDataFrame(df,df)
>> > ## deldir() function creates tesselation (voronoi) plot
>> > z <- deldir(df,plotit=TRUE,wl='te')
>> > ## tile.list() creates a list of data for tiles
>> > zz <- tile.list(deldir(df,plotit=TRUE,wl='te'))
>> > ## Voronoi Polygons Function
>> > voronoipolygons = function(layer) {
>> >   require(deldir)
>> >   crds = layer at coords
>> >   z = deldir(crds[,1], crds[,2])
>> >   w = tile.list(z)
>> >   polys = vector(mode='list', length=length(w))
>> >   require(sp)
>> >   for (i in seq(along=polys)) {
>> >     pcrds = cbind(w[[i]]$x, w[[i]]$y)
>> >     pcrds = rbind(pcrds, pcrds[1,])
>> >     polys[[i]] = Polygons(list(Polygon(pcrds)), ID=as.character(i))
>> >   }
>> >   SP = SpatialPolygons(polys)
>> >   voronoi = SpatialPolygonsDataFrame(SP, data=data.frame(x=crds[,1],
>> >             y=crds[,2], row.names=sapply(slot(SP, 'polygons'),
>> >             function(x) slot(x, 'ID'))))
>> > }
>> > ## Generate SpatialPolygonsDataFrame to use as input for over() function
>> > vpl <- voronoipolygons(spdf)
>> > ## Random Walk Function generates North, South East or West movement
>> > ## with transit from across screen (like PacMan, going out one side,
>> > ## coming back on the other side) to prevent getting stuck in corner
>> > random_walk <- function(step_quantity, step_length, plot = FALSE){
>> >   require(ggplot2)
>> >
>> >   walker <- data.frame(matrix(c(0,0), nrow = step_quantity, ncol = 3,
>> > byrow = T))
>> >   names(walker)[1]<-paste("x")
>> >   names(walker)[2]<-paste("y")
>> >   names(walker)[3]<-paste("which")
>> >
>> >   ## Seed random initial starting point
>> >   walker[1,1:2] <- matrix(sample(1:100,2,replace=TRUE),nrow=1)
>> >   walker[1,3] <-
>> > as.numeric(rownames(over(SpatialPoints(walker[1,1:2]),vpl,returnList=
>> > TRUE)[[1]]))
>> >
>> >   where_to <- as.numeric()
>> >
>> >   for(i in 2:step_quantity){
>> >     where_to <- as.numeric()
>> >     where_to <- walker[i-1,1:2]
>> >     which_next <- sample(c("bb","dd","ff","hh"),1)
>> >
>> >     if (which_next == "bb") {
>> >       if (walker[i-1,2] == side_length) {where_to[1,2] <- 0
>> >       } else {where_to[1,2] <- walker[i-1,2]+step_length}
>> >     }
>> >
>> >     else if (which_next == "dd") {
>> >       if (walker[i-1,1] == 0 ) {where_to[1,1] <- side_length
>> >       } else {where_to[1,1] <- walker[i-1,1]-step_length}
>> >     }
>> >
>> >     else if (which_next == "ff") {
>> >       if (walker[i-1,1] == side_length) {where_to[1,1] <- 0
>> >       } else {where_to[1,1] <- walker[i-1,1]+step_length}
>> >     }
>> >     else {
>> >       if (walker[i-1,2] == 0) {where_to[1,2] <- side_length
>> >       } else {where_to[1,2] <- walker[i-1,2]-step_length}
>> >     }
>> >
>> >     walker[i,1:2] <- where_to
>> >   }
>> >
>> >   walker[i,3] <- as.numeric(rownames(over(SpatialPoints(walker[i,1:2]),
>> >                                           vpl,returnList= TRUE)[[1]]))
>> >
>> >
>> >   if(plot){
>> >   require(ggplot2)
>> >   p <- ggplot(walker, aes(x = x, y = y))
>> >   p <- p + geom_path()
>> >   print(p)
>> >   }
>> >
>> >   return(walker)
>> > }
>> > try(transits <- random_walk(5000,1),silent=F)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Mon Nov  2 22:21:56 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 2 Nov 2015 22:21:56 +0100
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
	<CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511022202400.13686@reclus.nhh.no>

Hi Andy,

On Mon, 26 Oct 2015, Andy Teucher wrote:

> Hi Roger,
>
> Sorry I haven't been much help here - it's not for lack of trying,
> just lack of skills. I've been poring through OGR_write.cpp and trying
> to figure out language and the flow of things... a few thoughts
> occurred to me (which are probably obvious to you):
>

Your example was very helpful, the problem was that when writeOGR() and 
the underlying compiled code was written, the model used was that of the 
ESRI Shapefile driver, rather than OGC SFS, which was first published in 
2004. Most older formats (and their drivers in OGR) use a OGR geometry 
factory function to organize polygons on reading - but this is not present 
in shapelib (bundled with the R maptools package), so when designing 
polygon classes for sp, and writing rgdal::writeOGR() about 10 years ago, 
this was not known, and was not revisited subsequently, until you happily 
spotted the bug.

GEOS in rgeos uses OGC SFS definitions (the ones you are using below), but 
the SpatialPolygons/Polygons/Polygon structure was already established by 
then, and a fix (using comment attributes in Polygons objects) was used, 
rather than a major change to Polygons objects (in 2010).

The revision to rgdal::writeOGR() now branches on the input objects - if 
they have comments (applied in code, not user-facing), these are trusted, 
and the MultiPolygon objects constructed containing one or more Polygon 
objects with one exterior ring and zero or more interior rings on that 
basis. However, if the input objects do not have comment attributes, 
OGRGeometryFactory::organizePolygons() (C++) is used to create properly 
organized MultiPolygon objects for export.

This means that the pre-OGC SFS drivers continue to work, but that the OGC 
SFS drivers, like GeoJSON, now also work correctly when the second ring in 
an object is not assumed to be an interior ring (rgdal < 1.1-1). A test 
set for all the possible cases has been introduced.

The revision is now in source package form on CRAN:

https://cran.r-project.org/web/packages/rgdal/index.html

and a Windows binary package will be available later on Tuesday I hope. 
The OSX revision may take a little longer, but we are grateful to have 
what we have anyway.

Thanks for a clear and very helpful bug report.

Best wishes,

Roger

> 1) Is this bug because holes are standalone polygons in sp objects,
> while they are members of polygon objects in geojson, wkt, etc?
>
> 2) On a related note, I notice that a single polygon with a hole is
> identified as a multipolygon containing a single polygon with a hole,
> when using writeOGR and one of the affected drivers.  Practically I
> don't think this matters too much, but it's not quite right.
>
> 3) In lines 116-160 the polygon/multipolygon and line/multiline
> determination is made for the entire layer. Can/should this be made
> for each feature in the layer, as you could have a layer with a
> mixture of single polygons and multipolygons?
>
> 4) I feel like there ought to be one more layer of looping through the
> polyons. e.g.:
>
> loop over each feature;
>     determine whether each feature is a single polygon (length 1 or
> all rings but one are holes), or a multipolygon:
>        if a polygon loop over and add ring(s);
>        if a multipolygon loop over polygons:
>            for each polygon add ring(s) and somehow assign holes to
> parent polygons
>
> Again, apologies if I'm being totally obvious (or way off base).
> Thanks for all your work on these packages, and on this issue.
>
> Andy
>
>
> On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Fri, 23 Oct 2015, Andy Teucher wrote:
>>
>>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
>>>
>>>
>>> sessionInfo()
>>>
>>
>> OK, thanks.
>>
>> The problem also affects the SQLite driver (the CRAN binaries do not have
>> this driver). Could someone please check the PostGIS driver - my guess is
>> that all OGC SFS compliant drivers may be affected.
>>
>> Could somebody also please check whether this is a recently introduced issue
>> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp was
>> changed 2015-08-21, but the last previous change was 2015-06-11, then
>> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package CRAN
>> page.
>>
>> Roger
>>
>>
>>>
>>>
>>>
>>>
>>> R version 3.2.2 (2015-08-14)
>>>
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>
>>> Running under: OS X 10.11 (El Capitan)
>>>
>>>
>>>
>>>
>>> locale:
>>>
>>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>>>
>>>
>>>
>>>
>>> attached base packages:
>>>
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>>
>>>
>>> other attached packages:
>>>
>>> [1] rgdal_1.0-7 sp_1.2-1
>>>
>>>
>>>
>>>
>>> loaded via a namespace (and not attached):
>>>
>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>
>>>
>>>
>>>
>>> Andy
>>>
>>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <andy.teucher at gmail.com>
>>> wrote:
>>>
>>>> One more test: WKT has the same issue:
>>>> library(rgdal)
>>>> js <- '{
>>>> "type": "MultiPolygon",
>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0],
>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0],
>>>> [100.0, 0.0]]]]
>>>> } '
>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
>>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
>>>> layer_options = "GEOMETRY=AS_WKT")
>>>> cat(readLines("test.csv"), sep = "\n")
>>>> WKT,FID,
>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
>>>> 0,100 0)))",0
>>>> It should be:
>>>> WKT,FID,
>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
>>>> 1,101 0,100 0)))",0
>>>> Andy
>>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com>
>>>> wrote:
>>>>>
>>>>> Thanks very much Roger.
>>>>>
>>>>> I've replicated this on my work machine (Windows) and on my Mac at home.
>>>>>
>>>>> KML and GML are both affected. ESRI shapefile works fine and, though
>>>>> I'm not very familiar with the format, 'MapInfo File' works too
>>>>> (loading the file in qgis shows a multipart polygon with no geometry
>>>>> errors).
>>>>>
>>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
>>>>> gdal drivers):
>>>>>
>>>>> R version 3.2.2 (2015-08-14)
>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>>
>>>>> locale:
>>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>>> LC_MONETARY=English_Canada.1252
>>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> other attached packages:
>>>>> [1] rgdal_1.0-7 sp_1.2-0
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>>
>>>>>
>>>>> I'll send the details for my Mac environment this evening.
>>>>>
>>>>> I'll dig into the source code as soon as I can - C is a completely
>>>>> foreign language to me, so I can't promise anything fast!
>>>>>
>>>>> Thanks again,
>>>>> Andy
>>>>>
>>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>> wrote:
>>>>>>
>>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>>>>>
>>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly using
>>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>>>>>
>>>>>>>
>>>>>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>>>>>> with a geojson string with one multipolygon containing two polygons. I
>>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then write
>>>>>>> it with writeOGR:
>>>>>>>
>>>>>>> library(rgdal)
>>>>>>>
>>>>>>> js <- '{
>>>>>>> "type": "MultiPolygon",
>>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>>> 3.0],
>>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>>> 1.0],
>>>>>>> [100.0, 0.0]]]]
>>>>>>> } '
>>>>>>>
>>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>>>>>> SpatialPoygonsDataFrame
>>>>>>>
>>>>>>> temp <- tempfile()
>>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>>>>>> cat(readLines(temp))
>>>>>>>
>>>>>>> # Output:
>>>>>>> { "type": "FeatureCollection", "crs": { "type": "name", "properties":
>>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ { "type":
>>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": { "type":
>>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [
>>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } }
>>>>>>> ] }
>>>>>>
>>>>>>
>>>>>>
>>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp in
>>>>>> gives
>>>>>> the orphaned hole. I'm surprised that passing the js object to
>>>>>> readOGR()
>>>>>> doesn't fail, but that isn't the source of the problem. spdf appears to
>>>>>> be
>>>>>> structured correctly. Please provide your GDAL and rgdal versions, and
>>>>>> OS
>>>>>> details from sessionInfo().
>>>>>>
>>>>>> We are completely relying on the GDAL drivers here - we can't cherry
>>>>>> pick
>>>>>> for particular drivers (historically excepting ESRI Shapefile), so your
>>>>>> debugging will need to examine writeOGR(), the C code it calls, and the
>>>>>> interactions between the rgdal C code and called OGR functions. Please
>>>>>> check
>>>>>> which other drivers are affected (I think KML is, is GML?). Can you
>>>>>> place
>>>>>> debugging Rprintf(...); in the rgdal C code to see where this is coming
>>>>>> from?
>>>>>>
>>>>>> I can start looking at this sometime next week, so please make a start
>>>>>> yourself; contributions from others are very welcome.
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>>
>>>>>>> If you look closely at the output, you can see that the 'coordinates'
>>>>>>> array now contains a single polygon array with two coordinate arrays:
>>>>>>> the boundary, and a second one which is now treated as a hole of the
>>>>>>> first (orphaned as it is outside the bounds of the polygon). The
>>>>>>> original 'coordinates' array consists of two polygon arrays, each
>>>>>>> consisting of a single coordinate array which defining a polygon (with
>>>>>>> no holes), which is correct according the GeoJSON spec:
>>>>>>> http://geojson.org/geojson-spec.html#polygon.
>>>>>>>
>>>>>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>>>>>> happen using ogr2ogr on the command line:
>>>>>>>
>>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>>>>>> shapefile to convert using ogr2ogr
>>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>>>>>> cat(readLines("test_from_shp.geojson"))
>>>>>>>
>>>>>>> # Output:
>>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ], [
>>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0 ],
>>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>>>>>
>>>>>>> The resulting output is correct.
>>>>>>>
>>>>>>>
>>>>>>> Thanks in advance for any help on this.
>>>>>>>
>>>>>>> Andy
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Roger Bivand
>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From andy.teucher at gmail.com  Mon Nov  2 23:42:32 2015
From: andy.teucher at gmail.com (Andy Teucher)
Date: Mon, 2 Nov 2015 14:42:32 -0800
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <alpine.LFD.2.20.1511022202400.13686@reclus.nhh.no>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
	<CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
	<alpine.LFD.2.20.1511022202400.13686@reclus.nhh.no>
Message-ID: <CAOdCUxNY6Cz_9oWEyyOfqofwuNN+AZAuG4-akdYG+60-e10e4A@mail.gmail.com>

Amazing (and fast) work Roger, and thanks for the great explanation.
I can see why you wouldn't want to redo the way Polygons objects are
structured - I'm sure it would be break a huge amount of existing
code.

Just curious, does OSX take longer because you have to deal with
multiple possible GDAL versions?

Thanks again,
Andy

On Mon, Nov 2, 2015 at 1:21 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> Hi Andy,
>
> On Mon, 26 Oct 2015, Andy Teucher wrote:
>
>> Hi Roger,
>>
>> Sorry I haven't been much help here - it's not for lack of trying,
>> just lack of skills. I've been poring through OGR_write.cpp and trying
>> to figure out language and the flow of things... a few thoughts
>> occurred to me (which are probably obvious to you):
>>
>
> Your example was very helpful, the problem was that when writeOGR() and the
> underlying compiled code was written, the model used was that of the ESRI
> Shapefile driver, rather than OGC SFS, which was first published in 2004.
> Most older formats (and their drivers in OGR) use a OGR geometry factory
> function to organize polygons on reading - but this is not present in
> shapelib (bundled with the R maptools package), so when designing polygon
> classes for sp, and writing rgdal::writeOGR() about 10 years ago, this was
> not known, and was not revisited subsequently, until you happily spotted the
> bug.
>
> GEOS in rgeos uses OGC SFS definitions (the ones you are using below), but
> the SpatialPolygons/Polygons/Polygon structure was already established by
> then, and a fix (using comment attributes in Polygons objects) was used,
> rather than a major change to Polygons objects (in 2010).
>
> The revision to rgdal::writeOGR() now branches on the input objects - if
> they have comments (applied in code, not user-facing), these are trusted,
> and the MultiPolygon objects constructed containing one or more Polygon
> objects with one exterior ring and zero or more interior rings on that
> basis. However, if the input objects do not have comment attributes,
> OGRGeometryFactory::organizePolygons() (C++) is used to create properly
> organized MultiPolygon objects for export.
>
> This means that the pre-OGC SFS drivers continue to work, but that the OGC
> SFS drivers, like GeoJSON, now also work correctly when the second ring in
> an object is not assumed to be an interior ring (rgdal < 1.1-1). A test set
> for all the possible cases has been introduced.
>
> The revision is now in source package form on CRAN:
>
> https://cran.r-project.org/web/packages/rgdal/index.html
>
> and a Windows binary package will be available later on Tuesday I hope. The
> OSX revision may take a little longer, but we are grateful to have what we
> have anyway.
>
> Thanks for a clear and very helpful bug report.
>
> Best wishes,
>
> Roger
>
>
>> 1) Is this bug because holes are standalone polygons in sp objects,
>> while they are members of polygon objects in geojson, wkt, etc?
>>
>> 2) On a related note, I notice that a single polygon with a hole is
>> identified as a multipolygon containing a single polygon with a hole,
>> when using writeOGR and one of the affected drivers.  Practically I
>> don't think this matters too much, but it's not quite right.
>>
>> 3) In lines 116-160 the polygon/multipolygon and line/multiline
>> determination is made for the entire layer. Can/should this be made
>> for each feature in the layer, as you could have a layer with a
>> mixture of single polygons and multipolygons?
>>
>> 4) I feel like there ought to be one more layer of looping through the
>> polyons. e.g.:
>>
>> loop over each feature;
>>     determine whether each feature is a single polygon (length 1 or
>> all rings but one are holes), or a multipolygon:
>>        if a polygon loop over and add ring(s);
>>        if a multipolygon loop over polygons:
>>            for each polygon add ring(s) and somehow assign holes to
>> parent polygons
>>
>> Again, apologies if I'm being totally obvious (or way off base).
>> Thanks for all your work on these packages, and on this issue.
>>
>> Andy
>>
>>
>> On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no>
>> wrote:
>>>
>>> On Fri, 23 Oct 2015, Andy Teucher wrote:
>>>
>>>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
>>>>
>>>>
>>>> sessionInfo()
>>>>
>>>
>>> OK, thanks.
>>>
>>> The problem also affects the SQLite driver (the CRAN binaries do not have
>>> this driver). Could someone please check the PostGIS driver - my guess is
>>> that all OGC SFS compliant drivers may be affected.
>>>
>>> Could somebody also please check whether this is a recently introduced
>>> issue
>>> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp was
>>> changed 2015-08-21, but the last previous change was 2015-06-11, then
>>> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package CRAN
>>> page.
>>>
>>> Roger
>>>
>>>
>>>>
>>>>
>>>>
>>>>
>>>> R version 3.2.2 (2015-08-14)
>>>>
>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>
>>>> Running under: OS X 10.11 (El Capitan)
>>>>
>>>>
>>>>
>>>>
>>>> locale:
>>>>
>>>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>>>>
>>>>
>>>>
>>>>
>>>> attached base packages:
>>>>
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>>
>>>>
>>>>
>>>> other attached packages:
>>>>
>>>> [1] rgdal_1.0-7 sp_1.2-1
>>>>
>>>>
>>>>
>>>>
>>>> loaded via a namespace (and not attached):
>>>>
>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>
>>>>
>>>>
>>>>
>>>> Andy
>>>>
>>>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <andy.teucher at gmail.com>
>>>> wrote:
>>>>
>>>>> One more test: WKT has the same issue:
>>>>> library(rgdal)
>>>>> js <- '{
>>>>> "type": "MultiPolygon",
>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>> 3.0],
>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>> 1.0],
>>>>> [100.0, 0.0]]]]
>>>>> } '
>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
>>>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
>>>>> layer_options = "GEOMETRY=AS_WKT")
>>>>> cat(readLines("test.csv"), sep = "\n")
>>>>> WKT,FID,
>>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
>>>>> 0,100 0)))",0
>>>>> It should be:
>>>>> WKT,FID,
>>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
>>>>> 1,101 0,100 0)))",0
>>>>> Andy
>>>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>>
>>>>>> Thanks very much Roger.
>>>>>>
>>>>>> I've replicated this on my work machine (Windows) and on my Mac at
>>>>>> home.
>>>>>>
>>>>>> KML and GML are both affected. ESRI shapefile works fine and, though
>>>>>> I'm not very familiar with the format, 'MapInfo File' works too
>>>>>> (loading the file in qgis shows a multipart polygon with no geometry
>>>>>> errors).
>>>>>>
>>>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
>>>>>> gdal drivers):
>>>>>>
>>>>>> R version 3.2.2 (2015-08-14)
>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>>>
>>>>>> locale:
>>>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>>>> LC_MONETARY=English_Canada.1252
>>>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] rgdal_1.0-7 sp_1.2-0
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>>>
>>>>>>
>>>>>> I'll send the details for my Mac environment this evening.
>>>>>>
>>>>>> I'll dig into the source code as soon as I can - C is a completely
>>>>>> foreign language to me, so I can't promise anything fast!
>>>>>>
>>>>>> Thanks again,
>>>>>> Andy
>>>>>>
>>>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>>> wrote:
>>>>>>>
>>>>>>>
>>>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>>>>>>
>>>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly
>>>>>>>> using
>>>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>>>>>>> with a geojson string with one multipolygon containing two polygons.
>>>>>>>> I
>>>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then
>>>>>>>> write
>>>>>>>> it with writeOGR:
>>>>>>>>
>>>>>>>> library(rgdal)
>>>>>>>>
>>>>>>>> js <- '{
>>>>>>>> "type": "MultiPolygon",
>>>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>>>> 3.0],
>>>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>>>> 1.0],
>>>>>>>> [100.0, 0.0]]]]
>>>>>>>> } '
>>>>>>>>
>>>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>>>>>>> SpatialPoygonsDataFrame
>>>>>>>>
>>>>>>>> temp <- tempfile()
>>>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>>>>>>> cat(readLines(temp))
>>>>>>>>
>>>>>>>> # Output:
>>>>>>>> { "type": "FeatureCollection", "crs": { "type": "name",
>>>>>>>> "properties":
>>>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ {
>>>>>>>> "type":
>>>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": {
>>>>>>>> "type":
>>>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ],
>>>>>>>> [
>>>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] }
>>>>>>>> }
>>>>>>>> ] }
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp
>>>>>>> in
>>>>>>> gives
>>>>>>> the orphaned hole. I'm surprised that passing the js object to
>>>>>>> readOGR()
>>>>>>> doesn't fail, but that isn't the source of the problem. spdf appears
>>>>>>> to
>>>>>>> be
>>>>>>> structured correctly. Please provide your GDAL and rgdal versions,
>>>>>>> and
>>>>>>> OS
>>>>>>> details from sessionInfo().
>>>>>>>
>>>>>>> We are completely relying on the GDAL drivers here - we can't cherry
>>>>>>> pick
>>>>>>> for particular drivers (historically excepting ESRI Shapefile), so
>>>>>>> your
>>>>>>> debugging will need to examine writeOGR(), the C code it calls, and
>>>>>>> the
>>>>>>> interactions between the rgdal C code and called OGR functions.
>>>>>>> Please
>>>>>>> check
>>>>>>> which other drivers are affected (I think KML is, is GML?). Can you
>>>>>>> place
>>>>>>> debugging Rprintf(...); in the rgdal C code to see where this is
>>>>>>> coming
>>>>>>> from?
>>>>>>>
>>>>>>> I can start looking at this sometime next week, so please make a
>>>>>>> start
>>>>>>> yourself; contributions from others are very welcome.
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>>
>>>>>>>> If you look closely at the output, you can see that the
>>>>>>>> 'coordinates'
>>>>>>>> array now contains a single polygon array with two coordinate
>>>>>>>> arrays:
>>>>>>>> the boundary, and a second one which is now treated as a hole of the
>>>>>>>> first (orphaned as it is outside the bounds of the polygon). The
>>>>>>>> original 'coordinates' array consists of two polygon arrays, each
>>>>>>>> consisting of a single coordinate array which defining a polygon
>>>>>>>> (with
>>>>>>>> no holes), which is correct according the GeoJSON spec:
>>>>>>>> http://geojson.org/geojson-spec.html#polygon.
>>>>>>>>
>>>>>>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>>>>>>> happen using ogr2ogr on the command line:
>>>>>>>>
>>>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>>>>>>> shapefile to convert using ogr2ogr
>>>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>>>>>>> cat(readLines("test_from_shp.geojson"))
>>>>>>>>
>>>>>>>> # Output:
>>>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ],
>>>>>>>> [
>>>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0
>>>>>>>> ],
>>>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>>>>>>
>>>>>>>> The resulting output is correct.
>>>>>>>>
>>>>>>>>
>>>>>>>> Thanks in advance for any help on this.
>>>>>>>>
>>>>>>>> Andy
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-Geo mailing list
>>>>>>>> R-sig-Geo at r-project.org
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Roger Bivand
>>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no


From r-sig-geo at forreststevens.com  Mon Nov  2 23:52:15 2015
From: r-sig-geo at forreststevens.com (Forrest Stevens)
Date: Mon, 02 Nov 2015 22:52:15 +0000
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <CAOdCUxNY6Cz_9oWEyyOfqofwuNN+AZAuG4-akdYG+60-e10e4A@mail.gmail.com>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
	<CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
	<alpine.LFD.2.20.1511022202400.13686@reclus.nhh.no>
	<CAOdCUxNY6Cz_9oWEyyOfqofwuNN+AZAuG4-akdYG+60-e10e4A@mail.gmail.com>
Message-ID: <CAEBQMMkfiw-D70AyLe4kHHDb2=R_ONc=dnygNryWghssi-0Qrw@mail.gmail.com>

This is fantastic work, thank you both for troubleshooting it and the fix
Roger. Your tireless work is greatly appreciated! I just ran across this
problem a couple of weeks ago when exporting from R to GeoJSON, and will
happily test out the new version.

Sincerely,
Forrest

On Mon, Nov 2, 2015 at 5:44 PM Andy Teucher <andy.teucher at gmail.com> wrote:

> Amazing (and fast) work Roger, and thanks for the great explanation.
> I can see why you wouldn't want to redo the way Polygons objects are
> structured - I'm sure it would be break a huge amount of existing
> code.
>
> Just curious, does OSX take longer because you have to deal with
> multiple possible GDAL versions?
>
> Thanks again,
> Andy
>
> On Mon, Nov 2, 2015 at 1:21 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> > Hi Andy,
> >
> > On Mon, 26 Oct 2015, Andy Teucher wrote:
> >
> >> Hi Roger,
> >>
> >> Sorry I haven't been much help here - it's not for lack of trying,
> >> just lack of skills. I've been poring through OGR_write.cpp and trying
> >> to figure out language and the flow of things... a few thoughts
> >> occurred to me (which are probably obvious to you):
> >>
> >
> > Your example was very helpful, the problem was that when writeOGR() and
> the
> > underlying compiled code was written, the model used was that of the ESRI
> > Shapefile driver, rather than OGC SFS, which was first published in 2004.
> > Most older formats (and their drivers in OGR) use a OGR geometry factory
> > function to organize polygons on reading - but this is not present in
> > shapelib (bundled with the R maptools package), so when designing polygon
> > classes for sp, and writing rgdal::writeOGR() about 10 years ago, this
> was
> > not known, and was not revisited subsequently, until you happily spotted
> the
> > bug.
> >
> > GEOS in rgeos uses OGC SFS definitions (the ones you are using below),
> but
> > the SpatialPolygons/Polygons/Polygon structure was already established by
> > then, and a fix (using comment attributes in Polygons objects) was used,
> > rather than a major change to Polygons objects (in 2010).
> >
> > The revision to rgdal::writeOGR() now branches on the input objects - if
> > they have comments (applied in code, not user-facing), these are trusted,
> > and the MultiPolygon objects constructed containing one or more Polygon
> > objects with one exterior ring and zero or more interior rings on that
> > basis. However, if the input objects do not have comment attributes,
> > OGRGeometryFactory::organizePolygons() (C++) is used to create properly
> > organized MultiPolygon objects for export.
> >
> > This means that the pre-OGC SFS drivers continue to work, but that the
> OGC
> > SFS drivers, like GeoJSON, now also work correctly when the second ring
> in
> > an object is not assumed to be an interior ring (rgdal < 1.1-1). A test
> set
> > for all the possible cases has been introduced.
> >
> > The revision is now in source package form on CRAN:
> >
> > https://cran.r-project.org/web/packages/rgdal/index.html
> >
> > and a Windows binary package will be available later on Tuesday I hope.
> The
> > OSX revision may take a little longer, but we are grateful to have what
> we
> > have anyway.
> >
> > Thanks for a clear and very helpful bug report.
> >
> > Best wishes,
> >
> > Roger
> >
> >
> >> 1) Is this bug because holes are standalone polygons in sp objects,
> >> while they are members of polygon objects in geojson, wkt, etc?
> >>
> >> 2) On a related note, I notice that a single polygon with a hole is
> >> identified as a multipolygon containing a single polygon with a hole,
> >> when using writeOGR and one of the affected drivers.  Practically I
> >> don't think this matters too much, but it's not quite right.
> >>
> >> 3) In lines 116-160 the polygon/multipolygon and line/multiline
> >> determination is made for the entire layer. Can/should this be made
> >> for each feature in the layer, as you could have a layer with a
> >> mixture of single polygons and multipolygons?
> >>
> >> 4) I feel like there ought to be one more layer of looping through the
> >> polyons. e.g.:
> >>
> >> loop over each feature;
> >>     determine whether each feature is a single polygon (length 1 or
> >> all rings but one are holes), or a multipolygon:
> >>        if a polygon loop over and add ring(s);
> >>        if a multipolygon loop over polygons:
> >>            for each polygon add ring(s) and somehow assign holes to
> >> parent polygons
> >>
> >> Again, apologies if I'm being totally obvious (or way off base).
> >> Thanks for all your work on these packages, and on this issue.
> >>
> >> Andy
> >>
> >>
> >> On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no>
> >> wrote:
> >>>
> >>> On Fri, 23 Oct 2015, Andy Teucher wrote:
> >>>
> >>>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
> >>>>
> >>>>
> >>>> sessionInfo()
> >>>>
> >>>
> >>> OK, thanks.
> >>>
> >>> The problem also affects the SQLite driver (the CRAN binaries do not
> have
> >>> this driver). Could someone please check the PostGIS driver - my guess
> is
> >>> that all OGC SFS compliant drivers may be affected.
> >>>
> >>> Could somebody also please check whether this is a recently introduced
> >>> issue
> >>> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp
> was
> >>> changed 2015-08-21, but the last previous change was 2015-06-11, then
> >>> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package
> CRAN
> >>> page.
> >>>
> >>> Roger
> >>>
> >>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> R version 3.2.2 (2015-08-14)
> >>>>
> >>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >>>>
> >>>> Running under: OS X 10.11 (El Capitan)
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> locale:
> >>>>
> >>>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> attached base packages:
> >>>>
> >>>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> other attached packages:
> >>>>
> >>>> [1] rgdal_1.0-7 sp_1.2-1
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> loaded via a namespace (and not attached):
> >>>>
> >>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
> >>>>
> >>>>
> >>>>
> >>>>
> >>>> Andy
> >>>>
> >>>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <
> andy.teucher at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> One more test: WKT has the same issue:
> >>>>> library(rgdal)
> >>>>> js <- '{
> >>>>> "type": "MultiPolygon",
> >>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
> >>>>> 3.0],
> >>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
> >>>>> 1.0],
> >>>>> [100.0, 0.0]]]]
> >>>>> } '
> >>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
> >>>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
> >>>>> layer_options = "GEOMETRY=AS_WKT")
> >>>>> cat(readLines("test.csv"), sep = "\n")
> >>>>> WKT,FID,
> >>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101
> 1,101
> >>>>> 0,100 0)))",0
> >>>>> It should be:
> >>>>> WKT,FID,
> >>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
> >>>>> 1,101 0,100 0)))",0
> >>>>> Andy
> >>>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <
> andy.teucher at gmail.com>
> >>>>> wrote:
> >>>>>>
> >>>>>>
> >>>>>> Thanks very much Roger.
> >>>>>>
> >>>>>> I've replicated this on my work machine (Windows) and on my Mac at
> >>>>>> home.
> >>>>>>
> >>>>>> KML and GML are both affected. ESRI shapefile works fine and, though
> >>>>>> I'm not very familiar with the format, 'MapInfo File' works too
> >>>>>> (loading the file in qgis shows a multipart polygon with no geometry
> >>>>>> errors).
> >>>>>>
> >>>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with
> included
> >>>>>> gdal drivers):
> >>>>>>
> >>>>>> R version 3.2.2 (2015-08-14)
> >>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
> >>>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
> >>>>>>
> >>>>>> locale:
> >>>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
> >>>>>> LC_MONETARY=English_Canada.1252
> >>>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
> >>>>>>
> >>>>>> attached base packages:
> >>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>>>>
> >>>>>> other attached packages:
> >>>>>> [1] rgdal_1.0-7 sp_1.2-0
> >>>>>>
> >>>>>> loaded via a namespace (and not attached):
> >>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
> >>>>>>
> >>>>>>
> >>>>>> I'll send the details for my Mac environment this evening.
> >>>>>>
> >>>>>> I'll dig into the source code as soon as I can - C is a completely
> >>>>>> foreign language to me, so I can't promise anything fast!
> >>>>>>
> >>>>>> Thanks again,
> >>>>>> Andy
> >>>>>>
> >>>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no
> >
> >>>>>> wrote:
> >>>>>>>
> >>>>>>>
> >>>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
> >>>>>>>
> >>>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly
> >>>>>>>> using
> >>>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> >>>>>>>>
> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes
> )
> >>>>>>>> with a geojson string with one multipolygon containing two
> polygons.
> >>>>>>>> I
> >>>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then
> >>>>>>>> write
> >>>>>>>> it with writeOGR:
> >>>>>>>>
> >>>>>>>> library(rgdal)
> >>>>>>>>
> >>>>>>>> js <- '{
> >>>>>>>> "type": "MultiPolygon",
> >>>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0],
> [102.0,
> >>>>>>>> 3.0],
> >>>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0],
> [100.0,
> >>>>>>>> 1.0],
> >>>>>>>> [100.0, 0.0]]]]
> >>>>>>>> } '
> >>>>>>>>
> >>>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
> >>>>>>>> SpatialPoygonsDataFrame
> >>>>>>>>
> >>>>>>>> temp <- tempfile()
> >>>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
> >>>>>>>> cat(readLines(temp))
> >>>>>>>>
> >>>>>>>> # Output:
> >>>>>>>> { "type": "FeatureCollection", "crs": { "type": "name",
> >>>>>>>> "properties":
> >>>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ {
> >>>>>>>> "type":
> >>>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": {
> >>>>>>>> "type":
> >>>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0
> ],
> >>>>>>>> [
> >>>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ],
> [
> >>>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ]
> ] }
> >>>>>>>> }
> >>>>>>>> ] }
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp
> >>>>>>> in
> >>>>>>> gives
> >>>>>>> the orphaned hole. I'm surprised that passing the js object to
> >>>>>>> readOGR()
> >>>>>>> doesn't fail, but that isn't the source of the problem. spdf
> appears
> >>>>>>> to
> >>>>>>> be
> >>>>>>> structured correctly. Please provide your GDAL and rgdal versions,
> >>>>>>> and
> >>>>>>> OS
> >>>>>>> details from sessionInfo().
> >>>>>>>
> >>>>>>> We are completely relying on the GDAL drivers here - we can't
> cherry
> >>>>>>> pick
> >>>>>>> for particular drivers (historically excepting ESRI Shapefile), so
> >>>>>>> your
> >>>>>>> debugging will need to examine writeOGR(), the C code it calls, and
> >>>>>>> the
> >>>>>>> interactions between the rgdal C code and called OGR functions.
> >>>>>>> Please
> >>>>>>> check
> >>>>>>> which other drivers are affected (I think KML is, is GML?). Can you
> >>>>>>> place
> >>>>>>> debugging Rprintf(...); in the rgdal C code to see where this is
> >>>>>>> coming
> >>>>>>> from?
> >>>>>>>
> >>>>>>> I can start looking at this sometime next week, so please make a
> >>>>>>> start
> >>>>>>> yourself; contributions from others are very welcome.
> >>>>>>>
> >>>>>>> Roger
> >>>>>>>
> >>>>>>>>
> >>>>>>>> If you look closely at the output, you can see that the
> >>>>>>>> 'coordinates'
> >>>>>>>> array now contains a single polygon array with two coordinate
> >>>>>>>> arrays:
> >>>>>>>> the boundary, and a second one which is now treated as a hole of
> the
> >>>>>>>> first (orphaned as it is outside the bounds of the polygon). The
> >>>>>>>> original 'coordinates' array consists of two polygon arrays, each
> >>>>>>>> consisting of a single coordinate array which defining a polygon
> >>>>>>>> (with
> >>>>>>>> no holes), which is correct according the GeoJSON spec:
> >>>>>>>> http://geojson.org/geojson-spec.html#polygon.
> >>>>>>>>
> >>>>>>>> I'm always hesitant to call things a bug, but this doesn't appear
> to
> >>>>>>>> happen using ogr2ogr on the command line:
> >>>>>>>>
> >>>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
> >>>>>>>> shapefile to convert using ogr2ogr
> >>>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
> >>>>>>>> cat(readLines("test_from_shp.geojson"))
> >>>>>>>>
> >>>>>>>> # Output:
> >>>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
> >>>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
> >>>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0
> ],
> >>>>>>>> [
> >>>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0
> >>>>>>>> ],
> >>>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
> >>>>>>>>
> >>>>>>>> The resulting output is correct.
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> Thanks in advance for any help on this.
> >>>>>>>>
> >>>>>>>> Andy
> >>>>>>>>
> >>>>>>>> _______________________________________________
> >>>>>>>> R-sig-Geo mailing list
> >>>>>>>> R-sig-Geo at r-project.org
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>> --
> >>>>>>> Roger Bivand
> >>>>>>> Department of Economics, Norwegian School of Economics,
> >>>>>>> Helleveien 30, N-5045 Bergen, Norway.
> >>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >>>>>>> e-mail: Roger.Bivand at nhh.no
> >>>>
> >>>>
> >>>>
> >>>
> >>> --
> >>> Roger Bivand
> >>> Department of Economics, Norwegian School of Economics,
> >>> Helleveien 30, N-5045 Bergen, Norway.
> >>> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >>> e-mail: Roger.Bivand at nhh.no
> >>
> >>
> >
> > --
> > Roger Bivand
> > Department of Economics, Norwegian School of Economics,
> > Helleveien 30, N-5045 Bergen, Norway.
> > voice: +47 55 95 93 55; fax +47 55 95 91 00
> > e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Tue Nov  3 00:08:22 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 2 Nov 2015 23:08:22 +0000
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
Message-ID: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>

I can create a SpatiaLite DB file and put a layer in it, but if I try
and add another layer, rgdal fails. Example:

Versions etc:

 > require(rgdal)
Loading required package: rgdal
Loading required package: sp
prgdal: version: 1.0-7, (SVN revision 559)
 Geospatial Data Abstraction Library extensions to R successfully loaded
 Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
 Path to GDAL shared files: /usr/share/gdal/1.11
 Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
 Path to PROJ.4 shared files: (autodetected)
 Linking to sp version: 1.2-0

Create a simple points data set, write it:

 > pts = data.frame(x=runif(10),y=runif(10),z=1:10)
 > coordinates(pts)=~x+y
 > writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
dataset_option="SPATIALITE=YES")

Note the use of the dataset_option to make this a proper SpatiaLite,
and not just an SQLite table. The output file is about 4Mb and has a
lot of metadata tables in it. The file loads into QGIS which
recognises it as a SpatiaLite table and I can plot the points.

Now try and create another spatial table (this time, "pts2")  in the
same database file:

 > writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
dataset_option="SPATIALITE=YES")
Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
dataset_option = "SPATIALITE=YES") :
  Creation of output file failed

 I've tried various other options with no success. Is this possible?
Or do I ditch writeOGR for this and create the table by hand... ick...

Barry


From Roger.Bivand at nhh.no  Tue Nov  3 00:09:25 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Nov 2015 00:09:25 +0100
Subject: [R-sig-Geo] Exporting Multipolygon geojson with rgdal::writeOGR
In-Reply-To: <CAOdCUxNY6Cz_9oWEyyOfqofwuNN+AZAuG4-akdYG+60-e10e4A@mail.gmail.com>
References: <CAOdCUxNf4nLnXoKYqff=XxOLCWT8YgcRBHWxRMU+heEjeAWJSw@mail.gmail.com>
	<1445569713760.14aec109@Nodemailer>
	<alpine.LFD.2.20.1510230802470.21155@reclus.nhh.no>
	<CAOdCUxPUdqtT_wRLDaMvqt2d88JETn4iArU1CJU49Pcd=VmsFw@mail.gmail.com>
	<alpine.LFD.2.20.1511022202400.13686@reclus.nhh.no>
	<CAOdCUxNY6Cz_9oWEyyOfqofwuNN+AZAuG4-akdYG+60-e10e4A@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511022356480.15639@reclus.nhh.no>

On Mon, 2 Nov 2015, Andy Teucher wrote:

> Amazing (and fast) work Roger, and thanks for the great explanation.
> I can see why you wouldn't want to redo the way Polygons objects are
> structured - I'm sure it would be break a huge amount of existing
> code.
>
> Just curious, does OSX take longer because you have to deal with
> multiple possible GDAL versions?

No, the builds of the underlying external dependencies for the different 
platforms are handled by the CRAN administrators, Simon Urbanek for OSX, 
and I believe he has to trigger a fresh build manually. Windows (Uwe 
Ligges and Brian Ripley) also has the R Winbuilder service, which is worth 
knowing about, and is more automated.

Once the Windows build train compilers are upgraded, we'll move towards 
getting GDAL 2.0.* on these platforms.

For those using OSX, following the R-sig-mac list is very informative - 
see the thread in October on El Capitan ... of course working around 
things like this take time and attention.

Roger

>
> Thanks again,
> Andy
>
> On Mon, Nov 2, 2015 at 1:21 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> Hi Andy,
>>
>> On Mon, 26 Oct 2015, Andy Teucher wrote:
>>
>>> Hi Roger,
>>>
>>> Sorry I haven't been much help here - it's not for lack of trying,
>>> just lack of skills. I've been poring through OGR_write.cpp and trying
>>> to figure out language and the flow of things... a few thoughts
>>> occurred to me (which are probably obvious to you):
>>>
>>
>> Your example was very helpful, the problem was that when writeOGR() and the
>> underlying compiled code was written, the model used was that of the ESRI
>> Shapefile driver, rather than OGC SFS, which was first published in 2004.
>> Most older formats (and their drivers in OGR) use a OGR geometry factory
>> function to organize polygons on reading - but this is not present in
>> shapelib (bundled with the R maptools package), so when designing polygon
>> classes for sp, and writing rgdal::writeOGR() about 10 years ago, this was
>> not known, and was not revisited subsequently, until you happily spotted the
>> bug.
>>
>> GEOS in rgeos uses OGC SFS definitions (the ones you are using below), but
>> the SpatialPolygons/Polygons/Polygon structure was already established by
>> then, and a fix (using comment attributes in Polygons objects) was used,
>> rather than a major change to Polygons objects (in 2010).
>>
>> The revision to rgdal::writeOGR() now branches on the input objects - if
>> they have comments (applied in code, not user-facing), these are trusted,
>> and the MultiPolygon objects constructed containing one or more Polygon
>> objects with one exterior ring and zero or more interior rings on that
>> basis. However, if the input objects do not have comment attributes,
>> OGRGeometryFactory::organizePolygons() (C++) is used to create properly
>> organized MultiPolygon objects for export.
>>
>> This means that the pre-OGC SFS drivers continue to work, but that the OGC
>> SFS drivers, like GeoJSON, now also work correctly when the second ring in
>> an object is not assumed to be an interior ring (rgdal < 1.1-1). A test set
>> for all the possible cases has been introduced.
>>
>> The revision is now in source package form on CRAN:
>>
>> https://cran.r-project.org/web/packages/rgdal/index.html
>>
>> and a Windows binary package will be available later on Tuesday I hope. The
>> OSX revision may take a little longer, but we are grateful to have what we
>> have anyway.
>>
>> Thanks for a clear and very helpful bug report.
>>
>> Best wishes,
>>
>> Roger
>>
>>
>>> 1) Is this bug because holes are standalone polygons in sp objects,
>>> while they are members of polygon objects in geojson, wkt, etc?
>>>
>>> 2) On a related note, I notice that a single polygon with a hole is
>>> identified as a multipolygon containing a single polygon with a hole,
>>> when using writeOGR and one of the affected drivers.  Practically I
>>> don't think this matters too much, but it's not quite right.
>>>
>>> 3) In lines 116-160 the polygon/multipolygon and line/multiline
>>> determination is made for the entire layer. Can/should this be made
>>> for each feature in the layer, as you could have a layer with a
>>> mixture of single polygons and multipolygons?
>>>
>>> 4) I feel like there ought to be one more layer of looping through the
>>> polyons. e.g.:
>>>
>>> loop over each feature;
>>>     determine whether each feature is a single polygon (length 1 or
>>> all rings but one are holes), or a multipolygon:
>>>        if a polygon loop over and add ring(s);
>>>        if a multipolygon loop over polygons:
>>>            for each polygon add ring(s) and somehow assign holes to
>>> parent polygons
>>>
>>> Again, apologies if I'm being totally obvious (or way off base).
>>> Thanks for all your work on these packages, and on this issue.
>>>
>>> Andy
>>>
>>>
>>> On Thu, Oct 22, 2015 at 11:07 PM, Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>>>
>>>> On Fri, 23 Oct 2015, Andy Teucher wrote:
>>>>
>>>>> On my Mac, I am running rgdal 1.0-7 and GDAL 1.11.3
>>>>>
>>>>>
>>>>> sessionInfo()
>>>>>
>>>>
>>>> OK, thanks.
>>>>
>>>> The problem also affects the SQLite driver (the CRAN binaries do not have
>>>> this driver). Could someone please check the PostGIS driver - my guess is
>>>> that all OGC SFS compliant drivers may be affected.
>>>>
>>>> Could somebody also please check whether this is a recently introduced
>>>> issue
>>>> or not? For example somebody still on rgdal < 1.0? src/OGR_write.cpp was
>>>> changed 2015-08-21, but the last previous change was 2015-06-11, then
>>>> 2015-05-31, 2014-08-17 ... from the ChangeLog visible on the package CRAN
>>>> page.
>>>>
>>>> Roger
>>>>
>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> R version 3.2.2 (2015-08-14)
>>>>>
>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>>
>>>>> Running under: OS X 10.11 (El Capitan)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> locale:
>>>>>
>>>>> [1] en_CA.UTF-8/en_CA.UTF-8/en_CA.UTF-8/C/en_CA.UTF-8/en_CA.UTF-8
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> attached base packages:
>>>>>
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> other attached packages:
>>>>>
>>>>> [1] rgdal_1.0-7 sp_1.2-1
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>>
>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Andy
>>>>>
>>>>> On Thu, Oct 22, 2015 at 11:28 AM, Andy Teucher <andy.teucher at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> One more test: WKT has the same issue:
>>>>>> library(rgdal)
>>>>>> js <- '{
>>>>>> "type": "MultiPolygon",
>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>> 3.0],
>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>> 1.0],
>>>>>> [100.0, 0.0]]]]
>>>>>> } '
>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE)
>>>>>> writeOGR(spdf, dsn = "test.csv", layer = "test", driver="CSV",
>>>>>> layer_options = "GEOMETRY=AS_WKT")
>>>>>> cat(readLines("test.csv"), sep = "\n")
>>>>>> WKT,FID,
>>>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2),(100 0,100 1,101 1,101
>>>>>> 0,100 0)))",0
>>>>>> It should be:
>>>>>> WKT,FID,
>>>>>> "MULTIPOLYGON (((102 2,102 3,103 3,103 2,102 2)),((100 0,100 1,101
>>>>>> 1,101 0,100 0)))",0
>>>>>> Andy
>>>>>> On Thu, Oct 22, 2015 at 10:36 AM, Andy Teucher <andy.teucher at gmail.com>
>>>>>> wrote:
>>>>>>>
>>>>>>>
>>>>>>> Thanks very much Roger.
>>>>>>>
>>>>>>> I've replicated this on my work machine (Windows) and on my Mac at
>>>>>>> home.
>>>>>>>
>>>>>>> KML and GML are both affected. ESRI shapefile works fine and, though
>>>>>>> I'm not very familiar with the format, 'MapInfo File' works too
>>>>>>> (loading the file in qgis shows a multipart polygon with no geometry
>>>>>>> errors).
>>>>>>>
>>>>>>> sessionInfo() for my Windows machine (using rgdal 1.0-7 with included
>>>>>>> gdal drivers):
>>>>>>>
>>>>>>> R version 3.2.2 (2015-08-14)
>>>>>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>>>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>>>>>
>>>>>>> locale:
>>>>>>> [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252
>>>>>>> LC_MONETARY=English_Canada.1252
>>>>>>> [4] LC_NUMERIC=C                    LC_TIME=English_Canada.1252
>>>>>>>
>>>>>>> attached base packages:
>>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>>
>>>>>>> other attached packages:
>>>>>>> [1] rgdal_1.0-7 sp_1.2-0
>>>>>>>
>>>>>>> loaded via a namespace (and not attached):
>>>>>>> [1] tools_3.2.2     grid_3.2.2      lattice_0.20-33
>>>>>>>
>>>>>>>
>>>>>>> I'll send the details for my Mac environment this evening.
>>>>>>>
>>>>>>> I'll dig into the source code as soon as I can - C is a completely
>>>>>>> foreign language to me, so I can't promise anything fast!
>>>>>>>
>>>>>>> Thanks again,
>>>>>>> Andy
>>>>>>>
>>>>>>> On Thu, Oct 22, 2015 at 12:27 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>>>>>> wrote:
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, 22 Oct 2015, Andy Teucher wrote:
>>>>>>>>
>>>>>>>>> I?m finding that writeOGR isn?t exporting multipolygons properly
>>>>>>>>> using
>>>>>>>>> the GeoJSON driver. I have a simple test case (borrowed from here:
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> http://gis.stackexchange.com/questions/137977/writeogr-alters-multipolygon-holes)
>>>>>>>>> with a geojson string with one multipolygon containing two polygons.
>>>>>>>>> I
>>>>>>>>> use readOGR to create a SpatialPolygonsDataFrame out of it, then
>>>>>>>>> write
>>>>>>>>> it with writeOGR:
>>>>>>>>>
>>>>>>>>> library(rgdal)
>>>>>>>>>
>>>>>>>>> js <- '{
>>>>>>>>> "type": "MultiPolygon",
>>>>>>>>> "coordinates": [[[[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0,
>>>>>>>>> 3.0],
>>>>>>>>> [102.0, 2.0]]], [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0,
>>>>>>>>> 1.0],
>>>>>>>>> [100.0, 0.0]]]]
>>>>>>>>> } '
>>>>>>>>>
>>>>>>>>> spdf <- readOGR(js, layer='OGRGeoJSON', verbose=FALSE) # Create a
>>>>>>>>> SpatialPoygonsDataFrame
>>>>>>>>>
>>>>>>>>> temp <- tempfile()
>>>>>>>>> writeOGR(spdf, dsn = temp, layer = "", driver="GeoJSON")
>>>>>>>>> cat(readLines(temp))
>>>>>>>>>
>>>>>>>>> # Output:
>>>>>>>>> { "type": "FeatureCollection", "crs": { "type": "name",
>>>>>>>>> "properties":
>>>>>>>>> { "name": "urn:ogc:def:crs:OGC:1.3:CRS84" } }, "features": [ {
>>>>>>>>> "type":
>>>>>>>>> "Feature", "id": 0, "properties": { "FID": 0 }, "geometry": {
>>>>>>>>> "type":
>>>>>>>>> "MultiPolygon", "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ],
>>>>>>>>> [
>>>>>>>>> 103.0, 3.0 ], [ 103.0, 2.0 ], [ 102.0, 2.0 ] ], [ [ 100.0, 0.0 ], [
>>>>>>>>> 100.0, 1.0 ], [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] }
>>>>>>>>> }
>>>>>>>>> ] }
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> I can replicate this with GDAL 2.0.1 and rgdal 1.0-7 - reading temp
>>>>>>>> in
>>>>>>>> gives
>>>>>>>> the orphaned hole. I'm surprised that passing the js object to
>>>>>>>> readOGR()
>>>>>>>> doesn't fail, but that isn't the source of the problem. spdf appears
>>>>>>>> to
>>>>>>>> be
>>>>>>>> structured correctly. Please provide your GDAL and rgdal versions,
>>>>>>>> and
>>>>>>>> OS
>>>>>>>> details from sessionInfo().
>>>>>>>>
>>>>>>>> We are completely relying on the GDAL drivers here - we can't cherry
>>>>>>>> pick
>>>>>>>> for particular drivers (historically excepting ESRI Shapefile), so
>>>>>>>> your
>>>>>>>> debugging will need to examine writeOGR(), the C code it calls, and
>>>>>>>> the
>>>>>>>> interactions between the rgdal C code and called OGR functions.
>>>>>>>> Please
>>>>>>>> check
>>>>>>>> which other drivers are affected (I think KML is, is GML?). Can you
>>>>>>>> place
>>>>>>>> debugging Rprintf(...); in the rgdal C code to see where this is
>>>>>>>> coming
>>>>>>>> from?
>>>>>>>>
>>>>>>>> I can start looking at this sometime next week, so please make a
>>>>>>>> start
>>>>>>>> yourself; contributions from others are very welcome.
>>>>>>>>
>>>>>>>> Roger
>>>>>>>>
>>>>>>>>>
>>>>>>>>> If you look closely at the output, you can see that the
>>>>>>>>> 'coordinates'
>>>>>>>>> array now contains a single polygon array with two coordinate
>>>>>>>>> arrays:
>>>>>>>>> the boundary, and a second one which is now treated as a hole of the
>>>>>>>>> first (orphaned as it is outside the bounds of the polygon). The
>>>>>>>>> original 'coordinates' array consists of two polygon arrays, each
>>>>>>>>> consisting of a single coordinate array which defining a polygon
>>>>>>>>> (with
>>>>>>>>> no holes), which is correct according the GeoJSON spec:
>>>>>>>>> http://geojson.org/geojson-spec.html#polygon.
>>>>>>>>>
>>>>>>>>> I'm always hesitant to call things a bug, but this doesn't appear to
>>>>>>>>> happen using ogr2ogr on the command line:
>>>>>>>>>
>>>>>>>>> writeOGR(spdf, ".", "test", driver = "ESRI Shapefile") # Write a
>>>>>>>>> shapefile to convert using ogr2ogr
>>>>>>>>> system("ogr2ogr -f GeoJSON test_from_shp.geojson test.shp")
>>>>>>>>> cat(readLines("test_from_shp.geojson"))
>>>>>>>>>
>>>>>>>>> # Output:
>>>>>>>>> { "type": "FeatureCollection",  "features": [ { "type": "Feature",
>>>>>>>>> "properties": { "FID": 0 }, "geometry": { "type": "MultiPolygon",
>>>>>>>>> "coordinates": [ [ [ [ 102.0, 2.0 ], [ 102.0, 3.0 ], [ 103.0, 3.0 ],
>>>>>>>>> [
>>>>>>>>> 103.0, 2.0 ], [ 102.0, 2.0 ] ] ], [ [ [ 100.0, 0.0 ], [ 100.0, 1.0
>>>>>>>>> ],
>>>>>>>>> [ 101.0, 1.0 ], [ 101.0, 0.0 ], [ 100.0, 0.0 ] ] ] ] } } ] }
>>>>>>>>>
>>>>>>>>> The resulting output is correct.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Thanks in advance for any help on this.
>>>>>>>>>
>>>>>>>>> Andy
>>>>>>>>>
>>>>>>>>> _______________________________________________
>>>>>>>>> R-sig-Geo mailing list
>>>>>>>>> R-sig-Geo at r-project.org
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Roger Bivand
>>>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Tue Nov  3 00:21:18 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Nov 2015 00:21:18 +0100
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
In-Reply-To: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
References: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511030017110.15639@reclus.nhh.no>

On Tue, 3 Nov 2015, Barry Rowlingson wrote:

> I can create a SpatiaLite DB file and put a layer in it, but if I try
> and add another layer, rgdal fails. Example:
>
> Versions etc:
>
> > require(rgdal)
> Loading required package: rgdal
> Loading required package: sp
> prgdal: version: 1.0-7, (SVN revision 559)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
> Path to GDAL shared files: /usr/share/gdal/1.11
> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
> Path to PROJ.4 shared files: (autodetected)
> Linking to sp version: 1.2-0
>
> Create a simple points data set, write it:
>
> > pts = data.frame(x=runif(10),y=runif(10),z=1:10)
> > coordinates(pts)=~x+y
> > writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
> dataset_option="SPATIALITE=YES")
>
> Note the use of the dataset_option to make this a proper SpatiaLite,
> and not just an SQLite table. The output file is about 4Mb and has a
> lot of metadata tables in it. The file loads into QGIS which
> recognises it as a SpatiaLite table and I can plot the points.
>
> Now try and create another spatial table (this time, "pts2")  in the
> same database file:
>
> > writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
> dataset_option="SPATIALITE=YES")
> Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
> dataset_option = "SPATIALITE=YES") :
>  Creation of output file failed

No reported error in 1.1-1, but the original layer is overwritten. The 
layer in the existing dsn is overwritten. Appending is not something 
writeOGR knows about:

> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite", 
dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite", 
dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite", 
dataset_option = "SPATIALITE=YES",  :
   layer exists, use a new layer name
> ogrListLayers("tmpfile.db")
[1] "pts2"
attr(,"driver")
[1] "SQLite"
attr(,"nlayers")
[1] 1

For now, system("ogr2ogr ..."), or something from gdalUtils? Contribution 
to writeOGR() to implement appending as in 
http://www.gdal.org/drv_sqlite.html?

Roger

>
> I've tried various other options with no success. Is this possible?
> Or do I ditch writeOGR for this and create the table by hand... ick...
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Tue Nov  3 00:45:21 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 2 Nov 2015 23:45:21 +0000
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
In-Reply-To: <76a25d61efd043c88eeec97ddb5048b6@EX-0-HT0.lancs.local>
References: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
	<76a25d61efd043c88eeec97ddb5048b6@EX-0-HT0.lancs.local>
Message-ID: <CANVKczM-ocGjY+ZFrTuqdJ=ErKwk5rp5zufTFjDYdfjtcwJttA@mail.gmail.com>

I don't think what I'm trying to do is "appending". I'm trying to
write two spatial data tables with different names in the single
spatial database file. The database file is the DSN and the tables are
layers - and rgdal is quite happy to add Shapefile "layers" to a
folder "DSN"...

Have just upgraded to rgdal 1.1-1 and still the same problem. Here's a
reprex without prompts:

require(rgdal)
pts=data.frame(x=runif(10),y=runif(10),z=1:10)
coordinates(pts)=~x+y
file.remove("tmpfile.db")

# write layer pts, this works
writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")

# write layer pts2
writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")

Interestingly when I try and write with the *same* table name, rgdal
helpfully suggests "layer exists, use a new layer name", but when I
obey, I get the error behaviour I've described....

Barry



On Mon, Nov 2, 2015 at 11:21 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 3 Nov 2015, Barry Rowlingson wrote:
>
>> I can create a SpatiaLite DB file and put a layer in it, but if I try
>> and add another layer, rgdal fails. Example:
>>
>> Versions etc:
>>
>> > require(rgdal)
>> Loading required package: rgdal
>> Loading required package: sp
>> prgdal: version: 1.0-7, (SVN revision 559)
>> Geospatial Data Abstraction Library extensions to R successfully loaded
>> Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
>> Path to GDAL shared files: /usr/share/gdal/1.11
>> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>> Path to PROJ.4 shared files: (autodetected)
>> Linking to sp version: 1.2-0
>>
>> Create a simple points data set, write it:
>>
>> > pts = data.frame(x=runif(10),y=runif(10),z=1:10)
>> > coordinates(pts)=~x+y
>> > writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
>> dataset_option="SPATIALITE=YES")
>>
>> Note the use of the dataset_option to make this a proper SpatiaLite,
>> and not just an SQLite table. The output file is about 4Mb and has a
>> lot of metadata tables in it. The file loads into QGIS which
>> recognises it as a SpatiaLite table and I can plot the points.
>>
>> Now try and create another spatial table (this time, "pts2")  in the
>> same database file:
>>
>> > writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>> dataset_option="SPATIALITE=YES")
>> Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>> dataset_option = "SPATIALITE=YES") :
>>  Creation of output file failed
>
> No reported error in 1.1-1, but the original layer is overwritten. The
> layer in the existing dsn is overwritten. Appending is not something
> writeOGR knows about:
>
>> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
> Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
> dataset_option = "SPATIALITE=YES",  :
>    layer exists, use a new layer name
>> ogrListLayers("tmpfile.db")
> [1] "pts2"
> attr(,"driver")
> [1] "SQLite"
> attr(,"nlayers")
> [1] 1
>
> For now, system("ogr2ogr ..."), or something from gdalUtils? Contribution
> to writeOGR() to implement appending as in
> http://www.gdal.org/drv_sqlite.html?
>
> Roger
>
>>
>> I've tried various other options with no success. Is this possible?
>> Or do I ditch writeOGR for this and create the table by hand... ick...
>>
>> Barry
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>


From Roger.Bivand at nhh.no  Tue Nov  3 08:01:00 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Nov 2015 08:01:00 +0100
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
In-Reply-To: <CANVKczM-ocGjY+ZFrTuqdJ=ErKwk5rp5zufTFjDYdfjtcwJttA@mail.gmail.com>
References: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
	<76a25d61efd043c88eeec97ddb5048b6@EX-0-HT0.lancs.local>
	<CANVKczM-ocGjY+ZFrTuqdJ=ErKwk5rp5zufTFjDYdfjtcwJttA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511030741550.28173@reclus.nhh.no>

On Tue, 3 Nov 2015, Barry Rowlingson wrote:

> I don't think what I'm trying to do is "appending". I'm trying to
> write two spatial data tables with different names in the single
> spatial database file. The database file is the DSN and the tables are
> layers - and rgdal is quite happy to add Shapefile "layers" to a
> folder "DSN"...
>
> Have just upgraded to rgdal 1.1-1 and still the same problem. Here's a
> reprex without prompts:
>
> require(rgdal)
> pts=data.frame(x=runif(10),y=runif(10),z=1:10)
> coordinates(pts)=~x+y
> file.remove("tmpfile.db")
>
> # write layer pts, this works
> writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>
> # write layer pts2
> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>
> Interestingly when I try and write with the *same* table name, rgdal
> helpfully suggests "layer exists, use a new layer name", but when I
> obey, I get the error behaviour I've described....

There is nothing (much) in rgdal::writeOGR() that knows much about the 
drivers and (see separate recent thread) the implementation is really 
based on the simplest formats that existed 10 years ago. Spatialite is 
fast-changing, and not very stable in my experience. You're asking for OGR 
to handle this, but writeOGR() isn't aware that it needs to ask OGR for 
things that were not there when it was written (it was based on GRASS 
v.out.ogr from even earlier). It would be nice if it worked by chance, 
unspecified, but more needs to be done to check, and it looks as though 
it doesn't work (the single added layer overwrites the existing layer, 
problably because the dsn= isn't opened to append).

Does the same thing happen without specifying Spatialite? Does the same 
thing happen with PostGIS? Other DBs? We know that when dsn= is a 
directory and the driver is ESRI Shapefile, it does what we expect, but 
should we expect it to do that when dsn= is a file?

Please look around line 60 in rgdal/R/ogr_write.R to see how writeOGR() 
handles dsn and layer checking. This may need conditioning on the driver - 
there is already a kludgy "fix" for dsn= deletion for shapefiles for GDAL 
>=2.

When you're checking improvements to writeOGR(), please set a baseline 
using gdalUtils::ogr2ogr() so that we know where we are. We'll need to 
support GDAL < 2 and GDAL >= 2, which use drivers differently.

Best wishes,

Roger

>
> Barry
>
>
>
> On Mon, Nov 2, 2015 at 11:21 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Tue, 3 Nov 2015, Barry Rowlingson wrote:
>>
>>> I can create a SpatiaLite DB file and put a layer in it, but if I try
>>> and add another layer, rgdal fails. Example:
>>>
>>> Versions etc:
>>>
>>>> require(rgdal)
>>> Loading required package: rgdal
>>> Loading required package: sp
>>> prgdal: version: 1.0-7, (SVN revision 559)
>>> Geospatial Data Abstraction Library extensions to R successfully loaded
>>> Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
>>> Path to GDAL shared files: /usr/share/gdal/1.11
>>> Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>>> Path to PROJ.4 shared files: (autodetected)
>>> Linking to sp version: 1.2-0
>>>
>>> Create a simple points data set, write it:
>>>
>>>> pts = data.frame(x=runif(10),y=runif(10),z=1:10)
>>>> coordinates(pts)=~x+y
>>>> writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
>>> dataset_option="SPATIALITE=YES")
>>>
>>> Note the use of the dataset_option to make this a proper SpatiaLite,
>>> and not just an SQLite table. The output file is about 4Mb and has a
>>> lot of metadata tables in it. The file loads into QGIS which
>>> recognises it as a SpatiaLite table and I can plot the points.
>>>
>>> Now try and create another spatial table (this time, "pts2")  in the
>>> same database file:
>>>
>>>> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>>> dataset_option="SPATIALITE=YES")
>>> Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>>> dataset_option = "SPATIALITE=YES") :
>>>  Creation of output file failed
>>
>> No reported error in 1.1-1, but the original layer is overwritten. The
>> layer in the existing dsn is overwritten. Appending is not something
>> writeOGR knows about:
>>
>>> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>> writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>> Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>> dataset_option = "SPATIALITE=YES",  :
>>    layer exists, use a new layer name
>>> ogrListLayers("tmpfile.db")
>> [1] "pts2"
>> attr(,"driver")
>> [1] "SQLite"
>> attr(,"nlayers")
>> [1] 1
>>
>> For now, system("ogr2ogr ..."), or something from gdalUtils? Contribution
>> to writeOGR() to implement appending as in
>> http://www.gdal.org/drv_sqlite.html?
>>
>> Roger
>>
>>>
>>> I've tried various other options with no success. Is this possible?
>>> Or do I ditch writeOGR for this and create the table by hand... ick...
>>>
>>> Barry
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Tue Nov  3 08:15:34 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 3 Nov 2015 08:15:34 +0100
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
In-Reply-To: <alpine.LFD.2.20.1511030741550.28173@reclus.nhh.no>
References: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
	<76a25d61efd043c88eeec97ddb5048b6@EX-0-HT0.lancs.local>
	<CANVKczM-ocGjY+ZFrTuqdJ=ErKwk5rp5zufTFjDYdfjtcwJttA@mail.gmail.com>
	<alpine.LFD.2.20.1511030741550.28173@reclus.nhh.no>
Message-ID: <alpine.LFD.2.20.1511030813020.28662@reclus.nhh.no>

On Tue, 3 Nov 2015, Roger Bivand wrote:

> On Tue, 3 Nov 2015, Barry Rowlingson wrote:
>
>>  I don't think what I'm trying to do is "appending". I'm trying to
>>  write two spatial data tables with different names in the single
>>  spatial database file. The database file is the DSN and the tables are
>>  layers - and rgdal is quite happy to add Shapefile "layers" to a
>>  folder "DSN"...
>>
>>  Have just upgraded to rgdal 1.1-1 and still the same problem. Here's a
>>  reprex without prompts:
>>
>>  require(rgdal)
>>  pts=data.frame(x=runif(10),y=runif(10),z=1:10)
>>  coordinates(pts)=~x+y
>>  file.remove("tmpfile.db")
>>
>>  # write layer pts, this works
>>  writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
>>  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>
>>  # write layer pts2
>>  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>>  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>
>>  Interestingly when I try and write with the *same* table name, rgdal
>>  helpfully suggests "layer exists, use a new layer name", but when I
>>  obey, I get the error behaviour I've described....
>
> There is nothing (much) in rgdal::writeOGR() that knows much about the 
> drivers and (see separate recent thread) the implementation is really based 
> on the simplest formats that existed 10 years ago. Spatialite is 
> fast-changing, and not very stable in my experience. You're asking for OGR to 
> handle this, but writeOGR() isn't aware that it needs to ask OGR for things 
> that were not there when it was written (it was based on GRASS v.out.ogr from 
> even earlier). It would be nice if it worked by chance, unspecified, but more 
> needs to be done to check, and it looks as though it doesn't work (the single 
> added layer overwrites the existing layer, problably because the dsn= isn't 
> opened to append).
>
> Does the same thing happen without specifying Spatialite? Does the same thing 
> happen with PostGIS? Other DBs? We know that when dsn= is a directory and the 
> driver is ESRI Shapefile, it does what we expect, but should we expect it to 
> do that when dsn= is a file?
>
> Please look around line 60 in rgdal/R/ogr_write.R to see how writeOGR() 
> handles dsn and layer checking. This may need conditioning on the driver - 
> there is already a kludgy "fix" for dsn= deletion for shapefiles for GDAL 
>> =2.
>
> When you're checking improvements to writeOGR(), please set a baseline using 
> gdalUtils::ogr2ogr() so that we know where we are. We'll need to support GDAL 
> < 2 and GDAL >= 2, which use drivers differently.

tf1 <- tempfile()
tf2 <- tempfile()
require(rgdal)
pts=data.frame(x=runif(10),y=runif(10),z=1:10)
coordinates(pts)=~x+y
writeOGR(pts, tf1, "pts", driver="SQLite",
dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
writeOGR(pts, tf2, "pts2", driver="SQLite",
dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
ogrListLayers(tf1)
ogrListLayers(tf2)
library(gdalUtils)
ogr2ogr(tf2, tf1, append=TRUE, nln="pts2a")
ogrListLayers(tf1)
ogrInfo(tf1, "pts")
ogrInfo(tf1, "pts2a")

Roger

>
> Best wishes,
>
> Roger
>
>>
>>  Barry
>> 
>> 
>>
>>  On Mon, Nov 2, 2015 at 11:21 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> >  On Tue, 3 Nov 2015, Barry Rowlingson wrote:
>> > 
>> > >  I can create a SpatiaLite DB file and put a layer in it, but if I try
>> > >  and add another layer, rgdal fails. Example:
>> > > 
>> > >  Versions etc:
>> > > 
>> > > >  require(rgdal)
>> > >  Loading required package: rgdal
>> > >  Loading required package: sp
>> > >  prgdal: version: 1.0-7, (SVN revision 559)
>> > >  Geospatial Data Abstraction Library extensions to R successfully 
>> > >  loaded
>> > >  Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
>> > >  Path to GDAL shared files: /usr/share/gdal/1.11
>> > >  Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>> > >  Path to PROJ.4 shared files: (autodetected)
>> > >  Linking to sp version: 1.2-0
>> > > 
>> > >  Create a simple points data set, write it:
>> > > 
>> > > >  pts = data.frame(x=runif(10),y=runif(10),z=1:10)
>> > > >  coordinates(pts)=~x+y
>> > > >  writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
>> > >  dataset_option="SPATIALITE=YES")
>> > > 
>> > >  Note the use of the dataset_option to make this a proper SpatiaLite,
>> > >  and not just an SQLite table. The output file is about 4Mb and has a
>> > >  lot of metadata tables in it. The file loads into QGIS which
>> > >  recognises it as a SpatiaLite table and I can plot the points.
>> > > 
>> > >  Now try and create another spatial table (this time, "pts2")  in the
>> > >  same database file:
>> > > 
>> > > >  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>> > >  dataset_option="SPATIALITE=YES")
>> > >  Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>> > >  dataset_option = "SPATIALITE=YES") :
>> > >   Creation of output file failed
>> > 
>> >  No reported error in 1.1-1, but the original layer is overwritten. The
>> >  layer in the existing dsn is overwritten. Appending is not something
>> >  writeOGR knows about:
>> > 
>> > >  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>> >  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>> > >  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>> >  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>> >  Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>> >  dataset_option = "SPATIALITE=YES",  :
>> >     layer exists, use a new layer name
>> > >  ogrListLayers("tmpfile.db")
>> >  [1] "pts2"
>> >  attr(,"driver")
>> >  [1] "SQLite"
>> >  attr(,"nlayers")
>> >  [1] 1
>> > 
>> >  For now, system("ogr2ogr ..."), or something from gdalUtils? 
>> >  Contribution
>> >  to writeOGR() to implement appending as in
>> >  http://www.gdal.org/drv_sqlite.html?
>> > 
>> >  Roger
>> > 
>> > > 
>> > >  I've tried various other options with no success. Is this possible?
>> > >  Or do I ditch writeOGR for this and create the table by hand... ick...
>> > > 
>> > >  Barry
>> > > 
>> > >  _______________________________________________
>> > >  R-sig-Geo mailing list
>> > >  R-sig-Geo at r-project.org
>> > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > 
>> > 
>> >  --
>> >  Roger Bivand
>> >  Department of Economics, Norwegian School of Economics,
>> >  Helleveien 30, N-5045 Bergen, Norway.
>> >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>> >  e-mail: Roger.Bivand at nhh.no
>> > 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From b.rowlingson at lancaster.ac.uk  Tue Nov  3 10:24:33 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 3 Nov 2015 09:24:33 +0000
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
In-Reply-To: <alpine.LFD.2.20.1511030813020.28662@reclus.nhh.no>
References: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
	<76a25d61efd043c88eeec97ddb5048b6@EX-0-HT0.lancs.local>
	<CANVKczM-ocGjY+ZFrTuqdJ=ErKwk5rp5zufTFjDYdfjtcwJttA@mail.gmail.com>
	<alpine.LFD.2.20.1511030741550.28173@reclus.nhh.no>
	<alpine.LFD.2.20.1511030813020.28662@reclus.nhh.no>
Message-ID: <CANVKczNyqQizuBcY2g2bw6YJ0dQ+gzjnQsqC0-LQr=GMdJWpow@mail.gmail.com>

After some digging...

The problem appears to be that OGR_write.cpp always tries to create a
new data source. This would appear to be the wrong thing to do when
you have an existing data source that can have multiple layers. Code
should probably only try and create the data source if its not there.
The PostGIS driver in OGR can't create data sources, so I'd expect
writing PostGIS with writeOGR to fail, which I'm not sure is the case
because surely people would scream and I don't have a PostGIS handy so
that's a bit contradictory... There seems to be an OGR "Can You Create
a Data Source?" capability test for drivers...

I think ogr2ogr works because it has a special case for a few drivers
(inlcuding SQLite) where it uses the same driver handle for source and
destination - so it doesn't even try creating the destination data
source.

I'm not sure how much more I want to dig into this, especially since
I'm on a Gdal 1.11 system but everything is going all 2.0 now. Would
there be any point making it work for 1.11 systems? How long until
we're all on 2.0?

Barry







On Tue, Nov 3, 2015 at 7:15 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 3 Nov 2015, Roger Bivand wrote:
>
>> On Tue, 3 Nov 2015, Barry Rowlingson wrote:
>>
>>>  I don't think what I'm trying to do is "appending". I'm trying to
>>>  write two spatial data tables with different names in the single
>>>  spatial database file. The database file is the DSN and the tables are
>>>  layers - and rgdal is quite happy to add Shapefile "layers" to a
>>>  folder "DSN"...
>>>
>>>  Have just upgraded to rgdal 1.1-1 and still the same problem. Here's a
>>>  reprex without prompts:
>>>
>>>  require(rgdal)
>>>  pts=data.frame(x=runif(10),y=runif(10),z=1:10)
>>>  coordinates(pts)=~x+y
>>>  file.remove("tmpfile.db")
>>>
>>>  # write layer pts, this works
>>>  writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
>>>  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>>
>>>  # write layer pts2
>>>  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>>>  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>>
>>>  Interestingly when I try and write with the *same* table name, rgdal
>>>  helpfully suggests "layer exists, use a new layer name", but when I
>>>  obey, I get the error behaviour I've described....
>>
>>
>> There is nothing (much) in rgdal::writeOGR() that knows much about the
>> drivers and (see separate recent thread) the implementation is really based
>> on the simplest formats that existed 10 years ago. Spatialite is
>> fast-changing, and not very stable in my experience. You're asking for OGR
>> to handle this, but writeOGR() isn't aware that it needs to ask OGR for
>> things that were not there when it was written (it was based on GRASS
>> v.out.ogr from even earlier). It would be nice if it worked by chance,
>> unspecified, but more needs to be done to check, and it looks as though it
>> doesn't work (the single added layer overwrites the existing layer,
>> problably because the dsn= isn't opened to append).
>>
>> Does the same thing happen without specifying Spatialite? Does the same
>> thing happen with PostGIS? Other DBs? We know that when dsn= is a directory
>> and the driver is ESRI Shapefile, it does what we expect, but should we
>> expect it to do that when dsn= is a file?
>>
>> Please look around line 60 in rgdal/R/ogr_write.R to see how writeOGR()
>> handles dsn and layer checking. This may need conditioning on the driver -
>> there is already a kludgy "fix" for dsn= deletion for shapefiles for GDAL
>>>
>>> =2.
>>
>>
>> When you're checking improvements to writeOGR(), please set a baseline
>> using gdalUtils::ogr2ogr() so that we know where we are. We'll need to
>> support GDAL < 2 and GDAL >= 2, which use drivers differently.
>
>
> tf1 <- tempfile()
> tf2 <- tempfile()
> require(rgdal)
> pts=data.frame(x=runif(10),y=runif(10),z=1:10)
> coordinates(pts)=~x+y
> writeOGR(pts, tf1, "pts", driver="SQLite",
> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
> writeOGR(pts, tf2, "pts2", driver="SQLite",
> dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
> ogrListLayers(tf1)
> ogrListLayers(tf2)
> library(gdalUtils)
> ogr2ogr(tf2, tf1, append=TRUE, nln="pts2a")
> ogrListLayers(tf1)
> ogrInfo(tf1, "pts")
> ogrInfo(tf1, "pts2a")
>
> Roger
>
>>
>> Best wishes,
>>
>> Roger
>>
>>>
>>>  Barry
>>>
>>>
>>>
>>>  On Mon, Nov 2, 2015 at 11:21 PM, Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>> >  On Tue, 3 Nov 2015, Barry Rowlingson wrote:
>>> > > >  I can create a SpatiaLite DB file and put a layer in it, but if I
>>> > > > try
>>> > >  and add another layer, rgdal fails. Example:
>>> > > > >  Versions etc:
>>> > > > > >  require(rgdal)
>>> > >  Loading required package: rgdal
>>> > >  Loading required package: sp
>>> > >  prgdal: version: 1.0-7, (SVN revision 559)
>>> > >  Geospatial Data Abstraction Library extensions to R successfully > >
>>> > > loaded
>>> > >  Loaded GDAL runtime: GDAL 1.11.2, released 2015/02/10
>>> > >  Path to GDAL shared files: /usr/share/gdal/1.11
>>> > >  Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
>>> > >  Path to PROJ.4 shared files: (autodetected)
>>> > >  Linking to sp version: 1.2-0
>>> > > > >  Create a simple points data set, write it:
>>> > > > > >  pts = data.frame(x=runif(10),y=runif(10),z=1:10)
>>> > > >  coordinates(pts)=~x+y
>>> > > >  writeOGR(pts, "tmpfile.db", "pts", driver="SQLite",
>>> > >  dataset_option="SPATIALITE=YES")
>>> > > > >  Note the use of the dataset_option to make this a proper
>>> > > > > SpatiaLite,
>>> > >  and not just an SQLite table. The output file is about 4Mb and has a
>>> > >  lot of metadata tables in it. The file loads into QGIS which
>>> > >  recognises it as a SpatiaLite table and I can plot the points.
>>> > > > >  Now try and create another spatial table (this time, "pts2")  in
>>> > > > > the
>>> > >  same database file:
>>> > > > > >  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>>> > >  dataset_option="SPATIALITE=YES")
>>> > >  Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>>> > >  dataset_option = "SPATIALITE=YES") :
>>> > >   Creation of output file failed
>>> > >  No reported error in 1.1-1, but the original layer is overwritten.
>>> > > The
>>> >  layer in the existing dsn is overwritten. Appending is not something
>>> >  writeOGR knows about:
>>> > > >  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>>> >  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>> > >  writeOGR(pts, "tmpfile.db", "pts2", driver="SQLite",
>>> >  dataset_option="SPATIALITE=YES", layer_option="FORMAT=SPATIALITE")
>>> >  Error in writeOGR(pts, "tmpfile.db", "pts2", driver = "SQLite",
>>> >  dataset_option = "SPATIALITE=YES",  :
>>> >     layer exists, use a new layer name
>>> > >  ogrListLayers("tmpfile.db")
>>> >  [1] "pts2"
>>> >  attr(,"driver")
>>> >  [1] "SQLite"
>>> >  attr(,"nlayers")
>>> >  [1] 1
>>> > >  For now, system("ogr2ogr ..."), or something from gdalUtils? >
>>> > > Contribution
>>> >  to writeOGR() to implement appending as in
>>> >  http://www.gdal.org/drv_sqlite.html?
>>> > >  Roger
>>> > > > > >  I've tried various other options with no success. Is this
>>> > > > > > possible?
>>> > >  Or do I ditch writeOGR for this and create the table by hand...
>>> > > ick...
>>> > > > >  Barry
>>> > > > >  _______________________________________________
>>> > >  R-sig-Geo mailing list
>>> > >  R-sig-Geo at r-project.org
>>> > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > > > >  --
>>> >  Roger Bivand
>>> >  Department of Economics, Norwegian School of Economics,
>>> >  Helleveien 30, N-5045 Bergen, Norway.
>>> >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> >  e-mail: Roger.Bivand at nhh.no
>>> >
>>
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Lee.Hachadoorian+L at gmail.com  Tue Nov  3 17:26:35 2015
From: Lee.Hachadoorian+L at gmail.com (Lee Hachadoorian)
Date: Tue, 3 Nov 2015 11:26:35 -0500
Subject: [R-sig-Geo] Adding spatial tables to existing SpatiaLite DBs
In-Reply-To: <CANVKczNyqQizuBcY2g2bw6YJ0dQ+gzjnQsqC0-LQr=GMdJWpow@mail.gmail.com>
References: <CANVKczNHtxNiBJ_NAg70Lx4AWSAaJoxFXAxYYqWKhW+kmMmD1w@mail.gmail.com>
	<76a25d61efd043c88eeec97ddb5048b6@EX-0-HT0.lancs.local>
	<CANVKczM-ocGjY+ZFrTuqdJ=ErKwk5rp5zufTFjDYdfjtcwJttA@mail.gmail.com>
	<alpine.LFD.2.20.1511030741550.28173@reclus.nhh.no>
	<alpine.LFD.2.20.1511030813020.28662@reclus.nhh.no>
	<CANVKczNyqQizuBcY2g2bw6YJ0dQ+gzjnQsqC0-LQr=GMdJWpow@mail.gmail.com>
Message-ID: <5638E03B.2040404@gmail.com>



On 11/03/2015 04:24 AM, Barry Rowlingson wrote:
> After some digging...
>
> The problem appears to be that OGR_write.cpp always tries to create a
> new data source. This would appear to be the wrong thing to do when
> you have an existing data source that can have multiple layers. Code
> should probably only try and create the data source if its not there.
> The PostGIS driver in OGR can't create data sources, so I'd expect
> writing PostGIS with writeOGR to fail, which I'm not sure is the case
> because surely people would scream and I don't have a PostGIS handy so
> that's a bit contradictory... There seems to be an OGR "Can You Create
> a Data Source?" capability test for drivers...
>
> I think ogr2ogr works because it has a special case for a few drivers
> (inlcuding SQLite) where it uses the same driver handle for source and
> destination - so it doesn't even try creating the destination data
> source.
>
> I'm not sure how much more I want to dig into this, especially since
> I'm on a Gdal 1.11 system but everything is going all 2.0 now. Would
> there be any point making it work for 1.11 systems? How long until
> we're all on 2.0?
>
> Barry


Ogr2ogr can add layers to any driver that supports multiple layers using 
the -update switch:

     ogr2ogr -update destination source [layers]

If layers are not specified for a multi-layer source, *all* of them will 
be transferred.

Although writeOGR does expose the -update switch, it does successfully 
add layers to existing PostGIS database.

As Roger pointed out, gdalUtils exposes full functionality of ogr2ogr. 
So the following takes a couple of extra lines of code but works:

```
library(rgdal)
library(gdalUtils)

pts = data.frame(x=runif(10),y=runif(10),z=1:10)
coordinates(pts)=~x+y
writeOGR(pts, "final.sqlite", "pts", driver="SQLite", dataset_options = 
"SPATIALITE=YES")
writeOGR(pts, "tmp.sqlite", "pts2", driver="SQLite", dataset_options = 
"SPATIALITE=YES")

ogr2ogr("tmp.sqlite", "final.sqlite", "pts2", update=TRUE)
file.remove("tmp.sqlite")

```

Some other notes:

Without the -update switch, ogr2ogr will silently overwrite the 
destination.

Note that what writeOGR calls dataset_options are dataset *creation* 
options, so "SPATIALITE=YES" is not needed when adding layers to 
existing SpatiaLite DB. (For that matter, neither is the layer creation 
option "FORMAT=SPATIALITE".)

Best,
--Lee

-- 
Lee Hachadoorian
Assistant Professor of Instruction, Geography & Urban Studies
Assistant Director, Professional Science Master's in GIS
Temple University
http://geospatial.commons.gc.cuny.edu
http://freecity.commons.gc.cuny.edu


From strimas at zoology.ubc.ca  Tue Nov  3 21:29:03 2015
From: strimas at zoology.ubc.ca (Matt Strimas-Mackey)
Date: Tue, 3 Nov 2015 12:29:03 -0800
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
Message-ID: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>

I'm working with a regular hexagonal grid stored as SPDF. At some
point I subset this SPDF, then want to combine all adjacent hexagons
together so that each contiguous set of hexagons is a single polygon.
I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
clear what the different is actually). The problem is that in some
cases boundaries between clearly adjacent polygons are not dissolved.

Example:

## Create three adjacent hexagons
library(sp)
library(rgeos)
p1 <- Polygon(cbind(
      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
        1287248.96712942, 1281876.11747031, 1276503.26781119, 1276503.26781119),
      c(204391.40834643, 207493.42454344, 204391.40834643, 198187.37595242,
        195085.35975541, 198187.37595242, 204391.40834643)))
p2 <- Polygon(cbind(
      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
        1297994.66644766, 1292621.81678854, 1287248.96712943, 1287248.96712943),
      c(204391.40834643, 207493.42454344, 204391.40834643, 198187.37595242,
        195085.35975541, 198187.37595242, 204391.40834643)))
p3 <- Polygon(cbind(
      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
        1292621.81678854, 1287248.96712943, 1281876.11747031, 1281876.11747031),
      c(213697.45693745, 216799.47313446, 213697.45693745, 207493.42454344,
        204391.40834643, 207493.42454344, 213697.45693745)))
spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
plot(gUnaryUnion(spoly))

Note that p2 and p3 are dissolved together, but p1 is separate. The
shared edge of p1 and p2 is:
p1:
[2,] 1281876 207493.4
[3,] 1287249 204391.4
p2:
[5,] 1287249 204391.4
[6,] 1281876 207493.4

So, exactly the same apart from the order. I originally thought this
difference in order might be the problem, but this doesn't seem to be
an issue with in this example, where order is also flipped:
sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
ymx=2, vals=1:4))
lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
plot(sss)
plot(gUnaryUnion(sss))

Session Info:
R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.10.5 (Yosemite)

Message when rgeos is loaded:

rgeos version: 0.3-14, (SVN revision 511)
GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
Linking to sp version: 1.2-0
Polygon checking: TRUE

Any help on how to get these polygons to dissolve is appreciated.

M


From Roger.Bivand at nhh.no  Wed Nov  4 08:14:08 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Nov 2015 08:14:08 +0100
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>

On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:

> I'm working with a regular hexagonal grid stored as SPDF. At some
> point I subset this SPDF, then want to combine all adjacent hexagons
> together so that each contiguous set of hexagons is a single polygon.
> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
> clear what the different is actually). The problem is that in some
> cases boundaries between clearly adjacent polygons are not dissolved.
>
> Example:
>
> ## Create three adjacent hexagons
> library(sp)
> library(rgeos)
> p1 <- Polygon(cbind(
>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>        1287248.96712942, 1281876.11747031, 1276503.26781119, 1276503.26781119),
>      c(204391.40834643, 207493.42454344, 204391.40834643, 198187.37595242,
>        195085.35975541, 198187.37595242, 204391.40834643)))
> p2 <- Polygon(cbind(
>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>        1297994.66644766, 1292621.81678854, 1287248.96712943, 1287248.96712943),
>      c(204391.40834643, 207493.42454344, 204391.40834643, 198187.37595242,
>        195085.35975541, 198187.37595242, 204391.40834643)))
> p3 <- Polygon(cbind(
>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>        1292621.81678854, 1287248.96712943, 1281876.11747031, 1281876.11747031),
>      c(213697.45693745, 216799.47313446, 213697.45693745, 207493.42454344,
>        204391.40834643, 207493.42454344, 213697.45693745)))
> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
> plot(gUnaryUnion(spoly))

No, this is just numerical fuzz:

plot(spoly)
plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
oS <- getScale()
# default 1e+8
setScale(1e+4)
plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
setScale(oS)

JTS, GEOS, and consequently rgeos by default shift all coordinates to an 
integer grid after multiplying by a scale factor (finding integer matches 
is much easier than real matches). If the scaling is too detailed (in some 
cases), the operations do not give the expected outcomes.

There is work in progress in GEOS and JTS to provide other scaling options 
and models, and to permit iteration over scaling values until a "clean" 
result is obtained (for some meanings of clean).

gUnionCascaded() was the only possible function for GEOS < 3.3.0, from 
GEOS 3.3.0 gUnaryUnion() is available and the prefered and more efficient 
route. This is explained on the help page.

Hope this clarifies,

Roger

>
> Note that p2 and p3 are dissolved together, but p1 is separate. The
> shared edge of p1 and p2 is:
> p1:
> [2,] 1281876 207493.4
> [3,] 1287249 204391.4
> p2:
> [5,] 1287249 204391.4
> [6,] 1281876 207493.4
>
> So, exactly the same apart from the order. I originally thought this
> difference in order might be the problem, but this doesn't seem to be
> an issue with in this example, where order is also flipped:
> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
> ymx=2, vals=1:4))
> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
> plot(sss)
> plot(gUnaryUnion(sss))
>
> Session Info:
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: OS X 10.10.5 (Yosemite)
>
> Message when rgeos is loaded:
>
> rgeos version: 0.3-14, (SVN revision 511)
> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
> Linking to sp version: 1.2-0
> Polygon checking: TRUE
>
> Any help on how to get these polygons to dissolve is appreciated.
>
> M
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From mdsumner at gmail.com  Wed Nov  4 14:32:05 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 04 Nov 2015 13:32:05 +0000
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
Message-ID: <CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>

Thanks for all this detail Roger, is there a way to "re-build" a spatial
object so that the given scale setting is applied? Are there any general
rounding or "orthogonalize" functions in the Spatial suite?

Cheers, Mike.

On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>
> > I'm working with a regular hexagonal grid stored as SPDF. At some
> > point I subset this SPDF, then want to combine all adjacent hexagons
> > together so that each contiguous set of hexagons is a single polygon.
> > I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
> > clear what the different is actually). The problem is that in some
> > cases boundaries between clearly adjacent polygons are not dissolved.
> >
> > Example:
> >
> > ## Create three adjacent hexagons
> > library(sp)
> > library(rgeos)
> > p1 <- Polygon(cbind(
> >      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
> >        1287248.96712942, 1281876.11747031, 1276503.26781119,
> 1276503.26781119),
> >      c(204391.40834643, 207493.42454344, 204391.40834643,
> 198187.37595242,
> >        195085.35975541, 198187.37595242, 204391.40834643)))
> > p2 <- Polygon(cbind(
> >      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
> >        1297994.66644766, 1292621.81678854, 1287248.96712943,
> 1287248.96712943),
> >      c(204391.40834643, 207493.42454344, 204391.40834643,
> 198187.37595242,
> >        195085.35975541, 198187.37595242, 204391.40834643)))
> > p3 <- Polygon(cbind(
> >      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
> >        1292621.81678854, 1287248.96712943, 1281876.11747031,
> 1281876.11747031),
> >      c(213697.45693745, 216799.47313446, 213697.45693745,
> 207493.42454344,
> >        204391.40834643, 207493.42454344, 213697.45693745)))
> > spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
> > plot(gUnaryUnion(spoly))
>
> No, this is just numerical fuzz:
>
> plot(spoly)
> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
> oS <- getScale()
> # default 1e+8
> setScale(1e+4)
> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
> setScale(oS)
>
> JTS, GEOS, and consequently rgeos by default shift all coordinates to an
> integer grid after multiplying by a scale factor (finding integer matches
> is much easier than real matches). If the scaling is too detailed (in some
> cases), the operations do not give the expected outcomes.
>
> There is work in progress in GEOS and JTS to provide other scaling options
> and models, and to permit iteration over scaling values until a "clean"
> result is obtained (for some meanings of clean).
>
> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more efficient
> route. This is explained on the help page.
>
> Hope this clarifies,
>
> Roger
>
> >
> > Note that p2 and p3 are dissolved together, but p1 is separate. The
> > shared edge of p1 and p2 is:
> > p1:
> > [2,] 1281876 207493.4
> > [3,] 1287249 204391.4
> > p2:
> > [5,] 1287249 204391.4
> > [6,] 1281876 207493.4
> >
> > So, exactly the same apart from the order. I originally thought this
> > difference in order might be the problem, but this doesn't seem to be
> > an issue with in this example, where order is also flipped:
> > sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
> > ymx=2, vals=1:4))
> > lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
> > plot(sss)
> > plot(gUnaryUnion(sss))
> >
> > Session Info:
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-apple-darwin13.4.0 (64-bit)
> > Running under: OS X 10.10.5 (Yosemite)
> >
> > Message when rgeos is loaded:
> >
> > rgeos version: 0.3-14, (SVN revision 511)
> > GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
> > Linking to sp version: 1.2-0
> > Polygon checking: TRUE
> >
> > Any help on how to get these polygons to dissolve is appreciated.
> >
> > M
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed Nov  4 15:08:27 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Nov 2015 15:08:27 +0100
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>

On Wed, 4 Nov 2015, Michael Sumner wrote:

> Thanks for all this detail Roger, is there a way to "re-build" a spatial
> object so that the given scale setting is applied? Are there any general
> rounding or "orthogonalize" functions in the Spatial suite?

No, not really. In this case, the very detailed coordinate measurements 
may have made things worse, or possibly using Polygon rather than Polygons 
objects, or not building the Polygons object with a proper comment 
attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and

cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))

says the same (based on rgeos). I suggest working with Emmanuel Blondel 
(cleangeo maintainer) to extend cleangeo. GEOS is looking at allowing 
users to manipulate precision models, not just scale, but I'm uncertain 
about that.

Running spoly into GRASS and back out (GRASS builds topology on import) 
shows a different error, the object seems to be problematic.

Roger

>
> Cheers, Mike.
>
> On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
>> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>>
>>> I'm working with a regular hexagonal grid stored as SPDF. At some
>>> point I subset this SPDF, then want to combine all adjacent hexagons
>>> together so that each contiguous set of hexagons is a single polygon.
>>> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
>>> clear what the different is actually). The problem is that in some
>>> cases boundaries between clearly adjacent polygons are not dissolved.
>>>
>>> Example:
>>>
>>> ## Create three adjacent hexagons
>>> library(sp)
>>> library(rgeos)
>>> p1 <- Polygon(cbind(
>>>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>>>        1287248.96712942, 1281876.11747031, 1276503.26781119,
>> 1276503.26781119),
>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>> 198187.37595242,
>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>> p2 <- Polygon(cbind(
>>>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>>>        1297994.66644766, 1292621.81678854, 1287248.96712943,
>> 1287248.96712943),
>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>> 198187.37595242,
>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>> p3 <- Polygon(cbind(
>>>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>>>        1292621.81678854, 1287248.96712943, 1281876.11747031,
>> 1281876.11747031),
>>>      c(213697.45693745, 216799.47313446, 213697.45693745,
>> 207493.42454344,
>>>        204391.40834643, 207493.42454344, 213697.45693745)))
>>> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
>>> plot(gUnaryUnion(spoly))
>>
>> No, this is just numerical fuzz:
>>
>> plot(spoly)
>> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
>> oS <- getScale()
>> # default 1e+8
>> setScale(1e+4)
>> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>> setScale(oS)
>>
>> JTS, GEOS, and consequently rgeos by default shift all coordinates to an
>> integer grid after multiplying by a scale factor (finding integer matches
>> is much easier than real matches). If the scaling is too detailed (in some
>> cases), the operations do not give the expected outcomes.
>>
>> There is work in progress in GEOS and JTS to provide other scaling options
>> and models, and to permit iteration over scaling values until a "clean"
>> result is obtained (for some meanings of clean).
>>
>> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
>> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more efficient
>> route. This is explained on the help page.
>>
>> Hope this clarifies,
>>
>> Roger
>>
>>>
>>> Note that p2 and p3 are dissolved together, but p1 is separate. The
>>> shared edge of p1 and p2 is:
>>> p1:
>>> [2,] 1281876 207493.4
>>> [3,] 1287249 204391.4
>>> p2:
>>> [5,] 1287249 204391.4
>>> [6,] 1281876 207493.4
>>>
>>> So, exactly the same apart from the order. I originally thought this
>>> difference in order might be the problem, but this doesn't seem to be
>>> an issue with in this example, where order is also flipped:
>>> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
>>> ymx=2, vals=1:4))
>>> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
>>> plot(sss)
>>> plot(gUnaryUnion(sss))
>>>
>>> Session Info:
>>> R version 3.2.2 (2015-08-14)
>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> Running under: OS X 10.10.5 (Yosemite)
>>>
>>> Message when rgeos is loaded:
>>>
>>> rgeos version: 0.3-14, (SVN revision 511)
>>> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>>> Linking to sp version: 1.2-0
>>> Polygon checking: TRUE
>>>
>>> Any help on how to get these polygons to dissolve is appreciated.
>>>
>>> M
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From mdsumner at gmail.com  Wed Nov  4 15:30:42 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 04 Nov 2015 14:30:42 +0000
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
Message-ID: <CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>

On Thu, 5 Nov 2015 at 01:10 Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Wed, 4 Nov 2015, Michael Sumner wrote:
>
> > Thanks for all this detail Roger, is there a way to "re-build" a spatial
> > object so that the given scale setting is applied? Are there any general
> > rounding or "orthogonalize" functions in the Spatial suite?
>
> No, not really. In this case, the very detailed coordinate measurements
> may have made things worse, or possibly using Polygon rather than Polygons
> objects, or not building the Polygons object with a proper comment
> attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>
> cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>
> says the same (based on rgeos). I suggest working with Emmanuel Blondel
> (cleangeo maintainer) to extend cleangeo. GEOS is looking at allowing
> users to manipulate precision models, not just scale, but I'm uncertain
> about that.
>
> Running spoly into GRASS and back out (GRASS builds topology on import)
> shows a different error, the object seems to be problematic.
>
>
It can be fixed by changing "1287248.96712942" to "1287248.96712943", so
really the creator should not have had those values on input.  There's no
easy way out without topology.

This brought out some interesting issues for work I've been doing using the
"near-Delaunay triangulation" in RTriangle, and that requires a normalized
set of vertices (no duplicate vertices) which on its own presents
interesting problems. I have a related issue where a parallel (latitude)
line needs many vertices to look "smooth" on a polar projection, but when
building a mesh with triangles it's really best to allow relatively coarse
segmented boundaries rather than have many elements at parallels. The
Triangle library does not consider these hexagon coordinates to be
duplicates, so there are two vertical segments between the two bottom polys
at

 points(coordinates(as(as(spoly, "SpatialLines"), "SpatialPoints"))[c(3,
4), ])

Thanks for the reminder about cleangeo, I'll have closer look.

cheers, Mike.


> Roger
>
> >
> > Cheers, Mike.
> >
> > On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:
> >
> >> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
> >>
> >>> I'm working with a regular hexagonal grid stored as SPDF. At some
> >>> point I subset this SPDF, then want to combine all adjacent hexagons
> >>> together so that each contiguous set of hexagons is a single polygon.
> >>> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
> >>> clear what the different is actually). The problem is that in some
> >>> cases boundaries between clearly adjacent polygons are not dissolved.
> >>>
> >>> Example:
> >>>
> >>> ## Create three adjacent hexagons
> >>> library(sp)
> >>> library(rgeos)
> >>> p1 <- Polygon(cbind(
> >>>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
> >>>        1287248.96712942, 1281876.11747031, 1276503.26781119,
> >> 1276503.26781119),
> >>>      c(204391.40834643, 207493.42454344, 204391.40834643,
> >> 198187.37595242,
> >>>        195085.35975541, 198187.37595242, 204391.40834643)))
> >>> p2 <- Polygon(cbind(
> >>>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
> >>>        1297994.66644766, 1292621.81678854, 1287248.96712943,
> >> 1287248.96712943),
> >>>      c(204391.40834643, 207493.42454344, 204391.40834643,
> >> 198187.37595242,
> >>>        195085.35975541, 198187.37595242, 204391.40834643)))
> >>> p3 <- Polygon(cbind(
> >>>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
> >>>        1292621.81678854, 1287248.96712943, 1281876.11747031,
> >> 1281876.11747031),
> >>>      c(213697.45693745, 216799.47313446, 213697.45693745,
> >> 207493.42454344,
> >>>        204391.40834643, 207493.42454344, 213697.45693745)))
> >>> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
> >>> plot(gUnaryUnion(spoly))
> >>
> >> No, this is just numerical fuzz:
> >>
> >> plot(spoly)
> >> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
> >> oS <- getScale()
> >> # default 1e+8
> >> setScale(1e+4)
> >> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
> >> setScale(oS)
> >>
> >> JTS, GEOS, and consequently rgeos by default shift all coordinates to an
> >> integer grid after multiplying by a scale factor (finding integer
> matches
> >> is much easier than real matches). If the scaling is too detailed (in
> some
> >> cases), the operations do not give the expected outcomes.
> >>
> >> There is work in progress in GEOS and JTS to provide other scaling
> options
> >> and models, and to permit iteration over scaling values until a "clean"
> >> result is obtained (for some meanings of clean).
> >>
> >> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
> >> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more
> efficient
> >> route. This is explained on the help page.
> >>
> >> Hope this clarifies,
> >>
> >> Roger
> >>
> >>>
> >>> Note that p2 and p3 are dissolved together, but p1 is separate. The
> >>> shared edge of p1 and p2 is:
> >>> p1:
> >>> [2,] 1281876 207493.4
> >>> [3,] 1287249 204391.4
> >>> p2:
> >>> [5,] 1287249 204391.4
> >>> [6,] 1281876 207493.4
> >>>
> >>> So, exactly the same apart from the order. I originally thought this
> >>> difference in order might be the problem, but this doesn't seem to be
> >>> an issue with in this example, where order is also flipped:
> >>> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
> >>> ymx=2, vals=1:4))
> >>> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
> >>> plot(sss)
> >>> plot(gUnaryUnion(sss))
> >>>
> >>> Session Info:
> >>> R version 3.2.2 (2015-08-14)
> >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> >>> Running under: OS X 10.10.5 (Yosemite)
> >>>
> >>> Message when rgeos is loaded:
> >>>
> >>> rgeos version: 0.3-14, (SVN revision 511)
> >>> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
> >>> Linking to sp version: 1.2-0
> >>> Polygon checking: TRUE
> >>>
> >>> Any help on how to get these polygons to dissolve is appreciated.
> >>>
> >>> M
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>
> >> --
> >> Roger Bivand
> >> Department of Economics, Norwegian School of Economics,
> >> Helleveien 30, N-5045 Bergen, Norway.
> >> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >> e-mail: Roger.Bivand at nhh.no
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>

	[[alternative HTML version deleted]]


From strimas at zoology.ubc.ca  Wed Nov  4 16:38:41 2015
From: strimas at zoology.ubc.ca (Matt Strimas-Mackey)
Date: Wed, 4 Nov 2015 07:38:41 -0800
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
Message-ID: <CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>

Thanks, lots of useful info here. I've never seen the setScale()
function; I don't think it's mentioned in the gUnaryUnion help. This
saves me a lot of headache!

For what it's worth, the invalid geometry is an artifact of the
reproducible example I created. The original hexagonal grid is
produced with
g <- spsample(study_area, type="hexagonal", cellsize=size)
hex_grid <- HexPoints2SpatialPolygons(g)

And this object passes gIsValid() and clgeo_GeometryReport() without
any problems, yet still has the dissolving issue. Regardless, all is
solved with setScale().

Thanks!

M

On Wed, Nov 4, 2015 at 6:30 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>
> On Thu, 5 Nov 2015 at 01:10 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>
>> On Wed, 4 Nov 2015, Michael Sumner wrote:
>>
>> > Thanks for all this detail Roger, is there a way to "re-build" a spatial
>> > object so that the given scale setting is applied? Are there any general
>> > rounding or "orthogonalize" functions in the Spatial suite?
>>
>> No, not really. In this case, the very detailed coordinate measurements
>> may have made things worse, or possibly using Polygon rather than Polygons
>> objects, or not building the Polygons object with a proper comment
>> attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>>
>> cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>>
>> says the same (based on rgeos). I suggest working with Emmanuel Blondel
>> (cleangeo maintainer) to extend cleangeo. GEOS is looking at allowing
>> users to manipulate precision models, not just scale, but I'm uncertain
>> about that.
>>
>> Running spoly into GRASS and back out (GRASS builds topology on import)
>> shows a different error, the object seems to be problematic.
>>
>
> It can be fixed by changing "1287248.96712942" to "1287248.96712943", so
> really the creator should not have had those values on input.  There's no
> easy way out without topology.
>
> This brought out some interesting issues for work I've been doing using the
> "near-Delaunay triangulation" in RTriangle, and that requires a normalized
> set of vertices (no duplicate vertices) which on its own presents
> interesting problems. I have a related issue where a parallel (latitude)
> line needs many vertices to look "smooth" on a polar projection, but when
> building a mesh with triangles it's really best to allow relatively coarse
> segmented boundaries rather than have many elements at parallels. The
> Triangle library does not consider these hexagon coordinates to be
> duplicates, so there are two vertical segments between the two bottom polys
> at
>
>  points(coordinates(as(as(spoly, "SpatialLines"), "SpatialPoints"))[c(3, 4),
> ])
>
> Thanks for the reminder about cleangeo, I'll have closer look.
>
> cheers, Mike.
>
>>
>> Roger
>>
>> >
>> > Cheers, Mike.
>> >
>> > On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> >
>> >> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>> >>
>> >>> I'm working with a regular hexagonal grid stored as SPDF. At some
>> >>> point I subset this SPDF, then want to combine all adjacent hexagons
>> >>> together so that each contiguous set of hexagons is a single polygon.
>> >>> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
>> >>> clear what the different is actually). The problem is that in some
>> >>> cases boundaries between clearly adjacent polygons are not dissolved.
>> >>>
>> >>> Example:
>> >>>
>> >>> ## Create three adjacent hexagons
>> >>> library(sp)
>> >>> library(rgeos)
>> >>> p1 <- Polygon(cbind(
>> >>>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>> >>>        1287248.96712942, 1281876.11747031, 1276503.26781119,
>> >> 1276503.26781119),
>> >>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>> >> 198187.37595242,
>> >>>        195085.35975541, 198187.37595242, 204391.40834643)))
>> >>> p2 <- Polygon(cbind(
>> >>>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>> >>>        1297994.66644766, 1292621.81678854, 1287248.96712943,
>> >> 1287248.96712943),
>> >>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>> >> 198187.37595242,
>> >>>        195085.35975541, 198187.37595242, 204391.40834643)))
>> >>> p3 <- Polygon(cbind(
>> >>>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>> >>>        1292621.81678854, 1287248.96712943, 1281876.11747031,
>> >> 1281876.11747031),
>> >>>      c(213697.45693745, 216799.47313446, 213697.45693745,
>> >> 207493.42454344,
>> >>>        204391.40834643, 207493.42454344, 213697.45693745)))
>> >>> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
>> >>> plot(gUnaryUnion(spoly))
>> >>
>> >> No, this is just numerical fuzz:
>> >>
>> >> plot(spoly)
>> >> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
>> >> oS <- getScale()
>> >> # default 1e+8
>> >> setScale(1e+4)
>> >> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>> >> setScale(oS)
>> >>
>> >> JTS, GEOS, and consequently rgeos by default shift all coordinates to
>> >> an
>> >> integer grid after multiplying by a scale factor (finding integer
>> >> matches
>> >> is much easier than real matches). If the scaling is too detailed (in
>> >> some
>> >> cases), the operations do not give the expected outcomes.
>> >>
>> >> There is work in progress in GEOS and JTS to provide other scaling
>> >> options
>> >> and models, and to permit iteration over scaling values until a "clean"
>> >> result is obtained (for some meanings of clean).
>> >>
>> >> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
>> >> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more
>> >> efficient
>> >> route. This is explained on the help page.
>> >>
>> >> Hope this clarifies,
>> >>
>> >> Roger
>> >>
>> >>>
>> >>> Note that p2 and p3 are dissolved together, but p1 is separate. The
>> >>> shared edge of p1 and p2 is:
>> >>> p1:
>> >>> [2,] 1281876 207493.4
>> >>> [3,] 1287249 204391.4
>> >>> p2:
>> >>> [5,] 1287249 204391.4
>> >>> [6,] 1281876 207493.4
>> >>>
>> >>> So, exactly the same apart from the order. I originally thought this
>> >>> difference in order might be the problem, but this doesn't seem to be
>> >>> an issue with in this example, where order is also flipped:
>> >>> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
>> >>> ymx=2, vals=1:4))
>> >>> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
>> >>> plot(sss)
>> >>> plot(gUnaryUnion(sss))
>> >>>
>> >>> Session Info:
>> >>> R version 3.2.2 (2015-08-14)
>> >>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> >>> Running under: OS X 10.10.5 (Yosemite)
>> >>>
>> >>> Message when rgeos is loaded:
>> >>>
>> >>> rgeos version: 0.3-14, (SVN revision 511)
>> >>> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>> >>> Linking to sp version: 1.2-0
>> >>> Polygon checking: TRUE
>> >>>
>> >>> Any help on how to get these polygons to dissolve is appreciated.
>> >>>
>> >>> M
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-Geo mailing list
>> >>> R-sig-Geo at r-project.org
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>>
>> >>
>> >> --
>> >> Roger Bivand
>> >> Department of Economics, Norwegian School of Economics,
>> >> Helleveien 30, N-5045 Bergen, Norway.
>> >> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> >> e-mail: Roger.Bivand at nhh.no
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>


From Roger.Bivand at nhh.no  Wed Nov  4 17:57:22 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Nov 2015 17:57:22 +0100
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>

On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:

> Thanks, lots of useful info here. I've never seen the setScale()
> function; I don't think it's mentioned in the gUnaryUnion help. This
> saves me a lot of headache!
>
> For what it's worth, the invalid geometry is an artifact of the
> reproducible example I created. The original hexagonal grid is
> produced with
> g <- spsample(study_area, type="hexagonal", cellsize=size)
> hex_grid <- HexPoints2SpatialPolygons(g)

OK, thanks - this is useful. Could you please make available the study 
area object in some way - so that we can re-create g and see how 
HexPoints2SpatialPolygons() creates the artefact Mike spotted (although 
this looks like numeric fuzz - 'changing "1287248.96712942" to 
"1287248.96712943"' is a change in the 15th digit, which is on the 
precision edge of the "double" storage mode. If we can revisit functions 
creating SpatialPolygons objects to ensure that they are GEOS-compatible 
for the default scale of 1e+8, we'll be more secure.

Roger

>
> And this object passes gIsValid() and clgeo_GeometryReport() without
> any problems, yet still has the dissolving issue. Regardless, all is
> solved with setScale().
>
> Thanks!
>
> M
>
> On Wed, Nov 4, 2015 at 6:30 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>
>>
>> On Thu, 5 Nov 2015 at 01:10 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>
>>> On Wed, 4 Nov 2015, Michael Sumner wrote:
>>>
>>>> Thanks for all this detail Roger, is there a way to "re-build" a spatial
>>>> object so that the given scale setting is applied? Are there any general
>>>> rounding or "orthogonalize" functions in the Spatial suite?
>>>
>>> No, not really. In this case, the very detailed coordinate measurements
>>> may have made things worse, or possibly using Polygon rather than Polygons
>>> objects, or not building the Polygons object with a proper comment
>>> attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>>>
>>> cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>>>
>>> says the same (based on rgeos). I suggest working with Emmanuel Blondel
>>> (cleangeo maintainer) to extend cleangeo. GEOS is looking at allowing
>>> users to manipulate precision models, not just scale, but I'm uncertain
>>> about that.
>>>
>>> Running spoly into GRASS and back out (GRASS builds topology on import)
>>> shows a different error, the object seems to be problematic.
>>>
>>
>> It can be fixed by changing "1287248.96712942" to "1287248.96712943", so
>> really the creator should not have had those values on input.  There's no
>> easy way out without topology.
>>
>> This brought out some interesting issues for work I've been doing using the
>> "near-Delaunay triangulation" in RTriangle, and that requires a normalized
>> set of vertices (no duplicate vertices) which on its own presents
>> interesting problems. I have a related issue where a parallel (latitude)
>> line needs many vertices to look "smooth" on a polar projection, but when
>> building a mesh with triangles it's really best to allow relatively coarse
>> segmented boundaries rather than have many elements at parallels. The
>> Triangle library does not consider these hexagon coordinates to be
>> duplicates, so there are two vertical segments between the two bottom polys
>> at
>>
>>  points(coordinates(as(as(spoly, "SpatialLines"), "SpatialPoints"))[c(3, 4),
>> ])
>>
>> Thanks for the reminder about cleangeo, I'll have closer look.
>>
>> cheers, Mike.
>>
>>>
>>> Roger
>>>
>>>>
>>>> Cheers, Mike.
>>>>
>>>> On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>
>>>>> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>>>>>
>>>>>> I'm working with a regular hexagonal grid stored as SPDF. At some
>>>>>> point I subset this SPDF, then want to combine all adjacent hexagons
>>>>>> together so that each contiguous set of hexagons is a single polygon.
>>>>>> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
>>>>>> clear what the different is actually). The problem is that in some
>>>>>> cases boundaries between clearly adjacent polygons are not dissolved.
>>>>>>
>>>>>> Example:
>>>>>>
>>>>>> ## Create three adjacent hexagons
>>>>>> library(sp)
>>>>>> library(rgeos)
>>>>>> p1 <- Polygon(cbind(
>>>>>>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>>>>>>        1287248.96712942, 1281876.11747031, 1276503.26781119,
>>>>> 1276503.26781119),
>>>>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>>>>> 198187.37595242,
>>>>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>>>>> p2 <- Polygon(cbind(
>>>>>>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>>>>>>        1297994.66644766, 1292621.81678854, 1287248.96712943,
>>>>> 1287248.96712943),
>>>>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>>>>> 198187.37595242,
>>>>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>>>>> p3 <- Polygon(cbind(
>>>>>>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>>>>>>        1292621.81678854, 1287248.96712943, 1281876.11747031,
>>>>> 1281876.11747031),
>>>>>>      c(213697.45693745, 216799.47313446, 213697.45693745,
>>>>> 207493.42454344,
>>>>>>        204391.40834643, 207493.42454344, 213697.45693745)))
>>>>>> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
>>>>>> plot(gUnaryUnion(spoly))
>>>>>
>>>>> No, this is just numerical fuzz:
>>>>>
>>>>> plot(spoly)
>>>>> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
>>>>> oS <- getScale()
>>>>> # default 1e+8
>>>>> setScale(1e+4)
>>>>> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>>>>> setScale(oS)
>>>>>
>>>>> JTS, GEOS, and consequently rgeos by default shift all coordinates to
>>>>> an
>>>>> integer grid after multiplying by a scale factor (finding integer
>>>>> matches
>>>>> is much easier than real matches). If the scaling is too detailed (in
>>>>> some
>>>>> cases), the operations do not give the expected outcomes.
>>>>>
>>>>> There is work in progress in GEOS and JTS to provide other scaling
>>>>> options
>>>>> and models, and to permit iteration over scaling values until a "clean"
>>>>> result is obtained (for some meanings of clean).
>>>>>
>>>>> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
>>>>> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more
>>>>> efficient
>>>>> route. This is explained on the help page.
>>>>>
>>>>> Hope this clarifies,
>>>>>
>>>>> Roger
>>>>>
>>>>>>
>>>>>> Note that p2 and p3 are dissolved together, but p1 is separate. The
>>>>>> shared edge of p1 and p2 is:
>>>>>> p1:
>>>>>> [2,] 1281876 207493.4
>>>>>> [3,] 1287249 204391.4
>>>>>> p2:
>>>>>> [5,] 1287249 204391.4
>>>>>> [6,] 1281876 207493.4
>>>>>>
>>>>>> So, exactly the same apart from the order. I originally thought this
>>>>>> difference in order might be the problem, but this doesn't seem to be
>>>>>> an issue with in this example, where order is also flipped:
>>>>>> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
>>>>>> ymx=2, vals=1:4))
>>>>>> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
>>>>>> plot(sss)
>>>>>> plot(gUnaryUnion(sss))
>>>>>>
>>>>>> Session Info:
>>>>>> R version 3.2.2 (2015-08-14)
>>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>>> Running under: OS X 10.10.5 (Yosemite)
>>>>>>
>>>>>> Message when rgeos is loaded:
>>>>>>
>>>>>> rgeos version: 0.3-14, (SVN revision 511)
>>>>>> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>>>>>> Linking to sp version: 1.2-0
>>>>>> Polygon checking: TRUE
>>>>>>
>>>>>> Any help on how to get these polygons to dissolve is appreciated.
>>>>>>
>>>>>> M
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>
>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From karljarvis at gmail.com  Wed Nov  4 18:17:02 2015
From: karljarvis at gmail.com (Karl Jarvis)
Date: Wed, 4 Nov 2015 10:17:02 -0700
Subject: [R-sig-Geo] multiple random effects and correlation structure in
	nlme
Message-ID: <F7054A52-E4BD-447C-BE6D-14C87B8ACA1B@gmail.com>

Hi all,
I am trying to build a model that includes two random effects while also using a correlation structure to account for spatial autocorrelation. It?s a full factorial study on simulations of wildlife where individuals are spread across landscapes, so one of the random effects (N) is crossed. 

If I use nlme I can do this by reusing creating a new group factor by pasting the three crossed factors together (would be land:barr:mort in lme4), which I call ?lr'. The parameter estimates are similar, so it seems ok. (Link to the data frame: https://drive.google.com/open?id=0B096pYMrPnKAdC1FdWhCR3Z4bjg )
	ibr4 <- read.csv(?~/ibr4.csv?)
	m1 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr), data=ibr4, method = ?ML?)

Once I try to do that along with a correlation structure, it complains that there are incompatible formulas for ?random? and ?correlation?. 
	m2 <- lme(A ~ barr + mort, random = list(~cost | land, ~N | lr), data=ibr4, method = ?ML?,
	correlation = corExp(form = ~ x+y | lr))

I think it?s because it doesn?t know how to relate lr to land, because it complains the same way when the only random effect is '~cost | land?. However, when one random effect is in the model with a correlation structure nested as ~x+y | land/barr/mort, it does work. But it doesn?t seem to ever accept multiple random effects together with a correlation structure. I know Pinheiro and Bates say in their book (p.163) that you can build a crossed random-effects structure with pdBlocked and pdIdent, but (1) it?s not clear to me how to do this for a single random effect, and (2) it?s not clear to me that you could include multiple random effects in such a structure. Am I misunderstanding how correlation structures and/or random effects work? Let me know if you need more information about my data. 

Thanks,
Karl


From strimas at zoology.ubc.ca  Wed Nov  4 19:10:37 2015
From: strimas at zoology.ubc.ca (Matt Strimas-Mackey)
Date: Wed, 4 Nov 2015 10:10:37 -0800
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
	<alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
Message-ID: <CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>

The original study area shapefile is a boundary of the Indonesia half
of New Guinea. The file as well as the code to construct the hexagonal
grids are here:
https://www.dropbox.com/sh/ff8v08p3ambqcbs/AAAPBlGP4fthdmZhrto7oIuCa?dl=0

Since it's a large area, generating the grid takes a long time, so
I've also included code for a small subset of the original
shapefile--one small offshore island.

Finally, some more odd behaviour. I noticed each time I run this code,
the dissolve mistakes change, i.e. different boundaries are
erroneously kept. However, using set.seed() makes the errors the same
each time for a given seed, and changing the seed yields a different
set of errors. Example in the code in the dropbox link and copied
here:

library(sp)
library(raster)
library(rgeos)

# just a subset of full shapefile
set.seed(1)
size <- sqrt(2 * 1e8 / sqrt(3))
study_area <- shapefile('papua.shp')
hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
hex_grid <- HexPoints2SpatialPolygons(hex_points)
hex_union <- gUnaryUnion(hex_grid)
plot(hex_grid, col='lightgrey')
plot(hex_union, border='orange', lwd=3, add=T)

# results chage according to seed
set.seed(100)
size <- sqrt(2 * 1e8 / sqrt(3))
study_area <- shapefile('papua.shp')
hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
hex_grid <- HexPoints2SpatialPolygons(hex_points)
hex_union <- gUnaryUnion(hex_grid)
plot(hex_grid, col='lightgrey')
plot(hex_union, border='orange', lwd=3, add=T)

On Wed, Nov 4, 2015 at 8:57 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:
>
>> Thanks, lots of useful info here. I've never seen the setScale()
>> function; I don't think it's mentioned in the gUnaryUnion help. This
>> saves me a lot of headache!
>>
>> For what it's worth, the invalid geometry is an artifact of the
>> reproducible example I created. The original hexagonal grid is
>> produced with
>> g <- spsample(study_area, type="hexagonal", cellsize=size)
>> hex_grid <- HexPoints2SpatialPolygons(g)
>
>
> OK, thanks - this is useful. Could you please make available the study area
> object in some way - so that we can re-create g and see how
> HexPoints2SpatialPolygons() creates the artefact Mike spotted (although this
> looks like numeric fuzz - 'changing "1287248.96712942" to
> "1287248.96712943"' is a change in the 15th digit, which is on the precision
> edge of the "double" storage mode. If we can revisit functions creating
> SpatialPolygons objects to ensure that they are GEOS-compatible for the
> default scale of 1e+8, we'll be more secure.
>
> Roger
>
>
>>
>> And this object passes gIsValid() and clgeo_GeometryReport() without
>> any problems, yet still has the dissolving issue. Regardless, all is
>> solved with setScale().
>>
>> Thanks!
>>
>> M
>>
>> On Wed, Nov 4, 2015 at 6:30 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>>
>>>
>>>
>>> On Thu, 5 Nov 2015 at 01:10 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>
>>>>
>>>> On Wed, 4 Nov 2015, Michael Sumner wrote:
>>>>
>>>>> Thanks for all this detail Roger, is there a way to "re-build" a
>>>>> spatial
>>>>> object so that the given scale setting is applied? Are there any
>>>>> general
>>>>> rounding or "orthogonalize" functions in the Spatial suite?
>>>>
>>>>
>>>> No, not really. In this case, the very detailed coordinate measurements
>>>> may have made things worse, or possibly using Polygon rather than
>>>> Polygons
>>>> objects, or not building the Polygons object with a proper comment
>>>> attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>>>>
>>>>
>>>> cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>>>>
>>>> says the same (based on rgeos). I suggest working with Emmanuel Blondel
>>>> (cleangeo maintainer) to extend cleangeo. GEOS is looking at allowing
>>>> users to manipulate precision models, not just scale, but I'm uncertain
>>>> about that.
>>>>
>>>> Running spoly into GRASS and back out (GRASS builds topology on import)
>>>> shows a different error, the object seems to be problematic.
>>>>
>>>
>>> It can be fixed by changing "1287248.96712942" to "1287248.96712943", so
>>> really the creator should not have had those values on input.  There's no
>>> easy way out without topology.
>>>
>>> This brought out some interesting issues for work I've been doing using
>>> the
>>> "near-Delaunay triangulation" in RTriangle, and that requires a
>>> normalized
>>> set of vertices (no duplicate vertices) which on its own presents
>>> interesting problems. I have a related issue where a parallel (latitude)
>>> line needs many vertices to look "smooth" on a polar projection, but when
>>> building a mesh with triangles it's really best to allow relatively
>>> coarse
>>> segmented boundaries rather than have many elements at parallels. The
>>> Triangle library does not consider these hexagon coordinates to be
>>> duplicates, so there are two vertical segments between the two bottom
>>> polys
>>> at
>>>
>>>  points(coordinates(as(as(spoly, "SpatialLines"), "SpatialPoints"))[c(3,
>>> 4),
>>> ])
>>>
>>> Thanks for the reminder about cleangeo, I'll have closer look.
>>>
>>> cheers, Mike.
>>>
>>>>
>>>> Roger
>>>>
>>>>>
>>>>> Cheers, Mike.
>>>>>
>>>>> On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>>
>>>>>> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>>>>>>
>>>>>>> I'm working with a regular hexagonal grid stored as SPDF. At some
>>>>>>> point I subset this SPDF, then want to combine all adjacent hexagons
>>>>>>> together so that each contiguous set of hexagons is a single polygon.
>>>>>>> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
>>>>>>> clear what the different is actually). The problem is that in some
>>>>>>> cases boundaries between clearly adjacent polygons are not dissolved.
>>>>>>>
>>>>>>> Example:
>>>>>>>
>>>>>>> ## Create three adjacent hexagons
>>>>>>> library(sp)
>>>>>>> library(rgeos)
>>>>>>> p1 <- Polygon(cbind(
>>>>>>>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>>>>>>>        1287248.96712942, 1281876.11747031, 1276503.26781119,
>>>>>>
>>>>>> 1276503.26781119),
>>>>>>>
>>>>>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>>>>>>
>>>>>> 198187.37595242,
>>>>>>>
>>>>>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>>>>>> p2 <- Polygon(cbind(
>>>>>>>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>>>>>>>        1297994.66644766, 1292621.81678854, 1287248.96712943,
>>>>>>
>>>>>> 1287248.96712943),
>>>>>>>
>>>>>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>>>>>>
>>>>>> 198187.37595242,
>>>>>>>
>>>>>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>>>>>> p3 <- Polygon(cbind(
>>>>>>>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>>>>>>>        1292621.81678854, 1287248.96712943, 1281876.11747031,
>>>>>>
>>>>>> 1281876.11747031),
>>>>>>>
>>>>>>>      c(213697.45693745, 216799.47313446, 213697.45693745,
>>>>>>
>>>>>> 207493.42454344,
>>>>>>>
>>>>>>>        204391.40834643, 207493.42454344, 213697.45693745)))
>>>>>>> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
>>>>>>> plot(gUnaryUnion(spoly))
>>>>>>
>>>>>>
>>>>>> No, this is just numerical fuzz:
>>>>>>
>>>>>> plot(spoly)
>>>>>> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
>>>>>> oS <- getScale()
>>>>>> # default 1e+8
>>>>>> setScale(1e+4)
>>>>>> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>>>>>> setScale(oS)
>>>>>>
>>>>>> JTS, GEOS, and consequently rgeos by default shift all coordinates to
>>>>>> an
>>>>>> integer grid after multiplying by a scale factor (finding integer
>>>>>> matches
>>>>>> is much easier than real matches). If the scaling is too detailed (in
>>>>>> some
>>>>>> cases), the operations do not give the expected outcomes.
>>>>>>
>>>>>> There is work in progress in GEOS and JTS to provide other scaling
>>>>>> options
>>>>>> and models, and to permit iteration over scaling values until a
>>>>>> "clean"
>>>>>> result is obtained (for some meanings of clean).
>>>>>>
>>>>>> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
>>>>>> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more
>>>>>> efficient
>>>>>> route. This is explained on the help page.
>>>>>>
>>>>>> Hope this clarifies,
>>>>>>
>>>>>> Roger
>>>>>>
>>>>>>>
>>>>>>> Note that p2 and p3 are dissolved together, but p1 is separate. The
>>>>>>> shared edge of p1 and p2 is:
>>>>>>> p1:
>>>>>>> [2,] 1281876 207493.4
>>>>>>> [3,] 1287249 204391.4
>>>>>>> p2:
>>>>>>> [5,] 1287249 204391.4
>>>>>>> [6,] 1281876 207493.4
>>>>>>>
>>>>>>> So, exactly the same apart from the order. I originally thought this
>>>>>>> difference in order might be the problem, but this doesn't seem to be
>>>>>>> an issue with in this example, where order is also flipped:
>>>>>>> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
>>>>>>> ymx=2, vals=1:4))
>>>>>>> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
>>>>>>> plot(sss)
>>>>>>> plot(gUnaryUnion(sss))
>>>>>>>
>>>>>>> Session Info:
>>>>>>> R version 3.2.2 (2015-08-14)
>>>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>>>> Running under: OS X 10.10.5 (Yosemite)
>>>>>>>
>>>>>>> Message when rgeos is loaded:
>>>>>>>
>>>>>>> rgeos version: 0.3-14, (SVN revision 511)
>>>>>>> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>>>>>>> Linking to sp version: 1.2-0
>>>>>>> Polygon checking: TRUE
>>>>>>>
>>>>>>> Any help on how to get these polygons to dissolve is appreciated.
>>>>>>>
>>>>>>> M
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> Roger Bivand
>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>
>>>>
>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>


From eduardodiez at gmx.com  Wed Nov  4 19:34:18 2015
From: eduardodiez at gmx.com (Eduardo Diez)
Date: Wed, 4 Nov 2015 15:34:18 -0300
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
Message-ID: <CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>

Is there any way of doing this or should i forget it and go on using GRASS
through rgrass7?

Thanks

2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:

> Ok. So here's a link to a zip file that contains two shapefiles:
>  - pol_to_be_cleaned: the layer from which i'd like to remove small
> polygons
>  - pol_cleaned: the layer cleaned with the function v.clean rmarea
>
> http://1drv.ms/1GmRWS7
>
> The threshold i used for cleaning was 3000 (meaning 3000 squared meters).
>
> Although i do project it before sending it to GRASS, according to the
> official help page it should be able to handle it:
> "Threshold must always be in square meters, also for latitude-longitude
> locations or locations with units other than meters"
>
> Thanks
>
> 2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>
>> On Fri, 16 Oct 2015, Eduardo Diez wrote:
>>
>> Dear list,
>>> I'm willing to know if any knows a way of performing tha same thing i'm
>>> doing through rgrass7 with GRASS when I execute the function v.clean with
>>> "rmarea" as the tool argument. That is:
>>>
>>> "The rmarea tool removes all areas <= thresh. The longest boundary with
>>> an
>>> adjacent area is removed or all boundaries if there is no adjacent area.
>>> Area categories are not combined when a small area is merged with a
>>> larger
>>> area."
>>>
>>> Basically i have raster of zones within a field. I convert it to
>>> SpatialPolygonsDataFrame and in order to leave only the more
>>> important/meaningful ones i remove the small/sliver with this tool. In
>>> general it works fine but having to call an external software with a
>>> specific version makes the script less portable and you have to be
>>> careful
>>> with updates and such. Also you have to write rasters and shapefiles back
>>> and forth as GRASS can't work with in-memory objects.
>>>
>>
>> Could you please provide an example of a built-in or contributed data set
>> (URL, not attachment) with the slivers you mention, so that we know that we
>> are addressing your problem? I don't think that:
>>
>> https://cran.r-project.org/web/packages/cleangeo/index.html
>>
>> does this, as it seems to try to repair broken geometries.
>>
>> Also note that you need to specify that the area threshold is in a square
>> planar metric - dropping slivers in unprojected geometries may be more
>> complicated.
>>
>> Roger
>>
>>
>>> Does someone know a way of doing this in plain R?
>>>
>>> Thanks
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Wed Nov  4 19:54:29 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 4 Nov 2015 19:54:29 +0100
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>

On Wed, 4 Nov 2015, Eduardo Diez wrote:

> Is there any way of doing this or should i forget it and go on using GRASS
> through rgrass7?

I suggest working with Emmanuel Blondel (cleangeo maintainer) to extend 
cleangeo (also suggested in an earlier thread today, with apologies to 
Emmanuel for picking on him!). That package already uses rgeos, and is a 
logical place to put GRASS v.clean-like functionality (maybe even 
encapsulating using GRASs via rgrass7 and a throwaway location).

At the moment it is messy, though some rgeos internals do do something 
like this, but it isn't exposed to users.

Roger

>
> Thanks
>
> 2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>
>> Ok. So here's a link to a zip file that contains two shapefiles:
>>  - pol_to_be_cleaned: the layer from which i'd like to remove small
>> polygons
>>  - pol_cleaned: the layer cleaned with the function v.clean rmarea
>>
>> http://1drv.ms/1GmRWS7
>>
>> The threshold i used for cleaning was 3000 (meaning 3000 squared meters).
>>
>> Although i do project it before sending it to GRASS, according to the
>> official help page it should be able to handle it:
>> "Threshold must always be in square meters, also for latitude-longitude
>> locations or locations with units other than meters"
>>
>> Thanks
>>
>> 2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>
>>> On Fri, 16 Oct 2015, Eduardo Diez wrote:
>>>
>>> Dear list,
>>>> I'm willing to know if any knows a way of performing tha same thing i'm
>>>> doing through rgrass7 with GRASS when I execute the function v.clean with
>>>> "rmarea" as the tool argument. That is:
>>>>
>>>> "The rmarea tool removes all areas <= thresh. The longest boundary with
>>>> an
>>>> adjacent area is removed or all boundaries if there is no adjacent area.
>>>> Area categories are not combined when a small area is merged with a
>>>> larger
>>>> area."
>>>>
>>>> Basically i have raster of zones within a field. I convert it to
>>>> SpatialPolygonsDataFrame and in order to leave only the more
>>>> important/meaningful ones i remove the small/sliver with this tool. In
>>>> general it works fine but having to call an external software with a
>>>> specific version makes the script less portable and you have to be
>>>> careful
>>>> with updates and such. Also you have to write rasters and shapefiles back
>>>> and forth as GRASS can't work with in-memory objects.
>>>>
>>>
>>> Could you please provide an example of a built-in or contributed data set
>>> (URL, not attachment) with the slivers you mention, so that we know that we
>>> are addressing your problem? I don't think that:
>>>
>>> https://cran.r-project.org/web/packages/cleangeo/index.html
>>>
>>> does this, as it seems to try to repair broken geometries.
>>>
>>> Also note that you need to specify that the area threshold is in a square
>>> planar metric - dropping slivers in unprojected geometries may be more
>>> complicated.
>>>
>>> Roger
>>>
>>>
>>>> Does someone know a way of doing this in plain R?
>>>>
>>>> Thanks
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From thi_veloso at yahoo.com.br  Wed Nov  4 23:37:40 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 4 Nov 2015 22:37:40 +0000 (UTC)
Subject: [R-sig-Geo] How to perform cross-year date operations on rasters?
References: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>

Dear all,

Consider that I have a raster stack with daily values. How can I perform date operations covering a time interval that crosses years?

For example, I want to sum the values from every october-to-january period in this sample raster:

library(raster)

# Create a rasterStack similar to cmip5 - same dimensions and layer names
r <- raster(ncol=180, nrow=90)
s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))

# Apply time stamps to raster
#x <- as.Date(c("2010-01-01","2014-12-31"),format="%Y-%m-%d") 
#difftime(x[2], x[1], units="days") 
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
s <- setZ(s, idx)
s


 Thanks in advance,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota


From jianyun.fred.wu at gmail.com  Thu Nov  5 07:01:38 2015
From: jianyun.fred.wu at gmail.com (Jianyun Wu)
Date: Thu, 5 Nov 2015 17:01:38 +1100
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
Message-ID: <CAOMGRD+1rBrQpXV35pw2qa7Vit+F9s3JJM5XGT00J5Rv71FSaw@mail.gmail.com>

I tried to do that with a lattice map, and figured out a way to remove
those small polygons within a large area. But don't know whether it suits
your needs for raster.

I read the digital map with rgdal package.

Using Australia local government area as an example.

#remove the small polygons within the large LGA area

aus_lga = readOGR(dsn = ".", "LGA11aAust") #LGA
nsw_lga = aus_lga[aus_lga$STATE_CODE == 1, ]
N = length(nsw_lga)
for (i in 1:N) {
  pol = nsw_lga at polygons[[i]]@Polygons
  index = 1:length(pol)
  area = sapply(pol, function(x) x at area)
  n_remove = index[area!=max(area)]
  nsw_lga at polygons[[i]]@Polygons[n_remove] <- NULL
}

It basically extracts the area of the polygons within the S4 objects, and
set the spatial object of small polygons within a large area to NULL.

Regards

Fred

On Thu, Nov 5, 2015 at 5:34 AM, Eduardo Diez <eduardodiez at gmx.com> wrote:

> Is there any way of doing this or should i forget it and go on using GRASS
> through rgrass7?
>
> Thanks
>
> 2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>
> > Ok. So here's a link to a zip file that contains two shapefiles:
> >  - pol_to_be_cleaned: the layer from which i'd like to remove small
> > polygons
> >  - pol_cleaned: the layer cleaned with the function v.clean rmarea
> >
> > http://1drv.ms/1GmRWS7
> >
> > The threshold i used for cleaning was 3000 (meaning 3000 squared meters).
> >
> > Although i do project it before sending it to GRASS, according to the
> > official help page it should be able to handle it:
> > "Threshold must always be in square meters, also for latitude-longitude
> > locations or locations with units other than meters"
> >
> > Thanks
> >
> > 2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
> >
> >> On Fri, 16 Oct 2015, Eduardo Diez wrote:
> >>
> >> Dear list,
> >>> I'm willing to know if any knows a way of performing tha same thing i'm
> >>> doing through rgrass7 with GRASS when I execute the function v.clean
> with
> >>> "rmarea" as the tool argument. That is:
> >>>
> >>> "The rmarea tool removes all areas <= thresh. The longest boundary with
> >>> an
> >>> adjacent area is removed or all boundaries if there is no adjacent
> area.
> >>> Area categories are not combined when a small area is merged with a
> >>> larger
> >>> area."
> >>>
> >>> Basically i have raster of zones within a field. I convert it to
> >>> SpatialPolygonsDataFrame and in order to leave only the more
> >>> important/meaningful ones i remove the small/sliver with this tool. In
> >>> general it works fine but having to call an external software with a
> >>> specific version makes the script less portable and you have to be
> >>> careful
> >>> with updates and such. Also you have to write rasters and shapefiles
> back
> >>> and forth as GRASS can't work with in-memory objects.
> >>>
> >>
> >> Could you please provide an example of a built-in or contributed data
> set
> >> (URL, not attachment) with the slivers you mention, so that we know
> that we
> >> are addressing your problem? I don't think that:
> >>
> >> https://cran.r-project.org/web/packages/cleangeo/index.html
> >>
> >> does this, as it seems to try to repair broken geometries.
> >>
> >> Also note that you need to specify that the area threshold is in a
> square
> >> planar metric - dropping slivers in unprojected geometries may be more
> >> complicated.
> >>
> >> Roger
> >>
> >>
> >>> Does someone know a way of doing this in plain R?
> >>>
> >>> Thanks
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>>
> >> --
> >> Roger Bivand
> >> Department of Economics, Norwegian School of Economics,
> >> Helleveien 30, N-5045 Bergen, Norway.
> >> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >> e-mail: Roger.Bivand at nhh.no
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Nov  5 07:14:19 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 05 Nov 2015 06:14:19 +0000
Subject: [R-sig-Geo] How to perform cross-year date operations on
	rasters?
In-Reply-To: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
References: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
	<1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAAcGz99AAjLiQ-KK+5zUgsezQXX0BNwOQdXgrOicYW2kpY-NBA@mail.gmail.com>

On Thu, 5 Nov 2015 at 09:38 Thiago V. dos Santos <thi_veloso at yahoo.com.br>
wrote:

> Dear all,
>
> Consider that I have a raster stack with daily values. How can I perform
> date operations covering a time interval that crosses years?
>
> For example, I want to sum the values from every october-to-january period
> in this sample raster:
>
> library(raster)
>
> # Create a rasterStack similar to cmip5 - same dimensions and layer names
> r <- raster(ncol=180, nrow=90)
> s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
>
> # Apply time stamps to raster
> #x <- as.Date(c("2010-01-01","2014-12-31"),format="%Y-%m-%d")
> #difftime(x[2], x[1], units="days")
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
> s <- setZ(s, idx)
> s
>
>
>

You can subset on the dates, by running a test on the date values:

ldates <- format(getZ(s), "%m") %in% c("10", "11", "01")

subsetting the object

subset(s, which(ldates))

and finally calculating what you want

calc(subset(s, which(ldates)), sum)

HTH




>  Thanks in advance,
>  -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Nov  5 07:45:20 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2015 07:45:20 +0100
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
	<alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
	<CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511050737400.25686@reclus.nhh.no>

On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:

> The original study area shapefile is a boundary of the Indonesia half
> of New Guinea. The file as well as the code to construct the hexagonal
> grids are here:
> https://www.dropbox.com/sh/ff8v08p3ambqcbs/AAAPBlGP4fthdmZhrto7oIuCa?dl=0
>
> Since it's a large area, generating the grid takes a long time, so
> I've also included code for a small subset of the original
> shapefile--one small offshore island.

An equivalent scaling fix is to change the coordinate units from metres to 
kilometres:

library(rgdal)
study_area2 <- spTransform(study_area, CRS("+proj=aea +lat_1=-7.42
  +lat_2=-0.62 +lat_0=-9.119 +lon_0=128.91 +x_0=0 y_0=0 +datum=WGS84
  +units=km +no_defs +ellps=WGS84 +towgs84=0,0,0"))
size <- sqrt(2 * 1e2 / sqrt(3)) # reduce to suit
set.seed(1)
hex_points <- spsample(study_area2[2,], type="hexagonal", cellsize=size)
hex_grid <- HexPoints2SpatialPolygons(hex_points)
hex_union <- gUnaryUnion(hex_grid)
plot(hex_grid, col='lightgrey')
plot(hex_union, border='orange', lwd=3, add=T)

An advantage of these scaling issues being made visible is that we see 
that computers really do not operate in continuous space, and that 
computational geometry actually matters, I suppose.

I'll check the underlying code generating the hexagons to see why the 
nodes (where hexagon boundaries meet) appear to slide apart at the edge of 
machine precision.

Roger


>
> Finally, some more odd behaviour. I noticed each time I run this code,
> the dissolve mistakes change, i.e. different boundaries are
> erroneously kept. However, using set.seed() makes the errors the same
> each time for a given seed, and changing the seed yields a different
> set of errors. Example in the code in the dropbox link and copied
> here:
>
> library(sp)
> library(raster)
> library(rgeos)
>
> # just a subset of full shapefile
> set.seed(1)
> size <- sqrt(2 * 1e8 / sqrt(3))
> study_area <- shapefile('papua.shp')
> hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
> hex_grid <- HexPoints2SpatialPolygons(hex_points)
> hex_union <- gUnaryUnion(hex_grid)
> plot(hex_grid, col='lightgrey')
> plot(hex_union, border='orange', lwd=3, add=T)
>
> # results chage according to seed
> set.seed(100)
> size <- sqrt(2 * 1e8 / sqrt(3))
> study_area <- shapefile('papua.shp')
> hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
> hex_grid <- HexPoints2SpatialPolygons(hex_points)
> hex_union <- gUnaryUnion(hex_grid)
> plot(hex_grid, col='lightgrey')
> plot(hex_union, border='orange', lwd=3, add=T)
>
> On Wed, Nov 4, 2015 at 8:57 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:
>>
>>> Thanks, lots of useful info here. I've never seen the setScale()
>>> function; I don't think it's mentioned in the gUnaryUnion help. This
>>> saves me a lot of headache!
>>>
>>> For what it's worth, the invalid geometry is an artifact of the
>>> reproducible example I created. The original hexagonal grid is
>>> produced with
>>> g <- spsample(study_area, type="hexagonal", cellsize=size)
>>> hex_grid <- HexPoints2SpatialPolygons(g)
>>
>>
>> OK, thanks - this is useful. Could you please make available the study area
>> object in some way - so that we can re-create g and see how
>> HexPoints2SpatialPolygons() creates the artefact Mike spotted (although this
>> looks like numeric fuzz - 'changing "1287248.96712942" to
>> "1287248.96712943"' is a change in the 15th digit, which is on the precision
>> edge of the "double" storage mode. If we can revisit functions creating
>> SpatialPolygons objects to ensure that they are GEOS-compatible for the
>> default scale of 1e+8, we'll be more secure.
>>
>> Roger
>>
>>
>>>
>>> And this object passes gIsValid() and clgeo_GeometryReport() without
>>> any problems, yet still has the dissolving issue. Regardless, all is
>>> solved with setScale().
>>>
>>> Thanks!
>>>
>>> M
>>>
>>> On Wed, Nov 4, 2015 at 6:30 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>>>
>>>>
>>>>
>>>> On Thu, 5 Nov 2015 at 01:10 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>>
>>>>>
>>>>> On Wed, 4 Nov 2015, Michael Sumner wrote:
>>>>>
>>>>>> Thanks for all this detail Roger, is there a way to "re-build" a
>>>>>> spatial
>>>>>> object so that the given scale setting is applied? Are there any
>>>>>> general
>>>>>> rounding or "orthogonalize" functions in the Spatial suite?
>>>>>
>>>>>
>>>>> No, not really. In this case, the very detailed coordinate measurements
>>>>> may have made things worse, or possibly using Polygon rather than
>>>>> Polygons
>>>>> objects, or not building the Polygons object with a proper comment
>>>>> attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>>>>>
>>>>>
>>>>> cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>>>>>
>>>>> says the same (based on rgeos). I suggest working with Emmanuel Blondel
>>>>> (cleangeo maintainer) to extend cleangeo. GEOS is looking at allowing
>>>>> users to manipulate precision models, not just scale, but I'm uncertain
>>>>> about that.
>>>>>
>>>>> Running spoly into GRASS and back out (GRASS builds topology on import)
>>>>> shows a different error, the object seems to be problematic.
>>>>>
>>>>
>>>> It can be fixed by changing "1287248.96712942" to "1287248.96712943", so
>>>> really the creator should not have had those values on input.  There's no
>>>> easy way out without topology.
>>>>
>>>> This brought out some interesting issues for work I've been doing using
>>>> the
>>>> "near-Delaunay triangulation" in RTriangle, and that requires a
>>>> normalized
>>>> set of vertices (no duplicate vertices) which on its own presents
>>>> interesting problems. I have a related issue where a parallel (latitude)
>>>> line needs many vertices to look "smooth" on a polar projection, but when
>>>> building a mesh with triangles it's really best to allow relatively
>>>> coarse
>>>> segmented boundaries rather than have many elements at parallels. The
>>>> Triangle library does not consider these hexagon coordinates to be
>>>> duplicates, so there are two vertical segments between the two bottom
>>>> polys
>>>> at
>>>>
>>>>  points(coordinates(as(as(spoly, "SpatialLines"), "SpatialPoints"))[c(3,
>>>> 4),
>>>> ])
>>>>
>>>> Thanks for the reminder about cleangeo, I'll have closer look.
>>>>
>>>> cheers, Mike.
>>>>
>>>>>
>>>>> Roger
>>>>>
>>>>>>
>>>>>> Cheers, Mike.
>>>>>>
>>>>>> On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> wrote:
>>>>>>
>>>>>>> On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>>>>>>>
>>>>>>>> I'm working with a regular hexagonal grid stored as SPDF. At some
>>>>>>>> point I subset this SPDF, then want to combine all adjacent hexagons
>>>>>>>> together so that each contiguous set of hexagons is a single polygon.
>>>>>>>> I'm doing this last step using gUnaryUnion (or gUnionCascaded, not
>>>>>>>> clear what the different is actually). The problem is that in some
>>>>>>>> cases boundaries between clearly adjacent polygons are not dissolved.
>>>>>>>>
>>>>>>>> Example:
>>>>>>>>
>>>>>>>> ## Create three adjacent hexagons
>>>>>>>> library(sp)
>>>>>>>> library(rgeos)
>>>>>>>> p1 <- Polygon(cbind(
>>>>>>>>      c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>>>>>>>>        1287248.96712942, 1281876.11747031, 1276503.26781119,
>>>>>>>
>>>>>>> 1276503.26781119),
>>>>>>>>
>>>>>>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>>>>>>>
>>>>>>> 198187.37595242,
>>>>>>>>
>>>>>>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>>>>>>> p2 <- Polygon(cbind(
>>>>>>>>      c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>>>>>>>>        1297994.66644766, 1292621.81678854, 1287248.96712943,
>>>>>>>
>>>>>>> 1287248.96712943),
>>>>>>>>
>>>>>>>>      c(204391.40834643, 207493.42454344, 204391.40834643,
>>>>>>>
>>>>>>> 198187.37595242,
>>>>>>>>
>>>>>>>>        195085.35975541, 198187.37595242, 204391.40834643)))
>>>>>>>> p3 <- Polygon(cbind(
>>>>>>>>      c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>>>>>>>>        1292621.81678854, 1287248.96712943, 1281876.11747031,
>>>>>>>
>>>>>>> 1281876.11747031),
>>>>>>>>
>>>>>>>>      c(213697.45693745, 216799.47313446, 213697.45693745,
>>>>>>>
>>>>>>> 207493.42454344,
>>>>>>>>
>>>>>>>>        204391.40834643, 207493.42454344, 213697.45693745)))
>>>>>>>> spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 's1')))
>>>>>>>> plot(gUnaryUnion(spoly))
>>>>>>>
>>>>>>>
>>>>>>> No, this is just numerical fuzz:
>>>>>>>
>>>>>>> plot(spoly)
>>>>>>> plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, add=TRUE)
>>>>>>> oS <- getScale()
>>>>>>> # default 1e+8
>>>>>>> setScale(1e+4)
>>>>>>> plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>>>>>>> setScale(oS)
>>>>>>>
>>>>>>> JTS, GEOS, and consequently rgeos by default shift all coordinates to
>>>>>>> an
>>>>>>> integer grid after multiplying by a scale factor (finding integer
>>>>>>> matches
>>>>>>> is much easier than real matches). If the scaling is too detailed (in
>>>>>>> some
>>>>>>> cases), the operations do not give the expected outcomes.
>>>>>>>
>>>>>>> There is work in progress in GEOS and JTS to provide other scaling
>>>>>>> options
>>>>>>> and models, and to permit iteration over scaling values until a
>>>>>>> "clean"
>>>>>>> result is obtained (for some meanings of clean).
>>>>>>>
>>>>>>> gUnionCascaded() was the only possible function for GEOS < 3.3.0, from
>>>>>>> GEOS 3.3.0 gUnaryUnion() is available and the prefered and more
>>>>>>> efficient
>>>>>>> route. This is explained on the help page.
>>>>>>>
>>>>>>> Hope this clarifies,
>>>>>>>
>>>>>>> Roger
>>>>>>>
>>>>>>>>
>>>>>>>> Note that p2 and p3 are dissolved together, but p1 is separate. The
>>>>>>>> shared edge of p1 and p2 is:
>>>>>>>> p1:
>>>>>>>> [2,] 1281876 207493.4
>>>>>>>> [3,] 1287249 204391.4
>>>>>>>> p2:
>>>>>>>> [5,] 1287249 204391.4
>>>>>>>> [6,] 1281876 207493.4
>>>>>>>>
>>>>>>>> So, exactly the same apart from the order. I originally thought this
>>>>>>>> difference in order might be the problem, but this doesn't seem to be
>>>>>>>> an issue with in this example, where order is also flipped:
>>>>>>>> sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, ymn=0,
>>>>>>>> ymx=2, vals=1:4))
>>>>>>>> lapply(sss at polygons, function(x) slot(x, 'Polygons')[[1]]@coords)
>>>>>>>> plot(sss)
>>>>>>>> plot(gUnaryUnion(sss))
>>>>>>>>
>>>>>>>> Session Info:
>>>>>>>> R version 3.2.2 (2015-08-14)
>>>>>>>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>>>>>>> Running under: OS X 10.10.5 (Yosemite)
>>>>>>>>
>>>>>>>> Message when rgeos is loaded:
>>>>>>>>
>>>>>>>> rgeos version: 0.3-14, (SVN revision 511)
>>>>>>>> GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>>>>>>>> Linking to sp version: 1.2-0
>>>>>>>> Polygon checking: TRUE
>>>>>>>>
>>>>>>>> Any help on how to get these polygons to dissolve is appreciated.
>>>>>>>>
>>>>>>>> M
>>>>>>>>
>>>>>>>> _______________________________________________
>>>>>>>> R-sig-Geo mailing list
>>>>>>>> R-sig-Geo at r-project.org
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Roger Bivand
>>>>>>> Department of Economics, Norwegian School of Economics,
>>>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> Roger Bivand
>>>>> Department of Economics, Norwegian School of Economics,
>>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>> e-mail: Roger.Bivand at nhh.no
>>>>>
>>>>
>>>
>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Nov  5 11:49:24 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2015 11:49:24 +0100
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <alpine.LFD.2.20.1511050737400.25686@reclus.nhh.no>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
	<alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
	<CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>
	<alpine.LFD.2.20.1511050737400.25686@reclus.nhh.no>
Message-ID: <alpine.LFD.2.20.1511051138000.27962@reclus.nhh.no>

On Thu, 5 Nov 2015, Roger Bivand wrote:

> On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:
>
>>  The original study area shapefile is a boundary of the Indonesia half
>>  of New Guinea. The file as well as the code to construct the hexagonal
>>  grids are here:
>>  https://www.dropbox.com/sh/ff8v08p3ambqcbs/AAAPBlGP4fthdmZhrto7oIuCa?dl=0
>>
>>  Since it's a large area, generating the grid takes a long time, so
>>  I've also included code for a small subset of the original
>>  shapefile--one small offshore island.
>
> An equivalent scaling fix is to change the coordinate units from metres to 
> kilometres:
>
> library(rgdal)
> study_area2 <- spTransform(study_area, CRS("+proj=aea +lat_1=-7.42
>  +lat_2=-0.62 +lat_0=-9.119 +lon_0=128.91 +x_0=0 y_0=0 +datum=WGS84
>  +units=km +no_defs +ellps=WGS84 +towgs84=0,0,0"))
> size <- sqrt(2 * 1e2 / sqrt(3)) # reduce to suit
> set.seed(1)
> hex_points <- spsample(study_area2[2,], type="hexagonal", cellsize=size)
> hex_grid <- HexPoints2SpatialPolygons(hex_points)
> hex_union <- gUnaryUnion(hex_grid)
> plot(hex_grid, col='lightgrey')
> plot(hex_union, border='orange', lwd=3, add=T)
>
> An advantage of these scaling issues being made visible is that we see that 
> computers really do not operate in continuous space, and that computational 
> geometry actually matters, I suppose.
>
> I'll check the underlying code generating the hexagons to see why the nodes 
> (where hexagon boundaries meet) appear to slide apart at the edge of machine 
> precision.

A potentially robust approach at default scale uses the dx= argument to 
HexPoints2SpatialPolygons():

hex_grid <- HexPoints2SpatialPolygons(hex_points, dx=size)

Setting:

set_RGEOS_polyThreshold(1e-2) # for example
set_RGEOS_warnSlivers(TRUE)

shows the remaining slivers, and:

set_RGEOS_dropSlivers(TRUE)

drops them. It is still possible that an inward dangle will get through 
(zero area line in from boundary point, but part of the single boundary).

Setting dx= to the same value as cellsize= in the spsample call seems to 
be crucial, avoiding an approximation marked in the code as:

 	# EJP; changed:
 	# how to figure out dx from a grid? THK suggested:
         #dx <- hexGrid$x[2] - hexGrid$x[1]
 	# and the following will also not always work:

in sp:::genPolyList(), so there was a warning there against taking the 
default.

Roger

>
> Roger
>
>
>>
>>  Finally, some more odd behaviour. I noticed each time I run this code,
>>  the dissolve mistakes change, i.e. different boundaries are
>>  erroneously kept. However, using set.seed() makes the errors the same
>>  each time for a given seed, and changing the seed yields a different
>>  set of errors. Example in the code in the dropbox link and copied
>>  here:
>>
>>  library(sp)
>>  library(raster)
>>  library(rgeos)
>>
>>  # just a subset of full shapefile
>>  set.seed(1)
>>  size <- sqrt(2 * 1e8 / sqrt(3))
>>  study_area <- shapefile('papua.shp')
>>  hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
>>  hex_grid <- HexPoints2SpatialPolygons(hex_points)
>>  hex_union <- gUnaryUnion(hex_grid)
>>  plot(hex_grid, col='lightgrey')
>>  plot(hex_union, border='orange', lwd=3, add=T)
>>
>>  # results chage according to seed
>>  set.seed(100)
>>  size <- sqrt(2 * 1e8 / sqrt(3))
>>  study_area <- shapefile('papua.shp')
>>  hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
>>  hex_grid <- HexPoints2SpatialPolygons(hex_points)
>>  hex_union <- gUnaryUnion(hex_grid)
>>  plot(hex_grid, col='lightgrey')
>>  plot(hex_union, border='orange', lwd=3, add=T)
>>
>>  On Wed, Nov 4, 2015 at 8:57 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
>> >  On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:
>> > 
>> > >  Thanks, lots of useful info here. I've never seen the setScale()
>> > >  function; I don't think it's mentioned in the gUnaryUnion help. This
>> > >  saves me a lot of headache!
>> > > 
>> > >  For what it's worth, the invalid geometry is an artifact of the
>> > >  reproducible example I created. The original hexagonal grid is
>> > >  produced with
>> > >  g <- spsample(study_area, type="hexagonal", cellsize=size)
>> > >  hex_grid <- HexPoints2SpatialPolygons(g)
>> > 
>> > 
>> >  OK, thanks - this is useful. Could you please make available the study 
>> >  area
>> >  object in some way - so that we can re-create g and see how
>> >  HexPoints2SpatialPolygons() creates the artefact Mike spotted (although 
>> >  this
>> >  looks like numeric fuzz - 'changing "1287248.96712942" to
>> >  "1287248.96712943"' is a change in the 15th digit, which is on the 
>> >  precision
>> >  edge of the "double" storage mode. If we can revisit functions creating
>> >  SpatialPolygons objects to ensure that they are GEOS-compatible for the
>> >  default scale of 1e+8, we'll be more secure.
>> > 
>> >  Roger
>> > 
>> > 
>> > > 
>> > >  And this object passes gIsValid() and clgeo_GeometryReport() without
>> > >  any problems, yet still has the dissolving issue. Regardless, all is
>> > >  solved with setScale().
>> > > 
>> > >  Thanks!
>> > > 
>> > >  M
>> > > 
>> > >  On Wed, Nov 4, 2015 at 6:30 AM, Michael Sumner <mdsumner at gmail.com> 
>> > >  wrote:
>> > > > 
>> > > > 
>> > > > 
>> > > >  On Thu, 5 Nov 2015 at 01:10 Roger Bivand <Roger.Bivand at nhh.no> 
>> > > >  wrote:
>> > > > > 
>> > > > > 
>> > > > >  On Wed, 4 Nov 2015, Michael Sumner wrote:
>> > > > > 
>> > > > > >  Thanks for all this detail Roger, is there a way to "re-build" a
>> > > > > >  spatial
>> > > > > >  object so that the given scale setting is applied? Are there any
>> > > > > >  general
>> > > > > >  rounding or "orthogonalize" functions in the Spatial suite?
>> > > > > 
>> > > > > 
>> > > > >  No, not really. In this case, the very detailed coordinate 
>> > > > >  measurements
>> > > > >  may have made things worse, or possibly using Polygon rather than
>> > > > >  Polygons
>> > > > >  objects, or not building the Polygons object with a proper comment
>> > > > >  attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>> > > > > 
>> > > > > 
>> > > > >  cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>> > > > > 
>> > > > >  says the same (based on rgeos). I suggest working with Emmanuel 
>> > > > >  Blondel
>> > > > >  (cleangeo maintainer) to extend cleangeo. GEOS is looking at 
>> > > > >  allowing
>> > > > >  users to manipulate precision models, not just scale, but I'm 
>> > > > >  uncertain
>> > > > >  about that.
>> > > > > 
>> > > > >  Running spoly into GRASS and back out (GRASS builds topology on 
>> > > > >  import)
>> > > > >  shows a different error, the object seems to be problematic.
>> > > > > 
>> > > > 
>> > > >  It can be fixed by changing "1287248.96712942" to 
>> > > >  "1287248.96712943", so
>> > > >  really the creator should not have had those values on input. 
>> > > >  There's no
>> > > >  easy way out without topology.
>> > > > 
>> > > >  This brought out some interesting issues for work I've been doing 
>> > > >  using
>> > > >  the
>> > > >  "near-Delaunay triangulation" in RTriangle, and that requires a
>> > > >  normalized
>> > > >  set of vertices (no duplicate vertices) which on its own presents
>> > > >  interesting problems. I have a related issue where a parallel 
>> > > >  (latitude)
>> > > >  line needs many vertices to look "smooth" on a polar projection, but 
>> > > >  when
>> > > >  building a mesh with triangles it's really best to allow relatively
>> > > >  coarse
>> > > >  segmented boundaries rather than have many elements at parallels. 
>> > > >  The
>> > > >  Triangle library does not consider these hexagon coordinates to be
>> > > >  duplicates, so there are two vertical segments between the two 
>> > > >  bottom
>> > > >  polys
>> > > >  at
>> > > > 
>> > > >  points(coordinates(as(as(spoly, "SpatialLines"), 
>> > > >  "SpatialPoints"))[c(3,
>> > > >  4),
>> > > > ] ) 
>> > > > 
>> > > >  Thanks for the reminder about cleangeo, I'll have closer look.
>> > > > 
>> > > >  cheers, Mike.
>> > > > 
>> > > > > 
>> > > > >  Roger
>> > > > > 
>> > > > > > 
>> > > > > >  Cheers, Mike.
>> > > > > > 
>> > > > > >  On Wed, 4 Nov 2015 at 18:16 Roger Bivand <Roger.Bivand at nhh.no> 
>> > > > > >  wrote:
>> > > > > > 
>> > > > > > >  On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>> > > > > > > 
>> > > > > > > >  I'm working with a regular hexagonal grid stored as SPDF. At 
>> > > > > > > >  some
>> > > > > > > >  point I subset this SPDF, then want to combine all adjacent 
>> > > > > > > >  hexagons
>> > > > > > > >  together so that each contiguous set of hexagons is a single 
>> > > > > > > >  polygon.
>> > > > > > > >  I'm doing this last step using gUnaryUnion (or 
>> > > > > > > >  gUnionCascaded, not
>> > > > > > > >  clear what the different is actually). The problem is that 
>> > > > > > > >  in some
>> > > > > > > >  cases boundaries between clearly adjacent polygons are not 
>> > > > > > > >  dissolved.
>> > > > > > > > 
>> > > > > > > >  Example:
>> > > > > > > > 
>> > > > > > > >  ## Create three adjacent hexagons
>> > > > > > > >  library(sp)
>> > > > > > > >  library(rgeos)
>> > > > > > > >  p1 <- Polygon(cbind(
>> > > > > > > >       c(1276503.26781119, 1281876.11747031, 1287248.96712942,
>> > > > > > > >         1287248.96712942, 1281876.11747031, 1276503.26781119,
>> > > > > > > 
>> > > > > > >  1276503.26781119),
>> > > > > > > > 
>> > > > > > > >       c(204391.40834643, 207493.42454344, 204391.40834643,
>> > > > > > > 
>> > > > > > >  198187.37595242,
>> > > > > > > > 
>> > > > > > > >         195085.35975541, 198187.37595242, 204391.40834643)))
>> > > > > > > >  p2 <- Polygon(cbind(
>> > > > > > > >       c(1287248.96712943, 1292621.81678854, 1297994.66644766,
>> > > > > > > >         1297994.66644766, 1292621.81678854, 1287248.96712943,
>> > > > > > > 
>> > > > > > >  1287248.96712943),
>> > > > > > > > 
>> > > > > > > >       c(204391.40834643, 207493.42454344, 204391.40834643,
>> > > > > > > 
>> > > > > > >  198187.37595242,
>> > > > > > > > 
>> > > > > > > >         195085.35975541, 198187.37595242, 204391.40834643)))
>> > > > > > > >  p3 <- Polygon(cbind(
>> > > > > > > >       c(1281876.11747031, 1287248.96712943, 1292621.81678854,
>> > > > > > > >         1292621.81678854, 1287248.96712943, 1281876.11747031,
>> > > > > > > 
>> > > > > > >  1281876.11747031),
>> > > > > > > > 
>> > > > > > > >       c(213697.45693745, 216799.47313446, 213697.45693745,
>> > > > > > > 
>> > > > > > >  207493.42454344,
>> > > > > > > > 
>> > > > > > > >         204391.40834643, 207493.42454344, 213697.45693745)))
>> > > > > > > >  spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), 
>> > > > > > > >  's1')))
>> > > > > > > >  plot(gUnaryUnion(spoly))
>> > > > > > > 
>> > > > > > > 
>> > > > > > >  No, this is just numerical fuzz:
>> > > > > > > 
>> > > > > > >  plot(spoly)
>> > > > > > >  plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, 
>> > > > > > >  add=TRUE)
>> > > > > > >  oS <- getScale()
>> > > > > > >  # default 1e+8
>> > > > > > >  setScale(1e+4)
>> > > > > > >  plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>> > > > > > >  setScale(oS)
>> > > > > > > 
>> > > > > > >  JTS, GEOS, and consequently rgeos by default shift all 
>> > > > > > >  coordinates to
>> > > > > > >  an
>> > > > > > >  integer grid after multiplying by a scale factor (finding 
>> > > > > > >  integer
>> > > > > > >  matches
>> > > > > > >  is much easier than real matches). If the scaling is too 
>> > > > > > >  detailed (in
>> > > > > > >  some
>> > > > > > >  cases), the operations do not give the expected outcomes.
>> > > > > > > 
>> > > > > > >  There is work in progress in GEOS and JTS to provide other 
>> > > > > > >  scaling
>> > > > > > >  options
>> > > > > > >  and models, and to permit iteration over scaling values until 
>> > > > > > >  a
>> > > > > > >  "clean"
>> > > > > > >  result is obtained (for some meanings of clean).
>> > > > > > > 
>> > > > > > >  gUnionCascaded() was the only possible function for GEOS < 
>> > > > > > >  3.3.0, from
>> > > > > > >  GEOS 3.3.0 gUnaryUnion() is available and the prefered and 
>> > > > > > >  more
>> > > > > > >  efficient
>> > > > > > >  route. This is explained on the help page.
>> > > > > > > 
>> > > > > > >  Hope this clarifies,
>> > > > > > > 
>> > > > > > >  Roger
>> > > > > > > 
>> > > > > > > > 
>> > > > > > > >  Note that p2 and p3 are dissolved together, but p1 is 
>> > > > > > > >  separate. The
>> > > > > > > >  shared edge of p1 and p2 is:
>> > > > > > > >  p1:
>> > > > > > > >  [2,] 1281876 207493.4
>> > > > > > > >  [3,] 1287249 204391.4
>> > > > > > > >  p2:
>> > > > > > > >  [5,] 1287249 204391.4
>> > > > > > > >  [6,] 1281876 207493.4
>> > > > > > > > 
>> > > > > > > >  So, exactly the same apart from the order. I originally 
>> > > > > > > >  thought this
>> > > > > > > >  difference in order might be the problem, but this doesn't 
>> > > > > > > >  seem to be
>> > > > > > > >  an issue with in this example, where order is also flipped:
>> > > > > > > >  sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0, xmx=2, 
>> > > > > > > >  ymn=0,
>> > > > > > > >  ymx=2, vals=1:4))
>> > > > > > > >  lapply(sss at polygons, function(x) slot(x, 
>> > > > > > > >  'Polygons')[[1]]@coords)
>> > > > > > > >  plot(sss)
>> > > > > > > >  plot(gUnaryUnion(sss))
>> > > > > > > > 
>> > > > > > > >  Session Info:
>> > > > > > > >  R version 3.2.2 (2015-08-14)
>> > > > > > > >  Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> > > > > > > >  Running under: OS X 10.10.5 (Yosemite)
>> > > > > > > > 
>> > > > > > > >  Message when rgeos is loaded:
>> > > > > > > > 
>> > > > > > > >  rgeos version: 0.3-14, (SVN revision 511)
>> > > > > > > >  GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>> > > > > > > >  Linking to sp version: 1.2-0
>> > > > > > > >  Polygon checking: TRUE
>> > > > > > > > 
>> > > > > > > >  Any help on how to get these polygons to dissolve is 
>> > > > > > > >  appreciated.
>> > > > > > > > 
>> > > > > > > >  M
>> > > > > > > > 
>> > > > > > > >  _______________________________________________
>> > > > > > > >  R-sig-Geo mailing list
>> > > > > > > >  R-sig-Geo at r-project.org
>> > > > > > > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > > > > > 
>> > > > > > > 
>> > > > > > >  --
>> > > > > > >  Roger Bivand
>> > > > > > >  Department of Economics, Norwegian School of Economics,
>> > > > > > >  Helleveien 30, N-5045 Bergen, Norway.
>> > > > > > >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>> > > > > > >  e-mail: Roger.Bivand at nhh.no
>> > > > > > > 
>> > > > > > >  _______________________________________________
>> > > > > > >  R-sig-Geo mailing list
>> > > > > > >  R-sig-Geo at r-project.org
>> > > > > > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > > > > 
>> > > > > > 
>> > > > > 
>> > > > >  --
>> > > > >  Roger Bivand
>> > > > >  Department of Economics, Norwegian School of Economics,
>> > > > >  Helleveien 30, N-5045 Bergen, Norway.
>> > > > >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>> > > > >  e-mail: Roger.Bivand at nhh.no
>> > > > > 
>> > > > 
>> > > 
>> > 
>> >  --
>> >  Roger Bivand
>> >  Department of Economics, Norwegian School of Economics,
>> >  Helleveien 30, N-5045 Bergen, Norway.
>> >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>> >  e-mail: Roger.Bivand at nhh.no
>> > 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Nov  5 12:05:04 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 5 Nov 2015 12:05:04 +0100
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
	<alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
Message-ID: <alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>

On Wed, 4 Nov 2015, Roger Bivand wrote:

> On Wed, 4 Nov 2015, Eduardo Diez wrote:
>
>>  Is there any way of doing this or should i forget it and go on using GRASS
>>  through rgrass7?
>
> I suggest working with Emmanuel Blondel (cleangeo maintainer) to extend 
> cleangeo (also suggested in an earlier thread today, with apologies to 
> Emmanuel for picking on him!). That package already uses rgeos, and is a 
> logical place to put GRASS v.clean-like functionality (maybe even 
> encapsulating using GRASs via rgrass7 and a throwaway location).
>
> At the moment it is messy, though some rgeos internals do do something like 
> this, but it isn't exposed to users.

A possibility is to use:

set_RGEOS_polyThreshold(1e-2) # for example
set_RGEOS_warnSlivers(TRUE)

shows the remaining slivers, and:

set_RGEOS_dropSlivers(TRUE)

drops them when using for example:

> t1 <- gBuffer(<your_object>, byid=TRUE, width=0)

A buffer of zero width should not have side-effects, but your mileage may 
vary. It will only remove slivers, not dangles. I haven't tried it when it 
also finds a Polygons object under the threshold, which was your initial 
problem.

Roger

>
> Roger
>
>>
>>  Thanks
>>
>>  2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>> 
>> >  Ok. So here's a link to a zip file that contains two shapefiles:
>> >  - pol_to_be_cleaned: the layer from which i'd like to remove small
>> >  polygons
>> >   - pol_cleaned: the layer cleaned with the function v.clean rmarea
>> > 
>> >  http://1drv.ms/1GmRWS7
>> > 
>> >  The threshold i used for cleaning was 3000 (meaning 3000 squared 
>> >  meters).
>> > 
>> >  Although i do project it before sending it to GRASS, according to the
>> >  official help page it should be able to handle it:
>> >  "Threshold must always be in square meters, also for latitude-longitude
>> >  locations or locations with units other than meters"
>> > 
>> >  Thanks
>> > 
>> >  2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>> > 
>> > >  On Fri, 16 Oct 2015, Eduardo Diez wrote:
>> > > 
>> > >  Dear list,
>> > > >  I'm willing to know if any knows a way of performing tha same thing 
>> > > >  i'm
>> > > >  doing through rgrass7 with GRASS when I execute the function v.clean 
>> > > >  with
>> > > >  "rmarea" as the tool argument. That is:
>> > > > 
>> > > >  "The rmarea tool removes all areas <= thresh. The longest boundary 
>> > > >  with
>> > > >  an
>> > > >  adjacent area is removed or all boundaries if there is no adjacent 
>> > > >  area.
>> > > >  Area categories are not combined when a small area is merged with a
>> > > >  larger
>> > > >  area."
>> > > > 
>> > > >  Basically i have raster of zones within a field. I convert it to
>> > > >  SpatialPolygonsDataFrame and in order to leave only the more
>> > > >  important/meaningful ones i remove the small/sliver with this tool. 
>> > > >  In
>> > > >  general it works fine but having to call an external software with a
>> > > >  specific version makes the script less portable and you have to be
>> > > >  careful
>> > > >  with updates and such. Also you have to write rasters and shapefiles 
>> > > >  back
>> > > >  and forth as GRASS can't work with in-memory objects.
>> > > > 
>> > > 
>> > >  Could you please provide an example of a built-in or contributed data 
>> > >  set
>> > >  (URL, not attachment) with the slivers you mention, so that we know 
>> > >  that we
>> > >  are addressing your problem? I don't think that:
>> > > 
>> > >  https://cran.r-project.org/web/packages/cleangeo/index.html
>> > > 
>> > >  does this, as it seems to try to repair broken geometries.
>> > > 
>> > >  Also note that you need to specify that the area threshold is in a 
>> > >  square
>> > >  planar metric - dropping slivers in unprojected geometries may be more
>> > >  complicated.
>> > > 
>> > >  Roger
>> > > 
>> > > 
>> > > >  Does someone know a way of doing this in plain R?
>> > > > 
>> > > >  Thanks
>> > > > 
>> > > >          [[alternative HTML version deleted]]
>> > > > 
>> > > >  _______________________________________________
>> > > >  R-sig-Geo mailing list
>> > > >  R-sig-Geo at r-project.org
>> > > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > 
>> > > > 
>> > >  --
>> > >  Roger Bivand
>> > >  Department of Economics, Norwegian School of Economics,
>> > >  Helleveien 30, N-5045 Bergen, Norway.
>> > >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>> > >  e-mail: Roger.Bivand at nhh.no
>> > > 
>> > > 
>> > 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From thi_veloso at yahoo.com.br  Thu Nov  5 19:17:41 2015
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Thu, 5 Nov 2015 18:17:41 +0000 (UTC)
Subject: [R-sig-Geo] How to perform cross-year date operations on
 rasters?
In-Reply-To: <CAAcGz99AAjLiQ-KK+5zUgsezQXX0BNwOQdXgrOicYW2kpY-NBA@mail.gmail.com>
References: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
	<1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
	<CAAcGz99AAjLiQ-KK+5zUgsezQXX0BNwOQdXgrOicYW2kpY-NBA@mail.gmail.com>
Message-ID: <2012834656.318211.1446747461381.JavaMail.yahoo@mail.yahoo.com>

Thanks for your input Michael. With slight modifications on your suggestion, I almost got there:

library(raster)
library(zoo)

# Create a rasterStack similar to cmip5 - same dimensions and layer names
r <- raster(ncol=180, nrow=90)
s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
s <- setZ(s, idx)

# Separate layers with months of interest
ldates <- format(getZ(s), "%m") %in% c("10", "11", "12", "01")
s2 <- subset(s, which(ldates))

# Apply function
s3 <- zApply(s2, by=as.yearmon, fun = sum)


The problem now is that the "isolated" january in the first year is also taken into account, and the "isolated" oct-nov-dec in the last year as well. 

Ideally the function would run only on the contiguous period: oct-nov-dec-jan, and not when at least one month is missing (for example in the first and last years of the series).

Still possible to achieve this? 
Greetings,
 -- Thiago V. dos Santos

PhD student
Land and Atmospheric Science
University of Minnesota



On Thursday, November 5, 2015 12:15 AM, Michael Sumner <mdsumner at gmail.com> wrote:







On Thu, 5 Nov 2015 at 09:38 Thiago V. dos Santos <thi_veloso at yahoo.com.br> wrote:

Dear all,
>
>Consider that I have a raster stack with daily values. How can I perform date operations covering a time interval that crosses years?
>
>For example, I want to sum the values from every october-to-january period in this sample raster:
>
>library(raster)
>
># Create a rasterStack similar to cmip5 - same dimensions and layer names
>r <- raster(ncol=180, nrow=90)
>s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
>
># Apply time stamps to raster
>#x <- as.Date(c("2010-01-01","2014-12-31"),format="%Y-%m-%d")
>#difftime(x[2], x[1], units="days")
>idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
>s <- setZ(s, idx)
>s
>
>
>


You can subset on the dates, by running a test on the date values: 

ldates <- format(getZ(s), "%m") %in% c("10", "11", "01")

subsetting the object

subset(s, which(ldates))

and finally calculating what you want

calc(subset(s, which(ldates)), sum)

HTH



 
 Thanks in advance,
> -- Thiago V. dos Santos
>
>PhD student
>Land and Atmospheric Science
>University of Minnesota
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Dominik.Schneider at colorado.edu  Thu Nov  5 20:26:26 2015
From: Dominik.Schneider at colorado.edu (Dominik Schneider)
Date: Thu, 5 Nov 2015 12:26:26 -0700
Subject: [R-sig-Geo] How to perform cross-year date operations on
	rasters?
In-Reply-To: <2012834656.318211.1446747461381.JavaMail.yahoo@mail.yahoo.com>
References: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
	<CAAcGz99AAjLiQ-KK+5zUgsezQXX0BNwOQdXgrOicYW2kpY-NBA@mail.gmail.com>
	<2012834656.318211.1446747461381.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAHYDKLb07ir=Sk_ZSMqvWsr49QgduuZPLqNAFn-bJGnN+JP-SQ@mail.gmail.com>

Could you use water years for your dates? so Oct-Sep is the same year and
then subset based on month and water year.


On Thu, Nov 5, 2015 at 11:17 AM, Thiago V. dos Santos <
thi_veloso at yahoo.com.br> wrote:

> Thanks for your input Michael. With slight modifications on your
> suggestion, I almost got there:
>
> library(raster)
> library(zoo)
>
> # Create a rasterStack similar to cmip5 - same dimensions and layer names
> r <- raster(ncol=180, nrow=90)
> s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
> s <- setZ(s, idx)
>
> # Separate layers with months of interest
> ldates <- format(getZ(s), "%m") %in% c("10", "11", "12", "01")
> s2 <- subset(s, which(ldates))
>
> # Apply function
> s3 <- zApply(s2, by=as.yearmon, fun = sum)
>
>
> The problem now is that the "isolated" january in the first year is also
> taken into account, and the "isolated" oct-nov-dec in the last year as well.
>
> Ideally the function would run only on the contiguous period:
> oct-nov-dec-jan, and not when at least one month is missing (for example in
> the first and last years of the series).
>
> Still possible to achieve this?
> Greetings,
>  -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
>
>
> On Thursday, November 5, 2015 12:15 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
>
>
>
>
>
>
> On Thu, 5 Nov 2015 at 09:38 Thiago V. dos Santos <thi_veloso at yahoo.com.br>
> wrote:
>
> Dear all,
> >
> >Consider that I have a raster stack with daily values. How can I perform
> date operations covering a time interval that crosses years?
> >
> >For example, I want to sum the values from every october-to-january
> period in this sample raster:
> >
> >library(raster)
> >
> ># Create a rasterStack similar to cmip5 - same dimensions and layer names
> >r <- raster(ncol=180, nrow=90)
> >s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
> >
> ># Apply time stamps to raster
> >#x <- as.Date(c("2010-01-01","2014-12-31"),format="%Y-%m-%d")
> >#difftime(x[2], x[1], units="days")
> >idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
> >s <- setZ(s, idx)
> >s
> >
> >
> >
>
>
> You can subset on the dates, by running a test on the date values:
>
> ldates <- format(getZ(s), "%m") %in% c("10", "11", "01")
>
> subsetting the object
>
> subset(s, which(ldates))
>
> and finally calculating what you want
>
> calc(subset(s, which(ldates)), sum)
>
> HTH
>
>
>
>
>  Thanks in advance,
> > -- Thiago V. dos Santos
> >
> >PhD student
> >Land and Atmospheric Science
> >University of Minnesota
> >
> >_______________________________________________
> >R-sig-Geo mailing list
> >R-sig-Geo at r-project.org
> >https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From strimas at zoology.ubc.ca  Fri Nov  6 03:12:31 2015
From: strimas at zoology.ubc.ca (Matt Strimas-Mackey)
Date: Thu, 5 Nov 2015 18:12:31 -0800
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <alpine.LFD.2.20.1511051138000.27962@reclus.nhh.no>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
	<alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
	<CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>
	<alpine.LFD.2.20.1511050737400.25686@reclus.nhh.no>
	<alpine.LFD.2.20.1511051138000.27962@reclus.nhh.no>
Message-ID: <CAHb9yCB_sA4Zqdvca-Y=pWY4G3eQR0pZ=L=dKWsMf01KVkoJzA@mail.gmail.com>

Thanks for explaining this in such detail! I have a greater
appreciation for the importance of thinking about these topological
issues and for the role machine precision plays.

I constructed a series of simple examples to demonstrate to myself how
these sorts of problems arise and how setScale,
set_RGEOS_polyThreshold, set_RGEOS_dropSlivers, and
set_RGEOS_warnSlivers work. In case someone else stumbles on this
thread looking for similar clarification, I've pasted these examples
below, and they also appear in this gist:
https://gist.github.com/mstrimas/1b4a4b93a9d4a158bce4

library(sp)
library(raster)
library(rgeos)
set_RGEOS_polyThreshold(0)
set_RGEOS_warnSlivers(TRUE)
set_RGEOS_dropSlivers(FALSE)

# function to rigidly shift polygon
# only works for simple polygon objects with a single polygon
shift_poly <- function(p, x, y) {
  p at polygons[[1]]@Polygons[[1]]@coords[,'x'] <-
    p at polygons[[1]]@Polygons[[1]]@coords[,'x'] + x
  p at polygons[[1]]@Polygons[[1]]@coords[,'y'] <-
    p at polygons[[1]]@Polygons[[1]]@coords[,'y'] + y
  row.names(p) <- paste0('shifted', row.names(p))
  return(p)
}

p1 <- readWKT("POLYGON((0 0,0 1,1 1,1 0,0 0))")
row.names(p1) <- '1'
p2 <- readWKT("POLYGON((1 0,1 1,2 1,2 0,1 0))")
row.names(p2) <- '2'

plot(rbind(p1, p2))
plot(shift_poly(p2, -0.5, 0.1), border='orange', add=T, lty=2, lwd=1)

# default scale of 10^8
# behaviour of topology operations depends on scale!
setScale(1e8)
# shift horizontally by small amount so no longer touching
plot(gUnion(p1, shift_poly(p2, 1e-1, 0)))
plot(gUnion(p1, shift_poly(p2, 1e-8, 0)))
plot(gUnion(p1, shift_poly(p2, 1e-9, 0)))

gIntersects(p1, p2)
gIntersects(p1, shift_poly(p2, 1e-1, 0))
gIntersects(p1, shift_poly(p2, 1e-8, 0))
gIntersects(p1, shift_poly(p2, 1e-9, 0))
# polygons with coordinates different by less that the scale set by setScale()
# are considered to intersect and are merge together by union operations

# p1 and p2 share a boundary exactly so the intersection of the 2 is a line
class(gIntersection(p1, p2))
# shift right polygon horizontally slightly to it is just overlapping or just
# separated from the left polygon and consider the results
gIntersection(p1, shift_poly(p2, -1e-9, 0)) # overlap > scale => polygon
gIntersection(p1, shift_poly(p2, -1e-8, 0)) # overlap < scale => line
gIntersection(p1, p2) # exactly touching => line
gIntersection(p1, shift_poly(p2, 1e-9, 0)) # separation < scale => line
gIntersection(p1, shift_poly(p2, 1e-8, 0)) # separation > scale => NULL

# lower scale to 10^4
setScale(1e4)
plot(gUnion(p1, shift_poly(p2, 1e-1, 0)))
plot(gUnion(p1, shift_poly(p2, 1e-4, 0)))
plot(gUnion(p1, shift_poly(p2, 1e-5, 0)))

gIntersects(p1, p2)
gIntersects(p1, shift_poly(p2, 1e-1, 0))
gIntersects(p1, shift_poly(p2, 1e-4, 0))
gIntersects(p1, shift_poly(p2, 1e-5, 0))

gIntersection(p1, shift_poly(p2, -1e-4, 0)) # overlap > scale => polygon
gIntersection(p1, shift_poly(p2, -1e-5, 0)) # overlap < scale => line
gIntersection(p1, p2) # exactly touching => line
gIntersection(p1, shift_poly(p2, 1e-5, 0)) # separation < scale => line
gIntersection(p1, shift_poly(p2, 1e-4, 0)) # separation > scale => NULL


# consider the effect of setting polyThreshold and turning on sliver warning
# this will identify slivers resulting from topology operations
setScale(1e4)
set_RGEOS_polyThreshold(1e-2)
set_RGEOS_warnSlivers(TRUE)
# shift horizontally by increasing amount so just overlapping
gi <- gIntersection(p1, shift_poly(p2, -1e-5, 0))
class(gi) # overlap < scale => line, i.e. assumes just touching
# warnings raised in next 2 cases because:
#   a. overlap > scale => polygon on intersection
#   b. resulting polygon area < polyThreshold => sliver
gIntersection(p1, shift_poly(p2, -1e-4, 0))
gIntersection(p1, shift_poly(p2, -1e-3, 0))
# warnings raised in next 2 cases because:
#   a. overlap > scale => polygon on intersection
#   b. resulting polygon area > polyThreshold => not a sliver
gIntersection(p1, shift_poly(p2, -1e-2, 0))
gIntersection(p1, shift_poly(p2, -1e-1, 0))

# with a lower threshold
set_RGEOS_polyThreshold(1e-3)
# this still raises a warning
gIntersection(p1, shift_poly(p2, -1e-4, 0))
# but this doesn't since resulting polygon is at the threshold now
gIntersection(p1, shift_poly(p2, -1e-3, 0))

# not that it isn't the linear overlap that triggers the warning, it is that the
# area of the resulting polygons are below the threshold
# no warning
gi1 <- gIntersection(p1, shift_poly(p2, -1e-3, 0))
# now a warning is raised because a slight shift in the y direction has caused
# the polygons the resulting polygon to be just less than the 1e-3 threshold
gi2 <- gIntersection(p1, shift_poly(p2, -1e-3, 1e-3))
gArea(gi1) / get_RGEOS_polyThreshold()
gArea(gi2) / get_RGEOS_polyThreshold()

# rgeos can also be set to automatically remove these slivers
class(gIntersection(p1, shift_poly(p2, -1e-4, 0))) # SpaitalPolygons
set_RGEOS_dropSlivers(TRUE)
class(gIntersection(p1, shift_poly(p2, -1e-4, 0))) # NULL
set_RGEOS_dropSlivers(FALSE)

# slivers can also be generated as a result of union operations
setScale(1e4)
set_RGEOS_polyThreshold(1e-2)
set_RGEOS_warnSlivers(TRUE)
set_RGEOS_dropSlivers(FALSE)

p3 <- readWKT("POLYGON((0 1,0 2,2 2,2 1,0 1))")
row.names(p3) <- '3'
p4 <- readWKT("POLYGON((0 -1,0 0,2 0,2 -1,0 -1))")
row.names(p4) <- '4'
plot(rbind(p1, p3, p4))
plot(p2, add=T, col='red')

# offset the middle right (i.e. red) square slightly to the right
# not picked up since middle edge misalignment is < scale
pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-5, 0))
plot(gUnaryUnion(pp))
# misalignment picked up since = scale => a very narrow hole in center
# warning raised because hole area is < polyThreshold
pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-4, 0))
plot(gUnaryUnion(pp))
# misalignment picked up since = scale => a very narrow hole in center
# warning not raised because hole area is > polyThreshold
pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-2, 0))
plot(gUnaryUnion(pp))
# the fact that this is a hole and not a vertical line becomes apparent when
# the shift is bigger
pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-1, 0))
plot(gUnaryUnion(pp))
# finally, set_RGEOS_dropSlivers can be used to remove these slivers
# and fix the topology
set_RGEOS_dropSlivers(TRUE)
pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-4, 0))
plot(gUnaryUnion(pp))
set_RGEOS_dropSlivers(FALSE)

On Thu, Nov 5, 2015 at 2:49 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Thu, 5 Nov 2015, Roger Bivand wrote:
>
>> On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:
>>
>>>  The original study area shapefile is a boundary of the Indonesia half
>>>  of New Guinea. The file as well as the code to construct the hexagonal
>>>  grids are here:
>>>
>>> https://www.dropbox.com/sh/ff8v08p3ambqcbs/AAAPBlGP4fthdmZhrto7oIuCa?dl=0
>>>
>>>  Since it's a large area, generating the grid takes a long time, so
>>>  I've also included code for a small subset of the original
>>>  shapefile--one small offshore island.
>>
>>
>> An equivalent scaling fix is to change the coordinate units from metres to
>> kilometres:
>>
>> library(rgdal)
>> study_area2 <- spTransform(study_area, CRS("+proj=aea +lat_1=-7.42
>>  +lat_2=-0.62 +lat_0=-9.119 +lon_0=128.91 +x_0=0 y_0=0 +datum=WGS84
>>  +units=km +no_defs +ellps=WGS84 +towgs84=0,0,0"))
>> size <- sqrt(2 * 1e2 / sqrt(3)) # reduce to suit
>> set.seed(1)
>> hex_points <- spsample(study_area2[2,], type="hexagonal", cellsize=size)
>> hex_grid <- HexPoints2SpatialPolygons(hex_points)
>> hex_union <- gUnaryUnion(hex_grid)
>> plot(hex_grid, col='lightgrey')
>> plot(hex_union, border='orange', lwd=3, add=T)
>>
>> An advantage of these scaling issues being made visible is that we see
>> that computers really do not operate in continuous space, and that
>> computational geometry actually matters, I suppose.
>>
>> I'll check the underlying code generating the hexagons to see why the
>> nodes (where hexagon boundaries meet) appear to slide apart at the edge of
>> machine precision.
>
>
> A potentially robust approach at default scale uses the dx= argument to
> HexPoints2SpatialPolygons():
>
> hex_grid <- HexPoints2SpatialPolygons(hex_points, dx=size)
>
> Setting:
>
> set_RGEOS_polyThreshold(1e-2) # for example
> set_RGEOS_warnSlivers(TRUE)
>
> shows the remaining slivers, and:
>
> set_RGEOS_dropSlivers(TRUE)
>
> drops them. It is still possible that an inward dangle will get through
> (zero area line in from boundary point, but part of the single boundary).
>
> Setting dx= to the same value as cellsize= in the spsample call seems to be
> crucial, avoiding an approximation marked in the code as:
>
>         # EJP; changed:
>         # how to figure out dx from a grid? THK suggested:
>         #dx <- hexGrid$x[2] - hexGrid$x[1]
>         # and the following will also not always work:
>
> in sp:::genPolyList(), so there was a warning there against taking the
> default.
>
> Roger
>
>
>>
>> Roger
>>
>>
>>>
>>>  Finally, some more odd behaviour. I noticed each time I run this code,
>>>  the dissolve mistakes change, i.e. different boundaries are
>>>  erroneously kept. However, using set.seed() makes the errors the same
>>>  each time for a given seed, and changing the seed yields a different
>>>  set of errors. Example in the code in the dropbox link and copied
>>>  here:
>>>
>>>  library(sp)
>>>  library(raster)
>>>  library(rgeos)
>>>
>>>  # just a subset of full shapefile
>>>  set.seed(1)
>>>  size <- sqrt(2 * 1e8 / sqrt(3))
>>>  study_area <- shapefile('papua.shp')
>>>  hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
>>>  hex_grid <- HexPoints2SpatialPolygons(hex_points)
>>>  hex_union <- gUnaryUnion(hex_grid)
>>>  plot(hex_grid, col='lightgrey')
>>>  plot(hex_union, border='orange', lwd=3, add=T)
>>>
>>>  # results chage according to seed
>>>  set.seed(100)
>>>  size <- sqrt(2 * 1e8 / sqrt(3))
>>>  study_area <- shapefile('papua.shp')
>>>  hex_points <- spsample(study_area[2,], type="hexagonal", cellsize=size)
>>>  hex_grid <- HexPoints2SpatialPolygons(hex_points)
>>>  hex_union <- gUnaryUnion(hex_grid)
>>>  plot(hex_grid, col='lightgrey')
>>>  plot(hex_union, border='orange', lwd=3, add=T)
>>>
>>>  On Wed, Nov 4, 2015 at 8:57 AM, Roger Bivand <Roger.Bivand at nhh.no>
>>> wrote:
>>> >  On Wed, 4 Nov 2015, Matt Strimas-Mackey wrote:
>>> > > >  Thanks, lots of useful info here. I've never seen the setScale()
>>> > >  function; I don't think it's mentioned in the gUnaryUnion help. This
>>> > >  saves me a lot of headache!
>>> > > > >  For what it's worth, the invalid geometry is an artifact of the
>>> > >  reproducible example I created. The original hexagonal grid is
>>> > >  produced with
>>> > >  g <- spsample(study_area, type="hexagonal", cellsize=size)
>>> > >  hex_grid <- HexPoints2SpatialPolygons(g)
>>> > > >  OK, thanks - this is useful. Could you please make available the
>>> > > > study >  area
>>> >  object in some way - so that we can re-create g and see how
>>> >  HexPoints2SpatialPolygons() creates the artefact Mike spotted
>>> > (although >  this
>>> >  looks like numeric fuzz - 'changing "1287248.96712942" to
>>> >  "1287248.96712943"' is a change in the 15th digit, which is on the >
>>> > precision
>>> >  edge of the "double" storage mode. If we can revisit functions
>>> > creating
>>> >  SpatialPolygons objects to ensure that they are GEOS-compatible for
>>> > the
>>> >  default scale of 1e+8, we'll be more secure.
>>> > >  Roger
>>> > > > > > >  And this object passes gIsValid() and clgeo_GeometryReport()
>>> > > > > > > without
>>> > >  any problems, yet still has the dissolving issue. Regardless, all is
>>> > >  solved with setScale().
>>> > > > >  Thanks!
>>> > > > >  M
>>> > > > >  On Wed, Nov 4, 2015 at 6:30 AM, Michael Sumner
>>> > > > > <mdsumner at gmail.com> > >  wrote:
>>> > > > > > > > > > > > >  On Thu, 5 Nov 2015 at 01:10 Roger Bivand
>>> > > > > > > > > > > > > <Roger.Bivand at nhh.no> > > >  wrote:
>>> > > > > > > > > > > > >  On Wed, 4 Nov 2015, Michael Sumner wrote:
>>> > > > > > > > > >  Thanks for all this detail Roger, is there a way to
>>> > > > > > > > > > "re-build" a
>>> > > > > >  spatial
>>> > > > > >  object so that the given scale setting is applied? Are there
>>> > > > > > any
>>> > > > > >  general
>>> > > > > >  rounding or "orthogonalize" functions in the Spatial suite?
>>> > > > > > > > > > > > >  No, not really. In this case, the very detailed
>>> > > > > > > > > > > > > coordinate > > > >  measurements
>>> > > > >  may have made things worse, or possibly using Polygon rather
>>> > > > > than
>>> > > > >  Polygons
>>> > > > >  objects, or not building the Polygons object with a proper
>>> > > > > comment
>>> > > > >  attribute, I don't know. rgeos::gIsValid(spoly) is FALSE, and
>>> > > > > > > > > > > > >
>>> > > > > > > > > > > > > cleangeo::clgeo_GeometryReport(clgeo_CollectionReport(clgeo_Clean(spoly)))
>>> > > > > > > > >  says the same (based on rgeos). I suggest working with
>>> > > > > > > > > Emmanuel > > > >  Blondel
>>> > > > >  (cleangeo maintainer) to extend cleangeo. GEOS is looking at > >
>>> > > > > > >  allowing
>>> > > > >  users to manipulate precision models, not just scale, but I'm >
>>> > > > > > > >  uncertain
>>> > > > >  about that.
>>> > > > > > > > >  Running spoly into GRASS and back out (GRASS builds
>>> > > > > > > > > topology on > > > >  import)
>>> > > > >  shows a different error, the object seems to be problematic.
>>> > > > > > > > > > >  It can be fixed by changing "1287248.96712942" to >
>>> > > > > > > > > > > > >  "1287248.96712943", so
>>> > > >  really the creator should not have had those values on input. > >
>>> > > > >  There's no
>>> > > >  easy way out without topology.
>>> > > > > > >  This brought out some interesting issues for work I've been
>>> > > > > > > doing > > >  using
>>> > > >  the
>>> > > >  "near-Delaunay triangulation" in RTriangle, and that requires a
>>> > > >  normalized
>>> > > >  set of vertices (no duplicate vertices) which on its own presents
>>> > > >  interesting problems. I have a related issue where a parallel > >
>>> > > > >  (latitude)
>>> > > >  line needs many vertices to look "smooth" on a polar projection,
>>> > > > but > > >  when
>>> > > >  building a mesh with triangles it's really best to allow
>>> > > > relatively
>>> > > >  coarse
>>> > > >  segmented boundaries rather than have many elements at parallels.
>>> > > > > > >  The
>>> > > >  Triangle library does not consider these hexagon coordinates to be
>>> > > >  duplicates, so there are two vertical segments between the two > >
>>> > > > >  bottom
>>> > > >  polys
>>> > > >  at
>>> > > > > > >  points(coordinates(as(as(spoly, "SpatialLines"), > > >
>>> > > > > > > "SpatialPoints"))[c(3,
>>> > > >  4),
>>> > > > ] ) > > > > > >  Thanks for the reminder about cleangeo, I'll have
>>> > > > closer look.
>>> > > > > > >  cheers, Mike.
>>> > > > > > > > > > > >  Roger
>>> > > > > > > > > > > > > > >  Cheers, Mike.
>>> > > > > > > > > > >  On Wed, 4 Nov 2015 at 18:16 Roger Bivand
>>> > > > > > > > > > > <Roger.Bivand at nhh.no> > > > > >  wrote:
>>> > > > > > > > > > > >  On Tue, 3 Nov 2015, Matt Strimas-Mackey wrote:
>>> > > > > > > > > > > > > >  I'm working with a regular hexagonal grid
>>> > > > > > > > > > > > > > stored as SPDF. At > > > > > > >  some
>>> > > > > > > >  point I subset this SPDF, then want to combine all
>>> > > > > > > > adjacent > > > > > > >  hexagons
>>> > > > > > > >  together so that each contiguous set of hexagons is a
>>> > > > > > > > single > > > > > > >  polygon.
>>> > > > > > > >  I'm doing this last step using gUnaryUnion (or > > > > > >
>>> > > > > > > > >  gUnionCascaded, not
>>> > > > > > > >  clear what the different is actually). The problem is that
>>> > > > > > > > > > > > > > >  in some
>>> > > > > > > >  cases boundaries between clearly adjacent polygons are not
>>> > > > > > > > > > > > > > >  dissolved.
>>> > > > > > > > > > > > > > >  Example:
>>> > > > > > > > > > > > > > >  ## Create three adjacent hexagons
>>> > > > > > > >  library(sp)
>>> > > > > > > >  library(rgeos)
>>> > > > > > > >  p1 <- Polygon(cbind(
>>> > > > > > > >       c(1276503.26781119, 1281876.11747031,
>>> > > > > > > > 1287248.96712942,
>>> > > > > > > >         1287248.96712942, 1281876.11747031,
>>> > > > > > > > 1276503.26781119,
>>> > > > > > > > > > > > >  1276503.26781119),
>>> > > > > > > > > > > > > > >       c(204391.40834643, 207493.42454344,
>>> > > > > > > > > > > > > > > 204391.40834643,
>>> > > > > > > > > > > > >  198187.37595242,
>>> > > > > > > > > > > > > > >         195085.35975541, 198187.37595242,
>>> > > > > > > > > > > > > > > 204391.40834643)))
>>> > > > > > > >  p2 <- Polygon(cbind(
>>> > > > > > > >       c(1287248.96712943, 1292621.81678854,
>>> > > > > > > > 1297994.66644766,
>>> > > > > > > >         1297994.66644766, 1292621.81678854,
>>> > > > > > > > 1287248.96712943,
>>> > > > > > > > > > > > >  1287248.96712943),
>>> > > > > > > > > > > > > > >       c(204391.40834643, 207493.42454344,
>>> > > > > > > > > > > > > > > 204391.40834643,
>>> > > > > > > > > > > > >  198187.37595242,
>>> > > > > > > > > > > > > > >         195085.35975541, 198187.37595242,
>>> > > > > > > > > > > > > > > 204391.40834643)))
>>> > > > > > > >  p3 <- Polygon(cbind(
>>> > > > > > > >       c(1281876.11747031, 1287248.96712943,
>>> > > > > > > > 1292621.81678854,
>>> > > > > > > >         1292621.81678854, 1287248.96712943,
>>> > > > > > > > 1281876.11747031,
>>> > > > > > > > > > > > >  1281876.11747031),
>>> > > > > > > > > > > > > > >       c(213697.45693745, 216799.47313446,
>>> > > > > > > > > > > > > > > 213697.45693745,
>>> > > > > > > > > > > > >  207493.42454344,
>>> > > > > > > > > > > > > > >         204391.40834643, 207493.42454344,
>>> > > > > > > > > > > > > > > 213697.45693745)))
>>> > > > > > > >  spoly <- SpatialPolygons(list(Polygons(list(p1, p2, p3), >
>>> > > > > > > > > > > > > >  's1')))
>>> > > > > > > >  plot(gUnaryUnion(spoly))
>>> > > > > > > > > > > > > > > > > > >  No, this is just numerical fuzz:
>>> > > > > > > > > > > > >  plot(spoly)
>>> > > > > > >  plot(gUnaryUnion(spoly), border="green", lty=3, lwd=2, > > >
>>> > > > > > > > > >  add=TRUE)
>>> > > > > > >  oS <- getScale()
>>> > > > > > >  # default 1e+8
>>> > > > > > >  setScale(1e+4)
>>> > > > > > >  plot(gUnaryUnion(spoly), border="orange", lwd=2, add=TRUE)
>>> > > > > > >  setScale(oS)
>>> > > > > > > > > > > > >  JTS, GEOS, and consequently rgeos by default
>>> > > > > > > > > > > > > shift all > > > > > >  coordinates to
>>> > > > > > >  an
>>> > > > > > >  integer grid after multiplying by a scale factor (finding >
>>> > > > > > > > > > > >  integer
>>> > > > > > >  matches
>>> > > > > > >  is much easier than real matches). If the scaling is too > >
>>> > > > > > > > > > >  detailed (in
>>> > > > > > >  some
>>> > > > > > >  cases), the operations do not give the expected outcomes.
>>> > > > > > > > > > > > >  There is work in progress in GEOS and JTS to
>>> > > > > > > > > > > > > provide other > > > > > >  scaling
>>> > > > > > >  options
>>> > > > > > >  and models, and to permit iteration over scaling values
>>> > > > > > > until > > > > > >  a
>>> > > > > > >  "clean"
>>> > > > > > >  result is obtained (for some meanings of clean).
>>> > > > > > > > > > > > >  gUnionCascaded() was the only possible function
>>> > > > > > > > > > > > > for GEOS < > > > > > >  3.3.0, from
>>> > > > > > >  GEOS 3.3.0 gUnaryUnion() is available and the prefered and >
>>> > > > > > > > > > > >  more
>>> > > > > > >  efficient
>>> > > > > > >  route. This is explained on the help page.
>>> > > > > > > > > > > > >  Hope this clarifies,
>>> > > > > > > > > > > > >  Roger
>>> > > > > > > > > > > > > > > > > > > > >  Note that p2 and p3 are
>>> > > > > > > > > > > > > > > > > > > > > dissolved together, but p1 is > > > > > > >  separate. The
>>> > > > > > > >  shared edge of p1 and p2 is:
>>> > > > > > > >  p1:
>>> > > > > > > >  [2,] 1281876 207493.4
>>> > > > > > > >  [3,] 1287249 204391.4
>>> > > > > > > >  p2:
>>> > > > > > > >  [5,] 1287249 204391.4
>>> > > > > > > >  [6,] 1281876 207493.4
>>> > > > > > > > > > > > > > >  So, exactly the same apart from the order. I
>>> > > > > > > > > > > > > > > originally > > > > > > >  thought this
>>> > > > > > > >  difference in order might be the problem, but this doesn't
>>> > > > > > > > > > > > > > >  seem to be
>>> > > > > > > >  an issue with in this example, where order is also
>>> > > > > > > > flipped:
>>> > > > > > > >  sss <- rasterToPolygons(raster(nrow=2, ncol=2, xmn=0,
>>> > > > > > > > xmx=2, > > > > > > >  ymn=0,
>>> > > > > > > >  ymx=2, vals=1:4))
>>> > > > > > > >  lapply(sss at polygons, function(x) slot(x, > > > > > > >
>>> > > > > > > > 'Polygons')[[1]]@coords)
>>> > > > > > > >  plot(sss)
>>> > > > > > > >  plot(gUnaryUnion(sss))
>>> > > > > > > > > > > > > > >  Session Info:
>>> > > > > > > >  R version 3.2.2 (2015-08-14)
>>> > > > > > > >  Platform: x86_64-apple-darwin13.4.0 (64-bit)
>>> > > > > > > >  Running under: OS X 10.10.5 (Yosemite)
>>> > > > > > > > > > > > > > >  Message when rgeos is loaded:
>>> > > > > > > > > > > > > > >  rgeos version: 0.3-14, (SVN revision 511)
>>> > > > > > > >  GEOS runtime version: 3.5.0-CAPI-1.9.0 r0
>>> > > > > > > >  Linking to sp version: 1.2-0
>>> > > > > > > >  Polygon checking: TRUE
>>> > > > > > > > > > > > > > >  Any help on how to get these polygons to
>>> > > > > > > > > > > > > > > dissolve is > > > > > > >  appreciated.
>>> > > > > > > > > > > > > > >  M
>>> > > > > > > > > > > > > > >
>>> > > > > > > > > > > > > > > _______________________________________________
>>> > > > > > > >  R-sig-Geo mailing list
>>> > > > > > > >  R-sig-Geo at r-project.org
>>> > > > > > > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > > > > > > > > > > > > > > > > > > >  --
>>> > > > > > >  Roger Bivand
>>> > > > > > >  Department of Economics, Norwegian School of Economics,
>>> > > > > > >  Helleveien 30, N-5045 Bergen, Norway.
>>> > > > > > >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> > > > > > >  e-mail: Roger.Bivand at nhh.no
>>> > > > > > > > > > > > >  _______________________________________________
>>> > > > > > >  R-sig-Geo mailing list
>>> > > > > > >  R-sig-Geo at r-project.org
>>> > > > > > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > > > > > > > > > > > > > > > > > > >  --
>>> > > > >  Roger Bivand
>>> > > > >  Department of Economics, Norwegian School of Economics,
>>> > > > >  Helleveien 30, N-5045 Bergen, Norway.
>>> > > > >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> > > > >  e-mail: Roger.Bivand at nhh.no
>>> > > > > > > > > > > >  --
>>> >  Roger Bivand
>>> >  Department of Economics, Norwegian School of Economics,
>>> >  Helleveien 30, N-5045 Bergen, Norway.
>>> >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> >  e-mail: Roger.Bivand at nhh.no
>>> >
>>
>>
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>


From geponce at gmail.com  Fri Nov  6 04:26:21 2015
From: geponce at gmail.com (Guillermo E. Ponce-Campos)
Date: Thu, 5 Nov 2015 20:26:21 -0700
Subject: [R-sig-Geo] clusterR + rasterToPoints
Message-ID: <CAGKzJ7pFzijvGC70+6M1_vmpbdRDzXa0zGbPtuGvY3rMv_SW3A@mail.gmail.com>

Is it possible to take advantage of multi-cores with function
rasterToPoints for converting a stack of several rasters into a x,y,z data
frame ?

Thanks,
Guillermo

	[[alternative HTML version deleted]]


From loic.dutrieux at wur.nl  Fri Nov  6 10:51:25 2015
From: loic.dutrieux at wur.nl (Dutrieux, Loic)
Date: Fri, 6 Nov 2015 09:51:25 +0000
Subject: [R-sig-Geo] How to perform cross-year date operations on
	rasters?
In-Reply-To: <2012834656.318211.1446747461381.JavaMail.yahoo@mail.yahoo.com>
References: <1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
	<1627530934.1968819.1446676660151.JavaMail.yahoo@mail.yahoo.com>
	<CAAcGz99AAjLiQ-KK+5zUgsezQXX0BNwOQdXgrOicYW2kpY-NBA@mail.gmail.com>
	<2012834656.318211.1446747461381.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1446803485796.17654@wur.nl>

Hi Thiago,

Building on Michael's answer and your example, I think the following should work. The tricky part is to build the right by= argument for zApply().
You can see zApply as a wrapper of aggregate.zoo() for temporal raster bricks, and you're more likely to find answers for aggregate.zoo than for zApply when searching the internet.
This is where I found the answer: https://stat.ethz.ch/pipermail/r-help/2008-August/171366.html

Cheers,
Lo?c Dutrieux

library(raster)
library(zoo)
library(lubridate)

# Create a rasterStack similar to cmip5 - same dimensions and layer names
r <- raster(ncol=180, nrow=90)
s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
s <- setZ(s, idx)

# Separate layers with months of interest
ldates <- format(getZ(s), "%m") %in% c("10", "11", "12", "01")
s2 <- subset(s, which(ldates))

# Apply function
s3 <- zApply(s2, by=year(as.yearmon(getZ(s2)) - 1/12), fun = sum))

On 11/05/2015 07:17 PM, Thiago V. dos Santos wrote:
> Thanks for your input Michael. With slight modifications on your suggestion, I almost got there:
>
> library(raster)
> library(zoo)
>
> # Create a rasterStack similar to cmip5 - same dimensions and layer names
> r <- raster(ncol=180, nrow=90)
> s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
> s <- setZ(s, idx)
>
> # Separate layers with months of interest
> ldates <- format(getZ(s), "%m") %in% c("10", "11", "12", "01")
> s2 <- subset(s, which(ldates))
>
> # Apply function
> s3 <- zApply(s2, by=as.yearmon, fun = sum)
>
>
> The problem now is that the "isolated" january in the first year is also taken into account, and the "isolated" oct-nov-dec in the last year as well.
>
> Ideally the function would run only on the contiguous period: oct-nov-dec-jan, and not when at least one month is missing (for example in the first and last years of the series).
>
> Still possible to achieve this?
> Greetings,
>   -- Thiago V. dos Santos
>
> PhD student
> Land and Atmospheric Science
> University of Minnesota
>
>
>
> On Thursday, November 5, 2015 12:15 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>
>
>
>
>
>
> On Thu, 5 Nov 2015 at 09:38 Thiago V. dos Santos <thi_veloso at yahoo.com.br> wrote:
>
> Dear all,
>>
>> Consider that I have a raster stack with daily values. How can I perform date operations covering a time interval that crosses years?
>>
>> For example, I want to sum the values from every october-to-january period in this sample raster:
>>
>> library(raster)
>>
>> # Create a rasterStack similar to cmip5 - same dimensions and layer names
>> r <- raster(ncol=180, nrow=90)
>> s <- stack(lapply(1:1825, function(x) setValues(r, runif(ncell(r)))))
>>
>> # Apply time stamps to raster
>> #x <- as.Date(c("2010-01-01","2014-12-31"),format="%Y-%m-%d")
>> #difftime(x[2], x[1], units="days")
>> idx <- seq(as.Date("2010/1/1"), by = "day", length.out = 1825)
>> s <- setZ(s, idx)
>> s
>>
>>
>>
>
>
> You can subset on the dates, by running a test on the date values:
>
> ldates <- format(getZ(s), "%m") %in% c("10", "11", "01")
>
> subsetting the object
>
> subset(s, which(ldates))
>
> and finally calculating what you want
>
> calc(subset(s, which(ldates)), sum)
>
> HTH
>
>
>
>
>   Thanks in advance,
>> -- Thiago V. dos Santos
>>
>> PhD student
>> Land and Atmospheric Science
>> University of Minnesota
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Roger.Bivand at nhh.no  Fri Nov  6 15:29:40 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 6 Nov 2015 15:29:40 +0100
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <CAHb9yCB_sA4Zqdvca-Y=pWY4G3eQR0pZ=L=dKWsMf01KVkoJzA@mail.gmail.com>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
	<alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
	<CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>
	<alpine.LFD.2.20.1511050737400.25686@reclus.nhh.no>
	<alpine.LFD.2.20.1511051138000.27962@reclus.nhh.no>
	<CAHb9yCB_sA4Zqdvca-Y=pWY4G3eQR0pZ=L=dKWsMf01KVkoJzA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511061519110.26065@reclus.nhh.no>

Matt:

Thanks very much for this. I think that it would make an excellent 
vignette for rgeos, maybe you could consider using Markdown on your 
existing script to explain to the reader what they might expect? I'd also 
bring in Colin Rundel, as it was his insight that uncovered the scale "can 
of worms" five years ago, if you would like to go ahead.

Maybe also use maptools::elide methods instead of shift_poly() - maptools 
is Suggests: in rgeos, so is assumed to be able to be available 
(conditionally) when the package is built, installed and checked.

Actually, this is somewhat like a spatial version of FAQ 7.31:

https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

Best wishes,

Roger

On Fri, 6 Nov 2015, Matt Strimas-Mackey wrote:

> Thanks for explaining this in such detail! I have a greater
> appreciation for the importance of thinking about these topological
> issues and for the role machine precision plays.
>
> I constructed a series of simple examples to demonstrate to myself how
> these sorts of problems arise and how setScale,
> set_RGEOS_polyThreshold, set_RGEOS_dropSlivers, and
> set_RGEOS_warnSlivers work. In case someone else stumbles on this
> thread looking for similar clarification, I've pasted these examples
> below, and they also appear in this gist:
> https://gist.github.com/mstrimas/1b4a4b93a9d4a158bce4
>
> library(sp)
> library(raster)
> library(rgeos)
> set_RGEOS_polyThreshold(0)
> set_RGEOS_warnSlivers(TRUE)
> set_RGEOS_dropSlivers(FALSE)
>
> # function to rigidly shift polygon
> # only works for simple polygon objects with a single polygon
> shift_poly <- function(p, x, y) {
>  p at polygons[[1]]@Polygons[[1]]@coords[,'x'] <-
>    p at polygons[[1]]@Polygons[[1]]@coords[,'x'] + x
>  p at polygons[[1]]@Polygons[[1]]@coords[,'y'] <-
>    p at polygons[[1]]@Polygons[[1]]@coords[,'y'] + y
>  row.names(p) <- paste0('shifted', row.names(p))
>  return(p)
> }
>
> p1 <- readWKT("POLYGON((0 0,0 1,1 1,1 0,0 0))")
> row.names(p1) <- '1'
> p2 <- readWKT("POLYGON((1 0,1 1,2 1,2 0,1 0))")
> row.names(p2) <- '2'
>
> plot(rbind(p1, p2))
> plot(shift_poly(p2, -0.5, 0.1), border='orange', add=T, lty=2, lwd=1)
>
> # default scale of 10^8
> # behaviour of topology operations depends on scale!
> setScale(1e8)
> # shift horizontally by small amount so no longer touching
> plot(gUnion(p1, shift_poly(p2, 1e-1, 0)))
> plot(gUnion(p1, shift_poly(p2, 1e-8, 0)))
> plot(gUnion(p1, shift_poly(p2, 1e-9, 0)))
>
> gIntersects(p1, p2)
> gIntersects(p1, shift_poly(p2, 1e-1, 0))
> gIntersects(p1, shift_poly(p2, 1e-8, 0))
> gIntersects(p1, shift_poly(p2, 1e-9, 0))
> # polygons with coordinates different by less that the scale set by setScale()
> # are considered to intersect and are merge together by union operations
>
> # p1 and p2 share a boundary exactly so the intersection of the 2 is a line
> class(gIntersection(p1, p2))
> # shift right polygon horizontally slightly to it is just overlapping or just
> # separated from the left polygon and consider the results
> gIntersection(p1, shift_poly(p2, -1e-9, 0)) # overlap > scale => polygon
> gIntersection(p1, shift_poly(p2, -1e-8, 0)) # overlap < scale => line
> gIntersection(p1, p2) # exactly touching => line
> gIntersection(p1, shift_poly(p2, 1e-9, 0)) # separation < scale => line
> gIntersection(p1, shift_poly(p2, 1e-8, 0)) # separation > scale => NULL
>
> # lower scale to 10^4
> setScale(1e4)
> plot(gUnion(p1, shift_poly(p2, 1e-1, 0)))
> plot(gUnion(p1, shift_poly(p2, 1e-4, 0)))
> plot(gUnion(p1, shift_poly(p2, 1e-5, 0)))
>
> gIntersects(p1, p2)
> gIntersects(p1, shift_poly(p2, 1e-1, 0))
> gIntersects(p1, shift_poly(p2, 1e-4, 0))
> gIntersects(p1, shift_poly(p2, 1e-5, 0))
>
> gIntersection(p1, shift_poly(p2, -1e-4, 0)) # overlap > scale => polygon
> gIntersection(p1, shift_poly(p2, -1e-5, 0)) # overlap < scale => line
> gIntersection(p1, p2) # exactly touching => line
> gIntersection(p1, shift_poly(p2, 1e-5, 0)) # separation < scale => line
> gIntersection(p1, shift_poly(p2, 1e-4, 0)) # separation > scale => NULL
>
>
> # consider the effect of setting polyThreshold and turning on sliver warning
> # this will identify slivers resulting from topology operations
> setScale(1e4)
> set_RGEOS_polyThreshold(1e-2)
> set_RGEOS_warnSlivers(TRUE)
> # shift horizontally by increasing amount so just overlapping
> gi <- gIntersection(p1, shift_poly(p2, -1e-5, 0))
> class(gi) # overlap < scale => line, i.e. assumes just touching
> # warnings raised in next 2 cases because:
> #   a. overlap > scale => polygon on intersection
> #   b. resulting polygon area < polyThreshold => sliver
> gIntersection(p1, shift_poly(p2, -1e-4, 0))
> gIntersection(p1, shift_poly(p2, -1e-3, 0))
> # warnings raised in next 2 cases because:
> #   a. overlap > scale => polygon on intersection
> #   b. resulting polygon area > polyThreshold => not a sliver
> gIntersection(p1, shift_poly(p2, -1e-2, 0))
> gIntersection(p1, shift_poly(p2, -1e-1, 0))
>
> # with a lower threshold
> set_RGEOS_polyThreshold(1e-3)
> # this still raises a warning
> gIntersection(p1, shift_poly(p2, -1e-4, 0))
> # but this doesn't since resulting polygon is at the threshold now
> gIntersection(p1, shift_poly(p2, -1e-3, 0))
>
> # not that it isn't the linear overlap that triggers the warning, it is that the
> # area of the resulting polygons are below the threshold
> # no warning
> gi1 <- gIntersection(p1, shift_poly(p2, -1e-3, 0))
> # now a warning is raised because a slight shift in the y direction has caused
> # the polygons the resulting polygon to be just less than the 1e-3 threshold
> gi2 <- gIntersection(p1, shift_poly(p2, -1e-3, 1e-3))
> gArea(gi1) / get_RGEOS_polyThreshold()
> gArea(gi2) / get_RGEOS_polyThreshold()
>
> # rgeos can also be set to automatically remove these slivers
> class(gIntersection(p1, shift_poly(p2, -1e-4, 0))) # SpaitalPolygons
> set_RGEOS_dropSlivers(TRUE)
> class(gIntersection(p1, shift_poly(p2, -1e-4, 0))) # NULL
> set_RGEOS_dropSlivers(FALSE)
>
> # slivers can also be generated as a result of union operations
> setScale(1e4)
> set_RGEOS_polyThreshold(1e-2)
> set_RGEOS_warnSlivers(TRUE)
> set_RGEOS_dropSlivers(FALSE)
>
> p3 <- readWKT("POLYGON((0 1,0 2,2 2,2 1,0 1))")
> row.names(p3) <- '3'
> p4 <- readWKT("POLYGON((0 -1,0 0,2 0,2 -1,0 -1))")
> row.names(p4) <- '4'
> plot(rbind(p1, p3, p4))
> plot(p2, add=T, col='red')
>
> # offset the middle right (i.e. red) square slightly to the right
> # not picked up since middle edge misalignment is < scale
> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-5, 0))
> plot(gUnaryUnion(pp))
> # misalignment picked up since = scale => a very narrow hole in center
> # warning raised because hole area is < polyThreshold
> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-4, 0))
> plot(gUnaryUnion(pp))
> # misalignment picked up since = scale => a very narrow hole in center
> # warning not raised because hole area is > polyThreshold
> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-2, 0))
> plot(gUnaryUnion(pp))
> # the fact that this is a hole and not a vertical line becomes apparent when
> # the shift is bigger
> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-1, 0))
> plot(gUnaryUnion(pp))
> # finally, set_RGEOS_dropSlivers can be used to remove these slivers
> # and fix the topology
> set_RGEOS_dropSlivers(TRUE)
> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-4, 0))
> plot(gUnaryUnion(pp))
> set_RGEOS_dropSlivers(FALSE)
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From eduardodiez at gmx.com  Sat Nov  7 03:45:31 2015
From: eduardodiez at gmx.com (Eduardo Diez)
Date: Fri, 6 Nov 2015 23:45:31 -0300
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
	<alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
	<alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>
Message-ID: <CANK5cGwv7w7ODmxhYB2pTA_cABWLXUwkyYPtPe9c7z7066U-Vw@mail.gmail.com>

Roger,
Following this last approach strange things happen: the sliver polygons
that are fully inside another one get "merged" with the larger; the ones
that have no contact with the exterior but share boundaries with two or
more polygons get deleted and a hole left behind; the ones in contact with
the exterior get deleted.
This is what i tried. As the polygons were projected i used values
 in squared meters for the set_RGEOS_polyThreshold function. I think values
 of around 1e-2 are more appropriate for Spatial* objects in GCS.

> pol1 <- rasterToPolygons(raster1, dissolve = T)
> pol2 <- createSPComment(pol1)
> set_RGEOS_polyThreshold(3000) # for example
> set_RGEOS_warnSlivers(T)
> set_RGEOS_dropSlivers(T)
> t1 <- gBuffer(pol2, byid = T, width = 0)
There were 50 or more warnings (use warnings() to see the first 50)
> warnings()
Warning messages:
1: In gBuffer(pol2, byid = T, width = 0) : 1: Polygon object 0 area 726.084
2: In gBuffer(pol2, byid = T, width = 0) : 2: Polygon object 1 area 20.169
3: In gBuffer(pol2, byid = T, width = 0) : 3: Polygon object 2 area 20.169
4: In gBuffer(pol2, byid = T, width = 0) : 4: Polygon object 3 area 20.169
5: In gBuffer(pol2, byid = T, width = 0) : 5: Polygon object 4 area 20.169
6: In gBuffer(pol2, byid = T, width = 0) : 6: Polygon object 5 area 20.169
7: In gBuffer(pol2, byid = T, width = 0) : 7: Polygon object 6 area 80.676
8: In gBuffer(pol2, byid = T, width = 0) : 8: Polygon object 7 area 20.169
9: In gBuffer(pol2, byid = T, width = 0) : 9: Polygon object 8 area 20.169
10: In gBuffer(pol2, byid = T, width = 0) : 10: Polygon object 9 area 20.169
11: In gBuffer(pol2, byid = T, width = 0) : 11: Polygon object 10 area
2581.63
12: In gBuffer(pol2, byid = T, width = 0) : 12: Polygon object 11 area
40.338
13: In gBuffer(pol2, byid = T, width = 0) : 13: Polygon object 12 area
20.169
14: In gBuffer(pol2, byid = T, width = 0) : 14: Polygon object 14 area 1432
15: In gBuffer(pol2, byid = T, width = 0) : 15: Polygon object 15 area
40.338
16: In gBuffer(pol2, byid = T, width = 0) : 16: Polygon object 16 area
20.169
17: In gBuffer(pol2, byid = T, width = 0) : 17: Polygon object 17 area
20.169
18: In gBuffer(pol2, byid = T, width = 0) : 18: Polygon object 18 area
20.169
19: In gBuffer(pol2, byid = T, width = 0) : 19: Polygon object 19 area
80.676
20: In gBuffer(pol2, byid = T, width = 0) : 20: Polygon object 21 area
20.169
21: In gBuffer(pol2, byid = T, width = 0) : 21: Polygon object 22 area
1230.31
22: In gBuffer(pol2, byid = T, width = 0) : 22: Polygon object 23 area
20.169
23: In gBuffer(pol2, byid = T, width = 0) : 23: Polygon object 25 area
20.169
24: In gBuffer(pol2, byid = T, width = 0) : 24: Polygon object 26 area
20.169
25: In gBuffer(pol2, byid = T, width = 0) : 25: Polygon object 27 area
564.732
26: In gBuffer(pol2, byid = T, width = 0) : 26: Polygon object 28 area
40.338
27: In gBuffer(pol2, byid = T, width = 0) : 27: Polygon object 30 area
504.225
28: In gBuffer(pol2, byid = T, width = 0) : 28: Polygon object 31 area
605.07
29: In gBuffer(pol2, byid = T, width = 0) : 29: Polygon object 33 area
20.169
30: In gBuffer(pol2, byid = T, width = 0) : 30: Polygon object 34 area
20.169
31: In gBuffer(pol2, byid = T, width = 0) : 31: Polygon object 35 area
1210.14
32: In gBuffer(pol2, byid = T, width = 0) : 32: Polygon object 36 area
20.169
33: In gBuffer(pol2, byid = T, width = 0) : 33: Polygon object 37 area
685.746
34: In gBuffer(pol2, byid = T, width = 0) : 34: Polygon object 38 area
40.338
35: In gBuffer(pol2, byid = T, width = 0) : 35: Polygon object 39 area
20.169
36: In gBuffer(pol2, byid = T, width = 0) : 36: Polygon object 40 area
20.169
37: In gBuffer(pol2, byid = T, width = 0) : 37: Polygon object 41 area
80.676
38: In gBuffer(pol2, byid = T, width = 0) : 38: Polygon object 42 area
20.169
39: In gBuffer(pol2, byid = T, width = 0) : 39: Polygon object 43 area
625.239
40: In gBuffer(pol2, byid = T, width = 0) : 40: Polygon object 44 area
20.169
41: In gBuffer(pol2, byid = T, width = 0) : 41: Polygon object 46 area
262.197
42: In gBuffer(pol2, byid = T, width = 0) : 42: Polygon object 47 area
2500.96
43: In gBuffer(pol2, byid = T, width = 0) : 43: Polygon object 48 area
20.169
44: In gBuffer(pol2, byid = T, width = 0) : 44: Polygon object 49 area
40.338
45: In gBuffer(pol2, byid = T, width = 0) : 45: Polygon object 53 area
80.676
46: In gBuffer(pol2, byid = T, width = 0) : 46: Polygon object 56 area
1290.82
47: In gBuffer(pol2, byid = T, width = 0) : 47: Polygon object 57 area
2722.82
48: In gBuffer(pol2, byid = T, width = 0) : 48: Polygon object 59 area
2218.59
49: In gBuffer(pol2, byid = T, width = 0) : 49: Polygon object 60 area
40.338
50: In gBuffer(pol2, byid = T, width = 0) : 50: Polygon object 61 area
121.014

> spplot(t1)

Thanks, and sorry if i can't be of much help in making suggestions as i
don't know how could this be done


2015-11-05 8:05 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:

> On Wed, 4 Nov 2015, Roger Bivand wrote:
>
> On Wed, 4 Nov 2015, Eduardo Diez wrote:
>>
>>  Is there any way of doing this or should i forget it and go on using
>>> GRASS
>>>  through rgrass7?
>>>
>>
>> I suggest working with Emmanuel Blondel (cleangeo maintainer) to extend
>> cleangeo (also suggested in an earlier thread today, with apologies to
>> Emmanuel for picking on him!). That package already uses rgeos, and is a
>> logical place to put GRASS v.clean-like functionality (maybe even
>> encapsulating using GRASs via rgrass7 and a throwaway location).
>>
>> At the moment it is messy, though some rgeos internals do do something
>> like this, but it isn't exposed to users.
>>
>
> A possibility is to use:
>
> set_RGEOS_polyThreshold(1e-2) # for example
> set_RGEOS_warnSlivers(TRUE)
>
> shows the remaining slivers, and:
>
> set_RGEOS_dropSlivers(TRUE)
>
> drops them when using for example:
>
> t1 <- gBuffer(<your_object>, byid=TRUE, width=0)
>>
>
> A buffer of zero width should not have side-effects, but your mileage may
> vary. It will only remove slivers, not dangles. I haven't tried it when it
> also finds a Polygons object under the threshold, which was your initial
> problem.
>
> Roger
>
>
>
>> Roger
>>
>>
>>>  Thanks
>>>
>>>  2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>>>
>>> >  Ok. So here's a link to a zip file that contains two shapefiles:
>>> >  - pol_to_be_cleaned: the layer from which i'd like to remove small
>>> >  polygons
>>> >   - pol_cleaned: the layer cleaned with the function v.clean rmarea
>>> > >  http://1drv.ms/1GmRWS7
>>> > >  The threshold i used for cleaning was 3000 (meaning 3000 squared >
>>> meters).
>>> > >  Although i do project it before sending it to GRASS, according to
>>> the
>>> >  official help page it should be able to handle it:
>>> >  "Threshold must always be in square meters, also for
>>> latitude-longitude
>>> >  locations or locations with units other than meters"
>>> > >  Thanks
>>> > >  2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>> > > >  On Fri, 16 Oct 2015, Eduardo Diez wrote:
>>> > > > >  Dear list,
>>> > > >  I'm willing to know if any knows a way of performing tha same
>>> thing > > >  i'm
>>> > > >  doing through rgrass7 with GRASS when I execute the function
>>> v.clean > > >  with
>>> > > >  "rmarea" as the tool argument. That is:
>>> > > > > > >  "The rmarea tool removes all areas <= thresh. The longest
>>> boundary > > >  with
>>> > > >  an
>>> > > >  adjacent area is removed or all boundaries if there is no
>>> adjacent > > >  area.
>>> > > >  Area categories are not combined when a small area is merged with
>>> a
>>> > > >  larger
>>> > > >  area."
>>> > > > > > >  Basically i have raster of zones within a field. I convert
>>> it to
>>> > > >  SpatialPolygonsDataFrame and in order to leave only the more
>>> > > >  important/meaningful ones i remove the small/sliver with this
>>> tool. > > >  In
>>> > > >  general it works fine but having to call an external software
>>> with a
>>> > > >  specific version makes the script less portable and you have to be
>>> > > >  careful
>>> > > >  with updates and such. Also you have to write rasters and
>>> shapefiles > > >  back
>>> > > >  and forth as GRASS can't work with in-memory objects.
>>> > > > > > > >  Could you please provide an example of a built-in or
>>> contributed data > >  set
>>> > >  (URL, not attachment) with the slivers you mention, so that we know
>>> > >  that we
>>> > >  are addressing your problem? I don't think that:
>>> > > > >  https://cran.r-project.org/web/packages/cleangeo/index.html
>>> > > > >  does this, as it seems to try to repair broken geometries.
>>> > > > >  Also note that you need to specify that the area threshold is
>>> in a > >  square
>>> > >  planar metric - dropping slivers in unprojected geometries may be
>>> more
>>> > >  complicated.
>>> > > > >  Roger
>>> > > > > > > >  Does someone know a way of doing this in plain R?
>>> > > > > > >  Thanks
>>> > > > > > >          [[alternative HTML version deleted]]
>>> > > > > > >  _______________________________________________
>>> > > >  R-sig-Geo mailing list
>>> > > >  R-sig-Geo at r-project.org
>>> > > >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > > > > > > > >  --
>>> > >  Roger Bivand
>>> > >  Department of Economics, Norwegian School of Economics,
>>> > >  Helleveien 30, N-5045 Bergen, Norway.
>>> > >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> > >  e-mail: Roger.Bivand at nhh.no
>>> > > > > >
>>>
>>
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>

	[[alternative HTML version deleted]]


From kushhh4u at gmail.com  Sat Nov  7 04:11:34 2015
From: kushhh4u at gmail.com (Soumen Dey)
Date: Sat, 7 Nov 2015 08:41:34 +0530
Subject: [R-sig-Geo] Problem in reading .grd file using raster package
Message-ID: <CAFezJstzkz3R=oJaHTW68vbnTSo+oPBnC=hOPcZoPXF5pwH8Bw@mail.gmail.com>

Hi all,

I have a .grd file on rainfall data (sharing the file link below). It
is a Geosoft
grid format file. The following error I encountered when I tried to read
that using 'raster' package.


> require(raster)
Loading required package: raster
Loading required package: sp

> x<-raster("rf_1984.grd") Error in .local(.Object, ...) : `C:\Users\Soumen
Dey\Desktop\rf_1984.grd' not recognised as a supported file format. Error
in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer", :
Cannot create a RasterLayer object from this file.


Can anybody can give any suggestions regarding this and help me reading
this file ?

https://drive.google.com/file/d/0B3Mnscd1GGfkd2JkNzk4ODE0ZEE/view?usp=sharing

Thanks for your time.

Soumen

	[[alternative HTML version deleted]]


From strimas at zoology.ubc.ca  Sat Nov  7 04:14:05 2015
From: strimas at zoology.ubc.ca (Matt Strimas-Mackey)
Date: Fri, 6 Nov 2015 19:14:05 -0800
Subject: [R-sig-Geo] gUnaryUnion Not Dissolving Correctly
In-Reply-To: <alpine.LFD.2.20.1511061519110.26065@reclus.nhh.no>
References: <CAHb9yCD7xeqwRt3bf-ABrSL2d9hy78b1Kh8iVkA9k60eoOvh=g@mail.gmail.com>
	<alpine.LFD.2.20.1511040801520.15125@reclus.nhh.no>
	<CAAcGz98bZ0Szb96173p5_9EH1fvA80MzUd=XjtxruG039rx=Lw@mail.gmail.com>
	<alpine.LFD.2.20.1511041442510.16608@reclus.nhh.no>
	<CAAcGz990qS1RE6KLkYxp6RYtykMH0EhyTjs2cPavY+RSCYc5xA@mail.gmail.com>
	<CAHb9yCCy2x8m0hft3w9PsehhWJ2Sm=W_y4ynPSTbwBq8YPv5-w@mail.gmail.com>
	<alpine.LFD.2.20.1511041751260.14527@reclus.nhh.no>
	<CAHb9yCCjxQyi3WmOVh2NZzaYA1Kvh2eKtN79Sncd3dz0=rPo8w@mail.gmail.com>
	<alpine.LFD.2.20.1511050737400.25686@reclus.nhh.no>
	<alpine.LFD.2.20.1511051138000.27962@reclus.nhh.no>
	<CAHb9yCB_sA4Zqdvca-Y=pWY4G3eQR0pZ=L=dKWsMf01KVkoJzA@mail.gmail.com>
	<alpine.LFD.2.20.1511061519110.26065@reclus.nhh.no>
Message-ID: <CAHb9yCBZ3_MNoHMYEL2L+Q6jEK4n3nPGVxvKWyJyEKM6N-_kaQ@mail.gmail.com>

I've rewritten the script as an RMarkdown document and posted it on github:
https://github.com/mstrimas/rgeos-scale
The rendered html is here:
https://htmlpreview.github.io/?https://github.com/mstrimas/rgeos-scale/blob/master/rgeos-scale.html

If you or Colin Rundel want to modify this or use it in any way feel
free. It would be great if it helped clarify some of these issues for
others.

M

On Fri, Nov 6, 2015 at 6:29 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> Matt:
>
> Thanks very much for this. I think that it would make an excellent vignette
> for rgeos, maybe you could consider using Markdown on your existing script
> to explain to the reader what they might expect? I'd also bring in Colin
> Rundel, as it was his insight that uncovered the scale "can of worms" five
> years ago, if you would like to go ahead.
>
> Maybe also use maptools::elide methods instead of shift_poly() - maptools is
> Suggests: in rgeos, so is assumed to be able to be available (conditionally)
> when the package is built, installed and checked.
>
> Actually, this is somewhat like a spatial version of FAQ 7.31:
>
> https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
>
> Best wishes,
>
> Roger
>
>
> On Fri, 6 Nov 2015, Matt Strimas-Mackey wrote:
>
>> Thanks for explaining this in such detail! I have a greater
>> appreciation for the importance of thinking about these topological
>> issues and for the role machine precision plays.
>>
>> I constructed a series of simple examples to demonstrate to myself how
>> these sorts of problems arise and how setScale,
>> set_RGEOS_polyThreshold, set_RGEOS_dropSlivers, and
>> set_RGEOS_warnSlivers work. In case someone else stumbles on this
>> thread looking for similar clarification, I've pasted these examples
>> below, and they also appear in this gist:
>> https://gist.github.com/mstrimas/1b4a4b93a9d4a158bce4
>>
>> library(sp)
>> library(raster)
>> library(rgeos)
>> set_RGEOS_polyThreshold(0)
>> set_RGEOS_warnSlivers(TRUE)
>> set_RGEOS_dropSlivers(FALSE)
>>
>> # function to rigidly shift polygon
>> # only works for simple polygon objects with a single polygon
>> shift_poly <- function(p, x, y) {
>>  p at polygons[[1]]@Polygons[[1]]@coords[,'x'] <-
>>    p at polygons[[1]]@Polygons[[1]]@coords[,'x'] + x
>>  p at polygons[[1]]@Polygons[[1]]@coords[,'y'] <-
>>    p at polygons[[1]]@Polygons[[1]]@coords[,'y'] + y
>>  row.names(p) <- paste0('shifted', row.names(p))
>>  return(p)
>> }
>>
>> p1 <- readWKT("POLYGON((0 0,0 1,1 1,1 0,0 0))")
>> row.names(p1) <- '1'
>> p2 <- readWKT("POLYGON((1 0,1 1,2 1,2 0,1 0))")
>> row.names(p2) <- '2'
>>
>> plot(rbind(p1, p2))
>> plot(shift_poly(p2, -0.5, 0.1), border='orange', add=T, lty=2, lwd=1)
>>
>> # default scale of 10^8
>> # behaviour of topology operations depends on scale!
>> setScale(1e8)
>> # shift horizontally by small amount so no longer touching
>> plot(gUnion(p1, shift_poly(p2, 1e-1, 0)))
>> plot(gUnion(p1, shift_poly(p2, 1e-8, 0)))
>> plot(gUnion(p1, shift_poly(p2, 1e-9, 0)))
>>
>> gIntersects(p1, p2)
>> gIntersects(p1, shift_poly(p2, 1e-1, 0))
>> gIntersects(p1, shift_poly(p2, 1e-8, 0))
>> gIntersects(p1, shift_poly(p2, 1e-9, 0))
>> # polygons with coordinates different by less that the scale set by
>> setScale()
>> # are considered to intersect and are merge together by union operations
>>
>> # p1 and p2 share a boundary exactly so the intersection of the 2 is a
>> line
>> class(gIntersection(p1, p2))
>> # shift right polygon horizontally slightly to it is just overlapping or
>> just
>> # separated from the left polygon and consider the results
>> gIntersection(p1, shift_poly(p2, -1e-9, 0)) # overlap > scale => polygon
>> gIntersection(p1, shift_poly(p2, -1e-8, 0)) # overlap < scale => line
>> gIntersection(p1, p2) # exactly touching => line
>> gIntersection(p1, shift_poly(p2, 1e-9, 0)) # separation < scale => line
>> gIntersection(p1, shift_poly(p2, 1e-8, 0)) # separation > scale => NULL
>>
>> # lower scale to 10^4
>> setScale(1e4)
>> plot(gUnion(p1, shift_poly(p2, 1e-1, 0)))
>> plot(gUnion(p1, shift_poly(p2, 1e-4, 0)))
>> plot(gUnion(p1, shift_poly(p2, 1e-5, 0)))
>>
>> gIntersects(p1, p2)
>> gIntersects(p1, shift_poly(p2, 1e-1, 0))
>> gIntersects(p1, shift_poly(p2, 1e-4, 0))
>> gIntersects(p1, shift_poly(p2, 1e-5, 0))
>>
>> gIntersection(p1, shift_poly(p2, -1e-4, 0)) # overlap > scale => polygon
>> gIntersection(p1, shift_poly(p2, -1e-5, 0)) # overlap < scale => line
>> gIntersection(p1, p2) # exactly touching => line
>> gIntersection(p1, shift_poly(p2, 1e-5, 0)) # separation < scale => line
>> gIntersection(p1, shift_poly(p2, 1e-4, 0)) # separation > scale => NULL
>>
>>
>> # consider the effect of setting polyThreshold and turning on sliver
>> warning
>> # this will identify slivers resulting from topology operations
>> setScale(1e4)
>> set_RGEOS_polyThreshold(1e-2)
>> set_RGEOS_warnSlivers(TRUE)
>> # shift horizontally by increasing amount so just overlapping
>> gi <- gIntersection(p1, shift_poly(p2, -1e-5, 0))
>> class(gi) # overlap < scale => line, i.e. assumes just touching
>> # warnings raised in next 2 cases because:
>> #   a. overlap > scale => polygon on intersection
>> #   b. resulting polygon area < polyThreshold => sliver
>> gIntersection(p1, shift_poly(p2, -1e-4, 0))
>> gIntersection(p1, shift_poly(p2, -1e-3, 0))
>> # warnings raised in next 2 cases because:
>> #   a. overlap > scale => polygon on intersection
>> #   b. resulting polygon area > polyThreshold => not a sliver
>> gIntersection(p1, shift_poly(p2, -1e-2, 0))
>> gIntersection(p1, shift_poly(p2, -1e-1, 0))
>>
>> # with a lower threshold
>> set_RGEOS_polyThreshold(1e-3)
>> # this still raises a warning
>> gIntersection(p1, shift_poly(p2, -1e-4, 0))
>> # but this doesn't since resulting polygon is at the threshold now
>> gIntersection(p1, shift_poly(p2, -1e-3, 0))
>>
>> # not that it isn't the linear overlap that triggers the warning, it is
>> that the
>> # area of the resulting polygons are below the threshold
>> # no warning
>> gi1 <- gIntersection(p1, shift_poly(p2, -1e-3, 0))
>> # now a warning is raised because a slight shift in the y direction has
>> caused
>> # the polygons the resulting polygon to be just less than the 1e-3
>> threshold
>> gi2 <- gIntersection(p1, shift_poly(p2, -1e-3, 1e-3))
>> gArea(gi1) / get_RGEOS_polyThreshold()
>> gArea(gi2) / get_RGEOS_polyThreshold()
>>
>> # rgeos can also be set to automatically remove these slivers
>> class(gIntersection(p1, shift_poly(p2, -1e-4, 0))) # SpaitalPolygons
>> set_RGEOS_dropSlivers(TRUE)
>> class(gIntersection(p1, shift_poly(p2, -1e-4, 0))) # NULL
>> set_RGEOS_dropSlivers(FALSE)
>>
>> # slivers can also be generated as a result of union operations
>> setScale(1e4)
>> set_RGEOS_polyThreshold(1e-2)
>> set_RGEOS_warnSlivers(TRUE)
>> set_RGEOS_dropSlivers(FALSE)
>>
>> p3 <- readWKT("POLYGON((0 1,0 2,2 2,2 1,0 1))")
>> row.names(p3) <- '3'
>> p4 <- readWKT("POLYGON((0 -1,0 0,2 0,2 -1,0 -1))")
>> row.names(p4) <- '4'
>> plot(rbind(p1, p3, p4))
>> plot(p2, add=T, col='red')
>>
>> # offset the middle right (i.e. red) square slightly to the right
>> # not picked up since middle edge misalignment is < scale
>> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-5, 0))
>> plot(gUnaryUnion(pp))
>> # misalignment picked up since = scale => a very narrow hole in center
>> # warning raised because hole area is < polyThreshold
>> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-4, 0))
>> plot(gUnaryUnion(pp))
>> # misalignment picked up since = scale => a very narrow hole in center
>> # warning not raised because hole area is > polyThreshold
>> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-2, 0))
>> plot(gUnaryUnion(pp))
>> # the fact that this is a hole and not a vertical line becomes apparent
>> when
>> # the shift is bigger
>> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-1, 0))
>> plot(gUnaryUnion(pp))
>> # finally, set_RGEOS_dropSlivers can be used to remove these slivers
>> # and fix the topology
>> set_RGEOS_dropSlivers(TRUE)
>> pp <- rbind(p1, p3, p4, shift_poly(p2, 1e-4, 0))
>> plot(gUnaryUnion(pp))
>> set_RGEOS_dropSlivers(FALSE)
>>
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>


From tim.appelhans at gmail.com  Sat Nov  7 10:09:52 2015
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Sat, 7 Nov 2015 10:09:52 +0100
Subject: [R-sig-Geo] Problem in reading .grd file using raster package
In-Reply-To: <CAFezJstzkz3R=oJaHTW68vbnTSo+oPBnC=hOPcZoPXF5pwH8Bw@mail.gmail.com>
References: <CAFezJstzkz3R=oJaHTW68vbnTSo+oPBnC=hOPcZoPXF5pwH8Bw@mail.gmail.com>
Message-ID: <563DBFE0.1030707@gmail.com>

Morning,
a quick google search "geosoft read in r" returns this mailing list 
conversation from 2.5 years ago

http://r-sig-geo.2731867.n2.nabble.com/reading-grd-files-td7583427.html


Tim

On 07.11.2015 04:11, Soumen Dey wrote:
> Hi all,
>
> I have a .grd file on rainfall data (sharing the file link below). It
> is a Geosoft
> grid format file. The following error I encountered when I tried to read
> that using 'raster' package.
>
>
>> require(raster)
> Loading required package: raster
> Loading required package: sp
>
>> x<-raster("rf_1984.grd") Error in .local(.Object, ...) : `C:\Users\Soumen
> Dey\Desktop\rf_1984.grd' not recognised as a supported file format. Error
> in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer", :
> Cannot create a RasterLayer object from this file.
>
>
> Can anybody can give any suggestions regarding this and help me reading
> this file ?
>
> https://drive.google.com/file/d/0B3Mnscd1GGfkd2JkNzk4ODE0ZEE/view?usp=sharing
>
> Thanks for your time.
>
> Soumen
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
Raum 00A08
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From kushhh4u at gmail.com  Sat Nov  7 10:17:12 2015
From: kushhh4u at gmail.com (Soumen Dey)
Date: Sat, 7 Nov 2015 14:47:12 +0530
Subject: [R-sig-Geo] Problem in reading .grd file using raster package
In-Reply-To: <563DBFE0.1030707@gmail.com>
References: <CAFezJstzkz3R=oJaHTW68vbnTSo+oPBnC=hOPcZoPXF5pwH8Bw@mail.gmail.com>
	<563DBFE0.1030707@gmail.com>
Message-ID: <CAFezJstzFK10OmcmYNGKFQemNJwcsOmNCkVYuUi1DiXWiwu=Sg@mail.gmail.com>

Hi Tim,

I saw that conversation. Using montage viewer (as suggested by Barry) I
couldn't convert into an .flt file. Some error occurred. The montage viewer
does not specify what error initiated it. But in anyway raster should read
a .grd file. But in this case it isn't.

Soumen

On Sat, Nov 7, 2015 at 2:39 PM, Tim Appelhans <tim.appelhans at gmail.com>
wrote:

> Morning,
> a quick google search "geosoft read in r" returns this mailing list
> conversation from 2.5 years ago
>
> http://r-sig-geo.2731867.n2.nabble.com/reading-grd-files-td7583427.html
>
>
> Tim
>
>
> On 07.11.2015 04:11, Soumen Dey wrote:
>
>> Hi all,
>>
>> I have a .grd file on rainfall data (sharing the file link below). It
>> is a Geosoft
>> grid format file. The following error I encountered when I tried to read
>> that using 'raster' package.
>>
>>
>> require(raster)
>>>
>> Loading required package: raster
>> Loading required package: sp
>>
>> x<-raster("rf_1984.grd") Error in .local(.Object, ...) : `C:\Users\Soumen
>>>
>> Dey\Desktop\rf_1984.grd' not recognised as a supported file format. Error
>> in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer", :
>> Cannot create a RasterLayer object from this file.
>>
>>
>> Can anybody can give any suggestions regarding this and help me reading
>> this file ?
>>
>>
>> https://drive.google.com/file/d/0B3Mnscd1GGfkd2JkNzk4ODE0ZEE/view?usp=sharing
>>
>> Thanks for your time.
>>
>> Soumen
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> #####################################
> Tim Appelhans
> Department of Geography
> Environmental Informatics
> Philipps Universit?t Marburg
> Deutschhausstra?e 12
> Raum 00A08
> 35032 Marburg (Paketpost: 35037 Marburg)
> Germany
>
> Tel +49 (0) 6421 28-25957
>
> http://environmentalinformatics-marburg.de/
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From tim.appelhans at gmail.com  Sat Nov  7 10:21:27 2015
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Sat, 7 Nov 2015 10:21:27 +0100
Subject: [R-sig-Geo] Problem in reading .grd file using raster package
In-Reply-To: <CAFezJstzFK10OmcmYNGKFQemNJwcsOmNCkVYuUi1DiXWiwu=Sg@mail.gmail.com>
References: <CAFezJstzkz3R=oJaHTW68vbnTSo+oPBnC=hOPcZoPXF5pwH8Bw@mail.gmail.com>
	<563DBFE0.1030707@gmail.com>
	<CAFezJstzFK10OmcmYNGKFQemNJwcsOmNCkVYuUi1DiXWiwu=Sg@mail.gmail.com>
Message-ID: <563DC297.3030909@gmail.com>

Soumen,
ratser uses .grd (+.gri) file endings for it's own file format. That has 
nothing to do with Geosoft .grd files, apart from the fact that the file 
endings are identical. My guess is if gdal is not able to read it, you 
will still need to convert it somehow before getting it into R.

Tim

On 07.11.2015 10:17, Soumen Dey wrote:
> Hi Tim,
>
> I saw that conversation. Using montage viewer (as suggested by Barry) 
> I couldn't convert into an .flt file. Some error occurred. The montage 
> viewer does not specify what error initiated it. But in anyway raster 
> should read a .grd file. But in this case it isn't.
>
> Soumen
>
> On Sat, Nov 7, 2015 at 2:39 PM, Tim Appelhans <tim.appelhans at gmail.com 
> <mailto:tim.appelhans at gmail.com>> wrote:
>
>     Morning,
>     a quick google search "geosoft read in r" returns this mailing
>     list conversation from 2.5 years ago
>
>     http://r-sig-geo.2731867.n2.nabble.com/reading-grd-files-td7583427.html
>
>
>     Tim
>
>
>     On 07.11.2015 04:11, Soumen Dey wrote:
>
>         Hi all,
>
>         I have a .grd file on rainfall data (sharing the file link
>         below). It
>         is a Geosoft
>         grid format file. The following error I encountered when I
>         tried to read
>         that using 'raster' package.
>
>
>             require(raster)
>
>         Loading required package: raster
>         Loading required package: sp
>
>             x<-raster("rf_1984.grd") Error in .local(.Object, ...) :
>             `C:\Users\Soumen
>
>         Dey\Desktop\rf_1984.grd' not recognised as a supported file
>         format. Error
>         in .rasterObjectFromFile(x, band = band, objecttype =
>         "RasterLayer", :
>         Cannot create a RasterLayer object from this file.
>
>
>         Can anybody can give any suggestions regarding this and help
>         me reading
>         this file ?
>
>         https://drive.google.com/file/d/0B3Mnscd1GGfkd2JkNzk4ODE0ZEE/view?usp=sharing
>
>         Thanks for your time.
>
>         Soumen
>
>                 [[alternative HTML version deleted]]
>
>         _______________________________________________
>         R-sig-Geo mailing list
>         R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>         https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>     -- 
>     #####################################
>     Tim Appelhans
>     Department of Geography
>     Environmental Informatics
>     Philipps Universit?t Marburg
>     Deutschhausstra?e 12
>     Raum 00A08
>     35032 Marburg (Paketpost: 35037 Marburg)
>     Germany
>
>     Tel +49 (0) 6421 28-25957
>
>     http://environmentalinformatics-marburg.de/
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
Raum 00A08
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


	[[alternative HTML version deleted]]


From kushhh4u at gmail.com  Sat Nov  7 11:24:08 2015
From: kushhh4u at gmail.com (Soumen Dey)
Date: Sat, 7 Nov 2015 15:54:08 +0530
Subject: [R-sig-Geo] Problem in reading .grd file using raster package
In-Reply-To: <563DC297.3030909@gmail.com>
References: <CAFezJstzkz3R=oJaHTW68vbnTSo+oPBnC=hOPcZoPXF5pwH8Bw@mail.gmail.com>
	<563DBFE0.1030707@gmail.com>
	<CAFezJstzFK10OmcmYNGKFQemNJwcsOmNCkVYuUi1DiXWiwu=Sg@mail.gmail.com>
	<563DC297.3030909@gmail.com>
Message-ID: <CAFezJsu6BdptHrUMA4tae7Wi6+LPELAviVhbN6gvS4pHGkkGbg@mail.gmail.com>

Tim,
I really appreciate for the clarification about the .grd file encoding. I
will try to convert it somehow to .flt or something else. If you find
anything useful kindly pass through.

Soumen

On Sat, Nov 7, 2015 at 2:51 PM, Tim Appelhans <tim.appelhans at gmail.com>
wrote:

> Soumen,
> ratser uses .grd (+.gri) file endings for it's own file format. That has
> nothing to do with Geosoft .grd files, apart from the fact that the file
> endings are identical. My guess is if gdal is not able to read it, you will
> still need to convert it somehow before getting it into R.
>
> Tim
>
>
> On 07.11.2015 10:17, Soumen Dey wrote:
>
> Hi Tim,
>
> I saw that conversation. Using montage viewer (as suggested by Barry) I
> couldn't convert into an .flt file. Some error occurred. The montage viewer
> does not specify what error initiated it. But in anyway raster should read
> a .grd file. But in this case it isn't.
>
> Soumen
>
> On Sat, Nov 7, 2015 at 2:39 PM, Tim Appelhans <tim.appelhans at gmail.com>
> wrote:
>
>> Morning,
>> a quick google search "geosoft read in r" returns this mailing list
>> conversation from 2.5 years ago
>>
>> http://r-sig-geo.2731867.n2.nabble.com/reading-grd-files-td7583427.html
>>
>>
>> Tim
>>
>>
>> On 07.11.2015 04:11, Soumen Dey wrote:
>>
>>> Hi all,
>>>
>>> I have a .grd file on rainfall data (sharing the file link below). It
>>> is a Geosoft
>>> grid format file. The following error I encountered when I tried to read
>>> that using 'raster' package.
>>>
>>>
>>> require(raster)
>>>>
>>> Loading required package: raster
>>> Loading required package: sp
>>>
>>> x<-raster("rf_1984.grd") Error in .local(.Object, ...) : `C:\Users\Soumen
>>>>
>>> Dey\Desktop\rf_1984.grd' not recognised as a supported file format. Error
>>> in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer", :
>>> Cannot create a RasterLayer object from this file.
>>>
>>>
>>> Can anybody can give any suggestions regarding this and help me reading
>>> this file ?
>>>
>>>
>>> https://drive.google.com/file/d/0B3Mnscd1GGfkd2JkNzk4ODE0ZEE/view?usp=sharing
>>>
>>> Thanks for your time.
>>>
>>> Soumen
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> #####################################
>> Tim Appelhans
>> Department of Geography
>> Environmental Informatics
>> Philipps Universit?t Marburg
>> Deutschhausstra?e 12
>> Raum 00A08
>> 35032 Marburg (Paketpost: 35037 Marburg)
>> Germany
>>
>> Tel +49 (0) 6421 28-25957
>>
>> http://environmentalinformatics-marburg.de/
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
> --
> #####################################
> Tim Appelhans
> Department of Geography
> Environmental Informatics
> Philipps Universit?t Marburg
> Deutschhausstra?e 12
> Raum 00A08
> 35032 Marburg (Paketpost: 35037 Marburg)
> Germany
>
> Tel +49 (0) 6421 28-25957
> http://environmentalinformatics-marburg.de/
>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Sat Nov  7 16:09:47 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 7 Nov 2015 16:09:47 +0100
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <CANK5cGwv7w7ODmxhYB2pTA_cABWLXUwkyYPtPe9c7z7066U-Vw@mail.gmail.com>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
	<alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
	<alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>
	<CANK5cGwv7w7ODmxhYB2pTA_cABWLXUwkyYPtPe9c7z7066U-Vw@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511071556270.21395@reclus.nhh.no>

On Sat, 7 Nov 2015, Eduardo Diez wrote:

> Roger,
> Following this last approach strange things happen: the sliver polygons
> that are fully inside another one get "merged" with the larger; the ones
> that have no contact with the exterior but share boundaries with two or
> more polygons get deleted and a hole left behind; the ones in contact with
> the exterior get deleted.

It is important to actually find out what GRASS v.clean intends to do. I 
think that it is meant to remove precision and digitizing artefacts, 
really.

> This is what i tried. As the polygons were projected i used values
> in squared meters for the set_RGEOS_polyThreshold function. I think values
> of around 1e-2 are more appropriate for Spatial* objects in GCS.
>

No, the use of 1e-2 was for projected coordinates, and slivers were very, 
very thin polygons (slivers) created by coordinate precision issues (with 
areas o ~ 1e-5 m2).

So the underlying question is why you want to remove non-sliver geometries 
(that is geometries that do create visual clutter, but which are not 
caused by coordinate precision issues). In fact, you are probably actually 
trying to aggregate Polygons objects - those which have data attributes, 
with neighbouring but larger polygons. You then need to choose (the 
algorithms could, but you need to specify) which Polygons objects are to 
be aggregated first, and then run gUnaryUnion() to merge the geometries, 
then aggregate the attribute data, and finally remove any slivers that may 
be present.

You also seem to have many geometries of 20.169 m2 in area, or multiples 
of this, presumably created by rasterToPolygons(). They are likely 
isolated single pixels of another value in raster 1. Could you use a focal 
method in raster to "smooth" them out first? What are the statistical 
properties of the "smoothed" patches - they will no longer be as 
homogeneous as they were before - does this matter?

Roger

>> pol1 <- rasterToPolygons(raster1, dissolve = T)
>> pol2 <- createSPComment(pol1)
>> set_RGEOS_polyThreshold(3000) # for example
>> set_RGEOS_warnSlivers(T)
>> set_RGEOS_dropSlivers(T)
>> t1 <- gBuffer(pol2, byid = T, width = 0)
> There were 50 or more warnings (use warnings() to see the first 50)
>> warnings()
> Warning messages:
> 1: In gBuffer(pol2, byid = T, width = 0) : 1: Polygon object 0 area 726.084
> 2: In gBuffer(pol2, byid = T, width = 0) : 2: Polygon object 1 area 20.169
> 3: In gBuffer(pol2, byid = T, width = 0) : 3: Polygon object 2 area 20.169
> 4: In gBuffer(pol2, byid = T, width = 0) : 4: Polygon object 3 area 20.169
> 5: In gBuffer(pol2, byid = T, width = 0) : 5: Polygon object 4 area 20.169
> 6: In gBuffer(pol2, byid = T, width = 0) : 6: Polygon object 5 area 20.169
> 7: In gBuffer(pol2, byid = T, width = 0) : 7: Polygon object 6 area 80.676
> 8: In gBuffer(pol2, byid = T, width = 0) : 8: Polygon object 7 area 20.169
> 9: In gBuffer(pol2, byid = T, width = 0) : 9: Polygon object 8 area 20.169
> 10: In gBuffer(pol2, byid = T, width = 0) : 10: Polygon object 9 area 20.169
> 11: In gBuffer(pol2, byid = T, width = 0) : 11: Polygon object 10 area
> 2581.63
> 12: In gBuffer(pol2, byid = T, width = 0) : 12: Polygon object 11 area
> 40.338
> 13: In gBuffer(pol2, byid = T, width = 0) : 13: Polygon object 12 area
> 20.169
> 14: In gBuffer(pol2, byid = T, width = 0) : 14: Polygon object 14 area 1432
> 15: In gBuffer(pol2, byid = T, width = 0) : 15: Polygon object 15 area
> 40.338
> 16: In gBuffer(pol2, byid = T, width = 0) : 16: Polygon object 16 area
> 20.169
> 17: In gBuffer(pol2, byid = T, width = 0) : 17: Polygon object 17 area
> 20.169
> 18: In gBuffer(pol2, byid = T, width = 0) : 18: Polygon object 18 area
> 20.169
> 19: In gBuffer(pol2, byid = T, width = 0) : 19: Polygon object 19 area
> 80.676
> 20: In gBuffer(pol2, byid = T, width = 0) : 20: Polygon object 21 area
> 20.169
> 21: In gBuffer(pol2, byid = T, width = 0) : 21: Polygon object 22 area
> 1230.31
> 22: In gBuffer(pol2, byid = T, width = 0) : 22: Polygon object 23 area
> 20.169
> 23: In gBuffer(pol2, byid = T, width = 0) : 23: Polygon object 25 area
> 20.169
> 24: In gBuffer(pol2, byid = T, width = 0) : 24: Polygon object 26 area
> 20.169
> 25: In gBuffer(pol2, byid = T, width = 0) : 25: Polygon object 27 area
> 564.732
> 26: In gBuffer(pol2, byid = T, width = 0) : 26: Polygon object 28 area
> 40.338
> 27: In gBuffer(pol2, byid = T, width = 0) : 27: Polygon object 30 area
> 504.225
> 28: In gBuffer(pol2, byid = T, width = 0) : 28: Polygon object 31 area
> 605.07
> 29: In gBuffer(pol2, byid = T, width = 0) : 29: Polygon object 33 area
> 20.169
> 30: In gBuffer(pol2, byid = T, width = 0) : 30: Polygon object 34 area
> 20.169
> 31: In gBuffer(pol2, byid = T, width = 0) : 31: Polygon object 35 area
> 1210.14
> 32: In gBuffer(pol2, byid = T, width = 0) : 32: Polygon object 36 area
> 20.169
> 33: In gBuffer(pol2, byid = T, width = 0) : 33: Polygon object 37 area
> 685.746
> 34: In gBuffer(pol2, byid = T, width = 0) : 34: Polygon object 38 area
> 40.338
> 35: In gBuffer(pol2, byid = T, width = 0) : 35: Polygon object 39 area
> 20.169
> 36: In gBuffer(pol2, byid = T, width = 0) : 36: Polygon object 40 area
> 20.169
> 37: In gBuffer(pol2, byid = T, width = 0) : 37: Polygon object 41 area
> 80.676
> 38: In gBuffer(pol2, byid = T, width = 0) : 38: Polygon object 42 area
> 20.169
> 39: In gBuffer(pol2, byid = T, width = 0) : 39: Polygon object 43 area
> 625.239
> 40: In gBuffer(pol2, byid = T, width = 0) : 40: Polygon object 44 area
> 20.169
> 41: In gBuffer(pol2, byid = T, width = 0) : 41: Polygon object 46 area
> 262.197
> 42: In gBuffer(pol2, byid = T, width = 0) : 42: Polygon object 47 area
> 2500.96
> 43: In gBuffer(pol2, byid = T, width = 0) : 43: Polygon object 48 area
> 20.169
> 44: In gBuffer(pol2, byid = T, width = 0) : 44: Polygon object 49 area
> 40.338
> 45: In gBuffer(pol2, byid = T, width = 0) : 45: Polygon object 53 area
> 80.676
> 46: In gBuffer(pol2, byid = T, width = 0) : 46: Polygon object 56 area
> 1290.82
> 47: In gBuffer(pol2, byid = T, width = 0) : 47: Polygon object 57 area
> 2722.82
> 48: In gBuffer(pol2, byid = T, width = 0) : 48: Polygon object 59 area
> 2218.59
> 49: In gBuffer(pol2, byid = T, width = 0) : 49: Polygon object 60 area
> 40.338
> 50: In gBuffer(pol2, byid = T, width = 0) : 50: Polygon object 61 area
> 121.014
>
>> spplot(t1)
>
> Thanks, and sorry if i can't be of much help in making suggestions as i
> don't know how could this be done
>
>
> 2015-11-05 8:05 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>
>> On Wed, 4 Nov 2015, Roger Bivand wrote:
>>
>> On Wed, 4 Nov 2015, Eduardo Diez wrote:
>>>
>>>  Is there any way of doing this or should i forget it and go on using
>>>> GRASS
>>>>  through rgrass7?
>>>>
>>>
>>> I suggest working with Emmanuel Blondel (cleangeo maintainer) to extend
>>> cleangeo (also suggested in an earlier thread today, with apologies to
>>> Emmanuel for picking on him!). That package already uses rgeos, and is a
>>> logical place to put GRASS v.clean-like functionality (maybe even
>>> encapsulating using GRASs via rgrass7 and a throwaway location).
>>>
>>> At the moment it is messy, though some rgeos internals do do something
>>> like this, but it isn't exposed to users.
>>>
>>
>> A possibility is to use:
>>
>> set_RGEOS_polyThreshold(1e-2) # for example
>> set_RGEOS_warnSlivers(TRUE)
>>
>> shows the remaining slivers, and:
>>
>> set_RGEOS_dropSlivers(TRUE)
>>
>> drops them when using for example:
>>
>> t1 <- gBuffer(<your_object>, byid=TRUE, width=0)
>>>
>>
>> A buffer of zero width should not have side-effects, but your mileage may
>> vary. It will only remove slivers, not dangles. I haven't tried it when it
>> also finds a Polygons object under the threshold, which was your initial
>> problem.
>>
>> Roger
>>
>>
>>
>>> Roger
>>>
>>>
>>>>  Thanks
>>>>
>>>>  2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>>>>
>>>>>  Ok. So here's a link to a zip file that contains two shapefiles:
>>>>>  - pol_to_be_cleaned: the layer from which i'd like to remove small
>>>>>  polygons
>>>>>   - pol_cleaned: the layer cleaned with the function v.clean rmarea
>>>>>>  http://1drv.ms/1GmRWS7
>>>>>>  The threshold i used for cleaning was 3000 (meaning 3000 squared >
>>>> meters).
>>>>>>  Although i do project it before sending it to GRASS, according to
>>>> the
>>>>>  official help page it should be able to handle it:
>>>>>  "Threshold must always be in square meters, also for
>>>> latitude-longitude
>>>>>  locations or locations with units other than meters"
>>>>>>  Thanks
>>>>>>  2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>>>>  On Fri, 16 Oct 2015, Eduardo Diez wrote:
>>>>>>>>  Dear list,
>>>>>>>  I'm willing to know if any knows a way of performing tha same
>>>> thing > > >  i'm
>>>>>>>  doing through rgrass7 with GRASS when I execute the function
>>>> v.clean > > >  with
>>>>>>>  "rmarea" as the tool argument. That is:
>>>>>>>>>>  "The rmarea tool removes all areas <= thresh. The longest
>>>> boundary > > >  with
>>>>>>>  an
>>>>>>>  adjacent area is removed or all boundaries if there is no
>>>> adjacent > > >  area.
>>>>>>>  Area categories are not combined when a small area is merged with
>>>> a
>>>>>>>  larger
>>>>>>>  area."
>>>>>>>>>>  Basically i have raster of zones within a field. I convert
>>>> it to
>>>>>>>  SpatialPolygonsDataFrame and in order to leave only the more
>>>>>>>  important/meaningful ones i remove the small/sliver with this
>>>> tool. > > >  In
>>>>>>>  general it works fine but having to call an external software
>>>> with a
>>>>>>>  specific version makes the script less portable and you have to be
>>>>>>>  careful
>>>>>>>  with updates and such. Also you have to write rasters and
>>>> shapefiles > > >  back
>>>>>>>  and forth as GRASS can't work with in-memory objects.
>>>>>>>>>>>  Could you please provide an example of a built-in or
>>>> contributed data > >  set
>>>>>>  (URL, not attachment) with the slivers you mention, so that we know
>>>>>>  that we
>>>>>>  are addressing your problem? I don't think that:
>>>>>>>>  https://cran.r-project.org/web/packages/cleangeo/index.html
>>>>>>>>  does this, as it seems to try to repair broken geometries.
>>>>>>>>  Also note that you need to specify that the area threshold is
>>>> in a > >  square
>>>>>>  planar metric - dropping slivers in unprojected geometries may be
>>>> more
>>>>>>  complicated.
>>>>>>>>  Roger
>>>>>>>>>>>  Does someone know a way of doing this in plain R?
>>>>>>>>>>  Thanks
>>>>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>>>>  _______________________________________________
>>>>>>>  R-sig-Geo mailing list
>>>>>>>  R-sig-Geo at r-project.org
>>>>>>>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>>>>  --
>>>>>>  Roger Bivand
>>>>>>  Department of Economics, Norwegian School of Economics,
>>>>>>  Helleveien 30, N-5045 Bergen, Norway.
>>>>>>  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>  e-mail: Roger.Bivand at nhh.no
>>>>>>>>>
>>>>
>>>
>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Sat Nov  7 19:19:23 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 7 Nov 2015 19:19:23 +0100
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <alpine.LFD.2.20.1511071556270.21395@reclus.nhh.no>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
	<alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
	<alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>
	<CANK5cGwv7w7ODmxhYB2pTA_cABWLXUwkyYPtPe9c7z7066U-Vw@mail.gmail.com>
	<alpine.LFD.2.20.1511071556270.21395@reclus.nhh.no>
Message-ID: <alpine.LFD.2.20.1511071900560.24624@reclus.nhh.no>

On Sat, 7 Nov 2015, Roger Bivand wrote:

> On Sat, 7 Nov 2015, Eduardo Diez wrote:
>
>>  Roger,
>>  Following this last approach strange things happen: the sliver polygons
>>  that are fully inside another one get "merged" with the larger; the ones
>>  that have no contact with the exterior but share boundaries with two or
>>  more polygons get deleted and a hole left behind; the ones in contact with
>>  the exterior get deleted.
>
> It is important to actually find out what GRASS v.clean intends to do. I 
> think that it is meant to remove precision and digitizing artefacts, really.

The manual says:

"tool=rmarea

The rmarea tool removes all areas <= thresh. The longest boundary with an 
adjacent area is removed or all boundaries if there is no adjacent area. 
Area categories are not combined when a small area is merged with a larger 
area."

So to replicate v.clean tool=rmarea, you'd need to find the proportions of 
boundary lengths with neighbouring polygons in order to choose the larger 
polygon with which to merge. This cannot be done in R anyway, as the 
vector model is not topological. GRASS uses a topological model, so can 
find the boundary lengths between neighbouring polygons. Note that the 
operation overwrites the attribute values of the smaller, merged polygon 
with those of the larger.

So a workflow that would emulate this in rasterToPolygons() might be first 
to detect all patches, and for patches of fewer than 15 cells, change 
their values (categorical) to those of the majority of neighbours. Trying 
a 3x3 filter would correspond to only 9 cells, so ~ 1800 m2, and would 
also dilate or erode boundaries between larger patches, so it would be 
quite tedious and would potentially affect your inferences. You could also 
do this in GRASS, possibly using r.clump, r.mfilter and the r.li.* suite 
to find the < threshold patches. Did you use raster::clump() to generate 
raster1?

Roger

>
>>  This is what i tried. As the polygons were projected i used values
>>  in squared meters for the set_RGEOS_polyThreshold function. I think values
>>  of around 1e-2 are more appropriate for Spatial* objects in GCS.
>> 
>
> No, the use of 1e-2 was for projected coordinates, and slivers were very, 
> very thin polygons (slivers) created by coordinate precision issues (with 
> areas o ~ 1e-5 m2).
>
> So the underlying question is why you want to remove non-sliver geometries 
> (that is geometries that do create visual clutter, but which are not caused 
> by coordinate precision issues). In fact, you are probably actually trying to 
> aggregate Polygons objects - those which have data attributes, with 
> neighbouring but larger polygons. You then need to choose (the algorithms 
> could, but you need to specify) which Polygons objects are to be aggregated 
> first, and then run gUnaryUnion() to merge the geometries, then aggregate the 
> attribute data, and finally remove any slivers that may be present.
>
> You also seem to have many geometries of 20.169 m2 in area, or multiples of 
> this, presumably created by rasterToPolygons(). They are likely isolated 
> single pixels of another value in raster 1. Could you use a focal method in 
> raster to "smooth" them out first? What are the statistical properties of the 
> "smoothed" patches - they will no longer be as homogeneous as they were 
> before - does this matter?
>
> Roger
>
>> >  pol1 <- rasterToPolygons(raster1, dissolve = T)
>> >  pol2 <- createSPComment(pol1)
>> >  set_RGEOS_polyThreshold(3000) # for example
>> >  set_RGEOS_warnSlivers(T)
>> >  set_RGEOS_dropSlivers(T)
>> >  t1 <- gBuffer(pol2, byid = T, width = 0)
>>  There were 50 or more warnings (use warnings() to see the first 50)
>> >  warnings()
>>  Warning messages:
>>  1: In gBuffer(pol2, byid = T, width = 0) : 1: Polygon object 0 area
>>  726.084
>>  2: In gBuffer(pol2, byid = T, width = 0) : 2: Polygon object 1 area 20.169
>>  3: In gBuffer(pol2, byid = T, width = 0) : 3: Polygon object 2 area 20.169
>>  4: In gBuffer(pol2, byid = T, width = 0) : 4: Polygon object 3 area 20.169
>>  5: In gBuffer(pol2, byid = T, width = 0) : 5: Polygon object 4 area 20.169
>>  6: In gBuffer(pol2, byid = T, width = 0) : 6: Polygon object 5 area 20.169
>>  7: In gBuffer(pol2, byid = T, width = 0) : 7: Polygon object 6 area 80.676
>>  8: In gBuffer(pol2, byid = T, width = 0) : 8: Polygon object 7 area 20.169
>>  9: In gBuffer(pol2, byid = T, width = 0) : 9: Polygon object 8 area 20.169
>>  10: In gBuffer(pol2, byid = T, width = 0) : 10: Polygon object 9 area
>>  20.169
>>  11: In gBuffer(pol2, byid = T, width = 0) : 11: Polygon object 10 area
>>  2581.63
>>  12: In gBuffer(pol2, byid = T, width = 0) : 12: Polygon object 11 area
>>  40.338
>>  13: In gBuffer(pol2, byid = T, width = 0) : 13: Polygon object 12 area
>>  20.169
>>  14: In gBuffer(pol2, byid = T, width = 0) : 14: Polygon object 14 area
>>  1432
>>  15: In gBuffer(pol2, byid = T, width = 0) : 15: Polygon object 15 area
>>  40.338
>>  16: In gBuffer(pol2, byid = T, width = 0) : 16: Polygon object 16 area
>>  20.169
>>  17: In gBuffer(pol2, byid = T, width = 0) : 17: Polygon object 17 area
>>  20.169
>>  18: In gBuffer(pol2, byid = T, width = 0) : 18: Polygon object 18 area
>>  20.169
>>  19: In gBuffer(pol2, byid = T, width = 0) : 19: Polygon object 19 area
>>  80.676
>>  20: In gBuffer(pol2, byid = T, width = 0) : 20: Polygon object 21 area
>>  20.169
>>  21: In gBuffer(pol2, byid = T, width = 0) : 21: Polygon object 22 area
>>  1230.31
>>  22: In gBuffer(pol2, byid = T, width = 0) : 22: Polygon object 23 area
>>  20.169
>>  23: In gBuffer(pol2, byid = T, width = 0) : 23: Polygon object 25 area
>>  20.169
>>  24: In gBuffer(pol2, byid = T, width = 0) : 24: Polygon object 26 area
>>  20.169
>>  25: In gBuffer(pol2, byid = T, width = 0) : 25: Polygon object 27 area
>>  564.732
>>  26: In gBuffer(pol2, byid = T, width = 0) : 26: Polygon object 28 area
>>  40.338
>>  27: In gBuffer(pol2, byid = T, width = 0) : 27: Polygon object 30 area
>>  504.225
>>  28: In gBuffer(pol2, byid = T, width = 0) : 28: Polygon object 31 area
>>  605.07
>>  29: In gBuffer(pol2, byid = T, width = 0) : 29: Polygon object 33 area
>>  20.169
>>  30: In gBuffer(pol2, byid = T, width = 0) : 30: Polygon object 34 area
>>  20.169
>>  31: In gBuffer(pol2, byid = T, width = 0) : 31: Polygon object 35 area
>>  1210.14
>>  32: In gBuffer(pol2, byid = T, width = 0) : 32: Polygon object 36 area
>>  20.169
>>  33: In gBuffer(pol2, byid = T, width = 0) : 33: Polygon object 37 area
>>  685.746
>>  34: In gBuffer(pol2, byid = T, width = 0) : 34: Polygon object 38 area
>>  40.338
>>  35: In gBuffer(pol2, byid = T, width = 0) : 35: Polygon object 39 area
>>  20.169
>>  36: In gBuffer(pol2, byid = T, width = 0) : 36: Polygon object 40 area
>>  20.169
>>  37: In gBuffer(pol2, byid = T, width = 0) : 37: Polygon object 41 area
>>  80.676
>>  38: In gBuffer(pol2, byid = T, width = 0) : 38: Polygon object 42 area
>>  20.169
>>  39: In gBuffer(pol2, byid = T, width = 0) : 39: Polygon object 43 area
>>  625.239
>>  40: In gBuffer(pol2, byid = T, width = 0) : 40: Polygon object 44 area
>>  20.169
>>  41: In gBuffer(pol2, byid = T, width = 0) : 41: Polygon object 46 area
>>  262.197
>>  42: In gBuffer(pol2, byid = T, width = 0) : 42: Polygon object 47 area
>>  2500.96
>>  43: In gBuffer(pol2, byid = T, width = 0) : 43: Polygon object 48 area
>>  20.169
>>  44: In gBuffer(pol2, byid = T, width = 0) : 44: Polygon object 49 area
>>  40.338
>>  45: In gBuffer(pol2, byid = T, width = 0) : 45: Polygon object 53 area
>>  80.676
>>  46: In gBuffer(pol2, byid = T, width = 0) : 46: Polygon object 56 area
>>  1290.82
>>  47: In gBuffer(pol2, byid = T, width = 0) : 47: Polygon object 57 area
>>  2722.82
>>  48: In gBuffer(pol2, byid = T, width = 0) : 48: Polygon object 59 area
>>  2218.59
>>  49: In gBuffer(pol2, byid = T, width = 0) : 49: Polygon object 60 area
>>  40.338
>>  50: In gBuffer(pol2, byid = T, width = 0) : 50: Polygon object 61 area
>>  121.014
>> 
>> >  spplot(t1)
>>
>>  Thanks, and sorry if i can't be of much help in making suggestions as i
>>  don't know how could this be done
>> 
>>
>>  2015-11-05 8:05 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>> 
>> >  On Wed, 4 Nov 2015, Roger Bivand wrote:
>> > 
>> >  On Wed, 4 Nov 2015, Eduardo Diez wrote:
>> > > 
>> > >   Is there any way of doing this or should i forget it and go on using
>> > > >  GRASS
>> > > >   through rgrass7?
>> > > > 
>> > > 
>> > >  I suggest working with Emmanuel Blondel (cleangeo maintainer) to 
>> > >  extend
>> > >  cleangeo (also suggested in an earlier thread today, with apologies to
>> > >  Emmanuel for picking on him!). That package already uses rgeos, and is 
>> > >  a
>> > >  logical place to put GRASS v.clean-like functionality (maybe even
>> > >  encapsulating using GRASs via rgrass7 and a throwaway location).
>> > > 
>> > >  At the moment it is messy, though some rgeos internals do do something
>> > >  like this, but it isn't exposed to users.
>> > > 
>> > 
>> >  A possibility is to use:
>> > 
>> >  set_RGEOS_polyThreshold(1e-2) # for example
>> >  set_RGEOS_warnSlivers(TRUE)
>> > 
>> >  shows the remaining slivers, and:
>> > 
>> >  set_RGEOS_dropSlivers(TRUE)
>> > 
>> >  drops them when using for example:
>> > 
>> >  t1 <- gBuffer(<your_object>, byid=TRUE, width=0)
>> > > 
>> > 
>> >  A buffer of zero width should not have side-effects, but your mileage 
>> >  may
>> >  vary. It will only remove slivers, not dangles. I haven't tried it when 
>> >  it
>> >  also finds a Polygons object under the threshold, which was your initial
>> >  problem.
>> > 
>> >  Roger
>> > 
>> > 
>> > 
>> > >  Roger
>> > > 
>> > > 
>> > > >   Thanks
>> > > > 
>> > > >   2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>> > > > 
>> > > > >   Ok. So here's a link to a zip file that contains two shapefiles:
>> > > > >   - pol_to_be_cleaned: the layer from which i'd like to remove 
>> > > > >   small
>> > > > >   polygons
>> > > > >    - pol_cleaned: the layer cleaned with the function v.clean 
>> > > > >    rmarea
>> > > > > >   http://1drv.ms/1GmRWS7
>> > > > > >   The threshold i used for cleaning was 3000 (meaning 3000 
>> > > > > >   squared >
>> > > >  meters).
>> > > > > >   Although i do project it before sending it to GRASS, according 
>> > > > > >   to
>> > > >  the
>> > > > >   official help page it should be able to handle it:
>> > > > >   "Threshold must always be in square meters, also for
>> > > >  latitude-longitude
>> > > > >   locations or locations with units other than meters"
>> > > > > >   Thanks
>> > > > > >   2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>> > > > > > >   On Fri, 16 Oct 2015, Eduardo Diez wrote:
>> > > > > > > >   Dear list,
>> > > > > > >   I'm willing to know if any knows a way of performing tha same
>> > > > thing > > >   i'm
>> > > > > > >   doing through rgrass7 with GRASS when I execute the function
>> > > >  v.clean > > >  with
>> > > > > > >   "rmarea" as the tool argument. That is:
>> > > > > > > > > >   "The rmarea tool removes all areas <= thresh. The 
>> > > > > > > > > >   longest
>> > > > boundary > > >   with
>> > > > > > >   an
>> > > > > > >   adjacent area is removed or all boundaries if there is no
>> > > > adjacent > > >   area.
>> > > > > > >   Area categories are not combined when a small area is merged 
>> > > > > > >   with
>> > > >  a
>> > > > > > >   larger
>> > > > > > >   area."
>> > > > > > > > > >   Basically i have raster of zones within a field. I 
>> > > > > > > > > >   convert
>> > > >  it to
>> > > > > > >   SpatialPolygonsDataFrame and in order to leave only the more
>> > > > > > >   important/meaningful ones i remove the small/sliver with this
>> > > >  tool. > > >  In
>> > > > > > >   general it works fine but having to call an external software
>> > > >  with a
>> > > > > > >   specific version makes the script less portable and you have 
>> > > > > > >   to be
>> > > > > > >   careful
>> > > > > > >   with updates and such. Also you have to write rasters and
>> > > > shapefiles > > >   back
>> > > > > > >   and forth as GRASS can't work with in-memory objects.
>> > > > > > > > > > >   Could you please provide an example of a built-in or
>> > > >  contributed data > >  set
>> > > > > >   (URL, not attachment) with the slivers you mention, so that we 
>> > > > > >   know
>> > > > > >   that we
>> > > > > >   are addressing your problem? I don't think that:
>> > > > > > > >   https://cran.r-project.org/web/packages/cleangeo/index.html
>> > > > > > > >   does this, as it seems to try to repair broken geometries.
>> > > > > > > >   Also note that you need to specify that the area threshold 
>> > > > > > > >   is
>> > > >  in a > >  square
>> > > > > >   planar metric - dropping slivers in unprojected geometries may 
>> > > > > >   be
>> > > >  more
>> > > > > >   complicated.
>> > > > > > > >   Roger
>> > > > > > > > > > >   Does someone know a way of doing this in plain R?
>> > > > > > > > > >   Thanks
>> > > > > > > > > >           [[alternative HTML version deleted]]
>> > > > > > > > > >   _______________________________________________
>> > > > > > >   R-sig-Geo mailing list
>> > > > > > >   R-sig-Geo at r-project.org
>> > > > > > >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > > > > > > > > >   --
>> > > > > >   Roger Bivand
>> > > > > >   Department of Economics, Norwegian School of Economics,
>> > > > > >   Helleveien 30, N-5045 Bergen, Norway.
>> > > > > >   voice: +47 55 95 93 55; fax +47 55 95 91 00
>> > > > > >   e-mail: Roger.Bivand at nhh.no
>> > > > > > > > > 
>> > > > 
>> > > 
>> > > 
>> > > 
>> >  --
>> >  Roger Bivand
>> >  Department of Economics, Norwegian School of Economics,
>> >  Helleveien 30, N-5045 Bergen, Norway.
>> >  voice: +47 55 95 93 55; fax +47 55 95 91 00
>> >  e-mail: Roger.Bivand at nhh.no
>> > 
>> > 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From eduardodiez at gmx.com  Sat Nov  7 19:42:06 2015
From: eduardodiez at gmx.com (Eduardo Diez)
Date: Sat, 7 Nov 2015 15:42:06 -0300
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <alpine.LFD.2.20.1511071556270.21395@reclus.nhh.no>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
	<alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
	<alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>
	<CANK5cGwv7w7ODmxhYB2pTA_cABWLXUwkyYPtPe9c7z7066U-Vw@mail.gmail.com>
	<alpine.LFD.2.20.1511071556270.21395@reclus.nhh.no>
Message-ID: <CANK5cGxru5MsF74y=aWnZt7KbXuihOcZKvGrSoazb6f1RU6hLA@mail.gmail.com>

Ok, so i'm starting to see where the issues are. In the first place i
didn't fully understood what a sliver polygon was. My objective is to get
rid of polygons that didn't met my needs in terms of ability to manage them
once the analysis is complete, not the ones caused by coordinate precision
issues.

In this context get rid means merging them with the polygons with which
they share the longest boundary (basically removing the shared boundary
that separates them). That is regardless of whether they have the same
attributes or not (i don't care of the attribute because i won't be able to
handle it anyway).

The area covered by the resulting object should be the same of the original
one as no polygons get deleted, only merged with the larger ones.

The presence of single cell polygons is something with which i don't have
much problem because they all disappeared after running the GRASS tool and
is something to be expected from my workflow. I wouldn't be that
comfortable smoothing the raster because i would be messing with the
results.

One question that comes to my head is what would happen in the cases where
i have a polygon that is below the threshold, but is inside another polygon
below the threshold and these 2 inside a larger one above the threshold.
For example: with a threshold of 3000 sq m i may have a 1500 sq m polygon
inside a 2000 sq m polygon, and those inside a 4000 sq m polygon. From
experience i know that GRASS handles this cases quite well.

Thanks

2015-11-07 12:09 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:

> On Sat, 7 Nov 2015, Eduardo Diez wrote:
>
> Roger,
>> Following this last approach strange things happen: the sliver polygons
>> that are fully inside another one get "merged" with the larger; the ones
>> that have no contact with the exterior but share boundaries with two or
>> more polygons get deleted and a hole left behind; the ones in contact with
>> the exterior get deleted.
>>
>
> It is important to actually find out what GRASS v.clean intends to do. I
> think that it is meant to remove precision and digitizing artefacts, really.
>
> This is what i tried. As the polygons were projected i used values
>> in squared meters for the set_RGEOS_polyThreshold function. I think values
>> of around 1e-2 are more appropriate for Spatial* objects in GCS.
>>
>>
> No, the use of 1e-2 was for projected coordinates, and slivers were very,
> very thin polygons (slivers) created by coordinate precision issues (with
> areas o ~ 1e-5 m2).
>
> So the underlying question is why you want to remove non-sliver geometries
> (that is geometries that do create visual clutter, but which are not caused
> by coordinate precision issues). In fact, you are probably actually trying
> to aggregate Polygons objects - those which have data attributes, with
> neighbouring but larger polygons. You then need to choose (the algorithms
> could, but you need to specify) which Polygons objects are to be aggregated
> first, and then run gUnaryUnion() to merge the geometries, then aggregate
> the attribute data, and finally remove any slivers that may be present.
>
> You also seem to have many geometries of 20.169 m2 in area, or multiples
> of this, presumably created by rasterToPolygons(). They are likely isolated
> single pixels of another value in raster 1. Could you use a focal method in
> raster to "smooth" them out first? What are the statistical properties of
> the "smoothed" patches - they will no longer be as homogeneous as they were
> before - does this matter?
>
> Roger
>
>
> pol1 <- rasterToPolygons(raster1, dissolve = T)
>>> pol2 <- createSPComment(pol1)
>>> set_RGEOS_polyThreshold(3000) # for example
>>> set_RGEOS_warnSlivers(T)
>>> set_RGEOS_dropSlivers(T)
>>> t1 <- gBuffer(pol2, byid = T, width = 0)
>>>
>> There were 50 or more warnings (use warnings() to see the first 50)
>>
>>> warnings()
>>>
>> Warning messages:
>> 1: In gBuffer(pol2, byid = T, width = 0) : 1: Polygon object 0 area
>> 726.084
>> 2: In gBuffer(pol2, byid = T, width = 0) : 2: Polygon object 1 area 20.169
>> 3: In gBuffer(pol2, byid = T, width = 0) : 3: Polygon object 2 area 20.169
>> 4: In gBuffer(pol2, byid = T, width = 0) : 4: Polygon object 3 area 20.169
>> 5: In gBuffer(pol2, byid = T, width = 0) : 5: Polygon object 4 area 20.169
>> 6: In gBuffer(pol2, byid = T, width = 0) : 6: Polygon object 5 area 20.169
>> 7: In gBuffer(pol2, byid = T, width = 0) : 7: Polygon object 6 area 80.676
>> 8: In gBuffer(pol2, byid = T, width = 0) : 8: Polygon object 7 area 20.169
>> 9: In gBuffer(pol2, byid = T, width = 0) : 9: Polygon object 8 area 20.169
>> 10: In gBuffer(pol2, byid = T, width = 0) : 10: Polygon object 9 area
>> 20.169
>> 11: In gBuffer(pol2, byid = T, width = 0) : 11: Polygon object 10 area
>> 2581.63
>> 12: In gBuffer(pol2, byid = T, width = 0) : 12: Polygon object 11 area
>> 40.338
>> 13: In gBuffer(pol2, byid = T, width = 0) : 13: Polygon object 12 area
>> 20.169
>> 14: In gBuffer(pol2, byid = T, width = 0) : 14: Polygon object 14 area
>> 1432
>> 15: In gBuffer(pol2, byid = T, width = 0) : 15: Polygon object 15 area
>> 40.338
>> 16: In gBuffer(pol2, byid = T, width = 0) : 16: Polygon object 16 area
>> 20.169
>> 17: In gBuffer(pol2, byid = T, width = 0) : 17: Polygon object 17 area
>> 20.169
>> 18: In gBuffer(pol2, byid = T, width = 0) : 18: Polygon object 18 area
>> 20.169
>> 19: In gBuffer(pol2, byid = T, width = 0) : 19: Polygon object 19 area
>> 80.676
>> 20: In gBuffer(pol2, byid = T, width = 0) : 20: Polygon object 21 area
>> 20.169
>> 21: In gBuffer(pol2, byid = T, width = 0) : 21: Polygon object 22 area
>> 1230.31
>> 22: In gBuffer(pol2, byid = T, width = 0) : 22: Polygon object 23 area
>> 20.169
>> 23: In gBuffer(pol2, byid = T, width = 0) : 23: Polygon object 25 area
>> 20.169
>> 24: In gBuffer(pol2, byid = T, width = 0) : 24: Polygon object 26 area
>> 20.169
>> 25: In gBuffer(pol2, byid = T, width = 0) : 25: Polygon object 27 area
>> 564.732
>> 26: In gBuffer(pol2, byid = T, width = 0) : 26: Polygon object 28 area
>> 40.338
>> 27: In gBuffer(pol2, byid = T, width = 0) : 27: Polygon object 30 area
>> 504.225
>> 28: In gBuffer(pol2, byid = T, width = 0) : 28: Polygon object 31 area
>> 605.07
>> 29: In gBuffer(pol2, byid = T, width = 0) : 29: Polygon object 33 area
>> 20.169
>> 30: In gBuffer(pol2, byid = T, width = 0) : 30: Polygon object 34 area
>> 20.169
>> 31: In gBuffer(pol2, byid = T, width = 0) : 31: Polygon object 35 area
>> 1210.14
>> 32: In gBuffer(pol2, byid = T, width = 0) : 32: Polygon object 36 area
>> 20.169
>> 33: In gBuffer(pol2, byid = T, width = 0) : 33: Polygon object 37 area
>> 685.746
>> 34: In gBuffer(pol2, byid = T, width = 0) : 34: Polygon object 38 area
>> 40.338
>> 35: In gBuffer(pol2, byid = T, width = 0) : 35: Polygon object 39 area
>> 20.169
>> 36: In gBuffer(pol2, byid = T, width = 0) : 36: Polygon object 40 area
>> 20.169
>> 37: In gBuffer(pol2, byid = T, width = 0) : 37: Polygon object 41 area
>> 80.676
>> 38: In gBuffer(pol2, byid = T, width = 0) : 38: Polygon object 42 area
>> 20.169
>> 39: In gBuffer(pol2, byid = T, width = 0) : 39: Polygon object 43 area
>> 625.239
>> 40: In gBuffer(pol2, byid = T, width = 0) : 40: Polygon object 44 area
>> 20.169
>> 41: In gBuffer(pol2, byid = T, width = 0) : 41: Polygon object 46 area
>> 262.197
>> 42: In gBuffer(pol2, byid = T, width = 0) : 42: Polygon object 47 area
>> 2500.96
>> 43: In gBuffer(pol2, byid = T, width = 0) : 43: Polygon object 48 area
>> 20.169
>> 44: In gBuffer(pol2, byid = T, width = 0) : 44: Polygon object 49 area
>> 40.338
>> 45: In gBuffer(pol2, byid = T, width = 0) : 45: Polygon object 53 area
>> 80.676
>> 46: In gBuffer(pol2, byid = T, width = 0) : 46: Polygon object 56 area
>> 1290.82
>> 47: In gBuffer(pol2, byid = T, width = 0) : 47: Polygon object 57 area
>> 2722.82
>> 48: In gBuffer(pol2, byid = T, width = 0) : 48: Polygon object 59 area
>> 2218.59
>> 49: In gBuffer(pol2, byid = T, width = 0) : 49: Polygon object 60 area
>> 40.338
>> 50: In gBuffer(pol2, byid = T, width = 0) : 50: Polygon object 61 area
>> 121.014
>>
>> spplot(t1)
>>>
>>
>> Thanks, and sorry if i can't be of much help in making suggestions as i
>> don't know how could this be done
>>
>>
>> 2015-11-05 8:05 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>
>> On Wed, 4 Nov 2015, Roger Bivand wrote:
>>>
>>> On Wed, 4 Nov 2015, Eduardo Diez wrote:
>>>
>>>>
>>>>  Is there any way of doing this or should i forget it and go on using
>>>>
>>>>> GRASS
>>>>>  through rgrass7?
>>>>>
>>>>>
>>>> I suggest working with Emmanuel Blondel (cleangeo maintainer) to extend
>>>> cleangeo (also suggested in an earlier thread today, with apologies to
>>>> Emmanuel for picking on him!). That package already uses rgeos, and is a
>>>> logical place to put GRASS v.clean-like functionality (maybe even
>>>> encapsulating using GRASs via rgrass7 and a throwaway location).
>>>>
>>>> At the moment it is messy, though some rgeos internals do do something
>>>> like this, but it isn't exposed to users.
>>>>
>>>>
>>> A possibility is to use:
>>>
>>> set_RGEOS_polyThreshold(1e-2) # for example
>>> set_RGEOS_warnSlivers(TRUE)
>>>
>>> shows the remaining slivers, and:
>>>
>>> set_RGEOS_dropSlivers(TRUE)
>>>
>>> drops them when using for example:
>>>
>>> t1 <- gBuffer(<your_object>, byid=TRUE, width=0)
>>>
>>>>
>>>>
>>> A buffer of zero width should not have side-effects, but your mileage may
>>> vary. It will only remove slivers, not dangles. I haven't tried it when
>>> it
>>> also finds a Polygons object under the threshold, which was your initial
>>> problem.
>>>
>>> Roger
>>>
>>>
>>>
>>> Roger
>>>>
>>>>
>>>>  Thanks
>>>>>
>>>>>  2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>>>>>
>>>>>  Ok. So here's a link to a zip file that contains two shapefiles:
>>>>>>  - pol_to_be_cleaned: the layer from which i'd like to remove small
>>>>>>  polygons
>>>>>>   - pol_cleaned: the layer cleaned with the function v.clean rmarea
>>>>>>
>>>>>>>  http://1drv.ms/1GmRWS7
>>>>>>>  The threshold i used for cleaning was 3000 (meaning 3000 squared >
>>>>>>>
>>>>>> meters).
>>>>>
>>>>>>  Although i do project it before sending it to GRASS, according to
>>>>>>>
>>>>>> the
>>>>>
>>>>>>  official help page it should be able to handle it:
>>>>>>  "Threshold must always be in square meters, also for
>>>>>>
>>>>> latitude-longitude
>>>>>
>>>>>>  locations or locations with units other than meters"
>>>>>>
>>>>>>>  Thanks
>>>>>>>  2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>>>>
>>>>>>>>  On Fri, 16 Oct 2015, Eduardo Diez wrote:
>>>>>>>>
>>>>>>>>>  Dear list,
>>>>>>>>>
>>>>>>>>  I'm willing to know if any knows a way of performing tha same
>>>>>>>>
>>>>>>> thing > > >  i'm
>>>>>
>>>>>>  doing through rgrass7 with GRASS when I execute the function
>>>>>>>>
>>>>>>> v.clean > > >  with
>>>>>
>>>>>>  "rmarea" as the tool argument. That is:
>>>>>>>>
>>>>>>>>>  "The rmarea tool removes all areas <= thresh. The longest
>>>>>>>>>>>
>>>>>>>>>> boundary > > >  with
>>>>>
>>>>>>  an
>>>>>>>>  adjacent area is removed or all boundaries if there is no
>>>>>>>>
>>>>>>> adjacent > > >  area.
>>>>>
>>>>>>  Area categories are not combined when a small area is merged with
>>>>>>>>
>>>>>>> a
>>>>>
>>>>>>  larger
>>>>>>>>  area."
>>>>>>>>
>>>>>>>>>  Basically i have raster of zones within a field. I convert
>>>>>>>>>>>
>>>>>>>>>> it to
>>>>>
>>>>>>  SpatialPolygonsDataFrame and in order to leave only the more
>>>>>>>>  important/meaningful ones i remove the small/sliver with this
>>>>>>>>
>>>>>>> tool. > > >  In
>>>>>
>>>>>>  general it works fine but having to call an external software
>>>>>>>>
>>>>>>> with a
>>>>>
>>>>>>  specific version makes the script less portable and you have to be
>>>>>>>>  careful
>>>>>>>>  with updates and such. Also you have to write rasters and
>>>>>>>>
>>>>>>> shapefiles > > >  back
>>>>>
>>>>>>  and forth as GRASS can't work with in-memory objects.
>>>>>>>>
>>>>>>>>>  Could you please provide an example of a built-in or
>>>>>>>>>>>>
>>>>>>>>>>> contributed data > >  set
>>>>>
>>>>>>  (URL, not attachment) with the slivers you mention, so that we know
>>>>>>>  that we
>>>>>>>  are addressing your problem? I don't think that:
>>>>>>>
>>>>>>>>  https://cran.r-project.org/web/packages/cleangeo/index.html
>>>>>>>>>  does this, as it seems to try to repair broken geometries.
>>>>>>>>>  Also note that you need to specify that the area threshold is
>>>>>>>>>
>>>>>>>> in a > >  square
>>>>>
>>>>>>  planar metric - dropping slivers in unprojected geometries may be
>>>>>>>
>>>>>> more
>>>>>
>>>>>>  complicated.
>>>>>>>
>>>>>>>>  Roger
>>>>>>>>>
>>>>>>>>>>  Does someone know a way of doing this in plain R?
>>>>>>>>>>>>
>>>>>>>>>>>  Thanks
>>>>>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>>>>>  _______________________________________________
>>>>>>>>>>>
>>>>>>>>>>  R-sig-Geo mailing list
>>>>>>>>  R-sig-Geo at r-project.org
>>>>>>>>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>
>>>>>>>>>  --
>>>>>>>>>>>>>
>>>>>>>>>>>>  Roger Bivand
>>>>>>>  Department of Economics, Norwegian School of Economics,
>>>>>>>  Helleveien 30, N-5045 Bergen, Norway.
>>>>>>>  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>>  e-mail: Roger.Bivand at nhh.no
>>>>>>>
>>>>>>>>
>>>>>>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>> Roger Bivand
>>> Department of Economics, Norwegian School of Economics,
>>> Helleveien 30, N-5045 Bergen, Norway.
>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
>
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Sat Nov  7 20:17:53 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 7 Nov 2015 20:17:53 +0100
Subject: [R-sig-Geo] Cleaning small spatial polygons
In-Reply-To: <CANK5cGxru5MsF74y=aWnZt7KbXuihOcZKvGrSoazb6f1RU6hLA@mail.gmail.com>
References: <CANK5cGys6Ay1+WYWQfiCzyqgRHT2vw0cjEHGJRhObVhj0xym_w@mail.gmail.com>
	<alpine.LFD.2.20.1510191324520.32247@reclus.nhh.no>
	<CANK5cGz+ZuEMJJTRBfPDGx-26N0v5cbu-L8wEVRd_7n4S16QvQ@mail.gmail.com>
	<CANK5cGzKorwnXLtLd5JrsU_WTS-EA_iSBrBoK_AY_sd6s1K3mA@mail.gmail.com>
	<alpine.LFD.2.20.1511041950520.17585@reclus.nhh.no>
	<alpine.LFD.2.20.1511051201060.27962@reclus.nhh.no>
	<CANK5cGwv7w7ODmxhYB2pTA_cABWLXUwkyYPtPe9c7z7066U-Vw@mail.gmail.com>
	<alpine.LFD.2.20.1511071556270.21395@reclus.nhh.no>
	<CANK5cGxru5MsF74y=aWnZt7KbXuihOcZKvGrSoazb6f1RU6hLA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511072014570.25363@reclus.nhh.no>

On Sat, 7 Nov 2015, Eduardo Diez wrote:

> Ok, so i'm starting to see where the issues are. In the first place i
> didn't fully understood what a sliver polygon was. My objective is to get
> rid of polygons that didn't met my needs in terms of ability to manage them
> once the analysis is complete, not the ones caused by coordinate precision
> issues.
>
> In this context get rid means merging them with the polygons with which
> they share the longest boundary (basically removing the shared boundary
> that separates them). That is regardless of whether they have the same
> attributes or not (i don't care of the attribute because i won't be able to
> handle it anyway).
>
> The area covered by the resulting object should be the same of the original
> one as no polygons get deleted, only merged with the larger ones.
>
> The presence of single cell polygons is something with which i don't have
> much problem because they all disappeared after running the GRASS tool and
> is something to be expected from my workflow. I wouldn't be that
> comfortable smoothing the raster because i would be messing with the
> results.
>
> One question that comes to my head is what would happen in the cases where
> i have a polygon that is below the threshold, but is inside another polygon
> below the threshold and these 2 inside a larger one above the threshold.
> For example: with a threshold of 3000 sq m i may have a 1500 sq m polygon
> inside a 2000 sq m polygon, and those inside a 4000 sq m polygon. From
> experience i know that GRASS handles this cases quite well.

Try it and see - as far as I know, the threshold in rgeos is absolute and 
is meant for real slivers. My guess is that v.clean in GRASS is not doing 
this by design, and that the results are coincidental - it is designed to 
clean non-topological vectors.

Roger

>
> Thanks
>
> 2015-11-07 12:09 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>
>> On Sat, 7 Nov 2015, Eduardo Diez wrote:
>>
>> Roger,
>>> Following this last approach strange things happen: the sliver polygons
>>> that are fully inside another one get "merged" with the larger; the ones
>>> that have no contact with the exterior but share boundaries with two or
>>> more polygons get deleted and a hole left behind; the ones in contact with
>>> the exterior get deleted.
>>>
>>
>> It is important to actually find out what GRASS v.clean intends to do. I
>> think that it is meant to remove precision and digitizing artefacts, really.
>>
>> This is what i tried. As the polygons were projected i used values
>>> in squared meters for the set_RGEOS_polyThreshold function. I think values
>>> of around 1e-2 are more appropriate for Spatial* objects in GCS.
>>>
>>>
>> No, the use of 1e-2 was for projected coordinates, and slivers were very,
>> very thin polygons (slivers) created by coordinate precision issues (with
>> areas o ~ 1e-5 m2).
>>
>> So the underlying question is why you want to remove non-sliver geometries
>> (that is geometries that do create visual clutter, but which are not caused
>> by coordinate precision issues). In fact, you are probably actually trying
>> to aggregate Polygons objects - those which have data attributes, with
>> neighbouring but larger polygons. You then need to choose (the algorithms
>> could, but you need to specify) which Polygons objects are to be aggregated
>> first, and then run gUnaryUnion() to merge the geometries, then aggregate
>> the attribute data, and finally remove any slivers that may be present.
>>
>> You also seem to have many geometries of 20.169 m2 in area, or multiples
>> of this, presumably created by rasterToPolygons(). They are likely isolated
>> single pixels of another value in raster 1. Could you use a focal method in
>> raster to "smooth" them out first? What are the statistical properties of
>> the "smoothed" patches - they will no longer be as homogeneous as they were
>> before - does this matter?
>>
>> Roger
>>
>>
>> pol1 <- rasterToPolygons(raster1, dissolve = T)
>>>> pol2 <- createSPComment(pol1)
>>>> set_RGEOS_polyThreshold(3000) # for example
>>>> set_RGEOS_warnSlivers(T)
>>>> set_RGEOS_dropSlivers(T)
>>>> t1 <- gBuffer(pol2, byid = T, width = 0)
>>>>
>>> There were 50 or more warnings (use warnings() to see the first 50)
>>>
>>>> warnings()
>>>>
>>> Warning messages:
>>> 1: In gBuffer(pol2, byid = T, width = 0) : 1: Polygon object 0 area
>>> 726.084
>>> 2: In gBuffer(pol2, byid = T, width = 0) : 2: Polygon object 1 area 20.169
>>> 3: In gBuffer(pol2, byid = T, width = 0) : 3: Polygon object 2 area 20.169
>>> 4: In gBuffer(pol2, byid = T, width = 0) : 4: Polygon object 3 area 20.169
>>> 5: In gBuffer(pol2, byid = T, width = 0) : 5: Polygon object 4 area 20.169
>>> 6: In gBuffer(pol2, byid = T, width = 0) : 6: Polygon object 5 area 20.169
>>> 7: In gBuffer(pol2, byid = T, width = 0) : 7: Polygon object 6 area 80.676
>>> 8: In gBuffer(pol2, byid = T, width = 0) : 8: Polygon object 7 area 20.169
>>> 9: In gBuffer(pol2, byid = T, width = 0) : 9: Polygon object 8 area 20.169
>>> 10: In gBuffer(pol2, byid = T, width = 0) : 10: Polygon object 9 area
>>> 20.169
>>> 11: In gBuffer(pol2, byid = T, width = 0) : 11: Polygon object 10 area
>>> 2581.63
>>> 12: In gBuffer(pol2, byid = T, width = 0) : 12: Polygon object 11 area
>>> 40.338
>>> 13: In gBuffer(pol2, byid = T, width = 0) : 13: Polygon object 12 area
>>> 20.169
>>> 14: In gBuffer(pol2, byid = T, width = 0) : 14: Polygon object 14 area
>>> 1432
>>> 15: In gBuffer(pol2, byid = T, width = 0) : 15: Polygon object 15 area
>>> 40.338
>>> 16: In gBuffer(pol2, byid = T, width = 0) : 16: Polygon object 16 area
>>> 20.169
>>> 17: In gBuffer(pol2, byid = T, width = 0) : 17: Polygon object 17 area
>>> 20.169
>>> 18: In gBuffer(pol2, byid = T, width = 0) : 18: Polygon object 18 area
>>> 20.169
>>> 19: In gBuffer(pol2, byid = T, width = 0) : 19: Polygon object 19 area
>>> 80.676
>>> 20: In gBuffer(pol2, byid = T, width = 0) : 20: Polygon object 21 area
>>> 20.169
>>> 21: In gBuffer(pol2, byid = T, width = 0) : 21: Polygon object 22 area
>>> 1230.31
>>> 22: In gBuffer(pol2, byid = T, width = 0) : 22: Polygon object 23 area
>>> 20.169
>>> 23: In gBuffer(pol2, byid = T, width = 0) : 23: Polygon object 25 area
>>> 20.169
>>> 24: In gBuffer(pol2, byid = T, width = 0) : 24: Polygon object 26 area
>>> 20.169
>>> 25: In gBuffer(pol2, byid = T, width = 0) : 25: Polygon object 27 area
>>> 564.732
>>> 26: In gBuffer(pol2, byid = T, width = 0) : 26: Polygon object 28 area
>>> 40.338
>>> 27: In gBuffer(pol2, byid = T, width = 0) : 27: Polygon object 30 area
>>> 504.225
>>> 28: In gBuffer(pol2, byid = T, width = 0) : 28: Polygon object 31 area
>>> 605.07
>>> 29: In gBuffer(pol2, byid = T, width = 0) : 29: Polygon object 33 area
>>> 20.169
>>> 30: In gBuffer(pol2, byid = T, width = 0) : 30: Polygon object 34 area
>>> 20.169
>>> 31: In gBuffer(pol2, byid = T, width = 0) : 31: Polygon object 35 area
>>> 1210.14
>>> 32: In gBuffer(pol2, byid = T, width = 0) : 32: Polygon object 36 area
>>> 20.169
>>> 33: In gBuffer(pol2, byid = T, width = 0) : 33: Polygon object 37 area
>>> 685.746
>>> 34: In gBuffer(pol2, byid = T, width = 0) : 34: Polygon object 38 area
>>> 40.338
>>> 35: In gBuffer(pol2, byid = T, width = 0) : 35: Polygon object 39 area
>>> 20.169
>>> 36: In gBuffer(pol2, byid = T, width = 0) : 36: Polygon object 40 area
>>> 20.169
>>> 37: In gBuffer(pol2, byid = T, width = 0) : 37: Polygon object 41 area
>>> 80.676
>>> 38: In gBuffer(pol2, byid = T, width = 0) : 38: Polygon object 42 area
>>> 20.169
>>> 39: In gBuffer(pol2, byid = T, width = 0) : 39: Polygon object 43 area
>>> 625.239
>>> 40: In gBuffer(pol2, byid = T, width = 0) : 40: Polygon object 44 area
>>> 20.169
>>> 41: In gBuffer(pol2, byid = T, width = 0) : 41: Polygon object 46 area
>>> 262.197
>>> 42: In gBuffer(pol2, byid = T, width = 0) : 42: Polygon object 47 area
>>> 2500.96
>>> 43: In gBuffer(pol2, byid = T, width = 0) : 43: Polygon object 48 area
>>> 20.169
>>> 44: In gBuffer(pol2, byid = T, width = 0) : 44: Polygon object 49 area
>>> 40.338
>>> 45: In gBuffer(pol2, byid = T, width = 0) : 45: Polygon object 53 area
>>> 80.676
>>> 46: In gBuffer(pol2, byid = T, width = 0) : 46: Polygon object 56 area
>>> 1290.82
>>> 47: In gBuffer(pol2, byid = T, width = 0) : 47: Polygon object 57 area
>>> 2722.82
>>> 48: In gBuffer(pol2, byid = T, width = 0) : 48: Polygon object 59 area
>>> 2218.59
>>> 49: In gBuffer(pol2, byid = T, width = 0) : 49: Polygon object 60 area
>>> 40.338
>>> 50: In gBuffer(pol2, byid = T, width = 0) : 50: Polygon object 61 area
>>> 121.014
>>>
>>> spplot(t1)
>>>>
>>>
>>> Thanks, and sorry if i can't be of much help in making suggestions as i
>>> don't know how could this be done
>>>
>>>
>>> 2015-11-05 8:05 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>>
>>> On Wed, 4 Nov 2015, Roger Bivand wrote:
>>>>
>>>> On Wed, 4 Nov 2015, Eduardo Diez wrote:
>>>>
>>>>>
>>>>>  Is there any way of doing this or should i forget it and go on using
>>>>>
>>>>>> GRASS
>>>>>>  through rgrass7?
>>>>>>
>>>>>>
>>>>> I suggest working with Emmanuel Blondel (cleangeo maintainer) to extend
>>>>> cleangeo (also suggested in an earlier thread today, with apologies to
>>>>> Emmanuel for picking on him!). That package already uses rgeos, and is a
>>>>> logical place to put GRASS v.clean-like functionality (maybe even
>>>>> encapsulating using GRASs via rgrass7 and a throwaway location).
>>>>>
>>>>> At the moment it is messy, though some rgeos internals do do something
>>>>> like this, but it isn't exposed to users.
>>>>>
>>>>>
>>>> A possibility is to use:
>>>>
>>>> set_RGEOS_polyThreshold(1e-2) # for example
>>>> set_RGEOS_warnSlivers(TRUE)
>>>>
>>>> shows the remaining slivers, and:
>>>>
>>>> set_RGEOS_dropSlivers(TRUE)
>>>>
>>>> drops them when using for example:
>>>>
>>>> t1 <- gBuffer(<your_object>, byid=TRUE, width=0)
>>>>
>>>>>
>>>>>
>>>> A buffer of zero width should not have side-effects, but your mileage may
>>>> vary. It will only remove slivers, not dangles. I haven't tried it when
>>>> it
>>>> also finds a Polygons object under the threshold, which was your initial
>>>> problem.
>>>>
>>>> Roger
>>>>
>>>>
>>>>
>>>> Roger
>>>>>
>>>>>
>>>>>  Thanks
>>>>>>
>>>>>>  2015-10-19 15:03 GMT-03:00 Eduardo Diez <eduardodiez at gmx.com>:
>>>>>>
>>>>>>  Ok. So here's a link to a zip file that contains two shapefiles:
>>>>>>>  - pol_to_be_cleaned: the layer from which i'd like to remove small
>>>>>>>  polygons
>>>>>>>   - pol_cleaned: the layer cleaned with the function v.clean rmarea
>>>>>>>
>>>>>>>>  http://1drv.ms/1GmRWS7
>>>>>>>>  The threshold i used for cleaning was 3000 (meaning 3000 squared >
>>>>>>>>
>>>>>>> meters).
>>>>>>
>>>>>>>  Although i do project it before sending it to GRASS, according to
>>>>>>>>
>>>>>>> the
>>>>>>
>>>>>>>  official help page it should be able to handle it:
>>>>>>>  "Threshold must always be in square meters, also for
>>>>>>>
>>>>>> latitude-longitude
>>>>>>
>>>>>>>  locations or locations with units other than meters"
>>>>>>>
>>>>>>>>  Thanks
>>>>>>>>  2015-10-19 8:28 GMT-03:00 Roger Bivand <Roger.Bivand at nhh.no>:
>>>>>>>>
>>>>>>>>>  On Fri, 16 Oct 2015, Eduardo Diez wrote:
>>>>>>>>>
>>>>>>>>>>  Dear list,
>>>>>>>>>>
>>>>>>>>>  I'm willing to know if any knows a way of performing tha same
>>>>>>>>>
>>>>>>>> thing > > >  i'm
>>>>>>
>>>>>>>  doing through rgrass7 with GRASS when I execute the function
>>>>>>>>>
>>>>>>>> v.clean > > >  with
>>>>>>
>>>>>>>  "rmarea" as the tool argument. That is:
>>>>>>>>>
>>>>>>>>>>  "The rmarea tool removes all areas <= thresh. The longest
>>>>>>>>>>>>
>>>>>>>>>>> boundary > > >  with
>>>>>>
>>>>>>>  an
>>>>>>>>>  adjacent area is removed or all boundaries if there is no
>>>>>>>>>
>>>>>>>> adjacent > > >  area.
>>>>>>
>>>>>>>  Area categories are not combined when a small area is merged with
>>>>>>>>>
>>>>>>>> a
>>>>>>
>>>>>>>  larger
>>>>>>>>>  area."
>>>>>>>>>
>>>>>>>>>>  Basically i have raster of zones within a field. I convert
>>>>>>>>>>>>
>>>>>>>>>>> it to
>>>>>>
>>>>>>>  SpatialPolygonsDataFrame and in order to leave only the more
>>>>>>>>>  important/meaningful ones i remove the small/sliver with this
>>>>>>>>>
>>>>>>>> tool. > > >  In
>>>>>>
>>>>>>>  general it works fine but having to call an external software
>>>>>>>>>
>>>>>>>> with a
>>>>>>
>>>>>>>  specific version makes the script less portable and you have to be
>>>>>>>>>  careful
>>>>>>>>>  with updates and such. Also you have to write rasters and
>>>>>>>>>
>>>>>>>> shapefiles > > >  back
>>>>>>
>>>>>>>  and forth as GRASS can't work with in-memory objects.
>>>>>>>>>
>>>>>>>>>>  Could you please provide an example of a built-in or
>>>>>>>>>>>>>
>>>>>>>>>>>> contributed data > >  set
>>>>>>
>>>>>>>  (URL, not attachment) with the slivers you mention, so that we know
>>>>>>>>  that we
>>>>>>>>  are addressing your problem? I don't think that:
>>>>>>>>
>>>>>>>>>  https://cran.r-project.org/web/packages/cleangeo/index.html
>>>>>>>>>>  does this, as it seems to try to repair broken geometries.
>>>>>>>>>>  Also note that you need to specify that the area threshold is
>>>>>>>>>>
>>>>>>>>> in a > >  square
>>>>>>
>>>>>>>  planar metric - dropping slivers in unprojected geometries may be
>>>>>>>>
>>>>>>> more
>>>>>>
>>>>>>>  complicated.
>>>>>>>>
>>>>>>>>>  Roger
>>>>>>>>>>
>>>>>>>>>>>  Does someone know a way of doing this in plain R?
>>>>>>>>>>>>>
>>>>>>>>>>>>  Thanks
>>>>>>>>>>>>          [[alternative HTML version deleted]]
>>>>>>>>>>>>  _______________________________________________
>>>>>>>>>>>>
>>>>>>>>>>>  R-sig-Geo mailing list
>>>>>>>>>  R-sig-Geo at r-project.org
>>>>>>>>>  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>>>
>>>>>>>>>>  --
>>>>>>>>>>>>>>
>>>>>>>>>>>>>  Roger Bivand
>>>>>>>>  Department of Economics, Norwegian School of Economics,
>>>>>>>>  Helleveien 30, N-5045 Bergen, Norway.
>>>>>>>>  voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>>>>>>  e-mail: Roger.Bivand at nhh.no
>>>>>>>>
>>>>>>>>>
>>>>>>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>> --
>>>> Roger Bivand
>>>> Department of Economics, Norwegian School of Economics,
>>>> Helleveien 30, N-5045 Bergen, Norway.
>>>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>>
>>>
>> --
>> Roger Bivand
>> Department of Economics, Norwegian School of Economics,
>> Helleveien 30, N-5045 Bergen, Norway.
>> voice: +47 55 95 93 55; fax +47 55 95 91 00
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From giuseppe.amatulli at gmail.com  Sat Nov  7 21:41:18 2015
From: giuseppe.amatulli at gmail.com (Giuseppe Amatulli)
Date: Sat, 7 Nov 2015 15:41:18 -0500
Subject: [R-sig-Geo] plot3D raster and SpatialLinesDataFrame
Message-ID: <CAKoiDH+wraK65XadF-wVfYxSACF4vGHQfrAyUxZeyF04-dt4sA@mail.gmail.com>

Hi,
I have a digital elevation model (raster) and the derived river network
(SpatialLinesDataFrame) and I would like to plot them in 3D (the dem and on
top the river network).

I use the command plot3D(dem) from the rasterVis package, but i do not know
how to overlap the river network SpatialLinesDataFrame . I tried to convert
the river in raster and use the  surface3d but did not work.

Any idea?

Thanks

Best Regards

-- 
Giuseppe Amatulli, Ph.D.

Department of Ecology and Evolutionary Biology, Yale University.
Jetz Lab, OML Room 405

P.O. Box 208106
165 PROSPECT ST
New Haven, CT 06520-8106
Teaching: spatial-ecology.net
Work:  http://sbsc.yale.edu/giuseppe-amatulli
<http://www.spatial-ecology.net>

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Sun Nov  8 12:11:52 2015
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Sun, 8 Nov 2015 11:11:52 +0000
Subject: [R-sig-Geo] 3d box plot
In-Reply-To: <CAKoiDH+wraK65XadF-wVfYxSACF4vGHQfrAyUxZeyF04-dt4sA@mail.gmail.com>
References: <CAKoiDH+wraK65XadF-wVfYxSACF4vGHQfrAyUxZeyF04-dt4sA@mail.gmail.com>
Message-ID: <HE1PR04MB1161850F402713C771769F3BB3160@HE1PR04MB1161.eurprd04.prod.outlook.com>

Hi folks,
anyone could address me towards a R function/package able to do a 3d boxplot similar to

http://158.132.155.107/oess/POSH/StatSoft/popups/popup125.gif

Thanks in advance
best
paolo


From rhurlin at gwdg.de  Sun Nov  8 17:42:04 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 8 Nov 2015 17:42:04 +0100
Subject: [R-sig-Geo] rgdal_1.1-1: dsn path string problems
Message-ID: <563F7B5C.6070703@gwdg.de>

Dear Roger, dear list,

many thanks for the newest update 1.1-1 of package rgdal. It is really
helpful.

I am using rgdal with R-devel and GDAL 2.0.1, both on FreeBSD
11.0-CURRENT and Windows7. On both platforms, I have problems with path
strings in dsn.



(a) The minor problem is on Windows. While a dsn="C:/some/path" works
fine, the same path with a slash at the end (dsn="C:/some/path/") fails.

On most other software it is conventional to allow a closing slash.
Wouldn't it be nice, if rgdal would be more tolerant about it?


Now my main problem:
(b) On FreeBSD, for some time now, the dsn path can not be used anymore
to check for existence of a file.

I want to use writeOGR to overwrite an existing shapefile. I use
something like dsn="/path/to/somewhere" and layer="layername".

Within writeOGR(), R/ogr_write.R calls the C++ function
'ogrCheckExists'. ogrCheckExists is not able to return TRUE, if a
shapefile already exists. Every time its result is FALSE:

R/ogr_write.R
61:        ogrI <- .Call("ogrCheckExists", as.character(dsn),
s.character(layer), PACKAGE = "rgdal")
[1] FALSE


As far, as I can see, 'ogrCheckExists' comes from src/ogrsource.cpp.
Something must go wrong in that C++ file, at least for FreeBSD :(

Unfortunalety, I have no skills how to debug such a C++ code within an R
package ...

Any help is really appreciated. Please tell me, if I could try and test
something. My box has FreeBSD, R-devel, gcc-4.8.5, gdb-7.1.0 ...

Greetings,
Rainer Hurling


From Roger.Bivand at nhh.no  Sun Nov  8 18:02:57 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 8 Nov 2015 18:02:57 +0100
Subject: [R-sig-Geo] rgdal_1.1-1: dsn path string problems
In-Reply-To: <563F7B5C.6070703@gwdg.de>
References: <563F7B5C.6070703@gwdg.de>
Message-ID: <alpine.LFD.2.20.1511081747380.9569@reclus.nhh.no>

On Sun, 8 Nov 2015, Rainer Hurling wrote:

> Dear Roger, dear list,
>
> many thanks for the newest update 1.1-1 of package rgdal. It is really
> helpful.
>
> I am using rgdal with R-devel and GDAL 2.0.1, both on FreeBSD
> 11.0-CURRENT and Windows7. On both platforms, I have problems with path
> strings in dsn.
>
>
>
> (a) The minor problem is on Windows. While a dsn="C:/some/path" works
> fine, the same path with a slash at the end (dsn="C:/some/path/") fails.
>
> On most other software it is conventional to allow a closing slash.
> Wouldn't it be nice, if rgdal would be more tolerant about it?
>

R base::file.exists does include this in its help file: "However, 
directory names must not include a trailing backslash or slash on 
Windows".

so this isn't just rgdal. The dsn= argument for many drivers is a file 
name, not a directory; a work-around seems like overkill.

>
> Now my main problem:
> (b) On FreeBSD, for some time now, the dsn path can not be used anymore
> to check for existence of a file.
>
> I want to use writeOGR to overwrite an existing shapefile. I use
> something like dsn="/path/to/somewhere" and layer="layername".
>
> Within writeOGR(), R/ogr_write.R calls the C++ function
> 'ogrCheckExists'. ogrCheckExists is not able to return TRUE, if a
> shapefile already exists. Every time its result is FALSE:
>
> R/ogr_write.R
> 61:        ogrI <- .Call("ogrCheckExists", as.character(dsn),
> s.character(layer), PACKAGE = "rgdal")
> [1] FALSE
>
>
> As far, as I can see, 'ogrCheckExists' comes from src/ogrsource.cpp.
> Something must go wrong in that C++ file, at least for FreeBSD :(
>
> Unfortunalety, I have no skills how to debug such a C++ code within an R
> package ...
>

I do not have access to such a system. As a first step, does 
rgdal::ogrListLayers work correctly?

Beyond that, you'd need to insert Rprintf() statements into the C++ file 
to see whether the FALSE result comes from a failure to open the dsn with 
a known driver, or from the fact that such a layer is not found in that 
dsn.

Does using a different driver help? Does using the shapefile.shp as the 
dsn help (I think this works better in GDAL2)?

Hope this helps,

Roger

> Any help is really appreciated. Please tell me, if I could try and test
> something. My box has FreeBSD, R-devel, gcc-4.8.5, gdb-7.1.0 ...
>
> Greetings,
> Rainer Hurling
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From rhurlin at gwdg.de  Sun Nov  8 18:53:21 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Sun, 8 Nov 2015 18:53:21 +0100
Subject: [R-sig-Geo] rgdal_1.1-1: dsn path string problems
In-Reply-To: <alpine.LFD.2.20.1511081747380.9569@reclus.nhh.no>
References: <563F7B5C.6070703@gwdg.de>
	<alpine.LFD.2.20.1511081747380.9569@reclus.nhh.no>
Message-ID: <563F8C11.4090706@gwdg.de>

Hi Roger,

many thanks for your quick answer.


Am 08.11.15 um 18:02 schrieb Roger Bivand:
> On Sun, 8 Nov 2015, Rainer Hurling wrote:
> 
>> Dear Roger, dear list,
>>
>> many thanks for the newest update 1.1-1 of package rgdal. It is really
>> helpful.
>>
>> I am using rgdal with R-devel and GDAL 2.0.1, both on FreeBSD
>> 11.0-CURRENT and Windows7. On both platforms, I have problems with path
>> strings in dsn.
>>
>>
>>
>> (a) The minor problem is on Windows. While a dsn="C:/some/path" works
>> fine, the same path with a slash at the end (dsn="C:/some/path/") fails.
>>
>> On most other software it is conventional to allow a closing slash.
>> Wouldn't it be nice, if rgdal would be more tolerant about it?
>>
> 
> R base::file.exists does include this in its help file: "However,
> directory names must not include a trailing backslash or slash on Windows".
> 
> so this isn't just rgdal. The dsn= argument for many drivers is a file
> name, not a directory; a work-around seems like overkill.

OK, that seems reasonable. Of course, rgdal should handle this like R in
total. Thanks you for clarification.

>>
>> Now my main problem:
>> (b) On FreeBSD, for some time now, the dsn path can not be used anymore
>> to check for existence of a file.
>>
>> I want to use writeOGR to overwrite an existing shapefile. I use
>> something like dsn="/path/to/somewhere" and layer="layername".
>>
>> Within writeOGR(), R/ogr_write.R calls the C++ function
>> 'ogrCheckExists'. ogrCheckExists is not able to return TRUE, if a
>> shapefile already exists. Every time its result is FALSE:
>>
>> R/ogr_write.R
>> 61:        ogrI <- .Call("ogrCheckExists", as.character(dsn),
>> s.character(layer), PACKAGE = "rgdal")
>> [1] FALSE
>>
>>
>> As far, as I can see, 'ogrCheckExists' comes from src/ogrsource.cpp.
>> Something must go wrong in that C++ file, at least for FreeBSD :(
>>
>> Unfortunalety, I have no skills how to debug such a C++ code within an R
>> package ...
>>
> 
> I do not have access to such a system. As a first step, does
> rgdal::ogrListLayers work correctly?

The syntax, shown in the helpfile, does not work for me:

rgdal::ogrListLayers(dsn="/path", layer="layername")
Fehler in rgdal::ogrListLayers(dsn = "/path", layer = "layername") :
  unbenutztes Argument (layer = "layername")    # unused argument


The same, with layer integrated in the dsn, works fine:

rgdal::ogrListLayers(dsn="/path/layername.shp")
[1] "layername"
attr(,"driver")
[1] "ESRI Shapefile"
attr(,"nlayers")
[1] 1


This leads me to the idea, that the same could work for writeOGR or
ogrWrite.R. And yes, this works on FreeBSD:

writeOGR(gis.layer, dsn="/path/layername.shp",
         layer="layername", driver="ESRI Shapefile",
         check_exists=TRUE, overwrite_layer=TRUE)

So, I have to double 'layername' here, once in dsn and once in layer.
But it should be ok as a workaround until I found the real cause.

> 
> Beyond that, you'd need to insert Rprintf() statements into the C++ file
> to see whether the FALSE result comes from a failure to open the dsn
> with a known driver, or from the fact that such a layer is not found in
> that dsn.

Thanks for the tip. I will investigate into it.

A first question to this: If I want to integrate some Rprintf into
ogrsource.cpp in the section of ogrCheckExists (lines 832 ...), what is
a good syntax to output for example 'ogrSource' and 'Layer'?

What I tried at ogrsource.cpp:l834 without success is:

Rprintf( "ogrCheckExists: OGRSource %s %p\n", OGRLayer, (void *)
ogrSource) ;

It think, I have to wrap 'ogrSource' with some function here? (I am not
a C/C++ programmer)

> 
> Does using a different driver help? Does using the shapefile.shp as the
> dsn help (I think this works better in GDAL2)?

Because using the shapefile.shp as the dsn helps, I did not try a
different driver. If this is important for you, I can catch it up later.

Thanks again for your help,
Rainer

> 
> Hope this helps,
> 
> Roger
> 
>> Any help is really appreciated. Please tell me, if I could try and test
>> something. My box has FreeBSD, R-devel, gcc-4.8.5, gdb-7.1.0 ...
>>
>> Greetings,
>> Rainer Hurling
>>
>>
>


From Roger.Bivand at nhh.no  Sun Nov  8 20:57:15 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 8 Nov 2015 20:57:15 +0100
Subject: [R-sig-Geo] rgdal_1.1-1: dsn path string problems
In-Reply-To: <563F8C11.4090706@gwdg.de>
References: <563F7B5C.6070703@gwdg.de>
	<alpine.LFD.2.20.1511081747380.9569@reclus.nhh.no>
	<563F8C11.4090706@gwdg.de>
Message-ID: <alpine.LFD.2.20.1511082047520.12038@reclus.nhh.no>

On Sun, 8 Nov 2015, Rainer Hurling wrote:

> Hi Roger,
>
> many thanks for your quick answer.
>
>
> Am 08.11.15 um 18:02 schrieb Roger Bivand:
>> On Sun, 8 Nov 2015, Rainer Hurling wrote:
>>
>>> Dear Roger, dear list,
>>>
>>> many thanks for the newest update 1.1-1 of package rgdal. It is really
>>> helpful.
>>>
>>> I am using rgdal with R-devel and GDAL 2.0.1, both on FreeBSD
>>> 11.0-CURRENT and Windows7. On both platforms, I have problems with path
>>> strings in dsn.
>>>
>>>
>>>
>>> (a) The minor problem is on Windows. While a dsn="C:/some/path" works
>>> fine, the same path with a slash at the end (dsn="C:/some/path/") fails.
>>>
>>> On most other software it is conventional to allow a closing slash.
>>> Wouldn't it be nice, if rgdal would be more tolerant about it?
>>>
>>
>> R base::file.exists does include this in its help file: "However,
>> directory names must not include a trailing backslash or slash on Windows".
>>
>> so this isn't just rgdal. The dsn= argument for many drivers is a file
>> name, not a directory; a work-around seems like overkill.
>
> OK, that seems reasonable. Of course, rgdal should handle this like R in
> total. Thanks you for clarification.
>
>>>
>>> Now my main problem:
>>> (b) On FreeBSD, for some time now, the dsn path can not be used anymore
>>> to check for existence of a file.
>>>
>>> I want to use writeOGR to overwrite an existing shapefile. I use
>>> something like dsn="/path/to/somewhere" and layer="layername".
>>>
>>> Within writeOGR(), R/ogr_write.R calls the C++ function
>>> 'ogrCheckExists'. ogrCheckExists is not able to return TRUE, if a
>>> shapefile already exists. Every time its result is FALSE:
>>>
>>> R/ogr_write.R
>>> 61:        ogrI <- .Call("ogrCheckExists", as.character(dsn),
>>> s.character(layer), PACKAGE = "rgdal")
>>> [1] FALSE
>>>
>>>
>>> As far, as I can see, 'ogrCheckExists' comes from src/ogrsource.cpp.
>>> Something must go wrong in that C++ file, at least for FreeBSD :(
>>>
>>> Unfortunalety, I have no skills how to debug such a C++ code within an R
>>> package ...
>>>
>>
>> I do not have access to such a system. As a first step, does
>> rgdal::ogrListLayers work correctly?
>
> The syntax, shown in the helpfile, does not work for me:
>
> rgdal::ogrListLayers(dsn="/path", layer="layername")
> Fehler in rgdal::ogrListLayers(dsn = "/path", layer = "layername") :
>  unbenutztes Argument (layer = "layername")    # unused argument
>

The helpfile usage section says:

ogrListLayers(dsn)

which works, as you see below, there is no layer argument, as the 
function queries the dsn to ask what layers it contains (differs between 
drivers).

>
> The same, with layer integrated in the dsn, works fine:
>
> rgdal::ogrListLayers(dsn="/path/layername.shp")
> [1] "layername"
> attr(,"driver")
> [1] "ESRI Shapefile"
> attr(,"nlayers")
> [1] 1
>
>
> This leads me to the idea, that the same could work for writeOGR or
> ogrWrite.R. And yes, this works on FreeBSD:
>
> writeOGR(gis.layer, dsn="/path/layername.shp",
>         layer="layername", driver="ESRI Shapefile",
>         check_exists=TRUE, overwrite_layer=TRUE)
>
> So, I have to double 'layername' here, once in dsn and once in layer.
> But it should be ok as a workaround until I found the real cause.
>

I have seen this before in GDAL2; it also happened in GDAL1 where the dsn 
directory contained for example *.dbf without *.shp and *.shx. The way dsn 
is handled does vary a lot between drivers.

>>
>> Beyond that, you'd need to insert Rprintf() statements into the C++ file
>> to see whether the FALSE result comes from a failure to open the dsn
>> with a known driver, or from the fact that such a layer is not found in
>> that dsn.
>
> Thanks for the tip. I will investigate into it.
>
> A first question to this: If I want to integrate some Rprintf into
> ogrsource.cpp in the section of ogrCheckExists (lines 832 ...), what is
> a good syntax to output for example 'ogrSource' and 'Layer'?
>
> What I tried at ogrsource.cpp:l834 without success is:
>
> Rprintf( "ogrCheckExists: OGRSource %s %p\n", OGRLayer, (void *)
> ogrSource) ;

You'd need simple "No dns found" after line 860 and "No layer found" after 
line 878 to separate the two FALSE returns, but I guess the cause may have 
been in GDAL2, the shapefile driver, and/or what was in your dsn 
directory.

Roger

>
> It think, I have to wrap 'ogrSource' with some function here? (I am not
> a C/C++ programmer)
>
>>
>> Does using a different driver help? Does using the shapefile.shp as the
>> dsn help (I think this works better in GDAL2)?
>
> Because using the shapefile.shp as the dsn helps, I did not try a
> different driver. If this is important for you, I can catch it up later.
>
> Thanks again for your help,
> Rainer
>
>>
>> Hope this helps,
>>
>> Roger
>>
>>> Any help is really appreciated. Please tell me, if I could try and test
>>> something. My box has FreeBSD, R-devel, gcc-4.8.5, gdb-7.1.0 ...
>>>
>>> Greetings,
>>> Rainer Hurling
>>>
>>>
>>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From tea3rd at gmail.com  Sun Nov  8 21:37:55 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Sun, 8 Nov 2015 14:37:55 -0600
Subject: [R-sig-Geo] spplot graphics problem
Message-ID: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>

All:

I was previously able to do the kind of thing I will illustrate below on an
Intel based RedHat Linux system a few years ago. The simple task is to use
GRASS GIS with R, reading both raster and vector data into R through
rgrass7 (previously with spgrass6). Using spplot, display the raster and
overlay the vector polygon (a river basin boundary) for reference. As I
said, I have previously done this with success. However, now overlaying the
vector polygon fails, both with my own data and with the following example:
http://rspatial.r-forge.r-project.org/gallery/ -- see the example for
fig07.RThe raster data draws, but I get the following...

> spplot(zn, c("a", "b", "c", "d"),
+ names.attr = c("ordinary kriging", "universal kriging with dist to
river",
+ "stratified kriging with flood freq", "inverse distance"),
+ as.table = TRUE, main = "log-zinc interpolation",
+ sp.layout = list(rv, scale, text1, text2))

Warning messages:
1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
1L,  :
  Path drawing not available for this device
2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
1L,  :
  Path drawing not available for this device
3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
1L,  :
  Path drawing not available for this device
4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
1L,  :
  Path drawing not available for this device


I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for others
having this problem to no avail...

Thank you for your help.

Best,
Tom


--

	[[alternative HTML version deleted]]


From tim.appelhans at gmail.com  Sun Nov  8 21:45:34 2015
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Sun, 8 Nov 2015 21:45:34 +0100
Subject: [R-sig-Geo] spplot graphics problem
In-Reply-To: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
References: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
Message-ID: <563FB46E.4040105@gmail.com>

Hi Tom,
on Ubuntu 14.04 I can reproduce fig07.R without any problem
my sessionInfo()

R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.3 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=de_DE.UTF-8
  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8 
LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8 
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] lattice_0.20-33 sp_1.2-1        gstat_1.1-0

loaded via a namespace (and not attached):
[1] zoo_1.7-12       tools_3.2.2      xts_0.9-7 spacetime_1.1-4  
grid_3.2.2       FNN_1.1
[7] intervals_0.15.1

Cheers
Tim

On 08.11.2015 21:37, Thomas Adams wrote:
> All:
>
> I was previously able to do the kind of thing I will illustrate below on an
> Intel based RedHat Linux system a few years ago. The simple task is to use
> GRASS GIS with R, reading both raster and vector data into R through
> rgrass7 (previously with spgrass6). Using spplot, display the raster and
> overlay the vector polygon (a river basin boundary) for reference. As I
> said, I have previously done this with success. However, now overlaying the
> vector polygon fails, both with my own data and with the following example:
> http://rspatial.r-forge.r-project.org/gallery/ -- see the example for
> fig07.RThe raster data draws, but I get the following...
>
>> spplot(zn, c("a", "b", "c", "d"),
> + names.attr = c("ordinary kriging", "universal kriging with dist to
> river",
> + "stratified kriging with flood freq", "inverse distance"),
> + as.table = TRUE, main = "log-zinc interpolation",
> + sp.layout = list(rv, scale, text1, text2))
>
> Warning messages:
> 1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
> 1L,  :
>    Path drawing not available for this device
> 2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
> 1L,  :
>    Path drawing not available for this device
> 3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
> 1L,  :
>    Path drawing not available for this device
> 4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule, winding =
> 1L,  :
>    Path drawing not available for this device
>
>
> I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for others
> having this problem to no avail...
>
> Thank you for your help.
>
> Best,
> Tom
>
>
> --
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
Raum 00A08
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From edzer.pebesma at uni-muenster.de  Sun Nov  8 21:49:34 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 8 Nov 2015 21:49:34 +0100
Subject: [R-sig-Geo] spplot graphics problem
In-Reply-To: <563FB46E.4040105@gmail.com>
References: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
	<563FB46E.4040105@gmail.com>
Message-ID: <563FB55E.3000205@uni-muenster.de>

Me too.

> dev.list()
X11cairo
       2

What is your output of dev.list()? does plot(meuse.sr) work?


On 08/11/15 21:45, Tim Appelhans wrote:
> Hi Tom,
> on Ubuntu 14.04 I can reproduce fig07.R without any problem
> my sessionInfo()
> 
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.3 LTS
> 
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=de_DE.UTF-8
>  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8
> LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8
> LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
> 
> other attached packages:
> [1] lattice_0.20-33 sp_1.2-1        gstat_1.1-0
> 
> loaded via a namespace (and not attached):
> [1] zoo_1.7-12       tools_3.2.2      xts_0.9-7 spacetime_1.1-4 
> grid_3.2.2       FNN_1.1
> [7] intervals_0.15.1
> 
> Cheers
> Tim
> 
> On 08.11.2015 21:37, Thomas Adams wrote:
>> All:
>>
>> I was previously able to do the kind of thing I will illustrate below
>> on an
>> Intel based RedHat Linux system a few years ago. The simple task is to
>> use
>> GRASS GIS with R, reading both raster and vector data into R through
>> rgrass7 (previously with spgrass6). Using spplot, display the raster and
>> overlay the vector polygon (a river basin boundary) for reference. As I
>> said, I have previously done this with success. However, now
>> overlaying the
>> vector polygon fails, both with my own data and with the following
>> example:
>> http://rspatial.r-forge.r-project.org/gallery/ -- see the example for
>> fig07.RThe raster data draws, but I get the following...
>>
>>> spplot(zn, c("a", "b", "c", "d"),
>> + names.attr = c("ordinary kriging", "universal kriging with dist to
>> river",
>> + "stratified kriging with flood freq", "inverse distance"),
>> + as.table = TRUE, main = "log-zinc interpolation",
>> + sp.layout = list(rv, scale, text1, text2))
>>
>> Warning messages:
>> 1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> winding =
>> 1L,  :
>>    Path drawing not available for this device
>> 2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> winding =
>> 1L,  :
>>    Path drawing not available for this device
>> 3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> winding =
>> 1L,  :
>>    Path drawing not available for this device
>> 4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> winding =
>> 1L,  :
>>    Path drawing not available for this device
>>
>>
>> I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for others
>> having this problem to no avail...
>>
>> Thank you for your help.
>>
>> Best,
>> Tom
>>
>>
>> -- 
>>
>>     [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151108/8f36f2aa/attachment.bin>

From tea3rd at gmail.com  Sun Nov  8 23:42:50 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Sun, 8 Nov 2015 16:42:50 -0600
Subject: [R-sig-Geo] spplot graphics problem
In-Reply-To: <563FB55E.3000205@uni-muenster.de>
References: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
	<563FB46E.4040105@gmail.com> <563FB55E.3000205@uni-muenster.de>
Message-ID: <CAGxgkWh_qqiV84MAMV-Mtkwdu+oAH5SAndk3qo3dFTyZibLnsw@mail.gmail.com>

Edzer,

That's the problem... dev.list() returns NULL -- I don't understand. I
built R from source and did not see any problems. Any thoughts what I
should look for in building R correctly? I have built R from source many
times in the past and I have never encountered this kind of problem.

Thank you!

Tom

On Sun, Nov 8, 2015 at 2:49 PM, Edzer Pebesma <edzer.pebesma at uni-muenster.de
> wrote:

> Me too.
>
> > dev.list()
> X11cairo
>        2
>
> What is your output of dev.list()? does plot(meuse.sr) work?
>
>
> On 08/11/15 21:45, Tim Appelhans wrote:
> > Hi Tom,
> > on Ubuntu 14.04 I can reproduce fig07.R without any problem
> > my sessionInfo()
> >
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> > Running under: Ubuntu 14.04.3 LTS
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=de_DE.UTF-8
> >  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8
> > LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C LC_ADDRESS=C
> > [10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8
> > LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods base
> >
> > other attached packages:
> > [1] lattice_0.20-33 sp_1.2-1        gstat_1.1-0
> >
> > loaded via a namespace (and not attached):
> > [1] zoo_1.7-12       tools_3.2.2      xts_0.9-7 spacetime_1.1-4
> > grid_3.2.2       FNN_1.1
> > [7] intervals_0.15.1
> >
> > Cheers
> > Tim
> >
> > On 08.11.2015 21:37, Thomas Adams wrote:
> >> All:
> >>
> >> I was previously able to do the kind of thing I will illustrate below
> >> on an
> >> Intel based RedHat Linux system a few years ago. The simple task is to
> >> use
> >> GRASS GIS with R, reading both raster and vector data into R through
> >> rgrass7 (previously with spgrass6). Using spplot, display the raster and
> >> overlay the vector polygon (a river basin boundary) for reference. As I
> >> said, I have previously done this with success. However, now
> >> overlaying the
> >> vector polygon fails, both with my own data and with the following
> >> example:
> >> http://rspatial.r-forge.r-project.org/gallery/ -- see the example for
> >> fig07.RThe raster data draws, but I get the following...
> >>
> >>> spplot(zn, c("a", "b", "c", "d"),
> >> + names.attr = c("ordinary kriging", "universal kriging with dist to
> >> river",
> >> + "stratified kriging with flood freq", "inverse distance"),
> >> + as.table = TRUE, main = "log-zinc interpolation",
> >> + sp.layout = list(rv, scale, text1, text2))
> >>
> >> Warning messages:
> >> 1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> winding =
> >> 1L,  :
> >>    Path drawing not available for this device
> >> 2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> winding =
> >> 1L,  :
> >>    Path drawing not available for this device
> >> 3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> winding =
> >> 1L,  :
> >>    Path drawing not available for this device
> >> 4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> winding =
> >> 1L,  :
> >>    Path drawing not available for this device
> >>
> >>
> >> I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for others
> >> having this problem to no avail...
> >>
> >> Thank you for your help.
> >>
> >> Best,
> >> Tom
> >>
> >>
> >> --
> >>
> >>     [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Thomas E Adams, III
2330 Jack Warner PKWY, #334
Tuscaloosa, AL 35401

1 (513) 739-9512 (cell)

	[[alternative HTML version deleted]]


From dylan.beaudette at gmail.com  Mon Nov  9 00:16:35 2015
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sun, 8 Nov 2015 15:16:35 -0800
Subject: [R-sig-Geo] spplot graphics problem
In-Reply-To: <CAGxgkWh_qqiV84MAMV-Mtkwdu+oAH5SAndk3qo3dFTyZibLnsw@mail.gmail.com>
References: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
	<563FB46E.4040105@gmail.com> <563FB55E.3000205@uni-muenster.de>
	<CAGxgkWh_qqiV84MAMV-Mtkwdu+oAH5SAndk3qo3dFTyZibLnsw@mail.gmail.com>
Message-ID: <CAOGWcHJwK0f_ycw3yCjxwGs1-6Y7Zzzj5Uw-ph0GbJxkjDk6Og@mail.gmail.com>

Hi Tom,

I have encountered this in the past when compiling without X11
support, thinking that I wouldn't need it on a headless server. Turns
out you need X11 (or at least Cairo) for a working graphics device for
PNG and JPG formats. Any chance that you can post your configure
arguments or build information?

Dylan

On Sun, Nov 8, 2015 at 2:42 PM, Thomas Adams <tea3rd at gmail.com> wrote:
> Edzer,
>
> That's the problem... dev.list() returns NULL -- I don't understand. I
> built R from source and did not see any problems. Any thoughts what I
> should look for in building R correctly? I have built R from source many
> times in the past and I have never encountered this kind of problem.
>
> Thank you!
>
> Tom
>
> On Sun, Nov 8, 2015 at 2:49 PM, Edzer Pebesma <edzer.pebesma at uni-muenster.de
>> wrote:
>
>> Me too.
>>
>> > dev.list()
>> X11cairo
>>        2
>>
>> What is your output of dev.list()? does plot(meuse.sr) work?
>>
>>
>> On 08/11/15 21:45, Tim Appelhans wrote:
>> > Hi Tom,
>> > on Ubuntu 14.04 I can reproduce fig07.R without any problem
>> > my sessionInfo()
>> >
>> > R version 3.2.2 (2015-08-14)
>> > Platform: x86_64-pc-linux-gnu (64-bit)
>> > Running under: Ubuntu 14.04.3 LTS
>> >
>> > locale:
>> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=de_DE.UTF-8
>> >  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8
>> > LC_MESSAGES=en_US.UTF-8
>> >  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C LC_ADDRESS=C
>> > [10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8
>> > LC_IDENTIFICATION=C
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods base
>> >
>> > other attached packages:
>> > [1] lattice_0.20-33 sp_1.2-1        gstat_1.1-0
>> >
>> > loaded via a namespace (and not attached):
>> > [1] zoo_1.7-12       tools_3.2.2      xts_0.9-7 spacetime_1.1-4
>> > grid_3.2.2       FNN_1.1
>> > [7] intervals_0.15.1
>> >
>> > Cheers
>> > Tim
>> >
>> > On 08.11.2015 21:37, Thomas Adams wrote:
>> >> All:
>> >>
>> >> I was previously able to do the kind of thing I will illustrate below
>> >> on an
>> >> Intel based RedHat Linux system a few years ago. The simple task is to
>> >> use
>> >> GRASS GIS with R, reading both raster and vector data into R through
>> >> rgrass7 (previously with spgrass6). Using spplot, display the raster and
>> >> overlay the vector polygon (a river basin boundary) for reference. As I
>> >> said, I have previously done this with success. However, now
>> >> overlaying the
>> >> vector polygon fails, both with my own data and with the following
>> >> example:
>> >> http://rspatial.r-forge.r-project.org/gallery/ -- see the example for
>> >> fig07.RThe raster data draws, but I get the following...
>> >>
>> >>> spplot(zn, c("a", "b", "c", "d"),
>> >> + names.attr = c("ordinary kriging", "universal kriging with dist to
>> >> river",
>> >> + "stratified kriging with flood freq", "inverse distance"),
>> >> + as.table = TRUE, main = "log-zinc interpolation",
>> >> + sp.layout = list(rv, scale, text1, text2))
>> >>
>> >> Warning messages:
>> >> 1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> >> winding =
>> >> 1L,  :
>> >>    Path drawing not available for this device
>> >> 2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> >> winding =
>> >> 1L,  :
>> >>    Path drawing not available for this device
>> >> 3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> >> winding =
>> >> 1L,  :
>> >>    Path drawing not available for this device
>> >> 4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
>> >> winding =
>> >> 1L,  :
>> >>    Path drawing not available for this device
>> >>
>> >>
>> >> I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for others
>> >> having this problem to no avail...
>> >>
>> >> Thank you for your help.
>> >>
>> >> Best,
>> >> Tom
>> >>
>> >>
>> >> --
>> >>
>> >>     [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics (ifgi),  University of M?nster,
>> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
>> Journal of Statistical Software:   http://www.jstatsoft.org/
>> Computers & Geosciences:   http://elsevier.com/locate/cageo/
>> Spatial Statistics Society http://www.spatialstatistics.info
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>
>
> --
> Thomas E Adams, III
> 2330 Jack Warner PKWY, #334
> Tuscaloosa, AL 35401
>
> 1 (513) 739-9512 (cell)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From tea3rd at gmail.com  Mon Nov  9 00:22:00 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Sun, 8 Nov 2015 17:22:00 -0600
Subject: [R-sig-Geo] spplot graphics problem
In-Reply-To: <CAOGWcHJwK0f_ycw3yCjxwGs1-6Y7Zzzj5Uw-ph0GbJxkjDk6Og@mail.gmail.com>
References: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
	<563FB46E.4040105@gmail.com> <563FB55E.3000205@uni-muenster.de>
	<CAGxgkWh_qqiV84MAMV-Mtkwdu+oAH5SAndk3qo3dFTyZibLnsw@mail.gmail.com>
	<CAOGWcHJwK0f_ycw3yCjxwGs1-6Y7Zzzj5Uw-ph0GbJxkjDk6Og@mail.gmail.com>
Message-ID: <CAGxgkWhg6sekmuatWCgDRyPBC+cV-8rGemip=iqqSm3q+UADmg@mail.gmail.com>

Hi Dylan,

I'm using ./configure without any options, installing in /usr/local

teaiii at teaiii-Leopard-WS:~/R-3.2.2$ ./configure
checking build system type... x86_64-pc-linux-gnu
checking host system type... x86_64-pc-linux-gnu
loading site script './config.site'
loading build-specific script './config.site'
checking for pwd... /bin/pwd
checking whether builddir is srcdir... yes
checking for working aclocal... missing
checking for working autoconf... missing
checking for working automake... missing
checking for working autoheader... missing
checking for gawk... no
checking for mawk... mawk
checking whether ln -s works... yes
checking for bison... bison -y
checking for ar... ar
checking for a BSD-compatible install... /usr/bin/install -c
checking for sed... /bin/sed
checking for which... /usr/bin/which
checking for less... /usr/bin/less
checking for gtar... no
checking for gnutar... no
checking for tar... /bin/tar
checking for tex... /usr/bin/tex
checking for pdftex... /usr/bin/pdftex
checking for pdflatex... /usr/bin/pdflatex
checking for makeindex... /usr/bin/makeindex
checking for texi2any... no
configure: WARNING: you cannot build info or HTML versions of the R manuals
checking for texi2dvi... no
checking for kpsewhich... /usr/bin/kpsewhich
checking for latex inconsolata package... missing
configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF
vignettes and package manuals will not be rendered optimally
checking for unzip... /usr/bin/unzip
checking for zip... /usr/bin/zip
checking for gzip... /bin/gzip
checking for bzip2... /bin/bzip2
checking for firefox... /usr/bin/firefox
using default browser ... /usr/bin/firefox
checking for acroread... no
checking for acroread4... no
checking for xdg-open... /usr/bin/xdg-open
checking for notangle... false
checking for realpath... /usr/bin/realpath
checking for pkg-config... /usr/bin/pkg-config
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -E
checking for grep that handles long lines and -e... /bin/grep
checking for egrep... /bin/grep -E
checking whether gcc needs -traditional... no
checking how to run the C preprocessor... gcc -E
checking for gfortran... gfortran
checking whether we are using the GNU Fortran 77 compiler... yes
checking whether gfortran accepts -g... yes
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking whether __attribute__((visibility())) is supported... yes
checking whether gcc accepts -fvisibility... yes
checking whether gfortran accepts -fvisibility... yes
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking minix/config.h usability... no
checking minix/config.h presence... no
checking for minix/config.h... no
checking whether it is safe to define __EXTENSIONS__... yes
checking for gcc... gcc
checking whether we are using the GNU Objective C compiler... no
checking whether gcc accepts -g... no
checking for Objective C++ compiler... trying some possibilities
checking whether g++ can compile ObjC++... no
checking whether  can compile ObjC++... no
no working ObjC++ compiler found
checking for a sed that does not truncate output... (cached) /bin/sed
checking for fgrep... /bin/grep -F
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking the maximum length of command line arguments... 1572864
checking whether the shell understands some XSI constructs... yes
checking whether the shell understands "+="... yes
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for dlfcn.h... yes
checking whether we are using the GNU C++ compiler... (cached) yes
checking whether g++ accepts -g... (cached) yes
checking how to run the C++ preprocessor... g++ -E
checking whether we are using the GNU Fortran 77 compiler... (cached) yes
checking whether gfortran accepts -g... (cached) yes
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/bin/ld) supports shared libraries...
yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
checking for ld used by g++... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld) supports shared libraries...
yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... yes
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/bin/ld) supports shared libraries...
yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
checking for gfortran option to produce PIC... -fPIC
checking if gfortran PIC flag -fPIC works... yes
checking if gfortran static flag -static works... yes
checking if gfortran supports -c -o file.o... yes
checking if gfortran supports -c -o file.o... (cached) yes
checking whether the gfortran linker (/usr/bin/ld) supports shared
libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking for cos in -lm... yes
checking for sin in -lm... yes
checking for dlopen in -ldl... yes
checking readline/history.h usability... yes
checking readline/history.h presence... yes
checking for readline/history.h... yes
checking readline/readline.h usability... yes
checking readline/readline.h presence... yes
checking for readline/readline.h... yes
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... yes
checking for rl_callback_read_char in -lreadline... yes
checking for history_truncate_file... yes
checking whether rl_completion_matches exists and is declared... yes
checking for ANSI C header files... (cached) yes
checking for dirent.h that defines DIR... yes
checking for library containing opendir... none required
checking for sys/wait.h that is POSIX.1 compatible... yes
checking arpa/inet.h usability... yes
checking arpa/inet.h presence... yes
checking for arpa/inet.h... yes
checking dl.h usability... no
checking dl.h presence... no
checking for dl.h... no
checking for dlfcn.h... (cached) yes
checking elf.h usability... yes
checking elf.h presence... yes
checking for elf.h... yes
checking features.h usability... yes
checking features.h presence... yes
checking for features.h... yes
checking fcntl.h usability... yes
checking fcntl.h presence... yes
checking for fcntl.h... yes
checking floatingpoint.h usability... no
checking floatingpoint.h presence... no
checking for floatingpoint.h... no
checking fpu_control.h usability... yes
checking fpu_control.h presence... yes
checking for fpu_control.h... yes
checking glob.h usability... yes
checking glob.h presence... yes
checking for glob.h... yes
checking grp.h usability... yes
checking grp.h presence... yes
checking for grp.h... yes
checking langinfo.h usability... yes
checking langinfo.h presence... yes
checking for langinfo.h... yes
checking netdb.h usability... yes
checking netdb.h presence... yes
checking for netdb.h... yes
checking netinet/in.h usability... yes
checking netinet/in.h presence... yes
checking for netinet/in.h... yes
checking pwd.h usability... yes
checking pwd.h presence... yes
checking for pwd.h... yes
checking sched.h usability... yes
checking sched.h presence... yes
checking for sched.h... yes
checking for strings.h... (cached) yes
checking sys/param.h usability... yes
checking sys/param.h presence... yes
checking for sys/param.h... yes
checking sys/resource.h usability... yes
checking sys/resource.h presence... yes
checking for sys/resource.h... yes
checking sys/select.h usability... yes
checking sys/select.h presence... yes
checking for sys/select.h... yes
checking sys/socket.h usability... yes
checking sys/socket.h presence... yes
checking for sys/socket.h... yes
checking for sys/stat.h... (cached) yes
checking sys/time.h usability... yes
checking sys/time.h presence... yes
checking for sys/time.h... yes
checking sys/times.h usability... yes
checking sys/times.h presence... yes
checking for sys/times.h... yes
checking sys/utsname.h usability... yes
checking sys/utsname.h presence... yes
checking for sys/utsname.h... yes
checking for unistd.h... (cached) yes
checking utime.h usability... yes
checking utime.h presence... yes
checking for utime.h... yes
checking stdalign.h usability... yes
checking stdalign.h presence... yes
checking for stdalign.h... yes
checking errno.h usability... yes
checking errno.h presence... yes
checking for errno.h... yes
checking for inttypes.h... (cached) yes
checking limits.h usability... yes
checking limits.h presence... yes
checking for limits.h... yes
checking locale.h usability... yes
checking locale.h presence... yes
checking for locale.h... yes
checking stdarg.h usability... yes
checking stdarg.h presence... yes
checking for stdarg.h... yes
checking stdbool.h usability... yes
checking stdbool.h presence... yes
checking for stdbool.h... yes
checking for stdint.h... (cached) yes
checking for string.h... (cached) yes
checking whether setjmp.h is POSIX.1 compatible... yes
checking whether sigsetjmp is declared... yes
checking whether siglongjmp is declared... yes
checking for GNU C library with version >= 2... yes
checking return type of signal handlers... void
checking for uint64_t... yes
checking for int64_t... yes
checking for int_fast64_t... yes
checking for pid_t... yes
checking for size_t... yes
checking whether SIZE_MAX is declared... yes
checking for blkcnt_t... yes
checking for type of socket length... socklen_t *
checking for stack_t... yes
checking for intptr_t... yes
checking for uintptr_t... yes
checking whether byte ordering is bigendian... no
checking for an ANSI C-conforming const... yes
checking for gcc option to accept ISO C99... -std=gnu99
checking for gcc -std=gnu99 option to accept ISO Standard C... (cached)
-std=gnu99
checking for inline... inline
checking size of int... 4
checking size of long... 8
checking size of long long... 8
checking size of double... 8
checking size of size_t... 8
checking size of long double... 16
checking whether we can compute C Make dependencies... yes, using $(CC) -MM
checking whether gcc -std=gnu99 supports -c -o FILE.lo... yes
checking for gcc -std=gnu99 option to support OpenMP... -fopenmp
checking how to get verbose linking output from gfortran... -v
checking for Fortran 77 libraries of gfortran...  -L/usr/local/lib
-L/usr/lib/gcc/x86_64-linux-gnu/4.9
-L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../x86_64-linux-gnu
-L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../../lib -L/lib/x86_64-linux-gnu
-L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib
-L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../.. -lgfortran -lm -lquadmath
checking how to get verbose linking output from gcc -std=gnu99... -v
checking for C libraries of gcc -std=gnu99...  -L/usr/local/lib
-L/usr/lib/gcc/x86_64-linux-gnu/4.9
-L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../x86_64-linux-gnu
-L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../../lib -L/lib/x86_64-linux-gnu
-L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib
-L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../.. -lgcc_s
checking for dummy main to link with Fortran 77 libraries... none
checking for Fortran 77 name-mangling scheme... lower case, underscore, no
extra underscore
checking whether gfortran appends underscores to external names... yes
checking whether gfortran appends extra underscores to external names... no
checking whether mixed C/Fortran code can be run... yes
checking whether gfortran and gcc -std=gnu99 agree on int and double... yes
checking whether gfortran and gcc -std=gnu99 agree on double complex... yes
checking for gfortran option to support OpenMP... -fopenmp
checking whether g++ accepts -M for generating dependencies... yes
checking for g++ option to support OpenMP... -fopenmp
checking whether we can compute ObjC Make dependencies... no
checking whether C runtime needs -D__NO_MATH_INLINES... no
checking for xmkmf... no
checking whether g++  supports C++11 features by default... no
checking whether g++  supports C++11 features with -std=c++11... yes
checking for off_t... yes
checking for working alloca.h... yes
checking for alloca... yes
checking whether alloca is declared... yes
checking whether expm1 exists and is declared... yes
checking whether hypot exists and is declared... yes
checking whether log1p exists and is declared... yes
checking whether log1pl exists and is declared... yes
checking whether log2 exists and is declared... yes
checking whether log10 exists and is declared... yes
checking whether nearbyint exists and is declared... yes
checking whether nearbyintl exists and is declared... yes
checking whether powl exists and is declared... yes
checking whether rint exists and is declared... yes
checking whether rintl exists and is declared... yes
checking whether va_copy exists and is declared... yes
checking for isblank... yes
checking sunmath.h usability... no
checking sunmath.h presence... no
checking for sunmath.h... no
checking for cospi in -lsunmath... no
checking for atanpi... no
checking for atan2pi... no
checking for cospi... no
checking for exp10... yes
checking for pown... no
checking for sinpi... no
checking for tanpi... no
checking for fseeko... yes
checking for ftello... yes
checking for matherr... yes
checking whether fcntl exists and is declared... yes
checking whether getgrgid exists and is declared... yes
checking whether getpwuid exists and is declared... yes
checking whether kill exists and is declared... yes
checking whether sigaction exists and is declared... yes
checking whether sigaltstack exists and is declared... yes
checking whether sigemptyset exists and is declared... yes
checking whether fdopen exists and is declared... yes
checking whether popen exists and is declared... yes
checking whether setenv exists and is declared... yes
checking whether unsetenv exists and is declared... yes
checking whether getrlimit exists and is declared... yes
checking whether getrusage exists and is declared... yes
checking whether getpriority exists and is declared... yes
checking whether chmod exists and is declared... yes
checking whether mkfifo exists and is declared... yes
checking whether stat exists and is declared... yes
checking whether umask exists and is declared... yes
checking whether gettimeofday exists and is declared... yes
checking whether utimes exists and is declared... yes
checking whether times exists and is declared... yes
checking whether gmtime_r exists and is declared... yes
checking whether localtime_r exists and is declared... yes
checking whether nl_langinfo exists and is declared... yes
checking whether access exists and is declared... yes
checking whether chdir exists and is declared... yes
checking whether execv exists and is declared... yes
checking whether ftruncate exists and is declared... yes
checking whether getcwd exists and is declared... yes
checking whether geteuid exists and is declared... yes
checking whether getuid exists and is declared... yes
checking whether link exists and is declared... yes
checking whether readlink exists and is declared... yes
checking whether symlink exists and is declared... yes
checking whether sysconf exists and is declared... yes
checking whether sched_setaffinity exists and is declared... yes
checking whether sched_getaffinity exists and is declared... yes
checking whether utime exists and is declared... yes
checking for clock_gettime in -lrt... yes
checking whether clock_gettime exists and is declared... yes
checking whether timespec_get exists and is declared... yes
checking for putenv... yes
checking whether putenv is declared... yes
checking for vasprintf... yes
checking whether vasprintf is declared... yes
checking for mempcpy... yes
checking for realpath... yes
checking whether realpath is declared... yes
checking whether glob exists and is declared... yes
checking for isnan... yes
checking whether isfinite is declared... yes
checking whether isnan is declared... yes
checking whether you have IEEE 754 floating-point arithmetic... yes
checking whether putenv("FOO") can unset an environment variable... yes
checking whether putenv("FOO=") can unset an environment variable... no
checking for nl_langinfo and CODESET... yes
checking for mkdtemp... yes
checking for strdup... yes
checking for strncasecmp... yes
checking whether mkdtemp is declared... yes
checking whether strdup is declared... yes
checking whether strncasecmp is declared... yes
checking for library containing connect... none required
checking for library containing gethostbyname... none required
checking for library containing xdr_string... none required
checking for __setfpucw... no
checking for working calloc... yes
checking for working isfinite... yes
checking for working log1p... yes
checking whether ftell works correctly on files opened for append... yes
checking for working sigaction... yes
checking whether mktime sets errno... no
checking whether mktime works correctly outside 1902-2037... yes
checking complex.h usability... yes
checking complex.h presence... yes
checking for complex.h... yes
checking for double complex... yes
checking whether C99 double complex is supported... yes
checking whether cabs exists and is declared... yes
checking whether carg exists and is declared... yes
checking whether cexp exists and is declared... yes
checking whether clog exists and is declared... yes
checking whether csqrt exists and is declared... yes
checking whether cpow exists and is declared... yes
checking whether ccos exists and is declared... yes
checking whether csin exists and is declared... yes
checking whether ctan exists and is declared... yes
checking whether cacos exists and is declared... yes
checking whether casin exists and is declared... yes
checking whether catan exists and is declared... yes
checking whether ccosh exists and is declared... yes
checking whether csinh exists and is declared... yes
checking whether ctanh exists and is declared... yes
checking whether 'struct tm' includes tm_zone... yes
checking whether 'struct tm' includes tm_gmtoff... yes
checking iconv.h usability... yes
checking iconv.h presence... yes
checking for iconv.h... yes
checking for iconv... yes
checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"... yes
checking for iconvlist... no
checking for iconv... yes
checking for iconv declaration...
         extern size_t iconv (iconv_t cd, char * *inbuf, size_t
*inbytesleft, char * *outbuf, size_t *outbytesleft);
checking wchar.h usability... yes
checking wchar.h presence... yes
checking for wchar.h... yes
checking wctype.h usability... yes
checking wctype.h presence... yes
checking for wctype.h... yes
checking whether mbrtowc exists and is declared... yes
checking whether wcrtomb exists and is declared... yes
checking whether wcscoll exists and is declared... yes
checking whether wcsftime exists and is declared... yes
checking whether wcstod exists and is declared... yes
checking whether mbstowcs exists and is declared... yes
checking whether wcstombs exists and is declared... yes
checking whether wctrans exists and is declared... yes
checking whether iswblank exists and is declared... yes
checking whether wctype exists and is declared... yes
checking whether iswctype exists and is declared... yes
checking for wctrans_t... yes
checking for mbstate_t... yes
checking for ICU... yes
checking for X... libraries , headers
checking for gethostbyname... yes
checking for connect... yes
checking for remove... yes
checking for shmat... yes
checking for IceConnectionNumber in -lICE... yes
checking X11/Intrinsic.h usability... yes
checking X11/Intrinsic.h presence... yes
checking for X11/Intrinsic.h... yes
checking for XtToolkitInitialize in -lXt... yes
using X11 ... yes
checking for KeySym... yes
checking X11/Xmu/Atoms.h usability... yes
checking X11/Xmu/Atoms.h presence... yes
checking for X11/Xmu/Atoms.h... yes
checking for XmuInternAtom in -lXmu... yes
checking whether pkg-config knows about cairo and pango... no
checking whether pkg-config knows about cairo... yes
checking whether cairo is >= 1.2 and works... yes
checking for tclConfig.sh... no
checking for tclConfig.sh in library (sub)directories... no
checking for tkConfig.sh... no
checking for tkConfig.sh in library (sub)directories... no
checking for tcl.h... no
checking for BSD networking... yes
checking if jpeglib version >= 6b... yes
checking for jpeg_destroy_compress in -ljpeg... yes
checking for main in -lz... yes
checking if libpng version >= 1.2.7... yes
checking for png_create_write_struct in -lpng... yes
checking tiffio.h usability... yes
checking tiffio.h presence... yes
checking for tiffio.h... yes
checking for TIFFOpen in -ltiff... yes
checking rpc/types.h usability... yes
checking rpc/types.h presence... yes
checking for rpc/types.h... yes
checking for rpc/xdr.h... yes
checking for XDR support... yes
checking for inflateInit2_ in -lz... yes
checking zlib.h usability... yes
checking zlib.h presence... yes
checking for zlib.h... yes
checking if zlib version >= 1.2.5... yes
checking whether zlib support needs to be compiled... no
checking for BZ2_bzlibVersion in -lbz2... no
checking whether bzip2 support needs to be compiled... yes
checking for lzma_version_number in -llzma... yes
checking lzma.h usability... yes
checking lzma.h presence... yes
checking for lzma.h... yes
checking if lzma version >= 5.0.3... yes
checking for pcre_fullinfo in -lpcre... yes
checking pcre.h usability... yes
checking pcre.h presence... yes
checking for pcre.h... yes
checking pcre/pcre.h usability... no
checking pcre/pcre.h presence... no
checking for pcre/pcre.h... no
checking if PCRE version >= 8.10, < 10.0 and has UTF-8 support... yes
checking whether PCRE support needs to be compiled... no
checking for curl-config... /usr/bin/curl-config
libcurl 7.38.0
checking if libcurl version >= 7.28.0... yes
checking curl/curl.h usability... yes
checking curl/curl.h presence... yes
checking for curl/curl.h... yes
checking whether leap seconds are treated according to POSIX... yes
checking for inline... inline
checking for sys/time.h... (cached) yes
checking for stdlib.h... (cached) yes
checking for unistd.h... (cached) yes
checking for sys/param.h... (cached) yes
checking for struct stat.st_atim.tv_nsec... yes
checking whether struct stat.st_atim is of type struct timespec... yes
checking for setitimer... yes
checking for special C compiler options needed for large files... no
checking for _FILE_OFFSET_BITS value needed for large files... no
checking for _LARGEFILE_SOURCE value needed for large files... no
checking whether KERN_USRSTACK sysctl is supported... no
checking for visible __lib_stack_end... yes
checking for lpr... lpr
checking for paperconf... /usr/bin/paperconf
checking for gfortran... gfortran
checking whether we are using the GNU Fortran compiler... yes
checking whether gfortran accepts -g... yes
checking whether we are using the GNU Fortran compiler... (cached) yes
checking whether gfortran accepts -g... (cached) yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
checking for gfortran option to produce PIC... -fPIC
checking if gfortran PIC flag -fPIC works... yes
checking if gfortran static flag -static works... yes
checking if gfortran supports -c -o file.o... yes
checking if gfortran supports -c -o file.o... (cached) yes
checking whether the gfortran linker (/usr/bin/ld) supports shared
libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking for Fortran flag to compile .f90 files... none
checking for Fortran flag to compile .f95 files... none
checking for gfortran option to support OpenMP... -fopenmp
checking for recommended packages... yes
checking whether NLS is requested... yes

Configuring src/extra/intl directory
checking for a thread-safe mkdir -p... /bin/mkdir -p
checking whether we are using the GNU C Library 2 or newer... yes
checking for ranlib... (cached) ranlib
checking for simple visibility declarations... yes
checking for stdint.h... yes
checking for getpagesize... yes
checking for working mmap... yes
checking whether integer division by zero raises SIGFPE... yes
checking for inttypes.h... yes
checking for unsigned long long int... yes
checking for inttypes.h... (cached) yes
checking whether the inttypes.h PRIxNN macros are broken... no
checking whether imported symbols can be declared weak... yes
checking for multithread API to use... none
checking argz.h usability... yes
checking argz.h presence... yes
checking for argz.h... yes
checking for inttypes.h... (cached) yes
checking for limits.h... (cached) yes
checking for unistd.h... (cached) yes
checking for sys/param.h... (cached) yes
checking for getcwd... yes
checking for getegid... yes
checking for geteuid... yes
checking for getgid... yes
checking for getuid... yes
checking for mempcpy... (cached) yes
checking for munmap... yes
checking for stpcpy... yes
checking for strcasecmp... yes
checking for strdup... (cached) yes
checking for strtoul... yes
checking for tsearch... yes
checking for argz_count... yes
checking for argz_stringify... yes
checking for argz_next... yes
checking for __fsetlocking... yes
checking whether feof_unlocked is declared... yes
checking whether fgets_unlocked is declared... yes
checking for iconv... (cached) yes
checking for iconv declaration... (cached)
         extern size_t iconv (iconv_t cd, char * *inbuf, size_t
*inbytesleft, char * *outbuf, size_t *outbytesleft);
checking for NL_LOCALE_NAME macro... yes
checking for bison... bison
checking version of bison... 3.0.2, ok
checking for long long int... yes
checking for long double... yes
checking for wchar_t... yes
checking for wint_t... yes
checking for intmax_t... yes
checking whether printf() supports POSIX/XSI format strings... yes
checking whether we are using the GNU C Library 2.1 or newer... yes
checking for stdint.h... (cached) yes
checking for SIZE_MAX... yes
checking for stdint.h... (cached) yes
checking for CFPreferencesCopyAppValue... no
checking for CFLocaleCopyCurrent... no
checking for ptrdiff_t... yes
checking stddef.h usability... yes
checking stddef.h presence... yes
checking for stddef.h... yes
checking for stdlib.h... (cached) yes
checking for string.h... (cached) yes
checking for asprintf... yes
checking for fwprintf... yes
checking for putenv... (cached) yes
checking for setenv... yes
checking for setlocale... yes
checking for snprintf... yes
checking for wcslen... yes
checking whether _snprintf is declared... no
checking whether _snwprintf is declared... no
checking whether getc_unlocked is declared... yes
checking for nl_langinfo and CODESET... (cached) yes
checking for LC_MESSAGES... yes
checking for shared library run path origin... done
checking for CFPreferencesCopyAppValue... (cached) no
checking for CFLocaleCopyCurrent... (cached) no
checking whether included gettext is requested... no
checking for GNU gettext in libc... yes
checking whether to use NLS... yes
checking where the gettext function comes from... libc
Finished configuring src/extra/intl directory

using as R_SHELL for scripts ... /bin/bash
configure: creating ./config.status
config.status: creating Makeconf
config.status: creating Makefile
config.status: creating doc/Makefile
config.status: creating doc/html/Makefile
config.status: creating doc/manual/Makefile
config.status: creating etc/Makefile
config.status: creating etc/Makeconf
config.status: creating etc/Renviron
config.status: creating etc/javaconf
config.status: creating etc/ldpaths
config.status: creating m4/Makefile
config.status: creating po/Makefile
config.status: creating share/Makefile
config.status: creating src/Makefile
config.status: creating src/appl/Makefile
config.status: creating src/extra/Makefile
config.status: creating src/extra/blas/Makefile
config.status: creating src/extra/bzip2/Makefile
config.status: creating src/extra/intl/Makefile
config.status: creating src/extra/pcre/Makefile
config.status: creating src/extra/tre/Makefile
config.status: creating src/extra/tzone/Makefile
config.status: creating src/extra/xdr/Makefile
config.status: creating src/extra/xz/Makefile
config.status: creating src/extra/zlib/Makefile
config.status: creating src/include/Makefile
config.status: creating src/include/Rmath.h0
config.status: creating src/include/R_ext/Makefile
config.status: creating src/library/Recommended/Makefile
config.status: creating src/library/Makefile
config.status: creating src/library/base/DESCRIPTION
config.status: creating src/library/base/Makefile
config.status: creating src/library/compiler/DESCRIPTION
config.status: creating src/library/compiler/Makefile
config.status: creating src/library/datasets/DESCRIPTION
config.status: creating src/library/datasets/Makefile
config.status: creating src/library/graphics/DESCRIPTION
config.status: creating src/library/graphics/Makefile
config.status: creating src/library/graphics/src/Makefile
config.status: creating src/library/grDevices/DESCRIPTION
config.status: creating src/library/grDevices/Makefile
config.status: creating src/library/grDevices/src/Makefile
config.status: creating src/library/grDevices/src/cairo/Makefile
config.status: creating src/library/grid/DESCRIPTION
config.status: creating src/library/grid/Makefile
config.status: creating src/library/grid/src/Makefile
config.status: creating src/library/methods/DESCRIPTION
config.status: creating src/library/methods/Makefile
config.status: creating src/library/methods/src/Makefile
config.status: creating src/library/parallel/DESCRIPTION
config.status: creating src/library/parallel/Makefile
config.status: creating src/library/parallel/src/Makefile
config.status: creating src/library/profile/Makefile
config.status: creating src/library/stats/DESCRIPTION
config.status: creating src/library/stats/Makefile
config.status: creating src/library/stats/src/Makefile
config.status: creating src/library/stats4/DESCRIPTION
config.status: creating src/library/stats4/Makefile
config.status: creating src/library/splines/DESCRIPTION
config.status: creating src/library/splines/Makefile
config.status: creating src/library/splines/src/Makefile
config.status: creating src/library/tcltk/DESCRIPTION
config.status: creating src/library/tcltk/Makefile
config.status: creating src/library/tcltk/src/Makefile
config.status: creating src/library/tools/DESCRIPTION
config.status: creating src/library/tools/Makefile
config.status: creating src/library/tools/src/Makefile
config.status: creating src/library/translations/DESCRIPTION
config.status: creating src/library/translations/Makefile
config.status: creating src/library/utils/DESCRIPTION
config.status: creating src/library/utils/Makefile
config.status: creating src/library/utils/src/Makefile
config.status: creating src/main/Makefile
config.status: creating src/modules/Makefile
config.status: creating src/modules/X11/Makefile
config.status: creating src/modules/internet/Makefile
config.status: creating src/modules/lapack/Makefile
config.status: creating src/nmath/Makefile
config.status: creating src/nmath/standalone/Makefile
config.status: creating src/scripts/Makefile
config.status: creating src/scripts/R.sh
config.status: creating src/scripts/Rcmd
config.status: creating src/scripts/f77_f2c
config.status: creating src/scripts/javareconf
config.status: creating src/scripts/mkinstalldirs
config.status: creating src/scripts/pager
config.status: creating src/scripts/rtags
config.status: creating src/unix/Makefile
config.status: creating tests/Makefile
config.status: creating tests/Embedding/Makefile
config.status: creating tests/Examples/Makefile
config.status: creating tools/Makefile
config.status: creating src/include/config.h
config.status: executing libtool commands
config.status: executing stamp-h commands

R is now configured for x86_64-pc-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc -std=gnu99  -g -O2
  Fortran 77 compiler:       gfortran  -g -O2

  C++ compiler:              g++  -g -O2
  C++ 11 compiler:           g++  -std=c++11 -g -O2
  Fortran 90/95 compiler:    gfortran -g -O2
  Obj-C compiler:

  Interfaces supported:      X11
  External libraries:        readline, zlib, lzma, PCRE, curl
  Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
  Options enabled:           shared BLAS, R profiling

  Capabilities skipped:
  Options not enabled:       memory profiling

  Recommended packages:      yes

configure: WARNING: you cannot build info or HTML versions of the R manuals
configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF
vignettes and package manuals will not be rendered optimally


Thanks for looking at this; it's odd...

Tom

On Sun, Nov 8, 2015 at 5:16 PM, Dylan Beaudette <dylan.beaudette at gmail.com>
wrote:

> Hi Tom,
>
> I have encountered this in the past when compiling without X11
> support, thinking that I wouldn't need it on a headless server. Turns
> out you need X11 (or at least Cairo) for a working graphics device for
> PNG and JPG formats. Any chance that you can post your configure
> arguments or build information?
>
> Dylan
>
> On Sun, Nov 8, 2015 at 2:42 PM, Thomas Adams <tea3rd at gmail.com> wrote:
> > Edzer,
> >
> > That's the problem... dev.list() returns NULL -- I don't understand. I
> > built R from source and did not see any problems. Any thoughts what I
> > should look for in building R correctly? I have built R from source many
> > times in the past and I have never encountered this kind of problem.
> >
> > Thank you!
> >
> > Tom
> >
> > On Sun, Nov 8, 2015 at 2:49 PM, Edzer Pebesma <
> edzer.pebesma at uni-muenster.de
> >> wrote:
> >
> >> Me too.
> >>
> >> > dev.list()
> >> X11cairo
> >>        2
> >>
> >> What is your output of dev.list()? does plot(meuse.sr) work?
> >>
> >>
> >> On 08/11/15 21:45, Tim Appelhans wrote:
> >> > Hi Tom,
> >> > on Ubuntu 14.04 I can reproduce fig07.R without any problem
> >> > my sessionInfo()
> >> >
> >> > R version 3.2.2 (2015-08-14)
> >> > Platform: x86_64-pc-linux-gnu (64-bit)
> >> > Running under: Ubuntu 14.04.3 LTS
> >> >
> >> > locale:
> >> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=de_DE.UTF-8
> >> >  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8
> >> > LC_MESSAGES=en_US.UTF-8
> >> >  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C LC_ADDRESS=C
> >> > [10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8
> >> > LC_IDENTIFICATION=C
> >> >
> >> > attached base packages:
> >> > [1] stats     graphics  grDevices utils     datasets  methods base
> >> >
> >> > other attached packages:
> >> > [1] lattice_0.20-33 sp_1.2-1        gstat_1.1-0
> >> >
> >> > loaded via a namespace (and not attached):
> >> > [1] zoo_1.7-12       tools_3.2.2      xts_0.9-7 spacetime_1.1-4
> >> > grid_3.2.2       FNN_1.1
> >> > [7] intervals_0.15.1
> >> >
> >> > Cheers
> >> > Tim
> >> >
> >> > On 08.11.2015 21:37, Thomas Adams wrote:
> >> >> All:
> >> >>
> >> >> I was previously able to do the kind of thing I will illustrate below
> >> >> on an
> >> >> Intel based RedHat Linux system a few years ago. The simple task is
> to
> >> >> use
> >> >> GRASS GIS with R, reading both raster and vector data into R through
> >> >> rgrass7 (previously with spgrass6). Using spplot, display the raster
> and
> >> >> overlay the vector polygon (a river basin boundary) for reference.
> As I
> >> >> said, I have previously done this with success. However, now
> >> >> overlaying the
> >> >> vector polygon fails, both with my own data and with the following
> >> >> example:
> >> >> http://rspatial.r-forge.r-project.org/gallery/ -- see the example
> for
> >> >> fig07.RThe raster data draws, but I get the following...
> >> >>
> >> >>> spplot(zn, c("a", "b", "c", "d"),
> >> >> + names.attr = c("ordinary kriging", "universal kriging with dist to
> >> >> river",
> >> >> + "stratified kriging with flood freq", "inverse distance"),
> >> >> + as.table = TRUE, main = "log-zinc interpolation",
> >> >> + sp.layout = list(rv, scale, text1, text2))
> >> >>
> >> >> Warning messages:
> >> >> 1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> >> winding =
> >> >> 1L,  :
> >> >>    Path drawing not available for this device
> >> >> 2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> >> winding =
> >> >> 1L,  :
> >> >>    Path drawing not available for this device
> >> >> 3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> >> winding =
> >> >> 1L,  :
> >> >>    Path drawing not available for this device
> >> >> 4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> >> >> winding =
> >> >> 1L,  :
> >> >>    Path drawing not available for this device
> >> >>
> >> >>
> >> >> I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for
> others
> >> >> having this problem to no avail...
> >> >>
> >> >> Thank you for your help.
> >> >>
> >> >> Best,
> >> >> Tom
> >> >>
> >> >>
> >> >> --
> >> >>
> >> >>     [[alternative HTML version deleted]]
> >> >>
> >> >> _______________________________________________
> >> >> R-sig-Geo mailing list
> >> >> R-sig-Geo at r-project.org
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> >
> >>
> >> --
> >> Edzer Pebesma
> >> Institute for Geoinformatics (ifgi),  University of M?nster,
> >> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> >> Journal of Statistical Software:   http://www.jstatsoft.org/
> >> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> >> Spatial Statistics Society http://www.spatialstatistics.info
> >>
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >
> >
> > --
> > Thomas E Adams, III
> > 2330 Jack Warner PKWY, #334
> > Tuscaloosa, AL 35401
> >
> > 1 (513) 739-9512 (cell)
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Thomas E Adams, III
2330 Jack Warner PKWY, #334
Tuscaloosa, AL 35401

1 (513) 739-9512 (cell)

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Mon Nov  9 10:07:09 2015
From: englishchristophera at gmail.com (chris english)
Date: Mon, 9 Nov 2015 04:07:09 -0500
Subject: [R-sig-Geo] spplot graphics problem
In-Reply-To: <CAGxgkWhg6sekmuatWCgDRyPBC+cV-8rGemip=iqqSm3q+UADmg@mail.gmail.com>
References: <CAGxgkWj+b0TJbOyPrVEtRGQmJs5QzLiccfHqg_VkSdgtGsZHBA@mail.gmail.com>
	<563FB46E.4040105@gmail.com> <563FB55E.3000205@uni-muenster.de>
	<CAGxgkWh_qqiV84MAMV-Mtkwdu+oAH5SAndk3qo3dFTyZibLnsw@mail.gmail.com>
	<CAOGWcHJwK0f_ycw3yCjxwGs1-6Y7Zzzj5Uw-ph0GbJxkjDk6Og@mail.gmail.com>
	<CAGxgkWhg6sekmuatWCgDRyPBC+cV-8rGemip=iqqSm3q+UADmg@mail.gmail.com>
Message-ID: <CAASFQpTdr3ptV2mbL+Ne7QCfy7Zq0-=KqYep=4DwJRYWMi94gg@mail.gmail.com>

Tom,

Take a look at this discussion.
http://r.789695.n4.nabble.com/Compilation-problems-td4695292.html

and try the kpsewhich inconsolata.sty
                  kpsewhich zi4.sty

But it looks like you need the Ubuntu texinfo package judging from the
config warnings as
X11 is otherwise compiling properly.  Which is just to say that a device
might not be
spawned if the 'what is to be rendered' is not render-able, and probably
without
warning. Silent death or sorts.

> dev.list()
X11cairo
       2
> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.3 LTS

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] maptools_0.8-37  maps_3.0.0-2     rgeos_0.3-13     ggplot2_1.0.1
[5] sp_1.2-1         deldir_0.1-9     animation_2.4    data.table_1.9.6

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.1      magrittr_1.5     MASS_7.3-44      munsell_0.4.2
 [5] colorspace_1.2-6 lattice_0.20-33  stringr_1.0.0    plyr_1.8.3
 [9] tcltk_3.2.2      tools_3.2.2      grid_3.2.2       gtable_0.1.2
[13] digest_0.6.8     reshape2_1.4.1   labeling_0.3     stringi_1.0-1
[17] scales_0.3.0     foreign_0.8-66   chron_2.3-47     proto_0.3-10
>

HTH,
Chris

On Sun, Nov 8, 2015 at 6:22 PM, Thomas Adams <tea3rd at gmail.com> wrote:

> Hi Dylan,
>
> I'm using ./configure without any options, installing in /usr/local
>
> teaiii at teaiii-Leopard-WS:~/R-3.2.2$ ./configure
> checking build system type... x86_64-pc-linux-gnu
> checking host system type... x86_64-pc-linux-gnu
> loading site script './config.site'
> loading build-specific script './config.site'
> checking for pwd... /bin/pwd
> checking whether builddir is srcdir... yes
> checking for working aclocal... missing
> checking for working autoconf... missing
> checking for working automake... missing
> checking for working autoheader... missing
> checking for gawk... no
> checking for mawk... mawk
> checking whether ln -s works... yes
> checking for bison... bison -y
> checking for ar... ar
> checking for a BSD-compatible install... /usr/bin/install -c
> checking for sed... /bin/sed
> checking for which... /usr/bin/which
> checking for less... /usr/bin/less
> checking for gtar... no
> checking for gnutar... no
> checking for tar... /bin/tar
> checking for tex... /usr/bin/tex
> checking for pdftex... /usr/bin/pdftex
> checking for pdflatex... /usr/bin/pdflatex
> checking for makeindex... /usr/bin/makeindex
> checking for texi2any... no
> configure: WARNING: you cannot build info or HTML versions of the R manuals
> checking for texi2dvi... no
> checking for kpsewhich... /usr/bin/kpsewhich
> checking for latex inconsolata package... missing
> configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF
> vignettes and package manuals will not be rendered optimally
> checking for unzip... /usr/bin/unzip
> checking for zip... /usr/bin/zip
> checking for gzip... /bin/gzip
> checking for bzip2... /bin/bzip2
> checking for firefox... /usr/bin/firefox
> using default browser ... /usr/bin/firefox
> checking for acroread... no
> checking for acroread4... no
> checking for xdg-open... /usr/bin/xdg-open
> checking for notangle... false
> checking for realpath... /usr/bin/realpath
> checking for pkg-config... /usr/bin/pkg-config
> checking for gcc... gcc
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking whether gcc needs -traditional... no
> checking how to run the C preprocessor... gcc -E
> checking for gfortran... gfortran
> checking whether we are using the GNU Fortran 77 compiler... yes
> checking whether gfortran accepts -g... yes
> checking for g++... g++
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking how to run the C++ preprocessor... g++ -E
> checking whether __attribute__((visibility())) is supported... yes
> checking whether gcc accepts -fvisibility... yes
> checking whether gfortran accepts -fvisibility... yes
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking minix/config.h usability... no
> checking minix/config.h presence... no
> checking for minix/config.h... no
> checking whether it is safe to define __EXTENSIONS__... yes
> checking for gcc... gcc
> checking whether we are using the GNU Objective C compiler... no
> checking whether gcc accepts -g... no
> checking for Objective C++ compiler... trying some possibilities
> checking whether g++ can compile ObjC++... no
> checking whether  can compile ObjC++... no
> no working ObjC++ compiler found
> checking for a sed that does not truncate output... (cached) /bin/sed
> checking for fgrep... /bin/grep -F
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
> checking the name lister (/usr/bin/nm -B) interface... BSD nm
> checking the maximum length of command line arguments... 1572864
> checking whether the shell understands some XSI constructs... yes
> checking whether the shell understands "+="... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for objdump... objdump
> checking how to recognize dependent libraries... pass_all
> checking for strip... strip
> checking for ranlib... ranlib
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for dlfcn.h... yes
> checking whether we are using the GNU C++ compiler... (cached) yes
> checking whether g++ accepts -g... (cached) yes
> checking how to run the C++ preprocessor... g++ -E
> checking whether we are using the GNU Fortran 77 compiler... (cached) yes
> checking whether gfortran accepts -g... (cached) yes
> checking for objdir... .libs
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC -DPIC
> checking if gcc PIC flag -fPIC -DPIC works... yes
> checking if gcc static flag -static works... yes
> checking if gcc supports -c -o file.o... yes
> checking if gcc supports -c -o file.o... (cached) yes
> checking whether the gcc linker (/usr/bin/ld) supports shared libraries...
> yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking for ld used by g++... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared libraries...
> yes
> checking for g++ option to produce PIC... -fPIC -DPIC
> checking if g++ PIC flag -fPIC -DPIC works... yes
> checking if g++ static flag -static works... yes
> checking if g++ supports -c -o file.o... yes
> checking if g++ supports -c -o file.o... (cached) yes
> checking whether the g++ linker (/usr/bin/ld) supports shared libraries...
> yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking for gfortran option to produce PIC... -fPIC
> checking if gfortran PIC flag -fPIC works... yes
> checking if gfortran static flag -static works... yes
> checking if gfortran supports -c -o file.o... yes
> checking if gfortran supports -c -o file.o... (cached) yes
> checking whether the gfortran linker (/usr/bin/ld) supports shared
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking for cos in -lm... yes
> checking for sin in -lm... yes
> checking for dlopen in -ldl... yes
> checking readline/history.h usability... yes
> checking readline/history.h presence... yes
> checking for readline/history.h... yes
> checking readline/readline.h usability... yes
> checking readline/readline.h presence... yes
> checking for readline/readline.h... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... yes
> checking for rl_callback_read_char in -lreadline... yes
> checking for history_truncate_file... yes
> checking whether rl_completion_matches exists and is declared... yes
> checking for ANSI C header files... (cached) yes
> checking for dirent.h that defines DIR... yes
> checking for library containing opendir... none required
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking arpa/inet.h usability... yes
> checking arpa/inet.h presence... yes
> checking for arpa/inet.h... yes
> checking dl.h usability... no
> checking dl.h presence... no
> checking for dl.h... no
> checking for dlfcn.h... (cached) yes
> checking elf.h usability... yes
> checking elf.h presence... yes
> checking for elf.h... yes
> checking features.h usability... yes
> checking features.h presence... yes
> checking for features.h... yes
> checking fcntl.h usability... yes
> checking fcntl.h presence... yes
> checking for fcntl.h... yes
> checking floatingpoint.h usability... no
> checking floatingpoint.h presence... no
> checking for floatingpoint.h... no
> checking fpu_control.h usability... yes
> checking fpu_control.h presence... yes
> checking for fpu_control.h... yes
> checking glob.h usability... yes
> checking glob.h presence... yes
> checking for glob.h... yes
> checking grp.h usability... yes
> checking grp.h presence... yes
> checking for grp.h... yes
> checking langinfo.h usability... yes
> checking langinfo.h presence... yes
> checking for langinfo.h... yes
> checking netdb.h usability... yes
> checking netdb.h presence... yes
> checking for netdb.h... yes
> checking netinet/in.h usability... yes
> checking netinet/in.h presence... yes
> checking for netinet/in.h... yes
> checking pwd.h usability... yes
> checking pwd.h presence... yes
> checking for pwd.h... yes
> checking sched.h usability... yes
> checking sched.h presence... yes
> checking for sched.h... yes
> checking for strings.h... (cached) yes
> checking sys/param.h usability... yes
> checking sys/param.h presence... yes
> checking for sys/param.h... yes
> checking sys/resource.h usability... yes
> checking sys/resource.h presence... yes
> checking for sys/resource.h... yes
> checking sys/select.h usability... yes
> checking sys/select.h presence... yes
> checking for sys/select.h... yes
> checking sys/socket.h usability... yes
> checking sys/socket.h presence... yes
> checking for sys/socket.h... yes
> checking for sys/stat.h... (cached) yes
> checking sys/time.h usability... yes
> checking sys/time.h presence... yes
> checking for sys/time.h... yes
> checking sys/times.h usability... yes
> checking sys/times.h presence... yes
> checking for sys/times.h... yes
> checking sys/utsname.h usability... yes
> checking sys/utsname.h presence... yes
> checking for sys/utsname.h... yes
> checking for unistd.h... (cached) yes
> checking utime.h usability... yes
> checking utime.h presence... yes
> checking for utime.h... yes
> checking stdalign.h usability... yes
> checking stdalign.h presence... yes
> checking for stdalign.h... yes
> checking errno.h usability... yes
> checking errno.h presence... yes
> checking for errno.h... yes
> checking for inttypes.h... (cached) yes
> checking limits.h usability... yes
> checking limits.h presence... yes
> checking for limits.h... yes
> checking locale.h usability... yes
> checking locale.h presence... yes
> checking for locale.h... yes
> checking stdarg.h usability... yes
> checking stdarg.h presence... yes
> checking for stdarg.h... yes
> checking stdbool.h usability... yes
> checking stdbool.h presence... yes
> checking for stdbool.h... yes
> checking for stdint.h... (cached) yes
> checking for string.h... (cached) yes
> checking whether setjmp.h is POSIX.1 compatible... yes
> checking whether sigsetjmp is declared... yes
> checking whether siglongjmp is declared... yes
> checking for GNU C library with version >= 2... yes
> checking return type of signal handlers... void
> checking for uint64_t... yes
> checking for int64_t... yes
> checking for int_fast64_t... yes
> checking for pid_t... yes
> checking for size_t... yes
> checking whether SIZE_MAX is declared... yes
> checking for blkcnt_t... yes
> checking for type of socket length... socklen_t *
> checking for stack_t... yes
> checking for intptr_t... yes
> checking for uintptr_t... yes
> checking whether byte ordering is bigendian... no
> checking for an ANSI C-conforming const... yes
> checking for gcc option to accept ISO C99... -std=gnu99
> checking for gcc -std=gnu99 option to accept ISO Standard C... (cached)
> -std=gnu99
> checking for inline... inline
> checking size of int... 4
> checking size of long... 8
> checking size of long long... 8
> checking size of double... 8
> checking size of size_t... 8
> checking size of long double... 16
> checking whether we can compute C Make dependencies... yes, using $(CC) -MM
> checking whether gcc -std=gnu99 supports -c -o FILE.lo... yes
> checking for gcc -std=gnu99 option to support OpenMP... -fopenmp
> checking how to get verbose linking output from gfortran... -v
> checking for Fortran 77 libraries of gfortran...  -L/usr/local/lib
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../x86_64-linux-gnu
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../../lib -L/lib/x86_64-linux-gnu
> -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../.. -lgfortran -lm -lquadmath
> checking how to get verbose linking output from gcc -std=gnu99... -v
> checking for C libraries of gcc -std=gnu99...  -L/usr/local/lib
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../x86_64-linux-gnu
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../../../lib -L/lib/x86_64-linux-gnu
> -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib
> -L/usr/lib/gcc/x86_64-linux-gnu/4.9/../../.. -lgcc_s
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... lower case, underscore, no
> extra underscore
> checking whether gfortran appends underscores to external names... yes
> checking whether gfortran appends extra underscores to external names... no
> checking whether mixed C/Fortran code can be run... yes
> checking whether gfortran and gcc -std=gnu99 agree on int and double... yes
> checking whether gfortran and gcc -std=gnu99 agree on double complex... yes
> checking for gfortran option to support OpenMP... -fopenmp
> checking whether g++ accepts -M for generating dependencies... yes
> checking for g++ option to support OpenMP... -fopenmp
> checking whether we can compute ObjC Make dependencies... no
> checking whether C runtime needs -D__NO_MATH_INLINES... no
> checking for xmkmf... no
> checking whether g++  supports C++11 features by default... no
> checking whether g++  supports C++11 features with -std=c++11... yes
> checking for off_t... yes
> checking for working alloca.h... yes
> checking for alloca... yes
> checking whether alloca is declared... yes
> checking whether expm1 exists and is declared... yes
> checking whether hypot exists and is declared... yes
> checking whether log1p exists and is declared... yes
> checking whether log1pl exists and is declared... yes
> checking whether log2 exists and is declared... yes
> checking whether log10 exists and is declared... yes
> checking whether nearbyint exists and is declared... yes
> checking whether nearbyintl exists and is declared... yes
> checking whether powl exists and is declared... yes
> checking whether rint exists and is declared... yes
> checking whether rintl exists and is declared... yes
> checking whether va_copy exists and is declared... yes
> checking for isblank... yes
> checking sunmath.h usability... no
> checking sunmath.h presence... no
> checking for sunmath.h... no
> checking for cospi in -lsunmath... no
> checking for atanpi... no
> checking for atan2pi... no
> checking for cospi... no
> checking for exp10... yes
> checking for pown... no
> checking for sinpi... no
> checking for tanpi... no
> checking for fseeko... yes
> checking for ftello... yes
> checking for matherr... yes
> checking whether fcntl exists and is declared... yes
> checking whether getgrgid exists and is declared... yes
> checking whether getpwuid exists and is declared... yes
> checking whether kill exists and is declared... yes
> checking whether sigaction exists and is declared... yes
> checking whether sigaltstack exists and is declared... yes
> checking whether sigemptyset exists and is declared... yes
> checking whether fdopen exists and is declared... yes
> checking whether popen exists and is declared... yes
> checking whether setenv exists and is declared... yes
> checking whether unsetenv exists and is declared... yes
> checking whether getrlimit exists and is declared... yes
> checking whether getrusage exists and is declared... yes
> checking whether getpriority exists and is declared... yes
> checking whether chmod exists and is declared... yes
> checking whether mkfifo exists and is declared... yes
> checking whether stat exists and is declared... yes
> checking whether umask exists and is declared... yes
> checking whether gettimeofday exists and is declared... yes
> checking whether utimes exists and is declared... yes
> checking whether times exists and is declared... yes
> checking whether gmtime_r exists and is declared... yes
> checking whether localtime_r exists and is declared... yes
> checking whether nl_langinfo exists and is declared... yes
> checking whether access exists and is declared... yes
> checking whether chdir exists and is declared... yes
> checking whether execv exists and is declared... yes
> checking whether ftruncate exists and is declared... yes
> checking whether getcwd exists and is declared... yes
> checking whether geteuid exists and is declared... yes
> checking whether getuid exists and is declared... yes
> checking whether link exists and is declared... yes
> checking whether readlink exists and is declared... yes
> checking whether symlink exists and is declared... yes
> checking whether sysconf exists and is declared... yes
> checking whether sched_setaffinity exists and is declared... yes
> checking whether sched_getaffinity exists and is declared... yes
> checking whether utime exists and is declared... yes
> checking for clock_gettime in -lrt... yes
> checking whether clock_gettime exists and is declared... yes
> checking whether timespec_get exists and is declared... yes
> checking for putenv... yes
> checking whether putenv is declared... yes
> checking for vasprintf... yes
> checking whether vasprintf is declared... yes
> checking for mempcpy... yes
> checking for realpath... yes
> checking whether realpath is declared... yes
> checking whether glob exists and is declared... yes
> checking for isnan... yes
> checking whether isfinite is declared... yes
> checking whether isnan is declared... yes
> checking whether you have IEEE 754 floating-point arithmetic... yes
> checking whether putenv("FOO") can unset an environment variable... yes
> checking whether putenv("FOO=") can unset an environment variable... no
> checking for nl_langinfo and CODESET... yes
> checking for mkdtemp... yes
> checking for strdup... yes
> checking for strncasecmp... yes
> checking whether mkdtemp is declared... yes
> checking whether strdup is declared... yes
> checking whether strncasecmp is declared... yes
> checking for library containing connect... none required
> checking for library containing gethostbyname... none required
> checking for library containing xdr_string... none required
> checking for __setfpucw... no
> checking for working calloc... yes
> checking for working isfinite... yes
> checking for working log1p... yes
> checking whether ftell works correctly on files opened for append... yes
> checking for working sigaction... yes
> checking whether mktime sets errno... no
> checking whether mktime works correctly outside 1902-2037... yes
> checking complex.h usability... yes
> checking complex.h presence... yes
> checking for complex.h... yes
> checking for double complex... yes
> checking whether C99 double complex is supported... yes
> checking whether cabs exists and is declared... yes
> checking whether carg exists and is declared... yes
> checking whether cexp exists and is declared... yes
> checking whether clog exists and is declared... yes
> checking whether csqrt exists and is declared... yes
> checking whether cpow exists and is declared... yes
> checking whether ccos exists and is declared... yes
> checking whether csin exists and is declared... yes
> checking whether ctan exists and is declared... yes
> checking whether cacos exists and is declared... yes
> checking whether casin exists and is declared... yes
> checking whether catan exists and is declared... yes
> checking whether ccosh exists and is declared... yes
> checking whether csinh exists and is declared... yes
> checking whether ctanh exists and is declared... yes
> checking whether 'struct tm' includes tm_zone... yes
> checking whether 'struct tm' includes tm_gmtoff... yes
> checking iconv.h usability... yes
> checking iconv.h presence... yes
> checking for iconv.h... yes
> checking for iconv... yes
> checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"...
> yes
> checking for iconvlist... no
> checking for iconv... yes
> checking for iconv declaration...
>          extern size_t iconv (iconv_t cd, char * *inbuf, size_t
> *inbytesleft, char * *outbuf, size_t *outbytesleft);
> checking wchar.h usability... yes
> checking wchar.h presence... yes
> checking for wchar.h... yes
> checking wctype.h usability... yes
> checking wctype.h presence... yes
> checking for wctype.h... yes
> checking whether mbrtowc exists and is declared... yes
> checking whether wcrtomb exists and is declared... yes
> checking whether wcscoll exists and is declared... yes
> checking whether wcsftime exists and is declared... yes
> checking whether wcstod exists and is declared... yes
> checking whether mbstowcs exists and is declared... yes
> checking whether wcstombs exists and is declared... yes
> checking whether wctrans exists and is declared... yes
> checking whether iswblank exists and is declared... yes
> checking whether wctype exists and is declared... yes
> checking whether iswctype exists and is declared... yes
> checking for wctrans_t... yes
> checking for mbstate_t... yes
> checking for ICU... yes
> checking for X... libraries , headers
> checking for gethostbyname... yes
> checking for connect... yes
> checking for remove... yes
> checking for shmat... yes
> checking for IceConnectionNumber in -lICE... yes
> checking X11/Intrinsic.h usability... yes
> checking X11/Intrinsic.h presence... yes
> checking for X11/Intrinsic.h... yes
> checking for XtToolkitInitialize in -lXt... yes
> using X11 ... yes
> checking for KeySym... yes
> checking X11/Xmu/Atoms.h usability... yes
> checking X11/Xmu/Atoms.h presence... yes
> checking for X11/Xmu/Atoms.h... yes
> checking for XmuInternAtom in -lXmu... yes
> checking whether pkg-config knows about cairo and pango... no
> checking whether pkg-config knows about cairo... yes
> checking whether cairo is >= 1.2 and works... yes
> checking for tclConfig.sh... no
> checking for tclConfig.sh in library (sub)directories... no
> checking for tkConfig.sh... no
> checking for tkConfig.sh in library (sub)directories... no
> checking for tcl.h... no
> checking for BSD networking... yes
> checking if jpeglib version >= 6b... yes
> checking for jpeg_destroy_compress in -ljpeg... yes
> checking for main in -lz... yes
> checking if libpng version >= 1.2.7... yes
> checking for png_create_write_struct in -lpng... yes
> checking tiffio.h usability... yes
> checking tiffio.h presence... yes
> checking for tiffio.h... yes
> checking for TIFFOpen in -ltiff... yes
> checking rpc/types.h usability... yes
> checking rpc/types.h presence... yes
> checking for rpc/types.h... yes
> checking for rpc/xdr.h... yes
> checking for XDR support... yes
> checking for inflateInit2_ in -lz... yes
> checking zlib.h usability... yes
> checking zlib.h presence... yes
> checking for zlib.h... yes
> checking if zlib version >= 1.2.5... yes
> checking whether zlib support needs to be compiled... no
> checking for BZ2_bzlibVersion in -lbz2... no
> checking whether bzip2 support needs to be compiled... yes
> checking for lzma_version_number in -llzma... yes
> checking lzma.h usability... yes
> checking lzma.h presence... yes
> checking for lzma.h... yes
> checking if lzma version >= 5.0.3... yes
> checking for pcre_fullinfo in -lpcre... yes
> checking pcre.h usability... yes
> checking pcre.h presence... yes
> checking for pcre.h... yes
> checking pcre/pcre.h usability... no
> checking pcre/pcre.h presence... no
> checking for pcre/pcre.h... no
> checking if PCRE version >= 8.10, < 10.0 and has UTF-8 support... yes
> checking whether PCRE support needs to be compiled... no
> checking for curl-config... /usr/bin/curl-config
> libcurl 7.38.0
> checking if libcurl version >= 7.28.0... yes
> checking curl/curl.h usability... yes
> checking curl/curl.h presence... yes
> checking for curl/curl.h... yes
> checking whether leap seconds are treated according to POSIX... yes
> checking for inline... inline
> checking for sys/time.h... (cached) yes
> checking for stdlib.h... (cached) yes
> checking for unistd.h... (cached) yes
> checking for sys/param.h... (cached) yes
> checking for struct stat.st_atim.tv_nsec... yes
> checking whether struct stat.st_atim is of type struct timespec... yes
> checking for setitimer... yes
> checking for special C compiler options needed for large files... no
> checking for _FILE_OFFSET_BITS value needed for large files... no
> checking for _LARGEFILE_SOURCE value needed for large files... no
> checking whether KERN_USRSTACK sysctl is supported... no
> checking for visible __lib_stack_end... yes
> checking for lpr... lpr
> checking for paperconf... /usr/bin/paperconf
> checking for gfortran... gfortran
> checking whether we are using the GNU Fortran compiler... yes
> checking whether gfortran accepts -g... yes
> checking whether we are using the GNU Fortran compiler... (cached) yes
> checking whether gfortran accepts -g... (cached) yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking for gfortran option to produce PIC... -fPIC
> checking if gfortran PIC flag -fPIC works... yes
> checking if gfortran static flag -static works... yes
> checking if gfortran supports -c -o file.o... yes
> checking if gfortran supports -c -o file.o... (cached) yes
> checking whether the gfortran linker (/usr/bin/ld) supports shared
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking for Fortran flag to compile .f90 files... none
> checking for Fortran flag to compile .f95 files... none
> checking for gfortran option to support OpenMP... -fopenmp
> checking for recommended packages... yes
> checking whether NLS is requested... yes
>
> Configuring src/extra/intl directory
> checking for a thread-safe mkdir -p... /bin/mkdir -p
> checking whether we are using the GNU C Library 2 or newer... yes
> checking for ranlib... (cached) ranlib
> checking for simple visibility declarations... yes
> checking for stdint.h... yes
> checking for getpagesize... yes
> checking for working mmap... yes
> checking whether integer division by zero raises SIGFPE... yes
> checking for inttypes.h... yes
> checking for unsigned long long int... yes
> checking for inttypes.h... (cached) yes
> checking whether the inttypes.h PRIxNN macros are broken... no
> checking whether imported symbols can be declared weak... yes
> checking for multithread API to use... none
> checking argz.h usability... yes
> checking argz.h presence... yes
> checking for argz.h... yes
> checking for inttypes.h... (cached) yes
> checking for limits.h... (cached) yes
> checking for unistd.h... (cached) yes
> checking for sys/param.h... (cached) yes
> checking for getcwd... yes
> checking for getegid... yes
> checking for geteuid... yes
> checking for getgid... yes
> checking for getuid... yes
> checking for mempcpy... (cached) yes
> checking for munmap... yes
> checking for stpcpy... yes
> checking for strcasecmp... yes
> checking for strdup... (cached) yes
> checking for strtoul... yes
> checking for tsearch... yes
> checking for argz_count... yes
> checking for argz_stringify... yes
> checking for argz_next... yes
> checking for __fsetlocking... yes
> checking whether feof_unlocked is declared... yes
> checking whether fgets_unlocked is declared... yes
> checking for iconv... (cached) yes
> checking for iconv declaration... (cached)
>          extern size_t iconv (iconv_t cd, char * *inbuf, size_t
> *inbytesleft, char * *outbuf, size_t *outbytesleft);
> checking for NL_LOCALE_NAME macro... yes
> checking for bison... bison
> checking version of bison... 3.0.2, ok
> checking for long long int... yes
> checking for long double... yes
> checking for wchar_t... yes
> checking for wint_t... yes
> checking for intmax_t... yes
> checking whether printf() supports POSIX/XSI format strings... yes
> checking whether we are using the GNU C Library 2.1 or newer... yes
> checking for stdint.h... (cached) yes
> checking for SIZE_MAX... yes
> checking for stdint.h... (cached) yes
> checking for CFPreferencesCopyAppValue... no
> checking for CFLocaleCopyCurrent... no
> checking for ptrdiff_t... yes
> checking stddef.h usability... yes
> checking stddef.h presence... yes
> checking for stddef.h... yes
> checking for stdlib.h... (cached) yes
> checking for string.h... (cached) yes
> checking for asprintf... yes
> checking for fwprintf... yes
> checking for putenv... (cached) yes
> checking for setenv... yes
> checking for setlocale... yes
> checking for snprintf... yes
> checking for wcslen... yes
> checking whether _snprintf is declared... no
> checking whether _snwprintf is declared... no
> checking whether getc_unlocked is declared... yes
> checking for nl_langinfo and CODESET... (cached) yes
> checking for LC_MESSAGES... yes
> checking for shared library run path origin... done
> checking for CFPreferencesCopyAppValue... (cached) no
> checking for CFLocaleCopyCurrent... (cached) no
> checking whether included gettext is requested... no
> checking for GNU gettext in libc... yes
> checking whether to use NLS... yes
> checking where the gettext function comes from... libc
> Finished configuring src/extra/intl directory
>
> using as R_SHELL for scripts ... /bin/bash
> configure: creating ./config.status
> config.status: creating Makeconf
> config.status: creating Makefile
> config.status: creating doc/Makefile
> config.status: creating doc/html/Makefile
> config.status: creating doc/manual/Makefile
> config.status: creating etc/Makefile
> config.status: creating etc/Makeconf
> config.status: creating etc/Renviron
> config.status: creating etc/javaconf
> config.status: creating etc/ldpaths
> config.status: creating m4/Makefile
> config.status: creating po/Makefile
> config.status: creating share/Makefile
> config.status: creating src/Makefile
> config.status: creating src/appl/Makefile
> config.status: creating src/extra/Makefile
> config.status: creating src/extra/blas/Makefile
> config.status: creating src/extra/bzip2/Makefile
> config.status: creating src/extra/intl/Makefile
> config.status: creating src/extra/pcre/Makefile
> config.status: creating src/extra/tre/Makefile
> config.status: creating src/extra/tzone/Makefile
> config.status: creating src/extra/xdr/Makefile
> config.status: creating src/extra/xz/Makefile
> config.status: creating src/extra/zlib/Makefile
> config.status: creating src/include/Makefile
> config.status: creating src/include/Rmath.h0
> config.status: creating src/include/R_ext/Makefile
> config.status: creating src/library/Recommended/Makefile
> config.status: creating src/library/Makefile
> config.status: creating src/library/base/DESCRIPTION
> config.status: creating src/library/base/Makefile
> config.status: creating src/library/compiler/DESCRIPTION
> config.status: creating src/library/compiler/Makefile
> config.status: creating src/library/datasets/DESCRIPTION
> config.status: creating src/library/datasets/Makefile
> config.status: creating src/library/graphics/DESCRIPTION
> config.status: creating src/library/graphics/Makefile
> config.status: creating src/library/graphics/src/Makefile
> config.status: creating src/library/grDevices/DESCRIPTION
> config.status: creating src/library/grDevices/Makefile
> config.status: creating src/library/grDevices/src/Makefile
> config.status: creating src/library/grDevices/src/cairo/Makefile
> config.status: creating src/library/grid/DESCRIPTION
> config.status: creating src/library/grid/Makefile
> config.status: creating src/library/grid/src/Makefile
> config.status: creating src/library/methods/DESCRIPTION
> config.status: creating src/library/methods/Makefile
> config.status: creating src/library/methods/src/Makefile
> config.status: creating src/library/parallel/DESCRIPTION
> config.status: creating src/library/parallel/Makefile
> config.status: creating src/library/parallel/src/Makefile
> config.status: creating src/library/profile/Makefile
> config.status: creating src/library/stats/DESCRIPTION
> config.status: creating src/library/stats/Makefile
> config.status: creating src/library/stats/src/Makefile
> config.status: creating src/library/stats4/DESCRIPTION
> config.status: creating src/library/stats4/Makefile
> config.status: creating src/library/splines/DESCRIPTION
> config.status: creating src/library/splines/Makefile
> config.status: creating src/library/splines/src/Makefile
> config.status: creating src/library/tcltk/DESCRIPTION
> config.status: creating src/library/tcltk/Makefile
> config.status: creating src/library/tcltk/src/Makefile
> config.status: creating src/library/tools/DESCRIPTION
> config.status: creating src/library/tools/Makefile
> config.status: creating src/library/tools/src/Makefile
> config.status: creating src/library/translations/DESCRIPTION
> config.status: creating src/library/translations/Makefile
> config.status: creating src/library/utils/DESCRIPTION
> config.status: creating src/library/utils/Makefile
> config.status: creating src/library/utils/src/Makefile
> config.status: creating src/main/Makefile
> config.status: creating src/modules/Makefile
> config.status: creating src/modules/X11/Makefile
> config.status: creating src/modules/internet/Makefile
> config.status: creating src/modules/lapack/Makefile
> config.status: creating src/nmath/Makefile
> config.status: creating src/nmath/standalone/Makefile
> config.status: creating src/scripts/Makefile
> config.status: creating src/scripts/R.sh
> config.status: creating src/scripts/Rcmd
> config.status: creating src/scripts/f77_f2c
> config.status: creating src/scripts/javareconf
> config.status: creating src/scripts/mkinstalldirs
> config.status: creating src/scripts/pager
> config.status: creating src/scripts/rtags
> config.status: creating src/unix/Makefile
> config.status: creating tests/Makefile
> config.status: creating tests/Embedding/Makefile
> config.status: creating tests/Examples/Makefile
> config.status: creating tools/Makefile
> config.status: creating src/include/config.h
> config.status: executing libtool commands
> config.status: executing stamp-h commands
>
> R is now configured for x86_64-pc-linux-gnu
>
>   Source directory:          .
>   Installation directory:    /usr/local
>
>   C compiler:                gcc -std=gnu99  -g -O2
>   Fortran 77 compiler:       gfortran  -g -O2
>
>   C++ compiler:              g++  -g -O2
>   C++ 11 compiler:           g++  -std=c++11 -g -O2
>   Fortran 90/95 compiler:    gfortran -g -O2
>   Obj-C compiler:
>
>   Interfaces supported:      X11
>   External libraries:        readline, zlib, lzma, PCRE, curl
>   Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo, ICU
>   Options enabled:           shared BLAS, R profiling
>
>   Capabilities skipped:
>   Options not enabled:       memory profiling
>
>   Recommended packages:      yes
>
> configure: WARNING: you cannot build info or HTML versions of the R manuals
> configure: WARNING: neither inconsolata.sty nor zi4.sty found: PDF
> vignettes and package manuals will not be rendered optimally
>
>
> Thanks for looking at this; it's odd...
>
> Tom
>
> On Sun, Nov 8, 2015 at 5:16 PM, Dylan Beaudette <dylan.beaudette at gmail.com
> >
> wrote:
>
> > Hi Tom,
> >
> > I have encountered this in the past when compiling without X11
> > support, thinking that I wouldn't need it on a headless server. Turns
> > out you need X11 (or at least Cairo) for a working graphics device for
> > PNG and JPG formats. Any chance that you can post your configure
> > arguments or build information?
> >
> > Dylan
> >
> > On Sun, Nov 8, 2015 at 2:42 PM, Thomas Adams <tea3rd at gmail.com> wrote:
> > > Edzer,
> > >
> > > That's the problem... dev.list() returns NULL -- I don't understand. I
> > > built R from source and did not see any problems. Any thoughts what I
> > > should look for in building R correctly? I have built R from source
> many
> > > times in the past and I have never encountered this kind of problem.
> > >
> > > Thank you!
> > >
> > > Tom
> > >
> > > On Sun, Nov 8, 2015 at 2:49 PM, Edzer Pebesma <
> > edzer.pebesma at uni-muenster.de
> > >> wrote:
> > >
> > >> Me too.
> > >>
> > >> > dev.list()
> > >> X11cairo
> > >>        2
> > >>
> > >> What is your output of dev.list()? does plot(meuse.sr) work?
> > >>
> > >>
> > >> On 08/11/15 21:45, Tim Appelhans wrote:
> > >> > Hi Tom,
> > >> > on Ubuntu 14.04 I can reproduce fig07.R without any problem
> > >> > my sessionInfo()
> > >> >
> > >> > R version 3.2.2 (2015-08-14)
> > >> > Platform: x86_64-pc-linux-gnu (64-bit)
> > >> > Running under: Ubuntu 14.04.3 LTS
> > >> >
> > >> > locale:
> > >> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C LC_TIME=de_DE.UTF-8
> > >> >  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=de_DE.UTF-8
> > >> > LC_MESSAGES=en_US.UTF-8
> > >> >  [7] LC_PAPER=de_DE.UTF-8       LC_NAME=C LC_ADDRESS=C
> > >> > [10] LC_TELEPHONE=C             LC_MEASUREMENT=de_DE.UTF-8
> > >> > LC_IDENTIFICATION=C
> > >> >
> > >> > attached base packages:
> > >> > [1] stats     graphics  grDevices utils     datasets  methods base
> > >> >
> > >> > other attached packages:
> > >> > [1] lattice_0.20-33 sp_1.2-1        gstat_1.1-0
> > >> >
> > >> > loaded via a namespace (and not attached):
> > >> > [1] zoo_1.7-12       tools_3.2.2      xts_0.9-7 spacetime_1.1-4
> > >> > grid_3.2.2       FNN_1.1
> > >> > [7] intervals_0.15.1
> > >> >
> > >> > Cheers
> > >> > Tim
> > >> >
> > >> > On 08.11.2015 21:37, Thomas Adams wrote:
> > >> >> All:
> > >> >>
> > >> >> I was previously able to do the kind of thing I will illustrate
> below
> > >> >> on an
> > >> >> Intel based RedHat Linux system a few years ago. The simple task is
> > to
> > >> >> use
> > >> >> GRASS GIS with R, reading both raster and vector data into R
> through
> > >> >> rgrass7 (previously with spgrass6). Using spplot, display the
> raster
> > and
> > >> >> overlay the vector polygon (a river basin boundary) for reference.
> > As I
> > >> >> said, I have previously done this with success. However, now
> > >> >> overlaying the
> > >> >> vector polygon fails, both with my own data and with the following
> > >> >> example:
> > >> >> http://rspatial.r-forge.r-project.org/gallery/ -- see the example
> > for
> > >> >> fig07.RThe raster data draws, but I get the following...
> > >> >>
> > >> >>> spplot(zn, c("a", "b", "c", "d"),
> > >> >> + names.attr = c("ordinary kriging", "universal kriging with dist
> to
> > >> >> river",
> > >> >> + "stratified kriging with flood freq", "inverse distance"),
> > >> >> + as.table = TRUE, main = "log-zinc interpolation",
> > >> >> + sp.layout = list(rv, scale, text1, text2))
> > >> >>
> > >> >> Warning messages:
> > >> >> 1: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> > >> >> winding =
> > >> >> 1L,  :
> > >> >>    Path drawing not available for this device
> > >> >> 2: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> > >> >> winding =
> > >> >> 1L,  :
> > >> >>    Path drawing not available for this device
> > >> >> 3: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> > >> >> winding =
> > >> >> 1L,  :
> > >> >>    Path drawing not available for this device
> > >> >> 4: In grid.Call.graphics(L_path, x$x, x$y, index, switch(x$rule,
> > >> >> winding =
> > >> >> 1L,  :
> > >> >>    Path drawing not available for this device
> > >> >>
> > >> >>
> > >> >> I am using Ubuntu 15.10 and R 3.2.2. I have searched the web for
> > others
> > >> >> having this problem to no avail...
> > >> >>
> > >> >> Thank you for your help.
> > >> >>
> > >> >> Best,
> > >> >> Tom
> > >> >>
> > >> >>
> > >> >> --
> > >> >>
> > >> >>     [[alternative HTML version deleted]]
> > >> >>
> > >> >> _______________________________________________
> > >> >> R-sig-Geo mailing list
> > >> >> R-sig-Geo at r-project.org
> > >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >> >
> > >>
> > >> --
> > >> Edzer Pebesma
> > >> Institute for Geoinformatics (ifgi),  University of M?nster,
> > >> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> > >> Journal of Statistical Software:   http://www.jstatsoft.org/
> > >> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> > >> Spatial Statistics Society http://www.spatialstatistics.info
> > >>
> > >>
> > >> _______________________________________________
> > >> R-sig-Geo mailing list
> > >> R-sig-Geo at r-project.org
> > >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > >>
> > >
> > >
> > >
> > > --
> > > Thomas E Adams, III
> > > 2330 Jack Warner PKWY, #334
> > > Tuscaloosa, AL 35401
> > >
> > > 1 (513) 739-9512 (cell)
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > _______________________________________________
> > > R-sig-Geo mailing list
> > > R-sig-Geo at r-project.org
> > > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>
>
> --
> Thomas E Adams, III
> 2330 Jack Warner PKWY, #334
> Tuscaloosa, AL 35401
>
> 1 (513) 739-9512 (cell)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From hiztirab at yahoo.com  Mon Nov  9 10:53:49 2015
From: hiztirab at yahoo.com (Iztirab Hussain)
Date: Mon, 9 Nov 2015 09:53:49 +0000 (UTC)
Subject: [R-sig-Geo] Time sereis data anlysis
References: <65098350.1492467.1447062829350.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <65098350.1492467.1447062829350.JavaMail.yahoo@mail.yahoo.com>

HI every one
I am quite new here and i am want to get 15 days time series ?precipitation data from daily data and to make the different time series (daily weekly, 15 days, monthly and yearly) scatter plot showing the correlation coefficient . So would any one want to share the code and other details.
RegardsShakir

	[[alternative HTML version deleted]]


From rhurlin at gwdg.de  Tue Nov 10 08:44:39 2015
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 10 Nov 2015 08:44:39 +0100
Subject: [R-sig-Geo] rgdal_1.1-1: dsn path string problems
In-Reply-To: <alpine.LFD.2.20.1511082047520.12038@reclus.nhh.no>
References: <563F7B5C.6070703@gwdg.de>
	<alpine.LFD.2.20.1511081747380.9569@reclus.nhh.no>
	<563F8C11.4090706@gwdg.de>
	<alpine.LFD.2.20.1511082047520.12038@reclus.nhh.no>
Message-ID: <5641A067.50306@gwdg.de>

Am 08.11.15 um 20:57 schrieb Roger Bivand:
> On Sun, 8 Nov 2015, Rainer Hurling wrote:
>
>> Hi Roger,
>>
>> many thanks for your quick answer.
>>
>>
>> Am 08.11.15 um 18:02 schrieb Roger Bivand:
>>> On Sun, 8 Nov 2015, Rainer Hurling wrote:
>>>
>>>> Dear Roger, dear list,
>>>>
>>>> many thanks for the newest update 1.1-1 of package rgdal. It is really
>>>> helpful.
>>>>
>>>> I am using rgdal with R-devel and GDAL 2.0.1, both on FreeBSD
>>>> 11.0-CURRENT and Windows7. On both platforms, I have problems with path
>>>> strings in dsn.
>>>>
>>>>
>>>>
>>>> (a) The minor problem is on Windows. While a dsn="C:/some/path" works
>>>> fine, the same path with a slash at the end (dsn="C:/some/path/")
>>>> fails.
>>>>
>>>> On most other software it is conventional to allow a closing slash.
>>>> Wouldn't it be nice, if rgdal would be more tolerant about it?
>>>>
>>>
>>> R base::file.exists does include this in its help file: "However,
>>> directory names must not include a trailing backslash or slash on
>>> Windows".
>>>
>>> so this isn't just rgdal. The dsn= argument for many drivers is a file
>>> name, not a directory; a work-around seems like overkill.
>>
>> OK, that seems reasonable. Of course, rgdal should handle this like R in
>> total. Thanks you for clarification.
>>
>>>>
>>>> Now my main problem:
>>>> (b) On FreeBSD, for some time now, the dsn path can not be used anymore
>>>> to check for existence of a file.
>>>>
>>>> I want to use writeOGR to overwrite an existing shapefile. I use
>>>> something like dsn="/path/to/somewhere" and layer="layername".
>>>>
>>>> Within writeOGR(), R/ogr_write.R calls the C++ function
>>>> 'ogrCheckExists'. ogrCheckExists is not able to return TRUE, if a
>>>> shapefile already exists. Every time its result is FALSE:
>>>>
>>>> R/ogr_write.R
>>>> 61:        ogrI <- .Call("ogrCheckExists", as.character(dsn),
>>>> s.character(layer), PACKAGE = "rgdal")
>>>> [1] FALSE
>>>>
>>>>
>>>> As far, as I can see, 'ogrCheckExists' comes from src/ogrsource.cpp.
>>>> Something must go wrong in that C++ file, at least for FreeBSD :(
>>>>
>>>> Unfortunalety, I have no skills how to debug such a C++ code within
>>>> an R
>>>> package ...
>>>>
>>>
>>> I do not have access to such a system. As a first step, does
>>> rgdal::ogrListLayers work correctly?
>>
>> The syntax, shown in the helpfile, does not work for me:
>>
>> rgdal::ogrListLayers(dsn="/path", layer="layername")
>> Fehler in rgdal::ogrListLayers(dsn = "/path", layer = "layername") :
>>  unbenutztes Argument (layer = "layername")    # unused argument
>>
>
> The helpfile usage section says:
>
> ogrListLayers(dsn)
>
> which works, as you see below, there is no layer argument, as the
> function queries the dsn to ask what layers it contains (differs between
> drivers).
>

Ok, as always, I should read documents more careful ;) Thanks for 
clarification again. It seems, the GDAL2 driver for ESRI shapefiles is a 
very special thing ...

>>
>> The same, with layer integrated in the dsn, works fine:
>>
>> rgdal::ogrListLayers(dsn="/path/layername.shp")
>> [1] "layername"
>> attr(,"driver")
>> [1] "ESRI Shapefile"
>> attr(,"nlayers")
>> [1] 1
>>
>>
>> This leads me to the idea, that the same could work for writeOGR or
>> ogrWrite.R. And yes, this works on FreeBSD:
>>
>> writeOGR(gis.layer, dsn="/path/layername.shp",
>>         layer="layername", driver="ESRI Shapefile",
>>         check_exists=TRUE, overwrite_layer=TRUE)
>>
>> So, I have to double 'layername' here, once in dsn and once in layer.
>> But it should be ok as a workaround until I found the real cause.
>>
>
> I have seen this before in GDAL2; it also happened in GDAL1 where the
> dsn directory contained for example *.dbf without *.shp and *.shx. The
> way dsn is handled does vary a lot between drivers.

I wonder, why it is necessary, to also use the layer="layername" (at 
least on FreeBSD with GDAL2), if the full path and filename in 
dsn="/path/layername.shp" is already given.

For now, I will use this dsn and layer notation for shapefiles with GDAL2.

>
>>>
>>> Beyond that, you'd need to insert Rprintf() statements into the C++ file
>>> to see whether the FALSE result comes from a failure to open the dsn
>>> with a known driver, or from the fact that such a layer is not found in
>>> that dsn.
>>
>> Thanks for the tip. I will investigate into it.
>>
>> A first question to this: If I want to integrate some Rprintf into
>> ogrsource.cpp in the section of ogrCheckExists (lines 832 ...), what is
>> a good syntax to output for example 'ogrSource' and 'Layer'?
>>
>> What I tried at ogrsource.cpp:l834 without success is:
>>
>> Rprintf( "ogrCheckExists: OGRSource %s %p\n", OGRLayer, (void *)
>> ogrSource) ;
>
> You'd need simple "No dns found" after line 860 and "No layer found"
> after line 878 to separate the two FALSE returns, but I guess the cause
> may have been in GDAL2, the shapefile driver, and/or what was in your
> dsn directory.

Ok, I was used to use print statements in debugging code also to get 
variables content, pointers and so on ...

Again, many many thanks for your quick and helpful comments. I now 
understand the driver dependend requirements of GDAL2 a lot more :)

Greetings from G?ttingen,
Rainer

>
> Roger
>
>>
>> It think, I have to wrap 'ogrSource' with some function here? (I am not
>> a C/C++ programmer)
>>
>>>
>>> Does using a different driver help? Does using the shapefile.shp as the
>>> dsn help (I think this works better in GDAL2)?
>>
>> Because using the shapefile.shp as the dsn helps, I did not try a
>> different driver. If this is important for you, I can catch it up later.
>>
>> Thanks again for your help,
>> Rainer
>>
>>>
>>> Hope this helps,
>>>
>>> Roger
>>>
>>>> Any help is really appreciated. Please tell me, if I could try and test
>>>> something. My box has FreeBSD, R-devel, gcc-4.8.5, gdb-7.1.0 ...
>>>>
>>>> Greetings,
>>>> Rainer Hurling
>>>>
>>>>
>>>
>>
>>
>


From Roger.Bivand at nhh.no  Tue Nov 10 09:12:57 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 10 Nov 2015 09:12:57 +0100
Subject: [R-sig-Geo] rgdal_1.1-1: dsn path string problems
In-Reply-To: <5641A067.50306@gwdg.de>
References: <563F7B5C.6070703@gwdg.de>
	<alpine.LFD.2.20.1511081747380.9569@reclus.nhh.no>
	<563F8C11.4090706@gwdg.de>
	<alpine.LFD.2.20.1511082047520.12038@reclus.nhh.no>
	<5641A067.50306@gwdg.de>
Message-ID: <alpine.LFD.2.20.1511100908210.2986@reclus.nhh.no>

On Tue, 10 Nov 2015, Rainer Hurling wrote:

> Am 08.11.15 um 20:57 schrieb Roger Bivand:
>>  On Sun, 8 Nov 2015, Rainer Hurling wrote:
>> 
>> >  Hi Roger,
>> > 
>> >  many thanks for your quick answer.
>> > 
>> > 
>> >  Am 08.11.15 um 18:02 schrieb Roger Bivand:
>> > >  On Sun, 8 Nov 2015, Rainer Hurling wrote:
>> > > 
>> > > >  Dear Roger, dear list,
>> > > > 
>> > > >  many thanks for the newest update 1.1-1 of package rgdal. It is 
>> > > >  really
>> > > >  helpful.
>> > > > 
>> > > >  I am using rgdal with R-devel and GDAL 2.0.1, both on FreeBSD
>> > > >  11.0-CURRENT and Windows7. On both platforms, I have problems with 
>> > > >  path
>> > > >  strings in dsn.
>> > > > 
>> > > > 
>> > > > 
>> > > >  (a) The minor problem is on Windows. While a dsn="C:/some/path" 
>> > > >  works
>> > > >  fine, the same path with a slash at the end (dsn="C:/some/path/")
>> > > >  fails.
>> > > > 
>> > > >  On most other software it is conventional to allow a closing slash.
>> > > >  Wouldn't it be nice, if rgdal would be more tolerant about it?
>> > > > 
>> > > 
>> > >  R base::file.exists does include this in its help file: "However,
>> > >  directory names must not include a trailing backslash or slash on
>> > >  Windows".
>> > > 
>> > >  so this isn't just rgdal. The dsn= argument for many drivers is a file
>> > >  name, not a directory; a work-around seems like overkill.
>> > 
>> >  OK, that seems reasonable. Of course, rgdal should handle this like R in
>> >  total. Thanks you for clarification.
>> > 
>> > > > 
>> > > >  Now my main problem:
>> > > >  (b) On FreeBSD, for some time now, the dsn path can not be used 
>> > > >  anymore
>> > > >  to check for existence of a file.
>> > > > 
>> > > >  I want to use writeOGR to overwrite an existing shapefile. I use
>> > > >  something like dsn="/path/to/somewhere" and layer="layername".
>> > > > 
>> > > >  Within writeOGR(), R/ogr_write.R calls the C++ function
>> > > >  'ogrCheckExists'. ogrCheckExists is not able to return TRUE, if a
>> > > >  shapefile already exists. Every time its result is FALSE:
>> > > > 
>> > > >  R/ogr_write.R
>> > > >  61:        ogrI <- .Call("ogrCheckExists", as.character(dsn),
>> > > >  s.character(layer), PACKAGE = "rgdal")
>> > > >  [1] FALSE
>> > > > 
>> > > > 
>> > > >  As far, as I can see, 'ogrCheckExists' comes from src/ogrsource.cpp.
>> > > >  Something must go wrong in that C++ file, at least for FreeBSD :(
>> > > > 
>> > > >  Unfortunalety, I have no skills how to debug such a C++ code within
>> > > >  an R
>> > > >  package ...
>> > > > 
>> > > 
>> > >  I do not have access to such a system. As a first step, does
>> > >  rgdal::ogrListLayers work correctly?
>> > 
>> >  The syntax, shown in the helpfile, does not work for me:
>> > 
>> >  rgdal::ogrListLayers(dsn="/path", layer="layername")
>> >  Fehler in rgdal::ogrListLayers(dsn = "/path", layer = "layername") :
>> >   unbenutztes Argument (layer = "layername")    # unused argument
>> > 
>>
>>  The helpfile usage section says:
>>
>>  ogrListLayers(dsn)
>>
>>  which works, as you see below, there is no layer argument, as the
>>  function queries the dsn to ask what layers it contains (differs between
>>  drivers).
>> 
>
> Ok, as always, I should read documents more careful ;) Thanks for 
> clarification again. It seems, the GDAL2 driver for ESRI shapefiles is a very 
> special thing ...
>
>> > 
>> >  The same, with layer integrated in the dsn, works fine:
>> > 
>> >  rgdal::ogrListLayers(dsn="/path/layername.shp")
>> >  [1] "layername"
>> >  attr(,"driver")
>> >  [1] "ESRI Shapefile"
>> >  attr(,"nlayers")
>> >  [1] 1
>> > 
>> > 
>> >  This leads me to the idea, that the same could work for writeOGR or
>> >  ogrWrite.R. And yes, this works on FreeBSD:
>> > 
>> >  writeOGR(gis.layer, dsn="/path/layername.shp",
>> >          layer="layername", driver="ESRI Shapefile",
>> >          check_exists=TRUE, overwrite_layer=TRUE)
>> > 
>> >  So, I have to double 'layername' here, once in dsn and once in layer.
>> >  But it should be ok as a workaround until I found the real cause.
>> > 
>>
>>  I have seen this before in GDAL2; it also happened in GDAL1 where the
>>  dsn directory contained for example *.dbf without *.shp and *.shx. The
>>  way dsn is handled does vary a lot between drivers.
>
> I wonder, why it is necessary, to also use the layer="layername" (at least on 
> FreeBSD with GDAL2), if the full path and filename in 
> dsn="/path/layername.shp" is already given.
>
> For now, I will use this dsn and layer notation for shapefiles with GDAL2.

All drivers may be expected to differ in their treatments of the dsn= and 
layer= arguments - both within drivers between GDAL releases and between 
drivers. We benefit from GDAL, and are exposed to the choices changes that 
occur there. Things can be made too "easy" ...

>
>> 
>> > > 
>> > >  Beyond that, you'd need to insert Rprintf() statements into the C++ 
>> > >  file
>> > >  to see whether the FALSE result comes from a failure to open the dsn
>> > >  with a known driver, or from the fact that such a layer is not found 
>> > >  in
>> > >  that dsn.
>> > 
>> >  Thanks for the tip. I will investigate into it.
>> > 
>> >  A first question to this: If I want to integrate some Rprintf into
>> >  ogrsource.cpp in the section of ogrCheckExists (lines 832 ...), what is
>> >  a good syntax to output for example 'ogrSource' and 'Layer'?
>> > 
>> >  What I tried at ogrsource.cpp:l834 without success is:
>> > 
>> >  Rprintf( "ogrCheckExists: OGRSource %s %p\n", OGRLayer, (void *)
>> >  ogrSource) ;
>>
>>  You'd need simple "No dns found" after line 860 and "No layer found"
>>  after line 878 to separate the two FALSE returns, but I guess the cause
>>  may have been in GDAL2, the shapefile driver, and/or what was in your
>>  dsn directory.
>
> Ok, I was used to use print statements in debugging code also to get 
> variables content, pointers and so on ...
>
> Again, many many thanks for your quick and helpful comments. I now understand 
> the driver dependend requirements of GDAL2 a lot more :)

Many of the same types of things happened in < GDAL 2; this version is 
intended to try to be more systematic. Drivers are (were) contributed by 
developers outside GDAL (so not Even Roualt), and change sometimes 
rapidly.

Roger

>
> Greetings from G?ttingen,
> Rainer
>
>>
>>  Roger
>> 
>> > 
>> >  It think, I have to wrap 'ogrSource' with some function here? (I am not
>> >  a C/C++ programmer)
>> > 
>> > > 
>> > >  Does using a different driver help? Does using the shapefile.shp as 
>> > >  the
>> > >  dsn help (I think this works better in GDAL2)?
>> > 
>> >  Because using the shapefile.shp as the dsn helps, I did not try a
>> >  different driver. If this is important for you, I can catch it up later.
>> > 
>> >  Thanks again for your help,
>> >  Rainer
>> > 
>> > > 
>> > >  Hope this helps,
>> > > 
>> > >  Roger
>> > > 
>> > > >  Any help is really appreciated. Please tell me, if I could try and 
>> > > >  test
>> > > >  something. My box has FreeBSD, R-devel, gcc-4.8.5, gdb-7.1.0 ...
>> > > > 
>> > > >  Greetings,
>> > > >  Rainer Hurling
>> > > > 
>> > > > 
>> > > 
>> > 
>> > 
>> 
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no

From debangs at uwaterloo.ca  Tue Nov 10 15:19:27 2015
From: debangs at uwaterloo.ca (Donovan Bangs)
Date: Tue, 10 Nov 2015 09:19:27 -0500
Subject: [R-sig-Geo] Attn RSAGA Users - New Version and User Survey
Message-ID: <006901d11bc2$ceccaae0$6c6600a0$@connect.uwaterloo.ca>

Apologies for cross-posting.

 

Attention RSAGA users: RSAGA version 0.94-4, compatible up to SAGA 2.2.2 is
now available on CRAN and Github:

 

https://github.com/debangs/RSAGA/

 

Please find below a link to a (very short) survey about your RSAGA
experience. To keep your R code working with earlier versions of SAGA-GIS,
we attempt to keep RSAGA functional with as many SAGA versions as practical.
We are interested in hearing from you which versions you use, and any
comments about your experience with RSAGA.

 

http://doodle.com/poll/tqwdfigxg8awkke6

 

Thanks and cheers,

Donovan Bangs


	[[alternative HTML version deleted]]


From andrewcd at gmail.com  Tue Nov 10 16:13:00 2015
From: andrewcd at gmail.com (ACD)
Date: Tue, 10 Nov 2015 10:13:00 -0500
Subject: [R-sig-Geo] Spatial clustering gridded data with missing values
	(over water)
Message-ID: <5642097C.5010604@gmail.com>

I'm trying to cluster a spatial dataset, and use the cluster labels as 
an input to a second process.  I've been using the `spdep` package in R.

I've got gridded data at .5 degree lat/lon resolution.  There are 19 
covariates in the example subset of it linked here: 
https://www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0

The following shows that I can't calculate the minimum spanning tree -- 
a necessary input into `skater` -- when the dataset includes areas 
undefined because they are over water.

How would one get around this?

     system('wget 
https://www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0')
     load('example_data?dl=0')

         1> with(x, plot(lon,lat))
         1> library(spdep)
         1> bh.nb <- 
cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
         1> lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
         Error in data[id.neigh, , drop = FALSE] : subscript out of bounds


If I restrict the data to cut out the missing values, I have no problem:

     x = x[x$lon>-117,]
     bh.nb <- 
cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
     lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
     nb.w <- nb2listw(bh.nb, lcosts, style="B")
     mst.bh <- mstree(nb.w,10)
     res1 <- skater(mst.bh[,1:2], x, 5)
     plot(res1, cbind(x$lon,x$lat), cex.circles=0.035, cex.lab=.7)


How do I get around this over-water problem?  I want to be able to 
cluster the land surfaces, including islands and peninsulas.  I suppose 
that I want islands to be linked to their nearest point of land.

References appreciated as well as fixes to the specific problem with the 
`spdep` interface.

Thanks!
Andrew


From paolo.piras at uniroma3.it  Wed Nov 11 08:44:23 2015
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Wed, 11 Nov 2015 07:44:23 +0000
Subject: [R-sig-Geo] [R-sig-eco] 3d box plot
In-Reply-To: <CAH65v730oJws2g3mSqK1GjCgaVwuy02-PNVP5jHOSAGZh44=SA@mail.gmail.com>
References: <CAKoiDH+wraK65XadF-wVfYxSACF4vGHQfrAyUxZeyF04-dt4sA@mail.gmail.com>
	<HE1PR04MB1161850F402713C771769F3BB3160@HE1PR04MB1161.eurprd04.prod.outlook.com>,
	<CAH65v730oJws2g3mSqK1GjCgaVwuy02-PNVP5jHOSAGZh44=SA@mail.gmail.com>
Message-ID: <HE1PR04MB11611C4B34C0CDD1AEF32F48B3130@HE1PR04MB1161.eurprd04.prod.outlook.com>

Thanks to all who answered to my question; I found your comments very useful;

another option could be

http://www.cpwardell.com/2015/08/28/legoplots-in-r-3d-barplots-in-r/


My original purpose was to plot boxplots by groups for more than a variables (as the comment below does) at different times (the third dimension)


best

paolo



________________________________
Da: Jeremy Chacon <chaco001 at umn.edu>
Inviato: luned? 9 novembre 2015 16.21
A: Paolo Piras
Cc: R-SIG list; r-sig-ecology at r-project.org
Oggetto: Re: [R-sig-eco] 3d box plot

This doesn't directly answer your question, but I would recommend just using a 2d boxplot grouped by the variables. I personally find the 3d one very difficult to read. What about something like this, using ggplot2?

library(ggplot2)

fakeData = c(rnorm(10,1,2), rnorm(10,2,2),rnorm(10,2,2),rnorm(10,3,2))
group1 = c(rep("A",20),rep("B",20))
group2 = rep(c("X","Y"), 20)

df = data.frame(group1,group2, fakeData)
ggplot(df, aes(x = group1, y = fakeData, color = group2))+
  geom_boxplot()

On Sun, Nov 8, 2015 at 5:11 AM, Paolo Piras <paolo.piras at uniroma3.it<mailto:paolo.piras at uniroma3.it>> wrote:
Hi folks,
anyone could address me towards a R function/package able to do a 3d boxplot similar to

http://158.132.155.107/oess/POSH/StatSoft/popups/popup125.gif

Thanks in advance
best
paolo

_______________________________________________
R-sig-ecology mailing list
R-sig-ecology at r-project.org<mailto:R-sig-ecology at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-ecology



--
___________________________________________________________________________

Jeremy M. Chacon, Ph.D.

Post-Doctoral Associate, Harcombe Lab
University of Minnesota
Ecology, Evolution and Behavior


	[[alternative HTML version deleted]]


From phillipjallen830 at gmail.com  Wed Nov 11 15:22:44 2015
From: phillipjallen830 at gmail.com (Phillip Allen)
Date: Wed, 11 Nov 2015 07:22:44 -0700
Subject: [R-sig-Geo] Parse EWKT Polygon/MultiLineString/MultiPolygon Text
Message-ID: <CACUiXmibvuWF83UHZjYUv0XEg4bpRaQALVzJbdbF_LGwLLHeMQ@mail.gmail.com>

Hi all,

Years ago I wrote a short function (below) that parses a Extended Well Know
Text (EWKT) LineString field from PostGIS.  The code is below.  Unlike the
normal R sp functions this has XYZM values.

My problem is it was written for a simple linestring as seen below:
SRID=32611;LINESTRING(0 0 0 0,1 1 1 1,1 2 2 2 )

But now I need to parse multiLineString/multiPolygons, and Polygons all of
which have double & triple parentheses.
SRID=32611;POLYGON((0 0 0 0,4 0 0 1,4 4 2 3,0 4 2 4,0 0 3 5),(1 1 0 0, 2 1
2 2, 2 2 2 3, 1 2 3 4,1 1 0 5))
SRID=32611;MULTILINESTRING((0 0 0 0,1 1 0 1,1 2 2 2),(2 3 2 0,3 2 2 1,5 4 3
3))
SRID=32611;MULTIPOLYGON(((0 0 0 0,4 0 1 0,4 4 1 0,0 4 1 0,0 0 1 0),(1 1 1
0,2 1 1 0,2 2 1 0,1 2 1 0,1 1 0 0)), ((-1 -1 1 0,-1 -2 1 0,-2 -2 1 0,-2 -1
1 0,-1 -1 1 0)))

For the life of me I cannot think of an elegant way to parse it out without
a complicated for-each loop.  Does anyone have an idea of how to parse ewkt
(xyzm)?

I am using these to plot up vertical geological cross-sections in rgl's
plot3d/segments3d with bore-hole data such as this:
>segments3d(ewkt.xyzm2matrix(xsecD$gewkt) )

I hope one day soon sp can handle 2.5D data.

regards,
Phil

ewkt.xyzm2matrix <- function(t) {
# Converts Extented-Well-Know-Text Coordinates to XYZ Coordinate matrix
    t <- gsub("SRID=32611;LINESTRING", "", t)
    t <- unlist(substr(t, 2, nchar(t)-1 ))

    c <- 4
    r <-  length(unlist(strsplit(t,",")))

    t <- gsub(',', ' ', t)
    t <- as.double(unlist(strsplit(t," ")))

    tmat <- matrix(t, r, c, byrow=TRUE)
    tmat <- tmat[, 1:3]
return(tmat)
}

	[[alternative HTML version deleted]]


From sja_sari at yahoo.com  Fri Nov 13 09:58:55 2015
From: sja_sari at yahoo.com (Seyed Jalil Alavi)
Date: Fri, 13 Nov 2015 08:58:55 +0000 (UTC)
Subject: [R-sig-Geo] Relative Mean Error for comparing interpolation methods
References: <1560098924.3469185.1447405135199.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1560098924.3469185.1447405135199.JavaMail.yahoo@mail.yahoo.com>

?Dear All

I am comparing kriging and IDWmethods in mapping Forest Site Productivity?
using10-fold cross validation.

Bothkriging and IDW methods produced negative mean error. Now I want to use?
relativemean error for comparing these methods other than RMSE and mean absolute error.

here is the results of kriging;

mean ofresponse ?variable: 34.76982

meanerror: ?-0.03613827

meanabsolute error: 1.598008

RMSE:2.053376


how can Icalculate relative mean error?

I readsomewhere we can use this function for calculating relative mean?
errorhighlighted with red color:

OK_CV<- krige.cv(Site_Form ~1, ~X+Y, Data, model = model1.out, nfold=10)

# meanerror, ideally 0:

ME_OK<- mean(OK_CV$observed - OK_CV$ var1.pred)
ME_OK

### MeanAbsolutely Error
MAE_OK<- mean(abs(OK_CV$residual))
MAE_OK

###Relative Mean Error
MEr_OK<- (ME_OK/mean(Data$Site_Form))*100
MEr_OK

### RMSE
RMSE_OK<- sqrt(mean(OK_CV$residual^2))
RMSE_OK

###Relative RMSE

RMSEr_OK<- (RMSE_OK/mean(Data$Site_Form))*100
RMSEr_OK


if I use theabove function for relative mean error, the result will be negative!!!

I wouldbe very grateful?if anyone can help me to calculate?
relativemean error in R.

Regards

SJA




	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Nov 13 14:37:32 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 13 Nov 2015 14:37:32 +0100
Subject: [R-sig-Geo] Spatial clustering gridded data with missing values
 (over water)
In-Reply-To: <5642097C.5010604@gmail.com>
References: <5642097C.5010604@gmail.com>
Message-ID: <alpine.LFD.2.20.1511131431230.17643@reclus.nhh.no>

On Tue, 10 Nov 2015, ACD wrote:

> I'm trying to cluster a spatial dataset, and use the cluster labels as an 
> input to a second process.  I've been using the `spdep` package in R.
>
> I've got gridded data at .5 degree lat/lon resolution.  There are 19 
> covariates in the example subset of it linked here: 
> https://www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0
>
> The following shows that I can't calculate the minimum spanning tree -- a 
> necessary input into `skater` -- when the dataset includes areas undefined 
> because they are over water.
>
> How would one get around this?
>
>    system('wget 
> https://www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0')
>     load('example_data?dl=0')
>
>         1> with(x, plot(lon,lat))

No, don't do this, you are obscuring the data. Do first str(x), then build 
the object so that you know what is going on (the object structure 
matches the data representation more closely):

library(sp)
coordinates(x) <- c("lon", "lat")
proj4string(x) <- CRS("+proj=longlat +datum=WGS84")
plot(x)

OK, it's gridded, and n is small, so build the neighbour object using 
polygons, queen neighbours:

gridded(x) <- TRUE
x1 <- as(x, "SpatialPolygonsDataFrame")
library(spdep)
bh.nb <- poly2nb(x1)
plot(x1)
plot(bh.nb, coordinates(x1), add=TRUE)


>         1> library(spdep)
>         1> bh.nb <- 
> cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
>         1> lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
>         Error in data[id.neigh, , drop = FALSE] : subscript out of bounds
>
>
> If I restrict the data to cut out the missing values, I have no problem:

>From there on, it is reasonably simple:

lcosts <- nbcosts(nb = bh.nb, data = as(x1, "data.frame"),
  method='euclidean')
nb.w <- nb2listw(bh.nb, lcosts, style="B")
mst.bh <- mstree(nb.w, 10)
res1 <- skater(mst.bh[,1:2], as(x1, "data.frame"), 5)
plot(res1, coordinates(x1), cex.circles=0.035, cex.lab=.7)

Hope this clarifies,

Roger


>
>     x = x[x$lon>-117,]
>     bh.nb <- 
> cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
>     lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
>     nb.w <- nb2listw(bh.nb, lcosts, style="B")
>     mst.bh <- mstree(nb.w,10)
>     res1 <- skater(mst.bh[,1:2], x, 5)
>     plot(res1, cbind(x$lon,x$lat), cex.circles=0.035, cex.lab=.7)
>
>
> How do I get around this over-water problem?  I want to be able to cluster 
> the land surfaces, including islands and peninsulas.  I suppose that I want 
> islands to be linked to their nearest point of land.
>
> References appreciated as well as fixes to the specific problem with the 
> `spdep` interface.
>
> Thanks!
> Andrew
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From roland.pape at uni-oldenburg.de  Fri Nov 13 18:37:57 2015
From: roland.pape at uni-oldenburg.de (Roland Pape)
Date: Fri, 13 Nov 2015 17:37:57 +0000
Subject: [R-sig-Geo] How to assess orientation of a topographic feature?
Message-ID: <4780FC16AA89574CA36BB63C15DF63A12BA5FDD3@mbx05.w2kroot.uni-oldenburg.de>

Dear list,

is there any means to (automatically) assess the orientation of topographic features like a ridge or a valley based on a digital elevation model? To calculate the aspect (as direction of largest change) yields obviously not the wanted result, but what about using the direction of smallest change? Any help is greatly appreciated!

Kind regards,

Roland

	[[alternative HTML version deleted]]


From mtreglia at gmail.com  Fri Nov 13 19:41:58 2015
From: mtreglia at gmail.com (Michael Treglia)
Date: Fri, 13 Nov 2015 12:41:58 -0600
Subject: [R-sig-Geo] How to assess orientation of a topographic feature?
In-Reply-To: <4780FC16AA89574CA36BB63C15DF63A12BA5FDD3@mbx05.w2kroot.uni-oldenburg.de>
References: <4780FC16AA89574CA36BB63C15DF63A12BA5FDD3@mbx05.w2kroot.uni-oldenburg.de>
Message-ID: <CAPKp32vOcGu=+d5fXZGZ=_vPepdMEB=RYT+nY3zvb+=pwd5-Mw@mail.gmail.com>

Roland,

Do you have these features already defined and such? One thing that might
help in some of this is calculating the Multiresolution Index of Valley
Bottom Flatness (MRVBF) - it identify valleys and ridges in a quantitative
way.  I'm not aware of an implementation of this directly in R, but it is
implemented in SAGA GIS (
http://www.saga-gis.org/saga_module_doc/2.1.3/ta_morphometry_8.html) and
can be scripted through the RSAGA package (
https://cran.r-project.org/web/packages/RSAGA/index.html).

Potentially you could define your ridges and valleys using MRVBF or other
preferred method, then vectorize those areas, and then calculate the
average aspect for the area.  This average would represent the direction
that the feature runs, assuming it is a fairly linear feature.  (if you
have a valley or ridge that runs north/south, most slopes will be facing
west (270 degrees) or east (90 degrees); the average would be approximately
180 degrees (south), indicating that the feature runs North/South. If
features aren't linear, you'll have to think about the implications of
that, and consider breaking features up into multiple components or
something... depends on what you're ultimately interested in.

This is just an idea of potential workflow... can obviously be done in
various ways with various tools, but is definitely scriptable in R using
combination of RSAGA, sp, and raster packages.

hope that helps,
mike

On Fri, Nov 13, 2015 at 11:37 AM, Roland Pape <roland.pape at uni-oldenburg.de>
wrote:

> Dear list,
>
> is there any means to (automatically) assess the orientation of
> topographic features like a ridge or a valley based on a digital elevation
> model? To calculate the aspect (as direction of largest change) yields
> obviously not the wanted result, but what about using the direction of
> smallest change? Any help is greatly appreciated!
>
> Kind regards,
>
> Roland
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From joshmobrien at gmail.com  Fri Nov 13 20:20:20 2015
From: joshmobrien at gmail.com (Josh O'Brien)
Date: Fri, 13 Nov 2015 11:20:20 -0800
Subject: [R-sig-Geo] Parse EWKT Polygon/MultiLineString/MultiPolygon Text
Message-ID: <CAOwKfPRapSqJotGr+9BXHHmp5f1JF9ZV3b1X6STPYVJJj=fZcQ@mail.gmail.com>

Here is a good start, at least:

library(rgl)

## Helper functions
isLeaf <- function(x) {
    length(gregexpr("(", x, fixed=TRUE)[[1]]) == 1
}

extractBranches <- function(x) {
    x <- gsub("^\\(|\\)$", "",  x)
    pattern <- "\\(((?>[^()]+|(?R))*)\\)"
    m <- gregexpr(pattern, x, perl=TRUE)
    regmatches(x,m)[[1]]
}

leafToMatrix <- function(s, isPoly=FALSE) {
    x <- gsub("[\\(\\),]", " ", s)
    v <- scan(textConnection(x), quiet=TRUE)
    m <- matrix(v, ncol=4, byrow=TRUE)[,1:3]
    if(isPoly & !identical(m[1,], m[nrow(m),])) m <- rbind(m, m[1,])
    m
}

## (A few simple function calls, to see what the helper functions do.)
isLeaf("(0 0)")
isLeaf("((0 0),(1,1)")
extractBranches("((0 0),((1 1),(2 2)))")
leafToMatrix("(0 0 0 0, 1 1 0 1, 1 2 2 2)")


## The parsing engine
parseBranches <- function(x, isPoly=FALSE) {
    lapply(x, function(X) {
               if (isLeaf(X)) {
                   leafToMatrix(X, isPoly = isPoly)
               } else {
                   parseBranches(extractBranches(X), isPoly = isPoly)
               }
           })
}
parseBranches("((0 0 0 0, 9 9 9 9),((1 1 1 1, 6 6 6 6),(2 2 2 2,5 5 5 5)))")


## Main function, to be passed a single WKT string
parseWKT <- function(x) {
    x <- gsub("\n", "", x)
    geometry <- gsub("(^[^\\(]*)(.*)", "\\1", x)
    isPoly <- grepl("POLYGON", geometry)
    x <- gsub(geometry, "", x)
    parseBranches(x, isPoly=isPoly)[[1]]
}



## Examples
A <- "SRID=32611;MULTIPOLYGON(((0 0 0 0,4 0 1 0,4 4 1 0,0 4 1 0,0 0 1 0),
(1 1 1 0,2 1 1 0,2 2 1 0,1 2 1 0,1 1 0 0)),
((-1 -1 1 0,-1 -2 1 0,-2 -2 1 0,-2 -1 1 0,-1 -1 1 0)))"
AA <- parseWKT(A)
colors <- c("red", "blue", "green")
for(i in seq_along(AA)) lapply(AA[[i]], lines3d, color=colors[i])

B <- "SRID=32611;MULTILINESTRING((0 0 0 0,1 1 0 1,1 2 2 2),
(2 3 2 0,3 2 2 1,5 4 3 3))"
BB <- parseWKT(B)
colors <- c("green", "gold", "black")
for(i in seq_along(BB)) lines3d(BB[[i]], color=colors[i])

C <- "SRID=32611;LINESTRING(0 0 0 0,1 1 1 1,1 2 2 2 )"
CC <- parseWKT(C)
lines3d(CC)


From leila.zamani90 at gmail.com  Sat Nov 14 09:07:36 2015
From: leila.zamani90 at gmail.com (leila zamani)
Date: Sat, 14 Nov 2015 10:07:36 +0200
Subject: [R-sig-Geo] random number generation
Message-ID: <CAJPH+K2_itis01aL70MU2ZCKo+THhefZOv8BvU7x2wbUt0bcmA@mail.gmail.com>

Hi every one,

I'm new to R. I read about R and search all the packages but I couldn't
find the package that I want. I want to generate 2D (matrices) random
numbers that have correlation between them. One of my friends said that R
has a function in geor like rand...(spherical (correlation
coefficient=0.5)), but I read all packages with geo,like
geor,geoRlgm,georob and etc, but I didn't find this! Consider this
situation: we have a big square. We split it to smaller squares. Each
square points values change independently from other squares, but in each
square,values change proper to each other with a coefficient. For example a
point in a square number 1 increase 1 unit, the point near to this will
change too,but properly to the coefficient. So we give the coefficients of
all small squares and the function give me back the random numbers in each
square, that these numbers in each square are correlated with this
coefficient. My search is on process variation & I need random numbers.
Others told me that it's in geoR, but I can't find the function with these
features. Can you help me? Many Thanks.

	[[alternative HTML version deleted]]


From r-sig-geo at forreststevens.com  Sat Nov 14 15:44:29 2015
From: r-sig-geo at forreststevens.com (Forrest Stevens)
Date: Sat, 14 Nov 2015 14:44:29 +0000
Subject: [R-sig-Geo] random number generation
In-Reply-To: <CAJPH+K2_itis01aL70MU2ZCKo+THhefZOv8BvU7x2wbUt0bcmA@mail.gmail.com>
References: <CAJPH+K2_itis01aL70MU2ZCKo+THhefZOv8BvU7x2wbUt0bcmA@mail.gmail.com>
Message-ID: <CAEBQMMmTyJSoJn6EK1eZeocn9XSTRASeRcP8t_d0dDDpvu_1bw@mail.gmail.com>

Hi Leila, to generate spatially autocorrelated data, which I think is what
you're trying to get at, I use the gstat package.  You need to decide on
the geostatistical model that describes the nature of your correlation
structure, and then simulating a field is pretty easy:

library(gstat)

## Define your grid size:
xy <- expand.grid(1:100, 1:100)
names(xy) <- c('x','y')

## Generate geostatistical model:
vario_model <- vgm(psill=0.025, range=5, model='Exp')
geo_model <- gstat(formula=z~1, locations=~x+y, dummy=T, beta=1,
model=vario_model, nmax=20)

## Generate random field based on grid and model, visualize:
set.seed(1001) ## For reproducibiliity
rf <- predict(geo_model, newdata=xy, nsim=1)
image( rf )


Hopefully you found this helpful. When I was learning this process, I found
the illustrations in this blog post very helpful for different types of
geostatistical features:

http://santiago.begueria.es/2010/10/generating-spatially-correlated-random-fields-with-r/


Good luck,
Forrest

--
Forrest R. Stevens
Department of Geography & Geosciences
University of Louisville
www.forreststevens.com/teaching

On Sat, Nov 14, 2015 at 3:09 AM leila zamani <leila.zamani90 at gmail.com>
wrote:

> Hi every one,
>
> I'm new to R. I read about R and search all the packages but I couldn't
> find the package that I want. I want to generate 2D (matrices) random
> numbers that have correlation between them. One of my friends said that R
> has a function in geor like rand...(spherical (correlation
> coefficient=0.5)), but I read all packages with geo,like
> geor,geoRlgm,georob and etc, but I didn't find this! Consider this
> situation: we have a big square. We split it to smaller squares. Each
> square points values change independently from other squares, but in each
> square,values change proper to each other with a coefficient. For example a
> point in a square number 1 increase 1 unit, the point near to this will
> change too,but properly to the coefficient. So we give the coefficients of
> all small squares and the function give me back the random numbers in each
> square, that these numbers in each square are correlated with this
> coefficient. My search is on process variation & I need random numbers.
> Others told me that it's in geoR, but I can't find the function with these
> features. Can you help me? Many Thanks.
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From bfalevlist at gmail.com  Sat Nov 14 17:32:09 2015
From: bfalevlist at gmail.com (=?iso-8859-2?Q?Bede-Fazekas_=C1kos?=)
Date: Sat, 14 Nov 2015 17:32:09 +0100
Subject: [R-sig-Geo] gstat::krige() - regression kriging vs. kriging with
	external drift
Message-ID: <000901d11efa$026b78b0$07426a10$@gmail.com>

Dear List, dear Edzer,
is it correct if I use the term "regression kriging" when I run this
function?:
kriged_value <- gstat::krige(z ~ x + y, [...])@data$var1.pred

Or should I call it "kriging with external drift" (or "universal kriging" if
x and y are coordinates), and use the term "regression kriging" only in the
case of running this?:
linear_model <- lm(z ~ x + y, [...])
residuals <- linear_model$residuals
kriged_residuals <- gstat::krige(residuals ~ 1, [...])@data$var1.pred
kriged_value <- linear_model$fitted.values + kriged_residuals

Thank you in advance,
?kos Bede-Fazekas
Budapest, Hungary


From sja_sari at yahoo.com  Sun Nov 15 19:19:06 2015
From: sja_sari at yahoo.com (Seyed Jalil Alavi)
Date: Sun, 15 Nov 2015 10:19:06 -0800
Subject: [R-sig-Geo] Relative mean error in kriging
Message-ID: <1447611546.67830.YahooMailAndroidMobile@web181302.mail.ne1.yahoo.com>


Dear All

I am comparing kriging and IDW methods in mapping Forest Site Productivity using 10-fold cross validation.

Both kriging and IDW methods produced negative mean error. Now I want to use relative mean error for comparing these methods other than RMSE and mean absolute error. here is the results of kriging;

mean of response variable: 34.76982

mean error: -0.03613827

mean absolute error: 1.598008

RMSE: 2.053376

how can I calculate relative mean error?

I read somewhere we can use this function for calculating relative mean error:

OK_CV <- krige.cv(Site_Form ~1, ~X+Y, Data, model = model1.out, nfold=10)

# mean error, ideally 0:

ME_OK <- mean(OK_CV$observed - OK_CV$ var1.pred) ME_OK

### Mean Absolutely Error MAE_OK <-mean(abs(OK_CV$residual)) MAE_OK

### Relative Mean Error MEr_OK <- (ME_OK/mean(Data$Site_Form))*100 MEr_OK

### RMSE RMSE_OK <-sqrt(mean(OK_CV$residual^2)) RMSE_OK

### Relative RMSE

RMSEr_OK <- (RMSE_OK/mean(Data$Site_Form))*100 RMSEr_OK

if I use the above function for relative mean error, the result will be negative!!!

How can I interpret the negative value?

I would be very grateful if anyone can help me to calculate relative mean error in R.

Regards
Jalil
Sent from Yahoo Mail on Android


	[[alternative HTML version deleted]]


From javajimburke at gmail.com  Sun Nov 15 21:14:11 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Sun, 15 Nov 2015 14:14:11 -0600
Subject: [R-sig-Geo] "Paste" with poly titles
Message-ID: <CALkjiFSuJkWkjus9MfomCd8Ma9rm-S_Ais_BSKdJ14eJ8KoKCg@mail.gmail.com>

myLabel <- paste(PctShp$PCT, PctShp$Last_Name, sep = "\n", collapse = NULL)

GIVEN
PCT = "1234"
Last_name = "Open Seat"

EXPECTED BEHAVIOUR
1234
Open Seat

ACTUAL BEHAVIOUR Prints on maps like below.
1234

Open Seat


I suspect I do not know something important about "Paste"

All criticism and comments appreciated,
Jim Burke

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sun Nov 15 21:27:49 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 15 Nov 2015 15:27:49 -0500
Subject: [R-sig-Geo] "Paste" with poly titles
In-Reply-To: <CALkjiFSuJkWkjus9MfomCd8Ma9rm-S_Ais_BSKdJ14eJ8KoKCg@mail.gmail.com>
References: <CALkjiFSuJkWkjus9MfomCd8Ma9rm-S_Ais_BSKdJ14eJ8KoKCg@mail.gmail.com>
Message-ID: <CAM_vjukza52fOdcOUpRWe0XJ32VytZC6gVw9j5c2AoX24SfRPw@mail.gmail.com>

I think we need more information, and ideally a reproducible example.
I'm getting exactly what I'd expect:

myLabel <- paste("1234", "ABCD", sep="\n")
library(sp)
data(meuse.riv)
meuse.sr <- SpatialPolygons(list(Polygons(list(Polygon(meuse.riv)),"meuse.riv")))
plot(meuse.sr)
title(myLabel)

I don't think the problem lies in paste(), (which is not the same
thing as Paste), but in something else you are doing.

Sarah



On Sun, Nov 15, 2015 at 3:14 PM, Jim Burke <javajimburke at gmail.com> wrote:
> myLabel <- paste(PctShp$PCT, PctShp$Last_Name, sep = "\n", collapse = NULL)
>
> GIVEN
> PCT = "1234"
> Last_name = "Open Seat"
>
> EXPECTED BEHAVIOUR
> 1234
> Open Seat
>
> ACTUAL BEHAVIOUR Prints on maps like below.
> 1234
>
> Open Seat
>
>
> I suspect I do not know something important about "Paste"
>
> All criticism and comments appreciated,
> Jim Burke
>
>         [[alternative HTML version deleted]]
>

---
Sarah Goslee
http://www.functionaldiversity.org


From sytze.debruin at wur.nl  Mon Nov 16 12:54:29 2015
From: sytze.debruin at wur.nl (Bruin, Sytze de)
Date: Mon, 16 Nov 2015 11:54:29 +0000
Subject: [R-sig-Geo] gstat now uses Lapack / failing cokriging
Message-ID: <1a0e7afa34b94d24a942da63c8c1ea13@scomp5295.wurnet.nl>

On 10/20/2015 05:58 AM, Edzer Pebesma wrote:

> gstat 1.1-0, now on CRAN, no longer comes with its own functions for 
> matrix factorization and solving systems of equations [1], but now 
> directly uses Lapack (dpotrf and dtrsm) through R's own lapack interface 
> and R_ext/Lapack.h header files. 

> For global kriging at one location from 10,000 observations, as in 

> library(sp) 
> library(gstat) 
> set.seed(1331) 
> n = 10000 
> pts = SpatialPoints(cbind(x = runif(n), y = runif(n))) 
> pts$z = runif(n) 
> k <- krige(z~1, pts, pts[1,], vgm(1, "Exp", 1)) 

> I see a speed increase from 120 (gstat 1.0-26) to 46 seconds; using 
> openblas on a 4 core laptop brings this down to 15 seconds - I expect 
> sth similar with MKL/RevoR. 

> For local kriging on large data sets with smaller neighborhoods and many 
> locations, I wouldn't expect large improvements; for global kriging of 
> large data sets to many prediction locations, krige0 may be faster when 
> you use openblas or MKL - as long as things fit in memory. 

>  I'd be happy to hear experiences (positive and negative), or otherwise 
> reactions or questions.

Hi Edzer,

With the previous version of gstat the following code for doing cokriging using a linear model of coregionalization worked fine.

library(sp)
library(gstat)

# some data
x <- c(215, 330, 410, 470, 545)
y <- c(230, 310, 330, 340, 365)
fc <- c(0.211, 0.251, 0.281, 0.262, 0.242)
por <- c(0.438, 0.457, 0.419, 0.430, 0.468)
Allier <- data.frame(x, y, fc, por)
coordinates(Allier) = ~x+y

# gstat object for co-kriging using linear model of co-regionalization
g <- gstat(id=c("fc"), formula=fc~1, data=Allier,
           model=vgm(0.00247, "Sph", 480, 0.00166))
g <- gstat(g, id="por", formula=por~1, data=Allier,
           model=vgm(0.00239, "Sph", 480, 0.00118))
g <- gstat(g, id=c("fc", "por"),
           model=vgm(0.00151, "Sph", 480, -0.00124))

# predict at single point
point.krig <- predict(g, SpatialPoints(data.frame(x=450, y=350)))

However, using the recently downloaded version of gstat, I get:

Linear Model of Coregionalization found. Good.
[using ordinary cokriging]
Warning message:
In predict.gstat(g, SpatialPoints(data.frame(x = 450, y = 350))) :
  Warning: Covariance matrix (nearly) singular at location [450,350,0]: skipping...

Yet, the covariance matrix is not nearly singular. This appears to be caused by recent changes to the library.

Regards,

Sytze de Bruin
Wageningen University
Laboratory of Geo-Information Science and Remote Sensing 
Telephone: +31 317 481830
Mobile: +31 6 13898626


From edzer.pebesma at uni-muenster.de  Mon Nov 16 15:38:05 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 16 Nov 2015 15:38:05 +0100
Subject: [R-sig-Geo] gstat now uses Lapack / failing cokriging
In-Reply-To: <1a0e7afa34b94d24a942da63c8c1ea13@scomp5295.wurnet.nl>
References: <1a0e7afa34b94d24a942da63c8c1ea13@scomp5295.wurnet.nl>
Message-ID: <5649EA4D.7080905@uni-muenster.de>



On 16/11/15 12:54, Bruin, Sytze de wrote:
> On 10/20/2015 05:58 AM, Edzer Pebesma wrote:
> 
>> gstat 1.1-0, now on CRAN, no longer comes with its own functions for 
>> matrix factorization and solving systems of equations [1], but now 
>> directly uses Lapack (dpotrf and dtrsm) through R's own lapack interface 
>> and R_ext/Lapack.h header files. 
> 
>> For global kriging at one location from 10,000 observations, as in 
> 
>> library(sp) 
>> library(gstat) 
>> set.seed(1331) 
>> n = 10000 
>> pts = SpatialPoints(cbind(x = runif(n), y = runif(n))) 
>> pts$z = runif(n) 
>> k <- krige(z~1, pts, pts[1,], vgm(1, "Exp", 1)) 
> 
>> I see a speed increase from 120 (gstat 1.0-26) to 46 seconds; using 
>> openblas on a 4 core laptop brings this down to 15 seconds - I expect 
>> sth similar with MKL/RevoR. 
> 
>> For local kriging on large data sets with smaller neighborhoods and many 
>> locations, I wouldn't expect large improvements; for global kriging of 
>> large data sets to many prediction locations, krige0 may be faster when 
>> you use openblas or MKL - as long as things fit in memory. 
> 
>>  I'd be happy to hear experiences (positive and negative), or otherwise 
>> reactions or questions.
> 
> Hi Edzer,
> 
> With the previous version of gstat the following code for doing cokriging using a linear model of coregionalization worked fine.
> 
> library(sp)
> library(gstat)
> 
> # some data
> x <- c(215, 330, 410, 470, 545)
> y <- c(230, 310, 330, 340, 365)
> fc <- c(0.211, 0.251, 0.281, 0.262, 0.242)
> por <- c(0.438, 0.457, 0.419, 0.430, 0.468)
> Allier <- data.frame(x, y, fc, por)
> coordinates(Allier) = ~x+y
> 
> # gstat object for co-kriging using linear model of co-regionalization
> g <- gstat(id=c("fc"), formula=fc~1, data=Allier,
>            model=vgm(0.00247, "Sph", 480, 0.00166))
> g <- gstat(g, id="por", formula=por~1, data=Allier,
>            model=vgm(0.00239, "Sph", 480, 0.00118))
> g <- gstat(g, id=c("fc", "por"),
>            model=vgm(0.00151, "Sph", 480, -0.00124))
> 
> # predict at single point
> point.krig <- predict(g, SpatialPoints(data.frame(x=450, y=350)))
> 
> However, using the recently downloaded version of gstat, I get:
> 
> Linear Model of Coregionalization found. Good.
> [using ordinary cokriging]
> Warning message:
> In predict.gstat(g, SpatialPoints(data.frame(x = 450, y = 350))) :
>   Warning: Covariance matrix (nearly) singular at location [450,350,0]: skipping...
> 
> Yet, the covariance matrix is not nearly singular. This appears to be caused by recent changes to the library.

Hi Sytze, thanks for the clear test case. The warning message is wrong
but the problem remains: the covariance matrix is not singular, but
non-positive definite:

> r
             [,1]        [,2]        [,3]        [,4]        [,5]
 [1,] 0.004130000 0.001419390 0.000895995 0.000565582 0.000224073
 [2,] 0.001419390 0.004130000 0.001839760 0.001397620 0.000879083
 [3,] 0.000895995 0.001839760 0.004130000 0.002003000 0.001423810
 [4,] 0.000565582 0.001397620 0.002003000 0.004130000 0.001865300
 [5,] 0.000224073 0.000879083 0.001423810 0.001865300 0.004130000
 [6,] 0.001510000 0.002107720 0.001787750 0.001585760 0.001376980
 [7,] 0.002107720 0.001510000 0.002364710 0.002094420 0.001777420
 [8,] 0.001787750 0.002364710 0.001510000 0.002464510 0.002110430
 [9,] 0.001585760 0.002094420 0.002464510 0.001510000 0.002380320
[10,] 0.001376980 0.001777420 0.002110430 0.002380320 0.001510000
             [,6]        [,7]        [,8]        [,9]       [,10]
 [1,] 0.001510000 0.002107720 0.001787750 0.001585760 0.001376980
 [2,] 0.002107720 0.001510000 0.002364710 0.002094420 0.001777420
 [3,] 0.001787750 0.002364710 0.001510000 0.002464510 0.002110430
 [4,] 0.001585760 0.002094420 0.002464510 0.001510000 0.002380320
 [5,] 0.001376980 0.001777420 0.002110430 0.002380320 0.001510000
 [6,] 0.003570000 0.001373420 0.000866975 0.000547264 0.000216816
 [7,] 0.001373420 0.003570000 0.001780170 0.001352350 0.000850611
 [8,] 0.000866975 0.001780170 0.003570000 0.001938130 0.001377690
 [9,] 0.000547264 0.001352350 0.001938130 0.003570000 0.001804880
[10,] 0.000216816 0.000850611 0.001377690 0.001804880 0.003570000
> chol(r)
Error in chol.default(r) :
  the leading minor of order 9 is not positive definite

As explained in https://en.wikipedia.org/wiki/Cholesky_decomposition ,
Choleski differs from LDL', which gstat used to do before 1.1-0. As Tim
Peterson reminded me off-list, lapack also has LDL'; will look into it.

Changing the nugget of the cross variogram to -0.001 makes the matrix
positive definite, for your toy case.

> 
> Regards,
> 
> Sytze de Bruin
> Wageningen University
> Laboratory of Geo-Information Science and Remote Sensing 
> Telephone: +31 317 481830
> Mobile: +31 6 13898626
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151116/14982b8f/attachment.bin>

From sytze.debruin at wur.nl  Tue Nov 17 18:14:22 2015
From: sytze.debruin at wur.nl (Bruin, Sytze de)
Date: Tue, 17 Nov 2015 17:14:22 +0000
Subject: [R-sig-Geo] gstat now uses Lapack / failing cokriging
Message-ID: <4d812a6858d942f589a5502e117b1234@scomp5295.wurnet.nl>

Hi Edzer, thanks for your prompt reply. I tried reproducing your matrix r but got a different result, i.e. a valid covariance matrix. The cross-covariances are different. Using the same example as above, my code is as follows:

library(sp)
library(gstat)

# some data
x <- c(215, 330, 410, 470, 545)
y <- c(230, 310, 330, 340, 365)
fc <- c(0.211, 0.251, 0.281, 0.262, 0.242)
por <- c(0.438, 0.457, 0.419, 0.430, 0.468)
Allier <- data.frame(x, y, fc, por)
coordinates(Allier) = ~x+y

# gstat object for co-kriging using linear model of co-regionalization
g <- gstat(id=c("fc"), formula=fc~1, data=Allier,
            model=vgm(0.00247, "Sph", 480, 0.00166))
g <- gstat(g, id="por", formula=por~1, data=Allier,
            model=vgm(0.00239, "Sph", 480, 0.00118))
g <- gstat(g, id=c("fc", "por"),
            model=vgm(0.00151, "Sph", 480, -0.00124))


dists <- spDists(Allier)
r11 <- variogramLine(g$model$fc, dist_vector = dists, covariance = T)
r12 <- variogramLine(g$model$fc.por, dist_vector = dists, covariance = T)
r22 <- variogramLine(g$model$por, dist_vector = dists, covariance = T)
r <- cbind(r11, r12)
r <- rbind(r, cbind(r12, r22))

> r
              [,1]         [,2]         [,3]         [,4]         [,5]         [,6]         [,7]
 [1,] 0.0041300000 0.0014193874 0.0008959951 0.0005655821 0.0002240733 0.0002700000 0.0008677227
 [2,] 0.0014193874 0.0041300000 0.0018397575 0.0013976206 0.0008790828 0.0008677227 0.0002700000
 [3,] 0.0008959951 0.0018397575 0.0041300000 0.0020030001 0.0014238096 0.0005477541 0.0011247100
 [4,] 0.0005655821 0.0013976206 0.0020030001 0.0041300000 0.0018652970 0.0003457607 0.0008544158
 [5,] 0.0002240733 0.0008790828 0.0014238096 0.0018652970 0.0041300000 0.0001369841 0.0005374150
 [6,] 0.0002700000 0.0008677227 0.0005477541 0.0003457607 0.0001369841 0.0035700000 0.0013734154
 [7,] 0.0008677227 0.0002700000 0.0011247100 0.0008544158 0.0005374150 0.0013734154 0.0035700000
 [8,] 0.0005477541 0.0011247100 0.0002700000 0.0012245061 0.0008704261 0.0008669750 0.0017801702
 [9,] 0.0003457607 0.0008544158 0.0012245061 0.0002700000 0.0011403233 0.0005472637 0.0013523535
[10,] 0.0001369841 0.0005374150 0.0008704261 0.0011403233 0.0002700000 0.0002168159 0.0008506105
              [,8]         [,9]        [,10]
 [1,] 0.0005477541 0.0003457607 0.0001369841
 [2,] 0.0011247100 0.0008544158 0.0005374150
 [3,] 0.0002700000 0.0012245061 0.0008704261
 [4,] 0.0012245061 0.0002700000 0.0011403233
 [5,] 0.0008704261 0.0011403233 0.0002700000
 [6,] 0.0008669750 0.0005472637 0.0002168159
 [7,] 0.0017801702 0.0013523535 0.0008506105
 [8,] 0.0035700000 0.0019381256 0.0013776943
 [9,] 0.0019381256 0.0035700000 0.0018048825
[10,] 0.0013776943 0.0018048825 0.0035700000

> eigen(r)$values
 [1] 0.0124609506 0.0055040132 0.0046425761 0.0035980843 0.0031064016 0.0028989486 0.0028042439
 [8] 0.0018107335 0.0010254131 0.0006486352


From edzer.pebesma at uni-muenster.de  Tue Nov 17 20:38:33 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 17 Nov 2015 20:38:33 +0100
Subject: [R-sig-Geo] gstat now uses Lapack / failing cokriging
In-Reply-To: <4d812a6858d942f589a5502e117b1234@scomp5295.wurnet.nl>
References: <4d812a6858d942f589a5502e117b1234@scomp5295.wurnet.nl>
Message-ID: <564B8239.6080401@uni-muenster.de>


On 17/11/15 18:14, Bruin, Sytze de wrote:
> Hi Edzer, thanks for your prompt reply. I tried reproducing your matrix r but got a different result, i.e. a valid covariance matrix. The cross-covariances are different. Using the same example as above, my code is as follows:
> 
> library(sp)
> library(gstat)
> 
> # some data
> x <- c(215, 330, 410, 470, 545)
> y <- c(230, 310, 330, 340, 365)
> fc <- c(0.211, 0.251, 0.281, 0.262, 0.242)
> por <- c(0.438, 0.457, 0.419, 0.430, 0.468)
> Allier <- data.frame(x, y, fc, por)
> coordinates(Allier) = ~x+y
> 
> # gstat object for co-kriging using linear model of co-regionalization
> g <- gstat(id=c("fc"), formula=fc~1, data=Allier,
>             model=vgm(0.00247, "Sph", 480, 0.00166))
> g <- gstat(g, id="por", formula=por~1, data=Allier,
>             model=vgm(0.00239, "Sph", 480, 0.00118))
> g <- gstat(g, id=c("fc", "por"),
>             model=vgm(0.00151, "Sph", 480, -0.00124))
> 
> 
> dists <- spDists(Allier)
> r11 <- variogramLine(g$model$fc, dist_vector = dists, covariance = T)
> r12 <- variogramLine(g$model$fc.por, dist_vector = dists, covariance = T)
> r22 <- variogramLine(g$model$por, dist_vector = dists, covariance = T)
> r <- cbind(r11, r12)
> r <- rbind(r, cbind(r12, r22))
> 
>> r
>               [,1]         [,2]         [,3]         [,4]         [,5]         [,6]         [,7]
>  [1,] 0.0041300000 0.0014193874 0.0008959951 0.0005655821 0.0002240733 0.0002700000 0.0008677227
>  [2,] 0.0014193874 0.0041300000 0.0018397575 0.0013976206 0.0008790828 0.0008677227 0.0002700000
>  [3,] 0.0008959951 0.0018397575 0.0041300000 0.0020030001 0.0014238096 0.0005477541 0.0011247100
>  [4,] 0.0005655821 0.0013976206 0.0020030001 0.0041300000 0.0018652970 0.0003457607 0.0008544158
>  [5,] 0.0002240733 0.0008790828 0.0014238096 0.0018652970 0.0041300000 0.0001369841 0.0005374150
>  [6,] 0.0002700000 0.0008677227 0.0005477541 0.0003457607 0.0001369841 0.0035700000 0.0013734154
>  [7,] 0.0008677227 0.0002700000 0.0011247100 0.0008544158 0.0005374150 0.0013734154 0.0035700000
>  [8,] 0.0005477541 0.0011247100 0.0002700000 0.0012245061 0.0008704261 0.0008669750 0.0017801702
>  [9,] 0.0003457607 0.0008544158 0.0012245061 0.0002700000 0.0011403233 0.0005472637 0.0013523535
> [10,] 0.0001369841 0.0005374150 0.0008704261 0.0011403233 0.0002700000 0.0002168159 0.0008506105
>               [,8]         [,9]        [,10]
>  [1,] 0.0005477541 0.0003457607 0.0001369841
>  [2,] 0.0011247100 0.0008544158 0.0005374150
>  [3,] 0.0002700000 0.0012245061 0.0008704261
>  [4,] 0.0012245061 0.0002700000 0.0011403233
>  [5,] 0.0008704261 0.0011403233 0.0002700000
>  [6,] 0.0008669750 0.0005472637 0.0002168159
>  [7,] 0.0017801702 0.0013523535 0.0008506105
>  [8,] 0.0035700000 0.0019381256 0.0013776943
>  [9,] 0.0019381256 0.0035700000 0.0018048825
> [10,] 0.0013776943 0.0018048825 0.0035700000
> 
>> eigen(r)$values
>  [1] 0.0124609506 0.0055040132 0.0046425761 0.0035980843 0.0031064016 0.0028989486 0.0028042439
>  [8] 0.0018107335 0.0010254131 0.0006486352
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

Building upon your earlier example,

predict(g, SpatialPoints(data.frame(x=450, y=350)), debug = 32)

gives you the generalized covariance matrix that is used for the
cokriging, which I looked at. gstat computes generalized covariances as
C(0)-gamma(h) with C(0) = max(0, sum of the positive sill values),
instead of the sill of all sill values. If one of the sill components is
negative, this matters.

I looked in the Ver Hoef & Cressie 1993 paper, but couldn't find out
which one is right. Maybe Gerard can also take a look at it; the fix
would be trivial.

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151117/d7d023d9/attachment.bin>

From ejforrestel at gmail.com  Wed Nov 18 02:12:13 2015
From: ejforrestel at gmail.com (Beth Forrestel)
Date: Tue, 17 Nov 2015 20:12:13 -0500
Subject: [R-sig-Geo] issues with NAs when using resample function
Message-ID: <CAOmThiAxmLh8OwquU-1Cbb7eHuJmS7myTGkt5BZtwAh1oXJm2Q@mail.gmail.com>

Hello~

I am trying to resample a raster layer to match the resolution of another
layer using the bilinear interpolation method.  Is there a way to ignore
NAs (ocean) when I do this so that I don't lose data?
na.rm=TRUE does not seem to do the trick

Many thanks!

	[[alternative HTML version deleted]]


From stephen.stewart85 at gmail.com  Wed Nov 18 02:42:16 2015
From: stephen.stewart85 at gmail.com (Stephen Stewart)
Date: Wed, 18 Nov 2015 12:42:16 +1100
Subject: [R-sig-Geo] issues with NAs when using resample function
In-Reply-To: <CAOmThiAxmLh8OwquU-1Cbb7eHuJmS7myTGkt5BZtwAh1oXJm2Q@mail.gmail.com>
References: <CAOmThiAxmLh8OwquU-1Cbb7eHuJmS7myTGkt5BZtwAh1oXJm2Q@mail.gmail.com>
Message-ID: <CAJefdj5V8NrkMSaHPx5nR+RqnLTzn-hsJMapy1JCgAaEqtgo=A@mail.gmail.com>

Hi Beth,

In the past, I have interpolated coastal and border regions in the original
coarse resolution prior to resampling. This can be done relatively easily
using the *gstat* package, QGIS and/or GDAL/SAGA/GRASS.

Once the coarse resolution data has been interpolated, run bilinear
interpolation and then apply a mask so that ocean areas are excluded.

Depending upon the variable I would use bilinear interpolation with
caution. It may be worth investigating any potential downscaling approaches
if you haven't already.

Hope that helps!

Cheers,

Steve


On Wed, Nov 18, 2015 at 12:12 PM, Beth Forrestel <ejforrestel at gmail.com>
wrote:

> Hello~
>
> I am trying to resample a raster layer to match the resolution of another
> layer using the bilinear interpolation method.  Is there a way to ignore
> NAs (ocean) when I do this so that I don't lose data?
> na.rm=TRUE does not seem to do the trick
>
> Many thanks!
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From cornel.pop at gmail.com  Wed Nov 18 11:10:40 2015
From: cornel.pop at gmail.com (Cornel Pop)
Date: Wed, 18 Nov 2015 11:10:40 +0100
Subject: [R-sig-Geo] grass ascii support in the raster package
Message-ID: <CAGNAyd2q30ohJoRcggjJ-nAaxQvn0KSo0JEBkwk=h_iMb4TCYg@mail.gmail.com>

Dear all,

I just joined this list and I thought I would start off by making a small
contribution that may be of interest to some of you, namely a patch for the
raster package (replaces raster/R/rasterFromAscii.R) which:

1. Adds support for importing GRASS ASCII raster files.
2. Fixes what I think is an issue with the offset parameter in the import
function. Currently, if the offset is greater than the number of header
lines the function silently removes data without verifying that the number
of rows matches the nrows header parameter. This leads to potentially
difficult to diagnose errors (e.g. getValues(x) != ncell(x)). My modified
version determines the number of header lines and sets the correct offset
(i.e. excluding any data lines that may have been read in).
3. Generates an easy to understand error message if the header format is
not recognized.

In implementing these changes I tried to keep modifications of the original
code to a minimum (see the attached patch.txt). I'm sure things could be
improved, but I've used this patch for some time now and I haven't had any
issues.

Cheers,

Cornel M. Pop
---
PhD Candidate,
Max Planck Institute for Evolutionary Anthropology,
Leipzig, DE
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151118/e2b1e3e7/attachment.html>
-------------- next part --------------
--- rasterFromASCII_orig.R	2015-11-18 08:37:21.203485973 +0100
+++ final/rasterFromASCII.R	2015-11-18 08:47:39.073364056 +0100
@@ -3,12 +3,13 @@
 # Version 0.9
 # Licence GPL v3
 
+# Copyright 2015 (addendum) Cornel M. Pop <cornel at popgeology.com> Changed offset and added
+# option to load GRASS ASCII files. Offset parameter now ignored.
 
 .rasterFromASCIIFile <- function(filename, offset=6, crs=NA, ...) {
-	
-	offset <- as.integer(offset)
-	stopifnot(offset > 2)
-	
+	# Maximum real offset (GRASS = 6 required + 3 opts; ESRI = 5 required + 1 opt)
+  	offset <- 9
+  
 	splitasc <- function(s) {
 		s <- trim(s)
 		spl <- unlist(strsplit(s, ''), use.names = FALSE)
@@ -25,24 +26,49 @@
 	close(con)
 	ini <- lapply(lines, splitasc) 
 	ini <- matrix(unlist(ini, use.names = FALSE), ncol=2, byrow=TRUE)
-	
-	ini[,1] = toupper(ini[,1]) 
-	
-	w <- getOption('warn')
-	on.exit(options('warn' = w))
-	options('warn'=-1) 
-	test <- sum(as.numeric(ini[,1]), na.rm=TRUE) > 0
-	options('warn' = w)
-	if (test) {
-		m <- 'The header of this file appears to be incorrect: there are numbers where there should be keywords'
-		if (offset != 6) {
-			m <- paste(m, '\n  Are you using a wrong offset?', sep='')
-		} 
-		stop(m)
-	}
-	
-	
+
+	# Data may begin with a noval, which may not be numeric (i.e. NaN, NA)
+  	# Note that NODATA is not in the ESRI specs - using here for compatibility
+  	noval_kw <- c("NULL:", "NODATA", "NODATA_VALUE")
+
+  	noval <- ini[which(toupper(ini[,1]) %in% noval_kw == T), 2]
+  	if(length(noval) == 1){
+    	  # True offset. Rest is overshot (data)
+    	  offset <- length(which(is.na(suppressWarnings(try(as.numeric(ini[which(ini[,1] != noval),1]))))))
+  	} else {
+    	  offset <- length(which(is.na(suppressWarnings(try(as.numeric(ini[,1]))))))
+  	}
+  	stopifnot(offset > 2) # Note: This is not necessary.
+  	ini <- ini[1:offset,] # Keep only real header elements
+
+	ini[,1] = toupper(ini[,1])
+  
 	nodataval <- xn <- yn <- d <- nr <- nc <- xc <- yc <- NA
+  	grass_mandatory <- c("NORTH:", "SOUTH:", "EAST:", "WEST:", "ROWS:", "COLS:")
+  	if (!FALSE %in% (grass_mandatory %in% ini[,1])){
+   	  # GRASS ASCII - note: this is a bit different from how ESRI files are
+   	  # handled, in that we check for all mandatory header keys, and don't process
+    	  # the file if they are missing because, well, they should not be missing!
+    	  nr <- as.integer(ini[which(ini[,1] == "ROWS:"),2])
+    	  nc <- as.integer(ini[which(ini[,1] == "COLS:"),2])
+    	  xn <- as.numeric(ini[which(ini[,1] == "WEST:"),2])
+    	  yn <- as.numeric(ini[which(ini[,1] == "SOUTH:"),2])
+    	  xx <- as.numeric(ini[which(ini[,1] == "EAST:"),2])
+    	  yx <- as.numeric(ini[which(ini[,1] == "NORTH:"),2])
+    
+	  # Optional fields:
+    	  if ("NULL:" %in% ini[,1]){
+      	    nodataval <- as.numeric(ini[which(ini[,1] == "NULL:"),2])
+    	  } else {
+      	    warning('"NULL" not detected. Setting it to -Inf\n  You can set it to another value with function "NAvalue"')
+      	    nodataval <- -Inf
+    	  }
+    	  if ("TYPE:" %in% ini[,1]){
+     	    warning('Optional "TYPE" parameter detected, but ignoring and using the default data type.')
+    	  }
+    	  if ("MULTIPLIER:" %in% ini[,1]){multiplier <- as.numeric(ini[which(ini[,1] == "MULTIPLIER:"),2])}
+
+  	} else if ("NCOLS" %in% ini[,1]){
 	for (i in 1:nrow(ini)) {
 		if (ini[i,1] == "NCOLS") { nc <- as.integer(ini[i,2])
 		} else if (ini[i,1] == "NROWS") { nr <- as.integer(ini[i,2])
@@ -104,6 +130,9 @@
 	
 	xx <- xn + nc * d
 	yx <- yn + nr * d
+  	} else {
+    	  stop("File type not supported. Supported file types are: ESRI ASCII, GRASS ASCII")
+  	}
 
 	x <- raster(ncols=nc, nrows=nr, xmn=xn, ymn=yn, xmx=xx, ymx=yx, crs='')	
 
@@ -118,6 +147,9 @@
 		projection(x) <- crs
 	}
 	
+  	if(exists("multiplier")){
+		x <- setValues(x, getValues(x)*multiplier)
+  	}
 	return(x)
 }
 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rasterFromASCII.R
Type: text/x-r-source
Size: 5209 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151118/e2b1e3e7/attachment.bin>

From martin.tomko at geo.uzh.ch  Wed Nov 18 14:55:04 2015
From: martin.tomko at geo.uzh.ch (Martin Tomko)
Date: 18 Nov 2015 14:55:04 +0100
Subject: [R-sig-Geo] space-time - efficient creation of a TracksCollection
Message-ID: <2CA1B4FE-73F0-4802-97CB-EF27099130FA@geo.uzh.ch>

Dear list, cc Edzer,

I am trying to find an efficient method to read in data into a library(spacetime) TracksCollection, from a large CVS containing gps tracks of individual objects.

I have managed to do this for a small number of tracks, following the documentation, using a spatialPointsDataFrame spdf:
stidf = STIDF(geometry(spdf), spdf at data$timestamp, spdf at data)
T1 = Track(stidf)
etc for a number of Tracks, then mergins individual Track objects into Tracks for a given user
O1 = Tracks(list(T1=T1,T2=T2))
and then making a collection
Tr = TracksCollection(list(O1=O1,O2=O2)) of individual objects
Now - this is very cumbersome. I have potentially thousands of objects tracked, each with a number of tracks. They are all stored in one large CSV annotated by timestamp, objectid and trackid. Is there any efficient method to parse (even thorugh any other sp object) collections? The manual assignment of o1= o1, o2=o2 etc is the main problem, from my perspective. I would like to supply a vector of names of users, and a list of names of tracks (each are unique in the whole set) to this.

I can loop through the list of data frames for each individual Track before they are coerced into spatialPointDataFrame, and I can get the additional labels - I see this as a way to append a new STI to appropriate Tracks and to the collection?

Any hint welcome.

Thanks,

Martin



	[[alternative HTML version deleted]]


From andre.sbertoncini at gmail.com  Wed Nov 18 16:35:09 2015
From: andre.sbertoncini at gmail.com (=?UTF-8?Q?Andr=C3=A9_Bertoncini?=)
Date: Wed, 18 Nov 2015 13:35:09 -0200
Subject: [R-sig-Geo] Flow Accumulation Algorithm
Message-ID: <CAEVrojAmv2Srw0jzS0DzCf1duoo=bNTiAKLYoyKR7H3pO+ELew@mail.gmail.com>

Hi everyone,

Does anyone knows where I can find a code in R for the computation of flow
accumulation from a DEM?

I'm having a problem because the raster package does not perform this task
in a straightforward way.

Any hints are welcome.
Regards,

-- 
*Ge?grafo Andr? Bertoncini*
Mestrando em Sensoriamento Remoto
Instituto Nacional de Pesquisas Espaciais
(48) 9178-0686

	[[alternative HTML version deleted]]


From pingyang.whu at gmail.com  Wed Nov 18 16:50:20 2015
From: pingyang.whu at gmail.com (ping yang)
Date: Wed, 18 Nov 2015 09:50:20 -0600
Subject: [R-sig-Geo] Flow Accumulation Algorithm
In-Reply-To: <CAEVrojAmv2Srw0jzS0DzCf1duoo=bNTiAKLYoyKR7H3pO+ELew@mail.gmail.com>
References: <CAEVrojAmv2Srw0jzS0DzCf1duoo=bNTiAKLYoyKR7H3pO+ELew@mail.gmail.com>
Message-ID: <CAK8gSG-eNw9HX83duud-vN2KGNgwDmbDX-96HT4LBSCTBsNOwA@mail.gmail.com>

I used this code before and it works, see the link:
http://hydrology.usu.edu/taudem/taudem5/TauDEMRScript.txt

Also you may check this link (
http://gis.stackexchange.com/questions/84694/flow-accumulation-in-r) in
stackexchange.

Hope it helps.

Peter

On Wed, Nov 18, 2015 at 9:35 AM, Andr? Bertoncini <
andre.sbertoncini at gmail.com> wrote:

> Hi everyone,
>
> Does anyone knows where I can find a code in R for the computation of flow
> accumulation from a DEM?
>
> I'm having a problem because the raster package does not perform this task
> in a straightforward way.
>
> Any hints are welcome.
> Regards,
>
> --
> *Ge?grafo Andr? Bertoncini*
> Mestrando em Sensoriamento Remoto
> Instituto Nacional de Pesquisas Espaciais
> (48) 9178-0686
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Wed Nov 18 22:16:12 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 18 Nov 2015 22:16:12 +0100
Subject: [R-sig-Geo] space-time - efficient creation of a
	TracksCollection
In-Reply-To: <2CA1B4FE-73F0-4802-97CB-EF27099130FA@geo.uzh.ch>
References: <2CA1B4FE-73F0-4802-97CB-EF27099130FA@geo.uzh.ch>
Message-ID: <564CEA9C.9050102@uni-muenster.de>

Hi Martin, such a function would be a nice addition to the trajectories
package, and shouldn't be too hard to write. Maybe you can come up with
a short example csv data set?

library trajectories has two demo's, demo(Geolife) and demo(google),
which read the Geolife data set and google location history json dumps
to trajectories, but both are overly complicated for what you have in mind.

The selection you want to do on object and ID can be done on the
data.frame level, e.g with subset().

The function to write will use split to split the data.frame in a list
with sub-data.frames, and lapply to apply functions to list elements.

On 18/11/15 14:55, Martin Tomko wrote:
> Dear list, cc Edzer,
> 
> I am trying to find an efficient method to read in data into a
> library(spacetime) TracksCollection, from a large CVS containing gps
> tracks of individual objects.
> 
> I have managed to do this for a small number of tracks, following the
> documentation, using a spatialPointsDataFrame spdf:
> 
> stidf = STIDF(geometry(spdf), spdf at data$timestamp, spdf at data)
> T1 = Track(stidf)
> 
> etc for a number of Tracks, then mergins individual Track objects into
> Tracks for a given user
> 
> O1 = Tracks(list(T1=T1,T2=T2))
> 
> and then making a collection
> Tr = TracksCollection(list(O1=O1,O2=O2)) of individual objects
> 
> Now - this is very cumbersome. I have potentially thousands of objects
> tracked, each with a number of tracks. They are all stored in one large
> CSV annotated by timestamp, objectid and trackid. Is there any efficient
> method to parse (even thorugh any other sp object) collections? The
> manual assignment of o1= o1, o2=o2 etc is the main problem, from my
> perspective. I would like to supply a vector of names of users, and a
> list of names of tracks (each are unique in the whole set) to this.
> 
> I can loop through the list of data frames for each individual Track
> before they are coerced into spatialPointDataFrame, and I can get the
> additional labels - I see this as a way to append a new STI to
> appropriate Tracks and to the collection?
> 
> Any hint welcome.
> 
> Thanks,
> 
> Martin
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151118/7556f068/attachment.bin>

From timjp at unimelb.edu.au  Wed Nov 18 22:52:38 2015
From: timjp at unimelb.edu.au (Tim Peterson)
Date: Thu, 19 Nov 2015 08:52:38 +1100
Subject: [R-sig-Geo] Flow Accumulation Algorithm
In-Reply-To: <CAEVrojAmv2Srw0jzS0DzCf1duoo=bNTiAKLYoyKR7H3pO+ELew@mail.gmail.com>
References: <CAEVrojAmv2Srw0jzS0DzCf1duoo=bNTiAKLYoyKR7H3pO+ELew@mail.gmail.com>
Message-ID: <564CF326.3020403@unimelb.edu.au>

Hi Andre

Have you tried using TauDEM? The following demonstrates that it can be 
called from R - http://hydrology.usu.edu/taudem/taudem5/TauDEMRScript.txt

Also, TauDEM includes the much more realistic D-infinity flow direction 
and accumulation.

Cheers

Tim




On 19/11/15 02:35, Andr? Bertoncini wrote:
> Hi everyone,
>
> Does anyone knows where I can find a code in R for the computation of flow
> accumulation from a DEM?
>
> I'm having a problem because the raster package does not perform this task
> in a straightforward way.
>
> Any hints are welcome.
> Regards,
>

-- 
----------------------
Dr. Tim Peterson

The Department of Infrastructure Engineering
The University of Melbourne, 3010 Australia
T: +61 3 8344 9950 <tel:%2B61%203%208344%209950>, M: +61 0438 385 937 
<tel:%2B61%200438%20385%20937>

Dept. profile : 
http://www.ie.unimelb.edu.au/people/staff.php?person_ID=141135
Research Gate : https://www.researchgate.net/profile/Tim_Peterson7
Google Scholar: 
http://scholar.google.com.au/citations?user=kkYJLF4AAAAJ&hl=en&oi=ao

	[[alternative HTML version deleted]]


From rahmannorthampton at gmail.com  Wed Nov 18 23:17:01 2015
From: rahmannorthampton at gmail.com (Lutfor Rahman)
Date: Wed, 18 Nov 2015 22:17:01 +0000
Subject: [R-sig-Geo] probability contour plot on raster file
Message-ID: <CAP43mJ_QV0aRi2aU1k-f6Dsf-Eg6kjk9_T-Od1u5sCiVjVwFQw@mail.gmail.com>

Dear forum member,

I have spatial cell/pixels (20 thousands cells) with their co-ordinates
with their corresponding values. I would like to crate probability contours
at 50%, 75% and 99% of those values and after that I would like overlay in
world map.

I should creat raster file and adding contours onto raster and bringing map
onto it (Please let me know-am I right? or there is other way of doing
this?). However, I count see any contours created on my raster while I am
using following code.


Can anyone let me know how I can create probability contours at three
different levels (in three colours; 50%, 75% and 99%). Please let me know
how I could transfer this raster with contours in a map like google terrain
map (any particular package).

Any suggestions will be much appreciated.


best regards

Lutfor


##############

Population<-read.csv("rasterfile.csv", header=T)

names(Population)

summary(Population)

x1<-Population$x

y1<-Population$y

value<-Population$values

r <- raster(nrows=664, ncols=341, xmn=-2087158, xmx=1312843, ymn=-3201679,
ymx=3428321)

proj4string(r) <- CRS("+proj=aeqd +ellps=WGS84 +lon_0=110.7985
+lat_0=43.215")

###I have used above projection as these spatial cells extracted from same
projection.###

r1 <- rasterize(cbind(x1, y1), r, value)

plot(r1)
contour(r1, add=T, levels=c(.50, .75, .99))

#############################

	[[alternative HTML version deleted]]


From zhyuanzh at gmail.com  Wed Nov 18 23:56:50 2015
From: zhyuanzh at gmail.com (Zhong-Yuan Zhang)
Date: Thu, 19 Nov 2015 06:56:50 +0800
Subject: [R-sig-Geo] How to get the borders of scattered spacial points
Message-ID: <CAApZs+FxQqA2qTy6Lbv3RZKV3zp4q9b73sEm2uwPLS_+Kj8jDQ@mail.gmail.com>

Dear All:

   As a freshman, I am now analyzing some spacial data.

I want to get the border of scattered spacial points. Are there

any libraries that I can use?  Also is there any library that can

use Baidu map API?  I highly appreciate your help and

suggestions.

   Best Regards Always.

-- 
Zhong-Yuan Zhang (PhD.)
Full Professor
School of Statistics
Central University of Finance and Economics
39 South College Road, Haidian District, Beijing, P.R.China 100081
Email: zhyuanzh at gmail.com
Homepage: *http://zhongyuanzhang.github.io/
<http://zhongyuanzhang.github.io/>*

	[[alternative HTML version deleted]]


From SWalbridge at esri.com  Thu Nov 19 00:36:16 2015
From: SWalbridge at esri.com (Shaun Walbridge)
Date: Wed, 18 Nov 2015 23:36:16 +0000
Subject: [R-sig-Geo] Flow Accumulation Algorithm
In-Reply-To: <564CF326.3020403@unimelb.edu.au>
References: <CAEVrojAmv2Srw0jzS0DzCf1duoo=bNTiAKLYoyKR7H3pO+ELew@mail.gmail.com>
	<564CF326.3020403@unimelb.edu.au>
Message-ID: <7A118CBE55378145A2DF34C07644493C011F69A527@RED-INF-EXMB-P1.esri.com>

You could also look at calling out to a GIS environment from R to make the calculation. For example, there are bridge libraries to talk to SAGA [1], GRASS [2], and ArcGIS [3] from within R which can all read data formats raster can create.

1. https://cran.r-project.org/web/packages/RSAGA/
2. https://cran.r-project.org/web/packages/rgrass7/
3. https://cran.r-project.org/web/packages/RPyGeo/


-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Tim Peterson
Sent: Wednesday, November 18, 2015 4:53 PM
To: r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Flow Accumulation Algorithm

Hi Andre

Have you tried using TauDEM? The following demonstrates that it can be called from R - http://hydrology.usu.edu/taudem/taudem5/TauDEMRScript.txt

Also, TauDEM includes the much more realistic D-infinity flow direction and accumulation.

Cheers

Tim




On 19/11/15 02:35, Andr? Bertoncini wrote:
> Hi everyone,
>
> Does anyone knows where I can find a code in R for the computation of 
> flow accumulation from a DEM?
>
> I'm having a problem because the raster package does not perform this 
> task in a straightforward way.
>
> Any hints are welcome.
> Regards,
>

--
----------------------
Dr. Tim Peterson

The Department of Infrastructure Engineering The University of Melbourne, 3010 Australia
T: +61 3 8344 9950 <tel:%2B61%203%208344%209950>, M: +61 0438 385 937 <tel:%2B61%200438%20385%20937>

Dept. profile : 
http://www.ie.unimelb.edu.au/people/staff.php?person_ID=141135
Research Gate : https://www.researchgate.net/profile/Tim_Peterson7
Google Scholar: 
http://scholar.google.com.au/citations?user=kkYJLF4AAAAJ&hl=en&oi=ao

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

From martin.tomko at geo.uzh.ch  Thu Nov 19 12:28:18 2015
From: martin.tomko at geo.uzh.ch (Martin Tomko)
Date: 19 Nov 2015 12:28:18 +0100
Subject: [R-sig-Geo] space-time - efficient creation of a
	TracksCollection
In-Reply-To: <564CEA9C.9050102@uni-muenster.de>
References: <2CA1B4FE-73F0-4802-97CB-EF27099130FA@geo.uzh.ch>
	<564CEA9C.9050102@uni-muenster.de>
Message-ID: <A5A583BD-44B3-4FFD-8427-EDBB572D5BAC@geo.uzh.ch>

Dear Edzer, cc list,
thanks for your feedback, that sounds like a good suggestion - that was also my thinking.

I have managed to do the rest up to the splitting without troubles in the past few days. The splitting is a problem with large datasets - it seems that forming a list of df take a lot of memory (probably some objects overhead). Nevertheless, it works up to some extent.

I have resorted to use dlply ( at least it completes, while split fails has troubles with the size of my data, and bigsplit did not work for some reason).

I am still not sure how I would deal with the manual assignment of the 

>> O1 = Tracks(list(T1=T1,T2=T2)

and similar for the TracksColleciton. While I have a function that can be lapply-ied to each sub-df to create an STI object and a Track, I have no idea how to deal with the naming of the objects in Tracks or in the collection.  Maybe if there was a constructor to pass it the list of Track/Tracks respectively, along with a vector of names, that could be ziped together?

I will generate a small sample csv to support our discussion further and send it to you.

Thanks,

Martin



On 18 Nov 2015, at 22:16, Edzer Pebesma <edzer.pebesma at uni-muenster.de> wrote:

> Hi Martin, such a function would be a nice addition to the trajectories
> package, and shouldn't be too hard to write. Maybe you can come up with
> a short example csv data set?
> 
> library trajectories has two demo's, demo(Geolife) and demo(google),
> which read the Geolife data set and google location history json dumps
> to trajectories, but both are overly complicated for what you have in mind.
> 
> The selection you want to do on object and ID can be done on the
> data.frame level, e.g with subset().
> 
> The function to write will use split to split the data.frame in a list
> with sub-data.frames, and lapply to apply functions to list elements.
> 
> On 18/11/15 14:55, Martin Tomko wrote:
>> Dear list, cc Edzer,
>> 
>> I am trying to find an efficient method to read in data into a
>> library(spacetime) TracksCollection, from a large CVS containing gps
>> tracks of individual objects.
>> 
>> I have managed to do this for a small number of tracks, following the
>> documentation, using a spatialPointsDataFrame spdf:
>> 
>> stidf = STIDF(geometry(spdf), spdf at data$timestamp, spdf at data)
>> T1 = Track(stidf)
>> 
>> etc for a number of Tracks, then mergins individual Track objects into
>> Tracks for a given user
>> 
>> O1 = Tracks(list(T1=T1,T2=T2))
>> 
>> and then making a collection
>> Tr = TracksCollection(list(O1=O1,O2=O2)) of individual objects
>> 
>> Now - this is very cumbersome. I have potentially thousands of objects
>> tracked, each with a number of tracks. They are all stored in one large
>> CSV annotated by timestamp, objectid and trackid. Is there any efficient
>> method to parse (even thorugh any other sp object) collections? The
>> manual assignment of o1= o1, o2=o2 etc is the main problem, from my
>> perspective. I would like to supply a vector of names of users, and a
>> list of names of tracks (each are unique in the whole set) to this.
>> 
>> I can loop through the list of data frames for each individual Track
>> before they are coerced into spatialPointDataFrame, and I can get the
>> additional labels - I see this as a way to append a new STI to
>> appropriate Tracks and to the collection?
>> 
>> Any hint welcome.
>> 
>> Thanks,
>> 
>> Martin
>> 
>> 
> 
> -- 
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info
> 


	[[alternative HTML version deleted]]


From loic.dutrieux at wur.nl  Thu Nov 19 14:37:20 2015
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Thu, 19 Nov 2015 14:37:20 +0100
Subject: [R-sig-Geo] Match polygon and dataframe IDs after raster::extract
Message-ID: <564DD090.7090903@wur.nl>

Hi all,

I'm trying to look at correlation between two raster layers, for 
different polygons. So I use raster::extract to get all the raster 
values for every polygon, do the calculation and feed the output back to 
a SpatialPolygonDataFrame.
I got it working, but I have a doubt regarding the order of the rows; 
and it doesn't look like I can use match.ID = TRUE.

See the example below.

library(raster)
library(dplyr)

# Create brick with 2 layers
b <- brick(ncol=36, nrow=18, nl=2)
b[[1]] <- rnorm(ncell(b))
b[[2]] <- rnorm(ncell(b))

# Create sp
cds1 <- rbind(c(-180,-20), c(-160,5), c(-60, 0), c(-160,-60), c(-180,-20))
cds2 <- rbind(c(80,0), c(100,60), c(120,0), c(120,-55), c(80,0))
cds3 <- rbind(c(-10,20), c(50,60), c(70,-10))
polys <- spPolygons(cds1, cds2, cds3)

# Extract all values
df0 <- extract(b, polys, df = TRUE)

# Compute correlation betwen the two layers for every polygons (sorry 
for the pipe)
df1 <- group_by(df0, ID) %>%
   summarise(cor = cor(layer.1, layer.2)) %>%
   data.frame()

# Attach to df to spdf
spdf <- SpatialPointsDataFrame(polys, df1)



How do I know for sure that the order of the rows in the dataframe did 
not get mixed up? Can I just assume that they will remain in the same order?

The dataframe returned by extract has an ID column, but the IDs do not 
correspond to the polygons IDs. For instance if I remove the second 
polygon (which has the ID "2"), the IDs in the df extracted are still 1 
and 2 (instead of 1 and 3).

# Quick function to get polygons IDs
getPolyID <- function(x) {
   sapply(x at polygons, function(x) {x at ID} )
}


getPolyID(polys)
# [1] "1" "2" "3"
getPolyID(polys[-2])
# [1] "1" "3"

unique(extract(b, polys[-2], df = TRUE)$ID)
# [1] 1 2


Any suggestions?

Thanks,
Lo?c


From edzer.pebesma at uni-muenster.de  Thu Nov 19 15:08:45 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 19 Nov 2015 15:08:45 +0100
Subject: [R-sig-Geo] Match polygon and dataframe IDs after
	raster::extract
In-Reply-To: <564DD090.7090903@wur.nl>
References: <564DD090.7090903@wur.nl>
Message-ID: <564DD7ED.2010106@uni-muenster.de>



On 19/11/15 14:37, Lo?c Dutrieux wrote:
> Hi all,
> 
> I'm trying to look at correlation between two raster layers, for
> different polygons. So I use raster::extract to get all the raster
> values for every polygon, do the calculation and feed the output back to
> a SpatialPolygonDataFrame.
> I got it working, but I have a doubt regarding the order of the rows;
> and it doesn't look like I can use match.ID = TRUE.
> 
> See the example below.
> 
> library(raster)
> library(dplyr)
> 
> # Create brick with 2 layers
> b <- brick(ncol=36, nrow=18, nl=2)
> b[[1]] <- rnorm(ncell(b))
> b[[2]] <- rnorm(ncell(b))
> 
> # Create sp
> cds1 <- rbind(c(-180,-20), c(-160,5), c(-60, 0), c(-160,-60), c(-180,-20))
> cds2 <- rbind(c(80,0), c(100,60), c(120,0), c(120,-55), c(80,0))
> cds3 <- rbind(c(-10,20), c(50,60), c(70,-10))
> polys <- spPolygons(cds1, cds2, cds3)
> 
> # Extract all values
> df0 <- extract(b, polys, df = TRUE)
> 
> # Compute correlation betwen the two layers for every polygons (sorry
> for the pipe)
> df1 <- group_by(df0, ID) %>%
>   summarise(cor = cor(layer.1, layer.2)) %>%
>   data.frame()
> 
> # Attach to df to spdf
> spdf <- SpatialPointsDataFrame(polys, df1)
> 
> 
> 
> How do I know for sure that the order of the rows in the dataframe did
> not get mixed up? Can I just assume that they will remain in the same
> order?

If it does reshuffle and you didn't specify match.ID, it will warn you:

> pts = matrix(1:4,2,2,dimnames=list(c("a", "b"), NULL))
> pts
  [,1] [,2]
a    1    3
b    2    4
> df = data.frame(a = 2:3, row.names = c("b", "a"))
> df
  a
b 2
a 3
> SpatialPointsDataFrame(pts, df)
  coordinates a
a      (1, 3) 3
b      (2, 4) 2
Warning message:
In SpatialPointsDataFrame(pts, df) :
  forming a SpatialPointsDataFrame based on maching IDs, not on record
order. Use match.ID = FALSE to match on record order
> SpatialPointsDataFrame(pts, df, match.ID = FALSE)
  coordinates a
b      (1, 3) 2
a      (2, 4) 3

Using match.ID = FALSE ensures the input order of coordinates and points
is kept.

> 
> The dataframe returned by extract has an ID column, but the IDs do not
> correspond to the polygons IDs. For instance if I remove the second
> polygon (which has the ID "2"), the IDs in the df extracted are still 1
> and 2 (instead of 1 and 3).
> 
> # Quick function to get polygons IDs
> getPolyID <- function(x) {
>   sapply(x at polygons, function(x) {x at ID} )
> }
> 
> 
> getPolyID(polys)
> # [1] "1" "2" "3"
> getPolyID(polys[-2])
> # [1] "1" "3"
> 
> unique(extract(b, polys[-2], df = TRUE)$ID)
> # [1] 1 2
> 
> 
> Any suggestions?
> 
> Thanks,
> Lo?c
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151119/8b95be7f/attachment.bin>

From loic.dutrieux at wur.nl  Thu Nov 19 16:36:19 2015
From: loic.dutrieux at wur.nl (=?UTF-8?Q?Lo=c3=afc_Dutrieux?=)
Date: Thu, 19 Nov 2015 16:36:19 +0100
Subject: [R-sig-Geo] Match polygon and dataframe IDs after
	raster::extract
In-Reply-To: <564DD7ED.2010106@uni-muenster.de>
References: <564DD090.7090903@wur.nl> <564DD7ED.2010106@uni-muenster.de>
Message-ID: <564DEC73.6010408@wur.nl>

Thanks Edzer,

But then, how safe is it to match attributes and geometries based on the 
record order? Is there any chance that records get shuffled during the 
dataframe manipulation steps, or the raster::extract?

Also one note, SpatialPointsDataFrame() gives a warning, but 
SpatialPolygonsDataFrame() doesn't. (I made a mistake in my initial 
example, I want to create a SpatialPolygonsDataFrame, not a 
SpatialPointsDataFrame).

Cheers,
Lo?c


On 11/19/2015 03:08 PM, Edzer Pebesma wrote:
>
>
> On 19/11/15 14:37, Lo?c Dutrieux wrote:
>> Hi all,
>>
>> I'm trying to look at correlation between two raster layers, for
>> different polygons. So I use raster::extract to get all the raster
>> values for every polygon, do the calculation and feed the output back to
>> a SpatialPolygonDataFrame.
>> I got it working, but I have a doubt regarding the order of the rows;
>> and it doesn't look like I can use match.ID = TRUE.
>>
>> See the example below.
>>
>> library(raster)
>> library(dplyr)
>>
>> # Create brick with 2 layers
>> b <- brick(ncol=36, nrow=18, nl=2)
>> b[[1]] <- rnorm(ncell(b))
>> b[[2]] <- rnorm(ncell(b))
>>
>> # Create sp
>> cds1 <- rbind(c(-180,-20), c(-160,5), c(-60, 0), c(-160,-60), c(-180,-20))
>> cds2 <- rbind(c(80,0), c(100,60), c(120,0), c(120,-55), c(80,0))
>> cds3 <- rbind(c(-10,20), c(50,60), c(70,-10))
>> polys <- spPolygons(cds1, cds2, cds3)
>>
>> # Extract all values
>> df0 <- extract(b, polys, df = TRUE)
>>
>> # Compute correlation betwen the two layers for every polygons (sorry
>> for the pipe)
>> df1 <- group_by(df0, ID) %>%
>>    summarise(cor = cor(layer.1, layer.2)) %>%
>>    data.frame()
>>
>> # Attach to df to spdf
>> spdf <- SpatialPointsDataFrame(polys, df1)
>>
>>
>>
>> How do I know for sure that the order of the rows in the dataframe did
>> not get mixed up? Can I just assume that they will remain in the same
>> order?
>
> If it does reshuffle and you didn't specify match.ID, it will warn you:
>
>> pts = matrix(1:4,2,2,dimnames=list(c("a", "b"), NULL))
>> pts
>    [,1] [,2]
> a    1    3
> b    2    4
>> df = data.frame(a = 2:3, row.names = c("b", "a"))
>> df
>    a
> b 2
> a 3
>> SpatialPointsDataFrame(pts, df)
>    coordinates a
> a      (1, 3) 3
> b      (2, 4) 2
> Warning message:
> In SpatialPointsDataFrame(pts, df) :
>    forming a SpatialPointsDataFrame based on maching IDs, not on record
> order. Use match.ID = FALSE to match on record order
>> SpatialPointsDataFrame(pts, df, match.ID = FALSE)
>    coordinates a
> b      (1, 3) 2
> a      (2, 4) 3
>
> Using match.ID = FALSE ensures the input order of coordinates and points
> is kept.
>
>>
>> The dataframe returned by extract has an ID column, but the IDs do not
>> correspond to the polygons IDs. For instance if I remove the second
>> polygon (which has the ID "2"), the IDs in the df extracted are still 1
>> and 2 (instead of 1 and 3).
>>
>> # Quick function to get polygons IDs
>> getPolyID <- function(x) {
>>    sapply(x at polygons, function(x) {x at ID} )
>> }
>>
>>
>> getPolyID(polys)
>> # [1] "1" "2" "3"
>> getPolyID(polys[-2])
>> # [1] "1" "3"
>>
>> unique(extract(b, polys[-2], df = TRUE)$ID)
>> # [1] 1 2
>>
>>
>> Any suggestions?
>>
>> Thanks,
>> Lo?c
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From dncgst at gnewarchaeology.it  Thu Nov 19 19:52:20 2015
From: dncgst at gnewarchaeology.it (Domenico Giusti)
Date: Thu, 19 Nov 2015 19:52:20 +0100
Subject: [R-sig-Geo] How to get the borders of scattered spacial points
In-Reply-To: <CAApZs+FxQqA2qTy6Lbv3RZKV3zp4q9b73sEm2uwPLS_+Kj8jDQ@mail.gmail.com>
References: <CAApZs+FxQqA2qTy6Lbv3RZKV3zp4q9b73sEm2uwPLS_+Kj8jDQ@mail.gmail.com>
Message-ID: <564E1A64.9050504@gnewarchaeology.it>

Hi,

convexhull is probably what you need.

Best,

On 11/18/2015 11:56 PM, Zhong-Yuan Zhang wrote:
> Dear All:
> 
>    As a freshman, I am now analyzing some spacial data.
> 
> I want to get the border of scattered spacial points. Are there
> 
> any libraries that I can use?  Also is there any library that can
> 
> use Baidu map API?  I highly appreciate your help and
> 
> suggestions.
> 
>    Best Regards Always.
> 

-- 
Domenico Giusti <dncgst at gnewarchaeology.it>
GPG keyID: 2048R/A3AB7054F6E5D778


From jay.verstreater at gmail.com  Thu Nov 19 19:56:55 2015
From: jay.verstreater at gmail.com (Jay Verstreater)
Date: Thu, 19 Nov 2015 12:56:55 -0600
Subject: [R-sig-Geo] How to get the borders of scattered spacial points
In-Reply-To: <564E1A64.9050504@gnewarchaeology.it>
References: <CAApZs+FxQqA2qTy6Lbv3RZKV3zp4q9b73sEm2uwPLS_+Kj8jDQ@mail.gmail.com>
	<564E1A64.9050504@gnewarchaeology.it>
Message-ID: <CAJueOzo5kiX__s3=b-Dkqq1gKY8yTfsVuzPa6u6WO-aiwTWx7Q@mail.gmail.com>

Please unsubscribe me

On Thu, Nov 19, 2015 at 12:52 PM, Domenico Giusti <dncgst at gnewarchaeology.it
> wrote:

> Hi,
>
> convexhull is probably what you need.
>
> Best,
>
> On 11/18/2015 11:56 PM, Zhong-Yuan Zhang wrote:
> > Dear All:
> >
> >    As a freshman, I am now analyzing some spacial data.
> >
> > I want to get the border of scattered spacial points. Are there
> >
> > any libraries that I can use?  Also is there any library that can
> >
> > use Baidu map API?  I highly appreciate your help and
> >
> > suggestions.
> >
> >    Best Regards Always.
> >
>
> --
> Domenico Giusti <dncgst at gnewarchaeology.it>
> GPG keyID: 2048R/A3AB7054F6E5D778
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Nov 19 22:42:41 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 19 Nov 2015 22:42:41 +0100
Subject: [R-sig-Geo] Match polygon and dataframe IDs after
	raster::extract
In-Reply-To: <564DEC73.6010408@wur.nl>
References: <564DD090.7090903@wur.nl> <564DD7ED.2010106@uni-muenster.de>
	<564DEC73.6010408@wur.nl>
Message-ID: <564E4251.2070806@uni-muenster.de>



On 19/11/15 16:36, Lo?c Dutrieux wrote:
> Thanks Edzer,
> 
> But then, how safe is it to match attributes and geometries based on the
> record order? Is there any chance that records get shuffled during the
> dataframe manipulation steps, or the raster::extract?

Can you think of a reason why the author of the code would do that?

To be sure I would read the docs and then try to understand

library(raster)
getMethod("extract", c("Raster", "SpatialPolygons"))

> Also one note, SpatialPointsDataFrame() gives a warning, but
> SpatialPolygonsDataFrame() doesn't. (I made a mistake in my initial
> example, I want to create a SpatialPolygonsDataFrame, not a
> SpatialPointsDataFrame).

as documented, SpatialPolygonsDataFrame has argument match.ID default to
TRUE.

> 
> Cheers,
> Lo?c
> 
> 
> On 11/19/2015 03:08 PM, Edzer Pebesma wrote:
>>
>>
>> On 19/11/15 14:37, Lo?c Dutrieux wrote:
>>> Hi all,
>>>
>>> I'm trying to look at correlation between two raster layers, for
>>> different polygons. So I use raster::extract to get all the raster
>>> values for every polygon, do the calculation and feed the output back to
>>> a SpatialPolygonDataFrame.
>>> I got it working, but I have a doubt regarding the order of the rows;
>>> and it doesn't look like I can use match.ID = TRUE.
>>>
>>> See the example below.
>>>
>>> library(raster)
>>> library(dplyr)
>>>
>>> # Create brick with 2 layers
>>> b <- brick(ncol=36, nrow=18, nl=2)
>>> b[[1]] <- rnorm(ncell(b))
>>> b[[2]] <- rnorm(ncell(b))
>>>
>>> # Create sp
>>> cds1 <- rbind(c(-180,-20), c(-160,5), c(-60, 0), c(-160,-60),
>>> c(-180,-20))
>>> cds2 <- rbind(c(80,0), c(100,60), c(120,0), c(120,-55), c(80,0))
>>> cds3 <- rbind(c(-10,20), c(50,60), c(70,-10))
>>> polys <- spPolygons(cds1, cds2, cds3)
>>>
>>> # Extract all values
>>> df0 <- extract(b, polys, df = TRUE)
>>>
>>> # Compute correlation betwen the two layers for every polygons (sorry
>>> for the pipe)
>>> df1 <- group_by(df0, ID) %>%
>>>    summarise(cor = cor(layer.1, layer.2)) %>%
>>>    data.frame()
>>>
>>> # Attach to df to spdf
>>> spdf <- SpatialPointsDataFrame(polys, df1)
>>>
>>>
>>>
>>> How do I know for sure that the order of the rows in the dataframe did
>>> not get mixed up? Can I just assume that they will remain in the same
>>> order?
>>
>> If it does reshuffle and you didn't specify match.ID, it will warn you:
>>
>>> pts = matrix(1:4,2,2,dimnames=list(c("a", "b"), NULL))
>>> pts
>>    [,1] [,2]
>> a    1    3
>> b    2    4
>>> df = data.frame(a = 2:3, row.names = c("b", "a"))
>>> df
>>    a
>> b 2
>> a 3
>>> SpatialPointsDataFrame(pts, df)
>>    coordinates a
>> a      (1, 3) 3
>> b      (2, 4) 2
>> Warning message:
>> In SpatialPointsDataFrame(pts, df) :
>>    forming a SpatialPointsDataFrame based on maching IDs, not on record
>> order. Use match.ID = FALSE to match on record order
>>> SpatialPointsDataFrame(pts, df, match.ID = FALSE)
>>    coordinates a
>> b      (1, 3) 2
>> a      (2, 4) 3
>>
>> Using match.ID = FALSE ensures the input order of coordinates and points
>> is kept.
>>
>>>
>>> The dataframe returned by extract has an ID column, but the IDs do not
>>> correspond to the polygons IDs. For instance if I remove the second
>>> polygon (which has the ID "2"), the IDs in the df extracted are still 1
>>> and 2 (instead of 1 and 3).
>>>
>>> # Quick function to get polygons IDs
>>> getPolyID <- function(x) {
>>>    sapply(x at polygons, function(x) {x at ID} )
>>> }
>>>
>>>
>>> getPolyID(polys)
>>> # [1] "1" "2" "3"
>>> getPolyID(polys[-2])
>>> # [1] "1" "3"
>>>
>>> unique(extract(b, polys[-2], df = TRUE)$ID)
>>> # [1] 1 2
>>>
>>>
>>> Any suggestions?
>>>
>>> Thanks,
>>> Lo?c
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151119/b0f31fe4/attachment.bin>

From frtog at vestas.com  Fri Nov 20 07:35:36 2015
From: frtog at vestas.com (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Fri, 20 Nov 2015 06:35:36 +0000
Subject: [R-sig-Geo] How to get the borders of scattered spacial points
In-Reply-To: <CAJueOzo5kiX__s3=b-Dkqq1gKY8yTfsVuzPa6u6WO-aiwTWx7Q@mail.gmail.com>
References: <CAApZs+FxQqA2qTy6Lbv3RZKV3zp4q9b73sEm2uwPLS_+Kj8jDQ@mail.gmail.com>
	<564E1A64.9050504@gnewarchaeology.it>
	<CAJueOzo5kiX__s3=b-Dkqq1gKY8yTfsVuzPa6u6WO-aiwTWx7Q@mail.gmail.com>
Message-ID: <HE1PR04MB1276BF18F3FD8C58D0CF1BEEDB1A0@HE1PR04MB1276.eurprd04.prod.outlook.com>

Hi Jay

So you have forgot all the information you got when you subscribed to the list?

To refresh your memory please see:

https://stat.ethz.ch/mailman/listinfo/r-sig-geo 

Yours sincerely / Med venlig hilsen

Frede Aakmann T?gersen
Specialist, M.Sc., Ph.D.
Plant Performance & Modeling

Technology & Service Solutions
T +45 9730 5135
M +45 2547 6050
frtog at vestas.com
http://www.vestas.com

Company reg. name: Vestas Wind Systems A/S
This e-mail is subject to our e-mail disclaimer statement.
Please refer to www.vestas.com/legal/notice
If you have received this e-mail in error please contact the sender. 



-----Original Message-----
From: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Jay Verstreater
Sent: 19. november 2015 19:57
To: r-sig-geo
Subject: Re: [R-sig-Geo] How to get the borders of scattered spacial points

Please unsubscribe me

On Thu, Nov 19, 2015 at 12:52 PM, Domenico Giusti <dncgst at gnewarchaeology.it
> wrote:

> Hi,
>
> convexhull is probably what you need.
>
> Best,
>
> On 11/18/2015 11:56 PM, Zhong-Yuan Zhang wrote:
> > Dear All:
> >
> >    As a freshman, I am now analyzing some spacial data.
> >
> > I want to get the border of scattered spacial points. Are there
> >
> > any libraries that I can use?  Also is there any library that can
> >
> > use Baidu map API?  I highly appreciate your help and
> >
> > suggestions.
> >
> >    Best Regards Always.
> >
>
> --
> Domenico Giusti <dncgst at gnewarchaeology.it>
> GPG keyID: 2048R/A3AB7054F6E5D778
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From alobolistas at gmail.com  Fri Nov 20 10:34:36 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 20 Nov 2015 10:34:36 +0100
Subject: [R-sig-Geo] title in plot of raster::stack or brick objects
Message-ID: <CAG4NReLM9wXTr6xZJrXw6t1=XXuYOyL=DVC-vkykWhTxwPKy=g@mail.gmail.com>

Given
r <- raster(nrows=10, ncols=10)
r <- setValues(r, 1:ncell(r))
s <- stack(r, sqrt(r), r/sqrt(r))
names(s) <- paste0("S",1:3)
plot(s)

Is there any way to put a main title centered on the multiple plot and
get the names of the layers displayed as well?

plot(s, main="S")
puts the title for the 1st layer only and eliminates the names of the
layers from the plot

Thanks


From jmprietob at gmail.com  Fri Nov 20 10:42:55 2015
From: jmprietob at gmail.com (Jose)
Date: Fri, 20 Nov 2015 10:42:55 +0100
Subject: [R-sig-Geo] title in plot of raster::stack or brick objects
In-Reply-To: <CAG4NReLM9wXTr6xZJrXw6t1=XXuYOyL=DVC-vkykWhTxwPKy=g@mail.gmail.com>
References: <CAG4NReLM9wXTr6xZJrXw6t1=XXuYOyL=DVC-vkykWhTxwPKy=g@mail.gmail.com>
Message-ID: <CAErPEPv2_K0yYujtUuOZYK1jmvEfWLrE-6zMcVRY+GtrUXPzRw@mail.gmail.com>

Hello,
try with title():

r <- raster(nrows=10, ncols=10)
r <- setValues(r, 1:ncell(r))
s <- stack(r, sqrt(r), r/sqrt(r))
names(s) <- paste0("S",1:3)
plot(s)
title("Title", line=3)

Best

______________________________________
Jos? Manuel Prieto
https://jmprietob.shinyapps.io/eltiempo/
es.linkedin.com/in/josemanuelprietoblazquez/

2015-11-20 10:34 GMT+01:00 Agustin Lobo <alobolistas at gmail.com>:

> Given
> r <- raster(nrows=10, ncols=10)
> r <- setValues(r, 1:ncell(r))
> s <- stack(r, sqrt(r), r/sqrt(r))
> names(s) <- paste0("S",1:3)
> plot(s)
>
> Is there any way to put a main title centered on the multiple plot and
> get the names of the layers displayed as well?
>
> plot(s, main="S")
> puts the title for the 1st layer only and eliminates the names of the
> layers from the plot
>
> Thanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From alobolistas at gmail.com  Fri Nov 20 10:51:09 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 20 Nov 2015 10:51:09 +0100
Subject: [R-sig-Geo] title in plot of raster::stack or brick objects
In-Reply-To: <CAErPEPv2_K0yYujtUuOZYK1jmvEfWLrE-6zMcVRY+GtrUXPzRw@mail.gmail.com>
References: <CAG4NReLM9wXTr6xZJrXw6t1=XXuYOyL=DVC-vkykWhTxwPKy=g@mail.gmail.com>
	<CAErPEPv2_K0yYujtUuOZYK1jmvEfWLrE-6zMcVRY+GtrUXPzRw@mail.gmail.com>
Message-ID: <CAG4NReKYsi5ACv1=WRLS-meGbTpLaXJDiWhn5U-JXFQBe8jsYg@mail.gmail.com>

Thanks. Not great though, as the actual position depends on
the shape of the of the display . I.e., if you are on RStudio, open
the zoom window and the main title gets lower than the names of the
layers.

Perhaps the problem would be alleviated if raster::plot() could display
layer names as subtitles (at the bottom of the layers). That would leave more
room for the main title at the main top.

Agus

On Fri, Nov 20, 2015 at 10:42 AM, Jose <jmprietob at gmail.com> wrote:
> Hello,
> try with title():
>
> r <- raster(nrows=10, ncols=10)
> r <- setValues(r, 1:ncell(r))
> s <- stack(r, sqrt(r), r/sqrt(r))
> names(s) <- paste0("S",1:3)
> plot(s)
> title("Title", line=3)
>
> Best
>
> ______________________________________
> Jos? Manuel Prieto
> https://jmprietob.shinyapps.io/eltiempo/
> es.linkedin.com/in/josemanuelprietoblazquez/
>
> 2015-11-20 10:34 GMT+01:00 Agustin Lobo <alobolistas at gmail.com>:
>
>> Given
>> r <- raster(nrows=10, ncols=10)
>> r <- setValues(r, 1:ncell(r))
>> s <- stack(r, sqrt(r), r/sqrt(r))
>> names(s) <- paste0("S",1:3)
>> plot(s)
>>
>> Is there any way to put a main title centered on the multiple plot and
>> get the names of the layers displayed as well?
>>
>> plot(s, main="S")
>> puts the title for the 1st layer only and eliminates the names of the
>> layers from the plot
>>
>> Thanks
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mdsumner at gmail.com  Fri Nov 20 10:55:41 2015
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 20 Nov 2015 09:55:41 +0000
Subject: [R-sig-Geo] How to get the borders of scattered spacial points
In-Reply-To: <564E1A64.9050504@gnewarchaeology.it>
References: <CAApZs+FxQqA2qTy6Lbv3RZKV3zp4q9b73sEm2uwPLS_+Kj8jDQ@mail.gmail.com>
	<564E1A64.9050504@gnewarchaeology.it>
Message-ID: <CAAcGz9_j6K1_-1bmVaFqAs-ru0RN6XTyFj6vZCsLe7=O5B=woQ@mail.gmail.com>

On Fri, 20 Nov 2015 at 05:52 Domenico Giusti <dncgst at gnewarchaeology.it>
wrote:

> Hi,
>
> convexhull is probably what you need.
>
>
And if it is, there is ?grDevices::chull.

But, if convex is not what you are after the parameter-izable alphahull
(the package on CRAN) is more like it.

Cheers, Mike.



> Best,
>
> On 11/18/2015 11:56 PM, Zhong-Yuan Zhang wrote:
> > Dear All:
> >
> >    As a freshman, I am now analyzing some spacial data.
> >
> > I want to get the border of scattered spacial points. Are there
> >
> > any libraries that I can use?  Also is there any library that can
> >
> > use Baidu map API?  I highly appreciate your help and
> >
> > suggestions.
> >
> >    Best Regards Always.
> >
>
> --
> Domenico Giusti <dncgst at gnewarchaeology.it>
> GPG keyID: 2048R/A3AB7054F6E5D778
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From jmprietob at gmail.com  Fri Nov 20 10:59:54 2015
From: jmprietob at gmail.com (Jose)
Date: Fri, 20 Nov 2015 10:59:54 +0100
Subject: [R-sig-Geo] title in plot of raster::stack or brick objects
In-Reply-To: <CAG4NReKYsi5ACv1=WRLS-meGbTpLaXJDiWhn5U-JXFQBe8jsYg@mail.gmail.com>
References: <CAG4NReLM9wXTr6xZJrXw6t1=XXuYOyL=DVC-vkykWhTxwPKy=g@mail.gmail.com>
	<CAErPEPv2_K0yYujtUuOZYK1jmvEfWLrE-6zMcVRY+GtrUXPzRw@mail.gmail.com>
	<CAG4NReKYsi5ACv1=WRLS-meGbTpLaXJDiWhn5U-JXFQBe8jsYg@mail.gmail.com>
Message-ID: <CAErPEPtK5zRwuB1bBBKPJnGJep18FaNrP8kADSa3m=9BSPnARQ@mail.gmail.com>

maybe with spplot(), but the plot has only one legend for all the layers.

Regards

______________________________________
Jos? Manuel Prieto
https://jmprietob.shinyapps.io/eltiempo/
es.linkedin.com/in/josemanuelprietoblazquez/

2015-11-20 10:51 GMT+01:00 Agustin Lobo <alobolistas at gmail.com>:

> Thanks. Not great though, as the actual position depends on
> the shape of the of the display . I.e., if you are on RStudio, open
> the zoom window and the main title gets lower than the names of the
> layers.
>
> Perhaps the problem would be alleviated if raster::plot() could display
> layer names as subtitles (at the bottom of the layers). That would leave
> more
> room for the main title at the main top.
>
> Agus
>
> On Fri, Nov 20, 2015 at 10:42 AM, Jose <jmprietob at gmail.com> wrote:
> > Hello,
> > try with title():
> >
> > r <- raster(nrows=10, ncols=10)
> > r <- setValues(r, 1:ncell(r))
> > s <- stack(r, sqrt(r), r/sqrt(r))
> > names(s) <- paste0("S",1:3)
> > plot(s)
> > title("Title", line=3)
> >
> > Best
> >
> > ______________________________________
> > Jos? Manuel Prieto
> > https://jmprietob.shinyapps.io/eltiempo/
> > es.linkedin.com/in/josemanuelprietoblazquez/
> >
> > 2015-11-20 10:34 GMT+01:00 Agustin Lobo <alobolistas at gmail.com>:
> >
> >> Given
> >> r <- raster(nrows=10, ncols=10)
> >> r <- setValues(r, 1:ncell(r))
> >> s <- stack(r, sqrt(r), r/sqrt(r))
> >> names(s) <- paste0("S",1:3)
> >> plot(s)
> >>
> >> Is there any way to put a main title centered on the multiple plot and
> >> get the names of the layers displayed as well?
> >>
> >> plot(s, main="S")
> >> puts the title for the 1st layer only and eliminates the names of the
> >> layers from the plot
> >>
> >> Thanks
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From alobolistas at gmail.com  Fri Nov 20 14:37:23 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 20 Nov 2015 14:37:23 +0100
Subject: [R-sig-Geo] Different values from raster::Moran() and
	spdep::moran.test()
Message-ID: <CAG4NRe+KfD351HMQrRa7LRg1=QfG3jJREjqbsf_+6eYX2_a9wg@mail.gmail.com>

Using the testGrid example provided by
https://stat.ethz.ch/pipermail/r-sig-geo/2014-December/022106.html

lng <- rep(seq(0, 7, by=1), 8)
counter = 1
subCounter = 0
startNum = 0
lat = NULL
while (counter < 65) {
  if (subCounter == 8) {
    startNum = startNum + 1
    subCounter = 0
  }
  lat = c(lat, startNum)
  subCounter = subCounter + 1
  counter = counter + 1
}
# now add the black/ white chessboard pattern
chess <- rep(c(0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0), 4)
gridNum <- seq(1:64)
testGrid <- data.frame(gridNum, lat, lng, chess)

I define
require(raster)
rtestGrid <- rasterFromXYZ(testGrid[,2:4])
plot(rtestGrid)

and run

Moran(rtestGrid)
which results on:

[1] 0.07438017

while

require(spdep)
nb8q <- cell2nb(8, 8, type="queen", torus=FALSE)
moran.test(testGrid$chess, nb2listw(nb8q, style="B"),alternative="two.sided")

which results on:
Moran's I test under randomisation

data:  testGrid$chess
weights: nb2listw(nb8q, style = "B")

Moran I statistic standard deviate = -0.7714, p-value = 0.4404
alternative hypothesis: two.sided
sample estimates:
Moran I statistic       Expectation          Variance
     -0.066666667      -0.015873016       0.004335237

Considering the grid is regular, a negative I value makes sense.

Why is Moran() so different?

Thanks


From Roger.Bivand at nhh.no  Fri Nov 20 20:51:57 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 20 Nov 2015 20:51:57 +0100
Subject: [R-sig-Geo] Different values from raster::Moran() and
 spdep::moran.test()
In-Reply-To: <CAG4NRe+KfD351HMQrRa7LRg1=QfG3jJREjqbsf_+6eYX2_a9wg@mail.gmail.com>
References: <CAG4NRe+KfD351HMQrRa7LRg1=QfG3jJREjqbsf_+6eYX2_a9wg@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1511202037210.14224@reclus.nhh.no>

On Fri, 20 Nov 2015, Agustin Lobo wrote:

> Using the testGrid example provided by
> https://stat.ethz.ch/pipermail/r-sig-geo/2014-December/022106.html
>
> lng <- rep(seq(0, 7, by=1), 8)
> counter = 1
> subCounter = 0
> startNum = 0
> lat = NULL
> while (counter < 65) {
>  if (subCounter == 8) {
>    startNum = startNum + 1
>    subCounter = 0
>  }
>  lat = c(lat, startNum)
>  subCounter = subCounter + 1
>  counter = counter + 1
> }
> # now add the black/ white chessboard pattern
> chess <- rep(c(0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0), 4)
> gridNum <- seq(1:64)
> testGrid <- data.frame(gridNum, lat, lng, chess)
>
> I define
> require(raster)
> rtestGrid <- rasterFromXYZ(testGrid[,2:4])
> plot(rtestGrid)
>
> and run
>
> Moran(rtestGrid)
> which results on:
>
> [1] 0.07438017

The raster::Moran function does:

Moran(rtestGrid, w = matrix(1, 3, 3))

which makes i its own neighbour. The spdep::moran.test result can be 
reproduced by using:

Moran(rtestGrid, w=matrix(c(1,1,1,1,0,1,1,1,1), 3, 3))

that is, omitting i from the set of its neighbours.

Equivalently,

moran.test(testGrid$chess, nb2listw(include.self(nb8q), style="B"),
   alternative="two.sided")

in spdep::moran.test gives the default raster::Moran result.

The rook neighbours definition on ?raster::Moran is defined without the 
self-neighbour relationship (arguably correctly). I would suggest that the 
defaults for raster::Moran, Geary, MoranLocal and GearyLocal should be 
changed from w=matrix(1, 3, 3) to omit the self-neighbour on the central 
cell.

Hope this clarifies,

Roger

>
> while
>
> require(spdep)
> nb8q <- cell2nb(8, 8, type="queen", torus=FALSE)
> moran.test(testGrid$chess, nb2listw(nb8q, style="B"),alternative="two.sided")
>
> which results on:
> Moran's I test under randomisation
>
> data:  testGrid$chess
> weights: nb2listw(nb8q, style = "B")
>
> Moran I statistic standard deviate = -0.7714, p-value = 0.4404
> alternative hypothesis: two.sided
> sample estimates:
> Moran I statistic       Expectation          Variance
>     -0.066666667      -0.015873016       0.004335237
>
> Considering the grid is regular, a negative I value makes sense.
>
> Why is Moran() so different?
>
> Thanks
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From alobolistas at gmail.com  Sat Nov 21 12:28:15 2015
From: alobolistas at gmail.com (Agustin Lobo)
Date: Sat, 21 Nov 2015 12:28:15 +0100
Subject: [R-sig-Geo] Results from spdep::moran.mc() different from
 raster::Moran() on randomized raster layers
Message-ID: <CAG4NReL1BiPRPEFG+4c4JUb8RvLqR7b5DANo8Qq_nzHVXCJStw@mail.gmail.com>

I compare results of moran.test() and moran.mc()
to results of randomizing a raster layer and
calculating the mean and range of the raster::Moran() values
using w=matrix(c(1,1,1,1,0,1,1,1,1), 3, 3) (following advise
https://stat.ethz.ch/pipermail/r-sig-geo/2015-November/023761.html)

While the spdep functions let reject the null hypothesis
of CSR because of regularity (which makes sense
because the test is a check board pattern),
the range of raster::Moran() for the randomized raster
layers include the actual value of the observed test layer.
Could this be caused by the fact that the test raster layer
is too small (8x8)? Because sample() is actually not
randomizing as boot()? An error on my side?

This is what I do:

Using the testGrid example provided by
https://stat.ethz.ch/pipermail/r-sig-geo/2014-December/022106.html

lng <- rep(seq(0, 7, by=1), 8)
counter = 1
subCounter = 0
startNum = 0
lat = NULL
while (counter < 65) {
 if (subCounter == 8) {
   startNum = startNum + 1
   subCounter = 0
 }
 lat = c(lat, startNum)
 subCounter = subCounter + 1
 counter = counter + 1
}
# now add the black/ white chessboard pattern
chess <- rep(c(0,1,0,1,0,1,0,1,1,0,1,0,1,0,1,0), 4)
gridNum <- seq(1:64)
testGrid <- data.frame(gridNum, lat, lng, chess)


nb8q <- cell2nb(8, 8, type="queen", torus=FALSE)
moran.test(testGrid$chess, nb2listw(nb8q, style="B"), alternative="less")
moran.mc(testGrid$chess,nb2listw(nb8q, style="B"),nsim=200,alternative="less")
wn=matrix(c(1,1,1,1,0,1,1,1,1), 3, 3)
Moran(rtestGrid, w=wn)
nsim=200
rtest <- rtestGrid
vmoran <- (1:nsim)*0
for (i in 1:nsim){
  rtest[] <- sample(rtestGrid,ncell(rtestGrid),replace=TRUE)
  vmoran[i] <- Moran(rtest, w=wn)
  }
mean(vmoran)
var(vmoran)
range(vmoran)
hist(vmoran)
Moran(rtestGrid, w=wn)


From e.j.h.polle at gmail.com  Mon Nov 23 16:13:07 2015
From: e.j.h.polle at gmail.com (=?UTF-8?B?RWdnZS1KYW4gUG9sbMOp?=)
Date: Mon, 23 Nov 2015 16:13:07 +0100
Subject: [R-sig-Geo] Open source e-book "Geografische analyses met R"
Message-ID: <CAGVoNq0UJ+iyajL1jO1iKpKNKEdDFv_3t=nVttKyB=NdKXMRGg@mail.gmail.com>

Hi list,


I would like to draw your attention to a new publication:

an open source e-book "Geografische analyses met R"

Book:
http://www.twiav.nl/nl/cursusR/Geografische_analyses_met_R.pdf

Source:
https://github.com/TWIAV/Geografische_analyses_met_R


65 pages, packed with code samples, with sample data about the Netherlands.

Reviews are more than welcome.

Due to the language used in the book: this manual is mainly targeted at a
Dutch-reading audience.

BR,

Egge-Jan

------------------------------------------------------------------------------
Egge-Jan Poll?
e.j.h.polle at gmail.com
http://www.linkedin.com/in/ejhpolle
------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From andrewcd at gmail.com  Mon Nov 23 19:21:22 2015
From: andrewcd at gmail.com (ACD)
Date: Mon, 23 Nov 2015 13:21:22 -0500
Subject: [R-sig-Geo] Spatial clustering gridded data with missing values
 (over water)
In-Reply-To: <alpine.LFD.2.20.1511131431230.17643@reclus.nhh.no>
References: <5642097C.5010604@gmail.com>
	<alpine.LFD.2.20.1511131431230.17643@reclus.nhh.no>
Message-ID: <56535922.9080803@gmail.com>

Dear Roger,

Many thanks for this reply -- I see that the problem goes away when 
representing the data as gridcell polygons rather than as the gridpoints 
which they are.

This works well on the small data subset that I uploaded for my minimal 
working example, but the algorithm is quite slow on the full dataset 
(>3000 gridcells, with 19+ covariates).  Is there anything inherently 
faster or slower about the skater algorithm run on polygons vs the algo 
run on gridded data?

Thanks,
Andrew

On 11/13/2015 08:37 AM, Roger Bivand wrote:
> On Tue, 10 Nov 2015, ACD wrote:
>
>> I'm trying to cluster a spatial dataset, and use the cluster labels 
>> as an input to a second process. I've been using the `spdep` package 
>> in R.
>>
>> I've got gridded data at .5 degree lat/lon resolution.  There are 19 
>> covariates in the example subset of it linked here: 
>> https://www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0
>>
>> The following shows that I can't calculate the minimum spanning tree 
>> -- a necessary input into `skater` -- when the dataset includes areas 
>> undefined because they are over water.
>>
>> How would one get around this?
>>
>>    system('wget 
>> https://www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0')
>>     load('example_data?dl=0')
>>
>>         1> with(x, plot(lon,lat))
>
> No, don't do this, you are obscuring the data. Do first str(x), then 
> build the object so that you know what is going on (the object 
> structure matches the data representation more closely):
>
> library(sp)
> coordinates(x) <- c("lon", "lat")
> proj4string(x) <- CRS("+proj=longlat +datum=WGS84")
> plot(x)
>
> OK, it's gridded, and n is small, so build the neighbour object using 
> polygons, queen neighbours:
>
> gridded(x) <- TRUE
> x1 <- as(x, "SpatialPolygonsDataFrame")
> library(spdep)
> bh.nb <- poly2nb(x1)
> plot(x1)
> plot(bh.nb, coordinates(x1), add=TRUE)
>
>
>>         1> library(spdep)
>>         1> bh.nb <- 
>> cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
>>         1> lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
>>         Error in data[id.neigh, , drop = FALSE] : subscript out of 
>> bounds
>>
>>
>> If I restrict the data to cut out the missing values, I have no problem:
>
> From there on, it is reasonably simple:
>
> lcosts <- nbcosts(nb = bh.nb, data = as(x1, "data.frame"),
>  method='euclidean')
> nb.w <- nb2listw(bh.nb, lcosts, style="B")
> mst.bh <- mstree(nb.w, 10)
> res1 <- skater(mst.bh[,1:2], as(x1, "data.frame"), 5)
> plot(res1, coordinates(x1), cex.circles=0.035, cex.lab=.7)
>
> Hope this clarifies,
>
> Roger
>
>
>>
>>     x = x[x$lon>-117,]
>>     bh.nb <- 
>> cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
>>     lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
>>     nb.w <- nb2listw(bh.nb, lcosts, style="B")
>>     mst.bh <- mstree(nb.w,10)
>>     res1 <- skater(mst.bh[,1:2], x, 5)
>>     plot(res1, cbind(x$lon,x$lat), cex.circles=0.035, cex.lab=.7)
>>
>>
>> How do I get around this over-water problem?  I want to be able to 
>> cluster the land surfaces, including islands and peninsulas. I 
>> suppose that I want islands to be linked to their nearest point of land.
>>
>> References appreciated as well as fixes to the specific problem with 
>> the `spdep` interface.
>>
>> Thanks!
>> Andrew
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From Roger.Bivand at nhh.no  Mon Nov 23 19:27:33 2015
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 23 Nov 2015 19:27:33 +0100
Subject: [R-sig-Geo] Spatial clustering gridded data with missing values
 (over water)
In-Reply-To: <56535922.9080803@gmail.com>
References: <5642097C.5010604@gmail.com>
	<alpine.LFD.2.20.1511131431230.17643@reclus.nhh.no>
	<56535922.9080803@gmail.com>
Message-ID: <alpine.LFD.2.20.1511231922590.26099@reclus.nhh.no>

On Mon, 23 Nov 2015, ACD wrote:

> Dear Roger,
>
> Many thanks for this reply -- I see that the problem goes away when 
> representing the data as gridcell polygons rather than as the gridpoints 
> which they are.
>
> This works well on the small data subset that I uploaded for my minimal 
> working example, but the algorithm is quite slow on the full dataset (>3000 
> gridcells, with 19+ covariates).  Is there anything inherently faster or 
> slower about the skater algorithm run on polygons vs the algo run on gridded 
> data?

No, nothing faster, and note that the important conversion is via 
SpatialPixels (gridded() <- TRUE), which avoids the no-data grid cells in 
your example. All these methods work on the underlying neighbour graph, 
which for skater must be a single graph with no detached subgraphs. You 
may use the facilities provided in the skater workflow for parallel 
processing, which may help.

Roger

>
> Thanks,
> Andrew
>
> On 11/13/2015 08:37 AM, Roger Bivand wrote:
>>  On Tue, 10 Nov 2015, ACD wrote:
>> 
>> >  I'm trying to cluster a spatial dataset, and use the cluster labels as 
>> >  an input to a second process. I've been using the `spdep` package in R.
>> > 
>> >  I've got gridded data at .5 degree lat/lon resolution.  There are 19 
>> >  covariates in the example subset of it linked here: 
>> > https: //www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0
>> > 
>> >  The following shows that I can't calculate the minimum spanning tree -- 
>> >  a necessary input into `skater` -- when the dataset includes areas 
>> >  undefined because they are over water.
>> > 
>> >  How would one get around this?
>> > 
>> >     system('wget 
>> > https: //www.dropbox.com/s/i72na4k0k5gqvvx/example_data?dl=0')
>> >      load('example_data?dl=0')
>> > 
>> >          1> with(x, plot(lon,lat))
>>
>>  No, don't do this, you are obscuring the data. Do first str(x), then build
>>  the object so that you know what is going on (the object structure matches
>>  the data representation more closely):
>>
>>  library(sp)
>>  coordinates(x) <- c("lon", "lat")
>>  proj4string(x) <- CRS("+proj=longlat +datum=WGS84")
>>  plot(x)
>>
>>  OK, it's gridded, and n is small, so build the neighbour object using
>>  polygons, queen neighbours:
>>
>>  gridded(x) <- TRUE
>>  x1 <- as(x, "SpatialPolygonsDataFrame")
>>  library(spdep)
>>  bh.nb <- poly2nb(x1)
>>  plot(x1)
>>  plot(bh.nb, coordinates(x1), add=TRUE)
>> 
>> 
>> >          1> library(spdep)
>> >          1> bh.nb <- 
>> >  cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
>> >          1> lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
>> >          Error in data[id.neigh, , drop = FALSE] : subscript out of 
>> >  bounds
>> > 
>> > 
>> >  If I restrict the data to cut out the missing values, I have no problem:
>>
>>  From there on, it is reasonably simple:
>>
>>  lcosts <- nbcosts(nb = bh.nb, data = as(x1, "data.frame"),
>>  method='euclidean')
>>  nb.w <- nb2listw(bh.nb, lcosts, style="B")
>>  mst.bh <- mstree(nb.w, 10)
>>  res1 <- skater(mst.bh[,1:2], as(x1, "data.frame"), 5)
>>  plot(res1, coordinates(x1), cex.circles=0.035, cex.lab=.7)
>>
>>  Hope this clarifies,
>>
>>  Roger
>> 
>> 
>> > 
>> >      x = x[x$lon>-117,]
>> >      bh.nb <- 
>> >  cell2nb(length(unique(x$lon)),length(unique(x$lat)),torus=F,type='queen')
>> >      lcosts <- nbcosts(nb = bh.nb, data = x,method='euclidean')
>> >      nb.w <- nb2listw(bh.nb, lcosts, style="B")
>> >      mst.bh <- mstree(nb.w,10)
>> >      res1 <- skater(mst.bh[,1:2], x, 5)
>> >      plot(res1, cbind(x$lon,x$lat), cex.circles=0.035, cex.lab=.7)
>> > 
>> > 
>> >  How do I get around this over-water problem?  I want to be able to 
>> >  cluster the land surfaces, including islands and peninsulas. I suppose 
>> >  that I want islands to be linked to their nearest point of land.
>> > 
>> >  References appreciated as well as fixes to the specific problem with the 
>> >  `spdep` interface.
>> > 
>> >  Thanks!
>> >  Andrew
>> > 
>> >  _______________________________________________
>> >  R-sig-Geo mailing list
>> >  R-sig-Geo at r-project.org
>> > https: //stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > 
>> 
>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no


From w1malik at gmail.com  Tue Nov 24 13:56:01 2015
From: w1malik at gmail.com (Waseem Ali)
Date: Tue, 24 Nov 2015 17:56:01 +0500
Subject: [R-sig-Geo] =?windows-1256?q?How_to_download_individual_layer_fro?=
 =?windows-1256?q?m_MODIS_Package_using_runGdal=FE?=
Message-ID: <SNT151-W38493A238BC095CCF2384CEB060@phx.gbl>




Hi,I am recently working on downloading modis product called "MOD13Q1" EVI scientific data set starting from 2001 to 2004 time series data. Downloading individual data from lpdaac is daunting task. With a little effort I came across using MODIS R package to download bunch of data in a sequential fashion. The following is my code for single scene:library(MODIS)dates <- as.POSIXct( as.Date(c("01/05/2014"),format = "%d/%m/%Y") )
dates2 <- transDate(dates[1]) # Transform input dates from before 
h = "23"v = "05"runGdal(product = "MOD13Q1", begin=dates2$beginDOY,end = dates2$endDOY,tileH = h,tileV = v)My question is that Is that possible i can add layer information despite to fully download hdf (including 12 layers). I just need 2 layers that will reduce my time to download full product.Waseem Ali 


 		 	   		  
	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Wed Nov 25 09:46:33 2015
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 25 Nov 2015 09:46:33 +0100
Subject: [R-sig-Geo] gstat::krige() - regression kriging vs. kriging
 with external drift
In-Reply-To: <000901d11efa$026b78b0$07426a10$@gmail.com>
References: <000901d11efa$026b78b0$07426a10$@gmail.com>
Message-ID: <56557569.6020500@uni-muenster.de>


On 14/11/15 17:32, Bede-Fazekas ?kos wrote:
> Dear List, dear Edzer,
> is it correct if I use the term "regression kriging" when I run this
> function?:
> kriged_value <- gstat::krige(z ~ x + y, [...])@data$var1.pred
> 
> Or should I call it "kriging with external drift" (or "universal kriging" if
> x and y are coordinates), and use the term "regression kriging" only in the
> case of running this?:
> linear_model <- lm(z ~ x + y, [...])
> residuals <- linear_model$residuals
> kriged_residuals <- gstat::krige(residuals ~ 1, [...])@data$var1.pred
> kriged_value <- linear_model$fitted.values + kriged_residuals
> 

For what it's worth, my opinion:

I would call it universal kriging, in line with the software you're
using (which I wrote):

> x = krige(zinc~x+y, meuse, meuse.grid, m)
[using universal kriging]

Most of the (older) literature associates external drift kriging with a
single external drift variable (e.g. Goovaerts), and universal kriging
with using coordinates as covariates.

The statistician might call everything best linear unbiased prediction
under the the general linear model y = X beta + e, with a spatial
covariance function describing the covariance of e, and in that
perspective both methods are equivalent.

I'm not the person to tell what regression kriging is and what it is
not, but it might include the above models as well as those where trend
fitting and residuals are done in different steps, and potentially under
different assumptions for e.

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi),  University of M?nster,
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/
Spatial Statistics Society http://www.spatialstatistics.info

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20151125/b25e72fb/attachment.bin>

From kimofos at yahoo.com  Sat Nov 28 12:00:56 2015
From: kimofos at yahoo.com (Mohammad Abdel-Razek)
Date: Sat, 28 Nov 2015 11:00:56 +0000 (UTC)
Subject: [R-sig-Geo] Any plans to include MOD13Q1 collection 6 download and
 processing in MODIS package?
References: <2045919622.11934337.1448708456081.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2045919622.11934337.1448708456081.JavaMail.yahoo@mail.yahoo.com>

Dear List,
Are there any plans in the near future to include vegetation indices collection 6 download and processing in MODIS package?
thanks,Mohammad
	[[alternative HTML version deleted]]


From hengl at spatial-analyst.net  Sun Nov 29 20:35:37 2015
From: hengl at spatial-analyst.net (Tomislav Hengl)
Date: Sun, 29 Nov 2015 19:35:37 +0000
Subject: [R-sig-Geo] gstat::krige() - regression kriging vs. kriging
 with external drift
In-Reply-To: <56557569.6020500@uni-muenster.de>
References: <000901d11efa$026b78b0$07426a10$@gmail.com>
	<56557569.6020500@uni-muenster.de>
Message-ID: <20151129193537.Horde.UNixyQU7_yw2I3OJ20Bezw6@spatial-analyst.net>


I usually use "Kriging with External Drift (KED)" and "Universal  
kriging" as synonyms. I think "Universal kriging" is the oldest term  
(Matheron, 1963), but then 'universal' can seem a bit vague.

Regression-kriging (RK) is when you krige the residuals and add them  
to the trend (hence predict 'm' and 'e' separately). Edzer (gstat)  
implements mainly KED/UK, but then you need the regression residuals  
to estimate the variogram (I guess getting the residuals before you  
fit variogram is unavoidable). Both RK and KED/UK are equivalent i.e.  
give exactly the same predictions under same input settings  
(http://dx.doi.org/10.1016/j.cageo.2007.05.001), so this is where many  
get confused (two paths to the same destination).

The code you have sent is definitively RK.

The real difference between RK and KED is that with RK you can use  
different modelling techniques including random forest and similar. As  
long as the residuals are normal, you can then add interpolated  
residuals back to the trend.

HTH,

T. Hengl

Quoting Edzer Pebesma <edzer.pebesma at uni-muenster.de>:

> On 14/11/15 17:32, Bede-Fazekas ?kos wrote:
>> Dear List, dear Edzer,
>> is it correct if I use the term "regression kriging" when I run this
>> function?:
>> kriged_value <- gstat::krige(z ~ x + y, [...])@data$var1.pred
>>
>> Or should I call it "kriging with external drift" (or "universal kriging" if
>> x and y are coordinates), and use the term "regression kriging" only in the
>> case of running this?:
>> linear_model <- lm(z ~ x + y, [...])
>> residuals <- linear_model$residuals
>> kriged_residuals <- gstat::krige(residuals ~ 1, [...])@data$var1.pred
>> kriged_value <- linear_model$fitted.values + kriged_residuals
>>
>
> For what it's worth, my opinion:
>
> I would call it universal kriging, in line with the software you're
> using (which I wrote):
>
>> x = krige(zinc~x+y, meuse, meuse.grid, m)
> [using universal kriging]
>
> Most of the (older) literature associates external drift kriging with a
> single external drift variable (e.g. Goovaerts), and universal kriging
> with using coordinates as covariates.
>
> The statistician might call everything best linear unbiased prediction
> under the the general linear model y = X beta + e, with a spatial
> covariance function describing the covariance of e, and in that
> perspective both methods are equivalent.
>
> I'm not the person to tell what regression kriging is and what it is
> not, but it might include the above models as well as those where trend
> fitting and residuals are done in different steps, and potentially under
> different assumptions for e.
>
> --
> Edzer Pebesma
> Institute for Geoinformatics (ifgi),  University of M?nster,
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> Spatial Statistics Society http://www.spatialstatistics.info


From mweynants at gmail.com  Mon Nov 30 17:29:57 2015
From: mweynants at gmail.com (Melanie Weynants)
Date: Mon, 30 Nov 2015 17:29:57 +0100
Subject: [R-sig-Geo] problem with overlay applied to rasterStack
Message-ID: <CAAz9N_eZ+D80KmnKOM9qfjwpSS4=pHnDi8-M7oD1CPBZ-DETgg@mail.gmail.com>

Hi,
I am trying to apply a function with overlay on a raster stack. It works OK
with a small stack of synthetic data, but crashes when I apply it to a
larger stack.
Here is my script:

# create test data with structure similar to real data
# 100 x 100 x 7 array of integers between 1 and 4
a <- array(round(runif(70000,1,4)),dim=c(100,100,7))
# add no data/desert/permafrost/water
smpl0 <- sample.int(100,100, replace=TRUE)
a[smpl0[1:50],smpl0[51:100],] <- sample(c(0,5:7), 100, replace=TRUE)
# make brick
b <- brick(a)
# or stack
s <-
stack(raster(a[,,1]),raster(a[,,2]),raster(a[,,3]),raster(a[,,4]),raster(a[,,5]),raster(a[,,6]),raster(a[,,7]))

f <-function(sq1,sq2,sq3,sq4,sq5,sq6,sq7){
   indna <- ! sq1 %in% 1:4 | is.na(sq1)
   sr <- rep(NA, length(sq1))
   sr[indna] <- sq1[indna]
   srlow <- function(sq1,sq3,sq4,sq5,sq6,sq7){
     cb <- cbind(sq4,sq5,sq6,sq7)
     s <- apply(cb, FUN=sort, MARGIN=1)
     means <- rowMeans(t(s)[,-1]) # mean of other 3
     return(sq1*sq3*s[1,]*means)}
   tr <- function(sq){
     sqt <- rep(NA,length(sq))
     sqt[sq==1] <- 0.9
     sqt[sq==2] <- 0.7
     sqt[sq==3] <- 0.5
     sqt[sq==4] <- 0.3
     return(sqt)
   }
   sr[!indna] <- srlow(tr(sq1[!indna]), tr(sq3[!indna]), tr(sq4[!indna]),
tr(sq5[!indna]), tr(sq6[!indna]), tr(sq7[!indna]))

   return(sr)}

# on test data
# works on brick
tmp <- overlay(b, fun=f, filename="tmp.tif",format="GTiff")
# and on stack
tmp <- overlay(s,fun=f)
# until here everything works fine

# but when I want to apply to my data:
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq1.asc",
destfile="sq1.asc", method = "internal", mode="w")
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq2.asc",
destfile="sq2.asc", method = "internal", mode="w")
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq3.asc",
destfile="sq3.asc", method = "internal", mode="w")
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq4.asc",
destfile="sq4.asc", method = "internal", mode="w")
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq5.asc",
destfile="sq5.asc", method = "internal", mode="w")
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq6.asc",
destfile="sq6.asc", method = "internal", mode="w")
download.file("
http://webarchive.iiasa.ac.at/Research/LUC/External-World-soil-database/Soil_Quality/sq7.asc",
destfile="sq7.asc", method = "internal", mode="w")

SQ <-
stack("sq1.asc","sq2.asc","sq3.asc","sq4.asc","sq5.asc","sq6.asc","sq7.asc")
projection(SQ) <- "+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
+towgs84=0,0,0"

#class       : RasterStack
#dimensions  : 2160, 4320, 9331200, 7  (nrow, ncol, ncell, nlayers)
#resolution  : 0.08333333, 0.08333333  (x, y)
#extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
#coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
+towgs84=0,0,0
#names       :         sq1,         sq2,         sq3,         sq4,
sq5,         sq6,         sq7
#min values  :           0, -2147483648, -2147483648, -2147483648,
  0, -2147483648, -2147483648
#max values  :           7,  2147483647,  2147483647,  2147483647,
  7,  2147483647,  2147483647

# it crashes...
SRlow <- overlay(SQ, fun=f, filename = "SRlow.tif")
# Error in .overlayList(x, fun = fun, filename = filename, ...) :
  cannot use this formula, probably because it is not vectorized
# But the function is vectorized and works well with a smaller rasterLayers
object.

# when debugging, it shows that overlay is not running function f on chunks
in all layers but rather it takes one single cell values of each layer and
feeds them as argument sq1 to f, without assigning any values to the other
arguments.

# The following other overlay does not produce any error:
majorSoilConstraint <- function(sq1,sq2,sq3,sq4,sq5,sq6,sq7){
  indna <- ! sq1 %in% 1:4 | is.na(sq1)
  sr <- rep(NA, length(sq1))
  sr[indna] <- sq1[indna]
  constr <- cbind(sq1,sq2,sq3,sq4,sq5,sq6,sq7)
  indnc <- apply(constr[!indna,], FUN=function(x){max(x) == 1}, MARGIN=1) #
no constraints
  sc <- rep(NA, length(sq1))
  sc[indna] <- -sq1[indna]
  sc[!indna][indnc] <- 8
  sc[!indna][!indnc] <- apply(constr[!indna,][!indnc,],
FUN=function(x){which(x==max(x))[1]}, MARGIN=1)
  return(sc)
}

msc <- overlay(SQ, fun=majorSoilConstraint, filename = "msc.tif",
projection="+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
+towgs84=0,0,0", overwrite=TRUE)

# R version 3.2.1 (2015-06-18)
# packageVersion("raster")
#[1] ?2.4.20?

	[[alternative HTML version deleted]]


