From jean-paul.kibambe at uclouvain.be  Mon Sep  1 18:59:56 2008
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Mon, 1 Sep 2008 18:59:56 +0200 (CEST)
Subject: [R-sig-Geo] Export Matrix to ESRI Grid or tif file
Message-ID: <f1c09e968a5f2b90bf6fed37a508da1e.squirrel@mmp.sipr-dc.ucl.ac.be>

Hi,

I am a new R User and I am trying to write an Ascii grid file or tiff file
from a matrix created in R.

This is what I am doing :

1. write a matrix of x-coordinates (in degrees):
x<-matrix(rep(seq(11,13,0.5), by row=T, nrow=5)

2. write a matrix of y-coordinates (in degrees):
y<-matrix(rep(seq(3,5,0.5), by row=T, nrow=5)

3. I have a function which combine my coordinates (x and y) in the
following way:
z = 0.0052 + 0.001x - 0.00023y + 0.0011xy

z is my variable of interest and I want to put it in a GIS software,
ArcGIS for example, for an analysis with other geographical dataset.

So, I want to have my matrix z as a esri grid file (or tif file or any
kind of image format file), with a cell size equal to the interval (0.5) I
gave in the 'seq' function I have previously used for x and y coordinates.
How can I proceed ?

Thanks a lot for your help.


Jean-Paul Kibambe



From Roger.Bivand at nhh.no  Mon Sep  1 19:50:41 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 1 Sep 2008 19:50:41 +0200 (CEST)
Subject: [R-sig-Geo] Export Matrix to ESRI Grid or tif file
In-Reply-To: <f1c09e968a5f2b90bf6fed37a508da1e.squirrel@mmp.sipr-dc.ucl.ac.be>
References: <f1c09e968a5f2b90bf6fed37a508da1e.squirrel@mmp.sipr-dc.ucl.ac.be>
Message-ID: <Pine.LNX.4.64.0809011937001.22679@reclus.nhh.no>

On Mon, 1 Sep 2008, Jean-Paul Kibambe Lubamba wrote:

> Hi,
>
> I am a new R User and I am trying to write an Ascii grid file or tiff file
> from a matrix created in R.
>
> This is what I am doing :
>
> 1. write a matrix of x-coordinates (in degrees):
> x<-matrix(rep(seq(11,13,0.5), by row=T, nrow=5)
>
> 2. write a matrix of y-coordinates (in degrees):
> y<-matrix(rep(seq(3,5,0.5), by row=T, nrow=5)
>
> 3. I have a function which combine my coordinates (x and y) in the
> following way:
> z = 0.0052 + 0.001x - 0.00023y + 0.0011xy
>
> z is my variable of interest and I want to put it in a GIS software,
> ArcGIS for example, for an analysis with other geographical dataset.

library(sp)
grd <- GridTopology(cellcentre.offset=c(11,3), cellsize=c(0.5, 0.5),
  cells.dim=c(5, 5))
crds <- coordinates(grd)
z <- 0.0052 + 0.001*crds[,1] - 0.0023*crds[,2] + 0.0011*crds[,1]*crds[,2]
SGDF <- SpatialGridDataFrame(grd, data=data.frame(z=z))
spplot(SGDF)
library(rgdal)
writeGDAL(SGDF, "SGDF.tif")

or other drivers for writeGDAL() if you prefer.

Hope this helps,

Roger

>
> So, I want to have my matrix z as a esri grid file (or tif file or any
> kind of image format file), with a cell size equal to the interval (0.5) I
> gave in the 'seq' function I have previously used for x and y coordinates.
> How can I proceed ?
>
> Thanks a lot for your help.
>
>
> Jean-Paul Kibambe
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From lyndon_ang04 at yahoo.com.au  Tue Sep  2 02:45:44 2008
From: lyndon_ang04 at yahoo.com.au (Lyndon Ang)
Date: Mon, 1 Sep 2008 17:45:44 -0700 (PDT)
Subject: [R-sig-Geo] Using R spatial tools to merge polygons
Message-ID: <246640.20940.qm@web52408.mail.re2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080901/7f4c2e09/attachment.pl>

From Roger.Bivand at nhh.no  Tue Sep  2 08:27:39 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 Sep 2008 08:27:39 +0200 (CEST)
Subject: [R-sig-Geo] Using R spatial tools to merge polygons
In-Reply-To: <246640.20940.qm@web52408.mail.re2.yahoo.com>
References: <246640.20940.qm@web52408.mail.re2.yahoo.com>
Message-ID: <Pine.LNX.4.64.0809020818470.24937@reclus.nhh.no>

On Mon, 1 Sep 2008, Lyndon Ang wrote:

> Good day all,
>
> I've only recently been introduced to the useful spatial tools available in R (and indeed to GIS in general!).?? I have found reading some of the posts on this mailing list quite useful, so am hoping that someone can help, or else let me know it can't be done!
>
> I have a map in Shapefile format, which I can read into R.??The 
> shapefile is divided into regions.??What I want to do is merge the 
> regions on the shapefile into larger areas.??The link between each of 
> the individual shapefile regions and the larger regions is on a text 
> file of the following format:
>
> Area_ID?????? Larger_ID
> 1?????? ?????? ?????? ?????? ?????? 1
> 2?????? ?????? ?????? ?????? ?????? 1
> 3?????? ?????? ?????? ?????? ?????? 1
> 4?????? ?????? ?????? ?????? ?????? 2
> 5?????? ?????? ?????? ?????? ?????? 2
>
> Is it possible for me to do this in R, without the use of other GIS software?

Yes, you can use unionSpatialPolygons() in maptools. The specific problem 
is to add Area_ID and Larger_ID to the SpatialPolygonsDataFrame that you 
read in. If Area_ID exists in shapefile, then something like:

library(maptools)
SPDF0 <- readShapeSpatial("my_shapefile.shp", IDvar="Area_ID")
my_ids <- read.table("my_textfile")
row.names(my_ids) <- as.character(my_ids$Area_ID)
SPDF1 <- spCbind(SPDF0, my_ids)
# if there is trouble here, it is because the IDs don't match
IDs <- as.character(SPDF1$Larger_ID)
SP_out <- unionSpatialPolygons(SPDF1, IDs)

giving you a SpatialPolygons object with no attribute data (look at 
aggregate() for ways of merging rows in data.frame objects.

Roger

>
> Thanks in advance for any help that may be provided.
>
> Kind regards
> Lyndon
>
>
>      Win a MacBook Air or iPod touch with Yahoo!7. http://au.docs.yahoo.com/homepageset
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Tue Sep  2 10:56:22 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 Sep 2008 10:56:22 +0200 (CEST)
Subject: [R-sig-Geo] spplot: labels on maps / variables on different
 scales
In-Reply-To: <48B41824.7090307@yorku.ca>
References: <48B3F572.40903@yorku.ca> <48B3FAE1.1070506@uni-muenster.de>
	<48B41824.7090307@yorku.ca>
Message-ID: <Pine.LNX.4.64.0809021042570.24937@reclus.nhh.no>

On Tue, 26 Aug 2008, Michael Friendly wrote:

> Edzer Pebesma wrote:
>> 
>>
>>  Michael Friendly wrote:
>> >  Two short questions about working with maps:
>> > 
>> >  1.  I'm reading a shapefile with character labels for the regions (FSA). 
>> >  I can add the labels using plot(),
>> >  but when I try the same thing using spplot(), the labels are in the 
>> >  wrong positions -- they all seem to be
>> >  shrunk somewhat in toward the center of the map.  What am I doing wrong?
>> > 
>> >  # this doesn't work-- labels in wrong position
>> >  spplot(toronto,"FSA_NAME", colorkey=FALSE)
>> >  text(coordinates(toronto), labels=as.character(toronto$FSA), cex=0.4)
>>  Right: text() works with base graphics, not with lattice on which spplot
>>  is built.
>>
>>  Something like this should work:
>>  spplot(toronto,"FSA_NAME", colorkey=FALSE,
>>     sp.layout = list("sp.text", coordinates(toronto),
>>  as.character(toronto$FSA), cex=0.4))
>> 
> Great!  Now I also know where to look to generalize this.
>> > 
>> >  2. I have a bunch of attribute variables for the geographic regions, all 
>> >  on different scales.  Id like to
>> >  produce a set of comparative maps in the same figure (say with spplot()) 
>> >  with each attribute shaded
>> >  by its quantiles, e.g., 5 classes each.  Do I have to precompute these 
>> >  first, or is there something I can do in the call
>> >  to spplot() to have this done, using the variables in the 
>> >  SpatialPolygonsDataFrame?
>>  What exactly did you mean by "all on different scales"? They have
>>  different polygon structures?
> No - some of the attribute values are percents, some are quantitative & 
> positively skewed, like Income. If I do
>
> spplot(toronto, c("Household.Income","Unemployed","University"))
> a single scale is applied to all three, so the two % variables are shaded 
> uniformly in the lowest range.
> What I'd like is to apply a function to take each of these and recode into 
> quantiles for that variable.

After a little digging around, it looks as though the plot() method for 
trellis objects (pp. 202-206 in the Lattice book) provides a way to 
generate a single graphic from multiple calls to spplot, something like:

p1 <- spplot(toronto, c("Household.Income"))
p2 <- spplot(toronto, c("Unemployed"))
p3 <- spplot(toronto, c("University"))
plot(p1, split=c(1,1,2,2), more=TRUE)
plot(p2, split=c(1,2,2,2), more=TRUE)
plot(p3, split=c(2,1,2,2), more=FALSE)

using at=, col.regions=, main=, etc. in each of the spplot calls as 
appropriate for the selected variables. With the same col.regions= and at= 
based on quantiles (perhaps floor() for the first and ceiling() for the 
last), this should be pretty close visually, but with a key for each 
variable.

>
> It's partly that my data variables are now in the map object and, from the 
> help, I only know how to refer to
> zcol= names of these, rather than some transformations on the underlying 
> data.

The alternative might be to assign new derived variables to the 
Spatial*DatatFrame object, which for all intents and purposes "is" a data 
frame, and spplot() them.

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ajblist-geo at yahoo.de  Tue Sep  2 14:47:14 2008
From: ajblist-geo at yahoo.de (ajblist-geo at yahoo.de)
Date: Tue, 2 Sep 2008 12:47:14 +0000 (GMT)
Subject: [R-sig-Geo] Export Matrix to ESRI Grid or tif file
Message-ID: <809129.28837.qm@web24001.mail.ird.yahoo.com>

Hi,

here an alternative approach using RSAGA to write ASCII grids:

library(RSAGA)
x <- matrix(rep(seq(11,13,0.5), 5), byrow=T, nrow=5)
y <- matrix(rep(seq(3,5,0.5), 5), byrow=F, nrow=5)
z = 0.0052 + 0.001*x - 0.00023*y + 0.0011*x*y
hdr = list(
    ncols = ncol(z), nrows = nrow(z),
    xllcenter = min(x), yllcenter = min(y),
    cellsize = 0.5, nodata_value = -9999)
write.ascii.grid(x, "x.asc", header = hdr, digits = 1, georef = "center")
write.ascii.grid(y, "y.asc", header = hdr, digits = 1, georef = "center")
write.ascii.grid(z, "z.asc", header = hdr, digits = 6, georef = "center")


-- 
Alexander Brenning
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.environment.uwaterloo.ca/geography/faculty/brenning/





----- Urspr?ngliche Mail ----
Von: Roger Bivand <Roger.Bivand at nhh.no>
An: Jean-Paul Kibambe Lubamba <jean-paul.kibambe at uclouvain.be>
CC: r-sig-geo at stat.math.ethz.ch
Gesendet: Montag, den 1. September 2008, 13:50:41 Uhr
Betreff: Re: [R-sig-Geo] Export Matrix to ESRI Grid or tif file

On Mon, 1 Sep 2008, Jean-Paul Kibambe Lubamba wrote:

> Hi,
>
> I am a new R User and I am trying to write an Ascii grid file or tiff file
> from a matrix created in R.
>
> This is what I am doing :
>
> 1. write a matrix of x-coordinates (in degrees):
> x<-matrix(rep(seq(11,13,0.5), by row=T, nrow=5)
>
> 2. write a matrix of y-coordinates (in degrees):
> y<-matrix(rep(seq(3,5,0.5), by row=T, nrow=5)
>
> 3. I have a function which combine my coordinates (x and y) in the
> following way:
> z = 0.0052 + 0.001x - 0.00023y + 0.0011xy
>
> z is my variable of interest and I want to put it in a GIS software,
> ArcGIS for example, for an analysis with other geographical dataset.

library(sp)
grd <- GridTopology(cellcentre.offset=c(11,3), cellsize=c(0.5, 0.5),
  cells.dim=c(5, 5))
crds <- coordinates(grd)
z <- 0.0052 + 0.001*crds[,1] - 0.0023*crds[,2] + 0.0011*crds[,1]*crds[,2]
SGDF <- SpatialGridDataFrame(grd, data=data.frame(z=z))
spplot(SGDF)
library(rgdal)
writeGDAL(SGDF, "SGDF.tif")

or other drivers for writeGDAL() if you prefer.

Hope this helps,

Roger

>
> So, I want to have my matrix z as a esri grid file (or tif file or any
> kind of image format file), with a cell size equal to the interval (0.5) I
> gave in the 'seq' function I have previously used for x and y coordinates.
> How can I proceed ?
>
> Thanks a lot for your help.
>
>
> Jean-Paul Kibambe
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


__________________________________________________
Do You Yahoo!?
Sie sind Spam leid? 
 
http://mail.yahoo.com



From jean-paul.kibambe at uclouvain.be  Tue Sep  2 15:20:39 2008
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Tue, 2 Sep 2008 15:20:39 +0200 (CEST)
Subject: [R-sig-Geo] Weighted linear regression
Message-ID: <2e28fb94b47cd4fb781654c61b8e75ee.squirrel@mmp.sipr-dc.ucl.ac.be>

Hi,

I am trying to explain some of my variables using a weighted linear
regression, with x and y-coordinates as my explanatory variables.

For example, I want to explain my variable 'agri' in the following way :
agri = x + y + x*y+ x^2 + y^2 where x and y are my coordinates and the
regression must be weighted by the variance.

How can I do it ? Thanks in advance !

JP

For illustration, here is a part of my database (var_agri = variance)

    agri	     se_agri	var_agri	   x	         y
1  -1.04E-05  4.47E-06	2.00E-11	  23.78230555	2.968836238
2  -1.01E-05  4.36E-06	1.90E-11	  26.05798185	4.476217345
3  -9.47E-06  4.55E-06	2.07E-11	  30.5248107	3.058706843
4  -1.00E-05  4.22E-06	1.78E-11	  26.97325452	0.737615804
5  -9.96E-06  3.74E-06	1.40E-11	  17.67392327	-3.908029603
6  -1.05E-05  4.44E-06	1.97E-11	  25.92926863	3.114662312
7  -1.01E-05  4.35E-06	1.89E-11	  25.4312434	1.572565497
8  -6.54E-06  4.38E-06	1.92E-11	  20.07104333	1.048456276
9  -9.65E-06  4.38E-06	1.91E-11	  23.92598192	1.728975609
10 -7.39E-06  4.20E-06	1.76E-11	  21.2291592	0.489260168



From Thierry.ONKELINX at inbo.be  Tue Sep  2 15:37:29 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 2 Sep 2008 15:37:29 +0200
Subject: [R-sig-Geo] Weighted linear regression
In-Reply-To: <2e28fb94b47cd4fb781654c61b8e75ee.squirrel@mmp.sipr-dc.ucl.ac.be>
References: <2e28fb94b47cd4fb781654c61b8e75ee.squirrel@mmp.sipr-dc.ucl.ac.be>
Message-ID: <2E9C414912813E4EB981326983E0A104055414D3@inboexch.inbo.be>


Dear Jean-Paul,

Have a look at the weights argument in ?lm. This should do the trick:

lm(agri ~poly(x, y, degree = 2), data = yourDataFrameName, weights =
var_agri)

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Jean-Paul Kibambe
Lubamba
Verzonden: dinsdag 2 september 2008 15:21
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] Weighted linear regression

Hi,

I am trying to explain some of my variables using a weighted linear
regression, with x and y-coordinates as my explanatory variables.

For example, I want to explain my variable 'agri' in the following way :
agri = x + y + x*y+ x^2 + y^2 where x and y are my coordinates and the
regression must be weighted by the variance.

How can I do it ? Thanks in advance !

JP

For illustration, here is a part of my database (var_agri = variance)

    agri	     se_agri	var_agri	   x	         y
1  -1.04E-05  4.47E-06	2.00E-11	  23.78230555	2.968836238
2  -1.01E-05  4.36E-06	1.90E-11	  26.05798185	4.476217345
3  -9.47E-06  4.55E-06	2.07E-11	  30.5248107	3.058706843
4  -1.00E-05  4.22E-06	1.78E-11	  26.97325452	0.737615804
5  -9.96E-06  3.74E-06	1.40E-11	  17.67392327	-3.908029603
6  -1.05E-05  4.44E-06	1.97E-11	  25.92926863	3.114662312
7  -1.01E-05  4.35E-06	1.89E-11	  25.4312434	1.572565497
8  -6.54E-06  4.38E-06	1.92E-11	  20.07104333	1.048456276
9  -9.65E-06  4.38E-06	1.91E-11	  23.92598192	1.728975609
10 -7.39E-06  4.20E-06	1.76E-11	  21.2291592	0.489260168

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in  this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document



From milton.ruser at gmail.com  Tue Sep  2 20:04:07 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Tue, 2 Sep 2008 15:04:07 -0300
Subject: [R-sig-Geo] Utm to latlong conversion (Datum problem)
Message-ID: <3aaf1a030809021104j438c105aibc362f0d2c769f2b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080902/c353e090/attachment.pl>

From Roger.Bivand at nhh.no  Tue Sep  2 21:05:13 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 2 Sep 2008 21:05:13 +0200 (CEST)
Subject: [R-sig-Geo] Utm to latlong conversion (Datum problem)
In-Reply-To: <3aaf1a030809021104j438c105aibc362f0d2c769f2b@mail.gmail.com>
References: <3aaf1a030809021104j438c105aibc362f0d2c769f2b@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809022057420.26132@reclus.nhh.no>

On Tue, 2 Sep 2008, milton ruser wrote:

> Dear all,
>
> I know that it is a knew issue, but I have some troubles
> on the conversion of UTM to Latlong of my shape file.
> In fact, it apears to work but my input file is on South America Datum
> (SAD69),
> but I can?t find the how to indicate the datum. I tryed to include
> "+datum=SAD69"
> on the proj4string, but I received the following error: "unknown elliptical
> parameter name"

It seems that SAD69 is s general description, and you will probably need 
to dig deeper to find the correct +towgs84= values for your data. Add your 
chosen +towgs84= to the CRS for your input data. There are possibly useful 
links in this thread:

http://postgis.refractions.net/pipermail/postgis-users/2006-December/014064.html

or here:

http://osdir.com/ml/gis.proj-4.devel/2006-07/msg00012.html

Try googling SAD69 and towgs84 for lots of different values!

Good luck, don't use the results for navigation without checking, please!

Roger


> Any help are welcome.
>
> Best wishes,
>
> miltinho astronaura
> brazil
> -------------
>
> require(sp)
> require(maptools)
> require(rgdal)
>
> setwd("G:\\HDExt\\R_scripts_genericos\\converte_utm_latlong")
>
> SP<-readShapePoly("area_infl_ind.shp", IDvar=NULL,
> proj4string=CRS("+proj=utm +zone=22 +units=m +south"))
>
> SPll<-spTransform(SP, CRS("+proj=longlat +datum=WGS84"))
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From infohunter at gmail.com  Tue Sep  2 21:35:18 2008
From: infohunter at gmail.com (Harry Kim)
Date: Tue, 2 Sep 2008 12:35:18 -0700
Subject: [R-sig-Geo] importing adf file to R using RArcInfo / converting adf
	file to R friendly format
Message-ID: <91b8161f0809021235n55b3f514y57cb377d98f1daf5@mail.gmail.com>

Dear R-sig-geoers

     I need some help on importing adf file--ArcGIS coverage file
which is no longer supported--into R and was hoping if I could get any
input from you. I've searched the forum and came across a package
named "RArcInfo".
It has functions to read and plot the ArcGIS coverage files in R.
     I obtained the data from
http://www.fao.org/geonetwork/srv/en/metadata.show?id=12720

    The direct link to the data set is
http://www.fao.org/geonetwork/srv/en/resources.get?id=12720&fname=glbpototcor.zip&access=private

     and this is what it is supposed to look like
http://www.fao.org/geonetwork/srv/en/resources.get?access=public&id=12720&fname=glbpod1t0503m.gif

Here is what I did so far:

#set the path
datadir=getwd()
coveragedir= "C:/Users/Harry/Desktop/poultry/glbpod1t0503m/"
infodir= "C:/Users/Harry/Desktop/poultry/info/"

#obtain table and coverage names
tablenames<-get.tablenames(infodir)
covnames<-get.namesofcoverages(datadir)

arc=get.arcdata(datadir, covnames, filename="w001001x.adf")

   The arc file is read into R and I can even plot it but when I try
the file that I am actually interested in analyzing (w001001.adf), R
crashes. I am assuming that the size of the file (100 mb) is too much
to handle and it breaks.

So I would like to see if it is possible to convert this ArcGIS
coverage file into more managable format in R. Are there any suitable
options? My final aim is to get the density values associated with the
coordinates in the world.  I am aware that I can convert the coverage
file to E00 format but I've searched on the internet how I can use
this in R, and so far had no luck finding much of valuable
information.

Thank you so much
Harry



From T.Hengl at uva.nl  Wed Sep  3 00:06:42 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Wed, 3 Sep 2008 00:06:42 +0200
Subject: [R-sig-Geo] Utm to latlong conversion (Datum problem)
References: <3aaf1a030809021104j438c105aibc362f0d2c769f2b@mail.gmail.com>
Message-ID: <37382E8DCB905042969BA78541F6570624D5AB@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080903/a68bb5d8/attachment.pl>

From v.gomezrubio at imperial.ac.uk  Wed Sep  3 00:19:00 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Tue, 02 Sep 2008 23:19:00 +0100
Subject: [R-sig-Geo] importing adf file to R using RArcInfo /	converting
	adf file to R friendly format
In-Reply-To: <91b8161f0809021235n55b3f514y57cb377d98f1daf5@mail.gmail.com>
References: <91b8161f0809021235n55b3f514y57cb377d98f1daf5@mail.gmail.com>
Message-ID: <1220393940.6012.54.camel@fh-vrubio>

Harry,

I have been able to reproduce your error and it seems that the problem
is that there is not enough memory to load your data. Furthermore, I am
not sure whether RArcInfo can handle this sort of gridded data. I
believe that your data is an Arc/Info Binary Grid, which can be read
with package rgdal:

library(rgdal)
dpath<-"/home/vrubio/tmp/GLiPHAmaps/global/poultry/totcor/glbpod1t0503m/hdr.adf"
x <- new("GDALReadOnlyDataset", dpath)
getDriver(x)
getDriverLongName(getDriver(x))

library(RColorBrewer)
xx<-asSGDF_GROD(x, output.dim=c(200, 200))
spplot(xx, "band1", 
   at=c(0, 10, 50, 100, 200, 500, 1000, 2500, max(xx$band1,
na.rm=TRUE)),
   col.regions=brewer.pal(8,"Oranges") )

If you require a higher resolution try to increase the values of
output.dim=c(200, 200) but be careful because it can take a lot of
memory.

Hope this helps,

Virgilio

On Tue, 2008-09-02 at 12:35 -0700, Harry Kim wrote:
> Dear R-sig-geoers
> 
>      I need some help on importing adf file--ArcGIS coverage file
> which is no longer supported--into R and was hoping if I could get any
> input from you. I've searched the forum and came across a package
> named "RArcInfo".
> It has functions to read and plot the ArcGIS coverage files in R.
>      I obtained the data from
> http://www.fao.org/geonetwork/srv/en/metadata.show?id=12720
> 
>     The direct link to the data set is
> http://www.fao.org/geonetwork/srv/en/resources.get?id=12720&fname=glbpototcor.zip&access=private
> 
>      and this is what it is supposed to look like
> http://www.fao.org/geonetwork/srv/en/resources.get?access=public&id=12720&fname=glbpod1t0503m.gif
> 
> Here is what I did so far:
> 
> #set the path
> datadir=getwd()
> coveragedir= "C:/Users/Harry/Desktop/poultry/glbpod1t0503m/"
> infodir= "C:/Users/Harry/Desktop/poultry/info/"
> 
> #obtain table and coverage names
> tablenames<-get.tablenames(infodir)
> covnames<-get.namesofcoverages(datadir)
> 
> arc=get.arcdata(datadir, covnames, filename="w001001x.adf")
> 
>    The arc file is read into R and I can even plot it but when I try
> the file that I am actually interested in analyzing (w001001.adf), R
> crashes. I am assuming that the size of the file (100 mb) is too much
> to handle and it breaks.
> 
> So I would like to see if it is possible to convert this ArcGIS
> coverage file into more managable format in R. Are there any suitable
> options? My final aim is to get the density values associated with the
> coordinates in the world.  I am aware that I can convert the coverage
> file to E00 format but I've searched on the internet how I can use
> this in R, and so far had no luck finding much of valuable
> information.
> 
> Thank you so much
> Harry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From wouter at paramo.be  Wed Sep  3 23:41:52 2008
From: wouter at paramo.be (Wouter Buytaert)
Date: Wed, 3 Sep 2008 17:41:52 -0400 (CLT)
Subject: [R-sig-Geo] superimpose polygons on a grid
Message-ID: <alpine.OSX.1.10.0809031717370.345@carihuayrazo.local>


Hi all,

is there a way to plot polygons over a grid? It seems that:

> spplot(myspgrid, sp.layout(list("sp.polygon",mysppolygon)))

always plots the grid on top of the polygon (as in 
<http://r-spatial.sourceforge.net/gallery/#fig07.R> and contrary to 
lines and points).

Is there any way to change this (for instance to plot a lake area on top 
of a raster DEM)?

cheers
Wouter



From p.hiemstra at geo.uu.nl  Thu Sep  4 13:01:44 2008
From: p.hiemstra at geo.uu.nl (Paul Hiemstra)
Date: Thu, 4 Sep 2008 13:01:44 +0200 (CEST)
Subject: [R-sig-Geo] superimpose polygons on a grid
In-Reply-To: <alpine.OSX.1.10.0809031717370.345@carihuayrazo.local>
References: <alpine.OSX.1.10.0809031717370.345@carihuayrazo.local>
Message-ID: <19998.134.151.34.244.1220526104.squirrel@webmail.geo.uu.nl>

Hi,

There are two ways to do this, one is to use the "first = FALSE" argument
in the call to sp.layout. Like:

spplot(myspgrid, sp.layout(list("sp.polygon",mysppolygon, first = FALSE)))

A more complex way, but more flexible, is to use a custom panel function
like on the R wiki tips:

http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:spatial_data_visualization

Read the paragraph on "Adding GIS data as layout".

cheers,
Paul

ps The first e-mail with the error was caused by me

>
> Hi all,
>
> is there a way to plot polygons over a grid? It seems that:
>
>> spplot(myspgrid, sp.layout(list("sp.polygon",mysppolygon)))
>
> always plots the grid on top of the polygon (as in
> <http://r-spatial.sourceforge.net/gallery/#fig07.R> and contrary to
> lines and points).
>
> Is there any way to change this (for instance to plot a lake area on top
> of a raster DEM)?
>
> cheers
> Wouter
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From francois.jouvie at supelec.fr  Thu Sep  4 16:18:18 2008
From: francois.jouvie at supelec.fr (Francois JOUVIE)
Date: Thu, 4 Sep 2008 16:18:18 +0200
Subject: [R-sig-Geo] vgm with a Cauchy function
Message-ID: <E2303695-1B0A-4A82-8647-EBF3C3D4A0CA@supelec.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080904/de85c0f1/attachment.pl>

From v.gomezrubio at imperial.ac.uk  Thu Sep  4 16:47:14 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Thu, 04 Sep 2008 15:47:14 +0100
Subject: [R-sig-Geo] vgm with a Cauchy function
In-Reply-To: <E2303695-1B0A-4A82-8647-EBF3C3D4A0CA@supelec.fr>
References: <E2303695-1B0A-4A82-8647-EBF3C3D4A0CA@supelec.fr>
Message-ID: <1220539634.28408.25.camel@fh-vrubio>

Hi,

> I again send this below request to the List, because I do not receive  
> an answer to it, since July 8th.

A search in Goggle on "variogram cauchy" returns, as a first hit, the
following R manual page:

http://rss.acs.unt.edu/Rdoc/library/ProbForecastGOP/html/Variog.fit.html

This is not for gstat though. Package Random Fields seems to have a
variogram that can do what you want:

http://www.stat.ucl.ac.be/ISdidactique/Rhelp/library/RandomFields/html/CovarianceFct.html

Hope this helps.

Virgilio

P.S:

> (I'm new on this list and I don't know how to get the archived past  
> questions and answers)

You can add the word 'R-sig-geo' to your queries in Google and you will 
be searching the list as well.



From edzer.pebesma at uni-muenster.de  Thu Sep  4 17:23:35 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 04 Sep 2008 17:23:35 +0200
Subject: [R-sig-Geo] vgm with a Cauchy function
In-Reply-To: <E2303695-1B0A-4A82-8647-EBF3C3D4A0CA@supelec.fr>
References: <E2303695-1B0A-4A82-8647-EBF3C3D4A0CA@supelec.fr>
Message-ID: <48BFFD77.7000802@uni-muenster.de>

Francois JOUVIE wrote:
> Hello,
>
> I again send this below request to the List, because I do not receive  
> an answer to it, since July 8th.
> Perhaps anyone can help me ?
> Thanks you.
>
>
> My question:
>
>   I'm exploring the possibilities of the gstat package in the  
> R_Library context, to make variograms and kriging in a problem of  
> electromagnetic field.
>
>   This is my question:
>
>   To fit my points_variograms, the  vgm routine displays a closed set  
> of default functions ("Sph", "Gau", "Bes", etc.).
>
>   I'd like try a different fitting model (a Cauchy function  
> precisely). Do anyone knows if it is possible (and how to do it) to  
> use an owner_defined function to fit a
>   particular variogram ?
>   
There's two ways to do that.
1. you can pass an arbitrary function by computing its values and 
passing it as a table, an example is found in ?vgm:
     vv=vgm(model = "Tab",  covtable =
             variogramLine(vgm(1, "Sph", 1), 1, n=1e4, min = 0, 
covariance = TRUE))
2. you can edit the underlying C source code; if you can express the 
variogram function in terms of a C (or R) function, this is not as hard 
as it seems -- the code has been set up for easy addition of models.

You can also start working with packages that already provide this.
> Thanks you very much.
>
> (I'm new on this list and I don't know how to get the archived past  
> questions and answers)
>   
Just click on the link below any list message, and it will bring you 
there. Google searching with r-sig-geo as one of the key words should 
work as well.
--
Edzer
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From epistat at gmail.com  Fri Sep  5 04:53:57 2008
From: epistat at gmail.com (Zhijie Zhang)
Date: Fri, 5 Sep 2008 10:53:57 +0800
Subject: [R-sig-Geo] R-sig-Geo Digest, Vol 61, Issue 3
References: <mailman.9.1220522403.18385.r-sig-geo@stat.math.ethz.ch>
Message-ID: <005201c90f02$a5881540$a36fa8c0@zjzhang>

Wouter,
  Superimposing polygons on a grid could be easily done in ARCGIS. 
----- Original Message ----- 
From: <r-sig-geo-request at stat.math.ethz.ch>
To: <r-sig-geo at stat.math.ethz.ch>
Sent: Thursday, September 04, 2008 6:00 PM
Subject: R-sig-Geo Digest, Vol 61, Issue 3


> Send R-sig-Geo mailing list submissions to
> r-sig-geo at stat.math.ethz.ch
> 
> To subscribe or unsubscribe via the World Wide Web, visit
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> or, via email, send a message with subject or body 'help' to
> r-sig-geo-request at stat.math.ethz.ch
> 
> You can reach the person managing the list at
> r-sig-geo-owner at stat.math.ethz.ch
> 
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of R-sig-Geo digest..."
> 
> 
> Today's Topics:
> 
>   1. superimpose polygons on a grid (Wouter Buytaert)
> 
> 
> ----------------------------------------------------------------------
> 
> Message: 1
> Date: Wed, 3 Sep 2008 17:41:52 -0400 (CLT)
> From: Wouter Buytaert <wouter at paramo.be>
> Subject: [R-sig-Geo] superimpose polygons on a grid
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <alpine.OSX.1.10.0809031717370.345 at carihuayrazo.local>
> Content-Type: TEXT/PLAIN; format=flowed; charset=US-ASCII
> 
> 
> Hi all,
> 
> is there a way to plot polygons over a grid? It seems that:
> 
>> spplot(myspgrid, sp.layout(list("sp.polygon",mysppolygon)))
> 
> always plots the grid on top of the polygon (as in 
> <http://r-spatial.sourceforge.net/gallery/#fig07.R> and contrary to 
> lines and points).
> 
> Is there any way to change this (for instance to plot a lake area on top 
> of a raster DEM)?
> 
> cheers
> Wouter
> 
> 
> 
> ------------------------------
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 
> End of R-sig-Geo Digest, Vol 61, Issue 3
> ****************************************
>

From linxin.pku at gmail.com  Fri Sep  5 10:07:11 2008
From: linxin.pku at gmail.com (Xin LIN)
Date: Fri, 5 Sep 2008 16:07:11 +0800
Subject: [R-sig-Geo] How to remove polygons according to their attributes?
Message-ID: <66bcfc490809050107s4f7cab75l72712bc4dd5dc474@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080905/bcc36405/attachment.pl>

From Friderike.Oehler at fao.org  Fri Sep  5 11:16:21 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Fri, 05 Sep 2008 11:16:21 +0200
Subject: [R-sig-Geo] How to remove polygons according to their
	attributes?
Message-ID: <1A28265B00AA7E4085BB761555D3FCE8016AF91C@hqagex02.fao.org>

Hi Lin,

I think you can simply do your selection as with any dataframe, e.g.

require(rgdal)
Ctries=readOGR(dsn='C:/data/datasets/HornOfAfrica', layer='HornOfAfrica',
p4s=NULL)
str(Ctries at data)
try<-Ctries[Ctries$AREA>100,]
spplot(try, zcol='ADM0_CODE')
# or:
Kenya<-Ctries[Ctries$ADM0_NAME=='Kenya',]
spplot(Ctries, zcol='ADM0_CODE',sp.layout=list(list("sp.polygons",Kenya,
col="red")), scales=list(draw=TRUE), xlim=c(30,52), ylim=c(-10,18),
col.regions='transparent', colorkey=FALSE)

Hope this helps,
Friderike


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Xin LIN
Sent: 05 September 2008 10:07
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] How to remove polygons according to their attributes?


Hi, everyone

I have a shapefile with many adjacent polygons in. Each has a series of
attributes such as ID and area. Now I want to remove some of them based on
attributes, e.g. to remove polygons with areas less than a given value. How
can I proceed?

Thanks a lot.=)

Lin Xin

-- 
Lin Xin
Department of Ecology,
College of Urban and Environmental Sciences
Peking University
Beijing 100871, China
Tel: +8610 62765578
Mobile: +86 15801416516
Email: linxin.pku at gmail.com

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From jnylen+rgeo at gmail.com  Fri Sep  5 17:03:56 2008
From: jnylen+rgeo at gmail.com (James Nylen)
Date: Fri, 5 Sep 2008 10:03:56 -0500
Subject: [R-sig-Geo] How to remove polygons according to their
	attributes?
In-Reply-To: <66bcfc490809050107s4f7cab75l72712bc4dd5dc474@mail.gmail.com>
References: <66bcfc490809050107s4f7cab75l72712bc4dd5dc474@mail.gmail.com>
Message-ID: <205a4c310809050803i7ef5ae89ycff0148aba037b06@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080905/ad98be10/attachment.pl>

From murray.richardson at utoronto.ca  Fri Sep  5 18:40:51 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Fri, 05 Sep 2008 12:40:51 -0400
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
Message-ID: <48C16113.5050204@utoronto.ca>

Hi Roger

I'm just getting around to trying this out. 

I must say, I'm not clear on how to work with the neighbour list object 
to accomplish this.  Specifically, how would I identify the largest 
neighbours of the sliver candidates?

Furthermore, do I first subset the polygons according to the area 
threshold, and then construct the neighbour list for only these 
candidate slivers?  I'm not clear on how to identify neighbours for a 
subset of polygons.

Sorry to bother you with this again.  It will be very useful if it works 
as I would also like to use it for region merging based on other attributes.

Still waiting on that book...!

Murray



Roger Bivand wrote:
> On Wed, 13 Aug 2008, Murray Richardson wrote:
>
>> Hello again r.sig.geo list,
>>
>> Thanks Roger, for help on my previous question regarding iterating 
>> through a shapefile.
>>
>> I'm sure once I receive my copy of  "Applied Spatial Data Analysis 
>> with R" I will find answers to simple questions like this on my own, 
>> but in the meantime....
>>
>> Is it possible to merge sliver polygons that fall below a certain 
>> threshold area with adjacent neighbours (e.g. perhaps using  
>> unionSpatialPolygons but without aggregating any  polygons?).  If a 
>> sliver shares edges with more than one polygon, it doesn't really 
>> matter which one it merges with, but if I had to choose a rule I 
>> would have it merge with the largest one.
>
> Not such a simple question ...
>
> Both the Polygon and Polygons objects in the SpatialPolygons object 
> have "area" slots, with different roles. The Polygon objects have a 
> correct naive area in the geometry of the coordinates taken as planar. 
> The Polygons objects use the "gross" area of Polygon objects belonging 
> to them, but "only" to provide the plot order (plot from largest to 
> smallest to avoid over-painting).
>
> If you "trust" the area slot of the Polygons objects (beware of hole 
> Polygon objects), you can first find your candidate slivers by 
> retrieving the areas by:
>
> Polygons_areas <- sapply(slot(SPobj, "polygons"),
>   function(x) slot(x, "area"))
>
> and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to 
> find the neighbours (rook criterion). Next use the output object to 
> identify the largest neighbours of the sliver candidates, and build a 
> "new Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
> assuming you wouldn't have asked if there was useful data in the slivers!
>
> Hope this helps,
>
> Roger
>
>>
>> Thanks in advance,
>>
>> Murray Richardson
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>



From Roger.Bivand at nhh.no  Fri Sep  5 19:51:52 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 Sep 2008 19:51:52 +0200 (CEST)
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <48C16113.5050204@utoronto.ca>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48C16113.5050204@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0809051932350.7609@reclus.nhh.no>

On Fri, 5 Sep 2008, Murray Richardson wrote:

> Hi Roger
>
> I'm just getting around to trying this out. 
> I must say, I'm not clear on how to work with the neighbour list object to 
> accomplish this.  Specifically, how would I identify the largest neighbours 
> of the sliver candidates?
>
> Furthermore, do I first subset the polygons according to the area threshold, 
> and then construct the neighbour list for only these candidate slivers?  I'm 
> not clear on how to identify neighbours for a subset of polygons.

My idea (IIRC!) was to look at a distribution of the areas of the Polygon 
objects in the dataset. A good deal will depend on whether the slivers are 
represented as separate Polygons objects (note the _s_), or whether they 
are Polygon objects belonging to Polygons objects. So nimbleness will be 
needed!

library(maptools)
xx <- readShapeSpatial(system.file("shapes/sids.shp", package="maptools")[1],
       IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
pls <- slot(xx, "polygons")
AREAS <- sapply(pls, function(x) sapply(slot(x, "Polygons"), function(y)
       slot(y, "area")))
summary(sapply(AREAS, length))
summary(unlist(AREAS))

is not a very good example, because the "areas" are planar in non-planar 
coordinates, but I hope you see the point. If you have a clear break in 
the distribution, you can find out which they are, and where they are. If 
all the Polygons objects (the ones in the "polygons" slot of your 
SpatialPolygons object, pls) are singletons, things get much easier, 
because the merging will be between Polygons objects, provided directly in 
maptools.

This should be a start - once you have singleton Polygons objects with 
areas as attributes, we can continue.

Hope this helps,

Roger

>
> Sorry to bother you with this again.  It will be very useful if it works as I 
> would also like to use it for region merging based on other attributes.
>
> Still waiting on that book...!

PS. Edzer, Virgilio and I did see the only copy in Europe in Dortmund at 
useR! three weeks ago. It turns out that it was printed in the US, and is 
at or awaited at the publisher's warehouse for dispatch. Things seem to 
take time in the "real" world!

>
> Murray
>
>
>
> Roger Bivand wrote:
>>  On Wed, 13 Aug 2008, Murray Richardson wrote:
>> 
>> >  Hello again r.sig.geo list,
>> > 
>> >  Thanks Roger, for help on my previous question regarding iterating 
>> >  through a shapefile.
>> > 
>> >  I'm sure once I receive my copy of  "Applied Spatial Data Analysis with 
>> >  R" I will find answers to simple questions like this on my own, but in 
>> >  the meantime....
>> > 
>> >  Is it possible to merge sliver polygons that fall below a certain 
>> >  threshold area with adjacent neighbours (e.g. perhaps using 
>> >  unionSpatialPolygons but without aggregating any  polygons?).  If a 
>> >  sliver shares edges with more than one polygon, it doesn't really matter 
>> >  which one it merges with, but if I had to choose a rule I would have it 
>> >  merge with the largest one.
>>
>>  Not such a simple question ...
>>
>>  Both the Polygon and Polygons objects in the SpatialPolygons object have
>>  "area" slots, with different roles. The Polygon objects have a correct
>>  naive area in the geometry of the coordinates taken as planar. The
>>  Polygons objects use the "gross" area of Polygon objects belonging to
>>  them, but "only" to provide the plot order (plot from largest to smallest
>>  to avoid over-painting).
>>
>>  If you "trust" the area slot of the Polygons objects (beware of hole
>>  Polygon objects), you can first find your candidate slivers by retrieving
>>  the areas by:
>>
>>  Polygons_areas <- sapply(slot(SPobj, "polygons"),
>>    function(x) slot(x, "area"))
>>
>>  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to find
>>  the neighbours (rook criterion). Next use the output object to identify
>>  the largest neighbours of the sliver candidates, and build a "new
>>  Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm assuming you
>>  wouldn't have asked if there was useful data in the slivers!
>>
>>  Hope this helps,
>>
>>  Roger
>> 
>> > 
>> >  Thanks in advance,
>> > 
>> >  Murray Richardson
>> > 
>>> _______________________________________________
>> >  R-sig-Geo mailing list
>> >  R-sig-Geo at stat.math.ethz.ch
>> >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > 
>> > 
>> 
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From murray.richardson at utoronto.ca  Fri Sep  5 20:49:38 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Fri, 05 Sep 2008 14:49:38 -0400
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <Pine.LNX.4.64.0809051932350.7609@reclus.nhh.no>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48C16113.5050204@utoronto.ca>
	<Pine.LNX.4.64.0809051932350.7609@reclus.nhh.no>
Message-ID: <48C17F42.3060201@utoronto.ca>

Thanks Roger,

I have singletons with areas.  I think the slivers will be quite obvious 
based on their areas relative to the rest of the polygon areas.  I could 
even compute some perimeter to area index I supposed since they tend to 
be long a skinny.

So, my main uncertainty is still just how to work with the neighbour 
list to merge the sliver polygons with the LARGEST non-sliver polygon 
they share an edge with. i.e. to generate the new ids to use in 
unionSpatialPolygons.   I can't seem to find a good example of how to 
use the nb object in such a way.

cheers

Murray


Roger Bivand wrote:
> On Fri, 5 Sep 2008, Murray Richardson wrote:
>
>> Hi Roger
>>
>> I'm just getting around to trying this out. I must say, I'm not clear 
>> on how to work with the neighbour list object to accomplish this.  
>> Specifically, how would I identify the largest neighbours of the 
>> sliver candidates?
>>
>> Furthermore, do I first subset the polygons according to the area 
>> threshold, and then construct the neighbour list for only these 
>> candidate slivers?  I'm not clear on how to identify neighbours for a 
>> subset of polygons.
>
> My idea (IIRC!) was to look at a distribution of the areas of the 
> Polygon objects in the dataset. A good deal will depend on whether the 
> slivers are represented as separate Polygons objects (note the _s_), 
> or whether they are Polygon objects belonging to Polygons objects. So 
> nimbleness will be needed!
>
> library(maptools)
> xx <- readShapeSpatial(system.file("shapes/sids.shp", 
> package="maptools")[1],
>       IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
> pls <- slot(xx, "polygons")
> AREAS <- sapply(pls, function(x) sapply(slot(x, "Polygons"), function(y)
>       slot(y, "area")))
> summary(sapply(AREAS, length))
> summary(unlist(AREAS))
>
> is not a very good example, because the "areas" are planar in 
> non-planar coordinates, but I hope you see the point. If you have a 
> clear break in the distribution, you can find out which they are, and 
> where they are. If all the Polygons objects (the ones in the 
> "polygons" slot of your SpatialPolygons object, pls) are singletons, 
> things get much easier, because the merging will be between Polygons 
> objects, provided directly in maptools.
>
> This should be a start - once you have singleton Polygons objects with 
> areas as attributes, we can continue.
>
> Hope this helps,
>
> Roger
>
>>
>> Sorry to bother you with this again.  It will be very useful if it 
>> works as I would also like to use it for region merging based on 
>> other attributes.
>>
>> Still waiting on that book...!
>
> PS. Edzer, Virgilio and I did see the only copy in Europe in Dortmund 
> at useR! three weeks ago. It turns out that it was printed in the US, 
> and is at or awaited at the publisher's warehouse for dispatch. Things 
> seem to take time in the "real" world!
>
>>
>> Murray
>>
>>
>>
>> Roger Bivand wrote:
>>>  On Wed, 13 Aug 2008, Murray Richardson wrote:
>>>
>>> >  Hello again r.sig.geo list,
>>> > >  Thanks Roger, for help on my previous question regarding 
>>> iterating >  through a shapefile.
>>> > >  I'm sure once I receive my copy of  "Applied Spatial Data 
>>> Analysis with >  R" I will find answers to simple questions like 
>>> this on my own, but in >  the meantime....
>>> > >  Is it possible to merge sliver polygons that fall below a 
>>> certain >  threshold area with adjacent neighbours (e.g. perhaps 
>>> using >  unionSpatialPolygons but without aggregating any  
>>> polygons?).  If a >  sliver shares edges with more than one polygon, 
>>> it doesn't really matter >  which one it merges with, but if I had 
>>> to choose a rule I would have it >  merge with the largest one.
>>>
>>>  Not such a simple question ...
>>>
>>>  Both the Polygon and Polygons objects in the SpatialPolygons object 
>>> have
>>>  "area" slots, with different roles. The Polygon objects have a correct
>>>  naive area in the geometry of the coordinates taken as planar. The
>>>  Polygons objects use the "gross" area of Polygon objects belonging to
>>>  them, but "only" to provide the plot order (plot from largest to 
>>> smallest
>>>  to avoid over-painting).
>>>
>>>  If you "trust" the area slot of the Polygons objects (beware of hole
>>>  Polygon objects), you can first find your candidate slivers by 
>>> retrieving
>>>  the areas by:
>>>
>>>  Polygons_areas <- sapply(slot(SPobj, "polygons"),
>>>    function(x) slot(x, "area"))
>>>
>>>  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to 
>>> find
>>>  the neighbours (rook criterion). Next use the output object to 
>>> identify
>>>  the largest neighbours of the sliver candidates, and build a "new
>>>  Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
>>> assuming you
>>>  wouldn't have asked if there was useful data in the slivers!
>>>
>>>  Hope this helps,
>>>
>>>  Roger
>>>
>>> > >  Thanks in advance,
>>> > >  Murray Richardson
>>> >
>>>> _______________________________________________
>>> >  R-sig-Geo mailing list
>>> >  R-sig-Geo at stat.math.ethz.ch
>>> >  https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> > >
>>
>



From Roger.Bivand at nhh.no  Fri Sep  5 21:25:25 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 5 Sep 2008 21:25:25 +0200 (CEST)
Subject: [R-sig-Geo] merge sliver polygons
In-Reply-To: <48C17F42.3060201@utoronto.ca>
References: <48A2E556.3040305@utoronto.ca>
	<Pine.LNX.4.64.0808131613530.20340@reclus.nhh.no>
	<48C16113.5050204@utoronto.ca>
	<Pine.LNX.4.64.0809051932350.7609@reclus.nhh.no>
	<48C17F42.3060201@utoronto.ca>
Message-ID: <Pine.LNX.4.64.0809052111280.7609@reclus.nhh.no>

On Fri, 5 Sep 2008, Murray Richardson wrote:

> Thanks Roger,
>
> I have singletons with areas.  I think the slivers will be quite obvious 
> based on their areas relative to the rest of the polygon areas.  I could even 
> compute some perimeter to area index I supposed since they tend to be long a 
> skinny.
>
> So, my main uncertainty is still just how to work with the neighbour list to 
> merge the sliver polygons with the LARGEST non-sliver polygon they share an 
> edge with. i.e. to generate the new ids to use in unionSpatialPolygons.   I 
> can't seem to find a good example of how to use the nb object in such a way.

OK, so the Polygons are all singletons. This isn't tried:

is_a_sliver <- AREAS < very_small
library(spdep)
nb <- poly2nb(your_SPDF)
# check length(is_a_sliver) against length(nb)
crd <- card(nb)
IDs <- sapply(slot(your_SPDF, "polygons"), function(x) slot(x, "ID"))
for (i in seq(along=nb)) {
   if (is_a_sliver[i] && crd[i] > 0) {
     nbi <- nb[[i]]
     max_area <- nbi[which.max(AREAS[nbi])]
     IDs[i] <- IDs[max_area]
   }
}

then use IDs in unionSpatialPolygons()

I repeat, untried, but something like this should work.

Roger

PS. If you have the perimeter, you could try it as a sanity check if area 
alone give spurious results.

>
> cheers
>
> Murray
>
>
> Roger Bivand wrote:
>>  On Fri, 5 Sep 2008, Murray Richardson wrote:
>> 
>> >  Hi Roger
>> > 
>> >  I'm just getting around to trying this out. I must say, I'm not clear on 
>> >  how to work with the neighbour list object to accomplish this. 
>> >  Specifically, how would I identify the largest neighbours of the sliver 
>> >  candidates?
>> > 
>> >  Furthermore, do I first subset the polygons according to the area 
>> >  threshold, and then construct the neighbour list for only these 
>> >  candidate slivers?  I'm not clear on how to identify neighbours for a 
>> >  subset of polygons.
>>
>>  My idea (IIRC!) was to look at a distribution of the areas of the Polygon
>>  objects in the dataset. A good deal will depend on whether the slivers are
>>  represented as separate Polygons objects (note the _s_), or whether they
>>  are Polygon objects belonging to Polygons objects. So nimbleness will be
>>  needed!
>>
>>  library(maptools)
>>  xx <- readShapeSpatial(system.file("shapes/sids.shp",
>>  package="maptools")[1],
>>        IDvar="FIPSNO", proj4string=CRS("+proj=longlat +ellps=clrk66"))
>>  pls <- slot(xx, "polygons")
>>  AREAS <- sapply(pls, function(x) sapply(slot(x, "Polygons"), function(y)
>>        slot(y, "area")))
>>  summary(sapply(AREAS, length))
>>  summary(unlist(AREAS))
>>
>>  is not a very good example, because the "areas" are planar in non-planar
>>  coordinates, but I hope you see the point. If you have a clear break in
>>  the distribution, you can find out which they are, and where they are. If
>>  all the Polygons objects (the ones in the "polygons" slot of your
>>  SpatialPolygons object, pls) are singletons, things get much easier,
>>  because the merging will be between Polygons objects, provided directly in
>>  maptools.
>>
>>  This should be a start - once you have singleton Polygons objects with
>>  areas as attributes, we can continue.
>>
>>  Hope this helps,
>>
>>  Roger
>> 
>> > 
>> >  Sorry to bother you with this again.  It will be very useful if it works 
>> >  as I would also like to use it for region merging based on other 
>> >  attributes.
>> > 
>> >  Still waiting on that book...!
>>
>>  PS. Edzer, Virgilio and I did see the only copy in Europe in Dortmund at
>>  useR! three weeks ago. It turns out that it was printed in the US, and is
>>  at or awaited at the publisher's warehouse for dispatch. Things seem to
>>  take time in the "real" world!
>> 
>> > 
>> >  Murray
>> > 
>> > 
>> > 
>> >  Roger Bivand wrote:
>> > >   On Wed, 13 Aug 2008, Murray Richardson wrote:
>> > > 
>> > > >   Hello again r.sig.geo list,
>> > > > >   Thanks Roger, for help on my previous question regarding 
>> > > iterating >   through a shapefile.
>> > > > >   I'm sure once I receive my copy of  "Applied Spatial Data 
>> > >  Analysis with >  R" I will find answers to simple questions like this 
>> > >  on my own, but in >  the meantime....
>> > > > >   Is it possible to merge sliver polygons that fall below a 
>> > >  certain >  threshold area with adjacent neighbours (e.g. perhaps using 
>> > >  >  unionSpatialPolygons but without aggregating any  polygons?).  If a 
>> > >  >  sliver shares edges with more than one polygon, it doesn't really 
>> > >  matter >  which one it merges with, but if I had to choose a rule I 
>> > >  would have it >  merge with the largest one.
>> > > 
>> > >   Not such a simple question ...
>> > > 
>> > >  Both the Polygon and Polygons objects in the SpatialPolygons object 
>> > >  have
>> > >   "area" slots, with different roles. The Polygon objects have a 
>> > >   correct
>> > >   naive area in the geometry of the coordinates taken as planar. The
>> > >   Polygons objects use the "gross" area of Polygon objects belonging to
>> > >   them, but "only" to provide the plot order (plot from largest to 
>> > >  smallest
>> > >   to avoid over-painting).
>> > > 
>> > >   If you "trust" the area slot of the Polygons objects (beware of hole
>> > >   Polygon objects), you can first find your candidate slivers by 
>> > >  retrieving
>> > >   the areas by:
>> > > 
>> > >   Polygons_areas <- sapply(slot(SPobj, "polygons"),
>> > >     function(x) slot(x, "area"))
>> > > 
>> > >  and set a cutoff. Then use poly2nb(SPobj, queen=FALSE) in spdep to 
>> > >  find
>> > >  the neighbours (rook criterion). Next use the output object to 
>> > >  identify
>> > >   the largest neighbours of the sliver candidates, and build a "new
>> > >   Polygons" ID vector. Finally, use unionSpatialPolygons(). I'm 
>> > >  assuming you
>> > >   wouldn't have asked if there was useful data in the slivers!
>> > > 
>> > >   Hope this helps,
>> > > 
>> > >   Roger
>> > > 
>> > > > >   Thanks in advance,
>> > > > >   Murray Richardson
>> > > > 
>>>>> _______________________________________________
>> > > >   R-sig-Geo mailing list
>> > > >   R-sig-Geo at stat.math.ethz.ch
>> > > >   https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> > > > > 
>> > 
>> 
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From acmartensen at gmail.com  Sat Sep  6 01:32:27 2008
From: acmartensen at gmail.com (Alexandre Camargo Martensen)
Date: Fri, 5 Sep 2008 20:32:27 -0300
Subject: [R-sig-Geo] clipping psp & owin
Message-ID: <ea65d44c0809051632j687af1c0wbd42751f8325b69d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080905/74ad6129/attachment.pl>

From rossiter at itc.nl  Sat Sep  6 16:06:47 2008
From: rossiter at itc.nl (D G Rossiter)
Date: Sat, 6 Sep 2008 16:06:47 +0200
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it display /
	fit variograms?
Message-ID: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080906/dfee2b42/attachment.pl>

From Thierry.ONKELINX at inbo.be  Sat Sep  6 17:29:07 2008
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Sat, 6 Sep 2008 17:29:07 +0200
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it
	display /fit variograms?
In-Reply-To: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
Message-ID: <2E9C414912813E4EB981326983E0A10405541DA3@inboexch.inbo.be>

Hi,

A lot of people in our institute use ArcGIS. But I always advise them
not to use ArcGIS for kriging etc. Mainly because kriging in ArcGIS is a
black box tool. You only know the input and the output, but not how
things are calculated. More over people tend to try the different
options without really knowing what (and why) they are doing. The just
stick with the interpolated map that "looks" the best.

For kriging I promote R and gstat.

HTH,

Thierry


------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to
say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of
data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens D G Rossiter
Verzonden: zaterdag 6 september 2008 16:07
Aan: r-sig-geo at stat.math.ethz.ch
Onderwerp: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it
display /fit variograms?

Hi, I know this is mostly an R-spatial list but this is where the most  
computational geostats experts hang out, so please forgive me for  
asking an ArcGIS question.

I use R almost exclusively for my own work, but have been asked to  
supervise the development of an introductory geostats course for our  
partner at the University of Rwanda. They have standardized on ArcGIS  
for all of their GIS work (and SPSS for non-spatial stats), and the  
prospective students (mostly centre workers and collaborating  
researchers) are familiar with it. The decision was taken by their  
administration not to use my R/gstat material from the ITC distance  
education course, rather to develop the course with ArcGIS.

My counterpart is now with me developing the course. The deficiencies  
of ESRI documentation are well-known. I have dug around quite a bit  
both within the ESRI docs (on-line and with the program) and through  
various mailing lists and the web and can not find out some basic  
information. I hope you can shed some light,

1. What exactly is the display of the empirical variogram? The doc.  
implies there is one average semivariance per bin (as is usual) but  
the display often has several at the same bin. The variogram can be  
exported as a table, where it shows multiple (2 - 6 or so)  
semivariances for each bin; the table also shows a "weight" for each  
of these, but they do not add to 1 or 100 or anything I can  
recognize!  The close-range bins usually have one, then the number  
increases. So I guess each dot represents some number of point-pairs.

2. How is the variogram being fit? What weighting, what solver?  If  
the user changes the cutoff/bin width, the solution changes (as it  
should); but I can't see how it's solving, and I can't find any option  
to change the weighting (as in e.g. gstat).

3. When fitting direct and cross-variograms for co-kriging, it seems  
that a linear model of co-regionalization is being enforced (i.e. same  
range). Again, how is the fit being done? Like fit.lmc in gstat?

Naturally we want the students to understand what the program is doing  
for them!  Although ESRI promotes "press the button and look at the  
cross-validation". I do like their disclaimer in the ArcGIS Desktop  
9.3 help: "Kriging is a complex procedure that requires greater  
knowledge about spatial statistics than can be conveyed in this  
command reference". They then ref. Burrough (1986! not even the  
revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.  
37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,  
and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to  
date or accessible reference list (no offrence to the fine authors  
mentioned).

Thanks for your help.

D. G. Rossiter
Senior University Lecturer
Department of Earth Systems Analysis
International Institute for Geo-Information Science and Earth  
Observation (ITC)
PO Box 6, 7500 AA Enschede, The Netherlands
Internet: http://www.itc.nl/personal/rossiter/pubs/list.html#pubs_m_R



International Institute for Geo-Information Science and Earth
Observation (ITC)
Chamber of Commerce: 410 27 560

E-mail disclaimer
The information in this e-mail, including any attachments, is intended
for the addressee only. If you are not the intended recipient, you are
hereby notified that any disclosure, copying, distribution or action in
relation to the content of this information is strictly prohibited. If
you have received this e-mail by mistake, please delete the message and
any attachment and inform the sender by return e-mail. ITC accepts no
liability for any error or omission in the message content or for damage
of any kind that may arise as a result of e-mail transmission.

	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.%CRLF%The views expressed in  this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document%CRLF%



From b.rowlingson at lancaster.ac.uk  Sat Sep  6 18:33:11 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 6 Sep 2008 17:33:11 +0100
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it
	display / fit variograms?
In-Reply-To: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
Message-ID: <d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>

2008/9/6 D G Rossiter <rossiter at itc.nl>:

> Naturally we want the students to understand what the program is doing
> for them!  Although ESRI promotes "press the button and look at the
> cross-validation". I do like their disclaimer in the ArcGIS Desktop
> 9.3 help: "Kriging is a complex procedure that requires greater
> knowledge about spatial statistics than can be conveyed in this
> command reference". They then ref. Burrough (1986! not even the
> revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.
> 37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,
> and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to
> date or accessible reference list (no offrence to the fine authors
> mentioned).

 For software that costs $2500 dollars for a single-user license, I'd
expect documentation written in gold-leaf on human skin parchment. I
wouldn't expect to be palmed off with 'this bit is tricky, go read
some books', I'd expect the software to do just about everything,
explain what it was doing in the language of your choice, and give you
a backrub at the same time.

 I'm flabbergasted that a solution for what is probably not one of the
richest universities in the world is going to tie them to one of the
most expensive geostats packages I've ever seen. I'm staring at this
pricetag on the ESRI web site because I just feel like I must be
hallucinating. But I'm not. Two and a half THOUSAND dollars. Oh, and
you need an ArcView license as well, a mere snip at one and half
thousand dollars. Zimbabwe dollars? No, US dollars. I checked.

 I'm guessing you can't rethink your plans at this point, but you
could consider pointing out to students that free, cross-platform,
high-quality, open-source, well-documented software for statistics and
geostatistics is available to download from www.r-project.org, and
there's a friendly bunch of people willing to answer sensible
questions on the mailing list (including those professors who make it
their business to echo 'please read the posting guide' all the time).

 Hope this doesn't come over as too much of a rant, but I'm running a
course on Open-Source GeoSpatial Software in November and I think I
may have just found a nice counter-example :)

Barry
 [think I need a cup of tea and a lie-down now]



From Roger.Bivand at nhh.no  Sat Sep  6 19:15:27 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 6 Sep 2008 19:15:27 +0200 (CEST)
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it
 display / fit variograms?
In-Reply-To: <d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
	<d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809061911310.11229@reclus.nhh.no>

On Sat, 6 Sep 2008, Barry Rowlingson wrote:

> 2008/9/6 D G Rossiter <rossiter at itc.nl>:
>
>> Naturally we want the students to understand what the program is doing
>> for them!  Although ESRI promotes "press the button and look at the
>> cross-validation". I do like their disclaimer in the ArcGIS Desktop
>> 9.3 help: "Kriging is a complex procedure that requires greater
>> knowledge about spatial statistics than can be conveyed in this
>> command reference". They then ref. Burrough (1986! not even the
>> revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.
>> 37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,
>> and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to
>> date or accessible reference list (no offrence to the fine authors
>> mentioned).
>
> For software that costs $2500 dollars for a single-user license, I'd
> expect documentation written in gold-leaf on human skin parchment. I
> wouldn't expect to be palmed off with 'this bit is tricky, go read
> some books', I'd expect the software to do just about everything,
> explain what it was doing in the language of your choice, and give you
> a backrub at the same time.
>
> I'm flabbergasted that a solution for what is probably not one of the
> richest universities in the world is going to tie them to one of the
> most expensive geostats packages I've ever seen. I'm staring at this
> pricetag on the ESRI web site because I just feel like I must be
> hallucinating. But I'm not. Two and a half THOUSAND dollars. Oh, and
> you need an ArcView license as well, a mere snip at one and half
> thousand dollars. Zimbabwe dollars? No, US dollars. I checked.
>
> I'm guessing you can't rethink your plans at this point, but you
> could consider pointing out to students that free, cross-platform,
> high-quality, open-source, well-documented software for statistics and
> geostatistics is available to download from www.r-project.org, and
> there's a friendly bunch of people willing to answer sensible
> questions on the mailing list (including those professors who make it
> their business to echo 'please read the posting guide' all the time).
>
> Hope this doesn't come over as too much of a rant, but I'm running a
> course on Open-Source GeoSpatial Software in November and I think I
> may have just found a nice counter-example :)
>
> Barry
> [think I need a cup of tea and a lie-down now]

And FOSS4G 2008 is about to happen in Cape Town!

http://conference.osgeo.org/index.php/foss4g/2008

Just think what these young scientists could do with QGIS/GRASS/R/gstat 
or other suitable toolchains!

However, I've seen similar things, I'm afraid they may be being driven by 
clueless "donor" organisations.

I've just put the tea on ...

Roger

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From giohappy at gmail.com  Sat Sep  6 19:45:28 2008
From: giohappy at gmail.com (G. Allegri)
Date: Sat, 6 Sep 2008 19:45:28 +0200
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it
	display / fit variograms?
In-Reply-To: <Pine.LNX.4.64.0809061911310.11229@reclus.nhh.no>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
	<d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>
	<Pine.LNX.4.64.0809061911310.11229@reclus.nhh.no>
Message-ID: <e12429640809061045o35086965g1b786462bae7e397@mail.gmail.com>

I faced the problem of collecting informations about ArcGIS Geospatial
extension while I was following the geostatics course at university. A
month looking for documentation about what was behind the scene, but
nothing... Just basics explanations about kriging. That's when I've
discovered gstat!

In the Institute I come from ArcGIS/ArcInfo is the most widely used
system, for cartography and geoDB management. But nobody would use it
for geostatistical analysis! Ok, IDW, or other simple interpolations,
but nothing beyond this.
The only reason I would spend money for commercial software can be
Geovariances software (in the Institute they use Isatis) [1], nothing
else.

Giovanni

[1] http://www.geovariances.com/

2008/9/6 Roger Bivand <Roger.Bivand at nhh.no>:
> On Sat, 6 Sep 2008, Barry Rowlingson wrote:
>
>> 2008/9/6 D G Rossiter <rossiter at itc.nl>:
>>
>>> Naturally we want the students to understand what the program is doing
>>> for them!  Although ESRI promotes "press the button and look at the
>>> cross-validation". I do like their disclaimer in the ArcGIS Desktop
>>> 9.3 help: "Kriging is a complex procedure that requires greater
>>> knowledge about spatial statistics than can be conveyed in this
>>> command reference". They then ref. Burrough (1986! not even the
>>> revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.
>>> 37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,
>>> and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to
>>> date or accessible reference list (no offrence to the fine authors
>>> mentioned).
>>
>> For software that costs $2500 dollars for a single-user license, I'd
>> expect documentation written in gold-leaf on human skin parchment. I
>> wouldn't expect to be palmed off with 'this bit is tricky, go read
>> some books', I'd expect the software to do just about everything,
>> explain what it was doing in the language of your choice, and give you
>> a backrub at the same time.
>>
>> I'm flabbergasted that a solution for what is probably not one of the
>> richest universities in the world is going to tie them to one of the
>> most expensive geostats packages I've ever seen. I'm staring at this
>> pricetag on the ESRI web site because I just feel like I must be
>> hallucinating. But I'm not. Two and a half THOUSAND dollars. Oh, and
>> you need an ArcView license as well, a mere snip at one and half
>> thousand dollars. Zimbabwe dollars? No, US dollars. I checked.
>>
>> I'm guessing you can't rethink your plans at this point, but you
>> could consider pointing out to students that free, cross-platform,
>> high-quality, open-source, well-documented software for statistics and
>> geostatistics is available to download from www.r-project.org, and
>> there's a friendly bunch of people willing to answer sensible
>> questions on the mailing list (including those professors who make it
>> their business to echo 'please read the posting guide' all the time).
>>
>> Hope this doesn't come over as too much of a rant, but I'm running a
>> course on Open-Source GeoSpatial Software in November and I think I
>> may have just found a nice counter-example :)
>>
>> Barry
>> [think I need a cup of tea and a lie-down now]
>
> And FOSS4G 2008 is about to happen in Cape Town!
>
> http://conference.osgeo.org/index.php/foss4g/2008
>
> Just think what these young scientists could do with QGIS/GRASS/R/gstat or
> other suitable toolchains!
>
> However, I've seen similar things, I'm afraid they may be being driven by
> clueless "donor" organisations.
>
> I've just put the tea on ...
>
> Roger
>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From paciorek at hsph.harvard.edu  Sat Sep  6 20:43:51 2008
From: paciorek at hsph.harvard.edu (Christopher Paciorek)
Date: Sat, 06 Sep 2008 14:43:51 -0400
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does	itdisplay
	/ fit variograms?
In-Reply-To: <e12429640809061045o35086965g1b786462bae7e397@mail.gmail.com>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
	<d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>
	<Pine.LNX.4.64.0809061911310.11229@reclus.nhh.no>
	<e12429640809061045o35086965g1b786462bae7e397@mail.gmail.com>
Message-ID: <48C29717.10CD.002E.0@hsph.harvard.edu>

 This is a bit of a distant memory from a few years back when I also was trying to better understand what ArcGIS was actually doing, but I believe there is some, though probably not a large amount of, additional technical detail available in the following ESRI manuals:

Johnston, K. et al. 2001. Using ArcGIS geostatistical analyst. Redlands, CA: Environmental Systems Research Institute.
McCoy, J. et al. 2001. Using ArcGIS spatial analyst. Redlands, CA: Environmental Systems Research Institute.

I don't think I was able to find these online as I have a memory of tracking them down through the university map library.

-chris

----------------------------------------------------------------------------------------------
Chris Paciorek / Asst. Professor        Email: paciorek at hsph.harvard.edu
Department of Biostatistics             Voice: 617-432-4912
Harvard School of Public Health         Fax:   617-432-5619
655 Huntington Av., Bldg. 2-407         WWW: www.biostat.harvard.edu/~paciorek
Boston, MA 02115 USA                    Permanent forward: paciorek at alumni.cmu.edu

 
>>> "G. Allegri" <giohappy at gmail.com> 09/06/08 1:45 PM >>> 
I faced the problem of collecting informations about ArcGIS Geospatial
extension while I was following the geostatics course at university. A
month looking for documentation about what was behind the scene, but
nothing... Just basics explanations about kriging. That's when I've
discovered gstat!

In the Institute I come from ArcGIS/ArcInfo is the most widely used
system, for cartography and geoDB management. But nobody would use it
for geostatistical analysis! Ok, IDW, or other simple interpolations,
but nothing beyond this.
The only reason I would spend money for commercial software can be
Geovariances software (in the Institute they use Isatis) [1], nothing
else.

Giovanni

[1] http://www.geovariances.com/

2008/9/6 Roger Bivand <Roger.Bivand at nhh.no>:
> On Sat, 6 Sep 2008, Barry Rowlingson wrote:
>
>> 2008/9/6 D G Rossiter <rossiter at itc.nl>:
>>
>>> Naturally we want the students to understand what the program is doing
>>> for them!  Although ESRI promotes "press the button and look at the
>>> cross- validation". I do like their disclaimer in the ArcGIS Desktop
>>> 9.3 help: "Kriging is a complex procedure that requires greater
>>> knowledge about spatial statistics than can be conveyed in this
>>> command reference". They then ref. Burrough (1986! not even the
>>> revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.
>>> 37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,
>>> and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to
>>> date or accessible reference list (no offrence to the fine authors
>>> mentioned).
>>
>> For software that costs $2500 dollars for a single- user license, I'd
>> expect documentation written in gold- leaf on human skin parchment. I
>> wouldn't expect to be palmed off with 'this bit is tricky, go read
>> some books', I'd expect the software to do just about everything,
>> explain what it was doing in the language of your choice, and give you
>> a backrub at the same time.
>>
>> I'm flabbergasted that a solution for what is probably not one of the
>> richest universities in the world is going to tie them to one of the
>> most expensive geostats packages I've ever seen. I'm staring at this
>> pricetag on the ESRI web site because I just feel like I must be
>> hallucinating. But I'm not. Two and a half THOUSAND dollars. Oh, and
>> you need an ArcView license as well, a mere snip at one and half
>> thousand dollars. Zimbabwe dollars? No, US dollars. I checked.
>>
>> I'm guessing you can't rethink your plans at this point, but you
>> could consider pointing out to students that free, cross- platform,
>> high- quality, open- source, well- documented software for statistics and
>> geostatistics is available to download from www.r- project.org, and
>> there's a friendly bunch of people willing to answer sensible
>> questions on the mailing list (including those professors who make it
>> their business to echo 'please read the posting guide' all the time).
>>
>> Hope this doesn't come over as too much of a rant, but I'm running a
>> course on Open- Source GeoSpatial Software in November and I think I
>> may have just found a nice counter- example :)
>>
>> Barry
>> [think I need a cup of tea and a lie- down now]
>
> And FOSS4G 2008 is about to happen in Cape Town!
>
> http://conference.osgeo.org/index.php/foss4g/2008
>
> Just think what these young scientists could do with QGIS/GRASS/R/gstat or
> other suitable toolchains!
>
> However, I've seen similar things, I'm afraid they may be being driven by
> clueless "donor" organisations.
>
> I've just put the tea on ...
>
> Roger
>
>>
>> _______________________________________________
>> R- sig- Geo mailing list
>> R- sig- Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r- sig- geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N- 5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e- mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R- sig- Geo mailing list
> R- sig- Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r- sig- geo
>

_______________________________________________
R- sig- Geo mailing list
R- sig- Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r- sig- geo



From paulojus at c3sl.ufpr.br  Sat Sep  6 22:14:06 2008
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Sat, 6 Sep 2008 17:14:06 -0300 (BRT)
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does itdisplay
 / fit variograms?
In-Reply-To: <48C29717.10CD.002E.0@hsph.harvard.edu>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>
	<d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>
	<Pine.LNX.4.64.0809061911310.11229@reclus.nhh.no>
	<e12429640809061045o35086965g1b786462bae7e397@mail.gmail.com>
	<48C29717.10CD.002E.0@hsph.harvard.edu>
Message-ID: <Pine.LNX.4.58.0809061712040.14586@macalan.c3sl.ufpr.br>


Nothing else to say after Barry's email, apart from noting yet another
wonder of the free software world/community:

we even use our mailing lists to provide advice on commercial software!!!
Uau!

Would the reverse be true?


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus



On Sat, 6 Sep 2008, Christopher Paciorek wrote:

>  This is a bit of a distant memory from a few years back when I also was trying to better understand what ArcGIS was actually doing, but I believe there is some, though probably not a large amount of, additional technical detail available in the following ESRI manuals:
>
> Johnston, K. et al. 2001. Using ArcGIS geostatistical analyst. Redlands, CA: Environmental Systems Research Institute.
> McCoy, J. et al. 2001. Using ArcGIS spatial analyst. Redlands, CA: Environmental Systems Research Institute.
>
> I don't think I was able to find these online as I have a memory of tracking them down through the university map library.
>
> -chris
>
> ----------------------------------------------------------------------------------------------
> Chris Paciorek / Asst. Professor        Email: paciorek at hsph.harvard.edu
> Department of Biostatistics             Voice: 617-432-4912
> Harvard School of Public Health         Fax:   617-432-5619
> 655 Huntington Av., Bldg. 2-407         WWW: www.biostat.harvard.edu/~paciorek
> Boston, MA 02115 USA                    Permanent forward: paciorek at alumni.cmu.edu
>
>
> >>> "G. Allegri" <giohappy at gmail.com> 09/06/08 1:45 PM >>>
> I faced the problem of collecting informations about ArcGIS Geospatial
> extension while I was following the geostatics course at university. A
> month looking for documentation about what was behind the scene, but
> nothing... Just basics explanations about kriging. That's when I've
> discovered gstat!
>
> In the Institute I come from ArcGIS/ArcInfo is the most widely used
> system, for cartography and geoDB management. But nobody would use it
> for geostatistical analysis! Ok, IDW, or other simple interpolations,
> but nothing beyond this.
> The only reason I would spend money for commercial software can be
> Geovariances software (in the Institute they use Isatis) [1], nothing
> else.
>
> Giovanni
>
> [1] http://www.geovariances.com/
>
> 2008/9/6 Roger Bivand <Roger.Bivand at nhh.no>:
> > On Sat, 6 Sep 2008, Barry Rowlingson wrote:
> >
> >> 2008/9/6 D G Rossiter <rossiter at itc.nl>:
> >>
> >>> Naturally we want the students to understand what the program is doing
> >>> for them!  Although ESRI promotes "press the button and look at the
> >>> cross- validation". I do like their disclaimer in the ArcGIS Desktop
> >>> 9.3 help: "Kriging is a complex procedure that requires greater
> >>> knowledge about spatial statistics than can be conveyed in this
> >>> command reference". They then ref. Burrough (1986! not even the
> >>> revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.
> >>> 37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,
> >>> and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to
> >>> date or accessible reference list (no offrence to the fine authors
> >>> mentioned).
> >>
> >> For software that costs $2500 dollars for a single- user license, I'd
> >> expect documentation written in gold- leaf on human skin parchment. I
> >> wouldn't expect to be palmed off with 'this bit is tricky, go read
> >> some books', I'd expect the software to do just about everything,
> >> explain what it was doing in the language of your choice, and give you
> >> a backrub at the same time.
> >>
> >> I'm flabbergasted that a solution for what is probably not one of the
> >> richest universities in the world is going to tie them to one of the
> >> most expensive geostats packages I've ever seen. I'm staring at this
> >> pricetag on the ESRI web site because I just feel like I must be
> >> hallucinating. But I'm not. Two and a half THOUSAND dollars. Oh, and
> >> you need an ArcView license as well, a mere snip at one and half
> >> thousand dollars. Zimbabwe dollars? No, US dollars. I checked.
> >>
> >> I'm guessing you can't rethink your plans at this point, but you
> >> could consider pointing out to students that free, cross- platform,
> >> high- quality, open- source, well- documented software for statistics and
> >> geostatistics is available to download from www.r- project.org, and
> >> there's a friendly bunch of people willing to answer sensible
> >> questions on the mailing list (including those professors who make it
> >> their business to echo 'please read the posting guide' all the time).
> >>
> >> Hope this doesn't come over as too much of a rant, but I'm running a
> >> course on Open- Source GeoSpatial Software in November and I think I
> >> may have just found a nice counter- example :)
> >>
> >> Barry
> >> [think I need a cup of tea and a lie- down now]
> >
> > And FOSS4G 2008 is about to happen in Cape Town!
> >
> > http://conference.osgeo.org/index.php/foss4g/2008
> >
> > Just think what these young scientists could do with QGIS/GRASS/R/gstat or
> > other suitable toolchains!
> >
> > However, I've seen similar things, I'm afraid they may be being driven by
> > clueless "donor" organisations.
> >
> > I've just put the tea on ...
> >
> > Roger
> >
> >>
> >> _______________________________________________
> >> R- sig- Geo mailing list
> >> R- sig- Geo at stat.math.ethz.ch
> >> https://stat.ethz.ch/mailman/listinfo/r- sig- geo
> >>
> >
> > --
> > Roger Bivand
> > Economic Geography Section, Department of Economics, Norwegian School of
> > Economics and Business Administration, Helleveien 30, N- 5045 Bergen,
> > Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> > e- mail: Roger.Bivand at nhh.no
> >
> > _______________________________________________
> > R- sig- Geo mailing list
> > R- sig- Geo at stat.math.ethz.ch
> > https://stat.ethz.ch/mailman/listinfo/r- sig- geo
> >
>
> _______________________________________________
> R- sig- Geo mailing list
> R- sig- Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r- sig- geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Sun Sep  7 00:17:02 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 07 Sep 2008 00:17:02 +0200
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does itdisplay
 / fit variograms?
In-Reply-To: <Pine.LNX.4.58.0809061712040.14586@macalan.c3sl.ufpr.br>
References: <C78D7D02-C9B4-40B1-A085-5871251D3355@itc.nl>	<d8ad40b50809060933w5b1f3867h3fe8eecbafb42f@mail.gmail.com>	<Pine.LNX.4.64.0809061911310.11229@reclus.nhh.no>	<e12429640809061045o35086965g1b786462bae7e397@mail.gmail.com>	<48C29717.10CD.002E.0@hsph.harvard.edu>
	<Pine.LNX.4.58.0809061712040.14586@macalan.c3sl.ufpr.br>
Message-ID: <48C3015E.1040305@uni-muenster.de>



Paulo Justiniano Ribeiro Jr wrote:
> Nothing else to say after Barry's email, apart from noting yet another
> wonder of the free software world/community:
>
> we even use our mailing lists to provide advice on commercial software!!!
> Uau!
>
> Would the reverse be true?
>   
Paulo, this might be less utopic than it sounds. I've heard that at ESRI 
Redlands there are quite a few active, and I presume happy, R users.
--
Edzer



From kkrivoruchko at esri.com  Sun Sep  7 20:15:13 2008
From: kkrivoruchko at esri.com (Konstantin Krivoruchko)
Date: Sun, 7 Sep 2008 11:15:13 -0700
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does it
	display /fit?
References: <mailman.5.1220781602.4785.r-sig-geo@stat.math.ethz.ch>
Message-ID: <D7BFFE348C53EF4E8AA0698B1E395FA907B3D388@flybywire.esri.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080907/8a32bc19/attachment.pl>

From Robin.Naidoo at WWFUS.ORG  Mon Sep  8 01:08:22 2008
From: Robin.Naidoo at WWFUS.ORG (Naidoo, Robin)
Date: Sun, 7 Sep 2008 19:08:22 -0400
Subject: [R-sig-Geo] importing and viewing a JPEG2000 file
Message-ID: <94F37792B434C4429AD54210EAB2D935056A5F27FA@WWFUS-EXCH11.hq.wwfinternal.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080907/31d0dc41/attachment.pl>

From edzer.pebesma at uni-muenster.de  Mon Sep  8 08:14:29 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 08 Sep 2008 08:14:29 +0200
Subject: [R-sig-Geo] importing and viewing a JPEG2000 file
In-Reply-To: <94F37792B434C4429AD54210EAB2D935056A5F27FA@WWFUS-EXCH11.hq.wwfinternal.org>
References: <94F37792B434C4429AD54210EAB2D935056A5F27FA@WWFUS-EXCH11.hq.wwfinternal.org>
Message-ID: <48C4C2C5.9010506@uni-muenster.de>

Try readGDAL in package rgdal. On my machine, gdalDrivers() returns

...
35  JPEG2000      JPEG-2000 part 1 (ISO/IEC 15444-1)  FALSE  TRUE
...
as one of the available drivers. Then, look into
?image.SpatialGridDataFrame (package sp) and check the red/green/blue 
arguments.

Hth,
--
Edzer

Naidoo, Robin wrote:
> Hello,
>
> Please forgive any breaches in protocol or the simplicity of this question.
>
> I would like to import and display a JPEG2000 satellite image in R.  Could someone be so kind as to advise on how to do this?  And more generally: is it possible to import multi-band satellite images and to display them in colour using a subset of 3 of the bands, as in a standard GIS program?
>
> Many thanks,
>
> Robin Naidoo
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From adrian at maths.uwa.edu.au  Mon Sep  8 10:08:44 2008
From: adrian at maths.uwa.edu.au (adrian at maths.uwa.edu.au)
Date: Mon, 8 Sep 2008 16:08:44 +0800 (WST)
Subject: [R-sig-Geo] clipping psp & owin
Message-ID: <45129.130.95.98.17.1220861324.squirrel@130.95.98.17>

Alexandre Camargo Martensen writes:

> Subject: [R-sig-Geo] clipping psp & owin

> I'm trying to "clip" a psp and an owin object.

> My question is what should I do to get the information of what is inside
the
> clipping object (trans), having as an input object an owin (b).

Use the subset operator "[" to take the intersection of a psp with an owin.
For example
         X <- rpoisline(10)
         W <- owin(c(0.1,0.7), c(0.2, 0.8))
         Y <- X[W]

There are examples in demo(spatstat) and help("[.psp")

Adrian Baddeley



From jean-paul.kibambe at uclouvain.be  Mon Sep  8 12:30:51 2008
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Mon, 8 Sep 2008 12:30:51 +0200 (CEST)
Subject: [R-sig-Geo] Shapefile - GRID operations
Message-ID: <63d1c0678ad8e4c77bd157961e913670.squirrel@mmp.sipr-dc.ucl.ac.be>

Hello everybody,

I have one GRID with my weights values over my study area. I have also an
Administrative boundaries shapefile of my study area with an unique value
of my variable of interest for each administrative unit.

I want to distribute my unique value by administrative unit for each pixel
of my GRID taking into account the weights of each pixel.

So I want to do the following steps :

1. select an Administrative unit (value of interest = Vi)
2. clip the GRID at the boundaries of that admin unit
3. calculate the sum of the weights for that clipped grid (= Wi)
4. clipped grid * Vi / Wi
... the same for all my administrative units.

5. at the end, have a new GRID of my study area with the value of my
variable of interest distributed over all my administrative units.


So for sure (I mean), there is a more efficient way to do it with R...
Anyone could help me ?

Thanks in advance !


JP



From Henk.Sierdsema at sovon.nl  Mon Sep  8 16:14:26 2008
From: Henk.Sierdsema at sovon.nl (Henk Sierdsema)
Date: Mon, 8 Sep 2008 16:14:26 +0200
Subject: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how
	does	itdisplay/ fit variograms?
In-Reply-To: <48C29717.10CD.002E.0@hsph.harvard.edu>
Message-ID: <F7A3EE6B27F4D54B9CCAAB767F1B5AA3FDB45D@mail.sovon.nl>

Hi,

You can download the geostat-manual from http://dusk2.geo.orst.edu/gis/geostat_analyst.pdf and  http://www.ci.uri.edu/projects/geostats/Using_ArcGIS_Geostat_Anal_Tutor.pdf 

and the spatial-analyst manual from http://www.maproom.ruc.dk/software/arcmap/using_spatial_analyst.pdf/view and http://www.gis.unbc.ca/help/software/esri/Tutorials/Using_ArcGIS_Spatial_Analyst_Tutorial.pdf

Henk




Henk Sierdsema

SOVON Vogelonderzoek Nederland / SOVON Dutch Centre for Field Ornithology

Rijksstraatweg 178
6573 DG  Beek-Ubbergen
The Netherlands
tel: +31 (0)24 6848145
fax: +31 (0)24 6848122



-----Oorspronkelijk bericht-----
Van: Christopher Paciorek [mailto:paciorek at hsph.harvard.edu]
Verzonden: zaterdag 6 september 2008 20:44
Aan: G. Allegri
CC: r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] ArcGIS Geostatistical Analyst -- how does
itdisplay/ fit variograms?


 This is a bit of a distant memory from a few years back when I also was trying to better understand what ArcGIS was actually doing, but I believe there is some, though probably not a large amount of, additional technical detail available in the following ESRI manuals:

Johnston, K. et al. 2001. Using ArcGIS geostatistical analyst. Redlands, CA: Environmental Systems Research Institute.
McCoy, J. et al. 2001. Using ArcGIS spatial analyst. Redlands, CA: Environmental Systems Research Institute.

I don't think I was able to find these online as I have a memory of tracking them down through the university map library.

-chris

----------------------------------------------------------------------------------------------
Chris Paciorek / Asst. Professor        Email: paciorek at hsph.harvard.edu
Department of Biostatistics             Voice: 617-432-4912
Harvard School of Public Health         Fax:   617-432-5619
655 Huntington Av., Bldg. 2-407         WWW: www.biostat.harvard.edu/~paciorek
Boston, MA 02115 USA                    Permanent forward: paciorek at alumni.cmu.edu


>>> "G. Allegri" <giohappy at gmail.com> 09/06/08 1:45 PM >>> 
I faced the problem of collecting informations about ArcGIS Geospatial
extension while I was following the geostatics course at university. A
month looking for documentation about what was behind the scene, but
nothing... Just basics explanations about kriging. That's when I've
discovered gstat!

In the Institute I come from ArcGIS/ArcInfo is the most widely used
system, for cartography and geoDB management. But nobody would use it
for geostatistical analysis! Ok, IDW, or other simple interpolations,
but nothing beyond this.
The only reason I would spend money for commercial software can be
Geovariances software (in the Institute they use Isatis) [1], nothing
else.

Giovanni

[1] http://www.geovariances.com/

2008/9/6 Roger Bivand <Roger.Bivand at nhh.no>:
> On Sat, 6 Sep 2008, Barry Rowlingson wrote:
>
>> 2008/9/6 D G Rossiter <rossiter at itc.nl>:
>>
>>> Naturally we want the students to understand what the program is doing
>>> for them!  Although ESRI promotes "press the button and look at the
>>> cross- validation". I do like their disclaimer in the ArcGIS Desktop
>>> 9.3 help: "Kriging is a complex procedure that requires greater
>>> knowledge about spatial statistics than can be conveyed in this
>>> command reference". They then ref. Burrough (1986! not even the
>>> revised book), Heine (1986), McBratney & Webster Journal of Soil Sci.
>>> 37:317 (1986), Oliver IJGIS 4 (1990), Press etc. Numerical Recipes,
>>> and Royle et al. Geoprocessing 1 (1981). Not exactly the most up to
>>> date or accessible reference list (no offrence to the fine authors
>>> mentioned).
>>
>> For software that costs $2500 dollars for a single- user license, I'd
>> expect documentation written in gold- leaf on human skin parchment. I
>> wouldn't expect to be palmed off with 'this bit is tricky, go read
>> some books', I'd expect the software to do just about everything,
>> explain what it was doing in the language of your choice, and give you
>> a backrub at the same time.
>>
>> I'm flabbergasted that a solution for what is probably not one of the
>> richest universities in the world is going to tie them to one of the
>> most expensive geostats packages I've ever seen. I'm staring at this
>> pricetag on the ESRI web site because I just feel like I must be
>> hallucinating. But I'm not. Two and a half THOUSAND dollars. Oh, and
>> you need an ArcView license as well, a mere snip at one and half
>> thousand dollars. Zimbabwe dollars? No, US dollars. I checked.
>>
>> I'm guessing you can't rethink your plans at this point, but you
>> could consider pointing out to students that free, cross- platform,
>> high- quality, open- source, well- documented software for statistics and
>> geostatistics is available to download from www.r- project.org, and
>> there's a friendly bunch of people willing to answer sensible
>> questions on the mailing list (including those professors who make it
>> their business to echo 'please read the posting guide' all the time).
>>
>> Hope this doesn't come over as too much of a rant, but I'm running a
>> course on Open- Source GeoSpatial Software in November and I think I
>> may have just found a nice counter- example :)
>>
>> Barry
>> [think I need a cup of tea and a lie- down now]
>
> And FOSS4G 2008 is about to happen in Cape Town!
>
> http://conference.osgeo.org/index.php/foss4g/2008
>
> Just think what these young scientists could do with QGIS/GRASS/R/gstat or
> other suitable toolchains!
>
> However, I've seen similar things, I'm afraid they may be being driven by
> clueless "donor" organisations.
>
> I've just put the tea on ...
>
> Roger
>
>>
>> _______________________________________________
>> R- sig- Geo mailing list
>> R- sig- Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r- sig- geo
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N- 5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e- mail: Roger.Bivand at nhh.no
>
> _______________________________________________
> R- sig- Geo mailing list
> R- sig- Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r- sig- geo
>

_______________________________________________
R- sig- Geo mailing list
R- sig- Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r- sig- geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From r.m.krug at gmail.com  Mon Sep  8 16:42:02 2008
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Mon, 8 Sep 2008 16:42:02 +0200
Subject: [R-sig-Geo] Shapefile - GRID operations
In-Reply-To: <63d1c0678ad8e4c77bd157961e913670.squirrel@mmp.sipr-dc.ucl.ac.be>
References: <63d1c0678ad8e4c77bd157961e913670.squirrel@mmp.sipr-dc.ucl.ac.be>
Message-ID: <fb7c7e870809080742g4028faf1n891f454d95960048@mail.gmail.com>

On Mon, Sep 8, 2008 at 12:30 PM, Jean-Paul Kibambe Lubamba
<jean-paul.kibambe at uclouvain.be> wrote:
> Hello everybody,
>
> I have one GRID with my weights values over my study area. I have also an
> Administrative boundaries shapefile of my study area with an unique value
> of my variable of interest for each administrative unit.
>
> I want to distribute my unique value by administrative unit for each pixel
> of my GRID taking into account the weights of each pixel.
>
> So I want to do the following steps :
>
> 1. select an Administrative unit (value of interest = Vi)
> 2. clip the GRID at the boundaries of that admin unit
> 3. calculate the sum of the weights for that clipped grid (= Wi)
> 4. clipped grid * Vi / Wi
> ... the same for all my administrative units.
>
> 5. at the end, have a new GRID of my study area with the value of my
> variable of interest distributed over all my administrative units.

Look into the function overlay() in the package sp. This will do what you need.

Rainer


>
>
> So for sure (I mean), there is a more efficient way to do it with R...
> Anyone could help me ?
>
> Thanks in advance !
>
>
> JP
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



From ddepew at sciborg.uwaterloo.ca  Wed Sep 10 20:17:29 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Wed, 10 Sep 2008 14:17:29 -0400
Subject: [R-sig-Geo] nested variograms?
Message-ID: <48C80F39.4060305@scimail.uwaterloo.ca>

A quick question for experienced gstat users....
Can nested variograms be fit using gstat? if so, is it simply adding to 
an existing variogram structure?

Thanks


-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W.
Waterloo, ON. Canada
N2L 3G1

(T) 1-519-888-4567 x33895
(F) 1-519-746-0614

http://www.science.uwaterloo.ca/~ddepew



From edzer.pebesma at uni-muenster.de  Wed Sep 10 20:50:02 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 10 Sep 2008 20:50:02 +0200
Subject: [R-sig-Geo] nested variograms?
In-Reply-To: <48C80F39.4060305@scimail.uwaterloo.ca>
References: <48C80F39.4060305@scimail.uwaterloo.ca>
Message-ID: <48C816DA.2020703@uni-muenster.de>

Dave Depew wrote:
> A quick question for experienced gstat users....
> Can nested variograms be fit using gstat? if so, is it simply adding 
> to an existing variogram structure?
>
> Thanks
>
 > library(gstat)
Loading required package: sp
 > data(meuse)
 > coordinates(meuse) = c("x", "y")
 > v = variogram(log(zinc) ~ 1, meuse)
 > fit.variogram(v, vgm(1, "Exp", 300))
  model     psill    range
1   Exp 0.7186595 449.7664
 > fit.variogram(v, vgm(1, "Exp", 300, 1))
  model     psill    range
1   Nug 0.0000000   0.0000
2   Exp 0.7186528 449.7583
 > fit.variogram(v, vgm(1, "Exp", 300, add.to=vgm(1, "Nug", 0)))
  model     psill    range
1   Nug 0.0000000   0.0000
2   Exp 0.7186528 449.7583
 > fit.variogram(v, vgm(1, "Exp", 300, 1, add.to=vgm(1, "Exp", 10)))
Warning: singular model in variogram fit
  model psill range
1   Exp     1    10
2   Nug     1     0
3   Exp     1   300
 > fit.variogram(v, vgm(1, "Exp", 300, 1, add.to=vgm(1, "Exp", 10, 
add.to=vgm(1, "Exp", 50))))
Warning: singular model in variogram fit
  model psill range
1   Exp     1    50
2   Exp     1    10
3   Nug     1     0
4   Exp     1   300

Of course the fitting fails badly for this poor example, but I guess you 
get the idea. I think there is no limit to the number of nested 
structures, but consider that feature as pretty useless.

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From mario.gellrich at env.ethz.ch  Thu Sep 11 12:12:01 2008
From: mario.gellrich at env.ethz.ch (Gellrich  Mario)
Date: Thu, 11 Sep 2008 12:12:01 +0200
Subject: [R-sig-Geo] Distance-based neighbourhood statistics problem
Message-ID: <12DDB272B3619B49ACE8A185DEB6CD34165751@EX6.d.ethz.ch>

Hi,

I've got a question regarding distance-based neighbourhood statistics using two separate spatial data sets. What I have are municipalities and buildings within municipalities which both come with x- and y-coordinates. I merged the two datasets row-wise and used the following code to obtain aggregated values for the number of builings surrounding a municipality. The code hower doesn't work appropriately. Can anybody help?


d.geb <- read.table("gebaeuderecord_selection_test.csv", header=T, sep=";")
d.geb[1:10,]

     MUNICIP     NAME GEBID NUMBERGEB ABPER    LON    LAT
1          0 Gebaeude  4262         1     1 681864 225868
2          0 Gebaeude 14168         1     7 682190 224294
3          0 Gebaeude 33346         1     5 682176 224354
4          0 Gebaeude 44610         1    15 681571 225189
5          0 Gebaeude 62785         1     1 679800 226040
6          0 Gebaeude 72287         1     1 684619 224239
7          0 Gebaeude 83044         1     8 681701 224818
8          0 Gebaeude 84827         1     2 684878 230975
9          0 Gebaeude 86671         1     0 685733 227247
10         0 Gebaeude 88022         1     1 685691 230548


# Variable description:

# MUNICIP:   zero for buildings; one for municipalities
# NAME   :   if 'Gebaeude' == building; otherwise municipality name
# GEBID:     ID of building; -99 otherwise
# NUMBERGEB: number of buildings - one for each building-record; set to zero if record represents municipality
# ABWOW:     number of flats in a building


### Creates neighbourhood list and should provide aggregates values within a distance of 1 kilometer from a municipality for the variables NUMBERGEB or ABWOW

library(spdep)
geb.nb2   	<- dnearneigh(as.matrix(d.geb[,6:7]), 0, 1, longlat=TRUE)
d.geb$SUMGEB 	<- unlist(lapply(geb.nb2, function(x) ifelse(any(x==0), 0, sum(d.geb$ABPER[x])))) 

subset(d.geb, MUNICIP == 1)


Best regards,

Mario



From milton.ruser at gmail.com  Thu Sep 11 15:14:03 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Thu, 11 Sep 2008 11:14:03 -0200
Subject: [R-sig-Geo] Distance-based neighbourhood statistics problem
In-Reply-To: <12DDB272B3619B49ACE8A185DEB6CD34165751@EX6.d.ethz.ch>
References: <12DDB272B3619B49ACE8A185DEB6CD34165751@EX6.d.ethz.ch>
Message-ID: <3aaf1a030809110614l131dbc72vf396584b9130c65@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080911/858fbd5f/attachment.pl>

From mario.gellrich at env.ethz.ch  Thu Sep 11 17:32:34 2008
From: mario.gellrich at env.ethz.ch (Gellrich  Mario)
Date: Thu, 11 Sep 2008 17:32:34 +0200
Subject: [R-sig-Geo] Distance-based neighbourhood statistics problem
Message-ID: <12DDB272B3619B49ACE8A185DEB6CD34165755@EX6.d.ethz.ch>

Hi again,


no, the code line is not the problem - what's shown in the first message are just the first 10 lines of the data set. The problem seems to be the coordinates of the data. I have reduced the data set to only seven points to show the problem: 

# Example data set: 

d.geb <- read.table("geb_test.csv", header=T, sep=";")
d.geb

    GEBID ANZAHLGEB ABWOW   XACH   YACH Ortsname
1  896967         1     1 682886 226329 gebaeude
2  915184         1     0 682949 226280 gebaeude
3  988432         1     6 682960 226315 gebaeude
4 1070819         1     1 682939 226282 gebaeude
5 1070925         1     3 682991 226290 gebaeude
6 1413991         1     0 682905 226297 gebaeude
7     -99         0     0 682934 226299  TestOrt


# Here ANZAHLGEB is the number of buildings per data point (= 1, except for the municipality); ABWOW is the number of flats in the building.

library(spdep)

geb.nb2           <- dnearneigh(as.matrix(d.geb[,4:5]), 0, 500, longlat=TRUE)
d.geb$SUMGEB 	  <- unlist(lapply(geb.nb2, function(x) ifelse(any(x==0), 0, sum(d.geb$ANZAHLGEB[x]))))
d.geb

# The outcome 'SUMGEB' is zero (= no buildings within a distance of 500 meters) - this despite 500 m is the distance in wich all points have at least one neighbour: 

    GEBID ANZAHLGEB ABWOW   XACH   YACH Ortsname SUMGEB
1  896967         1     1 682886 226329 gebaeude      0
2  915184         1     0 682949 226280 gebaeude      0
3  988432         1     6 682960 226315 gebaeude      0
4 1070819         1     1 682939 226282 gebaeude      0
5 1070925         1     3 682991 226290 gebaeude      0
6 1413991         1     0 682905 226297 gebaeude      0
7     -99         0     0 682934 226299  TestOrt      0


### If I calculate the Euclidean Distanz between data point 2 and 4, it gives you the correct distance (in meters): 


d.dist <- sqrt( (682949 - 682939)^2 + (226280 - 226282)^2 )
d.dist

[1] 10.19804  

# It seems to be that dnearneigh uses another coordinate system (see also the X and Y variables in the columbus data set which comes with spdep) 


Best regards,

Mario






 
Hi Mario,
I don?t know if it is the problem, but the code line below need be changed:

subset(d.geb, d.geb$MUNICIP == 1)

best wishes,

miltinho astronauta
brazil

On Thu, Sep 11, 2008 at 8:12 AM, Gellrich Mario
<mario.gellrich at env.ethz.ch>wrote:

> Hi,
>
> I've got a question regarding distance-based neighbourhood statistics using
> two separate spatial data sets. What I have are municipalities and buildings
> within municipalities which both come with x- and y-coordinates. I merged
> the two datasets row-wise and used the following code to obtain aggregated
> values for the number of builings surrounding a municipality. The code hower
> doesn't work appropriately. Can anybody help?
>
>
> d.geb <- read.table("gebaeuderecord_selection_test.csv", header=T, sep=";")
> d.geb[1:10,]
>
>     MUNICIP     NAME GEBID NUMBERGEB ABPER    LON    LAT
> 1          0 Gebaeude  4262         1     1 681864 225868
> 2          0 Gebaeude 14168         1     7 682190 224294
> 3          0 Gebaeude 33346         1     5 682176 224354
> 4          0 Gebaeude 44610         1    15 681571 225189
> 5          0 Gebaeude 62785         1     1 679800 226040
> 6          0 Gebaeude 72287         1     1 684619 224239
> 7          0 Gebaeude 83044         1     8 681701 224818
> 8          0 Gebaeude 84827         1     2 684878 230975
> 9          0 Gebaeude 86671         1     0 685733 227247
> 10         0 Gebaeude 88022         1     1 685691 230548
>
>
> # Variable description:
>
> # MUNICIP:   zero for buildings; one for municipalities
> # NAME   :   if 'Gebaeude' == building; otherwise municipality name
> # GEBID:     ID of building; -99 otherwise
> # NUMBERGEB: number of buildings - one for each building-record; set to
> zero if record represents municipality
> # ABWOW:     number of flats in a building
>
>
> ### Creates neighbourhood list and should provide aggregates values within
> a distance of 1 kilometer from a municipality for the variables NUMBERGEB or
> ABWOW
>
> library(spdep)
> geb.nb2         <- dnearneigh(as.matrix(d.geb[,6:7]), 0, 1, longlat=TRUE)
> d.geb$SUMGEB    <- unlist(lapply(geb.nb2, function(x) ifelse(any(x==0), 0,
> sum(d.geb$ABPER[x]))))
>
> subset(d.geb, MUNICIP == 1)
>
>
> Best regards,
>
> Mario
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From giohappy at gmail.com  Thu Sep 11 23:23:46 2008
From: giohappy at gmail.com (G. Allegri)
Date: Thu, 11 Sep 2008 23:23:46 +0200
Subject: [R-sig-Geo] just received Applied spatial data analysis with R
Message-ID: <e12429640809111423g318218afme020feb0e0b2a48f@mail.gmail.com>

I've just received "Applied spatial data analysis with R" from Springer.
I want to thanks publicly all the authors for this jewel. It will be
on my job desk from now on!

Giovanni Allegri



From hi_ono2001 at ybb.ne.jp  Fri Sep 12 06:25:33 2008
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Fri, 12 Sep 2008 13:25:33 +0900 (JST)
Subject: [R-sig-Geo] How to convert results generated by "filled.contour" to
	shapefiles?
Message-ID: <20080912042533.84539.qmail@web10710.mail.bbt.yahoo.co.jp>

Hello.

 Currently I have developed geo-spatial mining tool using
R with spdep, spgwr and other packages as
OpenJUMP(http://www.openjump.org)'s plug-ins.

 I've already implemented contouring function using
contourlines function.

 I'd like to fill colours between levels of contours.

 So does anyone try to convert results generated by
"filled.contour" to shapefiles?

 Could you share the knowledge?


 Regards.

 P.S.

  I have received "Applied Spatial Data Analysis with R
(Use R) " from Amazon Japan.

 It's very nice and useful book. Thanks.



From Roger.Bivand at nhh.no  Fri Sep 12 09:13:18 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Sep 2008 09:13:18 +0200 (CEST)
Subject: [R-sig-Geo] Distance-based neighbourhood statistics problem
In-Reply-To: <12DDB272B3619B49ACE8A185DEB6CD34165755@EX6.d.ethz.ch>
References: <12DDB272B3619B49ACE8A185DEB6CD34165755@EX6.d.ethz.ch>
Message-ID: <Pine.LNX.4.64.0809120904470.10895@reclus.nhh.no>

On Thu, 11 Sep 2008, Gellrich  Mario wrote:

> Hi again,
>
>
> no, the code line is not the problem - what's shown in the first message are just the first 10 lines of the data set. The problem seems to be the coordinates of the data. I have reduced the data set to only seven points to show the problem:
>
> # Example data set:
>
> d.geb <- read.table("geb_test.csv", header=T, sep=";")
> d.geb
>
>    GEBID ANZAHLGEB ABWOW   XACH   YACH Ortsname
> 1  896967         1     1 682886 226329 gebaeude
> 2  915184         1     0 682949 226280 gebaeude
> 3  988432         1     6 682960 226315 gebaeude
> 4 1070819         1     1 682939 226282 gebaeude
> 5 1070925         1     3 682991 226290 gebaeude
> 6 1413991         1     0 682905 226297 gebaeude
> 7     -99         0     0 682934 226299  TestOrt

                             ^^^^^^^^^^^^^

This looks like the problem - these are not decimal degrees as expected by 
the longlat=TRUE used in dnearneigh().

> xy <- cbind(c(682886, 682949, 682960, 682939, 682991, 682905, 682934),
    c(226329, 226280, 226315, 226282, 226290, 226297, 226299))
> dnearneigh(xy, 0, 500)
Neighbour list object:
Number of regions: 7
Number of nonzero links: 42
Percentage nonzero weights: 85.71429
Average number of links: 6
> dnearneigh(xy, 0, 500, longlat=TRUE)
Neighbour list object:
Number of regions: 7
Number of nonzero links: 0
Percentage nonzero weights: 0
Average number of links: 0
7 regions with no links:

If the coordinates are decimal coordinates but multiplied by 1000 to 
store as integer, we get:

> dnearneigh(xy/1000, 0, 500, longlat=TRUE)
Neighbour list object:
Number of regions: 7
Number of nonzero links: 42
Percentage nonzero weights: 85.71429
Average number of links: 6

If you get that right first, the rest should follow.

Roger

>
>
> # Here ANZAHLGEB is the number of buildings per data point (= 1, except for the municipality); ABWOW is the number of flats in the building.
>
> library(spdep)
>
> geb.nb2           <- dnearneigh(as.matrix(d.geb[,4:5]), 0, 500, longlat=TRUE)
> d.geb$SUMGEB 	  <- unlist(lapply(geb.nb2, function(x) ifelse(any(x==0), 0, sum(d.geb$ANZAHLGEB[x]))))
> d.geb
>
> # The outcome 'SUMGEB' is zero (= no buildings within a distance of 500 meters) - this despite 500 m is the distance in wich all points have at least one neighbour:
>
>    GEBID ANZAHLGEB ABWOW   XACH   YACH Ortsname SUMGEB
> 1  896967         1     1 682886 226329 gebaeude      0
> 2  915184         1     0 682949 226280 gebaeude      0
> 3  988432         1     6 682960 226315 gebaeude      0
> 4 1070819         1     1 682939 226282 gebaeude      0
> 5 1070925         1     3 682991 226290 gebaeude      0
> 6 1413991         1     0 682905 226297 gebaeude      0
> 7     -99         0     0 682934 226299  TestOrt      0
>
>
> ### If I calculate the Euclidean Distanz between data point 2 and 4, it gives you the correct distance (in meters):
>
>
> d.dist <- sqrt( (682949 - 682939)^2 + (226280 - 226282)^2 )
> d.dist
>
> [1] 10.19804
>
> # It seems to be that dnearneigh uses another coordinate system (see also the X and Y variables in the columbus data set which comes with spdep)
>
>
> Best regards,
>
> Mario
>
>
>
>
>
>
>
> Hi Mario,
> I don?t know if it is the problem, but the code line below need be changed:
>
> subset(d.geb, d.geb$MUNICIP == 1)
>
> best wishes,
>
> miltinho astronauta
> brazil
>
> On Thu, Sep 11, 2008 at 8:12 AM, Gellrich Mario
> <mario.gellrich at env.ethz.ch>wrote:
>
>> Hi,
>>
>> I've got a question regarding distance-based neighbourhood statistics using
>> two separate spatial data sets. What I have are municipalities and buildings
>> within municipalities which both come with x- and y-coordinates. I merged
>> the two datasets row-wise and used the following code to obtain aggregated
>> values for the number of builings surrounding a municipality. The code hower
>> doesn't work appropriately. Can anybody help?
>>
>>
>> d.geb <- read.table("gebaeuderecord_selection_test.csv", header=T, sep=";")
>> d.geb[1:10,]
>>
>>     MUNICIP     NAME GEBID NUMBERGEB ABPER    LON    LAT
>> 1          0 Gebaeude  4262         1     1 681864 225868
>> 2          0 Gebaeude 14168         1     7 682190 224294
>> 3          0 Gebaeude 33346         1     5 682176 224354
>> 4          0 Gebaeude 44610         1    15 681571 225189
>> 5          0 Gebaeude 62785         1     1 679800 226040
>> 6          0 Gebaeude 72287         1     1 684619 224239
>> 7          0 Gebaeude 83044         1     8 681701 224818
>> 8          0 Gebaeude 84827         1     2 684878 230975
>> 9          0 Gebaeude 86671         1     0 685733 227247
>> 10         0 Gebaeude 88022         1     1 685691 230548
>>
>>
>> # Variable description:
>>
>> # MUNICIP:   zero for buildings; one for municipalities
>> # NAME   :   if 'Gebaeude' == building; otherwise municipality name
>> # GEBID:     ID of building; -99 otherwise
>> # NUMBERGEB: number of buildings - one for each building-record; set to
>> zero if record represents municipality
>> # ABWOW:     number of flats in a building
>>
>>
>> ### Creates neighbourhood list and should provide aggregates values within
>> a distance of 1 kilometer from a municipality for the variables NUMBERGEB or
>> ABWOW
>>
>> library(spdep)
>> geb.nb2         <- dnearneigh(as.matrix(d.geb[,6:7]), 0, 1, longlat=TRUE)
>> d.geb$SUMGEB    <- unlist(lapply(geb.nb2, function(x) ifelse(any(x==0), 0,
>> sum(d.geb$ABPER[x]))))
>>
>> subset(d.geb, MUNICIP == 1)
>>
>>
>> Best regards,
>>
>> Mario
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Fri Sep 12 10:10:55 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Sep 2008 10:10:55 +0200 (CEST)
Subject: [R-sig-Geo] How to convert results generated by
 "filled.contour" to shapefiles?
In-Reply-To: <20080912042533.84539.qmail@web10710.mail.bbt.yahoo.co.jp>
References: <20080912042533.84539.qmail@web10710.mail.bbt.yahoo.co.jp>
Message-ID: <Pine.LNX.4.64.0809120950460.10895@reclus.nhh.no>

On Fri, 12 Sep 2008, Hisaji ONO wrote:

> Hello.
>
> Currently I have developed geo-spatial mining tool using
> R with spdep, spgwr and other packages as
> OpenJUMP(http://www.openjump.org)'s plug-ins.
>
> I've already implemented contouring function using
> contourlines function.
>
> I'd like to fill colours between levels of contours.
>
> So does anyone try to convert results generated by
> "filled.contour" to shapefiles?

The filled.contour() is a different kind of function, essentially doing 
almost everything in C, and passing nothing back. So I think the only 
alternative is to build polygons from the contourLines() output by 
intersecting with a bounding box, and then finding out which polygon 
boundaries are the ones needed and which attribute interval should be 
associated with them.

My feeling would be that this kind of computational geometry might best be 
done outside R, though a lot can now be done with functions in spatstat 
and gpclib/PBSmapping. Alternatively, look at src/main/plot3d.c and check 
how the internals build their polygons. Returning them is hard - for 
contourLines I worked with Paul Murrell to expose the geometry in the way 
that it is now done - perhaps the same could be applied to 
filled.contours()?

>
> Could you share the knowledge?
>
>
> Regards.
>
> P.S.
>
>  I have received "Applied Spatial Data Analysis with R
> (Use R) " from Amazon Japan.
>
> It's very nice and useful book. Thanks.

Thanks! It's good to hear that copies have started arriving. We (the 
authors) would be grateful if anyone can tell us (preferably off-list!) of 
things that are wrong, so that we can put them in the errata on the 
website.

Best wishes,

Roger

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From h.wickham at gmail.com  Fri Sep 12 14:50:40 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 12 Sep 2008 07:50:40 -0500
Subject: [R-sig-Geo] How to convert results generated by
	"filled.contour" to shapefiles?
In-Reply-To: <Pine.LNX.4.64.0809120950460.10895@reclus.nhh.no>
References: <20080912042533.84539.qmail@web10710.mail.bbt.yahoo.co.jp>
	<Pine.LNX.4.64.0809120950460.10895@reclus.nhh.no>
Message-ID: <f8e6ff050809120550t7c6b4e55qbb25a63e15fab63c@mail.gmail.com>

> The filled.contour() is a different kind of function, essentially doing
> almost everything in C, and passing nothing back. So I think the only
> alternative is to build polygons from the contourLines() output by
> intersecting with a bounding box, and then finding out which polygon
> boundaries are the ones needed and which attribute interval should be
> associated with them.
>
> My feeling would be that this kind of computational geometry might best be
> done outside R, though a lot can now be done with functions in spatstat and
> gpclib/PBSmapping. Alternatively, look at src/main/plot3d.c and check how
> the internals build their polygons. Returning them is hard - for
> contourLines I worked with Paul Murrell to expose the geometry in the way
> that it is now done - perhaps the same could be applied to
> filled.contours()?

A while back I talked to Ross Ihaka about doing the same thing for
filled.contours - and the result of our discussion was that you can
actually work them out from the output of contourLines.  Unfortunately
I seem to have lost my notes about exactly what you need to do, but I
think basically you need to find the incomplete polygons (i.e.
contours that meet edges) and complete them by intersecting them with
the rectangular bounding box of the plot.

Hadley


-- 
http://had.co.nz/



From Roger.Bivand at nhh.no  Fri Sep 12 18:10:40 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 12 Sep 2008 18:10:40 +0200 (CEST)
Subject: [R-sig-Geo] How to convert results generated by
 "filled.contour" to shapefiles?
In-Reply-To: <f8e6ff050809120550t7c6b4e55qbb25a63e15fab63c@mail.gmail.com>
References: <20080912042533.84539.qmail@web10710.mail.bbt.yahoo.co.jp> 
	<Pine.LNX.4.64.0809120950460.10895@reclus.nhh.no>
	<f8e6ff050809120550t7c6b4e55qbb25a63e15fab63c@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809121806560.12825@reclus.nhh.no>

On Fri, 12 Sep 2008, hadley wickham wrote:

>> The filled.contour() is a different kind of function, essentially doing
>> almost everything in C, and passing nothing back. So I think the only
>> alternative is to build polygons from the contourLines() output by
>> intersecting with a bounding box, and then finding out which polygon
>> boundaries are the ones needed and which attribute interval should be
>> associated with them.
>>
>> My feeling would be that this kind of computational geometry might best be
>> done outside R, though a lot can now be done with functions in spatstat and
>> gpclib/PBSmapping. Alternatively, look at src/main/plot3d.c and check how
>> the internals build their polygons. Returning them is hard - for
>> contourLines I worked with Paul Murrell to expose the geometry in the way
>> that it is now done - perhaps the same could be applied to
>> filled.contours()?
>
> A while back I talked to Ross Ihaka about doing the same thing for
> filled.contours - and the result of our discussion was that you can
> actually work them out from the output of contourLines.  Unfortunately
> I seem to have lost my notes about exactly what you need to do, but I
> think basically you need to find the incomplete polygons (i.e.
> contours that meet edges) and complete them by intersecting them with
> the rectangular bounding box of the plot.

Thanks, the internals of plot3d.c are a bit forbidding, and there is an 
ominous FIXME suggesting that the contouring code ought to be factored out 
and hasn't yet been. So doing the computational geometry on the contour 
lines and a bounding box is the best offer for now.

Roger

>
> Hadley
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From h.wickham at gmail.com  Sun Sep 14 17:08:45 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 14 Sep 2008 10:08:45 -0500
Subject: [R-sig-Geo] unionSpatialPolygons - single polygon instead of
	multipart polygon
Message-ID: <f8e6ff050809140808t57037eeby6707842c9143248d@mail.gmail.com>

Hi All,

I'm trying to figure out exactly what output unionSpatialPolygons
gives me - it looks like it merges my singleton polygons into
multi-polygons (see output of str below), but what I really want is
just a single singleton polygon, containing the boundary of the
unioned areas.  How can I get that?

> str(unioned[4]@polygons[[1]])
Formal class 'Polygons' [package "sp"] with 5 slots
  ..@ Polygons :List of 3
  .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
  .. .. .. ..@ labpt  : num [1:2] -99.6  28.6
  .. .. .. ..@ area   : num 0.063
  .. .. .. ..@ hole   : logi FALSE
  .. .. .. ..@ ringDir: int 1
  .. .. .. ..@ coords : num [1:151, 1:2] -99.8 -99.7 -99.7 -99.6 -99.6 ...
  .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
  .. .. .. ..@ labpt  : num [1:2] -98.2  28.5
  .. .. .. ..@ area   : num 0.112
  .. .. .. ..@ hole   : logi FALSE
  .. .. .. ..@ ringDir: int 1
  .. .. .. ..@ coords : num [1:131, 1:2] -98 -98 -98 -98 -98 ...
  .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
  .. .. .. ..@ labpt  : num [1:2] -96.7  28.5
  .. .. .. ..@ area   : num 0.0558
  .. .. .. ..@ hole   : logi FALSE
  .. .. .. ..@ ringDir: int 1
  .. .. .. ..@ coords : num [1:190, 1:2] -96.8 -96.8 -96.8 -96.8 -96.8 ...
  ..@ plotOrder: int [1:3] 2 1 3
  ..@ labpt    : num [1:2] -98.2  28.5
  ..@ ID       : chr "007"
  ..@ area     : num 0.231


I've included my full code below to give more of a flavour of what I'm
trying to do - simplify the boundaries of TX counties and then get the
data into a regular R data frame.  This doesn't work at the moment,
because I'm only getting the first part of the multipart polygons.

counties <- readShapeSpatial("tx-counties")

attr <- as.data.frame(counties)
names(attr) <- tolower(names(attr))
attr <- attr[c("fips", "name", "area", "perimeter")]

polys <- split(row.names(attr), attr$fips)

cp <- polygons(counties)
unioned <- unionSpatialPolygons(cp, invert(polys))

coords <- function(x) x at polygons[[1]]@Polygons[[1]]@coords
ccoords <- lapply(seq_len(254), function(i) coords(unioned[i]))

id <- function(x) x at polygons[[1]]@ID
names(ccoords) <-  sapply(seq_len(254), function(i) id(unioned[i]))

cdf <- do.call("rbind", lapply(seq_along(ccoords), function(i) {
  df <- as.data.frame(ccoords[[i]])
  names(df) <- c("x", "y")
  df <- as.data.frame(dp(df, 0.01))
  df$id <- names(ccoords)[i]
  df
}))


Hadley

-- 
http://had.co.nz/



From hilton at meteo.psu.edu  Sun Sep 14 18:45:54 2008
From: hilton at meteo.psu.edu (Timothy W. Hilton)
Date: Sun, 14 Sep 2008 12:45:54 -0400
Subject: [R-sig-Geo] gstat::variogram - distance calculation is incorrect
Message-ID: <20080914164554.GA3353@abl.met.psu.edu>

Hello,

I am trying to use 'variogram' from the gstat package to compute an empirical semivariogram for a dataset that spans the North American continent.  I have been unable to get gstat to calculate the great circle distances correctly.  For example, in the example below, the first two lines of vg.foo suggest to me that the calculated distance between foo[1,] and foo[2,] is 4804, and between foo[1,] and foo[3,] is 3047.  I assume those units are km.  

spDistsN1, however tells me that those distances should be 3115 km and 1907 km, respectively.

Could someone suggest to me my error, or how I might use calculate an emprical variogram with correct distances?  I do not think UTM coordinates are an option for me, as my data span approximately 5000 km.

Many thanks,
Tim

=====

code to illustrate the problem:

library(sp)
library(rgdal)
library(gstat)

foo <-
structure(list(z = c(-1.95824831109744, -1.9158901643563, 4.22211761150161, 
3.23356929459598, 1.12038389231868, 0.34613850821113, 1.12589932643631, 
23.517912251617, 3.0519158690268, 3.20261431141517, -2.10947106854739
), lon = c(-125.29228, -82.1556, -98.524722, -99.948333, -104.691741, 
-79.420833, -105.100533, -88.291867, -72.171478, -121.556944, 
-89.34765), lat = c(49.87217, 48.2167, 55.905833, 56.635833, 
53.916264, 39.063333, 48.307883, 40.0061, 42.537756, 44.448889, 
46.242017)), .Names = c("z", "lon", "lat"), row.names = c(NA, 
-11L), class = "data.frame")

coordinates(foo) <- ~lon+lat

proj4string(foo) <- CRS('+proj=longlat')

vg.foo <- variogram(z~1, foo, cloud=TRUE, cutoff=1e10)

cat('==========\nvariogram:\n')
print(head(vg.foo))

cat('==========\nspDistsN1 Distances:\n')
print(spDistsN1(coordinates(foo), coordinates(foo)[1,], longlat=T))



From Roger.Bivand at nhh.no  Sun Sep 14 18:48:54 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 14 Sep 2008 18:48:54 +0200 (CEST)
Subject: [R-sig-Geo] unionSpatialPolygons - single polygon instead of
 multipart polygon
In-Reply-To: <f8e6ff050809140808t57037eeby6707842c9143248d@mail.gmail.com>
References: <f8e6ff050809140808t57037eeby6707842c9143248d@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809141831540.15921@reclus.nhh.no>

On Sun, 14 Sep 2008, hadley wickham wrote:

> Hi All,
>
> I'm trying to figure out exactly what output unionSpatialPolygons
> gives me - it looks like it merges my singleton polygons into
> multi-polygons (see output of str below), but what I really want is
> just a single singleton polygon, containing the boundary of the
> unioned areas.  How can I get that?

By defining the IDs= argument (as you do) for the output Polygons objects. 
Could you make your test file available - there may be slivers there 
making it look as though county boundaries are identical, but are 
separated by a river? See:

> nc1 <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
  proj4string=CRS("+proj=longlat +datum=NAD27"))
lps <- coordinates(nc1)
ID <- cut(lps[,1], quantile(lps[,1]), include.lowest=TRUE)
reg4 <- unionSpatialPolygons(nc1, ID)
length(slot(reg4, "polygons"))
# [1] 4
sapply(slot(reg4, "polygons"), function(x) length(slot(x, "Polygons")))
# [1] 1 1 1 6

where the islands end up as separate Polygon objects in the 4th Polygons 
object, because they don't share a boundary. If your dataset has slivers, 
that might be avoided using the threshold argument, but I wouldn't 
describe that as convenient, really.

Hope this helps,

Roger

>
>> str(unioned[4]@polygons[[1]])
> Formal class 'Polygons' [package "sp"] with 5 slots
>  ..@ Polygons :List of 3
>  .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>  .. .. .. ..@ labpt  : num [1:2] -99.6  28.6
>  .. .. .. ..@ area   : num 0.063
>  .. .. .. ..@ hole   : logi FALSE
>  .. .. .. ..@ ringDir: int 1
>  .. .. .. ..@ coords : num [1:151, 1:2] -99.8 -99.7 -99.7 -99.6 -99.6 ...
>  .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>  .. .. .. ..@ labpt  : num [1:2] -98.2  28.5
>  .. .. .. ..@ area   : num 0.112
>  .. .. .. ..@ hole   : logi FALSE
>  .. .. .. ..@ ringDir: int 1
>  .. .. .. ..@ coords : num [1:131, 1:2] -98 -98 -98 -98 -98 ...
>  .. ..$ :Formal class 'Polygon' [package "sp"] with 5 slots
>  .. .. .. ..@ labpt  : num [1:2] -96.7  28.5
>  .. .. .. ..@ area   : num 0.0558
>  .. .. .. ..@ hole   : logi FALSE
>  .. .. .. ..@ ringDir: int 1
>  .. .. .. ..@ coords : num [1:190, 1:2] -96.8 -96.8 -96.8 -96.8 -96.8 ...
>  ..@ plotOrder: int [1:3] 2 1 3
>  ..@ labpt    : num [1:2] -98.2  28.5
>  ..@ ID       : chr "007"
>  ..@ area     : num 0.231
>
>
> I've included my full code below to give more of a flavour of what I'm
> trying to do - simplify the boundaries of TX counties and then get the
> data into a regular R data frame.  This doesn't work at the moment,
> because I'm only getting the first part of the multipart polygons.
>
> counties <- readShapeSpatial("tx-counties")
>
> attr <- as.data.frame(counties)
> names(attr) <- tolower(names(attr))
> attr <- attr[c("fips", "name", "area", "perimeter")]
>
> polys <- split(row.names(attr), attr$fips)
>
> cp <- polygons(counties)
> unioned <- unionSpatialPolygons(cp, invert(polys))
>
> coords <- function(x) x at polygons[[1]]@Polygons[[1]]@coords
> ccoords <- lapply(seq_len(254), function(i) coords(unioned[i]))
>
> id <- function(x) x at polygons[[1]]@ID
> names(ccoords) <-  sapply(seq_len(254), function(i) id(unioned[i]))
>
> cdf <- do.call("rbind", lapply(seq_along(ccoords), function(i) {
>  df <- as.data.frame(ccoords[[i]])
>  names(df) <- c("x", "y")
>  df <- as.data.frame(dp(df, 0.01))
>  df$id <- names(ccoords)[i]
>  df
> }))
>
>
> Hadley
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From h.wickham at gmail.com  Sun Sep 14 19:22:35 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 14 Sep 2008 12:22:35 -0500
Subject: [R-sig-Geo] unionSpatialPolygons - single polygon instead of
	multipart polygon
In-Reply-To: <Pine.LNX.4.64.0809141831540.15921@reclus.nhh.no>
References: <f8e6ff050809140808t57037eeby6707842c9143248d@mail.gmail.com>
	<Pine.LNX.4.64.0809141831540.15921@reclus.nhh.no>
Message-ID: <f8e6ff050809141022j54d063c8h19e49db83282149b@mail.gmail.com>

On Sun, Sep 14, 2008 at 11:48 AM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Sun, 14 Sep 2008, hadley wickham wrote:
>
>> Hi All,
>>
>> I'm trying to figure out exactly what output unionSpatialPolygons
>> gives me - it looks like it merges my singleton polygons into
>> multi-polygons (see output of str below), but what I really want is
>> just a single singleton polygon, containing the boundary of the
>> unioned areas.  How can I get that?
>
> By defining the IDs= argument (as you do) for the output Polygons objects.
> Could you make your test file available - there may be slivers there making
> it look as though county boundaries are identical, but are separated by a
> river? See:

Ooops, I just doubled checked the input ids argument and it was in the
wrong order because the IDs were getting sorted alphabetically rather
than numerically - an as.numeric fixed the problem.  Thanks for your
help!

Hadley

-- 
http://had.co.nz/



From edzer.pebesma at uni-muenster.de  Sun Sep 14 21:23:11 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 14 Sep 2008 21:23:11 +0200
Subject: [R-sig-Geo] gstat::variogram - distance calculation is incorrect
In-Reply-To: <20080914164554.GA3353@abl.met.psu.edu>
References: <20080914164554.GA3353@abl.met.psu.edu>
Message-ID: <48CD649F.7070103@uni-muenster.de>

Thanks for the bug report; indeed, distance computation for longlat data 
variograms went wrong so far. I just uploaded a new gstat version to 
/incoming on CRAN that seems to repair this bug.

Next thing I'm not 100% sure of is the direction selections for 
directional variograms of longlat data.

I hope you don't mind I added your code below to one of the regression 
tests in the package (unproj.R).
--
Edzer

Timothy W. Hilton wrote:
> Hello,
>
> I am trying to use 'variogram' from the gstat package to compute an empirical semivariogram for a dataset that spans the North American continent.  I have been unable to get gstat to calculate the great circle distances correctly.  For example, in the example below, the first two lines of vg.foo suggest to me that the calculated distance between foo[1,] and foo[2,] is 4804, and between foo[1,] and foo[3,] is 3047.  I assume those units are km.  
>
> spDistsN1, however tells me that those distances should be 3115 km and 1907 km, respectively.
>
> Could someone suggest to me my error, or how I might use calculate an emprical variogram with correct distances?  I do not think UTM coordinates are an option for me, as my data span approximately 5000 km.
>
> Many thanks,
> Tim
>
> =====
>
> code to illustrate the problem:
>
> library(sp)
> library(rgdal)
> library(gstat)
>
> foo <-
> structure(list(z = c(-1.95824831109744, -1.9158901643563, 4.22211761150161, 
> 3.23356929459598, 1.12038389231868, 0.34613850821113, 1.12589932643631, 
> 23.517912251617, 3.0519158690268, 3.20261431141517, -2.10947106854739
> ), lon = c(-125.29228, -82.1556, -98.524722, -99.948333, -104.691741, 
> -79.420833, -105.100533, -88.291867, -72.171478, -121.556944, 
> -89.34765), lat = c(49.87217, 48.2167, 55.905833, 56.635833, 
> 53.916264, 39.063333, 48.307883, 40.0061, 42.537756, 44.448889, 
> 46.242017)), .Names = c("z", "lon", "lat"), row.names = c(NA, 
> -11L), class = "data.frame")
>
> coordinates(foo) <- ~lon+lat
>
> proj4string(foo) <- CRS('+proj=longlat')
>
> vg.foo <- variogram(z~1, foo, cloud=TRUE, cutoff=1e10)
>
> cat('==========\nvariogram:\n')
> print(head(vg.foo))
>
> cat('==========\nspDistsN1 Distances:\n')
> print(spDistsN1(coordinates(foo), coordinates(foo)[1,], longlat=T))
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From edzer.pebesma at uni-muenster.de  Tue Sep 16 08:18:57 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 16 Sep 2008 08:18:57 +0200
Subject: [R-sig-Geo] AI-GEOSTATS: About the sequential simulation in
	gstat!
In-Reply-To: <30306872.369201221525730258.JavaMail.coremail@app141.163.com>
References: <30306872.369201221525730258.JavaMail.coremail@app141.163.com>
Message-ID: <48CF4FD1.3040301@uni-muenster.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080916/b74d1bc4/attachment.pl>

From Friderike.Oehler at fao.org  Tue Sep 16 13:34:11 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Tue, 16 Sep 2008 13:34:11 +0200
Subject: [R-sig-Geo] R-SAGA-GRASS-ArcGIS strengths/weaknesses
Message-ID: <1A28265B00AA7E4085BB761555D3FCE8033C8B1F@hqagex02.fao.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080916/9793faa6/attachment.pl>

From r.m.krug at gmail.com  Tue Sep 16 16:56:23 2008
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Tue, 16 Sep 2008 16:56:23 +0200
Subject: [R-sig-Geo] Problem when loading GRASS 6 raster with large integer
	values
Message-ID: <fb7c7e870809160756y59585237qc5aa3ec20837a447@mail.gmail.com>

Hi

when I try to import a raster layer from grass with large integer
values, I get wrong values in R (see below). When I change the
datatype in GRASS to double, it works.

Thanks,

Rainer



GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R > r.stats -c
input=tmpDispLocal
 100%
0 39798
11 831
58 78
105 38
242 1652
889 816
2205 294
2310 56
3315 1171
4935 116
7875 9
8085 67
11550 6
13010 299
24675 2
30135 425
47702 1
48510 981
103635 1255
165375 8
177797 160
177870 6
379995 324
606375 8
662970 292
1416345 445
2260125 41
* 50661
[Raster MASK present]


BUT:


>     seeds <- readRAST6(
+                        "tmpDispLocal",
+                        ignore.stderr=!Debug
+                        )
Creating BIL support files...
Header File =
/home/rkrug/Documents/Projects/AlienSpread/R/../grass/simulation/.tmp/ecolmod/tmpDispLocal.hdr
World File =
/home/rkrug/Documents/Projects/AlienSpread/R/../grass/simulation/.tmp/ecolmod/tmpDispLocal.wld
Exporting raster as integer values (bytes=2)
Using the current region settings...
north=6247000.000000
south=6195000.000000
east=270200.000000
west=251000.000000
r=520
c=192

> table(seeds[[1]])

-31233 -27437 -25447 -18811 -18738 -17834 -17026 -13221      0     11     58
     8   1255    445    160      6      1    981    324  39798    831     78
   105    242    889   2205   2310   3315   4935   7610   7875   8085  11550
    38   1652    816    294     56   1171    116    292      9     67      6
 13010  16551  24675  30135  31901
   299      8      2    425     41
>


Additional info:

GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R > r.info map=tmpDispLocal
 +----------------------------------------------------------------------------+
 | Layer:    tmpDispLocal                   Date: Tue Sep 16 16:45:35 2008    |
 | Mapset:   simulation                     Login of Creator: rkrug           |
 | Location: grass                                                            |
 | DataBase: /home/rkrug/Documents/Projects/AlienSpread/R/..                  |
 | Title:     ( tmpDispLocal )                                                |
 | Timestamp: none                                                            |
 |----------------------------------------------------------------------------|
 |                                                                            |
 |   Type of Map:  raster               Number of Categories: 2260125         |
 |   Data Type:    CELL                                                       |
 |   Rows:         520                                                        |
 |   Columns:      192                                                        |
 |   Total Cells:  99840                                                      |
 |        Projection: UTM (zone -34)                                          |
 |            N:    6247000    S:    6195000   Res:   100                     |
 |            E:     270200    W:     251000   Res:   100                     |
 |   Range of data:    min = 0  max = 2260125                                 |
 |                                                                            |
 |   Data Description:                                                        |
 |    generated by r.mapcalc                                                  |
 |                                                                            |
 |   Comments:                                                                |
 |    round(tmpDisp * 0.300000)                                               |
 |                                                                            |
 +----------------------------------------------------------------------------+

[Raster MASK present]
GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R >

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



From a.ghisla at studenti.uninsubria.it  Tue Sep 16 17:00:02 2008
From: a.ghisla at studenti.uninsubria.it (Anne Ghisla)
Date: Tue, 16 Sep 2008 17:00:02 +0200
Subject: [R-sig-Geo] R-SAGA-GRASS-ArcGIS strengths/weaknesses
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE8033C8B1F@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B1F@hqagex02.fao.org>
Message-ID: <1221577202.6848.7.camel@galadriel>

On Tue, 2008-09-16 at 13:34 +0200, Oehler, Friderike (AGPP) wrote:
> If a non-experienced person wanted to decide for one program in which to
> invest time and if one was to highlight the strengths and weaknesses of R,
> SAGA, GRASS and ArcGIS in comparison to each other in a simplistic way ... 
[...]
> 
> Of course, I am aware that these programs -particularly R vs. GIS-  serve
> different purposes, but supposing that you don't know any of these and you
> wanted to have a starting point to select your tool for basic spatial data
> analysis and mapping, would this table help?

Hello Friderike, 

I would suggest to add to the comparison table an item about support
(wiki, mailing lists, developers and users community), and consider also
how do some systems (R, GRASS and SAGA) can cooperate so that users can
run complex analysis without stepping to one program to another.

On R wiki there is a starting page about this kind of comparison:
http://wiki.r-project.org/rwiki/doku.php?id=tips:spatial-data:when_to_use

HTH,

Anne Ghisla
Student at Insubria University, Varese

> 
> Any comment/suggestion is most welcome,
> many thanks,
> Friderike
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080916/380a9fdb/attachment.bin>

From Roger.Bivand at nhh.no  Tue Sep 16 18:38:12 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 16 Sep 2008 18:38:12 +0200 (CEST)
Subject: [R-sig-Geo] Problem when loading GRASS 6 raster with large
 integer values
In-Reply-To: <fb7c7e870809160756y59585237qc5aa3ec20837a447@mail.gmail.com>
References: <fb7c7e870809160756y59585237qc5aa3ec20837a447@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809161833070.23125@reclus.nhh.no>

On Tue, 16 Sep 2008, Rainer M Krug wrote:

> Hi
>
> when I try to import a raster layer from grass with large integer
> values, I get wrong values in R (see below). When I change the
> datatype in GRASS to double, it works.

The underlying r.out.bin exports CELL rasters as short integers using two 
bytes only, and the 6.3 version of the module has no option or flag for 
setting this differently. So conversion to DCELL (or FCELL) is the only 
fix.

Roger

>
> Thanks,
>
> Rainer
>
>
>
> GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R > r.stats -c
> input=tmpDispLocal
> 100%
> 0 39798
> 11 831
> 58 78
> 105 38
> 242 1652
> 889 816
> 2205 294
> 2310 56
> 3315 1171
> 4935 116
> 7875 9
> 8085 67
> 11550 6
> 13010 299
> 24675 2
> 30135 425
> 47702 1
> 48510 981
> 103635 1255
> 165375 8
> 177797 160
> 177870 6
> 379995 324
> 606375 8
> 662970 292
> 1416345 445
> 2260125 41
> * 50661
> [Raster MASK present]
>
>
> BUT:
>
>
>>     seeds <- readRAST6(
> +                        "tmpDispLocal",
> +                        ignore.stderr=!Debug
> +                        )
> Creating BIL support files...
> Header File =
> /home/rkrug/Documents/Projects/AlienSpread/R/../grass/simulation/.tmp/ecolmod/tmpDispLocal.hdr
> World File =
> /home/rkrug/Documents/Projects/AlienSpread/R/../grass/simulation/.tmp/ecolmod/tmpDispLocal.wld
> Exporting raster as integer values (bytes=2)
> Using the current region settings...
> north=6247000.000000
> south=6195000.000000
> east=270200.000000
> west=251000.000000
> r=520
> c=192
>
>> table(seeds[[1]])
>
> -31233 -27437 -25447 -18811 -18738 -17834 -17026 -13221      0     11     58
>     8   1255    445    160      6      1    981    324  39798    831     78
>   105    242    889   2205   2310   3315   4935   7610   7875   8085  11550
>    38   1652    816    294     56   1171    116    292      9     67      6
> 13010  16551  24675  30135  31901
>   299      8      2    425     41
>>
>
>
> Additional info:
>
> GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R > r.info map=tmpDispLocal
> +----------------------------------------------------------------------------+
> | Layer:    tmpDispLocal                   Date: Tue Sep 16 16:45:35 2008    |
> | Mapset:   simulation                     Login of Creator: rkrug           |
> | Location: grass                                                            |
> | DataBase: /home/rkrug/Documents/Projects/AlienSpread/R/..                  |
> | Title:     ( tmpDispLocal )                                                |
> | Timestamp: none                                                            |
> |----------------------------------------------------------------------------|
> |                                                                            |
> |   Type of Map:  raster               Number of Categories: 2260125         |
> |   Data Type:    CELL                                                       |
> |   Rows:         520                                                        |
> |   Columns:      192                                                        |
> |   Total Cells:  99840                                                      |
> |        Projection: UTM (zone -34)                                          |
> |            N:    6247000    S:    6195000   Res:   100                     |
> |            E:     270200    W:     251000   Res:   100                     |
> |   Range of data:    min = 0  max = 2260125                                 |
> |                                                                            |
> |   Data Description:                                                        |
> |    generated by r.mapcalc                                                  |
> |                                                                            |
> |   Comments:                                                                |
> |    round(tmpDisp * 0.300000)                                               |
> |                                                                            |
> +----------------------------------------------------------------------------+
>
> [Raster MASK present]
> GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R >
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From r.m.krug at gmail.com  Tue Sep 16 18:45:03 2008
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Tue, 16 Sep 2008 18:45:03 +0200
Subject: [R-sig-Geo] Problem when loading GRASS 6 raster with large
	integer values
In-Reply-To: <Pine.LNX.4.64.0809161833070.23125@reclus.nhh.no>
References: <fb7c7e870809160756y59585237qc5aa3ec20837a447@mail.gmail.com>
	<Pine.LNX.4.64.0809161833070.23125@reclus.nhh.no>
Message-ID: <fb7c7e870809160945x35182628s82337c550499d543@mail.gmail.com>

On Tue, Sep 16, 2008 at 6:38 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:
> On Tue, 16 Sep 2008, Rainer M Krug wrote:
>
>> Hi
>>
>> when I try to import a raster layer from grass with large integer
>> values, I get wrong values in R (see below). When I change the
>> datatype in GRASS to double, it works.
>
> The underlying r.out.bin exports CELL rasters as short integers using two
> bytes only, and the 6.3 version of the module has no option or flag for
> setting this differently. So conversion to DCELL (or FCELL) is the only fix.

Thanks for the clarification. I will see what can be done from the GRASS side.

Rainer

>
> Roger
>
>>
>> Thanks,
>>
>> Rainer
>>
>>
>>
>> GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R > r.stats -c
>> input=tmpDispLocal
>> 100%
>> 0 39798
>> 11 831
>> 58 78
>> 105 38
>> 242 1652
>> 889 816
>> 2205 294
>> 2310 56
>> 3315 1171
>> 4935 116
>> 7875 9
>> 8085 67
>> 11550 6
>> 13010 299
>> 24675 2
>> 30135 425
>> 47702 1
>> 48510 981
>> 103635 1255
>> 165375 8
>> 177797 160
>> 177870 6
>> 379995 324
>> 606375 8
>> 662970 292
>> 1416345 445
>> 2260125 41
>> * 50661
>> [Raster MASK present]
>>
>>
>> BUT:
>>
>>
>>>    seeds <- readRAST6(
>>
>> +                        "tmpDispLocal",
>> +                        ignore.stderr=!Debug
>> +                        )
>> Creating BIL support files...
>> Header File =
>>
>> /home/rkrug/Documents/Projects/AlienSpread/R/../grass/simulation/.tmp/ecolmod/tmpDispLocal.hdr
>> World File =
>>
>> /home/rkrug/Documents/Projects/AlienSpread/R/../grass/simulation/.tmp/ecolmod/tmpDispLocal.wld
>> Exporting raster as integer values (bytes=2)
>> Using the current region settings...
>> north=6247000.000000
>> south=6195000.000000
>> east=270200.000000
>> west=251000.000000
>> r=520
>> c=192
>>
>>> table(seeds[[1]])
>>
>> -31233 -27437 -25447 -18811 -18738 -17834 -17026 -13221      0     11
>> 58
>>    8   1255    445    160      6      1    981    324  39798    831     78
>>  105    242    889   2205   2310   3315   4935   7610   7875   8085  11550
>>   38   1652    816    294     56   1171    116    292      9     67      6
>> 13010  16551  24675  30135  31901
>>  299      8      2    425     41
>>>
>>
>>
>> Additional info:
>>
>> GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R > r.info
>> map=tmpDispLocal
>>
>> +----------------------------------------------------------------------------+
>> | Layer:    tmpDispLocal                   Date: Tue Sep 16 16:45:35 2008
>>    |
>> | Mapset:   simulation                     Login of Creator: rkrug
>>   |
>> | Location: grass
>>    |
>> | DataBase: /home/rkrug/Documents/Projects/AlienSpread/R/..
>>    |
>> | Title:     ( tmpDispLocal )
>>    |
>> | Timestamp: none
>>    |
>>
>> |----------------------------------------------------------------------------|
>> |
>>    |
>> |   Type of Map:  raster               Number of Categories: 2260125
>>   |
>> |   Data Type:    CELL
>>   |
>> |   Rows:         520
>>    |
>> |   Columns:      192
>>    |
>> |   Total Cells:  99840
>>    |
>> |        Projection: UTM (zone -34)
>>    |
>> |            N:    6247000    S:    6195000   Res:   100
>>   |
>> |            E:     270200    W:     251000   Res:   100
>>   |
>> |   Range of data:    min = 0  max = 2260125
>>   |
>> |
>>    |
>> |   Data Description:
>>    |
>> |    generated by r.mapcalc
>>    |
>> |
>>    |
>> |   Comments:
>>    |
>> |    round(tmpDisp * 0.300000)
>>   |
>> |
>>    |
>>
>> +----------------------------------------------------------------------------+
>>
>> [Raster MASK present]
>> GRASS 6.3.0 (grass):~/Documents/Projects/AlienSpread/R >
>>
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>



-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation
Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Faculty of Science
Natural Sciences Building
Private Bag X1
University of Stellenbosch
Matieland 7602
South Africa



From oliveira.nf at gmail.com  Tue Sep 16 22:34:17 2008
From: oliveira.nf at gmail.com (Nelson Oliveira)
Date: Tue, 16 Sep 2008 17:34:17 -0300
Subject: [R-sig-Geo] coff standard erros in ggwr
Message-ID: <4b86a35a0809161334r148c4af8s3674d1fe2e03b372@mail.gmail.com>

I'm using the function ggwr (for the first time). I want to test the
significance of the coeff. estimates (global), but I can't find their
standard errors.  I used the following code:
xx<-SpatialPointsDataFrame(coords=coord,data=en1)

bw <- ggwr.sel(numhomicidio~offset(log(popmedia))+I12 + I4 + I5 +
I10,data=xx,family=quasipoisson())

ed_quasi<-ggwr(numhomicidio~offset(log(popmedia))+I12 + I4 + I5 + I10,
data=xx,family=quasipoisson(),bandwidth=bw)

Thanks
Nelson



From milton.ruser at gmail.com  Wed Sep 17 04:09:07 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Wed, 17 Sep 2008 00:09:07 -0200
Subject: [R-sig-Geo] R-SAGA-GRASS-ArcGIS strengths/weaknesses
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE8033C8B1F@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B1F@hqagex02.fao.org>
Message-ID: <3aaf1a030809161909m6fa06e7en1f8afb71b88c362f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080917/45fa14c4/attachment.pl>

From yong.li at unimelb.edu.au  Wed Sep 17 05:05:29 2008
From: yong.li at unimelb.edu.au (Yong Li)
Date: Wed, 17 Sep 2008 13:05:29 +1000
Subject: [R-sig-Geo] how to load sp,
 gstate or other packages into R using R Dcom for standardalone
 applications?
In-Reply-To: <mailman.11.1221559202.19398.r-sig-geo@stat.math.ethz.ch>
Message-ID: <86DBA0678E017341B449A62F258E2956154908@IS-EX-BEV3.unimelb.edu.au>

Hi ALL,

I had a problem in using r Dcom to develop applications for applying
geostatistics using gstat. I transferred all code, which can run in R
successfully, into VB, but I could not make them running. However, data
management and simple graphing can be done without any problem.
Any help and tips to help me through would be highly appreciated.

Yong



From Roger.Bivand at nhh.no  Wed Sep 17 14:07:41 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Sep 2008 14:07:41 +0200 (CEST)
Subject: [R-sig-Geo] coff standard erros in ggwr
In-Reply-To: <4b86a35a0809161334r148c4af8s3674d1fe2e03b372@mail.gmail.com>
References: <4b86a35a0809161334r148c4af8s3674d1fe2e03b372@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809171357220.26182@reclus.nhh.no>

On Tue, 16 Sep 2008, Nelson Oliveira wrote:

> I'm using the function ggwr (for the first time). I want to test the
> significance of the coeff. estimates (global), but I can't find their
> standard errors.  I used the following code:
> xx<-SpatialPointsDataFrame(coords=coord,data=en1)
>
> bw <- ggwr.sel(numhomicidio~offset(log(popmedia))+I12 + I4 + I5 +
> I10,data=xx,family=quasipoisson())
>
> ed_quasi<-ggwr(numhomicidio~offset(log(popmedia))+I12 + I4 + I5 + I10,
> data=xx,family=quasipoisson(),bandwidth=bw)

The local coefficient standard error estimates are not calculated or 
returned by ggwr(). They could in principle be computed, but would you 
trust them? Since gwr() and ggwr() are seriously affected by induced 
collinearity, I doubt whether inference is where one wants to go. Please 
do try:

pairs(as(ed_quasi$SDF, "data.frame")[, 2:5])

for a quick check (Wheeler & Tiefelsdorf, 2005).

Roger

>
> Thanks
> Nelson
-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Sep 17 14:09:36 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 17 Sep 2008 14:09:36 +0200 (CEST)
Subject: [R-sig-Geo] how to load sp,
 gstate or other packages into R using R Dcom for standardalone
 applications?
In-Reply-To: <86DBA0678E017341B449A62F258E2956154908@IS-EX-BEV3.unimelb.edu.au>
References: <86DBA0678E017341B449A62F258E2956154908@IS-EX-BEV3.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0809171407540.26182@reclus.nhh.no>

On Wed, 17 Sep 2008, Yong Li wrote:

> Hi ALL,
>
> I had a problem in using r Dcom to develop applications for applying
> geostatistics using gstat. I transferred all code, which can run in R
> successfully, into VB, but I could not make them running. However, data
> management and simple graphing can be done without any problem.
> Any help and tips to help me through would be highly appreciated.

My guess would be that your problem is in the running R instance not 
finding the R_LIBS library directory with the packages in it. If it isn't 
that, then we'll need more details to resolve this.

Roger

>
> Yong
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From francois.jouvie at supelec.fr  Wed Sep 17 14:44:33 2008
From: francois.jouvie at supelec.fr (Francois JOUVIE)
Date: Wed, 17 Sep 2008 14:44:33 +0200
Subject: [R-sig-Geo] krige.cv with nfold=1
Message-ID: <616F9BD0-25EB-4363-8E84-BA93720A6911@supelec.fr>

Hello All,

I'm using for the first time the gstat command  krige.cv for cross  
validation.

Having some problems to perform with my own data, I tried with the  
data included with R which are often used in presentations (meuse data  
more precisely).
Then I tried the following commands which all perform:

 > data(meuse)
 > m<-vgm(.5,"Sph",900,0.04)
 > x<-krige.cv(log(zinc)~1,~x+y,meuse,m,nfold=5)
[using ordinary kriging]
[using ordinary kriging]
[using ordinary kriging]
[using ordinary kriging]
[using ordinary kriging]
 >

But if I want  nfold=1 (= not sub_divisions of the data ?) I get this  
(in French) :

 > x<-krige.cv(log(zinc)~1,~x+y,meuse,m,nfold=1)
Erreur dans gstat.formula(d$formula, d$data) :
   no response variable present in formula
De plus : Warning messages:
1: In min(x) : aucun argument trouv? pour min ; Inf est renvoy?
2: In max(x) : aucun argument pour max ; -Inf est renvoy?
3: In min(x) : aucun argument trouv? pour min ; Inf est renvoy?
4: In max(x) : aucun argument pour max ; -Inf est renvoy?
 >

What is happens ?

Thanks you very much if you can help me.

Francois



From edzer.pebesma at uni-muenster.de  Wed Sep 17 14:55:15 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 17 Sep 2008 14:55:15 +0200
Subject: [R-sig-Geo] krige.cv with nfold=1
In-Reply-To: <616F9BD0-25EB-4363-8E84-BA93720A6911@supelec.fr>
References: <616F9BD0-25EB-4363-8E84-BA93720A6911@supelec.fr>
Message-ID: <48D0FE33.7090502@uni-muenster.de>

n-fold cross validation splits the data in n parts, and each time holds 
one part out to compare it with predictions from the remaining part. So, 
having nfold=1 does not make sense.

I will add to the documentation that nfold should be 2 or larger.
--
Edzer

Francois JOUVIE wrote:
> Hello All,
>
> I'm using for the first time the gstat command  krige.cv for cross 
> validation.
>
> Having some problems to perform with my own data, I tried with the 
> data included with R which are often used in presentations (meuse data 
> more precisely).
> Then I tried the following commands which all perform:
>
> > data(meuse)
> > m<-vgm(.5,"Sph",900,0.04)
> > x<-krige.cv(log(zinc)~1,~x+y,meuse,m,nfold=5)
> [using ordinary kriging]
> [using ordinary kriging]
> [using ordinary kriging]
> [using ordinary kriging]
> [using ordinary kriging]
> >
>
> But if I want  nfold=1 (= not sub_divisions of the data ?) I get this 
> (in French) :
>
> > x<-krige.cv(log(zinc)~1,~x+y,meuse,m,nfold=1)
> Erreur dans gstat.formula(d$formula, d$data) :
>   no response variable present in formula
> De plus : Warning messages:
> 1: In min(x) : aucun argument trouv? pour min ; Inf est renvoy?
> 2: In max(x) : aucun argument pour max ; -Inf est renvoy?
> 3: In min(x) : aucun argument trouv? pour min ; Inf est renvoy?
> 4: In max(x) : aucun argument pour max ; -Inf est renvoy?
> >
>
> What is happens ?
>
> Thanks you very much if you can help me.
>
> Francois
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From Bjarke.Christensen at sydbank.dk  Wed Sep 17 16:59:02 2008
From: Bjarke.Christensen at sydbank.dk (Bjarke Christensen)
Date: Wed, 17 Sep 2008 16:59:02 +0200
Subject: [R-sig-Geo] coff standard erros in ggwr
In-Reply-To: <mailman.7.1221645602.19887.r-sig-geo@stat.math.ethz.ch>
Message-ID: <OF1D1DAD4D.7E41BEF8-ONC12574C7.004F1070-C12574C7.00524F45@bdpnet.dk>

>I'm using the function ggwr (for the first time). I want to test the
>significance of the coeff. estimates (global), but I can't find their
>standard errors.

I may be completely misunderstanding you, but last time I looked at GWR, it
was my impression that it was pretty much impossible to know the asymptotic
distribution of the coefficients.

>I used the following code:
>xx<-SpatialPointsDataFrame(coords=coord,data=en1)
>bw <- ggwr.sel(numhomicidio~offset(log(popmedia))+I12 + I4 + I5 +
>I10,data=xx,family=quasipoisson())
>ed_quasi<-ggwr(numhomicidio~offset(log(popmedia))+I12 + I4 + I5 + I10,
>data=xx,family=quasipoisson(),bandwidth=bw)

ed.parameters <- slot(ed_quasi$SDF, 'data')
sd(ed.parameters)

will give you the standard deviation of the estimated parameters. But, as I
said, I very much doubt that it is possible to use them for a meaningful
stationarity test.

If I am completely misunderstanding you, and you are just looking for the
standard errors of the aspatial model, then ed_quasi$lm will give you some
sort of a bastardised lm object. The following function is lifted out of
the code for summary.lm, and will give you the coefficient matrix for the
lm component of a gwr object. Alternatively, you could just estimate a glm
model with the same formula, and use all the trimmings that come with such
an object.

se.gwr <- function (object)
{
    z <- object$lm
    p <- z$rank
    Qr <- z$qr
    n <- NROW(Qr$qr)
    rdf <- n - p
    p1 <- 1:p
    rss <- sum(z$residuals^2)
    resvar <- rss/rdf
    R <- chol2inv(Qr$qr[p1, p1, drop = FALSE])
    se <- sqrt(diag(R) * resvar)
    est <- z$coefficients[Qr$pivot[p1]]
    tval <- est/se
    ans <- cbind(est, se, tval, 2 * pt(abs(tval),
        rdf, lower.tail = FALSE))
    rownames(ans) <- names(z$coefficients)
    colnames(ans) <- c("Estimate", "Std. Error", "t value", "Pr(>|t|)")
    printCoefmat(ans)
    invisible(ans)
}

se.gwr(ed_quasi)

Bjarke Christensen



From francois.jouvie at supelec.fr  Wed Sep 17 17:16:45 2008
From: francois.jouvie at supelec.fr (Francois JOUVIE)
Date: Wed, 17 Sep 2008 17:16:45 +0200
Subject: [R-sig-Geo] krige.cv
Message-ID: <6E734B10-99CD-45BB-B124-1034363BB640@supelec.fr>

Please,

Again, a question about the underlying process of krige.cv :

I have a set of 42 values at different coordinates points (x,y,z) in  
3D space.
I put an arbitrary model of variogram and I do a cross validation.

This below is working:

datacv<-read.table("/Users/fj/Desktop/septembre 08/ 
DonK3D_elev.txt",header=TRUE)
 > m1<-vgm(4,"Exp",2500)
 > x<-krige.cv(modE~1,~x+y+z,data=datacv,model=m1)
[using ordinary kriging]
[using ordinary kriging]
[using ordinary kriging]
[using ordinary kriging]

..... 42 times.

Now, if I had to define the coordinates in a previous work (to do a  
variogram by example), I can't do the cross validation because there  
is an ambiguity with these coordinates. By example:

datacv<-read.table("/Users/fj/Desktop/septembre 08/ 
DonK3D_elev.txt",header=TRUE)
coordinates(datacv)<-~x+y+z
 > m1<-vgm(4,"Exp",2500)
 > x<-krige.cv(modE~1,~x+y+z,data=datacv,model=m1)
Erreur dans `coordinates<-`(`*tmp*`, value = ~x + y + z) :
   setting coordinates cannot be done on Spatial objects, where they  
have already been set

This command neither do not work:

x<-krige.cv(modE~1,data=datacv,model=m1)
Erreur dans function (classes, fdef, mtable)  :
   unable to find an inherited method for function "krige.cv", for  
signature "formula", "missing"
 >
How to use the coordinates when they are known  (I have not a such  
problem with the krige command alone...?)

Thanks you very much

Francois



From edzer.pebesma at uni-muenster.de  Wed Sep 17 18:59:21 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Wed, 17 Sep 2008 18:59:21 +0200
Subject: [R-sig-Geo] krige.cv
In-Reply-To: <6E734B10-99CD-45BB-B124-1034363BB640@supelec.fr>
References: <6E734B10-99CD-45BB-B124-1034363BB640@supelec.fr>
Message-ID: <48D13769.8090408@uni-muenster.de>

Yes, this is a very annoying "feature" for which I couldn't find a good 
solution. Problem is that I chose both the old-style (pre-sp) formulation

krige(modE~1, ~x+y, dataFrame, dataFrame, model)

as well as

krige(modE~1, SpData, SpNewdata, model)

to be supported. As it decides on the base of the second argument, an S4 
approach was needed:
 > showMethods(krige.cv)
Function: krige.cv (package gstat)
formula="formula", locations="formula"
formula="formula", locations="Spatial"
formula="formula", locations="SpatialPointsDataFrame"
    (inherited from: formula="formula", locations="Spatial")

This however completely breaks when you start to name (some) arguments 
"data", and that's where the nice similarity to the lm-interface stops. 
The solution to this would have required (imo) hundreds of lines of 
unreadable code, dealing with all cases where some arguments are named, 
others not...

Francois JOUVIE wrote:
> Please,
>
> Again, a question about the underlying process of krige.cv :
>
> I have a set of 42 values at different coordinates points (x,y,z) in 
> 3D space.
> I put an arbitrary model of variogram and I do a cross validation.
>
> This below is working:
>
> datacv<-read.table("/Users/fj/Desktop/septembre 
> 08/DonK3D_elev.txt",header=TRUE)
> > m1<-vgm(4,"Exp",2500)
> > x<-krige.cv(modE~1,~x+y+z,data=datacv,model=m1)
> [using ordinary kriging]
> [using ordinary kriging]
> [using ordinary kriging]
> [using ordinary kriging]
>
> ..... 42 times.
>
> Now, if I had to define the coordinates in a previous work (to do a 
> variogram by example), I can't do the cross validation because there 
> is an ambiguity with these coordinates. By example:
>
> datacv<-read.table("/Users/fj/Desktop/septembre 
> 08/DonK3D_elev.txt",header=TRUE)
> coordinates(datacv)<-~x+y+z
> > m1<-vgm(4,"Exp",2500)
> > x<-krige.cv(modE~1,~x+y+z,data=datacv,model=m1)
> Erreur dans `coordinates<-`(`*tmp*`, value = ~x + y + z) :
>   setting coordinates cannot be done on Spatial objects, where they 
> have already been set
>
In this case you should do
x <- krige.cv(modE~1, datacv, m1)
> This command neither do not work:
>
> x<-krige.cv(modE~1,data=datacv,model=m1)
> Erreur dans function (classes, fdef, mtable)  :
>   unable to find an inherited method for function "krige.cv", for 
> signature "formula", "missing"
leave out the "data=" and it works.

The documentation of krige.cv gives:

     krige.cv(formula, locations, ...)
     krige.cv.locations(formula, locations, data, model = NULL, ..., 
beta = NULL, nmax = Inf,
             nmin = 0, maxdist = Inf, nfold = nrow(data), verbose = FALSE)
     krige.cv.spatial(formula, locations, model = NULL, ..., beta = 
NULL, nmax = Inf,
             nmin = 0, maxdist = Inf, nfold = nrow(locations), verbose = 
FALSE)
...
locations: formula with only independent variables that define the
          spatial data locations (coordinates), e.g. '~x+y', OR data
          object deriving from class 'Spatial', which has a
          'coordinates' method to extract its coordinates.
    data: data frame; should contain the dependent variable,
          independent variables, and coordinates; only to be provided
          if 'locations' is a formula

I'm moderately happy with the solution chosen, but at least it is 
documented...
--
Edzer
> >
> How to use the coordinates when they are known  (I have not a such 
> problem with the krige command alone...?)
>
> Thanks you very much
>
> Francois
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/



From ftmsd1 at uaf.edu  Wed Sep 17 20:57:05 2008
From: ftmsd1 at uaf.edu (Mel Durrett)
Date: Wed, 17 Sep 2008 10:57:05 -0800 (AKDT)
Subject: [R-sig-Geo] Seeking short course in geospatial statistics in R
Message-ID: <50181.137.229.65.183.1221677825.squirrel@ftmsd1.email.uaf.edu>

Geostats gurus:

Does anyone know of a short course (2 days to a week) in spatial
statistics, preferably taught in R, happening within the next few months
in North America?  I'm particularly interested in semivariograms and
kriging, and I have no GIS training.

I would greatly appreciate any leads.

Cheers!
Mel

-- 
Mel Durrett
PhD Student, Dept. of Biology & Wildlife
University of Alaska Fairbanks
Fairbanks, Alaska 99775



From paciorek at hsph.harvard.edu  Wed Sep 17 21:16:03 2008
From: paciorek at hsph.harvard.edu (Christopher Paciorek)
Date: Wed, 17 Sep 2008 15:16:03 -0400
Subject: [R-sig-Geo] Seeking short course in geospatial statistics	in R
In-Reply-To: <50181.137.229.65.183.1221677825.squirrel@ftmsd1.email.uaf.edu>
References: <50181.137.229.65.183.1221677825.squirrel@ftmsd1.email.uaf.edu>
Message-ID: <48D11F15.10CD.002E.0@hsph.harvard.edu>

Here's a one-day course: http://www.stat.purdue.edu/envr/shortcourse.html

chris

----------------------------------------------------------------------------------------------
Chris Paciorek / Asst. Professor        Email: paciorek at hsph.harvard.edu
Department of Biostatistics             Voice: 617-432-4912
Harvard School of Public Health         Fax:   617-432-5619
655 Huntington Av., Bldg. 2-407         WWW: www.biostat.harvard.edu/~paciorek
Boston, MA 02115 USA                    Permanent forward: paciorek at alumni.cmu.edu
  
====================================================
 
>>> "Mel Durrett" <ftmsd1 at uaf.edu> 09/17/08 2:57 PM >>> 
Geostats gurus:

Does anyone know of a short course (2 days to a week) in spatial
statistics, preferably taught in R, happening within the next few months
in North America?  I'm particularly interested in semivariograms and
kriging, and I have no GIS training.

I would greatly appreciate any leads.

Cheers!
Mel

--  
Mel Durrett
PhD Student, Dept. of Biology & Wildlife
University of Alaska Fairbanks
Fairbanks, Alaska 99775

_______________________________________________
R- sig- Geo mailing list
R- sig- Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r- sig- geo



From v.gomezrubio at imperial.ac.uk  Wed Sep 17 21:41:53 2008
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Wed, 17 Sep 2008 20:41:53 +0100
Subject: [R-sig-Geo] Seeking short course in geospatial statistics in R
In-Reply-To: <50181.137.229.65.183.1221677825.squirrel@ftmsd1.email.uaf.edu>
References: <50181.137.229.65.183.1221677825.squirrel@ftmsd1.email.uaf.edu>
Message-ID: <1221680513.7429.41.camel@fh-vrubio>

Mel,

> Does anyone know of a short course (2 days to a week) in spatial
> statistics, preferably taught in R, happening within the next few months
> in North America?  I'm particularly interested in semivariograms and
> kriging, and I have no GIS training.

You could also try these on-line materials:

http://www.bias-project.org.uk/ASDARcourse/

Best,

Virgilio



From T.Hengl at uva.nl  Wed Sep 17 23:55:36 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Wed, 17 Sep 2008 23:55:36 +0200
Subject: [R-sig-Geo] R-SAGA-GRASS-ArcGIS strengths/weaknesses
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B1F@hqagex02.fao.org>
	<3aaf1a030809161909m6fa06e7en1f8afb71b88c362f@mail.gmail.com>
Message-ID: <37382E8DCB905042969BA78541F6570624D5D3@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080917/ba813c61/attachment.pl>

From MAServe at lbl.gov  Thu Sep 18 02:30:09 2008
From: MAServe at lbl.gov (Marie-Anne C Serve)
Date: Wed, 17 Sep 2008 17:30:09 -0700
Subject: [R-sig-Geo] non symetric color scale
Message-ID: <fb3dce2563c8.48d13ea1@lbl.gov>

I would like to create a color scale covering values from -0.032 to 0.0025 with a neutral color (say grey or white) at 0. I tried to use designer.colors but i understand that the values have to be between 0 and 1. is there any simple mean to use either this function or another to get what i am looking for?
here is what i tried:
filled.contour(1:185,1:185,O3diff[,,1],xlim=c(1,185),ylim=c(1,185),asp=1,xlab="Xcell",ylab="Ycell",
designer.colors(n=20,col=c("darkblue","white","darkred"),seq(-0.032,0,0.0025)),
zlim=c(-0.032,0.0025),key.axes=axis(4,seq(-0.032,0.0025,by=0.0005),asp=1))



From h.wickham at gmail.com  Thu Sep 18 02:39:30 2008
From: h.wickham at gmail.com (hadley wickham)
Date: Wed, 17 Sep 2008 19:39:30 -0500
Subject: [R-sig-Geo] non symetric color scale
In-Reply-To: <fb3dce2563c8.48d13ea1@lbl.gov>
References: <fb3dce2563c8.48d13ea1@lbl.gov>
Message-ID: <f8e6ff050809171739h57842e2aj4933da0e57d00d83@mail.gmail.com>

For a start, have you looked at the output of seq(-0.032,0,0.0025)?  I
don't think it does what yo think it does.

Hadley

On Wed, Sep 17, 2008 at 7:30 PM, Marie-Anne C Serve <MAServe at lbl.gov> wrote:
> I would like to create a color scale covering values from -0.032 to 0.0025 with a neutral color (say grey or white) at 0. I tried to use designer.colors but i understand that the values have to be between 0 and 1. is there any simple mean to use either this function or another to get what i am looking for?
> here is what i tried:
> filled.contour(1:185,1:185,O3diff[,,1],xlim=c(1,185),ylim=c(1,185),asp=1,xlab="Xcell",ylab="Ycell",
> designer.colors(n=20,col=c("darkblue","white","darkred"),seq(-0.032,0,0.0025)),
> zlim=c(-0.032,0.0025),key.axes=axis(4,seq(-0.032,0.0025,by=0.0005),asp=1))
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
http://had.co.nz/



From jean-paul.kibambe at uclouvain.be  Thu Sep 18 10:37:07 2008
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Thu, 18 Sep 2008 10:37:07 +0200 (CEST)
Subject: [R-sig-Geo] 'spgwr' package citation
Message-ID: <6ba444ca915c9eae0263dd164468532f.squirrel@mmp.sipr-dc.ucl.ac.be>

Hi,

Someone could tell me how to cite the 'spgwr' package in a scientific paper ?

The command : citation ("pkgname") returns a warning message.

Thanks in advance !


JP



From Roger.Bivand at nhh.no  Thu Sep 18 11:20:19 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 18 Sep 2008 11:20:19 +0200 (CEST)
Subject: [R-sig-Geo] 'spgwr' package citation
In-Reply-To: <6ba444ca915c9eae0263dd164468532f.squirrel@mmp.sipr-dc.ucl.ac.be>
References: <6ba444ca915c9eae0263dd164468532f.squirrel@mmp.sipr-dc.ucl.ac.be>
Message-ID: <Pine.LNX.4.64.0809181113590.31344@reclus.nhh.no>

On Thu, 18 Sep 2008, Jean-Paul Kibambe Lubamba wrote:

> Hi,
>
> Someone could tell me how to cite the 'spgwr' package in a scientific paper ?
>
> The command : citation ("pkgname") returns a warning message.

I see:

> citation("spgwr")
To cite package 'spgwr' in publications use:

   Roger Bivand and Danlin Yu (2008). spgwr: Geographically weighted
   regression. R package version 0.5-4.
...
ATTENTION: This citation information has been auto-generated from the
package DESCRIPTION file and may need manual editing, see
'help("citation")' .
>

Is the "ATTENTION: ..." your warning? There are no publications about it 
as such, though it is mentioned in several (in particular in several of 
Danlin's papers) in the course of use. I'll leave it up to readers of the 
Bivand/Pebesma/G?mez-Rubio R-spatial book to see whether the section in 
Ch. 10 might serve, it is pretty short, and the book is slowly starting 
to reach people. The standard citation as above is reasonable, because it 
reflects the actual work put into the package itself.

Roger

>
> Thanks in advance !
>
>
> JP
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From yud at mail.montclair.edu  Thu Sep 18 15:13:35 2008
From: yud at mail.montclair.edu (Danlin Yu)
Date: Thu, 18 Sep 2008 09:13:35 -0400
Subject: [R-sig-Geo] 'spgwr' package citation
In-Reply-To: <Pine.LNX.4.64.0809181113590.31344@reclus.nhh.no>
References: <6ba444ca915c9eae0263dd164468532f.squirrel@mmp.sipr-dc.ucl.ac.be>
	<Pine.LNX.4.64.0809181113590.31344@reclus.nhh.no>
Message-ID: <48D253FF.6090800@mail.montclair.edu>

Indeed, in a recently publish paper in Environment and Planning B, I 
cited the package as following:

Bivand R,Yu D L, 2005, "SPGWR - an R package for geographically weighted 
regression'',
http://sourceforge.net/project/showfiles.php?group id=84357&package 
id=120594

Another one in a recently submitted paper cite the package as:

Bivand R, Yu D (2007) SPGWR: Geographically weighted regression. 
Available online at:
http://cran.r-project.org/bin/windows/contrib/r-release/spgwr_0.4-6.zip 
(Accessed June 17,
2008)

The link and time surely need update, but I hope this would help.

Best,
Danlin

Roger Bivand wrote:
> On Thu, 18 Sep 2008, Jean-Paul Kibambe Lubamba wrote:
>
>> Hi,
>>
>> Someone could tell me how to cite the 'spgwr' package in a scientific 
>> paper ?
>>
>> The command : citation ("pkgname") returns a warning message.
>
> I see:
>
>> citation("spgwr")
> To cite package 'spgwr' in publications use:
>
>   Roger Bivand and Danlin Yu (2008). spgwr: Geographically weighted
>   regression. R package version 0.5-4.
> ...
> ATTENTION: This citation information has been auto-generated from the
> package DESCRIPTION file and may need manual editing, see
> 'help("citation")' .
>>
>
> Is the "ATTENTION: ..." your warning? There are no publications about 
> it as such, though it is mentioned in several (in particular in 
> several of Danlin's papers) in the course of use. I'll leave it up to 
> readers of the Bivand/Pebesma/G?mez-Rubio R-spatial book to see 
> whether the section in Ch. 10 might serve, it is pretty short, and the 
> book is slowly starting to reach people. The standard citation as 
> above is reasonable, because it reflects the actual work put into the 
> package itself.
>
> Roger
>
>>
>> Thanks in advance !
>>
>>
>> JP
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> ------------------------------------------------------------------------
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
___________________________________________
Danlin Yu, Ph.D.
Assistant Professor
Department of Earth & Environmental Studies
Montclair State University
Montclair, NJ, 07043
Tel: 973-655-4313
Fax: 973-655-4072
email: yud at mail.montclair.edu
webpage: csam.montclair.edu/~yu



From Steve_Friedman at nps.gov  Thu Sep 18 22:48:46 2008
From: Steve_Friedman at nps.gov (Steve_Friedman at nps.gov)
Date: Thu, 18 Sep 2008 16:48:46 -0400
Subject: [R-sig-Geo] working with ncdf files
Message-ID: <OF81A625B7.F39AFA7A-ON852574C8.0072082A-852574C8.00725401@nps.gov>



Forgive the earlier post to r-help.


I'm working with a large hydrological data set stored in a netCDF format.
The file stores x and y coordinates in the UTM projected coordinate system,
yet when I use image to graphically display the z variable, the image is
distorted in the sense that it does not plot the map in the correct spatial
organization.

I'm wondering if I need to define the projection of the netCDF file with
rgdal or proj4 routines first before I send it to the graphics device.

My code is as follows:

 q1_2001 <- open.ncdf("H:\\SKF_DESKTOP FILES\\My
Documents\\EDEN\\EDEN\\Surfaces\\2000_q1.nc", readunlimi=FALSE)
#opens ncdf file for reading
 # gets the realinformation
   wat.data2000q1 <- get.var.ncdf(q1_2001,  verbose=FALSE )
 # GENERAL EXAMINATION OF HEADER DATA in the wat.data file
   day <- get.var.ncdf(q1_2001, "time")   # length(day) 91 days in quarter
   UTMx <-   get.var.ncdf(q1_2001, "x")   # columns (eastings)  # should
return 287
   UTMy <-   get.var.ncdf(q1_2001, "y")   # rows (northings)    # should
return 405

# plot first 91 days (3 months of the year)
    for(i in 1:91) {
       !is.na( image(UTMx, UTMy, z = wat.data2001q1[,,i], col=brewer.pal(8,
     "YlGnBu"), axes=T, pty="s", ylab="UTM Northing", xlab="UTM Easting",
      main = "First Quater 2001")  )
    }

As I indicated above the map is displayed on the graphics device. However
the orientation is distorted pulling the x axis to wide and the y axis too
tall.  How can I set the graphics device to know the orientation and
scaling (if these are the correct terms) in order to display this map
correctly?

All insights will be greatly appreciated.


Steve Friedman Ph. D.
Spatial Statistical Analyst
Everglades and Dry Tortugas National Park
950 N Krome Ave (3rd Floor)
Homestead, Florida 33034

Office (305) 224 - 4282
Steve_Friedman at nps.gov



From ddepew at sciborg.uwaterloo.ca  Fri Sep 19 15:26:12 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Fri, 19 Sep 2008 09:26:12 -0400
Subject: [R-sig-Geo] cokriging question
Message-ID: <48D3A874.3050103@scimail.uwaterloo.ca>

Is there a limit to the # of observations or size of file that can be 
co-kriged in gstat?
I have a ~12000 observation data set (2 variables), the variograms, 
cross variogram and lmc are fit well, and co-kriging starts ok

Linear Model of Coregionalization found. Good.
[using ordinary cokriging]

then immediately outputs

"memory.c", line 57: can't allocate memory in function m_get()
Error in predict.gstat(fit.ck, newdata = EcoSAV.grid, maxdist = 100) :
  m_get

Iv tried different maxdist from 10 to 1000, with exactly the same result.
I recently upgraded my RAM to 4Gb and flipped the windows XP /3GB switch.


-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W.
Waterloo, ON. Canada
N2L 3G1

(T) 1-519-888-4567 x33895
(F) 1-519-746-0614

http://www.science.uwaterloo.ca/~ddepew



From edzer.pebesma at uni-muenster.de  Fri Sep 19 15:53:33 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 19 Sep 2008 15:53:33 +0200
Subject: [R-sig-Geo] cokriging question
In-Reply-To: <48D3A874.3050103@scimail.uwaterloo.ca>
References: <48D3A874.3050103@scimail.uwaterloo.ca>
Message-ID: <48D3AEDD.4010007@uni-muenster.de>

Dave,

12000 observations fit, in the c representation, in less than 1 Mb (64 
bytes per observation).

The issue is that you think that passing maxdist to predict.gstat has an 
effect. It doesn't; you need to pass it to function gstat().

The same thing happened in this
https://stat.ethz.ch/pipermail/r-sig-geo/2008-September/004182.html
message, where nmax was passed to predict.gstat, and simulation took 
forever. The other issue in that question was, I suspect, lack of 
standardization of coordinates, used in a trend surface.
--
Edzer

Dave Depew wrote:
> Is there a limit to the # of observations or size of file that can be 
> co-kriged in gstat?
> I have a ~12000 observation data set (2 variables), the variograms, 
> cross variogram and lmc are fit well, and co-kriging starts ok
>
> Linear Model of Coregionalization found. Good.
> [using ordinary cokriging]
>
> then immediately outputs
>
> "memory.c", line 57: can't allocate memory in function m_get()
> Error in predict.gstat(fit.ck, newdata = EcoSAV.grid, maxdist = 100) :
>  m_get
>
> Iv tried different maxdist from 10 to 1000, with exactly the same result.
> I recently upgraded my RAM to 4Gb and flipped the windows XP /3GB switch.
>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9



From Chris.Taylor at noaa.gov  Fri Sep 19 16:19:17 2008
From: Chris.Taylor at noaa.gov (Chris Taylor)
Date: Fri, 19 Sep 2008 10:19:17 -0400
Subject: [R-sig-Geo] cokriging question
In-Reply-To: <48D3AEDD.4010007@uni-muenster.de>
References: <48D3A874.3050103@scimail.uwaterloo.ca>
	<48D3AEDD.4010007@uni-muenster.de>
Message-ID: <48D3B4E5.9000207@noaa.gov>

Good morning Edzer and Dave,
Thanks for bringing up this point.  I had a similar issue recently using 
krige().  Observations at 5800 locations, attempting to krige() 
predictions at 112,000 locations resulted in the same "memory.c" error 
message.  Reducing predicted locations to <<50,000 and reducing max.dist 
seemed to help, but the predictions still took a very long time (>2 
hours).  (Running winxp with 4GB memory.)
Can you clarify your suspicion regarding the "lack of standardization of 
coordinates"?

Chris

Edzer Pebesma wrote:
> Dave,
>
> 12000 observations fit, in the c representation, in less than 1 Mb (64 
> bytes per observation).
>
> The issue is that you think that passing maxdist to predict.gstat has 
> an effect. It doesn't; you need to pass it to function gstat().
>
> The same thing happened in this
> https://stat.ethz.ch/pipermail/r-sig-geo/2008-September/004182.html
> message, where nmax was passed to predict.gstat, and simulation took 
> forever. The other issue in that question was, I suspect, lack of 
> standardization of coordinates, used in a trend surface.
> -- 
> Edzer
>
> Dave Depew wrote:
>> Is there a limit to the # of observations or size of file that can be 
>> co-kriged in gstat?
>> I have a ~12000 observation data set (2 variables), the variograms, 
>> cross variogram and lmc are fit well, and co-kriging starts ok
>>
>> Linear Model of Coregionalization found. Good.
>> [using ordinary cokriging]
>>
>> then immediately outputs
>>
>> "memory.c", line 57: can't allocate memory in function m_get()
>> Error in predict.gstat(fit.ck, newdata = EcoSAV.grid, maxdist = 100) :
>>  m_get
>>
>> Iv tried different maxdist from 10 to 1000, with exactly the same 
>> result.
>> I recently upgraded my RAM to 4Gb and flipped the windows XP /3GB 
>> switch.
>>
>>
>

-- 
J. Christopher Taylor, Ph.D.
Applied Ecology and Restoration Research
National Ocean Service / NOAA  
National Centers for Coastal Ocean Science  
Center for Coastal Fisheries and Habitat Research  
101 Pivers Island Road, Beaufort, North Carolina 28516-9722  
Ph:(252) 838 0833  Fx:(252) 728 8784  
Website: http://www.ccfhr.noaa.gov/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Chris_Taylor.vcf
Type: text/x-vcard
Size: 388 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080919/1ebd6a98/attachment.vcf>

From edzer.pebesma at uni-muenster.de  Fri Sep 19 16:45:37 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 19 Sep 2008 16:45:37 +0200
Subject: [R-sig-Geo] cokriging question
In-Reply-To: <48D3B4E5.9000207@noaa.gov>
References: <48D3A874.3050103@scimail.uwaterloo.ca>
	<48D3AEDD.4010007@uni-muenster.de> <48D3B4E5.9000207@noaa.gov>
Message-ID: <48D3BB11.7050603@uni-muenster.de>

Good morning Dave (late afternoon here),

Chris Taylor wrote:
> Good morning Edzer and Dave,
> Thanks for bringing up this point.  I had a similar issue recently 
> using krige().  Observations at 5800 locations, attempting to krige() 
> predictions at 112,000 locations resulted in the same "memory.c" error 
> message.  Reducing predicted locations to <<50,000 and reducing 
> max.dist seemed to help, but the predictions still took a very long 
> time (>2 hours).  (Running winxp with 4GB memory.)
> Can you clarify your suspicion regarding the "lack of standardization 
> of coordinates"?
In this message, a trend was modelled based on x and y coordinates, as 
follows:
       x                y                DN4          indicator4
 Min.   :670462   Min.   :4215236   Min.   :18.00   Min.   :0.0000
 1st Qu.:670683   1st Qu.:4215456   1st Qu.:24.00   1st Qu.:0.0000
 Median :670904   Median :4215677   Median :32.50   Median :0.0000
 Mean   :670904   Mean   :4215677   Mean   :43.26   Mean   :0.4795
 3rd Qu.:671125   3rd Qu.:4215898   3rd Qu.:64.00   3rd Qu.:1.0000
 Max.   :671346   Max.   :4216119   Max.   :87.00   Max.   :1.0000
 > 
g<-gstat(id="indicator6",formula=indicator6~x+y+x*y+sqrt(x)+sqrt(y),location=~x+y,data=band6.data,...

computing the x*y will give numbers many orders of magnitude larger than 
sqrt(x),or the intercept. The advice is usually to (somewhat) 
standardize coordinates before using them as a trend. But I doubt this 
helps you very much.

I find it hard to consider > 2 hours as a very long time before I know 
all the details (e.g. how many points were there within your maxdist?), 
the reason why you want an instant answer, and preferably have heard a 
comparison with other software. If you then tell me what your budget is, 
I might come up with possible solutions (starting very cheap, e.g. look 
at demo(snow) in package gstat, or use an OS that can assign this 4Gb to 
a single process).
--
Edzer
>
> Chris
>
> Edzer Pebesma wrote:
>> Dave,
>>
>> 12000 observations fit, in the c representation, in less than 1 Mb 
>> (64 bytes per observation).
>>
>> The issue is that you think that passing maxdist to predict.gstat has 
>> an effect. It doesn't; you need to pass it to function gstat().
>>
>> The same thing happened in this
>> https://stat.ethz.ch/pipermail/r-sig-geo/2008-September/004182.html
>> message, where nmax was passed to predict.gstat, and simulation took 
>> forever. The other issue in that question was, I suspect, lack of 
>> standardization of coordinates, used in a trend surface.
>> -- 
>> Edzer
>>
>> Dave Depew wrote:
>>> Is there a limit to the # of observations or size of file that can 
>>> be co-kriged in gstat?
>>> I have a ~12000 observation data set (2 variables), the variograms, 
>>> cross variogram and lmc are fit well, and co-kriging starts ok
>>>
>>> Linear Model of Coregionalization found. Good.
>>> [using ordinary cokriging]
>>>
>>> then immediately outputs
>>>
>>> "memory.c", line 57: can't allocate memory in function m_get()
>>> Error in predict.gstat(fit.ck, newdata = EcoSAV.grid, maxdist = 100) :
>>>  m_get
>>>
>>> Iv tried different maxdist from 10 to 1000, with exactly the same 
>>> result.
>>> I recently upgraded my RAM to 4Gb and flipped the windows XP /3GB 
>>> switch.
>>>
>>>
>>
>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9



From ddepew at sciborg.uwaterloo.ca  Fri Sep 19 17:00:08 2008
From: ddepew at sciborg.uwaterloo.ca (Dave Depew)
Date: Fri, 19 Sep 2008 11:00:08 -0400
Subject: [R-sig-Geo] cokriging question
In-Reply-To: <48D3BB11.7050603@uni-muenster.de>
References: <48D3A874.3050103@scimail.uwaterloo.ca>
	<48D3AEDD.4010007@uni-muenster.de> <48D3B4E5.9000207@noaa.gov>
	<48D3BB11.7050603@uni-muenster.de>
Message-ID: <48D3BE78.9020001@scimail.uwaterloo.ca>

Thanks for the quick responses.
I've often done global OK or UK that can take ~ 2-3 days to complete. I 
always assumed that it was b/c the matrices were so large. Looking at 
task manager indicated that Rgui.exe only consumed ~ 800 Mb of RAM 
during the processes.
I'll try it by passing the maxdist to gstat() rather than predict.gstat().
The only other time I encounter the memory.c line is when I neglect to 
remove duplicate observations.

I think I only should have at most 500 or so points within a 100-200m 
maxdist...




Edzer Pebesma wrote:
> Good morning Dave (late afternoon here),
>
> Chris Taylor wrote:
>> Good morning Edzer and Dave,
>> Thanks for bringing up this point.  I had a similar issue recently 
>> using krige().  Observations at 5800 locations, attempting to krige() 
>> predictions at 112,000 locations resulted in the same "memory.c" 
>> error message.  Reducing predicted locations to <<50,000 and reducing 
>> max.dist seemed to help, but the predictions still took a very long 
>> time (>2 hours).  (Running winxp with 4GB memory.)
>> Can you clarify your suspicion regarding the "lack of standardization 
>> of coordinates"?
> In this message, a trend was modelled based on x and y coordinates, as 
> follows:
>       x                y                DN4          indicator4
> Min.   :670462   Min.   :4215236   Min.   :18.00   Min.   :0.0000
> 1st Qu.:670683   1st Qu.:4215456   1st Qu.:24.00   1st Qu.:0.0000
> Median :670904   Median :4215677   Median :32.50   Median :0.0000
> Mean   :670904   Mean   :4215677   Mean   :43.26   Mean   :0.4795
> 3rd Qu.:671125   3rd Qu.:4215898   3rd Qu.:64.00   3rd Qu.:1.0000
> Max.   :671346   Max.   :4216119   Max.   :87.00   Max.   :1.0000
> > 
> g<-gstat(id="indicator6",formula=indicator6~x+y+x*y+sqrt(x)+sqrt(y),location=~x+y,data=band6.data,... 
>
>
> computing the x*y will give numbers many orders of magnitude larger 
> than sqrt(x),or the intercept. The advice is usually to (somewhat) 
> standardize coordinates before using them as a trend. But I doubt this 
> helps you very much.
>
> I find it hard to consider > 2 hours as a very long time before I know 
> all the details (e.g. how many points were there within your 
> maxdist?), the reason why you want an instant answer, and preferably 
> have heard a comparison with other software. If you then tell me what 
> your budget is, I might come up with possible solutions (starting very 
> cheap, e.g. look at demo(snow) in package gstat, or use an OS that can 
> assign this 4Gb to a single process).
> -- 
> Edzer
>>
>> Chris
>>
>> Edzer Pebesma wrote:
>>> Dave,
>>>
>>> 12000 observations fit, in the c representation, in less than 1 Mb 
>>> (64 bytes per observation).
>>>
>>> The issue is that you think that passing maxdist to predict.gstat 
>>> has an effect. It doesn't; you need to pass it to function gstat().
>>>
>>> The same thing happened in this
>>> https://stat.ethz.ch/pipermail/r-sig-geo/2008-September/004182.html
>>> message, where nmax was passed to predict.gstat, and simulation took 
>>> forever. The other issue in that question was, I suspect, lack of 
>>> standardization of coordinates, used in a trend surface.
>>> -- 
>>> Edzer
>>>
>>> Dave Depew wrote:
>>>> Is there a limit to the # of observations or size of file that can 
>>>> be co-kriged in gstat?
>>>> I have a ~12000 observation data set (2 variables), the variograms, 
>>>> cross variogram and lmc are fit well, and co-kriging starts ok
>>>>
>>>> Linear Model of Coregionalization found. Good.
>>>> [using ordinary cokriging]
>>>>
>>>> then immediately outputs
>>>>
>>>> "memory.c", line 57: can't allocate memory in function m_get()
>>>> Error in predict.gstat(fit.ck, newdata = EcoSAV.grid, maxdist = 100) :
>>>>  m_get
>>>>
>>>> Iv tried different maxdist from 10 to 1000, with exactly the same 
>>>> result.
>>>> I recently upgraded my RAM to 4Gb and flipped the windows XP /3GB 
>>>> switch.
>>>>
>>>>
>>>
>>
>


-- 
David Depew
PhD Candidate
Department of Biology
University of Waterloo
200 University Ave W.
Waterloo, ON. Canada
N2L 3G1

(T) 1-519-888-4567 x33895
(F) 1-519-746-0614

http://www.science.uwaterloo.ca/~ddepew



From T.Hengl at uva.nl  Fri Sep 19 18:18:05 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Fri, 19 Sep 2008 18:18:05 +0200
Subject: [R-sig-Geo] cokriging question
References: <48D3A874.3050103@scimail.uwaterloo.ca><48D3AEDD.4010007@uni-muenster.de>
	<48D3B4E5.9000207@noaa.gov><48D3BB11.7050603@uni-muenster.de>
	<48D3BE78.9020001@scimail.uwaterloo.ca>
Message-ID: <37382E8DCB905042969BA78541F6570624D5D7@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080919/8a6bf36b/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Sep 19 18:57:20 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 19 Sep 2008 18:57:20 +0200
Subject: [R-sig-Geo] cokriging question
In-Reply-To: <37382E8DCB905042969BA78541F6570624D5D7@kwek.ic.uva.nl>
References: <48D3A874.3050103@scimail.uwaterloo.ca><48D3AEDD.4010007@uni-muenster.de>	<48D3B4E5.9000207@noaa.gov><48D3BB11.7050603@uni-muenster.de>	<48D3BE78.9020001@scimail.uwaterloo.ca>
	<37382E8DCB905042969BA78541F6570624D5D7@kwek.ic.uva.nl>
Message-ID: <48D3D9F0.9030809@uni-muenster.de>

Dear Tom,

Hengl, T. wrote:
>  
> Dear Edzer,
>  
> I do have a similar problem (extensive computation time, memory limits). I would like to run interpolation of 60,000 points for 500,000 new points using OK and nmax of 30 closest points (I am using a windowsxp machine with 2GB RAM).
>  
> But I have doubts that it can ever run in less than few hours in gstat. I mean, at each new location, the algorithm has to derive distances to all locations (60,000^2 matrix) and then find the 30 closest ones. There is no more intelligent way to pick up the closest points - or is there?
>   
There is, and it is being used: the short name is spatial index and 
quadtree; you'll find links and explanation on
http://www.gstat.org/manual/node8.html#SECTION00351000000000000000

Both computers & geosciences papers on gstat mention this.

To see the effect of this, try to enlarge split to a number larger than 
the number of observations, as in

krige(log(zinc)~1, meuse, meuse[1,], vgm(1, "Exp", 300), set = 
list(split=1000))

Here, the bucket size is 1000, and all observations will be ranked 
according to distance to the prediction location (which does not require 
an n^2 matrix), using quick sort.

Other software, such as GSLIB (iirc) put a course regular grid over the 
domain to speed up neighbourhood selection.
--
Edzer

>  
> Thanx,
>  
> Tom
>  
>
> ________________________________
>
> From: r-sig-geo-bounces at stat.math.ethz.ch on behalf of Dave Depew
> Sent: Fri 9/19/2008 5:00 PM
> To: Edzer Pebesma
> Cc: Chris Taylor; r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] cokriging question
>
>
>
> Thanks for the quick responses.
> I've often done global OK or UK that can take ~ 2-3 days to complete. I
> always assumed that it was b/c the matrices were so large. Looking at
> task manager indicated that Rgui.exe only consumed ~ 800 Mb of RAM
> during the processes.
> I'll try it by passing the maxdist to gstat() rather than predict.gstat().
> The only other time I encounter the memory.c line is when I neglect to
> remove duplicate observations.
>
> I think I only should have at most 500 or so points within a 100-200m
> maxdist...
>
>
>
>
> Edzer Pebesma wrote:
>   
>> Good morning Dave (late afternoon here),
>>
>> Chris Taylor wrote:
>>     
>>> Good morning Edzer and Dave,
>>> Thanks for bringing up this point.  I had a similar issue recently
>>> using krige().  Observations at 5800 locations, attempting to krige()
>>> predictions at 112,000 locations resulted in the same "memory.c"
>>> error message.  Reducing predicted locations to <<50,000 and reducing
>>> max.dist seemed to help, but the predictions still took a very long
>>> time (>2 hours).  (Running winxp with 4GB memory.)
>>> Can you clarify your suspicion regarding the "lack of standardization
>>> of coordinates"?
>>>       
>> In this message, a trend was modelled based on x and y coordinates, as
>> follows:
>>       x                y                DN4          indicator4
>> Min.   :670462   Min.   :4215236   Min.   :18.00   Min.   :0.0000
>> 1st Qu.:670683   1st Qu.:4215456   1st Qu.:24.00   1st Qu.:0.0000
>> Median :670904   Median :4215677   Median :32.50   Median :0.0000
>> Mean   :670904   Mean   :4215677   Mean   :43.26   Mean   :0.4795
>> 3rd Qu.:671125   3rd Qu.:4215898   3rd Qu.:64.00   3rd Qu.:1.0000
>> Max.   :671346   Max.   :4216119   Max.   :87.00   Max.   :1.0000
>>     
>> g<-gstat(id="indicator6",formula=indicator6~x+y+x*y+sqrt(x)+sqrt(y),location=~x+y,data=band6.data,...
>>
>>
>> computing the x*y will give numbers many orders of magnitude larger
>> than sqrt(x),or the intercept. The advice is usually to (somewhat)
>> standardize coordinates before using them as a trend. But I doubt this
>> helps you very much.
>>
>> I find it hard to consider > 2 hours as a very long time before I know
>> all the details (e.g. how many points were there within your
>> maxdist?), the reason why you want an instant answer, and preferably
>> have heard a comparison with other software. If you then tell me what
>> your budget is, I might come up with possible solutions (starting very
>> cheap, e.g. look at demo(snow) in package gstat, or use an OS that can
>> assign this 4Gb to a single process).
>> --
>> Edzer
>>     
>>> Chris
>>>
>>> Edzer Pebesma wrote:
>>>       
>>>> Dave,
>>>>
>>>> 12000 observations fit, in the c representation, in less than 1 Mb
>>>> (64 bytes per observation).
>>>>
>>>> The issue is that you think that passing maxdist to predict.gstat
>>>> has an effect. It doesn't; you need to pass it to function gstat().
>>>>
>>>> The same thing happened in this
>>>> https://stat.ethz.ch/pipermail/r-sig-geo/2008-September/004182.html
>>>> message, where nmax was passed to predict.gstat, and simulation took
>>>> forever. The other issue in that question was, I suspect, lack of
>>>> standardization of coordinates, used in a trend surface.
>>>> --
>>>> Edzer
>>>>
>>>> Dave Depew wrote:
>>>>         
>>>>> Is there a limit to the # of observations or size of file that can
>>>>> be co-kriged in gstat?
>>>>> I have a ~12000 observation data set (2 variables), the variograms,
>>>>> cross variogram and lmc are fit well, and co-kriging starts ok
>>>>>
>>>>> Linear Model of Coregionalization found. Good.
>>>>> [using ordinary cokriging]
>>>>>
>>>>> then immediately outputs
>>>>>
>>>>> "memory.c", line 57: can't allocate memory in function m_get()
>>>>> Error in predict.gstat(fit.ck, newdata = EcoSAV.grid, maxdist = 100) :
>>>>>  m_get
>>>>>
>>>>> Iv tried different maxdist from 10 to 1000, with exactly the same
>>>>> result.
>>>>> I recently upgraded my RAM to 4Gb and flipped the windows XP /3GB
>>>>> switch.
>>>>>
>>>>>
>>>>>           
>
>
> --
> David Depew
> PhD Candidate
> Department of Biology
> University of Waterloo
> 200 University Ave W.
> Waterloo, ON. Canada
> N2L 3G1
>
> (T) 1-519-888-4567 x33895
> (F) 1-519-746-0614
>
> http://www.science.uwaterloo.ca/~ddepew
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9



From milton.ruser at gmail.com  Fri Sep 19 23:01:10 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Fri, 19 Sep 2008 19:01:10 -0200
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
Message-ID: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080919/29c76a0b/attachment.pl>

From mdsumner at utas.edu.au  Sat Sep 20 01:05:46 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Sat, 20 Sep 2008 9:05:46 +1000
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
Message-ID: <200809192305.m8JN5k0m023451@corinna.its.utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080920/6fb714a0/attachment.pl>

From MAServe at lbl.gov  Sat Sep 20 02:16:52 2008
From: MAServe at lbl.gov (Marie-Anne C Serve)
Date: Fri, 19 Sep 2008 17:16:52 -0700
Subject: [R-sig-Geo] how to move a legend?
Message-ID: <f32286587fe7.48d3de84@lbl.gov>

Hello,
I would like to know how i can move a color scale, now vertical and on the right of the plot, to a horizontal one at the bottom.
i am using filled.contour().
thanks
Marie



From mdsumner at utas.edu.au  Sat Sep 20 02:46:26 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Sat, 20 Sep 2008 10:46:26 +1000
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
In-Reply-To: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
References: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
Message-ID: <48D447E2.6030402@utas.edu.au>

I tried this, and AAIGrid is not available for creation by rgdal on my 
machine. See gdalDrivers() for those available.

If you install FWTools you can use a workaround to convert the export 
externally, e.g.

 x <- readGDAL(system.file("external/test.ag", package="sp")[1])

## write to GeoTIFF
 writeGDAL(x, "mes01jan.tif",  type = "Byte")

## convert externally to AAIGrid
system("gdal_translate mes01jan.tif mes01jan.asc -of AAIGrid -ot Byte")

## check result
system("gdalinfo mes01jan.asc")

I don't believe that AAIGrid can explicitly support type Byte without 
augmentation, so I would carefully check the coercion that occurs (if 
it's actually needed).

Cheers, Mike.

milton ruser wrote:
> Dear all,
> I am reading a set of maps from ArcGRID format using rgdal and I need to
> export to ASC format.
>
> But when I try the commands below, I get an error.
>
> require(rgdal)
>
> mes01jan<-readGDAL("jan_00")
> image(mes01jan, col=topo.colors(50))  #looks find
> writeGDAL(mes01jan, "mes01jan.asc", drivername = "AAIGrid", type="Byte")
>
> Any idea?
>
> miltinho, brazil
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG - http://www.avg.com 
> Version: 8.0.169 / Virus Database: 270.7.0/1681 - Release Date: 9/19/2008 3:54 PM
>
>



From mdsumner at utas.edu.au  Sat Sep 20 02:50:19 2008
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Sat, 20 Sep 2008 10:50:19 +1000
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
In-Reply-To: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
References: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
Message-ID: <48D448CB.8000009@utas.edu.au>

Of course, you can use write.asciigrid() in package sp for a more 
immediate workaround (sorry for not thinking of this previously!):

e.g.


 x <- readGDAL(system.file("external/test.ag", package="sp")[1])

## be aware that only the first raster column will be written by attr = 1
write.asciigrid(x, "mes01jan.asc")

## which on my machine results in
system("gdalinfo mes01jan.asc")
Driver: AAIGrid/Arc/Info ASCII Grid
Files: mes01jan.asc
       mes01jan.asc.aux.xml
Size is 80, 115
Coordinate System is `'
Origin = (178400.000000000000000,334000.000000000000000)
Pixel Size = (40.000000000000000,-40.000000000000000)
Corner Coordinates:
Upper Left  (  178400.000,  334000.000)
Lower Left  (  178400.000,  329400.000)
Upper Right (  181600.000,  334000.000)
Lower Right (  181600.000,  329400.000)
Center      (  180000.000,  331700.000)
Band 1 Block=80x1 Type=Float32, ColorInterp=Gray
  NoData Value=-9999

Sorry for all the unnecessary email traffic . . .

Cheers, Mike.
milton ruser wrote:
> Dear all,
> I am reading a set of maps from ArcGRID format using rgdal and I need to
> export to ASC format.
>
> But when I try the commands below, I get an error.
>
> require(rgdal)
>
> mes01jan<-readGDAL("jan_00")
> image(mes01jan, col=topo.colors(50))  #looks find
> writeGDAL(mes01jan, "mes01jan.asc", drivername = "AAIGrid", type="Byte")
>
> Any idea?
>
> miltinho, brazil
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>   
> ------------------------------------------------------------------------
>
>
> No virus found in this incoming message.
> Checked by AVG - http://www.avg.com 
> Version: 8.0.169 / Virus Database: 270.7.0/1681 - Release Date: 9/19/2008 3:54 PM
>
>



From brenning at uwaterloo.ca  Sat Sep 20 03:12:09 2008
From: brenning at uwaterloo.ca (Alexander Brenning)
Date: Fri, 19 Sep 2008 21:12:09 -0400
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
In-Reply-To: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
References: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
Message-ID: <48D44DE9.3060505@uwaterloo.ca>

Hi,

an alternative to using GDAL for writing ASCII grids is the 
write.ascii.grid function in the RSAGA package. (RSAGA is an interface 
to SAGA GIS, but this function actually doesn't require SAGA to be 
installed on your computer.)

write.ascii.grid(data, file, header = NULL, write.header = TRUE,
     digits, dec = ".", georef = "corner")

The 'data' argument is a matrix, and the 'header' is a list with named 
components as in the ASCII grid header, see RSAGA help. Defining your 
own header is pretty simple.

I hope this helps
  Alex




milton ruser wrote:
> Dear all,
> I am reading a set of maps from ArcGRID format using rgdal and I need to
> export to ASC format.
> 
> But when I try the commands below, I get an error.
> 
> require(rgdal)
> 
> mes01jan<-readGDAL("jan_00")
> image(mes01jan, col=topo.colors(50))  #looks find
> writeGDAL(mes01jan, "mes01jan.asc", drivername = "AAIGrid", type="Byte")
> 
> Any idea?
> 
> miltinho, brazil
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 

-- 
Alexander Brenning
brenning at uwaterloo.ca - T +1-519-888-4567 ext 35783
Department of Geography and Environmental Management
University of Waterloo
200 University Ave. W - Waterloo, ON - Canada N2L 3G1
http://www.fes.uwaterloo.ca/geography/faculty/brenning/



From milton.ruser at gmail.com  Sat Sep 20 03:57:11 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Fri, 19 Sep 2008 23:57:11 -0200
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
In-Reply-To: <48D447E2.6030402@utas.edu.au>
References: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
	<48D447E2.6030402@utas.edu.au>
Message-ID: <3aaf1a030809191857rcc7c1f5i962ec1b12e91b516@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080919/ab835690/attachment.pl>

From Roger.Bivand at nhh.no  Sat Sep 20 09:15:42 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 20 Sep 2008 09:15:42 +0200 (CEST)
Subject: [R-sig-Geo] from ArcGIS GRID to .ASC
In-Reply-To: <3aaf1a030809191857rcc7c1f5i962ec1b12e91b516@mail.gmail.com>
References: <3aaf1a030809191401v8048246v67af6bed70163e3e@mail.gmail.com>
	<48D447E2.6030402@utas.edu.au>
	<3aaf1a030809191857rcc7c1f5i962ec1b12e91b516@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809200911550.11099@reclus.nhh.no>

On Fri, 19 Sep 2008, milton ruser wrote:

> Dear all,
> I tryed both suggestions and they worked fine.
> In fact, the short solution is
>
> require(rgdal)
> require(maptools)
> mes01jan<-readGDAL("jan_00")
> write.asciigrid(mes01jan,"mes01jan.asc")

One final note: write.asciigrid() in sp has arguments:

> args(write.asciigrid)
function (x, fname, attr = 1, na.value = -9999, ...)

while its copy in maptools has:

> args(writeAsciiGrid)
function (x, fname, attr = 1, na.value = -9999, dec = options()$OutDec,
     ...)

This accommodates problems that we've seen in ArcGIS' handling of locales 
differing from users' expectations - by setting dec=, you can impose the 
understanding of other software.

Roger

>
> Thanks Mike! Thanks Alex!
>
> best wishes,
>
> miltinho astronauta
> brazil
>
> On Fri, Sep 19, 2008 at 10:46 PM, Michael Sumner <mdsumner at utas.edu.au>wrote:
>
>> I tried this, and AAIGrid is not available for creation by rgdal on my
>> machine. See gdalDrivers() for those available.
>>
>> If you install FWTools you can use a workaround to convert the export
>> externally, e.g.
>>
>> x <- readGDAL(system.file("external/test.ag", package="sp")[1])
>>
>> ## write to GeoTIFF
>> writeGDAL(x, "mes01jan.tif",  type = "Byte")
>>
>> ## convert externally to AAIGrid
>> system("gdal_translate mes01jan.tif mes01jan.asc -of AAIGrid -ot Byte")
>>
>> ## check result
>> system("gdalinfo mes01jan.asc")
>>
>> I don't believe that AAIGrid can explicitly support type Byte without
>> augmentation, so I would carefully check the coercion that occurs (if it's
>> actually needed).
>>
>> Cheers, Mike.
>>
>> milton ruser wrote:
>>
>>> Dear all,
>>> I am reading a set of maps from ArcGRID format using rgdal and I need to
>>> export to ASC format.
>>>
>>> But when I try the commands below, I get an error.
>>>
>>> require(rgdal)
>>>
>>> mes01jan<-readGDAL("jan_00")
>>> image(mes01jan, col=topo.colors(50))  #looks find
>>> writeGDAL(mes01jan, "mes01jan.asc", drivername = "AAIGrid", type="Byte")
>>>
>>> Any idea?
>>>
>>> miltinho, brazil
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>  ------------------------------------------------------------------------
>>>
>>>
>>> No virus found in this incoming message.
>>> Checked by AVG - http://www.avg.com Version: 8.0.169 / Virus Database:
>>> 270.7.0/1681 - Release Date: 9/19/2008 3:54 PM
>>>
>>>
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Paul.Satterthwaite at oregonstate.edu  Thu Sep 25 00:10:30 2008
From: Paul.Satterthwaite at oregonstate.edu (Satterthwaite, Paul)
Date: Wed, 24 Sep 2008 15:10:30 -0700
Subject: [R-sig-Geo] question about simulating patchy landscapes
Message-ID: <D7B94F0B40246740A3EFF9DBBD921B7B796B65@SAGE.forestry.oregonstate.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080924/27487786/attachment.pl>

From dylan.beaudette at gmail.com  Thu Sep 25 00:32:11 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Wed, 24 Sep 2008 15:32:11 -0700
Subject: [R-sig-Geo] question about simulating patchy landscapes
In-Reply-To: <D7B94F0B40246740A3EFF9DBBD921B7B796B65@SAGE.forestry.oregonstate.edu>
References: <D7B94F0B40246740A3EFF9DBBD921B7B796B65@SAGE.forestry.oregonstate.edu>
Message-ID: <200809241532.11462.dylan.beaudette@gmail.com>

On Wednesday 24 September 2008, Satterthwaite, Paul wrote:
> Hello,
>
>
>
> I am a very new user of R, but have used S-Plus for about a year or so.
> I am curious about methods of creating simulated patch landscapes in R,
> and how to parameterize patch cover values and modify the
> periodicity/regularity of the patches in said landscapes.
>
>
>
> Can anyone point me in the right direction?
>

If you have access to GRASS GIS, check out:
http://grass.itc.it/grass64/manuals/html64_user/r.surf.fractal.html

not sure if there is an implementation in R.



From dylan.beaudette at gmail.com  Thu Sep 25 00:44:35 2008
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Wed, 24 Sep 2008 15:44:35 -0700
Subject: [R-sig-Geo] question about simulating patchy landscapes
In-Reply-To: <D7B94F0B40246740A3EFF9DBBD921B7B796B65@SAGE.forestry.oregonstate.edu>
References: <D7B94F0B40246740A3EFF9DBBD921B7B796B65@SAGE.forestry.oregonstate.edu>
Message-ID: <200809241544.35192.dylan.beaudette@gmail.com>

On Wednesday 24 September 2008, Satterthwaite, Paul wrote:
> Hello,
>
>
>
> I am a very new user of R, but have used S-Plus for about a year or so.
> I am curious about methods of creating simulated patch landscapes in R,
> and how to parameterize patch cover values and modify the
> periodicity/regularity of the patches in said landscapes.
>
>
>
> Can anyone point me in the right direction?
>

Forgot to mention the RandomFields package.

require(RandomFields)
example(soil)

-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From murray.richardson at utoronto.ca  Thu Sep 25 06:00:40 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Thu, 25 Sep 2008 00:00:40 -0400
Subject: [R-sig-Geo] select polygons in polygons
Message-ID: <48DB0CE8.4080603@utoronto.ca>

Hello users,

There is probably a very simple solution to this that I am missing: is 
there a way to select polygons in one SPDF that fall within the polygons 
of another SPDF? 
This would save me a lot of processing time as I am having to take a 
very circuitous route to achieve the same outcome.

Thanks!

Murray



From Friderike.Oehler at fao.org  Thu Sep 25 09:43:59 2008
From: Friderike.Oehler at fao.org (Oehler, Friderike (AGPP))
Date: Thu, 25 Sep 2008 09:43:59 +0200
Subject: [R-sig-Geo] select polygons in polygons
Message-ID: <1A28265B00AA7E4085BB761555D3FCE8033C8B73@hqagex02.fao.org>

Try 
?overlay

Regards,
Friderike


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Murray Richardson
Sent: 25 September 2008 06:01
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] select polygons in polygons


Hello users,

There is probably a very simple solution to this that I am missing: is 
there a way to select polygons in one SPDF that fall within the polygons 
of another SPDF? 
This would save me a lot of processing time as I am having to take a 
very circuitous route to achieve the same outcome.

Thanks!

Murray

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From edzer.pebesma at uni-muenster.de  Thu Sep 25 10:56:01 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 25 Sep 2008 10:56:01 +0200
Subject: [R-sig-Geo] question about simulating patchy landscapes
In-Reply-To: <200809241544.35192.dylan.beaudette@gmail.com>
References: <D7B94F0B40246740A3EFF9DBBD921B7B796B65@SAGE.forestry.oregonstate.edu>
	<200809241544.35192.dylan.beaudette@gmail.com>
Message-ID: <48DB5221.7060907@uni-muenster.de>

... or you could try the geostatistical indicator simulation formalism 
in gstat:

require(gstat)
demo(uisim)
--
Edzer

Dylan Beaudette wrote:
> On Wednesday 24 September 2008, Satterthwaite, Paul wrote:
>   
>> Hello,
>>
>>
>>
>> I am a very new user of R, but have used S-Plus for about a year or so.
>> I am curious about methods of creating simulated patch landscapes in R,
>> and how to parameterize patch cover values and modify the
>> periodicity/regularity of the patches in said landscapes.
>>
>>
>>
>> Can anyone point me in the right direction?
>>
>>     
>
> Forgot to mention the RandomFields package.
>
> require(RandomFields)
> example(soil)
>
>   

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9



From jean-paul.kibambe at uclouvain.be  Thu Sep 25 11:46:21 2008
From: jean-paul.kibambe at uclouvain.be (Jean-Paul Kibambe Lubamba)
Date: Thu, 25 Sep 2008 11:46:21 +0200 (CEST)
Subject: [R-sig-Geo] Meaning of df1 and df2 in the LMZ.F2GWR.test
Message-ID: <8e47d87472001cca1ee0e45d708d913e.squirrel@mmp.sipr-dc.ucl.ac.be>

Hello,

Is anyone can explain me how to find the degrees of freedom of OLS
Residuals, GWR Improvement and GWR Residuals when using the LMZ.F2GWR.test
? The result gives df1 and df2 as degrees of freedom and I do not want to
make the wrong correspondance.

The same with the LMZ.F1GWR.test

Thanks for any help.


JP



From Roger.Bivand at nhh.no  Thu Sep 25 11:56:13 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 25 Sep 2008 11:56:13 +0200 (CEST)
Subject: [R-sig-Geo] Meaning of df1 and df2 in the LMZ.F2GWR.test
In-Reply-To: <8e47d87472001cca1ee0e45d708d913e.squirrel@mmp.sipr-dc.ucl.ac.be>
References: <8e47d87472001cca1ee0e45d708d913e.squirrel@mmp.sipr-dc.ucl.ac.be>
Message-ID: <Pine.LNX.4.64.0809251153200.27114@reclus.nhh.no>

On Thu, 25 Sep 2008, Jean-Paul Kibambe Lubamba wrote:

> Hello,
>
> Is anyone can explain me how to find the degrees of freedom of OLS
> Residuals, GWR Improvement and GWR Residuals when using the LMZ.F2GWR.test
> ? The result gives df1 and df2 as degrees of freedom and I do not want to
> make the wrong correspondance.
>
> The same with the LMZ.F1GWR.test

Please see the references to the papers, and the GWR book. However, the 
references seem muddled, and do presuppose that inference from GWR makes 
sense. Wheeler & Tiefelsdorf (2005) undermine that presupposition 
(collinearity in local coefficients), so really any inference is very much 
done at the users' risk. Recall that GWR is an exploratory tool (only).

Hope this helps,

Roger

>
> Thanks for any help.
>
>
> JP
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From murray.richardson at utoronto.ca  Thu Sep 25 15:33:53 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Thu, 25 Sep 2008 09:33:53 -0400
Subject: [R-sig-Geo] select polygons in polygons
In-Reply-To: <1A28265B00AA7E4085BB761555D3FCE8033C8B73@hqagex02.fao.org>
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B73@hqagex02.fao.org>
Message-ID: <48DB9341.4010900@utoronto.ca>

Thanks Friderike.  I assumed this was the answer, but it doesn't appear 
to work with two SPDF objects.  i.e.:

 > overlay(polysA,polysB)
Error in function (classes, fdef, mtable)  :
  unable to find an inherited method for function "overlay", for 
signature "SpatialPolygonsDataFrame", "SpatialPolygonsDataFrame"


Murray


Oehler, Friderike (AGPP) wrote:
> Try 
> ?overlay
>
> Regards,
> Friderike
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Murray Richardson
> Sent: 25 September 2008 06:01
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] select polygons in polygons
>
>
> Hello users,
>
> There is probably a very simple solution to this that I am missing: is 
> there a way to select polygons in one SPDF that fall within the polygons 
> of another SPDF? 
> This would save me a lot of processing time as I am having to take a 
> very circuitous route to achieve the same outcome.
>
> Thanks!
>
> Murray
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>



From edzer.pebesma at uni-muenster.de  Thu Sep 25 15:45:44 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 25 Sep 2008 15:45:44 +0200
Subject: [R-sig-Geo] select polygons in polygons
In-Reply-To: <48DB9341.4010900@utoronto.ca>
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B73@hqagex02.fao.org>
	<48DB9341.4010900@utoronto.ca>
Message-ID: <48DB9608.90102@uni-muenster.de>

That's right, it is not there; I thought this morning about a way to 
look whether all the points of one polygon fall in another, which sp's 
overlay could do, but that's not a sufficient condition.

Perhaps functions in package gpclib can do this?
--
Edzer

Murray Richardson wrote:
> Thanks Friderike.  I assumed this was the answer, but it doesn't 
> appear to work with two SPDF objects.  i.e.:
>
> > overlay(polysA,polysB)
> Error in function (classes, fdef, mtable)  :
>  unable to find an inherited method for function "overlay", for 
> signature "SpatialPolygonsDataFrame", "SpatialPolygonsDataFrame"
>
>
> Murray
>
>
> Oehler, Friderike (AGPP) wrote:
>> Try ?overlay
>>
>> Regards,
>> Friderike
>>
>>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Murray 
>> Richardson
>> Sent: 25 September 2008 06:01
>> To: r-sig-geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] select polygons in polygons
>>
>>
>> Hello users,
>>
>> There is probably a very simple solution to this that I am missing: 
>> is there a way to select polygons in one SPDF that fall within the 
>> polygons of another SPDF? This would save me a lot of processing time 
>> as I am having to take a very circuitous route to achieve the same 
>> outcome.
>>
>> Thanks!
>>
>> Murray
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch 
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9



From mao.loecher at gmail.com  Thu Sep 25 16:00:20 2008
From: mao.loecher at gmail.com (Markus Loecher)
Date: Thu, 25 Sep 2008 10:00:20 -0400
Subject: [R-sig-Geo] lat/lon to timezone
Message-ID: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080925/c84e3ecb/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Thu Sep 25 16:04:43 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 25 Sep 2008 15:04:43 +0100
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
Message-ID: <d8ad40b50809250704o67e2d51br935cfc9d626f2916@mail.gmail.com>

2008/9/25 Markus Loecher <mao.loecher at gmail.com>:
> Dear geo users,
> pardon this trivial question (I did not succeed in searching the archives):
> is there an R function in one of the many spatial packages which returns the
> time zone for a given lat/lon pair ?

I can't see anything trivial about implementing this:

http://www3.shastacollege.edu/dscollon/images/time_zone_map.JPG

Barry



From john.callahan at udel.edu  Thu Sep 25 16:19:56 2008
From: john.callahan at udel.edu (John Callahan)
Date: Thu, 25 Sep 2008 10:19:56 -0400
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
Message-ID: <48DB9E0C.9080309@udel.edu>

If there's not a function within R for this, maybe there's a way to use 
the web services from Geonames.org and parse the results.  Maybe this 
could be done within R, or in a separate script called by R.  I haven't 
used R enough to know if this is possible.

http://ws.geonames.org/timezone?lat=47.01&lng=10.2&style=full

- John




Markus Loecher wrote:
> Dear geo users,
> pardon this trivial question (I did not succeed in searching the archives):
> is there an R function in one of the many spatial packages which returns the
> time zone for a given lat/lon pair ?
>
> Thanks !
>
> Markus
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From b.rowlingson at lancaster.ac.uk  Thu Sep 25 16:52:42 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 25 Sep 2008 15:52:42 +0100
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <48DB9E0C.9080309@udel.edu>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
	<48DB9E0C.9080309@udel.edu>
Message-ID: <d8ad40b50809250752x747cfccboe19d78825b7c6fdd@mail.gmail.com>

2008/9/25 John Callahan <john.callahan at udel.edu>:
> If there's not a function within R for this, maybe there's a way to use the
> web services from Geonames.org and parse the results.  Maybe this could be
> done within R, or in a separate script called by R.  I haven't used R enough
> to know if this is possible.
>
> http://ws.geonames.org/timezone?lat=47.01&lng=10.2&style=full

  Oh well, in that case it is trivial...

getTZ <- function(lat,long){
  url=paste("http://ws.geonames.org/timezone?lat=",lat,"&lng=",long,"&style=full",sep="")
  u=url(url,open="r")
  text=readLines(u)
  tz = text[grep("timezoneId",text)]
  tz = sub("<timezoneId>","",tz)
  tz = sub("</timezoneId>","",tz)
  return(tz)
}

 note how I avoid parsing XML....

Barry



From murray.richardson at utoronto.ca  Thu Sep 25 16:52:41 2008
From: murray.richardson at utoronto.ca (Murray Richardson)
Date: Thu, 25 Sep 2008 10:52:41 -0400
Subject: [R-sig-Geo] select polygons in polygons
In-Reply-To: <48DB9608.90102@uni-muenster.de>
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B73@hqagex02.fao.org>
	<48DB9341.4010900@utoronto.ca> <48DB9608.90102@uni-muenster.de>
Message-ID: <48DBA5B9.4020207@utoronto.ca>

Thanks Edzer - I looked into it but I need to coerce the SPDF objects to 
gpc.poly objects and then I will lose all the attribute data I think. 

I may just have to use RODBC with postGIS to speed up the selection 
process, which has worked well for me in other situations, but makes the 
scripts that much more cumbersome.

cheers

Murray

Edzer Pebesma wrote:
> That's right, it is not there; I thought this morning about a way to 
> look whether all the points of one polygon fall in another, which sp's 
> overlay could do, but that's not a sufficient condition.
>
> Perhaps functions in package gpclib can do this?
> -- 
> Edzer
>
> Murray Richardson wrote:
>> Thanks Friderike.  I assumed this was the answer, but it doesn't 
>> appear to work with two SPDF objects.  i.e.:
>>
>> > overlay(polysA,polysB)
>> Error in function (classes, fdef, mtable)  :
>>  unable to find an inherited method for function "overlay", for 
>> signature "SpatialPolygonsDataFrame", "SpatialPolygonsDataFrame"
>>
>>
>> Murray
>>
>>
>> Oehler, Friderike (AGPP) wrote:
>>> Try ?overlay
>>>
>>> Regards,
>>> Friderike
>>>
>>>
>>> -----Original Message-----
>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Murray 
>>> Richardson
>>> Sent: 25 September 2008 06:01
>>> To: r-sig-geo at stat.math.ethz.ch
>>> Subject: [R-sig-Geo] select polygons in polygons
>>>
>>>
>>> Hello users,
>>>
>>> There is probably a very simple solution to this that I am missing: 
>>> is there a way to select polygons in one SPDF that fall within the 
>>> polygons of another SPDF? This would save me a lot of processing 
>>> time as I am having to take a very circuitous route to achieve the 
>>> same outcome.
>>>
>>> Thanks!
>>>
>>> Murray
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch 
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From john.callahan at udel.edu  Thu Sep 25 16:59:49 2008
From: john.callahan at udel.edu (John Callahan)
Date: Thu, 25 Sep 2008 10:59:49 -0400
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <d8ad40b50809250752x747cfccboe19d78825b7c6fdd@mail.gmail.com>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>	
	<48DB9E0C.9080309@udel.edu>
	<d8ad40b50809250752x747cfccboe19d78825b7c6fdd@mail.gmail.com>
Message-ID: <48DBA765.2010105@udel.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080925/02cf00a7/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Sep 25 17:06:34 2008
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 25 Sep 2008 17:06:34 +0200
Subject: [R-sig-Geo] select polygons in polygons
In-Reply-To: <48DBA5B9.4020207@utoronto.ca>
References: <1A28265B00AA7E4085BB761555D3FCE8033C8B73@hqagex02.fao.org>
	<48DB9341.4010900@utoronto.ca> <48DB9608.90102@uni-muenster.de>
	<48DBA5B9.4020207@utoronto.ca>
Message-ID: <48DBA8FA.8010702@uni-muenster.de>

If you're thinking the PostGIS route, you might also want to look at 
read/writeOGR in package rgdal, which has a postgis driver.

There are some examples of this (for points) on 
http://wiki.intamap.org/index.php/PostGIS
--
Edzer

Murray Richardson wrote:
> Thanks Edzer - I looked into it but I need to coerce the SPDF objects 
> to gpc.poly objects and then I will lose all the attribute data I think.
> I may just have to use RODBC with postGIS to speed up the selection 
> process, which has worked well for me in other situations, but makes 
> the scripts that much more cumbersome.
>
> cheers
>
> Murray
>
> Edzer Pebesma wrote:
>> That's right, it is not there; I thought this morning about a way to 
>> look whether all the points of one polygon fall in another, which 
>> sp's overlay could do, but that's not a sufficient condition.
>>
>> Perhaps functions in package gpclib can do this?
>> -- 
>> Edzer
>>
>> Murray Richardson wrote:
>>> Thanks Friderike.  I assumed this was the answer, but it doesn't 
>>> appear to work with two SPDF objects.  i.e.:
>>>
>>> > overlay(polysA,polysB)
>>> Error in function (classes, fdef, mtable)  :
>>>  unable to find an inherited method for function "overlay", for 
>>> signature "SpatialPolygonsDataFrame", "SpatialPolygonsDataFrame"
>>>
>>>
>>> Murray
>>>
>>>
>>> Oehler, Friderike (AGPP) wrote:
>>>> Try ?overlay
>>>>
>>>> Regards,
>>>> Friderike
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Murray 
>>>> Richardson
>>>> Sent: 25 September 2008 06:01
>>>> To: r-sig-geo at stat.math.ethz.ch
>>>> Subject: [R-sig-Geo] select polygons in polygons
>>>>
>>>>
>>>> Hello users,
>>>>
>>>> There is probably a very simple solution to this that I am missing: 
>>>> is there a way to select polygons in one SPDF that fall within the 
>>>> polygons of another SPDF? This would save me a lot of processing 
>>>> time as I am having to take a very circuitous route to achieve the 
>>>> same outcome.
>>>>
>>>> Thanks!
>>>>
>>>> Murray
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at stat.math.ethz.ch 
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>>
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster,
Weseler Stra?e 253, 48151 M?nster, Germany.  Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de/
http://www.springer.com/978-0-387-78170-9



From b.rowlingson at lancaster.ac.uk  Thu Sep 25 18:15:53 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 25 Sep 2008 17:15:53 +0100
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <48DBA765.2010105@udel.edu>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
	<48DB9E0C.9080309@udel.edu>
	<d8ad40b50809250752x747cfccboe19d78825b7c6fdd@mail.gmail.com>
	<48DBA765.2010105@udel.edu>
Message-ID: <d8ad40b50809250915u786bca45s4c11cc56fd93077c@mail.gmail.com>

2008/9/25 John Callahan <john.callahan at udel.edu>:
> That's a handy little script to have, and learn from.  Geonames.org also
> hosts web services for finding the elevation, nearby populated places,
> nearby Wikipedia entries, some reverse geocoding, and a few more.
> (http://www.geonames.org/export/web-services.html)   Thanks for posting the
> script!

 Of course it fails if you are onboard a ship in the ocean:

> getTZ(55,0)
[1] "<timezoneId/>"

 since my naive xml processor doesn't spot this...

 I would rewrite it to use library(XML) but there's no Windows binary
package for that on CRAN and it looks like overkill for a simple
application... Hmmm....

 Ooh. geonames has a JSON interface, and R has a nice lightweight
rjson package! Win!

getTZ <- function(lat,long){
  require(rjson)
  url=paste("http://ws.geonames.org/timezoneJSON?lat=",lat,"&lng=",long,"&style=full",sep="")
  u=url(url,open="r")
  tz = fromJSON(readLines(u))
  close(u)
  return(tz)
}

> getTZ(55,-2)$timezoneId
[1] "Europe/London"
> getTZ(55,0)$timezoneId
NULL

 This version also closes the url connection to avoid warnings.

Maaaarvellous!

Barry



From Greg.Snow at imail.org  Thu Sep 25 18:24:45 2008
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 25 Sep 2008 10:24:45 -0600
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6132C70FAC@LP-EXMBVS10.CO.IHC.COM>

I found a shapefile for a timezone map at http://openmap.bbn.com/data/shape/timezone/, you can load this in using maptools and related packages, then use any of the tools to find out which polygon your lat/long pair is in (doesn't work in the oceans, etc.) and look at its timezone data.

Hope this helps,

--
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-
> bounces at stat.math.ethz.ch] On Behalf Of Markus Loecher
> Sent: Thursday, September 25, 2008 8:00 AM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] lat/lon to timezone
>
> Dear geo users,
> pardon this trivial question (I did not succeed in searching the
> archives):
> is there an R function in one of the many spatial packages which
> returns the
> time zone for a given lat/lon pair ?
>
> Thanks !
>
> Markus
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From b.rowlingson at lancaster.ac.uk  Thu Sep 25 18:34:28 2008
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 25 Sep 2008 17:34:28 +0100
Subject: [R-sig-Geo] lat/lon to timezone
In-Reply-To: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6132C70FAC@LP-EXMBVS10.CO.IHC.COM>
References: <3827b1320809250700t375434e6x16b9b3c0cc893313@mail.gmail.com>
	<B37C0A15B8FB3C468B5BC7EBC7DA14CC6132C70FAC@LP-EXMBVS10.CO.IHC.COM>
Message-ID: <d8ad40b50809250934t241642b5k2ff67d532c4414c@mail.gmail.com>

2008/9/25 Greg Snow <Greg.Snow at imail.org>:
> I found a shapefile for a timezone map at http://openmap.bbn.com/data/shape/timezone/, you can load this in using maptools and related packages, then use any of the tools to find out which polygon your lat/long pair is in (doesn't work in the oceans, etc.) and look at its timezone data.

 I just tried opening that up in Qgis, and when I queried a couple of
the big regions of Canada Qgis didn't think I was clicking on
anything, despite them being shaded properly.

 A data error problem? Or maybe nobody in that area of Canada has a watch...

Barry



From Ingo.Holz at uni-hohenheim.de  Fri Sep 26 13:09:13 2008
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Fri, 26 Sep 2008 13:09:13 +0200
Subject: [R-sig-Geo] spplot() - "grouping variable"
Message-ID: <48DCDEF9.24418.126620F@ingoholz.uni-hohenheim.de>

Hi,

 I use spplot to display the values of a SpatialPointsDataFrame.

 spplot(SPDF[,"var1"], col.regions=rainbow(100), pch =16)

 I have different types of locations (forests, pastures, etc) and would like to 
change the "point character" (pch) according to this "grouping variable". Is 
this or something like this possible?

 Thank you for your help!

 Ingo



From Jason.Gasper at noaa.gov  Sat Sep 27 00:31:11 2008
From: Jason.Gasper at noaa.gov (Jason Gasper)
Date: Fri, 26 Sep 2008 14:31:11 -0800
Subject: [R-sig-Geo] Ordering shapefile
Message-ID: <48DD62AF.7050601@noaa.gov>

I am using the readShapePoly() function in the maptools package to read 
in shape files.  I need to order an attribute in the shapefile in 
ascending order. For example, I have three attributes: C1,C2,C3
             C1         C2         C3
[1,] -0.5658135  0.0374106 -1.7702093
[2,]  0.6783104 -0.1110221 -0.7005937
[3,] -0.2228110  0.9176706  1.7612472

ordered attributes based on ascending order in C2 would look like this:

             C1         C2         C3
[1,]  0.6783104 -0.1110221 -0.7005937
[2,] -0.5658135  0.0374106 -1.7702093
[3,] -0.2228110  0.9176706  1.7612472

The problem of course is that I am dealing with a shapefile and thus 
cannot treat the attributes as a vector using the "order" function.  Has 
anyone found a way to order attributes in a shapefile? The reason I need 
to do this is that I have a bunch of 0's that I will need to eliminate 
after spatial weights are created (using the poly2nb() and nb2WB() 
functions.  So I need the index for spatial weighting and cannot simply 
pull out each attribute and create a new sorted vector.



From patuelli at tin.it  Sat Sep 27 16:19:22 2008
From: patuelli at tin.it (Roberto Patuelli)
Date: Sat, 27 Sep 2008 16:19:22 +0200
Subject: [R-sig-Geo] Creating new neighbour's list for aggregated regions
	and writing to shapefile
Message-ID: <5218122D44DA437AB81FEF9A976CD136@Ciretto>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080927/0229ba11/attachment.pl>

From gavin.simpson at ucl.ac.uk  Sun Sep 28 12:42:39 2008
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sun, 28 Sep 2008 11:42:39 +0100
Subject: [R-sig-Geo] how to move a legend?
In-Reply-To: <f32286587fe7.48d3de84@lbl.gov>
References: <f32286587fe7.48d3de84@lbl.gov>
Message-ID: <1222598560.2724.7.camel@graptoleberis.geog.ucl.ac.uk>

On Fri, 2008-09-19 at 17:16 -0700, Marie-Anne C Serve wrote:
> Hello,
> I would like to know how i can move a color scale, now vertical and on
> the right of the plot, to a horizontal one at the bottom.
> i am using filled.contour().
> thanks
> Marie

[Haven't seen a response on list to this one]

You can't; this is a canned function that splits the region up for the
various bits of the plot.

Solutions: Either hack the R code for filled.contour to split the plot
up in a different way, or try lattice graphics where you have more
control over the placement of keys.

HTH

G

> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Sun Sep 28 15:14:42 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 28 Sep 2008 15:14:42 +0200 (CEST)
Subject: [R-sig-Geo] Creating new neighbour's list for aggregated
 regions and writing to shapefile
In-Reply-To: <5218122D44DA437AB81FEF9A976CD136@Ciretto>
References: <5218122D44DA437AB81FEF9A976CD136@Ciretto>
Message-ID: <Pine.LNX.4.64.0809281458100.7333@reclus.nhh.no>

On Sat, 27 Sep 2008, Roberto Patuelli wrote:

> Hi All,
>
> I want to aggregate my NUTS-3 regions in bigger ones, for which, of 
> course, I have corresponding codes. I have two main problems:
>
> 1) In terms of map visualization, I used unionSpatialPolygons(),
>    starting from my original shape file. At this point I would like to
>    write the resulting object out to a shape file by writePolyShape(),
>    but R gives me the following answer:  class(x) ==
>    "SpatialPolygonsDataFrame" is not TRUE

You have created a new SpatialPolygons object, say x, but shapefiles also 
need attribute data. As an absolute minimum, do

IDs <- sapply(slot(x, "polygons"), function(i) slot(i, "ID"))
# to retrieve the new IDs
df <- data.frame(y=rep(1, length(IDs)), row.names=IDs)
xx <- SpatialPolygonsDataFrame(x, data=df)
writePolyShape(xx, "filename")

>
> 2) In order to use spatial econometric techniques, I need to obtain a
>    new neighbours list. Because of islands problems that have already
>    been solved, rather than creating a new spatial weights matrix, I
>    would like to obtain this by aggregating the one based on the
>    original regions, or by aggregating directly the neighbour's set (a
>    listw object for example), if possible.

This looks like a new function for spdep, somewhat like the reverse of 
nb2blocknb(). If you could provide me with an example off-list, I'll see 
what can be done.

Roger

>
> Can anyone help on these two problems?
>
> Thanks and best regards,
> Roberto Patuelli
>
>
>
> ********************
> Roberto Patuelli, Ph.D.
> Post-doc researcher
> Institute for Economic Research (IRE)
> University of Lugano (USI)
> via Maderno 24, CP 4361
> CH-6904 Lugano
> Switzerland
> Phone: +41-(0)58-666-4166
> Email: roberto.patuelli at lu.unisi.ch
> ********************
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sun Sep 28 15:19:26 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 28 Sep 2008 15:19:26 +0200 (CEST)
Subject: [R-sig-Geo] Ordering shapefile
In-Reply-To: <48DD62AF.7050601@noaa.gov>
References: <48DD62AF.7050601@noaa.gov>
Message-ID: <Pine.LNX.4.64.0809281517070.7333@reclus.nhh.no>

On Fri, 26 Sep 2008, Jason Gasper wrote:

> I am using the readShapePoly() function in the maptools package to read in 
> shape files.  I need to order an attribute in the shapefile in ascending 
> order. For example, I have three attributes: C1,C2,C3
>            C1         C2         C3
> [1,] -0.5658135  0.0374106 -1.7702093
> [2,]  0.6783104 -0.1110221 -0.7005937
> [3,] -0.2228110  0.9176706  1.7612472
>
> ordered attributes based on ascending order in C2 would look like this:
>
>            C1         C2         C3
> [1,]  0.6783104 -0.1110221 -0.7005937
> [2,] -0.5658135  0.0374106 -1.7702093
> [3,] -0.2228110  0.9176706  1.7612472
>
> The problem of course is that I am dealing with a shapefile and thus cannot 
> treat the attributes as a vector using the "order" function.  Has anyone 
> found a way to order attributes in a shapefile? The reason I need to do this 
> is that I have a bunch of 0's that I will need to eliminate after spatial 
> weights are created (using the poly2nb() and nb2WB() functions.  So I need 
> the index for spatial weighting and cannot simply pull out each attribute and 
> create a new sorted vector.

Probably using the "[" method on the SpatialPolygonsDataFrame object:

library(spdep)
example(nc.sids)
nc.sids1 <- nc.sids[order(nc.sids$SID74),]
nc.sids$SID74
nc.sids1$SID74

Construct the indexing variable first if need be to check what is going 
on.

Hope this helps,

Roger

>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From milton.ruser at gmail.com  Sun Sep 28 20:08:40 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Sun, 28 Sep 2008 16:08:40 -0200
Subject: [R-sig-Geo] Ordering shapefile
In-Reply-To: <Pine.LNX.4.64.0809281517070.7333@reclus.nhh.no>
References: <48DD62AF.7050601@noaa.gov>
	<Pine.LNX.4.64.0809281517070.7333@reclus.nhh.no>
Message-ID: <3aaf1a030809281108k296e6243ya84afbd70a9725fa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080928/ef1bcff3/attachment.pl>

From mmcmanus at TNC.ORG  Mon Sep 29 19:57:02 2008
From: mmcmanus at TNC.ORG (Mike McManus)
Date: Mon, 29 Sep 2008 13:57:02 -0400
Subject: [R-sig-Geo] exporting Geoda data to R
Message-ID: <09E0E729716950479036D63B11FDA76A40E136@mail04.TNC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080929/96af028e/attachment.pl>

From mmcmanus at TNC.ORG  Mon Sep 29 21:03:36 2008
From: mmcmanus at TNC.ORG (Mike McManus)
Date: Mon, 29 Sep 2008 15:03:36 -0400
Subject: [R-sig-Geo] used read.dbf function from spsurvey
Message-ID: <09E0E729716950479036D63B11FDA76A40E164@mail04.TNC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080929/58a50daa/attachment.pl>

From milton.ruser at gmail.com  Mon Sep 29 21:39:45 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 29 Sep 2008 16:39:45 -0300
Subject: [R-sig-Geo] polygons from pixels.
Message-ID: <3aaf1a030809291239l2af8df2cxf619de8bcf0404e6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080929/8269d11f/attachment.pl>

From T.Hengl at uva.nl  Tue Sep 30 00:50:58 2008
From: T.Hengl at uva.nl (Hengl, T.)
Date: Tue, 30 Sep 2008 00:50:58 +0200
Subject: [R-sig-Geo] polygons from pixels.
References: <3aaf1a030809291239l2af8df2cxf619de8bcf0404e6@mail.gmail.com>
Message-ID: <37382E8DCB905042969BA78541F6570624D5E9@kwek.ic.uva.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080930/f5e064a9/attachment.pl>

From milton.ruser at gmail.com  Tue Sep 30 02:17:21 2008
From: milton.ruser at gmail.com (milton ruser)
Date: Mon, 29 Sep 2008 21:17:21 -0300
Subject: [R-sig-Geo] polygons from pixels.
In-Reply-To: <37382E8DCB905042969BA78541F6570624D5E9@kwek.ic.uva.nl>
References: <3aaf1a030809291239l2af8df2cxf619de8bcf0404e6@mail.gmail.com>
	<37382E8DCB905042969BA78541F6570624D5E9@kwek.ic.uva.nl>
Message-ID: <3aaf1a030809291717k3e7ee176u40b23c985582aaae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20080929/354e3d3c/attachment.pl>

From Roger.Bivand at nhh.no  Tue Sep 30 09:25:08 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Sep 2008 09:25:08 +0200 (CEST)
Subject: [R-sig-Geo] polygons from pixels.
In-Reply-To: <3aaf1a030809291239l2af8df2cxf619de8bcf0404e6@mail.gmail.com>
References: <3aaf1a030809291239l2af8df2cxf619de8bcf0404e6@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0809300913010.17321@reclus.nhh.no>

On Mon, 29 Sep 2008, milton ruser wrote:

> Dear RGeo-Gurus,
>
> I have a ASC file, and would like that each pixel come to be a polygon.
> Any help are welcome.
>
> require(rgdal)
> require(adehabitat)
>
> (file1 <-  paste(system.file(package = "adehabitat"),
>               "ascfiles/elevation.asc", sep = "/"))
> el <- readGDAL(file1)
> image(el, axes=T)

Something like this is in sp:

el1 <- as(el, "SpatialPixelsDataFrame")
el2 <- as(el1, "SpatialPolygons")
IDs <- sapply(slot(el2, "polygons"), function(x) slot(x, "ID"))
df <- as(el1, "data.frame")
row.names(df) <- IDs
el3 <- SpatialPolygonsDataFrame(el2, data=df)
spplot(el3, "band1", col.regions=heat.colors(20))

The actual coercion is from SpatialPixels to SpatialPolygons, so the data 
need to be put back in.

Roger

>
> best wishes,
>
> miltinho astronauta
> brazil
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Tue Sep 30 09:30:53 2008
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 30 Sep 2008 09:30:53 +0200 (CEST)
Subject: [R-sig-Geo] used read.dbf function from spsurvey
In-Reply-To: <09E0E729716950479036D63B11FDA76A40E164@mail04.TNC.ORG>
References: <09E0E729716950479036D63B11FDA76A40E164@mail04.TNC.ORG>
Message-ID: <Pine.LNX.4.64.0809300926100.17321@reclus.nhh.no>

On Mon, 29 Sep 2008, Mike McManus wrote:

> I was able to work around my export Geoda problem by using the read.dbf
> function in the spsurvey package.

Unless there is a good reason to use the read.dbf() implementation in 
spsurvey, you might prefer to choose the one in the foreign package 
(recommended package, present in all R installations). Although it is 
shapelib-based, it has been strengthened somewhat by Prof. Ripley (adding 
date representation handling), and is pretty robust.

Roger

> Mike
>
> Michael McManus
> Senior Aquatic Ecologist
> The Nature Conservancy
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From corey.sparks at UTSA.EDU  Tue Sep 30 14:40:16 2008
From: corey.sparks at UTSA.EDU (Corey Sparks)
Date: Tue, 30 Sep 2008 07:40:16 -0500
Subject: [R-sig-Geo] exporting Geoda data to R
In-Reply-To: <mailman.11.1222768802.753.r-sig-geo@stat.math.ethz.ch>
References: <mailman.11.1222768802.753.r-sig-geo@stat.math.ethz.ch>
Message-ID: <95CFBE72-C975-4F18-A3B8-AA0C75E9898B@utsa.edu>

Have you tried just reading the shapefile directly into R using the  
readShapePoly command in maptools.  spdep can form the neighbors and  
weights matrices from the shapefile, then you don't have to bother  
with the export.
Corey

On Sep 30, 2008, at 5:00 AM, r-sig-geo-request at stat.math.ethz.ch wrote:
>
> Message: 1
> Date: Mon, 29 Sep 2008 13:57:02 -0400
> From: "Mike McManus" <mmcmanus at TNC.ORG>
> Subject: [R-sig-Geo] exporting Geoda data to R
> To: <r-sig-geo at stat.math.ethz.ch>
> Message-ID: <09E0E729716950479036D63B11FDA76A40E136 at mail04.TNC.ORG>
> Content-Type: text/plain
>
> I  have exported data from Geoda to R in the past just fine.  However,
> with a file I am working on today when I used the Tools > Data Export
>> ASII in Geoda not all of the variable names in the file are listed  
>> for
> export.  Does anyone know why this might be happening?  I need to  
> bring
> that file, and its associated spatial weights, into spdep in R.   
> Could I
> by-pass the Geoda export step by saving the .dbf as a .csv file and  
> read
> that data file with the read.csv function and then read the .gal  
> spatial
> weights file with the read.gal function?
> Thanks,
> Mike
>
> Michael McManus
> Senior Aquatic Ecologist
> The Nature Conservancy
>
>
> 	[[alternative HTML version deleted]]
>
>

Corey Sparks
Assistant Professor
Department of Demography and Organization Studies
College of Public Policy
One UTSA Circle
San Antonio, TX 78239
corey.sparks at utsa.edu



