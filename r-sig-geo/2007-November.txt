From levidrose at gmail.com  Thu Nov  1 03:03:03 2007
From: levidrose at gmail.com (Levi Rose)
Date: Wed, 31 Oct 2007 20:03:03 -0600
Subject: [R-sig-Geo] "Flipping" coverages and/or shapefiles
Message-ID: <a1762780710311903r47aad010xa228fa24d9391eae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071031/0f1f2880/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov  1 08:38:12 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 1 Nov 2007 08:38:12 +0100 (CET)
Subject: [R-sig-Geo] "Flipping" coverages and/or shapefiles
In-Reply-To: <a1762780710311903r47aad010xa228fa24d9391eae@mail.gmail.com>
References: <a1762780710311903r47aad010xa228fa24d9391eae@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0711010833560.23377@reclus.nhh.no>

On Wed, 31 Oct 2007, Levi Rose wrote:

> Hello everyone,
>
> I have coverages and shapefiles that are oriented incorrectly.  I need to be
> able to reorient the datasets by turning them over, from top to bottom,
> along the horizontal axis.  ArcToolbox has an exact function for Raster data
> in Data Management (Flip), with command line syntax for scripting.  I know
> how to manually flip the shapefiles and coverages, but I have around 1000
> files to transform, so it would be much more efficient to run a script. Does
> anyone know of command line syntax for a similar function with vector data?
>
> I have come very close to "flipping" the coverage files, but I'm stuck on
> how to update/change the x,y coordinates in tic files.  The RArcInfo package
> will allow you to read tic files via the "get.tabledata" function, but does
> not have a write table function that I'm aware of.  I would greatly
> appreciate any input or strategies to unravel this mystery.

Could you look at elide() in the maptools package? It isn't exactly what 
you are asking for, but probably quite close:

library(maptools)
xx <- readShapePoly(system.file("shapes/sids.shp", package="maptools")[1],
  IDvar="FIPSNO")
par(opar)
opar <- par(mfrow=c(2,1))
plot(xx, axes=TRUE)
plot(elide(xx, reflect=c(FALSE, TRUE)), axes=TRUE)

Looking at the code in elide should provide what you need to make a more 
exact fit.

Roger

>
> Cheers,
> Levi
>
>
> Research Assistant
> Dept. of Watershed Sciences
> Utah State University
> 5210 Old Main
> Logan, Utah 84322
> (740)-591-1750
> LeviDRose at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From loecher at eden.rutgers.edu  Thu Nov  1 16:00:58 2007
From: loecher at eden.rutgers.edu (Markus Loecher)
Date: Thu, 1 Nov 2007 11:00:58 -0400 (EDT)
Subject: [R-sig-Geo] plot.Map deprecated, alternative ?
Message-ID: <10877951.1157941193929258370.JavaMail.tomcat@aveo>

Dear all, 
I understand that plot.Map (the default method for plotting shape objects) is deprecated, however I have not found a working method converting my shape file into either a polylist or sp class.
I tried the following 
   p2roads <- read.shape("sf.shp")
  SF.map <- Map2poly(p2roads)
where sf.shp is a shape object of the San Francisco street map, and get the following error message:
   Error in Map2poly(p2roads) : maptype not poly
Are there differences between shape files ? Which other way could I try to convert my shape object so that plot.Spatial will work ?

Thanks !

Markus



From Roger.Bivand at nhh.no  Thu Nov  1 16:12:03 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 1 Nov 2007 16:12:03 +0100 (CET)
Subject: [R-sig-Geo] plot.Map deprecated, alternative ?
In-Reply-To: <10877951.1157941193929258370.JavaMail.tomcat@aveo>
References: <10877951.1157941193929258370.JavaMail.tomcat@aveo>
Message-ID: <Pine.LNX.4.64.0711011609260.23377@reclus.nhh.no>

On Thu, 1 Nov 2007, Markus Loecher wrote:

> Dear all,
> I understand that plot.Map (the default method for plotting shape objects) is deprecated, however I have not found a working method converting my shape file into either a polylist or sp class.
> I tried the following
>   p2roads <- read.shape("sf.shp")
>  SF.map <- Map2poly(p2roads)
> where sf.shp is a shape object of the San Francisco street map, and get the following error message:
>   Error in Map2poly(p2roads) : maptype not poly
> Are there differences between shape files ? Which other way could I try to convert my shape object so that plot.Spatial will work ?

For example:

library(maptools)
getinfo.shape("sf.shp")
# presumably lines
roads <- readShapeLines("sf.shp")
class(roads)
plot(roads, axes=TRUE)

or

library(rgdal)
roads <- readOGR(".", "sf")
class(roads)
plot(roads, axes=TRUE)

Roger


>
> Thanks !
>
> Markus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Jin.Li at ga.gov.au  Thu Nov  1 23:56:52 2007
From: Jin.Li at ga.gov.au (Jin.Li at ga.gov.au)
Date: Fri, 2 Nov 2007 09:56:52 +1100
Subject: [R-sig-Geo] Add coastline to an existing xyplot [SEC=UNCLASSIFIED]
Message-ID: <8BD19F29B0E16E4F88277A997CD872C202A29C26@mail.ga.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071102/ae0029f9/attachment.pl>

From felix at nfrac.org  Fri Nov  2 03:26:32 2007
From: felix at nfrac.org (Felix Andrews)
Date: Fri, 2 Nov 2007 13:26:32 +1100
Subject: [R-sig-Geo] Add coastline to an existing xyplot
	[SEC=UNCLASSIFIED]
In-Reply-To: <8BD19F29B0E16E4F88277A997CD872C202A29C26@mail.ga.gov.au>
References: <8BD19F29B0E16E4F88277A997CD872C202A29C26@mail.ga.gov.au>
Message-ID: <94730b8a0711011926h16817adck6a050565522b8c89@mail.gmail.com>

plot() is a base graphics function. You can not use it in a Lattice
context. And also you can not add to a Lattice plot as you tried to
do: you need to use a panel function, or call trellis.focus(). I
suggest you read the Lattice documentation.

This is one way to do it:

library(sp)

xyplot(lat ~ long, data=mud, panel=function(...) {
sp.polygons(coastline)
panel.xyplot(...)
},
asp="iso", type="p", pch=1, cex=0.01, xlab="", ylab="")



On 11/2/07, Jin.Li at ga.gov.au <Jin.Li at ga.gov.au> wrote:
> Hi there,
>
> I tried to add a coastline that is imported from a shapefile to a xyplot of
> sample points, but I got an error message.
>
>
>
> > library(lattice)
>
> > library(maptools)
>
> > xyplot(mud$lat~mud$long, asp="iso", type="p", pch=1, cex=0.01, xlab="",
> ylab="")
>
> >
>
> > plot(coastline, add=T)
>
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
>
>         plot.new has not been called yet
>
> >
>
> I also tried using plot.new=TRUE in the xyplot and got the same message.
>
>
>
> I could get a plot from only using plot(coastline),  but could not add it to
> the existing xyplot.
>
>
>
> Thanks in advance.
>
> Jin
>
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
Felix Andrews / ???
PhD candidate
Integrated Catchment Assessment and Management Centre
The Fenner School of Environment and Society
The Australian National University (Building 48A), ACT 0200
Beijing Bag, Locked Bag 40, Kingston ACT 2604
http://www.neurofractal.org/felix/
3358 543D AAC6 22C2 D336  80D9 360B 72DD 3E4C F5D8



From hi_ono2001 at ybb.ne.jp  Fri Nov  2 09:09:43 2007
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Fri, 2 Nov 2007 17:09:43 +0900 (JST)
Subject: [R-sig-Geo] Divide a polygon by a line?
In-Reply-To: <Pine.LNX.4.64.0710302018000.14848@reclus.nhh.no>
Message-ID: <20071102080943.46205.qmail@web10707.mail.bbt.yahoo.co.jp>

Hi.

 I've create very simple example "cutting polygon by line
c(0,5,10,5)" using by gpclib.

library(maptools)
library(gpclib)

 x1<-t(structure(c(0,0,10,0,10,10,0,10,0,0),dim=c(2,5))) #
simple square


### method  using buffer

 min_buffer_dist <- 1e-10 # set minimum value

x2<-t(structure(c(-1,5,11,5+min_buffer_dist,11,5-min_buffer_dist,-1,5),dim=c(2,4)))
# buffered similar line as polygon
# x2<-t(structure(c(-1,5,11,5,11,5,-1,5),dim=c(2,4))) # 
this line can't cut square, just vanished.
 plot(setdiff(as(x1,"gpc.poly"),as(x2,"gpc.poly"))) # plot
result




 Regards.


--- Roger Bivand <Roger.Bivand at nhh.no> wrote:

> On Tue, 30 Oct 2007, Agustin Lobo wrote:
> 
> > Is it possible to divide a polygon by a line
> > into 2 polygons?
> 
> No, in general. All computational geometry ends up
> in having to deal with 
> the type of polygon. A convex polygon is one thing,
> and can be divided 
> into two parts, but a general polygon may be
> concave, and the number of 
> parts does not have to be two - the line could cross
> it multiple times. 
> The approach taken in the Rgshhs function in
> maptools is to overlay a 
> rectangular box over the polygon(s), and see what
> comes out, but quite 
> often it isn't two (or in that case a single part
> within the rectangle).
> 
> Roger
> 
> >
> > Agus
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics,
> Norwegian School of
> Economics and Business Administration, Helleveien
> 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Agustin.Lobo at ija.csic.es  Fri Nov  2 09:29:30 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Fri, 02 Nov 2007 09:29:30 +0100
Subject: [R-sig-Geo] Divide a polygon by a line?
In-Reply-To: <20071102080943.46205.qmail@web10707.mail.bbt.yahoo.co.jp>
References: <20071102080943.46205.qmail@web10707.mail.bbt.yahoo.co.jp>
Message-ID: <472ADFEA.5090500@ija.csic.es>

Thanks Hisaji,

The problem is that my line is not an straight line, but
a very complex polyline (a boundary between types of forest
manually digitized over aerial photography) imported from a shp file
into a SpatialLinesDataFrame object.

Regards,

Agus

Hisaji ONO escribio':
> Hi.
> 
>  I've create very simple example "cutting polygon by line
> c(0,5,10,5)" using by gpclib.
> 
> library(maptools)
> library(gpclib)
> 
>  x1<-t(structure(c(0,0,10,0,10,10,0,10,0,0),dim=c(2,5))) #
> simple square
> 
> 
> ### method  using buffer
> 
>  min_buffer_dist <- 1e-10 # set minimum value
> 
> x2<-t(structure(c(-1,5,11,5+min_buffer_dist,11,5-min_buffer_dist,-1,5),dim=c(2,4)))
> # buffered similar line as polygon
> # x2<-t(structure(c(-1,5,11,5,11,5,-1,5),dim=c(2,4))) # 
> this line can't cut square, just vanished.
>  plot(setdiff(as(x1,"gpc.poly"),as(x2,"gpc.poly"))) # plot
> result
> 
> 
> 
> 
>  Regards.
> 
> 
> --- Roger Bivand <Roger.Bivand at nhh.no> wrote:
> 
>> On Tue, 30 Oct 2007, Agustin Lobo wrote:
>>
>>> Is it possible to divide a polygon by a line
>>> into 2 polygons?
>> No, in general. All computational geometry ends up
>> in having to deal with 
>> the type of polygon. A convex polygon is one thing,
>> and can be divided 
>> into two parts, but a general polygon may be
>> concave, and the number of 
>> parts does not have to be two - the line could cross
>> it multiple times. 
>> The approach taken in the Rgshhs function in
>> maptools is to overlay a 
>> rectangular box over the polygon(s), and see what
>> comes out, but quite 
>> often it isn't two (or in that case a single part
>> within the rectangle).
>>
>> Roger
>>
>>> Agus
>>>
>> -- 
>> Roger Bivand
>> Economic Geography Section, Department of Economics,
>> Norwegian School of
>> Economics and Business Administration, Helleveien
>> 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> 
> 
> 
> ------------------------------------------------------------------------
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Fri Nov  2 13:16:18 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 2 Nov 2007 13:16:18 +0100 (CET)
Subject: [R-sig-Geo] centering explanatory variables around spatial lag
In-Reply-To: <1193863597.4728e9ae0050b@webmail.pobox.upenn.edu>
References: <loom.20071030T133119-294@post.gmane.org>
	<47283CCE.9090109@uni-muenster.de>
	<4728A0A1.4000207@zevross.com> <4728AFE5.3080404@uni-muenster.de>
	<4728B219.8020707@zevross.com>
	<1193863597.4728e9ae0050b@webmail.pobox.upenn.edu>
Message-ID: <Pine.LNX.4.64.0711021311580.27501@reclus.nhh.no>

On Wed, 31 Oct 2007, Sam Field wrote:

> List,
>
> When the influence of explanatory variables "spills over" into adjacent 
> or proximate spatial units, one way to model this would be to include a 
> spatially lagged explanatory variable (WX). If there exists a 
> significant spatially lagged association, then (it would seem to me) the 
> influence of X would be biased if it is correlated with WX (which it 
> would be if X was non_randomly distributed in space). In other words, 
> the effect of X is confounded with WX if the two are correlated AND both 
> have independent impacts on the outcome.  It would seem that a properly 
> specified model would include both the effects of X and WX.  One 
> potential problem is that X and WX maybe highly correlated leading to 
> instability in the estimation of their independent effects.  It seems a 
> solution, analogous to what is often done in multi-level models, is to 
> center X on its spatial average, WX.  Thus,
>
> yhat = b0 + b1(X - WX) + b2(WX).
>
> where the influence of WX is now a function of two parameters: (b2-b1)WX 
> and the null H0:b2-b1 = 0
>
> Is there a reason not to do this with spatially lagged explanatory 
> variables? Is there any literature on this?  I have an empirical example 
> in which the results from centering versus non centering differ 
> dramatically, so I want to make sure that the situation is analogous to 
> the multi-level case before proceeding.  I could do some simulation, but 
> I thought I would ask the list first.
>

I'm not aware of work that has reported this approach, though use of WX 
and WWX as instruments for WY is known. I think that it would be 
interesting to pursue, if only to conclude that it doesn't help. One would 
still need to be fairly sure that there were no substantive missing X, and 
no X with the wrong functional form, in addition to choosing a likely and 
parsimonious W.

Roger

>
>
> thanks!
>
>
>
> Sam
>
>
>
>
>
>
>
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From honey_giroday at hotmail.com  Fri Nov  2 19:25:14 2007
From: honey_giroday at hotmail.com (Honey Giroday)
Date: Fri, 2 Nov 2007 18:25:14 +0000
Subject: [R-sig-Geo] Spatial join of a point and polygon shapefile
Message-ID: <BAY104-W37FB1F6E620E923C14115C8A8D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071102/97120428/attachment.pl>

From Roger.Bivand at nhh.no  Fri Nov  2 21:29:36 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 2 Nov 2007 21:29:36 +0100 (CET)
Subject: [R-sig-Geo] Spatial join of a point and polygon shapefile
In-Reply-To: <BAY104-W37FB1F6E620E923C14115C8A8D0@phx.gbl>
References: <BAY104-W37FB1F6E620E923C14115C8A8D0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0711022119350.28520@reclus.nhh.no>

On Fri, 2 Nov 2007, Honey Giroday wrote:

>
> Hi everyone

> I am a new useR running R on a Windows platform with Emacs.  I have been 
> searching package manuals and email archives trying to solve this 
> problem but have been unable to find a solution.  Your help with this is 
> appreciated.
>
> I have generated random points within a polygon shapefile (with 1 
> polygon) using dotsInPolys.  I now want to sample a field (attribute 
> data) of another polygon shapefile (with >>> 1 polygon) to add data to 
> the points dataframe based on the point's spatial location (known by 
> ArcView user's as a spatial join).  Is there a command in one of the 
> spatial packages that would allow me to do this (I have found join.asc; 
> however, I am looking for a command that will allow me to join vector 
> data).  As I am new to posting, suggestions for clarifying my question 
> or additional details I should provide would be appreciated.  Thank you 
> for your time.

Welcome!

If you can make (or import) your points and polygons into SpatialPoints 
and SpatialPolygons, as defined in the sp package, the overlay methods 
there will do this for you. Overlaying the points on the polygons will 
yield a vector as long as the number of points with NA where they miss the 
polygons, and numbers between 1 and n (# polygons) saying which polygon 
the point falls in.

You could also have used the spsample methods there too for generating the 
points. If your polygons are coming from shapefiles, then readShapePoly() 
in the maptools package will make them into SpatialPolygonsDataFrame 
objects (or readOGR() in rgdal, which also reads other vector file 
formats). There was a thread on sampling on this list last month which you 
might find entertaining, you have found yet another way:

https://stat.ethz.ch/pipermail/r-sig-geo/2007-October/002625.html

Roger

>
> Sincerely,
>
>
>
>
>
>
> Honey-Marie Giroday, M.Sc. Candidate, A.Ag., B.I.T. University of Northern British Columbia Prince George, BC, Canada
>
> _________________________________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From johan.vandewauw at gmail.com  Fri Nov  2 22:21:45 2007
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Fri, 2 Nov 2007 22:21:45 +0100
Subject: [R-sig-Geo] Spatial join of a point and polygon shapefile
In-Reply-To: <BAY104-W37FB1F6E620E923C14115C8A8D0@phx.gbl>
References: <BAY104-W37FB1F6E620E923C14115C8A8D0@phx.gbl>
Message-ID: <791a12030711021421j720ace6eg266e09dca905518c@mail.gmail.com>

This is what I usually do:
(points is a dataframe with x and y columns)

library("sp")
coordinates(points)=~x+y
polygon<-readShapePoly("shapefile.shp")
a<-overlay(points,polygon)
# a will contain the id's of the polygons per point
# . to get the attributes for every point I use:
polygon[a,]@data

--
Johan


On Nov 2, 2007 7:25 PM, Honey Giroday <honey_giroday at hotmail.com> wrote:
>
> Hi everyone
> I am a new useR running R on a Windows platform with Emacs.  I have been searching package manuals and email archives trying to solve this problem but have been unable to find a solution.  Your help with this is appreciated.
>
> I have generated random points within a polygon shapefile (with 1 polygon) using dotsInPolys.  I now want to sample a field (attribute data) of another polygon shapefile (with >>> 1 polygon) to add data to the points dataframe based on the point's spatial location (known by ArcView user's as a spatial join).  Is there a command in one of the spatial packages that would allow me to do this (I have found join.asc; however, I am looking for a command that will allow me to join vector data).  As I am new to posting, suggestions for clarifying my question or additional details I should provide would be appreciated.  Thank you for your time.
>
> Sincerely,
>
>
>
>
>
>
> Honey-Marie Giroday, M.Sc. Candidate, A.Ag., B.I.T. University of Northern British Columbia Prince George, BC, Canada
>
> _________________________________________________________________
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From hiemstra at geo.uu.nl  Sat Nov  3 01:20:26 2007
From: hiemstra at geo.uu.nl (hiemstra at geo.uu.nl)
Date: Sat, 3 Nov 2007 01:20:26 +0100 (CET)
Subject: [R-sig-Geo] Add coastline to an existing xyplot
 [SEC=UNCLASSIFIED]
In-Reply-To: <8BD19F29B0E16E4F88277A997CD872C202A29C26@mail.ga.gov.au>
References: <8BD19F29B0E16E4F88277A997CD872C202A29C26@mail.ga.gov.au>
Message-ID: <46106.62.45.82.84.1194049226.squirrel@webmail.geo.uu.nl>

Hi,

You could use the function spplot in the sp-pacakge. Use the sp.layout 
argument to add the shapefile to the plot. All the data needs to be in 
one of the Spatial classes provided by the sp-package. The code could 
look something like:

library(sp)
library(maptools)
points = read.table("points.csv")
coordinates(points) = ~x+y
shape_coast = readShapePoly("coast.shp") # Function from maptools
spplot(points, "attribute1", sp.layout = list("sp.polygons", shape_coast))
?spplot

hth,
Paul

Jin.Li at ga.gov.au wrote:
> Hi there,
> I tried to add a coastline that is imported from a shapefile to a xyplot
of
> sample points, but I got an error message.
>
>
>> library(lattice)
>>
>
>> library(maptools)
>>
>
>> xyplot(mud$lat~mud$long, asp="iso", type="p", pch=1, cex=0.01, xlab="",
>>
> ylab="")
>
>
>> plot(coastline, add=T)
>>
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
>         plot.new has not been called yet
>
> I also tried using plot.new=TRUE in the xyplot and got the same message.
>
> I could get a plot from only using plot(coastline),  but could not add
it to
> the existing xyplot.
>
> Thanks in advance.
> Jin
>
> 	[[alternative HTML version deleted]]
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Agustin.Lobo at ija.csic.es  Sat Nov  3 13:17:02 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Sat, 03 Nov 2007 13:17:02 +0100
Subject: [R-sig-Geo] convUL: wrong for Southern hemisphere
Message-ID: <472C66BE.8050003@ija.csic.es>

Dear list,

For negative latitudes (Southern hemisphere), convUL yields negative UTM 
coordinates as
for Northern hemisphere, instead of positive UTMY coordinates for the
South.  I don't see any option for modifying this behavior, is it?
The same is true for spTransform, can't fnd the way of stating that
the utm zone is in the Southern hemisphere (which should not be
required, because of the negative latitude)
spTransform(tomas1sp, CRS("+proj=utm +zone=19 +ellps=WGS84"))
yields negative UTMY coordinates and
spTransform(tomas1sp, CRS("+proj=utm +zone=-19 +ellps=WGS84"))
an error

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Roger.Bivand at nhh.no  Sat Nov  3 14:25:42 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 3 Nov 2007 14:25:42 +0100 (CET)
Subject: [R-sig-Geo] convUL: wrong for Southern hemisphere
In-Reply-To: <472C66BE.8050003@ija.csic.es>
References: <472C66BE.8050003@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0711031415240.30850@reclus.nhh.no>

On Sat, 3 Nov 2007, Agustin Lobo wrote:

> Dear list,
>
> For negative latitudes (Southern hemisphere), convUL yields negative UTM
> coordinates as
> for Northern hemisphere, instead of positive UTMY coordinates for the
> South.  I don't see any option for modifying this behavior, is it?
> The same is true for spTransform, can't fnd the way of stating that
> the utm zone is in the Southern hemisphere (which should not be
> required, because of the negative latitude)
> spTransform(tomas1sp, CRS("+proj=utm +zone=19 +ellps=WGS84"))
> yields negative UTMY coordinates and
> spTransform(tomas1sp, CRS("+proj=utm +zone=-19 +ellps=WGS84"))

Well, it is an error. It is not accepted that a negative zone number is 
what is needed to add the y offset. In PROJ.4 notation, you simply add 
+south to the definition:

> library(rgdal)
> CRS("+init=epsg:32719")
CRS arguments:
  +init=epsg:32719 +proj=utm +zone=19 +south +ellps=WGS84 +datum=WGS84
+units=m +no_defs +towgs84=0,0,0

Details at:

http://www.remotesensing.org/geotiff/proj_list/transverse_mercator.html

Other notations may vary, but just assuming that minus indicates south is 
overoptimistic.

Roger

> an error
>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Agustin.Lobo at ija.csic.es  Sat Nov  3 15:05:45 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Sat, 03 Nov 2007 15:05:45 +0100
Subject: [R-sig-Geo] convUL: wrong for Southern hemisphere
In-Reply-To: <Pine.LNX.4.64.0711031415240.30850@reclus.nhh.no>
References: <472C66BE.8050003@ija.csic.es>
	<Pine.LNX.4.64.0711031415240.30850@reclus.nhh.no>
Message-ID: <472C8039.1080100@ija.csic.es>

But negative latitude indicates Southern Hemisphere and negative
longitude indicates West of Greenwich, this is standard and correct.
Thus, just by having negative latitudes, the correct UTMY should
be calculated. Note that if +zone is omitted, the correct 19 zone
is calculated, hence accepting and correctly interpreting the negative
longitudes (+zone is provided for forcing coordinates according to another
zone, which is useful when you are working in 2 zones and decide
to have coordinates as for one single zone, otherwise +zone is not 
required).  The same should be done for the negative latitudes and
calculate the correct UTMY in the Southern Hemisphere.

Anyway, +south solves the problem for spTransform, thanks a lot:

 > tomas1sp
            coordinates V1         V2 V3     V4 V5     V6
1 (-66.6065, -14.8974)  1   Manguito 14 53.846 66 36.393
2 (-66.6475, -14.7857)  2 CampoBEllo 14 47.141 66 38.852
3 (-66.6633, -14.8128)  3 SanAntonio 14 48.771 66 39.801
4 (-66.6939, -14.8583)  4 Pto.Mendez 14 51.498 66 41.634
5 (-66.7367, -14.9731)  5     LaCRuz 14 58.385 66 44.204

 > spTransform(tomas1sp, CRS("+proj=utm +zone=19 +ellps=WGS84 +south"))
         coordinates V1         V2 V3     V4 V5     V6
1 (757501, 8351630)  1   Manguito 14 53.846 66 36.393
2 (753220, 8364050)  2 CampoBEllo 14 47.141 66 38.852
3 (751485, 8361060)  3 SanAntonio 14 48.771 66 39.801
4 (748144, 8356070)  4 Pto.Mendez 14 51.498 66 41.634
5 (743404, 8343410)  5     LaCRuz 14 58.385 66 44.204

(no solution for convUL(), though, just to mention it)

Agus


Roger Bivand escribi?:
> On Sat, 3 Nov 2007, Agustin Lobo wrote:
> 
>> Dear list,
>>
>> For negative latitudes (Southern hemisphere), convUL yields negative UTM
>> coordinates as
>> for Northern hemisphere, instead of positive UTMY coordinates for the
>> South.  I don't see any option for modifying this behavior, is it?
>> The same is true for spTransform, can't fnd the way of stating that
>> the utm zone is in the Southern hemisphere (which should not be
>> required, because of the negative latitude)
>> spTransform(tomas1sp, CRS("+proj=utm +zone=19 +ellps=WGS84"))
>> yields negative UTMY coordinates and
>> spTransform(tomas1sp, CRS("+proj=utm +zone=-19 +ellps=WGS84"))
> 
> Well, it is an error. It is not accepted that a negative zone number is 
> what is needed to add the y offset. In PROJ.4 notation, you simply add 
> +south to the definition:
> 
>> library(rgdal)
>> CRS("+init=epsg:32719")
> CRS arguments:
>  +init=epsg:32719 +proj=utm +zone=19 +south +ellps=WGS84 +datum=WGS84
> +units=m +no_defs +towgs84=0,0,0
> 
> Details at:
> 
> http://www.remotesensing.org/geotiff/proj_list/transverse_mercator.html
> 
> Other notations may vary, but just assuming that minus indicates south 
> is overoptimistic.
> 
> Roger
> 
>> an error
>>
>> Agus
>>
>>
> 

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From Agustin.Lobo at ija.csic.es  Sun Nov  4 17:36:28 2007
From: Agustin.Lobo at ija.csic.es (Agustin Lobo)
Date: Sun, 04 Nov 2007 17:36:28 +0100
Subject: [R-sig-Geo] spRbind() limited to 2 objects?
Message-ID: <472DF50C.5050204@ija.csic.es>

Is spRbind() limited to 2 objects? It seems so but this
detail is not mentioned in the doc. Note:

> class(pols.ferns1)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
> class(pols.ferns2)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
> class(pols.ferns3)
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
> class(spRbind(pols.ferns2,pols.ferns3))
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
> class(spRbind(pols.ferns1,pols.ferns3))
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"
> class(spRbind(pols.ferns1,pols.ferns2,pols.ferns3))
Error in spRbind(pols.ferns1, pols.ferns2, pols.ferns3) :
   unused argument(s) (<S4 object of class "SpatialPolygonsDataFrame">)
> class(spRbind(spRbind(pols.ferns1,pols.ferns2),pols.ferns3))
[1] "SpatialPolygonsDataFrame"
attr(,"package")
[1] "sp"

Thanks!

Agus

-- 
Dr. Agustin Lobo
Institut de Ciencies de la Terra "Jaume Almera" (CSIC)
LLuis Sole Sabaris s/n
08028 Barcelona
Spain
Tel. 34 934095410
Fax. 34 934110012
email: Agustin.Lobo at ija.csic.es
http://www.ija.csic.es/gt/obster



From friedman.steve at gmail.com  Sun Nov  4 18:14:30 2007
From: friedman.steve at gmail.com (Steve Friedman)
Date: Sun, 4 Nov 2007 12:14:30 -0500
Subject: [R-sig-Geo] working with Z values in spatial data frames
Message-ID: <2439f5740711040914j60726de8q51183f0731631a76@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071104/e6e184bb/attachment.pl>

From Roger.Bivand at nhh.no  Sun Nov  4 18:27:08 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 4 Nov 2007 18:27:08 +0100 (CET)
Subject: [R-sig-Geo] spRbind() limited to 2 objects?
In-Reply-To: <472DF50C.5050204@ija.csic.es>
References: <472DF50C.5050204@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0711041816290.11546@reclus.nhh.no>

On Sun, 4 Nov 2007, Agustin Lobo wrote:

> Is spRbind() limited to 2 objects? It seems so but this
> detail is not mentioned in the doc. Note:

Well, the signatures are for two objects of the same class only, so the 
most direct reading is that the spRbind methods in maptools take two and 
only two objects.

The rbind and cbind functions in R base are not methods, and do not do 
method dispatch.

There are also rbind.*  methods in sp which do essentially the same thing, 
can take multiple objects, but only dispatch on the class of the first 
object, so error terminate if one of the remaining objects is not of the 
same class.

The spRbind methods were thought of as being able to accumulate within a 
loop, or by multiple applications as you show.

Roger

>
>> class(pols.ferns1)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> class(pols.ferns2)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> class(pols.ferns3)
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> class(spRbind(pols.ferns2,pols.ferns3))
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> class(spRbind(pols.ferns1,pols.ferns3))
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>> class(spRbind(pols.ferns1,pols.ferns2,pols.ferns3))
> Error in spRbind(pols.ferns1, pols.ferns2, pols.ferns3) :
>   unused argument(s) (<S4 object of class "SpatialPolygonsDataFrame">)
>> class(spRbind(spRbind(pols.ferns1,pols.ferns2),pols.ferns3))
> [1] "SpatialPolygonsDataFrame"
> attr(,"package")
> [1] "sp"
>
> Thanks!
>
> Agus
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Sun Nov  4 21:14:15 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 4 Nov 2007 21:14:15 +0100 (CET)
Subject: [R-sig-Geo] "Abridged" description of SpatialPolygonsDataFrame
 objects?
In-Reply-To: <4725B1E7.5030903@utas.edu.au>
References: <4725A4EE.8030406@ija.csic.es> <4725B1E7.5030903@utas.edu.au>
Message-ID: <Pine.LNX.4.64.0711042110350.11546@reclus.nhh.no>

On Mon, 29 Oct 2007, Michael Sumner wrote:

> If "d" is a SPolyDF
>
> ## first row/object
> d[1,]
> str(d[1,])
>
> ## the first Polygons object itself  (Polygons can be of many)
> d at polygons[[1]]
> str(d at polygons[[1]])
>
> ## the first Polygon in the first Polygons object
> d at polygons[[1]]@Polygons[[1]]
> str(d at polygons[[1]]@Polygons[[1]])
>

Another possibility is to use the arguments to str(), in particular, 
setting max.level=2 prevents str() going into deeper levels of the nested 
object. Judicious use of slot() in str(), with the max.level= gives a good 
degree of control.

Roger

>
>
> Agustin Lobo wrote:
>> Hi!
>>
>> If I do str(a) where a is a SpatialGridDataFrame, I get
>> a description of the structure that is readable,
>> but for SpatialPolygonsDataFrame the output of str() is
>> too long. Is there any way of looking at the
>> structure of a SpatialPolygonsDataFrame object just down to
>> a certain level? For example, not getting the structure of the
>> each polygon but getting the first one only.
>>
>> Thanks
>> Agus
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mdsumner at utas.edu.au  Mon Nov  5 10:14:25 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 05 Nov 2007 20:14:25 +1100
Subject: [R-sig-Geo] working with Z values in spatial data frames
In-Reply-To: <2439f5740711040914j60726de8q51183f0731631a76@mail.gmail.com>
References: <2439f5740711040914j60726de8q51183f0731631a76@mail.gmail.com>
Message-ID: <472EDEF1.1080606@utas.edu.au>

Here's one simple way, using package akima:


library(sp)

data(meuse)

## assume your data is Spatial*

coordinates(meuse) <- ~x+y



## use "elev" column in akima
library(akima)

## define a grid
xx <- coordinates(meuse)[,1]
yy <- coordinates(meuse)[,2]
## modify offset of 100 to match your data, or use a proportion
grd <- expand.grid(x = seq(min(xx) - 200,  max(xx) + 200, length = 100),
          y = seq(min(yy) - 200, max(yy) + 200, length = 100))


res <- interpp(xx, yy, meuse$elev, grd$x, grd$y)
res <- as.data.frame(res) ## akima output is a list of 3 equal-length 
vectors like grd passed in


## if you want to interpolate on another "Z", repeat as desired, adding 
to output
res$cadmium <- interpp(xx, yy, meuse$cadmium, grd$x, grd$y)$z


coordinates(res) <- ~x+y
gridded(res) <- TRUE

## if you don't have a lot of empty cells
fullgrid(res) <- TRUE

image(res, "z")

## confirm where the high values were
points(meuse$x, meuse$y, cex = meuse$elev/5)

image(res, "cadmium")  ## etc

spplot(res)




Steve Friedman wrote:
> Hi,
>
> I have a spatial data set consisting of several z values and UTM
> coordinates.  Can someone direct me to documentation describing how I can
> plot specific z values using the coordinates to develop a continuous surface
> map?
>
> Thanks
> Steve
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>



From fieldsh at mail.med.upenn.edu  Mon Nov  5 16:23:54 2007
From: fieldsh at mail.med.upenn.edu (Sam Field)
Date: Mon,  5 Nov 2007 10:23:54 -0500
Subject: [R-sig-Geo] spautolm - standard errors of regression paramters
In-Reply-To: <Pine.LNX.4.64.0711042110350.11546@reclus.nhh.no>
References: <4725A4EE.8030406@ija.csic.es> <4725B1E7.5030903@utas.edu.au>
	<Pine.LNX.4.64.0711042110350.11546@reclus.nhh.no>
Message-ID: <1194276234.472f358a325e7@webmail.pobox.upenn.edu>

List,

I would like to grab the standard errors of the regression parameters from an
spautolm object.  Currently I am using...

mod1 <- spautolm(y~var1 + var2,....)

mod1_sd <-  (diag(mod1$fit[["imat"]])^2


This does produce a vector of the diagonal elements of a matrix that look like a
 variance covariance matrix (correct dimensions and row and column labels), but
the values I get do not agree with what the summary() function displays -- they
also seem implausibly small. 

any hints?

Thanks!

Sam









-- 
********Note the new contact information*******

Samuel H. Field, Ph.D. 
Senior Research Investigator
CHERP/Division of Internal Medicine - University of Pennsylvania
Philadelphia VA Medical Center
3900 Woodland Ave (9 East)
Philadelphia, PA 19104
(215) 823-5800 EXT. 6155 (Office)
(215) 823-6330 (Fax)



From Roger.Bivand at nhh.no  Mon Nov  5 20:18:24 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 5 Nov 2007 20:18:24 +0100 (CET)
Subject: [R-sig-Geo] spautolm - standard errors of regression paramters
In-Reply-To: <1194276234.472f358a325e7@webmail.pobox.upenn.edu>
References: <4725A4EE.8030406@ija.csic.es> <4725B1E7.5030903@utas.edu.au>
	<Pine.LNX.4.64.0711042110350.11546@reclus.nhh.no>
	<1194276234.472f358a325e7@webmail.pobox.upenn.edu>
Message-ID: <Pine.LNX.4.64.0711052010300.15356@reclus.nhh.no>

On Mon, 5 Nov 2007, Sam Field wrote:

> List,
>
> I would like to grab the standard errors of the regression parameters from an
> spautolm object.  Currently I am using...
>
> mod1 <- spautolm(y~var1 + var2,....)
>
> mod1_sd <-  (diag(mod1$fit[["imat"]])^2

As with most model fitting functions, you use the summary method, so

summary(mod1)$Coef

is a four-column matrix, and

summary(mod1)$Coef[,2]

is the column you want.

Roger

PS. Reading summary.spautolm shows that the diagonal values of the matrix 
you refer to are the squares of the SE values.

>
>
> This does produce a vector of the diagonal elements of a matrix that look like a
> variance covariance matrix (correct dimensions and row and column labels), but
> the values I get do not agree with what the summary() function displays -- they
> also seem implausibly small.
>
> any hints?
>
> Thanks!
>
> Sam
>
>
>
>
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mdsumner at utas.edu.au  Mon Nov  5 20:35:57 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Tue, 06 Nov 2007 06:35:57 +1100
Subject: [R-sig-Geo] working with Z values in spatial data frames
In-Reply-To: <2439f5740711050434r7e1836ach523b55e63a1827d5@mail.gmail.com>
References: <2439f5740711040914j60726de8q51183f0731631a76@mail.gmail.com>	
	<472EDEF1.1080606@utas.edu.au>
	<2439f5740711050434r7e1836ach523b55e63a1827d5@mail.gmail.com>
Message-ID: <472F709D.8020500@utas.edu.au>

I'm not totally sure what you mean:

You can use overlay() to transfer spatial attributes between *some* 
Spatial types, see ?"overlay-methods" for the allowed combinations.
Did you want to colour your polygons with values from the grid created 
by akima?

Cheers, Mike.

Steve Friedman wrote:
> Hello Michael,
>
> Thank you very much for providing this suggested approach.  I'm in the
> process of studying the code now to understand what it is doing and to
> prepare my data for use.
>
> Is there a way to use a polygon layer represented by a shapefile and use the
> SpatialPoints data set to color code the polygonal units in the former?
>
> Steve
>
>
> On 11/5/07, Michael Sumner <mdsumner at utas.edu.au> wrote:
>   
>> Here's one simple way, using package akima:
>>
>>
>> library(sp)
>>
>> data(meuse)
>>
>> ## assume your data is Spatial*
>>
>> coordinates(meuse) <- ~x+y
>>
>>
>>
>> ## use "elev" column in akima
>> library(akima)
>>
>> ## define a grid
>> xx <- coordinates(meuse)[,1]
>> yy <- coordinates(meuse)[,2]
>> ## modify offset of 100 to match your data, or use a proportion
>> grd <- expand.grid(x = seq(min(xx) - 200,  max(xx) + 200, length = 100),
>>          y = seq(min(yy) - 200, max(yy) + 200, length = 100))
>>
>>
>> res <- interpp(xx, yy, meuse$elev, grd$x, grd$y)
>> res <- as.data.frame(res) ## akima output is a list of 3 equal-length
>> vectors like grd passed in
>>
>>
>> ## if you want to interpolate on another "Z", repeat as desired, adding
>> to output
>> res$cadmium <- interpp(xx, yy, meuse$cadmium, grd$x, grd$y)$z
>>
>>
>> coordinates(res) <- ~x+y
>> gridded(res) <- TRUE
>>
>> ## if you don't have a lot of empty cells
>> fullgrid(res) <- TRUE
>>
>> image(res, "z")
>>
>> ## confirm where the high values were
>> points(meuse$x, meuse$y, cex = meuse$elev/5)
>>
>> image(res, "cadmium")  ## etc
>>
>> spplot(res)
>>
>>
>>
>>
>> Steve Friedman wrote:
>>     
>>> Hi,
>>>
>>> I have a spatial data set consisting of several z values and UTM
>>> coordinates.  Can someone direct me to documentation describing how I
>>>       
>> can
>>     
>>> plot specific z values using the coordinates to develop a continuous
>>>       
>> surface
>>     
>>> map?
>>>
>>> Thanks
>>> Steve
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>>
>>>       
>>     
>
>
>



From fieldsh at mail.med.upenn.edu  Mon Nov  5 23:18:57 2007
From: fieldsh at mail.med.upenn.edu (Sam Field)
Date: Mon,  5 Nov 2007 17:18:57 -0500
Subject: [R-sig-Geo] spautolm - standard errors of regression paramters
In-Reply-To: <Pine.LNX.4.64.0711052010300.15356@reclus.nhh.no>
References: <4725A4EE.8030406@ija.csic.es> <4725B1E7.5030903@utas.edu.au>
	<Pine.LNX.4.64.0711042110350.11546@reclus.nhh.no>
	<1194276234.472f358a325e7@webmail.pobox.upenn.edu>
	<Pine.LNX.4.64.0711052010300.15356@reclus.nhh.no>
Message-ID: <1194301137.472f96d1241de@webmail.pobox.upenn.edu>

thanks Roger!


In my haste, I mistyped.  I meant to write:


sqrt(diag(mod1$fit[["imat"]]))


which should be equivalent to


summary(mod1)$Coef[,2],

the standard errors of the regression coefficients.


In any case, I have managed to replicate the case where the two commands produce
different results. Using the "columbus data"...


library(spdep)
data(columbus)

#defining W

columbus_poly <- readShapePoly(system.file("etc/shapes/columbus.shp",
package="spdep")[1])
columbus_nb <- poly2nb(columbus_poly)
columbus_listw <- nb2listw(columbus_nb)

#running spautolm()

mod1 <- spautolm(CRIME ~ HOVAL +  DISCBD,listw=columbus_listw,data =
columbus,family="SAR")


sqrt(diag(mod1$fit[["imat"]]))

summary(mod1)$Coef[,2]



and the result:


> sqrt(diag(mod1$fit[["imat"]]))
(Intercept)       HOVAL      DISCBD 
0.468345807 0.009013047 0.146973631 

 
> summary(mod1)$Coef[,2]
(Intercept)       HOVAL      DISCBD 
 4.68573639  0.09017431  1.47045128 


looks like the decimal place is shifted over one place.  If you add more
variables to the model, the results differ by more then a decimal place in this
case (in my case the results are very different). For example,


mod2 <- spautolm(CRIME ~ HOVAL +  DISCBD + INC + PLUMB,listw=columbus_listw,data
= columbus,family="SAR")

sqrt(diag(mod2$fit[["imat"]]))

summary(mod2)$Coef[,2]

   
results in:

> sqrt(diag(mod2$fit[["imat"]]))
(Intercept)       HOVAL      DISCBD         INC       PLUMB 
 0.52884967  0.01002545  0.17186710  0.03379109  0.04940024 
> 
> summary(mod2)$Coef[,2]
(Intercept)       HOVAL      DISCBD         INC       PLUMB 
 4.86800598  0.09228322  1.58201870  0.31104348  0.45472408 


Initially, I just wanted the standard errors so that I could write them out in a
text file and put them in a table for a MSWord document.  However, I will also
need the covariances of the parameters and, thus, need the off diagonal elements
of the variance covariance matrix.   Am I reading this matrix incorrectly?


thanks for all of your help!

Sam









Quoting Roger Bivand <Roger.Bivand at nhh.no>:

> On Mon, 5 Nov 2007, Sam Field wrote:
> 
> > List,
> >
> > I would like to grab the standard errors of the regression parameters from
> an
> > spautolm object.  Currently I am using...
> >
> > mod1 <- spautolm(y~var1 + var2,....)
> >
> > mod1_sd <-  (diag(mod1$fit[["imat"]])^2
> 
> As with most model fitting functions, you use the summary method, so
> 
> summary(mod1)$Coef
> 
> is a four-column matrix, and
> 
> summary(mod1)$Coef[,2]
> 
> is the column you want.
> 
> Roger
> 
> PS. Reading summary.spautolm shows that the diagonal values of the matrix 
> you refer to are the squares of the SE values.
> 
> >
> >
> > This does produce a vector of the diagonal elements of a matrix that look
> like a
> > variance covariance matrix (correct dimensions and row and column labels),
> but
> > the values I get do not agree with what the summary() function displays --
> they
> > also seem implausibly small.
> >
> > any hints?
> >
> > Thanks!
> >
> > Sam
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> 
> -- 
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> 


-- 
********Note the new contact information*******

Samuel H. Field, Ph.D. 
Senior Research Investigator
CHERP/Division of Internal Medicine - University of Pennsylvania
Philadelphia VA Medical Center
3900 Woodland Ave (9 East)
Philadelphia, PA 19104
(215) 823-5800 EXT. 6155 (Office)
(215) 823-6330 (Fax)



From Petep at plano.gov  Mon Nov  5 20:56:19 2007
From: Petep at plano.gov (Pete Pennesi)
Date: Mon, 5 Nov 2007 13:56:19 -0600
Subject: [R-sig-Geo] Bailey & Gatrell Data files
Message-ID: <D1FD56BA49E3964CB5FBD96694234AA603F2191F@ISMB05.city.plano.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071105/e6dcb4b0/attachment.pl>

From Roger.Bivand at nhh.no  Tue Nov  6 09:20:38 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 6 Nov 2007 09:20:38 +0100 (CET)
Subject: [R-sig-Geo] spautolm - standard errors of regression paramters
In-Reply-To: <1194301137.472f96d1241de@webmail.pobox.upenn.edu>
References: <4725A4EE.8030406@ija.csic.es> <4725B1E7.5030903@utas.edu.au>
	<Pine.LNX.4.64.0711042110350.11546@reclus.nhh.no>
	<1194276234.472f358a325e7@webmail.pobox.upenn.edu>
	<Pine.LNX.4.64.0711052010300.15356@reclus.nhh.no>
	<1194301137.472f96d1241de@webmail.pobox.upenn.edu>
Message-ID: <Pine.LNX.4.64.0711060915300.20600@reclus.nhh.no>

On Mon, 5 Nov 2007, Sam Field wrote:

> thanks Roger!
>
>
> In my haste, I mistyped.  I meant to write:
>
>
> sqrt(diag(mod1$fit[["imat"]]))
>
>
> which should be equivalent to
>
>
> summary(mod1)$Coef[,2],
>
> the standard errors of the regression coefficients.

No, because the fit[["imat"]] matrix has not been multiplied by s^2 (in 
summary.spautolm):

     object$resvar <- object$fit$s2 * object$fit$imat

So:

> summary(mod1)$Coef[,2]
(Intercept)       HOVAL      DISCBD
  4.68573631  0.09017431  1.47045126
> sqrt(diag(mod1$fit$s2 * mod1$fit[["imat"]]))
(Intercept)       HOVAL      DISCBD
  4.68573631  0.09017431  1.47045126

And it is not multiplied in spautolm() because of the adj.se= argument to 
summary.spautolm, so that the SE values in Waller and Gotway - adjusting 
s^2 for the number of fitted coefficients - could be reproduced.

Roger

>
>
> In any case, I have managed to replicate the case where the two commands produce
> different results. Using the "columbus data"...
>
>
> library(spdep)
> data(columbus)
>
> #defining W
>
> columbus_poly <- readShapePoly(system.file("etc/shapes/columbus.shp",
> package="spdep")[1])
> columbus_nb <- poly2nb(columbus_poly)
> columbus_listw <- nb2listw(columbus_nb)
>
> #running spautolm()
>
> mod1 <- spautolm(CRIME ~ HOVAL +  DISCBD,listw=columbus_listw,data =
> columbus,family="SAR")
>
>
> sqrt(diag(mod1$fit[["imat"]]))
>
> summary(mod1)$Coef[,2]
>
>
>
> and the result:
>
>
>> sqrt(diag(mod1$fit[["imat"]]))
> (Intercept)       HOVAL      DISCBD
> 0.468345807 0.009013047 0.146973631
>
>
>> summary(mod1)$Coef[,2]
> (Intercept)       HOVAL      DISCBD
> 4.68573639  0.09017431  1.47045128
>
>
> looks like the decimal place is shifted over one place.  If you add more
> variables to the model, the results differ by more then a decimal place in this
> case (in my case the results are very different). For example,
>
>
> mod2 <- spautolm(CRIME ~ HOVAL +  DISCBD + INC + PLUMB,listw=columbus_listw,data
> = columbus,family="SAR")
>
> sqrt(diag(mod2$fit[["imat"]]))
>
> summary(mod2)$Coef[,2]
>
>
> results in:
>
>> sqrt(diag(mod2$fit[["imat"]]))
> (Intercept)       HOVAL      DISCBD         INC       PLUMB
> 0.52884967  0.01002545  0.17186710  0.03379109  0.04940024
>>
>> summary(mod2)$Coef[,2]
> (Intercept)       HOVAL      DISCBD         INC       PLUMB
> 4.86800598  0.09228322  1.58201870  0.31104348  0.45472408
>
>
> Initially, I just wanted the standard errors so that I could write them out in a
> text file and put them in a table for a MSWord document.  However, I will also
> need the covariances of the parameters and, thus, need the off diagonal elements
> of the variance covariance matrix.   Am I reading this matrix incorrectly?
>
>
> thanks for all of your help!
>
> Sam
>
>
>
>
>
>
>
>
>
> Quoting Roger Bivand <Roger.Bivand at nhh.no>:
>
>> On Mon, 5 Nov 2007, Sam Field wrote:
>>
>>> List,
>>>
>>> I would like to grab the standard errors of the regression parameters from
>> an
>>> spautolm object.  Currently I am using...
>>>
>>> mod1 <- spautolm(y~var1 + var2,....)
>>>
>>> mod1_sd <-  (diag(mod1$fit[["imat"]])^2
>>
>> As with most model fitting functions, you use the summary method, so
>>
>> summary(mod1)$Coef
>>
>> is a four-column matrix, and
>>
>> summary(mod1)$Coef[,2]
>>
>> is the column you want.
>>
>> Roger
>>
>> PS. Reading summary.spautolm shows that the diagonal values of the matrix
>> you refer to are the squares of the SE values.
>>
>>>
>>>
>>> This does produce a vector of the diagonal elements of a matrix that look
>> like a
>>> variance covariance matrix (correct dimensions and row and column labels),
>> but
>>> the values I get do not agree with what the summary() function displays --
>> they
>>> also seem implausibly small.
>>>
>>> any hints?
>>>
>>> Thanks!
>>>
>>> Sam
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Thierry.ONKELINX at inbo.be  Tue Nov  6 09:25:32 2007
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 6 Nov 2007 09:25:32 +0100
Subject: [R-sig-Geo] spautolm - standard errors of regression paramters
In-Reply-To: <1194301137.472f96d1241de@webmail.pobox.upenn.edu>
Message-ID: <2E9C414912813E4EB981326983E0A10403D0C1A6@inboexch.inbo.be>


Maybe spautolm() rescales the coordinates before calculating the model
parameters. In that case maybe het units mod1$fit are in the new scale
and the units of summary() in the original scale.

HTH,

Thierry

------------------------------------------------------------------------
----
ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature
and Forest
Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
methodology and quality assurance
Gaverstraat 4
9500 Geraardsbergen
Belgium 
tel. + 32 54/436 185
Thierry.Onkelinx at inbo.be 
www.inbo.be 

Do not put your faith in what statistics say until you have carefully
considered what they do not say.  ~William W. Watt
A statistical analysis, properly conducted, is a delicate dissection of
uncertainties, a surgery of suppositions. ~M.J.Moroney

-----Oorspronkelijk bericht-----
Van: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Sam Field
Verzonden: maandag 5 november 2007 23:19
Aan: Roger.Bivand at nhh.no
CC: r-sig-geo at stat.math.ethz.ch
Onderwerp: Re: [R-sig-Geo] spautolm - standard errors of regression
paramters

thanks Roger!


In my haste, I mistyped.  I meant to write:


sqrt(diag(mod1$fit[["imat"]]))


which should be equivalent to


summary(mod1)$Coef[,2],

the standard errors of the regression coefficients.


In any case, I have managed to replicate the case where the two commands
produce different results. Using the "columbus data"...


library(spdep)
data(columbus)

#defining W

columbus_poly <- readShapePoly(system.file("etc/shapes/columbus.shp",
package="spdep")[1])
columbus_nb <- poly2nb(columbus_poly)
columbus_listw <- nb2listw(columbus_nb)

#running spautolm()

mod1 <- spautolm(CRIME ~ HOVAL +  DISCBD,listw=columbus_listw,data =
columbus,family="SAR")


sqrt(diag(mod1$fit[["imat"]]))

summary(mod1)$Coef[,2]



and the result:


> sqrt(diag(mod1$fit[["imat"]]))
(Intercept)       HOVAL      DISCBD 
0.468345807 0.009013047 0.146973631 


> summary(mod1)$Coef[,2]
(Intercept)       HOVAL      DISCBD 
 4.68573639  0.09017431  1.47045128 


looks like the decimal place is shifted over one place.  If you add more
variables to the model, the results differ by more then a decimal place
in this case (in my case the results are very different). For example,


mod2 <- spautolm(CRIME ~ HOVAL +  DISCBD + INC +
PLUMB,listw=columbus_listw,data = columbus,family="SAR")

sqrt(diag(mod2$fit[["imat"]]))

summary(mod2)$Coef[,2]

   
results in:

> sqrt(diag(mod2$fit[["imat"]]))
(Intercept)       HOVAL      DISCBD         INC       PLUMB 
 0.52884967  0.01002545  0.17186710  0.03379109  0.04940024 
> 
> summary(mod2)$Coef[,2]
(Intercept)       HOVAL      DISCBD         INC       PLUMB 
 4.86800598  0.09228322  1.58201870  0.31104348  0.45472408 


Initially, I just wanted the standard errors so that I could write them
out in a text file and put them in a table for a MSWord document.
However, I will also need the covariances of the parameters and, thus,
need the off diagonal elements
of the variance covariance matrix.   Am I reading this matrix
incorrectly?


thanks for all of your help!

Sam









Quoting Roger Bivand <Roger.Bivand at nhh.no>:

> On Mon, 5 Nov 2007, Sam Field wrote:
> 
> > List,
> >
> > I would like to grab the standard errors of the regression 
> > parameters from
> an
> > spautolm object.  Currently I am using...
> >
> > mod1 <- spautolm(y~var1 + var2,....)
> >
> > mod1_sd <-  (diag(mod1$fit[["imat"]])^2
> 
> As with most model fitting functions, you use the summary method, so
> 
> summary(mod1)$Coef
> 
> is a four-column matrix, and
> 
> summary(mod1)$Coef[,2]
> 
> is the column you want.
> 
> Roger
> 
> PS. Reading summary.spautolm shows that the diagonal values of the 
> matrix you refer to are the squares of the SE values.
> 
> >
> >
> > This does produce a vector of the diagonal elements of a matrix that

> > look
> like a
> > variance covariance matrix (correct dimensions and row and column 
> > labels),
> but
> > the values I get do not agree with what the summary() function 
> > displays --
> they
> > also seem implausibly small.
> >
> > any hints?
> >
> > Thanks!
> >
> > Sam
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> 
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School 
> of Economics and Business Administration, Helleveien 30, N-5045 
> Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
> 
> 


--
********Note the new contact information*******

Samuel H. Field, Ph.D. 
Senior Research Investigator
CHERP/Division of Internal Medicine - University of Pennsylvania
Philadelphia VA Medical Center 3900 Woodland Ave (9 East) Philadelphia,
PA 19104
(215) 823-5800 EXT. 6155 (Office)
(215) 823-6330 (Fax)

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From Roger.Bivand at nhh.no  Tue Nov  6 09:34:28 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 6 Nov 2007 09:34:28 +0100 (CET)
Subject: [R-sig-Geo] spautolm - standard errors of regression paramters
In-Reply-To: <2E9C414912813E4EB981326983E0A10403D0C1A6@inboexch.inbo.be>
References: <2E9C414912813E4EB981326983E0A10403D0C1A6@inboexch.inbo.be>
Message-ID: <Pine.LNX.4.64.0711060933150.20600@reclus.nhh.no>

On Tue, 6 Nov 2007, ONKELINX, Thierry wrote:

>
> Maybe spautolm() rescales the coordinates before calculating the model
> parameters. In that case maybe het units mod1$fit are in the new scale
> and the units of summary() in the original scale.

No, no rescaling or other tricks. The code is quite clear, the returned 
matrix is not premultiplied by s^2 - see my other reply.

Roger

>
> HTH,
>
> Thierry
>
> ------------------------------------------------------------------------
> ----
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest
> Cel biometrie, methodologie en kwaliteitszorg / Section biometrics,
> methodology and quality assurance
> Gaverstraat 4
> 9500 Geraardsbergen
> Belgium
> tel. + 32 54/436 185
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> Do not put your faith in what statistics say until you have carefully
> considered what they do not say.  ~William W. Watt
> A statistical analysis, properly conducted, is a delicate dissection of
> uncertainties, a surgery of suppositions. ~M.J.Moroney
>
> -----Oorspronkelijk bericht-----
> Van: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] Namens Sam Field
> Verzonden: maandag 5 november 2007 23:19
> Aan: Roger.Bivand at nhh.no
> CC: r-sig-geo at stat.math.ethz.ch
> Onderwerp: Re: [R-sig-Geo] spautolm - standard errors of regression
> paramters
>
> thanks Roger!
>
>
> In my haste, I mistyped.  I meant to write:
>
>
> sqrt(diag(mod1$fit[["imat"]]))
>
>
> which should be equivalent to
>
>
> summary(mod1)$Coef[,2],
>
> the standard errors of the regression coefficients.
>
>
> In any case, I have managed to replicate the case where the two commands
> produce different results. Using the "columbus data"...
>
>
> library(spdep)
> data(columbus)
>
> #defining W
>
> columbus_poly <- readShapePoly(system.file("etc/shapes/columbus.shp",
> package="spdep")[1])
> columbus_nb <- poly2nb(columbus_poly)
> columbus_listw <- nb2listw(columbus_nb)
>
> #running spautolm()
>
> mod1 <- spautolm(CRIME ~ HOVAL +  DISCBD,listw=columbus_listw,data =
> columbus,family="SAR")
>
>
> sqrt(diag(mod1$fit[["imat"]]))
>
> summary(mod1)$Coef[,2]
>
>
>
> and the result:
>
>
>> sqrt(diag(mod1$fit[["imat"]]))
> (Intercept)       HOVAL      DISCBD
> 0.468345807 0.009013047 0.146973631
>
>
>> summary(mod1)$Coef[,2]
> (Intercept)       HOVAL      DISCBD
> 4.68573639  0.09017431  1.47045128
>
>
> looks like the decimal place is shifted over one place.  If you add more
> variables to the model, the results differ by more then a decimal place
> in this case (in my case the results are very different). For example,
>
>
> mod2 <- spautolm(CRIME ~ HOVAL +  DISCBD + INC +
> PLUMB,listw=columbus_listw,data = columbus,family="SAR")
>
> sqrt(diag(mod2$fit[["imat"]]))
>
> summary(mod2)$Coef[,2]
>
>
> results in:
>
>> sqrt(diag(mod2$fit[["imat"]]))
> (Intercept)       HOVAL      DISCBD         INC       PLUMB
> 0.52884967  0.01002545  0.17186710  0.03379109  0.04940024
>>
>> summary(mod2)$Coef[,2]
> (Intercept)       HOVAL      DISCBD         INC       PLUMB
> 4.86800598  0.09228322  1.58201870  0.31104348  0.45472408
>
>
> Initially, I just wanted the standard errors so that I could write them
> out in a text file and put them in a table for a MSWord document.
> However, I will also need the covariances of the parameters and, thus,
> need the off diagonal elements
> of the variance covariance matrix.   Am I reading this matrix
> incorrectly?
>
>
> thanks for all of your help!
>
> Sam
>
>
>
>
>
>
>
>
>
> Quoting Roger Bivand <Roger.Bivand at nhh.no>:
>
>> On Mon, 5 Nov 2007, Sam Field wrote:
>>
>>> List,
>>>
>>> I would like to grab the standard errors of the regression
>>> parameters from
>> an
>>> spautolm object.  Currently I am using...
>>>
>>> mod1 <- spautolm(y~var1 + var2,....)
>>>
>>> mod1_sd <-  (diag(mod1$fit[["imat"]])^2
>>
>> As with most model fitting functions, you use the summary method, so
>>
>> summary(mod1)$Coef
>>
>> is a four-column matrix, and
>>
>> summary(mod1)$Coef[,2]
>>
>> is the column you want.
>>
>> Roger
>>
>> PS. Reading summary.spautolm shows that the diagonal values of the
>> matrix you refer to are the squares of the SE values.
>>
>>>
>>>
>>> This does produce a vector of the diagonal elements of a matrix that
>
>>> look
>> like a
>>> variance covariance matrix (correct dimensions and row and column
>>> labels),
>> but
>>> the values I get do not agree with what the summary() function
>>> displays --
>> they
>>> also seem implausibly small.
>>>
>>> any hints?
>>>
>>> Thanks!
>>>
>>> Sam
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School
>> of Economics and Business Administration, Helleveien 30, N-5045
>> Bergen, Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
>
> --
> ********Note the new contact information*******
>
> Samuel H. Field, Ph.D.
> Senior Research Investigator
> CHERP/Division of Internal Medicine - University of Pennsylvania
> Philadelphia VA Medical Center 3900 Woodland Ave (9 East) Philadelphia,
> PA 19104
> (215) 823-5800 EXT. 6155 (Office)
> (215) 823-6330 (Fax)
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From cfarmer at uvic.ca  Tue Nov  6 23:57:34 2007
From: cfarmer at uvic.ca (Carson Farmer)
Date: Tue, 6 Nov 2007 14:57:34 -0800
Subject: [R-sig-Geo] problem with listw2sn...
Message-ID: <001d01c820c8$6cf01300$d222688e@MRBURNS>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071106/73453f2e/attachment.pl>

From knussear at usgs.gov  Wed Nov  7 01:52:05 2007
From: knussear at usgs.gov (Ken Nussear)
Date: Tue, 6 Nov 2007 16:52:05 -0800
Subject: [R-sig-Geo] retrieving fitted values from geoR model
In-Reply-To: <mailman.7.1194346802.23931.r-sig-geo@stat.math.ethz.ch>
References: <mailman.7.1194346802.23931.r-sig-geo@stat.math.ethz.ch>
Message-ID: <AAC0BCC3-D58E-4082-AFD1-3FBEC440ED8E@usgs.gov>

I'm trying to obtain the fitted values for a spatial model using  
likfit under geoR. When I use the statement

fitted(m4r, spatial = TRUE), per the instructions under help(likfit)

I get the following error

 > fitted(m4r, spatial = TRUE)
be patient ... this function currently require calling likfit again
Error in eval(object.call) : object "object.call" not found

If I ask the object for the call I get

 > m4r$call
likfit(geodata = spUta, trend = ~TransectLength + all.road +
     Urban, ini.cov.pars = c(0.82, 1949), nugget = 0.55, cov.model =  
"exponential",
     method.lik = "REML")



Can anyone provide help?

Thanks

Ken



The model summary is:

 > summary(m4r)
Summary of the parameter estimation
-----------------------------------
Estimation method: restricted maximum likelihood

Parameters of the mean component (trend):
   beta0   beta1   beta2   beta3
  1.1742  0.0008 -0.3758 -0.0001

Parameters of the spatial component:
    correlation function: exponential
       (estimated) variance parameter sigmasq (partial sill) =  1.167
       (estimated) cor. fct. parameter phi (range parameter)  =  1949
    anisotropy parameters:
       (fixed) anisotropy angle = 0  ( 0 degrees )
       (fixed) anisotropy ratio = 1

Parameter of the error component:
       (estimated) nugget =  0.2518

Transformation parameter:
       (fixed) Box-Cox parameter = 1 (no transformation)

Maximised Likelihood:
    log.L n.params      AIC      BIC
"-75.92"      "7"  "165.8"  "180.3"

non spatial model:
    log.L n.params      AIC      BIC
"-81.95"      "5"  "173.9"  "184.2"

Call:
likfit(geodata = spUta, trend = ~TransectLength + all.road +
     Urban, ini.cov.pars = c(0.82, 1949), nugget = 0.55, cov.model =  
"exponential",
     method.lik = "REML")



From Roger.Bivand at nhh.no  Wed Nov  7 08:22:24 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 7 Nov 2007 08:22:24 +0100 (CET)
Subject: [R-sig-Geo] problem with listw2sn...
In-Reply-To: <001d01c820c8$6cf01300$d222688e@MRBURNS>
References: <001d01c820c8$6cf01300$d222688e@MRBURNS>
Message-ID: <Pine.LNX.4.64.0711070807490.23728@reclus.nhh.no>

On Tue, 6 Nov 2007, Carson Farmer wrote:

> List,
>
> I am trying to create a GWT file from a shapefile, and all is fine up to
> listw2sn, at which point the region number ids are lost.
> Here is the code for reference, maybe someone can tell me where I went
> wrong?
>
> library(rgdal)
> library(spdep)
> vec <- readOGR(dsn = ".", layer = layerName)
> coords <- coordinates(vec)
> dist <- dnearneigh(coords, 0, 200, row_names, FALSE)
> dlist <- nbdists(dist, coords, FALSE)
> idlist <- lapply(dlist, function(x) 1/x)
> weights = nb2listw(dist, dlist, W, FALSE)
> sn <-listw2sn(weights)
> sn2gwt(sn, outName)
>
> This outputs a GWT file with region ids from 1 to (in this case) 127, not
> those which are specified above(row_names).

As you can see from the documentation, and:

> args(write.sn2gwt)
function (sn, file, shpfile = NULL, ind = NULL)

there is no provision for writing out the region.id attribute, which is 
passed through by listw2sn() - see str(sn). Since your rownames are 
arbitrary, that is not keyed to a given ID field in the shapefile, the 
1-based indices ought to be sufficient, and certainly make it easier to 
write out the output data frame.

You could try to patch write.sn2gwt() to do this, adding an argument, 
which by default is FALSE, but if TRUE replaces the values in sn[,1] and 
sn[,2] with attr(sn, "region.id")sn[,1] etc., and then modify the 
as.data.frame(sn) operation to avoid converting the character region.id to 
factors. A well tried patch would be welcome, but I don't think that it is 
worth the trouble, unless the software on the other side of the GWT knows 
what to do with the values.

Roger

> I've checked (summary) dist,
> dlist, idlist, and weights, and they all contain the right region ids, and
> I've checked (printed it out) sn, and it does not: so the only thing I can
> think of is that they are being lost at listw2sn.
>
> Note: I am running R 2.4.1 through the rpy python bindings in qgis (free
> open source gis).
>
> Carson Farmer
> Spatial Pattern Analysis & Research Lab (SPAR)
> Department of Geography, University of Victoria
> Victoria, BC, Canada
> web: www.geog.uvic.ca/spar
> email: cfarmer at uvic.ca
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From m.fanta at soilmaps.it  Wed Nov  7 10:01:11 2007
From: m.fanta at soilmaps.it (=?iso-8859-1?Q?maria_fantappi=E8?=)
Date: Wed, 7 Nov 2007 10:01:11 +0100
Subject: [R-sig-Geo] problems with memory limits of R
Message-ID: <002f01c8211c$be7af830$6c00a8c0@issds.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071107/fa886fad/attachment.pl>

From Roger.Bivand at nhh.no  Wed Nov  7 10:37:43 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 7 Nov 2007 10:37:43 +0100 (CET)
Subject: [R-sig-Geo] problems with memory limits of R
In-Reply-To: <002f01c8211c$be7af830$6c00a8c0@issds.it>
References: <002f01c8211c$be7af830$6c00a8c0@issds.it>
Message-ID: <Pine.LNX.4.64.0711071025480.23728@reclus.nhh.no>

On Wed, 7 Nov 2007, maria fantappi? wrote:

> Dear everybody,
>
> can anybody help me?
>
> I was trying to import raster maps on R of more than 20 MB size and I 
> got memory size limit problem. I found on R-help that probably I would 
> have to work with a 64 bit R version. But to use a 64 bit version of R I 
> think that I should need a 64 bit version of windows, isn't it?
>
> Maybe I'm not looking the right solution to this problem and I really 
> don't now how to go on!

Please follow the posting guide carefully. Please always state the output 
of sessionInfo(). The latest version of sp may help, but we do not know 
which version of R, sp, rgdal?, maptools?, whatever, you are using. All we 
know is that you are using Windows, for which no 64-bit version of R is 
currently available, and where Windows is known to have worse memory 
management, because it has more difficulties arranging smaller fragmented 
free memory chunks into a larger requested allocation.

Do you need to load 20MB rasters (this is a very imprecise description - a 
20MB geotiff may be very large indeed after compression is removed), even 
if 20MB means 20M raster cells (say 5000 by 4000, multiplied by 8 for 
double precision per band)? Can you use subsetting in rgdal to read tiles 
of data? Please also review the R for Windows FAQ on memory constraints - 
Q2.9.

Roger

>
> bye, Maria Fantappi?
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From knussear at usgs.gov  Wed Nov  7 13:39:30 2007
From: knussear at usgs.gov (Ken Nussear)
Date: Wed, 7 Nov 2007 04:39:30 -0800
Subject: [R-sig-Geo] retrieving fitted values from geoR model
In-Reply-To: <mailman.9.1194433201.22176.r-sig-geo@stat.math.ethz.ch>
References: <mailman.9.1194433201.22176.r-sig-geo@stat.math.ethz.ch>
Message-ID: <AE8C9B12-C71C-4D21-8308-31CFE901E744@usgs.gov>

Just in case anyone needs this in the future

Looks like I am able to get them using this call

fitted.likGRF(m4r)

Ken
>
>
> Message: 2
> Date: Tue, 6 Nov 2007 16:52:05 -0800
> From: Ken Nussear <knussear at usgs.gov>
> Subject: [R-sig-Geo] retrieving fitted values from geoR model
> To: r-sig-geo at stat.math.ethz.ch
> Message-ID: <AAC0BCC3-D58E-4082-AFD1-3FBEC440ED8E at usgs.gov>
> Content-Type: text/plain; charset=US-ASCII; format=flowed; delsp=yes
>
> I'm trying to obtain the fitted values for a spatial model using
> likfit under geoR. When I use the statement
>
> fitted(m4r, spatial = TRUE), per the instructions under help(likfit)
>
> I get the following error
>
>> fitted(m4r, spatial = TRUE)
> be patient ... this function currently require calling likfit again
> Error in eval(object.call) : object "object.call" not found
>
> If I ask the object for the call I get
>
>> m4r$call
> likfit(geodata = spUta, trend = ~TransectLength + all.road +
>     Urban, ini.cov.pars = c(0.82, 1949), nugget = 0.55, cov.model =
> "exponential",
>     method.lik = "REML")
>
>
>
> Can anyone provide help?
>
> Thanks
>
> Ken
>
>
>
> The model summary is:
>
>> summary(m4r)
> Summary of the parameter estimation
> -----------------------------------
> Estimation method: restricted maximum likelihood
>
> Parameters of the mean component (trend):
>   beta0   beta1   beta2   beta3
>  1.1742  0.0008 -0.3758 -0.0001
>
> Parameters of the spatial component:
>    correlation function: exponential
>       (estimated) variance parameter sigmasq (partial sill) =  1.167
>       (estimated) cor. fct. parameter phi (range parameter)  =  1949
>    anisotropy parameters:
>       (fixed) anisotropy angle = 0  ( 0 degrees )
>       (fixed) anisotropy ratio = 1
>
> Parameter of the error component:
>       (estimated) nugget =  0.2518
>
> Transformation parameter:
>       (fixed) Box-Cox parameter = 1 (no transformation)
>
> Maximised Likelihood:
>    log.L n.params      AIC      BIC
> "-75.92"      "7"  "165.8"  "180.3"
>
> non spatial model:
>    log.L n.params      AIC      BIC
> "-81.95"      "5"  "173.9"  "184.2"
>
> Call:
> likfit(geodata = spUta, trend = ~TransectLength + all.road +
>     Urban, ini.cov.pars = c(0.82, 1949), nugget = 0.55, cov.model =
> "exponential",
>     method.lik = "REML")



From Ingo.Holz at uni-hohenheim.de  Wed Nov  7 15:17:11 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Wed, 07 Nov 2007 15:17:11 +0100
Subject: [R-sig-Geo] change a value in the dataframe of a SPDF
Message-ID: <4731D6F7.22440.19E94DF@ingoholz.uni-hohenheim.de>

Hi,

 I changed a specific value in the dataframe of a SpatialPolygonsDataFrame 
in the following way:

 SPDF[["Name"]][1] <- 1

 This needed a very long time (about 10 seconds).

 I have two questions:
   Is there a faster way to do it?
   Why did it need that much time like I did it?

 Thank you,
 Ingo



From Roger.Bivand at nhh.no  Wed Nov  7 15:49:59 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 7 Nov 2007 15:49:59 +0100 (CET)
Subject: [R-sig-Geo] change a value in the dataframe of a SPDF
In-Reply-To: <4731D6F7.22440.19E94DF@ingoholz.uni-hohenheim.de>
References: <4731D6F7.22440.19E94DF@ingoholz.uni-hohenheim.de>
Message-ID: <Pine.LNX.4.64.0711071530270.24339@reclus.nhh.no>

On Wed, 7 Nov 2007, Ingo Holz wrote:

> Hi,
>
> I changed a specific value in the dataframe of a SpatialPolygonsDataFrame
> in the following way:
>
> SPDF[["Name"]][1] <- 1
>
> This needed a very long time (about 10 seconds).

When assigning to an existing object, in general the whole object gets 
recreated. With the North Carolina 100 county data set, both your version 
and the equivalent SPDF$Name[1] <- 1 take the same time, and the time is 
minimal (100 counties, 14 variables). If you can make the data available 
privately, and I imagine that the sizes are >> NC, I can see whether 
profiling provides any answers. With hundreds of thousands of polygons, 
you might see substantial time being used, because the memory model does 
not just "drop" the replacement value into the data.frame in the SPDF data 
slot. Is:

tmp <- SPDF[["Name"]]
tmp[1] <- 1
SPDF[["Name"]] <- tmp

faster, slower? Is assigning to a new column name faster or slower? Note 
that there are two nested access functions here, the [[]] and the [] - as 
you probably noticed, trying to replace [1, "Name"] doesn't work because 
there is no [,] <- replacement method.

Roger

>
> I have two questions:
>   Is there a faster way to do it?
>   Why did it need that much time like I did it?
>
> Thank you,
> Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Ingo.Holz at uni-hohenheim.de  Thu Nov  8 10:34:36 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Thu, 08 Nov 2007 10:34:36 +0100
Subject: [R-sig-Geo] spplot legends for each subplot
Message-ID: <4732E63C.22637.A419F2@ingoholz.uni-hohenheim.de>

Hi,

 is it possible to have different legends for each subplot in a figure produced 
by 

 spplot()  ?

Thanks, Ingo



From Roger.Bivand at nhh.no  Thu Nov  8 10:48:43 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 8 Nov 2007 10:48:43 +0100 (CET)
Subject: [R-sig-Geo] spplot legends for each subplot
In-Reply-To: <4732E63C.22637.A419F2@ingoholz.uni-hohenheim.de>
References: <4732E63C.22637.A419F2@ingoholz.uni-hohenheim.de>
Message-ID: <Pine.LNX.4.64.0711081046340.3262@reclus.nhh.no>

On Thu, 8 Nov 2007, Ingo Holz wrote:

> Hi,
>
> is it possible to have different legends for each subplot in a figure 
> produced by
>
> spplot()  ?

This is not what spplot() is for. You can use the levelplot() 
documentation to search further, but the key quality in lattice graphics 
is to condition the panels, which are assumed to be, for instance, 
measurements on the same variable at different dates.

Roger

>
> Thanks, Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From hengl at science.uva.nl  Thu Nov  8 13:26:09 2007
From: hengl at science.uva.nl (Tom Hengl)
Date: Thu, 8 Nov 2007 13:26:09 +0100 (CET)
Subject: [R-sig-Geo] working with Z values in spatial data frames
In-Reply-To: <472EDEF1.1080606@utas.edu.au>
References: <2439f5740711040914j60726de8q51183f0731631a76@mail.gmail.com>
	<472EDEF1.1080606@utas.edu.au>
Message-ID: <3506.89.172.224.193.1194524769.squirrel@webmail.science.uva.nl>


Another option to generate land surface models is the package gstat. You
can even use the position of streams/ridges to force physiographic breaks
in your output DEM.

The methodology and a sample dataset is available here:
http://geomorphometry.org/view_scripts.asp?id=6

The paper explaining the processing steps is still in review, but a
preprint can always be ordered.

Tom Hengl
http://spatial-analyst.net

> Here's one simple way, using package akima:
>
>
> library(sp)
>
> data(meuse)
>
> ## assume your data is Spatial*
>
> coordinates(meuse) <- ~x+y
>
>
>
> ## use "elev" column in akima
> library(akima)
>
> ## define a grid
> xx <- coordinates(meuse)[,1]
> yy <- coordinates(meuse)[,2]
> ## modify offset of 100 to match your data, or use a proportion
> grd <- expand.grid(x = seq(min(xx) - 200,  max(xx) + 200, length = 100),
>           y = seq(min(yy) - 200, max(yy) + 200, length = 100))
>
>
> res <- interpp(xx, yy, meuse$elev, grd$x, grd$y)
> res <- as.data.frame(res) ## akima output is a list of 3 equal-length
> vectors like grd passed in
>
>
> ## if you want to interpolate on another "Z", repeat as desired, adding
> to output
> res$cadmium <- interpp(xx, yy, meuse$cadmium, grd$x, grd$y)$z
>
>
> coordinates(res) <- ~x+y
> gridded(res) <- TRUE
>
> ## if you don't have a lot of empty cells
> fullgrid(res) <- TRUE
>
> image(res, "z")
>
> ## confirm where the high values were
> points(meuse$x, meuse$y, cex = meuse$elev/5)
>
> image(res, "cadmium")  ## etc
>
> spplot(res)
>
>
>
>
> Steve Friedman wrote:
>> Hi,
>>
>> I have a spatial data set consisting of several z values and UTM
>> coordinates.  Can someone direct me to documentation describing how I
>> can
>> plot specific z values using the coordinates to develop a continuous
>> surface
>> map?
>>
>> Thanks
>> Steve
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From friedman.steve at gmail.com  Thu Nov  8 14:32:48 2007
From: friedman.steve at gmail.com (Steve Friedman)
Date: Thu, 8 Nov 2007 08:32:48 -0500
Subject: [R-sig-Geo] working with Z values in spatial data frames
In-Reply-To: <3506.89.172.224.193.1194524769.squirrel@webmail.science.uva.nl>
References: <2439f5740711040914j60726de8q51183f0731631a76@mail.gmail.com>
	<472EDEF1.1080606@utas.edu.au>
	<3506.89.172.224.193.1194524769.squirrel@webmail.science.uva.nl>
Message-ID: <2439f5740711080532o3f827b0bn991a3748885b5ea3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071108/c1152a7f/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Nov  8 15:00:42 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Thu, 08 Nov 2007 15:00:42 +0100
Subject: [R-sig-Geo] spplot legends for each subplot
In-Reply-To: <Pine.LNX.4.64.0711081046340.3262@reclus.nhh.no>
References: <4732E63C.22637.A419F2@ingoholz.uni-hohenheim.de>
	<Pine.LNX.4.64.0711081046340.3262@reclus.nhh.no>
Message-ID: <4733168A.3060000@uni-muenster.de>

I fully agree with Roger's comment, but you may also want to check the 
help of ?print.trellis (library lattice), especially its more=, split= 
and position= arguments. It lets you combine trellis plots on a single page.
--
Edzer

Roger Bivand wrote:
> On Thu, 8 Nov 2007, Ingo Holz wrote:
>
>   
>> Hi,
>>
>> is it possible to have different legends for each subplot in a figure 
>> produced by
>>
>> spplot()  ?
>>     
>
> This is not what spplot() is for. You can use the levelplot() 
> documentation to search further, but the key quality in lattice graphics 
> is to condition the panels, which are assumed to be, for instance, 
> measurements on the same variable at different dates.
>
> Roger
>
>   
>> Thanks, Ingo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>     
>
>



From knussear at usgs.gov  Thu Nov  8 22:47:55 2007
From: knussear at usgs.gov (Ken Nussear)
Date: Thu, 8 Nov 2007 13:47:55 -0800
Subject: [R-sig-Geo] question about fitted values form geoR - results 'too
	good'
Message-ID: <56DA1DD1-B1C9-42F5-8A2B-DC095864986D@usgs.gov>

Hi

I'm using geoR for some spatial linear models and I'm getting  
surprisingly optimistic values from the spatial models relative to the  
non-spatial, even when the models appear to be performing about  
equally (by AIC comparison)

For example

This model relating encounter rates of lizards to a soil substrate  
parameter gives

> > summary(m2)
> Summary of the parameter estimation
> -----------------------------------
> Estimation method: maximum likelihood
>
> Parameters of the mean component (trend):
>  beta0  beta1
> 0.0312 0.0024
>
> Parameters of the spatial component:
>    correlation function: exponential
>       (estimated) variance parameter sigmasq (partial sill) =  0.0082
>       (estimated) cor. fct. parameter phi (range parameter)  =  797.1
>    anisotropy parameters:
>       (fixed) anisotropy angle = 0  ( 0 degrees )
>       (fixed) anisotropy ratio = 1
>
> Parameter of the error component:
>       (estimated) nugget =  0.002
>
> Transformation parameter:
>       (fixed) Box-Cox parameter = 1 (no transformation)
>
> Maximised Likelihood:
>    log.L n.params      AIC      BIC
>  "53.44"      "5" "-96.87" "-86.57"
>
> non spatial model:
>    log.L n.params      AIC      BIC
>  "51.99"      "3" "-97.98"  "-91.8"


With a difference in AIC of only about 1.

However looking at the predicted values versus the fits for the model  
The spatial model fitted values appear to be some how too good.

 > cor(fitted.likGRF(m2, spatial=TRUE), td$Crotaphytus)
[1] 0.9934701


 > cor(fitted.likGRF(m2, spatial=FALSE), td$Crotaphytus)
[1] 0.2522837

So I don't get how the spatial model with only a delta AIC of 1 can  
have a correlation with the dependent variable that is this high. Am I  
mis-interpreting the values I'm getting from the fitted call, or is  
something amis.  I've tried this with different data sets and I'm  
getting the same result.

Thanks

Ken



From johan.vandewauw at gmail.com  Fri Nov  9 09:16:07 2007
From: johan.vandewauw at gmail.com (Johan Van de Wauw)
Date: Fri, 9 Nov 2007 09:16:07 +0100
Subject: [R-sig-Geo] question about fitted values form geoR - results
	'too good'
In-Reply-To: <56DA1DD1-B1C9-42F5-8A2B-DC095864986D@usgs.gov>
References: <56DA1DD1-B1C9-42F5-8A2B-DC095864986D@usgs.gov>
Message-ID: <791a12030711090016v7d0028c8n4787f7199f9e9313@mail.gmail.com>

Kriging is an exact interpolator. It will always reproduce the values
that you use to predict if they are located on the same locations. You
should use an independant data set (or some sort of cross-validation)
to check how good your prediction is.

On Nov 8, 2007 10:47 PM, Ken Nussear <knussear at usgs.gov> wrote:
> Hi
>
> I'm using geoR for some spatial linear models and I'm getting
> surprisingly optimistic values from the spatial models relative to the
> non-spatial, even when the models appear to be performing about
> equally (by AIC comparison)
>
> For example
>
> This model relating encounter rates of lizards to a soil substrate
> parameter gives
>
> > > summary(m2)
> > Summary of the parameter estimation
> > -----------------------------------
> > Estimation method: maximum likelihood
> >
> > Parameters of the mean component (trend):
> >  beta0  beta1
> > 0.0312 0.0024
> >
> > Parameters of the spatial component:
> >    correlation function: exponential
> >       (estimated) variance parameter sigmasq (partial sill) =  0.0082
> >       (estimated) cor. fct. parameter phi (range parameter)  =  797.1
> >    anisotropy parameters:
> >       (fixed) anisotropy angle = 0  ( 0 degrees )
> >       (fixed) anisotropy ratio = 1
> >
> > Parameter of the error component:
> >       (estimated) nugget =  0.002
> >
> > Transformation parameter:
> >       (fixed) Box-Cox parameter = 1 (no transformation)
> >
> > Maximised Likelihood:
> >    log.L n.params      AIC      BIC
> >  "53.44"      "5" "-96.87" "-86.57"
> >
> > non spatial model:
> >    log.L n.params      AIC      BIC
> >  "51.99"      "3" "-97.98"  "-91.8"
>
>
> With a difference in AIC of only about 1.
>
> However looking at the predicted values versus the fits for the model
> The spatial model fitted values appear to be some how too good.
>
>  > cor(fitted.likGRF(m2, spatial=TRUE), td$Crotaphytus)
> [1] 0.9934701
>
>
>  > cor(fitted.likGRF(m2, spatial=FALSE), td$Crotaphytus)
> [1] 0.2522837
>
> So I don't get how the spatial model with only a delta AIC of 1 can
> have a correlation with the dependent variable that is this high. Am I
> mis-interpreting the values I'm getting from the fitted call, or is
> something amis.  I've tried this with different data sets and I'm
> getting the same result.
>
> Thanks
>
> Ken
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Ingo.Holz at uni-hohenheim.de  Fri Nov  9 14:32:46 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Fri, 09 Nov 2007 14:32:46 +0100
Subject: [R-sig-Geo] spplot legends for each subplot
Message-ID: <47346F8E.3087.179A4D1@ingoholz.uni-hohenheim.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071109/92658471/attachment.pl>

From edzer.pebesma at uni-muenster.de  Fri Nov  9 15:05:40 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Fri, 09 Nov 2007 15:05:40 +0100
Subject: [R-sig-Geo] spplot legends for each subplot
In-Reply-To: <47346F8E.3087.179A4D1@ingoholz.uni-hohenheim.de>
References: <47346F8E.3087.179A4D1@ingoholz.uni-hohenheim.de>
Message-ID: <47346934.3060201@uni-muenster.de>

This didn't happen with other graphics devices? Can you provide a simple 
reproducable example?
--
Edzer

Ingo Holz wrote:
> Thank you for this tip! I wouldn't have found it.
>
> Unfortunately I lose the figure titles (produced with spplot(..., main="title")) 
> after saving this figures with png().
>
> Ingo
>
>
> Message: 3
> Date: Thu, 08 Nov 2007 15:00:42 +0100
> From: "Edzer J. Pebesma" <edzer.pebesma at uni-muenster.de>
> Subject: Re: [R-sig-Geo] spplot legends for each subplot
> To: Roger.Bivand at nhh.no
> Cc: Ingo Holz <Ingo.Holz at uni-hohenheim.de>,
> 	r-sig-geo at stat.math.ethz.ch
> Message-ID: <4733168A.3060000 at uni-muenster.de>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> I fully agree with Roger's comment, but you may also want to check the 
> help of ?print.trellis (library lattice), especially its more=, split= 
> and position= arguments. It lets you combine trellis plots on a single
> page.
> --
> Edzer
>
> Roger Bivand wrote:
>   
>> On Thu, 8 Nov 2007, Ingo Holz wrote:
>>
>>   
>>     
>>> Hi,
>>>
>>> is it possible to have different legends for each subplot in a figure
>>> produced by
>>>
>>> spplot()  ?
>>>     
>>>       
>> This is not what spplot() is for. You can use the levelplot() 
>> documentation to search further, but the key quality in lattice graphics
>> is to condition the panels, which are assumed to be, for instance, 
>> measurements on the same variable at different dates.
>>
>> Roger
>>
>>   
>>     
>>> Thanks, Ingo
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>     
>>>       
>>     
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Ingo.Holz at uni-hohenheim.de  Sat Nov 10 13:02:52 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Sat, 10 Nov 2007 13:02:52 +0100
Subject: [R-sig-Geo] spplot legends for each subplot
Message-ID: <4735ABFC.19084.930D91@ingoholz.uni-hohenheim.de>

Hi,

it only happens using png(). It does not if I *.emf, *.jpg or *.bmp.

A simple reproducable example (from the print.trellis help file):

##########################
outfile <- ".../outfile.png"   ###  ... = your output directory

p11 <- histogram( ~ height | voice.part, data = singer, xlab="Height", 
main="Ingo's title")
p2 <- histogram( ~ height, data = singer, xlab = "Height")

png(outfile, width=800, height=800)
print(p11, split=c(1,1,1,2), more=TRUE)
print(p2, split=c(1,2,1,2))
dev.off()

########################

I use R 2.6.0 (2007-10-03) on WindowsXP.

Thanks, Ingo



From Ingo.Holz at uni-hohenheim.de  Sun Nov 11 10:50:33 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Sun, 11 Nov 2007 10:50:33 +0100
Subject: [R-sig-Geo] spplot -> sp.layout -> sp.text - only one "text" at the
	same time?
Message-ID: <4736DE79.17606.544C04@ingoholz.uni-hohenheim.de>

Hi,

 I am using spplot() and want to label points in the produced map by using 
sp.layout.

 SPolyDF = a SpatialPolygonsDataFrame
 SPointsDF = a SpatialPointsDataFrame

 Something like this:

 l1 <- list("sp.text", coordinates(SPointsDF[,1]), SPointsDF[["Name"]][1])
 spplot(SPolyDF[, "Name"], sp.layout = list(l1))

 This works fine for one point. It seems it is only possible to label one point 
at the same time, but not to do something like this:

 l1 <- list("sp.text", coordinates(SPointsDF), SPointsDF[["Name"]])
 spplot(SPolyDF[, "Name"], sp.layout = list(l1))

 Is there a way to label all points of the SpatialPointsDataFrame at the same 
time? Is it possible with sp.points?

Thanks, Ingo



From edzer.pebesma at uni-muenster.de  Sun Nov 11 11:26:00 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Sun, 11 Nov 2007 11:26:00 +0100
Subject: [R-sig-Geo] spplot legends for each subplot
In-Reply-To: <4735ABFC.19084.930D91@ingoholz.uni-hohenheim.de>
References: <4735ABFC.19084.930D91@ingoholz.uni-hohenheim.de>
Message-ID: <4736D8B8.2060108@uni-muenster.de>

... and I can't reproduce it under Linux, where "Ingo's title" happily 
appears.

I guess r-help would be the right place to ask this question. Remove the 
".../" before outfile.png, so it might run straight away.
--
Edzer

Ingo Holz wrote:
> Hi,
>
> it only happens using png(). It does not if I *.emf, *.jpg or *.bmp.
>
> A simple reproducable example (from the print.trellis help file):
>
> ##########################
> outfile <- ".../outfile.png"   ###  ... = your output directory
>
> p11 <- histogram( ~ height | voice.part, data = singer, xlab="Height", 
> main="Ingo's title")
> p2 <- histogram( ~ height, data = singer, xlab = "Height")
>
> png(outfile, width=800, height=800)
> print(p11, split=c(1,1,1,2), more=TRUE)
> print(p2, split=c(1,2,1,2))
> dev.off()
>
> ########################
>
> I use R 2.6.0 (2007-10-03) on WindowsXP.
>
> Thanks, Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From edzer.pebesma at uni-muenster.de  Sun Nov 11 13:45:31 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Sun, 11 Nov 2007 13:45:31 +0100
Subject: [R-sig-Geo] spplot -> sp.layout -> sp.text - only one "text" at
 the	same time?
In-Reply-To: <4736DE79.17606.544C04@ingoholz.uni-hohenheim.de>
References: <4736DE79.17606.544C04@ingoholz.uni-hohenheim.de>
Message-ID: <4736F96B.7010707@uni-muenster.de>

Ingo, that makes sense.

I committed a change to sp (in cvs), such that something like

spplot(meuse["zinc"],sp.layout=list("sp.text",coordinates(meuse),1:155))

works (although the plot of course does not make much sense)

It will be in the next release.
--
Edzer

Ingo Holz wrote:
> Hi,
>
>  I am using spplot() and want to label points in the produced map by using 
> sp.layout.
>
>  SPolyDF = a SpatialPolygonsDataFrame
>  SPointsDF = a SpatialPointsDataFrame
>
>  Something like this:
>
>  l1 <- list("sp.text", coordinates(SPointsDF[,1]), SPointsDF[["Name"]][1])
>  spplot(SPolyDF[, "Name"], sp.layout = list(l1))
>
>  This works fine for one point. It seems it is only possible to label one point 
> at the same time, but not to do something like this:
>
>  l1 <- list("sp.text", coordinates(SPointsDF), SPointsDF[["Name"]])
>  spplot(SPolyDF[, "Name"], sp.layout = list(l1))
>
>  Is there a way to label all points of the SpatialPointsDataFrame at the same 
> time? Is it possible with sp.points?
>
> Thanks, Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From "User Quarantine Release" at stat.math.ethz.ch  Sun Nov 11 17:06:49 2007
From: "User Quarantine Release" at stat.math.ethz.ch ("User Quarantine Release" at stat.math.ethz.ch)
Date: Mon, 12 Nov 2007 00:06:49 +0800
Subject: [R-sig-Geo] User Quarantine Release Notification - Mon,
	12 Nov 2007 00:06:49 +0800
Message-ID: <1194797209.974274@ssba.com.cn>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/de13bac3/attachment.pl>

From spluque at gmail.com  Mon Nov 12 00:01:21 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Sun, 11 Nov 2007 17:01:21 -0600
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
Message-ID: <87hcjs9yke.fsf@patagonia.sebmags.homelinux.org>

Hi,

Does anybody know of a painless way to write a SpatialGridDataFrame to a
netcdf grid format file?  I know there are 4 packages in CRAN that can
read/write netcdf data, but I think this would require a conversion of the
sp objects into an intermediary form.  Any suggestions welcome.


Cheers,

-- 
Seb



From ng at overcmail.de  Mon Nov 12 01:48:13 2007
From: ng at overcmail.de (Michael Z. Booker)
Date: Mon, 12 Nov 2007 07:48:13 +0700
Subject: [R-sig-Geo] Fwd:
Message-ID: <001c01c824c5$b492dca0$22d07abf@tgy>

An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/3e7cd991/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Text.pdf
Type: application/pdf
Size: 15942 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/3e7cd991/attachment.pdf>

From mdsumner at utas.edu.au  Mon Nov 12 03:38:57 2007
From: mdsumner at utas.edu.au (Michael Sumner)
Date: Mon, 12 Nov 2007 13:38:57 +1100
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
Message-ID: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/4545b0e0/attachment.pl>

From spluque at gmail.com  Mon Nov 12 05:21:19 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Sun, 11 Nov 2007 22:21:19 -0600
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
Message-ID: <87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>

On Mon, 12 Nov 2007 13:38:57 +1100,
Michael Sumner <mdsumner at utas.edu.au> wrote:

> Windows or Linux?  My experience is in Windows.  I would writeGDAL() the
> SGDF to GTiff, then use gdal_translate at the command line to convert to
> netCDF:

> gdal_translate -of NetCDF in.tif out.nc

Thanks for the idea, I'm under GNU/Linux though and don't see that
command.  It may not be difficult to track down the equivalent though.  At
any rate, is there some tradeoff to consider when using this these SGDF ->
GTiff -> NetCDF conversions?  I may have to look deeper into the other
packages (e.g. RNetCDF as you mentioned).

All the best,

-- 
Seb



From AlunPope at rismark.com.au  Mon Nov 12 07:18:29 2007
From: AlunPope at rismark.com.au (Alun Pope)
Date: Mon, 12 Nov 2007 17:18:29 +1100
Subject: [R-sig-Geo] nb2listw() in spdep fails
Message-ID: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5918@companyweb>

Running the latest version of spdep ("spdep, version 0.4-9, 2007-11-01")
I find that code that previously worked no longer does after updating R
to the latest release (2.6.0). 

 

The following example illustrates:

> dataex

       long       lat

1  151.1550 -33.88602

2  151.1922 -33.89780

3  151.1733 -33.91631

4  151.2042 -33.92947

5  151.1854 -33.87928

6  151.2355 -33.92529

7  151.1768 -33.91153

8  151.2352 -33.94703

9  151.2561 -33.93978

10 151.2316 -33.95854

> ngh.listex <-  knearneigh(cbind(dataex$long,dataex$lat), k=2, longlat
= TRUE)

> ngh.listex

$nn

      [,1] [,2]

 [1,]    5    7

 [2,]    7    5

 [3,]    7    2

 [4,]    6    3

 [5,]    2    1

 [6,]    8    9

 [7,]    3    2

 [8,]   10    9

 [9,]    8    6

[10,]    8    9

 

$np

[1] 10

 

$k

[1] 2

 

$dimension

[1] 2

 

$x

          [,1]      [,2]

 [1,] 151.1550 -33.88602

 [2,] 151.1922 -33.89780

 [3,] 151.1733 -33.91631

 [4,] 151.2042 -33.92947

 [5,] 151.1854 -33.87928

 [6,] 151.2355 -33.92529

 [7,] 151.1768 -33.91153

 [8,] 151.2352 -33.94703

 [9,] 151.2561 -33.93978

[10,] 151.2316 -33.95854

 

attr(,"class")

[1] "knn"

attr(,"call")

knearneigh(x = cbind(dataex$long, dataex$lat), k = 2, longlat = TRUE)

> nb.listex <- knn2nb(ngh.listex,sym=TRUE)

> nghwts.listex <- nb2listw(nb.listex,style="U")

Error in UseMethod("as.double") : no applicable method for "as.double"

 

 

The function nb2listw() in spdep contains statements of the form

 

    mode(x) <- "numeric" 

 

which I assume is what is causing that function to fail with the error
message above.  

 

 

I think this because it seems (to me) that this is caused by the change
to the behaviour of as.numeric() in the latest R release, when applied
to vectors of mode "integer".  Here is an example which illustrates
behaviour that appears odd to me:

 

> x1

[1] 1 2 3 4 4 4 4

> mode(x1)

[1] "numeric"

> as.numeric(x1)

Error in UseMethod("as.double") : no applicable method for "as.double"

> is.numeric(x1)

[1] TRUE

 

I have posted separately to the R-help mailing list.

 

I don't know if this ought to be a bug report, sorry.

 

Alun

 

 

 

Dr Alun Pope

 

Research Manager

Rismark International

 

For more on Equity Finance Mortgages*:

See www.efm.info <http://www.efm.info/> 

 

 

 

Level 13 | 50 Margaret Street

Sydney | NSW 2000 | Australia

T +61 (0)2 8243 0656

F +61 (0)2 9290 3703

M +61 (0)412 115 028

E alun.pope at rismark.com.au

W www.rismark.com.au

 

*Best New Product of the Year in the 2007 Your Mortgage Magazine
Mortgage of the Year Competition.

 

This email is strictly confidential. If you are not the intended
recipient you must not disclose or use the information contained in it.
If you have received this email in error please notify us immediately by
return email and delete the document. Failure to comply with this
request could invoke severe legal penalties.

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/efa37584/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 7920 bytes
Desc: image001.gif
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/efa37584/attachment.gif>

From AlunPope at rismark.com.au  Mon Nov 12 07:37:09 2007
From: AlunPope at rismark.com.au (Alun Pope)
Date: Mon, 12 Nov 2007 17:37:09 +1100
Subject: [R-sig-Geo] nb2listw() in spdep fails,
	also errorsarlm() has problems
In-Reply-To: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5918@companyweb>
Message-ID: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5923@companyweb>

Further to my post below, the function nb2listw() works if the mode is
coerced to "integer" rather than "numeric" (two places).

 

However the line 

 

can.sim <- as.logical(NA)

 

in errorsarlm() fails with the error message 

 

Error in UseMethod("as.logical") : no applicable method for
"as.logical".

 

It seems that as.logical(NA) is the culprit here, but I do not
understand how to fix this one.  I would be grateful for a quick fix.
Thanks a lot.

 

Alun

 

________________________________

From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Alun Pope
Sent: Monday, 12 November 2007 5:18 PM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] nb2listw() in spdep fails



Running the latest version of spdep ("spdep, version 0.4-9, 2007-11-01")
I find that code that previously worked no longer does after updating R
to the latest release (2.6.0). 



The following example illustrates:

> dataex

       long       lat

1  151.1550 -33.88602

2  151.1922 -33.89780

3  151.1733 -33.91631

4  151.2042 -33.92947

5  151.1854 -33.87928

6  151.2355 -33.92529

7  151.1768 -33.91153

8  151.2352 -33.94703

9  151.2561 -33.93978

10 151.2316 -33.95854

> ngh.listex <-  knearneigh(cbind(dataex$long,dataex$lat), k=2, longlat
= TRUE)

> ngh.listex

$nn

      [,1] [,2]

 [1,]    5    7

 [2,]    7    5

 [3,]    7    2

 [4,]    6    3

 [5,]    2    1

 [6,]    8    9

 [7,]    3    2

 [8,]   10    9

 [9,]    8    6

[10,]    8    9



$np

[1] 10



$k

[1] 2



$dimension

[1] 2



$x

          [,1]      [,2]

 [1,] 151.1550 -33.88602

 [2,] 151.1922 -33.89780

 [3,] 151.1733 -33.91631

 [4,] 151.2042 -33.92947

 [5,] 151.1854 -33.87928

 [6,] 151.2355 -33.92529

 [7,] 151.1768 -33.91153

 [8,] 151.2352 -33.94703

 [9,] 151.2561 -33.93978

[10,] 151.2316 -33.95854



attr(,"class")

[1] "knn"

attr(,"call")

knearneigh(x = cbind(dataex$long, dataex$lat), k = 2, longlat = TRUE)

> nb.listex <- knn2nb(ngh.listex,sym=TRUE)

> nghwts.listex <- nb2listw(nb.listex,style="U")

Error in UseMethod("as.double") : no applicable method for "as.double"





The function nb2listw() in spdep contains statements of the form



    mode(x) <- "numeric" 



which I assume is what is causing that function to fail with the error
message above.  





I think this because it seems (to me) that this is caused by the change
to the behaviour of as.numeric() in the latest R release, when applied
to vectors of mode "integer".  Here is an example which illustrates
behaviour that appears odd to me:



> x1

[1] 1 2 3 4 4 4 4

> mode(x1)

[1] "numeric"

> as.numeric(x1)

Error in UseMethod("as.double") : no applicable method for "as.double"

> is.numeric(x1)

[1] TRUE



I have posted separately to the R-help mailing list.



I don't know if this ought to be a bug report, sorry.



Alun







Dr Alun Pope



Research Manager

Rismark International



For more on Equity Finance Mortgages*:

See www.efm.info <http://www.efm.info/> 







Level 13 | 50 Margaret Street

Sydney | NSW 2000 | Australia

T +61 (0)2 8243 0656

F +61 (0)2 9290 3703

M +61 (0)412 115 028

E alun.pope at rismark.com.au

W www.rismark.com.au



*Best New Product of the Year in the 2007 Your Mortgage Magazine
Mortgage of the Year Competition.



This email is strictly confidential. If you are not the intended
recipient you must not disclose or use the information contained in it.
If you have received this email in error please notify us immediately by
return email and delete the document. Failure to comply with this
request could invoke severe legal penalties.





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/7f9dc67b/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/gif
Size: 7920 bytes
Desc: image001.gif
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071112/7f9dc67b/attachment.gif>

From edzer.pebesma at uni-muenster.de  Mon Nov 12 08:56:30 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Mon, 12 Nov 2007 08:56:30 +0100
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
In-Reply-To: <87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <4738072E.60500@uni-muenster.de>

On linux, you should have the netCDF driver istalled; from gdalDrivers() 
I see (on debian etch):

        name                               long_name create  copy
42    netCDF              Network Common Data Format  FALSE  TRUE

Then, reading the documentation of writeGDAL:

     'create2GDAL' creates a GDAL
     data set from a SpatialGridDataFrame object, in particular to be
     able to save to GDAL driver formats that only permit copying
     rather than creation.

Which is the case for net netCDF format. Might work!
--
Edzer

Sebastian P. Luque wrote:
> On Mon, 12 Nov 2007 13:38:57 +1100,
> Michael Sumner <mdsumner at utas.edu.au> wrote:
>
>   
>> Windows or Linux?  My experience is in Windows.  I would writeGDAL() the
>> SGDF to GTiff, then use gdal_translate at the command line to convert to
>> netCDF:
>>     
>
>   
>> gdal_translate -of NetCDF in.tif out.nc
>>     
>
> Thanks for the idea, I'm under GNU/Linux though and don't see that
> command.  It may not be difficult to track down the equivalent though.  At
> any rate, is there some tradeoff to consider when using this these SGDF ->
> GTiff -> NetCDF conversions?  I may have to look deeper into the other
> packages (e.g. RNetCDF as you mentioned).
>
> All the best,
>
>



From Roger.Bivand at nhh.no  Mon Nov 12 13:11:26 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Nov 2007 13:11:26 +0100 (CET)
Subject: [R-sig-Geo] nb2listw() in spdep fails
In-Reply-To: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5918@companyweb>
References: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5918@companyweb>
Message-ID: <Pine.LNX.4.64.0711121308010.24996@reclus.nhh.no>

On Mon, 12 Nov 2007, Alun Pope wrote:

> Running the latest version of spdep ("spdep, version 0.4-9, 2007-11-01")
> I find that code that previously worked no longer does after updating R
> to the latest release (2.6.0).
>

Thank you for your report. Please also state your platform, for example 
the output of sessionInfo(). I have tried to reproduce the error on:

> sessionInfo()
R version 2.6.0 (2007-10-03)
i386-pc-mingw32

locale:
LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian 
(Bokm?l)_Norway.1252;LC_MONETARY=Norwegian 
(Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian (Bokm?l)_Norway.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] spdep_0.4-9       Matrix_0.999375-3 lattice_0.17-2    boot_1.2-30
[5] maptools_0.6-19   foreign_0.8-23    sp_0.9-17         tripack_1.2-11

loaded via a namespace (and not attached):
[1] grid_2.6.0
>

without finding any errors. I will replace mode()<- calls with 
storage.mode()<- calls, but I don't think that this is the problem.

Best wishes,

Roger

>
>
> The following example illustrates:
>
>> dataex
>
>       long       lat
>
> 1  151.1550 -33.88602
>
> 2  151.1922 -33.89780
>
> 3  151.1733 -33.91631
>
> 4  151.2042 -33.92947
>
> 5  151.1854 -33.87928
>
> 6  151.2355 -33.92529
>
> 7  151.1768 -33.91153
>
> 8  151.2352 -33.94703
>
> 9  151.2561 -33.93978
>
> 10 151.2316 -33.95854
>
>> ngh.listex <-  knearneigh(cbind(dataex$long,dataex$lat), k=2, longlat
> = TRUE)
>
>> ngh.listex
>
> $nn
>
>      [,1] [,2]
>
> [1,]    5    7
>
> [2,]    7    5
>
> [3,]    7    2
>
> [4,]    6    3
>
> [5,]    2    1
>
> [6,]    8    9
>
> [7,]    3    2
>
> [8,]   10    9
>
> [9,]    8    6
>
> [10,]    8    9
>
>
>
> $np
>
> [1] 10
>
>
>
> $k
>
> [1] 2
>
>
>
> $dimension
>
> [1] 2
>
>
>
> $x
>
>          [,1]      [,2]
>
> [1,] 151.1550 -33.88602
>
> [2,] 151.1922 -33.89780
>
> [3,] 151.1733 -33.91631
>
> [4,] 151.2042 -33.92947
>
> [5,] 151.1854 -33.87928
>
> [6,] 151.2355 -33.92529
>
> [7,] 151.1768 -33.91153
>
> [8,] 151.2352 -33.94703
>
> [9,] 151.2561 -33.93978
>
> [10,] 151.2316 -33.95854
>
>
>
> attr(,"class")
>
> [1] "knn"
>
> attr(,"call")
>
> knearneigh(x = cbind(dataex$long, dataex$lat), k = 2, longlat = TRUE)
>
>> nb.listex <- knn2nb(ngh.listex,sym=TRUE)
>
>> nghwts.listex <- nb2listw(nb.listex,style="U")
>
> Error in UseMethod("as.double") : no applicable method for "as.double"
>
>
>
>
>
> The function nb2listw() in spdep contains statements of the form
>
>
>
>    mode(x) <- "numeric"
>
>
>
> which I assume is what is causing that function to fail with the error
> message above.
>
>
>
>
>
> I think this because it seems (to me) that this is caused by the change
> to the behaviour of as.numeric() in the latest R release, when applied
> to vectors of mode "integer".  Here is an example which illustrates
> behaviour that appears odd to me:
>
>
>
>> x1
>
> [1] 1 2 3 4 4 4 4
>
>> mode(x1)
>
> [1] "numeric"
>
>> as.numeric(x1)
>
> Error in UseMethod("as.double") : no applicable method for "as.double"
>
>> is.numeric(x1)
>
> [1] TRUE
>
>
>
> I have posted separately to the R-help mailing list.
>
>
>
> I don't know if this ought to be a bug report, sorry.
>
>
>
> Alun
>
>
>
>
>
>
>
> Dr Alun Pope
>
>
>
> Research Manager
>
> Rismark International
>
>
>
> For more on Equity Finance Mortgages*:
>
> See www.efm.info <http://www.efm.info/>
>
>
>
>
>
>
>
> Level 13 | 50 Margaret Street
>
> Sydney | NSW 2000 | Australia
>
> T +61 (0)2 8243 0656
>
> F +61 (0)2 9290 3703
>
> M +61 (0)412 115 028
>
> E alun.pope at rismark.com.au
>
> W www.rismark.com.au
>
>
>
> *Best New Product of the Year in the 2007 Your Mortgage Magazine
> Mortgage of the Year Competition.
>
>
>
> This email is strictly confidential. If you are not the intended
> recipient you must not disclose or use the information contained in it.
> If you have received this email in error please notify us immediately by
> return email and delete the document. Failure to comply with this
> request could invoke severe legal penalties.
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Roger.Bivand at nhh.no  Mon Nov 12 13:15:24 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Nov 2007 13:15:24 +0100 (CET)
Subject: [R-sig-Geo] nb2listw() in spdep fails,
 also errorsarlm() has problems
In-Reply-To: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5923@companyweb>
References: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5923@companyweb>
Message-ID: <Pine.LNX.4.64.0711121313040.24996@reclus.nhh.no>

On Mon, 12 Nov 2007, Alun Pope wrote:

> Further to my post below, the function nb2listw() works if the mode is
> coerced to "integer" rather than "numeric" (two places).
>

No, glist should be numeric or double, not integer - those are the only 
two mode()<- calls in nb2listw().

>
>
> However the line
>
>
>
> can.sim <- as.logical(NA)
>
>
>
> in errorsarlm() fails with the error message
>
>
>
> Error in UseMethod("as.logical") : no applicable method for
> "as.logical".
>

Almost certainly your system is broken, with a fresh version of R and a 
stale version of the methods package somewhere in a library on .libPaths()

Roger

>
>
> It seems that as.logical(NA) is the culprit here, but I do not
> understand how to fix this one.  I would be grateful for a quick fix.
> Thanks a lot.
>
>
>
> Alun
>
>
>
> ________________________________
>
> From: r-sig-geo-bounces at stat.math.ethz.ch
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Alun Pope
> Sent: Monday, 12 November 2007 5:18 PM
> To: r-sig-geo at stat.math.ethz.ch
> Subject: [R-sig-Geo] nb2listw() in spdep fails
>
>
>
> Running the latest version of spdep ("spdep, version 0.4-9, 2007-11-01")
> I find that code that previously worked no longer does after updating R
> to the latest release (2.6.0).
>
>
>
> The following example illustrates:
>
>> dataex
>
>       long       lat
>
> 1  151.1550 -33.88602
>
> 2  151.1922 -33.89780
>
> 3  151.1733 -33.91631
>
> 4  151.2042 -33.92947
>
> 5  151.1854 -33.87928
>
> 6  151.2355 -33.92529
>
> 7  151.1768 -33.91153
>
> 8  151.2352 -33.94703
>
> 9  151.2561 -33.93978
>
> 10 151.2316 -33.95854
>
>> ngh.listex <-  knearneigh(cbind(dataex$long,dataex$lat), k=2, longlat
> = TRUE)
>
>> ngh.listex
>
> $nn
>
>      [,1] [,2]
>
> [1,]    5    7
>
> [2,]    7    5
>
> [3,]    7    2
>
> [4,]    6    3
>
> [5,]    2    1
>
> [6,]    8    9
>
> [7,]    3    2
>
> [8,]   10    9
>
> [9,]    8    6
>
> [10,]    8    9
>
>
>
> $np
>
> [1] 10
>
>
>
> $k
>
> [1] 2
>
>
>
> $dimension
>
> [1] 2
>
>
>
> $x
>
>          [,1]      [,2]
>
> [1,] 151.1550 -33.88602
>
> [2,] 151.1922 -33.89780
>
> [3,] 151.1733 -33.91631
>
> [4,] 151.2042 -33.92947
>
> [5,] 151.1854 -33.87928
>
> [6,] 151.2355 -33.92529
>
> [7,] 151.1768 -33.91153
>
> [8,] 151.2352 -33.94703
>
> [9,] 151.2561 -33.93978
>
> [10,] 151.2316 -33.95854
>
>
>
> attr(,"class")
>
> [1] "knn"
>
> attr(,"call")
>
> knearneigh(x = cbind(dataex$long, dataex$lat), k = 2, longlat = TRUE)
>
>> nb.listex <- knn2nb(ngh.listex,sym=TRUE)
>
>> nghwts.listex <- nb2listw(nb.listex,style="U")
>
> Error in UseMethod("as.double") : no applicable method for "as.double"
>
>
>
>
>
> The function nb2listw() in spdep contains statements of the form
>
>
>
>    mode(x) <- "numeric"
>
>
>
> which I assume is what is causing that function to fail with the error
> message above.
>
>
>
>
>
> I think this because it seems (to me) that this is caused by the change
> to the behaviour of as.numeric() in the latest R release, when applied
> to vectors of mode "integer".  Here is an example which illustrates
> behaviour that appears odd to me:
>
>
>
>> x1
>
> [1] 1 2 3 4 4 4 4
>
>> mode(x1)
>
> [1] "numeric"
>
>> as.numeric(x1)
>
> Error in UseMethod("as.double") : no applicable method for "as.double"
>
>> is.numeric(x1)
>
> [1] TRUE
>
>
>
> I have posted separately to the R-help mailing list.
>
>
>
> I don't know if this ought to be a bug report, sorry.
>
>
>
> Alun
>
>
>
>
>
>
>
> Dr Alun Pope
>
>
>
> Research Manager
>
> Rismark International
>
>
>
> For more on Equity Finance Mortgages*:
>
> See www.efm.info <http://www.efm.info/>
>
>
>
>
>
>
>
> Level 13 | 50 Margaret Street
>
> Sydney | NSW 2000 | Australia
>
> T +61 (0)2 8243 0656
>
> F +61 (0)2 9290 3703
>
> M +61 (0)412 115 028
>
> E alun.pope at rismark.com.au
>
> W www.rismark.com.au
>
>
>
> *Best New Product of the Year in the 2007 Your Mortgage Magazine
> Mortgage of the Year Competition.
>
>
>
> This email is strictly confidential. If you are not the intended
> recipient you must not disclose or use the information contained in it.
> If you have received this email in error please notify us immediately by
> return email and delete the document. Failure to comply with this
> request could invoke severe legal penalties.
>
>
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Mon Nov 12 13:26:14 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Nov 2007 13:26:14 +0100 (CET)
Subject: [R-sig-Geo] nb2listw() in spdep fails,
 also errorsarlm() has problems
In-Reply-To: <Pine.LNX.4.64.0711121313040.24996@reclus.nhh.no>
References: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5923@companyweb>
	<Pine.LNX.4.64.0711121313040.24996@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0711121324050.24996@reclus.nhh.no>

Quoting Prof. Brian Ripley's reply on R-help, refering to:

https://stat.ethz.ch/pipermail/r-help/2007-October/142367.html

the problem is likely to be the spdep dependency on Matrix, which should 
be handled as described in the message.

Roger

On Mon, 12 Nov 2007, Roger Bivand wrote:

> On Mon, 12 Nov 2007, Alun Pope wrote:
>
>> Further to my post below, the function nb2listw() works if the mode is
>> coerced to "integer" rather than "numeric" (two places).
>>
>
> No, glist should be numeric or double, not integer - those are the only
> two mode()<- calls in nb2listw().
>
>>
>>
>> However the line
>>
>>
>>
>> can.sim <- as.logical(NA)
>>
>>
>>
>> in errorsarlm() fails with the error message
>>
>>
>>
>> Error in UseMethod("as.logical") : no applicable method for
>> "as.logical".
>>
>
> Almost certainly your system is broken, with a fresh version of R and a
> stale version of the methods package somewhere in a library on .libPaths()
>
> Roger
>
>>
>>
>> It seems that as.logical(NA) is the culprit here, but I do not
>> understand how to fix this one.  I would be grateful for a quick fix.
>> Thanks a lot.
>>
>>
>>
>> Alun
>>
>>
>>
>> ________________________________
>>
>> From: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Alun Pope
>> Sent: Monday, 12 November 2007 5:18 PM
>> To: r-sig-geo at stat.math.ethz.ch
>> Subject: [R-sig-Geo] nb2listw() in spdep fails
>>
>>
>>
>> Running the latest version of spdep ("spdep, version 0.4-9, 2007-11-01")
>> I find that code that previously worked no longer does after updating R
>> to the latest release (2.6.0).
>>
>>
>>
>> The following example illustrates:
>>
>>> dataex
>>
>>       long       lat
>>
>> 1  151.1550 -33.88602
>>
>> 2  151.1922 -33.89780
>>
>> 3  151.1733 -33.91631
>>
>> 4  151.2042 -33.92947
>>
>> 5  151.1854 -33.87928
>>
>> 6  151.2355 -33.92529
>>
>> 7  151.1768 -33.91153
>>
>> 8  151.2352 -33.94703
>>
>> 9  151.2561 -33.93978
>>
>> 10 151.2316 -33.95854
>>
>>> ngh.listex <-  knearneigh(cbind(dataex$long,dataex$lat), k=2, longlat
>> = TRUE)
>>
>>> ngh.listex
>>
>> $nn
>>
>>      [,1] [,2]
>>
>> [1,]    5    7
>>
>> [2,]    7    5
>>
>> [3,]    7    2
>>
>> [4,]    6    3
>>
>> [5,]    2    1
>>
>> [6,]    8    9
>>
>> [7,]    3    2
>>
>> [8,]   10    9
>>
>> [9,]    8    6
>>
>> [10,]    8    9
>>
>>
>>
>> $np
>>
>> [1] 10
>>
>>
>>
>> $k
>>
>> [1] 2
>>
>>
>>
>> $dimension
>>
>> [1] 2
>>
>>
>>
>> $x
>>
>>          [,1]      [,2]
>>
>> [1,] 151.1550 -33.88602
>>
>> [2,] 151.1922 -33.89780
>>
>> [3,] 151.1733 -33.91631
>>
>> [4,] 151.2042 -33.92947
>>
>> [5,] 151.1854 -33.87928
>>
>> [6,] 151.2355 -33.92529
>>
>> [7,] 151.1768 -33.91153
>>
>> [8,] 151.2352 -33.94703
>>
>> [9,] 151.2561 -33.93978
>>
>> [10,] 151.2316 -33.95854
>>
>>
>>
>> attr(,"class")
>>
>> [1] "knn"
>>
>> attr(,"call")
>>
>> knearneigh(x = cbind(dataex$long, dataex$lat), k = 2, longlat = TRUE)
>>
>>> nb.listex <- knn2nb(ngh.listex,sym=TRUE)
>>
>>> nghwts.listex <- nb2listw(nb.listex,style="U")
>>
>> Error in UseMethod("as.double") : no applicable method for "as.double"
>>
>>
>>
>>
>>
>> The function nb2listw() in spdep contains statements of the form
>>
>>
>>
>>    mode(x) <- "numeric"
>>
>>
>>
>> which I assume is what is causing that function to fail with the error
>> message above.
>>
>>
>>
>>
>>
>> I think this because it seems (to me) that this is caused by the change
>> to the behaviour of as.numeric() in the latest R release, when applied
>> to vectors of mode "integer".  Here is an example which illustrates
>> behaviour that appears odd to me:
>>
>>
>>
>>> x1
>>
>> [1] 1 2 3 4 4 4 4
>>
>>> mode(x1)
>>
>> [1] "numeric"
>>
>>> as.numeric(x1)
>>
>> Error in UseMethod("as.double") : no applicable method for "as.double"
>>
>>> is.numeric(x1)
>>
>> [1] TRUE
>>
>>
>>
>> I have posted separately to the R-help mailing list.
>>
>>
>>
>> I don't know if this ought to be a bug report, sorry.
>>
>>
>>
>> Alun
>>
>>
>>
>>
>>
>>
>>
>> Dr Alun Pope
>>
>>
>>
>> Research Manager
>>
>> Rismark International
>>
>>
>>
>> For more on Equity Finance Mortgages*:
>>
>> See www.efm.info <http://www.efm.info/>
>>
>>
>>
>>
>>
>>
>>
>> Level 13 | 50 Margaret Street
>>
>> Sydney | NSW 2000 | Australia
>>
>> T +61 (0)2 8243 0656
>>
>> F +61 (0)2 9290 3703
>>
>> M +61 (0)412 115 028
>>
>> E alun.pope at rismark.com.au
>>
>> W www.rismark.com.au
>>
>>
>>
>> *Best New Product of the Year in the 2007 Your Mortgage Magazine
>> Mortgage of the Year Competition.
>>
>>
>>
>> This email is strictly confidential. If you are not the intended
>> recipient you must not disclose or use the information contained in it.
>> If you have received this email in error please notify us immediately by
>> return email and delete the document. Failure to comply with this
>> request could invoke severe legal penalties.
>>
>>
>>
>>
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Mon Nov 12 18:24:49 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Nov 2007 18:24:49 +0100 (CET)
Subject: [R-sig-Geo] nb2listw() in spdep fails,
 also errorsarlm() has problems
In-Reply-To: <Pine.LNX.4.64.0711121324050.24996@reclus.nhh.no>
References: <F4B7D4806C6C8B42B0EFB680C6C0BA1E6E5923@companyweb>
	<Pine.LNX.4.64.0711121313040.24996@reclus.nhh.no>
	<Pine.LNX.4.64.0711121324050.24996@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0711121822080.27031@reclus.nhh.no>

And (acknowledging memory outage), I posted a note on the problem on:

http://www.sal.uiuc.edu/csiss/Rgeo/

on 9th October. Google on R 2.6.0 spdep break gets you there as first hit, 
R 2.6.0 spdep as third.

Roger


On Mon, 12 Nov 2007, Roger Bivand wrote:

> Quoting Prof. Brian Ripley's reply on R-help, refering to:
>
> https://stat.ethz.ch/pipermail/r-help/2007-October/142367.html
>
> the problem is likely to be the spdep dependency on Matrix, which should
> be handled as described in the message.
>
> Roger
>
> On Mon, 12 Nov 2007, Roger Bivand wrote:
>
>> On Mon, 12 Nov 2007, Alun Pope wrote:
>>
>>> Further to my post below, the function nb2listw() works if the mode is
>>> coerced to "integer" rather than "numeric" (two places).
>>>
>>
>> No, glist should be numeric or double, not integer - those are the only
>> two mode()<- calls in nb2listw().
>>
>>>
>>>
>>> However the line
>>>
>>>
>>>
>>> can.sim <- as.logical(NA)
>>>
>>>
>>>
>>> in errorsarlm() fails with the error message
>>>
>>>
>>>
>>> Error in UseMethod("as.logical") : no applicable method for
>>> "as.logical".
>>>
>>
>> Almost certainly your system is broken, with a fresh version of R and a
>> stale version of the methods package somewhere in a library on .libPaths()
>>
>> Roger
>>
>>>
>>>
>>> It seems that as.logical(NA) is the culprit here, but I do not
>>> understand how to fix this one.  I would be grateful for a quick fix.
>>> Thanks a lot.
>>>
>>>
>>>
>>> Alun
>>>
>>>
>>>
>>> ________________________________
>>>
>>> From: r-sig-geo-bounces at stat.math.ethz.ch
>>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Alun Pope
>>> Sent: Monday, 12 November 2007 5:18 PM
>>> To: r-sig-geo at stat.math.ethz.ch
>>> Subject: [R-sig-Geo] nb2listw() in spdep fails
>>>
>>>
>>>
>>> Running the latest version of spdep ("spdep, version 0.4-9, 2007-11-01")
>>> I find that code that previously worked no longer does after updating R
>>> to the latest release (2.6.0).
>>>
>>>
>>>
>>> The following example illustrates:
>>>
>>>> dataex
>>>
>>>       long       lat
>>>
>>> 1  151.1550 -33.88602
>>>
>>> 2  151.1922 -33.89780
>>>
>>> 3  151.1733 -33.91631
>>>
>>> 4  151.2042 -33.92947
>>>
>>> 5  151.1854 -33.87928
>>>
>>> 6  151.2355 -33.92529
>>>
>>> 7  151.1768 -33.91153
>>>
>>> 8  151.2352 -33.94703
>>>
>>> 9  151.2561 -33.93978
>>>
>>> 10 151.2316 -33.95854
>>>
>>>> ngh.listex <-  knearneigh(cbind(dataex$long,dataex$lat), k=2, longlat
>>> = TRUE)
>>>
>>>> ngh.listex
>>>
>>> $nn
>>>
>>>      [,1] [,2]
>>>
>>> [1,]    5    7
>>>
>>> [2,]    7    5
>>>
>>> [3,]    7    2
>>>
>>> [4,]    6    3
>>>
>>> [5,]    2    1
>>>
>>> [6,]    8    9
>>>
>>> [7,]    3    2
>>>
>>> [8,]   10    9
>>>
>>> [9,]    8    6
>>>
>>> [10,]    8    9
>>>
>>>
>>>
>>> $np
>>>
>>> [1] 10
>>>
>>>
>>>
>>> $k
>>>
>>> [1] 2
>>>
>>>
>>>
>>> $dimension
>>>
>>> [1] 2
>>>
>>>
>>>
>>> $x
>>>
>>>          [,1]      [,2]
>>>
>>> [1,] 151.1550 -33.88602
>>>
>>> [2,] 151.1922 -33.89780
>>>
>>> [3,] 151.1733 -33.91631
>>>
>>> [4,] 151.2042 -33.92947
>>>
>>> [5,] 151.1854 -33.87928
>>>
>>> [6,] 151.2355 -33.92529
>>>
>>> [7,] 151.1768 -33.91153
>>>
>>> [8,] 151.2352 -33.94703
>>>
>>> [9,] 151.2561 -33.93978
>>>
>>> [10,] 151.2316 -33.95854
>>>
>>>
>>>
>>> attr(,"class")
>>>
>>> [1] "knn"
>>>
>>> attr(,"call")
>>>
>>> knearneigh(x = cbind(dataex$long, dataex$lat), k = 2, longlat = TRUE)
>>>
>>>> nb.listex <- knn2nb(ngh.listex,sym=TRUE)
>>>
>>>> nghwts.listex <- nb2listw(nb.listex,style="U")
>>>
>>> Error in UseMethod("as.double") : no applicable method for "as.double"
>>>
>>>
>>>
>>>
>>>
>>> The function nb2listw() in spdep contains statements of the form
>>>
>>>
>>>
>>>    mode(x) <- "numeric"
>>>
>>>
>>>
>>> which I assume is what is causing that function to fail with the error
>>> message above.
>>>
>>>
>>>
>>>
>>>
>>> I think this because it seems (to me) that this is caused by the change
>>> to the behaviour of as.numeric() in the latest R release, when applied
>>> to vectors of mode "integer".  Here is an example which illustrates
>>> behaviour that appears odd to me:
>>>
>>>
>>>
>>>> x1
>>>
>>> [1] 1 2 3 4 4 4 4
>>>
>>>> mode(x1)
>>>
>>> [1] "numeric"
>>>
>>>> as.numeric(x1)
>>>
>>> Error in UseMethod("as.double") : no applicable method for "as.double"
>>>
>>>> is.numeric(x1)
>>>
>>> [1] TRUE
>>>
>>>
>>>
>>> I have posted separately to the R-help mailing list.
>>>
>>>
>>>
>>> I don't know if this ought to be a bug report, sorry.
>>>
>>>
>>>
>>> Alun
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Dr Alun Pope
>>>
>>>
>>>
>>> Research Manager
>>>
>>> Rismark International
>>>
>>>
>>>
>>> For more on Equity Finance Mortgages*:
>>>
>>> See www.efm.info <http://www.efm.info/>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Level 13 | 50 Margaret Street
>>>
>>> Sydney | NSW 2000 | Australia
>>>
>>> T +61 (0)2 8243 0656
>>>
>>> F +61 (0)2 9290 3703
>>>
>>> M +61 (0)412 115 028
>>>
>>> E alun.pope at rismark.com.au
>>>
>>> W www.rismark.com.au
>>>
>>>
>>>
>>> *Best New Product of the Year in the 2007 Your Mortgage Magazine
>>> Mortgage of the Year Competition.
>>>
>>>
>>>
>>> This email is strictly confidential. If you are not the intended
>>> recipient you must not disclose or use the information contained in it.
>>> If you have received this email in error please notify us immediately by
>>> return email and delete the document. Failure to comply with this
>>> request could invoke severe legal penalties.
>>>
>>>
>>>
>>>
>>>
>>>
>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From spluque at gmail.com  Mon Nov 12 21:52:56 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 12 Nov 2007 14:52:56 -0600
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
	<4738072E.60500@uni-muenster.de>
Message-ID: <8764074253.fsf@patagonia.sebmags.homelinux.org>

On Mon, 12 Nov 2007 08:56:30 +0100,
"Edzer J. Pebesma" <edzer.pebesma at uni-muenster.de> wrote:

> On linux, you should have the netCDF driver istalled; from gdalDrivers()
> I see (on debian etch):

>         name long_name create copy 42 netCDF Network Common Data Format
> FALSE TRUE

> Then, reading the documentation of writeGDAL:

>      'create2GDAL' creates a GDAL data set from a SpatialGridDataFrame
> object, in particular to be able to save to GDAL driver formats that
> only permit copying rather than creation.

> Which is the case for net netCDF format. Might work!

Thank you, I also see the same output in gdalDrivers():

        name                               long_name create  copy
43    netCDF              Network Common Data Format  FALSE  TRUE


but then create2GDAL fails with:

R> create2GDAL(locs.sub.ts, drivername="netCDF")
Error in .local(.Object, ...) : 
  
	GDAL Error 6: GDALDriver::Create() ... no create method implemented for this format.

I don't understand this message, given that create2GDAL() should be used
when only copying is allowed for a driver (as reported by gdalDrivers(),
and ?writeGDAL).  I'm using:

---<---------------cut here---------------start-------------->---
R> sessionInfo()
R version 2.6.0 (2007-10-03) 
x86_64-pc-linux-gnu 

locale:
LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] RColorBrewer_1.0-2 maptools_0.6-19    foreign_0.8-23     trip_1.0-4        
 [5] rgdal_0.5-20       sp_0.9-17          gstat_0.9-40       maps_2.0-38       
 [9] rcompgen_0.1-17    lattice_0.17-2    

loaded via a namespace (and not attached):
[1] grid_2.6.0  tools_2.6.0
---<---------------cut here---------------end---------------->---



-- 
Seb



From Roger.Bivand at nhh.no  Mon Nov 12 22:21:08 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Nov 2007 22:21:08 +0100 (CET)
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
In-Reply-To: <8764074253.fsf@patagonia.sebmags.homelinux.org>
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
	<4738072E.60500@uni-muenster.de>
	<8764074253.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <Pine.LNX.4.64.0711122215510.27031@reclus.nhh.no>

On Mon, 12 Nov 2007, Sebastian P. Luque wrote:

> On Mon, 12 Nov 2007 08:56:30 +0100,
> "Edzer J. Pebesma" <edzer.pebesma at uni-muenster.de> wrote:
>
>> On linux, you should have the netCDF driver istalled; from gdalDrivers()
>> I see (on debian etch):
>
>>         name long_name create copy 42 netCDF Network Common Data Format
>> FALSE TRUE
>
>> Then, reading the documentation of writeGDAL:
>
>>      'create2GDAL' creates a GDAL data set from a SpatialGridDataFrame
>> object, in particular to be able to save to GDAL driver formats that
>> only permit copying rather than creation.
>
>> Which is the case for net netCDF format. Might work!
>
> Thank you, I also see the same output in gdalDrivers():
>
>        name                               long_name create  copy
> 43    netCDF              Network Common Data Format  FALSE  TRUE
>
>
> but then create2GDAL fails with:
>
> R> create2GDAL(locs.sub.ts, drivername="netCDF")
> Error in .local(.Object, ...) :
>
> 	GDAL Error 6: GDALDriver::Create() ... no create method implemented for this format.

No, see the example in the help file. Use this function to create a 
dataset that can be created:

xx <- create2GDAL(locs.sub.ts, drivername="GTiff")

then copy xx:

xxx <- copyDataset(xx, drivername="netCDF")

and finay save it:

saveDataset(xxx, tf)
GDAL.close(xx)
GDAL.close(xxx)
GDALinfo(tf)

Watching the R tempdir, you'll see files appearing, so one or other of the 
steps may not be needed, but you cannot create a netCDF file directly.

Roger

>
> I don't understand this message, given that create2GDAL() should be used
> when only copying is allowed for a driver (as reported by gdalDrivers(),
> and ?writeGDAL).  I'm using:
>
> ---<---------------cut here---------------start-------------->---
> R> sessionInfo()
> R version 2.6.0 (2007-10-03)
> x86_64-pc-linux-gnu
>
> locale:
> LC_CTYPE=en_CA.UTF-8;LC_NUMERIC=C;LC_TIME=en_CA.UTF-8;LC_COLLATE=en_CA.UTF-8;LC_MONETARY=en_CA.UTF-8;LC_MESSAGES=en_CA.UTF-8;LC_PAPER=en_CA.UTF-8;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=en_CA.UTF-8;LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] RColorBrewer_1.0-2 maptools_0.6-19    foreign_0.8-23     trip_1.0-4
> [5] rgdal_0.5-20       sp_0.9-17          gstat_0.9-40       maps_2.0-38
> [9] rcompgen_0.1-17    lattice_0.17-2
>
> loaded via a namespace (and not attached):
> [1] grid_2.6.0  tools_2.6.0
> ---<---------------cut here---------------end---------------->---
>
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From spluque at gmail.com  Mon Nov 12 23:09:39 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Mon, 12 Nov 2007 16:09:39 -0600
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
	<4738072E.60500@uni-muenster.de>
	<8764074253.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0711122215510.27031@reclus.nhh.no>
Message-ID: <871wav3yl8.fsf@patagonia.sebmags.homelinux.org>

On Mon, 12 Nov 2007 22:21:08 +0100 (CET),
Roger Bivand <Roger.Bivand at nhh.no> wrote:

[...]

> No, see the example in the help file. Use this function to create a
> dataset that can be created:

> xx <- create2GDAL(locs.sub.ts, drivername="GTiff")

> then copy xx:

> xxx <- copyDataset(xx, drivername="netCDF")

Thanks Roger, I understand the process a little better.  However, R simply
crashes at this copying stage with:

---<---------------cut here---------------start-------------->---
netcdf: 4 is not a valid cdfid

Process R exited abnormally with code 3 at Mon Nov 12 16:00:27 2007
---<---------------cut here---------------end---------------->---

without leaving any other trace.  It seems as if this is an issue with
gdal netcdf driver.  Googling turns up a couple of hits with this message,
but they all indicate the problem should already be fixed with the current
version of gdal in Debian unstable (the system this happens on).


-- 
Seb



From Roger.Bivand at nhh.no  Mon Nov 12 23:29:59 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 12 Nov 2007 23:29:59 +0100 (CET)
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
In-Reply-To: <871wav3yl8.fsf@patagonia.sebmags.homelinux.org>
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
	<4738072E.60500@uni-muenster.de>
	<8764074253.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0711122215510.27031@reclus.nhh.no>
	<871wav3yl8.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <Pine.LNX.4.64.0711122324490.27031@reclus.nhh.no>

On Mon, 12 Nov 2007, Sebastian P. Luque wrote:

> On Mon, 12 Nov 2007 22:21:08 +0100 (CET),
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> [...]
>
>> No, see the example in the help file. Use this function to create a
>> dataset that can be created:
>
>> xx <- create2GDAL(locs.sub.ts, drivername="GTiff")
>
>> then copy xx:
>
>> xxx <- copyDataset(xx, drivername="netCDF")
>
> Thanks Roger, I understand the process a little better.  However, R simply
> crashes at this copying stage with:
>
> ---<---------------cut here---------------start-------------->---
> netcdf: 4 is not a valid cdfid
>
> Process R exited abnormally with code 3 at Mon Nov 12 16:00:27 2007
> ---<---------------cut here---------------end---------------->---
>
> without leaving any other trace.  It seems as if this is an issue with
> gdal netcdf driver.  Googling turns up a couple of hits with this message,
> but they all indicate the problem should already be fixed with the current
> version of gdal in Debian unstable (the system this happens on).
>

Then the fallback is to write a GTiff, and use gdal_translate to convert 
it (one of the gdal utilities that build with the GDAL shared object). If 
the same problem occurs, you may need to install netCDF and GDAL from 
source. If that doesn't resolve it, then you'll need to reshape the data 
to the required format and use functions in the ncdf package to create and 
write to the file.

Roger

>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Ingo.Holz at uni-hohenheim.de  Tue Nov 13 13:57:45 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Tue, 13 Nov 2007 13:57:45 +0100
Subject: [R-sig-Geo] readAsciiGrid (maptools)
Message-ID: <4739AD59.6807.BE038E@ingoholz.uni-hohenheim.de>

Hi,

 I have an ESRI-Ascii-Grid file which looks like this:

ncols 1001
nrows 1001
xllcorner 3539000
yllcorner 5379000
cellsize 1
NODATA_value -9999
766,65 766,65 766,67 766,69 766,7 766,72 766,74 766,76 766,78 766,8 
766,83 

 I imported this file as.image with readAsciiGrid():

kachel1 <- readAsciiGrid(file1, as.image=T, dec=",")

 After that I get the following "summary results":

min(kachel1$x)
  [1] 3539001               #  I think this should be 3539000

 kachel1$x[1:10]
 [1] 3539001 3539002 3539003 3539004 3539005 3539006 3539007 
3539008 3539009 3539010

 This are 1001 different values in kachel1$x !

 And...

 is(kachel1$x)
[1] "numeric" "vector" 

 However:

summary(kachel1$x)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
3539000 3539000 3540000 3540000 3540000 3540000 

Why this?
Ingo



From Roger.Bivand at nhh.no  Tue Nov 13 14:35:44 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 13 Nov 2007 14:35:44 +0100 (CET)
Subject: [R-sig-Geo] readAsciiGrid (maptools)
In-Reply-To: <4739AD59.6807.BE038E@ingoholz.uni-hohenheim.de>
References: <4739AD59.6807.BE038E@ingoholz.uni-hohenheim.de>
Message-ID: <Pine.LNX.4.64.0711131422140.29909@reclus.nhh.no>

On Tue, 13 Nov 2007, Ingo Holz wrote:

> Hi,
>
> I have an ESRI-Ascii-Grid file which looks like this:
>
> ncols 1001
> nrows 1001
> xllcorner 3539000
> yllcorner 5379000
> cellsize 1
> NODATA_value -9999
> 766,65 766,65 766,67 766,69 766,7 766,72 766,74 766,76 766,78 766,8
> 766,83
>
> I imported this file as.image with readAsciiGrid():
>
> kachel1 <- readAsciiGrid(file1, as.image=T, dec=",")

OK. We'll retire the as.image argument, please import it directly and 
coerce to image afterwards, and compare with the import using readGDAL in 
rgdal. Using the example data on my platform the problem is not 
reproducible. Can you make a copy of the data file available compressed on 
a website?

>
> After that I get the following "summary results":
>
> min(kachel1$x)
>  [1] 3539001               #  I think this should be 3539000

Rounding up for printing from the cell centre (3539000.5) on your 
platform - what is the value with more digits?


>
> kachel1$x[1:10]
> [1] 3539001 3539002 3539003 3539004 3539005 3539006 3539007
> 3539008 3539009 3539010
>
> This are 1001 different values in kachel1$x !

A list for image has x, y, and z members, where the x and y are the 
sequences of cell centres for each axis, and z is a (length(x)) by 
(length(y)) matrix.

Roger

>
> And...
>
> is(kachel1$x)
> [1] "numeric" "vector"
>
> However:
>
> summary(kachel1$x)
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 3539000 3539000 3540000 3540000 3540000 3540000
>
> Why this?
> Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Ingo.Holz at uni-hohenheim.de  Tue Nov 13 14:34:22 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Tue, 13 Nov 2007 14:34:22 +0100
Subject: [R-sig-Geo] readAsciiGrid (maptools) 2
Message-ID: <4739B5EE.30730.DF89B5@ingoholz.uni-hohenheim.de>

Hi again,

 OK, it is not a problem of readAsciiGrid (maptools)!

 However:

 x <- 3539000.5 : 3540000.5   ## OK, readAsciiGrid adds .5 to the coordinates
 length(x)
 x[1:10]
 min(x)                       ## OK, this is the rounded value
 summary(x)                   ## I still do not understand this
 summary(1:1001)

 I get the following results:

> x <- 3539000.5 : 3540000.5   ## OK, readAsciiGrid adds .5 to the coordinates
> length(x)
[1] 1001
> x[1:10]
 [1] 3539001 3539002 3539003 3539004 3539005 3539006 3539007 3539008 3539009 
3539010
> min(x)                       ## OK, this is the rounded value
[1] 3539001
> summary(x)                   ## I still do not understand this
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
3539000 3539000 3540000 3540000 3540000 3540000 
> summary(1:1001)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
      1     251     501     501     751    1001 
> 

Ingo



From Roger.Bivand at nhh.no  Tue Nov 13 14:49:40 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 13 Nov 2007 14:49:40 +0100 (CET)
Subject: [R-sig-Geo] readAsciiGrid (maptools) 2
In-Reply-To: <4739B5EE.30730.DF89B5@ingoholz.uni-hohenheim.de>
References: <4739B5EE.30730.DF89B5@ingoholz.uni-hohenheim.de>
Message-ID: <Pine.LNX.4.64.0711131447230.29909@reclus.nhh.no>

On Tue, 13 Nov 2007, Ingo Holz wrote:

> Hi again,
>
> OK, it is not a problem of readAsciiGrid (maptools)!
>
> However:
>
> x <- 3539000.5 : 3540000.5   ## OK, readAsciiGrid adds .5 to the coordinates
> length(x)
> x[1:10]
> min(x)                       ## OK, this is the rounded value
> summary(x)                   ## I still do not understand this
> summary(1:1001)
>
> I get the following results:
>
>> x <- 3539000.5 : 3540000.5   ## OK, readAsciiGrid adds .5 to the coordinates
>> length(x)
> [1] 1001
>> x[1:10]
> [1] 3539001 3539002 3539003 3539004 3539005 3539006 3539007 3539008 3539009
> 3539010
>> min(x)                       ## OK, this is the rounded value
> [1] 3539001
>> summary(x)                   ## I still do not understand this
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> 3539000 3539000 3540000 3540000 3540000 3540000

> x <- seq(3539000.5, 3540000.5, 1)
length(x)
[1] 1001
> options(digits=16)
> summary(x)
      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
3539000.5 3539250.5 3539500.5 3539500.5 3539750.5 3540000.5

OK?

Roger


>> summary(1:1001)
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>      1     251     501     501     751    1001
>>
>
> Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From spluque at gmail.com  Tue Nov 13 15:42:25 2007
From: spluque at gmail.com (Sebastian P. Luque)
Date: Tue, 13 Nov 2007 08:42:25 -0600
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>
	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>
	<4738072E.60500@uni-muenster.de>
	<8764074253.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0711122215510.27031@reclus.nhh.no>
	<871wav3yl8.fsf@patagonia.sebmags.homelinux.org>
	<Pine.LNX.4.64.0711122324490.27031@reclus.nhh.no>
Message-ID: <87ejeu8awe.fsf@patagonia.sebmags.homelinux.org>

On Mon, 12 Nov 2007 23:29:59 +0100 (CET),
Roger Bivand <Roger.Bivand at nhh.no> wrote:

[...]

> Then the fallback is to write a GTiff, and use gdal_translate to convert
> it (one of the gdal utilities that build with the GDAL shared
> object). If the same problem occurs, you may need to install netCDF and
> GDAL from source. If that doesn't resolve it, then you'll need to
> reshape the data to the required format and use functions in the ncdf
> package to create and write to the file.

I found out that the Debian packages with the gdal_translate binary is
gdal-bin, and trying to writeGDAL() to GTiff and then gdal_translate as
suggested earlier gives the same error message about cdfid not being
valid.

Just so I understand how the SpatialGridDataFrame object is structured:

R> gridparameters(locs.sub.ts)
  cellcentre.offset cellsize cells.dim
1            -69.12  0.06109       113
2             63.64  0.03424       122
R> bbox(locs.sub.ts)
             min    max
coords.x1 -69.15 -62.25
coords.x2  63.62  67.80

How are the data (e.g. z values) aligned with respect to these values?  I
would like to know what as.data.frame(locs.sub.ts) returns: the
coordinates and data for the midpoint of the cell, or the data for some
other reference point in the cell.  Thanks again for any help.


-- 
Seb



From mgallay01 at qub.ac.uk  Tue Nov 13 16:02:10 2007
From: mgallay01 at qub.ac.uk (Michal Gallay)
Date: 13 Nov 2007 15:02:10 +0000
Subject: [R-sig-Geo] readAsciiGrid (maptools) 2
In-Reply-To: <4739B5EE.30730.DF89B5@ingoholz.uni-hohenheim.de>
References: <4739B5EE.30730.DF89B5@ingoholz.uni-hohenheim.de>
Message-ID: <Prayer.1.0.12.0711131502100.94@amos.qub.ac.uk>

I Ingo,

I had a similar problem when reading ESRI ASCII grid in R. After checking 
it in ArcGIS I found out that there is one row of NoData values at the 
edges, when exporting from Arc. It has to do with the definition of the 
extent of the analysis and the grid cell definition (lower left corner or 
center of the cell).

This, doesn't really explain why you see the lenght of 1000 and 1001, but 
perhaps gives a clue.

Michal


On Nov 13 2007, Ingo Holz wrote:

> Hi again,
> 
>  OK, it is not a problem of readAsciiGrid (maptools)!
> 
>  However:
> 
>  x <- 3539000.5 : 3540000.5 ## OK, readAsciiGrid adds .5 to the 
> coordinates
>  length(x)
>  x[1:10]
>  min(x)                       ## OK, this is the rounded value
>  summary(x)                   ## I still do not understand this
>  summary(1:1001)
> 
>  I get the following results:
> 
> > x <- 3539000.5 : 3540000.5 ## OK, readAsciiGrid adds .5 to the 
> > coordinates length(x)
> [1] 1001
> > x[1:10]
>  [1] 3539001 3539002 3539003 3539004 3539005 3539006 3539007 3539008 
> 3539009 3539010
> > min(x)                       ## OK, this is the rounded value
> [1] 3539001
> > summary(x)                   ## I still do not understand this
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
> 3539000 3539000 3540000 3540000 3540000 3540000 
> > summary(1:1001)
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
>       1     251     501     501     751    1001 
> > 
> 
> Ingo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Michal Gallay

Postgraduate Research Student
School of Geography, Archaeology and Palaeoecology
Queen's University
Belfast BT7 1NN
Northern Ireland

Tel: +44(0)2890 273929
Fax: +44(0)2890 973212
email: mgallay01 at qub.ac.uk
www: www.qub.ac.uk/geog



From edzer.pebesma at uni-muenster.de  Tue Nov 13 16:54:57 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Tue, 13 Nov 2007 16:54:57 +0100
Subject: [R-sig-Geo] SpatialGridDataFrame to netcdf grid
In-Reply-To: <87ejeu8awe.fsf@patagonia.sebmags.homelinux.org>
References: <200711120238.lAC2cwRR017723@corinna.its.utas.edu.au>	<87d4ug9jr4.fsf@patagonia.sebmags.homelinux.org>	<4738072E.60500@uni-muenster.de>	<8764074253.fsf@patagonia.sebmags.homelinux.org>	<Pine.LNX.4.64.0711122215510.27031@reclus.nhh.no>	<871wav3yl8.fsf@patagonia.sebmags.homelinux.org>	<Pine.LNX.4.64.0711122324490.27031@reclus.nhh.no>
	<87ejeu8awe.fsf@patagonia.sebmags.homelinux.org>
Message-ID: <4739C8D1.8050603@uni-muenster.de>

Sebastian P. Luque wrote:
> On Mon, 12 Nov 2007 23:29:59 +0100 (CET),
> Roger Bivand <Roger.Bivand at nhh.no> wrote:
>
> [...]
>
>   
>> Then the fallback is to write a GTiff, and use gdal_translate to convert
>> it (one of the gdal utilities that build with the GDAL shared
>> object). If the same problem occurs, you may need to install netCDF and
>> GDAL from source. If that doesn't resolve it, then you'll need to
>> reshape the data to the required format and use functions in the ncdf
>> package to create and write to the file.
>>     
>
> I found out that the Debian packages with the gdal_translate binary is
> gdal-bin, and trying to writeGDAL() to GTiff and then gdal_translate as
> suggested earlier gives the same error message about cdfid not being
> valid.
>
> Just so I understand how the SpatialGridDataFrame object is structured:
>
> R> gridparameters(locs.sub.ts)
>   cellcentre.offset cellsize cells.dim
> 1            -69.12  0.06109       113
> 2             63.64  0.03424       122
> R> bbox(locs.sub.ts)
>              min    max
> coords.x1 -69.15 -62.25
> coords.x2  63.62  67.80
>
> How are the data (e.g. z values) aligned with respect to these values?  I
> would like to know what as.data.frame(locs.sub.ts) returns: the
> coordinates and data for the midpoint of the cell, or the data for some
> other reference point in the cell.  Thanks again for any help.
>   
The midpoint.
--
Edzer



From debarchana.ghosh at gmail.com  Wed Nov 14 00:55:21 2007
From: debarchana.ghosh at gmail.com (Debarchana Ghosh)
Date: Tue, 13 Nov 2007 17:55:21 -0600
Subject: [R-sig-Geo] Can voronoi polygons calculated in R be converted to
	ESRI shapefile?
Message-ID: <d1b8ff630711131555n6da4db8bo4dc627340fea4a3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071113/dde9b92b/attachment.pl>

From levidrose at gmail.com  Wed Nov 14 04:46:14 2007
From: levidrose at gmail.com (Levi Rose)
Date: Tue, 13 Nov 2007 20:46:14 -0700
Subject: [R-sig-Geo] Problems preserving attribute data while merging fields
	in shapefiles
Message-ID: <a1762780711131946p41787c63p687881bb05088c2f@mail.gmail.com>

To all,

Currently, I have old datasets(shapefiles) that contain a plant code #
field in the attributes table.  I have successfully merged in a table
with spp. names to correspond with the plant code #'s.  During this
process my attribute data is resorted and I lose continuity with other
attribute data. (I'm using the (sp) and (maptools) libraries to
execute read/write Poly/Point shape functions.)  While merging, how do
you maintain continuity between all of the other fields in your
attributes table?

Thank-you for your time and help,
Levi

-- 
Research Assistant
Dept. of Watershed Sciences
Utah State University
5210 Old Main
Logan, Utah 84322
(740)-591-1750
LeviDRose at gmail.com



From Roger.Bivand at nhh.no  Wed Nov 14 09:06:24 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 14 Nov 2007 09:06:24 +0100 (CET)
Subject: [R-sig-Geo] Can voronoi polygons calculated in R be converted
 to ESRI shapefile?
In-Reply-To: <d1b8ff630711131555n6da4db8bo4dc627340fea4a3@mail.gmail.com>
References: <d1b8ff630711131555n6da4db8bo4dc627340fea4a3@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0711140903240.1076@reclus.nhh.no>

On Tue, 13 Nov 2007, Debarchana Ghosh wrote:

> Hi,
>
> I have a point data frame with X and Y coordinates, where n=1051. I am
> trying to create Voronoi polygons using both the Tripack and PBSMapping
> packages.
>
> library(tripack)
> testbird.vm<-voronoi.mosaic(testbird$X, testbird$Y)
> testbird.vp<-voronoi.polygons(testbird.vm)
> plot(testbird.vp)
>
> library(PBSMapping)
> testbirdvor<-calcVoronoi(testbird)
>
>> From here how can I create an ESRI shapefile of the voronoi polygons in R
> and export to ArcGIS for further use.
>

There is a thread at:

http://article.gmane.org/gmane.comp.lang.r.geo/1275

which shows how to make a SpatialPolygonsDataFrame from deldir output 
(deldir closes the infinite polygons and clips large closed ones, but 
tripack does not). Could you please post with a short recipe once you 
resolve this, it is do-able, but the original thread touches on other 
things too, that are not relevant here.

Roger

> Thanks for the help,
> Debs.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Nov 14 09:10:37 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 14 Nov 2007 09:10:37 +0100 (CET)
Subject: [R-sig-Geo] Problems preserving attribute data while merging
 fields in shapefiles
In-Reply-To: <a1762780711131946p41787c63p687881bb05088c2f@mail.gmail.com>
References: <a1762780711131946p41787c63p687881bb05088c2f@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0711140906360.1076@reclus.nhh.no>

On Tue, 13 Nov 2007, Levi Rose wrote:

> To all,
>
> Currently, I have old datasets(shapefiles) that contain a plant code #
> field in the attributes table.  I have successfully merged in a table
> with spp. names to correspond with the plant code #'s.  During this
> process my attribute data is resorted and I lose continuity with other
> attribute data. (I'm using the (sp) and (maptools) libraries to
> execute read/write Poly/Point shape functions.)  While merging, how do
> you maintain continuity between all of the other fields in your
> attributes table?

Please include the output of sessionInfo(), and example code (preferably 
using shapefiles shipping with maptools or others that are posted 
somewhere) to show your workflow. It is not easy to "look over your 
shoulder" from your description above.

In general, the row names of point coordinate matrices and the row names 
of the included data frame should agree for SpatialPointsDataFrame 
objects, and the Polygons objects ID slots should agree with the row names 
of the included data frame for SpatialPolygonsDataFrame objects.

Roger


>
> Thank-you for your time and help,
> Levi
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From s0702025 at sta.cuhk.edu.hk  Thu Nov 15 16:36:58 2007
From: s0702025 at sta.cuhk.edu.hk (Yang Aijun)
Date: Thu, 15 Nov 2007 23:36:58 +0800
Subject: [R-sig-Geo]  RE: [R] adjacency matrix
Message-ID: <000001c8279d$61a681b0$9c24bd89@CUHKC435BFCCFF>

Dear R experts:

     The purpose of this e-mail is that I want to ask a question about "How
to get adjacency matrix from WINBUGS with ARCVIEW(.shp) files".As I can not
generate the "theme2.txt"  by convert.r .when I run the R project,it show
the problem as follows:
> source("convert.s")
> convert("theme2")
Read 289 records
Error in if (letter <= "9" & letter >= "0") { : 
        missing value where TRUE/FALSE needed

Would you please give me a help.Thank you!

Best regards

Aijun Yang

The Department of Statistics
The Chinese University of Hongkong
N.T. Hongkong
-------------- next part --------------
A non-text attachment was scrubbed...
Name: convert.r
Type: application/octet-stream
Size: 3180 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071115/a9c7570c/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: theme2.cgm
Type: application/octet-stream
Size: 9885 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071115/a9c7570c/attachment-0001.obj>

From Roger.Bivand at nhh.no  Thu Nov 15 16:59:35 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 15 Nov 2007 16:59:35 +0100 (CET)
Subject: [R-sig-Geo] [R] adjacency matrix
In-Reply-To: <000001c8279d$61a681b0$9c24bd89@CUHKC435BFCCFF>
References: <000001c8279d$61a681b0$9c24bd89@CUHKC435BFCCFF>
Message-ID: <Pine.LNX.4.64.0711151649340.4471@reclus.nhh.no>

On Thu, 15 Nov 2007, Yang Aijun wrote:

> Dear R experts:
>
>     The purpose of this e-mail is that I want to ask a question about "How
> to get adjacency matrix from WINBUGS with ARCVIEW(.shp) files".As I can not
> generate the "theme2.txt"  by convert.r .when I run the R project,it show
> the problem as follows:
>> source("convert.s")

You need to be very much more specific in your question. I guess (although 
you have not said so) that you are refering to:

http://www.biostat.umn.edu/~brad/yuecui/index.html

but this is far from common knowledge. When running other people's 
functions (not packages - packages on CRAN are thoroughly checked), you 
have to be careful to do exactly as they did on the same platform. You 
will need to debug() the convert function to see where it derails.

You could try the nb2WB() function in the spdep package instead, and use 
either functions in the maptools or rgdal packages to read in the 
shapefile without the route via CGM text file. Generate the neighbours 
list in spdep by any method you choose (poly2nb is simplest for contiguity 
neighbours for polygon shapes). It also removes the requirement to have a 
running copy of ArcView.

Roger

>> convert("theme2")
> Read 289 records
> Error in if (letter <= "9" & letter >= "0") { :
>        missing value where TRUE/FALSE needed
>
> Would you please give me a help.Thank you!
>
> Best regards
>
> Aijun Yang
>
> The Department of Statistics
> The Chinese University of Hongkong
> N.T. Hongkong
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From reeves at nceas.ucsb.edu  Thu Nov 15 22:48:47 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Thu, 15 Nov 2007 13:48:47 -0800
Subject: [R-sig-Geo] Can voronoi polygons calculated in R be converted
 to	ESRI shapefile?
In-Reply-To: <473B031A.7050608@gmail.com>
References: <d1b8ff630711131555n6da4db8bo4dc627340fea4a3@mail.gmail.com>
	<473A4087.3030005@nceas.ucsb.edu> <473B031A.7050608@gmail.com>
Message-ID: <473CBEBF.6050309@nceas.ucsb.edu>

Debs:

The script that I had written before used the older, deprecated  
SpatialRingsDataFrame
to create a shapefile from the tripack() voronoi polygons.
Here is an example, based on the answer to your message from Roger Bivand,
that demonstrates the technique  -
Regards,
Rick R
#
# example from the 'tripack' package documentation
#
voronoiShapefile <- function()
{
browser()
   library(tripack)
   data(tritest)
   tritest.vm <- voronoi.mosaic(tritest$x,tritest$y) 
   tritest.vp <- voronoi.polygons(tritest.vm)

   polys <- vector(mode="list", length=length(tritest.vp))
   library(sp)
   for (i in seq(along=polys))
  {
      pcrds <- cbind(tritest.vp[[8]][,1],tritest.vp[[8]][,2] )
      pcrds <- rbind(pcrds, pcrds[1,])
      polys[[i]] <- Polygons(list(Polygon(pcrds)), ID=as.character(i))
   }
   SP <- SpatialPolygons(polys) # 8 spatial polygons generated using 
voronoi.polygons
#
# Generate the SpatialPolygonsDataFrame object. For the purposes of this 
example,
# we use the last 8 points in the input point dataset as the data 
component of the data frame.
# You will probably have 'actual' attribute data to assign to each 
polygon. See data.frame documentation
#
   SPDF <- SpatialPolygonsDataFrame(SP, 
data=data.frame(x=tritest$x[5:12],y=tritest$y[5:12],
                                                            
row.names=sapply(slot(SP, "polygons"),
                                                            function(x) 
slot(x, "ID"))))
#
   Areas <- sapply(slot(SP, "polygons"), function(x) slot(x, "area"))
 
   print(fivenum(Areas), digits=8)
   print(sort(Areas), digits=8)
   SPDF1 <- SPDF[Areas < 0.866027,]

   plot(SPDF1, axes=TRUE, xlim=c(1,10), ylim=c(1,10))
   points(crds)
   library(maptools)
   writePolyShape(SPDF1, "hex")
}


Debarchaa Ghosh wrote:
> Hi Rick,
>
> Thanks for your help. I'll be looking forward to your script.
>
> Thanks,
> Debs.
>
> Rick Reeves wrote:
>> Hello Debs:
>>
>> Yes, this can be done by 'promoting' the polygons generated by the 
>> tripack package
>> into Spatial Polygon Data Frame objects, using the maptools and sp 
>> packages. I have
>> an example R script, written a few years ago, that does this with an 
>> older version of
>> the sp package. I suspect that it is easier to do now.....I could 
>> clean it up and send it to you..
>> Regards,
>> Rick Reeves
>>
>> Debarchana Ghosh wrote:
>>> Hi,
>>>
>>> I have a point data frame with X and Y coordinates, where n=1051. I am
>>> trying to create Voronoi polygons using both the Tripack and PBSMapping
>>> packages.
>>>
>>> library(tripack)
>>> testbird.vm<-voronoi.mosaic(testbird$X, testbird$Y)
>>> testbird.vp<-voronoi.polygons(testbird.vm)
>>> plot(testbird.vp)
>>>
>>> library(PBSMapping)
>>> testbirdvor<-calcVoronoi(testbird)
>>>
>>>  
>>>> >From here how can I create an ESRI shapefile of the voronoi 
>>>> polygons in R
>>>>     
>>> and export to ArcGIS for further use.
>>>
>>> Thanks for the help,
>>> Debs.
>>>
>>>   
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071115/3c63bdb5/attachment.vcf>

From reeves at nceas.ucsb.edu  Thu Nov 15 23:04:41 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Thu, 15 Nov 2007 14:04:41 -0800
Subject: [R-sig-Geo] Correction to that example...
Message-ID: <473CC279.7070609@nceas.ucsb.edu>

Debs (and list)

Please forgive the oversignt:  that post contained two errors:

     pcrds <- cbind(tritest.vp[[8]][,1],tritest.vp[[8]][,2] )
replaced by
    pcrds <- cbind(tritest.vp[[i]][,1],tritest.vp[[i]][,2] )

and this line should be removed:
    points(crds)

Thanks, Rick R

here is a corrected version:

voronoiShapefile <- function()
{
browser()
   data(tritest)
   tritest.vm <- voronoi.mosaic(tritest$x,tritest$y)
   tritest.vp <- voronoi.polygons(tritest.vm)

   polys <- vector(mode="list", length=length(tritest.vp))
   library(sp)
   for (i in seq(along=polys))
  {
      pcrds <- cbind(tritest.vp[[i]][,1],tritest.vp[[i]][,2] )
      pcrds <- rbind(pcrds, pcrds[1,])
      polys[[i]] <- Polygons(list(Polygon(pcrds)), ID=as.character(i))
   }
   SP <- SpatialPolygons(polys) # 8 spatial polygons generated using 
voronoi.polygons
#
# Generate the SpatialPolygonsDataFrame object. For the purposes of this 
example,
# we use the last 8 points in the input point dataset as the data 
component of the data frame.
# You will probably have 'actual' attribute data to assign to each 
polygon. See data.frame documentation
#
   SPDF <- SpatialPolygonsDataFrame(SP, 
data=data.frame(x=tritest$x[5:12],y=tritest$y[5:12],
                                                            
row.names=sapply(slot(SP, "polygons"),
                                                            function(x) 
slot(x, "ID"))))
#
   Areas <- sapply(slot(SP, "polygons"), function(x) slot(x, "area"))
 
   print(fivenum(Areas), digits=8)
   print(sort(Areas), digits=8)
   SPDF1 <- SPDF[Areas < 0.866027,]

   plot(SPDF1, axes=TRUE, xlim=c(1,10), ylim=c(1,10))
   library(maptools)
   writePolyShape(SPDF1, "hex")
}
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071115/4e8eb192/attachment.vcf>

From Ingo.Holz at uni-hohenheim.de  Fri Nov 16 13:45:19 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Fri, 16 Nov 2007 13:45:19 +0100
Subject: [R-sig-Geo] semi-transparent layer with image()
Message-ID: <473D9EEF.14047.156D8FB@ingoholz.uni-hohenheim.de>

Hi,

 I have two objects of "class image" (a list of x, y, z coordinates, where z is a 
matrix and x and y are row names / col names). 

 I would like to overlay one of this images on top of the other. As a semi-
transparent overlay. Is this possible using function image()?

 I suppose I could set some of the z-values as NA (every second?). Could 
this be a way to get a semi-transparent overlay?

  I know I could do this with a GIS or something similar...

Thank you for your help,
Ingo



From edzer.pebesma at uni-muenster.de  Fri Nov 16 13:58:04 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Fri, 16 Nov 2007 13:58:04 +0100
Subject: [R-sig-Geo] semi-transparent layer with image()
In-Reply-To: <473D9EEF.14047.156D8FB@ingoholz.uni-hohenheim.de>
References: <473D9EEF.14047.156D8FB@ingoholz.uni-hohenheim.de>
Message-ID: <473D93DC.8090901@uni-muenster.de>

Although not specifically related to r-sig-geo, I'll comment a bit -

I wouldn't delete part of the cells, but rather define the transparency 
bit in the color. You can do that, e.g. by

 > rgb(1,0,0,0.5)
[1] "#FF000080"

you'll get half transparent red. Note that you need a device that 
supports this; I'm not sure about windows screen device; X11 doesn't but 
Cairo does; pdf does if you specify version=1.4 or so (read ?pdf).
--
Edzer

Ingo Holz wrote:
> Hi,
>
>  I have two objects of "class image" (a list of x, y, z coordinates, where z is a 
> matrix and x and y are row names / col names). 
>
>  I would like to overlay one of this images on top of the other. As a semi-
> transparent overlay. Is this possible using function image()?
>
>  I suppose I could set some of the z-values as NA (every second?). Could 
> this be a way to get a semi-transparent overlay?
>
>   I know I could do this with a GIS or something similar...
>
> Thank you for your help,
> Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Ingo.Holz at uni-hohenheim.de  Fri Nov 16 14:46:51 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Fri, 16 Nov 2007 14:46:51 +0100
Subject: [R-sig-Geo] semi-transparent layer with image()
Message-ID: <473DAD5B.30286.18F2F58@ingoholz.uni-hohenheim.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071116/069e5179/attachment.pl>

From h.wickham at gmail.com  Fri Nov 16 23:34:55 2007
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 16 Nov 2007 16:34:55 -0600
Subject: [R-sig-Geo] semi-transparent layer with image()
In-Reply-To: <473DAD5B.30286.18F2F58@ingoholz.uni-hohenheim.de>
References: <473DAD5B.30286.18F2F58@ingoholz.uni-hohenheim.de>
Message-ID: <f8e6ff050711161434q466ad075s37066c0b49acbebc@mail.gmail.com>

There's the alpha function in the ggplot2 package:

plot(1:90, 1:90, pch=16, cex=2, col="red")
points(1:90, 1:90, pch=16, cex=2, col=alpha(grey(90:1/90), 0.5))

Hadley

On 11/16/07, Ingo Holz <Ingo.Holz at uni-hohenheim.de> wrote:
> Hi,
>
>  is there an easier way to get a semi-transparent grey-palette?
>
>  plot(1:90, 1:90, pch=16, cex=2, col="red")
>  points(1:90, 1:90, pch=16, cex=2, col=rgb(t(col2rgb(grey(90:1/90))),
> alpha=100, maxColorValue=255))
>
>  windows() does support semi-transparent colours
>
> Thanks,
> Ingo
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


-- 
http://had.co.nz/



From hi_ono2001 at ybb.ne.jp  Mon Nov 19 02:19:30 2007
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Mon, 19 Nov 2007 10:19:30 +0900 (JST)
Subject: [R-sig-Geo] Can voronoi polygons calculated in R be converted
	to ESRI shapefile?
In-Reply-To: <473CBEBF.6050309@nceas.ucsb.edu>
Message-ID: <20071119011930.62372.qmail@web10710.mail.bbt.yahoo.co.jp>

Hi

 Thank you for your useful info.

 However for following statement,

> voronoiShapefile <- function()
> {
-----X8--------------X8-----------X8--
>    for (i in seq(along=polys))
>   {
>       pcrds <-
> cbind(tritest.vp[[8]][,1],tritest.vp[[8]][,2] )

  I think all "8"s needed to "i" like this.

  cbind(tritest.vp[[i]][,1],tritest.vp[[i]][,2] )

  BTW, any method finding neightbour voronoi'cells' IDs?


 Regards.



From Ingo.Holz at uni-hohenheim.de  Mon Nov 19 15:07:24 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Mon, 19 Nov 2007 15:07:24 +0100
Subject: [R-sig-Geo] spplot(), SpatialGridDataFrame
Message-ID: <4741A6AC.22030.15E00B5@ingoholz.uni-hohenheim.de>

Hi,

 I have a SpatialGridDataFrame and want to plot it with spplot().

 Is it possible to plot only the grids that have a special value (eg. 312)?

 If it is not possible to do this with spplot() how would it be done with plot()?

Thanks, Ingo



From edzer.pebesma at uni-muenster.de  Mon Nov 19 15:49:29 2007
From: edzer.pebesma at uni-muenster.de (Edzer J. Pebesma)
Date: Mon, 19 Nov 2007 15:49:29 +0100
Subject: [R-sig-Geo] spplot(), SpatialGridDataFrame
In-Reply-To: <4741A6AC.22030.15E00B5@ingoholz.uni-hohenheim.de>
References: <4741A6AC.22030.15E00B5@ingoholz.uni-hohenheim.de>
Message-ID: <4741A279.9030003@uni-muenster.de>

Ingo Holz wrote:
> Hi,
>
>  I have a SpatialGridDataFrame and want to plot it with spplot().
>
>  Is it possible to plot only the grids that have a special value (eg. 312)?
>   
fullgrid(x) = FALSE
spplot(x[x$value == 312,"value"]

Note that if fullgrid(x) is TRUE, x[rows,cols] would select on 
rows/cols, not on attribute values.
>  If it is not possible to do this with spplot() how would it be done with plot()?
>
>   
I'd use image rather than plot; plot would use symbols instead of 
coloured squares.
--
Edzer
> Thanks, Ingo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From macq at llnl.gov  Mon Nov 19 22:27:13 2007
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 19 Nov 2007 13:27:13 -0800
Subject: [R-sig-Geo] Transforming from cartographic to arbitrary local
 coordinate system
Message-ID: <p06230904c367a2a6a021@[128.115.153.6]>

I have virtually no experience with cartographic coordinate systems, 
and transforming them, so I would like to ask for some help.

Someone has supplied me with a shapefile. When I open it in Qgis, 
Qgis tells me its "spatial reference system" is:

   +proj=lcc +lat_1=35.4666666666667 +lat_2=34.0333333333333 
+lat_0=33.5 +lon_0=-118 +x_0=1999999.9371016 +y_0=499999.9843516001 
+ellps=GRS80 +to_meter=0.3048006 +no_defs

I can read it into R using
    tmp <- readShapeLines('filename',
                       proj4string=CRS(pstring))

where pstring is that thing that Qgis gave me.
plot(tmp) then gives a picture that makes sense.

I would like to give the thing a convenient (to me) local coordinate 
system. I have quite a few such objects (all with the same proj.4 
spatial reference string (or coordinate specification?). Some are 
lines objects, some are polygon objects, and the polygon objects have 
nested polygons ("holes" or "islands").

Pretend for the moment that the lines of my object represent borders 
of a rectangular shaped plot of land . The rectangle is tilted 
relative to north/south.

What I now would like to do is rotate and shift the rectangle so that 
its borders appear vertical and horizontal (my local axes are 
parallel to its borders), and so that it has a local origin near one 
of the corners. I guess this isn't a true cartographic projection (?).

Is there a way I can do this with spTransform(), by supplying an 
appropriate CRS argument?


Thanks
-Don
-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA
925-423-1062



From dylan.beaudette at gmail.com  Mon Nov 19 22:50:15 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Mon, 19 Nov 2007 13:50:15 -0800
Subject: [R-sig-Geo] Transforming from cartographic to arbitrary local
	coordinate system
In-Reply-To: <p06230904c367a2a6a021@[128.115.153.6]>
References: <p06230904c367a2a6a021@[128.115.153.6]>
Message-ID: <200711191350.15169.dylan.beaudette@gmail.com>

On Monday 19 November 2007, Don MacQueen wrote:
> I have virtually no experience with cartographic coordinate systems,
> and transforming them, so I would like to ask for some help.
>
> Someone has supplied me with a shapefile. When I open it in Qgis,
> Qgis tells me its "spatial reference system" is:
>
>    +proj=lcc +lat_1=35.4666666666667 +lat_2=34.0333333333333
> +lat_0=33.5 +lon_0=-118 +x_0=1999999.9371016 +y_0=499999.9843516001
> +ellps=GRS80 +to_meter=0.3048006 +no_defs
>
> I can read it into R using
>     tmp <- readShapeLines('filename',
>                        proj4string=CRS(pstring))
>
> where pstring is that thing that Qgis gave me.
> plot(tmp) then gives a picture that makes sense.
>
> I would like to give the thing a convenient (to me) local coordinate
> system. I have quite a few such objects (all with the same proj.4
> spatial reference string (or coordinate specification?). Some are
> lines objects, some are polygon objects, and the polygon objects have
> nested polygons ("holes" or "islands").
>
> Pretend for the moment that the lines of my object represent borders
> of a rectangular shaped plot of land . The rectangle is tilted
> relative to north/south.
>
> What I now would like to do is rotate and shift the rectangle so that
> its borders appear vertical and horizontal (my local axes are
> parallel to its borders), and so that it has a local origin near one
> of the corners. I guess this isn't a true cartographic projection (?).
>
> Is there a way I can do this with spTransform(), by supplying an
> appropriate CRS argument?
>
>
> Thanks
> -Don

Hi Don, 

This looks like a US State-Plane coordinate system: Lambert Conformal Conic, 
with linear units defined in terms of feet. Try "re-projecting" the data to a 
local UTM zone first, or alternatively to achieve the rotation you are 
talking about, an Albers Equal Area projection. You will find the GDAL 
tool 'ogr2ogr' useful in this context. Here are some examples:

# convert shapefile whith defined projection to UTM Zone 10:
ogr2ogr -t_srs "+proj=utm +zone=10 +datum=NAD83" utm.shp original.shp 

Cheers,

Dylan

-- 
Dylan Beaudette
Soil Resource Laboratory
http://casoilresource.lawr.ucdavis.edu/
University of California at Davis
530.754.7341



From HMedina at iso.com  Mon Nov 19 23:55:47 2007
From: HMedina at iso.com (Medina, Hernan)
Date: Mon, 19 Nov 2007 17:55:47 -0500
Subject: [R-sig-Geo] finding points outside but very near a polygon
Message-ID: <248FB571F3283A4D9F0749C99DC6FFF8049BBAF1@ISOEMAILP2.iso.com>

I used the code below to find points in a North American Regional
Reanalysis data set that were within the 48 contiguous states.  

# The 48 contiguous states
m <- map("state",fill=TRUE,plot=FALSE)
indx1 <- in.polygon(m,list(x=my_lon,y=my_lat))
st <- map.where("state",my_lon,my_lat)

Unfortunately, this leaves out points that are over water.  For some of
the counties around Seattle Washington, I missed some of the points.  Is
there a way to find points that are just a little bit outside the border
of the polygon?

Hernan L. Medina

This email is intended for the recipient only.  If you are not the intended recipient please disregard, and do not use the information for any purpose.



From Roger.Bivand at nhh.no  Tue Nov 20 08:25:36 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 20 Nov 2007 08:25:36 +0100 (CET)
Subject: [R-sig-Geo] Transforming from cartographic to arbitrary local
 coordinate system
In-Reply-To: <p06230904c367a2a6a021@[128.115.153.6]>
References: <p06230904c367a2a6a021@[128.115.153.6]>
Message-ID: <Pine.LNX.4.64.0711200820510.11280@reclus.nhh.no>

On Mon, 19 Nov 2007, Don MacQueen wrote:

> I have virtually no experience with cartographic coordinate systems,
> and transforming them, so I would like to ask for some help.
>
> Someone has supplied me with a shapefile. When I open it in Qgis,
> Qgis tells me its "spatial reference system" is:
>
>   +proj=lcc +lat_1=35.4666666666667 +lat_2=34.0333333333333
> +lat_0=33.5 +lon_0=-118 +x_0=1999999.9371016 +y_0=499999.9843516001
> +ellps=GRS80 +to_meter=0.3048006 +no_defs
>
> I can read it into R using
>    tmp <- readShapeLines('filename',
>                       proj4string=CRS(pstring))
>
> where pstring is that thing that Qgis gave me.
> plot(tmp) then gives a picture that makes sense.
>
> I would like to give the thing a convenient (to me) local coordinate
> system. I have quite a few such objects (all with the same proj.4
> spatial reference string (or coordinate specification?). Some are
> lines objects, some are polygon objects, and the polygon objects have
> nested polygons ("holes" or "islands").
>
> Pretend for the moment that the lines of my object represent borders
> of a rectangular shaped plot of land . The rectangle is tilted
> relative to north/south.
>
> What I now would like to do is rotate and shift the rectangle so that
> its borders appear vertical and horizontal (my local axes are
> parallel to its borders), and so that it has a local origin near one
> of the corners. I guess this isn't a true cartographic projection (?).

The new elide methods in maptools would get you some of the way there, but 
only do 90 degree rotation, not arbitrary rotation. In general, sp classes 
expect north to be upwards, and no provision for other constructions is 
made. If you can find an appropriate PROJ.4 description for what you want, 
spTransform will do it, but the rotation is going to be the problem.

The easiest way in is almost certainly to customise elide() and adding 
trigenometry to do the arbitrary rotation.

Roger

>
> Is there a way I can do this with spTransform(), by supplying an
> appropriate CRS argument?
>
>
> Thanks
> -Don
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From mina_gu at yahoo.co.jp  Tue Nov 20 08:58:37 2007
From: mina_gu at yahoo.co.jp (=?ISO-2022-JP?B?GyRCISEhISEhISEhIRsoQiAbJEIhISEhISEhISEhGyhC?=)
Date: Tue, 20 Nov 2007 16:58:37 +0900 (JST)
Subject: [R-sig-Geo] About GeoBUGS and R
Message-ID: <20071120075837.34865.qmail@web3915.mail.bbt.yahoo.co.jp>

Hi, all

I use WinBUGS by way of R (R2WinBUGS).
So,I want to use GeoBUGS like this or another method
(batch / script etc.. not GUI.
I would like to use R,if possible).

Do you know what to do?

Thanks.

---
Minag (mina_gu at yahoo.co.jp)


--------------------------------------
New Design Yahoo! JAPAN  2008/01/01
http://pr.mail.yahoo.co.jp/newdesign/



From v.gomezrubio at imperial.ac.uk  Tue Nov 20 13:47:18 2007
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Tue, 20 Nov 2007 12:47:18 +0000
Subject: [R-sig-Geo] About GeoBUGS and R
In-Reply-To: <20071120075837.34865.qmail@web3915.mail.bbt.yahoo.co.jp>
References: <20071120075837.34865.qmail@web3915.mail.bbt.yahoo.co.jp>
Message-ID: <1195562838.8247.10.camel@fh-vrubio>

Dear Minag,

> I use WinBUGS by way of R (R2WinBUGS).
> So,I want to use GeoBUGS like this or another method
> (batch / script etc.. not GUI.
> I would like to use R,if possible).

What do you mean by using GeoBUGS? If you mean the spatial functions
(car.normal, etc.) you can make use of them as any other function in WB
by including them in your WB code and using R2WinBUGS to run it. If you
mean the adjacency tool, then you can check function nb2WB() in R to get
the adjacency matrix in the same way as in GeoBUGS from a nb object (see
the example therein). If you want to display the WB results in a map you
can use spplot(), for example.

Hope this helps.

Virgilio



From mperf at bp06.net  Tue Nov 20 15:05:01 2007
From: mperf at bp06.net (VISTAPRINT)
Date: Tue, 20 Nov 2007 15:05:01 +0100
Subject: [R-sig-Geo] =?utf-8?q?F=C3=A9licitation_vous_avez_gagn=C3=A9_un_c?=
	=?utf-8?q?alendrier_gratuit_!?=
Message-ID: <ASP104Z-0008GF000S1IU2071781@bp06.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071120/536fc5a6/attachment.pl>

From mina_gu at yahoo.co.jp  Wed Nov 21 06:42:08 2007
From: mina_gu at yahoo.co.jp (=?ISO-2022-JP?B?GyRCISEhISEhISEhIRsoQiAbJEIhISEhISEhISEhGyhC?=)
Date: Wed, 21 Nov 2007 14:42:08 +0900 (JST)
Subject: [R-sig-Geo] About GeoBUGS and R
In-Reply-To: <1195562838.8247.10.camel@fh-vrubio>
Message-ID: <20071121054208.46551.qmail@web3907.mail.bbt.yahoo.co.jp>

Dear Dr.Virsillo

Thank you for reply.
I try to spplot().

I want to use GeoBUGS for modeling and mapping(e.g SMR
map).
The former,I use GeoBUGS function by way of R2WinBUGS,but
latter I can't.

Usually,R2WinBUGS write results in logfile(.odc).
I want to add map to the logfile by way of R.
(If I use GeoBUGS's GUI with R2WinBUGS running on debug
mode(bugs(...,debug=TRUE)),
I can get it..)

Regards

Minag


--- Virgilio Gomez-Rubio <v.gomezrubio at imperial.ac.uk>
wrote:

> Dear Minag,
> 
> > I use WinBUGS by way of R (R2WinBUGS).
> > So,I want to use GeoBUGS like this or another
> method
> > (batch / script etc.. not GUI.
> > I would like to use R,if possible).
> 
> What do you mean by using GeoBUGS? If you mean the
> spatial functions
> (car.normal, etc.) you can make use of them as any
> other function in WB
> by including them in your WB code and using
> R2WinBUGS to run it. If you
> mean the adjacency tool, then you can check function
> nb2WB() in R to get
> the adjacency matrix in the same way as in GeoBUGS
> from a nb object (see
> the example therein). If you want to display the WB
> results in a map you
> can use spplot(), for example.
> 
> Hope this helps.
> 
> Virgilio
> 
> 


--------------------------------------
New Design Yahoo! JAPAN  2008/01/01
http://pr.mail.yahoo.co.jp/newdesign/



From hi_ono2001 at ybb.ne.jp  Wed Nov 21 09:33:55 2007
From: hi_ono2001 at ybb.ne.jp (Hisaji ONO)
Date: Wed, 21 Nov 2007 17:33:55 +0900 (JST)
Subject: [R-sig-Geo] Could you add my 'Jenks' method to your classInt
	package?
In-Reply-To: <Pine.LNX.4.64.0711200813070.11280@reclus.nhh.no>
Message-ID: <20071121083355.45456.qmail@web10714.mail.bbt.yahoo.co.jp>

Hello.

 I've tried to port Java code for Jenks optimization
classification method "natural break" to R, although far
from smart coding.

 My java code was ported Jenks's Basic code and I checked
these results compared to results of ArcView 3.x.

 Jenks method derived from Fischer, but seems to be a
little different in the algorithm.

 My code's results are similar to results of current
ArcGIS's, but not equal to them. Accordindg to Murray, A.
T. & Shyy, T. K.'s papaer (IJGIS, 2000, 14-7, 649-667,
http://geog-www.sbs.ohio-state.edu/faculty/murray/personal/research/crimepubs/murray-shyy2000.pdf),
there are difference between ArcGIS's and MapInfo's. How
about Autodesk's Map Guide Open Source which has employed
Jenks's method as a function.

 Could you try my following code and add this into your
classInt package if you like?


 Regards.





else if (style == "fisher") {
---- cut ---- cut ---- cut ---- cut ---- cut ----
        }
 else if (style == "Jenks") { # Jenks Optimisation Method
            d<- sort(var)
           #work<-matrix(0,k,length(d))
           mat1<-matrix(1,length(d),k)
           mat2<-matrix(0,length(d),k)
           mat2[2:length(d),1:k]<-10000000 #R's max double
value?
           v<-0

           for(l in 2:length(d)){
             s1=s2=w=0
             for(m in 1:l){
               i3 <- l - m + 1
               val <- d[i3]
               s2 <- s2 + val * val
               s1 <- s1 + val
               w<-w+1
               v <- s2 - (s1 * s1) / w
               i4 <- trunc(i3 - 1)

               if(i4 !=0){
                 for(j in 2:k){
                   if(mat2[l,j] >= (v + mat2[i4, j - 1])){
                     mat1[l,j] <- i3
                     mat2[l,j] <- v + mat2[i4, j - 1]
                   }
                 }
               }
             }
             mat1[l,1] <- 1
             mat2[l,1] <- v
           }

           kclass<-1:k
           kclass[k] <-length(d)
           k <- length(d)
           last<-length(d)
           for(j in length(kclass):1){
             id <- trunc(mat1[k,j]) - 1
             kclass[j - 1] <- id
             k <- id #lower
             last <- k -1 #upper
           }
           brks<-d[c(1, kclass)]
         }
         else stop(paste(style, "unknown"))



From v.gomezrubio at imperial.ac.uk  Wed Nov 21 13:35:50 2007
From: v.gomezrubio at imperial.ac.uk (Virgilio Gomez-Rubio)
Date: Wed, 21 Nov 2007 12:35:50 +0000
Subject: [R-sig-Geo] About GeoBUGS and R
In-Reply-To: <20071121054208.46551.qmail@web3907.mail.bbt.yahoo.co.jp>
References: <20071121054208.46551.qmail@web3907.mail.bbt.yahoo.co.jp>
Message-ID: <1195648550.25797.20.camel@fh-vrubio>

Dear Minga,

> I want to use GeoBUGS for modeling and mapping(e.g SMR
> map).
> The former,I use GeoBUGS function by way of R2WinBUGS,but
> latter I can't.
> 
> Usually,R2WinBUGS write results in logfile(.odc).
> I want to add map to the logfile by way of R.
> (If I use GeoBUGS's GUI with R2WinBUGS running on debug
> mode(bugs(...,debug=TRUE)),
> I can get it..)

Basically, what you need to do is to create a SpatialPolygonDataFrame
object from your map. Depending on the format, there are different
options available in R. Then you can read the results from your model
and add a new column to the map object with your estimate of the
smoothed relative risks (I presume). Then you can use spplot to display
the results.

Best,

Virgilio



From epistat at gmail.com  Wed Nov 21 14:17:25 2007
From: epistat at gmail.com (zhijie zhang)
Date: Wed, 21 Nov 2007 21:17:25 +0800
Subject: [R-sig-Geo] How to generate the coordinates of a circle if i know
	its center's coordinates and radius?
Message-ID: <2fc17e30711210517l90fce3bn5d5afeca65fdd701@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071121/29864ef5/attachment.pl>

From ggrothendieck at gmail.com  Wed Nov 21 14:28:53 2007
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 21 Nov 2007 08:28:53 -0500
Subject: [R-sig-Geo] How to generate the coordinates of a circle if i
	know its center's coordinates and radius?
In-Reply-To: <2fc17e30711210517l90fce3bn5d5afeca65fdd701@mail.gmail.com>
References: <2fc17e30711210517l90fce3bn5d5afeca65fdd701@mail.gmail.com>
Message-ID: <971536df0711210528k3a8ad0a0j8324630e65cd9815@mail.gmail.com>

See draw.circle and maybe draw.arc in the plotrix package.

On Nov 21, 2007 8:17 AM, zhijie zhang <epistat at gmail.com> wrote:
> Hi all,
>  How to generate the coordinates of a circle if i know  its center's
> coordinates and radius?
>  I want to overlay the circle with another figure, but i only know its
> center's coordinates and radius. It will be easy if i can get the
> coordinates of the circle.
>  Thanks.
>
> --
> With Kind Regards,
>
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
> [***********************************************************************]
> Zhi Jie,Zhang ,PHD
> Tel:+86-21-54237149
> Dept. of Epidemiology,School of Public Health,Fudan University
> Address:No. 138 Yi Xue Yuan Road,Shanghai,China
> Postcode:200032
> Email:epistat at gmail.com
> Website: www.statABC.com
> [***********************************************************************]
> oooO:::::::::
> (..):::::::::
> :\.(:::Oooo::
> ::\_)::(..)::
> :::::::)./:::
> ::::::(_/::::
> :::::::::::::
>
>        [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From Roger.Bivand at nhh.no  Wed Nov 21 19:15:07 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 21 Nov 2007 19:15:07 +0100 (CET)
Subject: [R-sig-Geo] Could you add my 'Jenks' method to your classInt
	package?
In-Reply-To: <20071121083355.45456.qmail@web10714.mail.bbt.yahoo.co.jp>
References: <20071121083355.45456.qmail@web10714.mail.bbt.yahoo.co.jp>
Message-ID: <Pine.LNX.4.64.0711211913290.15355@reclus.nhh.no>

On Wed, 21 Nov 2007, Hisaji ONO wrote:

> Hello.
>
> I've tried to port Java code for Jenks optimization
> classification method "natural break" to R, although far
> from smart coding.
>
> My java code was ported Jenks's Basic code and I checked
> these results compared to results of ArcView 3.x.
>
> Jenks method derived from Fischer, but seems to be a
> little different in the algorithm.
>
> My code's results are similar to results of current
> ArcGIS's, but not equal to them. Accordindg to Murray, A.
> T. & Shyy, T. K.'s papaer (IJGIS, 2000, 14-7, 649-667,
> http://geog-www.sbs.ohio-state.edu/faculty/murray/personal/research/crimepubs/murray-shyy2000.pdf),
> there are difference between ArcGIS's and MapInfo's. How
> about Autodesk's Map Guide Open Source which has employed
> Jenks's method as a function.
>
> Could you try my following code and add this into your
> classInt package if you like?

Thank you very much!

I have put your contribution into the sourceforge classInt repository in 
r-spatial - could those who are interested try it from there?

Roger

>
>
> Regards.
>
>
>
>
>
> else if (style == "fisher") {
> ---- cut ---- cut ---- cut ---- cut ---- cut ----
>        }
> else if (style == "Jenks") { # Jenks Optimisation Method
>            d<- sort(var)
>           #work<-matrix(0,k,length(d))
>           mat1<-matrix(1,length(d),k)
>           mat2<-matrix(0,length(d),k)
>           mat2[2:length(d),1:k]<-10000000 #R's max double
> value?
>           v<-0
>
>           for(l in 2:length(d)){
>             s1=s2=w=0
>             for(m in 1:l){
>               i3 <- l - m + 1
>               val <- d[i3]
>               s2 <- s2 + val * val
>               s1 <- s1 + val
>               w<-w+1
>               v <- s2 - (s1 * s1) / w
>               i4 <- trunc(i3 - 1)
>
>               if(i4 !=0){
>                 for(j in 2:k){
>                   if(mat2[l,j] >= (v + mat2[i4, j - 1])){
>                     mat1[l,j] <- i3
>                     mat2[l,j] <- v + mat2[i4, j - 1]
>                   }
>                 }
>               }
>             }
>             mat1[l,1] <- 1
>             mat2[l,1] <- v
>           }
>
>           kclass<-1:k
>           kclass[k] <-length(d)
>           k <- length(d)
>           last<-length(d)
>           for(j in length(kclass):1){
>             id <- trunc(mat1[k,j]) - 1
>             kclass[j - 1] <- id
>             k <- id #lower
>             last <- k -1 #upper
>           }
>           brks<-d[c(1, kclass)]
>         }
>         else stop(paste(style, "unknown"))
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From pegorett at science.unitn.it  Wed Nov 21 20:04:22 2007
From: pegorett at science.unitn.it (Stefano Pegoretti)
Date: Wed, 21 Nov 2007 20:04:22 +0100
Subject: [R-sig-Geo] computing rodogram & madogram
Message-ID: <47448136.9050504@science.unitn.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071121/3fb1a652/attachment.pl>

From siyali82 at gmail.com  Thu Nov 22 01:10:38 2007
From: siyali82 at gmail.com (Sisi)
Date: Thu, 22 Nov 2007 01:10:38 +0100
Subject: [R-sig-Geo] Large dataset on Ripley's K function
Message-ID: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071122/4808200b/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov 22 07:48:42 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 22 Nov 2007 07:48:42 +0100 (CET)
Subject: [R-sig-Geo] Large dataset on Ripley's K function
In-Reply-To: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no>

On Thu, 22 Nov 2007, Sisi wrote:

> Dear Roger Bivand and Dan Putler,
>
> Currently I'm working on the spatial point data analysis using Kernel
> estimation (spatstat), Ripley's K function (spatstat) and space-time K
> function (splancs). My research is at the continental level and the region
> area includes Asia, Europe and Africa. The methods work on small datasets
> (as I have seen solutions posted in R-sig-Geo by others) and this is not my
> real problem. Finding a solution with such a large dataset is the key issue
> here.
>
> I have a really big data set with 3345 points.

This number is not large in itself, and:

set.seed(1)
xy <- runifpoint(3500)
res <- Kest(xy, nlarge=3500)

works without any problems on a 1GB system:

> sessionInfo()
R version 2.6.0 (2007-10-03)
i386-pc-mingw32

locale:
LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian 
(Bokm?l)_Norway.1252;LC_MONETARY=Norwegian 
(Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian (Bokm?l)_Norway.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] spatstat_1.12-3 mgcv_1.3-29

(it is always helpful to include the output of sessionInfo())

However note that here:

> xy
  planar point pattern: 3500 points
window: rectangle = [0, 1] x [0, 1] units
> object.size(xy)
[1] 57760

only has the simplest window, and my guess is that your window mask is 
much richer (continental shorelines? raster landmass mask?). If so, edge 
correction will probably involve much more memory use. If you are using a 
vector shoreline, and this is the reason for the problems, have you tried 
using a raster mask instead?

I have tried using coarse GSHHS shorelines without difficulties (Rgshhs in 
maptools), but very possibly with a shoreline with too many details, you 
might see problems, or with a raster mask with too high resolution.

Have you considered the problems involved in using geographical 
coordinates?

Roger

> The spatial region includes
> Asia, Europe and Africa. When I run the "Kest" function, the error said
> "cannot allocate vector of size 382.8 Mb". I have already enlarge the memory
> to the maximum and make the nlarge=3500 in "Kest". I am not sure if this is
> the correct way of increase nlarge, as nlarge default value is 3000. Prior
> to me changing nlarge the following error message was "number of data points
> exceeds 3000 - computing border estimate only".
>
> Below is part of the code used where the error occurs:
>
> #Ripley's K function
> K <- Kest(p1,nlarge=3500)
> #Error: cannot allocate vector of size 381.8 Mb
> plot(K)
>
> Can you please assist?
> Thanks in advance.
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From A.Lam at geo.uu.nl  Thu Nov 22 15:00:50 2007
From: A.Lam at geo.uu.nl (Arien Lam)
Date: Thu, 22 Nov 2007 15:00:50 +0100
Subject: [R-sig-Geo] How to generate the coordinates of a circle if i
 know	its center's coordinates and radius?
In-Reply-To: <2fc17e30711210517l90fce3bn5d5afeca65fdd701@mail.gmail.com>
References: <2fc17e30711210517l90fce3bn5d5afeca65fdd701@mail.gmail.com>
Message-ID: <47458B92.6030609@geo.uu.nl>

For geographical coordinates, start with:
https://stat.ethz.ch/pipermail/r-sig-geo/2007-September/002595.html

Cheers, Arien

zhijie zhang schreef:
> Hi all,
>   How to generate the coordinates of a circle if i know  its center's
> coordinates and radius?
>   I want to overlay the circle with another figure, but i only know its
> center's coordinates and radius. It will be easy if i can get the
> coordinates of the circle.
>   Thanks.
>



From Ingo.Holz at uni-hohenheim.de  Thu Nov 22 15:19:53 2007
From: Ingo.Holz at uni-hohenheim.de (Ingo Holz)
Date: Thu, 22 Nov 2007 15:19:53 +0100
Subject: [R-sig-Geo] change projection?
Message-ID: <47459E19.23316.17F4DDA@ingoholz.uni-hohenheim.de>

Hi,

 I imported a ESRIAsciiGrid with readGDAL(). The result is a SpatialGridDataFrame (SGDF).

The projection of the grid (only the xllcorner, yllcorner ?) is:
Projection		LAMBERT
Units			METERS
Spheroid		BESSEL
(more details at the end of this email)

How can I change this to gauss-krueger projection zone 3 (gk3)?

I did not specify the projection in the SGDF, how is this done?

summary(SGDF):

Closing GDAL dataset handle (nil)... done.
Object of class SpatialGridDataFrame
Coordinates:
      min     max
x -250000  500000
y   20000 1020000
Is projected: NA 
proj4string : [NA]
Number of points: 2
Grid attributes:
  cellcentre.offset cellsize cells.dim
x           -249500     1000       750
y             20500     1000      1000
Data attributes:
     band1       
 Min.   :   812  
 ....

There should be a simple way to use library(proj4) to make this transformation?

Are I am right that actually only the "xllcorner, yllcorner"-values are transformed?

Where can I find an easy (and maybe short) introduction to this topic?

Thank you,
Ingo 


######
Description of Grid ...*

Cell Size (meters)	=	1000.000		Data Type:			
Integer
Number of Rows	 =	1000		 	Number of Values =		....*
Number of Columns =		750		 	Attribute Data (bytes) =	...*

BOUNDARY:					STATISTICS:
Xmin =			 -250000.000		Minimum Value =		...*
Xmax =		  500000.000		Maximum Value =		...*
Ymin =			    20000.000		Mean		 =		...*
Ymax =		1020000.000		Standard Deviation =		...*


COORDINATE SYSTEM DESCRIPTION

Projection		LAMBERT
Units			METERS
Spheroid		BESSEL
Parameters:
1st standard parallel				50 0 0.000
2nd standard parallel				51 0 0.000
central meridian				9 0 0.000
latitude of projection's origin			47 0 0.000
false easting (meters)				0.00000
false northing (meters)				0.00000



From Roger.Bivand at nhh.no  Thu Nov 22 17:47:20 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 22 Nov 2007 17:47:20 +0100 (CET)
Subject: [R-sig-Geo] change projection?
In-Reply-To: <47459E19.23316.17F4DDA@ingoholz.uni-hohenheim.de>
References: <47459E19.23316.17F4DDA@ingoholz.uni-hohenheim.de>
Message-ID: <Pine.LNX.4.64.0711221727370.18630@reclus.nhh.no>

On Thu, 22 Nov 2007, Ingo Holz wrote:

> Hi,
>
> I imported a ESRIAsciiGrid with readGDAL(). The result is a 
SpatialGridDataFrame (SGDF).
>
> The projection of the grid (only the xllcorner, yllcorner ?) is:
> Projection		LAMBERT
> Units			METERS
> Spheroid		BESSEL
> (more details at the end of this email)

You should be able to construct a string to represent this projection 
(which is more likely +proj=lcc than +proj=laea), although I cannot see it 
in the EPSG list as such.

>
> How can I change this to gauss-krueger projection zone 3 (gk3)?
>

This is a different projection, which means that the regular raster cells 
in the input will become irregular polygons in the output in general, and 
you need to warp from one to the other. You can interpolate to a regular 
grid in the output projection using standard interpolation tools.

> I did not specify the projection in the SGDF, how is this done?

proj4string(SGDF) <- CRS("<myprj>")

or if a *.prj file is present, readGDAL() may detect it.

Roger

>
> summary(SGDF):
>
> Closing GDAL dataset handle (nil)... done.
> Object of class SpatialGridDataFrame
> Coordinates:
>      min     max
> x -250000  500000
> y   20000 1020000
> Is projected: NA
> proj4string : [NA]
> Number of points: 2
> Grid attributes:
>  cellcentre.offset cellsize cells.dim
> x           -249500     1000       750
> y             20500     1000      1000
> Data attributes:
>     band1
> Min.   :   812
> ....
>
> There should be a simple way to use library(proj4) to make this transformation?
>
> Are I am right that actually only the "xllcorner, yllcorner"-values are transformed?
>
> Where can I find an easy (and maybe short) introduction to this topic?
>
> Thank you,
> Ingo
>
>
> ######
> Description of Grid ...*
>
> Cell Size (meters)	=	1000.000		Data Type:
> Integer
> Number of Rows	 =	1000		 	Number of Values =		....*
> Number of Columns =		750		 	Attribute Data (bytes) =	...*
>
> BOUNDARY:					STATISTICS:
> Xmin =			 -250000.000		Minimum Value =		...*
> Xmax =		  500000.000		Maximum Value =		...*
> Ymin =			    20000.000		Mean		 =		...*
> Ymax =		1020000.000		Standard Deviation =		...*
>
>
> COORDINATE SYSTEM DESCRIPTION
>
> Projection		LAMBERT
> Units			METERS
> Spheroid		BESSEL
> Parameters:
> 1st standard parallel				50 0 0.000
> 2nd standard parallel				51 0 0.000
> central meridian				9 0 0.000
> latitude of projection's origin			47 0 0.000
> false easting (meters)				0.00000
> false northing (meters)				0.00000
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dan.putler at sauder.ubc.ca  Thu Nov 22 18:46:16 2007
From: dan.putler at sauder.ubc.ca (Putler, Dan)
Date: Thu, 22 Nov 2007 09:46:16 -0800
Subject: [R-sig-Geo] Large dataset on Ripley's K function
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>
	<Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no>
Message-ID: <647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071122/69067896/attachment.pl>

From epistat at gmail.com  Fri Nov 23 11:34:18 2007
From: epistat at gmail.com (zhijie zhang)
Date: Fri, 23 Nov 2007 18:34:18 +0800
Subject: [R-sig-Geo] How to generate the coordinates of a circle if i
	know its center's coordinates and radius?
In-Reply-To: <47457473.6040504@geo.uu.nl>
References: <2fc17e30711210517l90fce3bn5d5afeca65fdd701@mail.gmail.com>
	<47457473.6040504@geo.uu.nl>
Message-ID: <2fc17e30711230234o65ed1432k2931cb4c12022d54@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071123/a42bb7f8/attachment.pl>

From siyali82 at gmail.com  Fri Nov 23 15:12:16 2007
From: siyali82 at gmail.com (Sisi)
Date: Fri, 23 Nov 2007 15:12:16 +0100
Subject: [R-sig-Geo] Large dataset on Ripley's K function
In-Reply-To: <647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private>
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>
	<Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no>
	<647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private>
Message-ID: <a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071123/d76ee361/attachment.pl>

From Roger.Bivand at nhh.no  Fri Nov 23 15:22:05 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 23 Nov 2007 15:22:05 +0100 (CET)
Subject: [R-sig-Geo] Large dataset on Ripley's K function
In-Reply-To: <a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com>
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com> 
	<Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no> 
	<647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private>
	<a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0711231516400.21607@reclus.nhh.no>

On Fri, 23 Nov 2007, Sisi wrote:

> Dear all,
>
> Thanks for your quick reply!
>
> For Roger, I checked the sessioninfo and mine is same as yours. My object
> size is indeed quite big, it is 275608. So I simplified the polygon
> and erased all the small islands, only hold the main land of Asia, Europe
> and Africa. After I loaded the polygon window and points, I checked the
> object size. It becomes  86768, which seems quite ok (compared with yours
> 57760). I ran the function again, and still doesn't work, the code and
> errors are as follow:
>
>
> sessionInfo()
> R version 2.6.0 (2007-10-03)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] RColorBrewer_1.0-2 spatstat_1.12-1    mgcv_1.3-27
> maptools_0.6-19    sp_0.9-16
> [6] foreign_0.8-23
>
> loaded via a namespace (and not attached):
> [1] grid_2.6.0     lattice_0.16-5 tools_2.6.0
>
> #Enlarge the memory
> memory.limit(size=4095)
> # creat polygon to be used as a window in ppp
> library(maptools)
> library(sp)
> library(spatstat)
> a <- readShapePoly("D:/5Bird/Result/New2Project.shp"[1])
> plot(a)
>
> # Define the window
> W <- as(as(a, "SpatialPolygons"), "owin")
> plot(W)
>
> # Import point data and creat ppp
> cases <- coordinates(readShapePoints("D:/5Bird/Result/BirdPoint.shp"))
> str(cases)
>
> #num [1:3345, 1:2] 5431396 5305812 5343499 1975828 2128985 ...
> #- attr(*, "dimnames")=List of 2
>  #..$ : NULL
>  #..$ : chr [1:2] "coords.x1" "coords.x2"
>
> colnames(cases)<-c("x","y")
> p1 <- ppp(cases[,1], cases[,2], window=W)
> plot(p1)
> points(cases, pch=20,col="red")
>
> object.size(p1)
> #[1] 86768
> #Ripley's K function
> K <- Kest(p1,nlarge=Inf)
> #Error: cannot allocate vector of size 38.6 Mb
> plot(K)
> #Generate envelope
> en <- envelope(p1, fun=Kest(p1,nlarge=3500), nsim=10)
> #Error: cannot allocate vector of size 38.6 Mb
> plot(en, main="Envelopes of K function based on CSR")
>
> For the question about the geographical coordinates, the projection system
> I'm using is Equidistant Cylindrical , the unit is meter. Just considering
> this projection has no distortion in distance.
>
> For Don, when I set nlarge=3500, the error was: "Error: cannot allocate
> vector of size 381.8 Mb". When I set nlarge=Inf, the error became:"Error:
> cannot allocate vector of size 38.6 Mb". I cannot figure out the cause
> of the errors. When you mentioned edge correction, I get a question to
> consult. Do I still need edge correction if my study area
> covers Asia, Europe and Africa continents. I mean the boundary is the real
> boundary, and beyond it is the sea.

The edge correction is the real issue. K is measuring the number of points 
within areas of distance bands adjusted for the area within the edges. So 
you have to correct - but shorelines may not be appropriate for birds - 
how far can your birds fly over water? Have you considered using a raster 
mask which would permit contact over channels between islands?

Roger

>
> Thank you for your time and best regards,
> Sisi
>
>
>
> On Thu, 22 Nov 2007, Roger Bivand  wrote:
>
> This number is not large in itself, and:
>
> set.seed(1)
> xy <- runifpoint(3500)
> res <- Kest(xy, nlarge=3500)
>
> works without any problems on a 1GB system:
>
>> sessionInfo()
> R version 2.6.0 (2007-10-03)
> i386-pc-mingw32
>
> locale:
> LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian
> (Bokm?l)_Norway.1252;LC_MONETARY=Norwegian
> (Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian (Bokm?l)_Norway.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] spatstat_1.12-3 mgcv_1.3-29
>
> (it is always helpful to include the output of sessionInfo())
>
> However note that here:
>
>> xy
> planar point pattern: 3500 points
> window: rectangle = [0, 1] x [0, 1] units
>> object.size(xy)
> [1] 57760
>
> only has the simplest window, and my guess is that your window mask is
> much richer (continental shorelines? raster landmass mask?). If so, edge
> correction will probably involve much more memory use. If you are using a
> vector shoreline, and this is the reason for the problems, have you tried
> using a raster mask instead?
>
> I have tried using coarse GSHHS shorelines without difficulties (Rgshhs in
> maptools), but very possibly with a shoreline with too many details, you
> might see problems, or with a raster mask with too high resolution.
>
> Have you considered the problems involved in using geographical
> coordinates?
>
> Roger
> On 22/11/2007, Putler, Dan <dan.putler at sauder.ubc.ca> wrote:
>
>>  Hi Sisi,
>>
>> By setting nlarge to 3500 you are creating problems (given that you have
>> just over 3300 observations) since you may be using either the isotropic or
>> Ripley's method for border correction. You want to use the border method
>> (which is what was used when nlarge was at its original value of 3000). To
>> quote the documentation of the function:
>>
>> If the point pattern X contains more than about 3000 points, the isotropic
>> and translation edge cor-
>> rections can be computationally prohibitive. The computations for the
>> border method are much
>> faster, and are statistically efficient when there are large numbers of
>> points. Accordingly, if the
>> number of points in X exceeds the threshold nlarge, then only the border
>> correction will be com-
>> puted. Setting nlarge=Inf will prevent this from happening. Setting
>> nlarge=0 is equivalent
>> to selecting only the border correction with correction="border".
>>
>> My guess is that Roger's suggested approach of simplifying the boundaries
>> is correct (my experience is that his suggestions are always on target),
>> which would allow you to take advantage of the other methods, but the using
>> the border method only can be justified in your case (and a lot easier to
>> implement).
>>
>> Dan
>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From dan.putler at sauder.ubc.ca  Fri Nov 23 18:38:17 2007
From: dan.putler at sauder.ubc.ca (Dan Putler)
Date: Fri, 23 Nov 2007 09:38:17 -0800
Subject: [R-sig-Geo] Large dataset on Ripley's K function
In-Reply-To: <a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com>
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>
	<Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no>
	<647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private>
	<a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com>
Message-ID: <1195839497.6179.8.camel@whitebox>

Hi Sisi,

A three continent study area is very large. It strikes me that border
effects would likely matter, so would probably need to be corrected for.
Although, what the correct border definition is will depend on what your
data relate to. Consequently, the natural question to ask is what kinds
of objects do your points represent?

Dan

On Fri, 2007-23-11 at 15:12 +0100, Sisi wrote:
> Dear all,
>  
> Thanks for your quick reply!
>  
> For Roger, I checked the sessioninfo and mine is same as yours. My
> object size is indeed quite big, it is 275608. So I simplified the
> polygon and erased all the small islands, only hold the main land of
> Asia, Europe and Africa. After I loaded the polygon window and points,
> I checked the object size. It becomes  86768, which seems quite ok
> (compared with yours 57760). I ran the function again, and still
> doesn't work, the code and errors are as follow:
>  
> sessionInfo()
> R version 2.6.0 (2007-10-03) 
> i386-pc-mingw32 
> 
> locale:
> LC_COLLATE=English_United States.1252;LC_CTYPE=English_United
> States.1252;LC_MONETARY=English_United
> States.1252;LC_NUMERIC=C;LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> base     
> 
> other attached packages:
> [1] RColorBrewer_1.0-2 spatstat_1.12-1    mgcv_1.3-27
> maptools_0.6-19    sp_0.9-16         
> [6] foreign_0.8-23    
> 
> loaded via a namespace (and not attached):
> [1] grid_2.6.0     lattice_0.16-5 tools_2.6.0   
> 
> 
> #Enlarge the memory
> memory.limit(size=4095)
> # creat polygon to be used as a window in ppp
> library(maptools)
> library(sp)
> library(spatstat)
> a <- readShapePoly("D:/5Bird/Result/New2Project.shp"[1]) 
> plot(a)
> 
> # Define the window
> W <- as(as(a, "SpatialPolygons"), "owin")
> plot(W)
> 
> # Import point data and creat ppp
> cases <- coordinates(readShapePoints("D:/5Bird/Result/BirdPoint.shp"))
> str(cases)
> 
> #num [1:3345, 1:2] 5431396 5305812 5343499 1975828 2128985 ...
>  #- attr(*, "dimnames")=List of 2
>   #..$ : NULL
>   #..$ : chr [1:2] "coords.x1" "coords.x2"
> 
> colnames(cases)<-c("x","y") 
> p1 <- ppp(cases[,1], cases[,2], window=W)
> plot(p1)
> points(cases, pch=20,col="red")
> 
> object.size(p1)
> #[1] 86768
> 
> 
> #Ripley's K function
> K <- Kest(p1,nlarge=Inf)
> #Error: cannot allocate vector of size 38.6 Mb
> plot(K)
> #Generate envelope 
> en <- envelope(p1, fun=Kest(p1,nlarge=3500), nsim=10) 
> #Error: cannot allocate vector of size 38.6 Mb
> plot(en, main="Envelopes of K function based on CSR")
>  
> For the question about the geographical coordinates, the projection
> system I'm using is Equidistant Cylindrical , the unit is meter. Just
> considering this projection has no distortion in distance.
>  
> For Don, when I set nlarge=3500, the error was: "Error: cannot
> allocate vector of size 381.8 Mb". When I set nlarge=Inf, the error
> became:"Error: cannot allocate vector of size 38.6 Mb". I cannot
> figure out the cause of the errors. When you mentioned edge
> correction, I get a question to consult. Do I still need edge
> correction if my study area covers Asia, Europe and Africa continents.
> I mean the boundary is the real boundary, and beyond it is the sea.
>  
> Thank you for your time and best regards,
> Sisi
>  
>  
>  
> On Thu, 22 Nov 2007, Roger Bivand  wrote:
>  
> This number is not large in itself, and:
> 
> set.seed(1)
> xy <- runifpoint(3500)
> res <- Kest(xy, nlarge=3500)
> 
> works without any problems on a 1GB system:
> 
> > sessionInfo() 
> R version 2.6.0 (2007-10-03)
> i386-pc-mingw32
> 
> locale:
> LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian
> (Bokm?l)_Norway.1252;LC_MONETARY=Norwegian
> (Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian
> (Bokm?l)_Norway.1252 
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] spatstat_1.12-3 mgcv_1.3-29
> 
> (it is always helpful to include the output of sessionInfo()) 
> 
> However note that here:
> 
> > xy
>  planar point pattern: 3500 points
> window: rectangle = [0, 1] x [0, 1] units
> > object.size(xy)
> [1] 57760
> 
> only has the simplest window, and my guess is that your window mask
> is 
> much richer (continental shorelines? raster landmass mask?). If so,
> edge
> correction will probably involve much more memory use. If you are
> using a
> vector shoreline, and this is the reason for the problems, have you
> tried 
> using a raster mask instead?
> 
> I have tried using coarse GSHHS shorelines without difficulties
> (Rgshhs in
> maptools), but very possibly with a shoreline with too many details,
> you
> might see problems, or with a raster mask with too high resolution. 
> 
> Have you considered the problems involved in using geographical
> coordinates?
> 
> Roger
> 
> On 22/11/2007, Putler, Dan <dan.putler at sauder.ubc.ca> wrote:
>         Hi Sisi,
>         
>         By setting nlarge to 3500 you are creating problems (given
>         that you have just over 3300 observations) since you may be
>         using either the isotropic or Ripley's method for border
>         correction. You want to use the border method (which is what
>         was used when nlarge was at its original value of 3000). To
>         quote the documentation of the function: 
>         
>         If the point pattern X contains more than about 3000 points,
>         the isotropic and translation edge cor-
>         rections can be computationally prohibitive. The computations
>         for the border method are much
>         faster, and are statistically efficient when there are large
>         numbers of points. Accordingly, if the 
>         number of points in X exceeds the threshold nlarge, then only
>         the border correction will be com-
>         puted. Setting nlarge=Inf will prevent this from happening.
>         Setting nlarge=0 is equivalent
>         to selecting only the border correction with
>         correction="border". 
>         
>         My guess is that Roger's suggested approach of simplifying the
>         boundaries is correct (my experience is that his suggestions
>         are always on target), which would allow you to take advantage
>         of the other methods, but the using the border method only can
>         be justified in your case (and a lot easier to implement). 
>         
>         Dan
>         
>         
> 
-- 
Dan Putler
Sauder School of Business
University of British Columbia



From siyali82 at gmail.com  Sat Nov 24 00:50:29 2007
From: siyali82 at gmail.com (Sisi)
Date: Sat, 24 Nov 2007 00:50:29 +0100
Subject: [R-sig-Geo] Large dataset on Ripley's K function
In-Reply-To: <1195839497.6179.8.camel@whitebox>
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com>
	<Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no>
	<647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private>
	<a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com>
	<1195839497.6179.8.camel@whitebox>
Message-ID: <a75641c60711231550g46f13895we4b0ef90e2fbd111@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071124/4b1a91ce/attachment.pl>

From Roger.Bivand at nhh.no  Sat Nov 24 07:55:07 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 24 Nov 2007 07:55:07 +0100 (CET)
Subject: [R-sig-Geo] Large dataset on Ripley's K function
In-Reply-To: <a75641c60711231550g46f13895we4b0ef90e2fbd111@mail.gmail.com>
References: <a75641c60711211610o6e6a6547h6306286096614e7a@mail.gmail.com> 
	<Pine.LNX.4.64.0711220724460.17444@reclus.nhh.no> 
	<647B90AA20066A40849C1518157B5BA12AD3BF@belgarth.sauder.private> 
	<a75641c60711230612p6cf8cf95n11f277e988c43ee3@mail.gmail.com> 
	<1195839497.6179.8.camel@whitebox>
	<a75641c60711231550g46f13895we4b0ef90e2fbd111@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0711240715470.26305@reclus.nhh.no>

On Sat, 24 Nov 2007, Sisi wrote:

> Dear all,
>
> It seems from the previous mails that you require the objective of the study
> in order to give approprate suggestions.

No. Like all the R lists, this list expects posters to follow the posting 
guide, which involves providing reproducable examples where the poster 
implies that software "does not work". This does not mean that there is 
any requirement to say what you are actually doing, only that you have a 
problem doing something - which can very well be a simple example.

Of course, it is a good idea to mention what the substantive research 
question is if it has significance for the posting. It is also useful to 
indicate an affiliation if posting from a non-informative email address 
like yours. It is polite to use one's name, not a nickname, especially if 
your questions involve those replying in using their time and effort doing 
so.

> My research objective is to detect the spatial, temporal and space-time 
> clustering of the birdflu outbreaks at the continental level.

Well, the file names in your earlier postings did suggest that birds were 
involved. Your other questions do however suggest that you are expecting 
the list to do your work for you, including reading basic references on 
point pattern analysis (which handle the importance of handling edge 
effects with care), and the help pages of the packages you have been 
using.

It is (perhaps unintentionally) evident that the results you may achieve 
will not provide much insight into the data generating process you claim 
to be interested in, including using small island windows and not handling 
the lack of homogeneity in the observed data (the distribution of farms 
with poultry is not uniform).

The posting guide does ask that posters refrain from posting homework 
questions (although good homework questions from posters with real names 
ans affiliations, and which demonstrate good preparation and effort are 
often answered anyway).

>
> Considering your suggestion about the raster mask, would this be able to
> give me a solution that elivates the problem I experienced in the R code
> given previously. It is difficult to find the solution to make the programme
> work. I really appreciate any suggestions you can provide.
>

Think through your process model (how you expect contagion to occur and 
whether it can occur across water bodies), see if you can find a control 
point pattern, such as the density of domestic poultry, recall that some 
incidences may not have been observed (or different virus strains may not 
be reported in your data), and review the relevant literature. Then look 
at ?im and ?as.owin.im.

The software all works (until you can demonstrate otherwise), the rest is 
in your hands. If you really get stuck, please do post, but preferably 
after thinking first and asking in your own institution (known offlist to 
be one with plenty of libraries, researchers, and R users).

Roger Bivand

> Kind regards,
> Sisi
>
>
>    Roger Bivand
> The edge correction is the real issue. K is measuring the number of points
> within areas of distance bands adjusted for the area within the edges. So
> you have to correct - but shorelines may not be appropriate for birds -
> how far can your birds fly over water? Have you considered using a raster
> mask which would permit contact over channels between islands?
>
>
> Roger
>
>
> On 23/11/2007, Dan Putler <dan.putler at sauder.ubc.ca> wrote:
>>
>> Hi Sisi,
>>
>> A three continent study area is very large. It strikes me that border
>> effects would likely matter, so would probably need to be corrected for.
>> Although, what the correct border definition is will depend on what your
>> data relate to. Consequently, the natural question to ask is what kinds
>> of objects do your points represent?
>>
>> Dan
>>
>>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From tomfool at as220.org  Sat Nov 24 23:04:17 2007
From: tomfool at as220.org (Tom Sgouros)
Date: Sat, 24 Nov 2007 17:04:17 -0500
Subject: [R-sig-Geo] mapping introduction
Message-ID: <20071124220417.17179FAC8EB@as220.org>


Hello all:

I was referred to this list when I asked a question on the r-help list
about mapping.  Unfortunately, I seem to be a little late to the party,
and a couple of weeks of monitoring the traffic have left me no more
enlightened than I was before, since it seems that the questions asked
are generally at a level I haven't approached yet.

I am an R user who wants to learn to make maps.  I have been using R to
analyze data associated with cities and towns in my area, and would
like to figure out how to get that data onto a map, but I'm having a
hard time seeing where to begin.

Assuming that I'm starting pretty much from zero, where can I start
reading in order to learn what is possible?  (And what to use to achieve
it.) 

I'm also a little confused about whether people use R as a GIS stand-in,
or whether they use some GIS package, and then use R as an adjunct.  If
the latter, can anyone recommend GNU or other freeware GIS packages to
learn about?  How about books to learn about them with?

Many thanks for your indulgence,

 -Tom

-- 
 ------------------------
 tomfool at as220 dot org
 http://sgouros.com  
 http://whatcheer.net



From dylan.beaudette at gmail.com  Sun Nov 25 05:29:00 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sat, 24 Nov 2007 20:29:00 -0800
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <20071124220417.17179FAC8EB@as220.org>
References: <20071124220417.17179FAC8EB@as220.org>
Message-ID: <200711242029.00372.dylan.beaudette@gmail.com>

On Saturday 24 November 2007 02:04:17 pm Tom Sgouros wrote:

Hi Tom, sorry to hear that you haven't discovered what you were looking for 
yet. Here are some comments / suggestions.

> Hello all:
>
> I was referred to this list when I asked a question on the r-help list
> about mapping.  Unfortunately, I seem to be a little late to the party,
> and a couple of weeks of monitoring the traffic have left me no more
> enlightened than I was before, since it seems that the questions asked
> are generally at a level I haven't approached yet.

R is one of those applications which takes some time to get into. I have been 
a graduate student for a couple years now, and it took three attempts to get 
over the initial "activation energy" required for me to feel comfortable with 
R. That said, persistence was really the key factor in getting there. 

> I am an R user who wants to learn to make maps.  I have been using R to
> analyze data associated with cities and towns in my area, and would
> like to figure out how to get that data onto a map, but I'm having a
> hard time seeing where to begin.

Now that you are familiar with working in R, it might be a good idea to become 
familiar with basic GIS concepts. There are a number of open source tools 
which can be used for GIS work, and quite a large community in the form of 
mailing lists / IRC channels. There are a number of books which should be 
coming out in the next couple of months which cover the wide range of open 
source GIS software. 

> Assuming that I'm starting pretty much from zero, where can I start
> reading in order to learn what is possible?  (And what to use to achieve
> it.)

Most of what I have learned about spatial statistics in R has been from a 
collection of books on R, R newsletter articles, and misc. online tutorials. 
Here is a link to some tutorials which illustrate using GRASS and R:

http://casoilresource.lawr.ucdavis.edu/drupal/node/438 

> I'm also a little confused about whether people use R as a GIS stand-in,
> or whether they use some GIS package, and then use R as an adjunct.  If
> the latter, can anyone recommend GNU or other freeware GIS packages to
> learn about? 

Since *most* R operations occur in memory, GIS operations on large datasets 
are best done in a dedicated GIS app like GRASS. For most of my work GRASS, 
GMT, PostGIS, R, and Mapserver are a tough combination to beat. 

> How about books to learn about them with? 
>

See above suggestions. There should be two books out soon which are dedicated 
to opensource GIS applications- I would keep an eye out for these.

Cheers,

Dylan



From Roger.Bivand at nhh.no  Sun Nov 25 12:10:23 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 25 Nov 2007 12:10:23 +0100 (CET)
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <200711242029.00372.dylan.beaudette@gmail.com>
References: <20071124220417.17179FAC8EB@as220.org>
	<200711242029.00372.dylan.beaudette@gmail.com>
Message-ID: <Pine.LNX.4.64.0711251155560.19104@reclus.nhh.no>

On Sat, 24 Nov 2007, Dylan Beaudette wrote:

> On Saturday 24 November 2007 02:04:17 pm Tom Sgouros wrote:
>
> Hi Tom, sorry to hear that you haven't discovered what you were looking for
> yet. Here are some comments / suggestions.
>
>> Hello all:
>>
>> I was referred to this list when I asked a question on the r-help list
>> about mapping.  Unfortunately, I seem to be a little late to the party,
>> and a couple of weeks of monitoring the traffic have left me no more
>> enlightened than I was before, since it seems that the questions asked
>> are generally at a level I haven't approached yet.
>
> R is one of those applications which takes some time to get into. I have been
> a graduate student for a couple years now, and it took three attempts to get
> over the initial "activation energy" required for me to feel comfortable with
> R. That said, persistence was really the key factor in getting there.
>
>> I am an R user who wants to learn to make maps.  I have been using R to
>> analyze data associated with cities and towns in my area, and would
>> like to figure out how to get that data onto a map, but I'm having a
>> hard time seeing where to begin.

In addition to Dylen's helpful reply, you might like to review the 
"Spatial" Task View on your local CRAN mirror, and the Rgeo website linked 
from the Task View. There are many possible choices, but using the classes 
and methods in the sp package may suit you. They are reviewed in a note in 
R News (2005 (2), pp. 9-13), in an online e-seminar at:

http://www.geog.uu.nl/~pebesma/wun/

and in courses and tutorials such as:

http://www.bias-project.org.uk/ASDARcourse/

Hope this helps,

Roger

>
> Now that you are familiar with working in R, it might be a good idea to become
> familiar with basic GIS concepts. There are a number of open source tools
> which can be used for GIS work, and quite a large community in the form of
> mailing lists / IRC channels. There are a number of books which should be
> coming out in the next couple of months which cover the wide range of open
> source GIS software.
>
>> Assuming that I'm starting pretty much from zero, where can I start
>> reading in order to learn what is possible?  (And what to use to achieve
>> it.)
>
> Most of what I have learned about spatial statistics in R has been from a
> collection of books on R, R newsletter articles, and misc. online tutorials.
> Here is a link to some tutorials which illustrate using GRASS and R:
>
> http://casoilresource.lawr.ucdavis.edu/drupal/node/438
>
>> I'm also a little confused about whether people use R as a GIS stand-in,
>> or whether they use some GIS package, and then use R as an adjunct.  If
>> the latter, can anyone recommend GNU or other freeware GIS packages to
>> learn about?
>
> Since *most* R operations occur in memory, GIS operations on large datasets
> are best done in a dedicated GIS app like GRASS. For most of my work GRASS,
> GMT, PostGIS, R, and Mapserver are a tough combination to beat.
>
>> How about books to learn about them with?
>>
>
> See above suggestions. There should be two books out soon which are dedicated
> to opensource GIS applications- I would keep an eye out for these.
>
> Cheers,
>
> Dylan
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From dylan.beaudette at gmail.com  Sun Nov 25 19:32:27 2007
From: dylan.beaudette at gmail.com (Dylan Beaudette)
Date: Sun, 25 Nov 2007 10:32:27 -0800
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <20071125043133.4D834FAC8EB@as220.org>
References: <20071124220417.17179FAC8EB@as220.org>
	<200711242029.00372.dylan.beaudette@gmail.com>
	<20071125043133.4D834FAC8EB@as220.org>
Message-ID: <200711251032.27443.dylan.beaudette@gmail.com>

On Saturday 24 November 2007 08:31:33 pm tom sgouros wrote:
> Thanks very much for the reply.  I think a lot of my confusion is in not
> knowing where the boundaries fall between the different applications.
> Can you tell me roughly the division of labor among the software you
> mentioned?

Sure. I use GRASS / PostGIS anytime I need to work with GIS data: raster, 
vector + attributes, etc. Importing, merging, subsetting, modification, and 
summarizing are best done within a GIS (I think). When I need graphical 
summaries (box and whisker plots and such) I will import the data into R and 
go from there. In other words, most of the heavy lifting of pushing pixels 
and vertices is done in the GIS. All of the analysis is done in R: summaries, 
hypothesis testing, and prediction using models. This nice thing about the 
GRASS-R bindings is that you can predict from GRASS data, and send the 
predicted values right back into a GRASS raster/vector . 

Lately I have been using R to produce some maps -- although mainly maps of 
purely vector data like thematic maps. The high quality PDF output from R 
makes for an ideal platform for producing press-ready vector graphics. Check 
out the spplot() function in the sp package for plotting a mixture of 
vector / raster data. When plotting raster data out to a PDF, be careful 
about generating gigantic files -- each pixel can be represented with a 
little rectangle, and for large grids can result in massive PDF files. 

I will try and post an examples of this.. in the mean time check out Roger's 
sp website- it should be in the manual page for the sp package. There are 
numerous mapping examples in there. 

For more complex maps I tend to favor GMT. Examples:
http://casoilresource.lawr.ucdavis.edu/drupal/node/130

>
> Dylan Beaudette <dylan.beaudette at gmail.com> wrote:
> > For most of my work GRASS,
> > GMT, PostGIS, R, and Mapserver are a tough combination to beat.
>
> Do you know any identifying details about the books you speak of here?
> (Are you writing one?)

I had to look through some notes: i am reviewing one of them, and contributed 
a chapter (along with Markus Neteler and others) to the other. 

1. Desktop GIS by Gary E. Sherman
This one provides an excellent introduction to both GIS and the entire range 
of open source software which can be used. There isn't (as of now) anything 
in there about R, but is a great resource otherwise.

2.  G.B. Hall (Ed), "Open Source Approaches to Spatial Data Handling", 
Springer, New York. In press.

This one should have some material on R -- sprinkled into some of the relevant 
chapters. I know that the GRASS chapter has a bit on R, specifically that 
kriging example I sent last time. 

A Related example can be found here:
http://casoilresource.lawr.ucdavis.edu/drupal/node/442


Those books should be out soon- I will post back when I hear from the 
authors / publisher.

> > See above suggestions. There should be two books out soon which are
> > dedicated to opensource GIS applications- I would keep an eye out for
> > these.
>
> Thanks again,
>
>  -Tom

Cheers,

Dylan



From reeves at nceas.ucsb.edu  Sun Nov 25 19:50:03 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Sun, 25 Nov 2007 10:50:03 -0800
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <20071124220417.17179FAC8EB@as220.org>
References: <20071124220417.17179FAC8EB@as220.org>
Message-ID: <4749C3DB.70500@nceas.ucsb.edu>

Hi Tom:

Good question. The information on GIS/Mapping and R (as well as other 
open-source software tools)
is somewhat decentralized, but there is a great deal of high-quality 
information available if you
know where to look -

One place that you might start is the CRAN task view for spatial data 
analysis:

http://cran.r-project.org/src/contrib/Views/Spatial.html

Another is a web site that we are developing here at the Center intended 
to educate ecologists
here and elsewhere on spatial analysis / mapping / GIS techniques:

http://nceas.ucsb.edu/scicomp/SolutionsCenter.html

http://nceas.ucsb.edu/scicomp/SciCompDocuments.html

These sites have many links to spatial data analysis resources;
we are adding to these sites on a regular basis.

Another very good site is maintained by the Soil Resource lab at UC Davis:

http://casoilresource.lawr.ucdavis.edu/drupal/taxonomy_dhtml (site map)

Best Regards,
Rick Reeves


Tom Sgouros wrote:
> Hello all:
>
> I was referred to this list when I asked a question on the r-help list
> about mapping.  Unfortunately, I seem to be a little late to the party,
> and a couple of weeks of monitoring the traffic have left me no more
> enlightened than I was before, since it seems that the questions asked
> are generally at a level I haven't approached yet.
>
> I am an R user who wants to learn to make maps.  I have been using R to
> analyze data associated with cities and towns in my area, and would
> like to figure out how to get that data onto a map, but I'm having a
> hard time seeing where to begin.
>
> Assuming that I'm starting pretty much from zero, where can I start
> reading in order to learn what is possible?  (And what to use to achieve
> it.) 
>
> I'm also a little confused about whether people use R as a GIS stand-in,
> or whether they use some GIS package, and then use R as an adjunct.  If
> the latter, can anyone recommend GNU or other freeware GIS packages to
> learn about?  How about books to learn about them with?
>
> Many thanks for your indulgence,
>
>  -Tom
>
>   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071125/e779878a/attachment.vcf>

From tomfool at as220.org  Sun Nov 25 21:18:34 2007
From: tomfool at as220.org (tom sgouros)
Date: Sun, 25 Nov 2007 15:18:34 -0500
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <4749C3DB.70500@nceas.ucsb.edu> 
References: <20071124220417.17179FAC8EB@as220.org>
	<4749C3DB.70500@nceas.ucsb.edu>
Message-ID: <20071125201834.7E72FFAC5BD@as220.org>


Hello all:

I almost hesitate to write and thank you all for the helpful replies,
because good ones keep appearing in my inbox, and who would want to put
a stop to that?

But my gratitude overcomes my cupiditude, so thank you all very much for
the pointers.

 -Tom

-- 
 ------------------------
 tomfool at as220 dot org
 http://sgouros.com  
 http://whatcheer.net



From tomfool at as220.org  Mon Nov 26 00:02:07 2007
From: tomfool at as220.org (tom sgouros)
Date: Sun, 25 Nov 2007 18:02:07 -0500
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <20071125201834.7E72FFAC5BD@as220.org> 
References: <20071124220417.17179FAC8EB@as220.org>
	<4749C3DB.70500@nceas.ucsb.edu>
	<20071125201834.7E72FFAC5BD@as220.org>
Message-ID: <20071125230207.2D45DFAC445@as220.org>


Hello all:

I've gotten two requests asking me to post a summary of the answers I
got to my question.  The answers were dense, and will take me a bit to
assimilate, but here's my early attempt at a review.  People will, I
hope, correct where I'm screwing it up.

The overall message was not to confuse R with a GIS system.  Use a GIS
to manipulate and display geographical data; use R to analyze it.

I found this helpful:

> Most of what I have learned about spatial statistics in R has been from a 
> collection of books on R, R newsletter articles, and misc. online tutorials. 
> Here is a link to some tutorials which illustrate using GRASS and R:

> http://casoilresource.lawr.ucdavis.edu/drupal/node/438 

GRASS came up frequently, as did QGIS as freeware GIS systems to try.
I'm not sure how to judge between them, but I figure frequency of
mention isn't a bad start.

> In which case, I recommend you look at uDig
> (http://undig.refractions.net), QGIS (www.qgis.org), and/or gvSIG
> (http://www.gvsig.gva.es/index.php?id=gvsig&L=2), which are open source,
> desktop GIS packages. If you are in the latter case, you will want one
> of the desktop products mentioned above (and GRASS will also be a
> possible option, http://grass.itc.it), and will you also want to look
> into the sp, maptools, PBSmapping, and spatstat R packages.

I've been looking into sp, of course, but haven't yet found the
introduction that will take me from the ground floor up to its dizzying
heights.  What seems true of it is something I've noticed about a lot or
R: there is stellar reference material available, but not much in the
way of usage guides.  The working theory seems to be that you pick that
up while you're earning your statistics PhD.

Along those lines, the following is a rich vein of information, but most
of it presumes you already know what you want:

> You might like to review the "Spatial" Task View on your local CRAN
> mirror, and the Rgeo website linked from the Task View. There are many
> possible choices, but using the classes and methods in the sp package
> may suit you.

On the other hand, I think the following will be quite helpful, since it
contains examples of maps similar to those I would like to create:

> and in courses and tutorials such as:
> 
> http://www.bias-project.org.uk/ASDARcourse/

It seems that a lot of my confusion is in and around the division of
software labor, so this explanation has set me on what I think is the
right course:

> > Thanks very much for the reply.  I think a lot of my confusion is in not
> > knowing where the boundaries fall between the different applications.
> > Can you tell me roughly the division of labor among the software you
> > mentioned?
> 
> Sure. I use GRASS / PostGIS anytime I need to work with GIS data: raster, 
> vector + attributes, etc. Importing, merging, subsetting, modification, and 
> summarizing are best done within a GIS (I think). When I need graphical 
> summaries (box and whisker plots and such) I will import the data into R and 
> go from there. In other words, most of the heavy lifting of pushing pixels 
> and vertices is done in the GIS. All of the analysis is done in R: summaries, 
> hypothesis testing, and prediction using models. This nice thing about the 
> GRASS-R bindings is that you can predict from GRASS data, and send the 
> predicted values right back into a GRASS raster/vector . 
> 
> Lately I have been using R to produce some maps -- although mainly maps of 
> purely vector data like thematic maps. The high quality PDF output from R 
> makes for an ideal platform for producing press-ready vector graphics. Check 
> out the spplot() function in the sp package for plotting a mixture of 
> vector / raster data. When plotting raster data out to a PDF, be careful 
> about generating gigantic files -- each pixel can be represented with a 
> little rectangle, and for large grids can result in massive PDF files. 
> 
> I will try and post an examples of this.. in the mean time check out Roger's 
> sp website- it should be in the manual page for the sp package. There are 
> numerous mapping examples in there. 
> 
> For more complex maps I tend to favor GMT. Examples:
> http://casoilresource.lawr.ucdavis.edu/drupal/node/130
> 

So my plan right now is to install the maptools package so I can follow
some of the course materials at bias-project.org.uk, and to install
GRASS or QGIS in the hope that one of them can help me convert the
ESRI-format political boundary map files available from my local
planning offices into something that R can munch on.  (I'm pretty sure
I'll be back seeking all your indulgence sometime then.)  For the moment,
I expect that the mapping I'll do will be via maptools, since the
immediate need is pretty rudimentary.  I still know nothing about GRASS
and QGIS (but will soon) so don't yet know whether I can produce
print-quality (hi-res, vector graphic axes and fonts) maps from them,
but I hope so.  (And I'll be checking out GMT, too.)

So that's what I learned this weekend.  Many thanks again for all the
advice.

 -tom





tom sgouros <tomfool at as220.org> wrote:

> 
> Hello all:
> 
> I almost hesitate to write and thank you all for the helpful replies,
> because good ones keep appearing in my inbox, and who would want to put
> a stop to that?
> 
> But my gratitude overcomes my cupiditude, so thank you all very much for
> the pointers.
> 
>  -Tom
> 
> -- 
>  ------------------------
>  tomfool at as220 dot org
>  http://sgouros.com  
>  http://whatcheer.net
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 


-- 
 ------------------------
 tomfool at as220 dot org
 http://sgouros.com  
 http://whatcheer.net



From p.vanbreugel at gmail.com  Mon Nov 26 12:55:20 2007
From: p.vanbreugel at gmail.com (Paulo van Breugel)
Date: Mon, 26 Nov 2007 14:55:20 +0300
Subject: [R-sig-Geo] mapping introduction
Message-ID: <474AB428.3060307@gmail.com>

Hi Tom,

In addition to the (very useful) earlier posts, I would like to point 
out SAGA GIS. It is a very good GIS software (and freeware / open 
source), especially for grid analyses. It has a command line version, 
which together with the ability of R to  invoke system commands using 
either 'Shell' or 'system' makes it fairly easy to do the typical GIS 
work in SAGA, and carry out other analyses in R, all from within R. With 
the recent release of the RSAGA package for R this has become 
considerably easier.

The documentation for SAGA is somewhat poor, but there are two very 
useful user guides available. See the SAGA website 
(http://www.saga-gis.uni-goettingen.de/html/index.php) for links. See 
CRAN for the RSAGA package.

Paulo



From hengl at science.uva.nl  Mon Nov 26 15:57:07 2007
From: hengl at science.uva.nl (Tomislav Hengl)
Date: Mon, 26 Nov 2007 15:57:07 +0100
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <474AB428.3060307@gmail.com>
Message-ID: <002c01c8303c$9d6d34d0$3a871291@pcibed193>


Dear Paulo,

I completely agree about SAGA. I have been monitoring the evolution of SAGA (or better to say of
Olaf Conrad) for quite some time. It is definitively one of the most extensive packages to analyze
DEMs, but also to do various grid computing (including geostatistics; see also my lecture notes
down-below).

I would be very much interested to see your R code-examples where you call SAGA operations. Olaf
told me that this functionality is still under construction (at least no instruction exists yet).

all the best,

Tom Hengl
http://spatial-analyst.net 

Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of Environmental Variables. EUR 22904
EN Scientific and Technical Research series, Office for Official Publications of the European
Communities, Luxemburg, 143 pp.
http://eusoils.jrc.it/ESDB_Archive/eusoils_docs/other/EUR22904en.pdf 


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
Paulo van Breugel
Sent: maandag 26 november 2007 12:55
To: tomfool at as220.org
Cc: r-sig-geo at stat.math.ethz.ch
Subject: Re: [R-sig-Geo] mapping introduction

Hi Tom,

In addition to the (very useful) earlier posts, I would like to point 
out SAGA GIS. It is a very good GIS software (and freeware / open 
source), especially for grid analyses. It has a command line version, 
which together with the ability of R to  invoke system commands using 
either 'Shell' or 'system' makes it fairly easy to do the typical GIS 
work in SAGA, and carry out other analyses in R, all from within R. With 
the recent release of the RSAGA package for R this has become 
considerably easier.

The documentation for SAGA is somewhat poor, but there are two very 
useful user guides available. See the SAGA website 
(http://www.saga-gis.uni-goettingen.de/html/index.php) for links. See 
CRAN for the RSAGA package.

Paulo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo



From stanhopkins at comcast.net  Mon Nov 26 16:59:21 2007
From: stanhopkins at comcast.net (Stan Hopkins)
Date: Mon, 26 Nov 2007 10:59:21 -0500
Subject: [R-sig-Geo] mapping introduction
References: <002c01c8303c$9d6d34d0$3a871291@pcibed193>
Message-ID: <00bb01c83045$4fa88520$6505a8c0@MXD32803WB>

I was just about ready to option out of this sig group as being too when the 
last few of questions and answers were posted perhaps by beginners like 
myself.

I wonder if there's any way to separate newbie questions from the more 
advanced so that my mailbox isn't flooded with the later.

Thanks,

Stan

----- Original Message ----- 
From: "Tomislav Hengl" <hengl at science.uva.nl>
To: "'Paulo van Breugel'" <p.vanbreugel at gmail.com>; <tomfool at as220.org>
Cc: <r-sig-geo at stat.math.ethz.ch>
Sent: Monday, November 26, 2007 9:57 AM
Subject: Re: [R-sig-Geo] mapping introduction


>
> Dear Paulo,
>
> I completely agree about SAGA. I have been monitoring the evolution of 
> SAGA (or better to say of
> Olaf Conrad) for quite some time. It is definitively one of the most 
> extensive packages to analyze
> DEMs, but also to do various grid computing (including geostatistics; see 
> also my lecture notes
> down-below).
>
> I would be very much interested to see your R code-examples where you call 
> SAGA operations. Olaf
> told me that this functionality is still under construction (at least no 
> instruction exists yet).
>
> all the best,
>
> Tom Hengl
> http://spatial-analyst.net
>
> Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of 
> Environmental Variables. EUR 22904
> EN Scientific and Technical Research series, Office for Official 
> Publications of the European
> Communities, Luxemburg, 143 pp.
> http://eusoils.jrc.it/ESDB_Archive/eusoils_docs/other/EUR22904en.pdf
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch 
> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> Paulo van Breugel
> Sent: maandag 26 november 2007 12:55
> To: tomfool at as220.org
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] mapping introduction
>
> Hi Tom,
>
> In addition to the (very useful) earlier posts, I would like to point
> out SAGA GIS. It is a very good GIS software (and freeware / open
> source), especially for grid analyses. It has a command line version,
> which together with the ability of R to  invoke system commands using
> either 'Shell' or 'system' makes it fairly easy to do the typical GIS
> work in SAGA, and carry out other analyses in R, all from within R. With
> the recent release of the RSAGA package for R this has become
> considerably easier.
>
> The documentation for SAGA is somewhat poor, but there are two very
> useful user guides available. See the SAGA website
> (http://www.saga-gis.uni-goettingen.de/html/index.php) for links. See
> CRAN for the RSAGA package.
>
> Paulo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> -- 
> No virus found in this incoming message.
> Checked by AVG Free Edition.
> Version: 7.5.503 / Virus Database: 269.16.7/1151 - Release Date: 
> 11/25/2007 4:24 PM
>
>



From iqbaljamal at shaw.ca  Mon Nov 26 16:59:44 2007
From: iqbaljamal at shaw.ca (Iqbal Jamal)
Date: Mon, 26 Nov 2007 08:59:44 -0700
Subject: [R-sig-Geo] Binary Map File
Message-ID: <cfd9fad142c05.474a8b00@shaw.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071126/226a1195/attachment.pl>

From Roger.Bivand at nhh.no  Mon Nov 26 18:55:25 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 26 Nov 2007 18:55:25 +0100 (CET)
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <00bb01c83045$4fa88520$6505a8c0@MXD32803WB>
References: <002c01c8303c$9d6d34d0$3a871291@pcibed193>
	<00bb01c83045$4fa88520$6505a8c0@MXD32803WB>
Message-ID: <Pine.LNX.4.64.0711261844100.23687@reclus.nhh.no>

On Mon, 26 Nov 2007, Stan Hopkins wrote:

> I was just about ready to option out of this sig group as being too when the
> last few of questions and answers were posted perhaps by beginners like
> myself.
>
> I wonder if there's any way to separate newbie questions from the more
> advanced so that my mailbox isn't flooded with the later.

This has been asked on the R-help list several times, with the general 
result that the current mixture of less and more experienced users being 
more beneficial for both than any alternative. The R wiki is also 
well-nigh moribund, for the same reasons (briefly that some posts by 
users with less experience are really high quality - point up a real 
issue, and attract the attention of more experienced users.

So the differences in experience are seen as a good thing for the R 
project as a whole. Very little of the traffic on this list is as 
difficult as R-devel, which involved system changes and compiled code, and 
much good advice offered here is contributed by users who, until recently, 
would have fell that they did not have much experience (at least with 
R-like things).

The R lists can be subscribed to in digest mode, and can be accessed via 
nabble and gmane too. So there are options. Offers to contribute new text 
to the Rgeo site and to the Spatial Task View will be welcomed - there is 
room for improvement in both that I'm aware of but cannot carry out for 
lack of time - any offers?

Thank you for your patience so far! One of the best kinds of contribution 
that can be made is good comments and questions!

Roger

>
> Thanks,
>
> Stan
>
> ----- Original Message -----
> From: "Tomislav Hengl" <hengl at science.uva.nl>
> To: "'Paulo van Breugel'" <p.vanbreugel at gmail.com>; <tomfool at as220.org>
> Cc: <r-sig-geo at stat.math.ethz.ch>
> Sent: Monday, November 26, 2007 9:57 AM
> Subject: Re: [R-sig-Geo] mapping introduction
>
>
>>
>> Dear Paulo,
>>
>> I completely agree about SAGA. I have been monitoring the evolution of
>> SAGA (or better to say of
>> Olaf Conrad) for quite some time. It is definitively one of the most
>> extensive packages to analyze
>> DEMs, but also to do various grid computing (including geostatistics; see
>> also my lecture notes
>> down-below).
>>
>> I would be very much interested to see your R code-examples where you call
>> SAGA operations. Olaf
>> told me that this functionality is still under construction (at least no
>> instruction exists yet).
>>
>> all the best,
>>
>> Tom Hengl
>> http://spatial-analyst.net
>>
>> Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of
>> Environmental Variables. EUR 22904
>> EN Scientific and Technical Research series, Office for Official
>> Publications of the European
>> Communities, Luxemburg, 143 pp.
>> http://eusoils.jrc.it/ESDB_Archive/eusoils_docs/other/EUR22904en.pdf
>>
>>
>> -----Original Message-----
>> From: r-sig-geo-bounces at stat.math.ethz.ch
>> [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
>> Paulo van Breugel
>> Sent: maandag 26 november 2007 12:55
>> To: tomfool at as220.org
>> Cc: r-sig-geo at stat.math.ethz.ch
>> Subject: Re: [R-sig-Geo] mapping introduction
>>
>> Hi Tom,
>>
>> In addition to the (very useful) earlier posts, I would like to point
>> out SAGA GIS. It is a very good GIS software (and freeware / open
>> source), especially for grid analyses. It has a command line version,
>> which together with the ability of R to  invoke system commands using
>> either 'Shell' or 'system' makes it fairly easy to do the typical GIS
>> work in SAGA, and carry out other analyses in R, all from within R. With
>> the recent release of the RSAGA package for R this has become
>> considerably easier.
>>
>> The documentation for SAGA is somewhat poor, but there are two very
>> useful user guides available. See the SAGA website
>> (http://www.saga-gis.uni-goettingen.de/html/index.php) for links. See
>> CRAN for the RSAGA package.
>>
>> Paulo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at stat.math.ethz.ch
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> --
>> No virus found in this incoming message.
>> Checked by AVG Free Edition.
>> Version: 7.5.503 / Virus Database: 269.16.7/1151 - Release Date:
>> 11/25/2007 4:24 PM
>>
>>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From p.vanbreugel at gmail.com  Mon Nov 26 21:22:31 2007
From: p.vanbreugel at gmail.com (Paulo van Breugel)
Date: Mon, 26 Nov 2007 23:22:31 +0300
Subject: [R-sig-Geo] mapping introduction
In-Reply-To: <002c01c8303c$9d6d34d0$3a871291@pcibed193>
References: <002c01c8303c$9d6d34d0$3a871291@pcibed193>
Message-ID: <474B2B07.7040707@gmail.com>

Dear Tom,

Thanks for the lecture notes, very interesting. I don't use the 
combination R - SAGA for the more advanced geostatistics you're 
describing, but rather to access more basic GIS modules such as the grid 
calculator and resample modules. But I don't see any reason why you 
couldn't use it for the other modules too.

I would recommend to have a look at the RSAGA package. It makes it 
easier to use SAGA. Moreover, it offers extended functionality, which, 
and I quote from the package help file, "include specific functions that 
are intended to be more user-friendly interfaces to the most frequently 
used SAGA modules. These higher-level interfaces support default values 
for the arguments and perform some error checking".

For those modules for which there is no direct interface (most), there 
is a low-level function (rsaga.geoprocessor) that can be used to run any 
SAGA modules and pass arguments. The interface is slightly different 
than when using the command line directly, see the RSAGA documentation 
for that. I just started using RSAGA so maybe you can also contact the 
author of the RSAGA package or use the SAGA user to user forum for more 
information.

Whether you use RSAGA or not, finding out the syntax of the different 
modules is probably the most complicated step because of missing 
documentation. For those interested, I normally use the following steps 
to figure out the arguments to a function (no R involved yet). I assume 
here you know which module you want to use; in this example I want to 
use the grid calculator to multiply grid 'inputA.sgrd' with grid 
'inputB.sgrd'

1) Before you run any command, you have to set the SAGA path, module 
path and data (working) directory, using the following commands (when 
you use RSAGA in R, this is easier):

 > cd c:\\program files\\saga_vc
 > set SAGA=.
 > SET SAGA_MLB=./modules
 > PATH=PATH;%SAGA%;%SAGA_MLB%

2) To find out which module library to call, you can select the module 
library that contains your module in the SAGA GUI (grid-calculus in this 
case) and than the description tab in the object properties window for 
the name of the dll (grid_calculus.dll).

3) Go back to the command line window and type in:

 > saga_cmd grid_calculus

4) You will be presented with a list of modules. Find the one you want 
to use. The grid calculator is module 1.

 > saga_cmd grid_calculus 1

5) you will be presented with the required syntax options. In my 
example, I'll need to give the names of the input and output layers and 
the equation:

 > saga_cmd grid_calculus 1 -INPUT inputA.sgrd;inputB.sgrd -RESULT 
output.sgrd -FORMUL a*b

 From within R, using the RSAGA package, you would use the following code:

rsaga.geoprocessor("grid_calculus", module=1, param=list(INPUT 
="inputA.sgrd;inputB.sgrd", RESULT=output.sgrd, FORMUL= 'a*b')

---
Below a small example of some real (but simple) code I used to resample 
grids to a certain extent and resolution. I wrote it as a function 
because I had to resample many grids to the same extent and resolution.

resample.SAGA <- function(sgrd.in, sgrd.out=sgrd, column=4294, 
rows=5415, east=12.210798, south=-13.451510, cell.size=0.008333, 
up.scale=0, down.scale=0){
options(digits=15)
rsaga.geoprocessor("grid_tools", module=0, param=list(INPUT=sgrd.in, 
GRID=sgrd.out, METHOD=1, KEEP_TYPE="", SYSTEM_SYSTEM_NX=column, 
SYSTEM_SYSTEM_NY=rows, SYSTEM_SYSTEM_X=east, SYSTEM_SYSTEM_Y=south, 
SYSTEM_SYSTEM_D=cell.size, SCALE_DOWN_METHOD=up.scale, 
SCALE_UP_METHOD=down.scale))}

---
In the following example I use the 'change grid values' module to change 
the grid values of a raster. The lookup table 'change.clim', with the 
mandatory three columns "Low Value", "High Value", and "Replace with", 
was generated in R:

library(foreign); library(RSAGA)
write.dbf(change.clim, "c:\\temp\\change_clim.dbf")
rsaga.geoprocessor("grid_tools", module=12, 
param=list(GRID_IN=c:\\temp\\clim.sgrd, GRID_OUT=c:\\temp\\climzon, 
METHOD=0, LOOKUP= c:\\temp\\chang_clim.dbf)
shell("del c:\\temp\\change_clim.dbf")

These are very simple examples, but hopefully they are useful nonetheless.

Paulo




Tomislav Hengl wrote:
> Dear Paulo,
>
> I completely agree about SAGA. I have been monitoring the evolution of SAGA (or better to say of
> Olaf Conrad) for quite some time. It is definitively one of the most extensive packages to analyze
> DEMs, but also to do various grid computing (including geostatistics; see also my lecture notes
> down-below).
>
> I would be very much interested to see your R code-examples where you call SAGA operations. Olaf
> told me that this functionality is still under construction (at least no instruction exists yet).
>
> all the best,
>
> Tom Hengl
> http://spatial-analyst.net 
>
> Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of Environmental Variables. EUR 22904
> EN Scientific and Technical Research series, Office for Official Publications of the European
> Communities, Luxemburg, 143 pp.
> http://eusoils.jrc.it/ESDB_Archive/eusoils_docs/other/EUR22904en.pdf 
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> Paulo van Breugel
> Sent: maandag 26 november 2007 12:55
> To: tomfool at as220.org
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] mapping introduction
>
> Hi Tom,
>
> In addition to the (very useful) earlier posts, I would like to point 
> out SAGA GIS. It is a very good GIS software (and freeware / open 
> source), especially for grid analyses. It has a command line version, 
> which together with the ability of R to  invoke system commands using 
> either 'Shell' or 'system' makes it fairly easy to do the typical GIS 
> work in SAGA, and carry out other analyses in R, all from within R. With 
> the recent release of the RSAGA package for R this has become 
> considerably easier.
>
> The documentation for SAGA is somewhat poor, but there are two very 
> useful user guides available. See the SAGA website 
> (http://www.saga-gis.uni-goettingen.de/html/index.php) for links. See 
> CRAN for the RSAGA package.
>
> Paulo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>   




Tomislav Hengl wrote:
> Dear Paulo,
>
> I completely agree about SAGA. I have been monitoring the evolution of SAGA (or better to say of
> Olaf Conrad) for quite some time. It is definitively one of the most extensive packages to analyze
> DEMs, but also to do various grid computing (including geostatistics; see also my lecture notes
> down-below).
>
> I would be very much interested to see your R code-examples where you call SAGA operations. Olaf
> told me that this functionality is still under construction (at least no instruction exists yet).
>
> all the best,
>
> Tom Hengl
> http://spatial-analyst.net 
>
> Hengl, T., 2007. A Practical Guide to Geostatistical Mapping of Environmental Variables. EUR 22904
> EN Scientific and Technical Research series, Office for Official Publications of the European
> Communities, Luxemburg, 143 pp.
> http://eusoils.jrc.it/ESDB_Archive/eusoils_docs/other/EUR22904en.pdf 
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at stat.math.ethz.ch [mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of
> Paulo van Breugel
> Sent: maandag 26 november 2007 12:55
> To: tomfool at as220.org
> Cc: r-sig-geo at stat.math.ethz.ch
> Subject: Re: [R-sig-Geo] mapping introduction
>
> Hi Tom,
>
> In addition to the (very useful) earlier posts, I would like to point 
> out SAGA GIS. It is a very good GIS software (and freeware / open 
> source), especially for grid analyses. It has a command line version, 
> which together with the ability of R to  invoke system commands using 
> either 'Shell' or 'system' makes it fairly easy to do the typical GIS 
> work in SAGA, and carry out other analyses in R, all from within R. With 
> the recent release of the RSAGA package for R this has become 
> considerably easier.
>
> The documentation for SAGA is somewhat poor, but there are two very 
> useful user guides available. See the SAGA website 
> (http://www.saga-gis.uni-goettingen.de/html/index.php) for links. See 
> CRAN for the RSAGA package.
>
> Paulo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>



From spurushothaman at nsac.ca  Tue Nov 27 00:36:09 2007
From: spurushothaman at nsac.ca (Sreedevi Purushothaman)
Date: Mon, 26 Nov 2007 19:36:09 -0400
Subject: [R-sig-Geo] Hexagonal latice
Message-ID: <474B20290200003E00002CD3@fs005.nsac.ns.ca>

Hi 

I am a student from Novs Scotia Agricultural College,Canada.
I am working on modleing of biod diversity in a natural eco system.
Now we are dealing with 2D hexagonal lattices.
If you could clear doubt,it will be very nice.
I just want to know whetehr,all the corner elemets in a hexagonal lattice with any number of rows will have 6 neighbours after applying cyclic boundary conditions?

Hope that am not disturbing you much

Sincerely
Sreedevi



From sreedeviep at gmail.com  Tue Nov 27 00:39:14 2007
From: sreedeviep at gmail.com (Sreedevi E.P)
Date: Mon, 26 Nov 2007 19:39:14 -0400
Subject: [R-sig-Geo] Hexagonal lattice
Message-ID: <6b04f30f0711261539y31b2c066nd0f3561a337dea7a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071126/972f7e1e/attachment.pl>

From White.Denis at epamail.epa.gov  Tue Nov 27 02:54:37 2007
From: White.Denis at epamail.epa.gov (White.Denis at epamail.epa.gov)
Date: Mon, 26 Nov 2007 17:54:37 -0800
Subject: [R-sig-Geo] Hexagonal lattice
Message-ID: <OF74FA119A.169247F9-ON882573A0.00092090-882573A0.000A7E9C@epamail.epa.gov>


Dear Sreedevi,

It depends on what kind of topological manifold you embed the lattice
in.  On a sphere the answer is no, because hexagons cannot tessellate a
sphere.  There can be 8 or 12 pentagons, for example, depending on
whether you use a spherical octagon or icosahedron model.  Perhaps
hexagons can tessellate a torus, but I have not examined that.  If so,
then all cells would have six neighbors.

But the question to ask is why do you want to wrap the boundaries?
Unless you are in fact modeling the entire sphere or doing strictly
theoretical studies, real world study areas have limits and it is
appropriate to impose restricted neighborhoods on boundary hexagons.

If you do want to work on a sphere you should visit the web site
http://www.sou.edu/cs/sahr/dgg/, where software for implementing
hexagons on spheres is available.

With respect to dynamic modeling on square or hexagonal grids, you may
be interested in the attached paper accepted for publication: White D,
Kiester AR; Topology matters: network topology affects outcomes from
community ecology neutral models; Computers, Environment and Urban
Systems.

best wishes,
Denis White
   US EPA, 200 SW 35th St, Corvallis, Oregon, 97333 USA
   voice: 541.754.4476, email: white.denis at epa.gov
   web: www.epa.gov/wed/pages/staff/white/


(See attached file: topology.matters.pdf)

----- Forwarded by Denis White/COR/USEPA/US on 2007-11-26 17:39 -----

Tony Olsen/COR/USEPA/US wrote on 2007-11-26 17:33:04:

> FYI.  He might be interested in your hex biodiversity papers and
algorithms.
>
> tony
>
> ----- Forwarded by Tony Olsen/COR/USEPA/US on 11/26/2007 05:32 PM
-----
>
> From: "Sreedevi E.P" <sreedeviep at gmail.com>
> Date: 11/26/2007 03:39 PM
> To: "r-sig-geo at stat.math.ethz.ch" <r-sig-geo at stat.math.ethz.ch>
> Subject: [R-sig-Geo] Hexagonal lattice
>
> Hi
>
> I am a student from Novs Scotia Agricultural College,Canada.
> I am working on modleing of biod diversity in a natural eco system.
> Now we are dealing with 2D hexagonal lattices.
> If you could clear doubt,it will be very nice.
> I just want to know whetehr,all the corner elemets in a hexagonal
lattice
> with any number of rows will have 6 neighbours after applying cyclic
> boundary conditions?
>
> Hope that am not disturbing you much
>
> Sincerely
> Sreedevi
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-------------- next part --------------
A non-text attachment was scrubbed...
Name: topology.matters.pdf
Type: application/pdf
Size: 182256 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071126/ef53fd6d/attachment.pdf>

From guzzetta at fbk.eu  Tue Nov 27 14:52:18 2007
From: guzzetta at fbk.eu (Giorgio Guzzetta)
Date: Tue, 27 Nov 2007 14:52:18 +0100
Subject: [R-sig-Geo] Buffer regions / owin to spatial object
Message-ID: <474C2112.4040603@fbk.eu>

Hello everybody.

I have a set of points and I want to calculate a buffer region within a
given distance from these points without using packages requiring other 
software (such as spgrass6). I have used function disc() for each
point and then union.owin() (both from spatstat) to merge the single
buffers.
The result is an object of class owin, but I would need to obtain an 
object representing the polygons enclosing this buffer.

1) Are there smarter ways to obtain the buffer region (the union.owin is
very slow when it comes to hundreds of points, as it must be applied to 
only two owin at a time)? It seems there isn't for buffers around 
polygons (as Adrian Baddeley wrote in a recent thread).

2) If not, how do I convert the owin object into a Spatial object? There 
are many functions doing the inverse, but I couldn't find any doing this
conversion.

Sorry if the questions are naive... I'm an R beginner :)

Thanks,
Giorgio Guzzetta



From HMedina at iso.com  Tue Nov 27 15:04:03 2007
From: HMedina at iso.com (Medina, Hernan)
Date: Tue, 27 Nov 2007 09:04:03 -0500
Subject: [R-sig-Geo] Buffer regions / owin to spatial object
In-Reply-To: <474C2112.4040603@fbk.eu>
References: <474C2112.4040603@fbk.eu>
Message-ID: <248FB571F3283A4D9F0749C99DC6FFF804A7DC0F@ISOEMAILP2.iso.com>

I have a question similar to Giorgio's.  I have a set of points that
cover a large region that could be projected as a parallelogram
including Canada, Greenland, the USA, and Mexico, as well as portions of
the Artic, Atlantic and Pacific oceans and the Great Lakes.  I used R
and the maps and mapdata packages to obtain the set points on land with
the in.polygon internal function.  I would like, however, to have a
buffer region of roughly 10 miles (16 km) around the coastal areas.
This seems similar to what Giorgio is trying to accomplish.

Hernan Medina


-----Original Message-----
From: r-sig-geo-bounces at stat.math.ethz.ch
[mailto:r-sig-geo-bounces at stat.math.ethz.ch] On Behalf Of Giorgio
Guzzetta
Sent: Tuesday, November 27, 2007 8:52 AM
To: r-sig-geo at stat.math.ethz.ch
Subject: [R-sig-Geo] Buffer regions / owin to spatial object

Hello everybody.

I have a set of points and I want to calculate a buffer region within a
given distance from these points without using packages requiring other 
software (such as spgrass6). I have used function disc() for each
point and then union.owin() (both from spatstat) to merge the single
buffers.
The result is an object of class owin, but I would need to obtain an 
object representing the polygons enclosing this buffer.

1) Are there smarter ways to obtain the buffer region (the union.owin is
very slow when it comes to hundreds of points, as it must be applied to 
only two owin at a time)? It seems there isn't for buffers around 
polygons (as Adrian Baddeley wrote in a recent thread).

2) If not, how do I convert the owin object into a Spatial object? There

are many functions doing the inverse, but I couldn't find any doing this
conversion.

Sorry if the questions are naive... I'm an R beginner :)

Thanks,
Giorgio Guzzetta

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

This email is intended for the recipient only.  If you are not the intended recipient please disregard, and do not use the information for any purpose.



From jgalkows at akamai.com  Tue Nov 27 18:03:48 2007
From: jgalkows at akamai.com (Galkowski, Jan)
Date: Tue, 27 Nov 2007 12:03:48 -0500
Subject: [R-sig-Geo] voronoi/Delaunay/Dirichlet tessellation on sphere in R
	or S?
Message-ID: <8FF09F15CB196E41B1CEA0FDADEAC6831641831D@MAVS1.kendall.corp.akamai.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071127/f06626fb/attachment.pl>

From Roger.Bivand at nhh.no  Wed Nov 28 21:46:07 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 28 Nov 2007 21:46:07 +0100 (CET)
Subject: [R-sig-Geo] Binary Map File
In-Reply-To: <cfd9fad142c05.474a8b00@shaw.ca>
References: <cfd9fad142c05.474a8b00@shaw.ca>
Message-ID: <Pine.LNX.4.64.0711282135030.29502@reclus.nhh.no>

On Mon, 26 Nov 2007, Iqbal Jamal wrote:

> Greetings:
>
> I'm trying to create a county map of Alberta, Canada and wondering
> how best to use the lat/lon data that I have. Do I need to create a binary map file?
> If so, how? Do these files exist at an ftp site, etc?

It seems possible that the boundaries you want may be found on the WMS 
service at http://www.geobase.ca/geobase/en/index.html, but a WFS service 
would have been more use. There may be other sources - could anyone with 
insight into boundary data for counties in Alberta, presumably as vector 
polygons, please help?

I'm not sure what is meant by a binary map here - digital?

Roger

> I wanted to recreate the examples using the dataset "state".
>
> Thanks
>
> Iqbal
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Wed Nov 28 22:28:34 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 28 Nov 2007 22:28:34 +0100 (CET)
Subject: [R-sig-Geo] Buffer regions / owin to spatial object
In-Reply-To: <474C2112.4040603@fbk.eu>
References: <474C2112.4040603@fbk.eu>
Message-ID: <Pine.LNX.4.64.0711282148190.29502@reclus.nhh.no>

On Tue, 27 Nov 2007, Giorgio Guzzetta wrote:

> Hello everybody.
>
> I have a set of points and I want to calculate a buffer region within a
> given distance from these points without using packages requiring other
> software (such as spgrass6). I have used function disc() for each
> point and then union.owin() (both from spatstat) to merge the single
> buffers.
> The result is an object of class owin, but I would need to obtain an
> object representing the polygons enclosing this buffer.
>
> 1) Are there smarter ways to obtain the buffer region (the union.owin is
> very slow when it comes to hundreds of points, as it must be applied to
> only two owin at a time)? It seems there isn't for buffers around
> polygons (as Adrian Baddeley wrote in a recent thread).

If you can move to raster, you can use erode and dilate methods for owin 
objects to buffer in and buffer out - these are based on "im" objects. It 
will not be quite the same, but the errors for moderate resolution 
probably will not be greater than the inaccuracies in polygon boundaries 
(where curves are represented as line segments).

library(maptools)
library(spatstat)
set.seed(1)
pts <- runifpoint(20)
grd <- GridTopology(c(0.005, 0.005), c(0.01, 0.01), c(100, 100))
ptsi <- overlay(SpatialGrid(grd), as(pts, "SpatialPoints"))
SGDF <- SpatialGridDataFrame(grd, data=data.frame(pts=rep(NA, 10000)))
SGDF$pts[ptsi] <- 1
pts_im <- as(SGDF, "im")
pts_owin <- as.owin(pts_im)
plot(pts_owin)
plot(pts, add=TRUE)
pts_owin_0.03 <- dilate.owin(pts_owin, r=0.03)
plot(pts_owin_0.03)
plot(pts, add=TRUE)

gets part of the way there, but most likely better routes exist.

>
> 2) If not, how do I convert the owin object into a Spatial object? There
> are many functions doing the inverse, but I couldn't find any doing this
> conversion.
>

You can get from "im" to SpatialGridDataFrame and from "ppp" fo several sp 
classes. So if you go with raster, you can retrieve the buffered objects.

Hope this helps,

Roger


> Sorry if the questions are naive... I'm an R beginner :)
>
> Thanks,
> Giorgio Guzzetta
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From iqbaljamal at shaw.ca  Wed Nov 28 22:41:07 2007
From: iqbaljamal at shaw.ca (Iqbal Jamal)
Date: Wed, 28 Nov 2007 14:41:07 -0700
Subject: [R-sig-Geo] Binary Map File
In-Reply-To: <Pine.LNX.4.64.0711282135030.29502@reclus.nhh.no>
References: <cfd9fad142c05.474a8b00@shaw.ca>
	<Pine.LNX.4.64.0711282135030.29502@reclus.nhh.no>
Message-ID: <f329e3212c74.474d7e03@shaw.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071128/cf766640/attachment.pl>

From Roger.Bivand at nhh.no  Thu Nov 29 08:44:21 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 29 Nov 2007 08:44:21 +0100 (CET)
Subject: [R-sig-Geo] Binary Map File
In-Reply-To: <f329e3212c74.474d7e03@shaw.ca>
References: <cfd9fad142c05.474a8b00@shaw.ca>
	<Pine.LNX.4.64.0711282135030.29502@reclus.nhh.no>
	<f329e3212c74.474d7e03@shaw.ca>
Message-ID: <Pine.LNX.4.64.0711290831420.31808@reclus.nhh.no>

On Wed, 28 Nov 2007, Iqbal Jamal wrote:

> Thanks for your response.
>
> This is the limit of my understanding to date:
>
> For "binary" I was referring to the files with extensions *.G, *.L which
> I gather are built using gmake and lmake. I'm trying to understand the
> format for the *.gon and *.line files that can be built into *.G and *.L files
> for use with package 'map'.
>
> Please let me know if I am thinking about this in the right way.

You can go that way if you choose. You'll need first to break out the line 
segments into a text file, then massage them manually into the required 
unique format. They will then need to have their topologies built, and as 
a final exercise in patience, you'll need to find out which built polygons 
belong to which counties. All of this is described in:

Richard A. Becker, and Allan R. Wilks, "Constructing a Geographical 
Database", AT&T Bell Laboratories Statistics, Research Report [95.2], 
1995. http://public.research.att.com/areas/stat/doc/95.2.ps

as mentioned in ?map.

On the other hand, you might find it easier to read the boundary data file 
by functions in the rgdal, maptools, shapefiles, or RArcInfo packages, 
read it in, and use it directly? The difference is mostly that map() style 
polygons must have a built topology because the line segments are only 
stored once, while most external formats and there representations in R 
(such as the sp package SpatialPolygons class) use a list of closed rings, 
avoiding building topologies.

Usually, finding the data file is the most difficult, and you'll need it 
anyway irrespective of your choice.

Roger

>
> Iqbal
>
>
> ----- Original Message -----
> From: Roger Bivand <Roger.Bivand at nhh.no>
> Date: Wednesday, November 28, 2007 1:46 pm
> Subject: Re: [R-sig-Geo] Binary Map File
> To: Iqbal Jamal <iqbaljamal at shaw.ca>
> Cc: r-sig-geo at stat.math.ethz.ch
>
>> On Mon, 26 Nov 2007, Iqbal Jamal wrote:
>>
>>> Greetings:
>>>
>>> I'm trying to create a county map of Alberta, Canada and wondering
>>> how best to use the lat/lon data that I have. Do I need to
>> create a binary map file?
>>> If so, how? Do these files exist at an ftp site, etc?
>>
>> It seems possible that the boundaries you want may be found on
>> the WMS
>> service at http://www.geobase.ca/geobase/en/index.html, but a
>> WFS service
>> would have been more use. There may be other sources - could
>> anyone with
>> insight into boundary data for counties in Alberta, presumably
>> as vector
>> polygons, please help?
>>
>> I'm not sure what is meant by a binary map here - digital?
>>
>> Roger
>>
>>> I wanted to recreate the examples using the dataset "state".
>>>
>>> Thanks
>>>
>>> Iqbal
>>>
>>>
>>> ?	[[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at stat.math.ethz.ch
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian
>> School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From lhq0837 at yahoo.com  Thu Nov 29 15:01:05 2007
From: lhq0837 at yahoo.com (Christina Li)
Date: Thu, 29 Nov 2007 06:01:05 -0800 (PST)
Subject: [R-sig-Geo] row-standardized spatial weighting matrix
Message-ID: <674244.25777.qm@web82612.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071129/066df05b/attachment.pl>

From paallen at attglobal.net  Thu Nov 29 15:39:40 2007
From: paallen at attglobal.net (paallen at attglobal.net)
Date: Thu, 29 Nov 2007 14:39:40 +0000
Subject: [R-sig-Geo] R/ArcGis and R-DCOM?
Message-ID: <1570406295-1196347275-cardhu_decombobulator_blackberry.rim.net-1638159378-@bxe031.bisx.prod.on.blackberry>

Hi all,

I am an ArcGis and R user.  I normally just share data between the two with the old import/export game using csv, pdf, and jpg file.  Lately I have just started to looked into the R-DCOM project and the r/arcgis repository (http://perso.univ-lr.fr/csainte/recherche/rarcgis/index.html).  I am hoping to use it to streamline the sharing of data between the two easier.  Specifically I am wanting to use r for some gridding and have it save the rasters into native arcgis rasters and automatically paste histograms/ecdf graphs onto layouts and plot princomp scores.

I have tried the raster example on the r/arcgis repository page without luck.  

Has anyone else tried this or something similar?

Regards,

Phillip Allen
Geochemist

Sent via BlackBerry by AT&T



From Roger.Bivand at nhh.no  Thu Nov 29 16:04:58 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 29 Nov 2007 16:04:58 +0100 (CET)
Subject: [R-sig-Geo] row-standardized spatial weighting matrix
In-Reply-To: <674244.25777.qm@web82612.mail.mud.yahoo.com>
References: <674244.25777.qm@web82612.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0711291539000.31808@reclus.nhh.no>

On Thu, 29 Nov 2007, Christina Li wrote:

> Dear list members,
>
> I have a couple of questions:
>
> 1. I kept getting this warning "spatial weights matrix not
>    row-standardized" when I ran LM tests, although I already row
>    standardized the weights matrix.
>
> Here are the specific steps: I row standardized a square contiguity 
> matrix in MatLab, exported it as an ASCII file. I then imported the 
> ASCII file into R as a matrix (as.matrix). I then convert the matrix to 
> a weights list object (mat2listw). Then I ran LM tests.
>
> Could it because that the row standardization was done in MatLab, not in 
> R? I couldn't find out how to do it in R, so had to do it in MatLab.

The code shows that what is happening is that an attribute of the weights 
component of the object set by nb2listw() is being checked. If the 
attribute is not found, the warning is issued. When weights are converted 
from a matrix, the attribute is not set, and the style component of the 
listw object as a whole is set to "M". The usual solution is to do 
something like:

x <- mat2listw(xmat)
xW <- nb2listw(x$neighbours, style="W")

to get to a listw object for which we know that row standardisation holds. 
If the original specification was for general weights, use the glist= 
argument to pass x$weights.

lm.LMtests() could check itself, and not issue the warning, but checking 
would be costly, and it is better to do this once by hand rather than many 
times automatically. I'm pretty sure in addition that the ASCII file route 
introduced rounding errors, so even if it did check, row sums might miss 
unity by machine fuzz (say 1e-12).

>
> Can anyone tell me how to do row standardization in R directly? Thank 
> you!!!
>
> 2. I got significantly different LM test results for LMlag, when i used
>    the original contiguity matrix and the row-standardized one. Is there
>    supposed to be a big difference?
>

If you check this out on the example on the help page for lm.LMtests(), 
you'll see the difference between nb2listw(COL.nb, style = "B") and 
nb2listw(COL.nb, style = "W"). If I remember correctly, the test is based 
on row-standardised weights. In general, row-standardisation increases the 
influence of observations with few neighbours, while other styles may 
increase the influence of those with many neighbours.

Roger

> Any help is much appreciated!
>
> Christina Li
>
>
> ---------------------------------
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From arosa at ist.utl.pt  Thu Nov 29 17:00:45 2007
From: arosa at ist.utl.pt (Rosa Trancoso)
Date: Thu, 29 Nov 2007 16:00:45 +0000
Subject: [R-sig-Geo] plot projected xyz
Message-ID: <474EE22D.3080809@ist.utl.pt>

Hello!

I'm having trouble making a map of terrain elevations.
I have a collection of (lon,lat, z) points. These points have regular 
spacing (20km) when projected, but not in geographical coordinates.

So I project the data and make a SpatialGRidDataFrame object with sp and 
rgdal packages.
How can I plot it with lon,lat axes? By costumizing the axes?
Is there a way to define the projection I am working on and do all the 
work with lon,lat coordinates?


Thanks in advance,
Ana Rosa



From Roger.Bivand at nhh.no  Thu Nov 29 18:43:35 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 29 Nov 2007 18:43:35 +0100 (CET)
Subject: [R-sig-Geo] R/ArcGis and R-DCOM?
In-Reply-To: <1570406295-1196347275-cardhu_decombobulator_blackberry.rim.net-1638159378-@bxe031.bisx.prod.on.blackberry>
References: <1570406295-1196347275-cardhu_decombobulator_blackberry.rim.net-1638159378-@bxe031.bisx.prod.on.blackberry>
Message-ID: <Pine.LNX.4.64.0711291815170.31808@reclus.nhh.no>

On Thu, 29 Nov 2007, paallen at attglobal.net wrote:

> Hi all,
>
> I am an ArcGis and R user.  I normally just share data between the two 
> with the old import/export game using csv, pdf, and jpg file.  Lately I 
> have just started to looked into the R-DCOM project and the r/arcgis 
> repository 
> (http://perso.univ-lr.fr/csainte/recherche/rarcgis/index.html).

This site was current for ArcGIS 8, but it seems that for ArcGIS 9, the 
Python interface using win32com.client to access the geoprocessor is 
easier to get running. One can call a short Python script from the R 
system() command, or call R from a Python script run from ArcGIS 
(typically using the R (D)COM StatConnector, or have a Python script use 
both.

Two useful links are:

http://code.env.duke.edu/projects/mget

and

http://courses.washington.edu/geog465/

where only MGET uses R, but the UW course provides a lot of useful 
guidance. Unfortunately, a University of Bergen course that we've just 
finished is only on an intranet - the general conclusions were that 
"things take time", and that the simplest scripts are the ones that work; 
beyond that, much of the documentation needs patience because many things 
do not work either at all, or as described - however, there are usually 
workarounds. Stopping using the ModelBuilder was crucial in most cases - 
it was far too difficult to debug - running code step-by-step from the 
Python command prompt was the main mode of learning. Styrk Finne (a 
participant) found that deleting the geoprocessor seemed to help on lab 
machines that were seldom shut down - the GP seems to be started at boot 
and accumulates zombie connections until it becomes unstable (in 9.1 and 
for our installation - laptop users who shutdown frequently could do more 
than users of the regular lab machines).

Most often the exchange is still by a subset of filetypes, but a good deal 
is possible. This, combined with the use of drivers for raster and vector 
data in the rgdal package, means that a lot can be streamlined.

> I am hoping to use it to streamline the sharing of data between the two 
> easier.  Specifically I am wanting to use r for some gridding and have 
> it save the rasters into native arcgis rasters and automatically paste 
> histograms/ecdf graphs onto layouts and plot princomp scores.
>

This imports an ASCII raster as written with writeAsciiGrid() in the 
maptools package - there are ways to use the AAIGrid driver in rgdal too - 
into Arc 9.1:

# import modules
import sys, os
from win32com.client import Dispatch

script = sys.argv[0]

# initialize ESRI ArcGIS geoprocessor
print "Initialising ArcGIS geoprocessor ..."
GP = Dispatch('esriGeoprocessing.GpDispatch.1')
GP.CheckOutExtension('Spatial')
GP.OverwriteOutput = 1    # setup for overwrite

out_ascii_grid = sys.argv[1]

out_ascii_type = sys.argv[2]

gridPath = sys.argv[3]

in_grid = sys.argv[4]

inRaster = gridPath + "/" + in_grid
try:
    GP.ASCIIToRaster_conversion(out_ascii_grid, inRaster, out_ascii_type)
except:
    msg = 'GP Error: %s' % GP.GetMessages()
    GP.AddError(msg); print msg; raise

del(GP)

(very rough, but apart from error handling, you can see how you might pass 
the arguments from system() in R).

To get R (D)COM Python support running, see the samples/scripts directory 
of the R(D)COM install - essentially a one-off build in Pythonwin of the 
COM hooks for the StatConnector server.

In rgdal, look at gdalDrivers() and ogrDrivers() to see what is available 
- the standard Windows binary package has plenty of drivers for reading 
things (but convert personal geodatabase files to say shapefiles or 
coverages using the GP to read), and many fewer for writing to Arc - 
again, use the GP to convert back.

Hope this helps,

Roger

PS. It would be very helpful if others with relevant experience could join 
this thread, which can then be linked from the Rgeo website.

> I have tried the raster example on the r/arcgis repository page without luck.
>
> Has anyone else tried this or something similar?
>
> Regards,
>
> Phillip Allen
> Geochemist
>
> Sent via BlackBerry by AT&T
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Thu Nov 29 20:01:49 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 29 Nov 2007 20:01:49 +0100 (CET)
Subject: [R-sig-Geo] plot projected xyz
In-Reply-To: <474EE22D.3080809@ist.utl.pt>
References: <474EE22D.3080809@ist.utl.pt>
Message-ID: <Pine.LNX.4.64.0711291938300.31808@reclus.nhh.no>

On Thu, 29 Nov 2007, Rosa Trancoso wrote:

> Hello!
>
> I'm having trouble making a map of terrain elevations.
> I have a collection of (lon,lat, z) points. These points have regular
> spacing (20km) when projected, but not in geographical coordinates.
>
> So I project the data and make a SpatialGRidDataFrame object with sp and
> rgdal packages.
> How can I plot it with lon,lat axes? By costumizing the axes?
> Is there a way to define the projection I am working on and do all the
> work with lon,lat coordinates?

See ?gridlines and ?gridat in the sp package to construct a grid and label 
it. If you construct the grid in geographical coordinates and project it 
using spTransform() methods in rgdal to the projection of the data, you 
can overplot your projected data with a longlat grid:

library(rgdal)
scot_BNG <- readOGR(system.file("vectors", package = "rgdal")[1],
   "scot_BNG")
scot_LL <- spTransform(scot_BNG, CRS("+proj=longlat +datum=WGS84"))
grd_LL <- gridlines(scot_LL, ndiscr=100)
summary(grd_LL)
grd_BNG <- spTransform(grd_LL, CRS(proj4string(scot_BNG)))
grdtxt_LL <- gridat(scot_LL)
grdtxt_BNG <- spTransform(grdtxt_LL, CRS(proj4string(scot_BNG)))
plot(scot_BNG)
plot(grd_BNG, add=TRUE, lty=2)
text(coordinates(grdtxt_BNG),
   labels=parse(text=as.character(grdtxt_BNG$labels)))

is an example.

Roger

>
>
> Thanks in advance,
> Ana Rosa
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From reeves at nceas.ucsb.edu  Thu Nov 29 22:36:42 2007
From: reeves at nceas.ucsb.edu (Rick Reeves)
Date: Thu, 29 Nov 2007 13:36:42 -0800
Subject: [R-sig-Geo] Method for: Creating contour maps of geocoded point
	shapefile attributes
Message-ID: <474F30EA.9050906@nceas.ucsb.edu>



Hello:

If one has a polygon shapefile of the USA and a point shapefile of USA 
cities (both in geographic coordinates),
and the point shapefile includes demographic attributes for each city, 
what would be the best way to create
a contour map of one of the attributes that overlays the polygon map?

I have been experimenting with using akima.interp (to generate a grid of 
interpolated values) and contour (to
generate the contours), with mixed results. I think that I can work out 
a technique to get this done, but would
like to know if this capability is embedded in any of the R spatial 
classes.

Thanks for any insight into this!

Rick Reeves
-------------- next part --------------
A non-text attachment was scrubbed...
Name: reeves.vcf
Type: text/x-vcard
Size: 339 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071129/4d010230/attachment.vcf>

From nikko at hailmail.net  Fri Nov 30 02:30:03 2007
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: Thu, 29 Nov 2007 20:30:03 -0500
Subject: [R-sig-Geo] neighborhood with
In-Reply-To: <56cce57d0711290442t299dd7faya8e5b3138b33a948@mail.gmail.com>
References: <56cce57d0711290319n2aace5fei9ccfacc893bafffa@mail.gmail.com>
	<56cce57d0711290442t299dd7faya8e5b3138b33a948@mail.gmail.com>
Message-ID: <1196386204.2316.1224007759@webmail.messagingengine.com>

Hi Alban,
I hope you don't mind that I have cc'd the list in my reply, there may
be more help from out there. I don't think these functions will quite
get you there.
These functions assume that you already have nb.obj created and are
wanting to preform 
set operations on the neighbors. Ideally you would want to look at 
knearneigh, and 
do something like
> k1<-knn2nb(knearneigh(x, k=1))
> k2<-knn2nb(knearneigh(x, k=2))

> 2nd.ord.neigh<-setdiff.nb(k2,k1)
However these functions are for points not polygons. If your polygons
are well behaved,
ie nicely convex than using the centroids of the polygons this would
give you a good
approximation. poly2nb will give you first order neighbors for polygons,
but you would have to do 
a lot of work to get the second order ones. Also I am thinking that
unless you have a
very well behaved set of polygons, defining second order neighbors could
be a topological nightmare.
There may be some better approaches using GRASS or postgis.

Hope this helps,
Nicholas

On Thu, 29 Nov 2007 13:42:05 +0100, "alban thomas"
<alban.thomas.fr at gmail.com> said:
> Good morning Mr Lewin-Koh,
> 
> I'm trying to use your functions on neighbors list objects (in spdep
> package). Do you have a more detailed description or references about
> setdiff.nb(nb.obj1,nb.obj2) and complement.nb (nb.obj) functions ?
> 
> My objective is to get first and 2nd order neighborhood of spatial
> polygons.
> I want to use topology and not a distance criterion.
> 
> I hope to be comprehensible, sorry for my rusty english.
> 
> Alban Thomas
> -- 
> ____________________________
>        Alban Thomas
> http://alban-thomas.exen.fr/



From Roger.Bivand at nhh.no  Fri Nov 30 08:20:48 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Nov 2007 08:20:48 +0100 (CET)
Subject: [R-sig-Geo] neighborhood with
In-Reply-To: <1196386204.2316.1224007759@webmail.messagingengine.com>
References: <56cce57d0711290319n2aace5fei9ccfacc893bafffa@mail.gmail.com>  
	<56cce57d0711290442t299dd7faya8e5b3138b33a948@mail.gmail.com>
	<1196386204.2316.1224007759@webmail.messagingengine.com>
Message-ID: <Pine.LNX.4.64.0711300815540.6766@reclus.nhh.no>

On Thu, 29 Nov 2007, Nicholas Lewin-Koh wrote:

> Hi Alban,

> I hope you don't mind that I have cc'd the list in my reply, there may 
> be more help from out there. I don't think these functions will quite 
> get you there. These functions assume that you already have nb.obj 
> created and are wanting to preform set operations on the neighbors. 
> Ideally you would want to look at knearneigh, and do something like

>> k1<-knn2nb(knearneigh(x, k=1))
>> k2<-knn2nb(knearneigh(x, k=2))
>
>> 2nd.ord.neigh<-setdiff.nb(k2,k1)

> However these functions are for points not polygons. If your polygons 
> are well behaved, ie nicely convex than using the centroids of the 
> polygons this would give you a good approximation. poly2nb will give you 
> first order neighbors for polygons, but you would have to do a lot of 
> work to get the second order ones. Also I am thinking that unless you 
> have a very well behaved set of polygons, defining second order 
> neighbors could be a topological nightmare. There may be some better 
> approaches using GRASS or postgis.

The nblag() function in spdep returns a list of order lags, from first to 
maxlag, so the first member of the list is the first order neighbour 
object and so on. This looks like what you need from your description.

Roger

>
> Hope this helps,
> Nicholas
>
> On Thu, 29 Nov 2007 13:42:05 +0100, "alban thomas"
> <alban.thomas.fr at gmail.com> said:
>> Good morning Mr Lewin-Koh,
>>
>> I'm trying to use your functions on neighbors list objects (in spdep
>> package). Do you have a more detailed description or references about
>> setdiff.nb(nb.obj1,nb.obj2) and complement.nb (nb.obj) functions ?
>>
>> My objective is to get first and 2nd order neighborhood of spatial
>> polygons.
>> I want to use topology and not a distance criterion.
>>
>> I hope to be comprehensible, sorry for my rusty english.
>>
>> Alban Thomas
>> --
>> ____________________________
>>        Alban Thomas
>> http://alban-thomas.exen.fr/
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Fri Nov 30 09:12:03 2007
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 30 Nov 2007 09:12:03 +0100 (CET)
Subject: [R-sig-Geo] Method for: Creating contour maps of geocoded point
 shapefile attributes
In-Reply-To: <474F30EA.9050906@nceas.ucsb.edu>
References: <474F30EA.9050906@nceas.ucsb.edu>
Message-ID: <Pine.LNX.4.64.0711300821410.6766@reclus.nhh.no>

On Thu, 29 Nov 2007, Rick Reeves wrote:

> Hello:
>
> If one has a polygon shapefile of the USA and a point shapefile of USA 
> cities (both in geographic coordinates), and the point shapefile 
> includes demographic attributes for each city, what would be the best 
> way to create a contour map of one of the attributes that overlays the 
> polygon map?
>
> I have been experimenting with using akima.interp (to generate a grid of 
> interpolated values) and contour (to generate the contours), with mixed 
> results. I think that I can work out a technique to get this done, but 
> would like to know if this capability is embedded in any of the R 
> spatial classes.

Not in the spatial classes, and the issue of Great Circle distances is 
there too. You could look at inverse distance weighting (in a small 
neighbourhood in gstat I think using GC distances (?idw, ?gstat and its 
predict method), or at kriging on GC distances in fields (?Krig, 
Distance="rdist.earth" - Tps does not seem to support GC distances).

This is just a sketch:

library(gstat)
library(fields)
data(ozone2)
o <- cbind(ozone2$lon.lat, ozone2$y[16,])
colnames(o) <- c("lon", "lat", "day16")
o <- as.data.frame(o)
o <- o[complete.cases(o),]
coordinates(o) <- c(1, 2)
proj4string(o) <- CRS("+proj=longlat")
grd <- GridTopology(c(-94,36), c(0.25,0.25), c(48,40))
SG <- SpatialGrid(grd, proj4string=CRS("+proj=longlat"))
p <- idw(day16 ~ 1, o, newdata=SG, nmax=16)
image(p[1], axes=TRUE)
points(o, pch=3)
pim <- as.image.SpatialGridDataFrame(p[1])
cl <- contourLines(pim)
library(maptools)
cL <- ContourLines2SLDF(cl)
proj4string(cL) <- CRS("+proj=longlat")
lines(cL)

Roger

>
> Thanks for any insight into this!
>
> Rick Reeves
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From alban.thomas.fr at gmail.com  Fri Nov 30 10:46:58 2007
From: alban.thomas.fr at gmail.com (alban thomas)
Date: Fri, 30 Nov 2007 10:46:58 +0100
Subject: [R-sig-Geo] neighborhood with
In-Reply-To: <Pine.LNX.4.64.0711300815540.6766@reclus.nhh.no>
References: <56cce57d0711290319n2aace5fei9ccfacc893bafffa@mail.gmail.com>
	<56cce57d0711290442t299dd7faya8e5b3138b33a948@mail.gmail.com>
	<1196386204.2316.1224007759@webmail.messagingengine.com>
	<Pine.LNX.4.64.0711300815540.6766@reclus.nhh.no>
Message-ID: <56cce57d0711300146p1aaf38afkccb171e554504495@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20071130/6e95e484/attachment.pl>

