From cicoz at anadolu.edu.tr  Sat Oct  1 15:02:25 2016
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Sat, 1 Oct 2016 13:02:25 +0000
Subject: [R-sig-Geo] Complete spatial randomness testing
Message-ID: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>

Hi friends,

I have a point pattern that consist of earthquake locations.  I want to test the pattern for complete spatial randomness based on distance functions.
I was using spatstat package allstats function to plot 4 of them together in a graph  however I took this error message:


"  Error in plot(allstats(dp1)) :
  error in evaluating the argument 'x' in selecting a method for function 'plot': Error: in Fest(X, r) the successive r values must be finely spaced: given spacing = 0.010196; required spacing <=  0.00586   "


Is it something related to plotting window properties? Although I got an error about F function , I could plot it individually.
In addition I could plot  all G, F, K  and L functions together in a graph manually.
Also I could not find a function to estimate J function in spatstat package. It is only included in allstat function.

Thanks in advance .


Res. Asst. Cenk ???z
Statistics Department ,Anadolu University, Turkey












	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Oct  1 23:29:22 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 2 Oct 2016 10:29:22 +1300
Subject: [R-sig-Geo] Complete spatial randomness testing
In-Reply-To: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
References: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
Message-ID: <74a86dbf-43e0-0ad0-e51c-1a65e69e6030@auckland.ac.nz>

On 02/10/16 02:02, Cenk ???Z via R-sig-Geo wrote:
> Hi friends,
>
> I have a point pattern that consist of earthquake locations.  I want
> to test the pattern for complete spatial randomness based on distance
> functions. I was using spatstat package allstats function to plot 4
> of them together in a graph  however I took this error message:
>
>
> "  Error in plot(allstats(dp1)) : error in evaluating the argument
> 'x' in selecting a method for function 'plot': Error: in Fest(X, r)
> the successive r values must be finely spaced: given spacing =
> 0.010196; required spacing <=  0.00586   "
>
>
> Is it something related to plotting window properties? Although I got
> an error about F function , I could plot it individually. In addition
> I could plot  all G, F, K  and L functions together in a graph
> manually. Also I could not find a function to estimate J function in
> spatstat package. It is only included in allstat function.
>
> Thanks in advance .

(a) What version of spatstat are you using?  It may be out of date.  The 
version of spatstat currently on CRAN is 1.46-1.

(b) When you say "based on distance functions" I presume that you mean 
"based on various distributions of interpoint distances".

(c) I presume that "dp1" is the point pattern (object of class "ppp") of 
earthquake locations.

(d) You have not provided a reproducible example of your problem. 
Consequently I checked things out with a simulated example:

set.seed(42)
X <- rpoispp(100)
plot(allstats(X))

This ran with no problem, and produced the expected plot.

(e) The function to estimate the J function is Jest().  It has been in 
the spatstat package for a very long time.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From albin.blaschka at standortsanalyse.net  Sun Oct  2 10:41:36 2016
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Sun, 2 Oct 2016 10:41:36 +0200
Subject: [R-sig-Geo] Global potential natural vegetation at 1km?
In-Reply-To: <6124ce51-9cd4-9864-11c9-aba73792aa6f@gmail.com>
References: <6124ce51-9cd4-9864-11c9-aba73792aa6f@gmail.com>
Message-ID: <d22c0299-7633-bb49-3fba-69eb33a4da2c@standortsanalyse.net>


Hello!

Most probably not exactly what you want, but maybe useful anyways...

"Ecological Land Units Map of the World" (Resolution is 250m)

https://blogs.esri.com/esri/esri-insider/2014/12/09/the-first-detailed-ecological-land-unitsmap-in-the-world/

Download:
http://rmgsc.cr.usgs.gov/outgoing/ecosystems/Global/

regards,
Albin


Am 2016-09-29 um 13:28 schrieb Tomislav Hengl:
> Dear R-sig-geo,
>
> I have been looking for an existing map of global PNV (potential natural
> vegetation) that we could maybe use global soil / biomass modelling. So
> far, I noticed only two data sources that could provide compatible data:
>
> 1. Levavasseur et al. 2012
> (http://iopscience.iop.org/article/10.1088/1748-9326/7/4/044019) uses
> http://www.bridge.bris.ac.uk/resources/Databases/BIOMES_data data set
> for model training,
>
> 2. Tian et al. 2015
> (http://www.nature.com/nature/journal/v531/n7593/full/nature16946.html)
>
> However, both maps seem to refer to very coarse resolutions 10-50 km and
> I would prefer to use 1 km resolution data (not to mention that the
> legends are a mixture of general vegetation groups / vegetation-climate
> groups). For USA, much more detailed natural vegetation map is available
> (https://databasin.org/datasets/1c7a301c8e6843f2b4fe63fdb3a9fe39), but I
> guess nothing comparable is available for the whole world? Are you maybe
> aware of any such global maps representing e.g. plant communities
> (https://www.wikiwand.com/en/Plant_community)?
>
> I might just try myself to derive global potential vegetation (plant
> communities) using e.g. GBIF data or the BIOME 6000 data and
> environmental covariates at 1 km. At least the training data seems to be
> available for modeling.
>
> If you are aware of any similar project / initiative / data set please
> let me know.
>


-- 
| Dr.rer.nat. Albin Blaschka
| Etrichstrasse 26, A-5020 Salzburg
|
| * www.researchgate.net/profile/Albin_Blaschka *
| - It's hard to live in the mountains, hard but not hopeless!


From cicoz at anadolu.edu.tr  Sun Oct  2 16:24:50 2016
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Sun, 2 Oct 2016 14:24:50 +0000
Subject: [R-sig-Geo]  Complete spatial randomness testing
Message-ID: <C2AF35551EE58A4487CC3151707449ADBCCC2EEF@mb05.porsuk.anadolu.edu.tr>



Hi Rolf,

Thanks for the reply.

A) I updated my R version and spatstat package. Currently  using  spatstat 1.46-1 spoiler alert and  3.3.1 version of R.

B) Yes the distributions of interpoint distancess. Sorry to mention it wrong. In some sources they call distance based tests on complete spatial randomness. 

C)  Again yes. dp1  is a class of ppp object of spatstat constructed like this.  
Latitude and longtitude and the specific window of the study area. 

dp1<-ppp(veri$Enlem, veri$Boylam, c(30,40), c(39,42))

D) I also tried constructing the plot with a simulated pattern. No problem in plotting the graph.

E) I performed the function Jest and plotted it . I took the same error message again unfortunately.

"""Error: in Fest(X, r) the successive r values must be finely spaced: given spacing = 0.010196; required spacing <=  0.00586""""

My question is that I have duplicated points of earthquake occurrences in the study area. Is it a problem related to  it?
 Or the spacing is too low to draw the plot that function can not manage to draw  it such a short distance. 

Thanks again all for the all help .

-----
Res. Asst Cenk Icoz
Anadolu University, Department of statistics, Turkey

________________________________________
Kimden: Rolf Turner [r.turner at auckland.ac.nz]
G?nderildi: 02 Ekim 2016 Pazar 00:29
Kime: Cenk ???Z
Bilgi: r-sig-geo at r-project.org; Adrian.Baddeley at curtin.edu.au; Ege Rubak
Konu: Re: [R-sig-Geo] Complete spatial randomness testing

On 02/10/16 02:02, Cenk ???Z via R-sig-Geo wrote:
> Hi friends,
>
> I have a point pattern that consist of earthquake locations.  I want 
> to test the pattern for complete spatial randomness based on distance 
> functions. I was using spatstat package allstats function to plot 4 of 
> them together in a graph  however I took this error message:
>
>
> "  Error in plot(allstats(dp1)) : error in evaluating the argument 'x' 
> in selecting a method for function 'plot': Error: in Fest(X, r) the 
> successive r values must be finely spaced: given spacing =
> 0.010196; required spacing <=  0.00586   "
>
>
> Is it something related to plotting window properties? Although I got 
> an error about F function , I could plot it individually. In addition 
> I could plot  all G, F, K  and L functions together in a graph 
> manually. Also I could not find a function to estimate J function in 
> spatstat package. It is only included in allstat function.
>
> Thanks in advance .

(a) What version of spatstat are you using?  It may be out of date.  The version of spatstat currently on CRAN is 1.46-1.

(b) When you say "based on distance functions" I presume that you mean "based on various distributions of interpoint distances".

(c) I presume that "dp1" is the point pattern (object of class "ppp") of earthquake locations.

(d) You have not provided a reproducible example of your problem.
Consequently I checked things out with a simulated example:

set.seed(42)
X <- rpoispp(100)
plot(allstats(X))

This ran with no problem, and produced the expected plot.

(e) The function to estimate the J function is Jest().  It has been in the spatstat package for a very long time.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From kmb56 at berkeley.edu  Sun Oct  2 23:25:15 2016
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Sun, 2 Oct 2016 14:25:15 -0700
Subject: [R-sig-Geo] raster[] slow on large rasters
Message-ID: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>

I am trying to sample points from a large RasterLayer (~100GB if read into
memory).

raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
to loop through rows, read in entire columns using rgdal::getRasterData,
and subset those columns in R.

Sampling 100000 pts from this raster is only a few per column, so this
isn't efficient.

Using my own random numbers with `[` also relies on raster:::.readCellsGDAL.

Does anyone have a suggestion for a better practice?

The raster is public so this code should be reproducible:

download:
ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip

cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
raster::sampleRandom(cdl, size = 100000) # slow

Cheers,
Kenny

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Sun Oct  2 23:47:24 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 02 Oct 2016 21:47:24 +0000
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
Message-ID: <CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>

Try creating it as a single layer brick, does it make a difference?

Cheers, Mike

On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:

> I am trying to sample points from a large RasterLayer (~100GB if read into
> memory).
>
> raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
> to loop through rows, read in entire columns using rgdal::getRasterData,
> and subset those columns in R.
>
> Sampling 100000 pts from this raster is only a few per column, so this
> isn't efficient.
>
> Using my own random numbers with `[` also relies on
> raster:::.readCellsGDAL.
>
> Does anyone have a suggestion for a better practice?
>
> The raster is public so this code should be reproducible:
>
> download:
> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>
> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
> raster::sampleRandom(cdl, size = 100000) # slow
>
> Cheers,
> Kenny
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From kmb56 at berkeley.edu  Mon Oct  3 00:32:34 2016
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Sun, 2 Oct 2016 15:32:34 -0700
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
Message-ID: <CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>

No substantial difference, no.

cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
system.time(raster::sampleRandom(cdl, size = 100))
#   user  system elapsed
#   4.16   21.32   25.50
system.time(cdl[random_pts$row_1D[1:100]])
#   user  system elapsed
#   1.33    5.36    6.69

cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
system.time(raster::sampleRandom(cdl, size = 100))
#   user  system elapsed
#   4.07   21.34   25.46
system.time(cdl[random_pts$row_1D[1:100]])
#   user  system elapsed
#   1.20    4.97    6.17



On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> Try creating it as a single layer brick, does it make a difference?
>
> Cheers, Mike
>
> On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:
>
>> I am trying to sample points from a large RasterLayer (~100GB if read into
>> memory).
>>
>> raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
>> to loop through rows, read in entire columns using rgdal::getRasterData,
>> and subset those columns in R.
>>
>> Sampling 100000 pts from this raster is only a few per column, so this
>> isn't efficient.
>>
>> Using my own random numbers with `[` also relies on
>> raster:::.readCellsGDAL.
>>
>> Does anyone have a suggestion for a better practice?
>>
>> The raster is public so this code should be reproducible:
>>
>> download:
>> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>>
>> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
>> raster::sampleRandom(cdl, size = 100000) # slow
>>
>> Cheers,
>> Kenny
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>


-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

	[[alternative HTML version deleted]]


From kmb56 at berkeley.edu  Mon Oct  3 00:40:31 2016
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Sun, 2 Oct 2016 15:40:31 -0700
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
	<CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
Message-ID: <CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>

Is an approach that could improve this is to arrange the locations to
collect into contiguous blocks inside raster:::.readCellsGDAL and read them
in block by block?

On Sun, Oct 2, 2016 at 3:32 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:

> No substantial difference, no.
>
> cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
> system.time(raster::sampleRandom(cdl, size = 100))
> #   user  system elapsed
> #   4.16   21.32   25.50
> system.time(cdl[random_pts$row_1D[1:100]])
> #   user  system elapsed
> #   1.33    5.36    6.69
>
> cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
> system.time(raster::sampleRandom(cdl, size = 100))
> #   user  system elapsed
> #   4.07   21.34   25.46
> system.time(cdl[random_pts$row_1D[1:100]])
> #   user  system elapsed
> #   1.20    4.97    6.17
>
>
>
> On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Try creating it as a single layer brick, does it make a difference?
>>
>> Cheers, Mike
>>
>> On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:
>>
>>> I am trying to sample points from a large RasterLayer (~100GB if read
>>> into
>>> memory).
>>>
>>> raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
>>> to loop through rows, read in entire columns using rgdal::getRasterData,
>>> and subset those columns in R.
>>>
>>> Sampling 100000 pts from this raster is only a few per column, so this
>>> isn't efficient.
>>>
>>> Using my own random numbers with `[` also relies on
>>> raster:::.readCellsGDAL.
>>>
>>> Does anyone have a suggestion for a better practice?
>>>
>>> The raster is public so this code should be reproducible:
>>>
>>> download:
>>> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>>>
>>> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
>>> raster::sampleRandom(cdl, size = 100000) # slow
>>>
>>> Cheers,
>>> Kenny
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>



-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon Oct  3 00:54:24 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 02 Oct 2016 22:54:24 +0000
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
	<CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
	<CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>
Message-ID: <CAAcGz98WQ=bOdHJwBufJ9Wj=iqZTP_4h3fvP-8dG2ftkLgnF6Q@mail.gmail.com>

Is the file tiled? Raster's extract is slow then because it scans line by
line rather than by tile. The only fix I know  is to readAll into memory or
write to a new untiled file. At any rate you might as well sample the cell
numbers more directly and use index cell extract instead of sampleRandom

On Mon, 3 Oct 2016, 09:40 Kenny Bell <kmb56 at berkeley.edu> wrote:

> Is an approach that could improve this is to arrange the locations to
> collect into contiguous blocks inside raster:::.readCellsGDAL and read them
> in block by block?
>
> On Sun, Oct 2, 2016 at 3:32 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:
>
> No substantial difference, no.
>
> cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
> system.time(raster::sampleRandom(cdl, size = 100))
> #   user  system elapsed
> #   4.16   21.32   25.50
> system.time(cdl[random_pts$row_1D[1:100]])
> #   user  system elapsed
> #   1.33    5.36    6.69
>
> cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
> system.time(raster::sampleRandom(cdl, size = 100))
> #   user  system elapsed
> #   4.07   21.34   25.46
> system.time(cdl[random_pts$row_1D[1:100]])
> #   user  system elapsed
> #   1.20    4.97    6.17
>
>
>
> On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
> Try creating it as a single layer brick, does it make a difference?
>
> Cheers, Mike
>
> On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:
>
> I am trying to sample points from a large RasterLayer (~100GB if read into
> memory).
>
> raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
> to loop through rows, read in entire columns using rgdal::getRasterData,
> and subset those columns in R.
>
> Sampling 100000 pts from this raster is only a few per column, so this
> isn't efficient.
>
> Using my own random numbers with `[` also relies on
> raster:::.readCellsGDAL.
>
> Does anyone have a suggestion for a better practice?
>
> The raster is public so this code should be reproducible:
>
> download:
> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>
> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
> raster::sampleRandom(cdl, size = 100000) # slow
>
> Cheers,
> Kenny
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>
>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From kmb56 at berkeley.edu  Mon Oct  3 01:05:05 2016
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Sun, 2 Oct 2016 16:05:05 -0700
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CAAcGz98WQ=bOdHJwBufJ9Wj=iqZTP_4h3fvP-8dG2ftkLgnF6Q@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
	<CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
	<CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>
	<CAAcGz98WQ=bOdHJwBufJ9Wj=iqZTP_4h3fvP-8dG2ftkLgnF6Q@mail.gmail.com>
Message-ID: <CALOjXYT_N=a1Hp3L-Kf2yuZvJkUByKLG+ENE0-dSfrzNm9c9Vg@mail.gmail.com>

I am unsure if the file is tiled - how do I find this out? I am finding
that sampling the cells directly and using `[` is also slow, though not as
slow as sampleRandom. Is that what you meant by "index cell extract"?

Using readAll isn't going to work as it reads in very slowly and is large
(~100GB).

On Sun, Oct 2, 2016 at 3:54 PM, Michael Sumner <mdsumner at gmail.com> wrote:

> Is the file tiled? Raster's extract is slow then because it scans line by
> line rather than by tile. The only fix I know  is to readAll into memory or
> write to a new untiled file. At any rate you might as well sample the cell
> numbers more directly and use index cell extract instead of sampleRandom
>
> On Mon, 3 Oct 2016, 09:40 Kenny Bell <kmb56 at berkeley.edu> wrote:
>
>> Is an approach that could improve this is to arrange the locations to
>> collect into contiguous blocks inside raster:::.readCellsGDAL and read them
>> in block by block?
>>
>> On Sun, Oct 2, 2016 at 3:32 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:
>>
>>> No substantial difference, no.
>>>
>>> cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
>>> system.time(raster::sampleRandom(cdl, size = 100))
>>> #   user  system elapsed
>>> #   4.16   21.32   25.50
>>> system.time(cdl[random_pts$row_1D[1:100]])
>>> #   user  system elapsed
>>> #   1.33    5.36    6.69
>>>
>>> cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
>>> system.time(raster::sampleRandom(cdl, size = 100))
>>> #   user  system elapsed
>>> #   4.07   21.34   25.46
>>> system.time(cdl[random_pts$row_1D[1:100]])
>>> #   user  system elapsed
>>> #   1.20    4.97    6.17
>>>
>>>
>>>
>>> On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com>
>>> wrote:
>>>
>>>> Try creating it as a single layer brick, does it make a difference?
>>>>
>>>> Cheers, Mike
>>>>
>>>> On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:
>>>>
>>>>> I am trying to sample points from a large RasterLayer (~100GB if read
>>>>> into
>>>>> memory).
>>>>>
>>>>> raster::sampleRandom relies on raster raster:::.readCellsGDAL which
>>>>> seems
>>>>> to loop through rows, read in entire columns using
>>>>> rgdal::getRasterData,
>>>>> and subset those columns in R.
>>>>>
>>>>> Sampling 100000 pts from this raster is only a few per column, so this
>>>>> isn't efficient.
>>>>>
>>>>> Using my own random numbers with `[` also relies on
>>>>> raster:::.readCellsGDAL.
>>>>>
>>>>> Does anyone have a suggestion for a better practice?
>>>>>
>>>>> The raster is public so this code should be reproducible:
>>>>>
>>>>> download:
>>>>> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>>>>>
>>>>> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
>>>>> raster::sampleRandom(cdl, size = 100000) # slow
>>>>>
>>>>> Cheers,
>>>>> Kenny
>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>> --
>>>> Dr. Michael Sumner
>>>> Software and Database Engineer
>>>> Australian Antarctic Division
>>>> 203 Channel Highway
>>>> Kingston Tasmania 7050 Australia
>>>>
>>>>
>>>
>>>
>>> --
>>> Kendon Bell
>>> Email: kmb56 at berkeley.edu
>>> Phone: (510) 612-3375
>>>
>>> Ph.D. Candidate
>>> Department of Agricultural & Resource Economics
>>> University of California, Berkeley
>>>
>>
>>
>>
>> --
>> Kendon Bell
>> Email: kmb56 at berkeley.edu
>> Phone: (510) 612-3375
>>
>> Ph.D. Candidate
>> Department of Agricultural & Resource Economics
>> University of California, Berkeley
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>


-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon Oct  3 01:57:19 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 02 Oct 2016 23:57:19 +0000
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CALOjXYT_N=a1Hp3L-Kf2yuZvJkUByKLG+ENE0-dSfrzNm9c9Vg@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
	<CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
	<CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>
	<CAAcGz98WQ=bOdHJwBufJ9Wj=iqZTP_4h3fvP-8dG2ftkLgnF6Q@mail.gmail.com>
	<CALOjXYT_N=a1Hp3L-Kf2yuZvJkUByKLG+ENE0-dSfrzNm9c9Vg@mail.gmail.com>
Message-ID: <CAAcGz9-mZjsQ34NvdzGOs9oX_Ljbf0=QeUSjb=4_Br0itn29Eg@mail.gmail.com>

rgdal::GDALinfo(filename) will show the block size. Here's an example of
the timings difference I'm talking about.

library(raster)
r <- disaggregate(raster(volcano), fact = 20)

writeRaster(r, "supersamp.tif", options = c("TILED=YES"))
rtif <- raster("supersamp.tif")
rmem <- readAll(rtif)
bmem <- brick(rmem)
cell <- sort(sample(ncell(rtif), 100))
library(rbenchmark)

benchmark(tif = extract(rtif, cell),
           rmem = extract(rmem, cell),
           bmem = extract(bmem, cell))
 test replications elapsed relative user.self sys.self user.child sys.child
3 bmem          100    0.01        1      0.01     0.00         NA        NA
2 rmem          100    0.15       15      0.12     0.02         NA        NA
1  tif          100   12.76     1276     12.35     0.39         NA        NA


You could group your cell numbers into tiles and use raster::crop to get
each block in turn, though presumably the block handling functions in
raster are better suited to that. I haven't used those, I tend to deal with
really long time series data sets and reasonable spatial sizes,  rather
than really massive spatial grids like this.

I don't know if you can get individual values by cell number via rgdal,
without extracting an entire SpatialPixels object - in which case I reckon
brick/crop is a better way.

Otherwise you might use GDAL itself to do the extractions, but I haven't
done that myself.

I'll try the block tools in raster later if I get a chance, that's my first
guess at what will be best here.  If you are familiar with the cell
abstractions in raster you can do a lot of work before hitting the raster
source at all, this can be really handy for organizing things the right
way.

Cheers, Mike.



On Mon, 3 Oct 2016 at 10:05 Kenny Bell <kmb56 at berkeley.edu> wrote:

> I am unsure if the file is tiled - how do I find this out? I am finding
> that sampling the cells directly and using `[` is also slow, though not as
> slow as sampleRandom. Is that what you meant by "index cell extract"?
>
> Using readAll isn't going to work as it reads in very slowly and is large
> (~100GB).
>
> On Sun, Oct 2, 2016 at 3:54 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
> Is the file tiled? Raster's extract is slow then because it scans line by
> line rather than by tile. The only fix I know  is to readAll into memory or
> write to a new untiled file. At any rate you might as well sample the cell
> numbers more directly and use index cell extract instead of sampleRandom
>
> On Mon, 3 Oct 2016, 09:40 Kenny Bell <kmb56 at berkeley.edu> wrote:
>
> Is an approach that could improve this is to arrange the locations to
> collect into contiguous blocks inside raster:::.readCellsGDAL and read them
> in block by block?
>
> On Sun, Oct 2, 2016 at 3:32 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:
>
> No substantial difference, no.
>
> cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
> system.time(raster::sampleRandom(cdl, size = 100))
> #   user  system elapsed
> #   4.16   21.32   25.50
> system.time(cdl[random_pts$row_1D[1:100]])
> #   user  system elapsed
> #   1.33    5.36    6.69
>
> cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
> system.time(raster::sampleRandom(cdl, size = 100))
> #   user  system elapsed
> #   4.07   21.34   25.46
> system.time(cdl[random_pts$row_1D[1:100]])
> #   user  system elapsed
> #   1.20    4.97    6.17
>
>
>
> On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
> Try creating it as a single layer brick, does it make a difference?
>
> Cheers, Mike
>
> On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:
>
> I am trying to sample points from a large RasterLayer (~100GB if read into
> memory).
>
> raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
> to loop through rows, read in entire columns using rgdal::getRasterData,
> and subset those columns in R.
>
> Sampling 100000 pts from this raster is only a few per column, so this
> isn't efficient.
>
> Using my own random numbers with `[` also relies on
> raster:::.readCellsGDAL.
>
> Does anyone have a suggestion for a better practice?
>
> The raster is public so this code should be reproducible:
>
> download:
> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>
> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
> raster::sampleRandom(cdl, size = 100000) # slow
>
> Cheers,
> Kenny
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>
>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From kmb56 at berkeley.edu  Mon Oct  3 02:04:31 2016
From: kmb56 at berkeley.edu (Kenny Bell)
Date: Sun, 2 Oct 2016 17:04:31 -0700
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CALOjXYT_N=a1Hp3L-Kf2yuZvJkUByKLG+ENE0-dSfrzNm9c9Vg@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
	<CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
	<CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>
	<CAAcGz98WQ=bOdHJwBufJ9Wj=iqZTP_4h3fvP-8dG2ftkLgnF6Q@mail.gmail.com>
	<CALOjXYT_N=a1Hp3L-Kf2yuZvJkUByKLG+ENE0-dSfrzNm9c9Vg@mail.gmail.com>
Message-ID: <CALOjXYQ-p6UzSLancwR5ZM0VFe6mHokMLaUnQ5m=ZafdrgA5wA@mail.gmail.com>

I have implemented an improvement that works for my context. Is this the
right place to suggest code improvements? This implements the approach
where there is one call to rgdal::getRasterData per contiguous block. Is
this the right place to make code change suggestions?

system.time(sampleRandom(cdl, 100))
> system.time(sampleRandom(cdl, 100))
   user  system elapsed
   0.20    0.08    0.61

It changes raster:::.readCellsGDAL to:

.readCellsGDAL <- function(x, cells, layers) {

nl <- nlayers(x)
if (nl == 1) {
if (inherits(x, 'RasterLayer')) {
layers <- bandnr(x)
} else {
layers <- 1
}
}
laysel <- length(layers)
colrow <- matrix(ncol=2+laysel, nrow=length(cells))
colrow[,1] <- colFromCell(x, cells)
colrow[,2] <- rowFromCell(x, cells)
colrow[,3] <- NA
colrow <- colrow[order(colrow[,2], colrow[,1]),]
# This is one if contiguous, something else if not (except for the end of a
row)
diffrowcol <- diff(colrow[,2]) + diff(colrow[,1])
# Block numbers
blocknums <- cumsum(c(TRUE, diffrowcol != 1))
nc <- x at ncols
con <- rgdal::GDAL.open(x at file@name, silent=TRUE)
if (laysel == 1) {
for (blocknum in unique(blocknums)) {
 block_lgl <- blocknum == blocknums
 offs <- c(colrow[block_lgl,2][1] - 1, colrow[block_lgl, 1][1] - 1)
v <- rgdal::getRasterData(con, offset=offs, region.dim=c(1,
sum(block_lgl)), band = layers)
colrow[block_lgl, 3] <- v
}
} else {
for (i in 1:length(rows)) {
thisrow <- colrow[colrow[,2] == rows[i], , drop=FALSE]
if (nrow(thisrow) == 1) {
offs <- c(rows[i]-1, thisrow[,1]-1)
v <- as.vector( rgdal::getRasterData(con, offset=offs, region.dim=c(1, 1)) )
colrow[colrow[,2]==rows[i], 2+(1:laysel)] <- v[layers]

} else {
offs <- c(rows[i]-1, 0)
v <- rgdal::getRasterData(con, offset=offs, region.dim=c(1, nc))
v <- do.call(cbind, lapply(1:nl, function(i) v[,,i]))
colrow[colrow[,2]==rows[i], 2+(1:laysel)] <- v[thisrow[,1], layers]
}
}
}
rgdal::closeDataset(con)
colnames(colrow)[2+(1:laysel)] <- names(x)[layers]
colrow[, 2+(1:laysel)]
}


On Sun, Oct 2, 2016 at 4:05 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:

> I am unsure if the file is tiled - how do I find this out? I am finding
> that sampling the cells directly and using `[` is also slow, though not as
> slow as sampleRandom. Is that what you meant by "index cell extract"?
>
> Using readAll isn't going to work as it reads in very slowly and is large
> (~100GB).
>
> On Sun, Oct 2, 2016 at 3:54 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>
>> Is the file tiled? Raster's extract is slow then because it scans line by
>> line rather than by tile. The only fix I know  is to readAll into memory or
>> write to a new untiled file. At any rate you might as well sample the cell
>> numbers more directly and use index cell extract instead of sampleRandom
>>
>> On Mon, 3 Oct 2016, 09:40 Kenny Bell <kmb56 at berkeley.edu> wrote:
>>
>>> Is an approach that could improve this is to arrange the locations to
>>> collect into contiguous blocks inside raster:::.readCellsGDAL and read them
>>> in block by block?
>>>
>>> On Sun, Oct 2, 2016 at 3:32 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:
>>>
>>>> No substantial difference, no.
>>>>
>>>> cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
>>>> system.time(raster::sampleRandom(cdl, size = 100))
>>>> #   user  system elapsed
>>>> #   4.16   21.32   25.50
>>>> system.time(cdl[random_pts$row_1D[1:100]])
>>>> #   user  system elapsed
>>>> #   1.33    5.36    6.69
>>>>
>>>> cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
>>>> system.time(raster::sampleRandom(cdl, size = 100))
>>>> #   user  system elapsed
>>>> #   4.07   21.34   25.46
>>>> system.time(cdl[random_pts$row_1D[1:100]])
>>>> #   user  system elapsed
>>>> #   1.20    4.97    6.17
>>>>
>>>>
>>>>
>>>> On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com>
>>>> wrote:
>>>>
>>>>> Try creating it as a single layer brick, does it make a difference?
>>>>>
>>>>> Cheers, Mike
>>>>>
>>>>> On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:
>>>>>
>>>>>> I am trying to sample points from a large RasterLayer (~100GB if read
>>>>>> into
>>>>>> memory).
>>>>>>
>>>>>> raster::sampleRandom relies on raster raster:::.readCellsGDAL which
>>>>>> seems
>>>>>> to loop through rows, read in entire columns using
>>>>>> rgdal::getRasterData,
>>>>>> and subset those columns in R.
>>>>>>
>>>>>> Sampling 100000 pts from this raster is only a few per column, so this
>>>>>> isn't efficient.
>>>>>>
>>>>>> Using my own random numbers with `[` also relies on
>>>>>> raster:::.readCellsGDAL.
>>>>>>
>>>>>> Does anyone have a suggestion for a better practice?
>>>>>>
>>>>>> The raster is public so this code should be reproducible:
>>>>>>
>>>>>> download:
>>>>>> ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip
>>>>>>
>>>>>> cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
>>>>>> raster::sampleRandom(cdl, size = 100000) # slow
>>>>>>
>>>>>> Cheers,
>>>>>> Kenny
>>>>>>
>>>>>>         [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>> --
>>>>> Dr. Michael Sumner
>>>>> Software and Database Engineer
>>>>> Australian Antarctic Division
>>>>> 203 Channel Highway
>>>>> Kingston Tasmania 7050 Australia
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> Kendon Bell
>>>> Email: kmb56 at berkeley.edu
>>>> Phone: (510) 612-3375
>>>>
>>>> Ph.D. Candidate
>>>> Department of Agricultural & Resource Economics
>>>> University of California, Berkeley
>>>>
>>>
>>>
>>>
>>> --
>>> Kendon Bell
>>> Email: kmb56 at berkeley.edu
>>> Phone: (510) 612-3375
>>>
>>> Ph.D. Candidate
>>> Department of Agricultural & Resource Economics
>>> University of California, Berkeley
>>>
>> --
>> Dr. Michael Sumner
>> Software and Database Engineer
>> Australian Antarctic Division
>> 203 Channel Highway
>> Kingston Tasmania 7050 Australia
>>
>>
>
>
> --
> Kendon Bell
> Email: kmb56 at berkeley.edu
> Phone: (510) 612-3375
>
> Ph.D. Candidate
> Department of Agricultural & Resource Economics
> University of California, Berkeley
>



-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon Oct  3 04:04:30 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 03 Oct 2016 02:04:30 +0000
Subject: [R-sig-Geo] raster[] slow on large rasters
In-Reply-To: <CALOjXYQ-p6UzSLancwR5ZM0VFe6mHokMLaUnQ5m=ZafdrgA5wA@mail.gmail.com>
References: <CALOjXYQGQcjEhA8YbSJJ=eQkVnoJbTywrW0mB6A1OGwDCfjFWw@mail.gmail.com>
	<CAAcGz99p5dqHC4_OYns6D1OX1uQJKaubJsn4S89ycMNmqLkBoQ@mail.gmail.com>
	<CALOjXYQ8_JCgQNTtRfABc6z_iKJbt-vMbRMmc6kO=g=q-sMh4Q@mail.gmail.com>
	<CALOjXYS4AtW4_0A-uAHWspVxx9Tdbkk7LwAppG31gay8_1jWtg@mail.gmail.com>
	<CAAcGz98WQ=bOdHJwBufJ9Wj=iqZTP_4h3fvP-8dG2ftkLgnF6Q@mail.gmail.com>
	<CALOjXYT_N=a1Hp3L-Kf2yuZvJkUByKLG+ENE0-dSfrzNm9c9Vg@mail.gmail.com>
	<CALOjXYQ-p6UzSLancwR5ZM0VFe6mHokMLaUnQ5m=ZafdrgA5wA@mail.gmail.com>
Message-ID: <CAAcGz9_2w3QjjXk7WKs1XGjVSSE3nsY_R1dvE7tH0Wjmyc-LGQ@mail.gmail.com>

Hey great, this been on my never-get-to-todo list for ages.

I can commit it to raster but I'd want to do a few tests first. Can you
provide some?

I'll include some tests when I commit it, but there's no actual test suite
as far as I know.

Just FYI, the source is on r-forge via Subversion and the author is Robert
Hijmans, but a couple of us also have write access:

https://r-forge.r-project.org/projects/raster/

Cheers, Mike.

On Mon, 3 Oct 2016 at 11:04 Kenny Bell <kmb56 at berkeley.edu> wrote:

I have implemented an improvement that works for my context. Is this the
right place to suggest code improvements? This implements the approach
where there is one call to rgdal::getRasterData per contiguous block. Is
this the right place to make code change suggestions?

system.time(sampleRandom(cdl, 100))
> system.time(sampleRandom(cdl, 100))
   user  system elapsed
   0.20    0.08    0.61

It changes raster:::.readCellsGDAL to:

.readCellsGDAL <- function(x, cells, layers) {

nl <- nlayers(x)
if (nl == 1) {
if (inherits(x, 'RasterLayer')) {
layers <- bandnr(x)
} else {
layers <- 1
}
}
laysel <- length(layers)
colrow <- matrix(ncol=2+laysel, nrow=length(cells))
colrow[,1] <- colFromCell(x, cells)
colrow[,2] <- rowFromCell(x, cells)
colrow[,3] <- NA
colrow <- colrow[order(colrow[,2], colrow[,1]),]
# This is one if contiguous, something else if not (except for the end of a
row)
diffrowcol <- diff(colrow[,2]) + diff(colrow[,1])
# Block numbers
blocknums <- cumsum(c(TRUE, diffrowcol != 1))
nc <- x at ncols
con <- rgdal::GDAL.open(x at file@name, silent=TRUE)
if (laysel == 1) {
for (blocknum in unique(blocknums)) {
 block_lgl <- blocknum == blocknums
 offs <- c(colrow[block_lgl,2][1] - 1, colrow[block_lgl, 1][1] - 1)
v <- rgdal::getRasterData(con, offset=offs, region.dim=c(1,
sum(block_lgl)), band = layers)
colrow[block_lgl, 3] <- v
}
} else {
for (i in 1:length(rows)) {
thisrow <- colrow[colrow[,2] == rows[i], , drop=FALSE]
if (nrow(thisrow) == 1) {
offs <- c(rows[i]-1, thisrow[,1]-1)
v <- as.vector( rgdal::getRasterData(con, offset=offs, region.dim=c(1, 1)) )
colrow[colrow[,2]==rows[i], 2+(1:laysel)] <- v[layers]

} else {
offs <- c(rows[i]-1, 0)
v <- rgdal::getRasterData(con, offset=offs, region.dim=c(1, nc))
v <- do.call(cbind, lapply(1:nl, function(i) v[,,i]))
colrow[colrow[,2]==rows[i], 2+(1:laysel)] <- v[thisrow[,1], layers]
}
}
}
rgdal::closeDataset(con)
colnames(colrow)[2+(1:laysel)] <- names(x)[layers]
colrow[, 2+(1:laysel)]
}


On Sun, Oct 2, 2016 at 4:05 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:

I am unsure if the file is tiled - how do I find this out? I am finding
that sampling the cells directly and using `[` is also slow, though not as
slow as sampleRandom. Is that what you meant by "index cell extract"?

Using readAll isn't going to work as it reads in very slowly and is large
(~100GB).

On Sun, Oct 2, 2016 at 3:54 PM, Michael Sumner <mdsumner at gmail.com> wrote:

Is the file tiled? Raster's extract is slow then because it scans line by
line rather than by tile. The only fix I know  is to readAll into memory or
write to a new untiled file. At any rate you might as well sample the cell
numbers more directly and use index cell extract instead of sampleRandom

On Mon, 3 Oct 2016, 09:40 Kenny Bell <kmb56 at berkeley.edu> wrote:

Is an approach that could improve this is to arrange the locations to
collect into contiguous blocks inside raster:::.readCellsGDAL and read them
in block by block?

On Sun, Oct 2, 2016 at 3:32 PM, Kenny Bell <kmb56 at berkeley.edu> wrote:

No substantial difference, no.

cdl <- brick("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
system.time(raster::sampleRandom(cdl, size = 100))
#   user  system elapsed
#   4.16   21.32   25.50
system.time(cdl[random_pts$row_1D[1:100]])
#   user  system elapsed
#   1.33    5.36    6.69

cdl <- raster("Data/CDL/2015_30m_cdls/2015_30m_cdls.img")
system.time(raster::sampleRandom(cdl, size = 100))
#   user  system elapsed
#   4.07   21.34   25.46
system.time(cdl[random_pts$row_1D[1:100]])
#   user  system elapsed
#   1.20    4.97    6.17



On Sun, Oct 2, 2016 at 2:47 PM, Michael Sumner <mdsumner at gmail.com> wrote:

Try creating it as a single layer brick, does it make a difference?

Cheers, Mike

On Mon, 3 Oct 2016, 08:26 Kenny Bell <kmb56 at berkeley.edu> wrote:

I am trying to sample points from a large RasterLayer (~100GB if read into
memory).

raster::sampleRandom relies on raster raster:::.readCellsGDAL which seems
to loop through rows, read in entire columns using rgdal::getRasterData,
and subset those columns in R.

Sampling 100000 pts from this raster is only a few per column, so this
isn't efficient.

Using my own random numbers with `[` also relies on raster:::.readCellsGDAL.

Does anyone have a suggestion for a better practice?

The raster is public so this code should be reproducible:

download:
ftp://ftp.nass.usda.gov/download/res/2015_30m_cdls.zip

cdl <- raster("2015_30m_cdls/2015_30m_cdls.img")
raster::sampleRandom(cdl, size = 100000) # slow

Cheers,
Kenny

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia




-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley




-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia




-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley




-- 
Kendon Bell
Email: kmb56 at berkeley.edu
Phone: (510) 612-3375

Ph.D. Candidate
Department of Agricultural & Resource Economics
University of California, Berkeley

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From cicoz at anadolu.edu.tr  Mon Oct  3 09:35:26 2016
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Mon, 3 Oct 2016 07:35:26 +0000
Subject: [R-sig-Geo] YNT:  Complete spatial randomness testing
In-Reply-To: <1bbf91f1-b9d6-d532-7beb-c22ecffe6945@auckland.ac.nz>
References: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
	<74a86dbf-43e0-0ad0-e51c-1a65e69e6030@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC1DFF@mb05.porsuk.anadolu.edu.tr>
	<1bbf91f1-b9d6-d532-7beb-c22ecffe6945@auckland.ac.nz>
Message-ID: <C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>

According to your suggestion , I excluded duplicated points. However I took the same error message.

udp1<-unique.ppp(dp1)
 xxx<-allstats(udp1)
Error: in Fest(X, r) the successive r values must be finely spaced: given spacing = 0.010196; required spacing <=  0.00586

I attached the data for you to investigate. Thanks a lot. 

Cenk 

-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: Sunday, October 2, 2016 10:17 PM
To: Cenk ???Z <cicoz at anadolu.edu.tr>
Cc: Adrian.Baddeley at curtin.edu.au; Ege Rubak <rubak at math.aau.dk>
Subject: Re: YNT: [R-sig-Geo] Complete spatial randomness testing

On 02/10/16 23:42, Cenk ???Z wrote:
> Hi Rolf,
>
> Thanks for the reply.
>
> A) I updated my R version and spatstat package. Currently  using  spatstat 1.46-1 spoiler alert and  3.3.1 version of R.
>
> B) Yes the distributions of interpoint distancess. Sorry to mention it wrong. In some sources they call distance based tests on complete spatial randomness.
>
> C)  Again yes. dp1  is a class of ppp object of spatstat constructed like this.
> Latitude and longtitude and the specific window of the study area.
>
> dp1<-ppp(veri$Enlem, veri$Boylam, c(30,40), c(39,42))
>
> D) I also tried constructing the plot with a simulated pattern. No problem in plotting the graph.
>
> E) I performed the function Jest and plotted it . I took the same error message again unfortunately.
>
> """Error: in Fest(X, r) the successive r values must be finely spaced: given spacing = 0.010196; required spacing <=  0.00586""""
>
> My question is that I have duplicated points of earthquake occurrences in the study area. Is it a problem related to  it?
>  Or the spacing is too low to draw the plot that function can not manage to draw  it such a short distance.
>
> Thanks again all for the all help .
>

The duplicated points could indeed be the problem.  Try

udp1 <- unique(dp1)
xxx  <- allstats(udp1)
plot(xxx)

If that doesn't work, can you make the data set "veri" available to us so that we can investigate?

cheers,

Rolf

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276
-------------- next part --------------
A non-text attachment was scrubbed...
Name: veri.RData
Type: application/octet-stream
Size: 8661 bytes
Desc: veri.RData
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20161003/7588d9e5/attachment.obj>

From mathieu.rajerison at gmail.com  Mon Oct  3 11:38:24 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 3 Oct 2016 11:38:24 +0200
Subject: [R-sig-Geo] DEM plot3D and overlay an aerial image
Message-ID: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>

Hi R-List,


I have a DEM on one hand, and on the other hand, I have an RGB aerial image

I tried rasterVis and plot3D function, but I didn't find how to use the
colors of my RGB aerial image.

For the moment, I used rgl instead although it doesn't seem very
appropriate for georeferenced data..

Here's the RGL code :

gruissan =
stack("../MAISON/DATA/geo/raster/bdortho_marseille/marseille.tif")

r = values(gruissan[[1]])/255
g = values(gruissan[[2]])/255
b = values(gruissan[[3]])/255
col = rgb(r, g, b)

library(rgl)
persp3d(1:nrow(mnt), 1:ncol(mnt), values(mnt), col=col)

Best,

Mathieu


?

	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Mon Oct  3 12:18:01 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 3 Oct 2016 12:18:01 +0200
Subject: [R-sig-Geo] spplot : different legends per plot & mode of
 classification by default ?
Message-ID: <CAGfc75=qmZ2xvBdf2+8bwr2dFUq1FQrjCJ64i8YJyc8_aFKqog@mail.gmail.com>

Hi,


I have several variables of numeric data that I whish to spplot.

How to push one classification per plot ?

Also, what is the mode of classification used by default by spplot ? Is the
data split into quantiles ?


Thanks in advance for your answer

Mathieu
?

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Mon Oct  3 13:14:28 2016
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 3 Oct 2016 12:14:28 +0100
Subject: [R-sig-Geo] DEM plot3D and overlay an aerial image
In-Reply-To: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
References: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
Message-ID: <CANVKczM6_iRedgd5OxxvzL4xPnTbWTF=RwRcZw5ftFWxzOdVcQ@mail.gmail.com>

On Mon, Oct 3, 2016 at 10:38 AM, Mathieu Rajerison
<mathieu.rajerison at gmail.com> wrote:
> Hi R-List,
>
>
> I have a DEM on one hand, and on the other hand, I have an RGB aerial image
>
> I tried rasterVis and plot3D function, but I didn't find how to use the
> colors of my RGB aerial image.

from the help for plot3D:

  drape: RasterLayer, to 'drape' colors representing the values of
          this layer on the 3D representation of layer ?x?. In this
          case?x? typically has elevation data

So plot(x=mydem, drape=myimage) will make a 3d plot with the heights
from `mydem` and the colours from `myimage` draped over it - if
`myimage` is a 3-layer RGB raster then I suspect you'll get what you
want...

Barry


From barbosa at uevora.pt  Mon Oct  3 13:22:02 2016
From: barbosa at uevora.pt (A. Marcia BARBOSA)
Date: Mon, 3 Oct 2016 12:22:02 +0100
Subject: [R-sig-Geo] spplot : different legends per plot & mode of
 classification by default ?
In-Reply-To: <CAGfc75=qmZ2xvBdf2+8bwr2dFUq1FQrjCJ64i8YJyc8_aFKqog@mail.gmail.com>
References: <CAGfc75=qmZ2xvBdf2+8bwr2dFUq1FQrjCJ64i8YJyc8_aFKqog@mail.gmail.com>
Message-ID: <CAP9xbzxNW3=JDx1+KMJEF1s8U2+9hMEgZ2VQTOGpOoK_wFv0xw@mail.gmail.com>

Hi,

Chek out the code under fig12.R at http://rspatial.r-forge.r-
project.org/gallery/.

If you don't necessarily have to use spplot, I find the choroLayer function
in the cartography package much simpler. It uses the plot function, so it's
compatible with par (allowing you to set mfrow, mar, etc.) and with other
related functions (e.g. add, title), and you can define the 'breaks' for
each map.

Cheers,
AMB


2016-10-03 11:18 GMT+01:00 Mathieu Rajerison <mathieu.rajerison at gmail.com>:

> Hi,
>
>
> I have several variables of numeric data that I whish to spplot.
>
> How to push one classification per plot ?
>
> Also, what is the mode of classification used by default by spplot ? Is the
> data split into quantiles ?
>
>
> Thanks in advance for your answer
>
> Mathieu
>

	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Mon Oct  3 14:26:13 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 3 Oct 2016 14:26:13 +0200
Subject: [R-sig-Geo] DEM plot3D and overlay an aerial image
In-Reply-To: <CANVKczM6_iRedgd5OxxvzL4xPnTbWTF=RwRcZw5ftFWxzOdVcQ@mail.gmail.com>
References: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
	<CANVKczM6_iRedgd5OxxvzL4xPnTbWTF=RwRcZw5ftFWxzOdVcQ@mail.gmail.com>
Message-ID: <CAGfc75nYxV+qcsXEYxBbaPO1X4Ey491QPxnrN0yd0cDPzvb4yg@mail.gmail.com>

Thanks Barry.

The doc says that drape uses a RasterLayer but not a RasterStack.

So I don't know to overlay my RGB 3-dim layer on top of the DEM.

Maybe I should convert the RGB to a unique value ?
How to convert a RGB value to a unique value and does plot3D accept it ?
?

2016-10-03 13:14 GMT+02:00 Barry Rowlingson <b.rowlingson at lancaster.ac.uk>:

> On Mon, Oct 3, 2016 at 10:38 AM, Mathieu Rajerison
> <mathieu.rajerison at gmail.com> wrote:
> > Hi R-List,
> >
> >
> > I have a DEM on one hand, and on the other hand, I have an RGB aerial
> image
> >
> > I tried rasterVis and plot3D function, but I didn't find how to use the
> > colors of my RGB aerial image.
>
> from the help for plot3D:
>
>   drape: RasterLayer, to 'drape' colors representing the values of
>           this layer on the 3D representation of layer ?x?. In this
>           case?x? typically has elevation data
>
> So plot(x=mydem, drape=myimage) will make a 3d plot with the heights
> from `mydem` and the colours from `myimage` draped over it - if
> `myimage` is a 3-layer RGB raster then I suspect you'll get what you
> want...
>
> Barry
>

	[[alternative HTML version deleted]]


From mathieu.rajerison at gmail.com  Mon Oct  3 14:26:42 2016
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 3 Oct 2016 14:26:42 +0200
Subject: [R-sig-Geo] spplot : different legends per plot & mode of
 classification by default ?
In-Reply-To: <CAP9xbzxNW3=JDx1+KMJEF1s8U2+9hMEgZ2VQTOGpOoK_wFv0xw@mail.gmail.com>
References: <CAGfc75=qmZ2xvBdf2+8bwr2dFUq1FQrjCJ64i8YJyc8_aFKqog@mail.gmail.com>
	<CAP9xbzxNW3=JDx1+KMJEF1s8U2+9hMEgZ2VQTOGpOoK_wFv0xw@mail.gmail.com>
Message-ID: <CAGfc75ko6pCnYVjmDrybPqofJAD7zGXrxiGBWT_UVdw-G86nGQ@mail.gmail.com>

Thanks a lot, it's perfect
?

2016-10-03 13:22 GMT+02:00 A. Marcia BARBOSA <barbosa at uevora.pt>:

> Hi,
>
> Chek out the code under fig12.R at http://rspatial.r-forge.r-proj
> ect.org/gallery/.
>
> If you don't necessarily have to use spplot, I find the choroLayer
> function in the cartography package much simpler. It uses the plot
> function, so it's compatible with par (allowing you to set mfrow, mar,
> etc.) and with other related functions (e.g. add, title), and you can
> define the 'breaks' for each map.
>
> Cheers,
> AMB
>
>
> 2016-10-03 11:18 GMT+01:00 Mathieu Rajerison <mathieu.rajerison at gmail.com>
> :
>
>> Hi,
>>
>>
>> I have several variables of numeric data that I whish to spplot.
>>
>> How to push one classification per plot ?
>>
>> Also, what is the mode of classification used by default by spplot ? Is
>> the
>> data split into quantiles ?
>>
>>
>> Thanks in advance for your answer
>>
>> Mathieu
>>
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon Oct  3 14:32:15 2016
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 03 Oct 2016 12:32:15 +0000
Subject: [R-sig-Geo] DEM plot3D and overlay an aerial image
In-Reply-To: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
References: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
Message-ID: <CAAcGz9_JQgeNmDT_SDufUqqLXtmVVCveq6xf5-DXrzCkxMZAqQ@mail.gmail.com>

On Mon, 3 Oct 2016 at 21:08 Mathieu Rajerison <mathieu.rajerison at gmail.com>
wrote:

> Hi R-List,
>
>
> I have a DEM on one hand, and on the other hand, I have an RGB aerial image
>
> I tried rasterVis and plot3D function, but I didn't find how to use the
> colors of my RGB aerial image.
>
> For the moment, I used rgl instead although it doesn't seem very
> appropriate for georeferenced data..
>
> Here's the RGL code :
>
> gruissan =
> stack("../MAISON/DATA/geo/raster/bdortho_marseille/marseille.tif")
>
> r = values(gruissan[[1]])/255
> g = values(gruissan[[2]])/255
> b = values(gruissan[[3]])/255
> col = rgb(r, g, b)
>
> library(rgl)
> persp3d(1:nrow(mnt), 1:ncol(mnt), values(mnt), col=col)
>
>
I find the results are much better to use rgl more directly, if you can
construct the quadmesh with the DEM you can then texture map an RGB image
(it has to be PNG) directly, and there's no need for either the resolution
(or even the coordinate systems) of the texture and the DEM to match.
Texture mapping basically creates a new set of coordinates  on the DEM
structure itself, something our spatial tools are generally not very good
at.  If you are only changing the colours of the DEM pixels you don't get
anywhere near as good a result if your image is higher resolution than the
DEM.

This doesn't seem to be used very often, and in fact texture mapping in rgl
is hard to get right - you can leave the shade3d() material colours at
their default setting for example.  (It's also hard to show off since
there's a limit to the WebGL export that can be bundled into a page. )

This sequence below (it was fully reproducible when I did it) shows the
required steps in all their detail. I've since put the quadmesh package on
CRAN that does simplify some of this a fair bit. I'd be happy to work up an
example if you provide links to a DEM and image.

https://gist.github.com/mdsumner/e131f6d73aa02d49c7fd3357d94d3ad1

Cheers, Mike.



> Best,
>
> Mathieu
>
>
> ?
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mauricio.zambrano at ufrontera.cl  Mon Oct  3 15:45:45 2016
From: mauricio.zambrano at ufrontera.cl (Mauricio Zambrano Bigiarini)
Date: Mon, 3 Oct 2016 10:45:45 -0300
Subject: [R-sig-Geo] raster: crop error ('nrows > 0 is not TRUE')
Message-ID: <CAP6VaruqGVc1WoAJEZ2CEjtdAahYgu01xrwWA7N65ZREAW3Ekw@mail.gmail.com>

Dear list,

I'm applying the 'crop' command of the raster pacakge to subset a
RasterStack ('r') with a SpatialPolygonsDataFrame ('boundary'):

raster.crop <- crop(r, boundary, snap="out")

and what I get is:

Error: nrows > 0 is not TRUE


The summary of the two previous objects are:

> r
class       : RasterStack
dimensions  : 666, 211, 140526, 8  (nrow, ncol, ncell, nlayers)
resolution  : 0.05, 0.05  (x, y)
extent      : -76.3, -65.75, -50, -16.7  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0
names       : Year.2003, Year.2004, Year.2005, Year.2006, Year.2007,
Year.2008, Year.2009, Year.2010
min values  :         0,         0,         0,         0,         0,
      0,         0,         0
max values  :    844.79,    706.53,    616.73,    888.75,    701.53,
 853.47,    642.07,    986.31


> boundary
class       : SpatialPolygonsDataFrame
features    : 16
extent      : -75.693, -66.419, -55.914, -17.498  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0
variables   : 1
names       : NOM_REG
min values  :       1
max values  :       9

the previous 'crop' command worked perfectly with a different
RasterStack object, with a similar spatial extent, and I don't now
what is wrong here.


The output of my sessionInfo() is:

sessionInfo()
R version 3.3.1 (2016-06-21)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.2 LTS

locale:
 [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_GB.UTF-8
LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] colorspace_1.2-6    reshape2_1.4.1      rasterVis_0.40
latticeExtra_0.6-28 RColorBrewer_1.1-2  lattice_0.20-34
rgdal_1.1-10        hydroGOF_0.3-8-7    hydroTSM_0.4-8      xts_0.9-7
         zoo_1.7-13
[12] raster_2.5-8        sp_1.2-3

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.6       magrittr_1.5      maptools_0.8-39
viridisLite_0.1.3 FNN_1.1           stringr_1.0.0     plyr_1.8.4
 tools_3.3.1       parallel_3.3.1    grid_3.3.1        gstat_1.1-3
  e1071_1.6-7
[13] class_7.3-14      intervals_0.15.1  automap_1.0-14    ncdf4_1.15
      stringi_1.1.1     spacetime_1.1-5   reshape_0.8.5
foreign_0.8-66    hexbin_1.27.1


Any idea about how to solve this issue is highly appreciated.

Thanks in advance,



Mauricio Zambrano-Bigiarini, PhD

=====================================
Department of Civil Engineering
Faculty of Engineering and Sciences
Universidad de La Frontera
PO Box 54-D, Temuco, Chile
http://hzambran.github.io/
=====================================
mailto     : mauricio.zambrano at ufrontera.cl
work-phone : +56 45 259 2812
=====================================
"To accomplish great things, we must not only act,
but also dream; not only plan, but also believe"
(Anatole France)
=====================================
Linux user #454569 -- Linux Mint user

-- 
La informaci?n contenida en este correo electr?nico y cualquier anexo o 
respuesta relacionada, puede contener datos e informaci?n confidencial y no 
puede ser usada o difundida por personas distintas a su(s) destinatario(s). 
Si usted no es el destinatario de esta comunicaci?n, le informamos que 
cualquier divulgaci?n, distribuci?n o copia de esta informaci?n constituye 
un delito conforme a la ley chilena. Si lo ha recibido por error, por favor 
borre el mensaje y todos sus anexos y notifique al remitente.


From dosc3612 at colorado.edu  Mon Oct  3 17:34:38 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Mon, 3 Oct 2016 09:34:38 -0600
Subject: [R-sig-Geo] raster: crop error ('nrows > 0 is not TRUE')
In-Reply-To: <CAP6VaruqGVc1WoAJEZ2CEjtdAahYgu01xrwWA7N65ZREAW3Ekw@mail.gmail.com>
References: <CAP6VaruqGVc1WoAJEZ2CEjtdAahYgu01xrwWA7N65ZREAW3Ekw@mail.gmail.com>
Message-ID: <CAF1jk_mP-4egysHjwvUwRUWJWWvSg=_Wofbb6orMXpwGS8YmbQ@mail.gmail.com>

Isn't the southern border of your boundary shapefile outside the extent of
your raster? hence there are no rows to extract.

On Mon, Oct 3, 2016 at 7:45 AM, Mauricio Zambrano Bigiarini <
mauricio.zambrano at ufrontera.cl> wrote:

> Dear list,
>
> I'm applying the 'crop' command of the raster pacakge to subset a
> RasterStack ('r') with a SpatialPolygonsDataFrame ('boundary'):
>
> raster.crop <- crop(r, boundary, snap="out")
>
> and what I get is:
>
> Error: nrows > 0 is not TRUE
>
>
> The summary of the two previous objects are:
>
> > r
> class       : RasterStack
> dimensions  : 666, 211, 140526, 8  (nrow, ncol, ncell, nlayers)
> resolution  : 0.05, 0.05  (x, y)
> extent      : -76.3, -65.75, -50, -16.7  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> +towgs84=0,0,0
> names       : Year.2003, Year.2004, Year.2005, Year.2006, Year.2007,
> Year.2008, Year.2009, Year.2010
> min values  :         0,         0,         0,         0,         0,
>       0,         0,         0
> max values  :    844.79,    706.53,    616.73,    888.75,    701.53,
>  853.47,    642.07,    986.31
>
>
> > boundary
> class       : SpatialPolygonsDataFrame
> features    : 16
> extent      : -75.693, -66.419, -55.914, -17.498  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
> +towgs84=0,0,0
> variables   : 1
> names       : NOM_REG
> min values  :       1
> max values  :       9
>
> the previous 'crop' command worked perfectly with a different
> RasterStack object, with a similar spatial extent, and I don't now
> what is wrong here.
>
>
> The output of my sessionInfo() is:
>
> sessionInfo()
> R version 3.3.1 (2016-06-21)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.2 LTS
>
> locale:
>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
> LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_GB.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>  [1] colorspace_1.2-6    reshape2_1.4.1      rasterVis_0.40
> latticeExtra_0.6-28 RColorBrewer_1.1-2  lattice_0.20-34
> rgdal_1.1-10        hydroGOF_0.3-8-7    hydroTSM_0.4-8      xts_0.9-7
>          zoo_1.7-13
> [12] raster_2.5-8        sp_1.2-3
>
> loaded via a namespace (and not attached):
>  [1] Rcpp_0.12.6       magrittr_1.5      maptools_0.8-39
> viridisLite_0.1.3 FNN_1.1           stringr_1.0.0     plyr_1.8.4
>  tools_3.3.1       parallel_3.3.1    grid_3.3.1        gstat_1.1-3
>   e1071_1.6-7
> [13] class_7.3-14      intervals_0.15.1  automap_1.0-14    ncdf4_1.15
>       stringi_1.1.1     spacetime_1.1-5   reshape_0.8.5
> foreign_0.8-66    hexbin_1.27.1
>
>
> Any idea about how to solve this issue is highly appreciated.
>
> Thanks in advance,
>
>
>
> Mauricio Zambrano-Bigiarini, PhD
>
> =====================================
> Department of Civil Engineering
> Faculty of Engineering and Sciences
> Universidad de La Frontera
> PO Box 54-D, Temuco, Chile
> http://hzambran.github.io/
> =====================================
> mailto     : mauricio.zambrano at ufrontera.cl
> work-phone : +56 45 259 2812
> =====================================
> "To accomplish great things, we must not only act,
> but also dream; not only plan, but also believe"
> (Anatole France)
> =====================================
> Linux user #454569 -- Linux Mint user
>
> --
> La informaci?n contenida en este correo electr?nico y cualquier anexo o
> respuesta relacionada, puede contener datos e informaci?n confidencial y no
> puede ser usada o difundida por personas distintas a su(s) destinatario(s).
> Si usted no es el destinatario de esta comunicaci?n, le informamos que
> cualquier divulgaci?n, distribuci?n o copia de esta informaci?n constituye
> un delito conforme a la ley chilena. Si lo ha recibido por error, por favor
> borre el mensaje y todos sus anexos y notifique al remitente.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From mauricio.zambrano at ufrontera.cl  Mon Oct  3 21:39:32 2016
From: mauricio.zambrano at ufrontera.cl (Mauricio Zambrano Bigiarini)
Date: Mon, 3 Oct 2016 16:39:32 -0300
Subject: [R-sig-Geo] raster: crop error ('nrows > 0 is not TRUE')
In-Reply-To: <CAF1jk_mP-4egysHjwvUwRUWJWWvSg=_Wofbb6orMXpwGS8YmbQ@mail.gmail.com>
References: <CAP6VaruqGVc1WoAJEZ2CEjtdAahYgu01xrwWA7N65ZREAW3Ekw@mail.gmail.com>
	<CAF1jk_mP-4egysHjwvUwRUWJWWvSg=_Wofbb6orMXpwGS8YmbQ@mail.gmail.com>
Message-ID: <CAP6VartHSTGzjHLwJ8CrSMYpCDpTLCPV26AmJP8WU3Qsz5XhqQ@mail.gmail.com>

Thank you very much Dominik.

You are right,  the southern border of the shapefile used as boundary
is outside the borders of the RasterStack that I want to crop, and
that is the difference with a previous case where the 'crop' command
worked without any problem.

However, reading the documentation of 'crop', I think that command
should rise a warning and not an error in such a case:

 "Areas included in ?y? but outside the extent of  ?x? are ignored
(see ?extend? if you want a larger area)."


Thanks for your help.

mzb

=====================================
"To accomplish great things, we must not only act,
but also dream; not only plan, but also believe"
(Anatole France)
=====================================
Linux user #454569 -- Linux Mint user


On 3 October 2016 at 12:34, Dominik Schneider <dosc3612 at colorado.edu> wrote:
> Isn't the southern border of your boundary shapefile outside the extent of
> your raster? hence there are no rows to extract.
>
> On Mon, Oct 3, 2016 at 7:45 AM, Mauricio Zambrano Bigiarini
> <mauricio.zambrano at ufrontera.cl> wrote:
>>
>> Dear list,
>>
>> I'm applying the 'crop' command of the raster pacakge to subset a
>> RasterStack ('r') with a SpatialPolygonsDataFrame ('boundary'):
>>
>> raster.crop <- crop(r, boundary, snap="out")
>>
>> and what I get is:
>>
>> Error: nrows > 0 is not TRUE
>>
>>
>> The summary of the two previous objects are:
>>
>> > r
>> class       : RasterStack
>> dimensions  : 666, 211, 140526, 8  (nrow, ncol, ncell, nlayers)
>> resolution  : 0.05, 0.05  (x, y)
>> extent      : -76.3, -65.75, -50, -16.7  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
>> +towgs84=0,0,0
>> names       : Year.2003, Year.2004, Year.2005, Year.2006, Year.2007,
>> Year.2008, Year.2009, Year.2010
>> min values  :         0,         0,         0,         0,         0,
>>       0,         0,         0
>> max values  :    844.79,    706.53,    616.73,    888.75,    701.53,
>>  853.47,    642.07,    986.31
>>
>>
>> > boundary
>> class       : SpatialPolygonsDataFrame
>> features    : 16
>> extent      : -75.693, -66.419, -55.914, -17.498  (xmin, xmax, ymin, ymax)
>> coord. ref. : +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs
>> +towgs84=0,0,0
>> variables   : 1
>> names       : NOM_REG
>> min values  :       1
>> max values  :       9
>>
>> the previous 'crop' command worked perfectly with a different
>> RasterStack object, with a similar spatial extent, and I don't now
>> what is wrong here.
>>
>>
>> The output of my sessionInfo() is:
>>
>> sessionInfo()
>> R version 3.3.1 (2016-06-21)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.2 LTS
>>
>> locale:
>>  [1] LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C
>> LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8
>> LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_GB.UTF-8
>> LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>  [1] colorspace_1.2-6    reshape2_1.4.1      rasterVis_0.40
>> latticeExtra_0.6-28 RColorBrewer_1.1-2  lattice_0.20-34
>> rgdal_1.1-10        hydroGOF_0.3-8-7    hydroTSM_0.4-8      xts_0.9-7
>>          zoo_1.7-13
>> [12] raster_2.5-8        sp_1.2-3
>>
>> loaded via a namespace (and not attached):
>>  [1] Rcpp_0.12.6       magrittr_1.5      maptools_0.8-39
>> viridisLite_0.1.3 FNN_1.1           stringr_1.0.0     plyr_1.8.4
>>  tools_3.3.1       parallel_3.3.1    grid_3.3.1        gstat_1.1-3
>>   e1071_1.6-7
>> [13] class_7.3-14      intervals_0.15.1  automap_1.0-14    ncdf4_1.15
>>       stringi_1.1.1     spacetime_1.1-5   reshape_0.8.5
>> foreign_0.8-66    hexbin_1.27.1
>>
>>
>> Any idea about how to solve this issue is highly appreciated.
>>
>> Thanks in advance,
>>
>>
>>
>> Mauricio Zambrano-Bigiarini, PhD
>>
>> =====================================
>> Department of Civil Engineering
>> Faculty of Engineering and Sciences
>> Universidad de La Frontera
>> PO Box 54-D, Temuco, Chile
>> http://hzambran.github.io/
>> =====================================
>> mailto     : mauricio.zambrano at ufrontera.cl
>> work-phone : +56 45 259 2812
>> =====================================
>> "To accomplish great things, we must not only act,
>> but also dream; not only plan, but also believe"
>> (Anatole France)
>> =====================================
>> Linux user #454569 -- Linux Mint user
>>
>> --
>> La informaci?n contenida en este correo electr?nico y cualquier anexo o
>> respuesta relacionada, puede contener datos e informaci?n confidencial y
>> no
>> puede ser usada o difundida por personas distintas a su(s)
>> destinatario(s).
>> Si usted no es el destinatario de esta comunicaci?n, le informamos que
>> cualquier divulgaci?n, distribuci?n o copia de esta informaci?n constituye
>> un delito conforme a la ley chilena. Si lo ha recibido por error, por
>> favor
>> borre el mensaje y todos sus anexos y notifique al remitente.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>

-- 
La informaci?n contenida en este correo electr?nico y cualquier anexo o 
respuesta relacionada, puede contener datos e informaci?n confidencial y no 
puede ser usada o difundida por personas distintas a su(s) destinatario(s). 
Si usted no es el destinatario de esta comunicaci?n, le informamos que 
cualquier divulgaci?n, distribuci?n o copia de esta informaci?n constituye 
un delito conforme a la ley chilena. Si lo ha recibido por error, por favor 
borre el mensaje y todos sus anexos y notifique al remitente.


From macqueen1 at llnl.gov  Mon Oct  3 21:50:30 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 3 Oct 2016 19:50:30 +0000
Subject: [R-sig-Geo] DEM plot3D and overlay an aerial image
In-Reply-To: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
References: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>
Message-ID: <D418045E.187B65%macqueen1@llnl.gov>

Have you tried
  plotRGB(gruissan)
?

plotRGB is in the raster package.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/3/16, 2:38 AM, "R-sig-Geo on behalf of Mathieu Rajerison"
<r-sig-geo-bounces at r-project.org on behalf of mathieu.rajerison at gmail.com>
wrote:

>Hi R-List,
>
>
>I have a DEM on one hand, and on the other hand, I have an RGB aerial
>image
>
>I tried rasterVis and plot3D function, but I didn't find how to use the
>colors of my RGB aerial image.
>
>For the moment, I used rgl instead although it doesn't seem very
>appropriate for georeferenced data..
>
>Here's the RGL code :
>
>gruissan =
>stack("../MAISON/DATA/geo/raster/bdortho_marseille/marseille.tif")
>
>r = values(gruissan[[1]])/255
>g = values(gruissan[[2]])/255
>b = values(gruissan[[3]])/255
>col = rgb(r, g, b)
>
>library(rgl)
>persp3d(1:nrow(mnt), 1:ncol(mnt), values(mnt), col=col)
>
>Best,
>
>Mathieu
>
>
>?
>
>	[[alternative HTML version deleted]]
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.turner at auckland.ac.nz  Mon Oct  3 22:19:49 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 4 Oct 2016 09:19:49 +1300
Subject: [R-sig-Geo] YNT:  Complete spatial randomness testing
In-Reply-To: <C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>
References: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
	<74a86dbf-43e0-0ad0-e51c-1a65e69e6030@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC1DFF@mb05.porsuk.anadolu.edu.tr>
	<1bbf91f1-b9d6-d532-7beb-c22ecffe6945@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>
Message-ID: <d4f55fef-b389-e9e1-0fd6-328a81484b2c@auckland.ac.nz>

On 03/10/16 20:35, Cenk ???Z wrote:
> According to your suggestion , I excluded duplicated points. However
> I
took the same error message.
>
> udp1<-unique.ppp(dp1) xxx<-allstats(udp1) Error: in Fest(X, r) the
> successive r values must be finely spaced:
given spacing = 0.010196; required spacing <= 0.00586
>
> I attached the data for you to investigate. Thanks a lot.


Thank you for providing the data.  There does indeed seem to be a 
problem.  We are looking into it.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From paolo.piras at uniroma3.it  Tue Oct  4 19:48:46 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Tue, 4 Oct 2016 17:48:46 +0000
Subject: [R-sig-Geo] Fractal dimension 2d and 3d shapes
In-Reply-To: <D418045E.187B65%macqueen1@llnl.gov>
References: <CAGfc75mpGqLhgJ4RvtnwnrRVNAhqp+7e15XKCe=Pg+BoFcxFjQ@mail.gmail.com>,
	<D418045E.187B65%macqueen1@llnl.gov>
Message-ID: <HE1PR04MB11612666EA7EF3A160F44A79B3C50@HE1PR04MB1161.eurprd04.prod.outlook.com>

HI folks,

I would like to compute the fractal dimension of 2D and 3D shapes identified by k points thus on matrices kx2 or  kx3.

I know fractaldim package but I have some trouble in working with it.

I write to ask if anyone has some experience with this kind of analysis.

All the best

Paolo



	[[alternative HTML version deleted]]


From potts.a at gmail.com  Tue Oct  4 21:08:09 2016
From: potts.a at gmail.com (Alastair Potts)
Date: Tue, 4 Oct 2016 21:08:09 +0200
Subject: [R-sig-Geo] Extracting polygon information from points with
	variable buffer distances
Message-ID: <CAG_8N1Z5SbyBg9ue_Ag=i+Gk3azHbNKkB_0XyPmbxYVipHLMLw@mail.gmail.com>

Hi all,

I have a dataset of site locality information with locality confidence
distances (ranging from 0 m to ~10 km). I am trying to intersect these
points with a polygon shape file and extract the polygon information (or
just the polygon id for further extraction), but with the added complexity
of including all those polygons that fall within the locality confidence
distance (i.e. a buffer).

I am a familiar with R, but not so much the spatial libraries. I have spent
quite a while looking around on RSeek, and Google, but nothing I find is
quite right. What I would appreciate is any pointers to functions that
could help me with the above scenario. I can probably figure it out from
there.

What I have put my efforts into:
I initially thought that extract() would work, but this appears to only be
for rasters.
I have been trying to use gBuffer() as an initial step prior to using the
over() function, but I can't get gBuffer to operate in the meters (or
kilometres) as the polyshape is projected using WGS84 and lat/long units.
(any suggestions here).

Any pointers would be greatly appreciated.

Kind regards,
Alastair

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Oct  4 21:38:20 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Oct 2016 08:38:20 +1300
Subject: [R-sig-Geo] YNT:  Complete spatial randomness testing
In-Reply-To: <C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>
References: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
	<74a86dbf-43e0-0ad0-e51c-1a65e69e6030@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC1DFF@mb05.porsuk.anadolu.edu.tr>
	<1bbf91f1-b9d6-d532-7beb-c22ecffe6945@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>
Message-ID: <de29e631-061e-ecda-d6e0-e7ffb1bd860a@auckland.ac.nz>

On 03/10/16 20:35, Cenk ???Z wrote:
> According to your suggestion , I excluded duplicated points. However I took the same error message.
>
> udp1<-unique.ppp(dp1)
>  xxx<-allstats(udp1)
> Error: in Fest(X, r) the successive r values must be finely spaced: given spacing = 0.010196; required spacing <=  0.00586
>
> I attached the data for you to investigate. Thanks a lot.


There was indeed a bug in the Jest() function.  It has now been fixed.
The fixed version will be available in the next release of spatstat.
You can also get a fixed (updated) version of spatstat (version 
1.46-1.059) from github.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From cicoz at anadolu.edu.tr  Wed Oct  5 10:29:14 2016
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Wed, 5 Oct 2016 08:29:14 +0000
Subject: [R-sig-Geo] YNT:  Complete spatial randomness testing
In-Reply-To: <5b759ded-e3dd-540d-8b4b-0ebb9d768dd5@auckland.ac.nz>
References: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
	<74a86dbf-43e0-0ad0-e51c-1a65e69e6030@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC1DFF@mb05.porsuk.anadolu.edu.tr>
	<1bbf91f1-b9d6-d532-7beb-c22ecffe6945@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>
	<5b759ded-e3dd-540d-8b4b-0ebb9d768dd5@auckland.ac.nz>
Message-ID: <C2AF35551EE58A4487CC3151707449ADBCCC326A@mb05.porsuk.anadolu.edu.tr>

Dear Rolf,

I installed the fixed version of spatstat from github repository. allstats and Jest worked perfectly. 
Thanks for all the help. I will be waiting for the new version release.
Many thanks for the package and contributions to the point pattern analysis too,  they are a great asset for people working with point pattern data.



Res. Asst. Cenk Icoz
Statistics Department ,Anadolu University, Turkey





-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz] 
Sent: Tuesday, October 4, 2016 9:41 PM
To: Cenk ???Z <cicoz at anadolu.edu.tr>
Subject: Re: YNT: [R-sig-Geo] Complete spatial randomness testing


Dear Cenk,

The fixed version of spatstat (in which Jest() works properly) is available from github.  If you need/would like a Windoze binary, let me know, and I'll get one built for you.  (The facility for putting Windoze binaries up on github is broken.)

cheers,

Rolf

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Wed Oct  5 10:46:42 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 5 Oct 2016 21:46:42 +1300
Subject: [R-sig-Geo] YNT:  Complete spatial randomness testing
In-Reply-To: <C2AF35551EE58A4487CC3151707449ADBCCC326A@mb05.porsuk.anadolu.edu.tr>
References: <C2AF35551EE58A4487CC3151707449ADBCCC0CB1@mb05.porsuk.anadolu.edu.tr>
	<74a86dbf-43e0-0ad0-e51c-1a65e69e6030@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC1DFF@mb05.porsuk.anadolu.edu.tr>
	<1bbf91f1-b9d6-d532-7beb-c22ecffe6945@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC2FED@mb05.porsuk.anadolu.edu.tr>
	<5b759ded-e3dd-540d-8b4b-0ebb9d768dd5@auckland.ac.nz>
	<C2AF35551EE58A4487CC3151707449ADBCCC326A@mb05.porsuk.anadolu.edu.tr>
Message-ID: <c21d85d4-e05b-71ad-d499-641bf16804d2@auckland.ac.nz>

On 05/10/16 21:29, Cenk ???Z wrote:
> Dear Rolf,
>
> I installed the fixed version of spatstat from github repository.
> allstats and Jest worked perfectly.
> Thanks for all the help. I will be waiting for the new version
> release. Many thanks for the package and contributions to the point
> pattern  analysis too, they are a great asset for people working with point
> pattern data.


Glad to hear that it's working for you.  You will note (if you look at 
"latest.news") that you got an acknowledgement.  (With that, and 2 bob,
you can make a phone call. :-)  Said he, showing his age.)

Thank you for your kind words about spatstat.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From lma243 at nau.edu  Wed Oct  5 19:50:02 2016
From: lma243 at nau.edu (Lindsie McCabe)
Date: Wed, 5 Oct 2016 10:50:02 -0700
Subject: [R-sig-Geo] count points greater than in a raster
Message-ID: <CAJTy0xB3A7ivzNJ0UTrY1u2CuM+_QMoth69zNbfm52dS-gQ3wA@mail.gmail.com>

Hi All,

I am creating a raster map of insect occurrence records, right now I have
if counting up the number of occurrence points based on the pixel area.

However because there is one area that is highly abundant in occurrence
records it is saturating the rest of the map.

What I would like to do is call a function in R that says if count is
grater the 100,000 records count as 100,000.

This is the code I am working with now:
pop <- read.table("allGeo.tsv", header=TRUE, stringsAsFactors=FALSE)
head(pop)
r2 = raster (ncol=500,nrow=1000)
pr<-raster::rasterize(pop, r2, fun='count', cex=0.6)
cropbox2 <-c(-178,-49,18, 71)
pr2 <- crop(pr, cropbox2)
pr2
plot(pr2)


Thank you,


-- 
*Lindsie McCabe*
PhD Student
Department of Biology
Merriam Powell Center for Environmental Research
Northern Arizona University

	[[alternative HTML version deleted]]


From dicko.ahmadou at gmail.com  Wed Oct  5 19:57:41 2016
From: dicko.ahmadou at gmail.com (Ahmadou Dicko)
Date: Wed, 5 Oct 2016 19:57:41 +0200
Subject: [R-sig-Geo] count points greater than in a raster
In-Reply-To: <CAJTy0xB3A7ivzNJ0UTrY1u2CuM+_QMoth69zNbfm52dS-gQ3wA@mail.gmail.com>
References: <CAJTy0xB3A7ivzNJ0UTrY1u2CuM+_QMoth69zNbfm52dS-gQ3wA@mail.gmail.com>
Message-ID: <CAP8THHXbrxACJHFGaq4XVySK8Xemw84xSHTHNaM8wxSQVGKWcg@mail.gmail.com>

Hi,

I don't see any need to create a custom function for that, you can just
manipulate the final raster as requested.

pop <- read.table("allGeo.tsv", header=TRUE, stringsAsFactors=FALSE)
head(pop)
r2 = raster (ncol=500,nrow=1000)
pr<-raster::rasterize(pop, r2, fun='count', cex=0.6)
cropbox2 <-c(-178,-49,18, 71)
pr2 <- crop(pr, cropbox2)
pr2[pr2 >= 1e5] <- 1e5

Hope it helps


On Wed, Oct 5, 2016 at 7:50 PM, Lindsie McCabe <lma243 at nau.edu> wrote:

> Hi All,
>
> I am creating a raster map of insect occurrence records, right now I have
> if counting up the number of occurrence points based on the pixel area.
>
> However because there is one area that is highly abundant in occurrence
> records it is saturating the rest of the map.
>
> What I would like to do is call a function in R that says if count is
> grater the 100,000 records count as 100,000.
>
> This is the code I am working with now:
> pop <- read.table("allGeo.tsv", header=TRUE, stringsAsFactors=FALSE)
> head(pop)
> r2 = raster (ncol=500,nrow=1000)
> pr<-raster::rasterize(pop, r2, fun='count', cex=0.6)
> cropbox2 <-c(-178,-49,18, 71)
> pr2 <- crop(pr, cropbox2)
> pr2
> plot(pr2)
>
>
> Thank you,
>
>
> --
> *Lindsie McCabe*
> PhD Student
> Department of Biology
> Merriam Powell Center for Environmental Research
> Northern Arizona University
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Ahmadou H. DICKO, PhD
Data hacker and climate change economist
Post-doctoral researcher
CIRAD - UMR15 CIRAD/INRA Control of exotic and emerging diseases
email : ahmadou-hamady.dicko at cirad.fr <ahmadou.dicko at ucad.edu.sn>
twitter : @dickoah
github : github/dickoa <https://github.com/dickoa>
portable: +33 7 68 16 11 58

	[[alternative HTML version deleted]]


From kimon-vincent.krenz.12 at ucl.ac.uk  Wed Oct  5 22:43:48 2016
From: kimon-vincent.krenz.12 at ucl.ac.uk (Krenz, Kimon-Vincent)
Date: Wed, 5 Oct 2016 20:43:48 +0000
Subject: [R-sig-Geo] Generating Random Planar Graph with 1m Edges
Message-ID: <0715E972-25B4-4A48-986E-7F933F6C3BE8@ucl.ac.uk>

Dear All,

I started a week ago to use R to solve a problem I am currently facing in my PhD.
Apologies in advance for the long-winded explanation of my problem.

I am trying to generate a random planar graph with approximately 1 million edges, where:

A) nodes (points) feature spatial coordinates
B) the network has a given boundary

C) edges (lines) are created if two points fall within a given distance (e.g. 100 - 1000 metres)
D) degree (connectivity) ranges between given k max and min (e.g. k ? 5)
E) edges do not intersect

This will result in something one might want to compare to a random street network.

I am following a method proposed here: Masucci, A. P., Smith, D., Crooks, A., & Batty, M. (2009). Random planar graphs and the London street network. European Physical Journal B, 71(2), 259?271. http://doi.org/10.1140/epjb/e2009-00290-4) link to paper: https://goo.gl/6XWW8P

Masucci et al.: "We first introduce a random model for a static planar graph. ... To build an ERPG we start with a Poisson distribution of N points in a plane and we choose a distance r. To build the first segment, we randomly pick up two points of the distribution that have a distance less then r and we connect them. Then we continue to randomly pick up pairs of points P and Q in the given points distribution that have a distance less then r. If the segment PQ does not intersect any other line of the graph, we add it to the graph. The process ends when we add the desired number of edges E.?

I hence, started with generating random points using the Poisson distribution in a given spatial box (A and A):

require(spatstat)
require(maps)
library(sp)
w <- as.owin(list(xrange=c(32275175,32475175),yrange=c(5611910,5811910)))
Y <- rpoispp(0.00001, win=w)
Ydata <- data.frame(Y)
list(Y)

That seems to be quite straightforward in R.
I then followed the proposed method and wrote a simple loop, that selects two points from Ydata
based on a random sample and adds the projection of the coordinate system.

#399717 is = N from the rpoispp

repeat {
  l1 <- sample(1:399717, 2, replace=F)

 Ydata.sp<-Ydata[l1, c('x','y')]
  coordinates(Ydata.sp)<-~x+y
  crs.geo <- CRS("+init=epsg:4647 +proj=tmerc +lat_0=0 +lon_0=9 +k=0.9996 +x_0=32500000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
  proj4string(Ydata.sp) <- crs.geo

  L = SpatialLines(list(Lines(list(Line(coordinates(Ydata.sp))),"X")))
  if (SpatialLinesLengths(L)<=4000){
    break
  }
}
plot(L)
SpatialLinesLengths(L)

This fulfils the requirement of C) and I have not yet reached the point to deal with D) and E).
My problem here is that the process takes way too long for a single pair (approx 20 seconds, resulting in 250 days computational time).

Is there a quicker way solve this in a more efficient manner?

I have thought about selecting the first point by random and the second one randomly based on an evaluation
of all points within a given radius to the first point, rather than two complete random points.

This would at least cut down the test of several thousand meaningless combinations. However, I couldn't find a way to do this.
Another option might be gDistance from the (rgeos), but with 400k points, the result seems to be not computable.

I am also happy for any suggestions regarding requirements D and E, or help with the task in general.

Best,
Kimon

Kimon Krenz

PhD Researcher
MSc SDAC Course Coordinator<http://www.bartlett.ucl.ac.uk/space-syntax/programmes/mres-msc/msc-spatial-design>
Space Syntax Laboratory<http://www.bartlett.ucl.ac.uk/space-syntax>

mail.       ucftkr3 at ucl.ac.uk<mailto:ucftkr3 at ucl.ac.uk>
phone.    0044 7784 329089
web.       www.kimonkrenz.com<http://www.kimonkrenz.com/>

Bartlett School of Architecture<http://www.bartlett.ucl.ac.uk/>
UCL
140 Hampstead Road
London     NW1 2BX     UK


	[[alternative HTML version deleted]]


From philipova at imbm.bas.bg  Thu Oct  6 11:39:49 2016
From: philipova at imbm.bas.bg (Philipova)
Date: Thu, 6 Oct 2016 12:39:49 +0300
Subject: [R-sig-Geo] What is essential for Bayesian trans-Gaussian kriging
	using bootstrap and using copulas
Message-ID: <004801d21fb5$9520ebb0$b0e660c3@NikolinaKo1>

Dear members of R-geo,
Could someone expalin me what do
Bayesian trans-Gaussian kriging using bootstrap and using copulas mean

Thank you so much in advance!

Regards

Nina Philipova


---
???? ????? ? ???????? ?? ?????? ?? Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From santiago.begueria at csic.es  Thu Oct  6 11:52:06 2016
From: santiago.begueria at csic.es (=?utf-8?Q?Santiago_Beguer=C3=ADa?=)
Date: Thu, 6 Oct 2016 11:52:06 +0200
Subject: [R-sig-Geo] Kriging with uncertain data
Message-ID: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>

Dear R-sig-geo list members,

I am curious about what are sensible approaches to spatial interpolation, most especially by using kriging, in the context of uncertain data.

Suppose one has a dataset of values observed at different locations, and each value consists on the expected value and its variance. Variance here represents the uncertainty related to the observation, and shows spatial variation due to external factors, for instance the geological setting affecting the quality of the measurement.

How would you proceed to model the spatial distribution of this variable, including propagation of the (spatially varying)?

I suppose one approach could be by simulation, but at there other ways of propagating the uncertainty that do not involve potentially expensive (in computation time) simulation approaches?

Cheers,

Santiago Beguer?a
CSIC
Spain


From Roger.Bivand at nhh.no  Thu Oct  6 14:32:14 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 6 Oct 2016 14:32:14 +0200
Subject: [R-sig-Geo] Generating Random Planar Graph with 1m Edges
In-Reply-To: <0715E972-25B4-4A48-986E-7F933F6C3BE8@ucl.ac.uk>
References: <0715E972-25B4-4A48-986E-7F933F6C3BE8@ucl.ac.uk>
Message-ID: <alpine.LFD.2.20.1610061429450.12536@reclus.nhh.no>

Just a partial suggestion: the RANN package will let you index the points 
byk-neighbourness, avoiding some of the burden of searching for points 
within your 100-1000m band.

Hope this helps,

Roger

On Wed, 5 Oct 2016, Krenz, Kimon-Vincent wrote:

> Dear All,
>
> I started a week ago to use R to solve a problem I am currently facing in my PhD.
> Apologies in advance for the long-winded explanation of my problem.
>
> I am trying to generate a random planar graph with approximately 1 million edges, where:
>
> A) nodes (points) feature spatial coordinates
> B) the network has a given boundary
>
> C) edges (lines) are created if two points fall within a given distance 
> (e.g. 100 - 1000 metres)

> D) degree (connectivity) ranges between given k max and min (e.g. k ? 5)
> E) edges do not intersect
>
> This will result in something one might want to compare to a random street network.
>
> I am following a method proposed here: Masucci, A. P., Smith, D., Crooks, A., & Batty, M. (2009). Random planar graphs and the London street network. European Physical Journal B, 71(2), 259?271. http://doi.org/10.1140/epjb/e2009-00290-4) link to paper: https://goo.gl/6XWW8P
>
> Masucci et al.: "We first introduce a random model for a static planar graph. ... To build an ERPG we start with a Poisson distribution of N points in a plane and we choose a distance r. To build the first segment, we randomly pick up two points of the distribution that have a distance less then r and we connect them. Then we continue to randomly pick up pairs of points P and Q in the given points distribution that have a distance less then r. If the segment PQ does not intersect any other line of the graph, we add it to the graph. The process ends when we add the desired number of edges E.?
>
> I hence, started with generating random points using the Poisson distribution in a given spatial box (A and A):
>
> require(spatstat)
> require(maps)
> library(sp)
> w <- as.owin(list(xrange=c(32275175,32475175),yrange=c(5611910,5811910)))
> Y <- rpoispp(0.00001, win=w)
> Ydata <- data.frame(Y)
> list(Y)
>
> That seems to be quite straightforward in R.
> I then followed the proposed method and wrote a simple loop, that selects two points from Ydata
> based on a random sample and adds the projection of the coordinate system.
>
> #399717 is = N from the rpoispp
>
> repeat {
>  l1 <- sample(1:399717, 2, replace=F)
>
> Ydata.sp<-Ydata[l1, c('x','y')]
>  coordinates(Ydata.sp)<-~x+y
>  crs.geo <- CRS("+init=epsg:4647 +proj=tmerc +lat_0=0 +lon_0=9 +k=0.9996 +x_0=32500000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
>  proj4string(Ydata.sp) <- crs.geo
>
>  L = SpatialLines(list(Lines(list(Line(coordinates(Ydata.sp))),"X")))
>  if (SpatialLinesLengths(L)<=4000){
>    break
>  }
> }
> plot(L)
> SpatialLinesLengths(L)
>
> This fulfils the requirement of C) and I have not yet reached the point to deal with D) and E).
> My problem here is that the process takes way too long for a single pair (approx 20 seconds, resulting in 250 days computational time).
>
> Is there a quicker way solve this in a more efficient manner?
>
> I have thought about selecting the first point by random and the second one randomly based on an evaluation
> of all points within a given radius to the first point, rather than two complete random points.
>
> This would at least cut down the test of several thousand meaningless combinations. However, I couldn't find a way to do this.
> Another option might be gDistance from the (rgeos), but with 400k points, the result seems to be not computable.
>
> I am also happy for any suggestions regarding requirements D and E, or help with the task in general.
>
> Best,
> Kimon
>
> Kimon Krenz
>
> PhD Researcher
> MSc SDAC Course Coordinator<http://www.bartlett.ucl.ac.uk/space-syntax/programmes/mres-msc/msc-spatial-design>
> Space Syntax Laboratory<http://www.bartlett.ucl.ac.uk/space-syntax>
>
> mail.       ucftkr3 at ucl.ac.uk<mailto:ucftkr3 at ucl.ac.uk>
> phone.    0044 7784 329089
> web.       www.kimonkrenz.com<http://www.kimonkrenz.com/>
>
> Bartlett School of Architecture<http://www.bartlett.ucl.ac.uk/>
> UCL
> 140 Hampstead Road
> London     NW1 2BX     UK
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From bfalevlist at gmail.com  Fri Oct  7 08:39:56 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Fri, 7 Oct 2016 08:39:56 +0200
Subject: [R-sig-Geo] Kriging with uncertain data
In-Reply-To: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
Message-ID: <dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>

Dear Santiago,

you mean you have two values at each location (observed value and 
uncertainty)? Or you have an observed value that is the sum of the real 
value and the observation error (uncertainty). If the last, then I think 
using the gstat::krige() function is straightforward, since the result 
of the function contains the variance of the prediction ("Attributes 
columns contain prediction and
prediction variance"; 
https://cran.r-project.org/web/packages/gstat/gstat.pdf).

HTH,
?kos Bede-Fazekas
Hungarian Academy of Sciences



2016.10.06. 11:52 keltez?ssel, Santiago Beguer?a ?rta:
> Dear R-sig-geo list members,
>
> I am curious about what are sensible approaches to spatial interpolation, most especially by using kriging, in the context of uncertain data.
>
> Suppose one has a dataset of values observed at different locations, and each value consists on the expected value and its variance. Variance here represents the uncertainty related to the observation, and shows spatial variation due to external factors, for instance the geological setting affecting the quality of the measurement.
>
> How would you proceed to model the spatial distribution of this variable, including propagation of the (spatially varying)?
>
> I suppose one approach could be by simulation, but at there other ways of propagating the uncertainty that do not involve potentially expensive (in computation time) simulation approaches?
>
> Cheers,
>
> Santiago Beguer?a
> CSIC
> Spain
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From santiago.begueria at csic.es  Fri Oct  7 10:27:20 2016
From: santiago.begueria at csic.es (=?utf-8?Q?Santiago_Beguer=C3=ADa?=)
Date: Fri, 7 Oct 2016 10:27:20 +0200
Subject: [R-sig-Geo] Kriging with uncertain data
In-Reply-To: <dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
Message-ID: <4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>

Dear ?kos,

I was referring to the former: I have data with two values at each location: measured value and uncertainty of the measurement. So, each observation is in fact a statistical variate, which we can assume is Gaussian distributed. Hence, my two values are the expected (mean) and the variance of the distribution.

Cheers,

Stg


> El 7 oct 2016, a las 8:39, Bede-Fazekas ?kos <bfalevlist at gmail.com> escribi?:
> 
> Dear Santiago,
> 
> you mean you have two values at each location (observed value and uncertainty)? Or you have an observed value that is the sum of the real value and the observation error (uncertainty). If the last, then I think using the gstat::krige() function is straightforward, since the result of the function contains the variance of the prediction ("Attributes columns contain prediction and
> prediction variance"; https://cran.r-project.org/web/packages/gstat/gstat.pdf).
> 
> HTH,
> ?kos Bede-Fazekas
> Hungarian Academy of Sciences
> 
> 
> 
> 2016.10.06. 11:52 keltez?ssel, Santiago Beguer?a ?rta:
>> Dear R-sig-geo list members,
>> 
>> I am curious about what are sensible approaches to spatial interpolation, most especially by using kriging, in the context of uncertain data.
>> 
>> Suppose one has a dataset of values observed at different locations, and each value consists on the expected value and its variance. Variance here represents the uncertainty related to the observation, and shows spatial variation due to external factors, for instance the geological setting affecting the quality of the measurement.
>> 
>> How would you proceed to model the spatial distribution of this variable, including propagation of the (spatially varying)?
>> 
>> I suppose one approach could be by simulation, but at there other ways of propagating the uncertainty that do not involve potentially expensive (in computation time) simulation approaches?
>> 
>> Cheers,
>> 
>> Santiago Beguer?a
>> CSIC
>> Spain
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From edzer.pebesma at uni-muenster.de  Fri Oct  7 10:37:50 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 7 Oct 2016 10:37:50 +0200
Subject: [R-sig-Geo] Kriging with uncertain data
In-Reply-To: <4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
Message-ID: <488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>

If the only problem is to krige these data, the solution is pretty
trivial; add a location specific value to the nugget; this is what
Delhomme in 1978 coined as regression kriging [1] (kriging of regressed
rather than observed values, using estimates + estimation errors).

An implementation is found in gstat, look up argument "weights" in
?gstat; you can use this argument in gstat::krige

Trickier is to infer the variogram of the underlying, unobserved
stationary variable from your estimates + estimation errors, in
particular when these estimation errors are rather large and/or vary
strongly. Anyone knows a good ref to a paper that tackles that issue?


[1] Delhomme, J. P. "Kriging in the hydrosciences." Advances in water
resources 1.5 (1978): 251-266.

On 07/10/16 10:27, Santiago Beguer?a wrote:
> Dear ?kos,
> 
> I was referring to the former: I have data with two values at each location: measured value and uncertainty of the measurement. So, each observation is in fact a statistical variate, which we can assume is Gaussian distributed. Hence, my two values are the expected (mean) and the variance of the distribution.
> 
> Cheers,
> 
> Stg
> 
> 
>> El 7 oct 2016, a las 8:39, Bede-Fazekas ?kos <bfalevlist at gmail.com> escribi?:
>>
>> Dear Santiago,
>>
>> you mean you have two values at each location (observed value and uncertainty)? Or you have an observed value that is the sum of the real value and the observation error (uncertainty). If the last, then I think using the gstat::krige() function is straightforward, since the result of the function contains the variance of the prediction ("Attributes columns contain prediction and
>> prediction variance"; https://cran.r-project.org/web/packages/gstat/gstat.pdf).
>>
>> HTH,
>> ?kos Bede-Fazekas
>> Hungarian Academy of Sciences
>>
>>
>>
>> 2016.10.06. 11:52 keltez?ssel, Santiago Beguer?a ?rta:
>>> Dear R-sig-geo list members,
>>>
>>> I am curious about what are sensible approaches to spatial interpolation, most especially by using kriging, in the context of uncertain data.
>>>
>>> Suppose one has a dataset of values observed at different locations, and each value consists on the expected value and its variance. Variance here represents the uncertainty related to the observation, and shows spatial variation due to external factors, for instance the geological setting affecting the quality of the measurement.
>>>
>>> How would you proceed to model the spatial distribution of this variable, including propagation of the (spatially varying)?
>>>
>>> I suppose one approach could be by simulation, but at there other ways of propagating the uncertainty that do not involve potentially expensive (in computation time) simulation approaches?
>>>
>>> Cheers,
>>>
>>> Santiago Beguer?a
>>> CSIC
>>> Spain
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20161007/48f43c83/attachment.bin>

From bfalevlist at gmail.com  Fri Oct  7 10:42:55 2016
From: bfalevlist at gmail.com (=?UTF-8?Q?Bede-Fazekas_=c3=81kos?=)
Date: Fri, 7 Oct 2016 10:42:55 +0200
Subject: [R-sig-Geo] Kriging with uncertain data
In-Reply-To: <4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
Message-ID: <d0c276c8-5e5a-75d1-5ae5-3aaafa24cd9d@gmail.com>

Dear Santiago,

in this case I would interpolate/krige the uncertainty as well. Since 
uncertainty might have different distribution, different covariates, and 
different spatial autocorrelation than those of the measured value, I 
would build a new kriging model (fit new semivariogram, etc.) and 
interpret the predicted values of krige() as the predicted measurement 
uncertainty. I'll have now two uncertainty maps: one is the 
interpolation uncertainty (variance from the result of the 
krige(measurement)) and the other is the interpolated measurement 
uncertainty (predicted values from the result of krige(uncertainty)). 
Afterwards, these two can be combined or can be used separately as well.

Have a nice day,
?kos

2016.10.07. 10:27 keltez?ssel, Santiago Beguer?a ?rta:
> Dear ?kos,
>
> I was referring to the former: I have data with two values at each location: measured value and uncertainty of the measurement. So, each observation is in fact a statistical variate, which we can assume is Gaussian distributed. Hence, my two values are the expected (mean) and the variance of the distribution.
>
> Cheers,
>
> Stg
>
>
>> El 7 oct 2016, a las 8:39, Bede-Fazekas ?kos <bfalevlist at gmail.com> escribi?:
>>
>> Dear Santiago,
>>
>> you mean you have two values at each location (observed value and uncertainty)? Or you have an observed value that is the sum of the real value and the observation error (uncertainty). If the last, then I think using the gstat::krige() function is straightforward, since the result of the function contains the variance of the prediction ("Attributes columns contain prediction and
>> prediction variance"; https://cran.r-project.org/web/packages/gstat/gstat.pdf).
>>
>> HTH,
>> ?kos Bede-Fazekas
>> Hungarian Academy of Sciences
>>
>>
>>
>> 2016.10.06. 11:52 keltez?ssel, Santiago Beguer?a ?rta:
>>> Dear R-sig-geo list members,
>>>
>>> I am curious about what are sensible approaches to spatial interpolation, most especially by using kriging, in the context of uncertain data.
>>>
>>> Suppose one has a dataset of values observed at different locations, and each value consists on the expected value and its variance. Variance here represents the uncertainty related to the observation, and shows spatial variation due to external factors, for instance the geological setting affecting the quality of the measurement.
>>>
>>> How would you proceed to model the spatial distribution of this variable, including propagation of the (spatially varying)?
>>>
>>> I suppose one approach could be by simulation, but at there other ways of propagating the uncertainty that do not involve potentially expensive (in computation time) simulation approaches?
>>>
>>> Cheers,
>>>
>>> Santiago Beguer?a
>>> CSIC
>>> Spain
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From fabrice.vinatier.pro at gmail.com  Mon Oct 10 10:15:26 2016
From: fabrice.vinatier.pro at gmail.com (Fabrice Vinatier)
Date: Mon, 10 Oct 2016 10:15:26 +0200
Subject: [R-sig-Geo] Get importance variables in dismo package
Message-ID: <caf4c37c-f2c2-33c3-ff17-95bd93705f60@gmail.com>

Dear list members (and especially Robert J. Hijmans),

I am actually using the excellent "dismo" package for flora species 
distribution modelling, and I am wondering if there is a way to get 
importance of variables used in maxent, domain, mahal and bioclim 
functions, to handle these importances in a table.

I tested all possible models included in 
https://cran.r-project.org/web/packages/dismo/vignettes/sdm.pdf and I 
get easily the importance of variables issued from Random Forest, GLM 
and RPART models using "$importance", "$coefficients[-1], and 
"$variable.importance", respectively, but it is more difficult to get 
the others, although there is a possible indirect access to the 
importance variable of Maxent model using plot(me) (if me is the fitted 
model).

Best regards,

Fabrice Vinatier


From dicko.ahmadou at gmail.com  Mon Oct 10 10:48:56 2016
From: dicko.ahmadou at gmail.com (Ahmadou Dicko)
Date: Mon, 10 Oct 2016 10:48:56 +0200
Subject: [R-sig-Geo] Get importance variables in dismo package
In-Reply-To: <caf4c37c-f2c2-33c3-ff17-95bd93705f60@gmail.com>
References: <caf4c37c-f2c2-33c3-ff17-95bd93705f60@gmail.com>
Message-ID: <CAP8THHWAsf=CNHhRbM_1DxUib8WH_1J5TUoTUU2vtVDw+DRQvg@mail.gmail.com>

Hi Fabrice,

If you want to access variable contribution from a MaxEnt model, you can
use still use the plot method.

var_imp <- plot(me)
var_imp

Or build you own function based on the code of the plot method

var_contrib <- function(m, df = TRUE, ...) {
  stopifnot(inherits(m,  "MaxEnt"))
  res <- m at results[grep("contribution", rownames(m at results)), ]
  names(res) <- gsub(".contribution", "", names(res))
  if (df)
    res <- data.frame(var = names(res), contrib = unname(res))
  res
}

var_contrib(me)

Hope it helps





On Mon, Oct 10, 2016 at 10:15 AM, Fabrice Vinatier <
fabrice.vinatier.pro at gmail.com> wrote:

> Dear list members (and especially Robert J. Hijmans),
>
> I am actually using the excellent "dismo" package for flora species
> distribution modelling, and I am wondering if there is a way to get
> importance of variables used in maxent, domain, mahal and bioclim
> functions, to handle these importances in a table.
>
> I tested all possible models included in https://cran.r-project.org/web
> /packages/dismo/vignettes/sdm.pdf and I get easily the importance of
> variables issued from Random Forest, GLM and RPART models using
> "$importance", "$coefficients[-1], and "$variable.importance",
> respectively, but it is more difficult to get the others, although there is
> a possible indirect access to the importance variable of Maxent model using
> plot(me) (if me is the fitted model).
>
> Best regards,
>
> Fabrice Vinatier
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Ahmadou H. DICKO, PhD
Data hacker and climate change economist
Post-doctoral researcher
CIRAD - UMR15 CIRAD/INRA Control of exotic and emerging diseases
email : ahmadou-hamady.dicko at cirad.fr <ahmadou.dicko at ucad.edu.sn>
twitter : @dickoah
github : github/dickoa <https://github.com/dickoa>
portable: +33 7 68 16 11 58

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Mon Oct 10 14:15:42 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 10 Oct 2016 08:15:42 -0400
Subject: [R-sig-Geo] Get importance variables in dismo package
In-Reply-To: <CAP8THHWAsf=CNHhRbM_1DxUib8WH_1J5TUoTUU2vtVDw+DRQvg@mail.gmail.com>
References: <caf4c37c-f2c2-33c3-ff17-95bd93705f60@gmail.com>
	<CAP8THHWAsf=CNHhRbM_1DxUib8WH_1J5TUoTUU2vtVDw+DRQvg@mail.gmail.com>
Message-ID: <701EA2D6-94D2-4216-A8ED-C8C8D79D06ED@bigelow.org>

Hi,

Along a similar vein, I have been assembling into a package some basic helper tools for working with dismo and in particular MaxEnt.  

https://github.com/BigelowLab/dismotools

> library(devtools)
> install_github("BigelowLab/dismotools")
> library(dismotools)
> maxent_get_results(me, "importance")
> maxent_get_results(me, "contribution")

Ben



> On Oct 10, 2016, at 4:48 AM, Ahmadou Dicko <dicko.ahmadou at gmail.com> wrote:
> 
> Hi Fabrice,
> 
> If you want to access variable contribution from a MaxEnt model, you can
> use still use the plot method.
> 
> var_imp <- plot(me)
> var_imp
> 
> Or build you own function based on the code of the plot method
> 
> var_contrib <- function(m, df = TRUE, ...) {
>  stopifnot(inherits(m,  "MaxEnt"))
>  res <- m at results[grep("contribution", rownames(m at results)), ]
>  names(res) <- gsub(".contribution", "", names(res))
>  if (df)
>    res <- data.frame(var = names(res), contrib = unname(res))
>  res
> }
> 
> var_contrib(me)
> 
> Hope it helps
> 
> 
> 
> 
> 
> On Mon, Oct 10, 2016 at 10:15 AM, Fabrice Vinatier <
> fabrice.vinatier.pro at gmail.com> wrote:
> 
>> Dear list members (and especially Robert J. Hijmans),
>> 
>> I am actually using the excellent "dismo" package for flora species
>> distribution modelling, and I am wondering if there is a way to get
>> importance of variables used in maxent, domain, mahal and bioclim
>> functions, to handle these importances in a table.
>> 
>> I tested all possible models included in https://cran.r-project.org/web
>> /packages/dismo/vignettes/sdm.pdf and I get easily the importance of
>> variables issued from Random Forest, GLM and RPART models using
>> "$importance", "$coefficients[-1], and "$variable.importance",
>> respectively, but it is more difficult to get the others, although there is
>> a possible indirect access to the importance variable of Maxent model using
>> plot(me) (if me is the fitted model).
>> 
>> Best regards,
>> 
>> Fabrice Vinatier
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> 
> 
> -- 
> Ahmadou H. DICKO, PhD
> Data hacker and climate change economist
> Post-doctoral researcher
> CIRAD - UMR15 CIRAD/INRA Control of exotic and emerging diseases
> email : ahmadou-hamady.dicko at cirad.fr <ahmadou.dicko at ucad.edu.sn>
> twitter : @dickoah
> github : github/dickoa <https://github.com/dickoa>
> portable: +33 7 68 16 11 58
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From tim.appelhans at gmail.com  Mon Oct 10 14:18:38 2016
From: tim.appelhans at gmail.com (Tim Appelhans)
Date: Mon, 10 Oct 2016 14:18:38 +0200
Subject: [R-sig-Geo] Get importance variables in dismo package
In-Reply-To: <701EA2D6-94D2-4216-A8ED-C8C8D79D06ED@bigelow.org>
References: <caf4c37c-f2c2-33c3-ff17-95bd93705f60@gmail.com>
	<CAP8THHWAsf=CNHhRbM_1DxUib8WH_1J5TUoTUU2vtVDw+DRQvg@mail.gmail.com>
	<701EA2D6-94D2-4216-A8ED-C8C8D79D06ED@bigelow.org>
Message-ID: <57FB871E.3030407@gmail.com>

There's also this:

https://cran.r-project.org/web/packages/MaxentVariableSelection/index.html

On 10.10.2016 14:15, Ben Tupper wrote:
> Hi,
>
> Along a similar vein, I have been assembling into a package some basic helper tools for working with dismo and in particular MaxEnt.
>
> https://github.com/BigelowLab/dismotools
>
>> library(devtools)
>> install_github("BigelowLab/dismotools")
>> library(dismotools)
>> maxent_get_results(me, "importance")
>> maxent_get_results(me, "contribution")
> Ben
>
>
>
>> On Oct 10, 2016, at 4:48 AM, Ahmadou Dicko <dicko.ahmadou at gmail.com> wrote:
>>
>> Hi Fabrice,
>>
>> If you want to access variable contribution from a MaxEnt model, you can
>> use still use the plot method.
>>
>> var_imp <- plot(me)
>> var_imp
>>
>> Or build you own function based on the code of the plot method
>>
>> var_contrib <- function(m, df = TRUE, ...) {
>>   stopifnot(inherits(m,  "MaxEnt"))
>>   res <- m at results[grep("contribution", rownames(m at results)), ]
>>   names(res) <- gsub(".contribution", "", names(res))
>>   if (df)
>>     res <- data.frame(var = names(res), contrib = unname(res))
>>   res
>> }
>>
>> var_contrib(me)
>>
>> Hope it helps
>>
>>
>>
>>
>>
>> On Mon, Oct 10, 2016 at 10:15 AM, Fabrice Vinatier <
>> fabrice.vinatier.pro at gmail.com> wrote:
>>
>>> Dear list members (and especially Robert J. Hijmans),
>>>
>>> I am actually using the excellent "dismo" package for flora species
>>> distribution modelling, and I am wondering if there is a way to get
>>> importance of variables used in maxent, domain, mahal and bioclim
>>> functions, to handle these importances in a table.
>>>
>>> I tested all possible models included in https://cran.r-project.org/web
>>> /packages/dismo/vignettes/sdm.pdf and I get easily the importance of
>>> variables issued from Random Forest, GLM and RPART models using
>>> "$importance", "$coefficients[-1], and "$variable.importance",
>>> respectively, but it is more difficult to get the others, although there is
>>> a possible indirect access to the importance variable of Maxent model using
>>> plot(me) (if me is the fitted model).
>>>
>>> Best regards,
>>>
>>> Fabrice Vinatier
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>> -- 
>> Ahmadou H. DICKO, PhD
>> Data hacker and climate change economist
>> Post-doctoral researcher
>> CIRAD - UMR15 CIRAD/INRA Control of exotic and emerging diseases
>> email : ahmadou-hamady.dicko at cirad.fr <ahmadou.dicko at ucad.edu.sn>
>> twitter : @dickoah
>> github : github/dickoa <https://github.com/dickoa>
>> portable: +33 7 68 16 11 58
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
#####################################
Tim Appelhans
Department of Geography
Environmental Informatics
Philipps Universit?t Marburg
Deutschhausstra?e 12
Raum 00A08
35032 Marburg (Paketpost: 35037 Marburg)
Germany

Tel +49 (0) 6421 28-25957

http://environmentalinformatics-marburg.de/


From santiago.begueria at csic.es  Tue Oct 11 12:34:58 2016
From: santiago.begueria at csic.es (=?utf-8?Q?Santiago_Beguer=C3=ADa_Portugu=C3=A9s?=)
Date: Tue, 11 Oct 2016 12:34:58 +0200
Subject: [R-sig-Geo] Kriging with uncertain data
In-Reply-To: <488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
Message-ID: <7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>

Hi,

Thank you for your suggestions. I gave the gstat with weights argument a try, but I?m not sure about the results / my implementation.

I have worked out an example with the meuse dataset so I can share it with you:

library(gstat)
library(sp)

data(meuse)
coordinates(meuse) <- ~x+y

data(meuse.grid)
gridded(meuse.grid) = ~x+y

For a starting, let?s fit a standard universal kriging model:

# model 1: UK

v <- variogram(log(zinc)~sqrt(dist)+x+y, meuse)
var1 <- fit.variogram(v, vgm(1, "Sph", 700, 1))

m1 <- gstat(formula=log(zinc)~sqrt(dist), data=meuse, id='log_zinc',
            model=var1)
predm1 <- predict(m1, meuse.grid)

summary(predm1 at data)

Let?s now simulate some measurement variances. I will assume the standard error to be uniformly distributed, with values between 0.2 and 0.4 times the measured values: 

meuse$var <- (meuse$zinc*runif(155,0.1,0.2))^2

plot(meuse$var~meuse$zinc)
plot(log(meuse$var)~log(meuse$zinc))

Let?s now fit a weighted UK model, using measurement precisions (= 1/variance) as weights:

# model 2: weighted UK

m2 <- update(m1, weights=1/log(meuse$var))
predm2 <- predict(m2, meuse.grid)

If we compare the results of both models, we shall see that the variability of the predictions has shrinked a bit in model 2, while the kriging variances have increased:

summary(predm1 at data)
summary(predm2 at data)

The spatial distribution of the variances has also changed, reflecting the spatial distribution of the measurement variances.

All good so far: the uncertainty of the measurements has influenced the kriging model, and now we obtain slightly less certain krigged values. But this does not answer my question, since we have not propagated the measurement uncertainty to the estimated field. You can see this by comparing the magnitudes of model 2 kriging variances to the measurement variances:

summary(log(meuse$var))
summary(predm2 at data$log_zinc.var)

?kos? suggestion, i.e. to krige the measured values and their variances separately, is a good suggestion. We can still use the weights argument to krige the observations, and we shall get separated measurement and kriging variances, which is nice. If we suspect that there is a relation between the measured values and their errors (as it is the case in my simulated example), we could even use the trigged surface of the measurement as a coverable; I suppose. 

What do you think about that approached? Does it make sense, is it statistically correct regarding the kriging assumptions?

Also, I am a bit worried about the semivariogram model fitted, since there is no way that I have found to incorporate the error variances of the measurements. There is an Err argument to the vim function in gstat, but as I understand it a single error variance for the whole spatial field is expected, i.e. it does not work with spatially varying errors.

Cheers,

Santiago



> El 7 oct 2016, a las 10:37, Edzer Pebesma <edzer.pebesma at uni-muenster.de> escribi?:
> 
> If the only problem is to krige these data, the solution is pretty
> trivial; add a location specific value to the nugget; this is what
> Delhomme in 1978 coined as regression kriging [1] (kriging of regressed
> rather than observed values, using estimates + estimation errors).
> 
> An implementation is found in gstat, look up argument "weights" in
> ?gstat; you can use this argument in gstat::krige
> 
> Trickier is to infer the variogram of the underlying, unobserved
> stationary variable from your estimates + estimation errors, in
> particular when these estimation errors are rather large and/or vary
> strongly. Anyone knows a good ref to a paper that tackles that issue?
> 
> 
> [1] Delhomme, J. P. "Kriging in the hydrosciences." Advances in water
> resources 1.5 (1978): 251-266.
> 
> On 07/10/16 10:27, Santiago Beguer?a wrote:
>> Dear ?kos,
>> 
>> I was referring to the former: I have data with two values at each location: measured value and uncertainty of the measurement. So, each observation is in fact a statistical variate, which we can assume is Gaussian distributed. Hence, my two values are the expected (mean) and the variance of the distribution.
>> 
>> Cheers,
>> 
>> Stg
>> 
>> 
>>> El 7 oct 2016, a las 8:39, Bede-Fazekas ?kos <bfalevlist at gmail.com> escribi?:
>>> 
>>> Dear Santiago,
>>> 
>>> you mean you have two values at each location (observed value and uncertainty)? Or you have an observed value that is the sum of the real value and the observation error (uncertainty). If the last, then I think using the gstat::krige() function is straightforward, since the result of the function contains the variance of the prediction ("Attributes columns contain prediction and
>>> prediction variance"; https://cran.r-project.org/web/packages/gstat/gstat.pdf).
>>> 
>>> HTH,
>>> ?kos Bede-Fazekas
>>> Hungarian Academy of Sciences
>>> 
>>> 
>>> 
>>> 2016.10.06. 11:52 keltez?ssel, Santiago Beguer?a ?rta:
>>>> Dear R-sig-geo list members,
>>>> 
>>>> I am curious about what are sensible approaches to spatial interpolation, most especially by using kriging, in the context of uncertain data.
>>>> 
>>>> Suppose one has a dataset of values observed at different locations, and each value consists on the expected value and its variance. Variance here represents the uncertainty related to the observation, and shows spatial variation due to external factors, for instance the geological setting affecting the quality of the measurement.
>>>> 
>>>> How would you proceed to model the spatial distribution of this variable, including propagation of the (spatially varying)?
>>>> 
>>>> I suppose one approach could be by simulation, but at there other ways of propagating the uncertainty that do not involve potentially expensive (in computation time) simulation approaches?
>>>> 
>>>> Cheers,
>>>> 
>>>> Santiago Beguer?a
>>>> CSIC
>>>> Spain
>>>> 
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
> 
> -- 
> Edzer Pebesma
> Institute for Geoinformatics  (ifgi),  University of M?nster
> Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
> Journal of Statistical Software:   http://www.jstatsoft.org/
> Computers & Geosciences:   http://elsevier.com/locate/cageo/
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


	[[alternative HTML version deleted]]


From mercetadzio at gmail.com  Tue Oct 11 13:37:35 2016
From: mercetadzio at gmail.com (=?UTF-8?Q?Mercedes_Rom=C3=A1n?=)
Date: Tue, 11 Oct 2016 13:37:35 +0200
Subject: [R-sig-Geo] Generating uncertainty maps with Monte-Carlo simulation
	and large rasters
Message-ID: <CAAOWriPGYHURB36EFiUSP43qBgOC=L7jAELdgZE7bihAJ3eOTw@mail.gmail.com>

Dear list members,



I am trying to generate uncertainty maps of available water capacity
predicted with a pedotransfer function via Monte-Carlo simulation. I have
the raster layers with the mean and SD of the input variables, so I can
sample from their distributions (I ignore the correlations among variables,
and consider their distributions as univariate in this exercise). All I
want is to apply Monte-Carlo simulation for each cell of the raster. I
found very useful some of the previous postings on this subject with the
mc2d package (
http://r-sig-geo.2731867.n2.nabble.com/parallel-raster-processing-with-calc-and-mc2d-monte-carlo-simulation-td7587901.html#a7587902).
Finally, I found that it was quicker to use the package lhs, generate a
latin hypercube sample from a uniform distribution, and then obtain the
sample for each of my variables with qnorm. I give an example of my
function bellow. The PTF is a bit long; you can ignore most of it and just
look at the beginning, where I sample from the distributions, and at the
end (the output layers with the prediction interval limits).



Applied to a small raster it is pretty quick. The problem is that I have to
apply the function to 300 raster stacks of 2805374 cells each, and that is
going to take a long time even with parallel computing using clusterR (a
couple of weeks with a computer like mine).



I imagine some of you have dealt with similar problems. Do you have any
advice for sampling from probability distributions in monte-carlo
simulations from big raster files? Or any advice for generating uncertainty
maps?



I believe much of the time is due to accessing the data (getValues). So I
tried to do an alternative function, by extracting the data of the raster
stack first into a dataframe, but that did not seem to save time either.



Thank you in advance for all your help.



Kind regards,



Mercedes Roman







require(raster)

require(sp)

require(rgdal)

library(lhs)

library(parallel)

library(doParallel)

library(snow)





### Generate example rasters

r <- raster(nrow=10, ncol=10)

set.seed(23850)



s1 <- setValues(r,runif(n = 100, min = 0, max=1000))

s2 <- setValues(r,runif(n = 100, min = 0, max=100))

s3 <- setValues(r,runif(n = 100, min = 0, max=1000))

s4 <- setValues(r,runif(n = 100, min = 0, max=20))

s5 <- setValues(r,runif(n = 100, min = 0, max=300))

s6 <- setValues(r,runif(n = 100, min = 0, max=20))

s7 <- setValues(r,runif(n = 100, min = 0, max=200))

s8 <- setValues(r,runif(n = 100, min = 0, max=20))

s9 <- setValues(r,runif(n = 100, min = 0, max=14))

s10 <- setValues(r,runif(n = 100, min = 0, max=1))



s<-stack(s1, s2,s3,s4,s5,s6,s7,s8,s9,s10)

plot(s)



# Write the PTF function, sample with package lhs

func_lhs <- function(x){



    ###How many simulations we want?

    simulations <- 1000

    sLHS <-randomLHS(n=simulations,k=5) ### Draws a Latin Hypercube Sample
from a set of uniform distribution



    ### Transform the values into normal distribution with the mean and sd
of each variable

    ### sand

    sim_sand <- qnorm(sLHS[,1], mean = x[[1]], sd = x[[2]])

    ### constrained to be between 0 and 1000

    sim_sand <- ifelse(sim_sand<0, 0, ifelse(sim_sand>1000, 1000, sim_sand))

    ### silt

    sim_silt <- qnorm(sLHS[,2], mean = x[[3]], sd = x[[4]])

    ### constrained to be between 0 and 1000

    sim_silt <- ifelse(sim_silt<0, 0, ifelse(sim_silt>1000, 1000, sim_silt))

    ### SOC

    sim_soc <- qnorm(sLHS[,3], mean = x[[5]], sd = x[[6]])

    ### constrained to be between 0 and 1000

    sim_soc <- ifelse(sim_soc<0, 0, ifelse(sim_soc>1000, 1000, sim_soc))

    ### CEC

    sim_cec <- qnorm(sLHS[,4], mean = x[[7]], sd = x[[8]])

    ### constrained to be > 0

    sim_cec <- ifelse(sim_cec<0, 0, sim_cec)

    ### pH

    sim_ph <- qnorm(sLHS[,5], mean = x[[9]], sd = x[[10]])

    ### constrained to be betweeen 0 and 14

    sim_ph <- ifelse(sim_ph<0, 0, ifelse(sim_ph>14, 14, sim_ph))



    ### Apply the PTF

    ### Define the functions



    ### Because from the simulations we cannot guarantee that the sum of
texture fractions is 1000, we calculate clay as the difference 1000 - (sand
+ silt)

    sim_clay <- 1000 - (sim_sand + sim_silt)

    ### What if silt and sand sum > 1000?

    sim_clay <- ifelse(sim_clay <0, 0, sim_clay)



    ### To calculate the first parameter, SMres, the residual water content
(cm? cm-3), we need sand content, as %

    ### GSM has sand as g/kg - So the 2% by Toth et al is 20 g/kg here

    SMres <- ifelse(is.na(sim_sand), NA, ifelse(sim_sand >= 20, 0.041,
0.179))



    ### Now for SMs, the saturated water content (cm? cm-3)

    ### SMs = 0.5056 - 0.1437 * (1/(OC+1)) + 0.0004152 * Si

    SMsat <- 0.5056 - (0.1437 * (1/((0.1* sim_soc)+1))) + (0.0004152 *
sim_silt * 0.1)



    #### the parameter alpha

    #### log10(alpha) = -1.3050 - 0.0006123 * Si - 0.009810 * Cl + 0.07611
* (1/(OC+1)) - 0.0004508 * Si * Cl + 0.03472 * Cl * (1/(OC+1)) - 0.01226 *
Si * (1/(OC+1))

    logAlpha <- -1.3050 - (0.0006123 * sim_silt * 0.1) - (0.009810 *
sim_clay * 0.1) + (0.07611 * (1/((0.1*sim_soc)+1))) - (0.0004508 * sim_silt
* sim_clay *0.01) + (0.03472 * sim_clay * 0.1 * (1/((sim_soc*0.1)+1))) -
(0.01226 * sim_silt * 0.1 * (1/((sim_soc*0.1)+1)))

    alpha <-  10^logAlpha



    ### the parameter n

    ### log10(n-1) = 0.01516 - 0.005775 * (1/(OC+1)) - 0.24885 * log10(CEC)
- 0.01918 * Cl - 0.0005052 * Si - 0.007544 * pH2

    ### - 0.02159 * Cl * (1/(OC+1)) + 0.01556 * Cl * log10(CEC) + 0.01477 *
(1/(OC+1)) * pH2 + 0.0001121 * Si * Cl - 0.33198 * (1/(OC+1)) * log10(CEC)

    logN_1 <- 0.01516 - (0.005775 * (1/((sim_soc * 0.1)+1))) - (0.24885 *
log10(sim_cec)) - (0.01918 * sim_clay * 0.1) - (0.0005052 * sim_silt * 0.1)
- (0.007544 * (sim_ph^2)) - (0.02159 * 0.1 * sim_clay * (1/((0.1 *
sim_soc)+1))) + (0.01556 * 0.1 * sim_clay * log10(sim_cec)) + (0.01477 *
(1/((0.1 * sim_soc)+1)) * (sim_ph^2)) + (0.0001121 * 0.01 * sim_silt *
sim_clay) - (0.33198 * (1/((0.1*sim_soc)+1)) * log10(sim_cec))

    n <- (10^logN_1)+1



    ### define the soil matric potential (cm of water column)

    #h <- 101.9716       ### soil matric potential in cm of water column
----- 10 kPa equivalent to 101.9716 cmH2O



    ### We fit the Mualem-van Genuchten equation for theta at field capacity

    smFC <- SMres +((SMsat-SMres)/((1+((alpha*101.9716)^n))^(1-(1/n))))

    smFC <- ifelse(smFC < 0, 0, smFC)



    ##### Soil moisture at permanent wilting point

    ##### thWP =  0.09878 + 0.002127* Cl - 0.0008366 * Si - 0.07670
*(1/(OC+1)) + 0.00003853 * Si * Cl + 0.002330 * Cl * (1/(OC+1)) + 0.0009498
* Si * (1/(OC+1))

    smWP <- 0.09878 + (0.002127*sim_clay*0.1) - (0.0008366*sim_silt*0.1) -
(0.07670 *(1/((sim_soc*0.1)+1))) + (0.00003853 * sim_silt*sim_clay*0.01) +
(0.002330 * sim_clay*0.1 * (1/((sim_soc*0.1)+1))) + (0.0009498 *
sim_silt*0.1 * (1/((sim_soc*0.1)+1)))

    smWP <- ifelse(smWP < 0, 0, smWP)



    ### Calculate the AWC as difference of both

    AWC <- smFC - smWP

    ### what if smWP > smFC?

    AWC <- ifelse(AWC<0,0,AWC)



    ### Calculate the PI

    AWC_lower <-quantile(AWC, probs =.05, na.rm=TRUE)

    AWC_upper <-quantile(AWC, probs =.95, na.rm=TRUE)



    smFC_lower <-quantile(smFC, probs =.05, na.rm=TRUE)

    smFC_upper <-quantile(smFC, probs =.95, na.rm=TRUE)



    smWP_lower <-quantile(smWP, probs =.05, na.rm=TRUE)

    smWP_upper <-quantile(smWP, probs =.95, na.rm=TRUE)



    all_results <- c(AWC_lower, AWC_upper, smFC_lower, smFC_upper,
smWP_lower, smWP_upper )  ### Returns a nlayers raster stack. Ordered as
smFC, smWP, and AWC



    return(all_results)

}





### Apply function with clusterR

ff <- function(x) calc(x, func_lhs)



beginCluster(n = 8, type='SOCK')

little_test <- clusterR(s, ff, export='func_lhs')

endCluster()

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Thu Oct 13 20:03:25 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Thu, 13 Oct 2016 18:03:25 +0000
Subject: [R-sig-Geo] uniformly sample points on a border of a polygon
In-Reply-To: <7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>,
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
Message-ID: <HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>

HI folks,

I write for a (hopefully) relatively simple question:

I would need to uniformly sample 1000 or more points **along the border** of a polygon (not within the area enclosed) that is identified by ordered but not equally spaced points; which is the fastest way?

In a first moment I thought to sample between any pair of consecutive points but, given that starting points are not uniformly distributed, the final result would be very far from a uniform distribution.

here my polygon:


  mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449, 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498, 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734, 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776, -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543, -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439, -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818, 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131, 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
  plot(mypol,asp=1,cex=0)
  text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
Thanks in advance for any hints
all the best
paolo






	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Oct 13 23:12:13 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 14 Oct 2016 10:12:13 +1300
Subject: [R-sig-Geo] [FORGED] uniformly sample points on a border of a
 polygon
In-Reply-To: <HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
Message-ID: <166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>

On 14/10/16 07:03, Paolo Piras wrote:
> HI folks,
>
> I write for a (hopefully) relatively simple question:
>
> I would need to uniformly sample 1000 or more points **along the border** of a polygon (not within the area enclosed) that is identified by ordered but not equally spaced points; which is the fastest way?
>
> In a first moment I thought to sample between any pair of consecutive points but, given that starting points are not uniformly distributed, the final result would be very far from a uniform distribution.
>
> here my polygon:
>
>
>   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449, 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498, 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734, 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776, -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543, -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439, -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818, 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131, 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
>   plot(mypol,asp=1,cex=0)
>   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> Thanks in advance for any hints


This can be done reasonably easily using the spatstat package, for some 
value of the word "reasonably".  Here's how:

require(spatstat)
W <- owin(poly=mypol)
m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
m <- as.data.frame(m)
names(m) <- c("x0","y0","x1","y1")
L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
set.seed(42)
#X <- runifpointOnLines(1000,L)
X <- runifpointOnLines(100,L)
plot(W,main="Piras's Polygon")
plot(X,add=TRUE)

Note that I have just generated 100 uniform points, r.t. 1000, so that 
the resulting plot is a little less cluttered.

There may be a sexier way of accomplishing your desideratum; I have 
cc-ed this email to my co-authors Adrian and Ege who may come up with 
better ideas.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wsavran at gmail.com  Thu Oct 13 23:16:31 2016
From: wsavran at gmail.com (William Savran)
Date: Thu, 13 Oct 2016 21:16:31 +0000
Subject: [R-sig-Geo] optimizing SGSim for large data sets
Message-ID: <CADMaJ=OuMMLEKgRP9_gksY--fao0PJEHSjyMN+vmPS+3+6v30Q@mail.gmail.com>

Hi R-Sig-Geo,

I am working on a project related to deterministic probabilistic seismic
hazard analysis (PSHA).  I know this sounds quite like an oxymoron, but the
idea is to use deterministic simulations of seismic wave propagation (due
to a dearth of data at large magnitudes) to help make statistical
inferences about seismic hazard in a particular area.

This project involves simulating several dozen up to several thousand large
grids (< 1 million degrees of freedom) using SGSim that represent an
earthquake source.  Right now, I am using the R gstat package for the
simulation and it works great for a 'prototype' of the model, but I believe
the performance is too slow for a 'production' version of the model where
the simulation of several thousand grids becomes a reality.

Does anyone have any benchmarking data comparing the SGSim implementation
in R to an implementation in pure C or Fortran? Or a C or Fortran code that
performs the simulation for me to run and share the benchmarking results?

Cheers,
Bill

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Thu Oct 13 23:22:58 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Thu, 13 Oct 2016 21:22:58 +0000
Subject: [R-sig-Geo] [FORGED] uniformly sample points on a border of a
 polygon
In-Reply-To: <166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>,
	<166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>
Message-ID: <HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>

Thanks a lot Rolf!

This is virtually exactly what I need;

I'm very grateful for that

All the best

Paolo


________________________________
Da: Rolf Turner <r.turner at auckland.ac.nz>
Inviato: gioved? 13 ottobre 2016 23.12
A: Paolo Piras
Cc: r-sig-geo; Adrian.Baddeley at curtin.edu.au; Ege Rubak
Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon

On 14/10/16 07:03, Paolo Piras wrote:
> HI folks,
>
> I write for a (hopefully) relatively simple question:
>
> I would need to uniformly sample 1000 or more points **along the border** of a polygon (not within the area enclosed) that is identified by ordered but not equally spaced points; which is the fastest way?
>
> In a first moment I thought to sample between any pair of consecutive points but, given that starting points are not uniformly distributed, the final result would be very far from a uniform distribution.
>
> here my polygon:
>
>
>   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449, 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498, 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734, 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776, -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543, -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439, -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818, 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131, 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
>   plot(mypol,asp=1,cex=0)
>   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> Thanks in advance for any hints


This can be done reasonably easily using the spatstat package, for some
value of the word "reasonably".  Here's how:

require(spatstat)
W <- owin(poly=mypol)
m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
m <- as.data.frame(m)
names(m) <- c("x0","y0","x1","y1")
L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
set.seed(42)
#X <- runifpointOnLines(1000,L)
X <- runifpointOnLines(100,L)
plot(W,main="Piras's Polygon")
plot(X,add=TRUE)

Note that I have just generated 100 uniform points, r.t. 1000, so that
the resulting plot is a little less cluttered.

There may be a sexier way of accomplishing your desideratum; I have
cc-ed this email to my co-authors Adrian and Ege who may come up with
better ideas.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From adrian.baddeley at curtin.edu.au  Fri Oct 14 02:14:02 2016
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Fri, 14 Oct 2016 00:14:02 +0000
Subject: [R-sig-Geo] [FORGED] uniformly sample points on a border of a
 polygon
In-Reply-To: <HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>,
	<166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>,
	<HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
Message-ID: <SG2PR02MB137374175954B7E432BD4BFFA4DF0@SG2PR02MB1373.apcprd02.prod.outlook.com>

You can use the spatstat function 'edges' to extract the edges of a polygonal window.


Example:

            W <- letterR    #polygonal window

            E <- edges(W)

            X <- runifpointOnLines(20, E)

            plot(E)

            plot(X, add=TRUE)



Prof Adrian Baddeley DSc FAA

Department of Mathematics and Statistics

Curtin University, Perth, Western Australia


________________________________
From: Paolo Piras <paolo.piras at uniroma3.it>
Sent: Friday, 14 October 2016 5:22 AM
To: Rolf Turner
Cc: r-sig-geo; Adrian Baddeley; Ege Rubak
Subject: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon


Thanks a lot Rolf!

This is virtually exactly what I need;

I'm very grateful for that

All the best

Paolo


________________________________
Da: Rolf Turner <r.turner at auckland.ac.nz>
Inviato: gioved? 13 ottobre 2016 23.12
A: Paolo Piras
Cc: r-sig-geo; Adrian.Baddeley at curtin.edu.au; Ege Rubak
Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon

On 14/10/16 07:03, Paolo Piras wrote:
> HI folks,
>
> I write for a (hopefully) relatively simple question:
>
> I would need to uniformly sample 1000 or more points **along the border** of a polygon (not within the area enclosed) that is identified by ordered but not equally spaced points; which is the fastest way?
>
> In a first moment I thought to sample between any pair of consecutive points but, given that starting points are not uniformly distributed, the final result would be very far from a uniform distribution.
>
> here my polygon:
>
>
>   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449, 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498, 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734, 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776, -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543, -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439, -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818, 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131, 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
>   plot(mypol,asp=1,cex=0)
>   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> Thanks in advance for any hints


This can be done reasonably easily using the spatstat package, for some
value of the word "reasonably".  Here's how:

require(spatstat)
W <- owin(poly=mypol)
m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
m <- as.data.frame(m)
names(m) <- c("x0","y0","x1","y1")
L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
set.seed(42)
#X <- runifpointOnLines(1000,L)
X <- runifpointOnLines(100,L)
plot(W,main="Piras's Polygon")
plot(X,add=TRUE)

Note that I have just generated 100 uniform points, r.t. 1000, so that
the resulting plot is a little less cluttered.

There may be a sexier way of accomplishing your desideratum; I have
cc-ed this email to my co-authors Adrian and Ege who may come up with
better ideas.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Fri Oct 14 10:23:32 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Fri, 14 Oct 2016 08:23:32 +0000
Subject: [R-sig-Geo] [FORGED] uniformly sample points on a border of a
 polygon
In-Reply-To: <SG2PR02MB137374175954B7E432BD4BFFA4DF0@SG2PR02MB1373.apcprd02.prod.outlook.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>,
	<166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>,
	<HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>,
	<SG2PR02MB137374175954B7E432BD4BFFA4DF0@SG2PR02MB1373.apcprd02.prod.outlook.com>
Message-ID: <HE1PR04MB1161AF0D51F7A50015388856B3DF0@HE1PR04MB1161.eurprd04.prod.outlook.com>

Dear Adrian,

even this solution is pretty cool.

Again, thanks to all who suggested me how to do that.

Best

Paolo


________________________________
Da: Adrian Baddeley <adrian.baddeley at curtin.edu.au>
Inviato: venerd? 14 ottobre 2016 02.14
A: Paolo Piras; Rolf Turner
Cc: r-sig-geo; Ege Rubak
Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon


You can use the spatstat function 'edges' to extract the edges of a polygonal window.


Example:

            W <- letterR    #polygonal window

            E <- edges(W)

            X <- runifpointOnLines(20, E)

            plot(E)

            plot(X, add=TRUE)



Prof Adrian Baddeley DSc FAA

Department of Mathematics and Statistics

Curtin University, Perth, Western Australia


________________________________
From: Paolo Piras <paolo.piras at uniroma3.it>
Sent: Friday, 14 October 2016 5:22 AM
To: Rolf Turner
Cc: r-sig-geo; Adrian Baddeley; Ege Rubak
Subject: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon


Thanks a lot Rolf!

This is virtually exactly what I need;

I'm very grateful for that

All the best

Paolo


________________________________
Da: Rolf Turner <r.turner at auckland.ac.nz>
Inviato: gioved? 13 ottobre 2016 23.12
A: Paolo Piras
Cc: r-sig-geo; Adrian.Baddeley at curtin.edu.au; Ege Rubak
Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon

On 14/10/16 07:03, Paolo Piras wrote:
> HI folks,
>
> I write for a (hopefully) relatively simple question:
>
> I would need to uniformly sample 1000 or more points **along the border** of a polygon (not within the area enclosed) that is identified by ordered but not equally spaced points; which is the fastest way?
>
> In a first moment I thought to sample between any pair of consecutive points but, given that starting points are not uniformly distributed, the final result would be very far from a uniform distribution.
>
> here my polygon:
>
>
>   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449, 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498, 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734, 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776, -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543, -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439, -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818, 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131, 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
>   plot(mypol,asp=1,cex=0)
>   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> Thanks in advance for any hints


This can be done reasonably easily using the spatstat package, for some
value of the word "reasonably".  Here's how:

require(spatstat)
W <- owin(poly=mypol)
m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
m <- as.data.frame(m)
names(m) <- c("x0","y0","x1","y1")
L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
set.seed(42)
#X <- runifpointOnLines(1000,L)
X <- runifpointOnLines(100,L)
plot(W,main="Piras's Polygon")
plot(X,add=TRUE)

Note that I have just generated 100 uniform points, r.t. 1000, so that
the resulting plot is a little less cluttered.

There may be a sexier way of accomplishing your desideratum; I have
cc-ed this email to my co-authors Adrian and Ege who may come up with
better ideas.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

	[[alternative HTML version deleted]]


From maaggi at yahoo.com  Fri Oct 14 13:55:25 2016
From: maaggi at yahoo.com (Mandakh Nyamtseren 2)
Date: Fri, 14 Oct 2016 11:55:25 +0000 (UTC)
Subject: [R-sig-Geo] Can't run mk.test for raster stack
References: <2118838418.190407.1476446125835.ref@mail.yahoo.com>
Message-ID: <2118838418.190407.1476446125835@mail.yahoo.com>

Dear all,I'm trying to use MannKendall test to get trend of 10 year aridity data. Can some one help me to correct this code. 
>library(raster)
>library(trend)
>setwd("D:/ClimateData/MK_aridity")
>list <- list.files(pattern = "*.asc")
>RasterStack <- Stack(list)
>test <- calc(r, fun=function(x) {return(unlist(mk.test(x)))}, na.rm)
When I run I receive messege : 
Error in .calcTest(x[1:5], fun, na.rm, forcefun, forceapply) : 
  cannot use this function
In addition: Warning messages:
1: In .HTMLsearch(query) : Unrecognized search field: title
2: In .HTMLsearch(query) : Unrecognized search field: keyword
3: In .HTMLsearch(query) : Unrecognized search field: alias


The raster has a portion of pixels with NA values. 
Thank you in advance for your help. 

Sincerely, 

Ms. N.Mandakh
Division for Desertification Study
Institute of Geography and Geoecology Mongolian Academy of Sciences

Baruun Selbe-15
Ulaanbatar - 15170
Mongolia

Fax: 976-11-321862
Cellular: 976-99148380
E-mail: maaggi at yahoo.com, n.mandakh at gmail.com
	[[alternative HTML version deleted]]


From mgm917391 at gmail.com  Fri Oct 14 23:12:16 2016
From: mgm917391 at gmail.com (mgm mgm)
Date: Fri, 14 Oct 2016 17:12:16 -0400
Subject: [R-sig-Geo] uniformly sample points on a border of a polygon
In-Reply-To: <HE1PR04MB1161AF0D51F7A50015388856B3DF0@HE1PR04MB1161.eurprd04.prod.outlook.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>
	<HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<SG2PR02MB137374175954B7E432BD4BFFA4DF0@SG2PR02MB1373.apcprd02.prod.outlook.com>
	<HE1PR04MB1161AF0D51F7A50015388856B3DF0@HE1PR04MB1161.eurprd04.prod.outlook.com>
Message-ID: <CAJWFm93G0a1JYrmK5h-+4oomNHjyUmp-rj99abmEcTdrj7VJCg@mail.gmail.com>

Another possible solution is to use the spsurvey package, and think of each
edge as a level of stratification and use the grts function to design a
survey of sample points on the edges. An advantage of the grts function is
that it uses a local neighborhood variance estimator, which can produce
smaller confidence limits compared to simple random sample variiance.
Mike

On Friday, October 14, 2016, Paolo Piras <paolo.piras at uniroma3.it> wrote:

> Dear Adrian,
>
> even this solution is pretty cool.
>
> Again, thanks to all who suggested me how to do that.
>
> Best
>
> Paolo
>
>
> ________________________________
> Da: Adrian Baddeley <adrian.baddeley at curtin.edu.au <javascript:;>>
> Inviato: venerd? 14 ottobre 2016 02.14
> A: Paolo Piras; Rolf Turner
> Cc: r-sig-geo; Ege Rubak
> Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a
> polygon
>
>
> You can use the spatstat function 'edges' to extract the edges of a
> polygonal window.
>
>
> Example:
>
>             W <- letterR    #polygonal window
>
>             E <- edges(W)
>
>             X <- runifpointOnLines(20, E)
>
>             plot(E)
>
>             plot(X, add=TRUE)
>
>
>
> Prof Adrian Baddeley DSc FAA
>
> Department of Mathematics and Statistics
>
> Curtin University, Perth, Western Australia
>
>
> ________________________________
> From: Paolo Piras <paolo.piras at uniroma3.it <javascript:;>>
> Sent: Friday, 14 October 2016 5:22 AM
> To: Rolf Turner
> Cc: r-sig-geo; Adrian Baddeley; Ege Rubak
> Subject: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a
> polygon
>
>
> Thanks a lot Rolf!
>
> This is virtually exactly what I need;
>
> I'm very grateful for that
>
> All the best
>
> Paolo
>
>
> ________________________________
> Da: Rolf Turner <r.turner at auckland.ac.nz <javascript:;>>
> Inviato: gioved? 13 ottobre 2016 23.12
> A: Paolo Piras
> Cc: r-sig-geo; Adrian.Baddeley at curtin.edu.au <javascript:;>; Ege Rubak
> Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a
> polygon
>
> On 14/10/16 07:03, Paolo Piras wrote:
> > HI folks,
> >
> > I write for a (hopefully) relatively simple question:
> >
> > I would need to uniformly sample 1000 or more points **along the
> border** of a polygon (not within the area enclosed) that is identified by
> ordered but not equally spaced points; which is the fastest way?
> >
> > In a first moment I thought to sample between any pair of consecutive
> points but, given that starting points are not uniformly distributed, the
> final result would be very far from a uniform distribution.
> >
> > here my polygon:
> >
> >
> >   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449,
> 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498,
> 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734,
> 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776,
> -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543,
> -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439,
> -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818,
> 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131,
> 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
> >   plot(mypol,asp=1,cex=0)
> >   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> > Thanks in advance for any hints
>
>
> This can be done reasonably easily using the spatstat package, for some
> value of the word "reasonably".  Here's how:
>
> require(spatstat)
> W <- owin(poly=mypol)
> m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
> m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
> m <- as.data.frame(m)
> names(m) <- c("x0","y0","x1","y1")
> L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
> set.seed(42)
> #X <- runifpointOnLines(1000,L)
> X <- runifpointOnLines(100,L)
> plot(W,main="Piras's Polygon")
> plot(X,add=TRUE)
>
> Note that I have just generated 100 uniform points, r.t. 1000, so that
> the resulting plot is a little less cluttered.
>
> There may be a sexier way of accomplishing your desideratum; I have
> cc-ed this email to my co-authors Adrian and Ege who may come up with
> better ideas.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>         [[alternative HTML version deleted]]
>
>

	[[alternative HTML version deleted]]


From lockhart.katherine at gmail.com  Sat Oct 15 00:02:55 2016
From: lockhart.katherine at gmail.com (Katherine Ransom)
Date: Fri, 14 Oct 2016 15:02:55 -0700
Subject: [R-sig-Geo] Problem with predict() from raster stack containing
	factor
Message-ID: <CAMEAd6wmk+1MxzXkG3Ue9=Ksk=320ZdM9vzugoL_dMgMZ3Dwog@mail.gmail.com>

Hi All,
I am puzzled by some predictions I am getting from the predict() function
on a raster stack containing a factor. I trained a gbm() model on 25
variables, one of which is a factor. Then, I am using the predict()
function on a raster stack created from a group of gridded ESRI .txt files,
one of which is my factor variable. The factor variable grid was created
the same way as the other variables (it is just the same value for every
cell). I am using:

hab = list.files(getwd(), pattern="txt$", full.names=FALSE)
rstack <- stack(hab)
pred <- predict(rstack, final, n.trees=final$n.trees, family="gaussian")

I have also tried setting the factors option with:
pred <- predict(rstack, final, n.trees=final$n.trees, family="gaussian",
factors=factor)
where factor is ("WaterUse2" is my factor variable):
 factor
$WaterUse2
[1] 2

I have also tried explicitly converting the specific raster layer within
the stack to a factor by doing:
rstack[[25]] <- as.factor(rstack[[25]]) # convert WaterUse2 raster to factor

The data used to train the model has 9 levels for WaterUse2. For
prediction, I want to make two separate prediction grids, one where
WaterUse2 is "2" everywhere, and one where it is "5" everywhere, I don't
care about the rest of the values since 2 and 5 dominate the data. In my
original data the levels were capital letters, e.g. "P","H", "I", but I
renamed them 1-9 in order to make the gridded layers for this variable for
prediction read in nice into R.

Without going into tons of detail, the variable seems to be throwing off my
predictions big time (much higher values than expected). I can leave it out
and get predictions much more in line with expectations. Also, the behavior
is not in line with the evidence in the partial plots for this variable.

Are there currently any known issues with using factors in predict()? Is
there something I could be doing wrong with this factor variable that would
lead to obviously incorrect predictions?

Many thanks,
Katie

-- 
--
Katherine Ransom
PhD Candidate
Hydrologic Sciences Graduate Group
UC Davis

	[[alternative HTML version deleted]]


From tephilippi at gmail.com  Sat Oct 15 22:46:54 2016
From: tephilippi at gmail.com (Tom Philippi)
Date: Sat, 15 Oct 2016 13:46:54 -0700
Subject: [R-sig-Geo] uniformly sample points on a border of a polygon
In-Reply-To: <CAJWFm93G0a1JYrmK5h-+4oomNHjyUmp-rj99abmEcTdrj7VJCg@mail.gmail.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>
	<HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<SG2PR02MB137374175954B7E432BD4BFFA4DF0@SG2PR02MB1373.apcprd02.prod.outlook.com>
	<HE1PR04MB1161AF0D51F7A50015388856B3DF0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<CAJWFm93G0a1JYrmK5h-+4oomNHjyUmp-rj99abmEcTdrj7VJCg@mail.gmail.com>
Message-ID: <CALyPt8wbUFX+2T3=1o-sUXuebhB9bPCwqVchviN20S9rQsP2pA@mail.gmail.com>

Note that the spsurvey package can also do IRS (simple independent random
sample) on points, polylines (e.g., stream networks), and area (polygons).
While the irslin() function only shows shapefile and not sp object, the
irs() function allows you to specify an sp object.

So, you can convert your polygon boundary to an sp spatialLines object
boundary, then:

design1 <- list("Stratum 1"=list(panel=c(Panel=1000), seltype="Equal")

draw <- irs(design=design1, type.frame='linear',

           src.frame='sp.object', sp.object='boundary')  # I'm pretty
sure boundary is a quoted name

This is roughly the same design object & syntax for a grts draw.


Tom 2


On Fri, Oct 14, 2016 at 2:12 PM, mgm mgm <mgm917391 at gmail.com> wrote:

> Another possible solution is to use the spsurvey package, and think of each
> edge as a level of stratification and use the grts function to design a
> survey of sample points on the edges. An advantage of the grts function is
> that it uses a local neighborhood variance estimator, which can produce
> smaller confidence limits compared to simple random sample variiance.
> Mike
>
> On Friday, October 14, 2016, Paolo Piras <paolo.piras at uniroma3.it> wrote:
>
> > Dear Adrian,
> >
> > even this solution is pretty cool.
> >
> > Again, thanks to all who suggested me how to do that.
> >
> > Best
> >
> > Paolo
> >
> >
> > ________________________________
> > Da: Adrian Baddeley <adrian.baddeley at curtin.edu.au <javascript:;>>
> > Inviato: venerd? 14 ottobre 2016 02.14
> > A: Paolo Piras; Rolf Turner
> > Cc: r-sig-geo; Ege Rubak
> > Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of
> a
> > polygon
> >
> >
> > You can use the spatstat function 'edges' to extract the edges of a
> > polygonal window.
> >
> >
> > Example:
> >
> >             W <- letterR    #polygonal window
> >
> >             E <- edges(W)
> >
> >             X <- runifpointOnLines(20, E)
> >
> >             plot(E)
> >
> >             plot(X, add=TRUE)
> >
> >
> >
> > Prof Adrian Baddeley DSc FAA
> >
> > Department of Mathematics and Statistics
> >
> > Curtin University, Perth, Western Australia
> >
> >
> > ________________________________
> > From: Paolo Piras <paolo.piras at uniroma3.it <javascript:;>>
> > Sent: Friday, 14 October 2016 5:22 AM
> > To: Rolf Turner
> > Cc: r-sig-geo; Adrian Baddeley; Ege Rubak
> > Subject: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of
> a
> > polygon
> >
> >
> > Thanks a lot Rolf!
> >
> > This is virtually exactly what I need;
> >
> > I'm very grateful for that
> >
> > All the best
> >
> > Paolo
> >
> >
> > ________________________________
> > Da: Rolf Turner <r.turner at auckland.ac.nz <javascript:;>>
> > Inviato: gioved? 13 ottobre 2016 23.12
> > A: Paolo Piras
> > Cc: r-sig-geo; Adrian.Baddeley at curtin.edu.au <javascript:;>; Ege Rubak
> > Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of
> a
> > polygon
> >
> > On 14/10/16 07:03, Paolo Piras wrote:
> > > HI folks,
> > >
> > > I write for a (hopefully) relatively simple question:
> > >
> > > I would need to uniformly sample 1000 or more points **along the
> > border** of a polygon (not within the area enclosed) that is identified
> by
> > ordered but not equally spaced points; which is the fastest way?
> > >
> > > In a first moment I thought to sample between any pair of consecutive
> > points but, given that starting points are not uniformly distributed, the
> > final result would be very far from a uniform distribution.
> > >
> > > here my polygon:
> > >
> > >
> > >   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449,
> > 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498,
> > 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734,
> > 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776,
> > -17.2262670680261, -17.5217563171495, -2.29667185082115,
> -7.72275721405543,
> > -9.77084968112857, -8.81725304021858, -8.32894043391822,
> -4.76080777897439,
> > -0.0600572363382094, 4.62779963258511, 8.20771806467615,
> 8.70484104396818,
> > 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131,
> > 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
> > >   plot(mypol,asp=1,cex=0)
> > >   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> > > Thanks in advance for any hints
> >
> >
> > This can be done reasonably easily using the spatstat package, for some
> > value of the word "reasonably".  Here's how:
> >
> > require(spatstat)
> > W <- owin(poly=mypol)
> > m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
> > m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
> > m <- as.data.frame(m)
> > names(m) <- c("x0","y0","x1","y1")
> > L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
> > set.seed(42)
> > #X <- runifpointOnLines(1000,L)
> > X <- runifpointOnLines(100,L)
> > plot(W,main="Piras's Polygon")
> > plot(X,add=TRUE)
> >
> > Note that I have just generated 100 uniform points, r.t. 1000, so that
> > the resulting plot is a little less cluttered.
> >
> > There may be a sexier way of accomplishing your desideratum; I have
> > cc-ed this email to my co-authors Adrian and Ege who may come up with
> > better ideas.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> >         [[alternative HTML version deleted]]
> >
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Sat Oct 15 22:50:06 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Sat, 15 Oct 2016 20:50:06 +0000
Subject: [R-sig-Geo] uniformly sample points on a border of a polygon
In-Reply-To: <CAJWFm93G0a1JYrmK5h-+4oomNHjyUmp-rj99abmEcTdrj7VJCg@mail.gmail.com>
References: <F7815991-4967-449B-8173-C26865B49F2A@csic.es>
	<dde216dd-80a6-8cc5-5f9b-0ff6caca5b88@gmail.com>
	<4368F5A7-18E0-4B9C-8780-D919697AE20F@csic.es>
	<488518ee-3d60-4dec-8c75-4ebd395a22aa@uni-muenster.de>
	<7F4D3C03-DA92-4EA8-BD8E-D0051F595F33@csic.es>
	<HE1PR04MB116188A769C000E73053BCC6B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<166efa41-cdec-2940-072e-94db5500c04c@auckland.ac.nz>
	<HE1PR04MB1161F4161A7BCAC3A9969B43B3DC0@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<SG2PR02MB137374175954B7E432BD4BFFA4DF0@SG2PR02MB1373.apcprd02.prod.outlook.com>
	<HE1PR04MB1161AF0D51F7A50015388856B3DF0@HE1PR04MB1161.eurprd04.prod.outlook.com>,
	<CAJWFm93G0a1JYrmK5h-+4oomNHjyUmp-rj99abmEcTdrj7VJCg@mail.gmail.com>
Message-ID: <HE1PR04MB1161302D75002D8CE31BDCD2B3DE0@HE1PR04MB1161.eurprd04.prod.outlook.com>

Thanks Mike,

I'll look forward for this solution too

best

paolo



________________________________
Da: mgm mgm <mgm917391 at gmail.com>
Inviato: venerd? 14 ottobre 2016 23.12
A: Paolo Piras
Cc: Adrian Baddeley; Rolf Turner; Ege Rubak; r-sig-geo
Oggetto: Re: [R-sig-Geo] uniformly sample points on a border of a polygon

Another possible solution is to use the spsurvey package, and think of each edge as a level of stratification and use the grts function to design a survey of sample points on the edges. An advantage of the grts function is that it uses a local neighborhood variance estimator, which can produce smaller confidence limits compared to simple random sample variiance.
Mike

On Friday, October 14, 2016, Paolo Piras <paolo.piras at uniroma3.it<mailto:paolo.piras at uniroma3.it>> wrote:
Dear Adrian,

even this solution is pretty cool.

Again, thanks to all who suggested me how to do that.

Best

Paolo


________________________________
Da: Adrian Baddeley <adrian.baddeley at curtin.edu.au>
Inviato: venerd? 14 ottobre 2016 02.14
A: Paolo Piras; Rolf Turner
Cc: r-sig-geo; Ege Rubak
Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon


You can use the spatstat function 'edges' to extract the edges of a polygonal window.


Example:

            W <- letterR    #polygonal window

            E <- edges(W)

            X <- runifpointOnLines(20, E)

            plot(E)

            plot(X, add=TRUE)



Prof Adrian Baddeley DSc FAA

Department of Mathematics and Statistics

Curtin University, Perth, Western Australia


________________________________
From: Paolo Piras <paolo.piras at uniroma3.it>
Sent: Friday, 14 October 2016 5:22 AM
To: Rolf Turner
Cc: r-sig-geo; Adrian Baddeley; Ege Rubak
Subject: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon


Thanks a lot Rolf!

This is virtually exactly what I need;

I'm very grateful for that

All the best

Paolo


________________________________
Da: Rolf Turner <r.turner at auckland.ac.nz>
Inviato: gioved? 13 ottobre 2016 23.12
A: Paolo Piras
Cc: r-sig-geo; Adrian.Baddeley at curtin.edu.au; Ege Rubak
Oggetto: Re: [FORGED] [R-sig-Geo] uniformly sample points on a border of a polygon

On 14/10/16 07:03, Paolo Piras wrote:
> HI folks,
>
> I write for a (hopefully) relatively simple question:
>
> I would need to uniformly sample 1000 or more points **along the border** of a polygon (not within the area enclosed) that is identified by ordered but not equally spaced points; which is the fastest way?
>
> In a first moment I thought to sample between any pair of consecutive points but, given that starting points are not uniformly distributed, the final result would be very far from a uniform distribution.
>
> here my polygon:
>
>
>   mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449, 6.09494902836977, 6.83498916728338, 9.20403746769121, 15.3061452155498, 18.4050681631565, 15.334153355932, 9.21809033073377, 6.90467983448734, 6.17942233200763, -3.4864867866601, -13.8299219386242, -17.5237987124776, -17.2262670680261, -17.5217563171495, -2.29667185082115, -7.72275721405543, -9.77084968112857, -8.81725304021858, -8.32894043391822, -4.76080777897439, -0.0600572363382094, 4.62779963258511, 8.20771806467615, 8.70484104396818, 9.68531129857718, 7.67574865642846, 2.46081860449754, 1.31152149442131, 0.0845735294613392, -1.11988475144136),ncol=2),digits=2)
>   plot(mypol,asp=1,cex=0)
>   text(mypol[,1],mypol[,2],c(1:nrow(mypol)))
> Thanks in advance for any hints


This can be done reasonably easily using the spatstat package, for some
value of the word "reasonably".  Here's how:

require(spatstat)
W <- owin(poly=mypol)
m <- cbind(mypol[-nrow(mypol),],mypol[-1,])
m <- rbind(m,c(mypol[nrow(mypol),],mypol[1,]))
m <- as.data.frame(m)
names(m) <- c("x0","y0","x1","y1")
L <- with(m,psp(x0,y0,x1,y1,window=boundingbox(W)))
set.seed(42)
#X <- runifpointOnLines(1000,L)
X <- runifpointOnLines(100,L)
plot(W,main="Piras's Polygon")
plot(X,add=TRUE)

Note that I have just generated 100 uniform points, r.t. 1000, so that
the resulting plot is a little less cluttered.

There may be a sexier way of accomplishing your desideratum; I have
cc-ed this email to my co-authors Adrian and Ege who may come up with
better ideas.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

        [[alternative HTML version deleted]]


	[[alternative HTML version deleted]]


From milujisb at gmail.com  Sun Oct 16 15:32:00 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 16 Oct 2016 15:32:00 +0200
Subject: [R-sig-Geo] Merge data by latitude and longitude
Message-ID: <CAMLwc7NGsU-c_yJ6oGhGuwFn2LLtd67E6-+E27dL7XxR2k7nHQ@mail.gmail.com>

Dear all,

I have two dataframe 1 by latitude and longitude but they always do not
match. Is it possible to merge them (e.g. nearest distance)?

# Dataframe 1
structure(list(lat = c(54L, 55L, 51L, 54L, 53L, 50L, 47L, 51L,
49L, 54L), lon = c(14L, 8L, 15L, 7L, 6L, 5L, 13L, 5L, 13L, 11L
), PPP2000_40 = c(4606, 6575, 6593, 7431, 9393, 10773, 11716,
12226, 13544, 14526)), .Names = c("lat", "lon", "PPP2000_40"), row.names =
c(6764L,
8796L, 8901L, 9611L, 11649L, 12819L, 13763L, 14389L, 15641L,
16571L), class = "data.frame")

# Dataframe 2
structure(list(lat = c(47, 47, 47, 47, 47, 47, 48, 48, 48, 48
), lon = c(7, 8, 9, 10, 11, 12, 7, 8, 9, 10), GDP = c(19.09982,
13.31977, 14.95925, 6.8575635, 23.334565, 6.485748, 24.01197,
14.30393075, 21.33759675, 9.71803675)), .Names = c("lat", "lon",
"GDP"), row.names = c(NA, 10L), class = "data.frame")

Thank you so much!

Sincerely,

Milu

	[[alternative HTML version deleted]]


From Hollister.Jeff at epa.gov  Sun Oct 16 15:30:54 2016
From: Hollister.Jeff at epa.gov (Hollister, Jeff)
Date: Sun, 16 Oct 2016 13:30:54 +0000
Subject: [R-sig-Geo] uniformly sample points on a border of a polygon
In-Reply-To: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>
Message-ID: <BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>

And for another option, using sp::spsample


mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449,
                              6.09494902836977, 6.83498916728338,
                              9.20403746769121, 15.3061452155498,
                              18.4050681631565, 15.334153355932,
                              9.21809033073377, 6.90467983448734,
                              6.17942233200763, -3.4864867866601,
                              -13.8299219386242, -17.5237987124776,
                              -17.2262670680261, -17.5217563171495,
                              -2.29667185082115, -7.72275721405543,
                              -9.77084968112857, -8.81725304021858,
                              -8.32894043391822, -4.76080777897439,
                              -0.0600572363382094, 4.62779963258511,
                              8.20771806467615, 8.70484104396818,
                              9.68531129857718, 7.67574865642846,
                              2.46081860449754, 1.31152149442131,
                              0.0845735294613392, -1.11988475144136),
                            ncol=2),digits=2)
mypol <- SpatialPolygons(list(Polygons(list(Polygon(mypol)),ID = "1")))
pts <- spsample(as(mypol, "SpatialLines"), 100, "regular")
plot(mypol)
plot(pts, add=T,col="red")

Cheers,

Jeff


	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Sun Oct 16 15:53:15 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Sun, 16 Oct 2016 13:53:15 +0000
Subject: [R-sig-Geo] uniformly sample points on a border of a polygon
In-Reply-To: <BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>,
	<BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>
Message-ID: <HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>

Thanks Jeff,

this solution also works quite well!

Thanks again to all those that proposed different solutions.

Best

Paolo


________________________________
Da: R-sig-Geo <r-sig-geo-bounces at r-project.org> per conto di Hollister, Jeff <Hollister.Jeff at epa.gov>
Inviato: domenica 16 ottobre 2016 15.30
A: r-sig-geo at r-project.org
Oggetto: Re: [R-sig-Geo] uniformly sample points on a border of a polygon

And for another option, using sp::spsample


mypol<-round(matrix(c(-13.8447497369687, -3.51439434200449,
                              6.09494902836977, 6.83498916728338,
                              9.20403746769121, 15.3061452155498,
                              18.4050681631565, 15.334153355932,
                              9.21809033073377, 6.90467983448734,
                              6.17942233200763, -3.4864867866601,
                              -13.8299219386242, -17.5237987124776,
                              -17.2262670680261, -17.5217563171495,
                              -2.29667185082115, -7.72275721405543,
                              -9.77084968112857, -8.81725304021858,
                              -8.32894043391822, -4.76080777897439,
                              -0.0600572363382094, 4.62779963258511,
                              8.20771806467615, 8.70484104396818,
                              9.68531129857718, 7.67574865642846,
                              2.46081860449754, 1.31152149442131,
                              0.0845735294613392, -1.11988475144136),
                            ncol=2),digits=2)
mypol <- SpatialPolygons(list(Polygons(list(Polygon(mypol)),ID = "1")))
pts <- spsample(as(mypol, "SpatialLines"), 100, "regular")
plot(mypol)
plot(pts, add=T,col="red")

Cheers,

Jeff


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo
R-sig-Geo Info Page<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
R-sig-Geo -- R Special Interest Group on using Geographical data and Mapping About R-sig-Geo




	[[alternative HTML version deleted]]


From bob at rud.is  Mon Oct 17 03:54:30 2016
From: bob at rud.is (Bob Rudis)
Date: Sun, 16 Oct 2016 21:54:30 -0400
Subject: [R-sig-Geo] Merge data by latitude and longitude
In-Reply-To: <CAMLwc7NGsU-c_yJ6oGhGuwFn2LLtd67E6-+E27dL7XxR2k7nHQ@mail.gmail.com>
References: <CAMLwc7NGsU-c_yJ6oGhGuwFn2LLtd67E6-+E27dL7XxR2k7nHQ@mail.gmail.com>
Message-ID: <CAA-FpKVJPziPCFEEjs0mpZR1kJ0Pbaxz+RRe3cyXhxkz=1qBKA@mail.gmail.com>

When your cross-post on StackOverflow is answered (or is answered
here) were you planning on cross-posting the answer as well?

On Sun, Oct 16, 2016 at 9:32 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have two dataframe 1 by latitude and longitude but they always do not
> match. Is it possible to merge them (e.g. nearest distance)?
>
> # Dataframe 1
> structure(list(lat = c(54L, 55L, 51L, 54L, 53L, 50L, 47L, 51L,
> 49L, 54L), lon = c(14L, 8L, 15L, 7L, 6L, 5L, 13L, 5L, 13L, 11L
> ), PPP2000_40 = c(4606, 6575, 6593, 7431, 9393, 10773, 11716,
> 12226, 13544, 14526)), .Names = c("lat", "lon", "PPP2000_40"), row.names =
> c(6764L,
> 8796L, 8901L, 9611L, 11649L, 12819L, 13763L, 14389L, 15641L,
> 16571L), class = "data.frame")
>
> # Dataframe 2
> structure(list(lat = c(47, 47, 47, 47, 47, 47, 48, 48, 48, 48
> ), lon = c(7, 8, 9, 10, 11, 12, 7, 8, 9, 10), GDP = c(19.09982,
> 13.31977, 14.95925, 6.8575635, 23.334565, 6.485748, 24.01197,
> 14.30393075, 21.33759675, 9.71803675)), .Names = c("lat", "lon",
> "GDP"), row.names = c(NA, 10L), class = "data.frame")
>
> Thank you so much!
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From G.Maubach at weinwolf.de  Tue Oct 18 10:31:34 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Tue, 18 Oct 2016 10:31:34 +0200
Subject: [R-sig-Geo] Reshaping geographic data
Message-ID: <OFD1A821BB.C32D3B56-ONC1258050.0027A1CA-C1258050.002ED610@lotus.hawesko.de>

Hi All,

I need to reshape an ESRI shape file: http://arnulf.us/PLZ and resp 
http://www.metaspatial.net/download/plz.tar.gz

This means that I need to combine the areas of the ZipCodes (i. e. PLZ) to 
the ZipCode regions (i. e. PLZ Leitregion). 

Example:
The city "Duesseldorf" has a couple of ZipCodes for different parts of the 
city, e. g. 40210 40211 40212 40213 40215 40217 and so on. The ZipCode 
region (PLZ Leitregion) is "40".

What I need to do is to combine the area information in the above given 
ESRI shapefile to get the area for the ZipCode region.

I found an instruction for T-SQL Server:

https://blog.oraylis.de/2010/05/german-map-spatial-data-for-plz-postal-code-regions/

How can I do this using R?

Kind regards

Georg


From milujisb at gmail.com  Tue Oct 18 11:19:36 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Tue, 18 Oct 2016 11:19:36 +0200
Subject: [R-sig-Geo] Merge data by latitude and longitude
In-Reply-To: <CAMLwc7NGsU-c_yJ6oGhGuwFn2LLtd67E6-+E27dL7XxR2k7nHQ@mail.gmail.com>
References: <CAMLwc7NGsU-c_yJ6oGhGuwFn2LLtd67E6-+E27dL7XxR2k7nHQ@mail.gmail.com>
Message-ID: <CAMLwc7NLGE0oSwS4rBP-Omu6xxACOSQDJN8Y4SQ59CGwDvP0EA@mail.gmail.com>

Possible solution:

http://stackoverflow.com/a/40075289/4373531

On Sun, Oct 16, 2016 at 3:32 PM, Miluji Sb <milujisb at gmail.com> wrote:

> Dear all,
>
> I have two dataframe 1 by latitude and longitude but they always do not
> match. Is it possible to merge them (e.g. nearest distance)?
>
> # Dataframe 1
> structure(list(lat = c(54L, 55L, 51L, 54L, 53L, 50L, 47L, 51L,
> 49L, 54L), lon = c(14L, 8L, 15L, 7L, 6L, 5L, 13L, 5L, 13L, 11L
> ), PPP2000_40 = c(4606, 6575, 6593, 7431, 9393, 10773, 11716,
> 12226, 13544, 14526)), .Names = c("lat", "lon", "PPP2000_40"), row.names =
> c(6764L,
> 8796L, 8901L, 9611L, 11649L, 12819L, 13763L, 14389L, 15641L,
> 16571L), class = "data.frame")
>
> # Dataframe 2
> structure(list(lat = c(47, 47, 47, 47, 47, 47, 48, 48, 48, 48
> ), lon = c(7, 8, 9, 10, 11, 12, 7, 8, 9, 10), GDP = c(19.09982,
> 13.31977, 14.95925, 6.8575635, 23.334565, 6.485748, 24.01197,
> 14.30393075, 21.33759675, 9.71803675)), .Names = c("lat", "lon",
> "GDP"), row.names = c(NA, 10L), class = "data.frame")
>
> Thank you so much!
>
> Sincerely,
>
> Milu
>

	[[alternative HTML version deleted]]


From ahartell at gmail.com  Tue Oct 18 13:24:05 2016
From: ahartell at gmail.com (Ann Hartell)
Date: Tue, 18 Oct 2016 13:24:05 +0200
Subject: [R-sig-Geo] Reshaping geographic data
Message-ID: <CADOma_Yq-3WyTQCWZ_PTRckgOmbWncNpo9S9zMj9b1WTKS2+wA@mail.gmail.com>

Howdy Georg,

I've followed this tutorial/example to dissolve related polygons into
larger spatial units:
https://philmikejones.wordpress.com/2015/09/03/dissolve-polygons-in-r/

And Roger has additional info here:
https://cran.r-project.org/web/packages/maptools/vignettes/combine_maptools.pdf

Hope these resources help get you where you want to go,
Ann H.


----------------------------------------------------------------------

Message: 1
Date: Tue, 18 Oct 2016 10:31:34 +0200
From: G.Maubach at weinwolf.de
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Reshaping geographic data
Message-ID:
        <OFD1A821BB.C32D3B56-ONC1258050.0027A1CA-C1258050.
002ED610 at lotus.hawesko.de>

Content-Type: text/plain; charset="US-ASCII"

Hi All,

I need to reshape an ESRI shape file: http://arnulf.us/PLZ and resp
http://www.metaspatial.net/download/plz.tar.gz

This means that I need to combine the areas of the ZipCodes (i. e. PLZ) to
the ZipCode regions (i. e. PLZ Leitregion).

Example:
The city "Duesseldorf" has a couple of ZipCodes for different parts of the
city, e. g. 40210 40211 40212 40213 40215 40217 and so on. The ZipCode
region (PLZ Leitregion) is "40".

What I need to do is to combine the area information in the above given
ESRI shapefile to get the area for the ZipCode region.

I found an instruction for T-SQL Server:

https://blog.oraylis.de/2010/05/german-map-spatial-data-
for-plz-postal-code-regions/

How can I do this using R?

Kind regards

Georg

	[[alternative HTML version deleted]]


From ignacio.barbeito-sanchez at inra.fr  Tue Oct 18 15:04:44 2016
From: ignacio.barbeito-sanchez at inra.fr (Ignacio Barbeito-Sanchez)
Date: Tue, 18 Oct 2016 13:04:44 +0000
Subject: [R-sig-Geo] Calculating envelopes for a point pattern on a linear
 network (equivalent to rshift in 2D)
Message-ID: <1476795988817.365@inra.fr>

Dear list members,

We have a bivariate point pattern (two tree species) in a linear
transect and would like to obtain a null model equivalent to the one
provided by rshift in 2D to test the independence of both populations
(in spatstat)

We are using spatstat, but this option does not seem available at the
moment, or we can't find it (the option available tests the complete
spatial randomness of one population (p) once the other population is
fixed (s) but does not keep the pattern of the second population (p)
unchanged- which is a problem because both populations are clustered in
our case)

An example of our code follows:

T1 is a point pattern on a linear transect as follows:
 > T1
Point pattern on linear network
232 points
Multitype, with possible types: p, s
Linear network with 2 vertices and 1 line
Enclosing window: rectangle = [-1, 101] x [-1, 1] units

We used multiple pair correlation functions (linearpfccross)

We computed an envelope to test the hypothesis of complete spatial
randomness and independance:
T1.env = envelope.lpp ( T1, fun = linearpcfcross , nsim = 30 , i = "s",
j = "p")

If anybody has experienced a similar problem or has some hints on how to
proceed we would be very grateful

Thanks in advance
cheers,
Ignacio?

	[[alternative HTML version deleted]]


From mel at mbacou.com  Tue Oct 18 15:35:12 2016
From: mel at mbacou.com (Bacou, Melanie)
Date: Tue, 18 Oct 2016 09:35:12 -0400
Subject: [R-sig-Geo] Extract() fails to return data for boundary admin units
In-Reply-To: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
References: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
Message-ID: <76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>

Hi,
I'm summarizing biophysical rasters (UDEL precipitation and temperature) 
across administrative units for countries in Africa using (pseudo code):

raster::extract(udel, admin, fun=mean, na.rm=T, small=T)

Out of the 756 units I need data for, extract() fails to return means 
for a few coastal units (in red on the maps below) even though the 
rasters show data at these locations.

Is there a particular reason why this might happen? Shall I look for 
possible geometry errors in my source shapefiles, or could there be 
another reason?

Maps here:
https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png
https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png

Thanks for any tip. --Mel.


From englishchristophera at gmail.com  Tue Oct 18 17:10:18 2016
From: englishchristophera at gmail.com (chris english)
Date: Tue, 18 Oct 2016 18:10:18 +0300
Subject: [R-sig-Geo] Extract() fails to return data for boundary admin
	units
In-Reply-To: <76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>
References: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
	<76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>
Message-ID: <CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>

Mel,

Looking at detail in cjg.png the northmost missing data island shows approx
20-25 in Southern three quarters and 0-5 the small North at tip of island.
Directly above this 0-5 another coastal 0-5.
If a substantial east-west scarp bisected the island it might explain. I
would otherwise expect a very slight mismatch in projection, a thing I
often have problems with.

Though reading raster::extract it looks like you want to employ the weights
are if your polys are relatively smaller than your cells.

HTH
Chris

On Oct 18, 2016 4:35 PM, "Bacou, Melanie" <mel at mbacou.com> wrote:

> Hi,
> I'm summarizing biophysical rasters (UDEL precipitation and temperature)
> across administrative units for countries in Africa using (pseudo code):
>
> raster::extract(udel, admin, fun=mean, na.rm=T, small=T)
>
> Out of the 756 units I need data for, extract() fails to return means for
> a few coastal units (in red on the maps below) even though the rasters show
> data at these locations.
>
> Is there a particular reason why this might happen? Shall I look for
> possible geometry errors in my source shapefiles, or could there be another
> reason?
>
> Maps here:
> https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png
> https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png
>
> Thanks for any tip. --Mel.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Tue Oct 18 19:18:34 2016
From: englishchristophera at gmail.com (chris english)
Date: Tue, 18 Oct 2016 20:18:34 +0300
Subject: [R-sig-Geo] Extract() fails to return data for boundary admin
	units
In-Reply-To: <CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
References: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
	<76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>
	<CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
Message-ID: <CAASFQpTs-ono3hRD9NPwPMfzkmTGW+D5=OV6mHMG9RemGH1OsA@mail.gmail.com>

Mel,

Sorry, your pseudo-code:

raster::extract(udel, admin, fun=mean, na.rm=T, small=T, weights = TRUE)

Chris

On Tue, Oct 18, 2016 at 6:10 PM, chris english <
englishchristophera at gmail.com> wrote:

> Mel,
>
> Looking at detail in cjg.png the northmost missing data island shows
> approx 20-25 in Southern three quarters and 0-5 the small North at tip of
> island. Directly above this 0-5 another coastal 0-5.
> If a substantial east-west scarp bisected the island it might explain. I
> would otherwise expect a very slight mismatch in projection, a thing I
> often have problems with.
>
> Though reading raster::extract it looks like you want to employ the
> weights are if your polys are relatively smaller than your cells.
>
> HTH
> Chris
>
> On Oct 18, 2016 4:35 PM, "Bacou, Melanie" <mel at mbacou.com> wrote:
>
>> Hi,
>> I'm summarizing biophysical rasters (UDEL precipitation and temperature)
>> across administrative units for countries in Africa using (pseudo code):
>>
>> raster::extract(udel, admin, fun=mean, na.rm=T, small=T)
>>
>> Out of the 756 units I need data for, extract() fails to return means for
>> a few coastal units (in red on the maps below) even though the rasters show
>> data at these locations.
>>
>> Is there a particular reason why this might happen? Shall I look for
>> possible geometry errors in my source shapefiles, or could there be another
>> reason?
>>
>> Maps here:
>> https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png
>> https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png
>>
>> Thanks for any tip. --Mel.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>

	[[alternative HTML version deleted]]


From mel at mbacou.com  Tue Oct 18 20:33:56 2016
From: mel at mbacou.com (Bacou, Melanie)
Date: Tue, 18 Oct 2016 14:33:56 -0400
Subject: [R-sig-Geo] Extract() fails to return data for boundary admin
 units
In-Reply-To: <CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
References: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
	<76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>
	<CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
Message-ID: <f3809f6e-a35a-3b2e-7e2e-4a803f9dc59a@mbacou.com>

Chris,
Thanks, using `weights=TRUE` to compute the means fixed the problem.
Perfect, --Mel.


On 10/18/2016 11:10 AM, chris english wrote:
>
> Mel,
>
> Looking at detail in cjg.png the northmost missing data island shows 
> approx 20-25 in Southern three quarters and 0-5 the small North at tip 
> of island. Directly above this 0-5 another coastal 0-5.
> If a substantial east-west scarp bisected the island it might explain. 
> I would otherwise expect a very slight mismatch in projection, a thing 
> I often have problems with.
>
> Though reading raster::extract it looks like you want to employ the 
> weights are if your polys are relatively smaller than your cells.
>
> HTH
> Chris
>
>
> On Oct 18, 2016 4:35 PM, "Bacou, Melanie" <mel at mbacou.com 
> <mailto:mel at mbacou.com>> wrote:
>
>     Hi,
>     I'm summarizing biophysical rasters (UDEL precipitation and
>     temperature) across administrative units for countries in Africa
>     using (pseudo code):
>
>     raster::extract(udel, admin, fun=mean, na.rm=T, small=T)
>
>     Out of the 756 units I need data for, extract() fails to return
>     means for a few coastal units (in red on the maps below) even
>     though the rasters show data at these locations.
>
>     Is there a particular reason why this might happen? Shall I look
>     for possible geometry errors in my source shapefiles, or could
>     there be another reason?
>
>     Maps here:
>     https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png
>     <https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png>
>     https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png
>     <https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png>
>
>     Thanks for any tip. --Mel.
>
>     _______________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>


	[[alternative HTML version deleted]]


From kimon-vincent.krenz.12 at ucl.ac.uk  Tue Oct 18 20:47:52 2016
From: kimon-vincent.krenz.12 at ucl.ac.uk (Krenz, Kimon-Vincent)
Date: Tue, 18 Oct 2016 18:47:52 +0000
Subject: [R-sig-Geo] Generating Random Planar Graph with 1m Edges
In-Reply-To: <alpine.LFD.2.20.1610061429450.12536@reclus.nhh.no>
References: <0715E972-25B4-4A48-986E-7F933F6C3BE8@ucl.ac.uk>
	<alpine.LFD.2.20.1610061429450.12536@reclus.nhh.no>
Message-ID: <20D94BB4-5DB5-4FE9-98E0-106C83162BD5@ucl.ac.uk>

Dear Roger,

Apologies for the late reply.

Your suggestion was a life saver, the computation time by which RANN produces nearest neighbour indexes and distances is incredible. Even with more than 1.5million points it took only a minute to compute 30 neighbours and their distance for each pair.

The only problem I faced with the RANN approach is that one arrives with the nearest points first. Meaning that if a point is surrounded by lets say 30 other points within a distance of 500 meter, one will never arrive with a pair that is in distance of 5000 meter. To overcome this one can only increase the number of k neighbours, which in my case would mean minimum k=100, leading to 100million combinations of which I then sampled randomly the amount necessary to proceed.

Still the best and fastest option. Thanks for your help!

Best,
Kimon

Kimon Krenz

PhD Researcher
MSc SDAC Course Coordinator<http://www.bartlett.ucl.ac.uk/space-syntax/programmes/mres-msc/msc-spatial-design>
Space Syntax Laboratory<http://www.bartlett.ucl.ac.uk/space-syntax>

mail.       ucftkr3 at ucl.ac.uk<mailto:ucftkr3 at ucl.ac.uk>
phone.    0044 7784 329089
web.       www.kimonkrenz.com<http://www.kimonkrenz.com/>

Bartlett School of Architecture<http://www.bartlett.ucl.ac.uk/>
UCL
140 Hampstead Road
London     NW1 2BX     UK

On 06 Oct 2016, at 13:32, Roger Bivand <Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>> wrote:

Just a partial suggestion: the RANN package will let you index the points byk-neighbourness, avoiding some of the burden of searching for points within your 100-1000m band.

Hope this helps,

Roger

On Wed, 5 Oct 2016, Krenz, Kimon-Vincent wrote:

Dear All,

I started a week ago to use R to solve a problem I am currently facing in my PhD.
Apologies in advance for the long-winded explanation of my problem.

I am trying to generate a random planar graph with approximately 1 million edges, where:

A) nodes (points) feature spatial coordinates
B) the network has a given boundary

C) edges (lines) are created if two points fall within a given distance (e.g. 100 - 1000 metres)

D) degree (connectivity) ranges between given k max and min (e.g. k ? 5)
E) edges do not intersect

This will result in something one might want to compare to a random street network.

I am following a method proposed here: Masucci, A. P., Smith, D., Crooks, A., & Batty, M. (2009). Random planar graphs and the London street network. European Physical Journal B, 71(2), 259?271. http://doi.org/10.1140/epjb/e2009-00290-4) link to paper: https://goo.gl/6XWW8P

Masucci et al.: "We first introduce a random model for a static planar graph. ... To build an ERPG we start with a Poisson distribution of N points in a plane and we choose a distance r. To build the first segment, we randomly pick up two points of the distribution that have a distance less then r and we connect them. Then we continue to randomly pick up pairs of points P and Q in the given points distribution that have a distance less then r. If the segment PQ does not intersect any other line of the graph, we add it to the graph. The process ends when we add the desired number of edges E.?

I hence, started with generating random points using the Poisson distribution in a given spatial box (A and A):

require(spatstat)
require(maps)
library(sp)
w <- as.owin(list(xrange=c(32275175,32475175),yrange=c(5611910,5811910)))
Y <- rpoispp(0.00001, win=w)
Ydata <- data.frame(Y)
list(Y)

That seems to be quite straightforward in R.
I then followed the proposed method and wrote a simple loop, that selects two points from Ydata
based on a random sample and adds the projection of the coordinate system.

#399717 is = N from the rpoispp

repeat {
l1 <- sample(1:399717, 2, replace=F)

Ydata.sp<-Ydata[l1, c('x','y')]
coordinates(Ydata.sp)<-~x+y
crs.geo <- CRS("+init=epsg:4647 +proj=tmerc +lat_0=0 +lon_0=9 +k=0.9996 +x_0=32500000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
proj4string(Ydata.sp) <- crs.geo

L = SpatialLines(list(Lines(list(Line(coordinates(Ydata.sp))),"X")))
if (SpatialLinesLengths(L)<=4000){
  break
}
}
plot(L)
SpatialLinesLengths(L)

This fulfils the requirement of C) and I have not yet reached the point to deal with D) and E).
My problem here is that the process takes way too long for a single pair (approx 20 seconds, resulting in 250 days computational time).

Is there a quicker way solve this in a more efficient manner?

I have thought about selecting the first point by random and the second one randomly based on an evaluation
of all points within a given radius to the first point, rather than two complete random points.

This would at least cut down the test of several thousand meaningless combinations. However, I couldn't find a way to do this.
Another option might be gDistance from the (rgeos), but with 400k points, the result seems to be not computable.

I am also happy for any suggestions regarding requirements D and E, or help with the task in general.

Best,
Kimon

Kimon Krenz

PhD Researcher
MSc SDAC Course Coordinator<http://www.bartlett.ucl.ac.uk/space-syntax/programmes/mres-msc/msc-spatial-design>
Space Syntax Laboratory<http://www.bartlett.ucl.ac.uk/space-syntax>

mail.       ucftkr3 at ucl.ac.uk<mailto:ucftkr3 at ucl.ac.uk><mailto:ucftkr3 at ucl.ac.uk>
phone.    0044 7784 329089
web.       www.kimonkrenz.com<http://www.kimonkrenz.com/><http://www.kimonkrenz.com/>

Bartlett School of Architecture<http://www.bartlett.ucl.ac.uk/>
UCL
140 Hampstead Road
London     NW1 2BX     UK


[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


	[[alternative HTML version deleted]]


From mel at mbacou.com  Tue Oct 18 21:06:23 2016
From: mel at mbacou.com (Bacou, Melanie)
Date: Tue, 18 Oct 2016 15:06:23 -0400
Subject: [R-sig-Geo] Extract() fails to return data for boundary admin
 units
In-Reply-To: <f3809f6e-a35a-3b2e-7e2e-4a803f9dc59a@mbacou.com>
References: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
	<76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>
	<CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
	<f3809f6e-a35a-3b2e-7e2e-4a803f9dc59a@mbacou.com>
Message-ID: <cd4ba618-a285-a4ab-850a-d6001ecf6853@mbacou.com>

Chris,
Actually I take that back, using extract() with `weights=TRUE` returned 
`0` instead of NA values for these problematic coastal admin units. 
Think I might have to impute them manually.

--Mel.


On 10/18/2016 2:33 PM, Bacou, Melanie wrote:
>
> Chris,
> Thanks, using `weights=TRUE` to compute the means fixed the problem.
> Perfect, --Mel.
>
>
> On 10/18/2016 11:10 AM, chris english wrote:
>>
>> Mel,
>>
>> Looking at detail in cjg.png the northmost missing data island shows 
>> approx 20-25 in Southern three quarters and 0-5 the small North at 
>> tip of island. Directly above this 0-5 another coastal 0-5.
>> If a substantial east-west scarp bisected the island it might 
>> explain. I would otherwise expect a very slight mismatch in 
>> projection, a thing I often have problems with.
>>
>> Though reading raster::extract it looks like you want to employ the 
>> weights are if your polys are relatively smaller than your cells.
>>
>> HTH
>> Chris
>>
>>
>> On Oct 18, 2016 4:35 PM, "Bacou, Melanie" <mel at mbacou.com 
>> <mailto:mel at mbacou.com>> wrote:
>>
>>     Hi,
>>     I'm summarizing biophysical rasters (UDEL precipitation and
>>     temperature) across administrative units for countries in Africa
>>     using (pseudo code):
>>
>>     raster::extract(udel, admin, fun=mean, na.rm=T, small=T)
>>
>>     Out of the 756 units I need data for, extract() fails to return
>>     means for a few coastal units (in red on the maps below) even
>>     though the rasters show data at these locations.
>>
>>     Is there a particular reason why this might happen? Shall I look
>>     for possible geometry errors in my source shapefiles, or could
>>     there be another reason?
>>
>>     Maps here:
>>     https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png
>>     <https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png>
>>     https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png
>>     <https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png>
>>
>>     Thanks for any tip. --Mel.
>>
>>     _______________________________________________
>>     R-sig-Geo mailing list
>>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>>     https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>>
>


	[[alternative HTML version deleted]]


From tylerdrudolph at gmail.com  Tue Oct 18 22:06:01 2016
From: tylerdrudolph at gmail.com (Tyler D. Rudolph)
Date: Tue, 18 Oct 2016 16:06:01 -0400
Subject: [R-sig-Geo] raster::predict coercing factors
Message-ID: <CAD_xVVWdeK2cgFSRTmTXLRq7Q4FVOZjaNq+zB+H7bpf8Xxr-rw@mail.gmail.com>

I have used a data set consisting of continuous and categorical variables
to build a statistical (glmer) model. I now wish to produce a spatial map
of model predictions given landscape conditions where the values of all
independent variables are known and introduced to the raster::predict
function as a raster stack via the newdata argument . Variables 12 to 29
should appear as factors and indeed check out that way:

all(sapply(12:29, function(i) is.factor(newdata.stack[[i]])))
[1] TRUE

However, when I run the function it invariably tells me these variables are
not factors:

predict(obj=newdata.stack, model=mymodel, allow.new.levels=TRUE,
type="response")

Error in `contrasts<-`(`*tmp*`, value = contrasts.arg[[nn]]) :
  contrasts apply only to factors
In addition: There were 12 warnings (use warnings() to see them)

There is subsequently one warning for every categorical variable in the
model formula (the remaining 7 were excluded from this model. The first
warning is about ignoring unused variables.). E.g.:

5: In model.frame.default(delete.response(Terms), newdata,  ... :
  variable 'opine_0_14_nat' is not a factor

This is a problem I have never encountered before during this kind of
operation. It seems the factor class attributed to those categorical raster
layers is somehow coerced to something else once the call is passed. That
or there is something else I am overlooking?

	[[alternative HTML version deleted]]


From pingyang.whu at gmail.com  Tue Oct 18 22:31:24 2016
From: pingyang.whu at gmail.com (ping yang)
Date: Tue, 18 Oct 2016 15:31:24 -0500
Subject: [R-sig-Geo] Extract() fails to return data for boundary admin
	units
In-Reply-To: <CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
References: <6f3fb8f5-8025-fbb2-ef78-f11914b22df8@mbacou.com>
	<76531033-52c6-c0ba-487b-bb136f1ac6e0@mbacou.com>
	<CAASFQpQna=d_tM+tEQKV2Ux9vWxW9i1GctQFJxDHSJMFSoCtbA@mail.gmail.com>
Message-ID: <CAK8gSG8YjsCUPXFBFiE6NrnYprw5sSAfxXiygod4aoF2Asrp2A@mail.gmail.com>

I also found issues with the raster::extract function, for some reason, I
got crazy values when I compared the resulting value with the one from
QGIS(Zonal Statistics Plugin) and ArcGIS?zonal statistics), while the value
from qgis and arcgis were close but the raster::extract has a lot of
disturbances:

#example
library(raster)
library(rgdal)

r <- raster("PRISM_ppt_stable_4kmM3_201608_bil.bil
http://prism.nacse.org/6month/")
setwd("D:/PRISM/2005-2016/cb_2015_us_state_500k/")
psa <- readOGR(".",paste("cb_2015_us_state_500k
<http://www2.census.gov/geo/tiger/GENZ2015/shp/cb_2015_us_state_500k.zip>
",sep=''))
e <- extract(r, psa, weights=TRUE, sp=TRUE, na.rm=TRUE, df=TRUE,fun=mean)

result <- cbind(psa$monmean,e$PRISM_ppt_stable_4kmM3_201609_bil)
result
            [,1]       [,2]
 [1,]  67.756948  59.672969
 [2,]   8.163987  44.415848
 [3,]  91.171480  53.295749
 [4,]  74.446065  52.633753
 [5,] 128.915104  56.779383
 [6,] 105.266005  93.266030
 [7,] 187.633359  45.947235
 [8,] 106.659815  90.639262
 [9,] 160.519008  46.249172
[10,]  57.266614  26.728985
[11,]  23.258635  49.885868
[12,] 132.101744  46.713378
[13,]  21.995937  51.782905
[14,] 168.313586  93.790604
[15,]         NA         NA
......
[56,]  76.527362  82.369481

Has anyone have looked into this issue?

Thanks,

Peter

On Tue, Oct 18, 2016 at 10:10 AM, chris english <
englishchristophera at gmail.com> wrote:

> Mel,
>
> Looking at detail in cjg.png the northmost missing data island shows approx
> 20-25 in Southern three quarters and 0-5 the small North at tip of island.
> Directly above this 0-5 another coastal 0-5.
> If a substantial east-west scarp bisected the island it might explain. I
> would otherwise expect a very slight mismatch in projection, a thing I
> often have problems with.
>
> Though reading raster::extract it looks like you want to employ the weights
> are if your polys are relatively smaller than your cells.
>
> HTH
> Chris
>
> On Oct 18, 2016 4:35 PM, "Bacou, Melanie" <mel at mbacou.com> wrote:
>
> > Hi,
> > I'm summarizing biophysical rasters (UDEL precipitation and temperature)
> > across administrative units for countries in Africa using (pseudo code):
> >
> > raster::extract(udel, admin, fun=mean, na.rm=T, small=T)
> >
> > Out of the 756 units I need data for, extract() fails to return means for
> > a few coastal units (in red on the maps below) even though the rasters
> show
> > data at these locations.
> >
> > Is there a particular reason why this might happen? Shall I look for
> > possible geometry errors in my source shapefiles, or could there be
> another
> > reason?
> >
> > Maps here:
> > https://dl.dropboxusercontent.com/u/30925475/eclgcdmhapfplaml.png
> > https://dl.dropboxusercontent.com/u/30925475/lmkgmdoohpmhdcjg.png
> >
> > Thanks for any tip. --Mel.
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From nick.vandoormaal at gmail.com  Wed Oct 19 15:01:03 2016
From: nick.vandoormaal at gmail.com (Nick van Doormaal)
Date: Wed, 19 Oct 2016 15:01:03 +0200
Subject: [R-sig-Geo] No neighbours in sample using spatcounts package in R
Message-ID: <CAG0JA8uPYaVOv5wjm6=RWQnkpP1j1_BaqfqC6PuU_9m=C5YwGQ@mail.gmail.com>

Dear list members,

I'm trying to do a bootstrap of a spatial count model using the
*spatcounts-package* in R. However, resampling with replacement may lead to
"islands", because sometimes no neighbors will be selected. I believe this
is causing the error message: Error: NA/NaN/Inf in foreign function call
(arg 1). Can somebody confirm this if this indeed the case? If so, is there
a way to get around it, so that I would still be able to carry out a
bootstrap?

Please find below the code to recreate the problem using the example
dataset of the spatcounts package.

Thank you for your time and I hope somebody can help me out a bit.

####START CODE#####
set.seed(987654321)

library(spatcounts)

AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
colnames(AllData)[1:2] <- c("Yin", "Region")

idx <- sample(1:nrow(AllData), 100, replace=TRUE)
newdata.df <- AllData[idx,]
newdata.df <- newdata.df[order(newdata.df$Region),]
X <- as.data.frame(newdata.df[,3:4])
region <- as.data.frame(newdata.df$Region)
colnames(region) <- "V1"
Yin <- as.data.frame(newdata.df$Yin)

temp.idx <- sort(unique(newdata.df$Region))
g.temp <- sim.gmat[temp.idx,temp.idx]

TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT IN THIS
VECTOR.##OTHERWISE RUN AGAIN UNTIL AT LEAST ONE ZERO

n.temp <- sim.nmat[temp.idx,]
n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
n.temp$V6 <- TotalN

n.temp[is.na(n.temp)] <- 0

Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
region, model="NB", g.temp, n.temp, totalit=10) ##ERROR

	[[alternative HTML version deleted]]


From juta.kawalerowicz at nuffield.ox.ac.uk  Wed Oct 19 17:19:31 2016
From: juta.kawalerowicz at nuffield.ox.ac.uk (Juta Kawalerowicz)
Date: Wed, 19 Oct 2016 17:19:31 +0200
Subject: [R-sig-Geo] vulnerability mapping
Message-ID: <CAHMizkMvOKN8jkKGO6Zup46uUiyoGpTEFin9XJVuWBw+iv_SFw@mail.gmail.com>

Hi,

I would like to produce a map of riot vulnerability. I have spatial
SpatialPoints representing shopping malls and SpataialPolygonsDataFrame
with data on index of socio-economic deprivation in each Census tract. My
hunch is that these factors increase the vulnerability of for the area. How
to go about creating a map representing this vulnerability? Any suggestions
would be much appreciated.

Best wishes,
Juta

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Oct 20 01:06:06 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 20 Oct 2016 12:06:06 +1300
Subject: [R-sig-Geo] Calculating envelopes for a point pattern on a
 linear network (equivalent to rshift in 2D)
In-Reply-To: <1476795988817.365@inra.fr>
References: <1476795988817.365@inra.fr>
Message-ID: <36568c3a-f971-c3b6-f6a5-b591e1f2bbb1@auckland.ac.nz>


On 19/10/16 02:04, Ignacio Barbeito-Sanchez wrote:

> Dear list members,
>
> We have a bivariate point pattern (two tree species) in a linear
> transect and would like to obtain a null model equivalent to the one
> provided by rshift in 2D to test the independence of both populations
> (in spatstat)
>
> We are using spatstat, but this option does not seem available at the
> moment, or we can't find it (the option available tests the complete
> spatial randomness of one population (p) once the other population is
> fixed (s) but does not keep the pattern of the second population (p)
> unchanged-

I don't understand what you are saying here, not that it matters a great 
deal.

> which is a problem because both populations are clustered in
> our case)
>
> An example of our code follows:
>
> T1 is a point pattern on a linear transect as follows:
>  > T1
> Point pattern on linear network
> 232 points
> Multitype, with possible types: p, s
> Linear network with 2 vertices and 1 line
> Enclosing window: rectangle = [-1, 101] x [-1, 1] units
>
> We used multiple pair correlation functions (linearpfccross)
>
> We computed an envelope to test the hypothesis of complete spatial
> randomness and independance:
> T1.env = envelope.lpp ( T1, fun = linearpcfcross , nsim = 30 , i = "s",
> j = "p")
>
> If anybody has experienced a similar problem or has some hints on how to
> proceed we would be very grateful.

As of present there is no rshift() method for the lpp class in spatstat, 
and it may be a while before such a method is added.  However for the 
simple structure in your example it is not hard to write a little add 
hoc function to do the shifting.  I enclose a skeletal example below.

Note that the characteristics of your example are "hard wired" in the 
given code; it shouldn't to too difficult to make the code more general 
however.  The code does a "loop" type shift, analogous to setting 
edge="torus" in rshift.ppp; this may be inappropriate for clustered 
data.  Again it shouldn't be too difficult to change this behaviour.

Since you did not provide a reproducible example I have tried out my 
code on simplistically simulated data.

=====================================================================
# Code:
X <- psp(0,1,100,1,window=owin(c(0,101),c(-50,50)))
X <- as.linnet(X)
set.seed(42)
X <- runiflpp(232,X)
marks(X) <- factor(sample(c("p","s"),232,TRUE))

foo <- function(r0,X){
    u <- runif(2,-r0/2,r0/2)
    xp <- X$data$x[marks(X)=="p"]+u[1]
    xp[xp < 1] <- xp[xp < 1] + 99
    xp[xp > 100] <- xp[xp > 100] - 99
    xs <- X$data$x[marks(X)=="s"]+u[2]
    xs[xs < 1] <- xs[xs < 1] + 99
    xs[xs > 100] <- xs[xs > 100] - 99
    X$data$x[marks(X)=="p"] <- xp
    X$data$x[marks(X)=="s"] <- xs
    X
}

E <- envelope(X,fun=linearpcfcross,i="s",j="p",
               simulate=expression(foo(15,X)))
plot(E)
=====================================================================

HTH

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From englishchristophera at gmail.com  Thu Oct 20 12:20:17 2016
From: englishchristophera at gmail.com (chris english)
Date: Thu, 20 Oct 2016 13:20:17 +0300
Subject: [R-sig-Geo] No neighbours in sample using spatcounts package in
	R
In-Reply-To: <CAG0JA8uPYaVOv5wjm6=RWQnkpP1j1_BaqfqC6PuU_9m=C5YwGQ@mail.gmail.com>
References: <CAG0JA8uPYaVOv5wjm6=RWQnkpP1j1_BaqfqC6PuU_9m=C5YwGQ@mail.gmail.com>
Message-ID: <CAASFQpT8NbWyycrQEN0=fsu-qk-NQrser+sMGvoQmn_zF80mSg@mail.gmail.com>

Nick,

I get the same error running your code.

set.seed(987654321)

library(spatcounts)
data("sim.Yin")
data("sim.fm.X")
data("sim.gmat")
data("sim.nmat")
data("sim.region")
AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
colnames(AllData)[1:2] <- c("Yin", "Region")

idx <- sample(1:nrow(AllData), 100, replace=TRUE)
newdata.df <- AllData[idx,]
newdata.df <- newdata.df[order(newdata.df$Region),]
X <- as.data.frame(newdata.df[,3:4])
region <- as.data.frame(newdata.df$Region)
colnames(region) <- "V1"
Yin <- as.data.frame(newdata.df$Yin)

temp.idx <- sort(unique(newdata.df$Region))
g.temp <- sim.gmat[temp.idx,temp.idx]

TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT
> is.element(0, n.temp$V6)
[1] TRUE # after a few run thru's of idx to is.element

n.temp <- sim.nmat[temp.idx,]
n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
n.temp$V6 <- TotalN

> class(n.temp$V1)
[1] "numeric"
> class(n.temp$V2)
[1] "integer"
> class(n.temp$V3)
[1] "integer"
> class(n.temp$V4)
[1] "integer"
> class(n.temp$V5)
[1] "integer"
> class(n.temp$V6)
[1] "numeric"

# here, essentially checking what NA might be replaced with by class
# and wondering if a small numeric is desirable (0.001), $V1 & $v6
# and your 0 for integers ($V2-V5)

Well, a bunch of different tries and the error persists.

> n.temp[is.na(n.temp)] <- 1
> n.temp$V6[7] <- 10
> n.temp$V6[24] <- 10
> n.temp$V6[28] <- 0.001
>
> n.temp$V6[28] <- 10

> which(n.temp$V6 == 0)
integer(0)


> Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
+ region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
Error: NA/NaN/Inf in foreign function call (arg 1)

So, i guess i'd do a debugonce(est.sc) and find out which foreign function
is disappointing or
disappointed by the inputs, but the culprit does not appear to be TotalN.

HTH,

Chris



On Wed, Oct 19, 2016 at 4:01 PM, Nick van Doormaal <
nick.vandoormaal at gmail.com> wrote:

> Dear list members,
>
> I'm trying to do a bootstrap of a spatial count model using the
> *spatcounts-package* in R. However, resampling with replacement may lead to
> "islands", because sometimes no neighbors will be selected. I believe this
> is causing the error message: Error: NA/NaN/Inf in foreign function call
> (arg 1). Can somebody confirm this if this indeed the case? If so, is there
> a way to get around it, so that I would still be able to carry out a
> bootstrap?
>
> Please find below the code to recreate the problem using the example
> dataset of the spatcounts package.
>
> Thank you for your time and I hope somebody can help me out a bit.
>
> ####START CODE#####
> set.seed(987654321)
>
> library(spatcounts)
>
> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
> colnames(AllData)[1:2] <- c("Yin", "Region")
>
> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
> newdata.df <- AllData[idx,]
> newdata.df <- newdata.df[order(newdata.df$Region),]
> X <- as.data.frame(newdata.df[,3:4])
> region <- as.data.frame(newdata.df$Region)
> colnames(region) <- "V1"
> Yin <- as.data.frame(newdata.df$Yin)
>
> temp.idx <- sort(unique(newdata.df$Region))
> g.temp <- sim.gmat[temp.idx,temp.idx]
>
> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT IN THIS
> VECTOR.##OTHERWISE RUN AGAIN UNTIL AT LEAST ONE ZERO
>
> n.temp <- sim.nmat[temp.idx,]
> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
> n.temp$V6 <- TotalN
>
> n.temp[is.na(n.temp)] <- 0
>
> Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
> region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Thu Oct 20 14:18:43 2016
From: englishchristophera at gmail.com (chris english)
Date: Thu, 20 Oct 2016 15:18:43 +0300
Subject: [R-sig-Geo] Generating Random Planar Graph with 1m Edges
In-Reply-To: <42C5ED1D-7820-4C3C-839A-6561D700BBE3@ucl.ac.uk>
References: <0715E972-25B4-4A48-986E-7F933F6C3BE8@ucl.ac.uk>
	<CAASFQpSxoQXiUSkMyfSqWN=egaGa2PHVSWzZ3sf_ToaZL7AJVg@mail.gmail.com>
	<42C5ED1D-7820-4C3C-839A-6561D700BBE3@ucl.ac.uk>
Message-ID: <CAASFQpRDD3vRZQrZ9ye38A6Vya2bniiiFy5YEacH_z8Fvv7zNA@mail.gmail.com>

For Completeness:

This was what I suggested to Kimon-Vincent, offline, as I felt quite
uncertain as to my input.

Kimon-Vincent,

I write off list because perhaps my suggestion is just too stupid and I
don't want to further solidify my reputation for 'stupid' suggestions. But
it seems to me, taking Roger's RANN suggestion in mind, that the test for
E, be taken, not just at the end, as in the ABCDE approach the paper
suggests, but upon selection of each C, prior to adding to a list of
successful (non-intersecting) edges using (rgeos) gIntersection upon a
candidate back against an existing list, prior to appending to said list.
Should it fail, next C. I need to give some more thought to what is meant
by D (though it seems to suggest a limit of neighbors, I'd have to read the
paper),do D, and finally E again as non-intersecting confirmatory.

And look back at your repeat{, (which I find quite interesting anyway) and
figure out how to vectorize using some apply family as this should greatly
reduce computation time. Flow control is useful, but teasing apart the
exact vector steps and the order you want them applied, while puzzling,
should remove your computation time bottlenecks. I'm not expert enough at
this time to advise.

Sorry if all of this seems silly.


On Tue, Oct 18, 2016 at 10:16 PM, Krenz, Kimon-Vincent <
kimon-vincent.krenz.12 at ucl.ac.uk> wrote:

> Dear Chris,
>
> Thanks a lot for your input and suggestion. It took me a while to fiddle
> my way through it, but I followed your logic, which I believe is probably
> the best way to go.
>
> Using RANN I randomly sampled a data.frame with possible combinations
> meeting the distance requirement, of which I then read
> the first row and remove it from the list. Then I created a line pair,
> tested if it intersects with existing lines and if not added it to the line
> list. After this the process starts form the beginning until there are no
> pair combinations int he data.frame list.
>
> I did not use the gIntersect as I felt crossing.psp() was easier to
> handle. However, the process for 50000 lines takes roughly half an hour. So
> roughly 20 hours.
>
> In case you have an idea to speed up the process let me know! I have
> attached the code at the bottom.
>
> Best,
> Kimon
>
> Kimon Krenz
>
> PhD Researcher
> MSc SDAC Course Coordinator
> <http://www.bartlett.ucl.ac.uk/space-syntax/programmes/mres-msc/msc-spatial-design>
> Space Syntax Laboratory <http://www.bartlett.ucl.ac.uk/space-syntax>
>
> mail.       ucftkr3 at ucl.ac.uk
> phone.    0044 7784 329089
> web.       www.kimonkrenz.com
>
> Bartlett School of Architecture <http://www.bartlett.ucl.ac.uk/>
> UCL
> 140 Hampstead Road
> London     NW1 2BX     UK
>
> require(spatstat)
> require(maps)
> library(sp)
> #set coordinate frame
> w <- as.owin(list(xrange=c(32275175,32475175),yrange=c(5611910,5811910)))
> #generate poisson distribution point set (0.000025 for 1million points)
> Y <- rpoispp(0.0000001, win=w)
> Ydata <- data.frame(Y)
> list(Y)
>
> #create k nearest neighbour matrix of points
> require(RANN)
> #radius <- 5000
> #NN1 <- nn2(Ydata, k=10,  treetype = c("bd"), searchtype="radius", radius
> = radius)
> NN1 <- nn2(Ydata, k=30,  treetype = c("bd"), searchtype="standard")
> #delete first collumn
> NN1$nn.idx <- NN1$nn.idx[,-1]
> NN1$nn.dists <- NN1$nn.dists[,-1]
>
> #rearrange matrix from column to rows
> require(reshape2)
> NN2 <- melt(NN1$nn.idx)
> NN3 <- melt(NN1$nn.dists)
> #merge matrices together
> NN4 <- cbind(NN2,NN3)
> #remove unecessary columns
> NN5 <- NN4[ -c(2,4:5)]
> rm(NN2, NN3, NN4)
> #remove point pairs with a longer distance than x
> NN5 <- NN5[NN5$value.1 <= 5000, ]
>
> require(plyr)
> #change column name
> NN5 <- rename(NN5, c("Var1"="p1", "value"="p2", "value.1"="length"))
> #as data frame
> NN6 <- data.frame(NN5)
> #create logic
> NN6$Dup <- NN6$p1 < NN6$p2
> #subset data based on logic
> NN7 <- NN6[NN6$Dup == TRUE,]
> NN8 <- NN6[NN6$Dup == FALSE,]
> #swap columns
> NN8 <- rename(NN8, c("p1"="p2", "p2"="p1", "length"="length"))
> NN9 <- rbind(NN7,NN8)
> #remove logic column
> NN9 <- NN9[-c(4)]
> #remove duplicate
> rm(NN5, NN6, NN7, NN8)
> NN10 <- NN9[!duplicated(NN9), ]
> rm(NN9)
> #Reindex row names
> row.names(NN10) <- 1:nrow(NN10)
> #drop distance column
> NN10 <- NN10[,-3]
>
> require(dplyr)
> NN11 <- sample_n(NN10, 2000000, replace=F)
> NN13 <- NN11[!duplicated(NN11), ]
> rm(NN11)
>
> #split file into several sub data.frame for faster computation
> #n <- 50000
> #nr <- nrow(NN12)
> #NN13 <- split(NN12, rep(1:ceiling(nr/n), each=n, length.out=nr))
>
>
>
> #FIRST LINE
> l1 <- NN13[1, ]
> NN13 <- NN13[-1,]
> l1 <- c(t(l1))
> #read l1 from poisson point set
> Ydata2 <- Ydata[l1, c('x','y')]
> #divide into two point sets
> Z1 <- Ydata2[1,]
> Z2 <- Ydata2[2,]
> #create Line Segment Pattern
> Z <- psp(Z1[1, 1], Z1[1, 2], Z2[1, 1], Z2[1, 2], window=owin(w))
>
> #LOOP START
> repeat {
>   l1 <- NN13[1, ]
>   NN13 <- NN13[-1, ]
>   l1 <- c(t(l1))
>   #read l1 from poisson point set
>   Ydata2 <- Ydata[l1, c('x','y')]
>   #divide into two point sets
>   Z1 <- Ydata2[1,]
>   Z2 <- Ydata2[2,]
>   #create Line Segment Pattern
>   H <- psp(Z1[1, 1], Z1[1, 2], Z2[1, 1], Z2[1, 2], window=owin(w))
>   #intersecting lines check
>   J <- crossing.psp(Z,H,fatal=TRUE,details=FALSE)
>
>   H1 <- as.vector(H$ends, mode="numeric")
>   J$x <- setdiff(J$x, H1)
>   J$y <- setdiff(J$y, H1)
>   J$y1 <- data.frame(J$y)
>   J$x1 <- data.frame(J$x)
>   J$Ally <- count(J$y1)
>   J$Allx <- count(J$x1)
>
>   if ( J$Ally == 0 & J$Allx == 0 ) { Z <- append.psp(Z,H) }
>   else
>     if ( nrow(NN13)==0 ) { break }
>   else
>   { }
> }
>
>
> plot(owin(w))
> plot(Z, add=TRUE)
> detach("package:dplyr", unload=TRUE)
>
>
>
> On 06 Oct 2016, at 15:58, chris english <englishchristophera at gmail.com>
> wrote:
>
> Kimon-Vincent,
>
> I write off list because perhaps my suggestion is just too stupid and I
> don't want to further solidify my reputation for 'stupid' suggestions. But
> it seems to me, taking Roger's RANN suggestion in mind, that the test for
> E, be taken, not just at the end, as in the ABCDE approach the paper
> suggests, but upon selection of each C, prior to adding to a list of
> successful (non-intersecting) edges using (rgeos) gIntersection upon a
> candidate back against an existing list, prior to appending to said list.
> Should it fail, next C. I need to give some more thought to what is meant
> by D (though it seems to suggest a limit of neighbors, I'd have to read the
> paper),do D, and finally E again as non-intersecting confirmatory.
>
> And look back at your repeat{, (which I find quite interesting anyway) and
> figure out how to vectorize using some apply family as this should greatly
> reduce computation time. Flow control is useful, but teasing apart the
> exact vector steps and the order you want them applied, while puzzling,
> should remove your computation time bottlenecks. I'm not expert enough at
> this time to advise.
>
> Sorry if all of this seems silly.
>
> Chris
>
> On Wed, Oct 5, 2016 at 11:43 PM, Krenz, Kimon-Vincent <kimon-vincent.
> krenz.12 at ucl.ac.uk> wrote:
>
>> Dear All,
>>
>> I started a week ago to use R to solve a problem I am currently facing in
>> my PhD.
>> Apologies in advance for the long-winded explanation of my problem.
>>
>> I am trying to generate a random planar graph with approximately 1
>> million edges, where:
>>
>> A) nodes (points) feature spatial coordinates
>> B) the network has a given boundary
>>
>> C) edges (lines) are created if two points fall within a given distance
>> (e.g. 100 - 1000 metres)
>> D) degree (connectivity) ranges between given k max and min (e.g. k ? 5)
>> E) edges do not intersect
>>
>> This will result in something one might want to compare to a random
>> street network.
>>
>> I am following a method proposed here: Masucci, A. P., Smith, D., Crooks,
>> A., & Batty, M. (2009). Random planar graphs and the London street network.
>> European Physical Journal B, 71(2), 259?271. http://doi.org/10.
>> 1140/epjb/e2009-00290-4) link to paper: https://goo.gl/6XWW8P
>>
>> Masucci et al.: "We first introduce a random model for a static planar
>> graph. ... To build an ERPG we start with a Poisson distribution of N
>> points in a plane and we choose a distance r. To build the first segment,
>> we randomly pick up two points of the distribution that have a distance
>> less then r and we connect them. Then we continue to randomly pick up pairs
>> of points P and Q in the given points distribution that have a distance
>> less then r. If the segment PQ does not intersect any other line of the
>> graph, we add it to the graph. The process ends when we add the desired
>> number of edges E.?
>>
>> I hence, started with generating random points using the Poisson
>> distribution in a given spatial box (A and A):
>>
>> require(spatstat)
>> require(maps)
>> library(sp)
>> w <- as.owin(list(xrange=c(32275175,32475175),yrange=c(5611910,5811910)))
>> Y <- rpoispp(0.00001, win=w)
>> Ydata <- data.frame(Y)
>> list(Y)
>>
>> That seems to be quite straightforward in R.
>> I then followed the proposed method and wrote a simple loop, that selects
>> two points from Ydata
>> based on a random sample and adds the projection of the coordinate system.
>>
>> #399717 is = N from the rpoispp
>>
>> repeat {
>>   l1 <- sample(1:399717, 2, replace=F)
>>
>>  Ydata.sp<-Ydata[l1, c('x','y')]
>>   coordinates(Ydata.sp)<-~x+y
>>   crs.geo <- CRS("+init=epsg:4647 +proj=tmerc +lat_0=0 +lon_0=9 +k=0.9996
>> +x_0=32500000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")
>>   proj4string(Ydata.sp) <- crs.geo
>>
>>   L = SpatialLines(list(Lines(list(Line(coordinates(Ydata.sp))),"X")))
>>   if (SpatialLinesLengths(L)<=4000){
>>     break
>>   }
>> }
>> plot(L)
>> SpatialLinesLengths(L)
>>
>> This fulfils the requirement of C) and I have not yet reached the point
>> to deal with D) and E).
>> My problem here is that the process takes way too long for a single pair
>> (approx 20 seconds, resulting in 250 days computational time).
>>
>> Is there a quicker way solve this in a more efficient manner?
>>
>> I have thought about selecting the first point by random and the second
>> one randomly based on an evaluation
>> of all points within a given radius to the first point, rather than two
>> complete random points.
>>
>> This would at least cut down the test of several thousand meaningless
>> combinations. However, I couldn't find a way to do this.
>> Another option might be gDistance from the (rgeos), but with 400k points,
>> the result seems to be not computable.
>>
>> I am also happy for any suggestions regarding requirements D and E, or
>> help with the task in general.
>>
>> Best,
>> Kimon
>>
>> Kimon Krenz
>>
>> PhD Researcher
>> MSc SDAC Course Coordinator<http://www.bartlett.ucl.ac.uk/space-syntax/
>> programmes/mres-msc/msc-spatial-design>
>> Space Syntax Laboratory<http://www.bartlett.ucl.ac.uk/space-syntax>
>>
>> mail.       ucftkr3 at ucl.ac.uk<mailto:ucftkr3 at ucl.ac.uk>
>> phone.    0044 7784 329089
>> web.       www.kimonkrenz.com<http://www.kimonkrenz.com/>
>>
>> Bartlett School of Architecture<http://www.bartlett.ucl.ac.uk/>
>> UCL
>> 140 Hampstead Road
>> London     NW1 2BX     UK
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From nick.vandoormaal at gmail.com  Fri Oct 21 10:46:39 2016
From: nick.vandoormaal at gmail.com (Nick van Doormaal)
Date: Fri, 21 Oct 2016 10:46:39 +0200
Subject: [R-sig-Geo] No neighbours in sample using spatcounts package in
	R
In-Reply-To: <CAASFQpT8NbWyycrQEN0=fsu-qk-NQrser+sMGvoQmn_zF80mSg@mail.gmail.com>
References: <CAG0JA8uPYaVOv5wjm6=RWQnkpP1j1_BaqfqC6PuU_9m=C5YwGQ@mail.gmail.com>
	<CAASFQpT8NbWyycrQEN0=fsu-qk-NQrser+sMGvoQmn_zF80mSg@mail.gmail.com>
Message-ID: <CAG0JA8s1d431aXP5f4VpHVM_78T+ZEsZdm+k+xELB=S7z3n+Ng@mail.gmail.com>

Hi Chris,

Thank you very much for your time and effort to help me out. Much
appreciated!
When I checked the structure of the example dataset, it seems that all the
variables are numerical. That's why I thought that replacing all the NAs
with 0s would be an okay way.

library(spatcounts)
data(sim.nmat)
str(sim.nmat)
'data.frame':   100 obs. of  6 variables:
 $ V1: num  1 2 3 4 5 6 7 8 9 10 ...
 $ V2: num  11 12 13 14 15 16 17 18 19 20 ...
 $ V3: num  2 1 2 3 4 5 6 7 8 9 ...
 $ V4: num  0 3 4 5 6 7 8 9 10 0 ...
 $ V5: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V6: num  2 3 3 3 3 3 3 3 3 2 ...

str(n.temp)
'data.frame':   63 obs. of  6 variables:
 $ V1: num  1 2 7 13 14 16 19 20 21 22 ...
 $ V2: num  1 1 1 1 1 1 1 1 1 1 ...
 $ V3: num  2 1 1 23 1 26 1 30 31 32 ...
 $ V4: num  1 1 1 1 13 1 1 19 22 21 ...
 $ V5: num  1 1 1 14 1 1 20 1 1 23 ...
 $ V6: num  1 1 0 2 1 1 1 2 2 3 ...

I think it has something to do with the combination of nmat (ntemp) and
gmat (gtemp)...but I can't really figure out how or why.

On 20 October 2016 at 12:20, chris english <englishchristophera at gmail.com>
wrote:

> Nick,
>
> I get the same error running your code.
>
> set.seed(987654321)
>
> library(spatcounts)
> data("sim.Yin")
> data("sim.fm.X")
> data("sim.gmat")
> data("sim.nmat")
> data("sim.region")
> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
> colnames(AllData)[1:2] <- c("Yin", "Region")
>
> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
> newdata.df <- AllData[idx,]
> newdata.df <- newdata.df[order(newdata.df$Region),]
> X <- as.data.frame(newdata.df[,3:4])
> region <- as.data.frame(newdata.df$Region)
> colnames(region) <- "V1"
> Yin <- as.data.frame(newdata.df$Yin)
>
> temp.idx <- sort(unique(newdata.df$Region))
> g.temp <- sim.gmat[temp.idx,temp.idx]
>
> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT
> > is.element(0, n.temp$V6)
> [1] TRUE # after a few run thru's of idx to is.element
>
> n.temp <- sim.nmat[temp.idx,]
> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
> n.temp$V6 <- TotalN
>
> > class(n.temp$V1)
> [1] "numeric"
> > class(n.temp$V2)
> [1] "integer"
> > class(n.temp$V3)
> [1] "integer"
> > class(n.temp$V4)
> [1] "integer"
> > class(n.temp$V5)
> [1] "integer"
> > class(n.temp$V6)
> [1] "numeric"
>
> # here, essentially checking what NA might be replaced with by class
> # and wondering if a small numeric is desirable (0.001), $V1 & $v6
> # and your 0 for integers ($V2-V5)
>
> Well, a bunch of different tries and the error persists.
>
> > n.temp[is.na(n.temp)] <- 1
> > n.temp$V6[7] <- 10
> > n.temp$V6[24] <- 10
> > n.temp$V6[28] <- 0.001
> >
> > n.temp$V6[28] <- 10
>
> > which(n.temp$V6 == 0)
> integer(0)
>
>
> > Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
> + region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
> Error: NA/NaN/Inf in foreign function call (arg 1)
>
> So, i guess i'd do a debugonce(est.sc) and find out which foreign
> function is disappointing or
> disappointed by the inputs, but the culprit does not appear to be TotalN.
>
> HTH,
>
> Chris
>
>
>
> On Wed, Oct 19, 2016 at 4:01 PM, Nick van Doormaal <
> nick.vandoormaal at gmail.com> wrote:
>
>> Dear list members,
>>
>> I'm trying to do a bootstrap of a spatial count model using the
>> *spatcounts-package* in R. However, resampling with replacement may lead
>> to
>> "islands", because sometimes no neighbors will be selected. I believe this
>> is causing the error message: Error: NA/NaN/Inf in foreign function call
>> (arg 1). Can somebody confirm this if this indeed the case? If so, is
>> there
>> a way to get around it, so that I would still be able to carry out a
>> bootstrap?
>>
>> Please find below the code to recreate the problem using the example
>> dataset of the spatcounts package.
>>
>> Thank you for your time and I hope somebody can help me out a bit.
>>
>> ####START CODE#####
>> set.seed(987654321)
>>
>> library(spatcounts)
>>
>> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
>> colnames(AllData)[1:2] <- c("Yin", "Region")
>>
>> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
>> newdata.df <- AllData[idx,]
>> newdata.df <- newdata.df[order(newdata.df$Region),]
>> X <- as.data.frame(newdata.df[,3:4])
>> region <- as.data.frame(newdata.df$Region)
>> colnames(region) <- "V1"
>> Yin <- as.data.frame(newdata.df$Yin)
>>
>> temp.idx <- sort(unique(newdata.df$Region))
>> g.temp <- sim.gmat[temp.idx,temp.idx]
>>
>> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT IN THIS
>> VECTOR.##OTHERWISE RUN AGAIN UNTIL AT LEAST ONE ZERO
>>
>> n.temp <- sim.nmat[temp.idx,]
>> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
>> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
>> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
>> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
>> n.temp$V6 <- TotalN
>>
>> n.temp[is.na(n.temp)] <- 0
>>
>> Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
>> region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Fri Oct 21 13:32:02 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Fri, 21 Oct 2016 11:32:02 +0000
Subject: [R-sig-Geo] Access to google drive account using RGoogleDocs
In-Reply-To: <HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>,
	<BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>,
	<HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>
Message-ID: <HE1PR04MB1161E56ED2E39051A86EF0A6B3D40@HE1PR04MB1161.eurprd04.prod.outlook.com>

Hi folks,

I'm not sure if this topic could be appropriate here as it is not properly geostatistical but maybe someone could help me

I have a shared space on google drive with some colleagues; I would like to access there from R and to list files in the folders and eventually to load some data into R.

I know that RGoogleDocs package allows it but it seems not working when I try to login using

auth = getGoogleAuth("mygmail at gmail.com","mypasword",service="wise")
I have:
"Error: not found"

I found an old post where other people experienced the same problem but a solution was not present there.
Maybe there are other packages such as googlesheets but my primary purpose is to list files present in the folder.
Anyway...thanks in advance for any hint
All the best
Paolo



	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Fri Oct 21 14:06:38 2016
From: englishchristophera at gmail.com (chris english)
Date: Fri, 21 Oct 2016 05:06:38 -0700
Subject: [R-sig-Geo] No neighbours in sample using spatcounts package in
	R
In-Reply-To: <CAG0JA8s1d431aXP5f4VpHVM_78T+ZEsZdm+k+xELB=S7z3n+Ng@mail.gmail.com>
References: <CAG0JA8uPYaVOv5wjm6=RWQnkpP1j1_BaqfqC6PuU_9m=C5YwGQ@mail.gmail.com>
	<CAASFQpT8NbWyycrQEN0=fsu-qk-NQrser+sMGvoQmn_zF80mSg@mail.gmail.com>
	<CAG0JA8s1d431aXP5f4VpHVM_78T+ZEsZdm+k+xELB=S7z3n+Ng@mail.gmail.com>
Message-ID: <CAASFQpQcjfe7SjDLdoJOrAdCaU0s0BUdvhx7VXOZ1eqQ=N=wXw@mail.gmail.com>

Nick,

Perhaps a pitch it to the maintainer and report back here? I was just
fooling around and it was the
structure of n.temp that was driving my approach, but each input finds its
way in thru the formula. Still
haven't had time to run this thru debugonce() as i am trying to flee a
non-country, god help me, with dogs.
And, where I know this actually does't help much, I'll try to look at it
later. Have to get off the turkish keyboard and
back to my own machine/

Chris



On Fri, Oct 21, 2016 at 1:46 AM, Nick van Doormaal <
nick.vandoormaal at gmail.com> wrote:

> Hi Chris,
>
> Thank you very much for your time and effort to help me out. Much
> appreciated!
> When I checked the structure of the example dataset, it seems that all the
> variables are numerical. That's why I thought that replacing all the NAs
> with 0s would be an okay way.
>
> library(spatcounts)
> data(sim.nmat)
> str(sim.nmat)
> 'data.frame':   100 obs. of  6 variables:
>  $ V1: num  1 2 3 4 5 6 7 8 9 10 ...
>  $ V2: num  11 12 13 14 15 16 17 18 19 20 ...
>  $ V3: num  2 1 2 3 4 5 6 7 8 9 ...
>  $ V4: num  0 3 4 5 6 7 8 9 10 0 ...
>  $ V5: num  0 0 0 0 0 0 0 0 0 0 ...
>  $ V6: num  2 3 3 3 3 3 3 3 3 2 ...
>
> str(n.temp)
> 'data.frame':   63 obs. of  6 variables:
>  $ V1: num  1 2 7 13 14 16 19 20 21 22 ...
>  $ V2: num  1 1 1 1 1 1 1 1 1 1 ...
>  $ V3: num  2 1 1 23 1 26 1 30 31 32 ...
>  $ V4: num  1 1 1 1 13 1 1 19 22 21 ...
>  $ V5: num  1 1 1 14 1 1 20 1 1 23 ...
>  $ V6: num  1 1 0 2 1 1 1 2 2 3 ...
>
> I think it has something to do with the combination of nmat (ntemp) and
> gmat (gtemp)...but I can't really figure out how or why.
>
> On 20 October 2016 at 12:20, chris english <englishchristophera at gmail.com>
> wrote:
>
>> Nick,
>>
>> I get the same error running your code.
>>
>> set.seed(987654321)
>>
>> library(spatcounts)
>> data("sim.Yin")
>> data("sim.fm.X")
>> data("sim.gmat")
>> data("sim.nmat")
>> data("sim.region")
>> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
>> colnames(AllData)[1:2] <- c("Yin", "Region")
>>
>> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
>> newdata.df <- AllData[idx,]
>> newdata.df <- newdata.df[order(newdata.df$Region),]
>> X <- as.data.frame(newdata.df[,3:4])
>> region <- as.data.frame(newdata.df$Region)
>> colnames(region) <- "V1"
>> Yin <- as.data.frame(newdata.df$Yin)
>>
>> temp.idx <- sort(unique(newdata.df$Region))
>> g.temp <- sim.gmat[temp.idx,temp.idx]
>>
>> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT
>> > is.element(0, n.temp$V6)
>> [1] TRUE # after a few run thru's of idx to is.element
>>
>> n.temp <- sim.nmat[temp.idx,]
>> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
>> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
>> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
>> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
>> n.temp$V6 <- TotalN
>>
>> > class(n.temp$V1)
>> [1] "numeric"
>> > class(n.temp$V2)
>> [1] "integer"
>> > class(n.temp$V3)
>> [1] "integer"
>> > class(n.temp$V4)
>> [1] "integer"
>> > class(n.temp$V5)
>> [1] "integer"
>> > class(n.temp$V6)
>> [1] "numeric"
>>
>> # here, essentially checking what NA might be replaced with by class
>> # and wondering if a small numeric is desirable (0.001), $V1 & $v6
>> # and your 0 for integers ($V2-V5)
>>
>> Well, a bunch of different tries and the error persists.
>>
>> > n.temp[is.na(n.temp)] <- 1
>> > n.temp$V6[7] <- 10
>> > n.temp$V6[24] <- 10
>> > n.temp$V6[28] <- 0.001
>> >
>> > n.temp$V6[28] <- 10
>>
>> > which(n.temp$V6 == 0)
>> integer(0)
>>
>>
>> > Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
>> + region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
>> Error: NA/NaN/Inf in foreign function call (arg 1)
>>
>> So, i guess i'd do a debugonce(est.sc) and find out which foreign
>> function is disappointing or
>> disappointed by the inputs, but the culprit does not appear to be TotalN.
>>
>> HTH,
>>
>> Chris
>>
>>
>>
>> On Wed, Oct 19, 2016 at 4:01 PM, Nick van Doormaal <
>> nick.vandoormaal at gmail.com> wrote:
>>
>>> Dear list members,
>>>
>>> I'm trying to do a bootstrap of a spatial count model using the
>>> *spatcounts-package* in R. However, resampling with replacement may lead
>>> to
>>> "islands", because sometimes no neighbors will be selected. I believe
>>> this
>>> is causing the error message: Error: NA/NaN/Inf in foreign function call
>>> (arg 1). Can somebody confirm this if this indeed the case? If so, is
>>> there
>>> a way to get around it, so that I would still be able to carry out a
>>> bootstrap?
>>>
>>> Please find below the code to recreate the problem using the example
>>> dataset of the spatcounts package.
>>>
>>> Thank you for your time and I hope somebody can help me out a bit.
>>>
>>> ####START CODE#####
>>> set.seed(987654321)
>>>
>>> library(spatcounts)
>>>
>>> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
>>> colnames(AllData)[1:2] <- c("Yin", "Region")
>>>
>>> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
>>> newdata.df <- AllData[idx,]
>>> newdata.df <- newdata.df[order(newdata.df$Region),]
>>> X <- as.data.frame(newdata.df[,3:4])
>>> region <- as.data.frame(newdata.df$Region)
>>> colnames(region) <- "V1"
>>> Yin <- as.data.frame(newdata.df$Yin)
>>>
>>> temp.idx <- sort(unique(newdata.df$Region))
>>> g.temp <- sim.gmat[temp.idx,temp.idx]
>>>
>>> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT IN THIS
>>> VECTOR.##OTHERWISE RUN AGAIN UNTIL AT LEAST ONE ZERO
>>>
>>> n.temp <- sim.nmat[temp.idx,]
>>> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
>>> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
>>> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
>>> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
>>> n.temp$V6 <- TotalN
>>>
>>> n.temp[is.na(n.temp)] <- 0
>>>
>>> Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
>>> region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From jacek.stefaniak at gmail.com  Fri Oct 21 14:41:07 2016
From: jacek.stefaniak at gmail.com (Jacek Stefaniak)
Date: Fri, 21 Oct 2016 14:41:07 +0200
Subject: [R-sig-Geo] vulnerability mapping
In-Reply-To: <CAHMizkMvOKN8jkKGO6Zup46uUiyoGpTEFin9XJVuWBw+iv_SFw@mail.gmail.com>
References: <CAHMizkMvOKN8jkKGO6Zup46uUiyoGpTEFin9XJVuWBw+iv_SFw@mail.gmail.com>
Message-ID: <CAMNc56CJb7-4HFQY+e_VeqRKauEJBR=FOPmZaBZVXVBeXxW7og@mail.gmail.com>

Hi,

Honestly speaking I do not have clear idea what you will plan to do. You
want to just create map with highlighted areas showing hypothetical "better
conditions" for riots, or you want to use a model for finding such areas
and explore potential variables causing higher risk? In any of this two
cases, you will need slightly different data and approach... Can you care
to elaborate?

PS: Mo?esz napisa? do mnie po polsku na prywatny adres, je?li tak Ci jest
?atwiej ;)

	[[alternative HTML version deleted]]


From tcorms at gmail.com  Fri Oct 21 14:59:18 2016
From: tcorms at gmail.com (Tina Cormier)
Date: Fri, 21 Oct 2016 08:59:18 -0400
Subject: [R-sig-Geo] vulnerability mapping
In-Reply-To: <CAMNc56CJb7-4HFQY+e_VeqRKauEJBR=FOPmZaBZVXVBeXxW7og@mail.gmail.com>
References: <CAHMizkMvOKN8jkKGO6Zup46uUiyoGpTEFin9XJVuWBw+iv_SFw@mail.gmail.com>
	<CAMNc56CJb7-4HFQY+e_VeqRKauEJBR=FOPmZaBZVXVBeXxW7og@mail.gmail.com>
Message-ID: <CAFfx769kMJxaKjDH3rJ61p3mtyAhLehMwjRx++7Ydd7caEd9YA@mail.gmail.com>

Hi Juta,

It seems to me that what you have are potential predictors of riots. I
think you'll also need some riot location data - that is, if you are trying
to model vulnerability (as Jacek said) to identify important variables. If
you are just trying to create a map that shows potential areas (without
modeling - as in, you already KNOW that these are good predictors), then I
would probably do something simple, like create a ranking system for
socioeconomic status and distance from malls - add them together to ID hot
spots. Without knowing your goal, it's probably not worth going into too
much detail on those methods, but I would start by interpolating a raster
that shows distance to malls (ranked), and combine with census rankings. It
seems to me these two predictors alone are not sufficient, but if that's
what you're going with, this would be my simple approach.

Good luck!
Tina

On Fri, Oct 21, 2016 at 8:41 AM, Jacek Stefaniak <jacek.stefaniak at gmail.com>
wrote:

> Hi,
>
> Honestly speaking I do not have clear idea what you will plan to do. You
> want to just create map with highlighted areas showing hypothetical "better
> conditions" for riots, or you want to use a model for finding such areas
> and explore potential variables causing higher risk? In any of this two
> cases, you will need slightly different data and approach... Can you care
> to elaborate?
>
> PS: Mo?esz napisa? do mnie po polsku na prywatny adres, je?li tak Ci jest
> ?atwiej ;)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From nick.vandoormaal at gmail.com  Fri Oct 21 15:03:05 2016
From: nick.vandoormaal at gmail.com (Nick van Doormaal)
Date: Fri, 21 Oct 2016 15:03:05 +0200
Subject: [R-sig-Geo] No neighbours in sample using spatcounts package in
	R
In-Reply-To: <CAASFQpQcjfe7SjDLdoJOrAdCaU0s0BUdvhx7VXOZ1eqQ=N=wXw@mail.gmail.com>
References: <CAG0JA8uPYaVOv5wjm6=RWQnkpP1j1_BaqfqC6PuU_9m=C5YwGQ@mail.gmail.com>
	<CAASFQpT8NbWyycrQEN0=fsu-qk-NQrser+sMGvoQmn_zF80mSg@mail.gmail.com>
	<CAG0JA8s1d431aXP5f4VpHVM_78T+ZEsZdm+k+xELB=S7z3n+Ng@mail.gmail.com>
	<CAASFQpQcjfe7SjDLdoJOrAdCaU0s0BUdvhx7VXOZ1eqQ=N=wXw@mail.gmail.com>
Message-ID: <CAG0JA8scSgxLUsBRak+8a6h9Fo6RGGUqGrerDAy=MvGXNYYz_Q@mail.gmail.com>

Thanks again for all your time Chris!
I did email the maintainer, Vinzenz Erhardt, a couple of days ago but no
reply from him. I scraped his email from some webpage because the
email-address mentioned in the spatcounts-package is not working.

All the best and good luck fleeing the non-country!

On 21 October 2016 at 14:06, chris english <englishchristophera at gmail.com>
wrote:

> Nick,
>
> Perhaps a pitch it to the maintainer and report back here? I was just
> fooling around and it was the
> structure of n.temp that was driving my approach, but each input finds its
> way in thru the formula. Still
> haven't had time to run this thru debugonce() as i am trying to flee a
> non-country, god help me, with dogs.
> And, where I know this actually does't help much, I'll try to look at it
> later. Have to get off the turkish keyboard and
> back to my own machine/
>
> Chris
>
>
>
> On Fri, Oct 21, 2016 at 1:46 AM, Nick van Doormaal <
> nick.vandoormaal at gmail.com> wrote:
>
>> Hi Chris,
>>
>> Thank you very much for your time and effort to help me out. Much
>> appreciated!
>> When I checked the structure of the example dataset, it seems that all
>> the variables are numerical. That's why I thought that replacing all the
>> NAs with 0s would be an okay way.
>>
>> library(spatcounts)
>> data(sim.nmat)
>> str(sim.nmat)
>> 'data.frame':   100 obs. of  6 variables:
>>  $ V1: num  1 2 3 4 5 6 7 8 9 10 ...
>>  $ V2: num  11 12 13 14 15 16 17 18 19 20 ...
>>  $ V3: num  2 1 2 3 4 5 6 7 8 9 ...
>>  $ V4: num  0 3 4 5 6 7 8 9 10 0 ...
>>  $ V5: num  0 0 0 0 0 0 0 0 0 0 ...
>>  $ V6: num  2 3 3 3 3 3 3 3 3 2 ...
>>
>> str(n.temp)
>> 'data.frame':   63 obs. of  6 variables:
>>  $ V1: num  1 2 7 13 14 16 19 20 21 22 ...
>>  $ V2: num  1 1 1 1 1 1 1 1 1 1 ...
>>  $ V3: num  2 1 1 23 1 26 1 30 31 32 ...
>>  $ V4: num  1 1 1 1 13 1 1 19 22 21 ...
>>  $ V5: num  1 1 1 14 1 1 20 1 1 23 ...
>>  $ V6: num  1 1 0 2 1 1 1 2 2 3 ...
>>
>> I think it has something to do with the combination of nmat (ntemp) and
>> gmat (gtemp)...but I can't really figure out how or why.
>>
>> On 20 October 2016 at 12:20, chris english <englishchristophera at gmail.com
>> > wrote:
>>
>>> Nick,
>>>
>>> I get the same error running your code.
>>>
>>> set.seed(987654321)
>>>
>>> library(spatcounts)
>>> data("sim.Yin")
>>> data("sim.fm.X")
>>> data("sim.gmat")
>>> data("sim.nmat")
>>> data("sim.region")
>>> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
>>> colnames(AllData)[1:2] <- c("Yin", "Region")
>>>
>>> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
>>> newdata.df <- AllData[idx,]
>>> newdata.df <- newdata.df[order(newdata.df$Region),]
>>> X <- as.data.frame(newdata.df[,3:4])
>>> region <- as.data.frame(newdata.df$Region)
>>> colnames(region) <- "V1"
>>> Yin <- as.data.frame(newdata.df$Yin)
>>>
>>> temp.idx <- sort(unique(newdata.df$Region))
>>> g.temp <- sim.gmat[temp.idx,temp.idx]
>>>
>>> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT
>>> > is.element(0, n.temp$V6)
>>> [1] TRUE # after a few run thru's of idx to is.element
>>>
>>> n.temp <- sim.nmat[temp.idx,]
>>> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
>>> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
>>> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
>>> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
>>> n.temp$V6 <- TotalN
>>>
>>> > class(n.temp$V1)
>>> [1] "numeric"
>>> > class(n.temp$V2)
>>> [1] "integer"
>>> > class(n.temp$V3)
>>> [1] "integer"
>>> > class(n.temp$V4)
>>> [1] "integer"
>>> > class(n.temp$V5)
>>> [1] "integer"
>>> > class(n.temp$V6)
>>> [1] "numeric"
>>>
>>> # here, essentially checking what NA might be replaced with by class
>>> # and wondering if a small numeric is desirable (0.001), $V1 & $v6
>>> # and your 0 for integers ($V2-V5)
>>>
>>> Well, a bunch of different tries and the error persists.
>>>
>>> > n.temp[is.na(n.temp)] <- 1
>>> > n.temp$V6[7] <- 10
>>> > n.temp$V6[24] <- 10
>>> > n.temp$V6[28] <- 0.001
>>> >
>>> > n.temp$V6[28] <- 10
>>>
>>> > which(n.temp$V6 == 0)
>>> integer(0)
>>>
>>>
>>> > Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
>>> + region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
>>> Error: NA/NaN/Inf in foreign function call (arg 1)
>>>
>>> So, i guess i'd do a debugonce(est.sc) and find out which foreign
>>> function is disappointing or
>>> disappointed by the inputs, but the culprit does not appear to be TotalN.
>>>
>>> HTH,
>>>
>>> Chris
>>>
>>>
>>>
>>> On Wed, Oct 19, 2016 at 4:01 PM, Nick van Doormaal <
>>> nick.vandoormaal at gmail.com> wrote:
>>>
>>>> Dear list members,
>>>>
>>>> I'm trying to do a bootstrap of a spatial count model using the
>>>> *spatcounts-package* in R. However, resampling with replacement may
>>>> lead to
>>>> "islands", because sometimes no neighbors will be selected. I believe
>>>> this
>>>> is causing the error message: Error: NA/NaN/Inf in foreign function call
>>>> (arg 1). Can somebody confirm this if this indeed the case? If so, is
>>>> there
>>>> a way to get around it, so that I would still be able to carry out a
>>>> bootstrap?
>>>>
>>>> Please find below the code to recreate the problem using the example
>>>> dataset of the spatcounts package.
>>>>
>>>> Thank you for your time and I hope somebody can help me out a bit.
>>>>
>>>> ####START CODE#####
>>>> set.seed(987654321)
>>>>
>>>> library(spatcounts)
>>>>
>>>> AllData <- cbind(sim.Yin, sim.region, sim.fm.X)
>>>> colnames(AllData)[1:2] <- c("Yin", "Region")
>>>>
>>>> idx <- sample(1:nrow(AllData), 100, replace=TRUE)
>>>> newdata.df <- AllData[idx,]
>>>> newdata.df <- newdata.df[order(newdata.df$Region),]
>>>> X <- as.data.frame(newdata.df[,3:4])
>>>> region <- as.data.frame(newdata.df$Region)
>>>> colnames(region) <- "V1"
>>>> Yin <- as.data.frame(newdata.df$Yin)
>>>>
>>>> temp.idx <- sort(unique(newdata.df$Region))
>>>> g.temp <- sim.gmat[temp.idx,temp.idx]
>>>>
>>>> TotalN <- rowSums(g.temp) ##CHECK IF THERE ARE ZEROS PRESENT IN THIS
>>>> VECTOR.##OTHERWISE RUN AGAIN UNTIL AT LEAST ONE ZERO
>>>>
>>>> n.temp <- sim.nmat[temp.idx,]
>>>> n.temp$V2 <- temp.idx[match(n.temp$V2, temp.idx)]
>>>> n.temp$V3 <- temp.idx[match(n.temp$V3, temp.idx)]
>>>> n.temp$V4 <- temp.idx[match(n.temp$V4, temp.idx)]
>>>> n.temp$V5 <- temp.idx[match(n.temp$V5, temp.idx)]
>>>> n.temp$V6 <- TotalN
>>>>
>>>> n.temp[is.na(n.temp)] <- 0
>>>>
>>>> Yin.NB <- est.sc(Yin, ~ X[,1] + X[,2] -1,
>>>> region, model="NB", g.temp, n.temp, totalit=10) ##ERROR
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> _______________________________________________
>>>> R-sig-Geo mailing list
>>>> R-sig-Geo at r-project.org
>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Fri Oct 21 19:55:24 2016
From: englishchristophera at gmail.com (chris english)
Date: Fri, 21 Oct 2016 20:55:24 +0300
Subject: [R-sig-Geo] Access to google drive account using RGoogleDocs
In-Reply-To: <HE1PR04MB1161E56ED2E39051A86EF0A6B3D40@HE1PR04MB1161.eurprd04.prod.outlook.com>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>
	<BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>
	<HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<HE1PR04MB1161E56ED2E39051A86EF0A6B3D40@HE1PR04MB1161.eurprd04.prod.outlook.com>
Message-ID: <CAASFQpSEqfKvzbQbWkJ5UxpDCUvfOQML33V3cBR6YqhXfV0zEA@mail.gmail.com>

Paolo,

I saw your post and was just anticipating sharing some data with colleagues
in New Zealand, and I believe that
between two weeks ago and now, github has changed some Apache Server
settings so that me, sitting in Cyprus can no longer
access, though if I went in through my wife's VPN and appeared to be in
NYC, it might work. So, at the moment
I can't even get into github using devtools to check, but I believe that
your 'error' has to do with your locale 'it' as against where
github servers are and a new filter. I could, of course, be wrong on all
counts, but when I arrive NYC next week I'll
check and report.

I realize that this seems somewhat far afield of your question regarding
RGoogleDocs, but I've been noticing a segmentation
in accessibility in Amazon, Google (at times), and now github which is
completely inaccessible. So perhaps it is a matter of contracting
a VPN service. As I say, I'll check in NY and report.

Chris

On Fri, Oct 21, 2016 at 2:32 PM, Paolo Piras <paolo.piras at uniroma3.it>
wrote:

> Hi folks,
>
> I'm not sure if this topic could be appropriate here as it is not properly
> geostatistical but maybe someone could help me
>
> I have a shared space on google drive with some colleagues; I would like
> to access there from R and to list files in the folders and eventually to
> load some data into R.
>
> I know that RGoogleDocs package allows it but it seems not working when I
> try to login using
>
> auth = getGoogleAuth("mygmail at gmail.com","mypasword",service="wise")
> I have:
> "Error: not found"
>
> I found an old post where other people experienced the same problem but a
> solution was not present there.
> Maybe there are other packages such as googlesheets but my primary purpose
> is to list files present in the folder.
> Anyway...thanks in advance for any hint
> All the best
> Paolo
>
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Fri Oct 21 20:06:21 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 21 Oct 2016 20:06:21 +0200
Subject: [R-sig-Geo] Access to google drive account using RGoogleDocs
In-Reply-To: <CAASFQpSEqfKvzbQbWkJ5UxpDCUvfOQML33V3cBR6YqhXfV0zEA@mail.gmail.com>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>
	<BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>
	<HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<HE1PR04MB1161E56ED2E39051A86EF0A6B3D40@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<CAASFQpSEqfKvzbQbWkJ5UxpDCUvfOQML33V3cBR6YqhXfV0zEA@mail.gmail.com>
Message-ID: <alpine.LFD.2.20.1610212004200.30046@reclus.nhh.no>

It appears that there are ongoing DDOS incidents affecting DNS providers 
and through them the services you mention; see:

https://tech.slashdot.org/story/16/10/21/135241/several-sites-including-twitter-spotify-paypal-nytimes-suffering-outage----dyn-dns-under-ddos-attack-update

so I'd wait until things calm down before drawing conclusions.

Roger

On Fri, 21 Oct 2016, chris english wrote:

> Paolo,
>
> I saw your post and was just anticipating sharing some data with colleagues
> in New Zealand, and I believe that
> between two weeks ago and now, github has changed some Apache Server
> settings so that me, sitting in Cyprus can no longer
> access, though if I went in through my wife's VPN and appeared to be in
> NYC, it might work. So, at the moment
> I can't even get into github using devtools to check, but I believe that
> your 'error' has to do with your locale 'it' as against where
> github servers are and a new filter. I could, of course, be wrong on all
> counts, but when I arrive NYC next week I'll
> check and report.
>
> I realize that this seems somewhat far afield of your question regarding
> RGoogleDocs, but I've been noticing a segmentation
> in accessibility in Amazon, Google (at times), and now github which is
> completely inaccessible. So perhaps it is a matter of contracting
> a VPN service. As I say, I'll check in NY and report.
>
> Chris
>
> On Fri, Oct 21, 2016 at 2:32 PM, Paolo Piras <paolo.piras at uniroma3.it>
> wrote:
>
>> Hi folks,
>>
>> I'm not sure if this topic could be appropriate here as it is not properly
>> geostatistical but maybe someone could help me
>>
>> I have a shared space on google drive with some colleagues; I would like
>> to access there from R and to list files in the folders and eventually to
>> load some data into R.
>>
>> I know that RGoogleDocs package allows it but it seems not working when I
>> try to login using
>>
>> auth = getGoogleAuth("mygmail at gmail.com","mypasword",service="wise")
>> I have:
>> "Error: not found"
>>
>> I found an old post where other people experienced the same problem but a
>> solution was not present there.
>> Maybe there are other packages such as googlesheets but my primary purpose
>> is to list files present in the folder.
>> Anyway...thanks in advance for any hint
>> All the best
>> Paolo
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From englishchristophera at gmail.com  Fri Oct 21 20:19:22 2016
From: englishchristophera at gmail.com (chris english)
Date: Fri, 21 Oct 2016 21:19:22 +0300
Subject: [R-sig-Geo] Access to google drive account using RGoogleDocs
In-Reply-To: <alpine.LFD.2.20.1610212004200.30046@reclus.nhh.no>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>
	<BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>
	<HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<HE1PR04MB1161E56ED2E39051A86EF0A6B3D40@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<CAASFQpSEqfKvzbQbWkJ5UxpDCUvfOQML33V3cBR6YqhXfV0zEA@mail.gmail.com>
	<alpine.LFD.2.20.1610212004200.30046@reclus.nhh.no>
Message-ID: <CAASFQpRgC1iHh-sfnDt+bR+Yz6ekMqK5GVG7n8Tt+rMw7QPKJA@mail.gmail.com>

Roger,

Thank you for this input. I am accustomed to high latency. Though I imagine
that this DDOS on DSN services will escalate through the
the end of the present election and beyond. There's probably an R approach,
in addition to Apache, to dealing with this...

As a completely peculiar aside, my wife decided a year ago that when she
has her fugue state, her last name will be Bivand.
She loves the sound. Best to think forties movies here. Hope you look
something like Charles Boyer, as it will round things out nicely.

Chris

On Fri, Oct 21, 2016 at 9:06 PM, Roger Bivand <Roger.Bivand at nhh.no> wrote:

> It appears that there are ongoing DDOS incidents affecting DNS providers
> and through them the services you mention; see:
>
> https://tech.slashdot.org/story/16/10/21/135241/several-site
> s-including-twitter-spotify-paypal-nytimes-suffering-
> outage----dyn-dns-under-ddos-attack-update
>
> so I'd wait until things calm down before drawing conclusions.
>
> Roger
>
>
> On Fri, 21 Oct 2016, chris english wrote:
>
> Paolo,
>>
>> I saw your post and was just anticipating sharing some data with
>> colleagues
>> in New Zealand, and I believe that
>> between two weeks ago and now, github has changed some Apache Server
>> settings so that me, sitting in Cyprus can no longer
>> access, though if I went in through my wife's VPN and appeared to be in
>> NYC, it might work. So, at the moment
>> I can't even get into github using devtools to check, but I believe that
>> your 'error' has to do with your locale 'it' as against where
>> github servers are and a new filter. I could, of course, be wrong on all
>> counts, but when I arrive NYC next week I'll
>> check and report.
>>
>> I realize that this seems somewhat far afield of your question regarding
>> RGoogleDocs, but I've been noticing a segmentation
>> in accessibility in Amazon, Google (at times), and now github which is
>> completely inaccessible. So perhaps it is a matter of contracting
>> a VPN service. As I say, I'll check in NY and report.
>>
>> Chris
>>
>> On Fri, Oct 21, 2016 at 2:32 PM, Paolo Piras <paolo.piras at uniroma3.it>
>> wrote:
>>
>> Hi folks,
>>>
>>> I'm not sure if this topic could be appropriate here as it is not
>>> properly
>>> geostatistical but maybe someone could help me
>>>
>>> I have a shared space on google drive with some colleagues; I would like
>>> to access there from R and to list files in the folders and eventually to
>>> load some data into R.
>>>
>>> I know that RGoogleDocs package allows it but it seems not working when I
>>> try to login using
>>>
>>> auth = getGoogleAuth("mygmail at gmail.com","mypasword",service="wise")
>>> I have:
>>> "Error: not found"
>>>
>>> I found an old post where other people experienced the same problem but a
>>> solution was not present there.
>>> Maybe there are other packages such as googlesheets but my primary
>>> purpose
>>> is to list files present in the folder.
>>> Anyway...thanks in advance for any hint
>>> All the best
>>> Paolo
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> http://depsy.org/person/434412
>

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Fri Oct 21 22:51:22 2016
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Fri, 21 Oct 2016 20:51:22 +0000
Subject: [R-sig-Geo] Access to google drive account using RGoogleDocs
In-Reply-To: <CAASFQpRgC1iHh-sfnDt+bR+Yz6ekMqK5GVG7n8Tt+rMw7QPKJA@mail.gmail.com>
References: <mailman.5.1476612002.5416.r-sig-geo@r-project.org>
	<BY2PR09MB0676E38D7DD6E37A645C2A1981D10@BY2PR09MB0676.namprd09.prod.outlook.com>
	<HE1PR04MB11618A843A1FBDBA637D0912B3D10@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<HE1PR04MB1161E56ED2E39051A86EF0A6B3D40@HE1PR04MB1161.eurprd04.prod.outlook.com>
	<CAASFQpSEqfKvzbQbWkJ5UxpDCUvfOQML33V3cBR6YqhXfV0zEA@mail.gmail.com>
	<alpine.LFD.2.20.1610212004200.30046@reclus.nhh.no>,
	<CAASFQpRgC1iHh-sfnDt+bR+Yz6ekMqK5GVG7n8Tt+rMw7QPKJA@mail.gmail.com>
Message-ID: <AM3PR04MB1155AF8556B1B312D03D1DB5B3D40@AM3PR04MB1155.eurprd04.prod.outlook.com>

It seems my "conspiracy" explanation was not so wrong after all....

Let's wait some time and we will see

All the best in the meantime

paolo



________________________________
Da: chris english <englishchristophera at gmail.com>
Inviato: venerd? 21 ottobre 2016 20.19
A: Roger.Bivand at nhh.no
Cc: Paolo Piras; r-sig-geo at r-project.org
Oggetto: Re: [R-sig-Geo] Access to google drive account using RGoogleDocs

Roger,

Thank you for this input. I am accustomed to high latency. Though I imagine that this DDOS on DSN services will escalate through the
the end of the present election and beyond. There's probably an R approach, in addition to Apache, to dealing with this...

As a completely peculiar aside, my wife decided a year ago that when she has her fugue state, her last name will be Bivand.
She loves the sound. Best to think forties movies here. Hope you look something like Charles Boyer, as it will round things out nicely.

Chris

On Fri, Oct 21, 2016 at 9:06 PM, Roger Bivand <Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>> wrote:
It appears that there are ongoing DDOS incidents affecting DNS providers and through them the services you mention; see:

https://tech.slashdot.org/story/16/10/21/135241/several-sites-including-twitter-spotify-paypal-nytimes-suffering-outage----dyn-dns-under-ddos-attack-update

so I'd wait until things calm down before drawing conclusions.

Roger


On Fri, 21 Oct 2016, chris english wrote:

Paolo,

I saw your post and was just anticipating sharing some data with colleagues
in New Zealand, and I believe that
between two weeks ago and now, github has changed some Apache Server
settings so that me, sitting in Cyprus can no longer
access, though if I went in through my wife's VPN and appeared to be in
NYC, it might work. So, at the moment
I can't even get into github using devtools to check, but I believe that
your 'error' has to do with your locale 'it' as against where
github servers are and a new filter. I could, of course, be wrong on all
counts, but when I arrive NYC next week I'll
check and report.

I realize that this seems somewhat far afield of your question regarding
RGoogleDocs, but I've been noticing a segmentation
in accessibility in Amazon, Google (at times), and now github which is
completely inaccessible. So perhaps it is a matter of contracting
a VPN service. As I say, I'll check in NY and report.

Chris

On Fri, Oct 21, 2016 at 2:32 PM, Paolo Piras <paolo.piras at uniroma3.it<mailto:paolo.piras at uniroma3.it>>
wrote:

Hi folks,

I'm not sure if this topic could be appropriate here as it is not properly
geostatistical but maybe someone could help me

I have a shared space on google drive with some colleagues; I would like
to access there from R and to list files in the folders and eventually to
load some data into R.

I know that RGoogleDocs package allows it but it seems not working when I
try to login using

auth = getGoogleAuth("mygmail at gmail.com<mailto:mygmail at gmail.com>","mypasword",service="wise")
I have:
"Error: not found"

I found an old post where other people experienced the same problem but a
solution was not present there.
Maybe there are other packages such as googlesheets but my primary purpose
is to list files present in the folder.
Anyway...thanks in advance for any hint
All the best
Paolo



        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


--
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55<tel:%2B47%2055%2095%2093%2055>; fax +47 55 95 91 00<tel:%2B47%2055%2095%2091%2000>
e-mail: Roger.Bivand at nhh.no<mailto:Roger.Bivand at nhh.no>
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


	[[alternative HTML version deleted]]


From juta.kawalerowicz at nuffield.ox.ac.uk  Sun Oct 23 23:53:26 2016
From: juta.kawalerowicz at nuffield.ox.ac.uk (Juta Kawalerowicz)
Date: Sun, 23 Oct 2016 23:53:26 +0200
Subject: [R-sig-Geo] vulnerability mapping
In-Reply-To: <942af556-2cfc-4408-bba4-9461a54d0f72@HUB06.ad.oak.ox.ac.uk>
References: <CAHMizkMvOKN8jkKGO6Zup46uUiyoGpTEFin9XJVuWBw+iv_SFw@mail.gmail.com>
	<CAMNc56CJb7-4HFQY+e_VeqRKauEJBR=FOPmZaBZVXVBeXxW7og@mail.gmail.com>
	<942af556-2cfc-4408-bba4-9461a54d0f72@HUB06.ad.oak.ox.ac.uk>
Message-ID: <CAHMizkNK+BUmwcC88MdeN=s_ObMpSB_E2KUOdpxVmv8qRzpX8g@mail.gmail.com>

Thanks Tina and Jacek for your messages!

More about the problem (which hopefully I can illustrate this better now).
I want to show that the area where 2011 rioting in London started was
particularly good for a quick spread of the rioting given that it was on
the intersection of high density of shopping malls which are targeted
during rioting and socio-economic deprivation. So no modelling of riots per
se just showing that the area where the (initially peaceful) protest which
later turned violent happened fell into a vulnerable zone.

What data I have:

spatial points showing malls locations (see here
<https://www.dropbox.com/s/9e9dnjcy0182txf/picture1.tiff?dl=0>)
spatialpolygon dataframe which has a column with indices of deprivation for
each polygon (see here
<https://www.dropbox.com/s/3yc3sqyb9ltj7ir/picture6.tiff?dl=0> shows
quintiles)

The concept so far is to:

1. Create hotspots from shopping malls locations (here
<https://www.dropbox.com/s/tl8x9xabxcyzp1v/picture2.tiff?dl=0>)
2. Convert hotspots into spatial polygons (here
<https://www.dropbox.com/s/pd7i0lz90p5pbbx/picture3.tiff?dl=0>)
3. Calculate the mean value of deprivation within each hotspot polygon.
Before I would need to create a raster out of deprivation in neighbourhoods
(here <https://www.dropbox.com/s/m43t38wywllmh2w/picture4.tiff?dl=0>)
4. The final result would be to create a column based on multiplication of
shopping map hotspots and mean value of deprivation in that hotspot polygon
(here <https://www.dropbox.com/s/qune4w812sikwmr/picture5.tiff?dl=0>)

I realise that this can seem quite arbitrary as a method so I was wondering
whether someone would now a more standard procedure or R packages which are
normally used for such tasks?

Juta

On Fri, Oct 21, 2016 at 2:59 PM, Tina Cormier <tcorms at gmail.com> wrote:

> Hi Juta,
>
> It seems to me that what you have are potential predictors of riots. I
> think you'll also need some riot location data - that is, if you are trying
> to model vulnerability (as Jacek said) to identify important variables. If
> you are just trying to create a map that shows potential areas (without
> modeling - as in, you already KNOW that these are good predictors), then I
> would probably do something simple, like create a ranking system for
> socioeconomic status and distance from malls - add them together to ID hot
> spots. Without knowing your goal, it's probably not worth going into too
> much detail on those methods, but I would start by interpolating a raster
> that shows distance to malls (ranked), and combine with census rankings. It
> seems to me these two predictors alone are not sufficient, but if that's
> what you're going with, this would be my simple approach.
>
> Good luck!
> Tina
>
> On Fri, Oct 21, 2016 at 8:41 AM, Jacek Stefaniak <
> jacek.stefaniak at gmail.com> wrote:
>
>> Hi,
>>
>> Honestly speaking I do not have clear idea what you will plan to do. You
>> want to just create map with highlighted areas showing hypothetical
>> "better
>> conditions" for riots, or you want to use a model for finding such areas
>> and explore potential variables causing higher risk? In any of this two
>> cases, you will need slightly different data and approach... Can you care
>> to elaborate?
>>
>> PS: Mo?esz napisa? do mnie po polsku na prywatny adres, je?li tak Ci jest
>> ?atwiej ;)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

	[[alternative HTML version deleted]]


From maaz at iastate.edu  Wed Oct 26 19:40:48 2016
From: maaz at iastate.edu (Maaz Gardezi)
Date: Wed, 26 Oct 2016 12:40:48 -0500
Subject: [R-sig-Geo] getting standard errors of prediction (SAR/CAR) in spdep
Message-ID: <CALcs7UL+kjr46i8-hB_R+qe0cF7tOaZ58G6gEYPVCHN3AT33JA@mail.gmail.com>

Hello,

Does anyone know if there's a way that the package 'spdep' can give
standard errors of the prediction (for either SAR or CAR model)? I'm using
the spautolm function.

Regards,

Maaz

PhD Candidate and Graduate Research Assistant
Sociology, Sustainable Agriculture, and Statistics (minor)
Editor, Journal of Critical Thought and Praxis
409 B East Hall, Iowa State University

	[[alternative HTML version deleted]]


From Roger.Bivand at nhh.no  Thu Oct 27 19:55:00 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 27 Oct 2016 19:55:00 +0200
Subject: [R-sig-Geo] readOGR() in rgdal and 64-bit integers
Message-ID: <alpine.LFD.2.20.1610271941340.26038@reclus.nhh.no>

Since the release of GDAL 2, feature IDs are 64-bit integers and fields of 
vector data may be 64-bit integers. Most often, the declarations of these 
fields are misunderstandings, as such data is almost always a long key ID 
(should be string), or may be an area in square metres (should be float).

readOGR() received an argument integer64= with the default value of 
"allow.loss", which silently clamps 64-bit integers to 32-bit signed 
integers. Of course, users who first read the output of ogrInfo() on their 
input files would have been warned that action may be required on their 
part to avoid data loss.

The alternative values, as in base::type.convert(), are "warn.loss" - 
which issues a warning if clamping takes place, and "no.loss" which 
returns character strings (often represented as a factor) instead of 
clamping.

The current default assumes that users actually use ogrInfo() to examine 
their data before reading it. Is this overly optimistic? Would it be 
better to change the default to "no.loss" or "warn.loss"? A doodle is 
here: http://doodle.com/poll/9qaqrkbs6q7k5skz - I'd be grateful for 
feedback.

Roger

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412


From rshepard at appl-ecosys.com  Thu Oct 27 20:01:46 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 27 Oct 2016 11:01:46 -0700 (PDT)
Subject: [R-sig-Geo] readOGR() in rgdal and 64-bit integers
In-Reply-To: <alpine.LFD.2.20.1610271941340.26038@reclus.nhh.no>
References: <alpine.LFD.2.20.1610271941340.26038@reclus.nhh.no>
Message-ID: <alpine.LNX.2.11.1610271058530.16551@localhost>

On Thu, 27 Oct 2016, Roger Bivand wrote:

> The current default assumes that users actually use ogrInfo() to examine
> their data before reading it. Is this overly optimistic? Would it be
> better to change the default to "no.loss" or "warn.loss"? A doodle is
> here: http://doodle.com/poll/9qaqrkbs6q7k5skz - I'd be grateful for
> feedback.

Roger,

   Given human nature I think that default assumption is incorrect. While
'warn.loss' seems to be a resonable replacement it assumes that users all
know what to do about the loss of data. I voted for 'no.loss' as
accommodating everyone without assumptions about reading or adjusting.

Regards,

Rich


From lockhart.katherine at gmail.com  Fri Oct 28 01:19:02 2016
From: lockhart.katherine at gmail.com (Katherine Ransom)
Date: Thu, 27 Oct 2016 16:19:02 -0700
Subject: [R-sig-Geo] Reproducibility of results from predict() function -
	raster package
Message-ID: <CAMEAd6wip7QKONQkgWK8QTaa7_FktCPfKVABU-BfAMDkw0JXgg@mail.gmail.com>

Hi All,
I am having trouble reproducing my results exactly when I make predictions
with predict() and a saved gbm model object. Each time I run predict() with
the same model object and inputs (a raster stack), I get slightly different
values (max value within 0.7 for a range of predictions from 0.08 to 12.30
for example). However, there seems to be a limited amount of outcomes. For
example, I can get the results to reproduce if I run predict enough times.

The issue seems to be within the predict() function as it doesn't seem to
be related to R session, loading package libraries, etc.

Are there any random number generators or known bugs within the predict
function that could be causing this behavior?

Here is my code line that calls predict: pred <- predict(rstack, final,
n.trees=final$n.trees,na.rm=TRUE,const=data.frame(WaterUse2="H"))  #
family="gaussian"

Not sure if I need the family = "gaussian" option. It doesn't seem to
affect the results.

Thank you,
Katie

-- 
--
Katherine Ransom
PhD Candidate
Hydrologic Sciences Graduate Group
UC Davis

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Fri Oct 28 16:54:00 2016
From: englishchristophera at gmail.com (chris english)
Date: Fri, 28 Oct 2016 17:54:00 +0300
Subject: [R-sig-Geo] Reproducibility of results from predict() function
 - raster package
In-Reply-To: <CAMEAd6wip7QKONQkgWK8QTaa7_FktCPfKVABU-BfAMDkw0JXgg@mail.gmail.com>
References: <CAMEAd6wip7QKONQkgWK8QTaa7_FktCPfKVABU-BfAMDkw0JXgg@mail.gmail.com>
Message-ID: <CAASFQpQnom7VZH5VqxRmEz6MuN+UzwEYD7nkfMvPWZr+xCOyrQ@mail.gmail.com>

Katie,

set.seed(123) on each run thru will (should) result in reproducibility.

set.seed(1234)
pred <- predict(

Chr

On Oct 27, 2016 7:19 PM, "Katherine Ransom" <lockhart.katherine at gmail.com>
wrote:
>
> Hi All,
> I am having trouble reproducing my results exactly when I make predictions
> with predict() and a saved gbm model object. Each time I run predict()
with
> the same model object and inputs (a raster stack), I get slightly
different
> values (max value within 0.7 for a range of predictions from 0.08 to 12.30
> for example). However, there seems to be a limited amount of outcomes. For
> example, I can get the results to reproduce if I run predict enough times.
>
> The issue seems to be within the predict() function as it doesn't seem to
> be related to R session, loading package libraries, etc.
>
> Are there any random number generators or known bugs within the predict
> function that could be causing this behavior?
>
> Here is my code line that calls predict: pred <- predict(rstack, final,
> n.trees=final$n.trees,na.rm=TRUE,const=data.frame(WaterUse2="H"))  #
> family="gaussian"
>
> Not sure if I need the family = "gaussian" option. It doesn't seem to
> affect the results.
>
> Thank you,
> Katie
>
> --
> --
> Katherine Ransom
> PhD Candidate
> Hydrologic Sciences Graduate Group
> UC Davis
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From englishchristophera at gmail.com  Fri Oct 28 17:09:03 2016
From: englishchristophera at gmail.com (chris english)
Date: Fri, 28 Oct 2016 18:09:03 +0300
Subject: [R-sig-Geo] readOGR() in rgdal and 64-bit integers
In-Reply-To: <alpine.LNX.2.11.1610271058530.16551@localhost>
References: <alpine.LFD.2.20.1610271941340.26038@reclus.nhh.no>
	<alpine.LNX.2.11.1610271058530.16551@localhost>
Message-ID: <CAASFQpQSbWDFOm9+49PON6x+g-NBQVRW0iqVZETUhM=vLeX2+Q@mail.gmail.com>

Roger,

I concur with Rich, both that most (new) users won't quite follow the
implication of the transforms, clamping, work flow, nor yet have a sense of
what the numbers "should look like". Perhaps no.loss coupled with warning
pointing to readOGR() help to expand on implications.

Chris

On Oct 27, 2016 2:02 PM, "Rich Shepard" <rshepard at appl-ecosys.com> wrote:

> On Thu, 27 Oct 2016, Roger Bivand wrote:
>
> The current default assumes that users actually use ogrInfo() to examine
>> their data before reading it. Is this overly optimistic? Would it be
>> better to change the default to "no.loss" or "warn.loss"? A doodle is
>> here: http://doodle.com/poll/9qaqrkbs6q7k5skz - I'd be grateful for
>> feedback.
>>
>
> Roger,
>
>   Given human nature I think that default assumption is incorrect. While
> 'warn.loss' seems to be a resonable replacement it assumes that users all
> know what to do about the loss of data. I voted for 'no.loss' as
> accommodating everyone without assumptions about reading or adjusting.
>
> Regards,
>
> Rich
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Fri Oct 28 17:18:51 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 28 Oct 2016 08:18:51 -0700 (PDT)
Subject: [R-sig-Geo] Spatial analyses of censored geochemical data
Message-ID: <alpine.LNX.2.11.1610280813080.28988@localhost>

   I've read the task view pages for spatial, spatiotemporal, and
envirometrics packages without seeing explicit reference to censored
geochemical data. These are data whose values are below detection limits.

   The NADA package allows correct analyses of these data for descriptive and
advanced analyses, but I've not seen documentation for spatial and
spatiotemporal models.

   If there is/are such packages for R please point me to the appropriate
ones.

TIA,

Rich


From lockhart.katherine at gmail.com  Fri Oct 28 20:30:02 2016
From: lockhart.katherine at gmail.com (Katherine Ransom)
Date: Fri, 28 Oct 2016 11:30:02 -0700
Subject: [R-sig-Geo] Reproducibility of results from predict() function
 - raster package
In-Reply-To: <CAASFQpQnom7VZH5VqxRmEz6MuN+UzwEYD7nkfMvPWZr+xCOyrQ@mail.gmail.com>
References: <CAMEAd6wip7QKONQkgWK8QTaa7_FktCPfKVABU-BfAMDkw0JXgg@mail.gmail.com>
	<CAASFQpQnom7VZH5VqxRmEz6MuN+UzwEYD7nkfMvPWZr+xCOyrQ@mail.gmail.com>
Message-ID: <CAMEAd6zxZhzQiywJMqhF8W=TFmsf4O5Tp2Nn+Wp6djN2RH2BFQ@mail.gmail.com>

Hi Chris,
Thank you.
I have tried that (should have mentioned it) and I just tried it again.
However, it did not help. Also, I just tried summing the raster values in R
rather than looking at summary stats in ArcGIS and they are still not the
same.
Any other ideas?

On Fri, Oct 28, 2016 at 7:54 AM, chris english <
englishchristophera at gmail.com> wrote:

> Katie,
>
> set.seed(123) on each run thru will (should) result in reproducibility.
>
> set.seed(1234)
> pred <- predict(
>
> Chr
>
> On Oct 27, 2016 7:19 PM, "Katherine Ransom" <lockhart.katherine at gmail.com>
> wrote:
> >
> > Hi All,
> > I am having trouble reproducing my results exactly when I make
> predictions
> > with predict() and a saved gbm model object. Each time I run predict()
> with
> > the same model object and inputs (a raster stack), I get slightly
> different
> > values (max value within 0.7 for a range of predictions from 0.08 to
> 12.30
> > for example). However, there seems to be a limited amount of outcomes.
> For
> > example, I can get the results to reproduce if I run predict enough
> times.
> >
> > The issue seems to be within the predict() function as it doesn't seem to
> > be related to R session, loading package libraries, etc.
> >
> > Are there any random number generators or known bugs within the predict
> > function that could be causing this behavior?
> >
> > Here is my code line that calls predict: pred <- predict(rstack, final,
> > n.trees=final$n.trees,na.rm=TRUE,const=data.frame(WaterUse2="H"))  #
> > family="gaussian"
> >
> > Not sure if I need the family = "gaussian" option. It doesn't seem to
> > affect the results.
> >
> > Thank you,
> > Katie
> >
> > --
> > --
> > Katherine Ransom
> > PhD Candidate
> > Hydrologic Sciences Graduate Group
> > UC Davis
> >
> >         [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>


-- 
--
Katherine Ransom
PhD Candidate
Hydrologic Sciences Graduate Group
UC Davis

	[[alternative HTML version deleted]]


From Jin.Li at ga.gov.au  Mon Oct 31 05:09:35 2016
From: Jin.Li at ga.gov.au (Li Jin)
Date: Mon, 31 Oct 2016 04:09:35 +0000
Subject: [R-sig-Geo] Error with gstat::predict [SEC=UNCLASSIFIED]
Message-ID: <541880c21d784932a43e9ec6903a2b2b@win-exch-prod01.prod.lan>

Hi All,

I need to use the predict{gstat}  function in one of my functions for a R package. I use RStudio to make the package. When I specified gstat::predict in the function, I received the following error:

Error: 'predict' is not an exported object from 'namespace:gstat'

The session information is:

> sessionInfo()

R version 3.3.1 (2016-06-21)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252

[3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C

[5] LC_TIME=English_Australia.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

[1] myrpackage_0.0.0.9000 devtools_1.12.0



loaded via a namespace (and not attached):

[1] tools_3.3.1   withr_1.0.2   memoise_1.0.0 digest_0.6.10

Is this a bug? Any suggestions? Many thanks in advance!

Kind regards,
Jin

Jin Li, PhD
Spatial Modeller/Computational Statistician  |  National Earth and Marine Observations
Environmental Geoscience Division  |  GEOSCIENCE AUSTRALIA
____________________________________________________________
Phone:  +61 2 6249 9899    Fax:  +61 2 6249 9999
Email:  Jin.Li at ga.gov.au<mailto:Jin.Li at ga.gov.au>    Web:  www.ga.gov.au<http://www.ga.gov.au/>
101 Jerrabomberra Avenue Symonston ACT
GPO Box 378 Canberra ACT 2601 Australia
Applying geoscience to Australia?s most important challenges



Geoscience Australia Disclaimer: This e-mail (and files transmitted with it) is intended only for the person or entity to which it is addressed. If you are not the intended recipient, then you have received this e-mail by mistake and any use, dissemination, forwarding, printing or copying of this e-mail and its file attachments is prohibited. The security of emails transmitted cannot be guaranteed; by forwarding or replying to this email, you acknowledge and accept these risks.
-------------------------------------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Mon Oct 31 08:57:58 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 31 Oct 2016 08:57:58 +0100
Subject: [R-sig-Geo] Error with gstat::predict [SEC=UNCLASSIFIED]
In-Reply-To: <541880c21d784932a43e9ec6903a2b2b@win-exch-prod01.prod.lan>
References: <541880c21d784932a43e9ec6903a2b2b@win-exch-prod01.prod.lan>
Message-ID: <118d1262-4dd0-3340-9aba-fef180f32642@uni-muenster.de>



On 31/10/16 05:09, Li Jin wrote:
> Hi All,
> 
> I need to use the predict{gstat}  function in one of my functions for a R package. I use RStudio to make the package. When I specified gstat::predict in the function, I received the following error:
> 
> Error: 'predict' is not an exported object from 'namespace:gstat'

gstat exports 'predict' as an S3method; if it would export 'predict' as
an object, this would hide the generic in package stats.

The solution to your problem is to not put prepend 'predict' with
gstat::, but instead rely on S3 method dispatch.

The actual, un-exported function called is gstat:::predict.gstat, but it
is discouraged to call that directly.

> 
> The session information is:
> 
>> sessionInfo()
> 
> R version 3.3.1 (2016-06-21)
> 
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> 
> 
> locale:
> 
> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
> 
> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
> 
> [5] LC_TIME=English_Australia.1252
> 
> 
> 
> attached base packages:
> 
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> 
> other attached packages:
> 
> [1] myrpackage_0.0.0.9000 devtools_1.12.0
> 
> 
> 
> loaded via a namespace (and not attached):
> 
> [1] tools_3.3.1   withr_1.0.2   memoise_1.0.0 digest_0.6.10
> 
> Is this a bug? Any suggestions? Many thanks in advance!
> 
> Kind regards,
> Jin
> 
> Jin Li, PhD
> Spatial Modeller/Computational Statistician  |  National Earth and Marine Observations
> Environmental Geoscience Division  |  GEOSCIENCE AUSTRALIA
> ____________________________________________________________
> Phone:  +61 2 6249 9899    Fax:  +61 2 6249 9999
> Email:  Jin.Li at ga.gov.au<mailto:Jin.Li at ga.gov.au>    Web:  www.ga.gov.au<http://www.ga.gov.au/>
> 101 Jerrabomberra Avenue Symonston ACT
> GPO Box 378 Canberra ACT 2601 Australia
> Applying geoscience to Australia?s most important challenges
> 
> 
> 
> Geoscience Australia Disclaimer: This e-mail (and files transmitted with it) is intended only for the person or entity to which it is addressed. If you are not the intended recipient, then you have received this e-mail by mistake and any use, dissemination, forwarding, printing or copying of this e-mail and its file attachments is prohibited. The security of emails transmitted cannot be guaranteed; by forwarding or replying to this email, you acknowledge and accept these risks.
> -------------------------------------------------------------------------------------------------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20161031/9e9e49d5/attachment.bin>

From Roger.Bivand at nhh.no  Mon Oct 31 09:12:33 2016
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 31 Oct 2016 09:12:33 +0100
Subject: [R-sig-Geo] Error with gstat::predict [SEC=UNCLASSIFIED]
In-Reply-To: <118d1262-4dd0-3340-9aba-fef180f32642@uni-muenster.de>
References: <541880c21d784932a43e9ec6903a2b2b@win-exch-prod01.prod.lan>
	<118d1262-4dd0-3340-9aba-fef180f32642@uni-muenster.de>
Message-ID: <alpine.LFD.2.20.1610310911150.2648@reclus.nhh.no>

On Mon, 31 Oct 2016, Edzer Pebesma wrote:

>
>
> On 31/10/16 05:09, Li Jin wrote:
>> Hi All,
>>
>> I need to use the predict{gstat} function in one of my functions for a 
>> R package. I use RStudio to make the package. When I specified 
>> gstat::predict in the function, I received the following error:
>>
>> Error: 'predict' is not an exported object from 'namespace:gstat'
>
> gstat exports 'predict' as an S3method; if it would export 'predict' as
> an object, this would hide the generic in package stats.
>
> The solution to your problem is to not put prepend 'predict' with
> gstat::, but instead rely on S3 method dispatch.

Is it possible that the OP is not importing correctly in the NAMESPACE 
file of the package in question?

Roger

>
> The actual, un-exported function called is gstat:::predict.gstat, but it
> is discouraged to call that directly.
>
>>
>> The session information is:
>>
>>> sessionInfo()
>>
>> R version 3.3.1 (2016-06-21)
>>
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>
>>
>>
>> locale:
>>
>> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>>
>> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
>>
>> [5] LC_TIME=English_Australia.1252
>>
>>
>>
>> attached base packages:
>>
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>>
>>
>> other attached packages:
>>
>> [1] myrpackage_0.0.0.9000 devtools_1.12.0
>>
>>
>>
>> loaded via a namespace (and not attached):
>>
>> [1] tools_3.3.1   withr_1.0.2   memoise_1.0.0 digest_0.6.10
>>
>> Is this a bug? Any suggestions? Many thanks in advance!
>>
>> Kind regards,
>> Jin
>>
>> Jin Li, PhD
>> Spatial Modeller/Computational Statistician  |  National Earth and Marine Observations
>> Environmental Geoscience Division  |  GEOSCIENCE AUSTRALIA
>> ____________________________________________________________
>> Phone:  +61 2 6249 9899    Fax:  +61 2 6249 9999
>> Email:  Jin.Li at ga.gov.au<mailto:Jin.Li at ga.gov.au>    Web:  www.ga.gov.au<http://www.ga.gov.au/>
>> 101 Jerrabomberra Avenue Symonston ACT
>> GPO Box 378 Canberra ACT 2601 Australia
>> Applying geoscience to Australia?s most important challenges
>>
>>
>>
>> Geoscience Australia Disclaimer: This e-mail (and files transmitted with it) is intended only for the person or entity to which it is addressed. If you are not the intended recipient, then you have received this e-mail by mistake and any use, dissemination, forwarding, printing or copying of this e-mail and its file attachments is prohibited. The security of emails transmitted cannot be guaranteed; by forwarding or replying to this email, you acknowledge and accept these risks.
>> -------------------------------------------------------------------------------------------------------------------------
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 91 00
e-mail: Roger.Bivand at nhh.no
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
http://depsy.org/person/434412

From edzer.pebesma at uni-muenster.de  Mon Oct 31 10:46:21 2016
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 31 Oct 2016 10:46:21 +0100
Subject: [R-sig-Geo] Error with gstat::predict [SEC=UNCLASSIFIED]
In-Reply-To: <alpine.LFD.2.20.1610310911150.2648@reclus.nhh.no>
References: <541880c21d784932a43e9ec6903a2b2b@win-exch-prod01.prod.lan>
	<118d1262-4dd0-3340-9aba-fef180f32642@uni-muenster.de>
	<alpine.LFD.2.20.1610310911150.2648@reclus.nhh.no>
Message-ID: <aea4ba06-dd14-2338-7ad6-dcd019a83f2a@uni-muenster.de>



On 31/10/16 09:12, Roger Bivand wrote:
> On Mon, 31 Oct 2016, Edzer Pebesma wrote:
> 
>>
>>
>> On 31/10/16 05:09, Li Jin wrote:
>>> Hi All,
>>>
>>> I need to use the predict{gstat} function in one of my functions for
>>> a R package. I use RStudio to make the package. When I specified
>>> gstat::predict in the function, I received the following error:
>>>
>>> Error: 'predict' is not an exported object from 'namespace:gstat'
>>
>> gstat exports 'predict' as an S3method; if it would export 'predict' as
>> an object, this would hide the generic in package stats.
>>
>> The solution to your problem is to not put prepend 'predict' with
>> gstat::, but instead rely on S3 method dispatch.
> 
> Is it possible that the OP is not importing correctly in the NAMESPACE
> file of the package in question?

Indeed: your package should load (import):

1. predict from package stats, if it wants to use predict
2. package gstat if it wants to use the predict method for gstat objects.
3. use stats::predict rather than gstat::predict if you'd insist on
prepending package:: to a generic

> 
> Roger
> 
>>
>> The actual, un-exported function called is gstat:::predict.gstat, but it
>> is discouraged to call that directly.
>>
>>>
>>> The session information is:
>>>
>>>> sessionInfo()
>>>
>>> R version 3.3.1 (2016-06-21)
>>>
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>
>>> Running under: Windows 7 x64 (build 7601) Service Pack 1
>>>
>>>
>>>
>>> locale:
>>>
>>> [1] LC_COLLATE=English_Australia.1252  LC_CTYPE=English_Australia.1252
>>>
>>> [3] LC_MONETARY=English_Australia.1252 LC_NUMERIC=C
>>>
>>> [5] LC_TIME=English_Australia.1252
>>>
>>>
>>>
>>> attached base packages:
>>>
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>>
>>>
>>> other attached packages:
>>>
>>> [1] myrpackage_0.0.0.9000 devtools_1.12.0
>>>
>>>
>>>
>>> loaded via a namespace (and not attached):
>>>
>>> [1] tools_3.3.1   withr_1.0.2   memoise_1.0.0 digest_0.6.10
>>>
>>> Is this a bug? Any suggestions? Many thanks in advance!
>>>
>>> Kind regards,
>>> Jin
>>>
>>> Jin Li, PhD
>>> Spatial Modeller/Computational Statistician  |  National Earth and
>>> Marine Observations
>>> Environmental Geoscience Division  |  GEOSCIENCE AUSTRALIA
>>> ____________________________________________________________
>>> Phone:  +61 2 6249 9899    Fax:  +61 2 6249 9999
>>> Email:  Jin.Li at ga.gov.au<mailto:Jin.Li at ga.gov.au>    Web: 
>>> www.ga.gov.au<http://www.ga.gov.au/>
>>> 101 Jerrabomberra Avenue Symonston ACT
>>> GPO Box 378 Canberra ACT 2601 Australia
>>> Applying geoscience to Australia?s most important challenges
>>>
>>>
>>>
>>> Geoscience Australia Disclaimer: This e-mail (and files transmitted
>>> with it) is intended only for the person or entity to which it is
>>> addressed. If you are not the intended recipient, then you have
>>> received this e-mail by mistake and any use, dissemination,
>>> forwarding, printing or copying of this e-mail and its file
>>> attachments is prohibited. The security of emails transmitted cannot
>>> be guaranteed; by forwarding or replying to this email, you
>>> acknowledge and accept these risks.
>>> -------------------------------------------------------------------------------------------------------------------------
>>>
>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
> 

-- 
Edzer Pebesma
Institute for Geoinformatics  (ifgi),  University of M?nster
Heisenbergstra?e 2, 48149 M?nster, Germany; +49 251 83 33081
Journal of Statistical Software:   http://www.jstatsoft.org/
Computers & Geosciences:   http://elsevier.com/locate/cageo/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 490 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20161031/2065925f/attachment.bin>

From frzambra at gmail.com  Mon Oct 31 14:21:30 2016
From: frzambra at gmail.com (Francisco Zambrano)
Date: Mon, 31 Oct 2016 14:21:30 +0100
Subject: [R-sig-Geo] Extract vs Zonal: Efficient method to extract and
 averaging values from large raster datasets using polygons
Message-ID: <CANE=RDMq6RVyqDUHBjJFnX-DqxyGqfc+SxRdA2-gryKEAxNZOA@mail.gmail.com>

Hi all,

I need to know which is the quickest way to extract values from a large
raster datasets (> 300 layers) using polygons (SpatialPolygonsDataFrame).

Also, I need to know if worth it to use some parallelization, or just be
enough to start the cluster with beginCluster(n) at the beginning, knowing
that 'extract' use parallelization.

Using "extract" function will be something like this:

> library(raster)
> library(maptools)
> rasters <- stack(files_rasters)
> polygons <- readShapePoly(file_shape)

> beginCluster(8)
> dataOut <- extract(rasters,polygons,fun='mean')
 > endCluster()

In the case of select the "zonal" function will be:

> library(raster)
> library(maptools)
> rasters <- stack(files_rasters)
> polygons <- readShapePoly(file_shape)
> polygonsRaster <- rasterize(polygons, subset(rasters,1))

> beginCluster(8)
> dataOut <- zonal(rasters, polygonsRaster, 'mean')
> endCluster()

Which of those would have the quickest result?
There is another quickest way to do it?
If not, for those methods worth it to try some improvements such as
parallelization?

I've reviewed some discussion, but I think still there is not an answer to
conclusive about it. Right now, I'm testing different approach, using
smaller subset data but I still don't have a conclusion.

Best to all,

Francisco Zambrano
Ph.D. Candidate from University of Concepcion, Chile.
Visiting researcher at ITC, University of Twente, Netherlands.


frzambra.github.io
Agricultural Drought Webmapping <https://frzambra.shinyapps.io/shinyapp/>

	[[alternative HTML version deleted]]


From pingyang.whu at gmail.com  Mon Oct 31 14:29:15 2016
From: pingyang.whu at gmail.com (ping yang)
Date: Mon, 31 Oct 2016 08:29:15 -0500
Subject: [R-sig-Geo] Extract vs Zonal: Efficient method to extract and
 averaging values from large raster datasets using polygons
In-Reply-To: <CANE=RDMq6RVyqDUHBjJFnX-DqxyGqfc+SxRdA2-gryKEAxNZOA@mail.gmail.com>
References: <CANE=RDMq6RVyqDUHBjJFnX-DqxyGqfc+SxRdA2-gryKEAxNZOA@mail.gmail.com>
Message-ID: <CAK8gSG9oUziadfXrHtWcfL0Hp5=u9O5gjGQWs+eWRzYn=SpH4g@mail.gmail.com>

Have you think about whether if the result of the extract function in the
raster library compare to the result from other GIS software?
I found some weird result when I compared it to the result from Zonal
Statistic from arcGIS and qGIS.
I was wondering there were some wrong with the raster::extract function.

On Mon, Oct 31, 2016 at 8:21 AM, Francisco Zambrano <frzambra at gmail.com>
wrote:

> Hi all,
>
> I need to know which is the quickest way to extract values from a large
> raster datasets (> 300 layers) using polygons (SpatialPolygonsDataFrame).
>
> Also, I need to know if worth it to use some parallelization, or just be
> enough to start the cluster with beginCluster(n) at the beginning, knowing
> that 'extract' use parallelization.
>
> Using "extract" function will be something like this:
>
> > library(raster)
> > library(maptools)
> > rasters <- stack(files_rasters)
> > polygons <- readShapePoly(file_shape)
>
> > beginCluster(8)
> > dataOut <- extract(rasters,polygons,fun='mean')
>  > endCluster()
>
> In the case of select the "zonal" function will be:
>
> > library(raster)
> > library(maptools)
> > rasters <- stack(files_rasters)
> > polygons <- readShapePoly(file_shape)
> > polygonsRaster <- rasterize(polygons, subset(rasters,1))
>
> > beginCluster(8)
> > dataOut <- zonal(rasters, polygonsRaster, 'mean')
> > endCluster()
>
> Which of those would have the quickest result?
> There is another quickest way to do it?
> If not, for those methods worth it to try some improvements such as
> parallelization?
>
> I've reviewed some discussion, but I think still there is not an answer to
> conclusive about it. Right now, I'm testing different approach, using
> smaller subset data but I still don't have a conclusion.
>
> Best to all,
>
> Francisco Zambrano
> Ph.D. Candidate from University of Concepcion, Chile.
> Visiting researcher at ITC, University of Twente, Netherlands.
>
>
> frzambra.github.io
> Agricultural Drought Webmapping <https://frzambra.shinyapps.io/shinyapp/>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


