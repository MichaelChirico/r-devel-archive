From mdsumner at gmail.com  Fri Dec  1 12:24:50 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 01 Dec 2017 11:24:50 +0000
Subject: [R-sig-Geo] make a raster from Aquarius files
In-Reply-To: <CAE8g1gPGRAy6HNeMR2gXiUF_d90E0sQ8wq-qEzEdmH=kjVEAyg@mail.gmail.com>
References: <CAE8g1gPGRAy6HNeMR2gXiUF_d90E0sQ8wq-qEzEdmH=kjVEAyg@mail.gmail.com>
Message-ID: <CAAcGz9_ub5Dd01Z0rZE_BWF2GqL2pTW7vtmYwpDH6Jtw0TVDdg@mail.gmail.com>

That file name does not correspond to the standard patterns used by the
oceancolor site. All the L3m products from there are now (NetCDF 4.0) .nc
and so will work fine with raster/ncdf4.  (Some years ago they were HDF4 -
without an extension, as the shortcuts in the image thumbnails hints
(SMI/HDF and BIN/HDF - SMI/L3m standard mapped image in your case).

I think you've got some other provider's version of a file, but there's not
enough information here to know where you got it or what form it's in. I'm
happy to look if you can point us to the source of
Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.

But otherwise, can you share with us the output of

nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
print(nc.data)

and if you're on a suitable system with HDF4 support a gdalinfo output of
the file would be useful too.

Given that you can read it with ncdf4, and if it actually is NetCDF4 (not
HDF4 or something else) you might help raster work with it by renaming it
to "Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.nc" since (unlike GDAL and
the NetCDF lib itself) raster uses explicit extension to dispatch to
different format logic code, though it ultimately sends it down to rgdal to
deal with if it can't recognize it - which is why I'm surprised you can't
get it to work and ( I'm guessing wildly now):

Do you not have rgdal installed?


What system are you on? Please use sessionInfo() to share details.

Cheers, Mike.
On Fri, 1 Dec 2017, 06:14 Antonio Silva, <aolinto.lst at gmail.com> wrote:

> Hello
>
> Some time ago I prepared scripts to extract temperature data from Modis
> Aqua files. It can be found at https://gist.github.com/aolinto
>
> HDF files can be downloaded at https://oceancolor.gsfc.nasa.gov/cgi/l3
>
> I got the Aquarius sea surface salinity smoothed file from June 2015.
>
> I could open and read the file:
>
> library(ncdf4)
> library(raster)
>
> nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
> print(nc.data)
> dim(ncvar_get(nc.data,"l3m_data"))
> ncvar_get(nc.data,"l3m_data")[c(110:160),c(110:117)]
>
> But I could not prepare a raster from it. I tryed many things as:
>
> rst.data <-
> raster("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg",varname="l3m_data")
> Error in .local(.Object, ...) :
>   `AQUARIUS/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg' not recognised as a
> supported file format.
>
> Error in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer",
> :
>   Cannot create a RasterLayer object from this file.
>
> and variations with band and layer.
>
> I would greatly appreciate any suggestions to solve this issue.
>
> Thanks
>
> --
> Ant?nio Olinto ?vila da Silva
> Fisheries Institute
> S?o Paulo, Brasil
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Fri Dec  1 15:35:06 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 1 Dec 2017 09:35:06 -0500
Subject: [R-sig-Geo] make a raster from Aquarius files
In-Reply-To: <CAAcGz9_ub5Dd01Z0rZE_BWF2GqL2pTW7vtmYwpDH6Jtw0TVDdg@mail.gmail.com>
References: <CAE8g1gPGRAy6HNeMR2gXiUF_d90E0sQ8wq-qEzEdmH=kjVEAyg@mail.gmail.com>
 <CAAcGz9_ub5Dd01Z0rZE_BWF2GqL2pTW7vtmYwpDH6Jtw0TVDdg@mail.gmail.com>
Message-ID: <7C5B491A-921A-430B-A30F-26D51ECB29A9@bigelow.org>

Hi,

Those Aquarius files look quite different from others I have used from OBPG (mostly MODISA and SeaWiFS). 

As a short-cut alternative, you could read all of the values into a matrix and make a global raster from that.  An example is shown below.  You can also subset the extraction as you have shown, but it might be easier to subset after making the raster using raster::crop()

CHeers,
Ben


### START

library(raster)
library(ncdf4)
library(rasterVis)

filename = "Q20151522015181.L3m_MO_SCIA_V5.0_SSS_1deg"

nc = ncdf4::nc_open(filename)
m = ncdf4::ncvar_get(nc, 'l3m_data')
ncdf4::nc_close(nc)
r = raster::raster(t(m))
rasterVis::levelplot(r)

### END

> On Dec 1, 2017, at 6:24 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> 
> That file name does not correspond to the standard patterns used by the
> oceancolor site. All the L3m products from there are now (NetCDF 4.0) .nc
> and so will work fine with raster/ncdf4.  (Some years ago they were HDF4 -
> without an extension, as the shortcuts in the image thumbnails hints
> (SMI/HDF and BIN/HDF - SMI/L3m standard mapped image in your case).
> 
> I think you've got some other provider's version of a file, but there's not
> enough information here to know where you got it or what form it's in. I'm
> happy to look if you can point us to the source of
> Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.
> 
> But otherwise, can you share with us the output of
> 
> nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
> print(nc.data)
> 
> and if you're on a suitable system with HDF4 support a gdalinfo output of
> the file would be useful too.
> 
> Given that you can read it with ncdf4, and if it actually is NetCDF4 (not
> HDF4 or something else) you might help raster work with it by renaming it
> to "Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.nc" since (unlike GDAL and
> the NetCDF lib itself) raster uses explicit extension to dispatch to
> different format logic code, though it ultimately sends it down to rgdal to
> deal with if it can't recognize it - which is why I'm surprised you can't
> get it to work and ( I'm guessing wildly now):
> 
> Do you not have rgdal installed?
> 
> 
> What system are you on? Please use sessionInfo() to share details.
> 
> Cheers, Mike.
> On Fri, 1 Dec 2017, 06:14 Antonio Silva, <aolinto.lst at gmail.com> wrote:
> 
>> Hello
>> 
>> Some time ago I prepared scripts to extract temperature data from Modis
>> Aqua files. It can be found at https://gist.github.com/aolinto
>> 
>> HDF files can be downloaded at https://oceancolor.gsfc.nasa.gov/cgi/l3
>> 
>> I got the Aquarius sea surface salinity smoothed file from June 2015.
>> 
>> I could open and read the file:
>> 
>> library(ncdf4)
>> library(raster)
>> 
>> nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
>> print(nc.data)
>> dim(ncvar_get(nc.data,"l3m_data"))
>> ncvar_get(nc.data,"l3m_data")[c(110:160),c(110:117)]
>> 
>> But I could not prepare a raster from it. I tryed many things as:
>> 
>> rst.data <-
>> raster("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg",varname="l3m_data")
>> Error in .local(.Object, ...) :
>>  `AQUARIUS/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg' not recognised as a
>> supported file format.
>> 
>> Error in .rasterObjectFromFile(x, band = band, objecttype = "RasterLayer",
>> :
>>  Cannot create a RasterLayer object from this file.
>> 
>> and variations with band and layer.
>> 
>> I would greatly appreciate any suggestions to solve this issue.
>> 
>> Thanks
>> 
>> --
>> Ant?nio Olinto ?vila da Silva
>> Fisheries Institute
>> S?o Paulo, Brasil
>> 
>>        [[alternative HTML version deleted]]
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> -- 
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/


From aolinto.lst at gmail.com  Fri Dec  1 21:27:56 2017
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Fri, 1 Dec 2017 18:27:56 -0200
Subject: [R-sig-Geo] make a raster from Aquarius files
In-Reply-To: <7C5B491A-921A-430B-A30F-26D51ECB29A9@bigelow.org>
References: <CAE8g1gPGRAy6HNeMR2gXiUF_d90E0sQ8wq-qEzEdmH=kjVEAyg@mail.gmail.com>
 <CAAcGz9_ub5Dd01Z0rZE_BWF2GqL2pTW7vtmYwpDH6Jtw0TVDdg@mail.gmail.com>
 <7C5B491A-921A-430B-A30F-26D51ECB29A9@bigelow.org>
Message-ID: <CAE8g1gPDmCzRuFy2M3ZOUe0=MgY3P0ve+hwpUGsTyNieZyt3Aw@mail.gmail.com>

Thanks Ben and Michael for the attention

The file I'm trying to rasterize can be downloaded at
https://oceancolor.gsfc.nasa.gov/cgi/l3

I selected the Aquarius sea surface salinity smoothed file from June 2015
(SMI HDF).

As Ben pointed it is also available from OBPG Nasa Ocean Color site at
https://oceandata.sci.gsfc.nasa.gov/Aquarius/Mapped/Monthly/1deg/V5.0_SSS/

or directly from
https://oceandata.sci.gsfc.nasa.gov/cgi/getfile/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.bz2

Thanks again

Antonio Olinto Avila da Silva
Fisheries Institute
S?o Paulo, Brasil


2017-12-01 12:35 GMT-02:00 Ben Tupper <btupper at bigelow.org>:

> Hi,
>
> Those Aquarius files look quite different from others I have used from
> OBPG (mostly MODISA and SeaWiFS).
>
> As a short-cut alternative, you could read all of the values into a matrix
> and make a global raster from that.  An example is shown below.  You can
> also subset the extraction as you have shown, but it might be easier to
> subset after making the raster using raster::crop()
>
> CHeers,
> Ben
>
>
> ### START
>
> library(raster)
> library(ncdf4)
> library(rasterVis)
>
> filename = "Q20151522015181.L3m_MO_SCIA_V5.0_SSS_1deg"
>
> nc = ncdf4::nc_open(filename)
> m = ncdf4::ncvar_get(nc, 'l3m_data')
> ncdf4::nc_close(nc)
> r = raster::raster(t(m))
> rasterVis::levelplot(r)
>
> ### END
>
> > On Dec 1, 2017, at 6:24 AM, Michael Sumner <mdsumner at gmail.com> wrote:
> >
> > That file name does not correspond to the standard patterns used by the
> > oceancolor site. All the L3m products from there are now (NetCDF 4.0) .nc
> > and so will work fine with raster/ncdf4.  (Some years ago they were HDF4
> -
> > without an extension, as the shortcuts in the image thumbnails hints
> > (SMI/HDF and BIN/HDF - SMI/L3m standard mapped image in your case).
> >
> > I think you've got some other provider's version of a file, but there's
> not
> > enough information here to know where you got it or what form it's in.
> I'm
> > happy to look if you can point us to the source of
> > Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.
> >
> > But otherwise, can you share with us the output of
> >
> > nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
> > print(nc.data)
> >
> > and if you're on a suitable system with HDF4 support a gdalinfo output of
> > the file would be useful too.
> >
> > Given that you can read it with ncdf4, and if it actually is NetCDF4 (not
> > HDF4 or something else) you might help raster work with it by renaming it
> > to "Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.nc" since (unlike GDAL
> and
> > the NetCDF lib itself) raster uses explicit extension to dispatch to
> > different format logic code, though it ultimately sends it down to rgdal
> to
> > deal with if it can't recognize it - which is why I'm surprised you can't
> > get it to work and ( I'm guessing wildly now):
> >
> > Do you not have rgdal installed?
> >
> >
> > What system are you on? Please use sessionInfo() to share details.
> >
> > Cheers, Mike.
> > On Fri, 1 Dec 2017, 06:14 Antonio Silva, <aolinto.lst at gmail.com> wrote:
> >
> >> Hello
> >>
> >> Some time ago I prepared scripts to extract temperature data from Modis
> >> Aqua files. It can be found at https://gist.github.com/aolinto
> >>
> >> HDF files can be downloaded at https://oceancolor.gsfc.nasa.gov/cgi/l3
> >>
> >> I got the Aquarius sea surface salinity smoothed file from June 2015.
> >>
> >> I could open and read the file:
> >>
> >> library(ncdf4)
> >> library(raster)
> >>
> >> nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
> >> print(nc.data)
> >> dim(ncvar_get(nc.data,"l3m_data"))
> >> ncvar_get(nc.data,"l3m_data")[c(110:160),c(110:117)]
> >>
> >> But I could not prepare a raster from it. I tryed many things as:
> >>
> >> rst.data <-
> >> raster("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg",varname="l3m_data")
> >> Error in .local(.Object, ...) :
> >>  `AQUARIUS/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg' not recognised
> as a
> >> supported file format.
> >>
> >> Error in .rasterObjectFromFile(x, band = band, objecttype =
> "RasterLayer",
> >> :
> >>  Cannot create a RasterLayer object from this file.
> >>
> >> and variations with band and layer.
> >>
> >> I would greatly appreciate any suggestions to solve this issue.
> >>
> >> Thanks
> >>
> >> --
> >> Ant?nio Olinto ?vila da Silva
> >> Fisheries Institute
> >> S?o Paulo, Brasil
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >
> > --
> > Dr. Michael Sumner
> > Software and Database Engineer
> > Australian Antarctic Division
> > 203 Channel Highway
> > Kingston Tasmania 7050 Australia
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecocast Reports: http://seascapemodeling.org/ecocast.html
> Tick Reports: https://report.bigelow.org/tick/
> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>
>
>
>

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Dec  1 21:44:44 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 01 Dec 2017 20:44:44 +0000
Subject: [R-sig-Geo] make a raster from Aquarius files
In-Reply-To: <CAE8g1gPDmCzRuFy2M3ZOUe0=MgY3P0ve+hwpUGsTyNieZyt3Aw@mail.gmail.com>
References: <CAE8g1gPGRAy6HNeMR2gXiUF_d90E0sQ8wq-qEzEdmH=kjVEAyg@mail.gmail.com>
 <CAAcGz9_ub5Dd01Z0rZE_BWF2GqL2pTW7vtmYwpDH6Jtw0TVDdg@mail.gmail.com>
 <7C5B491A-921A-430B-A30F-26D51ECB29A9@bigelow.org>
 <CAE8g1gPDmCzRuFy2M3ZOUe0=MgY3P0ve+hwpUGsTyNieZyt3Aw@mail.gmail.com>
Message-ID: <CAAcGz99cDRS6Et=b5sp4815VuoQaRQ2byF+h3AN=kkukRqzP8Q@mail.gmail.com>

Ah thanks, and sorry I didn't think any of those old HDF4 files were still
there!

This is HDF5 with subdatasets, from gdalinfo:

Subdatasets:

SUBDATASET_1_NAME=HDF5:"Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg"://l3m_data
  SUBDATASET_1_DESC=[180x360] //l3m_data (32-bit floating-point)

SUBDATASET_2_NAME=HDF5:"Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg"://palette
  SUBDATASET_2_DESC=[3x256] //palette (8-bit unsigned character)

so you need to use the subdataset string directly i.e.

raster("HDF5:"Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")

or spit them out to seperate files at the command line first e.g.

gdal_translate Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg
Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.tif -sds

and this assumes a suitable system with HDF5 etc. etc.

rgdal on Windows now has HDF5 drivers so should work there too, and Ben's
method also.

Cheers, Mike.

On Sat, 2 Dec 2017 at 07:27 Antonio Silva <aolinto.lst at gmail.com> wrote:

> Thanks Ben and Michael for the attention
>
> The file I'm trying to rasterize can be downloaded at
> https://oceancolor.gsfc.nasa.gov/cgi/l3
>
> I selected the Aquarius sea surface salinity smoothed file from June 2015
> (SMI HDF).
>
> As Ben pointed it is also available from OBPG Nasa Ocean Color site at
> https://oceandata.sci.gsfc.nasa.gov/Aquarius/Mapped/Monthly/1deg/V5.0_SSS/
>
> or directly from
> https://oceandata.sci.gsfc.nasa.gov/cgi/getfile/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.bz2
>
> Thanks again
>
> Antonio Olinto Avila da Silva
> Fisheries Institute
> S?o Paulo, Brasil
>
>
> 2017-12-01 12:35 GMT-02:00 Ben Tupper <btupper at bigelow.org>:
>
>> Hi,
>>
>> Those Aquarius files look quite different from others I have used from
>> OBPG (mostly MODISA and SeaWiFS).
>>
>> As a short-cut alternative, you could read all of the values into a
>> matrix and make a global raster from that.  An example is shown below.  You
>> can also subset the extraction as you have shown, but it might be easier to
>> subset after making the raster using raster::crop()
>>
>> CHeers,
>> Ben
>>
>>
>> ### START
>>
>> library(raster)
>> library(ncdf4)
>> library(rasterVis)
>>
>> filename = "Q20151522015181.L3m_MO_SCIA_V5.0_SSS_1deg"
>>
>> nc = ncdf4::nc_open(filename)
>> m = ncdf4::ncvar_get(nc, 'l3m_data')
>> ncdf4::nc_close(nc)
>> r = raster::raster(t(m))
>> rasterVis::levelplot(r)
>>
>> ### END
>>
>> > On Dec 1, 2017, at 6:24 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>> >
>> > That file name does not correspond to the standard patterns used by the
>> > oceancolor site. All the L3m products from there are now (NetCDF 4.0)
>> .nc
>> > and so will work fine with raster/ncdf4.  (Some years ago they were
>> HDF4 -
>> > without an extension, as the shortcuts in the image thumbnails hints
>> > (SMI/HDF and BIN/HDF - SMI/L3m standard mapped image in your case).
>> >
>> > I think you've got some other provider's version of a file, but there's
>> not
>> > enough information here to know where you got it or what form it's in.
>> I'm
>> > happy to look if you can point us to the source of
>> > Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.
>> >
>> > But otherwise, can you share with us the output of
>> >
>> > nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
>> > print(nc.data)
>> >
>> > and if you're on a suitable system with HDF4 support a gdalinfo output
>> of
>> > the file would be useful too.
>> >
>> > Given that you can read it with ncdf4, and if it actually is NetCDF4
>> (not
>> > HDF4 or something else) you might help raster work with it by renaming
>> it
>> > to "Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.nc" since (unlike GDAL
>> and
>> > the NetCDF lib itself) raster uses explicit extension to dispatch to
>> > different format logic code, though it ultimately sends it down to
>> rgdal to
>> > deal with if it can't recognize it - which is why I'm surprised you
>> can't
>> > get it to work and ( I'm guessing wildly now):
>> >
>> > Do you not have rgdal installed?
>> >
>> >
>> > What system are you on? Please use sessionInfo() to share details.
>> >
>> > Cheers, Mike.
>> > On Fri, 1 Dec 2017, 06:14 Antonio Silva, <aolinto.lst at gmail.com> wrote:
>> >
>> >> Hello
>> >>
>> >> Some time ago I prepared scripts to extract temperature data from Modis
>> >> Aqua files. It can be found at https://gist.github.com/aolinto
>> >>
>> >> HDF files can be downloaded at https://oceancolor.gsfc.nasa.gov/cgi/l3
>> >>
>> >> I got the Aquarius sea surface salinity smoothed file from June 2015.
>> >>
>> >> I could open and read the file:
>> >>
>> >> library(ncdf4)
>> >> library(raster)
>> >>
>> >> nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
>> >> print(nc.data)
>> >> dim(ncvar_get(nc.data,"l3m_data"))
>> >> ncvar_get(nc.data,"l3m_data")[c(110:160),c(110:117)]
>> >>
>> >> But I could not prepare a raster from it. I tryed many things as:
>> >>
>> >> rst.data <-
>> >> raster("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg",varname="l3m_data")
>> >> Error in .local(.Object, ...) :
>> >>  `AQUARIUS/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg' not recognised
>> as a
>> >> supported file format.
>> >>
>> >> Error in .rasterObjectFromFile(x, band = band, objecttype =
>> "RasterLayer",
>> >> :
>> >>  Cannot create a RasterLayer object from this file.
>> >>
>> >> and variations with band and layer.
>> >>
>> >> I would greatly appreciate any suggestions to solve this issue.
>> >>
>> >> Thanks
>> >>
>> >> --
>> >> Ant?nio Olinto ?vila da Silva
>> >> Fisheries Institute
>> >> S?o Paulo, Brasil
>> >>
>> >>        [[alternative HTML version deleted]]
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>> > --
>> > Dr. Michael Sumner
>> > Software and Database Engineer
>> > Australian Antarctic Division
>> > 203 Channel Highway
>> <https://maps.google.com/?q=203+Channel+Highway+%0D+%3E+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>>
>> <https://maps.google.com/?q=203+Channel+Highway+%0D+%3E+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>>
>> Kingston Tasmania 7050 Australia
>> <https://maps.google.com/?q=203+Channel+Highway+%0D+%3E+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive
>> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>, P.O.
>> Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>>
>> Ecocast Reports: http://seascapemodeling.org/ecocast.html
>> Tick Reports: https://report.bigelow.org/tick/
>> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>>
>>
>>
>>
>
>
>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Fri Dec  1 21:57:03 2017
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 01 Dec 2017 20:57:03 +0000
Subject: [R-sig-Geo] make a raster from Aquarius files
In-Reply-To: <CAAcGz99cDRS6Et=b5sp4815VuoQaRQ2byF+h3AN=kkukRqzP8Q@mail.gmail.com>
References: <CAE8g1gPGRAy6HNeMR2gXiUF_d90E0sQ8wq-qEzEdmH=kjVEAyg@mail.gmail.com>
 <CAAcGz9_ub5Dd01Z0rZE_BWF2GqL2pTW7vtmYwpDH6Jtw0TVDdg@mail.gmail.com>
 <7C5B491A-921A-430B-A30F-26D51ECB29A9@bigelow.org>
 <CAE8g1gPDmCzRuFy2M3ZOUe0=MgY3P0ve+hwpUGsTyNieZyt3Aw@mail.gmail.com>
 <CAAcGz99cDRS6Et=b5sp4815VuoQaRQ2byF+h3AN=kkukRqzP8Q@mail.gmail.com>
Message-ID: <CAAcGz98+BqtFwugxhFzCMtDVhrOq7KyaikcAD4nBhOy9BO9N6w@mail.gmail.com>

Ugh, and you must think I'm crazy given that it's clearly HDF5 not HDF4 as
per my opening line (the file naming is more the latter). I'll stop now.
Hope it's useful.

Cheers, Mike.

On Sat, 2 Dec 2017 at 07:44 Michael Sumner <mdsumner at gmail.com> wrote:

> Ah thanks, and sorry I didn't think any of those old HDF4 files were still
> there!
>
> This is HDF5 with subdatasets, from gdalinfo:
>
> Subdatasets:
>
> SUBDATASET_1_NAME=HDF5:"Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg"://l3m_data
>   SUBDATASET_1_DESC=[180x360] //l3m_data (32-bit floating-point)
>
> SUBDATASET_2_NAME=HDF5:"Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg"://palette
>   SUBDATASET_2_DESC=[3x256] //palette (8-bit unsigned character)
>
> so you need to use the subdataset string directly i.e.
>
> raster("HDF5:"Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
>
> or spit them out to seperate files at the command line first e.g.
>
> gdal_translate Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg
> Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.tif -sds
>
> and this assumes a suitable system with HDF5 etc. etc.
>
> rgdal on Windows now has HDF5 drivers so should work there too, and Ben's
> method also.
>
> Cheers, Mike.
>
> On Sat, 2 Dec 2017 at 07:27 Antonio Silva <aolinto.lst at gmail.com> wrote:
>
>> Thanks Ben and Michael for the attention
>>
>> The file I'm trying to rasterize can be downloaded at
>> https://oceancolor.gsfc.nasa.gov/cgi/l3
>>
>> I selected the Aquarius sea surface salinity smoothed file from June 2015
>> (SMI HDF).
>>
>> As Ben pointed it is also available from OBPG Nasa Ocean Color site at
>> https://oceandata.sci.gsfc.nasa.gov/Aquarius/Mapped/Monthly/1deg/V5.0_SSS/
>>
>> or directly from
>> https://oceandata.sci.gsfc.nasa.gov/cgi/getfile/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.bz2
>>
>> Thanks again
>>
>> Antonio Olinto Avila da Silva
>> Fisheries Institute
>> S?o Paulo, Brasil
>>
>>
>> 2017-12-01 12:35 GMT-02:00 Ben Tupper <btupper at bigelow.org>:
>>
>>> Hi,
>>>
>>> Those Aquarius files look quite different from others I have used from
>>> OBPG (mostly MODISA and SeaWiFS).
>>>
>>> As a short-cut alternative, you could read all of the values into a
>>> matrix and make a global raster from that.  An example is shown below.  You
>>> can also subset the extraction as you have shown, but it might be easier to
>>> subset after making the raster using raster::crop()
>>>
>>> CHeers,
>>> Ben
>>>
>>>
>>> ### START
>>>
>>> library(raster)
>>> library(ncdf4)
>>> library(rasterVis)
>>>
>>> filename = "Q20151522015181.L3m_MO_SCIA_V5.0_SSS_1deg"
>>>
>>> nc = ncdf4::nc_open(filename)
>>> m = ncdf4::ncvar_get(nc, 'l3m_data')
>>> ncdf4::nc_close(nc)
>>> r = raster::raster(t(m))
>>> rasterVis::levelplot(r)
>>>
>>> ### END
>>>
>>> > On Dec 1, 2017, at 6:24 AM, Michael Sumner <mdsumner at gmail.com> wrote:
>>> >
>>> > That file name does not correspond to the standard patterns used by the
>>> > oceancolor site. All the L3m products from there are now (NetCDF 4.0)
>>> .nc
>>> > and so will work fine with raster/ncdf4.  (Some years ago they were
>>> HDF4 -
>>> > without an extension, as the shortcuts in the image thumbnails hints
>>> > (SMI/HDF and BIN/HDF - SMI/L3m standard mapped image in your case).
>>> >
>>> > I think you've got some other provider's version of a file, but
>>> there's not
>>> > enough information here to know where you got it or what form it's in.
>>> I'm
>>> > happy to look if you can point us to the source of
>>> > Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.
>>> >
>>> > But otherwise, can you share with us the output of
>>> >
>>> > nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
>>> > print(nc.data)
>>> >
>>> > and if you're on a suitable system with HDF4 support a gdalinfo output
>>> of
>>> > the file would be useful too.
>>> >
>>> > Given that you can read it with ncdf4, and if it actually is NetCDF4
>>> (not
>>> > HDF4 or something else) you might help raster work with it by renaming
>>> it
>>> > to "Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg.nc" since (unlike GDAL
>>> and
>>> > the NetCDF lib itself) raster uses explicit extension to dispatch to
>>> > different format logic code, though it ultimately sends it down to
>>> rgdal to
>>> > deal with if it can't recognize it - which is why I'm surprised you
>>> can't
>>> > get it to work and ( I'm guessing wildly now):
>>> >
>>> > Do you not have rgdal installed?
>>> >
>>> >
>>> > What system are you on? Please use sessionInfo() to share details.
>>> >
>>> > Cheers, Mike.
>>> > On Fri, 1 Dec 2017, 06:14 Antonio Silva, <aolinto.lst at gmail.com>
>>> wrote:
>>> >
>>> >> Hello
>>> >>
>>> >> Some time ago I prepared scripts to extract temperature data from
>>> Modis
>>> >> Aqua files. It can be found at https://gist.github.com/aolinto
>>> >>
>>> >> HDF files can be downloaded at
>>> https://oceancolor.gsfc.nasa.gov/cgi/l3
>>> >>
>>> >> I got the Aquarius sea surface salinity smoothed file from June 2015.
>>> >>
>>> >> I could open and read the file:
>>> >>
>>> >> library(ncdf4)
>>> >> library(raster)
>>> >>
>>> >> nc.data<-nc_open("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg")
>>> >> print(nc.data)
>>> >> dim(ncvar_get(nc.data,"l3m_data"))
>>> >> ncvar_get(nc.data,"l3m_data")[c(110:160),c(110:117)]
>>> >>
>>> >> But I could not prepare a raster from it. I tryed many things as:
>>> >>
>>> >> rst.data <-
>>> >>
>>> raster("Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg",varname="l3m_data")
>>> >> Error in .local(.Object, ...) :
>>> >>  `AQUARIUS/Q20151522015181.L3m_MO_SCISM_V5.0_SSS_1deg' not recognised
>>> as a
>>> >> supported file format.
>>> >>
>>> >> Error in .rasterObjectFromFile(x, band = band, objecttype =
>>> "RasterLayer",
>>> >> :
>>> >>  Cannot create a RasterLayer object from this file.
>>> >>
>>> >> and variations with band and layer.
>>> >>
>>> >> I would greatly appreciate any suggestions to solve this issue.
>>> >>
>>> >> Thanks
>>> >>
>>> >> --
>>> >> Ant?nio Olinto ?vila da Silva
>>> >> Fisheries Institute
>>> >> S?o Paulo, Brasil
>>> >>
>>> >>        [[alternative HTML version deleted]]
>>> >>
>>> >> _______________________________________________
>>> >> R-sig-Geo mailing list
>>> >> R-sig-Geo at r-project.org
>>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> >
>>> > --
>>> > Dr. Michael Sumner
>>> > Software and Database Engineer
>>> > Australian Antarctic Division
>>> > 203 Channel Highway
>>> <https://maps.google.com/?q=203+Channel+Highway+%0D+%3E+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>>>
>>> <https://maps.google.com/?q=203+Channel+Highway+%0D+%3E+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>>
>>> Kingston Tasmania 7050 Australia
>>> <https://maps.google.com/?q=203+Channel+Highway+%0D+%3E+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > _______________________________________________
>>> > R-sig-Geo mailing list
>>> > R-sig-Geo at r-project.org
>>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>> Ben Tupper
>>> Bigelow Laboratory for Ocean Sciences
>>> 60 Bigelow Drive
>>> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>,
>>> P.O. Box 380
>>> East Boothbay, Maine 04544
>>> http://www.bigelow.org
>>>
>>> Ecocast Reports: http://seascapemodeling.org/ecocast.html
>>> Tick Reports: https://report.bigelow.org/tick/
>>> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>>>
>>>
>>>
>>>
>>
>>
>>
>> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From bernard2120 at outlook.com  Mon Dec  4 17:30:46 2017
From: bernard2120 at outlook.com (bernard julien)
Date: Mon, 4 Dec 2017 16:30:46 +0000
Subject: [R-sig-Geo] is the nugget parameter included in the "VariogramLine"
 function in gstat?
Message-ID: <DM5PR05MB3355A8ADCC30921E89F73882B13C0@DM5PR05MB3355.namprd05.prod.outlook.com>

Good day all,


I would like to know apply a smoothing effect to my kriging and thus, would like to include the nugget when generating my Covariance matrices for both measured and unmeasured locations.


I am generating my Covariance matrices using the variogramLine function as follows:


covariates <= variogram( response~covariate1+covariate2, spatial_df,cressie=TRUE)

A <- vgm("Exp")
myvariog<- fit.variogram(covariates, A)

V = variogramLine( myvariog, dist_vector = sp::spDists(as.matrix(measured), as.matrix(measured), longlat=FALSE),covariance = TRUE)

Is it assumed the nugget is included when forming the Covariance matrix when using VariogramLine?


thank you.

Bernard

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Mon Dec  4 22:33:37 2017
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 4 Dec 2017 22:33:37 +0100
Subject: [R-sig-Geo] is the nugget parameter included in the
 "VariogramLine" function in gstat?
In-Reply-To: <DM5PR05MB3355A8ADCC30921E89F73882B13C0@DM5PR05MB3355.namprd05.prod.outlook.com>
References: <DM5PR05MB3355A8ADCC30921E89F73882B13C0@DM5PR05MB3355.namprd05.prod.outlook.com>
Message-ID: <6e45a905-d528-18e3-4ecd-bcf469c62351@uni-muenster.de>



On 12/04/2017 05:30 PM, bernard julien wrote:
> Good day all,
> 
> 
> I would like to know apply a smoothing effect to my kriging and thus, would like to include the nugget when generating my Covariance matrices for both measured and unmeasured locations.
> 
> 
> I am generating my Covariance matrices using the variogramLine function as follows:
> 
> 
> covariates <= variogram( response~covariate1+covariate2, spatial_df,cressie=TRUE)
> 
> A <- vgm("Exp")
> myvariog<- fit.variogram(covariates, A)
> 
> V = variogramLine( myvariog, dist_vector = sp::spDists(as.matrix(measured), as.matrix(measured), longlat=FALSE),covariance = TRUE)
> 
> Is it assumed the nugget is included when forming the Covariance matrix when using VariogramLine?

Yes: it will add to the entries corresponding to zero values in dist_vector.

> variogramLine(vgm(1, "Exp", 1, 0), dist_vector =
matrix(c(0,1,1,0),2),covariance=TRUE)
          [,1]      [,2]
[1,] 1.0000000 0.3678794
[2,] 0.3678794 1.0000000
> variogramLine(vgm(1, "Exp", 1, 1), dist_vector =
matrix(c(0,1,1,0),2),covariance=TRUE)
          [,1]      [,2]
[1,] 2.0000000 0.3678794
[2,] 0.3678794 2.0000000


> 
> 
> thank you.
> 
> Bernard
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From chino_tones at hotmail.com  Tue Dec  5 16:35:05 2017
From: chino_tones at hotmail.com (Joelle k. Akram)
Date: Tue, 5 Dec 2017 15:35:05 +0000
Subject: [R-sig-Geo] Why is the covariance in Universal Kriging modeled
 this way in lectures by Prof. Edzer Pebesma?
In-Reply-To: <4f96f149-5096-9c42-ecfe-1d7b3386b760@uni-muenster.de>
References: <YTXPR0101MB1149BA555ACBFB88134DA18B90230@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
 <9fca0070-f9ad-1c68-cd81-cf77c265f338@uni-muenster.de>
 <YTXPR0101MB11490478EF8EB27A738C1BA490200@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>,
 <4f96f149-5096-9c42-ecfe-1d7b3386b760@uni-muenster.de>
Message-ID: <YTXPR0101MB1149B7E8B49827BEA704A9A2903D0@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>

hi Prof. Pebesma,


just to follow up on my question about adding the nugget term to both V and v from your lecture 7 on github.

I do not want an exact interpolator. Instead I want to do a smoothing interpolator using UnivKrig. Would you

recommend only adding the nugget to V only ? and set the nugget=0 for defining v (whilst retaining the same psill and range used for defining V).

thanks
Chris Akram

________________________________
From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Sent: November 22, 2017 2:55 PM
To: Joelle k. Akram; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Why is the covariance in Universal Kriging modeled this way in lectures by Prof. Edzer Pebesma?



On 11/22/2017 10:23 PM, Joelle k. Akram wrote:
> thank you for clarifying Prof. Pebesma. I have a couple more question
> for you regarding the inclusion of a
>
> nugget to the diagonals of V. As we know,there are 2 covariances, V and
> v; one for the existing coordinates (i.e., V) and the other for the
> distances between these existing coordinates and other new locations
> (i.e., v).
>
>
> I) Assuming unscaled coordinates in latitude/longitude; should the
> Nugget theoretically be a small value (lets say typically less than <1)
> or does it depend on other the dataset's spatial distribution,etc?
>

I would say it should depend on the data.

>
> 2) When computing Beta coefficients as in you lecture 7 in github, do we
> have to add the nugget term to both V and v or only one of them?

For a nugget, by definition to each of them; if you'd only add it to V
you no longer obtain an exact interpolator (i.e., you no longer predict
the data value at data locations); if your measured process is subject
to a measurement error, this may however be preferred.

>
>
> thank you,
>
> Chris Akram
>
>
>
>
> ------------------------------------------------------------------------
> *From:* R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Edzer
> Pebesma <edzer.pebesma at uni-muenster.de>
> *Sent:* November 22, 2017 6:16 AM
> *To:* r-sig-geo at r-project.org
> *Subject:* Re: [R-sig-Geo] Why is the covariance in Universal Kriging
> modeled this way in lectures by Prof. Edzer Pebesma?
>
>
>
> On 11/22/2017 12:09 AM, Joelle k. Akram wrote:
>> Greetings,
>>
>> There is code for Universal Kriging from Prof. Edzer Pebesma in GitHub<https://github.com/edzer/mstp/blob/master/lec7.Rmd>.
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



>
> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



> github.com
> mstp - Course slides: modelling spatio-temporal processes
>
>
>
>
> https://edzer.github.io/mstp/lec7.html
>
> gives you the rendered version.
>
>>
>> The covariance function is defined as follows:
>>
>> cov = function(h) exp(-h)
>>
>> And defined without any variogram modeling/generation to produce partial sill, range or nugget parameters for defining the covariance matrix.
>
> Well, it implies nugget=0, sill=1 and range parameter=1, it was the
> shortest covariance function I could think of.
>
>>
>> If  I want to include a regularization term to account for singularity effects caused due to close spatial points, how do I modify the matrix computation for computing the 'beta' coefficients ?
>
> Add a nugget (i.e. add a constant to the diagonal of V)?
>
>>
>> I know there are standard formulae for different models (e.g. Matern, Exp,etc). But I would like to retain the simple cov function defined above and possibly use a regularizer (like ridge regression) to account for a nugget-like effect.
>>
>> thanks,
>>
>> Chris
>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
A mailing list for discussing the development and use of R functions and packages for handling and analysis of spatial, and particularly geographical, data.



>>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics
> Heisenbergstrasse 2, 48151 Muenster, Germany
> Phone: +49 251 8333081
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
A mailing list for discussing the development and use of R functions and packages for handling and analysis of spatial, and particularly geographical, data.




--
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081

	[[alternative HTML version deleted]]


From mauricio.mardones at ifop.cl  Tue Dec  5 16:45:17 2017
From: mauricio.mardones at ifop.cl (Mauricio Mardones Inostroza)
Date: Tue, 5 Dec 2017 12:45:17 -0300
Subject: [R-sig-Geo] format. adm
Message-ID: <CAG=XH2uJtyFDKamvvynnwFGvPx3dEiSoHN9ehTntE0SaHTkdYA@mail.gmail.com>

Dear group

Do you know some routine to transform .adm files from a Garmin echo sounder
to a .txt or .csv?

I hope you can help me

Regards

-- 

*Mauricio Mardones Inostroza*

Investigador Departamento Evaluaci?n de Recursos
Instituto de Fomento Pesquero - IFOP
Valpara?so - Chile
+56-32-21514 <callto:+56-32-2151424>42

www.ifop.cl

-- 
*Certificaci?n SO 9001/2008*: Sistema de Datos Biol?gico-Pesqueros (Arica, 
Iquique, Coquimbo, Valpara?so, San Antonio, Talcahuano y Calbuco, 
pesquer?as industriales y artesanales)

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Tue Dec  5 16:51:46 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 5 Dec 2017 15:51:46 +0000
Subject: [R-sig-Geo] format. adm
In-Reply-To: <CAG=XH2uJtyFDKamvvynnwFGvPx3dEiSoHN9ehTntE0SaHTkdYA@mail.gmail.com>
References: <CAG=XH2uJtyFDKamvvynnwFGvPx3dEiSoHN9ehTntE0SaHTkdYA@mail.gmail.com>
Message-ID: <CANVKczPwOD9J3UzHhWOEvuKRKN7kQSHG7O7QPc9m1GqnH6jaLQ@mail.gmail.com>

Do you have a sample file you could share? I've tried a quick internet
search, and nothing sticks out.

There seems to have been one effort about seven years ago that died out:

http://gpsbabel.2324879.n4.nabble.com/Garmin-ADM-file-format-td3588.html

If you have a typical file and you know roughly what is in it (tracks,
waypoints, etc) then we might be able to write a decoder.

Barry



2017-12-05 15:45 GMT+00:00 Mauricio Mardones Inostroza <
mauricio.mardones at ifop.cl>:

> Dear group
>
> Do you know some routine to transform .adm files from a Garmin echo sounder
> to a .txt or .csv?
>
> I hope you can help me
>
> Regards
>
> --
>
> *Mauricio Mardones Inostroza*
>
> Investigador Departamento Evaluaci?n de Recursos
> Instituto de Fomento Pesquero - IFOP
> Valpara?so - Chile
> +56-32-21514 <callto:+56-32-2151424>42
>
> www.ifop.cl
>
> --
> *Certificaci?n SO 9001/2008*: Sistema de Datos Biol?gico-Pesqueros (Arica,
> Iquique, Coquimbo, Valpara?so, San Antonio, Talcahuano y Calbuco,
> pesquer?as industriales y artesanales)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Tue Dec  5 16:55:09 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 5 Dec 2017 15:55:09 +0000
Subject: [R-sig-Geo] format. adm
In-Reply-To: <CAG=XH2uJtyFDKamvvynnwFGvPx3dEiSoHN9ehTntE0SaHTkdYA@mail.gmail.com>
References: <CAG=XH2uJtyFDKamvvynnwFGvPx3dEiSoHN9ehTntE0SaHTkdYA@mail.gmail.com>
Message-ID: <CANVKczMj-cmDEWuhnvrBnXVSq6JtPihWDJvyVQOix7jRahwrww@mail.gmail.com>

There's a converter on sourceforge that claims it can convert adm to gpx,
and you can read gpx with rgdal:

https://sourceforge.net/projects/adm2gpx/



2017-12-05 15:45 GMT+00:00 Mauricio Mardones Inostroza <
mauricio.mardones at ifop.cl>:

> Dear group
>
> Do you know some routine to transform .adm files from a Garmin echo sounder
> to a .txt or .csv?
>
> I hope you can help me
>
> Regards
>
> --
>
> *Mauricio Mardones Inostroza*
>
> Investigador Departamento Evaluaci?n de Recursos
> Instituto de Fomento Pesquero - IFOP
> Valpara?so - Chile
> +56-32-21514 <callto:+56-32-2151424>42
>
> www.ifop.cl
>
> --
> *Certificaci?n SO 9001/2008*: Sistema de Datos Biol?gico-Pesqueros (Arica,
> Iquique, Coquimbo, Valpara?so, San Antonio, Talcahuano y Calbuco,
> pesquer?as industriales y artesanales)
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Tue Dec  5 16:59:05 2017
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 5 Dec 2017 16:59:05 +0100
Subject: [R-sig-Geo] Why is the covariance in Universal Kriging modeled
 this way in lectures by Prof. Edzer Pebesma?
In-Reply-To: <YTXPR0101MB1149B7E8B49827BEA704A9A2903D0@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
References: <YTXPR0101MB1149BA555ACBFB88134DA18B90230@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
 <9fca0070-f9ad-1c68-cd81-cf77c265f338@uni-muenster.de>
 <YTXPR0101MB11490478EF8EB27A738C1BA490200@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
 <4f96f149-5096-9c42-ecfe-1d7b3386b760@uni-muenster.de>
 <YTXPR0101MB1149B7E8B49827BEA704A9A2903D0@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <aeff297d-cf72-397f-c07e-84707305f368@uni-muenster.de>



On 12/05/2017 04:35 PM, Joelle k. Akram wrote:
> hi Prof. Pebesma,
> 
> 
> just to follow up on my question about?adding the nugget term to both V
> and v from your lecture 7 on github.
> 
> I do not want an exact interpolator. Instead I want to do a smoothing
> interpolator using UnivKrig. Would you?
> 
> recommend only adding the nugget to V only ? and set the nugget=0?for
> defining?v (whilst retaining the same?psill and range used for defining?V).

Yes.

> 
> 
> thanks
> Chris Akram
> 
> ------------------------------------------------------------------------
> *From:* Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> *Sent:* November 22, 2017 2:55 PM
> *To:* Joelle k. Akram; r-sig-geo at r-project.org
> *Subject:* Re: [R-sig-Geo] Why is the covariance in Universal Kriging
> modeled this way in lectures by Prof. Edzer Pebesma?
> ?
> 
> 
> On 11/22/2017 10:23 PM, Joelle k. Akram wrote:
>> thank you for clarifying Prof. Pebesma. I have a couple more question
>> for you regarding the inclusion of a
>> 
>> nugget to the diagonals of V. As we know,there are 2 covariances, V and
>> v;?one for the existing coordinates (i.e., V)?and the other for the
>> distances between these existing coordinates and other new locations
>> (i.e., v).
>> 
>> 
>> I) Assuming unscaled coordinates in latitude/longitude; should the
>> Nugget theoretically be a small value (lets say typically less than <1)
>> or does it depend on other the dataset's spatial distribution,etc?
>> 
> 
> I would say it should depend on the data.
> 
>> 
>> 2) When computing Beta coefficients as in you lecture 7 in github, do we
>> have to add the nugget term to both V and v or only one of them?
> 
> For a nugget, by definition to each of them; if you'd only add it to V
> you no longer obtain an exact interpolator (i.e., you no longer predict
> the data value at data locations); if your measured process is subject
> to a measurement error, this may however be preferred.
> 
>> 
>> 
>> thank you,
>> 
>> Chris Akram
>> 
>> 
>> 
>> 
>> ------------------------------------------------------------------------
>> *From:* R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Edzer
>> Pebesma <edzer.pebesma at uni-muenster.de>
>> *Sent:* November 22, 2017 6:16 AM
>> *To:* r-sig-geo at r-project.org
>> *Subject:* Re: [R-sig-Geo] Why is the covariance in Universal Kriging
>> modeled this way in lectures by Prof. Edzer Pebesma?
>> ?
>> 
>> 
>> On 11/22/2017 12:09 AM, Joelle k. Akram wrote:
>>> Greetings,
>>> 
>>> There is code for Universal Kriging from Prof. Edzer Pebesma in GitHub<https://github.com/edzer/mstp/blob/master/lec7.Rmd>.
> <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
> 	
> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
> github.com
> mstp - Course slides: modelling spatio-temporal processes
> 
> 
> 
>> 
>> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
> <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
> 	
> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
> github.com
> mstp - Course slides: modelling spatio-temporal processes
> 
> 
> 
>> github.com
>> mstp - Course slides: modelling spatio-temporal processes
>> 
>> 
>> 
>> 
>> https://edzer.github.io/mstp/lec7.html
>> 
>> gives you the rendered version.
>> 
>>> 
>>> The covariance function is defined as follows:
>>> 
>>> cov = function(h) exp(-h)
>>> 
>>> And defined without any variogram modeling/generation to produce partial sill, range or nugget parameters for defining the covariance matrix.
>> 
>> Well, it implies nugget=0, sill=1 and range parameter=1, it was the
>> shortest covariance function I could think of.
>> 
>>> 
>>> If? I want to include a regularization term to account for singularity effects caused due to close spatial points, how do I modify the matrix computation for computing the 'beta' coefficients ?
>> 
>> Add a nugget (i.e. add a constant to the diagonal of V)?
>> 
>>> 
>>> I know there are standard formulae for different models (e.g. Matern, Exp,etc). But I would like to retain the simple cov function defined above and possibly use a regularizer (like ridge regression) to account for a nugget-like effect.
>>> 
>>> thanks,
>>> 
>>> Chris
>>> 
>>>??????? [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...
> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> stat.ethz.ch
> A mailing list for discussing the development and use of R functions and
> packages for handling and analysis of spatial, and particularly
> geographical, data.
> 
> 
> 
>>> 
>> 
>> -- 
>> Edzer Pebesma
>> Institute for Geoinformatics
>> Heisenbergstrasse 2, 48151 Muenster, Germany
>> Phone: +49 251 8333081
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...
> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
> stat.ethz.ch
> A mailing list for discussing the development and use of R functions and
> packages for handling and analysis of spatial, and particularly
> geographical, data.
> 
> 
> 
> 
> -- 
> Edzer Pebesma
> Institute for Geoinformatics
> Heisenbergstrasse 2, 48151 Muenster, Germany
> Phone: +49 251 8333081

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From chino_tones at hotmail.com  Tue Dec  5 17:20:43 2017
From: chino_tones at hotmail.com (Joelle k. Akram)
Date: Tue, 5 Dec 2017 16:20:43 +0000
Subject: [R-sig-Geo] Why is the covariance in Universal Kriging modeled
 this way in lectures by Prof. Edzer Pebesma?
In-Reply-To: <aeff297d-cf72-397f-c07e-84707305f368@uni-muenster.de>
References: <YTXPR0101MB1149BA555ACBFB88134DA18B90230@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
 <9fca0070-f9ad-1c68-cd81-cf77c265f338@uni-muenster.de>
 <YTXPR0101MB11490478EF8EB27A738C1BA490200@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>
 <4f96f149-5096-9c42-ecfe-1d7b3386b760@uni-muenster.de>
 <YTXPR0101MB1149B7E8B49827BEA704A9A2903D0@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>,
 <aeff297d-cf72-397f-c07e-84707305f368@uni-muenster.de>
Message-ID: <YTXPR0101MB114956B4C331529F5C1E427D903D0@YTXPR0101MB1149.CANPRD01.PROD.OUTLOOK.COM>

Thanks Prof. Pebesma.

In your opinion, by setting nugget=0 for unmeasured locations, what does it represent physically?

>From my understanding, it means the unmeasured locations we want to predict/interpolate has no measurement error.

But is this a valid assumption? ( given that for the known, measure locations we use a nugget to define the covariance) .

-Chris
________________________________
From: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Sent: December 5, 2017 8:59 AM
To: Joelle k. Akram; r-sig-geo at r-project.org
Subject: Re: [R-sig-Geo] Why is the covariance in Universal Kriging modeled this way in lectures by Prof. Edzer Pebesma?



On 12/05/2017 04:35 PM, Joelle k. Akram wrote:
> hi Prof. Pebesma,
>
>
> just to follow up on my question about adding the nugget term to both V
> and v from your lecture 7 on github.
>
> I do not want an exact interpolator. Instead I want to do a smoothing
> interpolator using UnivKrig. Would you
>
> recommend only adding the nugget to V only ? and set the nugget=0 for
> defining v (whilst retaining the same psill and range used for defining V).

Yes.

>
>
> thanks
> Chris Akram
>
> ------------------------------------------------------------------------
> *From:* Edzer Pebesma <edzer.pebesma at uni-muenster.de>
> *Sent:* November 22, 2017 2:55 PM
> *To:* Joelle k. Akram; r-sig-geo at r-project.org
> *Subject:* Re: [R-sig-Geo] Why is the covariance in Universal Kriging
> modeled this way in lectures by Prof. Edzer Pebesma?
>
>
>
> On 11/22/2017 10:23 PM, Joelle k. Akram wrote:
>> thank you for clarifying Prof. Pebesma. I have a couple more question
>> for you regarding the inclusion of a
>>
>> nugget to the diagonals of V. As we know,there are 2 covariances, V and
>> v; one for the existing coordinates (i.e., V) and the other for the
>> distances between these existing coordinates and other new locations
>> (i.e., v).
>>
>>
>> I) Assuming unscaled coordinates in latitude/longitude; should the
>> Nugget theoretically be a small value (lets say typically less than <1)
>> or does it depend on other the dataset's spatial distribution,etc?
>>
>
> I would say it should depend on the data.
>
>>
>> 2) When computing Beta coefficients as in you lecture 7 in github, do we
>> have to add the nugget term to both V and v or only one of them?
>
> For a nugget, by definition to each of them; if you'd only add it to V
> you no longer obtain an exact interpolator (i.e., you no longer predict
> the data value at data locations); if your measured process is subject
> to a measurement error, this may however be preferred.
>
>>
>>
>> thank you,
>>
>> Chris Akram
>>
>>
>>
>>
>> ------------------------------------------------------------------------
>> *From:* R-sig-Geo <r-sig-geo-bounces at r-project.org> on behalf of Edzer
>> Pebesma <edzer.pebesma at uni-muenster.de>
>> *Sent:* November 22, 2017 6:16 AM
>> *To:* r-sig-geo at r-project.org
>> *Subject:* Re: [R-sig-Geo] Why is the covariance in Universal Kriging
>> modeled this way in lectures by Prof. Edzer Pebesma?
>>
>>
>>
>> On 11/22/2017 12:09 AM, Joelle k. Akram wrote:
>>> Greetings,
>>>
>>> There is code for Universal Kriging from Prof. Edzer Pebesma in GitHub<https://github.com/edzer/mstp/blob/master/lec7.Rmd>.
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



> <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



>
> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



> github.com
> mstp - Course slides: modelling spatio-temporal processes
>
>
>
>>
>> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



> <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



>
> edzer/mstp <https://github.com/edzer/mstp/blob/master/lec7.Rmd>
[https://avatars2.githubusercontent.com/u/520851?s=400&v=4]<https://github.com/edzer/mstp/blob/master/lec7.Rmd>

edzer/mstp<https://github.com/edzer/mstp/blob/master/lec7.Rmd>
github.com
mstp - Course slides: modelling spatio-temporal processes



> github.com
> mstp - Course slides: modelling spatio-temporal processes
>
>
>
>> github.com
>> mstp - Course slides: modelling spatio-temporal processes
>>
>>
>>
>>
>> https://edzer.github.io/mstp/lec7.html
>>
>> gives you the rendered version.
>>
>>>
>>> The covariance function is defined as follows:
>>>
>>> cov = function(h) exp(-h)
>>>
>>> And defined without any variogram modeling/generation to produce partial sill, range or nugget parameters for defining the covariance matrix.
>>
>> Well, it implies nugget=0, sill=1 and range parameter=1, it was the
>> shortest covariance function I could think of.
>>
>>>
>>> If  I want to include a regularization term to account for singularity effects caused due to close spatial points, how do I modify the matrix computation for computing the 'beta' coefficients ?
>>
>> Add a nugget (i.e. add a constant to the diagonal of V)?
>>
>>>
>>> I know there are standard formulae for different models (e.g. Matern, Exp,etc). But I would like to retain the simple cov function defined above and possibly use a regularizer (like ridge regression) to account for a nugget-like effect.
>>>
>>> thanks,
>>>
>>> Chris
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
A mailing list for discussing the development and use of R functions and packages for handling and analysis of spatial, and particularly geographical, data.



> R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...
> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
A mailing list for discussing the development and use of R functions and packages for handling and analysis of spatial, and particularly geographical, data.



> stat.ethz.ch
> A mailing list for discussing the development and use of R functions and
> packages for handling and analysis of spatial, and particularly
> geographical, data.
>
>
>
>>>
>>
>> --
>> Edzer Pebesma
>> Institute for Geoinformatics
>> Heisenbergstrasse 2, 48151 Muenster, Germany
>> Phone: +49 251 8333081
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
A mailing list for discussing the development and use of R functions and packages for handling and analysis of spatial, and particularly geographical, data.



> R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...
> <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
R-sig-Geo Info Page - SfS ? Seminar for Statistics | ETH ...<https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
stat.ethz.ch
A mailing list for discussing the development and use of R functions and packages for handling and analysis of spatial, and particularly geographical, data.



> stat.ethz.ch
> A mailing list for discussing the development and use of R functions and
> packages for handling and analysis of spatial, and particularly
> geographical, data.
>
>
>
>
> --
> Edzer Pebesma
> Institute for Geoinformatics
> Heisenbergstrasse 2, 48151 Muenster, Germany
> Phone: +49 251 8333081

--
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081

	[[alternative HTML version deleted]]


From julian.burgos at hafogvatn.is  Thu Dec  7 17:28:24 2017
From: julian.burgos at hafogvatn.is (Julian M. Burgos)
Date: Thu, 07 Dec 2017 16:28:24 +0000
Subject: [R-sig-Geo] gstat: block kriging variance
Message-ID: <xgzvahiy02f.fsf@hafogvatn.is>

Dear list,

I am doing block kriging using the gstat package in order to estimate
the mean and variance of a variable over an irregular polygon. I do this
by passing to the krige function a SpatialPolyons object under the
newdata argument. The krige block variance is calculated (as I
understand) using the point-to-point, point-to-block and within-block
variograms.

My question is about how this calculation is done in gstat. It seems that
gstat's krige function deals with an irregular polygon by discretising
it using the spsample function to select a number of regular nodes in
the polygon (~500 by default).  But according to Goovaerts (1999,
Geostatistical Tools for Deriving Block-Averaged Values of Environmental
Attributes, p.91), this approach is difficult because "the variance of the
global estimator cannot be derived as a mere combination of the kriging
variances at each discretizing point".  But clearly gstat is producing a
krige variance estimate.  So how it is done?

At the end, what I want is to be sure that the variance estimate is
valid. :)

Many thanks for the clarification,

Julian

--
Julian Mariano Burgos, PhD
Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
Marine and Freshwater Research Institute
Botnsj?varsvi?s / Demersal Division
Sk?lagata 4, 121 Reykjav?k, Iceland
S?mi/Telephone : +354-5752037
Br?fs?mi/Telefax:  +354-5752001
Netfang/Email: julian.burgos at hafogvatn.is


From b.rowlingson at lancaster.ac.uk  Thu Dec  7 18:00:50 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 7 Dec 2017 17:00:50 +0000
Subject: [R-sig-Geo] format. adm
In-Reply-To: <CANVKczMj-cmDEWuhnvrBnXVSq6JtPihWDJvyVQOix7jRahwrww@mail.gmail.com>
References: <CAG=XH2uJtyFDKamvvynnwFGvPx3dEiSoHN9ehTntE0SaHTkdYA@mail.gmail.com>
 <CANVKczMj-cmDEWuhnvrBnXVSq6JtPihWDJvyVQOix7jRahwrww@mail.gmail.com>
Message-ID: <CANVKczMqobxnnwiiwT=511-h9DK3-jiRMAYZvKFH4nCEGz_QSg@mail.gmail.com>

Just bringing this back on-list after some off-list discussion in case
anyone reads this in the future and wonders what happened..

 * The adm2gpx converter from sourceforge seems to be the only open-source
code for converting Garmin's ADM format to anything else.

 * On Mauricio's data it failed badly to convert the waypoints (producing
nonsense waypoints) but produced some sensible track points, but every few
hundred track points were interrupted by about 20 nonsense points again,
all in the resulting GPX file.

 * The GPX failed to load into QGIS or R since GDAL/OGR took a strong
dislike to the broken waypoints.

 * I edited the GPX manually and deleted the waypoints. Now it would load,
but it still had the nonsense track points causing the track to scatter all
over the world.

 * Further text editing to remove the nonsense track points resulted in a
reasonable looking track but with big gaps where the nonsense points were,
possibly these were misencoded and real data has been removed.

In conclusion, there's no way to read Garmin ADM files into R, and no good
way to convert them to something that can - at least not with open source
tools. Other web documents trying to describe the ADM format seem to say it
is a bit hard to understand with variants changing substantial parts of the
structure - I suspect something like that has caused the problematic
conversion experienced.


Barry


On Tue, Dec 5, 2017 at 3:55 PM, Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

> There's a converter on sourceforge that claims it can convert adm to gpx,
> and you can read gpx with rgdal:
>
> https://sourceforge.net/projects/adm2gpx/
>
>
>
> 2017-12-05 15:45 GMT+00:00 Mauricio Mardones Inostroza <
> mauricio.mardones at ifop.cl>:
>
>> Dear group
>>
>> Do you know some routine to transform .adm files from a Garmin echo
>> sounder
>> to a .txt or .csv?
>>
>> I hope you can help me
>>
>> Regards
>>
>> --
>>
>> *Mauricio Mardones Inostroza*
>>
>> Investigador Departamento Evaluaci?n de Recursos
>> Instituto de Fomento Pesquero - IFOP
>> Valpara?so - Chile
>> +56-32-21514 <callto:+56-32-2151424>42
>>
>> www.ifop.cl
>>
>> --
>> *Certificaci?n SO 9001/2008*: Sistema de Datos Biol?gico-Pesqueros (Arica,
>> Iquique, Coquimbo, Valpara?so, San Antonio, Talcahuano y Calbuco,
>> pesquer?as industriales y artesanales)
>>
>>         [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>

	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Thu Dec  7 19:56:57 2017
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 7 Dec 2017 19:56:57 +0100
Subject: [R-sig-Geo] gstat: block kriging variance
In-Reply-To: <xgzvahiy02f.fsf@hafogvatn.is>
References: <xgzvahiy02f.fsf@hafogvatn.is>
Message-ID: <b5339e09-afe8-8ad1-706e-90140c74a228@uni-muenster.de>



On 12/07/2017 05:28 PM, Julian M. Burgos wrote:
> Dear list,
> 
> I am doing block kriging using the gstat package in order to estimate
> the mean and variance of a variable over an irregular polygon. I do this
> by passing to the krige function a SpatialPolyons object under the
> newdata argument. The krige block variance is calculated (as I
> understand) using the point-to-point, point-to-block and within-block
> variograms.
> 
> My question is about how this calculation is done in gstat. It seems that
> gstat's krige function deals with an irregular polygon by discretising
> it using the spsample function to select a number of regular nodes in
> the polygon (~500 by default).  But according to Goovaerts (1999,
> Geostatistical Tools for Deriving Block-Averaged Values of Environmental
> Attributes, p.91), this approach is difficult because "the variance of the
> global estimator cannot be derived as a mere combination of the kriging
> variances at each discretizing point".  But clearly gstat is producing a
> krige variance estimate.  So how it is done?

It does exactly as what Goovaerts points to (read Journel & Huijbregts).

> 
> At the end, what I want is to be sure that the variance estimate is
> valid. :)

Of course it is approximate, but that is what happens with most
numerical integration. It is easy to think of weird cases where the
whole thing is not so valid, but I think it is unlikely that you
spontaneously create them.

> 
> Many thanks for the clarification,
> 
> Julian
> 
> --
> Julian Mariano Burgos, PhD
> Hafranns?knastofnun, ranns?kna- og r??gjafarstofnun hafs og vatna/
> Marine and Freshwater Research Institute
> Botnsj?varsvi?s / Demersal Division
> Sk?lagata 4, 121 Reykjav?k, Iceland
> S?mi/Telephone : +354-5752037
> Br?fs?mi/Telefax:  +354-5752001
> Netfang/Email: julian.burgos at hafogvatn.is
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From btupper at bigelow.org  Sat Dec  9 00:52:39 2017
From: btupper at bigelow.org (Ben Tupper)
Date: Fri, 8 Dec 2017 18:52:39 -0500
Subject: [R-sig-Geo] Reclassification of raster
In-Reply-To: <CAJgdCD4C0yL450GjBXVTssm9=hqhsVDAZK-XpimkFsPx0kbvXg@mail.gmail.com>
References: <CAJgdCD4C0yL450GjBXVTssm9=hqhsVDAZK-XpimkFsPx0kbvXg@mail.gmail.com>
Message-ID: <A98ED064-F5E6-49A5-B6AE-10A0B8D552DE@bigelow.org>

Hi John,

I'm happy to help, but I have copied the r-sig-geo list as the community (and you and I) benefit from using the list.

I'm not very clear on what you mean by 'I loose the negative values'. Also, I don't see the connection between the raster you show and the quantile values computed.  If you asked for the 0% quantile you should get the lowest available value - (since all pixels are at or above this value).  According to the raster info you show that should be -0.893809, but instead your 0% quantile is shown to be 40.00199   Perhaps you have unwittingly mixed up the rasters you are using.

Here is what I get using a small reproducible example (thanks, reprex! https://github.com/tidyverse/reprex <https://github.com/tidyverse/reprex>)  You can see that all of the -1 values are classified to class #1.

library(raster)
#> Loading required package: sp

# make a dummy matrix that ranges from -1 to 6 
nx = 10
ny = 5
m <- matrix(sample(-1:6, nx*ny, replace = TRUE), nrow = nx, ncol = ny)

# and make a raster
r <- raster(m)
r
#> class       : RasterLayer 
#> dimensions  : 10, 5, 50  (nrow, ncol, ncell)
#> resolution  : 0.2, 0.1  (x, y)
#> extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
#> coord. ref. : NA 
#> data source : in memory
#> names       : layer 
#> values      : -1, 6  (min, max)


# compute the quantiles
pp <- quantile(r, c(0, 0.15, 0.85))
pp
#>  0% 15% 85% 
#>  -1   0   5

# classify the pixels according to the quantile each pixel belongs to
ix <- findInterval(getValues(r), pp)

# make a classified version of r (class 0, 1 or 3)
classified_r <- setValues(r, ix) 
classified_r
#> class       : RasterLayer 
#> dimensions  : 10, 5, 50  (nrow, ncol, ncell)
#> resolution  : 0.2, 0.1  (x, y)
#> extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
#> coord. ref. : NA 
#> data source : in memory
#> names       : layer 
#> values      : 1, 3  (min, max)

# show how they pair up
df <- data.frame(value = getValues(r), class = getValues(classified_r))
df
#>    value class
#> 1      0     2
#> 2      0     2
#> 3      5     2
#> 4      6     3
#> 5      5     2
#> 6      4     2
#> 7      1     2
#> 8      5     2
#> 9     -1     1
#> 10     2     2
#> 11     0     2
#> 12     1     2
#> 13     3     2
#> 14     3     2
#> 15     6     3
#> 16    -1     1
#> 17     2     2
#> 18     6     3
#> 19     1     2
#> 20     0     2
#> 21     1     2
#> 22     5     2
#> 23     4     2
#> 24     2     2
#> 25     1     2
#> 26     0     2
#> 27     4     2
#> 28     6     3
#> 29     3     2
#> 30     0     2
#> 31     6     3
#> 32     6     3
#> 33     0     2
#> 34     2     2
#> 35     2     2
#> 36     6     3
#> 37     5     2
#> 38     6     3
#> 39     1     2
#> 40     5     2
#> 41     4     2
#> 42     4     2
#> 43     3     2
#> 44     4     2
#> 45     0     2
#> 46     4     2
#> 47     0     2
#> 48     1     2
#> 49     1     2
#> 50    -1     1


Cheers,
Ben


> On Dec 8, 2017, at 7:36 AM, John Wasige <johnwasige at gmail.com> wrote:
> 
> Hi Ben,
> 
> We had an email exchange on r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org> in June this year on raster classification where you made some suggestions. See the link below
> 
>  <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> 
>  <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> 
>  <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> However, when I run the reclassification, I loose the negative values. Any suggestion on how I can have all data classified & not loose pixels?
> Thanks for your help
> 
> pp <- quantile(r, c(0, 0.15, 0.85)) 
> # pp 
> #       0%      15%      85% 
> # 40.00199 47.64569 82.50751 
> ix <- findInterval(getValues(r), pp) 
> classified_r <- setValues(r, ix) 
> 
> ########
> 
> My raster looks;
> 
> class       : RasterLayer 
> dimensions  : 6557, 4281, 28070517  (nrow, ncol, ncell)
> resolution  : 0.0002335903, 0.0001525088  (x, y)
> extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
> coord. ref. : NA 
> data source : J:\LPD_data\gpp.tif 
> names       : gpp 
> values      : -0.893809, 5.855252  (min, max)
> 
> 
>  <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> 
>  <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecocast Reports: http://seascapemodeling.org/ecocast.html
Tick Reports: https://report.bigelow.org/tick/
Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/




	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Sun Dec 10 15:19:10 2017
From: johnwasige at gmail.com (John Wasige)
Date: Sun, 10 Dec 2017 15:19:10 +0100
Subject: [R-sig-Geo] Reclassification of raster
In-Reply-To: <A98ED064-F5E6-49A5-B6AE-10A0B8D552DE@bigelow.org>
References: <CAJgdCD4C0yL450GjBXVTssm9=hqhsVDAZK-XpimkFsPx0kbvXg@mail.gmail.com>
 <A98ED064-F5E6-49A5-B6AE-10A0B8D552DE@bigelow.org>
Message-ID: <CAJgdCD5bg9wmaHeKe4sX+Lppuz3pa_GhRqtm3L0iuc6ka5DWow@mail.gmail.com>

Thank you Ben,
works great!

Best Rgds
John

On Sat, Dec 9, 2017 at 12:52 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi John,
>
> I'm happy to help, but I have copied the r-sig-geo list as the community
> (and you and I) benefit from using the list.
>
> I'm not very clear on what you mean by 'I loose the negative values'.
> Also, I don't see the connection between the raster you show and the
> quantile values computed.  If you asked for the 0% quantile you should get
> the lowest available value - (since all pixels are at or above this
> value).  According to the raster info you show that should be -0.893809,
> but instead your 0% quantile is shown to be 40.00199   Perhaps you have
> unwittingly mixed up the rasters you are using.
>
> Here is what I get using a small reproducible example (thanks, reprex!
> https://github.com/tidyverse/reprex)  You can see that all of the -1
> values are classified to class #1.
>
> library(raster)
> #> Loading required package: sp
>
> # make a dummy matrix that ranges from -1 to 6
> nx = 10
> ny = 5
> m <- matrix(sample(-1:6, nx*ny, replace = TRUE), nrow = nx, ncol = ny)
>
> # and make a raster
> r <- raster(m)
> r
> #> class       : RasterLayer
> #> dimensions  : 10, 5, 50  (nrow, ncol, ncell)
> #> resolution  : 0.2, 0.1  (x, y)
> #> extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
> #> coord. ref. : NA
> #> data source : in memory
> #> names       : layer
> #> values      : -1, 6  (min, max)
>
>
> # compute the quantiles
> pp <- quantile(r, c(0, 0.15, 0.85))
> pp
> #>  0% 15% 85%
> #>  -1   0   5
>
> # classify the pixels according to the quantile each pixel belongs to
> ix <- findInterval(getValues(r), pp)
>
> # make a classified version of r (class 0, 1 or 3)
> classified_r <- setValues(r, ix)
> classified_r
> #> class       : RasterLayer
> #> dimensions  : 10, 5, 50  (nrow, ncol, ncell)
> #> resolution  : 0.2, 0.1  (x, y)
> #> extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
> #> coord. ref. : NA
> #> data source : in memory
> #> names       : layer
> #> values      : 1, 3  (min, max)
>
> # show how they pair up
> df <- data.frame(value = getValues(r), class = getValues(classified_r))
> df
> #>    value class
> #> 1      0     2
> #> 2      0     2
> #> 3      5     2
> #> 4      6     3
> #> 5      5     2
> #> 6      4     2
> #> 7      1     2
> #> 8      5     2
> #> 9     -1     1
> #> 10     2     2
> #> 11     0     2
> #> 12     1     2
> #> 13     3     2
> #> 14     3     2
> #> 15     6     3
> #> 16    -1     1
> #> 17     2     2
> #> 18     6     3
> #> 19     1     2
> #> 20     0     2
> #> 21     1     2
> #> 22     5     2
> #> 23     4     2
> #> 24     2     2
> #> 25     1     2
> #> 26     0     2
> #> 27     4     2
> #> 28     6     3
> #> 29     3     2
> #> 30     0     2
> #> 31     6     3
> #> 32     6     3
> #> 33     0     2
> #> 34     2     2
> #> 35     2     2
> #> 36     6     3
> #> 37     5     2
> #> 38     6     3
> #> 39     1     2
> #> 40     5     2
> #> 41     4     2
> #> 42     4     2
> #> 43     3     2
> #> 44     4     2
> #> 45     0     2
> #> 46     4     2
> #> 47     0     2
> #> 48     1     2
> #> 49     1     2
> #> 50    -1     1
>
>
> Cheers,
> Ben
>
>
> On Dec 8, 2017, at 7:36 AM, John Wasige <johnwasige at gmail.com> wrote:
>
> Hi Ben,
>
> We had an email exchange on r-sig-geo at r-project.org in June this year on
> raster classification where you made some suggestions. See the link below
>
>
> <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
>
>
> <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclas
> sify-raster-td7591266.html
>
>
> <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
> However, when I run the reclassification, I loose the negative values. Any
> suggestion on how I can have all data classified & not loose pixels?
> Thanks for your help
>
> pp <- quantile(r, c(0, 0.15, 0.85))
> # pp
> #       0%      15%      85%
> # 40.00199 47.64569 82.50751
> ix <- findInterval(getValues(r), pp)
> classified_r <- setValues(r, ix)
>
> ########
>
> My raster looks;
>
> class       : RasterLayer
> dimensions  : 6557, 4281, 28070517  (nrow, ncol, ncell)
> resolution  : 0.0002335903, 0.0001525088  (x, y)
> extent      : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)
> coord. ref. : NA
> data source : J:\LPD_data\gpp.tif
> names       : gpp
> values      : -0.893809, 5.855252  (min, max)
>
>
>
>
> <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
>
>
> <http://r-sig-geo.2731867.n2.nabble.com/Thresholds-amp-reclassify-raster-td7591266.html>
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive
> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>, P.O.
> Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecocast Reports: http://seascapemodeling.org/ecocast.html
> Tick Reports: https://report.bigelow.org/tick/
> Jellyfish Reports: https://jellyfish.bigelow.org/jellyfish/
>
>
>
>

	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Tue Dec 12 12:59:52 2017
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Tue, 12 Dec 2017 11:59:52 +0000
Subject: [R-sig-Geo] point pattern in 3D
In-Reply-To: <CAJgdCD5bg9wmaHeKe4sX+Lppuz3pa_GhRqtm3L0iuc6ka5DWow@mail.gmail.com>
References: <CAJgdCD4C0yL450GjBXVTssm9=hqhsVDAZK-XpimkFsPx0kbvXg@mail.gmail.com>
 <A98ED064-F5E6-49A5-B6AE-10A0B8D552DE@bigelow.org>,
 <CAJgdCD5bg9wmaHeKe4sX+Lppuz3pa_GhRqtm3L0iuc6ka5DWow@mail.gmail.com>
Message-ID: <VI1PR04MB316607A0A2E6D7EDD80E73D3B3340@VI1PR04MB3166.eurprd04.prod.outlook.com>

Dear members,

I write in order to ask if someone could indicate me if there is a way to measure and compare between groups the 3D homogeneity of a distribution of points in 3D. I think to some extension in 3D of usual point pattern analysis.

Thanks in advance for any advice

Best

Paolo


	[[alternative HTML version deleted]]


From paolo.piras at uniroma3.it  Tue Dec 12 13:01:12 2017
From: paolo.piras at uniroma3.it (Paolo Piras)
Date: Tue, 12 Dec 2017 12:01:12 +0000
Subject: [R-sig-Geo] 3D point pattern
Message-ID: <VI1PR04MB31665A297BD8B1601C1B06BDB3340@VI1PR04MB3166.eurprd04.prod.outlook.com>

Dear members,

I write in order to ask if someone could indicate me if there is a way to measure and compare between groups the 3D homogeneity of a distribution of points in 3D. I think to some extension in 3D of usual point pattern analysis.

Thanks in advance for any advice

Best

Paolo

	[[alternative HTML version deleted]]


From manuel.schneider at agroscope.admin.ch  Tue Dec 12 15:16:16 2017
From: manuel.schneider at agroscope.admin.ch (manuel.schneider at agroscope.admin.ch)
Date: Tue, 12 Dec 2017 14:16:16 +0000
Subject: [R-sig-Geo] +towgs84 in st_write
Message-ID: <EEFB79841DF60B4FB2B1C68614C88518030DEE8E@sb00106a.adb.intra.admin.ch>

Dear list

I have a feature projected in EPSG:2056 (http://spatialreference.org/ref/epsg/2056/). When st_write this to a shapefile I get a prj-File without the +towgs84 parameters and this results in an offset if the shapefile is projected on the fly in a QGIS project with OpenLayers (EPSG:3857). Placement is correct if I open in a project with EPSG:2056 or if I manually assign EPSG:2056 to the shapefile.
This looks a bit similar to this older thread https://www.mail-archive.com/r-sig-geo at r-project.org/msg06462.html but in this case the +towgs84 parameters are well defined.
The feature has
> st_crs(p)
Coordinate Reference System:
  EPSG: 2056
  proj4string: "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs"
st_write generates a prj reading PROJCS["Hotine_Oblique_Mercator_Azimuth_Center",GEOGCS["GCS_Bessel 1841",DATUM["D_unknown",SPHEROID["bessel",6377397.155,299.1528128]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],PARAMETER["latitude_of_center",46.95240555555556],PARAMETER["longitude_of_center",7.439583333333333],PARAMETER["azimuth",90],PARAMETER["scale_factor",1],PARAMETER["false_easting",2600000],PARAMETER["false_northing",1200000],UNIT["Meter",1]]
The result is that QGIS interprets this as a user defined CRS with +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +units=m +no_defs . The +towgs84 are assumed to be 0, I guess, and this results in the offset.

Does anybody know if there is a way to specify the information written by st_write to the .prj-File?

Many thanks for suggestions
Manuel



-----
Manuel Schneider (Ing.-Agr. ETH, Dr. sc. nat.)
Team leader, Mountain grassland ecology & management

Federal Department of Economic Affairs, Education and Research EAER
Agroscope

Reckenholzstrasse 191, CH-8046 Z?rich
Ph. +41 58 468 75 98
Fax  +41 58 468 72 01
manuel.schneider at agroscope.admin.ch<mailto:manuel.schneider at art.admin.ch>
https://www.agroscope.admin.ch/agroscope/en/home/topics/plant-production/forage-grassland-grazing-systems.html
http://scholar.google.com/citations?user=a0CE8xoAAAAJ&hl=de

www.agroscope.ch<http://www.agroscope.ch/>  I good food, healthy environment



	[[alternative HTML version deleted]]


From edzer.pebesma at uni-muenster.de  Tue Dec 12 23:03:20 2017
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 Dec 2017 23:03:20 +0100
Subject: [R-sig-Geo] +towgs84 in st_write
In-Reply-To: <EEFB79841DF60B4FB2B1C68614C88518030DEE8E@sb00106a.adb.intra.admin.ch>
References: <EEFB79841DF60B4FB2B1C68614C88518030DEE8E@sb00106a.adb.intra.admin.ch>
Message-ID: <58425dcd-6dc9-4434-fcc9-94f9980f0f7a@uni-muenster.de>



On 12/12/2017 03:16 PM, manuel.schneider at agroscope.admin.ch wrote:
> Dear list
> 
> I have a feature projected in EPSG:2056 (http://spatialreference.org/ref/epsg/2056/). When st_write this to a shapefile I get a prj-File without the +towgs84 parameters and this results in an offset if the shapefile is projected on the fly in a QGIS project with OpenLayers (EPSG:3857). Placement is correct if I open in a project with EPSG:2056 or if I manually assign EPSG:2056 to the shapefile.
> This looks a bit similar to this older thread https://www.mail-archive.com/r-sig-geo at r-project.org/msg06462.html but in this case the +towgs84 parameters are well defined.
> The feature has
>> st_crs(p)
> Coordinate Reference System:
>   EPSG: 2056
>   proj4string: "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs"
> st_write generates a prj reading PROJCS["Hotine_Oblique_Mercator_Azimuth_Center",GEOGCS["GCS_Bessel 1841",DATUM["D_unknown",SPHEROID["bessel",6377397.155,299.1528128]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],PARAMETER["latitude_of_center",46.95240555555556],PARAMETER["longitude_of_center",7.439583333333333],PARAMETER["azimuth",90],PARAMETER["scale_factor",1],PARAMETER["false_easting",2600000],PARAMETER["false_northing",1200000],UNIT["Meter",1]]
> The result is that QGIS interprets this as a user defined CRS with +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +units=m +no_defs . The +towgs84 are assumed to be 0, I guess, and this results in the offset.
> 
> Does anybody know if there is a way to specify the information written by st_write to the .prj-File?

I can reproduce that, and see the same when writing to ESRI Shapefile
using rgdal::writeOGR. The funny thing is that from gdal one also gets
the following back, when asking for proj.4 -> wkt conversion:

cat(st_as_text(st_crs(2056), pretty = TRUE))
PROJCS["unnamed",
    GEOGCS["Bessel 1841",
        DATUM["unknown",
            SPHEROID["bessel",6377397.155,299.1528128],
            TOWGS84[674.374,15.056,405.346,0,0,0,0]],
        PRIMEM["Greenwich",0],
        UNIT["degree",0.0174532925199433]],
    PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],
    PARAMETER["latitude_of_center",46.95240555555556],
    PARAMETER["longitude_of_center",7.439583333333333],
    PARAMETER["azimuth",90],
    PARAMETER["rectified_grid_angle",90],
    PARAMETER["scale_factor",1],
    PARAMETER["false_easting",2600000],
    PARAMETER["false_northing",1200000],
    UNIT["Meter",1]]

which has the towgs parameters.

If I write this file to GeoPackage, i.e. by

st_write(nc, "xx.gpkg")

I do see the towgs parameters when looking at it with ogrinfo (or
reading it back with st_read).

One more reason to ditch shapefiles?

> 
> Many thanks for suggestions
> Manuel
> 
> 
> 
> -----
> Manuel Schneider (Ing.-Agr. ETH, Dr. sc. nat.)
> Team leader, Mountain grassland ecology & management
> 
> Federal Department of Economic Affairs, Education and Research EAER
> Agroscope
> 
> Reckenholzstrasse 191, CH-8046 Z?rich
> Ph. +41 58 468 75 98
> Fax  +41 58 468 72 01
> manuel.schneider at agroscope.admin.ch<mailto:manuel.schneider at art.admin.ch>
> https://www.agroscope.admin.ch/agroscope/en/home/topics/plant-production/forage-grassland-grazing-systems.html
> http://scholar.google.com/citations?user=a0CE8xoAAAAJ&hl=de
> 
> www.agroscope.ch<http://www.agroscope.ch/>  I good food, healthy environment
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 

-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From Roger.Bivand at nhh.no  Tue Dec 12 23:27:20 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 12 Dec 2017 23:27:20 +0100
Subject: [R-sig-Geo] +towgs84 in st_write
In-Reply-To: <58425dcd-6dc9-4434-fcc9-94f9980f0f7a@uni-muenster.de>
References: <EEFB79841DF60B4FB2B1C68614C88518030DEE8E@sb00106a.adb.intra.admin.ch>
 <58425dcd-6dc9-4434-fcc9-94f9980f0f7a@uni-muenster.de>
Message-ID: <alpine.LFD.2.21.1712122309300.19338@reclus.nhh.no>

On Tue, 12 Dec 2017, Edzer Pebesma wrote:

>
>
> On 12/12/2017 03:16 PM, manuel.schneider at agroscope.admin.ch wrote:
>> Dear list
>> 
>> I have a feature projected in EPSG:2056 (http://spatialreference.org/ref/epsg/2056/). When st_write this to a shapefile I get a prj-File without the +towgs84 parameters and this results in an offset if the shapefile is projected on the fly in a QGIS project with OpenLayers (EPSG:3857). Placement is correct if I open in a project with EPSG:2056 or if I manually assign EPSG:2056 to the shapefile.
>> This looks a bit similar to this older thread https://www.mail-archive.com/r-sig-geo at r-project.org/msg06462.html but in this case the +towgs84 parameters are well defined.
>> The feature has
>>> st_crs(p)
>> Coordinate Reference System:
>>   EPSG: 2056
>>   proj4string: "+proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs"
>> st_write generates a prj reading PROJCS["Hotine_Oblique_Mercator_Azimuth_Center",GEOGCS["GCS_Bessel 1841",DATUM["D_unknown",SPHEROID["bessel",6377397.155,299.1528128]],PRIMEM["Greenwich",0],UNIT["Degree",0.017453292519943295]],PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],PARAMETER["latitude_of_center",46.95240555555556],PARAMETER["longitude_of_center",7.439583333333333],PARAMETER["azimuth",90],PARAMETER["scale_factor",1],PARAMETER["false_easting",2600000],PARAMETER["false_northing",1200000],UNIT["Meter",1]]
>> The result is that QGIS interprets this as a user defined CRS with +proj=somerc +lat_0=46.95240555555556 +lon_0=7.439583333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +units=m +no_defs . The +towgs84 are assumed to be 0, I guess, and this results in the offset.
>> 
>> Does anybody know if there is a way to specify the information written by st_write to the .prj-File?
>
> I can reproduce that, and see the same when writing to ESRI Shapefile
> using rgdal::writeOGR. The funny thing is that from gdal one also gets
> the following back, when asking for proj.4 -> wkt conversion:

I think this is the writeOGR() morphToESRI argument (but commented out, 
maybe in the "ESRI Shapefile" driver?). Does sf use morphToESRI()? This 
changes the WKT SRS representation:

library(rgdal)
CRSargs(CRS("+init=epsg:2056"))
showWKT(CRSargs(CRS("+init=epsg:2056")), morphToESRI=TRUE)
showWKT(CRSargs(CRS("+init=epsg:2056")), morphToESRI=FALSE)

Roger

>
> cat(st_as_text(st_crs(2056), pretty = TRUE))
> PROJCS["unnamed",
>    GEOGCS["Bessel 1841",
>        DATUM["unknown",
>            SPHEROID["bessel",6377397.155,299.1528128],
>            TOWGS84[674.374,15.056,405.346,0,0,0,0]],
>        PRIMEM["Greenwich",0],
>        UNIT["degree",0.0174532925199433]],
>    PROJECTION["Hotine_Oblique_Mercator_Azimuth_Center"],
>    PARAMETER["latitude_of_center",46.95240555555556],
>    PARAMETER["longitude_of_center",7.439583333333333],
>    PARAMETER["azimuth",90],
>    PARAMETER["rectified_grid_angle",90],
>    PARAMETER["scale_factor",1],
>    PARAMETER["false_easting",2600000],
>    PARAMETER["false_northing",1200000],
>    UNIT["Meter",1]]
>
> which has the towgs parameters.
>
> If I write this file to GeoPackage, i.e. by
>
> st_write(nc, "xx.gpkg")
>
> I do see the towgs parameters when looking at it with ogrinfo (or
> reading it back with st_read).
>
> One more reason to ditch shapefiles?
>
>> 
>> Many thanks for suggestions
>> Manuel
>> 
>> 
>> 
>> -----
>> Manuel Schneider (Ing.-Agr. ETH, Dr. sc. nat.)
>> Team leader, Mountain grassland ecology & management
>> 
>> Federal Department of Economic Affairs, Education and Research EAER
>> Agroscope
>> 
>> Reckenholzstrasse 191, CH-8046 Z???rich
>> Ph. +41 58 468 75 98
>> Fax  +41 58 468 72 01
>> manuel.schneider at agroscope.admin.ch<mailto:manuel.schneider at art.admin.ch>
>> https://www.agroscope.admin.ch/agroscope/en/home/topics/plant-production/forage-grassland-grazing-systems.html
>> http://scholar.google.com/citations?user=a0CE8xoAAAAJ&hl=de
>> 
>> www.agroscope.ch<http://www.agroscope.ch/>  I good food, healthy environment
>> 
>> 
>>
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> 
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> 
>
> -- 
> Edzer Pebesma
> Institute for Geoinformatics
> Heisenbergstrasse 2, 48151 Muenster, Germany
> Phone: +49 251 8333081
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From edzer.pebesma at uni-muenster.de  Tue Dec 12 23:55:30 2017
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 12 Dec 2017 23:55:30 +0100
Subject: [R-sig-Geo] +towgs84 in st_write
In-Reply-To: <alpine.LFD.2.21.1712122309300.19338@reclus.nhh.no>
References: <EEFB79841DF60B4FB2B1C68614C88518030DEE8E@sb00106a.adb.intra.admin.ch>
 <58425dcd-6dc9-4434-fcc9-94f9980f0f7a@uni-muenster.de>
 <alpine.LFD.2.21.1712122309300.19338@reclus.nhh.no>
Message-ID: <268ee628-1899-e98a-8db7-a36c8fdd5c48@uni-muenster.de>



On 12/12/2017 11:27 PM, Roger Bivand wrote:
> Does sf use morphToESRI()?

No.
-- 
Edzer Pebesma
Institute for Geoinformatics
Heisenbergstrasse 2, 48151 Muenster, Germany
Phone: +49 251 8333081


From Roger.Bivand at nhh.no  Wed Dec 13 07:09:25 2017
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 13 Dec 2017 07:09:25 +0100
Subject: [R-sig-Geo] +towgs84 in st_write
In-Reply-To: <268ee628-1899-e98a-8db7-a36c8fdd5c48@uni-muenster.de>
References: <EEFB79841DF60B4FB2B1C68614C88518030DEE8E@sb00106a.adb.intra.admin.ch>
 <58425dcd-6dc9-4434-fcc9-94f9980f0f7a@uni-muenster.de>
 <alpine.LFD.2.21.1712122309300.19338@reclus.nhh.no>
 <268ee628-1899-e98a-8db7-a36c8fdd5c48@uni-muenster.de>
Message-ID: <alpine.LFD.2.21.1712130658320.25967@reclus.nhh.no>

On Tue, 12 Dec 2017, Edzer Pebesma wrote:

>
>
> On 12/12/2017 11:27 PM, Roger Bivand wrote:
>> Does sf use morphToESRI()?
>
> No.
>

I think the "ESRI Shapefile" driver changed - at one stage it was needed 
during writing some time ago, I think. Now the driver simply does it 
itself (line 763 in ogrsf_frmts/ogrshapedatasource.cpp:

* -------------------------------------------------------------------- */
/*      Create the .prj file, if required.                              */
/* -------------------------------------------------------------------- */
     if( poSRS != NULL )
     {
         CPLString osPrjFile =
             CPLFormFilename( NULL, pszFilenameWithoutExt, "prj");

         // The shape layer needs its own copy.
         poSRS = poSRS->Clone();
         poSRS->morphToESRI();

         char *pszWKT = NULL;
         VSILFILE *fp = NULL;
         if( poSRS->exportToWkt( &pszWKT ) == OGRERR_NONE
             && (fp = VSIFOpenL( osPrjFile, "wt" )) != NULL )
         {
             VSIFWriteL( pszWKT, strlen(pszWKT), 1, fp );
             VSIFCloseL( fp );
         }

         CPLFree( pszWKT );

         poSRS->morphFromESRI();
     }

So the driver is doing what it believes ArcGIS would like to read - the 
*.prj file isn't well specified. In https://issues.qgis.org/issues/2154 
Frank Warmerdam wrote eight years ago: "Yes, OGR does strip the towgs84 
parameter when writing the .prj file. TOWGS84 is not a legal construct in 
an ESRI Projection Engine string (for .prj files)."

Sounds like another reason to abandon shapefiles as not fit for purpose.

Roger

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en


From manuel.schneider at agroscope.admin.ch  Wed Dec 13 15:09:45 2017
From: manuel.schneider at agroscope.admin.ch (manuel.schneider at agroscope.admin.ch)
Date: Wed, 13 Dec 2017 14:09:45 +0000
Subject: [R-sig-Geo] +towgs84 in st_write
Message-ID: <EEFB79841DF60B4FB2B1C68614C88518030DF094@sb00106a.adb.intra.admin.ch>

Dear Roger and Edzer

Many thanks for looking into this. Projection is perfectly transferred from R to QGIS when using a geopackage, so this is definitively a shapefile issue. It's absolutely time to change ... and since st_write to GPKG works perfectly now (thanks to your efforts) there is no obstacle to do so.
All best wishes
Manuel

-----Urspr?ngliche Nachricht-----
Von: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] Im Auftrag von Roger Bivand
Gesendet: Mittwoch, 13. Dezember 2017 07:09
An: Edzer Pebesma <edzer.pebesma at uni-muenster.de>
Cc: r-sig-geo at r-project.org
Betreff: Re: [R-sig-Geo] +towgs84 in st_write

On Tue, 12 Dec 2017, Edzer Pebesma wrote:

>
>
> On 12/12/2017 11:27 PM, Roger Bivand wrote:
>> Does sf use morphToESRI()?
>
> No.
>

I think the "ESRI Shapefile" driver changed - at one stage it was needed 
during writing some time ago, I think. Now the driver simply does it 
itself (line 763 in ogrsf_frmts/ogrshapedatasource.cpp:

* -------------------------------------------------------------------- */
/*      Create the .prj file, if required.                              */
/* -------------------------------------------------------------------- */
     if( poSRS != NULL )
     {
         CPLString osPrjFile =
             CPLFormFilename( NULL, pszFilenameWithoutExt, "prj");

         // The shape layer needs its own copy.
         poSRS = poSRS->Clone();
         poSRS->morphToESRI();

         char *pszWKT = NULL;
         VSILFILE *fp = NULL;
         if( poSRS->exportToWkt( &pszWKT ) == OGRERR_NONE
             && (fp = VSIFOpenL( osPrjFile, "wt" )) != NULL )
         {
             VSIFWriteL( pszWKT, strlen(pszWKT), 1, fp );
             VSIFCloseL( fp );
         }

         CPLFree( pszWKT );

         poSRS->morphFromESRI();
     }

So the driver is doing what it believes ArcGIS would like to read - the 
*.prj file isn't well specified. In https://issues.qgis.org/issues/2154 
Frank Warmerdam wrote eight years ago: "Yes, OGR does strip the towgs84 
parameter when writing the .prj file. TOWGS84 is not a legal construct in 
an ESRI Projection Engine string (for .prj files)."

Sounds like another reason to abandon shapefiles as not fit for purpose.

Roger

-- 
Roger Bivand
Department of Economics, Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; e-mail: Roger.Bivand at nhh.no
Editor-in-Chief of The R Journal, https://journal.r-project.org/index.html
http://orcid.org/0000-0003-2392-6140
https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From karsten at terragis.net  Wed Dec 13 22:13:14 2017
From: karsten at terragis.net (karsten)
Date: Wed, 13 Dec 2017 22:13:14 +0100
Subject: [R-sig-Geo] comparing one raster to a stack and condition
Message-ID: <B594C2B0D9E94CD388967240715FD4FE@terragispc>

Hi All,
 
I am trying to compare one precipitation raster to a stack of precipitation
raster and would like to create a result raster with a count of how often
the raster value is below those of the stack.
So far I have the following code:
 
----------------------------------------------
 
library(zoo)
library(raster)
# create raster stack for Januaries
alltiffs = list.files(getwd(), pattern="*\\.tif$", full.names=TRUE) 

#filter the ones with 01 in it for january
januarygrids =  alltiffs[grepl("*.01.*", alltiffs)]
 
# Create raster stack of grids
r <- stack(januarygrids, quick=TRUE)
 
# set current january layer to compare with
currentmonth <- "es_af.2017.01.tif"
currentmonthraster <- raster(currentmonth)
 
# function to count how oftetn current ratser is below values in stack,
input r and currentmonthraster 
belowCurrentRaster <- function(x, y) {
  sum(x > y)
}
 
-------------------------------------------------------
 
Now I thought I could use zApply or overlay to get the count from the
belowCurrentRaster function and write those counts into a result raster.
But I could not figure out how to make this work.
Any ideas appreciated.
 
Cheers 
Karsten Vennemann
Terra GIS LTD


	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Thu Dec 14 09:28:39 2017
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 14 Dec 2017 08:28:39 +0000
Subject: [R-sig-Geo] comparing one raster to a stack and condition
In-Reply-To: <B594C2B0D9E94CD388967240715FD4FE@terragispc>
References: <B594C2B0D9E94CD388967240715FD4FE@terragispc>
Message-ID: <CANVKczO5=AGT5X4gbSkUhA9COdR9=65zffsK-yvHM+4D_hXaMQ@mail.gmail.com>

Here's a way - first let's make some sample data in a stack:

 maker = function(d){raster(matrix(runif(16),4,4))}
 rains = stack(lapply(1:10, maker))

so `rains` is a stack of 10 4x4 rasters with random numbers in. Now the
raster we want to test:

 r1 = maker()

Okay, all set up. We have a raster and a stack, then:

 r1 < rains

is a stack of 1s and 0s where r1 is less than the cell in each layer of
rains, and then we can do:

 sum(r1 < rains)

to total those up.

plot(sum(r1<rains))

should map how many times r1 is less than the values in rains.

Barry



On Wed, Dec 13, 2017 at 9:13 PM, karsten <karsten at terragis.net> wrote:

> Hi All,
>
> I am trying to compare one precipitation raster to a stack of precipitation
> raster and would like to create a result raster with a count of how often
> the raster value is below those of the stack.
> So far I have the following code:
>
> ----------------------------------------------
>
> library(zoo)
> library(raster)
> # create raster stack for Januaries
> alltiffs = list.files(getwd(), pattern="*\\.tif$", full.names=TRUE)
>
> #filter the ones with 01 in it for january
> januarygrids =  alltiffs[grepl("*.01.*", alltiffs)]
>
> # Create raster stack of grids
> r <- stack(januarygrids, quick=TRUE)
>
> # set current january layer to compare with
> currentmonth <- "es_af.2017.01.tif"
> currentmonthraster <- raster(currentmonth)
>
> # function to count how oftetn current ratser is below values in stack,
> input r and currentmonthraster
> belowCurrentRaster <- function(x, y) {
>   sum(x > y)
> }
>
> -------------------------------------------------------
>
> Now I thought I could use zApply or overlay to get the count from the
> belowCurrentRaster function and write those counts into a result raster.
> But I could not figure out how to make this work.
> Any ideas appreciated.
>
> Cheers
> Karsten Vennemann
> Terra GIS LTD
>
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

	[[alternative HTML version deleted]]


From cicoz at anadolu.edu.tr  Thu Dec 14 13:01:25 2017
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Thu, 14 Dec 2017 12:01:25 +0000
Subject: [R-sig-Geo] Intensity Estimation Methods
Message-ID: <C2AF35551EE58A4487CC3151707449ADCC2E7EA6@mb06.porsuk.anadolu.edu.tr>

Hello list,,

I have a spatial point pattern . I am trying to estimate its intensity both with a fixed bandwidth and  with an adaptive bandwidth.
How could I compare the goodness of these two fits? I mean are there any things like mse, aic or any other criteria???
I want to compare the difference between the estimated intensity and the original pattern's intensity.

Thanks
Cenk





________________________________

Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z, y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini yans?tmayabilir.

This electronic mail and any files transmitted with it are intended for the private use of the people named above. If you are not the intended recipient and received this message in error, forwarding, copying or use of any of the information is strictly prohibited. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal. In this case, please immediately notify the sender and delete it from your system. Anadolu University does not guarantee the accuracy or completeness of any information included in this message. Therefore, by any means Anadolu University is not responsible for the content of the message, and the transmission, reception, storage, and use of the information. The opinions expressed in this message only belong to the sender of it and may not reflect the opinions of Anadolu University.


From r.turner at auckland.ac.nz  Thu Dec 14 21:13:54 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 15 Dec 2017 09:13:54 +1300
Subject: [R-sig-Geo] Intensity Estimation Methods
In-Reply-To: <C2AF35551EE58A4487CC3151707449ADCC2E7EA6@mb06.porsuk.anadolu.edu.tr>
References: <C2AF35551EE58A4487CC3151707449ADCC2E7EA6@mb06.porsuk.anadolu.edu.tr>
Message-ID: <0fddf500-5da6-a4e6-673f-a433fec81981@auckland.ac.nz>

On 15/12/17 01:01, Cenk ???Z via R-sig-Geo wrote:
> Hello list,,
> 
> I have a spatial point pattern . I am trying to estimate its
> intensity both with a fixed bandwidth and  with an adaptive
> bandwidth. How could I compare the goodness of these two fits? I mean
> are there any things like mse, aic or any other criteria??? I want to
> compare the difference between the estimated intensity and the
> original pattern's intensity.

I think that the following fortune (fortunes::fortune(340)) might be 
relevant:

> Bandwidth selection is an unresolved (and possibly unsolvable) problem in
> smoothing, so you're perfectly justified in trying/choosing an arbitrary value
> if it produces good pictures!
>    -- Adrian Baddeley (answering a user's question about the choice of
>       smoothing parameter when using the density.ppp() function from the
>       spatstat package)
>       private communication (March 2013)

I am cc-ing to the man himself to see if he has further comment.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From karsten at terragis.net  Thu Dec 14 15:20:46 2017
From: karsten at terragis.net (karsten)
Date: Thu, 14 Dec 2017 15:20:46 +0100
Subject: [R-sig-Geo] comparing one raster to a stack and condition
In-Reply-To: <CANVKczO5=AGT5X4gbSkUhA9COdR9=65zffsK-yvHM+4D_hXaMQ@mail.gmail.com>
References: <B594C2B0D9E94CD388967240715FD4FE@terragispc>
 <CANVKczO5=AGT5X4gbSkUhA9COdR9=65zffsK-yvHM+4D_hXaMQ@mail.gmail.com>
Message-ID: <4E1B3AC7F668486187C75D3AC47F6DC9@terragispc>

Thanks Barry,
 
this is ingenious ! It works really well. For the record below is my code
using this and writing the result to disk.
Karsten
 
 
library(raster)
# Use pattern arg to return a wildcard to get a list of all tifs in dir
alltiffs = list.files(getwd(), pattern="*\\.tif$", full.names=TRUE)
januarygrids =  alltiffs[grepl("*01.tif*", alltiffs)]

# Create raster stack of january rain grids
r <- stack(januarygrids, quick=TRUE)
 
# set current january layer to compare with
currentmonth <- "es_af.2017.01.tif"
currentmonthraster <- raster(currentmonth)
 
# create count for each cell where january rain is below the rain value in
the raster stack layers
resultbelow01 <- sum(r<currentmonthraster)

# write resulttif
writeRaster(resultbelow01, filename='below01.tif', overwrite=TRUE)

  _____  

From: b.rowlingson at gmail.com [mailto:b.rowlingson at gmail.com] On Behalf Of
Barry Rowlingson
Sent: Donnerstag, 14. Dezember 2017 09:29
To: karsten
Cc: r-sig-geo
Subject: Re: [R-sig-Geo] comparing one raster to a stack and condition


Here's a way - first let's make some sample data in a stack:

 maker = function(d){raster(matrix(runif(16),4,4))}
 rains = stack(lapply(1:10, maker))


so `rains` is a stack of 10 4x4 rasters with random numbers in. Now the
raster we want to test:


 r1 = maker()


Okay, all set up. We have a raster and a stack, then:

 r1 < rains

is a stack of 1s and 0s where r1 is less than the cell in each layer of
rains, and then we can do:

 sum(r1 < rains)

to total those up.

plot(sum(r1<rains))


should map how many times r1 is less than the values in rains.

Barry



On Wed, Dec 13, 2017 at 9:13 PM, karsten <karsten at terragis.net> wrote:


Hi All,

I am trying to compare one precipitation raster to a stack of precipitation
raster and would like to create a result raster with a count of how often
the raster value is below those of the stack.
So far I have the following code:

----------------------------------------------

library(zoo)
library(raster)
# create raster stack for Januaries
alltiffs = list.files(getwd(), pattern="*\\.tif$", full.names=TRUE)

#filter the ones with 01 in it for january
januarygrids =  alltiffs[grepl("*.01.*", alltiffs)]

# Create raster stack of grids
r <- stack(januarygrids, quick=TRUE)

# set current january layer to compare with
currentmonth <- "es_af.2017.01.tif"
currentmonthraster <- raster(currentmonth)

# function to count how oftetn current ratser is below values in stack,
input r and currentmonthraster
belowCurrentRaster <- function(x, y) {
  sum(x > y)
}

-------------------------------------------------------

Now I thought I could use zApply or overlay to get the count from the
belowCurrentRaster function and write those counts into a result raster.
But I could not figure out how to make this work.
Any ideas appreciated.

Cheers
Karsten Vennemann
Terra GIS LTD


        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/
<https://stat.ethz.ch/mailman/listinfo/r-sig-geo> listinfo/r-sig-geo




	[[alternative HTML version deleted]]


From cicoz at anadolu.edu.tr  Fri Dec 15 13:23:27 2017
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Fri, 15 Dec 2017 12:23:27 +0000
Subject: [R-sig-Geo] Intensity Estimation Methods
In-Reply-To: <0fddf500-5da6-a4e6-673f-a433fec81981@auckland.ac.nz>
References: <C2AF35551EE58A4487CC3151707449ADCC2E7EA6@mb06.porsuk.anadolu.edu.tr>
 <0fddf500-5da6-a4e6-673f-a433fec81981@auckland.ac.nz>
Message-ID: <C2AF35551EE58A4487CC3151707449ADCC2E7FA5@mb06.porsuk.anadolu.edu.tr>

Thanks a lot.
I did superimpose the original pattern to pixel images of intensities. With adaptive smothing intensity higher zones are too narrowed.
Also the differences of intensities are getting higher in the study region. The fixed bandwidth choosen with bw.ppl( ) in spatstat give me a better Picture. This is my opinion and also this is in my case . I use this bandwidth as a global bandwidth for adaptive smoothing.


-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
Sent: Thursday, December 14, 2017 11:14 PM
To: Cenk ???Z <cicoz at anadolu.edu.tr>
Cc: r-sig-geo at r-project.org; Adrian.Baddeley at curtin.edu.au; Ege Rubak <rubak at math.aau.dk>
Subject: Re: [R-sig-Geo] Intensity Estimation Methods

On 15/12/17 01:01, Cenk ???Z via R-sig-Geo wrote:
> Hello list,,
>
> I have a spatial point pattern . I am trying to estimate its intensity
> both with a fixed bandwidth and  with an adaptive bandwidth. How could
> I compare the goodness of these two fits? I mean are there any things
> like mse, aic or any other criteria??? I want to compare the
> difference between the estimated intensity and the original pattern's
> intensity.

I think that the following fortune (fortunes::fortune(340)) might be
relevant:

> Bandwidth selection is an unresolved (and possibly unsolvable) problem
> in smoothing, so you're perfectly justified in trying/choosing an
> arbitrary value if it produces good pictures!
>    -- Adrian Baddeley (answering a user's question about the choice of
>       smoothing parameter when using the density.ppp() function from the
>       spatstat package)
>       private communication (March 2013)

I am cc-ing to the man himself to see if he has further comment.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


________________________________

Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z, y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini yans?tmayabilir.

This electronic mail and any files transmitted with it are intended for the private use of the people named above. If you are not the intended recipient and received this message in error, forwarding, copying or use of any of the information is strictly prohibited. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal. In this case, please immediately notify the sender and delete it from your system. Anadolu University does not guarantee the accuracy or completeness of any information included in this message. Therefore, by any means Anadolu University is not responsible for the content of the message, and the transmission, reception, storage, and use of the information. The opinions expressed in this message only belong to the sender of it and may not reflect the opinions of Anadolu University.


From cryan at binghamton.edu  Fri Dec 15 20:37:31 2017
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Fri, 15 Dec 2017 14:37:31 -0500
Subject: [R-sig-Geo] how to limit an image or a funxy to an irregular
 polygonal window, instead of the whole enclosing rectangle?
Message-ID: <c7b13737-2944-cbdb-c856-dbfcf290be01@binghamton.edu>

Using R 3.3.3 and spatstat 1.50-0 on Windows 7.  MWE below.

I have a SpatialPolygonsDataFrame of census tract poverty levels in 3
contiguous counties in the US, called sremsPoverty. I want to use this
as a predictor in a ppm model. The window for the point pattern is the
three counties--so an irregular polygon--called sremsWindow.

I understand ppm predictors need to be an image, a tesselation, a funxy,
a window, or a single number. So I proceed as follows:

### Poverty
p <- slot(sremsPoverty, "polygons")
v <- lapply(p, function(z) { SpatialPolygons(list(z)) })
sat <- tess(tiles = lapply(v, as.owin) )
pov.f <- as.function.tess(sat, values = sremsPoverty at data$propPoverty)

Thus pov.f is a spatial function (funxy) that I can use in a call to ppm():

m1 <- ppm(unique.cases.ppp ~ pov.f)

pov.f looks as expected when I plot it. But examing the structure of
as.im(pov.f) it appears it is a 128 x 128 pixel array, with the value of
the function at all pixels outside of the irregular polygonal window,
but inside the bounding rectangle, set to NA. I think this is the cause
of the NA values I am seeing among the residuals from m1, and those NA
residuals are causing me some trouble with model diagnostics such as
rhohat().

How do I constrain the funxy (or the image I can derive from it) to the
irregular polygonal window, so as to eliminate the NA values outside the
window but inside the bounding rectangle? Or can I constrain the
modeling activity of ppm() to the window?

Thanks.

--Chris Ryan
Broome County Health Department
Binghamton University
SUNY Upstate Medical University
Binghamt, NY, US

MWE:

x <- c(0, 2.6, 3, 1, 0)
y <- c(1,2,3,2,1)
test.window <- owin(poly=list(x=x,y=y))
plot(test.window)  ## looks as expected
## make spatial function
test.f <- function(x,y){x+y}
test.funxy <- funxy(test.f, W = test.window)  ## I *thought* this would
restrict the funxy to the window, but I don't think it does
plot(test.funxy)  ## looks as expected
## but the image from test.funxy is square, with NA values outside the
polygonal window, which is not square
test.im <- as.im(test.funxy)
str(test.im)

## my incorrect attempts to restrict the image to the window yields a
numeric vector
str(test.im[test.window])
## or an error message
window(test.im) <- test.window


From r.turner at auckland.ac.nz  Fri Dec 15 22:20:56 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Dec 2017 10:20:56 +1300
Subject: [R-sig-Geo] how to limit an image or a funxy to an irregular
 polygonal window, instead of the whole enclosing rectangle?
In-Reply-To: <c7b13737-2944-cbdb-c856-dbfcf290be01@binghamton.edu>
References: <c7b13737-2944-cbdb-c856-dbfcf290be01@binghamton.edu>
Message-ID: <51c95310-f970-53c7-59c7-d8e28b490980@auckland.ac.nz>


I am probably misunderstanding something (as usual) but I cannot fathom 
what you *expect* the values of the funxy object or the image to *be*, 
outside of the window.

See inline below.

On 16/12/17 08:37, Christopher W. Ryan wrote:
> Using R 3.3.3 and spatstat 1.50-0 on Windows 7.  MWE below.

Thank you for providing a clear and simple example.

> 
> I have a SpatialPolygonsDataFrame of census tract poverty levels in 3
> contiguous counties in the US, called sremsPoverty. I want to use this
> as a predictor in a ppm model. The window for the point pattern is the
> three counties--so an irregular polygon--called sremsWindow.
> 
> I understand ppm predictors need to be an image, a tesselation, a funxy,
> a window, or a single number. So I proceed as follows:
> 
> ### Poverty
> p <- slot(sremsPoverty, "polygons")
> v <- lapply(p, function(z) { SpatialPolygons(list(z)) })
> sat <- tess(tiles = lapply(v, as.owin) )
> pov.f <- as.function.tess(sat, values = sremsPoverty at data$propPoverty)
> 
> Thus pov.f is a spatial function (funxy) that I can use in a call to ppm():
> 
> m1 <- ppm(unique.cases.ppp ~ pov.f)
> 
> pov.f looks as expected when I plot it. But examing the structure of
> as.im(pov.f) it appears it is a 128 x 128 pixel array, with the value of
> the function at all pixels outside of the irregular polygonal window,
> but inside the bounding rectangle, set to NA.

What else could/should they be set to?

> I think this is the cause
> of the NA values I am seeing among the residuals from m1,

I don't think this is the case.  Perhaps more detail is needed; perhaps 
Adrian or Ege will be able to provide more insight.

> and those NA
> residuals are causing me some trouble with model diagnostics such as
> rhohat().

Again I, at least, would need more detail before being able to provide 
any constructive comment.

> How do I constrain the funxy (or the image I can derive from it) to the
> irregular polygonal window, so as to eliminate the NA values outside the
> window but inside the bounding rectangle? Or can I constrain the
> modeling activity of ppm() to the window?

The "modelling activity of ppm()" is *ALWAYS* constrained to the window 
of the pattern to which ppm() is applied.  This is fundamental to the 
the way that ppm() works, and to what a window *means*.

> 
> Thanks.
> 
> --Chris Ryan
> Broome County Health Department
> Binghamton University
> SUNY Upstate Medical University
> Binghamt, NY, US
> 
> MWE:
> 
> x <- c(0, 2.6, 3, 1, 0)
> y <- c(1,2,3,2,1)
> test.window <- owin(poly=list(x=x,y=y))
> plot(test.window)  ## looks as expected
> ## make spatial function
> test.f <- function(x,y){x+y}
> test.funxy <- funxy(test.f, W = test.window)  ## I *thought* this would
> restrict the funxy to the window, but I don't think it does
> plot(test.funxy)  ## looks as expected
> ## but the image from test.funxy is square, with NA values outside the
> polygonal window, which is not square
> test.im <- as.im(test.funxy)
> str(test.im)

Again, what could the values of the image, outside of test.window, 
possibly *be*, other than NA?

> ## my incorrect attempts to restrict the image to the window yields a
> numeric vector
> str(test.im[test.window])

You need to do

      new.im <- test.im[test.window,drop=FALSE]

to get an image rather than a numeric vector.  However the "new.im" that 
you obtain will be identical to test.im:

     > all.equal(new.im,test.im)
     [1] TRUE

> ## or an error message
> window(test.im) <- test.window

You need a capital "W" on Window(test.im) (to avoid an error message). 
But again this won't change anything.

Finally:

set.seed(42)
X <- runifpoint(20,win=test.window)
xxx <- ppm(X ~ test.im)
plot(residuals(xxx))
# No sign of any missing values.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From cryan at binghamton.edu  Fri Dec 15 23:43:24 2017
From: cryan at binghamton.edu (Christopher W. Ryan)
Date: Fri, 15 Dec 2017 17:43:24 -0500
Subject: [R-sig-Geo] how to limit an image or a funxy to an irregular
 polygonal window, instead of the whole enclosing rectangle?
In-Reply-To: <51c95310-f970-53c7-59c7-d8e28b490980@auckland.ac.nz>
References: <c7b13737-2944-cbdb-c856-dbfcf290be01@binghamton.edu>
 <51c95310-f970-53c7-59c7-d8e28b490980@auckland.ac.nz>
Message-ID: <0dc26394-af24-69ae-2d56-237ba3a414fc@binghamton.edu>

Thanks Rolf. I'm going to have to reflect more on my code and my data,
to understand better what is going on.

Obviously this won't help you much, without having access to all my data
and preceeding code, but the error message that is tripping me up is:

> rhohat(m12, pov.f)
Error:  the fitted intensity contains NA values

And yet,

table(is.na(fitted(m12)))
FALSE
  876

The predicted intensity, however, contains many NA values:

table(is.na(predict(m12)$v))
FALSE  TRUE
10379  6005

I try to force predictions only within my window by specifying locations
(which I think requires a binary mask window) but get the same result:

> table(is.na(predict(m12, locations = as.mask(sremsWindow))$v))
FALSE  TRUE
10379  6005

Does rhohat use fitted values (at quadrature points) or predicted values
(on a 128 x 128 pixel grid within the window)? Top of p. 415 in your
book Spatial Point Patterns: Methodology and Applications wtih R seems
to indicate the latter, while the error message from my rhohat command
above speaks of fitted values.  And how is a rectangular 128 x 128 grid
fit in an irregularly-shaped polygonal window?  Maybe that's how NA
predicted values arise--pixels outside an intra-window rectangular grid
but still inside the window?


And I can see now that no residuals from the model are missing:

> table(is.na(residuals(m12)$val))
FALSE
  876

All the NA's in my predicted values *around* my window, but inside the
bounding rectangle, led me down the garden path.

The origin of most of my predictors, such as pov.f, are shapefiles from
the US Census Bureau, with a discrete value of poverty level for each
census tract. So a tesselation of my window, really.  Through much
wrangling (possibly poorly-done) I was able to turn each predictor into
a funxy--therefore they are essentially step functions, constant across
a census tract and with abrupt changes at census tract boundaries.  I
notice that rhohat calls for a continuous covariate. Could that be an
issue?  Although, I have one predictor that is a continuous distfun, and
I get the same error message from rhohat with that.


Thanks.

--Chris Ryan

Rolf Turner wrote:
> set.seed(42)
> X <- runifpoint(20,win=test.window)
> xxx <- ppm(X ~ test.im)
> plot(residuals(xxx))
> # No sign of any missing values.


From r.turner at auckland.ac.nz  Sat Dec 16 06:13:53 2017
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Dec 2017 18:13:53 +1300
Subject: [R-sig-Geo] how to limit an image or a funxy to an irregular
 polygonal window, instead of the whole enclosing rectangle?
In-Reply-To: <0dc26394-af24-69ae-2d56-237ba3a414fc@binghamton.edu>
References: <c7b13737-2944-cbdb-c856-dbfcf290be01@binghamton.edu>
 <51c95310-f970-53c7-59c7-d8e28b490980@auckland.ac.nz>
 <0dc26394-af24-69ae-2d56-237ba3a414fc@binghamton.edu>
Message-ID: <892c7c7e-4c04-c655-45cb-5f2ddff268ea@auckland.ac.nz>

On 16/12/17 11:43, Christopher W. Ryan wrote:
> Thanks Rolf. I'm going to have to reflect more on my code and my data,
> to understand better what is going on.
> 
> Obviously this won't help you much, without having access to all my data
> and preceeding code,

Too true!

> but the error message that is tripping me up is:
> 
>> rhohat(m12, pov.f)
> Error:  the fitted intensity contains NA values

No idea what is causing that to happen, and it's impossible to work it 
out without having your data.  (Point pattern and the predictor image.)

I can't find that error message anywhere in the spatstat code.  Is it 
possible that you have some other rhohat() function (maybe from some 
other package) hanging around and getting in the way?  Using traceback() 
*might* provide some insight.

> 
> And yet,
> 
> table(is.na(fitted(m12)))
> FALSE
>    876
> 
> The predicted intensity, however, contains many NA values:
> 
> table(is.na(predict(m12)$v))
> FALSE  TRUE
> 10379  6005

This is a *COMPLETE RED HERRING* !!!

Of course you will get NAs from this.  The predicted intensity is an 
*image* on the window of the point pattern to which the model is fitted.
All pixels within the bounding box of that window, but outside of the 
actual window, have pixel value NA.
> 
> I try to force predictions only within my window by specifying locations
> (which I think requires a binary mask window) but get the same result:
> 
>> table(is.na(predict(m12, locations = as.mask(sremsWindow))$v))
> FALSE  TRUE
> 10379  6005

No, no, no!!!  The predictions are always "within your window".  That's 
*why* they are NA at pixels outside that window.

> 
> Does rhohat use fitted values (at quadrature points) or predicted values
> (on a 128 x 128 pixel grid within the window)? Top of p. 415 in your
> book Spatial Point Patterns: Methodology and Applications wtih R seems
> to indicate the latter, while the error message from my rhohat command
> above speaks of fitted values.

I don't understand where that error message is coming from, so I don't
get what it is on about, but essentially rhohat() looks at values of the 
predictive covariate and of the fitted intensity at all pixel centres 
within the window.  The 128 x 128 grid is the default here, but can be 
changed (in the call to rhohat()).

> And how is a rectangular 128 x 128 grid
> fit in an irregularly-shaped polygonal window?  Maybe that's how NA
> predicted values arise--pixels outside an intra-window rectangular grid
> but still inside the window?

The rectangular grid is over the bounding box of the window.  (Which is
rectangular!!!) Only pixels whose centres are within the window have 
non-NA values.

> 
> 
> And I can see now that no residuals from the model are missing:
> 
>> table(is.na(residuals(m12)$val))
> FALSE
>    876
> 
> All the NA's in my predicted values *around* my window, but inside the
> bounding rectangle, led me down the garden path.

Indeed.

> 
> The origin of most of my predictors, such as pov.f, are shapefiles from
> the US Census Bureau, with a discrete value of poverty level for each
> census tract. So a tesselation of my window, really.  Through much
> wrangling (possibly poorly-done) I was able to turn each predictor into
> a funxy--therefore they are essentially step functions, constant across
> a census tract and with abrupt changes at census tract boundaries.  I
> notice that rhohat calls for a continuous covariate. Could that be an
> issue? 

I don't think so.  The rhohat() function works by smoothing, and 
smoothing a step function doesn't really make sense.  But I think that
rhohat() should still give you an answer, even though it's a crappy answer.

> Although, I have one predictor that is a continuous distfun, and
> I get the same error message from rhohat with that.

Don't think that I can come up with any useful suggestions as to how to 
proceed from here.  Sorry.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From adrian.baddeley at curtin.edu.au  Sat Dec 16 09:58:09 2017
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Sat, 16 Dec 2017 08:58:09 +0000
Subject: [R-sig-Geo] Intensity Estimation Methods
In-Reply-To: <C2AF35551EE58A4487CC3151707449ADCC2E7FA5@mb06.porsuk.anadolu.edu.tr>
References: <C2AF35551EE58A4487CC3151707449ADCC2E7EA6@mb06.porsuk.anadolu.edu.tr>
 <0fddf500-5da6-a4e6-673f-a433fec81981@auckland.ac.nz>,
 <C2AF35551EE58A4487CC3151707449ADCC2E7FA5@mb06.porsuk.anadolu.edu.tr>
Message-ID: <ME1PR01MB07710170EB3BE577F26B186AA4080@ME1PR01MB0771.ausprd01.prod.outlook.com>


Cenk ???Z <cicoz at anadolu.edu.tr> writes:


 I have a spatial point pattern . I am trying to estimate its intensity
> both with a fixed bandwidth and  with an adaptive bandwidth. How could
> I compare the goodness of these two fits? I mean are there any things
> like mse, aic or any other criteria??? I want to compare the
> difference between the estimated intensity and the original pattern's
> intensity.


If you know the 'true' intensity then you could compute, for example, the integrated squared error.

In the spatstat package, if 'lamtrue' is the true intensity and 'lamest' the estimated intensity, given as pixel images (class 'im') then you can just do

     ISE <- integral((lamtrue-lamest)^2)


Alternatives include the Kulback-Leibler divergence

     KL <- integral(log(lamest/lamtrue) * lamtrue)

and the total variation distance

     TV <- integral(abs(lamtrue-lamest))/2


However if you have two competing estimates of the intensity of an observed point pattern, you're probably best to use the point process likelihood. Suppose lam1 and lam2 are pixel images giving  two competing estimates of the intensity of the same point pattern X. Then you could do


      lik1 <- sum(log(lam1[X])) - integral(lam1)

      lik2 <- sum(log(lam2[X])) - integral(lam2)


and compare the likelihoods.


Adrian Baddeley


________________________________
From: Cenk ???Z <cicoz at anadolu.edu.tr>
Sent: Friday, 15 December 2017 8:23 PM
To: Rolf Turner
Cc: r-sig-geo at r-project.org; Adrian Baddeley; Ege Rubak
Subject: RE: [R-sig-Geo] Intensity Estimation Methods

Thanks a lot.
I did superimpose the original pattern to pixel images of intensities. With adaptive smothing intensity higher zones are too narrowed.
Also the differences of intensities are getting higher in the study region. The fixed bandwidth choosen with bw.ppl( ) in spatstat give me a better Picture. This is my opinion and also this is in my case . I use this bandwidth as a global bandwidth for adaptive smoothing.


-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
Sent: Thursday, December 14, 2017 11:14 PM
To: Cenk ???Z <cicoz at anadolu.edu.tr>
Cc: r-sig-geo at r-project.org; Adrian.Baddeley at curtin.edu.au; Ege Rubak <rubak at math.aau.dk>
Subject: Re: [R-sig-Geo] Intensity Estimation Methods

On 15/12/17 01:01, Cenk ???Z via R-sig-Geo wrote:
> Hello list,,
>
> I have a spatial point pattern . I am trying to estimate its intensity
> both with a fixed bandwidth and  with an adaptive bandwidth. How could
> I compare the goodness of these two fits? I mean are there any things
> like mse, aic or any other criteria??? I want to compare the
> difference between the estimated intensity and the original pattern's
> intensity.

I think that the following fortune (fortunes::fortune(340)) might be
relevant:

> Bandwidth selection is an unresolved (and possibly unsolvable) problem
> in smoothing, so you're perfectly justified in trying/choosing an
> arbitrary value if it produces good pictures!
>    -- Adrian Baddeley (answering a user's question about the choice of
>       smoothing parameter when using the density.ppp() function from the
>       spatstat package)
>       private communication (March 2013)

I am cc-ing to the man himself to see if he has further comment.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


________________________________

Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z, y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini yans?tmayabilir.

This electronic mail and any files transmitted with it are intended for the private use of the people named above. If you are not the intended recipient and received this message in error, forwarding, copying or use of any of the information is strictly prohibited. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal. In this case, please immediately notify the sender and delete it from your system. Anadolu University does not guarantee the accuracy or completeness of any information included in this message. Therefore, by any means Anadolu University is not responsible for the content of the message, and the transmission, reception, storage, and use of the information. The opinions expressed in this message only belong to the sender of it and may not reflect the opinions of Anadolu University.

	[[alternative HTML version deleted]]


From adrian.baddeley at curtin.edu.au  Sat Dec 16 10:10:30 2017
From: adrian.baddeley at curtin.edu.au (Adrian Baddeley)
Date: Sat, 16 Dec 2017 09:10:30 +0000
Subject: [R-sig-Geo] how to limit an image or a funxy to an irregular
 polygonal window, instead of the whole enclosing rectangle?
In-Reply-To: <51c95310-f970-53c7-59c7-d8e28b490980@auckland.ac.nz>
References: <c7b13737-2944-cbdb-c856-dbfcf290be01@binghamton.edu>,
 <51c95310-f970-53c7-59c7-d8e28b490980@auckland.ac.nz>
Message-ID: <ME1PR01MB07713046164B14E9337BCEF0A4080@ME1PR01MB0771.ausprd01.prod.outlook.com>

Christopher W. Ryan writes:


> I have a SpatialPolygonsDataFrame of census tract poverty levels in 3
> contiguous counties in the US, called sremsPoverty. I want to use this
> as a predictor in a ppm model. The window for the point pattern is the
> three counties--so an irregular polygon--called sremsWindow.
>
> I understand ppm predictors need to be an image, a tesselation, a funxy,
> a window, or a single number. So I proceed as follows:
>
> ### Poverty
> p <- slot(sremsPoverty, "polygons")
> v <- lapply(p, function(z) { SpatialPolygons(list(z)) })
> sat <- tess(tiles = lapply(v, as.owin) )
> pov.f <- as.function.tess(sat, values = sremsPoverty at data$propPoverty)
>
> Thus pov.f is a spatial function (funxy) that I can use in a call to ppm():
>
> m1 <- ppm(unique.cases.ppp ~ pov.f)
>
> pov.f looks as expected when I plot it. But examing the structure of
> as.im(pov.f) it appears it is a 128 x 128 pixel array, with the value of
> the function at all pixels outside of the irregular polygonal window,
> but inside the bounding rectangle, set to NA.

> I think this is the cause of the NA values I am seeing among the residuals from m1,
> and those NA residuals are causing me some trouble with model diagnostics such as
> rhohat().
> How do I constrain the funxy (or the image I can derive from it) to the
> irregular polygonal window, so as to eliminate the NA values outside the
> window but inside the bounding rectangle? Or can I constrain the
> modeling activity of ppm() to the window?

When you convert the tessellation 'sat' into the function 'pov.f' using as.function.tess, the domain of the function is the union of all the tiles in the tessellation 'sat'. After all, this function pov.f(x) works by figuring out which tile of the tessellation the given location x falls inside, and returns the poverty value associated with that tile. So this function is restricted to the union of the tiles given.

When you fit a model to the point pattern 'unique.cases.ppp', the fitting procedure has to place sample points all over the window associated with the point pattern, and evaluate the covariate 'pov.f' at all these sample points. So this window should not be larger than the window where the poverty values are defined - if it is, then you'll get NA's.

I suggest you do something like
        X <- unique.cases.ppp
        W <- intersect.owin(Window(X), Window(pov.f))
        Y <- X[W]
        m1 <- ppm(Y ~ pov.f)

Adrian Baddeley





	[[alternative HTML version deleted]]


From cicoz at anadolu.edu.tr  Sun Dec 17 11:44:15 2017
From: cicoz at anadolu.edu.tr (=?iso-8859-9?B?Q2VuayDdx9Za?=)
Date: Sun, 17 Dec 2017 10:44:15 +0000
Subject: [R-sig-Geo] Intensity Estimation Methods
In-Reply-To: <ME1PR01MB07710170EB3BE577F26B186AA4080@ME1PR01MB0771.ausprd01.prod.outlook.com>
References: <C2AF35551EE58A4487CC3151707449ADCC2E7EA6@mb06.porsuk.anadolu.edu.tr>
 <0fddf500-5da6-a4e6-673f-a433fec81981@auckland.ac.nz>,
 <C2AF35551EE58A4487CC3151707449ADCC2E7FA5@mb06.porsuk.anadolu.edu.tr>
 <ME1PR01MB07710170EB3BE577F26B186AA4080@ME1PR01MB0771.ausprd01.prod.outlook.com>
Message-ID: <C2AF35551EE58A4487CC3151707449ADCC2E82AB@mb06.porsuk.anadolu.edu.tr>

Adrian and Rolf.
Adrian's second example will solve my problem I guess.
Because I do not know the original intensity of the pattern. I only have an observed point pattern.

Thanks a lot.
Cenk


From: Adrian Baddeley [mailto:adrian.baddeley at curtin.edu.au]
Sent: Saturday, December 16, 2017 11:58 AM
To: Cenk ???Z <cicoz at anadolu.edu.tr>; Rolf Turner <r.turner at auckland.ac.nz>
Cc: r-sig-geo at r-project.org; Ege Rubak <rubak at math.aau.dk>
Subject: Re: [R-sig-Geo] Intensity Estimation Methods




Cenk ???Z <cicoz at anadolu.edu.tr<mailto:cicoz at anadolu.edu.tr>> writes:



 I have a spatial point pattern . I am trying to estimate its intensity
> both with a fixed bandwidth and  with an adaptive bandwidth. How could
> I compare the goodness of these two fits? I mean are there any things
> like mse, aic or any other criteria??? I want to compare the
> difference between the estimated intensity and the original pattern's
> intensity.



If you know the 'true' intensity then you could compute, for example, the integrated squared error.

In the spatstat package, if 'lamtrue' is the true intensity and 'lamest' the estimated intensity, given as pixel images (class 'im') then you can just do

     ISE <- integral((lamtrue-lamest)^2)



Alternatives include the Kulback-Leibler divergence

     KL <- integral(log(lamest/lamtrue) * lamtrue)

and the total variation distance

     TV <- integral(abs(lamtrue-lamest))/2



However if you have two competing estimates of the intensity of an observed point pattern, you're probably best to use the point process likelihood. Suppose lam1 and lam2 are pixel images giving  two competing estimates of the intensity of the same point pattern X. Then you could do



      lik1 <- sum(log(lam1[X])) - integral(lam1)

      lik2 <- sum(log(lam2[X])) - integral(lam2)



and compare the likelihoods.



Adrian Baddeley



________________________________
From: Cenk ???Z <cicoz at anadolu.edu.tr<mailto:cicoz at anadolu.edu.tr>>
Sent: Friday, 15 December 2017 8:23 PM
To: Rolf Turner
Cc: r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>; Adrian Baddeley; Ege Rubak
Subject: RE: [R-sig-Geo] Intensity Estimation Methods

Thanks a lot.
I did superimpose the original pattern to pixel images of intensities. With adaptive smothing intensity higher zones are too narrowed.
Also the differences of intensities are getting higher in the study region. The fixed bandwidth choosen with bw.ppl( ) in spatstat give me a better Picture. This is my opinion and also this is in my case . I use this bandwidth as a global bandwidth for adaptive smoothing.


-----Original Message-----
From: Rolf Turner [mailto:r.turner at auckland.ac.nz]
Sent: Thursday, December 14, 2017 11:14 PM
To: Cenk ???Z <cicoz at anadolu.edu.tr<mailto:cicoz at anadolu.edu.tr>>
Cc: r-sig-geo at r-project.org<mailto:r-sig-geo at r-project.org>; Adrian.Baddeley at curtin.edu.au<mailto:Adrian.Baddeley at curtin.edu.au>; Ege Rubak <rubak at math.aau.dk<mailto:rubak at math.aau.dk>>
Subject: Re: [R-sig-Geo] Intensity Estimation Methods

On 15/12/17 01:01, Cenk ???Z via R-sig-Geo wrote:
> Hello list,,
>
> I have a spatial point pattern . I am trying to estimate its intensity
> both with a fixed bandwidth and  with an adaptive bandwidth. How could
> I compare the goodness of these two fits? I mean are there any things
> like mse, aic or any other criteria??? I want to compare the
> difference between the estimated intensity and the original pattern's
> intensity.

I think that the following fortune (fortunes::fortune(340)) might be
relevant:

> Bandwidth selection is an unresolved (and possibly unsolvable) problem
> in smoothing, so you're perfectly justified in trying/choosing an
> arbitrary value if it produces good pictures!
>    -- Adrian Baddeley (answering a user's question about the choice of
>       smoothing parameter when using the density.ppp() function from the
>       spatstat package)
>       private communication (March 2013)

I am cc-ing to the man himself to see if he has further comment.

cheers,

Rolf Turner

--
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


________________________________

Bu elektronik posta ve onunla iletilen b?t?n dosyalar sadece yukar?da isimleri belirtilen ki?iler aras?nda ?zel haberle?me amac?n? ta??makta olup g?nderici taraf?ndan al?nmas? ama?lanan yetkili ger?ek ya da t?zel ki?inin kullan?m?na aittir. E?er bu elektronik posta size yanl??l?kla ula?m??sa, elektronik postan?n i?eri?ini a??klaman?z, kopyalaman?z, y?nlendirmeniz ve kullanman?z kesinlikle yasakt?r. Bu durumda, l?tfen mesaj? geri g?nderiniz ve sisteminizden siliniz. Anadolu ?niversitesi bu mesaj?n i?erdi?i bilgilerin do?rulu?u veya eksiksiz oldu?u konusunda herhangi bir garanti vermemektedir. Bu nedenle bu bilgilerin ne ?ekilde olursa olsun i?eri?inden, iletilmesinden, al?nmas?ndan ve saklanmas?ndan sorumlu de?ildir. Bu mesajdaki g?r??ler yaln?zca g?nderen ki?iye aittir ve Anadolu ?niversitesinin g?r??lerini yans?tmayabilir.

This electronic mail and any files transmitted with it are intended for the private use of the people named above. If you are not the intended recipient and received this message in error, forwarding, copying or use of any of the information is strictly prohibited. Any dissemination or use of this information by a person other than the intended recipient is unauthorized and may be illegal. In this case, please immediately notify the sender and delete it from your system. Anadolu University does not guarantee the accuracy or completeness of any information included in this message. Therefore, by any means Anadolu University is not responsible for the content of the message, and the transmission, reception, storage, and use of the information. The opinions expressed in this message only belong to the sender of it and may not reflect the opinions of Anadolu University.

	[[alternative HTML version deleted]]


From dave.gregovich at alaska.gov  Wed Dec 20 21:49:47 2017
From: dave.gregovich at alaska.gov (Gregovich, Dave P (DFG))
Date: Wed, 20 Dec 2017 20:49:47 +0000
Subject: [R-sig-Geo] Adding rasters to a 'plotRGB' plot
Message-ID: <DM5PR09MB2041C1A012BE6E152C37244AEB0C0@DM5PR09MB2041.namprd09.prod.outlook.com>

Hello,
I would like to add rasters to a plotRGB plot, but they don't seem to register correctly with the initial (=background) raster plotted, as illustrated with the following code.
Does anybody out there know of a way to ensure that additional overlain rasters register spatially with the initially plotted background raster? If not possible with plotRGB, what other function would you use for this task?
(it also appears that SPDF's and their ilk have the same issue when trying to add to a plotRGB plot)
Thanks kindly.

library(raster)
#create initial background raster
side.length <- 100
r1 <- raster(nrow = side.length, ncol = side.length, ext = extent(0,side.length, 0, side.length))
r2 <- r3 <- r1
r1[]<- 200; r2[]<- 210; r3[]<- 230
stack1 <- stack(r1, r2, r3)

#create extents of rasters to plot on top of background
ex.1 <- extent(side.length * 0.1, side.length * 0.9, side.length * 0.1, side.length * 0.9)
ex.2 <- extent(side.length * 0.05, side.length * 0.95, side.length * 0.05, side.length * 0.95)
ex.3 <- extent(side.length * 0.02, side.length * 0.98, side.length * 0.02, side.length * 0.98)

rast1 <- crop(t.stack, ex.1)[[1]]
rast2 <- crop(t.stack, ex.2)[[1]]
rast3 <- crop(t.stack, ex.3)[[1]]

#plot and inspect region covered by each raster...
x11(10, 10)
plotRGB(stack1)

#first raster looks centered as it should be...
plot(rast1, add = T, col = '#ffff334D', legend = F)
plot(ex.1, add = T)
#second raster does not look centered, and does not align with its plotted extent
plot(rast2, add = T, col = '#ff1a754D', legend = F)
plot(ex.2, add = T)
#each successive raster should be larger than the first, but they aren't
plot(rast3, add = T, col = '#1a75ff4D', legend = F)
plot(ex.3, add = T)

___________________________________________
Dave Gregovich
Research Analyst
Alaska Department of Fish and Game
Division of Wildlife Conservation
802 3rd Street
Douglas, AK 99824
907-465-4291
___________________________________________


	[[alternative HTML version deleted]]


From benjamin.leutner at uni-wuerzburg.de  Thu Dec 21 19:28:59 2017
From: benjamin.leutner at uni-wuerzburg.de (Benjamin Leutner)
Date: Thu, 21 Dec 2017 19:28:59 +0100
Subject: [R-sig-Geo] Adding rasters to a 'plotRGB' plot
In-Reply-To: <DM5PR09MB2041C1A012BE6E152C37244AEB0C0@DM5PR09MB2041.namprd09.prod.outlook.com>
References: <DM5PR09MB2041C1A012BE6E152C37244AEB0C0@DM5PR09MB2041.namprd09.prod.outlook.com>
Message-ID: <16ce8339-816c-9ece-f2a3-ef6fc9fc3049@uni-wuerzburg.de>

Hi,

I think plotRGB() uses image() in the background, which is different 
from the standard plot(). Maybe that's were things go wrong.

Since you're also asking for an alternative, let me shamelessly plug 
RStoolbox::ggRGB() ,? a ggplot2 equivalent to raster::plotRGB().
ggRGB() is for colour composite rasters and ggR() is for single layers.
The ggLayer argument turns them in layers which can be added to an 
existing ggplot.

For example:

ggRGB(raster) +???????????????????????????????????????? # base layer
 ?? ggR(raster, ggLayer = TRUE) +????????????? # layer on? top
 ?? ggRGB(raster, ggLayer = TRUE) +
 ?? ...more_ggplot_stuff...

Cheers,
Benjamin

On 12/20/2017 09:49 PM, Gregovich, Dave P (DFG) wrote:
> Hello,
> I would like to add rasters to a plotRGB plot, but they don't seem to register correctly with the initial (=background) raster plotted, as illustrated with the following code.
> Does anybody out there know of a way to ensure that additional overlain rasters register spatially with the initially plotted background raster? If not possible with plotRGB, what other function would you use for this task?
> (it also appears that SPDF's and their ilk have the same issue when trying to add to a plotRGB plot)
> Thanks kindly.
>
> library(raster)
> #create initial background raster
> side.length <- 100
> r1 <- raster(nrow = side.length, ncol = side.length, ext = extent(0,side.length, 0, side.length))
> r2 <- r3 <- r1
> r1[]<- 200; r2[]<- 210; r3[]<- 230
> stack1 <- stack(r1, r2, r3)
>
> #create extents of rasters to plot on top of background
> ex.1 <- extent(side.length * 0.1, side.length * 0.9, side.length * 0.1, side.length * 0.9)
> ex.2 <- extent(side.length * 0.05, side.length * 0.95, side.length * 0.05, side.length * 0.95)
> ex.3 <- extent(side.length * 0.02, side.length * 0.98, side.length * 0.02, side.length * 0.98)
>
> rast1 <- crop(t.stack, ex.1)[[1]]
> rast2 <- crop(t.stack, ex.2)[[1]]
> rast3 <- crop(t.stack, ex.3)[[1]]
>
> #plot and inspect region covered by each raster...
> x11(10, 10)
> plotRGB(stack1)
>
> #first raster looks centered as it should be...
> plot(rast1, add = T, col = '#ffff334D', legend = F)
> plot(ex.1, add = T)
> #second raster does not look centered, and does not align with its plotted extent
> plot(rast2, add = T, col = '#ff1a754D', legend = F)
> plot(ex.2, add = T)
> #each successive raster should be larger than the first, but they aren't
> plot(rast3, add = T, col = '#1a75ff4D', legend = F)
> plot(ex.3, add = T)
>
> ___________________________________________
> Dave Gregovich
> Research Analyst
> Alaska Department of Fish and Game
> Division of Wildlife Conservation
> 802 3rd Street
> Douglas, AK 99824
> 907-465-4291
> ___________________________________________
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Benjamin Leutner

Department of Remote Sensing
University of W?rzburg
Campus Hubland Nord 86
97074 W?rzburg, Germany

Tel: +49-(0)931-31 89594
Email: benjamin.leutner at uni-wuerzburg.de
Web: www.geographie.uni-wuerzburg.de/fernerkundung


From ruettenauer at sowi.uni-kl.de  Fri Dec 22 11:18:42 2017
From: ruettenauer at sowi.uni-kl.de (=?iso-8859-1?Q?Tobias_R=FCttenauer?=)
Date: Fri, 22 Dec 2017 11:18:42 +0100
Subject: [R-sig-Geo] SLX model for splm package in R
Message-ID: <000301d37b0e$3f637e80$be2a7b80$@sowi.uni-kl.de>

Dear all,

though this is an old issue by now (but still one of the first google
results on the topic), here is some code answering one of the questions:
should you demean the spatial lag or lag the demeaned variable.

As far as I understand the following results, it does not matter. Both ways
produce identical results, which both conform to the LSDV approach.

Please find the example code below:


library(spdep)
library(splm)
library(texreg)

### Demean function
dm<-function(x, id){
  res<-x-ave(x,id,FUN=function(x) mean(x, na.rm=T))
  res
}

data(Produc, package="plm")
data(usaww)

usa.lw<-mat2listw(usaww)

Produc.pd<-pdata.frame(Produc, index=c("state", "year"))

Produc.pd$Wpcap<-slag(Produc.pd$pcap, usa.lw)
Produc.pd$Wpc<-slag(Produc.pd$pc, usa.lw)
Produc.pd$Wunemp<-slag(Produc.pd$unemp, usa.lw)

#### LSDV ####

lsdv.mod<-lm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp
             +state,
             data=Produc.pd)
summary(lsdv.mod)

#### Demean after lag ####

dal.mod<-plm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp,
             data=Produc.pd, effect="individual", model="within")
summary(dal.mod)

# Manual demeaning
Produc.pd[,4:ncol(Produc.pd)]<-apply(Produc.pd[,4:ncol(Produc.pd)], 2,
function(x) dm(x, Produc.pd$state))

dal2.mod<-lm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp,
             data=Produc.pd)
summary(dal2.mod)

#### Lag after demean ####

# Replace slags by demeaned slags
Produc.pd$Wpcap<-slag(Produc.pd$pcap, usa.lw)
Produc.pd$Wpc<-slag(Produc.pd$pc, usa.lw)
Produc.pd$Wunemp<-slag(Produc.pd$unemp, usa.lw)

lad.mod<-lm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp,
             data=Produc.pd)
summary(lad.mod)


screenreg(l=list(lsdv.mod, dal.mod, dal2.mod, lad.mod),
          omit.coef = "state", digits=6)



#### Test if both ways produce identical vectors ####

Produc.pd<-pdata.frame(Produc, index=c("state", "year"))

x<-Produc.pd$gsp

# lag after demean
dx<-dm(x, Produc.pd$state)
wdx<-slag(dx, usa.lw)

# deaman after lag
wx<-slag(x, usa.lw)
dwx<-dm(wx, Produc.pd$state)

# Test for equality
all.equal(wdx, dwx)


Best,
Tobi


Tobias R?ttenauer
TU Kaiserslautern
Erwin-Schr?dinger-Stra?e 57
67663 Kaiserslautern

ruettenauer at sowi.uni-kl.de
Tel.: 0631 205 5785




> -----Urspr?ngliche Nachricht-----
> Von: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org] Im Auftrag von
> Roger Bivand
> Gesendet: 30 August 2016 08:44
> An: dfamaral at usp.br
> Cc: r-sig-geo at r-project.org
> Betreff: Re: [R-sig-Geo] SLX model for splm package in R
> 
> On Tue, 30 Aug 2016, dfamaral at usp.br wrote:
> 
> > Dear all,
> >
> > Impacts in SLX model are calculated directly by parameters estimation:
> >
> > http://onlinelibrary.wiley.com/doi/10.1111/jors.12188/abstract
> >
> > Beta1 gives direct impact and Beta 2 the indirect:
> >
> > y = beta1*X + beta2*WX + e
> >
> 
> Yes, but you need the total impact beta1+beta2, but more work to infer
from
> that sum, which is what you need to assess the impact of X.
> 
> > I understand W must multiply T times the X matrix (T is the lenght of
> > time series for a panel data). And variables are demeaned after WX is
> > calculated.
> 
> Kronecker product of sparse matrices. Please contribute a patch for
> create_WX if desirable.
> 
> Please motivate the demean-after-lag concusion. Will this not affect the
> direct link between X and WX?
> 
> Roger
> 
> >
> > Daniel.
> >
> > ----- Mensagem original -----
> >
> >
> > De: "Roger Bivand" <Roger.Bivand at nhh.no>
> > Para: "Burcu Ozuduru" <bozuduru at gmail.com>
> > Cc: dfamaral at usp.br, r-sig-geo at r-project.org
> > Enviadas: Segunda-feira, 29 de Agosto de 2016 4:13:26
> > Assunto: Re: [R-sig-Geo] SLX model for splm package in R
> >
> > This is far too ad-hoc a discussion. For Spatial panel SLX, please
> > read
> > carefully:
> >
> > http://dx.doi.org/10.1016/j.spasta.2014.02.002
> > DOI 10.1007/s10109-015-0217-3
> > DOI: 10.1111/jors.12188
> >
> > for a view of the state of play. One question - should you demean the
> > X variables before taking spatial lags? This does not apply to
> > cross-section models for which spdep::create_WX() was written, for
> > obvious reasons. A second question - how do you handle the calculation
> > of total impacts in this setting? In cross-section models, this is
> > reasonably easy, by linear combination. But in spatial panel SLX
> > models, is it easy? What does the literature suggest?
> >
> > On Mon, 29 Aug 2016, Burcu Ozuduru wrote:
> >
> >> Hi,
> >>
> >> This is a great question because I faced the same problem a while back.
> >> What I did is to obtain the spatial weight matrix as (have spdep
> >> installed).
> >>
> >> S47matrix<-W1%*%S47
> >>
> >> and then put it in my data frame and equation. Btw, above W1 is a
> >> spatial weights matrix I obtained from a neighbor list
> >> (W1=as.matrix(as_dgRMatrix_listw(ccListw))) and S47 is the dependent
> >> variable.
> >>
> >> m2<-
> data.frame(S41,S46,S47,S65,S68,S47matrix,MAD10000,NQPDA10000,TPBt
> >> A10000,DivA10000,Lnk10000)
> >> summary(m2<-zeroinfl(S47~MAD10000+NQPDA10000+S47matrix,
> >> dist="negbin"))
> >>
> >> I also wanted to ask whether I was on the right track. Professor
> >> Bivand, if this is a common problem could you direct us to a relevant
> >> page -if available and if at all possible- please? Your advice would
> >> be sincerely appreciated.
> >
> > This is an inappropriate question for this thread (SLX spatial panel
> > models). You must refer to the literature, and understand what you are
> > doing:
> >
> > zeroinfl(S47~MAD10000+NQPDA10000+S47matrix, dist="negbin")
> >
> > is completely wrong, as S47matrix is Wy, the spatial lag of the
> > dependent variable, and this spatial lag model of response S47 cannot
> > be estimated using pscl::zeroinfl (do say which package provides the
> > functions you mention). Your only recourse is to write your own
> > Bayesian model. It is even extremely likely that this model doesn't
> > make any substantive sense, unless you have a good understanding about
> > why S47 at i (for all i) should be simultaneously caused by the full
> > set of values of S47. A model in the error might make sense (a zero
> > inflated negbin model with an additive mrf random effect (maybe
> R2BayesX 10.18637/jss.v014.i11).
> >
> > An SLX zero inflated negbin model could maybe apply, in which case
> > pscl::zeroinfl might be applicable, but then you'd be including the
> > lags of MAD10000 and NQPDA10000, not the response, and inference on
> > total impacts of these variables could be challenging rather than
> > obvious (MCMC summaries of the summed samples of the coefficients
> > would work, but here no MCMC I think - R2BayesX might help).
> >
> > Most of these issues are far more complex than students or their
> > supervisors understand, do ask an experienced applied statistician
> > (I'm not an applied statistician, don't rely on my suggestions, you
> > yourself are responsible for your results).
> >
> > Hope this clarifies,
> >
> > Roger
> >
> >>
> >> Kind Regards-
> >>
> >> Thanks-
> >>
> >> Burcu
> >>
> >> ---
> >>
> >> Burcu H. Ozuduru,
> >> Gazi University, Faculty of Architecture, Department of City and
> >> Regional Planning Maltepe-Ankara Turkey
> >> t: +90-312-5823701
> >> e: bozuduru at gazi.edu.tr
> >> http://websitem.gazi.edu.tr/bozuduru
> >>
> >>
> >> On Mon, Aug 29, 2016 at 12:42 AM, Roger Bivand
> <Roger.Bivand at nhh.no> wrote:
> >>
> >>> On Sun, 28 Aug 2016, dfamaral at usp.br wrote:
> >>>
> >>> Dear colleagues,
> >>>>
> >>>> Does anyone know how to implement Spatial Lag of X (SLX) model for
> >>>> panel data using splm package? I tried the following to create a WX
> >>>> matrix and then apply Fixed and Random Effects:
> >>>>
> >>>> tb <- read.csv2("panel.csv", header = TRUE, sep = ";", dec = ".")
> >>>> time <- length(unique(tb$year)) X <- as.matrix(tb[ ,3:20])
> >>>>
> >>>
> >>> class(X) is not "pseries", is it?
> >>>
> >>> WX <- slag(X, listw, maxlag = 1)
> >>>>
> >>>> I see that slag is applicable for vectors of pseries, but this
command
> >>>> led to the error message: "Error in UseMethod("slag"): no applicable
> method
> >>>> for 'slag' applied to an object of class "c('matrix', 'double',
'numeric')"
> >>>>
> >>>
> >>> slag.default() takes a vector, slag.pseries() a "pseries" object.
> >>>
> >>>
> >>>> Is there any way to implement this SLX model for panel series?
> >>>>
> >>>
> >>> Did you look at spdep::create_WX?
> >>>
> >>>
> >>>> Regards,
> >>>>
> >>>> Daniel.
> >>>>
> >>>> [[alternative HTML version deleted]]
> >>>>
> >>>>
> >>> Please do not post HTML - like insects, HTML carries infectious
payloads
> >>> and wastes bandwidth and server processing capacity.
> >>>
> >>> _______________________________________________
> >>>> R-sig-Geo mailing list
> >>>> R-sig-Geo at r-project.org
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>>
> >>>>
> >>> --
> >>> Roger Bivand
> >>> Department of Economics, Norwegian School of Economics,
> >>> Helleveien 30, N-5045 Bergen, Norway.
> >>> voice: +47 55 95 93 55; fax +47 55 95 91 00
> >>> e-mail: Roger.Bivand at nhh.no
> >>> http://orcid.org/0000-0003-2392-6140
> >>> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> >>> http://depsy.org/person/434412
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>
> >
> >
> 
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55; fax +47 55 95 91 00
> e-mail: Roger.Bivand at nhh.no
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en
> http://depsy.org/person/434412
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mahsasameti1384 at gmail.com  Wed Dec 27 10:23:18 2017
From: mahsasameti1384 at gmail.com (Mahsa Sameti)
Date: Wed, 27 Dec 2017 12:53:18 +0330
Subject: [R-sig-Geo] Question about wireframe of spatio-temporal emperical
	variogram
Message-ID: <CADN=v_yph3H5u=+v_jocj4K8hSHSPAz-oTReFkPgQAJVkeLyjg@mail.gmail.com>

Dear all

I'm working on monthly spatio-temporal data.
I have constructed STSDF object and then compute empVgm. When i want to
plot it, the scale of time axis is based on year.
I tested different methods for creating time series for correcting this
problem but it shows the time scale only based on days or years. can any
one help me about what is wrong in this problem?

 Thanks alot.

	[[alternative HTML version deleted]]


From dfamaral at usp.br  Fri Dec 29 20:51:32 2017
From: dfamaral at usp.br (Daniel Furlan Amaral)
Date: Fri, 29 Dec 2017 17:51:32 -0200
Subject: [R-sig-Geo] Change dataframe values using log and if condition
Message-ID: <CANVFQJUQGoc3fFuwdiy1muHWA8tgsEr=h3z_qWNAzGk1q3VdUQ@mail.gmail.com>

Dear all,

I need to calculate log or log1p for all values (rows) in specific
columns of a data.frame with 5500 rows and 23 columns.

When i > 0, apply log, and when i == 0, apply log1p. So I thought I
should use a for loop with a ifelse condition, log and log1p
functions.

I have already tried many possibilities, but none solved. This is
something I tried, but the data.frame's values didn't change:



tcPainelLog <- tcPainel; cols <- names(tcPainelLog[6:17])

for (j in cols) {
    for (i in 1:length(j)) {
        ifelse(tcPainelLog[[i]] > 0, log(i), log1p(i))
    }
}



I would appreciate any help.

Thank you.

Daniel


From vijaylulla at gmail.com  Fri Dec 29 21:38:40 2017
From: vijaylulla at gmail.com (Vijay Lulla)
Date: Fri, 29 Dec 2017 15:38:40 -0500
Subject: [R-sig-Geo] Change dataframe values using log and if condition
In-Reply-To: <CANVFQJUQGoc3fFuwdiy1muHWA8tgsEr=h3z_qWNAzGk1q3VdUQ@mail.gmail.com>
References: <CANVFQJUQGoc3fFuwdiy1muHWA8tgsEr=h3z_qWNAzGk1q3VdUQ@mail.gmail.com>
Message-ID: <CAKkiGbuxkBFXLLSpaq9y4=xY4_hBCi4fgaYrM3iuPVH3i7URag@mail.gmail.com>

Maybe this can be of some help to you.

> set.seed(1234L)
> d <-
data.frame(v1=1:5,v2=c(0,abs(runif(4))),v3=c(runif(3),0,0),v4=0,v5=0.5)
> fn <- function(x) {
+   y <- x
+   y[y==0] <- log1p(y[y==0])
+   y[y>0] <- log(y[y>0])
+   y
+ }
>
> d[,2:5] <- apply(d[,2:5], 2, fn)
>
> d
  v1         v2         v3 v4         v5
1  1  0.0000000 -0.1497591  0 -0.6931472
2  2 -2.1741619 -0.4458019  0 -0.6931472
3  3 -0.4743339 -4.6569103  0 -0.6931472
4  4 -0.4954860  0.0000000  0 -0.6931472
5  5 -0.4725999  0.0000000  0 -0.6931472
>

Thanks,
Vijay.

On Fri, Dec 29, 2017 at 2:51 PM, Daniel Furlan Amaral <dfamaral at usp.br>
wrote:

> Dear all,
>
> I need to calculate log or log1p for all values (rows) in specific
> columns of a data.frame with 5500 rows and 23 columns.
>
> When i > 0, apply log, and when i == 0, apply log1p. So I thought I
> should use a for loop with a ifelse condition, log and log1p
> functions.
>
> I have already tried many possibilities, but none solved. This is
> something I tried, but the data.frame's values didn't change:
>
>
>
> tcPainelLog <- tcPainel; cols <- names(tcPainelLog[6:17])
>
> for (j in cols) {
>     for (i in 1:length(j)) {
>         ifelse(tcPainelLog[[i]] > 0, log(i), log1p(i))
>     }
> }
>
>
>
> I would appreciate any help.
>
> Thank you.
>
> Daniel
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Vijay Lulla, Ph.D.

Assistant Professor,
Dept. of Geography, IUPUI
425 University Blvd, CA-207C.
Indianapolis, IN-46202
vlulla at iupui.edu

<http://vijaylulla.com>
http://vijaylulla.com

	[[alternative HTML version deleted]]


From ruettenauer at sowi.uni-kl.de  Sun Dec 31 09:51:53 2017
From: ruettenauer at sowi.uni-kl.de (=?UTF-8?Q?Tobias_R=C3=BCttenauer?=)
Date: Sun, 31 Dec 2017 09:51:53 +0100
Subject: [R-sig-Geo] SLX model for splm package in R
In-Reply-To: <CANVFQJUOkZ9ZK3jqsk_hRxDCi-JXh7X+VrN0BOApkNBN+LwTrQ@mail.gmail.com>
References: <000301d37b0e$3f637e80$be2a7b80$@sowi.uni-kl.de>
 <CANVFQJUOkZ9ZK3jqsk_hRxDCi-JXh7X+VrN0BOApkNBN+LwTrQ@mail.gmail.com>
Message-ID: <001d01d38214$9b833360$d2899a20$@sowi.uni-kl.de>

Dear Daniel,

 

yes, that is basically the same answer to the problem. With time-series SLX you need to create a pseries and then apply slag. A second solution (using a data.frame) would be to apply lag.listw to each cross-section. Using my example below, this would be:

 

# Reorder data by cross-sections, then time

oo<-order(Produc$year, Produc$state)

Produc<-Produc[oo,]

 

# Build indices

indic<-seq(1,length(unique(Produc$year)))

inde<-as.numeric(rep(indic, each=length(unique(Produc$state))))

 

# Construct WX

Produc$Wpcap <- unlist(tapply(as.vector(Produc$pcap), inde, function(u) lag.listw(usa.lw, u, NAOK=T), simplify=TRUE))

 

Best,

Tobi

 

 

Von: Daniel Furlan Amaral [mailto:dfamaral at usp.br] 
Gesendet: 29 December 2017 17:27
An: Tobias R?ttenauer <ruettenauer at sowi.uni-kl.de>
Betreff: Re: [R-sig-Geo] SLX model for splm package in R

 

Dear Tobias,

 

Thank you for the answer. Coincidently, I published my answer on Stack Overflow today and answered my own question. I think we came up with the same solution. Please see by the link what you think:

 

https://stackoverflow.com/questions/46004670/slx-model-spatial-econometrics-with-panel-in-r-data-using-splm-package-and-sla

 

Best regards,

 

Daniel

 

2017-12-22 8:18 GMT-02:00 Tobias R?ttenauer <ruettenauer at sowi.uni-kl.de <mailto:ruettenauer at sowi.uni-kl.de> >:

Dear all,

though this is an old issue by now (but still one of the first google
results on the topic), here is some code answering one of the questions:
should you demean the spatial lag or lag the demeaned variable.

As far as I understand the following results, it does not matter. Both ways
produce identical results, which both conform to the LSDV approach.

Please find the example code below:


library(spdep)
library(splm)
library(texreg)

### Demean function
dm<-function(x, id){
  res<-x-ave(x,id,FUN=function(x) mean(x, na.rm=T))
  res
}

data(Produc, package="plm")
data(usaww)

usa.lw<-mat2listw(usaww)

Produc.pd<-pdata.frame(Produc, index=c("state", "year"))

Produc.pd$Wpcap<-slag(Produc.pd$pcap, usa.lw)
Produc.pd$Wpc<-slag(Produc.pd$pc, usa.lw)
Produc.pd$Wunemp<-slag(Produc.pd$unemp, usa.lw)

#### LSDV ####

lsdv.mod<-lm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp
             +state,
             data=Produc.pd)
summary(lsdv.mod)

#### Demean after lag ####

dal.mod<-plm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp,
             data=Produc.pd, effect="individual", model="within")
summary(dal.mod)

# Manual demeaning
Produc.pd[,4:ncol(Produc.pd)]<-apply(Produc.pd[,4:ncol(Produc.pd)], 2,
function(x) dm(x, Produc.pd$state))

dal2.mod<-lm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp,
             data=Produc.pd)
summary(dal2.mod)

#### Lag after demean ####

# Replace slags by demeaned slags
Produc.pd$Wpcap<-slag(Produc.pd$pcap, usa.lw)
Produc.pd$Wpc<-slag(Produc.pd$pc, usa.lw)
Produc.pd$Wunemp<-slag(Produc.pd$unemp, usa.lw)

lad.mod<-lm(gsp~pcap+pc+unemp + Wpcap+Wpc+Wunemp,
             data=Produc.pd)
summary(lad.mod)


screenreg(l=list(lsdv.mod, dal.mod, dal2.mod, lad.mod),
          omit.coef = "state", digits=6)



#### Test if both ways produce identical vectors ####

Produc.pd<-pdata.frame(Produc, index=c("state", "year"))

x<-Produc.pd$gsp

# lag after demean
dx<-dm(x, Produc.pd$state)
wdx<-slag(dx, usa.lw)

# deaman after lag
wx<-slag(x, usa.lw)
dwx<-dm(wx, Produc.pd$state)

# Test for equality
all.equal(wdx, dwx)


Best,
Tobi


Tobias R?ttenauer
TU Kaiserslautern
Erwin-Schr?dinger-Stra?e 57
67663 Kaiserslautern

ruettenauer at sowi.uni-kl.de <mailto:ruettenauer at sowi.uni-kl.de> 
Tel.: 0631 205 5785




> -----Urspr?ngliche Nachricht-----
> Von: R-sig-Geo [mailto:r-sig-geo-bounces at r-project.org <mailto:r-sig-geo-bounces at r-project.org> ] Im Auftrag von
> Roger Bivand
> Gesendet: 30 August 2016 08:44
> An: dfamaral at usp.br <mailto:dfamaral at usp.br> 
> Cc: r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org> 
> Betreff: Re: [R-sig-Geo] SLX model for splm package in R
>
> On Tue, 30 Aug 2016, dfamaral at usp.br <mailto:dfamaral at usp.br>  wrote:
>
> > Dear all,
> >
> > Impacts in SLX model are calculated directly by parameters estimation:
> >
> > http://onlinelibrary.wiley.com/doi/10.1111/jors.12188/abstract
> >
> > Beta1 gives direct impact and Beta 2 the indirect:
> >
> > y = beta1*X + beta2*WX + e
> >
>
> Yes, but you need the total impact beta1+beta2, but more work to infer
from
> that sum, which is what you need to assess the impact of X.
>
> > I understand W must multiply T times the X matrix (T is the lenght of
> > time series for a panel data). And variables are demeaned after WX is
> > calculated.
>
> Kronecker product of sparse matrices. Please contribute a patch for
> create_WX if desirable.
>
> Please motivate the demean-after-lag concusion. Will this not affect the
> direct link between X and WX?
>
> Roger
>
> >
> > Daniel.
> >
> > ----- Mensagem original -----
> >
> >
> > De: "Roger Bivand" <Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> >
> > Para: "Burcu Ozuduru" <bozuduru at gmail.com <mailto:bozuduru at gmail.com> >
> > Cc: dfamaral at usp.br <mailto:dfamaral at usp.br> , r-sig-geo at r-project.org <mailto:r-sig-geo at r-project.org> 
> > Enviadas: Segunda-feira, 29 de Agosto de 2016 4:13:26
> > Assunto: Re: [R-sig-Geo] SLX model for splm package in R
> >
> > This is far too ad-hoc a discussion. For Spatial panel SLX, please
> > read
> > carefully:
> >
> > http://dx.doi.org/10.1016/j.spasta.2014.02.002
> > DOI 10.1007/s10109-015-0217-3
> > DOI: 10.1111/jors.12188
> >
> > for a view of the state of play. One question - should you demean the
> > X variables before taking spatial lags? This does not apply to
> > cross-section models for which spdep::create_WX() was written, for
> > obvious reasons. A second question - how do you handle the calculation
> > of total impacts in this setting? In cross-section models, this is
> > reasonably easy, by linear combination. But in spatial panel SLX
> > models, is it easy? What does the literature suggest?
> >
> > On Mon, 29 Aug 2016, Burcu Ozuduru wrote:
> >
> >> Hi,
> >>
> >> This is a great question because I faced the same problem a while back.
> >> What I did is to obtain the spatial weight matrix as (have spdep
> >> installed).
> >>
> >> S47matrix<-W1%*%S47
> >>
> >> and then put it in my data frame and equation. Btw, above W1 is a
> >> spatial weights matrix I obtained from a neighbor list
> >> (W1=as.matrix(as_dgRMatrix_listw(ccListw))) and S47 is the dependent
> >> variable.
> >>
> >> m2<-
> data.frame(S41,S46,S47,S65,S68,S47matrix,MAD10000,NQPDA10000,TPBt
> >> A10000,DivA10000,Lnk10000)
> >> summary(m2<-zeroinfl(S47~MAD10000+NQPDA10000+S47matrix,
> >> dist="negbin"))
> >>
> >> I also wanted to ask whether I was on the right track. Professor
> >> Bivand, if this is a common problem could you direct us to a relevant
> >> page -if available and if at all possible- please? Your advice would
> >> be sincerely appreciated.
> >
> > This is an inappropriate question for this thread (SLX spatial panel
> > models). You must refer to the literature, and understand what you are
> > doing:
> >
> > zeroinfl(S47~MAD10000+NQPDA10000+S47matrix, dist="negbin")
> >
> > is completely wrong, as S47matrix is Wy, the spatial lag of the
> > dependent variable, and this spatial lag model of response S47 cannot
> > be estimated using pscl::zeroinfl (do say which package provides the
> > functions you mention). Your only recourse is to write your own
> > Bayesian model. It is even extremely likely that this model doesn't
> > make any substantive sense, unless you have a good understanding about
> > why S47 at i (for all i) should be simultaneously caused by the full
> > set of values of S47. A model in the error might make sense (a zero
> > inflated negbin model with an additive mrf random effect (maybe
> R2BayesX 10.18637/jss.v014.i11).
> >
> > An SLX zero inflated negbin model could maybe apply, in which case
> > pscl::zeroinfl might be applicable, but then you'd be including the
> > lags of MAD10000 and NQPDA10000, not the response, and inference on
> > total impacts of these variables could be challenging rather than
> > obvious (MCMC summaries of the summed samples of the coefficients
> > would work, but here no MCMC I think - R2BayesX might help).
> >
> > Most of these issues are far more complex than students or their
> > supervisors understand, do ask an experienced applied statistician
> > (I'm not an applied statistician, don't rely on my suggestions, you
> > yourself are responsible for your results).
> >
> > Hope this clarifies,
> >
> > Roger
> >
> >>
> >> Kind Regards-
> >>
> >> Thanks-
> >>
> >> Burcu
> >>
> >> ---
> >>
> >> Burcu H. Ozuduru,
> >> Gazi University, Faculty of Architecture, Department of City and
> >> Regional Planning Maltepe-Ankara Turkey
> >> t: +90-312-5823701
> >> e: bozuduru at gazi.edu.tr <mailto:bozuduru at gazi.edu.tr> 
> >> http://websitem.gazi.edu.tr/bozuduru
> >>
> >>
> >> On Mon, Aug 29, 2016 at 12:42 AM, Roger Bivand
> <Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> > wrote:
> >>
> >>> On Sun, 28 Aug 2016, dfamaral at usp.br <mailto:dfamaral at usp.br>  wrote:
> >>>
> >>> Dear colleagues,
> >>>>
> >>>> Does anyone know how to implement Spatial Lag of X (SLX) model for
> >>>> panel data using splm package? I tried the following to create a WX
> >>>> matrix and then apply Fixed and Random Effects:
> >>>>
> >>>> tb <- read.csv2("panel.csv", header = TRUE, sep = ";", dec = ".")
> >>>> time <- length(unique(tb$year)) X <- as.matrix(tb[ ,3:20])
> >>>>
> >>>
> >>> class(X) is not "pseries", is it?
> >>>
> >>> WX <- slag(X, listw, maxlag = 1)
> >>>>
> >>>> I see that slag is applicable for vectors of pseries, but this
command
> >>>> led to the error message: "Error in UseMethod("slag"): no applicable
> method
> >>>> for 'slag' applied to an object of class "c('matrix', 'double',
'numeric')"
> >>>>
> >>>
> >>> slag.default() takes a vector, slag.pseries() a "pseries" object.
> >>>
> >>>
> >>>> Is there any way to implement this SLX model for panel series?
> >>>>
> >>>
> >>> Did you look at spdep::create_WX?
> >>>
> >>>
> >>>> Regards,
> >>>>
> >>>> Daniel.
> >>>>
> >>>> [[alternative HTML version deleted]]
> >>>>
> >>>>
> >>> Please do not post HTML - like insects, HTML carries infectious
payloads
> >>> and wastes bandwidth and server processing capacity.
> >>>
> >>> _______________________________________________
> >>>> R-sig-Geo mailing list
> >>>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> 
> >>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>>
> >>>>
> >>> --
> >>> Roger Bivand
> >>> Department of Economics, Norwegian School of Economics,
> >>> Helleveien 30, N-5045 Bergen, Norway.
> >>> voice: +47 55 95 93 55 <tel:%2B47%2055%2095%2093%2055> ; fax +47 55 95 91 00 <tel:%2B47%2055%2095%2091%2000> 
> >>> e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> 
> >>> http://orcid.org/0000-0003-2392-6140
> >>> https://scholar.google.no/citations?user=AWeghB0AAAAJ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en> &hl=en
> >>> http://depsy.org/person/434412
> >>>
> >>> _______________________________________________
> >>> R-sig-Geo mailing list
> >>> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> 
> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>>
> >>
> >
> >
>
> --
> Roger Bivand
> Department of Economics, Norwegian School of Economics,
> Helleveien 30, N-5045 Bergen, Norway.
> voice: +47 55 95 93 55 <tel:%2B47%2055%2095%2093%2055> ; fax +47 55 95 91 00 <tel:%2B47%2055%2095%2091%2000> 
> e-mail: Roger.Bivand at nhh.no <mailto:Roger.Bivand at nhh.no> 
> http://orcid.org/0000-0003-2392-6140
> https://scholar.google.no/citations?user=AWeghB0AAAAJ <https://scholar.google.no/citations?user=AWeghB0AAAAJ&hl=en> &hl=en
> http://depsy.org/person/434412
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org> 
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

 


	[[alternative HTML version deleted]]


