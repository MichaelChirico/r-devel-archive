From sglish at hotmail.com  Wed Jun  1 20:41:37 2011
From: sglish at hotmail.com (Chris English)
Date: Wed, 1 Jun 2011 14:41:37 -0400
Subject: [R-sig-Geo] proper syntax for passing MINUSERPIXELVALUE,
 MAXUSERPIXELVALUE to Terragen driver
Message-ID: <SNT117-W282663DE3E84B8ECAD10BDC57D0@phx.gbl>


Dear List,
I have a SpatialGridDataFrame that from which I hope to createa Terragen file.
My consistent error in create2GDAL:
GDAL Error 1: Inverted, flat, or unspecified span for Terragen file.
I need to pass the options =c("MINUSERPIXELVALUE = 1", "MAXUSERPIXELVALUE=2736")to the Terragen driver and don't know how.
Details of writeGDAL suggest:it may also be necessary in some cases to escape quotation markes if included in thestring passed to the driver.
As there aren't embedded quotation marks, I don't think this applies. ?But, ifone doesn't establish the MIN/MAX~USERPIXELVALUE, one will always get the aboveerror.
Thank you,
Chris English







 		 	   		  

From jthayn at ilstu.edu  Thu Jun  2 01:06:52 2011
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Wed, 1 Jun 2011 18:06:52 -0500
Subject: [R-sig-Geo] SpatialFiltering function in the spdep package
Message-ID: <D9A675E4-7B2B-4970-A8D6-52FA1CFF69CA@ilstu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110601/cfdec560/attachment.pl>

From thi_veloso at yahoo.com.br  Thu Jun  2 17:16:36 2011
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Thu, 2 Jun 2011 08:16:36 -0700
Subject: [R-sig-Geo] Methodology to compare crop maps
Message-ID: <455880.9586.qm@web161406.mail.bf1.yahoo.com>

? Dear R-SIG colleagues,

? I am working with crops planted area maps from two distinct sources. One of the maps is based on a maximum NDVI composition, and the other map uses joint information from satellite and census to estimate the planted area.

 Although the sources employ different methodologies to map the area where the crop exists, the results should be comparable.

 After downloading the datasets, I have performed a visual inpection, and they show reasonable agreement. However, I need a more robust comparison method. Could anybody point out a methodology which allows me to show the difference between both maps?

? Here is an example of each one of the maps: http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not available to download directly, but I can get it in shapefile)

 Thanks in advance,

 Thiago Veloso.





From rshepard at appl-ecosys.com  Thu Jun  2 17:27:19 2011
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 2 Jun 2011 08:27:19 -0700
Subject: [R-sig-Geo] Methodology to compare crop maps
In-Reply-To: <455880.9586.qm@web161406.mail.bf1.yahoo.com>
References: <455880.9586.qm@web161406.mail.bf1.yahoo.com>
Message-ID: <alpine.LNX.2.00.1106020822260.19598@salmo.appl-ecosys.com>

On Thu, 2 Jun 2011, Thiago Veloso wrote:

> I am working with crops planted area maps from two distinct sources. One
> of the maps is based on a maximum NDVI composition, and the other map uses
> joint information from satellite and census to estimate the planted area.

> After downloading the datasets, I have performed a visual inpection, and
> they show reasonable agreement. However, I need a more robust comparison
> method. Could anybody point out a methodology which allows me to show the
> difference between both maps?

Thiago,

   Please accept my suggestion that you're not using the best tool for this
job in the positive way I intend. This is a spatial analytical question best
answered by an analytical GIS rather than statistical software.

   I've been using GRASS <http://grass.osgeo.org/> for a dozen or so years
and it will quickly answer your question as well as many others. Assuming
that your maps are grid- (or raster-) based a simple subtraction of one from
the other will show differences. You can also ask for differences in other
ways. The r.mapcalc() module is quite powerful. If your source data are in
vector format you can transform them to rasters for more powerful analysis.

HTH,

Rich


From bstults at fsu.edu  Thu Jun  2 18:15:26 2011
From: bstults at fsu.edu (Brian J. Stults)
Date: Thu, 2 Jun 2011 12:15:26 -0400
Subject: [R-sig-Geo] gUnion causes segfault
Message-ID: <4DE7B71E.2060301@fsu.edu>

Hello,

I am working with the 2009 Tiger/LINE topological faces files.  I want
to create a shapefile with polygons for unique instances of state,
county, place, and tract.  Since the topological faces shapefiles
provide many smaller geographies, my approach has been to dissolve those
smaller geographies into larger ones using the gUnion function from
rgeos.  This works for most counties, but it causes segfaults for some.
 One example is Apache County, AL.  The shapefile is here:

http://www2.census.gov/geo/tiger/TIGER2009/04_ARIZONA/04001_Apache_County/tl_2009_04001_faces.zip

My code (modified to work on a single county) is:

library(maptools)
library(rgeos)

tiger <- readShapePoly("tl_2009_04001_faces.shp",
proj4string=CRS("+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"))[,
c(4,37)]
tiger$PLACEFP <- as.character(tiger$PLACEFP)
tiger$PLACEFP[is.na(tiger$PLACEFP)] <- "99999"
tiger$uniqueid <- paste(tiger$PLACEFP00, tiger$TRACTCE00, sep="")
tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
q()


The error message is:

> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)

 *** caught segfault ***
address 0x17c9, cause 'memory not mapped'

Traceback:
 1: .Call(func, .RGEOS_HANDLE, spgeom, id, byid, PACKAGE = "rgeos")
 2: TopologyFunc(groupID(spgeom, id), unique(na.omit(id)), TRUE,
"rgeos_unioncascaded")
 3: gUnionCascaded(tiger, tiger$uniqueid)
aborting ...


The full output can be viewed here:
http://www2.criminology.fsu.edu/~stults/misc/union_tiger.txt


Can anyone tell me what is going wrong, or how to go about debugging the
problem?  I uninstalled rgeos to force using UnionSpatialPolygons (there
must be a better way to force that than uninstalling, right?), but that
ran overnight and never finished.  I am guessing there must be something
strange about these shapefiles.

I can successfully dissolve this shapefile using the ftools module in
qgis.  However, I want to do this for a large number of counties, which
is why I am pursuing a programmed solution.  I tried doing it via python
scripting with qgis, but could not get that to work after a lot of
trying.  I am currently trying to do it with Spatialite, which seems
promising.  I would be happy to hear any other suggested approaches.

Thanks,
Brian

-- 
Brian J. Stults
Assistant Professor
College of Criminology and Criminal Justice
Florida State University
phone: 850-645-7376   fax: 850-644-9614


From luca.morandini1 at gmail.com  Thu Jun  2 18:39:51 2011
From: luca.morandini1 at gmail.com (Luca Morandini)
Date: Thu, 2 Jun 2011 18:39:51 +0200
Subject: [R-sig-Geo] Methodology to compare crop maps
In-Reply-To: <alpine.LNX.2.00.1106020822260.19598@salmo.appl-ecosys.com>
References: <455880.9586.qm@web161406.mail.bf1.yahoo.com>
	<alpine.LNX.2.00.1106020822260.19598@salmo.appl-ecosys.com>
Message-ID: <4DE7BCD7.1050608@gmail.com>

On 06/02/2011 05:27 PM, Rich Shepard wrote:
>
> Please accept my suggestion that you're not using the best tool for this
> job in the positive way I intend. This is a spatial analytical question best
> answered by an analytical GIS rather than statistical software.

Well, yes... but the R raster package allows you to do map algebra and a host of 
other raster functions as well: one may try that before switching to GIS.

It must be noted, however, that the raster package performance is poor when large 
datasets are involved.


> I've been using GRASS <http://grass.osgeo.org/> for a dozen or so years

For a newbie I would suggest Quantum GIS coupled with its GRASS plug-in instead: 
same power, more friendly UI.

Regards,

Luca Morandini
http://www.lucamorandini.it

-- 
Regards,

Luca Morandini
http://www.lucamorandini.it


From tavgar at uoguelph.ca  Thu Jun  2 18:49:15 2011
From: tavgar at uoguelph.ca (Tal Avgar)
Date: Thu, 2 Jun 2011 12:49:15 -0400
Subject: [R-sig-Geo] clustering spatial point data
Message-ID: <002c01cc2145$01e3d430$05ab7c90$@ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110602/fd52e748/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jun  2 19:34:16 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 2 Jun 2011 19:34:16 +0200
Subject: [R-sig-Geo] gUnion causes segfault
In-Reply-To: <4DE7B71E.2060301@fsu.edu>
References: <4DE7B71E.2060301@fsu.edu>
Message-ID: <alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>

On Thu, 2 Jun 2011, Brian J. Stults wrote:

> Hello,
>
> I am working with the 2009 Tiger/LINE topological faces files.  I want
> to create a shapefile with polygons for unique instances of state,
> county, place, and tract.  Since the topological faces shapefiles
> provide many smaller geographies, my approach has been to dissolve those
> smaller geographies into larger ones using the gUnion function from
> rgeos.  This works for most counties, but it causes segfaults for some.
> One example is Apache County, AL.  The shapefile is here:
Please always include the output of sessionInfo() in any report like this. 
Both the OS for binary packages, and the specific version of rgeos, may 
play a role. I cannot check on a 1GB laptop, because the shapefile creates 
a 180MB object and has 63K polygons. I don't know why subsetting the 
columns in the data slot would help, but I do think that your assignment 
back into the object is a hidrance in memory terms for such a large object 
- provoking copies. I assumed that you do know that you have no other way 
to dissolve so many polygons into so few (40) output units - this isn't a 
typical use case. The version of rgeos may matter, as protection against 
unclean objects provoking seg.faults has recently been extended.

Roger


>
> http://www2.census.gov/geo/tiger/TIGER2009/04_ARIZONA/04001_Apache_County/tl_2009_04001_faces.zip
>
> My code (modified to work on a single county) is:
>
> library(maptools)
> library(rgeos)
>
> tiger <- readShapePoly("tl_2009_04001_faces.shp",
> proj4string=CRS("+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"))[,
> c(4,37)]
> tiger$PLACEFP <- as.character(tiger$PLACEFP)
> tiger$PLACEFP[is.na(tiger$PLACEFP)] <- "99999"
> tiger$uniqueid <- paste(tiger$PLACEFP00, tiger$TRACTCE00, sep="")
> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
> q()
>
>
> The error message is:
>
>> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
>
> *** caught segfault ***
> address 0x17c9, cause 'memory not mapped'
>
> Traceback:
> 1: .Call(func, .RGEOS_HANDLE, spgeom, id, byid, PACKAGE = "rgeos")
> 2: TopologyFunc(groupID(spgeom, id), unique(na.omit(id)), TRUE,
> "rgeos_unioncascaded")
> 3: gUnionCascaded(tiger, tiger$uniqueid)
> aborting ...
>
>
> The full output can be viewed here:
> http://www2.criminology.fsu.edu/~stults/misc/union_tiger.txt
>
>
> Can anyone tell me what is going wrong, or how to go about debugging the
> problem?  I uninstalled rgeos to force using UnionSpatialPolygons (there
> must be a better way to force that than uninstalling, right?), but that
> ran overnight and never finished.  I am guessing there must be something
> strange about these shapefiles.
>
> I can successfully dissolve this shapefile using the ftools module in
> qgis.  However, I want to do this for a large number of counties, which
> is why I am pursuing a programmed solution.  I tried doing it via python
> scripting with qgis, but could not get that to work after a lot of
> trying.  I am currently trying to do it with Spatialite, which seems
> promising.  I would be happy to hear any other suggested approaches.
>
> Thanks,
> Brian
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From bstults at fsu.edu  Thu Jun  2 20:10:31 2011
From: bstults at fsu.edu (Brian J. Stults)
Date: Thu, 2 Jun 2011 14:10:31 -0400
Subject: [R-sig-Geo] gUnion causes segfault
In-Reply-To: <alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>
References: <4DE7B71E.2060301@fsu.edu>
	<alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>
Message-ID: <4DE7D217.6060001@fsu.edu>

> On Thu, 2 Jun 2011, Brian J. Stults wrote:
> 
>> Hello,
>>
>> I am working with the 2009 Tiger/LINE topological faces files.  I want
>> to create a shapefile with polygons for unique instances of state,
>> county, place, and tract.  Since the topological faces shapefiles
>> provide many smaller geographies, my approach has been to dissolve those
>> smaller geographies into larger ones using the gUnion function from
>> rgeos.  This works for most counties, but it causes segfaults for some.
>> One example is Apache County, AL.  The shapefile is here:
> Please always include the output of sessionInfo() in any report like
> this. Both the OS for binary packages, and the specific version of
> rgeos, may play a role.

Thanks for looking into this.  Here is the sessionInfo output.

R version 2.13.0 (2011-04-13)
Platform: i486-pc-linux-gnu (32-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgeos_0.1-6     stringr_0.4     maptools_0.8-7  lattice_0.19-26
[5] sp_0.9-82       foreign_0.8-44

loaded via a namespace (and not attached):
[1] grid_2.13.0 plyr_1.5.2
Warning message:
'DESCRIPTION' file has 'Encoding' field and re-encoding is not possible


> I cannot check on a 1GB laptop, because the
> shapefile creates a 180MB object and has 63K polygons. 

Here is a smaller county that results in the same problem:

http://www2.census.gov/geo/tiger/TIGER2009/02_ALASKA/02013_Aleutians_East_Borough/tl_2009_02013_faces.zip


> I don't know why
> subsetting the columns in the data slot would help, but I do think that
> your assignment back into the object is a hidrance in memory terms for
> such a large object - provoking copies. 

I am (probably obviously) pretty new to R.  I thought that subsetting
the columns would reduce the required memory.  Perhaps it was just the
opposite.


> I assumed that you do know that
> you have no other way to dissolve so many polygons into so few (40)
> output units - this isn't a typical use case. The version of rgeos may
> matter, as protection against unclean objects provoking seg.faults has
> recently been extended.

I first tried using the intersection of the TIGER files for places and
tracts using gIntersection since there are far fewer polygons to deal
with in those files.  However, the processing took a prohibitively long
time.  Using gUnionCascaded didn't take too, too long for the counties
that did not cause a segfault.

Thanks,
Brian


> 
> Roger
> 
> 
>>
>> http://www2.census.gov/geo/tiger/TIGER2009/04_ARIZONA/04001_Apache_County/tl_2009_04001_faces.zip
>>
>>
>> My code (modified to work on a single county) is:
>>
>> library(maptools)
>> library(rgeos)
>>
>> tiger <- readShapePoly("tl_2009_04001_faces.shp",
>> proj4string=CRS("+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"))[,
>> c(4,37)]
>> tiger$PLACEFP <- as.character(tiger$PLACEFP)
>> tiger$PLACEFP[is.na(tiger$PLACEFP)] <- "99999"
>> tiger$uniqueid <- paste(tiger$PLACEFP00, tiger$TRACTCE00, sep="")
>> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
>> q()
>>
>>
>> The error message is:
>>
>>> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
>>
>> *** caught segfault ***
>> address 0x17c9, cause 'memory not mapped'
>>
>> Traceback:
>> 1: .Call(func, .RGEOS_HANDLE, spgeom, id, byid, PACKAGE = "rgeos")
>> 2: TopologyFunc(groupID(spgeom, id), unique(na.omit(id)), TRUE,
>> "rgeos_unioncascaded")
>> 3: gUnionCascaded(tiger, tiger$uniqueid)
>> aborting ...
>>
>>
>> The full output can be viewed here:
>> http://www2.criminology.fsu.edu/~stults/misc/union_tiger.txt
>>
>>
>> Can anyone tell me what is going wrong, or how to go about debugging the
>> problem?  I uninstalled rgeos to force using UnionSpatialPolygons (there
>> must be a better way to force that than uninstalling, right?), but that
>> ran overnight and never finished.  I am guessing there must be something
>> strange about these shapefiles.
>>
>> I can successfully dissolve this shapefile using the ftools module in
>> qgis.  However, I want to do this for a large number of counties, which
>> is why I am pursuing a programmed solution.  I tried doing it via python
>> scripting with qgis, but could not get that to work after a lot of
>> trying.  I am currently trying to do it with Spatialite, which seems
>> promising.  I would be happy to hear any other suggested approaches.
>>
>> Thanks,
>> Brian
>>
>>
>


From b.rowlingson at lancaster.ac.uk  Thu Jun  2 21:12:36 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 2 Jun 2011 20:12:36 +0100
Subject: [R-sig-Geo] gUnion causes segfault
In-Reply-To: <4DE7D217.6060001@fsu.edu>
References: <4DE7B71E.2060301@fsu.edu>
	<alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>
	<4DE7D217.6060001@fsu.edu>
Message-ID: <BANLkTinG=iRmc6A1bXAx9iOLUqo310wYsQ@mail.gmail.com>

I get a buffer overflow and a nice traceback that might be helpful:

*** buffer overflow detected ***: /usr/lib/R/bin/exec/R terminated
======= Backtrace: =========
/lib/tls/i686/cmov/libc.so.6(__fortify_fail+0x50)[0x1f3390]
/lib/tls/i686/cmov/libc.so.6(+0xe12ca)[0x1f22ca]
/lib/tls/i686/cmov/libc.so.6(__strcpy_chk+0x44)[0x1f1644]
/home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(RGEOS_comment2comm+0x8f)[0xc70aff]
/home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_Polygons2geospolygon+0x5c)[0xc73a8c]
/home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_SpatialPolygons2geospolygon+0x8b)[0xc73d7b]
/home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_convert_R2geos+0x548)[0xc74a58]
/home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_topologyfunc+0x51)[0xc7cf61]
/home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_unioncascaded+0x3c)[0xc7d1cc]
[etc]

My rgeos is:

rgeos: (SVN revision (unknown))
 GEOS runtime version: 3.2.2-CAPI-1.6.2
 Polygon checking: TRUE

Version: 0.1-6

Barry


From Roger.Bivand at nhh.no  Thu Jun  2 23:27:12 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 2 Jun 2011 23:27:12 +0200
Subject: [R-sig-Geo] gUnion causes segfault
In-Reply-To: <4DE7D217.6060001@fsu.edu>
References: <4DE7B71E.2060301@fsu.edu>
	<alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>
	<4DE7D217.6060001@fsu.edu>
Message-ID: <alpine.LRH.2.00.1106022324140.28815@reclus.nhh.no>

On Thu, 2 Jun 2011, Brian J. Stults wrote:

>> On Thu, 2 Jun 2011, Brian J. Stults wrote:
>>
>>> Hello,
>>>
>>> I am working with the 2009 Tiger/LINE topological faces files.  I want
>>> to create a shapefile with polygons for unique instances of state,
>>> county, place, and tract.  Since the topological faces shapefiles
>>> provide many smaller geographies, my approach has been to dissolve those
>>> smaller geographies into larger ones using the gUnion function from
>>> rgeos.  This works for most counties, but it causes segfaults for some.
>>> One example is Apache County, AL.  The shapefile is here:
>> Please always include the output of sessionInfo() in any report like
>> this. Both the OS for binary packages, and the specific version of
>> rgeos, may play a role.
>
> Thanks for looking into this.  Here is the sessionInfo output.
>
> R version 2.13.0 (2011-04-13)
> Platform: i486-pc-linux-gnu (32-bit)
>
> locale:
> [1] C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] rgeos_0.1-6     stringr_0.4     maptools_0.8-7  lattice_0.19-26
> [5] sp_0.9-82       foreign_0.8-44
>
> loaded via a namespace (and not attached):
> [1] grid_2.13.0 plyr_1.5.2
> Warning message:
> 'DESCRIPTION' file has 'Encoding' field and re-encoding is not possible


OK, thanks. Next, how was GEOS and the GEOS C API installed - from source, 
or from a Debian/Ubuntu or RPM package - if so, which?

>
>
>> I cannot check on a 1GB laptop, because the
>> shapefile creates a 180MB object and has 63K polygons.
>
> Here is a smaller county that results in the same problem:
>
> http://www2.census.gov/geo/tiger/TIGER2009/02_ALASKA/02013_Aleutians_East_Borough/tl_2009_02013_faces.zip
>
>
>> I don't know why
>> subsetting the columns in the data slot would help, but I do think that
>> your assignment back into the object is a hidrance in memory terms for
>> such a large object - provoking copies.
>
> I am (probably obviously) pretty new to R.  I thought that subsetting
> the columns would reduce the required memory.  Perhaps it was just the
> opposite.
>
>
>> I assumed that you do know that
>> you have no other way to dissolve so many polygons into so few (40)
>> output units - this isn't a typical use case. The version of rgeos may
>> matter, as protection against unclean objects provoking seg.faults has
>> recently been extended.
>
> I first tried using the intersection of the TIGER files for places and
> tracts using gIntersection since there are far fewer polygons to deal
> with in those files.  However, the processing took a prohibitively long
> time.  Using gUnionCascaded didn't take too, too long for the counties
> that did not cause a segfault.

I'll see whether building candidate intersections with the STRtree helps - 
it may not.

Roger

>
> Thanks,
> Brian
>
>
>>
>> Roger
>>
>>
>>>
>>> http://www2.census.gov/geo/tiger/TIGER2009/04_ARIZONA/04001_Apache_County/tl_2009_04001_faces.zip
>>>
>>>
>>> My code (modified to work on a single county) is:
>>>
>>> library(maptools)
>>> library(rgeos)
>>>
>>> tiger <- readShapePoly("tl_2009_04001_faces.shp",
>>> proj4string=CRS("+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"))[,
>>> c(4,37)]
>>> tiger$PLACEFP <- as.character(tiger$PLACEFP)
>>> tiger$PLACEFP[is.na(tiger$PLACEFP)] <- "99999"
>>> tiger$uniqueid <- paste(tiger$PLACEFP00, tiger$TRACTCE00, sep="")
>>> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
>>> q()
>>>
>>>
>>> The error message is:
>>>
>>>> tiger.dissolve <- gUnionCascaded(tiger, tiger$uniqueid)
>>>
>>> *** caught segfault ***
>>> address 0x17c9, cause 'memory not mapped'
>>>
>>> Traceback:
>>> 1: .Call(func, .RGEOS_HANDLE, spgeom, id, byid, PACKAGE = "rgeos")
>>> 2: TopologyFunc(groupID(spgeom, id), unique(na.omit(id)), TRUE,
>>> "rgeos_unioncascaded")
>>> 3: gUnionCascaded(tiger, tiger$uniqueid)
>>> aborting ...
>>>
>>>
>>> The full output can be viewed here:
>>> http://www2.criminology.fsu.edu/~stults/misc/union_tiger.txt
>>>
>>>
>>> Can anyone tell me what is going wrong, or how to go about debugging the
>>> problem?  I uninstalled rgeos to force using UnionSpatialPolygons (there
>>> must be a better way to force that than uninstalling, right?), but that
>>> ran overnight and never finished.  I am guessing there must be something
>>> strange about these shapefiles.
>>>
>>> I can successfully dissolve this shapefile using the ftools module in
>>> qgis.  However, I want to do this for a large number of counties, which
>>> is why I am pursuing a programmed solution.  I tried doing it via python
>>> scripting with qgis, but could not get that to work after a lot of
>>> trying.  I am currently trying to do it with Spatialite, which seems
>>> promising.  I would be happy to hear any other suggested approaches.
>>>
>>> Thanks,
>>> Brian
>>>
>>>
>>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Jun  2 23:29:47 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 2 Jun 2011 23:29:47 +0200
Subject: [R-sig-Geo] gUnion causes segfault
In-Reply-To: <BANLkTinG=iRmc6A1bXAx9iOLUqo310wYsQ@mail.gmail.com>
References: <4DE7B71E.2060301@fsu.edu>
	<alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>
	<4DE7D217.6060001@fsu.edu>
	<BANLkTinG=iRmc6A1bXAx9iOLUqo310wYsQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106022328110.28815@reclus.nhh.no>

On Thu, 2 Jun 2011, Barry Rowlingson wrote:

> I get a buffer overflow and a nice traceback that might be helpful:
>
> *** buffer overflow detected ***: /usr/lib/R/bin/exec/R terminated
> ======= Backtrace: =========
> /lib/tls/i686/cmov/libc.so.6(__fortify_fail+0x50)[0x1f3390]
> /lib/tls/i686/cmov/libc.so.6(+0xe12ca)[0x1f22ca]
> /lib/tls/i686/cmov/libc.so.6(__strcpy_chk+0x44)[0x1f1644]
> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(RGEOS_comment2comm+0x8f)[0xc70aff]

Thanks - this is in the code for trying to construct OGC SFS alike Polygon 
or MultiPolygon objects from R/sp Polygons objects. I'll try to see what 
it is.

Roger

> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_Polygons2geospolygon+0x5c)[0xc73a8c]
> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_SpatialPolygons2geospolygon+0x8b)[0xc73d7b]
> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_convert_R2geos+0x548)[0xc74a58]
> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_topologyfunc+0x51)[0xc7cf61]
> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_unioncascaded+0x3c)[0xc7d1cc]
> [etc]
>
> My rgeos is:
>
> rgeos: (SVN revision (unknown))
> GEOS runtime version: 3.2.2-CAPI-1.6.2
> Polygon checking: TRUE
>
> Version: 0.1-6
>
> Barry
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From r.turner at auckland.ac.nz  Fri Jun  3 06:33:31 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 03 Jun 2011 16:33:31 +1200
Subject: [R-sig-Geo] clustering spatial point data
In-Reply-To: <002c01cc2145$01e3d430$05ab7c90$@ca>
References: <002c01cc2145$01e3d430$05ab7c90$@ca>
Message-ID: <4DE8641B.5000303@auckland.ac.nz>

On 03/06/11 04:49, Tal Avgar wrote:
> I am looking for a code/function/algorithm for clustering spatial point data
> into two distinct groups, based on spatial coordinates and a measure of a
> continuous response variable at these locations. The requirement is for
> group members to be as similar as possible in their affiliated response
> values but also group members must be clustered in space so that there are
> no events belonging to one group within the space affiliated with the other.
> Any ideas?
> Thanks,
> Tal.

I haven't yet seen any replies to your post, so I'll chip in with my
two cents (or less!) worth.

I think you need to be more explicit/specific as to how you wish
to form the clusters.  Clustering is usually based on some sort
of distance measure between the points.  Your distance measure
will need to be based both on the spatial distance between the
points and the difference in the values of ``the continuous response
variable''  (such a value is referred to in the trade as a numeric
*mark*) corresponding to a given point.

Once you've defined the distance measure you should be able
to create a ``distance matrix'' and then apply standard clustering
techniques (readily available in R) to that matrix.

One very naive approach would be just to use the Euclidean distance
between the triples (x_i, y_i, z_i) where x_i and y_i specify the point
locations and z_i is the numeric mark of the point in question.

Using Euclidean distance is almost surely *not* the right thing to do.
However you could try it, since it would be very easy to implement,
and see what it tells you.  You might thereby get some insight into
how to define the distance measure properly.

     cheers,

         Rolf Turner


From luca.morandini1 at gmail.com  Fri Jun  3 06:51:56 2011
From: luca.morandini1 at gmail.com (Luca Morandini)
Date: Fri, 03 Jun 2011 06:51:56 +0200
Subject: [R-sig-Geo] clustering spatial point data
In-Reply-To: <4DE8641B.5000303@auckland.ac.nz>
References: <002c01cc2145$01e3d430$05ab7c90$@ca>
	<4DE8641B.5000303@auckland.ac.nz>
Message-ID: <4DE8686C.4000506@gmail.com>

On 06/03/2011 06:33 AM, Rolf Turner wrote:
>
> I haven't yet seen any replies to your post, so I'll chip in with my
> two cents (or less!) worth.

I'll put down my 2 ?cent as well ;)


> One very naive approach would be just to use the Euclidean distance
> between the triples (x_i, y_i, z_i) where x_i and y_i specify the point
> locations and z_i is the numeric mark of the point in question.
>
> Using Euclidean distance is almost surely *not* the right thing to do.

What about the local version of Moran'I auto-correlation index ?

This indicator should be suitable as a metric for detecting the wanted clusters, 
since it takes into account both response variable and spatial distance.

Regards,

Luca Morandini
http://www.lucamorandini.it

-- 
Regards,

Luca Morandini
http://www.lucamorandini.it


From marcelino.delacruz at upm.es  Fri Jun  3 10:28:14 2011
From: marcelino.delacruz at upm.es (marcelino.delacruz at upm.es)
Date: Fri, 03 Jun 2011 09:28:14 +0100
Subject: [R-sig-Geo] clustering spatial point data
In-Reply-To: <4DE8641B.5000303@auckland.ac.nz>
Message-ID: <RuWYUSKi.1307089694.4134090.marcelino.delacruz@upm.es>

My less of two cents:

I  think Tal Avgar is asking for some kind of spatial-constrained
clustering tool as, e.g.,  in Legendre and Legendre (1999 Numerical
Ecology: 756-760).

Maybe function chclust  in the rioja package could  help with this
problem. It it would not, Legendre and Legendre (1999) describe very
clearly an algorithm to perfom this task that, surely, may be easily
implemented in R.

HTH,
Marcelino

Con fecha 3/6/2011, "Rolf Turner" <r.turner at auckland.ac.nz> escribi?:

>On 03/06/11 04:49, Tal Avgar wrote:
>> I am looking for a code/function/algorithm for clustering spatial point data
>> into two distinct groups, based on spatial coordinates and a measure of a
>> continuous response variable at these locations. The requirement is for
>> group members to be as similar as possible in their affiliated response
>> values but also group members must be clustered in space so that there are
>> no events belonging to one group within the space affiliated with the other.
>> Any ideas?
>> Thanks,
>> Tal.
>
>I haven't yet seen any replies to your post, so I'll chip in with my
>two cents (or less!) worth.
>
>I think you need to be more explicit/specific as to how you wish
>to form the clusters.  Clustering is usually based on some sort
>of distance measure between the points.  Your distance measure
>will need to be based both on the spatial distance between the
>points and the difference in the values of ``the continuous response
>variable''  (such a value is referred to in the trade as a numeric
>*mark*) corresponding to a given point.
>
>Once you've defined the distance measure you should be able
>to create a ``distance matrix'' and then apply standard clustering
>techniques (readily available in R) to that matrix.
>
>One very naive approach would be just to use the Euclidean distance
>between the triples (x_i, y_i, z_i) where x_i and y_i specify the point
>locations and z_i is the numeric mark of the point in question.
>
>Using Euclidean distance is almost surely *not* the right thing to do.
>However you could try it, since it would be very easy to implement,
>and see what it tells you.  You might thereby get some insight into
>how to define the distance measure properly.
>
>     cheers,
>
>         Rolf Turner
>
>_______________________________________________
>R-sig-Geo mailing list
>R-sig-Geo at r-project.org
>https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From r.hijmans at gmail.com  Fri Jun  3 18:17:06 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 3 Jun 2011 09:17:06 -0700 (PDT)
Subject: [R-sig-Geo] Methodology to compare crop maps
In-Reply-To: <455880.9586.qm@web161406.mail.bf1.yahoo.com>
References: <455880.9586.qm@web161406.mail.bf1.yahoo.com>
Message-ID: <1307117826912-6435902.post@n2.nabble.com>

> ?I am working with crops planted area maps from two distinct sources.
> One of the maps is based on a maximum NDVI composition, and the other
> map uses joint information from satellite and census to estimate the
> planted area.
>
> ?Although the sources employ different methodologies to map the area
> where the crop exists, the results should be comparable.
>
> ?After downloading the datasets, I have performed a visual inpection,
> and they show reasonable agreement. However, I need a more robust
> comparison method. Could anybody point out a methodology which allows
> me to show the difference between both maps?
>
> ?Here is an example of each one of the maps:
> http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz
> (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not
> available to download directly, but I can get it in shapefile)
>


Thiago, 

I assume that the Brazilian data has a much higher spatial resolution than
the mcgill data (that I think I am familiar with), and it probably has a
different CRS. And I assume that you can get it as a the original raster
file (and not as shapefile) for the Brazilian data. If I am not mistaken,
the mcgill data has the fraction of land area covered by a crop. I assume
that the Brazilan data is presence/absence. If so I would use the raster
package and aggregate the Brazilian data to a cell size that is similar to
the mcgill data (~9 km), computing the fraction of cells that have sugarcane
(sum divided by the number of cells, make sure to handle NA values). Then
use function projectRaster to transform the mcgill data to the same
extent/resolution as the aggregated Brazilian data. Now you have two layers
that you can compare in different ways. 

You can make plots, compute correlation, etc. Of course the p-values are no
good because of spatial autocorrelation.

library(raster)
x <- y <- raster(nc=100, nr=100)
x[] <- runif(ncell(r))
y[] <- runif(ncell(r))
plot(x, y)
m <- lm(values(x), values(y))
summary(m)
abline(m)

hist(x-y)
plot(x-y)
cor(values(x), values(y))


Perhaps you want to treat your data as presence/absence (with presence being
> 0 or some another threshold). These can then be easily compared with the
crosstab function which returns, in this case, a confusion matrix which can
be directly interpreted or used to compute some statistics from.
crosstab(x>0, y>0)

crosstab(x>0.5, y>0.5)

And there surely are many other approaches possible, which is why I think
that R is the way to go in this case: it is easy, flexible and fast.

Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Methodology-to-compare-crop-maps-tp6431598p6435902.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alobolistas at gmail.com  Fri Jun  3 18:19:56 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 3 Jun 2011 18:19:56 +0200
Subject: [R-sig-Geo] Simulated rasters?
Message-ID: <BANLkTin_CN2Rrs8_6XtaTPea0zfGAfFKWw@mail.gmail.com>

Hi!
Could raster inherit from grf objects (package feoR)?
This would be useful


From alobolistas at gmail.com  Fri Jun  3 18:36:30 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Fri, 3 Jun 2011 18:36:30 +0200
Subject: [R-sig-Geo] simulated rasters?
Message-ID: <BANLkTimfXfmwHKmJ4-s8UjS278EK1D-f_Q@mail.gmail.com>

Hi!

Could raster inherit from grf objects (package geoR)?
It would be useful to generate simulated raster fields.Or perhpas is there
a way of doing this with another package?
> sim <- grf(441, grid="reg", cov.pars=c(1, .25), nsim=4)
> simr = raster(sim)
Error in function (classes, fdef, mtable)  :
  unable to find an inherited method for function "raster", for signature "grf"

By now I use
> a = (sim$data)
> dim(a) <- c(21,21)
> simr = raster(t(a)[21:1,])

Thanks,

Agus


From r.hijmans at gmail.com  Fri Jun  3 19:42:02 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 3 Jun 2011 10:42:02 -0700
Subject: [R-sig-Geo] simulated rasters?
In-Reply-To: <BANLkTimfXfmwHKmJ4-s8UjS278EK1D-f_Q@mail.gmail.com>
References: <BANLkTimfXfmwHKmJ4-s8UjS278EK1D-f_Q@mail.gmail.com>
Message-ID: <BANLkTinYhhCZ5pugJmZG4uZF=NdW-tRnrQ@mail.gmail.com>

Hi Agus,

I have implemented a similar function in raster version 1.8-31, such
that you can coerce from grf to Raster* objects

library(geoR)
library(raster)
sim <- grf(441, grid="reg", cov.pars=c(1, .25), nsim=4)
b <- brick(sim)
# or
x <- as(b, 'RasterBrick')

# and
r <- raster(sim)
r <- raster(sim, 2)

Not much tested or optimized, obviously.

Best,
Robert



On Fri, Jun 3, 2011 at 9:36 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> Could raster inherit from grf objects (package geoR)?
> It would be useful to generate simulated raster fields.Or perhpas is there
> a way of doing this with another package?
>> sim <- grf(441, grid="reg", cov.pars=c(1, .25), nsim=4)
>> simr = raster(sim)
> Error in function (classes, fdef, mtable) ?:
> ?unable to find an inherited method for function "raster", for signature "grf"
>
> By now I use
>> a = (sim$data)
>> dim(a) <- c(21,21)
>> simr = raster(t(a)[21:1,])
>
> Thanks,
>
> Agus
>


From kadraamrane at hotmail.fr  Sat Jun  4 04:01:57 2011
From: kadraamrane at hotmail.fr (kad)
Date: Fri, 3 Jun 2011 19:01:57 -0700 (PDT)
Subject: [R-sig-Geo] 70 conseils pour etre un bon musulman
In-Reply-To: <4C619BD0.3040906@uni-muenster.de>
References: <1281445567867-5392938.post@n2.nabble.com>
	<4C61537D.2020203@uni-muenster.de>
	<1281452987970-5393442.post@n2.nabble.com>
	<4C619BD0.3040906@uni-muenster.de>
Message-ID: <DUB105-w59059CA3E95EE94550EFF3D37E0@phx.gbl>




1)N'oublies jamais que tu n'es qu'une faible cr?ature.

2)Choisis tes amis parmi les meilleurs des musulmans, tu en tireras profit et ne cherches pas la compagnie du p?cheur car tu apprendras ? p?cher comme lui.

3)Visites ta famille, ?cris ou t?l?phones ? ceux qui sont loin.

4)M?dites sur la cr?ation de Dieu.

5)Sois comme la pluie, l? o? elle passe c'est frais et propre.

6)Rappelles-toi de ton Cr?ateur en lui ob?issant.

7)Fermes la porte au diable, ne le laisses pas se jouer de toi.

8)Le soir en te couchant, aie l'intention de rechercher le repos afin d'?tre dispos pour les adorations du lendemain.

9)Le matin en te levant, dis-toi voil? une nouvelle journ?e pour oeuvrer dans le bien et ?vites le mal.


10)Le mariage apporte le soutien, ne sois pas la cause d'une s?paration car tu te retrouveras seul.

11)Invoques Dieu pour ton ami, comme tu aimes invoquer Dieu pour toi.

12)Ne regardes pas les filles dans la rue (pour les gar?ons), ne regardes pas les gar?ons dans la rue (pour les filles).

13)Ne sois pas vulgaire, restes poli, chaste et r?serv?.

14)Penses ? te corriger et ? faire des efforts.

15)Apprends les obligations et attaches-y toi, apprends les interdits et d?taches-en toi.

16)Ne parles pas trop de ce qui n'apporte point de r?compenses.

17)Ne te mets pas en col?re, contr?les-toi.

18)Ne profites pas de l'amiti? qui s'ouvre ? toi.

19)Ne dors pas plus de sept heures.

20)Ne manges pas jusqu'? n'en plus pouvoir, ne gaspilles point.

21)Ne te plains pas de ce qui n'est pas un droit sur toi et ?loignes toi de ce qui ne te concerne pas.

22)N'oublies pas ta m?re, elle t'a port? et s'est occup?e de toi.

23)Acceptes le conseil, peu importe comment et qui te le donne.

24)R?vises tes cours, relis-les plusieurs fois.

25)Notes tes questions et tes r?ponses, la science c'est l'?criture qui l'attache.

26)Ne restes pas isol? des fr?res et des soeurs, sinon c'est le diable qui sera le plus souvent avec toi.

27)Fais provisions pour demain, mais sache que la meilleure est la pi?t?.

28)N'oublies pas que tu es pris pour exemple, alors crains Dieu en public comme en secret

29)Pardonnes aux autres et ne garde pas ne serait-ce qu'une graine de rancune ou de haine dans ton coeur.

30)Pers?v?res dans la pri?re, fais-la du mieux que tu le peux, dans le calme et sans te pr?cipiter en consid?rant que c'est la pri?re d'adieu.

31)Restes souriant, ne fais pas de mal autour de toi.

32)Sois g?n?reux et ne sois pas avare.

33)Rappelles-toi de l'Enfer et fuis ce qui fait y rentrer et rappelles-toi du Paradis et fais ce qui fait y rentrer.

34)Remercies Dieu pour les bienfaits qu'Il t'a donn?s.

35)Patientes durant les ?preuves, cela fortifiera ton coeur.

36)Apprends la science obligatoire avant tout et applique-la.

37)N'oublies pas de d?fendre la religion de Dieu.

38)Utilises le siwak et manges de la main droite car ceci est sounnah (recommand?).

39)D?barrasses-toi de tout ce qui est mauvais en toi et sois indiff?rent aussi bien envers l'?loge que le mal des gens.

40)Trouves des excuses ? ton conjoint et ? tes amis, certes ceci est pr?f?rable ? la querelle qui fait partir l'amour des coeurs.

41)Le bon comportement apporte l'union et la solidarit? alors que le mauvais comportement engendre les s?parations et les ennemis.

42)Passes souvent le Salam au Proph?te.

43)Ne perds pas ton temps car il est plus pr?cieux que l'or et l'argent.

44)Loin des soucis de ce monde, pleures sur tes p?ch?s et inqui?tes-toi de ne pas savoir dans quel ?tat tu vas mourir.

45)Repens-toi, ceci est chose facile: c'est une seconde chance.

46)Ne fais pas de mal, l'amiti? ne s'ach?te pas.

47)Invoques souvent ton Cr?ateur, Il est l'Entendant, Le Voyant.

48)Piques-toi si tu t'enorgueillis, le fort c'est celui qui se ma?trise, et reste bon pratiquant.

49)Envers les plus ?g?s des musulmans sois respectueux, envers les plus petits sois cl?ment.

50)Le p?lerinage est une obligation, fais des ?conomies.

51)Apprends le minimum obligatoire, fais-toi corriger puis deviens ? ton tour enseignant.

52)Sois modeste, d?laisse la fiert? et la pr?tention.

53)Laisses le surplus de ce bas monde car tu ne pourras rien amener avec toi.

54)Ne te pr?cipites pas et agis avec prudence.

55)Penses ? la mort, ? ton tour tu seras lav?, mis dans un linceul et enterr?.

56)Sois sinc?re dans les actes de bien.

57)Prends exemple sur les compagnons, suis-les comme ils ont suivi le meilleur des guides, notre bien-aim? le Proph?te Muhammad.

58)Tires des le?ons des histoires que tu ?coutes.

59)Ne parles pas de tes fr?res et s?urs en mal.

60)Le Paradis est une v?rit? et l'Enfer est une v?rit?, l'un des deux sera ta future demeure.

61)Tu as une raison, sers-toi en comme il se doit.

62)Trop rire fait mourir le c?ur.

63)Que ton silence soit m?ditation, que ta parole soit invocation et que ton regard te serve de le?on.

64)Ne cries pas et n'?l?ves pas la voix sur ton interlocuteur.

65)Cesses de te plaindre, ceci n'est pas l'habitude des saints et confies tes probl?mes ? Dieu.

66)D?taches-toi du luxe et satisfais-toi de peu.

67)L'homme n'est pas celui qui r?unit les gens autour de lui mais c'est celui qui r?unit les gens dans l'ob?issance ? Dieu.

68)Le fort n'est pas celui qui vainc les gens mais c'est celui qui ?touffe sa col?re alors qu'il peut l'exercer.

69)Juges-toi avant d'?tre jug? et chaque soir fais un bilan de ta journ?e.

70)Un jour tu seras descendu dans l'obscurit? et la solitude de la tombe malgr? toi, alors d?sob?is au diable et ? ton ego. 



????? ?????? ??????? ?????? ??????? ??????? ?????? ??????? ???????? ??? ??? ??? ?? ????? !! ???.. ? ??? ??

 		 	   		  

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Error-autoKrige-tp5392938p6438017.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Adrian.Baddeley at csiro.au  Sat Jun  4 12:40:08 2011
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Sat, 4 Jun 2011 18:40:08 +0800
Subject: [R-sig-Geo]  pixellate.owin when "owin" contains separate,
 overlapping polygons
Message-ID: <57DC18C299094D4299F837570C5DF1C53AAA303C18@EXWA-MBX01.nexus.csiro.au>

Robin W Hunnewell rhunne at mac.com wrote:

> I've used pixellate.owin() to convert an object of class "owin" to a pixel image -- the owin in question is 
> unusual in that it contains multiple, overlapping polygons.

This is  a question about the 'spatstat' package.

Out of curiosity - How did you create such an object? The code should refuse to create it, unless you switched off the error checking.... Overlapping polygons violate the requirements of the owin class, and this will cause trouble sooner or later. 

> Now I'd like to change (constrict) the frame area of a resulting "im" object by assigning 
> a different and smaller window to it, using pixellate.owin 

pixellate.owin is not designed to do that. 
The argument 'W' to pixellate.owin is mainly intended as a way of controlling pixel resolution. It is meant to define a pixel raster. The raster must be large enough to contain the original window.

To do what you want, first convert your window to an 'im' object using pixellate.owin (without the 'W' argument), and then trim it to a smaller window using "[.im" as follows (where 'Depth' is your original window and 'ConvexW3' is the desired subwindow)

       A <- pixellate(Depth)
       B <- A[ConvexW3, drop=FALSE]
       C <- B[as.rectangle(ConvexW3)]

Line 2 sets all pixels outside the window 'ConvexW3' to NA. It is needed only if 'ConvexW3' is not a rectangle; it's redundant if 'ConvexW3' is a rectangle. 
Line 3 trims the pixel raster to the smallest valid rectangle.

To control the pixel resolution, for example if you want pixels to have size 'eps', replace line 1 by 

       A <- pixellate(Depth, eps=eps)

Adrian Baddeley

From sadz_a1000 at yahoo.co.uk  Sat Jun  4 13:34:11 2011
From: sadz_a1000 at yahoo.co.uk (Sadz A)
Date: Sat, 4 Jun 2011 12:34:11 +0100 (BST)
Subject: [R-sig-Geo] Neighbor stats by polygon
Message-ID: <306482.37595.qm@web24614.mail.ird.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110604/28b06e05/attachment.pl>

From rhunne at mac.com  Sat Jun  4 16:38:44 2011
From: rhunne at mac.com (Robin W Hunnewell)
Date: Sat, 04 Jun 2011 14:38:44 +0000 (GMT)
Subject: [R-sig-Geo] pixellate.owin when "owin" contains separate,
 overlapping polygons
In-Reply-To: <57DC18C299094D4299F837570C5DF1C53AAA303C18@EXWA-MBX01.nexus.csiro.au>
Message-ID: <d6e0518f-6f3a-46e8-df27-ea0c30043639@me.com>

Thank you! ?I see how this works better now..?

To answer your query on how I created such an object, it's as?you guessed -- to get around violating the code when spatstat.options(checkpolygons=TRUE), which would give error message ?"Error in owin(poly = opls) : ?Polygon data contain overlaps between polygons,"?
I temporarily set it to FALSE in order that my garbled polygon data would be accepted, as least for now!?

I'm not planning to assign such a garbled window to my point pattern data; for that I have a normal, single-poly window.?

But I am seeking a way to generate a smooth estimate of a set of spatially varying occurrences -- the?population of survey flights that went on within the boundary of that overall single-poly window. ?Idea was to address this as a key spatial covariate underlying the distribution of all my points... hope that makes sense.

Thanks so much for the help!
Robin


On 04 Jun, 2011,at 07:40 AM, Adrian.Baddeley at csiro.au wrote:

Robin W Hunnewell rhunne at mac.com wrote:

> I've used pixellate.owin() to convert an object of class "owin" to a pixel image -- the owin in question is 
> unusual in that it contains multiple, overlapping polygons.

This is a question about the 'spatstat' package.

Out of curiosity - How did you create such an object? The code should refuse to create it, unless you switched off the error checking.... Overlapping polygons violate the requirements of the owin class, and this will cause trouble sooner or later. 

> Now I'd like to change (constrict) the frame area of a resulting "im" object by assigning 
> a different and smaller window to it, using pixellate.owin 

pixellate.owin is not designed to do that. 
The argument 'W' to pixellate.owin is mainly intended as a way of controlling pixel resolution. It is meant to define a pixel raster. The raster must be large enough to contain the original window.

To do what you want, first convert your window to an 'im' object using pixellate.owin (without the 'W' argument), and then trim it to a smaller window using "[.im" as follows (where 'Depth' is your original window and 'ConvexW3' is the desired subwindow)

A <- pixellate(Depth)
B <- A[ConvexW3, drop=FALSE]
C <- B[as.rectangle(ConvexW3)]

Line 2 sets all pixels outside the window 'ConvexW3' to NA. It is needed only if 'ConvexW3' is not a rectangle; it's redundant if 'ConvexW3' is a rectangle. 
Line 3 trims the pixel raster to the smallest valid rectangle.

To control the pixel resolution, for example if you want pixels to have size 'eps', replace line 1 by 

A <- pixellate(Depth, eps=eps)

Adrian Baddeley
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110604/b3664248/attachment.html>

From bymanh at gmail.com  Sun Jun  5 12:22:45 2011
From: bymanh at gmail.com (Byman)
Date: Sun, 05 Jun 2011 12:22:45 +0200
Subject: [R-sig-Geo] Raster - zonal statistics -zones are not matching the
	mask?
Message-ID: <4DEB58F5.3040909@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110605/1491cad0/attachment.pl>

From Tobias.Reiners at bio.uni-giessen.de  Sun Jun  5 15:24:53 2011
From: Tobias.Reiners at bio.uni-giessen.de (Tobias Erik Reiners)
Date: Sun, 05 Jun 2011 15:24:53 +0200
Subject: [R-sig-Geo] Comparing euclidean distances between point groups in
	space andtime
In-Reply-To: <d6e0518f-6f3a-46e8-df27-ea0c30043639@me.com>
References: <d6e0518f-6f3a-46e8-df27-ea0c30043639@me.com>
Message-ID: <20110605152453.45865ljrtxlrf4kc@webmail.stud.uni-giessen.de>

Dear all,

i have a question concerning comparing the distances between groups of points.
task:
1. I have 4 groups of points. (a) male and (b)female shelter with  
hunting location for each (c)(d).
2. I have three seasons each with the 4 sets of points from 1 having  
12 pointssets in the end.

I already did distance analysis comparing the distances of each group  
in each season. Quite a lot comparisons (a-b;a-c;a-d..c-d). I got a  
nice change in distances between the seasons and strong differences  
for each group.

One Critism on this analysis was that I have a lot of points twice in  
my comparisons and assumptions of tests are violated because points  
occur twice.
They told me to use non-parametric multivariate analysis of variance  
with the adonis() function in the package vegan.

in short
adonis(distancematrix~gender*season)

How can I achieve having all comparison in one flat table and how to  
can I code my gender and season. I got the impression that I violate  
even more statistical assumtions when doing it that way.

Thanks for any help
-- 
Tobias Erik Reiners
Mammalian Ecology Group

Justus-Liebig-University
IFZ - Department of Animal Ecology
Heinrich-Buff-Ring 26
D-35392 Giessen
Germany

Phone:        +49 (0) 641 / 99 - 35761
Fax.:         +49 (0) 641 / 99 - 35709


From muenchen at utk.edu  Sun Jun  5 16:14:50 2011
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Sun, 5 Jun 2011 14:14:50 +0000
Subject: [R-sig-Geo] Example country data to plot
Message-ID: <81D92650D162664791CB7C482A8784121340336E@kmbx1.utk.tennessee.edu>

Hi All,

I'm looking for a data set of miscellaneous country measures like population, education, crime, etc. The particular variables aren't that important. I'll use the data for maps and non-spatial plots such as bar plots, scatter plots, etc. If all goes well it'll end up in a book, so I either need to be able to distribute the data or (much better) simply point to a data frame in an R package already on CRAN if I can find one. 

The UN Data at http://data.un.org/Explorer.aspx?d=UNESCO provides plenty of variables that would work and it's re-distributable, but each topic is in a separate file and in a slightly different format making a merger a fair amount of work. Does anyone know of an existing file I can use?

Thanks,
Bob

http://r4stats.com 


From landis at isciences.com  Mon Jun  6 03:35:56 2011
From: landis at isciences.com (Matthew Landis)
Date: Sun, 5 Jun 2011 21:35:56 -0400
Subject: [R-sig-Geo] Example country data to plot
In-Reply-To: <81D92650D162664791CB7C482A8784121340336E@kmbx1.utk.tennessee.edu>
References: <81D92650D162664791CB7C482A8784121340336E@kmbx1.utk.tennessee.edu>
Message-ID: <1D6E496F-69EA-47FF-AD47-537229B9FC35@isciences.com>

Try the World Development Indicators from the World Bank.  You can  
download the whole thing as a giant CSV file without too much trouble  
and there are hundreds of variables at the national scale.

Sent from my iPod -- that's why it's short and misspelled.


On Jun 5, 2011, at 10:14 AM, "Muenchen, Robert A (Bob)" <muenchen at utk.edu 
 > wrote:

> Hi All,
>
> I'm looking for a data set of miscellaneous country measures like  
> population, education, crime, etc. The particular variables aren't  
> that important. I'll use the data for maps and non-spatial plots  
> such as bar plots, scatter plots, etc. If all goes well it'll end up  
> in a book, so I either need to be able to distribute the data or  
> (much better) simply point to a data frame in an R package already  
> on CRAN if I can find one.
>
> The UN Data at http://data.un.org/Explorer.aspx?d=UNESCO provides  
> plenty of variables that would work and it's re-distributable, but  
> each topic is in a separate file and in a slightly different format  
> making a merger a fair amount of work. Does anyone know of an  
> existing file I can use?
>
> Thanks,
> Bob
>
> http://r4stats.com
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From brwin338 at aol.com  Mon Jun  6 06:21:36 2011
From: brwin338 at aol.com (brwin338)
Date: Mon, 6 Jun 2011 00:21:36 -0400
Subject: [R-sig-Geo] converting between SpatialPolygonsDataFrame polygons
	and gpc.poly objects
Message-ID: <8CDF2185C1B8878-C44-33640@webmail-m161.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110606/22d272a5/attachment.pl>

From research at georgruss.de  Sun Jun  5 19:42:36 2011
From: research at georgruss.de (Georg =?iso-8859-15?B?UnXf?=)
Date: Sun, 5 Jun 2011 19:42:36 +0200
Subject: [R-sig-Geo] clustering spatial point data
In-Reply-To: <002c01cc2145$01e3d430$05ab7c90$@ca>
References: <002c01cc2145$01e3d430$05ab7c90$@ca>
Message-ID: <20110605174236.GA4857@greode.iws.cs.uni-magdeburg.de>

On 02/06/11 12:49:15, Tal Avgar wrote:
> I am looking for a code/function/algorithm for clustering spatial point data
> into two distinct groups, based on spatial coordinates and a measure of a
> continuous response variable at these locations. The requirement is for
> group members to be as similar as possible in their affiliated response
> values but also group members must be clustered in space so that there are
> no events belonging to one group within the space affiliated with the other.
> Any ideas?
> Thanks,
> Tal.

Hi Tal,

I think that the HACC-spatial algorithm which I've developed may turn out
to be of interest to you. I'm using that for management zone delineation 
on precision agriculture data sets which are structurally the same as
yours, i.e. a spatialpoints data frame, I guess.

The idea of HACC-spatial is rather simple: it's a hierarchically
agglomerative constrained clustering procedure, where the constraint (for
me) is spatial contiguity, i.e. the resulting clusters (or zones) should
be mostly contiguous. The trick is to proceed as in standard hierarchical
clustering but to only consider geospatially adjacent points/clusters for
merging. You may even be able to keep this constraint throughout your
algorithm, while I had to switch off the constraint at some point during
the clustering algorithm.

The similarity of points is based on Euclidean distance (or any other
distance measure), the spatial distance is Euclidean, too. The algorithm
starts with generating a distance matrix for the spatial points using
"dist", then it looks for the most similar points (which are allowed to be
merged), merges those points into a cluster and updates the distance
matrix accordingly. The average linkage criterion is used for determining
the similarity of clusters.

You may have a look at the most recent version I've published here:
http://fuzzy.cs.uni-magdeburg.de/aigaion/index.php/publications/show/793
Maybe this helps. It's easy to implement in R. It could probably be
implemented in C or something quicker and then run within R, but I
currently don't have the time to do that. It's likely to be 50% of my PhD
thesis.

Regards,
Georg.


From mathieu.rajerison at gmail.com  Mon Jun  6 10:01:08 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 6 Jun 2011 10:01:08 +0200
Subject: [R-sig-Geo] Neighbor stats by polygon
In-Reply-To: <306482.37595.qm@web24614.mail.ird.yahoo.com>
References: <306482.37595.qm@web24614.mail.ird.yahoo.com>
Message-ID: <BANLkTimFc_5rR6EzOYsU1Kkc2jqv2GAxwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110606/38760181/attachment.pl>

From Roger.Bivand at nhh.no  Mon Jun  6 10:59:17 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 6 Jun 2011 10:59:17 +0200
Subject: [R-sig-Geo] converting between SpatialPolygonsDataFrame
 polygons and gpc.poly objects
In-Reply-To: <8CDF2185C1B8878-C44-33640@webmail-m161.sysops.aol.com>
References: <8CDF2185C1B8878-C44-33640@webmail-m161.sysops.aol.com>
Message-ID: <alpine.LRH.2.00.1106061056160.10222@reclus.nhh.no>

On Mon, 6 Jun 2011, brwin338 wrote:

>
> Good Evening
> I have spent a good deal of time reading the list and the book "Applied Spatial Data Analysis with R" and as well as trying to figure this one out but can't quite seem to get it.
> I would appreciate it greatly if someone could direct me to a site (or send me an example) describing how I could do the following:
>
> (1) I have a SpatialPolygonDataFrame (SPDF) object.
> (2) I want to convert the SPDF object's polygons into a list of gpc.poly objects.
> (3) I then perform a set of operations on the list of gpc.poly objects (this one works fine with a set of artificial data) giving me a second list of gpc.poly objects.
> (4) I then want to convert the second list of gpc.poly objects back into a SPDF object where I can then add information into the the new SPDF at data data frame.
>
> Any help would be appreciated.

Briefly, don't. The gpclib package has a bad license, and should be 
avoided. Apart from triangle splitting of polygons, everything that gpclib 
does can be done in rgeos, which additionally provides SPDF/gpc.poly 
interfaces and mimics gpclib code if you need to use that syntax 
(internally it converts back to SPDF). So, please use rgeos, not gpclib.

Roger

>
> Joe
>
>
>
> .
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From martin_brandt at gmx.net  Mon Jun  6 14:32:45 2011
From: martin_brandt at gmx.net (Martin)
Date: Mon, 6 Jun 2011 05:32:45 -0700 (PDT)
Subject: [R-sig-Geo] spatial time series
Message-ID: <1307363565755-6444907.post@n2.nabble.com>

Dear list,

I have some rasters, respresentig a time series (let's say 5 years and 24
rasters for each year). The rasters are in a raster stack or a
SpatialGridDataframe, whatever is better.

Now I want to do some time series analysis which call for a ts class object.


# I have a brick called gimms with 144 layers:

gimms=brick(b)

# I summarize the cell values and create a time series:
 
s=cellStats(gimms, stat='mean')
gimms.ts = ts(s, start=c(2001,1), end=c(2006,24), frequency=24)


# I do some decomposition. The final result is the slope of a regression of
the decomp. trend and the time: 

gimms2.decomp = decompose(gimms.ts, type="multi")
gimms.trend = gimms2.decomp$trend

gimms.new = time(gimms.ts)
x = lm(gimms.trend ~ gimms.new)

summary(x)$coefficients[2]


Now what I want to do is to do the same with every single pixel and get a
gridded result. What is the best appoach to start with? Is there a way to
create a time series with my brick or SpatialGidDataframe? Beside this
example there are also other things I want to do with my rasters which call
for a "ts" class object, but I don't know where to start and I'd be thankful
for any hints...

best wishes,
Martin



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatial-time-series-tp6444907p6444907.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Mon Jun  6 18:07:47 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Mon, 6 Jun 2011 09:07:47 -0700
Subject: [R-sig-Geo] Raster - zonal statistics -zones are not matching
	the mask?
In-Reply-To: <4DEB58F5.3040909@gmail.com>
References: <4DEB58F5.3040909@gmail.com>
Message-ID: <BANLkTikttKiTAKAFsQ8ECgLmYBbwLEKWBg@mail.gmail.com>

Byman,

I suspect that raster cell sizes are large relative to some of the
polygons (small island states), and that not all polygons cover at
least one raster cell. You can check that with:

um <- unique(msk)
length(um)

# what you are doing can be done more directly, I think, like this:

library(raster)
world <- readShapePoly("world.shp", proj4string=CRS("+proj=longlat"))
bdat <- brick("global.obs.Prcp.1950-1999.nc",varname="Prcp")

msk <- rasterize(world, bdat)
zst <- zonal(bdat, msk, stat='median')

# and now perhaps this?
zst[,2:ncol(zst)] <- zst[,2:ncol(zst)] * 12 * 30


# to deal with the missing values, you can do something like this
x <- data.frame(zone=1:480)
zst2 <- merge(x, zst, by='zone', all.x=T)

world at data <- cbind(world at data, zst2[,-1])

# To insist in getting a value for the small countries, you can do
this, with a recent version of raster
# (but this is much slower than zonal)

x <- extract(bdat, world, fun=median, small=TRUE)

Best, Robert


On Sun, Jun 5, 2011 at 3:22 AM, Byman <bymanh at gmail.com> wrote:
> Hi
>
> I am computing average values on country /state basis globally. I am using
> raster package in R to compute the zonal values &? I read a shape file from
> ArcGIS in R also. Here is my short process i used. I am not able to get the
> zones to match the polygon in the mask.....
>
> ??? world<-readShapePoly("world.shp", proj4string=CRS("+proj=longlat"))
>
> bdat<-brick("global.obs.Prcp.1950-1999.nc",varname="Prcp")
> # read the NetCDF file uisng raster package
> ??? ras<-raster(ncol=bdat at ncols,nrow=bdat at nrows)
> ??? ??? ??? ??? ??? #create mask with same attributes with raster
> ??? ras[]<-1
> ??? extent(ras)<-extent(world)
> ??? msk <- rasterize(world, ras)
> ??? bdat <- mask(bdat, msk)
>
> zst<-zonal(bdat*12*30,msk,stat='median')
> #Compute the zonal statistics
>
> The shape file has 480 polygons and I expect to get the same number of zones
> but to my surprise I get 337 zones..? As such I cannot map back/assign the
> results of the zonal function to the object in order to plot. The mask (msk)
> has the 480 zones but after the step I get different number of zones. What
> am I missing here.
>
> world$zonal = zst
>
> Error in `[[<-.data.frame`(`*tmp*`, name, value = list(zone = c(3, 4,? :
> ? replacement has 337 rows, data has 480
>
> I have not supplied the files but I can do so.
>
> Thank you in advance for suggested solutions
>
> rgds
> Byman
>


From Andy.Bunn at wwu.edu  Mon Jun  6 18:31:06 2011
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Mon, 6 Jun 2011 16:31:06 +0000
Subject: [R-sig-Geo] spatial time series
References: <1307363565755-6444907.post@n2.nabble.com> 
Message-ID: <9B597DE5AF080D418509A7E9F1E93EAF0207B4BE@Exch2010MB-3.univ.dir.wwu.edu>

> > Now what I want to do is to do the same with every single pixel and
> get
> > a
> > gridded result. What is the best appoach to start with? Is there a
> way
> > to
> > create a time series with my brick or SpatialGidDataframe? Beside
> this
> > example there are also other things I want to do with my rasters
> which
> > call
> > for a "ts" class object, but I don't know where to start and I'd be
> > thankful
> > for any hints...
> >
> 
When I have to do this kind of thing I take my stack and turn it into
an array. Then I write a function to do what I want and apply that
function over the array. Then remake the raster. Something like:

    bar <- as.array(my.raster.stack)
    foo <- apply(bar,c(1,2),function(x) {
        stuff(x)
        })
    foo <- raster(foo)
    extent(foo) <- extent(my.raster.stack)
    projection(foo) <- projection(my.raster.stack)

I'm sure there are other/better ways but this works pretty well for
what I do.


From r.hijmans at gmail.com  Mon Jun  6 21:34:59 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 6 Jun 2011 12:34:59 -0700 (PDT)
Subject: [R-sig-Geo] spatial time series
In-Reply-To: <1307363565755-6444907.post@n2.nabble.com>
References: <1307363565755-6444907.post@n2.nabble.com>
Message-ID: <1307388899863-6446630.post@n2.nabble.com>

> I have some rasters, respresentig a time series (let's say 5 years and 24
rasters for each year). The rasters are in a
> raster stack or a SpatialGridDataframe, whatever is better. 
> Now I want to do some time series analysis which call for a ts class
> object. 
> ...
> Now what I want to do is to do the same with every single pixel and get a
> gridded result. 

Martin, Here is an approach using the 'raster' function 'calc' . Robert

library(raster)
# creating a RasterStack with 144 layers: 
r <- raster(nc=10, nr=10)
gimms <- stack(lapply(1:144, function(x) setValues(r, runif(ncell(r)))))

tsfun <- function(x) {  
	gimms.ts = ts(x, start=c(2001,1), end=c(2006,24), frequency=24) 
	gimms2.decomp = decompose(gimms.ts, type="multi") 
	gimms.trend = gimms2.decomp$trend 
	gimms.new = time(gimms.ts) 
	x = lm(gimms.trend ~ gimms.new) 
	summary(x)$coefficients[2] 
}

res <- calc(gimms, fun=tsfun)

plot(res)
res


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatial-time-series-tp6444907p6446630.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alfreale74 at gmail.com  Tue Jun  7 15:09:00 2011
From: alfreale74 at gmail.com (Alfredo Alessandrini)
Date: Tue, 7 Jun 2011 15:09:00 +0200
Subject: [R-sig-Geo] replace NA with closest value
Message-ID: <BANLkTikjJOHYZVku4b52J=cMeYQNYO1vPg@mail.gmail.com>

Hi,

I need to write a function to use with calc (raster package) that
replace the NA value of the raster with the value closest to it.

Any suggestion on how to write it?


thanks,

Alfredo


From martin_brandt at gmx.net  Tue Jun  7 15:35:08 2011
From: martin_brandt at gmx.net (Martin)
Date: Tue, 7 Jun 2011 06:35:08 -0700 (PDT)
Subject: [R-sig-Geo] spatial time series
In-Reply-To: <1307388899863-6446630.post@n2.nabble.com>
References: <1307363565755-6444907.post@n2.nabble.com>
	<1307388899863-6446630.post@n2.nabble.com>
Message-ID: <1307453708369-6449592.post@n2.nabble.com>

thanks a lot for both tips!
Robert, slowly but surely I understand the functionality of the calc
functions :-)
this opens endless possibilities... 



--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/spatial-time-series-tp6444907p6449592.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Raphael.Viscarra-Rossel at csiro.au  Tue Jun  7 15:41:15 2011
From: Raphael.Viscarra-Rossel at csiro.au (Raphael.Viscarra-Rossel at csiro.au)
Date: Tue, 7 Jun 2011 23:41:15 +1000
Subject: [R-sig-Geo] moving average along transects
In-Reply-To: <BANLkTikjJOHYZVku4b52J=cMeYQNYO1vPg@mail.gmail.com>
Message-ID: <CA1464FA.3274%raphael.viscarra-rossel@csiro.au>

Hello

I have a spatial dataset that is made up of 60 transects (of different lengths and not all are straight) across a large area and I want to filter the data along each transect using moving averages.

The data is in a SpatialPointsDataframe with 30,000 obs (rows) and 50 variables (cols). There are no Ids for the transects?although it would not be hard to add them?

I would like to filter the data from each of the 50 variables along these transects.

There are no IDs for the transects and each transect can only be identified by their coordinates.

Any ideas on how I might do this will be appreciated?

Best wishes

Raphael



_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From matteo.mattiuzzi at boku.ac.at  Tue Jun  7 17:26:39 2011
From: matteo.mattiuzzi at boku.ac.at (Matteo Mattiuzzi)
Date: Tue, 07 Jun 2011 17:26:39 +0200
Subject: [R-sig-Geo] Antw:  replace NA with closest value
In-Reply-To: <BANLkTikjJOHYZVku4b52J=cMeYQNYO1vPg@mail.gmail.com>
References: <BANLkTikjJOHYZVku4b52J=cMeYQNYO1vPg@mail.gmail.com>
Message-ID: <4DEE5F4F020000270000EE34@gwia2.boku.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110607/ba82ccea/attachment.pl>

From mathieu.rajerison at gmail.com  Tue Jun  7 18:13:16 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 7 Jun 2011 18:13:16 +0200
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
Message-ID: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110607/1a7ea21c/attachment.pl>

From roman.lustrik at gmail.com  Tue Jun  7 18:19:52 2011
From: roman.lustrik at gmail.com (=?UTF-8?Q?Roman_Lu=C5=A1trik?=)
Date: Tue, 7 Jun 2011 18:19:52 +0200
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
Message-ID: <BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110607/670928dd/attachment.pl>

From mattias at norrasverige.se  Tue Jun  7 18:56:39 2011
From: mattias at norrasverige.se (newmat)
Date: Tue, 7 Jun 2011 09:56:39 -0700 (PDT)
Subject: [R-sig-Geo] writeRaster give error "no slot of name "file" for this
	object..."
Message-ID: <1307465799277-6450479.post@n2.nabble.com>

I'm using the raster-package in R. I have problem writing an RasterStack to a
multi-band tif-file. I provide an example code below that is
self-explaining. I receive the following error on the last row, using
writeRaster:
Error in attr(x at file, "transient") <- temp[[1]] : 
  no slot of name "file" for this object of class "RasterStack"

Can it be because my rasterLayers and rasterStack are "inMemory"?

rExtent <- extent(664300,665800,7585000,7586400)
rasterTemplate <- raster(rExtent, 140, 150, crs=NA) rLayers <- list() for(i
in 1:64) { rLayers[[i]] <- raster(rasterTemplate)
values(rLayers[[i]]) <- runif(ncell(rasterTemplate), min=0, max=10) }

rStack <- stack(rLayers)

writeRaster(rStack, "test.tif", overwrite=TRUE)


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-give-error-no-slot-of-name-file-for-this-object-tp6450479p6450479.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mathieu.rajerison at gmail.com  Tue Jun  7 19:00:07 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Tue, 7 Jun 2011 19:00:07 +0200
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
Message-ID: <BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110607/3133dd79/attachment.pl>

From r.hijmans at gmail.com  Tue Jun  7 19:49:34 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Tue, 7 Jun 2011 10:49:34 -0700 (PDT)
Subject: [R-sig-Geo] writeRaster give error "no slot of name "file" for
 this object..."
In-Reply-To: <1307465799277-6450479.post@n2.nabble.com>
References: <1307465799277-6450479.post@n2.nabble.com>
Message-ID: <1307468974241-6450713.post@n2.nabble.com>

> I'm using the raster-package in R. I have problem writing an RasterStack to
a multi-band tif-file.
> Error in attr(x at file, "transient") <- temp[[1]] : 
>   no slot of name "file" for this object of class "RasterStack" 

I believe this is a bug that has been fixed. Can you try again after
updating the raster package from CRAN? 
(and please include the result of sessionInfo() when reporting this type of
trouble).
Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-give-error-no-slot-of-name-file-for-this-object-tp6450479p6450713.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From rundel at gmail.com  Tue Jun  7 19:53:04 2011
From: rundel at gmail.com (Colin Rundel)
Date: Tue, 7 Jun 2011 10:53:04 -0700
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
Message-ID: <E9AA27D3-35AA-4A14-8A59-F9239C33E494@gmail.com>

This message is occuring because the geos library (that rgeos is based on) needs to know which holes belong to which polygons which is something that sp objects don't indicate natively. rgeos includes a simple algorithm that attempts to identify which holes belong to which polygons but there are plenty of edge cases that it wont work for. If the shapefile is something that you can share, post it somewhere and provide a link and we can take a look at the polygons to see what is going wrong.

-Colin


On Jun 7, 2011, at 10:00 AM, Mathieu Rajerison wrote:

> Thanks for the answer!
> 
> I think I surely have to use gIntersection then gLength for this purpose
> 
> I've tried gIntersection like this:
> routes2 = gIntersection(routes, bdc)
> 
> But I get the following message:
> Erreur dans createPolygonsComment(p) :
>  rgeos_PolyCreateComment: orphaned hole, cannot find containing polygon for
> hole at index 1
> 
> Do you have an idea why I get this message and how to correct it?
> 
> 
> 
> 2011/6/7 Roman Lu?trik <roman.lustrik at gmail.com>
> 
>> Package rgeos has all sorts of functions that might come handy.
>> 
>> Cheers,
>> Roman
>> 
>> 
>> 
>> On Tue, Jun 7, 2011 at 6:13 PM, Mathieu Rajerison <
>> mathieu.rajerison at gmail.com> wrote:
>> 
>>> Hi,
>>> 
>>> 
>>> I have a SpatialLines object representing roads and a SpatialPolygons
>>> object
>>> containing cities.
>>> 
>>> I'd like to know how to overlay a SpatialLines object by aSpatialPolygons
>>> object.
>>> 
>>> I'd like to know the total distance of roads that cover each of my cities.
>>> 
>>> Is it possible?
>>> 
>>> 
>>> Thanks,
>>> 
>>> Mathieu
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>> 
>> 
>> 
>> 
>> --
>> In God we trust, all others bring data.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Tue Jun  7 19:58:55 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 7 Jun 2011 19:58:55 +0200 (CEST)
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>

On Tue, 7 Jun 2011, Mathieu Rajerison wrote:

> Thanks for the answer!
>
> I think I surely have to use gIntersection then gLength for this purpose
>
> I've tried gIntersection like this:
> routes2 = gIntersection(routes, bdc)
>
> But I get the following message:
> Erreur dans createPolygonsComment(p) :
>  rgeos_PolyCreateComment: orphaned hole, cannot find containing polygon for
> hole at index 1
>
> Do you have an idea why I get this message and how to correct it?

The polygon object is malformed, and at least one polygon claims only to 
be an interior ring, which is impossible. You need to look at how you are 
creating your SpatialPolygons object, and possibly use 
checkPolygonsHoles() in maptools to repair damaged objects. Typically 
running:

library(maptools)
pls <- slot(bdc, "polygons")
pls1 <- lapply(pls, checkPolygonsHoles)
slot(bdc, "polygons") <- pls1

may help. As Colin says, posting a link to the polygons object, and to 
code used to create it, may be helpful.

Roger

>
>
>
> 2011/6/7 Roman Lu??trik <roman.lustrik at gmail.com>
>
>> Package rgeos has all sorts of functions that might come handy.
>>
>> Cheers,
>> Roman
>>
>>
>>
>> On Tue, Jun 7, 2011 at 6:13 PM, Mathieu Rajerison <
>> mathieu.rajerison at gmail.com> wrote:
>>
>>> Hi,
>>>
>>>
>>> I have a SpatialLines object representing roads and a SpatialPolygons
>>> object
>>> containing cities.
>>>
>>> I'd like to know how to overlay a SpatialLines object by aSpatialPolygons
>>> object.
>>>
>>> I'd like to know the total distance of roads that cover each of my cities.
>>>
>>> Is it possible?
>>>
>>>
>>> Thanks,
>>>
>>> Mathieu
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
>>
>> --
>> In God we trust, all others bring data.
>>
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From muenchen at utk.edu  Tue Jun  7 22:23:30 2011
From: muenchen at utk.edu (Muenchen, Robert A (Bob))
Date: Tue, 7 Jun 2011 20:23:30 +0000
Subject: [R-sig-Geo] Example country data to plot
In-Reply-To: <1D6E496F-69EA-47FF-AD47-537229B9FC35@isciences.com>
References: <81D92650D162664791CB7C482A8784121340336E@kmbx1.utk.tennessee.edu>
	<1D6E496F-69EA-47FF-AD47-537229B9FC35@isciences.com>
Message-ID: <81D92650D162664791CB7C482A87841213417573@kmbx1.utk.tennessee.edu>

It took a while to understand their data layout options, but it finally worked well. Thanks for the suggestion! 

Cheers, Bob

>-----Original Message-----
>From: Matthew Landis [mailto:landis at isciences.com]
>Sent: Sunday, June 05, 2011 9:36 PM
>To: Muenchen, Robert A (Bob)
>Cc: r-sig-geo at r-project.org
>Subject: Re: [R-sig-Geo] Example country data to plot
>
>Try the World Development Indicators from the World Bank.  You can download
>the whole thing as a giant CSV file without too much trouble and there are
>hundreds of variables at the national scale.
>
>Sent from my iPod -- that's why it's short and misspelled.
>
>
>On Jun 5, 2011, at 10:14 AM, "Muenchen, Robert A (Bob)" <muenchen at utk.edu
>> wrote:
>
>> Hi All,
>>
>> I'm looking for a data set of miscellaneous country measures like
>> population, education, crime, etc. The particular variables aren't
>> that important. I'll use the data for maps and non-spatial plots such
>> as bar plots, scatter plots, etc. If all goes well it'll end up in a
>> book, so I either need to be able to distribute the data or (much
>> better) simply point to a data frame in an R package already on CRAN
>> if I can find one.
>>
>> The UN Data at http://data.un.org/Explorer.aspx?d=UNESCO provides
>> plenty of variables that would work and it's re-distributable, but
>> each topic is in a separate file and in a slightly different format
>> making a merger a fair amount of work. Does anyone know of an existing
>> file I can use?
>>
>> Thanks,
>> Bob
>>
>> http://r4stats.com
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mattias at norrasverige.se  Tue Jun  7 22:28:15 2011
From: mattias at norrasverige.se (newmat)
Date: Tue, 7 Jun 2011 13:28:15 -0700 (PDT)
Subject: [R-sig-Geo] writeRaster give error "no slot of name "file" for
 this object..."
In-Reply-To: <1307468974241-6450713.post@n2.nabble.com>
References: <1307465799277-6450479.post@n2.nabble.com>
	<1307468974241-6450713.post@n2.nabble.com>
Message-ID: <1307478495574-6451257.post@n2.nabble.com>

Thanks for your quick reply. I updated to the latest version of raster now
and everything works! Thanks a lot!

I didn't know the function sessionInfo(). I will definitely include it next
time!

//Mattias

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/writeRaster-give-error-no-slot-of-name-file-for-this-object-tp6450479p6451257.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From afischbach at usgs.gov  Tue Jun  7 22:30:26 2011
From: afischbach at usgs.gov (afischbach)
Date: Tue, 7 Jun 2011 13:30:26 -0700 (PDT)
Subject: [R-sig-Geo] adehabitatLT: Selecting ltraj with nb.reloc > [minimum
	sample size]
Message-ID: <1307478626689-6451264.post@n2.nabble.com>

In preparation for analyzing the monthly utilization distribution of scores
of marine mammal trajectories, I wish to exclude monthly trajectories that
have fewer than a minimum number of relocations.

I know there must be a simple means of selecting the trajectories that have
no.reloc greater than a specified valeu, such as

nMin <- #some minimum number or relocations#
ltraj <- ltraj[no.reloc > nMin]







-----
Tony Fischbach, Wildlife Biologist
Walrus Research Program
Alaska Science Center
U.S. Geological Survey
4210 University Drive
Anchorage, AK 99508-4650

AFischbach at usgs.gov
http://alaska.usgs.gov/science/biology/walrus
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/adehabitatLT-Selecting-ltraj-with-nb-reloc-minimum-sample-size-tp6451264p6451264.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From afischbach at usgs.gov  Tue Jun  7 23:25:46 2011
From: afischbach at usgs.gov (afischbach)
Date: Tue, 7 Jun 2011 14:25:46 -0700 (PDT)
Subject: [R-sig-Geo] adehabitatLT: Selecting ltraj with nb.reloc >
 [minimum sample size]
In-Reply-To: <1307478626689-6451264.post@n2.nabble.com>
References: <1307478626689-6451264.post@n2.nabble.com>
Message-ID: <1307481946545-6451458.post@n2.nabble.com>

Sorry to answer my own inquiry.

I found a brute force means to perform the selection:

	sniffer <-summary(ltraj[i])
	if(sniffer$nb.reloc > nMin){ 
        [perform ud analysis on ltraj[i] here] ...
        } #end if

Certainly, there must be an elegant means to handle the nb.reloc variable
directly.


afischbach wrote:
> 
> ...a simple means of selecting the trajectories that have no.reloc greater
> than a specified valeu, such as
> 
> nMin <- #some minimum number or relocations#
> ltraj <- ltraj[no.reloc > nMin]
> 


-----
Tony Fischbach, Wildlife Biologist
Walrus Research Program
Alaska Science Center
U.S. Geological Survey
4210 University Drive
Anchorage, AK 99508-4650

AFischbach at usgs.gov
http://alaska.usgs.gov/science/biology/walrus
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/adehabitatLT-Selecting-ltraj-with-nb-reloc-minimum-sample-size-tp6451264p6451458.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From M.J.Cracknell at utas.edu.au  Wed Jun  8 07:32:26 2011
From: M.J.Cracknell at utas.edu.au (mattc0)
Date: Wed, 08 Jun 2011 15:32:26 +1000
Subject: [R-sig-Geo] Fwd: distmap() error with used defined image window and
	resolution
Message-ID: <fb852e021d6f0.4def960a@utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110608/9bd22973/attachment.pl>

From Roger.Bivand at nhh.no  Wed Jun  8 07:46:15 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 8 Jun 2011 07:46:15 +0200 (CEST)
Subject: [R-sig-Geo] SpatialFiltering function in the spdep package
In-Reply-To: <D9A675E4-7B2B-4970-A8D6-52FA1CFF69CA@ilstu.edu>
References: <D9A675E4-7B2B-4970-A8D6-52FA1CFF69CA@ilstu.edu>
Message-ID: <alpine.LRH.2.00.1106080743010.8912@reclus.nhh.no>

On Wed, 1 Jun 2011, Jonathan Thayn wrote:

> I have a quick question regarding the SpatialFiltering function. I have 
> created a dataset wherein I control the amount of spatial 
> autocorrelation in the model residuals before submission to spatial 
> filtering. The SpatialFiltering function works really well when model 
> residuals are positively spatially autocorrelated, but it doesn't seem 
> to work when the residuals are spatially negatively autocorrelated. It 
> seems to me from the literature, that spatial filtering with 
> eigenvectors aught to be able to handle negatively spatially 
> autocorrelated model residuals. Is something about the way 
> SpatialFiltering is coded that excludes negative SAC? Does anyone have 
> any other ideas that might explain this? Thanks.

The comment at the head of the source for the function says:

# tol: tolerance value for convergence of spatial filtering (Moran's I).
# The search for eigenvector terminates, once the residual
# autocorrelation falls below abs(Moran's I) < tol. For positive
# spatial autocorrelation in the residuals of the basic unfiltered model,
# only those eigenvectors associated with positive autocorrelation are in
# the selection set. Vice versa, for negative autocorrelation in the
# regression residuals.
#
# zerovalue: eigenvectors with eigenvalues smaller than zerovalue
# will be excluded in eigenvector search. Allows to restrict the
# search set of eigenvectors to those with extreme autocorrelation levels.

so the intention was to take both sides symmetrically. Do you have a small 
example with say simulated autocorrelation (code) to demonstrate the 
problem? It may be that a comparison somewhere is not protected by abs().

Roger

>
>
> Jonathan B. Thayn, Ph.D.
> Illinois State University
> Department of Geography - Geology
> 200A Felmley Hall
> Normal, Illinois 61790-4400
>
> (309) 438-8112
> jthayn at ilstu.edu
> my.ilstu.edu/~jthayn
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From pierre.roudier at gmail.com  Wed Jun  8 10:16:36 2011
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Wed, 8 Jun 2011 20:16:36 +1200
Subject: [R-sig-Geo] moving average along transects
In-Reply-To: <CA1464FA.3274%raphael.viscarra-rossel@csiro.au>
References: <BANLkTikjJOHYZVku4b52J=cMeYQNYO1vPg@mail.gmail.com>
	<CA1464FA.3274%raphael.viscarra-rossel@csiro.au>
Message-ID: <BANLkTimU5=oN54u=zV+AJxV6kEXutECCOw@mail.gmail.com>

Hi Raphael,

As I wrote you off-list, it is quite easy to create SpatialLines from
your transects points.

Then, the function over() allows you to overlay those SpatialLines
with your SpatialPointsDataFrame. But that would only give you the
mean for each transect - I *don't think that's what you want.

Maybe an easier way to go would be to:

- compute the point-to-point distance using spDist()
- consider your transect like a time serie, with the point-to-point
distance computed above.
- smooth your pseudo-time-serie using a moving average (I think the
zoo package does that), or any other smoother (spline, kernel
density...)
- add the smooth data  as a new attribute of your SpatialPointsDataFrame object.

Untested - just my 12 cents,

Pierre



2011/6/8  <Raphael.Viscarra-Rossel at csiro.au>:
> Hello
>
> I have a spatial dataset that is made up of 60 transects (of different lengths and not all are straight) across a large area and I want to filter the data along each transect using moving averages.
>
> The data is in a SpatialPointsDataframe with 30,000 obs (rows) and 50 variables (cols). There are no Ids for the transects?although it would not be hard to add them?
>
> I would like to filter the data from each of the 50 variables along these transects.
>
> There are no IDs for the transects and each transect can only be identified by their coordinates.
>
> Any ideas on how I might do this will be appreciated?
>
> Best wishes
>
> Raphael
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Scientist
Landcare Research, New Zealand


From mathieu.rajerison at gmail.com  Wed Jun  8 11:22:46 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Wed, 8 Jun 2011 11:22:46 +0200
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
	<alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>
Message-ID: <BANLkTimK+3niq2CLMF4kFU6YpyD7+qOtAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110608/c6d3b7fe/attachment.pl>

From r.turner at auckland.ac.nz  Wed Jun  8 11:34:42 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 08 Jun 2011 21:34:42 +1200
Subject: [R-sig-Geo] Fwd: distmap() error with used defined image window
 and	resolution
In-Reply-To: <fb852e021d6f0.4def960a@utas.edu.au>
References: <fb852e021d6f0.4def960a@utas.edu.au>
Message-ID: <4DEF4232.9000607@auckland.ac.nz>


Perhaps I'm being obtuse (not an unusual occurrence :-) ) but I don't 
understand
why you do what you do.

(1) You create a new window for the patterns --- only very slightly 
different from the
window that ``comes with'' the patterns.  This has however nothing to do 
with the
resolution of the distmap () result that you say you are concerned about.

(2) The distmap function takes as arguments the pattern (of points or 
segments)
(or window, as the case may be) and ``...'' which (sayeth the help) 
consists of
``Arguments passed to as.mask to control pixel resolution''.   There is 
no mention
of passing a ***window*** as an argument to  distmap.  (So I think that 
this may
well be a case of RTFM.)

Anyway it is the fact that you are passing this unexpected window that 
is causing
the error.

You might want to do:

     cdm <- with(copper,distmap(Lines,dimyx=c(158,70))

Or, if you really want the window to be [0,70] x [0,158] you could do

     copper$Lines$window <-  owin(c(0,70),c(0,158)

and then

     cdm <- with(copper,distmap(Lines,dimyx=c(158,70)) # Same as before.

or

     cdm <- with(copper,distmap(Lines,eps=1)) # Gives the same result as 
above.

Does this accomplish your objectives?

     cheers,

         Rolf Turner

On 08/06/11 17:32, mattc0 wrote:Hi R-sig-geo'ers
> I am attempting to generate an image with each pixel showing the euclidean distance to nearest line feature using spatstat.
> I  would like to set the image extent and resolution, rather than the  default 100 x 100 (nx, ny) cells. However, when attempting this I get  the following error
>
> Error in diff(w$yrange)/eps : non-numeric argument to binary operator
>
> I am using R version 2.12.1 64-bit and spatstat 1.22-1
>
> Below  is an example using the copper dataset that is provided with spatstat.  This generates the same error that I am getting with my data
>
>> library(spatstat)
>>   # get data
>> data(copper)
>>   # set user defined window
>> copper.win<- owin(c(0,70),c(0,158))
>>   # default distmap image resolution with 100 x 100 (ny,nx)
>> distmap.psp(copper$Lines) # OK
> real-valued pixel image
> 100 x 100 pixel array (ny, nx)
> enclosing rectangle: [-0.335, 70.11] x [0.19, 158.23] km
>>   # user defined window and resolution 158 x 70 (ny,nx)
>> distmap.psp(copper$Lines,as.mask(w=copper.win,eps=1)) # Error
> Error in diff(w$yrange)/eps : non-numeric argument to binary operator
>
>   I have tried as.mask() with xy coordinates with pixel locations but have encounter the same error.
>
> Thanks
>
> Matthew Cracknell
> PhD. Candidate
>
> ARC Centre of Excellence in Ore Deposits
> University of Tasmania
> Private Bag 79
> Hobart, 7001
> Australia
>
> Mob: 0409438924


From linxin at craes.org.cn  Wed Jun  8 12:08:58 2011
From: linxin at craes.org.cn (Xin LIN)
Date: Wed, 08 Jun 2011 18:08:58 +0800 (CST)
Subject: [R-sig-Geo] Is there any function to create buffer zones
Message-ID: <20110608100858.05BFB2E6DB7@craes.org.cn>

Hi list,

Is there any function to create buffer zones for polygons? For example, here
I have polygon shapefile of a city. I want to create a buffer zone 1km
outside its boundary, or a buffer zone with its area equal to that of the
city. Then which function should I use here? 

Any suggestion is welcome. Thank you so much for your help.

Best,

Xin


From pierre.roudier at gmail.com  Wed Jun  8 12:52:30 2011
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Wed, 8 Jun 2011 22:52:30 +1200
Subject: [R-sig-Geo] Is there any function to create buffer zones
In-Reply-To: <20110608100858.05BFB2E6DB7@craes.org.cn>
References: <20110608100858.05BFB2E6DB7@craes.org.cn>
Message-ID: <BANLkTimC1K=rO7zQ0Mq4sBPuYk5-Peqaqw@mail.gmail.com>

Hi,

See function gBuffer() in the rgeos package.

Pierre

2011/6/8 Xin LIN <linxin at craes.org.cn>:
> Hi list,
>
> Is there any function to create buffer zones for polygons? For example, here
> I have polygon shapefile of a city. I want to create a buffer zone 1km
> outside its boundary, or a buffer zone with its area equal to that of the
> city. Then which function should I use here?
>
> Any suggestion is welcome. Thank you so much for your help.
>
> Best,
>
> Xin
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Scientist
Landcare Research, New Zealand


From Roger.Bivand at nhh.no  Wed Jun  8 16:51:57 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 8 Jun 2011 16:51:57 +0200 (CEST)
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <BANLkTimK+3niq2CLMF4kFU6YpyD7+qOtAA@mail.gmail.com>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
	<alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>
	<BANLkTimK+3niq2CLMF4kFU6YpyD7+qOtAA@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106081649300.13848@reclus.nhh.no>

On Wed, 8 Jun 2011, Mathieu Rajerison wrote:

> Hi,
>
>
> First, thanks to all. It's the first time I use rgeos.
>
> I finally managed to get a layer of roads (routes.bdc object) that are the
> result of the intersection between roads and cities (bdc object).
>
> But the problem now is that some intersected roads are not considered being
> contained in any of the cities, although they should be, as the result of an
> intersection. I put two images of them as attached files (city contours in
> light orange, roads in blue, and some selected roads in yellow)
>
> http://hpics.li/750b6bf
> http://hpics.li/578ab3d

What is needed is a reproducible example, so that the classes of the 
output objects become evident. Can you provide such an example with 
publically available data, or put a relevant data subset on a link?

Roger

>
> Here is the code, for the moment:
> ####
> library(rgeos)
>
> pls <- slot(bdc, "polygons")
> pls1 <- lapply(pls, checkPolygonsHoles)
> slot(bdc, "polygons") <- pls1
>
> routes.bdc = gIntersection(routes, bdc)
>
> routes.bdc = slot(routes.bdc, "lineobj")
>
> bdc.contains = gContains(bdc, routes.bdc, byid=TRUE)
>
> nbdc = apply(bdc.contains, 1, function(x) as.numeric(which(x)))
>
> apply(bdc.contains, 1, function(x) any(x))
> ###
>
> apply(bdc.contains, 1, function(x) any(x))
> mentions many FALSE values which indicate that some roads are not contained
> in any city...(?)
>
>
> Any help would be greatly appreciated!
>
> Thanks again
>
> 2011/6/7 Roger Bivand <Roger.Bivand at nhh.no>
>
>> On Tue, 7 Jun 2011, Mathieu Rajerison wrote:
>>
>>  Thanks for the answer!
>>>
>>> I think I surely have to use gIntersection then gLength for this purpose
>>>
>>> I've tried gIntersection like this:
>>> routes2 = gIntersection(routes, bdc)
>>>
>>> But I get the following message:
>>> Erreur dans createPolygonsComment(p) :
>>>  rgeos_PolyCreateComment: orphaned hole, cannot find containing polygon
>>> for
>>> hole at index 1
>>>
>>> Do you have an idea why I get this message and how to correct it?
>>>
>>
>> The polygon object is malformed, and at least one polygon claims only to be
>> an interior ring, which is impossible. You need to look at how you are
>> creating your SpatialPolygons object, and possibly use checkPolygonsHoles()
>> in maptools to repair damaged objects. Typically running:
>>
>> library(maptools)
>> pls <- slot(bdc, "polygons")
>> pls1 <- lapply(pls, checkPolygonsHoles)
>> slot(bdc, "polygons") <- pls1
>>
>> may help. As Colin says, posting a link to the polygons object, and to code
>> used to create it, may be helpful.
>>
>> Roger
>>
>>
>>>
>>>
>>> 2011/6/7 Roman Lu??trik <roman.lustrik at gmail.com>
>>>
>>>  Package rgeos has all sorts of functions that might come handy.
>>>>
>>>> Cheers,
>>>> Roman
>>>>
>>>>
>>>>
>>>> On Tue, Jun 7, 2011 at 6:13 PM, Mathieu Rajerison <
>>>> mathieu.rajerison at gmail.com> wrote:
>>>>
>>>>  Hi,
>>>>>
>>>>>
>>>>> I have a SpatialLines object representing roads and a SpatialPolygons
>>>>> object
>>>>> containing cities.
>>>>>
>>>>> I'd like to know how to overlay a SpatialLines object by
>>>>> aSpatialPolygons
>>>>> object.
>>>>>
>>>>> I'd like to know the total distance of roads that cover each of my
>>>>> cities.
>>>>>
>>>>> Is it possible?
>>>>>
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Mathieu
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> _______________________________________________
>>>>> R-sig-Geo mailing list
>>>>> R-sig-Geo at r-project.org
>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>
>>>>>
>>>>
>>>>
>>>> --
>>>> In God we trust, all others bring data.
>>>>
>>>>
>>>        [[alternative HTML version deleted]]
>>>
>>>
>>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From zev at zevross.com  Wed Jun  8 17:24:50 2011
From: zev at zevross.com (Zev Ross)
Date: Wed, 8 Jun 2011 11:24:50 -0400
Subject: [R-sig-Geo] Other kernels for density.psp (spatstat)?
Message-ID: <4DEF9442.7060209@zevross.com>

Hi All,

I'm just wondering if anyone has used alternate kernel functions in 
density.psp from spatstat. The generic density function from stats, of 
course, allows for the use of several different kernel functions 
(triangular, biweight etc). I'm interested in applying kernel density 
estimation to lines (a road network) which density.psp is well-suited 
for, but that function is limited to the Gaussian kernel. Has anyone 
developed code to do this?

Thank you! Zev

-- 
Zev Ross
ZevRoss Spatial Analysis
120 N Aurora, Suite 3A
Ithaca, NY 14850
607-277-0004 (phone)
866-877-3690 (fax, toll-free)
zev at zevross.com


From M.J.Cracknell at utas.edu.au  Wed Jun  8 17:34:26 2011
From: M.J.Cracknell at utas.edu.au (mattc0)
Date: Thu, 09 Jun 2011 01:34:26 +1000
Subject: [R-sig-Geo] Fwd: distmap() error with used defined image window
 and	resolution
In-Reply-To: <4DEF4232.9000607@auckland.ac.nz>
References: <fb852e021d6f0.4def960a@utas.edu.au>
	<4DEF4232.9000607@auckland.ac.nz>
Message-ID: <fb6389491e9a8.4df02322@utas.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/39a21fa5/attachment.pl>

From aritra.sourav at gmail.com  Wed Jun  8 21:33:10 2011
From: aritra.sourav at gmail.com (Aritra Sengupta)
Date: Wed, 8 Jun 2011 15:33:10 -0400
Subject: [R-sig-Geo] Help with spplot
Message-ID: <BANLkTi=59QvqFKoWQ1viV+2XYgbWkRTo6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110608/40de050d/attachment.pl>

From pierre.roudier at gmail.com  Wed Jun  8 23:49:15 2011
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Thu, 9 Jun 2011 09:49:15 +1200
Subject: [R-sig-Geo] Help with spplot
In-Reply-To: <BANLkTi=59QvqFKoWQ1viV+2XYgbWkRTo6g@mail.gmail.com>
References: <BANLkTi=59QvqFKoWQ1viV+2XYgbWkRTo6g@mail.gmail.com>
Message-ID: <BANLkTi=q3=zRJw=PXuUO+dPXZ_cReSt4mQ@mail.gmail.com>

Hello Aritra,

If you want just the CRESS_ID column to be plotted, try:

spplot(nc, zcol = "CRESS_ID", col.regions = heat.colors(64))

If you want to have both maps on the plot:

p1 <-  spplot(nc, "CRESS_ID", col.regions = heat.colors(64))
p2 <-  spplot(nc, "both", col.regions = sample(rainbow(nboth)))
plot(p1, split=c(1,1, 2,1), more=TRUE)
plot(p2, split=c(2,1,2,1), more=FALSE)

HTH,

Pierre

2011/6/9 Aritra Sengupta <aritra.sourav at gmail.com>:
> Hello,
>
> I am trying to plot the map of NC and using a color scheme. I have done that
> using spplot().
>
> Here is a code (reference: Introduction to the North Carolina SIDS data
> set (revised), Roger Bivand, April 12, 2011)
>
> library(sp)
> library(maptools)
> library(spdep)
> nc_file <- system.file("etc/shapes/sids.shp", package = "spdep")[1]
> llCRS <- CRS("+proj=longlat +datum=NAD27")
> nc <- readShapeSpatial(nc_file, ID = "FIPSNO", proj4string = llCRS)
>
> nc$both <- factor(paste(nc$L_id, nc$M_id, sep = ":"))
> nboth <- length(table(unclass(nc$both)))
> spplot(nc, "both", col.regions = sample(rainbow(nboth)))
>
> Now I want to have the county index (CRESS_ID in nc) for each county,
> plotted on the same map. I have not been able to figure out how to do it :(
>
> Any help/suggestion will be greatly appreciated.
>
> Thanks.
>
> -Aritra
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Scientist
Landcare Research, New Zealand


From mathieu.rajerison at gmail.com  Thu Jun  9 00:55:05 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 9 Jun 2011 00:55:05 +0200
Subject: [R-sig-Geo] Help with spplot
In-Reply-To: <BANLkTi=q3=zRJw=PXuUO+dPXZ_cReSt4mQ@mail.gmail.com>
References: <BANLkTi=59QvqFKoWQ1viV+2XYgbWkRTo6g@mail.gmail.com>
	<BANLkTi=q3=zRJw=PXuUO+dPXZ_cReSt4mQ@mail.gmail.com>
Message-ID: <BANLkTikO63sYkPWmk4LMwOwtiiDH8pTueg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/832890c8/attachment.pl>

From Raphael.Viscarra-Rossel at csiro.au  Thu Jun  9 01:13:10 2011
From: Raphael.Viscarra-Rossel at csiro.au (Raphael.Viscarra-Rossel at csiro.au)
Date: Thu, 9 Jun 2011 09:13:10 +1000
Subject: [R-sig-Geo] moving average along transects
In-Reply-To: <BANLkTimU5=oN54u=zV+AJxV6kEXutECCOw@mail.gmail.com>
Message-ID: <CA163EBF.33A9%raphael.viscarra-rossel@csiro.au>

Hello Pierre,
good hints! I shall try them.
Thank you for your help.
Will be in touch when I find a solution?it is a bit trickier than I thought.
Raphael.

On 8/06/11 6:16 PM, "Pierre Roudier" <pierre.roudier at gmail.com<mailto:pierre.roudier at gmail.com>> wrote:

Hi Raphael,

As I wrote you off-list, it is quite easy to create SpatialLines from
your transects points.

Then, the function over() allows you to overlay those SpatialLines
with your SpatialPointsDataFrame. But that would only give you the
mean for each transect - I *don't think that's what you want.

Maybe an easier way to go would be to:

- compute the point-to-point distance using spDist()
- consider your transect like a time serie, with the point-to-point
distance computed above.
- smooth your pseudo-time-serie using a moving average (I think the
zoo package does that), or any other smoother (spline, kernel
density...)
- add the smooth data  as a new attribute of your SpatialPointsDataFrame object.

Untested - just my 12 cents,

Pierre



2011/6/8  <Raphael.Viscarra-Rossel at csiro.au<mailto:Raphael.Viscarra-Rossel at csiro.au>>:
Hello

I have a spatial dataset that is made up of 60 transects (of different lengths and not all are straight) across a large area and I want to filter the data along each transect using moving averages.

The data is in a SpatialPointsDataframe with 30,000 obs (rows) and 50 variables (cols). There are no Ids for the transects?although it would not be hard to add them?

I would like to filter the data from each of the 50 variables along these transects.

There are no IDs for the transects and each transect can only be identified by their coordinates.

Any ideas on how I might do this will be appreciated?

Best wishes

Raphael



_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org><mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org<mailto:R-sig-Geo at r-project.org>
https://stat.ethz.ch/mailman/listinfo/r-sig-geo




--
Scientist
Landcare Research, New Zealand


From pierre.roudier at gmail.com  Thu Jun  9 01:38:15 2011
From: pierre.roudier at gmail.com (Pierre Roudier)
Date: Thu, 9 Jun 2011 11:38:15 +1200
Subject: [R-sig-Geo] Help with spplot
In-Reply-To: <BANLkTikO63sYkPWmk4LMwOwtiiDH8pTueg@mail.gmail.com>
References: <BANLkTi=59QvqFKoWQ1viV+2XYgbWkRTo6g@mail.gmail.com>
	<BANLkTi=q3=zRJw=PXuUO+dPXZ_cReSt4mQ@mail.gmail.com>
	<BANLkTikO63sYkPWmk4LMwOwtiiDH8pTueg@mail.gmail.com>
Message-ID: <BANLkTi=hCA8RxnP046Kj_HRQB1OrkoxoRg@mail.gmail.com>

Hi Mathieu,

In the code snippet I posted, I just created two treillis objects, p1
and p2. Those are sort of plots objects. I then plot then in a canvas
in the plot command. The split option is simply to split the canvas in
two views, one for each plot p1 and p2. The "more" option simply lets
the canvas open for more stuff to be plotted if TRUE. When set to
FALSE, it closes the canvas - you can't add any more plot to it.

Nice to hear from you here!

Pierre

2011/6/9 Mathieu Rajerison <mathieu.rajerison at gmail.com>:
> Hello Pierre ;-)
>
>
> What's the purpose of using options split and more in plot() function?
>
>
> Thanks,
>
>
> "ex same class in school" Mathieu
>
> 2011/6/8 Pierre Roudier <pierre.roudier at gmail.com>
>
>> Hello Aritra,
>>
>> If you want just the CRESS_ID column to be plotted, try:
>>
>> spplot(nc, zcol = "CRESS_ID", col.regions = heat.colors(64))
>>
>> If you want to have both maps on the plot:
>>
>> p1 <- ?spplot(nc, "CRESS_ID", col.regions = heat.colors(64))
>> p2 <- ?spplot(nc, "both", col.regions = sample(rainbow(nboth)))
>> plot(p1, split=c(1,1, 2,1), more=TRUE)
>> plot(p2, split=c(2,1,2,1), more=FALSE)
>>
>> HTH,
>>
>> Pierre
>>
>> 2011/6/9 Aritra Sengupta <aritra.sourav at gmail.com>:
>> > Hello,
>> >
>> > I am trying to plot the map of NC and using a color scheme. I have done
>> that
>> > using spplot().
>> >
>> > Here is a code (reference: Introduction to the North Carolina SIDS data
>> > set (revised), Roger Bivand, April 12, 2011)
>> >
>> > library(sp)
>> > library(maptools)
>> > library(spdep)
>> > nc_file <- system.file("etc/shapes/sids.shp", package = "spdep")[1]
>> > llCRS <- CRS("+proj=longlat +datum=NAD27")
>> > nc <- readShapeSpatial(nc_file, ID = "FIPSNO", proj4string = llCRS)
>> >
>> > nc$both <- factor(paste(nc$L_id, nc$M_id, sep = ":"))
>> > nboth <- length(table(unclass(nc$both)))
>> > spplot(nc, "both", col.regions = sample(rainbow(nboth)))
>> >
>> > Now I want to have the county index (CRESS_ID in nc) for each county,
>> > plotted on the same map. I have not been able to figure out how to do it
>> :(
>> >
>> > Any help/suggestion will be greatly appreciated.
>> >
>> > Thanks.
>> >
>> > -Aritra
>> >
>> > ? ? ? ?[[alternative HTML version deleted]]
>> >
>> > _______________________________________________
>> > R-sig-Geo mailing list
>> > R-sig-Geo at r-project.org
>> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >
>>
>>
>>
>> --
>> Scientist
>> Landcare Research, New Zealand
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Scientist
Landcare Research, New Zealand


From gos47 at hotmail.com  Thu Jun  9 02:59:46 2011
From: gos47 at hotmail.com (=?iso-8859-1?Q?Gaspar_Reyes_P=F3ndigo?=)
Date: Wed, 8 Jun 2011 19:59:46 -0500
Subject: [R-sig-Geo] 2-D Scatter Plots from the Image
Message-ID: <BLU0-SMTP1614F090AE1E132D90BAE1FB7650@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110608/cf301584/attachment.pl>

From mathieu.rajerison at gmail.com  Thu Jun  9 10:03:06 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 9 Jun 2011 10:03:06 +0200
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <alpine.LRH.2.00.1106081649300.13848@reclus.nhh.no>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
	<alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>
	<BANLkTimK+3niq2CLMF4kFU6YpyD7+qOtAA@mail.gmail.com>
	<alpine.LRH.2.00.1106081649300.13848@reclus.nhh.no>
Message-ID: <BANLkTim_eY4aOWAR5J0z86WKiS0ww_O0pA@mail.gmail.com>

Hi,


Thanks a lot for taking my problem into account.

I've put a data subset as attached file. It contains two files: roads.shp
and cities.shp.

routes is the result of an intersection between initial complete roads file
and cities. Features in actual roads have been split up, therefore gContains
test can directly be executed.

In roads, a column named "contained" indicates whether the road is
considered contained or not after my gContains test


Mathieu

2011/6/8 Roger Bivand <Roger.Bivand at nhh.no>

> On Wed, 8 Jun 2011, Mathieu Rajerison wrote:
>
>  Hi,
>>
>>
>> First, thanks to all. It's the first time I use rgeos.
>>
>> I finally managed to get a layer of roads (routes.bdc object) that are the
>> result of the intersection between roads and cities (bdc object).
>>
>> But the problem now is that some intersected roads are not considered
>> being
>> contained in any of the cities, although they should be, as the result of
>> an
>> intersection. I put two images of them as attached files (city contours in
>> light orange, roads in blue, and some selected roads in yellow)
>>
>> http://hpics.li/750b6bf
>> http://hpics.li/578ab3d
>>
>
> What is needed is a reproducible example, so that the classes of the output
> objects become evident. Can you provide such an example with publically
> available data, or put a relevant data subset on a link?
>
> Roger
>
>
>
>> Here is the code, for the moment:
>> ####
>> library(rgeos)
>>
>> pls <- slot(bdc, "polygons")
>> pls1 <- lapply(pls, checkPolygonsHoles)
>> slot(bdc, "polygons") <- pls1
>>
>> routes.bdc = gIntersection(routes, bdc)
>>
>> routes.bdc = slot(routes.bdc, "lineobj")
>>
>> bdc.contains = gContains(bdc, routes.bdc, byid=TRUE)
>>
>> nbdc = apply(bdc.contains, 1, function(x) as.numeric(which(x)))
>>
>> apply(bdc.contains, 1, function(x) any(x))
>> ###
>>
>> apply(bdc.contains, 1, function(x) any(x))
>> mentions many FALSE values which indicate that some roads are not
>> contained
>> in any city...(?)
>>
>>
>> Any help would be greatly appreciated!
>>
>> Thanks again
>>
>> 2011/6/7 Roger Bivand <Roger.Bivand at nhh.no>
>>
>>  On Tue, 7 Jun 2011, Mathieu Rajerison wrote:
>>>
>>>  Thanks for the answer!
>>>
>>>>
>>>> I think I surely have to use gIntersection then gLength for this purpose
>>>>
>>>> I've tried gIntersection like this:
>>>> routes2 = gIntersection(routes, bdc)
>>>>
>>>> But I get the following message:
>>>> Erreur dans createPolygonsComment(p) :
>>>>  rgeos_PolyCreateComment: orphaned hole, cannot find containing polygon
>>>> for
>>>> hole at index 1
>>>>
>>>> Do you have an idea why I get this message and how to correct it?
>>>>
>>>>
>>> The polygon object is malformed, and at least one polygon claims only to
>>> be
>>> an interior ring, which is impossible. You need to look at how you are
>>> creating your SpatialPolygons object, and possibly use
>>> checkPolygonsHoles()
>>> in maptools to repair damaged objects. Typically running:
>>>
>>> library(maptools)
>>> pls <- slot(bdc, "polygons")
>>> pls1 <- lapply(pls, checkPolygonsHoles)
>>> slot(bdc, "polygons") <- pls1
>>>
>>> may help. As Colin says, posting a link to the polygons object, and to
>>> code
>>> used to create it, may be helpful.
>>>
>>> Roger
>>>
>>>
>>>
>>>>
>>>> 2011/6/7 Roman Lu??trik <roman.lustrik at gmail.com>
>>>>
>>>>  Package rgeos has all sorts of functions that might come handy.
>>>>
>>>>>
>>>>> Cheers,
>>>>> Roman
>>>>>
>>>>>
>>>>>
>>>>> On Tue, Jun 7, 2011 at 6:13 PM, Mathieu Rajerison <
>>>>> mathieu.rajerison at gmail.com> wrote:
>>>>>
>>>>>  Hi,
>>>>>
>>>>>>
>>>>>>
>>>>>> I have a SpatialLines object representing roads and a SpatialPolygons
>>>>>> object
>>>>>> containing cities.
>>>>>>
>>>>>> I'd like to know how to overlay a SpatialLines object by
>>>>>> aSpatialPolygons
>>>>>> object.
>>>>>>
>>>>>> I'd like to know the total distance of roads that cover each of my
>>>>>> cities.
>>>>>>
>>>>>> Is it possible?
>>>>>>
>>>>>>
>>>>>> Thanks,
>>>>>>
>>>>>> Mathieu
>>>>>>
>>>>>>      [[alternative HTML version deleted]]
>>>>>>
>>>>>> _______________________________________________
>>>>>> R-sig-Geo mailing list
>>>>>> R-sig-Geo at r-project.org
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>> --
>>>>> In God we trust, all others bring data.
>>>>>
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>
>>>>
>>>>
>>>>  --
>>> Roger Bivand
>>> Economic Geography Section, Department of Economics, Norwegian School of
>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>> e-mail: Roger.Bivand at nhh.no
>>>
>>>
>>>
>>        [[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/2724f25d/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: subset_rgeos_contains.zip
Type: application/zip
Size: 11645 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/2724f25d/attachment.zip>

From Roger.Bivand at nhh.no  Thu Jun  9 10:50:04 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 9 Jun 2011 10:50:04 +0200 (CEST)
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <BANLkTim_eY4aOWAR5J0z86WKiS0ww_O0pA@mail.gmail.com>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
	<alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>
	<BANLkTimK+3niq2CLMF4kFU6YpyD7+qOtAA@mail.gmail.com>
	<alpine.LRH.2.00.1106081649300.13848@reclus.nhh.no>
	<BANLkTim_eY4aOWAR5J0z86WKiS0ww_O0pA@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106091040040.23124@reclus.nhh.no>

On Thu, 9 Jun 2011, Mathieu Rajerison wrote:

> Hi,
>
>
> Thanks a lot for taking my problem into account.
>
> I've put a data subset as attached file. It contains two files: roads.shp
> and cities.shp.
>
> routes is the result of an intersection between initial complete roads file
> and cities. Features in actual roads have been split up, therefore gContains
> test can directly be executed.

This works, but could be tidied up in a loop:

library(rgeos)
library(rgdal)
cities <- readOGR(".", "cities")
routes <- readOGR(".", "routes")
candidates <- gIntersects(routes, cities, byid=TRUE)
i1 <- gIntersection(routes[candidates[1,],], cities[1,])
i2 <- gIntersection(routes[candidates[2,],], cities[2,])
i3 <- gIntersection(routes[candidates[3,],], cities[3,])
ii <- rbind(i1, i2, i3, makeUniqueIDs=TRUE)
row.names(ii) <- row.names(cities)
SpatialLinesLengths(ii)

With a loop:

library(rgdal)
cities <- readOGR(".", "cities")
routes <- readOGR(".", "routes")
candidates <- gIntersects(routes, cities, byid=TRUE)
nc <- nrow(candidates)
out <- vector(mode="list", length=nc)
for (i in seq(along=out)) {
   out[[i]] <- gIntersection(routes[candidates[i,],], cities[i,])
   row.names(out[[i]]) <- as.character(i)
}
ii <- do.call("rbind", out)
row.names(ii) <- row.names(cities)
SpatialLinesLengths(ii)

This gives the total lengths by city that you need. Using a candidate 
matrix avoids trying to do intersections on objects that do not intersect.

Hope this helps,

Roger

>
> In roads, a column named "contained" indicates whether the road is
> considered contained or not after my gContains test
>
>
> Mathieu
>
> 2011/6/8 Roger Bivand <Roger.Bivand at nhh.no>
>
>> On Wed, 8 Jun 2011, Mathieu Rajerison wrote:
>>
>>  Hi,
>>>
>>>
>>> First, thanks to all. It's the first time I use rgeos.
>>>
>>> I finally managed to get a layer of roads (routes.bdc object) that are the
>>> result of the intersection between roads and cities (bdc object).
>>>
>>> But the problem now is that some intersected roads are not considered
>>> being
>>> contained in any of the cities, although they should be, as the result of
>>> an
>>> intersection. I put two images of them as attached files (city contours in
>>> light orange, roads in blue, and some selected roads in yellow)
>>>
>>> http://hpics.li/750b6bf
>>> http://hpics.li/578ab3d
>>>
>>
>> What is needed is a reproducible example, so that the classes of the output
>> objects become evident. Can you provide such an example with publically
>> available data, or put a relevant data subset on a link?
>>
>> Roger
>>
>>
>>
>>> Here is the code, for the moment:
>>> ####
>>> library(rgeos)
>>>
>>> pls <- slot(bdc, "polygons")
>>> pls1 <- lapply(pls, checkPolygonsHoles)
>>> slot(bdc, "polygons") <- pls1
>>>
>>> routes.bdc = gIntersection(routes, bdc)
>>>
>>> routes.bdc = slot(routes.bdc, "lineobj")
>>>
>>> bdc.contains = gContains(bdc, routes.bdc, byid=TRUE)
>>>
>>> nbdc = apply(bdc.contains, 1, function(x) as.numeric(which(x)))
>>>
>>> apply(bdc.contains, 1, function(x) any(x))
>>> ###
>>>
>>> apply(bdc.contains, 1, function(x) any(x))
>>> mentions many FALSE values which indicate that some roads are not
>>> contained
>>> in any city...(?)
>>>
>>>
>>> Any help would be greatly appreciated!
>>>
>>> Thanks again
>>>
>>> 2011/6/7 Roger Bivand <Roger.Bivand at nhh.no>
>>>
>>>  On Tue, 7 Jun 2011, Mathieu Rajerison wrote:
>>>>
>>>>  Thanks for the answer!
>>>>
>>>>>
>>>>> I think I surely have to use gIntersection then gLength for this purpose
>>>>>
>>>>> I've tried gIntersection like this:
>>>>> routes2 = gIntersection(routes, bdc)
>>>>>
>>>>> But I get the following message:
>>>>> Erreur dans createPolygonsComment(p) :
>>>>>  rgeos_PolyCreateComment: orphaned hole, cannot find containing polygon
>>>>> for
>>>>> hole at index 1
>>>>>
>>>>> Do you have an idea why I get this message and how to correct it?
>>>>>
>>>>>
>>>> The polygon object is malformed, and at least one polygon claims only to
>>>> be
>>>> an interior ring, which is impossible. You need to look at how you are
>>>> creating your SpatialPolygons object, and possibly use
>>>> checkPolygonsHoles()
>>>> in maptools to repair damaged objects. Typically running:
>>>>
>>>> library(maptools)
>>>> pls <- slot(bdc, "polygons")
>>>> pls1 <- lapply(pls, checkPolygonsHoles)
>>>> slot(bdc, "polygons") <- pls1
>>>>
>>>> may help. As Colin says, posting a link to the polygons object, and to
>>>> code
>>>> used to create it, may be helpful.
>>>>
>>>> Roger
>>>>
>>>>
>>>>
>>>>>
>>>>> 2011/6/7 Roman Lu??trik <roman.lustrik at gmail.com>
>>>>>
>>>>>  Package rgeos has all sorts of functions that might come handy.
>>>>>
>>>>>>
>>>>>> Cheers,
>>>>>> Roman
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Tue, Jun 7, 2011 at 6:13 PM, Mathieu Rajerison <
>>>>>> mathieu.rajerison at gmail.com> wrote:
>>>>>>
>>>>>>  Hi,
>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> I have a SpatialLines object representing roads and a SpatialPolygons
>>>>>>> object
>>>>>>> containing cities.
>>>>>>>
>>>>>>> I'd like to know how to overlay a SpatialLines object by
>>>>>>> aSpatialPolygons
>>>>>>> object.
>>>>>>>
>>>>>>> I'd like to know the total distance of roads that cover each of my
>>>>>>> cities.
>>>>>>>
>>>>>>> Is it possible?
>>>>>>>
>>>>>>>
>>>>>>> Thanks,
>>>>>>>
>>>>>>> Mathieu
>>>>>>>
>>>>>>>      [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> _______________________________________________
>>>>>>> R-sig-Geo mailing list
>>>>>>> R-sig-Geo at r-project.org
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> In God we trust, all others bring data.
>>>>>>
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>>
>>>>>  --
>>>> Roger Bivand
>>>> Economic Geography Section, Department of Economics, Norwegian School of
>>>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>>>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>>>> e-mail: Roger.Bivand at nhh.no
>>>>
>>>>
>>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>>
>> --
>> Roger Bivand
>> Economic Geography Section, Department of Economics, Norwegian School of
>> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>> e-mail: Roger.Bivand at nhh.no
>>
>>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From mathieu.rajerison at gmail.com  Thu Jun  9 11:52:24 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 9 Jun 2011 11:52:24 +0200
Subject: [R-sig-Geo] Overlaying SpatialLines by SpatialPolygons
In-Reply-To: <alpine.LRH.2.00.1106091040040.23124@reclus.nhh.no>
References: <BANLkTinjFf3vMVxJgBcmkH2Q_xJkzsX6ig@mail.gmail.com>
	<BANLkTimkMWzOkOXsq4rke4OEeKpMEqkt7A@mail.gmail.com>
	<BANLkTim2AtrVUexSD5_CkuTbCFBsyEGnbQ@mail.gmail.com>
	<alpine.LRH.2.00.1106071953290.4150@reclus.nhh.no>
	<BANLkTimK+3niq2CLMF4kFU6YpyD7+qOtAA@mail.gmail.com>
	<alpine.LRH.2.00.1106081649300.13848@reclus.nhh.no>
	<BANLkTim_eY4aOWAR5J0z86WKiS0ww_O0pA@mail.gmail.com>
	<alpine.LRH.2.00.1106091040040.23124@reclus.nhh.no>
Message-ID: <BANLkTinoHdaWGcmfnfgxdLn1uVxu-WQfnQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/d1f4678f/attachment.pl>

From luca.morandini1 at gmail.com  Thu Jun  9 12:28:52 2011
From: luca.morandini1 at gmail.com (Luca Morandini)
Date: Thu, 09 Jun 2011 12:28:52 +0200
Subject: [R-sig-Geo] Generating geo-statistical data
Message-ID: <4DF0A064.8070505@gmail.com>

Folks,

I would like to generate, for educational purpose, data with a set level of 
auto-correlation; that is, I would like to generate Zs that exhibit an higher 
correlation with points that are closer to their locations.

One method I've found out in "Statistical methods for spatial data analysis" is 
the use of convolutions (in the sense of "smoothers"), that is, to generate random 
Zs and then compute Z2s as Z + (some weight based on neighbouring points).

Of curse this would work, but, ideally, I would like to set a level of 
autocorrelation and then have a function generating data with (about) that 
level... any suggestion ?

Regards,

Luca Morandini
http://www.lucamorandini.it


From alobolistas at gmail.com  Thu Jun  9 15:59:49 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Thu, 9 Jun 2011 15:59:49 +0200
Subject: [R-sig-Geo] raster::plot() common color scale?
Message-ID: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>

Hi!
I'm doing

par(mfrow=c(2,2))
plot(simr)
plot(simrlisa)
a2 = simr>l$lisamax
plot(l$lisamax)
plot(simr*a2)

where simr, l%lisamax and a2 are raster objects. Is there any way to
get a common color scheme
(i.e., setting common min and max values)?
The color table is the same, but the scaling is independent for each
raster object and cannot be compared.

Thanks

Agus


From sadz_a1000 at yahoo.co.uk  Thu Jun  9 17:26:26 2011
From: sadz_a1000 at yahoo.co.uk (Sadz A)
Date: Thu, 9 Jun 2011 16:26:26 +0100
Subject: [R-sig-Geo] Morans I Correlogram help
Message-ID: <960584.1944.qm@web24609.mail.ird.yahoo.com>

Hi, 

I am trying to get a moransI correlogram in R with either library (Ape) or 
library (spdep). 
I already have a Mantel correlogram (attached word.doc) but I really want to do 
the 'same' for MoransI, unfortunately nothing I try is working. 

The data I am using is X, Y location data (minicipXY.txt) and density 
(RDdensityChange.txt), both of which I have attached. 

If anyone knows how I can get my data to give me a MoransI correlogram graph and 
associated stats, I would greatly appreciate any help or advice you have to 
offer. 

Thank you 
S.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/bb065629/attachment.html>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: municipXY.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/bb065629/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: RDdensityChange.txt
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/bb065629/attachment-0001.txt>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: mantels correlogram.docx
Type: application/vnd.openxmlformats-officedocument.wordprocessingml.document
Size: 13812 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110609/bb065629/attachment.bin>

From Roger.Bivand at nhh.no  Thu Jun  9 18:24:23 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 9 Jun 2011 18:24:23 +0200
Subject: [R-sig-Geo] Morans I Correlogram help
In-Reply-To: <960584.1944.qm@web24609.mail.ird.yahoo.com>
References: <960584.1944.qm@web24609.mail.ird.yahoo.com>
Message-ID: <alpine.LRH.2.00.1106091823230.25255@reclus.nhh.no>

On Thu, 9 Jun 2011, Sadz A wrote:

> Hi, 
>
> I am trying to get a moransI correlogram in R with either library (Ape) or 
> library (spdep). 
> I already have a Mantel correlogram (attached word.doc) but I really want to do 
> the 'same' for MoransI, unfortunately nothing I try is working. 
>
> The data I am using is X, Y location data (minicipXY.txt) and density 
> (RDdensityChange.txt), both of which I have attached. 
>
> If anyone knows how I can get my data to give me a MoransI correlogram graph and 
> associated stats, I would greatly appreciate any help or advice you have to 
> offer.

Try this:

xy <- read.table("municipXY.txt", header=TRUE)
dens <- read.table("RDdensityChange.txt", header=TRUE)
library(pgirmess)
corr <- correlog(xy, dens$change)
plot(corr)
corr

Hope this helps,

Roger


>
> Thank you 
> S.

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Jun  9 19:17:16 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 9 Jun 2011 19:17:16 +0200
Subject: [R-sig-Geo] gUnion causes segfault
In-Reply-To: <alpine.LRH.2.00.1106022328110.28815@reclus.nhh.no>
References: <4DE7B71E.2060301@fsu.edu>
	<alpine.LRH.2.00.1106021927050.28340@reclus.nhh.no>
	<4DE7D217.6060001@fsu.edu>
	<BANLkTinG=iRmc6A1bXAx9iOLUqo310wYsQ@mail.gmail.com>
	<alpine.LRH.2.00.1106022328110.28815@reclus.nhh.no>
Message-ID: <alpine.LRH.2.00.1106091908100.25383@reclus.nhh.no>

On Thu, 2 Jun 2011, Roger Bivand wrote:

> On Thu, 2 Jun 2011, Barry Rowlingson wrote:
>
>> I get a buffer overflow and a nice traceback that might be helpful:
>> 
>> *** buffer overflow detected ***: /usr/lib/R/bin/exec/R terminated
>> ======= Backtrace: =========
>> /lib/tls/i686/cmov/libc.so.6(__fortify_fail+0x50)[0x1f3390]
>> /lib/tls/i686/cmov/libc.so.6(+0xe12ca)[0x1f22ca]
>> /lib/tls/i686/cmov/libc.so.6(__strcpy_chk+0x44)[0x1f1644]
>> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(RGEOS_comment2comm+0x8f)[0xc70aff]
>
> Thanks - this is in the code for trying to construct OGC SFS alike Polygon or 
> MultiPolygon objects from R/sp Polygons objects. I'll try to see what it is.

rgeos 0.1-7 has been submitted to CRAN and will be available shortly. When 
the dissolve set included very many polygons, the comment string, used to 
record which polygons are inside which others, seems to have got too long, 
because UnionCascaded in GEOS 3.2.2 did not accept GeometryCollection 
objects.

In GEOS 3.3.0, UnaryUnion does accept GeometryCollection objects, so 
unflattened sp objects may be used, avoiding the need to construct a 
Polygons object with thousands of member Polygon objects.

With GEOS 3.2.2, one needs to dissolve in two stages, first in subsets for 
dissolve sets with over 1000 objects, then once they have been dissolved, 
the second dissolve step on the intermediate sets. Tiling the input data 
with Sobj_SpatialGrid() in maptools is a possible solution.

Thanks to Brian for reproducible examples and to Barry for accurate 
diagnostics,

Roger

>
> Roger
>
>> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_Polygons2geospolygon+0x5c)[0xc73a8c]
>> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_SpatialPolygons2geospolygon+0x8b)[0xc73d7b]
>> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_convert_R2geos+0x548)[0xc74a58]
>> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_topologyfunc+0x51)[0xc7cf61]
>> /home/rowlings/R/i486-pc-linux-gnu-library/2.12/rgeos/libs/rgeos.so(rgeos_unioncascaded+0x3c)[0xc7d1cc]
>> [etc]
>> 
>> My rgeos is:
>> 
>> rgeos: (SVN revision (unknown))
>> GEOS runtime version: 3.2.2-CAPI-1.6.2
>> Polygon checking: TRUE
>> 
>> Version: 0.1-6
>> 
>> Barry
>> 
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From thi_veloso at yahoo.com.br  Fri Jun 10 00:51:52 2011
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Thu, 9 Jun 2011 15:51:52 -0700 (PDT)
Subject: [R-sig-Geo] Methodology to compare crop maps
Message-ID: <311663.80559.qm@web161421.mail.bf1.yahoo.com>

 Robert, Rich and Luca,

 Thank you very much for the suggestions. 

 Robert, I still haven't managed to implement all of your directions due to the burocracy to obtain the sugarcane raster (or shape) files from INPE.

 In the meanwhile, I am trying to convert mcgill data (you're right about the units) from fraction of land covered by a crop to presence/absence. This is because my ultimate goal is to add a new plant functional type (PFT) to a map where 15 PFTs already exist (http://www.sage.wisc.edu/download/potveg/global_potveg.html). This way, cells where cane is present should contain the value "16".

 It seemed to be a simple task, but what I am doing is changing the map substantially. Please take a peek at the code:

#Loading required packages
library(raster)
library(maptools)

#Loading SAGE vegetation map and McGill sugarcane map
vegmap<-raster("data/vegtype.nc")
cane<-raster("data/sugarcane_5min.nc")

> vegmap
class       : RasterLayer 
dimensions  : 360, 720, 259200  (nrow, ncol, ncell)
resolution  : 0.5, 0.5  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
values      : data/vegtype.nc 
min         : ? 
max         : ? 

> cane
class       : RasterLayer 
dimensions  : 2160, 4320, 9331200  (nrow, ncol, ncell)
resolution  : 0.08333333, 0.08333334  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
values      : data/sugarcane_5min.nc 
min         : ? 
max         : ? 

#Resampling McGill map to match SAGE's resolution
cane_coarser<-aggregate(cane,fact=6.00000024,fun=mean)

> cane_coarser
class       : RasterLayer 
dimensions  : 360, 720, 259200  (nrow, ncol, ncell)
resolution  : 0.5, 0.5  (x, y)
extent      : -180, 180, -90, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
values      : /tmp/R_raster_tmp/raster_tmp_39924224710.grd 
min value   : 0 
max value   : 0.5680773 

#Loading SA shapefile
south_america<-readShapePoly("shapes/southamerica.shp")

#Cropping sugar cane map
cane_sa<-crop(cane_coarser,south_america)

> cane_sa
class       : RasterLayer 
dimensions  : 137, 93, 12741  (nrow, ncol, ncell)
resolution  : 0.5, 0.5  (x, y)
extent      : -81.49999, -34.99999, -56, 12.5  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 
values      : in memory
min value   : 0 
max value   : 0.5237272 

#Below is an attempt to replace fraction with presence
cane_sa[cane_sa>0]<-16

#Check result
plot(cane_coarser)

#Adding cane map to SAGE vegetation map
new_vegmap<merge(vegmap,cane_sa)

#Writing out updated map to a netcdf file
if(require(ncdf)){
writeRaster(new_vegmap,filename="/home/thiago/IBIS/data/inpue/new_vegmap.nc",format="CDF",overwrite=TRUE)
} 
 
 Everything goes fine until cropping the resampled map. However, replacing grater than zero values results in a totally different map.

 What am I doing wrong? Maybe spatial data frames are harder to deal with (for newbies like me), or maybe the massive amount of NA's and?tiny numbers (0.000000e+00, 2.433714e-03 and etc) produced after agregation is the problem...

 Thanks in advance and best wishes,

 Thiago.

--- On Fri, 3/6/11, Robert Hijmans <r.hijmans at gmail.com> wrote:

> From: Robert Hijmans <r.hijmans at gmail.com>
> Subject: Re: [R-sig-Geo] Methodology to compare crop maps
> To: r-sig-geo at r-project.org
> Date: Friday, 3 June, 2011, 13:17
> > ?I am working with crops
> planted area maps from two distinct sources.
> > One of the maps is based on a maximum NDVI
> composition, and the other
> > map uses joint information from satellite and census
> to estimate the
> > planted area.
> >
> > ?Although the sources employ different methodologies
> to map the area
> > where the crop exists, the results should be
> comparable.
> >
> > ?After downloading the datasets, I have performed a
> visual inpection,
> > and they show reasonable agreement. However, I need a
> more robust
> > comparison method. Could anybody point out a
> methodology which allows
> > me to show the difference between both maps?
> >
> > ?Here is an example of each one of the maps:
> > http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz
> > (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not
> > available to download directly, but I can get it in
> shapefile)
> >
> 
> 
> Thiago, 
> 
> I assume that the Brazilian data has a much higher spatial
> resolution than
> the mcgill data (that I think I am familiar with), and it
> probably has a
> different CRS. And I assume that you can get it as a the
> original raster
> file (and not as shapefile) for the Brazilian data. If I am
> not mistaken,
> the mcgill data has the fraction of land area covered by a
> crop. I assume
> that the Brazilan data is presence/absence. If so I would
> use the raster
> package and aggregate the Brazilian data to a cell size
> that is similar to
> the mcgill data (~9 km), computing the fraction of cells
> that have sugarcane
> (sum divided by the number of cells, make sure to handle NA
> values). Then
> use function projectRaster to transform the mcgill data to
> the same
> extent/resolution as the aggregated Brazilian data. Now you
> have two layers
> that you can compare in different ways. 
> 
> You can make plots, compute correlation, etc. Of course the
> p-values are no
> good because of spatial autocorrelation.
> 
> library(raster)
> x <- y <- raster(nc=100, nr=100)
> x[] <- runif(ncell(r))
> y[] <- runif(ncell(r))
> plot(x, y)
> m <- lm(values(x), values(y))
> summary(m)
> abline(m)
> 
> hist(x-y)
> plot(x-y)
> cor(values(x), values(y))
> 
> 
> Perhaps you want to treat your data as presence/absence
> (with presence being
> > 0 or some another threshold). These can then be easily
> compared with the
> crosstab function which returns, in this case, a confusion
> matrix which can
> be directly interpreted or used to compute some statistics
> from.
> crosstab(x>0, y>0)
> 
> crosstab(x>0.5, y>0.5)
> 
> And there surely are many other approaches possible, which
> is why I think
> that R is the way to go in this case: it is easy, flexible
> and fast.
> 
> Robert
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Methodology-to-compare-crop-maps-tp6431598p6435902.html
> Sent from the R-sig-geo mailing list archive at
> Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



From lyolya at gmail.com  Fri Jun 10 12:30:12 2011
From: lyolya at gmail.com (Lyolya)
Date: Fri, 10 Jun 2011 11:30:12 +0100
Subject: [R-sig-Geo] a krige.conv() question :: covariance parameters
Message-ID: <BANLkTimF_TMP3ZOfyEOWhBFuHh=AS45bEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110610/93e03274/attachment.pl>

From paulojus at c3sl.ufpr.br  Fri Jun 10 13:09:27 2011
From: paulojus at c3sl.ufpr.br (Paulo Justiniano Ribeiro Jr)
Date: Fri, 10 Jun 2011 08:09:27 -0300 (BRT)
Subject: [R-sig-Geo] a krige.conv() question :: covariance parameters
In-Reply-To: <BANLkTimF_TMP3ZOfyEOWhBFuHh=AS45bEw@mail.gmail.com>
References: <BANLkTimF_TMP3ZOfyEOWhBFuHh=AS45bEw@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1106100803160.25282@macalan.c3sl.ufpr.br>

The covariance parameters can be from:
1. a visual fit (which can be permoed with eyefit() in geoR)
2. variofit() for WLS, OLS variogram fit
3. likfit()  for max. likelihood estimates
4. arbitrary values inputed by the user

for the first 3 there will be an object storing the parameters which can 
be passad to krige.control() using the argument obj.model.
In this case it is **not necessary** pass the other parameters 
individually.

an example with basic steps would be

data(s100)
v <- variog(s100, max.dist=1)
vf <- variofit(v)

predLocs <- expand.grid((0:50)/50, (0:50)/50)

kc <- krige.conv(s100, loc=predLocs, krige=krige.control(obj.m=vf))





On Fri, 10 Jun 2011, Lyolya wrote:

> Dear List,
>
> I've been performing the ordinary kriging using the krige.conv() function,
> and I have come across something I don't understand.
> In order perform the kriging, one has to input the covariance parameters in
> krige.control(..., cov.pars=c(a, b), ...). Those can be obtained form the
> variofit() function, right?
>
> variofit() estimates the initial covariance parameters and the estimated
> ones. The least ones are to be input in the krige.control() function, right?
>
> Then, what is to be input in the krige.control(obj.model)? Or this option is
> required in some special cases, and I should rather skip it?
>
> Thank you, in advance.
>
> -- 
> Best
> Lyolya.
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


Paulo Justiniano Ribeiro Jr
LEG (Laboratorio de Estatistica e Geoinformacao)
Universidade Federal do Parana
Caixa Postal 19.081
CEP 81.531-990
Curitiba, PR  -  Brasil
Tel: (+55) 41 3361 3573
VOIP: (+55) (41) (3361 3600) 1053 1066
Fax: (+55) 41 3361 3141
e-mail: paulojus AT  ufpr  br
http://www.leg.ufpr.br/~paulojus


From paul.hiemstra at knmi.nl  Fri Jun 10 13:20:39 2011
From: paul.hiemstra at knmi.nl (Paul Hiemstra)
Date: Fri, 10 Jun 2011 11:20:39 +0000
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
Message-ID: <4DF1FE07.4070707@knmi.nl>

 Hi,

I would recommend using one of the more advanced plotting facilities in
R, ggplot. An example:

library(ggplot2)
library(raster)
theme_set(theme_bw())

r = raster(system.file("external/test.grd", package="raster"))

# Convert to data.frame
r_df = as.data.frame(as(r, 'SpatialPixelsDataFrame'))
# create new column 10 times larger
# here you could extract data from other grids that
# you want to show at the same time
r_df$valuesx10 = r_df$values*2

# Reshape the data for ggplot
plotData = melt(r_df, id.vars = c('x','y'))

ggplot(aes(x = x, y = y), data = plotData) +
    geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
    scale_fill_gradient(low = 'white', high = 'blue') +
    coord_equal()

This is a basic ggplot example of visualizing rasters. I realize that it
is a short example with a lot of things specific to ggplot, but I hope
you can figure out why I use the code that I use. In my view, the
investment in learning to use ggplot is worth it. A good place to start
is the ggplot website [1].

cheers.
Paul

[1] http://had.co.nz/ggplot2/

On 06/09/2011 01:59 PM, Agustin Lobo wrote:
> Hi!
> I'm doing
>
> par(mfrow=c(2,2))
> plot(simr)
> plot(simrlisa)
> a2 = simr>l$lisamax
> plot(l$lisamax)
> plot(simr*a2)
>
> where simr, l%lisamax and a2 are raster objects. Is there any way to
> get a common color scheme
> (i.e., setting common min and max values)?
> The color table is the same, but the scaling is independent for each
> raster object and cannot be compared.
>
> Thanks
>
> Agus
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Paul Hiemstra, Ph.D.
Global Climate Division
Royal Netherlands Meteorological Institute (KNMI)
Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
P.O. Box 201 | 3730 AE | De Bilt
tel: +31 30 2206 494

http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From adamhsparks at gmail.com  Fri Jun 10 13:30:20 2011
From: adamhsparks at gmail.com (Adam Sparks)
Date: Fri, 10 Jun 2011 19:30:20 +0800
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
Message-ID: <BANLkTim1hX-zAAbxLKsS5Sz2F9SyJsTujA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110610/4bcf5667/attachment.pl>

From mihai.niculita at uaic.ro  Fri Jun 10 16:38:54 2011
From: mihai.niculita at uaic.ro (mihai.niculita)
Date: Fri, 10 Jun 2011 07:38:54 -0700 (PDT)
Subject: [R-sig-Geo] converting bounding box to shapefile problem
Message-ID: <1307716734078-6462495.post@n2.nabble.com>

Hy all,

I need to convert the bounding box of several rasters to shapefile. I wrote
a script starting from several scripts available over the Internet, and I am
stuck at the final command which should write the bounding box polygons
(contained in spatpoldf.list) obtained with sp package to shapefile using
rgdal:

> # export to a GIS format:
> write.list <- list()
> for(i in 1:length(spatpol.list[[i]])) {
+ write.list[[i]] <- writeOGR(spatpoldf.list[[i]], 
+ ".", layer=map.list[[i]], driver="ESRI Shapefile")
+ }
Error in writeOGR(spatpoldf.list[[i]], ".", layer = map.list[[1]], driver =
"ESRI Shapefile") : 
  number of objects mismatch
> 

map.list is a vector containing the raster names and looks like this:

[1] "N21W157.asc" "N21W158.asc" .....

I mention that the bounding box polygon does not have CRS because I can not
attach decimal degree coordinates with sp package. I really need the
Lat/Long coordinates because finally I must apply the script to a big number
of SRTM1 rasters which cover several UTM zones.

The entire script and the data is available at:
http://www.geomorphologyonline.com/script.r
http://www.geomorphologyonline.com/data.tgz

I work with R.2.12.1 x64 on Windows and I have the latest sp and rgdal for
x64.

Thank you in advance for any help with this!

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/converting-bounding-box-to-shapefile-problem-tp6462495p6462495.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mehajain13 at gmail.com  Fri Jun 10 16:53:38 2011
From: mehajain13 at gmail.com (Meha Jain)
Date: Fri, 10 Jun 2011 10:53:38 -0400
Subject: [R-sig-Geo] smooth.spline in calc function
Message-ID: <BANLkTikZXahretD9eo=uDMa7+=qR3LSAVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110610/3fbe847e/attachment.pl>

From matteo.mattiuzzi at boku.ac.at  Fri Jun 10 18:05:27 2011
From: matteo.mattiuzzi at boku.ac.at (Matteo Mattiuzzi)
Date: Fri, 10 Jun 2011 18:05:27 +0200
Subject: [R-sig-Geo] Antw:  smooth.spline in calc function
In-Reply-To: <BANLkTikZXahretD9eo=uDMa7+=qR3LSAVQ@mail.gmail.com>
References: <BANLkTikZXahretD9eo=uDMa7+=qR3LSAVQ@mail.gmail.com>
Message-ID: <4DF25CE7020000270000EF12@gwia2.boku.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110610/ea699607/attachment.pl>

From b.rowlingson at lancaster.ac.uk  Fri Jun 10 18:06:49 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 10 Jun 2011 17:06:49 +0100
Subject: [R-sig-Geo] converting bounding box to shapefile problem
In-Reply-To: <1307716734078-6462495.post@n2.nabble.com>
References: <1307716734078-6462495.post@n2.nabble.com>
Message-ID: <BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>

On Fri, Jun 10, 2011 at 3:38 PM, mihai.niculita <mihai.niculita at uaic.ro> wrote:
> Hy all,
>
> I need to convert the bounding box of several rasters to shapefile. I wrote
> a script starting from several scripts available over the Internet, and I am
> stuck at the final command which should write the bounding box polygons
> (contained in spatpoldf.list) obtained with sp package to shapefile using
> rgdal:
>
>> # export to a GIS format:
>> write.list <- list()
>> for(i in 1:length(spatpol.list[[i]])) {
> + write.list[[i]] <- writeOGR(spatpoldf.list[[i]],
> + ".", layer=map.list[[i]], driver="ESRI Shapefile")
> + }
> Error in writeOGR(spatpoldf.list[[i]], ".", layer = map.list[[1]], driver =
> "ESRI Shapefile") :
> ?number of objects mismatch
>>
>
> map.list is a vector containing the raster names and looks like this:
>
> [1] "N21W157.asc" "N21W158.asc" .....
>
> I mention that the bounding box polygon does not have CRS because I can not
> attach decimal degree coordinates with sp package. I really need the
> Lat/Long coordinates because finally I must apply the script to a big number
> of SRTM1 rasters which cover several UTM zones.
>
> The entire script and the data is available at:
> http://www.geomorphologyonline.com/script.r
> http://www.geomorphologyonline.com/data.tgz
>
> I work with R.2.12.1 x64 on Windows and I have the latest sp and rgdal for
> x64.

 This is because the SpatialPolygonDataFrames you try to write to
shapefiles have 7 items in their data but only one polygon - a square.
The data should only be a data frame with one row.

 It comes from this:

ID <- array(map.list, dim=c(7,1))   # why 7 here?
IDD <- as.data.frame(ID)

and then:

spatpoldf.list[[i]] <- SpatialPolygonsDataFrame(spatpol.list[[i]],
IDD, match.ID = FALSE)

I'm not sure why SpatialPolygonsDataFrame doesnt complain at this
point. I do know that if you replace IDD with data.frame(ID=1) or some
other single-row data frame when you construct it then it will work.

[Also, you only need about three of those packages loaded in your file]

Barry


From Roger.Bivand at nhh.no  Fri Jun 10 19:31:58 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 10 Jun 2011 19:31:58 +0200 (CEST)
Subject: [R-sig-Geo] converting bounding box to shapefile problem
In-Reply-To: <BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>
References: <1307716734078-6462495.post@n2.nabble.com>
	<BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106101930030.31275@reclus.nhh.no>

On Fri, 10 Jun 2011, Barry Rowlingson wrote:

> On Fri, Jun 10, 2011 at 3:38 PM, mihai.niculita <mihai.niculita at uaic.ro> wrote:
>> Hy all,
>>
>> I need to convert the bounding box of several rasters to shapefile. I wrote
>> a script starting from several scripts available over the Internet, and I am
>> stuck at the final command which should write the bounding box polygons
>> (contained in spatpoldf.list) obtained with sp package to shapefile using
>> rgdal:
>>
>>> # export to a GIS format:
>>> write.list <- list()
>>> for(i in 1:length(spatpol.list[[i]])) {
>> + write.list[[i]] <- writeOGR(spatpoldf.list[[i]],
>> + ".", layer=map.list[[i]], driver="ESRI Shapefile")
>> + }
>> Error in writeOGR(spatpoldf.list[[i]], ".", layer = map.list[[1]], driver =
>> "ESRI Shapefile") :
>> ?number of objects mismatch
>>>
>>
>> map.list is a vector containing the raster names and looks like this:
>>
>> [1] "N21W157.asc" "N21W158.asc" .....
>>
>> I mention that the bounding box polygon does not have CRS because I can not
>> attach decimal degree coordinates with sp package. I really need the
>> Lat/Long coordinates because finally I must apply the script to a big number
>> of SRTM1 rasters which cover several UTM zones.
>>
>> The entire script and the data is available at:
>> http://www.geomorphologyonline.com/script.r
>> http://www.geomorphologyonline.com/data.tgz
>>
>> I work with R.2.12.1 x64 on Windows and I have the latest sp and rgdal for
>> x64.
>
> This is because the SpatialPolygonDataFrames you try to write to
> shapefiles have 7 items in their data but only one polygon - a square.
> The data should only be a data frame with one row.
>
> It comes from this:
>
> ID <- array(map.list, dim=c(7,1))   # why 7 here?
> IDD <- as.data.frame(ID)
>
> and then:
>
> spatpoldf.list[[i]] <- SpatialPolygonsDataFrame(spatpol.list[[i]],
> IDD, match.ID = FALSE)
>
> I'm not sure why SpatialPolygonsDataFrame doesnt complain at this
> point. I do know that if you replace IDD with data.frame(ID=1) or some
> other single-row data frame when you construct it then it will work.

It doesn't complain in principle because the user turned off ID checking, 
but you are right that nrow(df) should be checked even if ID checking is 
turned off.

Thanks for noticing an open barn door!

Roger

>
> [Also, you only need about three of those packages loaded in your file]
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no

From Andy.Bunn at wwu.edu  Fri Jun 10 20:01:02 2011
From: Andy.Bunn at wwu.edu (Andy Bunn)
Date: Fri, 10 Jun 2011 18:01:02 +0000
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
Message-ID: <9B597DE5AF080D418509A7E9F1E93EAF0207C9FB@Exch2010MB-3.univ.dir.wwu.edu>



> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Agustin Lobo
> Sent: Thursday, June 09, 2011 7:00 AM
> To: r-sig-geo; Robert J. Hijmans
> Subject: [R-sig-Geo] raster::plot() common color scale?
> 
> Hi!
> I'm doing
> 
> par(mfrow=c(2,2))
> plot(simr)
> plot(simrlisa)
> a2 = simr>l$lisamax
> plot(l$lisamax)
> plot(simr*a2)
> 
> where simr, l%lisamax and a2 are raster objects. Is there any way to
> get a common color scheme
> (i.e., setting common min and max values)?
> The color table is the same, but the scaling is independent for each
> raster object and cannot be compared.


Last time I had to do this I did something like: 

foo <- raster(nrows=20, ncols=20)
values(foo) <- runif(400)
bar <- raster(nrows=20, ncols=20)
values(bar) <- runif(400)
brks <- seq(0,1,by=0.1)
nbrks <- length(brks)-1
plot(foo,breaks=brks,col=rev(terrain.colors(nbrks)),lab.breaks=brks,zlim=c(0,1))
plot(bar,breaks=brks,col=rev(terrain.colors(nbrks)),lab.breaks=brks,zlim=c(0,1))




> 
> Thanks
> 
> Agus
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mihai.niculita at uaic.ro  Fri Jun 10 20:34:03 2011
From: mihai.niculita at uaic.ro (mihai.niculita)
Date: Fri, 10 Jun 2011 11:34:03 -0700 (PDT)
Subject: [R-sig-Geo] converting bounding box to shapefile problem
In-Reply-To: <alpine.LRH.2.00.1106101930030.31275@reclus.nhh.no>
References: <1307716734078-6462495.post@n2.nabble.com>
	<BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>
	<alpine.LRH.2.00.1106101930030.31275@reclus.nhh.no>
Message-ID: <1307730843990-6463373.post@n2.nabble.com>

Thank you Barry and Roger,

You are right with the objects. This part from sp package I didn't
understood to well. My code is trying to obtain a list of
SpatialPolygonsDataFrame:

ID <- array(map.list, dim=c(7,1))
IDD <- as.data.frame(ID)
spatpol.list <- list()
polygon.list <- list()
spatpoldf.list <- list()
for(i in 1:length(bbx.list)) {
polygon.list[[i]] <- list(Polygons(list(Polygon(bbx.list[[i]])),
map.list[[i]]))
spatpol.list[[i]] <- SpatialPolygons(polygon.list[[i]])
spatpoldf.list[[i]] <- SpatialPolygonsDataFrame(spatpol.list[[i]], IDD,
match.ID = FALSE)
}

I mention that I want to process automatically almost 800 rasters. In this
case I had 7 rastesr, that's why ID is an array of 7 rows.
The sp documentation says for the above code:
"srl       list with Polygon-class objects" == which in my script is
bbx.list[[i]]
"ID       character vector of length one with identifier" == !!!!this I
didn't understood, and in my case I choose the vector with the names of arc
ascii grid files
"Srl       list with objects of class Polygons-class" == which in my script
is polygon.list[[i]]
"pO       integer vector; plotting order; if missing in reverse order of
Polygons area" 
"Sr        object of class SpatialPolygons-class" == which in my script is
spatpol.list[[i]]
"data     object of class data.frame; the number of rows in data should
equal the"
            number of Polygons-class objects in Sr" ==!!!!this I didn't
understood, and in my case I transformed the vector with the names of arc
ascii grid files in a matrix
"match.ID       logical: (default TRUE): match SpatialPolygons member
Polygons ID slot values"
                    with data frame row names, and re-order the data frame
rows if necessary."
                    If character: indicates the column in data with Polygons
IDs to match"

In my case spatpol.list[[i]] should have i spatial polygons, not only one as
Barry say.
As a conclusion if some one can give me an example of how "ID" and "data"
should look I think I will resolve the problem.


-----
teaching assistant/phD student
Department of Geography
Faculty of Geography and Geology
University Al. I. Cuza
Iasi, Romania
email: mihai.niculita at uaic.ro
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/converting-bounding-box-to-shapefile-problem-tp6462495p6463373.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From b.rowlingson at lancaster.ac.uk  Sat Jun 11 00:12:07 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 10 Jun 2011 23:12:07 +0100
Subject: [R-sig-Geo] converting bounding box to shapefile problem
In-Reply-To: <1307730843990-6463373.post@n2.nabble.com>
References: <1307716734078-6462495.post@n2.nabble.com>
	<BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>
	<alpine.LRH.2.00.1106101930030.31275@reclus.nhh.no>
	<1307730843990-6463373.post@n2.nabble.com>
Message-ID: <BANLkTi=q89tin_neH5DMthTzj6pf+SM4hQ@mail.gmail.com>

On Fri, Jun 10, 2011 at 7:34 PM, mihai.niculita <mihai.niculita at uaic.ro> wrote:

> In my case spatpol.list[[i]] should have i spatial polygons, not only one as
> Barry say.

 Well, no, spatpol.list is a list of the same length as bbx.list. Each
element of spatpol.list, referred to as spatpol.list[[i]] is a single
spatial polygon (with four coordinates).

> As a conclusion if some one can give me an example of how "ID" and "data"
> should look I think I will resolve the problem.

You have to decide if you want to create 7 different shapefiles, one
for each of your grids and each containing one bounding box polygon,
or one shapefile with 7 features.

 You are very close to the first solution. A shapefile, and a
SpatialPolygonsDataFrame, contains 1 or more features, where each
feature has a geometry (the polygon) and some attributes (the data
frame). Currently you create your SpatialPOlygonsDataFrame from a
single geometry and a data frame (IDD) with 7 rows - these dont match.
You need to make sure that IDD is only *one* row.


Barry


From r.hijmans at gmail.com  Sat Jun 11 06:27:33 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Fri, 10 Jun 2011 21:27:33 -0700
Subject: [R-sig-Geo] Methodology to compare crop maps
In-Reply-To: <311663.80559.qm@web161421.mail.bf1.yahoo.com>
References: <455880.9586.qm@web161406.mail.bf1.yahoo.com>
	<311663.80559.qm@web161421.mail.bf1.yahoo.com>
Message-ID: <BANLkTinhDmyaJ-cSmuJwS9oa8rSWtyad0w@mail.gmail.com>

Hi Thiago,

You are not saying _what_ goes wrong. That makes it difficult to help.
I am guessing that you are missing some of the steps below. You do:

cane_sa[cane_sa>0]<-16

# I do not know your exact objectives but it seems strange to use 0 here,
# as even a cell that is covered for 1/600 of its area with cane would
be classified as cane.
# but irrespective of the threshold you choose, I think you need:

cane_sa[cane_sa < 16] <- NA
veg_sa <- crop(vegmap,south_america)
newveg_sa <- cover(cane_sa, veg_sa)

# and then continue with your code again:

new_vegmap <- merge(newveg_sa, vegmap)

Robert

On Thu, Jun 9, 2011 at 3:51 PM, Thiago Veloso <thi_veloso at yahoo.com.br> wrote:
> ?Robert, Rich and Luca,
>
> ?Thank you very much for the suggestions.
>
> ?Robert, I still haven't managed to implement all of your directions due to the burocracy to obtain the sugarcane raster (or shape) files from INPE.
>
> ?In the meanwhile, I am trying to convert mcgill data (you're right about the units) from fraction of land covered by a crop to presence/absence. This is because my ultimate goal is to add a new plant functional type (PFT) to a map where 15 PFTs already exist (http://www.sage.wisc.edu/download/potveg/global_potveg.html). This way, cells where cane is present should contain the value "16".
>
> ?It seemed to be a simple task, but what I am doing is changing the map substantially. Please take a peek at the code:
>
> #Loading required packages
> library(raster)
> library(maptools)
>
> #Loading SAGE vegetation map and McGill sugarcane map
> vegmap<-raster("data/vegtype.nc")
> cane<-raster("data/sugarcane_5min.nc")
>
>> vegmap
> class ? ? ? : RasterLayer
> dimensions ?: 360, 720, 259200 ?(nrow, ncol, ncell)
> resolution ?: 0.5, 0.5 ?(x, y)
> extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84
> values ? ? ?: data/vegtype.nc
> min ? ? ? ? : ?
> max ? ? ? ? : ?
>
>> cane
> class ? ? ? : RasterLayer
> dimensions ?: 2160, 4320, 9331200 ?(nrow, ncol, ncell)
> resolution ?: 0.08333333, 0.08333334 ?(x, y)
> extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84
> values ? ? ?: data/sugarcane_5min.nc
> min ? ? ? ? : ?
> max ? ? ? ? : ?
>
> #Resampling McGill map to match SAGE's resolution
> cane_coarser<-aggregate(cane,fact=6.00000024,fun=mean)
>
>> cane_coarser
> class ? ? ? : RasterLayer
> dimensions ?: 360, 720, 259200 ?(nrow, ncol, ncell)
> resolution ?: 0.5, 0.5 ?(x, y)
> extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84
> values ? ? ?: /tmp/R_raster_tmp/raster_tmp_39924224710.grd
> min value ? : 0
> max value ? : 0.5680773
>
> #Loading SA shapefile
> south_america<-readShapePoly("shapes/southamerica.shp")
>
> #Cropping sugar cane map
> cane_sa<-crop(cane_coarser,south_america)
>
>> cane_sa
> class ? ? ? : RasterLayer
> dimensions ?: 137, 93, 12741 ?(nrow, ncol, ncell)
> resolution ?: 0.5, 0.5 ?(x, y)
> extent ? ? ?: -81.49999, -34.99999, -56, 12.5 ?(xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84
> values ? ? ?: in memory
> min value ? : 0
> max value ? : 0.5237272
>
> #Below is an attempt to replace fraction with presence
> cane_sa[cane_sa>0]<-16
>
> #Check result
> plot(cane_coarser)
>
> #Adding cane map to SAGE vegetation map
> new_vegmap<merge(vegmap,cane_sa)
>
> #Writing out updated map to a netcdf file
> if(require(ncdf)){
> writeRaster(new_vegmap,filename="/home/thiago/IBIS/data/inpue/new_vegmap.nc",format="CDF",overwrite=TRUE)
> }
>
> ?Everything goes fine until cropping the resampled map. However, replacing grater than zero values results in a totally different map.
>
> ?What am I doing wrong? Maybe spatial data frames are harder to deal with (for newbies like me), or maybe the massive amount of NA's and?tiny numbers (0.000000e+00, 2.433714e-03 and etc) produced after agregation is the problem...
>
> ?Thanks in advance and best wishes,
>
> ?Thiago.
>
> --- On Fri, 3/6/11, Robert Hijmans <r.hijmans at gmail.com> wrote:
>
>> From: Robert Hijmans <r.hijmans at gmail.com>
>> Subject: Re: [R-sig-Geo] Methodology to compare crop maps
>> To: r-sig-geo at r-project.org
>> Date: Friday, 3 June, 2011, 13:17
>> > ?I am working with crops
>> planted area maps from two distinct sources.
>> > One of the maps is based on a maximum NDVI
>> composition, and the other
>> > map uses joint information from satellite and census
>> to estimate the
>> > planted area.
>> >
>> > ?Although the sources employ different methodologies
>> to map the area
>> > where the crop exists, the results should be
>> comparable.
>> >
>> > ?After downloading the datasets, I have performed a
>> visual inpection,
>> > and they show reasonable agreement. However, I need a
>> more robust
>> > comparison method. Could anybody point out a
>> methodology which allows
>> > me to show the difference between both maps?
>> >
>> > ?Here is an example of each one of the maps:
>> > http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz
>> > (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not
>> > available to download directly, but I can get it in
>> shapefile)
>> >
>>
>>
>> Thiago,
>>
>> I assume that the Brazilian data has a much higher spatial
>> resolution than
>> the mcgill data (that I think I am familiar with), and it
>> probably has a
>> different CRS. And I assume that you can get it as a the
>> original raster
>> file (and not as shapefile) for the Brazilian data. If I am
>> not mistaken,
>> the mcgill data has the fraction of land area covered by a
>> crop. I assume
>> that the Brazilan data is presence/absence. If so I would
>> use the raster
>> package and aggregate the Brazilian data to a cell size
>> that is similar to
>> the mcgill data (~9 km), computing the fraction of cells
>> that have sugarcane
>> (sum divided by the number of cells, make sure to handle NA
>> values). Then
>> use function projectRaster to transform the mcgill data to
>> the same
>> extent/resolution as the aggregated Brazilian data. Now you
>> have two layers
>> that you can compare in different ways.
>>
>> You can make plots, compute correlation, etc. Of course the
>> p-values are no
>> good because of spatial autocorrelation.
>>
>> library(raster)
>> x <- y <- raster(nc=100, nr=100)
>> x[] <- runif(ncell(r))
>> y[] <- runif(ncell(r))
>> plot(x, y)
>> m <- lm(values(x), values(y))
>> summary(m)
>> abline(m)
>>
>> hist(x-y)
>> plot(x-y)
>> cor(values(x), values(y))
>>
>>
>> Perhaps you want to treat your data as presence/absence
>> (with presence being
>> > 0 or some another threshold). These can then be easily
>> compared with the
>> crosstab function which returns, in this case, a confusion
>> matrix which can
>> be directly interpreted or used to compute some statistics
>> from.
>> crosstab(x>0, y>0)
>>
>> crosstab(x>0.5, y>0.5)
>>
>> And there surely are many other approaches possible, which
>> is why I think
>> that R is the way to go in this case: it is easy, flexible
>> and fast.
>>
>> Robert
>>
>>
>> --
>> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Methodology-to-compare-crop-maps-tp6431598p6435902.html
>> Sent from the R-sig-geo mailing list archive at
>> Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>
>


From r.hijmans at gmail.com  Sat Jun 11 06:38:14 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 10 Jun 2011 21:38:14 -0700 (PDT)
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <9B597DE5AF080D418509A7E9F1E93EAF0207C9FB@Exch2010MB-3.univ.dir.wwu.edu>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
	<9B597DE5AF080D418509A7E9F1E93EAF0207C9FB@Exch2010MB-3.univ.dir.wwu.edu>
Message-ID: <1307767094157-6464547.post@n2.nabble.com>

> Is there any way to 
> get a common color scheme 
> (i.e., setting common min and max values)? 

Here is yet another way:

library(raster)
foo <- raster(nrows=20, ncols=20) 
values(foo) <- runif(400) 
bar <- raster(nrows=20, ncols=20) 
values(bar) <- runif(400) 
s <- stack(foo, bar, foo*2)

# first sample large rasters:
x <- sampleRegular(s, 25000, asRaster=T)

# then use spplot
spplot(as(x, 'SpatialGridDataFrame'))


# I have added two functions to raster version 1.8-33 
# a generic function for spplot and Raster objects
# that does the same as the example above in one short line:

spplot(s)

# and a wrapper around ggplot (called gplot),
# based on Paul's example, that allows you to do things like:

theme_set(theme_bw())

gplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
            scale_fill_gradient(low = 'white', high = 'blue') +
coord_equal()


Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-plot-common-color-scale-tp6457926p6464547.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Sat Jun 11 06:57:15 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Fri, 10 Jun 2011 21:57:15 -0700 (PDT)
Subject: [R-sig-Geo] converting bounding box to shapefile problem
In-Reply-To: <BANLkTi=q89tin_neH5DMthTzj6pf+SM4hQ@mail.gmail.com>
References: <1307716734078-6462495.post@n2.nabble.com>
	<BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>
	<alpine.LRH.2.00.1106101930030.31275@reclus.nhh.no>
	<1307730843990-6463373.post@n2.nabble.com>
	<BANLkTi=q89tin_neH5DMthTzj6pf+SM4hQ@mail.gmail.com>
Message-ID: <1307768235335-6464586.post@n2.nabble.com>

Interesting problem

> You have to decide if you want to create 7 different shapefiles, one 
> for each of your grids and each containing one bounding box polygon, 
> or one shapefile with 7 features. 

Here is a solution, I think, if you want a single shapefile with all
bounding boxes

library(raster)
maps <- list.files(, ".asc", full.names=TRUE)

# get extents. Advantage of this no need to read the raster file values
ext <- lapply(maps, function(x)  extent(raster(x)))

# get SpatialPolygons (is there an easier way to append SpatialPolygons with
the same ID?)
sp <- SpatialPolygons(lapply(1:length(ext), function(x) { Polygons(list(
as(ext[[x]], 'SpatialPolygons')@polygons[[1]]@Polygons[[1]]), x) } ))

# data.frame
dat <- do.call(rbind, lapply(ext, function(x)  as.vector(bbox(x))))
dat <- data.frame(dat, filename=basename(maps))
colnames(dat)[1:4] = c('xmin', 'ymin', 'xmax', 'ymax')

sp <- SpatialPolygonsDataFrame(sp, dat)

writeOGR(sp, ".", layer='filename', driver="ESRI Shapefile")

plot(sp)
xy = coordinates(sp)
text(xy[,1], xy[,2], 1:nrow(xy))


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/converting-bounding-box-to-shapefile-problem-tp6462495p6464586.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mihai.niculita at uaic.ro  Sat Jun 11 08:28:20 2011
From: mihai.niculita at uaic.ro (mihai.niculita)
Date: Fri, 10 Jun 2011 23:28:20 -0700 (PDT)
Subject: [R-sig-Geo] converting bounding box to shapefile problem
In-Reply-To: <1307768235335-6464586.post@n2.nabble.com>
References: <1307716734078-6462495.post@n2.nabble.com>
	<BANLkTimPYdf29qs3ngL44DrjJBE_b7YLQg@mail.gmail.com>
	<alpine.LRH.2.00.1106101930030.31275@reclus.nhh.no>
	<1307730843990-6463373.post@n2.nabble.com>
	<BANLkTi=q89tin_neH5DMthTzj6pf+SM4hQ@mail.gmail.com>
	<1307768235335-6464586.post@n2.nabble.com>
Message-ID: <1307773700668-6464692.post@n2.nabble.com>

Thanks Barry and Robert,

Now I understood the meaning of the ID and IDD refering to
SpatialPolygonsDataFrame function. And I managed to run the entire script.
My intention is to obtain a shapefile of the bounding box for every raster
file. I think I can modify Robert shortcut to obtain this also.

Thanks again for your time!

-----
teaching assistant/phD student
Department of Geography
Faculty of Geography and Geology
University Al. I. Cuza
Iasi, Romania
email: mihai.niculita at uaic.ro
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/converting-bounding-box-to-shapefile-problem-tp6462495p6464692.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From villers.alexandre at gmail.com  Sat Jun 11 10:44:03 2011
From: villers.alexandre at gmail.com (Alexandre Villers)
Date: Sat, 11 Jun 2011 11:44:03 +0300
Subject: [R-sig-Geo] Supervised landscape classification according to NDVI
	time series
Message-ID: <4DF32AD3.8000704@gmail.com>

Hey,

 From what I understood, most landscape classification methods available 
from GRASS (through R) do not account for the temporaI aspect of 
spectrum. So for example, if you have a raster where each band 
represents NDVI values at a given date, from March to September for 
example, the classification will not consider that values are 
time-dependant. I would like to use time series of NDVI values to 
classify pixels in different type of crop, accordingly to the shape of 
each time series (rapeseed will not present the same NDVI time serie as 
would alfalfa or wheat).
I was wondering if someone could point me to a method that would allow 
such classification using R ? I started looking at Functional Data 
Analysis but I must admit that I'm a bit lost at the moment.

Thanks for any help


Alexandre


From luca.morandini1 at gmail.com  Sat Jun 11 19:06:52 2011
From: luca.morandini1 at gmail.com (Luca Morandini)
Date: Sat, 11 Jun 2011 19:06:52 +0200
Subject: [R-sig-Geo] R-sig-geo on an NNTP server ?
Message-ID: <4DF3A0AC.3080307@gmail.com>

Does anyone know of a NNTP server hosting this list (I hate my inbox being 
cluttered) ?

If no one is available, do you mind if I add this mailing list to gmane.org (no 
spam from there, since one has to subscribe to the mailing list before posting 
through their server) ?

Regards,

Luca Morandini
http://www.lucamorandini.it


From Roger.Bivand at nhh.no  Sat Jun 11 20:06:12 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 11 Jun 2011 20:06:12 +0200
Subject: [R-sig-Geo] R-sig-geo on an NNTP server ?
References: <4DF3A0AC.3080307@gmail.com>
Message-ID: <AD51AB79BC327C40AB2C7EB75D57A3C4051337@TOLAR.valuta.nhh.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110611/a0d4c0de/attachment.pl>

From lmorandini at ieee.org  Sat Jun 11 21:12:27 2011
From: lmorandini at ieee.org (Luca Morandini)
Date: Sat, 11 Jun 2011 21:12:27 +0200
Subject: [R-sig-Geo] R-sig-geo on an NNTP server ?
In-Reply-To: <AD51AB79BC327C40AB2C7EB75D57A3C4051337@TOLAR.valuta.nhh.no>
References: <4DF3A0AC.3080307@gmail.com>
	<AD51AB79BC327C40AB2C7EB75D57A3C4051337@TOLAR.valuta.nhh.no>
Message-ID: <it0emr$h0p$2@dough.gmane.org>

On 06/11/2011 08:06 PM, Roger Bivand wrote:
> The list is on nabble - indeed, its complete archives were also imported there,
> and it is already on gmane http://dir.gmane.org/gmane.comp.lang.r.geo.

Great !


> So before you clutter any more inboxes, perhaps check ? (!)

Well, checking I did, but I looked for it under the "comp.gis" hierarchy, not 
under the "comp.lang" one, hence I was not able to find it.

Regards,

Luca Morandini
http://www.lucamorandini.it


From lyolya at gmail.com  Sun Jun 12 14:02:00 2011
From: lyolya at gmail.com (Lyolya)
Date: Sun, 12 Jun 2011 13:02:00 +0100
Subject: [R-sig-Geo] a krige.conv() question :: covariance parameters
In-Reply-To: <alpine.DEB.2.00.1106100803160.25282@macalan.c3sl.ufpr.br>
References: <BANLkTimF_TMP3ZOfyEOWhBFuHh=AS45bEw@mail.gmail.com>
	<alpine.DEB.2.00.1106100803160.25282@macalan.c3sl.ufpr.br>
Message-ID: <BANLkTinyK4=1Ss6W8j=4WGmEzYcS0EojYQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110612/5f3aaa6a/attachment.pl>

From matteo.mattiuzzi at boku.ac.at  Sun Jun 12 14:40:37 2011
From: matteo.mattiuzzi at boku.ac.at (Matteo Mattiuzzi)
Date: Sun, 12 Jun 2011 14:40:37 +0200
Subject: [R-sig-Geo] Antw: Supervised landscape classification	 according to
	NDVI time series
Message-ID: <4DF4CFE5020000270000EF53@gwia2.boku.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110612/d6b67490/attachment.pl>

From m.fairbrother at bristol.ac.uk  Mon Jun 13 10:48:43 2011
From: m.fairbrother at bristol.ac.uk (Malcolm Fairbrother)
Date: Mon, 13 Jun 2011 09:48:43 +0100
Subject: [R-sig-Geo] Generating geo-statistical data
In-Reply-To: <mailman.13.1307700003.21127.r-sig-geo@r-project.org>
References: <mailman.13.1307700003.21127.r-sig-geo@r-project.org>
Message-ID: <5BDAA122-DEBE-42A4-B855-DA4F2BD0658A@bristol.ac.uk>

Dear Luca,

Are you looking for something like this?

N <- 300 # set the number of units
W <- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N)) # build a connectivity matrix, randomly
W <- W + t(W) # make the connectivity matrix symmetrical
W <- W/apply(W, 1, sum) # row-standardise the connectivity matrix (make rows sum to 1)
rho <- 0.2 # set the level of autocorrelation
y <- solve(diag(N) - rho*W) %*% rnorm(N, 1, 1) # generate y data with mean 1, sd 1 (prior to "spatialisation")
library(spdep) # for lagarlm below
lagsarlm(y ~ 1, listw=mat2listw(W)) # check that parameters can be recovered (subject to random simulation error)

Cheers,
Malcolm



> Date: Thu, 09 Jun 2011 12:28:52 +0200
> From: Luca Morandini <luca.morandini1 at gmail.com>
> To: R-sig-geo <r-sig-geo at r-project.org>
> Subject: [R-sig-Geo] Generating geo-statistical data
> Message-ID: <4DF0A064.8070505 at gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
> 
> Folks,
> 
> I would like to generate, for educational purpose, data with a set level of 
> auto-correlation; that is, I would like to generate Zs that exhibit an higher 
> correlation with points that are closer to their locations.
> 
> One method I've found out in "Statistical methods for spatial data analysis" is 
> the use of convolutions (in the sense of "smoothers"), that is, to generate random 
> Zs and then compute Z2s as Z + (some weight based on neighbouring points).
> 
> Of curse this would work, but, ideally, I would like to set a level of 
> autocorrelation and then have a function generating data with (about) that 
> level... any suggestion ?
> 
> Regards,
> 
> Luca Morandini
> http://www.lucamorandini.it


From lmorandini at ieee.org  Mon Jun 13 15:33:57 2011
From: lmorandini at ieee.org (Luca Morandini)
Date: Mon, 13 Jun 2011 15:33:57 +0200
Subject: [R-sig-Geo] Generating geo-statistical data
In-Reply-To: <5BDAA122-DEBE-42A4-B855-DA4F2BD0658A@bristol.ac.uk>
References: <mailman.13.1307700003.21127.r-sig-geo@r-project.org>
	<5BDAA122-DEBE-42A4-B855-DA4F2BD0658A@bristol.ac.uk>
Message-ID: <it53k4$am5$1@dough.gmane.org>

On 06/13/2011 10:48 AM, Malcolm Fairbrother wrote:
> Dear Luca,
>
> Are you looking for something like this?
>
> N<- 300 # set the number of units
> W<- matrix(rbinom(N^2, 1, 0.25), N, N)*upper.tri(matrix(1, N, N)) # build a connectivity matrix, randomly
> W<- W + t(W) # make the connectivity matrix symmetrical
> W<- W/apply(W, 1, sum) # row-standardise the connectivity matrix (make rows sum to 1)
> rho<- 0.2 # set the level of autocorrelation
> y<- solve(diag(N) - rho*W) %*% rnorm(N, 1, 1) # generate y data with mean 1, sd 1 (prior to "spatialisation")
> library(spdep) # for lagarlm below
> lagsarlm(y ~ 1, listw=mat2listw(W)) # check that parameters can be recovered (subject to random simulation error)

Thanks for the suggestion Malcolm, but I'd rather use the solution suggested by 
Caspar Hallman, since I've found it more straightforward.

Actually, I have implemented it in a more verbose form:

#
# Generates an instance of a spatial process over a grid
# of <ncol> columns and <ncol> rows,  having <step> size each.
# The spatial process has <avg> mean and <sd> standard deviation
#
pp.generate2 <- function (ncol, step, avg, sd) {

   pp<-list()
   npoints<-ncol * ncol

   # Sets X and Y coordinates of point process
   for(i in 1:ncol) {
     for(j in 1:ncol) {
       pp$x[(i - 1) * ncol + j]<-(i * step)
       pp$y[(i - 1) * ncol + j]<-(j * step)
     }
   }

   # Generates the variance-covariance matrix
   # that fades with distance
   cor<-matrix(0, ncol=npoints, nrow=npoints)
   for(h in 1:npoints) {
     for(k in h:npoints) {
       cor[h, k]<-0.5^(pp.dist(pp, h, k))
     }
   }
   cor<-cor + t(cor)
   diag(cor)<-rep(1, npoints)
   v<-rep(sd, npoints)
   pp$vc<-diag(v) %*% cor %*% diag(v)

   # Generates npoints values according to the vc variance-covariance
   # matrix with mean avg
   pp$z<-mvrnorm(1, rep(avg, npoints), pp$vc)

   return(pp)
}

Regards,

Luca Morandini
http://www.lucamorandini.it


From cfusting at gmail.com  Mon Jun 13 15:37:57 2011
From: cfusting at gmail.com (Christopher Fusting)
Date: Mon, 13 Jun 2011 09:37:57 -0400
Subject: [R-sig-Geo] RE: Supervised landscape classification according to
 NDVI time series
Message-ID: <BANLkTi=MP3LDAL+DtZrrTx6x+Pm0qb_Ocw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110613/60c43cdb/attachment.pl>

From metras.raphaelle at choisyclub.org  Mon Jun 13 18:05:55 2011
From: metras.raphaelle at choisyclub.org (=?iso-8859-1?Q?rapha=EBlle_m=E9tras?=)
Date: Mon, 13 Jun 2011 18:05:55 +0200 (CEST)
Subject: [R-sig-Geo] Import from Geodatabase
Message-ID: <20188.195.195.217.140.1307981155.squirrel@wwws.choisyclub.org>

Hello,

Sorry for my beginner question.

I have created a Personal Geodatabase (Created in ArcCatalog - ArcGIS),
with shapefiles and raster maps of my project.

I would like to import these files in R, directly from this Geodatabase.
Is it possible? I used the odbcConnectAccess2007 command from the ROBDC
package, but then I don't manage to read/open the shapefiles.

Please if you have some hints, that would be very helpful. My searches and
attempts have been unsuccesfull so far.

Thank you very much, best wishes,

Raphaelle


From afischbach at usgs.gov  Mon Jun 13 20:42:02 2011
From: afischbach at usgs.gov (afischbach)
Date: Mon, 13 Jun 2011 11:42:02 -0700 (PDT)
Subject: [R-sig-Geo] Import from Geodatabase
In-Reply-To: <20188.195.195.217.140.1307981155.squirrel@wwws.choisyclub.org>
References: <20188.195.195.217.140.1307981155.squirrel@wwws.choisyclub.org>
Message-ID: <1307990522197-6471298.post@n2.nabble.com>

For shape files the package maptools has worked for me.

require(rgdal) 
require(maptools)

prj <- CRS("+proj=aeqd +lat_0=70 +lon_0=-170")  #Azimuthal Equadistant -170,
70
fileName <- 'YourShapeFile.shp'
shape=readShapeLines(fileName, proj4string=prj, verbose=FALSE, repair=FALSE,
delete_null_obj=FALSE)

For ASCII rasters the package sp works well.

require (sp)
map <- readGDAL( 'Your_ASCII_raster.asc')

Being able to pull in ArcGIS personal geodatabase features would be nice to
do.

-----
Tony Fischbach, Wildlife Biologist
Walrus Research Program
Alaska Science Center
U.S. Geological Survey
4210 University Drive
Anchorage, AK 99508-4650

AFischbach at usgs.gov
http://alaska.usgs.gov/science/biology/walrus
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Import-from-Geodatabase-tp6470731p6471298.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Mon Jun 13 21:09:02 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 13 Jun 2011 21:09:02 +0200 (CEST)
Subject: [R-sig-Geo] Import from Geodatabase
In-Reply-To: <1307990522197-6471298.post@n2.nabble.com>
References: <20188.195.195.217.140.1307981155.squirrel@wwws.choisyclub.org>
	<1307990522197-6471298.post@n2.nabble.com>
Message-ID: <alpine.LRH.2.00.1106132057450.15150@reclus.nhh.no>

On Mon, 13 Jun 2011, afischbach wrote:

> For shape files the package maptools has worked for me.
>
> require(rgdal)
> require(maptools)
>
> prj <- CRS("+proj=aeqd +lat_0=70 +lon_0=-170")  #Azimuthal Equadistant -170,
> 70
> fileName <- 'YourShapeFile.shp'
> shape=readShapeLines(fileName, proj4string=prj, verbose=FALSE, repair=FALSE,
> delete_null_obj=FALSE)
>
> For ASCII rasters the package sp works well.
>
> require (sp)
> map <- readGDAL( 'Your_ASCII_raster.asc')
>
> Being able to pull in ArcGIS personal geodatabase features would be nice to
> do.

As you may be aware, personal geodatabase are MS Access-based objects, and 
are being replaced by ESRI with file-geodatabase solutions (if I 
understand correctly). There is no effective cross-platform support for 
personal geodatabases anywhere, and in practice they are very bloated, 
contain multiple copies of the same information, and generally not 
portable. For interfacing any other software than ESRI on the same 
platform and architecture, they are not a helpful solution, and the open 
source world has abandoned attempts to try to reverse engineer them - see 
notes in the OGR part of GDAL as implemented in rgdal.

As ESRI moves towards openly documented data storage standards, we may be 
able to interface more easily, for example, ESRI now used GDAL for reading 
and writing rasters for which it doesn't have its own support, and is 
active in improving code. So look at the drivers available in rgdal for 
raster and vector objects in rgdal: ogrDrivers() and gdalDrivers(), and 
export data from Arc in those formats if you want to avoid unnecessary 
delay; think workflow before committing to a choice of format.

Roger

>
> -----
> Tony Fischbach, Wildlife Biologist
> Walrus Research Program
> Alaska Science Center
> U.S. Geological Survey
> 4210 University Drive
> Anchorage, AK 99508-4650
>
> AFischbach at usgs.gov
> http://alaska.usgs.gov/science/biology/walrus
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Import-from-Geodatabase-tp6470731p6471298.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Mon Jun 13 22:56:55 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Mon, 13 Jun 2011 22:56:55 +0200
Subject: [R-sig-Geo] Supervised landscape classification according to
 NDVI time series
In-Reply-To: <BANLkTi=MP3LDAL+DtZrrTx6x+Pm0qb_Ocw@mail.gmail.com>
References: <BANLkTi=MP3LDAL+DtZrrTx6x+Pm0qb_Ocw@mail.gmail.com>
Message-ID: <4DF67997.7010705@uni-muenster.de>



On 06/13/2011 03:37 PM, Christopher Fusting wrote:
> Second, have a look at the CRAN 'spacetime' package for R.  Although this
> will not solve your query, it may offer a different perspective.

Looking at packages is always good advice. There was also some discussion at

https://stat.ethz.ch/pipermail/r-sig-geo/2011-April/011599.html

about dealing with spatio-temporal multi-spectral data. Referenced space
and time are there, band width you'll have to deal with yourself.
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From paul.hiemstra at knmi.nl  Tue Jun 14 09:52:45 2011
From: paul.hiemstra at knmi.nl (Paul Hiemstra)
Date: Tue, 14 Jun 2011 07:52:45 +0000
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <1307767094157-6464547.post@n2.nabble.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>	<9B597DE5AF080D418509A7E9F1E93EAF0207C9FB@Exch2010MB-3.univ.dir.wwu.edu>
	<1307767094157-6464547.post@n2.nabble.com>
Message-ID: <4DF7134D.2070708@knmi.nl>

 On 06/11/2011 04:38 AM, Robert Hijmans wrote:
>> Is there any way to 
>> get a common color scheme 
>> (i.e., setting common min and max values)? 
> Here is yet another way:
>
> library(raster)
> foo <- raster(nrows=20, ncols=20) 
> values(foo) <- runif(400) 
> bar <- raster(nrows=20, ncols=20) 
> values(bar) <- runif(400) 
> s <- stack(foo, bar, foo*2)
>
> # first sample large rasters:
> x <- sampleRegular(s, 25000, asRaster=T)
>
> # then use spplot
> spplot(as(x, 'SpatialGridDataFrame'))
>
>
> # I have added two functions to raster version 1.8-33 
> # a generic function for spplot and Raster objects
> # that does the same as the example above in one short line:
>
> spplot(s)
>
> # and a wrapper around ggplot (called gplot),
> # based on Paul's example, that allows you to do things like:
>
> theme_set(theme_bw())

Hi Robert,

So gplot performs the data transformation from RasterLayer to
data.frame? For plotting polygons look at ?fortify.SpatialPolygons. This
function translates SpatialPolygons (and SpatialLines) to a data.frame
which can be used by geom_polygon or geom_path. In pseudo-code:

poly_df = fortify(poly_spatial, region = 'some_id')
ggplot(aes(x = x, y = y, fill = z), data = somedata) + geom_tile() +
geom_path(aes(group = group), data = poly_df)

cheers,
Paul

> gplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
>             scale_fill_gradient(low = 'white', high = 'blue') +
> coord_equal()
>
>
> Robert
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-plot-common-color-scale-tp6457926p6464547.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Paul Hiemstra, Ph.D.
Global Climate Division
Royal Netherlands Meteorological Institute (KNMI)
Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
P.O. Box 201 | 3730 AE | De Bilt
tel: +31 30 2206 494

http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From csfowler at uw.edu  Tue Jun 14 20:35:00 2011
From: csfowler at uw.edu (Christopher S. Fowler)
Date: Tue, 14 Jun 2011 11:35:00 -0700
Subject: [R-sig-Geo] Calculating point density
Message-ID: <BANLkTi=3iWHqn5Mk9MWcf9XN20H816T0og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110614/525cc824/attachment.pl>

From renaud.lancelot at gmail.com  Tue Jun 14 22:26:17 2011
From: renaud.lancelot at gmail.com (Renaud Lancelot)
Date: Tue, 14 Jun 2011 22:26:17 +0200
Subject: [R-sig-Geo] spplot: character size of color key labels
Message-ID: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>

Dear all,

How can I control the character size  of color key labels produced by
spplot ? I have unsucessfully tried to use cex, as in

spplot(obj, zcol = "var1",
             panel = function(...){
                 panel.polygonsplot(...)
                 sp.text(coordinates(obj), txt = as.character(obj at data$z))
             },
             cex = 1.5)

All the best,

Renaud
-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel. ?+33 4 67 59 37 17 ?- ?Fax ?+33 4 67 59 37 95
Secr. +33 4 67 59 37 37 ?- Cell. +33 6 77 52 08 69


From r.turner at auckland.ac.nz  Tue Jun 14 22:36:50 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 15 Jun 2011 08:36:50 +1200
Subject: [R-sig-Geo] Calculating point density
In-Reply-To: <BANLkTi=3iWHqn5Mk9MWcf9XN20H816T0og@mail.gmail.com>
References: <BANLkTi=3iWHqn5Mk9MWcf9XN20H816T0og@mail.gmail.com>
Message-ID: <4DF7C662.3060703@auckland.ac.nz>

On 15/06/11 06:35, Christopher S. Fowler wrote:
> I am working out a comparison of results for point pattern analysis using
> ArcGIS and R, specifically the spatstat package. One of the key functions
> for density calculations in ArcGIS is "Point Density" which counts the
> points within a given distance (r) of the centroid of each cell in a raster
> grid and divides it by the area of circle with radius r. The closest
> equivalent I have found is the density.ppp function in spatstat, but that is
> kernel density. Am I correct in thinking that this "reverses" the process of
> point density and assigns a contribution value extending out from each point
> in the data consistent with the function specified in the bandwidth
> variable?
>
> Any suggestions on the location of an appropriate point density function, or
> barring that, the reason for preferring kernel density to point density.

As the help for density.ppp() says, this function uses an isotropic Gaussian
kernel of standard deviation sigma. Its value at "x" is in effect the sum of
k(x - x_i) where k() is the kernel and the x_i are the points of the pattern
in question (although internally it use fast Fourier transform methods 
rather
than calculating this sum directly).

Thus the value at "x" is a sum of weights associated with each point of the
pattern, with the weights diminishing as the distance of points of the 
pattern
from "x" increases.

Note that the integral of the resulting density over the observation window
is ``theoretically'' equal to the number of points observed in the window,
but is in fact slightly less.

     cheers,

         Rolf Turner


From edzer.pebesma at uni-muenster.de  Tue Jun 14 23:52:03 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 14 Jun 2011 23:52:03 +0200
Subject: [R-sig-Geo] spplot: character size of color key labels
In-Reply-To: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>
References: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>
Message-ID: <4DF7D803.1090705@uni-muenster.de>

Renaud, as spplot is a wrapper around xyplot or levelplot in package
lattice, try to pass par.settings as a list; its contents can be learned
from:

library(lattice)
trellis.par.get()
?trellis.par.set

an example is:

xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=T,par.settings=list(fontsize=list(text=20)))
# read arg par.settings in ?xyplot

as you can see, it resizes all other characters as well. No doubt there
is a way to do this more fine grained.

This may be personal, but I find myself rarely (if ever) in need of
this. Font sizes can be manipulated to some extent indirectly by
changing the size of the plotting region.

Hth,

On 06/14/2011 10:26 PM, Renaud Lancelot wrote:
> Dear all,
> 
> How can I control the character size  of color key labels produced by
> spplot ? I have unsucessfully tried to use cex, as in
> 
> spplot(obj, zcol = "var1",
>              panel = function(...){
>                  panel.polygonsplot(...)
>                  sp.text(coordinates(obj), txt = as.character(obj at data$z))
>              },
>              cex = 1.5)
> 
> All the best,
> 
> Renaud

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From Adrian.Baddeley at csiro.au  Wed Jun 15 03:17:04 2011
From: Adrian.Baddeley at csiro.au (Adrian.Baddeley at csiro.au)
Date: Wed, 15 Jun 2011 09:17:04 +0800
Subject: [R-sig-Geo] Calculating point density
In-Reply-To: <4DF7C662.3060703@auckland.ac.nz>
References: <BANLkTi=3iWHqn5Mk9MWcf9XN20H816T0og@mail.gmail.com>,
	<4DF7C662.3060703@auckland.ac.nz>
Message-ID: <57DC18C299094D4299F837570C5DF1C53AAA303C2A@EXWA-MBX01.nexus.csiro.au>

The calculation of PointDensity described by Chris Fowler is *equivalent* to a kernel density estimator. The kernel k(v) is equal to 1/(pi*r^2) when v is inside the circle of radius r centred at the origin 0, and k(v) = 0 otherwise. 

There are theoretical reasons for preferring a smooth kernel instead of the discontinuous kernel used in PointDensity. There are practical advantages in using the Gaussian kernel - mainly that the density estimate can be computed rapidly using the Fast Fourier Transform. The relative merits of different density estimators are discussed in books on density estimation, e.g. Silverman 1986

Adrian Baddeley
________________________________________
From: Rolf Turner [r.turner at auckland.ac.nz]
Sent: Wednesday, 15 June 2011 4:36 AM
To: Christopher S. Fowler
Cc: r-sig-geo at r-project.org; Baddeley, Adrian (CMIS, Floreat)
Subject: Re: [R-sig-Geo] Calculating point density

On 15/06/11 06:35, Christopher S. Fowler wrote:
> I am working out a comparison of results for point pattern analysis using
> ArcGIS and R, specifically the spatstat package. One of the key functions
> for density calculations in ArcGIS is "Point Density" which counts the
> points within a given distance (r) of the centroid of each cell in a raster
> grid and divides it by the area of circle with radius r. The closest
> equivalent I have found is the density.ppp function in spatstat, but that is
> kernel density. Am I correct in thinking that this "reverses" the process of
> point density and assigns a contribution value extending out from each point
> in the data consistent with the function specified in the bandwidth
> variable?
>
> Any suggestions on the location of an appropriate point density function, or
> barring that, the reason for preferring kernel density to point density.

As the help for density.ppp() says, this function uses an isotropic Gaussian
kernel of standard deviation sigma. Its value at "x" is in effect the sum of
k(x - x_i) where k() is the kernel and the x_i are the points of the pattern
in question (although internally it use fast Fourier transform methods
rather
than calculating this sum directly).

Thus the value at "x" is a sum of weights associated with each point of the
pattern, with the weights diminishing as the distance of points of the
pattern
from "x" increases.

Note that the integral of the resulting density over the observation window
is ``theoretically'' equal to the number of points observed in the window,
but is in fact slightly less.

     cheers,

         Rolf Turner


From renaud.lancelot at cirad.fr  Wed Jun 15 09:06:27 2011
From: renaud.lancelot at cirad.fr (lancelot)
Date: Wed, 15 Jun 2011 09:06:27 +0200
Subject: [R-sig-Geo] spplot: character size of color key labels
In-Reply-To: <4DF7D803.1090705@uni-muenster.de>
References: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>
	<4DF7D803.1090705@uni-muenster.de>
Message-ID: <4DF859F3.6030405@cirad.fr>

Thank you Edzer, it works fine with spplot.

Renaud

Le 14/06/2011 23:52, Edzer Pebesma a ?crit :
> Renaud, as spplot is a wrapper around xyplot or levelplot in package
> lattice, try to pass par.settings as a list; its contents can be learned
> from:
>
> library(lattice)
> trellis.par.get()
> ?trellis.par.set
>
> an example is:
>
> xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=T,par.settings=list(fontsize=list(text=20)))
> # read arg par.settings in ?xyplot
>
> as you can see, it resizes all other characters as well. No doubt there
> is a way to do this more fine grained.
>
> This may be personal, but I find myself rarely (if ever) in need of
> this. Font sizes can be manipulated to some extent indirectly by
> changing the size of the plotting region.
>
> Hth,
>
> On 06/14/2011 10:26 PM, Renaud Lancelot wrote:
>> Dear all,
>>
>> How can I control the character size  of color key labels produced by
>> spplot ? I have unsucessfully tried to use cex, as in
>>
>> spplot(obj, zcol = "var1",
>>               panel = function(...){
>>                   panel.polygonsplot(...)
>>                   sp.text(coordinates(obj), txt = as.character(obj at data$z))
>>               },
>>               cex = 1.5)
>>
>> All the best,
>>
>> Renaud
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From idhamkhalil at gmail.com  Wed Jun 15 11:28:22 2011
From: idhamkhalil at gmail.com (idham khalil)
Date: Wed, 15 Jun 2011 10:28:22 +0100
Subject: [R-sig-Geo] How to calculate slope in rasterbrick
Message-ID: <BANLkTinAmZAJo0LZm5=nm_Vehsv+8EqG+A@mail.gmail.com>

Hi Guys,

Sorry if this is a vey simple question.

I have a brick that contains 348 layers. Each layer is small in
dimension ncol=69, nrow=43. My question is, how do I calculate slopes
for each pixels from layer 1 to layer 348(Month one to months 348). I
am trying to find the trend as I am working with time series data.

Thanks in advance.


From eddieatr at gmail.com  Wed Jun 15 13:27:13 2011
From: eddieatr at gmail.com (eddie smith)
Date: Wed, 15 Jun 2011 12:27:13 +0100
Subject: [R-sig-Geo] Raster regression cooeficients plot?
Message-ID: <BANLkTikYj+E8A7dtNgWgrijPChASTEZFQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110615/f5bad818/attachment.pl>

From alobolistas at gmail.com  Wed Jun 15 16:26:03 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 15 Jun 2011 16:26:03 +0200
Subject: [R-sig-Geo] rastrer::raster no extent argument?
Message-ID: <BANLkTinGG73Szf01dYGeeMv_HMdtb9dk0w@mail.gmail.com>

Hi!

In order to define an arbitrary test raster object, I thought I could do:
> foo4 <- raster(nrows=20, ncols=20,crs=NA,extent=c(0,20,0,20))
> values(foo4) <- runif(400,-100,150)

but extent is not a valid argument, so I use another step
> foo4 <- raster(nrows=20, ncols=20,crs=NA)
> values(foo4) <- runif(400,-100,150)
> extent(foo4) = extent(c(0,20,0,20))

Would not make sense adding this feature to raster() itself?

Agus


From alobolistas at gmail.com  Wed Jun 15 16:59:33 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 15 Jun 2011 16:59:33 +0200
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <4DF1FE07.4070707@knmi.nl>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
	<4DF1FE07.4070707@knmi.nl>
Message-ID: <BANLkTikE02Tb+MBQPJ18khrJjp8McH4_wg@mail.gmail.com>

Paul,

While this is certainly the most elegant solution, would it work with
really large raster objects? Note that you
make a data.frame, and the most important characteristic of package
raster is its ability to do not incorporate
the actual raster values to the raster objects to save memory.

Would this problem be avoided by the new wrapper provided by Robert?

Thanks

Agus

2011/6/10 Paul Hiemstra <paul.hiemstra at knmi.nl>:
> ?Hi,
>
> I would recommend using one of the more advanced plotting facilities in
> R, ggplot. An example:
>
> library(ggplot2)
> library(raster)
> theme_set(theme_bw())
>
> r = raster(system.file("external/test.grd", package="raster"))
>
> # Convert to data.frame
> r_df = as.data.frame(as(r, 'SpatialPixelsDataFrame'))
> # create new column 10 times larger
> # here you could extract data from other grids that
> # you want to show at the same time
> r_df$valuesx10 = r_df$values*2
>
> # Reshape the data for ggplot
> plotData = melt(r_df, id.vars = c('x','y'))
>
> ggplot(aes(x = x, y = y), data = plotData) +
> ? ?geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
> ? ?scale_fill_gradient(low = 'white', high = 'blue') +
> ? ?coord_equal()
>
> This is a basic ggplot example of visualizing rasters. I realize that it
> is a short example with a lot of things specific to ggplot, but I hope
> you can figure out why I use the code that I use. In my view, the
> investment in learning to use ggplot is worth it. A good place to start
> is the ggplot website [1].
>
> cheers.
> Paul
>
> [1] http://had.co.nz/ggplot2/
>
> On 06/09/2011 01:59 PM, Agustin Lobo wrote:
>> Hi!
>> I'm doing
>>
>> par(mfrow=c(2,2))
>> plot(simr)
>> plot(simrlisa)
>> a2 = simr>l$lisamax
>> plot(l$lisamax)
>> plot(simr*a2)
>>
>> where simr, l%lisamax and a2 are raster objects. Is there any way to
>> get a common color scheme
>> (i.e., setting common min and max values)?
>> The color table is the same, but the scaling is independent for each
>> raster object and cannot be compared.
>>
>> Thanks
>>
>> Agus
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
> --
> Paul Hiemstra, Ph.D.
> Global Climate Division
> Royal Netherlands Meteorological Institute (KNMI)
> Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
> P.O. Box 201 | 3730 AE | De Bilt
> tel: +31 30 2206 494
>
> http://intamap.geo.uu.nl/~paul
> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770
>
>


From alobolistas at gmail.com  Wed Jun 15 17:12:25 2011
From: alobolistas at gmail.com (Agustin Lobo)
Date: Wed, 15 Jun 2011 17:12:25 +0200
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <1307767094157-6464547.post@n2.nabble.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
	<9B597DE5AF080D418509A7E9F1E93EAF0207C9FB@Exch2010MB-3.univ.dir.wwu.edu>
	<1307767094157-6464547.post@n2.nabble.com>
Message-ID: <BANLkTi=gWb0=y9bnVq6wL69K=SDcH+GxsA@mail.gmail.com>

Robert,

I've tried with raster_1.8-35
but:

other attached packages:
[1] raster_1.8-35 ggplot2_0.8.9 proto_0.3-8   reshape_0.8.4 plyr_1.4
[6] plotrix_3.2-2 sp_0.9-76     rkward_0.5.6

loaded via a namespace (and not attached):
[1] digest_0.4.2    lattice_0.19-26 tools_2.13.0


> foo1 <- foo2 <- foo3<- foo4 <- raster(nrows=20, ncols=20)
> values(foo1) <- runif(400,-100.100)
> values(foo2) <- runif(400,-150,100)
> values(foo3) <- runif(400,0,50)
> values(foo4) <- runif(400,-100,150)
> extent(foo1) = extent(foo2) = extent(foo3) = extent(foo4) = extent(c(0,20,0,20))
> s <- stack(foo1,foo2,foo3,foo4)

> spplot(as(x, 'SpatialGridDataFrame'))
Error in rk.record.plot$.save.tlo.in.hP() :
  could not find function "trellis.last.object"
Calls: print ... print -> print.trellis -> printFunction -> <Anonymous>
> spplot(s)
Error in function (classes, fdef, mtable)  :
  unable to find an inherited method for function "spplot", for
signature "RasterStack"
Calls: spplot -> <Anonymous>
> theme_set(theme_bw())
+ gplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
+            scale_fill_gradient(low = 'white', high = 'blue') +
+ coord_equal()
Error: could not find function "gplot"
> theme_set(theme_bw())
+ ggplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
+            scale_fill_gradient(low = 'white', high = 'blue') +
+ coord_equal()
Error: ggplot2 doesn't know how to deal with data of class RasterStack
>


Agus

2011/6/11 Robert Hijmans <r.hijmans at gmail.com>:
>> Is there any way to
>> get a common color scheme
>> (i.e., setting common min and max values)?
>
> Here is yet another way:
>
> library(raster)
> foo <- raster(nrows=20, ncols=20)
> values(foo) <- runif(400)
> bar <- raster(nrows=20, ncols=20)
> values(bar) <- runif(400)
> s <- stack(foo, bar, foo*2)
>
> # first sample large rasters:
> x <- sampleRegular(s, 25000, asRaster=T)
>
> # then use spplot
> spplot(as(x, 'SpatialGridDataFrame'))
>
>
> # I have added two functions to raster version 1.8-33
> # a generic function for spplot and Raster objects
> # that does the same as the example above in one short line:
>
> spplot(s)
>
> # and a wrapper around ggplot (called gplot),
> # based on Paul's example, that allows you to do things like:
>
> theme_set(theme_bw())
>
> gplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
> ? ? ? ? ? ?scale_fill_gradient(low = 'white', high = 'blue') +
> coord_equal()
>
>
> Robert
>
>
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-plot-common-color-scale-tp6457926p6464547.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From r.hijmans at gmail.com  Wed Jun 15 18:56:53 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 15 Jun 2011 09:56:53 -0700
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <BANLkTi=gWb0=y9bnVq6wL69K=SDcH+GxsA@mail.gmail.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
	<9B597DE5AF080D418509A7E9F1E93EAF0207C9FB@Exch2010MB-3.univ.dir.wwu.edu>
	<1307767094157-6464547.post@n2.nabble.com>
	<BANLkTi=gWb0=y9bnVq6wL69K=SDcH+GxsA@mail.gmail.com>
Message-ID: <BANLkTiny4ptW5fYbGG1-J-StTF7V6a2mmA@mail.gmail.com>

This works for me. It seems that the new version or raster did not get
loaded properly. Can you close & open R and try again? Perhaps without
loading the previous session. Robert

On Wed, Jun 15, 2011 at 8:12 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Robert,
>
> I've tried with raster_1.8-35
> but:
>
> other attached packages:
> [1] raster_1.8-35 ggplot2_0.8.9 proto_0.3-8 ? reshape_0.8.4 plyr_1.4
> [6] plotrix_3.2-2 sp_0.9-76 ? ? rkward_0.5.6
>
> loaded via a namespace (and not attached):
> [1] digest_0.4.2 ? ?lattice_0.19-26 tools_2.13.0
>
>
>> foo1 <- foo2 <- foo3<- foo4 <- raster(nrows=20, ncols=20)
>> values(foo1) <- runif(400,-100.100)
>> values(foo2) <- runif(400,-150,100)
>> values(foo3) <- runif(400,0,50)
>> values(foo4) <- runif(400,-100,150)
>> extent(foo1) = extent(foo2) = extent(foo3) = extent(foo4) = extent(c(0,20,0,20))
>> s <- stack(foo1,foo2,foo3,foo4)
>
>> spplot(as(x, 'SpatialGridDataFrame'))
> Error in rk.record.plot$.save.tlo.in.hP() :
> ?could not find function "trellis.last.object"
> Calls: print ... print -> print.trellis -> printFunction -> <Anonymous>
>> spplot(s)
> Error in function (classes, fdef, mtable) ?:
> ?unable to find an inherited method for function "spplot", for
> signature "RasterStack"
> Calls: spplot -> <Anonymous>
>> theme_set(theme_bw())
> + gplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
> + ? ? ? ? ? ?scale_fill_gradient(low = 'white', high = 'blue') +
> + coord_equal()
> Error: could not find function "gplot"
>> theme_set(theme_bw())
> + ggplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
> + ? ? ? ? ? ?scale_fill_gradient(low = 'white', high = 'blue') +
> + coord_equal()
> Error: ggplot2 doesn't know how to deal with data of class RasterStack
>>
>
>
> Agus
>
> 2011/6/11 Robert Hijmans <r.hijmans at gmail.com>:
>>> Is there any way to
>>> get a common color scheme
>>> (i.e., setting common min and max values)?
>>
>> Here is yet another way:
>>
>> library(raster)
>> foo <- raster(nrows=20, ncols=20)
>> values(foo) <- runif(400)
>> bar <- raster(nrows=20, ncols=20)
>> values(bar) <- runif(400)
>> s <- stack(foo, bar, foo*2)
>>
>> # first sample large rasters:
>> x <- sampleRegular(s, 25000, asRaster=T)
>>
>> # then use spplot
>> spplot(as(x, 'SpatialGridDataFrame'))
>>
>>
>> # I have added two functions to raster version 1.8-33
>> # a generic function for spplot and Raster objects
>> # that does the same as the example above in one short line:
>>
>> spplot(s)
>>
>> # and a wrapper around ggplot (called gplot),
>> # based on Paul's example, that allows you to do things like:
>>
>> theme_set(theme_bw())
>>
>> gplot(s) + geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
>> ? ? ? ? ? ?scale_fill_gradient(low = 'white', high = 'blue') +
>> coord_equal()
>>
>>
>> Robert
>>
>>
>> --
>> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/raster-plot-common-color-scale-tp6457926p6464547.html
>> Sent from the R-sig-geo mailing list archive at Nabble.com.
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>


From r.hijmans at gmail.com  Wed Jun 15 18:58:07 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 15 Jun 2011 09:58:07 -0700
Subject: [R-sig-Geo] raster::plot() common color scale?
In-Reply-To: <BANLkTikE02Tb+MBQPJ18khrJjp8McH4_wg@mail.gmail.com>
References: <BANLkTi=DEb5Qp-qen3uoYBSu5nLnESUKgQ@mail.gmail.com>
	<4DF1FE07.4070707@knmi.nl>
	<BANLkTikE02Tb+MBQPJ18khrJjp8McH4_wg@mail.gmail.com>
Message-ID: <BANLkTik0QEPfWQgxRnBncv=KuWsfZtY_7Q@mail.gmail.com>

> Would this problem be avoided by the new wrapper provided by Robert?

Yes, through its "maxpixels" argument (which has a default value).


On Wed, Jun 15, 2011 at 7:59 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Paul,
>
> While this is certainly the most elegant solution, would it work with
> really large raster objects? Note that you
> make a data.frame, and the most important characteristic of package
> raster is its ability to do not incorporate
> the actual raster values to the raster objects to save memory.
>
> Would this problem be avoided by the new wrapper provided by Robert?
>
> Thanks
>
> Agus
>
> 2011/6/10 Paul Hiemstra <paul.hiemstra at knmi.nl>:
>> ?Hi,
>>
>> I would recommend using one of the more advanced plotting facilities in
>> R, ggplot. An example:
>>
>> library(ggplot2)
>> library(raster)
>> theme_set(theme_bw())
>>
>> r = raster(system.file("external/test.grd", package="raster"))
>>
>> # Convert to data.frame
>> r_df = as.data.frame(as(r, 'SpatialPixelsDataFrame'))
>> # create new column 10 times larger
>> # here you could extract data from other grids that
>> # you want to show at the same time
>> r_df$valuesx10 = r_df$values*2
>>
>> # Reshape the data for ggplot
>> plotData = melt(r_df, id.vars = c('x','y'))
>>
>> ggplot(aes(x = x, y = y), data = plotData) +
>> ? ?geom_tile(aes(fill = value)) + facet_wrap(~ variable) +
>> ? ?scale_fill_gradient(low = 'white', high = 'blue') +
>> ? ?coord_equal()
>>
>> This is a basic ggplot example of visualizing rasters. I realize that it
>> is a short example with a lot of things specific to ggplot, but I hope
>> you can figure out why I use the code that I use. In my view, the
>> investment in learning to use ggplot is worth it. A good place to start
>> is the ggplot website [1].
>>
>> cheers.
>> Paul
>>
>> [1] http://had.co.nz/ggplot2/
>>
>> On 06/09/2011 01:59 PM, Agustin Lobo wrote:
>>> Hi!
>>> I'm doing
>>>
>>> par(mfrow=c(2,2))
>>> plot(simr)
>>> plot(simrlisa)
>>> a2 = simr>l$lisamax
>>> plot(l$lisamax)
>>> plot(simr*a2)
>>>
>>> where simr, l%lisamax and a2 are raster objects. Is there any way to
>>> get a common color scheme
>>> (i.e., setting common min and max values)?
>>> The color table is the same, but the scaling is independent for each
>>> raster object and cannot be compared.
>>>
>>> Thanks
>>>
>>> Agus
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>>
>> --
>> Paul Hiemstra, Ph.D.
>> Global Climate Division
>> Royal Netherlands Meteorological Institute (KNMI)
>> Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
>> P.O. Box 201 | 3730 AE | De Bilt
>> tel: +31 30 2206 494
>>
>> http://intamap.geo.uu.nl/~paul
>> http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770
>>
>>
>


From r.hijmans at gmail.com  Wed Jun 15 19:07:33 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 15 Jun 2011 10:07:33 -0700
Subject: [R-sig-Geo] rastrer::raster no extent argument?
In-Reply-To: <BANLkTinGG73Szf01dYGeeMv_HMdtb9dk0w@mail.gmail.com>
References: <BANLkTinGG73Szf01dYGeeMv_HMdtb9dk0w@mail.gmail.com>
Message-ID: <BANLkTi=dh+OCyUJ=eFJ56s0m0aR9Chrdog@mail.gmail.com>

Agus,

You can do:

foo4 <- raster(nrows=20, ncols=20,crs=NA,extent(0,20,0,20))

#which is the same as
foo4 <- raster(x=extent(0,20,0,20), nrows=20, ncols=20, crs=NA )

#or
foo4 <- raster(nrows=20, ncols=20,crs=NA, xmn=0, xmx=20, ymn=0, ymx=20)

What I will add to the package is the ability to do

foo4 <- raster(nrows=20, ncols=20,crs=NA, ext=c(0,20,0,20))

i.e. ext in stead of xmn, xmx, ymn, ymx. (I am standardizing on "ext"
as the argument name for Extent objects)

Best, Robert


On Wed, Jun 15, 2011 at 7:26 AM, Agustin Lobo <alobolistas at gmail.com> wrote:
> Hi!
>
> In order to define an arbitrary test raster object, I thought I could do:
>> foo4 <- raster(nrows=20, ncols=20,crs=NA,extent=c(0,20,0,20))
>> values(foo4) <- runif(400,-100,150)
>
> but extent is not a valid argument, so I use another step
>> foo4 <- raster(nrows=20, ncols=20,crs=NA)
>> values(foo4) <- runif(400,-100,150)
>> extent(foo4) = extent(c(0,20,0,20))
>
> Would not make sense adding this feature to raster() itself?
>
> Agus
>


From r.hijmans at gmail.com  Wed Jun 15 19:53:44 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 15 Jun 2011 10:53:44 -0700 (PDT)
Subject: [R-sig-Geo] Raster regression cooeficients plot?
In-Reply-To: <BANLkTikYj+E8A7dtNgWgrijPChASTEZFQA@mail.gmail.com>
References: <BANLkTikYj+E8A7dtNgWgrijPChASTEZFQA@mail.gmail.com>
Message-ID: <1308160424716-6479923.post@n2.nabble.com>

> I am analysing monthly time series data using rasterbrick.
> Commands below give me one slope plot
>
> fun <- function(x) { lm(x ~ time)$coefficients[2] }
> slope <- calc(s, fun)
> plot(slope)
>
>
> But what other 7 plots means when I run these lines...
> fun <- function(x) { lm(x ~ time)$coefficients }
> ?x3<- calc(s, fun)
> plot(x3)

I do not know, because I do not know what "time" refers to. My guess is that
it is a factor with 6 levels as that would give you 7 coefficients
(intercept + 6). 

This might be clear from the layerNames of x3 (shown as the titles of the
plots). 
perhaps this becomes clear if you do:

m <- lm( as.vector(x[1]) ~ time) # assuming that the first cell does not
only have NA values
m$coefficients 
str(m)


If you want an intercept and slope, time should be numeric. For example,
here:

time <- 1:nlayers(s)
fun <- function(x) { lm(x ~ time)$coefficients }
x4 <- calc(s, fun)

should return 2 layers.


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Raster-regression-cooeficients-plot-tp6478377p6479923.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Wed Jun 15 20:00:36 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 15 Jun 2011 11:00:36 -0700 (PDT)
Subject: [R-sig-Geo] How to calculate slope in rasterbrick
In-Reply-To: <BANLkTinAmZAJo0LZm5=nm_Vehsv+8EqG+A@mail.gmail.com>
References: <BANLkTinAmZAJo0LZm5=nm_Vehsv+8EqG+A@mail.gmail.com>
Message-ID: <1308160836491-6479946.post@n2.nabble.com>

> I have a brick that contains 348 layers. Each layer is small in 
> dimension ncol=69, nrow=43. My question is, how do I calculate slopes 
> for each pixels from layer 1 to layer 348(Month one to months 348). I 
> am trying to find the trend as I am working with time series data. 


for RasterBrick 'b'

time <- 1:nlayers(b)
fun <- function(x) { lm(x ~ time)$coefficients[2] }
x <- calc(b, fun)

x is a RasterLayer with the slope of a linear regression model for each
cell.

Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/How-to-calculate-slope-in-rasterbrick-tp6478027p6479946.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Wed Jun 15 20:35:28 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 15 Jun 2011 11:35:28 -0700 (PDT)
Subject: [R-sig-Geo] Supervised landscape classification according to
 NDVI time series
In-Reply-To: <4DF32AD3.8000704@gmail.com>
References: <4DF32AD3.8000704@gmail.com>
Message-ID: <1308162928514-6480065.post@n2.nabble.com>

> From what I understood, most landscape classification methods available 
> from GRASS (through R) do not account for the temporaI aspect of 
> spectrum. So for example, if you have a raster where each band 
> represents NDVI values at a given date, from March to September for 
> example, the classification will not consider that values are 
> time-dependant. I would like to use time series of NDVI values to 
> classify pixels in different type of crop, accordingly to the shape of 
> each time series (rapeseed will not present the same NDVI time serie as 
> would alfalfa or wheat). 
> I was wondering if someone could point me to a method that would allow 
> such classification using R ? I started looking at Functional Data 
> Analysis but I must admit that I'm a bit lost at the moment. 

If you want to ignore the problem that Matteo mentions (i.e. that temporal
signatures of a crop will vary over space), perhaps because you are working
with a relatively homogeneous (small & flat) geographic area, you can use a
number of (machine learning) algorithms. Chris mentioned CART, below is an
example using RandomForest, which is more powerful; indeed treating time as
'bands'. 

library(raster)

# monthly NDVI values (12 rasters)
r <- raster(ncol=20, nrow=20, extent(0,20,0,20))
s <- stack(lapply(1:12, function(x) setValues(r, runif(ncell(r)))))
layerNames(s) <- c('jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug',
'sep', 'oct', 'nov', 'dec')
s

#'ground truth' for 30 points, and 3 crops 
xy <- matrix(runif(60), ncol=2) * 20
crop <- factor(rep(1:3, each=10))
xyNDVI <- data.frame(crop, extract(s, xy))

library(randomForest)

# fit a model
m <- randomForest(crop~., data=xyNDVI)

# make a prediction
x <- predict(s, m)
plot(x)

Hth, Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Supervised-landscape-classification-according-to-NDVI-time-series-tp6464837p6480065.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From freddy.vate01 at gmail.com  Thu Jun 16 04:36:08 2011
From: freddy.vate01 at gmail.com (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Wed, 15 Jun 2011 22:06:08 -0430
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
Message-ID: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>

Hello guys,

I think this question is in the border: r-sig-geo or grass-user list...

I want to do some interpolation using GRASS' graphical features but
using code and libraries written in R and I'm trying to follow section
10.2.1 from 3rd edition GRASS BOOK (Open Source GIS: A GRASS GIS
Approach).

I create a location into GRASS, venest3, apparently with no problem
and I can plot it using d.vect.

After starting R and run the readVECT6 function I get

> readVECT6('venest3')
Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
input_field_name_encoding) :
?Cannot open layer

I have experimented using the spearfish60 file and it works perfectly
(I selected randomly geology...):

> readVECT6('geology'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/spearfish60/PERMANENT/vector/geology/head",
layer: "1"
with 422 features and 2 fields
Feature type: wkbPolygon with 2 dimensions
...


Both locations (venest3 and spearfish60), inside its 'vector'
directory have the same six files: cidx, coor, dbln, head, hist, topo.

Have you any ideas how can I solve this situation? How to read my vector data?

Thanks in advance.-


--
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From eddieatr at gmail.com  Thu Jun 16 10:29:13 2011
From: eddieatr at gmail.com (eddie)
Date: Thu, 16 Jun 2011 01:29:13 -0700 (PDT)
Subject: [R-sig-Geo] Raster regression cooeficients plot?
In-Reply-To: <1308160424716-6479923.post@n2.nabble.com>
References: <BANLkTikYj+E8A7dtNgWgrijPChASTEZFQA@mail.gmail.com>
	<1308160424716-6479923.post@n2.nabble.com>
Message-ID: <1308212953956-6482176.post@n2.nabble.com>

Dear Robert, 

Thank you very much for your reply. Sorry for not giving you enough
information in order for you to give comments on what are the 8 coefficients
generated. The full code is as below. My rasterbrick contains 365 layers. 

library(raster)
setwd("C:/mydata")
getwd()
# define raster layer
r <- raster(ncol=69, nrow=43, xmn=96.5, xmx=165.5, ymn=-16.5, ymx=26.5)
# build rasterstack and then rasterbrick
s = stack(list.files(pattern='*.rst'))
b = brick(s)
# fit linear model
time <- 1:nlayers(b) 
fun=function(x) { if (is.na(x[1])){ NA } else { m = lm(x ~ time);
summary(m)$coefficients}}
x3 <- calc(b, fun)
plote(x3)
# end

Thank you.


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Raster-regression-cooeficients-plot-tp6478377p6482176.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Thu Jun 16 11:24:06 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Thu, 16 Jun 2011 02:24:06 -0700 (PDT)
Subject: [R-sig-Geo] Raster regression cooeficients plot?
In-Reply-To: <1308212953956-6482176.post@n2.nabble.com>
References: <BANLkTikYj+E8A7dtNgWgrijPChASTEZFQA@mail.gmail.com>
	<1308160424716-6479923.post@n2.nabble.com>
	<1308212953956-6482176.post@n2.nabble.com>
Message-ID: <BANLkTimcC4u3agwrKTtobws-=rCuekcfmQ@mail.gmail.com>

Hi Eddie,

Consider this:

> set.seed(0)
> y = runif(365)
> time = 1:365
> m = lm(y~time)
> m$coefficients
(Intercept)          time
 0.5297172419 -0.0001886475

But you do:

> summary(m)$coefficients

                 Estimate   Std. Error   t value     Pr(>|t|)
(Intercept)  0.5297172419 0.0292052249 18.137756 8.474764e-53
time        -0.0001886475 0.0001383047 -1.363999 1.734129e-01

Hence the 8 layers
> as.vector(summary(m)$coefficients)
[1]  5.297172e-01 -1.886475e-04  2.920522e-02  1.383047e-04
1.813776e+01 -1.363999e+00  8.474764e-53  1.734129e-01

I think you want to use this function (like the one in your original message!)

fun = function(x) { if (is.na(x[1])) { c(NA,NA) } else { lm(x ~
time)$coefficients } }

Note the two NA values such that the function always returns the same
number of values.
Before you use it in calc, you can first test it to see if it returns
what you expect

> fun(runif(365))
  (Intercept)          time
 0.5306391079 -0.0001631673


> funold=function(x) { if (is.na(x[1])){ NA } else { m = lm(x ~ time);summary(m)$coefficients}}
> funold(runif(365))
                 Estimate  Std. Error    t value     Pr(>|t|)
(Intercept)  4.814148e-01 0.030698435 15.6820636 1.099704e-42
time        -3.910719e-05 0.000145376 -0.2690073 7.880769e-01
>

Best, Robert


On Thu, Jun 16, 2011 at 1:29 AM, eddie [via R-sig-geo]
<ml-node+6482176-1417003307-149542 at n2.nabble.com> wrote:
> Dear Robert,
>
> Thank you very much for your reply. Sorry for not giving you enough
> information in order for you to give comments on what are the 8 coefficients
> generated. The full code is as below. My rasterbrick contains 365 layers.
>
> library(raster)
> setwd("C:/mydata")
> getwd()
> # define raster layer
> r <- raster(ncol=69, nrow=43, xmn=96.5, xmx=165.5, ymn=-16.5, ymx=26.5)
> # build rasterstack and then rasterbrick
> s = stack(list.files(pattern='*.rst'))
> b = brick(s)
> # fit linear model
> time <- 1:nlayers(b)
> fun=function(x) { if (is.na(x[1])){ NA } else { m = lm(x ~ time);
> summary(m)$coefficients}}
> x3 <- calc(b, fun)
> plote(x3)
> # end
>
> Thank you.
>
>
> ________________________________
> If you reply to this email, your message will be added to the discussion
> below:
> http://r-sig-geo.2731867.n2.nabble.com/Raster-regression-cooeficients-plot-tp6478377p6482176.html
> To unsubscribe from Raster regression cooeficients plot?, click here.


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Raster-regression-cooeficients-plot-tp6478377p6482308.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From mathieu.rajerison at gmail.com  Thu Jun 16 11:33:44 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 16 Jun 2011 11:33:44 +0200
Subject: [R-sig-Geo] Assign a point to its nearest polygon
Message-ID: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/d947a2af/attachment.pl>

From paul.hiemstra at knmi.nl  Thu Jun 16 11:48:35 2011
From: paul.hiemstra at knmi.nl (Paul Hiemstra)
Date: Thu, 16 Jun 2011 09:48:35 +0000
Subject: [R-sig-Geo] Assign a point to its nearest polygon
In-Reply-To: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>
References: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>
Message-ID: <4DF9D173.7010309@knmi.nl>

 Hi Mathieu,

You could take a look at the overlay() command from the sp-package. You
could use this function to find out which  points are in which polygons.
This should allow you assign the point label to a polygon, especially if
one polygon is associated with just one point.

cheers,
Paul

On 06/16/2011 09:33 AM, Mathieu Rajerison wrote:
> HI,
>
>
> I've got a SpatialPointsDataFrame with labels of polygons but the polygon
> objects do not contain these labels.
>
> I want to find a way to assign the labels to their nearest polygons.
>
> I tried spatstat:nncros but my SpatialPolygonsDataFrame, when coerced to a
> psp object, is split up in many many lines. I couldn't find a way, with
> spatstat to accomplish this operation. But there may be one (?)
>
> I found out the geosphere package with function dist2Line. It seems nice
> because it works with both SpatialPointsData and SpatialPolygons.
>
> But when launching the command, I get:
>
> Erreur dans geosphere:::.pointsToMatrix(p) :
>   Points are projected. They should be in degrees (longitude/latitude)
>
> So my questions are:
> -is there a way to make this assignment easily with spatstat::nncross
> -is geosphere::dist2Line preferrable and if so, how can I convert my
> projected coordinates into lon/lat: any package existent? or necessary
> to type in the formula
> <http://www.ehow.co.uk/how_8449009_convert-xy-coordinates-longitude-latitude.html>?
>
>
> Thanks in advance, any help would be appreciated
>
> Mathieu
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


-- 
Paul Hiemstra, Ph.D.
Global Climate Division
Royal Netherlands Meteorological Institute (KNMI)
Wilhelminalaan 10 | 3732 GK | De Bilt | Kamer B 3.39
P.O. Box 201 | 3730 AE | De Bilt
tel: +31 30 2206 494

http://intamap.geo.uu.nl/~paul
http://nl.linkedin.com/pub/paul-hiemstra/20/30b/770


From oscar.perpinan at upm.es  Thu Jun 16 12:34:47 2011
From: oscar.perpinan at upm.es (Oscar =?UTF-8?B?UGVycGnDsWFu?= Lamigueiro)
Date: Thu, 16 Jun 2011 12:34:47 +0200
Subject: [R-sig-Geo] spplot: character size of color key labels
In-Reply-To: <4DF7D803.1090705@uni-muenster.de>
References: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>
	<4DF7D803.1090705@uni-muenster.de>
Message-ID: <20110616123447.05af4869@OPL-EUITI>

Hello,

Following the example of Edzer, you can supply a list to auto.key
(instead of only the TRUE value) with a replacement for some values:

xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=list(cex=3)) 

Bye,

Oscar.

-- 
Oscar Perpi??n Lamigueiro
Dpto. Ingenier?a El?ctrica
EUITI-UPM

http://procomun.wordpress.com

El Tue, 14 Jun 2011 23:52:03
+0200 Edzer Pebesma <edzer.pebesma at uni-muenster.de> escribi?:
> Renaud, as spplot is a wrapper around xyplot or levelplot in package
> lattice, try to pass par.settings as a list; its contents can be
> learned from:
> 
> library(lattice)
> trellis.par.get()
> ?trellis.par.set
> 
> an example is:
> 
> xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=T,par.settings=list(fontsize=list(text=20)))
> # read arg par.settings in ?xyplot
> 
> as you can see, it resizes all other characters as well. No doubt
> there is a way to do this more fine grained.
> 
> This may be personal, but I find myself rarely (if ever) in need of
> this. Font sizes can be manipulated to some extent indirectly by
> changing the size of the plotting region.
> 
> Hth,
> 
> On 06/14/2011 10:26 PM, Renaud Lancelot wrote:
> > Dear all,
> > 
> > How can I control the character size  of color key labels produced
> > by spplot ? I have unsucessfully tried to use cex, as in
> > 
> > spplot(obj, zcol = "var1",
> >              panel = function(...){
> >                  panel.polygonsplot(...)
> >                  sp.text(coordinates(obj), txt =
> > as.character(obj at data$z)) },
> >              cex = 1.5)
> > 
> > All the best,
> > 
> > Renaud
> 


From mathieu.rajerison at gmail.com  Thu Jun 16 12:44:30 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 16 Jun 2011 12:44:30 +0200
Subject: [R-sig-Geo] Assign a point to its nearest polygon
In-Reply-To: <BANLkTik6BLRUVbknwxvjf4HQMbCiNAVEBw@mail.gmail.com>
References: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>
	<BANLkTik6BLRUVbknwxvjf4HQMbCiNAVEBw@mail.gmail.com>
Message-ID: <BANLkTikf0abMYGDM0GWwDyR1CwZu=pce6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/4fefd4ff/attachment.pl>

From edzer.pebesma at uni-muenster.de  Thu Jun 16 12:51:14 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 16 Jun 2011 12:51:14 +0200
Subject: [R-sig-Geo] Assign a point to its nearest polygon
In-Reply-To: <4DF9D173.7010309@knmi.nl>
References: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>
	<4DF9D173.7010309@knmi.nl>
Message-ID: <4DF9E022.2050608@uni-muenster.de>

Some additions to Paul's comments:

-- method "over" was written to replace "overlay", as overlay has
inconsistencies (like overlay(x,y) would be identical to (overlay(y,x)).
-- if some of your points are not inside a polygon (you mentioned
"nearest"), function gDistance in package rgeos might be used to get
distances from points to polygons, from there it is fairly easy to get
the nearest
-- if some points fall in more than one polygon, over(x,y,returnList)
can return all polygons a point falls in

Hth,

On 06/16/2011 11:48 AM, Paul Hiemstra wrote:
>  Hi Mathieu,
> 
> You could take a look at the overlay() command from the sp-package. You
> could use this function to find out which  points are in which polygons.
> This should allow you assign the point label to a polygon, especially if
> one polygon is associated with just one point.
> 
> cheers,
> Paul
> 
> On 06/16/2011 09:33 AM, Mathieu Rajerison wrote:
>> HI,
>>
>>
>> I've got a SpatialPointsDataFrame with labels of polygons but the polygon
>> objects do not contain these labels.
>>
>> I want to find a way to assign the labels to their nearest polygons.
>>
>> I tried spatstat:nncros but my SpatialPolygonsDataFrame, when coerced to a
>> psp object, is split up in many many lines. I couldn't find a way, with
>> spatstat to accomplish this operation. But there may be one (?)
>>
>> I found out the geosphere package with function dist2Line. It seems nice
>> because it works with both SpatialPointsData and SpatialPolygons.
>>
>> But when launching the command, I get:
>>
>> Erreur dans geosphere:::.pointsToMatrix(p) :
>>   Points are projected. They should be in degrees (longitude/latitude)
>>
>> So my questions are:
>> -is there a way to make this assignment easily with spatstat::nncross
>> -is geosphere::dist2Line preferrable and if so, how can I convert my
>> projected coordinates into lon/lat: any package existent? or necessary
>> to type in the formula
>> <http://www.ehow.co.uk/how_8449009_convert-xy-coordinates-longitude-latitude.html>?
>>
>>
>> Thanks in advance, any help would be appreciated
>>
>> Mathieu
>>
>> 	[[alternative HTML version deleted]]
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> 
> 

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From edzer.pebesma at uni-muenster.de  Thu Jun 16 13:01:07 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 16 Jun 2011 13:01:07 +0200
Subject: [R-sig-Geo] Assign a point to its nearest polygon
In-Reply-To: <BANLkTikf0abMYGDM0GWwDyR1CwZu=pce6Q@mail.gmail.com>
References: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>	<BANLkTik6BLRUVbknwxvjf4HQMbCiNAVEBw@mail.gmail.com>
	<BANLkTikf0abMYGDM0GWwDyR1CwZu=pce6Q@mail.gmail.com>
Message-ID: <4DF9E273.5060400@uni-muenster.de>

So I missed your answer. For finding nearest polygons, try:

library(sp)
loadMeuse()
pols = as(meuse.grid[sample(length(meuse.grid),10),], "SpatialPolygons")
plot(meuse)
plot(pols, col = 'red', add=T)
library(rgeos)
m = gDistance(meuse, pols,byid=TRUE)
dim(m)
col = apply(m, 2, function(x) which(x==min(x)))
plot(meuse, col = col, add=TRUE)

(note that R has not so many unique colors if passed as numbers, they
recycle pretty quickly)

On 06/16/2011 12:44 PM, Mathieu Rajerison wrote:
> Hi,
> 
> 
> Thanks for your answers!
> 
> @paul: Overlay will not work as my polygons do not overlay any points.
> 
> @Jos?: I know v.distance command, but I was interested in doing the same in
> R.
> 
> 
> So, if you have any idea on how to accomplish that in R!..
> 
> Mathieu
> 
> 2011/6/16 Jos? Miguel Barrios <jmbarriosg at gmail.com>
> 
>> Hi,
>>
>> What about using spgrass6 to interface with GRASS and use v.distance in
>> GRASS.?
>>
>> http://grass.fbk.eu/grass62/manuals/html62_user/v.distance.html
>>
>>
>> Regards,
>>
>> J.Miguel
>>
>> 2011/6/16 Mathieu Rajerison <mathieu.rajerison at gmail.com>
>>
>>> HI,
>>>
>>>
>>> I've got a SpatialPointsDataFrame with labels of polygons but the polygon
>>> objects do not contain these labels.
>>>
>>> I want to find a way to assign the labels to their nearest polygons.
>>>
>>> I tried spatstat:nncros but my SpatialPolygonsDataFrame, when coerced to a
>>> psp object, is split up in many many lines. I couldn't find a way, with
>>> spatstat to accomplish this operation. But there may be one (?)
>>>
>>> I found out the geosphere package with function dist2Line. It seems nice
>>> because it works with both SpatialPointsData and SpatialPolygons.
>>>
>>> But when launching the command, I get:
>>>
>>> Erreur dans geosphere:::.pointsToMatrix(p) :
>>>  Points are projected. They should be in degrees (longitude/latitude)
>>>
>>> So my questions are:
>>> -is there a way to make this assignment easily with spatstat::nncross
>>> -is geosphere::dist2Line preferrable and if so, how can I convert my
>>> projected coordinates into lon/lat: any package existent? or necessary
>>> to type in the formula
>>> <
>>> http://www.ehow.co.uk/how_8449009_convert-xy-coordinates-longitude-latitude.html
>>>> ?
>>>
>>>
>>> Thanks in advance, any help would be appreciated
>>>
>>> Mathieu
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>>
>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From thi_veloso at yahoo.com.br  Thu Jun 16 13:11:56 2011
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Thu, 16 Jun 2011 04:11:56 -0700 (PDT)
Subject: [R-sig-Geo] Methodology to compare crop maps
Message-ID: <844869.70710.qm@web161421.mail.bf1.yahoo.com>

 Dear Robert,

 Sorry for not stating my question concisely. Still, you captured what was wrong in my code: that was exactly the threshold of the existence of the crop. Raising the limit helped to alleviate the crop existence map at a coarser resolution.

 Following the code, I experienced another difficulty. The merge function replaces the whole contents from one map to the other. Is there any way to impose conditions? Something like "merge if pixel value is greater than..."?

 Best wishes,

 Thiago Veloso.

--- On Sat, 11/6/11, Robert J. Hijmans <r.hijmans at gmail.com> wrote:

> From: Robert J. Hijmans <r.hijmans at gmail.com>
> Subject: Re: [R-sig-Geo] Methodology to compare crop maps
> To: "Thiago Veloso" <thi_veloso at yahoo.com.br>
> Cc: r-sig-geo at r-project.org
> Date: Saturday, 11 June, 2011, 1:27
> Hi Thiago,
> 
> You are not saying _what_ goes wrong. That makes it
> difficult to help.
> I am guessing that you are missing some of the steps below.
> You do:
> 
> cane_sa[cane_sa>0]<-16
> 
> # I do not know your exact objectives but it seems strange
> to use 0 here,
> # as even a cell that is covered for 1/600 of its area with
> cane would
> be classified as cane.
> # but irrespective of the threshold you choose, I think you
> need:
> 
> cane_sa[cane_sa < 16] <- NA
> veg_sa <- crop(vegmap,south_america)
> newveg_sa <- cover(cane_sa, veg_sa)
> 
> # and then continue with your code again:
> 
> new_vegmap <- merge(newveg_sa, vegmap)
> 
> Robert
> 
> On Thu, Jun 9, 2011 at 3:51 PM, Thiago Veloso <thi_veloso at yahoo.com.br>
> wrote:
> > ?Robert, Rich and Luca,
> >
> > ?Thank you very much for the suggestions.
> >
> > ?Robert, I still haven't managed to implement all of
> your directions due to the burocracy to obtain the sugarcane
> raster (or shape) files from INPE.
> >
> > ?In the meanwhile, I am trying to convert mcgill data
> (you're right about the units) from fraction of land covered
> by a crop to presence/absence. This is because my ultimate
> goal is to add a new plant functional type (PFT) to a map
> where 15 PFTs already exist (http://www.sage.wisc.edu/download/potveg/global_potveg.html).
> This way, cells where cane is present should contain the
> value "16".
> >
> > ?It seemed to be a simple task, but what I am doing
> is changing the map substantially. Please take a peek at the
> code:
> >
> > #Loading required packages
> > library(raster)
> > library(maptools)
> >
> > #Loading SAGE vegetation map and McGill sugarcane map
> > vegmap<-raster("data/vegtype.nc")
> > cane<-raster("data/sugarcane_5min.nc")
> >
> >> vegmap
> > class ? ? ? : RasterLayer
> > dimensions ?: 360, 720, 259200 ?(nrow, ncol, ncell)
> > resolution ?: 0.5, 0.5 ?(x, y)
> > extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax,
> ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84
> > values ? ? ?: data/vegtype.nc
> > min ? ? ? ? : ?
> > max ? ? ? ? : ?
> >
> >> cane
> > class ? ? ? : RasterLayer
> > dimensions ?: 2160, 4320, 9331200 ?(nrow, ncol,
> ncell)
> > resolution ?: 0.08333333, 0.08333334 ?(x, y)
> > extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax,
> ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84
> > values ? ? ?: data/sugarcane_5min.nc
> > min ? ? ? ? : ?
> > max ? ? ? ? : ?
> >
> > #Resampling McGill map to match SAGE's resolution
> >
> cane_coarser<-aggregate(cane,fact=6.00000024,fun=mean)
> >
> >> cane_coarser
> > class ? ? ? : RasterLayer
> > dimensions ?: 360, 720, 259200 ?(nrow, ncol, ncell)
> > resolution ?: 0.5, 0.5 ?(x, y)
> > extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax,
> ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84
> > values ? ? ?:
> /tmp/R_raster_tmp/raster_tmp_39924224710.grd
> > min value ? : 0
> > max value ? : 0.5680773
> >
> > #Loading SA shapefile
> >
> south_america<-readShapePoly("shapes/southamerica.shp")
> >
> > #Cropping sugar cane map
> > cane_sa<-crop(cane_coarser,south_america)
> >
> >> cane_sa
> > class ? ? ? : RasterLayer
> > dimensions ?: 137, 93, 12741 ?(nrow, ncol, ncell)
> > resolution ?: 0.5, 0.5 ?(x, y)
> > extent ? ? ?: -81.49999, -34.99999, -56, 12.5
> ?(xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84
> > values ? ? ?: in memory
> > min value ? : 0
> > max value ? : 0.5237272
> >
> > #Below is an attempt to replace fraction with
> presence
> > cane_sa[cane_sa>0]<-16
> >
> > #Check result
> > plot(cane_coarser)
> >
> > #Adding cane map to SAGE vegetation map
> > new_vegmap<merge(vegmap,cane_sa)
> >
> > #Writing out updated map to a netcdf file
> > if(require(ncdf)){
> >
> writeRaster(new_vegmap,filename="/home/thiago/IBIS/data/inpue/new_vegmap.nc",format="CDF",overwrite=TRUE)
> > }
> >
> > ?Everything goes fine until cropping the resampled
> map. However, replacing grater than zero values results in a
> totally different map.
> >
> > ?What am I doing wrong? Maybe spatial data frames are
> harder to deal with (for newbies like me), or maybe the
> massive amount of NA's and?tiny numbers (0.000000e+00,
> 2.433714e-03 and etc) produced after agregation is the
> problem...
> >
> > ?Thanks in advance and best wishes,
> >
> > ?Thiago.
> >
> > --- On Fri, 3/6/11, Robert Hijmans <r.hijmans at gmail.com>
> wrote:
> >
> >> From: Robert Hijmans <r.hijmans at gmail.com>
> >> Subject: Re: [R-sig-Geo] Methodology to compare
> crop maps
> >> To: r-sig-geo at r-project.org
> >> Date: Friday, 3 June, 2011, 13:17
> >> > ?I am working with crops
> >> planted area maps from two distinct sources.
> >> > One of the maps is based on a maximum NDVI
> >> composition, and the other
> >> > map uses joint information from satellite and
> census
> >> to estimate the
> >> > planted area.
> >> >
> >> > ?Although the sources employ different
> methodologies
> >> to map the area
> >> > where the crop exists, the results should be
> >> comparable.
> >> >
> >> > ?After downloading the datasets, I have
> performed a
> >> visual inpection,
> >> > and they show reasonable agreement. However,
> I need a
> >> more robust
> >> > comparison method. Could anybody point out a
> >> methodology which allows
> >> > me to show the difference between both maps?
> >> >
> >> > ?Here is an example of each one of the
> maps:
> >> > http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz
> >> > (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not
> >> > available to download directly, but I can get
> it in
> >> shapefile)
> >> >
> >>
> >>
> >> Thiago,
> >>
> >> I assume that the Brazilian data has a much higher
> spatial
> >> resolution than
> >> the mcgill data (that I think I am familiar with),
> and it
> >> probably has a
> >> different CRS. And I assume that you can get it as
> a the
> >> original raster
> >> file (and not as shapefile) for the Brazilian
> data. If I am
> >> not mistaken,
> >> the mcgill data has the fraction of land area
> covered by a
> >> crop. I assume
> >> that the Brazilan data is presence/absence. If so
> I would
> >> use the raster
> >> package and aggregate the Brazilian data to a cell
> size
> >> that is similar to
> >> the mcgill data (~9 km), computing the fraction of
> cells
> >> that have sugarcane
> >> (sum divided by the number of cells, make sure to
> handle NA
> >> values). Then
> >> use function projectRaster to transform the mcgill
> data to
> >> the same
> >> extent/resolution as the aggregated Brazilian
> data. Now you
> >> have two layers
> >> that you can compare in different ways.
> >>
> >> You can make plots, compute correlation, etc. Of
> course the
> >> p-values are no
> >> good because of spatial autocorrelation.
> >>
> >> library(raster)
> >> x <- y <- raster(nc=100, nr=100)
> >> x[] <- runif(ncell(r))
> >> y[] <- runif(ncell(r))
> >> plot(x, y)
> >> m <- lm(values(x), values(y))
> >> summary(m)
> >> abline(m)
> >>
> >> hist(x-y)
> >> plot(x-y)
> >> cor(values(x), values(y))
> >>
> >>
> >> Perhaps you want to treat your data as
> presence/absence
> >> (with presence being
> >> > 0 or some another threshold). These can then
> be easily
> >> compared with the
> >> crosstab function which returns, in this case, a
> confusion
> >> matrix which can
> >> be directly interpreted or used to compute some
> statistics
> >> from.
> >> crosstab(x>0, y>0)
> >>
> >> crosstab(x>0.5, y>0.5)
> >>
> >> And there surely are many other approaches
> possible, which
> >> is why I think
> >> that R is the way to go in this case: it is easy,
> flexible
> >> and fast.
> >>
> >> Robert
> >>
> >>
> >> --
> >> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Methodology-to-compare-crop-maps-tp6431598p6435902.html
> >> Sent from the R-sig-geo mailing list archive at
> >> Nabble.com.
> >>
> >> _______________________________________________
> >> R-sig-Geo mailing list
> >> R-sig-Geo at r-project.org
> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >>
> >
> >
>




From mathieu.rajerison at gmail.com  Thu Jun 16 13:30:35 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 16 Jun 2011 13:30:35 +0200
Subject: [R-sig-Geo] Assign a point to its nearest polygon
In-Reply-To: <4DF9E273.5060400@uni-muenster.de>
References: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>
	<BANLkTik6BLRUVbknwxvjf4HQMbCiNAVEBw@mail.gmail.com>
	<BANLkTikf0abMYGDM0GWwDyR1CwZu=pce6Q@mail.gmail.com>
	<4DF9E273.5060400@uni-muenster.de>
Message-ID: <BANLkTim3LzxUiT88X9oVu47E+0a3E813BQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/a1416375/attachment.pl>

From r.hijmans at gmail.com  Thu Jun 16 13:53:15 2011
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Thu, 16 Jun 2011 04:53:15 -0700
Subject: [R-sig-Geo] Methodology to compare crop maps
In-Reply-To: <844869.70710.qm@web161421.mail.bf1.yahoo.com>
References: <844869.70710.qm@web161421.mail.bf1.yahoo.com>
Message-ID: <BANLkTim_fggStrA+CwExkWeqTOujRdps6Q@mail.gmail.com>

Dear Thiago,

That's why I suggested:

> cane_sa[cane_sa < 16] <- NA
> veg_sa <- crop(vegmap,south_america)
> newveg_sa <- cover(cane_sa, veg_sa)
> new_vegmap <- merge(newveg_sa, vegmap)

i.e. set all values you do not want to NA, and then use 'cover' to
replace NA values in the new raster with the values of the old raster,
and then use merge.

Best, Robert


On Thu, Jun 16, 2011 at 4:11 AM, Thiago Veloso <thi_veloso at yahoo.com.br> wrote:
> ?Dear Robert,
>
> ?Sorry for not stating my question concisely. Still, you captured what was wrong in my code: that was exactly the threshold of the existence of the crop. Raising the limit helped to alleviate the crop existence map at a coarser resolution.
>
> ?Following the code, I experienced another difficulty. The merge function replaces the whole contents from one map to the other. Is there any way to impose conditions? Something like "merge if pixel value is greater than..."?
>
> ?Best wishes,
>
> ?Thiago Veloso.
>
> --- On Sat, 11/6/11, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>
>> From: Robert J. Hijmans <r.hijmans at gmail.com>
>> Subject: Re: [R-sig-Geo] Methodology to compare crop maps
>> To: "Thiago Veloso" <thi_veloso at yahoo.com.br>
>> Cc: r-sig-geo at r-project.org
>> Date: Saturday, 11 June, 2011, 1:27
>> Hi Thiago,
>>
>> You are not saying _what_ goes wrong. That makes it
>> difficult to help.
>> I am guessing that you are missing some of the steps below.
>> You do:
>>
>> cane_sa[cane_sa>0]<-16
>>
>> # I do not know your exact objectives but it seems strange
>> to use 0 here,
>> # as even a cell that is covered for 1/600 of its area with
>> cane would
>> be classified as cane.
>> # but irrespective of the threshold you choose, I think you
>> need:
>>
>> cane_sa[cane_sa < 16] <- NA
>> veg_sa <- crop(vegmap,south_america)
>> newveg_sa <- cover(cane_sa, veg_sa)
>>
>> # and then continue with your code again:
>>
>> new_vegmap <- merge(newveg_sa, vegmap)
>>
>> Robert
>>
>> On Thu, Jun 9, 2011 at 3:51 PM, Thiago Veloso <thi_veloso at yahoo.com.br>
>> wrote:
>> > ?Robert, Rich and Luca,
>> >
>> > ?Thank you very much for the suggestions.
>> >
>> > ?Robert, I still haven't managed to implement all of
>> your directions due to the burocracy to obtain the sugarcane
>> raster (or shape) files from INPE.
>> >
>> > ?In the meanwhile, I am trying to convert mcgill data
>> (you're right about the units) from fraction of land covered
>> by a crop to presence/absence. This is because my ultimate
>> goal is to add a new plant functional type (PFT) to a map
>> where 15 PFTs already exist (http://www.sage.wisc.edu/download/potveg/global_potveg.html).
>> This way, cells where cane is present should contain the
>> value "16".
>> >
>> > ?It seemed to be a simple task, but what I am doing
>> is changing the map substantially. Please take a peek at the
>> code:
>> >
>> > #Loading required packages
>> > library(raster)
>> > library(maptools)
>> >
>> > #Loading SAGE vegetation map and McGill sugarcane map
>> > vegmap<-raster("data/vegtype.nc")
>> > cane<-raster("data/sugarcane_5min.nc")
>> >
>> >> vegmap
>> > class ? ? ? : RasterLayer
>> > dimensions ?: 360, 720, 259200 ?(nrow, ncol, ncell)
>> > resolution ?: 0.5, 0.5 ?(x, y)
>> > extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax,
>> ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84
>> > values ? ? ?: data/vegtype.nc
>> > min ? ? ? ? : ?
>> > max ? ? ? ? : ?
>> >
>> >> cane
>> > class ? ? ? : RasterLayer
>> > dimensions ?: 2160, 4320, 9331200 ?(nrow, ncol,
>> ncell)
>> > resolution ?: 0.08333333, 0.08333334 ?(x, y)
>> > extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax,
>> ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84
>> > values ? ? ?: data/sugarcane_5min.nc
>> > min ? ? ? ? : ?
>> > max ? ? ? ? : ?
>> >
>> > #Resampling McGill map to match SAGE's resolution
>> >
>> cane_coarser<-aggregate(cane,fact=6.00000024,fun=mean)
>> >
>> >> cane_coarser
>> > class ? ? ? : RasterLayer
>> > dimensions ?: 360, 720, 259200 ?(nrow, ncol, ncell)
>> > resolution ?: 0.5, 0.5 ?(x, y)
>> > extent ? ? ?: -180, 180, -90, 90 ?(xmin, xmax,
>> ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84
>> > values ? ? ?:
>> /tmp/R_raster_tmp/raster_tmp_39924224710.grd
>> > min value ? : 0
>> > max value ? : 0.5680773
>> >
>> > #Loading SA shapefile
>> >
>> south_america<-readShapePoly("shapes/southamerica.shp")
>> >
>> > #Cropping sugar cane map
>> > cane_sa<-crop(cane_coarser,south_america)
>> >
>> >> cane_sa
>> > class ? ? ? : RasterLayer
>> > dimensions ?: 137, 93, 12741 ?(nrow, ncol, ncell)
>> > resolution ?: 0.5, 0.5 ?(x, y)
>> > extent ? ? ?: -81.49999, -34.99999, -56, 12.5
>> ?(xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84
>> > values ? ? ?: in memory
>> > min value ? : 0
>> > max value ? : 0.5237272
>> >
>> > #Below is an attempt to replace fraction with
>> presence
>> > cane_sa[cane_sa>0]<-16
>> >
>> > #Check result
>> > plot(cane_coarser)
>> >
>> > #Adding cane map to SAGE vegetation map
>> > new_vegmap<merge(vegmap,cane_sa)
>> >
>> > #Writing out updated map to a netcdf file
>> > if(require(ncdf)){
>> >
>> writeRaster(new_vegmap,filename="/home/thiago/IBIS/data/inpue/new_vegmap.nc",format="CDF",overwrite=TRUE)
>> > }
>> >
>> > ?Everything goes fine until cropping the resampled
>> map. However, replacing grater than zero values results in a
>> totally different map.
>> >
>> > ?What am I doing wrong? Maybe spatial data frames are
>> harder to deal with (for newbies like me), or maybe the
>> massive amount of NA's and?tiny numbers (0.000000e+00,
>> 2.433714e-03 and etc) produced after agregation is the
>> problem...
>> >
>> > ?Thanks in advance and best wishes,
>> >
>> > ?Thiago.
>> >
>> > --- On Fri, 3/6/11, Robert Hijmans <r.hijmans at gmail.com>
>> wrote:
>> >
>> >> From: Robert Hijmans <r.hijmans at gmail.com>
>> >> Subject: Re: [R-sig-Geo] Methodology to compare
>> crop maps
>> >> To: r-sig-geo at r-project.org
>> >> Date: Friday, 3 June, 2011, 13:17
>> >> > ?I am working with crops
>> >> planted area maps from two distinct sources.
>> >> > One of the maps is based on a maximum NDVI
>> >> composition, and the other
>> >> > map uses joint information from satellite and
>> census
>> >> to estimate the
>> >> > planted area.
>> >> >
>> >> > ?Although the sources employ different
>> methodologies
>> >> to map the area
>> >> > where the crop exists, the results should be
>> >> comparable.
>> >> >
>> >> > ?After downloading the datasets, I have
>> performed a
>> >> visual inpection,
>> >> > and they show reasonable agreement. However,
>> I need a
>> >> more robust
>> >> > comparison method. Could anybody point out a
>> >> methodology which allows
>> >> > me to show the difference between both maps?
>> >> >
>> >> > ?Here is an example of each one of the
>> maps:
>> >> > http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz
>> >> > (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not
>> >> > available to download directly, but I can get
>> it in
>> >> shapefile)
>> >> >
>> >>
>> >>
>> >> Thiago,
>> >>
>> >> I assume that the Brazilian data has a much higher
>> spatial
>> >> resolution than
>> >> the mcgill data (that I think I am familiar with),
>> and it
>> >> probably has a
>> >> different CRS. And I assume that you can get it as
>> a the
>> >> original raster
>> >> file (and not as shapefile) for the Brazilian
>> data. If I am
>> >> not mistaken,
>> >> the mcgill data has the fraction of land area
>> covered by a
>> >> crop. I assume
>> >> that the Brazilan data is presence/absence. If so
>> I would
>> >> use the raster
>> >> package and aggregate the Brazilian data to a cell
>> size
>> >> that is similar to
>> >> the mcgill data (~9 km), computing the fraction of
>> cells
>> >> that have sugarcane
>> >> (sum divided by the number of cells, make sure to
>> handle NA
>> >> values). Then
>> >> use function projectRaster to transform the mcgill
>> data to
>> >> the same
>> >> extent/resolution as the aggregated Brazilian
>> data. Now you
>> >> have two layers
>> >> that you can compare in different ways.
>> >>
>> >> You can make plots, compute correlation, etc. Of
>> course the
>> >> p-values are no
>> >> good because of spatial autocorrelation.
>> >>
>> >> library(raster)
>> >> x <- y <- raster(nc=100, nr=100)
>> >> x[] <- runif(ncell(r))
>> >> y[] <- runif(ncell(r))
>> >> plot(x, y)
>> >> m <- lm(values(x), values(y))
>> >> summary(m)
>> >> abline(m)
>> >>
>> >> hist(x-y)
>> >> plot(x-y)
>> >> cor(values(x), values(y))
>> >>
>> >>
>> >> Perhaps you want to treat your data as
>> presence/absence
>> >> (with presence being
>> >> > 0 or some another threshold). These can then
>> be easily
>> >> compared with the
>> >> crosstab function which returns, in this case, a
>> confusion
>> >> matrix which can
>> >> be directly interpreted or used to compute some
>> statistics
>> >> from.
>> >> crosstab(x>0, y>0)
>> >>
>> >> crosstab(x>0.5, y>0.5)
>> >>
>> >> And there surely are many other approaches
>> possible, which
>> >> is why I think
>> >> that R is the way to go in this case: it is easy,
>> flexible
>> >> and fast.
>> >>
>> >> Robert
>> >>
>> >>
>> >> --
>> >> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Methodology-to-compare-crop-maps-tp6431598p6435902.html
>> >> Sent from the R-sig-geo mailing list archive at
>> >> Nabble.com.
>> >>
>> >> _______________________________________________
>> >> R-sig-Geo mailing list
>> >> R-sig-Geo at r-project.org
>> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >
>> >
>>
>
>
>


From a-gregmc at microsoft.com  Thu Jun 16 14:42:22 2011
From: a-gregmc at microsoft.com (Greg McInerny (Brook Street))
Date: Thu, 16 Jun 2011 12:42:22 +0000
Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution
 Modelling Survey (niches, climate envelopes, habitat suitability etc...)
Message-ID: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51AFA@DB3EX14MBXC304.europe.corp.microsoft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/c6a3d5ae/attachment.pl>

From freddy.vate01 at gmail.com  Thu Jun 16 14:43:42 2011
From: freddy.vate01 at gmail.com (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Thu, 16 Jun 2011 08:13:42 -0430
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
In-Reply-To: <4DF9A340.80400@tum.de>
References: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>
	<4DF9A340.80400@tum.de>
Message-ID: <BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>

Dear Tom,

Excuse me for the misuse of terms. I create a new location with a
shapefile (using v.in.ogr) and it creates automatically a mapset (am I
wrong?) in /home/vate01/grassdata/venest3/PERMANENT/vector/.

When I use the same steps with example datasets, this time North
Carolina data, I get:

# once inside gisdemo_ncspm location, I run R and...
> library(spgrass6)
Loading required package: sp
Loading required package: rgdal
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.8.0, released 2011/01/12
Path to GDAL shared files: /usr/share/gdal/1.8
Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
Path to PROJ.4 shared files: (autodetected)
Loading required package: XML
GRASS GIS interface loaded with GRASS version: 6.4.1
and location: gisdemo_ncspm

# one test...
> plot(readVECT6('geology'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/geology/head",
layer: "1"
with 1832 features and 8 fields
Feature type: wkbPolygon with 2 dimensions

# another test...
> plot(readVECT6('firestations'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/firestations/head",
layer: "1"
with 71 features and 22 fields
Feature type: wkbPoint with 2 dimensions

#  idem...
> plot(readVECT6('elev_points'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/elev_points/head",
layer: "1"
with 6000 features and 2 fields
Feature type: wkbPoint with 2 dimensions

Beautiful maps; but following the same steps with venest3, it reports
the message

Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
input_field_name_encoding) :
 Cannot open layer

Additionally, when I use readShapePoly() function (with the original
shapefile) there are no problems. I can plot the map perfectly
(indeed, I have used this shape several times from either R or GRASS
but never working one from another).

Thanks for your attention.

Cheers.


On Thu, Jun 16, 2011 at 02:01, Tom Gottfried <tom.gottfried at tum.de> wrote:
> Hi Freddy,
>
> if, as you have written, venest3 is a location, then you can't read it as
> vector. You have to create a mapset in your location and a vector dataset in
> the mapset. Then you can read the vector dataset.
>
> regards,
> Tom
>
> Am 16.06.2011 04:36, schrieb Freddy L?pez:
>>
>> Hello guys,
>>
>> I think this question is in the border: r-sig-geo or grass-user list...
>>
>> I want to do some interpolation using GRASS' graphical features but
>> using code and libraries written in R and I'm trying to follow section
>> 10.2.1 from 3rd edition GRASS BOOK (Open Source GIS: A GRASS GIS
>> Approach).
>>
>> I create a location into GRASS, venest3, apparently with no problem
>> and I can plot it using d.vect.
>>
>> After starting R and run the readVECT6 function I get
>>
>>> readVECT6('venest3')
>>
>> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>> input_field_name_encoding) :
>> ?Cannot open layer
>>
>> I have experimented using the spearfish60 file and it works perfectly
>> (I selected randomly geology...):
>>
>>> readVECT6('geology'))
>>
>> OGR data source with driver: GRASS
>> Source:
>> "/home/vate01/grassdata/spearfish60/PERMANENT/vector/geology/head",
>> layer: "1"
>> with 422 features and 2 fields
>> Feature type: wkbPolygon with 2 dimensions
>> ...
>>
>>
>> Both locations (venest3 and spearfish60), inside its 'vector'
>> directory have the same six files: cidx, coor, dbln, head, hist, topo.
>>
>> Have you any ideas how can I solve this situation? How to read my vector
>> data?
>>
>> Thanks in advance.-
>>
>>
>> --
>> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>>
>> JRR Tolkien
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Technische Universit?t M?nchen
> Department f?r Pflanzenwissenschaften
> Lehrstuhl f?r Gr?nlandlehre
> Alte Akademie 12
> 85350 Freising / Germany
> Phone: ++49 (0)8161 715324
> Fax: ? ++49 (0)8161 713243
> email: tom.gottfried at wzw.tum.de
> http://www.wzw.tum.de/gruenland
>



-- 
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From timothy.gregoire at yale.edu  Thu Jun 16 14:48:11 2011
From: timothy.gregoire at yale.edu (Gregoire, Timothy)
Date: Thu, 16 Jun 2011 08:48:11 -0400
Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution
 Modelling Survey (niches, climate envelopes, habitat suitability etc...)
In-Reply-To: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51AFA@DB3EX14MBXC304.europe.corp.microsoft.com>
References: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51AFA@DB3EX14MBXC304.europe.corp.microsoft.com>
Message-ID: <141D0A818175C842AC5577DF2D5A310DCF1B28E833@XVS1-CLUSTER.yu.yale.edu>

IS THIS AN APPROPRIATE USE OF THIS LISTSERV? SEEMS VERY QUESTIONABLE TO ME!

Timothy G. Gregoire
J. P. Weyerhaeuser Professor of Forest Management
School of Forestry & Environmental Studies, Yale University
360 Prospect Street, New Haven, CT  06511-2104  U.S.A.

office: 1.203.432.9398  mobile: 1.203.508.4014, fax: 1.203.432.3809
timothy.gregoire at yale.edu
G&V sampling text: http://crcpress.com/product/isbn/9781584883708


-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Greg McInerny (Brook Street)
Sent: Thursday, June 16, 2011 8:42 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution Modelling Survey (niches, climate envelopes, habitat suitability etc...)

Thuiller et al. (2009) suggest that our science is "intertwined with technical innovation..." and how it is "dependent on the existence of suitable software" (Thuiller et al. 2009, Ecography, 32, 369-373).
What do you want to do with software and how? We are researching these questions.

As users and developers of R and R packages we would love you to participate, obviously the best information will come if all types of users and all software are well represented.

Please accept this invitation to take the (anonymous) research survey on Species Distribution Modelling and Software. It takes only takes 5 to 15 minutes, just follow this link...
https://microsoft.qualtrics.com/SE/?SID=SV_80yEiYdFCj7Q3dO
The survey is open until 1st of July, but please complete as soon as possible! Your views and experiences are immensely valued!

We will publish aggregated results so the modelling community & developers (everyone!) benefits from this research project. It is all anonymous (you can find the project and privacy information here http://research.microsoft.com/en-us/projects/sdmsoftwaresurvey/default.aspx).

If you have any questions please email us here<mailto:sdmquest at microsoft.com?subject=SDM%20Survey>
Best wishes
Greg, Lucas, & Lara


The Research team

We (Greg McInerny, Lucas Joppa and Lara Salido) are Ecologists in the Computational Ecology and Environmental Sciences group in the Computational Science Laboratory at Microsoft Research Cambridge, UK. We frequently use SDM and are interested in all kinds of ecological and methodological questions. Find out more about our group's research here<http://research.microsoft.com/en-us/groups/ecology/default.aspx>  You can also find out more about the survey at the project homepage here <http://research.microsoft.com/sdmsoftwaresurvey/%20>  If you have any questions, please email us here<mailto:sdmquest at microsoft.com?subject=SDM%20Survey>


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From mathieu.rajerison at gmail.com  Thu Jun 16 14:56:39 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Thu, 16 Jun 2011 14:56:39 +0200
Subject: [R-sig-Geo] Assign a point to its nearest polygon
In-Reply-To: <BANLkTim3LzxUiT88X9oVu47E+0a3E813BQ@mail.gmail.com>
References: <BANLkTi=wpExpDgRd=kxKx4K5S-jWXLHrjA@mail.gmail.com>
	<BANLkTik6BLRUVbknwxvjf4HQMbCiNAVEBw@mail.gmail.com>
	<BANLkTikf0abMYGDM0GWwDyR1CwZu=pce6Q@mail.gmail.com>
	<4DF9E273.5060400@uni-muenster.de>
	<BANLkTim3LzxUiT88X9oVu47E+0a3E813BQ@mail.gmail.com>
Message-ID: <BANLkTikaT0FR-3Lg5BvqLSFJWCpRVoODHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/606d2cef/attachment.pl>

From a-gregmc at microsoft.com  Thu Jun 16 15:13:48 2011
From: a-gregmc at microsoft.com (Greg McInerny (Brook Street))
Date: Thu, 16 Jun 2011 13:13:48 +0000
Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution
 Modelling Survey (niches, climate envelopes, habitat suitability etc...)
In-Reply-To: <141D0A818175C842AC5577DF2D5A310DCF1B28E833@XVS1-CLUSTER.yu.yale.edu>
References: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51AFA@DB3EX14MBXC304.europe.corp.microsoft.com>
	<141D0A818175C842AC5577DF2D5A310DCF1B28E833@XVS1-CLUSTER.yu.yale.edu>
Message-ID: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51B6A@DB3EX14MBXC304.europe.corp.microsoft.com>

Dear Timothy (and r-sig-geo), 
This fits perfectly into the interests of this discussion forum? - "a discussion forum for those analysing ecological and environmental data with R". 
I maybe should clarify, we are ecologists (yes at Microsoft Research!) and this is part of a research project where we are investigating the interactions between software and the users in scientific activities. An online survey is the only way we can reach the diversity of users, across a diversity of software, and get a good representation of what people do. 
We aren't posing a technical question, but we inviting people to talk about their user experiences (such as R) and what tasks people really want the software to perform. I apologise for any cross posting and happy for the survey to be removed if required.
To clarify we are extremely careful with all the information collected and the privacy and disclaimer information can be found here http://research.microsoft.com/en-us/projects/sdmsoftwaresurvey/default.aspx if you would like to ch3eck it out. If you have any questions please email us sdmquest at microsoft.com or reply to this post. Happy to answer all queries.
Best wishes.
Greg.

-----Original Message-----
From: Gregoire, Timothy [mailto:timothy.gregoire at yale.edu] 
Sent: 16 June 2011 13:48
To: Greg McInerny (Brook Street); r-sig-geo at r-project.org
Subject: RE: [R-sig-Geo] Invitation to Partcipate: Species Distribution Modelling Survey (niches, climate envelopes, habitat suitability etc...)

IS THIS AN APPROPRIATE USE OF THIS LISTSERV? SEEMS VERY QUESTIONABLE TO ME!

Timothy G. Gregoire
J. P. Weyerhaeuser Professor of Forest Management School of Forestry & Environmental Studies, Yale University
360 Prospect Street, New Haven, CT  06511-2104  U.S.A.

office: 1.203.432.9398  mobile: 1.203.508.4014, fax: 1.203.432.3809 timothy.gregoire at yale.edu G&V sampling text: http://crcpress.com/product/isbn/9781584883708


-----Original Message-----
From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Greg McInerny (Brook Street)
Sent: Thursday, June 16, 2011 8:42 AM
To: r-sig-geo at r-project.org
Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution Modelling Survey (niches, climate envelopes, habitat suitability etc...)

Thuiller et al. (2009) suggest that our science is "intertwined with technical innovation..." and how it is "dependent on the existence of suitable software" (Thuiller et al. 2009, Ecography, 32, 369-373).
What do you want to do with software and how? We are researching these questions.

As users and developers of R and R packages we would love you to participate, obviously the best information will come if all types of users and all software are well represented.

Please accept this invitation to take the (anonymous) research survey on Species Distribution Modelling and Software. It takes only takes 5 to 15 minutes, just follow this link...
https://microsoft.qualtrics.com/SE/?SID=SV_80yEiYdFCj7Q3dO
The survey is open until 1st of July, but please complete as soon as possible! Your views and experiences are immensely valued!

We will publish aggregated results so the modelling community & developers (everyone!) benefits from this research project. It is all anonymous (you can find the project and privacy information here http://research.microsoft.com/en-us/projects/sdmsoftwaresurvey/default.aspx).

If you have any questions please email us here<mailto:sdmquest at microsoft.com?subject=SDM%20Survey>
Best wishes
Greg, Lucas, & Lara


The Research team

We (Greg McInerny, Lucas Joppa and Lara Salido) are Ecologists in the Computational Ecology and Environmental Sciences group in the Computational Science Laboratory at Microsoft Research Cambridge, UK. We frequently use SDM and are interested in all kinds of ecological and methodological questions. Find out more about our group's research here<http://research.microsoft.com/en-us/groups/ecology/default.aspx>  You can also find out more about the survey at the project homepage here <http://research.microsoft.com/sdmsoftwaresurvey/%20>  If you have any questions, please email us here<mailto:sdmquest at microsoft.com?subject=SDM%20Survey>


	[[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From Roger.Bivand at nhh.no  Thu Jun 16 15:38:56 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 16 Jun 2011 15:38:56 +0200 (CEST)
Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution
 Modelling Survey (niches, climate envelopes, habitat suitability etc...)
In-Reply-To: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51B6A@DB3EX14MBXC304.europe.corp.microsoft.com>
References: <F40E2C430CC2DD4D9C0873A2FAC976B41CB51AFA@DB3EX14MBXC304.europe.corp.microsoft.com>
	<141D0A818175C842AC5577DF2D5A310DCF1B28E833@XVS1-CLUSTER.yu.yale.edu>
	<F40E2C430CC2DD4D9C0873A2FAC976B41CB51B6A@DB3EX14MBXC304.europe.corp.microsoft.com>
Message-ID: <alpine.LRH.2.00.1106161530320.9246@reclus.nhh.no>

On Thu, 16 Jun 2011, Greg McInerny (Brook Street) wrote:

> Dear Timothy (and r-sig-geo), This fits perfectly into the interests of 
> this discussion forum? - "a discussion forum for those analysing 
> ecological and environmental data with R".

In fact:

"R-sig-Geo -- R Special Interest Group on using Geographical data and 
Mapping"

and:

"A mailing list for discussing the development and use of R functions and 
packages for handling and analysis of spatial, and particularly 
geographical, data. The list also covers mapping and cartographic issues, 
and interfaces between R and geographical information systems."

So the posting was somewhat off-topic, but not radically so, and was 
perhaps rather less humble in tone than some might prefer. It is not easy 
to survey researchers about software use, and other postings have done 
this in the past (on other R lists, and I think on this one). If 
subscribers find it irritating - especially those with no connection to 
species distribution modelling, ignoring it is a possibility. The authors 
have clarified their affiliation, so that shouldn't be an issue.

Roger

> I maybe should clarify, we 
> are ecologists (yes at Microsoft Research!) and this is part of a 
> research project where we are investigating the interactions between 
> software and the users in scientific activities. An online survey is the 
> only way we can reach the diversity of users, across a diversity of 
> software, and get a good representation of what people do. We aren't 
> posing a technical question, but we inviting people to talk about their 
> user experiences (such as R) and what tasks people really want the 
> software to perform. I apologise for any cross posting and happy for the 
> survey to be removed if required. To clarify we are extremely careful 
> with all the information collected and the privacy and disclaimer 
> information can be found here 
> http://research.microsoft.com/en-us/projects/sdmsoftwaresurvey/default.aspx 
> if you would like to ch3eck it out. If you have any questions please 
> email us sdmquest at microsoft.com or reply to this post. Happy to answer 
> all queries. Best wishes. Greg.
>
> -----Original Message-----
> From: Gregoire, Timothy [mailto:timothy.gregoire at yale.edu]
> Sent: 16 June 2011 13:48
> To: Greg McInerny (Brook Street); r-sig-geo at r-project.org
> Subject: RE: [R-sig-Geo] Invitation to Partcipate: Species Distribution Modelling Survey (niches, climate envelopes, habitat suitability etc...)
>
> IS THIS AN APPROPRIATE USE OF THIS LISTSERV? SEEMS VERY QUESTIONABLE TO ME!
>
> Timothy G. Gregoire
> J. P. Weyerhaeuser Professor of Forest Management School of Forestry & Environmental Studies, Yale University
> 360 Prospect Street, New Haven, CT  06511-2104  U.S.A.
>
> office: 1.203.432.9398  mobile: 1.203.508.4014, fax: 1.203.432.3809 timothy.gregoire at yale.edu G&V sampling text: http://crcpress.com/product/isbn/9781584883708
>
>
> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-project.org] On Behalf Of Greg McInerny (Brook Street)
> Sent: Thursday, June 16, 2011 8:42 AM
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Invitation to Partcipate: Species Distribution Modelling Survey (niches, climate envelopes, habitat suitability etc...)
>
> Thuiller et al. (2009) suggest that our science is "intertwined with technical innovation..." and how it is "dependent on the existence of suitable software" (Thuiller et al. 2009, Ecography, 32, 369-373).
> What do you want to do with software and how? We are researching these questions.
>
> As users and developers of R and R packages we would love you to participate, obviously the best information will come if all types of users and all software are well represented.
>
> Please accept this invitation to take the (anonymous) research survey on Species Distribution Modelling and Software. It takes only takes 5 to 15 minutes, just follow this link...
> https://microsoft.qualtrics.com/SE/?SID=SV_80yEiYdFCj7Q3dO
> The survey is open until 1st of July, but please complete as soon as possible! Your views and experiences are immensely valued!
>
> We will publish aggregated results so the modelling community & developers (everyone!) benefits from this research project. It is all anonymous (you can find the project and privacy information here http://research.microsoft.com/en-us/projects/sdmsoftwaresurvey/default.aspx).
>
> If you have any questions please email us here<mailto:sdmquest at microsoft.com?subject=SDM%20Survey>
> Best wishes
> Greg, Lucas, & Lara
>
>
> The Research team
>
> We (Greg McInerny, Lucas Joppa and Lara Salido) are Ecologists in the Computational Ecology and Environmental Sciences group in the Computational Science Laboratory at Microsoft Research Cambridge, UK. We frequently use SDM and are interested in all kinds of ecological and methodological questions. Find out more about our group's research here<http://research.microsoft.com/en-us/groups/ecology/default.aspx>  You can also find out more about the survey at the project homepage here <http://research.microsoft.com/sdmsoftwaresurvey/%20>  If you have any questions, please email us here<mailto:sdmquest at microsoft.com?subject=SDM%20Survey>
>
>
> 	[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From nkkroy3 at gmail.com  Thu Jun 16 16:07:02 2011
From: nkkroy3 at gmail.com (Nikki roy)
Date: Thu, 16 Jun 2011 16:07:02 +0200
Subject: [R-sig-Geo] Nugget-Sill-Ratio of a Linear Model of Coregionalizaton
Message-ID: <BANLkTinQJeXGQ8wpi0KzKz3fTApQegu+-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/c314e4e1/attachment.pl>

From tom.gottfried at tum.de  Thu Jun 16 17:53:21 2011
From: tom.gottfried at tum.de (Gottfried, Tom)
Date: Thu, 16 Jun 2011 15:53:21 +0000
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
In-Reply-To: <BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>
References: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>
	<4DF9A340.80400@tum.de>,
	<BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>
Message-ID: <9B16DFA4E75D54409B978C6E911D667A0C234A8F@BADWLRZ-SWMBX1.ads.mwn.de>

Hi,

you have to be in the location and mapset where the vector is you want to read. In your case location=venest3, mapset=PERMANENT. Then start R, then
library(spgrass6)
readVECT6("yourvector")

regards,
Tom 
________________________________________
Von: Freddy L?pez [freddy.vate01 at gmail.com]
Gesendet: Donnerstag, 16. Juni 2011 14:44
Bis: r-sig-geo at r-project.org
Cc: Gottfried, Tom
Betreff: Re: [R-sig-Geo] Reading vector data from GRASS GIS.-

Dear Tom,

Excuse me for the misuse of terms. I create a new location with a
shapefile (using v.in.ogr) and it creates automatically a mapset (am I
wrong?) in /home/vate01/grassdata/venest3/PERMANENT/vector/.

Just to be nasty: PERMANENT is the (default) mapset.

When I use the same steps with example datasets, this time North
Carolina data, I get:

# once inside gisdemo_ncspm location, I run R and...
> library(spgrass6)
Loading required package: sp
Loading required package: rgdal
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 1.8.0, released 2011/01/12
Path to GDAL shared files: /usr/share/gdal/1.8
Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
Path to PROJ.4 shared files: (autodetected)
Loading required package: XML
GRASS GIS interface loaded with GRASS version: 6.4.1
and location: gisdemo_ncspm

# one test...
> plot(readVECT6('geology'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/geology/head",
layer: "1"
with 1832 features and 8 fields
Feature type: wkbPolygon with 2 dimensions

# another test...
> plot(readVECT6('firestations'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/firestations/head",
layer: "1"
with 71 features and 22 fields
Feature type: wkbPoint with 2 dimensions

#  idem...
> plot(readVECT6('elev_points'))
OGR data source with driver: GRASS
Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/elev_points/head",
layer: "1"
with 6000 features and 2 fields
Feature type: wkbPoint with 2 dimensions

Beautiful maps; but following the same steps with venest3, it reports
the message

Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
input_field_name_encoding) :
 Cannot open layer

Additionally, when I use readShapePoly() function (with the original
shapefile) there are no problems. I can plot the map perfectly
(indeed, I have used this shape several times from either R or GRASS
but never working one from another).

Thanks for your attention.

Cheers.


On Thu, Jun 16, 2011 at 02:01, Tom Gottfried <tom.gottfried at tum.de> wrote:
> Hi Freddy,
>
> if, as you have written, venest3 is a location, then you can't read it as
> vector. You have to create a mapset in your location and a vector dataset in
> the mapset. Then you can read the vector dataset.
>
> regards,
> Tom
>
> Am 16.06.2011 04:36, schrieb Freddy L?pez:
>>
>> Hello guys,
>>
>> I think this question is in the border: r-sig-geo or grass-user list...
>>
>> I want to do some interpolation using GRASS' graphical features but
>> using code and libraries written in R and I'm trying to follow section
>> 10.2.1 from 3rd edition GRASS BOOK (Open Source GIS: A GRASS GIS
>> Approach).
>>
>> I create a location into GRASS, venest3, apparently with no problem
>> and I can plot it using d.vect.
>>
>> After starting R and run the readVECT6 function I get
>>
>>> readVECT6('venest3')
>>
>> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>> input_field_name_encoding) :
>>  Cannot open layer
>>
>> I have experimented using the spearfish60 file and it works perfectly
>> (I selected randomly geology...):
>>
>>> readVECT6('geology'))
>>
>> OGR data source with driver: GRASS
>> Source:
>> "/home/vate01/grassdata/spearfish60/PERMANENT/vector/geology/head",
>> layer: "1"
>> with 422 features and 2 fields
>> Feature type: wkbPolygon with 2 dimensions
>> ...
>>
>>
>> Both locations (venest3 and spearfish60), inside its 'vector'
>> directory have the same six files: cidx, coor, dbln, head, hist, topo.
>>
>> Have you any ideas how can I solve this situation? How to read my vector
>> data?
>>
>> Thanks in advance.-
>>
>>
>> --
>> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>>
>> JRR Tolkien
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> --
> Technische Universit?t M?nchen
> Department f?r Pflanzenwissenschaften
> Lehrstuhl f?r Gr?nlandlehre
> Alte Akademie 12
> 85350 Freising / Germany
> Phone: ++49 (0)8161 715324
> Fax:   ++49 (0)8161 713243
> email: tom.gottfried at wzw.tum.de
> http://www.wzw.tum.de/gruenland
>



--
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien

From freddy.vate01 at gmail.com  Thu Jun 16 18:23:59 2011
From: freddy.vate01 at gmail.com (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Thu, 16 Jun 2011 11:53:59 -0430
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
In-Reply-To: <9B16DFA4E75D54409B978C6E911D667A0C234A8F@BADWLRZ-SWMBX1.ads.mwn.de>
References: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>
	<4DF9A340.80400@tum.de>
	<BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>
	<9B16DFA4E75D54409B978C6E911D667A0C234A8F@BADWLRZ-SWMBX1.ads.mwn.de>
Message-ID: <BANLkTik0-fb+MgBT7HNEigEvQ3CeCVvmGw@mail.gmail.com>

> you have to be in the location and mapset where the vector is you want to read. In your case location=venest3, mapset=PERMANENT. Then start R, then
> library(spgrass6)
> readVECT6("yourvector")


Thank you Tom, but it is what is not working. I'm of course in
venest3/PERMANENT but readVECT6() does not read the vector.

I will suppose is a file or data problem because it works for example
North Carolina and spearfish60 mapsets and I'm following the same
steps with venest3.

Cheers.

On Thu, Jun 16, 2011 at 11:23, Gottfried, Tom <tom.gottfried at tum.de> wrote:
> Hi,
>
> you have to be in the location and mapset where the vector is you want to read. In your case location=venest3, mapset=PERMANENT. Then start R, then
> library(spgrass6)
> readVECT6("yourvector")
>
> regards,
> Tom
> ________________________________________
> Von: Freddy L?pez [freddy.vate01 at gmail.com]
> Gesendet: Donnerstag, 16. Juni 2011 14:44
> Bis: r-sig-geo at r-project.org
> Cc: Gottfried, Tom
> Betreff: Re: [R-sig-Geo] Reading vector data from GRASS GIS.-
>
> Dear Tom,
>
> Excuse me for the misuse of terms. I create a new location with a
> shapefile (using v.in.ogr) and it creates automatically a mapset (am I
> wrong?) in /home/vate01/grassdata/venest3/PERMANENT/vector/.
>
> Just to be nasty: PERMANENT is the (default) mapset.
>
> When I use the same steps with example datasets, this time North
> Carolina data, I get:
>
> # once inside gisdemo_ncspm location, I run R and...
>> library(spgrass6)
> Loading required package: sp
> Loading required package: rgdal
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 1.8.0, released 2011/01/12
> Path to GDAL shared files: /usr/share/gdal/1.8
> Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
> Path to PROJ.4 shared files: (autodetected)
> Loading required package: XML
> GRASS GIS interface loaded with GRASS version: 6.4.1
> and location: gisdemo_ncspm
>
> # one test...
>> plot(readVECT6('geology'))
> OGR data source with driver: GRASS
> Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/geology/head",
> layer: "1"
> with 1832 features and 8 fields
> Feature type: wkbPolygon with 2 dimensions
>
> # another test...
>> plot(readVECT6('firestations'))
> OGR data source with driver: GRASS
> Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/firestations/head",
> layer: "1"
> with 71 features and 22 fields
> Feature type: wkbPoint with 2 dimensions
>
> # ?idem...
>> plot(readVECT6('elev_points'))
> OGR data source with driver: GRASS
> Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/elev_points/head",
> layer: "1"
> with 6000 features and 2 fields
> Feature type: wkbPoint with 2 dimensions
>
> Beautiful maps; but following the same steps with venest3, it reports
> the message
>
> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
> input_field_name_encoding) :
> ?Cannot open layer
>
> Additionally, when I use readShapePoly() function (with the original
> shapefile) there are no problems. I can plot the map perfectly
> (indeed, I have used this shape several times from either R or GRASS
> but never working one from another).
>
> Thanks for your attention.
>
> Cheers.
>
>
> On Thu, Jun 16, 2011 at 02:01, Tom Gottfried <tom.gottfried at tum.de> wrote:
>> Hi Freddy,
>>
>> if, as you have written, venest3 is a location, then you can't read it as
>> vector. You have to create a mapset in your location and a vector dataset in
>> the mapset. Then you can read the vector dataset.
>>
>> regards,
>> Tom
>>
>> Am 16.06.2011 04:36, schrieb Freddy L?pez:
>>>
>>> Hello guys,
>>>
>>> I think this question is in the border: r-sig-geo or grass-user list...
>>>
>>> I want to do some interpolation using GRASS' graphical features but
>>> using code and libraries written in R and I'm trying to follow section
>>> 10.2.1 from 3rd edition GRASS BOOK (Open Source GIS: A GRASS GIS
>>> Approach).
>>>
>>> I create a location into GRASS, venest3, apparently with no problem
>>> and I can plot it using d.vect.
>>>
>>> After starting R and run the readVECT6 function I get
>>>
>>>> readVECT6('venest3')
>>>
>>> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>>> input_field_name_encoding) :
>>> ?Cannot open layer
>>>
>>> I have experimented using the spearfish60 file and it works perfectly
>>> (I selected randomly geology...):
>>>
>>>> readVECT6('geology'))
>>>
>>> OGR data source with driver: GRASS
>>> Source:
>>> "/home/vate01/grassdata/spearfish60/PERMANENT/vector/geology/head",
>>> layer: "1"
>>> with 422 features and 2 fields
>>> Feature type: wkbPolygon with 2 dimensions
>>> ...
>>>
>>>
>>> Both locations (venest3 and spearfish60), inside its 'vector'
>>> directory have the same six files: cidx, coor, dbln, head, hist, topo.
>>>
>>> Have you any ideas how can I solve this situation? How to read my vector
>>> data?
>>>
>>> Thanks in advance.-
>>>
>>>
>>> --
>>> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>>>
>>> JRR Tolkien
>>>
>>> _______________________________________________
>>> R-sig-Geo mailing list
>>> R-sig-Geo at r-project.org
>>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>>
>> --
>> Technische Universit?t M?nchen
>> Department f?r Pflanzenwissenschaften
>> Lehrstuhl f?r Gr?nlandlehre
>> Alte Akademie 12
>> 85350 Freising / Germany
>> Phone: ++49 (0)8161 715324
>> Fax: ? ++49 (0)8161 713243
>> email: tom.gottfried at wzw.tum.de
>> http://www.wzw.tum.de/gruenland
>>
>
>
>
> --
> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>
> JRR Tolkien



-- 
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From renaud.lancelot at cirad.fr  Thu Jun 16 18:27:03 2011
From: renaud.lancelot at cirad.fr (lancelot)
Date: Thu, 16 Jun 2011 18:27:03 +0200
Subject: [R-sig-Geo] spplot: character size of color key labels
In-Reply-To: <20110616123447.05af4869@OPL-EUITI>
References: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>	<4DF7D803.1090705@uni-muenster.de>
	<20110616123447.05af4869@OPL-EUITI>
Message-ID: <4DFA2ED7.8050306@cirad.fr>

Thank you Oscar. I had tried it but it fails with spplot:

 > library(sp)
 > data(meuse)
 > coordinates(meuse) <- ~ x + y
 > spplot(meuse, zcol = "ffreq", auto.key = list(cex = 3))
Error in !is.null(dots$auto.key) && dots$auto.key :
   invalid 'y' type in 'x && y'

All the best,

Renaud


Le 16/06/2011 12:34, Oscar Perpi?an Lamigueiro a ?crit :
> Hello,
>
> Following the example of Edzer, you can supply a list to auto.key
> (instead of only the TRUE value) with a replacement for some values:
>
> xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=list(cex=3))
>
> Bye,
>
> Oscar.
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From oscar.perpinan at upm.es  Fri Jun 17 02:32:38 2011
From: oscar.perpinan at upm.es (Oscar =?UTF-8?B?UGVycGnDsWFu?= Lamigueiro)
Date: Fri, 17 Jun 2011 02:32:38 +0200
Subject: [R-sig-Geo] spplot: character size of color key labels
In-Reply-To: <4DFA3CDE.6010705@uni-muenster.de>
References: <BANLkTi=RAp60gib3KVCwgXk=bcydXrhnmA@mail.gmail.com>
	<4DF7D803.1090705@uni-muenster.de>
	<20110616123447.05af4869@OPL-EUITI> <4DFA2ED7.8050306@cirad.fr>
	<4DFA3CDE.6010705@uni-muenster.de>
Message-ID: <20110617023238.2ef0f0b1@upm.es>

Hi,

It seems to be a problem with sp:::fill.call.groups. 

A workaround is to use auto.key=FALSE with spplot and then update with
auto.key=list(cex=3). It works with xyplot:

p <- xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=FALSE,
par.settings=custom.theme.2())
update(p, auto.key=list(cex=3))

However, although it also works with spplot, I cannot get good results
because it seems to ignore the par.settings argument, and therefore the
colors of the points inside the graphic are different from the points
of the legend. Perhaps I am missing something...

Bye,

Oscar.

El Thu, 16 Jun 2011 19:26:54 +0200 Edzer Pebesma
<edzer.pebesma at uni-muenster.de> escribi?:
> I also found that. Let me know if this is something urgently needed.
> 
> On 06/16/2011 06:27 PM, lancelot wrote:
> > Thank you Oscar. I had tried it but it fails with spplot:
> > 
> >> library(sp)
> >> data(meuse)
> >> coordinates(meuse) <- ~ x + y
> >> spplot(meuse, zcol = "ffreq", auto.key = list(cex = 3))
> > Error in !is.null(dots$auto.key) && dots$auto.key :
> >   invalid 'y' type in 'x && y'
> > 
> > All the best,
> > 
> > Renaud
> > 
> > 
> > Le 16/06/2011 12:34, Oscar Perpi?an Lamigueiro a ?crit :
> >> Hello,
> >>
> >> Following the example of Edzer, you can supply a list to auto.key
> >> (instead of only the TRUE value) with a replacement for some
> >> values:
> >>
> >> xyplot(a~b,data.frame(a=1:3,b=1:3,c=1:3),groups=c,auto.key=list(cex=3))
> >>
> >> Bye,
> >>
> >> Oscar.
> >>
> > 
> 


From cfusting at gmail.com  Fri Jun 17 02:53:55 2011
From: cfusting at gmail.com (Christopher Fusting)
Date: Thu, 16 Jun 2011 20:53:55 -0400
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
In-Reply-To: <BANLkTik0-fb+MgBT7HNEigEvQ3CeCVvmGw@mail.gmail.com>
References: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>
	<4DF9A340.80400@tum.de>
	<BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>
	<9B16DFA4E75D54409B978C6E911D667A0C234A8F@BADWLRZ-SWMBX1.ads.mwn.de>
	<BANLkTik0-fb+MgBT7HNEigEvQ3CeCVvmGw@mail.gmail.com>
Message-ID: <BANLkTim2jEwDH3620WSOkRFcUeZ2owtkrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/bbdfee9d/attachment.pl>

From freddy.vate01 at gmail.com  Fri Jun 17 04:37:10 2011
From: freddy.vate01 at gmail.com (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Thu, 16 Jun 2011 22:07:10 -0430
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
In-Reply-To: <BANLkTim2jEwDH3620WSOkRFcUeZ2owtkrg@mail.gmail.com>
References: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>
	<4DF9A340.80400@tum.de>
	<BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>
	<9B16DFA4E75D54409B978C6E911D667A0C234A8F@BADWLRZ-SWMBX1.ads.mwn.de>
	<BANLkTik0-fb+MgBT7HNEigEvQ3CeCVvmGw@mail.gmail.com>
	<BANLkTim2jEwDH3620WSOkRFcUeZ2owtkrg@mail.gmail.com>
Message-ID: <BANLkTimEYzArgd+3cePMeVX31wPnDiPN4Q@mail.gmail.com>

Thanks, Christopher, for your attention.

> Are you able to import other point files you have generated in this location? ?How about other vectors and rasters (also from this location).

I couldn't do it.

And v.info map=venest3 produces (it is in spanish):

GRASS 6.4.1 (venest3):~ > v.info map=venest3
 +----------------------------------------------------------------------------+
 | Capa:                venest3                                               |
 | Directorio de mapas: PERMANENT                                             |
 | Localizaci?n:        venest3                                              |
 | Base de datos:       /home/vate01/grassdata                                |
 | T?tulo:                                                                   |
 | Escala del mapa:     1:1                                                   |
 | Formato del mapa:    native                                                |
 | Nombre del creador:  vate01                                                |
 | Organizaci?n:                                                             |
 | Fecha del origen:    Wed Jun 15 21:02:40 2011                              |
 |----------------------------------------------------------------------------|
 |   Tipo de mapa:  vectorial (nivel: 2)                                      |
 |                                                                            |
 |   N?mero de puntos:        0               N?mero de ?reas:        244  |
 |   N?mero de l?neas:        0               N?mero de islas:        204  |
 |   N?mero de contornos:     313             N?mero de caras:      0       |
 |   N?mero de centroides:    230             N?mero de kernels:    0       |
 |                                                                            |
 |   Map is 3D:              No                                               |
 |   N?mero de enlaces a base de datos:      1                               |
 |                                                                            |
 |         Proyecci?n: Lat/Lon                                               |
 |               N:  15:40:47.245789N    S:   0:39:09.376273N                 |
 |               E:  58:09:55.788574W    W:  73:22:24.396973W                 |
 |                                                                            |
 |   Umbral de digitalizaci?n: 0                                             |
 |   Comentarios:                                                             |
 |                                                                            |
 +----------------------------------------------------------------------------+


Thanks again.

On Thu, Jun 16, 2011 at 20:23, Christopher Fusting <cfusting at gmail.com> wrote:
>
> Are you able to import other point files you have generated in this location? ?How about other vectors and rasters (also from this location). ?Can you post 'v.info map=venest3' command output?
> _Chris
>
> On Thu, Jun 16, 2011 at 12:23 PM, Freddy L?pez <freddy.vate01 at gmail.com> wrote:
>>
>> > you have to be in the location and mapset where the vector is you want to read. In your case location=venest3, mapset=PERMANENT. Then start R, then
>> > library(spgrass6)
>> > readVECT6("yourvector")
>>
>>
>> Thank you Tom, but it is what is not working. I'm of course in
>> venest3/PERMANENT but readVECT6() does not read the vector.
>>
>> I will suppose is a file or data problem because it works for example
>> North Carolina and spearfish60 mapsets and I'm following the same
>> steps with venest3.
>>
>> Cheers.
>>
>> On Thu, Jun 16, 2011 at 11:23, Gottfried, Tom <tom.gottfried at tum.de> wrote:
>> > Hi,
>> >
>> > you have to be in the location and mapset where the vector is you want to read. In your case location=venest3, mapset=PERMANENT. Then start R, then
>> > library(spgrass6)
>> > readVECT6("yourvector")
>> >
>> > regards,
>> > Tom
>> > ________________________________________
>> > Von: Freddy L?pez [freddy.vate01 at gmail.com]
>> > Gesendet: Donnerstag, 16. Juni 2011 14:44
>> > Bis: r-sig-geo at r-project.org
>> > Cc: Gottfried, Tom
>> > Betreff: Re: [R-sig-Geo] Reading vector data from GRASS GIS.-
>> >
>> > Dear Tom,
>> >
>> > Excuse me for the misuse of terms. I create a new location with a
>> > shapefile (using v.in.ogr) and it creates automatically a mapset (am I
>> > wrong?) in /home/vate01/grassdata/venest3/PERMANENT/vector/.
>> >
>> > Just to be nasty: PERMANENT is the (default) mapset.
>> >
>> > When I use the same steps with example datasets, this time North
>> > Carolina data, I get:
>> >
>> > # once inside gisdemo_ncspm location, I run R and...
>> >> library(spgrass6)
>> > Loading required package: sp
>> > Loading required package: rgdal
>> > Geospatial Data Abstraction Library extensions to R successfully loaded
>> > Loaded GDAL runtime: GDAL 1.8.0, released 2011/01/12
>> > Path to GDAL shared files: /usr/share/gdal/1.8
>> > Loaded PROJ.4 runtime: Rel. 4.7.1, 23 September 2009
>> > Path to PROJ.4 shared files: (autodetected)
>> > Loading required package: XML
>> > GRASS GIS interface loaded with GRASS version: 6.4.1
>> > and location: gisdemo_ncspm
>> >
>> > # one test...
>> >> plot(readVECT6('geology'))
>> > OGR data source with driver: GRASS
>> > Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/geology/head",
>> > layer: "1"
>> > with 1832 features and 8 fields
>> > Feature type: wkbPolygon with 2 dimensions
>> >
>> > # another test...
>> >> plot(readVECT6('firestations'))
>> > OGR data source with driver: GRASS
>> > Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/firestations/head",
>> > layer: "1"
>> > with 71 features and 22 fields
>> > Feature type: wkbPoint with 2 dimensions
>> >
>> > # ?idem...
>> >> plot(readVECT6('elev_points'))
>> > OGR data source with driver: GRASS
>> > Source: "/home/vate01/grassdata/gisdemo_ncspm/PERMANENT/vector/elev_points/head",
>> > layer: "1"
>> > with 6000 features and 2 fields
>> > Feature type: wkbPoint with 2 dimensions
>> >
>> > Beautiful maps; but following the same steps with venest3, it reports
>> > the message
>> >
>> > Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>> > input_field_name_encoding) :
>> > ?Cannot open layer
>> >
>> > Additionally, when I use readShapePoly() function (with the original
>> > shapefile) there are no problems. I can plot the map perfectly
>> > (indeed, I have used this shape several times from either R or GRASS
>> > but never working one from another).
>> >
>> > Thanks for your attention.
>> >
>> > Cheers.
>> >
>> >
>> > On Thu, Jun 16, 2011 at 02:01, Tom Gottfried <tom.gottfried at tum.de> wrote:
>> >> Hi Freddy,
>> >>
>> >> if, as you have written, venest3 is a location, then you can't read it as
>> >> vector. You have to create a mapset in your location and a vector dataset in
>> >> the mapset. Then you can read the vector dataset.
>> >>
>> >> regards,
>> >> Tom
>> >>
>> >> Am 16.06.2011 04:36, schrieb Freddy L?pez:
>> >>>
>> >>> Hello guys,
>> >>>
>> >>> I think this question is in the border: r-sig-geo or grass-user list...
>> >>>
>> >>> I want to do some interpolation using GRASS' graphical features but
>> >>> using code and libraries written in R and I'm trying to follow section
>> >>> 10.2.1 from 3rd edition GRASS BOOK (Open Source GIS: A GRASS GIS
>> >>> Approach).
>> >>>
>> >>> I create a location into GRASS, venest3, apparently with no problem
>> >>> and I can plot it using d.vect.
>> >>>
>> >>> After starting R and run the readVECT6 function I get
>> >>>
>> >>>> readVECT6('venest3')
>> >>>
>> >>> Error en ogrInfo(dsn = dsn, layer = layer, input_field_name_encoding =
>> >>> input_field_name_encoding) :
>> >>> ?Cannot open layer
>> >>>
>> >>> I have experimented using the spearfish60 file and it works perfectly
>> >>> (I selected randomly geology...):
>> >>>
>> >>>> readVECT6('geology'))
>> >>>
>> >>> OGR data source with driver: GRASS
>> >>> Source:
>> >>> "/home/vate01/grassdata/spearfish60/PERMANENT/vector/geology/head",
>> >>> layer: "1"
>> >>> with 422 features and 2 fields
>> >>> Feature type: wkbPolygon with 2 dimensions
>> >>> ...
>> >>>
>> >>>
>> >>> Both locations (venest3 and spearfish60), inside its 'vector'
>> >>> directory have the same six files: cidx, coor, dbln, head, hist, topo.
>> >>>
>> >>> Have you any ideas how can I solve this situation? How to read my vector
>> >>> data?
>> >>>
>> >>> Thanks in advance.-
>> >>>
>> >>>
>> >>> --
>> >>> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>> >>>
>> >>> JRR Tolkien
>> >>>
>> >>> _______________________________________________
>> >>> R-sig-Geo mailing list
>> >>> R-sig-Geo at r-project.org
>> >>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>> >>
>> >> --
>> >> Technische Universit?t M?nchen
>> >> Department f?r Pflanzenwissenschaften
>> >> Lehrstuhl f?r Gr?nlandlehre
>> >> Alte Akademie 12
>> >> 85350 Freising / Germany
>> >> Phone: ++49 (0)8161 715324
>> >> Fax: ? ++49 (0)8161 713243
>> >> email: tom.gottfried at wzw.tum.de
>> >> http://www.wzw.tum.de/gruenland
>> >>
>> >
>> >
>> >
>> > --
>> > ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>> >
>> > JRR Tolkien
>>
>>
>>
>> --
>> ?But Gwindor answered: 'The doom lies in yourself, not in your name.'?
>>
>> JRR Tolkien
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
>
>
> --
> Christopher W. Fusting
>
> Specializing in Geospatial?:
> Analysis
> Data Modeling
> Application Development
>
> Cell:
> 828-772-0012



--
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From cfusting at gmail.com  Fri Jun 17 05:27:06 2011
From: cfusting at gmail.com (Christopher Fusting)
Date: Thu, 16 Jun 2011 23:27:06 -0400
Subject: [R-sig-Geo] Reading vector data from GRASS GIS.-
In-Reply-To: <BANLkTimEYzArgd+3cePMeVX31wPnDiPN4Q@mail.gmail.com>
References: <BANLkTi=Ma=J892cs9E_PibAQmrdeDo5Kxw@mail.gmail.com>
	<4DF9A340.80400@tum.de>
	<BANLkTi=-w3myNK0U=4Xm+z0L4d0EHr5n1w@mail.gmail.com>
	<9B16DFA4E75D54409B978C6E911D667A0C234A8F@BADWLRZ-SWMBX1.ads.mwn.de>
	<BANLkTik0-fb+MgBT7HNEigEvQ3CeCVvmGw@mail.gmail.com>
	<BANLkTim2jEwDH3620WSOkRFcUeZ2owtkrg@mail.gmail.com>
	<BANLkTimEYzArgd+3cePMeVX31wPnDiPN4Q@mail.gmail.com>
Message-ID: <BANLkTikyoPNGFx-oaBqNqb8-mV21pGd7tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110616/72d414ad/attachment.pl>

From narayani at ku.edu  Fri Jun 17 20:02:07 2011
From: narayani at ku.edu (Narayani Barve)
Date: Fri, 17 Jun 2011 13:02:07 -0500
Subject: [R-sig-Geo] NetCDF file size
Message-ID: <BANLkTi=DvDpbW9XfMKHsGArRMHffDnZUeQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110617/16e4df11/attachment.pl>

From bstults at fsu.edu  Fri Jun 17 20:56:41 2011
From: bstults at fsu.edu (Brian J. Stults)
Date: Fri, 17 Jun 2011 14:56:41 -0400
Subject: [R-sig-Geo] gUnion:  no outgoing dirEdge found
Message-ID: <4DFBA369.2090403@fsu.edu>

Hello,

I am trying to create a union and intersection between two shapefiles.
They consist of census tracts in the state of Delaware - one file for
1990 and the other for 2000.  They are available here:

http://www2.criminology.fsu.edu/~stults/misc/delaware_tracts.zip

I would like to generate a shapefile that includes all identical
polygons between the two layers as well as all portions that intersect
(i.e. "union" in Qgis).  I believe gUnion is the function I need to use.

Here is my code:

library(maptools)
library(rgeos)

de1990 <- readShapePoly("shapefiles/subset_1990_de.shp")
de2000 <- readShapePoly("shapefiles/subset_2000_de.shp")

union <- gUnion(de1990, de2000)


I receive the following error (full output attached):

> union <- gUnion(de1990, de2000)
Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, "rgeos_union") :
  TopologyException: no outgoing dirEdge found at -77.0822 38.9222
Calls: gUnion -> RGEOSBinTopoFunc -> .Call
Execution halted

I confirmed that the polygons are valid using gIsValid, but maybe that's
not what this error is indicating.

I am able to successfully do the union in Qgis.  However, I eventually
need to do this for the entire U.S. for several decades, and just one
union of the full U.S. takes several days to complete on my desktop.  I
would rather run it in R on my university's supercomputer, which would
significantly reduce the run-time.

I am hoping that this does not require editing the shapefile, since I
could not possibly do that for all tracts in the U.S.

Thanks for any suggestions,
Brian


-- 
Brian J. Stults
Assistant Professor
College of Criminology and Criminal Justice
Florida State University
phone: 850-645-7376   fax: 850-644-9614
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: union_intersect.rlog
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110617/9e5f007a/attachment.pl>

From Roger.Bivand at nhh.no  Fri Jun 17 22:03:44 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 17 Jun 2011 22:03:44 +0200 (CEST)
Subject: [R-sig-Geo] gUnion:  no outgoing dirEdge found
In-Reply-To: <4DFBA369.2090403@fsu.edu>
References: <4DFBA369.2090403@fsu.edu>
Message-ID: <alpine.LRH.2.00.1106172115340.13578@reclus.nhh.no>

On Fri, 17 Jun 2011, Brian J. Stults wrote:

> Hello,
>
> I am trying to create a union and intersection between two shapefiles.
> They consist of census tracts in the state of Delaware - one file for
> 1990 and the other for 2000.  They are available here:
>
> http://www2.criminology.fsu.edu/~stults/misc/delaware_tracts.zip
>
> I would like to generate a shapefile that includes all identical
> polygons between the two layers as well as all portions that intersect
> (i.e. "union" in Qgis).  I believe gUnion is the function I need to use.

I can replicate the GEOS error:

> union <- gUnion(de1990, de2000)
Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, "rgeos_union") :
   TopologyException: no outgoing dirEdge found at -77.0822 38.9222

but in:

> sessionInfo()
R version 2.13.0 (2011-04-13)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
...

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rgeos_0.1-8     stringr_0.5     maptools_0.8-9  lattice_0.19-26
[5] sp_0.9-83       foreign_0.8-44

loaded via a namespace (and not attached):
[1] grid_2.13.0  plyr_1.5.2   tools_2.13.0

no error exit - is this a script running on a node, if so, could you catch 
errors with try() or similar means? I am in doubt about whether your 
approach is sensible, and suspect that running gEquals(de1990, de2000, 
byid=TRUE) first to establish the duplicates, then tackle the ones which 
are not seen as equal. Most of the polygons are the same:

eq <- gEquals(de1990, de2000, byid=TRUE)
sum(apply(eq, 2, any))
sum(apply(eq, 1, any))
plot(de1990, col="cyan", border="transparent")
plot(de1990[apply(eq, 2, any),], add=TRUE)
nde1990 <- de1990[!apply(eq, 2, any),]
nde2000 <- de2000[!apply(eq, 1, any),]

then step through int row by row (or column by column) to union the ones 
for which the correct predicate is TRUE for that combination. I'm unsure 
whether you want to dissolve to the 2000 file or the other way round, or 
to create sub-units permiting either to be reconstructed, so I can't 
suggest further steps now. The predicates should let you find the 
geometries on which topology operations are to be performed, which should 
then work provided that the shapefiles are clean. The trick seems to be in 
finding the right predicates, then the right operation, but it needs 
interactive analysis to work through use cases and instrument a script to 
be sure that the correct joins are being made.

Hope this helps,

Roger


>
> Here is my code:
>
> library(maptools)
> library(rgeos)
>
> de1990 <- readShapePoly("shapefiles/subset_1990_de.shp")
> de2000 <- readShapePoly("shapefiles/subset_2000_de.shp")
>
> union <- gUnion(de1990, de2000)
>
>
> I receive the following error (full output attached):
>
>> union <- gUnion(de1990, de2000)
> Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, "rgeos_union") :
>  TopologyException: no outgoing dirEdge found at -77.0822 38.9222
> Calls: gUnion -> RGEOSBinTopoFunc -> .Call
> Execution halted
>
> I confirmed that the polygons are valid using gIsValid, but maybe that's
> not what this error is indicating.
>
> I am able to successfully do the union in Qgis.  However, I eventually
> need to do this for the entire U.S. for several decades, and just one
> union of the full U.S. takes several days to complete on my desktop.  I
> would rather run it in R on my university's supercomputer, which would
> significantly reduce the run-time.
>
> I am hoping that this does not require editing the shapefile, since I
> could not possibly do that for all tracts in the U.S.
>
> Thanks for any suggestions,
> Brian
>
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From bstults at fsu.edu  Fri Jun 17 22:27:52 2011
From: bstults at fsu.edu (Brian J. Stults)
Date: Fri, 17 Jun 2011 16:27:52 -0400
Subject: [R-sig-Geo] gUnion:  no outgoing dirEdge found
In-Reply-To: <alpine.LRH.2.00.1106172115340.13578@reclus.nhh.no>
References: <4DFBA369.2090403@fsu.edu>
	<alpine.LRH.2.00.1106172115340.13578@reclus.nhh.no>
Message-ID: <4DFBB8C8.9040307@fsu.edu>

On 06/17/2011 04:03 PM, Roger Bivand wrote:
> On Fri, 17 Jun 2011, Brian J. Stults wrote:
> 
> no error exit - is this a script running on a node, if so, could you
> catch errors with try() or similar means? I am in doubt about whether

Yes, it is a script.  Wrapping the command in try() or tryCatch()
resulted in the same output, as did running the commands interactively.

> your approach is sensible, and suspect that running gEquals(de1990,
> de2000, byid=TRUE) first to establish the duplicates, then tackle the
> ones which are not seen as equal. Most of the polygons are the same:

Delaware 1990-2000 is probably not a good example since tracts did not
change much.  Indeed, that's why I chose it to test with, so it might
run more quickly and be less confusing to me.  When I union 1970 and
2010, there will be many more differences (though fewer tracted areas in
1970).

> 
> eq <- gEquals(de1990, de2000, byid=TRUE)
> sum(apply(eq, 2, any))
> sum(apply(eq, 1, any))
> plot(de1990, col="cyan", border="transparent")
> plot(de1990[apply(eq, 2, any),], add=TRUE)
> nde1990 <- de1990[!apply(eq, 2, any),]
> nde2000 <- de2000[!apply(eq, 1, any),]
> 
> then step through int row by row (or column by column) to union the ones
> for which the correct predicate is TRUE for that combination. I'm unsure
> whether you want to dissolve to the 2000 file or the other way round, or
> to create sub-units permiting either to be reconstructed, so I can't
> suggest further steps now. The predicates should let you find the

I want to retain all sub-units, so I think the last option you listed is
what I want.

> geometries on which topology operations are to be performed, which
> should then work provided that the shapefiles are clean. The trick seems
> to be in finding the right predicates, then the right operation, but it
> needs interactive analysis to work through use cases and instrument a
> script to be sure that the correct joins are being made.

I very much look forward to being capable of doing what you suggest, but
right now I think it is beyond my coding ability in R.  I hate to give
up so quickly, but perhaps the better option for now is compiling Qgis
on the supercomputer and running the union that way.  But I *will*
eventually learn how to do it in R.

Thanks!


From b.rowlingson at lancaster.ac.uk  Sat Jun 18 01:28:08 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 18 Jun 2011 00:28:08 +0100
Subject: [R-sig-Geo] NetCDF file size
In-Reply-To: <BANLkTi=DvDpbW9XfMKHsGArRMHffDnZUeQ@mail.gmail.com>
References: <BANLkTi=DvDpbW9XfMKHsGArRMHffDnZUeQ@mail.gmail.com>
Message-ID: <BANLkTinOZVeePVnQvKzCncC554gY+5-xLw@mail.gmail.com>

On Fri, Jun 17, 2011 at 7:02 PM, Narayani Barve <narayani at ku.edu> wrote:
> Hi All,
>
> I am using ncdf package to manipulate netcdf file downloaded from ECMWF
> website. The downloaded data file contains 8 observations per day for a
> single variable. The size of file is 800+ mb for a whole year data. The
> dimension for the data is 240 x 120 x 1460, where 240 is DimX, 120 is DimY
> and 2920 is Time Dimension. I want to take only 4 observations from this
> file. To do this I wrote a script in R and used ncdf package to manipulate
> the data. My script is working great. And my effective dimension of the
> variable is 240 x 120 x 1460 (which is half of 2920). The only trouble is
> size of the new file is same as old file. In my opinion, the file size
> should have reduced to half. But this is not happening. Is there any
> documentation which tell me more about how the file size is decided, OR Do
> you think I am doing something wrong ? OR is there any way to compact the
> file size like in Microsoft Access, there is a option to compact database ?
>
> Thanks in advance, any help is appreciated.

 Hard to tell without seeing your code. I suspect either you are
creating the new netcdf file with the same dimensions as the original,
and then only writing the first 1460 of the time dimension, or
possibly your source file is in single precision and you are writing
in double precision...

Barry


From mdsumner at gmail.com  Sat Jun 18 01:28:33 2011
From: mdsumner at gmail.com (Michael Sumner)
Date: Sat, 18 Jun 2011 09:28:33 +1000
Subject: [R-sig-Geo] NetCDF file size
In-Reply-To: <BANLkTi=DvDpbW9XfMKHsGArRMHffDnZUeQ@mail.gmail.com>
References: <BANLkTi=DvDpbW9XfMKHsGArRMHffDnZUeQ@mail.gmail.com>
Message-ID: <BANLkTikbacwX=nrwVVLTo=V=caBfEmafdQ@mail.gmail.com>

Please post the code you use to create the file. There are a number of
possibilities for why the file size may not have changed, but frankly
I expect you have just created a file with the original dimensions.

Your description is at least inconsistent in reporting the size here:

> dimension for the data is 240 x 120 x 1460, where 240 is DimX, 120 is DimY
> and 2920 is Time Dimension. I want to take only 4 observations from this

There's no point in us speculating in what your code might be doing
when you could share it with us and we would know exactly.

Cheers, Mike.

On Sat, Jun 18, 2011 at 4:02 AM, Narayani Barve <narayani at ku.edu> wrote:
> Hi All,
>
> I am using ncdf package to manipulate netcdf file downloaded from ECMWF
> website. The downloaded data file contains 8 observations per day for a
> single variable. The size of file is 800+ mb for a whole year data. The
> dimension for the data is 240 x 120 x 1460, where 240 is DimX, 120 is DimY
> and 2920 is Time Dimension. I want to take only 4 observations from this
> file. To do this I wrote a script in R and used ncdf package to manipulate
> the data. My script is working great. And my effective dimension of the
> variable is 240 x 120 x 1460 (which is half of 2920). The only trouble is
> size of the new file is same as old file. In my opinion, the file size
> should have reduced to half. But this is not happening. Is there any
> documentation which tell me more about how the file size is decided, OR Do
> you think I am doing something wrong ? OR is there any way to compact the
> file size like in Microsoft Access, there is a option to compact database ?
>
> Thanks in advance, any help is appreciated.
>
> Narayani Barve
>
> --
> Narayani Barve
> PhD Student,
> Ecology and Evolutionary Biology,
> University of Kansas, KS 66044
>
> ? ? ? ?[[alternative HTML version deleted]]
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Michael Sumner
Institute for Marine and Antarctic Studies, University of Tasmania
Hobart, Australia
e-mail: mdsumner at gmail.com


From Roger.Bivand at nhh.no  Sat Jun 18 14:56:41 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 18 Jun 2011 14:56:41 +0200 (CEST)
Subject: [R-sig-Geo] gUnion:  no outgoing dirEdge found
In-Reply-To: <4DFBB8C8.9040307@fsu.edu>
References: <4DFBA369.2090403@fsu.edu>
	<alpine.LRH.2.00.1106172115340.13578@reclus.nhh.no>
	<4DFBB8C8.9040307@fsu.edu>
Message-ID: <alpine.LRH.2.00.1106181250290.15851@reclus.nhh.no>

On Fri, 17 Jun 2011, Brian J. Stults wrote:

> On 06/17/2011 04:03 PM, Roger Bivand wrote:
>> On Fri, 17 Jun 2011, Brian J. Stults wrote:
>>
>> no error exit - is this a script running on a node, if so, could you
>> catch errors with try() or similar means? I am in doubt about whether
>
> Yes, it is a script.  Wrapping the command in try() or tryCatch()
> resulted in the same output, as did running the commands interactively.
>
>> your approach is sensible, and suspect that running gEquals(de1990,
>> de2000, byid=TRUE) first to establish the duplicates, then tackle the
>> ones which are not seen as equal. Most of the polygons are the same:
>
> Delaware 1990-2000 is probably not a good example since tracts did not
> change much.  Indeed, that's why I chose it to test with, so it might
> run more quickly and be less confusing to me.  When I union 1970 and
> 2010, there will be many more differences (though fewer tracted areas in
> 1970).
>

For your data, this works:

library(maptools)
de1990 <- readShapeSpatial("subset_1990_de")
de2000 <- readShapeSpatial("subset_2000_de")
library(rgeos)
slot(de1990, "polygons") <- lapply(slot(de1990, "polygons"),
   checkPolygonsHoles)
slot(de2000, "polygons") <- lapply(slot(de2000, "polygons"),
   checkPolygonsHoles)
row.names(de1990) <- paste("de1990", row.names(de1990), sep="_")
row.names(de2000) <- paste("de2000", row.names(de2000), sep="_")
eq <- gEquals(de1990, de2000, byid=TRUE)
nde1990 <- de1990[!apply(eq, 2, any),]
nde2000 <- de2000[!apply(eq, 1, any),]
eq1 <- eq[apply(eq, 1, any), apply(eq, 2, any)]
wh <- which(eq1, arr.ind=TRUE)
same <- de1990[apply(eq, 2, any),]
row.names(same) <- paste(row.names(same), row.names(de2000[apply(eq, 1,
   any),])[wh[,1]])
int <- gIntersects(nde1990, nde2000, byid=TRUE)
vec <- vector(mode="list", length=dim(int)[2])
for (i in seq(along=vec)) vec[[i]] <- try(gUnion(nde1990[i,],
   nde2000[int[,i],], byid=TRUE))
# needs checking for non-SpatialPolygons entities
out <- do.call("rbind", vec)

plot(out, col="cyan")
plot(same, col="magenta", add=TRUE)

out1 <- spRbind(out, same)

plot(de1990, col="cyan", border="magenta")
plot(out1, add=TRUE)

plot(de2000, col="cyan", border="magenta")
plot(out1, add=TRUE)

row.names(out1)

Apart from working, I think that it suggests that union is not the 
operation needed (the plot of merged borders on 1990 borders shows that 
some 1990 borders are not respected in the merged set), but perhaps rather 
a sequence of intersection, and two asymmetric differences, before 
combining on completion, so that all the parts get retained whether split 
or joined between periods.

For your larger project, you will also run into cleaning issues, and 
possibly also datum shift and precision model questions. The underlying 
data are presumably Tiger, which typically do need manual intervention, I 
believe. Have you tried to do this in a topological GIS, either ArcINFO or 
GRASS?

For me on GRASS 6.4.1, a sequence of two v.in.ogr commands in a suitable 
location and region, followed by v.overlay, then v.out.ogr, generates what 
is needed. Building GRASS for your cluster and scripting it in shell 
script should be easier than QGIS:

v.in.ogr -o dsn=. layer=subset_1990_de output=de1990
v.in.ogr -o dsn=. layer=subset_2000_de output=de2000
v.overlay ainput=de1990 binput=de2000 output=overlay
v.out.ogr -c input=overlay type=area dsn=. olayer=overlay

in region:

> g.region -p
projection: 3 (Latitude-Longitude)
zone:       0
datum:      nad83
ellipsoid:  grs80
north:      39N
south:      38:48N
west:       77:07:12W
east:       76:54W

Or from within R:

library(rgdal)
de2000 <- readOGR(".", "subset_2000_de")
de1990 <- readOGR(".", "subset_1990_de")
proj4string(de2000) <- CRS("+proj=longlat +datum=NAD83")
proj4string(de1990) <- CRS("+proj=longlat +datum=NAD83")
library(maptools)
SG <- Sobj_SpatialGrid(de1990)$SG
library(spgrass6)
# using a throw-away temporary location and
# my GRASS installation path
initGRASS("/home/rsb/topics/grass/g641/grass-6.4.1", tempdir(), SG)
# need to ensure that location is in correct
# coordinate reference system
execGRASS("g.proj", flags="p")
tf <- tempfile()
mapset <- execGRASS("g.gisenv", parameters=list(get="MAPSET"), 
intern=TRUE)
execGRASS("g.gisenv", parameters=list(set=shQuote('MAPSET=PERMANENT')))
prj <- showWKT(proj4string(de1990), tf)
execGRASS("g.proj", flags="c", parameters=list(wkt=tf))
execGRASS("g.proj", flags="p")
execGRASS("g.gisenv", parameters=list(set=paste("'MAPSET=", mapset,
  "'", sep="")))
execGRASS("g.region", flags="d")
# now in correct CRS
writeVECT6(de1990, "de1990")
writeVECT6(de2000, "de2000")
execGRASS("v.overlay", parameters=list(ainput="de1990", binput="de2000",
   output="overlay"))
o <- readVECT6("overlay", with_c=TRUE)
plot(de1990, col="cyan", border="magenta")
plot(o, add=TRUE)
plot(de2000, col="cyan", border="magenta")
plot(o, add=TRUE)

GRASS is doing what you need it to do. You don't need QGIS to use GRASS, 
but GRASS - because it is constructing the topology for each vector 
object, can avoid the awkwardness of using the OGC SFS constructions used 
in GEOS. So my advice would be to deploy GRASS, but you'll need to be 
careful to construct the locations, regions, and CRS suitably. The GRASS 
book by Neteler and Mitasova (2008, 3rd ed.), has a discussion of 
v.overlay on pp. 206-208.

Hope this helps,

Roger



>>
>> eq <- gEquals(de1990, de2000, byid=TRUE)
>> sum(apply(eq, 2, any))
>> sum(apply(eq, 1, any))
>> plot(de1990, col="cyan", border="transparent")
>> plot(de1990[apply(eq, 2, any),], add=TRUE)
>> nde1990 <- de1990[!apply(eq, 2, any),]
>> nde2000 <- de2000[!apply(eq, 1, any),]
>>
>> then step through int row by row (or column by column) to union the ones
>> for which the correct predicate is TRUE for that combination. I'm unsure
>> whether you want to dissolve to the 2000 file or the other way round, or
>> to create sub-units permiting either to be reconstructed, so I can't
>> suggest further steps now. The predicates should let you find the
>
> I want to retain all sub-units, so I think the last option you listed is
> what I want.
>
>> geometries on which topology operations are to be performed, which
>> should then work provided that the shapefiles are clean. The trick seems
>> to be in finding the right predicates, then the right operation, but it
>> needs interactive analysis to work through use cases and instrument a
>> script to be sure that the correct joins are being made.
>
> I very much look forward to being capable of doing what you suggest, but
> right now I think it is beyond my coding ability in R.  I hate to give
> up so quickly, but perhaps the better option for now is compiling Qgis
> on the supercomputer and running the union that way.  But I *will*
> eventually learn how to do it in R.
>
> Thanks!
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From renaud.lancelot at cirad.fr  Sat Jun 18 20:50:04 2011
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sat, 18 Jun 2011 20:50:04 +0200
Subject: [R-sig-Geo] random locations within a SpatialPolygonsDataFrame
Message-ID: <4DFCF35C.5020601@cirad.fr>

Dear all,

How can I draw a random set of locations within the borders of a 
SpatialPolygonsDataFrame? I'd like something similar to function 
runifpoint in package spatstat.

All the best,

Renaud
-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From emmanuel.blondel1 at gmail.com  Sat Jun 18 21:23:41 2011
From: emmanuel.blondel1 at gmail.com (Emmanuel Blondel)
Date: Sat, 18 Jun 2011 21:23:41 +0200
Subject: [R-sig-Geo] random locations within a SpatialPolygonsDataFrame
In-Reply-To: <4DFCF35C.5020601@cirad.fr>
References: <4DFCF35C.5020601@cirad.fr>
Message-ID: <4DFCFB3D.5040209@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110618/0240d936/attachment.pl>

From renaud.lancelot at cirad.fr  Sat Jun 18 21:35:17 2011
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sat, 18 Jun 2011 21:35:17 +0200
Subject: [R-sig-Geo] random locations within a SpatialPolygonsDataFrame
In-Reply-To: <4DFCFB3D.5040209@gmail.com>
References: <4DFCF35C.5020601@cirad.fr> <4DFCFB3D.5040209@gmail.com>
Message-ID: <4DFCFDF5.5080407@cirad.fr>

Dear Emmanuel,

Thank you for the suggestion. I am aware of spsample but it is not 
appropriate to my needs. I want to generate a random sample of points 
within the borders of a SpatialPolygonsDataFrame, like runifpoint does 
with the borders of an owin object.

Best wishes,

Renaud

Le 18/06/2011 21:23, Emmanuel Blondel a ?crit :
> Hello Renaud,
>
> To create a random set of locations in a SpatialPolygonsDataFrame, did
> you try to use the function *spsample*() from package sp?
> See:
> http://www.dpi.inpe.br/gilberto/tutorials/software/R-contrib/sp/html/spsample.html
> In your case, you would specify type="random".
>
> Cheers,
> Emmanuel
>
>
> Le 18/06/2011 20:50, lancelot a ?crit :
>> Dear all,
>>
>> How can I draw a random set of locations within the borders of a
>> SpatialPolygonsDataFrame? I'd like something similar to function
>> runifpoint in package spatstat.
>>
>> All the best,
>>
>> Renaud
>
>
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From renaud.lancelot at cirad.fr  Sat Jun 18 23:24:02 2011
From: renaud.lancelot at cirad.fr (lancelot)
Date: Sat, 18 Jun 2011 23:24:02 +0200
Subject: [R-sig-Geo] random locations within a SpatialPolygonsDataFrame
In-Reply-To: <BANLkTinxSAKAmBu9=zD-dcdpFnO1hzPbtw@mail.gmail.com>
References: <4DFCF35C.5020601@cirad.fr>
	<BANLkTinxSAKAmBu9=zD-dcdpFnO1hzPbtw@mail.gmail.com>
Message-ID: <4DFD1772.6050608@cirad.fr>

Thank you very much! I had completely overlooked this simple and obvious 
solution!

All the best,

Renaud

Le 18/06/2011 23:08, Ant?nio M. Rodrigues a ?crit :
> Hi Renaud,
>
> Try spsample {sp}.
>
> Something like:
>
> ppp <- spsample(SPDF, type="random", n=100)
>
> will randomly create 100 points within the borders of
> the SpatialPolygonsDataFrame SPDF.
>
> Hope it helps.
> Ant?no
>
> 2011/6/18 lancelot <renaud.lancelot at cirad.fr
> <mailto:renaud.lancelot at cirad.fr>>
>
>     Dear all,
>
>     How can I draw a random set of locations within the borders of a
>     SpatialPolygonsDataFrame? I'd like something similar to function
>     runifpoint in package spatstat.
>
>     All the best,
>
>     Renaud
>     --
>     Renaud Lancelot
>     EDENext Project, coordinator: http://www.edenext.eu/
>
>     CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
>     F34398 Montpellier
>
>     Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
>     Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69
>
>     _________________________________________________
>     R-sig-Geo mailing list
>     R-sig-Geo at r-project.org <mailto:R-sig-Geo at r-project.org>
>     https://stat.ethz.ch/mailman/__listinfo/r-sig-geo
>     <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>
>
>

-- 
Renaud Lancelot
EDENext Project, coordinator: http://www.edenext.eu/

CIRAD, UMR15, Campus International de Baillarguet TA A-DIR / B
F34398 Montpellier

Tel.  +33 4 67 59 37 17  -  Fax  +33 4 67 59 37 95
Secr. +33 4 67 59 37 37  - Cell. +33 6 77 52 08 69


From narayani at ku.edu  Sun Jun 19 17:40:54 2011
From: narayani at ku.edu (Narayani Barve)
Date: Sun, 19 Jun 2011 10:40:54 -0500
Subject: [R-sig-Geo] NetCDF file size
In-Reply-To: <BANLkTinOZVeePVnQvKzCncC554gY+5-xLw@mail.gmail.com>
References: <BANLkTi=DvDpbW9XfMKHsGArRMHffDnZUeQ@mail.gmail.com>
	<BANLkTinOZVeePVnQvKzCncC554gY+5-xLw@mail.gmail.com>
Message-ID: <BANLkTi=pw_k=B4-eg-155zoq4DZuwkGmzg@mail.gmail.com>

Thank you Mike and Barry for your response. I am attaching my code with this
email. I am actually taking the dimension from original file as it is, like
name, units, precision etc. But I am changing the dimension value in the
program. I am not expert in R, so the code is not very compact.

In my previous email there was a mistake, the dimension of the original file
is 240 x 120 x 2920, where 240 is DimX, 120 is DimY and 2920 is Time
Dimension. The new file dimension is 240 x 120 x 1460, where 240 is DimX,
120 is DimY and 1460 is Time Dimension. I am changing time dimension in the
destination file.

Thanks in advance,

Narayani

On Fri, Jun 17, 2011 at 6:28 PM, Barry Rowlingson <
b.rowlingson at lancaster.ac.uk> wrote:

> On Fri, Jun 17, 2011 at 7:02 PM, Narayani Barve <narayani at ku.edu> wrote:
> > Hi All,
> >
> > I am using ncdf package to manipulate netcdf file downloaded from ECMWF
> > website. The downloaded data file contains 8 observations per day for a
> > single variable. The size of file is 800+ mb for a whole year data. The
> > dimension for the data is 240 x 120 x 1460, where 240 is DimX, 120 is
> DimY
> > and 2920 is Time Dimension. I want to take only 4 observations from this
> > file. To do this I wrote a script in R and used ncdf package to
> manipulate
> > the data. My script is working great. And my effective dimension of the
> > variable is 240 x 120 x 1460 (which is half of 2920). The only trouble is
> > size of the new file is same as old file. In my opinion, the file size
> > should have reduced to half. But this is not happening. Is there any
> > documentation which tell me more about how the file size is decided, OR
> Do
> > you think I am doing something wrong ? OR is there any way to compact the
> > file size like in Microsoft Access, there is a option to compact database
> ?
> >
> > Thanks in advance, any help is appreciated.
>
>  Hard to tell without seeing your code. I suspect either you are
> creating the new netcdf file with the same dimensions as the original,
> and then only writing the first 1460 of the time dimension, or
> possibly your source file is in single precision and you are writing
> in double precision...
>
> Barry
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



-- 
Narayani Barve
PhD Student,
Ecology and Evolutionary Biology,
University of Kansas, KS 66044
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110619/2ebe7156/attachment.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: WriteFile2.R
Type: application/octet-stream
Size: 2501 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110619/2ebe7156/attachment.obj>

From whitf015 at umn.edu  Mon Jun 20 00:04:30 2011
From: whitf015 at umn.edu (Tim Whitfeld)
Date: Sun, 19 Jun 2011 17:04:30 -0500
Subject: [R-sig-Geo] Using spatial autocoregressive models
Message-ID: <4DFE726E.7050508@umn.edu>

I'm new to the list and am hoping for some assistance with analysis for 
a paper that investigates patterns of tree diversity in the tropics. For 
this project I surveyed all trees in a 19 quarter hectare plots in a 
tropical lowland rainforest. I'm interested in testing whether the 
observed correlation between patterns of diversity (measured by mean 
evolutionary distance between all trees in each plot) and total tree 
area (measured by total cross sectional area of tree trunks at 1.3 m 
above ground level, i.e., the basal area) is confounded by plot location 
(measured by UTM coordinates). In other word, I want to test whether 
spatial auto correlation is driving the observed relationship. I have 
performed a partial Mantel test that indicates no spatial 
autocorrelation but I'd also like to test this with a more sophisticated 
approach using simultaneous autogressive models. I understand SAR models 
can be implemented in R using the spdep package. I have used R with 
other packages but am no expert. Does anyone have an example or a walk 
through of how to run the type of analysis I'm interested in and also 
how to interpret the results?
With thanks, Tim


From mathieu.rajerison at gmail.com  Mon Jun 20 01:32:14 2011
From: mathieu.rajerison at gmail.com (Mathieu Rajerison)
Date: Mon, 20 Jun 2011 01:32:14 +0200
Subject: [R-sig-Geo] Using spatial autocoregressive models
In-Reply-To: <4DFE726E.7050508@umn.edu>
References: <4DFE726E.7050508@umn.edu>
Message-ID: <BANLkTindscRvNpo4nAfVXLVRCOD95tBynQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110620/412caca2/attachment.pl>

From ana.nuno08 at imperial.ac.uk  Mon Jun 20 15:30:50 2011
From: ana.nuno08 at imperial.ac.uk (Ana Nuno)
Date: Mon, 20 Jun 2011 14:30:50 +0100
Subject: [R-sig-Geo] spatially autocorrelated wildlife counts
Message-ID: <BANLkTimkPpZ4POiZOA3AOeZZ32z9nd+qSg@mail.gmail.com>

Dear list,

I have a few beginners' questions and I would greatly appreciate your
comments and suggestions.

I am trying to simulate the distribution of a ungulate species across
a landscape, where animals of this species are spatially aggregated
(exact aggregation level is unknown so I'll have a range of values). I
know the "true" size of this population because it results from my
previously built biological model. After spreading these, let's say 10
000, animals across the landscape, I'll simulate counts using fixed
transects.

My response variable is number of animals per cell. I am assuming a
zero-inflated negative binomial distribution and, to simulate spatial
autocorrelation, I'm planning to use spatial lag models (number of
animals in each cell should be affected by number of animals in
neighbour cells). Because my landscape matrix has 250 000 cells, I'm
using the function powerWeights and not invIrW.

My questions are:
- approximately 70% of cells should have no animals (hence the
zero-inflated distribution) but after applying the spatial weights,
these cells are populated. How could I control this (i.e., "forbid"
70% of cells to have animals allocated)?

- the total population is known so, after incorporating spatial
autocorrelation, I need to have exactly 10 000 animals across the
landscape. Any advice on how to do this? Also, is there a way to have
sum(uncorrelated variable)=sum(correlated variable)?

Finally, I'd also appreciate any comments on my approach to this
simulation. Please, do let me know about alternative approaches!

Thanks in advance!


-- 
Ana Nuno


From Jan.Quets at ua.ac.be  Mon Jun 20 18:52:12 2011
From: Jan.Quets at ua.ac.be (Quets Jan)
Date: Mon, 20 Jun 2011 16:52:12 +0000
Subject: [R-sig-Geo] determining used default bandwidth in pcf function
	(spatstat)
Message-ID: <F7452FEC9FABCF4493C2DBB2E9DC31CE0377A5@xmail32.ad.ua.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110620/a40a18b1/attachment.pl>

From zev at zevross.com  Mon Jun 20 21:05:10 2011
From: zev at zevross.com (Zev Ross)
Date: Mon, 20 Jun 2011 15:05:10 -0400
Subject: [R-sig-Geo] Kernels in spatstat for lines
Message-ID: <4DFF99E6.1010705@zevross.com>

Hi All,

Sorry, I thought I'd try my question one more time, hoping that someone 
could give me some guidance. I'm wondering if anyone has used alternate 
kernel functions in  density.psp from spatstat. The generic density 
function from stats allows for the use of several different kernel 
functions  (triangular, biweight etc). I'm interested in applying kernel 
density  estimation to lines (a road network) which density.psp is 
well-suited  for, but that function is limited to the Gaussian kernel.

Has anyone developed code to do this or can anyone provide guidance?

Thank you in advance, Zev

-- 
Zev Ross
ZevRoss Spatial Analysis
120 N Aurora, Suite 3A
Ithaca, NY 14850
607-277-0004 (phone)
866-877-3690 (fax, toll-free)
zev at zevross.com


From afischbach at usgs.gov  Mon Jun 20 22:31:35 2011
From: afischbach at usgs.gov (afischbach)
Date: Mon, 20 Jun 2011 13:31:35 -0700 (PDT)
Subject: [R-sig-Geo] Walruses and adehabitatHR: class estUDm exclusion of
 non-habitat pixels and summary over all animals
Message-ID: <1308601895714-6497315.post@n2.nabble.com>

I am tracking a variable number of walruses throughout their summering range
in the Chukchi Sea.
We wish to summarize monthly summer foraging home ranges based on daily
locations and a daily summary of foraging behavior measured by instruments
on-board the satellite-linked tag, which is a metric similar in nature to
the 'activity' index utilized by Benhamou and Cornelis (2010).

For each walrus with a threshold amount of tracking in each month I
construct a utilization distribution.  Then I must exclude land as
non-habitat from each walruses monthly utilization distribution.  
Because their summering range abuts a coastline that is too complex (sharp
peninsulas and sounds that violate the angle rules and relatively short
shore line segments that violate the 3*h rule of Benhamou and Cornelis
(2010)) the BRB(boundary=simpleCoastLine) option fails.  As such, I am
inclined to resort to the raster exclusion approach, whereby a
pre-constructed raster with cell values assigned to 1 (habitat) or 0
(non-habitat) is multiplied against each utilization distribution, all built
on the same raster grid.

Under the predecessor package, adehabitat, I would multiply each estimated
utilization distribution (class asc) by a raster (also of class asc, read in
using the rgdal readGDAL() function).

Please advise on  how to multiply out the non-habitat from the estUDm class
object and how to normalize total volume back to 1.

Also, please advise on how to summarize utilization distributions across
walruses (in each estUDm object) to derive a single generalized utilization
distribution for each month.


-----
Tony Fischbach, Wildlife Biologist
Walrus Research Program
Alaska Science Center
U.S. Geological Survey
4210 University Drive
Anchorage, AK 99508-4650

AFischbach at usgs.gov
http://alaska.usgs.gov/science/biology/walrus
--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Walruses-and-adehabitatHR-class-estUDm-exclusion-of-non-habitat-pixels-and-summary-over-all-animals-tp6497315p6497315.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From alexander.arpaci at boku.ac.at  Mon Jun 20 22:51:21 2011
From: alexander.arpaci at boku.ac.at (Alexander Arpaci)
Date: Mon, 20 Jun 2011 22:51:21 +0200
Subject: [R-sig-Geo] insert NODATA_value  -999.0 into asc file
Message-ID: <4DFFCEE90200000300020A63@gwia1.boku.ac.at>

Dear List,

I have a large number (several thousand) of asci files which were
delivered to me without a NODATA_value  -999.0 line in the header
I can?t use them with the raster package like that so far.  I got an
error message about the missing NODATAVAL when I try to read it into a
raster object.
Does somebody have a suggestion how to insert that line into my existing
asci files?
I can?t really figure out how do insert that row in line number 5
without replacing the old line 5...especially with a format like that
ncols         601
nrows         351
xllcorner     100000.0
yllcorner     250000.0
cellsize      1000.0
NODATA_value  -999.0

while the other rows have 601 entries
every help apreciated
alexander






MSc. Alexander Arpaci
Assistant researcher

Department of Forest - and Soil Sciences
Institute of Silviculture
Tel. +43-1-47654-4081
e-mail: alexander.arpaci at boku.ac.at
www.wabo.boku.ac.at


From r.turner at auckland.ac.nz  Mon Jun 20 23:07:46 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 21 Jun 2011 09:07:46 +1200
Subject: [R-sig-Geo] determining used default bandwidth in pcf function
 (spatstat)
In-Reply-To: <F7452FEC9FABCF4493C2DBB2E9DC31CE0377A5@xmail32.ad.ua.ac.be>
References: <F7452FEC9FABCF4493C2DBB2E9DC31CE0377A5@xmail32.ad.ua.ac.be>
Message-ID: <4DFFB6A2.9000305@auckland.ac.nz>

On 21/06/11 04:52, Quets Jan wrote:
> Dear readers,
>
> I would like to know the default value of the bandwidth of the Epanechnikov kernel which is used in calculating a pcf.
>
> For example
>
> pp = rSSI(0.1,50)     #a point pattern
> plot(pcf(pp))              #the pcf of this point pattern
>
> There is a kernel bandwidth calculated here according to Stoyan's rule of thumb. But what is its value, is it possible to retrieve this in a simple way?
>
> Stoyan's rule of thumb = bw = c/sqrt(lambda).
>
> lambda is the point density and is known,
> c is a value between 0.1 and 0.2 according to the documentation, but I don't know how c is exactly calculated.
>
> I could search for the book of Stoyan but perhaps there is a simpler way?

The documentation for pcf.ppp() states clearly that the default value of "c"
(given as argument "stoyan") is 0.15.

Does this tell you what you want to know?

     cheers,

         Rolf Turner


From j.m.signer at gmail.com  Mon Jun 20 23:11:51 2011
From: j.m.signer at gmail.com (Johannes Signer)
Date: Mon, 20 Jun 2011 17:11:51 -0400
Subject: [R-sig-Geo] insert NODATA_value -999.0 into asc file
In-Reply-To: <4DFFCEE90200000300020A63@gwia1.boku.ac.at>
References: <4DFFCEE90200000300020A63@gwia1.boku.ac.at>
Message-ID: <BANLkTin5Bz85n_LXYrq7=+bqYtbt0Ou_vw@mail.gmail.com>

Hello,

I would do that on a command line not R:

echo "ncols         601
nrows         351
xllcorner     100000.0
yllcorner     250000.0
cellsize      1000.0
0 0 0 0 0 0
0 0 0 0 0 0" > test.asc

head -n 5 test.asc > tmp_header
awk 'NR>5{print $0}' test.asc > tmp_body
echo NODATA -999.0 >> tmp_header
cat tmp_header rest.asc > new.asc
mv new.asc test.asc
rm tmp_header tmp body

You can easily wrap a loop arround it to apply it to a  few thousand rasters.

Of course you could do it also in R with readLines().

Hope this helps
Johannes

On Mon, Jun 20, 2011 at 4:51 PM, Alexander Arpaci
<alexander.arpaci at boku.ac.at> wrote:
> Dear List,
>
> I have a large number (several thousand) of asci files which were
> delivered to me without a NODATA_value ?-999.0 line in the header
> I can?t use them with the raster package like that so far. ?I got an
> error message about the missing NODATAVAL when I try to read it into a
> raster object.
> Does somebody have a suggestion how to insert that line into my existing
> asci files?
> I can?t really figure out how do insert that row in line number 5
> without replacing the old line 5...especially with a format like that
> ncols ? ? ? ? 601
> nrows ? ? ? ? 351
> xllcorner ? ? 100000.0
> yllcorner ? ? 250000.0
> cellsize ? ? ?1000.0
> NODATA_value ?-999.0
>
> while the other rows have 601 entries
> every help apreciated
> alexander
>
>
>
>
>
>
> MSc. Alexander Arpaci
> Assistant researcher
>
> Department of Forest - and Soil Sciences
> Institute of Silviculture
> Tel. +43-1-47654-4081
> e-mail: alexander.arpaci at boku.ac.at
> www.wabo.boku.ac.at
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From rhurlin at gwdg.de  Tue Jun 21 08:54:57 2011
From: rhurlin at gwdg.de (Rainer Hurling)
Date: Tue, 21 Jun 2011 08:54:57 +0200
Subject: [R-sig-Geo] insert NODATA_value -999.0 into asc file
In-Reply-To: <BANLkTin5Bz85n_LXYrq7=+bqYtbt0Ou_vw@mail.gmail.com>
References: <4DFFCEE90200000300020A63@gwia1.boku.ac.at>
	<BANLkTin5Bz85n_LXYrq7=+bqYtbt0Ou_vw@mail.gmail.com>
Message-ID: <4E004041.7020307@gwdg.de>

Am 20.06.2011 23:11 (UTC+1) schrieb Johannes Signer:
> Hello,
>
> I would do that on a command line not R:
>
> echo "ncols         601
> nrows         351
> xllcorner     100000.0
> yllcorner     250000.0
> cellsize      1000.0
> 0 0 0 0 0 0
> 0 0 0 0 0 0">  test.asc
>
> head -n 5 test.asc>  tmp_header
> awk 'NR>5{print $0}' test.asc>  tmp_body
> echo NODATA -999.0>>  tmp_header
> cat tmp_header rest.asc>  new.asc
> mv new.asc test.asc
> rm tmp_header tmp body

When using the stream editor 'sed' you would only need a one liner for that:

All you have to do before you can start converting, is creating a text 
file, say 'asc.sed' with only two lines:

--------------------
5a\
nodata_value  -999.0
--------------------

This is your script file for 'sed'. It appends the text (second script 
line) after the fifth line of the original data.

A conversion of a single .asc-file should then work like this:

sed -f asc.sed file0001_old.asc > file0001_new.asc

Please be aware that you have to choose a new file name, because sed 
reads in the old file and writes to the new file at the same time 
(potential data loss!).

> You can easily wrap a loop arround it to apply it to a  few thousand rasters.

Yes, and in this loop you could handle your file naming scheme. Both awk 
and sed are little tools on Unix alike systems and they are very fast.

Just as a second way to solve this issue,
Rainer Hurling


> Of course you could do it also in R with readLines().
>
> Hope this helps
> Johannes
>
> On Mon, Jun 20, 2011 at 4:51 PM, Alexander Arpaci
> <alexander.arpaci at boku.ac.at>  wrote:
>> Dear List,
>>
>> I have a large number (several thousand) of asci files which were
>> delivered to me without a NODATA_value  -999.0 line in the header
>> I can?t use them with the raster package like that so far.  I got an
>> error message about the missing NODATAVAL when I try to read it into a
>> raster object.
>> Does somebody have a suggestion how to insert that line into my existing
>> asci files?
>> I can?t really figure out how do insert that row in line number 5
>> without replacing the old line 5...especially with a format like that
>> ncols         601
>> nrows         351
>> xllcorner     100000.0
>> yllcorner     250000.0
>> cellsize      1000.0
>> NODATA_value  -999.0
>>
>> while the other rows have 601 entries
>> every help apreciated
>> alexander
>>
>> MSc. Alexander Arpaci
>> Assistant researcher
>>
>> Department of Forest - and Soil Sciences
>> Institute of Silviculture
>> Tel. +43-1-47654-4081
>> e-mail: alexander.arpaci at boku.ac.at
>> www.wabo.boku.ac.at


From martin_brandt at gmx.net  Tue Jun 21 10:43:43 2011
From: martin_brandt at gmx.net (Martin)
Date: Tue, 21 Jun 2011 01:43:43 -0700 (PDT)
Subject: [R-sig-Geo] Supervised landscape classification according to
 NDVI time series
In-Reply-To: <1308162928514-6480065.post@n2.nabble.com>
References: <4DF32AD3.8000704@gmail.com>
	<1308162928514-6480065.post@n2.nabble.com>
Message-ID: <1308645823239-6499112.post@n2.nabble.com>

This is indeed an interesting topic. Robert's method may work if you average
the months over serveral years, e.g. an average january over 5-10 years may
not be influenced too much by seasonality...
But if you find a method which works better i think some would be interested
if you post your results here... 

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Supervised-landscape-classification-according-to-NDVI-time-series-tp6464837p6499112.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From carsten.dormann at ufz.de  Tue Jun 21 10:47:41 2011
From: carsten.dormann at ufz.de (Carsten Dormann)
Date: Tue, 21 Jun 2011 10:47:41 +0200
Subject: [R-sig-Geo] change projection of large raster file
Message-ID: <4E005AAD.4080905@ufz.de>

Dear all,

I want to compute equal-area grid values for global land cover (GLC2000 
data). The equal-area grid is in Mollweide projection.

I use raster to read the GLC-data. Now I want to project these 
WGS84-projected GLC-data into Mollweide.

Even after 24 hours of computing, R was still milling away. I regard 
this as a problem, rather than a consequence of the large data set (54 
MB). Correctly so?

Any hints on how to do this correctly appreciated!

[Only in case you were wondering WHY I do this: The next steps will be 
to simplify down to only one category (using data == "1") and then use 
"aggregate" to actually sum the number of positive pixels in each cell. 
I did the whole thing with a 1-degree grid without any problems (taking 
roughly 30min for each class).]


Cheers,

Carsten


R-code:

r <- raster(grid100) # to convert the SpatialGrid into a raster
test <- raster("glc2000_v1_1") #reads the GLC data
ex <- projectExtent(test, CRS(proj4string(grid100))) # reprojects the extent
setOptions(chunksize = 1e+04, maxmemory = 1e+06)
# based on comment in: 
https://r-forge.r-project.org/forum/message.php?msg_id=4025&group_id=294
test2 <- projectRaster(test, ex) # to project the actual GLC-data


sessionInfo()

R version 2.13.0 RC (2011-04-05 r55311)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] de_DE.UTF-8/de_DE.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] maptools_0.8-6  lattice_0.19-26 foreign_0.8-44  rgdal_0.6-33 
raster_1.8-12   sp_0.9-80

loaded via a namespace (and not attached):
[1] grid_2.13.0  tools_2.13.0





-- 
Dr. Carsten F. Dormann
Department of Computational Landscape Ecology
Helmholtz Centre for Environmental Research-UFZ	
(Department Landschafts?kologie)
(Helmholtz Zentrum f?r Umweltforschung - UFZ)
Permoserstr. 15	
04318 Leipzig				
Germany

Tel: ++49(0)341 2351946
Fax: ++49(0)341 2351939
Email: carsten.dormann at ufz.de
internet: http://www.ufz.de/index.php?de=4205

Registered Office/Sitz der Gesellschaft: Leipzig
Commercial Register Number/Registergericht: Amtsgericht Leipzig, 
Handelsregister Nr. B 4703
Chairman of the Supervisory Board/Vorsitzender des Aufsichtsrats: MinR 
Wilfried Kraus
Scientific Managing Director/Wissenschaftlicher Gesch?ftsf?hrer: Prof. 
Dr. Georg Teutsch
Administrative Managing Director/Administrativer Gesch?ftsf?hrer: Dr. 
Andreas Schmidt


From breitbach at uni-mainz.de  Tue Jun 21 11:03:04 2011
From: breitbach at uni-mainz.de (Breitbach, Nils)
Date: Tue, 21 Jun 2011 09:03:04 +0000
Subject: [R-sig-Geo] change projection of large raster file
In-Reply-To: <4E005AAD.4080905@ufz.de>
References: <4E005AAD.4080905@ufz.de>
Message-ID: <E7F1EF063B11DA4DAD16374549B879E84F86756A@e14mdb-03.zdv.Uni-Mainz.DE>

Dear Carsten,

I rarely work with rasta data sets but I would suggest that this is a memory problem. In R (and in ArcGIS as well) unfortunately all the data of an operation are held in the working memory which sometimes made it necessary for me to split bigger data sets into many small ones. This seems to be not only true for GIS data but also for other operations with huge data sets; it is getting even worse in loops. Have you tried to test your script with a smaller data set (i.e. a small fraction of the total area to be projected) on another computer, while the big operation is still running?

Regards,

Nils

________________________________________
Von: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org]&quot; im Auftrag von &quot;Carsten Dormann [carsten.dormann at ufz.de]
Gesendet: Dienstag, 21. Juni 2011 10:47
Bis: r-sig-geo at stat.math.ethz.ch
Betreff: [R-sig-Geo] change projection of large raster file

Dear all,

I want to compute equal-area grid values for global land cover (GLC2000
data). The equal-area grid is in Mollweide projection.

I use raster to read the GLC-data. Now I want to project these
WGS84-projected GLC-data into Mollweide.

Even after 24 hours of computing, R was still milling away. I regard
this as a problem, rather than a consequence of the large data set (54
MB). Correctly so?

Any hints on how to do this correctly appreciated!

[Only in case you were wondering WHY I do this: The next steps will be
to simplify down to only one category (using data == "1") and then use
"aggregate" to actually sum the number of positive pixels in each cell.
I did the whole thing with a 1-degree grid without any problems (taking
roughly 30min for each class).]


Cheers,

Carsten


R-code:

r <- raster(grid100) # to convert the SpatialGrid into a raster
test <- raster("glc2000_v1_1") #reads the GLC data
ex <- projectExtent(test, CRS(proj4string(grid100))) # reprojects the extent
setOptions(chunksize = 1e+04, maxmemory = 1e+06)
# based on comment in:
https://r-forge.r-project.org/forum/message.php?msg_id=4025&group_id=294
test2 <- projectRaster(test, ex) # to project the actual GLC-data


sessionInfo()

R version 2.13.0 RC (2011-04-05 r55311)
Platform: i386-apple-darwin9.8.0/i386 (32-bit)

locale:
[1] de_DE.UTF-8/de_DE.UTF-8/C/C/de_DE.UTF-8/de_DE.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] maptools_0.8-6  lattice_0.19-26 foreign_0.8-44  rgdal_0.6-33
raster_1.8-12   sp_0.9-80

loaded via a namespace (and not attached):
[1] grid_2.13.0  tools_2.13.0





--
Dr. Carsten F. Dormann
Department of Computational Landscape Ecology
Helmholtz Centre for Environmental Research-UFZ
(Department Landschafts?kologie)
(Helmholtz Zentrum f?r Umweltforschung - UFZ)
Permoserstr. 15
04318 Leipzig
Germany

Tel: ++49(0)341 2351946
Fax: ++49(0)341 2351939
Email: carsten.dormann at ufz.de
internet: http://www.ufz.de/index.php?de=4205

Registered Office/Sitz der Gesellschaft: Leipzig
Commercial Register Number/Registergericht: Amtsgericht Leipzig,
Handelsregister Nr. B 4703
Chairman of the Supervisory Board/Vorsitzender des Aufsichtsrats: MinR
Wilfried Kraus
Scientific Managing Director/Wissenschaftlicher Gesch?ftsf?hrer: Prof.
Dr. Georg Teutsch
Administrative Managing Director/Administrativer Gesch?ftsf?hrer: Dr.
Andreas Schmidt

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From matteo.mattiuzzi at boku.ac.at  Tue Jun 21 11:07:57 2011
From: matteo.mattiuzzi at boku.ac.at (Matteo Mattiuzzi)
Date: Tue, 21 Jun 2011 11:07:57 +0200
Subject: [R-sig-Geo] Antw:  change projection of large raster file
In-Reply-To: <4E005AAD.4080905@ufz.de>
References: <4E005AAD.4080905@ufz.de>
Message-ID: <4E007B8D020000270000F1DA@gwia2.boku.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110621/10c8f30a/attachment.pl>

From thi_veloso at yahoo.com.br  Tue Jun 21 13:17:37 2011
From: thi_veloso at yahoo.com.br (Thiago Veloso)
Date: Tue, 21 Jun 2011 04:17:37 -0700 (PDT)
Subject: [R-sig-Geo] Methodology to compare crop maps
In-Reply-To: <BANLkTim_fggStrA+CwExkWeqTOujRdps6Q@mail.gmail.com>
Message-ID: <812122.89677.qm@web161424.mail.bf1.yahoo.com>

  Robert,

  Thank you very much. Your tips helped me to achieve my goals! Thanks for your patience!

  Best wishes,

  Thiago.

--- On Thu, 16/6/11, Robert J. Hijmans <r.hijmans at gmail.com> wrote:

> From: Robert J. Hijmans <r.hijmans at gmail.com>
> Subject: Re: [R-sig-Geo] Methodology to compare crop maps
> To: "Thiago Veloso" <thi_veloso at yahoo.com.br>
> Cc: r-sig-geo at r-project.org
> Date: Thursday, 16 June, 2011, 8:53
> Dear Thiago,
> 
> That's why I suggested:
> 
> > cane_sa[cane_sa < 16] <- NA
> > veg_sa <- crop(vegmap,south_america)
> > newveg_sa <- cover(cane_sa, veg_sa)
> > new_vegmap <- merge(newveg_sa, vegmap)
> 
> i.e. set all values you do not want to NA, and then use
> 'cover' to
> replace NA values in the new raster with the values of the
> old raster,
> and then use merge.
> 
> Best, Robert
> 
> 
> On Thu, Jun 16, 2011 at 4:11 AM, Thiago Veloso <thi_veloso at yahoo.com.br>
> wrote:
> > ?Dear Robert,
> >
> > ?Sorry for not stating my question concisely. Still,
> you captured what was wrong in my code: that was exactly the
> threshold of the existence of the crop. Raising the limit
> helped to alleviate the crop existence map at a coarser
> resolution.
> >
> > ?Following the code, I experienced another
> difficulty. The merge function replaces the whole contents
> from one map to the other. Is there any way to impose
> conditions? Something like "merge if pixel value is greater
> than..."?
> >
> > ?Best wishes,
> >
> > ?Thiago Veloso.
> >
> > --- On Sat, 11/6/11, Robert J. Hijmans <r.hijmans at gmail.com>
> wrote:
> >
> >> From: Robert J. Hijmans <r.hijmans at gmail.com>
> >> Subject: Re: [R-sig-Geo] Methodology to compare
> crop maps
> >> To: "Thiago Veloso" <thi_veloso at yahoo.com.br>
> >> Cc: r-sig-geo at r-project.org
> >> Date: Saturday, 11 June, 2011, 1:27
> >> Hi Thiago,
> >>
> >> You are not saying _what_ goes wrong. That makes
> it
> >> difficult to help.
> >> I am guessing that you are missing some of the
> steps below.
> >> You do:
> >>
> >> cane_sa[cane_sa>0]<-16
> >>
> >> # I do not know your exact objectives but it seems
> strange
> >> to use 0 here,
> >> # as even a cell that is covered for 1/600 of its
> area with
> >> cane would
> >> be classified as cane.
> >> # but irrespective of the threshold you choose, I
> think you
> >> need:
> >>
> >> cane_sa[cane_sa < 16] <- NA
> >> veg_sa <- crop(vegmap,south_america)
> >> newveg_sa <- cover(cane_sa, veg_sa)
> >>
> >> # and then continue with your code again:
> >>
> >> new_vegmap <- merge(newveg_sa, vegmap)
> >>
> >> Robert
> >>
> >> On Thu, Jun 9, 2011 at 3:51 PM, Thiago Veloso
> <thi_veloso at yahoo.com.br>
> >> wrote:
> >> > ?Robert, Rich and Luca,
> >> >
> >> > ?Thank you very much for the suggestions.
> >> >
> >> > ?Robert, I still haven't managed to
> implement all of
> >> your directions due to the burocracy to obtain the
> sugarcane
> >> raster (or shape) files from INPE.
> >> >
> >> > ?In the meanwhile, I am trying to convert
> mcgill data
> >> (you're right about the units) from fraction of
> land covered
> >> by a crop to presence/absence. This is because my
> ultimate
> >> goal is to add a new plant functional type (PFT)
> to a map
> >> where 15 PFTs already exist (http://www.sage.wisc.edu/download/potveg/global_potveg.html).
> >> This way, cells where cane is present should
> contain the
> >> value "16".
> >> >
> >> > ?It seemed to be a simple task, but what I
> am doing
> >> is changing the map substantially. Please take a
> peek at the
> >> code:
> >> >
> >> > #Loading required packages
> >> > library(raster)
> >> > library(maptools)
> >> >
> >> > #Loading SAGE vegetation map and McGill
> sugarcane map
> >> > vegmap<-raster("data/vegtype.nc")
> >> > cane<-raster("data/sugarcane_5min.nc")
> >> >
> >> >> vegmap
> >> > class ? ? ? : RasterLayer
> >> > dimensions ?: 360, 720, 259200 ?(nrow,
> ncol, ncell)
> >> > resolution ?: 0.5, 0.5 ?(x, y)
> >> > extent ? ? ?: -180, 180, -90, 90 ?(xmin,
> xmax,
> >> ymin, ymax)
> >> > coord. ref. : +proj=longlat +datum=WGS84
> >> > values ? ? ?: data/vegtype.nc
> >> > min ? ? ? ? : ?
> >> > max ? ? ? ? : ?
> >> >
> >> >> cane
> >> > class ? ? ? : RasterLayer
> >> > dimensions ?: 2160, 4320, 9331200 ?(nrow,
> ncol,
> >> ncell)
> >> > resolution ?: 0.08333333, 0.08333334 ?(x,
> y)
> >> > extent ? ? ?: -180, 180, -90, 90 ?(xmin,
> xmax,
> >> ymin, ymax)
> >> > coord. ref. : +proj=longlat +datum=WGS84
> >> > values ? ? ?: data/sugarcane_5min.nc
> >> > min ? ? ? ? : ?
> >> > max ? ? ? ? : ?
> >> >
> >> > #Resampling McGill map to match SAGE's
> resolution
> >> >
> >>
> cane_coarser<-aggregate(cane,fact=6.00000024,fun=mean)
> >> >
> >> >> cane_coarser
> >> > class ? ? ? : RasterLayer
> >> > dimensions ?: 360, 720, 259200 ?(nrow,
> ncol, ncell)
> >> > resolution ?: 0.5, 0.5 ?(x, y)
> >> > extent ? ? ?: -180, 180, -90, 90 ?(xmin,
> xmax,
> >> ymin, ymax)
> >> > coord. ref. : +proj=longlat +datum=WGS84
> >> > values ? ? ?:
> >> /tmp/R_raster_tmp/raster_tmp_39924224710.grd
> >> > min value ? : 0
> >> > max value ? : 0.5680773
> >> >
> >> > #Loading SA shapefile
> >> >
> >>
> south_america<-readShapePoly("shapes/southamerica.shp")
> >> >
> >> > #Cropping sugar cane map
> >> > cane_sa<-crop(cane_coarser,south_america)
> >> >
> >> >> cane_sa
> >> > class ? ? ? : RasterLayer
> >> > dimensions ?: 137, 93, 12741 ?(nrow, ncol,
> ncell)
> >> > resolution ?: 0.5, 0.5 ?(x, y)
> >> > extent ? ? ?: -81.49999, -34.99999, -56,
> 12.5
> >> ?(xmin, xmax, ymin, ymax)
> >> > coord. ref. : +proj=longlat +datum=WGS84
> >> > values ? ? ?: in memory
> >> > min value ? : 0
> >> > max value ? : 0.5237272
> >> >
> >> > #Below is an attempt to replace fraction
> with
> >> presence
> >> > cane_sa[cane_sa>0]<-16
> >> >
> >> > #Check result
> >> > plot(cane_coarser)
> >> >
> >> > #Adding cane map to SAGE vegetation map
> >> > new_vegmap<merge(vegmap,cane_sa)
> >> >
> >> > #Writing out updated map to a netcdf file
> >> > if(require(ncdf)){
> >> >
> >>
> writeRaster(new_vegmap,filename="/home/thiago/IBIS/data/inpue/new_vegmap.nc",format="CDF",overwrite=TRUE)
> >> > }
> >> >
> >> > ?Everything goes fine until cropping the
> resampled
> >> map. However, replacing grater than zero values
> results in a
> >> totally different map.
> >> >
> >> > ?What am I doing wrong? Maybe spatial data
> frames are
> >> harder to deal with (for newbies like me), or
> maybe the
> >> massive amount of NA's and?tiny numbers
> (0.000000e+00,
> >> 2.433714e-03 and etc) produced after agregation is
> the
> >> problem...
> >> >
> >> > ?Thanks in advance and best wishes,
> >> >
> >> > ?Thiago.
> >> >
> >> > --- On Fri, 3/6/11, Robert Hijmans <r.hijmans at gmail.com>
> >> wrote:
> >> >
> >> >> From: Robert Hijmans <r.hijmans at gmail.com>
> >> >> Subject: Re: [R-sig-Geo] Methodology to
> compare
> >> crop maps
> >> >> To: r-sig-geo at r-project.org
> >> >> Date: Friday, 3 June, 2011, 13:17
> >> >> > ?I am working with crops
> >> >> planted area maps from two distinct
> sources.
> >> >> > One of the maps is based on a
> maximum NDVI
> >> >> composition, and the other
> >> >> > map uses joint information from
> satellite and
> >> census
> >> >> to estimate the
> >> >> > planted area.
> >> >> >
> >> >> > ?Although the sources employ
> different
> >> methodologies
> >> >> to map the area
> >> >> > where the crop exists, the results
> should be
> >> >> comparable.
> >> >> >
> >> >> > ?After downloading the datasets, I
> have
> >> performed a
> >> >> visual inpection,
> >> >> > and they show reasonable agreement.
> However,
> >> I need a
> >> >> more robust
> >> >> > comparison method. Could anybody
> point out a
> >> >> methodology which allows
> >> >> > me to show the difference between
> both maps?
> >> >> >
> >> >> > ?Here is an example of each one of
> the
> >> maps:
> >> >> > http://www.geog.mcgill.ca/landuse/pub/Data/175crops2000/NetCDF/sugarcane_5min.nc.gz
> >> >> > (in netcdf) and http://www.dsr.inpe.br/laf/canasat/en/map.html (not
> >> >> > available to download directly, but
> I can get
> >> it in
> >> >> shapefile)
> >> >> >
> >> >>
> >> >>
> >> >> Thiago,
> >> >>
> >> >> I assume that the Brazilian data has a
> much higher
> >> spatial
> >> >> resolution than
> >> >> the mcgill data (that I think I am
> familiar with),
> >> and it
> >> >> probably has a
> >> >> different CRS. And I assume that you can
> get it as
> >> a the
> >> >> original raster
> >> >> file (and not as shapefile) for the
> Brazilian
> >> data. If I am
> >> >> not mistaken,
> >> >> the mcgill data has the fraction of land
> area
> >> covered by a
> >> >> crop. I assume
> >> >> that the Brazilan data is
> presence/absence. If so
> >> I would
> >> >> use the raster
> >> >> package and aggregate the Brazilian data
> to a cell
> >> size
> >> >> that is similar to
> >> >> the mcgill data (~9 km), computing the
> fraction of
> >> cells
> >> >> that have sugarcane
> >> >> (sum divided by the number of cells, make
> sure to
> >> handle NA
> >> >> values). Then
> >> >> use function projectRaster to transform
> the mcgill
> >> data to
> >> >> the same
> >> >> extent/resolution as the aggregated
> Brazilian
> >> data. Now you
> >> >> have two layers
> >> >> that you can compare in different ways.
> >> >>
> >> >> You can make plots, compute correlation,
> etc. Of
> >> course the
> >> >> p-values are no
> >> >> good because of spatial autocorrelation.
> >> >>
> >> >> library(raster)
> >> >> x <- y <- raster(nc=100, nr=100)
> >> >> x[] <- runif(ncell(r))
> >> >> y[] <- runif(ncell(r))
> >> >> plot(x, y)
> >> >> m <- lm(values(x), values(y))
> >> >> summary(m)
> >> >> abline(m)
> >> >>
> >> >> hist(x-y)
> >> >> plot(x-y)
> >> >> cor(values(x), values(y))
> >> >>
> >> >>
> >> >> Perhaps you want to treat your data as
> >> presence/absence
> >> >> (with presence being
> >> >> > 0 or some another threshold). These
> can then
> >> be easily
> >> >> compared with the
> >> >> crosstab function which returns, in this
> case, a
> >> confusion
> >> >> matrix which can
> >> >> be directly interpreted or used to
> compute some
> >> statistics
> >> >> from.
> >> >> crosstab(x>0, y>0)
> >> >>
> >> >> crosstab(x>0.5, y>0.5)
> >> >>
> >> >> And there surely are many other
> approaches
> >> possible, which
> >> >> is why I think
> >> >> that R is the way to go in this case: it
> is easy,
> >> flexible
> >> >> and fast.
> >> >>
> >> >> Robert
> >> >>
> >> >>
> >> >> --
> >> >> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Methodology-to-compare-crop-maps-tp6431598p6435902.html
> >> >> Sent from the R-sig-geo mailing list
> archive at
> >> >> Nabble.com.
> >> >>
> >> >>
> _______________________________________________
> >> >> R-sig-Geo mailing list
> >> >> R-sig-Geo at r-project.org
> >> >> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> >> >>
> >> >
> >> >
> >>
> >
> >
> >
>


From ana.nuno08 at imperial.ac.uk  Tue Jun 21 14:37:22 2011
From: ana.nuno08 at imperial.ac.uk (Ana Nuno)
Date: Tue, 21 Jun 2011 13:37:22 +0100
Subject: [R-sig-Geo] spatially autocorrelated wildlife counts
In-Reply-To: <BANLkTimkPpZ4POiZOA3AOeZZ32z9nd+qSg@mail.gmail.com>
References: <BANLkTimkPpZ4POiZOA3AOeZZ32z9nd+qSg@mail.gmail.com>
Message-ID: <BANLkTi=hAzGHVtUrDLt-1hp4g+e3UZT8gg@mail.gmail.com>

Dear all,

Sorry for posting the question again but I'd been advised to do so
including more information. Hopefully, this will make my simulation
approach and questions clearer.

As I said before:

> I am trying to simulate the distribution of a ungulate species across
> a landscape, where animals of this species are spatially aggregated
> (exact aggregation level is unknown so I'll have a range of values). I
> know the "true" size of this population because it results from my
> previously built biological model. After spreading these animals across the landscape, I'll simulate counts using fixed
> transects.
>
> My response variable is number of animals per cell. I am assuming a
> zero-inflated negative binomial distribution and, to simulate spatial
> autocorrelation, I'm planning to use spatial lag models (number of
> animals in each cell should be affected by number of animals in
> neighbour cells). Because my landscape matrix has 250 000 cells, I'm
> using the function powerWeights and not invIrW.


Thus, I am using:

library(spdep)

neighbours <- cell2nb(500, 500, torus=TRUE)
x <- matrix(rzinbinom(length(neighbours),52,0.1,0.7), nrow=length(neighbours))
W <- as(as_dgRMatrix_listw(nb2listw(neighbours,style="W")), "CsparseMatrix")
ee <- powerWeights(W, rho=0.9, X=x)

# and zero-inflated negative binomial distribution is defined by:

rzinbinom <- function(n, mu, size, zprob) {
  ifelse(runif(n) < zprob, 0, rnbinom(n, mu=mu, size=size))
}

My questions are:

- approximately 70% of cells should have no animals (hence the
zero-inflated distribution) but after applying the spatial weights,
these cells are populated. How to maintain some cells empty?

 - the total population is known so, after incorporating spatial
autocorrelation, I should have exactly 1 000 000 animals across the
landscape. Any advice on how to do this? I am currently using an
extremely simplistic, and potentially wrong, approach, where:

ratio<-sum(ee)/1000000 #1000000 is total pop size; ratio calculates
discrepancy between simulated and real population
final<-round(ee at x/ratio) # this gives the real number of animals per
cell (total across 250 000 cells should be 1 000 000)


Finally, I'd also appreciate any comments on my approach to this simulation.

Thanks in advance!


-- 
Ana Nuno

http://iccs.org.uk/ananuno.htm
http://fp7hunt.net/


From simon.ohanlon at imperial.ac.uk  Tue Jun 21 18:21:02 2011
From: simon.ohanlon at imperial.ac.uk (O'Hanlon, Simon J)
Date: Tue, 21 Jun 2011 17:21:02 +0100
Subject: [R-sig-Geo] Resampling rasters with count data
Message-ID: <BC1C610780300542BA4CBE44AEDE3704278CBFB7@icexm6.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110621/8919ad93/attachment.pl>

From landis at isciences.com  Tue Jun 21 18:32:10 2011
From: landis at isciences.com (Matthew Landis)
Date: Tue, 21 Jun 2011 12:32:10 -0400
Subject: [R-sig-Geo] Resampling rasters with count data
In-Reply-To: <BC1C610780300542BA4CBE44AEDE3704278CBFB7@icexm6.ic.ac.uk>
References: <BC1C610780300542BA4CBE44AEDE3704278CBFB7@icexm6.ic.ac.uk>
Message-ID: <4E00C78A.6060900@isciences.com>

Simon - will nearest neighbor sampling solve your problem?

resample(x, y, method = 'ngb')

On 6/21/2011 12:21 PM, O'Hanlon, Simon J wrote:
> Dear list,
> does anybody know of a method to resample rasters which contain count data? The 'normal' way of resampling would be to perform some interpolation between cells to smooth between the values, for instance if you have a raster of 1km by 1km cells and you resample to 5by 5km cells you would typically employ bilinear or cubic resampling methods to average out the values at the higher resolution.
>
> However, as I have population count data I want to maintain the integrity of the count. I have a raster of square cells which is 523 by 307 cells, which I need to resample to slightly larger cells which will give me 477 columns by 275 rows, ensuring that the total count across the slightly larger cells adds up to that of the original dataset.
>
> Many thanks for your thoughts.
>
> Simon
>

-- 
~~~~~~~~~~~~~~~~~~~~~~~~~~
Matthew Landis, Ph.D.
Research Scientist
ISciences, LLC
61 Main St. Suite 200
Burlington VT 05401
802.864.2999
~~~~~~~~~~~~~~~~~~~~~~~~~~


From edzer.pebesma at uni-muenster.de  Tue Jun 21 19:32:36 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Tue, 21 Jun 2011 19:32:36 +0200
Subject: [R-sig-Geo] Resampling rasters with count data
In-Reply-To: <BC1C610780300542BA4CBE44AEDE3704278CBFB7@icexm6.ic.ac.uk>
References: <BC1C610780300542BA4CBE44AEDE3704278CBFB7@icexm6.ic.ac.uk>
Message-ID: <4E00D5B4.90604@uni-muenster.de>

Simon, package sp has an aggregate method:

library(sp)
grd1 = SpatialPixels(SpatialPoints(expand.grid(1:100,1:100)))
grd2 = SpatialPixels(SpatialPoints(expand.grid(0:100 * 1.5,0:100 * 1.5)))
grd1df = SpatialPixelsDataFrame(grd1, data.frame(counts=rpois(10000,10)))
spplot(grd1df)
res = aggregate(grd1df, grd2, function(x) ifelse(nrow(x)>0,sum(x),0))
spplot(res)
# check count integrety:
sum(grd1df[[1]])
sum(res[[1]])

read more in the vignette on overlay and aggregation:
http://cran.r-project.org/web/packages/sp/vignettes/over.pdf

Please note the pattern in the output grid: grid cell counts in grd1df
are not redistributed over new grid cells they overlap with, they are
essentially considered as points, and assigned to the new grid cell in
which their center falls.

No doubt package raster can do the same thing.


On 06/21/2011 06:21 PM, O'Hanlon, Simon J wrote:
> Dear list,
> does anybody know of a method to resample rasters which contain count data? The 'normal' way of resampling would be to perform some interpolation between cells to smooth between the values, for instance if you have a raster of 1km by 1km cells and you resample to 5by 5km cells you would typically employ bilinear or cubic resampling methods to average out the values at the higher resolution.
> 
> However, as I have population count data I want to maintain the integrity of the count. I have a raster of square cells which is 523 by 307 cells, which I need to resample to slightly larger cells which will give me 477 columns by 275 rows, ensuring that the total count across the slightly larger cells adds up to that of the original dataset.
> 
> Many thanks for your thoughts.
> 
> Simon
> 
> --------------------------------
> Simon O'Hanlon,
> Department of Infectious Disease Epidemiology
> Imperial College London
> 
> 	[[alternative HTML version deleted]]
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From j.maspons at creaf.uab.cat  Tue Jun 21 19:34:50 2011
From: j.maspons at creaf.uab.cat (Joan Maspons)
Date: Tue, 21 Jun 2011 19:34:50 +0200
Subject: [R-sig-Geo] How to merge SpatialPolygonsDataFrame?
Message-ID: <201106211934.51125.j.maspons@creaf.uab.cat>

Hello,
I'm new in GIS from R and I have some problems. I have some points with many 
variables and I want to interpolate and apply a mask from country borders:

valuesES<- data.frame(LON=runif(n, min=-9, max=3), LAT=runif(n, min=36, 
max=43), val1=runif(n), val2=runif(n), valn=runif(n))

createMap1<- function(valuesES, fileName=NULL, country, ...){
  require(raster)
  r<-raster(nrows=300, ncols=300, xmn=min(values$LON)-1, 
xmx=max(values$LON)+1, ymn=min(values$LAT)-1, ymx=max(values$LAT)+1)
  r<-rasterize(as.matrix(values[,1:2]), r)
  r[cellFromXY(r, values[,1:2])]<- values[[3]]
  tps<- Tps(values[,1:2], values[,3])
  p <- raster(r)
  p <- interpolate(p, tps)
  c<- getData("GADM", country=country, level=0)
  rc<- rasterize(c, r)
  pc<- mask(p, rc)
#   png(fileName)
  plot(pc, ...)
#   dev.off()
}

createMap1(valuesES[,1:3], country="ESP")

This seems to work but I'm not sure about the interpolation method. The 
problem arise when I try to use more than one country as a mask:

createMap<- function(values, fileName, countries, ...){
  require(raster)
  require(fields)
  require(maptools) # unionSpatialPolygons
  gpclibPermit() # polygon geometry computations in maptools

  r<-raster(nrows=300, ncols=300, xmn=min(values$LON)-1, 
xmx=max(values$LON)+1, ymn=min(values$LAT)-1, ymx=max(values$LAT)+1)
  rv<-rasterize(as.matrix(values[,1:2]), r)
  rv[cellFromXY(r, values[,1:2])]<- values[,3]
  tps<- Tps(values[,1:2], values[,3])
  p <- raster(r)
  p <- interpolate(p, tps)

  country<- list()
  pol<- list()
  pols<- list()
  data<- data.frame()
  for (j in 1:length(countries)){
    country[[j]]<- getData("GADM", country=countries[j], level=0)
    data<- rbind(data, country[[j]]@data)
    pol[[j]]<- Polygon(country[[j]]) # not to plotable
    pols[[j]]<- Polygons(list(pol[[j]]), countries[j]) # not to plotable
  }
  sPol<- SpatialPolygons(pols, 1:length(countries)) # not to plotable
  row.names(data)<- data$ISO
  sPolDF<- SpatialPolygonsDataFrame(sPol, data) # not to plotable
  spplot(sPolDF, "ISON") # not to plotable

#   uSPolDF<- unionSpatialPolygons(sPolDF, countries) 
#   spplot(uSPolDF, "ISON")

  reuro<- rasterize(sPolDF, r)

  pam<- mask(p, reuro)
  plot(pam, ...)

}

n<- 100
countries<- c("AUT", "BEL", "BGR", "CZE", "DEU", "DNK", "EST", "ESP", "FIN", 
"FRA", "GRC", "HUN", "IRL", "ITA", "LTU", "LUX", "LVA", "NLD", "POL", "PRT", 
"ROU", "SWE", "SVN", "SVK")

values<- data.frame(LON=runif(n, min=-9, max=31), LAT=runif(n, min=36, 
max=70), val1=runif(n), val2=runif(n), valn=runif(n))
valuesES<- data.frame(LON=runif(n, min=-9, max=3), LAT=runif(n, min=36, 
max=43), val1=runif(n), val2=runif(n), valn=runif(n))

for (i in 3:(ncol(values)-2)){
  createMap(values[, c(1:2, i)], fileName=names(values)[i], 
countries=countries, main=paste(substr(names(values)[i], 1, 
nchar(names(values)[i])-4)))
}

I've tried to create a SpatialPolygonsDataFrame containing all the countries 
but it don't display anything. Where is the mistake? Could you give me a hand?

> sessionInfo()
R version 2.11.1 (2010-05-31) 
i686-pc-linux-gnu 

locale:
 [1] LC_CTYPE=ca_ES.UTF-8          LC_NUMERIC=C                  
LC_TIME=ca_ES.UTF-8          
 [4] LC_COLLATE=ca_ES.UTF-8        LC_MONETARY=ca_ES.UTF-8       
LC_MESSAGES=ca_ES.UTF-8      
 [7] LC_PAPER=ca_ES.UTF-8          LC_NAME=ca_ES.UTF-8           
LC_ADDRESS=ca_ES.UTF-8       
[10] LC_TELEPHONE=ca_ES.UTF-8      LC_MEASUREMENT=ca_ES.UTF-8    
LC_IDENTIFICATION=ca_ES.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] gpclib_1.5-1    maptools_0.7-34 lattice_0.18-8  foreign_0.8-40  fields_6.3      
spam_0.23-0     raster_1.8-22  
[8] sp_0.9-81       rkward_0.5.3   

loaded via a namespace (and not attached):
[1] grid_2.11.1  tools_2.11.1


Yours,

Joan Maspons 
CREAF (Centre de Recerca Ecol?gica i Aplicacions Forestals)
Universitat Aut?noma de Barcelona, 08193 Bellaterra (Barcelona), Catalonia
Tel +34 93 581 2915            j.maspons at creaf.uab.cat
http://www.creaf.uab.cat


From a.mosnier at gmail.com  Wed Jun 22 14:40:10 2011
From: a.mosnier at gmail.com (Arnaud Mosnier)
Date: Wed, 22 Jun 2011 08:40:10 -0400
Subject: [R-sig-Geo] GLS models and variance explained
Message-ID: <BANLkTi=e34GUy4uXNzjfMuX5bGt5yN4V5Q@mail.gmail.com>

Dear list,

Inspecting residuals of my linear models, I detected spatial autocorrelation.
In order to take this into account, I decided to use the GLS method
with the correlation = corGaus ( ~ X + Y).

Then, I can sort my GLS models based on their AIC.
But ... how to know the proportion of the variance explained by the
best one (it can be best of the worst models) ?
R-squared value has not the same meaning for OLS and GLS ...


- Could the R2 value calculated with the OLS model (using lm)
constitute a potential proxy of the variance explained by the GLS
model ? (the answer is probably no)

- Is a R-squared based on sqrt(cor(obs, predicted)) a better approach ?

- What about pseudo R-squared like Nagelkerke's ?

Suggestions for any better approach are welcome !


Thanks in advance,

Arnaud


From matthias.m.hinz at googlemail.com  Wed Jun 22 17:36:57 2011
From: matthias.m.hinz at googlemail.com (Matthias Hinz)
Date: Wed, 22 Jun 2011 17:36:57 +0200
Subject: [R-sig-Geo] How to merge SpatialPolygonsDataFrame?
In-Reply-To: <201106211934.51125.j.maspons@creaf.uab.cat>
References: <201106211934.51125.j.maspons@creaf.uab.cat>
Message-ID: <BANLkTimPSxffemgbv4W0OP1ZJtpi3VzXVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110622/e220a871/attachment.pl>

From r.hijmans at gmail.com  Wed Jun 22 18:08:37 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 22 Jun 2011 09:08:37 -0700 (PDT)
Subject: [R-sig-Geo] Antw:  change projection of large raster file
In-Reply-To: <4E007B8D020000270000F1DA@gwia2.boku.ac.at>
References: <4E005AAD.4080905@ufz.de>
	<4E007B8D020000270000F1DA@gwia2.boku.ac.at>
Message-ID: <1308758917925-6504895.post@n2.nabble.com>

Apart from the multicore that Matteo mentioned, there are other things that
might speed things up.

first: this is a bad idea. 

setOptions(chunksize = 1e+04, maxmemory = 1e+06) 

By doing this you are giving the function very little memory to work this. I
would only do this if the function fails becaise of memory problems. In
other cases it might be good to increase the default values of these setting
to speed things up.

you have 

test <- raster("glc2000_v1_1") #reads the GLC data

And then you want to project to the universe of grid100

But what cell size etc? For a large raster like this, I would do something
like

r <- raster(grid100) # to convert the SpatialGrid into a raster 
r <- raster(r) # remove the values

now use nrow, ncol, or res to set the resolution you desire. And then do

test2 <- projectRaster(test, r)  

Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/change-projection-of-large-raster-file-tp6499121p6504895.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Wed Jun 22 18:21:02 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Wed, 22 Jun 2011 09:21:02 -0700 (PDT)
Subject: [R-sig-Geo] insert NODATA_value -999.0 into asc file
In-Reply-To: <BANLkTin5Bz85n_LXYrq7=+bqYtbt0Ou_vw@mail.gmail.com>
References: <4DFFCEE90200000300020A63@gwia1.boku.ac.at>
	<BANLkTin5Bz85n_LXYrq7=+bqYtbt0Ou_vw@mail.gmail.com>
Message-ID: <1308759662453-6504947.post@n2.nabble.com>

> have a large number (several thousand) of asci files which were 
> delivered to me without a NODATA_value  -999.0 line in the header 


If all your files are for the same area you could do something like

r <- raster(ncol=601, nrow=351, xmn=100000, xmx=701000, ymax=250000, 
ymn=-101000)

filename <- 'file.asc'
v <- as.numeric( scan(filename, skip=6, what='character') 
v[v==-999] <- NA
r1 <- setValues(r, v)

Else you could read the first couple of lines to adjust values in the
'raster' function. 

Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/insert-NODATA-value-999-0-into-asc-file-tp6497397p6504947.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Wed Jun 22 19:52:46 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 22 Jun 2011 19:52:46 +0200 (CEST)
Subject: [R-sig-Geo] How to merge SpatialPolygonsDataFrame?
In-Reply-To: <BANLkTimPSxffemgbv4W0OP1ZJtpi3VzXVQ@mail.gmail.com>
References: <201106211934.51125.j.maspons@creaf.uab.cat>
	<BANLkTimPSxffemgbv4W0OP1ZJtpi3VzXVQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106221801030.3592@reclus.nhh.no>

On Wed, 22 Jun 2011, Matthias Hinz wrote:

> Hi,
>
> I can give you an example for merging two of those data frames. It might not
> be the best solution, but it should work for all your data. In general, i
> separated Polygons - Objects and data, assigned new, unique ids to the
> polygons and merged them together. Then i merged the data and changed the
> rownames to the ids, to match them with the polygon ids (alternatively you
> can just add match.ID = FALSE when creating SpatialPolygonsDataFrames)

If you use match.ID = FALSE, all hell may be let loose, and you certainly 
lose control of whether the geometries and the data are properly 
associated.

Did you consider using spRbind() in maptools, which will try to handle 
things properly?

In addition, never use the @ operator to access slots unless you have 
written the functions concerned yourself, it is an effective and very 
elegant way to shoot yourself in the foot. Always use provided access 
or coercion methods, and if you wonder why they are not provided, you'll 
usually find that there is a good reason.

library(raster)
td <- tempdir()
bel <- getData("GADM", country="BEL", level=0, path=td)
nld <- getData("GADM", country="NLD", level=0, path=td)
row.names(nld) <- paste("nld", row.names(nld), sep="_")
row.names(bel) <- paste("bel", row.names(bel), sep="_")
library(maptools)
bel_nld <- spRbind(bel, nld)
plot(bel_nld)
summary(bel_nld)

Or equivalently:

library(sp)
bel_nld1 <- rbind(bel, nld)
plot(bel_nld1)

Hope this clarifies,

Roger


>
> countries<- c("AUT", "BEL", "BGR", "CZE", "DEU", "DNK", "EST", "ESP", "FIN",
> "FRA", "GRC", "HUN", "IRL", "ITA", "LTU", "LUX", "LVA", "NLD", "POL", "PRT",
> "ROU", "SWE", "SVN", "SVK")
>
> one = getData("GADM", country=countries[1], level=0)
> two = getData("GADM", country=countries[2], level=0)
>
> #retrieve new lists of Polygons and assign new ids:
> #(note: polygons slot eventually contain more than 1 Polygons - object)
> p1 = Polygons(one at polygons[[1]]@Polygons,one$GADMID)
> p2 = Polygons(two at polygons[[1]]@Polygons,two$GADMID)
>
> #merge polygons:
> plist = list(p1, p2)
> p = SpatialPolygons(plist, proj4string=one at proj4string)
>
> #merge data:
> data=rbind(one at data,two at data)
> #match rownames with Polygons ids:
> rownames(data) = data$GADMID
> spdf = SpatialPolygonsDataFrame(p, data)
> sp::plot(spdf)
>
> Kind regards,
> Matthias
>
>

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From pmagdon at gwdg.de  Thu Jun 23 16:55:53 2011
From: pmagdon at gwdg.de (Paul Magdon)
Date: Thu, 23 Jun 2011 16:55:53 +0200
Subject: [R-sig-Geo] Calculating 3d area and perimeter for a landscape patch?
Message-ID: <4E0353F9.1080709@gwdg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110623/1438e38c/attachment.pl>

From metras.raphaelle at choisyclub.org  Thu Jun 23 18:48:15 2011
From: metras.raphaelle at choisyclub.org (Raphaelle)
Date: Thu, 23 Jun 2011 09:48:15 -0700 (PDT)
Subject: [R-sig-Geo] as.yearmon in attribute table of shapefiles
Message-ID: <1308847695009-6509058.post@n2.nabble.com>

Dear all,

I am experiencing troubles with Dates objects in shapefiles:

1. I open my shapefile using readShapePoints from maptools : ok.

2. Within the shapefile, the date appears correctly as Class Date (which is
good):
> str(Centroid_SA at data$rvf_date[44569:44577])
Class 'Date'  num [1:9] NA 14706 NA NA 14741 ...

3. but when I display all the dates, it appears in " ", as if it was a
character:
[44569] NA   "2010-04-07" NA  NA "2010-05-12" NA NA NA

4. This becomes a problem because want to work on these dates. I use the
as.yearmon function from the 'zoo' package because I want to work with
monthly
data.

Centroid_SA at data$rvf_dateym <- as.yearmon(Centroid_SA at data$rvf_date)

5. I display the new vector date I just created, still appearing in " ":
[44561] NA NA NA NA NA NA NA   NA   NA    "Apr 2010"
[44571] NA  NA  "May 2010" NA 

6. and then when I want to open the attribute table, I have the following
message
(see below) and I can't work anymore with the variable.

> head(Centroid_SA at data)
Error in charToDate(x) : 
  character string is not in a standard unambiguous format

7. I have tried the function as.yearmon with a normal dataset (not
shapefile), and
I have no problem. All works fine. The only difference apparently is the
presence
of " " in steps 3 & 5, that are not appearing when I use normal dataset.

8. I have also extracted the attribute table from the shapefile to work with
it
independently, trying to reformat in as.Date etc but the problem remains.

Thank you very much if someone could give me some hints.

Best regards,

Raphaelle Metras


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/as-yearmon-in-attribute-table-of-shapefiles-tp6509058p6509058.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From potts.a at gmail.com  Thu Jun 23 19:52:58 2011
From: potts.a at gmail.com (Alastair Potts)
Date: Thu, 23 Jun 2011 19:52:58 +0200
Subject: [R-sig-Geo] dismo library: species distribution modelling and
 obtaining thresholds values
Message-ID: <4E037D7A.7050903@gmail.com>

Good day all,
I am using the dismo library for species distribution modelling using a 
number of models. I would like to select different threshold levels. The 
sdm.pdf vignette only gives an example to obtain the Maximum training 
(or testing) sensitivity plus specificity threshold:
e at t[which.max(e at TPR + e at TNR)]

I was wondering how one would go about obtaining the following 
thresholds from a ModelEvaluation object:
Equal training sensitivity and specificity
Balance training omission, predicted area and threshold value
Equate entropy of thresholded and original distributions

Thanks in advance for your time,
Cheers,
Alastair Potts


From matthew at matthewvavrek.com  Thu Jun 23 20:10:42 2011
From: matthew at matthewvavrek.com (Matthew Vavrek)
Date: Thu, 23 Jun 2011 14:10:42 -0400
Subject: [R-sig-Geo] Text label buffering
Message-ID: <4E0381A2.7090904@matthewvavrek.com>

Hello all,
I'm making up some maps in R, but some of the labels are being obscured 
by other lines on the map. I'd like to be able to buffer my labels, so 
that there's a bit of whitespace surrounding each letter to make them 
more readable. I've tried doing this by doing a double call to text(), 
with white in bold (font=2) and then a regular font, and by adjusting 
the text size, but the text doesn't really match up between the two 
labels this way.

for example:

par(bg='black')
plot.new()
text(0.5, 0.5, label='text', col='white', font=2, cex=3)
text(0.5, 0.5, label='text', col='black', font=1, cex=3)

or:

par(bg='black')
plot.new()
text(0.5, 0.5, label='text', col='white', cex=3)
text(0.5, 0.5, label='text', col='black', cex=2.9)

give the idea of what I want, but not quite as cleanly as I'd like.

Is there some way of doing this? Seems like there should be, but 
searching the internets hasn't turned up anything yet.

Thanks
Matthew


From edzer.pebesma at uni-muenster.de  Thu Jun 23 20:40:44 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Thu, 23 Jun 2011 20:40:44 +0200
Subject: [R-sig-Geo] as.yearmon in attribute table of shapefiles
In-Reply-To: <1308847695009-6509058.post@n2.nabble.com>
References: <1308847695009-6509058.post@n2.nabble.com>
Message-ID: <4E0388AC.3060802@uni-muenster.de>

Hi Raphaelle,

I can't see what went wrong. Please provide a script, or the shapefile
with script (possibly off-list) to reproduce the problem.

The printing of Date and yearmon data with quotes is standard behaviour,
and does not indicate they are transformed or so, or of another class. Try:

class(Centroid_SA at data$rvf_date)

Have you tried, as an alternative, to read the shapefile with function
readOGR in package rgdal?

On 06/23/2011 06:48 PM, Raphaelle wrote:
> Dear all,
> 
> I am experiencing troubles with Dates objects in shapefiles:
> 
> 1. I open my shapefile using readShapePoints from maptools : ok.
> 
> 2. Within the shapefile, the date appears correctly as Class Date (which is
> good):
>> str(Centroid_SA at data$rvf_date[44569:44577])
> Class 'Date'  num [1:9] NA 14706 NA NA 14741 ...
> 
> 3. but when I display all the dates, it appears in " ", as if it was a
> character:
> [44569] NA   "2010-04-07" NA  NA "2010-05-12" NA NA NA
> 
> 4. This becomes a problem because want to work on these dates. I use the
> as.yearmon function from the 'zoo' package because I want to work with
> monthly
> data.
> 
> Centroid_SA at data$rvf_dateym <- as.yearmon(Centroid_SA at data$rvf_date)
> 
> 5. I display the new vector date I just created, still appearing in " ":
> [44561] NA NA NA NA NA NA NA   NA   NA    "Apr 2010"
> [44571] NA  NA  "May 2010" NA 
> 
> 6. and then when I want to open the attribute table, I have the following
> message
> (see below) and I can't work anymore with the variable.
> 
>> head(Centroid_SA at data)
> Error in charToDate(x) : 
>   character string is not in a standard unambiguous format
> 
> 7. I have tried the function as.yearmon with a normal dataset (not
> shapefile), and
> I have no problem. All works fine. The only difference apparently is the
> presence
> of " " in steps 3 & 5, that are not appearing when I use normal dataset.
> 
> 8. I have also extracted the attribute table from the shapefile to work with
> it
> independently, trying to reformat in as.Date etc but the problem remains.
> 
> Thank you very much if someone could give me some hints.
> 
> Best regards,
> 
> Raphaelle Metras
> 
> 
> --
> View this message in context: http://r-sig-geo.2731867.n2.nabble.com/as-yearmon-in-attribute-table-of-shapefiles-tp6509058p6509058.html
> Sent from the R-sig-geo mailing list archive at Nabble.com.
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From sarah.goslee at gmail.com  Thu Jun 23 20:49:31 2011
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 23 Jun 2011 14:49:31 -0400
Subject: [R-sig-Geo] Text label buffering
In-Reply-To: <4E0381A2.7090904@matthewvavrek.com>
References: <4E0381A2.7090904@matthewvavrek.com>
Message-ID: <BANLkTikiLyAidggYA=o0HJu-nVp7vatz0A@mail.gmail.com>

I would just use rect() to draw a white rectangle, then put the text
on top of it. Trying to frame each letter just seems like too much
work.

par(bg='black')
plot.new()
rect(.4, .4, .6, .6, col="white")
text(0.5, 0.5, label='text', col='black', font=1, cex=3)

Sarah

On Thu, Jun 23, 2011 at 2:10 PM, Matthew Vavrek
<matthew at matthewvavrek.com> wrote:
> Hello all,
> I'm making up some maps in R, but some of the labels are being obscured by
> other lines on the map. I'd like to be able to buffer my labels, so that
> there's a bit of whitespace surrounding each letter to make them more
> readable. I've tried doing this by doing a double call to text(), with white
> in bold (font=2) and then a regular font, and by adjusting the text size,
> but the text doesn't really match up between the two labels this way.
>
> for example:
>
> par(bg='black')
> plot.new()
> text(0.5, 0.5, label='text', col='white', font=2, cex=3)
> text(0.5, 0.5, label='text', col='black', font=1, cex=3)
>
> or:
>
> par(bg='black')
> plot.new()
> text(0.5, 0.5, label='text', col='white', cex=3)
> text(0.5, 0.5, label='text', col='black', cex=2.9)
>
> give the idea of what I want, but not quite as cleanly as I'd like.
>
> Is there some way of doing this? Seems like there should be, but searching
> the internets hasn't turned up anything yet.
>
> Thanks
> Matthew
>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From j.m.signer at gmail.com  Thu Jun 23 20:55:49 2011
From: j.m.signer at gmail.com (Johannes Signer)
Date: Thu, 23 Jun 2011 14:55:49 -0400
Subject: [R-sig-Geo] Text label buffering
In-Reply-To: <BANLkTikiLyAidggYA=o0HJu-nVp7vatz0A@mail.gmail.com>
References: <4E0381A2.7090904@matthewvavrek.com>
	<BANLkTikiLyAidggYA=o0HJu-nVp7vatz0A@mail.gmail.com>
Message-ID: <BANLkTikLzKDFbJnqEoZM5Ci=0EjeZb9L_w@mail.gmail.com>

There is also the boxed.labels() function in the plotrix package.

HTH Johannes

On Thu, Jun 23, 2011 at 2:49 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> I would just use rect() to draw a white rectangle, then put the text
> on top of it. Trying to frame each letter just seems like too much
> work.
>
> par(bg='black')
> plot.new()
> rect(.4, .4, .6, .6, col="white")
> text(0.5, 0.5, label='text', col='black', font=1, cex=3)
>
> Sarah
>
> On Thu, Jun 23, 2011 at 2:10 PM, Matthew Vavrek
> <matthew at matthewvavrek.com> wrote:
>> Hello all,
>> I'm making up some maps in R, but some of the labels are being obscured by
>> other lines on the map. I'd like to be able to buffer my labels, so that
>> there's a bit of whitespace surrounding each letter to make them more
>> readable. I've tried doing this by doing a double call to text(), with white
>> in bold (font=2) and then a regular font, and by adjusting the text size,
>> but the text doesn't really match up between the two labels this way.
>>
>> for example:
>>
>> par(bg='black')
>> plot.new()
>> text(0.5, 0.5, label='text', col='white', font=2, cex=3)
>> text(0.5, 0.5, label='text', col='black', font=1, cex=3)
>>
>> or:
>>
>> par(bg='black')
>> plot.new()
>> text(0.5, 0.5, label='text', col='white', cex=3)
>> text(0.5, 0.5, label='text', col='black', cex=2.9)
>>
>> give the idea of what I want, but not quite as cleanly as I'd like.
>>
>> Is there some way of doing this? Seems like there should be, but searching
>> the internets hasn't turned up anything yet.
>>
>> Thanks
>> Matthew
>>
>
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From Greg.Snow at imail.org  Thu Jun 23 21:22:54 2011
From: Greg.Snow at imail.org (Greg Snow)
Date: Thu, 23 Jun 2011 13:22:54 -0600
Subject: [R-sig-Geo] Text label buffering
In-Reply-To: <4E0381A2.7090904@matthewvavrek.com>
References: <4E0381A2.7090904@matthewvavrek.com>
Message-ID: <B37C0A15B8FB3C468B5BC7EBC7DA14CC6347EA6E08@LP-EXMBVS10.CO.IHC.COM>

Look at the shadowtext function in the TeachingDemos package.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at imail.org
801.408.8111


> -----Original Message-----
> From: r-sig-geo-bounces at r-project.org [mailto:r-sig-geo-bounces at r-
> project.org] On Behalf Of Matthew Vavrek
> Sent: Thursday, June 23, 2011 12:11 PM
> To: r-sig-geo at r-project.org
> Subject: [R-sig-Geo] Text label buffering
> 
> Hello all,
> I'm making up some maps in R, but some of the labels are being obscured
> by other lines on the map. I'd like to be able to buffer my labels, so
> that there's a bit of whitespace surrounding each letter to make them
> more readable. I've tried doing this by doing a double call to text(),
> with white in bold (font=2) and then a regular font, and by adjusting
> the text size, but the text doesn't really match up between the two
> labels this way.
> 
> for example:
> 
> par(bg='black')
> plot.new()
> text(0.5, 0.5, label='text', col='white', font=2, cex=3)
> text(0.5, 0.5, label='text', col='black', font=1, cex=3)
> 
> or:
> 
> par(bg='black')
> plot.new()
> text(0.5, 0.5, label='text', col='white', cex=3)
> text(0.5, 0.5, label='text', col='black', cex=2.9)
> 
> give the idea of what I want, but not quite as cleanly as I'd like.
> 
> Is there some way of doing this? Seems like there should be, but
> searching the internets hasn't turned up anything yet.
> 
> Thanks
> Matthew
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From sewellpatrick at gmail.com  Thu Jun 23 22:36:01 2011
From: sewellpatrick at gmail.com (Patrick S)
Date: Thu, 23 Jun 2011 15:36:01 -0500
Subject: [R-sig-Geo] Variable Bandwidth Kernel Density
Message-ID: <BANLkTinVhVXy5o3YV_zd14yTUkALN_UYtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110623/ad256b5c/attachment.pl>

From emanuele.cordano at gmail.com  Fri Jun 24 11:57:43 2011
From: emanuele.cordano at gmail.com (Emanuele Cordano)
Date: Fri, 24 Jun 2011 11:57:43 +0200
Subject: [R-sig-Geo] categorical AR or ARMA time series processes
Message-ID: <BANLkTimU1w3401xuJcXjNir58CipcL-QLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110624/65a4faa5/attachment.pl>

From r.turner at auckland.ac.nz  Fri Jun 24 12:49:12 2011
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 24 Jun 2011 22:49:12 +1200
Subject: [R-sig-Geo] categorical AR or ARMA time series processes
In-Reply-To: <BANLkTimU1w3401xuJcXjNir58CipcL-QLQ@mail.gmail.com>
References: <BANLkTimU1w3401xuJcXjNir58CipcL-QLQ@mail.gmail.com>
Message-ID: <4E046BA8.6050603@auckland.ac.nz>

On 24/06/11 21:57, Emanuele Cordano wrote:
> Dear all,
>
> I'm working on daily precipitation generation time series, in particular I
> want to model a binary time serries (wet/dry day) for several years. I read
> about Discrete-Value or Catagorical-value AR or ARMA techniques. They refer
> to  Pegram?s [Pegram, G.G.S., 1980. An autoregressive model for multilag
> markov chains. J. Appl. Probab. 17, 350?362] mixing operator and subsequent
> more recent works  like
> http://www.sciencedirect.com/science/article/pii/S0167715209001977 or
> http://www.sciencedirect.com/science/article/pii/S0378375809000330.
> Are these methods and Pegram's operetor  already implemented in some CRAN
> package  or something similar? I'm looking if there is something already
> implemented on which I can work?

The CRAN package hmm.discnp might be of some use to you.

cheers,

Rolf Turner


From r.m.krug at gmail.com  Fri Jun 24 15:46:14 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Fri, 24 Jun 2011 15:46:14 +0200
Subject: [R-sig-Geo] Import of 3D vector from grass into R?
Message-ID: <BANLkTinj4XF7C11tXnX9sj31GzcnWrSUo8OANHFShjR=+Qv+HQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110624/b1ccb042/attachment.pl>

From horning at amnh.org  Fri Jun 24 16:10:58 2011
From: horning at amnh.org (Ned Horning)
Date: Fri, 24 Jun 2011 10:10:58 -0400
Subject: [R-sig-Geo] Feature space plotting
Message-ID: <4E049AF2.9070307@amnh.org>

Hi - Before I embark to develop a script to create feature space plots 
of two image bands I was wondering if anyone was aware of a package that 
provides this capability. I would like to be able to plot pixel values 
from one image band on the X-axis and pixel values from the another band 
on the Y-axis and show different frequencies of occurrence in the 
different plot bins with different colors. I would then overlay training 
data on the graph to see how well it is distributed in the 2-band 
feature space.

This should be pretty easy to implement but I thought I'd check first.

Ned


From emanuele.cordano at gmail.com  Fri Jun 24 16:41:40 2011
From: emanuele.cordano at gmail.com (Emanuele Cordano)
Date: Fri, 24 Jun 2011 16:41:40 +0200
Subject: [R-sig-Geo] categorical AR or ARMA time series processes
In-Reply-To: <4E046BA8.6050603@auckland.ac.nz>
References: <BANLkTimU1w3401xuJcXjNir58CipcL-QLQ@mail.gmail.com>
	<4E046BA8.6050603@auckland.ac.nz>
Message-ID: <BANLkTimxRdCWpwHnc2Wge67F9-h6RcLtdg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110624/555ba23d/attachment.pl>

From patrick.brown at utoronto.ca  Fri Jun 24 17:23:25 2011
From: patrick.brown at utoronto.ca (Patrick Brown)
Date: Fri, 24 Jun 2011 11:23:25 -0400
Subject: [R-sig-Geo] read subset of postgis table
Message-ID: <BANLkTi=dCCFznhK1nAJsHdR0PtNjULXTZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110624/17f7c4aa/attachment.pl>

From tom.gottfried at tum.de  Fri Jun 24 17:24:29 2011
From: tom.gottfried at tum.de (Tom Gottfried)
Date: Fri, 24 Jun 2011 17:24:29 +0200
Subject: [R-sig-Geo] colocated cokriging with empty neighbourhood causes
	crash
Message-ID: <4E04AC2D.1020305@tum.de>

Dear list,

while doing local colocated cokriging it seems that, if some points to be predicted have no value of 
the primary variable in the neighbourhood, this causes R to crash with the messages shown below 
(script with modified code from ASDAR book to generate the crash attached).
Should it be expected that NA is predicted at the respective points (as I understood, this is what 
ordinary kriging and cokriging do when the neighbourhood is empty)?

regards,
Tom

Output at crash-time:

Intrinsic Correlation found. Good.
[using ordinary cokriging]

  *** caught segfault ***
address 0x50, cause 'memory not mapped'

Traceback:
  1: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))), as.double(as.vector(raw$locations)), 
     as.vector(new.X), as.integer(block.cols), as.vector(block),     as.vector(bl_weights), 
as.integer(nsim), as.integer(BLUE))
  2: predict.gstat(g.cc, meuse.grid)
  3: predict(g.cc, meuse.grid)

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Selection:

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: test_local_colocated.R
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110624/8669077c/attachment.pl>

From arindam.gis at gmail.com  Fri Jun 24 17:35:14 2011
From: arindam.gis at gmail.com (ari)
Date: Fri, 24 Jun 2011 08:35:14 -0700 (PDT)
Subject: [R-sig-Geo] Download MODIS images
In-Reply-To: <00b701cb1c26$240a7070$6c1f5150$@net>
References: <AANLkTinVPgiPqo453wiehtt__bOObI1UjB_U00jhRA8v@mail.gmail.com>
	<00b701cb1c26$240a7070$6c1f5150$@net>
Message-ID: <1308929714153-6512456.post@n2.nabble.com>

Hi,
     I am trying to download MODIS daily product using T. Hengl's script
downloaded from: 
http://spatial-analyst.net/book/Rscripts in order to get daily surface
reflectance modis products (MOD09GQ & MYD09GQ) for the block h10v5. Could
you please help me in modifying the script so that I can download daily data
(2009 onwards) and schedule a task to automatically download data everyday?

I will appreciate your help very much.


Sincerely,
A

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Download-MODIS-images-tp5251474p6512456.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From Roger.Bivand at nhh.no  Fri Jun 24 18:49:40 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 24 Jun 2011 18:49:40 +0200
Subject: [R-sig-Geo] Import of 3D vector from grass into R?
In-Reply-To: <BANLkTinj4XF7C11tXnX9sj31GzcnWrSUo8OANHFShjR=+Qv+HQ@mail.gmail.com>
References: <BANLkTinj4XF7C11tXnX9sj31GzcnWrSUo8OANHFShjR=+Qv+HQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.00.1106241826520.14313@reclus.nhh.no>

On Fri, 24 Jun 2011, Rainer M Krug wrote:

> Hi
>
> Is it possible to import a 3D vector from GRASS into R, so that all three
> dimensions are available?
>
> I have 3D lines in GRASS which which I have to do some calculations from 
> the z-values.

Hi,

I don't think so. The code in rgdal does not accept any third dimension in 
lines or polygons, but may accept Z for points - the same applies to code 
for reading vector objects in maptools from shapefiles. Can you use 
v.to.points -v first to generate points? I think that you'd need to copy 
the input entity label or FID if possible to retain information on which 
point belongs to which line. This can also be reconstituted from the 
lengths starting at 0 in the second layer created by v.to.points.

Hope this helps,

Roger

>
> Cheers,
>
> Rainer
>
>

-- 
Roger Bivand
Department of Economics, NHH Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From edzer.pebesma at uni-muenster.de  Sun Jun 26 21:54:47 2011
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Sun, 26 Jun 2011 21:54:47 +0200
Subject: [R-sig-Geo] colocated cokriging with empty neighbourhood causes
 crash
In-Reply-To: <4E04AC2D.1020305@tum.de>
References: <4E04AC2D.1020305@tum.de>
Message-ID: <4E078E87.1090509@uni-muenster.de>

Well spotted! I submitted an updated gstat version (0.9-82) that fixes
this bug to CRAN.

Best regards,

On 06/24/2011 05:24 PM, Tom Gottfried wrote:
> Dear list,
> 
> while doing local colocated cokriging it seems that, if some points to
> be predicted have no value of the primary variable in the neighbourhood,
> this causes R to crash with the messages shown below (script with
> modified code from ASDAR book to generate the crash attached).
> Should it be expected that NA is predicted at the respective points (as
> I understood, this is what ordinary kriging and cokriging do when the
> neighbourhood is empty)?
> 
> regards,
> Tom
> 
> Output at crash-time:
> 
> Intrinsic Correlation found. Good.
> [using ordinary cokriging]
> 
>  *** caught segfault ***
> address 0x50, cause 'memory not mapped'
> 
> Traceback:
>  1: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
> as.double(as.vector(raw$locations)),     as.vector(new.X),
> as.integer(block.cols), as.vector(block),     as.vector(bl_weights),
> as.integer(nsim), as.integer(BLUE))
>  2: predict.gstat(g.cc, meuse.grid)
>  3: predict(g.cc, meuse.grid)
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Selection:
> 
> 
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From nick.greenfield at gmail.com  Mon Jun 27 07:25:59 2011
From: nick.greenfield at gmail.com (Nicholas Greenfield)
Date: Sun, 26 Jun 2011 22:25:59 -0700
Subject: [R-sig-Geo] Problem with extent of output raster from crop()
	function in raster package
Message-ID: <BANLkTi=bjdroqpmrzAwnDtLVV7N-MzfzGw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110626/fc0fcdf4/attachment.pl>

From alexander.arpaci at boku.ac.at  Mon Jun 27 08:18:24 2011
From: alexander.arpaci at boku.ac.at (Alexander Arpaci)
Date: Mon, 27 Jun 2011 08:18:24 +0200
Subject: [R-sig-Geo] Antw: Re:  insert NODATA_value -999.0 into asc file
Message-ID: <4E083CD00200000300020D13@gwia1.boku.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110627/7ed0142c/attachment.pl>

From a-gregmc at microsoft.com  Mon Jun 27 13:10:08 2011
From: a-gregmc at microsoft.com (Greg McInerny (Brook Street))
Date: Mon, 27 Jun 2011 11:10:08 +0000
Subject: [R-sig-Geo] LAST CHANCE TO HAVE YOUR SAY... Species Distribution
 Modelling Survey (niches, climate envelopes, habitat suitability etc...)
Message-ID: <F40E2C430CC2DD4D9C0873A2FAC976B41CB5F4F0@DB3EX14MBXC306.europe.corp.microsoft.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110627/7e6e3bd4/attachment.pl>

From freddy.vate01 at gmail.com  Mon Jun 27 14:47:07 2011
From: freddy.vate01 at gmail.com (=?UTF-8?Q?Freddy_L=C3=B3pez?=)
Date: Mon, 27 Jun 2011 08:17:07 -0430
Subject: [R-sig-Geo] categorical AR or ARMA time series processes
In-Reply-To: <BANLkTimU1w3401xuJcXjNir58CipcL-QLQ@mail.gmail.com>
References: <BANLkTimU1w3401xuJcXjNir58CipcL-QLQ@mail.gmail.com>
Message-ID: <BANLkTikX_WzyMrsrfRegHQa3UxgG541eug@mail.gmail.com>

Hello Emanuele,

Perhaps GARMA models can be useful. A reference:

http://pubs.amstat.org/doi/abs/10.1198/016214503388619238

This is implemented (partially, I think) in VGAM library. See garma()
function. I could model some years ago count data using an
autoregressive framework with this package.

I hope this help.

Cheers.

On Fri, Jun 24, 2011 at 05:27, Emanuele Cordano
<emanuele.cordano at gmail.com> wrote:
>
> Dear all,
>
> I'm working on daily precipitation generation time series, in particular I
> want to model a binary time serries (wet/dry day) for several years. I read
> about Discrete-Value or Catagorical-value AR or ARMA techniques. They refer
> to ?Pegram?s [Pegram, G.G.S., 1980. An autoregressive model for multilag
> markov chains. J. Appl. Probab. 17, 350?362] mixing operator and subsequent
> more recent works ?like
> http://www.sciencedirect.com/science/article/pii/S0167715209001977 or
> http://www.sciencedirect.com/science/article/pii/S0378375809000330.
> Are these methods and Pegram's operetor ?already implemented in some CRAN
> package ?or something similar? I'm looking if there is something already
> implemented on which I can work
>
> Thanks a lot in advance
>
> Regards
> Emanuele Cordano
>
> ? ? ? ?[[alternative HTML version deleted]]
>
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>



--
?But Gwindor answered: 'The doom lies in yourself, not in your name.'?

JRR Tolkien


From r.hijmans at gmail.com  Mon Jun 27 17:28:07 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 27 Jun 2011 08:28:07 -0700 (PDT)
Subject: [R-sig-Geo] dismo library: species distribution modelling and
 obtaining thresholds values
In-Reply-To: <4E037D7A.7050903@gmail.com>
References: <4E037D7A.7050903@gmail.com>
Message-ID: <1309188487599-6520941.post@n2.nabble.com>

> I am using the dismo library for species distribution modelling using a 
> number of models. I would like to select different threshold levels. The 
> sdm.pdf vignette only gives an example to obtain the Maximum training 
> (or testing) sensitivity plus specificity threshold: 
> e at t[which.max(e at TPR + e at TNR)] 

> I was wondering how one would go about obtaining the following 
> thresholds from a ModelEvaluation object: 
> Equal training sensitivity and specificity 
> Balance training omission, predicted area and threshold value 
> Equate entropy of thresholded and original distributions 

Alastair, 

There is some need for further development here. But for "Equal training
sensitivity and specificity" you could probably do

e at t[which.min(abs(e at TPR - e at TNR))] 

"threshold value" would be one of the values in (or the nearest to) e at t (t
stands for threshold), and you can set these with an argument to evaluate.

I do not know what "balance training omission" is (balance with what?).
"Predicted area" is also vague for a threshold: relative to what?

See str(e) for what else is in there. 

Hope this helps,
Robert


--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/dismo-library-species-distribution-modelling-and-obtaining-thresholds-values-tp6509338p6520941.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.hijmans at gmail.com  Mon Jun 27 17:34:42 2011
From: r.hijmans at gmail.com (Robert Hijmans)
Date: Mon, 27 Jun 2011 08:34:42 -0700 (PDT)
Subject: [R-sig-Geo] Problem with extent of output raster from crop()
 function in raster package
In-Reply-To: <BANLkTi=bjdroqpmrzAwnDtLVV7N-MzfzGw@mail.gmail.com>
References: <BANLkTi=bjdroqpmrzAwnDtLVV7N-MzfzGw@mail.gmail.com>
Message-ID: <1309188882243-6520978.post@n2.nabble.com>

> I'm currently having some problems getting the crop() function in the
raster 
> package to work properly, and cannot for the life of me figure out what's 
> going on. 
> Essentially, I'm trying to crop a larger raster (raster1) to match one
> with 
> a smaller extent (raster2), which is entirely contained in the first
> raster. 
> The projections seem to match and the resolution is the same. 
> (....) 
> Unfortunately, the documentation doesn't seem to indicate that there are
> any 
> special cases where such an error would occur. 

Nick, 

You can only only crop entire raster cells. That is why the docs say that
"the Extent is aligned to the cells of the input RasterLayer." (this could
be elaborated on), and why this is not an error.

You may need to use resample if you want the raster cells to align. (or, if
the misalignment is in fact an error, use shift)

Robert

--
View this message in context: http://r-sig-geo.2731867.n2.nabble.com/Problem-with-extent-of-output-raster-from-crop-function-in-raster-package-tp6519108p6520978.html
Sent from the R-sig-geo mailing list archive at Nabble.com.


From r.m.krug at gmail.com  Tue Jun 28 14:44:41 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Tue, 28 Jun 2011 14:44:41 +0200
Subject: [R-sig-Geo] Import of 3D vector from grass into R?
In-Reply-To: <alpine.LRH.2.00.1106241826520.14313@reclus.nhh.no>
References: <BANLkTinj4XF7C11tXnX9sj31GzcnWrSUo8OANHFShjR=+Qv+HQ@mail.gmail.com>
	<alpine.LRH.2.00.1106241826520.14313@reclus.nhh.no>
Message-ID: <BANLkTi=XMHRQXdpUGX4sd4mFiUg=BaQm_ghxDknfu3aXN-SwLw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110628/3ee86467/attachment.pl>

From r.m.krug at gmail.com  Tue Jun 28 14:54:07 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Tue, 28 Jun 2011 14:54:07 +0200
Subject: [R-sig-Geo] Model deposition of water dispersed seeds based on DEM
 and deposition rates per slope
Message-ID: <BANLkTi=LEAP4H2pd=bXH4LAwBqBKX_uu5edc5fNEvcndk484kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110628/f2f75a10/attachment.pl>

From ruthkelly123 at gmail.com  Tue Jun 28 15:24:15 2011
From: ruthkelly123 at gmail.com (Ruth Kelly)
Date: Tue, 28 Jun 2011 14:24:15 +0100
Subject: [R-sig-Geo] Calculating distance (km) between points by sea
Message-ID: <BANLkTimTt3HYEFy5JmQ6oNiUF7bbLhpcxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110628/89a6d8ba/attachment.pl>

From sarah.goslee at gmail.com  Tue Jun 28 15:35:30 2011
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 28 Jun 2011 09:35:30 -0400
Subject: [R-sig-Geo] Calculating distance (km) between points by sea
In-Reply-To: <BANLkTimTt3HYEFy5JmQ6oNiUF7bbLhpcxw@mail.gmail.com>
References: <BANLkTimTt3HYEFy5JmQ6oNiUF7bbLhpcxw@mail.gmail.com>
Message-ID: <BANLkTimNUXnik9BBRzL8rXesHF5yU2CPNg@mail.gmail.com>

Hi,

On Tue, Jun 28, 2011 at 9:24 AM, Ruth Kelly <ruthkelly123 at gmail.com> wrote:
> Hi,
>
> I'm trying to calculate the shortest distances by sea between points in the
> Meditteranean sea. ? I've been trying to do this using a costDistance
> approach in the gdistance package. ? ?(See code below).
>
> I have imported maps from ArcGIS in which sea has a value of 1 and land
> 10,000 there are also NA values at edges of the ascii matrix. ?I have set
> the transition values to resistance so that points should choose travel by
> sea. ?The projection is WCS 1984 (lat long) and the cell size (after
> aggregate command) is 0.1
>
> Hopefully the steps along the way are correct, but the output of the
> costDistance command is confusing to me. ?The actually distances in km
> should be in the region of from <10 to 100km.

As a very quick first look, you're calculating distances on lat-lon
units, so you're getting distances in lat-lon units.

If I were doing it, I would reproject into m or km before calculating
the distances, since lat-lon isn't a surface distance measure. In
particular, a unit of longitude varies in length depending on the
latitude, so you really can't convert after the fact.

> ?Could anybody help me to find a way of converting this? ?I have tried a lot
> of variations on the code and hope it is correct. ?I would appreciate
> someone looking over it for me and letting me know if it's right.
>
> Many thanks
>
> Ruth
>
> ################### code
>
> library(maptools)
>
> y <- readAsciiGrid("C:\\R\\Marine_algae\\westmed1.asc", proj4string =
> CRS("+proj=longlat + ellps=WGS84"))
>
>
> ############# vector of values from ascii grid ##########
> v1 <- y at data$westmed1.asc
>
> ########## create raster #######
>
> library(raster)
> med <- raster(y)
> setValues(med, v1)
>
> med2 <- aggregate(med, fact=10, fun=min)
>
>
> ############### g distance ##########
>
> library(gdistance)
> tr2 <- transition(med2, transitionFunction="mean", directions = 8)
> tr2 <- geoCorrection(tr2, type = "c")
> matrixValues(tr2) <- "resistance"
>
> ########## test points ##############
>
> p1 <- read.table("C:\\R\\Marine_algae\\test_points_med.csv", header = T, sep
> =",")
> p1 <- unique(p1)
> p1 <- as.matrix(cbind(p1$x, p1$y))
>
>
> cost1 <- costDistance(transition = tr2, fromCoords = p1, toCoords = p1)
>
> ?cost1
> ? ? ? ? [,1] ? ? ?[,2] ? ? ?[,3] ? ? ?[,4] ? ? ?[,5] ? ? [,6] ? ? [,7]
> [1,] 0.000000 2.7774957 2.7774957 2.7774957 2.0402271 2.306833 3.386609
> [2,] 2.777496 0.0000000 0.0000000 0.0000000 0.7372686 2.479186 3.576727
> [3,] 2.777496 0.0000000 0.0000000 0.0000000 0.7372686 2.479186 3.576727
> [4,] 2.777496 0.0000000 0.0000000 0.0000000 0.7372686 2.479186 3.576727
> [5,] 2.040227 0.7372686 0.7372686 0.7372686 0.0000000 1.741917 2.839459
> [6,] 2.306833 2.4791858 2.4791858 2.4791858 1.7419172 0.000000 3.106073
> [7,] 3.386609 3.5767274 3.5767274 3.5767274 2.8394588 3.106073 0.000000
>
>
> ########## ??? conversion to km???
>
>
> ___________________

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jacobvanetten at yahoo.com  Tue Jun 28 21:31:52 2011
From: jacobvanetten at yahoo.com (Jacob van Etten)
Date: Tue, 28 Jun 2011 20:31:52 +0100 (BST)
Subject: [R-sig-Geo] Calculating distance (km) between points by sea
In-Reply-To: <BANLkTimNUXnik9BBRzL8rXesHF5yU2CPNg@mail.gmail.com>
Message-ID: <1309289512.45257.YahooMailClassic@web29717.mail.ird.yahoo.com>

Try to set the scaling in geoCorrection() to FALSE to get meters. (This is the default in the new version of gdistance, which will be on CRAN shortly.) See the documentation of geoCorrection() for more info.

--- On Tue, 28/6/11, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> From: Sarah Goslee <sarah.goslee at gmail.com>
> Subject: Re: [R-sig-Geo] Calculating distance (km) between points by sea
> To: "Ruth Kelly" <ruthkelly123 at gmail.com>
> Cc: r-sig-geo at r-project.org
> Date: Tuesday, 28 June, 2011, 15:35
> Hi,
> 
> On Tue, Jun 28, 2011 at 9:24 AM, Ruth Kelly <ruthkelly123 at gmail.com>
> wrote:
> > Hi,
> >
> > I'm trying to calculate the shortest distances by sea
> between points in the
> > Meditteranean sea. ? I've been trying to do this
> using a costDistance
> > approach in the gdistance package. ? ?(See code
> below).
> >
> > I have imported maps from ArcGIS in which sea has a
> value of 1 and land
> > 10,000 there are also NA values at edges of the ascii
> matrix. ?I have set
> > the transition values to resistance so that points
> should choose travel by
> > sea. ?The projection is WCS 1984 (lat long) and the
> cell size (after
> > aggregate command) is 0.1
> >
> > Hopefully the steps along the way are correct, but the
> output of the
> > costDistance command is confusing to me. ?The
> actually distances in km
> > should be in the region of from <10 to 100km.
> 
> As a very quick first look, you're calculating distances on
> lat-lon
> units, so you're getting distances in lat-lon units.
> 
> If I were doing it, I would reproject into m or km before
> calculating
> the distances, since lat-lon isn't a surface distance
> measure. In
> particular, a unit of longitude varies in length depending
> on the
> latitude, so you really can't convert after the fact.
> 
> > ?Could anybody help me to find a way of converting
> this? ?I have tried a lot
> > of variations on the code and hope it is correct. ?I
> would appreciate
> > someone looking over it for me and letting me know if
> it's right.
> >
> > Many thanks
> >
> > Ruth
> >
> > ################### code
> >
> > library(maptools)
> >
> > y <-
> readAsciiGrid("C:\\R\\Marine_algae\\westmed1.asc",
> proj4string =
> > CRS("+proj=longlat + ellps=WGS84"))
> >
> >
> > ############# vector of values from ascii grid
> ##########
> > v1 <- y at data$westmed1.asc
> >
> > ########## create raster #######
> >
> > library(raster)
> > med <- raster(y)
> > setValues(med, v1)
> >
> > med2 <- aggregate(med, fact=10, fun=min)
> >
> >
> > ############### g distance ##########
> >
> > library(gdistance)
> > tr2 <- transition(med2, transitionFunction="mean",
> directions = 8)
> > tr2 <- geoCorrection(tr2, type = "c")
> > matrixValues(tr2) <- "resistance"
> >
> > ########## test points ##############
> >
> > p1 <-
> read.table("C:\\R\\Marine_algae\\test_points_med.csv",
> header = T, sep
> > =",")
> > p1 <- unique(p1)
> > p1 <- as.matrix(cbind(p1$x, p1$y))
> >
> >
> > cost1 <- costDistance(transition = tr2, fromCoords
> = p1, toCoords = p1)
> >
> > ?cost1
> > ? ? ? ? [,1] ? ? ?[,2] ? ? ?[,3] ? ?
> ?[,4] ? ? ?[,5] ? ? [,6] ? ? [,7]
> > [1,] 0.000000 2.7774957 2.7774957 2.7774957 2.0402271
> 2.306833 3.386609
> > [2,] 2.777496 0.0000000 0.0000000 0.0000000 0.7372686
> 2.479186 3.576727
> > [3,] 2.777496 0.0000000 0.0000000 0.0000000 0.7372686
> 2.479186 3.576727
> > [4,] 2.777496 0.0000000 0.0000000 0.0000000 0.7372686
> 2.479186 3.576727
> > [5,] 2.040227 0.7372686 0.7372686 0.7372686 0.0000000
> 1.741917 2.839459
> > [6,] 2.306833 2.4791858 2.4791858 2.4791858 1.7419172
> 0.000000 3.106073
> > [7,] 3.386609 3.5767274 3.5767274 3.5767274 2.8394588
> 3.106073 0.000000
> >
> >
> > ########## ??? conversion to km???
> >
> >
> > ___________________
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From clement.calenge at oncfs.gouv.fr  Wed Jun 29 09:49:22 2011
From: clement.calenge at oncfs.gouv.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Wed, 29 Jun 2011 09:49:22 +0200
Subject: [R-sig-Geo] Walruses and adehabitatHR: class estUDm exclusion
 of non-habitat pixels and summary over all animals
In-Reply-To: <1308601895714-6497315.post@n2.nabble.com>
References: <1308601895714-6497315.post@n2.nabble.com>
Message-ID: <4E0AD902.30108@oncfs.gouv.fr>

Dear Tony,


> We wish to summarize monthly summer foraging home ranges based on daily
> locations and a daily summary of foraging behavior measured by instruments
> on-board the satellite-linked tag, which is a metric similar in nature to
> the 'activity' index utilized by Benhamou and Cornelis (2010).
>
> For each walrus with a threshold amount of tracking in each month I
> construct a utilization distribution.  Then I must exclude land as
> non-habitat from each walruses monthly utilization distribution.
> Because their summering range abuts a coastline that is too complex (sharp
> peninsulas and sounds that violate the angle rules and relatively short
> shore line segments that violate the 3*h rule of Benhamou and Cornelis
> (2010)) the BRB(boundary=simpleCoastLine) option fails.  As such, I am
> inclined to resort to the raster exclusion approach, whereby a
> pre-constructed raster with cell values assigned to 1 (habitat) or 0
> (non-habitat) is multiplied against each utilization distribution, all built
> on the same raster grid.
>
> Under the predecessor package, adehabitat, I would multiply each estimated
> utilization distribution (class asc) by a raster (also of class asc, read in
> using the rgdal readGDAL() function).
>
> Please advise on  how to multiply out the non-habitat from the estUDm class
> object and how to normalize total volume back to 1.
>
> Also, please advise on how to summarize utilization distributions across
> walruses (in each estUDm object) to derive a single generalized utilization
> distribution for each month.

Sorry for the late reply. Actually, it is now easier to perform such 
operations, as the package sp provides useful functions for such 
calculations. The code below gives you an example (just copy and paste 
in R):

## Load the data
library(adehabitatHR)
data(puechabonsp)

## Store the relocations
loc <- puechabonsp$relocs

## and the map
elev <- puechabonsp$map

## have a look at the data
head(as.data.frame(loc))
## the first column of this data frame is the ID

## Look at the map
image(elev)

## Now we build a "fake" habitat map (1 = habitat and 0 = non habitat) 
from the elevation map
fullgrid(elev) <- TRUE
hab <- elev
hab[[1]] <- as.numeric(!is.na(hab[[1]]))

## show this habitat map (yellow is habitat)
image(hab)

## Estimation of UD for the four animals, using
## the map hab as the grid
ud <- kernelUD(loc[,1], grid=hab)

## ud is an object of the class estUDm
## Convert it to SpatialPixelsDataFrame:
udspdf <- estUDm2spixdf(ud)

## udspdf is an object of class SpatialPixelsDataFrame
## have a look
mimage(udspdf)

## Convert the original map to fullgrid (i.e. SpatialGridDataFrame)
fullgrid(udspdf) <- TRUE

## and the same for the original habitat map (here, it is not needed,
## as the map hab is already fullgrid, but it might be required on you data)
fullgrid(hab)<-TRUE

## The two maps have the same dimensions:
## > length(udspdf[[1]])
## [1] 6636
## > length(hab[[1]])
## [1] 6636


## Then, you just have to multiply each column of udspdf by the habitat 
variable:
resu <- lapply(1:ncol(udspdf), function(i) {
     udspdf[[i]] * hab[[1]] / sum(udspdf[[i]] * hab[[1]])
})
resu <- as.data.frame(resu)
names(resu) <- names(udspdf at data)

## and define it as data slot for udspdf
udspdf at data <- resu

## Have a look at the data (after conversion to SpatialPixelsDataFrame):
fullgrid(udspdf) <- FALSE
mimage(udspdf)

## Note that Brock and Calou, the UD have sharp limits

HTH,


Cl?ment Calenge

-- 
Cl?ment CALENGE
Cellule d'appui ? l'analyse de donn?es
Direction des Etudes et de la Recherche
Office national de la chasse et de la faune sauvage
Saint Benoist - 78610 Auffargis
tel. (33) 01.30.46.54.14


From tom.gottfried at tum.de  Wed Jun 29 10:37:03 2011
From: tom.gottfried at tum.de (Tom Gottfried)
Date: Wed, 29 Jun 2011 10:37:03 +0200
Subject: [R-sig-Geo] colocated cokriging with empty neighbourhood causes
 crash
In-Reply-To: <4E078E87.1090509@uni-muenster.de>
References: <4E04AC2D.1020305@tum.de> <4E078E87.1090509@uni-muenster.de>
Message-ID: <4E0AE42F.6040808@tum.de>

Wow! Thanks for the quick reaction.
Tom

Am 26.06.2011 21:54, schrieb Edzer Pebesma:
> Well spotted! I submitted an updated gstat version (0.9-82) that fixes
> this bug to CRAN.
>
> Best regards,
>
> On 06/24/2011 05:24 PM, Tom Gottfried wrote:
>> Dear list,
>>
>> while doing local colocated cokriging it seems that, if some points to
>> be predicted have no value of the primary variable in the neighbourhood,
>> this causes R to crash with the messages shown below (script with
>> modified code from ASDAR book to generate the crash attached).
>> Should it be expected that NA is predicted at the respective points (as
>> I understood, this is what ordinary kriging and cokriging do when the
>> neighbourhood is empty)?
>>
>> regards,
>> Tom
>>
>> Output at crash-time:
>>
>> Intrinsic Correlation found. Good.
>> [using ordinary cokriging]
>>
>>   *** caught segfault ***
>> address 0x50, cause 'memory not mapped'
>>
>> Traceback:
>>   1: .Call("gstat_predict", as.integer(nrow(as.matrix(new.X))),
>> as.double(as.vector(raw$locations)),     as.vector(new.X),
>> as.integer(block.cols), as.vector(block),     as.vector(bl_weights),
>> as.integer(nsim), as.integer(BLUE))
>>   2: predict.gstat(g.cc, meuse.grid)
>>   3: predict(g.cc, meuse.grid)
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>> Selection:
>>
>>
>>
>> _______________________________________________
>> R-sig-Geo mailing list
>> R-sig-Geo at r-project.org
>> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Technische Universit?t M?nchen
Department f?r Pflanzenwissenschaften
Lehrstuhl f?r Gr?nlandlehre
Alte Akademie 12
85350 Freising / Germany
Phone: ++49 (0)8161 715324
Fax:   ++49 (0)8161 713243
email: tom.gottfried at wzw.tum.de
http://www.wzw.tum.de/gruenland


From r.m.krug at gmail.com  Wed Jun 29 13:25:53 2011
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Wed, 29 Jun 2011 13:25:53 +0200
Subject: [R-sig-Geo] Identifying
Message-ID: <BANLkTimdYryxYStrx+ut0zK+-MVxYZ80h8URPXv1C1JM3JP=Pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20110629/f52d70dd/attachment.pl>

From gscumming at googlemail.com  Wed Jun 29 13:41:28 2011
From: gscumming at googlemail.com (Graeme Cumming)
Date: Wed, 29 Jun 2011 13:41:28 +0200
Subject: [R-sig-Geo] Calculating lengths of shared edges for neighbouring
	polygons (in R, without resorting to GRASS)
Message-ID: <3AED52E9-E2C5-4056-AAA8-E7BB8CFE3034@gmail.com>

Dear all,

I am trying to calculate lengths of shared edge for neighbouring  
polygons in a shapefile. I have most of the code working, I think, but  
I don't get the right answer (estimated edge lengths are too long by  
about half as much again). I'd be grateful if someone can help me  
figure out where I'm going wrong.

To offer some background: My underlying motive is to generate a  
boundary length file for use with the UQ MARXAN conservation planning  
software. I have found a number of related queries on this list and as  
best I can tell, the only viable solution to this problem so far  
proposed has been to go via GRASS. I am teaching my students  
conservation planning in ArcGIS, however, and I don't want them to  
have to grapple with other GIS packages just yet (and yes, I am aware  
of the various other alternatives for boundary file creation - most of  
them don't work in ArcGIS 9.3 or 10, ArcView won't run in Windows 7,  
and Zonae Cogito represents too niche-oriented a step away from  
classical GIS for my class).

Each row in the output file needs to contain IDs of polygons 1 and 2,  
which are neighbours, followed by the length of shared boundary. The  
input shapefie is currently a vector grid of squares generated in  
ArcGIS using fishnet or Hawth's tools. The grid is clipped by the  
boundary of the western cape, so there is a set of irregular edge  
cells, but central cells are square. I am testing this with a data set  
in Albers Equal area projection and a cell side length of 10,000m. I  
should also add that I am working on a Mac, so rgeos is not currently  
available.

The neighbour list element of the problem seems to be working fine. I  
have coded it using poly2nb as follows:

library(spdep)
library(gpclib)
library(sp)
library(PBSmapping)

#call shapefile and plot it to check that it is functional
wcape <-readShapePoly("WCapeGrid1_Clip"); #then define the projection
proj4string(wcape)<-CRS("+proj=aea +datum=WGS84 +units=m");
plot(wcape);#check that the map looks OK

nbs<-poly2nb(wcape, queen=FALSE); #we want shared edges, not just  
vertices
#use 'summary(nbs)' to summarize contents of nbs

wcapenlist<-nb2listw(nbs,style='B');
#use 'names(wcapenlist)' to view variables in the data structure

nbs2<-wcapenlist$neighbours #extracts neighbour data from object

#then we do some fiddling around to get the data in more workable  
format:
nbs3 <- nb2listw(nbs2, style="B") #generate a list
nbs4 <- as(as_dgRMatrix_listw(nbs3), "CsparseMatrix") #coerce it into  
an nrowsxnrows sparse matrix
nbs5<-which(nbs4!=0,arr.ind=T)#find and make a list of row, col IDs of  
nonzero entries

nrows <- nrow(nbs5); #find how long the matrix is
duplicates <- matrix(data=0,nrow=nrows); #create and add a colum to  
mark duplicates
nbs6<-cbind(nbs5,duplicates);

#loop through the matrix to find complementary pairs (a,b and b,a) and  
mark them with '1'
for (j in 1:nrows) {
	for (k in j:nrows) {
		if (j!=k && nbs6[j,1]==nbs5[k,2] && nbs6[j,2]==nbs6[k,1])
			nbs6[k,3]<- 1;
	}
}

#create a new matrix that contains only unique pairs
#this step can probably be done more efficiently
nuniquerows <- nrows-sum(nbs6[,3]);
nbs7 <- matrix(data=0,nrow=nuniquerows,ncol=2);
ticker<-0;
for (j in 1:nrows){
	if(nbs6[j,3]==0){
		ticker<-ticker+1;
		nbs7[ticker,1]=nbs6[j,1];
		nbs7[ticker,2]=nbs6[j,2];
	}
}

OK. The problem comes somewhere in the next set of steps:

#we now have a list of all neighbour IDs. The next step is to  
calculate shared boundary lengths.
#we do this by (1) picking pairs to compare; (2) unioning pairs of  
polygons, which effectively removes the shared boundary; and then (3)  
subtracting the perimeter of the union from the summed perimeters of  
the two individual polygons.
###############################################################################################

nbscommon<- matrix(data=0,nrow=nuniquerows,ncol=1) #create a vector to  
hold the lengths of common (shared) edges

for (j in 1:nuniquerows){
	poly1=wcape[nbs7[j,1],];#extract first polygon
	poly2=wcape[nbs7[j,2],];#extract its neighbour
	poly1PBS <- combinePolys(SpatialPolygons2PolySet(poly1)); #convert to  
PBS mapping format
	poly2PBS <- combinePolys(SpatialPolygons2PolySet(poly2));
	union.p1p2 <- combinePolys(joinPolys(poly1PBS, poly2PBS,"UNION",  
maxVert = 1000));
	#plotPolys(union.p1p2); addPolys(poly1PBS); #check that the union  
looks OK
	lengthp1 <- calcLength(poly1PBS); #calculate perimeter of poly1
		lengthp1 <- sum(lengthp1$length); #use 'sum' because edges sometimes  
lead to split polys
	lengthp2 <- calcLength(poly2PBS); #calculate perimeter of poly2
		lengthp2 <- sum(lengthp2$length);
	lengthunion <- calcLength(union.p1p2); #calculate perimeter of union  
of poly1 and poly2
		lunion <- sum(lengthunion$length);
	nbscommon[j] <- (lengthp1+lengthp2-lunion)/2; #shared/common perim is  
half the difference between union and sum of individual polys
}

boundarymat <- cbind(nbs7,nbscommon);

save (boundarymat,file="boundary.txt",ascii=TRUE);
#export boundarymat to text file and we're done.

So far so good, I would have thought. But the problem is that my  
square cells have side length 10km, and these cells are assigned a  
side length of 15km by my algorithm. What aren't I seeing? Does  
'combinePolys' double up on lines? I have a similar algorithm working  
fine in Matlab, main problem being that my students don't have access  
to the necessary toolboxes and so can't run it for themselves.

Thanks for your help!

Graeme Cumming
Prof. Graeme S. Cumming
Percy FitzPatrick Institute
University of Cape Town
Tel. +27-21-650-3439
http://www.fitzpatrick.uct.ac.za/gcumming/index.htm


From e.o.folmer at gmail.com  Wed Jun 29 13:58:03 2011
From: e.o.folmer at gmail.com (Eelke Folmer)
Date: Wed, 29 Jun 2011 13:58:03 +0200
Subject: [R-sig-Geo] Calculate the surface of polygons within gridcells with
	gIntersection
Message-ID: <4E0B134B.8060002@gmail.com>

Hi all,

I have a polygon shapefile with a column in the attribute table denoting 
class (in my case "habitat"). I construct a gridded 
SpatialPolygonsDataFrame. For each gridcell I'd like to be able to 
obtain the surface of each of the classes from the polygon shapefile 
resulting in something like this:

cell	classA	classB	classC
1	10	25	31
2	53	23	0
3	13	25	..
4	..	..	..	

I tried by means of gIntersection (rgeos) to make a new geometry but I 
run into difficulties (see below for a reproducable example). If I were 
to obtain a new geometry I would probably be able to match the grid with 
the area (perhaps looping through the classes?).
I'd suspect that this is a relatively common operation and I wonder if 
there is a more direct way (within R).

Example:
require(raster)
require(rgeos)

ext = extent(c(0, 10, 0, 10))
grd     <- raster(ext, nrows=10, ncols=10, crs=NA )
grd.pol <- rasterToPolygons(grd, fun=NULL, n=4, na.rm=TRUE, digits=12)

grd2     <- raster(ext-1.5, nrows=5, ncols=5, crs=NA )
grd.pol2 <- rasterToPolygons(grd2, fun=NULL, n=4, na.rm=TRUE, digits=12)

plot(grd.pol)
plot(grd.pol2, add=T, lty=2)

int <- gIntersection(grd.pol2, grd.pol, byid=T)

Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, 
"rgeos_intersection") : Geometry collections may not contain other 
geometry collections


I have tried with various other geometries (polygon shapefiles) and run 
into the same problem. I have also searched the the mailing list for a 
hint how to carry on but with no luck.

Thanks for a powerful library anyway!

Eelke


From Roger.Bivand at nhh.no  Wed Jun 29 15:01:50 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 29 Jun 2011 15:01:50 +0200 (CEST)
Subject: [R-sig-Geo] Calculating lengths of shared edges for
 neighbouring polygons (in R, without resorting to GRASS)
In-Reply-To: <3AED52E9-E2C5-4056-AAA8-E7BB8CFE3034@gmail.com>
References: <3AED52E9-E2C5-4056-AAA8-E7BB8CFE3034@gmail.com>
Message-ID: <alpine.LRH.2.00.1106291451160.9191@reclus.nhh.no>

On Wed, 29 Jun 2011, Graeme Cumming wrote:

> Dear all,
>
> I am trying to calculate lengths of shared edge for neighbouring polygons in 
> a shapefile. I have most of the code working, I think, but I don't get the 
> right answer (estimated edge lengths are too long by about half as much 
> again). I'd be grateful if someone can help me figure out where I'm going 
> wrong.
>
> To offer some background: My underlying motive is to generate a boundary 
> length file for use with the UQ MARXAN conservation planning software. I have 
> found a number of related queries on this list and as best I can tell, the 
> only viable solution to this problem so far proposed has been to go via 
> GRASS. I am teaching my students conservation planning in ArcGIS, however, 
> and I don't want them to have to grapple with other GIS packages just yet 
> (and yes, I am aware of the various other alternatives for boundary file 
> creation - most of them don't work in ArcGIS 9.3 or 10, ArcView won't run in 
> Windows 7, and Zonae Cogito represents too niche-oriented a step away from 
> classical GIS for my class).
>
> Each row in the output file needs to contain IDs of polygons 1 and 2, which 
> are neighbours, followed by the length of shared boundary. The input shapefie 
> is currently a vector grid of squares generated in ArcGIS using fishnet or 
> Hawth's tools. The grid is clipped by the boundary of the western cape, so 
> there is a set of irregular edge cells, but central cells are square. I am 
> testing this with a data set in Albers Equal area projection and a cell side 
> length of 10,000m. I should also add that I am working on a Mac, so rgeos is 
> not currently available.
>
> The neighbour list element of the problem seems to be working fine. I have 
> coded it using poly2nb as follows:


Could I suggest using ArcGIS - convert the vector feature class to a 
vector coverage, then use the AVCBin driver in rgdal to read the PAL and 
ARC versions? Refer to:

http://www.asdar-book.org/exercises.php?excode=3

from ASDAR, download http://www.asdar-book.org/bundles/nb_ARC.zip, unzip, 
then srarting R in Arc/:

library(rgdal)
sy <- readOGR(dsn="syr_cov1", layer="PAL", drop_unsupported_fields=TRUE)
sy_arc <- readOGR(dsn="syr_cov1", layer="ARC",
   drop_unsupported_fields=TRUE)
sy_arc$length <- SpatialLinesLengths(sy_arc)
summary(sy_arc)

gives the boundary lengths by right and left neighbour. You may need to 
look at and modify coverage2nb.R to see how to get the correct FID values 
- the function as it is only outputs neighbours. Note that *POLY_ 1 is the 
excluded background. This may be simpler than trying to get the lengths in 
R. The alternative is to use GRASS, as in the previous additional material 
entry on the book website.

Hope this helps,

Roger



>
> library(spdep)
> library(gpclib)
> library(sp)
> library(PBSmapping)
>
> #call shapefile and plot it to check that it is functional
> wcape <-readShapePoly("WCapeGrid1_Clip"); #then define the projection
> proj4string(wcape)<-CRS("+proj=aea +datum=WGS84 +units=m");
> plot(wcape);#check that the map looks OK
>
> nbs<-poly2nb(wcape, queen=FALSE); #we want shared edges, not just vertices
> #use 'summary(nbs)' to summarize contents of nbs
>
> wcapenlist<-nb2listw(nbs,style='B');
> #use 'names(wcapenlist)' to view variables in the data structure
>
> nbs2<-wcapenlist$neighbours #extracts neighbour data from object
>
> #then we do some fiddling around to get the data in more workable format:
> nbs3 <- nb2listw(nbs2, style="B") #generate a list
> nbs4 <- as(as_dgRMatrix_listw(nbs3), "CsparseMatrix") #coerce it into an 
> nrowsxnrows sparse matrix
> nbs5<-which(nbs4!=0,arr.ind=T)#find and make a list of row, col IDs of 
> nonzero entries
>
> nrows <- nrow(nbs5); #find how long the matrix is
> duplicates <- matrix(data=0,nrow=nrows); #create and add a colum to mark 
> duplicates
> nbs6<-cbind(nbs5,duplicates);
>
> #loop through the matrix to find complementary pairs (a,b and b,a) and mark 
> them with '1'
> for (j in 1:nrows) {
> 	for (k in j:nrows) {
> 		if (j!=k && nbs6[j,1]==nbs5[k,2] && nbs6[j,2]==nbs6[k,1])
> 			nbs6[k,3]<- 1;
> 	}
> }
>
> #create a new matrix that contains only unique pairs
> #this step can probably be done more efficiently
> nuniquerows <- nrows-sum(nbs6[,3]);
> nbs7 <- matrix(data=0,nrow=nuniquerows,ncol=2);
> ticker<-0;
> for (j in 1:nrows){
> 	if(nbs6[j,3]==0){
> 		ticker<-ticker+1;
> 		nbs7[ticker,1]=nbs6[j,1];
> 		nbs7[ticker,2]=nbs6[j,2];
> 	}
> }
>
> OK. The problem comes somewhere in the next set of steps:
>
> #we now have a list of all neighbour IDs. The next step is to calculate 
> shared boundary lengths.
> #we do this by (1) picking pairs to compare; (2) unioning pairs of polygons, 
> which effectively removes the shared boundary; and then (3) subtracting the 
> perimeter of the union from the summed perimeters of the two individual 
> polygons.
> ###############################################################################################
>
> nbscommon<- matrix(data=0,nrow=nuniquerows,ncol=1) #create a vector to hold 
> the lengths of common (shared) edges
>
> for (j in 1:nuniquerows){
> 	poly1=wcape[nbs7[j,1],];#extract first polygon
> 	poly2=wcape[nbs7[j,2],];#extract its neighbour
> 	poly1PBS <- combinePolys(SpatialPolygons2PolySet(poly1)); #convert to 
> PBS mapping format
> 	poly2PBS <- combinePolys(SpatialPolygons2PolySet(poly2));
> 	union.p1p2 <- combinePolys(joinPolys(poly1PBS, poly2PBS,"UNION", 
> maxVert = 1000));
> 	#plotPolys(union.p1p2); addPolys(poly1PBS); #check that the union 
> looks OK
> 	lengthp1 <- calcLength(poly1PBS); #calculate perimeter of poly1
> 		lengthp1 <- sum(lengthp1$length); #use 'sum' because edges 
> sometimes lead to split polys
> 	lengthp2 <- calcLength(poly2PBS); #calculate perimeter of poly2
> 		lengthp2 <- sum(lengthp2$length);
> 	lengthunion <- calcLength(union.p1p2); #calculate perimeter of union 
> of poly1 and poly2
> 		lunion <- sum(lengthunion$length);
> 	nbscommon[j] <- (lengthp1+lengthp2-lunion)/2; #shared/common perim is 
> half the difference between union and sum of individual polys
> }
>
> boundarymat <- cbind(nbs7,nbscommon);
>
> save (boundarymat,file="boundary.txt",ascii=TRUE);
> #export boundarymat to text file and we're done.
>
> So far so good, I would have thought. But the problem is that my square cells 
> have side length 10km, and these cells are assigned a side length of 15km by 
> my algorithm. What aren't I seeing? Does 'combinePolys' double up on lines? I 
> have a similar algorithm working fine in Matlab, main problem being that my 
> students don't have access to the necessary toolboxes and so can't run it for 
> themselves.
>
> Thanks for your help!
>
> Graeme Cumming
> Prof. Graeme S. Cumming
> Percy FitzPatrick Institute
> University of Cape Town
> Tel. +27-21-650-3439
> http://www.fitzpatrick.uct.ac.za/gcumming/index.htm
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo

-- 
Roger Bivand
Department of Economics, NHH Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Wed Jun 29 15:43:37 2011
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 29 Jun 2011 15:43:37 +0200 (CEST)
Subject: [R-sig-Geo] Calculate the surface of polygons within gridcells
 with gIntersection
In-Reply-To: <4E0B134B.8060002@gmail.com>
References: <4E0B134B.8060002@gmail.com>
Message-ID: <alpine.LRH.2.00.1106291537090.9191@reclus.nhh.no>

On Wed, 29 Jun 2011, Eelke Folmer wrote:

> Hi all,
>
> I have a polygon shapefile with a column in the attribute table denoting 
> class (in my case "habitat"). I construct a gridded SpatialPolygonsDataFrame. 
> For each gridcell I'd like to be able to obtain the surface of each of the 
> classes from the polygon shapefile resulting in something like this:
>
> cell	classA	classB	classC
> 1	10	25	31
> 2	53	23	0
> 3	13	25	..
> 4	..	..	.. 
>
> I tried by means of gIntersection (rgeos) to make a new geometry but I run 
> into difficulties (see below for a reproducable example). If I were to obtain 
> a new geometry I would probably be able to match the grid with the area 
> (perhaps looping through the classes?).
> I'd suspect that this is a relatively common operation and I wonder if there 
> is a more direct way (within R).
>
> Example:
> require(raster)
> require(rgeos)
>
> ext = extent(c(0, 10, 0, 10))
> grd     <- raster(ext, nrows=10, ncols=10, crs=NA )
> grd.pol <- rasterToPolygons(grd, fun=NULL, n=4, na.rm=TRUE, digits=12)
>
> grd2     <- raster(ext-1.5, nrows=5, ncols=5, crs=NA )
> grd.pol2 <- rasterToPolygons(grd2, fun=NULL, n=4, na.rm=TRUE, digits=12)
>
> plot(grd.pol)
> plot(grd.pol2, add=T, lty=2)
>
> int <- gIntersection(grd.pol2, grd.pol, byid=T)
>
> Error in RGEOSBinTopoFunc(spgeom1, spgeom2, byid, id, "rgeos_intersection") : 
> Geometry collections may not contain other geometry collections


With byid=TRUE, you may end up with rgeos trying to re-assemble things in 
a different way than you intended. With reference to an earlier thread 
this month, if you do:

int <- gIntersects(grd.pol2, grd.pol, byid=TRUE)
vec <- vector(mode="list", length=dim(int)[2])
for (i in seq(along=vec)) vec[[i]] <- try(gIntersection(grd.pol2[i,], 
grd.pol[int[,i],], byid=TRUE))
out <- do.call("rbind", vec)
rn <- row.names(out)
nrn <- do.call("rbind", strsplit(rn, " "))
df <- data.frame(pol2=nrn[,1], pol=nrn[,2], area=sapply(slot(out,
   "polygons"), slot, "area"))
plot(grd.pol, border="red")
plot(grd.pol2, border="green", add=TRUE)
plot(out, col="#00FFFF64", add=TRUE, border="transparent")
text(coordinates(grd.pol), labels=row.names(grd.pol), cex=0.5)
head(df)

you can see that you are now getting a Polygons object for each 
intersection, which you should be able to tally.

Using a predicate first (and it is also possible to use STRtrees) also 
saves time, but we wanted to get the standard facilities of rgeos working 
before optimising, so the optimisation should be done by hand.

Hope this helps,

Roger

>
>
> I have tried with various other geometries (polygon shapefiles) and run into 
> the same problem. I have also searched the the mailing list for a hint how to 
> carry on but with no luck.
>
> Thanks for a powerful library anyway!
>
> Eelke
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>

-- 
Roger Bivand
Department of Economics, NHH Norwegian School of Economics,
Helleveien 30, N-5045 Bergen, Norway.
voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no


From colinr23 at gmail.com  Wed Jun 29 17:50:18 2011
From: colinr23 at gmail.com (Colin Robertson)
Date: Wed, 29 Jun 2011 11:50:18 -0400
Subject: [R-sig-Geo] raster package display
Message-ID: <BANLkTim5Ys-yhu0rqvJMgrehMQ_PrZh82A@mail.gmail.com>

Dear List,

I am creating a raster as the output of a function, and for testing
purposes the output of this function should be a raster with all 1's.

When I check with summary, this is the case:

class(out[[2]])
[1] "RasterLayer"
attr(,"package")
[1] "raster"

summary(out[[2]])
Cells:  1600
NAs  :  304

Min.      1
1st Qu.   1
Median    1
Mean      1
3rd Qu.   1
Max.      1
NA's    304

Yet when I plot using plot(out[[2]]), I get a display of values
ranging from 0.6 - 1.4.

All summaries on the raster indicates all cells have value of 1, but
the display shows differently.

Any ideas on what is happening here much appreciated,

Thanks -

Colin


From b.rowlingson at lancaster.ac.uk  Wed Jun 29 18:13:23 2011
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 29 Jun 2011 17:13:23 +0100
Subject: [R-sig-Geo] raster package display
In-Reply-To: <BANLkTim5Ys-yhu0rqvJMgrehMQ_PrZh82A@mail.gmail.com>
References: <BANLkTim5Ys-yhu0rqvJMgrehMQ_PrZh82A@mail.gmail.com>
Message-ID: <BANLkTik=GycN11h-H+gdqbpim0SBsg+b=w@mail.gmail.com>

On Wed, Jun 29, 2011 at 4:50 PM, Colin Robertson <colinr23 at gmail.com> wrote:
> Dear List,
>
> I am creating a raster as the output of a function, and for testing
> purposes the output of this function should be a raster with all 1's.
>
> When I check with summary, this is the case:
>
> class(out[[2]])
> [1] "RasterLayer"
> attr(,"package")
> [1] "raster"
>
> summary(out[[2]])
> Cells: ?1600
> NAs ?: ?304
>
> Min. ? ? ?1
> 1st Qu. ? 1
> Median ? ?1
> Mean ? ? ?1
> 3rd Qu. ? 1
> Max. ? ? ?1
> NA's ? ?304
>
> Yet when I plot using plot(out[[2]]), I get a display of values
> ranging from 0.6 - 1.4.
>
> All summaries on the raster indicates all cells have value of 1, but
> the display shows differently.
>
> Any ideas on what is happening here much appreciated,

 I suspect - and a quick look at the code will confirm it - that it
just decides to expand the key a bit because your values are all 1.

 The image.plot function in the fields package does the same thing for
a matrix of all the same values.

 In a way it's not lying, because its showing you all the cells with
value 1 are the same colour. It's just not showing you that there are
no cells with any other colour. I guess a scale with 1 at the top,
middle, and bottom would look odd.

 If you add a zlim parameter you can get something that may be a bit
more meaningful:

 m=raster(matrix(1,10,10))
 plot(m)
 plot(m,zlim=c(0.99,1.01))

 - the colour ramp then shows you there's nothing at 1.010, since
there's nothing green on the plot...

Barry


From colinr23 at gmail.com  Wed Jun 29 18:21:11 2011
From: colinr23 at gmail.com (Colin Robertson)
Date: Wed, 29 Jun 2011 12:21:11 -0400
Subject: [R-sig-Geo] raster package display
In-Reply-To: <BANLkTik=GycN11h-H+gdqbpim0SBsg+b=w@mail.gmail.com>
References: <BANLkTim5Ys-yhu0rqvJMgrehMQ_PrZh82A@mail.gmail.com>
	<BANLkTik=GycN11h-H+gdqbpim0SBsg+b=w@mail.gmail.com>
Message-ID: <BANLkTimyoNgMpsAef5bM_XoYnykVQ2MtMg@mail.gmail.com>

Thanks Barry, that was it.

Colin

On Wed, Jun 29, 2011 at 12:13 PM, Barry Rowlingson
<b.rowlingson at lancaster.ac.uk> wrote:
> On Wed, Jun 29, 2011 at 4:50 PM, Colin Robertson <colinr23 at gmail.com> wrote:
>> Dear List,
>>
>> I am creating a raster as the output of a function, and for testing
>> purposes the output of this function should be a raster with all 1's.
>>
>> When I check with summary, this is the case:
>>
>> class(out[[2]])
>> [1] "RasterLayer"
>> attr(,"package")
>> [1] "raster"
>>
>> summary(out[[2]])
>> Cells: ?1600
>> NAs ?: ?304
>>
>> Min. ? ? ?1
>> 1st Qu. ? 1
>> Median ? ?1
>> Mean ? ? ?1
>> 3rd Qu. ? 1
>> Max. ? ? ?1
>> NA's ? ?304
>>
>> Yet when I plot using plot(out[[2]]), I get a display of values
>> ranging from 0.6 - 1.4.
>>
>> All summaries on the raster indicates all cells have value of 1, but
>> the display shows differently.
>>
>> Any ideas on what is happening here much appreciated,
>
> ?I suspect - and a quick look at the code will confirm it - that it
> just decides to expand the key a bit because your values are all 1.
>
> ?The image.plot function in the fields package does the same thing for
> a matrix of all the same values.
>
> ?In a way it's not lying, because its showing you all the cells with
> value 1 are the same colour. It's just not showing you that there are
> no cells with any other colour. I guess a scale with 1 at the top,
> middle, and bottom would look odd.
>
> ?If you add a zlim parameter you can get something that may be a bit
> more meaningful:
>
> ?m=raster(matrix(1,10,10))
> ?plot(m)
> ?plot(m,zlim=c(0.99,1.01))
>
> ?- the colour ramp then shows you there's nothing at 1.010, since
> there's nothing green on the plot...
>
> Barry
>


From lestes at princeton.edu  Wed Jun 29 18:28:34 2011
From: lestes at princeton.edu (Lyndon Estes)
Date: Wed, 29 Jun 2011 12:28:34 -0400
Subject: [R-sig-Geo] raster package display
In-Reply-To: <BANLkTim5Ys-yhu0rqvJMgrehMQ_PrZh82A@mail.gmail.com>
References: <BANLkTim5Ys-yhu0rqvJMgrehMQ_PrZh82A@mail.gmail.com>
Message-ID: <BANLkTik4ejEOoVzgDCyiAXDpjFvv7Z7vDw@mail.gmail.com>

Hi Colin,

How many colors are actually displayed?  I find that the legend/scale
bar often shows a range of values, even though there is only one value
in the raster.

For instance if I do this:

dummy <- raster(extent(-100, 100, -200, 200))
dummy[] <- 1
plot(dummy)

I have the same values as you in the scale bar, but there is only one
color (yellow), which corresponds to value 1.

I suppose one could make a custom legend to display just a single
value, but I usually just ignore this.

Hope this helps.

Cheers, Lyndon

On Wed, Jun 29, 2011 at 11:50 AM, Colin Robertson <colinr23 at gmail.com> wrote:
> Dear List,
>
> I am creating a raster as the output of a function, and for testing
> purposes the output of this function should be a raster with all 1's.
>
> When I check with summary, this is the case:
>
> class(out[[2]])
> [1] "RasterLayer"
> attr(,"package")
> [1] "raster"
>
> summary(out[[2]])
> Cells: ?1600
> NAs ?: ?304
>
> Min. ? ? ?1
> 1st Qu. ? 1
> Median ? ?1
> Mean ? ? ?1
> 3rd Qu. ? 1
> Max. ? ? ?1
> NA's ? ?304
>
> Yet when I plot using plot(out[[2]]), I get a display of values
> ranging from 0.6 - 1.4.
>
> All summaries on the raster indicates all cells have value of 1, but
> the display shows differently.
>
> Any ideas on what is happening here much appreciated,
>
> Thanks -
>
> Colin
>
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at r-project.org
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>


From zutal at yahoo.es  Thu Jun 30 10:22:53 2011
From: zutal at yahoo.es (Zulima Tablado Almela)
Date: Thu, 30 Jun 2011 10:22:53 +0200
Subject: [R-sig-Geo] Measure the distance/home range along terrain surface
In-Reply-To: <4E0B4AC9.8000008@yahoo.es>
References: <4E0B4AC9.8000008@yahoo.es>
Message-ID: <4E0C325D.2070501@yahoo.es>

Hello all,

I have two questions:

1)Given two coordinates on a digital elevation model (DEM), I would like 
to measure the actual distance traveled between the two locations, 
assuming a straight line route. Does anyone know the function(if there 
exists) to do that in R?

2)How can I calculate or correct the home range size taking into account 
the variations in elevation (DEM) within it?

Thank you so much in advance, any suggestion will be very much appreciated,

Zulima


