From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep  1 01:51:09 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 31 Aug 2021 16:51:09 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>
Message-ID: <7013D663-1266-4422-A405-537DA425F676@dcn.davis.ca.us>

Never use stringsAsFactors on uncleaned data. For one thing you give a factor to as.Date and it tries to make sense of the integer representation, not the character representation.

library(dplyr)
dta <- read.csv( text =
"sampdate,samptime,cfs
2020-08-26,09:30,136000
2020-08-26,09:35,126000
2020-08-26,09:40,130000
2020-08-26,09:45,128000
2020-08-26,09:50,126000
2020-08-26,09:55,125000
2020-08-26,10:00,121000
2020-08-26,10:05,117000
2020-08-26,10:10,120000
", stringsAsFactors = FALSE)
dtad <- (   dta
        %>% group_by( sampdate )
        %>% summarise( exp_value = mean(cfs, na.rm = TRUE)
                     , Count = n()
                     )
        )

On August 31, 2021 2:11:05 PM PDT, Rich Shepard <rshepard at appl-ecosys.com> wrote:
>On Sun, 29 Aug 2021, Jeff Newmiller wrote:
>
>> The general idea is to create a "grouping" column with repeated values for
>> each day, and then to use aggregate to compute your combined results. The
>> dplyr package's group_by/summarise functions can also do this, and there
>> are also proponents of the data.table package which is high performance
>> but tends to depend on altering data in-place unlike most other R data
>> handling functions.
>
>Jeff,
>
>I've read a number of docs discussing dplyr's summerize and group_by
>functions (including that section of Hadley's 'R for Data Science' book, yet
>I'm missing something; I think that I need to separate the single sampdate
>column into colums for year, month, and day and group_by year/month
>summarizing within those groups.
>
>The data are of this format:
>sampdate,samptime,cfs
>2020-08-26,09:30,136000
>2020-08-26,09:35,126000
>2020-08-26,09:40,130000
>2020-08-26,09:45,128000
>2020-08-26,09:50,126000
>2020-08-26,09:55,125000
>2020-08-26,10:00,121000
>2020-08-26,10:05,117000
>2020-08-26,10:10,120000
>
>My curent script is:
>
>-------8<--------------
>library('tidyverse')
>
>discharge <- read.table('../data/discharge.dat', header = TRUE, sep = ',', stringsAsFactors = TRUE)
>discharge$sampdate <- as.Date(discharge$sampdate)
>discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>
># use dplyr.summarize grouped by date
>
># need to separate sampdate into %Y-%M-%D in order to group_by the month?
>by_month <- discharge %>%
>   group_by(sampdate ...
>summarize(by_month, exp_value = mean(cfs, na.rm = TRUE), sd(cfs))
>---------------->8--------
>
>and the results are:
>
>> str(discharge)
>'data.frame':	93254 obs. of  3 variables:
>  $ sampdate: Date, format: "2020-08-26" "2020-08-26" ...
>  $ samptime: Factor w/ 728 levels "00:00","00:05",..: 115 116 117 118 123 128 133 138 143 148 ...
>  $ cfs     : num  176 156 165 161 156 154 144 137 142 142 ...
>> ls()
>[1] "by_month"  "discharge"
>> by_month
># A tibble: 93,254 ? 3
># Groups:   sampdate [322]
>    sampdate   samptime   cfs
>    <date>     <fct>    <dbl>
>  1 2020-08-26 09:30      176
>  2 2020-08-26 09:35      156
>  3 2020-08-26 09:40      165
>  4 2020-08-26 09:45      161
>  5 2020-08-26 09:50      156
>  6 2020-08-26 09:55      154
>  7 2020-08-26 10:00      144
>  8 2020-08-26 10:05      137
>  9 2020-08-26 10:10      142
>10 2020-08-26 10:15      142
># ? with 93,244 more rows
>
>I don't know why the discharge values are truncated to 3 digits when they're
>6 digits in the input data.
>
>Suggested readings appreciated,
>
>Rich
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Sep  1 05:59:04 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 1 Sep 2021 15:59:04 +1200
Subject: [R] What if there's nothing to dispatch on?
Message-ID: <20210901155904.33a8f6e0@rolf-Latitude-E7470>


I'm trying to build a pair of (S3) methods, a "formula" method and a
"default" method.  The methods have a "data" argument.  If the variables
in question cannot be found in "data" then they should be sought in
the global environment.

My problem is that the generic dispatches on its first argument, which
may be a formula (in which case it of course dispatches to the formula
method) or the first of the variables.  If this variable exists in
the global environment then all is well.  But if it doesn't exist there,
then the generic falls over with an error of the form "object 'x' not
found" --- because there isn't anything to dispatch on.

I'd *like* to be able to tell the generic that if "x" is not found then
it should dispatch to the default method (which will, if the call is
sensible, find "x" in "data").

Is there any way to tell the generic to do this?

Or is there any other way out of this dilemma? (Other than "Give up and
go to the pub", which I cannot currently do since Auckland is in Level 4
lockdown. :-) )

Thanks for any enlightenment.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@oknz @end|ng |rom gm@||@com  Wed Sep  1 06:05:30 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Wed, 1 Sep 2021 16:05:30 +1200
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
 <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>
 <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>
Message-ID: <CABcYAdKnPTLfNHjJ9WZvEGWQ07yEE-g4ceeiSM+1sfd1EkkjaA@mail.gmail.com>

I wrote:
> > By the time you get the data from the USGS, you are already far past the point
> > where what the instruments can write is important.
Rich Shepard replied:
> The data are important because they show what's happened in that period of
> record. Don't physicians take a medical history from patients even though
> those data are far past the point they occurred?

You have missed the point.  The issue is not the temporal distance, but the
fact that the data you have are NOT the raw instrumental data and are NOT
subject to the limitations of the recording instruments.  The data you get from
the USGS is not the raw instrumental value, and there is no longer any good
reason for there to be any gaps in it.  Indeed, the Rogue River data I looked
at explicitly includes some flows labelled "Ae" meaning that they are NOT the
instrumental data at all, but estimated.

> And I use emacs to replace the space between columns with commas so the date
> and the time are separate.

There does not seem to be any good reason for this.
As I demonstrated, it is easy to convert these timestamps to
POSIXct form, which is good for calculating with.
If you want to extract year, month, day, &c, by far the easiest
way is to convert to POSIXlt form (so keeping the timestamp as a
single field) and then use $<whatever> to extract the field.
> n <- as.POSIXlt("2003.04.05 06:07", format="%Y.%m.%d %H:%M", tz="UTC")
> n
[1] "2003-04-05 06:07:00 UTC"
> c(n$year+1900, n$mon+1, n$mday, n$hour, $min)
[1] 2003    4    5    6    7

> > The flow is dominated by a series of "bursts" with a fast onset to a peak
> > and a slow decay, coming in a range of sizes from quite small to rather
> > large, separated by gaps of 4 to 45 days.
>
> And when discharge is controlled by flows through a hydroelectric dam there
> is a lot of variability. The pattern is important to fish as well as
> regulators.

And what is important to fish is NOT captured by daily means and standard
deviations.  For what it's worth, my understanding is that most of the dams on
the Rogue River have been removed, leaving only the Lost Creek Lake one,
and that this has been good for the fish.

Suppose you have a day when there are 16 hours with no water at all flowing,
then 8 hours with 12 cumecs because a dam upstream is discharging.  Then
the daily mean is 4 cumecs, which might look good for fish, but it wasn't.
"Number of minutes below minimum safe level" might be more interesting
for the fish.

>From the data we have alone, we cannot tell which bursts are due to
releases from dams and which have other causes.  Dam releases are under
human control, storms are not.

Looking at the Rogue River data, plotting daily means
- lowers the peaks
- moves them right
- changes the overall shape
Not severely, mind you, but enough to avoid if you don't have to.

By the way, by far the easiest way to do day-wise summaries,
if you really feel you must, is to start with a POSIXct or POSIXlt
column, let's call it r$when, then
  d <- trunc(difftime(r$when, min(r$when), units="days)) + 1
  m <- aggregate(r$flow, by=list(d), FUN=mean)
  plot(m, type="l")
You can plug in other summary functions, not just mean.

Remember:
  for all calculations involving dates and times,
  prefer using the built in date and time classes to
  hacking around the problem

  aggregate() is a good way to compute oddball summaries.


> > - how do I *detect* these bursts? (detecting a peak isn't too hard,
> >   but the peak is not the onset)
> > - how do I *characterise* these bursts?
> >   (and is the onset rate related to the peak size?)
> > - what's left after taking the bursts out?
> > - can I relate these bursts to something going on upstream?
>
> Well, those questions could be appropriate depending on what questions you
> need the data to answer.
>
> Environmental data are quite different from experimental, economic,
> financial, and public data (e.g., unemployment, housing costs).
>
> There are always multiple ways to address an analytical need. Thank you for
> your contributions.
>
> Stay well,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Wed Sep  1 07:25:52 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Wed, 01 Sep 2021 07:25:52 +0200
Subject: [R] Converting characters back to Date and Time
In-Reply-To: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 (Eliza Botto's message of "Tue, 31 Aug 2021 20:26:01 +0000")
References: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <87y28g50kf.fsf@enricoschumann.net>

On Tue, 31 Aug 2021, Eliza Botto writes:

> DeaR useR,
>
> I read an excel column in R having Date and time (written in the same cell) as follow,
>
> 06/18/18 10:00
>
> 06/18/18 11:00
>
> 06/18/18 12:00
>
> In R environment, they are read as
>
> 43269.42
>
> 43269.46
>
> 43269.50
>
> Is there a way to covert these characters back to the original format?
>
> Thank-you very much in advance.
>
>
> Eliza Botto
>

If using a package is an option:

  library("datetimeutils")
  convert_date(c(43269.42, 43269.46, 43269.50), "excel")
  ## [1] "2018-06-18" "2018-06-18" "2018-06-18"

  convert_date(c(43269.42, 43269.46, 43269.50), "excel", fraction = TRUE)
  ## [1] "2018-06-18 10:04:48 CEST" "2018-06-18 11:02:24 CEST"
  ## [3] "2018-06-18 12:00:00 CEST"

Note that the times differ: the numbers are probably
not /displayed/ to full precision in R.

You may also want to search the archives of this list,
as this question has been discussed before.


-- 
Enrico Schumann (maintainer of package datetimeutils)
Lucerne, Switzerland
http://enricoschumann.net


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  1 11:35:03 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 1 Sep 2021 05:35:03 -0400
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
Message-ID: <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>

On 31/08/2021 11:59 p.m., Rolf Turner wrote:
> 
> I'm trying to build a pair of (S3) methods, a "formula" method and a
> "default" method.  The methods have a "data" argument.  If the variables
> in question cannot be found in "data" then they should be sought in
> the global environment.
> 
> My problem is that the generic dispatches on its first argument, which
> may be a formula (in which case it of course dispatches to the formula
> method) or the first of the variables.  If this variable exists in
> the global environment then all is well.  But if it doesn't exist there,
> then the generic falls over with an error of the form "object 'x' not
> found" --- because there isn't anything to dispatch on.
> 
> I'd *like* to be able to tell the generic that if "x" is not found then
> it should dispatch to the default method (which will, if the call is
> sensible, find "x" in "data").
> 
> Is there any way to tell the generic to do this?
> 
> Or is there any other way out of this dilemma? (Other than "Give up and
> go to the pub", which I cannot currently do since Auckland is in Level 4
> lockdown. :-) )
> 

That design is probably not a good idea:  what if one of the variables 
in data matches the name of some other object in the global environment? 
  Then it would dispatch on that other object, and things won't go well.

But here's a way to shoot yourself in the foot:

function(x) {
   x1 <- try(x, silent = TRUE)
   if (inherits(x1, "try-error"))
     foo.default(x)
   else
     UseMethod("foo", x)
}

Happy shooting!

Duncan


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep  1 14:27:21 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 1 Sep 2021 12:27:21 +0000
Subject: [R] Converting characters back to Date and Time
In-Reply-To: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099979E9FD39C8A3705261579ACC9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <ca44b3d71ab74492b660c4c8df343d9f@SRVEXCHCM1302.precheza.cz>

Hi

You can use as.POSIXct function
https://stackoverflow.com/questions/19172632/converting-excel-datetime-seria
l-number-to-r-datetime

But you should preferably try to read the date as character vector and then
convert it to date and time.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Eliza Botto
> Sent: Tuesday, August 31, 2021 10:26 PM
> To: r-help at r-project.org
> Subject: [R] Converting characters back to Date and Time
> 
> DeaR useR,
> 
> I read an excel column in R having Date and time (written in the same
cell) as
> follow,
> 
> 06/18/18 10:00
> 
> 06/18/18 11:00
> 
> 06/18/18 12:00
> 
> In R environment, they are read as
> 
> 43269.42
> 
> 43269.46
> 
> 43269.50
> 
> Is there a way to covert these characters back to the original format?
> 
> Thank-you very much in advance.
> 
> 
> Eliza Botto
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  1 15:15:34 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 1 Sep 2021 06:15:34 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdKnPTLfNHjJ9WZvEGWQ07yEE-g4ceeiSM+1sfd1EkkjaA@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2108300538250.15422@salmo.appl-ecosys.com>
 <CABcYAdKHKXZy9yzGcvP3K9=K5bQrVCBX7mN9iCPSqiV=TGJN9w@mail.gmail.com>
 <alpine.LNX.2.20.2108301630260.15422@salmo.appl-ecosys.com>
 <CABcYAdLtdFOR6FJps1cXGTmEEYWZ6ZArn+fnnhyWKEgY0_rYMw@mail.gmail.com>
 <alpine.LNX.2.20.2108310525150.6620@salmo.appl-ecosys.com>
 <CABcYAdKnPTLfNHjJ9WZvEGWQ07yEE-g4ceeiSM+1sfd1EkkjaA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109010615040.29114@salmo.appl-ecosys.com>

On Wed, 1 Sep 2021, Richard O'Keefe wrote:

> You have missed the point. The issue is not the temporal distance, but the
> fact that the data you have are NOT the raw instrumental data and are NOT
> subject to the limitations of the recording instruments. The data you get
> from the USGS is not the raw instrumental value, and there is no longer
> any good reason for there to be any gaps in it. Indeed, the Rogue River
> data I looked at explicitly includes some flows labelled "Ae" meaning that
> they are NOT the instrumental data at all, but estimated.

Richard,

Thanks for your comments.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Sep  1 16:30:44 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 1 Sep 2021 07:30:44 -0700 (PDT)
Subject: [R] 
 Calculate daily means from 5-minute interval data [RESOLVED]
In-Reply-To: <7013D663-1266-4422-A405-537DA425F676@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <0AAD5464-4D4C-497C-87B3-C929842CA237@dcn.davis.ca.us>
 <alpine.LNX.2.20.2108311402330.6620@salmo.appl-ecosys.com>
 <7013D663-1266-4422-A405-537DA425F676@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2109010724410.29114@salmo.appl-ecosys.com>

On Tue, 31 Aug 2021, Jeff Newmiller wrote:

> Never use stringsAsFactors on uncleaned data. For one thing you give a
> factor to as.Date and it tries to make sense of the integer
> representation, not the character representation.

Jeff,

Oops! I had changed it in a previous version of the script and for got to
change it back again. Fixed

> dtad <- (   dta
>        %>% group_by( sampdate )
>        %>% summarise( exp_value = mean(cfs, na.rm = TRUE)
>                     , Count = n()
>                     )
>        )

Thank you. Now I understand how to use dplyr's summarize().

Best regards,

Rich


From c@ghpm m@iii@g oii gm@ii@com  Wed Sep  1 16:34:07 2021
From: c@ghpm m@iii@g oii gm@ii@com (c@ghpm m@iii@g oii gm@ii@com)
Date: Wed, 1 Sep 2021 11:34:07 -0300
Subject: [R] how to install npsm package
Message-ID: <012701d79f3e$79cb6300$6d622900$@gmail.com>

I need to install the package "npsm" to follow Kloke & McKean book. However,
npsm is no longer on CRAN. So, please let me know in detail how to proceed
to install it.

 

Thanks.

 

Carlos Gonzalez


	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Sep  1 17:31:15 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 1 Sep 2021 18:31:15 +0300
Subject: [R] how to install npsm package
In-Reply-To: <012701d79f3e$79cb6300$6d622900$@gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
Message-ID: <CAGgJW76wD-ai58K=QkUrH0yWaG9-6XTR5D8r7J8DuYLL3Pid-g@mail.gmail.com>

Instructions can be found at https://github.com/kloke/npsm


On Wed, Sep 1, 2021 at 6:27 PM <caghpm at gmail.com> wrote:

> I need to install the package "npsm" to follow Kloke & McKean book.
> However,
> npsm is no longer on CRAN. So, please let me know in detail how to proceed
> to install it.
>
>
>
> Thanks.
>
>
>
> Carlos Gonzalez
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Wed Sep  1 17:32:08 2021
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Wed, 1 Sep 2021 11:32:08 -0400
Subject: [R] how to install npsm package
In-Reply-To: <012701d79f3e$79cb6300$6d622900$@gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
Message-ID: <7e1ae8e5-08d7-d704-2d2f-0c9460d88861@loesl.us>

Does  this link help?

> https://rdrr.io/cran/npsm/



---JRG



On 9/1/21 10:34 AM, caghpm at gmail.com wrote:
> I need to install the package "npsm" to follow Kloke & McKean book. However,
> npsm is no longer on CRAN. So, please let me know in detail how to proceed
> to install it.
> 
>  
> 
> Thanks.
> 
>  
> 
> Carlos Gonzalez
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Sep  1 18:06:02 2021
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 1 Sep 2021 09:06:02 -0700
Subject: [R] how to install npsm package
In-Reply-To: <012701d79f3e$79cb6300$6d622900$@gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
Message-ID: <CAA99HCzr_mvpRbT3+3+cP+Q22uRvevhHQcRP8Pq33GoqmfLF6A@mail.gmail.com>

Hi,

I found package "npsm" at the links below:

https://mran.microsoft.com/snapshot/2017-02-04/web/packages/npsm/index.html
https://cran.r-project.org/src/contrib/Archive/npsm/

HTH, Bill.

W. Michels, Ph.D.


On Wed, Sep 1, 2021 at 8:27 AM <caghpm at gmail.com> wrote:
>
> I need to install the package "npsm" to follow Kloke & McKean book. However,
> npsm is no longer on CRAN. So, please let me know in detail how to proceed
> to install it.
>
>
>
> Thanks.
>
>
>
> Carlos Gonzalez
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e||z@_botto @end|ng |rom out|ook@com  Wed Sep  1 22:59:42 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Wed, 1 Sep 2021 20:59:42 +0000
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
Message-ID: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?


Thanks in advance,

Eliza Botto

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Sep  1 23:12:11 2021
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 1 Sep 2021 21:12:11 +0000
Subject: [R] 
 [External] conditional replacement of elements of matrix with
 another matrix column
In-Reply-To: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <07000564-9D6B-4773-B7EE-079ABFBD4C95@temple.edu>

> A
      [,1] [,2]
 [1,]   12   NA
 [2,]   12   NA
 [3,]   12   NA
 [4,]   13   NA
 [5,]   13   NA
 [6,]   13   NA
 [7,]   14   NA
 [8,]   14   NA
 [9,]   14   NA
> B
      [,1] [,2]
 [1,]   11    6
 [2,]   11    7
 [3,]   11    8
 [4,]   13    9
 [5,]   13   10
 [6,]   13   11
 [7,]   14   12
 [8,]   14   13
 [9,]   14   14
> C
      [,1] [,2]
 [1,]   12   NA
 [2,]   12   NA
 [3,]   12   NA
 [4,]   13    9
 [5,]   13   10
 [6,]   13   11
 [7,]   14   12
 [8,]   14   13
 [9,]   14   14
> same <- A[,1] == B[,1]
> same
[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

> A[same,2] <- B[same,2]
> A
      [,1] [,2]
 [1,]   12   NA
 [2,]   12   NA
 [3,]   12   NA
 [4,]   13    9
 [5,]   13   10
 [6,]   13   11
 [7,]   14   12
 [8,]   14   13
 [9,]   14   14
> 

> On Sep 01, 2021, at 16:59, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
>> dput(A)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
> NA, NA, NA, NA, NA), .Dim = c(9L, 2L))
> 
>> dput(B)
> 
> structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
> 11, 12, 13, 14), .Dim = c(9L, 2L))
> 
>> dput(C)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
> 10, 11, 12, 13, 14), .Dim = c(9L, 2L))


From @v|gro@@ @end|ng |rom ver|zon@net  Wed Sep  1 23:34:25 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 1 Sep 2021 17:34:25 -0400
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <04b701d79f79$23534d40$69f9e7c0$@verizon.net>

Seems trivial enough Elizabeth, either using a matrix or data.frame.

R is vectorized mostly so A[,1] notation selects a column all at once. Your
condition is thus:

A[,1] == B[,1]

After using your sample data to initialize an A and a B, I get this:

> A[,1] == B[,1]
[1] FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE

That Boolean vector can be used to index either of your matrices or any that
have the same number of rows:

Here is one solution using the vectorized ifelse() function:

using <- A[,1] == B[,1]

C <- A

C[, 2 ] <- ifelse(using, B[, 2], A[, 2])

I show the results below and you can tell us if that matches your need on
this sample data:

> A
[,1] [,2]
[1,]   12   NA
[2,]   12   NA
[3,]   12   NA
[4,]   13   NA
[5,]   13   NA
[6,]   13   NA
[7,]   14   NA
[8,]   14   NA
[9,]   14   NA
> B
[,1] [,2]
[1,]   11    6
[2,]   11    7
[3,]   11    8
[4,]   13    9
[5,]   13   10
[6,]   13   11
[7,]   14   12
[8,]   14   13
[9,]   14   14
> C
[,1] [,2]
[1,]   12   NA
[2,]   12   NA
[3,]   12   NA
[4,]   13    9
[5,]   13   10
[6,]   13   11
[7,]   14   12
[8,]   14   13
[9,]   14   14

Of course, the above can be done in fewer steps or many other ways.




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Eliza Botto
Sent: Wednesday, September 1, 2021 5:00 PM
To: r-help at r-project.org
Subject: [R] conditional replacement of elements of matrix with another
matrix column

deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a
way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA, NA, NA, NA,
NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10, 11, 12, 13,
14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9, 10, 11, 12,
13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B
provided the elements of 1st column match. Is there a single line loop or
code for that?


Thanks in advance,

Eliza Botto

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@@hr@ng@ @end|ng |rom y@hoo@com  Wed Sep  1 23:48:26 2021
From: m@@hr@ng@ @end|ng |rom y@hoo@com (Mohammad Tanvir Ahamed)
Date: Wed, 1 Sep 2021 21:48:26 +0000 (UTC)
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <1424132412.2013968.1630532906443@mail.yahoo.com>

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed 






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto <eliza_botto at outlook.com> wrote: 





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?


Thanks in advance,

Eliza Botto

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e||z@_botto @end|ng |rom out|ook@com  Thu Sep  2 00:00:22 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Wed, 1 Sep 2021 22:00:22 +0000
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <1424132412.2013968.1630532906443@mail.yahoo.com>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
Message-ID: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

I thank you all. But the code doesn't work on my different dataset where A and B have different column lengths. For example,

> dput(A)
structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897,
17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897,
17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17898,
17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
17898, 17898, 17898, 17898, 17898, 17899, 17899, 17899, 17899,
17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
17899, 17899, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17901,
17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
17901, 17901, 17901, 17901, 17901, 17902, 17902, 17902, 17902,
17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
17902, 17902, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17904,
17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
17904, 17904, 17904, 17904, 17904, 17905, 17905, 17905, 17905,
17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
17905, 17905, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17907,
17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
17907, 17907, 17907, 17907, 17907, 17908, 17908, 17908, 17908,
17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
17908, 17908, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17910,
17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
17910, 17910, 17910, 17910, 17910, 17911, 17911, 17911, 17911,
17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
17911, 17911, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17913,
17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
17913, 17913, 17913, 17913, 17913, 17914, 17914, 17914, 17914,
17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
17914, 17914, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17916,
17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
17916, 17916, 17916, 17916, 17916, 17917, 17917, 17917, 17917,
17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
17917, 17917, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17919,
17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
17919, 17919, 17919, 17919, 17919, 17920, 17920, 17920, 17920,
17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
17920, 17920, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17922,
17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
17922, 17922, 17922, 17922, 17922, 17923, 17923, 17923, 17923,
17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
17923, 17923, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17925,
17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
17925, 17925, 17925, 17925, 17925, 17926, 17926, 17926, 17926,
17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
17926, 17926, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17928,
17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
17928, 17928, 17928, 17928, 17928, 17929, 17929, 17929, 17929,
17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
17929, 17929, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17931,
17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
17931, 17931, 17931, 17931, 17931, 17932, 17932, 17932, 17932,
17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
17932, 17932, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17934,
17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
17934, 17934, 17934, 17934, 17934, 17935, 17935, 17935, 17935,
17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
17935, 17935, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17937,
17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
17937, 17937, 17937, 17937, 17937, 17938, 17938, 17938, 17938,
17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
17938, 17938, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17940,
17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
17940, 17940, 17940, 17940, 17940, 17941, 17941, 17941, 17941,
17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
17941, 17941, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17943,
17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
17943, 17943, 17943, 17943, 17943, 17944, 17944, 17944, 17944,
17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
17944, 17944, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17946,
17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
17946, 17946, 17946, 17946, 17946, 17947, 17947, 17947, 17947,
17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
17947, 17947, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17949,
17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
17949, 17949, 17949, 17949, 17949, 17950, 17950, 17950, 17950,
17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
17950, 17950, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17952,
17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
17952, 17952, 17952, 17952, 17952, 17953, 17953, 17953, 17953,
17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
17953, 17953, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17955,
17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
17955, 17955, 17955, 17955, 17955, 17956, 17956, 17956, 17956,
17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
17956, 17956, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17958,
17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
17958, 17958, 17958, 17958, 17958, 17959, 17959, 17959, 17959,
17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
17959, 17959, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17961,
17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
17961, 17961, 17961, 17961, 17961, 17962, 17962, 17962, 17962,
17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
17962, 17962, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17964,
17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
17964, 17964, 17964, 17964, 17964, 17965, 17965, 17965, 17965,
17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
17965, 17965, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17967,
17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
17967, 17967, 17967, 17967, 17967, 17968, 17968, 17968, 17968,
17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
17968, 17968, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17970,
17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
17970, 17970, 17970, 17970, 17970, 17971, 17971, 17971, 17971,
17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
17971, 17971, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17973,
17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
17973, 17973, 17973, 17973, 17973, 17974, 17974, 17974, 17974,
17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
17974, 17974, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17976,
17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
17976, 17976, 17976, 17976, 17976, 17977, 17977, 17977, 17977,
17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
17977, 17977, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17979,
17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
17979, 17979, 17979, 17979, 17979, 17980, 17980, 17980, 17980,
17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
17980, 17980, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17982,
17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
17982, 17982, 17982, 17982, 17982, 17983, 17983, 17983, 17983,
17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
17983, 17983, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17985,
17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
17985, 17985, 17985, 17985, 17985, 17986, 17986, 17986, 17986,
17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
17986, 17986, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17988,
17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
17988, 17988, 17988, 17988, 17988, 17989, 17989, 17989, 17989,
17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
17989, 17989, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17991,
17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
17991, 17991, 17991, 17991, 17991, 17992, 17992, 17992, 17992,
17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
17992, 17992, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17994,
17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
17994, 17994, 17994, 17994, 17994, 17995, 17995, 17995, 17995,
17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
17995, 17995, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17997,
17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
17997, 17997, 17997, 17997, 17997, 17998, 17998, 17998, 17998,
17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
17998, 17998, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 18000,
18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
18000, 18000, 18000, 18000, 18000, 18001, 18001, 18001, 18001,
18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
18001, 18001, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18003,
18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
18003, 18003, 18003, 18003, 18003, 18004, 18004, 18004, 18004,
18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
18004, 18004, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18006,
18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
18006, 18006, 18006, 18006, 18006, 18007, 18007, 18007, 18007,
18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
18007, 18007, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18009,
18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
18009, 18009, 18009, 18009, 18009, 18010, 18010, 18010, 18010,
18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
18010, 18010, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18012,
18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
18012, 18012, 18012, 18012, 18012, 18013, 18013, 18013, 18013,
18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
18013, 18013, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18015,
18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
18015, 18015, 18015, 18015, 18015, 18016, 18016, 18016, 18016,
18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
18016, 18016, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18018,
18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
18018, 18018, 18018, 18018, 18018, 18019, 18019, 18019, 18019,
18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
18019, 18019, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18021,
18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
18021, 18021, 18021, 18021, 18021, 18022, 18022, 18022, 18022,
18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
18022, 18022, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18024,
18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
18024, 18024, 18024, 18024, 18024, 18025, 18025, 18025, 18025,
18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
18025, 18025, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18027,
18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
18027, 18027, 18027, 18027, 18027, 18028, 18028, 18028, 18028,
18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
18028, 18028, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18030,
18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
18030, 18030, 18030, 18030, 18030, 18031, 18031, 18031, 18031,
18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
18031, 18031, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18033,
18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
18033, 18033, 18033, 18033, 18033, 18034, 18034, 18034, 18034,
18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
18034, 18034, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18036,
18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
18036, 18036, 18036, 18036, 18036, 18037, 18037, 18037, 18037,
18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
18037, 18037, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18039,
18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
18039, 18039, 18039, 18039, 18039, 18040, 18040, 18040, 18040,
18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
18040, 18040, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18042,
18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
18042, 18042, 18042, 18042, 18042, 18043, 18043, 18043, 18043,
18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
18043, 18043, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18045,
18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
18045, 18045, 18045, 18045, 18045, 18046, 18046, 18046, 18046,
18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
18046, 18046, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18048,
18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
18048, 18048, 18048, 18048, 18048, 18049, 18049, 18049, 18049,
18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
18049, 18049, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18051,
18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
18051, 18051, 18051, 18051, 18051, 18052, 18052, 18052, 18052,
18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
18052, 18052, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18054,
18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
18054, 18054, 18054, 18054, 18054, 18055, 18055, 18055, 18055,
18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
18055, 18055, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18057,
18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
18057, 18057, 18057, 18057, 18057, 18058, 18058, 18058, 18058,
18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
18058, 18058, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18060,
18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
18060, 18060, 18060, 18060, 18060, 18061, 18061, 18061, 18061,
18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
18061, 18061, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18063,
18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
18063, 18063, 18063, 18063, 18063, 18064, 18064, 18064, 18064,
18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
18064, 18064, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18066,
18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
18066, 18066, 18066, 18066, 18066, 18067, 18067, 18067, 18067,
18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
18067, 18067, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18069,
18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
18069, 18069, 18069, 18069, 18069, 18070, 18070, 18070, 18070,
18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
18070, 18070, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18072,
18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
18072, 18072, 18072, 18072, 18072, 18073, 18073, 18073, 18073,
18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
18073, 18073, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18075,
18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
18075, 18075, 18075, 18075, 18075, 18076, 18076, 18076, 18076,
18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
18076, 18076, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18078,
18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
18078, 18078, 18078, 18078, 18078, 18079, 18079, 18079, 18079,
18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
18079, 18079, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18081,
18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
18081, 18081, 18081, 18081, 18081, 18082, 18082, 18082, 18082,
18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
18082, 18082, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18084,
18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
18084, 18084, 18084, 18084, 18084, 18085, 18085, 18085, 18085,
18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
18085, 18085, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18087,
18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
18087, 18087, 18087, 18087, 18087, 18088, 18088, 18088, 18088,
18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
18088, 18088, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18090,
18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
18090, 18090, 18090, 18090, 18090, 18091, 18091, 18091, 18091,
18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
18091, 18091, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18093,
18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
18093, 18093, 18093, 18093, 18093, 18094, 18094, 18094, 18094,
18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
18094, 18094, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18096,
18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
18096, 18096, 18096, 18096, 18096, 18097, 18097, 18097, 18097,
18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
18097, 18097, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18099,
18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
18099, 18099, 18099, 18099, 18099, 18100, 18100, 18100, 18100,
18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
18100, 18100, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18102,
18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
18102, 18102, 18102, 18102, 18102, 18103, 18103, 18103, 18103,
18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
18103, 18103, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18105,
18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
18105, 18105, 18105, 18105, 18105, 18106, 18106, 18106, 18106,
18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
18106, 18106, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18108,
18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
18108, 18108, 18108, 18108, 18108, 18109, 18109, 18109, 18109,
18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
18109, 18109, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18111,
18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
18111, 18111, 18111, 18111, 18111, 18112, 18112, 18112, 18112,
18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
18112, 18112, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18114,
18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
18114, 18114, 18114, 18114, 18114, 18115, 18115, 18115, 18115,
18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
18115, 18115, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18117,
18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
18117, 18117, 18117, 18117, 18117, 18118, 18118, 18118, 18118,
18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
18118, 18118, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18120,
18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
18120, 18120, 18120, 18120, 18120, 18121, 18121, 18121, 18121,
18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
18121, 18121, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18123,
18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
18123, 18123, 18123, 18123, 18123, 18124, 18124, 18124, 18124,
18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
18124, 18124, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18126,
18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
18126, 18126, 18126, 18126, 18126, 18127, 18127, 18127, 18127,
18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
18127, 18127, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18129,
18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
18129, 18129, 18129, 18129, 18129, 18130, 18130, 18130, 18130,
18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
18130, 18130, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18132,
18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
18132, 18132, 18132, 18132, 18132, 18133, 18133, 18133, 18133,
18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
18133, 18133, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18135,
18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
18135, 18135, 18135, 18135, 18135, 18136, 18136, 18136, 18136,
18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
18136, 18136, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18138,
18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
18138, 18138, 18138, 18138, 18138, 18139, 18139, 18139, 18139,
18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
18139, 18139, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18141,
18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
18141, 18141, 18141, 18141, 18141, 18142, 18142, 18142, 18142,
18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
18142, 18142, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18144,
18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
18144, 18144, 18144, 18144, 18144, 18145, 18145, 18145, 18145,
18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
18145, 18145, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18147,
18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
18147, 18147, 18147, 18147, 18147, 18148, 18148, 18148, 18148,
18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
18148, 18148, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18150,
18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
18150, 18150, 18150, 18150, 18150, 18151, 18151, 18151, 18151,
18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
18151, 18151, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18153,
18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
18153, 18153, 18153, 18153, 18153, 18154, 18154, 18154, 18154,
18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
18154, 18154, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18156,
18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
18156, 18156, 18156, 18156, 18156, 18157, 18157, 18157, 18157,
18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
18157, 18157, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18159,
18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
18159, 18159, 18159, 18159, 18159, 18160, 18160, 18160, 18160,
18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
18160, 18160, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18162,
18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
18162, 18162, 18162, 18162, 18162, 18163, 18163, 18163, 18163,
18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
18163, 18163, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18165,
18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
18165, 18165, 18165, 18165, 18165, 18166, 18166, 18166, 18166,
18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
18166, 18166, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18168,
18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
18168, 18168, 18168, 18168, 18168, 18169, 18169, 18169, 18169,
18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
18169, 18169, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18171,
18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
18171, 18171, 18171, 18171, 18171, 18172, 18172, 18172, 18172,
18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
18172, 18172, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18174,
18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
18174, 18174, 18174, 18174, 18174, 18175, 18175, 18175, 18175,
18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
18175, 18175, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18177,
18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
18177, 18177, 18177, 18177, 18177, 18178, 18178, 18178, 18178,
18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
18178, 18178, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18180,
18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
18180, 18180, 18180, 18180, 18180, 18181, 18181, 18181, 18181,
18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
18181, 18181, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18183,
18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
18183, 18183, 18183, 18183, 18183, 18184, 18184, 18184, 18184,
18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
18184, 18184, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18186,
18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
18186, 18186, 18186, 18186, 18186, 18187, 18187, 18187, 18187,
18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
18187, 18187, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18189,
18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
18189, 18189, 18189, 18189, 18189, 18190, 18190, 18190, 18190,
18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
18190, 18190, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18192,
18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
18192, 18192, 18192, 18192, 18192, 18193, 18193, 18193, 18193,
18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
18193, 18193, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18195,
18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
18195, 18195, 18195, 18195, 18195, 18196, 18196, 18196, 18196,
18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
18196, 18196, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18198,
18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
18198, 18198, 18198, 18198, 18198, 18199, 18199, 18199, 18199,
18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
18199, 18199, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18201,
18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
18201, 18201, 18201, 18201, 18201, 18202, 18202, 18202, 18202,
18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
18202, 18202, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18204,
18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
18204, 18204, 18204, 18204, 18204, 18205, 18205, 18205, 18205,
18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
18205, 18205, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18207,
18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
18207, 18207, 18207, 18207, 18207, 18208, 18208, 18208, 18208,
18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
18208, 18208, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18210,
18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
18210, 18210, 18210, 18210, 18210, 18211, 18211, 18211, 18211,
18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
18211, 18211, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18213,
18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
18213, 18213, 18213, 18213, 18213, 18214, 18214, 18214, 18214,
18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
18214, 18214, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18216,
18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
18216, 18216, 18216, 18216, 18216, 18217, 18217, 18217, 18217,
18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
18217, 18217, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18219,
18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
18219, 18219, 18219, 18219, 18219, 18220, 18220, 18220, 18220,
18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
18220, 18220, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18222,
18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
18222, 18222, 18222, 18222, 18222, 18223, 18223, 18223, 18223,
18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
18223, 18223, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18225,
18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
18225, 18225, 18225, 18225, 18225, 18226, 18226, 18226, 18226,
18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
18226, 18226, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18228,
18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
18228, 18228, 18228, 18228, 18228, 18229, 18229, 18229, 18229,
18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
18229, 18229, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18231,
18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
18231, 18231, 18231, 18231, 18231, 18232, 18232, 18232, 18232,
18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
18232, 18232, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18234,
18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
18234, 18234, 18234, 18234, 18234, 18235, 18235, 18235, 18235,
18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
18235, 18235, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18237,
18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
18237, 18237, 18237, 18237, 18237, 18238, 18238, 18238, 18238,
18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
18238, 18238, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18240,
18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
18240, 18240, 18240, 18240, 18240, 18241, 18241, 18241, 18241,
18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
18241, 18241, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18243,
18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
18243, 18243, 18243, 18243, 18243, 18244, 18244, 18244, 18244,
18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
18244, 18244, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18246,
18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
18246, 18246, 18246, 18246, 18246, 18247, 18247, 18247, 18247,
18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
18247, 18247, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18249,
18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
18249, 18249, 18249, 18249, 18249, 18250, 18250, 18250, 18250,
18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
18250, 18250, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18252,
18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
18252, 18252, 18252, 18252, 18252, 18253, 18253, 18253, 18253,
18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
18253, 18253, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18255,
18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
18255, 18255, 18255, 18255, 18255, 18256, 18256, 18256, 18256,
18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
18256, 18256, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18258,
18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
18258, 18258, 18258, 18258, 18258, 18259, 18259, 18259, 18259,
18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
18259, 18259, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18261,
18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
18261, 18261, 18261, 18261, 18261, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA), .Dim = c(8760L, 2L))


> dput(B)
structure(c(13634, 13635, 13637, 13638, 13639, 13640, 13641,
13642, 13643, 13645, 13646, 13647, 13648, 13649, 13650, 13651,
13652, 13653, 13654, 13655, 13656, 13657, 13658, 13659, 13660,
13661, 13662, 13663, 13664, 13665, 13666, 13667, 13677, 13678,
13680, 13681, 13682, 13684, 13685, 13686, 13687, 13689, 13690,
13691, 13695, 13696, 13697, 13698, 13701, 13702, 13703, 13705,
13706, 13710, 13711, 13712, 13713, 13714, 13715, 13716, 13717,
13718, 13719, 13720, 13721, 13722, 13723, 13724, 13725, 13726,
13727, 13728, 13729, 13730, 13731, 13732, 13733, 13734, 13735,
13736, 13737, 13738, 13739, 13740, 13741, 13742, 13743, 13748,
13749, 13750, 13751, 13752, 13753, 13754, 13755, 14008, 14009,
14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018,
14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027,
14028, 14029, 14030, 14031, 14035, 14036, 14037, 14038, 14039,
14040, 14041, 14042, 14043, 14044, 14045, 14046, 14047, 14048,
14049, 14050, 14051, 14052, 14053, 14054, 14055, 14056, 14057,
14058, 14059, 14060, 14061, 14062, 14063, 14064, 14065, 14066,
14067, 14068, 14069, 14070, 14071, 14072, 14073, 14074, 14075,
14076, 14077, 14078, 14079, 14080, 14081, 14082, 14083, 14084,
14085, 14086, 14087, 14088, 14089, 14090, 14091, 14092, 14093,
14094, 14095, 14096, 14097, 14098, 14102, 14103, 14104, 14105,
14106, 14107, 14108, 14109, 14112, 14113, 14114, 14115, 14116,
14117, 14118, 14119, 14120, 14121, 14122, 14371, 14372, 14373,
14375, 14376, 14377, 14378, 14379, 14380, 14381, 14382, 14383,
14384, 14385, 14386, 14387, 14388, 14389, 14390, 14391, 14392,
14393, 14394, 14395, 14396, 14397, 14398, 14399, 14403, 14404,
14405, 14406, 14407, 14408, 14409, 14410, 14411, 14413, 14414,
14415, 14416, 14417, 14418, 14419, 14420, 14421, 14422, 14423,
14424, 14425, 14426, 14427, 14428, 14429, 14430, 14431, 14432,
14433, 14434, 14435, 14436, 14437, 14438, 14439, 14440, 14441,
14442, 14443, 14444, 14445, 14446, 14447, 14448, 14449, 14450,
14451, 14452, 14453, 14455, 14459, 14460, 14461, 14466, 14467,
14468, 14469, 14470, 14471, 14472, 14473, 14474, 14475, 14476,
14477, 14478, 14479, 14480, 14481, 14482, 14483, 14484, 14485,
14486, 14487, 14742, 14746, 14749, 14756, 14767, 14770, 14774,
14776, 14781, 14784, 14788, 14795, 14798, 14802, 14805, 14809,
14812, 14816, 14819, 14826, 14830, 14833, 14837, 14840, 14844,
14847, 14851, 15461, 15462, 15463, 15464, 15465, 15466, 15467,
15468, 15469, 15470, 15471, 15472, 15473, 15474, 15475, 15476,
15477, 15478, 15479, 15480, 15481, 15482, 15483, 15484, 15485,
15486, 15487, 15488, 15489, 15490, 15491, 15492, 15493, 15494,
15495, 15496, 15497, 15498, 15499, 15500, 15501, 15502, 15503,
15504, 15505, 15506, 15507, 15508, 15509, 15510, 15511, 15512,
15513, 15514, 15515, 15516, 15517, 15518, 15519, 15520, 15521,
15522, 15523, 15524, 15525, 15526, 15527, 15528, 15529, 15530,
15531, 15532, 15533, 15534, 15535, 15536, 15537, 15538, 15539,
15540, 15541, 15542, 15543, 15544, 15545, 15546, 15547, 15548,
15549, 15550, 15551, 15552, 15553, 15554, 15555, 15556, 15557,
15558, 15559, 15560, 15561, 15562, 15563, 15564, 15565, 15566,
15567, 15568, 15569, 15570, 15571, 15572, 15573, 15574, 15575,
15576, 15577, 15578, 15579, 15580, 15581, 15582, 15583, 15584,
15585, 15586, 15587, 15825, 15826, 15827, 15828, 15831, 15832,
15833, 15834, 15835, 15836, 15837, 15838, 15839, 15840, 15841,
15848, 15849, 15850, 15851, 15852, 15853, 15854, 15855, 15856,
15857, 15858, 15859, 15862, 15863, 15864, 15865, 15866, 15867,
15868, 15869, 15870, 15871, 15872, 15873, 15874, 15875, 15889,
15890, 15891, 15892, 15893, 15894, 15895, 15896, 15897, 15898,
15899, 15900, 15901, 15902, 15903, 15904, 15905, 15906, 15907,
15908, 15909, 15910, 15911, 15912, 15913, 15914, 15918, 15919,
15920, 15921, 15922, 15923, 15924, 15925, 15926, 15927, 15928,
15929, 15930, 15931, 15932, 15933, 15934, 15935, 15936, 15937,
15938, 15939, 15940, 15941, 15942, 15943, 15944, 15945, 15946,
15947, 15948, 15949, 15950, 15951, 16192, 16193, 16194, 16195,
16196, 16197, 16198, 16199, 16200, 16202, 16203, 16204, 16205,
16206, 16207, 16208, 16209, 16212, 16213, 16214, 16215, 16216,
16217, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233,
16238, 16239, 16240, 16241, 16244, 16245, 16246, 16247, 16248,
16249, 16250, 16251, 16252, 16253, 16254, 16255, 16256, 16257,
16258, 16259, 16260, 16261, 16262, 16263, 16264, 16265, 16266,
16267, 16268, 16269, 16270, 16271, 16275, 16276, 16277, 16278,
16279, 16280, 16281, 16282, 16285, 16293, 16294, 16295, 16296,
16297, 16298, 16299, 16300, 16301, 16302, 16303, 16304, 16305,
16306, 16307, 16308, 16309, 16310, 16589, 16603, 16607, 16616,
16632, 16651, 16662, 16971, 16986, 17007, 17023, 17180, 17184,
17189, 17218, 17231, 17239, 17245, 17269, 17273, 17301, 17304,
17315, 17326, 17343, 17367, 17387, 17392, 17393, 17393, 17399,
17416, 17422, 17423, 17427, 17431, 17442, 17455, 17469, 17483,
17494, 17498, 17511, 17528, 17539, 17550, 17553, 17583, 17595,
17603, 17605, 17610, 17611, 17612, 17618, 17619, 17623, 17637,
17651, 17665, 17679, 17682, 17696, 17707, 17721, 17722, 17731,
17735, 17736, 17738, 17751, 17763, 17778, 17791, 18033, 18037,
18053, 18063, 18066, 18114, 18130, 18133, 18148, 3, 32, 88, 126,
8, 2, 2, 4, 5, 5, 60, 1, 1, 1.5, 1.5, 2, 2, 330, 7, 1, 40, 52,
15, 4, 3, 2, 1, 5, 3, 1, 5, 1234, 5, 6, 34, 107, 12, 6, 6, 1,
1, 189, 9, 4, 1, 1, 5, 5, 3, 5, 4, 14, 3, 15, 3.5, 9, 2, 1, 1,
1, 10, 133, 109, 8, 1, 2, 1, 13, 1, 1, 2, 4, 60, 4, 2, 2, 226,
111, 23, 2, 1, 2, 2, 2, 2, 3, 1, 15, 2, 1, 111, 93, 6, 5, 1,
42, 9, 3, 2, 1, 1, 0.75, 1, 0.5, 0.5, 1, 5, 235, 129, 120, 102,
41, 63, 11, 5, 0.75, 257, 45, 7, 164, 161, 223, 111, 175, 158,
76, 39, 39, 22, 5, 4, 3, 4, 3, 6, 4, 13, 2, 137, 5, 3, 2, 2,
1, 47, 1, 1, 1, 256, 29, 51, 427, 54, 15, 131, 52, 6, 329, 111,
43, 9, 2, 87, 11, 3, 5, 6, 12, 17, 3, 5, 306, 28, 5, 3, 0.5,
1, 0.5, 0.5, 4, 1.5, 3, 2, 3, 2, 3, 2, 2, 2, 507, 10, 70, 12,
1, 3, 1, 49, 2, 3, 1, 189, 39, 39, 122, 63, 5, 184, 37, 78, 22,
7, 4, 47, 12, 65, 6, 9, 2, 3, 42, 7, 3, 3, 2, 2, 18, 2, 1, 2,
2, 9, 10, 3, 3, 3, 32, 13, 5, 98, 442, 51, 6, 101, 5, 2, 2, 6,
5, 3, 2, 3, 6, 17, 125, 6, 70, 11, 171, 24.5, 87, 11, 11, 2,
2, 137, 16, 35, 5, 2, 2, 3, 2, 3, 3, 3, 2, 1, 8, 2, 3, 61, 119,
62, 22, 8, 25, 3, 159, 38, 42, 9, 3, 93, 36, 4, 5, 4, 4, 5, 4,
5, 4, 3, 332, 20, 6, 2.5, 7.5, 3, 331, 149.5, 44, 36.5, 311,
427, 3, 43.5, 7, 140, 594, 46, 23, 11, 46, 436, 82.5, 600, 53,
1.5, 9, 4, 40, 8, 6, 6, 6, 13, 141, 11, 4, 2, 4, 1, 1, 1, 1,
1, 1, 1, 21, 6, 4, 1, 1, 553, 93, 41, 40, 4, 2, 2, 4, 1, 3, 2,
17, 3, 5, 951, 138, 6, 67, 24, 66, 3, 4, 167, 259, 32, 4, 8,
143, 64, 4, 3, 25, 68, 119, 8, 57, 61, 2, 2, 4, 3, 2, 3, 2, 12.61666667,
51, 7, 5.916666667, 2, 6, 1, 5, 3, 3, 4.083333333, 8, 7, 1, 1,
17, 4, 3, 12, 1, 1, 1, 2, 3, 3, 1, 1, 19, 18, 3, 1, 1, 1, 1,
1, 4, 4, 3, 121, 94, 13, 4, 4, 1, 2, 1, 1, 1, 1, 1, 83, 4, 1,
4, 2, 1, 1, 2, 5, 3, 1, 1, 23, 6, 12, 28, 12, 4, 4, 4, 3, 10,
5, 6, 36, 5, 8, 386, 177.5, 23, 3, 9, 174, 248, 116, 29, 5, 88,
56, 4, 11, 30, 9, 8, 14, 6, 28, 139.5, 64, 4, 18, 64, 67, 39,
144, 102, 10, 4, 252, 4, 4, 4, 4, 19, 1, 4, 3, 3, 9, 2, 1, 1,
314, 44, 12, 87, 7, 132, 26, 14, 16, 7, 10, 8, 107, 40, 33, 18,
5, 5, 6, 4, 3, 2, 6, 6, 5, 4, 5, 7, 5, 6, 8, 6, 29, 7, 4, 77,
3, 3, 4, 17, 3, 154, 60, 45, 7, 18.5, 8, 5, 118, 56, 6.5, 2,
1, 4, 4, 4, 34, 16, 14, 7, 6, 6, 44, 6, 8.5, 2, 1, 1, 9, 1, 16,
4, 50, 98, 57, 45, 10, 142, 170, 6, 60, 605, 25, 30, 18.5, 19,
9.5, 1, 1, 993.5, 57, 4, 2, 30, 4, 4, 2, 2, 1, 9, 53, 4, 3, 580.75,
60, 45, 21, 25, 44, 18, 10, 27, 534.3333333, 4, 10, 2, 63, 14,
4, 4, 8, 15, 408, 46, 18, 8, 3, 6, 4, 9, 137.5, 428.49, 78.8,
30.49, 9.97, 229.77, 550.175, 167.17, 186.17, 224.855, 609.835,
1180, 130.7077449, 229.6460144, 3, 4, 20, 409.1286324, 18, 452,
4, 4, 107, 8, 487, 2, 9, 1, 159, 329, 324, 2, 10, 174, 67, 1,
42, 43, 4, 3, 3, 104, 9, 1, 1, 4, 32, 1, 1, 2, 238, 237, 190,
214, 156, 240, 29, 2, 374, 36, 4, 18, 419, 2, 5, 3, 277, 340,
1, 216, 93, 1, 4, 2, 3, 42, 78, 190, 40, 808, 80, 266, 66, 42
), .Dim = c(734L, 2L))

Can you please guide me how to implement the given code on this dataset?
I thanyou in advance
________________________________
From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Sent: Wednesday 1 September 2021 21:48
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto <eliza_botto at outlook.com>
Subject: Re: [R] conditional replacement of elements of matrix with another matrix column

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto <eliza_botto at outlook.com> wrote:





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?


Thanks in advance,

Eliza Botto

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 00:06:22 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 1 Sep 2021 18:06:22 -0400
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
 <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <053c01d79f7d$99744020$cc5cc060$@verizon.net>

Why would you ask your question without mentioning that the two vectors may
be of unequal length when your abbreviated example was not like that!

 

You have two CASES here. In one A is longer and in one B is longer. When
they are the same, it does not matter.

 

So in your scenario, consider looking at length(A) and length(B) and
adjusting whatever method you use carefully. You now might need to use 1:N
notation to limit what you are doing so you do not access values out of
bounds.

 

Not going to do it for you. I see others have also supplied variants and .

 

From: Eliza Botto <eliza_botto at outlook.com> 
Sent: Wednesday, September 1, 2021 6:00 PM
To: r-help at r-project.org; Mohammad Tanvir Ahamed <mashranga at yahoo.com>; Avi
Gross <avigross at verizon.net>; Richard M. Heiberger <rmh at temple.edu>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column

 

I thank you all. But the code doesn't work on my different dataset where A
and B have different column lengths. For example,

 

> dput(A) 

structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897, 

17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 

SNIP

 

 

Can you please guide me how to implement the given code on this dataset?

I thanyou in advance

  _____  

From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Sent: Wednesday 1 September 2021 21:48
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto
<eliza_botto at outlook.com>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column 

 

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed 






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto
<eliza_botto at outlook.com> wrote: 





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a
way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B
provided the elements of 1st column match. Is there a single line loop or
code for that?


Thanks in advance,

Eliza Botto

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Sep  2 00:29:50 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Sep 2021 10:29:50 +1200
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
Message-ID: <20210902102950.0e873a42@rolf-Latitude-E7470>


On Wed, 1 Sep 2021 05:35:03 -0400
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 31/08/2021 11:59 p.m., Rolf Turner wrote:
> > 
> > I'm trying to build a pair of (S3) methods, a "formula" method and a
> > "default" method.  The methods have a "data" argument.  If the
> > variables in question cannot be found in "data" then they should be
> > sought in the global environment.
> > 
> > My problem is that the generic dispatches on its first argument,
> > which may be a formula (in which case it of course dispatches to
> > the formula method) or the first of the variables.  If this
> > variable exists in the global environment then all is well.  But if
> > it doesn't exist there, then the generic falls over with an error
> > of the form "object 'x' not found" --- because there isn't anything
> > to dispatch on.
> > 
> > I'd *like* to be able to tell the generic that if "x" is not found
> > then it should dispatch to the default method (which will, if the
> > call is sensible, find "x" in "data").
> > 
> > Is there any way to tell the generic to do this?
> > 
> > Or is there any other way out of this dilemma? (Other than "Give up
> > and go to the pub", which I cannot currently do since Auckland is
> > in Level 4 lockdown. :-) )
> > 
> 
> That design is probably not a good idea:  what if one of the
> variables in data matches the name of some other object in the global
> environment? Then it would dispatch on that other object, and things
> won't go well.
> 
> But here's a way to shoot yourself in the foot:
> 
> function(x) {
>    x1 <- try(x, silent = TRUE)
>    if (inherits(x1, "try-error"))
>      foo.default(x)
>    else
>      UseMethod("foo", x)
> }
> 
> Happy shooting!

Thanks Duncan. I don't understand your warning, but.

If I call foo(y ~ x,data=xxx) I want the generic to dispatch to the
formula method.  That method will then look for y and x first in xxx,
and if it can't find them there it then will look for them in the global
environment.

If I call foo(x,y,data=xxx) I want the generic to dispatch to the
default method, irrespective of whether x exists in the global
environment.  I can't figure out how to arrange this.  As before
(if I could arrange for the dispatch to happen as desired) I would want
the method to look for y and x first in xxx, and if it can't find them
there it then will look for them in the global environment.

It doesn't matter there is an "x" in both xxx and in the global
environment; the methods will/should use the "x" from xxx.

I don't see a problem with respect to this issue.

Whatever.  I can't get your shoot-in-the-foot solution to work anyway.

If I set

    xxx <- data.frame(u=1:10,v=rnorm(10))

and do

    foo(x=u,y=v,data=xxx)

I get

> Error in foo.default(x, y, data) : Cannot find x.

The argument names need to match up.  Note that calling foo.default()
directly works:

    foo.default(x=u,y=v,data=xxx)

runs just fine.

I think I'm going to have to give up on the classes-and-methods
approach.  I *think* I can see a way through with a using a single
function and if-statements based on your "try" idea.

Thanks!!!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From no@p@m @end|ng |rom ||@@e@NA  Thu Sep  2 00:32:30 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 2 Sep 2021 00:32:30 +0200
Subject: [R] ISO Code for Namibia ('NA')
Message-ID: <sgov20$3kl$1@ciao.gmane.io>

Hi,

how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
which looks something like

	# A tibble: 10 ? 1
	   location_code
	   <chr>
	 1 NC
[...]
	10 NZ

but should look like

	# A tibble: 10 ? 1
	   location_code
	   <chr>
	 1 NA
	 2 NC
[...]
	11 NZ

In other words 'NA' is taken for the missing value NA.

greetings, el


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep  2 00:41:16 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 1 Sep 2021 15:41:16 -0700
Subject: [R] ISO Code for Namibia ('NA')
In-Reply-To: <sgov20$3kl$1@ciao.gmane.io>
References: <sgov20$3kl$1@ciao.gmane.io>
Message-ID: <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>

> z <- tibble(Code=c("NA","NZ",NA), Name=c("Namibia","New Zealand","?"))
> z
# A tibble: 3 x 2
  Code  Name
  <chr> <chr>
1 NA    Namibia
2 NZ    New Zealand
3 <NA>  ?
> subset(z, Code=="NA")
# A tibble: 1 x 2
  Code  Name
  <chr> <chr>
1 NA    Namibia
> subset(z, is.na(Code))
# A tibble: 1 x 2
  Code  Name
  <chr> <chr>
1 <NA>  ?
> subset(z, Code==NA_character_)
# A tibble: 0 x 2
# ... with 2 variables: Code <chr>, Name <chr>

On Wed, Sep 1, 2021 at 3:33 PM Dr Eberhard Lisse <nospam at lisse.na> wrote:

> Hi,
>
> how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
> which looks something like
>
>         # A tibble: 10 ? 1
>            location_code
>            <chr>
>          1 NC
> [...]
>         10 NZ
>
> but should look like
>
>         # A tibble: 10 ? 1
>            location_code
>            <chr>
>          1 NA
>          2 NC
> [...]
>         11 NZ
>
> In other words 'NA' is taken for the missing value NA.
>
> greetings, el
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Sep  2 00:57:27 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Wed, 1 Sep 2021 15:57:27 -0700
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <20210902102950.0e873a42@rolf-Latitude-E7470>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
 <20210902102950.0e873a42@rolf-Latitude-E7470>
Message-ID: <CAHqSRuR7JFwPsULje+p+jBjywTC2OpWrvSirjXg+wFryNwor1w@mail.gmail.com>

Is this the kind of thing you are looking for?  It separates the scoping
issue from the method dispatch by defining another S3-generic function,
".foo".

> foo <- function(x, ..., data=NULL) with(data, .foo(x, ...))
> .foo <- function(x, ...) UseMethod(".foo")
> .foo.default <- function(x, ...) cat("default method\n")
> .foo.integer <- function(x, ...) cat("integer method\n")
> .foo.formula <- function(x, ...) cat("formula method\n")
>
> rm(x)
Warning message:
In rm(x) : object 'x' not found
> foo(32L)
integer method
> foo(y~x)
formula method
> foo(x, data=list(x=2.7))
default method
> x <- 45L ; foo(x)
integer method
> x <- 45L ; foo(x, data=list(x=3.4))
default method
> x <- 45L ; foo(x, data=list(x=Y~X1+X2))
formula method

On Wed, Sep 1, 2021 at 3:30 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:

>
> On Wed, 1 Sep 2021 05:35:03 -0400
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> > On 31/08/2021 11:59 p.m., Rolf Turner wrote:
> > >
> > > I'm trying to build a pair of (S3) methods, a "formula" method and a
> > > "default" method.  The methods have a "data" argument.  If the
> > > variables in question cannot be found in "data" then they should be
> > > sought in the global environment.
> > >
> > > My problem is that the generic dispatches on its first argument,
> > > which may be a formula (in which case it of course dispatches to
> > > the formula method) or the first of the variables.  If this
> > > variable exists in the global environment then all is well.  But if
> > > it doesn't exist there, then the generic falls over with an error
> > > of the form "object 'x' not found" --- because there isn't anything
> > > to dispatch on.
> > >
> > > I'd *like* to be able to tell the generic that if "x" is not found
> > > then it should dispatch to the default method (which will, if the
> > > call is sensible, find "x" in "data").
> > >
> > > Is there any way to tell the generic to do this?
> > >
> > > Or is there any other way out of this dilemma? (Other than "Give up
> > > and go to the pub", which I cannot currently do since Auckland is
> > > in Level 4 lockdown. :-) )
> > >
> >
> > That design is probably not a good idea:  what if one of the
> > variables in data matches the name of some other object in the global
> > environment? Then it would dispatch on that other object, and things
> > won't go well.
> >
> > But here's a way to shoot yourself in the foot:
> >
> > function(x) {
> >    x1 <- try(x, silent = TRUE)
> >    if (inherits(x1, "try-error"))
> >      foo.default(x)
> >    else
> >      UseMethod("foo", x)
> > }
> >
> > Happy shooting!
>
> Thanks Duncan. I don't understand your warning, but.
>
> If I call foo(y ~ x,data=xxx) I want the generic to dispatch to the
> formula method.  That method will then look for y and x first in xxx,
> and if it can't find them there it then will look for them in the global
> environment.
>
> If I call foo(x,y,data=xxx) I want the generic to dispatch to the
> default method, irrespective of whether x exists in the global
> environment.  I can't figure out how to arrange this.  As before
> (if I could arrange for the dispatch to happen as desired) I would want
> the method to look for y and x first in xxx, and if it can't find them
> there it then will look for them in the global environment.
>
> It doesn't matter there is an "x" in both xxx and in the global
> environment; the methods will/should use the "x" from xxx.
>
> I don't see a problem with respect to this issue.
>
> Whatever.  I can't get your shoot-in-the-foot solution to work anyway.
>
> If I set
>
>     xxx <- data.frame(u=1:10,v=rnorm(10))
>
> and do
>
>     foo(x=u,y=v,data=xxx)
>
> I get
>
> > Error in foo.default(x, y, data) : Cannot find x.
>
> The argument names need to match up.  Note that calling foo.default()
> directly works:
>
>     foo.default(x=u,y=v,data=xxx)
>
> runs just fine.
>
> I think I'm going to have to give up on the classes-and-methods
> approach.  I *think* I can see a way through with a using a single
> function and if-statements based on your "try" idea.
>
> Thanks!!!
>
> cheers,
>
> Rolf
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  2 01:29:32 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 1 Sep 2021 19:29:32 -0400
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <20210902102950.0e873a42@rolf-Latitude-E7470>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
 <20210902102950.0e873a42@rolf-Latitude-E7470>
Message-ID: <6a6ca852-2a8b-7f20-b85f-fadd2c6af769@gmail.com>

On 01/09/2021 6:29 p.m., Rolf Turner wrote:
> 
> On Wed, 1 Sep 2021 05:35:03 -0400
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 31/08/2021 11:59 p.m., Rolf Turner wrote:
>>>
>>> I'm trying to build a pair of (S3) methods, a "formula" method and a
>>> "default" method.  The methods have a "data" argument.  If the
>>> variables in question cannot be found in "data" then they should be
>>> sought in the global environment.
>>>
>>> My problem is that the generic dispatches on its first argument,
>>> which may be a formula (in which case it of course dispatches to
>>> the formula method) or the first of the variables.  If this
>>> variable exists in the global environment then all is well.  But if
>>> it doesn't exist there, then the generic falls over with an error
>>> of the form "object 'x' not found" --- because there isn't anything
>>> to dispatch on.
>>>
>>> I'd *like* to be able to tell the generic that if "x" is not found
>>> then it should dispatch to the default method (which will, if the
>>> call is sensible, find "x" in "data").
>>>
>>> Is there any way to tell the generic to do this?
>>>
>>> Or is there any other way out of this dilemma? (Other than "Give up
>>> and go to the pub", which I cannot currently do since Auckland is
>>> in Level 4 lockdown. :-) )
>>>
>>
>> That design is probably not a good idea:  what if one of the
>> variables in data matches the name of some other object in the global
>> environment? Then it would dispatch on that other object, and things
>> won't go well.
>>
>> But here's a way to shoot yourself in the foot:
>>
>> function(x) {
>>     x1 <- try(x, silent = TRUE)
>>     if (inherits(x1, "try-error"))
>>       foo.default(x)
>>     else
>>       UseMethod("foo", x)
>> }
>>
>> Happy shooting!
> 
> Thanks Duncan. I don't understand your warning, but.
> 
> If I call foo(y ~ x,data=xxx) I want the generic to dispatch to the
> formula method.  That method will then look for y and x first in xxx,
> and if it can't find them there it then will look for them in the global
> environment.
> 
> If I call foo(x,y,data=xxx) I want the generic to dispatch to the
> default method, irrespective of whether x exists in the global
> environment.  I can't figure out how to arrange this.  As before
> (if I could arrange for the dispatch to happen as desired) I would want
> the method to look for y and x first in xxx, and if it can't find them
> there it then will look for them in the global environment.
> 
> It doesn't matter there is an "x" in both xxx and in the global
> environment; the methods will/should use the "x" from xxx.
> 
> I don't see a problem with respect to this issue.
> 
> Whatever.  I can't get your shoot-in-the-foot solution to work anyway.
> 
> If I set
> 
>      xxx <- data.frame(u=1:10,v=rnorm(10))
> 
> and do
> 
>      foo(x=u,y=v,data=xxx)
> 
> I get
> 
>> Error in foo.default(x, y, data) : Cannot find x.
> 
> The argument names need to match up.  Note that calling foo.default()
> directly works:
> 
>      foo.default(x=u,y=v,data=xxx)
> 
> runs just fine.
> 
> I think I'm going to have to give up on the classes-and-methods
> approach.  I *think* I can see a way through with a using a single
> function and if-statements based on your "try" idea.
> 

I don't know the header of your foo() method, but let's suppose foo() is

   foo <- function(x, data, ...) {
     UseMethod("foo")
   }

with

   foo.formula <- function(x, data, ...) {
     # do something with the formula x
   }

   foo.default <- function(x, data, ...) {
     # do the default thing.
   }

Now you have

   xxx <- data.frame(u = 1:10, v = rnorm(10))
   foo(x = u, y = v, data = xxx)

You want this to dispatch to the default method, because u is not a 
formula, it's a column in xxx.  But how do you know that?  Maybe in some 
other part of your code you have

   u <- someresponse ~ somepredictor

So now u *is* a formula, and this will dispatch to the formula method, 
causing havoc.

I think Bill's suggestion doesn't help here.  To do what you want to do 
doesn't really match what S3 is designed to do.

Duncan


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 04:15:38 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Wed, 1 Sep 2021 22:15:38 -0400
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
 <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <009401d79fa0$6c33b230$449b1690$@verizon.net>

Just for the hell of is I looked at the huge amount of data to see the
lengths:

 

> nrow(A)

[1] 8760

> nrow(B)

[1] 734

> sum(is.na(A[, 2]))

[1] 8760

> sum(is.na(B[, 2]))

[1] 0

 

So it seems your first huge matrix has 8,760 rows where the second entry is
always NA.

 

B seems to have 733 unique values out of 734 entries. For what I call a key
and 192 different values mapped into by the keys.

 

> length(unique(B[,1]))

[1] 733

> length(unique(B[,2]))

[1] 192

 

I now conclude the question was badly phrased, as often happens when English
is not the main language used, or the person asking may have provided an
incomplete request, perhaps based on their misunderstanding.

 

First, matrix A has NOTHING anywhere in the second column other than an NA
placeholder. It has umpteen copies of the same number followed by umpteen of
the next and so on. And specifically exactly 24 copies of each!

 

> table(A[,1])

 

17897 17898 17899 17900 17901 17902 17903 17904 17905 17906 17907 17908
17909 17910 17911 17912 

24    24    24    24    24    24    24    24    24    24    24    24    24
24    24    24 

<<SNIP>>

  18249 18250 18251 18252 18253 18254 18255 18256 18257 18258 18259 18260
18261 

24    24    24    24    24    24    24    24    24    24    24    24    24

 

I have no interest in why any of that is but the problem now strikes me as
different. It is not about what to do when A and B have the same value in
column one at all, especially as they are not at all similar. It is about
table lookup, I think.

 

As such, the request is to do something so that you replace the NA in table
A (probably no need to make a C, albeit that works too) by using column2 in
B for whichever one table A in column one matches, using the corresponding
column two.

 

Such a request can be handled quite a few ways BEFORE or after. I mean
instead of making 24 copies in A, you could just make 24 copies of B, and if
needed sort them.  But more generally, there are many R function in base R
that do all kinds of joins such as merge() or in the dplyr/tidyverse package
albeit some of these may be done on data.frames rather than matrices, albeit
they can easily be converted.

 

And of course many alternatives, some painful, involve iterating over one
matrix while searching the other for a match, or setting up B as a
searchable object that simulates a hash or dictionary in other languages,
such as a named structure.

 

For example, make a named vector containing column two with the names of
column 1:

 

You can now look up items in B_vech using the character representation:

 

Here is the first few lines of B:

 

> head(B)

[,1] [,2]

[1,] 13634    3

[2,] 13635   32

[3,] 13637   88

[4,] 13638  126

[5,] 13639    8

[6,] 13640    2

 

Searching for 13635 works fine:

 

> B_vec[as.character(13635)]

13635 

32 

> B_vec[as.character(13636)]

<NA> 

  NA 

> B_vec[as.character(13637)]

13637 

88

 

But since 13636 is not in the vector, it fails.

 

So to convert A (or a copy called C) becomes fairly simple IFF the set of
numbers in A and B are properly set up.

 

A[,2] <- B_vec[as.character(A[,1])]

 

But are they?

 

> range(A[,1])

[1] 17897 18261

> range(B[,1])

[1] 13634 18148

 

But I think I have wasted enough of my time and of everyone who read this
far on a problem that was not explained and may well still not be what I am
guessing. As noted, probably easiest to solve using a merge.

 

 

 

 

From: Eliza Botto <eliza_botto at outlook.com> 
Sent: Wednesday, September 1, 2021 6:00 PM
To: r-help at r-project.org; Mohammad Tanvir Ahamed <mashranga at yahoo.com>; Avi
Gross <avigross at verizon.net>; Richard M. Heiberger <rmh at temple.edu>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column

 

I thank you all. But the code doesn't work on my different dataset where A
and B have different column lengths. For example,

 

> dput(A) 

structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897, 

17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 

<<SNIP>>

NA), .Dim = c(8760L, 2L))

 

 

> dput(B) 

structure(c(13634, 13635, 13637, 13638, 13639, 13640, 13641, 

13642, 13643, 13645, 13646, 13647, 13648, 13649, 13650, 13651, 

<<SNIP>>

214, 156, 240, 29, 2, 374, 36, 4, 18, 419, 2, 5, 3, 277, 340, 

1, 216, 93, 1, 4, 2, 3, 42, 78, 190, 40, 808, 80, 266, 66, 42

), .Dim = c(734L, 2L))

 

Can you please guide me how to implement the given code on this dataset?

I thanyou in advance

  _____  

From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
Sent: Wednesday 1 September 2021 21:48
To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto
<eliza_botto at outlook.com>
Subject: Re: [R] conditional replacement of elements of matrix with another
matrix column 

 

C1 <- A
C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]


Regards.............
Tanvir Ahamed 






On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto
<eliza_botto at outlook.com> wrote: 





deaR useRs,

I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a
way of doing it?

> dput(A)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
NA, NA, NA, NA, NA), .Dim = c(9L, 2L))

> dput(B)

structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
11, 12, 13, 14), .Dim = c(9L, 2L))

> dput(C)

structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
10, 11, 12, 13, 14), .Dim = c(9L, 2L))

Precisely, I want to replace the elements of 2nd column of A with those of B
provided the elements of 1st column match. Is there a single line loop or
code for that?


Thanks in advance,

Eliza Botto

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From no@p@m @end|ng |rom ||@@e@NA  Thu Sep  2 09:03:55 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 2 Sep 2021 09:03:55 +0200
Subject: [R] ISO Code for Namibia ('NA')
In-Reply-To: <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
References: <sgov20$3kl$1@ciao.gmane.io>
 <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
Message-ID: <00c8e252-067b-608b-6b4a-d34d684ca8d6@lisse.NA>

Thank you.

el


On 02/09/2021 00:41, Bill Dunlap wrote:
>> z <- tibble(Code=c("NA","NZ",NA), Name=c("Namibia","New Zealand","?"))
>> z
> # A tibble: 3 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
> 2 NZ    New Zealand
> 3 <NA>  ?
>> subset(z, Code=="NA")
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
>> subset(z, is.na(Code))
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 <NA>  ?
>> subset(z, Code==NA_character_)
> # A tibble: 0 x 2
> # ... with 2 variables: Code <chr>, Name <chr>
> 
> On Wed, Sep 1, 2021 at 3:33 PM Dr Eberhard Lisse <nospam at lisse.na> wrote:
> 
>> Hi,
>>
>> how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
>> which looks something like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NC
>> [...]
>>          10 NZ
>>
>> but should look like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NA
>>           2 NC
>> [...]
>>          11 NZ
>>
>> In other words 'NA' is taken for the missing value NA.
>>
>> greetings, el
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 


-- 
To email me replace 'nospam' with 'el'


From no@p@m @end|ng |rom ||@@e@NA  Thu Sep  2 09:03:55 2021
From: no@p@m @end|ng |rom ||@@e@NA (Dr Eberhard Lisse)
Date: Thu, 2 Sep 2021 09:03:55 +0200
Subject: [R] ISO Code for Namibia ('NA')
In-Reply-To: <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
References: <sgov20$3kl$1@ciao.gmane.io>
 <CAHqSRuRx2PQz_RTZfMFaFFZb8XmJnx8w4ztxNp2pLaciOD81ew@mail.gmail.com>
Message-ID: <00c8e252-067b-608b-6b4a-d34d684ca8d6@lisse.NA>

Thank you.

el


On 02/09/2021 00:41, Bill Dunlap wrote:
>> z <- tibble(Code=c("NA","NZ",NA), Name=c("Namibia","New Zealand","?"))
>> z
> # A tibble: 3 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
> 2 NZ    New Zealand
> 3 <NA>  ?
>> subset(z, Code=="NA")
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 NA    Namibia
>> subset(z, is.na(Code))
> # A tibble: 1 x 2
>    Code  Name
>    <chr> <chr>
> 1 <NA>  ?
>> subset(z, Code==NA_character_)
> # A tibble: 0 x 2
> # ... with 2 variables: Code <chr>, Name <chr>
> 
> On Wed, Sep 1, 2021 at 3:33 PM Dr Eberhard Lisse <nospam at lisse.na> wrote:
> 
>> Hi,
>>
>> how can I look for the ISO code for Namibia 'NA' in a list of ISO codes
>> which looks something like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NC
>> [...]
>>          10 NZ
>>
>> but should look like
>>
>>          # A tibble: 10 ? 1
>>             location_code
>>             <chr>
>>           1 NA
>>           2 NC
>> [...]
>>          11 NZ
>>
>> In other words 'NA' is taken for the missing value NA.
>>
>> greetings, el
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 


-- 
To email me replace 'nospam' with 'el'


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Sep  2 10:54:42 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 2 Sep 2021 10:54:42 +0200
Subject: [R] combining geom_boxplot and geom_point with jitter
Message-ID: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>

Dear useRs,

I'm having a problem to combine geom_boxplot and geom_point with jitter. 
It is difficult to explain but the code and result should make it clear 
(the example dataset is long so I copy it at the end of the email):

p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
p <- p + geom_boxplot(outlier.shape = NA)
p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
position_jitterdodge())
print(p)

As you can see in the resulting plot, the points with different shapes 
are dodged across the boxplot categories (colors). I'd like the three 
shapes per color to be restricted in one boxplot color, with jitter of 
course to better visualize the points.

Does that make sense?

I have played with the arguments of position_jitterdodge(), but it seems 
to me that the problem is that the shape aesthetic is not in the 
geom_boxplot() call (but I don't want it there, see below).

For background information, the column used for shape gives some sort of 
"quality" to the points; that's why I want to show the points 
differently, so that it can easily be seen whether "good" points plot in 
the same area as the "bad" points.
Because I'm doing facet plots with other variables, I do not want to 
separate these categories in the boxplots - the resulting plots would be 
overcrowded.

Thank you for the help.
Ivan

---

my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
"Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
"Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
"Dry grass", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
"Dry bamboo", "Dry bamboo",
"Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
"ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
"Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L), .Label = c("0-5%", "5-10%", 
"10-20%", "20-100%"), class = c("ordered", "factor")), name = 
structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), 
.Label = c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), 
class = "factor"), value = c(16.00716636, 12.925787, 14.05932485, 
11.999816, 15.12321532, 12.711474, 12.79565826, 10.900949, 15.90481161, 
12.836045, 16.22778102, 13.565995, 14.71354945, 12.384152, 16.61354777, 
13.714165, 15.91399496, 12.983796, 19.44739619, 15.173215, 16.13761798, 
12.932798, 14.7332952, 12.10277, 10.78710961, 8.762726, 10.16027362, 
8.040399, 14.53444662, 11.527896, 17.38120685, 13.78922, 11.26840546, 
9.426558, 24.01797992, 18.398553, 13.7435699, 11.44385, 14.391873, 
10.757141, 22.39390393, 18.176262, 11.60322022, 9.969118, 11.6099975, 
10.059618, 11.86282935, 10.280864, 16.22473644, 13.562839, 12.46350165, 
10.629406, 23.9347534, 19.062174, 19.58121507, 15.910959, 13.99145447, 
11.352648, 14.38942328, 11.821431, 23.4733371, 18.549503, 13.08142223, 
10.735494, 17.09293046, 13.012834, 28.80020878, 22.447105, 25.74460885, 
19.76834, 14.29106582, 12.233774, 12.03005024, 10.364224, 12.58953574, 
10.30257, 18.07111578, 14.416143, 20.85562751, 16.524047, 21.06132234, 
15.744758, 15.24052683, 11.891487, 11.62446752, 9.14325, 11.75704705, 
10.358542, 13.65568703, 11.766129, 16.98137759, 12.594787, 11.6560954, 
10.32073, 15.46708251, 13.199232, 13.20110131, 11.060226, 16.13986173, 
13.564802, 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 
11.994841, 12.07940958, 9.470493, 13.93630412, 11.489685, 21.84464295, 
17.806018, 17.4383111, 14.478338, 20.55074297, 16.254467, 30.15238714, 
24.193768, 32.8541897, 25.769585, 32.06966759, 24.507185, 20.53975772, 
15.951186, 11.54494952, 9.676342, 13.56490524, 11.456356, 13.58242208, 
10.919419, 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 
18.749955, 26.38707155, 20.877856, 26.18252748, 20.758242)), row.names = 
c(NA, -140L), class = c("tbl_df", "tbl", "data.frame"))

-- 
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From c@ghpm m@iii@g oii gm@ii@com  Wed Sep  1 22:50:27 2021
From: c@ghpm m@iii@g oii gm@ii@com (c@ghpm m@iii@g oii gm@ii@com)
Date: Wed, 1 Sep 2021 17:50:27 -0300
Subject: [R] how to install npsm package
In-Reply-To: <CAGgJW76wD-ai58K=QkUrH0yWaG9-6XTR5D8r7J8DuYLL3Pid-g@mail.gmail.com>
References: <012701d79f3e$79cb6300$6d622900$@gmail.com>
 <CAGgJW76wD-ai58K=QkUrH0yWaG9-6XTR5D8r7J8DuYLL3Pid-g@mail.gmail.com>
Message-ID: <017101d79f73$0c73a580$255af080$@gmail.com>

Thank you, Eric. Very useful. 

 

From: Eric Berger <ericjberger at gmail.com> 
Sent: Wednesday, September 1, 2021 12:31 PM
To: caghpm at gmail.com
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] how to install npsm package

 

Instructions can be found at https://github.com/kloke/npsm

 

 

On Wed, Sep 1, 2021 at 6:27 PM <caghpm at gmail.com <mailto:caghpm at gmail.com> > wrote:

I need to install the package "npsm" to follow Kloke & McKean book. However,
npsm is no longer on CRAN. So, please let me know in detail how to proceed
to install it.



Thanks.



Carlos Gonzalez


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 11:28:01 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 10:28:01 +0100
Subject: [R] conditional replacement of elements of matrix with another
 matrix column
In-Reply-To: <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099980A639EB635D298BF6DB9ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
 <1424132412.2013968.1630532906443@mail.yahoo.com>
 <AS8P194MB09995D93045EF2ECC72FF6C49ACD9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <9ffc93df-e6d1-c123-c6af-c0a774a91e4a@sapo.pt>

Hello,

With the new data, here are two ways.
The first with a for loop. I find it simple and readable.


for(b in unique(B[,1])){
   A[which(A[,1] == b), 2] <- B[which(B[,1] == b), 2]
}
na <- is.na(A[,2])
A[!na, 2]

sum(!na)               # [1] 216
sum(A[,1] %in% B[,1])  # [1] 216

# Another way, with merge
mrg <- merge(as.data.frame(A), as.data.frame(B), by = "V1", all.x = 
TRUE)[c(1, 3)]
sum(!is.na(mrg[[2]]))  # [1] 216

identical(A[,2], mrg[[2]])  # [1] TRUE


Note that mrg is a data.frame, you can coerce back to matrix


A <- as.matrix(mrg)


Hope this helps,

Rui Barradas


?s 23:00 de 01/09/21, Eliza Botto escreveu:
> I thank you all. But the code doesn't work on my different dataset where A and B have different column lengths. For example,
> 
>> dput(A)
> structure(c(17897, 17897, 17897, 17897, 17897, 17897, 17897,
> 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897,
> 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17897, 17898,
> 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
> 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898, 17898,
> 17898, 17898, 17898, 17898, 17898, 17899, 17899, 17899, 17899,
> 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
> 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899, 17899,
> 17899, 17899, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
> 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900,
> 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17900, 17901,
> 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
> 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901, 17901,
> 17901, 17901, 17901, 17901, 17901, 17902, 17902, 17902, 17902,
> 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
> 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902, 17902,
> 17902, 17902, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
> 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903,
> 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17903, 17904,
> 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
> 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904, 17904,
> 17904, 17904, 17904, 17904, 17904, 17905, 17905, 17905, 17905,
> 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
> 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905, 17905,
> 17905, 17905, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
> 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906,
> 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17906, 17907,
> 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
> 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907, 17907,
> 17907, 17907, 17907, 17907, 17907, 17908, 17908, 17908, 17908,
> 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
> 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908, 17908,
> 17908, 17908, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
> 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909,
> 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17909, 17910,
> 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
> 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910, 17910,
> 17910, 17910, 17910, 17910, 17910, 17911, 17911, 17911, 17911,
> 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
> 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911, 17911,
> 17911, 17911, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
> 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912,
> 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17912, 17913,
> 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
> 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913, 17913,
> 17913, 17913, 17913, 17913, 17913, 17914, 17914, 17914, 17914,
> 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
> 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914, 17914,
> 17914, 17914, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
> 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915,
> 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17915, 17916,
> 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
> 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916, 17916,
> 17916, 17916, 17916, 17916, 17916, 17917, 17917, 17917, 17917,
> 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
> 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917, 17917,
> 17917, 17917, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
> 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918,
> 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17918, 17919,
> 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
> 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919, 17919,
> 17919, 17919, 17919, 17919, 17919, 17920, 17920, 17920, 17920,
> 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
> 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920, 17920,
> 17920, 17920, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
> 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921,
> 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17921, 17922,
> 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
> 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922, 17922,
> 17922, 17922, 17922, 17922, 17922, 17923, 17923, 17923, 17923,
> 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
> 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923, 17923,
> 17923, 17923, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
> 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924,
> 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17924, 17925,
> 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
> 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925, 17925,
> 17925, 17925, 17925, 17925, 17925, 17926, 17926, 17926, 17926,
> 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
> 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926, 17926,
> 17926, 17926, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
> 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927,
> 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17927, 17928,
> 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
> 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928, 17928,
> 17928, 17928, 17928, 17928, 17928, 17929, 17929, 17929, 17929,
> 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
> 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929, 17929,
> 17929, 17929, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
> 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930,
> 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17930, 17931,
> 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
> 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931, 17931,
> 17931, 17931, 17931, 17931, 17931, 17932, 17932, 17932, 17932,
> 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
> 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932, 17932,
> 17932, 17932, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
> 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933,
> 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17933, 17934,
> 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
> 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934, 17934,
> 17934, 17934, 17934, 17934, 17934, 17935, 17935, 17935, 17935,
> 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
> 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935, 17935,
> 17935, 17935, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
> 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936,
> 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17936, 17937,
> 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
> 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937, 17937,
> 17937, 17937, 17937, 17937, 17937, 17938, 17938, 17938, 17938,
> 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
> 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938, 17938,
> 17938, 17938, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
> 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939,
> 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17939, 17940,
> 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
> 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940, 17940,
> 17940, 17940, 17940, 17940, 17940, 17941, 17941, 17941, 17941,
> 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
> 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941, 17941,
> 17941, 17941, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
> 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942,
> 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17942, 17943,
> 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
> 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943, 17943,
> 17943, 17943, 17943, 17943, 17943, 17944, 17944, 17944, 17944,
> 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
> 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944, 17944,
> 17944, 17944, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
> 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945,
> 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17945, 17946,
> 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
> 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946, 17946,
> 17946, 17946, 17946, 17946, 17946, 17947, 17947, 17947, 17947,
> 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
> 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947, 17947,
> 17947, 17947, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
> 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948,
> 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17948, 17949,
> 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
> 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949, 17949,
> 17949, 17949, 17949, 17949, 17949, 17950, 17950, 17950, 17950,
> 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
> 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950, 17950,
> 17950, 17950, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
> 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951,
> 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17951, 17952,
> 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
> 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952, 17952,
> 17952, 17952, 17952, 17952, 17952, 17953, 17953, 17953, 17953,
> 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
> 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953, 17953,
> 17953, 17953, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
> 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954,
> 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17954, 17955,
> 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
> 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955, 17955,
> 17955, 17955, 17955, 17955, 17955, 17956, 17956, 17956, 17956,
> 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
> 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956, 17956,
> 17956, 17956, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
> 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957,
> 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17957, 17958,
> 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
> 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958, 17958,
> 17958, 17958, 17958, 17958, 17958, 17959, 17959, 17959, 17959,
> 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
> 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959, 17959,
> 17959, 17959, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
> 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960,
> 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17960, 17961,
> 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
> 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961, 17961,
> 17961, 17961, 17961, 17961, 17961, 17962, 17962, 17962, 17962,
> 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
> 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962, 17962,
> 17962, 17962, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
> 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963,
> 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17963, 17964,
> 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
> 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964, 17964,
> 17964, 17964, 17964, 17964, 17964, 17965, 17965, 17965, 17965,
> 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
> 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965, 17965,
> 17965, 17965, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
> 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966,
> 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17966, 17967,
> 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
> 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967, 17967,
> 17967, 17967, 17967, 17967, 17967, 17968, 17968, 17968, 17968,
> 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
> 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968, 17968,
> 17968, 17968, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
> 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969,
> 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17969, 17970,
> 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
> 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970, 17970,
> 17970, 17970, 17970, 17970, 17970, 17971, 17971, 17971, 17971,
> 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
> 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971, 17971,
> 17971, 17971, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
> 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972,
> 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17972, 17973,
> 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
> 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973, 17973,
> 17973, 17973, 17973, 17973, 17973, 17974, 17974, 17974, 17974,
> 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
> 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974, 17974,
> 17974, 17974, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
> 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975,
> 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17975, 17976,
> 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
> 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976, 17976,
> 17976, 17976, 17976, 17976, 17976, 17977, 17977, 17977, 17977,
> 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
> 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977, 17977,
> 17977, 17977, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
> 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978,
> 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17978, 17979,
> 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
> 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979, 17979,
> 17979, 17979, 17979, 17979, 17979, 17980, 17980, 17980, 17980,
> 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
> 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980, 17980,
> 17980, 17980, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
> 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981,
> 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17981, 17982,
> 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
> 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982, 17982,
> 17982, 17982, 17982, 17982, 17982, 17983, 17983, 17983, 17983,
> 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
> 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983, 17983,
> 17983, 17983, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
> 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984,
> 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17984, 17985,
> 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
> 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985, 17985,
> 17985, 17985, 17985, 17985, 17985, 17986, 17986, 17986, 17986,
> 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
> 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986, 17986,
> 17986, 17986, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
> 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987,
> 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17987, 17988,
> 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
> 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988, 17988,
> 17988, 17988, 17988, 17988, 17988, 17989, 17989, 17989, 17989,
> 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
> 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989, 17989,
> 17989, 17989, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
> 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990,
> 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17990, 17991,
> 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
> 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991, 17991,
> 17991, 17991, 17991, 17991, 17991, 17992, 17992, 17992, 17992,
> 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
> 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992, 17992,
> 17992, 17992, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
> 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993,
> 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17993, 17994,
> 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
> 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994, 17994,
> 17994, 17994, 17994, 17994, 17994, 17995, 17995, 17995, 17995,
> 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
> 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995, 17995,
> 17995, 17995, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
> 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996,
> 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17996, 17997,
> 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
> 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997, 17997,
> 17997, 17997, 17997, 17997, 17997, 17998, 17998, 17998, 17998,
> 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
> 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998, 17998,
> 17998, 17998, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
> 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999,
> 17999, 17999, 17999, 17999, 17999, 17999, 17999, 17999, 18000,
> 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
> 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000, 18000,
> 18000, 18000, 18000, 18000, 18000, 18001, 18001, 18001, 18001,
> 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
> 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001, 18001,
> 18001, 18001, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
> 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002,
> 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18002, 18003,
> 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
> 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003, 18003,
> 18003, 18003, 18003, 18003, 18003, 18004, 18004, 18004, 18004,
> 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
> 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004, 18004,
> 18004, 18004, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
> 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005,
> 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18005, 18006,
> 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
> 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006, 18006,
> 18006, 18006, 18006, 18006, 18006, 18007, 18007, 18007, 18007,
> 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
> 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007, 18007,
> 18007, 18007, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
> 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008,
> 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18008, 18009,
> 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
> 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009, 18009,
> 18009, 18009, 18009, 18009, 18009, 18010, 18010, 18010, 18010,
> 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
> 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010, 18010,
> 18010, 18010, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
> 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011,
> 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18011, 18012,
> 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
> 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012, 18012,
> 18012, 18012, 18012, 18012, 18012, 18013, 18013, 18013, 18013,
> 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
> 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013, 18013,
> 18013, 18013, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
> 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014,
> 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18014, 18015,
> 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
> 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015, 18015,
> 18015, 18015, 18015, 18015, 18015, 18016, 18016, 18016, 18016,
> 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
> 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016, 18016,
> 18016, 18016, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
> 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017,
> 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18017, 18018,
> 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
> 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018, 18018,
> 18018, 18018, 18018, 18018, 18018, 18019, 18019, 18019, 18019,
> 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
> 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019, 18019,
> 18019, 18019, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
> 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020,
> 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18020, 18021,
> 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
> 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021, 18021,
> 18021, 18021, 18021, 18021, 18021, 18022, 18022, 18022, 18022,
> 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
> 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022, 18022,
> 18022, 18022, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
> 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023,
> 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18023, 18024,
> 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
> 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024, 18024,
> 18024, 18024, 18024, 18024, 18024, 18025, 18025, 18025, 18025,
> 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
> 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025, 18025,
> 18025, 18025, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
> 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026,
> 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18026, 18027,
> 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
> 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027, 18027,
> 18027, 18027, 18027, 18027, 18027, 18028, 18028, 18028, 18028,
> 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
> 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028, 18028,
> 18028, 18028, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
> 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029,
> 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18029, 18030,
> 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
> 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030, 18030,
> 18030, 18030, 18030, 18030, 18030, 18031, 18031, 18031, 18031,
> 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
> 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031, 18031,
> 18031, 18031, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
> 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032,
> 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18032, 18033,
> 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
> 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033, 18033,
> 18033, 18033, 18033, 18033, 18033, 18034, 18034, 18034, 18034,
> 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
> 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034, 18034,
> 18034, 18034, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
> 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035,
> 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18035, 18036,
> 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
> 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036, 18036,
> 18036, 18036, 18036, 18036, 18036, 18037, 18037, 18037, 18037,
> 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
> 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037, 18037,
> 18037, 18037, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
> 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038,
> 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18038, 18039,
> 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
> 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039, 18039,
> 18039, 18039, 18039, 18039, 18039, 18040, 18040, 18040, 18040,
> 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
> 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040, 18040,
> 18040, 18040, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
> 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041,
> 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18041, 18042,
> 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
> 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042, 18042,
> 18042, 18042, 18042, 18042, 18042, 18043, 18043, 18043, 18043,
> 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
> 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043, 18043,
> 18043, 18043, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
> 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044,
> 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18044, 18045,
> 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
> 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045, 18045,
> 18045, 18045, 18045, 18045, 18045, 18046, 18046, 18046, 18046,
> 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
> 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046, 18046,
> 18046, 18046, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
> 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047,
> 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18047, 18048,
> 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
> 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048, 18048,
> 18048, 18048, 18048, 18048, 18048, 18049, 18049, 18049, 18049,
> 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
> 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049, 18049,
> 18049, 18049, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
> 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050,
> 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18050, 18051,
> 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
> 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051, 18051,
> 18051, 18051, 18051, 18051, 18051, 18052, 18052, 18052, 18052,
> 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
> 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052, 18052,
> 18052, 18052, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
> 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053,
> 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18053, 18054,
> 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
> 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054, 18054,
> 18054, 18054, 18054, 18054, 18054, 18055, 18055, 18055, 18055,
> 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
> 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055, 18055,
> 18055, 18055, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
> 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056,
> 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18056, 18057,
> 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
> 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057, 18057,
> 18057, 18057, 18057, 18057, 18057, 18058, 18058, 18058, 18058,
> 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
> 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058, 18058,
> 18058, 18058, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
> 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059,
> 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18059, 18060,
> 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
> 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060, 18060,
> 18060, 18060, 18060, 18060, 18060, 18061, 18061, 18061, 18061,
> 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
> 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061, 18061,
> 18061, 18061, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
> 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062,
> 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18062, 18063,
> 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
> 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063, 18063,
> 18063, 18063, 18063, 18063, 18063, 18064, 18064, 18064, 18064,
> 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
> 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064, 18064,
> 18064, 18064, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
> 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065,
> 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18065, 18066,
> 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
> 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066, 18066,
> 18066, 18066, 18066, 18066, 18066, 18067, 18067, 18067, 18067,
> 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
> 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067, 18067,
> 18067, 18067, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
> 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068,
> 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18068, 18069,
> 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
> 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069, 18069,
> 18069, 18069, 18069, 18069, 18069, 18070, 18070, 18070, 18070,
> 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
> 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070, 18070,
> 18070, 18070, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
> 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071,
> 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18071, 18072,
> 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
> 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072, 18072,
> 18072, 18072, 18072, 18072, 18072, 18073, 18073, 18073, 18073,
> 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
> 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073, 18073,
> 18073, 18073, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
> 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074,
> 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18074, 18075,
> 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
> 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075, 18075,
> 18075, 18075, 18075, 18075, 18075, 18076, 18076, 18076, 18076,
> 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
> 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076, 18076,
> 18076, 18076, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
> 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077,
> 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18077, 18078,
> 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
> 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078, 18078,
> 18078, 18078, 18078, 18078, 18078, 18079, 18079, 18079, 18079,
> 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
> 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079, 18079,
> 18079, 18079, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
> 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080,
> 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18080, 18081,
> 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
> 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081, 18081,
> 18081, 18081, 18081, 18081, 18081, 18082, 18082, 18082, 18082,
> 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
> 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082, 18082,
> 18082, 18082, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
> 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083,
> 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18083, 18084,
> 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
> 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084, 18084,
> 18084, 18084, 18084, 18084, 18084, 18085, 18085, 18085, 18085,
> 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
> 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085, 18085,
> 18085, 18085, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
> 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086,
> 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18086, 18087,
> 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
> 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087, 18087,
> 18087, 18087, 18087, 18087, 18087, 18088, 18088, 18088, 18088,
> 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
> 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088, 18088,
> 18088, 18088, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
> 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089,
> 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18089, 18090,
> 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
> 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090, 18090,
> 18090, 18090, 18090, 18090, 18090, 18091, 18091, 18091, 18091,
> 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
> 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091, 18091,
> 18091, 18091, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
> 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092,
> 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18092, 18093,
> 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
> 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093, 18093,
> 18093, 18093, 18093, 18093, 18093, 18094, 18094, 18094, 18094,
> 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
> 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094, 18094,
> 18094, 18094, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
> 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095,
> 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18095, 18096,
> 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
> 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096, 18096,
> 18096, 18096, 18096, 18096, 18096, 18097, 18097, 18097, 18097,
> 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
> 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097, 18097,
> 18097, 18097, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
> 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098,
> 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18098, 18099,
> 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
> 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099, 18099,
> 18099, 18099, 18099, 18099, 18099, 18100, 18100, 18100, 18100,
> 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
> 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100, 18100,
> 18100, 18100, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
> 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101,
> 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18101, 18102,
> 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
> 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102, 18102,
> 18102, 18102, 18102, 18102, 18102, 18103, 18103, 18103, 18103,
> 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
> 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103, 18103,
> 18103, 18103, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
> 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104,
> 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18104, 18105,
> 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
> 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105, 18105,
> 18105, 18105, 18105, 18105, 18105, 18106, 18106, 18106, 18106,
> 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
> 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106, 18106,
> 18106, 18106, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
> 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107,
> 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18107, 18108,
> 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
> 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108, 18108,
> 18108, 18108, 18108, 18108, 18108, 18109, 18109, 18109, 18109,
> 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
> 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109, 18109,
> 18109, 18109, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
> 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110,
> 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18110, 18111,
> 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
> 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111, 18111,
> 18111, 18111, 18111, 18111, 18111, 18112, 18112, 18112, 18112,
> 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
> 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112, 18112,
> 18112, 18112, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
> 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113,
> 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18113, 18114,
> 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
> 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114, 18114,
> 18114, 18114, 18114, 18114, 18114, 18115, 18115, 18115, 18115,
> 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
> 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115, 18115,
> 18115, 18115, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
> 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116,
> 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18116, 18117,
> 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
> 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117, 18117,
> 18117, 18117, 18117, 18117, 18117, 18118, 18118, 18118, 18118,
> 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
> 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118, 18118,
> 18118, 18118, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
> 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119,
> 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18119, 18120,
> 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
> 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120, 18120,
> 18120, 18120, 18120, 18120, 18120, 18121, 18121, 18121, 18121,
> 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
> 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121, 18121,
> 18121, 18121, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
> 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122,
> 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18122, 18123,
> 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
> 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123, 18123,
> 18123, 18123, 18123, 18123, 18123, 18124, 18124, 18124, 18124,
> 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
> 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124, 18124,
> 18124, 18124, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
> 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125,
> 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18125, 18126,
> 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
> 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126, 18126,
> 18126, 18126, 18126, 18126, 18126, 18127, 18127, 18127, 18127,
> 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
> 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127, 18127,
> 18127, 18127, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
> 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128,
> 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18128, 18129,
> 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
> 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129, 18129,
> 18129, 18129, 18129, 18129, 18129, 18130, 18130, 18130, 18130,
> 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
> 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130, 18130,
> 18130, 18130, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
> 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131,
> 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18131, 18132,
> 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
> 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132, 18132,
> 18132, 18132, 18132, 18132, 18132, 18133, 18133, 18133, 18133,
> 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
> 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133, 18133,
> 18133, 18133, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
> 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134,
> 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18134, 18135,
> 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
> 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135, 18135,
> 18135, 18135, 18135, 18135, 18135, 18136, 18136, 18136, 18136,
> 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
> 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136, 18136,
> 18136, 18136, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
> 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137,
> 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18137, 18138,
> 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
> 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138, 18138,
> 18138, 18138, 18138, 18138, 18138, 18139, 18139, 18139, 18139,
> 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
> 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139, 18139,
> 18139, 18139, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
> 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140,
> 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18140, 18141,
> 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
> 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141, 18141,
> 18141, 18141, 18141, 18141, 18141, 18142, 18142, 18142, 18142,
> 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
> 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142, 18142,
> 18142, 18142, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
> 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143,
> 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18143, 18144,
> 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
> 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144, 18144,
> 18144, 18144, 18144, 18144, 18144, 18145, 18145, 18145, 18145,
> 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
> 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145, 18145,
> 18145, 18145, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
> 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146,
> 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18146, 18147,
> 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
> 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147, 18147,
> 18147, 18147, 18147, 18147, 18147, 18148, 18148, 18148, 18148,
> 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
> 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148, 18148,
> 18148, 18148, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
> 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149,
> 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18149, 18150,
> 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
> 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150, 18150,
> 18150, 18150, 18150, 18150, 18150, 18151, 18151, 18151, 18151,
> 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
> 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151, 18151,
> 18151, 18151, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
> 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152,
> 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18152, 18153,
> 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
> 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153, 18153,
> 18153, 18153, 18153, 18153, 18153, 18154, 18154, 18154, 18154,
> 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
> 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154, 18154,
> 18154, 18154, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
> 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155,
> 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18155, 18156,
> 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
> 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156, 18156,
> 18156, 18156, 18156, 18156, 18156, 18157, 18157, 18157, 18157,
> 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
> 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157, 18157,
> 18157, 18157, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
> 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158,
> 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18158, 18159,
> 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
> 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159, 18159,
> 18159, 18159, 18159, 18159, 18159, 18160, 18160, 18160, 18160,
> 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
> 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160, 18160,
> 18160, 18160, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
> 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161,
> 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18161, 18162,
> 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
> 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162, 18162,
> 18162, 18162, 18162, 18162, 18162, 18163, 18163, 18163, 18163,
> 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
> 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163, 18163,
> 18163, 18163, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
> 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164,
> 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18164, 18165,
> 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
> 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165, 18165,
> 18165, 18165, 18165, 18165, 18165, 18166, 18166, 18166, 18166,
> 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
> 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166, 18166,
> 18166, 18166, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
> 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167,
> 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18167, 18168,
> 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
> 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168, 18168,
> 18168, 18168, 18168, 18168, 18168, 18169, 18169, 18169, 18169,
> 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
> 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169, 18169,
> 18169, 18169, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
> 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170,
> 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18170, 18171,
> 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
> 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171, 18171,
> 18171, 18171, 18171, 18171, 18171, 18172, 18172, 18172, 18172,
> 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
> 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172, 18172,
> 18172, 18172, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
> 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173,
> 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18173, 18174,
> 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
> 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174, 18174,
> 18174, 18174, 18174, 18174, 18174, 18175, 18175, 18175, 18175,
> 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
> 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175, 18175,
> 18175, 18175, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
> 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176,
> 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18176, 18177,
> 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
> 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177, 18177,
> 18177, 18177, 18177, 18177, 18177, 18178, 18178, 18178, 18178,
> 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
> 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178, 18178,
> 18178, 18178, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
> 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179,
> 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18179, 18180,
> 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
> 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180, 18180,
> 18180, 18180, 18180, 18180, 18180, 18181, 18181, 18181, 18181,
> 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
> 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181, 18181,
> 18181, 18181, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
> 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182,
> 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18182, 18183,
> 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
> 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183, 18183,
> 18183, 18183, 18183, 18183, 18183, 18184, 18184, 18184, 18184,
> 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
> 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184, 18184,
> 18184, 18184, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
> 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185,
> 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18185, 18186,
> 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
> 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186, 18186,
> 18186, 18186, 18186, 18186, 18186, 18187, 18187, 18187, 18187,
> 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
> 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187, 18187,
> 18187, 18187, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
> 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188,
> 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18188, 18189,
> 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
> 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189, 18189,
> 18189, 18189, 18189, 18189, 18189, 18190, 18190, 18190, 18190,
> 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
> 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190, 18190,
> 18190, 18190, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
> 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191,
> 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18191, 18192,
> 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
> 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192, 18192,
> 18192, 18192, 18192, 18192, 18192, 18193, 18193, 18193, 18193,
> 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
> 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193, 18193,
> 18193, 18193, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
> 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194,
> 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18194, 18195,
> 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
> 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195, 18195,
> 18195, 18195, 18195, 18195, 18195, 18196, 18196, 18196, 18196,
> 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
> 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196, 18196,
> 18196, 18196, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
> 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197,
> 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18197, 18198,
> 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
> 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198, 18198,
> 18198, 18198, 18198, 18198, 18198, 18199, 18199, 18199, 18199,
> 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
> 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199, 18199,
> 18199, 18199, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
> 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200,
> 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18200, 18201,
> 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
> 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201, 18201,
> 18201, 18201, 18201, 18201, 18201, 18202, 18202, 18202, 18202,
> 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
> 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202, 18202,
> 18202, 18202, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
> 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203,
> 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18203, 18204,
> 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
> 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204, 18204,
> 18204, 18204, 18204, 18204, 18204, 18205, 18205, 18205, 18205,
> 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
> 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205, 18205,
> 18205, 18205, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
> 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206,
> 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18206, 18207,
> 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
> 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207, 18207,
> 18207, 18207, 18207, 18207, 18207, 18208, 18208, 18208, 18208,
> 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
> 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208, 18208,
> 18208, 18208, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
> 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209,
> 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18209, 18210,
> 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
> 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210, 18210,
> 18210, 18210, 18210, 18210, 18210, 18211, 18211, 18211, 18211,
> 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
> 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211, 18211,
> 18211, 18211, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
> 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212,
> 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18212, 18213,
> 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
> 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213, 18213,
> 18213, 18213, 18213, 18213, 18213, 18214, 18214, 18214, 18214,
> 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
> 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214, 18214,
> 18214, 18214, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
> 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215,
> 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18215, 18216,
> 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
> 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216, 18216,
> 18216, 18216, 18216, 18216, 18216, 18217, 18217, 18217, 18217,
> 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
> 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217, 18217,
> 18217, 18217, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
> 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218,
> 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18218, 18219,
> 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
> 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219, 18219,
> 18219, 18219, 18219, 18219, 18219, 18220, 18220, 18220, 18220,
> 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
> 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220, 18220,
> 18220, 18220, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
> 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221,
> 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18221, 18222,
> 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
> 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222, 18222,
> 18222, 18222, 18222, 18222, 18222, 18223, 18223, 18223, 18223,
> 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
> 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223, 18223,
> 18223, 18223, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
> 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224,
> 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18224, 18225,
> 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
> 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225, 18225,
> 18225, 18225, 18225, 18225, 18225, 18226, 18226, 18226, 18226,
> 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
> 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226, 18226,
> 18226, 18226, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
> 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227,
> 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18227, 18228,
> 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
> 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228, 18228,
> 18228, 18228, 18228, 18228, 18228, 18229, 18229, 18229, 18229,
> 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
> 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229, 18229,
> 18229, 18229, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
> 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230,
> 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18230, 18231,
> 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
> 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231, 18231,
> 18231, 18231, 18231, 18231, 18231, 18232, 18232, 18232, 18232,
> 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
> 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232, 18232,
> 18232, 18232, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
> 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233,
> 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18233, 18234,
> 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
> 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234, 18234,
> 18234, 18234, 18234, 18234, 18234, 18235, 18235, 18235, 18235,
> 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
> 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235, 18235,
> 18235, 18235, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
> 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236,
> 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18236, 18237,
> 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
> 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237, 18237,
> 18237, 18237, 18237, 18237, 18237, 18238, 18238, 18238, 18238,
> 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
> 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238, 18238,
> 18238, 18238, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
> 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239,
> 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18239, 18240,
> 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
> 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240, 18240,
> 18240, 18240, 18240, 18240, 18240, 18241, 18241, 18241, 18241,
> 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
> 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241, 18241,
> 18241, 18241, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
> 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242,
> 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18242, 18243,
> 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
> 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243, 18243,
> 18243, 18243, 18243, 18243, 18243, 18244, 18244, 18244, 18244,
> 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
> 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244, 18244,
> 18244, 18244, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
> 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245,
> 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18245, 18246,
> 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
> 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246, 18246,
> 18246, 18246, 18246, 18246, 18246, 18247, 18247, 18247, 18247,
> 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
> 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247, 18247,
> 18247, 18247, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
> 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248,
> 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18248, 18249,
> 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
> 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249, 18249,
> 18249, 18249, 18249, 18249, 18249, 18250, 18250, 18250, 18250,
> 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
> 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250, 18250,
> 18250, 18250, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
> 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251,
> 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18251, 18252,
> 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
> 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252, 18252,
> 18252, 18252, 18252, 18252, 18252, 18253, 18253, 18253, 18253,
> 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
> 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253, 18253,
> 18253, 18253, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
> 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254,
> 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18254, 18255,
> 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
> 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255, 18255,
> 18255, 18255, 18255, 18255, 18255, 18256, 18256, 18256, 18256,
> 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
> 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256, 18256,
> 18256, 18256, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
> 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257,
> 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18257, 18258,
> 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
> 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258, 18258,
> 18258, 18258, 18258, 18258, 18258, 18259, 18259, 18259, 18259,
> 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
> 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259, 18259,
> 18259, 18259, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
> 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260,
> 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18260, 18261,
> 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
> 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261, 18261,
> 18261, 18261, 18261, 18261, 18261, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA), .Dim = c(8760L, 2L))
> 
> 
>> dput(B)
> structure(c(13634, 13635, 13637, 13638, 13639, 13640, 13641,
> 13642, 13643, 13645, 13646, 13647, 13648, 13649, 13650, 13651,
> 13652, 13653, 13654, 13655, 13656, 13657, 13658, 13659, 13660,
> 13661, 13662, 13663, 13664, 13665, 13666, 13667, 13677, 13678,
> 13680, 13681, 13682, 13684, 13685, 13686, 13687, 13689, 13690,
> 13691, 13695, 13696, 13697, 13698, 13701, 13702, 13703, 13705,
> 13706, 13710, 13711, 13712, 13713, 13714, 13715, 13716, 13717,
> 13718, 13719, 13720, 13721, 13722, 13723, 13724, 13725, 13726,
> 13727, 13728, 13729, 13730, 13731, 13732, 13733, 13734, 13735,
> 13736, 13737, 13738, 13739, 13740, 13741, 13742, 13743, 13748,
> 13749, 13750, 13751, 13752, 13753, 13754, 13755, 14008, 14009,
> 14010, 14011, 14012, 14013, 14014, 14015, 14016, 14017, 14018,
> 14019, 14020, 14021, 14022, 14023, 14024, 14025, 14026, 14027,
> 14028, 14029, 14030, 14031, 14035, 14036, 14037, 14038, 14039,
> 14040, 14041, 14042, 14043, 14044, 14045, 14046, 14047, 14048,
> 14049, 14050, 14051, 14052, 14053, 14054, 14055, 14056, 14057,
> 14058, 14059, 14060, 14061, 14062, 14063, 14064, 14065, 14066,
> 14067, 14068, 14069, 14070, 14071, 14072, 14073, 14074, 14075,
> 14076, 14077, 14078, 14079, 14080, 14081, 14082, 14083, 14084,
> 14085, 14086, 14087, 14088, 14089, 14090, 14091, 14092, 14093,
> 14094, 14095, 14096, 14097, 14098, 14102, 14103, 14104, 14105,
> 14106, 14107, 14108, 14109, 14112, 14113, 14114, 14115, 14116,
> 14117, 14118, 14119, 14120, 14121, 14122, 14371, 14372, 14373,
> 14375, 14376, 14377, 14378, 14379, 14380, 14381, 14382, 14383,
> 14384, 14385, 14386, 14387, 14388, 14389, 14390, 14391, 14392,
> 14393, 14394, 14395, 14396, 14397, 14398, 14399, 14403, 14404,
> 14405, 14406, 14407, 14408, 14409, 14410, 14411, 14413, 14414,
> 14415, 14416, 14417, 14418, 14419, 14420, 14421, 14422, 14423,
> 14424, 14425, 14426, 14427, 14428, 14429, 14430, 14431, 14432,
> 14433, 14434, 14435, 14436, 14437, 14438, 14439, 14440, 14441,
> 14442, 14443, 14444, 14445, 14446, 14447, 14448, 14449, 14450,
> 14451, 14452, 14453, 14455, 14459, 14460, 14461, 14466, 14467,
> 14468, 14469, 14470, 14471, 14472, 14473, 14474, 14475, 14476,
> 14477, 14478, 14479, 14480, 14481, 14482, 14483, 14484, 14485,
> 14486, 14487, 14742, 14746, 14749, 14756, 14767, 14770, 14774,
> 14776, 14781, 14784, 14788, 14795, 14798, 14802, 14805, 14809,
> 14812, 14816, 14819, 14826, 14830, 14833, 14837, 14840, 14844,
> 14847, 14851, 15461, 15462, 15463, 15464, 15465, 15466, 15467,
> 15468, 15469, 15470, 15471, 15472, 15473, 15474, 15475, 15476,
> 15477, 15478, 15479, 15480, 15481, 15482, 15483, 15484, 15485,
> 15486, 15487, 15488, 15489, 15490, 15491, 15492, 15493, 15494,
> 15495, 15496, 15497, 15498, 15499, 15500, 15501, 15502, 15503,
> 15504, 15505, 15506, 15507, 15508, 15509, 15510, 15511, 15512,
> 15513, 15514, 15515, 15516, 15517, 15518, 15519, 15520, 15521,
> 15522, 15523, 15524, 15525, 15526, 15527, 15528, 15529, 15530,
> 15531, 15532, 15533, 15534, 15535, 15536, 15537, 15538, 15539,
> 15540, 15541, 15542, 15543, 15544, 15545, 15546, 15547, 15548,
> 15549, 15550, 15551, 15552, 15553, 15554, 15555, 15556, 15557,
> 15558, 15559, 15560, 15561, 15562, 15563, 15564, 15565, 15566,
> 15567, 15568, 15569, 15570, 15571, 15572, 15573, 15574, 15575,
> 15576, 15577, 15578, 15579, 15580, 15581, 15582, 15583, 15584,
> 15585, 15586, 15587, 15825, 15826, 15827, 15828, 15831, 15832,
> 15833, 15834, 15835, 15836, 15837, 15838, 15839, 15840, 15841,
> 15848, 15849, 15850, 15851, 15852, 15853, 15854, 15855, 15856,
> 15857, 15858, 15859, 15862, 15863, 15864, 15865, 15866, 15867,
> 15868, 15869, 15870, 15871, 15872, 15873, 15874, 15875, 15889,
> 15890, 15891, 15892, 15893, 15894, 15895, 15896, 15897, 15898,
> 15899, 15900, 15901, 15902, 15903, 15904, 15905, 15906, 15907,
> 15908, 15909, 15910, 15911, 15912, 15913, 15914, 15918, 15919,
> 15920, 15921, 15922, 15923, 15924, 15925, 15926, 15927, 15928,
> 15929, 15930, 15931, 15932, 15933, 15934, 15935, 15936, 15937,
> 15938, 15939, 15940, 15941, 15942, 15943, 15944, 15945, 15946,
> 15947, 15948, 15949, 15950, 15951, 16192, 16193, 16194, 16195,
> 16196, 16197, 16198, 16199, 16200, 16202, 16203, 16204, 16205,
> 16206, 16207, 16208, 16209, 16212, 16213, 16214, 16215, 16216,
> 16217, 16226, 16227, 16228, 16229, 16230, 16231, 16232, 16233,
> 16238, 16239, 16240, 16241, 16244, 16245, 16246, 16247, 16248,
> 16249, 16250, 16251, 16252, 16253, 16254, 16255, 16256, 16257,
> 16258, 16259, 16260, 16261, 16262, 16263, 16264, 16265, 16266,
> 16267, 16268, 16269, 16270, 16271, 16275, 16276, 16277, 16278,
> 16279, 16280, 16281, 16282, 16285, 16293, 16294, 16295, 16296,
> 16297, 16298, 16299, 16300, 16301, 16302, 16303, 16304, 16305,
> 16306, 16307, 16308, 16309, 16310, 16589, 16603, 16607, 16616,
> 16632, 16651, 16662, 16971, 16986, 17007, 17023, 17180, 17184,
> 17189, 17218, 17231, 17239, 17245, 17269, 17273, 17301, 17304,
> 17315, 17326, 17343, 17367, 17387, 17392, 17393, 17393, 17399,
> 17416, 17422, 17423, 17427, 17431, 17442, 17455, 17469, 17483,
> 17494, 17498, 17511, 17528, 17539, 17550, 17553, 17583, 17595,
> 17603, 17605, 17610, 17611, 17612, 17618, 17619, 17623, 17637,
> 17651, 17665, 17679, 17682, 17696, 17707, 17721, 17722, 17731,
> 17735, 17736, 17738, 17751, 17763, 17778, 17791, 18033, 18037,
> 18053, 18063, 18066, 18114, 18130, 18133, 18148, 3, 32, 88, 126,
> 8, 2, 2, 4, 5, 5, 60, 1, 1, 1.5, 1.5, 2, 2, 330, 7, 1, 40, 52,
> 15, 4, 3, 2, 1, 5, 3, 1, 5, 1234, 5, 6, 34, 107, 12, 6, 6, 1,
> 1, 189, 9, 4, 1, 1, 5, 5, 3, 5, 4, 14, 3, 15, 3.5, 9, 2, 1, 1,
> 1, 10, 133, 109, 8, 1, 2, 1, 13, 1, 1, 2, 4, 60, 4, 2, 2, 226,
> 111, 23, 2, 1, 2, 2, 2, 2, 3, 1, 15, 2, 1, 111, 93, 6, 5, 1,
> 42, 9, 3, 2, 1, 1, 0.75, 1, 0.5, 0.5, 1, 5, 235, 129, 120, 102,
> 41, 63, 11, 5, 0.75, 257, 45, 7, 164, 161, 223, 111, 175, 158,
> 76, 39, 39, 22, 5, 4, 3, 4, 3, 6, 4, 13, 2, 137, 5, 3, 2, 2,
> 1, 47, 1, 1, 1, 256, 29, 51, 427, 54, 15, 131, 52, 6, 329, 111,
> 43, 9, 2, 87, 11, 3, 5, 6, 12, 17, 3, 5, 306, 28, 5, 3, 0.5,
> 1, 0.5, 0.5, 4, 1.5, 3, 2, 3, 2, 3, 2, 2, 2, 507, 10, 70, 12,
> 1, 3, 1, 49, 2, 3, 1, 189, 39, 39, 122, 63, 5, 184, 37, 78, 22,
> 7, 4, 47, 12, 65, 6, 9, 2, 3, 42, 7, 3, 3, 2, 2, 18, 2, 1, 2,
> 2, 9, 10, 3, 3, 3, 32, 13, 5, 98, 442, 51, 6, 101, 5, 2, 2, 6,
> 5, 3, 2, 3, 6, 17, 125, 6, 70, 11, 171, 24.5, 87, 11, 11, 2,
> 2, 137, 16, 35, 5, 2, 2, 3, 2, 3, 3, 3, 2, 1, 8, 2, 3, 61, 119,
> 62, 22, 8, 25, 3, 159, 38, 42, 9, 3, 93, 36, 4, 5, 4, 4, 5, 4,
> 5, 4, 3, 332, 20, 6, 2.5, 7.5, 3, 331, 149.5, 44, 36.5, 311,
> 427, 3, 43.5, 7, 140, 594, 46, 23, 11, 46, 436, 82.5, 600, 53,
> 1.5, 9, 4, 40, 8, 6, 6, 6, 13, 141, 11, 4, 2, 4, 1, 1, 1, 1,
> 1, 1, 1, 21, 6, 4, 1, 1, 553, 93, 41, 40, 4, 2, 2, 4, 1, 3, 2,
> 17, 3, 5, 951, 138, 6, 67, 24, 66, 3, 4, 167, 259, 32, 4, 8,
> 143, 64, 4, 3, 25, 68, 119, 8, 57, 61, 2, 2, 4, 3, 2, 3, 2, 12.61666667,
> 51, 7, 5.916666667, 2, 6, 1, 5, 3, 3, 4.083333333, 8, 7, 1, 1,
> 17, 4, 3, 12, 1, 1, 1, 2, 3, 3, 1, 1, 19, 18, 3, 1, 1, 1, 1,
> 1, 4, 4, 3, 121, 94, 13, 4, 4, 1, 2, 1, 1, 1, 1, 1, 83, 4, 1,
> 4, 2, 1, 1, 2, 5, 3, 1, 1, 23, 6, 12, 28, 12, 4, 4, 4, 3, 10,
> 5, 6, 36, 5, 8, 386, 177.5, 23, 3, 9, 174, 248, 116, 29, 5, 88,
> 56, 4, 11, 30, 9, 8, 14, 6, 28, 139.5, 64, 4, 18, 64, 67, 39,
> 144, 102, 10, 4, 252, 4, 4, 4, 4, 19, 1, 4, 3, 3, 9, 2, 1, 1,
> 314, 44, 12, 87, 7, 132, 26, 14, 16, 7, 10, 8, 107, 40, 33, 18,
> 5, 5, 6, 4, 3, 2, 6, 6, 5, 4, 5, 7, 5, 6, 8, 6, 29, 7, 4, 77,
> 3, 3, 4, 17, 3, 154, 60, 45, 7, 18.5, 8, 5, 118, 56, 6.5, 2,
> 1, 4, 4, 4, 34, 16, 14, 7, 6, 6, 44, 6, 8.5, 2, 1, 1, 9, 1, 16,
> 4, 50, 98, 57, 45, 10, 142, 170, 6, 60, 605, 25, 30, 18.5, 19,
> 9.5, 1, 1, 993.5, 57, 4, 2, 30, 4, 4, 2, 2, 1, 9, 53, 4, 3, 580.75,
> 60, 45, 21, 25, 44, 18, 10, 27, 534.3333333, 4, 10, 2, 63, 14,
> 4, 4, 8, 15, 408, 46, 18, 8, 3, 6, 4, 9, 137.5, 428.49, 78.8,
> 30.49, 9.97, 229.77, 550.175, 167.17, 186.17, 224.855, 609.835,
> 1180, 130.7077449, 229.6460144, 3, 4, 20, 409.1286324, 18, 452,
> 4, 4, 107, 8, 487, 2, 9, 1, 159, 329, 324, 2, 10, 174, 67, 1,
> 42, 43, 4, 3, 3, 104, 9, 1, 1, 4, 32, 1, 1, 2, 238, 237, 190,
> 214, 156, 240, 29, 2, 374, 36, 4, 18, 419, 2, 5, 3, 277, 340,
> 1, 216, 93, 1, 4, 2, 3, 42, 78, 190, 40, 808, 80, 266, 66, 42
> ), .Dim = c(734L, 2L))
> 
> Can you please guide me how to implement the given code on this dataset?
> I thanyou in advance
> ________________________________
> From: Mohammad Tanvir Ahamed <mashranga at yahoo.com>
> Sent: Wednesday 1 September 2021 21:48
> To: r-help at r-project.org <r-help at r-project.org>; Eliza Botto <eliza_botto at outlook.com>
> Subject: Re: [R] conditional replacement of elements of matrix with another matrix column
> 
> C1 <- A
> C1[,2][which(B[,1]%in%A[,1])] <- B[,2][which(B[,1]%in%A[,1])]
> 
> 
> Regards.............
> Tanvir Ahamed
> 
> 
> 
> 
> 
> 
> On Wednesday, 1 September 2021, 11:00:16 pm GMT+2, Eliza Botto <eliza_botto at outlook.com> wrote:
> 
> 
> 
> 
> 
> deaR useRs,
> 
> I have the matrix "A" and matrix "B" and I want the matrix "C". Is there a way of doing it?
> 
>> dput(A)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, NA,
> NA, NA, NA, NA, NA), .Dim = c(9L, 2L))
> 
>> dput(B)
> 
> structure(c(11, 11, 11, 13, 13, 13, 14, 14, 14, 6, 7, 8, 9, 10,
> 11, 12, 13, 14), .Dim = c(9L, 2L))
> 
>> dput(C)
> 
> structure(c(12, 12, 12, 13, 13, 13, 14, 14, 14, NA, NA, NA, 9,
> 10, 11, 12, 13, 14), .Dim = c(9L, 2L))
> 
> Precisely, I want to replace the elements of 2nd column of A with those of B provided the elements of 1st column match. Is there a single line loop or code for that?
> 
> 
> Thanks in advance,
> 
> Eliza Botto
> 
>      [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Sep  2 12:21:30 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 2 Sep 2021 22:21:30 +1200
Subject: [R] What if there's nothing to dispatch on?
In-Reply-To: <6a6ca852-2a8b-7f20-b85f-fadd2c6af769@gmail.com>
References: <20210901155904.33a8f6e0@rolf-Latitude-E7470>
 <c46921e2-4d2a-09f6-110d-376eb188e327@gmail.com>
 <20210902102950.0e873a42@rolf-Latitude-E7470>
 <6a6ca852-2a8b-7f20-b85f-fadd2c6af769@gmail.com>
Message-ID: <20210902222130.6e98bd7f@rolf-Latitude-E7470>


On Wed, 1 Sep 2021 19:29:32 -0400
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

<SNIP>

> I don't know the header of your foo() method, but let's suppose foo()
> is
> 
>    foo <- function(x, data, ...) {
>      UseMethod("foo")
>    }
> 
> with
> 
>    foo.formula <- function(x, data, ...) {
>      # do something with the formula x
>    }
> 
>    foo.default <- function(x, data, ...) {
>      # do the default thing.
>    }
> 
> Now you have
> 
>    xxx <- data.frame(u = 1:10, v = rnorm(10))
>    foo(x = u, y = v, data = xxx)
> 
> You want this to dispatch to the default method, because u is not a 
> formula, it's a column in xxx.  But how do you know that?  Maybe in
> some other part of your code you have
> 
>    u <- someresponse ~ somepredictor

Well I *don't* have such code anywhere, but a user could have such a
formula saved in the global environment.

> So now u *is* a formula, and this will dispatch to the formula
> method, causing havoc.
> 
> I think Bill's suggestion doesn't help here.  To do what you want to
> do doesn't really match what S3 is designed to do.

Yes.  I have come to realise that and have moved away from the S3
classes and method approach. I now have a solution with which I am
basically satisfied.  But I now understand the problem that you raised.
(Sorry to be so slow!  And thank you for the explanation.)

We need to guard against the possibility that a user may invoke the
"non-formula" syntax, foo(x,y,data)  where x is the predictor and y is
the response, and inadvertently trigger the formula syntax because
there is a pre-constructed formula, with the same name as x, hanging
about.

Not really very likely, but certainly not impossible.

I think that the following works:  suppose that x turns out (using
your handy-dandy try() trick) to be a formula.

    x1 <-try(x,silent=TRUE)

If inherits(x1,"formula") firstly check whether this formula exists in
the global environment:

    nmx <- deparse(substitute(x))
    if(exists(nmx,envir=.GlobalEnv)) {
        (throw an error)
    }

I have also added an argument forceFormula=FALSE, which if set to TRUE
prevents the error from being thrown.   Just in case using the formula
named by x *really is* what the user wants to do!

I've tested this out a bit (in my real application) and it seems to
work.  I'm sure that there are other pitfalls and Traps for Young
Players.  E.g. someone might call my function from inside
another function in which the offending formula is constructed.
So the offending formula *won't* be found in the global environment and
the error won't be triggered.  Psigh! Somebody will always be able to
find a way to break things. See fortunes::fortune(15).

However I think the code that I have written is reasonably robust, and
does what I want.  (BTW I want the function to accommodate the
"non-formula" syntax, as well as the formula syntax, to maintain some
semblance of backwards-compatibility.)

Thanks again for (a) the try() trick, and (b) pointing out the lurking
danger.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 13:02:05 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 13:02:05 +0200
Subject: [R] Show only header of str() function
Message-ID: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>

Hello, is it possible to show only the header (that is: `'data.frame':
x obs. of  y variables:` part) of the str function?
Thank you

-- 
Best regards,
Luigi


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 13:31:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 12:31:17 +0100
Subject: [R] Show only header of str() function
In-Reply-To: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
Message-ID: <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>

Hello,

Not perfect but works for data.frames:


header_str <- function(x){
   capture.output(str(x))[[1]]
}
header_str(iris)
header_str(AirPassengers)
header_str(1:10)


Hope this helps,

Rui Barradas

?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
> Hello, is it possible to show only the header (that is: `'data.frame':
> x obs. of  y variables:` part) of the str function?
> Thank you
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 14:47:21 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 14:47:21 +0200
Subject: [R] Show only header of str() function
In-Reply-To: <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
Message-ID: <CAMk+s2T2cpXGJw87eb_DbAEshsTWH1UUNUt1F5EGwQnNtoo6WQ@mail.gmail.com>

Thank you! better than dim() anyway.
Best regards
Luigi

On Thu, Sep 2, 2021 at 1:31 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Not perfect but works for data.frames:
>
>
> header_str <- function(x){
>    capture.output(str(x))[[1]]
> }
> header_str(iris)
> header_str(AirPassengers)
> header_str(1:10)
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
> > Hello, is it possible to show only the header (that is: `'data.frame':
> > x obs. of  y variables:` part) of the str function?
> > Thank you
> >



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 15:18:13 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 15:18:13 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
Message-ID: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>

Hello,
I have some NaN values in some elements of a dataframe that I would
like to convert to NA.
The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
Is there an alternative for the global modification at once of all
instances?
I have seen from
https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
that once could use:
```

is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))

data123[is.nan(data123)] <- 0
```
replacing o with NA, but I got
```
str(df)
> logi NA
```
when modifying my dataframe df.
What would be the correct syntax?
Thank you



-- 
Best regards,
Luigi


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  2 15:29:24 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Sep 2021 13:29:24 +0000
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
Message-ID: <5d3f9164ac3f4edbbd537226caa3cb7f@SRVEXCHCM1302.precheza.cz>

Hi

what about

data[sapply(data, is.nan)] <- NA

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, September 2, 2021 3:18 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] How to globally convert NaN to NA in dataframe?
> 
> Hello,
> I have some NaN values in some elements of a dataframe that I would like
to
> convert to NA.
> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> Is there an alternative for the global modification at once of all
instances?
> I have seen from
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-
> with-zero-in-a-huge-data-frame/18143097#18143097
> that once could use:
> ```
> 
> is.nan.data.frame <- function(x)
> do.call(cbind, lapply(x, is.nan))
> 
> data123[is.nan(data123)] <- 0
> ```
> replacing o with NA, but I got
> ```
> str(df)
> > logi NA
> ```
> when modifying my dataframe df.
> What would be the correct syntax?
> Thank you
> 
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 15:29:54 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 09:29:54 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
Message-ID: <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>

Hello,


I would use something like:


x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
as.data.frame()
x[] <- lapply(x, function(xx) {
    xx[is.nan(xx)] <- NA_real_
    xx
})


This prevents attributes from being changed in 'x', but accomplishes the
same thing as you have above, I hope this helps!

On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have some NaN values in some elements of a dataframe that I would
> like to convert to NA.
> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> Is there an alternative for the global modification at once of all
> instances?
> I have seen from
>
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
> that once could use:
> ```
>
> is.nan.data.frame <- function(x)
> do.call(cbind, lapply(x, is.nan))
>
> data123[is.nan(data123)] <- 0
> ```
> replacing o with NA, but I got
> ```
> str(df)
> > logi NA
> ```
> when modifying my dataframe df.
> What would be the correct syntax?
> Thank you
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 15:35:24 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 15:35:24 +0200
Subject: [R] Loop over columns of dataframe and change values condtionally
Message-ID: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>

Hello,
it is possible to select the columns of a dataframe in sequence with:
```
for(i in 1:ncol(df)) {
  df[ , i]
}
# or
for(i in 1:ncol(df)) {
  df[ i]
}
```
And change all values with, for instance:
```
for(i in 1:ncol(df)) {
  df[ , i] <- df[ , i] + 10
}
```
Is it possible to apply a condition? What would be the syntax?
For instance, to change all 0s in a column to NA would `df[i][df[i ==
0] = NA` be right?
Thank you


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 15:45:33 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 15:45:33 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
Message-ID: <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>

`data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
still get NaN when using the summary function, for instance one of the
columns give:
```
Min.   : NA
1st Qu.: NA
Median : NA
Mean   :NaN
3rd Qu.: NA
Max.   : NA
NA's   :110
```
I tried to implement the second solution but:
```
df <- lapply(x, function(xx) {
  xx[is.nan(xx)] <- NA
})
> str(df)
List of 1
 $ sd_ef_rash_loc___palm: logi NA
```
What am I getting wrong?
Thanks

On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> Hello,
>
>
> I would use something like:
>
>
> x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |> as.data.frame()
> x[] <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
>
>
> This prevents attributes from being changed in 'x', but accomplishes the same thing as you have above, I hope this helps!
>
> On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I have some NaN values in some elements of a dataframe that I would
>> like to convert to NA.
>> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>> Is there an alternative for the global modification at once of all
>> instances?
>> I have seen from
>> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
>> that once could use:
>> ```
>>
>> is.nan.data.frame <- function(x)
>> do.call(cbind, lapply(x, is.nan))
>>
>> data123[is.nan(data123)] <- 0
>> ```
>> replacing o with NA, but I got
>> ```
>> str(df)
>> > logi NA
>> ```
>> when modifying my dataframe df.
>> What would be the correct syntax?
>> Thank you
>>
>>
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 15:47:06 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 09:47:06 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
Message-ID: <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>

You removed the second line 'xx' from the function, put it back and it
should work

On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
> still get NaN when using the summary function, for instance one of the
> columns give:
> ```
> Min.   : NA
> 1st Qu.: NA
> Median : NA
> Mean   :NaN
> 3rd Qu.: NA
> Max.   : NA
> NA's   :110
> ```
> I tried to implement the second solution but:
> ```
> df <- lapply(x, function(xx) {
>   xx[is.nan(xx)] <- NA
> })
> > str(df)
> List of 1
>  $ sd_ef_rash_loc___palm: logi NA
> ```
> What am I getting wrong?
> Thanks
>
> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
> >
> > Hello,
> >
> >
> > I would use something like:
> >
> >
> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> as.data.frame()
> > x[] <- lapply(x, function(xx) {
> >     xx[is.nan(xx)] <- NA_real_
> >     xx
> > })
> >
> >
> > This prevents attributes from being changed in 'x', but accomplishes the
> same thing as you have above, I hope this helps!
> >
> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >>
> >> Hello,
> >> I have some NaN values in some elements of a dataframe that I would
> >> like to convert to NA.
> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> >> Is there an alternative for the global modification at once of all
> >> instances?
> >> I have seen from
> >>
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
> >> that once could use:
> >> ```
> >>
> >> is.nan.data.frame <- function(x)
> >> do.call(cbind, lapply(x, is.nan))
> >>
> >> data123[is.nan(data123)] <- 0
> >> ```
> >> replacing o with NA, but I got
> >> ```
> >> str(df)
> >> > logi NA
> >> ```
> >> when modifying my dataframe df.
> >> What would be the correct syntax?
> >> Thank you
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  2 15:51:00 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 2 Sep 2021 13:51:00 +0000
Subject: [R] 
 Loop over columns of dataframe and change values condtionally
In-Reply-To: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
References: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
Message-ID: <83fe857d702049c3b6a4468959cec5f1@SRVEXCHCM1302.precheza.cz>

Hi

you could operate with whole data frame (sometimes)
head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa

chenge all

> head(iris[,1:4]+10) 
  Sepal.Length Sepal.Width Petal.Length Petal.Width
1         15.1        13.5         11.4        10.2
2         14.9        13.0         11.4        10.2
3         14.7        13.2         11.3        10.2
4         14.6        13.1         11.5        10.2
5         15.0        13.6         11.4        10.2
6         15.4        13.9         11.7        10.4

change only some
> iris[,1:4][iris[,1:4]<2] <- iris[,1:4][iris[,1:4]<2]+10
> head(iris)
  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5         11.4        10.2  setosa
2          4.9         3.0         11.4        10.2  setosa
3          4.7         3.2         11.3        10.2  setosa
4          4.6         3.1         11.5        10.2  setosa
5          5.0         3.6         11.4        10.2  setosa
6          5.4         3.9         11.7        10.4  setosa


Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, September 2, 2021 3:35 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] Loop over columns of dataframe and change values condtionally
> 
> Hello,
> it is possible to select the columns of a dataframe in sequence with:
> ```
> for(i in 1:ncol(df)) {
>   df[ , i]
> }
> # or
> for(i in 1:ncol(df)) {
>   df[ i]
> }
> ```
> And change all values with, for instance:
> ```
> for(i in 1:ncol(df)) {
>   df[ , i] <- df[ , i] + 10
> }
> ```
> Is it possible to apply a condition? What would be the syntax?
> For instance, to change all 0s in a column to NA would `df[i][df[i == 0] =
NA`
> be right?
> Thank you
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 16:01:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 15:01:17 +0100
Subject: [R] 
 Loop over columns of dataframe and change values condtionally
In-Reply-To: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
References: <CAMk+s2T0TaPuYZDywiOH7YOZgr8WUjusN=mDpxP4mMyQ=nW=Uw@mail.gmail.com>
Message-ID: <3916e2d9-a21e-635b-5b48-65494c4d0e15@sapo.pt>

Hello,

In the particular case you have, to change to NA based on condition, use 
`is.na<-`.

Here is some test data, 3 times the same df.


set.seed(2021)
df3 <- df2 <- df1 <- data.frame(
   x = c(0, 0, 1, 2, 3),
   y = c(1, 2, 3, 0, 0),
   z = rbinom(5, 1, prob = c(0.25, 0.75)),
   a = letters[1:5]
)


# change all columns
is.na(df1) <- df1 == 0
df1

# only one column
is.na(df2[, 2]) <- df2[, 2] == 0
df2

# change several columns given by an index
is.na(df3[c(1, 3)]) <- df3[c(1, 3)] == 0
df3


Hope this helps,

Rui Barradas


?s 14:35 de 02/09/21, Luigi Marongiu escreveu:
> Hello,
> it is possible to select the columns of a dataframe in sequence with:
> ```
> for(i in 1:ncol(df)) {
>    df[ , i]
> }
> # or
> for(i in 1:ncol(df)) {
>    df[ i]
> }
> ```
> And change all values with, for instance:
> ```
> for(i in 1:ncol(df)) {
>    df[ , i] <- df[ , i] + 10
> }
> ```
> Is it possible to apply a condition? What would be the syntax?
> For instance, to change all 0s in a column to NA would `df[i][df[i ==
> 0] = NA` be right?
> Thank you
> 
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 16:01:39 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 16:01:39 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
Message-ID: <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>

Sorry,
still I don't get it:
```
> dim(df)
[1] 302 626
> # clean
> df <- lapply(x, function(xx) {
+   xx[is.nan(xx)] <- NA
+   xx
+ })
> dim(df)
NULL
```

On Thu, Sep 2, 2021 at 3:47 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> You removed the second line 'xx' from the function, put it back and it should work
>
> On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
>> still get NaN when using the summary function, for instance one of the
>> columns give:
>> ```
>> Min.   : NA
>> 1st Qu.: NA
>> Median : NA
>> Mean   :NaN
>> 3rd Qu.: NA
>> Max.   : NA
>> NA's   :110
>> ```
>> I tried to implement the second solution but:
>> ```
>> df <- lapply(x, function(xx) {
>>   xx[is.nan(xx)] <- NA
>> })
>> > str(df)
>> List of 1
>>  $ sd_ef_rash_loc___palm: logi NA
>> ```
>> What am I getting wrong?
>> Thanks
>>
>> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> >
>> > I would use something like:
>> >
>> >
>> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |> as.data.frame()
>> > x[] <- lapply(x, function(xx) {
>> >     xx[is.nan(xx)] <- NA_real_
>> >     xx
>> > })
>> >
>> >
>> > This prevents attributes from being changed in 'x', but accomplishes the same thing as you have above, I hope this helps!
>> >
>> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >>
>> >> Hello,
>> >> I have some NaN values in some elements of a dataframe that I would
>> >> like to convert to NA.
>> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>> >> Is there an alternative for the global modification at once of all
>> >> instances?
>> >> I have seen from
>> >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
>> >> that once could use:
>> >> ```
>> >>
>> >> is.nan.data.frame <- function(x)
>> >> do.call(cbind, lapply(x, is.nan))
>> >>
>> >> data123[is.nan(data123)] <- 0
>> >> ```
>> >> replacing o with NA, but I got
>> >> ```
>> >> str(df)
>> >> > logi NA
>> >> ```
>> >> when modifying my dataframe df.
>> >> What would be the correct syntax?
>> >> Thank you
>> >>
>> >>
>> >>
>> >> --
>> >> Best regards,
>> >> Luigi
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Best regards,
>> Luigi



-- 
Best regards,
Luigi


From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 16:17:31 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 10:17:31 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
 <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>
Message-ID: <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>

It seems like you might've missed one more thing, you need the brackets
next to 'x' to get it to work.


x[] <- lapply(x, function(xx) {
    xx[is.nan(xx)] <- NA_real_
    xx
})

is different from

x <- lapply(x, function(xx) {
    xx[is.nan(xx)] <- NA_real_
    xx
})

Also, if all of your data is numeric, it might be better to convert to a
matrix before doing your calculations. For example:

x <- as.matrix(x)
x[is.nan(x)] <- NA_real_

I'd also suggest this same solution for the other question you posted,

x[x == 0] <- NA

On Thu, Sep 2, 2021 at 10:01 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Sorry,
> still I don't get it:
> ```
> > dim(df)
> [1] 302 626
> > # clean
> > df <- lapply(x, function(xx) {
> +   xx[is.nan(xx)] <- NA
> +   xx
> + })
> > dim(df)
> NULL
> ```
>
> On Thu, Sep 2, 2021 at 3:47 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
> >
> > You removed the second line 'xx' from the function, put it back and it
> should work
> >
> > On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >>
> >> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
> >> still get NaN when using the summary function, for instance one of the
> >> columns give:
> >> ```
> >> Min.   : NA
> >> 1st Qu.: NA
> >> Median : NA
> >> Mean   :NaN
> >> 3rd Qu.: NA
> >> Max.   : NA
> >> NA's   :110
> >> ```
> >> I tried to implement the second solution but:
> >> ```
> >> df <- lapply(x, function(xx) {
> >>   xx[is.nan(xx)] <- NA
> >> })
> >> > str(df)
> >> List of 1
> >>  $ sd_ef_rash_loc___palm: logi NA
> >> ```
> >> What am I getting wrong?
> >> Thanks
> >>
> >> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
> wrote:
> >> >
> >> > Hello,
> >> >
> >> >
> >> > I would use something like:
> >> >
> >> >
> >> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> as.data.frame()
> >> > x[] <- lapply(x, function(xx) {
> >> >     xx[is.nan(xx)] <- NA_real_
> >> >     xx
> >> > })
> >> >
> >> >
> >> > This prevents attributes from being changed in 'x', but accomplishes
> the same thing as you have above, I hope this helps!
> >> >
> >> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <
> marongiu.luigi at gmail.com> wrote:
> >> >>
> >> >> Hello,
> >> >> I have some NaN values in some elements of a dataframe that I would
> >> >> like to convert to NA.
> >> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work
> column-wise.
> >> >> Is there an alternative for the global modification at once of all
> >> >> instances?
> >> >> I have seen from
> >> >>
> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
> >> >> that once could use:
> >> >> ```
> >> >>
> >> >> is.nan.data.frame <- function(x)
> >> >> do.call(cbind, lapply(x, is.nan))
> >> >>
> >> >> data123[is.nan(data123)] <- 0
> >> >> ```
> >> >> replacing o with NA, but I got
> >> >> ```
> >> >> str(df)
> >> >> > logi NA
> >> >> ```
> >> >> when modifying my dataframe df.
> >> >> What would be the correct syntax?
> >> >> Thank you
> >> >>
> >> >>
> >> >>
> >> >> --
> >> >> Best regards,
> >> >> Luigi
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
>
>
>
> --
> Best regards,
> Luigi
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 16:29:47 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 16:29:47 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <CAPcHnpTEsoWGcndBzUWtfNj4QJXr5T=_6fsHeKt7MthO36pgkw@mail.gmail.com>
 <CAMk+s2TqNXTj1Ys7QPD3=-F_97+XBgkshZPaLgaLZsHjtqQ+=g@mail.gmail.com>
 <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>
Message-ID: <CAMk+s2RNk3bhB___0Lu+qQPqxFgeU3wcVvyzQu0fAhV-LCqssw@mail.gmail.com>

Thank you!

On Thu, Sep 2, 2021 at 4:17 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> It seems like you might've missed one more thing, you need the brackets next to 'x' to get it to work.
>
>
> x[] <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
>
> is different from
>
> x <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
>
> Also, if all of your data is numeric, it might be better to convert to a matrix before doing your calculations. For example:
>
> x <- as.matrix(x)
> x[is.nan(x)] <- NA_real_
>
> I'd also suggest this same solution for the other question you posted,
>
> x[x == 0] <- NA
>
> On Thu, Sep 2, 2021 at 10:01 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Sorry,
>> still I don't get it:
>> ```
>> > dim(df)
>> [1] 302 626
>> > # clean
>> > df <- lapply(x, function(xx) {
>> +   xx[is.nan(xx)] <- NA
>> +   xx
>> + })
>> > dim(df)
>> NULL
>> ```
>>
>> On Thu, Sep 2, 2021 at 3:47 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>> >
>> > You removed the second line 'xx' from the function, put it back and it should work
>> >
>> > On Thu, Sep 2, 2021, 09:45 Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >>
>> >> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I
>> >> still get NaN when using the summary function, for instance one of the
>> >> columns give:
>> >> ```
>> >> Min.   : NA
>> >> 1st Qu.: NA
>> >> Median : NA
>> >> Mean   :NaN
>> >> 3rd Qu.: NA
>> >> Max.   : NA
>> >> NA's   :110
>> >> ```
>> >> I tried to implement the second solution but:
>> >> ```
>> >> df <- lapply(x, function(xx) {
>> >>   xx[is.nan(xx)] <- NA
>> >> })
>> >> > str(df)
>> >> List of 1
>> >>  $ sd_ef_rash_loc___palm: logi NA
>> >> ```
>> >> What am I getting wrong?
>> >> Thanks
>> >>
>> >> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>> >> >
>> >> > Hello,
>> >> >
>> >> >
>> >> > I would use something like:
>> >> >
>> >> >
>> >> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |> as.data.frame()
>> >> > x[] <- lapply(x, function(xx) {
>> >> >     xx[is.nan(xx)] <- NA_real_
>> >> >     xx
>> >> > })
>> >> >
>> >> >
>> >> > This prevents attributes from being changed in 'x', but accomplishes the same thing as you have above, I hope this helps!
>> >> >
>> >> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >> >>
>> >> >> Hello,
>> >> >> I have some NaN values in some elements of a dataframe that I would
>> >> >> like to convert to NA.
>> >> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>> >> >> Is there an alternative for the global modification at once of all
>> >> >> instances?
>> >> >> I have seen from
>> >> >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-value-with-zero-in-a-huge-data-frame/18143097#18143097
>> >> >> that once could use:
>> >> >> ```
>> >> >>
>> >> >> is.nan.data.frame <- function(x)
>> >> >> do.call(cbind, lapply(x, is.nan))
>> >> >>
>> >> >> data123[is.nan(data123)] <- 0
>> >> >> ```
>> >> >> replacing o with NA, but I got
>> >> >> ```
>> >> >> str(df)
>> >> >> > logi NA
>> >> >> ```
>> >> >> when modifying my dataframe df.
>> >> >> What would be the correct syntax?
>> >> >> Thank you
>> >> >>
>> >> >>
>> >> >>
>> >> >> --
>> >> >> Best regards,
>> >> >> Luigi
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>> >>
>> >> --
>> >> Best regards,
>> >> Luigi
>>
>>
>>
>> --
>> Best regards,
>> Luigi



-- 
Best regards,
Luigi


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 17:45:50 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 11:45:50 -0400
Subject: [R] Show only header of str() function
In-Reply-To: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
Message-ID: <010801d7a011$9b36ff80$d1a4fe80$@verizon.net>

Luigi,

If you are sure you are looking at something like a data.frame, and all you
want o know is how many rows and how many columns are in it, then str() is
perhaps too detailed a tool.

The functions nrow() and ncol() tell you what you want and you can get both
together with dim(). You can, of course, print out whatever message you want
using the numbers supplied by throwing together some function like this:

sstr <- function(x) {
  cat(nrow(x), "obs. of ", ncol(x), " variables\n")
}

Calling that instead of str may meet your needs.  Of course, unlike str, it
will not work on arbitrary data structures.

Note the output of str()goes straight to the screen, similar to what cat
does. Capturing the output to say chop out just the first line is not
therefore a simple option. 


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
Sent: Thursday, September 2, 2021 7:02 AM
To: r-help <r-help at r-project.org>
Subject: [R] Show only header of str() function

Hello, is it possible to show only the header (that is: `'data.frame':
x obs. of  y variables:` part) of the str function?
Thank you

--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep  2 17:56:28 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Sep 2021 17:56:28 +0200
Subject: [R] Show only header of str() function
In-Reply-To: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 (Luigi Marongiu's message of "Thu, 2 Sep 2021 13:02:05 +0200")
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
Message-ID: <87y28fynrn.fsf@enricoschumann.net>

On Thu, 02 Sep 2021, Luigi Marongiu writes:

> Hello, is it possible to show only the header (that is: `'data.frame':
> x obs. of  y variables:` part) of the str function?
> Thank you

Perhaps one more solution. You could limit the number
of list components to be printed, though it will leave
a "truncated" message.

    str(iris, list.len = 0)
    ## 'data.frame':    150 obs. of  5 variables:
    ##   [list output truncated]

Since 'str' is a generic function, you could also
define a new 'str' method. Perhaps something among
those lines:

    str.data.frame.oneline <- function (object, ...) {
        cat("'data.frame':\t", nrow(object), " obs. of  ",
            (p <- length(object)), 
            " variable", if (p != 1) "s", "\n", sep = "")
        invisible(NULL)
    }

(which is essentially taken from 'str.data.frame').

Then:

    class(iris) <- c("data.frame.oneline", class(iris))

    str(iris)
    ## 'data.frame':  150 obs. of  5 variables
    
    str(list(a = 1,
             list(b = 2,
                  c = iris)))
    ## List of 2
    ##  $ a: num 1
    ##  $  :List of 2
    ##   ..$ b: num 2
    ##   ..$ c:'data.frame':   150 obs. of  5 variables




-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 18:32:24 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 09:32:24 -0700 (PDT)
Subject: [R] read.csv() error
Message-ID: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>

The first three commands in the script are:
stage <- read.csv('../data/water/gauge-ht.dat', header = TRUE, sep = ',', 
stringsAsFactors = FALSE)
stage$sampdate <- as.Date(stage$sampdate)
stage$ht <- as.numeric(stage$ht, length = 6)

Running the script produces this error:
> source('stage.R')
Error in `$<-.data.frame`(`*tmp*`, ht, value = numeric(0)) :
   replacement has 0 rows, data has 486336

Sample lines from the data file:
sampdate,samptime,elev
2007-10-01,01:00,2.80
2007-10-01,01:15,2.71
2007-10-01,01:30,2.63
2007-10-01,01:45,2.53
2007-10-01,02:00,2.45
2007-10-01,02:15,2.36
2007-10-01,02:30,2.27
2007-10-01,02:45,2.17
2007-10-01,03:00,2.07

Maximum value for elev is about 11.00, 5 digits.

I don't understand this error because the equivalent commands for another
data source file completes without error.

What is that error message telling me?

TIA,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  2 18:32:56 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 12:32:56 -0400
Subject: [R] Show only header of str() function
In-Reply-To: <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
Message-ID: <013401d7a018$2f6c6090$8e4521b0$@verizon.net>

Thanks for the interesting method Rui. So that is a way to do a redirect of output not to a sinkfile but to an in-memory variable as a textConnection.

Of course, one has to wonder why the makers of str thought it would be too inefficient to have an option that returns the output in a form that can be captured directly, not just to the screen. 

I have in the past done odd things such as using sink() to capture the output of a program that wrote another program dynamically in a loop. The saved file could then be used with source(). So a similar technique can capture the output from str() or cat() or whatever normally only writes to the screen and then the file can be read in to get the first line or whatever you need. I have had to play games to get the right output from some statistical programs too as it was assumed the user would read it, and sometimes had to cherry pick what I needed directly from withing the underlying object.

I suspect one reason R has so many packages including the tidyverse I like to use, is because the original R was designed in another time and in many places is not very consistent. I wonder how hard it would be to change some programs to simply accept an additional argument like sink() has where you can say split=TRUE and get a copy of what is being diverted to also come to the screen. I find cat() to be a very useful way to put more complicated output together than say print() but since it does not allow capture of the text into variables, I end up having to use other methods such as the glue() function or something like print(sprint("Hello %s, I have %d left.\n", "Brian", 5))

But you work with what you have. Your solution works albeit having read the function definition, is quite a bit of overkill when I read the code as it does things not needed. But as noted, if efficiency matters and you are only looking at data.frame style objects, there are cheaper solutions.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
Sent: Thursday, September 2, 2021 7:31 AM
To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
Subject: Re: [R] Show only header of str() function

Hello,

Not perfect but works for data.frames:


header_str <- function(x){
   capture.output(str(x))[[1]]
}
header_str(iris)
header_str(AirPassengers)
header_str(1:10)


Hope this helps,

Rui Barradas

?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
> Hello, is it possible to show only the header (that is: `'data.frame':
> x obs. of  y variables:` part) of the str function?
> Thank you
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep  2 18:43:22 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Sep 2021 18:43:22 +0200
Subject: [R] read.csv() error
In-Reply-To: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com> (Rich
 Shepard's message of "Thu, 2 Sep 2021 09:32:24 -0700 (PDT)")
References: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>
Message-ID: <87sfynyllh.fsf@enricoschumann.net>

On Thu, 02 Sep 2021, Rich Shepard writes:

> The first three commands in the script are:
> stage <- read.csv('../data/water/gauge-ht.dat', header
> = TRUE, sep = ',', stringsAsFactors = FALSE)
> stage$sampdate <- as.Date(stage$sampdate)
> stage$ht <- as.numeric(stage$ht, length = 6)
>
> Running the script produces this error:
>> source('stage.R')
> Error in `$<-.data.frame`(`*tmp*`, ht, value = numeric(0)) :
>   replacement has 0 rows, data has 486336
>
> Sample lines from the data file:
> sampdate,samptime,elev
> 2007-10-01,01:00,2.80
> 2007-10-01,01:15,2.71
> 2007-10-01,01:30,2.63
> 2007-10-01,01:45,2.53
> 2007-10-01,02:00,2.45
> 2007-10-01,02:15,2.36
> 2007-10-01,02:30,2.27
> 2007-10-01,02:45,2.17
> 2007-10-01,03:00,2.07
>
> Maximum value for elev is about 11.00, 5 digits.
>
> I don't understand this error because the equivalent commands for another
> data source file completes without error.
>
> What is that error message telling me?
>
> TIA,
>
> Rich
>

There is no column 'ht'.

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From e@ @end|ng |rom enr|co@chum@nn@net  Thu Sep  2 18:43:22 2021
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Thu, 02 Sep 2021 18:43:22 +0200
Subject: [R] read.csv() error
In-Reply-To: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com> (Rich
 Shepard's message of "Thu, 2 Sep 2021 09:32:24 -0700 (PDT)")
References: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>
Message-ID: <87lf4ezzua.fsf@enricoschumann.net>

On Thu, 02 Sep 2021, Rich Shepard writes:

> The first three commands in the script are:
> stage <- read.csv('../data/water/gauge-ht.dat', header
> = TRUE, sep = ',', stringsAsFactors = FALSE)
> stage$sampdate <- as.Date(stage$sampdate)
> stage$ht <- as.numeric(stage$ht, length = 6)
>
> Running the script produces this error:
>> source('stage.R')
> Error in `$<-.data.frame`(`*tmp*`, ht, value = numeric(0)) :
>   replacement has 0 rows, data has 486336
>
> Sample lines from the data file:
> sampdate,samptime,elev
> 2007-10-01,01:00,2.80
> 2007-10-01,01:15,2.71
> 2007-10-01,01:30,2.63
> 2007-10-01,01:45,2.53
> 2007-10-01,02:00,2.45
> 2007-10-01,02:15,2.36
> 2007-10-01,02:30,2.27
> 2007-10-01,02:45,2.17
> 2007-10-01,03:00,2.07
>
> Maximum value for elev is about 11.00, 5 digits.
>
> I don't understand this error because the equivalent commands for another
> data source file completes without error.
>
> What is that error message telling me?
>
> TIA,
>
> Rich
>

(Sorry, sent too early.)

There is no column 'ht'.

    df <- data.frame(a = 1:5)
    df$b <- as.numeric(df$b)
    ## Error in `$<-.data.frame`(`*tmp*`, b, value = numeric(0)) : 
    ##   replacement has 0 rows, data has 5

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From deep@y@n@@@rk@r @end|ng |rom gm@||@com  Thu Sep  2 19:02:34 2021
From: deep@y@n@@@rk@r @end|ng |rom gm@||@com (Deepayan Sarkar)
Date: Thu, 2 Sep 2021 22:32:34 +0530
Subject: [R] Show only header of str() function
In-Reply-To: <87y28fynrn.fsf@enricoschumann.net>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <87y28fynrn.fsf@enricoschumann.net>
Message-ID: <CADfFDC4i_jDyDRJ44i64+MX=E_xEpKf9+Z5Wq03jOqwWRTO0-A@mail.gmail.com>

On Thu, Sep 2, 2021 at 9:26 PM Enrico Schumann <es at enricoschumann.net> wrote:
>
> On Thu, 02 Sep 2021, Luigi Marongiu writes:
>
> > Hello, is it possible to show only the header (that is: `'data.frame':
> > x obs. of  y variables:` part) of the str function?
> > Thank you
>
> Perhaps one more solution. You could limit the number
> of list components to be printed, though it will leave
> a "truncated" message.
>
>     str(iris, list.len = 0)
>     ## 'data.frame':    150 obs. of  5 variables:
>     ##   [list output truncated]

Or use 'max.level', which is also generally useful for nested lists:

str(iris, max.level=0)
## 'data.frame':    150 obs. of  5 variables:

Best,
-Deepayan

> Since 'str' is a generic function, you could also
> define a new 'str' method. Perhaps something among
> those lines:
>
>     str.data.frame.oneline <- function (object, ...) {
>         cat("'data.frame':\t", nrow(object), " obs. of  ",
>             (p <- length(object)),
>             " variable", if (p != 1) "s", "\n", sep = "")
>         invisible(NULL)
>     }
>
> (which is essentially taken from 'str.data.frame').
>
> Then:
>
>     class(iris) <- c("data.frame.oneline", class(iris))
>
>     str(iris)
>     ## 'data.frame':  150 obs. of  5 variables
>
>     str(list(a = 1,
>              list(b = 2,
>                   c = iris)))
>     ## List of 2
>     ##  $ a: num 1
>     ##  $  :List of 2
>     ##   ..$ b: num 2
>     ##   ..$ c:'data.frame':   150 obs. of  5 variables
>
>
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 19:05:46 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 10:05:46 -0700 (PDT)
Subject: [R] read.csv() error
In-Reply-To: <87sfynyllh.fsf@enricoschumann.net>
References: <alpine.LNX.2.20.2109020931350.18288@salmo.appl-ecosys.com>
 <87sfynyllh.fsf@enricoschumann.net>
Message-ID: <alpine.LNX.2.20.2109021005000.18288@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Enrico Schumann wrote:

> There is no column 'ht'.

Enrico,

New eyeballs caught my change in variable name that I kept missing.

Thanks very much,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 20:16:16 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 11:16:16 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>

On Mon, 30 Aug 2021, Richard O'Keefe wrote:

>> x <- rnorm(samples.per.day * 365)
>> length(x)
> [1] 105120
>
> Reshape the fake data into a matrix where each row represents one
> 24-hour period.
>
>> m <- matrix(x, ncol=samples.per.day, byrow=TRUE)

Richard,

Now I understand the need to keep the date and time as a single datetime
column; separately dplyr's sumamrize() provides daily means (too many data
points to plot over 3-5 years). I reformatted the data to provide a
sampledatetime column and a values column.

If I correctly understand the output of as.POSIXlt each date and time
element is separate, so input such as 2016-03-03 12:00 would now be 2016 03
03 12 00 (I've not read how the elements are separated). (The TZ is not
important because all data are either PST or PDT.)

> Now we can summarise the rows any way we want.
> The basic tool here is ?apply.
> ?rowMeans is said to be faster than using apply to calculate means,
> so we'll use that.  There is no *rowSds so we have to use apply
> for the standard deviation.  I use ?head because I don't want to
> post tens of thousands of meaningless numbers.

If I create a matrix using the above syntax the resulting rows contain all
recorded values for a specific day. What would be the syntax to collect all
values for each month?

This would result in 12 rows per year; the periods of record for the five
variables availble from that gauge station vary in length.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 20:42:41 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 11:42:41 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Rich Shepard wrote:

> If I correctly understand the output of as.POSIXlt each date and time
> element is separate, so input such as 2016-03-03 12:00 would now be 2016 03
> 03 12 00 (I've not read how the elements are separated). (The TZ is not
> important because all data are either PST or PDT.)

Using this script:
discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE)
discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
                                  format = '%Y-%m-%d %H:%M',
                                  optional = 'logical')
discharge$cfs <- as.numeric(discharge$cfs, length = 6)

I get this result:
> head(discharge)
              sampdate    cfs
1 2016-03-03 12:00:00 149000
2 2016-03-03 12:10:00 150000
3 2016-03-03 12:20:00 151000
4 2016-03-03 12:30:00 156000
5 2016-03-03 12:40:00 154000
6 2016-03-03 12:50:00 150000

I'm completely open to suggestions on using this output to calculate monthly
means and sds.

If dplyr:summarize() will do so please show me how to modify this command:
disc_monthly <- ( discharge
         %>% group_by(sampdate)
         %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
because it produces daily means, not monthly means.

TIA,

Rich


From @kw@|mmo @end|ng |rom gm@||@com  Thu Sep  2 21:10:15 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 2 Sep 2021 15:10:15 -0400
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
Message-ID: <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>

You could use 'split' to create a list of data frames, and then apply a
function to each to get the means and sds.


cols <- "cfs"  # add more as necessary
S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
TRUE)))

On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Thu, 2 Sep 2021, Rich Shepard wrote:
>
> > If I correctly understand the output of as.POSIXlt each date and time
> > element is separate, so input such as 2016-03-03 12:00 would now be 2016
> 03
> > 03 12 00 (I've not read how the elements are separated). (The TZ is not
> > important because all data are either PST or PDT.)
>
> Using this script:
> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep =
> ',', stringsAsFactors = FALSE)
> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
>                                   format = '%Y-%m-%d %H:%M',
>                                   optional = 'logical')
> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>
> I get this result:
> > head(discharge)
>               sampdate    cfs
> 1 2016-03-03 12:00:00 149000
> 2 2016-03-03 12:10:00 150000
> 3 2016-03-03 12:20:00 151000
> 4 2016-03-03 12:30:00 156000
> 5 2016-03-03 12:40:00 154000
> 6 2016-03-03 12:50:00 150000
>
> I'm completely open to suggestions on using this output to calculate
> monthly
> means and sds.
>
> If dplyr:summarize() will do so please show me how to modify this command:
> disc_monthly <- ( discharge
>          %>% group_by(sampdate)
>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
> because it produces daily means, not monthly means.
>
> TIA,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|n@h@|| @end|ng |rom um|ch@edu  Thu Sep  2 21:20:56 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Thu, 02 Sep 2021 22:20:56 +0300
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: Your message of "Thu, 02 Sep 2021 10:17:31 -0400."
 <CAPcHnpTtapJMLwv0Q-W1w8zzynthrC+myJO1zWiARAo8gbiyKw@mail.gmail.com>
Message-ID: <1021538.1630610456@apollo2.minshall.org>

Andrew,

> x[] <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })
> 
> is different from
> 
> x <- lapply(x, function(xx) {
>     xx[is.nan(xx)] <- NA_real_
>     xx
> })

indeed, the two are different -- but some ignorance of mine is exposed.
i wonder, can you explain why the two are different?

is it because of (or, "is the clue...") this in the "Value:" section of
: ?"[<-.data.frame"
----
     For '[<-', '[[<-' and '$<-', a data frame.
----
?

cheers, Greg


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Sep  2 21:31:40 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 2 Sep 2021 12:31:40 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109021230300.18288@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Andrew Simmons wrote:

> You could use 'split' to create a list of data frames, and then apply a
> function to each to get the means and sds.
>
> cols <- "cfs"  # add more as necessary
> S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
> means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
> sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
> TRUE)))

Andrew,

Thank you for the valuable lesson. This is new to me and I know I'll have
use for it in the future, too.

Much appreciated!

Stay well,

Rich


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  2 21:40:46 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 02 Sep 2021 12:40:46 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
Message-ID: <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>

Regardless of whether you use the lower-level split function, or the higher-level aggregate function, or the tidyverse group_by function, the key is learning how to create the column that is the same for all records corresponding to the time interval of interest.

If you convert the sampdate to POSIXct, the tz IS important, because most of us use local timezones that respect daylight savings time, and a naive conversion of standard time will run into trouble if R is assuming daylight savings time applies. The lubridate package gets around this by always assuming UTC and giving you a function to "fix" the timezone after the conversion. I prefer to always be specific about timezones, at least by using so something like

    Sys.setenv( TZ = "Etc/GMT+8" )

which does not respect daylight savings.

Regarding using character data for identifying the month, in order to have clean plots of the data I prefer to use the trunc function but it returns a POSIXlt so I convert it to POSIXct:

    discharge$sampmonthbegin <- as.POSIXct( trunc( discharge$sampdate, units = "months" ) )

Then any of various ways can be used to aggregate the records by that column.

On September 2, 2021 12:10:15 PM PDT, Andrew Simmons <akwsimmo at gmail.com> wrote:
>You could use 'split' to create a list of data frames, and then apply a
>function to each to get the means and sds.
>
>
>cols <- "cfs"  # add more as necessary
>S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
>means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
>sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
>TRUE)))
>
>On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
>wrote:
>
>> On Thu, 2 Sep 2021, Rich Shepard wrote:
>>
>> > If I correctly understand the output of as.POSIXlt each date and time
>> > element is separate, so input such as 2016-03-03 12:00 would now be 2016
>> 03
>> > 03 12 00 (I've not read how the elements are separated). (The TZ is not
>> > important because all data are either PST or PDT.)
>>
>> Using this script:
>> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep =
>> ',', stringsAsFactors = FALSE)
>> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
>>                                   format = '%Y-%m-%d %H:%M',
>>                                   optional = 'logical')
>> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>>
>> I get this result:
>> > head(discharge)
>>               sampdate    cfs
>> 1 2016-03-03 12:00:00 149000
>> 2 2016-03-03 12:10:00 150000
>> 3 2016-03-03 12:20:00 151000
>> 4 2016-03-03 12:30:00 156000
>> 5 2016-03-03 12:40:00 154000
>> 6 2016-03-03 12:50:00 150000
>>
>> I'm completely open to suggestions on using this output to calculate
>> monthly
>> means and sds.
>>
>> If dplyr:summarize() will do so please show me how to modify this command:
>> disc_monthly <- ( discharge
>>          %>% group_by(sampdate)
>>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
>> because it produces daily means, not monthly means.
>>
>> TIA,
>>
>> Rich
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  2 21:44:07 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 2 Sep 2021 15:44:07 -0400
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <1021538.1630610456@apollo2.minshall.org>
References: <1021538.1630610456@apollo2.minshall.org>
Message-ID: <9df5d40e-f922-1282-025f-2b6b0b09e2e6@gmail.com>

On 02/09/2021 3:20 p.m., Greg Minshall wrote:
> Andrew,
> 
>> x[] <- lapply(x, function(xx) {
>>      xx[is.nan(xx)] <- NA_real_
>>      xx
>> })
>>
>> is different from
>>
>> x <- lapply(x, function(xx) {
>>      xx[is.nan(xx)] <- NA_real_
>>      xx
>> })
> 
> indeed, the two are different -- but some ignorance of mine is exposed.
> i wonder, can you explain why the two are different?

x <- lapply(...) says "set x to the list on the RHS", so x becomes a 
list, not a dataframe.

x[] <- lapply(...) says "set the values in x to the values in the list 
on the RHS", so x retains its class.

Duncan Murdoch


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep  2 22:04:31 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 2 Sep 2021 21:04:31 +0100
Subject: [R] Show only header of str() function
In-Reply-To: <013401d7a018$2f6c6090$8e4521b0$@verizon.net>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <ca4ddb3d-110d-fe3f-240c-b8ba0217a146@sapo.pt>
 <013401d7a018$2f6c6090$8e4521b0$@verizon.net>
Message-ID: <fc87a627-f9b7-6c81-afb1-ad74c340c149@sapo.pt>

Hello,

I believe but do not have references that str was meant for interactive 
use, not for use in a script or package. If this is the case, then it 
should be rare to have to output to an object such as a character vector.

As for my solution, it is far from perfect, I try to avoid 
capture.output and, once again, limit its use to interactive R. It is 
overkill but I use it so few times that performance issues probably do 
not matter. It is sometimes a convenient way of solving an immediate 
problem and once done, move on.

As for the OP, Enrico's solution seems better, even with the 2nd printed 
line. Unless the 1st line is to be processed (?).

Hope this helps,

Rui Barradas

?s 17:32 de 02/09/21, Avi Gross via R-help escreveu:
> Thanks for the interesting method Rui. So that is a way to do a redirect of output not to a sinkfile but to an in-memory variable as a textConnection.
> 
> Of course, one has to wonder why the makers of str thought it would be too inefficient to have an option that returns the output in a form that can be captured directly, not just to the screen.
> 
> I have in the past done odd things such as using sink() to capture the output of a program that wrote another program dynamically in a loop. The saved file could then be used with source(). So a similar technique can capture the output from str() or cat() or whatever normally only writes to the screen and then the file can be read in to get the first line or whatever you need. I have had to play games to get the right output from some statistical programs too as it was assumed the user would read it, and sometimes had to cherry pick what I needed directly from withing the underlying object.
> 
> I suspect one reason R has so many packages including the tidyverse I like to use, is because the original R was designed in another time and in many places is not very consistent. I wonder how hard it would be to change some programs to simply accept an additional argument like sink() has where you can say split=TRUE and get a copy of what is being diverted to also come to the screen. I find cat() to be a very useful way to put more complicated output together than say print() but since it does not allow capture of the text into variables, I end up having to use other methods such as the glue() function or something like print(sprint("Hello %s, I have %d left.\n", "Brian", 5))
> 
> But you work with what you have. Your solution works albeit having read the function definition, is quite a bit of overkill when I read the code as it does things not needed. But as noted, if efficiency matters and you are only looking at data.frame style objects, there are cheaper solutions.
> 
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
> Sent: Thursday, September 2, 2021 7:31 AM
> To: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
> Subject: Re: [R] Show only header of str() function
> 
> Hello,
> 
> Not perfect but works for data.frames:
> 
> 
> header_str <- function(x){
>     capture.output(str(x))[[1]]
> }
> header_str(iris)
> header_str(AirPassengers)
> header_str(1:10)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 12:02 de 02/09/21, Luigi Marongiu escreveu:
>> Hello, is it possible to show only the header (that is: `'data.frame':
>> x obs. of  y variables:` part) of the str function?
>> Thank you
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep  2 22:25:25 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 2 Sep 2021 22:25:25 +0200
Subject: [R] Show only header of str() function
In-Reply-To: <CADfFDC4i_jDyDRJ44i64+MX=E_xEpKf9+Z5Wq03jOqwWRTO0-A@mail.gmail.com>
References: <CAMk+s2Q9QxN9fNdCEyEgjXw4Gvn72K4C=3N2r7cm7Q94g7XX2w@mail.gmail.com>
 <87y28fynrn.fsf@enricoschumann.net>
 <CADfFDC4i_jDyDRJ44i64+MX=E_xEpKf9+Z5Wq03jOqwWRTO0-A@mail.gmail.com>
Message-ID: <CAMk+s2T3zgvd69nAij2dMz2xYgGe2XwmN+5KmCRMfKdX6MYMyg@mail.gmail.com>

Thanks, that is perfect!

On Thu, Sep 2, 2021 at 7:02 PM Deepayan Sarkar
<deepayan.sarkar at gmail.com> wrote:
>
> On Thu, Sep 2, 2021 at 9:26 PM Enrico Schumann <es at enricoschumann.net> wrote:
> >
> > On Thu, 02 Sep 2021, Luigi Marongiu writes:
> >
> > > Hello, is it possible to show only the header (that is: `'data.frame':
> > > x obs. of  y variables:` part) of the str function?
> > > Thank you
> >
> > Perhaps one more solution. You could limit the number
> > of list components to be printed, though it will leave
> > a "truncated" message.
> >
> >     str(iris, list.len = 0)
> >     ## 'data.frame':    150 obs. of  5 variables:
> >     ##   [list output truncated]
>
> Or use 'max.level', which is also generally useful for nested lists:
>
> str(iris, max.level=0)
> ## 'data.frame':    150 obs. of  5 variables:
>
> Best,
> -Deepayan
>
> > Since 'str' is a generic function, you could also
> > define a new 'str' method. Perhaps something among
> > those lines:
> >
> >     str.data.frame.oneline <- function (object, ...) {
> >         cat("'data.frame':\t", nrow(object), " obs. of  ",
> >             (p <- length(object)),
> >             " variable", if (p != 1) "s", "\n", sep = "")
> >         invisible(NULL)
> >     }
> >
> > (which is essentially taken from 'str.data.frame').
> >
> > Then:
> >
> >     class(iris) <- c("data.frame.oneline", class(iris))
> >
> >     str(iris)
> >     ## 'data.frame':  150 obs. of  5 variables
> >
> >     str(list(a = 1,
> >              list(b = 2,
> >                   c = iris)))
> >     ## List of 2
> >     ##  $ a: num 1
> >     ##  $  :List of 2
> >     ##   ..$ b: num 2
> >     ##   ..$ c:'data.frame':   150 obs. of  5 variables
> >
> >
> >
> >
> > --
> > Enrico Schumann
> > Lucerne, Switzerland
> > http://enricoschumann.net
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From e||z@_botto @end|ng |rom out|ook@com  Fri Sep  3 00:44:10 2021
From: e||z@_botto @end|ng |rom out|ook@com (Eliza Botto)
Date: Thu, 2 Sep 2021 22:44:10 +0000
Subject: [R] plotting some rows in different color
Message-ID: <AS8P194MB099914EF5653553F8FC81E879ACE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>

Dear useRs,

For the following dataset,

dput(BFA3)

structure(c(17532, 17533, 17534, 17535, 17536, 17537, 17538,
17539, 17540, 17541, 17542, 17543, 17544, 17545, 17546, 17547,
17548, 17549, 17550, 17551, 17552, 17553, 17554, 17555, 17556,
17557, 17558, 17559, 17560, 17561, 17562, 17563, 17564, 17565,
17566, 17567, 17568, 17569, 17570, 17571, 17572, 17573, 17574,
17575, 17576, 17577, 17578, 17579, 17580, 17581, 17582, 17583,
17584, 17585, 17586, 17587, 17588, 17589, 17590, 17591, 17592,
17593, 17594, 17595, 17596, 17597, 17598, 17599, 17600, 17601,
17602, 17603, 17604, 17605, 17606, 17607, 17608, 17609, 17610,
17611, 17612, 17613, 17614, 17615, 17616, 17617, 17618, 17619,
17620, 17621, 17622, 17623, 17624, 17625, 17626, 17627, 17628,
17629, 17630, 17631, 17632, 17633, 17634, 17635, 17636, 17637,
17638, 17639, 17640, 17641, 17642, 17643, 17644, 17645, 17646,
17647, 17648, 17649, 17650, 17651, 17652, 17653, 17654, 17655,
17656, 17657, 17658, 17659, 17660, 17661, 17662, 17663, 17664,
17665, 17666, 17667, 17668, 17669, 17670, 17671, 17672, 17673,
17674, 17675, 17676, 17677, 17678, 17679, 17680, 17681, 17682,
17683, 17684, 17685, 17686, 17687, 17688, 17689, 17690, 17691,
17692, 17693, 17694, 17695, 17696, 17697, 17698, 17699, 17700,
17701, 17702, 17703, 17704, 17705, 17706, 17707, 17708, 17709,
17710, 17711, 17712, 17713, 17714, 17715, 17716, 17717, 17718,
17719, 17720, 17721, 17722, 17723, 17724, 17725, 17726, 17727,
17728, 17729, 17730, 17731, 17732, 17733, 17734, 17735, 17736,
17737, 17738, 17739, 17740, 17741, 17742, 17743, 17744, 17745,
17746, 17747, 17748, 17749, 17750, 17751, 17752, 17753, 17754,
17755, 17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763,
17764, 17765, 17766, 17767, 17768, 17769, 17770, 17771, 17772,
17773, 17774, 17775, 17776, 17777, 17778, 17779, 17780, 17781,
17782, 17783, 17784, 17785, 17786, 17787, 17788, 17789, 17790,
17791, 17792, 17793, 17794, 17795, 17796, 17797, 17798, 17799,
17800, 17801, 17802, 17803, 17804, 17805, 17806, 17807, 17808,
17809, 17810, 17811, 17812, 17813, 17814, 17815, 17816, 17817,
17818, 17819, 17820, 17821, 17822, 17823, 17824, 17825, 17826,
17827, 17828, 17829, 17830, 17831, 17832, 17833, 17834, 17835,
17836, 17837, 17838, 17839, 17840, 17841, 17842, 17843, 17844,
17845, 17846, 17847, 17848, 17849, 17850, 17851, 17852, 17853,
17854, 17855, 17856, 17857, 17858, 17859, 17860, 17861, 17862,
17863, 17864, 17865, 17866, 17867, 17868, 17869, 17870, 17871,
17872, 17873, 17874, 17875, 17876, 17877, 17878, 17879, 17880,
17881, 17882, 17883, 17884, 17885, 17886, 17887, 17888, 17889,
17890, 17891, 17892, 17893, 17894, 17895, 17896, 8.36875, 15.12875,
14.2825, 12.355, 13.1825, 88.58375, 47.52125, 26.53375, 22.85875,
12.4925, 9.86875, 13.125, 14.055, 14.0175, 14.70625, 15.46125,
11.8725, 17.505, 19.8575, 74.875445, 62.018935, 23.9481046910236,
9.68, 9.6175, 9.78, 9.8875, 9.5125, 9.885, 9.99, 14.16625, 11.99375,
10.7875, 9.85625, 12.17125, 11.76625, 11.0425, 9.28875, 9.425,
23.29375, 12.66875, 9.6, 10.06875, 10.055, 30.89625, 36.69375,
16.63875, 11.84625, 12.825, 14.94, 11.495, 10.795, 9.14625, 10.17875,
11.0525, 10.0175, 10.67625, 10.4325, 12.5175, 13.93, 14.1675,
17.3175, 18.3875, 12.06, 10.3125, 9.94125, 10.8575, 11.2425,
13.28875, 43.885, 76.225, 125.277272727273, 198.285, 181.40125,
113.38875, 89.7925, 108.27875, 100.24375, 103.57, 189.015, 190.8925,
113.76875, 109.055, 96.4925, 99.04625, 127.47125, 300.86, 250.0725,
108.72125, 54.61, 39.76625, 30.11875, 31.46875, 40.73, 40.63,
27.48125, 24.9125, 24.105, 53.65625, 209.77125, 281.53125, 460.90875,
296.4225, 349.58375, 494.825, 404.4475, 510.68125, 681.65625,
637.78125, 838.40125, 740.0875, 601.81375, 246.75625, 127.1725,
92.36875, 78.11875, 73.61625, 62.77875, 59.87, 106.36, 115.31125,
64.025, 96.30125, 97.50625, 92.875, 92.49875, 89.295, 84.46375,
80.05625, 80.745, 114.13, 91.3225, 79.72125, 70.555, 30.8975,
14.28625, 13.02875, 93.59125, 246.7875, 54.37125, 29.45375, 16.2725,
15.175, 15.1475, 16.27875, 15.0575, 14.0425, 11.675, 12.9275,
11.26, 12.56, 183.555, 413.2025, 111.46375, 43.01375, 27.66125,
17.55875, 15.28, 14.88875, 14.60875, 14.44625, 281.95125, 85.16875,
24.6675, 14.88875, 15.02, 23.35125, 65.385, 83.95, 37.675, 22.31375,
15.1075, 15.02625, 96.39, 1856.72375, 612.275, 97.04875, 46.065,
28.62125, 23.22875, 234.78375, 58.21375, 33.29, 55.595, 66.57375,
81.39875, 42.84625, 26.945, 20.00375, 14.26875, 14.87625, 82.975,
85.12125, 35.7575, 26.875, 40.36375, 28.63875, 15.68, 13.70125,
29.42625, 51.81125, 26.6125, 15.56375, 13.725, 191.72625, 376.08625,
66.27875, 72.0275, 47.50375, 26.555, 16.58625, 16.9275, 15.26875,
33.3125, 64.98625, 66.93875, 194.75875, 65.15, 29.03375, 15.545,
14.83625, 14.89, 15.08875, 14.71, 146.1525, 112.855, 34.10625,
16.46625, 15.0175, 15.06125, 13.94625, 12.1075, 14.265, 14.30125,
13.77125, 12.51, 181.65625, 82.07875, 59.46125, 209.9875, 42.5525,
22.19, 32.95, 19.89875, 37.7175, 29.62875, 41.705, 34.1225, 23.7275,
20.565, 17.61125, 16.53125, 15.75125, 119.1025, 79.8675, 27.6375,
15.6675, 13.955, 16.54875, 24.2075, 21.97875, 17.3525, 19.9875,
18.2275, 109.57875, 73.06625, 47.2775, 50.1475, 28.66875, 17.8,
373.38375, 96.49875, 62.55125, 24.56375, 26.7675, 109.57375,
265.26125, 161.6575, 86.80375, 67.98, 62.88125, 64.88625, 97.665,
77.29125, 52.015, 81.7925, 75.305, 45.81875, 39.425, 37.78625,
35.40125, 32.1275, 31.89875, 31.77125, 30.1575, 28.62875, 28.065,
29.6875, 28.47125, 25.525, 25.2125, 22.68125, 22.81625, 20.165,
18.03125, 18.0425, 18.945, 19.88125, 24.6225, 25.6025, 24.65125,
31.76375, 27.41375, 22.8075, 28.64, 25.06875, 26.36125, 29.74625,
23.1, 19.67, 30.01625, 27.285, 43.90125, 50.1425, 33.45375, 23.2225,
19.91625, 27.22875, 46.14125, 33.70375, 38.7525, 178.45625, 85.08,
37.93875, 22.4225, 23.45125, 34.1375, 22.3325, 18.7125, 17.5375,
16.07625, 15.07375, 15.035, 15.16875, 15.6225, 15.9125, 15.3325,
15.09, 14.91125, 14.94125, 14.8325, 14.86375, 14.9675, 14.895,
14.81, 14.77125, 13.66625, 13.135, 13.00875, 12.86375, 12.9525,
13.0675, 12.97, 13.02, 13.10375, 12.96, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, 9.86875, 9.84942307692308, 9.83009615384615,
9.81076923076923, 9.79144230769231, 9.77211538461539, 9.75278846153846,
9.73346153846154, 9.71413461538462, 9.69480769230769, 9.67548076923077,
9.65615384615385, 9.63682692307692, 9.6175, 9.5825, 9.5475, 9.5125,
9.56979166666667, 9.62708333333333, 9.684375, 9.74166666666667,
9.79895833333333, 9.85625, 9.714375, 9.5725, 9.430625, 9.28875,
9.3665625, 9.444375, 9.5221875, 9.6, 9.55875, 9.5175, 9.47625,
9.435, 9.39375, 9.3525, 9.31125, 9.27, 9.22875, 9.1875, 9.14625,
9.20740384615385, 9.26855769230769, 9.32971153846154, 9.39086538461538,
9.45201923076923, 9.51317307692308, 9.57432692307692, 9.63548076923077,
9.69663461538462, 9.75778846153846, 9.81894230769231, 9.88009615384615,
9.94125, 10.8575, 11.2425, 11.7121774193548, 12.1395161290323,
12.5668548387097, 12.9941935483871, 13.4215322580645, 13.8488709677419,
14.2762096774194, 14.7035483870968, 15.1308870967742, 15.5582258064516,
15.985564516129, 16.4129032258065, 16.8402419354839, 17.2675806451613,
17.6949193548387, 18.1222580645161, 18.5495967741935, 18.976935483871,
19.4042741935484, 19.8316129032258, 20.2589516129032, 20.6862903225806,
21.1136290322581, 21.5409677419355, 21.9683064516129, 22.3956451612903,
22.8229838709677, 23.2503225806452, 23.6776612903226, 24.105,
25.8080952380952, 27.5111904761905, 29.2142857142857, 30.917380952381,
32.6204761904762, 34.3235714285714, 36.0266666666667, 37.7297619047619,
39.4328571428571, 41.1359523809524, 42.8390476190476, 44.5421428571429,
46.2452380952381, 47.9483333333333, 49.6514285714286, 51.3545238095238,
53.057619047619, 54.7607142857143, 56.4638095238095, 58.1669047619048,
59.87, 61.255, 62.64, 64.025, 60.4722321428572, 56.9194642857143,
53.3666964285714, 49.8139285714286, 46.2611607142857, 42.7083928571429,
39.155625, 35.6028571428571, 32.0500892857143, 28.4973214285714,
24.9445535714286, 21.3917857142857, 17.8390178571429, 14.28625,
13.02875, 12.8926923076923, 12.7566346153846, 12.6205769230769,
12.4845192307692, 12.3484615384615, 12.2124038461538, 12.0763461538462,
11.9402884615385, 11.8042307692308, 11.6681730769231, 11.5321153846154,
11.3960576923077, 11.26, 11.5496590909091, 11.8393181818182,
12.1289772727273, 12.4186363636364, 12.7082954545455, 12.9979545454545,
13.2876136363636, 13.5772727272727, 13.8669318181818, 14.1565909090909,
14.44625, 14.556875, 14.6675, 14.778125, 14.88875, 14.9059375,
14.923125, 14.9403125, 14.9575, 14.9746875, 14.991875, 15.0090625,
15.02625, 14.9816911764706, 14.9371323529412, 14.8925735294118,
14.8480147058824, 14.8034558823529, 14.7588970588235, 14.7143382352941,
14.6697794117647, 14.6252205882353, 14.5806617647059, 14.5361029411765,
14.4915441176471, 14.4469852941176, 14.4024264705882, 14.3578676470588,
14.3133088235294, 14.26875, 14.2056944444444, 14.1426388888889,
14.0795833333333, 14.0165277777778, 13.9534722222222, 13.8904166666667,
13.8273611111111, 13.7643055555556, 13.70125, 13.706, 13.71075,
13.7155, 13.72025, 13.725, 13.8965277777778, 14.0680555555556,
14.2395833333333, 14.4111111111111, 14.5826388888889, 14.7541666666667,
14.9256944444444, 15.0972222222222, 15.26875, 15.2146875, 15.160625,
15.1065625, 15.0525, 14.9984375, 14.944375, 14.8903125, 14.83625,
14.7941666666667, 14.7520833333333, 14.71, 14.3846875, 14.059375,
13.7340625, 13.40875, 13.0834375, 12.758125, 12.4328125, 12.1075,
12.1785576923077, 12.2496153846154, 12.3206730769231, 12.3917307692308,
12.4627884615385, 12.5338461538462, 12.6049038461538, 12.6759615384615,
12.7470192307692, 12.8180769230769, 12.8891346153846, 12.9601923076923,
13.03125, 13.1023076923077, 13.1733653846154, 13.2444230769231,
13.3154807692308, 13.3865384615385, 13.4575961538462, 13.5286538461538,
13.5997115384615, 13.6707692307692, 13.7418269230769, 13.8128846153846,
13.8839423076923, 13.955, 14.2754166666667, 14.5958333333333,
14.91625, 15.2366666666667, 15.5570833333333, 15.8775, 16.1979166666667,
16.5183333333333, 16.83875, 17.1591666666667, 17.4795833333333,
17.8, 17.8066071428571, 17.8132142857143, 17.8198214285714, 17.8264285714286,
17.8330357142857, 17.8396428571429, 17.84625, 17.8528571428571,
17.8594642857143, 17.8660714285714, 17.8726785714286, 17.8792857142857,
17.8858928571429, 17.8925, 17.8991071428571, 17.9057142857143,
17.9123214285714, 17.9189285714286, 17.9255357142857, 17.9321428571429,
17.93875, 17.9453571428571, 17.9519642857143, 17.9585714285714,
17.9651785714286, 17.9717857142857, 17.9783928571429, 17.985,
17.9916071428571, 17.9982142857143, 18.0048214285714, 18.0114285714286,
18.0180357142857, 18.0246428571429, 18.03125, 18.0425, 18.945,
19.0007692307692, 19.0565384615385, 19.1123076923077, 19.1680769230769,
19.2238461538462, 19.2796153846154, 19.3353846153846, 19.3911538461538,
19.4469230769231, 19.5026923076923, 19.5584615384615, 19.6142307692308,
19.67, 19.7051785714286, 19.7403571428571, 19.7755357142857,
19.8107142857143, 19.8458928571429, 19.8810714285714, 19.91625,
19.6419642857143, 19.3676785714286, 19.0933928571429, 18.8191071428571,
18.5448214285714, 18.2705357142857, 17.99625, 17.7219642857143,
17.4476785714286, 17.1733928571429, 16.8991071428571, 16.6248214285714,
16.3505357142857, 16.07625, 15.07375, 15.035, 15.0096875, 14.984375,
14.9590625, 14.93375, 14.9084375, 14.883125, 14.8578125, 14.8325,
14.61375, 14.395, 14.17625, 13.9575, 13.73875, 13.52, 13.135,
13.00875, 12.86375, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, NA,
3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
NA, NA, NA, NA, NA, NA, 1, 4, NA, NA, NA, NA, NA, NA, 2, NA,
NA, NA, NA, NA, 4, 9, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA,
18, 12, 22, 22, 40, NA, NA, NA, NA, 19.5, 14, 17, NA, NA, NA,
NA, 21, 6, 11, NA, NA, NA, 8, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, 11, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, 5, 10, 6, NA, NA, NA, NA, NA, NA, NA, 4, 2, NA, NA,
9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8, NA,
NA, 8, 1, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, 5, NA, 6, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, 2, NA, 2, 5, 12, NA, NA, NA, NA,
NA, NA, NA, NA, NA, 19, 13, 19, 23, NA, NA, NA, NA, NA, NA, NA,
19, NA, NA, NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, 9, NA, NA, NA, 8, 4, 9, NA, NA, NA, NA, NA, NA, NA, NA, 3,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA), .Dim = c(365L, 4L), .Dimnames = list(
    c("17532", "17533", "17534", "17535", "17536", "17537", "17538",
    "17539", "17540", "17541", "17542", "17543", "17544", "17545",
    "17546", "17547", "17548", "17549", "17550", "17551", "17552",
    "17553", "17554", "17555", "17556", "17557", "17558", "17559",
    "17560", "17561", "17562", "17563", "17564", "17565", "17566",
    "17567", "17568", "17569", "17570", "17571", "17572", "17573",
    "17574", "17575", "17576", "17577", "17578", "17579", "17580",
    "17581", "17582", "17583", "17584", "17585", "17586", "17587",
    "17588", "17589", "17590", "17591", "17592", "17593", "17594",
    "17595", "17596", "17597", "17598", "17599", "17600", "17601",
    "17602", "17603", "17604", "17605", "17606", "17607", "17608",
    "17609", "17610", "17611", "17612", "17613", "17614", "17615",
    "17616", "17617", "17618", "17619", "17620", "17621", "17622",
    "17623", "17624", "17625", "17626", "17627", "17628", "17629",
    "17630", "17631", "17632", "17633", "17634", "17635", "17636",
    "17637", "17638", "17639", "17640", "17641", "17642", "17643",
    "17644", "17645", "17646", "17647", "17648", "17649", "17650",
    "17651", "17652", "17653", "17654", "17655", "17656", "17657",
    "17658", "17659", "17660", "17661", "17662", "17663", "17664",
    "17665", "17666", "17667", "17668", "17669", "17670", "17671",
    "17672", "17673", "17674", "17675", "17676", "17677", "17678",
    "17679", "17680", "17681", "17682", "17683", "17684", "17685",
    "17686", "17687", "17688", "17689", "17690", "17691", "17692",
    "17693", "17694", "17695", "17696", "17697", "17698", "17699",
    "17700", "17701", "17702", "17703", "17704", "17705", "17706",
    "17707", "17708", "17709", "17710", "17711", "17712", "17713",
    "17714", "17715", "17716", "17717", "17718", "17719", "17720",
    "17721", "17722", "17723", "17724", "17725", "17726", "17727",
    "17728", "17729", "17730", "17731", "17732", "17733", "17734",
    "17735", "17736", "17737", "17738", "17739", "17740", "17741",
    "17742", "17743", "17744", "17745", "17746", "17747", "17748",
    "17749", "17750", "17751", "17752", "17753", "17754", "17755",
    "17756", "17757", "17758", "17759", "17760", "17761", "17762",
    "17763", "17764", "17765", "17766", "17767", "17768", "17769",
    "17770", "17771", "17772", "17773", "17774", "17775", "17776",
    "17777", "17778", "17779", "17780", "17781", "17782", "17783",
    "17784", "17785", "17786", "17787", "17788", "17789", "17790",
    "17791", "17792", "17793", "17794", "17795", "17796", "17797",
    "17798", "17799", "17800", "17801", "17802", "17803", "17804",
    "17805", "17806", "17807", "17808", "17809", "17810", "17811",
    "17812", "17813", "17814", "17815", "17816", "17817", "17818",
    "17819", "17820", "17821", "17822", "17823", "17824", "17825",
    "17826", "17827", "17828", "17829", "17830", "17831", "17832",
    "17833", "17834", "17835", "17836", "17837", "17838", "17839",
    "17840", "17841", "17842", "17843", "17844", "17845", "17846",
    "17847", "17848", "17849", "17850", "17851", "17852", "17853",
    "17854", "17855", "17856", "17857", "17858", "17859", "17860",
    "17861", "17862", "17863", "17864", "17865", "17866", "17867",
    "17868", "17869", "17870", "17871", "17872", "17873", "17874",
    "17875", "17876", "17877", "17878", "17879", "17880", "17881",
    "17882", "17883", "17884", "17885", "17886", "17887", "17888",
    "17889", "17890", "17891", "17892", "17893", "17894", "17895",
    "17896"), c("DAT", "Q", "BF", "")))

The following command gives the values of 1st column for which the values in 2nd and 3rd columns are similar

val<-BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)]

dput(val)
c(`17542` = 17542, `17555` = 17555, `17558` = 17558, `17564` = 17564,
`17568` = 17568, `17572` = 17572, `17583` = 17583, `17596` = 17596,
`17597` = 17597, `17598` = 17598, `17628` = 17628, `17649` = 17649,
`17652` = 17652, `17666` = 17666, `17667` = 17667, `17680` = 17680,
`17691` = 17691, `17695` = 17695, `17703` = 17703, `17720` = 17720,
`17729` = 17729, `17734` = 17734, `17743` = 17743, `17751` = 17751,
`17754` = 17754, `17762` = 17762, `17788` = 17788, `17800` = 17800,
`17835` = 17835, `17836` = 17836, `17837` = 17837, `17850` = 17850,
`17857` = 17857, `17871` = 17871, `17872` = 17872, `17873` = 17873,
`17881` = 17881, `17888` = 17888, `17889` = 17889, `17890` = 17890
)


Now for these values of "val" I want the values of 4th column to be plotted in "green" while all other in "red". I have tried the following command but to no avail

plot(as.numeric(as.Date(BFA3[,1])), BFA3[,4], pch=16, xlab = "", ylab = "",col= ifelse(BFA3[,1]==BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)], "green","red"),axes=F)

Is there a way around it?
I thankyou in advance

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep  3 02:18:42 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Sep 2021 10:18:42 +1000
Subject: [R] plotting some rows in different color
In-Reply-To: <AS8P194MB099914EF5653553F8FC81E879ACE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
References: <AS8P194MB099914EF5653553F8FC81E879ACE9@AS8P194MB0999.EURP194.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fWP8h509H7udmKMPB4Zm4jxNAiT1-t1gBia+ckgwqFcNw@mail.gmail.com>

Hi Eliza
This seems to work:

plot(BFA3[,1],BFA3[,4],
 pch=16, xlab = "", ylab = "",col=(BFA3[,2]==BFA3[,3])+2,axes=FALSE)

but I have no idea what you are trying to do with the

as.numeric(as.Date(...))

business.

Jim

On Fri, Sep 3, 2021 at 8:44 AM Eliza Botto <eliza_botto at outlook.com> wrote:
>
> Dear useRs,
>
> For the following dataset,
>
> dput(BFA3)
>
> structure(c(17532, 17533, 17534, 17535, 17536, 17537, 17538,
> 17539, 17540, 17541, 17542, 17543, 17544, 17545, 17546, 17547,
> 17548, 17549, 17550, 17551, 17552, 17553, 17554, 17555, 17556,
> 17557, 17558, 17559, 17560, 17561, 17562, 17563, 17564, 17565,
> 17566, 17567, 17568, 17569, 17570, 17571, 17572, 17573, 17574,
> 17575, 17576, 17577, 17578, 17579, 17580, 17581, 17582, 17583,
> 17584, 17585, 17586, 17587, 17588, 17589, 17590, 17591, 17592,
> 17593, 17594, 17595, 17596, 17597, 17598, 17599, 17600, 17601,
> 17602, 17603, 17604, 17605, 17606, 17607, 17608, 17609, 17610,
> 17611, 17612, 17613, 17614, 17615, 17616, 17617, 17618, 17619,
> 17620, 17621, 17622, 17623, 17624, 17625, 17626, 17627, 17628,
> 17629, 17630, 17631, 17632, 17633, 17634, 17635, 17636, 17637,
> 17638, 17639, 17640, 17641, 17642, 17643, 17644, 17645, 17646,
> 17647, 17648, 17649, 17650, 17651, 17652, 17653, 17654, 17655,
> 17656, 17657, 17658, 17659, 17660, 17661, 17662, 17663, 17664,
> 17665, 17666, 17667, 17668, 17669, 17670, 17671, 17672, 17673,
> 17674, 17675, 17676, 17677, 17678, 17679, 17680, 17681, 17682,
> 17683, 17684, 17685, 17686, 17687, 17688, 17689, 17690, 17691,
> 17692, 17693, 17694, 17695, 17696, 17697, 17698, 17699, 17700,
> 17701, 17702, 17703, 17704, 17705, 17706, 17707, 17708, 17709,
> 17710, 17711, 17712, 17713, 17714, 17715, 17716, 17717, 17718,
> 17719, 17720, 17721, 17722, 17723, 17724, 17725, 17726, 17727,
> 17728, 17729, 17730, 17731, 17732, 17733, 17734, 17735, 17736,
> 17737, 17738, 17739, 17740, 17741, 17742, 17743, 17744, 17745,
> 17746, 17747, 17748, 17749, 17750, 17751, 17752, 17753, 17754,
> 17755, 17756, 17757, 17758, 17759, 17760, 17761, 17762, 17763,
> 17764, 17765, 17766, 17767, 17768, 17769, 17770, 17771, 17772,
> 17773, 17774, 17775, 17776, 17777, 17778, 17779, 17780, 17781,
> 17782, 17783, 17784, 17785, 17786, 17787, 17788, 17789, 17790,
> 17791, 17792, 17793, 17794, 17795, 17796, 17797, 17798, 17799,
> 17800, 17801, 17802, 17803, 17804, 17805, 17806, 17807, 17808,
> 17809, 17810, 17811, 17812, 17813, 17814, 17815, 17816, 17817,
> 17818, 17819, 17820, 17821, 17822, 17823, 17824, 17825, 17826,
> 17827, 17828, 17829, 17830, 17831, 17832, 17833, 17834, 17835,
> 17836, 17837, 17838, 17839, 17840, 17841, 17842, 17843, 17844,
> 17845, 17846, 17847, 17848, 17849, 17850, 17851, 17852, 17853,
> 17854, 17855, 17856, 17857, 17858, 17859, 17860, 17861, 17862,
> 17863, 17864, 17865, 17866, 17867, 17868, 17869, 17870, 17871,
> 17872, 17873, 17874, 17875, 17876, 17877, 17878, 17879, 17880,
> 17881, 17882, 17883, 17884, 17885, 17886, 17887, 17888, 17889,
> 17890, 17891, 17892, 17893, 17894, 17895, 17896, 8.36875, 15.12875,
> 14.2825, 12.355, 13.1825, 88.58375, 47.52125, 26.53375, 22.85875,
> 12.4925, 9.86875, 13.125, 14.055, 14.0175, 14.70625, 15.46125,
> 11.8725, 17.505, 19.8575, 74.875445, 62.018935, 23.9481046910236,
> 9.68, 9.6175, 9.78, 9.8875, 9.5125, 9.885, 9.99, 14.16625, 11.99375,
> 10.7875, 9.85625, 12.17125, 11.76625, 11.0425, 9.28875, 9.425,
> 23.29375, 12.66875, 9.6, 10.06875, 10.055, 30.89625, 36.69375,
> 16.63875, 11.84625, 12.825, 14.94, 11.495, 10.795, 9.14625, 10.17875,
> 11.0525, 10.0175, 10.67625, 10.4325, 12.5175, 13.93, 14.1675,
> 17.3175, 18.3875, 12.06, 10.3125, 9.94125, 10.8575, 11.2425,
> 13.28875, 43.885, 76.225, 125.277272727273, 198.285, 181.40125,
> 113.38875, 89.7925, 108.27875, 100.24375, 103.57, 189.015, 190.8925,
> 113.76875, 109.055, 96.4925, 99.04625, 127.47125, 300.86, 250.0725,
> 108.72125, 54.61, 39.76625, 30.11875, 31.46875, 40.73, 40.63,
> 27.48125, 24.9125, 24.105, 53.65625, 209.77125, 281.53125, 460.90875,
> 296.4225, 349.58375, 494.825, 404.4475, 510.68125, 681.65625,
> 637.78125, 838.40125, 740.0875, 601.81375, 246.75625, 127.1725,
> 92.36875, 78.11875, 73.61625, 62.77875, 59.87, 106.36, 115.31125,
> 64.025, 96.30125, 97.50625, 92.875, 92.49875, 89.295, 84.46375,
> 80.05625, 80.745, 114.13, 91.3225, 79.72125, 70.555, 30.8975,
> 14.28625, 13.02875, 93.59125, 246.7875, 54.37125, 29.45375, 16.2725,
> 15.175, 15.1475, 16.27875, 15.0575, 14.0425, 11.675, 12.9275,
> 11.26, 12.56, 183.555, 413.2025, 111.46375, 43.01375, 27.66125,
> 17.55875, 15.28, 14.88875, 14.60875, 14.44625, 281.95125, 85.16875,
> 24.6675, 14.88875, 15.02, 23.35125, 65.385, 83.95, 37.675, 22.31375,
> 15.1075, 15.02625, 96.39, 1856.72375, 612.275, 97.04875, 46.065,
> 28.62125, 23.22875, 234.78375, 58.21375, 33.29, 55.595, 66.57375,
> 81.39875, 42.84625, 26.945, 20.00375, 14.26875, 14.87625, 82.975,
> 85.12125, 35.7575, 26.875, 40.36375, 28.63875, 15.68, 13.70125,
> 29.42625, 51.81125, 26.6125, 15.56375, 13.725, 191.72625, 376.08625,
> 66.27875, 72.0275, 47.50375, 26.555, 16.58625, 16.9275, 15.26875,
> 33.3125, 64.98625, 66.93875, 194.75875, 65.15, 29.03375, 15.545,
> 14.83625, 14.89, 15.08875, 14.71, 146.1525, 112.855, 34.10625,
> 16.46625, 15.0175, 15.06125, 13.94625, 12.1075, 14.265, 14.30125,
> 13.77125, 12.51, 181.65625, 82.07875, 59.46125, 209.9875, 42.5525,
> 22.19, 32.95, 19.89875, 37.7175, 29.62875, 41.705, 34.1225, 23.7275,
> 20.565, 17.61125, 16.53125, 15.75125, 119.1025, 79.8675, 27.6375,
> 15.6675, 13.955, 16.54875, 24.2075, 21.97875, 17.3525, 19.9875,
> 18.2275, 109.57875, 73.06625, 47.2775, 50.1475, 28.66875, 17.8,
> 373.38375, 96.49875, 62.55125, 24.56375, 26.7675, 109.57375,
> 265.26125, 161.6575, 86.80375, 67.98, 62.88125, 64.88625, 97.665,
> 77.29125, 52.015, 81.7925, 75.305, 45.81875, 39.425, 37.78625,
> 35.40125, 32.1275, 31.89875, 31.77125, 30.1575, 28.62875, 28.065,
> 29.6875, 28.47125, 25.525, 25.2125, 22.68125, 22.81625, 20.165,
> 18.03125, 18.0425, 18.945, 19.88125, 24.6225, 25.6025, 24.65125,
> 31.76375, 27.41375, 22.8075, 28.64, 25.06875, 26.36125, 29.74625,
> 23.1, 19.67, 30.01625, 27.285, 43.90125, 50.1425, 33.45375, 23.2225,
> 19.91625, 27.22875, 46.14125, 33.70375, 38.7525, 178.45625, 85.08,
> 37.93875, 22.4225, 23.45125, 34.1375, 22.3325, 18.7125, 17.5375,
> 16.07625, 15.07375, 15.035, 15.16875, 15.6225, 15.9125, 15.3325,
> 15.09, 14.91125, 14.94125, 14.8325, 14.86375, 14.9675, 14.895,
> 14.81, 14.77125, 13.66625, 13.135, 13.00875, 12.86375, 12.9525,
> 13.0675, 12.97, 13.02, 13.10375, 12.96, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, 9.86875, 9.84942307692308, 9.83009615384615,
> 9.81076923076923, 9.79144230769231, 9.77211538461539, 9.75278846153846,
> 9.73346153846154, 9.71413461538462, 9.69480769230769, 9.67548076923077,
> 9.65615384615385, 9.63682692307692, 9.6175, 9.5825, 9.5475, 9.5125,
> 9.56979166666667, 9.62708333333333, 9.684375, 9.74166666666667,
> 9.79895833333333, 9.85625, 9.714375, 9.5725, 9.430625, 9.28875,
> 9.3665625, 9.444375, 9.5221875, 9.6, 9.55875, 9.5175, 9.47625,
> 9.435, 9.39375, 9.3525, 9.31125, 9.27, 9.22875, 9.1875, 9.14625,
> 9.20740384615385, 9.26855769230769, 9.32971153846154, 9.39086538461538,
> 9.45201923076923, 9.51317307692308, 9.57432692307692, 9.63548076923077,
> 9.69663461538462, 9.75778846153846, 9.81894230769231, 9.88009615384615,
> 9.94125, 10.8575, 11.2425, 11.7121774193548, 12.1395161290323,
> 12.5668548387097, 12.9941935483871, 13.4215322580645, 13.8488709677419,
> 14.2762096774194, 14.7035483870968, 15.1308870967742, 15.5582258064516,
> 15.985564516129, 16.4129032258065, 16.8402419354839, 17.2675806451613,
> 17.6949193548387, 18.1222580645161, 18.5495967741935, 18.976935483871,
> 19.4042741935484, 19.8316129032258, 20.2589516129032, 20.6862903225806,
> 21.1136290322581, 21.5409677419355, 21.9683064516129, 22.3956451612903,
> 22.8229838709677, 23.2503225806452, 23.6776612903226, 24.105,
> 25.8080952380952, 27.5111904761905, 29.2142857142857, 30.917380952381,
> 32.6204761904762, 34.3235714285714, 36.0266666666667, 37.7297619047619,
> 39.4328571428571, 41.1359523809524, 42.8390476190476, 44.5421428571429,
> 46.2452380952381, 47.9483333333333, 49.6514285714286, 51.3545238095238,
> 53.057619047619, 54.7607142857143, 56.4638095238095, 58.1669047619048,
> 59.87, 61.255, 62.64, 64.025, 60.4722321428572, 56.9194642857143,
> 53.3666964285714, 49.8139285714286, 46.2611607142857, 42.7083928571429,
> 39.155625, 35.6028571428571, 32.0500892857143, 28.4973214285714,
> 24.9445535714286, 21.3917857142857, 17.8390178571429, 14.28625,
> 13.02875, 12.8926923076923, 12.7566346153846, 12.6205769230769,
> 12.4845192307692, 12.3484615384615, 12.2124038461538, 12.0763461538462,
> 11.9402884615385, 11.8042307692308, 11.6681730769231, 11.5321153846154,
> 11.3960576923077, 11.26, 11.5496590909091, 11.8393181818182,
> 12.1289772727273, 12.4186363636364, 12.7082954545455, 12.9979545454545,
> 13.2876136363636, 13.5772727272727, 13.8669318181818, 14.1565909090909,
> 14.44625, 14.556875, 14.6675, 14.778125, 14.88875, 14.9059375,
> 14.923125, 14.9403125, 14.9575, 14.9746875, 14.991875, 15.0090625,
> 15.02625, 14.9816911764706, 14.9371323529412, 14.8925735294118,
> 14.8480147058824, 14.8034558823529, 14.7588970588235, 14.7143382352941,
> 14.6697794117647, 14.6252205882353, 14.5806617647059, 14.5361029411765,
> 14.4915441176471, 14.4469852941176, 14.4024264705882, 14.3578676470588,
> 14.3133088235294, 14.26875, 14.2056944444444, 14.1426388888889,
> 14.0795833333333, 14.0165277777778, 13.9534722222222, 13.8904166666667,
> 13.8273611111111, 13.7643055555556, 13.70125, 13.706, 13.71075,
> 13.7155, 13.72025, 13.725, 13.8965277777778, 14.0680555555556,
> 14.2395833333333, 14.4111111111111, 14.5826388888889, 14.7541666666667,
> 14.9256944444444, 15.0972222222222, 15.26875, 15.2146875, 15.160625,
> 15.1065625, 15.0525, 14.9984375, 14.944375, 14.8903125, 14.83625,
> 14.7941666666667, 14.7520833333333, 14.71, 14.3846875, 14.059375,
> 13.7340625, 13.40875, 13.0834375, 12.758125, 12.4328125, 12.1075,
> 12.1785576923077, 12.2496153846154, 12.3206730769231, 12.3917307692308,
> 12.4627884615385, 12.5338461538462, 12.6049038461538, 12.6759615384615,
> 12.7470192307692, 12.8180769230769, 12.8891346153846, 12.9601923076923,
> 13.03125, 13.1023076923077, 13.1733653846154, 13.2444230769231,
> 13.3154807692308, 13.3865384615385, 13.4575961538462, 13.5286538461538,
> 13.5997115384615, 13.6707692307692, 13.7418269230769, 13.8128846153846,
> 13.8839423076923, 13.955, 14.2754166666667, 14.5958333333333,
> 14.91625, 15.2366666666667, 15.5570833333333, 15.8775, 16.1979166666667,
> 16.5183333333333, 16.83875, 17.1591666666667, 17.4795833333333,
> 17.8, 17.8066071428571, 17.8132142857143, 17.8198214285714, 17.8264285714286,
> 17.8330357142857, 17.8396428571429, 17.84625, 17.8528571428571,
> 17.8594642857143, 17.8660714285714, 17.8726785714286, 17.8792857142857,
> 17.8858928571429, 17.8925, 17.8991071428571, 17.9057142857143,
> 17.9123214285714, 17.9189285714286, 17.9255357142857, 17.9321428571429,
> 17.93875, 17.9453571428571, 17.9519642857143, 17.9585714285714,
> 17.9651785714286, 17.9717857142857, 17.9783928571429, 17.985,
> 17.9916071428571, 17.9982142857143, 18.0048214285714, 18.0114285714286,
> 18.0180357142857, 18.0246428571429, 18.03125, 18.0425, 18.945,
> 19.0007692307692, 19.0565384615385, 19.1123076923077, 19.1680769230769,
> 19.2238461538462, 19.2796153846154, 19.3353846153846, 19.3911538461538,
> 19.4469230769231, 19.5026923076923, 19.5584615384615, 19.6142307692308,
> 19.67, 19.7051785714286, 19.7403571428571, 19.7755357142857,
> 19.8107142857143, 19.8458928571429, 19.8810714285714, 19.91625,
> 19.6419642857143, 19.3676785714286, 19.0933928571429, 18.8191071428571,
> 18.5448214285714, 18.2705357142857, 17.99625, 17.7219642857143,
> 17.4476785714286, 17.1733928571429, 16.8991071428571, 16.6248214285714,
> 16.3505357142857, 16.07625, 15.07375, 15.035, 15.0096875, 14.984375,
> 14.9590625, 14.93375, 14.9084375, 14.883125, 14.8578125, 14.8325,
> 14.61375, 14.395, 14.17625, 13.9575, 13.73875, 13.52, 13.135,
> 13.00875, 12.86375, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, 2, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, NA,
> 3, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 2,
> NA, NA, NA, NA, NA, NA, 1, 4, NA, NA, NA, NA, NA, NA, 2, NA,
> NA, NA, NA, NA, 4, 9, NA, NA, NA, NA, 16, NA, NA, NA, NA, NA,
> 18, 12, 22, 22, 40, NA, NA, NA, NA, 19.5, 14, 17, NA, NA, NA,
> NA, 21, 6, 11, NA, NA, NA, 8, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 11, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, 5, 10, 6, NA, NA, NA, NA, NA, NA, NA, 4, 2, NA, NA,
> 9, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 8, NA,
> NA, 8, 1, NA, NA, NA, NA, NA, NA, NA, NA, 2, 4, 5, NA, 6, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, 6, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, 2, NA, 2, 5, 12, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, 19, 13, 19, 23, NA, NA, NA, NA, NA, NA, NA,
> 19, NA, NA, NA, NA, 17, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, 9, NA, NA, NA, 8, 4, 9, NA, NA, NA, NA, NA, NA, NA, NA, 3,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA), .Dim = c(365L, 4L), .Dimnames = list(
>     c("17532", "17533", "17534", "17535", "17536", "17537", "17538",
>     "17539", "17540", "17541", "17542", "17543", "17544", "17545",
>     "17546", "17547", "17548", "17549", "17550", "17551", "17552",
>     "17553", "17554", "17555", "17556", "17557", "17558", "17559",
>     "17560", "17561", "17562", "17563", "17564", "17565", "17566",
>     "17567", "17568", "17569", "17570", "17571", "17572", "17573",
>     "17574", "17575", "17576", "17577", "17578", "17579", "17580",
>     "17581", "17582", "17583", "17584", "17585", "17586", "17587",
>     "17588", "17589", "17590", "17591", "17592", "17593", "17594",
>     "17595", "17596", "17597", "17598", "17599", "17600", "17601",
>     "17602", "17603", "17604", "17605", "17606", "17607", "17608",
>     "17609", "17610", "17611", "17612", "17613", "17614", "17615",
>     "17616", "17617", "17618", "17619", "17620", "17621", "17622",
>     "17623", "17624", "17625", "17626", "17627", "17628", "17629",
>     "17630", "17631", "17632", "17633", "17634", "17635", "17636",
>     "17637", "17638", "17639", "17640", "17641", "17642", "17643",
>     "17644", "17645", "17646", "17647", "17648", "17649", "17650",
>     "17651", "17652", "17653", "17654", "17655", "17656", "17657",
>     "17658", "17659", "17660", "17661", "17662", "17663", "17664",
>     "17665", "17666", "17667", "17668", "17669", "17670", "17671",
>     "17672", "17673", "17674", "17675", "17676", "17677", "17678",
>     "17679", "17680", "17681", "17682", "17683", "17684", "17685",
>     "17686", "17687", "17688", "17689", "17690", "17691", "17692",
>     "17693", "17694", "17695", "17696", "17697", "17698", "17699",
>     "17700", "17701", "17702", "17703", "17704", "17705", "17706",
>     "17707", "17708", "17709", "17710", "17711", "17712", "17713",
>     "17714", "17715", "17716", "17717", "17718", "17719", "17720",
>     "17721", "17722", "17723", "17724", "17725", "17726", "17727",
>     "17728", "17729", "17730", "17731", "17732", "17733", "17734",
>     "17735", "17736", "17737", "17738", "17739", "17740", "17741",
>     "17742", "17743", "17744", "17745", "17746", "17747", "17748",
>     "17749", "17750", "17751", "17752", "17753", "17754", "17755",
>     "17756", "17757", "17758", "17759", "17760", "17761", "17762",
>     "17763", "17764", "17765", "17766", "17767", "17768", "17769",
>     "17770", "17771", "17772", "17773", "17774", "17775", "17776",
>     "17777", "17778", "17779", "17780", "17781", "17782", "17783",
>     "17784", "17785", "17786", "17787", "17788", "17789", "17790",
>     "17791", "17792", "17793", "17794", "17795", "17796", "17797",
>     "17798", "17799", "17800", "17801", "17802", "17803", "17804",
>     "17805", "17806", "17807", "17808", "17809", "17810", "17811",
>     "17812", "17813", "17814", "17815", "17816", "17817", "17818",
>     "17819", "17820", "17821", "17822", "17823", "17824", "17825",
>     "17826", "17827", "17828", "17829", "17830", "17831", "17832",
>     "17833", "17834", "17835", "17836", "17837", "17838", "17839",
>     "17840", "17841", "17842", "17843", "17844", "17845", "17846",
>     "17847", "17848", "17849", "17850", "17851", "17852", "17853",
>     "17854", "17855", "17856", "17857", "17858", "17859", "17860",
>     "17861", "17862", "17863", "17864", "17865", "17866", "17867",
>     "17868", "17869", "17870", "17871", "17872", "17873", "17874",
>     "17875", "17876", "17877", "17878", "17879", "17880", "17881",
>     "17882", "17883", "17884", "17885", "17886", "17887", "17888",
>     "17889", "17890", "17891", "17892", "17893", "17894", "17895",
>     "17896"), c("DAT", "Q", "BF", "")))
>
> The following command gives the values of 1st column for which the values in 2nd and 3rd columns are similar
>
> val<-BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)]
>
> dput(val)
> c(`17542` = 17542, `17555` = 17555, `17558` = 17558, `17564` = 17564,
> `17568` = 17568, `17572` = 17572, `17583` = 17583, `17596` = 17596,
> `17597` = 17597, `17598` = 17598, `17628` = 17628, `17649` = 17649,
> `17652` = 17652, `17666` = 17666, `17667` = 17667, `17680` = 17680,
> `17691` = 17691, `17695` = 17695, `17703` = 17703, `17720` = 17720,
> `17729` = 17729, `17734` = 17734, `17743` = 17743, `17751` = 17751,
> `17754` = 17754, `17762` = 17762, `17788` = 17788, `17800` = 17800,
> `17835` = 17835, `17836` = 17836, `17837` = 17837, `17850` = 17850,
> `17857` = 17857, `17871` = 17871, `17872` = 17872, `17873` = 17873,
> `17881` = 17881, `17888` = 17888, `17889` = 17889, `17890` = 17890
> )
>
>
> Now for these values of "val" I want the values of 4th column to be plotted in "green" while all other in "red". I have tried the following command but to no avail
>
> plot(as.numeric(as.Date(BFA3[,1])), BFA3[,4], pch=16, xlab = "", ylab = "",col= ifelse(BFA3[,1]==BFA3[,1][which(BFA3[,2]-BFA3[,3]==0)], "green","red"),axes=F)
>
> Is there a way around it?
> I thankyou in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 03:30:28 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Thu, 2 Sep 2021 21:30:28 -0400
Subject: [R] Splitting a data column randomly into 3 groups
Message-ID: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>

Dear All:

How to split a column data *randomly* into three groups. Please see the
attached data. I need to split column #2 titled "Data"

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data_example.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210902/064b4219/attachment.txt>

From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep  3 03:42:06 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 21:42:06 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
Message-ID: <00e501d7a064$e7113f80$b533be80$@verizon.net>

What is stopping you Abou?

Some of us here start wondering if we have better things to do than homework for others. Help is supposed to be after they try and encounter issues that we may help with.

So think about your problem. You supplied data in a file that is NOT in CSV format but is in Tab separated format.

You need to get it in to your program and store it in something. It looks like you have 204 items so 1/3 of those would be exactly 68.

So if your data is in an object like a vector or data.frame, you want to choose random number between 1 and 204. How do you do that? You need 1/3 of the length of the object items, in your case 68.

Now extract the items with  those indices into say A1. Extract all the rest into a temporary item.

Make another 68 random indices, with no overlap, and copy those items into A2 and the ones that do not have those into A3 and you are sort of done, other than some cleanup or whatever.

There are many ways to do the above and I am sure packages too.

But since you have made no visible effort, I personally am not going to pick anything in particular.

Had you shown some text and code along the lines of the above and just wanted to know how to copy just the ones that were not selected, we could easily ...


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of AbouEl-Makarim Aboueissa
Sent: Thursday, September 2, 2021 9:30 PM
To: R mailing list <r-help at r-project.org>
Subject: [R] Splitting a data column randomly into 3 groups

Dear All:

How to split a column data *randomly* into three groups. Please see the attached data. I need to split column #2 titled "Data"

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science* *Graduate Coordinator*

*Department of Mathematics and Statistics* *University of Southern Maine*


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep  3 03:46:04 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 3 Sep 2021 11:46:04 +1000
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
Message-ID: <CA+8X3fUn-XTqM3dUgdDu7+vnBTZPKw=-kh7W=cQmWFDz6EX+mQ@mail.gmail.com>

Hi Abou,
One way is to shuffle the original data frame using sample(). and
split up the result into three equal parts.
I was going to provide example code, but Avi's response popped up and
I kind of agree with him.

Jim

On Fri, Sep 3, 2021 at 11:31 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 03:51:20 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Thu, 2 Sep 2021 21:51:20 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <00e501d7a064$e7113f80$b533be80$@verizon.net>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <00e501d7a064$e7113f80$b533be80$@verizon.net>
Message-ID: <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>

Sorry, please forget about it. I believe that I am very serious when I
posted my question.

with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Sep 2, 2021 at 9:42 PM Avi Gross via R-help <r-help at r-project.org>
wrote:

> What is stopping you Abou?
>
> Some of us here start wondering if we have better things to do than
> homework for others. Help is supposed to be after they try and encounter
> issues that we may help with.
>
> So think about your problem. You supplied data in a file that is NOT in
> CSV format but is in Tab separated format.
>
> You need to get it in to your program and store it in something. It looks
> like you have 204 items so 1/3 of those would be exactly 68.
>
> So if your data is in an object like a vector or data.frame, you want to
> choose random number between 1 and 204. How do you do that? You need 1/3 of
> the length of the object items, in your case 68.
>
> Now extract the items with  those indices into say A1. Extract all the
> rest into a temporary item.
>
> Make another 68 random indices, with no overlap, and copy those items into
> A2 and the ones that do not have those into A3 and you are sort of done,
> other than some cleanup or whatever.
>
> There are many ways to do the above and I am sure packages too.
>
> But since you have made no visible effort, I personally am not going to
> pick anything in particular.
>
> Had you shown some text and code along the lines of the above and just
> wanted to know how to copy just the ones that were not selected, we could
> easily ...
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of AbouEl-Makarim
> Aboueissa
> Sent: Thursday, September 2, 2021 9:30 PM
> To: R mailing list <r-help at r-project.org>
> Subject: [R] Splitting a data column randomly into 3 groups
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science* *Graduate Coordinator*
>
> *Department of Mathematics and Statistics* *University of Southern Maine*
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep  3 04:42:18 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 2 Sep 2021 22:42:18 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <00e501d7a064$e7113f80$b533be80$@verizon.net>
 <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>
Message-ID: <012901d7a06d$50067980$f0136c80$@verizon.net>

Abou,

 

I am not trying to be negative. Assuming you are a professor of Statistics, your request seems odd as what you are asking about is very routine in much of statistical work where you want to make a model or something using just part of your data and need to reserve some to check if you perhaps trained an algorithm too much for the original data used.

 

A simple online search before asking questions here is appreciated. I did a quick search for something like ?R split data into three parts? and see several applicable answers.

 

There are people on this forum who actually get paid to do nontrivial tasks and do not mind help in spots but feel sort of used if expected to write a serious amount of code and perhaps then be asked to redo it with more bells and whistles added. A recent badly phrased request comes to mind where several of us provided and answer only to find out it was for a different scenario, ?

 

So let me continue with a serious answer. May we assume you KNOW how to read the data in to something like a data.frame? If so, and if you see no need or value in doing this the hard way, then your question could have been to ask if there is an R built-in function or perhaps a pacjkage already set to solve it quickly. Again, a simple online search can do wonders.  Here, for example is a package called caret and this page discusses spliutting data multiple ways:

 

https://topepo.github.io/caret/data-splitting.html

 

There are other such pages suggesting how to do it using base R.

 

Here is one that gives an example on how to make  three unequal partitions:

 

inds <- partition(iris$Sepal.Length, p = c(train = 0.6, valid = 0.2, test = 0.2))

 

 

There is more to do below but in the above, you would use whatever names you want instead of train/valid/test and set all three to 0.33 and so on.

 

I repeat, that what you want to do strikes some of us as a fairly routine thing to do and lots of people have written how they have done it and you can pick and choose, or redo it on your own. If what you have is a homework assignment, the appropriate thing is to have you learn to use some technique yourself and perhaps get minor help when it fails. But if you will be doing this regularly, use of some packages is highly valuable.

 

Good Luck.

 

 

 

 

 

From: AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com> 
Sent: Thursday, September 2, 2021 9:51 PM
To: Avi Gross <avigross at verizon.net>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] Splitting a data column randomly into 3 groups

 

Sorry, please forget about it. I believe that I am very serious when I posted my question.

 

with thanks

abou


______________________

AbouEl-Makarim Aboueissa, PhD

 

Professor, Statistics and Data Science

Graduate Coordinator

Department of Mathematics and Statistics

University of Southern Maine

 

 

 

On Thu, Sep 2, 2021 at 9:42 PM Avi Gross via R-help <r-help at r-project.org <mailto:r-help at r-project.org> > wrote:

What is stopping you Abou?

Some of us here start wondering if we have better things to do than homework for others. Help is supposed to be after they try and encounter issues that we may help with.

So think about your problem. You supplied data in a file that is NOT in CSV format but is in Tab separated format.

You need to get it in to your program and store it in something. It looks like you have 204 items so 1/3 of those would be exactly 68.

So if your data is in an object like a vector or data.frame, you want to choose random number between 1 and 204. How do you do that? You need 1/3 of the length of the object items, in your case 68.

Now extract the items with  those indices into say A1. Extract all the rest into a temporary item.

Make another 68 random indices, with no overlap, and copy those items into A2 and the ones that do not have those into A3 and you are sort of done, other than some cleanup or whatever.

There are many ways to do the above and I am sure packages too.

But since you have made no visible effort, I personally am not going to pick anything in particular.

Had you shown some text and code along the lines of the above and just wanted to know how to copy just the ones that were not selected, we could easily ...


-----Original Message-----
From: R-help <r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org> > On Behalf Of AbouEl-Makarim Aboueissa
Sent: Thursday, September 2, 2021 9:30 PM
To: R mailing list <r-help at r-project.org <mailto:r-help at r-project.org> >
Subject: [R] Splitting a data column randomly into 3 groups

Dear All:

How to split a column data *randomly* into three groups. Please see the attached data. I need to split column #2 titled "Data"

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science* *Graduate Coordinator*

*Department of Mathematics and Statistics* *University of Southern Maine*

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep  3 08:26:49 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 3 Sep 2021 06:26:49 +0000
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
Message-ID: <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>

Hi Luigi.

Weird. But maybe it is the desired behaviour of summary when calculating
mean of numeric column full of NAs.

See example

dat <- data.frame(x=rep(NA, 110), y=rep(1, 110), z= rnorm(110))

# change all values in second column to NA
dat[,2] <- NA
# change some of them to NAN
dat[5:6, 2:3] <- 0/0

# see summary
summary(dat)
    x                 y             z          
 Mode:logical   Min.   : NA   Min.   :-1.9798  
 NA's:110       1st Qu.: NA   1st Qu.:-0.4729  
                Median : NA   Median : 0.1745  
                Mean   :NaN   Mean   : 0.1856  
                3rd Qu.: NA   3rd Qu.: 0.8017  
                Max.   : NA   Max.   : 2.5075  
                NA's   :110   NA's   :2        

# change NAN values to NA
dat[sapply(dat, is.nan)] <- NA
*************************

#summary is same
summary(dat)
    x                 y             z          
 Mode:logical   Min.   : NA   Min.   :-1.9798  
 NA's:110       1st Qu.: NA   1st Qu.:-0.4729  
                Median : NA   Median : 0.1745  
                Mean   :NaN   Mean   : 0.1856  
                3rd Qu.: NA   3rd Qu.: 0.8017  
                Max.   : NA   Max.   : 2.5075  
                NA's   :110   NA's   :2        

# but no NAN value in data
dat[1:10,]
    x  y          z
1  NA NA -0.9148696
2  NA NA  0.7110570
3  NA NA -0.1901676
4  NA NA  0.5900650
5  NA NA         NA
6  NA NA         NA
7  NA NA  0.7987658
8  NA NA -0.5225229
9  NA NA  0.7673103
10 NA NA -0.5263897

So my "nice compact command"
dat[sapply(dat, is.nan)] <- NA

works as expected, but summary gives as mean NAN.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, September 2, 2021 3:46 PM
> To: Andrew Simmons <akwsimmo at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] How to globally convert NaN to NA in dataframe?
> 
> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I still
get
> NaN when using the summary function, for instance one of the columns give:
> ```
> Min.   : NA
> 1st Qu.: NA
> Median : NA
> Mean   :NaN
> 3rd Qu.: NA
> Max.   : NA
> NA's   :110
> ```
> I tried to implement the second solution but:
> ```
> df <- lapply(x, function(xx) {
>   xx[is.nan(xx)] <- NA
> })
> > str(df)
> List of 1
>  $ sd_ef_rash_loc___palm: logi NA
> ```
> What am I getting wrong?
> Thanks
> 
> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
> wrote:
> >
> > Hello,
> >
> >
> > I would use something like:
> >
> >
> > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> > as.data.frame() x[] <- lapply(x, function(xx) {
> >     xx[is.nan(xx)] <- NA_real_
> >     xx
> > })
> >
> >
> > This prevents attributes from being changed in 'x', but accomplishes the
> same thing as you have above, I hope this helps!
> >
> > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >>
> >> Hello,
> >> I have some NaN values in some elements of a dataframe that I would
> >> like to convert to NA.
> >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> >> Is there an alternative for the global modification at once of all
> >> instances?
> >> I have seen from
> >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-
> value
> >> -with-zero-in-a-huge-data-frame/18143097#18143097
> >> that once could use:
> >> ```
> >>
> >> is.nan.data.frame <- function(x)
> >> do.call(cbind, lapply(x, is.nan))
> >>
> >> data123[is.nan(data123)] <- 0
> >> ```
> >> replacing o with NA, but I got
> >> ```
> >> str(df)
> >> > logi NA
> >> ```
> >> when modifying my dataframe df.
> >> What would be the correct syntax?
> >> Thank you
> >>
> >>
> >>
> >> --
> >> Best regards,
> >> Luigi
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep  3 09:59:12 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 3 Sep 2021 09:59:12 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2TurkxmAEqqB513h4XjbeT-MaFGVUPKype0JMKWPKNS-w@mail.gmail.com>

Fair enough, I'll check the actual data to see if there are indeed any
NaN (which should not, since the data are categories, not generated by
math).
Thanks!

On Fri, Sep 3, 2021 at 8:26 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi Luigi.
>
> Weird. But maybe it is the desired behaviour of summary when calculating
> mean of numeric column full of NAs.
>
> See example
>
> dat <- data.frame(x=rep(NA, 110), y=rep(1, 110), z= rnorm(110))
>
> # change all values in second column to NA
> dat[,2] <- NA
> # change some of them to NAN
> dat[5:6, 2:3] <- 0/0
>
> # see summary
> summary(dat)
>     x                 y             z
>  Mode:logical   Min.   : NA   Min.   :-1.9798
>  NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>                 Median : NA   Median : 0.1745
>                 Mean   :NaN   Mean   : 0.1856
>                 3rd Qu.: NA   3rd Qu.: 0.8017
>                 Max.   : NA   Max.   : 2.5075
>                 NA's   :110   NA's   :2
>
> # change NAN values to NA
> dat[sapply(dat, is.nan)] <- NA
> *************************
>
> #summary is same
> summary(dat)
>     x                 y             z
>  Mode:logical   Min.   : NA   Min.   :-1.9798
>  NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>                 Median : NA   Median : 0.1745
>                 Mean   :NaN   Mean   : 0.1856
>                 3rd Qu.: NA   3rd Qu.: 0.8017
>                 Max.   : NA   Max.   : 2.5075
>                 NA's   :110   NA's   :2
>
> # but no NAN value in data
> dat[1:10,]
>     x  y          z
> 1  NA NA -0.9148696
> 2  NA NA  0.7110570
> 3  NA NA -0.1901676
> 4  NA NA  0.5900650
> 5  NA NA         NA
> 6  NA NA         NA
> 7  NA NA  0.7987658
> 8  NA NA -0.5225229
> 9  NA NA  0.7673103
> 10 NA NA -0.5263897
>
> So my "nice compact command"
> dat[sapply(dat, is.nan)] <- NA
>
> works as expected, but summary gives as mean NAN.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Thursday, September 2, 2021 3:46 PM
> > To: Andrew Simmons <akwsimmo at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] How to globally convert NaN to NA in dataframe?
> >
> > `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I still
> get
> > NaN when using the summary function, for instance one of the columns give:
> > ```
> > Min.   : NA
> > 1st Qu.: NA
> > Median : NA
> > Mean   :NaN
> > 3rd Qu.: NA
> > Max.   : NA
> > NA's   :110
> > ```
> > I tried to implement the second solution but:
> > ```
> > df <- lapply(x, function(xx) {
> >   xx[is.nan(xx)] <- NA
> > })
> > > str(df)
> > List of 1
> >  $ sd_ef_rash_loc___palm: logi NA
> > ```
> > What am I getting wrong?
> > Thanks
> >
> > On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
> > wrote:
> > >
> > > Hello,
> > >
> > >
> > > I would use something like:
> > >
> > >
> > > x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
> > > as.data.frame() x[] <- lapply(x, function(xx) {
> > >     xx[is.nan(xx)] <- NA_real_
> > >     xx
> > > })
> > >
> > >
> > > This prevents attributes from being changed in 'x', but accomplishes the
> > same thing as you have above, I hope this helps!
> > >
> > > On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
> > wrote:
> > >>
> > >> Hello,
> > >> I have some NaN values in some elements of a dataframe that I would
> > >> like to convert to NA.
> > >> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
> > >> Is there an alternative for the global modification at once of all
> > >> instances?
> > >> I have seen from
> > >> https://stackoverflow.com/questions/18142117/how-to-replace-nan-
> > value
> > >> -with-zero-in-a-huge-data-frame/18143097#18143097
> > >> that once could use:
> > >> ```
> > >>
> > >> is.nan.data.frame <- function(x)
> > >> do.call(cbind, lapply(x, is.nan))
> > >>
> > >> data123[is.nan(data123)] <- 0
> > >> ```
> > >> replacing o with NA, but I got
> > >> ```
> > >> str(df)
> > >> > logi NA
> > >> ```
> > >> when modifying my dataframe df.
> > >> What would be the correct syntax?
> > >> Thank you
> > >>
> > >>
> > >>
> > >> --
> > >> Best regards,
> > >> Luigi
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From pd@|gd @end|ng |rom gm@||@com  Fri Sep  3 11:51:55 2021
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 3 Sep 2021 11:51:55 +0200
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: <CAMk+s2TurkxmAEqqB513h4XjbeT-MaFGVUPKype0JMKWPKNS-w@mail.gmail.com>
References: <CAMk+s2RFnye1D3ncRy6FAxKsrbMF7c3mZ54JBPra6WYFoP6qgg@mail.gmail.com>
 <CAPcHnpTFZ7-jj5JHVy7E-SMSJ-f-CPgQPK4=4TbY9drA-sL3vQ@mail.gmail.com>
 <CAMk+s2QTkoWAxX8OxywBr_T2t8yXVni6TJaHrGbGcTyyNSYZMg@mail.gmail.com>
 <8252a0fe9c2b42e1b855cfd24015e622@SRVEXCHCM1302.precheza.cz>
 <CAMk+s2TurkxmAEqqB513h4XjbeT-MaFGVUPKype0JMKWPKNS-w@mail.gmail.com>
Message-ID: <B1EF7DC1-39A1-4642-9F9E-924300032E09@gmail.com>

Yes, even

> summary(NA_real_)
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
     NA      NA      NA     NaN      NA      NA       1 

which is presumably because the mean is an empty sum (= 0) divided by a zero count, and 0/0 = NaN.

Notice also the differenc between

> mean(NA_real_)
[1] NA
> mean(NA_real_, na.rm=TRUE)
[1] NaN


> On 3 Sep 2021, at 09:59 , Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Fair enough, I'll check the actual data to see if there are indeed any
> NaN (which should not, since the data are categories, not generated by
> math).
> Thanks!
> 
> On Fri, Sep 3, 2021 at 8:26 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> 
>> Hi Luigi.
>> 
>> Weird. But maybe it is the desired behaviour of summary when calculating
>> mean of numeric column full of NAs.
>> 
>> See example
>> 
>> dat <- data.frame(x=rep(NA, 110), y=rep(1, 110), z= rnorm(110))
>> 
>> # change all values in second column to NA
>> dat[,2] <- NA
>> # change some of them to NAN
>> dat[5:6, 2:3] <- 0/0
>> 
>> # see summary
>> summary(dat)
>>    x                 y             z
>> Mode:logical   Min.   : NA   Min.   :-1.9798
>> NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>>                Median : NA   Median : 0.1745
>>                Mean   :NaN   Mean   : 0.1856
>>                3rd Qu.: NA   3rd Qu.: 0.8017
>>                Max.   : NA   Max.   : 2.5075
>>                NA's   :110   NA's   :2
>> 
>> # change NAN values to NA
>> dat[sapply(dat, is.nan)] <- NA
>> *************************
>> 
>> #summary is same
>> summary(dat)
>>    x                 y             z
>> Mode:logical   Min.   : NA   Min.   :-1.9798
>> NA's:110       1st Qu.: NA   1st Qu.:-0.4729
>>                Median : NA   Median : 0.1745
>>                Mean   :NaN   Mean   : 0.1856
>>                3rd Qu.: NA   3rd Qu.: 0.8017
>>                Max.   : NA   Max.   : 2.5075
>>                NA's   :110   NA's   :2
>> 
>> # but no NAN value in data
>> dat[1:10,]
>>    x  y          z
>> 1  NA NA -0.9148696
>> 2  NA NA  0.7110570
>> 3  NA NA -0.1901676
>> 4  NA NA  0.5900650
>> 5  NA NA         NA
>> 6  NA NA         NA
>> 7  NA NA  0.7987658
>> 8  NA NA -0.5225229
>> 9  NA NA  0.7673103
>> 10 NA NA -0.5263897
>> 
>> So my "nice compact command"
>> dat[sapply(dat, is.nan)] <- NA
>> 
>> works as expected, but summary gives as mean NAN.
>> 
>> Cheers
>> Petr
>> 
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
>>> Sent: Thursday, September 2, 2021 3:46 PM
>>> To: Andrew Simmons <akwsimmo at gmail.com>
>>> Cc: r-help <r-help at r-project.org>
>>> Subject: Re: [R] How to globally convert NaN to NA in dataframe?
>>> 
>>> `data[sapply(data, is.nan)] <- NA` is a nice compact command, but I still
>> get
>>> NaN when using the summary function, for instance one of the columns give:
>>> ```
>>> Min.   : NA
>>> 1st Qu.: NA
>>> Median : NA
>>> Mean   :NaN
>>> 3rd Qu.: NA
>>> Max.   : NA
>>> NA's   :110
>>> ```
>>> I tried to implement the second solution but:
>>> ```
>>> df <- lapply(x, function(xx) {
>>>  xx[is.nan(xx)] <- NA
>>> })
>>>> str(df)
>>> List of 1
>>> $ sd_ef_rash_loc___palm: logi NA
>>> ```
>>> What am I getting wrong?
>>> Thanks
>>> 
>>> On Thu, Sep 2, 2021 at 3:30 PM Andrew Simmons <akwsimmo at gmail.com>
>>> wrote:
>>>> 
>>>> Hello,
>>>> 
>>>> 
>>>> I would use something like:
>>>> 
>>>> 
>>>> x <- c(1:5, NaN) |> sample(100, replace = TRUE) |> matrix(10, 10) |>
>>>> as.data.frame() x[] <- lapply(x, function(xx) {
>>>>    xx[is.nan(xx)] <- NA_real_
>>>>    xx
>>>> })
>>>> 
>>>> 
>>>> This prevents attributes from being changed in 'x', but accomplishes the
>>> same thing as you have above, I hope this helps!
>>>> 
>>>> On Thu, Sep 2, 2021 at 9:19 AM Luigi Marongiu <marongiu.luigi at gmail.com>
>>> wrote:
>>>>> 
>>>>> Hello,
>>>>> I have some NaN values in some elements of a dataframe that I would
>>>>> like to convert to NA.
>>>>> The command `df1$col[is.nan(df1$col)]<-NA` allows to work column-wise.
>>>>> Is there an alternative for the global modification at once of all
>>>>> instances?
>>>>> I have seen from
>>>>> https://stackoverflow.com/questions/18142117/how-to-replace-nan-
>>> value
>>>>> -with-zero-in-a-huge-data-frame/18143097#18143097
>>>>> that once could use:
>>>>> ```
>>>>> 
>>>>> is.nan.data.frame <- function(x)
>>>>> do.call(cbind, lapply(x, is.nan))
>>>>> 
>>>>> data123[is.nan(data123)] <- 0
>>>>> ```
>>>>> replacing o with NA, but I got
>>>>> ```
>>>>> str(df)
>>>>>> logi NA
>>>>> ```
>>>>> when modifying my dataframe df.
>>>>> What would be the correct syntax?
>>>>> Thank you
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> Best regards,
>>>>> Luigi
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> --
>>> Best regards,
>>> Luigi
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From r@oknz @end|ng |rom gm@||@com  Fri Sep  3 16:24:57 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 4 Sep 2021 02:24:57 +1200
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
Message-ID: <CABcYAdKHY7vrjGsicgNxB7ggRnYYqe23=onWNd0TpOJ6J2e4gQ@mail.gmail.com>

Your question is ambiguous.
One reading is
  n <- length(table$Data)
  m <- n %/% 3
  s <- sample(1:n, n)
  X <- table$Data[s[1:m]]
  Y <- table$Data[s[(m+1):(2*m)]]
  Z <- table$Data[s[(m*2+1):(3*m)]]




On Fri, 3 Sept 2021 at 13:31, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 16:27:45 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 3 Sep 2021 10:27:45 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <012901d7a06d$50067980$f0136c80$@verizon.net>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <00e501d7a064$e7113f80$b533be80$@verizon.net>
 <CAE9stmdgQRWkJZOKqy7PYFTiSgC+v0oc1qkKEsFGbfzNo03HEg@mail.gmail.com>
 <012901d7a06d$50067980$f0136c80$@verizon.net>
Message-ID: <CAE9stmfRFtgQLxBWASnir7kdwY+2uMVp4C82ta4ie1XvasNgzg@mail.gmail.com>

Hi Avi: good morning

Again, many thanks to all of you. I appreciate all what you are doing. You
are good. I did it in Minitab. It cost me a little bit more time, but it is
okay.

It was a little bit confusing for me to do it in R. Because in *Step 1: *I
have to select a random sample of size n=204 (say) out of N=700 (say). Then
in Step 2: I have to allocate the 204 randomly selected obs. into three
groups of equal sample sizes.

Again, thank you very much, and sorry if I bothered you.


with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Thu, Sep 2, 2021 at 10:42 PM Avi Gross via R-help <r-help at r-project.org>
wrote:

> Abou,
>
>
>
> I am not trying to be negative. Assuming you are a professor of
> Statistics, your request seems odd as what you are asking about is very
> routine in much of statistical work where you want to make a model or
> something using just part of your data and need to reserve some to check if
> you perhaps trained an algorithm too much for the original data used.
>
>
>
> A simple online search before asking questions here is appreciated. I did
> a quick search for something like ?R split data into three parts? and see
> several applicable answers.
>
>
>
> There are people on this forum who actually get paid to do nontrivial
> tasks and do not mind help in spots but feel sort of used if expected to
> write a serious amount of code and perhaps then be asked to redo it with
> more bells and whistles added. A recent badly phrased request comes to mind
> where several of us provided and answer only to find out it was for a
> different scenario, ?
>
>
>
> So let me continue with a serious answer. May we assume you KNOW how to
> read the data in to something like a data.frame? If so, and if you see no
> need or value in doing this the hard way, then your question could have
> been to ask if there is an R built-in function or perhaps a pacjkage
> already set to solve it quickly. Again, a simple online search can do
> wonders.  Here, for example is a package called caret and this page
> discusses spliutting data multiple ways:
>
>
>
> https://topepo.github.io/caret/data-splitting.html
>
>
>
> There are other such pages suggesting how to do it using base R.
>
>
>
> Here is one that gives an example on how to make  three unequal partitions:
>
>
>
> inds <- partition(iris$Sepal.Length, p = c(train = 0.6, valid = 0.2, test
> = 0.2))
>
>
>
>
>
> There is more to do below but in the above, you would use whatever names
> you want instead of train/valid/test and set all three to 0.33 and so on.
>
>
>
> I repeat, that what you want to do strikes some of us as a fairly routine
> thing to do and lots of people have written how they have done it and you
> can pick and choose, or redo it on your own. If what you have is a homework
> assignment, the appropriate thing is to have you learn to use some
> technique yourself and perhaps get minor help when it fails. But if you
> will be doing this regularly, use of some packages is highly valuable.
>
>
>
> Good Luck.
>
>
>
>
>
>
>
>
>
>
>
> From: AbouEl-Makarim Aboueissa <abouelmakarim1962 at gmail.com>
> Sent: Thursday, September 2, 2021 9:51 PM
> To: Avi Gross <avigross at verizon.net>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] Splitting a data column randomly into 3 groups
>
>
>
> Sorry, please forget about it. I believe that I am very serious when I
> posted my question.
>
>
>
> with thanks
>
> abou
>
>
> ______________________
>
> AbouEl-Makarim Aboueissa, PhD
>
>
>
> Professor, Statistics and Data Science
>
> Graduate Coordinator
>
> Department of Mathematics and Statistics
>
> University of Southern Maine
>
>
>
>
>
>
>
> On Thu, Sep 2, 2021 at 9:42 PM Avi Gross via R-help <r-help at r-project.org
> <mailto:r-help at r-project.org> > wrote:
>
> What is stopping you Abou?
>
> Some of us here start wondering if we have better things to do than
> homework for others. Help is supposed to be after they try and encounter
> issues that we may help with.
>
> So think about your problem. You supplied data in a file that is NOT in
> CSV format but is in Tab separated format.
>
> You need to get it in to your program and store it in something. It looks
> like you have 204 items so 1/3 of those would be exactly 68.
>
> So if your data is in an object like a vector or data.frame, you want to
> choose random number between 1 and 204. How do you do that? You need 1/3 of
> the length of the object items, in your case 68.
>
> Now extract the items with  those indices into say A1. Extract all the
> rest into a temporary item.
>
> Make another 68 random indices, with no overlap, and copy those items into
> A2 and the ones that do not have those into A3 and you are sort of done,
> other than some cleanup or whatever.
>
> There are many ways to do the above and I am sure packages too.
>
> But since you have made no visible effort, I personally am not going to
> pick anything in particular.
>
> Had you shown some text and code along the lines of the above and just
> wanted to know how to copy just the ones that were not selected, we could
> easily ...
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org <mailto:
> r-help-bounces at r-project.org> > On Behalf Of AbouEl-Makarim Aboueissa
> Sent: Thursday, September 2, 2021 9:30 PM
> To: R mailing list <r-help at r-project.org <mailto:r-help at r-project.org> >
> Subject: [R] Splitting a data column randomly into 3 groups
>
> Dear All:
>
> How to split a column data *randomly* into three groups. Please see the
> attached data. I need to split column #2 titled "Data"
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science* *Graduate Coordinator*
>
> *Department of Mathematics and Statistics* *University of Southern Maine*
>
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Sep  3 16:29:07 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 3 Sep 2021 10:29:07 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CABcYAdKHY7vrjGsicgNxB7ggRnYYqe23=onWNd0TpOJ6J2e4gQ@mail.gmail.com>
References: <CAE9stmd5Rn4oXK=gF0dOKz_ckwOcLaKfUcc7ZoRBiUooBTXkOA@mail.gmail.com>
 <CABcYAdKHY7vrjGsicgNxB7ggRnYYqe23=onWNd0TpOJ6J2e4gQ@mail.gmail.com>
Message-ID: <CAE9stmd6qWnzcqyna9=kUXWKXrEzGhwz=k0h2s2Q4iS4rHyuhg@mail.gmail.com>

Hi Richard:

Thank you very much for your help in this matter.

with thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Fri, Sep 3, 2021 at 10:25 AM Richard O'Keefe <raoknz at gmail.com> wrote:

> Your question is ambiguous.
> One reading is
>   n <- length(table$Data)
>   m <- n %/% 3
>   s <- sample(1:n, n)
>   X <- table$Data[s[1:m]]
>   Y <- table$Data[s[(m+1):(2*m)]]
>   Z <- table$Data[s[(m*2+1):(3*m)]]
>
>
>
>
> On Fri, 3 Sept 2021 at 13:31, AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > Dear All:
> >
> > How to split a column data *randomly* into three groups. Please see the
> > attached data. I need to split column #2 titled "Data"
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep  3 17:37:13 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 3 Sep 2021 08:37:13 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
 <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2109030833500.10519@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Jeff Newmiller wrote:

> Regardless of whether you use the lower-level split function, or the
> higher-level aggregate function, or the tidyverse group_by function, the
> key is learning how to create the column that is the same for all records
> corresponding to the time interval of interest.

Jeff,

I tried responding to only you but my message bounced:

<jdnewmil at dcn.davis.ca.us>: host
     d9300a.ess.barracudanetworks.com[209.222.82.252] said: 550 permanent
     failure for one or more recipients (jdnewmil at dcn.davis.ca.us:blocked) (in
     reply to end of DATA command)

My response was not pertininet to the entire list, IMO, so I sent it to your
address.

Rich


From Stephen@Bond @end|ng |rom c|bc@com  Fri Sep  3 18:01:35 2021
From: Stephen@Bond @end|ng |rom c|bc@com (Bond, Stephen)
Date: Fri, 3 Sep 2021 16:01:35 +0000
Subject: [R] coxph means not equal to means of model matrix
Message-ID: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>

Hi,

Please, help me understand what is happening with the means of a Cox model?
I have:
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

getOption("contrasts")
        unordered           ordered
"contr.treatment"      "contr.poly"

According to the help  coxph.object has a component holding the means of the X (model.matrix). This does not hold any more.
```
library(survival)
test1 <- list(time=c(4,3,1,1,2,2,3),
                   status=c(1,1,1,0,1,1,0),
                   x=c(0,2,1,1,1,0,0),
                   sex=factor(c(0,0,0,0,1,1,1)))
m1 <- coxph(Surv(time, status) ~ x + sex, test1)
m1$means
##        x      sex1
## 0.7142857 0.0000000
colMeans(model.matrix(m1))
##         x      sex1
## 0.7142857 0.4285714

```
Will new observations be scored using the zero mean from the object?? Is this just a reporting change where $means shows the reference level and no longer the mean of the model matrix??

Thanks everybody



	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Fri Sep  3 18:37:24 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Sep 2021 11:37:24 -0500
Subject: [R] coxph means not equal to means of model matrix
In-Reply-To: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
References: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <2e47ad$giu8ae@ironport10.mayo.edu>

See ?coxph, in particular the new "nocenter" option.

Basically, the "mean" component is used to center later computations.? This can be 
critical for continuous variables, avoiding overflow in the exp function, but is not 
necessary for 0/1 covariates.?? The fact that the default survival curve would be for a 
sex of .453, say, was off-putting to many.

Terry T.


On 9/3/21 11:01 AM, Bond, Stephen wrote:
>
> Hi,
>
> Please, help me understand what is happening with the means of a Cox model?
>
> I have:
>
> R version 4.0.2 (2020-06-22) -- "Taking Off Again"
>
> Copyright (C) 2020 The R Foundation for Statistical Computing
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> getOption("contrasts")
>
> ??????? unordered?????????? ordered
>
> "contr.treatment"????? "contr.poly"
>
> According to the help ?coxph.object has a component holding the means of the X 
> (model.matrix). This does not hold any more.
>
> ```
>
> library(survival)
>
> test1 <- list(time=c(4,3,1,1,2,2,3),
>
> ???????????????????status=c(1,1,1,0,1,1,0),
>
> ???????????????????x=c(0,2,1,1,1,0,0),
>
> ???????????????????sex=factor(c(0,0,0,0,1,1,1)))
>
> m1 <- coxph(Surv(time, status) ~ x + sex, test1)
>
> m1$means
>
> ##??????? x????? sex1
>
> ## 0.7142857 0.0000000
>
> colMeans(model.matrix(m1))
>
> ##???????? x????? sex1
>
> ## 0.7142857 0.4285714
>
> ```
>
> Will new observations be scored using the zero mean from the object?? Is this just a 
> reporting change where $means shows the reference level and no longer the mean of the 
> model matrix??
>
> Thanks everybody
>


	[[alternative HTML version deleted]]


From Stephen@Bond @end|ng |rom c|bc@com  Fri Sep  3 19:59:37 2021
From: Stephen@Bond @end|ng |rom c|bc@com (Bond, Stephen)
Date: Fri, 3 Sep 2021 17:59:37 +0000
Subject: [R] coxph means not equal to means of model matrix
In-Reply-To: <2e47ad$giu8af@ironport10.mayo.edu>
References: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
 <2e47ad$giu8af@ironport10.mayo.edu>
Message-ID: <YT3PR01MB5026E0FB5440DC99B1D82DBBE6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>

I looked at the nocenter and it says (-1,0,1) values but it seems that any three-level factor is included in that (represented as 1,2,3 in R) .
Also, is the baseline curve now showing the reference level and not the fictional .428 sex? If I predict the risk for a new row, should I multiply the coefficient shown in the output by 1 for a sex=1? It used to be (1-.428)*coef.
Thanks for clarifying.
SB

From: Therneau, Terry M., Ph.D. <therneau at mayo.edu>
Sent: Friday, 3 September, 2021 12:37
To: Bond, Stephen <Stephen.Bond at cibc.com>
Cc: R-help <r-help at R-project.org>
Subject: Re: coxph means not equal to means of model matrix

[EXTERNAL]
________________________________
See ?coxph, in particular the new "nocenter" option.

Basically, the "mean" component is used to center later computations.  This can be critical for continuous variables, avoiding overflow in the exp function, but is not necessary for 0/1 covariates.   The fact that the default survival curve would be for a sex of .453, say, was off-putting to many.

Terry T.

On 9/3/21 11:01 AM, Bond, Stephen wrote:
Hi,

Please, help me understand what is happening with the means of a Cox model?
I have:
R version 4.0.2 (2020-06-22) -- "Taking Off Again"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

getOption("contrasts")
        unordered           ordered
"contr.treatment"      "contr.poly"

According to the help  coxph.object has a component holding the means of the X (model.matrix). This does not hold any more.
```
library(survival)
test1 <- list(time=c(4,3,1,1,2,2,3),
                   status=c(1,1,1,0,1,1,0),
                   x=c(0,2,1,1,1,0,0),
                   sex=factor(c(0,0,0,0,1,1,1)))
m1 <- coxph(Surv(time, status) ~ x + sex, test1)
m1$means
##        x      sex1
## 0.7142857 0.0000000
colMeans(model.matrix(m1))
##         x      sex1
## 0.7142857 0.4285714

```
Will new observations be scored using the zero mean from the object?? Is this just a reporting change where $means shows the reference level and no longer the mean of the model matrix??

Thanks everybody



ATTENTION : This email originated outside your organization. Exercise caution before clicking links, opening attachments, or responding with personal information.
________________________________

	[[alternative HTML version deleted]]


From therne@u @end|ng |rom m@yo@edu  Fri Sep  3 21:10:00 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Sep 2021 14:10:00 -0500
Subject: [R] coxph means not equal to means of model matrix
In-Reply-To: <YT3PR01MB5026E0FB5440DC99B1D82DBBE6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
References: <YT3PR01MB502649419C3D4D226D854524E6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
 <2e47ad$giu8af@ironport10.mayo.edu>
 <YT3PR01MB5026E0FB5440DC99B1D82DBBE6CF9@YT3PR01MB5026.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <2e47ad$givhj1@ironport10.mayo.edu>



On 9/3/21 12:59 PM, Bond, Stephen wrote:
>
> I looked at the nocenter and it says (-1,0,1) values but it seems that any three-level 
> factor is included in that (represented as 1,2,3 in R) .
>
A factor is turned into a set of 0/1 dummy variable, so the nocenter applies.? I will add 
more clarification to the documentation.

> Also, is the baseline curve now showing the reference level and not the fictional .428 
> sex? If I predict the risk for a new row, should I multiply the coefficient shown in the 
> output by 1 for a sex=1? It used to be (1-.428)*coef.
>
Yes, the "mean" component is the reference level for predict and survfit.? If I could go 
back in time it would be labeled as "reference" instead of "mean".?? Another opportunity 
for me to make the documentation clearer.

Good questions,
 ? Terry T

> Thanks for clarifying.
>
> SB
>
> *From:* Therneau, Terry M., Ph.D. <therneau at mayo.edu>
> *Sent:* Friday, 3 September, 2021 12:37
> *To:* Bond, Stephen <Stephen.Bond at cibc.com>
> *Cc:* R-help <r-help at R-project.org>
> *Subject:* Re: coxph means not equal to means of model matrix
>
> [EXTERNAL]
>
> ------------------------------------------------------------------------------------------
>
> See ?coxph, in particular the new "nocenter" option.
>
> Basically, the "mean" component is used to center later computations.? This can be 
> critical for continuous variables, avoiding overflow in the exp function, but is not 
> necessary for 0/1 covariates.?? The fact that the default survival curve would be for a 
> sex of .453, say, was off-putting to many.
>
> Terry T.
>
> On 9/3/21 11:01 AM, Bond, Stephen wrote:
>
>     Hi,
>
>     Please, help me understand what is happening with the means of a Cox model?
>
>     I have:
>
>     R version 4.0.2 (2020-06-22) -- "Taking Off Again"
>
>     Copyright (C) 2020 The R Foundation for Statistical Computing
>
>     Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>     getOption("contrasts")
>
>     ??????? unordered ordered
>
>     "contr.treatment" "contr.poly"
>
>     According to the help ?coxph.object has a component holding the means of the X
>     (model.matrix). This does not hold any more.
>
>     ```
>
>     library(survival)
>
>     test1 <- list(time=c(4,3,1,1,2,2,3),
>
>     ???????????????????status=c(1,1,1,0,1,1,0),
>
>     ???????????????????x=c(0,2,1,1,1,0,0),
>
>     ???????????????????sex=factor(c(0,0,0,0,1,1,1)))
>
>     m1 <- coxph(Surv(time, status) ~ x + sex, test1)
>
>     m1$means
>
>     ##??????? x????? sex1
>
>     ## 0.7142857 0.0000000
>
>     colMeans(model.matrix(m1))
>
>     ##???????? x????? sex1
>
>     ## 0.7142857 0.4285714
>
>     ```
>
>     Will new observations be scored using the zero mean from the object?? Is this just a
>     reporting change where $means shows the reference level and no longer the mean of
>     the model matrix??
>
>     Thanks everybody
>
> ATTENTION : This email originated outside your organization. Exercise caution before 
> clicking links, opening attachments, or responding with personal information.
>
> ------------------------------------------------------------------------------------------


	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Fri Sep  3 21:17:53 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 3 Sep 2021 12:17:53 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
Message-ID: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>

On Thu, 2 Sep 2021, Jeff Newmiller wrote:

> Regardless of whether you use the lower-level split function, or the
> higher-level aggregate function, or the tidyverse group_by function, the
> key is learning how to create the column that is the same for all records
> corresponding to the time interval of interest.

Jeff,

I definitely agree with the above

> If you convert the sampdate to POSIXct, the tz IS important, because most
> of us use local timezones that respect daylight savings time, and a naive
> conversion of standard time will run into trouble if R is assuming
> daylight savings time applies. The lubridate package gets around this by
> always assuming UTC and giving you a function to "fix" the timezone after
> the conversion. I prefer to always be specific about timezones, at least
> by using so something like
>    Sys.setenv( TZ = "Etc/GMT+8" )
> which does not respect daylight savings.

I'm not following you here. All my projects have always been in a single
time zone and the data might be recorded at June 19th or November 4th but do
not depend on whether the time is PDT or PST. My hosts all set the hardware
clock to local time, not UTC.

As the location(s) at which data are collected remain fixed geographically I
don't understand why daylight savings time, or non-daylight savings time is
important.

> Regarding using character data for identifying the month, in order to have
> clean plots of the data I prefer to use the trunc function but it returns
> a POSIXlt so I convert it to POSIXct:

I don't use character data for months, as far as I know. If a sample data
is, for example, 2021-09-03 then monthly summaries are based on '09', not
'September.'

I've always valued your inputs to help me understand what I don't. In this
case I'm really lost in understanding your position.

Have a good Labor Day weekend,

Rich


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  4 08:30:26 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 3 Sep 2021 23:30:26 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>
Message-ID: <alpine.BSF.2.00.2109032251260.3401@pedal.dcn.davis.ca.us>

On Fri, 3 Sep 2021, Rich Shepard wrote:

> On Thu, 2 Sep 2021, Jeff Newmiller wrote:
>
>> Regardless of whether you use the lower-level split function, or the
>> higher-level aggregate function, or the tidyverse group_by function, the
>> key is learning how to create the column that is the same for all records
>> corresponding to the time interval of interest.
>
> Jeff,
>
> I definitely agree with the above
>
>> If you convert the sampdate to POSIXct, the tz IS important, because most
>> of us use local timezones that respect daylight savings time, and a naive
>> conversion of standard time will run into trouble if R is assuming
>> daylight savings time applies. The lubridate package gets around this by
>> always assuming UTC and giving you a function to "fix" the timezone after
>> the conversion. I prefer to always be specific about timezones, at least
>> by using so something like
>>    Sys.setenv( TZ = "Etc/GMT+8" )
>> which does not respect daylight savings.
>
> I'm not following you here. All my projects have always been in a single
> time zone and the data might be recorded at June 19th or November 4th but do
> not depend on whether the time is PDT or PST. My hosts all set the hardware
> clock to local time, not UTC.

The fact that your projects are in a single time zone is irrelevant. I am 
not sure how you can be so confident in saying it does not matter whether 
the data were recorded in PDT or PST, since if it were recorded in PDT 
then there would be a day in March with 23 hours and another day in 
November with 25 hours, but if it were recorded in PST then there would 
always be 24 hours in every day, and R almost always assumes daylight 
savings if you don't tell it otherwise!

I am also normally working with automated collection devices that record 
data in standard time year round. But if you fail to tell R that this is 
the case, then it will almost always assume your data are stored with 
daylight savings time and screw up the conversion to computable time 
format. This screw up may include NA values in spring time when standard 
time has perfectly valid times between 1am and 2am on the changeover day, 
but in daylight time those timestamps would be invalid and will end up as 
NA values in your timestamp column.

> As the location(s) at which data are collected remain fixed geographically I
> don't understand why daylight savings time, or non-daylight savings time is
> important.

I am telling you that it is important _TO R_ if you use POSIXt times. 
Acknowledge this and move on with life, or avoid POSIXt data. As I said, 
one way to acknowledge this while limiting the amount of attention you 
have to give to the problem is to use UTC/GMT everywhere... but this can 
lead to weird time of day problems as I pointed out in my timestamp 
cleaning slides: 
https://jdnewmil.github.io/time-2018-10/TimestampCleaning.html

If you want to use GMT everywhere... then you have to use GMT explicitly 
because the default timezone in R is practically never GMT for most 
people. You. Need. To. Be. Explicit. Don't fight it. Just do it. It isn't 
hard.

>> Regarding using character data for identifying the month, in order to have
>> clean plots of the data I prefer to use the trunc function but it returns
>> a POSIXlt so I convert it to POSIXct:
>
> I don't use character data for months, as far as I know. If a sample data
> is, for example, 2021-09-03 then monthly summaries are based on '09', not
> 'September.'

You are taking this out of context and complaining that it has no context. 
This was a reply to a response by Andrew Simmons in which he used the 
"format" function to create unique year/month strings to act as group-by 
data. Earlier, when I originally responded to clarify how you could use 
the dplyr group_by function, I used your character date column without 
combining it with time or convertint to Date at all. If you studied these 
responses more carefully you would indeed have been using character data 
for grouping in some cases, and my only point was that doing so can indeed 
be a shortcut to the immediate answer while being troublesome later in the 
analysis. Accusing you of mishandling data was not my intention.

> I've always valued your inputs to help me understand what I don't. In this
> case I'm really lost in understanding your position.

I hope my comments are clear enough now.

> Have a good Labor Day weekend,

Thanks! (Not relevant to many on this list.)

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Sep  4 14:42:51 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 4 Sep 2021 05:42:51 -0700 (PDT)
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <alpine.BSF.2.00.2109032251260.3401@pedal.dcn.davis.ca.us>
References: <alpine.LNX.2.20.2109031217230.10519@salmo.appl-ecosys.com>
 <alpine.BSF.2.00.2109032251260.3401@pedal.dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2109040541470.29254@salmo.appl-ecosys.com>

On Fri, 3 Sep 2021, Jeff Newmiller wrote:

> The fact that your projects are in a single time zone is irrelevant. I am
> not sure how you can be so confident in saying it does not matter whether
> the data were recorded in PDT or PST, since if it were recorded in PDT
> then there would be a day in March with 23 hours and another day in
> November with 25 hours, but if it were recorded in PST then there would
> always be 24 hours in every day, and R almost always assumes daylight
> savings if you don't tell it otherwise!

Got it, Jeff. Thanks very much.

Regards,

Rich


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Sat Sep  4 18:06:57 2021
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Sat, 4 Sep 2021 16:06:57 +0000
Subject: [R] Managing NA values in aggregate
Message-ID: <8B435C9568170B469AE31E8891E8CC4F011E6DE4FF@ESINO.regionemarche.intra>

Dear R-list users,
I encountered a silly problem using aggregate, but I am not able to get rid of it.
I read the manual quite carefully, probaby not enough.
Suppose I have the following data frame:

mydf <- data.frame(year_month=rep(c("2003-12", "2004-12", "2005-12"), 3), station_number=c(rep(1818,3), rep(1819,3), rep(1820,3)), value=c(NA, NA, 20, NA, NA, 40, NA, 15, 50))

I want aggregate the column value by the column year_month, but I need to preserve rows with NA when all data are NA:

aggregate(mydf$value, list(mydf$year_month), sum) gives
1 2003-12  NA
2 2004-12  NA
3 2005-12 110

aggregate(mydf$value, list(mydf$year_month), sum, na.rm=TRUE) gives
1 2003-12   0
2 2004-12  15
3 2005-12 110

but I need
1 2003-12   NA
2 2004-12  15
3 2005-12 110

How can I get it?
Thank you for your attention and your help
Stefano


         (oo)
--oOO--( )--OOo--------------------------------------
Stefano Sofia PhD
Civil Protection - Marche Region - Italy
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona (AN)
Uff: +39 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------------------------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
This message was scanned by Libraesva ESG and is believed to be clean.


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Sep  4 18:21:38 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 04 Sep 2021 09:21:38 -0700
Subject: [R] Managing NA values in aggregate
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F011E6DE4FF@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F011E6DE4FF@ESINO.regionemarche.intra>
Message-ID: <92AF0B15-0F5E-4EDD-A59A-68A850FBAC9C@dcn.davis.ca.us>

Literal translation...

aggregate( mydf$value
         , mydf[ , "year_month", drop=FALSE ]
         , function( x ) if ( all( is.na( x ) ) ) NA else sum( x, na.rm = TRUE )
         )

On September 4, 2021 9:06:57 AM PDT, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
>Dear R-list users,
>I encountered a silly problem using aggregate, but I am not able to get rid of it.
>I read the manual quite carefully, probaby not enough.
>Suppose I have the following data frame:
>
>mydf <- data.frame(year_month=rep(c("2003-12", "2004-12", "2005-12"), 3), station_number=c(rep(1818,3), rep(1819,3), rep(1820,3)), value=c(NA, NA, 20, NA, NA, 40, NA, 15, 50))
>
>I want aggregate the column value by the column year_month, but I need to preserve rows with NA when all data are NA:
>
>aggregate(mydf$value, list(mydf$year_month), sum) gives
>1 2003-12  NA
>2 2004-12  NA
>3 2005-12 110
>
>aggregate(mydf$value, list(mydf$year_month), sum, na.rm=TRUE) gives
>1 2003-12   0
>2 2004-12  15
>3 2005-12 110
>
>but I need
>1 2003-12   NA
>2 2004-12  15
>3 2005-12 110
>
>How can I get it?
>Thank you for your attention and your help
>Stefano
>
>
>         (oo)
>--oOO--( )--OOo--------------------------------------
>Stefano Sofia PhD
>Civil Protection - Marche Region - Italy
>Meteo Section
>Snow Section
>Via del Colle Ameno 5
>60126 Torrette di Ancona, Ancona (AN)
>Uff: +39 071 806 7743
>E-mail: stefano.sofia at regione.marche.it
>---Oo---------oO----------------------------------------
>
>________________________________
>
>AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
>--
>Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
>This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Sep  4 18:22:14 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 4 Sep 2021 17:22:14 +0100
Subject: [R] combining geom_boxplot and geom_point with jitter
In-Reply-To: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
References: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
Message-ID: <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>

Hello,

The problem is that you have two grouping aesthetics, color and shape.
In geom_point make the group explicit:


p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
p <- p + geom_boxplot(outlier.shape = NA)

p + geom_point(
   mapping = aes(shape = NMP_cat, group = Software),
   position = position_jitterdodge()
)


Hope this helps,

Rui Barradas

?s 09:54 de 02/09/21, Ivan Calandra escreveu:
> Dear useRs,
> 
> I'm having a problem to combine geom_boxplot and geom_point with jitter. 
> It is difficult to explain but the code and result should make it clear 
> (the example dataset is long so I copy it at the end of the email):
> 
> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
> p <- p + geom_boxplot(outlier.shape = NA)
> p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
> position_jitterdodge())
> print(p)
> 
> As you can see in the resulting plot, the points with different shapes 
> are dodged across the boxplot categories (colors). I'd like the three 
> shapes per color to be restricted in one boxplot color, with jitter of 
> course to better visualize the points.
> 
> Does that make sense?
> 
> I have played with the arguments of position_jitterdodge(), but it seems 
> to me that the problem is that the shape aesthetic is not in the 
> geom_boxplot() call (but I don't want it there, see below).
> 
> For background information, the column used for shape gives some sort of 
> "quality" to the points; that's why I want to show the points 
> differently, so that it can easily be seen whether "good" points plot in 
> the same area as the "bad" points.
> Because I'm doing facet plots with other variables, I do not want to 
> separate these categories in the boxplots - the resulting plots would be 
> overcrowded.
> 
> Thank you for the help.
> Ivan
> 
> ---
> 
> my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
> "Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
> "Dry grass", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", 
> "Dry bamboo", "Dry bamboo",
> "Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
> "Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
> 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 
> 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 2L, 
> 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 2L, 2L), .Label = c("0-5%", "5-10%", 
> "10-20%", "20-100%"), class = c("ordered", "factor")), name = 
> structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), 
> .Label = c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), 
> class = "factor"), value = c(16.00716636, 12.925787, 14.05932485, 
> 11.999816, 15.12321532, 12.711474, 12.79565826, 10.900949, 15.90481161, 
> 12.836045, 16.22778102, 13.565995, 14.71354945, 12.384152, 16.61354777, 
> 13.714165, 15.91399496, 12.983796, 19.44739619, 15.173215, 16.13761798, 
> 12.932798, 14.7332952, 12.10277, 10.78710961, 8.762726, 10.16027362, 
> 8.040399, 14.53444662, 11.527896, 17.38120685, 13.78922, 11.26840546, 
> 9.426558, 24.01797992, 18.398553, 13.7435699, 11.44385, 14.391873, 
> 10.757141, 22.39390393, 18.176262, 11.60322022, 9.969118, 11.6099975, 
> 10.059618, 11.86282935, 10.280864, 16.22473644, 13.562839, 12.46350165, 
> 10.629406, 23.9347534, 19.062174, 19.58121507, 15.910959, 13.99145447, 
> 11.352648, 14.38942328, 11.821431, 23.4733371, 18.549503, 13.08142223, 
> 10.735494, 17.09293046, 13.012834, 28.80020878, 22.447105, 25.74460885, 
> 19.76834, 14.29106582, 12.233774, 12.03005024, 10.364224, 12.58953574, 
> 10.30257, 18.07111578, 14.416143, 20.85562751, 16.524047, 21.06132234, 
> 15.744758, 15.24052683, 11.891487, 11.62446752, 9.14325, 11.75704705, 
> 10.358542, 13.65568703, 11.766129, 16.98137759, 12.594787, 11.6560954, 
> 10.32073, 15.46708251, 13.199232, 13.20110131, 11.060226, 16.13986173, 
> 13.564802, 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 
> 11.994841, 12.07940958, 9.470493, 13.93630412, 11.489685, 21.84464295, 
> 17.806018, 17.4383111, 14.478338, 20.55074297, 16.254467, 30.15238714, 
> 24.193768, 32.8541897, 25.769585, 32.06966759, 24.507185, 20.53975772, 
> 15.951186, 11.54494952, 9.676342, 13.56490524, 11.456356, 13.58242208, 
> 10.919419, 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 
> 18.749955, 26.38707155, 20.877856, 26.18252748, 20.758242)), row.names = 
> c(NA, -140L), class = c("tbl_df", "tbl", "data.frame"))
>


From tg@77m @end|ng |rom y@hoo@com  Sat Sep  4 18:25:40 2021
From: tg@77m @end|ng |rom y@hoo@com (Thomas Subia)
Date: Sat, 4 Sep 2021 09:25:40 -0700
Subject: [R] . Re: Splitting a data column randomly into 3 groups
References: <006c01d7a1a9$80cca840$8265f8c0$.ref@yahoo.com>
Message-ID: <006c01d7a1a9$80cca840$8265f8c0$@yahoo.com>

I was wondering if this is a good alternative method to split a data column
into distinct groups.
Let's say I want my first group to have 4 elements selected randomly

mydata <- LETTERS[1:11] 
 random_grp <- sample(mydata,4,replace=FALSE)

Now random_grp is:
> random_grp
[1] "H" "E" "A" "D"
# How's that for a random selection!

Now my choices for another group of random data now becomes:
 data_wo_random <- setdiff(mydata,random_grp)

> data_wo_random
[1] "B" "C" "F" "G" "I" "J" "K"

Now from this reduced dataset, I can generate another random selection with
any size I choose.

One problem with this is that this is cumbersome when ones original dataset
is large or when one wants to subgroup the original dataset into many
different subgroup sizes.

Nevertheless, it's an intuitive method which is relatively easy to
understand

Hope this helps!

Thomas Subia
Statistician


From m|n@h@|| @end|ng |rom um|ch@edu  Sat Sep  4 18:31:04 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Sat, 04 Sep 2021 19:31:04 +0300
Subject: [R] How to globally convert NaN to NA in dataframe?
In-Reply-To: Your message of "Thu, 02 Sep 2021 15:44:07 -0400."
 <9df5d40e-f922-1282-025f-2b6b0b09e2e6@gmail.com>
Message-ID: <1314604.1630773064@apollo2.minshall.org>

Duncan,

> x[] <- lapply(...) says "set the values in x to the values in the list
> on the RHS", so x retains its class.

thanks!

cheers, Greg


From @v|gro@@ @end|ng |rom ver|zon@net  Sat Sep  4 19:58:18 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 4 Sep 2021 13:58:18 -0400
Subject: [R] . Re: Splitting a data column randomly into 3 groups
In-Reply-To: <006c01d7a1a9$80cca840$8265f8c0$@yahoo.com>
References: <006c01d7a1a9$80cca840$8265f8c0$.ref@yahoo.com>
 <006c01d7a1a9$80cca840$8265f8c0$@yahoo.com>
Message-ID: <00f601d7a1b6$7193a420$54baec60$@verizon.net>

Thomas,

There are many approaches tried over the years to do partitioning along the
lines you mentioned and others. R already has many built-in or in packages
including some that are quite optimized. So anyone doing serious work can
often avoid doing this the hard way and build on earlier work.

Now, obviously, some people learning may take on such challenges or have
them assigned as homework. And if you want to tweak the efficiency, you may
be able to do things like knowing the conditions needed by sample() are met,
you can directly call sample.int() and so on.

But fundamentally, a large subset of all these kinds of sampling can often
be done by just playing with indices. It does not matter whether your data
is in the form of a list or other kind of vector or a data.frame or matrix.
Anything you can subset with integers will do.

So an algorithm could determine how many subsets of the indices you want and
calculate how many you want in each bucket and it can be done fairly simply.
One approach might be to scramble the indices in some form, and that can be
a vector of them or something more like an unordered set. You then take the
first number of them as needed for the first partition then the next ones
for the additional partitions. Finally, you apply the selected ones to
subset the original data into multiple smaller data collections.

Obviously you can instead work in stages, if you prefer. Your algorithm
seems to be along those lines. Start with your full data and pull out what
you want for the first partition. Then with what is left, repeat for the
second partition and so on, till what is left is used for the final
partition. Arguably this may in some ways be more work, especially for
larger amounts of data.

I do note many statistical processes, such as bootstrapping, may include
allowing various kinds of overlap in which the same items are allowed to be
used repeatedly, sometimes even within a single random sample. In those
cases, the algorithm has to include replacement and that is a somewhat
different discussion.

What I am finding here is that many problems posed are not explained in the
way they turn out to be needed in the end. So answering a question before we
know what it is can be a tad premature and waste time all around. But in
reality, some people new to R or computing in general, may be stuck
precisely on understanding the question they are trying to solve or may not
realize their use of language (especially when English is not one of their
stronger languages) can be a problem as their listeners/readers assume they
mean something else.

Your suggestion of how to do some things is reasonable and you note a
question about larger amounts of data. Many languages, for example Python,
will often have higher-level abilities arguable better designed for some
problems. R was built with vectorization in mind and most things are
ultimately vectors in a sense. For some purposes, it would be nice to have
an implementation of primitives along the lines of sets and bags and
hashes/dictionaries and so on. People have added some things along these
lines but if you look at the implementation of your use of setdiff(), it
just calls unique on two arguments coerced into vector format!

So consider what happens if you instead start in a language where you can
use a native construct called a set where sets are implemented efficiently.
To make N groupings that are distinct, you might start by adding all the
indices, or even complete entities, into the set. You can then ask to get a
random element from the set (perhaps also with deletion) until you have
reached your N items. You can then ask for the next group of N' and then N''
till you have what you need and perhaps the set is empty. An implementation
that uses some form of hashing to store and access set items can make
finding things take the same amount of time no matter the size. There is no
endless copying of parts of data. There may be no need for a setdiff() step
or if used, a more efficient way it is done. 

And, of course, if your data can have things like redundant elements or
rows, some kind of bag primitive may be useful and you can do your
scrambling and partitioning without using obvious indices.

R has been used extensively for a long time and most people use what is
already there. Some create new object types or packages, of course.

I have sometimes taken a hybrid approach and one interesting one is to use a
hybrid environment. I have, for example, done things like the above by
writing a program that has a package that allows both an R and a Python
interpreter to work together on data they sort of share and at times
interconvert. In an example where you have lots of statistical routines you
trust in R but want some of the preparation and arrangement or further
analysis, to be done with functionality you have in Python, you can sort of
combine the best of both worlds into a single program. Heck, the same
environment may also be creating a document in a markup language where the
above language codes are embedded and selectively output results including
graphics and result in something like a PDF or other document form.

I know the current discussion was, sort of, about dividing a set of data
into three groups. Efficiency may not be a major consideration, especially
as what is done with the groups may be the dominant user of resources. But
many newer techniques, such as Random Forest, may involve taking the same
data and repeatedly partitioning it and running an analysis and repeating
many thousands of times and then in some way combining the results. Some
break it down over multiple stages till they have just a few items. Some
will allow strange things like making small groups that could in theory
consist of the same original item repeated several times even if in the real
world that makes no sense as it may improve the results. So the partitioning
part may well best be done well.





-----Original Message-----
From: Thomas Subia <tgs77m at yahoo.com> 
Sent: Saturday, September 4, 2021 12:26 PM
To: r-help at r-project.org
Cc: avigross at verizon.net; abouelmakarim1962 at gmail.com
Subject: . Re: Splitting a data column randomly into 3 groups

I was wondering if this is a good alternative method to split a data column
into distinct groups.
Let's say I want my first group to have 4 elements selected randomly

mydata <- LETTERS[1:11]
 random_grp <- sample(mydata,4,replace=FALSE)

Now random_grp is:
> random_grp
[1] "H" "E" "A" "D"
# How's that for a random selection!

Now my choices for another group of random data now becomes:
 data_wo_random <- setdiff(mydata,random_grp)

> data_wo_random
[1] "B" "C" "F" "G" "I" "J" "K"

Now from this reduced dataset, I can generate another random selection with
any size I choose.

One problem with this is that this is cumbersome when ones original dataset
is large or when one wants to subgroup the original dataset into many
different subgroup sizes.

Nevertheless, it's an intuitive method which is relatively easy to
understand

Hope this helps!

Thomas Subia
Statistician


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Sat Sep  4 23:12:43 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Sat, 4 Sep 2021 17:12:43 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
Message-ID: <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>

Dear Thomas:


Thank you very much for your input in this matter.


The core part of this R code(s) (please see below) was written by *Richard
O'Keefe*. I had three examples with different sample sizes.



*First sample of size n1 = 204* divided randomly into three groups of sizes
68. *No problems with this one*.



*The second sample of size n2 = 112* divided randomly into three groups of
sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes
(37, 37, and 37). *How to fix the code to make sure that the output will be
three groups of sizes 37, 37, and 38*.



*The third sample of size n3 = 284* divided randomly into three groups of
sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes
(94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
output will be three groups of sizes 94, 95, and 95*.


With many thanks

abou


###########  ------------------------   #############


N1 <- 485
population1.IDs <- seq(1, N1, by = 1)
#### population1.IDs

n1<-204                                        ##### in this case the size
of each group of the three groups = 68
sample1.IDs <- sample(population1.IDs,n1)
#### sample1.IDs

####  n1 <- length(sample1.IDs)

  m1 <- n1 %/% 3
  s1 <- sample(1:n1, n1)
  group1.IDs <- sample1.IDs[s1[1:m1]]
  group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
  group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------


N2 <- 266
population2.IDs <- seq(1, N2, by = 1)
#### population2.IDs

n2<-112                           ##### in this case the sizes of the three
groups are(37, 37, and 38)
                                          ##### BUT this codes generate
three groups of equal sizes (37, 37, and 37)
sample2.IDs <- sample(population2.IDs,n2)
#### sample2.IDs

####  n2 <- length(sample2.IDs)

  m2 <- n2 %/% 3
  s2 <- sample(1:n2, n2)
  group1.IDs <- sample2.IDs[s2[1:m2]]
  group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
  group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------



N3 <- 674
population3.IDs <- seq(1, N3, by = 1)
#### population3.IDs

n3<-284                           ##### in this case the sizes of the three
groups are(94, 95, and 95)
                                          ##### BUT this codes generate
three groups of equal sizes (94, 94, and 94)
sample2.IDs <- sample(population2.IDs,n2)
sample3.IDs <- sample(population3.IDs,n3)
#### sample3.IDs

####  n3 <- length(sample2.IDs)

  m3 <- n3 %/% 3
  s3 <- sample(1:n3, n3)
  group1.IDs <- sample3.IDs[s3[1:m3]]
  group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
  group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:

> Abou,
>
>
>
> I?ve been following your question on how to split a data column randomly
> into 3 groups using R.
>
>
>
> My method may not be amenable for a large set of data but it surely worth
> considering since it makes sense intuitively.
>
>
>
> mydata <- LETTERS[1:11]
>
> > mydata
>
> [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
>
>
>
> # Let?s choose a random sample of size 4 from mydata
>
> > random_grp1
>
> [1] "J" "H" "D" "A"
>
>
>
> Now my next random selection of data is defined by
>
> data_wo_random <- setdiff(mydata,random_grp1)
>
> # this makes sense because I need to choose random data from a set which
> is defined by the difference of the sets mydata and random_grp1
>
>
>
> > data_wo_random
>
> [1] "B" "C" "E" "F" "G" "I" "K"
>
>
>
> This is great! So now I can randomly select data of any size from this set.
>
> Repeating this process can easily generate subgroups of your original
> dataset of any size you want.
>
>
>
> Surely this method could be improved so that this could be done
> automatically.
>
> Nevertheless, this is an intuitive method which I believe is easier to
> understand than some of the other methods posted.
>
>
>
> Hope this helps!
>
>
>
> Thomas Subia
>
> Statistician
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Sep  5 00:02:08 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 4 Sep 2021 23:02:08 +0100
Subject: [R] combining geom_boxplot and geom_point with jitter
In-Reply-To: <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
References: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
 <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
Message-ID: <6af06d92-0c68-873f-d08b-a24d0d415f3b@sapo.pt>

Hello,

And another way, with geom_jitter


p + geom_jitter(
   mapping = aes(shape = NMP_cat, group = Software),
   position = position_dodge2(width = 1)
)


Hope this helps,

Rui Barradas

?s 17:22 de 04/09/21, Rui Barradas escreveu:
> Hello,
> 
> The problem is that you have two grouping aesthetics, color and shape.
> In geom_point make the group explicit:
> 
> 
> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
> p <- p + geom_boxplot(outlier.shape = NA)
> 
> p + geom_point(
>  ? mapping = aes(shape = NMP_cat, group = Software),
>  ? position = position_jitterdodge()
> )
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 09:54 de 02/09/21, Ivan Calandra escreveu:
>> Dear useRs,
>>
>> I'm having a problem to combine geom_boxplot and geom_point with 
>> jitter. It is difficult to explain but the code and result should make 
>> it clear (the example dataset is long so I copy it at the end of the 
>> email):
>>
>> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
>> p <- p + geom_boxplot(outlier.shape = NA)
>> p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
>> position_jitterdodge())
>> print(p)
>>
>> As you can see in the resulting plot, the points with different shapes 
>> are dodged across the boxplot categories (colors). I'd like the three 
>> shapes per color to be restricted in one boxplot color, with jitter of 
>> course to better visualize the points.
>>
>> Does that make sense?
>>
>> I have played with the arguments of position_jitterdodge(), but it 
>> seems to me that the problem is that the shape aesthetic is not in the 
>> geom_boxplot() call (but I don't want it there, see below).
>>
>> For background information, the column used for shape gives some sort 
>> of "quality" to the points; that's why I want to show the points 
>> differently, so that it can easily be seen whether "good" points plot 
>> in the same area as the "bad" points.
>> Because I'm doing facet plots with other variables, I do not want to 
>> separate these categories in the boxplots - the resulting plots would 
>> be overcrowded.
>>
>> Thank you for the help.
>> Ivan
>>
>> ---
>>
>> my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
>> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo",
>> "Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
>> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>> 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 
>> 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 2L, 2L), .Label = c("0-5%", "5-10%", "10-20%", "20-100%"), class = 
>> c("ordered", "factor")), name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = 
>> c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), class = 
>> "factor"), value = c(16.00716636, 12.925787, 14.05932485, 11.999816, 
>> 15.12321532, 12.711474, 12.79565826, 10.900949, 15.90481161, 
>> 12.836045, 16.22778102, 13.565995, 14.71354945, 12.384152, 
>> 16.61354777, 13.714165, 15.91399496, 12.983796, 19.44739619, 
>> 15.173215, 16.13761798, 12.932798, 14.7332952, 12.10277, 10.78710961, 
>> 8.762726, 10.16027362, 8.040399, 14.53444662, 11.527896, 17.38120685, 
>> 13.78922, 11.26840546, 9.426558, 24.01797992, 18.398553, 13.7435699, 
>> 11.44385, 14.391873, 10.757141, 22.39390393, 18.176262, 11.60322022, 
>> 9.969118, 11.6099975, 10.059618, 11.86282935, 10.280864, 16.22473644, 
>> 13.562839, 12.46350165, 10.629406, 23.9347534, 19.062174, 19.58121507, 
>> 15.910959, 13.99145447, 11.352648, 14.38942328, 11.821431, 23.4733371, 
>> 18.549503, 13.08142223, 10.735494, 17.09293046, 13.012834, 
>> 28.80020878, 22.447105, 25.74460885, 19.76834, 14.29106582, 12.233774, 
>> 12.03005024, 10.364224, 12.58953574, 10.30257, 18.07111578, 14.416143, 
>> 20.85562751, 16.524047, 21.06132234, 15.744758, 15.24052683, 
>> 11.891487, 11.62446752, 9.14325, 11.75704705, 10.358542, 13.65568703, 
>> 11.766129, 16.98137759, 12.594787, 11.6560954, 10.32073, 15.46708251, 
>> 13.199232, 13.20110131, 11.060226, 16.13986173, 13.564802, 
>> 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 11.994841, 
>> 12.07940958, 9.470493, 13.93630412, 11.489685, 21.84464295, 17.806018, 
>> 17.4383111, 14.478338, 20.55074297, 16.254467, 30.15238714, 24.193768, 
>> 32.8541897, 25.769585, 32.06966759, 24.507185, 20.53975772, 15.951186, 
>> 11.54494952, 9.676342, 13.56490524, 11.456356, 13.58242208, 10.919419, 
>> 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 18.749955, 
>> 26.38707155, 20.877856, 26.18252748, 20.758242)), row.names = c(NA, 
>> -140L), class = c("tbl_df", "tbl", "data.frame"))
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep  5 00:34:41 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 4 Sep 2021 15:34:41 -0700
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
Message-ID: <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>

I have a more general problem for you.

Given n items and 2 <=g <<n , how do you divide the n items into g
groups that are as "equal as possible."

First, operationally define "as equal as possible."
Second, define the algorithm to carry out the definition. Hint: Note
that sum{m[i]} for i <=g must sum to n, where m[i] is the number of
items in the ith group.
Third, write R code for the algorithm. Exercise for the reader.

I may be wrong, but I think numerical analysts might also have a
little fun here.

Randomization, of course, is trivial.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Sep 4, 2021 at 2:13 PM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> Dear Thomas:
>
>
> Thank you very much for your input in this matter.
>
>
> The core part of this R code(s) (please see below) was written by *Richard
> O'Keefe*. I had three examples with different sample sizes.
>
>
>
> *First sample of size n1 = 204* divided randomly into three groups of sizes
> 68. *No problems with this one*.
>
>
>
> *The second sample of size n2 = 112* divided randomly into three groups of
> sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes
> (37, 37, and 37). *How to fix the code to make sure that the output will be
> three groups of sizes 37, 37, and 38*.
>
>
>
> *The third sample of size n3 = 284* divided randomly into three groups of
> sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes
> (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
> output will be three groups of sizes 94, 95, and 95*.
>
>
> With many thanks
>
> abou
>
>
> ###########  ------------------------   #############
>
>
> N1 <- 485
> population1.IDs <- seq(1, N1, by = 1)
> #### population1.IDs
>
> n1<-204                                        ##### in this case the size
> of each group of the three groups = 68
> sample1.IDs <- sample(population1.IDs,n1)
> #### sample1.IDs
>
> ####  n1 <- length(sample1.IDs)
>
>   m1 <- n1 %/% 3
>   s1 <- sample(1:n1, n1)
>   group1.IDs <- sample1.IDs[s1[1:m1]]
>   group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
>   group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]
>
> groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
>
> groups.IDs
>
>
> ####### --------------------------
>
>
> N2 <- 266
> population2.IDs <- seq(1, N2, by = 1)
> #### population2.IDs
>
> n2<-112                           ##### in this case the sizes of the three
> groups are(37, 37, and 38)
>                                           ##### BUT this codes generate
> three groups of equal sizes (37, 37, and 37)
> sample2.IDs <- sample(population2.IDs,n2)
> #### sample2.IDs
>
> ####  n2 <- length(sample2.IDs)
>
>   m2 <- n2 %/% 3
>   s2 <- sample(1:n2, n2)
>   group1.IDs <- sample2.IDs[s2[1:m2]]
>   group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
>   group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]
>
> groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
>
> groups.IDs
>
>
> ####### --------------------------
>
>
>
> N3 <- 674
> population3.IDs <- seq(1, N3, by = 1)
> #### population3.IDs
>
> n3<-284                           ##### in this case the sizes of the three
> groups are(94, 95, and 95)
>                                           ##### BUT this codes generate
> three groups of equal sizes (94, 94, and 94)
> sample2.IDs <- sample(population2.IDs,n2)
> sample3.IDs <- sample(population3.IDs,n3)
> #### sample3.IDs
>
> ####  n3 <- length(sample2.IDs)
>
>   m3 <- n3 %/% 3
>   s3 <- sample(1:n3, n3)
>   group1.IDs <- sample3.IDs[s3[1:m3]]
>   group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
>   group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]
>
> groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
>
> groups.IDs
>
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>
>
> On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:
>
> > Abou,
> >
> >
> >
> > I?ve been following your question on how to split a data column randomly
> > into 3 groups using R.
> >
> >
> >
> > My method may not be amenable for a large set of data but it surely worth
> > considering since it makes sense intuitively.
> >
> >
> >
> > mydata <- LETTERS[1:11]
> >
> > > mydata
> >
> > [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
> >
> >
> >
> > # Let?s choose a random sample of size 4 from mydata
> >
> > > random_grp1
> >
> > [1] "J" "H" "D" "A"
> >
> >
> >
> > Now my next random selection of data is defined by
> >
> > data_wo_random <- setdiff(mydata,random_grp1)
> >
> > # this makes sense because I need to choose random data from a set which
> > is defined by the difference of the sets mydata and random_grp1
> >
> >
> >
> > > data_wo_random
> >
> > [1] "B" "C" "E" "F" "G" "I" "K"
> >
> >
> >
> > This is great! So now I can randomly select data of any size from this set.
> >
> > Repeating this process can easily generate subgroups of your original
> > dataset of any size you want.
> >
> >
> >
> > Surely this method could be improved so that this could be done
> > automatically.
> >
> > Nevertheless, this is an intuitive method which I believe is easier to
> > understand than some of the other methods posted.
> >
> >
> >
> > Hope this helps!
> >
> >
> >
> > Thomas Subia
> >
> > Statistician
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Sun Sep  5 01:58:53 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sat, 4 Sep 2021 19:58:53 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
Message-ID: <016501d7a1e8$d098d300$71ca7900$@verizon.net>

Abou,

I believe I addressed this issue in a private message the other day.

As a general rule, truncating can leave a remainder. If 
	M  = length(whatever)/3 

Then M is no longer an integer. It can be a number ending in .333... or .666... as well as 0.

Now R may silently truncate something like 100/3 which you see to use and make it be as if you typed 33. Same for 2*M. In your code, you used integer division and that is a truncation too!

  m1 <- n1 %/% 3
  s1 <- sample(1:n1, n1)
  group1.IDs <- sample1.IDs[s1[1:m1]]
  group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
  group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]

A proper solution accounts for any leftover items. One method is to leave all extra items till the end and have:

MAX <- length(original or whatever)
group3.IDs <- sample1.IDs[s1[(m1*2+1):MAX]]


The last group then might have one or two extra items. Another is to go for  a second sweep and take any leftover items and move one each into whatever groups you wish for some balance.

Or, as discussed, there are packages available that let you specify percentages you want and handle these edge cases too.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of AbouEl-Makarim Aboueissa
Sent: Saturday, September 4, 2021 5:13 PM
To: Thomas Subia <tgs77m at yahoo.com>
Cc: R mailing list <r-help at r-project.org>
Subject: Re: [R] Splitting a data column randomly into 3 groups

Dear Thomas:


Thank you very much for your input in this matter.


The core part of this R code(s) (please see below) was written by *Richard O'Keefe*. I had three examples with different sample sizes.



*First sample of size n1 = 204* divided randomly into three groups of sizes 68. *No problems with this one*.



*The second sample of size n2 = 112* divided randomly into three groups of sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes (37, 37, and 37). *How to fix the code to make sure that the output will be three groups of sizes 37, 37, and 38*.



*The third sample of size n3 = 284* divided randomly into three groups of sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the output will be three groups of sizes 94, 95, and 95*.


With many thanks

abou


###########  ------------------------   #############


N1 <- 485
population1.IDs <- seq(1, N1, by = 1)
#### population1.IDs

n1<-204                                        ##### in this case the size
of each group of the three groups = 68
sample1.IDs <- sample(population1.IDs,n1) #### sample1.IDs

####  n1 <- length(sample1.IDs)

  m1 <- n1 %/% 3
  s1 <- sample(1:n1, n1)
  group1.IDs <- sample1.IDs[s1[1:m1]]
  group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
  group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------


N2 <- 266
population2.IDs <- seq(1, N2, by = 1)
#### population2.IDs

n2<-112                           ##### in this case the sizes of the three
groups are(37, 37, and 38)
                                          ##### BUT this codes generate three groups of equal sizes (37, 37, and 37) sample2.IDs <- sample(population2.IDs,n2) #### sample2.IDs

####  n2 <- length(sample2.IDs)

  m2 <- n2 %/% 3
  s2 <- sample(1:n2, n2)
  group1.IDs <- sample2.IDs[s2[1:m2]]
  group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
  group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs


####### --------------------------



N3 <- 674
population3.IDs <- seq(1, N3, by = 1)
#### population3.IDs

n3<-284                           ##### in this case the sizes of the three
groups are(94, 95, and 95)
                                          ##### BUT this codes generate three groups of equal sizes (94, 94, and 94) sample2.IDs <- sample(population2.IDs,n2) sample3.IDs <- sample(population3.IDs,n3) #### sample3.IDs

####  n3 <- length(sample2.IDs)

  m3 <- n3 %/% 3
  s3 <- sample(1:n3, n3)
  group1.IDs <- sample3.IDs[s3[1:m3]]
  group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
  group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science* *Graduate Coordinator*

*Department of Mathematics and Statistics* *University of Southern Maine*



On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:

> Abou,
>
>
>
> I?ve been following your question on how to split a data column 
> randomly into 3 groups using R.
>
>
>
> My method may not be amenable for a large set of data but it surely 
> worth considering since it makes sense intuitively.
>
>
>
> mydata <- LETTERS[1:11]
>
> > mydata
>
> [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
>
>
>
> # Let?s choose a random sample of size 4 from mydata
>
> > random_grp1
>
> [1] "J" "H" "D" "A"
>
>
>
> Now my next random selection of data is defined by
>
> data_wo_random <- setdiff(mydata,random_grp1)
>
> # this makes sense because I need to choose random data from a set 
> which is defined by the difference of the sets mydata and random_grp1
>
>
>
> > data_wo_random
>
> [1] "B" "C" "E" "F" "G" "I" "K"
>
>
>
> This is great! So now I can randomly select data of any size from this set.
>
> Repeating this process can easily generate subgroups of your original 
> dataset of any size you want.
>
>
>
> Surely this method could be improved so that this could be done 
> automatically.
>
> Nevertheless, this is an intuitive method which I believe is easier to 
> understand than some of the other methods posted.
>
>
>
> Hope this helps!
>
>
>
> Thomas Subia
>
> Statistician
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From brunoju||@tt| @end|ng |rom gm@||@com  Sat Sep  4 16:13:57 2021
From: brunoju||@tt| @end|ng |rom gm@||@com (=?UTF-8?Q?Bruno_C=C3=A9sar_Juliatti?=)
Date: Sat, 4 Sep 2021 11:13:57 -0300
Subject: [R] Help with bibliometrix and biblioshiny
Message-ID: <CADUw8q5jbvGu5y6mVfoH+ihZsGWYun3Fn7krKT0Kdxu6Hkd5Xw@mail.gmail.com>

Hi, everyone. I'm new in this R language universe. I want to use
bibliometric as a research in m Master's program. I run the code in R
studio and works just fine. But, in the web-interface (biblioshiny), I load
the table in .csv and keeps showing this message: Error: object 'M' not
found
PS: I already exported the searches in Web of Science and Scopus.

This is the code and below the console's messages.

*install.packages("bibliometrix")* # Baixar o pacote. S? precisa fazer isso
uma #vez! E demora muito, por vezes muitos minutos!

#library(bibliometrix)  # carregar o pacote na mem?ria para utiliz?-lo
agora.

# D?vidas de uso do Bibliometrix, execute  o comando que segue:
help(bibliometrix)

#Artigo: CAPACIDADE ESTATAL
#AUTORES: PATR? CIA ROSVADOSKI-DA-SILVA, WELLES ABREU
#OBJETIVO -> Caracterizar e clusterizar os trabalhos de capacidade estatal


#######COLETA DOS DADOS ##############

#WEB OF SCIENCE
#Pesquisa B??sica
# vari??veis da pesquisa: BOLEADORES -> AND, OR , NOT
############ ATEN????O: ASPAS (") E *
# configura????es
#Filtros ##########ATEN????O: ANOTAR TODOS OS PASSOS
# EXPORTAR -> Outros formatos de arquivo
# Registro completo de refer??ncias citadas (m??ximo de 500)
# bibtex. OBS-> Salvar arquivo: ser?? gerado um arquivo #???savedrecs.bib??
na ??rea de downloads

#SCOPUS
#PESQUISA
#CAMPOS
#  FILTROS -> Data range, document type, Access type
#FILTROS
#EXPORT -> Bibtex (citation information, Bibliographical information,
Abstract & keywords, Funding details, Other information -> Export)
#limite de 2000 artigos, Salvar arquivo: ser?? gerado um arquivo
#???scopus.bib?? na ??rea de downloads








############### ETAPA 1 - CARREGAMENTO E CONVERS?O DOS DADOS ###############

# WEB OF SCIENCE (ISI): Converter os dados para o padr?o do bibliometrix

*W <- convert2df("C:/Users/bruno/Desktop/Bibliometria/wos_scielo.bib",
dbsource = "isi", format = "bibtex")*
#W1 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (12).bib", dbsource = "isi", format
= "bibtex")
#W2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (13).bib", dbsource = "isi", format
= "bibtex")
#W3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (14).bib", dbsource = "isi", format
= "bibtex")
#W4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/WOS/savedrecs (15).bib", dbsource = "isi", format
= "bibtex")




#W <- mergeDbSources(W1, W2, W3, W4)




# SCOPUS: Converter os dados   para o padr?o do bibliometrix

*S <-convert2df("C:/Users/bruno/Desktop/Bibliometria/scopus_elsevier.bib",
dbsource = "scopus", format = "bibtex")*
#S2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (2).bib", dbsource = "scopus",
format = "bibtex")
#S3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (4).bib", dbsource = "scopus",
format = "bibtex")
#S4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (5).bib", dbsource = "scopus",
format = "bibtex")
#S5 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (6).bib", dbsource = "scopus",
format = "bibtex")
#S6 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (7).bib", dbsource = "scopus",
format = "bibtex")
#S7 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (8).bib", dbsource = "scopus",
format = "bibtex")
#S8 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (9).bib", dbsource = "scopus",
format = "bibtex")
#S9 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
andamento/Cooperativismo/Scopus/scopus (10).bib", dbsource = "scopus",
format = "bibtex")
#S10 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
#andamento/Cooperativismo/Scopus/scopus (11).bib", dbsource = "scopus",
#format = "bibtex")


#S <- mergeDbSources(S1, S2, S3, S4, S5, S6, S7, S8, S9, S10)

# PUBMED: Se desejar caregar dado, execute o script do PubMed, gerando o
#arquivo de dados "C"

# COCHRANE: Se desejar carregar dados  execute a linha que segue, gerando
#o arquivo de dados "D"
# D <- convert2df("c:/bib/citation-export.bib", dbsource = "isi", format =
"bibtex")

#### Juntar bases WEB OF SCIENCE (ISI), SCOPUS, PUBMED e #COCHRANE
*M <- mergeDbSources(W, S, remove.duplicated = TRUE)*

# se precisar juntar dados do Pubmed e Cochrane, execute linha que segue
# M <- mergeDbSources(A, B, C, D, remove.duplicated = TRUE)

#### Cria um arquivo.csv para importar para o Excel
*P<- M[,c("AU","TI","SO","AB","DE", "ID", "DI","LA","DT","TC","PY")] * #
#Cria lista na ordem desejada
*write.table(P, "C:/Users/bruno/Desktop/Bibliometria/opa.csv", sep=";",
row.names=FALSE)* # para gerar com separador ";", sem necessidade de
#ajustar o CSV, quanto ? primeira coluna

#### BiblioAnalysis - Processamento dos dados
*resultados <- biblioAnalysis(M)*




############### ETAPA 2 - AN?LISE e VISUALIZA??O DOS DADOS ###############

#### 2.1 - Resumo dos resultados na console do RStudio


*Resumo <- summary(object = resultados, k = 10)Resumoplot(resultados, k=10)*
  # Gr?ficos com dados bibliom?tricos b?sicos
*plot*


# Para visualizar os resultados via web-interface (browser)
*biblioshiny()*

#### Para mais informa??es, tutoriais e v?deos, acessar
www.bibliometrix.org/

This is the console's message about the error:













*Warning: Error in eventReactiveValueFunc: object 'M' not found  149:
eventReactiveValueFunc
[C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#321]
105: DATAloading  104: exprFunc
[C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#330]
103: widgetFunc  102: htmlwidgets::shinyRenderWidget  101: func   88:
renderFunc   87: renderFunc   83: renderFunc   82: output$contents    2:
runApp*
*    1: biblioshiny *

	[[alternative HTML version deleted]]


From |euk@m|r@nk||n18 @end|ng |rom y@hoo@com  Sun Sep  5 12:43:21 2021
From: |euk@m|r@nk||n18 @end|ng |rom y@hoo@com (Franklin Feukam)
Date: Sun, 5 Sep 2021 12:43:21 +0200
Subject: [R] Multivariate tobit regression
Message-ID: <mailman.364135.5.1630856431.1337.r-help@r-project.org>

Please can I have the package of Multivariate Tobit regression??

I am a student at Ecole Nationale de la Statistique et de l?Administration Economique of Paris.

Thanks?!

Envoy? ? partir de Courrier pour Windows


	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Sun Sep  5 17:26:05 2021
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Sun, 5 Sep 2021 11:26:05 -0400
Subject: [R] Multivariate tobit regression
In-Reply-To: <20210905152032.397D412E8@hypatia.math.ethz.ch>
References: <20210905152032.397D412E8@hypatia.math.ethz.ch>
Message-ID: <a919c6e5-43a3-1e9d-2820-cb1143d553c5@loesl.us>

Have you tried

RSiteSearch("tobit")

??

---JRG



On 9/5/21 6:43 AM, Franklin Feukam via R-help wrote:
> Multivariate Tobit regression


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  5 17:50:29 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Sep 2021 08:50:29 -0700
Subject: [R] Multivariate tobit regression
In-Reply-To: <20210905152032.397D412E8@hypatia.math.ethz.ch>
References: <20210905152032.397D412E8@hypatia.math.ethz.ch>
Message-ID: <58CC285F-3F6D-4182-AAA9-64B3E8D629A8@dcn.davis.ca.us>

Quite probably, but not via this mailing list. Do read the Posting Guide mentioned in the footer. http://cran.nexr.com/web/views/Econometrics.html may suggest options.

On September 5, 2021 3:43:21 AM PDT, Franklin Feukam via R-help <r-help at r-project.org> wrote:
>Please can I have the package of Multivariate Tobit regression??
>
>I am a student at Ecole Nationale de la Statistique et de l?Administration Economique of Paris.
>
>Thanks?!
>
>Envoy? ? partir de Courrier pour Windows
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep  5 18:02:05 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 5 Sep 2021 09:02:05 -0700
Subject: [R] Help with bibliometrix and biblioshiny
In-Reply-To: <CADUw8q5jbvGu5y6mVfoH+ihZsGWYun3Fn7krKT0Kdxu6Hkd5Xw@mail.gmail.com>
References: <CADUw8q5jbvGu5y6mVfoH+ihZsGWYun3Fn7krKT0Kdxu6Hkd5Xw@mail.gmail.com>
Message-ID: <CAGxFJbR3nD1tNj5yYjS5+OcR=U24Dsnnp9T1Ojn9LMpVxor7mA@mail.gmail.com>

Please read and follow the posting guide, which says:

"For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
If the question relates to a contributed package , e.g., one
downloaded from CRAN, try contacting the package maintainer first. You
can also use find("functionname") and
packageDescription("packagename") to find this information. Only send
such questions to R-help or R-devel if you get no reply or need
further assistance. "

So for a specialized package like bibliometrix, though you might get
lucky here, you should probably contact the maintainers. I also noted
that the package has its own web page with a FAQ and other resources.
Have you consulted them yet?  There might also be a user community
that could help, but I did not see it in my brief look around.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Sep 5, 2021 at 8:20 AM Bruno C?sar Juliatti
<brunojuliatti at gmail.com> wrote:
>
> Hi, everyone. I'm new in this R language universe. I want to use
> bibliometric as a research in m Master's program. I run the code in R
> studio and works just fine. But, in the web-interface (biblioshiny), I load
> the table in .csv and keeps showing this message: Error: object 'M' not
> found
> PS: I already exported the searches in Web of Science and Scopus.
>
> This is the code and below the console's messages.
>
> *install.packages("bibliometrix")* # Baixar o pacote. S? precisa fazer isso
> uma #vez! E demora muito, por vezes muitos minutos!
>
> #library(bibliometrix)  # carregar o pacote na mem?ria para utiliz?-lo
> agora.
>
> # D?vidas de uso do Bibliometrix, execute  o comando que segue:
> help(bibliometrix)
>
> #Artigo: CAPACIDADE ESTATAL
> #AUTORES: PATR? CIA ROSVADOSKI-DA-SILVA, WELLES ABREU
> #OBJETIVO -> Caracterizar e clusterizar os trabalhos de capacidade estatal
>
>
> #######COLETA DOS DADOS ##############
>
> #WEB OF SCIENCE
> #Pesquisa B??sica
> # vari??veis da pesquisa: BOLEADORES -> AND, OR , NOT
> ############ ATEN????O: ASPAS (") E *
> # configura????es
> #Filtros ##########ATEN????O: ANOTAR TODOS OS PASSOS
> # EXPORTAR -> Outros formatos de arquivo
> # Registro completo de refer??ncias citadas (m??ximo de 500)
> # bibtex. OBS-> Salvar arquivo: ser?? gerado um arquivo #???savedrecs.bib??
> na ??rea de downloads
>
> #SCOPUS
> #PESQUISA
> #CAMPOS
> #  FILTROS -> Data range, document type, Access type
> #FILTROS
> #EXPORT -> Bibtex (citation information, Bibliographical information,
> Abstract & keywords, Funding details, Other information -> Export)
> #limite de 2000 artigos, Salvar arquivo: ser?? gerado um arquivo
> #???scopus.bib?? na ??rea de downloads
>
>
>
>
>
>
>
>
> ############### ETAPA 1 - CARREGAMENTO E CONVERS?O DOS DADOS ###############
>
> # WEB OF SCIENCE (ISI): Converter os dados para o padr?o do bibliometrix
>
> *W <- convert2df("C:/Users/bruno/Desktop/Bibliometria/wos_scielo.bib",
> dbsource = "isi", format = "bibtex")*
> #W1 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (12).bib", dbsource = "isi", format
> = "bibtex")
> #W2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (13).bib", dbsource = "isi", format
> = "bibtex")
> #W3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (14).bib", dbsource = "isi", format
> = "bibtex")
> #W4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/WOS/savedrecs (15).bib", dbsource = "isi", format
> = "bibtex")
>
>
>
>
> #W <- mergeDbSources(W1, W2, W3, W4)
>
>
>
>
> # SCOPUS: Converter os dados   para o padr?o do bibliometrix
>
> *S <-convert2df("C:/Users/bruno/Desktop/Bibliometria/scopus_elsevier.bib",
> dbsource = "scopus", format = "bibtex")*
> #S2 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (2).bib", dbsource = "scopus",
> format = "bibtex")
> #S3 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (4).bib", dbsource = "scopus",
> format = "bibtex")
> #S4 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (5).bib", dbsource = "scopus",
> format = "bibtex")
> #S5 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (6).bib", dbsource = "scopus",
> format = "bibtex")
> #S6 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (7).bib", dbsource = "scopus",
> format = "bibtex")
> #S7 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (8).bib", dbsource = "scopus",
> format = "bibtex")
> #S8 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (9).bib", dbsource = "scopus",
> format = "bibtex")
> #S9 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> andamento/Cooperativismo/Scopus/scopus (10).bib", dbsource = "scopus",
> format = "bibtex")
> #S10 <- convert2df("/Users/user/OneDrive/Curriculum/Artigos em
> #andamento/Cooperativismo/Scopus/scopus (11).bib", dbsource = "scopus",
> #format = "bibtex")
>
>
> #S <- mergeDbSources(S1, S2, S3, S4, S5, S6, S7, S8, S9, S10)
>
> # PUBMED: Se desejar caregar dado, execute o script do PubMed, gerando o
> #arquivo de dados "C"
>
> # COCHRANE: Se desejar carregar dados  execute a linha que segue, gerando
> #o arquivo de dados "D"
> # D <- convert2df("c:/bib/citation-export.bib", dbsource = "isi", format =
> "bibtex")
>
> #### Juntar bases WEB OF SCIENCE (ISI), SCOPUS, PUBMED e #COCHRANE
> *M <- mergeDbSources(W, S, remove.duplicated = TRUE)*
>
> # se precisar juntar dados do Pubmed e Cochrane, execute linha que segue
> # M <- mergeDbSources(A, B, C, D, remove.duplicated = TRUE)
>
> #### Cria um arquivo.csv para importar para o Excel
> *P<- M[,c("AU","TI","SO","AB","DE", "ID", "DI","LA","DT","TC","PY")] * #
> #Cria lista na ordem desejada
> *write.table(P, "C:/Users/bruno/Desktop/Bibliometria/opa.csv", sep=";",
> row.names=FALSE)* # para gerar com separador ";", sem necessidade de
> #ajustar o CSV, quanto ? primeira coluna
>
> #### BiblioAnalysis - Processamento dos dados
> *resultados <- biblioAnalysis(M)*
>
>
>
>
> ############### ETAPA 2 - AN?LISE e VISUALIZA??O DOS DADOS ###############
>
> #### 2.1 - Resumo dos resultados na console do RStudio
>
>
> *Resumo <- summary(object = resultados, k = 10)Resumoplot(resultados, k=10)*
>   # Gr?ficos com dados bibliom?tricos b?sicos
> *plot*
>
>
> # Para visualizar os resultados via web-interface (browser)
> *biblioshiny()*
>
> #### Para mais informa??es, tutoriais e v?deos, acessar
> www.bibliometrix.org/
>
> This is the console's message about the error:
>
>
>
>
>
>
>
>
>
>
>
>
>
> *Warning: Error in eventReactiveValueFunc: object 'M' not found  149:
> eventReactiveValueFunc
> [C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#321]
> 105: DATAloading  104: exprFunc
> [C:\Users\bruno\OneDrive\Documentos\R\win-library\4.1\bibliometrix\biblioshiny/server.R#330]
> 103: widgetFunc  102: htmlwidgets::shinyRenderWidget  101: func   88:
> renderFunc   87: renderFunc   83: renderFunc   82: output$contents    2:
> runApp*
> *    1: biblioshiny *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun Sep  5 19:18:48 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 5 Sep 2021 10:18:48 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
 <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
Message-ID: <CAHqSRuTmg0+RXa5gxFCETx2bfYL5e7n-bpwnX2R92JDxqzV0Dw@mail.gmail.com>

What is the best way to read (from a text file) timestamps from the fall
time change, where there are two 1:15am's?  E.g., here is an extract from a
US Geological Survey web site giving data on the river through our county
on 2020-11-01, when we changed from PDT to PST,
https://nwis.waterdata.usgs.gov/wa/nwis/uv/?cb_00010=on&cb_00060=on&cb_00065=on&format=rdb&site_no=12200500&period=&begin_date=2020-11-01&end_date=2020-11-05
.

The timestamps include the date and time as well as PDT or PST.

river <-
c("datetime,tz,discharge,height,temp",
  "2020-11-01 00:00,PDT,20500,16.44,9.3",
  "2020-11-01 00:15,PDT,20500,16.44,9.3",
  "2020-11-01 00:30,PDT,20500,16.43,9.3",
  "2020-11-01 00:45,PDT,20400,16.40,9.3",
  "2020-11-01 01:00,PDT,20400,16.40,9.3",
  "2020-11-01 01:00,PST,20200,16.34,9.2",
  "2020-11-01 01:15,PDT,20400,16.39,9.3",
  "2020-11-01 01:15,PST,20200,16.34,9.2",
  "2020-11-01 01:30,PDT,20300,16.37,9.2",
  "2020-11-01 01:30,PST,20100,16.31,9.2",
  "2020-11-01 01:45,PDT,20300,16.35,9.2",
  "2020-11-01 01:45,PST,20100,16.29,9.2",
  "2020-11-01 02:00,PST,20100,16.29,9.2",
  "2020-11-01 02:15,PST,20000,16.27,9.1",
  "2020-11-01 02:30,PST,20000,16.26,9.1"
  )
d <- read.table(text=river, sep=",",header=TRUE)

The entries are obviously not in time order.

Is there a simple way to read the timedate and tz columns together?  One
way is to use d$tz to construct an offset that can be read with
strptime's "%z".

> d$POSIXct <-
as.POSIXct(paste(d$datetime,ifelse(d$tz=="PDT","-0700","-0800")),
format="%Y-%m-%d %H:%M %z")
> d
           datetime  tz discharge height temp             POSIXct
1  2020-11-01 00:00 PDT     20500  16.44  9.3 2020-11-01 00:00:00
2  2020-11-01 00:15 PDT     20500  16.44  9.3 2020-11-01 00:15:00
3  2020-11-01 00:30 PDT     20500  16.43  9.3 2020-11-01 00:30:00
4  2020-11-01 00:45 PDT     20400  16.40  9.3 2020-11-01 00:45:00
5  2020-11-01 01:00 PDT     20400  16.40  9.3 2020-11-01 01:00:00
6  2020-11-01 01:00 PST     20200  16.34  9.2 2020-11-01 01:00:00
7  2020-11-01 01:15 PDT     20400  16.39  9.3 2020-11-01 01:15:00
8  2020-11-01 01:15 PST     20200  16.34  9.2 2020-11-01 01:15:00
9  2020-11-01 01:30 PDT     20300  16.37  9.2 2020-11-01 01:30:00
10 2020-11-01 01:30 PST     20100  16.31  9.2 2020-11-01 01:30:00
11 2020-11-01 01:45 PDT     20300  16.35  9.2 2020-11-01 01:45:00
12 2020-11-01 01:45 PST     20100  16.29  9.2 2020-11-01 01:45:00
13 2020-11-01 02:00 PST     20100  16.29  9.2 2020-11-01 02:00:00
14 2020-11-01 02:15 PST     20000  16.27  9.1 2020-11-01 02:15:00
15 2020-11-01 02:30 PST     20000  16.26  9.1 2020-11-01 02:30:00
> with(d[order(d$POSIXct),], plot(temp)) # monotonic temperature

-Bill


On Thu, Sep 2, 2021 at 12:41 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Regardless of whether you use the lower-level split function, or the
> higher-level aggregate function, or the tidyverse group_by function, the
> key is learning how to create the column that is the same for all records
> corresponding to the time interval of interest.
>
> If you convert the sampdate to POSIXct, the tz IS important, because most
> of us use local timezones that respect daylight savings time, and a naive
> conversion of standard time will run into trouble if R is assuming daylight
> savings time applies. The lubridate package gets around this by always
> assuming UTC and giving you a function to "fix" the timezone after the
> conversion. I prefer to always be specific about timezones, at least by
> using so something like
>
>     Sys.setenv( TZ = "Etc/GMT+8" )
>
> which does not respect daylight savings.
>
> Regarding using character data for identifying the month, in order to have
> clean plots of the data I prefer to use the trunc function but it returns a
> POSIXlt so I convert it to POSIXct:
>
>     discharge$sampmonthbegin <- as.POSIXct( trunc( discharge$sampdate,
> units = "months" ) )
>
> Then any of various ways can be used to aggregate the records by that
> column.
>
> On September 2, 2021 12:10:15 PM PDT, Andrew Simmons <akwsimmo at gmail.com>
> wrote:
> >You could use 'split' to create a list of data frames, and then apply a
> >function to each to get the means and sds.
> >
> >
> >cols <- "cfs"  # add more as necessary
> >S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
> >means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
> >sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
> >TRUE)))
> >
> >On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
> >wrote:
> >
> >> On Thu, 2 Sep 2021, Rich Shepard wrote:
> >>
> >> > If I correctly understand the output of as.POSIXlt each date and time
> >> > element is separate, so input such as 2016-03-03 12:00 would now be
> 2016
> >> 03
> >> > 03 12 00 (I've not read how the elements are separated). (The TZ is
> not
> >> > important because all data are either PST or PDT.)
> >>
> >> Using this script:
> >> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep
> =
> >> ',', stringsAsFactors = FALSE)
> >> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
> >>                                   format = '%Y-%m-%d %H:%M',
> >>                                   optional = 'logical')
> >> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
> >>
> >> I get this result:
> >> > head(discharge)
> >>               sampdate    cfs
> >> 1 2016-03-03 12:00:00 149000
> >> 2 2016-03-03 12:10:00 150000
> >> 3 2016-03-03 12:20:00 151000
> >> 4 2016-03-03 12:30:00 156000
> >> 5 2016-03-03 12:40:00 154000
> >> 6 2016-03-03 12:50:00 150000
> >>
> >> I'm completely open to suggestions on using this output to calculate
> >> monthly
> >> means and sds.
> >>
> >> If dplyr:summarize() will do so please show me how to modify this
> command:
> >> disc_monthly <- ( discharge
> >>          %>% group_by(sampdate)
> >>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
> >> because it produces daily means, not monthly means.
> >>
> >> TIA,
> >>
> >> Rich
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Sep  5 20:04:43 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 05 Sep 2021 11:04:43 -0700
Subject: [R] Calculate daily means from 5-minute interval data
In-Reply-To: <CAHqSRuTmg0+RXa5gxFCETx2bfYL5e7n-bpwnX2R92JDxqzV0Dw@mail.gmail.com>
References: <alpine.LNX.2.20.2108290801570.32406@salmo.appl-ecosys.com>
 <CABcYAdLKiLrE22gnM1YSRGURtg3P=MdGyUHJwmhAcqHViFKDEw@mail.gmail.com>
 <alpine.LNX.2.20.2109021107460.18288@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109021135461.18288@salmo.appl-ecosys.com>
 <CAPcHnpRJ9LUOTYx+Yf-w1j3wu9=XcGEjUj2-1DB82vu9oy9PoA@mail.gmail.com>
 <219F64F7-55D9-4D5B-9666-2C2DF6EC7AF4@dcn.davis.ca.us>
 <CAHqSRuTmg0+RXa5gxFCETx2bfYL5e7n-bpwnX2R92JDxqzV0Dw@mail.gmail.com>
Message-ID: <8F130A55-5394-4EFB-9BBB-5E9511624356@dcn.davis.ca.us>

This problem nearly always boils down to using meta knowledge about the file. Having informal TZ info in the file is very helpful, but PST is not necessarily a uniquely-defined time zone specification so you have to draw on information outside of the file to know that these codes correspond to -0800 etc. (e.g. CST could be China Standard Time or US Central Standard Time.) Thus, it is tough to make this into a broadly-useful function.

You can also construct the timezone column from knowledge about the location of interest and the monotonicity of the time data. https://jdnewmil.github.io/eci298sp2016/QuickHowtos1.html#handling-time-data ... but the answer to "easy" seems firmly in the eyes of the beholder.

On September 5, 2021 10:18:48 AM PDT, Bill Dunlap <williamwdunlap at gmail.com> wrote:
>What is the best way to read (from a text file) timestamps from the fall
>time change, where there are two 1:15am's?  E.g., here is an extract from a
>US Geological Survey web site giving data on the river through our county
>on 2020-11-01, when we changed from PDT to PST,
>https://nwis.waterdata.usgs.gov/wa/nwis/uv/?cb_00010=on&cb_00060=on&cb_00065=on&format=rdb&site_no=12200500&period=&begin_date=2020-11-01&end_date=2020-11-05
>.
>
>The timestamps include the date and time as well as PDT or PST.
>
>river <-
>c("datetime,tz,discharge,height,temp",
>  "2020-11-01 00:00,PDT,20500,16.44,9.3",
>  "2020-11-01 00:15,PDT,20500,16.44,9.3",
>  "2020-11-01 00:30,PDT,20500,16.43,9.3",
>  "2020-11-01 00:45,PDT,20400,16.40,9.3",
>  "2020-11-01 01:00,PDT,20400,16.40,9.3",
>  "2020-11-01 01:00,PST,20200,16.34,9.2",
>  "2020-11-01 01:15,PDT,20400,16.39,9.3",
>  "2020-11-01 01:15,PST,20200,16.34,9.2",
>  "2020-11-01 01:30,PDT,20300,16.37,9.2",
>  "2020-11-01 01:30,PST,20100,16.31,9.2",
>  "2020-11-01 01:45,PDT,20300,16.35,9.2",
>  "2020-11-01 01:45,PST,20100,16.29,9.2",
>  "2020-11-01 02:00,PST,20100,16.29,9.2",
>  "2020-11-01 02:15,PST,20000,16.27,9.1",
>  "2020-11-01 02:30,PST,20000,16.26,9.1"
>  )
>d <- read.table(text=river, sep=",",header=TRUE)
>
>The entries are obviously not in time order.
>
>Is there a simple way to read the timedate and tz columns together?  One
>way is to use d$tz to construct an offset that can be read with
>strptime's "%z".
>
>> d$POSIXct <-
>as.POSIXct(paste(d$datetime,ifelse(d$tz=="PDT","-0700","-0800")),
>format="%Y-%m-%d %H:%M %z")
>> d
>           datetime  tz discharge height temp             POSIXct
>1  2020-11-01 00:00 PDT     20500  16.44  9.3 2020-11-01 00:00:00
>2  2020-11-01 00:15 PDT     20500  16.44  9.3 2020-11-01 00:15:00
>3  2020-11-01 00:30 PDT     20500  16.43  9.3 2020-11-01 00:30:00
>4  2020-11-01 00:45 PDT     20400  16.40  9.3 2020-11-01 00:45:00
>5  2020-11-01 01:00 PDT     20400  16.40  9.3 2020-11-01 01:00:00
>6  2020-11-01 01:00 PST     20200  16.34  9.2 2020-11-01 01:00:00
>7  2020-11-01 01:15 PDT     20400  16.39  9.3 2020-11-01 01:15:00
>8  2020-11-01 01:15 PST     20200  16.34  9.2 2020-11-01 01:15:00
>9  2020-11-01 01:30 PDT     20300  16.37  9.2 2020-11-01 01:30:00
>10 2020-11-01 01:30 PST     20100  16.31  9.2 2020-11-01 01:30:00
>11 2020-11-01 01:45 PDT     20300  16.35  9.2 2020-11-01 01:45:00
>12 2020-11-01 01:45 PST     20100  16.29  9.2 2020-11-01 01:45:00
>13 2020-11-01 02:00 PST     20100  16.29  9.2 2020-11-01 02:00:00
>14 2020-11-01 02:15 PST     20000  16.27  9.1 2020-11-01 02:15:00
>15 2020-11-01 02:30 PST     20000  16.26  9.1 2020-11-01 02:30:00
>> with(d[order(d$POSIXct),], plot(temp)) # monotonic temperature
>
>-Bill
>
>
>On Thu, Sep 2, 2021 at 12:41 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Regardless of whether you use the lower-level split function, or the
>> higher-level aggregate function, or the tidyverse group_by function, the
>> key is learning how to create the column that is the same for all records
>> corresponding to the time interval of interest.
>>
>> If you convert the sampdate to POSIXct, the tz IS important, because most
>> of us use local timezones that respect daylight savings time, and a naive
>> conversion of standard time will run into trouble if R is assuming daylight
>> savings time applies. The lubridate package gets around this by always
>> assuming UTC and giving you a function to "fix" the timezone after the
>> conversion. I prefer to always be specific about timezones, at least by
>> using so something like
>>
>>     Sys.setenv( TZ = "Etc/GMT+8" )
>>
>> which does not respect daylight savings.
>>
>> Regarding using character data for identifying the month, in order to have
>> clean plots of the data I prefer to use the trunc function but it returns a
>> POSIXlt so I convert it to POSIXct:
>>
>>     discharge$sampmonthbegin <- as.POSIXct( trunc( discharge$sampdate,
>> units = "months" ) )
>>
>> Then any of various ways can be used to aggregate the records by that
>> column.
>>
>> On September 2, 2021 12:10:15 PM PDT, Andrew Simmons <akwsimmo at gmail.com>
>> wrote:
>> >You could use 'split' to create a list of data frames, and then apply a
>> >function to each to get the means and sds.
>> >
>> >
>> >cols <- "cfs"  # add more as necessary
>> >S <- split(discharge[cols], format(discharge$sampdate, format = "%Y-%m"))
>> >means <- do.call("rbind", lapply(S, colMeans, na.rm = TRUE))
>> >sds   <- do.call("rbind", lapply(S, function(xx) sapply(xx, sd, na.rm =
>> >TRUE)))
>> >
>> >On Thu, Sep 2, 2021 at 3:01 PM Rich Shepard <rshepard at appl-ecosys.com>
>> >wrote:
>> >
>> >> On Thu, 2 Sep 2021, Rich Shepard wrote:
>> >>
>> >> > If I correctly understand the output of as.POSIXlt each date and time
>> >> > element is separate, so input such as 2016-03-03 12:00 would now be
>> 2016
>> >> 03
>> >> > 03 12 00 (I've not read how the elements are separated). (The TZ is
>> not
>> >> > important because all data are either PST or PDT.)
>> >>
>> >> Using this script:
>> >> discharge <- read.csv('../data/water/discharge.dat', header = TRUE, sep
>> =
>> >> ',', stringsAsFactors = FALSE)
>> >> discharge$sampdate <- as.POSIXlt(discharge$sampdate, tz = "",
>> >>                                   format = '%Y-%m-%d %H:%M',
>> >>                                   optional = 'logical')
>> >> discharge$cfs <- as.numeric(discharge$cfs, length = 6)
>> >>
>> >> I get this result:
>> >> > head(discharge)
>> >>               sampdate    cfs
>> >> 1 2016-03-03 12:00:00 149000
>> >> 2 2016-03-03 12:10:00 150000
>> >> 3 2016-03-03 12:20:00 151000
>> >> 4 2016-03-03 12:30:00 156000
>> >> 5 2016-03-03 12:40:00 154000
>> >> 6 2016-03-03 12:50:00 150000
>> >>
>> >> I'm completely open to suggestions on using this output to calculate
>> >> monthly
>> >> means and sds.
>> >>
>> >> If dplyr:summarize() will do so please show me how to modify this
>> command:
>> >> disc_monthly <- ( discharge
>> >>          %>% group_by(sampdate)
>> >>          %>% summarize(exp_value = mean(cfs, na.rm = TRUE))
>> >> because it produces daily means, not monthly means.
>> >>
>> >> TIA,
>> >>
>> >> Rich
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep  6 00:50:41 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 5 Sep 2021 15:50:41 -0700
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
 <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>
Message-ID: <CAGxFJbQPFXdB79EJXTpgEqg0G5JzZwgDnb_fGm8UN+r_Y68mHA@mail.gmail.com>

In case anyone is still interested in my query, note that if there are
n total items to be split into g groups as evenly as possible, if we
define this as at most two different size groups whose size differs by
1, then:

if n = k*g + r, where 0 <= r < g,
then n = k*(g - r) + (k + 1)*r  .
i.e. g-r groups of size k and r groups of size k+1

So using R's modular arithmetic operators, which are handy to know
about, we have:

r = n %% g and k = n %/% g .

(and note that you should disregard my previous stupid remark about
numerical analysis).

Cheers,
Bert


On Sat, Sep 4, 2021 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I have a more general problem for you.
>
> Given n items and 2 <=g <<n , how do you divide the n items into g
> groups that are as "equal as possible."
>
> First, operationally define "as equal as possible."
> Second, define the algorithm to carry out the definition. Hint: Note
> that sum{m[i]} for i <=g must sum to n, where m[i] is the number of
> items in the ith group.
> Third, write R code for the algorithm. Exercise for the reader.
>
> I may be wrong, but I think numerical analysts might also have a
> little fun here.
>
> Randomization, of course, is trivial.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sat, Sep 4, 2021 at 2:13 PM AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > Dear Thomas:
> >
> >
> > Thank you very much for your input in this matter.
> >
> >
> > The core part of this R code(s) (please see below) was written by *Richard
> > O'Keefe*. I had three examples with different sample sizes.
> >
> >
> >
> > *First sample of size n1 = 204* divided randomly into three groups of sizes
> > 68. *No problems with this one*.
> >
> >
> >
> > *The second sample of size n2 = 112* divided randomly into three groups of
> > sizes 37, 37, and 38. BUT this R code generated three groups of equal sizes
> > (37, 37, and 37). *How to fix the code to make sure that the output will be
> > three groups of sizes 37, 37, and 38*.
> >
> >
> >
> > *The third sample of size n3 = 284* divided randomly into three groups of
> > sizes 94, 95, and 95. BUT this R code generated three groups of equal sizes
> > (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
> > output will be three groups of sizes 94, 95, and 95*.
> >
> >
> > With many thanks
> >
> > abou
> >
> >
> > ###########  ------------------------   #############
> >
> >
> > N1 <- 485
> > population1.IDs <- seq(1, N1, by = 1)
> > #### population1.IDs
> >
> > n1<-204                                        ##### in this case the size
> > of each group of the three groups = 68
> > sample1.IDs <- sample(population1.IDs,n1)
> > #### sample1.IDs
> >
> > ####  n1 <- length(sample1.IDs)
> >
> >   m1 <- n1 %/% 3
> >   s1 <- sample(1:n1, n1)
> >   group1.IDs <- sample1.IDs[s1[1:m1]]
> >   group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
> >   group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]
> >
> > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> >
> > groups.IDs
> >
> >
> > ####### --------------------------
> >
> >
> > N2 <- 266
> > population2.IDs <- seq(1, N2, by = 1)
> > #### population2.IDs
> >
> > n2<-112                           ##### in this case the sizes of the three
> > groups are(37, 37, and 38)
> >                                           ##### BUT this codes generate
> > three groups of equal sizes (37, 37, and 37)
> > sample2.IDs <- sample(population2.IDs,n2)
> > #### sample2.IDs
> >
> > ####  n2 <- length(sample2.IDs)
> >
> >   m2 <- n2 %/% 3
> >   s2 <- sample(1:n2, n2)
> >   group1.IDs <- sample2.IDs[s2[1:m2]]
> >   group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
> >   group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]
> >
> > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> >
> > groups.IDs
> >
> >
> > ####### --------------------------
> >
> >
> >
> > N3 <- 674
> > population3.IDs <- seq(1, N3, by = 1)
> > #### population3.IDs
> >
> > n3<-284                           ##### in this case the sizes of the three
> > groups are(94, 95, and 95)
> >                                           ##### BUT this codes generate
> > three groups of equal sizes (94, 94, and 94)
> > sample2.IDs <- sample(population2.IDs,n2)
> > sample3.IDs <- sample(population3.IDs,n3)
> > #### sample3.IDs
> >
> > ####  n3 <- length(sample2.IDs)
> >
> >   m3 <- n3 %/% 3
> >   s3 <- sample(1:n3, n3)
> >   group1.IDs <- sample3.IDs[s3[1:m3]]
> >   group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
> >   group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]
> >
> > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> >
> > groups.IDs
> >
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >
> >
> > On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:
> >
> > > Abou,
> > >
> > >
> > >
> > > I?ve been following your question on how to split a data column randomly
> > > into 3 groups using R.
> > >
> > >
> > >
> > > My method may not be amenable for a large set of data but it surely worth
> > > considering since it makes sense intuitively.
> > >
> > >
> > >
> > > mydata <- LETTERS[1:11]
> > >
> > > > mydata
> > >
> > > [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
> > >
> > >
> > >
> > > # Let?s choose a random sample of size 4 from mydata
> > >
> > > > random_grp1
> > >
> > > [1] "J" "H" "D" "A"
> > >
> > >
> > >
> > > Now my next random selection of data is defined by
> > >
> > > data_wo_random <- setdiff(mydata,random_grp1)
> > >
> > > # this makes sense because I need to choose random data from a set which
> > > is defined by the difference of the sets mydata and random_grp1
> > >
> > >
> > >
> > > > data_wo_random
> > >
> > > [1] "B" "C" "E" "F" "G" "I" "K"
> > >
> > >
> > >
> > > This is great! So now I can randomly select data of any size from this set.
> > >
> > > Repeating this process can easily generate subgroups of your original
> > > dataset of any size you want.
> > >
> > >
> > >
> > > Surely this method could be improved so that this could be done
> > > automatically.
> > >
> > > Nevertheless, this is an intuitive method which I believe is easier to
> > > understand than some of the other methods posted.
> > >
> > >
> > >
> > > Hope this helps!
> > >
> > >
> > >
> > > Thomas Subia
> > >
> > > Statistician
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From g@@@uu| @end|ng |rom gm@||@com  Mon Sep  6 08:37:07 2021
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Mon, 6 Sep 2021 15:37:07 +0900
Subject: [R] field significance test
Message-ID: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>

Dear r-list member,

I want to plot a histogram that shows a number of station that have a
significant statistic (positive or negative) based on the value itself
and its p-value. df3 shows the test statistic value (column shows the
station and rows show the result from the resample matrix
(repetition/bootstrap)) and df4 shows the p-value.

#the value
dput(head(df3,10))
structure(c(0.569535339474781, 1.02925697755861, 1.08125714350978,
0.50589479161552, -0.695827095264809, 0.455608022735733, 1.2552019505074,
0.981335144120386, 1.63020923423253, -0.424613279862939, 0.429207234903993,
1.99059339634301, -1.25731480224036, 0.64293796635093, 0.0189774621961392,
0.1163965630274, -1.41756397958877, 1.58945674395921, -1.2551489541395,
-2.84122761058959, -0.72446669544026, -0.719331298629362, -0.164045813998067,
0.444120153507258, -0.0845757313567553, -0.27732982718919, -0.166982066770785,
-0.193859909749249, 0.277426534878283, -0.0430460496295642, -0.0741475736028902,
-0.017026178205196, 0.732589091697401, 0.332813962514037, -0.0860983232517636,
0.155930932436498, -0.438635444604027, 0.046881008364722, -0.704876076807635,
-0.945506782070735, 0.662399207637722, -0.860903464600488, 1.06638547921749,
-0.462184163508299, 0.442447468362937, 0.145655792120232, 0.696309974316211,
1.84692085953474, 0.00841868461519582, -1.04408256815264, -0.548599461573869,
1.22352273108675, 0.0191993545723452, 1.26090162037733, 0.192106046362172,
-1.02864978106213, -0.0712068006002629, -0.674610175422543, -0.658383381010154,
-1.52779151484935, 0.479809528798632, -0.112078644619679, -0.19482661081522,
-0.192179943664117, -0.246553759113406, -0.563554156777087, -1.0236492805268,
0.0289772842372375, -0.274878506644853, 0.95578159001869, -0.27550722692588,
-0.66586322268903, 1.24703690613745, -0.00368775734780707, -0.0766884108214613,
-1.41610325144406, 0.518897523428314, -2.12289477996499, 0.968369305561191,
0.0766656793804207, 0.470712743077857, 0.241711948576043, 0.0636131491007723,
-1.13735866614159, 0.625015831730259, -0.234696421716696, 0.358555918256736,
-0.651761882852838, -0.236796663592383, 0.0421395303375618, 0.574747610964774,
-0.730646230622174, -0.20839489662388, -1.4832025994155, -0.366841536561336,
0.621868015281511, 0.945609952617796, 0.297055307072896, 0.737974050847397,
1.49862070675738), .Dim = c(10L, 10L))

#the p-value
dput(head(df4,10))
structure(c(0.560903574193679, 0.358019718822816, 0.320136568444488,
0.721538652049639, 0.419898899237915, 0.511481779449553, 0.208829636238898,
0.535905791761543, 0.252523383923989, 0.721538652049639, 0.487651926831611,
0.0281856103410957, 0.138370395238992, 0.639104270712721, 0.98503410973661,
0.955123383216192, 0.358019718822816, 0.138370395238992, 0.252523383923989,
0.0373292396736942, 0.302215769747998, 0.302215769747998, 0.807343273858921,
0.560903574193679, 0.955123383216192, 0.836526366120417, 0.807343273858921,
0.807343273858921, 0.693640621783759, 0.895532903167044, 0.895532903167044,
0.98503410973661, 0.159470497055087, 0.560903574193679, 0.925275729900227,
0.865936215436343, 0.441845502530452, 0.98503410973661, 0.358019718822816,
0.170893484254114, 0.586452625432322, 0.268412562734209, 0.102689728987727,
0.511481779449553, 0.666151798537229, 0.925275729900227, 0.358019718822816,
0.0581501553999165, 0.98503410973661, 0.170893484254114, 0.586452625432322,
0.464434476654839, 0.98503410973661, 0.252523383923989, 0.925275729900227,
0.377977518007105, 0.98503410973661, 0.586452625432322,
0.666151798537229, 0.284975267823252, 0.560903574193679,
0.721538652049639, 0.778425914188847,
0.836526366120417, 0.778425914188847, 0.511481779449553, 0.087825095630195,
0.98503410973661, 0.693640621783759, 0.208829636238898, 0.807343273858921,
0.222740206090239, 0.222740206090239, 0.98503410973661, 0.925275729900227,
0.0373292396736942, 0.586452625432322, 0.00322938266821475, 0.222740206090239,
0.865936215436343, 0.338738311334395, 0.639104270712721, 0.895532903167044,
0.0533495868962313, 0.268412562734209, 0.721538652049639, 0.721538652049639,
0.195559652706897, 0.778425914188847, 0.880692897134707, 0.398606385377039,
0.398606385377039, 0.693640621783759, 0.102689728987727, 0.666151798537229,
0.252523383923989, 0.358019718822816, 0.778425914188847, 0.284975267823252,
0.0633043080023749), .Dim = c(10L, 10L))

#find the positive significant station
df5<-df3
df5[df4>0.05|df5<0]<-NA
df5[df5>0]<-1
pos<-as.numeric(rowSums(df5, na.rm=T))
hist(pos)

#find the negative significant station
df6<-df3
df6[df4>0.05|df5>0]<-NA
df6[df6<0]<-1
neg<-as.numeric(rowSums(df6, na.rm=T))
hist(neg)

but above code is not correct because the 0 station (row when there is
no significant station detected) should be the same. The problem is
when the row produces significant positive and negative at the same
time. Is there any way to combine positive and negative significant
value and plot the histogram? or we can calculate the 0 station first
separately?

Any lead is really appreciated. Thank you.

Ani Jaya


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 08:52:07 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 08:52:07 +0200
Subject: [R] combining geom_boxplot and geom_point with jitter
In-Reply-To: <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
References: <29e2f7e6-b2a7-9b4f-83d3-44bc197f0cac@rgzm.de>
 <de5962ba-7d8c-9dbe-c0bf-898fa245380f@sapo.pt>
Message-ID: <a0a547ec-92ae-d75d-7a16-471fc333fcb3@rgzm.de>

Thank you very much Rui!

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 04/09/2021 18:22, Rui Barradas wrote:
> Hello,
>
> The problem is that you have two grouping aesthetics, color and shape.
> In geom_point make the group explicit:
>
>
> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
> p <- p + geom_boxplot(outlier.shape = NA)
>
> p + geom_point(
> ? mapping = aes(shape = NMP_cat, group = Software),
> ? position = position_jitterdodge()
> )
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 09:54 de 02/09/21, Ivan Calandra escreveu:
>> Dear useRs,
>>
>> I'm having a problem to combine geom_boxplot and geom_point with 
>> jitter. It is difficult to explain but the code and result should 
>> make it clear (the example dataset is long so I copy it at the end of 
>> the email):
>>
>> p <- ggplot(my_data, aes(x = Diet, y = value, color = Software))
>> p <- p + geom_boxplot(outlier.shape = NA)
>> p <- p + geom_point(mapping = aes(shape = NMP_cat), position = 
>> position_jitterdodge())
>> print(p)
>>
>> As you can see in the resulting plot, the points with different 
>> shapes are dodged across the boxplot categories (colors). I'd like 
>> the three shapes per color to be restricted in one boxplot color, 
>> with jitter of course to better visualize the points.
>>
>> Does that make sense?
>>
>> I have played with the arguments of position_jitterdodge(), but it 
>> seems to me that the problem is that the shape aesthetic is not in 
>> the geom_boxplot() call (but I don't want it there, see below).
>>
>> For background information, the column used for shape gives some sort 
>> of "quality" to the points; that's why I want to show the points 
>> differently, so that it can easily be seen whether "good" points plot 
>> in the same area as the "bad" points.
>> Because I'm doing facet plots with other variables, I do not want to 
>> separate these categories in the boxplots - the resulting plots would 
>> be overcrowded.
>>
>> Thank you for the help.
>> Ivan
>>
>> ---
>>
>> my_data <- structure(list(Diet = c("Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne",
>> "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry 
>> lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", "Dry lucerne", 
>> "Dry lucerne", "Dry grass", "Dry grass", "Dry grass", "Dry grass", 
>> "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> grass", "Dry grass", "Dry grass", "Dry grass", "Dry grass", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry bamboo", "Dry 
>> bamboo",
>> "Dry bamboo", "Dry bamboo"), Software = c("ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax",
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", 
>> "ConfoMap", "Toothfrax", "ConfoMap", "Toothfrax", "ConfoMap", 
>> "Toothfrax", "ConfoMap", "Toothfrax"), NMP_cat = structure(c(1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 
>> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
>> 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 
>> 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 
>> 2L, 2L), .Label = c("0-5%", "5-10%", "10-20%", "20-100%"), class = 
>> c("ordered", "factor")), name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = 
>> c("Asfc", "Smfc", "HAsfc9", "HAsfc81", "epLsar", "NewEplsar"), class 
>> = "factor"), value = c(16.00716636, 12.925787, 14.05932485, 
>> 11.999816, 15.12321532, 12.711474, 12.79565826, 10.900949, 
>> 15.90481161, 12.836045, 16.22778102, 13.565995, 14.71354945, 
>> 12.384152, 16.61354777, 13.714165, 15.91399496, 12.983796, 
>> 19.44739619, 15.173215, 16.13761798, 12.932798, 14.7332952, 12.10277, 
>> 10.78710961, 8.762726, 10.16027362, 8.040399, 14.53444662, 11.527896, 
>> 17.38120685, 13.78922, 11.26840546, 9.426558, 24.01797992, 18.398553, 
>> 13.7435699, 11.44385, 14.391873, 10.757141, 22.39390393, 18.176262, 
>> 11.60322022, 9.969118, 11.6099975, 10.059618, 11.86282935, 10.280864, 
>> 16.22473644, 13.562839, 12.46350165, 10.629406, 23.9347534, 
>> 19.062174, 19.58121507, 15.910959, 13.99145447, 11.352648, 
>> 14.38942328, 11.821431, 23.4733371, 18.549503, 13.08142223, 
>> 10.735494, 17.09293046, 13.012834, 28.80020878, 22.447105, 
>> 25.74460885, 19.76834, 14.29106582, 12.233774, 12.03005024, 
>> 10.364224, 12.58953574, 10.30257, 18.07111578, 14.416143, 
>> 20.85562751, 16.524047, 21.06132234, 15.744758, 15.24052683, 
>> 11.891487, 11.62446752, 9.14325, 11.75704705, 10.358542, 13.65568703, 
>> 11.766129, 16.98137759, 12.594787, 11.6560954, 10.32073, 15.46708251, 
>> 13.199232, 13.20110131, 11.060226, 16.13986173, 13.564802, 
>> 25.45656859, 20.071231, 24.84006178, 19.335892, 14.4723856, 
>> 11.994841, 12.07940958, 9.470493, 13.93630412, 11.489685, 
>> 21.84464295, 17.806018, 17.4383111, 14.478338, 20.55074297, 
>> 16.254467, 30.15238714, 24.193768, 32.8541897, 25.769585, 
>> 32.06966759, 24.507185, 20.53975772, 15.951186, 11.54494952, 
>> 9.676342, 13.56490524, 11.456356, 13.58242208, 10.919419, 
>> 13.55260161, 11.356056, 38.58113502, 31.087536, 23.6753536, 
>> 18.749955, 26.38707155, 20.877856, 26.18252748, 20.758242)), 
>> row.names = c(NA, -140L), class = c("tbl_df", "tbl", "data.frame"))
>>
>


From drj|m|emon @end|ng |rom gm@||@com  Mon Sep  6 10:41:43 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 6 Sep 2021 18:41:43 +1000
Subject: [R] field significance test
In-Reply-To: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
Message-ID: <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>

HI Ani,
I would create these two matrices:

# matrix of logicals for positive stat values
posvalue<-df3 > 0
# matrix of logicals for significance
sigstat<-df4 < 0.05

Then you can identify the positive/negative and significant values:

which(posvalue & sigstat)
[1] 12
which(!posvalue & sigstat)
[1] 20 76 78

and as you note, column 2 has 2 significant results, one statistical
value positive and the other negative.
I'm not sure what sort of histogram you want, perhaps all ten columns
with groups of ten bars for each column (very messy and sparse). Maybe
a bit more info will enlighten me.

Jim

On Mon, Sep 6, 2021 at 4:37 PM ani jaya <gaaauul at gmail.com> wrote:
>
> Dear r-list member,
>
> I want to plot a histogram that shows a number of station that have a
> significant statistic (positive or negative) based on the value itself
> and its p-value. df3 shows the test statistic value (column shows the
> station and rows show the result from the resample matrix
> (repetition/bootstrap)) and df4 shows the p-value.
>
> #the value
> dput(head(df3,10))
> structure(c(0.569535339474781, 1.02925697755861, 1.08125714350978,
> 0.50589479161552, -0.695827095264809, 0.455608022735733, 1.2552019505074,
> 0.981335144120386, 1.63020923423253, -0.424613279862939, 0.429207234903993,
> 1.99059339634301, -1.25731480224036, 0.64293796635093, 0.0189774621961392,
> 0.1163965630274, -1.41756397958877, 1.58945674395921, -1.2551489541395,
> -2.84122761058959, -0.72446669544026, -0.719331298629362, -0.164045813998067,
> 0.444120153507258, -0.0845757313567553, -0.27732982718919, -0.166982066770785,
> -0.193859909749249, 0.277426534878283, -0.0430460496295642, -0.0741475736028902,
> -0.017026178205196, 0.732589091697401, 0.332813962514037, -0.0860983232517636,
> 0.155930932436498, -0.438635444604027, 0.046881008364722, -0.704876076807635,
> -0.945506782070735, 0.662399207637722, -0.860903464600488, 1.06638547921749,
> -0.462184163508299, 0.442447468362937, 0.145655792120232, 0.696309974316211,
> 1.84692085953474, 0.00841868461519582, -1.04408256815264, -0.548599461573869,
> 1.22352273108675, 0.0191993545723452, 1.26090162037733, 0.192106046362172,
> -1.02864978106213, -0.0712068006002629, -0.674610175422543, -0.658383381010154,
> -1.52779151484935, 0.479809528798632, -0.112078644619679, -0.19482661081522,
> -0.192179943664117, -0.246553759113406, -0.563554156777087, -1.0236492805268,
> 0.0289772842372375, -0.274878506644853, 0.95578159001869, -0.27550722692588,
> -0.66586322268903, 1.24703690613745, -0.00368775734780707, -0.0766884108214613,
> -1.41610325144406, 0.518897523428314, -2.12289477996499, 0.968369305561191,
> 0.0766656793804207, 0.470712743077857, 0.241711948576043, 0.0636131491007723,
> -1.13735866614159, 0.625015831730259, -0.234696421716696, 0.358555918256736,
> -0.651761882852838, -0.236796663592383, 0.0421395303375618, 0.574747610964774,
> -0.730646230622174, -0.20839489662388, -1.4832025994155, -0.366841536561336,
> 0.621868015281511, 0.945609952617796, 0.297055307072896, 0.737974050847397,
> 1.49862070675738), .Dim = c(10L, 10L))
>
> #the p-value
> dput(head(df4,10))
> structure(c(0.560903574193679, 0.358019718822816, 0.320136568444488,
> 0.721538652049639, 0.419898899237915, 0.511481779449553, 0.208829636238898,
> 0.535905791761543, 0.252523383923989, 0.721538652049639, 0.487651926831611,
> 0.0281856103410957, 0.138370395238992, 0.639104270712721, 0.98503410973661,
> 0.955123383216192, 0.358019718822816, 0.138370395238992, 0.252523383923989,
> 0.0373292396736942, 0.302215769747998, 0.302215769747998, 0.807343273858921,
> 0.560903574193679, 0.955123383216192, 0.836526366120417, 0.807343273858921,
> 0.807343273858921, 0.693640621783759, 0.895532903167044, 0.895532903167044,
> 0.98503410973661, 0.159470497055087, 0.560903574193679, 0.925275729900227,
> 0.865936215436343, 0.441845502530452, 0.98503410973661, 0.358019718822816,
> 0.170893484254114, 0.586452625432322, 0.268412562734209, 0.102689728987727,
> 0.511481779449553, 0.666151798537229, 0.925275729900227, 0.358019718822816,
> 0.0581501553999165, 0.98503410973661, 0.170893484254114, 0.586452625432322,
> 0.464434476654839, 0.98503410973661, 0.252523383923989, 0.925275729900227,
> 0.377977518007105, 0.98503410973661, 0.586452625432322,
> 0.666151798537229, 0.284975267823252, 0.560903574193679,
> 0.721538652049639, 0.778425914188847,
> 0.836526366120417, 0.778425914188847, 0.511481779449553, 0.087825095630195,
> 0.98503410973661, 0.693640621783759, 0.208829636238898, 0.807343273858921,
> 0.222740206090239, 0.222740206090239, 0.98503410973661, 0.925275729900227,
> 0.0373292396736942, 0.586452625432322, 0.00322938266821475, 0.222740206090239,
> 0.865936215436343, 0.338738311334395, 0.639104270712721, 0.895532903167044,
> 0.0533495868962313, 0.268412562734209, 0.721538652049639, 0.721538652049639,
> 0.195559652706897, 0.778425914188847, 0.880692897134707, 0.398606385377039,
> 0.398606385377039, 0.693640621783759, 0.102689728987727, 0.666151798537229,
> 0.252523383923989, 0.358019718822816, 0.778425914188847, 0.284975267823252,
> 0.0633043080023749), .Dim = c(10L, 10L))
>
> #find the positive significant station
> df5<-df3
> df5[df4>0.05|df5<0]<-NA
> df5[df5>0]<-1
> pos<-as.numeric(rowSums(df5, na.rm=T))
> hist(pos)
>
> #find the negative significant station
> df6<-df3
> df6[df4>0.05|df5>0]<-NA
> df6[df6<0]<-1
> neg<-as.numeric(rowSums(df6, na.rm=T))
> hist(neg)
>
> but above code is not correct because the 0 station (row when there is
> no significant station detected) should be the same. The problem is
> when the row produces significant positive and negative at the same
> time. Is there any way to combine positive and negative significant
> value and plot the histogram? or we can calculate the 0 station first
> separately?
>
> Any lead is really appreciated. Thank you.
>
> Ani Jaya
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Mon Sep  6 12:16:08 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Mon, 6 Sep 2021 06:16:08 -0400
Subject: [R] Splitting a data column randomly into 3 groups
In-Reply-To: <CAGxFJbQPFXdB79EJXTpgEqg0G5JzZwgDnb_fGm8UN+r_Y68mHA@mail.gmail.com>
References: <005601d7a1a5$11da6480$358f2d80$.ref@yahoo.com>
 <005601d7a1a5$11da6480$358f2d80$@yahoo.com>
 <CAE9stmfGWWt74+K+3mo-KuCQrgnpeoRNANfEAQFFAKHyVDBEqw@mail.gmail.com>
 <CAGxFJbQ+=0j4=7g4LUS2HvnXJw4KFVe0FLzBrGDuDLcURcedqA@mail.gmail.com>
 <CAGxFJbQPFXdB79EJXTpgEqg0G5JzZwgDnb_fGm8UN+r_Y68mHA@mail.gmail.com>
Message-ID: <CAE9stmcGBVvoMGWuo2pUq6M3OFjsz-VRm57K9eNLf7VRZO7ObQ@mail.gmail.com>

Hi Bert and All: good morning

I promise this would be the last time to write about this topic.

I come up with this R function (please see below), for sure with your help.
It works for all sample sizes. I also provided three different simple
examples.

with many thanks
abou

##################    Here it is    ###############

Random.Sample.IDs <- function (N,n, ngroups){    #### N = population size,
and n = sample size, ngroups = number of groups

population.IDs <- seq(1, N, by = 1)
sample.IDs <- sample(population.IDs,n)

##### to print sample.IDs in a column format
##### --------------------------------------------------
sample.IDs.in.column<-data.frame(sample.IDs)
print(sample.IDs.in.column)

reminder.n<-n%%ngroups
reminder.n

n.final<-n-reminder.n
n.final

  m <- n %/% 3
  m
  s <- sample(1:n, n)

if (reminder.n == 0) {

  group1.IDs <- sample.IDs[s[1:m]]
  group2.IDs <- sample.IDs[s[(m+1):(2*m)]]
  group3.IDs <- sample.IDs[s[(m*2+1):(3*m)]]

} else if(reminder.n == 1){

  group1.IDs <- sample.IDs[s[1:(m+1)]]
  group2.IDs <- sample.IDs[s[(m+2):(2*m+1)]]
  group3.IDs <- sample.IDs[s[(m*2+2):(3*m+1)]]

} else if(reminder.n == 2){

  group1.IDs <- sample.IDs[s[1:(m+1)]]
  group2.IDs <- sample.IDs[s[(m+2):(2*m+2)]]
  group3.IDs <- sample.IDs[s[(m*2+3):(3*m+2)]]
}
nn<-max(length(group1.IDs),length(group2.IDs),length(group3.IDs))
nn
length(group1.IDs) <- nn
length(group2.IDs) <- nn
length(group3.IDs) <- nn

groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)

groups.IDs

}


#####  Examples
#####  --------

Random.Sample.IDs (100,12,3)    #### group sizes are equal (n1=n2=n3=4)

Random.Sample.IDs (100,13,3)    #### group sizes are NOT equal (n1=5, n2=4,
n3=4)

Random.Sample.IDs (100,17,3)    #### group sizes are NOT equal (n1=6, n2=6,
n3=5)


______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Sun, Sep 5, 2021 at 6:50 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> In case anyone is still interested in my query, note that if there are
> n total items to be split into g groups as evenly as possible, if we
> define this as at most two different size groups whose size differs by
> 1, then:
>
> if n = k*g + r, where 0 <= r < g,
> then n = k*(g - r) + (k + 1)*r  .
> i.e. g-r groups of size k and r groups of size k+1
>
> So using R's modular arithmetic operators, which are handy to know
> about, we have:
>
> r = n %% g and k = n %/% g .
>
> (and note that you should disregard my previous stupid remark about
> numerical analysis).
>
> Cheers,
> Bert
>
>
> On Sat, Sep 4, 2021 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > I have a more general problem for you.
> >
> > Given n items and 2 <=g <<n , how do you divide the n items into g
> > groups that are as "equal as possible."
> >
> > First, operationally define "as equal as possible."
> > Second, define the algorithm to carry out the definition. Hint: Note
> > that sum{m[i]} for i <=g must sum to n, where m[i] is the number of
> > items in the ith group.
> > Third, write R code for the algorithm. Exercise for the reader.
> >
> > I may be wrong, but I think numerical analysts might also have a
> > little fun here.
> >
> > Randomization, of course, is trivial.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Sat, Sep 4, 2021 at 2:13 PM AbouEl-Makarim Aboueissa
> > <abouelmakarim1962 at gmail.com> wrote:
> > >
> > > Dear Thomas:
> > >
> > >
> > > Thank you very much for your input in this matter.
> > >
> > >
> > > The core part of this R code(s) (please see below) was written by
> *Richard
> > > O'Keefe*. I had three examples with different sample sizes.
> > >
> > >
> > >
> > > *First sample of size n1 = 204* divided randomly into three groups of
> sizes
> > > 68. *No problems with this one*.
> > >
> > >
> > >
> > > *The second sample of size n2 = 112* divided randomly into three
> groups of
> > > sizes 37, 37, and 38. BUT this R code generated three groups of equal
> sizes
> > > (37, 37, and 37). *How to fix the code to make sure that the output
> will be
> > > three groups of sizes 37, 37, and 38*.
> > >
> > >
> > >
> > > *The third sample of size n3 = 284* divided randomly into three groups
> of
> > > sizes 94, 95, and 95. BUT this R code generated three groups of equal
> sizes
> > > (94, 94, and 94). *Again*, h*ow to fix the code to make sure that the
> > > output will be three groups of sizes 94, 95, and 95*.
> > >
> > >
> > > With many thanks
> > >
> > > abou
> > >
> > >
> > > ###########  ------------------------   #############
> > >
> > >
> > > N1 <- 485
> > > population1.IDs <- seq(1, N1, by = 1)
> > > #### population1.IDs
> > >
> > > n1<-204                                        ##### in this case the
> size
> > > of each group of the three groups = 68
> > > sample1.IDs <- sample(population1.IDs,n1)
> > > #### sample1.IDs
> > >
> > > ####  n1 <- length(sample1.IDs)
> > >
> > >   m1 <- n1 %/% 3
> > >   s1 <- sample(1:n1, n1)
> > >   group1.IDs <- sample1.IDs[s1[1:m1]]
> > >   group2.IDs <- sample1.IDs[s1[(m1+1):(2*m1)]]
> > >   group3.IDs <- sample1.IDs[s1[(m1*2+1):(3*m1)]]
> > >
> > > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> > >
> > > groups.IDs
> > >
> > >
> > > ####### --------------------------
> > >
> > >
> > > N2 <- 266
> > > population2.IDs <- seq(1, N2, by = 1)
> > > #### population2.IDs
> > >
> > > n2<-112                           ##### in this case the sizes of the
> three
> > > groups are(37, 37, and 38)
> > >                                           ##### BUT this codes generate
> > > three groups of equal sizes (37, 37, and 37)
> > > sample2.IDs <- sample(population2.IDs,n2)
> > > #### sample2.IDs
> > >
> > > ####  n2 <- length(sample2.IDs)
> > >
> > >   m2 <- n2 %/% 3
> > >   s2 <- sample(1:n2, n2)
> > >   group1.IDs <- sample2.IDs[s2[1:m2]]
> > >   group2.IDs <- sample2.IDs[s2[(m2+1):(2*m2)]]
> > >   group3.IDs <- sample2.IDs[s2[(m2*2+1):(3*m2)]]
> > >
> > > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> > >
> > > groups.IDs
> > >
> > >
> > > ####### --------------------------
> > >
> > >
> > >
> > > N3 <- 674
> > > population3.IDs <- seq(1, N3, by = 1)
> > > #### population3.IDs
> > >
> > > n3<-284                           ##### in this case the sizes of the
> three
> > > groups are(94, 95, and 95)
> > >                                           ##### BUT this codes generate
> > > three groups of equal sizes (94, 94, and 94)
> > > sample2.IDs <- sample(population2.IDs,n2)
> > > sample3.IDs <- sample(population3.IDs,n3)
> > > #### sample3.IDs
> > >
> > > ####  n3 <- length(sample2.IDs)
> > >
> > >   m3 <- n3 %/% 3
> > >   s3 <- sample(1:n3, n3)
> > >   group1.IDs <- sample3.IDs[s3[1:m3]]
> > >   group2.IDs <- sample3.IDs[s3[(m3+1):(2*m3)]]
> > >   group3.IDs <- sample3.IDs[s3[(m3*2+1):(3*m3)]]
> > >
> > > groups.IDs <-cbind(group1.IDs,group2.IDs,group3.IDs)
> > >
> > > groups.IDs
> > >
> > > ______________________
> > >
> > >
> > > *AbouEl-Makarim Aboueissa, PhD*
> > >
> > > *Professor, Statistics and Data Science*
> > > *Graduate Coordinator*
> > >
> > > *Department of Mathematics and Statistics*
> > > *University of Southern Maine*
> > >
> > >
> > >
> > > On Sat, Sep 4, 2021 at 11:54 AM Thomas Subia <tgs77m at yahoo.com> wrote:
> > >
> > > > Abou,
> > > >
> > > >
> > > >
> > > > I?ve been following your question on how to split a data column
> randomly
> > > > into 3 groups using R.
> > > >
> > > >
> > > >
> > > > My method may not be amenable for a large set of data but it surely
> worth
> > > > considering since it makes sense intuitively.
> > > >
> > > >
> > > >
> > > > mydata <- LETTERS[1:11]
> > > >
> > > > > mydata
> > > >
> > > > [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K"
> > > >
> > > >
> > > >
> > > > # Let?s choose a random sample of size 4 from mydata
> > > >
> > > > > random_grp1
> > > >
> > > > [1] "J" "H" "D" "A"
> > > >
> > > >
> > > >
> > > > Now my next random selection of data is defined by
> > > >
> > > > data_wo_random <- setdiff(mydata,random_grp1)
> > > >
> > > > # this makes sense because I need to choose random data from a set
> which
> > > > is defined by the difference of the sets mydata and random_grp1
> > > >
> > > >
> > > >
> > > > > data_wo_random
> > > >
> > > > [1] "B" "C" "E" "F" "G" "I" "K"
> > > >
> > > >
> > > >
> > > > This is great! So now I can randomly select data of any size from
> this set.
> > > >
> > > > Repeating this process can easily generate subgroups of your original
> > > > dataset of any size you want.
> > > >
> > > >
> > > >
> > > > Surely this method could be improved so that this could be done
> > > > automatically.
> > > >
> > > > Nevertheless, this is an intuitive method which I believe is easier
> to
> > > > understand than some of the other methods posted.
> > > >
> > > >
> > > >
> > > > Hope this helps!
> > > >
> > > >
> > > >
> > > > Thomas Subia
> > > >
> > > > Statistician
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 16:03:46 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 16:03:46 +0200
Subject: [R] ggsave() with width only
Message-ID: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>

Dear useRs,

I produce several independent ggplot2 plots and I would like to save 
them to a fixed width (for publications), but the height (and therefore 
aspect ratio) is different from plot to plot.

How can I save my plots with ggsave() supplying only a fixed width but 
without knowing the height nor the aspect ratio? If I specify the width 
only, the plots are truncated in width because the aspect ratio is not 
correct.

Thank you for the tip!
Ivan

-- 

Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  6 16:24:35 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 06 Sep 2021 07:24:35 -0700
Subject: [R] ggsave() with width only
In-Reply-To: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
Message-ID: <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>

I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.

On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Dear useRs,
>
>I produce several independent ggplot2 plots and I would like to save 
>them to a fixed width (for publications), but the height (and therefore 
>aspect ratio) is different from plot to plot.
>
>How can I save my plots with ggsave() supplying only a fixed width but 
>without knowing the height nor the aspect ratio? If I specify the width 
>only, the plots are truncated in width because the aspect ratio is not 
>correct.
>
>Thank you for the tip!
>Ivan
>

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 16:29:34 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 16:29:34 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
Message-ID: <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>

Thank you Jeff for your answer.

I do use rmarkdown but I do not write papers completely with it. I do 
output a report in HTML but I also like to export the plots as PDF so 
that I can edit them (using Inkscape or similar) if and as needed.
And because I like to have both the HTML report including plots and 
extra plots as PDF, I cannot use pdf(). That's why I use ggsave().

Or am I missing something?

Ivan

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 06/09/2021 16:24, Jeff Newmiller wrote:
> I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.
>
> On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Dear useRs,
>>
>> I produce several independent ggplot2 plots and I would like to save
>> them to a fixed width (for publications), but the height (and therefore
>> aspect ratio) is different from plot to plot.
>>
>> How can I save my plots with ggsave() supplying only a fixed width but
>> without knowing the height nor the aspect ratio? If I specify the width
>> only, the plots are truncated in width because the aspect ratio is not
>> correct.
>>
>> Thank you for the tip!
>> Ivan
>>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Sep  6 16:44:25 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 06 Sep 2021 07:44:25 -0700
Subject: [R] ggsave() with width only
In-Reply-To: <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
 <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
Message-ID: <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>

I don't always use rmarkdown to write papers either, but you can capture figures from it. I avoid hand editing figures like the plague of irreproducibility. But sometimes you get stuck in an approach... I cannot answer your original post, but wanted to point out that it may not actually be necessary to answer it if you change your approach.

On September 6, 2021 7:29:34 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>Thank you Jeff for your answer.
>
>I do use rmarkdown but I do not write papers completely with it. I do 
>output a report in HTML but I also like to export the plots as PDF so 
>that I can edit them (using Inkscape or similar) if and as needed.
>And because I like to have both the HTML report including plots and 
>extra plots as PDF, I cannot use pdf(). That's why I use ggsave().
>
>Or am I missing something?
>
>Ivan
>
>--
>Dr. Ivan Calandra
>Imaging lab
>RGZM - MONREPOS Archaeological Research Centre
>Schloss Monrepos
>56567 Neuwied, Germany
>+49 (0) 2631 9772-243
>https://www.researchgate.net/profile/Ivan_Calandra
>
>On 06/09/2021 16:24, Jeff Newmiller wrote:
>> I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.
>>
>> On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>>> Dear useRs,
>>>
>>> I produce several independent ggplot2 plots and I would like to save
>>> them to a fixed width (for publications), but the height (and therefore
>>> aspect ratio) is different from plot to plot.
>>>
>>> How can I save my plots with ggsave() supplying only a fixed width but
>>> without knowing the height nor the aspect ratio? If I specify the width
>>> only, the plots are truncated in width because the aspect ratio is not
>>> correct.
>>>
>>> Thank you for the tip!
>>> Ivan
>>>

-- 
Sent from my phone. Please excuse my brevity.


From c@|@ndr@ @end|ng |rom rgzm@de  Mon Sep  6 17:06:15 2021
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Mon, 6 Sep 2021 17:06:15 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
 <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
 <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>
Message-ID: <1388dab2-31c9-ebe3-f496-385ee9d0d49d@rgzm.de>

Yes Jeff, you are right. I hate manually editing figures too, but 
sometimes I find it's still the easiest way (e.g. when you submit your 
paper several times when journals have differing guidelines, or when you 
build figures from several (sub)plots + other images, or when you 
combine plots that a colleague has done in Python with your R plots). I 
have the impression that at some point, there is always something to 
edit by hand, no matter how much you've adjusted the graphical 
parameters and even if you use all possible tools available for ggplot2...

I have thought a lot about it and, as it is, I am not sure it would be 
worth the effort. I might be missing some arguments for it, but I would 
actually like someone to show me how it could look like - this might 
just be what I need to be convinced!

--
Dr. Ivan Calandra
Imaging lab
RGZM - MONREPOS Archaeological Research Centre
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 06/09/2021 16:44, Jeff Newmiller wrote:
> I don't always use rmarkdown to write papers either, but you can capture figures from it. I avoid hand editing figures like the plague of irreproducibility. But sometimes you get stuck in an approach... I cannot answer your original post, but wanted to point out that it may not actually be necessary to answer it if you change your approach.
>
> On September 6, 2021 7:29:34 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>> Thank you Jeff for your answer.
>>
>> I do use rmarkdown but I do not write papers completely with it. I do
>> output a report in HTML but I also like to export the plots as PDF so
>> that I can edit them (using Inkscape or similar) if and as needed.
>> And because I like to have both the HTML report including plots and
>> extra plots as PDF, I cannot use pdf(). That's why I use ggsave().
>>
>> Or am I missing something?
>>
>> Ivan
>>
>> --
>> Dr. Ivan Calandra
>> Imaging lab
>> RGZM - MONREPOS Archaeological Research Centre
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> On 06/09/2021 16:24, Jeff Newmiller wrote:
>>> I use an rmarkdown file to generate consistent output figures and tables for html or Word. I just use Rnw files directly if I am generating LaTeX. I do not use R files for building output... and I never use ggsave. So you might consider altering your approach to bypass the question entirely.
>>>
>>> On September 6, 2021 7:03:46 AM PDT, Ivan Calandra <calandra at rgzm.de> wrote:
>>>> Dear useRs,
>>>>
>>>> I produce several independent ggplot2 plots and I would like to save
>>>> them to a fixed width (for publications), but the height (and therefore
>>>> aspect ratio) is different from plot to plot.
>>>>
>>>> How can I save my plots with ggsave() supplying only a fixed width but
>>>> without knowing the height nor the aspect ratio? If I specify the width
>>>> only, the plots are truncated in width because the aspect ratio is not
>>>> correct.
>>>>
>>>> Thank you for the tip!
>>>> Ivan
>>>>


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep  6 17:53:23 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 6 Sep 2021 11:53:23 -0400
Subject: [R] ggsave() with width only
In-Reply-To: <1388dab2-31c9-ebe3-f496-385ee9d0d49d@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
 <CC6FE349-3CA9-48A7-9532-F15C2EE1F692@dcn.davis.ca.us>
 <5a218981-c1f2-ea50-d6b1-ba5b8d0a827e@rgzm.de>
 <1F817A73-D4A1-4B0B-8625-F8E7975B7169@dcn.davis.ca.us>
 <1388dab2-31c9-ebe3-f496-385ee9d0d49d@rgzm.de>
Message-ID: <7b49ca23-3661-a341-86c0-d265f75a4fff@gmail.com>

On 06/09/2021 11:06 a.m., Ivan Calandra wrote:
> Yes Jeff, you are right. I hate manually editing figures too, but
> sometimes I find it's still the easiest way (e.g. when you submit your
> paper several times when journals have differing guidelines, or when you
> build figures from several (sub)plots + other images, or when you
> combine plots that a colleague has done in Python with your R plots). I
> have the impression that at some point, there is always something to
> edit by hand, no matter how much you've adjusted the graphical
> parameters and even if you use all possible tools available for ggplot2...
> 
> I have thought a lot about it and, as it is, I am not sure it would be
> worth the effort. I might be missing some arguments for it, but I would
> actually like someone to show me how it could look like - this might
> just be what I need to be convinced!

It's not much effort.  For example, the document below produces two PDF 
figures with different heights but the same width.    I called the 
document Untitled.Rmd, so the figures show up in 
Untitled_figures/figure-latex/fig1-1.pdf and 
Untitled_figures/figure-latex/fig2-1.pdf.

   ---
   title: "Untitled"
   author: "Duncan Murdoch"
   date: "06/09/2021"
   output:
     pdf_document:
       keep_tex: true
   ---

   ```{r setup, include=FALSE}
   knitr::opts_chunk$set(echo = TRUE)
   ```

   ```{r fig1, fig.width=2, echo=FALSE}
   library(ggplot2)
   ggplot(mtcars, aes(carb, gear)) +
     geom_point()
   ```

   ```{r fig2, fig.width=2, echo=FALSE}
   ggplot(mtcars, aes(carb, gear)) +
     geom_point() +
     coord_fixed()
   ```


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Mon Sep  6 16:16:10 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Mon, 6 Sep 2021 14:16:10 +0000
Subject: [R] 'Double to logical' error
Message-ID: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>

Dear colleagues
>
> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>
> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> This follows the commands
>
> for (region in regions){
>    for (study in unique(df$studyid)){
>      single_study_df <- df %>% filter(studyid==study)
>      if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>        df <- calc_bilat(study, region, r, df)
>      }
>    }
> }
>
>
> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>
> I would greatly value your input on this matter
>
> Kind regards
>
> John Tully
>
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep  6 18:34:03 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 6 Sep 2021 12:34:03 -0400
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>

On 06/09/2021 10:16 a.m., John Tully wrote:
> Dear colleagues
>>
>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>
>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.

That certainly looks like a tidyverse error, specifically from the 
tibble package.

Duncan Murdoch

>>
>> This follows the commands
>>
>> for (region in regions){
>>     for (study in unique(df$studyid)){
>>       single_study_df <- df %>% filter(studyid==study)
>>       if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>         df <- calc_bilat(study, region, r, df)
>>       }
>>     }
>> }
>>
>>
>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>
>> I would greatly value your input on this matter
>>
>> Kind regards
>>
>> John Tully
>>
>>
>>
>>
> 
> 
> 
> 
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
> 
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Sep  6 18:36:59 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 6 Sep 2021 09:36:59 -0700
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>

>  Run `rlang::last_error()` to see where the error occurred

What did rlang::last_error() show?

-Bill


On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk>
wrote:

> Dear colleagues
> >
> > in conducting a meta-analysis (of MRI data) I am running into the
> repeated issue:
> >
> > Error: Assigned data `single_study_df` must be compatible with existing
> data. ? Error occurred for column `accumbens_sd`. x Can't convert from
> <double> to <logical> due to loss of precision. * Locations: 1, 2. Run
> `rlang::last_error()` to see where the error occurred.
> >
> > This follows the commands
> >
> > for (region in regions){
> >    for (study in unique(df$studyid)){
> >      single_study_df <- df %>% filter(studyid==study)
> >      if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l',
> region)])){
> >        df <- calc_bilat(study, region, r, df)
> >      }
> >    }
> > }
> >
> >
> > My colleague (cc'd) believed it may be an issue with tidyverse version,
> however using an older version (1.2.1), the issue persists. note
> 'accumbens' is the first of many columns so I suspect this is why it flags
> this up.
> >
> > I would greatly value your input on this matter
> >
> > Kind regards
> >
> > John Tully
> >
> >
> >
> >
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep  6 18:49:26 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 6 Sep 2021 12:49:26 -0400
Subject: [R] 'Double to logical' error
In-Reply-To: <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
Message-ID: <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>

You get this error from this kind of operation on tibbles:

library(tibble)
t1 <- tibble(x = c(TRUE, FALSE))
t2 <- tibble(x = c(1.2, 1.3))
t1[1,] <- t2[1,]
#> Error: Assigned data `t2[1, ]` must be compatible with existing data.
#> ? Error occurred for column `x`.
#> x Can't convert from <double> to <logical> due to loss of precision.
#> * Locations: 1.

If t1 had been a data.frame instead of a tibble, this would convert t1$x 
to type double.  So it is possible some code you are using assumes 
things inheriting from class "data.frame" act like dataframes.  Or maybe 
they were just sloppy.  In any case, you might be able to fix it by 
changing single_study_df to a dataframe using

   single_study_df <- as.data.frame(single_study_df)

Duncan Murdoch


On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
> On 06/09/2021 10:16 a.m., John Tully wrote:
>> Dear colleagues
>>>
>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>
>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
> 
> That certainly looks like a tidyverse error, specifically from the
> tibble package.
> 
> Duncan Murdoch
> 
>>>
>>> This follows the commands
>>>
>>> for (region in regions){
>>>      for (study in unique(df$studyid)){
>>>        single_study_df <- df %>% filter(studyid==study)
>>>        if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>          df <- calc_bilat(study, region, r, df)
>>>        }
>>>      }
>>> }
>>>
>>>
>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>
>>> I would greatly value your input on this matter
>>>
>>> Kind regards
>>>
>>> John Tully
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>> This message and any attachment are intended solely for the addressee
>> and may contain confidential information. If you have received this
>> message in error, please contact the sender and delete the email and
>> attachment.
>>
>> Any views or opinions expressed by the author of this email do not
>> necessarily reflect the views of the University of Nottingham. Email
>> communications with the University of Nottingham may be monitored
>> where permitted by law.
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From j|n||68 @end|ng |rom gm@||@com  Tue Sep  7 01:46:34 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Tue, 7 Sep 2021 09:46:34 +1000
Subject: [R] spm package is available on CRAN again
Message-ID: <CAGu_3ZKf=6txLZ5VQNCJzKPTuJw7Fev1XDVuG9pbyVx0p3UMpA@mail.gmail.com>

Dear spm users and all,

I am glad to inform you that the spm package is available on CRAN again. It
is an updated version with a few bugs fixed. Please note that some
functions in the package are not only for spatial predictive modelling but
also for general predictive modeling.

Please feel free to contact me if you have any questions regarding the spm
package.

Best regards,
-- 
Jin
------------------------------------------
Jin Li, PhD
Founder, Data2action, Australia
https://www.researchgate.net/profile/Jin_Li32
https://scholar.google.com/citations?user=Jeot53EAAAAJ&hl=en

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Tue Sep  7 02:38:44 2021
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 7 Sep 2021 09:38:44 +0900
Subject: [R] field significance test
In-Reply-To: <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
 <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
Message-ID: <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>

Hello Jim, thank you for your response. What I am trying to achieve is
like this:

#calculate the positive significant station for every row based on p-value
df5<-df3
df5[df4>0.05|df5<0]<-NA
      #remove the insignificant one or negative statistic value
df5[df5>0]<-1
            #change the positive value to be +1 so I can row sum later
pos<-as.data.frame(rowSums(df5, na.rm=T))                         #row
sum to see the total significant station (column) for each row
poss<-as.data.frame(table(pos))
   #get the frequency of each significant number (row that have only
1,2,3,.. significant station)
posss<-as.numeric(rep(poss$pos[-1],poss$Freq[-1]))-1          #create
the series based on frequency

#calculate the negative significant station for every row based on p-value
df6<-df3
df6[df4>0.05|df5>0]<-NA
df6[df6<0]<-1
neg<-as.data.frame(rowSums(df6, na.rm=T))
negg<-as.data.frame(table(neg))
neggg<-(as.numeric(rep(negg$neg[-1],negg$Freq[-1]))-1)*-1

ne<-sum(pos==0&neg==0)
#to see the 0 significant station, row that have no significant
station



after that I want to combine posss, neggg, and ne to be 1 column data
frame but not success yet. After that, I want to plot the histogram to
see the distribution of significant stations.
Any lead is appreciate. Thank you
Ani Jaya


From g@@@uu| @end|ng |rom gm@||@com  Tue Sep  7 02:50:52 2021
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Tue, 7 Sep 2021 09:50:52 +0900
Subject: [R] field significance test
In-Reply-To: <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
 <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
 <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>
Message-ID: <CAHXS41z0MFVKF10oS-emL-LsGHQsQp=V_F6XAZiW8EOjhhzazg@mail.gmail.com>

and yes I can sleep well now. Thank you, Jim.

ne<-rep(0,ne)
total<-c(neggg,posss,ne)
hist(total)

Best,
Ani Jaya

On Tue, Sep 7, 2021 at 9:38 AM ani jaya <gaaauul at gmail.com> wrote:
>
> Hello Jim, thank you for your response. What I am trying to achieve is
> like this:
>
> #calculate the positive significant station for every row based on p-value
> df5<-df3
> df5[df4>0.05|df5<0]<-NA
>       #remove the insignificant one or negative statistic value
> df5[df5>0]<-1
>             #change the positive value to be +1 so I can row sum later
> pos<-as.data.frame(rowSums(df5, na.rm=T))                         #row
> sum to see the total significant station (column) for each row
> poss<-as.data.frame(table(pos))
>    #get the frequency of each significant number (row that have only
> 1,2,3,.. significant station)
> posss<-as.numeric(rep(poss$pos[-1],poss$Freq[-1]))-1          #create
> the series based on frequency
>
> #calculate the negative significant station for every row based on p-value
> df6<-df3
> df6[df4>0.05|df5>0]<-NA
> df6[df6<0]<-1
> neg<-as.data.frame(rowSums(df6, na.rm=T))
> negg<-as.data.frame(table(neg))
> neggg<-(as.numeric(rep(negg$neg[-1],negg$Freq[-1]))-1)*-1
>
> ne<-sum(pos==0&neg==0)
> #to see the 0 significant station, row that have no significant
> station
>
>
>
> after that I want to combine posss, neggg, and ne to be 1 column data
> frame but not success yet. After that, I want to plot the histogram to
> see the distribution of significant stations.
> Any lead is appreciate. Thank you
> Ani Jaya


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 12:37:41 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 10:37:41 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
Message-ID: <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

Thank you

I ran:

```{r}
rlang::last_error()
```

Here is the output:

<error/tibble_error_assign_incompatible_type>
Assigned data `single_study_df` must be compatible with existing data.
? Error occurred for column `third_ventricle_mn`.
x Can't convert from <double> to <logical> due to loss of precision.
* Locations: 1, 2.
Backtrace:
Run `rlang::last_trace()` to see the full context.




________________________________
From: Bill Dunlap <williamwdunlap at gmail.com>
Sent: Monday, September 6, 2021 5:36 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>
Cc: r-help at R-project.org <r-help at r-project.org>; McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

>  Run `rlang::last_error()` to see where the error occurred

What did rlang::last_error() show?

-Bill


On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk<mailto:John.Tully at nottingham.ac.uk>> wrote:
Dear colleagues
>
> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>
> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> This follows the commands
>
> for (region in regions){
>    for (study in unique(df$studyid)){
>      single_study_df <- df %>% filter(studyid==study)
>      if (is.na<http://is.na>(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na<http://is.na>(single_study_df[sprintf('%s_mn_l', region)])){
>        df <- calc_bilat(study, region, r, df)
>      }
>    }
> }
>
>
> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>
> I would greatly value your input on this matter
>
> Kind regards
>
> John Tully
>
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment.

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored
where permitted by law.





        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From nmw2000 @end|ng |rom hw@@c@uk  Tue Sep  7 13:00:21 2021
From: nmw2000 @end|ng |rom hw@@c@uk (Wray, Nicholas M)
Date: Tue, 7 Sep 2021 11:00:21 +0000
Subject: [R] SWATplusR package problems
Message-ID: <LO0P265MB3082361D120234F96AAC21BB8FD39@LO0P265MB3082.GBRP265.PROD.OUTLOOK.COM>

I am trying to get to grips with the SWAT+ hydrological model and with the package SWATplusR which is meant instantiate SWAT+ into R. I have going through the code supplied on this website https://github.com/chrisschuerz/SWATplusR/blob/master/vignettes/SWATplusR.Rmd

I can get so far, as shown beneath but then I get the error message also shown. I cannot see how to get any further


library(SWATdata)
library(SWATplusR)
demo_path<-"C:Documents"
demo_path
######
path_plus <- load_demo(dataset = "project",
                       version = "plus",
                       path = demo_path,
                       revision = 57)


q_obs <- load_demo(dataset = "observation")
q_obs
plot(q_obs, type = "l")####### Path to the subbasin shape file
sub_path <- load_demo(dataset = "subbasin", version = "plus")# Path to the subbasin shape file
riv_path <- load_demo(dataset = "river", version = "plus")
sub_path
riv_path
library(sf)
library(ggplot2)
sub <- read_sf(sub_path)
riv <- read_sf(riv_path)
ggplot() +
  geom_sf(data = sub) +
  geom_sf(data = riv, col = "royalblue", lwd = 0.75) +
  geom_sf_label(data = riv, aes(label = Channel)) +
  theme_bw()
q_sim_plus <- run_swatplus(project_path = path_plus,
                           output = define_output(file = "channel",
                                                  variable = "flo_out",
                                                  unit = 1))

The ggplot gives me a map but for the next line I get this error message:


Error: 'C:/swat_demo/swatplus_rev57_demo/time.sim' does not exist.

Where might this file be? I've tried searching for sources but cannot find anything. Thanks Nick Wray


________________________________

Founded in 1821, Heriot-Watt is a leader in ideas and solutions. With campuses and students across the entire globe we span the world, delivering innovation and educational excellence in business, engineering, design and the physical, social and life sciences. This email is generated from the Heriot-Watt University Group, which includes:

  1.  Heriot-Watt University, a Scottish charity registered under number SC000278
  2.  Heriot- Watt Services Limited (Oriam), Scotland's national performance centre for sport. Heriot-Watt Services Limited is a private limited company registered is Scotland with registered number SC271030 and registered office at Research & Enterprise Services Heriot-Watt University, Riccarton, Edinburgh, EH14 4AS.

The contents (including any attachments) are confidential. If you are not the intended recipient of this e-mail, any disclosure, copying, distribution or use of its contents is strictly prohibited, and you should please notify the sender immediately and then delete it (including any attachments) from your system.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep  7 14:51:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 7 Sep 2021 08:51:12 -0400
Subject: [R] SWATplusR package problems
In-Reply-To: <LO0P265MB3082361D120234F96AAC21BB8FD39@LO0P265MB3082.GBRP265.PROD.OUTLOOK.COM>
References: <LO0P265MB3082361D120234F96AAC21BB8FD39@LO0P265MB3082.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <582e3bc7-72b1-e7e3-38bf-36b7d73b93a9@gmail.com>

On 07/09/2021 7:00 a.m., Wray, Nicholas M via R-help wrote:
> I am trying to get to grips with the SWAT+ hydrological model and with the package SWATplusR which is meant instantiate SWAT+ into R. I have going through the code supplied on this website https://github.com/chrisschuerz/SWATplusR/blob/master/vignettes/SWATplusR.Rmd
> 

I think you'll need to raise this as an "Issue" on that Github site; 
it's not really something we're likely to be able to help with (and is 
formally off-topic here, being a contributed package).

Duncan Murdoch

> I can get so far, as shown beneath but then I get the error message also shown. I cannot see how to get any further
> 
> 
> library(SWATdata)
> library(SWATplusR)
> demo_path<-"C:Documents"
> demo_path
> ######
> path_plus <- load_demo(dataset = "project",
>                         version = "plus",
>                         path = demo_path,
>                         revision = 57)
> 
> 
> q_obs <- load_demo(dataset = "observation")
> q_obs
> plot(q_obs, type = "l")####### Path to the subbasin shape file
> sub_path <- load_demo(dataset = "subbasin", version = "plus")# Path to the subbasin shape file
> riv_path <- load_demo(dataset = "river", version = "plus")
> sub_path
> riv_path
> library(sf)
> library(ggplot2)
> sub <- read_sf(sub_path)
> riv <- read_sf(riv_path)
> ggplot() +
>    geom_sf(data = sub) +
>    geom_sf(data = riv, col = "royalblue", lwd = 0.75) +
>    geom_sf_label(data = riv, aes(label = Channel)) +
>    theme_bw()
> q_sim_plus <- run_swatplus(project_path = path_plus,
>                             output = define_output(file = "channel",
>                                                    variable = "flo_out",
>                                                    unit = 1))
> 
> The ggplot gives me a map but for the next line I get this error message:
> 
> 
> Error: 'C:/swat_demo/swatplus_rev57_demo/time.sim' does not exist.
> 
> Where might this file be? I've tried searching for sources but cannot find anything. Thanks Nick Wray
> 
> 
> ________________________________
> 
> Founded in 1821, Heriot-Watt is a leader in ideas and solutions. With campuses and students across the entire globe we span the world, delivering innovation and educational excellence in business, engineering, design and the physical, social and life sciences. This email is generated from the Heriot-Watt University Group, which includes:
> 
>    1.  Heriot-Watt University, a Scottish charity registered under number SC000278
>    2.  Heriot- Watt Services Limited (Oriam), Scotland's national performance centre for sport. Heriot-Watt Services Limited is a private limited company registered is Scotland with registered number SC271030 and registered office at Research & Enterprise Services Heriot-Watt University, Riccarton, Edinburgh, EH14 4AS.
> 
> The contents (including any attachments) are confidential. If you are not the intended recipient of this e-mail, any disclosure, copying, distribution or use of its contents is strictly prohibited, and you should please notify the sender immediately and then delete it (including any attachments) from your system.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Sep  7 15:27:55 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 7 Sep 2021 09:27:55 -0400
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
 <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
 <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <380f96fa-8b35-c2da-4f0e-efe0e39f7a6b@gmail.com>

And what is in the string that triggers the issue?

On 07/09/2021 9:23 a.m., John Tully wrote:
> Thank you Duncan
> 
> we now resolved this
> 
> However I have run into another problem with the section of script 
> below- I am getting in reply
> 
> Error in nchar(a) : invalid multibyte string, element 1
> 
> Thanks
> 
> 
> 
> 
> SCRIPT SECTION:
> 
> **
> 
> **
> 
> # fill data frame with meta results
> j=1
> for (indiv_meta in to_include){
>  ? graph_results$estimate[j]=results_list[[indiv_meta]]$b
>  ? graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
>  ? graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
>  ? graph_results$p[j]=results_list[[indiv_meta]]$pval
>  ? a <- as.character(results_list[[indiv_meta]]$slab)
>  ? #this reduces the 'k' printed on the graph for instancews where 
> sibsamples counted as sepearte studies
>  ? b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
>  ? num_dups = sum(b==".")/2
>  ? graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
>  ? j=j+1
> }
> 
> 
> 
> 
> ------------------------------------------------------------------------
> *From:* Duncan Murdoch <murdoch.duncan at gmail.com>
> *Sent:* Monday, September 6, 2021 5:49 PM
> *To:* John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org 
> <r-help at R-project.org>
> *Cc:* McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
> *Subject:* Re: [R] 'Double to logical' error
> You get this error from this kind of operation on tibbles:
> 
> library(tibble)
> t1 <- tibble(x = c(TRUE, FALSE))
> t2 <- tibble(x = c(1.2, 1.3))
> t1[1,] <- t2[1,]
> #> Error: Assigned data `t2[1, ]` must be compatible with existing data.
> #> ? Error occurred for column `x`.
> #> x Can't convert from <double> to <logical> due to loss of precision.
> #> * Locations: 1.
> 
> If t1 had been a data.frame instead of a tibble, this would convert t1$x
> to type double.? So it is possible some code you are using assumes
> things inheriting from class "data.frame" act like dataframes.? Or maybe
> they were just sloppy.? In any case, you might be able to fix it by
> changing single_study_df to a dataframe using
> 
>  ?? single_study_df <- as.data.frame(single_study_df)
> 
> Duncan Murdoch
> 
> 
> On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
>> On 06/09/2021 10:16 a.m., John Tully wrote:
>>> Dear colleagues
>>>>
>>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>>
>>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the  error occurred.
>> 
>> That certainly looks like a tidyverse error, specifically from the
>> tibble package.
>> 
>> Duncan Murdoch
>> 
>>>>
>>>> This follows the commands
>>>>
>>>> for (region in regions){
>>>>????? for (study in unique(df$studyid)){
>>>>??????? single_study_df <- df %>% filter(studyid==study)
>>>>??????? if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>>????????? df <- calc_bilat(study, region, r, df)
>>>>??????? }
>>>>????? }
>>>> }
>>>>
>>>>
>>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>>
>>>> I would greatly value your input on this matter
>>>>
>>>> Kind regards
>>>>
>>>> John Tully
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>
>>> This message and any attachment are intended solely for the addressee
>>> and may contain confidential information. If you have received this
>>> message in error, please contact the sender and delete the email and
>>> attachment.
>>>
>>> Any views or opinions expressed by the author of this email do not
>>> necessarily reflect the views of the University of Nottingham. Email
>>> communications with the University of Nottingham may be monitored
>>> where permitted by law.
>>>
>>>
>>>
>>>
>>>
>>>?????? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help 
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
> <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> 
> 
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
> 
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
> 
> 
>


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Sep  7 17:06:03 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 7 Sep 2021 08:06:03 -0700
Subject: [R] 'Double to logical' error
In-Reply-To: <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
 <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
Message-ID: <CAHqSRuRLH0a_ibiZ1YUN-qRbM5oTePDFaVVpp-s_YefDfUd_kQ@mail.gmail.com>

Thanks.  If you can still reproduce the problem, what did
    rlang::last_trace()
report?

-Bill

On Tue, Sep 7, 2021 at 3:37 AM John Tully <John.Tully at nottingham.ac.uk>
wrote:

> Thank you
>
> I ran:
>
> ```{r}
> rlang::last_error()
> ```
>
> Here is the output:
>
> <error/tibble_error_assign_incompatible_type>
> Assigned data `single_study_df` must be compatible with existing data.
> ? Error occurred for column `third_ventricle_mn`.
> x Can't convert from <double> to <logical> due to loss of precision.
> * Locations: 1, 2.
> Backtrace:
> Run `rlang::last_trace()` to see the full context.
>
>
>
>
> ------------------------------
> *From:* Bill Dunlap <williamwdunlap at gmail.com>
> *Sent:* Monday, September 6, 2021 5:36 PM
> *To:* John Tully <mszjt1 at exmail.nottingham.ac.uk>
> *Cc:* r-help at R-project.org <r-help at r-project.org>; McCutcheon, Robert <
> robert.mccutcheon at kcl.ac.uk>
> *Subject:* Re: [R] 'Double to logical' error
>
> >  Run `rlang::last_error()` to see where the error occurred
>
> What did rlang::last_error() show?
>
> -Bill
>
>
> On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk>
> wrote:
>
> Dear colleagues
> >
> > in conducting a meta-analysis (of MRI data) I am running into the
> repeated issue:
> >
> > Error: Assigned data `single_study_df` must be compatible with existing
> data. ? Error occurred for column `accumbens_sd`. x Can't convert from
> <double> to <logical> due to loss of precision. * Locations: 1, 2. Run
> `rlang::last_error()` to see where the error occurred.
> >
> > This follows the commands
> >
> > for (region in regions){
> >    for (study in unique(df$studyid)){
> >      single_study_df <- df %>% filter(studyid==study)
> >      if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l',
> region)])){
> >        df <- calc_bilat(study, region, r, df)
> >      }
> >    }
> > }
> >
> >
> > My colleague (cc'd) believed it may be an issue with tidyverse version,
> however using an older version (1.2.1), the issue persists. note
> 'accumbens' is the first of many columns so I suspect this is why it flags
> this up.
> >
> > I would greatly value your input on this matter
> >
> > Kind regards
> >
> > John Tully
> >
> >
> >
> >
>
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>
>
>

	[[alternative HTML version deleted]]


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 15:23:50 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 13:23:50 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
 <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
Message-ID: <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

Thank you Duncan

we now resolved this

However I have run into another problem with the section of script below- I am getting in reply

Error in nchar(a) : invalid multibyte string, element 1

Thanks




SCRIPT SECTION:


# fill data frame with meta results
j=1
for (indiv_meta in to_include){
  graph_results$estimate[j]=results_list[[indiv_meta]]$b
  graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
  graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
  graph_results$p[j]=results_list[[indiv_meta]]$pval
  a <- as.character(results_list[[indiv_meta]]$slab)
  #this reduces the 'k' printed on the graph for instancews where sibsamples counted as sepearte studies
  b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
  num_dups = sum(b==".")/2
  graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
  j=j+1
}




________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Monday, September 6, 2021 5:49 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org <r-help at R-project.org>
Cc: McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

You get this error from this kind of operation on tibbles:

library(tibble)
t1 <- tibble(x = c(TRUE, FALSE))
t2 <- tibble(x = c(1.2, 1.3))
t1[1,] <- t2[1,]
#> Error: Assigned data `t2[1, ]` must be compatible with existing data.
#> ? Error occurred for column `x`.
#> x Can't convert from <double> to <logical> due to loss of precision.
#> * Locations: 1.

If t1 had been a data.frame instead of a tibble, this would convert t1$x
to type double.  So it is possible some code you are using assumes
things inheriting from class "data.frame" act like dataframes.  Or maybe
they were just sloppy.  In any case, you might be able to fix it by
changing single_study_df to a dataframe using

   single_study_df <- as.data.frame(single_study_df)

Duncan Murdoch


On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
> On 06/09/2021 10:16 a.m., John Tully wrote:
>> Dear colleagues
>>>
>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>
>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> That certainly looks like a tidyverse error, specifically from the
> tibble package.
>
> Duncan Murdoch
>
>>>
>>> This follows the commands
>>>
>>> for (region in regions){
>>>      for (study in unique(df$studyid)){
>>>        single_study_df <- df %>% filter(studyid==study)
>>>        if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>          df <- calc_bilat(study, region, r, df)
>>>        }
>>>      }
>>> }
>>>
>>>
>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>
>>> I would greatly value your input on this matter
>>>
>>> Kind regards
>>>
>>> John Tully
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>> This message and any attachment are intended solely for the addressee
>> and may contain confidential information. If you have received this
>> message in error, please contact the sender and delete the email and
>> attachment.
>>
>> Any views or opinions expressed by the author of this email do not
>> necessarily reflect the views of the University of Nottingham. Email
>> communications with the University of Nottingham may be monitored
>> where permitted by law.
>>
>>
>>
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 16:01:29 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 14:01:29 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <380f96fa-8b35-c2da-4f0e-efe0e39f7a6b@gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <7fd99717-b3dc-747e-5819-7e21493f405b@gmail.com>
 <8e5dd1a0-2a21-63cb-eb20-25226aebe847@gmail.com>
 <AS8PR06MB76404B55C21D5E24CF55633392D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <380f96fa-8b35-c2da-4f0e-efe0e39f7a6b@gmail.com>
Message-ID: <AS8PR06MB76400A66C58E07BDE7C3DE1E92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

I?m afraid I don?t know this. I ran rlang to no avail. Any other suggestion?

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Duncan Murdoch <murdoch.duncan at gmail.com>
Sent: Tuesday, September 7, 2021 2:27:55 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org <r-help at R-project.org>
Cc: McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

And what is in the string that triggers the issue?

On 07/09/2021 9:23 a.m., John Tully wrote:
> Thank you Duncan
>
> we now resolved this
>
> However I have run into another problem with the section of script
> below- I am getting in reply
>
> Error in nchar(a) : invalid multibyte string, element 1
>
> Thanks
>
>
>
>
> SCRIPT SECTION:
>
> **
>
> **
>
> # fill data frame with meta results
> j=1
> for (indiv_meta in to_include){
>    graph_results$estimate[j]=results_list[[indiv_meta]]$b
>    graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
>    graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
>    graph_results$p[j]=results_list[[indiv_meta]]$pval
>    a <- as.character(results_list[[indiv_meta]]$slab)
>    #this reduces the 'k' printed on the graph for instancews where
> sibsamples counted as sepearte studies
>    b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
>    num_dups = sum(b==".")/2
>    graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
>    j=j+1
> }
>
>
>
>
> ------------------------------------------------------------------------
> *From:* Duncan Murdoch <murdoch.duncan at gmail.com>
> *Sent:* Monday, September 6, 2021 5:49 PM
> *To:* John Tully <mszjt1 at exmail.nottingham.ac.uk>; r-help at R-project.org
> <r-help at R-project.org>
> *Cc:* McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
> *Subject:* Re: [R] 'Double to logical' error
> You get this error from this kind of operation on tibbles:
>
> library(tibble)
> t1 <- tibble(x = c(TRUE, FALSE))
> t2 <- tibble(x = c(1.2, 1.3))
> t1[1,] <- t2[1,]
> #> Error: Assigned data `t2[1, ]` must be compatible with existing data.
> #> ? Error occurred for column `x`.
> #> x Can't convert from <double> to <logical> due to loss of precision.
> #> * Locations: 1.
>
> If t1 had been a data.frame instead of a tibble, this would convert t1$x
> to type double.  So it is possible some code you are using assumes
> things inheriting from class "data.frame" act like dataframes.  Or maybe
> they were just sloppy.  In any case, you might be able to fix it by
> changing single_study_df to a dataframe using
>
>     single_study_df <- as.data.frame(single_study_df)
>
> Duncan Murdoch
>
>
> On 06/09/2021 12:34 p.m., Duncan Murdoch wrote:
>> On 06/09/2021 10:16 a.m., John Tully wrote:
>>> Dear colleagues
>>>>
>>>> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>>>>
>>>> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the  error occurred.
>>
>> That certainly looks like a tidyverse error, specifically from the
>> tibble package.
>>
>> Duncan Murdoch
>>
>>>>
>>>> This follows the commands
>>>>
>>>> for (region in regions){
>>>>      for (study in unique(df$studyid)){
>>>>        single_study_df <- df %>% filter(studyid==study)
>>>>        if (is.na(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na(single_study_df[sprintf('%s_mn_l', region)])){
>>>>          df <- calc_bilat(study, region, r, df)
>>>>        }
>>>>      }
>>>> }
>>>>
>>>>
>>>> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>>>>
>>>> I would greatly value your input on this matter
>>>>
>>>> Kind regards
>>>>
>>>> John Tully
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>
>>> This message and any attachment are intended solely for the addressee
>>> and may contain confidential information. If you have received this
>>> message in error, please contact the sender and delete the email and
>>> attachment.
>>>
>>> Any views or opinions expressed by the author of this email do not
>>> necessarily reflect the views of the University of Nottingham. Email
>>> communications with the University of Nottingham may be monitored
>>> where permitted by law.
>>>
>>>
>>>
>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
> <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please contact the sender and delete the email and
> attachment.
>
> Any views or opinions expressed by the author of this email do not
> necessarily reflect the views of the University of Nottingham. Email
> communications with the University of Nottingham may be monitored
> where permitted by law.
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From John@Tu||y @end|ng |rom nott|ngh@m@@c@uk  Tue Sep  7 17:42:17 2021
From: John@Tu||y @end|ng |rom nott|ngh@m@@c@uk (John Tully)
Date: Tue, 7 Sep 2021 15:42:17 +0000
Subject: [R] 'Double to logical' error
In-Reply-To: <CAHqSRuRLH0a_ibiZ1YUN-qRbM5oTePDFaVVpp-s_YefDfUd_kQ@mail.gmail.com>
References: <AS8PR06MB76404C35CD531010D5265C7B92D29@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuR4tONhT9-vFm-wVSQBU-aimD001xG5BOyEMQr8F9U=qw@mail.gmail.com>
 <AS8PR06MB76408F9128B6863223D95E3B92D39@AS8PR06MB7640.eurprd06.prod.outlook.com>
 <CAHqSRuRLH0a_ibiZ1YUN-qRbM5oTePDFaVVpp-s_YefDfUd_kQ@mail.gmail.com>
Message-ID: <AS8PR06MB76403D1DE539F715ACA67D4992D39@AS8PR06MB7640.eurprd06.prod.outlook.com>

thanks

i get a red bar to the left of all of this

for (indiv_meta in to_include){
  graph_results$estimate[j]=results_list[[indiv_meta]]$b
  graph_results$lb[j]=results_list[[indiv_meta]]$ci.lb
  graph_results$ub[j]=results_list[[indiv_meta]]$ci.ub
  graph_results$p[j]=results_list[[indiv_meta]]$pval
  a <- as.character(results_list[[indiv_meta]]$slab)
  #this reduces the 'k' printed on the graph for instancews where sibsamples counted as sepearte studies
  b <- substr( a, start = nchar(a) - 1 , stop = nchar(a)-1)
  num_dups = sum(b==".")/2
  graph_results$k[j]=as.integer(results_list[[indiv_meta]]$k)-num_dups
  j=j+1
}






rlang last trace gives this

<error/tibble_error_assign_incompatible_type>
Assigned data `single_study_df` must be compatible with existing data.
? Error occurred for column `third_ventricle_mn`.
x Can't convert from <double> to <logical> due to loss of precision.
* Locations: 1, 2.
Backtrace:
     ?
  1. ??global::calc_bilat(study, region, r, df)
  2. ? ??base::`[<-`(...) aspd_funcs.r:11:2
  3. ? ??tibble:::`[<-.tbl_df`(...) aspd_funcs.r:11:2
  4. ?   ??tibble:::tbl_subassign(x, i, j, value, i_arg, j_arg, substitute(value))
  5. ?     ??tibble:::tbl_subassign_row(x, i, value, value_arg)
  6. ?       ??base::withCallingHandlers(...)
  7. ?       ??vctrs::`vec_slice<-`(`*tmp*`, i, value = value[[j]])
  8. ?         ??(function () ...
  9. ?           ??vctrs:::vec_cast.logical.double(...)
 10. ?             ??vctrs::maybe_lossy_cast(out, x, to, lossy, x_arg = x_arg, to_arg = to_arg)
 11. ?               ??base::withRestarts(...)
 12. ?               ? ??base:::withOneRestart(expr, restarts[[1L]])
 13. ?               ?   ??base:::doWithOneRestart(return(expr), restart)
 14. ?               ??vctrs:::stop_lossy_cast(...)
 15. ?                 ??vctrs:::stop_vctrs(...)
 16. ?                   ??rlang::abort(message, class = c(class, "vctrs_error"), ...)
 17. ?                     ??rlang:::signal_abort(cnd)
 18. ?                       ??base::signalCondition(cnd)
 19. ??(function (cnd) ...


?


________________________________
From: Bill Dunlap <williamwdunlap at gmail.com>
Sent: Tuesday, September 7, 2021 4:06 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk>
Cc: r-help at R-project.org <r-help at r-project.org>; McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk>
Subject: Re: [R] 'Double to logical' error

Thanks.  If you can still reproduce the problem, what did
    rlang::last_trace()
report?

-Bill

On Tue, Sep 7, 2021 at 3:37 AM John Tully <John.Tully at nottingham.ac.uk<mailto:John.Tully at nottingham.ac.uk>> wrote:
Thank you

I ran:

```{r}
rlang::last_error()
```

Here is the output:

<error/tibble_error_assign_incompatible_type>
Assigned data `single_study_df` must be compatible with existing data.
? Error occurred for column `third_ventricle_mn`.
x Can't convert from <double> to <logical> due to loss of precision.
* Locations: 1, 2.
Backtrace:
Run `rlang::last_trace()` to see the full context.




________________________________
From: Bill Dunlap <williamwdunlap at gmail.com<mailto:williamwdunlap at gmail.com>>
Sent: Monday, September 6, 2021 5:36 PM
To: John Tully <mszjt1 at exmail.nottingham.ac.uk<mailto:mszjt1 at exmail.nottingham.ac.uk>>
Cc: r-help at R-project.org <r-help at r-project.org<mailto:r-help at r-project.org>>; McCutcheon, Robert <robert.mccutcheon at kcl.ac.uk<mailto:robert.mccutcheon at kcl.ac.uk>>
Subject: Re: [R] 'Double to logical' error

>  Run `rlang::last_error()` to see where the error occurred

What did rlang::last_error() show?

-Bill


On Mon, Sep 6, 2021 at 9:19 AM John Tully <John.Tully at nottingham.ac.uk<mailto:John.Tully at nottingham.ac.uk>> wrote:
Dear colleagues
>
> in conducting a meta-analysis (of MRI data) I am running into the repeated issue:
>
> Error: Assigned data `single_study_df` must be compatible with existing data. ? Error occurred for column `accumbens_sd`. x Can't convert from <double> to <logical> due to loss of precision. * Locations: 1, 2. Run `rlang::last_error()` to see where the error occurred.
>
> This follows the commands
>
> for (region in regions){
>    for (study in unique(df$studyid)){
>      single_study_df <- df %>% filter(studyid==study)
>      if (is.na<http://is.na>(single_study_df[sprintf('%s_mn', region)][[1]]) & !is.na<http://is.na>(single_study_df[sprintf('%s_mn_l', region)])){
>        df <- calc_bilat(study, region, r, df)
>      }
>    }
> }
>
>
> My colleague (cc'd) believed it may be an issue with tidyverse version, however using an older version (1.2.1), the issue persists. note 'accumbens' is the first of many columns so I suspect this is why it flags this up.
>
> I would greatly value your input on this matter
>
> Kind regards
>
> John Tully
>
>
>
>




This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment.

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored
where permitted by law.





        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment.

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored
where permitted by law.







This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please contact the sender and delete the email and
attachment. 

Any views or opinions expressed by the author of this email do not
necessarily reflect the views of the University of Nottingham. Email
communications with the University of Nottingham may be monitored 
where permitted by law.





	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep  8 01:30:04 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 8 Sep 2021 09:30:04 +1000
Subject: [R] field significance test
In-Reply-To: <CAHXS41z0MFVKF10oS-emL-LsGHQsQp=V_F6XAZiW8EOjhhzazg@mail.gmail.com>
References: <CAHXS41xewf=m01MSh9DdYwwyL_iLJupADLJkedQRLwOqMJePPg@mail.gmail.com>
 <CA+8X3fVbxs=GAAsGKnM6RAAArJ9OL3vap4q-ZPZEUb9=58EDJA@mail.gmail.com>
 <CAHXS41w_5PM0mbgHTXMqG8SogX2a_MCyP0tbcZukNi7cV2FD6Q@mail.gmail.com>
 <CAHXS41z0MFVKF10oS-emL-LsGHQsQp=V_F6XAZiW8EOjhhzazg@mail.gmail.com>
Message-ID: <CA+8X3fWW2YOnw_1mJZy2zco7xVdvUkKynrTCexc6mw0TmAbRfg@mail.gmail.com>

HIi Ani,
 I think you are going to a lot of trouble to get a fairly simple result.

# matrix of logicals for positive stat values
possig<-df3 > 0 & df4 < 0.05
# now negative stat values
negsig<-df3 < 0 & df4 < 0.05
# very clunky plots of column counts
barplot(colSums(possig),
 names.arg=paste0("S",1:10),
 main="Positive significant")
barplot(colSums(negsig))
 names.arg=paste0("S",1:10),
 main="Negative significant")

You said something about displaying the values of the statistics. As
the positive and negative values are mutually exclusive, you may want
to do something like this:

allsig<-possig | negsig
allsig[!allsig]<-NA
plot(1:10,1:10,type="n",xlab="Station",ylab="Rep",
 main="Significant statistical values")
text(rep(1:10,each=10),rep(10:1,10),round(df3*allsig,2))

giving you a matrix-like plot of the stat values. You could also add
the p-values.

Jim

On Tue, Sep 7, 2021 at 10:51 AM ani jaya <gaaauul at gmail.com> wrote:
>
> and yes I can sleep well now. Thank you, Jim.
>
> ne<-rep(0,ne)
> total<-c(neggg,posss,ne)
> hist(total)
>
> Best,
> Ani Jaya
>
> On Tue, Sep 7, 2021 at 9:38 AM ani jaya <gaaauul at gmail.com> wrote:
> >
> > Hello Jim, thank you for your response. What I am trying to achieve is
> > like this:
> >
> > #calculate the positive significant station for every row based on p-value
> > df5<-df3
> > df5[df4>0.05|df5<0]<-NA
> >       #remove the insignificant one or negative statistic value
> > df5[df5>0]<-1
> >             #change the positive value to be +1 so I can row sum later
> > pos<-as.data.frame(rowSums(df5, na.rm=T))                         #row
> > sum to see the total significant station (column) for each row
> > poss<-as.data.frame(table(pos))
> >    #get the frequency of each significant number (row that have only
> > 1,2,3,.. significant station)
> > posss<-as.numeric(rep(poss$pos[-1],poss$Freq[-1]))-1          #create
> > the series based on frequency
> >
> > #calculate the negative significant station for every row based on p-value
> > df6<-df3
> > df6[df4>0.05|df5>0]<-NA
> > df6[df6<0]<-1
> > neg<-as.data.frame(rowSums(df6, na.rm=T))
> > negg<-as.data.frame(table(neg))
> > neggg<-(as.numeric(rep(negg$neg[-1],negg$Freq[-1]))-1)*-1
> >
> > ne<-sum(pos==0&neg==0)
> > #to see the 0 significant station, row that have no significant
> > station
> >
> >
> >
> > after that I want to combine posss, neggg, and ne to be 1 column data
> > frame but not success yet. After that, I want to plot the histogram to
> > see the distribution of significant stations.
> > Any lead is appreciate. Thank you
> > Ani Jaya


From j|n||68 @end|ng |rom gm@||@com  Wed Sep  8 06:46:58 2021
From: j|n||68 @end|ng |rom gm@||@com (Jin Li)
Date: Wed, 8 Sep 2021 14:46:58 +1000
Subject: [R] Spm package is updated and available on CRAN again
Message-ID: <CAGu_3ZK4v3=NZBhfErJUecoB_Nx11NjtkQ58TN_giJ7U0DWC=Q@mail.gmail.com>

Dear spm users and all,

I am glad to inform you that the spm package is available on CRAN again. It
is an updated version with a few bugs fixed. Please note that some
functions in the package are not only for spatial predictive modelling but
also for predictive modeling in general.

Please feel free to contact me if you have any questions regarding the spm
package.

Best regards,

-- 
Jin

	[[alternative HTML version deleted]]


From grjon|80 @end|ng |rom gm@||@com  Wed Sep  8 12:13:03 2021
From: grjon|80 @end|ng |rom gm@||@com (=?UTF-8?Q?Sigurj=C3=B3n_=C3=9Eorsteinsson?=)
Date: Wed, 8 Sep 2021 10:13:03 +0000
Subject: [R] R: Many package imports have issues related to 'pillar'
Message-ID: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>

Hi

I am looking for a solution to this problem
> library(geepack)
Error: package or namespace load failed for ?geepack?:
 .onLoad failed in loadNamespace() for 'pillar', details:
  call: readRDS(nsInfoFilePath)
  error: unknown input format

More information:
https://stackoverflow.com/questions/69073165/r-many-package-imports-have-issues-related-to-pillar

Thanks for helping
Sigurjon


From R@H@un@ch||d @end|ng |rom |k|@mpg@de  Wed Sep  8 16:52:08 2021
From: R@H@un@ch||d @end|ng |rom |k|@mpg@de (Dr. Robin Haunschild)
Date: Wed, 8 Sep 2021 16:52:08 +0200
Subject: [R] Interpretation of download counts of r packages using
 cranlogs::cran_downloads
Message-ID: <e2530d3a-f87e-6594-5c44-a20cdd1fd181@fkf.mpg.de>

Hi,

I looked at the download counts retrieved via the function
cran_downloads in the package cranlogs. According to the documentation,
download counts from the RStudio CRAN mirror are retrieved.

Are requests from other mirrors included, or can each download count be
interpreted as a download from a real user?


Best regards,

Robin
-- 
Dr. Robin Haunschild
Max Planck Institute for Solid State Research
Heisenbergstr. 1
D-70569 Stuttgart (Germany)
phone: +49 (0) 711-689-1285
fax:   +49 (0) 711-689-1292
email: R.Haunschild at fkf.mpg.de
http://www.fkf.mpg.de/ivs
Publons: https://publons.com/researcher/1421847/robin-haunschild/
GS: https://scholar.google.de/citations?user=kDfateQAAAAJ&hl=de&oi=ao


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  8 17:08:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 8 Sep 2021 11:08:12 -0400
Subject: [R] R: Many package imports have issues related to 'pillar'
In-Reply-To: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
References: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
Message-ID: <a6da4923-c8dc-d48d-133e-ebd48c921f16@gmail.com>

On 08/09/2021 6:13 a.m., Sigurj?n ?orsteinsson wrote:
> Hi
> 
> I am looking for a solution to this problem
>> library(geepack)
> Error: package or namespace load failed for ?geepack?:
>   .onLoad failed in loadNamespace() for 'pillar', details:
>    call: readRDS(nsInfoFilePath)
>    error: unknown input format
> 
> More information:
> https://stackoverflow.com/questions/69073165/r-many-package-imports-have-issues-related-to-pillar

What does "library(pillar)" show?

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Sep  8 17:09:45 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 8 Sep 2021 11:09:45 -0400
Subject: [R] Interpretation of download counts of r packages using
 cranlogs::cran_downloads
In-Reply-To: <e2530d3a-f87e-6594-5c44-a20cdd1fd181@fkf.mpg.de>
References: <e2530d3a-f87e-6594-5c44-a20cdd1fd181@fkf.mpg.de>
Message-ID: <d9e23bcc-52f9-1149-38ce-740783283715@gmail.com>

On 08/09/2021 10:52 a.m., Dr. Robin Haunschild wrote:
> Hi,
> 
> I looked at the download counts retrieved via the function
> cran_downloads in the package cranlogs. According to the documentation,
> download counts from the RStudio CRAN mirror are retrieved.
> 
> Are requests from other mirrors included, or can each download count be
> interpreted as a download from a real user?

I think the answer to both questions is "no".  RStudio doesn't know what 
happens on other mirrors, and lots of automatic tests would download 
from RStudio's mirrors.

Duncan Murdoch


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Sep  8 17:09:36 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 8 Sep 2021 08:09:36 -0700
Subject: [R] R: Many package imports have issues related to 'pillar'
In-Reply-To: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
References: <CAG-konykcgVq=KW9EAf0qyhtXg+y4+W=nstWgzpPoGyLmZ7r1g@mail.gmail.com>
Message-ID: <3d6a91a3-6c26-32e5-c9b4-778f14e08494@comcast.net>


On 9/8/21 3:13 AM, Sigurj?n ?orsteinsson wrote:
> Hi
>
> I am looking for a solution to this problem
>> library(geepack)
> Error: package or namespace load failed for ?geepack?:
>   .onLoad failed in loadNamespace() for 'pillar', details:
>    call: readRDS(nsInfoFilePath)
>    error: unknown input format
>
> More information:
> https://stackoverflow.com/questions/69073165/r-many-package-imports-have-issues-related-to-pillar


If you search on SO you find that the error typically lies in failing to 
properly update R package libraries when you upgrade to a new 
installation of R. So it may not have anything to to do with the pillar 
package specifically.? My understanding (not an expert understanding) is 
that this arises because the serialization protocol of rds files may 
differ from version to version.


https://stackoverflow.com/questions/6473831/readrdsfile-in-r

You might first follow the usual path of removing any .Rdata and 
.Rhistory files

Then an R console command to try might be:


update.packages(checkBuilt=TRUE, ask=FALSE) # may take a long time


-- 

David.

>
> Thanks for helping
> Sigurjon
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Adr|@n@Bowm@n @end|ng |rom g|@@gow@@c@uk  Wed Sep  8 12:15:45 2021
From: Adr|@n@Bowm@n @end|ng |rom g|@@gow@@c@uk (Adrian Bowman)
Date: Wed, 8 Sep 2021 10:15:45 +0000
Subject: [R] [R-pkgs] rpanel package update
Message-ID: <230AB4F1-4D98-4F1B-9E1D-7215A4267693@glasgow.ac.uk>


The rpanel package provides a set of tools to build simple GUI controls for R functions, using the tcltk R package and the Tcl/Tk system. Some ?cartoons? which use interaction and animation to communicate statistical concepts are also included.  There have been some difficulties in installing rpanel on some systems (notably Mac computers) due to the reference to a Tcl/Tk module known as BWidget.  This has now been resolved.  If BWidget is not available the rpanel package can still be installed but two facilities, namely the ?combobox? (R function rp.combo) and ?notebook? (R functions rp.notebook and rp.notebook.raise) are disabled.

Adrian Bowman

Prof. Adrian Bowman
BSc (Hons) Dip.Math.Stat PhD FRSE
Emeritus Professor of Statistics
University of Glasgow

E: adrian.bowman at glasgow.ac.uk<mailto:adrian.bowman at glasgow.ac.uk>
W: www.stats.gla.ac.uk/~adrian<http://www.stats.gla.ac.uk/~adrian>

School of Mathematics and Statistics
University of Glasgow
Glasgow G12 8QQ

The University of Glasgow, charity number SC004401



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From m@rio@corr@do m@iii@g oii cro@iii@@ce@com  Thu Sep  9 17:55:53 2021
From: m@rio@corr@do m@iii@g oii cro@iii@@ce@com (m@rio@corr@do m@iii@g oii cro@iii@@ce@com)
Date: Thu, 9 Sep 2021 17:55:53 +0200
Subject: [R] Windows installation failed testing
Message-ID: <00e001d7a593$2c785c60$85691520$@croalliance.com>

Dear all

Our IT has installed R on a Windows PC following the manual instruction.
The installation was validated as in manual ?3.3. "Testing an installation", by using the commands

Sys.setenv(LC_COLLATE = "C", LANGUAGE = "en")
library("tools")
testInstalledBasic("both")
testInstalledPackages(scope = "base", errorsAreFatal = FALSE)
testInstalledPackages(scope = "recommended", errorsAreFatal = FALSE)

All tests passed with the exception of this:

Testing examples for package 'utils'
Running specific tests for package 'utils'
  Running 'charclass.R'
  Running 'completion.R'
  Running 'download.file.R'
  Running 'Sweave-tst.R'
Warning: testing 'utils' failed

What can we do to track the reason of the failure?
Is this expected?
Any hint?

Thanks

Mario


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Sep  9 19:13:15 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 9 Sep 2021 13:13:15 -0400
Subject: [R] Windows installation failed testing
In-Reply-To: <00e001d7a593$2c785c60$85691520$@croalliance.com>
References: <00e001d7a593$2c785c60$85691520$@croalliance.com>
Message-ID: <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>

On 09/09/2021 11:55 a.m., mario.corrado at croalliance.com wrote:
> Dear all
> 
> Our IT has installed R on a Windows PC following the manual instruction.
> The installation was validated as in manual ?3.3. "Testing an installation", by using the commands
> 
> Sys.setenv(LC_COLLATE = "C", LANGUAGE = "en")
> library("tools")
> testInstalledBasic("both")
> testInstalledPackages(scope = "base", errorsAreFatal = FALSE)
> testInstalledPackages(scope = "recommended", errorsAreFatal = FALSE)
> 
> All tests passed with the exception of this:
> 
> Testing examples for package 'utils'
> Running specific tests for package 'utils'
>    Running 'charclass.R'
>    Running 'completion.R'
>    Running 'download.file.R'
>    Running 'Sweave-tst.R'
> Warning: testing 'utils' failed
> 
> What can we do to track the reason of the failure?

The current working directory is the default output directory.  You will 
see a directory produced there containing the results of the tests. 
Look in it for filenames like "*.fail".

I just ran the tests just for utils, and it failed on the Sweave test, 
because it couldn't find pdflatex.  If that's the only failure you get, 
don't worry about it, just make sure that pdflatex can be found on the 
PATH when you actually need it.

Duncan Murdoch


From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Sep  9 21:00:15 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 9 Sep 2021 19:00:15 +0000 (UTC)
Subject: [R] how to find "first" or "last" record after sort in R
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
Message-ID: <1763582423.2148373.1631214015039@mail.yahoo.com>

Hello List,
Please look at the sample data frame below:

ID? ? ? ? ?date1? ? ? ? ? ? ? date2? ? ? ? ? ? ?date3
1? ? 2015-10-08? ? 2015-12-17? ? 2015-07-23

2? ? 2016-01-16? ? NA? ? ? ? ? ? ? ? ?2015-10-08
3? ? 2016-08-01? ? NA? ? ? ? ? ? ? ? ?2017-01-10
3? ? 2017-01-10? ? NA? ? ? ? ? ? ? ? ?2016-01-16
4? ? 2016-01-19? ? 2016-02-24? ?2016-08-01
5? ? 2016-03-01? ? 2016-03-10? ?2016-01-19
This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5?has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.

the question is, how can I identify the "last" record and set it as NA in date3 column.
Thank you,
Kai
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  9 21:20:56 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Sep 2021 12:20:56 -0700
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <1763582423.2148373.1631214015039@mail.yahoo.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
Message-ID: <CAGxFJbSbFaSgzf8iV9ZS_KWXATCw1-ZZBs0YepSOhvCWQ2uGjQ@mail.gmail.com>

Many ways to do this, of course, but if I understand correctly ?rle
may be the simplest, because you already have the data sorted by ID.

The following little example should give you the idea. It gets the
index of the last row in each id,, which you can then use to assign
NA's or whatever:

> id <- c(1,2,2,2,3,4,5,5)
> last.index <- cumsum(rle(test)$lengths)
> last.index
[1] 1 4 5 6 8

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 9, 2021 at 12:00 PM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
> Hello List,
> Please look at the sample data frame below:
>
> ID         date1              date2             date3
> 1    2015-10-08    2015-12-17    2015-07-23
>
> 2    2016-01-16    NA                 2015-10-08
> 3    2016-08-01    NA                 2017-01-10
> 3    2017-01-10    NA                 2016-01-16
> 4    2016-01-19    2016-02-24   2016-08-01
> 5    2016-03-01    2016-03-10   2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
>
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  9 21:35:12 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 9 Sep 2021 12:35:12 -0700
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <CAGxFJbSbFaSgzf8iV9ZS_KWXATCw1-ZZBs0YepSOhvCWQ2uGjQ@mail.gmail.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
 <CAGxFJbSbFaSgzf8iV9ZS_KWXATCw1-ZZBs0YepSOhvCWQ2uGjQ@mail.gmail.com>
Message-ID: <CAGxFJbQaDpqeLva7cVvfO2q1PxFbr23Wtx_0AhaGkz9Lr6A59A@mail.gmail.com>

Sorry, that should be

> id <- c(1,2,2,2,3,4,5,5)
> last.index <- cumsum(rle(id)$lengths)
> last.index
[1] 1 4 5 6 8

of course.

Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Sep 9, 2021 at 12:20 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Many ways to do this, of course, but if I understand correctly ?rle
> may be the simplest, because you already have the data sorted by ID.
>
> The following little example should give you the idea. It gets the
> index of the last row in each id,, which you can then use to assign
> NA's or whatever:
>
> > id <- c(1,2,2,2,3,4,5,5)
> > last.index <- cumsum(rle(test)$lengths)
> > last.index
> [1] 1 4 5 6 8
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Thu, Sep 9, 2021 at 12:00 PM Kai Yang via R-help
> <r-help at r-project.org> wrote:
> >
> > Hello List,
> > Please look at the sample data frame below:
> >
> > ID         date1              date2             date3
> > 1    2015-10-08    2015-12-17    2015-07-23
> >
> > 2    2016-01-16    NA                 2015-10-08
> > 3    2016-08-01    NA                 2017-01-10
> > 3    2017-01-10    NA                 2016-01-16
> > 4    2016-01-19    2016-02-24   2016-08-01
> > 5    2016-03-01    2016-03-10   2016-01-19
> > This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
> >
> > the question is, how can I identify the "last" record and set it as NA in date3 column.
> > Thank you,
> > Kai
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Sep  9 21:43:21 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 9 Sep 2021 15:43:21 -0400
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <1763582423.2148373.1631214015039@mail.yahoo.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
Message-ID: <00b501d7a5b2$f25a87e0$d70f97a0$@verizon.net>

I am sure there are many good ways to do the task including taking the data.frame out into a list of data.frames and making the change to each by taking the nth row that matches nrow(it) and changing it and then recombining.

What follows are several attempts leading up to one at the end I find is probably the best choice.

I did the following sample demo using the dplyr package in the tidyverse but want to explain. My data was three small groups of 1 then 2 then 3. The second column in each had the same number as the group and it was unique for that group. If the last item can be a duplicate of another item, this method changes too much:

library(dplyr)

mydf <-
  tribble(
    ~grouper, ~val,
    1, 1,
    2, 1,
    2, 2,
    3, 1,
    3, 2,
    3, 3,
  )

mydf %>% group_by(grouper) %>% mutate(val2 = last(val), val=ifelse(val==val2,0,val))

The result is this:

> mydf %>% group_by(grouper) %>% mutate(val2 = last(val), val=ifelse(val==val2,0,val))
# A tibble: 6 x 3
# Groups:   grouper [3]
grouper   val  val2
<dbl> <dbl> <dbl>
  1       1     0     1
2       2     1     2
3       2     0     2
4       3     1     3
5       3     2     3
6       3     0     3

Now obviously this introduced an extra temporary row called val2, which is easily removed by many methods like piping to select(-val2) ...

But that is not needed as a shorter and more direct method is this:

mydf %>% 
  group_by(grouper) %>% 
  mutate(val = ifelse(val==last(val), 
                      0, 
                      val))

But some more research shows the helper functions that make this trivial.

Recall you wanted the last row in each group altered, I think to have an NA in column. I used 0 above but can use NA just as easily or any constant. The functions are:

n() gives the number of rows in the group.
row_number() gives the number of the current row as the functionality is being applied, within that group. The condition being offered is that n() == row_number() so this version surgically changes just the last rows no matter what other rows contain.

mydf %>% 
  group_by(grouper) %>% 
  mutate(val = ifelse(row_number() == n(), 
                      0, 
                      val))

If you have no interest in using a package like this, someone else will likely point you to a way. I suspect using something like split() to make a list of data.frames then applying some functionality to each smaller data.frame to get the result then recombining it back.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kai Yang via R-help
Sent: Thursday, September 9, 2021 3:00 PM
To: R-help Mailing List <r-help at r-project.org>
Subject: [R] how to find "first" or "last" record after sort in R

Hello List,
Please look at the sample data frame below:

ID         date1              date2             date3
1    2015-10-08    2015-12-17    2015-07-23

2    2016-01-16    NA                 2015-10-08
3    2016-08-01    NA                 2017-01-10
3    2017-01-10    NA                 2016-01-16
4    2016-01-19    2016-02-24   2016-08-01
5    2016-03-01    2016-03-10   2016-01-19 This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.

the question is, how can I identify the "last" record and set it as NA in date3 column.
Thank you,
Kai
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From therne@u @end|ng |rom m@yo@edu  Fri Sep 10 14:13:45 2021
From: therne@u @end|ng |rom m@yo@edu (Therneau, Terry M., Ph.D.)
Date: Fri, 10 Sep 2021 07:13:45 -0500
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
References: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
Message-ID: <6315bd$gjsu9b@ironport10.mayo.edu>

I prefer the duplicated() function, since the final code will be clear to a future reader. 
  (Particularly when I am that future reader).

last <- !duplicated(mydata$ID, fromLast=TRUE)  # point to the last ID for each subject
mydata$data3[last] <- NA

Terry T.

(I read the list once a day in digest form, so am always a late reply.)

On 9/10/21 5:00 AM, r-help-request at r-project.org wrote:
> Hello List,
> Please look at the sample data frame below:
> 
> ID? ? ? ? ?date1? ? ? ? ? ? ? date2? ? ? ? ? ? ?date3
> 1? ? 2015-10-08? ? 2015-12-17? ? 2015-07-23
> 
> 2? ? 2016-01-16? ? NA? ? ? ? ? ? ? ? ?2015-10-08
> 3? ? 2016-08-01? ? NA? ? ? ? ? ? ? ? ?2017-01-10
> 3? ? 2017-01-10? ? NA? ? ? ? ? ? ? ? ?2016-01-16
> 4? ? 2016-01-19? ? 2016-02-24? ?2016-08-01
> 5? ? 2016-03-01? ? 2016-03-10? ?2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5?has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
> 
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
> 	[[alternative HTML version deleted]]
>


From m@rio@corr@do m@iii@g oii cro@iii@@ce@com  Fri Sep 10 15:51:29 2021
From: m@rio@corr@do m@iii@g oii cro@iii@@ce@com (m@rio@corr@do m@iii@g oii cro@iii@@ce@com)
Date: Fri, 10 Sep 2021 15:51:29 +0200
Subject: [R] Windows installation failed testing
In-Reply-To: <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>
References: <00e001d7a593$2c785c60$85691520$@croalliance.com>
 <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>
Message-ID: <020c01d7a64a$f62883c0$e2798b40$@croalliance.com>

Thanks

Unfortunately we checked the PATH and is correctly set
Any other suggestion?
Other Windows users experiment the same problem?
Mario

-----Original Message-----
[cut]

The current working directory is the default output directory.  You will see a directory produced there containing the results of the tests. 
Look in it for filenames like "*.fail".

I just ran the tests just for utils, and it failed on the Sweave test, because it couldn't find pdflatex.  If that's the only failure you get, don't worry about it, just make sure that pdflatex can be found on the PATH when you actually need it.

Duncan Murdoch


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Sep 10 16:43:18 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 10 Sep 2021 16:43:18 +0200
Subject: [R] Handling interrupts in long-running R functions
Message-ID: <20210910164318.65b75378@trisector>

Hello everyone,

I'm writing an R function that may be running for "long" periods of
time (think tens of minutes), and I would like to be able to tell it:
"please stop what you're doing and return the not-yet converged results
as they are for inspection".

The behaviour I'm striving for is

1) User presses interrupt
2) Function handles the interrupt and returns as if the convergence
   test passed
3) By some black magic, the interrupt condition is raised on the
   previous function call level (to avoid the situation where my
   function is called in a loop by some other function and the user
   wants to interrupt the whole process, not just my function).

Is this a good idea? Is (3) even possible? (I guess I could check the
length of sys.parents() and avoid recovering from the interrupt if
called from some other function, but that feels dirty.) Could something
similar be achieved with options(error = recover) and R restarts? Are
there other ways of, well, interrupting the execution of R functions
without changing the semantics of interrupts in R?

I've been working with MATLAB lately (when in Rome, do as Romans
do...), and their idiom for my desired behaviour is "create a plot
window and return when that window is closed", but that doesn't
translate well to R.

-- 
Best regards,
Ivan


From iuke-tier@ey m@iii@g oii uiow@@edu  Fri Sep 10 17:02:27 2021
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Fri, 10 Sep 2021 10:02:27 -0500 (CDT)
Subject: [R] [External]  Handling interrupts in long-running R functions
In-Reply-To: <20210910164318.65b75378@trisector>
References: <20210910164318.65b75378@trisector>
Message-ID: <alpine.DEB.2.22.394.2109100957200.2943@luke-Latitude-7480>

Some variation of this might do it:

     tryCatch(for (i in seq_len(1000000)) Sys.sleep(1),
              interrupt = function(e) i)

If you want the option to inspect and continue you would need to use
withCallingHandlers and invoke a 'resume' restart.

Best,

luke

On Fri, 10 Sep 2021, Ivan Krylov wrote:

> Hello everyone,
>
> I'm writing an R function that may be running for "long" periods of
> time (think tens of minutes), and I would like to be able to tell it:
> "please stop what you're doing and return the not-yet converged results
> as they are for inspection".
>
> The behaviour I'm striving for is
>
> 1) User presses interrupt
> 2) Function handles the interrupt and returns as if the convergence
>   test passed
> 3) By some black magic, the interrupt condition is raised on the
>   previous function call level (to avoid the situation where my
>   function is called in a loop by some other function and the user
>   wants to interrupt the whole process, not just my function).
>
> Is this a good idea? Is (3) even possible? (I guess I could check the
> length of sys.parents() and avoid recovering from the interrupt if
> called from some other function, but that feels dirty.) Could something
> similar be achieved with options(error = recover) and R restarts? Are
> there other ways of, well, interrupting the execution of R functions
> without changing the semantics of interrupts in R?
>
> I've been working with MATLAB lately (when in Rome, do as Romans
> do...), and their idiom for my desired behaviour is "create a plot
> window and return when that window is closed", but that doesn't
> translate well to R.
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From y@ngk@|9999 @end|ng |rom y@hoo@com  Fri Sep 10 17:51:39 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 10 Sep 2021 15:51:39 +0000 (UTC)
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <6315bd$gjsu9c@ironport10.mayo.edu>
References: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
 <6315bd$gjsu9c@ironport10.mayo.edu>
Message-ID: <1140284697.2617467.1631289099919@mail.yahoo.com>

 Thanks Therneau,?duplicated() function works well. --- Kai
    On Friday, September 10, 2021, 05:13:47 AM PDT, Therneau, Terry M., Ph.D. <therneau at mayo.edu> wrote:  
 
 I prefer the duplicated() function, since the final code will be clear to a future reader. 
? (Particularly when I am that future reader).

last <- !duplicated(mydata$ID, fromLast=TRUE)? # point to the last ID for each subject
mydata$data3[last] <- NA

Terry T.

(I read the list once a day in digest form, so am always a late reply.)

On 9/10/21 5:00 AM, r-help-request at r-project.org wrote:
> Hello List,
> Please look at the sample data frame below:
> 
> ID? ? ? ? ?date1? ? ? ? ? ? ? date2? ? ? ? ? ? ?date3
> 1? ? 2015-10-08? ? 2015-12-17? ? 2015-07-23
> 
> 2? ? 2016-01-16? ? NA? ? ? ? ? ? ? ? ?2015-10-08
> 3? ? 2016-08-01? ? NA? ? ? ? ? ? ? ? ?2017-01-10
> 3? ? 2017-01-10? ? NA? ? ? ? ? ? ? ? ?2016-01-16
> 4? ? 2016-01-19? ? 2016-02-24? ?2016-08-01
> 5? ? 2016-03-01? ? 2016-03-10? ?2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5?has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
> 
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
> ??? [[alternative HTML version deleted]]
> 
  
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Sep 10 18:12:47 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 10 Sep 2021 12:12:47 -0400
Subject: [R] Windows installation failed testing
In-Reply-To: <020c01d7a64a$f62883c0$e2798b40$@croalliance.com>
References: <00e001d7a593$2c785c60$85691520$@croalliance.com>
 <09c447e1-c084-f2f2-df2e-daa0f9abe317@gmail.com>
 <020c01d7a64a$f62883c0$e2798b40$@croalliance.com>
Message-ID: <446a33b9-da95-8dfb-1f81-ae4978c75fec@gmail.com>

On 10/09/2021 9:51 a.m., mario.corrado at croalliance.com wrote:
> Thanks
> 
> Unfortunately we checked the PATH and is correctly set
> Any other suggestion?
> Other Windows users experiment the same problem?

What error did you see in the output dir?

Duncan Murdoch

> Mario
> 
> -----Original Message-----
> [cut]
> 
> The current working directory is the default output directory.  You will see a directory produced there containing the results of the tests.
> Look in it for filenames like "*.fail".
> 
> I just ran the tests just for utils, and it failed on the Sweave test, because it couldn't find pdflatex.  If that's the only failure you get, don't worry about it, just make sure that pdflatex can be found on the PATH when you actually need it.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @v|gro@@ @end|ng |rom ver|zon@net  Fri Sep 10 20:45:32 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Fri, 10 Sep 2021 14:45:32 -0400
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <6315bd$gjsu9b@ironport10.mayo.edu>
References: <mailman.364180.1.1631268001.4139.r-help@r-project.org>
 <6315bd$gjsu9b@ironport10.mayo.edu>
Message-ID: <009f01d7a674$093340d0$1b99c270$@verizon.net>

Excellent function to use, Terry.

 

I note when I used it on a vector (in this case the  first column of a data.frame, it accepted last=TRUE as well a fromlast=TRUE, which I did not see documented. Used on a data.frame, that change fails as function duplicated.data.frame only passes along the fromlast keyword value. ?

 

When given a problem, we sometimes use a hammer when existing functions are already there to help.

 

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Therneau, Terry M., Ph.D. via R-help
Sent: Friday, September 10, 2021 8:14 AM
To: yangkai9999 at yahoo.com; R-help <r-help at R-project.org>
Subject: Re: [R] how to find "first" or "last" record after sort in R

 

I prefer the duplicated() function, since the final code will be clear to a future reader. 

  (Particularly when I am that future reader).

 

last <- !duplicated(mydata$ID, fromLast=TRUE)  # point to the last ID for each subject mydata$data3[last] <- NA

 

Terry T.

 

(I read the list once a day in digest form, so am always a late reply.)

 

On 9/10/21 5:00 AM,  <mailto:r-help-request at r-project.org> r-help-request at r-project.org wrote:

> Hello List,

> Please look at the sample data frame below:

> 

> ID         date1              date2             date3

> 1    2015-10-08    2015-12-17    2015-07-23

> 

> 2    2016-01-16    NA                 2015-10-08

> 3    2016-08-01    NA                 2017-01-10

> 3    2017-01-10    NA                 2016-01-16

> 4    2016-01-19    2016-02-24   2016-08-01

> 5    2016-03-01    2016-03-10   2016-01-19 This data frame was sorted 

> by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.

> 

> the question is, how can I identify the "last" record and set it as NA in date3 column.

> Thank you,

> Kai

>             [[alternative HTML version deleted]]

> 

 

______________________________________________

 <mailto:R-help at r-project.org> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  <https://stat.ethz.ch/mailman/listinfo/r-help> https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide  <http://www.R-project.org/posting-guide.html> http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sat Sep 11 03:20:28 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 11 Sep 2021 13:20:28 +1200
Subject: [R] how to find "first" or "last" record after sort in R
In-Reply-To: <1763582423.2148373.1631214015039@mail.yahoo.com>
References: <1763582423.2148373.1631214015039.ref@mail.yahoo.com>
 <1763582423.2148373.1631214015039@mail.yahoo.com>
Message-ID: <CABcYAd+5CXee0fB4r6VFuHd9WLTY2sL5H4-0YchP5O_-AtQuFw@mail.gmail.com>

Let's simplify this to consider a single vector, such as
x <- c(1,1,1,2,2,3,3,3,3,4,5,5,5)
in which equal elements are in contiguous blocks.
> diff(x)
 [1] 0 0 1 0 1 0 0 0 1 1 0 0
Of course, there could be gaps, or the sequence might be descending
instead of ascending.  So
> diff(x) != 0
We are nearly there, but there is a problem.
The last element of the vector is always the last element of a group,
but it will never be reported, because there is no following element
to compare it with.  So
> c(diff(x) != 0, TRUE)
That gives us a logical vector which we can use in indexing.
> w <- c(diff(x) != 0, TRUE)
> x[w] <- NA
> x
 [1]  1  1 NA  2 NA  3  3  3 NA NA  5  5 NA

On Fri, 10 Sept 2021 at 07:00, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> Please look at the sample data frame below:
>
> ID         date1              date2             date3
> 1    2015-10-08    2015-12-17    2015-07-23
>
> 2    2016-01-16    NA                 2015-10-08
> 3    2016-08-01    NA                 2017-01-10
> 3    2017-01-10    NA                 2016-01-16
> 4    2016-01-19    2016-02-24   2016-08-01
> 5    2016-03-01    2016-03-10   2016-01-19
> This data frame was sorted by ID and date1. I need to set the column date3 as missing for the "last" record for each ID. In the sample data set, the ID 1, 2, 4 and 5 has one row only, so they can be consider as first and last records. the data3 can be set as missing. But the ID 3 has 2 rows. Since I sorted the data by ID and date1, the ID=3 and date1=2017-01-10 should be the last record only. I need to set date3=NA for this row only.
>
> the question is, how can I identify the "last" record and set it as NA in date3 column.
> Thank you,
> Kai
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |eo@m@d@ @end|ng |rom @yon|c@eu  Sun Sep 12 16:33:25 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Sun, 12 Sep 2021 17:33:25 +0300
Subject: [R] Evaluating lazily 'f<-' ?
Message-ID: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>

How can I avoid evaluation?

right = function(x, val) {print("Right");};
padding = function(x) {print("Padding");};
df = data.frame(x=1:5, y = sample(1:5, 5));

### OK
'%=%' = function(x, val) {
 ??? x = substitute(x);
}
right(padding(df)) %=% 1; # but ugly

### Does NOT work
'right<-' = function(x, val) {
 ??? print("Already evaluated and also does not use 'val'");
 ??? x = substitute(x); # is evaluated before
}

right(padding(df)) = 1


Sincerely,


Leonard


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 13 15:11:01 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Sep 2021 09:11:01 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
Message-ID: <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>

On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
> How can I avoid evaluation?
> 
> right = function(x, val) {print("Right");};
> padding = function(x) {print("Padding");};
> df = data.frame(x=1:5, y = sample(1:5, 5));
> 
> ### OK
> '%=%' = function(x, val) {
>   ??? x = substitute(x);
> }
> right(padding(df)) %=% 1; # but ugly
> 
> ### Does NOT work
> 'right<-' = function(x, val) {
>   ??? print("Already evaluated and also does not use 'val'");
>   ??? x = substitute(x); # is evaluated before
> }
> 
> right(padding(df)) = 1

That doesn't make sense.  You don't have a `padding<-` function, and yet 
you are trying to call right<- to assign something to padding(df).

I'm not sure about your real intention, but assignment functions by 
their nature need to evaluate the thing they are assigning to, since 
they are designed to modify objects, not create new ones.

To create a new object, just use regular assignment.

Duncan Murdoch


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 15:38:00 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 16:38:00 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
Message-ID: <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>

Hello,


I can include code for "padding<-"as well, but the error is before that, 
namely in 'right<-':

right = function(x, val) {print("Right");};
# more options:
padding = function(x, right, left, top, bottom) {print("Padding");};
'padding<-' = function(x, ...) {print("Padding = ");};
df = data.frame(x=1:5, y = sample(1:5, 5));


### Does NOT work
'right<-' = function(x, val) {
 ? ??? print("Already evaluated and also does not use 'val'");
 ? ??? x = substitute(x); # x was evaluated before
}

right(padding(df)) = 1;


I want to capture the assignment event inside "right<-" and then call 
the function padding() properly.

I haven't thought yet if I should use:

padding(x, right, left, ... other parameters);

or

padding(x, parameter) <- value;


It also depends if I can properly capture the unevaluated expression 
inside "right<-":

'right<-' = function(x, val) {

# x is automatically evaluated when using 'f<-'!

# but not when implementing as '%f%' = function(x, y);

}


Many thanks,


Leonard


On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>> How can I avoid evaluation?
>>
>> right = function(x, val) {print("Right");};
>> padding = function(x) {print("Padding");};
>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>
>> ### OK
>> '%=%' = function(x, val) {
>> ? ??? x = substitute(x);
>> }
>> right(padding(df)) %=% 1; # but ugly
>>
>> ### Does NOT work
>> 'right<-' = function(x, val) {
>> ? ??? print("Already evaluated and also does not use 'val'");
>> ? ??? x = substitute(x); # is evaluated before
>> }
>>
>> right(padding(df)) = 1
>
> That doesn't make sense.? You don't have a `padding<-` function, and 
> yet you are trying to call right<- to assign something to padding(df).
>
> I'm not sure about your real intention, but assignment functions by 
> their nature need to evaluate the thing they are assigning to, since 
> they are designed to modify objects, not create new ones.
>
> To create a new object, just use regular assignment.
>
> Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 13 15:45:12 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Sep 2021 09:45:12 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
Message-ID: <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>

On 13/09/2021 9:38 a.m., Leonard Mada wrote:
> Hello,
> 
> 
> I can include code for "padding<-"as well, but the error is before that,
> namely in 'right<-':
> 
> right = function(x, val) {print("Right");};
> # more options:
> padding = function(x, right, left, top, bottom) {print("Padding");};
> 'padding<-' = function(x, ...) {print("Padding = ");};
> df = data.frame(x=1:5, y = sample(1:5, 5));
> 
> 
> ### Does NOT work
> 'right<-' = function(x, val) {
>   ? ??? print("Already evaluated and also does not use 'val'");
>   ? ??? x = substitute(x); # x was evaluated before
> }
> 
> right(padding(df)) = 1;

It "works" (i.e. doesn't generate an error) for me, when I correct your 
typo:  the second argument to `right<-` should be `value`, not `val`.

I'm still not clear whether it does what you want with that fix, because 
I don't really understand what you want.

Duncan Murdoch

> 
> 
> I want to capture the assignment event inside "right<-" and then call
> the function padding() properly.
> 
> I haven't thought yet if I should use:
> 
> padding(x, right, left, ... other parameters);
> 
> or
> 
> padding(x, parameter) <- value;
> 
> 
> It also depends if I can properly capture the unevaluated expression
> inside "right<-":
> 
> 'right<-' = function(x, val) {
> 
> # x is automatically evaluated when using 'f<-'!
> 
> # but not when implementing as '%f%' = function(x, y);
> 
> }
> 
> 
> Many thanks,
> 
> 
> Leonard
> 
> 
> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>> How can I avoid evaluation?
>>>
>>> right = function(x, val) {print("Right");};
>>> padding = function(x) {print("Padding");};
>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>
>>> ### OK
>>> '%=%' = function(x, val) {
>>>  ? ??? x = substitute(x);
>>> }
>>> right(padding(df)) %=% 1; # but ugly
>>>
>>> ### Does NOT work
>>> 'right<-' = function(x, val) {
>>>  ? ??? print("Already evaluated and also does not use 'val'");
>>>  ? ??? x = substitute(x); # is evaluated before
>>> }
>>>
>>> right(padding(df)) = 1
>>
>> That doesn't make sense.? You don't have a `padding<-` function, and
>> yet you are trying to call right<- to assign something to padding(df).
>>
>> I'm not sure about your real intention, but assignment functions by
>> their nature need to evaluate the thing they are assigning to, since
>> they are designed to modify objects, not create new ones.
>>
>> To create a new object, just use regular assignment.
>>
>> Duncan Murdoch


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 17:28:09 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 18:28:09 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
Message-ID: <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>

I try to clarify the code:


###
right = function(x, val) {print("Right");};
padding = function(x, right, left, top, bottom) {print("Padding");};
'padding<-' = function(x, ...) {print("Padding = ");};
df = data.frame(x=1:5, y = sample(1:5, 5)); # anything

### Does NOT work as expected
'right<-' = function(x, value) {
 ??? print("This line should be the first printed!")
 ??? print("But ERROR: x was already evaluated, which printed \"Padding\"");
 ??? x = substitute(x); # x was already evaluated before substitute();
 ??? return("Nothing"); # do not now what the behaviour should be?
}

right(padding(df)) = 1;

### Output:

[1] "Padding"
[1] "This line should be the first printed!"
[1] "But ERROR: x was already evaluated, which printed \"Padding\""
[1] "Padding = " # How did this happen ???


### Problems:

1.) substitute(x): did not capture the expression;
- the first parameter of 'right<-' was already evaluated, which is not 
the case with '%f%';
Can I avoid evaluating this parameter?
How can I avoid to evaluate it and capture the expression: "right(...)"?


2.) Unexpected
'padding<-' was also called!
I did not know this. Is it feature or bug?
R 4.0.4


Sincerely,


Leonard


On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
> On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>> Hello,
>>
>>
>> I can include code for "padding<-"as well, but the error is before that,
>> namely in 'right<-':
>>
>> right = function(x, val) {print("Right");};
>> # more options:
>> padding = function(x, right, left, top, bottom) {print("Padding");};
>> 'padding<-' = function(x, ...) {print("Padding = ");};
>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>
>>
>> ### Does NOT work
>> 'right<-' = function(x, val) {
>> ? ? ??? print("Already evaluated and also does not use 'val'");
>> ? ? ??? x = substitute(x); # x was evaluated before
>> }
>>
>> right(padding(df)) = 1;
>
> It "works" (i.e. doesn't generate an error) for me, when I correct 
> your typo:? the second argument to `right<-` should be `value`, not 
> `val`.
>
> I'm still not clear whether it does what you want with that fix, 
> because I don't really understand what you want.
>
> Duncan Murdoch
>
>>
>>
>> I want to capture the assignment event inside "right<-" and then call
>> the function padding() properly.
>>
>> I haven't thought yet if I should use:
>>
>> padding(x, right, left, ... other parameters);
>>
>> or
>>
>> padding(x, parameter) <- value;
>>
>>
>> It also depends if I can properly capture the unevaluated expression
>> inside "right<-":
>>
>> 'right<-' = function(x, val) {
>>
>> # x is automatically evaluated when using 'f<-'!
>>
>> # but not when implementing as '%f%' = function(x, y);
>>
>> }
>>
>>
>> Many thanks,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>>> How can I avoid evaluation?
>>>>
>>>> right = function(x, val) {print("Right");};
>>>> padding = function(x) {print("Padding");};
>>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>
>>>> ### OK
>>>> '%=%' = function(x, val) {
>>>> ?? ??? x = substitute(x);
>>>> }
>>>> right(padding(df)) %=% 1; # but ugly
>>>>
>>>> ### Does NOT work
>>>> 'right<-' = function(x, val) {
>>>> ?? ??? print("Already evaluated and also does not use 'val'");
>>>> ?? ??? x = substitute(x); # is evaluated before
>>>> }
>>>>
>>>> right(padding(df)) = 1
>>>
>>> That doesn't make sense.? You don't have a `padding<-` function, and
>>> yet you are trying to call right<- to assign something to padding(df).
>>>
>>> I'm not sure about your real intention, but assignment functions by
>>> their nature need to evaluate the thing they are assigning to, since
>>> they are designed to modify objects, not create new ones.
>>>
>>> To create a new object, just use regular assignment.
>>>
>>> Duncan Murdoch
>


From @kw@|mmo @end|ng |rom gm@||@com  Mon Sep 13 17:45:54 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 13 Sep 2021 11:45:54 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
Message-ID: <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>

I think you're trying to do something like:

`padding<-` <- function (x, which, value)
{
    which <- match.arg(which, c("bottom", "left", "top", "right"),
several.ok = TRUE)
    # code to pad to each side here
}

Then you could use it like

df <- data.frame(x=1:5, y = sample(1:5, 5))
padding(df, "right") <- 1

Does that work as expected for you?

On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <r-help at r-project.org>
wrote:

> I try to clarify the code:
>
>
> ###
> right = function(x, val) {print("Right");};
> padding = function(x, right, left, top, bottom) {print("Padding");};
> 'padding<-' = function(x, ...) {print("Padding = ");};
> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>
> ### Does NOT work as expected
> 'right<-' = function(x, value) {
>      print("This line should be the first printed!")
>      print("But ERROR: x was already evaluated, which printed
> \"Padding\"");
>      x = substitute(x); # x was already evaluated before substitute();
>      return("Nothing"); # do not now what the behaviour should be?
> }
>
> right(padding(df)) = 1;
>
> ### Output:
>
> [1] "Padding"
> [1] "This line should be the first printed!"
> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
> [1] "Padding = " # How did this happen ???
>
>
> ### Problems:
>
> 1.) substitute(x): did not capture the expression;
> - the first parameter of 'right<-' was already evaluated, which is not
> the case with '%f%';
> Can I avoid evaluating this parameter?
> How can I avoid to evaluate it and capture the expression: "right(...)"?
>
>
> 2.) Unexpected
> 'padding<-' was also called!
> I did not know this. Is it feature or bug?
> R 4.0.4
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
> >> Hello,
> >>
> >>
> >> I can include code for "padding<-"as well, but the error is before that,
> >> namely in 'right<-':
> >>
> >> right = function(x, val) {print("Right");};
> >> # more options:
> >> padding = function(x, right, left, top, bottom) {print("Padding");};
> >> 'padding<-' = function(x, ...) {print("Padding = ");};
> >> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>
> >>
> >> ### Does NOT work
> >> 'right<-' = function(x, val) {
> >>         print("Already evaluated and also does not use 'val'");
> >>         x = substitute(x); # x was evaluated before
> >> }
> >>
> >> right(padding(df)) = 1;
> >
> > It "works" (i.e. doesn't generate an error) for me, when I correct
> > your typo:  the second argument to `right<-` should be `value`, not
> > `val`.
> >
> > I'm still not clear whether it does what you want with that fix,
> > because I don't really understand what you want.
> >
> > Duncan Murdoch
> >
> >>
> >>
> >> I want to capture the assignment event inside "right<-" and then call
> >> the function padding() properly.
> >>
> >> I haven't thought yet if I should use:
> >>
> >> padding(x, right, left, ... other parameters);
> >>
> >> or
> >>
> >> padding(x, parameter) <- value;
> >>
> >>
> >> It also depends if I can properly capture the unevaluated expression
> >> inside "right<-":
> >>
> >> 'right<-' = function(x, val) {
> >>
> >> # x is automatically evaluated when using 'f<-'!
> >>
> >> # but not when implementing as '%f%' = function(x, y);
> >>
> >> }
> >>
> >>
> >> Many thanks,
> >>
> >>
> >> Leonard
> >>
> >>
> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
> >>>> How can I avoid evaluation?
> >>>>
> >>>> right = function(x, val) {print("Right");};
> >>>> padding = function(x) {print("Padding");};
> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>>>
> >>>> ### OK
> >>>> '%=%' = function(x, val) {
> >>>>        x = substitute(x);
> >>>> }
> >>>> right(padding(df)) %=% 1; # but ugly
> >>>>
> >>>> ### Does NOT work
> >>>> 'right<-' = function(x, val) {
> >>>>        print("Already evaluated and also does not use 'val'");
> >>>>        x = substitute(x); # is evaluated before
> >>>> }
> >>>>
> >>>> right(padding(df)) = 1
> >>>
> >>> That doesn't make sense.  You don't have a `padding<-` function, and
> >>> yet you are trying to call right<- to assign something to padding(df).
> >>>
> >>> I'm not sure about your real intention, but assignment functions by
> >>> their nature need to evaluate the thing they are assigning to, since
> >>> they are designed to modify objects, not create new ones.
> >>>
> >>> To create a new object, just use regular assignment.
> >>>
> >>> Duncan Murdoch
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 18:17:18 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 19:17:18 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
Message-ID: <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>

Hello Andrew,


this could work. I will think about it.


But I was thinking more generically. Suppose we have a series of functions:
padding(), border(), some_other_style();
Each of these functions has the parameter "right" (or the group of 
parameters c("right", ...)).


Then I could design a function right(FUN) that assigns the value to this 
parameter and evaluates the function FUN().


There are a few ways to do this:

1.) Other parameters as ...
right(FUN, value, ...) = value; and then pass "..." to FUN.
right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)

2.) Another way:
right(FUN(...other parameters already specified...)) = value;
I wanted to explore this 2nd option: but avoid evaluating FUN, unless 
the parameter "right" is injected into the call.

3.) Option 3:
The option you mentioned.


Independent of the method: there are still weird/unexplained behaviours 
when I try the initial code (see the latest mail with the improved code).


Sincerely,


Leonard


On 9/13/2021 6:45 PM, Andrew Simmons wrote:
> I think you're trying to do something like:
>
> `padding<-` <- function (x, which, value)
> {
> ? ? which <- match.arg(which, c("bottom", "left", "top", "right"), 
> several.ok = TRUE)
> ? ? # code to pad to each side here
> }
>
> Then you could use it like
>
> df <- data.frame(x=1:5, y = sample(1:5, 5))
> padding(df, "right") <- 1
>
> Does that work as expected for you?
>
> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>     I try to clarify the code:
>
>
>     ###
>     right = function(x, val) {print("Right");};
>     padding = function(x, right, left, top, bottom) {print("Padding");};
>     'padding<-' = function(x, ...) {print("Padding = ");};
>     df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>
>     ### Does NOT work as expected
>     'right<-' = function(x, value) {
>     ???? print("This line should be the first printed!")
>     ???? print("But ERROR: x was already evaluated, which printed
>     \"Padding\"");
>     ???? x = substitute(x); # x was already evaluated before substitute();
>     ???? return("Nothing"); # do not now what the behaviour should be?
>     }
>
>     right(padding(df)) = 1;
>
>     ### Output:
>
>     [1] "Padding"
>     [1] "This line should be the first printed!"
>     [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>     [1] "Padding = " # How did this happen ???
>
>
>     ### Problems:
>
>     1.) substitute(x): did not capture the expression;
>     - the first parameter of 'right<-' was already evaluated, which is
>     not
>     the case with '%f%';
>     Can I avoid evaluating this parameter?
>     How can I avoid to evaluate it and capture the expression:
>     "right(...)"?
>
>
>     2.) Unexpected
>     'padding<-' was also called!
>     I did not know this. Is it feature or bug?
>     R 4.0.4
>
>
>     Sincerely,
>
>
>     Leonard
>
>
>     On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>     > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>     >> Hello,
>     >>
>     >>
>     >> I can include code for "padding<-"as well, but the error is
>     before that,
>     >> namely in 'right<-':
>     >>
>     >> right = function(x, val) {print("Right");};
>     >> # more options:
>     >> padding = function(x, right, left, top, bottom)
>     {print("Padding");};
>     >> 'padding<-' = function(x, ...) {print("Padding = ");};
>     >> df = data.frame(x=1:5, y = sample(1:5, 5));
>     >>
>     >>
>     >> ### Does NOT work
>     >> 'right<-' = function(x, val) {
>     >> ? ? ??? print("Already evaluated and also does not use 'val'");
>     >> ? ? ??? x = substitute(x); # x was evaluated before
>     >> }
>     >>
>     >> right(padding(df)) = 1;
>     >
>     > It "works" (i.e. doesn't generate an error) for me, when I correct
>     > your typo:? the second argument to `right<-` should be `value`, not
>     > `val`.
>     >
>     > I'm still not clear whether it does what you want with that fix,
>     > because I don't really understand what you want.
>     >
>     > Duncan Murdoch
>     >
>     >>
>     >>
>     >> I want to capture the assignment event inside "right<-" and
>     then call
>     >> the function padding() properly.
>     >>
>     >> I haven't thought yet if I should use:
>     >>
>     >> padding(x, right, left, ... other parameters);
>     >>
>     >> or
>     >>
>     >> padding(x, parameter) <- value;
>     >>
>     >>
>     >> It also depends if I can properly capture the unevaluated
>     expression
>     >> inside "right<-":
>     >>
>     >> 'right<-' = function(x, val) {
>     >>
>     >> # x is automatically evaluated when using 'f<-'!
>     >>
>     >> # but not when implementing as '%f%' = function(x, y);
>     >>
>     >> }
>     >>
>     >>
>     >> Many thanks,
>     >>
>     >>
>     >> Leonard
>     >>
>     >>
>     >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>     >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>     >>>> How can I avoid evaluation?
>     >>>>
>     >>>> right = function(x, val) {print("Right");};
>     >>>> padding = function(x) {print("Padding");};
>     >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>     >>>>
>     >>>> ### OK
>     >>>> '%=%' = function(x, val) {
>     >>>> ?? ??? x = substitute(x);
>     >>>> }
>     >>>> right(padding(df)) %=% 1; # but ugly
>     >>>>
>     >>>> ### Does NOT work
>     >>>> 'right<-' = function(x, val) {
>     >>>> ?? ??? print("Already evaluated and also does not use 'val'");
>     >>>> ?? ??? x = substitute(x); # is evaluated before
>     >>>> }
>     >>>>
>     >>>> right(padding(df)) = 1
>     >>>
>     >>> That doesn't make sense.? You don't have a `padding<-`
>     function, and
>     >>> yet you are trying to call right<- to assign something to
>     padding(df).
>     >>>
>     >>> I'm not sure about your real intention, but assignment
>     functions by
>     >>> their nature need to evaluate the thing they are assigning to,
>     since
>     >>> they are designed to modify objects, not create new ones.
>     >>>
>     >>> To create a new object, just use regular assignment.
>     >>>
>     >>> Duncan Murdoch
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Mon Sep 13 20:15:17 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 13 Sep 2021 14:15:17 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
Message-ID: <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>

R's parser doesn't work the way you're expecting it to. When doing an
assignment like:


padding(right(df)) <- 1


it is broken into small stages. The guide "R Language Definition" claims
that the above would be equivalent to:


`<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))


but that is not correct, and you can tell by using `substitute` as you were
above. There isn't a way to do what you want with the syntax you provided,
you'll have to do something different. You could add a `which` argument to
each style function, and maybe put the code for `match.arg` in a separate
function:


match.which <- function (which)
match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)


padding <- function (x, which)
{
    which <- match.which(which)
    # more code
}


border <- function (x, which)
{
    which <- match.which(which)
    # more code
}


some_other_style <- function (x, which)
{
    which <- match.which(which)
    # more code
}


I hope this helps.

On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu> wrote:

> Hello Andrew,
>
>
> this could work. I will think about it.
>
> But I was thinking more generically. Suppose we have a series of functions:
> padding(), border(), some_other_style();
> Each of these functions has the parameter "right" (or the group of
> parameters c("right", ...)).
>
>
> Then I could design a function right(FUN) that assigns the value to this
> parameter and evaluates the function FUN().
>
>
> There are a few ways to do this:
> 1.) Other parameters as ...
> right(FUN, value, ...) = value; and then pass "..." to FUN.
> right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)
>
> 2.) Another way:
> right(FUN(...other parameters already specified...)) = value;
> I wanted to explore this 2nd option: but avoid evaluating FUN, unless the
> parameter "right" is injected into the call.
>
> 3.) Option 3:
> The option you mentioned.
>
>
> Independent of the method: there are still weird/unexplained behaviours
> when I try the initial code (see the latest mail with the improved code).
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>
> I think you're trying to do something like:
>
> `padding<-` <- function (x, which, value)
> {
>     which <- match.arg(which, c("bottom", "left", "top", "right"),
> several.ok = TRUE)
>     # code to pad to each side here
> }
>
> Then you could use it like
>
> df <- data.frame(x=1:5, y = sample(1:5, 5))
> padding(df, "right") <- 1
>
> Does that work as expected for you?
>
> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <r-help at r-project.org>
> wrote:
>
>> I try to clarify the code:
>>
>>
>> ###
>> right = function(x, val) {print("Right");};
>> padding = function(x, right, left, top, bottom) {print("Padding");};
>> 'padding<-' = function(x, ...) {print("Padding = ");};
>> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>
>> ### Does NOT work as expected
>> 'right<-' = function(x, value) {
>>      print("This line should be the first printed!")
>>      print("But ERROR: x was already evaluated, which printed
>> \"Padding\"");
>>      x = substitute(x); # x was already evaluated before substitute();
>>      return("Nothing"); # do not now what the behaviour should be?
>> }
>>
>> right(padding(df)) = 1;
>>
>> ### Output:
>>
>> [1] "Padding"
>> [1] "This line should be the first printed!"
>> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>> [1] "Padding = " # How did this happen ???
>>
>>
>> ### Problems:
>>
>> 1.) substitute(x): did not capture the expression;
>> - the first parameter of 'right<-' was already evaluated, which is not
>> the case with '%f%';
>> Can I avoid evaluating this parameter?
>> How can I avoid to evaluate it and capture the expression: "right(...)"?
>>
>>
>> 2.) Unexpected
>> 'padding<-' was also called!
>> I did not know this. Is it feature or bug?
>> R 4.0.4
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>> >> Hello,
>> >>
>> >>
>> >> I can include code for "padding<-"as well, but the error is before
>> that,
>> >> namely in 'right<-':
>> >>
>> >> right = function(x, val) {print("Right");};
>> >> # more options:
>> >> padding = function(x, right, left, top, bottom) {print("Padding");};
>> >> 'padding<-' = function(x, ...) {print("Padding = ");};
>> >> df = data.frame(x=1:5, y = sample(1:5, 5));
>> >>
>> >>
>> >> ### Does NOT work
>> >> 'right<-' = function(x, val) {
>> >>         print("Already evaluated and also does not use 'val'");
>> >>         x = substitute(x); # x was evaluated before
>> >> }
>> >>
>> >> right(padding(df)) = 1;
>> >
>> > It "works" (i.e. doesn't generate an error) for me, when I correct
>> > your typo:  the second argument to `right<-` should be `value`, not
>> > `val`.
>> >
>> > I'm still not clear whether it does what you want with that fix,
>> > because I don't really understand what you want.
>> >
>> > Duncan Murdoch
>> >
>> >>
>> >>
>> >> I want to capture the assignment event inside "right<-" and then call
>> >> the function padding() properly.
>> >>
>> >> I haven't thought yet if I should use:
>> >>
>> >> padding(x, right, left, ... other parameters);
>> >>
>> >> or
>> >>
>> >> padding(x, parameter) <- value;
>> >>
>> >>
>> >> It also depends if I can properly capture the unevaluated expression
>> >> inside "right<-":
>> >>
>> >> 'right<-' = function(x, val) {
>> >>
>> >> # x is automatically evaluated when using 'f<-'!
>> >>
>> >> # but not when implementing as '%f%' = function(x, y);
>> >>
>> >> }
>> >>
>> >>
>> >> Many thanks,
>> >>
>> >>
>> >> Leonard
>> >>
>> >>
>> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>> >>>> How can I avoid evaluation?
>> >>>>
>> >>>> right = function(x, val) {print("Right");};
>> >>>> padding = function(x) {print("Padding");};
>> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>> >>>>
>> >>>> ### OK
>> >>>> '%=%' = function(x, val) {
>> >>>>        x = substitute(x);
>> >>>> }
>> >>>> right(padding(df)) %=% 1; # but ugly
>> >>>>
>> >>>> ### Does NOT work
>> >>>> 'right<-' = function(x, val) {
>> >>>>        print("Already evaluated and also does not use 'val'");
>> >>>>        x = substitute(x); # is evaluated before
>> >>>> }
>> >>>>
>> >>>> right(padding(df)) = 1
>> >>>
>> >>> That doesn't make sense.  You don't have a `padding<-` function, and
>> >>> yet you are trying to call right<- to assign something to padding(df).
>> >>>
>> >>> I'm not sure about your real intention, but assignment functions by
>> >>> their nature need to evaluate the thing they are assigning to, since
>> >>> they are designed to modify objects, not create new ones.
>> >>>
>> >>> To create a new object, just use regular assignment.
>> >>>
>> >>> Duncan Murdoch
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 20:42:56 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 21:42:56 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
Message-ID: <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>

Hello Andrew,


I try now to understand the evaluation of the expression:

e = expression(r(x) <- 1)

# parameter named "value" seems to be required;
'r<-' = function(x, value) {print("R");}
eval(e, list(x=2))
# [1] "R"

# both versions work
'r<-' = function(value, x) {print("R");}
eval(e, list(x=2))
# [1] "R"


### the Expression
e[[1]][[1]] # "<-", not "r<-"
e[[1]][[2]] # "r(x)"


The evaluation of "e" somehow calls "r<-", but evaluates also the 
argument of r(...). I am still investigating what is actually happening.


Sincerely,


Leonard


On 9/13/2021 9:15 PM, Andrew Simmons wrote:
> R's parser doesn't work the way you're expecting it to. When doing an 
> assignment like:
>
>
> padding(right(df)) <- 1
>
>
> it is broken into small stages. The guide "R Language Definition" 
> claims that the above would be equivalent to:
>
>
> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>
>
> but that is not correct, and you can tell by using `substitute` as you 
> were above. There isn't a way to do what you want with the syntax you 
> provided, you'll have to do something different. You could add a 
> `which` argument to each style function, and maybe put the code for 
> `match.arg` in a separate function:
>
>
> match.which <- function (which)
> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>
>
> padding <- function (x, which)
> {
> ? ? which <- match.which(which)
> ? ? # more code
> }
>
>
> border <- function (x, which)
> {
> ? ? which <- match.which(which)
> ? ? # more code
> }
>
>
> some_other_style <- function (x, which)
> {
> ? ? which <- match.which(which)
> ? ? # more code
> }
>
>
> I hope this helps.
>
> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Hello Andrew,
>
>
>     this could work. I will think about it.
>
>
>     But I was thinking more generically. Suppose we have a series of
>     functions:
>     padding(), border(), some_other_style();
>     Each of these functions has the parameter "right" (or the group of
>     parameters c("right", ...)).
>
>
>     Then I could design a function right(FUN) that assigns the value
>     to this parameter and evaluates the function FUN().
>
>
>     There are a few ways to do this:
>
>     1.) Other parameters as ...
>     right(FUN, value, ...) = value; and then pass "..." to FUN.
>     right(value, FUN, ...) = value; # or is this the syntax? (TODO:
>     explore)
>
>     2.) Another way:
>     right(FUN(...other parameters already specified...)) = value;
>     I wanted to explore this 2nd option: but avoid evaluating FUN,
>     unless the parameter "right" is injected into the call.
>
>     3.) Option 3:
>     The option you mentioned.
>
>
>     Independent of the method: there are still weird/unexplained
>     behaviours when I try the initial code (see the latest mail with
>     the improved code).
>
>
>     Sincerely,
>
>
>     Leonard
>
>
>     On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>     I think you're trying to do something like:
>>
>>     `padding<-` <- function (x, which, value)
>>     {
>>     ? ? which <- match.arg(which, c("bottom", "left", "top",
>>     "right"), several.ok = TRUE)
>>     ? ? # code to pad to each side here
>>     }
>>
>>     Then you could use it like
>>
>>     df <- data.frame(x=1:5, y = sample(1:5, 5))
>>     padding(df, "right") <- 1
>>
>>     Does that work as expected for you?
>>
>>     On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>
>>         I try to clarify the code:
>>
>>
>>         ###
>>         right = function(x, val) {print("Right");};
>>         padding = function(x, right, left, top, bottom)
>>         {print("Padding");};
>>         'padding<-' = function(x, ...) {print("Padding = ");};
>>         df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>
>>         ### Does NOT work as expected
>>         'right<-' = function(x, value) {
>>         ???? print("This line should be the first printed!")
>>         ???? print("But ERROR: x was already evaluated, which printed
>>         \"Padding\"");
>>         ???? x = substitute(x); # x was already evaluated before
>>         substitute();
>>         ???? return("Nothing"); # do not now what the behaviour
>>         should be?
>>         }
>>
>>         right(padding(df)) = 1;
>>
>>         ### Output:
>>
>>         [1] "Padding"
>>         [1] "This line should be the first printed!"
>>         [1] "But ERROR: x was already evaluated, which printed
>>         \"Padding\""
>>         [1] "Padding = " # How did this happen ???
>>
>>
>>         ### Problems:
>>
>>         1.) substitute(x): did not capture the expression;
>>         - the first parameter of 'right<-' was already evaluated,
>>         which is not
>>         the case with '%f%';
>>         Can I avoid evaluating this parameter?
>>         How can I avoid to evaluate it and capture the expression:
>>         "right(...)"?
>>
>>
>>         2.) Unexpected
>>         'padding<-' was also called!
>>         I did not know this. Is it feature or bug?
>>         R 4.0.4
>>
>>
>>         Sincerely,
>>
>>
>>         Leonard
>>
>>
>>         On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>         > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>         >> Hello,
>>         >>
>>         >>
>>         >> I can include code for "padding<-"as well, but the error
>>         is before that,
>>         >> namely in 'right<-':
>>         >>
>>         >> right = function(x, val) {print("Right");};
>>         >> # more options:
>>         >> padding = function(x, right, left, top, bottom)
>>         {print("Padding");};
>>         >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>         >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>         >>
>>         >>
>>         >> ### Does NOT work
>>         >> 'right<-' = function(x, val) {
>>         >> ? ? ??? print("Already evaluated and also does not use
>>         'val'");
>>         >> ? ? ??? x = substitute(x); # x was evaluated before
>>         >> }
>>         >>
>>         >> right(padding(df)) = 1;
>>         >
>>         > It "works" (i.e. doesn't generate an error) for me, when I
>>         correct
>>         > your typo:? the second argument to `right<-` should be
>>         `value`, not
>>         > `val`.
>>         >
>>         > I'm still not clear whether it does what you want with that
>>         fix,
>>         > because I don't really understand what you want.
>>         >
>>         > Duncan Murdoch
>>         >
>>         >>
>>         >>
>>         >> I want to capture the assignment event inside "right<-"
>>         and then call
>>         >> the function padding() properly.
>>         >>
>>         >> I haven't thought yet if I should use:
>>         >>
>>         >> padding(x, right, left, ... other parameters);
>>         >>
>>         >> or
>>         >>
>>         >> padding(x, parameter) <- value;
>>         >>
>>         >>
>>         >> It also depends if I can properly capture the unevaluated
>>         expression
>>         >> inside "right<-":
>>         >>
>>         >> 'right<-' = function(x, val) {
>>         >>
>>         >> # x is automatically evaluated when using 'f<-'!
>>         >>
>>         >> # but not when implementing as '%f%' = function(x, y);
>>         >>
>>         >> }
>>         >>
>>         >>
>>         >> Many thanks,
>>         >>
>>         >>
>>         >> Leonard
>>         >>
>>         >>
>>         >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>         >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>         >>>> How can I avoid evaluation?
>>         >>>>
>>         >>>> right = function(x, val) {print("Right");};
>>         >>>> padding = function(x) {print("Padding");};
>>         >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>         >>>>
>>         >>>> ### OK
>>         >>>> '%=%' = function(x, val) {
>>         >>>> ?? ??? x = substitute(x);
>>         >>>> }
>>         >>>> right(padding(df)) %=% 1; # but ugly
>>         >>>>
>>         >>>> ### Does NOT work
>>         >>>> 'right<-' = function(x, val) {
>>         >>>> ?? ??? print("Already evaluated and also does not use
>>         'val'");
>>         >>>> ?? ??? x = substitute(x); # is evaluated before
>>         >>>> }
>>         >>>>
>>         >>>> right(padding(df)) = 1
>>         >>>
>>         >>> That doesn't make sense.? You don't have a `padding<-`
>>         function, and
>>         >>> yet you are trying to call right<- to assign something to
>>         padding(df).
>>         >>>
>>         >>> I'm not sure about your real intention, but assignment
>>         functions by
>>         >>> their nature need to evaluate the thing they are
>>         assigning to, since
>>         >>> they are designed to modify objects, not create new ones.
>>         >>>
>>         >>> To create a new object, just use regular assignment.
>>         >>>
>>         >>> Duncan Murdoch
>>         >
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Sep 13 20:44:31 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 13 Sep 2021 18:44:31 +0000 (UTC)
Subject: [R] dbWriteTable does not append rows in database
References: <653155647.2729013.1631558671249.ref@mail.yahoo.com>
Message-ID: <653155647.2729013.1631558671249@mail.yahoo.com>

Hi List,
I want to append some rows from R into sql server. So, I submitted the code below. there is not any error message:
dbWriteTable(conn = con,?name = "PMDB._Alias_A", value = try1, overwrite=FALSE, append=TRUE, row.names = FALSE)
But when I try to query the data from the Sql server, I can not find the records were appended. Did I miss something in the code?
Thank you,
Kai

	[[alternative HTML version deleted]]


From ||809 @end|ng |rom nc|@c@  Mon Sep 13 15:33:26 2021
From: ||809 @end|ng |rom nc|@c@ (Brian Lunergan)
Date: Mon, 13 Sep 2021 09:33:26 -0400
Subject: [R] Error msg trying to load R Commander with an older R edition...
Message-ID: <32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>

Hi folks:

I'm running Linux Mint 19.3 on my machine. Tried to install a more
recent edition of R but I couldn't seem to get it working so I pulled it
off and went with a good, basic install of the edition available through
the software manager. So... I'm running version 3.4.4.

Mucking about with the attempt at a newer edition seems to have left
some excess baggage behind. When I loaded R Commander and attempted to
run it I received the following error message.

Error: package or namespace load failed for ?car? in readRDS(pfile):
 cannot read workspace version 3 written by R 3.6.2; need R 3.5.0 or newer
During startup - Warning message:
package ?Rcmdr? in options("defaultPackages") was not found

I get a similar message in Rkward when I try to load any more packages.

Is there any solution for this? Any "leftovers" I can track down and
delete? Any assistance would be greatly appreciated.

Kind regards...
-- 
Brian Lunergan
Pavillon Marionville
Russell, Ontario
Canada




-------------- next part --------------
A non-text attachment was scrubbed...
Name: OpenPGP_signature
Type: application/pgp-signature
Size: 665 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210913/e4afd0f5/attachment.sig>

From @d@m@wy@ok|n@k| @end|ng |rom e@em@||  Mon Sep 13 15:40:11 2021
From: @d@m@wy@ok|n@k| @end|ng |rom e@em@|| (=?UTF-8?Q?Adam_Wysoki=c5=84ski?=)
Date: Mon, 13 Sep 2021 15:40:11 +0200
Subject: [R] ggsave() with width only
In-Reply-To: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
References: <22aa6abd-6fe0-f968-2283-8dccd96777ac@rgzm.de>
Message-ID: <a6477734-fefa-9cba-b7c1-b214858edd83@e.email>

Hi,
Instead of ggsave(), use save_plot() from the "cowplot" package:

library(ggplot2)
library(cowplot)
x <- 1:10
y <- x^2
df <- data.frame(x, y)
p <- ggplot(df, aes(x, y)) + geom_point()
save_plot("/tmp/plot.png", p, base_aspect_ratio = 1, base_width = 5, 
base_height = NULL)

-- 
Regards,
Adam Wysoki?ski

On 9/6/21 16:03, Ivan Calandra wrote:
> Dear useRs,
> 
> I produce several independent ggplot2 plots and I would like to save 
> them to a fixed width (for publications), but the height (and therefore 
> aspect ratio) is different from plot to plot.
> 
> How can I save my plots with ggsave() supplying only a fixed width but 
> without knowing the height nor the aspect ratio? If I specify the width 
> only, the plots are truncated in width because the aspect ratio is not 
> correct.
> 
> Thank you for the tip!
> Ivan
>


From bgunter@4567 @end|ng |rom gm@||@com  Mon Sep 13 22:09:47 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Sep 2021 13:09:47 -0700
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
Message-ID: <CAGxFJbTxVKVQ7zPsY0J-qnLYAHD4V1NRnKJYbasMc3i2p6csOQ@mail.gmail.com>

e = expression(r(x) <- 1)

lapply(e, as.list)
[[1]]
[[1]][[1]]
`<-`

[[1]][[2]]
r(x)

[[1]][[3]]
[1] 1
#######################

lapply(e[[1]], as.list)
[[1]]
[[1]][[1]]
`<-`


[[2]]
[[2]][[1]]
r

[[2]][[2]]
x


[[3]]
[[3]][[1]]
[1] 1

However, I would urge you not to go down this rabbit hole unless you
are comfortable with recursion and have good reason to compute on the
language.

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 13, 2021 at 11:43 AM Leonard Mada via R-help
<r-help at r-project.org> wrote:
>
> Hello Andrew,
>
>
> I try now to understand the evaluation of the expression:
>
> e = expression(r(x) <- 1)
>
> # parameter named "value" seems to be required;
> 'r<-' = function(x, value) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
> # both versions work
> 'r<-' = function(value, x) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
>
> ### the Expression
> e[[1]][[1]] # "<-", not "r<-"
> e[[1]][[2]] # "r(x)"
>
>
> The evaluation of "e" somehow calls "r<-", but evaluates also the
> argument of r(...). I am still investigating what is actually happening.
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
> > R's parser doesn't work the way you're expecting it to. When doing an
> > assignment like:
> >
> >
> > padding(right(df)) <- 1
> >
> >
> > it is broken into small stages. The guide "R Language Definition"
> > claims that the above would be equivalent to:
> >
> >
> > `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
> >
> >
> > but that is not correct, and you can tell by using `substitute` as you
> > were above. There isn't a way to do what you want with the syntax you
> > provided, you'll have to do something different. You could add a
> > `which` argument to each style function, and maybe put the code for
> > `match.arg` in a separate function:
> >
> >
> > match.which <- function (which)
> > match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
> >
> >
> > padding <- function (x, which)
> > {
> >     which <- match.which(which)
> >     # more code
> > }
> >
> >
> > border <- function (x, which)
> > {
> >     which <- match.which(which)
> >     # more code
> > }
> >
> >
> > some_other_style <- function (x, which)
> > {
> >     which <- match.which(which)
> >     # more code
> > }
> >
> >
> > I hope this helps.
> >
> > On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu
> > <mailto:leo.mada at syonic.eu>> wrote:
> >
> >     Hello Andrew,
> >
> >
> >     this could work. I will think about it.
> >
> >
> >     But I was thinking more generically. Suppose we have a series of
> >     functions:
> >     padding(), border(), some_other_style();
> >     Each of these functions has the parameter "right" (or the group of
> >     parameters c("right", ...)).
> >
> >
> >     Then I could design a function right(FUN) that assigns the value
> >     to this parameter and evaluates the function FUN().
> >
> >
> >     There are a few ways to do this:
> >
> >     1.) Other parameters as ...
> >     right(FUN, value, ...) = value; and then pass "..." to FUN.
> >     right(value, FUN, ...) = value; # or is this the syntax? (TODO:
> >     explore)
> >
> >     2.) Another way:
> >     right(FUN(...other parameters already specified...)) = value;
> >     I wanted to explore this 2nd option: but avoid evaluating FUN,
> >     unless the parameter "right" is injected into the call.
> >
> >     3.) Option 3:
> >     The option you mentioned.
> >
> >
> >     Independent of the method: there are still weird/unexplained
> >     behaviours when I try the initial code (see the latest mail with
> >     the improved code).
> >
> >
> >     Sincerely,
> >
> >
> >     Leonard
> >
> >
> >     On 9/13/2021 6:45 PM, Andrew Simmons wrote:
> >>     I think you're trying to do something like:
> >>
> >>     `padding<-` <- function (x, which, value)
> >>     {
> >>         which <- match.arg(which, c("bottom", "left", "top",
> >>     "right"), several.ok = TRUE)
> >>         # code to pad to each side here
> >>     }
> >>
> >>     Then you could use it like
> >>
> >>     df <- data.frame(x=1:5, y = sample(1:5, 5))
> >>     padding(df, "right") <- 1
> >>
> >>     Does that work as expected for you?
> >>
> >>     On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
> >>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
> >>
> >>         I try to clarify the code:
> >>
> >>
> >>         ###
> >>         right = function(x, val) {print("Right");};
> >>         padding = function(x, right, left, top, bottom)
> >>         {print("Padding");};
> >>         'padding<-' = function(x, ...) {print("Padding = ");};
> >>         df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
> >>
> >>         ### Does NOT work as expected
> >>         'right<-' = function(x, value) {
> >>              print("This line should be the first printed!")
> >>              print("But ERROR: x was already evaluated, which printed
> >>         \"Padding\"");
> >>              x = substitute(x); # x was already evaluated before
> >>         substitute();
> >>              return("Nothing"); # do not now what the behaviour
> >>         should be?
> >>         }
> >>
> >>         right(padding(df)) = 1;
> >>
> >>         ### Output:
> >>
> >>         [1] "Padding"
> >>         [1] "This line should be the first printed!"
> >>         [1] "But ERROR: x was already evaluated, which printed
> >>         \"Padding\""
> >>         [1] "Padding = " # How did this happen ???
> >>
> >>
> >>         ### Problems:
> >>
> >>         1.) substitute(x): did not capture the expression;
> >>         - the first parameter of 'right<-' was already evaluated,
> >>         which is not
> >>         the case with '%f%';
> >>         Can I avoid evaluating this parameter?
> >>         How can I avoid to evaluate it and capture the expression:
> >>         "right(...)"?
> >>
> >>
> >>         2.) Unexpected
> >>         'padding<-' was also called!
> >>         I did not know this. Is it feature or bug?
> >>         R 4.0.4
> >>
> >>
> >>         Sincerely,
> >>
> >>
> >>         Leonard
> >>
> >>
> >>         On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
> >>         > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
> >>         >> Hello,
> >>         >>
> >>         >>
> >>         >> I can include code for "padding<-"as well, but the error
> >>         is before that,
> >>         >> namely in 'right<-':
> >>         >>
> >>         >> right = function(x, val) {print("Right");};
> >>         >> # more options:
> >>         >> padding = function(x, right, left, top, bottom)
> >>         {print("Padding");};
> >>         >> 'padding<-' = function(x, ...) {print("Padding = ");};
> >>         >> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>         >>
> >>         >>
> >>         >> ### Does NOT work
> >>         >> 'right<-' = function(x, val) {
> >>         >>         print("Already evaluated and also does not use
> >>         'val'");
> >>         >>         x = substitute(x); # x was evaluated before
> >>         >> }
> >>         >>
> >>         >> right(padding(df)) = 1;
> >>         >
> >>         > It "works" (i.e. doesn't generate an error) for me, when I
> >>         correct
> >>         > your typo:  the second argument to `right<-` should be
> >>         `value`, not
> >>         > `val`.
> >>         >
> >>         > I'm still not clear whether it does what you want with that
> >>         fix,
> >>         > because I don't really understand what you want.
> >>         >
> >>         > Duncan Murdoch
> >>         >
> >>         >>
> >>         >>
> >>         >> I want to capture the assignment event inside "right<-"
> >>         and then call
> >>         >> the function padding() properly.
> >>         >>
> >>         >> I haven't thought yet if I should use:
> >>         >>
> >>         >> padding(x, right, left, ... other parameters);
> >>         >>
> >>         >> or
> >>         >>
> >>         >> padding(x, parameter) <- value;
> >>         >>
> >>         >>
> >>         >> It also depends if I can properly capture the unevaluated
> >>         expression
> >>         >> inside "right<-":
> >>         >>
> >>         >> 'right<-' = function(x, val) {
> >>         >>
> >>         >> # x is automatically evaluated when using 'f<-'!
> >>         >>
> >>         >> # but not when implementing as '%f%' = function(x, y);
> >>         >>
> >>         >> }
> >>         >>
> >>         >>
> >>         >> Many thanks,
> >>         >>
> >>         >>
> >>         >> Leonard
> >>         >>
> >>         >>
> >>         >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
> >>         >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
> >>         >>>> How can I avoid evaluation?
> >>         >>>>
> >>         >>>> right = function(x, val) {print("Right");};
> >>         >>>> padding = function(x) {print("Padding");};
> >>         >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
> >>         >>>>
> >>         >>>> ### OK
> >>         >>>> '%=%' = function(x, val) {
> >>         >>>>        x = substitute(x);
> >>         >>>> }
> >>         >>>> right(padding(df)) %=% 1; # but ugly
> >>         >>>>
> >>         >>>> ### Does NOT work
> >>         >>>> 'right<-' = function(x, val) {
> >>         >>>>        print("Already evaluated and also does not use
> >>         'val'");
> >>         >>>>        x = substitute(x); # is evaluated before
> >>         >>>> }
> >>         >>>>
> >>         >>>> right(padding(df)) = 1
> >>         >>>
> >>         >>> That doesn't make sense.  You don't have a `padding<-`
> >>         function, and
> >>         >>> yet you are trying to call right<- to assign something to
> >>         padding(df).
> >>         >>>
> >>         >>> I'm not sure about your real intention, but assignment
> >>         functions by
> >>         >>> their nature need to evaluate the thing they are
> >>         assigning to, since
> >>         >>> they are designed to modify objects, not create new ones.
> >>         >>>
> >>         >>> To create a new object, just use regular assignment.
> >>         >>>
> >>         >>> Duncan Murdoch
> >>         >
> >>
> >>         ______________________________________________
> >>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
> >>         list -- To UNSUBSCRIBE and more, see
> >>         https://stat.ethz.ch/mailman/listinfo/r-help
> >>         <https://stat.ethz.ch/mailman/listinfo/r-help>
> >>         PLEASE do read the posting guide
> >>         http://www.R-project.org/posting-guide.html
> >>         <http://www.R-project.org/posting-guide.html>
> >>         and provide commented, minimal, self-contained, reproducible
> >>         code.
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Sep 13 22:12:21 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 13 Sep 2021 16:12:21 -0400
Subject: [R] 
 Error msg trying to load R Commander with an older R edition...
In-Reply-To: <32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
References: <32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
Message-ID: <4d596d9a-ca18-bdb4-4799-d710f38858f7@gmail.com>

On 13/09/2021 9:33 a.m., Brian Lunergan wrote:
> Hi folks:
> 
> I'm running Linux Mint 19.3 on my machine. Tried to install a more
> recent edition of R but I couldn't seem to get it working so I pulled it
> off and went with a good, basic install of the edition available through
> the software manager. So... I'm running version 3.4.4.
> 
> Mucking about with the attempt at a newer edition seems to have left
> some excess baggage behind. When I loaded R Commander and attempted to
> run it I received the following error message.
> 
> Error: package or namespace load failed for ?car? in readRDS(pfile):
>   cannot read workspace version 3 written by R 3.6.2; need R 3.5.0 or newer
> During startup - Warning message:
> package ?Rcmdr? in options("defaultPackages") was not found

That likely means you still have some files from the newer R in your 
package library.  To find where your library is stored, run .libPaths(). 
  Then look in that directory and remove the "car" directory.  You might 
want to also remove anything else that was installed before you 
installed R 3.4.4, because all the old dirs in there will cause you trouble.

Duncan Murdoch

> 
> I get a similar message in Rkward when I try to load any more packages.
> 
> Is there any solution for this? Any "leftovers" I can track down and
> delete? Any assistance would be greatly appreciated.
> 
> Kind regards...
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 22:18:16 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 23:18:16 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
Message-ID: <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>

Hello,


I have found the evaluation: it is described in the section on 
subsetting. The forced evaluation makes sense for subsetting.


On 9/13/2021 9:42 PM, Leonard Mada wrote:
>
> Hello Andrew,
>
>
> I try now to understand the evaluation of the expression:
>
> e = expression(r(x) <- 1)
>
> # parameter named "value" seems to be required;
> 'r<-' = function(x, value) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
> # both versions work
> 'r<-' = function(value, x) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
>
> ### the Expression
> e[[1]][[1]] # "<-", not "r<-"
> e[[1]][[2]] # "r(x)"
>
>
> The evaluation of "e" somehow calls "r<-", but evaluates also the 
> argument of r(...). I am still investigating what is actually happening.
>

The forced evaluation is relevant for subsetting, e.g.:
expression(r(x)[3] <- 1)
expression(r(x)[3] <- 1)[[1]][[2]]
# r(x)[3] # the evaluation details are NOT visible in the expression per se;
# Note: indeed, it makes sens to first evaluate r(x) and then to perform 
the subsetting;


However, in the case of a non-subsetted expression:
r(x) <- 1;
It would make sense to evaluate lazily r(x) if no subsetting is involved 
(more precisely "r<-"(x, value) ).

Would this have any impact on the current code?


Sincerely,


Leonard


>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>> R's parser doesn't work the way you're expecting it to. When doing an 
>> assignment like:
>>
>>
>> padding(right(df)) <- 1
>>
>>
>> it is broken into small stages. The guide "R Language Definition" 
>> claims that the above would be equivalent to:
>>
>>
>> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>>
>>
>> but that is not correct, and you can tell by using `substitute` as 
>> you were above. There isn't a way to do what you want with the syntax 
>> you provided, you'll have to do something different. You could add a 
>> `which` argument to each style function, and maybe put the code for 
>> `match.arg` in a separate function:
>>
>>
>> match.which <- function (which)
>> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>>
>>
>> padding <- function (x, which)
>> {
>> ? ? which <- match.which(which)
>> ? ? # more code
>> }
>>
>>
>> border <- function (x, which)
>> {
>> ? ? which <- match.which(which)
>> ? ? # more code
>> }
>>
>>
>> some_other_style <- function (x, which)
>> {
>> ? ? which <- match.which(which)
>> ? ? # more code
>> }
>>
>>
>> I hope this helps.
>>
>> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu 
>> <mailto:leo.mada at syonic.eu>> wrote:
>>
>>     Hello Andrew,
>>
>>
>>     this could work. I will think about it.
>>
>>
>>     But I was thinking more generically. Suppose we have a series of
>>     functions:
>>     padding(), border(), some_other_style();
>>     Each of these functions has the parameter "right" (or the group
>>     of parameters c("right", ...)).
>>
>>
>>     Then I could design a function right(FUN) that assigns the value
>>     to this parameter and evaluates the function FUN().
>>
>>
>>     There are a few ways to do this:
>>
>>     1.) Other parameters as ...
>>     right(FUN, value, ...) = value; and then pass "..." to FUN.
>>     right(value, FUN, ...) = value; # or is this the syntax? (TODO:
>>     explore)
>>
>>     2.) Another way:
>>     right(FUN(...other parameters already specified...)) = value;
>>     I wanted to explore this 2nd option: but avoid evaluating FUN,
>>     unless the parameter "right" is injected into the call.
>>
>>     3.) Option 3:
>>     The option you mentioned.
>>
>>
>>     Independent of the method: there are still weird/unexplained
>>     behaviours when I try the initial code (see the latest mail with
>>     the improved code).
>>
>>
>>     Sincerely,
>>
>>
>>     Leonard
>>
>>
>>     On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>     I think you're trying to do something like:
>>>
>>>     `padding<-` <- function (x, which, value)
>>>     {
>>>     ? ? which <- match.arg(which, c("bottom", "left", "top",
>>>     "right"), several.ok = TRUE)
>>>     ? ? # code to pad to each side here
>>>     }
>>>
>>>     Then you could use it like
>>>
>>>     df <- data.frame(x=1:5, y = sample(1:5, 5))
>>>     padding(df, "right") <- 1
>>>
>>>     Does that work as expected for you?
>>>
>>>     On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>>     <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>
>>>         I try to clarify the code:
>>>
>>>
>>>         ###
>>>         right = function(x, val) {print("Right");};
>>>         padding = function(x, right, left, top, bottom)
>>>         {print("Padding");};
>>>         'padding<-' = function(x, ...) {print("Padding = ");};
>>>         df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>
>>>         ### Does NOT work as expected
>>>         'right<-' = function(x, value) {
>>>         ???? print("This line should be the first printed!")
>>>         ???? print("But ERROR: x was already evaluated, which
>>>         printed \"Padding\"");
>>>         ???? x = substitute(x); # x was already evaluated before
>>>         substitute();
>>>         ???? return("Nothing"); # do not now what the behaviour
>>>         should be?
>>>         }
>>>
>>>         right(padding(df)) = 1;
>>>
>>>         ### Output:
>>>
>>>         [1] "Padding"
>>>         [1] "This line should be the first printed!"
>>>         [1] "But ERROR: x was already evaluated, which printed
>>>         \"Padding\""
>>>         [1] "Padding = " # How did this happen ???
>>>
>>>
>>>         ### Problems:
>>>
>>>         1.) substitute(x): did not capture the expression;
>>>         - the first parameter of 'right<-' was already evaluated,
>>>         which is not
>>>         the case with '%f%';
>>>         Can I avoid evaluating this parameter?
>>>         How can I avoid to evaluate it and capture the expression:
>>>         "right(...)"?
>>>
>>>
>>>         2.) Unexpected
>>>         'padding<-' was also called!
>>>         I did not know this. Is it feature or bug?
>>>         R 4.0.4
>>>
>>>
>>>         Sincerely,
>>>
>>>
>>>         Leonard
>>>
>>>
>>>         On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>         > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>         >> Hello,
>>>         >>
>>>         >>
>>>         >> I can include code for "padding<-"as well, but the error
>>>         is before that,
>>>         >> namely in 'right<-':
>>>         >>
>>>         >> right = function(x, val) {print("Right");};
>>>         >> # more options:
>>>         >> padding = function(x, right, left, top, bottom)
>>>         {print("Padding");};
>>>         >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>         >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>         >>
>>>         >>
>>>         >> ### Does NOT work
>>>         >> 'right<-' = function(x, val) {
>>>         >> ? ? ??? print("Already evaluated and also does not use
>>>         'val'");
>>>         >> ? ? ??? x = substitute(x); # x was evaluated before
>>>         >> }
>>>         >>
>>>         >> right(padding(df)) = 1;
>>>         >
>>>         > It "works" (i.e. doesn't generate an error) for me, when I
>>>         correct
>>>         > your typo:? the second argument to `right<-` should be
>>>         `value`, not
>>>         > `val`.
>>>         >
>>>         > I'm still not clear whether it does what you want with
>>>         that fix,
>>>         > because I don't really understand what you want.
>>>         >
>>>         > Duncan Murdoch
>>>         >
>>>         >>
>>>         >>
>>>         >> I want to capture the assignment event inside "right<-"
>>>         and then call
>>>         >> the function padding() properly.
>>>         >>
>>>         >> I haven't thought yet if I should use:
>>>         >>
>>>         >> padding(x, right, left, ... other parameters);
>>>         >>
>>>         >> or
>>>         >>
>>>         >> padding(x, parameter) <- value;
>>>         >>
>>>         >>
>>>         >> It also depends if I can properly capture the unevaluated
>>>         expression
>>>         >> inside "right<-":
>>>         >>
>>>         >> 'right<-' = function(x, val) {
>>>         >>
>>>         >> # x is automatically evaluated when using 'f<-'!
>>>         >>
>>>         >> # but not when implementing as '%f%' = function(x, y);
>>>         >>
>>>         >> }
>>>         >>
>>>         >>
>>>         >> Many thanks,
>>>         >>
>>>         >>
>>>         >> Leonard
>>>         >>
>>>         >>
>>>         >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>         >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>>         >>>> How can I avoid evaluation?
>>>         >>>>
>>>         >>>> right = function(x, val) {print("Right");};
>>>         >>>> padding = function(x) {print("Padding");};
>>>         >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>         >>>>
>>>         >>>> ### OK
>>>         >>>> '%=%' = function(x, val) {
>>>         >>>> ?? ??? x = substitute(x);
>>>         >>>> }
>>>         >>>> right(padding(df)) %=% 1; # but ugly
>>>         >>>>
>>>         >>>> ### Does NOT work
>>>         >>>> 'right<-' = function(x, val) {
>>>         >>>> ?? ??? print("Already evaluated and also does not use
>>>         'val'");
>>>         >>>> ?? ??? x = substitute(x); # is evaluated before
>>>         >>>> }
>>>         >>>>
>>>         >>>> right(padding(df)) = 1
>>>         >>>
>>>         >>> That doesn't make sense.? You don't have a `padding<-`
>>>         function, and
>>>         >>> yet you are trying to call right<- to assign something
>>>         to padding(df).
>>>         >>>
>>>         >>> I'm not sure about your real intention, but assignment
>>>         functions by
>>>         >>> their nature need to evaluate the thing they are
>>>         assigning to, since
>>>         >>> they are designed to modify objects, not create new ones.
>>>         >>>
>>>         >>> To create a new object, just use regular assignment.
>>>         >>>
>>>         >>> Duncan Murdoch
>>>         >
>>>
>>>         ______________________________________________
>>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>         list -- To UNSUBSCRIBE and more, see
>>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>         PLEASE do read the posting guide
>>>         http://www.R-project.org/posting-guide.html
>>>         <http://www.R-project.org/posting-guide.html>
>>>         and provide commented, minimal, self-contained, reproducible
>>>         code.
>>>

	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Mon Sep 13 22:28:55 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 13 Sep 2021 16:28:55 -0400
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
Message-ID: <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>

In the example you gave : r(x) <- 1
r(x) is never evaluated, the above calls `r<-`,
in fact r does not even have to be an existing function.

On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu> wrote:

> Hello,
>
>
> I have found the evaluation: it is described in the section on subsetting.
> The forced evaluation makes sense for subsetting.
>
>
> On 9/13/2021 9:42 PM, Leonard Mada wrote:
>
> Hello Andrew,
>
>
> I try now to understand the evaluation of the expression:
>
> e = expression(r(x) <- 1)
>
> # parameter named "value" seems to be required;
> 'r<-' = function(x, value) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
> # both versions work
> 'r<-' = function(value, x) {print("R");}
> eval(e, list(x=2))
> # [1] "R"
>
>
> ### the Expression
> e[[1]][[1]] # "<-", not "r<-"
> e[[1]][[2]] # "r(x)"
>
>
> The evaluation of "e" somehow calls "r<-", but evaluates also the argument
> of r(...). I am still investigating what is actually happening.
>
>
> The forced evaluation is relevant for subsetting, e.g.:
> expression(r(x)[3] <- 1)
> expression(r(x)[3] <- 1)[[1]][[2]]
> # r(x)[3] # the evaluation details are NOT visible in the expression per
> se;
> # Note: indeed, it makes sens to first evaluate r(x) and then to perform
> the subsetting;
>
>
> However, in the case of a non-subsetted expression:
> r(x) <- 1;
> It would make sense to evaluate lazily r(x) if no subsetting is involved
> (more precisely "r<-"(x, value) ).
>
> Would this have any impact on the current code?
>
>
> Sincerely,
>
>
> Leonard
>
>
>
> Sincerely,
>
>
> Leonard
>
>
> On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>
> R's parser doesn't work the way you're expecting it to. When doing an
> assignment like:
>
>
> padding(right(df)) <- 1
>
>
> it is broken into small stages. The guide "R Language Definition" claims
> that the above would be equivalent to:
>
>
> `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>
>
> but that is not correct, and you can tell by using `substitute` as you
> were above. There isn't a way to do what you want with the syntax you
> provided, you'll have to do something different. You could add a `which`
> argument to each style function, and maybe put the code for `match.arg` in
> a separate function:
>
>
> match.which <- function (which)
> match.arg(which, c("bottom", "left", "top", "right"), several.ok = TRUE)
>
>
> padding <- function (x, which)
> {
>     which <- match.which(which)
>     # more code
> }
>
>
> border <- function (x, which)
> {
>     which <- match.which(which)
>     # more code
> }
>
>
> some_other_style <- function (x, which)
> {
>     which <- match.which(which)
>     # more code
> }
>
>
> I hope this helps.
>
> On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada <leo.mada at syonic.eu> wrote:
>
>> Hello Andrew,
>>
>>
>> this could work. I will think about it.
>>
>> But I was thinking more generically. Suppose we have a series of
>> functions:
>> padding(), border(), some_other_style();
>> Each of these functions has the parameter "right" (or the group of
>> parameters c("right", ...)).
>>
>>
>> Then I could design a function right(FUN) that assigns the value to this
>> parameter and evaluates the function FUN().
>>
>>
>> There are a few ways to do this:
>> 1.) Other parameters as ...
>> right(FUN, value, ...) = value; and then pass "..." to FUN.
>> right(value, FUN, ...) = value; # or is this the syntax? (TODO: explore)
>>
>> 2.) Another way:
>> right(FUN(...other parameters already specified...)) = value;
>> I wanted to explore this 2nd option: but avoid evaluating FUN, unless the
>> parameter "right" is injected into the call.
>>
>> 3.) Option 3:
>> The option you mentioned.
>>
>>
>> Independent of the method: there are still weird/unexplained behaviours
>> when I try the initial code (see the latest mail with the improved code).
>>
>>
>> Sincerely,
>>
>>
>> Leonard
>>
>>
>> On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>
>> I think you're trying to do something like:
>>
>> `padding<-` <- function (x, which, value)
>> {
>>     which <- match.arg(which, c("bottom", "left", "top", "right"),
>> several.ok = TRUE)
>>     # code to pad to each side here
>> }
>>
>> Then you could use it like
>>
>> df <- data.frame(x=1:5, y = sample(1:5, 5))
>> padding(df, "right") <- 1
>>
>> Does that work as expected for you?
>>
>> On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help <r-help at r-project.org>
>> wrote:
>>
>>> I try to clarify the code:
>>>
>>>
>>> ###
>>> right = function(x, val) {print("Right");};
>>> padding = function(x, right, left, top, bottom) {print("Padding");};
>>> 'padding<-' = function(x, ...) {print("Padding = ");};
>>> df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>
>>> ### Does NOT work as expected
>>> 'right<-' = function(x, value) {
>>>      print("This line should be the first printed!")
>>>      print("But ERROR: x was already evaluated, which printed
>>> \"Padding\"");
>>>      x = substitute(x); # x was already evaluated before substitute();
>>>      return("Nothing"); # do not now what the behaviour should be?
>>> }
>>>
>>> right(padding(df)) = 1;
>>>
>>> ### Output:
>>>
>>> [1] "Padding"
>>> [1] "This line should be the first printed!"
>>> [1] "But ERROR: x was already evaluated, which printed \"Padding\""
>>> [1] "Padding = " # How did this happen ???
>>>
>>>
>>> ### Problems:
>>>
>>> 1.) substitute(x): did not capture the expression;
>>> - the first parameter of 'right<-' was already evaluated, which is not
>>> the case with '%f%';
>>> Can I avoid evaluating this parameter?
>>> How can I avoid to evaluate it and capture the expression: "right(...)"?
>>>
>>>
>>> 2.) Unexpected
>>> 'padding<-' was also called!
>>> I did not know this. Is it feature or bug?
>>> R 4.0.4
>>>
>>>
>>> Sincerely,
>>>
>>>
>>> Leonard
>>>
>>>
>>> On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>> > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>> >> Hello,
>>> >>
>>> >>
>>> >> I can include code for "padding<-"as well, but the error is before
>>> that,
>>> >> namely in 'right<-':
>>> >>
>>> >> right = function(x, val) {print("Right");};
>>> >> # more options:
>>> >> padding = function(x, right, left, top, bottom) {print("Padding");};
>>> >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>> >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>> >>
>>> >>
>>> >> ### Does NOT work
>>> >> 'right<-' = function(x, val) {
>>> >>         print("Already evaluated and also does not use 'val'");
>>> >>         x = substitute(x); # x was evaluated before
>>> >> }
>>> >>
>>> >> right(padding(df)) = 1;
>>> >
>>> > It "works" (i.e. doesn't generate an error) for me, when I correct
>>> > your typo:  the second argument to `right<-` should be `value`, not
>>> > `val`.
>>> >
>>> > I'm still not clear whether it does what you want with that fix,
>>> > because I don't really understand what you want.
>>> >
>>> > Duncan Murdoch
>>> >
>>> >>
>>> >>
>>> >> I want to capture the assignment event inside "right<-" and then call
>>> >> the function padding() properly.
>>> >>
>>> >> I haven't thought yet if I should use:
>>> >>
>>> >> padding(x, right, left, ... other parameters);
>>> >>
>>> >> or
>>> >>
>>> >> padding(x, parameter) <- value;
>>> >>
>>> >>
>>> >> It also depends if I can properly capture the unevaluated expression
>>> >> inside "right<-":
>>> >>
>>> >> 'right<-' = function(x, val) {
>>> >>
>>> >> # x is automatically evaluated when using 'f<-'!
>>> >>
>>> >> # but not when implementing as '%f%' = function(x, y);
>>> >>
>>> >> }
>>> >>
>>> >>
>>> >> Many thanks,
>>> >>
>>> >>
>>> >> Leonard
>>> >>
>>> >>
>>> >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>> >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help wrote:
>>> >>>> How can I avoid evaluation?
>>> >>>>
>>> >>>> right = function(x, val) {print("Right");};
>>> >>>> padding = function(x) {print("Padding");};
>>> >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>> >>>>
>>> >>>> ### OK
>>> >>>> '%=%' = function(x, val) {
>>> >>>>        x = substitute(x);
>>> >>>> }
>>> >>>> right(padding(df)) %=% 1; # but ugly
>>> >>>>
>>> >>>> ### Does NOT work
>>> >>>> 'right<-' = function(x, val) {
>>> >>>>        print("Already evaluated and also does not use 'val'");
>>> >>>>        x = substitute(x); # is evaluated before
>>> >>>> }
>>> >>>>
>>> >>>> right(padding(df)) = 1
>>> >>>
>>> >>> That doesn't make sense.  You don't have a `padding<-` function, and
>>> >>> yet you are trying to call right<- to assign something to
>>> padding(df).
>>> >>>
>>> >>> I'm not sure about your real intention, but assignment functions by
>>> >>> their nature need to evaluate the thing they are assigning to, since
>>> >>> they are designed to modify objects, not create new ones.
>>> >>>
>>> >>> To create a new object, just use regular assignment.
>>> >>>
>>> >>> Duncan Murdoch
>>> >
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Sep 13 22:33:19 2021
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 13 Sep 2021 23:33:19 +0300
Subject: [R] Evaluating lazily 'f<-' ?
In-Reply-To: <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
References: <fd47c8ab-7a7c-b478-07d7-777dc0a47291@syonic.eu>
 <6b5deddf-d8fe-4184-4aed-f7ce3ffa85e2@gmail.com>
 <0964390c-8e43-f306-8e88-70f61b484620@syonic.eu>
 <6f180c59-2e7e-d921-ee0c-b29bf915f153@gmail.com>
 <8e83c6a5-f917-53db-dcdf-43f6d5afc22f@syonic.eu>
 <CAPcHnpQvoEFGuHDGb04NqbajwTf5Ak=F-mHQzScT9Urma+c7jg@mail.gmail.com>
 <32c80412-c4f8-610c-a833-52d2b3322ea9@syonic.eu>
 <CAPcHnpRR3kN4238xdx17ThvCGNUgm81x6HTEcHVUHut3dni8Ew@mail.gmail.com>
 <eb40966e-6b09-7df5-ef64-262e77d6eacc@syonic.eu>
 <250d355b-072e-67cb-8bd5-bb012aed20a2@syonic.eu>
 <CAPcHnpSR=ZtCk=bX=NkFWO8wNc4hks07x+eGJU+Z4QA0+cJcjg@mail.gmail.com>
Message-ID: <12584b25-8150-4002-4eee-b4bc21525996@syonic.eu>


On 9/13/2021 11:28 PM, Andrew Simmons wrote:
> In the example you gave : r(x) <- 1
> r(x) is never evaluated, the above calls `r<-`,
> in fact r does not even have to be an existing function.


I meant:

'*tmp*' <- x; # "x" is evaluated here;

'r<-' is called after this step, which makes sense in the case of 
subsetting;


But I am wondering if changing this behaviour, when NO subsetting is 
performed, would have any impact.

e.g. names(x) = c("some names");

# would it have any impact to skip the evaluation of "x" and call directly:

'names<-'(x, value);


Leonard


>
> On Mon, Sep 13, 2021, 16:18 Leonard Mada <leo.mada at syonic.eu 
> <mailto:leo.mada at syonic.eu>> wrote:
>
>     Hello,
>
>
>     I have found the evaluation: it is described in the section on
>     subsetting. The forced evaluation makes sense for subsetting.
>
>
>     On 9/13/2021 9:42 PM, Leonard Mada wrote:
>>
>>     Hello Andrew,
>>
>>
>>     I try now to understand the evaluation of the expression:
>>
>>     e = expression(r(x) <- 1)
>>
>>     # parameter named "value" seems to be required;
>>     'r<-' = function(x, value) {print("R");}
>>     eval(e, list(x=2))
>>     # [1] "R"
>>
>>     # both versions work
>>     'r<-' = function(value, x) {print("R");}
>>     eval(e, list(x=2))
>>     # [1] "R"
>>
>>
>>     ### the Expression
>>     e[[1]][[1]] # "<-", not "r<-"
>>     e[[1]][[2]] # "r(x)"
>>
>>
>>     The evaluation of "e" somehow calls "r<-", but evaluates also the
>>     argument of r(...). I am still investigating what is actually
>>     happening.
>>
>
>     The forced evaluation is relevant for subsetting, e.g.:
>     expression(r(x)[3] <- 1)
>     expression(r(x)[3] <- 1)[[1]][[2]]
>     # r(x)[3] # the evaluation details are NOT visible in the
>     expression per se;
>     # Note: indeed, it makes sens to first evaluate r(x) and then to
>     perform the subsetting;
>
>
>     However, in the case of a non-subsetted expression:
>     r(x) <- 1;
>     It would make sense to evaluate lazily r(x) if no subsetting is
>     involved (more precisely "r<-"(x, value) ).
>
>     Would this have any impact on the current code?
>
>
>     Sincerely,
>
>
>     Leonard
>
>
>>
>>     Sincerely,
>>
>>
>>     Leonard
>>
>>
>>     On 9/13/2021 9:15 PM, Andrew Simmons wrote:
>>>     R's parser doesn't work the way you're expecting it to. When
>>>     doing an assignment like:
>>>
>>>
>>>     padding(right(df)) <- 1
>>>
>>>
>>>     it is broken into small stages. The guide "R Language
>>>     Definition" claims that the above would be equivalent to:
>>>
>>>
>>>     `<-`(df, `padding<-`(df, value = `right<-`(padding(df), value = 1)))
>>>
>>>
>>>     but that is not correct, and you can tell by using `substitute`
>>>     as you were above. There isn't a way to do what you want with
>>>     the syntax you provided, you'll have to do something different.
>>>     You could add a `which` argument to each style function, and
>>>     maybe put the code for `match.arg` in a separate function:
>>>
>>>
>>>     match.which <- function (which)
>>>     match.arg(which, c("bottom", "left", "top", "right"), several.ok
>>>     = TRUE)
>>>
>>>
>>>     padding <- function (x, which)
>>>     {
>>>     ? ? which <- match.which(which)
>>>     ? ? # more code
>>>     }
>>>
>>>
>>>     border <- function (x, which)
>>>     {
>>>     ? ? which <- match.which(which)
>>>     ? ? # more code
>>>     }
>>>
>>>
>>>     some_other_style <- function (x, which)
>>>     {
>>>     ? ? which <- match.which(which)
>>>     ? ? # more code
>>>     }
>>>
>>>
>>>     I hope this helps.
>>>
>>>     On Mon, Sep 13, 2021 at 12:17 PM Leonard Mada
>>>     <leo.mada at syonic.eu <mailto:leo.mada at syonic.eu>> wrote:
>>>
>>>         Hello Andrew,
>>>
>>>
>>>         this could work. I will think about it.
>>>
>>>
>>>         But I was thinking more generically. Suppose we have a
>>>         series of functions:
>>>         padding(), border(), some_other_style();
>>>         Each of these functions has the parameter "right" (or the
>>>         group of parameters c("right", ...)).
>>>
>>>
>>>         Then I could design a function right(FUN) that assigns the
>>>         value to this parameter and evaluates the function FUN().
>>>
>>>
>>>         There are a few ways to do this:
>>>
>>>         1.) Other parameters as ...
>>>         right(FUN, value, ...) = value; and then pass "..." to FUN.
>>>         right(value, FUN, ...) = value; # or is this the syntax?
>>>         (TODO: explore)
>>>
>>>         2.) Another way:
>>>         right(FUN(...other parameters already specified...)) = value;
>>>         I wanted to explore this 2nd option: but avoid evaluating
>>>         FUN, unless the parameter "right" is injected into the call.
>>>
>>>         3.) Option 3:
>>>         The option you mentioned.
>>>
>>>
>>>         Independent of the method: there are still weird/unexplained
>>>         behaviours when I try the initial code (see the latest mail
>>>         with the improved code).
>>>
>>>
>>>         Sincerely,
>>>
>>>
>>>         Leonard
>>>
>>>
>>>         On 9/13/2021 6:45 PM, Andrew Simmons wrote:
>>>>         I think you're trying to do something like:
>>>>
>>>>         `padding<-` <- function (x, which, value)
>>>>         {
>>>>         ? ? which <- match.arg(which, c("bottom", "left", "top",
>>>>         "right"), several.ok = TRUE)
>>>>         ? ? # code to pad to each side here
>>>>         }
>>>>
>>>>         Then you could use it like
>>>>
>>>>         df <- data.frame(x=1:5, y = sample(1:5, 5))
>>>>         padding(df, "right") <- 1
>>>>
>>>>         Does that work as expected for you?
>>>>
>>>>         On Mon, Sep 13, 2021, 11:28 Leonard Mada via R-help
>>>>         <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>>>>
>>>>             I try to clarify the code:
>>>>
>>>>
>>>>             ###
>>>>             right = function(x, val) {print("Right");};
>>>>             padding = function(x, right, left, top, bottom)
>>>>             {print("Padding");};
>>>>             'padding<-' = function(x, ...) {print("Padding = ");};
>>>>             df = data.frame(x=1:5, y = sample(1:5, 5)); # anything
>>>>
>>>>             ### Does NOT work as expected
>>>>             'right<-' = function(x, value) {
>>>>             ???? print("This line should be the first printed!")
>>>>             ???? print("But ERROR: x was already evaluated, which
>>>>             printed \"Padding\"");
>>>>             ???? x = substitute(x); # x was already evaluated
>>>>             before substitute();
>>>>             ???? return("Nothing"); # do not now what the behaviour
>>>>             should be?
>>>>             }
>>>>
>>>>             right(padding(df)) = 1;
>>>>
>>>>             ### Output:
>>>>
>>>>             [1] "Padding"
>>>>             [1] "This line should be the first printed!"
>>>>             [1] "But ERROR: x was already evaluated, which printed
>>>>             \"Padding\""
>>>>             [1] "Padding = " # How did this happen ???
>>>>
>>>>
>>>>             ### Problems:
>>>>
>>>>             1.) substitute(x): did not capture the expression;
>>>>             - the first parameter of 'right<-' was already
>>>>             evaluated, which is not
>>>>             the case with '%f%';
>>>>             Can I avoid evaluating this parameter?
>>>>             How can I avoid to evaluate it and capture the
>>>>             expression: "right(...)"?
>>>>
>>>>
>>>>             2.) Unexpected
>>>>             'padding<-' was also called!
>>>>             I did not know this. Is it feature or bug?
>>>>             R 4.0.4
>>>>
>>>>
>>>>             Sincerely,
>>>>
>>>>
>>>>             Leonard
>>>>
>>>>
>>>>             On 9/13/2021 4:45 PM, Duncan Murdoch wrote:
>>>>             > On 13/09/2021 9:38 a.m., Leonard Mada wrote:
>>>>             >> Hello,
>>>>             >>
>>>>             >>
>>>>             >> I can include code for "padding<-"as well, but the
>>>>             error is before that,
>>>>             >> namely in 'right<-':
>>>>             >>
>>>>             >> right = function(x, val) {print("Right");};
>>>>             >> # more options:
>>>>             >> padding = function(x, right, left, top, bottom)
>>>>             {print("Padding");};
>>>>             >> 'padding<-' = function(x, ...) {print("Padding = ");};
>>>>             >> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>             >>
>>>>             >>
>>>>             >> ### Does NOT work
>>>>             >> 'right<-' = function(x, val) {
>>>>             >> ? ? ??? print("Already evaluated and also does not
>>>>             use 'val'");
>>>>             >> ? ? ??? x = substitute(x); # x was evaluated before
>>>>             >> }
>>>>             >>
>>>>             >> right(padding(df)) = 1;
>>>>             >
>>>>             > It "works" (i.e. doesn't generate an error) for me,
>>>>             when I correct
>>>>             > your typo:? the second argument to `right<-` should
>>>>             be `value`, not
>>>>             > `val`.
>>>>             >
>>>>             > I'm still not clear whether it does what you want
>>>>             with that fix,
>>>>             > because I don't really understand what you want.
>>>>             >
>>>>             > Duncan Murdoch
>>>>             >
>>>>             >>
>>>>             >>
>>>>             >> I want to capture the assignment event inside
>>>>             "right<-" and then call
>>>>             >> the function padding() properly.
>>>>             >>
>>>>             >> I haven't thought yet if I should use:
>>>>             >>
>>>>             >> padding(x, right, left, ... other parameters);
>>>>             >>
>>>>             >> or
>>>>             >>
>>>>             >> padding(x, parameter) <- value;
>>>>             >>
>>>>             >>
>>>>             >> It also depends if I can properly capture the
>>>>             unevaluated expression
>>>>             >> inside "right<-":
>>>>             >>
>>>>             >> 'right<-' = function(x, val) {
>>>>             >>
>>>>             >> # x is automatically evaluated when using 'f<-'!
>>>>             >>
>>>>             >> # but not when implementing as '%f%' = function(x, y);
>>>>             >>
>>>>             >> }
>>>>             >>
>>>>             >>
>>>>             >> Many thanks,
>>>>             >>
>>>>             >>
>>>>             >> Leonard
>>>>             >>
>>>>             >>
>>>>             >> On 9/13/2021 4:11 PM, Duncan Murdoch wrote:
>>>>             >>> On 12/09/2021 10:33 a.m., Leonard Mada via R-help
>>>>             wrote:
>>>>             >>>> How can I avoid evaluation?
>>>>             >>>>
>>>>             >>>> right = function(x, val) {print("Right");};
>>>>             >>>> padding = function(x) {print("Padding");};
>>>>             >>>> df = data.frame(x=1:5, y = sample(1:5, 5));
>>>>             >>>>
>>>>             >>>> ### OK
>>>>             >>>> '%=%' = function(x, val) {
>>>>             >>>> ?? ??? x = substitute(x);
>>>>             >>>> }
>>>>             >>>> right(padding(df)) %=% 1; # but ugly
>>>>             >>>>
>>>>             >>>> ### Does NOT work
>>>>             >>>> 'right<-' = function(x, val) {
>>>>             >>>> ?? ??? print("Already evaluated and also does not
>>>>             use 'val'");
>>>>             >>>> ?? ??? x = substitute(x); # is evaluated before
>>>>             >>>> }
>>>>             >>>>
>>>>             >>>> right(padding(df)) = 1
>>>>             >>>
>>>>             >>> That doesn't make sense.? You don't have a
>>>>             `padding<-` function, and
>>>>             >>> yet you are trying to call right<- to assign
>>>>             something to padding(df).
>>>>             >>>
>>>>             >>> I'm not sure about your real intention, but
>>>>             assignment functions by
>>>>             >>> their nature need to evaluate the thing they are
>>>>             assigning to, since
>>>>             >>> they are designed to modify objects, not create new
>>>>             ones.
>>>>             >>>
>>>>             >>> To create a new object, just use regular assignment.
>>>>             >>>
>>>>             >>> Duncan Murdoch
>>>>             >
>>>>
>>>>             ______________________________________________
>>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>             PLEASE do read the posting guide
>>>>             http://www.R-project.org/posting-guide.html
>>>>             <http://www.R-project.org/posting-guide.html>
>>>>             and provide commented, minimal, self-contained,
>>>>             reproducible code.
>>>>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 13 22:52:42 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 13:52:42 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
Message-ID: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>

I changed the data files so the date-times are in five separate columns:
year, month, day, hour, and minute; for example,
year,month,day,hour,min,cfs
2016,03,03,12,00,149000
2016,03,03,12,10,150000
2016,03,03,12,20,151000
2016,03,03,12,30,156000
2016,03,03,12,40,154000
2016,03,03,12,50,150000
2016,03,03,13,00,153000
2016,03,03,13,10,156000
2016,03,03,13,20,154000

The script is based on the example (on page 59 of 'R for Data Science'):
library('tidyverse')
disc <- read.csv('../data/water/disc.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE)
disc$year <- as.integer(disc$year)
disc$month <- as.integer(disc$month)
disc$day <- as.integer(disc$day)
disc$hour <- as.integer(disc$hour)
disc$min <- as.integer(disc$min)
disc$cfs <- as.double(disc$cfs, length = 6)

# use dplyr to filter() by year, month, day; summarize() to get monthly
# means, sds
disc_by_month <- group_by(disc, year, month)
summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

but my syntax is off because the results are:
> source('disc.R')
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
Warning messages:
1: In eval(ei, envir) : NAs introduced by coercion
2: In eval(ei, envir) : NAs introduced by coercion
> ls()
[1] "disc"          "disc_by_month"
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I have the same results if I use as.numeric rather than as.integer and
as.double. What am I doing incorrectly?

TIA,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Mon Sep 13 23:10:12 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 17:10:12 -0400
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
Message-ID: <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>

Rich,

Did I miss something? The summarise() command is telling you that  you had not implicitly grouped the data and it made a guess. The canonical way is:

... %>% group_by(year, month, day, hour) %>% summarise(...)


You decide which fields to group by, sometimes including others so they are in the output. 

Avi

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 4:53 PM
To: r-help at r-project.org
Subject: [R] tidyverse: grouped summaries (with summerize)

I changed the data files so the date-times are in five separate columns:
year, month, day, hour, and minute; for example, year,month,day,hour,min,cfs
2016,03,03,12,00,149000
2016,03,03,12,10,150000
2016,03,03,12,20,151000
2016,03,03,12,30,156000
2016,03,03,12,40,154000
2016,03,03,12,50,150000
2016,03,03,13,00,153000
2016,03,03,13,10,156000
2016,03,03,13,20,154000

The script is based on the example (on page 59 of 'R for Data Science'):
library('tidyverse')
disc <- read.csv('../data/water/disc.dat', header = TRUE, sep = ',', stringsAsFactors = FALSE) disc$year <- as.integer(disc$year) disc$month <- as.integer(disc$month) disc$day <- as.integer(disc$day) disc$hour <- as.integer(disc$hour) disc$min <- as.integer(disc$min) disc$cfs <- as.double(disc$cfs, length = 6)

# use dplyr to filter() by year, month, day; summarize() to get monthly # means, sds disc_by_month <- group_by(disc, year, month) summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

but my syntax is off because the results are:
> source('disc.R')
`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.
Warning messages:
1: In eval(ei, envir) : NAs introduced by coercion
2: In eval(ei, envir) : NAs introduced by coercion
> ls()
[1] "disc"          "disc_by_month"
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I have the same results if I use as.numeric rather than as.integer and as.double. What am I doing incorrectly?

TIA,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 13 23:22:09 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 14:22:09 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
Message-ID: <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> Did I miss something?

Avi,

Probably not.

> The summarise() command is telling you that  you had not implicitly
> grouped the data and it made a guess. The canonical way is:
> ... %>% group_by(year, month, day, hour) %>% summarise(...)

After sending the message I saw the example using %>% and didn't realize
that it made a difference from the previous example.

> You decide which fields to group by, sometimes including others so they
> are in the output.

That's what I thought I did. I'll rewrite the script and work toward the
output I need.

Thanks,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep 13 23:50:38 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 14:50:38 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
Message-ID: <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Rich Shepard wrote:

> That's what I thought I did. I'll rewrite the script and work toward the
> output I need.

Still not the correct syntax. Command is now:
disc_by_month %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

and results are:
> source('disc.R')
`summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.

> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

The grouping is still not right. I expected to see a mean value for each
month of each year in the data set, not for each minute.

Rich


From er|cjberger @end|ng |rom gm@||@com  Mon Sep 13 23:56:16 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 14 Sep 2021 00:56:16 +0300
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
Message-ID: <CAGgJW763+eH8c15Vek2OUHGYU8aO8oAG6jE2e51YdhOw_R40Ag@mail.gmail.com>

This code is not correct:
disc_by_month %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

It should be:

disc %>% group_by(year,month) %>% summarize(vol=mean(cfs,na.rm=TRUE)





On Tue, Sep 14, 2021 at 12:51 AM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Mon, 13 Sep 2021, Rich Shepard wrote:
>
> > That's what I thought I did. I'll rewrite the script and work toward the
> > output I need.
>
> Still not the correct syntax. Command is now:
> disc_by_month %>%
>      group_by(year, month) %>%
>      summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))
>
> and results are:
> > source('disc.R')
> `summarise()` has grouped output by 'year', 'month'. You can override
> using the `.groups` argument.
>
> > disc_by_month
> # A tibble: 590,940 ? 6
> # Groups:   year, month [66]
>      year month   day  hour   min    cfs
>     <int> <int> <int> <int> <int>  <dbl>
>   1  2016     3     3    12     0 149000
>   2  2016     3     3    12    10 150000
>   3  2016     3     3    12    20 151000
>   4  2016     3     3    12    30 156000
>   5  2016     3     3    12    40 154000
>   6  2016     3     3    12    50 150000
>   7  2016     3     3    13     0 153000
>   8  2016     3     3    13    10 156000
>   9  2016     3     3    13    20 154000
> 10  2016     3     3    13    30 155000
> # ? with 590,930 more rows
>
> The grouping is still not right. I expected to see a mean value for each
> month of each year in the data set, not for each minute.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 00:31:33 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 15:31:33 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <CAGgJW763+eH8c15Vek2OUHGYU8aO8oAG6jE2e51YdhOw_R40Ag@mail.gmail.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <CAGgJW763+eH8c15Vek2OUHGYU8aO8oAG6jE2e51YdhOw_R40Ag@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2109131524400.10716@salmo.appl-ecosys.com>

On Tue, 14 Sep 2021, Eric Berger wrote:

> This code is not correct:
> disc_by_month %>%
>     group_by(year, month) %>%
>     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))
> It should be:
> disc %>% group_by(year,month) %>% summarize(vol=mean(cfs,na.rm=TRUE)

Eric/Avi:

That makes no difference:
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I wondered if I need to group first by hour, then day, then year-month.
This, too, produces the same output:

disc %>%
     group_by(hour) %>%
     group_by(day) %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

And disc shows the read dataframe.

I don't understand why the columns are not grouping.

Thanks,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 00:36:06 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 18:36:06 -0400
Subject: [R] tidyverse: grouped summaries (with summerize)
In-Reply-To: <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
Message-ID: <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>

As Eric has pointed out, perhaps Rich is not thinking pipelined. Summarize() takes a first argument as:
	summarise(.data=whatever, ...)

But in a pipeline, you OMIT the first argument and let the pipeline supply an argument silently.

What I think summarize saw was something like:

summarize(. , disc_by_month, vol = mean(cfs, na.rm = TRUE))

There is now a superfluous SECOND argument in a place it expected not a data.frame type of variable but the name of a column in the hidden data.frame-like object it was passed. You do not have a column called disc_by_month and presumably some weird logic made it suggest it was replacing that by the first column or something.

I hope this makes sense. You do not cobble a pipeline together from parts without carefully making sure all first arguments otherwise used are NOT used.

And, just FYI, the subject line should not use a word that some see as the opposite companion of "winterize" ...

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 5:51 PM
To: r-help at r-project.org
Subject: Re: [R] tidyverse: grouped summaries (with summerize)

On Mon, 13 Sep 2021, Rich Shepard wrote:

> That's what I thought I did. I'll rewrite the script and work toward 
> the output I need.

Still not the correct syntax. Command is now:
disc_by_month %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

and results are:
> source('disc.R')
`summarise()` has grouped output by 'year', 'month'. You can override using the `.groups` argument.

> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

The grouping is still not right. I expected to see a mean value for each month of each year in the data set, not for each minute.

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 00:43:03 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 18:43:03 -0400
Subject: [R] tidyverse: grouped summaries (with summArize)
References: <03ed01d7a8f0$b6a20d90$23e628b0$.ref@verizon.net>
Message-ID: <03ed01d7a8f0$b6a20d90$23e628b0$@verizon.net>

I think we wandered away into a package rather than base R, but the request seems easy enough.

Just FYI, Rich, as you seem not to have incorporated the advice we gave yet about the first argument, your use of group_by() is a tad odd.

disc %>%
     group_by(hour) %>%
     group_by(day) %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

Not sure why you use disc once and disc_by_month the second superfluous time but if you read the manual page for group_by() https://dplyr.tidyverse.org/reference/group_by.html you may note it tends to be called ONCE with multiple arguments in sequence that specify what columns in the data.frame to group by sequentially.

disc %>%
     group_by(hour, day, year, month) %>%
     summarize(vol = mean(cfs, na.rm = TRUE))

Not sure most people would group that way as the above sorts by hours first. Many might reverse that sequence.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 6:32 PM
To: R mailing list <r-help at r-project.org>
Subject: Re: [R] tidyverse: grouped summaries (with summerize)

On Tue, 14 Sep 2021, Eric Berger wrote:

> This code is not correct:
> disc_by_month %>%
>     group_by(year, month) %>%
>     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE)) It should 
> be:
> disc %>% group_by(year,month) %>% summarize(vol=mean(cfs,na.rm=TRUE)

Eric/Avi:

That makes no difference:
> disc_by_month
# A tibble: 590,940 ? 6
# Groups:   year, month [66]
     year month   day  hour   min    cfs
    <int> <int> <int> <int> <int>  <dbl>
  1  2016     3     3    12     0 149000
  2  2016     3     3    12    10 150000
  3  2016     3     3    12    20 151000
  4  2016     3     3    12    30 156000
  5  2016     3     3    12    40 154000
  6  2016     3     3    12    50 150000
  7  2016     3     3    13     0 153000
  8  2016     3     3    13    10 156000
  9  2016     3     3    13    20 154000
10  2016     3     3    13    30 155000
# ? with 590,930 more rows

I wondered if I need to group first by hour, then day, then year-month.
This, too, produces the same output:

disc %>%
     group_by(hour) %>%
     group_by(day) %>%
     group_by(year, month) %>%
     summarize(disc_by_month, vol = mean(cfs, na.rm = TRUE))

And disc shows the read dataframe.

I don't understand why the columns are not grouping.

Thanks,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Tue Sep 14 00:46:09 2021
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 13 Sep 2021 18:46:09 -0400
Subject: [R] 
 Error msg trying to load R Commander with an older R edition...
In-Reply-To: <18272_1631562598_18DJnvtf022235_32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
References: <18272_1631562598_18DJnvtf022235_32f8ac2a-a9f0-7379-f499-2fa357b9a723@ncf.ca>
Message-ID: <d18ca8cc-551e-7a04-437f-7858da7ff4a0@mcmaster.ca>

Dear Brian,

On 2021-09-13 9:33 a.m., Brian Lunergan wrote:
> Hi folks:
> 
> I'm running Linux Mint 19.3 on my machine. Tried to install a more
> recent edition of R but I couldn't seem to get it working so I pulled it
> off and went with a good, basic install of the edition available through
> the software manager. So... I'm running version 3.4.4.
> 
> Mucking about with the attempt at a newer edition seems to have left
> some excess baggage behind. When I loaded R Commander and attempted to
> run it I received the following error message.
> 
> Error: package or namespace load failed for ?car? in readRDS(pfile):
>   cannot read workspace version 3 written by R 3.6.2; need R 3.5.0 or newer
> During startup - Warning message:
> package ?Rcmdr? in options("defaultPackages") was not found
> 
> I get a similar message in Rkward when I try to load any more packages.
> 
> Is there any solution for this? Any "leftovers" I can track down and
> delete? Any assistance would be greatly appreciated.

It's hard to know exactly how many things are wrong here, but one 
problem seems to be that you saved the R workspace in the newer version 
of R, and that the older version is trying to load the saved workspace, 
which is an incompatible format.

The workspace is probably saved in the file .RData in your R home 
directory. If that's the case, then you should see a message to this 
effect when R starts up. I'd begin by simply deleting this file.

Then, if the Rcmdr package fails to load with an error indicating that 
car or another package is missing, I'd try installing the missing 
package(s).

Finally, you might be better off persevering in your attempt to install 
the current version of R rather than the quite old version that you're 
trying get working.

I hope this helps,
  John

> 
> Kind regards...
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 01:04:28 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 16:04:28 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
Message-ID: <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> As Eric has pointed out, perhaps Rich is not thinking pipelined. Summarize() takes a first argument as:
> 	summarise(.data=whatever, ...)
>
> But in a pipeline, you OMIT the first argument and let the pipeline supply an argument silently.

Avi,

Thank you. I read your message carefully and re-read the example on the
bottom of page 60 and top of page 61. Then changed the command to:
disc_by_month = disc %>%
     group_by(year, month) %>%
     summarize(vol = mean(cfs, na.rm = TRUE))

And, the script now returns what I need:
> disc_by_month
# A tibble: 66 ? 3
# Groups:   year [7]
     year month     vol
    <int> <int>   <dbl>
  1  2016     3 221840.
  2  2016     4 288589.
  3  2016     5 255164.
  4  2016     6 205371.
  5  2016     7 167252.
  6  2016     8 140465.
  7  2016     9  97779.
  8  2016    10 135482.
  9  2016    11 166808.
10  2016    12 165787.

I missed the beginning of the command where the resulting dataframe needs to
be named first.

This clarifies my understanding and I appreciate your and Eric's help.

Regards,

Rich


From @v|gro@@ @end|ng |rom ver|zon@net  Tue Sep 14 01:44:14 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Mon, 13 Sep 2021 19:44:14 -0400
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
Message-ID: <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>

Just FYI, Rich, the way the idiom with pipeline works does allow but not require the method you used:

Yours was
  RESULT <-
    DATAFRAME %>%
    FN1(args) %>%
    ...
    FNn(args)
    
But equally valid are forms that assign the result at the end:

    DATAFRAME %>%
    FN1(args) %>%
    ...
    FNn(args) -> RESULT

Or that supply the first argument to just the first function:

    FN1(DATAFRAME, args) %>%
    ...
    FNn(args) -> RESULT

And if you read some tutorials, there are many other things you can do including variants on the pipe symbol to do other things but also how to put the variable returned into a different part (not the first position) of the argument that follows and lots more. Some people spend most of the programming time relatively purely in the tidyverse functions without looking much at base R.

I am not saying that is a good thing.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rich Shepard
Sent: Monday, September 13, 2021 7:04 PM
To: r-help at r-project.org
Subject: Re: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> As Eric has pointed out, perhaps Rich is not thinking pipelined. Summarize() takes a first argument as:
> 	summarise(.data=whatever, ...)
>
> But in a pipeline, you OMIT the first argument and let the pipeline supply an argument silently.

Avi,

Thank you. I read your message carefully and re-read the example on the bottom of page 60 and top of page 61. Then changed the command to:
disc_by_month = disc %>%
     group_by(year, month) %>%
     summarize(vol = mean(cfs, na.rm = TRUE))

And, the script now returns what I need:
> disc_by_month
# A tibble: 66 ? 3
# Groups:   year [7]
     year month     vol
    <int> <int>   <dbl>
  1  2016     3 221840.
  2  2016     4 288589.
  3  2016     5 255164.
  4  2016     6 205371.
  5  2016     7 167252.
  6  2016     8 140465.
  7  2016     9  97779.
  8  2016    10 135482.
  9  2016    11 166808.
10  2016    12 165787.

I missed the beginning of the command where the resulting dataframe needs to be named first.

This clarifies my understanding and I appreciate your and Eric's help.

Regards,

Rich

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Sep 14 02:15:06 2021
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 13 Sep 2021 17:15:06 -0700 (PDT)
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
 <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
Message-ID: <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>

On Mon, 13 Sep 2021, Avi Gross via R-help wrote:

> Just FYI, Rich, the way the idiom with pipeline works does allow but not
> require the method you used:
   ...
> But equally valid are forms that assign the result at the end:

Avi,

I'll read more about tidyverse and summarize() in R and not just in the
book.

Most of what I've done has been in base R, but I've not before grouped
hydraulic values before plotting them. Seasonal patterns are more
informative than daily ones.

Thanks again,

Rich


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep 14 03:10:33 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 13 Sep 2021 18:10:33 -0700
Subject: [R] tidyverse: grouped summaries (with summarize) [RESOLVED]
In-Reply-To: <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2109131339260.10716@salmo.appl-ecosys.com>
 <034b01d7a8e3$be08cf90$3a1a6eb0$@verizon.net>
 <alpine.LNX.2.20.2109131419190.10716@salmo.appl-ecosys.com>
 <alpine.LNX.2.20.2109131446090.10716@salmo.appl-ecosys.com>
 <03e801d7a8ef$be336b90$3a9a42b0$@verizon.net>
 <alpine.LNX.2.20.2109131600180.10716@salmo.appl-ecosys.com>
 <043401d7a8f9$42a34b80$c7e9e280$@verizon.net>
 <alpine.LNX.2.20.2109131712150.10716@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSGw=PUkc+EJEJUZsxaFw759b5egZ3UJcQKUy2WcofrfQ@mail.gmail.com>

If you are interested in extracting seasonal patterns from time
series, you might wish to check out ?stl (in the stats package). Of
course, there are all sorts of ways in many packages to fit
seasonality in time series that are more sophisticated, but probably
also more complicated, than your manual summarization and plotting.


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Sep 13, 2021 at 5:15 PM Rich Shepard <rshepard at appl-ecosys.com> wrote:
>
> On Mon, 13 Sep 2021, Avi Gross via R-help wrote:
>
> > Just FYI, Rich, the way the idiom with pipeline works does allow but not
> > require the method you used:
>    ...
> > But equally valid are forms that assign the result at the end:
>
> Avi,
>
> I'll read more about tidyverse and summarize() in R and not just in the
> book.
>
> Most of what I've done has been in base R, but I've not before grouped
> hydraulic values before plotting them. Seasonal patterns are more
> informative than daily ones.
>
> Thanks again,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


