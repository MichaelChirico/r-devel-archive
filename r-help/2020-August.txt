From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 04:18:06 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 21:18:06 -0500
Subject: [R] How to extract information from .Rdata format
Message-ID: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>

Hello,

I have this file:
> a=load("paired_example.Rdata")
> a
[1] "rawdata"   "treatment" "patient"

I can extract "rawdata" with:
 dat<-local(get(load("paired_example.Rdata")))

Can you please advise how would I extract in data frame "treatment"
and "patient"?

Thanks
Ana


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 04:35:05 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 31 Jul 2020 19:35:05 -0700
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
Message-ID: <CAGxFJbRnqAZ6nrOi-KbWA_V6W8+pdc7fH3fd7tSuhC-pQ2qNMQ@mail.gmail.com>

What does
str(a)

give?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jul 31, 2020 at 7:18 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have this file:
> > a=load("paired_example.Rdata")
> > a
> [1] "rawdata"   "treatment" "patient"
>
> I can extract "rawdata" with:
>  dat<-local(get(load("paired_example.Rdata")))
>
> Can you please advise how would I extract in data frame "treatment"
> and "patient"?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sat Aug  1 04:37:38 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 31 Jul 2020 22:37:38 -0400
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
Message-ID: <CAM_vjumi5Ds2Kkzz=24wTkNwei6Kf-r9_Ev8wRZwS92S3s2SOg@mail.gmail.com>

Hi Ana,

You are making this far too complicated.

load("paired_example.Rdata")

ls()

str(rawdata)
str(treatment)
str(patient)

load() puts all of them into your current environment. If you assign
the result of load() to something, in your example a, that object
contains the names of the objects, but the objects themselves are in
your workspace.

You should probably try a basic R tutorial; it will help you with this
kind of thing.

Sarah

On Fri, Jul 31, 2020 at 10:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have this file:
> > a=load("paired_example.Rdata")
> > a
> [1] "rawdata"   "treatment" "patient"
>
> I can extract "rawdata" with:
>  dat<-local(get(load("paired_example.Rdata")))
>
> Can you please advise how would I extract in data frame "treatment"
> and "patient"?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 04:53:47 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 21:53:47 -0500
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
Message-ID: <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>

Hi Bert,

it gives me this:

> a=load("paired_example.Rdata")
> str(a)
 chr [1:3] "rawdata" "treatment" "patient"

I don't know how to extract "treatment" for example in a data frame.

I tried this but of no help.
> b=a[[2]]
> b
[1] "treatment"

> str(treatment)
 chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...

but this is not the format I need.

On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have this file:
> > a=load("paired_example.Rdata")
> > a
> [1] "rawdata"   "treatment" "patient"
>
> I can extract "rawdata" with:
>  dat<-local(get(load("paired_example.Rdata")))
>
> Can you please advise how would I extract in data frame "treatment"
> and "patient"?
>
> Thanks
> Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 04:59:41 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 21:59:41 -0500
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
Message-ID: <CAF9-5jPLcdh-H7-1edD9GbeP37Xc0rJBtakA=bo0NwST7hSYEw@mail.gmail.com>

It seems that "treatment" and "patient" are just vectors.

> treatment
 [1] "treat"   "treat"   "treat"   "treat"   "treat"   "control" "control"
 [8] "control" "control" "control"
> patient
 [1] "a" "b" "c" "d" "e" "a" "b" "c" "d" "e"

On Fri, Jul 31, 2020 at 9:53 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Bert,
>
> it gives me this:
>
> > a=load("paired_example.Rdata")
> > str(a)
>  chr [1:3] "rawdata" "treatment" "patient"
>
> I don't know how to extract "treatment" for example in a data frame.
>
> I tried this but of no help.
> > b=a[[2]]
> > b
> [1] "treatment"
>
> > str(treatment)
>  chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>
> but this is not the format I need.
>
> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have this file:
> > > a=load("paired_example.Rdata")
> > > a
> > [1] "rawdata"   "treatment" "patient"
> >
> > I can extract "rawdata" with:
> >  dat<-local(get(load("paired_example.Rdata")))
> >
> > Can you please advise how would I extract in data frame "treatment"
> > and "patient"?
> >
> > Thanks
> > Ana


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 06:05:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 31 Jul 2020 21:05:47 -0700
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
Message-ID: <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>

Sarah has explained all.

I agree with her about the need for tutorials also. This list cannot
substitute for such homework on your own.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jul 31, 2020 at 7:55 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi Bert,
>
> it gives me this:
>
> > a=load("paired_example.Rdata")
> > str(a)
>  chr [1:3] "rawdata" "treatment" "patient"
>
> I don't know how to extract "treatment" for example in a data frame.
>
> I tried this but of no help.
> > b=a[[2]]
> > b
> [1] "treatment"
>
> > str(treatment)
>  chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>
> but this is not the format I need.
>
> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >
> > Hello,
> >
> > I have this file:
> > > a=load("paired_example.Rdata")
> > > a
> > [1] "rawdata"   "treatment" "patient"
> >
> > I can extract "rawdata" with:
> >  dat<-local(get(load("paired_example.Rdata")))
> >
> > Can you please advise how would I extract in data frame "treatment"
> > and "patient"?
> >
> > Thanks
> > Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Aug  1 06:30:33 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 31 Jul 2020 23:30:33 -0500
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
 <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>
Message-ID: <CAF9-5jM01B-SAPAEifUoVLqLCYNUHH+v3stxoKZa5q1J=E=n8w@mail.gmail.com>

do you think that this is useful output from Basics of R?
> load("paired_example.Rdata")
> str(rawdata)
 num [1:4482, 1:10] 46 4 3 48 1 4 0 60 0 12 ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:4482] "gene1" "gene2" "gene3" "gene4" ...
  ..$ : chr [1:10] "a.cancer" "b.cancer" "c.cancer" "d.cancer" ..

I think this one is better:
> dat<-local(get(load("paired_example.Rdata")))
> head(dat)
      a.cancer b.cancer c.cancer d.cancer e.cancer a.normal b.normal c.normal
gene1       46        4       33        5        8       61        5       42
gene2        4        0        2        1        5       24        1       30
gene3        3        4        4        2        1        3        0        0
gene4       48        2       10        0        6        9        4        3
gene5        1        5        2        3        6        1        0        3
gene6        4        0        0        1        1        4        0        7

On Fri, Jul 31, 2020 at 11:05 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Sarah has explained all.
>
> I agree with her about the need for tutorials also. This list cannot substitute for such homework on your own.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Jul 31, 2020 at 7:55 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>
>> Hi Bert,
>>
>> it gives me this:
>>
>> > a=load("paired_example.Rdata")
>> > str(a)
>>  chr [1:3] "rawdata" "treatment" "patient"
>>
>> I don't know how to extract "treatment" for example in a data frame.
>>
>> I tried this but of no help.
>> > b=a[[2]]
>> > b
>> [1] "treatment"
>>
>> > str(treatment)
>>  chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>>
>> but this is not the format I need.
>>
>> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> > I have this file:
>> > > a=load("paired_example.Rdata")
>> > > a
>> > [1] "rawdata"   "treatment" "patient"
>> >
>> > I can extract "rawdata" with:
>> >  dat<-local(get(load("paired_example.Rdata")))
>> >
>> > Can you please advise how would I extract in data frame "treatment"
>> > and "patient"?
>> >
>> > Thanks
>> > Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  1 07:56:42 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Aug 2020 06:56:42 +0100
Subject: [R] How to extract information from .Rdata format
In-Reply-To: <CAF9-5jM01B-SAPAEifUoVLqLCYNUHH+v3stxoKZa5q1J=E=n8w@mail.gmail.com>
References: <CAF9-5jNNbP3skT0C=JLPs-EVnBRwvx0BBvuLPWFgL6OZ8wxgsQ@mail.gmail.com>
 <CAF9-5jPKXR3SCh3dP7oU4dfDvxM1N3PBQ32EP4+qfrkawLgOHQ@mail.gmail.com>
 <CAGxFJbRY84JZexukj5DQ5L-jc5r35ViswtLb3OR7XEvnm-EU+A@mail.gmail.com>
 <CAF9-5jM01B-SAPAEifUoVLqLCYNUHH+v3stxoKZa5q1J=E=n8w@mail.gmail.com>
Message-ID: <1e68876b-6a1c-390a-16ca-8bdbf0b4ef37@sapo.pt>

Hello,

Inline.

?s 05:30 de 01/08/2020, Ana Marija escreveu:
> do you think that this is useful output from Basics of R?

Actually, the answer will be yes, I do. Explanation follows.

>> load("paired_example.Rdata")
>> str(rawdata)
>   num [1:4482, 1:10] 46 4 3 48 1 4 0 60 0 12 ...
>   - attr(*, "dimnames")=List of 2
>    ..$ : chr [1:4482] "gene1" "gene2" "gene3" "gene4" ...
>    ..$ : chr [1:10] "a.cancer" "b.cancer" "c.cancer" "d.cancer" ..

This says that rawdata is a numeric matrix with 4482 rows and 10 columns.
And that an useful attribute, dimnames, is set.

>
> I think this one is better:
>> dat<-local(get(load("paired_example.Rdata")))
>> head(dat)
>        a.cancer b.cancer c.cancer d.cancer e.cancer a.normal b.normal c.normal
> gene1       46        4       33        5        8       61        5       42
> gene2        4        0        2        1        5       24        1       30
> gene3        3        4        4        2        1        3        0        0
> gene4       48        2       10        0        6        9        4        3
> gene5        1        5        2        3        6        1        0        3
> gene6        4        0        0        1        1        4        0        7

This gives a better *visual* representation of the data, rawdata is an 
object of class "matrix" and it now *looks* like a table. We are used to 
seeing matrices printed like this so it's very easy to understand what 
rawdata is about.
Note that this one only has 8 columns, did you process the data before 
calling head()?

Anyway, why not run both str(rawdata) and head(rawdata)? Not only I 
don't see a conflict, they are even complementary to one another.

As for the original question, Sarah did answer to it, when you load() a 
.Rdata or .RData file the objects are created in a certain environment 
and their names are returned, you don't need get(), it's redundant.

Hope this helps,

Rui Barradas
>
> On Fri, Jul 31, 2020 at 11:05 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Sarah has explained all.
>>
>> I agree with her about the need for tutorials also. This list cannot substitute for such homework on your own.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Jul 31, 2020 at 7:55 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>> Hi Bert,
>>>
>>> it gives me this:
>>>
>>>> a=load("paired_example.Rdata")
>>>> str(a)
>>>   chr [1:3] "rawdata" "treatment" "patient"
>>>
>>> I don't know how to extract "treatment" for example in a data frame.
>>>
>>> I tried this but of no help.
>>>> b=a[[2]]
>>>> b
>>> [1] "treatment"
>>>
>>>> str(treatment)
>>>   chr [1:10] "treat" "treat" "treat" "treat" "treat" "control" "control" ...
>>>
>>> but this is not the format I need.
>>>
>>> On Fri, Jul 31, 2020 at 9:18 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>>>> Hello,
>>>>
>>>> I have this file:
>>>>> a=load("paired_example.Rdata")
>>>>> a
>>>> [1] "rawdata"   "treatment" "patient"
>>>>
>>>> I can extract "rawdata" with:
>>>>   dat<-local(get(load("paired_example.Rdata")))
>>>>
>>>> Can you please advise how would I extract in data frame "treatment"
>>>> and "patient"?
>>>>
>>>> Thanks
>>>> Ana
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sat Aug  1 13:01:08 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Sat, 1 Aug 2020 16:01:08 +0500
Subject: [R] RNA Seq Analysis in R
Message-ID: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>

I choose microarray data GSE75693 of 30 patients with stable kidney
transplantation and 15 with BKVN to identify differentially expressed genes
(DEGs). I performed this in GEO2R and find R script there and Runs R script
Successfully on R studio as well. The R script is :

 # Differential expression analysis with limma

library(Biobase)
library(GEOquery)
library(limma)
# load series and platform data from GEO

gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE)if
(length(gset) > 1) idx <- grep("GPL570", attr(gset, "names")) else idx
<- 1
gset <- gset[[idx]]
# make proper column names to match toptable
fvarLabels(gset) <- make.names(fvarLabels(gset))
# group names for all samples
gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
        "1111111111XXXXXXXXXXXXXXXXXXX")
sml <- c()for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
# eliminate samples marked as "X"
sel <- which(sml != "X")
sml <- sml[sel]
gset <- gset[ ,sel]
# log2 transform
exprs(gset) <- log2(exprs(gset))
# set up the data and proceed with analysis
sml <- paste("G", sml, sep="")    # set group names
fl <- as.factor(sml)
gset$description <- fl
design <- model.matrix(~ description + 0, gset)
colnames(design) <- levels(fl)
fit <- lmFit(gset, design)
cont.matrix <- makeContrasts(G1-G0, levels=design)
fit2 <- contrasts.fit(fit, cont.matrix)
fit2 <- eBayes(fit2, 0.01)
tT <- topTable(fit2, adjust="fdr", sort.by="B", number=1250)

tT <- subset(tT,
select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))
DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2)

After running this no genes are found plz help me

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  1 19:13:56 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 01 Aug 2020 10:13:56 -0700
Subject: [R] RNA Seq Analysis in R
In-Reply-To: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
References: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
Message-ID: <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>

https://www.bioconductor.org/help/

On August 1, 2020 4:01:08 AM PDT, Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>I choose microarray data GSE75693 of 30 patients with stable kidney
>transplantation and 15 with BKVN to identify differentially expressed
>genes
>(DEGs). I performed this in GEO2R and find R script there and Runs R
>script
>Successfully on R studio as well. The R script is :
>
> # Differential expression analysis with limma
>
>library(Biobase)
>library(GEOquery)
>library(limma)
># load series and platform data from GEO
>
>gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE)if
>(length(gset) > 1) idx <- grep("GPL570", attr(gset, "names")) else idx
><- 1
>gset <- gset[[idx]]
># make proper column names to match toptable
>fvarLabels(gset) <- make.names(fvarLabels(gset))
># group names for all samples
>gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
>        "1111111111XXXXXXXXXXXXXXXXXXX")
>sml <- c()for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
># eliminate samples marked as "X"
>sel <- which(sml != "X")
>sml <- sml[sel]
>gset <- gset[ ,sel]
># log2 transform
>exprs(gset) <- log2(exprs(gset))
># set up the data and proceed with analysis
>sml <- paste("G", sml, sep="")    # set group names
>fl <- as.factor(sml)
>gset$description <- fl
>design <- model.matrix(~ description + 0, gset)
>colnames(design) <- levels(fl)
>fit <- lmFit(gset, design)
>cont.matrix <- makeContrasts(G1-G0, levels=design)
>fit2 <- contrasts.fit(fit, cont.matrix)
>fit2 <- eBayes(fit2, 0.01)
>tT <- topTable(fit2, adjust="fdr", sort.by="B", number=1250)
>
>tT <- subset(tT,
>select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))
>DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2)
>
>After running this no genes are found plz help me
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Aug  1 19:39:58 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 1 Aug 2020 12:39:58 -0500
Subject: [R] Dependent Variable in Logistic Regression
Message-ID: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>

Dear friends,

Hope you are doing great. I want to fit a logistic regression in R, where
the dependent variable is the covid status (I used 1 for covid positives,
and 0 for covid negatives), but when I ran the glm, R complains that I
should make the dependent variable a factor.

What would be more advisable, to keep the dependent variable with 1s and
0s, or code it as yes/no and then make it a factor?

Any guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Sat Aug  1 19:50:39 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Sat, 1 Aug 2020 22:50:39 +0500
Subject: [R] DEG Analysis in R through Bioconductor
Message-ID: <CAG0CrLj03yQCXpnQ8dk4-tdnp4_T2y4J8CYDdg680qgpBZ3RCg@mail.gmail.com>

Basically I want to redo the methodology of the paper:
https://www.nature.com/articles/s41598-018-23492-2
I choose microarray data GSE75693 of 30 patients with stable kidney
transplantation and 15 with BKVN to identify differentially expressed genes
(DEGs). I performed this in GEO2R and find R script there and Runs R script
Successfully on R studio as well. The R script is :
Differential expression analysis with limma

library(Biobase) library(GEOquery) library(limma)
load series and platform data from GEO

gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE) if (length(gset)
> 1) idx <- grep("GPL570", attr(gset, "names")) else idx <- 1 gset <-
gset[[idx]]
make proper column names to match toptable

fvarLabels(gset) <- make.names(fvarLabels(gset))
group names for all samples

gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
"1111111111XXXXXXXXXXXXXXXXXXX") sml <- c() for (i in 1:nchar(gsms)) {
sml[i] <- substr(gsms,i,i) }
eliminate samples marked as "X"

sel <- which(sml != "X") sml <- sml[sel] gset <- gset[ ,sel]
log2 transform

exprs(gset) <- log2(exprs(gset))
set up the data and proceed with analysis

sml <- paste("G", sml, sep="") # set group names fl <- as.factor(sml)
gset$description <- fl design <- model.matrix(~ description + 0, gset)
colnames(design) <- levels(fl) fit <- lmFit(gset, design) cont.matrix <-
makeContrasts(G1-G0, levels=design) fit2 <- contrasts.fit(fit, cont.matrix)
fit2 <- eBayes(fit2, 0.01) tT <- topTable(fit2, adjust="fdr", sort.by="B",
number=1250) tT <- subset(tT,
select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))

DEGs = subset(tT, P.Value < 0.01 & logFC >2)

*Problem :*

But the problem is that I can't find any DEGs based on the threshold P <
0.01 and fold change >2.0 plz help me

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 19:59:36 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 10:59:36 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>

x <- factor(0:1)
x <- factor("yes","no")

will produce identical results up to labeling.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends,
>
> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
>
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?
>
> Any guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Aug  1 20:03:06 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 1 Aug 2020 11:03:06 -0700 (PDT)
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2008011101340.5024@salmo.appl-ecosys.com>

On Sat, 1 Aug 2020, Paul Bernal wrote:

> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
>
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?

Paul,

1 or 0 are equivalent to yes or no, success or failure. All are nomminal
variables so all should be factors, regardless of the coding.

Rich


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Aug  1 20:04:17 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 1 Aug 2020 13:04:17 -0500
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
Message-ID: <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>

Hi Bert,

Thank you for the kind reply.

But what if I don't turn the variable into a factor. Let's say that in
excel I just coded the variable as 1s and 0s and just imported the dataset
into R and fitted the logistic regression without turning any categorical
variable or dummy variable into a factor?

Does R requires every dummy variable to be treated as a factor?

Best regards,

Paul

El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
bgunter.4567 at gmail.com> escribi?:

> x <- factor(0:1)
> x <- factor("yes","no")
>
> will produce identical results up to labeling.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear friends,
>>
>> Hope you are doing great. I want to fit a logistic regression in R, where
>> the dependent variable is the covid status (I used 1 for covid positives,
>> and 0 for covid negatives), but when I ran the glm, R complains that I
>> should make the dependent variable a factor.
>>
>> What would be more advisable, to keep the dependent variable with 1s and
>> 0s, or code it as yes/no and then make it a factor?
>>
>> Any guidance will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:22:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:22:20 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
Message-ID: <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>

... yes, but so does lm() for a categorical **INdependent** variable with
more than 2 numerically labeled levels. n levels  = (n-1) df for a
categorical covariate, but 1 for a continuous one (unless more complex
models are explicitly specified of course). As I said, the OP seems
confused about whether he is referring to the response or covariates. Or
maybe he just made the same typo I did.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
malone at malonequantitative.com> wrote:

> No, R does not. glm() does in order to do logistic regression.
>
> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com> wrote:
>
>> Hi Bert,
>>
>> Thank you for the kind reply.
>>
>> But what if I don't turn the variable into a factor. Let's say that in
>> excel I just coded the variable as 1s and 0s and just imported the dataset
>> into R and fitted the logistic regression without turning any categorical
>> variable or dummy variable into a factor?
>>
>> Does R requires every dummy variable to be treated as a factor?
>>
>> Best regards,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>> bgunter.4567 at gmail.com> escribi?:
>>
>> > x <- factor(0:1)
>> > x <- factor("yes","no")
>> >
>> > will produce identical results up to labeling.
>> >
>> >
>> > Bert Gunter
>> >
>> > "The trouble with having an open mind is that people keep coming along
>> and
>> > sticking things into it."
>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >
>> >
>> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>> > wrote:
>> >
>> >> Dear friends,
>> >>
>> >> Hope you are doing great. I want to fit a logistic regression in R,
>> where
>> >> the dependent variable is the covid status (I used 1 for covid
>> positives,
>> >> and 0 for covid negatives), but when I ran the glm, R complains that I
>> >> should make the dependent variable a factor.
>> >>
>> >> What would be more advisable, to keep the dependent variable with 1s
>> and
>> >> 0s, or code it as yes/no and then make it a factor?
>> >>
>> >> Any guidance will be greatly appreciated,
>> >>
>> >> Best regards,
>> >>
>> >> Paul
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His
>

	[[alternative HTML version deleted]]


From p@u|bern@|07 @end|ng |rom gm@||@com  Sat Aug  1 20:25:57 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Sat, 1 Aug 2020 13:25:57 -0500
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
Message-ID: <CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>

Dear friend,

I am aware that I have a binomial dependent variable, which is covid status
(1 if covid positive, and 0 otherwise).

My question was if R requires to turn a binomial response variable into a
factor or not, that's all.

Cheers,

Paul

El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter <bgunter.4567 at gmail.com>
escribi?:

> ... yes, but so does lm() for a categorical **INdependent** variable with
> more than 2 numerically labeled levels. n levels  = (n-1) df for a
> categorical covariate, but 1 for a continuous one (unless more complex
> models are explicitly specified of course). As I said, the OP seems
> confused about whether he is referring to the response or covariates. Or
> maybe he just made the same typo I did.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
> malone at malonequantitative.com> wrote:
>
>> No, R does not. glm() does in order to do logistic regression.
>>
>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Hi Bert,
>>>
>>> Thank you for the kind reply.
>>>
>>> But what if I don't turn the variable into a factor. Let's say that in
>>> excel I just coded the variable as 1s and 0s and just imported the
>>> dataset
>>> into R and fitted the logistic regression without turning any categorical
>>> variable or dummy variable into a factor?
>>>
>>> Does R requires every dummy variable to be treated as a factor?
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>> bgunter.4567 at gmail.com> escribi?:
>>>
>>> > x <- factor(0:1)
>>> > x <- factor("yes","no")
>>> >
>>> > will produce identical results up to labeling.
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> and
>>> > sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> > wrote:
>>> >
>>> >> Dear friends,
>>> >>
>>> >> Hope you are doing great. I want to fit a logistic regression in R,
>>> where
>>> >> the dependent variable is the covid status (I used 1 for covid
>>> positives,
>>> >> and 0 for covid negatives), but when I ran the glm, R complains that I
>>> >> should make the dependent variable a factor.
>>> >>
>>> >> What would be more advisable, to keep the dependent variable with 1s
>>> and
>>> >> 0s, or code it as yes/no and then make it a factor?
>>> >>
>>> >> Any guidance will be greatly appreciated,
>>> >>
>>> >> Best regards,
>>> >>
>>> >> Paul
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Patrick S. Malone, Ph.D., Malone Quantitative
>> NEW Service Models: http://malonequantitative.com
>>
>> He/Him/His
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:13:59 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:13:59 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
Message-ID: <CAGxFJbRR3_Bukb4p26j1TmMHnMeJUw235BykntnLsPRFaJbYug@mail.gmail.com>

Sorry, typo.My first sentences should read:

"You appear to be confusing a binomial **response** with categorical
"independent variables." glm() of course fits continuous or categorical
independent variables."

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:11 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You appear to be confusing a binomial **response** with categorical
> "dependent variables." glm() of course fits continuous or categorical
> dependent variables. If a continuous dependent variable has only 2 values,
> the results for glm() will be the same whether or not it is considered to
> be continuous or categorical, though you may not recognize it as such.
>
> This discussion has already wandered off topic to statistical issues. I
> will not comment further on or off list. I suggest you consult a good
> reference on linear/generalized linear models or talk with a local
> statistician.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:04 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Hi Bert,
>>
>> Thank you for the kind reply.
>>
>> But what if I don't turn the variable into a factor. Let's say that in
>> excel I just coded the variable as 1s and 0s and just imported the dataset
>> into R and fitted the logistic regression without turning any categorical
>> variable or dummy variable into a factor?
>>
>> Does R requires every dummy variable to be treated as a factor?
>>
>> Best regards,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>> bgunter.4567 at gmail.com> escribi?:
>>
>>> x <- factor(0:1)
>>> x <- factor("yes","no")
>>>
>>> will produce identical results up to labeling.
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>
>>>> Dear friends,
>>>>
>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>> where
>>>> the dependent variable is the covid status (I used 1 for covid
>>>> positives,
>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>>> should make the dependent variable a factor.
>>>>
>>>> What would be more advisable, to keep the dependent variable with 1s and
>>>> 0s, or code it as yes/no and then make it a factor?
>>>>
>>>> Any guidance will be greatly appreciated,
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:15:08 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:15:08 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>
Message-ID: <CAGxFJbR_Nt_ZfB6sYL0md2GkS58f6=5EDM6vG0sYRTu+87Ld_g@mail.gmail.com>

... and further:
" If a continuous independent variable has only 2 values,..."

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:11 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> You appear to be confusing a binomial **response** with categorical
> "dependent variables." glm() of course fits continuous or categorical
> dependent variables. If a continuous dependent variable has only 2 values,
> the results for glm() will be the same whether or not it is considered to
> be continuous or categorical, though you may not recognize it as such.
>
> This discussion has already wandered off topic to statistical issues. I
> will not comment further on or off list. I suggest you consult a good
> reference on linear/generalized linear models or talk with a local
> statistician.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:04 AM Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Hi Bert,
>>
>> Thank you for the kind reply.
>>
>> But what if I don't turn the variable into a factor. Let's say that in
>> excel I just coded the variable as 1s and 0s and just imported the dataset
>> into R and fitted the logistic regression without turning any categorical
>> variable or dummy variable into a factor?
>>
>> Does R requires every dummy variable to be treated as a factor?
>>
>> Best regards,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>> bgunter.4567 at gmail.com> escribi?:
>>
>>> x <- factor(0:1)
>>> x <- factor("yes","no")
>>>
>>> will produce identical results up to labeling.
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>
>>>> Dear friends,
>>>>
>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>> where
>>>> the dependent variable is the covid status (I used 1 for covid
>>>> positives,
>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>>> should make the dependent variable a factor.
>>>>
>>>> What would be more advisable, to keep the dependent variable with 1s and
>>>> 0s, or code it as yes/no and then make it a factor?
>>>>
>>>> Any guidance will be greatly appreciated,
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Aug  1 20:15:29 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 1 Aug 2020 14:15:29 -0400
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
Message-ID: <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>

No, R does not. glm() does in order to do logistic regression.

On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Hi Bert,
>
> Thank you for the kind reply.
>
> But what if I don't turn the variable into a factor. Let's say that in
> excel I just coded the variable as 1s and 0s and just imported the dataset
> into R and fitted the logistic regression without turning any categorical
> variable or dummy variable into a factor?
>
> Does R requires every dummy variable to be treated as a factor?
>
> Best regards,
>
> Paul
>
> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
> bgunter.4567 at gmail.com> escribi?:
>
> > x <- factor(0:1)
> > x <- factor("yes","no")
> >
> > will produce identical results up to labeling.
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and
> > sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
> > wrote:
> >
> >> Dear friends,
> >>
> >> Hope you are doing great. I want to fit a logistic regression in R,
> where
> >> the dependent variable is the covid status (I used 1 for covid
> positives,
> >> and 0 for covid negatives), but when I ran the glm, R complains that I
> >> should make the dependent variable a factor.
> >>
> >> What would be more advisable, to keep the dependent variable with 1s and
> >> 0s, or code it as yes/no and then make it a factor?
> >>
> >> Any guidance will be greatly appreciated,
> >>
> >> Best regards,
> >>
> >> Paul
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug  1 20:11:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 1 Aug 2020 11:11:15 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
Message-ID: <CAGxFJbQkAzzOcYGgBjYi3nk+YbpDVrENva8K+zGQjn9wVSaCnA@mail.gmail.com>

You appear to be confusing a binomial **response** with categorical
"dependent variables." glm() of course fits continuous or categorical
dependent variables. If a continuous dependent variable has only 2 values,
the results for glm() will be the same whether or not it is considered to
be continuous or categorical, though you may not recognize it as such.

This discussion has already wandered off topic to statistical issues. I
will not comment further on or off list. I suggest you consult a good
reference on linear/generalized linear models or talk with a local
statistician.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 1, 2020 at 11:04 AM Paul Bernal <paulbernal07 at gmail.com> wrote:

> Hi Bert,
>
> Thank you for the kind reply.
>
> But what if I don't turn the variable into a factor. Let's say that in
> excel I just coded the variable as 1s and 0s and just imported the dataset
> into R and fitted the logistic regression without turning any categorical
> variable or dummy variable into a factor?
>
> Does R requires every dummy variable to be treated as a factor?
>
> Best regards,
>
> Paul
>
> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
> bgunter.4567 at gmail.com> escribi?:
>
>> x <- factor(0:1)
>> x <- factor("yes","no")
>>
>> will produce identical results up to labeling.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Dear friends,
>>>
>>> Hope you are doing great. I want to fit a logistic regression in R, where
>>> the dependent variable is the covid status (I used 1 for covid positives,
>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>> should make the dependent variable a factor.
>>>
>>> What would be more advisable, to keep the dependent variable with 1s and
>>> 0s, or code it as yes/no and then make it a factor?
>>>
>>> Any guidance will be greatly appreciated,
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Sat Aug  1 21:01:29 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Sat, 1 Aug 2020 15:01:29 -0400
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
 <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
Message-ID: <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>

Dear Paul,

I think that this thread has gotten unnecessarily complicated. The 
answer, as is easily demonstrated, is that a binary response for a 
binomial GLM in glm() may be a factor, a numeric variable, or a logical 
variable, with identical results; for example:

--------------- snip -------------

 > set.seed(123)

 > head(x <- rnorm(100))
[1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499

 > head(y <- rbinom(100, 1, 1/(1 + exp(-x))))
[1] 0 1 1 1 1 0

 > head(yf <- as.factor(y))
[1] 0 1 1 1 1 0
Levels: 0 1

 > head(yl <- y == 1)
[1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE

 > glm(y ~ x, family=binomial)

Call:  glm(formula = y ~ x, family = binomial)

Coefficients:
(Intercept)            x
      0.3995       1.1670

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    134.6
Residual Deviance: 114.9 	AIC: 118.9

 > glm(yf ~ x, family=binomial)

Call:  glm(formula = yf ~ x, family = binomial)

Coefficients:
(Intercept)            x
      0.3995       1.1670

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    134.6
Residual Deviance: 114.9 	AIC: 118.9

 > glm(yl ~ x, family=binomial)

Call:  glm(formula = yl ~ x, family = binomial)

Coefficients:
(Intercept)            x
      0.3995       1.1670

Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
Null Deviance:	    134.6
Residual Deviance: 114.9 	AIC: 118.9

--------------- snip -------------

The original poster claimed to have encountered an error with a 0/1 
numeric response, but didn't show any data or even a command. I suspect 
that the response was a character variable, but of course can't really 
know that.

Best,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-08-01 2:25 p.m., Paul Bernal wrote:
> Dear friend,
> 
> I am aware that I have a binomial dependent variable, which is covid status
> (1 if covid positive, and 0 otherwise).
> 
> My question was if R requires to turn a binomial response variable into a
> factor or not, that's all.
> 
> Cheers,
> 
> Paul
> 
> El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter <bgunter.4567 at gmail.com>
> escribi?:
> 
>> ... yes, but so does lm() for a categorical **INdependent** variable with
>> more than 2 numerically labeled levels. n levels  = (n-1) df for a
>> categorical covariate, but 1 for a continuous one (unless more complex
>> models are explicitly specified of course). As I said, the OP seems
>> confused about whether he is referring to the response or covariates. Or
>> maybe he just made the same typo I did.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
>> malone at malonequantitative.com> wrote:
>>
>>> No, R does not. glm() does in order to do logistic regression.
>>>
>>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>>> wrote:
>>>
>>>> Hi Bert,
>>>>
>>>> Thank you for the kind reply.
>>>>
>>>> But what if I don't turn the variable into a factor. Let's say that in
>>>> excel I just coded the variable as 1s and 0s and just imported the
>>>> dataset
>>>> into R and fitted the logistic regression without turning any categorical
>>>> variable or dummy variable into a factor?
>>>>
>>>> Does R requires every dummy variable to be treated as a factor?
>>>>
>>>> Best regards,
>>>>
>>>> Paul
>>>>
>>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>>> bgunter.4567 at gmail.com> escribi?:
>>>>
>>>>> x <- factor(0:1)
>>>>> x <- factor("yes","no")
>>>>>
>>>>> will produce identical results up to labeling.
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>> and
>>>>> sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Dear friends,
>>>>>>
>>>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>> where
>>>>>> the dependent variable is the covid status (I used 1 for covid
>>>> positives,
>>>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
>>>>>> should make the dependent variable a factor.
>>>>>>
>>>>>> What would be more advisable, to keep the dependent variable with 1s
>>>> and
>>>>>> 0s, or code it as yes/no and then make it a factor?
>>>>>>
>>>>>> Any guidance will be greatly appreciated,
>>>>>>
>>>>>> Best regards,
>>>>>>
>>>>>> Paul
>>>>>>
>>>>>>          [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>
>>>>          [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> Patrick S. Malone, Ph.D., Malone Quantitative
>>> NEW Service Models: http://malonequantitative.com
>>>
>>> He/Him/His
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  1 21:09:47 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Aug 2020 20:09:47 +0100
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <0f71fcba-2503-6373-5c41-03abefc16e85@sapo.pt>

Hello,

 From the documentation, help('glm'):


      Details

A typical predictor has the form|response ~ terms|where|response|is the 
(numeric) response vector and|terms|is a series of terms which specifies 
a linear predictor for|response|. 
For|binomial|and|quasibinomial|families the response can also be 
specified as a|factor 
<http://127.0.0.1:11611/library/stats/help/factor>|(when the first level 
denotes failure and all others success) or as a two-column matrix with 
the columns giving the numbers of successes and failures. A terms 
specification of the form|first + second|indicates all the terms 
in|first|together with all the terms in|second|with any duplicates removed.


There is no need for the response to be a factor, it is optional, the 
wording is very clear,

"For|binomial|and|quasibinomial|families the response *can* also be 
specified as a|factor <http://127.0.0.1:11611/library/stats/help/factor>"|

And with binary, numeric responses I cannot reproduce the warning 
message, the models fit silently.


Hope this helps,

Rui Barradas




?s 18:39 de 01/08/2020, Paul Bernal escreveu:
> Dear friends,
>
> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
>
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?
>
> Any guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Sat Aug  1 20:38:16 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Sat, 1 Aug 2020 14:38:16 -0400
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
Message-ID: <CAJc=yOGL3O83tQs3r1nfp6hkjGJn7RjsS9jQ3wQyNYWrS0DKaA@mail.gmail.com>

I didn't mean to imply that was the only time that it was required, only
that it's not universal in R.

On Sat, Aug 1, 2020 at 2:22 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... yes, but so does lm() for a categorical **INdependent** variable with
> more than 2 numerically labeled levels. n levels  = (n-1) df for a
> categorical covariate, but 1 for a continuous one (unless more complex
> models are explicitly specified of course). As I said, the OP seems
> confused about whether he is referring to the response or covariates. Or
> maybe he just made the same typo I did.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
> malone at malonequantitative.com> wrote:
>
>> No, R does not. glm() does in order to do logistic regression.
>>
>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>>
>>> Hi Bert,
>>>
>>> Thank you for the kind reply.
>>>
>>> But what if I don't turn the variable into a factor. Let's say that in
>>> excel I just coded the variable as 1s and 0s and just imported the
>>> dataset
>>> into R and fitted the logistic regression without turning any categorical
>>> variable or dummy variable into a factor?
>>>
>>> Does R requires every dummy variable to be treated as a factor?
>>>
>>> Best regards,
>>>
>>> Paul
>>>
>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>> bgunter.4567 at gmail.com> escribi?:
>>>
>>> > x <- factor(0:1)
>>> > x <- factor("yes","no")
>>> >
>>> > will produce identical results up to labeling.
>>> >
>>> >
>>> > Bert Gunter
>>> >
>>> > "The trouble with having an open mind is that people keep coming along
>>> and
>>> > sticking things into it."
>>> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> >
>>> >
>>> > On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>> > wrote:
>>> >
>>> >> Dear friends,
>>> >>
>>> >> Hope you are doing great. I want to fit a logistic regression in R,
>>> where
>>> >> the dependent variable is the covid status (I used 1 for covid
>>> positives,
>>> >> and 0 for covid negatives), but when I ran the glm, R complains that I
>>> >> should make the dependent variable a factor.
>>> >>
>>> >> What would be more advisable, to keep the dependent variable with 1s
>>> and
>>> >> 0s, or code it as yes/no and then make it a factor?
>>> >>
>>> >> Any guidance will be greatly appreciated,
>>> >>
>>> >> Best regards,
>>> >>
>>> >> Paul
>>> >>
>>> >>         [[alternative HTML version deleted]]
>>> >>
>>> >> ______________________________________________
>>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Patrick S. Malone, Ph.D., Malone Quantitative
>> NEW Service Models: http://malonequantitative.com
>>
>> He/Him/His
>>
>

-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  1 21:48:12 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Aug 2020 20:48:12 +0100
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
 <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
 <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
Message-ID: <feffe1d6-fc95-29ed-24bc-7e8c5419b959@sapo.pt>

Hello,

Inline.

?s 20:01 de 01/08/2020, John Fox escreveu:
> Dear Paul,
>
> I think that this thread has gotten unnecessarily complicated. The 
> answer, as is easily demonstrated, is that a binary response for a 
> binomial GLM in glm() may be a factor, a numeric variable, or a 
> logical variable, with identical results; for example:
>
> --------------- snip -------------
>
> > set.seed(123)
>
> > head(x <- rnorm(100))
> [1] -0.56047565 -0.23017749? 1.55870831? 0.07050839? 0.12928774 
> 1.71506499
>
> > head(y <- rbinom(100, 1, 1/(1 + exp(-x))))
> [1] 0 1 1 1 1 0
>
> > head(yf <- as.factor(y))
> [1] 0 1 1 1 1 0
> Levels: 0 1
>
> > head(yl <- y == 1)
> [1] FALSE? TRUE? TRUE? TRUE? TRUE FALSE
>
> > glm(y ~ x, family=binomial)
>
> Call:? glm(formula = y ~ x, family = binomial)
>
> Coefficients:
> (Intercept)??????????? x
> ???? 0.3995?????? 1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);? 98 Residual
> Null Deviance:??????? 134.6
> Residual Deviance: 114.9???? AIC: 118.9
>
> > glm(yf ~ x, family=binomial)
>
> Call:? glm(formula = yf ~ x, family = binomial)
>
> Coefficients:
> (Intercept)??????????? x
> ???? 0.3995?????? 1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);? 98 Residual
> Null Deviance:??????? 134.6
> Residual Deviance: 114.9???? AIC: 118.9
>
> > glm(yl ~ x, family=binomial)
>
> Call:? glm(formula = yl ~ x, family = binomial)
>
> Coefficients:
> (Intercept)??????????? x
> ???? 0.3995?????? 1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);? 98 Residual
> Null Deviance:??????? 134.6
> Residual Deviance: 114.9???? AIC: 118.9
>
> --------------- snip -------------
>
> The original poster claimed to have encountered an error with a 0/1 
> numeric response, but didn't show any data or even a command. I 
> suspect that the response was a character variable, but of course 
> can't really know that.

So continuing with your example:

 > head(yc <- as.character(y))
[1] "0" "1" "1" "1" "1" "0"
 > glm(yc ~ x, family=binomial)
Error in weights * y : non-numeric argument to binary operator


But the OP says that

[...] R complains that I should make the dependent variable a factor.

That is not what the error message says, it "asks" for a numeric 
argument to the '*' operator.
We haven't seen the exact R message yet, so, like others have said, the 
OP should post it along with code.

Hope this helps,

Rui Barradas

>
> Best,
> ?John
>
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> On 2020-08-01 2:25 p.m., Paul Bernal wrote:
>> Dear friend,
>>
>> I am aware that I have a binomial dependent variable, which is covid 
>> status
>> (1 if covid positive, and 0 otherwise).
>>
>> My question was if R requires to turn a binomial response variable 
>> into a
>> factor or not, that's all.
>>
>> Cheers,
>>
>> Paul
>>
>> El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter 
>> <bgunter.4567 at gmail.com>
>> escribi?:
>>
>>> ... yes, but so does lm() for a categorical **INdependent** variable 
>>> with
>>> more than 2 numerically labeled levels. n levels? = (n-1) df for a
>>> categorical covariate, but 1 for a continuous one (unless more complex
>>> models are explicitly specified of course). As I said, the OP seems
>>> confused about whether he is referring to the response or 
>>> covariates. Or
>>> maybe he just made the same typo I did.
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming 
>>> along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
>>> malone at malonequantitative.com> wrote:
>>>
>>>> No, R does not. glm() does in order to do logistic regression.
>>>>
>>>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Bert,
>>>>>
>>>>> Thank you for the kind reply.
>>>>>
>>>>> But what if I don't turn the variable into a factor. Let's say 
>>>>> that in
>>>>> excel I just coded the variable as 1s and 0s and just imported the
>>>>> dataset
>>>>> into R and fitted the logistic regression without turning any 
>>>>> categorical
>>>>> variable or dummy variable into a factor?
>>>>>
>>>>> Does R requires every dummy variable to be treated as a factor?
>>>>>
>>>>> Best regards,
>>>>>
>>>>> Paul
>>>>>
>>>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
>>>>> bgunter.4567 at gmail.com> escribi?:
>>>>>
>>>>>> x <- factor(0:1)
>>>>>> x <- factor("yes","no")
>>>>>>
>>>>>> will produce identical results up to labeling.
>>>>>>
>>>>>>
>>>>>> Bert Gunter
>>>>>>
>>>>>> "The trouble with having an open mind is that people keep coming 
>>>>>> along
>>>>> and
>>>>>> sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>
>>>>>>
>>>>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Dear friends,
>>>>>>>
>>>>>>> Hope you are doing great. I want to fit a logistic regression in R,
>>>>> where
>>>>>>> the dependent variable is the covid status (I used 1 for covid
>>>>> positives,
>>>>>>> and 0 for covid negatives), but when I ran the glm, R complains 
>>>>>>> that I
>>>>>>> should make the dependent variable a factor.
>>>>>>>
>>>>>>> What would be more advisable, to keep the dependent variable 
>>>>>>> with 1s
>>>>> and
>>>>>>> 0s, or code it as yes/no and then make it a factor?
>>>>>>>
>>>>>>> Any guidance will be greatly appreciated,
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> Paul
>>>>>>>
>>>>>>> ???????? [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>
>>>>> ???????? [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>> -- 
>>>> Patrick S. Malone, Ph.D., Malone Quantitative
>>>> NEW Service Models: http://malonequantitative.com
>>>>
>>>> He/Him/His
>>>>
>>>
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Sat Aug  1 21:52:19 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Sat, 1 Aug 2020 15:52:19 -0400
Subject: [R] RNA Seq Analysis in R
In-Reply-To: <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>
References: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
 <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>
Message-ID: <a43bbcd2-1063-69f9-09d4-234aec529cff@molbio.mgh.harvard.edu>

As with the previous post, I agree that Bioconductor will be a better 
place to ask this question.

As a quick thought you also might try to adjust the p-value in the last 
line:

DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2). You could play 
around with the P.Value, 0.01 is pretty low, you could try 0.05 and 
maybe abs(logFC) > 1.

But, first you should try to print out tT with something like 
write.table(tT, file = TopTable.txt, sep = "\t").

This will write out tT to a tab-delimited text file (in the directory 
that you are working in) that you can import into Excel and then inspect 
the logFC and p-values for the top 1250 genes.

Matthew

On 8/1/20 1:13 PM, Jeff Newmiller wrote:
>          External Email - Use Caution
>
> https://www.bioconductor.org/help/
>
> On August 1, 2020 4:01:08 AM PDT, Anas Jamshed <anasjamshed1994 at gmail.com> wrote:
>> I choose microarray data GSE75693 of 30 patients with stable kidney
>> transplantation and 15 with BKVN to identify differentially expressed
>> genes
>> (DEGs). I performed this in GEO2R and find R script there and Runs R
>> script
>> Successfully on R studio as well. The R script is :
>>
>> # Differential expression analysis with limma
>>
>> library(Biobase)
>> library(GEOquery)
>> library(limma)
>> # load series and platform data from GEO
>>
>> gset <- getGEO("GSE75693", GSEMatrix =TRUE, AnnotGPL=TRUE)if
>> (length(gset) > 1) idx <- grep("GPL570", attr(gset, "names")) else idx
>> <- 1
>> gset <- gset[[idx]]
>> # make proper column names to match toptable
>> fvarLabels(gset) <- make.names(fvarLabels(gset))
>> # group names for all samples
>> gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
>>         "1111111111XXXXXXXXXXXXXXXXXXX")
>> sml <- c()for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
>> # eliminate samples marked as "X"
>> sel <- which(sml != "X")
>> sml <- sml[sel]
>> gset <- gset[ ,sel]
>> # log2 transform
>> exprs(gset) <- log2(exprs(gset))
>> # set up the data and proceed with analysis
>> sml <- paste("G", sml, sep="")    # set group names
>> fl <- as.factor(sml)
>> gset$description <- fl
>> design <- model.matrix(~ description + 0, gset)
>> colnames(design) <- levels(fl)
>> fit <- lmFit(gset, design)
>> cont.matrix <- makeContrasts(G1-G0, levels=design)
>> fit2 <- contrasts.fit(fit, cont.matrix)
>> fit2 <- eBayes(fit2, 0.01)
>> tT <- topTable(fit2, adjust="fdr", sort.by="B", number=1250)
>>
>> tT <- subset(tT,
>> select=c("ID","adj.P.Val","P.Value","t","B","logFC","Gene.symbol","Gene.title"))
>> DEGs = subset(tT, P.Value < 0.01 & abs(logFC) > 2)
>>
>> After running this no genes are found plz help me
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Sat Aug  1 22:09:47 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sat, 1 Aug 2020 13:09:47 -0700
Subject: [R] Dependent Variable in Logistic Regression
In-Reply-To: <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <CAGxFJbROMurnTq0HJwhzzLo1mRK9fZA9BED4-+9+FWHY6D9p0A@mail.gmail.com>
 <CAMOcQfPUWqn05x4++QUCKReTUnjQisyKuLgXRyUGh4T8rS_J7A@mail.gmail.com>
 <CAJc=yOEUVLhsX7wLSNjX3UMmhg5VagMThJLZu5Vzb6DWd_F-UA@mail.gmail.com>
 <CAGxFJbTfvRc7BRHsdy-mvj-FMsigPotSyn7O+N7jU2D+4VMRwQ@mail.gmail.com>
 <20623_1596307270_071If9r3008374_CAMOcQfNX0rf1kcXQLnr3-gO4L7yNupsvhqwn-zeH3rnn2PHTaQ@mail.gmail.com>
 <bf7cb4e6-0b2c-25e4-dee7-215fd2d11fa2@mcmaster.ca>
Message-ID: <CAF8bMcYBu3c3stF3H=s_N-Anu2DFQ2BNDSzjSVRFjveBqEDENg@mail.gmail.com>

I like using a logical response in cases like this, but put its
construction in the formula so it is unambiguous when I look at the
results later.
> d <- data.frame(Covid=c("Pos","Pos","Neg","Pos","Neg","Neg"), Age=41:46)
> glm(family=binomial, data=d, Covid=="Pos"~Age)

Call:  glm(formula = Covid == "Pos" ~ Age, family = binomial, data = d)

Coefficients:
(Intercept)          Age
     52.810       -1.214

Degrees of Freedom: 5 Total (i.e. Null);  4 Residual
Null Deviance:      8.318
Residual Deviance: 4.956        AIC: 8.956


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Aug 1, 2020 at 12:21 PM John Fox <jfox at mcmaster.ca> wrote:
>
> Dear Paul,
>
> I think that this thread has gotten unnecessarily complicated. The
> answer, as is easily demonstrated, is that a binary response for a
> binomial GLM in glm() may be a factor, a numeric variable, or a logical
> variable, with identical results; for example:
>
> --------------- snip -------------
>
>  > set.seed(123)
>
>  > head(x <- rnorm(100))
> [1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774  1.71506499
>
>  > head(y <- rbinom(100, 1, 1/(1 + exp(-x))))
> [1] 0 1 1 1 1 0
>
>  > head(yf <- as.factor(y))
> [1] 0 1 1 1 1 0
> Levels: 0 1
>
>  > head(yl <- y == 1)
> [1] FALSE  TRUE  TRUE  TRUE  TRUE FALSE
>
>  > glm(y ~ x, family=binomial)
>
> Call:  glm(formula = y ~ x, family = binomial)
>
> Coefficients:
> (Intercept)            x
>       0.3995       1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:      134.6
> Residual Deviance: 114.9        AIC: 118.9
>
>  > glm(yf ~ x, family=binomial)
>
> Call:  glm(formula = yf ~ x, family = binomial)
>
> Coefficients:
> (Intercept)            x
>       0.3995       1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:      134.6
> Residual Deviance: 114.9        AIC: 118.9
>
>  > glm(yl ~ x, family=binomial)
>
> Call:  glm(formula = yl ~ x, family = binomial)
>
> Coefficients:
> (Intercept)            x
>       0.3995       1.1670
>
> Degrees of Freedom: 99 Total (i.e. Null);  98 Residual
> Null Deviance:      134.6
> Residual Deviance: 114.9        AIC: 118.9
>
> --------------- snip -------------
>
> The original poster claimed to have encountered an error with a 0/1
> numeric response, but didn't show any data or even a command. I suspect
> that the response was a character variable, but of course can't really
> know that.
>
> Best,
>   John
>
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
>
> On 2020-08-01 2:25 p.m., Paul Bernal wrote:
> > Dear friend,
> >
> > I am aware that I have a binomial dependent variable, which is covid status
> > (1 if covid positive, and 0 otherwise).
> >
> > My question was if R requires to turn a binomial response variable into a
> > factor or not, that's all.
> >
> > Cheers,
> >
> > Paul
> >
> > El s?b., 1 de agosto de 2020 1:22 p. m., Bert Gunter <bgunter.4567 at gmail.com>
> > escribi?:
> >
> >> ... yes, but so does lm() for a categorical **INdependent** variable with
> >> more than 2 numerically labeled levels. n levels  = (n-1) df for a
> >> categorical covariate, but 1 for a continuous one (unless more complex
> >> models are explicitly specified of course). As I said, the OP seems
> >> confused about whether he is referring to the response or covariates. Or
> >> maybe he just made the same typo I did.
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Sat, Aug 1, 2020 at 11:15 AM Patrick (Malone Quantitative) <
> >> malone at malonequantitative.com> wrote:
> >>
> >>> No, R does not. glm() does in order to do logistic regression.
> >>>
> >>> On Sat, Aug 1, 2020 at 2:11 PM Paul Bernal <paulbernal07 at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi Bert,
> >>>>
> >>>> Thank you for the kind reply.
> >>>>
> >>>> But what if I don't turn the variable into a factor. Let's say that in
> >>>> excel I just coded the variable as 1s and 0s and just imported the
> >>>> dataset
> >>>> into R and fitted the logistic regression without turning any categorical
> >>>> variable or dummy variable into a factor?
> >>>>
> >>>> Does R requires every dummy variable to be treated as a factor?
> >>>>
> >>>> Best regards,
> >>>>
> >>>> Paul
> >>>>
> >>>> El s?b., 1 de agosto de 2020 12:59 p. m., Bert Gunter <
> >>>> bgunter.4567 at gmail.com> escribi?:
> >>>>
> >>>>> x <- factor(0:1)
> >>>>> x <- factor("yes","no")
> >>>>>
> >>>>> will produce identical results up to labeling.
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming along
> >>>> and
> >>>>> sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Sat, Aug 1, 2020 at 10:40 AM Paul Bernal <paulbernal07 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> Dear friends,
> >>>>>>
> >>>>>> Hope you are doing great. I want to fit a logistic regression in R,
> >>>> where
> >>>>>> the dependent variable is the covid status (I used 1 for covid
> >>>> positives,
> >>>>>> and 0 for covid negatives), but when I ran the glm, R complains that I
> >>>>>> should make the dependent variable a factor.
> >>>>>>
> >>>>>> What would be more advisable, to keep the dependent variable with 1s
> >>>> and
> >>>>>> 0s, or code it as yes/no and then make it a factor?
> >>>>>>
> >>>>>> Any guidance will be greatly appreciated,
> >>>>>>
> >>>>>> Best regards,
> >>>>>>
> >>>>>> Paul
> >>>>>>
> >>>>>>          [[alternative HTML version deleted]]
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>
> >>>>
> >>>>          [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> Patrick S. Malone, Ph.D., Malone Quantitative
> >>> NEW Service Models: http://malonequantitative.com
> >>>
> >>> He/Him/His
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Sun Aug  2 01:34:18 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sun, 2 Aug 2020 01:34:18 +0200
Subject: [R] RNA Seq Analysis in R
In-Reply-To: <a43bbcd2-1063-69f9-09d4-234aec529cff@molbio.mgh.harvard.edu>
References: <CAG0CrLjk82DdbWYPUk0_+SEpJORM9ZCAPRN7UThzd1qJu5RZVA@mail.gmail.com>
 <4776E357-58F1-4702-A4A7-145365A1FC82@dcn.davis.ca.us>
 <a43bbcd2-1063-69f9-09d4-234aec529cff@molbio.mgh.harvard.edu>
Message-ID: <20200801233418.GA303455@posteo.no>

On 2020-08-01 15:52 -0400, Matthew McCormack wrote:
| On 8/1/20 1:13 PM, Jeff Newmiller wrote:
| | On August 1, 2020 4:01:08 AM PDT, Anas Jamshed wrote:
| | | I performed this in GEO2R and find 
| | | R script there and Runs R script 

Anas, how did you come up with this 
script at all by reading the article?

How can you be sure that 
limma::lmFit/limma::eBayes procedure was 
the one Jia et al. used in their 
article?

The three author emails are listed on 
page 1 of the article.

| | | After running this no genes are 
| | | found plz help me
| |
| | https://www.bioconductor.org/help/
| 
| As with the previous post, I agree 
| that Bioconductor will be a better 
| place to ask this question.
| 
| As a quick thought you also might try 
| to adjust the p-value in the last 
| line:
 
This is the "distribution" of 
possible log2 Fold Change in tT:

	> tab <- table(signif(tT$logFC, 1))
	> tab[as.character(sort(
	+   as.numeric(names(tab)),
	+   decreasing=F))]
	 -0.5  -0.4  -0.3  -0.2  -0.1 -0.09   0.1
	    1    25   158   376   185     7    49
	  0.2   0.3   0.4   0.5   0.6   0.7
	  250   140    42    11     4     2

... knowing full well ?regulated? is 
supposed to be abs(logFC)>1, we can 
instead select above .5 there to get 
the few up-regulated ones ...

	> rownames(tT) <- NULL
	> subset(x=tT,
	+   subset=
	+     adj.P.Val < .01 &
	+     abs(logFC) > .5,
	+   select=adj.P.Val:Gene.symbol)
	       adj.P.Val      P.Value        t
	4   7.457501e-05 5.894525e-09 7.075753
	5   7.457501e-05 7.877860e-09 6.993182
	9   1.170092e-04 1.926078e-08 6.738920
	29  2.565179e-04 1.432599e-07 6.168230
	42  3.202947e-04 2.511181e-07 6.008168
	60  4.039665e-04 4.433103e-07 5.845695
	343 1.043185e-03 6.555444e-06 5.066127
	475 1.391091e-03 1.208538e-05 4.885755
	            B     logFC       Gene.symbol
	4   10.264385 0.6225559             REG1A
	5    9.996103 0.6630585              TNMD
	9    9.168329 0.5138611            NKAIN4
	29   7.306904 0.5538644              C1QB
	42   6.785641 0.5530439             ISG20
	60   6.257651 0.5082288              GZMH
	343  3.755608 0.5543619 MIR155///MIR155HG
	475  3.188253 0.7264114            CXCL13

... none of which are in the network of 
important proteins in figure 5 on page 6.

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200802/99d754d3/attachment.sig>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  2 02:46:40 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 2 Aug 2020 12:46:40 +1200
Subject: [R] [FORGED]  Dependent Variable in Logistic Regression
In-Reply-To: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
Message-ID: <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>


On 2/08/20 5:39 am, Paul Bernal wrote:

> Dear friends,
> 
> Hope you are doing great. I want to fit a logistic regression in R, where
> the dependent variable is the covid status (I used 1 for covid positives,
> and 0 for covid negatives), but when I ran the glm, R complains that I
> should make the dependent variable a factor.
> 
> What would be more advisable, to keep the dependent variable with 1s and
> 0s, or code it as yes/no and then make it a factor?
> 
> Any guidance will be greatly appreciated,


There have been many responses to this post, the majority of them being 
confusing and off the point.

BOTTOM LINE:  R/glm() does *NOT* complain that one "should make the 
dependent variable a factor".   This is bovine faecal output.

As Rui Barradas has pointed out (alternatively: RTFM!) when you fit a 
Bernoulli model using glm(), your response/dependent variable is allowed 
to be

     * a numeric variable with values 0 or 1
     * a logical variable
     * a factor with two levels

The OP presumably fed glm() a *character* vector with values "0" and 
"1".  Doing *this* will cause glm() to whinge.

I reiterate:  RTFM!!!  (And perhaps learn to distinguish between 
character vectors and factors.)

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @purd|e@@ @end|ng |rom gm@||@com  Sun Aug  2 05:13:51 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 2 Aug 2020 15:13:51 +1200
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
Message-ID: <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>

That's a bit harsh.
Isn't the best advice here, to post a reproducible example...
Which I believe has been mentioned.

Also, I'd strongly encourage people to use package+function name, for
this sort of thing.

    stats::glm

As there are many R functions for GLMs...


On Sun, Aug 2, 2020 at 12:47 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> On 2/08/20 5:39 am, Paul Bernal wrote:
>
> > Dear friends,
> >
> > Hope you are doing great. I want to fit a logistic regression in R, where
> > the dependent variable is the covid status (I used 1 for covid positives,
> > and 0 for covid negatives), but when I ran the glm, R complains that I
> > should make the dependent variable a factor.
> >
> > What would be more advisable, to keep the dependent variable with 1s and
> > 0s, or code it as yes/no and then make it a factor?
> >
> > Any guidance will be greatly appreciated,
>
>
> There have been many responses to this post, the majority of them being
> confusing and off the point.
>
> BOTTOM LINE:  R/glm() does *NOT* complain that one "should make the
> dependent variable a factor".   This is bovine faecal output.
>
> As Rui Barradas has pointed out (alternatively: RTFM!) when you fit a
> Bernoulli model using glm(), your response/dependent variable is allowed
> to be
>
>      * a numeric variable with values 0 or 1
>      * a logical variable
>      * a factor with two levels
>
> The OP presumably fed glm() a *character* vector with values "0" and
> "1".  Doing *this* will cause glm() to whinge.
>
> I reiterate:  RTFM!!!  (And perhaps learn to distinguish between
> character vectors and factors.)
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From herd_dog @end|ng |rom cox@net  Sun Aug  2 18:24:24 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Sun, 2 Aug 2020 09:24:24 -0700
Subject: [R] Parsing a Date
Message-ID: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>

Below is some Weather Service data.  I would like to parse the forecast date field into four different columns:

    Year
    Month
    Day
    Hour

I would like to drop the final four zeros.  Any suggestions?

forecast.date                 levels      lon           lat         HGT      RH          TMP       UGRD    VGRD
1 2020-08-01 12:00:00 1000 mb -113.130 33.6335 75.5519 49.6484 305.495 1.40155 2.23264
2 2020-08-01 12:00:00 1000 mb -113.111 33.5142 75.9582 51.0234 305.245 1.65155 2.23264
3 2020-08-01 12:00:00 1000 mb -113.092 33.3948 76.3957 52.7734 305.057 1.90155 2.23264
4 2020-08-01 12:00:00 1000 mb -112.987 33.6495 75.9269 49.1484 305.745 1.90155 2.04514
5 2020-08-01 12:00:00 1000 mb -112.968 33.5301 76.3019 50.2734 305.495 2.08905 1.98264

Philip Heinrich



	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sun Aug  2 18:33:17 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 2 Aug 2020 19:33:17 +0300
Subject: [R] Parsing a Date
In-Reply-To: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
Message-ID: <CAGgJW76f=AScpyt0sp41wgWR-RvvuGcGVoCRAAoUK5nG_j-dBw@mail.gmail.com>

If the forecast.date column is of type character you can use lubridate to
do this:

> library(lubridate)
> a <- "2020-08-01 12:00:00"
> year(a)
# [1] 2020
> month(a)
# [1] 8

etc


On Sun, Aug 2, 2020 at 7:24 PM Philip <herd_dog at cox.net> wrote:

> Below is some Weather Service data.  I would like to parse the forecast
> date field into four different columns:
>
>     Year
>     Month
>     Day
>     Hour
>
> I would like to drop the final four zeros.  Any suggestions?
>
> forecast.date                 levels      lon           lat         HGT
>   RH          TMP       UGRD    VGRD
> 1 2020-08-01 12:00:00 1000 mb -113.130 33.6335 75.5519 49.6484 305.495
> 1.40155 2.23264
> 2 2020-08-01 12:00:00 1000 mb -113.111 33.5142 75.9582 51.0234 305.245
> 1.65155 2.23264
> 3 2020-08-01 12:00:00 1000 mb -113.092 33.3948 76.3957 52.7734 305.057
> 1.90155 2.23264
> 4 2020-08-01 12:00:00 1000 mb -112.987 33.6495 75.9269 49.1484 305.745
> 1.90155 2.04514
> 5 2020-08-01 12:00:00 1000 mb -112.968 33.5301 76.3019 50.2734 305.495
> 2.08905 1.98264
>
> Philip Heinrich
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug  2 18:56:21 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 02 Aug 2020 09:56:21 -0700
Subject: [R] Parsing a Date
In-Reply-To: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
Message-ID: <887C5EFE-C578-45A9-BAEF-91DDC29B6F67@dcn.davis.ca.us>

Learn to post plain text and use dput to include data:

dta <- structure(list(forecast.date = c("2020-08-01 12:00:00", "2020-08-01 12:00:00", "2020-08-01 12:00:00", "2020-08-01 12:00:00", "2020-08-01 12:00:00" ), levels = c("1000 mb", "1000 mb", "1000 mb", "1000 mb", "1000 mb" ), lon = c(-113.13, -113.111, -113.092, -112.987, -112.968), lat = c(33.6335, 33.5142, 33.3948, 33.6495, 33.5301), HGT = c(75.5519, 75.9582, 76.3957, 75.9269, 76.3019), RH = c(49.6484, 51.0234, 52.7734, 49.1484, 50.2734), TMP = c(305.495, 305.245, 305.057, 305.745, 305.495), UGRD = c(1.40155, 1.65155, 1.90155, 1.90155, 2.08905), VGRD = c(2.23264, 2.23264, 2.23264, 2.04514, 1.98264 )), .Names = c("forecast.date", "levels", "lon", "lat", "HGT", "RH", "TMP", "UGRD", "VGRD"), class = "data.frame", row.names = c(NA, -5L))

dta$Year <- as.integer( substr( dta$forecast.date, 1, 4 ) )
dta$Month <- as.integer( substr( dta$forecast.date, 6, 7 ) )
dta$Day <- as.integer( substr( dta$forecast.date, 9, 10 ) )
dta$Hour <- as.integer( substr( dta$forecast.date, 12, 13 ) )
dta


On August 2, 2020 9:24:24 AM PDT, Philip <herd_dog at cox.net> wrote:
>Below is some Weather Service data.  I would like to parse the forecast
>date field into four different columns:
>
>    Year
>    Month
>    Day
>    Hour
>
>I would like to drop the final four zeros.  Any suggestions?
>
>forecast.date                 levels      lon           lat         HGT
>     RH          TMP       UGRD    VGRD
>1 2020-08-01 12:00:00 1000 mb -113.130 33.6335 75.5519 49.6484 305.495
>1.40155 2.23264
>2 2020-08-01 12:00:00 1000 mb -113.111 33.5142 75.9582 51.0234 305.245
>1.65155 2.23264
>3 2020-08-01 12:00:00 1000 mb -113.092 33.3948 76.3957 52.7734 305.057
>1.90155 2.23264
>4 2020-08-01 12:00:00 1000 mb -112.987 33.6495 75.9269 49.1484 305.745
>1.90155 2.04514
>5 2020-08-01 12:00:00 1000 mb -112.968 33.5301 76.3019 50.2734 305.495
>2.08905 1.98264
>
>Philip Heinrich
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Sun Aug  2 19:26:48 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sun, 2 Aug 2020 19:26:48 +0200
Subject: [R] Parsing a Date
In-Reply-To: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
Message-ID: <20200802172648.GE1827@posteo.no>

On 2020-08-02 09:24 -0700, Philip wrote:
| Below is some Weather Service data.  I 
| would like to parse the forecast date 
| field into four different columns: 
| Year, Month, Day, Hour

Dear Philip,

I'm largely re-iterating Eric and Jeff's 
excellent solutions:

	> dat <- structure(list(forecast.date =
	+ c("2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00",
	+ "2020-08-01 12:00:00"
	+ ), TMP = c("305.495", "305.245",
	+ "305.057", "305.745", "305.495"
	+ )), row.names = c(NA, 5L),
	+ class = "data.frame")
	> t(apply(simplify2array(
	+   strsplit(dat$forecast.date, "-| |:")),
	+   2, as.numeric))
	     [,1] [,2] [,3] [,4] [,5] [,6]
	[1,] 2020    8    1   12    0    0
	[2,] 2020    8    1   12    0    0
	[3,] 2020    8    1   12    0    0
	[4,] 2020    8    1   12    0    0
	[5,] 2020    8    1   12    0    0
	> simplify2array(parallel::mclapply(c(
	+   lubridate::year,
	+   lubridate::month,
	+   lubridate::day,
	+   lubridate::hour), function(FUN, x) {
	+     FUN(x)
	+   }, x=dat$forecast.date))
	     [,1] [,2] [,3] [,4]
	[1,] 2020    8    1   12
	[2,] 2020    8    1   12
	[3,] 2020    8    1   12
	[4,] 2020    8    1   12
	[5,] 2020    8    1   12

V

r

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200802/465df8ed/attachment.sig>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  2 23:54:21 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 2 Aug 2020 22:54:21 +0100
Subject: [R] Parsing a Date
In-Reply-To: <20200802172648.GE1827@posteo.no>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
 <20200802172648.GE1827@posteo.no>
Message-ID: <a5e29edb-b03a-dbd0-1b5f-37f9e8bde4cd@sapo.pt>

Hello,

And another solution, taking advantage of Rasmus' one:



simplify2array(parallel::mclapply(c(
 ? "%Y",
 ? "%m",
 ? "%d",
 ? "%H"), function(fmt, x) {
 ??? as.integer(format(as.POSIXct(x), format = fmt))
}, x = dta$forecast.date))
#???? [,1] [,2] [,3] [,4]
#[1,] 2020??? 8??? 1?? 12
#[2,] 2020??? 8??? 1?? 12
#[3,] 2020??? 8??? 1?? 12
#[4,] 2020??? 8??? 1?? 12
#[5,] 2020??? 8??? 1?? 12


The data set dta is Jeff's, it's in dput format.

Hope this helps,

Rui Barradas

?s 18:26 de 02/08/2020, Rasmus Liland escreveu:
> On 2020-08-02 09:24 -0700, Philip wrote:
> | Below is some Weather Service data.  I
> | would like to parse the forecast date
> | field into four different columns:
> | Year, Month, Day, Hour
>
> Dear Philip,
>
> I'm largely re-iterating Eric and Jeff's
> excellent solutions:
>
> 	> dat <- structure(list(forecast.date =
> 	+ c("2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00",
> 	+ "2020-08-01 12:00:00"
> 	+ ), TMP = c("305.495", "305.245",
> 	+ "305.057", "305.745", "305.495"
> 	+ )), row.names = c(NA, 5L),
> 	+ class = "data.frame")
> 	> t(apply(simplify2array(
> 	+   strsplit(dat$forecast.date, "-| |:")),
> 	+   2, as.numeric))
> 	     [,1] [,2] [,3] [,4] [,5] [,6]
> 	[1,] 2020    8    1   12    0    0
> 	[2,] 2020    8    1   12    0    0
> 	[3,] 2020    8    1   12    0    0
> 	[4,] 2020    8    1   12    0    0
> 	[5,] 2020    8    1   12    0    0
> 	> simplify2array(parallel::mclapply(c(
> 	+   lubridate::year,
> 	+   lubridate::month,
> 	+   lubridate::day,
> 	+   lubridate::hour), function(FUN, x) {
> 	+     FUN(x)
> 	+   }, x=dat$forecast.date))
> 	     [,1] [,2] [,3] [,4]
> 	[1,] 2020    8    1   12
> 	[2,] 2020    8    1   12
> 	[3,] 2020    8    1   12
> 	[4,] 2020    8    1   12
> 	[5,] 2020    8    1   12
>
> V
>
> r
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Aug  3 09:25:25 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 3 Aug 2020 09:25:25 +0200
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
 <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
Message-ID: <24359.48101.586559.824590@stat.math.ethz.ch>

>>>>> Abby Spurdle 
>>>>>     on Sun, 2 Aug 2020 15:13:51 +1200 writes:

    > That's a bit harsh.  Isn't the best advice here, to post a
    > reproducible example...  Which I believe has been
    > mentioned.

    > Also, I'd strongly encourage people to use
    > package+function name, for this sort of thing.

    >     stats::glm

    > As there are many R functions for GLMs...

Sorry, Abby, I do disagree here ((strongly enough as to warrant
this reply) :

We're talking about doing "basic" statistics with R,  and these
function in the stats package have been part of R even before
got a version number.

So, no,  glm()  {and the stats package} are the default and I still
think everybody should know and assume that.

Martin

    > On Sun, Aug 2, 2020 at 12:47 PM Rolf Turner
    > <r.turner at auckland.ac.nz> wrote:
    >> 
    >> 
    >> On 2/08/20 5:39 am, Paul Bernal wrote:
    >> 
    >> > Dear friends,
    >> >
    >> > Hope you are doing great. I want to fit a logistic
    >> regression in R, where > the dependent variable is the
    >> covid status (I used 1 for covid positives, > and 0 for
    >> covid negatives), but when I ran the glm, R complains
    >> that I > should make the dependent variable a factor.
    >> >
    >> > What would be more advisable, to keep the dependent
    >> variable with 1s and > 0s, or code it as yes/no and then
    >> make it a factor?
    >> >
    >> > Any guidance will be greatly appreciated,
    >> 
    >> 
    >> There have been many responses to this post, the majority
    >> of them being confusing and off the point.
    >> 
    >> BOTTOM LINE: R/glm() does *NOT* complain that one "should
    >> make the dependent variable a factor".  This is bovine
    >> faecal output.
    >> 
    >> As Rui Barradas has pointed out (alternatively: RTFM!)
    >> when you fit a Bernoulli model using glm(), your
    >> response/dependent variable is allowed to be
    >> 
    >> * a numeric variable with values 0 or 1 * a logical
    >> variable * a factor with two levels
    >> 
    >> The OP presumably fed glm() a *character* vector with
    >> values "0" and "1".  Doing *this* will cause glm() to
    >> whinge.
    >> 
    >> I reiterate: RTFM!!!  (And perhaps learn to distinguish
    >> between character vectors and factors.)
    >> 
    >> cheers,
    >> 
    >> Rolf Turner
    >> 
    >> --
    >> Honorary Research Fellow Department of Statistics
    >> University of Auckland Phone: +64-9-373-7599 ext. 88276
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  3 10:24:13 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 09:24:13 +0100
Subject: [R] Parsing a Date
In-Reply-To: <a5e29edb-b03a-dbd0-1b5f-37f9e8bde4cd@sapo.pt>
References: <A35F61D77FD44E499621A5A6787035A7@OWNERPC>
 <20200802172648.GE1827@posteo.no>
 <a5e29edb-b03a-dbd0-1b5f-37f9e8bde4cd@sapo.pt>
Message-ID: <552cbeae-4d11-c13d-8aa6-0bacd2ffc901@sapo.pt>

Hello,

I'm reposting, I sent the previous in HTML format.
My apologies, I'm not at my computers.

And another solution, taking advantage of Rasmus' one:


simplify2array(parallel::mclapply(c(
 ?"%Y",
 ?"%m",
 ?"%d",
 ?"%H"), function(fmt, x) {
 ?as.integer(format(as.POSIXct(x), format = fmt))
}, x = dta$forecast.date))
#???? [,1] [,2] [,3] [,4]
#[1,] 2020??? 8??? 1?? 12
#[2,] 2020??? 8??? 1?? 12
#[3,] 2020??? 8??? 1?? 12
#[4,] 2020??? 8??? 1?? 12
#[5,] 2020??? 8??? 1?? 12



The data set dta is Jeff's, it's in dput format.

Hope this helps,

Rui Barradas



?s 22:54 de 02/08/2020, Rui Barradas escreveu:
> Hello,
>
> And another solution, taking advantage of Rasmus' one:
>
>
>
> simplify2array(parallel::mclapply(c(
>   ? "%Y",
>   ? "%m",
>   ? "%d",
>   ? "%H"), function(fmt, x) {
>   ??? as.integer(format(as.POSIXct(x), format = fmt))
> }, x = dta$forecast.date))
> #???? [,1] [,2] [,3] [,4]
> #[1,] 2020??? 8??? 1?? 12
> #[2,] 2020??? 8??? 1?? 12
> #[3,] 2020??? 8??? 1?? 12
> #[4,] 2020??? 8??? 1?? 12
> #[5,] 2020??? 8??? 1?? 12
>
>
> The data set dta is Jeff's, it's in dput format.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 18:26 de 02/08/2020, Rasmus Liland escreveu:
>> On 2020-08-02 09:24 -0700, Philip wrote:
>> | Below is some Weather Service data.  I
>> | would like to parse the forecast date
>> | field into four different columns:
>> | Year, Month, Day, Hour
>>
>> Dear Philip,
>>
>> I'm largely re-iterating Eric and Jeff's
>> excellent solutions:
>>
>> 	> dat <- structure(list(forecast.date =
>> 	+ c("2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00",
>> 	+ "2020-08-01 12:00:00"
>> 	+ ), TMP = c("305.495", "305.245",
>> 	+ "305.057", "305.745", "305.495"
>> 	+ )), row.names = c(NA, 5L),
>> 	+ class = "data.frame")
>> 	> t(apply(simplify2array(
>> 	+   strsplit(dat$forecast.date, "-| |:")),
>> 	+   2, as.numeric))
>> 	     [,1] [,2] [,3] [,4] [,5] [,6]
>> 	[1,] 2020    8    1   12    0    0
>> 	[2,] 2020    8    1   12    0    0
>> 	[3,] 2020    8    1   12    0    0
>> 	[4,] 2020    8    1   12    0    0
>> 	[5,] 2020    8    1   12    0    0
>> 	> simplify2array(parallel::mclapply(c(
>> 	+   lubridate::year,
>> 	+   lubridate::month,
>> 	+   lubridate::day,
>> 	+   lubridate::hour), function(FUN, x) {
>> 	+     FUN(x)
>> 	+   }, x=dat$forecast.date))
>> 	     [,1] [,2] [,3] [,4]
>> 	[1,] 2020    8    1   12
>> 	[2,] 2020    8    1   12
>> 	[3,] 2020    8    1   12
>> 	[4,] 2020    8    1   12
>> 	[5,] 2020    8    1   12
>>
>> V
>>
>> r
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From ht @end|ng |rom he@therturner@net  Mon Aug  3 10:24:34 2020
From: ht @end|ng |rom he@therturner@net (Heather Turner)
Date: Mon, 03 Aug 2020 09:24:34 +0100
Subject: [R] useR! 2020 survey
Message-ID: <5af3e0c2-19ff-4840-8542-482d56487664@www.fastmail.com>

Dear All,

We hope you have been able to watch/attend some of the breakout sessions, keynotes, R core panel, contributed tutorials, or online tutorials that were part of the useR! 2020 program.

We'd appreciate it you took 5 minutes to let us know a bit more about yourself and what you thought of useR! this year, by answering the useR! 2020 survey: bit.ly/useR2020survey.

Many thanks,

Heather



	[[alternative HTML version deleted]]

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  3 12:51:32 2020
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 3 Aug 2020 11:51:32 +0100
Subject: [R] Arrange data
Message-ID: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>

Hi,

I have a dataset having monthly observations (from January to December)
over a period of time like (2000 to 2018). Now, I am trying to take an
average the value from January to July of each year.

The data looks like
Year    Month  Value
2000    1         25
2000    2         28
2000    3         22
....    ......      .....
2000    12       26
2001     1       27
.......         ........
2018    11       30
20118   12      29

Can someone help me in this regard?

Many thanks in advance.

*Regards,*
*Md*

	[[alternative HTML version deleted]]


From @@h|mk@poor @end|ng |rom gm@||@com  Mon Aug  3 12:52:48 2020
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Mon, 3 Aug 2020 16:22:48 +0530
Subject: [R] tidyquant package
Message-ID: <CAC8=1eoz=sXUazhRkkGmhke3WXta6+MsXJ3C6a0PtCv+OF852A@mail.gmail.com>

Dear all,

I am trying to follow along/ recreate this page ( but I do not get the
same results) :-

https://bookdown.org/sstoeckl/Tidy_Portfoliomanagement_in_R/s-2Data.html

Here is a reprex / what I have done till now / my queries ( 3 in
number ) are as comments :-

> library(tidyquant)
Loading required package: lubridate

Attaching package: ?lubridate?

The following object is masked from ?package:base?:

    date

Loading required package: PerformanceAnalytics
Loading required package: xts
Loading required package: zoo

Attaching package: ?zoo?

The following objects are masked from ?package:base?:

    as.Date, as.Date.numeric


Attaching package: ?PerformanceAnalytics?

The following object is masked from ?package:graphics?:

    legend

Loading required package: quantmod
Loading required package: TTR
Registered S3 method overwritten by 'quantmod':
  method            from
  as.zoo.data.frame zoo
Version 0.4-0 included new data defaults. See ?getSymbols.
?? Need to Learn tidyquant? ????????????????????????????????????????????????????
Business Science offers a 1-hour course - Learning Lab #9: Performance
Analysis & Portfolio Optimization with tidyquant!
</> Learn more at:
https://university.business-science.io/p/learning-labs-pro </>
> library(tidyverse)
?? Attaching packages ??????????????????????????????????????? tidyverse 1.3.0 ??
? ggplot2 3.2.1     ? purrr   0.3.3
? tibble  3.0.3     ? dplyr   1.0.1
? tidyr   1.1.1     ? stringr 1.4.0
? readr   1.3.1     ? forcats 0.4.0
?? Conflicts ?????????????????????????????????????????? tidyverse_conflicts() ??
? lubridate::as.difftime() masks base::as.difftime()
? lubridate::date()        masks base::date()
? dplyr::filter()          masks stats::filter()
? dplyr::first()           masks xts::first()
? lubridate::intersect()   masks base::intersect()
? dplyr::lag()             masks stats::lag()
? dplyr::last()            masks xts::last()
? lubridate::setdiff()     masks base::setdiff()
? lubridate::union()       masks base::union()
> tq_exchange_options()
[1] "AMEX"   "NASDAQ" "NYSE"
> tq_index_options()
[1] "DOW"       "DOWGLOBAL" "SP400"     "SP500"     "SP600"

# Query 1 : The above should also show RUSSELL3000. Why is it not showing?

> tq_get_options()
 [1] "stock.prices"       "stock.prices.japan" "dividends"
 [4] "splits"             "economic.data"      "quandl"
 [7] "quandl.datatable"   "tiingo"             "tiingo.iex"
[10] "tiingo.crypto"      "alphavantager"      "alphavantage"
[13] "rblpapi"
> glimpse(sp500)
Error in glimpse(sp500) : object 'sp500' not found

# Query 2 : This is working fine in the page mentioned on top. What
mistake have I made?

> tq_exchange("NYSE")
Getting data...

[1] NA
Warning messages:
1: In download.file(url, destfile = tmp, quiet = TRUE) :
  URL 'https://old.nasdaq.com/screening/companies-by-name.aspx?letter=0&exchange=nyse&render=download':
status was 'Failure when receiving data from the peer'
2: In value[[3L]](cond) : Error at nyse during call to tq_exchange.
>
# Query 3 : Is this a networking issue? Should I try after some time ?


Here is my session info:-

> sessionInfo()
R version 3.6.2 (2019-12-12)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS/LAPACK: /opt/intel/compilers_and_libraries_2018.2.199/linux/mkl/lib/intel64_lin/libmkl_rt.so

locale:
 [1] LC_CTYPE=en_IN       LC_NUMERIC=C         LC_TIME=en_IN
 [4] LC_COLLATE=en_IN     LC_MONETARY=en_IN    LC_MESSAGES=en_IN
 [7] LC_PAPER=en_IN       LC_NAME=C            LC_ADDRESS=C
[10] LC_TELEPHONE=C       LC_MEASUREMENT=en_IN LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
 [1] forcats_0.4.0              stringr_1.4.0
 [3] dplyr_1.0.1                purrr_0.3.3
 [5] readr_1.3.1                tidyr_1.1.1
 [7] tibble_3.0.3               ggplot2_3.2.1
 [9] tidyverse_1.3.0            tidyquant_1.0.1
[11] quantmod_0.4-15            TTR_0.23-6
[13] PerformanceAnalytics_2.0.4 xts_0.12-0
[15] zoo_1.8-7                  lubridate_1.7.4

loaded via a namespace (and not attached):
 [1] tidyselect_1.1.0 haven_2.2.0      lattice_0.20-38  colorspace_1.4-1
 [5] vctrs_0.3.2      generics_0.0.2   rlang_0.4.7      pillar_1.4.6
 [9] withr_2.1.2      glue_1.4.1       DBI_1.1.0        dbplyr_1.4.2
[13] modelr_0.1.5     readxl_1.3.1     lifecycle_0.2.0  Quandl_2.10.0
[17] cellranger_1.1.0 munsell_0.5.0    gtable_0.3.0     rvest_0.3.5
[21] curl_4.3         fansi_0.4.1      broom_0.5.3      Rcpp_1.0.3
[25] backports_1.1.5  scales_1.1.0     jsonlite_1.6     fs_1.3.1
[29] hms_0.5.2        stringi_1.4.6    grid_3.6.2       quadprog_1.5-8
[33] cli_2.0.1        tools_3.6.2      magrittr_1.5     lazyeval_0.2.2
[37] crayon_1.3.4     pkgconfig_2.0.3  ellipsis_0.3.0   xml2_1.2.2
[41] reprex_0.3.0     assertthat_0.2.1 httr_1.4.1       rstudioapi_0.10
[45] R6_2.4.1         nlme_3.1-143     compiler_3.6.2
>

Many thanks,
Ashim


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  3 13:11:59 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 3 Aug 2020 21:11:59 +1000
Subject: [R] Arrange data
In-Reply-To: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
Message-ID: <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>

Hi Md,
One way is to form a subset of your data, then calculate the means by year:

# assume your data is named mddat
mddat2<-mddat[mddat$month < 7,]
jan2jun<-by(mddat2$value,mddat2$year,mean)

Jim

On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Hi,
>
> I have a dataset having monthly observations (from January to December)
> over a period of time like (2000 to 2018). Now, I am trying to take an
> average the value from January to July of each year.
>
> The data looks like
> Year    Month  Value
> 2000    1         25
> 2000    2         28
> 2000    3         22
> ....    ......      .....
> 2000    12       26
> 2001     1       27
> .......         ........
> 2018    11       30
> 20118   12      29
>
> Can someone help me in this regard?
>
> Many thanks in advance.
>
> *Regards,*
> *Md*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Mon Aug  3 13:33:37 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 3 Aug 2020 13:33:37 +0200
Subject: [R] Arrange data
In-Reply-To: <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
Message-ID: <20200803113337.GC106339@posteo.no>

On 2020-08-03 21:11 +1000, Jim Lemon wrote:
> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
> >
> > Hi,
> >
> > I have a dataset having monthly 
> > observations (from January to 
> > December) over a period of time like 
> > (2000 to 2018). Now, I am trying to 
> > take an average the value from 
> > January to July of each year.
> >
> > The data looks like
> > Year    Month  Value
> > 2000    1         25
> > 2000    2         28
> > 2000    3         22
> > ....    ......      .....
> > 2000    12       26
> > 2001     1       27
> > .......         ........
> > 2018    11       30
> > 20118   12      29
> >
> > Can someone help me in this regard? 
> >
> > Many thanks in advance.
> 
> Hi Md,
> One way is to form a subset of your 
> data, then calculate the means by 
> year:
> 
> # assume your data is named mddat
> mddat2<-mddat[mddat$month < 7,]
> jan2jun<-by(mddat2$value,mddat2$year,mean)
> 
> Jim

Hi Md,

you can also define the period in a new 
column, and use aggregate like this:

	Md <- structure(list(
	Year = c(2000L, 2000L, 2000L, 
	2000L, 2001L, 2018L, 2018L), 
	Month = c(1L, 2L, 3L, 12L, 1L,
	11L, 12L), 
	Value = c(25L, 28L, 22L, 26L,
	27L, 30L, 29L)), 
	class = "data.frame", 
	row.names = c(NA, -7L))
	
	Md[Md$Month %in%
	        1:6,"Period"] <- "first six months of the year"
	Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
	
	aggregate(
	  formula=Value~Year+Period,
	  data=Md,
	  FUN=mean)

Rasmus


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Mon Aug  3 16:22:21 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Mon, 3 Aug 2020 14:22:21 +0000 (UTC)
Subject: [R] Double MAD with R
References: <401386585.16460890.1596464541734.ref@mail.yahoo.com>
Message-ID: <401386585.16460890.1596464541734@mail.yahoo.com>

Dear R-Experts,

Is there an all-ready function to calculate the Double MAD (Median absolute deviation) as there is an easy function to calculate the MAD "mad function". Or I have to write my own function for Double MAD ?

To calculate the double MAD, the idea is the following : for the obtained median value, we should calculate two median absolution deviations. One deviation should be calculated for the numbers below the median and one for the numbers above the median:

Here is the very easy reproducible example :

x<-c(2.5,4.4,3.2,2.1,1.3,2.6,5,6.6,5,5,6.1,7.2,9.4,6.9)
mad(x)


From j|en@gu90 @end|ng |rom gm@||@com  Sun Aug  2 02:35:38 2020
From: j|en@gu90 @end|ng |rom gm@||@com (Jiena McLellan)
Date: Sat, 1 Aug 2020 20:35:38 -0400
Subject: [R] [R-pkgs] faq v0.1.0 on CRAN
Message-ID: <CAB+AFnLTfpSGcd2f73-9SgjX8_ROwZp4OT30wtH1KaAvLW7iAw@mail.gmail.com>

R Users,

I?m writing to introduce a new package, faq. This package offers a fast
tool to create an interactive and toggle styling Frequently Asked Questions
page by using R data.
Hopefully you find this useful. Please feel free to reach out with feedback
or questions.

CRAN: https://cran.r-project.org/web/packages/faq/index.html
Github: https://github.com/jienagu/faq

Best Regards,
Jiena Gu McLellan

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  3 16:54:20 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 15:54:20 +0100
Subject: [R] Double MAD with R
In-Reply-To: <401386585.16460890.1596464541734@mail.yahoo.com>
References: <401386585.16460890.1596464541734.ref@mail.yahoo.com>
 <401386585.16460890.1596464541734@mail.yahoo.com>
Message-ID: <c41de121-e6ca-493c-ec98-c066c32914b4@sapo.pt>

Hello,

No, there isn't a built-in that I know of.
Here is one:


double.mad <- function(x, include.right = FALSE, na.rm = FALSE){
 ? if(na.rm) x <- x[!is.na(x)]
 ? m <- median(x)
 ? odd <- (length(x) %% 2L) == 1L
 ? out <- if(odd){
 ??? if(include.right) {
 ????? c(lo = mad(x[x < m]), hi = mad(x[x >= m]))
 ??? } else {
 ????? c(lo = mad(x[x <= m]), hi = mad(x[x > m]))
 ??? }
 ? } else {
 ??? c(lo = mad(x[x < m]), hi = mad(x[x > m]))
 ? }
 ? out
}

double.mad(x)
#???? lo????? hi
#0.81543 0.44478

double.mad(c(x, 1))
#???? lo????? hi
#2.29803 0.44478

double.mad(c(x, 1), include.right = TRUE)
#???? lo????? hi
#1.03782 1.63086


Hope this helps,

Rui Barradas

?s 15:22 de 03/08/2020, varin sacha via R-help escreveu:
> Dear R-Experts,
>
> Is there an all-ready function to calculate the Double MAD (Median absolute deviation) as there is an easy function to calculate the MAD "mad function". Or I have to write my own function for Double MAD ?
>
> To calculate the double MAD, the idea is the following : for the obtained median value, we should calculate two median absolution deviations. One deviation should be calculated for the numbers below the median and one for the numbers above the median:
>
> Here is the very easy reproducible example :
>
> x<-c(2.5,4.4,3.2,2.1,1.3,2.6,5,6.6,5,5,6.1,7.2,9.4,6.9)
> mad(x)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From @purd|e@@ @end|ng |rom gm@||@com  Mon Aug  3 21:39:08 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 4 Aug 2020 07:39:08 +1200
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <24359.48101.586559.824590@stat.math.ethz.ch>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
 <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
 <24359.48101.586559.824590@stat.math.ethz.ch>
Message-ID: <CAB8pepxfDbEED8ZQW=WdWisNdrcRzOt-HZcgAhdrdA24CFokJw@mail.gmail.com>

> Sorry, Abby, I do disagree here ((strongly enough as to warrant
> this reply) :

Which part are you disagreeing with?
That unambiquous names/references should be used, or that there are
many R functions for GLMs.
The wording of your post, suggests (kind of), that there is only one R
function for GLMs.

> We're talking about doing "basic" statistics with R,  and these
> function in the stats package have been part of R even before
> got a version number.

Remember, not everyone is using the same R packages, as you.
And some people have done university courses, or done online courses,
etc, in R, without ever using one function from the stats package.

I'm reluctant to assume that all R users will have a common understanding.
And what may seem obvious to you or me, may seem quite foreign to some
users, or vice versa.

> So, no,  glm()  {and the stats package} are the default and I still
> think everybody should know and assume that.

But perhaps most importantly, the OP said "the glm".
He never said "glm()", but rather the subsequent posters did.

Rolf suggested his post was bullshit, after removing the lexical peroxide.
How does anyone know that it wasn't a genuine post, but in reference
to something other than stats::glm?

Shouldn't people be innocent until proven guilty.
Otherwise (something I have been guilty of in the past), the mailing
list turns into statistical propaganda...

Even if the OP was referring to stats::glm, I'm still inclined to feel
the post was legitimate, just a bit short on technical details...


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug  3 23:11:20 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 3 Aug 2020 14:11:20 -0700
Subject: [R] [FORGED] Dependent Variable in Logistic Regression
In-Reply-To: <CAB8pepxfDbEED8ZQW=WdWisNdrcRzOt-HZcgAhdrdA24CFokJw@mail.gmail.com>
References: <CAMOcQfPo49hFxAR0Y_3ODy8bZuBrP76tPYdzHHEstrj_QGGPvg@mail.gmail.com>
 <2b8cd11e-440c-59fa-aa3c-611debcfd6aa@auckland.ac.nz>
 <CAB8pepxrTMY6d33-Q3hvH5E48FkY_EVpVAK4PXEivOY_3mK7Nw@mail.gmail.com>
 <24359.48101.586559.824590@stat.math.ethz.ch>
 <CAB8pepxfDbEED8ZQW=WdWisNdrcRzOt-HZcgAhdrdA24CFokJw@mail.gmail.com>
Message-ID: <CAGxFJbQtpZ9tyXmAAueiGQ0t9ObgnPeBw_v_8S0CT4OKu6svxA@mail.gmail.com>

All: Kindly take this offline please.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Aug 3, 2020 at 12:39 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> > Sorry, Abby, I do disagree here ((strongly enough as to warrant
> > this reply) :
>
> Which part are you disagreeing with?
> That unambiquous names/references should be used, or that there are
> many R functions for GLMs.
> The wording of your post, suggests (kind of), that there is only one R
> function for GLMs.
>
> > We're talking about doing "basic" statistics with R,  and these
> > function in the stats package have been part of R even before
> > got a version number.
>
> Remember, not everyone is using the same R packages, as you.
> And some people have done university courses, or done online courses,
> etc, in R, without ever using one function from the stats package.
>
> I'm reluctant to assume that all R users will have a common understanding.
> And what may seem obvious to you or me, may seem quite foreign to some
> users, or vice versa.
>
> > So, no,  glm()  {and the stats package} are the default and I still
> > think everybody should know and assume that.
>
> But perhaps most importantly, the OP said "the glm".
> He never said "glm()", but rather the subsequent posters did.
>
> Rolf suggested his post was bullshit, after removing the lexical peroxide.
> How does anyone know that it wasn't a genuine post, but in reference
> to something other than stats::glm?
>
> Shouldn't people be innocent until proven guilty.
> Otherwise (something I have been guilty of in the past), the mailing
> list turns into statistical propaganda...
>
> Even if the OP was referring to stats::glm, I'm still inclined to feel
> the post was legitimate, just a bit short on technical details...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  3 23:44:49 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 22:44:49 +0100
Subject: [R] hist from a list
In-Reply-To: <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>
References: <CAB-TgNv88YE29BkrXg9teFoMGXVOGfrYtDWy+Ltb8znRK9_OFQ@mail.gmail.com>
 <42a74b91-08ed-f5f2-b621-193e447dd824@dewey.myzen.co.uk>
 <70ef6db0-8a9d-d140-8347-b4e8b758f640@sapo.pt>
 <CAPPM_gQTOQwXdiMQtD_smhZDJ7uAjwyfT65TR_J-0Vhh+xhYqg@mail.gmail.com>
 <20200731162847.GB106339@posteo.no>
 <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>
Message-ID: <ea46a48f-e9aa-8d89-aed5-0f7454b3da3b@sapo.pt>

Hello,

Thanks for the data in dput format.
If you run

str(bwchist)

you will see that what you have is a data.frame, yes, but, with columns 
of class "list", not vectors.
So the first step is to make them vectors, to unlist the lists. I will 
do it applying function unlist() to each of the columns. Since lapply 
returns a list, I remake a data.frame. The original is kept unchanged, 
the new object is bwch.

bwch <- lapply(bwchist, unlist, recursive = FALSE)
bwch <- do.call(cbind.data.frame, bwch)
str(bwch)


Now that everything is as it should, here are two ways of plotting bar 
graphs.

#--- base R
x11(width = 11.5, height = 6)
old_par <- par(mar =? par("mar") + c(1, 0, 0, 0))
bp <- barplot(bwch$reval, yaxt = "n", ylim = c(-1, 0.4))
axis(1, at = bp, labels = bwch$Accion, las = 2)
axis(2, at = pretty(bwch$reval))
par(old_par)


#--- package ggplot2
library(ggplot2)

x11(width = 11.5, height = 6)
ggplot(bwch, aes(factor(Accion, levels = Accion), reval)) +
 ? geom_col() +
 ? theme(axis.text.x = element_text(angle = 60, hjust = 1))


Hope this helps,

Rui Barradas

?s 19:48 de 03/08/2020, Pedro p?ramo escreveu:
> Hi Rasmus, Josh and Rui,
>
> First of all many thanks?in advance about your help.
>
> The first thig?is sometimes?you say " you are posting in HTML and that 
> makes the
> post unreadable as this is a plain text list" how can I put the code 
> in the correct way, not html (attaching in txt?)
>
> The second?about the code:
>
> I have used this:
>
> bwc <- cbind(bwfinal2,bwfinal)
> colnames(bwc)=c("Accion","reval")
> df <- matrix(unlist(bwc), nrow=nrow(bwc), byrow=F)
> colnames(bwchist)=c("Accion","reval")
> bwchist <-as.data.frame(bwc[order(df[,2]), ])
>
> bwchist is the ordered cum stock returns in the year but because is a 
> list it is not possible to plot and histogram with x (names of stocks) 
> and the x axist?the value of cum stocks (reval)
>
> when I put dput(bwchist) the console says:
>
> dput(bwchist)
> structure(list(Accion = list("REE", "Enagas", "Grifols", "Ferrovial",
> ? ? "Acerinox", "Naturgy", "Inditex", "Bankia", "ENCE", "Aena",
> ? ? "Bankinter", "Mapfre", "CaixaBank", "CIE", "Colonial", "Almirall",
> ? ? "Indra", "ArcelorMittal", "ACS", "Telefonica", "Amadeus",
> ? ? "BBVA", "Merlin", "Santander", "Repsol", "Melia", "Sabadell",
> ? ? "IAG", "Acciona", "Endesa", "MasMovil", "Iberdrola", "SGamesa",
> ? ? "Viscofan", "Cellnex"), reval = list(-0.0200827282700085,
> ? ? -0.0590294115600855, -0.214126598790964, -0.220773677809979,
> ? ? -0.229653300324357, -0.257944379583984, -0.283942789063822,
> ? ? -0.285159347392533, -0.303814713896458, -0.30734460425763,
> ? ? -0.309408155539818, -0.319912221435868, -0.322790949659181,
> ? ? -0.344047579452905, -0.347919538415482, -0.356898907103825,
> ? ? -0.374263261296661, -0.40147247119078, -0.405150043834815,
> ? ? -0.406022775042175, -0.413786100987797, -0.440679109311707,
> ? ? -0.442603156492871, -0.491634140733524, -0.499254932434042,
> ? ? -0.6, -0.709737357505148, -0.724461258850966, 0.0220528711420083,
> ? ? 0.0462767672643172, 0.115044247787611, 0.238734548714937,
> ? ? 0.274578114644054, 0.343422896082666, 0.387826126094928)), class = 
> "data.frame", row.names = c(NA,
> -35L))
>
> I try to make an hist or barplot but because it is a list no way to 
> obtain the plot.
>
> Many thanks again for your help.
>
> I have printed two manuals to improve my level, but if you can help 
> me, I would be very very gratefull.
>
>
>
> El vie., 31 jul. 2020 a las 18:28, Rasmus Liland (<jral at posteo.no 
> <mailto:jral at posteo.no>>) escribi?:
>
>     On 2020-07-31 10:07 -0500, Joshua Ulrich wrote:
>     | On Fri, Jul 31, 2020 at 9:55 AM Rui Barradas wrote:
>     | | ?s 15:44 de 31/07/2020, Michael Dewey escreveu:
>     | | | Dear Pedro
>     | | |
>     | | | Some comments in-line
>     | | |
>     | | | On 30/07/2020 21:16, Pedro p?ramo wrote:
>     | | | | Hi all,
>     | | | |
>     | | | | I attach my code, the think is I
>     | | | | want to make a bar plot the last
>     | | | | variable called "bwchist" so the
>     | | | | X axis are "Accion" and the y
>     | | | | axis are "reval" values.
>     | | | |
>     | | | | I have prove class(bwchist) and
>     | | | | says dataframe but its still a
>     | | | | list because it says me I have
>     | | | | prove to unlist, but it doesnt
>     | | | | work
>     | | | |
>     | | | | hist(bwchist)
>     | | | | Error in hist.default(bwchist) : 'x' must be numeric
>     | | |
>     | | | So bwchist is not a numeric
>     | | | variable as hist needs. Aboce you
>     | | | said it is a data frame but data
>     | | | frames are not numeric.
>     | | |
>     | | | For future reference your example
>     | | | is way too long for anyone to go
>     | | | through and try to help you. Try
>     | | | next time to reduce it to the
>     | | | absolute minimum by removing
>     | | | sections while you still get the
>     | | | error.? It is also easier to get
>     | | | help if you can remove unnecessary
>     | | | packages.
>     | | |
>     | | | It is also unreadable because you
>     | | | are posting in HTML and that makes
>     | | | the post unreadable as this is a
>     | | | plain text list.
>     | |
>     | | Hello,
>     | |
>     | | I second Michael's opinion. When the
>     | | post's code is very long, there is a
>     | | tendency to have less answers.
>     | |
>     | | Please post the output of
>     | |
>     | |? ? ?dput(head(bwchist, 30))
>     | |
>     | | It's much shorter code and it
>     | | recreates the data so we will be
>     | | able to see what's wrong and try to
>     | | find a solution.
>     |
>     | Hi Pedro,
>     |
>     | Another 'best practice' and polite
>     | thing to do is link to other places
>     | you may have cross-posted.? That will
>     | give people the opportunity to see if
>     | your questions has been answered in
>     | another forum.
>     |
>     | I saw your post on R-SIG-Finance
>     | (https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/014979.html),
>     | and started to work on a solution.
>     |
>     | I don't know how to do this in
>     | tidyquant, but here's how you can do
>     | it with quantmod:
>     |
>     | # all tickers
>     | tk <- c("ANA.MC <http://ANA.MC>", "ACS.MC <http://ACS.MC>",
>     "AENA.MC <http://AENA.MC>", "AMS.MC <http://AMS.MC>", "MTS.MC
>     <http://MTS.MC>", "BBVA.MC <http://BBVA.MC>", "SAB.MC
>     <http://SAB.MC>",
>     |? ?"SAN.MC <http://SAN.MC>", "BKT.MC <http://BKT.MC>", "CABK.MC
>     <http://CABK.MC>", "CLNX.MC <http://CLNX.MC>", "ENG.MC
>     <http://ENG.MC>", "ENC.MC <http://ENC.MC>", "ELE.MC <http://ELE.MC>",
>     |? ?"FER.MC <http://FER.MC>", "GRF.MC <http://GRF.MC>", "IBE.MC
>     <http://IBE.MC>", "ITX.MC <http://ITX.MC>", "COL.MC
>     <http://COL.MC>", "IAG.MC <http://IAG.MC>", "MAP.MC <http://MAP.MC>",
>     |? ?"MEL.MC <http://MEL.MC>", "MRL.MC <http://MRL.MC>", "NTGY.MC
>     <http://NTGY.MC>", "REE.MC <http://REE.MC>", "REP.MC
>     <http://REP.MC>", "SGRE.MC <http://SGRE.MC>", "TEF.MC
>     <http://TEF.MC>",
>     |? ?"VIS.MC <http://VIS.MC>", "ACX.MC <http://ACX.MC>", "BKIA.MC
>     <http://BKIA.MC>", "CIE.MC <http://CIE.MC>", "MAS.MC
>     <http://MAS.MC>", "ALM.MC <http://ALM.MC>", "IDR.MC <http://IDR.MC>")
>     |
>     | # download them into an environment ('e')
>     | require(quantmod)
>     | getSymbols(tk, from = "2019-12-31", env = (e <- new.env()))
>     |
>     | # extract adjusted close column
>     | adj <- lapply(e, Ad)
>     | # calculate daily returns from adjusted data,
>     | # merge into a xts matrix, and fill NA with 0
>     | ret <- do.call(merge, c(lapply(adj, dailyReturn), fill = 0))
>     | # cumulative returns
>     | cumret <- cumprod(1 + ret) - 1
>     | # set names
>     | colnames(cumret) <- names(adj)
>     | last(cumret)
>     | # calculate histogram for period-to-date returns
>     | hist(drop(last(cumret)))
>     |
>     | I'm not sure that's the histogram
>     | you're looking for, but I hope it
>     | gives you a start toward a solution.
>     |
>     | Best,
>     | Josh
>
>     Wow Josh!? That's very elegant.
>
>     Myself now, I just plowed through the
>     original code to make it simpler, but am
>     at a loss as to how this histogram looks
>     ...
>
>     ? ? ? ? x <- c("ANA.MC <http://ANA.MC>", "ACS.MC <http://ACS.MC>",
>     "AENA.MC <http://AENA.MC>", "AMS.MC <http://AMS.MC>", "MTS.MC
>     <http://MTS.MC>", "BBVA.MC <http://BBVA.MC>",
>     ? ? ? ? ? "SAB.MC <http://SAB.MC>", "SAN.MC <http://SAN.MC>",
>     "BKT.MC <http://BKT.MC>", "CABK.MC <http://CABK.MC>", "CLNX.MC
>     <http://CLNX.MC>", "ENG.MC <http://ENG.MC>",
>     ? ? ? ? ? "ENC.MC <http://ENC.MC>", "ELE.MC <http://ELE.MC>",
>     "FER.MC <http://FER.MC>", "GRF.MC <http://GRF.MC>", "IBE.MC
>     <http://IBE.MC>", "ITX.MC <http://ITX.MC>",
>     ? ? ? ? ? "COL.MC <http://COL.MC>", "IAG.MC <http://IAG.MC>",
>     "MAP.MC <http://MAP.MC>", "MEL.MC <http://MEL.MC>", "MRL.MC
>     <http://MRL.MC>", "NTGY.MC <http://NTGY.MC>",
>     ? ? ? ? ? "REE.MC <http://REE.MC>", "REP.MC <http://REP.MC>",
>     "SGRE.MC <http://SGRE.MC>", "TEF.MC <http://TEF.MC>", "VIS.MC
>     <http://VIS.MC>", "ACX.MC <http://ACX.MC>",
>     ? ? ? ? ? "BKIA.MC <http://BKIA.MC>", "CIE.MC <http://CIE.MC>",
>     "MAS.MC <http://MAS.MC>", "ALM.MC <http://ALM.MC>", "IDR.MC
>     <http://IDR.MC>")
>     ? ? ? ? stock.prices <-
>     ? ? ? ? ? lapply(x, function(stock) {
>     ? ? ? ? ? ? tidyquant::tq_get(x=stock,from = '2019-12-31',get =
>     "stock.prices")
>     ? ? ? ? ? })
>     ? ? ? ? names(stock.prices) <- x
>
>     ? ? ? ? library(tidyquant)
>
>     ? ? ? ? returns <- lapply(stock.prices, function(data) {
>     ? ? ? ? ? tab <-
>     ? ? ? ? ? ? tq_transmute(
>     ? ? ? ? ? ? ? data = data,
>     ? ? ? ? ? ? ? select = adjusted,? ? ? ? ? ?# this specifies which
>     column to select
>     ? ? ? ? ? ? ? mutate_fun = periodReturn,? ?# This specifies what
>     to do with that column
>     ? ? ? ? ? ? ? period = "daily",? ? ? ? ? ? # This argument
>     calculates Daily returns
>     ? ? ? ? ? ? ? col_rename = "idr_returns")? # renames the column
>     ? ? ? ? ? tab[,"cr"] <- cumprod(1 + tab[,"idr_returns"])
>     ? ? ? ? ? tab[,"cumulative_returns"] <- tab[,"cr"] - 1
>
>     ? ? ? ? ? dplyr::pull(
>     ? ? ? ? ? ? tab[nrow(tab[,"cumulative_returns"]),
>     ? ? ? ? ? ? ? ? ? ? ? ? ? "cumulative_returns"]
>     ? ? ? ? ? )
>     ? ? ? ? })
>
>     ? ? ? ? bestworst <- simplify2array(returns)
>
>     ? ? ? ? namebw <-
>     ? ? ? ? ? c("Acciona", "ACS", "Aena", "Amadeus",
>     ? ? ? ? ? ? "ArcelorMittal", "BBVA", "Sabadell",
>     ? ? ? ? ? ? "Santander", "Bankinter",
>     ? ? ? ? ? ? "CaixaBank", "Cellnex", "Enagas",
>     ? ? ? ? ? ? "ENCE", "Endesa", "Ferrovial",
>     ? ? ? ? ? ? "Grifols", "Iberdrola", "Inditex",
>     ? ? ? ? ? ? "Colonial", "IAG", "Mapfre",
>     ? ? ? ? ? ? "Melia", "Merlin", "Naturgy", "REE",
>     ? ? ? ? ? ? "Repsol", "SGamesa", "Telefonica",
>     ? ? ? ? ? ? "Viscofan", "Acerinox", "Bankia",
>     ? ? ? ? ? ? "CIE", "MasMovil", "Almirall",
>     ? ? ? ? ? ? "Indra")
>
>     ? ? ? ? bwc <- data.frame(
>     ? ? ? ? ? symbol=names(bestworst),
>     ? ? ? ? ? Accion=namebw,
>     ? ? ? ? ? reval=bestworst)
>
>     | | | | bwc<-cbind(bwfinal2,bwfinal)
>     | | | | colnames(bwc)=c("Accion","reval")
>     | | | | bwc <- as.data.frame(bwc)
>
>     ... aaaand you know something's
>     happening between here (where bwchist is
>     created), but you don't know what it is,
>     do you, Mr p?ramo?
>
>     | | | | colnames(bwchist)=c("Accion","reval")
>     | | | | bwchist <-as.data.frame(bwc[order(bwc$reval), ])
>
>     Best,
>     Rasmus
>



-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  4 00:28:27 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Aug 2020 23:28:27 +0100
Subject: [R] Arrange data
In-Reply-To: <20200803113337.GC106339@posteo.no>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
Message-ID: <de75298f-9ba6-2ed3-5e2b-4095424f9834@sapo.pt>

Hello,

And here is another way, with aggregate.

Make up test data.

set.seed(2020)
df1 <- expand.grid(Year = 2000:2018, Month = 1:12)
df1 <- df1[order(df1$Year),]
df1$Value <- sample(20:30, nrow(df1), TRUE)
head(df1)


#Use subset to keep only the relevant months
aggregate(Value ~ Year, data = subset(df1, Month <= 7), FUN = mean)


Hope this helps,

Rui Barradas

?s 12:33 de 03/08/2020, Rasmus Liland escreveu:
> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>>> Hi,
>>>
>>> I have a dataset having monthly
>>> observations (from January to
>>> December) over a period of time like
>>> (2000 to 2018). Now, I am trying to
>>> take an average the value from
>>> January to July of each year.
>>>
>>> The data looks like
>>> Year    Month  Value
>>> 2000    1         25
>>> 2000    2         28
>>> 2000    3         22
>>> ....    ......      .....
>>> 2000    12       26
>>> 2001     1       27
>>> .......         ........
>>> 2018    11       30
>>> 20118   12      29
>>>
>>> Can someone help me in this regard?
>>>
>>> Many thanks in advance.
>> Hi Md,
>> One way is to form a subset of your
>> data, then calculate the means by
>> year:
>>
>> # assume your data is named mddat
>> mddat2<-mddat[mddat$month < 7,]
>> jan2jun<-by(mddat2$value,mddat2$year,mean)
>>
>> Jim
> Hi Md,
>
> you can also define the period in a new
> column, and use aggregate like this:
>
> 	Md <- structure(list(
> 	Year = c(2000L, 2000L, 2000L,
> 	2000L, 2001L, 2018L, 2018L),
> 	Month = c(1L, 2L, 3L, 12L, 1L,
> 	11L, 12L),
> 	Value = c(25L, 28L, 22L, 26L,
> 	27L, 30L, 29L)),
> 	class = "data.frame",
> 	row.names = c(NA, -7L))
> 	
> 	Md[Md$Month %in%
> 	        1:6,"Period"] <- "first six months of the year"
> 	Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
> 	
> 	aggregate(
> 	  formula=Value~Year+Period,
> 	  data=Md,
> 	  FUN=mean)
>
> Rasmus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug  4 09:41:09 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 4 Aug 2020 17:41:09 +1000
Subject: [R] Arrange data
In-Reply-To: <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
Message-ID: <CA+8X3fWF4TBbhqiUErDKKKw-j8nbK8+oEh0kV7+Ow8RiaU6kug@mail.gmail.com>

Your problem is in the subset operation. You have asked for a value of
month greater or equal to 7 and less than or equal to 6. You probably
got an error message that told you that the data were of length zero
or something similar. If you check the result of that statement:

> mddat$month >= 7 & mddat$month <= 6
logical(0)

In other words, the two logical statements when ANDed cannot produce a
result. A number cannot be greater than or equal to 7 AND less than or
equal to 6. What you want is:

mddat2<-mddat[mddat$Year == 1975 & mddat$Month >= 7 |
 mddat$Year == 1976 & mddat$Month <= 6,]
mean(mddat2$Value)
[1] 88.91667

Apart from that, your email client is inserting EOL characters that
cause an error when pasted into R.

Error: unexpected input in "?"

Probably due to MS Outlook, this has been happening quite a bit lately.

Jim

On Mon, Aug 3, 2020 at 11:30 PM Md. Moyazzem Hossain
<hossainmm at juniv.edu> wrote:
>
> Dear Jim,
>
> Thank you very much. It is working now.
>
> However, I am also trying to find the average of the value from July 1975 to June 1976 and recorded as the value for the year 1975 but got an error message. I am attaching the data file here. Please check the attachment.
>
> mddat=read.csv("F:/mddat.csv", header=TRUE)
> mddat2<-mddat[mddat$Month >=7 & mddat$Month <= 6,]
> jan2jun<-by(mddat2$Value,mddat2$Year,mean)
> jan2jun
>
> Please help me again and many thanks in advance.
>
> Md
>
>
> On Mon, Aug 3, 2020 at 12:33 PM Rasmus Liland <jral at posteo.no> wrote:
>>
>> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>> > On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>> > >
>> > > Hi,
>> > >
>> > > I have a dataset having monthly
>> > > observations (from January to
>> > > December) over a period of time like
>> > > (2000 to 2018). Now, I am trying to
>> > > take an average the value from
>> > > January to July of each year.
>> > >
>> > > The data looks like
>> > > Year    Month  Value
>> > > 2000    1         25
>> > > 2000    2         28
>> > > 2000    3         22
>> > > ....    ......      .....
>> > > 2000    12       26
>> > > 2001     1       27
>> > > .......         ........
>> > > 2018    11       30
>> > > 20118   12      29
>> > >
>> > > Can someone help me in this regard?
>> > >
>> > > Many thanks in advance.
>> >
>> > Hi Md,
>> > One way is to form a subset of your
>> > data, then calculate the means by
>> > year:
>> >
>> > # assume your data is named mddat
>> > mddat2<-mddat[mddat$month < 7,]
>> > jan2jun<-by(mddat2$value,mddat2$year,mean)
>> >
>> > Jim
>>
>> Hi Md,
>>
>> you can also define the period in a new
>> column, and use aggregate like this:
>>
>>         Md <- structure(list(
>>         Year = c(2000L, 2000L, 2000L,
>>         2000L, 2001L, 2018L, 2018L),
>>         Month = c(1L, 2L, 3L, 12L, 1L,
>>         11L, 12L),
>>         Value = c(25L, 28L, 22L, 26L,
>>         27L, 30L, 29L)),
>>         class = "data.frame",
>>         row.names = c(NA, -7L))
>>
>>         Md[Md$Month %in%
>>                 1:6,"Period"] <- "first six months of the year"
>>         Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
>>
>>         aggregate(
>>           formula=Value~Year+Period,
>>           data=Md,
>>           FUN=mean)
>>
>> Rasmus
>
>
>


From @ndrew@h@||ord @end|ng |rom gm@||@com  Tue Aug  4 11:48:41 2020
From: @ndrew@h@||ord @end|ng |rom gm@||@com (Andrew Halford)
Date: Tue, 4 Aug 2020 20:48:41 +1100
Subject: [R] defining group colours in a call to rda
Message-ID: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>

Hi,

I've been trying to use the output on group membership of the final leaves
in a MRT analysis to define my own colours, however I am not getting the
result I'm after.

Here is the code
fish.pca <-rda(fish_all.hel,scale=TRUE)
fish.site <- scores(fish.pca,display="sites",scaling=3)
fish.spp <-
scores(fish.pca,display="species",scaling=3)[fish.MRT.indval$pval<=0.05,]
plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
points(fish.site,pch=21,bg=MI_fish_all.mrt$where,cex=1.2)
plotcolor <-
c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
 fish.pca <-rda(fish_all.hel,scale=TRUE)
plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
points(fish.site,pch=21,bg=plotcolor,cex=1.2)
MI_fish_all.mrt$where

If I run the points command and insert the group membership direct from the
MRT analysis e.g.  bg=MI_fish_all.mrt$where , then the subsequent points
plot up correctly with a different colour for each group.However if I try
to impose my own colour combo with plotcolor.....It prints colours for 2
groups and leaves the rest uncoloured.

The call to  MI_fish_all.mrt$where gives...
 [1] 3 3 8 6 6 9 5 5 9 3 8 6 9 6 5 9 5 3 8 6 9 6 5 9 5 3 3 8 6 6 9 5 5 9 6
9 5 9.

These are the split groupings for all 39 sites in the analysis and there
are 5 numbers corresponding to 5 final leaves in the tree.

I cant see why my colour scheme isnt being recognised.

All help accepted.

Andy


-- 
Andrew Halford Ph.D
Senior Coastal Fisheries Scientist
Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
New Caledonia | Noum?a, Nouvelle-Cal?donie

	[[alternative HTML version deleted]]


From percent||101 @end|ng |rom gm@||@com  Mon Aug  3 20:48:30 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Mon, 3 Aug 2020 20:48:30 +0200
Subject: [R] hist from a list
In-Reply-To: <20200731162847.GB106339@posteo.no>
References: <CAB-TgNv88YE29BkrXg9teFoMGXVOGfrYtDWy+Ltb8znRK9_OFQ@mail.gmail.com>
 <42a74b91-08ed-f5f2-b621-193e447dd824@dewey.myzen.co.uk>
 <70ef6db0-8a9d-d140-8347-b4e8b758f640@sapo.pt>
 <CAPPM_gQTOQwXdiMQtD_smhZDJ7uAjwyfT65TR_J-0Vhh+xhYqg@mail.gmail.com>
 <20200731162847.GB106339@posteo.no>
Message-ID: <CAB-TgNucrY+Qxp=Nn6-FJ2rWkbdPL2g4QK+G5FNmON5EgujBjg@mail.gmail.com>

Hi Rasmus, Josh and Rui,

First of all many thanks in advance about your help.

The first thig is sometimes you say " you are posting in HTML and that
makes the
post unreadable as this is a plain text list" how can I put the code in the
correct way, not html (attaching in txt?)

The second about the code:

I have used this:

bwc <- cbind(bwfinal2,bwfinal)
colnames(bwc)=c("Accion","reval")
df <- matrix(unlist(bwc), nrow=nrow(bwc), byrow=F)
colnames(bwchist)=c("Accion","reval")
bwchist <-as.data.frame(bwc[order(df[,2]), ])

bwchist is the ordered cum stock returns in the year but because is a list
it is not possible to plot and histogram with x (names of stocks) and the x
axist the value of cum stocks (reval)

when I put dput(bwchist) the console says:

dput(bwchist)
structure(list(Accion = list("REE", "Enagas", "Grifols", "Ferrovial",
    "Acerinox", "Naturgy", "Inditex", "Bankia", "ENCE", "Aena",
    "Bankinter", "Mapfre", "CaixaBank", "CIE", "Colonial", "Almirall",
    "Indra", "ArcelorMittal", "ACS", "Telefonica", "Amadeus",
    "BBVA", "Merlin", "Santander", "Repsol", "Melia", "Sabadell",
    "IAG", "Acciona", "Endesa", "MasMovil", "Iberdrola", "SGamesa",
    "Viscofan", "Cellnex"), reval = list(-0.0200827282700085,
    -0.0590294115600855, -0.214126598790964, -0.220773677809979,
    -0.229653300324357, -0.257944379583984, -0.283942789063822,
    -0.285159347392533, -0.303814713896458, -0.30734460425763,
    -0.309408155539818, -0.319912221435868, -0.322790949659181,
    -0.344047579452905, -0.347919538415482, -0.356898907103825,
    -0.374263261296661, -0.40147247119078, -0.405150043834815,
    -0.406022775042175, -0.413786100987797, -0.440679109311707,
    -0.442603156492871, -0.491634140733524, -0.499254932434042,
    -0.6, -0.709737357505148, -0.724461258850966, 0.0220528711420083,
    0.0462767672643172, 0.115044247787611, 0.238734548714937,
    0.274578114644054, 0.343422896082666, 0.387826126094928)), class =
"data.frame", row.names = c(NA,
-35L))

I try to make an hist or barplot but because it is a list no way to obtain
the plot.

Many thanks again for your help.

I have printed two manuals to improve my level, but if you can help me, I
would be very very gratefull.



El vie., 31 jul. 2020 a las 18:28, Rasmus Liland (<jral at posteo.no>)
escribi?:

> On 2020-07-31 10:07 -0500, Joshua Ulrich wrote:
> | On Fri, Jul 31, 2020 at 9:55 AM Rui Barradas wrote:
> | | ?s 15:44 de 31/07/2020, Michael Dewey escreveu:
> | | | Dear Pedro
> | | |
> | | | Some comments in-line
> | | |
> | | | On 30/07/2020 21:16, Pedro p?ramo wrote:
> | | | | Hi all,
> | | | |
> | | | | I attach my code, the think is I
> | | | | want to make a bar plot the last
> | | | | variable called "bwchist" so the
> | | | | X axis are "Accion" and the y
> | | | | axis are "reval" values.
> | | | |
> | | | | I have prove class(bwchist) and
> | | | | says dataframe but its still a
> | | | | list because it says me I have
> | | | | prove to unlist, but it doesnt
> | | | | work
> | | | |
> | | | | hist(bwchist)
> | | | | Error in hist.default(bwchist) : 'x' must be numeric
> | | |
> | | | So bwchist is not a numeric
> | | | variable as hist needs. Aboce you
> | | | said it is a data frame but data
> | | | frames are not numeric.
> | | |
> | | | For future reference your example
> | | | is way too long for anyone to go
> | | | through and try to help you. Try
> | | | next time to reduce it to the
> | | | absolute minimum by removing
> | | | sections while you still get the
> | | | error.  It is also easier to get
> | | | help if you can remove unnecessary
> | | | packages.
> | | |
> | | | It is also unreadable because you
> | | | are posting in HTML and that makes
> | | | the post unreadable as this is a
> | | | plain text list.
> | |
> | | Hello,
> | |
> | | I second Michael's opinion. When the
> | | post's code is very long, there is a
> | | tendency to have less answers.
> | |
> | | Please post the output of
> | |
> | |     dput(head(bwchist, 30))
> | |
> | | It's much shorter code and it
> | | recreates the data so we will be
> | | able to see what's wrong and try to
> | | find a solution.
> |
> | Hi Pedro,
> |
> | Another 'best practice' and polite
> | thing to do is link to other places
> | you may have cross-posted.  That will
> | give people the opportunity to see if
> | your questions has been answered in
> | another forum.
> |
> | I saw your post on R-SIG-Finance
> | (https://stat.ethz.ch/pipermail/r-sig-finance/2020q3/014979.html),
> | and started to work on a solution.
> |
> | I don't know how to do this in
> | tidyquant, but here's how you can do
> | it with quantmod:
> |
> | # all tickers
> | tk <- c("ANA.MC", "ACS.MC", "AENA.MC", "AMS.MC", "MTS.MC", "BBVA.MC", "
> SAB.MC",
> |   "SAN.MC", "BKT.MC", "CABK.MC", "CLNX.MC", "ENG.MC", "ENC.MC", "ELE.MC
> ",
> |   "FER.MC", "GRF.MC", "IBE.MC", "ITX.MC", "COL.MC", "IAG.MC", "MAP.MC",
> |   "MEL.MC", "MRL.MC", "NTGY.MC", "REE.MC", "REP.MC", "SGRE.MC", "TEF.MC
> ",
> |   "VIS.MC", "ACX.MC", "BKIA.MC", "CIE.MC", "MAS.MC", "ALM.MC", "IDR.MC")
> |
> | # download them into an environment ('e')
> | require(quantmod)
> | getSymbols(tk, from = "2019-12-31", env = (e <- new.env()))
> |
> | # extract adjusted close column
> | adj <- lapply(e, Ad)
> | # calculate daily returns from adjusted data,
> | # merge into a xts matrix, and fill NA with 0
> | ret <- do.call(merge, c(lapply(adj, dailyReturn), fill = 0))
> | # cumulative returns
> | cumret <- cumprod(1 + ret) - 1
> | # set names
> | colnames(cumret) <- names(adj)
> | last(cumret)
> | # calculate histogram for period-to-date returns
> | hist(drop(last(cumret)))
> |
> | I'm not sure that's the histogram
> | you're looking for, but I hope it
> | gives you a start toward a solution.
> |
> | Best,
> | Josh
>
> Wow Josh!  That's very elegant.
>
> Myself now, I just plowed through the
> original code to make it simpler, but am
> at a loss as to how this histogram looks
> ...
>
>         x <- c("ANA.MC", "ACS.MC", "AENA.MC", "AMS.MC", "MTS.MC", "BBVA.MC
> ",
>           "SAB.MC", "SAN.MC", "BKT.MC", "CABK.MC", "CLNX.MC", "ENG.MC",
>           "ENC.MC", "ELE.MC", "FER.MC", "GRF.MC", "IBE.MC", "ITX.MC",
>           "COL.MC", "IAG.MC", "MAP.MC", "MEL.MC", "MRL.MC", "NTGY.MC",
>           "REE.MC", "REP.MC", "SGRE.MC", "TEF.MC", "VIS.MC", "ACX.MC",
>           "BKIA.MC", "CIE.MC", "MAS.MC", "ALM.MC", "IDR.MC")
>         stock.prices <-
>           lapply(x, function(stock) {
>             tidyquant::tq_get(x=stock,from = '2019-12-31',get =
> "stock.prices")
>           })
>         names(stock.prices) <- x
>
>         library(tidyquant)
>
>         returns <- lapply(stock.prices, function(data) {
>           tab <-
>             tq_transmute(
>               data = data,
>               select = adjusted,           # this specifies which column
> to select
>               mutate_fun = periodReturn,   # This specifies what to do
> with that column
>               period = "daily",            # This argument calculates
> Daily returns
>               col_rename = "idr_returns")  # renames the column
>           tab[,"cr"] <- cumprod(1 + tab[,"idr_returns"])
>           tab[,"cumulative_returns"] <- tab[,"cr"] - 1
>
>           dplyr::pull(
>             tab[nrow(tab[,"cumulative_returns"]),
>                           "cumulative_returns"]
>           )
>         })
>
>         bestworst <- simplify2array(returns)
>
>         namebw <-
>           c("Acciona", "ACS", "Aena", "Amadeus",
>             "ArcelorMittal", "BBVA", "Sabadell",
>             "Santander", "Bankinter",
>             "CaixaBank", "Cellnex", "Enagas",
>             "ENCE", "Endesa", "Ferrovial",
>             "Grifols", "Iberdrola", "Inditex",
>             "Colonial", "IAG", "Mapfre",
>             "Melia", "Merlin", "Naturgy", "REE",
>             "Repsol", "SGamesa", "Telefonica",
>             "Viscofan", "Acerinox", "Bankia",
>             "CIE", "MasMovil", "Almirall",
>             "Indra")
>
>         bwc <- data.frame(
>           symbol=names(bestworst),
>           Accion=namebw,
>           reval=bestworst)
>
> | | | | bwc<-cbind(bwfinal2,bwfinal)
> | | | | colnames(bwc)=c("Accion","reval")
> | | | | bwc <- as.data.frame(bwc)
>
> ... aaaand you know something's
> happening between here (where bwchist is
> created), but you don't know what it is,
> do you, Mr p?ramo?
>
> | | | | colnames(bwchist)=c("Accion","reval")
> | | | | bwchist <-as.data.frame(bwc[order(bwc$reval), ])
>
> Best,
> Rasmus
>

	[[alternative HTML version deleted]]


From pr@k@@h@n@n| @end|ng |rom gm@||@com  Tue Aug  4 13:54:23 2020
From: pr@k@@h@n@n| @end|ng |rom gm@||@com (K Purna Prakash)
Date: Tue, 4 Aug 2020 17:24:23 +0530
Subject: [R] Mathematical working procedure of duplicated() function in r
Message-ID: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>

Dear Sir(s),
I request you to provide the detailed* internal mathematical working
mechanism of the following function *for better understanding.
*x[duplicated(x) | duplicated(x, fromLast=TRUE), ]*
I am having some confusion in understanding how duplicates are being
identified when thousands of records are there.
I will look for a positive response.
Thank you,
K.Purna Prakash.

	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Aug  4 15:51:26 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 4 Aug 2020 13:51:26 +0000 (UTC)
Subject: [R] Double MAD with R
In-Reply-To: <c41de121-e6ca-493c-ec98-c066c32914b4@sapo.pt>
References: <401386585.16460890.1596464541734.ref@mail.yahoo.com>
 <401386585.16460890.1596464541734@mail.yahoo.com>
 <c41de121-e6ca-493c-ec98-c066c32914b4@sapo.pt>
Message-ID: <1132519911.436880.1596549086818@mail.yahoo.com>

Dear Rui,

Many thanks for your response. 

Best,

SV







Le lundi 3 ao?t 2020 ? 16:54:35 UTC+2, Rui Barradas <ruipbarradas at sapo.pt> a ?crit : 





Hello,

No, there isn't a built-in that I know of.
Here is one:


double.mad <- function(x, include.right = FALSE, na.rm = FALSE){
? if(na.rm) x <- x[!is.na(x)]
? m <- median(x)
? odd <- (length(x) %% 2L) == 1L
? out <- if(odd){
??? if(include.right) {
????? c(lo = mad(x[x < m]), hi = mad(x[x >= m]))
??? } else {
????? c(lo = mad(x[x <= m]), hi = mad(x[x > m]))
??? }
? } else {
??? c(lo = mad(x[x < m]), hi = mad(x[x > m]))
? }
? out
}

double.mad(x)
#???? lo????? hi
#0.81543 0.44478

double.mad(c(x, 1))
#???? lo????? hi
#2.29803 0.44478

double.mad(c(x, 1), include.right = TRUE)
#???? lo????? hi
#1.03782 1.63086


Hope this helps,

Rui Barradas

?s 15:22 de 03/08/2020, varin sacha via R-help escreveu:
> Dear R-Experts,
>
> Is there an all-ready function to calculate the Double MAD (Median absolute deviation) as there is an easy function to calculate the MAD "mad function". Or I have to write my own function for Double MAD ?
>
> To calculate the double MAD, the idea is the following : for the obtained median value, we should calculate two median absolution deviations. One deviation should be calculated for the numbers below the median and one for the numbers above the median:
>
> Here is the very easy reproducible example :
>
> x<-c(2.5,4.4,3.2,2.1,1.3,2.6,5,6.6,5,5,6.1,7.2,9.4,6.9)
> mad(x)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Aug  4 16:08:06 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 4 Aug 2020 14:08:06 +0000 (UTC)
Subject: [R] confidence intervals for the difference between group means
References: <287735883.448015.1596550086626.ref@mail.yahoo.com>
Message-ID: <287735883.448015.1596550086626@mail.yahoo.com>

Dear R-experts,

Using the bootES package I can easily calculate the bootstrap confidence intervals of the means like in the toy example here below. Now, I am looking for the confidence intervals for the difference between group means. In my case, the point estimate of the mean difference is 64.4. I am looking at the 95% confidence intervals around this point estimate (64.4).

Many thanks for your response.

############
library(bootES)
a<-c(523,435,478,567,654) 
b<-c(423,523,421,467,501)
bootES(a)
bootES(b)
############


From M@tth|@@@Koh| @end|ng |rom @t@m@t@@de  Tue Aug  4 16:22:03 2020
From: M@tth|@@@Koh| @end|ng |rom @t@m@t@@de (Prof. Dr. Matthias Kohl)
Date: Tue, 4 Aug 2020 16:22:03 +0200
Subject: [R] confidence intervals for the difference between group means
In-Reply-To: <287735883.448015.1596550086626@mail.yahoo.com>
References: <287735883.448015.1596550086626.ref@mail.yahoo.com>
 <287735883.448015.1596550086626@mail.yahoo.com>
Message-ID: <49a5936b-47e3-1b19-0398-893c4a8b8c5e@stamats.de>

you could try:

library(MKinfer)
meanDiffCI(a, b, boot = TRUE)

Best
Matthias

Am 04.08.20 um 16:08 schrieb varin sacha via R-help:
> Dear R-experts,
> 
> Using the bootES package I can easily calculate the bootstrap confidence intervals of the means like in the toy example here below. Now, I am looking for the confidence intervals for the difference between group means. In my case, the point estimate of the mean difference is 64.4. I am looking at the 95% confidence intervals around this point estimate (64.4).
> 
> Many thanks for your response.
> 
> ############
> library(bootES)
> a<-c(523,435,478,567,654)
> b<-c(423,523,421,467,501)
> bootES(a)
> bootES(b)
> ############
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Prof. Dr. Matthias Kohl
www.stamats.de


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  4 18:35:00 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 4 Aug 2020 17:35:00 +0100
Subject: [R] 
 Mathematical working procedure of duplicated() function in r
In-Reply-To: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
References: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
Message-ID: <f49bf364-4d6e-1750-b9e5-2e2b4ebeb776@sapo.pt>

Hello,

R is open source, you can see exactly what is the internal working of 
any function. You can have access to the code by typing the function's 
name without parenthesis at an R command line.

 > duplicated
function (x, incomparables = FALSE, ...)
UseMethod("duplicated")
<bytecode: 0x55e5ef683040>
<environment: namespace:base>

Now, this tells users that duplicated is a generic function, and that 
there are methods written to handle the different S3 classes of objects x.
When this happens, there is always a default method, duplicated.default

 > duplicated.default
function (x, incomparables = FALSE, fromLast = FALSE, nmax = NA,
     ...)
.Internal(duplicated(x, incomparables, fromLast, if (is.factor(x)) 
min(length(x),
     nlevels(x) + 1L) else nmax))
<bytecode: 0x55e5ef6826a0>
<environment: namespace:base>


The default method calls .Internal(duplicated, etc). So you'll have to 
download the R sources, if you haven't done it yet, and search for a 
file where that function might be. The file is

src/main/duplicate.c


Good reading.
Also, like the posting guide asks R-Help users to do, please post in 
plain text, not in HTML.

Hope this helps,

Rui Barradas

?s 12:54 de 04/08/20, K Purna Prakash escreveu:
> Dear Sir(s),
> I request you to provide the detailed* internal mathematical working
> mechanism of the following function *for better understanding.
> *x[duplicated(x) | duplicated(x, fromLast=TRUE), ]*
> I am having some confusion in understanding how duplicates are being
> identified when thousands of records are there.
> I will look for a positive response.
> Thank you,
> K.Purna Prakash.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 @end|ng |rom gm@||@com  Tue Aug  4 21:22:13 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 4 Aug 2020 13:22:13 -0600
Subject: [R] 
 Mathematical working procedure of duplicated() function in r
In-Reply-To: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
References: <CAOGJCotyVfPC8iHU3b97ZcwPpkW0B2tPZy0n2sTmf5Ab5A=xBw@mail.gmail.com>
Message-ID: <CAFEqCdyVzsV4muDSrMH77_M+8HGBW35oJjoTAWD9FrWfuorzzA@mail.gmail.com>

Rui pointed out that you can examine the source yourself.  FAQ 7.40
has a link to an article with detail on finding and examining the
source code.

A general algorithm for checking for duplicates follows (I have not
examined to R source code to see if they use something more clever).

Create an empty object (I will call it seen).  This could be a simple
vector, but for efficiency it is better to use an object type that has
fast lookup, e.g. binary tree, associative array/hash/dictionary, etc.

Create an empty vector of logicals the same length as x (I will call it result).

loop from 1 to the length of x (or from the length to 1 if
fromLast=TRUE), on each iteration
 check to see if the value of x[i] is in seen
   If it is: set result[i] to TRUE
   If it is not: add the current value to seen and set result[i] to false

After the loop finishes, throw away seen and reclaim the memory, then
return result.

Since it looks like you are using this on a matrix or data frame,
there is probably a preprocessing step that combines all the values on
each row into a single character string.

On Tue, Aug 4, 2020 at 6:45 AM K Purna Prakash <prakash.nani at gmail.com> wrote:
>
> Dear Sir(s),
> I request you to provide the detailed* internal mathematical working
> mechanism of the following function *for better understanding.
> *x[duplicated(x) | duplicated(x, fromLast=TRUE), ]*
> I am having some confusion in understanding how duplicates are being
> identified when thousands of records are there.
> I will look for a positive response.
> Thank you,
> K.Purna Prakash.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From @purd|e@@ @end|ng |rom gm@||@com  Tue Aug  4 23:39:56 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 5 Aug 2020 09:39:56 +1200
Subject: [R] defining group colours in a call to rda
In-Reply-To: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>
References: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>
Message-ID: <CAB8pepwCnn9qFa0NA5=yB2TFy5XhFHHi35-p2kdkkqCCrEsGSA@mail.gmail.com>

Hi,

Your example is not reproducible.
However, I suspect that the following is the problem:

c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]

Here's my version:

where = c (3, 3, 8, 6, 6, 9, 5, 5, 9, 3, 8, 6, 9, 6, 5, 9, 5, 3, 8, 6,
9, 6, 5, 9, 5, 3, 3, 8, 6, 6, 9, 5, 5, 9, 6, 9, 5, 9)
unique (where)

c("red", "green", "blue", "aquamarine", "magenta")[where]

There's five colors.
But only two of the indices are within one to five.
So, the resulting color vector contains missing values.

In the base graphics system, if you set colors to NA, it usually means no color.

I'm not sure exactly what you want to do, but I'm assuming you can fix
it from here.

On Tue, Aug 4, 2020 at 9:49 PM Andrew Halford <andrew.halford at gmail.com> wrote:
>
> Hi,
>
> I've been trying to use the output on group membership of the final leaves
> in a MRT analysis to define my own colours, however I am not getting the
> result I'm after.
>
> Here is the code
> fish.pca <-rda(fish_all.hel,scale=TRUE)
> fish.site <- scores(fish.pca,display="sites",scaling=3)
> fish.spp <-
> scores(fish.pca,display="species",scaling=3)[fish.MRT.indval$pval<=0.05,]
> plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
> points(fish.site,pch=21,bg=MI_fish_all.mrt$where,cex=1.2)
> plotcolor <-
> c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
>  fish.pca <-rda(fish_all.hel,scale=TRUE)
> plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
> points(fish.site,pch=21,bg=plotcolor,cex=1.2)
> MI_fish_all.mrt$where
>
> If I run the points command and insert the group membership direct from the
> MRT analysis e.g.  bg=MI_fish_all.mrt$where , then the subsequent points
> plot up correctly with a different colour for each group.However if I try
> to impose my own colour combo with plotcolor.....It prints colours for 2
> groups and leaves the rest uncoloured.
>
> The call to  MI_fish_all.mrt$where gives...
>  [1] 3 3 8 6 6 9 5 5 9 3 8 6 9 6 5 9 5 3 8 6 9 6 5 9 5 3 3 8 6 6 9 5 5 9 6
> 9 5 9.
>
> These are the split groupings for all 39 sites in the analysis and there
> are 5 numbers corresponding to 5 final leaves in the tree.
>
> I cant see why my colour scheme isnt being recognised.
>
> All help accepted.
>
> Andy
>
>
> --
> Andrew Halford Ph.D
> Senior Coastal Fisheries Scientist
> Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
> New Caledonia | Noum?a, Nouvelle-Cal?donie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Aug  4 23:45:00 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 4 Aug 2020 22:45:00 +0100
Subject: [R] Arrange data
In-Reply-To: <CAO29qn7_qpuOvDodrWUCm+3Js7mXrRhAYa0-kmunEyWZbMMUbA@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <de75298f-9ba6-2ed3-5e2b-4095424f9834@sapo.pt>
 <CAO29qn7_qpuOvDodrWUCm+3Js7mXrRhAYa0-kmunEyWZbMMUbA@mail.gmail.com>
Message-ID: <63668df7-0823-0a33-3e31-71a794e85b28@sapo.pt>

Hello,

Please keep cc-ing the list R-help is threaded and questions and answers 
might be of help to others in the future.

As for the question, see if the following code does what you want.
First, create a logical index i of the months between 7 and 3 and use 
that index to subset the original data.frame. Then, a cumsum trick gives 
a vector M defining the data grouping. Group and compute the Value means 
with aggregate. Finally, since each group spans a year border, create a 
more meaningful Years column and put everything together.

df1 <- read.csv("mddat.csv")

i <- with(df1, (Month >= 7 & Month <= 12) | (Month >= 1 & Month <= 3))
df2 <- df1[i, ]
M <- cumsum(c(FALSE, diff(as.integer(row.names(df2))) > 1))

agg <- aggregate(Value ~ M, df2, mean)
Years <- sapply(split(df2$Year, M), function(x){paste(x[1], 
x[length(x)], sep = "-")})
final <- cbind.data.frame(Years, Value = agg[["Value"]])

head(final)
#      Years    Value
#0 1975-1975 87.00000
#1 1975-1976 89.44444
#2 1976-1977 85.77778
#3 1977-1978 81.55556
#4 1978-1979 71.55556
#5 1979-1980 75.77778


Hope this helps,

Rui Barradas



?s 20:44 de 04/08/20, Md. Moyazzem Hossain escreveu:
> Dear Rui,
> 
> Thanks a lot for your help.
> 
> It is working. Now I am also trying to find the average of values for 
> *July 1975 to March 1976* and record as the value of the year 1975. 
> Moreover, I want to continue it up to the year 2017. You may check the 
> attached file for data (mddat.csv).
> 
> I use the following function but got error
> aggregate(Value ~ Year, data = subset(df1, Month >= 7 & Month <= 3), FUN 
> = mean)
> 
> Please help me again. Thanks in advance.
> 
> Best Regards,
> Md
> 
> On Mon, Aug 3, 2020 at 11:28 PM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     And here is another way, with aggregate.
> 
>     Make up test data.
> 
>     set.seed(2020)
>     df1 <- expand.grid(Year = 2000:2018, Month = 1:12)
>     df1 <- df1[order(df1$Year),]
>     df1$Value <- sample(20:30, nrow(df1), TRUE)
>     head(df1)
> 
> 
>     #Use subset to keep only the relevant months
>     aggregate(Value ~ Year, data = subset(df1, Month <= 7), FUN = mean)
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 12:33 de 03/08/2020, Rasmus Liland escreveu:
>      > On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>      >> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain
>     <hossainmm at juniv.edu <mailto:hossainmm at juniv.edu>> wrote:
>      >>> Hi,
>      >>>
>      >>> I have a dataset having monthly
>      >>> observations (from January to
>      >>> December) over a period of time like
>      >>> (2000 to 2018). Now, I am trying to
>      >>> take an average the value from
>      >>> January to July of each year.
>      >>>
>      >>> The data looks like
>      >>> Year? ? Month? Value
>      >>> 2000? ? 1? ? ? ? ?25
>      >>> 2000? ? 2? ? ? ? ?28
>      >>> 2000? ? 3? ? ? ? ?22
>      >>> ....? ? ......? ? ? .....
>      >>> 2000? ? 12? ? ? ?26
>      >>> 2001? ? ?1? ? ? ?27
>      >>> .......? ? ? ? ?........
>      >>> 2018? ? 11? ? ? ?30
>      >>> 20118? ?12? ? ? 29
>      >>>
>      >>> Can someone help me in this regard?
>      >>>
>      >>> Many thanks in advance.
>      >> Hi Md,
>      >> One way is to form a subset of your
>      >> data, then calculate the means by
>      >> year:
>      >>
>      >> # assume your data is named mddat
>      >> mddat2<-mddat[mddat$month < 7,]
>      >> jan2jun<-by(mddat2$value,mddat2$year,mean)
>      >>
>      >> Jim
>      > Hi Md,
>      >
>      > you can also define the period in a new
>      > column, and use aggregate like this:
>      >
>      >? ? ? ?Md <- structure(list(
>      >? ? ? ?Year = c(2000L, 2000L, 2000L,
>      >? ? ? ?2000L, 2001L, 2018L, 2018L),
>      >? ? ? ?Month = c(1L, 2L, 3L, 12L, 1L,
>      >? ? ? ?11L, 12L),
>      >? ? ? ?Value = c(25L, 28L, 22L, 26L,
>      >? ? ? ?27L, 30L, 29L)),
>      >? ? ? ?class = "data.frame",
>      >? ? ? ?row.names = c(NA, -7L))
>      >
>      >? ? ? ?Md[Md$Month %in%
>      >? ? ? ? ? ? ? ?1:6,"Period"] <- "first six months of the year"
>      >? ? ? ?Md[Md$Month %in% 7:12,"Period"] <- "last six months of the
>     year"
>      >
>      >? ? ? ?aggregate(
>      >? ? ? ? ?formula=Value~Year+Period,
>      >? ? ? ? ?data=Md,
>      >? ? ? ? ?FUN=mean)
>      >
>      > Rasmus
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
> 
> 
>     -- 
>     Este e-mail foi verificado em termos de v?rus pelo software
>     antiv?rus Avast.
>     https://www.avast.com/antivirus
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From d@071185 @end|ng |rom gm@||@com  Tue Aug  4 21:03:13 2020
From: d@071185 @end|ng |rom gm@||@com (Debasmita Sur)
Date: Wed, 5 Aug 2020 00:33:13 +0530
Subject: [R] finding nearest zip codes
Message-ID: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>

Dear R-experts,
I have two lists of US zip codes and want to pick the nearest zip code from
second list against my first list.e.g.30043 (from second list) is closest
to the zip code 30094 (from first list).So,it should come against 30094.The
code should compare the distance from each zip and pick the nearest one.
I have written the following code. It is giving proper results for many,
but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
giving proper minimum distance. Please note it will be effective for 5
digit zip codes. Any help will be highly appreciated.

df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")

results<-merge(x=df1,y=zipcode,all.x=TRUE)
results1<-merge(x=df2,y=zipcode,all.x=TRUE)
distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))

rnum=apply(distance, 1, which.min)
mindist=apply(distance, 1, min)

final<-cbind(results,results1$zip[unlist(rnum)],mindist)


Thanks & Regards,
*Debasmita *

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Aug  5 03:38:45 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 4 Aug 2020 21:38:45 -0400
Subject: [R] [External]  finding nearest zip codes
In-Reply-To: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
Message-ID: <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>

verify that you actually have five-digit zip codes stored as
characters. New Jersey and Massachusetts have zero as
the first digit.  When these codes are saved as numbers, they become
four-digit codes and will probably cause errors.
For example Cambridge, Mass is '02138', and would be reported as 2138
when interpreted as a number..

On Tue, Aug 4, 2020 at 9:29 PM Debasmita Sur <ds071185 at gmail.com> wrote:
>
> Dear R-experts,
> I have two lists of US zip codes and want to pick the nearest zip code from
> second list against my first list.e.g.30043 (from second list) is closest
> to the zip code 30094 (from first list).So,it should come against 30094.The
> code should compare the distance from each zip and pick the nearest one.
> I have written the following code. It is giving proper results for many,
> but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
> giving proper minimum distance. Please note it will be effective for 5
> digit zip codes. Any help will be highly appreciated.
>
> df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
> df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
>
> results<-merge(x=df1,y=zipcode,all.x=TRUE)
> results1<-merge(x=df2,y=zipcode,all.x=TRUE)
> distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
>
> rnum=apply(distance, 1, which.min)
> mindist=apply(distance, 1, min)
>
> final<-cbind(results,results1$zip[unlist(rnum)],mindist)
>
>
> Thanks & Regards,
> *Debasmita *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug  5 03:54:09 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 4 Aug 2020 18:54:09 -0700
Subject: [R] finding nearest zip codes
In-Reply-To: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
Message-ID: <CAGxFJbT_zHmCWyAwmPzXjrKJrRbMX0zk3iBBBqYmAV1oqinfJA@mail.gmail.com>

In addition to Rich's advice...
as always, have you searched?!
e.g. on "zip code distances" or similar at rseek.org.

This appears to have been asked before and there are tools available.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 4, 2020 at 6:29 PM Debasmita Sur <ds071185 at gmail.com> wrote:

> Dear R-experts,
> I have two lists of US zip codes and want to pick the nearest zip code from
> second list against my first list.e.g.30043 (from second list) is closest
> to the zip code 30094 (from first list).So,it should come against 30094.The
> code should compare the distance from each zip and pick the nearest one.
> I have written the following code. It is giving proper results for many,
> but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
> giving proper minimum distance. Please note it will be effective for 5
> digit zip codes. Any help will be highly appreciated.
>
> df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
> df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
>
> results<-merge(x=df1,y=zipcode,all.x=TRUE)
> results1<-merge(x=df2,y=zipcode,all.x=TRUE)
>
> distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
>
> rnum=apply(distance, 1, which.min)
> mindist=apply(distance, 1, min)
>
> final<-cbind(results,results1$zip[unlist(rnum)],mindist)
>
>
> Thanks & Regards,
> *Debasmita *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @ndrew@h@||ord @end|ng |rom gm@||@com  Wed Aug  5 06:32:33 2020
From: @ndrew@h@||ord @end|ng |rom gm@||@com (Andrew Halford)
Date: Wed, 5 Aug 2020 15:32:33 +1100
Subject: [R] Fwd:  defining group colours in a call to rda
In-Reply-To: <CAB8pepwQEGkCcQHci12R66KYiYvczZvXAW+hQ+S6aaw6_4DaZg@mail.gmail.com>
References: <CAJrFtq+2CW2Ecnj1hYxMnf7Gm0K_wsdgW7h92you+oiKgfxJQg@mail.gmail.com>
 <CAB8pepwCnn9qFa0NA5=yB2TFy5XhFHHi35-p2kdkkqCCrEsGSA@mail.gmail.com>
 <CAJrFtqJyN8CnCrVi9uRSQMbs=TiU7YJOYvkn_qE5uCweOqQAuw@mail.gmail.com>
 <CAB8pepwQEGkCcQHci12R66KYiYvczZvXAW+hQ+S6aaw6_4DaZg@mail.gmail.com>
Message-ID: <CAJrFtqLna9yZT+4hgr-fVswGsJLkSdmtNjPMdi1zkwXBJAqdbw@mail.gmail.com>

---------- Forwarded message ---------
From: Abby Spurdle <spurdle.a at gmail.com>
Date: Wed, Aug 5, 2020 at 3:07 PM
Subject: Re: [R] defining group colours in a call to rda
To: Andrew Halford <andrew.halford at gmail.com>


Hi Andrew,

Perhaps you want this:

    cols <- rep_len (c ("red", "green", "blue", "aquamarine", "magenta"), 9)
    cols

Or this:

    cols = rep ("", 9)
    cols [unique (MI_fish_all.mrt$where)] = c ("red", "green", "blue",
"aquamarine", "magenta")
    cols

Then you can substitute either into your original example:

    plotcolor <- cols [MI_fish_all.mrt$where]


On Wed, Aug 5, 2020 at 1:02 PM Andrew Halford <andrew.halford at gmail.com>
wrote:
>
> Hi Abby,
>
> Apologies for not providing more info but you have worked out what I was
on about anyways.
>
> I thought it would scroll through and allocate the colours to each unique
number sequentially. I will add more colours to my vector but I would like
to know if it is possible to do what I originally hoped for.
>
> cheers
>
> Andy
>
> On Wed, Aug 5, 2020 at 8:40 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>> Hi,
>>
>> Your example is not reproducible.
>> However, I suspect that the following is the problem:
>>
>> c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
>>
>> Here's my version:
>>
>> where = c (3, 3, 8, 6, 6, 9, 5, 5, 9, 3, 8, 6, 9, 6, 5, 9, 5, 3, 8, 6,
>> 9, 6, 5, 9, 5, 3, 3, 8, 6, 6, 9, 5, 5, 9, 6, 9, 5, 9)
>> unique (where)
>>
>> c("red", "green", "blue", "aquamarine", "magenta")[where]
>>
>> There's five colors.
>> But only two of the indices are within one to five.
>> So, the resulting color vector contains missing values.
>>
>> In the base graphics system, if you set colors to NA, it usually means
no color.
>>
>> I'm not sure exactly what you want to do, but I'm assuming you can fix
>> it from here.
>>
>> On Tue, Aug 4, 2020 at 9:49 PM Andrew Halford <andrew.halford at gmail.com>
wrote:
>> >
>> > Hi,
>> >
>> > I've been trying to use the output on group membership of the final
leaves
>> > in a MRT analysis to define my own colours, however I am not getting
the
>> > result I'm after.
>> >
>> > Here is the code
>> > fish.pca <-rda(fish_all.hel,scale=TRUE)
>> > fish.site <- scores(fish.pca,display="sites",scaling=3)
>> > fish.spp <-
>> >
scores(fish.pca,display="species",scaling=3)[fish.MRT.indval$pval<=0.05,]
>> > plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
>> > points(fish.site,pch=21,bg=MI_fish_all.mrt$where,cex=1.2)
>> > plotcolor <-
>> > c("red","green","blue","aquamarine","magenta")[MI_fish_all.mrt$where]
>> >  fish.pca <-rda(fish_all.hel,scale=TRUE)
>> > plot(fish.pca,display=c("sites","species"),type="n",scaling=3)
>> > points(fish.site,pch=21,bg=plotcolor,cex=1.2)
>> > MI_fish_all.mrt$where
>> >
>> > If I run the points command and insert the group membership direct
from the
>> > MRT analysis e.g.  bg=MI_fish_all.mrt$where , then the subsequent
points
>> > plot up correctly with a different colour for each group.However if I
try
>> > to impose my own colour combo with plotcolor.....It prints colours for
2
>> > groups and leaves the rest uncoloured.
>> >
>> > The call to  MI_fish_all.mrt$where gives...
>> >  [1] 3 3 8 6 6 9 5 5 9 3 8 6 9 6 5 9 5 3 8 6 9 6 5 9 5 3 3 8 6 6 9 5 5
9 6
>> > 9 5 9.
>> >
>> > These are the split groupings for all 39 sites in the analysis and
there
>> > are 5 numbers corresponding to 5 final leaves in the tree.
>> >
>> > I cant see why my colour scheme isnt being recognised.
>> >
>> > All help accepted.
>> >
>> > Andy
>> >
>> >
>> > --
>> > Andrew Halford Ph.D
>> > Senior Coastal Fisheries Scientist
>> > Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848
Noumea,
>> > New Caledonia | Noum?a, Nouvelle-Cal?donie
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Andrew Halford Ph.D
> Senior Coastal Fisheries Scientist
> Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
> New Caledonia | Noum?a, Nouvelle-Cal?donie


-- 
Andrew Halford Ph.D
Senior Coastal Fisheries Scientist
Pacific Community | Communaut? du Pacifique CPS ? B.P. D5 | 98848 Noumea,
New Caledonia | Noum?a, Nouvelle-Cal?donie

	[[alternative HTML version deleted]]


From d@071185 @end|ng |rom gm@||@com  Wed Aug  5 08:01:01 2020
From: d@071185 @end|ng |rom gm@||@com (Debasmita Sur)
Date: Wed, 5 Aug 2020 11:31:01 +0530
Subject: [R] [External]  finding nearest zip codes
In-Reply-To: <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
 <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>
Message-ID: <CACtCA_N1WJo-1A_AhAVDCj4PBiLHovbVtNafzSURu8a_Bf3GAg@mail.gmail.com>

Hi Richard,

I have not considered the 4 digit zip codes, I have taken only 5 digits. I
have attached two folders, in the 'air' folder I have some specific zip
codes and in output I got proper results, whereas in the 'par' folder I got
'NA's in the minimum distance column. Actually, the problem was to find the
nearest store for a specific brand.

Thanks,
*Debasmita*

On Wed, Aug 5, 2020 at 7:08 AM Richard M. Heiberger <rmh at temple.edu> wrote:

> verify that you actually have five-digit zip codes stored as
> characters. New Jersey and Massachusetts have zero as
> the first digit.  When these codes are saved as numbers, they become
> four-digit codes and will probably cause errors.
> For example Cambridge, Mass is '02138', and would be reported as 2138
> when interpreted as a number..
>
> On Tue, Aug 4, 2020 at 9:29 PM Debasmita Sur <ds071185 at gmail.com> wrote:
> >
> > Dear R-experts,
> > I have two lists of US zip codes and want to pick the nearest zip code
> from
> > second list against my first list.e.g.30043 (from second list) is closest
> > to the zip code 30094 (from first list).So,it should come against
> 30094.The
> > code should compare the distance from each zip and pick the nearest one.
> > I have written the following code. It is giving proper results for many,
> > but in mindist, it is showing 'NAs'. But for some of the zip codes, it is
> > giving proper minimum distance. Please note it will be effective for 5
> > digit zip codes. Any help will be highly appreciated.
> >
> > df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
> > df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
> >
> > results<-merge(x=df1,y=zipcode,all.x=TRUE)
> > results1<-merge(x=df2,y=zipcode,all.x=TRUE)
> >
> distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
> >
> > rnum=apply(distance, 1, which.min)
> > mindist=apply(distance, 1, min)
> >
> > final<-cbind(results,results1$zip[unlist(rnum)],mindist)
> >
> >
> > Thanks & Regards,
> > *Debasmita *
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug  5 08:12:39 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Aug 2020 23:12:39 -0700
Subject: [R] [External]  finding nearest zip codes
In-Reply-To: <CACtCA_N1WJo-1A_AhAVDCj4PBiLHovbVtNafzSURu8a_Bf3GAg@mail.gmail.com>
References: <CACtCA_PN94ZMQsX8Fok7FTXxrL_PR8BD=_KhUYH+DtLLMX9_ZQ@mail.gmail.com>
 <CAGx1TMCicANrTXt-jrtvMZs=N-KAKNQGKcXrxyzopC81-_J6Uw@mail.gmail.com>
 <CACtCA_N1WJo-1A_AhAVDCj4PBiLHovbVtNafzSURu8a_Bf3GAg@mail.gmail.com>
Message-ID: <1862AB56-5524-414D-BC73-734290EF1299@dcn.davis.ca.us>

If you fail to force the zip code data to be read in as character data then you will have problems. Your code does not use the colClasses argument or the stringsAsFactors=FALSE argument (needed if you are using a version of R earlier than 4.x). Richard was suggesting that you use the str function to examine your data frames to verify correct data types were present.

Please read the Posting Guide... using HTML formatted email and attaching disallowed file types as you have done are good ways to prevent useful answers from being offered.

On August 4, 2020 11:01:01 PM PDT, Debasmita Sur <ds071185 at gmail.com> wrote:
>Hi Richard,
>
>I have not considered the 4 digit zip codes, I have taken only 5
>digits. I
>have attached two folders, in the 'air' folder I have some specific zip
>codes and in output I got proper results, whereas in the 'par' folder I
>got
>'NA's in the minimum distance column. Actually, the problem was to find
>the
>nearest store for a specific brand.
>
>Thanks,
>*Debasmita*
>
>On Wed, Aug 5, 2020 at 7:08 AM Richard M. Heiberger <rmh at temple.edu>
>wrote:
>
>> verify that you actually have five-digit zip codes stored as
>> characters. New Jersey and Massachusetts have zero as
>> the first digit.  When these codes are saved as numbers, they become
>> four-digit codes and will probably cause errors.
>> For example Cambridge, Mass is '02138', and would be reported as 2138
>> when interpreted as a number..
>>
>> On Tue, Aug 4, 2020 at 9:29 PM Debasmita Sur <ds071185 at gmail.com>
>wrote:
>> >
>> > Dear R-experts,
>> > I have two lists of US zip codes and want to pick the nearest zip
>code
>> from
>> > second list against my first list.e.g.30043 (from second list) is
>closest
>> > to the zip code 30094 (from first list).So,it should come against
>> 30094.The
>> > code should compare the distance from each zip and pick the nearest
>one.
>> > I have written the following code. It is giving proper results for
>many,
>> > but in mindist, it is showing 'NAs'. But for some of the zip codes,
>it is
>> > giving proper minimum distance. Please note it will be effective
>for 5
>> > digit zip codes. Any help will be highly appreciated.
>> >
>> > df1<-read.csv("C:/Users/dxsur/Desktop/ZIP1.csv")
>> > df2<-read.csv("C:/Users/dxsur/Desktop/ZIP2.csv")
>> >
>> > results<-merge(x=df1,y=zipcode,all.x=TRUE)
>> > results1<-merge(x=df2,y=zipcode,all.x=TRUE)
>> >
>>
>distance<-distm(subset(results,select=c(longitude,latitude)),subset(results1,select=c(longitude,latitude)))
>> >
>> > rnum=apply(distance, 1, which.min)
>> > mindist=apply(distance, 1, min)
>> >
>> > final<-cbind(results,results1$zip[unlist(rnum)],mindist)
>> >
>> >
>> > Thanks & Regards,
>> > *Debasmita *
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@r||61 @end|ng |rom w|ndow@||ve@com  Wed Aug  5 02:10:42 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-9?Q?ahmet_varl=FD?=)
Date: Wed, 5 Aug 2020 00:10:42 +0000
Subject: [R] find number of consecutive days in NC files
Message-ID: <VI1PR0302MB31999746078946CC2D26E474BB4B0@VI1PR0302MB3199.eurprd03.prod.outlook.com>

There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated. However, I couldn't reach exactly what I wanted.

nctoarray <- function(ncfname, varid = NA) { nc <- nc_open(ncfname) a <- aperm(ncvar_get(nc), c(2,1,3)) nc_close(nc) a }

function(x, threshold = 0.28, below = TRUE) { if (below) {

y <- ifelse(x < threshold,1,0)
   } else y <- ifelse(x > threshold,1,0)
 y2 <- rle(y)
 sel <- which(y2$values == 1)
 max(y2$lengths[sel])    }


m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))

m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug  5 09:33:19 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 05 Aug 2020 00:33:19 -0700
Subject: [R] find number of consecutive days in NC files
In-Reply-To: <VI1PR0302MB31999746078946CC2D26E474BB4B0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB31999746078946CC2D26E474BB4B0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <DD54021B-B4F9-46FB-8202-729B561AD9D8@dcn.davis.ca.us>

rle( x > thresh )

On August 4, 2020 5:10:42 PM PDT, "ahmet varl?" <varli61 at windowslive.com> wrote:
>There are 365 days of soil moisture NC files and I am trying to find
>out how many days the values are below and above this certain threshold
>are repeated. However, I couldn't reach exactly what I wanted.
>
>nctoarray <- function(ncfname, varid = NA) { nc <- nc_open(ncfname) a
><- aperm(ncvar_get(nc), c(2,1,3)) nc_close(nc) a }
>
>function(x, threshold = 0.28, below = TRUE) { if (below) {
>
>y <- ifelse(x < threshold,1,0)
>   } else y <- ifelse(x > threshold,1,0)
> y2 <- rle(y)
> sel <- which(y2$values == 1)
> max(y2$lengths[sel])    }
>
>
>m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
>
>m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug  5 14:06:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 5 Aug 2020 22:06:13 +1000
Subject: [R] Arrange data
In-Reply-To: <CAO29qn4qjv=i0SGr0QLZSzmpOuW1imhUqeiK4-ivwMj_fk75UQ@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
 <CA+8X3fWF4TBbhqiUErDKKKw-j8nbK8+oEh0kV7+Ow8RiaU6kug@mail.gmail.com>
 <CAO29qn4qjv=i0SGr0QLZSzmpOuW1imhUqeiK4-ivwMj_fk75UQ@mail.gmail.com>
Message-ID: <CA+8X3fUvBuPjJR+xkp+mL2KLfg3DqqOhAcEnqdiDVSpZ6LWzhg@mail.gmail.com>

Hi Md,
I think the errors are that you forgot to initialize "m", calculated
the mean outside the loops and forgot the final brace:

m<-rep(0,44)
for(i in 1975:2017) {
  for(j in 1:44) {
   mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
      mddat$Year == (i+1) & mddat$Month <= 6,]
   m[j]=mean(mddat2$Value)
 }
}

Jim

On Wed, Aug 5, 2020 at 6:04 AM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Dear Jim,
>
> Thank you very much. You are right. It is good now. However, I want to continue it up to the year 2017.
>
> I use the following code but got the error
>
> for(i in 1975:2017){
>   for(j in 1:44){
> mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
>                 mddat$Year == (i+1) & mddat$Month <= 6,]
> }
> m[j]=mean(mddat2$Value)
>
> }
> m
>
> Please help me in this regard. Many thanks in advance.
>
> Regards,
> Md
>
> On Tue, Aug 4, 2020 at 8:41 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Your problem is in the subset operation. You have asked for a value of
>> month greater or equal to 7 and less than or equal to 6. You probably
>> got an error message that told you that the data were of length zero
>> or something similar. If you check the result of that statement:
>>
>> > mddat$month >= 7 & mddat$month <= 6
>> logical(0)
>>
>> In other words, the two logical statements when ANDed cannot produce a
>> result. A number cannot be greater than or equal to 7 AND less than or
>> equal to 6. What you want is:
>>
>> mddat2<-mddat[mddat$Year == 1975 & mddat$Month >= 7 |
>>  mddat$Year == 1976 & mddat$Month <= 6,]
>> mean(mddat2$Value)
>> [1] 88.91667
>>
>> Apart from that, your email client is inserting EOL characters that
>> cause an error when pasted into R.
>>
>> Error: unexpected input in "?"
>>
>> Probably due to MS Outlook, this has been happening quite a bit lately.
>>
>> Jim
>>
>> On Mon, Aug 3, 2020 at 11:30 PM Md. Moyazzem Hossain
>> <hossainmm at juniv.edu> wrote:
>> >
>> > Dear Jim,
>> >
>> > Thank you very much. It is working now.
>> >
>> > However, I am also trying to find the average of the value from July 1975 to June 1976 and recorded as the value for the year 1975 but got an error message. I am attaching the data file here. Please check the attachment.
>> >
>> > mddat=read.csv("F:/mddat.csv", header=TRUE)
>> > mddat2<-mddat[mddat$Month >=7 & mddat$Month <= 6,]
>> > jan2jun<-by(mddat2$Value,mddat2$Year,mean)
>> > jan2jun
>> >
>> > Please help me again and many thanks in advance.
>> >
>> > Md
>> >
>> >
>> > On Mon, Aug 3, 2020 at 12:33 PM Rasmus Liland <jral at posteo.no> wrote:
>> >>
>> >> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
>> >> > On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>> >> > >
>> >> > > Hi,
>> >> > >
>> >> > > I have a dataset having monthly
>> >> > > observations (from January to
>> >> > > December) over a period of time like
>> >> > > (2000 to 2018). Now, I am trying to
>> >> > > take an average the value from
>> >> > > January to July of each year.
>> >> > >
>> >> > > The data looks like
>> >> > > Year    Month  Value
>> >> > > 2000    1         25
>> >> > > 2000    2         28
>> >> > > 2000    3         22
>> >> > > ....    ......      .....
>> >> > > 2000    12       26
>> >> > > 2001     1       27
>> >> > > .......         ........
>> >> > > 2018    11       30
>> >> > > 20118   12      29
>> >> > >
>> >> > > Can someone help me in this regard?
>> >> > >
>> >> > > Many thanks in advance.
>> >> >
>> >> > Hi Md,
>> >> > One way is to form a subset of your
>> >> > data, then calculate the means by
>> >> > year:
>> >> >
>> >> > # assume your data is named mddat
>> >> > mddat2<-mddat[mddat$month < 7,]
>> >> > jan2jun<-by(mddat2$value,mddat2$year,mean)
>> >> >
>> >> > Jim
>> >>
>> >> Hi Md,
>> >>
>> >> you can also define the period in a new
>> >> column, and use aggregate like this:
>> >>
>> >>         Md <- structure(list(
>> >>         Year = c(2000L, 2000L, 2000L,
>> >>         2000L, 2001L, 2018L, 2018L),
>> >>         Month = c(1L, 2L, 3L, 12L, 1L,
>> >>         11L, 12L),
>> >>         Value = c(25L, 28L, 22L, 26L,
>> >>         27L, 30L, 29L)),
>> >>         class = "data.frame",
>> >>         row.names = c(NA, -7L))
>> >>
>> >>         Md[Md$Month %in%
>> >>                 1:6,"Period"] <- "first six months of the year"
>> >>         Md[Md$Month %in% 7:12,"Period"] <- "last six months of the year"
>> >>
>> >>         aggregate(
>> >>           formula=Value~Year+Period,
>> >>           data=Md,
>> >>           FUN=mean)
>> >>
>> >> Rasmus
>> >
>> >
>> >
>
>
>


From percent||101 @end|ng |rom gm@||@com  Wed Aug  5 21:42:59 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Wed, 5 Aug 2020 21:42:59 +0200
Subject: [R] Print and plot a cross Data
Message-ID: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>

Hi all,

I have a csv (extracted from a web) I attach the data:

I use this code to read the data;

library("readr")

tusDatos <- read_csv('~/datayield.csv')

In this CSV, I want to use three columns:

 tusDatos$DATA_TYPE_FM,  (will be X axis)
tusDatos$TIME_PERIOD (will be the pivot to search the values)
tusDatos$OBS_VALUE (Y Values)

In Data_Type_FM I want to plot a graph where only some rows (included in
thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
specific DATE.

So for each day (time period) I will plot a plot imagine 04/08/2020 (a
value on TIME_PERIOD) for the values

c(  PY_1Y, PY_2Y,
PY_3Y, PY_4Y,
PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM

In excel for me is "easy" but in R I dont know how to proceed can you give
me some clue to make this king of operations?

If I wanted to do a 3D PloT would be possible? only also for this limited
values c(  PY_1Y, PY_2Y,
PY_3Y, PY_4Y,
PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM

tusDatos$DATA_TYPE_FM,  (will be X axis)
tusDatos$TIME_PERIOD (Z axis)
tusDatos$OBS_VALUE (Y Values)

Hope I explained properly and hope you can help and guide.



 datayield.csv
<https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug  6 02:24:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 6 Aug 2020 10:24:07 +1000
Subject: [R] Print and plot a cross Data
In-Reply-To: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
Message-ID: <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>

Hi Pedro,
I'm not exactly sure of what you want, but try this:

# I downloaded the CSV file as datayield.csv
tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
library(scatterplot3d)
data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
row_subset<-tus.datos$DATA_TYPE %in% data_types
scatterplot3d(tus.datos$DATA_TYPE_FM[row_subset],
 tus.datos$OBS_VALUE[row_subset],
 tus.datos$TIME_PERIOD[row_subset],
 color=order(as.numeric(tus.datos$DATA_TYPE[row_subset])))
legend(9,8,data_types,pch=1,col=1:7,xpd=TRUE)

I used a few tricks to get this to work without being too long a
script. The color for PY_7Y is yellow, and this can be changed with a
bit of extra code.

Jim

On Thu, Aug 6, 2020 at 8:40 AM Pedro p?ramo <percentil101 at gmail.com> wrote:
>
> Hi all,
>
> I have a csv (extracted from a web) I attach the data:
>
> I use this code to read the data;
>
> library("readr")
>
> tusDatos <- read_csv('~/datayield.csv')
>
> In this CSV, I want to use three columns:
>
>  tusDatos$DATA_TYPE_FM,  (will be X axis)
> tusDatos$TIME_PERIOD (will be the pivot to search the values)
> tusDatos$OBS_VALUE (Y Values)
>
> In Data_Type_FM I want to plot a graph where only some rows (included in
> thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
> specific DATE.
>
> So for each day (time period) I will plot a plot imagine 04/08/2020 (a
> value on TIME_PERIOD) for the values
>
> c(  PY_1Y, PY_2Y,
> PY_3Y, PY_4Y,
> PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>
> In excel for me is "easy" but in R I dont know how to proceed can you give
> me some clue to make this king of operations?
>
> If I wanted to do a 3D PloT would be possible? only also for this limited
> values c(  PY_1Y, PY_2Y,
> PY_3Y, PY_4Y,
> PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>
> tusDatos$DATA_TYPE_FM,  (will be X axis)
> tusDatos$TIME_PERIOD (Z axis)
> tusDatos$OBS_VALUE (Y Values)
>
> Hope I explained properly and hope you can help and guide.
>
>
>
>  datayield.csv
> <https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From percent||101 @end|ng |rom gm@||@com  Thu Aug  6 15:54:01 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Thu, 6 Aug 2020 15:54:01 +0200
Subject: [R] Print and plot a cross Data
In-Reply-To: <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
 <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
Message-ID: <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>

Hi Jim,

Many thanks for your help, I will try a 2D plot and then pass to 3D.

I am trying something like this:

tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)

data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")

row_subset<-tus.datos$DATA_TYPE %in% data_types

x<-tus.datos$DATA_TYPE_FM[row_subset]
y<-tus.datos$OBS_VALUE[row_subset]

PERIOD<-tus.datos$TIME_PERIOD=="01/06/2020"

for (PERIOD="TRUE") {


plot(x, y)

}


And the error is

 for (PERIOD="TRUE") {
Error: inesperado '=' in "for (PERIOD="
>
>
> plot(x, y)
Error: no se puede ubicar un vector de tama?o  1.3 Gb
>
> }
Error: inesperado '}' in "}"
>



El jue., 6 ago. 2020 a las 2:24, Jim Lemon (<drjimlemon at gmail.com>)
escribi?:

> Hi Pedro,
> I'm not exactly sure of what you want, but try this:
>
> # I downloaded the CSV file as datayield.csv
> tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
> library(scatterplot3d)
> data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
> row_subset<-tus.datos$DATA_TYPE %in% data_types
> scatterplot3d(tus.datos$DATA_TYPE_FM[row_subset],
>  tus.datos$OBS_VALUE[row_subset],
>  tus.datos$TIME_PERIOD[row_subset],
>  color=order(as.numeric(tus.datos$DATA_TYPE[row_subset])))
> legend(9,8,data_types,pch=1,col=1:7,xpd=TRUE)
>
> I used a few tricks to get this to work without being too long a
> script. The color for PY_7Y is yellow, and this can be changed with a
> bit of extra code.
>
> Jim
>
> On Thu, Aug 6, 2020 at 8:40 AM Pedro p?ramo <percentil101 at gmail.com>
> wrote:
> >
> > Hi all,
> >
> > I have a csv (extracted from a web) I attach the data:
> >
> > I use this code to read the data;
> >
> > library("readr")
> >
> > tusDatos <- read_csv('~/datayield.csv')
> >
> > In this CSV, I want to use three columns:
> >
> >  tusDatos$DATA_TYPE_FM,  (will be X axis)
> > tusDatos$TIME_PERIOD (will be the pivot to search the values)
> > tusDatos$OBS_VALUE (Y Values)
> >
> > In Data_Type_FM I want to plot a graph where only some rows (included in
> > thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
> > specific DATE.
> >
> > So for each day (time period) I will plot a plot imagine 04/08/2020 (a
> > value on TIME_PERIOD) for the values
> >
> > c(  PY_1Y, PY_2Y,
> > PY_3Y, PY_4Y,
> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
> >
> > In excel for me is "easy" but in R I dont know how to proceed can you
> give
> > me some clue to make this king of operations?
> >
> > If I wanted to do a 3D PloT would be possible? only also for this limited
> > values c(  PY_1Y, PY_2Y,
> > PY_3Y, PY_4Y,
> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
> >
> > tusDatos$DATA_TYPE_FM,  (will be X axis)
> > tusDatos$TIME_PERIOD (Z axis)
> > tusDatos$OBS_VALUE (Y Values)
> >
> > Hope I explained properly and hope you can help and guide.
> >
> >
> >
> >  datayield.csv
> > <
> https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@r||61 @end|ng |rom w|ndow@||ve@com  Thu Aug  6 17:58:09 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-3?Q?ahmet_varl=B9?=)
Date: Thu, 6 Aug 2020 15:58:09 +0000
Subject: [R] find number of consecutive days in NC files by R
Message-ID: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>

Hi all,


There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily

nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)

a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }



function(x, threshold = 0.28, below = TRUE) {

    if (below) {

        y <- ifelse(x < threshold,1,0)

    } else y <- ifelse(x > threshold,1,0)



    y2 <- rle(y)

    sel <- which(y2$values == 1)

    max(y2$lengths[sel])

}



m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))



m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))




	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Aug  6 19:49:50 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 06 Aug 2020 10:49:50 -0700
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <9DC09EF7-2E8A-42C5-AE2C-6F9DB9FC9D4D@dcn.davis.ca.us>

You need to make a small fake dataset that illustrates what you have and what you want out of it. Telling us you are not getting what you want is simply not useful.

On August 6, 2020 8:58:09 AM PDT, "ahmet varl?" <varli61 at windowslive.com> wrote:
>Hi all,
>
>
>There are 365 days of soil moisture NC files and I am trying to find
>out how many days the values are below and above this certain threshold
>are repeated by R. However, I couldn't reach exactly what I wanted. For
>example, Daily soil moisture is below 0.3 without interrupting how many
>days in 365 days. NC file contains annual soil moisture values daily
>
>nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
>
>a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
>
>
>
>function(x, threshold = 0.28, below = TRUE) {
>
>    if (below) {
>
>        y <- ifelse(x < threshold,1,0)
>
>    } else y <- ifelse(x > threshold,1,0)
>
>
>
>    y2 <- rle(y)
>
>    sel <- which(y2$values == 1)
>
>    max(y2$lengths[sel])
>
>}
>
>
>
>m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
>
>
>
>m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  7 03:16:50 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 Aug 2020 11:16:50 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>

Hi Ahmet,
I think what you are looking for can be done using run length encoding (rle).

# make up some data
soil_moisture<-sin(seq(0,4*pi,length.out=730))+1.1
dates<-as.Date(as.Date("2018-01-01"):as.Date("2019-12-31"),
 origin=as.Date("1970-01-01"))
# get a logical vector for your condition
under.28<-soil_moisture < 0.28
# show the soil moisture against time
plot(dates,soil_moisture,pch=".",col=under.28+3,cex=2)
abline(h=0.28)
# use rle to get  the runs of low soil moisture
sm.rle<-rle(soil_moisture < 0.28)
cat("Consecutive days below 0.28",
 paste(1:sum(sm.rle$values),sm.rle$lengths[sm.rle$values==TRUE],sep="-"),
 "\n")

Jim

On Fri, Aug 7, 2020 at 3:33 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
> Hi all,
>
>
> There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily
>
> nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
>
> a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
>
>
>
> function(x, threshold = 0.28, below = TRUE) {
>
>     if (below) {
>
>         y <- ifelse(x < threshold,1,0)
>
>     } else y <- ifelse(x > threshold,1,0)
>
>
>
>     y2 <- rle(y)
>
>     sel <- which(y2$values == 1)
>
>     max(y2$lengths[sel])
>
> }
>
>
>
> m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
>
>
>
> m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  7 07:17:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 Aug 2020 15:17:07 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>

Hi Ahmet,
Here is a way to get the result you ask for for one geographic grid
cell. You may want more detail or something, but this is a
"reproducible example".

# retrieved from
ftp://ftp2.psi.noaa.gov/Datasets/ncep.renalysis.dailyavgs/surface_gauss/soilw.1-10cm.gauss.1949.nc
library(ncdf4)
soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
soil_moist<-ncvar_get(soilm)
# find a suitable grid cell
for(i in 1:192) {
 for(j in 1:94) {
  minmoist<-min(soil_moist[i,j,],na.rm=TRUE)
  if(minmoist < 0.3) cat(i,j,minmoist,"\n")
 }
}
# data is 3D numeric array use cell 159,66
soil_moisture<-soil_moist[159,66,]
dates<-as.Date(as.Date("1949-01-01"):as.Date("1949-12-31"),
 origin=as.Date("1970-01-01"))
# get a logical vector for your condition
under.28<-soil_moisture < 0.28
plot(dates,soil_moisture,
 main="Soil moisture for grid cell 159,66 1949",
 col=under.28+3)
abline(h=0.28)
sm.rle<-rle(soil_moisture < 0.28)
day_of_year<-1
cat("Consecutive days below 0.28\n")
for(run in 1:length(sm.rle$lengths)) {
 if(sm.rle$values[run]) {
  cat("Day",day_of_year,"-",day_of_year+sm.rle$lengths[run],
   "-",sm.rle$lengths[run],"days\n")
  day_of_year<-day_of_year+sm.rle$lengths[run]
 }
}

Jim

On Fri, Aug 7, 2020 at 11:54 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
>  Many thanks for your answer
>
> > nc
>
> File soilw_1949.nc (NC_FORMAT_NETCDF4_CLASSIC):
>
>
>
>      1 variables (excluding dimension variables):
>
>         float soilw[lon,lat,time]
>
>             long_name: mean Daily Volumetric Soil Moisture between 0-10 cm Below Ground Level
>
>             units: fraction
>
>             precision: 4
>
>             least_significant_digit: 3
>
>             GRIB_id: 144
>
>             GRIB_name: SOILW
>
>             var_desc: Volumetric Soil Moisture
>
>             dataset: NCEP Reanalysis Daily Averages
>
>             level_desc: Between 0-10 cm BGL
>
>             statistic: Mean
>
>             parent_stat: Individual Obs
>
>             missing_value: -9.96920996838687e+36
>
>             actual_range: 0.100000143051147
>
>              actual_range: 0.434000015258789
>
>             valid_range: 0
>
>              valid_range: 1
>
>
>
>      3 dimensions:
>
>         lon  Size:192
>
>             units: degrees_east
>
>             long_name: Longitude
>
>             actual_range: 0
>
>              actual_range: 358.125
>
>             standard_name: longitude
>
>             axis: X
>
>         lat  Size:94
>
>             units: degrees_north
>
>             actual_range: 88.5419998168945
>
>              actual_range: -88.5419998168945
>
>             long_name: Latitude
>
>             standard_name: latitude
>
>             axis: Y
>
>         time  Size:365   *** is unlimited ***
>
>             long_name: Time
>
>             delta_t: 0000-00-01 00:00:00
>
>             avg_period: 0000-00-01 00:00:00
>
>             standard_name: time
>
>             axis: T
>
>             units: hours since 1800-01-01 00:00:0.0
>
>             actual_range: 1306104
>
>              actual_range: 1314840
>
>
>
>     7 global attributes:
>
>         Conventions: COARDS
>
>         title: mean daily NMC reanalysis (1949)
>
>         description: Data is from NMC initialized reanalysis
>
> (4x/day).  It consists of T62 variables interpolated to
>
> pressure surfaces from model (sigma) surfaces.
>
>         platform: Model
>
>         history: created 99/05/29 by Hoop (netCDF2.3)
>
> Converted to chunked, deflated non-packed NetCDF4 2014/09
>
>         dataset_title: NCEP-NCAR Reanalysis 1
>
>         References: http://www.psl.noaa.gov/data/gridded/data.ncep.reanalysis.html
>
>
>
> I swiched nc to array to calculate threshold it is a 3d matrix and there is no date in files
>
>
>
>
>
> > dim(a)
>
>
>
> [1]  94 192 365
>
>
>
> >a
>
> , , 1
>
>
>
>       [,169]    [,170]    [,171]    [,172]    [,173]    [,174]    [,175]    [,176]    [,177]    [,178]    [,179]    [,180]    [,181]    [,182]
>
>  [1,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [2,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [3,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [4,] 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3577001 0.3577001 0.3577001 0.0000000 0.0000000 0.0000000 0.0000000
>
>  [5,] 0.3580000 0.3575001 0.3572001 0.3572001 0.3572001 0.3570001 0.3570001 0.3575001 0.3577001 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000
>
>
>
>
>
>
>
> [ reached getOption("max.print") -- omitted 89 row(s) and 364 matrix slice(s) ]
>
>
>
>
>
> Windows 10 i?in Posta ile g?nderildi
>
>
>
> Kimden: Jim Lemon
> G?nderilme: 7 A?ustos 2020 Cuma 02:17
> Kime: ahmet varl?; r-help mailing list
> Konu: Re: [R] find number of consecutive days in NC files by R
>
>
>
> Hi Ahmet,
> I think what you are looking for can be done using run length encoding (rle).
>
> # make up some data
> soil_moisture<-sin(seq(0,4*pi,length.out=730))+1.1
> dates<-as.Date(as.Date("2018-01-01"):as.Date("2019-12-31"),
>  origin=as.Date("1970-01-01"))
> # get a logical vector for your condition
> under.28<-soil_moisture < 0.28
> # show the soil moisture against time
> plot(dates,soil_moisture,pch=".",col=under.28+3,cex=2)
> abline(h=0.28)
> # use rle to get  the runs of low soil moisture
> sm.rle<-rle(soil_moisture < 0.28)
> cat("Consecutive days below 0.28",
>  paste(1:sum(sm.rle$values),sm.rle$lengths[sm.rle$values==TRUE],sep="-"),
>  "\n")
>
> Jim
>
> On Fri, Aug 7, 2020 at 3:33 AM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> > Hi all,
> >
> >
> > There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily
> >
> > nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
> >
> > a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
> >
> >
> >
> > function(x, threshold = 0.28, below = TRUE) {
> >
> >     if (below) {
> >
> >         y <- ifelse(x < threshold,1,0)
> >
> >     } else y <- ifelse(x > threshold,1,0)
> >
> >
> >
> >     y2 <- rle(y)
> >
> >     sel <- which(y2$values == 1)
> >
> >     max(y2$lengths[sel])
> >
> > }
> >
> >
> >
> > m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
> >
> >
> >
> > m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


From drj|m|emon @end|ng |rom gm@||@com  Fri Aug  7 07:46:06 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 7 Aug 2020 15:46:06 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
Message-ID: <CA+8X3fUDzdJ3diRFthS=LzCH6R5wpwaowuBgisYTOETt=vTaQQ@mail.gmail.com>

Hi Ahmet,
My apologies, the final for loop should read:

for(run in 1:length(sm.rle$lengths)) {
 if(sm.rle$values[run]) {
  cat("Day",day_of_year,"-",day_of_year+sm.rle$lengths[run],
   "-",sm.rle$lengths[run],"days\n")
 }
 day_of_year<-day_of_year+sm.rle$lengths[run]
}

Jim

On Fri, Aug 7, 2020 at 3:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ahmet,
> Here is a way to get the result you ask for for one geographic grid
> cell. You may want more detail or something, but this is a
> "reproducible example".
>
> # retrieved from
> ftp://ftp2.psi.noaa.gov/Datasets/ncep.renalysis.dailyavgs/surface_gauss/soilw.1-10cm.gauss.1949.nc
> library(ncdf4)
> soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
> soil_moist<-ncvar_get(soilm)
> # find a suitable grid cell
> for(i in 1:192) {
>  for(j in 1:94) {
>   minmoist<-min(soil_moist[i,j,],na.rm=TRUE)
>   if(minmoist < 0.3) cat(i,j,minmoist,"\n")
>  }
> }
> # data is 3D numeric array use cell 159,66
> soil_moisture<-soil_moist[159,66,]
> dates<-as.Date(as.Date("1949-01-01"):as.Date("1949-12-31"),
>  origin=as.Date("1970-01-01"))
> # get a logical vector for your condition
> under.28<-soil_moisture < 0.28
> plot(dates,soil_moisture,
>  main="Soil moisture for grid cell 159,66 1949",
>  col=under.28+3)
> abline(h=0.28)
> sm.rle<-rle(soil_moisture < 0.28)
> day_of_year<-1
> cat("Consecutive days below 0.28\n")
> for(run in 1:length(sm.rle$lengths)) {
>  if(sm.rle$values[run]) {
>   cat("Day",day_of_year,"-",day_of_year+sm.rle$lengths[run],
>    "-",sm.rle$lengths[run],"days\n")
>   day_of_year<-day_of_year+sm.rle$lengths[run]
>  }
> }
>
> Jim
>
> On Fri, Aug 7, 2020 at 11:54 AM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> >  Many thanks for your answer
> >
> > > nc
> >
> > File soilw_1949.nc (NC_FORMAT_NETCDF4_CLASSIC):
> >
> >
> >
> >      1 variables (excluding dimension variables):
> >
> >         float soilw[lon,lat,time]
> >
> >             long_name: mean Daily Volumetric Soil Moisture between 0-10 cm Below Ground Level
> >
> >             units: fraction
> >
> >             precision: 4
> >
> >             least_significant_digit: 3
> >
> >             GRIB_id: 144
> >
> >             GRIB_name: SOILW
> >
> >             var_desc: Volumetric Soil Moisture
> >
> >             dataset: NCEP Reanalysis Daily Averages
> >
> >             level_desc: Between 0-10 cm BGL
> >
> >             statistic: Mean
> >
> >             parent_stat: Individual Obs
> >
> >             missing_value: -9.96920996838687e+36
> >
> >             actual_range: 0.100000143051147
> >
> >              actual_range: 0.434000015258789
> >
> >             valid_range: 0
> >
> >              valid_range: 1
> >
> >
> >
> >      3 dimensions:
> >
> >         lon  Size:192
> >
> >             units: degrees_east
> >
> >             long_name: Longitude
> >
> >             actual_range: 0
> >
> >              actual_range: 358.125
> >
> >             standard_name: longitude
> >
> >             axis: X
> >
> >         lat  Size:94
> >
> >             units: degrees_north
> >
> >             actual_range: 88.5419998168945
> >
> >              actual_range: -88.5419998168945
> >
> >             long_name: Latitude
> >
> >             standard_name: latitude
> >
> >             axis: Y
> >
> >         time  Size:365   *** is unlimited ***
> >
> >             long_name: Time
> >
> >             delta_t: 0000-00-01 00:00:00
> >
> >             avg_period: 0000-00-01 00:00:00
> >
> >             standard_name: time
> >
> >             axis: T
> >
> >             units: hours since 1800-01-01 00:00:0.0
> >
> >             actual_range: 1306104
> >
> >              actual_range: 1314840
> >
> >
> >
> >     7 global attributes:
> >
> >         Conventions: COARDS
> >
> >         title: mean daily NMC reanalysis (1949)
> >
> >         description: Data is from NMC initialized reanalysis
> >
> > (4x/day).  It consists of T62 variables interpolated to
> >
> > pressure surfaces from model (sigma) surfaces.
> >
> >         platform: Model
> >
> >         history: created 99/05/29 by Hoop (netCDF2.3)
> >
> > Converted to chunked, deflated non-packed NetCDF4 2014/09
> >
> >         dataset_title: NCEP-NCAR Reanalysis 1
> >
> >         References: http://www.psl.noaa.gov/data/gridded/data.ncep.reanalysis.html
> >
> >
> >
> > I swiched nc to array to calculate threshold it is a 3d matrix and there is no date in files
> >
> >
> >
> >
> >
> > > dim(a)
> >
> >
> >
> > [1]  94 192 365
> >
> >
> >
> > >a
> >
> > , , 1
> >
> >
> >
> >       [,169]    [,170]    [,171]    [,172]    [,173]    [,174]    [,175]    [,176]    [,177]    [,178]    [,179]    [,180]    [,181]    [,182]
> >
> >  [1,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [2,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [3,] 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [4,] 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000 0.3577001 0.3577001 0.3577001 0.0000000 0.0000000 0.0000000 0.0000000
> >
> >  [5,] 0.3580000 0.3575001 0.3572001 0.3572001 0.3572001 0.3570001 0.3570001 0.3575001 0.3577001 0.3580000 0.3580000 0.3580000 0.3580000 0.3580000
> >
> >
> >
> >
> >
> >
> >
> > [ reached getOption("max.print") -- omitted 89 row(s) and 364 matrix slice(s) ]
> >
> >
> >
> >
> >
> > Windows 10 i?in Posta ile g?nderildi
> >
> >
> >
> > Kimden: Jim Lemon
> > G?nderilme: 7 A?ustos 2020 Cuma 02:17
> > Kime: ahmet varl?; r-help mailing list
> > Konu: Re: [R] find number of consecutive days in NC files by R
> >
> >
> >
> > Hi Ahmet,
> > I think what you are looking for can be done using run length encoding (rle).
> >
> > # make up some data
> > soil_moisture<-sin(seq(0,4*pi,length.out=730))+1.1
> > dates<-as.Date(as.Date("2018-01-01"):as.Date("2019-12-31"),
> >  origin=as.Date("1970-01-01"))
> > # get a logical vector for your condition
> > under.28<-soil_moisture < 0.28
> > # show the soil moisture against time
> > plot(dates,soil_moisture,pch=".",col=under.28+3,cex=2)
> > abline(h=0.28)
> > # use rle to get  the runs of low soil moisture
> > sm.rle<-rle(soil_moisture < 0.28)
> > cat("Consecutive days below 0.28",
> >  paste(1:sum(sm.rle$values),sm.rle$lengths[sm.rle$values==TRUE],sep="-"),
> >  "\n")
> >
> > Jim
> >
> > On Fri, Aug 7, 2020 at 3:33 AM ahmet varl? <varli61 at windowslive.com> wrote:
> > >
> > > Hi all,
> > >
> > >
> > > There are 365 days of soil moisture NC files and I am trying to find out how many days the values are below and above this certain threshold are repeated by R. However, I couldn't reach exactly what I wanted. For example, Daily soil moisture is below 0.3 without interrupting how many days in 365 days. NC file contains annual soil moisture values daily
> > >
> > > nctoarray <- function(ncfname, varid = NA) {   nc <- nc_open(ncfname)
> > >
> > > a <- aperm(ncvar_get(nc), c(2,1,3))   nc_close(nc)   a }
> > >
> > >
> > >
> > > function(x, threshold = 0.28, below = TRUE) {
> > >
> > >     if (below) {
> > >
> > >         y <- ifelse(x < threshold,1,0)
> > >
> > >     } else y <- ifelse(x > threshold,1,0)
> > >
> > >
> > >
> > >     y2 <- rle(y)
> > >
> > >     sel <- which(y2$values == 1)
> > >
> > >     max(y2$lengths[sel])
> > >
> > > }
> > >
> > >
> > >
> > > m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3, TRUE))
> > >
> > >
> > >
> > > m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4, FALSE))
> > >
> > >
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >


From |knecht @end|ng |rom |redhutch@org  Thu Aug  6 23:32:30 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Thu, 6 Aug 2020 21:32:30 +0000
Subject: [R] How Can I Build a Standalone Binary
Message-ID: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>

Hello all,

===== The short version =====

I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.

The inspiration for this comes from here:
https://www.youtube.com/watch?v=ARrbbviGvjc
and here
https://github.com/dirkschumacher/r-shiny-electron

I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.

===== Questions =====

-   How is the R binary at this link created?
    -   Link: https://cloud.r-project.org/bin/macosx/R-4.0.2.pkg
-   How do I include `libgfortran.5.dylib`
    -   This distributable, when configured shows a file called `libgfortran.5.dylib`
    -   As of this writing, my solution fails because this is missing when I run the self-hosted R
-   Is there any guidance on how to build a self-hosted R executable for each operating system?
    -   OSX
    -   Linux
    -   Windows

===== The long version =====

----- The Goal -----

Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.

----- The Impetus -----

It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.

We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.

It should be as simple as downloading an application and running it.

----- The Current Progress -----

I have a repo here that is an electron application

https://github.com/FredHutch/FAUST_Nextflow_Desktop/tree/research/create_r_4_0_2_build-dev

I can bundle these resources without issues

-   Java
-   Nextflow
-   Our Shiny App

----- Process -----
The only missing piece is `R`

I have a set of environment variables here:
https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/build_environment_variables.env

I `source` the env variables and then I run this script here:
`https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/download_r_osx.sh`

I then use the downloaded `R` to install dependencies with these scripts:

-   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_dependencies.r
-   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_cran_dependencies.r
-   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_biocmanager_dependencies.r

And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.

Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.

===== The Plea For Guidance =====

I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.

Any guidance or suggestions are greatly appreciated!

Warm Regards,

Logan Knecht

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug  7 13:50:00 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 7 Aug 2020 07:50:00 -0400
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
Message-ID: <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>

Wouldn't it be easier to set up a Shiny host system, and just give your 
collaborators a URL to the Shiny app running there?

Duncan Murdoch


On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
> Hello all,
> 
> ===== The short version =====
> 
> I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
> 
> The inspiration for this comes from here:
> https://www.youtube.com/watch?v=ARrbbviGvjc
> and here
> https://github.com/dirkschumacher/r-shiny-electron
> 
> I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
> 
> ===== Questions =====
> 
> -   How is the R binary at this link created?
>      -   Link: https://cloud.r-project.org/bin/macosx/R-4.0.2.pkg
> -   How do I include `libgfortran.5.dylib`
>      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
>      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
> -   Is there any guidance on how to build a self-hosted R executable for each operating system?
>      -   OSX
>      -   Linux
>      -   Windows
> 
> ===== The long version =====
> 
> ----- The Goal -----
> 
> Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
> 
> ----- The Impetus -----
> 
> It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
> 
> We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
> 
> It should be as simple as downloading an application and running it.
> 
> ----- The Current Progress -----
> 
> I have a repo here that is an electron application
> 
> https://github.com/FredHutch/FAUST_Nextflow_Desktop/tree/research/create_r_4_0_2_build-dev
> 
> I can bundle these resources without issues
> 
> -   Java
> -   Nextflow
> -   Our Shiny App
> 
> ----- Process -----
> The only missing piece is `R`
> 
> I have a set of environment variables here:
> https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/build_environment_variables.env
> 
> I `source` the env variables and then I run this script here:
> `https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/download_r_osx.sh`
> 
> I then use the downloaded `R` to install dependencies with these scripts:
> 
> -   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_dependencies.r
> -   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_cran_dependencies.r
> -   https://github.com/FredHutch/FAUST_Nextflow_Desktop/blob/research/create_r_4_0_2_build-dev/electron_faust_nextflow_desktop/app/binaries/r/install_r_biocmanager_dependencies.r
> 
> And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
> 
> Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
> 
> ===== The Plea For Guidance =====
> 
> I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
> 
> Any guidance or suggestions are greatly appreciated!
> 
> Warm Regards,
> 
> Logan Knecht
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Aug  7 14:05:16 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 7 Aug 2020 12:05:16 +0000
Subject: [R] find end of monotonic part of vector
Message-ID: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>

Hallo all

I have such data
> dput(kalo.v)
structure(list(cas = structure(c(1595847000, 1595847060, 1595847120, 
1595847180, 1595847240, 1595847300, 1595847360, 1595847420, 1595847480, 
1595847540, 1595847600, 1595847660, 1595847720, 1595847780, 1595847840, 
1595847900, 1595847960, 1595848020, 1595848080, 1595848140, 1595848200, 
1595848260, 1595848320, 1595848380, 1595848440, 1595848500, 1595848560, 
1595848620, 1595848680, 1595848740, 1595848800, 1595848860, 1595848920, 
1595848980, 1595849040, 1595849100, 1595849160, 1595849220, 1595849280, 
1595849340, 1595849400, 1595849460, 1595849520, 1595849580, 1595849640
), class = c("POSIXct", "POSIXt"), tzone = "UTC"), vodiv = c(999.9000244, 
999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 991.6404419, 925.2166748, 864.3446045, 812.1702271, 
758.9353027, 722.5073242, 684.5323486, 652.5300293, 82.18816376, 
141.1757813, 402.7521667, 999.9000244, 959.1779175, 967.0949707, 
517.1983643, 50, 50, 524.569458, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 999.9000244, 999.9000244, 999.9000244, 977.0491943, 
889.9714355, 999.9000244, 999.9000244, 999.9000244, 999.9000244, 
999.9000244, 999.9000244)), row.names = 71211:71255, class = "data.frame")

and I would like to automatically find endpoint of gradually decreasing part
(here point 20, vodiv = 652.****).

Usually I use diff but this is just a chunk of bigger data and diff seems to
be difficult to use. I appreciate any hint.

Best regards.
Petr

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug  7 16:05:08 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 7 Aug 2020 15:05:08 +0100
Subject: [R] find end of monotonic part of vector
In-Reply-To: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
References: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
Message-ID: <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>

Hello,

Maybe I'm not understanding but looking at this graph


i <- diff(kalo.v$vodiv) > 0
plot(kalo.v)
lines(kalo.v)
points(kalo.v$cas[i], kalo.v$vodiv[i], pch = 16, col = "red")


it seems you want the point before the first local minimum?


min(which(i)) - 1L
#[1] 20


Hope this helps,

Rui Barradas


?s 13:05 de 07/08/20, PIKAL Petr escreveu:
> Hallo all
> 
> I have such data
>> dput(kalo.v)
> structure(list(cas = structure(c(1595847000, 1595847060, 1595847120,
> 1595847180, 1595847240, 1595847300, 1595847360, 1595847420, 1595847480,
> 1595847540, 1595847600, 1595847660, 1595847720, 1595847780, 1595847840,
> 1595847900, 1595847960, 1595848020, 1595848080, 1595848140, 1595848200,
> 1595848260, 1595848320, 1595848380, 1595848440, 1595848500, 1595848560,
> 1595848620, 1595848680, 1595848740, 1595848800, 1595848860, 1595848920,
> 1595848980, 1595849040, 1595849100, 1595849160, 1595849220, 1595849280,
> 1595849340, 1595849400, 1595849460, 1595849520, 1595849580, 1595849640
> ), class = c("POSIXct", "POSIXt"), tzone = "UTC"), vodiv = c(999.9000244,
> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 991.6404419, 925.2166748, 864.3446045, 812.1702271,
> 758.9353027, 722.5073242, 684.5323486, 652.5300293, 82.18816376,
> 141.1757813, 402.7521667, 999.9000244, 959.1779175, 967.0949707,
> 517.1983643, 50, 50, 524.569458, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 977.0491943,
> 889.9714355, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> 999.9000244, 999.9000244)), row.names = 71211:71255, class = "data.frame")
> 
> and I would like to automatically find endpoint of gradually decreasing part
> (here point 20, vodiv = 652.****).
> 
> Usually I use diff but this is just a chunk of bigger data and diff seems to
> be difficult to use. I appreciate any hint.
> 
> Best regards.
> Petr
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Aug  7 17:44:38 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 7 Aug 2020 16:44:38 +0100
Subject: [R] find end of monotonic part of vector
In-Reply-To: <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>
References: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
 <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>
Message-ID: <5416c4bd-6365-46e0-abeb-9c8f852163f7@sapo.pt>

Hello,

I should have continued, inline.

?s 15:05 de 07/08/20, Rui Barradas escreveu:
> Hello,
> 
> Maybe I'm not understanding but looking at this graph
> 
> 
> i <- diff(kalo.v$vodiv) > 0
> plot(kalo.v)
> lines(kalo.v)
> points(kalo.v$cas[i], kalo.v$vodiv[i], pch = 16, col = "red")
> 
> 
> it seems you want the point before the first local minimum?
> 
> 
> min(which(i)) - 1L
> #[1] 20
> 

(k <- min(which(i)) - 1L)
#[1] 20

kalo.v[k, ]
#                      cas  vodiv
#71230 2020-07-27 11:09:00 652.53


Rui Barradas

> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 13:05 de 07/08/20, PIKAL Petr escreveu:
>> Hallo all
>>
>> I have such data
>>> dput(kalo.v)
>> structure(list(cas = structure(c(1595847000, 1595847060, 1595847120,
>> 1595847180, 1595847240, 1595847300, 1595847360, 1595847420, 1595847480,
>> 1595847540, 1595847600, 1595847660, 1595847720, 1595847780, 1595847840,
>> 1595847900, 1595847960, 1595848020, 1595848080, 1595848140, 1595848200,
>> 1595848260, 1595848320, 1595848380, 1595848440, 1595848500, 1595848560,
>> 1595848620, 1595848680, 1595848740, 1595848800, 1595848860, 1595848920,
>> 1595848980, 1595849040, 1595849100, 1595849160, 1595849220, 1595849280,
>> 1595849340, 1595849400, 1595849460, 1595849520, 1595849580, 1595849640
>> ), class = c("POSIXct", "POSIXt"), tzone = "UTC"), vodiv = c(999.9000244,
>> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 991.6404419, 925.2166748, 864.3446045, 812.1702271,
>> 758.9353027, 722.5073242, 684.5323486, 652.5300293, 82.18816376,
>> 141.1757813, 402.7521667, 999.9000244, 959.1779175, 967.0949707,
>> 517.1983643, 50, 50, 524.569458, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 977.0491943,
>> 889.9714355, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
>> 999.9000244, 999.9000244)), row.names = 71211:71255, class = 
>> "data.frame")
>>
>> and I would like to automatically find endpoint of gradually 
>> decreasing part
>> (here point 20, vodiv = 652.****).
>>
>> Usually I use diff but this is just a chunk of bigger data and diff 
>> seems to
>> be difficult to use. I appreciate any hint.
>>
>> Best regards.
>> Petr
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Aug  7 23:23:48 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 7 Aug 2020 17:23:48 -0400
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
Message-ID: <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>

I don't think it's feasible to do what you want.  At a very basic level, 
R assumes it has files distributed across a file system (mostly below 
the R.home() directory).  Faking that in a single standalone executable 
may be possible but wouldn't be easy.

If running a server isn't possible, then I'd suggest you work on 
automating a regular R installation, and put the things you want to run 
into scripts that make use of it.  Two steps instead of one.

Duncan Murdoch



On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
> Unfortunately, that is not a solution due to the constraints of file sizes associated with the run time operations as well as specific execution workflows.
> 
> I need to make this a packaged distributable and the only blocker for it at the moment is not being able to successfully bundle R as a standalone binary.
> 
> Warm Regards,
> 
> Logan Knecht
> 
> ?2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:
> 
>      Wouldn't it be easier to set up a Shiny host system, and just give your
>      collaborators a URL to the Shiny app running there?
> 
>      Duncan Murdoch
> 
> 
>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
>      > Hello all,
>      >
>      > ===== The short version =====
>      >
>      > I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
>      >
>      > The inspiration for this comes from here:
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
>      > and here
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
>      >
>      > I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
>      >
>      > ===== Questions =====
>      >
>      > -   How is the R binary at this link created?
>      >      -   Link: https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
>      > -   How do I include `libgfortran.5.dylib`
>      >      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
>      >      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
>      > -   Is there any guidance on how to build a self-hosted R executable for each operating system?
>      >      -   OSX
>      >      -   Linux
>      >      -   Windows
>      >
>      > ===== The long version =====
>      >
>      > ----- The Goal -----
>      >
>      > Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
>      >
>      > ----- The Impetus -----
>      >
>      > It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
>      >
>      > We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
>      >
>      > It should be as simple as downloading an application and running it.
>      >
>      > ----- The Current Progress -----
>      >
>      > I have a repo here that is an electron application
>      >
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
>      >
>      > I can bundle these resources without issues
>      >
>      > -   Java
>      > -   Nextflow
>      > -   Our Shiny App
>      >
>      > ----- Process -----
>      > The only missing piece is `R`
>      >
>      > I have a set of environment variables here:
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
>      >
>      > I `source` the env variables and then I run this script here:
>      > `https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e= `
>      >
>      > I then use the downloaded `R` to install dependencies with these scripts:
>      >
>      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
>      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
>      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
>      >
>      > And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
>      >
>      > Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
>      >
>      > ===== The Plea For Guidance =====
>      >
>      > I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
>      >
>      > Any guidance or suggestions are greatly appreciated!
>      >
>      > Warm Regards,
>      >
>      > Logan Knecht
>      >
>      > 	[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
>      > PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  8 01:37:17 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 07 Aug 2020 16:37:17 -0700
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
Message-ID: <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>

While I have not attempted to apply this to Shiny apps on the desktop, layered container technology (e.g. Docker) is being rolled out for desktop app distribution on Linux (snap, flatpak) and Windows (Open Packaging Conventions), with which complex filesystem structures can be managed in isolated runtime environments. The hardest part is working out how the container will interact with the world... which I don't know the details of but it is clearly in the realm of "feasible".

On August 7, 2020 2:23:48 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>I don't think it's feasible to do what you want.  At a very basic
>level, 
>R assumes it has files distributed across a file system (mostly below 
>the R.home() directory).  Faking that in a single standalone executable
>
>may be possible but wouldn't be easy.
>
>If running a server isn't possible, then I'd suggest you work on 
>automating a regular R installation, and put the things you want to run
>
>into scripts that make use of it.  Two steps instead of one.
>
>Duncan Murdoch
>
>
>
>On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
>> Unfortunately, that is not a solution due to the constraints of file
>sizes associated with the run time operations as well as specific
>execution workflows.
>> 
>> I need to make this a packaged distributable and the only blocker for
>it at the moment is not being able to successfully bundle R as a
>standalone binary.
>> 
>> Warm Regards,
>> 
>> Logan Knecht
>> 
>> ?2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com>
>????????:
>> 
>>      Wouldn't it be easier to set up a Shiny host system, and just
>give your
>>      collaborators a URL to the Shiny app running there?
>> 
>>      Duncan Murdoch
>> 
>> 
>>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
>>      > Hello all,
>>      >
>>      > ===== The short version =====
>>      >
>>      > I am trying to build a standalone version for R so that I can
>bundle and package a self-hosted environment for a shiny app. There are
>reasons for this decision, but it will only distract from the
>discussion.
>>      >
>>      > The inspiration for this comes from here:
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
>>      > and here
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
>>      >
>>      > I have tried these solutions, to no avail as I repeatedly
>encounter issues with the process. Some issues have been difficulties
>importing libraries after repeating their steps, others have been
>issues with missing dynamic libraries that aren't available when I
>build from source.
>>      >
>>      > ===== Questions =====
>>      >
>>      > -   How is the R binary at this link created?
>>      >      -   Link:
>https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
>>      > -   How do I include `libgfortran.5.dylib`
>>      >      -   This distributable, when configured shows a file
>called `libgfortran.5.dylib`
>>      >      -   As of this writing, my solution fails because this is
>missing when I run the self-hosted R
>>      > -   Is there any guidance on how to build a self-hosted R
>executable for each operating system?
>>      >      -   OSX
>>      >      -   Linux
>>      >      -   Windows
>>      >
>>      > ===== The long version =====
>>      >
>>      > ----- The Goal -----
>>      >
>>      > Create a self hosted version of R that runs independent of
>each system so that I can package and build shiny apps to be
>distributed to collaborators in order to evangelize our new statistical
>method.
>>      >
>>      > ----- The Impetus -----
>>      >
>>      > It is too distracting and too much work to get our
>collaborators to configure their environments just to try our statiscal
>methods we have been creating.
>>      >
>>      > We have a shiny app built around the statistical methods to
>simplify the interface for interaction. Now we want to package it for
>easy consumption.
>>      >
>>      > It should be as simple as downloading an application and
>running it.
>>      >
>>      > ----- The Current Progress -----
>>      >
>>      > I have a repo here that is an electron application
>>      >
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
>>      >
>>      > I can bundle these resources without issues
>>      >
>>      > -   Java
>>      > -   Nextflow
>>      > -   Our Shiny App
>>      >
>>      > ----- Process -----
>>      > The only missing piece is `R`
>>      >
>>      > I have a set of environment variables here:
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
>>      >
>>      > I `source` the env variables and then I run this script here:
>>      >
>`https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e=
>`
>>      >
>>      > I then use the downloaded `R` to install dependencies with
>these scripts:
>>      >
>>      > -  
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
>>      > -  
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
>>      > -  
>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
>>      >
>>      > And then voil?! It works. Well. It works on my local machine.
>I can run the development build, I can package the build, I can run the
>release after installing it. Everything works.
>>      >
>>      > Except when I bring it over to a separate computer it doesn't
>work because it states that it can't find `libgfortran.5.dylib`. See
>the attached screen shot.
>>      >
>>      > ===== The Plea For Guidance =====
>>      >
>>      > I would love any help to figure out how to achieve this. We
>are very close to somethng tangibly interesting and it's very deflating
>to be blocked because `R` does not have a distributable that can be
>bundled.
>>      >
>>      > Any guidance or suggestions are greatly appreciated!
>>      >
>>      > Warm Regards,
>>      >
>>      > Logan Knecht
>>      >
>>      > 	[[alternative HTML version deleted]]
>>      >
>>      > ______________________________________________
>>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>      >
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
>>      > PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
>>      > and provide commented, minimal, self-contained, reproducible
>code.
>>      >
>> 
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Sat Aug  8 02:08:12 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Aug 2020 10:08:12 +1000
Subject: [R] Print and plot a cross Data
In-Reply-To: <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
 <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
 <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>
Message-ID: <CA+8X3fUGsjKo4X+S5BJWRO_MePGiZFwOCHA=SAPT6BH64GyaMg@mail.gmail.com>

Hi Pedro,
I think the error arises in your "if" statement, should be:

if(PERIOD == TRUE)

or more simply:

if(PERIOD)

Jim

On Thu, Aug 6, 2020 at 11:54 PM Pedro p?ramo <percentil101 at gmail.com> wrote:
>
> Hi Jim,
>
> Many thanks for your help, I will try a 2D plot and then pass to 3D.
>
> I am trying something like this:
>
> tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
>
> data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
>
> row_subset<-tus.datos$DATA_TYPE %in% data_types
>
> x<-tus.datos$DATA_TYPE_FM[row_subset]
> y<-tus.datos$OBS_VALUE[row_subset]
>
> PERIOD<-tus.datos$TIME_PERIOD=="01/06/2020"
>
> for (PERIOD="TRUE") {
>
>
> plot(x, y)
>
> }
>
>
> And the error is
>
>  for (PERIOD="TRUE") {
> Error: inesperado '=' in "for (PERIOD="
> >
> >
> > plot(x, y)
> Error: no se puede ubicar un vector de tama?o  1.3 Gb
> >
> > }
> Error: inesperado '}' in "}"
> >
>
>
>
> El jue., 6 ago. 2020 a las 2:24, Jim Lemon (<drjimlemon at gmail.com>) escribi?:
>>
>> Hi Pedro,
>> I'm not exactly sure of what you want, but try this:
>>
>> # I downloaded the CSV file as datayield.csv
>> tus.datos<-read.table("datayield.csv",sep=";",header=TRUE)
>> library(scatterplot3d)
>> data_types<-c("PY_1Y","PY_2Y","PY_3Y","PY_4Y","PY_5Y","PY_6Y","PY_7Y")
>> row_subset<-tus.datos$DATA_TYPE %in% data_types
>> scatterplot3d(tus.datos$DATA_TYPE_FM[row_subset],
>>  tus.datos$OBS_VALUE[row_subset],
>>  tus.datos$TIME_PERIOD[row_subset],
>>  color=order(as.numeric(tus.datos$DATA_TYPE[row_subset])))
>> legend(9,8,data_types,pch=1,col=1:7,xpd=TRUE)
>>
>> I used a few tricks to get this to work without being too long a
>> script. The color for PY_7Y is yellow, and this can be changed with a
>> bit of extra code.
>>
>> Jim
>>
>> On Thu, Aug 6, 2020 at 8:40 AM Pedro p?ramo <percentil101 at gmail.com> wrote:
>> >
>> > Hi all,
>> >
>> > I have a csv (extracted from a web) I attach the data:
>> >
>> > I use this code to read the data;
>> >
>> > library("readr")
>> >
>> > tusDatos <- read_csv('~/datayield.csv')
>> >
>> > In this CSV, I want to use three columns:
>> >
>> >  tusDatos$DATA_TYPE_FM,  (will be X axis)
>> > tusDatos$TIME_PERIOD (will be the pivot to search the values)
>> > tusDatos$OBS_VALUE (Y Values)
>> >
>> > In Data_Type_FM I want to plot a graph where only some rows (included in
>> > thar colum) will be the X-axis and the Y-axis will be OBS:Value for an
>> > specific DATE.
>> >
>> > So for each day (time period) I will plot a plot imagine 04/08/2020 (a
>> > value on TIME_PERIOD) for the values
>> >
>> > c(  PY_1Y, PY_2Y,
>> > PY_3Y, PY_4Y,
>> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>> >
>> > In excel for me is "easy" but in R I dont know how to proceed can you give
>> > me some clue to make this king of operations?
>> >
>> > If I wanted to do a 3D PloT would be possible? only also for this limited
>> > values c(  PY_1Y, PY_2Y,
>> > PY_3Y, PY_4Y,
>> > PY_5Y, PY_6Y, PY_7Y) this values are included on DATA_TYPE_FM
>> >
>> > tusDatos$DATA_TYPE_FM,  (will be X axis)
>> > tusDatos$TIME_PERIOD (Z axis)
>> > tusDatos$OBS_VALUE (Y Values)
>> >
>> > Hope I explained properly and hope you can help and guide.
>> >
>> >
>> >
>> >  datayield.csv
>> > <https://drive.google.com/file/d/1WvIIhxXOeg8y_7LssRu0wK9s_c9c03sZ/view?usp=drive_web>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Aug  8 02:30:29 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Aug 2020 10:30:29 +1000
Subject: [R] Print and plot a cross Data
In-Reply-To: <CA+8X3fUGsjKo4X+S5BJWRO_MePGiZFwOCHA=SAPT6BH64GyaMg@mail.gmail.com>
References: <CAB-TgNvrYxbm73jhJv5OO7jo6RuRMy8s1nJDC6f=cBjUAqcePQ@mail.gmail.com>
 <CA+8X3fWxDA7toOj=rC8rE7zc10HevuWV1tg=1Caw5iwCu=jzWA@mail.gmail.com>
 <CAB-TgNtgktrfSS85fHSCudsvkHhU7q0+EocKHYQxy2ARTAZh-w@mail.gmail.com>
 <CA+8X3fUGsjKo4X+S5BJWRO_MePGiZFwOCHA=SAPT6BH64GyaMg@mail.gmail.com>
Message-ID: <CA+8X3fUAdG4Ubm1xPFcSuP7jHLtzQTg23pp2FNaQqom8nMP8eA@mail.gmail.com>

Hi Pedro,
Scratch that last email. I remembered that "tus.datos" was so large
that it was hanging my R session last time. However, this seems to
work:

tus.datos<-read.table("datayield.csv",sep=";",
 header=TRUE,stringsAsFactors=FALSE)
row_subset<-tus.datos$DATA_TYPE_FM %in% data_types &
 tus.datos$TIME_PERIOD == "01/06/2020"
x<-tus.datos$DATA_TYPE_FM[row_subset]
y<-as.numeric(tus.datos$OBS_VALUE[row_subset])
# DATA_TYPE_FM is a character variable
# unless you let it be read as a factor (beware, it may hang your R session)
# and use as.numeric() it will not turn out well.
barplot(y,names.arg=x)

Jim


From kev|neg@n31 @end|ng |rom gm@||@com  Fri Aug  7 22:24:55 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Fri, 7 Aug 2020 15:24:55 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
Message-ID: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>

I posted this question:

I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.

After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.

Thanks.

and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.

Thanks.
	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  8 15:17:42 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 08 Aug 2020 06:17:42 -0700
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
Message-ID: <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>

Compare the sessionInfo outputs for the different environments.

On August 7, 2020 1:24:55 PM PDT, Kevin Egan <kevinegan31 at gmail.com> wrote:
>I posted this question:
>
>I am currently using R , RStudio , and a remote computer (using an R
>script) to run the same code. I start by using set.seed(123) in all
>three versions of the code, then using glmnet to assess a matrix.
>Ultimately, I am having trouble reproducing the results between my
>local and the remote computer's results. I am using R version 4.0.2
>locally, and R version 3.6.0 remote.
>
>After running several tests, I'm wondering if there is a difference
>between the two versions in R which may lead to slightly different
>coefficients. If anyone has any insight I would appreciate it.
>
>Thanks.
>
>and found that there were slight differences between using rnorm with
>R-4.0.2 and R-3.6.0 but did not find any differences for runif between
>both systems. In my original code, I am using rnorm and was wondering
>if this may be the reason I am finding slight differences in
>coefficients for glmnet and lars testing between using my local
>computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my
>code locally on a MacOSX and remote on what I believe is an HPC.
>
>Thanks.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Aug  8 15:34:21 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Sat, 8 Aug 2020 09:34:21 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
Message-ID: <D95591B3-7B2D-47AD-AB32-FD0A70CFFEF7@me.com>

Hi,

I was initially going to think that the change in the RNG might be the source, however, that change was made in 3.6.0 and would have applied to runif() and sample():

"sample.kind can be "Rounding" or "Rejection", or partial matches to these. The former was the default in versions prior to 3.6.0: it made sample noticeably non-uniform on large populations, and should only be used for reproduction of old results. See PR#17494 for a discussion."

Three other possibilities:

1. Read news() for your local 4.0.2 installation, as there are some changes that were made, including some changes to round() that could be applicable here.

2. Check to see if the version of glmnet is the same on both machines. There have been changes to that package that might be relevant here and you might read the README and NEWS files for the package on CRAN to see if there is any relevant information there.

3. There is always a chance that different hardware and OS versions could lead to issues, especially out to a number of decimal places that could alter results. If you or via an Admin, have the ability to update the remote machine (both R and installed packages), that can help to reduce the number of variables at play here.

Regards,

Marc Schwartz


> On Aug 7, 2020, at 4:24 PM, Kevin Egan <kevinegan31 at gmail.com> wrote:
> 
> I posted this question:
> 
> I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.
> 
> After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.
> 
> Thanks.
> 
> and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.
> 
> Thanks.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Aug  8 16:24:23 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 08 Aug 2020 07:24:23 -0700
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <60A6FED9-D9DD-4EAF-AF04-73080ED17EF4@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>
 <60A6FED9-D9DD-4EAF-AF04-73080ED17EF4@gmail.com>
Message-ID: <45B367BF-7931-41B4-9F47-DF8841695920@dcn.davis.ca.us>

You did not load the corresponding packages in both environments.

Also.. please post plain text format per the Posting Guide mentioned in the footer of every post.

On August 8, 2020 7:15:16 AM PDT, Kevin Egan <kevinegan31 at gmail.com> wrote:
>Local:
>R version 4.0.2 (2020-06-22)
>Platform: x86_64-apple-darwin17.0 (64-bit)
>Running under: macOS Catalina 10.15.6
>
>Matrix products: default
>BLAS:  
>/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
>LAPACK:
>/Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
>
>locale:
>[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] crayon_1.3.4     dplyr_1.0.0      R6_2.4.1         lifecycle_0.2.0 
>magrittr_1.5     pillar_1.4.3    
>[7] rlang_0.4.7      rstudioapi_0.11  vctrs_0.3.1      generics_0.0.2  
>ellipsis_0.3.0   tools_4.0.2     
>[13] glue_1.4.1       purrr_0.3.4      yaml_2.2.1       compiler_4.0.2 
> pkgconfig_2.0.3  tidyselect_1.1.0
>[19] tibble_3.0.1 
>
>
>Remote:
>> sessionInfo()
>R version 3.6.3 (2020-02-29)
>Platform: x86_64-pc-linux-gnu (64-bit)
>Running under: CentOS Linux 7 (Core)
>
>Matrix products: default
>BLAS/LAPACK:
>/ddn/apps/Cluster-Apps/intel/2019.5/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so
>
>locale:
>[1] C
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] compiler_3.6.3
>
>> On 8 Aug 2020, at 08:17, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> Compare the sessionInfo outputs for the different environments.
>> 
>> On August 7, 2020 1:24:55 PM PDT, Kevin Egan <kevinegan31 at gmail.com>
>wrote:
>>> I posted this question:
>>> 
>>> I am currently using R , RStudio , and a remote computer (using an R
>>> script) to run the same code. I start by using set.seed(123) in all
>>> three versions of the code, then using glmnet to assess a matrix.
>>> Ultimately, I am having trouble reproducing the results between my
>>> local and the remote computer's results. I am using R version 4.0.2
>>> locally, and R version 3.6.0 remote.
>>> 
>>> After running several tests, I'm wondering if there is a difference
>>> between the two versions in R which may lead to slightly different
>>> coefficients. If anyone has any insight I would appreciate it.
>>> 
>>> Thanks.
>>> 
>>> and found that there were slight differences between using rnorm
>with
>>> R-4.0.2 and R-3.6.0 but did not find any differences for runif
>between
>>> both systems. In my original code, I am using rnorm and was
>wondering
>>> if this may be the reason I am finding slight differences in
>>> coefficients for glmnet and lars testing between using my local
>>> computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my
>>> code locally on a MacOSX and remote on what I believe is an HPC.
>>> 
>>> Thanks.
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Sun Aug  9 01:05:02 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 9 Aug 2020 11:05:02 +1200
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
Message-ID: <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>

Hi Kevin,

Intuitively, the first step would be to ensure that all versions of R,
and all the R packages, are the same.

However, you mention HPC.
And the glmnet package imports the foreach package, which appears
(after a quick glance) to support multi-core and parallel computing.

If your code uses parallel computing (?), you may need to look at how
random numbers, and related results, are handled...


On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>
> I posted this question:
>
> I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.
>
> After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.
>
> Thanks.
>
> and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.
>
> Thanks.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  9 01:13:19 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 8 Aug 2020 19:13:19 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <D95591B3-7B2D-47AD-AB32-FD0A70CFFEF7@me.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <D95591B3-7B2D-47AD-AB32-FD0A70CFFEF7@me.com>
Message-ID: <b18405d9-abb7-27fe-e649-178abdbfe35f@gmail.com>

On 08/08/2020 9:34 a.m., Marc Schwartz via R-help wrote:
> Hi,
> 
> I was initially going to think that the change in the RNG might be the source, however, that change was made in 3.6.0 and would have applied to runif() and sample():
> 
> "sample.kind can be "Rounding" or "Rejection", or partial matches to these. The former was the default in versions prior to 3.6.0: it made sample noticeably non-uniform on large populations, and should only be used for reproduction of old results. See PR#17494 for a discussion."
> 

That still may be an issue.  If a user saves a workspace in an old 
version and reloads it in a newer version, I believe they get the old 
version of the RNG.

You need to check that the output of RNGkind() matches in all machines 
to know that they're using the same RNGs.

Duncan Murdoch

> Three other possibilities:
> 
> 1. Read news() for your local 4.0.2 installation, as there are some changes that were made, including some changes to round() that could be applicable here.
> 
> 2. Check to see if the version of glmnet is the same on both machines. There have been changes to that package that might be relevant here and you might read the README and NEWS files for the package on CRAN to see if there is any relevant information there.
> 
> 3. There is always a chance that different hardware and OS versions could lead to issues, especially out to a number of decimal places that could alter results. If you or via an Admin, have the ability to update the remote machine (both R and installed packages), that can help to reduce the number of variables at play here.
> 
> Regards,
> 
> Marc Schwartz
> 
> 
>> On Aug 7, 2020, at 4:24 PM, Kevin Egan <kevinegan31 at gmail.com> wrote:
>>
>> I posted this question:
>>
>> I am currently using R , RStudio , and a remote computer (using an R script) to run the same code. I start by using set.seed(123) in all three versions of the code, then using glmnet to assess a matrix. Ultimately, I am having trouble reproducing the results between my local and the remote computer's results. I am using R version 4.0.2 locally, and R version 3.6.0 remote.
>>
>> After running several tests, I'm wondering if there is a difference between the two versions in R which may lead to slightly different coefficients. If anyone has any insight I would appreciate it.
>>
>> Thanks.
>>
>> and found that there were slight differences between using rnorm with R-4.0.2 and R-3.6.0 but did not find any differences for runif between both systems. In my original code, I am using rnorm and was wondering if this may be the reason I am finding slight differences in coefficients for glmnet and lars testing between using my local computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my code locally on a MacOSX and remote on what I believe is an HPC.
>>
>> Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @@e||ck @end|ng |rom gm@||@com  Sun Aug  9 01:18:22 2020
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Sat, 8 Aug 2020 19:18:22 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
Message-ID: <CADKEMqjiN0imSFhBGPztPOEub1TGu+Fg+paQ5kKFtJfi8NMNVg@mail.gmail.com>

Caveat, I have only skimmed this email thread, so please forgive me if I
have missed something.

Are you able to use Renv, packrat, docker, or anaconda? Your compute
environments are very different.
Kindest regards,

Stephen Sefick

On Sat, Aug 8, 2020, 19:05 Abby Spurdle <spurdle.a at gmail.com> wrote:

> Hi Kevin,
>
> Intuitively, the first step would be to ensure that all versions of R,
> and all the R packages, are the same.
>
> However, you mention HPC.
> And the glmnet package imports the foreach package, which appears
> (after a quick glance) to support multi-core and parallel computing.
>
> If your code uses parallel computing (?), you may need to look at how
> random numbers, and related results, are handled...
>
>
> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
> >
> > I posted this question:
> >
> > I am currently using R , RStudio , and a remote computer (using an R
> script) to run the same code. I start by using set.seed(123) in all three
> versions of the code, then using glmnet to assess a matrix. Ultimately, I
> am having trouble reproducing the results between my local and the remote
> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
> remote.
> >
> > After running several tests, I'm wondering if there is a difference
> between the two versions in R which may lead to slightly different
> coefficients. If anyone has any insight I would appreciate it.
> >
> > Thanks.
> >
> > and found that there were slight differences between using rnorm with
> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
> systems. In my original code, I am using rnorm and was wondering if this
> may be the reason I am finding slight differences in coefficients for
> glmnet and lars testing between using my local computer (R-4.0.2) and my
> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
> remote on what I believe is an HPC.
> >
> > Thanks.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kev|neg@n31 @end|ng |rom gm@||@com  Sat Aug  8 16:15:16 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Sat, 8 Aug 2020 09:15:16 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <3CF1FDDF-6C0B-4FB7-BC71-3E475E9BA6DD@dcn.davis.ca.us>
Message-ID: <60A6FED9-D9DD-4EAF-AF04-73080ED17EF4@gmail.com>

Local:
R version 4.0.2 (2020-06-22)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.6

Matrix products: default
BLAS:   /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
 [1] crayon_1.3.4     dplyr_1.0.0      R6_2.4.1         lifecycle_0.2.0  magrittr_1.5     pillar_1.4.3    
 [7] rlang_0.4.7      rstudioapi_0.11  vctrs_0.3.1      generics_0.0.2   ellipsis_0.3.0   tools_4.0.2     
[13] glue_1.4.1       purrr_0.3.4      yaml_2.2.1       compiler_4.0.2   pkgconfig_2.0.3  tidyselect_1.1.0
[19] tibble_3.0.1 


Remote:
> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: CentOS Linux 7 (Core)

Matrix products: default
BLAS/LAPACK: /ddn/apps/Cluster-Apps/intel/2019.5/compilers_and_libraries_2019.5.281/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.6.3

> On 8 Aug 2020, at 08:17, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Compare the sessionInfo outputs for the different environments.
> 
> On August 7, 2020 1:24:55 PM PDT, Kevin Egan <kevinegan31 at gmail.com> wrote:
>> I posted this question:
>> 
>> I am currently using R , RStudio , and a remote computer (using an R
>> script) to run the same code. I start by using set.seed(123) in all
>> three versions of the code, then using glmnet to assess a matrix.
>> Ultimately, I am having trouble reproducing the results between my
>> local and the remote computer's results. I am using R version 4.0.2
>> locally, and R version 3.6.0 remote.
>> 
>> After running several tests, I'm wondering if there is a difference
>> between the two versions in R which may lead to slightly different
>> coefficients. If anyone has any insight I would appreciate it.
>> 
>> Thanks.
>> 
>> and found that there were slight differences between using rnorm with
>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between
>> both systems. In my original code, I am using rnorm and was wondering
>> if this may be the reason I am finding slight differences in
>> coefficients for glmnet and lars testing between using my local
>> computer (R-4.0.2) and my remote computer (R-3.6.0). I am running my
>> code locally on a MacOSX and remote on what I believe is an HPC.
>> 
>> Thanks.
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


	[[alternative HTML version deleted]]


From |knecht @end|ng |rom |redhutch@org  Fri Aug  7 23:26:58 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Fri, 7 Aug 2020 21:26:58 +0000
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
Message-ID: <3B5EC0C3-1118-44BA-B347-78C0EE08B685@fredhutch.org>

I believe that's what I've been doing already with the links I've provided below.

One of the pieces that escapes me is that there are bundled dynamic libraries like `gfortran` that are missing from the build from source solution I'm pursuing, however they exist in the packaged artifact available from here:
https://cloud.r-project.org/bin/macosx/R-4.0.2.pkg

How does that artifact get created? Does anyone know.

Warm Regards,

Logan

?2020/08/07 ??2:23 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:

    I don't think it's feasible to do what you want.  At a very basic level, 
    R assumes it has files distributed across a file system (mostly below 
    the R.home() directory).  Faking that in a single standalone executable 
    may be possible but wouldn't be easy.

    If running a server isn't possible, then I'd suggest you work on 
    automating a regular R installation, and put the things you want to run 
    into scripts that make use of it.  Two steps instead of one.

    Duncan Murdoch



    On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
    > Unfortunately, that is not a solution due to the constraints of file sizes associated with the run time operations as well as specific execution workflows.
    > 
    > I need to make this a packaged distributable and the only blocker for it at the moment is not being able to successfully bundle R as a standalone binary.
    > 
    > Warm Regards,
    > 
    > Logan Knecht
    > 
    > 2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:
    > 
    >      Wouldn't it be easier to set up a Shiny host system, and just give your
    >      collaborators a URL to the Shiny app running there?
    > 
    >      Duncan Murdoch
    > 
    > 
    >      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
    >      > Hello all,
    >      >
    >      > ===== The short version =====
    >      >
    >      > I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
    >      >
    >      > The inspiration for this comes from here:
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
    >      > and here
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
    >      >
    >      > I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
    >      >
    >      > ===== Questions =====
    >      >
    >      > -   How is the R binary at this link created?
    >      >      -   Link: https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
    >      > -   How do I include `libgfortran.5.dylib`
    >      >      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
    >      >      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
    >      > -   Is there any guidance on how to build a self-hosted R executable for each operating system?
    >      >      -   OSX
    >      >      -   Linux
    >      >      -   Windows
    >      >
    >      > ===== The long version =====
    >      >
    >      > ----- The Goal -----
    >      >
    >      > Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
    >      >
    >      > ----- The Impetus -----
    >      >
    >      > It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
    >      >
    >      > We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
    >      >
    >      > It should be as simple as downloading an application and running it.
    >      >
    >      > ----- The Current Progress -----
    >      >
    >      > I have a repo here that is an electron application
    >      >
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
    >      >
    >      > I can bundle these resources without issues
    >      >
    >      > -   Java
    >      > -   Nextflow
    >      > -   Our Shiny App
    >      >
    >      > ----- Process -----
    >      > The only missing piece is `R`
    >      >
    >      > I have a set of environment variables here:
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
    >      >
    >      > I `source` the env variables and then I run this script here:
    >      > `https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e= `
    >      >
    >      > I then use the downloaded `R` to install dependencies with these scripts:
    >      >
    >      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
    >      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
    >      > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
    >      >
    >      > And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
    >      >
    >      > Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
    >      >
    >      > ===== The Plea For Guidance =====
    >      >
    >      > I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
    >      >
    >      > Any guidance or suggestions are greatly appreciated!
    >      >
    >      > Warm Regards,
    >      >
    >      > Logan Knecht
    >      >
    >      > 	[[alternative HTML version deleted]]
    >      >
    >      > ______________________________________________
    >      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >      > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
    >      > PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
    >      > and provide commented, minimal, self-contained, reproducible code.
    >      >
    > 
    > 



From kev|neg@n31 @end|ng |rom gm@||@com  Sun Aug  9 14:33:41 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Sun, 9 Aug 2020 07:33:41 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
Message-ID: <CAMKuLyRFVL=G3FRwV-MXk5J3x6F_WcczeEpdL0Am-HwG0ZcGRw@mail.gmail.com>

Hi Abby,

After running a few tests on my local and remote versions of R, this seems
to be the most plausible answer to the problem. I put set.seed(123)
several times within my code and produced the same results but would rather
not have to do that if possible.


On Sat, Aug 8, 2020 at 6:05 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> Hi Kevin,
>
> Intuitively, the first step would be to ensure that all versions of R,
> and all the R packages, are the same.
>
> However, you mention HPC.
> And the glmnet package imports the foreach package, which appears
> (after a quick glance) to support multi-core and parallel computing.
>
> If your code uses parallel computing (?), you may need to look at how
> random numbers, and related results, are handled...
>
>
> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
> >
> > I posted this question:
> >
> > I am currently using R , RStudio , and a remote computer (using an R
> script) to run the same code. I start by using set.seed(123) in all three
> versions of the code, then using glmnet to assess a matrix. Ultimately, I
> am having trouble reproducing the results between my local and the remote
> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
> remote.
> >
> > After running several tests, I'm wondering if there is a difference
> between the two versions in R which may lead to slightly different
> coefficients. If anyone has any insight I would appreciate it.
> >
> > Thanks.
> >
> > and found that there were slight differences between using rnorm with
> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
> systems. In my original code, I am using rnorm and was wondering if this
> may be the reason I am finding slight differences in coefficients for
> glmnet and lars testing between using my local computer (R-4.0.2) and my
> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
> remote on what I believe is an HPC.
> >
> > Thanks.
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@e||ck @end|ng |rom gm@||@com  Sun Aug  9 15:42:38 2020
From: @@e||ck @end|ng |rom gm@||@com (stephen sefick)
Date: Sun, 9 Aug 2020 09:42:38 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <D69C605E-5CA1-4B07-A37E-83144C513B31@gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
 <CADKEMqjiN0imSFhBGPztPOEub1TGu+Fg+paQ5kKFtJfi8NMNVg@mail.gmail.com>
 <D69C605E-5CA1-4B07-A37E-83144C513B31@gmail.com>
Message-ID: <CADKEMqhoFgoEK6qRiBkJTsgoTX4sgDBP9MCYi-S7Fhg824ZbOQ@mail.gmail.com>

Hi Kevin,

I think Abby has suggested something similar to what I think the problem is
related to - environment setup.

Some possible solutions:
The renv and packrat packages are a way to version your packages to help
with reproducability. Anaconda might be a solution for the R version and
package version problem, if installed on your hpc. Docker could work as
well (maybe the best option if installed). There are other workarounds, but
I would have to know how your particular hpc/compute environment is set up
to comment further.

Brass tacks:
I think you need to ensure all your package versions (R and add-on
packages) are the same.

Fwiw,

Stephen

On Sun, Aug 9, 2020, 08:26 Kevin Egan <kevinegan31 at gmail.com> wrote:

> Hi Stephen,
>
> I believe I am using Renv, but on my remote computer I am running batch
> files.
>
> Thanks,
>
> Kevin
>
> On 8 Aug 2020, at 18:18, stephen sefick <ssefick at gmail.com> wrote:
>
> Caveat, I have only skimmed this email thread, so please forgive me if I
> have missed something.
>
> Are you able to use Renv, packrat, docker, or anaconda? Your compute
> environments are very different.
> Kindest regards,
>
> Stephen Sefick
>
> On Sat, Aug 8, 2020, 19:05 Abby Spurdle <spurdle.a at gmail.com> wrote:
>
>> Hi Kevin,
>>
>> Intuitively, the first step would be to ensure that all versions of R,
>> and all the R packages, are the same.
>>
>> However, you mention HPC.
>> And the glmnet package imports the foreach package, which appears
>> (after a quick glance) to support multi-core and parallel computing.
>>
>> If your code uses parallel computing (?), you may need to look at how
>> random numbers, and related results, are handled...
>>
>>
>> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>> >
>> > I posted this question:
>> >
>> > I am currently using R , RStudio , and a remote computer (using an R
>> script) to run the same code. I start by using set.seed(123) in all three
>> versions of the code, then using glmnet to assess a matrix. Ultimately, I
>> am having trouble reproducing the results between my local and the remote
>> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
>> remote.
>> >
>> > After running several tests, I'm wondering if there is a difference
>> between the two versions in R which may lead to slightly different
>> coefficients. If anyone has any insight I would appreciate it.
>> >
>> > Thanks.
>> >
>> > and found that there were slight differences between using rnorm with
>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
>> systems. In my original code, I am using rnorm and was wondering if this
>> may be the reason I am finding slight differences in coefficients for
>> glmnet and lars testing between using my local computer (R-4.0.2) and my
>> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
>> remote on what I believe is an HPC.
>> >
>> > Thanks.
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  9 15:47:59 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 9 Aug 2020 09:47:59 -0400
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CAMKuLyRFVL=G3FRwV-MXk5J3x6F_WcczeEpdL0Am-HwG0ZcGRw@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
 <CAMKuLyRFVL=G3FRwV-MXk5J3x6F_WcczeEpdL0Am-HwG0ZcGRw@mail.gmail.com>
Message-ID: <41887239-72c9-e0f9-c281-14032c2765b7@gmail.com>

On 09/08/2020 8:33 a.m., Kevin Egan wrote:
> Hi Abby,
> 
> After running a few tests on my local and remote versions of R, this seems
> to be the most plausible answer to the problem. I put set.seed(123)
> several times within my code and produced the same results but would rather
> not have to do that if possible.

You should look at the doRNG package, which addresses exactly this 
problem.  See its vignette, vignette("doRNG", package="doRNG").

Duncan Murdoch
> 
> 
> On Sat, Aug 8, 2020 at 6:05 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
>> Hi Kevin,
>>
>> Intuitively, the first step would be to ensure that all versions of R,
>> and all the R packages, are the same.
>>
>> However, you mention HPC.
>> And the glmnet package imports the foreach package, which appears
>> (after a quick glance) to support multi-core and parallel computing.
>>
>> If your code uses parallel computing (?), you may need to look at how
>> random numbers, and related results, are handled...
>>
>>
>> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>>>
>>> I posted this question:
>>>
>>> I am currently using R , RStudio , and a remote computer (using an R
>> script) to run the same code. I start by using set.seed(123) in all three
>> versions of the code, then using glmnet to assess a matrix. Ultimately, I
>> am having trouble reproducing the results between my local and the remote
>> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
>> remote.
>>>
>>> After running several tests, I'm wondering if there is a difference
>> between the two versions in R which may lead to slightly different
>> coefficients. If anyone has any insight I would appreciate it.
>>>
>>> Thanks.
>>>
>>> and found that there were slight differences between using rnorm with
>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
>> systems. In my original code, I am using rnorm and was wondering if this
>> may be the reason I am finding slight differences in coefficients for
>> glmnet and lars testing between using my local computer (R-4.0.2) and my
>> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
>> remote on what I believe is an HPC.
>>>
>>> Thanks.
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From |knecht @end|ng |rom |redhutch@org  Fri Aug  7 23:10:17 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Fri, 7 Aug 2020 21:10:17 +0000
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
Message-ID: <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>

Unfortunately, that is not a solution due to the constraints of file sizes associated with the run time operations as well as specific execution workflows.

I need to make this a packaged distributable and the only blocker for it at the moment is not being able to successfully bundle R as a standalone binary.

Warm Regards,

Logan Knecht

?2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com> ????????:

    Wouldn't it be easier to set up a Shiny host system, and just give your 
    collaborators a URL to the Shiny app running there?

    Duncan Murdoch


    On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
    > Hello all,
    > 
    > ===== The short version =====
    > 
    > I am trying to build a standalone version for R so that I can bundle and package a self-hosted environment for a shiny app. There are reasons for this decision, but it will only distract from the discussion.
    > 
    > The inspiration for this comes from here:
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e= 
    > and here
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e= 
    > 
    > I have tried these solutions, to no avail as I repeatedly encounter issues with the process. Some issues have been difficulties importing libraries after repeating their steps, others have been issues with missing dynamic libraries that aren't available when I build from source.
    > 
    > ===== Questions =====
    > 
    > -   How is the R binary at this link created?
    >      -   Link: https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e= 
    > -   How do I include `libgfortran.5.dylib`
    >      -   This distributable, when configured shows a file called `libgfortran.5.dylib`
    >      -   As of this writing, my solution fails because this is missing when I run the self-hosted R
    > -   Is there any guidance on how to build a self-hosted R executable for each operating system?
    >      -   OSX
    >      -   Linux
    >      -   Windows
    > 
    > ===== The long version =====
    > 
    > ----- The Goal -----
    > 
    > Create a self hosted version of R that runs independent of each system so that I can package and build shiny apps to be distributed to collaborators in order to evangelize our new statistical method.
    > 
    > ----- The Impetus -----
    > 
    > It is too distracting and too much work to get our collaborators to configure their environments just to try our statiscal methods we have been creating.
    > 
    > We have a shiny app built around the statistical methods to simplify the interface for interaction. Now we want to package it for easy consumption.
    > 
    > It should be as simple as downloading an application and running it.
    > 
    > ----- The Current Progress -----
    > 
    > I have a repo here that is an electron application
    > 
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e= 
    > 
    > I can bundle these resources without issues
    > 
    > -   Java
    > -   Nextflow
    > -   Our Shiny App
    > 
    > ----- Process -----
    > The only missing piece is `R`
    > 
    > I have a set of environment variables here:
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e= 
    > 
    > I `source` the env variables and then I run this script here:
    > `https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e= `
    > 
    > I then use the downloaded `R` to install dependencies with these scripts:
    > 
    > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e= 
    > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e= 
    > -   https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e= 
    > 
    > And then voil?! It works. Well. It works on my local machine. I can run the development build, I can package the build, I can run the release after installing it. Everything works.
    > 
    > Except when I bring it over to a separate computer it doesn't work because it states that it can't find `libgfortran.5.dylib`. See the attached screen shot.
    > 
    > ===== The Plea For Guidance =====
    > 
    > I would love any help to figure out how to achieve this. We are very close to somethng tangibly interesting and it's very deflating to be blocked because `R` does not have a distributable that can be bundled.
    > 
    > Any guidance or suggestions are greatly appreciated!
    > 
    > Warm Regards,
    > 
    > Logan Knecht
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e= 
    > PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e= 
    > and provide commented, minimal, self-contained, reproducible code.
    > 



From kev|neg@n31 @end|ng |rom gm@||@com  Sun Aug  9 16:40:02 2020
From: kev|neg@n31 @end|ng |rom gm@||@com (Kevin Egan)
Date: Sun, 9 Aug 2020 09:40:02 -0500
Subject: [R] Reproducibility Between Local and Remote Computer with R
In-Reply-To: <CADKEMqhoFgoEK6qRiBkJTsgoTX4sgDBP9MCYi-S7Fhg824ZbOQ@mail.gmail.com>
References: <E1A493F5-66D6-4492-B5D1-4B76ED06B516@gmail.com>
 <CAB8pepwvWMTnDnYctgOrjxogh0cquHzSEOW56=6FLrCou14B6g@mail.gmail.com>
 <CADKEMqjiN0imSFhBGPztPOEub1TGu+Fg+paQ5kKFtJfi8NMNVg@mail.gmail.com>
 <D69C605E-5CA1-4B07-A37E-83144C513B31@gmail.com>
 <CADKEMqhoFgoEK6qRiBkJTsgoTX4sgDBP9MCYi-S7Fhg824ZbOQ@mail.gmail.com>
Message-ID: <CAMKuLySjPTR1MqKR319ryhUqJFtLYQiWwvrZm9dMD=EuMdKsXw@mail.gmail.com>

Hi Stephen,

Thanks, I?m now trying to use R 3.6.3 on the HPC, I was able to run a few
tests remote and get reproducible results. The batches have not yet run,
but I?m hoping will give reproducible results when they do.

Thanks,

Kevin

On Sun, Aug 9, 2020 at 08:42 stephen sefick <ssefick at gmail.com> wrote:

> Hi Kevin,
>
> I think Abby has suggested something similar to what I think the problem
> is related to - environment setup.
>
> Some possible solutions:
> The renv and packrat packages are a way to version your packages to help
> with reproducability. Anaconda might be a solution for the R version and
> package version problem, if installed on your hpc. Docker could work as
> well (maybe the best option if installed). There are other workarounds, but
> I would have to know how your particular hpc/compute environment is set up
> to comment further.
>
> Brass tacks:
> I think you need to ensure all your package versions (R and add-on
> packages) are the same.
>
> Fwiw,
>
> Stephen
>
> On Sun, Aug 9, 2020, 08:26 Kevin Egan <kevinegan31 at gmail.com> wrote:
>
>> Hi Stephen,
>>
>> I believe I am using Renv, but on my remote computer I am running batch
>> files.
>>
>> Thanks,
>>
>> Kevin
>>
>> On 8 Aug 2020, at 18:18, stephen sefick <ssefick at gmail.com> wrote:
>>
>> Caveat, I have only skimmed this email thread, so please forgive me if I
>> have missed something.
>>
>> Are you able to use Renv, packrat, docker, or anaconda? Your compute
>> environments are very different.
>> Kindest regards,
>>
>> Stephen Sefick
>>
>> On Sat, Aug 8, 2020, 19:05 Abby Spurdle <spurdle.a at gmail.com> wrote:
>>
>>> Hi Kevin,
>>>
>>> Intuitively, the first step would be to ensure that all versions of R,
>>> and all the R packages, are the same.
>>>
>>> However, you mention HPC.
>>> And the glmnet package imports the foreach package, which appears
>>> (after a quick glance) to support multi-core and parallel computing.
>>>
>>> If your code uses parallel computing (?), you may need to look at how
>>> random numbers, and related results, are handled...
>>>
>>>
>>> On Sun, Aug 9, 2020 at 1:14 AM Kevin Egan <kevinegan31 at gmail.com> wrote:
>>> >
>>> > I posted this question:
>>> >
>>> > I am currently using R , RStudio , and a remote computer (using an R
>>> script) to run the same code. I start by using set.seed(123) in all three
>>> versions of the code, then using glmnet to assess a matrix. Ultimately, I
>>> am having trouble reproducing the results between my local and the remote
>>> computer's results. I am using R version 4.0.2 locally, and R version 3.6.0
>>> remote.
>>> >
>>> > After running several tests, I'm wondering if there is a difference
>>> between the two versions in R which may lead to slightly different
>>> coefficients. If anyone has any insight I would appreciate it.
>>> >
>>> > Thanks.
>>> >
>>> > and found that there were slight differences between using rnorm with
>>> R-4.0.2 and R-3.6.0 but did not find any differences for runif between both
>>> systems. In my original code, I am using rnorm and was wondering if this
>>> may be the reason I am finding slight differences in coefficients for
>>> glmnet and lars testing between using my local computer (R-4.0.2) and my
>>> remote computer (R-3.6.0). I am running my code locally on a MacOSX and
>>> remote on what I believe is an HPC.
>>> >
>>> > Thanks.
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Aug  9 21:59:07 2020
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 9 Aug 2020 20:59:07 +0100
Subject: [R] Arrange data
In-Reply-To: <63668df7-0823-0a33-3e31-71a794e85b28@sapo.pt>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <de75298f-9ba6-2ed3-5e2b-4095424f9834@sapo.pt>
 <CAO29qn7_qpuOvDodrWUCm+3Js7mXrRhAYa0-kmunEyWZbMMUbA@mail.gmail.com>
 <63668df7-0823-0a33-3e31-71a794e85b28@sapo.pt>
Message-ID: <CAO29qn48LtC505-nqib9DoCt-hYv-PCJtzaAkNPoM_T3tiYgdw@mail.gmail.com>

Dear Rui,

Thank you for your nice help.

Take care and be safe.

Md

On Tue, Aug 4, 2020 at 10:45 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Please keep cc-ing the list R-help is threaded and questions and answers
> might be of help to others in the future.
>
> As for the question, see if the following code does what you want.
> First, create a logical index i of the months between 7 and 3 and use
> that index to subset the original data.frame. Then, a cumsum trick gives
> a vector M defining the data grouping. Group and compute the Value means
> with aggregate. Finally, since each group spans a year border, create a
> more meaningful Years column and put everything together.
>
> df1 <- read.csv("mddat.csv")
>
> i <- with(df1, (Month >= 7 & Month <= 12) | (Month >= 1 & Month <= 3))
> df2 <- df1[i, ]
> M <- cumsum(c(FALSE, diff(as.integer(row.names(df2))) > 1))
>
> agg <- aggregate(Value ~ M, df2, mean)
> Years <- sapply(split(df2$Year, M), function(x){paste(x[1],
> x[length(x)], sep = "-")})
> final <- cbind.data.frame(Years, Value = agg[["Value"]])
>
> head(final)
> #      Years    Value
> #0 1975-1975 87.00000
> #1 1975-1976 89.44444
> #2 1976-1977 85.77778
> #3 1977-1978 81.55556
> #4 1978-1979 71.55556
> #5 1979-1980 75.77778
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> ?s 20:44 de 04/08/20, Md. Moyazzem Hossain escreveu:
> > Dear Rui,
> >
> > Thanks a lot for your help.
> >
> > It is working. Now I am also trying to find the average of values for
> > *July 1975 to March 1976* and record as the value of the year 1975.
> > Moreover, I want to continue it up to the year 2017. You may check the
> > attached file for data (mddat.csv).
> >
> > I use the following function but got error
> > aggregate(Value ~ Year, data = subset(df1, Month >= 7 & Month <= 3), FUN
> > = mean)
> >
> > Please help me again. Thanks in advance.
> >
> > Best Regards,
> > Md
> >
> > On Mon, Aug 3, 2020 at 11:28 PM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     And here is another way, with aggregate.
> >
> >     Make up test data.
> >
> >     set.seed(2020)
> >     df1 <- expand.grid(Year = 2000:2018, Month = 1:12)
> >     df1 <- df1[order(df1$Year),]
> >     df1$Value <- sample(20:30, nrow(df1), TRUE)
> >     head(df1)
> >
> >
> >     #Use subset to keep only the relevant months
> >     aggregate(Value ~ Year, data = subset(df1, Month <= 7), FUN = mean)
> >
> >
> >     Hope this helps,
> >
> >     Rui Barradas
> >
> >     ?s 12:33 de 03/08/2020, Rasmus Liland escreveu:
> >      > On 2020-08-03 21:11 +1000, Jim Lemon wrote:
> >      >> On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain
> >     <hossainmm at juniv.edu <mailto:hossainmm at juniv.edu>> wrote:
> >      >>> Hi,
> >      >>>
> >      >>> I have a dataset having monthly
> >      >>> observations (from January to
> >      >>> December) over a period of time like
> >      >>> (2000 to 2018). Now, I am trying to
> >      >>> take an average the value from
> >      >>> January to July of each year.
> >      >>>
> >      >>> The data looks like
> >      >>> Year    Month  Value
> >      >>> 2000    1         25
> >      >>> 2000    2         28
> >      >>> 2000    3         22
> >      >>> ....    ......      .....
> >      >>> 2000    12       26
> >      >>> 2001     1       27
> >      >>> .......         ........
> >      >>> 2018    11       30
> >      >>> 20118   12      29
> >      >>>
> >      >>> Can someone help me in this regard?
> >      >>>
> >      >>> Many thanks in advance.
> >      >> Hi Md,
> >      >> One way is to form a subset of your
> >      >> data, then calculate the means by
> >      >> year:
> >      >>
> >      >> # assume your data is named mddat
> >      >> mddat2<-mddat[mddat$month < 7,]
> >      >> jan2jun<-by(mddat2$value,mddat2$year,mean)
> >      >>
> >      >> Jim
> >      > Hi Md,
> >      >
> >      > you can also define the period in a new
> >      > column, and use aggregate like this:
> >      >
> >      >       Md <- structure(list(
> >      >       Year = c(2000L, 2000L, 2000L,
> >      >       2000L, 2001L, 2018L, 2018L),
> >      >       Month = c(1L, 2L, 3L, 12L, 1L,
> >      >       11L, 12L),
> >      >       Value = c(25L, 28L, 22L, 26L,
> >      >       27L, 30L, 29L)),
> >      >       class = "data.frame",
> >      >       row.names = c(NA, -7L))
> >      >
> >      >       Md[Md$Month %in%
> >      >               1:6,"Period"] <- "first six months of the year"
> >      >       Md[Md$Month %in% 7:12,"Period"] <- "last six months of the
> >     year"
> >      >
> >      >       aggregate(
> >      >         formula=Value~Year+Period,
> >      >         data=Md,
> >      >         FUN=mean)
> >      >
> >      > Rasmus
> >      >
> >      > ______________________________________________
> >      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >      > https://stat.ethz.ch/mailman/listinfo/r-help
> >      > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >      > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >     --
> >     Este e-mail foi verificado em termos de v?rus pelo software
> >     antiv?rus Avast.
> >     https://www.avast.com/antivirus
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Aug  9 21:59:50 2020
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 9 Aug 2020 20:59:50 +0100
Subject: [R] Arrange data
In-Reply-To: <CA+8X3fUvBuPjJR+xkp+mL2KLfg3DqqOhAcEnqdiDVSpZ6LWzhg@mail.gmail.com>
References: <CAO29qn4y-Dz2OLk05P=vsppw0mDNgcJQQfOS8PzHkBe-HY9ujQ@mail.gmail.com>
 <CA+8X3fXEYJwEAGV1hhD6DExZ8jHvq7U-J5Echbrs0v1b4g3=8A@mail.gmail.com>
 <20200803113337.GC106339@posteo.no>
 <CAO29qn4BPp-+2ysAi0GftKSyRBcH5T+W_6NHGZ16q_jpaMHq4g@mail.gmail.com>
 <CA+8X3fWF4TBbhqiUErDKKKw-j8nbK8+oEh0kV7+Ow8RiaU6kug@mail.gmail.com>
 <CAO29qn4qjv=i0SGr0QLZSzmpOuW1imhUqeiK4-ivwMj_fk75UQ@mail.gmail.com>
 <CA+8X3fUvBuPjJR+xkp+mL2KLfg3DqqOhAcEnqdiDVSpZ6LWzhg@mail.gmail.com>
Message-ID: <CAO29qn4AC-nq_pueBPhpFqRPhYXG828TMNJS39OBzu7hb1LgrQ@mail.gmail.com>

Dear Jim,

Thanks a lot for your support.

Take care.

Md

On Wed, Aug 5, 2020 at 1:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Md,
> I think the errors are that you forgot to initialize "m", calculated
> the mean outside the loops and forgot the final brace:
>
> m<-rep(0,44)
> for(i in 1975:2017) {
>   for(j in 1:44) {
>    mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
>       mddat$Year == (i+1) & mddat$Month <= 6,]
>    m[j]=mean(mddat2$Value)
>  }
> }
>
> Jim
>
> On Wed, Aug 5, 2020 at 6:04 AM Md. Moyazzem Hossain <hossainmm at juniv.edu>
> wrote:
> >
> > Dear Jim,
> >
> > Thank you very much. You are right. It is good now. However, I want to
> continue it up to the year 2017.
> >
> > I use the following code but got the error
> >
> > for(i in 1975:2017){
> >   for(j in 1:44){
> > mddat2[j]<-mddat[mddat$Year == i & mddat$Month >= 7 |
> >                 mddat$Year == (i+1) & mddat$Month <= 6,]
> > }
> > m[j]=mean(mddat2$Value)
> >
> > }
> > m
> >
> > Please help me in this regard. Many thanks in advance.
> >
> > Regards,
> > Md
> >
> > On Tue, Aug 4, 2020 at 8:41 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Your problem is in the subset operation. You have asked for a value of
> >> month greater or equal to 7 and less than or equal to 6. You probably
> >> got an error message that told you that the data were of length zero
> >> or something similar. If you check the result of that statement:
> >>
> >> > mddat$month >= 7 & mddat$month <= 6
> >> logical(0)
> >>
> >> In other words, the two logical statements when ANDed cannot produce a
> >> result. A number cannot be greater than or equal to 7 AND less than or
> >> equal to 6. What you want is:
> >>
> >> mddat2<-mddat[mddat$Year == 1975 & mddat$Month >= 7 |
> >>  mddat$Year == 1976 & mddat$Month <= 6,]
> >> mean(mddat2$Value)
> >> [1] 88.91667
> >>
> >> Apart from that, your email client is inserting EOL characters that
> >> cause an error when pasted into R.
> >>
> >> Error: unexpected input in "?"
> >>
> >> Probably due to MS Outlook, this has been happening quite a bit lately.
> >>
> >> Jim
> >>
> >> On Mon, Aug 3, 2020 at 11:30 PM Md. Moyazzem Hossain
> >> <hossainmm at juniv.edu> wrote:
> >> >
> >> > Dear Jim,
> >> >
> >> > Thank you very much. It is working now.
> >> >
> >> > However, I am also trying to find the average of the value from July
> 1975 to June 1976 and recorded as the value for the year 1975 but got an
> error message. I am attaching the data file here. Please check the
> attachment.
> >> >
> >> > mddat=read.csv("F:/mddat.csv", header=TRUE)
> >> > mddat2<-mddat[mddat$Month >=7 & mddat$Month <= 6,]
> >> > jan2jun<-by(mddat2$Value,mddat2$Year,mean)
> >> > jan2jun
> >> >
> >> > Please help me again and many thanks in advance.
> >> >
> >> > Md
> >> >
> >> >
> >> > On Mon, Aug 3, 2020 at 12:33 PM Rasmus Liland <jral at posteo.no> wrote:
> >> >>
> >> >> On 2020-08-03 21:11 +1000, Jim Lemon wrote:
> >> >> > On Mon, Aug 3, 2020 at 8:52 PM Md. Moyazzem Hossain <
> hossainmm at juniv.edu> wrote:
> >> >> > >
> >> >> > > Hi,
> >> >> > >
> >> >> > > I have a dataset having monthly
> >> >> > > observations (from January to
> >> >> > > December) over a period of time like
> >> >> > > (2000 to 2018). Now, I am trying to
> >> >> > > take an average the value from
> >> >> > > January to July of each year.
> >> >> > >
> >> >> > > The data looks like
> >> >> > > Year    Month  Value
> >> >> > > 2000    1         25
> >> >> > > 2000    2         28
> >> >> > > 2000    3         22
> >> >> > > ....    ......      .....
> >> >> > > 2000    12       26
> >> >> > > 2001     1       27
> >> >> > > .......         ........
> >> >> > > 2018    11       30
> >> >> > > 20118   12      29
> >> >> > >
> >> >> > > Can someone help me in this regard?
> >> >> > >
> >> >> > > Many thanks in advance.
> >> >> >
> >> >> > Hi Md,
> >> >> > One way is to form a subset of your
> >> >> > data, then calculate the means by
> >> >> > year:
> >> >> >
> >> >> > # assume your data is named mddat
> >> >> > mddat2<-mddat[mddat$month < 7,]
> >> >> > jan2jun<-by(mddat2$value,mddat2$year,mean)
> >> >> >
> >> >> > Jim
> >> >>
> >> >> Hi Md,
> >> >>
> >> >> you can also define the period in a new
> >> >> column, and use aggregate like this:
> >> >>
> >> >>         Md <- structure(list(
> >> >>         Year = c(2000L, 2000L, 2000L,
> >> >>         2000L, 2001L, 2018L, 2018L),
> >> >>         Month = c(1L, 2L, 3L, 12L, 1L,
> >> >>         11L, 12L),
> >> >>         Value = c(25L, 28L, 22L, 26L,
> >> >>         27L, 30L, 29L)),
> >> >>         class = "data.frame",
> >> >>         row.names = c(NA, -7L))
> >> >>
> >> >>         Md[Md$Month %in%
> >> >>                 1:6,"Period"] <- "first six months of the year"
> >> >>         Md[Md$Month %in% 7:12,"Period"] <- "last six months of the
> year"
> >> >>
> >> >>         aggregate(
> >> >>           formula=Value~Year+Period,
> >> >>           data=Md,
> >> >>           FUN=mean)
> >> >>
> >> >> Rasmus
> >> >
> >> >
> >> >
> >
> >
> >
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug 10 05:23:00 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 10 Aug 2020 13:23:00 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB3199D2DBA9ECD5A24F839B93BB470@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
 <CA+8X3fUDzdJ3diRFthS=LzCH6R5wpwaowuBgisYTOETt=vTaQQ@mail.gmail.com>
 <VI1PR0302MB3199E50BAE6DF7AE78178FFCBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fWAexSRCM7mxzv58MTVaQp2rAbeAWtN7Zrd_ffxxXW==g@mail.gmail.com>
 <VI1PR0302MB3199D2DBA9ECD5A24F839B93BB470@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fVHt9MkCzKWvFB3QoeJOxxXkpgTw_omNKXfT1AqqM9QWA@mail.gmail.com>

Hi Ahmet,
An easy way is this:

library(ncdf4)
soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
soil_moist<-ncvar_get(soilm)
smdim<-dim(soil_moist)
# identify NA grid cells
sm_NA_count<-matrix(NA,nrow=smdim[1],ncol=smdim[2])
for(i in 1:smdim[1]) {
 for(j in 1:smdim[2]) {
  sm_NA_count[i,j]<-sum(!is.na(soil_moist[i,j,]))
 }
}

The resulting matrix contains the counts of valid (not NA) values in
each 365 day series in the array. It looks to me as though there are
5914 complete series and the rest are all NA. This does not tell you
why some files (the third dimension) are all NA. Probably the best
guess is that the soil moisture content is not measurable for some
reason. Here is the explanation from NOAA:

Missing Data:

There is no missing data though the ocean has 0's. There is a file
with the percent of the grid that is land. Another file has simply 1
and 0's for land/ocean. Grids where the percent of land is zero are
"missing".

You can get a feel for the geographic coverage like this (white cells
are not NA):

library(maps)
library(plotrix)
color2D.matplot(t(sm_NA_count))

Jim

On Mon, Aug 10, 2020 at 4:09 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
> Hi Jim,
>
>
>
> Could you help me to remove NA values which are water values ?
>
>
>
>
>
> Kimden: Jim Lemon
> G?nderilme: 7 A?ustos 2020 Cuma 22:53
> Kime: ahmet varl?
> Konu: Re: [R] find number of consecutive days in NC files by R
>
>
>
> There are 17848 grid cells in the file I downloaded for 1949. Many of
> them only contain NA values, probably because they are from a
> geographic grid that is covered by water. In the code there is a
> section that prints out a list of the grid cells that contain minimum
> values less than 0.3. Since I don't know which grid cell you are
> using, I had to find one that would produce interpretable results for
> the problem you are trying to solve.
>
> Jim
>
> On Fri, Aug 7, 2020 at 11:03 PM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> > I am greatfull for your helps and ? just want to ask why did you use cell 159,66
> >
>
>


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug 10 08:37:33 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 10 Aug 2020 06:37:33 +0000
Subject: [R] find end of monotonic part of vector
In-Reply-To: <5416c4bd-6365-46e0-abeb-9c8f852163f7@sapo.pt>
References: <cf21a63f09fe4db58861dabcb5c5c1db@SRVEXCHCM1302.precheza.cz>
 <1d24a145-1789-da41-124a-a779bfd96d1f@sapo.pt>
 <5416c4bd-6365-46e0-abeb-9c8f852163f7@sapo.pt>
Message-ID: <f6230d43aab84b73ae68e165a797cc9d@SRVEXCHCM1302.precheza.cz>

Thank you Rui

The problem is that this was just a part of my data and I have many of such
consecutive chunks. So far I have a solution in mind which I will try. 

Set all values above 900 to NA.
Set all values below 600 (or 650) to NA
Find parts which have at least 4 continuous values (values not having NA
within them).
Find position of all minimum values.

Not sure if this approach will work, though.

Cheers
Petr

> -----Original Message-----
> From: Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Friday, August 7, 2020 5:45 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; R-help <r-help at r-project.org>
> Subject: Re: [R] find end of monotonic part of vector
> 
> Hello,
> 
> I should have continued, inline.
> 
> ?s 15:05 de 07/08/20, Rui Barradas escreveu:
> > Hello,
> >
> > Maybe I'm not understanding but looking at this graph
> >
> >
> > i <- diff(kalo.v$vodiv) > 0
> > plot(kalo.v)
> > lines(kalo.v)
> > points(kalo.v$cas[i], kalo.v$vodiv[i], pch = 16, col = "red")
> >
> >
> > it seems you want the point before the first local minimum?
> >
> >
> > min(which(i)) - 1L
> > #[1] 20
> >
> 
> (k <- min(which(i)) - 1L)
> #[1] 20
> 
> kalo.v[k, ]
> #                      cas  vodiv
> #71230 2020-07-27 11:09:00 652.53
> 
> 
> Rui Barradas
> 
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 13:05 de 07/08/20, PIKAL Petr escreveu:
> >> Hallo all
> >>
> >> I have such data
> >>> dput(kalo.v)
> >> structure(list(cas = structure(c(1595847000, 1595847060, 1595847120,
> >> 1595847180, 1595847240, 1595847300, 1595847360, 1595847420,
> >> 1595847480, 1595847540, 1595847600, 1595847660, 1595847720,
> >> 1595847780, 1595847840, 1595847900, 1595847960, 1595848020,
> >> 1595848080, 1595848140, 1595848200, 1595848260, 1595848320,
> >> 1595848380, 1595848440, 1595848500, 1595848560, 1595848620,
> >> 1595848680, 1595848740, 1595848800, 1595848860, 1595848920,
> >> 1595848980, 1595849040, 1595849100, 1595849160, 1595849220,
> >> 1595849280, 1595849340, 1595849400, 1595849460, 1595849520,
> >> 1595849580, 1595849640 ), class = c("POSIXct", "POSIXt"), tzone =
> >> "UTC"), vodiv = c(999.9000244, 999.9000244, 999.9000244, 999.9000244,
> >> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> >> 999.9000244, 999.9000244, 999.9000244, 991.6404419, 925.2166748,
> >> 864.3446045, 812.1702271, 758.9353027, 722.5073242, 684.5323486,
> >> 652.5300293, 82.18816376, 141.1757813, 402.7521667, 999.9000244,
> >> 959.1779175, 967.0949707, 517.1983643, 50, 50, 524.569458,
> >> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244,
> >> 999.9000244, 999.9000244, 977.0491943, 889.9714355, 999.9000244,
> >> 999.9000244, 999.9000244, 999.9000244, 999.9000244, 999.9000244)),
> >> row.names = 71211:71255, class =
> >> "data.frame")
> >>
> >> and I would like to automatically find endpoint of gradually
> >> decreasing part (here point 20, vodiv = 652.****).
> >>
> >> Usually I use diff but this is just a chunk of bigger data and diff
> >> seems to be difficult to use. I appreciate any hint.
> >>
> >> Best regards.
> >> Petr
> >>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From percent||101 @end|ng |rom gm@||@com  Fri Aug  7 15:56:43 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Fri, 7 Aug 2020 15:56:43 +0200
Subject: [R] Add a logo on a plot
Message-ID: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>

Hi,

There is a way to add a photo like a free text but images on a plot, (hist,
chart trough ggplot) to add a logo or any PNG .

	[[alternative HTML version deleted]]


From m@||2r@jk@poor @end|ng |rom gm@||@com  Fri Aug  7 18:55:32 2020
From: m@||2r@jk@poor @end|ng |rom gm@||@com (Raj kapoor)
Date: Fri, 7 Aug 2020 22:25:32 +0530
Subject: [R] C stack usage 7970372 is too close to the limit
Message-ID: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>

Hi Team,

I have one production instance in aws, in CentoOs linux environment, i have
5 user to access the instance for using RStudio, In case R-studio working 4
users running good, while we access 5th users its getting error,

First issue : C stack usage 7970372 is too close to the limit

Second Issue :  no stack overflow

Please provide the solution.

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug 10 15:57:08 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 10 Aug 2020 16:57:08 +0300
Subject: [R] Add a logo on a plot
In-Reply-To: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
References: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
Message-ID: <20200810165708.69c92df4@trisector>

On Fri, 7 Aug 2020 15:56:43 +0200
Pedro p?ramo <percentil101 at gmail.com> wrote:

> There is a way to add a photo like a free text but images on a plot,
> (hist, chart trough ggplot) to add a logo or any PNG .

See ?rasterImage and the example in ?png::readPNG [*].

-- 
Best regards,
Ivan

[*] png is a CRAN package, https://cran.r-project.org/package=png


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug 10 16:04:09 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 10 Aug 2020 17:04:09 +0300
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
Message-ID: <20200810170409.36f8bb99@trisector>

On Fri, 7 Aug 2020 22:25:32 +0530
Raj kapoor <mail2rajkapoor at gmail.com> wrote:

> I have one production instance in aws, in CentoOs linux environment,
> i have 5 user to access the instance for using RStudio, In case
> R-studio working 4 users running good, while we access 5th users its
> getting error,

Sorry, R-Studio support is over there: https://support.rstudio.com/

If you think that the issue is with R and not R-Studio, please show us
how this problem can be reproduced (i.e. include the data and the code
we could run ourselves to trigger the issue). Check out the posting
guide [*] and, in particular, this HOWTO [**] on seeking technical help.

-- 
Best regards,
Ivan

> 	[[alternative HTML version deleted]]

P.S. Please post in plain text, not HTML.

[*] https://www.r-project.org/posting-guide.html
The link is appended to every e-mail sent via this list.

[**] http://www.catb.org/~esr/faqs/smart-questions.html


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug 10 18:36:49 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 10 Aug 2020 09:36:49 -0700
Subject: [R] Question about PERL lookahead construct in regex's
Message-ID: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>

Folks:

Consider:
> y <- "xx wt"

> grep(" +(?=t)",y, perl = TRUE)
integer(0)
## Unexpected. Lookahead construct does not find "t" after space
## But
> grep(" +(?=.+t)",y, perl = TRUE)
[1] 1
## Expected. Given pattern for **exact** match, lookahead finds it

My concern is:
?regexp says this:
"Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
 *assertions*: they match if an attempt to match the ... forward from the
current position would succeed (or not), but use up no characters in the
string being processed."

But this appears to be imprecise (it confused me, anyway). The usual sense
of "matching" in regex's is "match the pattern somewhere in the string
going forward." But in the perl lookahead construct it apparently must
**exactly** match *everything* in the string that follows.

Questions:
Am I correct about this? If not, what do I misunderstand?
If I am correct, should the regex help be slightly modified to something
like:

"Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
 *assertions*: they match if an attempt to **exactly" match all of ... forward
from the current position would succeed (or not), but use up no characters
in the string being processed."

Thanks.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From john@m@h@rro|d @end|ng |rom gm@||@com  Mon Aug 10 18:51:14 2020
From: john@m@h@rro|d @end|ng |rom gm@||@com (John Harrold)
Date: Mon, 10 Aug 2020 09:51:14 -0700
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
Message-ID: <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>

Hello Raj,

I've gotten this type of error in the past when I've done things like use
while loops that didn't end. Basically, I think this means you're running
out of memory. If you want more users, possibly increase the amount of ram
in your machine.

John

On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor <mail2rajkapoor at gmail.com> wrote:

> Hi Team,
>
> I have one production instance in aws, in CentoOs linux environment, i have
> 5 user to access the instance for using RStudio, In case R-studio working 4
> users running good, while we access 5th users its getting error,
>
> First issue : C stack usage 7970372 is too close to the limit
>
> Second Issue :  no stack overflow
>
> Please provide the solution.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John
:wq

	[[alternative HTML version deleted]]


From m@||2r@jk@poor @end|ng |rom gm@||@com  Mon Aug 10 20:13:05 2020
From: m@||2r@jk@poor @end|ng |rom gm@||@com (Raj kapoor)
Date: Mon, 10 Aug 2020 23:43:05 +0530
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
Message-ID: <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>

Hi John,

I have 10 user in the instance, 9 user is working and access the R studio
app, but while access the 10th user it's getting stack usage limit issues,
then we create the new users its working fine.

On Mon, 10 Aug 2020, 10:21 pm John Harrold, <john.m.harrold at gmail.com>
wrote:

> Hello Raj,
>
> I've gotten this type of error in the past when I've done things like use
> while loops that didn't end. Basically, I think this means you're running
> out of memory. If you want more users, possibly increase the amount of ram
> in your machine.
>
> John
>
> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor <mail2rajkapoor at gmail.com>
> wrote:
>
>> Hi Team,
>>
>> I have one production instance in aws, in CentoOs linux environment, i
>> have
>> 5 user to access the instance for using RStudio, In case R-studio working
>> 4
>> users running good, while we access 5th users its getting error,
>>
>> First issue : C stack usage 7970372 is too close to the limit
>>
>> Second Issue :  no stack overflow
>>
>> Please provide the solution.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> John
> :wq
>

	[[alternative HTML version deleted]]


From m@||2r@jk@poor @end|ng |rom gm@||@com  Mon Aug 10 20:14:22 2020
From: m@||2r@jk@poor @end|ng |rom gm@||@com (Raj kapoor)
Date: Mon, 10 Aug 2020 23:44:22 +0530
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
 <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
Message-ID: <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>

Hi John,

Only the particular users getting error john. Please help me




On Mon, 10 Aug 2020, 11:43 pm Raj kapoor, <mail2rajkapoor at gmail.com> wrote:

> Hi John,
>
> I have 10 user in the instance, 9 user is working and access the R studio
> app, but while access the 10th user it's getting stack usage limit issues,
> then we create the new users its working fine.
>
> On Mon, 10 Aug 2020, 10:21 pm John Harrold, <john.m.harrold at gmail.com>
> wrote:
>
>> Hello Raj,
>>
>> I've gotten this type of error in the past when I've done things like use
>> while loops that didn't end. Basically, I think this means you're running
>> out of memory. If you want more users, possibly increase the amount of ram
>> in your machine.
>>
>> John
>>
>> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor <mail2rajkapoor at gmail.com>
>> wrote:
>>
>>> Hi Team,
>>>
>>> I have one production instance in aws, in CentoOs linux environment, i
>>> have
>>> 5 user to access the instance for using RStudio, In case R-studio
>>> working 4
>>> users running good, while we access 5th users its getting error,
>>>
>>> First issue : C stack usage 7970372 is too close to the limit
>>>
>>> Second Issue :  no stack overflow
>>>
>>> Please provide the solution.
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> John
>> :wq
>>
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 10 21:05:50 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Aug 2020 12:05:50 -0700
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <C81804B4-27CC-4898-9A37-72031495BFBA@fredhutch.org>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
 <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>
 <C81804B4-27CC-4898-9A37-72031495BFBA@fredhutch.org>
Message-ID: <CA704D54-8FC2-4BD5-85D1-FCD94EA0C6E1@dcn.davis.ca.us>

I specifically said that there are approaches that apply container technology to user software... I generally cannot tell whether software I am running on Ubuntu is a snap container or a native binary. Windows Store offers a similar experience. Your goal of targeting multiple platforms is complicating this discussion though... I don't plan to follow you down that rabbit hole. This forum is about the R language.

On August 10, 2020 10:37:57 AM PDT, "Knecht, Logan" <lknecht at fredhutch.org> wrote:
>I am an expert user for Docker. Unfortunately this is not a use case
>that will work with Docker.
>
>The goal is to provide a self-contained artifact as a solution so that
>no effort needs to be put into the environment configuration.
>
>If Docker was used, the users would need to download docker and figure
>out how to run the docker image I build.
>
>That is a solution, but it does not fit the deliverable requirements
>I'm shooting for.
>
>Logan
>
>?2020/08/07 ??4:37 ??"Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>????????:
>
>While I have not attempted to apply this to Shiny apps on the desktop,
>layered container technology (e.g. Docker) is being rolled out for
>desktop app distribution on Linux (snap, flatpak) and Windows (Open
>Packaging Conventions), with which complex filesystem structures can be
>managed in isolated runtime environments. The hardest part is working
>out how the container will interact with the world... which I don't
>know the details of but it is clearly in the realm of "feasible".
>
>On August 7, 2020 2:23:48 PM PDT, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
>    >I don't think it's feasible to do what you want.  At a very basic
>    >level, 
>>R assumes it has files distributed across a file system (mostly below 
>>the R.home() directory).  Faking that in a single standalone
>executable
>    >
>    >may be possible but wouldn't be easy.
>    >
>    >If running a server isn't possible, then I'd suggest you work on 
>>automating a regular R installation, and put the things you want to
>run
>    >
>    >into scripts that make use of it.  Two steps instead of one.
>    >
>    >Duncan Murdoch
>    >
>    >
>    >
>    >On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
>>> Unfortunately, that is not a solution due to the constraints of file
>    >sizes associated with the run time operations as well as specific
>    >execution workflows.
>    >> 
>>> I need to make this a packaged distributable and the only blocker
>for
>    >it at the moment is not being able to successfully bundle R as a
>    >standalone binary.
>    >> 
>    >> Warm Regards,
>    >> 
>    >> Logan Knecht
>    >> 
>    >> 2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com>
>    >????????:
>    >> 
>  >>      Wouldn't it be easier to set up a Shiny host system, and just
>    >give your
>    >>      collaborators a URL to the Shiny app running there?
>    >> 
>    >>      Duncan Murdoch
>    >> 
>    >> 
>    >>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
>    >>      > Hello all,
>    >>      >
>    >>      > ===== The short version =====
>    >>      >
>>>      > I am trying to build a standalone version for R so that I can
>>bundle and package a self-hosted environment for a shiny app. There
>are
>    >reasons for this decision, but it will only distract from the
>    >discussion.
>    >>      >
>    >>      > The inspiration for this comes from here:
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
>    >>      > and here
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
>    >>      >
>    >>      > I have tried these solutions, to no avail as I repeatedly
> >encounter issues with the process. Some issues have been difficulties
>    >importing libraries after repeating their steps, others have been
>    >issues with missing dynamic libraries that aren't available when I
>    >build from source.
>    >>      >
>    >>      > ===== Questions =====
>    >>      >
>    >>      > -   How is the R binary at this link created?
>    >>      >      -   Link:
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
>    >>      > -   How do I include `libgfortran.5.dylib`
>    >>      >      -   This distributable, when configured shows a file
>    >called `libgfortran.5.dylib`
>>>      >      -   As of this writing, my solution fails because this
>is
>    >missing when I run the self-hosted R
>    >>      > -   Is there any guidance on how to build a self-hosted R
>    >executable for each operating system?
>    >>      >      -   OSX
>    >>      >      -   Linux
>    >>      >      -   Windows
>    >>      >
>    >>      > ===== The long version =====
>    >>      >
>    >>      > ----- The Goal -----
>    >>      >
>   >>      > Create a self hosted version of R that runs independent of
>    >each system so that I can package and build shiny apps to be
>>distributed to collaborators in order to evangelize our new
>statistical
>    >method.
>    >>      >
>    >>      > ----- The Impetus -----
>    >>      >
>    >>      > It is too distracting and too much work to get our
>>collaborators to configure their environments just to try our
>statiscal
>    >methods we have been creating.
>    >>      >
>  >>      > We have a shiny app built around the statistical methods to
> >simplify the interface for interaction. Now we want to package it for
>    >easy consumption.
>    >>      >
>    >>      > It should be as simple as downloading an application and
>    >running it.
>    >>      >
>    >>      > ----- The Current Progress -----
>    >>      >
>    >>      > I have a repo here that is an electron application
>    >>      >
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
>    >>      >
>    >>      > I can bundle these resources without issues
>    >>      >
>    >>      > -   Java
>    >>      > -   Nextflow
>    >>      > -   Our Shiny App
>    >>      >
>    >>      > ----- Process -----
>    >>      > The only missing piece is `R`
>    >>      >
>    >>      > I have a set of environment variables here:
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
>    >>      >
>>>      > I `source` the env variables and then I run this script here:
>    >>      >
>>`https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e=
>    >`
>    >>      >
>   >>      > I then use the downloaded `R` to install dependencies with
>    >these scripts:
>    >>      >
>    >>      > -  
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
>    >>      > -  
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
>    >>      > -  
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
>    >>      >
>>>      > And then voil?! It works. Well. It works on my local machine.
>>I can run the development build, I can package the build, I can run
>the
>    >release after installing it. Everything works.
>    >>      >
>>>      > Except when I bring it over to a separate computer it doesn't
>  >work because it states that it can't find `libgfortran.5.dylib`. See
>    >the attached screen shot.
>    >>      >
>    >>      > ===== The Plea For Guidance =====
>    >>      >
>  >>      > I would love any help to figure out how to achieve this. We
>>are very close to somethng tangibly interesting and it's very
>deflating
>   >to be blocked because `R` does not have a distributable that can be
>    >bundled.
>    >>      >
>    >>      > Any guidance or suggestions are greatly appreciated!
>    >>      >
>    >>      > Warm Regards,
>    >>      >
>    >>      > Logan Knecht
>    >>      >
>    >>      > 	[[alternative HTML version deleted]]
>    >>      >
>    >>      > ______________________________________________
>>>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>    >see
>    >>      >
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
>    >>      > PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
> >>      > and provide commented, minimal, self-contained, reproducible
>    >code.
>    >>      >
>    >> 
>    >>
>    >
>    >______________________________________________
>    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=Edz5G4Mxqrv8jUU1i-etY2hmLRGE6fTtUsuO1meaE80&e=
>
>    >PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=wT-y_1LicEh73lA1bSAIHIhxzmmQR1otfvU_-ddVnw4&e=
>
>    >and provide commented, minimal, self-contained, reproducible code.
>
>    -- 
>    Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Aug 10 21:08:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 10 Aug 2020 12:08:26 -0700
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
 <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
 <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>
Message-ID: <B9F37CC1-8716-4E41-92AD-72962303978A@dcn.davis.ca.us>

Please take this discussion elsewhere... it is off-topic here. Ivan offered options earlier in this regard.

On August 10, 2020 11:14:22 AM PDT, Raj kapoor <mail2rajkapoor at gmail.com> wrote:
>Hi John,
>
>Only the particular users getting error john. Please help me
>
>
>
>
>On Mon, 10 Aug 2020, 11:43 pm Raj kapoor, <mail2rajkapoor at gmail.com>
>wrote:
>
>> Hi John,
>>
>> I have 10 user in the instance, 9 user is working and access the R
>studio
>> app, but while access the 10th user it's getting stack usage limit
>issues,
>> then we create the new users its working fine.
>>
>> On Mon, 10 Aug 2020, 10:21 pm John Harrold,
><john.m.harrold at gmail.com>
>> wrote:
>>
>>> Hello Raj,
>>>
>>> I've gotten this type of error in the past when I've done things
>like use
>>> while loops that didn't end. Basically, I think this means you're
>running
>>> out of memory. If you want more users, possibly increase the amount
>of ram
>>> in your machine.
>>>
>>> John
>>>
>>> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor
><mail2rajkapoor at gmail.com>
>>> wrote:
>>>
>>>> Hi Team,
>>>>
>>>> I have one production instance in aws, in CentoOs linux
>environment, i
>>>> have
>>>> 5 user to access the instance for using RStudio, In case R-studio
>>>> working 4
>>>> users running good, while we access 5th users its getting error,
>>>>
>>>> First issue : C stack usage 7970372 is too close to the limit
>>>>
>>>> Second Issue :  no stack overflow
>>>>
>>>> Please provide the solution.
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> John
>>> :wq
>>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From roy@mende|@@ohn @end|ng |rom no@@@gov  Mon Aug 10 22:08:30 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Mon, 10 Aug 2020 13:08:30 -0700
Subject: [R] optim with upper and lower bounds
Message-ID: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>

I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.

Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.

Thanks,

-Roy



**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pd@|gd @end|ng |rom gm@||@com  Tue Aug 11 09:48:46 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 11 Aug 2020 09:48:46 +0200
Subject: [R] optim with upper and lower bounds
In-Reply-To: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
References: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
Message-ID: <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>

This stuff is of course dependent on exactly which optimization problem you have, but optimx::optimr is often a very good drop-in replacement for optim, especially when bounds are involved (e.g., optim has an awkward habit of attempting evaluations outside the domain when numerical derivatives are needed).

You might want to look at the last examples in ?stats4::mle (in R 4.x.x)

-pd

> On 10 Aug 2020, at 22:08 , Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
> 
> I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.
> 
> Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.
> 
> Thanks,
> 
> -Roy
> 
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new street address***
> 110 McAllister Way
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From |knecht @end|ng |rom |redhutch@org  Mon Aug 10 19:37:57 2020
From: |knecht @end|ng |rom |redhutch@org (Knecht, Logan)
Date: Mon, 10 Aug 2020 17:37:57 +0000
Subject: [R] How Can I Build a Standalone Binary
In-Reply-To: <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>
References: <0F5FA64A-831C-4132-AE17-4B9BB8AA5050@fredhutch.org>
 <54b539ad-8a58-0305-30c1-5de7f5ee7ddb@gmail.com>
 <5C3BF3C2-1A70-4EB2-8B93-3CDD1C376324@fredhutch.org>
 <68d618e7-fcb6-0820-cb0e-460284b78b38@gmail.com>
 <50D144A2-C46B-486A-8EA0-A7F1F8270D5A@dcn.davis.ca.us>
Message-ID: <C81804B4-27CC-4898-9A37-72031495BFBA@fredhutch.org>

I am an expert user for Docker. Unfortunately this is not a use case that will work with Docker.

The goal is to provide a self-contained artifact as a solution so that no effort needs to be put into the environment configuration.

If Docker was used, the users would need to download docker and figure out how to run the docker image I build.

That is a solution, but it does not fit the deliverable requirements I'm shooting for.

Logan

?2020/08/07 ??4:37 ??"Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> ????????:

    While I have not attempted to apply this to Shiny apps on the desktop, layered container technology (e.g. Docker) is being rolled out for desktop app distribution on Linux (snap, flatpak) and Windows (Open Packaging Conventions), with which complex filesystem structures can be managed in isolated runtime environments. The hardest part is working out how the container will interact with the world... which I don't know the details of but it is clearly in the realm of "feasible".

    On August 7, 2020 2:23:48 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
    >I don't think it's feasible to do what you want.  At a very basic
    >level, 
    >R assumes it has files distributed across a file system (mostly below 
    >the R.home() directory).  Faking that in a single standalone executable
    >
    >may be possible but wouldn't be easy.
    >
    >If running a server isn't possible, then I'd suggest you work on 
    >automating a regular R installation, and put the things you want to run
    >
    >into scripts that make use of it.  Two steps instead of one.
    >
    >Duncan Murdoch
    >
    >
    >
    >On 07/08/2020 5:10 p.m., Knecht, Logan wrote:
    >> Unfortunately, that is not a solution due to the constraints of file
    >sizes associated with the run time operations as well as specific
    >execution workflows.
    >> 
    >> I need to make this a packaged distributable and the only blocker for
    >it at the moment is not being able to successfully bundle R as a
    >standalone binary.
    >> 
    >> Warm Regards,
    >> 
    >> Logan Knecht
    >> 
    >> 2020/08/07 ??4:50 ??"Duncan Murdoch" <murdoch.duncan at gmail.com>
    >????????:
    >> 
    >>      Wouldn't it be easier to set up a Shiny host system, and just
    >give your
    >>      collaborators a URL to the Shiny app running there?
    >> 
    >>      Duncan Murdoch
    >> 
    >> 
    >>      On 06/08/2020 5:32 p.m., Knecht, Logan wrote:
    >>      > Hello all,
    >>      >
    >>      > ===== The short version =====
    >>      >
    >>      > I am trying to build a standalone version for R so that I can
    >bundle and package a self-hosted environment for a shiny app. There are
    >reasons for this decision, but it will only distract from the
    >discussion.
    >>      >
    >>      > The inspiration for this comes from here:
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__www.youtube.com_watch-3Fv-3DARrbbviGvjc&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=yHknXdnol-gw1NqdlK0Md_dn9jW_NU6DlTZJ0aoKnxc&e=
    >>      > and here
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dirkschumacher_r-2Dshiny-2Delectron&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=iCgG_D3ngLrfXykUszOieQIRiwj5prEN3c0gFb8V_1g&e=
    >>      >
    >>      > I have tried these solutions, to no avail as I repeatedly
    >encounter issues with the process. Some issues have been difficulties
    >importing libraries after repeating their steps, others have been
    >issues with missing dynamic libraries that aren't available when I
    >build from source.
    >>      >
    >>      > ===== Questions =====
    >>      >
    >>      > -   How is the R binary at this link created?
    >>      >      -   Link:
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__cloud.r-2Dproject.org_bin_macosx_R-2D4.0.2.pkg&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=pUj6yAcIF2zy9KcB7dXJD4ezIwluDIhuc3UN05ZcIs4&e=
    >>      > -   How do I include `libgfortran.5.dylib`
    >>      >      -   This distributable, when configured shows a file
    >called `libgfortran.5.dylib`
    >>      >      -   As of this writing, my solution fails because this is
    >missing when I run the self-hosted R
    >>      > -   Is there any guidance on how to build a self-hosted R
    >executable for each operating system?
    >>      >      -   OSX
    >>      >      -   Linux
    >>      >      -   Windows
    >>      >
    >>      > ===== The long version =====
    >>      >
    >>      > ----- The Goal -----
    >>      >
    >>      > Create a self hosted version of R that runs independent of
    >each system so that I can package and build shiny apps to be
    >distributed to collaborators in order to evangelize our new statistical
    >method.
    >>      >
    >>      > ----- The Impetus -----
    >>      >
    >>      > It is too distracting and too much work to get our
    >collaborators to configure their environments just to try our statiscal
    >methods we have been creating.
    >>      >
    >>      > We have a shiny app built around the statistical methods to
    >simplify the interface for interaction. Now we want to package it for
    >easy consumption.
    >>      >
    >>      > It should be as simple as downloading an application and
    >running it.
    >>      >
    >>      > ----- The Current Progress -----
    >>      >
    >>      > I have a repo here that is an electron application
    >>      >
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_tree_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=c_SfZuM1kBF7onYsTkktR5K6DyeLHO_iJU_8tn7XJE4&e=
    >>      >
    >>      > I can bundle these resources without issues
    >>      >
    >>      > -   Java
    >>      > -   Nextflow
    >>      > -   Our Shiny App
    >>      >
    >>      > ----- Process -----
    >>      > The only missing piece is `R`
    >>      >
    >>      > I have a set of environment variables here:
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_build-5Fenvironment-5Fvariables.env&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=asCEqMQrRxIP9twZSG53oZmV8uK2PnP9iv2nqxw18xc&e=
    >>      >
    >>      > I `source` the env variables and then I run this script here:
    >>      >
    >`https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_download-5Fr-5Fosx.sh&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=6J4zNQoHoBCICudLqtBbiLk1xpStNSpsrtsnb6-O0Ak&e=
    >`
    >>      >
    >>      > I then use the downloaded `R` to install dependencies with
    >these scripts:
    >>      >
    >>      > -  
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=irTsih9Pq4R_rzV_6-eF0cAEAGTYbERYDRjnpy-hrgk&e=
    >>      > -  
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fcran-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=T9dVoi8UTeY8nd4o5ykO4Mzx4jFBpRy5YNUTFaZVbJs&e=
    >>      > -  
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_FredHutch_FAUST-5FNextflow-5FDesktop_blob_research_create-5Fr-5F4-5F0-5F2-5Fbuild-2Ddev_electron-5Ffaust-5Fnextflow-5Fdesktop_app_binaries_r_install-5Fr-5Fbiocmanager-5Fdependencies.r&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=AA7yI29L7ET5-HAfUlzguKp28j8N7755H6pCNA4m6uU&e=
    >>      >
    >>      > And then voil?! It works. Well. It works on my local machine.
    >I can run the development build, I can package the build, I can run the
    >release after installing it. Everything works.
    >>      >
    >>      > Except when I bring it over to a separate computer it doesn't
    >work because it states that it can't find `libgfortran.5.dylib`. See
    >the attached screen shot.
    >>      >
    >>      > ===== The Plea For Guidance =====
    >>      >
    >>      > I would love any help to figure out how to achieve this. We
    >are very close to somethng tangibly interesting and it's very deflating
    >to be blocked because `R` does not have a distributable that can be
    >bundled.
    >>      >
    >>      > Any guidance or suggestions are greatly appreciated!
    >>      >
    >>      > Warm Regards,
    >>      >
    >>      > Logan Knecht
    >>      >
    >>      > 	[[alternative HTML version deleted]]
    >>      >
    >>      > ______________________________________________
    >>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
    >see
    >>      >
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=rXWnxYtLId2lxALBHyFwuyXWU-yTHljjCyH-AZ4alpc&e=
    >>      > PLEASE do read the posting guide
    >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIDaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=6GL5xCevUT873KGyFsJhVe44s-QATomA_BHxDVctiOA&s=RlRm34djv4feVOhSjRGeswgJsw13nHd02YTERiDBxng&e=
    >>      > and provide commented, minimal, self-contained, reproducible
    >code.
    >>      >
    >> 
    >>
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=Edz5G4Mxqrv8jUU1i-etY2hmLRGE6fTtUsuO1meaE80&e= 
    >PLEASE do read the posting guide
    >https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwIFaQ&c=eRAMFD45gAfqt84VtBcfhQ&r=yLJd2IoXkBkWMIBcuv1k7wCSdpKnUqiEZDh_EJHHU08&m=-_rGGkN8eOYj8ZX-qUh967_-8HiKdgWtKdCqcJcwwUE&s=wT-y_1LicEh73lA1bSAIHIhxzmmQR1otfvU_-ddVnw4&e= 
    >and provide commented, minimal, self-contained, reproducible code.

    -- 
    Sent from my phone. Please excuse my brevity.


From @zwj|08 @end|ng |rom gm@||@com  Tue Aug 11 10:59:05 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jeff King)
Date: Tue, 11 Aug 2020 16:59:05 +0800
Subject: [R] C stack usage 7970372 is too close to the limit
In-Reply-To: <B9F37CC1-8716-4E41-92AD-72962303978A@dcn.davis.ca.us>
References: <CAOBz0jkJKng8HS7L_5dUBoghJrmHOVBuinTLk+UfurxHHA9-SQ@mail.gmail.com>
 <CANAiAiWWq_9nLYT=G1RR7ZoeP3-j7kokO=nYtDjomwO0UgpG8w@mail.gmail.com>
 <CAOBz0j=LD9WUd+wqFSX3uMDNJu6_SRT-y57L0Pe86-2pRNHsNQ@mail.gmail.com>
 <CAOBz0jnAKb1g1frDzpYuTPaSgCUGRS-90cz7MymwQYuVhJTK1A@mail.gmail.com>
 <B9F37CC1-8716-4E41-92AD-72962303978A@dcn.davis.ca.us>
Message-ID: <CAGiFhPO4EiSp6+NtEg5bY0=CvzRdCMLAeb-ku_h=xbHEcjZgAg@mail.gmail.com>

Hello Raj,

Please include a reproducible example. If you only give a generic error
message, the best solution we can offer is to reboot your server and try it
again.

Anyway, from the information you gave, it seems like you should ask this
question in the Rstudio community(I assume you are running their production
on the server). This is R's community, you are welcome to ask but it is
less likely that you can get an expert to answer this type of question.

Best,
Jiefei

On Tue, Aug 11, 2020 at 3:08 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please take this discussion elsewhere... it is off-topic here. Ivan
> offered options earlier in this regard.
>
> On August 10, 2020 11:14:22 AM PDT, Raj kapoor <mail2rajkapoor at gmail.com>
> wrote:
> >Hi John,
> >
> >Only the particular users getting error john. Please help me
> >
> >
> >
> >
> >On Mon, 10 Aug 2020, 11:43 pm Raj kapoor, <mail2rajkapoor at gmail.com>
> >wrote:
> >
> >> Hi John,
> >>
> >> I have 10 user in the instance, 9 user is working and access the R
> >studio
> >> app, but while access the 10th user it's getting stack usage limit
> >issues,
> >> then we create the new users its working fine.
> >>
> >> On Mon, 10 Aug 2020, 10:21 pm John Harrold,
> ><john.m.harrold at gmail.com>
> >> wrote:
> >>
> >>> Hello Raj,
> >>>
> >>> I've gotten this type of error in the past when I've done things
> >like use
> >>> while loops that didn't end. Basically, I think this means you're
> >running
> >>> out of memory. If you want more users, possibly increase the amount
> >of ram
> >>> in your machine.
> >>>
> >>> John
> >>>
> >>> On Mon, Aug 10, 2020 at 6:43 AM Raj kapoor
> ><mail2rajkapoor at gmail.com>
> >>> wrote:
> >>>
> >>>> Hi Team,
> >>>>
> >>>> I have one production instance in aws, in CentoOs linux
> >environment, i
> >>>> have
> >>>> 5 user to access the instance for using RStudio, In case R-studio
> >>>> working 4
> >>>> users running good, while we access 5th users its getting error,
> >>>>
> >>>> First issue : C stack usage 7970372 is too close to the limit
> >>>>
> >>>> Second Issue :  no stack overflow
> >>>>
> >>>> Please provide the solution.
> >>>>
> >>>>         [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> John
> >>> :wq
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d||eepkunj@@| @end|ng |rom gm@||@com  Tue Aug 11 14:21:20 2020
From: d||eepkunj@@| @end|ng |rom gm@||@com (Dileepkumar R)
Date: Tue, 11 Aug 2020 17:51:20 +0530
Subject: [R] Trend value from smoothing spline trend fit
Message-ID: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>

Dear All,

I am trying to estimate the non -linear trend value from smooth spline
trend fit (using the generalized additive model (GAM)).

I want to estimate the trend value from a temperature dataset (spatial
averaged annual meantime from 1906 to 2005) as given in the Box 2.2, Table
1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
Report 5 chapter 2
<https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf>,
page number 21-22 )

I do not understand how they estimate the single value trend with 95%
confidence interval from a time-series data as given in the Box 2.2, Figure
1.  Is there any easy way to extract the trend value using mgcv library of
R.?

Google Doc Link:
https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing

Thank you all in advance

Dileepkumar R

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Tue Aug 11 15:24:37 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 11 Aug 2020 09:24:37 -0400
Subject: [R] optim with upper and lower bounds
In-Reply-To: <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>
References: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
 <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>
Message-ID: <b63018f6-54de-afe6-73da-e4e3a96fcc25@gmail.com>

Thanks to Peter for noting that the numerical derivative part of code doesn't check bounds in optim().
I tried to put some checks into Rvmmin and Rcgmin in optimx package (they were separate packages before, and
still on CRAN), but I'm far from capturing all the places where numerical derivative steps can go outside bounds.

And if you have a "production" problem where you are going to run a given optimization over a lot of cases, I'd
strongly suggest that you write your own derivative code, even if it is a numerical approximation. In the case of
a specialized derivative code e.g., part analytic, part numeric, with bounds checking, I'll be willing
to kibbitz, but suggest off-list until something is working, in which case it is probably at least worth
a vignette, as this sort of situation seems to pop up at least once a year and a good example would really
be helpful to guide the process. I'm reluctant to prepare an artificial example because, well, it will be
artificial and not capture the sort of details that have to be addressed.

Best, JN


On 2020-08-11 3:48 a.m., peter dalgaard wrote:
> This stuff is of course dependent on exactly which optimization problem you have, but optimx::optimr is often a very good drop-in replacement for optim, especially when bounds are involved (e.g., optim has an awkward habit of attempting evaluations outside the domain when numerical derivatives are needed).
> 
> You might want to look at the last examples in ?stats4::mle (in R 4.x.x)
> 
> -pd
> 
>> On 10 Aug 2020, at 22:08 , Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
>>
>> I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.
>>
>> Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.
>>
>> Thanks,
>>
>> -Roy
>>
>>
>>
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
>> Environmental Research Division
>> Southwest Fisheries Science Center
>> ***Note new street address***
>> 110 McAllister Way
>> Santa Cruz, CA 95060
>> Phone: (831)-420-3666
>> Fax: (831) 420-3980
>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>>
>> "Old age and treachery will overcome youth and skill."
>> "From those who have been given much, much will be expected" 
>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From roy@mende|@@ohn @end|ng |rom no@@@gov  Tue Aug 11 16:06:44 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Tue, 11 Aug 2020 07:06:44 -0700
Subject: [R] optim with upper and lower bounds
In-Reply-To: <b63018f6-54de-afe6-73da-e4e3a96fcc25@gmail.com>
References: <BF72E357-4198-46BC-980E-893E0F1A5F0B@noaa.gov>
 <D556EBC6-D006-4788-9E1C-5EAB76E86F0E@gmail.com>
 <b63018f6-54de-afe6-73da-e4e3a96fcc25@gmail.com>
Message-ID: <4136B92F-AB3F-4560-88C0-900389A4CB73@noaa.gov>

Thanks to all who responded.  Will take me some time to digest it all.

-Roy


> On Aug 11, 2020, at 6:24 AM, J C Nash <profjcnash at gmail.com> wrote:
> 
> Thanks to Peter for noting that the numerical derivative part of code doesn't check bounds in optim().
> I tried to put some checks into Rvmmin and Rcgmin in optimx package (they were separate packages before, and
> still on CRAN), but I'm far from capturing all the places where numerical derivative steps can go outside bounds.
> 
> And if you have a "production" problem where you are going to run a given optimization over a lot of cases, I'd
> strongly suggest that you write your own derivative code, even if it is a numerical approximation. In the case of
> a specialized derivative code e.g., part analytic, part numeric, with bounds checking, I'll be willing
> to kibbitz, but suggest off-list until something is working, in which case it is probably at least worth
> a vignette, as this sort of situation seems to pop up at least once a year and a good example would really
> be helpful to guide the process. I'm reluctant to prepare an artificial example because, well, it will be
> artificial and not capture the sort of details that have to be addressed.
> 
> Best, JN
> 
> 
> On 2020-08-11 3:48 a.m., peter dalgaard wrote:
>> This stuff is of course dependent on exactly which optimization problem you have, but optimx::optimr is often a very good drop-in replacement for optim, especially when bounds are involved (e.g., optim has an awkward habit of attempting evaluations outside the domain when numerical derivatives are needed).
>> 
>> You might want to look at the last examples in ?stats4::mle (in R 4.x.x)
>> 
>> -pd
>> 
>>> On 10 Aug 2020, at 22:08 , Roy Mendelssohn - NOAA Federal via R-help <r-help at r-project.org> wrote:
>>> 
>>> I am running a lot of optimization problems, at the moment using 'optim'  ('optim' is actually called by another program).  All of the problems have variables with simple upper and lower bounds,  which I can easily transform into a form that is unconstrained and solve using 'BFGS'.  But I was wondering is if it is more robust to solve the problem this way,  or to use L-BFGS-B instead.
>>> 
>>> Also how much difference can it make using 'optimx' instead 'optim'?  The program I am using (KFAS) allows this,  I just have to do some extra programming to use it.
>>> 
>>> Thanks,
>>> 
>>> -Roy
>>> 
>>> 
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>>> Environmental Research Division
>>> Southwest Fisheries Science Center
>>> ***Note new street address***
>>> 110 McAllister Way
>>> Santa Cruz, CA 95060
>>> Phone: (831)-420-3666
>>> Fax: (831) 420-3980
>>> e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/
>>> 
>>> "Old age and treachery will overcome youth and skill."
>>> "From those who have been given much, much will be expected" 
>>> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 11 16:31:46 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Aug 2020 07:31:46 -0700
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
Message-ID: <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>

Caveat: Did not look at any of your links.

However, the usual answer for this sort of question is ?predict.gam  (in
general, predict.whatevermethod)
Have you consulted the man page? If this is not what you want, you may need
to explain more carefully.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 11, 2020 at 5:21 AM Dileepkumar R <dileepkunjaai at gmail.com>
wrote:

> Dear All,
>
> I am trying to estimate the non -linear trend value from smooth spline
> trend fit (using the generalized additive model (GAM)).
>
> I want to estimate the trend value from a temperature dataset (spatial
> averaged annual meantime from 1906 to 2005) as given in the Box 2.2, Table
> 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
> Report 5 chapter 2
> <
> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
> >,
> page number 21-22 )
>
> I do not understand how they estimate the single value trend with 95%
> confidence interval from a time-series data as given in the Box 2.2, Figure
> 1.  Is there any easy way to extract the trend value using mgcv library of
> R.?
>
> Google Doc Link:
>
> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
>
> Thank you all in advance
>
> Dileepkumar R
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v|kr@m@byreddy @end|ng |rom gm@||@com  Mon Aug 10 18:44:05 2020
From: v|kr@m@byreddy @end|ng |rom gm@||@com (Vikram Reddy)
Date: Mon, 10 Aug 2020 10:44:05 -0600
Subject: [R] =?utf-8?q?How_to_auto_generate_=E2=80=9Canchor_links_?=
	=?utf-8?q?=E2=80=9C_and_directory_path_to_text_search_function?=
In-Reply-To: <6049da82b00843319ddd14ae7f74c606@utah.edu>
References: <6049da82b00843319ddd14ae7f74c606@utah.edu>
Message-ID: <CAH+2LYoq=q4xC0fgE7ZLsy=9PnDYGnmyQvVTiKDTZeS7ZWvR2Q@mail.gmail.com>

I have a tokenized txt document with 'div' tags and 'id' to it :




    library(quanteda)


    library(htmltools)


    library(tidyverse)




    text <- <div id="4">But how do you do?</div>


            <div id="5">I see I have frightened you?sit... ?</div>


            <div id="6">It was in July, 1805, and the speaker..</div>


            <div id="7">With these words she greeted Prince Vas?li
Kur?gin...</div>


            <div id="8">Anna P?vlovna had had a cough for some days...</div>


            <div id="9">She was, as she said, suffering from la
grippe....</div>


            <div id="10">Petersburg, used only by the elite.</div>


            <div id="11">All her invitations without exception, written in
French...</div>


            <div id="12">?If you have nothing better to do, Count (or
Prince).. </div>


            <div id="13">?Heavens!</div>


            <div id="14">what a virulent attack!?</div>





             ''''


            <div id="2107">It was plain that this ?well??</div>







I need to auto generate this output to finish it up



    <a href="C:\Users\John\Desktop\final_tokens.html#div number"> text-
sentence </a>



Ex- When I search for the word 'good'





    <a href="C:\Users\John\Desktop\final_tokens.html#49"> Our good and
wonderful sovereign has to </a>


    <a href="C:\Users\John\Desktop\final_tokens.html#73">He is one of the
the good ones.</a>


    <a href="C:\Users\John\Desktop\final_tokens.html#138">She is rich and
of good family..</a>



the div id number should go beside # as show above.



Previously i used



    make_sentences <- function(word) {


                      grep(word,text,value= TRUE)}



above grep  worked fine with plain text before but with lot of regex I need
to modify it ,to get the anchor links directory path and div number to. is
there any solution to this maybe ?

	[[alternative HTML version deleted]]


From d||eepkunj@@| @end|ng |rom gm@||@com  Tue Aug 11 19:41:15 2020
From: d||eepkunj@@| @end|ng |rom gm@||@com (Dileepkumar R)
Date: Tue, 11 Aug 2020 23:11:15 +0530
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
 <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>
Message-ID: <CALTF6snGv9uAz_H+fYGcrsvVdisB8VC4ew6_73xmaozvac19zQ@mail.gmail.com>

Thank you for your reply.

Yes, we can get the curve fit values on the line (as the length of input
data frame) from predict.gam() function.  But I wish to get the trend value
(in Trends in ?C per decade or ?C per year) as given in the Box 2.2, Table
1.  But I couldn't find any option in GAM method.

Actually on of the reviewer of my paper suggested me to estimate the
non-linear trend as given in this Box 2.2, Table 1 and Figure 1.



Dileepkumar R



On Tue, Aug 11, 2020 at 8:01 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Caveat: Did not look at any of your links.
>
> However, the usual answer for this sort of question is ?predict.gam  (in
> general, predict.whatevermethod)
> Have you consulted the man page? If this is not what you want, you may
> need to explain more carefully.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Aug 11, 2020 at 5:21 AM Dileepkumar R <dileepkunjaai at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I am trying to estimate the non -linear trend value from smooth spline
>> trend fit (using the generalized additive model (GAM)).
>>
>> I want to estimate the trend value from a temperature dataset (spatial
>> averaged annual meantime from 1906 to 2005) as given in the Box 2.2, Table
>> 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
>> Report 5 chapter 2
>> <
>> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
>> >,
>> page number 21-22 )
>>
>> I do not understand how they estimate the single value trend with 95%
>> confidence interval from a time-series data as given in the Box 2.2,
>> Figure
>> 1.  Is there any easy way to extract the trend value using mgcv library of
>> R.?
>>
>> Google Doc Link:
>>
>> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
>>
>> Thank you all in advance
>>
>> Dileepkumar R
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Aug 11 19:47:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Aug 2020 10:47:10 -0700
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <CALTF6snGv9uAz_H+fYGcrsvVdisB8VC4ew6_73xmaozvac19zQ@mail.gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
 <CAGxFJbRnp6EmGbooak=e+O+=jBwT679whkGMOSmO+grWRVg3iQ@mail.gmail.com>
 <CALTF6snGv9uAz_H+fYGcrsvVdisB8VC4ew6_73xmaozvac19zQ@mail.gmail.com>
Message-ID: <CAGxFJbQ4CXpfhGaWMpZ=kOdr5Q9Xd1wNWh54YoXsW0Xyfi2Rmg@mail.gmail.com>

??

Change per year = (estimated end value - estimated begin value)/## years

Am I missing something subtle here?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 11, 2020 at 10:41 AM Dileepkumar R <dileepkunjaai at gmail.com>
wrote:

> Thank you for your reply.
>
> Yes, we can get the curve fit values on the line (as the length of input
> data frame) from predict.gam() function.  But I wish to get the trend value
> (in Trends in ?C per decade or ?C per year) as given in the Box 2.2, Table
> 1.  But I couldn't find any option in GAM method.
>
> Actually on of the reviewer of my paper suggested me to estimate the
> non-linear trend as given in this Box 2.2, Table 1 and Figure 1.
>
>
>
> Dileepkumar R
>
>
>
> On Tue, Aug 11, 2020 at 8:01 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Caveat: Did not look at any of your links.
>>
>> However, the usual answer for this sort of question is ?predict.gam  (in
>> general, predict.whatevermethod)
>> Have you consulted the man page? If this is not what you want, you may
>> need to explain more carefully.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Aug 11, 2020 at 5:21 AM Dileepkumar R <dileepkunjaai at gmail.com>
>> wrote:
>>
>>> Dear All,
>>>
>>> I am trying to estimate the non -linear trend value from smooth spline
>>> trend fit (using the generalized additive model (GAM)).
>>>
>>> I want to estimate the trend value from a temperature dataset (spatial
>>> averaged annual meantime from 1906 to 2005) as given in the Box 2.2,
>>> Table
>>> 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
>>> Report 5 chapter 2
>>> <
>>> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
>>> >,
>>> page number 21-22 )
>>>
>>> I do not understand how they estimate the single value trend with 95%
>>> confidence interval from a time-series data as given in the Box 2.2,
>>> Figure
>>> 1.  Is there any easy way to extract the trend value using mgcv library
>>> of
>>> R.?
>>>
>>> Google Doc Link:
>>>
>>> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
>>>
>>> Thank you all in advance
>>>
>>> Dileepkumar R
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From v|vek@utr@ @end|ng |rom gm@||@com  Tue Aug 11 19:50:34 2020
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Tue, 11 Aug 2020 19:50:34 +0200
Subject: [R] Interactive paint corrections on a raster image
Message-ID: <CAHLp6SCddgTsBhVnzaWF-aWm8wYxACPotW6vQnavRaDivUkuzA@mail.gmail.com>

Hi,

I have tried to develop a simple method of correcting some artefacts in an
image with R. Before proceeding further with image analysis.

An example of my attempt:

library(imager)

im <- load.example('coins')

imr <- as.raster(im)

plot(imr)

sel <- locator(n=1)

sel

x1 <- floor(sel$x)

x2 <- x1+10

y1 <- floor(sel$y)

y2 <- y1+10

imr[y1:y2,x1:x2] <- "#FFFFFF"

# I want this correction to be immediately visible without the need for
replotting

imr2 <- imr

plot(imr2)


This works. But I want to improve it to be more flexible inmaking
interactive corrections.
The improvements that I am thinking of are:

1.       Instead of a rectangular area, I want a circular one. And I want
the painting to be visible directly without the need for replotting. I
would like to be able to enlarge slowly the area where I need to do the
corrections (with multiple small corrections to cover an irregular area).
This may require other techniques. For example, with shiny. I know almost
nothing about it. Would appreciate some tips to get started.

2. I am having trouble with specification of colour in the hexadecimal
mode. How can I convert a grayscale image to a numerical mode? I would like
to be able to have corrections made with the intensity in a certain range.
How do I access the colour values at specific locations? I did not succeed
with the getValues function (in a different image).

> getValues(imi3,nrows=seq(917,1017,1),ncols=seq(1119,1219,1))

Error in (function (classes, fdef, mtable)  :

  unable to find an inherited method for function ?getValues? for signature
?"raster", "missing", "numeric"?

I would like to know my mistake here .

I will appreciate all help that I can get.

Thanking you,

Vivek

	[[alternative HTML version deleted]]


From 538280 @end|ng |rom gm@||@com  Tue Aug 11 21:14:04 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 11 Aug 2020 13:14:04 -0600
Subject: [R] Add a logo on a plot
In-Reply-To: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
References: <CAB-TgNs=P+D0XxNfZacK50g+QZzpqgEbrUdPzv-KB0ZqPcLxEQ@mail.gmail.com>
Message-ID: <CAFEqCdw4G=Fg49D6rX19ZVz0m6MvKieyGanVSaxyXY8-H3X2Pw@mail.gmail.com>

One option is to use the my.symbols and ms.image functions from the
TeachingDemos package.  There is an example under ?ms.image.


On Mon, Aug 10, 2020 at 7:43 AM Pedro p?ramo <percentil101 at gmail.com> wrote:
>
> Hi,
>
> There is a way to add a photo like a free text but images on a plot, (hist,
> chart trough ggplot) to add a logo or any PNG .
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 @end|ng |rom gm@||@com  Tue Aug 11 21:23:21 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Tue, 11 Aug 2020 13:23:21 -0600
Subject: [R] Question about PERL lookahead construct in regex's
In-Reply-To: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
References: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
Message-ID: <CAFEqCdyRN95w7GraKusBPdR+fqqqwg4oYvBJtvWN==FR4xcS6g@mail.gmail.com>

I think that the current documentation is correct, but that does not
mean that it cannot be improved.

The key phrase for me is "from the current position"  which says to me
that the match needs to happen right there, not just somewhere in the
rest of the string.

If you used the expression " +t" then you would expect it to only
match if the t was immediately after the last space, not somewhere in
the string after the last space, it is the same with the look-ahead.

On Mon, Aug 10, 2020 at 10:37 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Folks:
>
> Consider:
> > y <- "xx wt"
>
> > grep(" +(?=t)",y, perl = TRUE)
> integer(0)
> ## Unexpected. Lookahead construct does not find "t" after space
> ## But
> > grep(" +(?=.+t)",y, perl = TRUE)
> [1] 1
> ## Expected. Given pattern for **exact** match, lookahead finds it
>
> My concern is:
> ?regexp says this:
> "Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
>  *assertions*: they match if an attempt to match the ... forward from the
> current position would succeed (or not), but use up no characters in the
> string being processed."
>
> But this appears to be imprecise (it confused me, anyway). The usual sense
> of "matching" in regex's is "match the pattern somewhere in the string
> going forward." But in the perl lookahead construct it apparently must
> **exactly** match *everything* in the string that follows.
>
> Questions:
> Am I correct about this? If not, what do I misunderstand?
> If I am correct, should the regex help be slightly modified to something
> like:
>
> "Patterns (?=...) and (?!...) are zero-width positive and negative lookahead
>  *assertions*: they match if an attempt to **exactly" match all of ... forward
> from the current position would succeed (or not), but use up no characters
> in the string being processed."
>
> Thanks.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From r@m|ro @end|ng |rom prec|@|onb|o@@@@y@com  Tue Aug 11 21:35:49 2020
From: r@m|ro @end|ng |rom prec|@|onb|o@@@@y@com (Ramiro Barrantes)
Date: Tue, 11 Aug 2020 19:35:49 +0000
Subject: [R] Huge speed performance difference when using non-trivial fixed
 effects in NLMER vs NLME
Message-ID: <50350c703cfe44a7b328dba48601f99c@precisionbioassay.com>

Following Ben Bolker's methodology (described here https://rpubs.com/bbolker/3423) I incorporated non-trivial fixed effects in NLMER for a four-parameter logistic.   I placed a reproducible example here: https://rpubs.com/ramirob/648103


To summarize the question, if we have a dataset with individuals in groups where we have group-specific fixed effects, NLME's performance remains the same:

## [1] "NLME Time Required for data2Groups: 0.0458040237426758"

fit3Groups <- fitNLME(data3Groups,initialValues3Groups)

## [1] "NLME Time Required for data3Groups: 0.0375699996948242"

fit4Groups <- fitNLME(data4Groups,initialValues4Groups)

## [1] "NLME Time Required for data4Groups: 0.0526559352874756"

fit5Groups <- fitNLME(data5Groups,initialValues5Groups)

## [1] "NLME Time Required for data5Groups: 0.0502560138702393"


But when we do the analogous thing in NLMER, the performance increases with increasing number of groups:


## [1] "Time required for the data2Groups: 0.404773950576782"

fitNlmer3Groups <- fitNlmer(data3Groups, initialValues3Groups)

## [1] "Time required for the data3Groups: 0.579570055007935"

fitNlmer4Groups <- fitNlmer(data4Groups, initialValues4Groups)

## [1] "Time required for the data4Groups: 0.957509994506836"

fitNlmer5Groups <- fitNlmer(data5Groups, initialValues5Groups)

## [1] "Time required for the data5Groups: 1.68412184715271"


In addition, NLMER is much slower in general.  This is just a short example, but for more complicated cases the differences in performance are huge (minutes vs seconds).


Is NLMER "worth the wait" (e.g. less fragile, better convergence, etc) when trying to do non-trivial fixed effects? Is there a better methodology than the one described by Ben Bolker back in 2013?


Any insight appreciated.  Again, you can see a reproducible example here https://rpubs.com/ramirob/648103

Thank you!




	[[alternative HTML version deleted]]


From d||eepkunj@@| @end|ng |rom gm@||@com  Tue Aug 11 22:49:29 2020
From: d||eepkunj@@| @end|ng |rom gm@||@com (Dileepkumar R)
Date: Wed, 12 Aug 2020 02:19:29 +0530
Subject: [R] Trend value from smoothing spline trend fit
In-Reply-To: <823E171D-0931-4A12-8B60-9943CD32DF1C@gmail.com>
References: <CALTF6skaSsCQr6nN+hfKa+JiOL7EH4ytmxgKGszxe+O=jVb0BQ@mail.gmail.com>
 <823E171D-0931-4A12-8B60-9943CD32DF1C@gmail.com>
Message-ID: <CALTF6smZwUYu8TgjEcERsJycucqBSuVg1ONnugSFG_JzhL4bLg@mail.gmail.com>

Dear Bert Gunter and Mathew Guilfoyle,

Thanks for the reply.

I also agree with you. But that is the actual slope of the straight line
connecting from the first estimated value to last estimated value ( like
dy/dx slope). I tried in that way also, but I couldn't replicate the
results as given in that  Box 2.2, Table 1 and Figure 1.  I can replicate
the line plot as in Box 2.2,  Figure 1 (a) (to verify my input data is the
same as in Figure 1 (a)).

You can see my plot here:
https://drive.google.com/file/d/14WDFFW5J69WvxnhbfdcOZKvGRk6HUWVn/view?usp=sharing


I have attached my code and data (as NetCDF file) along with this mail.

input Data (only 32Kb) :
https://drive.google.com/file/d/1Wt5sjVhWmjhRWOfdc6elUzwOvifRk-OI/view?usp=sharing

code:
https://drive.google.com/file/d/1r5mg1vcNmDCIf19jnMUAFEiLNOLKQiKq/view?usp=sharing

output figure:
https://drive.google.com/file/d/1bEXWCB-H5doVKXO8i_FLO7KZMW3qc9Cw/view?usp=sharing

Sincerely,

Dileepkumar R



On Tue, Aug 11, 2020 at 11:41 PM Mathew Guilfoyle <mrguilfoyle at gmail.com>
wrote:

> Looking at the report (specifically the legend for the table) I think all
> they have done is take the difference between fitted temperatures (given by
> linear regression or the GAM) at the start and end of each period (e.g. in
> 1901 and 2012), and then calculate the average change per year.
>
> In a way it ?linearises? the spline trend but I don?t think it?s really
> valid.  It just highlights how poorly a (simple) linear regression can fit
> a very non-linear trend.
>
> > On 11 Aug 2020, at 13:21, Dileepkumar R <dileepkunjaai at gmail.com> wrote:
> >
> > ?Dear All,
> >
> > I am trying to estimate the non -linear trend value from smooth spline
> > trend fit (using the generalized additive model (GAM)).
> >
> > I want to estimate the trend value from a temperature dataset (spatial
> > averaged annual meantime from 1906 to 2005) as given in the Box 2.2,
> Table
> > 1  in the attached Google doc pdf.  (That pages are from  IPCC Assessment
> > Report 5 chapter 2
> > <
> https://www.ipcc.ch/site/assets/uploads/2017/09/WG1AR5_Chapter02_FINAL.pdf
> >,
> > page number 21-22 )
> >
> > I do not understand how they estimate the single value trend with 95%
> > confidence interval from a time-series data as given in the Box 2.2,
> Figure
> > 1.  Is there any easy way to extract the trend value using mgcv library
> of
> > R.?
> >
> > Google Doc Link:
> >
> https://drive.google.com/file/d/1z3XLW-154dsZE6GrvQ4rH_fev9lqdsho/view?usp=sharing
> >
> > Thank you all in advance
> >
> > Dileepkumar R
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 12 01:42:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 11 Aug 2020 16:42:21 -0700
Subject: [R] 
 Huge speed performance difference when using non-trivial fixed
 effects in NLMER vs NLME
In-Reply-To: <50350c703cfe44a7b328dba48601f99c@precisionbioassay.com>
References: <50350c703cfe44a7b328dba48601f99c@precisionbioassay.com>
Message-ID: <CAGxFJbQTex-9ibWOkXeGKBWObdZrNRSS6QgywA1+mKmQCvVhnA@mail.gmail.com>

This should be posted on the r-sig-mixed-models list rather than here. The
interest and expertise you seek is more likely to be found there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Aug 11, 2020 at 12:39 PM Ramiro Barrantes <
ramiro at precisionbioassay.com> wrote:

> Following Ben Bolker's methodology (described here
> https://rpubs.com/bbolker/3423) I incorporated non-trivial fixed effects
> in NLMER for a four-parameter logistic.   I placed a reproducible example
> here: https://rpubs.com/ramirob/648103
>
>
> To summarize the question, if we have a dataset with individuals in groups
> where we have group-specific fixed effects, NLME's performance remains the
> same:
>
> ## [1] "NLME Time Required for data2Groups: 0.0458040237426758"
>
> fit3Groups <- fitNLME(data3Groups,initialValues3Groups)
>
> ## [1] "NLME Time Required for data3Groups: 0.0375699996948242"
>
> fit4Groups <- fitNLME(data4Groups,initialValues4Groups)
>
> ## [1] "NLME Time Required for data4Groups: 0.0526559352874756"
>
> fit5Groups <- fitNLME(data5Groups,initialValues5Groups)
>
> ## [1] "NLME Time Required for data5Groups: 0.0502560138702393"
>
>
> But when we do the analogous thing in NLMER, the performance increases
> with increasing number of groups:
>
>
> ## [1] "Time required for the data2Groups: 0.404773950576782"
>
> fitNlmer3Groups <- fitNlmer(data3Groups, initialValues3Groups)
>
> ## [1] "Time required for the data3Groups: 0.579570055007935"
>
> fitNlmer4Groups <- fitNlmer(data4Groups, initialValues4Groups)
>
> ## [1] "Time required for the data4Groups: 0.957509994506836"
>
> fitNlmer5Groups <- fitNlmer(data5Groups, initialValues5Groups)
>
> ## [1] "Time required for the data5Groups: 1.68412184715271"
>
>
> In addition, NLMER is much slower in general.  This is just a short
> example, but for more complicated cases the differences in performance are
> huge (minutes vs seconds).
>
>
> Is NLMER "worth the wait" (e.g. less fragile, better convergence, etc)
> when trying to do non-trivial fixed effects? Is there a better methodology
> than the one described by Ben Bolker back in 2013?
>
>
> Any insight appreciated.  Again, you can see a reproducible example here
> https://rpubs.com/ramirob/648103
>
> Thank you!
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From percent||101 @end|ng |rom gm@||@com  Tue Aug 11 17:34:31 2020
From: percent||101 @end|ng |rom gm@||@com (=?UTF-8?Q?Pedro_p=C3=A1ramo?=)
Date: Tue, 11 Aug 2020 17:34:31 +0200
Subject: [R] write csv of a structure
Message-ID: <CAB-TgNvuGG+aHyRFh3hfAVyreg4XrdAQCZM=bwK_cq3xdMMjXw@mail.gmail.com>

Hi all,

I want to "save" export in a csv or plain text format the results of my
calculations

I use cbind and I obtain what I call "resultprob" if I put deput it shows
me this

dput(resultprob)
structure(c(88.6572680743221, 7250.7), .Dim = 1:2)

> str(resultprob)
 num [1, 1:2] 88.7 7250.7

I use

write_csv(resultprob, file = "resultprob.csv", sep=",")

But this error appears:

Error in write_csv(resultprob, file = "resultprob.csv", sep = ",") :
  unused arguments (file = "resultprob.csv", sep = ",")

What will be happening?

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Aug 12 09:58:45 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 12 Aug 2020 10:58:45 +0300
Subject: [R] write csv of a structure
In-Reply-To: <CAB-TgNvuGG+aHyRFh3hfAVyreg4XrdAQCZM=bwK_cq3xdMMjXw@mail.gmail.com>
References: <CAB-TgNvuGG+aHyRFh3hfAVyreg4XrdAQCZM=bwK_cq3xdMMjXw@mail.gmail.com>
Message-ID: <20200812105845.37d50a28@Tarkus>

On Tue, 11 Aug 2020 17:34:31 +0200
Pedro p?ramo <percentil101 at gmail.com> wrote:

> Error in write_csv(resultprob, file = "resultprob.csv", sep = ",") :
>   unused arguments (file = "resultprob.csv", sep = ",")

There is utils::write.csv and there is readr::write_csv. Judging by the
parameters you pass, you seem to want to call the former, not the
latter.

Hint: use help() to find out the correct arguments of a function if R
tells you that there was a mistake.

-- 
Best regards,
Ivan


From p@r|@@@g@njeh @end|ng |rom med@un|-goett|ngen@de  Wed Aug 12 11:11:46 2020
From: p@r|@@@g@njeh @end|ng |rom med@un|-goett|ngen@de (Ganjeh, Parisa)
Date: Wed, 12 Aug 2020 09:11:46 +0000
Subject: [R] Calculating effectsize or standarized coefficents for gls
 models in R
Message-ID: <22E1A8776829374C9D4E04A0C7A18FF046214F6F@umg-exc-4.ads.local.med.uni-goettingen.de>

Hi,

I am new in R and I would appreciate if you guide me how I can estimate effect size or standardized coefficients for a gls model (generalized least square) in R. if I can find the way for estimating standardized coefficients is better, because I used effect size package for other models (glm) in my study and got a standardized coefficients as effect size. Unfortunately this package could not give a standardized coefficients or another effect size estimator for gls model. As far as I have searched I could not find a formula in R for calculating effect size or standardized coefficients for my gls model.
My model :
Model1<-gls(Ehyp1~Sex1+SESc1+Ebmi1+Age1+PA1,weights=varIdent(form =~1|PA1), data =X6_17_years_Wave1, na.action = na.exclude)
PA1 is  independent variable and categorical and has 3 levels.
Sex1+SESc1+Ebmi1+Age1: consider as covariates
Sex1 is nominal and has 2 groups (girl and boy).
It is the result of R for my gls model:
Generalized least squares fit by REML
  Model: Ehyp1 ~ Sex1 + SESc1 + Ebmi1 + Age1 + PA1
  Data: X6_17_years_Wave1
       AIC      BIC    logLik
  27156.95 27224.53 -13568.48

Variance function:
Structure: Different standard deviations per stratum
Formula: ~1 | PA1
Parameter estimates:
        3         1         2
1.0000000 0.9268285 0.9310299

Coefficients:
                Value  Std.Error    t-value p-value
(Intercept)  5.957760 0.19569967  30.443382  0.0000
Sex12       -0.832327 0.05159467 -16.132034  0.0000
SESc1       -0.099512 0.00727373 -13.681054  0.0000
Ebmi1        0.021064 0.00837363   2.515553  0.0119
Age1        -0.134280 0.00983979 -13.646654  0.0000
PA12        -0.192089 0.06553337  -2.931163  0.0034
PA13        -0.137575 0.07748981  -1.775395  0.0759

Correlation:
      (Intr) Sex12  SESc1  Ebmi1  Age1   PA12
Sex12 -0.203
SESc1 -0.572 -0.017
Ebmi1 -0.578  0.053  0.145
Age1  -0.230  0.001 -0.001 -0.504
PA12  -0.267  0.116 -0.089  0.005  0.086
PA13  -0.339  0.138 -0.038  0.028  0.179  0.621

Standardized residuals:
        Min          Q1         Med          Q3         Max
-2.34330971 -0.76897681 -0.07360691  0.62658220  3.13138556

Residual standard error: 2.146151
Degrees of freedom: 6363 total; 6356 residual


	[[alternative HTML version deleted]]


From |re|ey@ @end|ng |rom gm@||@com  Wed Aug 12 13:44:10 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 12 Aug 2020 13:44:10 +0200
Subject: [R] add trailing dates with rbind
Message-ID: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>

I am having a hell of a time, this must surely be simple to solve?.

Basically I want to add trailing dates to datasets with differing starting dates so that across datasets I have the same starting date.

# make dataset with the same starting date
start_date = as.Date("2020-03-01")
d_start_date = min(agg_d_h$Group.date)

diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days")) 

for(i in 1:diff_in_days) {
  next_date  = start_date+i
  app_d <- rbind(agg_d_h, c(next_date, 0) )
}

gives:
Error in as.Date.numeric(value) : 'origin' must be supplied

Thank you for your time to help me!

Frederik Feys


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 12 14:10:28 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 12 Aug 2020 15:10:28 +0300
Subject: [R] add trailing dates with rbind
In-Reply-To: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
Message-ID: <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>

Hi Frederik,
(short answer) modify the assignment statement to
    agg_d_h <- rbind( agg_d_h, data.frame(Group.date=next_date,x=0) )

    Note: replace x=0 by your-variable-name=0
    Note: left-hand-side of the assignment statement should be agg_d_h

(longer answer) Your approach is far from the best way to do this task, for
a variety of reasons.
If you think that in the future you will be working a lot with daily time
series and need to perform similar tasks, I would strongly recommend
learning the xts data structure in the xts package.
If you have several time series with different date ranges, and all of them
are xts objects, you can merge them with 'joins' (left joins, right joins,
full joins). xts will automatically handle alignment
and preserving dates, etc.

HTH,
Eric




On Wed, Aug 12, 2020 at 2:44 PM Frederik Feys <frefeys at gmail.com> wrote:

> I am having a hell of a time, this must surely be simple to solve?.
>
> Basically I want to add trailing dates to datasets with differing starting
> dates so that across datasets I have the same starting date.
>
> # make dataset with the same starting date
> start_date = as.Date("2020-03-01")
> d_start_date = min(agg_d_h$Group.date)
>
> diff_in_days = as.numeric(difftime(d_start_date, start_date, units =
> "days"))
>
> for(i in 1:diff_in_days) {
>   next_date  = start_date+i
>   app_d <- rbind(agg_d_h, c(next_date, 0) )
> }
>
> gives:
> Error in as.Date.numeric(value) : 'origin' must be supplied
>
> Thank you for your time to help me!
>
> Frederik Feys
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |re|ey@ @end|ng |rom gm@||@com  Wed Aug 12 15:07:53 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Wed, 12 Aug 2020 15:07:53 +0200
Subject: [R] add trailing dates with rbind
In-Reply-To: <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
 <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>
Message-ID: <36E06F41-BDE1-4D71-AD3C-F65AF363C9C7@gmail.com>

Thank you so much Eric! Wonderful to have an R community helping out so quickly! 

> Op 12 aug. 2020, om 14:10 heeft Eric Berger <ericjberger at gmail.com> het volgende geschreven:
> 
> Hi Frederik,
> (short answer) modify the assignment statement to
>     agg_d_h <- rbind( agg_d_h, data.frame(Group.date=next_date,x=0) )
> 
>     Note: replace x=0 by your-variable-name=0
>     Note: left-hand-side of the assignment statement should be agg_d_h
> 
> (longer answer) Your approach is far from the best way to do this task, for a variety of reasons.
> If you think that in the future you will be working a lot with daily time series and need to perform similar tasks, I would strongly recommend learning the xts data structure in the xts package.
> If you have several time series with different date ranges, and all of them are xts objects, you can merge them with 'joins' (left joins, right joins, full joins). xts will automatically handle alignment
> and preserving dates, etc. 
> 
> HTH,
> Eric
> 
> 
>   
> 
> On Wed, Aug 12, 2020 at 2:44 PM Frederik Feys <frefeys at gmail.com <mailto:frefeys at gmail.com>> wrote:
> I am having a hell of a time, this must surely be simple to solve?.
> 
> Basically I want to add trailing dates to datasets with differing starting dates so that across datasets I have the same starting date.
> 
> # make dataset with the same starting date
> start_date = as.Date("2020-03-01")
> d_start_date = min(agg_d_h$Group.date)
> 
> diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days")) 
> 
> for(i in 1:diff_in_days) {
>   next_date  = start_date+i
>   app_d <- rbind(agg_d_h, c(next_date, 0) )
> }
> 
> gives:
> Error in as.Date.numeric(value) : 'origin' must be supplied
> 
> Thank you for your time to help me!
> 
> Frederik Feys
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @te|@nML @end|ng |rom co||oc@t|on@@de  Wed Aug 12 15:35:20 2020
From: @te|@nML @end|ng |rom co||oc@t|on@@de (Stefan Evert)
Date: Wed, 12 Aug 2020 15:35:20 +0200
Subject: [R] Question about PERL lookahead construct in regex's
In-Reply-To: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
References: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
Message-ID: <D8791839-84CA-4846-A96B-9FCBDD538EC5@collocations.de>


> On 10 Aug 2020, at 18:36, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> But this appears to be imprecise (it confused me, anyway). The usual sense
> of "matching" in regex's is "match the pattern somewhere in the string
> going forward." But in the perl lookahead construct it apparently must
> **exactly** match *everything* in the string that follows.
> 
> Questions:
> Am I correct about this? If not, what do I misunderstand?

I think you're confused about the terminology.  To _match_ a regular expression is to find a substring described by the regexp at a given starting point; what you have in mind is to _search_ a string for matches of a regular expression.

Python uses this terminology in its regexp matching functions, and from what you cited in the documentation so do Perl and PCRE in their docs.

Best,
Stefan

From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Wed Aug 12 15:42:09 2020
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Wed, 12 Aug 2020 08:42:09 -0500
Subject: [R] add trailing dates with rbind
In-Reply-To: <36E06F41-BDE1-4D71-AD3C-F65AF363C9C7@gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
 <CAGgJW76_USOt20r0FKWyA-Lo0c5us9t4FS13RkPoa0f9BZwPvA@mail.gmail.com>
 <36E06F41-BDE1-4D71-AD3C-F65AF363C9C7@gmail.com>
Message-ID: <CAPPM_gSNgxX904HBN_dN=wna+QQ3OV+P5n4V7aqnXcBQYFEFyw@mail.gmail.com>

Eric,

Thanks for the recommendation for xts!

Frederik,

Please direct future questions about xts to R-SIG-Finance, or
Stackoverflow.  I (and other users) are more likely to see your
questions there than here on R-help.

Best,
Josh

On Wed, Aug 12, 2020 at 8:08 AM Frederik Feys <frefeys at gmail.com> wrote:
>
> Thank you so much Eric! Wonderful to have an R community helping out so quickly!
>
> > Op 12 aug. 2020, om 14:10 heeft Eric Berger <ericjberger at gmail.com> het volgende geschreven:
> >
> > Hi Frederik,
> > (short answer) modify the assignment statement to
> >     agg_d_h <- rbind( agg_d_h, data.frame(Group.date=next_date,x=0) )
> >
> >     Note: replace x=0 by your-variable-name=0
> >     Note: left-hand-side of the assignment statement should be agg_d_h
> >
> > (longer answer) Your approach is far from the best way to do this task, for a variety of reasons.
> > If you think that in the future you will be working a lot with daily time series and need to perform similar tasks, I would strongly recommend learning the xts data structure in the xts package.
> > If you have several time series with different date ranges, and all of them are xts objects, you can merge them with 'joins' (left joins, right joins, full joins). xts will automatically handle alignment
> > and preserving dates, etc.
> >
> > HTH,
> > Eric
> >
> >
> >
> >
> > On Wed, Aug 12, 2020 at 2:44 PM Frederik Feys <frefeys at gmail.com <mailto:frefeys at gmail.com>> wrote:
> > I am having a hell of a time, this must surely be simple to solve?.
> >
> > Basically I want to add trailing dates to datasets with differing starting dates so that across datasets I have the same starting date.
> >
> > # make dataset with the same starting date
> > start_date = as.Date("2020-03-01")
> > d_start_date = min(agg_d_h$Group.date)
> >
> > diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days"))
> >
> > for(i in 1:diff_in_days) {
> >   next_date  = start_date+i
> >   app_d <- rbind(agg_d_h, c(next_date, 0) )
> > }
> >
> > gives:
> > Error in as.Date.numeric(value) : 'origin' must be supplied
> >
> > Thank you for your time to help me!
> >
> > Frederik Feys
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 12 16:41:43 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Aug 2020 07:41:43 -0700
Subject: [R] Question about PERL lookahead construct in regex's
In-Reply-To: <D8791839-84CA-4846-A96B-9FCBDD538EC5@collocations.de>
References: <CAGxFJbT2qC_=+Rb=F-bH=zg_y4HWcr61kb7W66zp=48PtL8wuw@mail.gmail.com>
 <D8791839-84CA-4846-A96B-9FCBDD538EC5@collocations.de>
Message-ID: <CAGxFJbQsTResp06QaTmbQMvqDug0dR_xOaJgWLC8TEEEyrVpMQ@mail.gmail.com>

Thank you.
That indeed dispels my brain fog!

Best,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 12, 2020 at 6:35 AM Stefan Evert <stefanML at collocations.de>
wrote:

>
> > On 10 Aug 2020, at 18:36, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > But this appears to be imprecise (it confused me, anyway). The usual
> sense
> > of "matching" in regex's is "match the pattern somewhere in the string
> > going forward." But in the perl lookahead construct it apparently must
> > **exactly** match *everything* in the string that follows.
> >
> > Questions:
> > Am I correct about this? If not, what do I misunderstand?
>
> I think you're confused about the terminology.  To _match_ a regular
> expression is to find a substring described by the regexp at a given
> starting point; what you have in mind is to _search_ a string for matches
> of a regular expression.
>
> Python uses this terminology in its regexp matching functions, and from
> what you cited in the documentation so do Perl and PCRE in their docs.
>
> Best,
> Stefan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@mo|n@r @end|ng |rom @bcg|ob@|@net  Wed Aug 12 16:56:53 2020
From: @@mo|n@r @end|ng |rom @bcg|ob@|@net (Stephen P. Molnar)
Date: Wed, 12 Aug 2020 10:56:53 -0400
Subject: [R] Date Conversion Problem
References: <5F340335.6020201.ref@sbcglobal.net>
Message-ID: <5F340335.6020201@sbcglobal.net>

i have written an R script which allow me to plot the number of Covid-10 
cases reported by he state of Ohio. In that se t of data the date format 
is in the form yyyy-mm-dd.

My script uses:

datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1 week")
            .
            .
            .
       + scale_x_date(breaks=datebreaks)
       + theme(axis.text.x = element_text(angle=30, hjust=1))

to plot the data.

The COVID Tracking Project publishes considerably more data than does 
the state of Ohio. However, The project supplies daily statistics using 
the date format YYYYMMDD.I have done some searching, but I can't seem to 
find a solution (that I can understand).

How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?

Thanks is advanced.

-- 
Stephen P. Molnar, Ph.D.
www.molecular-modeling.net
614.312.7528 (c)
Skype:  smolnar1


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 12 17:01:19 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 12 Aug 2020 18:01:19 +0300
Subject: [R] Date Conversion Problem
In-Reply-To: <5F340335.6020201@sbcglobal.net>
References: <5F340335.6020201.ref@sbcglobal.net>
 <5F340335.6020201@sbcglobal.net>
Message-ID: <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>

library(lubridate)
a <- "20200403"
lubridate::ymd(a)
# 2020-04-03

HTH,
Eric


On Wed, Aug 12, 2020 at 5:57 PM Stephen P. Molnar <s.molnar at sbcglobal.net>
wrote:

> i have written an R script which allow me to plot the number of Covid-10
> cases reported by he state of Ohio. In that se t of data the date format
> is in the form yyyy-mm-dd.
>
> My script uses:
>
> datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1
> week")
>             .
>             .
>             .
>        + scale_x_date(breaks=datebreaks)
>        + theme(axis.text.x = element_text(angle=30, hjust=1))
>
> to plot the data.
>
> The COVID Tracking Project publishes considerably more data than does
> the state of Ohio. However, The project supplies daily statistics using
> the date format YYYYMMDD.I have done some searching, but I can't seem to
> find a solution (that I can understand).
>
> How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?
>
> Thanks is advanced.
>
> --
> Stephen P. Molnar, Ph.D.
> www.molecular-modeling.net
> 614.312.7528 (c)
> Skype:  smolnar1
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 12 17:18:17 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 12 Aug 2020 08:18:17 -0700
Subject: [R] Date Conversion Problem
In-Reply-To: <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>
References: <5F340335.6020201.ref@sbcglobal.net>
 <5F340335.6020201@sbcglobal.net>
 <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>
Message-ID: <CAGxFJbQazqumrPe9+pCndYgESNbHsnJsdDEEVFsEoiMs4LU5Fw@mail.gmail.com>

Extra packages are not needed.

My question is: why change the character representation at all?  See the
format argument of ?as.Date.

> as.Date("20010102",format="%Y%m%d")
[1] "2001-01-02" ## the default format for the print method for Date objects


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Aug 12, 2020 at 8:07 AM Eric Berger <ericjberger at gmail.com> wrote:

> library(lubridate)
> a <- "20200403"
> lubridate::ymd(a)
> # 2020-04-03
>
> HTH,
> Eric
>
>
> On Wed, Aug 12, 2020 at 5:57 PM Stephen P. Molnar <s.molnar at sbcglobal.net>
> wrote:
>
> > i have written an R script which allow me to plot the number of Covid-10
> > cases reported by he state of Ohio. In that se t of data the date format
> > is in the form yyyy-mm-dd.
> >
> > My script uses:
> >
> > datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1
> > week")
> >             .
> >             .
> >             .
> >        + scale_x_date(breaks=datebreaks)
> >        + theme(axis.text.x = element_text(angle=30, hjust=1))
> >
> > to plot the data.
> >
> > The COVID Tracking Project publishes considerably more data than does
> > the state of Ohio. However, The project supplies daily statistics using
> > the date format YYYYMMDD.I have done some searching, but I can't seem to
> > find a solution (that I can understand).
> >
> > How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?
> >
> > Thanks is advanced.
> >
> > --
> > Stephen P. Molnar, Ph.D.
> > www.molecular-modeling.net
> > 614.312.7528 (c)
> > Skype:  smolnar1
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Wed Aug 12 17:22:16 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 12 Aug 2020 18:22:16 +0300
Subject: [R] Date Conversion Problem
In-Reply-To: <CAGxFJbQazqumrPe9+pCndYgESNbHsnJsdDEEVFsEoiMs4LU5Fw@mail.gmail.com>
References: <5F340335.6020201.ref@sbcglobal.net>
 <5F340335.6020201@sbcglobal.net>
 <CAGgJW77=+3PYxEG0CXLbVF-JSEwng=+xO=n2YMYEAkUg65gNaw@mail.gmail.com>
 <CAGxFJbQazqumrPe9+pCndYgESNbHsnJsdDEEVFsEoiMs4LU5Fw@mail.gmail.com>
Message-ID: <CAGgJW76ka7A-2NYCuQsJTkgSAZOGPWV9CnhoGzDgZ-VMLkXMvg@mail.gmail.com>

nice

On Wed, Aug 12, 2020 at 6:18 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Extra packages are not needed.
>
> My question is: why change the character representation at all?  See the
> format argument of ?as.Date.
>
> > as.Date("20010102",format="%Y%m%d")
> [1] "2001-01-02" ## the default format for the print method for Date
> objects
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Aug 12, 2020 at 8:07 AM Eric Berger <ericjberger at gmail.com> wrote:
>
>> library(lubridate)
>> a <- "20200403"
>> lubridate::ymd(a)
>> # 2020-04-03
>>
>> HTH,
>> Eric
>>
>>
>> On Wed, Aug 12, 2020 at 5:57 PM Stephen P. Molnar <s.molnar at sbcglobal.net
>> >
>> wrote:
>>
>> > i have written an R script which allow me to plot the number of Covid-10
>> > cases reported by he state of Ohio. In that se t of data the date format
>> > is in the form yyyy-mm-dd.
>> >
>> > My script uses:
>> >
>> > datebreaks <- seq(as.Date("2020-01-01"), as.Date("2020-08-10"), by="1
>> > week")
>> >             .
>> >             .
>> >             .
>> >        + scale_x_date(breaks=datebreaks)
>> >        + theme(axis.text.x = element_text(angle=30, hjust=1))
>> >
>> > to plot the data.
>> >
>> > The COVID Tracking Project publishes considerably more data than does
>> > the state of Ohio. However, The project supplies daily statistics using
>> > the date format YYYYMMDD.I have done some searching, but I can't seem to
>> > find a solution (that I can understand).
>> >
>> > How can I change the date forma from YYYYMMDD tp YYYY-MM-DD?
>> >
>> > Thanks is advanced.
>> >
>> > --
>> > Stephen P. Molnar, Ph.D.
>> > www.molecular-modeling.net
>> > 614.312.7528 (c)
>> > Skype:  smolnar1
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Aug 12 14:08:48 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 12 Aug 2020 12:08:48 +0000
Subject: [R] add trailing dates with rbind
In-Reply-To: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
References: <F554FAE1-3995-475F-B260-64DECB95FAE7@gmail.com>
Message-ID: <d9a412a8750d42be821e673b347f450e@SRVEXCHCM1302.precheza.cz>

Hi

I am not sure if I understand correctly. You want to change starting days to some common value?

It seems to me that you actually want start at zero date and continue in each dataset regardless of actual starting date. If it is the case, I would use day numbers like in these examples

> x <- seq(as.Date("2020-03-01"), by=1,length.out=20)
> x-x[1]
Time differences in days
 [1]  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19
> y <- seq(as.Date("2020-03-01"), by=2,length.out=10)
> y-y[1]
Time differences in days
 [1]  0  2  4  6  8 10 12 14 16 18
> z <- seq(as.Date("2019-03-01"), by=2,length.out=50)
> z -z[1]
Time differences in days
 [1]  0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48
[26] 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94 96 98
>

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Frederik Feys
> Sent: Wednesday, August 12, 2020 1:44 PM
> To: R-help <r-help at r-project.org>
> Subject: [R] add trailing dates with rbind
> 
> I am having a hell of a time, this must surely be simple to solve?.
> 
> Basically I want to add trailing dates to datasets with differing starting dates
> so that across datasets I have the same starting date.
> 
> # make dataset with the same starting date
> start_date = as.Date("2020-03-01")
> d_start_date = min(agg_d_h$Group.date)
> 
> diff_in_days = as.numeric(difftime(d_start_date, start_date, units = "days"))
> 
> for(i in 1:diff_in_days) {
>   next_date  = start_date+i
>   app_d <- rbind(agg_d_h, c(next_date, 0) )
> }
> 
> gives:
> Error in as.Date.numeric(value) : 'origin' must be supplied
> 
> Thank you for your time to help me!
> 
> Frederik Feys
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From @bdou|@ye@@r @end|ng |rom gm@||@com  Wed Aug 12 14:27:39 2020
From: @bdou|@ye@@r @end|ng |rom gm@||@com (Abdoulaye Sarr)
Date: Wed, 12 Aug 2020 12:27:39 +0000
Subject: [R] date conversion problem
Message-ID: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>

I have dataset with time sine 1800-01-01 and extracted data from 1981 to
2019 and used these lines for the data conversion:
> time_d <- as.Date(time, format="%j", origin=as.Date("1800-01-01"))
> time_years <- format(time_d, "%Y")
> time_months <- format(time_d, "%m")
> time_year_months <- format(time_d, "%Y-%m")
> head(time_d)
[1] "6095-12-22" "6096-01-15" "6096-02-08" "6096-03-03" "6096-03-27"
"6096-04-20"

As you see these gregorian dates are unrealistic and wonder what I am doing
wrong?
The time from the raw file in Jd are like this:

> time
   [1] 1569072 1569096 1569120 1569144 1569168 1569192 1569216 1569240etc.

Hope hint and/or suggestion to solve this.

Best regards

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug 13 10:37:51 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 13 Aug 2020 18:37:51 +1000
Subject: [R] date conversion problem
In-Reply-To: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>
References: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>
Message-ID: <CA+8X3fU6wH=t9SoYrMvJN0MOYK1eTPR--bSLYs=CnbnUepvYHw@mail.gmail.com>

Hi Abdoulaye,
It looks to me as though your offsets are in hours, not days. You can
get a rough date like this:

time<-c(1569072,1569096,1569120,1569144,
 1569168,1569192,1569216,1569240)
time_d<-as.Date("1800-01-01")+time/24
time_d
[1] "1979-01-01" "1979-01-02" "1979-01-03" "1979-01-04" "1979-01-05"
[6] "1979-01-06" "1979-01-07" "1979-01-08"

Jim

On Thu, Aug 13, 2020 at 6:10 PM Abdoulaye Sarr <abdoulayesar at gmail.com> wrote:
>
> I have dataset with time sine 1800-01-01 and extracted data from 1981 to
> 2019 and used these lines for the data conversion:
> > time_d <- as.Date(time, format="%j", origin=as.Date("1800-01-01"))
> > time_years <- format(time_d, "%Y")
> > time_months <- format(time_d, "%m")
> > time_year_months <- format(time_d, "%Y-%m")
> > head(time_d)
> [1] "6095-12-22" "6096-01-15" "6096-02-08" "6096-03-03" "6096-03-27"
> "6096-04-20"
>
> As you see these gregorian dates are unrealistic and wonder what I am doing
> wrong?
> The time from the raw file in Jd are like this:
>
> > time
>    [1] 1569072 1569096 1569120 1569144 1569168 1569192 1569216 1569240etc.
>
> Hope hint and/or suggestion to solve this.
>
> Best regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m|@ojpm @end|ng |rom gm@||@com  Thu Aug 13 11:05:01 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 13 Aug 2020 17:05:01 +0800
Subject: [R] stacked bar on single-color printing
Message-ID: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>

Hi,

   I would like to create percentage stacked bar with graphics package
(e.g., ggplot2) and print it in white/black. The regular option is to use
different color on the bar. Is there any way to use different background on
a bar so that we can tell on a black/white printing? For example, let my
green correspond to ***, while my red correspond to ....

   Thanks,

J

	[[alternative HTML version deleted]]


From pr@@@ddn79 @end|ng |rom gm@||@com  Wed Aug 12 12:50:25 2020
From: pr@@@ddn79 @end|ng |rom gm@||@com (Prasad DN)
Date: Wed, 12 Aug 2020 16:20:25 +0530
Subject: [R] Binomial PCA Using pcr()
Message-ID: <CAN+jWPpZNCMrn=VFSPax3U3LmAzYKaWb2HZsTt97oYWgcQHPLA@mail.gmail.com>

Hi All,

i am very new to R and need guidance.

Need help in doing process capability Analysis for my data set (6 months of
data) given in below format:

Date   |   Opportunities  |  Defectives | DefectivesInPercent

I searched and found that pcr() from QualityTools package can be used for
this purpose.  The USL is 2% defectives.

MyData = read.csv(file.choose())   #select  CSV file that has data in above
mentioned format.
x <- MyData$DefectivesInPercent

pcr(x, distribution = "negative-binomial", usl=0.02)

I get error message as:
Error in pcr(x, distribution = "negative-binomial", usl = 0.02) :
  y distribution could not be found!

Please advise, how to proceed?

Regards,
Prasad DN

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 13 12:31:19 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 13 Aug 2020 11:31:19 +0100
Subject: [R] stacked bar on single-color printing
In-Reply-To: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
Message-ID: <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>

Hello,

Without sample data and the code you've tried it's difficult to say but 
are you looking for something like this?


set.seed(2020)
df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
df1 <- df1[sample(nrow(df1), 100, TRUE), ]

library(ggplot2)

tbl <- as.data.frame(table(df1))

ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
   geom_col() +
   scale_color_manual(values = c("black", "black")) +
   scale_fill_manual(values = c("white", "gray70")) +
   theme_bw()


Hope this helps,

Rui Barradas

?s 10:05 de 13/08/20, John escreveu:
> Hi,
> 
>     I would like to create percentage stacked bar with graphics package
> (e.g., ggplot2) and print it in white/black. The regular option is to use
> different color on the bar. Is there any way to use different background on
> a bar so that we can tell on a black/white printing? For example, let my
> green correspond to ***, while my red correspond to ....
> 
>     Thanks,
> 
> J
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From n|co|@ @end|ng |rom g@mb@ro@co@uk  Thu Aug 13 11:03:16 2020
From: n|co|@ @end|ng |rom g@mb@ro@co@uk (Nicola Gambaro)
Date: Thu, 13 Aug 2020 11:03:16 +0200
Subject: [R] Error with sf ordinary kriging after creating grid
Message-ID: <43C4A697-1F13-4BAB-8A0E-F1DB7E1E886E@gambaro.co.uk>

I want to perform ordinary kriging of temperature (UTCI) data in Nigeria with sf and gstat packages. However, after fitting the variogram model and creating a grid for the region, the krige function returns this error:

Error in (function (classes, fdef, mtable)  : 
  unable to find an inherited method for function ?krige? for signature ?"formula", "sfc_POINT"?
What am I doing wrong? Here is my code:

library(gstat)
library(sf)  
sf_data <- st_as_sf(x = data, coords = c("longitude", "latitude"), crs = 4326)

#VARIOGRAM  
vgm_utci <- variogram(UTCI~1, sf_data)
utci_fit <- fit.variogram(vgm_utci, vgm("Mat"), fit.kappa = TRUE)
   
#CREATE GRID
nigeria <- read_sf("./Igismap/Nigeria_Boundary.shp")
nigeria <- nigeria$geometry
nigeria.grid <- nigeria %>% 
              st_make_grid(cellsize = 0.1, what = "centers") %>%
              st_intersection(nigeria)
            
#UTCI ORDINARY KRIGING
utci_krig <- krige(formula = sf_data$UTCI ~ 1, nigeria.grid, model = utci_fit)
When plotted, the grid and the variogram model look fine. I have attached data and shapefile. Thank you so much in advance,

Nicola

From bgunter@4567 @end|ng |rom gm@||@com  Thu Aug 13 14:20:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Aug 2020 05:20:26 -0700
Subject: [R] Error with sf ordinary kriging after creating grid
In-Reply-To: <43C4A697-1F13-4BAB-8A0E-F1DB7E1E886E@gambaro.co.uk>
References: <43C4A697-1F13-4BAB-8A0E-F1DB7E1E886E@gambaro.co.uk>
Message-ID: <CAGxFJbSyTPGe=pYSkh1UTpvMgUs601zMKDvoswy_nnCyj4MXow@mail.gmail.com>

You should post on r-sig-geo, not here. The specific expertise you seek is
much more likely to be found there.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 13, 2020 at 4:09 AM Nicola Gambaro <nicola at gambaro.co.uk> wrote:

> I want to perform ordinary kriging of temperature (UTCI) data in Nigeria
> with sf and gstat packages. However, after fitting the variogram model and
> creating a grid for the region, the krige function returns this error:
>
> Error in (function (classes, fdef, mtable)  :
>   unable to find an inherited method for function ?krige? for signature
> ?"formula", "sfc_POINT"?
> What am I doing wrong? Here is my code:
>
> library(gstat)
> library(sf)
> sf_data <- st_as_sf(x = data, coords = c("longitude", "latitude"), crs =
> 4326)
>
> #VARIOGRAM
> vgm_utci <- variogram(UTCI~1, sf_data)
> utci_fit <- fit.variogram(vgm_utci, vgm("Mat"), fit.kappa = TRUE)
>
> #CREATE GRID
> nigeria <- read_sf("./Igismap/Nigeria_Boundary.shp")
> nigeria <- nigeria$geometry
> nigeria.grid <- nigeria %>%
>               st_make_grid(cellsize = 0.1, what = "centers") %>%
>               st_intersection(nigeria)
>
> #UTCI ORDINARY KRIGING
> utci_krig <- krige(formula = sf_data$UTCI ~ 1, nigeria.grid, model =
> utci_fit)
> When plotted, the grid and the variogram model look fine. I have attached
> data and shapefile. Thank you so much in advance,
>
> Nicola
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Thu Aug 13 15:27:23 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 13 Aug 2020 21:27:23 +0800
Subject: [R] stacked bar on single-color printing
In-Reply-To: <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
 <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
Message-ID: <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>

Thanks Rui. That's very close to what I am looking for. You use gray scales
for different categories. That would be a great idea. Could we use pattern
fill?
Rui Barradas <ruipbarradas at sapo.pt> ? 2020?8?13? ?? ??6:31???

> Hello,
>
> Without sample data and the code you've tried it's difficult to say but
> are you looking for something like this?
>
>
> set.seed(2020)
> df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
> df1 <- df1[sample(nrow(df1), 100, TRUE), ]
>
> library(ggplot2)
>
> tbl <- as.data.frame(table(df1))
>
> ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
>    geom_col() +
>    scale_color_manual(values = c("black", "black")) +
>    scale_fill_manual(values = c("white", "gray70")) +
>    theme_bw()
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 10:05 de 13/08/20, John escreveu:
> > Hi,
> >
> >     I would like to create percentage stacked bar with graphics package
> > (e.g., ggplot2) and print it in white/black. The regular option is to use
> > different color on the bar. Is there any way to use different background
> on
> > a bar so that we can tell on a black/white printing? For example, let my
> > green correspond to ***, while my red correspond to ....
> >
> >     Thanks,
> >
> > J
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @bdou|@ye@@r @end|ng |rom gm@||@com  Thu Aug 13 12:35:09 2020
From: @bdou|@ye@@r @end|ng |rom gm@||@com (Abdoulaye Sarr)
Date: Thu, 13 Aug 2020 10:35:09 +0000
Subject: [R] date conversion problem
In-Reply-To: <CA+8X3fU6wH=t9SoYrMvJN0MOYK1eTPR--bSLYs=CnbnUepvYHw@mail.gmail.com>
References: <CAN=6O0KQc_U1TSa7pm4463gnoM6nCB2A+GRK_egULC7_nZsKJA@mail.gmail.com>
 <CA+8X3fU6wH=t9SoYrMvJN0MOYK1eTPR--bSLYs=CnbnUepvYHw@mail.gmail.com>
Message-ID: <CAN=6O0+jP1UWiTJFZmjdB45eypUuovGQL8m0ObeQ=d8uk_quHA@mail.gmail.com>

Hi Jim,

Thanks for the hint, that makes sense and I'll arrange accordingly.
Best regards,
Abdoulaye

On Thu, Aug 13, 2020 at 8:38 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Abdoulaye,
> It looks to me as though your offsets are in hours, not days. You can
> get a rough date like this:
>
> time<-c(1569072,1569096,1569120,1569144,
>  1569168,1569192,1569216,1569240)
> time_d<-as.Date("1800-01-01")+time/24
> time_d
> [1] "1979-01-01" "1979-01-02" "1979-01-03" "1979-01-04" "1979-01-05"
> [6] "1979-01-06" "1979-01-07" "1979-01-08"
>
> Jim
>
> On Thu, Aug 13, 2020 at 6:10 PM Abdoulaye Sarr <abdoulayesar at gmail.com>
> wrote:
> >
> > I have dataset with time sine 1800-01-01 and extracted data from 1981 to
> > 2019 and used these lines for the data conversion:
> > > time_d <- as.Date(time, format="%j", origin=as.Date("1800-01-01"))
> > > time_years <- format(time_d, "%Y")
> > > time_months <- format(time_d, "%m")
> > > time_year_months <- format(time_d, "%Y-%m")
> > > head(time_d)
> > [1] "6095-12-22" "6096-01-15" "6096-02-08" "6096-03-03" "6096-03-27"
> > "6096-04-20"
> >
> > As you see these gregorian dates are unrealistic and wonder what I am
> doing
> > wrong?
> > The time from the raw file in Jd are like this:
> >
> > > time
> >    [1] 1569072 1569096 1569120 1569144 1569168 1569192 1569216
> 1569240etc.
> >
> > Hope hint and/or suggestion to solve this.
> >
> > Best regards
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 13 15:48:57 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 13 Aug 2020 14:48:57 +0100
Subject: [R] stacked bar on single-color printing
In-Reply-To: <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
 <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
 <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
Message-ID: <07ebe6a0-ce45-5f1b-7daf-e1c3388356d8@sapo.pt>

Hello,

In base graphics function barplot has arguments angle and density, see 
the help page ?barplot. As an example, with the same data (note that the 
argument density is recycled, 2 values, one per stacked bar times the 
number of unique X vakues):


barplot(Freq ~ Y + X, tbl, density = c(10, 0))


Hope this helps,

Rui Barradas

?s 14:27 de 13/08/20, John escreveu:
> Thanks Rui. That's very close to what I am looking for. You use gray 
> scales for different categories. That would be a great idea. Could we 
> use pattern fill?
> Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> ? 
> 2020?8?13? ?? ??6:31???
> 
>     Hello,
> 
>     Without sample data and the code you've tried it's difficult to say but
>     are you looking for something like this?
> 
> 
>     set.seed(2020)
>     df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
>     df1 <- df1[sample(nrow(df1), 100, TRUE), ]
> 
>     library(ggplot2)
> 
>     tbl <- as.data.frame(table(df1))
> 
>     ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
>      ? ?geom_col() +
>      ? ?scale_color_manual(values = c("black", "black")) +
>      ? ?scale_fill_manual(values = c("white", "gray70")) +
>      ? ?theme_bw()
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     ?s 10:05 de 13/08/20, John escreveu:
>      > Hi,
>      >
>      >? ? ?I would like to create percentage stacked bar with graphics
>     package
>      > (e.g., ggplot2) and print it in white/black. The regular option
>     is to use
>      > different color on the bar. Is there any way to use different
>     background on
>      > a bar so that we can tell on a black/white printing? For example,
>     let my
>      > green correspond to ***, while my red correspond to ....
>      >
>      >? ? ?Thanks,
>      >
>      > J
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From 538280 @end|ng |rom gm@||@com  Thu Aug 13 16:37:42 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 13 Aug 2020 08:37:42 -0600
Subject: [R] stacked bar on single-color printing
In-Reply-To: <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
References: <CABcx46CUJwb3kPwWJ_Zu94wo5GO=SkE3B7B=c8j9qXdMjvq_8w@mail.gmail.com>
 <42c88327-eb2d-e8c0-743e-62a574920e24@sapo.pt>
 <CABcx46AVEB9qgprTTtwd=Dw3z-A_H9dm4cQ5k1HtpkcZHSn-hQ@mail.gmail.com>
Message-ID: <CAFEqCdw=-iOJre0CQ4U5J1ZT7=zTUduMbZbsJud4S0FxtKMJwA@mail.gmail.com>

While it is possible to fill bars with patterns, it is not
recommended.  Fill patterns can lead to what is called the Moire
effect and other optical illusions.  Depending on the fill patterns
and how they relate to each other this can cause an illusion of
movement within the plot, straight lines appearing curved, and
distorting of lengths/positions.  Fill patterns (through the
illusions) can subtly move the observer's eye away from the important
parts of a graph and make it hard to focus on the parts of the graph
that are most important.  Google for phrases "Moire effect graphs" and
"optical illusion diagonal lines" for some examples.

Perhaps a dot chart (using symbols instead of colors/greyscale/fill
patterns) would be a better option than a bar chart for your case.

On Thu, Aug 13, 2020 at 7:21 AM John <miaojpm at gmail.com> wrote:
>
> Thanks Rui. That's very close to what I am looking for. You use gray scales
> for different categories. That would be a great idea. Could we use pattern
> fill?
> Rui Barradas <ruipbarradas at sapo.pt> ? 2020?8?13? ?? ??6:31???
>
> > Hello,
> >
> > Without sample data and the code you've tried it's difficult to say but
> > are you looking for something like this?
> >
> >
> > set.seed(2020)
> > df1 <- expand.grid(X = factor(1:5), Y = LETTERS[1:2])
> > df1 <- df1[sample(nrow(df1), 100, TRUE), ]
> >
> > library(ggplot2)
> >
> > tbl <- as.data.frame(table(df1))
> >
> > ggplot(tbl, aes(X, Freq, color = Y, fill = Y)) +
> >    geom_col() +
> >    scale_color_manual(values = c("black", "black")) +
> >    scale_fill_manual(values = c("white", "gray70")) +
> >    theme_bw()
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 10:05 de 13/08/20, John escreveu:
> > > Hi,
> > >
> > >     I would like to create percentage stacked bar with graphics package
> > > (e.g., ggplot2) and print it in white/black. The regular option is to use
> > > different color on the bar. Is there any way to use different background
> > on
> > > a bar so that we can tell on a black/white printing? For example, let my
> > > green correspond to ***, while my red correspond to ....
> > >
> > >     Thanks,
> > >
> > > J
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From e|en@@|v@nov@ @end|ng |rom hu-ber||n@de  Thu Aug 13 08:00:10 2020
From: e|en@@|v@nov@ @end|ng |rom hu-ber||n@de (Elena Ivanova)
Date: Thu, 13 Aug 2020 09:00:10 +0300
Subject: [R] R 3.6.1 for MAC
Message-ID: <BDD153B8-1A34-41BC-AAF6-B6AF81297F19@hu-berlin.de>

Dear Sir/Madame, 
Could you please let me know where to find the Version 3.6.1 for MAC since I have a package only working with this version

Unfortunately I can not find it here

https://cran.r-project.org/bin/macosx/




Elena Ivanova
PhD Student
elena.ivanova at hu-berlin.de




	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Aug 13 16:58:20 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 13 Aug 2020 17:58:20 +0300
Subject: [R] R 3.6.1 for MAC
In-Reply-To: <BDD153B8-1A34-41BC-AAF6-B6AF81297F19@hu-berlin.de>
References: <BDD153B8-1A34-41BC-AAF6-B6AF81297F19@hu-berlin.de>
Message-ID: <20200813175820.2124d534@trisector>

Dear Elena,

On Thu, 13 Aug 2020 09:00:10 +0300
Elena Ivanova <elena.ivanova at hu-berlin.de> wrote:

> Could you please let me know where to find the Version 3.6.1 for MAC
> since I have a package only working with this version

Short answer: perhaps
https://cran.r-project.org/bin/macosx/el-capitan/base/R-3.6.1.pkg would
work?

R-Help is about R programming, not installation of R on macOS, so if the
link above does not help you, please ask in the R-SIG-Mac mailing list:
https://stat.ethz.ch/mailman/listinfo/r-sig-mac

-- 
Best regards,
Ivan


From herd_dog @end|ng |rom cox@net  Thu Aug 13 17:59:22 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Thu, 13 Aug 2020 08:59:22 -0700
Subject: [R] rNOMAD package
Message-ID: <C9788A2AE06D48D9A943102C9F1F6AE4@OWNERPC>

Daniel Bowman wrote a wonderful package to access National Weather Service data with R.

Unfortunately I stuck trying to download archived Rapid Update Forecasts (RAP) going back into 2016.  I have been poking around on the Internet for days but keep getting recycled to three or four websites that assume a certain level of background knowledge that I don?t have.  It has something to do with OPenDAP (Data Access Protocol) which is a piece of software to grab data over the Internet.

Can someone give me some direction?

Thanks,
Philip
	[[alternative HTML version deleted]]


From roy@mende|@@ohn @end|ng |rom no@@@gov  Thu Aug 13 18:23:20 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Thu, 13 Aug 2020 09:23:20 -0700
Subject: [R] rNOMAD package
In-Reply-To: <C9788A2AE06D48D9A943102C9F1F6AE4@OWNERPC>
References: <C9788A2AE06D48D9A943102C9F1F6AE4@OWNERPC>
Message-ID: <C4807CC7-FC68-4D22-BE6C-A27677B1B33A@noaa.gov>


Hi Philip:

Both 'ncdf4' and 'Rnetcdf' should be able to download data using OPeNDAP.  That the package is using OPeNDAP is transparent to the user,  other than the fact that the "file" is an URL.  Extracts are just like reading a netCDF file using these packages,  so you may have to spend some time learning how to do that.

It is possible that 'tidnyNC' can also do OPeNDAP,  I am just not certain that.

-Roy

> On Aug 13, 2020, at 8:59 AM, Philip <herd_dog at cox.net> wrote:
> 
> Daniel Bowman wrote a wonderful package to access National Weather Service data with R.
> 
> Unfortunately I stuck trying to download archived Rapid Update Forecasts (RAP) going back into 2016.  I have been poking around on the Internet for days but keep getting recycled to three or four websites that assume a certain level of background knowledge that I don?t have.  It has something to do with OPenDAP (Data Access Protocol) which is a piece of software to grab data over the Internet.
> 
> Can someone give me some direction?
> 
> Thanks,
> Philip
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From jgreenberg @end|ng |rom unr@edu  Thu Aug 13 20:58:25 2020
From: jgreenberg @end|ng |rom unr@edu (Jonathan Greenberg)
Date: Thu, 13 Aug 2020 11:58:25 -0700
Subject: [R] Best settings for RStudio video recording?
Message-ID: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>

Folks:

I was wondering if you all would suggest some helpful RStudio
configurations that make recording a session via e.g. zoom the most useful
for students doing remote learning.  Thoughts?

--j

-- 
Jonathan A. Greenberg, PhD
Randall Endowed Professor and Associate Professor of Remote Sensing
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Natural Resources & Environmental Science
University of Nevada, Reno
1664 N Virginia St MS/0186
Reno, NV 89557
Phone: 415-763-5476
https://www.gearslab.org/

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 14 00:15:31 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Aug 2020 15:15:31 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
Message-ID: <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>

Way off topic. Ask at RStudio. This is **R-Help** -- help on R
programming.  RStudio is a private company.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg <jgreenberg at unr.edu>
wrote:

> Folks:
>
> I was wondering if you all would suggest some helpful RStudio
> configurations that make recording a session via e.g. zoom the most useful
> for students doing remote learning.  Thoughts?
>
> --j
>
> --
> Jonathan A. Greenberg, PhD
> Randall Endowed Professor and Associate Professor of Remote Sensing
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Natural Resources & Environmental Science
> University of Nevada, Reno
> 1664 N Virginia St MS/0186
> Reno, NV 89557
> Phone: 415-763-5476
> https://www.gearslab.org/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mtmorg@n@b|oc @end|ng |rom gm@||@com  Fri Aug 14 00:47:30 2020
From: mtmorg@n@b|oc @end|ng |rom gm@||@com (Martin Morgan)
Date: Thu, 13 Aug 2020 22:47:30 +0000
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
Message-ID: <BL0PR04MB6609D91356C1E80EED4E998AF9430@BL0PR04MB6609.namprd04.prod.outlook.com>

Excellent question! I think most R courses use RStudio, so it is completely appropriate to ask about how to help people learn R using RStudio.

I don't have a lot experience with virtual teaching, and very limited experience with anything other than short-term workshops.

I think that there is tremendous value, during the 'in person' portion of a course, in doing interactive and even 'ad hoc' analysis, perhaps especially handling the off-the-wall questions that participants might raise (when I have to struggle to figure out what the R answer is, and then convey to the attendees my thinking process), and making all kinds of mistakes, including simple typos (requiring me to explain what the error message means, and how I diagnosed the problem and arrived at a solution that was other than a pull-it-out-of-the-hat miracle).

With this in mind, I try to increase the prominence of the console portion of the RStudio interface. I place it at the top left of the screen (this might be a remnant of in-person presentations, where the heads of people in front often block the view of the lines where code is being enter; this is obviously not relevant in a virtual context). Usually I keep the script portion of the display visible at the bottom left, with only a few lines showing, as a kind of cheat sheet for me, rather than for the students to 'follow along').

I use a large font, which I think helps in both virtual and physical sessions in part because it limits the amount of information on the screen, causing me to slow my presentation enough that the students can absorb what I am saying. Perhaps as a consequence of the limited screen real-estate, students often ask 'to see the last command' so I now include in the right panel the 'History' tab. The division is asymmetric, so the console continues to take up the majority of screen real estate.

The end result of a sequence of operations is often a pretty picture, but since this is only the end result and not the meat of the learning experience I tend to keep the plot window (lower right) relatively small, and try to remember to expand things at the time when the end result is in sight (so to speak;)).

I hope others with more direct experience are not dissuaded by Bert's opinions, and offer up their own experiences or resource recommendations.

Martin Morgan

?On 8/13/20, 6:05 PM, "R-help on behalf of Jonathan Greenberg" <r-help-bounces at r-project.org on behalf of jgreenberg at unr.edu> wrote:

    Folks:

    I was wondering if you all would suggest some helpful RStudio
    configurations that make recording a session via e.g. zoom the most useful
    for students doing remote learning.  Thoughts?

    --j

    -- 
    Jonathan A. Greenberg, PhD
    Randall Endowed Professor and Associate Professor of Remote Sensing
    Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
    Natural Resources & Environmental Science
    University of Nevada, Reno
    1664 N Virginia St MS/0186
    Reno, NV 89557
    Phone: 415-763-5476
    https://www.gearslab.org/

    	[[alternative HTML version deleted]]

    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Aug 14 02:11:17 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 13 Aug 2020 17:11:17 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
Message-ID: <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>

The jab about a "private company" detracted from your point. It is a public benefit corporation, but either way they produce open source software that is frequently used to introduce people to R, and the company management structure is irrelevant.

While I would have preferred to see a question that was open to any presentation format, forbidding discussion of how to teach R just because the query happens to limit itself to RStudio seems excessively narrow to me.

I have been frustrated by the fact that there is no r-sig-windows, since I find myself uncomfortably discussing OS-specific issues on R-help for which there is no better place to forward them. Using the multi-OS RStudio for teaching R seems rather less off-topic than that.

On August 13, 2020 3:15:31 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>Way off topic. Ask at RStudio. This is **R-Help** -- help on R
>programming.  RStudio is a private company.
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg <jgreenberg at unr.edu>
>wrote:
>
>> Folks:
>>
>> I was wondering if you all would suggest some helpful RStudio
>> configurations that make recording a session via e.g. zoom the most
>useful
>> for students doing remote learning.  Thoughts?
>>
>> --j
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Randall Endowed Professor and Associate Professor of Remote Sensing
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Natural Resources & Environmental Science
>> University of Nevada, Reno
>> 1664 N Virginia St MS/0186
>> Reno, NV 89557
>> Phone: 415-763-5476
>> https://www.gearslab.org/
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug 14 02:22:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 13 Aug 2020 17:22:21 -0700
Subject: [R] Best settings for RStudio video recording?
In-Reply-To: <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
References: <CABG0rfvUKHLyiwE_T+Ao=vyLTGh5B7XPRkbXAZCLxhJUiV44sg@mail.gmail.com>
 <CAGxFJbTnF3S-4QxRgXHZ22SXkS10yYnXbOqTyQy8vncupm8hjQ@mail.gmail.com>
 <923FA85F-56EF-46B2-B151-6F900F3007FF@dcn.davis.ca.us>
Message-ID: <CAGxFJbR50pJbfJDk1tv_gQ5Hxbw1LE0ujFNhteCzKGg_O-k70w@mail.gmail.com>

Well then:
"Using the multi-OS RStudio for teaching R seems rather less off-topic than
that."

If the query is about teaching r, wouldn't R-Sig-teaching be the right
place to post?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Aug 13, 2020 at 5:11 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> The jab about a "private company" detracted from your point. It is a
> public benefit corporation, but either way they produce open source
> software that is frequently used to introduce people to R, and the company
> management structure is irrelevant.
>
> While I would have preferred to see a question that was open to any
> presentation format, forbidding discussion of how to teach R just because
> the query happens to limit itself to RStudio seems excessively narrow to me.
>
> I have been frustrated by the fact that there is no r-sig-windows, since I
> find myself uncomfortably discussing OS-specific issues on R-help for which
> there is no better place to forward them. Using the multi-OS RStudio for
> teaching R seems rather less off-topic than that.
>
> On August 13, 2020 3:15:31 PM PDT, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >Way off topic. Ask at RStudio. This is **R-Help** -- help on R
> >programming.  RStudio is a private company.
> >
> >Bert Gunter
> >
> >"The trouble with having an open mind is that people keep coming along
> >and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> >On Thu, Aug 13, 2020 at 3:05 PM Jonathan Greenberg <jgreenberg at unr.edu>
> >wrote:
> >
> >> Folks:
> >>
> >> I was wondering if you all would suggest some helpful RStudio
> >> configurations that make recording a session via e.g. zoom the most
> >useful
> >> for students doing remote learning.  Thoughts?
> >>
> >> --j
> >>
> >> --
> >> Jonathan A. Greenberg, PhD
> >> Randall Endowed Professor and Associate Professor of Remote Sensing
> >> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> >> Natural Resources & Environmental Science
> >> University of Nevada, Reno
> >> 1664 N Virginia St MS/0186
> >> Reno, NV 89557
> >> Phone: 415-763-5476
> >> https://www.gearslab.org/
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


