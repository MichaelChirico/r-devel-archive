From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Sep  1 22:19:38 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 1 Sep 2020 15:19:38 -0500
Subject: [R] Odd Results when generating predictions with nnet function
Message-ID: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>

Dear friends,

Hope you are all doing well. I am currently using R version 4.0.2 and
working with the nnet package.

My dataframe consists of three columns, FECHA which is the date, x, which
is a sequence from 1 to 159, and y, which is the number of covid cases (I
am also providing the dput for this data frame below).

I tried fitting a neural net model using the following code:

xnew = 1:159
Fit <- nnet(a$y ~ a$x, a, size = 5, maxit = 1000, lineout = T, decay =
0.001)

Finally, I attempted to generate predictions with the following code:

predictions <- predict(Fit, newdata = list(x = xnew), type = "raw")

But obtained extremely odd results:
As you can see, instead of obtaining numbers, more or less in the range of
the last observations  of a$y, I end up getting a bunch of 1s, which
doesn?t make any sense (if anyone could help me understand what could be
causing this):
dput(predictions)
structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim = c(159L,
1L), .Dimnames = list(c("1", "2", "3", "4", "5", "6", "7", "8",
"9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",
"20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30",
"31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41",
"42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52",
"53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63",
"64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74",
"75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85",
"86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96",
"97", "98", "99", "100", "101", "102", "103", "104", "105", "106",
"107", "108", "109", "110", "111", "112", "113", "114", "115",
"116", "117", "118", "119", "120", "121", "122", "123", "124",
"125", "126", "127", "128", "129", "130", "131", "132", "133",
"134", "135", "136", "137", "138", "139", "140", "141", "142",
"143", "144", "145", "146", "147", "148", "149", "150", "151",
"152", "153", "154", "155", "156", "157", "158", "159"), NULL))

head(a)
       FECHA    x  y
1 2020-03-09 1  1
2 2020-03-10 2  8
3 2020-03-11 3 14
4 2020-03-12 4 27
5 2020-03-13 5 36
6 2020-03-14 6 43

dput(a)
structure(list(FECHA = structure(c(18330, 18331, 18332, 18333,
18334, 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342,
18343, 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351,
18352, 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360,
18361, 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369,
18370, 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378,
18379, 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396,
18397, 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405,
18406, 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414,
18415, 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423,
18424, 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432,
18433, 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441,
18442, 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450,
18451, 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467, 18468,
18469, 18470, 18471, 18472, 18473, 18474, 18475, 18476, 18477,
18478, 18479, 18480, 18481, 18482, 18483, 18484, 18485, 18486,
18487, 18488), class = "Date"), x = 1:159, y = c(1, 8, 14, 27,
36, 43, 55, 69, 86, 109, 137, 200, 245, 313, 345, 443, 558, 674,
786, 901, 989, 1075, 1181, 1317, 1475, 1673, 1801, 1988, 2100,
2249, 2528, 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779, 6021, 6200,
6378, 6532, 6720, 7090, 7197, 7387, 7523, 7731, 7868, 8070, 8282,
8448, 8616, 8783, 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977,
10116, 10267, 10577, 10926, 11183, 11447, 11728, 12131, 12531,
13015, 13463, 13837, 14095, 14609, 15044, 15463, 16004, 16425,
16854, 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030, 29037,
29905, 30658, 31686, 32785, 33550, 34463, 35237, 35995, 36983,
38149, 39334, 40291, 41251, 42216, 43257, 44352, 45633, 47177,
48096, 49243, 50373, 51408, 52261, 53468, 54426, 55153, 55906,
56817, 57993, 58864, 60296, 61442, 62223, 63269, 64191, 65256,
66383, 67453, 68456, 69424, 70231, 71418, 72560, 73651, 74492,
75394, 76464, 77377, 78446, 79402)), row.names = c(NA, 159L), class =
"data.frame")
Any help and/or guidance will be greatly appreciated,

Cheers,

Paul

	[[alternative HTML version deleted]]


From d@v|d@tn@jone@ @end|ng |rom gm@||@com  Wed Sep  2 04:44:51 2020
From: d@v|d@tn@jone@ @end|ng |rom gm@||@com (David Jones)
Date: Tue, 1 Sep 2020 21:44:51 -0500
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
Message-ID: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>

I ran a number of analyses in R and saved the workspace, which
resulted in a 2GB .RData file. When I try to read the file back into R
later, it won't read into R and provides the error: "Error: cannot
allocate vector of size 37 Kb"

This error comes after 1 minute of trying to read things in - I
presume a single vector sends it over the memory limit. But,
memory.limit() shows that I have access to a full 16gb of ram on my
machine (12 GB are free when I try to load the RData file).

gc() shows the following after I receive this error:

used (Mb) gc trigger (Mb) max used (Mb)
Ncells 623130 33.3 4134347 220.8 5715387 305.3
Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3


From pd@|gd @end|ng |rom gm@||@com  Wed Sep  2 08:41:09 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 2 Sep 2020 08:41:09 +0200
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
Message-ID: <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>

Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x, data=a, ...) otherwise predict will go looking for a$x, no matter what is in xnew. 

But more importantly, nnet() is a _classifier_, so the LHS should be a class, not a numeric variable.

-pd

> On 1 Sep 2020, at 22:19 , Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> Hope you are all doing well. I am currently using R version 4.0.2 and
> working with the nnet package.
> 
> My dataframe consists of three columns, FECHA which is the date, x, which
> is a sequence from 1 to 159, and y, which is the number of covid cases (I
> am also providing the dput for this data frame below).
> 
> I tried fitting a neural net model using the following code:
> 
> xnew = 1:159
> Fit <- nnet(a$y ~ a$x, a, size = 5, maxit = 1000, lineout = T, decay =
> 0.001)
> 
> Finally, I attempted to generate predictions with the following code:
> 
> predictions <- predict(Fit, newdata = list(x = xnew), type = "raw")
> 
> But obtained extremely odd results:
> As you can see, instead of obtaining numbers, more or less in the range of
> the last observations  of a$y, I end up getting a bunch of 1s, which
> doesn?t make any sense (if anyone could help me understand what could be
> causing this):
> dput(predictions)
> structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim = c(159L,
> 1L), .Dimnames = list(c("1", "2", "3", "4", "5", "6", "7", "8",
> "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19",
> "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30",
> "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41",
> "42", "43", "44", "45", "46", "47", "48", "49", "50", "51", "52",
> "53", "54", "55", "56", "57", "58", "59", "60", "61", "62", "63",
> "64", "65", "66", "67", "68", "69", "70", "71", "72", "73", "74",
> "75", "76", "77", "78", "79", "80", "81", "82", "83", "84", "85",
> "86", "87", "88", "89", "90", "91", "92", "93", "94", "95", "96",
> "97", "98", "99", "100", "101", "102", "103", "104", "105", "106",
> "107", "108", "109", "110", "111", "112", "113", "114", "115",
> "116", "117", "118", "119", "120", "121", "122", "123", "124",
> "125", "126", "127", "128", "129", "130", "131", "132", "133",
> "134", "135", "136", "137", "138", "139", "140", "141", "142",
> "143", "144", "145", "146", "147", "148", "149", "150", "151",
> "152", "153", "154", "155", "156", "157", "158", "159"), NULL))
> 
> head(a)
>       FECHA    x  y
> 1 2020-03-09 1  1
> 2 2020-03-10 2  8
> 3 2020-03-11 3 14
> 4 2020-03-12 4 27
> 5 2020-03-13 5 36
> 6 2020-03-14 6 43
> 
> dput(a)
> structure(list(FECHA = structure(c(18330, 18331, 18332, 18333,
> 18334, 18335, 18336, 18337, 18338, 18339, 18340, 18341, 18342,
> 18343, 18344, 18345, 18346, 18347, 18348, 18349, 18350, 18351,
> 18352, 18353, 18354, 18355, 18356, 18357, 18358, 18359, 18360,
> 18361, 18362, 18363, 18364, 18365, 18366, 18367, 18368, 18369,
> 18370, 18371, 18372, 18373, 18374, 18375, 18376, 18377, 18378,
> 18379, 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395, 18396,
> 18397, 18398, 18399, 18400, 18401, 18402, 18403, 18404, 18405,
> 18406, 18407, 18408, 18409, 18410, 18411, 18412, 18413, 18414,
> 18415, 18416, 18417, 18418, 18419, 18420, 18421, 18422, 18423,
> 18424, 18425, 18426, 18427, 18428, 18429, 18430, 18431, 18432,
> 18433, 18434, 18435, 18436, 18437, 18438, 18439, 18440, 18441,
> 18442, 18443, 18444, 18445, 18446, 18447, 18448, 18449, 18450,
> 18451, 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467, 18468,
> 18469, 18470, 18471, 18472, 18473, 18474, 18475, 18476, 18477,
> 18478, 18479, 18480, 18481, 18482, 18483, 18484, 18485, 18486,
> 18487, 18488), class = "Date"), x = 1:159, y = c(1, 8, 14, 27,
> 36, 43, 55, 69, 86, 109, 137, 200, 245, 313, 345, 443, 558, 674,
> 786, 901, 989, 1075, 1181, 1317, 1475, 1673, 1801, 1988, 2100,
> 2249, 2528, 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779, 6021, 6200,
> 6378, 6532, 6720, 7090, 7197, 7387, 7523, 7731, 7868, 8070, 8282,
> 8448, 8616, 8783, 8944, 9118, 9268, 9449, 9606, 9726, 9867, 9977,
> 10116, 10267, 10577, 10926, 11183, 11447, 11728, 12131, 12531,
> 13015, 13463, 13837, 14095, 14609, 15044, 15463, 16004, 16425,
> 16854, 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030, 29037,
> 29905, 30658, 31686, 32785, 33550, 34463, 35237, 35995, 36983,
> 38149, 39334, 40291, 41251, 42216, 43257, 44352, 45633, 47177,
> 48096, 49243, 50373, 51408, 52261, 53468, 54426, 55153, 55906,
> 56817, 57993, 58864, 60296, 61442, 62223, 63269, 64191, 65256,
> 66383, 67453, 68456, 69424, 70231, 71418, 72560, 73651, 74492,
> 75394, 76464, 77377, 78446, 79402)), row.names = c(NA, 159L), class =
> "data.frame")
> Any help and/or guidance will be greatly appreciated,
> 
> Cheers,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Sep  2 09:37:28 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 2 Sep 2020 09:37:28 +0200
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
Message-ID: <24399.19384.307117.628619@stat.math.ethz.ch>

>>>>> peter dalgaard 
>>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:

    > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
    > data=a, ...) otherwise predict will go looking for a$x, no
    > matter what is in xnew.  

    > But more importantly, nnet() is a _classifier_, 
    > so the LHS should be a class, not a numeric variable.

    > -pd

Well, nnet() can be used for both classification *and* regression,
which is quite clear from the MASS book, but indeed, not from
its help page, which indeed mentions one formula  'class ~ ...'
and then only has classification examples.

So, indeed, the  ?nnet  help page could improved.

In his case, y are counts,  so  John Tukey's good old
"first aid transformation" principle would suggest to model

sqrt(y) ~ ..   in a *regression* model which nnet() can do.

Martin Maechler
ETH Zurich  and  R Core team



    >> On 1 Sep 2020, at 22:19 , Paul Bernal
    >> <paulbernal07 at gmail.com> wrote:
    >> 
    >> Dear friends,
    >> 
    >> Hope you are all doing well. I am currently using R
    >> version 4.0.2 and working with the nnet package.
    >> 
    >> My dataframe consists of three columns, FECHA which is
    >> the date, x, which is a sequence from 1 to 159, and y,
    >> which is the number of covid cases (I am also providing
    >> the dput for this data frame below).
    >> 
    >> I tried fitting a neural net model using the following
    >> code:
    >> 
    >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
    >> 1000, lineout = T, decay = 0.001)
    >> 
    >> Finally, I attempted to generate predictions with the
    >> following code:
    >> 
    >> predictions <- predict(Fit, newdata = list(x = xnew),
    >> type = "raw")
    >> 
    >> But obtained extremely odd results: As you can see,
    >> instead of obtaining numbers, more or less in the range
    >> of the last observations of a$y, I end up getting a bunch
    >> of 1s, which doesn?t make any sense (if anyone could help
    >> me understand what could be causing this):
    >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
    >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
    >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
    >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
    >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
    >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
    >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
    >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
    >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
    >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
    >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
    >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
    >> "96", "97", "98", "99", "100", "101", "102", "103",
    >> "104", "105", "106", "107", "108", "109", "110", "111",
    >> "112", "113", "114", "115", "116", "117", "118", "119",
    >> "120", "121", "122", "123", "124", "125", "126", "127",
    >> "128", "129", "130", "131", "132", "133", "134", "135",
    >> "136", "137", "138", "139", "140", "141", "142", "143",
    >> "144", "145", "146", "147", "148", "149", "150", "151",
    >> "152", "153", "154", "155", "156", "157", "158", "159"),
    >> NULL))
    >> 
    >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
    >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
    >> 2020-03-14 6 43
    >> 
    >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
    >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
    >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
    >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
    >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
    >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
    >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
    >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
    >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
    >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
    >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
    >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
    >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
    >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
    >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
    >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
    >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
    >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
    >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
    >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
    >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
    >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
    >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
    >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
    >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
    >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
    >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
    >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
    >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
    >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
    >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
    >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
    >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
    >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
    >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
    >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
    >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
    >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
    >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
    >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
    >> "data.frame") Any help and/or guidance will be greatly
    >> appreciated,
    >> 
    >> Cheers,
    >> 
    >> Paul
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > -- 
    > Peter Dalgaard, Professor, Center for Statistics,
    > Copenhagen Business School Solbjerg Plads 3, 2000
    > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
    > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Sep  2 11:56:12 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 2 Sep 2020 09:56:12 +0000
Subject: [R] augPred and missing data error
Message-ID: <72e84da8b5374afdaebe55ed4e637ab0@SRVEXCHCM1302.precheza.cz>

Dear all

I would like to ask if augPred is able to handle missing values. Here is
example with below data "test".  I read augPred documentation and nothing is
mentioned that fitted object from data with missing values cannot be used in
augPred. Maybe it would be worth to add something.

Or I just did not read it correctly and with some special setting augPred
can handle such objects?

Cheers
Petr Pikal

test data below

test.g <- groupedData(vodivnorm~cas|variable, data=test)
fit <- nlsList(vodivnorm ~ SSbiexp(cas, Al, lrc1, A2, lrc2), data=test.g)
Error in na.fail.default(data) : missing values in object

na.exclude (or na.omit) works as expected

fit <- nlsList(vodivnorm ~ SSbiexp(cas, Al, lrc1, A2, lrc2), data=test.g,
na.action=na.exclude)

However augPred results in error
plot(augPred(fit))
Error in tapply(object[[nm]], groups, FUN[["numeric"]], ...) : 
  arguments must have same length

The workaround is to discard missing values **before** the fit.

test.gs <- test.g[complete.cases(test.g),]
fit <- nlsList(vodivnorm ~ SSbiexp(cas, Al, lrc1, A2, lrc2), data=test.gs)
plot(augPred(fit))

test <- structure(list(cas = c(0L, 10L, 20L, 30L, 40L, 50L, 60L, 65L, 
70L, 72L, 76L, 80L, 90L, 100L, 110L, 120L, 123L, 130L, 140L, 
146L, 0L, 10L, 20L, 30L, 40L, 50L, 60L, 65L, 70L, 72L, 76L, 80L, 
90L, 100L, 110L, 120L, 123L, 130L, 140L, 146L, 0L, 10L, 20L, 
30L, 40L, 50L, 60L, 65L, 70L, 72L, 76L, 80L, 90L, 100L, 110L, 
120L, 123L, 130L, 140L, 146L), variable = structure(c(9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L), .Label = c("vod02", "vod03", "vod04", "vod10", 
"vod11", "vod12", "vod08", "vod09", "vod05", "vod06", "vod07"
), class = "factor"), value = c(45.78, 9.404, 3.915, 2.074, 1.049, 
0.502, 0.248, NA, 0.159, NA, NA, 0.124, 0.11, 0.104, 0.098, NA, 
NA, NA, NA, NA, 45.75, 12.56, 4.125, 2.204, 1.158, 0.653, 0.381, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 47.22, 15.45, 
6.337, 2.736, 1.107, 0.475, 0.241, NA, 0.187, NA, NA, 0.167, 
0.154, 0.147, 0.134, 0.124, NA, 0.114, 0.103, 0.098), vodivnorm = c(1, 
0.205417212756662, 0.0855176933158585, 0.045303626037571,
0.0229139362166885, 
0.0109654871122761, 0.0054172127566623, NA, 0.00347313237221494, 
NA, NA, 0.00270860637833115, 0.00240279598077763, 0.00227173438182612, 
0.00214067278287462, NA, NA, NA, NA, NA, 1, 0.274535519125683, 
0.0901639344262295, 0.0481748633879781, 0.0253114754098361,
0.0142732240437158, 
0.00832786885245902, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, 1, 0.327191867852605, 0.134201609487505, 0.0579415501905972, 
0.0234434561626429, 0.0100592969080898, 0.00510376958915714, 
NA, 0.00396018636171114, NA, NA, 0.00353663701821262, 0.00326132994493859, 
0.0031130876747141, 0.00283778060144007, 0.00262600592969081, 
NA, 0.00241423125794155, 0.00218127911901737, 0.00207539178314274
)), row.names = c("vod05.161", "vod05.162", "vod05.163", "vod05.164", 
"vod05.165", "vod05.166", "vod05.167", "vod05.168", "vod05.169", 
"vod05.170", "vod05.171", "vod05.172", "vod05.173", "vod05.174", 
"vod05.175", "vod05.176", "vod05.177", "vod05.178", "vod05.179", 
"vod05.180", "vod06.181", "vod06.182", "vod06.183", "vod06.184", 
"vod06.185", "vod06.186", "vod06.187", "vod06.188", "vod06.189", 
"vod06.190", "vod06.191", "vod06.192", "vod06.193", "vod06.194", 
"vod06.195", "vod06.196", "vod06.197", "vod06.198", "vod06.199", 
"vod06.200", "vod07.201", "vod07.202", "vod07.203", "vod07.204", 
"vod07.205", "vod07.206", "vod07.207", "vod07.208", "vod07.209", 
"vod07.210", "vod07.211", "vod07.212", "vod07.213", "vod07.214", 
"vod07.215", "vod07.216", "vod07.217", "vod07.218", "vod07.219", 
"vod07.220"), class = "data.frame")

From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Wed Sep  2 13:36:43 2020
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Wed, 2 Sep 2020 13:36:43 +0200
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
Message-ID: <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>



On 02.09.2020 04:44, David Jones wrote:
> I ran a number of analyses in R and saved the workspace, which
> resulted in a 2GB .RData file. When I try to read the file back into R

Compressed in RData but uncompressed in main memory....


> later, it won't read into R and provides the error: "Error: cannot
> allocate vector of size 37 Kb"
> 
> This error comes after 1 minute of trying to read things in - I
> presume a single vector sends it over the memory limit. But,
> memory.limit() shows that I have access to a full 16gb of ram on my
> machine (12 GB are free when I try to load the RData file).

But the data may need more....


> gc() shows the following after I receive this error:
> 
> used (Mb) gc trigger (Mb) max used (Mb)
> Ncells 623130 33.3 4134347 220.8 5715387 305.3
> Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3

So 16GB were used when R gave up.

Best,
Uwe Ligges



> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Sep  2 16:21:58 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 2 Sep 2020 09:21:58 -0500
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <24399.19384.307117.628619@stat.math.ethz.ch>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
Message-ID: <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>

Dear Dr. Martin and Dr. Peter,

Hope you are doing well. Thank you for your kind feedback. I also tried
fitting the nnet using y ~ x, but the model kept on generating odd
predictions. If I understand correctly, from what Dr. Martin said, it would
be a good idea to try modeling sqrt(y) ~ x and then backtransform raising
both y and x to 0.5?

I was looking at a video where the guy modeled count data without doing any
kind of transformation and didn't get odd results, which is rather extrange.

Cheers,

Paul



El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<
maechler at stat.math.ethz.ch>) escribi?:

> >>>>> peter dalgaard
> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
>
>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
>     > data=a, ...) otherwise predict will go looking for a$x, no
>     > matter what is in xnew.
>
>     > But more importantly, nnet() is a _classifier_,
>     > so the LHS should be a class, not a numeric variable.
>
>     > -pd
>
> Well, nnet() can be used for both classification *and* regression,
> which is quite clear from the MASS book, but indeed, not from
> its help page, which indeed mentions one formula  'class ~ ...'
> and then only has classification examples.
>
> So, indeed, the  ?nnet  help page could improved.
>
> In his case, y are counts,  so  John Tukey's good old
> "first aid transformation" principle would suggest to model
>
> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
>
> Martin Maechler
> ETH Zurich  and  R Core team
>
>
>
>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
>     >> <paulbernal07 at gmail.com> wrote:
>     >>
>     >> Dear friends,
>     >>
>     >> Hope you are all doing well. I am currently using R
>     >> version 4.0.2 and working with the nnet package.
>     >>
>     >> My dataframe consists of three columns, FECHA which is
>     >> the date, x, which is a sequence from 1 to 159, and y,
>     >> which is the number of covid cases (I am also providing
>     >> the dput for this data frame below).
>     >>
>     >> I tried fitting a neural net model using the following
>     >> code:
>     >>
>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
>     >> 1000, lineout = T, decay = 0.001)
>     >>
>     >> Finally, I attempted to generate predictions with the
>     >> following code:
>     >>
>     >> predictions <- predict(Fit, newdata = list(x = xnew),
>     >> type = "raw")
>     >>
>     >> But obtained extremely odd results: As you can see,
>     >> instead of obtaining numbers, more or less in the range
>     >> of the last observations of a$y, I end up getting a bunch
>     >> of 1s, which doesn?t make any sense (if anyone could help
>     >> me understand what could be causing this):
>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
>     >> "96", "97", "98", "99", "100", "101", "102", "103",
>     >> "104", "105", "106", "107", "108", "109", "110", "111",
>     >> "112", "113", "114", "115", "116", "117", "118", "119",
>     >> "120", "121", "122", "123", "124", "125", "126", "127",
>     >> "128", "129", "130", "131", "132", "133", "134", "135",
>     >> "136", "137", "138", "139", "140", "141", "142", "143",
>     >> "144", "145", "146", "147", "148", "149", "150", "151",
>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
>     >> NULL))
>     >>
>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
>     >> 2020-03-14 6 43
>     >>
>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
>     >> "data.frame") Any help and/or guidance will be greatly
>     >> appreciated,
>     >>
>     >> Cheers,
>     >>
>     >> Paul
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html and provide
>     >> commented, minimal, self-contained, reproducible code.
>
>     > --
>     > Peter Dalgaard, Professor, Center for Statistics,
>     > Copenhagen Business School Solbjerg Plads 3, 2000
>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Sep  2 17:01:22 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Sep 2020 08:01:22 -0700
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
 <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
Message-ID: <19EA33E8-9938-4D7A-B92C-B4258BA0FC0F@dcn.davis.ca.us>

Why would you expect raising y_pred to the 0.5 to "backtransform" a model sqrt(y)~x? Wouldn't you raise to the 2?

Why would you "backtransform" x in such a model if it were never transformed in the first place? Dr Maechler did not suggest that.

And why are you mentioning some random unspecified video on Youtube? That does not enlighten anyone here, apparently including you. Please reference package documentation, and/or reproduce the analysis discussed in that video to provide a contrasting (or supporting) point with the example you gave.


On September 2, 2020 7:21:58 AM PDT, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear Dr. Martin and Dr. Peter,
>
>Hope you are doing well. Thank you for your kind feedback. I also tried
>fitting the nnet using y ~ x, but the model kept on generating odd
>predictions. If I understand correctly, from what Dr. Martin said, it
>would
>be a good idea to try modeling sqrt(y) ~ x and then backtransform
>raising
>both y and x to 0.5?
>
>I was looking at a video where the guy modeled count data without doing
>any
>kind of transformation and didn't get odd results, which is rather
>extrange.
>
>Cheers,
>
>Paul
>
>
>
>El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<
>maechler at stat.math.ethz.ch>) escribi?:
>
>> >>>>> peter dalgaard
>> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
>>
>>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
>>     > data=a, ...) otherwise predict will go looking for a$x, no
>>     > matter what is in xnew.
>>
>>     > But more importantly, nnet() is a _classifier_,
>>     > so the LHS should be a class, not a numeric variable.
>>
>>     > -pd
>>
>> Well, nnet() can be used for both classification *and* regression,
>> which is quite clear from the MASS book, but indeed, not from
>> its help page, which indeed mentions one formula  'class ~ ...'
>> and then only has classification examples.
>>
>> So, indeed, the  ?nnet  help page could improved.
>>
>> In his case, y are counts,  so  John Tukey's good old
>> "first aid transformation" principle would suggest to model
>>
>> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
>>
>> Martin Maechler
>> ETH Zurich  and  R Core team
>>
>>
>>
>>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
>>     >> <paulbernal07 at gmail.com> wrote:
>>     >>
>>     >> Dear friends,
>>     >>
>>     >> Hope you are all doing well. I am currently using R
>>     >> version 4.0.2 and working with the nnet package.
>>     >>
>>     >> My dataframe consists of three columns, FECHA which is
>>     >> the date, x, which is a sequence from 1 to 159, and y,
>>     >> which is the number of covid cases (I am also providing
>>     >> the dput for this data frame below).
>>     >>
>>     >> I tried fitting a neural net model using the following
>>     >> code:
>>     >>
>>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
>>     >> 1000, lineout = T, decay = 0.001)
>>     >>
>>     >> Finally, I attempted to generate predictions with the
>>     >> following code:
>>     >>
>>     >> predictions <- predict(Fit, newdata = list(x = xnew),
>>     >> type = "raw")
>>     >>
>>     >> But obtained extremely odd results: As you can see,
>>     >> instead of obtaining numbers, more or less in the range
>>     >> of the last observations of a$y, I end up getting a bunch
>>     >> of 1s, which doesn?t make any sense (if anyone could help
>>     >> me understand what could be causing this):
>>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
>>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
>>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
>>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
>>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
>>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
>>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
>>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
>>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
>>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
>>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
>>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
>>     >> "96", "97", "98", "99", "100", "101", "102", "103",
>>     >> "104", "105", "106", "107", "108", "109", "110", "111",
>>     >> "112", "113", "114", "115", "116", "117", "118", "119",
>>     >> "120", "121", "122", "123", "124", "125", "126", "127",
>>     >> "128", "129", "130", "131", "132", "133", "134", "135",
>>     >> "136", "137", "138", "139", "140", "141", "142", "143",
>>     >> "144", "145", "146", "147", "148", "149", "150", "151",
>>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
>>     >> NULL))
>>     >>
>>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
>>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
>>     >> 2020-03-14 6 43
>>     >>
>>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
>>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
>>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
>>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
>>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
>>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
>>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
>>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
>>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
>>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
>>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
>>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
>>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
>>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
>>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
>>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
>>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
>>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
>>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
>>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
>>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
>>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
>>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
>>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
>>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
>>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
>>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
>>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
>>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
>>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
>>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
>>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
>>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
>>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
>>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
>>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
>>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
>>     >> "data.frame") Any help and/or guidance will be greatly
>>     >> appreciated,
>>     >>
>>     >> Cheers,
>>     >>
>>     >> Paul
>>     >>
>>     >> [[alternative HTML version deleted]]
>>     >>
>>     >> ______________________________________________
>>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> PLEASE do read the posting guide
>>     >> http://www.R-project.org/posting-guide.html and provide
>>     >> commented, minimal, self-contained, reproducible code.
>>
>>     > --
>>     > Peter Dalgaard, Professor, Center for Statistics,
>>     > Copenhagen Business School Solbjerg Plads 3, 2000
>>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
>>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>>
>>     > ______________________________________________
>>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>>     > PLEASE do read the posting guide
>>     > http://www.R-project.org/posting-guide.html and provide
>>     > commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From pd@|gd @end|ng |rom gm@||@com  Wed Sep  2 17:33:57 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 2 Sep 2020 17:33:57 +0200
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
 <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
Message-ID: <7324A23D-0A27-4CF9-BCC5-ADE04F0C11F1@gmail.com>

The problem seems to be the fit rather than the predictions. Looks like nnet is happier with data between 0 and 1, witness

Fit <- nnet(y/max(y) ~ x, a, size = 5, maxit = 1000, lineout = T, decay = 0.001)
plot(y/max(y)~x,a)
lines(fitted(Fit)~x,a)


> On 2 Sep 2020, at 16:21 , Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear Dr. Martin and Dr. Peter, 
> 
> Hope you are doing well. Thank you for your kind feedback. I also tried fitting the nnet using y ~ x, but the model kept on generating odd predictions. If I understand correctly, from what Dr. Martin said, it would be a good idea to try modeling sqrt(y) ~ x and then backtransform raising both y and x to 0.5?
> 
> I was looking at a video where the guy modeled count data without doing any kind of transformation and didn't get odd results, which is rather extrange.
> 
> Cheers,
> 
> Paul
> 
> 
> 
> El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<maechler at stat.math.ethz.ch>) escribi?:
> >>>>> peter dalgaard 
> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
> 
>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
>     > data=a, ...) otherwise predict will go looking for a$x, no
>     > matter what is in xnew.  
> 
>     > But more importantly, nnet() is a _classifier_, 
>     > so the LHS should be a class, not a numeric variable.
> 
>     > -pd
> 
> Well, nnet() can be used for both classification *and* regression,
> which is quite clear from the MASS book, but indeed, not from
> its help page, which indeed mentions one formula  'class ~ ...'
> and then only has classification examples.
> 
> So, indeed, the  ?nnet  help page could improved.
> 
> In his case, y are counts,  so  John Tukey's good old
> "first aid transformation" principle would suggest to model
> 
> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
> 
> Martin Maechler
> ETH Zurich  and  R Core team
> 
> 
> 
>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
>     >> <paulbernal07 at gmail.com> wrote:
>     >> 
>     >> Dear friends,
>     >> 
>     >> Hope you are all doing well. I am currently using R
>     >> version 4.0.2 and working with the nnet package.
>     >> 
>     >> My dataframe consists of three columns, FECHA which is
>     >> the date, x, which is a sequence from 1 to 159, and y,
>     >> which is the number of covid cases (I am also providing
>     >> the dput for this data frame below).
>     >> 
>     >> I tried fitting a neural net model using the following
>     >> code:
>     >> 
>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
>     >> 1000, lineout = T, decay = 0.001)
>     >> 
>     >> Finally, I attempted to generate predictions with the
>     >> following code:
>     >> 
>     >> predictions <- predict(Fit, newdata = list(x = xnew),
>     >> type = "raw")
>     >> 
>     >> But obtained extremely odd results: As you can see,
>     >> instead of obtaining numbers, more or less in the range
>     >> of the last observations of a$y, I end up getting a bunch
>     >> of 1s, which doesn?t make any sense (if anyone could help
>     >> me understand what could be causing this):
>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
>     >> "96", "97", "98", "99", "100", "101", "102", "103",
>     >> "104", "105", "106", "107", "108", "109", "110", "111",
>     >> "112", "113", "114", "115", "116", "117", "118", "119",
>     >> "120", "121", "122", "123", "124", "125", "126", "127",
>     >> "128", "129", "130", "131", "132", "133", "134", "135",
>     >> "136", "137", "138", "139", "140", "141", "142", "143",
>     >> "144", "145", "146", "147", "148", "149", "150", "151",
>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
>     >> NULL))
>     >> 
>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
>     >> 2020-03-14 6 43
>     >> 
>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
>     >> "data.frame") Any help and/or guidance will be greatly
>     >> appreciated,
>     >> 
>     >> Cheers,
>     >> 
>     >> Paul
>     >> 
>     >> [[alternative HTML version deleted]]
>     >> 
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide
>     >> http://www.R-project.org/posting-guide.html and provide
>     >> commented, minimal, self-contained, reproducible code.
> 
>     > -- 
>     > Peter Dalgaard, Professor, Center for Statistics,
>     > Copenhagen Business School Solbjerg Plads 3, 2000
>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> 
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html and provide
>     > commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Sep  2 18:45:36 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 2 Sep 2020 11:45:36 -0500
Subject: [R] Odd Results when generating predictions with nnet function
In-Reply-To: <19EA33E8-9938-4D7A-B92C-B4258BA0FC0F@dcn.davis.ca.us>
References: <CAMOcQfNKrAiXQs4yGDpPfjLQK1+ouJb0AhQ7X_x_-GRxLA6mLw@mail.gmail.com>
 <C774833D-704C-4620-9DBE-588BE3ED067A@gmail.com>
 <24399.19384.307117.628619@stat.math.ethz.ch>
 <CAMOcQfPUhazJ=d7mso1XGqv-V4HUkJNxkwFh+jo54tD9baRJWg@mail.gmail.com>
 <19EA33E8-9938-4D7A-B92C-B4258BA0FC0F@dcn.davis.ca.us>
Message-ID: <CAMOcQfMf=7wNUm39U06Uub3MRowfeEfC8bw=FthPgOmu7OQJrg@mail.gmail.com>

You are right Jeff, that was a mistake, I was focusing on the square root
and made the mistake of talking about taking the square root instead of
raising to the 2nd power.

This is the example I was following (
https://www.youtube.com/watch?v=SaQgA6V8UA4). Of course, I tried fitting
the nnet model to my own data, to see what kind of results I'd get (the
data that I used, I provided in the very first e-mail).

The question I was asking is why do I get a bunch of 1s for the
predictions, given that the expected results would have to be somewhere
close to the latest observations.

The code and the data from the example I was following is provided in the
youtube link above.

Paul


<https://www.youtube.com/watch?v=SaQgA6V8UA4>

El mi?., 2 sept. 2020 a las 10:01, Jeff Newmiller (<jdnewmil at dcn.davis.ca.us>)
escribi?:

> Why would you expect raising y_pred to the 0.5 to "backtransform" a model
> sqrt(y)~x? Wouldn't you raise to the 2?
>
> Why would you "backtransform" x in such a model if it were never
> transformed in the first place? Dr Maechler did not suggest that.
>
> And why are you mentioning some random unspecified video on Youtube? That
> does not enlighten anyone here, apparently including you. Please reference
> package documentation, and/or reproduce the analysis discussed in that
> video to provide a contrasting (or supporting) point with the example you
> gave.
>
>
> On September 2, 2020 7:21:58 AM PDT, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >Dear Dr. Martin and Dr. Peter,
> >
> >Hope you are doing well. Thank you for your kind feedback. I also tried
> >fitting the nnet using y ~ x, but the model kept on generating odd
> >predictions. If I understand correctly, from what Dr. Martin said, it
> >would
> >be a good idea to try modeling sqrt(y) ~ x and then backtransform
> >raising
> >both y and x to 0.5?
> >
> >I was looking at a video where the guy modeled count data without doing
> >any
> >kind of transformation and didn't get odd results, which is rather
> >extrange.
> >
> >Cheers,
> >
> >Paul
> >
> >
> >
> >El mi?., 2 sept. 2020 a las 2:37, Martin Maechler (<
> >maechler at stat.math.ethz.ch>) escribi?:
> >
> >> >>>>> peter dalgaard
> >> >>>>>     on Wed, 2 Sep 2020 08:41:09 +0200 writes:
> >>
> >>     > Generically, nnet(a$y ~ a$x, a ...) should be nnet(y ~ x,
> >>     > data=a, ...) otherwise predict will go looking for a$x, no
> >>     > matter what is in xnew.
> >>
> >>     > But more importantly, nnet() is a _classifier_,
> >>     > so the LHS should be a class, not a numeric variable.
> >>
> >>     > -pd
> >>
> >> Well, nnet() can be used for both classification *and* regression,
> >> which is quite clear from the MASS book, but indeed, not from
> >> its help page, which indeed mentions one formula  'class ~ ...'
> >> and then only has classification examples.
> >>
> >> So, indeed, the  ?nnet  help page could improved.
> >>
> >> In his case, y are counts,  so  John Tukey's good old
> >> "first aid transformation" principle would suggest to model
> >>
> >> sqrt(y) ~ ..   in a *regression* model which nnet() can do.
> >>
> >> Martin Maechler
> >> ETH Zurich  and  R Core team
> >>
> >>
> >>
> >>     >> On 1 Sep 2020, at 22:19 , Paul Bernal
> >>     >> <paulbernal07 at gmail.com> wrote:
> >>     >>
> >>     >> Dear friends,
> >>     >>
> >>     >> Hope you are all doing well. I am currently using R
> >>     >> version 4.0.2 and working with the nnet package.
> >>     >>
> >>     >> My dataframe consists of three columns, FECHA which is
> >>     >> the date, x, which is a sequence from 1 to 159, and y,
> >>     >> which is the number of covid cases (I am also providing
> >>     >> the dput for this data frame below).
> >>     >>
> >>     >> I tried fitting a neural net model using the following
> >>     >> code:
> >>     >>
> >>     >> xnew = 1:159 Fit <- nnet(a$y ~ a$x, a, size = 5, maxit =
> >>     >> 1000, lineout = T, decay = 0.001)
> >>     >>
> >>     >> Finally, I attempted to generate predictions with the
> >>     >> following code:
> >>     >>
> >>     >> predictions <- predict(Fit, newdata = list(x = xnew),
> >>     >> type = "raw")
> >>     >>
> >>     >> But obtained extremely odd results: As you can see,
> >>     >> instead of obtaining numbers, more or less in the range
> >>     >> of the last observations of a$y, I end up getting a bunch
> >>     >> of 1s, which doesn?t make any sense (if anyone could help
> >>     >> me understand what could be causing this):
> >>     >> dput(predictions) structure(c(1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> >>     >> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1), .Dim
> >>     >> = c(159L, 1L), .Dimnames = list(c("1", "2", "3", "4",
> >>     >> "5", "6", "7", "8", "9", "10", "11", "12", "13", "14",
> >>     >> "15", "16", "17", "18", "19", "20", "21", "22", "23",
> >>     >> "24", "25", "26", "27", "28", "29", "30", "31", "32",
> >>     >> "33", "34", "35", "36", "37", "38", "39", "40", "41",
> >>     >> "42", "43", "44", "45", "46", "47", "48", "49", "50",
> >>     >> "51", "52", "53", "54", "55", "56", "57", "58", "59",
> >>     >> "60", "61", "62", "63", "64", "65", "66", "67", "68",
> >>     >> "69", "70", "71", "72", "73", "74", "75", "76", "77",
> >>     >> "78", "79", "80", "81", "82", "83", "84", "85", "86",
> >>     >> "87", "88", "89", "90", "91", "92", "93", "94", "95",
> >>     >> "96", "97", "98", "99", "100", "101", "102", "103",
> >>     >> "104", "105", "106", "107", "108", "109", "110", "111",
> >>     >> "112", "113", "114", "115", "116", "117", "118", "119",
> >>     >> "120", "121", "122", "123", "124", "125", "126", "127",
> >>     >> "128", "129", "130", "131", "132", "133", "134", "135",
> >>     >> "136", "137", "138", "139", "140", "141", "142", "143",
> >>     >> "144", "145", "146", "147", "148", "149", "150", "151",
> >>     >> "152", "153", "154", "155", "156", "157", "158", "159"),
> >>     >> NULL))
> >>     >>
> >>     >> head(a) FECHA x y 1 2020-03-09 1 1 2 2020-03-10 2 8 3
> >>     >> 2020-03-11 3 14 4 2020-03-12 4 27 5 2020-03-13 5 36 6
> >>     >> 2020-03-14 6 43
> >>     >>
> >>     >> dput(a) structure(list(FECHA = structure(c(18330, 18331,
> >>     >> 18332, 18333, 18334, 18335, 18336, 18337, 18338, 18339,
> >>     >> 18340, 18341, 18342, 18343, 18344, 18345, 18346, 18347,
> >>     >> 18348, 18349, 18350, 18351, 18352, 18353, 18354, 18355,
> >>     >> 18356, 18357, 18358, 18359, 18360, 18361, 18362, 18363,
> >>     >> 18364, 18365, 18366, 18367, 18368, 18369, 18370, 18371,
> >>     >> 18372, 18373, 18374, 18375, 18376, 18377, 18378, 18379,
> >>     >> 18380, 18381, 18382, 18383, 18384, 18385, 18386, 18387,
> >>     >> 18388, 18389, 18390, 18391, 18392, 18393, 18394, 18395,
> >>     >> 18396, 18397, 18398, 18399, 18400, 18401, 18402, 18403,
> >>     >> 18404, 18405, 18406, 18407, 18408, 18409, 18410, 18411,
> >>     >> 18412, 18413, 18414, 18415, 18416, 18417, 18418, 18419,
> >>     >> 18420, 18421, 18422, 18423, 18424, 18425, 18426, 18427,
> >>     >> 18428, 18429, 18430, 18431, 18432, 18433, 18434, 18435,
> >>     >> 18436, 18437, 18438, 18439, 18440, 18441, 18442, 18443,
> >>     >> 18444, 18445, 18446, 18447, 18448, 18449, 18450, 18451,
> >>     >> 18452, 18453, 18454, 18455, 18456, 18457, 18458, 18459,
> >>     >> 18460, 18461, 18462, 18463, 18464, 18465, 18466, 18467,
> >>     >> 18468, 18469, 18470, 18471, 18472, 18473, 18474, 18475,
> >>     >> 18476, 18477, 18478, 18479, 18480, 18481, 18482, 18483,
> >>     >> 18484, 18485, 18486, 18487, 18488), class = "Date"), x =
> >>     >> 1:159, y = c(1, 8, 14, 27, 36, 43, 55, 69, 86, 109, 137,
> >>     >> 200, 245, 313, 345, 443, 558, 674, 786, 901, 989, 1075,
> >>     >> 1181, 1317, 1475, 1673, 1801, 1988, 2100, 2249, 2528,
> >>     >> 2752, 2974, 3234, 3400, 3472, 3574, 3751, 4016, 4210,
> >>     >> 4273, 4467, 4658, 4821, 4992, 5166, 5338, 5538, 5779,
> >>     >> 6021, 6200, 6378, 6532, 6720, 7090, 7197, 7387, 7523,
> >>     >> 7731, 7868, 8070, 8282, 8448, 8616, 8783, 8944, 9118,
> >>     >> 9268, 9449, 9606, 9726, 9867, 9977, 10116, 10267, 10577,
> >>     >> 10926, 11183, 11447, 11728, 12131, 12531, 13015, 13463,
> >>     >> 13837, 14095, 14609, 15044, 15463, 16004, 16425, 16854,
> >>     >> 17233, 17889, 18586, 19211, 20059, 20686, 21422, 21962,
> >>     >> 22597, 23351, 24274, 25222, 26030, 26752, 27314, 28030,
> >>     >> 29037, 29905, 30658, 31686, 32785, 33550, 34463, 35237,
> >>     >> 35995, 36983, 38149, 39334, 40291, 41251, 42216, 43257,
> >>     >> 44352, 45633, 47177, 48096, 49243, 50373, 51408, 52261,
> >>     >> 53468, 54426, 55153, 55906, 56817, 57993, 58864, 60296,
> >>     >> 61442, 62223, 63269, 64191, 65256, 66383, 67453, 68456,
> >>     >> 69424, 70231, 71418, 72560, 73651, 74492, 75394, 76464,
> >>     >> 77377, 78446, 79402)), row.names = c(NA, 159L), class =
> >>     >> "data.frame") Any help and/or guidance will be greatly
> >>     >> appreciated,
> >>     >>
> >>     >> Cheers,
> >>     >>
> >>     >> Paul
> >>     >>
> >>     >> [[alternative HTML version deleted]]
> >>     >>
> >>     >> ______________________________________________
> >>     >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >>     >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >>     >> PLEASE do read the posting guide
> >>     >> http://www.R-project.org/posting-guide.html and provide
> >>     >> commented, minimal, self-contained, reproducible code.
> >>
> >>     > --
> >>     > Peter Dalgaard, Professor, Center for Statistics,
> >>     > Copenhagen Business School Solbjerg Plads 3, 2000
> >>     > Frederiksberg, Denmark Phone: (+45)38153501 Office: A 4.23
> >>     > Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> >>
> >>     > ______________________________________________
> >>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >>     > more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >>     > PLEASE do read the posting guide
> >>     > http://www.R-project.org/posting-guide.html and provide
> >>     > commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jwd @end|ng |rom @urewe@t@net  Wed Sep  2 22:27:29 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 2 Sep 2020 13:27:29 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
Message-ID: <20200902132729.6e710c03@Draco>

On Wed, 2 Sep 2020 13:36:43 +0200
Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> On 02.09.2020 04:44, David Jones wrote:
> > I ran a number of analyses in R and saved the workspace, which
> > resulted in a 2GB .RData file. When I try to read the file back
> > into R  
> 
> Compressed in RData but uncompressed in main memory....
> 
> 
> > later, it won't read into R and provides the error: "Error: cannot
> > allocate vector of size 37 Kb"
> > 
> > This error comes after 1 minute of trying to read things in - I
> > presume a single vector sends it over the memory limit. But,
> > memory.limit() shows that I have access to a full 16gb of ram on my
> > machine (12 GB are free when I try to load the RData file).  
> 
> But the data may need more....
> 
> 
> > gc() shows the following after I receive this error:
> > 
> > used (Mb) gc trigger (Mb) max used (Mb)
> > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3  
> 
> So 16GB were used when R gave up.
> 
> Best,
> Uwe Ligges

For my own part, looking at the OP's question, it does seem curious
that R could write that .RData file, but on the same system not be able
to reload something it created.  How would that work.  Wouldn't the
memory limit have been exceeded BEFORE the the .RData file was written
the FIRST time?

JDougherty


From bgunter@4567 @end|ng |rom gm@||@com  Wed Sep  2 22:32:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 2 Sep 2020 13:32:15 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <20200902132729.6e710c03@Draco>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <20200902132729.6e710c03@Draco>
Message-ID: <CAGxFJbTpC-DiZjiKAixzmX0HkUbY7KLpX4Gc1Q+yQRFSZky2jA@mail.gmail.com>

R experts may give you a detailed explanation, but it is certainly possible
that the memory available to R when it wrote the file was different than
when it tried to read it, is it not?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help at r-project.org> wrote:

> On Wed, 2 Sep 2020 13:36:43 +0200
> Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
> > On 02.09.2020 04:44, David Jones wrote:
> > > I ran a number of analyses in R and saved the workspace, which
> > > resulted in a 2GB .RData file. When I try to read the file back
> > > into R
> >
> > Compressed in RData but uncompressed in main memory....
> >
> >
> > > later, it won't read into R and provides the error: "Error: cannot
> > > allocate vector of size 37 Kb"
> > >
> > > This error comes after 1 minute of trying to read things in - I
> > > presume a single vector sends it over the memory limit. But,
> > > memory.limit() shows that I have access to a full 16gb of ram on my
> > > machine (12 GB are free when I try to load the RData file).
> >
> > But the data may need more....
> >
> >
> > > gc() shows the following after I receive this error:
> > >
> > > used (Mb) gc trigger (Mb) max used (Mb)
> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
> >
> > So 16GB were used when R gave up.
> >
> > Best,
> > Uwe Ligges
>
> For my own part, looking at the OP's question, it does seem curious
> that R could write that .RData file, but on the same system not be able
> to reload something it created.  How would that work.  Wouldn't the
> memory limit have been exceeded BEFORE the the .RData file was written
> the FIRST time?
>
> JDougherty
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@v|d@tn@jone@ @end|ng |rom gm@||@com  Wed Sep  2 23:31:53 2020
From: d@v|d@tn@jone@ @end|ng |rom gm@||@com (David Jones)
Date: Wed, 2 Sep 2020 16:31:53 -0500
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
Message-ID: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>

Thank you Uwe, John, and Bert - this is very helpful context.

If it helps inform the discussion, to address John and Bert's
questions - I actually had less memory free when I originally ran the
analyses and saved the workspace, than when I read in the data back in
later on (I rebooted in an attempt to free all possible memory before
rereading the workspace back in).



On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
r-project.org> wrote:

>> On Wed, 2 Sep 2020 13:36:43 +0200
>> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
>>
>> > On 02.09.2020 04:44, David Jones wrote:
>> > > I ran a number of analyses in R and saved the workspace, which
>> > > resulted in a 2GB .RData file. When I try to read the file back
>> > > into R
>> >
>> > Compressed in RData but uncompressed in main memory....
>> >
>> >
>> > > later, it won't read into R and provides the error: "Error: cannot
>> > > allocate vector of size 37 Kb"
>> > >
>> > > This error comes after 1 minute of trying to read things in - I
>> > > presume a single vector sends it over the memory limit. But,
>> > > memory.limit() shows that I have access to a full 16gb of ram on my
>> > > machine (12 GB are free when I try to load the RData file).
>> >
>> > But the data may need more....
>> >
>> >
>> > > gc() shows the following after I receive this error:
>> > >
>> > > used (Mb) gc trigger (Mb) max used (Mb)
>> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
>> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
>> >
>> > So 16GB were used when R gave up.
>> >
>> > Best,
>> > Uwe Ligges
>>
>> For my own part, looking at the OP's question, it does seem curious
>> that R could write that .RData file, but on the same system not be able
>> to reload something it created.  How would that work.  Wouldn't the
>> memory limit have been exceeded BEFORE the the .RData file was written
>> the FIRST time?
>>
>> JDougherty


>R experts may give you a detailed explanation, but it is certainly possible
>that the memory available to R when it wrote the file was different than
>when it tried to read it, is it not?

>Bert Gunter

>"The trouble with having an open mind is that people keep coming along and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From |e@ndrom@r|no @end|ng |rom |e@ndrom@r|no@com@br  Thu Sep  3 01:21:53 2020
From: |e@ndrom@r|no @end|ng |rom |e@ndrom@r|no@com@br (Leandro Marino)
Date: Wed, 2 Sep 2020 20:21:53 -0300
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
Message-ID: <CAKSaaF=RskDefRehCW66Shhd-2YVHR6CTRpmnESJH6F6Q_9gow@mail.gmail.com>

David,

If the ".Rdata" contains more than one object you could (and maybe should
use) the SOAR package (from Venables). This package helps you to split the
objects over multiple RData files. It's useful when you have numerous
medium-large objects in the workspace but doesn't use then at the same
time.

When use SOAR::Attach(), for instance, it loads the current name of all the
objects and retain than available in the searchpath but without load then
to the memory. As you call, they will be loaded into the memory.

If needed, you can update the object and then store it again with the
SOAR::Store()

For my use, this package is terrific! I use it with an analysis that I need
to repeat over medium-large similars datasets.

Best
Leandro

Em qua., 2 de set. de 2020 ?s 18:33, David Jones <david.tn.jones at gmail.com>
escreveu:

> Thank you Uwe, John, and Bert - this is very helpful context.
>
> If it helps inform the discussion, to address John and Bert's
> questions - I actually had less memory free when I originally ran the
> analyses and saved the workspace, than when I read in the data back in
> later on (I rebooted in an attempt to free all possible memory before
> rereading the workspace back in).
>
>
>
> On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
> r-project.org> wrote:
>
> >> On Wed, 2 Sep 2020 13:36:43 +0200
> >> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
> >>
> >> > On 02.09.2020 04:44, David Jones wrote:
> >> > > I ran a number of analyses in R and saved the workspace, which
> >> > > resulted in a 2GB .RData file. When I try to read the file back
> >> > > into R
> >> >
> >> > Compressed in RData but uncompressed in main memory....
> >> >
> >> >
> >> > > later, it won't read into R and provides the error: "Error: cannot
> >> > > allocate vector of size 37 Kb"
> >> > >
> >> > > This error comes after 1 minute of trying to read things in - I
> >> > > presume a single vector sends it over the memory limit. But,
> >> > > memory.limit() shows that I have access to a full 16gb of ram on my
> >> > > machine (12 GB are free when I try to load the RData file).
> >> >
> >> > But the data may need more....
> >> >
> >> >
> >> > > gc() shows the following after I receive this error:
> >> > >
> >> > > used (Mb) gc trigger (Mb) max used (Mb)
> >> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> >> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
> >> >
> >> > So 16GB were used when R gave up.
> >> >
> >> > Best,
> >> > Uwe Ligges
> >>
> >> For my own part, looking at the OP's question, it does seem curious
> >> that R could write that .RData file, but on the same system not be able
> >> to reload something it created.  How would that work.  Wouldn't the
> >> memory limit have been exceeded BEFORE the the .RData file was written
> >> the FIRST time?
> >>
> >> JDougherty
>
>
> >R experts may give you a detailed explanation, but it is certainly
> possible
> >that the memory available to R when it wrote the file was different than
> >when it tried to read it, is it not?
>
> >Bert Gunter
>
> >"The trouble with having an open mind is that people keep coming along and
> >sticking things into it."
> >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  3 01:51:15 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Sep 2020 16:51:15 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
Message-ID: <FE6986EB-431B-4B17-8FCB-FB60572B374A@dcn.davis.ca.us>

You need more RAM to load this file. As the memory was being used in your original file, certain objects (such as numeric columns) were being shared among different higher-level objects (such as data frames). When serialized into the file those optimizations were lost, and now those columns are stored separately.

Search [1] for "shared" to learn more about measuring object memory requirements.

[1] http://adv-r.had.co.nz/memory.html

On September 2, 2020 2:31:53 PM PDT, David Jones <david.tn.jones at gmail.com> wrote:
>Thank you Uwe, John, and Bert - this is very helpful context.
>
>If it helps inform the discussion, to address John and Bert's
>questions - I actually had less memory free when I originally ran the
>analyses and saved the workspace, than when I read in the data back in
>later on (I rebooted in an attempt to free all possible memory before
>rereading the workspace back in).
>
>
>
>On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
>r-project.org> wrote:
>
>>> On Wed, 2 Sep 2020 13:36:43 +0200
>>> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
>>>
>>> > On 02.09.2020 04:44, David Jones wrote:
>>> > > I ran a number of analyses in R and saved the workspace, which
>>> > > resulted in a 2GB .RData file. When I try to read the file back
>>> > > into R
>>> >
>>> > Compressed in RData but uncompressed in main memory....
>>> >
>>> >
>>> > > later, it won't read into R and provides the error: "Error:
>cannot
>>> > > allocate vector of size 37 Kb"
>>> > >
>>> > > This error comes after 1 minute of trying to read things in - I
>>> > > presume a single vector sends it over the memory limit. But,
>>> > > memory.limit() shows that I have access to a full 16gb of ram on
>my
>>> > > machine (12 GB are free when I try to load the RData file).
>>> >
>>> > But the data may need more....
>>> >
>>> >
>>> > > gc() shows the following after I receive this error:
>>> > >
>>> > > used (Mb) gc trigger (Mb) max used (Mb)
>>> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
>>> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
>>> >
>>> > So 16GB were used when R gave up.
>>> >
>>> > Best,
>>> > Uwe Ligges
>>>
>>> For my own part, looking at the OP's question, it does seem curious
>>> that R could write that .RData file, but on the same system not be
>able
>>> to reload something it created.  How would that work.  Wouldn't the
>>> memory limit have been exceeded BEFORE the the .RData file was
>written
>>> the FIRST time?
>>>
>>> JDougherty
>
>
>>R experts may give you a detailed explanation, but it is certainly
>possible
>>that the memory available to R when it wrote the file was different
>than
>>when it tried to read it, is it not?
>
>>Bert Gunter
>
>>"The trouble with having an open mind is that people keep coming along
>and
>>sticking things into it."
>>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From herd_dog @end|ng |rom cox@net  Thu Sep  3 02:29:54 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Wed, 2 Sep 2020 17:29:54 -0700
Subject: [R] .grb2 Files
Message-ID: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>

Any advise about how to get NOAA .grb2 files into R?

Thanks.
	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Sep  3 02:57:28 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 2 Sep 2020 20:57:28 -0400
Subject: [R] .grb2 Files
In-Reply-To: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>
References: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>
Message-ID: <CAM_vjukc1uoKCye2P6w_bxWuUBozdnRt0G4TMvZ7Zi8OEHC+_g@mail.gmail.com>

GDAL supports GRIB2 so it should be easy using rgdal and raster packages.

Sarah

On Wed, Sep 2, 2020 at 8:32 PM Philip <herd_dog at cox.net> wrote:
>
> Any advise about how to get NOAA .grb2 files into R?
>
> Thanks.
-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Sep  3 02:59:24 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 2 Sep 2020 17:59:24 -0700
Subject: [R] .grb2 Files
In-Reply-To: <CAM_vjukc1uoKCye2P6w_bxWuUBozdnRt0G4TMvZ7Zi8OEHC+_g@mail.gmail.com>
References: <C0E975DE08A84F1D99B83535D2A894AE@OWNERPC>
 <CAM_vjukc1uoKCye2P6w_bxWuUBozdnRt0G4TMvZ7Zi8OEHC+_g@mail.gmail.com>
Message-ID: <5652a48b-e50c-fc67-303d-3fdc15d464a4@comcast.net>

A very simple search (= "CRAN NOAA .grb2") and small bit of reading help 
files suggests that you might want wgrib2 and rNOMADS

https://rdrr.io/cran/rNOMADS/man/GribInfo.html

https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/

-- 

David

On 9/2/20 5:57 PM, Sarah Goslee wrote:
> GDAL supports GRIB2 so it should be easy using rgdal and raster packages.
>
> Sarah
>
> On Wed, Sep 2, 2020 at 8:32 PM Philip <herd_dog at cox.net> wrote:
>> Any advise about how to get NOAA .grb2 files into R?
>>
>> Thanks.


From he@h@m|bb @end|ng |rom y@hoo@com  Thu Sep  3 03:13:08 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Thu, 3 Sep 2020 01:13:08 +0000 (UTC)
Subject: [R] statment can tacke value in row1 and rows
References: <167820381.2055618.1599095588454.ref@mail.yahoo.com>
Message-ID: <167820381.2055618.1599095588454@mail.yahoo.com>

hello.I have this code :#################################3#read data just thee columns. first and second columns are catogary , third column? is number.?out<-read.csv("outbr.csv")
truth<-out[,seq(1,2)]?#truth about 2000 rows, some values in row1 can? show in rows2,and the some values in row2 can also show in row1 :
#for example :#G1(row1), G2(row2)
#G2(row1),G1(row2)
#if this happend add to thrid column in truth 1 otherwise add 0 as in statment followtruth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3Q:# i want make loop take all 2000 rows and comparsion between all values in row one and row two :
#Gi(value in row1), Gj(value in row2)
#Gj(varow1),Gi(row2),?#############more :#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?
(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Sep  3 03:27:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 2 Sep 2020 18:27:24 -0700
Subject: [R] statment can tacke value in row1 and rows
In-Reply-To: <167820381.2055618.1599095588454@mail.yahoo.com>
References: <167820381.2055618.1599095588454.ref@mail.yahoo.com>
 <167820381.2055618.1599095588454@mail.yahoo.com>
Message-ID: <CAGxFJbT+bNANdOLVqk_F1v4yZb1XT0E7=bSUHKSvpN6+M=KMrQ@mail.gmail.com>

Please re-post in plain text. This is a plain text list and html can get
messed up, as here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Sep 2, 2020 at 6:18 PM Hesham A. AL-bukhaiti via R-help <
r-help at r-project.org> wrote:

> hello.I have this code :#################################3#read data just
> thee columns. first and second columns are catogary , third column  is
> number. out<-read.csv("outbr.csv")
> truth<-out[,seq(1,2)] #truth about 2000 rows, some values in row1 can
> show in rows2,and the some values in row2 can also show in row1 :
> #for example :#G1(row1), G2(row2)
> #G2(row1),G1(row2)
> #if this happend add to thrid column in truth 1 otherwise add 0 as in
> statment
> followtruth<-cbind(as.character(truth[,1]),as.character(truth[,2])
>    ,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make
> loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" &
> truth[,2]=="G2") | (truth[,1]=="G2" &
> truth[,2]=="G3"),3]<-1 ###############################3Q:# i want make loop
> take all 2000 rows and comparsion between all values in row one and row two
> :
> #Gi(value in row1), Gj(value in row2)
> #Gj(varow1),Gi(row2), #############more :#here just G2 and G3, i want make
> loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" &
> truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1
> (Simply they regulate the other. If element A is in the first group , and
> it is related to element B in the second group , and element B also in  in
> the first group , and it is related to element A(the same element  in the
> first group)  in the second group , we write 1 and otherwise 0.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jwd @end|ng |rom @urewe@t@net  Thu Sep  3 03:32:42 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 2 Sep 2020 18:32:42 -0700
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
Message-ID: <20200902183242.6719ead3@Draco>

On Wed, 2 Sep 2020 16:31:53 -0500
David Jones <david.tn.jones at gmail.com> wrote:

> Thank you Uwe, John, and Bert - this is very helpful context.
> 
> If it helps inform the discussion, to address John and Bert's
> questions - I actually had less memory free when I originally ran the
> analyses and saved the workspace, than when I read in the data back in
> later on (I rebooted in an attempt to free all possible memory before
> rereading the workspace back in).
> 
I assumed that, though I shouldn't have.  Nice to know.  Were you
working from a terminal or through a GUI like RStudio?  You will need
to provide a really clear description of the initial and later
conditions.  Your step to reboot and then load is exactly what I would
have done, I would also have killed any network connection temporarily
to see if there are other things going on that caused the problem out
side of R.  You should also let any potential helper know what OS you
are using, and what hardware configuration you have.  Since you
rebooted you are probably not working across a network, but ...

JWDougherty


From drj|m|emon @end|ng |rom gm@||@com  Thu Sep  3 05:27:17 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 3 Sep 2020 13:27:17 +1000
Subject: [R] statment can tacke value in row1 and rows
In-Reply-To: <167820381.2055618.1599095588454@mail.yahoo.com>
References: <167820381.2055618.1599095588454.ref@mail.yahoo.com>
 <167820381.2055618.1599095588454@mail.yahoo.com>
Message-ID: <CA+8X3fUQqzmSTxha2HH-9F9q6JbQ3U2Xd7yKrwb4vBgamO3SHQ@mail.gmail.com>

Hi Hesham,
It think you are looking for something like this:

truth<-data.frame(G1=sample(LETTERS[1:4],20,TRUE),
 G2=sample(LETTERS[1:4],20,TRUE))
truth
truth$G3<-as.numeric(truth$G1 == truth$G2)
truth

Note that like quite a few emails produced with Javascript formatting,
there are embedded characters that R can't interpret.

Jim

On Thu, Sep 3, 2020 at 11:18 AM Hesham A. AL-bukhaiti via R-help
<r-help at r-project.org> wrote:
>
> hello.I have this code :#################################3#read data just thee columns. first and second columns are catogary , third column  is number. out<-read.csv("outbr.csv")
> truth<-out[,seq(1,2)] #truth about 2000 rows, some values in row1 can  show in rows2,and the some values in row2 can also show in row1 :
> #for example :#G1(row1), G2(row2)
> #G2(row1),G1(row2)
> #if this happend add to thrid column in truth 1 otherwise add 0 as in statment followtruth<-cbind(as.character(truth[,1]),as.character(truth[,2])             ,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1 ###############################3Q:# i want make loop take all 2000 rows and comparsion between all values in row one and row two :
> #Gi(value in row1), Gj(value in row2)
> #Gj(varow1),Gi(row2), #############more :#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000 truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1
> (Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in  in the first group , and it is related to element A(the same element  in the first group)  in the second group , we write 1 and otherwise 0.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pr|yb|o|n|o @end|ng |rom gm@||@com  Wed Sep  2 13:12:04 2020
From: pr|yb|o|n|o @end|ng |rom gm@||@com (Dr Priyanka Jain)
Date: Wed, 2 Sep 2020 16:42:04 +0530
Subject: [R] Error in running diffcoexp
In-Reply-To: <CANVWkqevFHYiLauYZV0cars+HmVjra-TUc9kK+n=NjdE2u-qMw@mail.gmail.com>
References: <CANVWkqevFHYiLauYZV0cars+HmVjra-TUc9kK+n=NjdE2u-qMw@mail.gmail.com>
Message-ID: <CANVWkqeMXx4Cd0CuMt4ua5etiHY5_K3noWmscTp2gNqwPAAHZA@mail.gmail.com>

Dear Sir/ Madam,
                             I am getting the following error:


geneExp <- read.table("DV_control_FPKM.txt",header=T, sep="\t",row.names=1)
geneExp=as.matrix(as.data.frame(geneExp))
head(geneExp)
geneExp2 <- read.table("DV_introgressed_line_FPKM.txt",header=T,
sep="\t",row.names=1)
geneExp2=as.matrix(as.data.frame(geneExp))
head(geneExp2)
library(diffcoexp)
allowWGCNAThreads()
res=diffcoexp(exprs.1 = geneExp, exprs.2 = geneExp2, r.method = "spearman" )
Error in exprs.1[rownames(exprs.1) != "", ] :
  incorrect number of dimensions

I have attached my input file along with mail
-- 
With Regards,
*Dr Priyanka Jain (PhD)*,
Mobile : 9718854136





-- 
With Regards,
*Dr Priyanka Jain (PhD)*,
Mobile : 9718854136

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Sep  3 14:54:36 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 3 Sep 2020 12:54:36 +0000
Subject: [R] Error in running diffcoexp
In-Reply-To: <CANVWkqeMXx4Cd0CuMt4ua5etiHY5_K3noWmscTp2gNqwPAAHZA@mail.gmail.com>
References: <CANVWkqevFHYiLauYZV0cars+HmVjra-TUc9kK+n=NjdE2u-qMw@mail.gmail.com>
 <CANVWkqeMXx4Cd0CuMt4ua5etiHY5_K3noWmscTp2gNqwPAAHZA@mail.gmail.com>
Message-ID: <493e330d020a4b0db585c724add24eaf@SRVEXCHCM1302.precheza.cz>

Hi.

See inline

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Dr Priyanka Jain
> Sent: Wednesday, September 2, 2020 1:12 PM
> To: r-help at r-project.org
> Subject: [R] Error in running diffcoexp
> 
> Dear Sir/ Madam,
>                              I am getting the following error:
> 
> 
> geneExp <- read.table("DV_control_FPKM.txt",header=T,

already data frame

> sep="\t",row.names=1)
> geneExp=as.matrix(as.data.frame(geneExp))

so as.data.frame unnecessary

> head(geneExp)

better str(geneExp) to see actual structure

> geneExp2 <- read.table("DV_introgressed_line_FPKM.txt",header=T,
> sep="\t",row.names=1)
> geneExp2=as.matrix(as.data.frame(geneExp))
> head(geneExp2)
> library(diffcoexp)
> allowWGCNAThreads()
> res=diffcoexp(exprs.1 = geneExp, exprs.2 = geneExp2, r.method = "spearman"
)
> Error in exprs.1[rownames(exprs.1) != "", ] :
>   incorrect number of dimensions

My guess is that during fiddling with as.data.frame and matrix your data are
not complient with the function
>From help page 
"a SummarizedExperiment, data frame or matrix for condition 1, with gene IDs
as rownames and sample IDs as column names"

> 
> I have attached my input file along with mail

No (or almost no) attachments allowed. Better using dput for sharing data.

Cheers
Petr

> --
> With Regards,
> *Dr Priyanka Jain (PhD)*,
> Mobile : 9718854136
> 
> 
> 
> 
> 
> --
> With Regards,
> *Dr Priyanka Jain (PhD)*,
> Mobile : 9718854136
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From |@t@z@hn @end|ng |rom gm@||@com  Thu Sep  3 15:54:47 2020
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Thu, 3 Sep 2020 09:54:47 -0400
Subject: [R] Why does a 2 GB RData file exceed my 16GB memory limit when
 reading it in?
In-Reply-To: <CAKSaaF=RskDefRehCW66Shhd-2YVHR6CTRpmnESJH6F6Q_9gow@mail.gmail.com>
References: <CAJgUswJSO43GmChwySCSgXzmivWf85PkVeROgMhKRYsAM8SNuQ@mail.gmail.com>
 <63590920-b88f-2428-650e-4fa54e85e96a@statistik.tu-dortmund.de>
 <CAJgUswLDjKKYm1G-QJKdZB=Rt62GoJraZJF32wukRO2x5x1u9g@mail.gmail.com>
 <CAKSaaF=RskDefRehCW66Shhd-2YVHR6CTRpmnESJH6F6Q_9gow@mail.gmail.com>
Message-ID: <CA+vqiLGnuLbPvfAhaMXCxhhBtyzGuzBYKA7huEd6vrB3WrhY-w@mail.gmail.com>

On Wed, Sep 2, 2020 at 7:22 PM Leandro Marino
<leandromarino at leandromarino.com.br> wrote:
>
> David,
>
> If the ".Rdata" contains more than one object you could (and maybe should
> use) the SOAR package (from Venables). This package helps you to split the
> objects over multiple RData files. It's useful when you have numerous
> medium-large objects in the workspace but doesn't use then at the same
> time.
>
> When use SOAR::Attach(), for instance, it loads the current name of all the
> objects and retain than available in the searchpath but without load then
> to the memory. As you call, they will be loaded into the memory.
>
> If needed, you can update the object and then store it again with the
> SOAR::Store()
>
> For my use, this package is terrific! I use it with an analysis that I need
> to repeat over medium-large similars datasets.
>

The qs package might also be worth a try. I don't have a specific
reason for thinking it will avoid the original problem, but in general
qs uses lots of fancy compression and memory management features.

--Ista

> Best
> Leandro
>
> Em qua., 2 de set. de 2020 ?s 18:33, David Jones <david.tn.jones at gmail.com>
> escreveu:
>
> > Thank you Uwe, John, and Bert - this is very helpful context.
> >
> > If it helps inform the discussion, to address John and Bert's
> > questions - I actually had less memory free when I originally ran the
> > analyses and saved the workspace, than when I read in the data back in
> > later on (I rebooted in an attempt to free all possible memory before
> > rereading the workspace back in).
> >
> >
> >
> > On Wed, Sep 2, 2020 at 1:27 PM John via R-help <r-help using
> > r-project.org> wrote:
> >
> > >> On Wed, 2 Sep 2020 13:36:43 +0200
> > >> Uwe Ligges <ligges using statistik.tu-dortmund.de> wrote:
> > >>
> > >> > On 02.09.2020 04:44, David Jones wrote:
> > >> > > I ran a number of analyses in R and saved the workspace, which
> > >> > > resulted in a 2GB .RData file. When I try to read the file back
> > >> > > into R
> > >> >
> > >> > Compressed in RData but uncompressed in main memory....
> > >> >
> > >> >
> > >> > > later, it won't read into R and provides the error: "Error: cannot
> > >> > > allocate vector of size 37 Kb"
> > >> > >
> > >> > > This error comes after 1 minute of trying to read things in - I
> > >> > > presume a single vector sends it over the memory limit. But,
> > >> > > memory.limit() shows that I have access to a full 16gb of ram on my
> > >> > > machine (12 GB are free when I try to load the RData file).
> > >> >
> > >> > But the data may need more....
> > >> >
> > >> >
> > >> > > gc() shows the following after I receive this error:
> > >> > >
> > >> > > used (Mb) gc trigger (Mb) max used (Mb)
> > >> > > Ncells 623130 33.3 4134347 220.8 5715387 305.3
> > >> > > Vcells 1535682 11.8 883084810 6737.5 2100594002 16026.3
> > >> >
> > >> > So 16GB were used when R gave up.
> > >> >
> > >> > Best,
> > >> > Uwe Ligges
> > >>
> > >> For my own part, looking at the OP's question, it does seem curious
> > >> that R could write that .RData file, but on the same system not be able
> > >> to reload something it created.  How would that work.  Wouldn't the
> > >> memory limit have been exceeded BEFORE the the .RData file was written
> > >> the FIRST time?
> > >>
> > >> JDougherty
> >
> >
> > >R experts may give you a detailed explanation, but it is certainly
> > possible
> > >that the memory available to R when it wrote the file was different than
> > >when it tried to read it, is it not?
> >
> > >Bert Gunter
> >
> > >"The trouble with having an open mind is that people keep coming along and
> > >sticking things into it."
> > >-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Thu Sep  3 19:36:05 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Thu, 3 Sep 2020 13:36:05 -0400
Subject: [R] [R-pkgs] new ivreg package for 2SLS regression with diagnostics
Message-ID: <febda047-9c87-840b-d995-41e58d116021@mcmaster.ca>

Dear list members,

Christian Kleiber, Achim Zeileis, and I would like to announce a new 
CRAN package, ivreg, which provides a comprehensive implementation of 
instrumental variables estimation using two-stage least-squares (2SLS) 
regression.

The standard regression functionality (parameter estimation, inference, 
robust covariances, predictions, etc.) in the package is derived from 
and supersedes the ivreg() function in the AER package. Additionally, 
various regression diagnostics are supported, including hat values, 
deletion diagnostics such as studentized residuals and Cook's distances; 
graphical diagnostics such as component-plus-residual plots and 
added-variable plots; and effect plots with partial residuals. In order 
to provide these features, the ivreg package integrates seamlessly with 
other packages through suitable S3 methods, specifically for generic 
functions in the base-R stats package, and in the car, effects, lmtest, 
and sandwich packages, among others.

The ivreg package is accompanied by two online vignettes: a brief 
general introduction to the package, and an introduction to the 
regression diagnostics and graphics that are provided.

For more information, see the ivreg CRAN webpage at 
<https://cran.r-project.org/package=ivreg> and the ivreg pkgdown webpage 
at <https://john-d-fox.github.io/ivreg/>.

Comments, suggestions, and bug reports would be appreciated.

John

-- 
John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From |e@||e@rutkow@k| @end|ng |rom gm@||@com  Thu Sep  3 19:44:34 2020
From: |e@||e@rutkow@k| @end|ng |rom gm@||@com (Leslie Rutkowski)
Date: Thu, 3 Sep 2020 13:44:34 -0400
Subject: [R] Assigning cores
Message-ID: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>

Hi all,

I'm working on a large simulation and I'm using the doParallel package to
parallelize my work. I have 20 cores on my machine and would like to
preserve some for day-to-day activities - word processing, sending emails,
etc.

I started by saving 1 core and it was clear that *everything* was so slow
as to be nearly unusable.

Any suggestions on how many cores to hold back (e.g., not to put to work on
the parallel process)?

Thanks,
Leslie

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Sep  3 19:51:22 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Thu, 03 Sep 2020 13:51:22 -0400
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <20200903135122.Horde.bOYJpYRDmOAg-IEW0YsOpIA@www.ontargettek.com>

Hi Leslie and all.

You may want to investigate using SparklyR on a cloud environment like  
AWS, where you have more packages that are designed to work on cluster  
computing environments and you have more control over those types of  
parallel operations.


V/r,

Tom W.


Quoting Leslie Rutkowski <leslie.rutkowski at gmail.com>:

> Hi all,
>
> I'm working on a large simulation and I'm using the doParallel package to
> parallelize my work. I have 20 cores on my machine and would like to
> preserve some for day-to-day activities - word processing, sending emails,
> etc.
>
> I started by saving 1 core and it was clear that *everything* was so slow
> as to be nearly unusable.
>
> Any suggestions on how many cores to hold back (e.g., not to put to work on
> the parallel process)?
>
> Thanks,
> Leslie
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r||61 @end|ng |rom w|ndow@||ve@com  Thu Sep  3 20:36:44 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-3?Q?ahmet_varl=B9?=)
Date: Thu, 3 Sep 2020 18:36:44 +0000
Subject: [R] calculating linear regression for each word cell
Message-ID: <VI1PR0302MB31990D2BA95E068E965B7009BB2C0@VI1PR0302MB3199.eurprd03.prod.outlook.com>

Hi all,



I have 71 raster for each year. I am trying to convert all raster layer to 1 array (94 ,192 , 71) and then ? would calculate for each word cell a linear regression that shows the change but i dont know how ? can do this


For creating array with rasters between 1949 and 2019

library(raster)
r<-raster("C:/max_consecutive_days_1949.tif")
a<-array(NA,dim=c(dim(r)[1:2],71))
i <- 1
for (year in 1949:2019) {
  fi<-paste0("C:/ max_consecutive_days_",year,".tif")
  r<-raster(fi)
  a[,,i]<-getValues(r,format="matrix")
            i<-i+1
}

Windows 10 i?in Posta<https://go.microsoft.com/fwlink/?LinkId=550986> ile g?nderildi


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Sep  3 20:58:33 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 03 Sep 2020 11:58:33 -0700
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
References: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <CD816A55-28E8-43CF-AFC7-D0FFA35A4CF7@dcn.davis.ca.us>

Do you have 20 actual cores or 10 cores/20 threads? detectCores() doesn't usually know the difference but the CPU may be too busy accessing memory to let that last thread get any useful work done. I often find that allocating real cores is more practical than thinking in terms of thread so try allocating 9 workers and watch your cpu usage.

Experiment with your settings... the right balance may be dependent on your other activities as well as your hardware, since your analysis may not be completely memory access limited and threads might make (some) sense for you.

On September 3, 2020 10:44:34 AM PDT, Leslie Rutkowski <leslie.rutkowski at gmail.com> wrote:
>Hi all,
>
>I'm working on a large simulation and I'm using the doParallel package
>to
>parallelize my work. I have 20 cores on my machine and would like to
>preserve some for day-to-day activities - word processing, sending
>emails,
>etc.
>
>I started by saving 1 core and it was clear that *everything* was so
>slow
>as to be nearly unusable.
>
>Any suggestions on how many cores to hold back (e.g., not to put to
>work on
>the parallel process)?
>
>Thanks,
>Leslie
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Thu Sep  3 22:32:39 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 3 Sep 2020 22:32:39 +0200
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
References: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <20200903203239.GC1771@posteo.no>

On 2020-09-03 13:44 -0400, Leslie Rutkowski wrote:
> Hi all,
> 
> I'm working on a large simulation and 
> I'm using the doParallel package to 
> parallelize my work. I have 20 cores 
> on my machine and would like to 
> preserve some for day-to-day 
> activities - word processing, sending 
> emails, etc.
> 
> I started by saving 1 core and it was 
> clear that *everything* was so slow as 
> to be nearly unusable.
> 
> Any suggestions on how many cores to 
> hold back (e.g., not to put to work on 
> the parallel process)?

Dear Leslie,

you can also use the core parallel 
package.  See ?parallel::makeCluster and 
?parallel::parSapply.

Here I run the function FUN on the 
vector 1:3 over three threads.  FUN 
needs otherFun, so you can export it to 
the cluster.  Remember to stop the 
cluster in the end.

	cl <- parallel::makeCluster(3)
	FUN <- function(x) {
	  return(otherFun(x^2))
	}
	otherFun <- function(x) {
	  return(x+1)
	}
	parallel::clusterExport(cl, "otherFun")
	parallel::parSapply(
	  cl=cl,
	  X=1:3,
	  FUN=FUN)
	parallel::stopCluster(cl)

You could run e.g. 15 cores or 
something?  parallel::makeCluster(15) 
...

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200903/30aa348d/attachment.sig>

From peter@|@ng|e|der @end|ng |rom gm@||@com  Thu Sep  3 22:56:38 2020
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Thu, 3 Sep 2020 13:56:38 -0700
Subject: [R] Assigning cores
In-Reply-To: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
References: <CAA0F9kWW+SwB_ZZGop+gWHZRgv4BN4KMN8Kzpu+5DE-5=LnxNQ@mail.gmail.com>
Message-ID: <CA+hbrhUdmSqCpGUSHd2UTgV_Kmw+j=DX3Hvn+Yo8Zz47+jtkKg@mail.gmail.com>

The big question is whether each worker or thread uses parallel
processing itself, or whether it uses resources like cache in which
case 20 threads fighting over the cache would slow you down
substantially. If your simulations use operations implemented in BLAS
or LAPACK, be aware that some R installations use custom fast BLAS
that can use multiple cores and the processor cache. You can see some
of it in sessionInfo().

The other issue is memory usage - if you exhaust your physical RAM,
your computer will slow down not so much because of CPU load but
rather because of memory management (swapping to and from disk).

I would run some smaller experimental runs that take just a minute or
two to finish with say 4, 8 and 12 workers and see how fast these go -
you may find no or very little speed up past 8 or perhaps even 4-6
workers.

HTH,

Peter

On Thu, Sep 3, 2020 at 10:45 AM Leslie Rutkowski
<leslie.rutkowski at gmail.com> wrote:
>
> Hi all,
>
> I'm working on a large simulation and I'm using the doParallel package to
> parallelize my work. I have 20 cores on my machine and would like to
> preserve some for day-to-day activities - word processing, sending emails,
> etc.
>
> I started by saving 1 core and it was clear that *everything* was so slow
> as to be nearly unusable.
>
> Any suggestions on how many cores to hold back (e.g., not to put to work on
> the parallel process)?
>
> Thanks,
> Leslie
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Fri Sep  4 01:49:23 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 4 Sep 2020 09:49:23 +1000
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <VI1PR0302MB3199579461E1E56EC70A5BABBB5E0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fX=Msyqq5zB+5jop5YDrEB+gwZAODyNOnT9xchAiRESgA@mail.gmail.com>
 <VI1PR0302MB3199695FD3E2E4340EBA485EBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUAmaGdHsXYwq-yaqvMz_km46j3pJs7TO3N0CZX--pG4Q@mail.gmail.com>
 <CA+8X3fUDzdJ3diRFthS=LzCH6R5wpwaowuBgisYTOETt=vTaQQ@mail.gmail.com>
 <VI1PR0302MB3199E50BAE6DF7AE78178FFCBB490@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fWAexSRCM7mxzv58MTVaQp2rAbeAWtN7Zrd_ffxxXW==g@mail.gmail.com>
 <VI1PR0302MB3199D2DBA9ECD5A24F839B93BB470@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fVHt9MkCzKWvFB3QoeJOxxXkpgTw_omNKXfT1AqqM9QWA@mail.gmail.com>
 <VI1PR0302MB319998C51816A238854844C4BB440@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <CA+8X3fUADTEMxtjJNWs6dvdGvBZCF-7YWwS+XcUAzXOqPhYdXw@mail.gmail.com>
 <VI1PR0302MB3199579461E1E56EC70A5BABBB5E0@VI1PR0302MB3199.eurprd03.prod.outlook.com>
Message-ID: <CA+8X3fU_tM4+Cv79SP6KY5fFPaxUimvXa5fnGCoi-GBgg7gbsA@mail.gmail.com>

Hi Ahmet,
I really can't work out what your problem is. I don't have access to
the data you are using and so cannot inspect "a" to see what might be
in it.

Jim

On Wed, Sep 2, 2020 at 8:54 AM ahmet varl? <varli61 at windowslive.com> wrote:
>
> Hi jim,
>
>
>
> I have a new question. I have 71 years raster data from 1949 to 2019 and ? am trying to convert these 71 yeears raster an array to calculate a liner regration.
>
>
>
>
>
> library(raster)
>
> r<-raster("C:/Teaching/MSCprojects/2020/Ahmet/soilm/max_consecutive_days/max_consecutive_days_1949.tif")
>
> a<-array(NA,dim=c(dim(r)[1:2],70))
>
> i <- 1
>
> for (year in 1949:2019) {
>
>   fi<-paste0("C:/Teaching/MSCprojects/2020/Ahmet/soilm/max_consecutive_days_",year,".tif")
>
>   r<-raster(fi)
>
>   a[,,i]<-getValues(r,format="matrix")
>
>             i<-i+1
>
> }
>
> Best wishes,
>
> Windows 10 i?in Posta ile g?nderildi
>
>
>
> Kimden: Jim Lemon
> G?nderilme: 10 A?ustos 2020 Pazartesi 06:28
> Kime: ahmet varl?
> Konu: Re: [R] find number of consecutive days in NC files by R
>
>
>
> That's right. If you want to get the result for all cells with valid
> readings, step through the cells, texting for valid data. The result
> will be quite large, so I suggest sending the output to a file:
>
> sink("soil_moisture_result.txt")
> for(i in 1:nrows(soil_moist)) {
>  for(j in 1:ncols(soil_moist)) {
>  if(sum(!is.na(soil_moist[i,j,]) > 0) {
>   # process the cell here and print out the result
>  }
> }
> sink()
>
> caution: untested
>
> Jim
>
> On Mon, Aug 10, 2020 at 2:02 PM ahmet varl? <varli61 at windowslive.com> wrote:
> >
> > Hi Jim,
> >
> >
> >
> > I would like to find out how many consecutive days each cell is under the specific value for a certain date range. ?f I am right your code is for just one cell
> >
> >
> >
> >
> >
> > Kimden: Jim Lemon
> > G?nderilme: 10 A?ustos 2020 Pazartesi 04:23
> > Kime: ahmet varl?; r-help mailing list
> > Konu: Re: [R] find number of consecutive days in NC files by R
> >
> >
> >
> > Hi Ahmet,
> > An easy way is this:
> >
> > library(ncdf4)
> > soilm<-nc_open("soilw.0-10cm.gauss.1949.nc")
> > soil_moist<-ncvar_get(soilm)
> > smdim<-dim(soil_moist)
> > # identify NA grid cells
> > sm_NA_count<-matrix(NA,nrow=smdim[1],ncol=smdim[2])
> > for(i in 1:smdim[1]) {
> >  for(j in 1:smdim[2]) {
> >   sm_NA_count[i,j]<-sum(!is.na(soil_moist[i,j,]))
> >  }
> > }
> >
> > The resulting matrix contains the counts of valid (not NA) values in
> > each 365 day series in the array. It looks to me as though there are
> > 5914 complete series and the rest are all NA. This does not tell you
> > why some files (the third dimension) are all NA. Probably the best
> > guess is that the soil moisture content is not measurable for some
> > reason. Here is the explanation from NOAA:
> >
> > Missing Data:
> >
> > There is no missing data though the ocean has 0's. There is a file
> > with the percent of the grid that is land. Another file has simply 1
> > and 0's for land/ocean. Grids where the percent of land is zero are
> > "missing".
> >
> > You can get a feel for the geographic coverage like this (white cells
> > are not NA):
> >
> > library(maps)
> > library(plotrix)
> > color2D.matplot(t(sm_NA_count))
> >
> > Jim
> >
> > On Mon, Aug 10, 2020 at 4:09 AM ahmet varl? <varli61 at windowslive.com> wrote:
> > >
> > > Hi Jim,
> > >
> > >
> > >
> > > Could you help me to remove NA values which are water values ?
> > >
> > >
> > >
> > >
> > >
> > > Kimden: Jim Lemon
> > > G?nderilme: 7 A?ustos 2020 Cuma 22:53
> > > Kime: ahmet varl?
> > > Konu: Re: [R] find number of consecutive days in NC files by R
> > >
> > >
> > >
> > > There are 17848 grid cells in the file I downloaded for 1949. Many of
> > > them only contain NA values, probably because they are from a
> > > geographic grid that is covered by water. In the code there is a
> > > section that prints out a list of the grid cells that contain minimum
> > > values less than 0.3. Since I don't know which grid cell you are
> > > using, I had to find one that would produce interpretable results for
> > > the problem you are trying to solve.
> > >
> > > Jim
> > >
> > > On Fri, Aug 7, 2020 at 11:03 PM ahmet varl? <varli61 at windowslive.com> wrote:
> > > >
> > > > I am greatfull for your helps and ? just want to ask why did you use cell 159,66
> > > >
> > >
> > >
> >
> >
>
>


From @rr@ypro|||e @end|ng |rom y@hoo@com  Fri Sep  4 06:46:58 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Fri, 4 Sep 2020 04:46:58 +0000 (UTC)
Subject: [R] R rounding problem?
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
Message-ID: <1362142831.3113261.1599194818782@mail.yahoo.com>

Hello,

I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.

For exmaple, when I just simply type:

> (6.9-6.3) > 0.6
[1] TRUE

6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!

Similarly, R thinks 5.6-5.5 is smaller than 0.1:

> (5.6-5.5) < 0.1
[1] TRUE

Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.

Can anyone shed a light on how to avoid the issue?

Thanks,

Yi


From jrg @end|ng |rom |oe@|@u@  Fri Sep  4 06:51:34 2020
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Fri, 4 Sep 2020 00:51:34 -0400
Subject: [R] R rounding problem?
In-Reply-To: <1362142831.3113261.1599194818782@mail.yahoo.com>
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
 <1362142831.3113261.1599194818782@mail.yahoo.com>
Message-ID: <dd180af4-703e-dc7f-fb94-8cba54fb98cf@loesl.us>

On 2020-09-04 00:46, array chip via R-help wrote:
> Hello,
>
> I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.
>
> For exmaple, when I just simply type:
>
>> (6.9-6.3) > 0.6
> [1] TRUE
>
> 6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!
>
> Similarly, R thinks 5.6-5.5 is smaller than 0.1:
>
>> (5.6-5.5) < 0.1
> [1] TRUE
>
> Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.
>
> Can anyone shed a light on how to avoid the issue?


Maybe learn a little bit about digital arithmetic?



---JRG




> Thanks,
>
> Yi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Fri Sep  4 07:12:22 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 4 Sep 2020 01:12:22 -0400
Subject: [R] [External]  R rounding problem?
In-Reply-To: <1362142831.3113261.1599194818782@mail.yahoo.com>
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
 <1362142831.3113261.1599194818782@mail.yahoo.com>
Message-ID: <CAGx1TMBEcK6cgchMOVJZfVMRspQuznKWQBXmL68rnAooP=OLWQ@mail.gmail.com>

FAQ 7.31

On Fri, Sep 4, 2020 at 12:47 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.
>
> For exmaple, when I just simply type:
>
> > (6.9-6.3) > 0.6
> [1] TRUE
>
> 6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!
>
> Similarly, R thinks 5.6-5.5 is smaller than 0.1:
>
> > (5.6-5.5) < 0.1
> [1] TRUE
>
> Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.
>
> Can anyone shed a light on how to avoid the issue?
>
> Thanks,
>
> Yi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @rr@ypro|||e @end|ng |rom y@hoo@com  Fri Sep  4 07:38:34 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Fri, 4 Sep 2020 05:38:34 +0000 (UTC)
Subject: [R] [External]  R rounding problem?
In-Reply-To: <CAGx1TMBEcK6cgchMOVJZfVMRspQuznKWQBXmL68rnAooP=OLWQ@mail.gmail.com>
References: <1362142831.3113261.1599194818782.ref@mail.yahoo.com>
 <1362142831.3113261.1599194818782@mail.yahoo.com>
 <CAGx1TMBEcK6cgchMOVJZfVMRspQuznKWQBXmL68rnAooP=OLWQ@mail.gmail.com>
Message-ID: <775217190.119177.1599197914138@mail.yahoo.com>

Thanks Richard. Got it now...


On Thursday, September 3, 2020, 10:12:36 PM PDT, Richard M. Heiberger <rmh at temple.edu> wrote: 


FAQ 7.31

On Fri, Sep 4, 2020 at 12:47 AM array chip via R-help
<r-help at r-project.org> wrote:
>
> Hello,
>
> I made a mistake today on simple counting in R, that almost got me into trouble. After trying multiple times, I finally figured out it's rounding issue in R.
>
> For exmaple, when I just simply type:
>
> > (6.9-6.3) > 0.6
> [1] TRUE
>
> 6.9-6.3 should be 0.6 exactly, but R thinks that it's greater than 0.6!!
>
> Similarly, R thinks 5.6-5.5 is smaller than 0.1:
>
> > (5.6-5.5) < 0.1
> [1] TRUE
>
> Why is the above happening? This rounding issue seems to be small, but this could cause serious problem in real world.
>
> Can anyone shed a light on how to avoid the issue?
>
> Thanks,
>
> Yi

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Sep  4 09:19:11 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 4 Sep 2020 09:19:11 +0200
Subject: [R] find number of consecutive days in NC files by R
In-Reply-To: <9DC09EF7-2E8A-42C5-AE2C-6F9DB9FC9D4D@dcn.davis.ca.us>
References: <VI1PR0302MB319971243B2465E3AF2FE44BBB480@VI1PR0302MB3199.eurprd03.prod.outlook.com>
 <9DC09EF7-2E8A-42C5-AE2C-6F9DB9FC9D4D@dcn.davis.ca.us>
Message-ID: <24401.60015.368054.501096@stat.math.ethz.ch>

>>>>> Jeff Newmiller 
>>>>>     on Thu, 06 Aug 2020 10:49:50 -0700 writes:

    > You need to make a small fake dataset that illustrates
    > what you have and what you want out of it. Telling us you
    > are not getting what you want is simply not useful.  

Indeed.

In addition:  Do *not* use  suppressWarnings( . ) lightly !

Warnings are there for a good reason, and you should think hard
and may be ask for help before "blindly" using
suppressWarnings().

Whoever told you to do that routinely
has not been a good teacher of R ..

Best regards,

Martin Maechler
ETH Zurich  and  R Core team

    > On August 6, 2020 8:58:09 AM PDT, "ahmet varl?"
    > <varli61 at windowslive.com> wrote:
    >> Hi all,
    >> 
    >> 
    >> There are 365 days of soil moisture NC files and I am
    >> trying to find out how many days the values are below and
    >> above this certain threshold are repeated by R. However,
    >> I couldn't reach exactly what I wanted. For example,
    >> Daily soil moisture is below 0.3 without interrupting how
    >> many days in 365 days. NC file contains annual soil
    >> moisture values daily
    >> 
    >> nctoarray <- function(ncfname, varid = NA) { nc <-
    >> nc_open(ncfname)
    >> 
    >> a <- aperm(ncvar_get(nc), c(2,1,3)) nc_close(nc) a }
    >> 
    >> 
    >> 
    >> function(x, threshold = 0.28, below = TRUE) {
    >> 
    >> if (below) {
    >> 
    >> y <- ifelse(x < threshold,1,0)
    >> 
    >> } else y <- ifelse(x > threshold,1,0)
    >> 
    >> 
    >> 
    >> y2 <- rle(y)
    >> 
    >> sel <- which(y2$values == 1)
    >> 
    >> max(y2$lengths[sel])
    >> 
    >> }
    >> 
    >> 
    >> 
    >> m1 <- suppressWarnings(apply(a,c(1,2), consechours, 0.3,
    >> TRUE))
    >> 
    >> 
    >> 
    >> m2 <- suppressWarnings(apply(a,c(1,2), consechours, 0.4,
    >> FALSE))
    >> 
    >> 
    >> 
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > -- 
    > Sent from my phone. Please excuse my brevity.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From m|eher1971 @end|ng |rom gm@||@com  Fri Sep  4 03:26:21 2020
From: m|eher1971 @end|ng |rom gm@||@com (Michael Feher)
Date: Thu, 3 Sep 2020 21:26:21 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
Message-ID: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>

Greetings,

I am a brand-new user to R and want to install and run this on my iMac running macOS 10.15.6.  I successfully downloaded the correct package, installed it with no problems (I was not given any options for Tcl/Tk or Texinfo), and started it up as any other normal app.  Some introductory commands like license() and help() worked just fine.  But when I went to execute demo(), it just beach-balled.  I?ve had to force-quit R a number of times.

Yes, I read the Mac installation instructions.

Thanks in advance.

Mike

From m@rc_@chw@rtz @end|ng |rom me@com  Fri Sep  4 14:05:37 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 4 Sep 2020 08:05:37 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
In-Reply-To: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
References: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
Message-ID: <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>


> On Sep 3, 2020, at 9:26 PM, Michael Feher <mfeher1971 at gmail.com> wrote:
> 
> Greetings,
> 
> I am a brand-new user to R and want to install and run this on my iMac running macOS 10.15.6.  I successfully downloaded the correct package, installed it with no problems (I was not given any options for Tcl/Tk or Texinfo), and started it up as any other normal app.  Some introductory commands like license() and help() worked just fine.  But when I went to execute demo(), it just beach-balled.  I?ve had to force-quit R a number of times.
> 
> Yes, I read the Mac installation instructions.
> 
> Thanks in advance.
> 
> Mike


Hi,

Sounds like you need to install XQuartz:

  https://www.xquartz.org

which is referenced in the macOS installation instructions and the macOS specific FAQ.

Also, be aware that there is a macOS specific e-mail list here:

  https://stat.ethz.ch/mailman/listinfo/r-sig-mac

which is where macOS specific R issues should be posted.

You will need to re-install XQuartz any time you upgrade/install a new version of R.

Regards,

Marc Schwartz


From c@|um@po|w@rt @end|ng |rom nh@@net  Fri Sep  4 17:45:57 2020
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST))
Date: Fri, 4 Sep 2020 15:45:57 +0000
Subject: [R] Survival Object - is 12month survival = 365days
Message-ID: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>

Using survfit I can get the '1 year' Survival from this dataset which holds survival in days:

require (survival)
survfit( Surv(time, status) ~sex, data=colon)
summary (fit, 365)

My current real world data I'm calculating time using lubridate to calculate time and since it made the axis easy I just told it to do and so my "time" appears to be  a float in months.

time <- time_length(interval(startDate, endDate), "months")

Is there a "right" approach to this (as in a convention). If I use 12months as a year and describe it in the write up as 12, 24 and 36 month survival rather than 1, 2 and 3 year presumably that is OK..

I've been asked to report 30, 60 & 90day. Then 6month, 1, 2 and 3 year survival.

Should I calculate time 3 times, (interval day, month and year) and run the survival on each to get the requested outputs or would people just provide something close.

Should I run a campaign to decimilise time?






Sent from Nine<http://www.9folders.com/>


********************************************************************************************************************

This message may contain confidential information. If you are not the intended recipient please inform the
sender that you have received the message in error before deleting it.
Please do not disclose, copy or distribute information in this e-mail or take any action in relation to its contents. To do so is strictly prohibited and may be unlawful. Thank you for your co-operation.

NHSmail is the secure email and directory service available for all NHS staff in England and Scotland. NHSmail is approved for exchanging patient data and other sensitive information with NHSmail and other accredited email services.

For more information and to find out how you can switch, https://portal.nhs.net/help/joiningnhsmail


	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Sep  4 18:27:07 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 4 Sep 2020 12:27:07 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
In-Reply-To: <CAN5WjXKM0cw73O53LAmyzOeTBCdj+SzFKN_+Xw98SaSEgxw-5Q@mail.gmail.com>
References: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
 <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>
 <CAN5WjXKM0cw73O53LAmyzOeTBCdj+SzFKN_+Xw98SaSEgxw-5Q@mail.gmail.com>
Message-ID: <19C1EF5A-0C67-4973-9121-013915E27ABA@me.com>

Hi Mike,

The installation interface has a minimal process, where what may be optional components are left to you to install on your own. Thus, the Installation and Admin manual references these, as does the macOS FAQ, but the wording may leave open to interpretation what may or may not be required, based upon your specific use case. In some use cases, XQuartz would not be required and you need to go to a third party site to obtain it, much like you would need to for MacTeX or similar.

With respect to the lists, each R list is moderated by a volunteer, thus will require a subscription in order to get your posts sent out without manual intervention by the list admins/moderators. For example, I am one of the two Admins for R-Devel, along with Martin M?chler, thus spend some amount of time having to manually approve posts where the poster is not, and does not become a subscriber.

Once you subscribe, and your first post is approved, subsequent posts can get through without manual intervention, which is appreciated.

If you do not want to keep getting posts from the lists, once your issue is resolved, you can return to the list interface, sign into your account, and disable getting the posts. Of course, if you need to interact again in the future, you would need to remember to re-enable the posts being sent, as responses to posts do not always include you as a cc:.

Digests are available, but can be more complicated to interact with, in some cases, depending upon your e-mail client, if you should want to reply to a specific post. You can set this in your account settings for the relevant list if you wish.

One option for you to consider, is that I have server side filters/rules set up for the R lists (and others) that I subscribe to. These then move each e-mail from my main inbox to the relevant online (IMAP) sub-folder for organization. Thus, it keeps my inbox clean and let's me review relevant posts in a more efficient and focused manner.

Regards,

Marc


> On Sep 4, 2020, at 11:43 AM, Mike Feher <mfeher1971 at gmail.com> wrote:
> 
> Good morning Marc,
> 
> Thank you kindly for your quick response.  I had read prior to installation that I might have needed or wanted to install some different packages to support R, but did not catch that XQuartz was a requirement.  (I also never got prompted for various options during the installation of R-4.0.2.pkg.)
> 
> Regarding email lists, perhaps you can assist with this question: While I don't mind becoming a registered member, I prefer not to get email traffic from groups as I have in the past (I actually really hate email for a lot of reasons these days), so I'm wondering, is there a way to get a digest (I thought I saw that) of just a weekly summary of information or questions posted, rather than getting CC:d on every back-and-forth within the user community?  Also, do I have to become an approved user to the R mailing list community or anything like that?  Or are all posts moderated?
> 
> Now that the weekend is upon me, I'll have some time to come up to speed on all this.  Thanks for your patience.
> 
> Thanks again!
> Mike
> 
> On Fri, Sep 4, 2020 at 8:05 AM Marc Schwartz <marc_schwartz at me.com> wrote:
> 
> > On Sep 3, 2020, at 9:26 PM, Michael Feher <mfeher1971 at gmail.com> wrote:
> > 
> > Greetings,
> > 
> > I am a brand-new user to R and want to install and run this on my iMac running macOS 10.15.6.  I successfully downloaded the correct package, installed it with no problems (I was not given any options for Tcl/Tk or Texinfo), and started it up as any other normal app.  Some introductory commands like license() and help() worked just fine.  But when I went to execute demo(), it just beach-balled.  I?ve had to force-quit R a number of times.
> > 
> > Yes, I read the Mac installation instructions.
> > 
> > Thanks in advance.
> > 
> > Mike
> 
> 
> Hi,
> 
> Sounds like you need to install XQuartz:
> 
>   https://www.xquartz.org
> 
> which is referenced in the macOS installation instructions and the macOS specific FAQ.
> 
> Also, be aware that there is a macOS specific e-mail list here:
> 
>   https://stat.ethz.ch/mailman/listinfo/r-sig-mac
> 
> which is where macOS specific R issues should be posted.
> 
> You will need to re-install XQuartz any time you upgrade/install a new version of R.
> 
> Regards,
> 
> Marc Schwartz
> 


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Sep  4 19:32:25 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 4 Sep 2020 13:32:25 -0400
Subject: [R] Survival Object - is 12month survival = 365days
In-Reply-To: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>
References: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>
Message-ID: <E79E13DA-C473-4FC2-B9F5-5378C172EE16@me.com>

On Sep 4, 2020, at 11:45 AM, POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
> 
> Using survfit I can get the '1 year' Survival from this dataset which holds survival in days:
> 
> require (survival)
> survfit( Surv(time, status) ~sex, data=colon)
> summary (fit, 365)
> 
> My current real world data I'm calculating time using lubridate to calculate time and since it made the axis easy I just told it to do and so my "time" appears to be  a float in months.
> 
> time <- time_length(interval(startDate, endDate), "months")
> 
> Is there a "right" approach to this (as in a convention). If I use 12months as a year and describe it in the write up as 12, 24 and 36 month survival rather than 1, 2 and 3 year presumably that is OK..
> 
> I've been asked to report 30, 60 & 90day. Then 6month, 1, 2 and 3 year survival.
> 
> Should I calculate time 3 times, (interval day, month and year) and run the survival on each to get the requested outputs or would people just provide something close.
> 
> Should I run a campaign to decimilise time?

Hi,

The answer may depend upon whether you are presenting the results in a tabular fashion, in the body of a manuscript, or in a figure. Also, what may be the community conventions in your domain. 

If you want to get the irregular time points out in a single output, you can use the times argument to do this, remembering that the default time intervals are in days for this dataset:

> summary(fit, times = c(30, 60, 90, 180, 365.25, 2 * 365.25, 3 * 365.25))
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    887       2    0.998 0.00159        0.995        1.000
   60    880       6    0.991 0.00317        0.985        0.997
   90    869      11    0.979 0.00485        0.969        0.988
  180    827      42    0.931 0.00849        0.915        0.948
  365    731      94    0.825 0.01274        0.801        0.851
  730    595     135    0.673 0.01576        0.643        0.705
 1096    536      57    0.608 0.01641        0.577        0.641

                sex=1 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    962       5    0.995 0.00230        0.990        0.999
   60    955       6    0.989 0.00341        0.982        0.995
   90    947       8    0.980 0.00446        0.972        0.989
  180    906      41    0.938 0.00776        0.923        0.953
  365    819      85    0.850 0.01150        0.828        0.873
  730    679     133    0.711 0.01462        0.683        0.740
 1096    592      84    0.623 0.01566        0.593        0.654


Now, the time output there is arguably a bit cumbersome to read...but, at least you get the relevant values in a single output. You can transform those values as you may require.

Another option is to use the scale argument, but I just noted that, unless I am missing something, I think that there may be a lingering buglet in the code for summary.survfit(), and I am adding Terry Therneau here as a cc:, if that is correct. The behavior of the interaction between the times and scale arguments changed in 2009 after an exchange I had with Thomas Lumley: 

  https://stat.ethz.ch/pipermail/r-devel/2009-April/052901.html

and it is not clear to me if the current behavior is or is not intended after all this time. Albeit, it may be the defacto behavior at this point in either case, given some volume of code written over the years that may depend upon this behavior.

Thus, this may be better for you, using the current behavior:

> summary(fit, scale = 30.44, times = c(1, 2, 3, 6, 12, 24, 36) * 30.44)
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    887       2    0.998 0.00159        0.995        1.000
    2    880       6    0.991 0.00317        0.985        0.997
    3    868      12    0.977 0.00498        0.968        0.987
    6    826      42    0.930 0.00855        0.914        0.947
   12    731      93    0.825 0.01274        0.801        0.851
   24    595     135    0.673 0.01576        0.643        0.705
   36    536      57    0.608 0.01641        0.577        0.641

                sex=1 
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    962       5    0.995 0.00230        0.990        0.999
    2    955       6    0.989 0.00341        0.982        0.995
    3    946       9    0.979 0.00458        0.970        0.988
    6    906      40    0.938 0.00776        0.923        0.953
   12    819      85    0.850 0.01150        0.828        0.873
   24    679     133    0.711 0.01462        0.683        0.740
   36    592      84    0.623 0.01566        0.593        0.654


where the times values are now in months over the range of values, instead of days.

I don't use the lubridate package, so there may be other options for you there, but the above will work, if your underlying time intervals in the source data frame for the model are still in days as a unit of measurement. 

Using the base graphics functions, albeit perhaps you are using ggplot or similar, you can plot the above model with axis markings at the irregular time intervals, using something like the following:

plot(fit, xaxt = "n", las = 1, xlim = c(0, 36 * 30.44))
axis(1, at = c(1, 2, 3, 6, 12, 24, 36) * 30.44, labels = c(1, 2, 3, 6, 12, 24, 36), cex.axis = 0.65)

This essentially truncates the x axis to 36 months, since the intervals in the example colon dataset go to about 9 years or so, and does not label the x axis. Bearing in mind that the underlying x axis unit is in days, the axis() function then places labels at the irregular intervals. You could then annotate the plot further as you may desire.

Regards,

Marc Schwartz


From c@|um@po|w@rt @end|ng |rom nh@@net  Fri Sep  4 19:43:08 2020
From: c@|um@po|w@rt @end|ng |rom nh@@net (POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST))
Date: Fri, 4 Sep 2020 17:43:08 +0000
Subject: [R] Survival Object - is 12month survival = 365days
In-Reply-To: <E79E13DA-C473-4FC2-B9F5-5378C172EE16@me.com>
References: <ff0a24c9-c000-4e6d-9dd9-ecfd2dac13be@nhs.net>,
 <E79E13DA-C473-4FC2-B9F5-5378C172EE16@me.com>
Message-ID: <f7f51d78-19a5-46c4-999f-3b1a9b2cac4a@nhs.net>

Hi Mark

Huge thanks for the detailed answer.

At the moment, likely to be a mix of tabulation (30, 60, 90), a plot and some narrative with the 6mo, 12mo and so on. I think!

So it sounds like days is the answer, and then estimate months and years from days.

Sent from Nine<http://www.9folders.com/>
________________________________
From: Marc Schwartz <marc_schwartz at me.com>
Sent: Friday, 4 September 2020 18:32
To: POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST)
Cc: R-help; Terry Therneau
Subject: Re: [R] Survival Object - is 12month survival = 365days

On Sep 4, 2020, at 11:45 AM, POLWART, Calum (SOUTH TEES HOSPITALS NHS FOUNDATION TRUST) via R-help <r-help at r-project.org> wrote:
>
> Using survfit I can get the '1 year' Survival from this dataset which holds survival in days:
>
> require (survival)
> survfit( Surv(time, status) ~sex, data=colon)
> summary (fit, 365)
>
> My current real world data I'm calculating time using lubridate to calculate time and since it made the axis easy I just told it to do and so my "time" appears to be  a float in months.
>
> time <- time_length(interval(startDate, endDate), "months")
>
> Is there a "right" approach to this (as in a convention). If I use 12months as a year and describe it in the write up as 12, 24 and 36 month survival rather than 1, 2 and 3 year presumably that is OK..
>
> I've been asked to report 30, 60 & 90day. Then 6month, 1, 2 and 3 year survival.
>
> Should I calculate time 3 times, (interval day, month and year) and run the survival on each to get the requested outputs or would people just provide something close.
>
> Should I run a campaign to decimilise time?

Hi,

The answer may depend upon whether you are presenting the results in a tabular fashion, in the body of a manuscript, or in a figure. Also, what may be the community conventions in your domain.

If you want to get the irregular time points out in a single output, you can use the times argument to do this, remembering that the default time intervals are in days for this dataset:

> summary(fit, times = c(30, 60, 90, 180, 365.25, 2 * 365.25, 3 * 365.25))
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    887       2    0.998 0.00159        0.995        1.000
   60    880       6    0.991 0.00317        0.985        0.997
   90    869      11    0.979 0.00485        0.969        0.988
  180    827      42    0.931 0.00849        0.915        0.948
  365    731      94    0.825 0.01274        0.801        0.851
  730    595     135    0.673 0.01576        0.643        0.705
 1096    536      57    0.608 0.01641        0.577        0.641

                sex=1
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
   30    962       5    0.995 0.00230        0.990        0.999
   60    955       6    0.989 0.00341        0.982        0.995
   90    947       8    0.980 0.00446        0.972        0.989
  180    906      41    0.938 0.00776        0.923        0.953
  365    819      85    0.850 0.01150        0.828        0.873
  730    679     133    0.711 0.01462        0.683        0.740
 1096    592      84    0.623 0.01566        0.593        0.654


Now, the time output there is arguably a bit cumbersome to read...but, at least you get the relevant values in a single output. You can transform those values as you may require.

Another option is to use the scale argument, but I just noted that, unless I am missing something, I think that there may be a lingering buglet in the code for summary.survfit(), and I am adding Terry Therneau here as a cc:, if that is correct. The behavior of the interaction between the times and scale arguments changed in 2009 after an exchange I had with Thomas Lumley:

  https://stat.ethz.ch/pipermail/r-devel/2009-April/052901.html

and it is not clear to me if the current behavior is or is not intended after all this time. Albeit, it may be the defacto behavior at this point in either case, given some volume of code written over the years that may depend upon this behavior.

Thus, this may be better for you, using the current behavior:

> summary(fit, scale = 30.44, times = c(1, 2, 3, 6, 12, 24, 36) * 30.44)
Call: survfit(formula = Surv(time, status) ~ sex, data = colon)

                sex=0
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    887       2    0.998 0.00159        0.995        1.000
    2    880       6    0.991 0.00317        0.985        0.997
    3    868      12    0.977 0.00498        0.968        0.987
    6    826      42    0.930 0.00855        0.914        0.947
   12    731      93    0.825 0.01274        0.801        0.851
   24    595     135    0.673 0.01576        0.643        0.705
   36    536      57    0.608 0.01641        0.577        0.641

                sex=1
 time n.risk n.event survival std.err lower 95% CI upper 95% CI
    1    962       5    0.995 0.00230        0.990        0.999
    2    955       6    0.989 0.00341        0.982        0.995
    3    946       9    0.979 0.00458        0.970        0.988
    6    906      40    0.938 0.00776        0.923        0.953
   12    819      85    0.850 0.01150        0.828        0.873
   24    679     133    0.711 0.01462        0.683        0.740
   36    592      84    0.623 0.01566        0.593        0.654


where the times values are now in months over the range of values, instead of days.

I don't use the lubridate package, so there may be other options for you there, but the above will work, if your underlying time intervals in the source data frame for the model are still in days as a unit of measurement.

Using the base graphics functions, albeit perhaps you are using ggplot or similar, you can plot the above model with axis markings at the irregular time intervals, using something like the following:

plot(fit, xaxt = "n", las = 1, xlim = c(0, 36 * 30.44))
axis(1, at = c(1, 2, 3, 6, 12, 24, 36) * 30.44, labels = c(1, 2, 3, 6, 12, 24, 36), cex.axis = 0.65)

This essentially truncates the x axis to 36 months, since the intervals in the example colon dataset go to about 9 years or so, and does not label the x axis. Bearing in mind that the underlying x axis unit is in days, the axis() function then places labels at the irregular intervals. You could then annotate the plot further as you may desire.

Regards,

Marc Schwartz



********************************************************************************************************************

This message may contain confidential information. If yo...{{dropped:19}}


From m|eher1971 @end|ng |rom gm@||@com  Fri Sep  4 17:43:11 2020
From: m|eher1971 @end|ng |rom gm@||@com (Mike Feher)
Date: Fri, 4 Sep 2020 11:43:11 -0400
Subject: [R] R 4.0.2 not running on macOS 10.15.6
In-Reply-To: <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>
References: <702ECB1C-900D-422F-A597-86ED53E456EC@gmail.com>
 <2E156B79-2ABC-40E4-BC6F-FAE6D1D93B46@me.com>
Message-ID: <CAN5WjXKM0cw73O53LAmyzOeTBCdj+SzFKN_+Xw98SaSEgxw-5Q@mail.gmail.com>

Good morning Marc,

Thank you kindly for your quick response.  I had read prior to installation
that I might have needed or wanted to install some different packages to
support R, but did not catch that XQuartz was a requirement.  (I also never
got prompted for various options during the installation of R-4.0.2.pkg.)

Regarding email lists, perhaps you can assist with this question: While I
don't mind becoming a registered member, I prefer not to get email traffic
from groups as I have in the past (I actually really hate email for a lot
of reasons these days), so I'm wondering, is there a way to get a digest (I
thought I saw that) of just a weekly summary of information or questions
posted, rather than getting CC:d on every back-and-forth within the user
community?  Also, do I have to become an approved user to the R mailing
list community or anything like that?  Or are all posts moderated?

Now that the weekend is upon me, I'll have some time to come up to speed on
all this.  Thanks for your patience.

Thanks again!
Mike

On Fri, Sep 4, 2020 at 8:05 AM Marc Schwartz <marc_schwartz at me.com> wrote:

>
> > On Sep 3, 2020, at 9:26 PM, Michael Feher <mfeher1971 at gmail.com> wrote:
> >
> > Greetings,
> >
> > I am a brand-new user to R and want to install and run this on my iMac
> running macOS 10.15.6.  I successfully downloaded the correct package,
> installed it with no problems (I was not given any options for Tcl/Tk or
> Texinfo), and started it up as any other normal app.  Some introductory
> commands like license() and help() worked just fine.  But when I went to
> execute demo(), it just beach-balled.  I?ve had to force-quit R a number of
> times.
> >
> > Yes, I read the Mac installation instructions.
> >
> > Thanks in advance.
> >
> > Mike
>
>
> Hi,
>
> Sounds like you need to install XQuartz:
>
>   https://www.xquartz.org
>
> which is referenced in the macOS installation instructions and the macOS
> specific FAQ.
>
> Also, be aware that there is a macOS specific e-mail list here:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
> which is where macOS specific R issues should be posted.
>
> You will need to re-install XQuartz any time you upgrade/install a new
> version of R.
>
> Regards,
>
> Marc Schwartz
>
>

	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Sat Sep  5 00:32:05 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Fri, 4 Sep 2020 15:32:05 -0700
Subject: [R] NOAA .grb2 files
Message-ID: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>

I?m trying to download NOAA Rapid Refresh model weather data but I keep getting the error message below.  Do I just need a computer with more memory?

Philip

***********************************************************************************************************************************************
Error in paste(gsub("\"", "", csv.str), collapse = ",") : 
  could not allocate memory (994 Mb) in C function 'R_AllocStringBuffer' 
	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Sat Sep  5 00:36:05 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Fri, 4 Sep 2020 15:36:05 -0700
Subject: [R] NOAA .grp2 files
Message-ID: <5194862CE4014B22B985DF996E8CD216@OWNERPC>

Neglected to mention in the previous email that I?m using the rNOMADS package and the FReadGrib function.

Philip
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  5 00:47:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 4 Sep 2020 15:47:33 -0700
Subject: [R] NOAA .grp2 files
In-Reply-To: <5194862CE4014B22B985DF996E8CD216@OWNERPC>
References: <5194862CE4014B22B985DF996E8CD216@OWNERPC>
Message-ID: <CAGxFJbQaj0GmrX02dnNJZwG1xzgjvg2OP2q062gGs=9UQO+PwQ@mail.gmail.com>

If you don't get an answer here, try posting on the r-sig-geo list, where
folks with the expertise you seek are more likely to hang out.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Sep 4, 2020 at 3:44 PM Philip <herd_dog at cox.net> wrote:

> Neglected to mention in the previous email that I?m using the rNOMADS
> package and the FReadGrib function.
>
> Philip
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sat Sep  5 00:49:01 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Fri, 4 Sep 2020 15:49:01 -0700 (PDT)
Subject: [R] NOAA .grb2 files
In-Reply-To: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
References: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
Message-ID: <alpine.LNX.2.20.2009041548380.7473@salmo.appl-ecosys.com>

On Fri, 4 Sep 2020, Philip wrote:

> I?m trying to download NOAA Rapid Refresh model weather data but I keep
> getting the error message below. Do I just need a computer with more
> memory?

Philip,

And how much available memory do you have on that host?

Rich


From roy@mende|@@ohn @end|ng |rom no@@@gov  Sat Sep  5 01:11:04 2020
From: roy@mende|@@ohn @end|ng |rom no@@@gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 4 Sep 2020 16:11:04 -0700
Subject: [R] NOAA .grb2 files
In-Reply-To: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
References: <A9FA3D1A358F43D9A3AAC16BC7C18EC2@OWNERPC>
Message-ID: <26424FD6-CE0C-41F0-9337-4B463BF7F025@noaa.gov>

Hi Philip:

It would help if you gave the complete script you are trying to run,  and the name of the file.  

for those unfamiliar with all this,  Philip has already downloaded the grib2 file,  either using rNOMADS or directly from the NOAA website,  and the function he is calling reads the data from that grib2 file by wrapping a system call to a C-program called wgrib2.  And if you don't know about grib2 files,  they are highly compressed files of fields,  using bit-packing to do the compression. Forecast grib2 files usually have a plethora of fields,  for example since I don't know exactly which  NOAA Rapid Refresh model files he obtain,  looking at the inventory of one possible such file,  see:

https://www.nco.ncep.noaa.gov/pmb/products/rap/rap.t00z.awp252pgrbf00.grib2.shtml

Usually given this,  only one or a couple of fields at a time are unpacked,  unless you have a large computer.  Since no example script was given,  it is impossible to tell if he is trying to read in the entire grib2 file or what.  And each expanded array in R will be much much bigger than the equivalent in grib2.

-Roy



> On Sep 4, 2020, at 3:32 PM, Philip <herd_dog at cox.net> wrote:
> 
> I?m trying to download NOAA Rapid Refresh model weather data but I keep getting the error message below.  Do I just need a computer with more memory?
> 
> Philip
> 
> ***********************************************************************************************************************************************
> Error in paste(gsub("\"", "", csv.str), collapse = ",") : 
>  could not allocate memory (994 Mb) in C function 'R_AllocStringBuffer' 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new street address***
110 McAllister Way
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: https://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From v|vek@utr@ @end|ng |rom gm@||@com  Sat Sep  5 20:18:07 2020
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Sat, 5 Sep 2020 20:18:07 +0200
Subject: [R] fusion of two matrices (numerical and logical)
Message-ID: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>

Hi
I would like to get help in combining two matrices. Here is my example:
A <- 1:20
B <- matrix(A,nrow=5,ncol=4)
# B is a numerical matrix
C <- B<7
C[4,4] <- TRUE
# C is a logical matrix
# if I combine A and C, I get a vector
D1 <- A[C==TRUE]
D1
D2 <- A[C==FALSE]
D2

I want to get a matrix with the same dimensions as matrix A. At the
coordinates given by the vector D1, I want to retain the values in
matrix A. At the locations in D2, I want a zero value.
I want to know if I can do this without using any loops.
Thanks, Vivek

	[[alternative HTML version deleted]]


From v|vek@utr@ @end|ng |rom gm@||@com  Sat Sep  5 20:41:01 2020
From: v|vek@utr@ @end|ng |rom gm@||@com (Vivek Sutradhara)
Date: Sat, 5 Sep 2020 20:41:01 +0200
Subject: [R] fusion of two matrices (numerical and logical)
In-Reply-To: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
References: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
Message-ID: <CAHLp6SD-+A2ip967q0noxF=2Ga_77ebMzRZTPyRLzR3FauvsPQ@mail.gmail.com>

The result that I want to get is this:
for (i in 1:5) {
  for (j in 1:4) {
    B[i,j] <- ifelse(C[i,j]==FALSE,0,B[i,j])
  }
}
I would like to know if I can do this without loops.

Den l?r 5 sep. 2020 kl 20:18 skrev Vivek Sutradhara <viveksutra at gmail.com>:

> Hi
> I would like to get help in combining two matrices. Here is my example:
> A <- 1:20
> B <- matrix(A,nrow=5,ncol=4)
> # B is a numerical matrix
> C <- B<7
> C[4,4] <- TRUE
> # C is a logical matrix
> # if I combine A and C, I get a vector
> D1 <- A[C==TRUE]
> D1
> D2 <- A[C==FALSE]
> D2
>
> I want to get a matrix with the same dimensions as matrix A. At the
> coordinates given by the vector D1, I want to retain the values in
> matrix A. At the locations in D2, I want a zero value.
> I want to know if I can do this without using any loops.
> Thanks, Vivek
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Sep  5 20:51:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 5 Sep 2020 11:51:26 -0700
Subject: [R] fusion of two matrices (numerical and logical)
In-Reply-To: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
References: <CAHLp6SAWgxJvBJdXb03ZU-XaTxp+NUO31oB=iO2X7j=y4oNcbw@mail.gmail.com>
Message-ID: <CAGxFJbSKvodBk1kvP5DQmdFN+kNihgKOr_szPYRykMQaoPABwA@mail.gmail.com>

A is not a matrix. I presume you meant B. If so:

> B[!C] <- 0
> B
     [,1] [,2] [,3] [,4]
[1,]    1    6    0    0
[2,]    2    0    0    0
[3,]    3    0    0    0
[4,]    4    0    0   19
[5,]    5    0    0    0

Cheers,
Bert





On Sat, Sep 5, 2020 at 11:18 AM Vivek Sutradhara <viveksutra at gmail.com>
wrote:

> Hi
> I would like to get help in combining two matrices. Here is my example:
> A <- 1:20
> B <- matrix(A,nrow=5,ncol=4)
> # B is a numerical matrix
> C <- B<7
> C[4,4] <- TRUE
> # C is a logical matrix
> # if I combine A and C, I get a vector
> D1 <- A[C==TRUE]
> D1
> D2 <- A[C==FALSE]
> D2
>
> I want to get a matrix with the same dimensions as matrix A. At the
> coordinates given by the vector D1, I want to retain the values in
> matrix A. At the locations in D2, I want a zero value.
> I want to know if I can do this without using any loops.
> Thanks, Vivek
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 01:44:03 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sat, 5 Sep 2020 16:44:03 -0700 (PDT)
Subject: [R] dataRetrieval query error
Message-ID: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>

I'm learning the dataRetrieval package. Following the example in Section
1.1.2 of the vignette (whatNWISdata) I prepared this script:
------
library("dataRetrieval")

siteNumbers <- c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")

dataAvailable <- whatNWISdata(siteNumbers, service="all", parameterCD="all", statCD="all")
-----

The vignette says that for service, parameterCD, and statCD the default is
"all", but the package wants that explicitly. So that's what I did. Yet, my
syntax is still off:

> source("R-scripts/get-site-data-list.R") 
Error: All components of query must be named

Please show me what I'm missing.

Rich


From bgunter@4567 @end|ng |rom gm@||@com  Sun Sep  6 02:14:23 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 5 Sep 2020 17:14:23 -0700
Subject: [R] dataRetrieval query error
In-Reply-To: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
Message-ID: <CAGxFJbSWx5M4Gf-Mu5uVkm6x6VkxOBoACb02yDUCOC=z3gZgvQ@mail.gmail.com>

You failed to name the first parameter, siteNumbers?


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Sep 5, 2020 at 4:44 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> I'm learning the dataRetrieval package. Following the example in Section
> 1.1.2 of the vignette (whatNWISdata) I prepared this script:
> ------
> library("dataRetrieval")
>
> siteNumbers <-
> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")
>
> dataAvailable <- whatNWISdata(siteNumbers, service="all",
> parameterCD="all", statCD="all")
> -----
>
> The vignette says that for service, parameterCD, and statCD the default is
> "all", but the package wants that explicitly. So that's what I did. Yet, my
> syntax is still off:
>
> > source("R-scripts/get-site-data-list.R")
> Error: All components of query must be named
>
> Please show me what I'm missing.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Sep  6 02:20:58 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 5 Sep 2020 17:20:58 -0700
Subject: [R] dataRetrieval query error
In-Reply-To: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
Message-ID: <13dc0272-b354-93dd-09da-b060a85c1826@comcast.net>

This worked:


 > dataAvailable <- whatNWISdata(siteNumber=siteNumbers)
 > str(dataAvailable)
'data.frame':??? 2565 obs. of? 24 variables:
 ?$ agency_cd???????? : chr? "USGS" "USGS" "USGS" "USGS" ...
 ?$ site_no?????????? : chr? "14207920" "14208000" "14208000" "14208000" ...
 ?$ station_nm??????? : chr? "POOP CREEK NEAR BIG BOTTOM, OR" "CLACKAMAS 
RIVER AT BIG BOTTOM, OREG." "CLACKAMAS RIVER AT BIG BOTTOM, OREG." 
"CLACKAMAS RIVER AT BIG BOTTOM, OREG." ...
 ?$ site_tp_cd??????? : chr? "ST" "ST" "ST" "ST" ...
 ?$ dec_lat_va??????? : num? 45 45 45 45 44.9 ...
 ?$ dec_long_va?????? : num? -122 -122 -122 -122 -122 ...
 ?$ coord_acy_cd????? : chr? "U" "U" "U" "U" ...
 ?$ dec_coord_datum_cd: chr? "NAD83" "NAD83" "NAD83" "NAD83" ...
 ?$ alt_va??????????? : chr? " 2760.00" " 2040.00" " 2040.00" " 2040.00" ...
 ?$ alt_acy_va??????? : chr? " 20" " 20" " 20" " 20" ...
 ?$ alt_datum_cd????? : chr? "NGVD29" "NGVD29" "NGVD29" "NGVD29" ...
 ?$ huc_cd??????????? : chr? "17090011" "17090011" "17090011" "17090011" ...
 ?$ data_type_cd????? : chr? "pk" "dv" "pk" "sv" ...
 ?$ parm_cd?????????? : chr? NA "00060" NA NA ...
 ?$ stat_cd?????????? : chr? NA "00003" NA NA ...
 ?$ ts_id???????????? : num? 0 114288 0 0 0 ...
 ?$ loc_web_ds??????? : chr? NA NA NA NA ...
 ?$ medium_grp_cd???? : chr? "wat" "wat" "wat" "wat" ...
 ?$ parm_grp_cd?????? : chr? NA NA NA NA ...
 ?$ srs_id??????????? : num? 0 1645423 0 0 0 ...
 ?$ access_cd???????? : num? 0 0 0 0 0 0 0 0 0 0 ...
 ?$ begin_date??????? : Date, format: "1966-05-05" "1920-04-01" 
"1921-01-03" ...
 ?$ end_date????????? : Date, format: "1983-01-06" "1970-09-29" 
"1970-01-23" ...
 ?$ count_nu????????? : num? 17 18444 50 26 10 ...
 ?- attr(*, "comment")= chr? "#" "#" "# US Geological Survey" "# 
retrieved: 2020-09-05 20:18:46 -04:00\t(caas01)" ...
 ?- attr(*, "queryTime")= POSIXct, format: "2020-09-05 17:18:46"
 ?- attr(*, "url")= chr 
"https://waterservices.usgs.gov/nwis/site/?seriesCatalogOutput=true&sites=14207920,14208000,14208200,14208300,14"| 
__truncated__
 ?- attr(*, "header")=List of 12
 ? ..$ date?????????????????????? : chr "Sun, 06 Sep 2020 00:18:45 GMT"
 ? ..$ server???????????????????? : chr "Apache-Coyote/1.1"
 ? ..$ strict-transport-security? : chr "max-age=31536000"
 ? ..$ vary?????????????????????? : chr "Accept-Encoding"
 ? ..$ content-encoding?????????? : chr "gzip"
 ? ..$ content-type?????????????? : chr "text/plain;charset=UTF-8"
 ? ..$ cache-control????????????? : chr "max-age=900"
 ? ..$ expires??????????????????? : chr "Sun, 06 Sep 2020 00:33:46 GMT"
 ? ..$ x-ua-compatible??????????? : chr "IE=edge,chrome=1"
 ? ..$ access-control-allow-origin: chr "*"
 ? ..$ x-frame-options??????????? : chr "deny"
 ? ..$ transfer-encoding????????? : chr "chunked"
 ? ..- attr(*, "class")= chr? "insensitive" "list"


--

David.


On 9/5/20 4:44 PM, Rich Shepard wrote:

> I'm learning the dataRetrieval package. Following the example in Section
> 1.1.2 of the vignette (whatNWISdata) I prepared this script:
> ------
> library("dataRetrieval")
>
> siteNumbers <- 
> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")
>
> dataAvailable <- whatNWISdata(siteNumbers, service="all", 
> parameterCD="all", statCD="all")
> -----
>
> The vignette says that for service, parameterCD, and statCD the 
> default is
> "all", but the package wants that explicitly. So that's what I did. 
> Yet, my
> syntax is still off:
>
>> source("R-scripts/get-site-data-list.R") 
> Error: All components of query must be named
>
> Please show me what I'm missing.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sun Sep  6 04:06:27 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sat, 5 Sep 2020 19:06:27 -0700
Subject: [R] dataRetrieval query error
In-Reply-To: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
Message-ID: <CAHqSRuSKOVZcokFcNcNMqSks4wtxtmrc6MCn2R-FqsH9GanthA@mail.gmail.com>

Name all your arguments (the vignette gets this wrong), including
siteNumber=siteNumbers.

Also, the vignette uses 'statCd', not 'statCD'.

dataAvailable <- whatNWISdata(siteNumber=siteNumbers, service="all",
statCd="all")

gives some results.

-Bill

On Sat, Sep 5, 2020 at 4:44 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> I'm learning the dataRetrieval package. Following the example in Section
> 1.1.2 of the vignette (whatNWISdata) I prepared this script:
> ------
> library("dataRetrieval")
>
> siteNumbers <-
> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")
>
> dataAvailable <- whatNWISdata(siteNumbers, service="all",
> parameterCD="all", statCD="all")
> -----
>
> The vignette says that for service, parameterCD, and statCD the default is
> "all", but the package wants that explicitly. So that's what I did. Yet, my
> syntax is still off:
>
> > source("R-scripts/get-site-data-list.R")
> Error: All components of query must be named
>
> Please show me what I'm missing.
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From he@h@m|bb @end|ng |rom y@hoo@com  Sun Sep  6 11:58:21 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Sun, 6 Sep 2020 09:58:21 +0000 (UTC)
Subject: [R] truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[,
 1]=="G2" & truth[, 2]=="G3"), 3]<-1
References: <1445305015.747995.1599386302002.ref@mail.yahoo.com>
Message-ID: <1445305015.747995.1599386302002@mail.yahoo.com>

helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
?If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1?# note G1 and G2 are values from 1 to 2000?#if this happend add to thrid column in truth 1 otherwise add 0 as in statment follow
truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?
truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.
this the distination result:
I want this result
G1 G2? G3?D? ? B? ? 1?B? ?D? ? ?1?A? ? D? ? 0?B? ? A? ? 1B? ? C? ? 0A ? B? ? 1


	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Sep  6 13:04:34 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 6 Sep 2020 12:04:34 +0100
Subject: [R] truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[,
 1]=="G2" & truth[, 2]=="G3"), 3]<-1
In-Reply-To: <1445305015.747995.1599386302002@mail.yahoo.com>
References: <1445305015.747995.1599386302002.ref@mail.yahoo.com>
 <1445305015.747995.1599386302002@mail.yahoo.com>
Message-ID: <517607e5-72ba-23f3-e49e-bbe35a73ff64@dewey.myzen.co.uk>

I am afraid this is completely unreadable because you posted in HTML ad 
this is a plain text list. Best to resend it having set your mailer to 
send plain text as HTML gets mangled here.

Michael

On 06/09/2020 10:58, Hesham A. AL-bukhaiti via R-help wrote:
> helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
>  ?If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1?# note G1 and G2 are values from 1 to 2000?#if this happend add to thrid column in truth 1 otherwise add 0 as in statment follow
> truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000
> truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.
> this the distination result:
> I want this result
> G1 G2? G3?D? ? B? ? 1?B? ?D? ? ?1?A? ? D? ? 0?B? ? A? ? 1B? ? C? ? 0A ? B? ? 1
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 14:45:36 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 05:45:36 -0700 (PDT)
Subject: [R] dataRetrieval query error
In-Reply-To: <CAGxFJbSWx5M4Gf-Mu5uVkm6x6VkxOBoACb02yDUCOC=z3gZgvQ@mail.gmail.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
 <CAGxFJbSWx5M4Gf-Mu5uVkm6x6VkxOBoACb02yDUCOC=z3gZgvQ@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2009060542470.1648@salmo.appl-ecosys.com>

On Sat, 5 Sep 2020, Bert Gunter wrote:

> You failed to name the first parameter, siteNumbers?

Bert,

>> siteNumbers <-
>> c("14207920","14208000","14208200","14208300","14208500","14208600","14208700","14208850","14209000","14209100","14209250","14209500","14209600","14209670","14209700","14209710","14209750","14209775","14209790","14209900","14210000","14210005","14210020","14210025","14210030","14210100","14210150","14210152","14210160","14210200","14210255","14210400","14210480","14210490","14210500","14210530","14210535","14210600","14210650","14210676","14210750","14210760","14210765","14210800","14210830","14210850","14210900","14211000","14211004","14211005","14211006","14211008","14211010","14211023","14211494")

This is where I defined that vector; the MUA split it into two lines. The
vector's name is the same as in the vignette example

>> dataAvailable <- whatNWISdata(siteNumbers, service="all", parameterCD="all", statCD="all")

Have I not specified the list of site numbers properly here?

Thanks,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 14:48:10 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 05:48:10 -0700 (PDT)
Subject: [R] dataRetrieval query error [RESOLVED]
In-Reply-To: <13dc0272-b354-93dd-09da-b060a85c1826@comcast.net>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
 <13dc0272-b354-93dd-09da-b060a85c1826@comcast.net>
Message-ID: <alpine.LNX.2.20.2009060546090.1648@salmo.appl-ecosys.com>

On Sat, 5 Sep 2020, David Winsemius wrote:

> This worked:
>> dataAvailable <- whatNWISdata(siteNumber=siteNumbers)

David/Bert,

Mea culpa! The vignette example used a single siteNumber which is also the
variable name and I missed that last point.

Thank you very much.

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 14:56:10 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 05:56:10 -0700 (PDT)
Subject: [R] dataRetrieval query error
In-Reply-To: <CAHqSRuSKOVZcokFcNcNMqSks4wtxtmrc6MCn2R-FqsH9GanthA@mail.gmail.com>
References: <alpine.LNX.2.20.2009051634360.25030@salmo.appl-ecosys.com>
 <CAHqSRuSKOVZcokFcNcNMqSks4wtxtmrc6MCn2R-FqsH9GanthA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2009060553190.1648@salmo.appl-ecosys.com>

On Sat, 5 Sep 2020, Bill Dunlap wrote:

> Name all your arguments (the vignette gets this wrong), including
> siteNumber=siteNumbers.
> Also, the vignette uses 'statCd', not 'statCD'.

Bill,

Thanks very much. I missed these.

> dataAvailable <- whatNWISdata(siteNumber=siteNumbers, service="all",
> statCd="all")
> gives some results.

Much appreciated,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Sun Sep  6 21:27:54 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 12:27:54 -0700 (PDT)
Subject: [R] dataRetrieval: whatNWISdata() return value type
Message-ID: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>

The dataRetrieval package PDF has a list of values returned by
whatNWISdata(). One value returned when I run this function is not on the
list and my searches of USGS web sites doesn't find it. The value's name is
"ts_id". A pointer to where that's defined is needed.

Regards,

Rich


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Sep  7 00:02:40 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 6 Sep 2020 15:02:40 -0700
Subject: [R] dataRetrieval: whatNWISdata() return value type
In-Reply-To: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>
References: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>
Message-ID: <CAHqSRuSYCqPUu9xPTtf_7+QWzgbqLPw=Q+U_MDyyxyZt_eJN-g@mail.gmail.com>

https://help.waterdata.usgs.gov/codes-and-parameters/codes


   - *Time series identifier* - A 5-6 digit number (ts_id) which uniquely
   identifies a series of data for one parameter at one location at a
   continuous-recording data site. The ts_id is used by the database for
   selecting data for download or display as a list, table, or graph and may
   change over time as new database tables are created.


On Sun, Sep 6, 2020 at 12:28 PM Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> The dataRetrieval package PDF has a list of values returned by
> whatNWISdata(). One value returned when I run this function is not on the
> list and my searches of USGS web sites doesn't find it. The value's name is
> "ts_id". A pointer to where that's defined is needed.
>
> Regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Sep  7 00:36:42 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Sun, 6 Sep 2020 15:36:42 -0700 (PDT)
Subject: [R] dataRetrieval: whatNWISdata() return value type
In-Reply-To: <CAHqSRuSYCqPUu9xPTtf_7+QWzgbqLPw=Q+U_MDyyxyZt_eJN-g@mail.gmail.com>
References: <alpine.LNX.2.20.2009061223000.1648@salmo.appl-ecosys.com>
 <CAHqSRuSYCqPUu9xPTtf_7+QWzgbqLPw=Q+U_MDyyxyZt_eJN-g@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2009061531400.1648@salmo.appl-ecosys.com>

On Sun, 6 Sep 2020, Bill Dunlap wrote:

> https://help.waterdata.usgs.gov/codes-and-parameters/codes
>
>   - *Time series identifier* - A 5-6 digit number (ts_id) which uniquely
>   identifies a series of data for one parameter at one location at a
>   continuous-recording data site. The ts_id is used by the database for
>   selecting data for download or display as a list, table, or graph and may
>   change over time as new database tables are created.

Bill,

I found many lists of parameters none included this one. Thank you again.

Rich


From he@h@m|bb @end|ng |rom y@hoo@com  Mon Sep  7 05:48:32 2020
From: he@h@m|bb @end|ng |rom y@hoo@com (Hesham A. AL-bukhaiti)
Date: Mon, 7 Sep 2020 03:48:32 +0000 (UTC)
Subject: [R] (i want change G3 and G2 to variable tke all elements in rows)
 (truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[, 1]=="G2" & truth[,
 2]=="G3"), 3]<-1
References: <523701431.950619.1599450512634.ref@mail.yahoo.com>
Message-ID: <523701431.950619.1599450512634@mail.yahoo.com>

helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
?If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1?# note G1 and G2 are values from 1 to 2000?#if this happend add to thrid column in truth 1 otherwise add 0 as in statment follow
truth<-cbind(as.character(truth[,1]),as.character(truth[,2])? ? ? ? ? ? ?,as.data.frame(rep(0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all values from G1 to G2000?
truth[(truth[,1]=="G3" & truth[,2]=="G2") | (truth[,1]=="G2" & truth[,2]=="G3"),3]<-1?###############################3(Simply they regulate the other. If element A is in the first group , and it is related to element B in the second group , and element B also in? in the first group , and it is related to element A(the same element? in the first group)? in the second group , we write 1 and otherwise 0.
this the distination result:
I want this result
G1 G2? G3?D? ? B? ? 1?B? ?D? ? ?1?A? ? D? ? 0?B? ? A? ? 1B? ? C? ? 0A ? B? ? 1

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Sep  7 08:43:37 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 7 Sep 2020 06:43:37 +0000
Subject: [R] 
 (i want change G3 and G2 to variable tke all elements in rows)
 (truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[, 1]=="G2" & truth[,
 2]=="G3"), 3]<-1
In-Reply-To: <523701431.950619.1599450512634@mail.yahoo.com>
References: <523701431.950619.1599450512634.ref@mail.yahoo.com>
 <523701431.950619.1599450512634@mail.yahoo.com>
Message-ID: <ab1b0e09e31c4f85ab920059fef089d6@SRVEXCHCM1302.precheza.cz>

Hi

You still fail to send your message in plain text, so it is unreadable.

If I managed to decipher it correctly what you wanted you probably could set 2 
related logical expression and considering that FALSE is 0 and TRUE is 1 you 
get desired result.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Hesham A. AL-
> bukhaiti via R-help
> Sent: Monday, September 7, 2020 5:49 AM
> To: r-help at r-project.org
> Subject: [R] (i want change G3 and G2 to variable tke all elements in rows)
> (truth[(truth[, 1]=="G3" & truth[, 2]=="G2") | (truth[, 1]=="G2" & truth[,
> 2]=="G3"), 3]<-1
>
> helloout<-read.csv("outbr.csv")truth<-out[,seq(1,2)]for example :
>  If row1= G1 and row2=G2 , and row 1 = G2 and row 2= G1,make G3=1 # note
> G1 and G2 are values from 1 to 2000 #if this happend add to thrid column in
> truth 1 otherwise add 0 as in statment follow
> truth<-
> cbind(as.character(truth[,1]),as.character(truth[,2]) 
> ,as.data.frame(rep(
> 0,,dim(out)[1])));#here just G2 and G3, i want make loop to cam[are all 
> values
> from G1 to G2000 truth[(truth[,1]=="G3" & truth[,2]=="G2") | 
> (truth[,1]=="G2"
> & truth[,2]=="G3"),3]<-1 ###############################3(Simply they
> regulate the other. If element A is in the first group , and it is related 
> to
> element B in the second group , and element B also in  in the first group , 
> and
> it is related to element A(the same element  in the first group)  in the 
> second
> group , we write 1 and otherwise 0.
> this the distination result:
> I want this result
> G1 G2  G3 D    B    1 B   D     1 A    D    0 B    A    1B    C    0A   B 
> 1
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Sep  7 11:17:36 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 7 Sep 2020 11:17:36 +0200
Subject: [R] How to run Hutcheson t-test on R?
Message-ID: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>

Hello,
is it possible to run the Hutcheson t-test
(https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
on R? How?

-- 
Best regards,
Luigi


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Sep  8 00:17:15 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 8 Sep 2020 10:17:15 +1200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
Message-ID: <20200908101715.0dfab483@rolf-Latitude-E7470>


On Mon, 7 Sep 2020 11:17:36 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Hello,
> is it possible to run the Hutcheson t-test
> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
> on R?

Almost surely.  With R, all things are possible. :-)

> How?

Program it up?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Tue Sep  8 01:17:52 2020
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Mon, 7 Sep 2020 19:17:52 -0400
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <20200908101715.0dfab483@rolf-Latitude-E7470>
References: <20200908101715.0dfab483@rolf-Latitude-E7470>
Message-ID: <9B799156-1CC0-4AEC-BE5E-86A9CAF4F898@comcast.net>

This website has an example calculation shown in Excel Which might help in programming it in R.

https://www.dataanalytics.org.uk/comparing-diversity/


Bernard
Sent from my iPhone so please excuse the spelling!"

> On Sep 7, 2020, at 6:17 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> ?
>> On Mon, 7 Sep 2020 11:17:36 +0200
>> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> 
>> Hello,
>> is it possible to run the Hutcheson t-test
>> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
>> on R?
> 
> Almost surely.  With R, all things are possible. :-)
> 
>> How?
> 
> Program it up?
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Sep  8 01:23:00 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 7 Sep 2020 16:23:00 -0700
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <20200908101715.0dfab483@rolf-Latitude-E7470>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <20200908101715.0dfab483@rolf-Latitude-E7470>
Message-ID: <a6a7ed5f-1d32-d2f6-127d-9b24ae080e62@comcast.net>


On 9/7/20 3:17 PM, Rolf Turner wrote:
> On Mon, 7 Sep 2020 11:17:36 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
>> Hello,
>> is it possible to run the Hutcheson t-test
>> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244)
>> on R?
> Almost surely.  With R, all things are possible. :-)
>
>> How?
> Program it up?


To Luigi;


Citing a 50 year-old paper that sits behind a paywall seems a bit 
ineffective in getting coding support.

Seems this might be a more appropriate question on the R-SIG-ecology or 
R-SIG-phylo mailing lists. (It would also have been appropriate to 
indicate what sort of searching has been done. My efforts at searching 
led me to the vegan package and this tutorial: 
https://cran.r-project.org/web/packages/vegan/vignettes/diversity-vegan.pdf 
. It doesn't appear to have a Hutcheson t-test, but I'm guessing that is 
because there are more modern and more sophisticated tests currently in 
use.)


See: https://www.r-project.org/mail.html

-- 

David

>
> cheers,
>
> Rolf Turner
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Sep  8 07:06:49 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 8 Sep 2020 07:06:49 +0200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <a6a7ed5f-1d32-d2f6-127d-9b24ae080e62@comcast.net>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <20200908101715.0dfab483@rolf-Latitude-E7470>
 <a6a7ed5f-1d32-d2f6-127d-9b24ae080e62@comcast.net>
Message-ID: <CAMk+s2QWkrQG1EB1maHWzV-52WchRDNK-rDfJqFadYG9THTuJg@mail.gmail.com>

I cited that paper to show what test I was referring to, I was hoping it
was already coded...
Thanks, I will look into vegan
Best regards

On Tue, 8 Sep 2020, 01:23 David Winsemius, <dwinsemius at comcast.net> wrote:

>
> On 9/7/20 3:17 PM, Rolf Turner wrote:
> > On Mon, 7 Sep 2020 11:17:36 +0200
> > Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> >> Hello,
> >> is it possible to run the Hutcheson t-test
> >> (https://www.sciencedirect.com/science/article/abs/pii/0022519370901244
> )
> >> on R?
> > Almost surely.  With R, all things are possible. :-)
> >
> >> How?
> > Program it up?
>
>
> To Luigi;
>
>
> Citing a 50 year-old paper that sits behind a paywall seems a bit
> ineffective in getting coding support.
>
> Seems this might be a more appropriate question on the R-SIG-ecology or
> R-SIG-phylo mailing lists. (It would also have been appropriate to
> indicate what sort of searching has been done. My efforts at searching
> led me to the vegan package and this tutorial:
> https://cran.r-project.org/web/packages/vegan/vignettes/diversity-vegan.pdf
> . It doesn't appear to have a Hutcheson t-test, but I'm guessing that is
> because there are more modern and more sophisticated tests currently in
> use.)
>
>
> See: https://www.r-project.org/mail.html
>
> --
>
> David
>
> >
> > cheers,
> >
> > Rolf Turner
> >
>

	[[alternative HTML version deleted]]


From bobby@kn|ght @end|ng |rom gm@||@com  Tue Sep  8 05:51:10 2020
From: bobby@kn|ght @end|ng |rom gm@||@com (Robert Knight)
Date: Mon, 7 Sep 2020 22:51:10 -0500
Subject: [R] Some R code works on Linux,
 but not Linux via Windows Subsystem Linux
Message-ID: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>

RE: Some R code works on Linux, but not Linux via Windows Subsystem Linux

This is taking data from a CSV and placing it into a data frame.  This is R
3.6.3 inside Windows Subsystem for Linux v2, Ubuntu 18.04.   The exact same
code, unchanged and on the same computer, works correctly in Ubuntu 18.04
and other Linux systems directly if the computer is dual booted into one of
those rather than Windows.

    Error in FUN(X[[i]], ?) :
      only defined on a data frame with all numeric variables
    Calls: Summary.data.frame -> lapply -> FUN

Any idea why the FUN function would error on Windows Subsytem for Linux,
but not Linux itself?  Any insight into the basic mechanism of how that
could vary between systems?  Haven't yet checked to see if the data is even
getting imported via WSL.  The script runs using Rscript as opposed to
running interactively via the R console.

Robert D. Knight, MBA

Developer of Meal Plan and Grocery List maker for Android and iOS.
https://play.google.com/store/apps/details?id=io.robertknight.MPGL
https://itunes.apple.com/us/app/meal-plan-and-grocery-list/id1452755707

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Sep  8 12:56:36 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 8 Sep 2020 13:56:36 +0300
Subject: [R] Some R code works on Linux,
 but not Linux via Windows Subsystem Linux
In-Reply-To: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
References: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
Message-ID: <CAGgJW74wHreiiRMfrPeSTB4-OaFjnb_xJsMwpOY1G5xWqa9TNw@mail.gmail.com>

Hi Robert,
You don't provide a self-contained reproducible example, so I am just
guessing here.
I doubt your theory that the error is related to R. More likely the step
that creates a data frame from reading
the CSV is probably resulting in different data frames in the two cases. I
recommend that you compare the
data frames. (And, if they differ, it might be related to filenames,
directory structures, assumptions about these, etc.)
Another possibility is that you have R 4.* somewhere and there is, in fact,
a difference between R 3.* and R4.*
in terms of creating a data frame from a CSV file.

If my "guesses" are not correct, see if you can create a self-contained
reproducible example
(that does not depend on reading in the CSV. You can just provide the
contents of the data frame via dput().)
Then post the example to the list.

HTH,
Eric


On Tue, Sep 8, 2020 at 1:47 PM Robert Knight <bobby.knight at gmail.com> wrote:

> RE: Some R code works on Linux, but not Linux via Windows Subsystem Linux
>
> This is taking data from a CSV and placing it into a data frame.  This is R
> 3.6.3 inside Windows Subsystem for Linux v2, Ubuntu 18.04.   The exact same
> code, unchanged and on the same computer, works correctly in Ubuntu 18.04
> and other Linux systems directly if the computer is dual booted into one of
> those rather than Windows.
>
>     Error in FUN(X[[i]], ?) :
>       only defined on a data frame with all numeric variables
>     Calls: Summary.data.frame -> lapply -> FUN
>
> Any idea why the FUN function would error on Windows Subsytem for Linux,
> but not Linux itself?  Any insight into the basic mechanism of how that
> could vary between systems?  Haven't yet checked to see if the data is even
> getting imported via WSL.  The script runs using Rscript as opposed to
> running interactively via the R console.
>
> Robert D. Knight, MBA
>
> Developer of Meal Plan and Grocery List maker for Android and iOS.
> https://play.google.com/store/apps/details?id=io.robertknight.MPGL
> https://itunes.apple.com/us/app/meal-plan-and-grocery-list/id1452755707
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tom@@@k@||ber@ @end|ng |rom gm@||@com  Tue Sep  8 13:01:53 2020
From: tom@@@k@||ber@ @end|ng |rom gm@||@com (Tomas Kalibera)
Date: Tue, 8 Sep 2020 13:01:53 +0200
Subject: [R] Some R code works on Linux,
 but not Linux via Windows Subsystem Linux
In-Reply-To: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
References: <CAKBFG3aCkTfic3iCom4cqj_7-56mvfKGMwAHm7i7CCcK=P0SqQ@mail.gmail.com>
Message-ID: <ed3dd221-1cd0-c484-dddc-a99f39a59201@gmail.com>

On 9/8/20 5:51 AM, Robert Knight wrote:
> RE: Some R code works on Linux, but not Linux via Windows Subsystem Linux
>
> This is taking data from a CSV and placing it into a data frame.  This is R
> 3.6.3 inside Windows Subsystem for Linux v2, Ubuntu 18.04.   The exact same
> code, unchanged and on the same computer, works correctly in Ubuntu 18.04
> and other Linux systems directly if the computer is dual booted into one of
> those rather than Windows.
>
>      Error in FUN(X[[i]], ?) :
>        only defined on a data frame with all numeric variables
>      Calls: Summary.data.frame -> lapply -> FUN
>
> Any idea why the FUN function would error on Windows Subsytem for Linux,
> but not Linux itself?  Any insight into the basic mechanism of how that
> could vary between systems?  Haven't yet checked to see if the data is even
> getting imported via WSL.  The script runs using Rscript as opposed to
> running interactively via the R console.

Yes, I think you should just try importing the data (reading the CSV), 
this is probably where things break. Then try also with a small trivial 
variant of that CSV, ensuring it only has ASCII characters, as a sanity 
check. So in other words, creating a minimal reproducible example. This 
can be an encoding issue, for instance.

Tomas

>
> Robert D. Knight, MBA
>
> Developer of Meal Plan and Grocery List maker for Android and iOS.
> https://play.google.com/store/apps/details?id=io.robertknight.MPGL
> https://itunes.apple.com/us/app/meal-plan-and-grocery-list/id1452755707
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Tue Sep  8 13:35:35 2020
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Tue, 8 Sep 2020 13:35:35 +0200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
Message-ID: <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>

Could it be that the test you are looking for is implemented in the 
vegan package (function diversity(... index = "shannon" ...), and/or the 
BiodiversityR package, function "diversityresult (..., index = 
"Shannon",...)

best,
Karl Schilling


From nev||@@mo@ @end|ng |rom gm@||@com  Tue Sep  8 13:37:44 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Tue, 8 Sep 2020 21:37:44 +1000
Subject: [R] Return filematrix column by column names instead of column
 index?
Message-ID: <CAN9eD7=-gO1xa9-vqenOjNJMzRCfDJEuAM53PtUrhE4aEoyGmQ@mail.gmail.com>

Is there a way to get columns out of a filematrix using the column name
directly in the same way that  you can with a regular matrix?

library(filematrix)
M<-t(matrix(1:3,3,4))
colnames(M)<-c("one","two", "three")
M
#Extract column
M[,1]
M[,"one"]
M[,c(1,3)]
M[,c("one","three")]
FM<-fm.create.from.matrix(filenamebase = "test",mat = M)
FM[,1]
colnames(FM)
#extract by column by name does not work
FM[,"one"]

#workaround using grep
#is there a more direct way of doing this  to retrieve more than one column?
FM[,grep("one",colnames(FM))]

FM[,c(grep("one",colnames(FM)),grep("three",colnames(FM)))]

many thanks for any suggestions

Nevil Amos

	[[alternative HTML version deleted]]


From pgokoo| @end|ng |rom gm@||@com  Tue Sep  8 14:05:18 2020
From: pgokoo| @end|ng |rom gm@||@com (pgokool)
Date: Tue, 8 Sep 2020 08:05:18 -0400
Subject: [R] Spatio-Temporal Modelling
Message-ID: <CAE+vJJ-cx9JzYmTYV3OZzYQBG50masMfMEJOgq_Tn9uB3mHU_w@mail.gmail.com>

I have a data set of rainfall from 12 weather stations over 10 years. I
would like to model it using a Spatio-Temporal model in R.

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Sep  8 16:25:56 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 8 Sep 2020 07:25:56 -0700
Subject: [R] Spatio-Temporal Modelling
In-Reply-To: <CAE+vJJ-cx9JzYmTYV3OZzYQBG50masMfMEJOgq_Tn9uB3mHU_w@mail.gmail.com>
References: <CAE+vJJ-cx9JzYmTYV3OZzYQBG50masMfMEJOgq_Tn9uB3mHU_w@mail.gmail.com>
Message-ID: <CAGxFJbSn5EkTq3Fi7TDw6FMUYdPqLcyoUq9cVZGUATbD701q9Q@mail.gmail.com>

https://cran.r-project.org/web/views/SpatioTemporal.html


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Sep 8, 2020 at 7:15 AM pgokool <pgokool at gmail.com> wrote:

> I have a data set of rainfall from 12 weather stations over 10 years. I
> would like to model it using a Spatio-Temporal model in R.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Sep  8 16:55:14 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 8 Sep 2020 15:55:14 +0100
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>
Message-ID: <88ef05c2-dda5-7e9e-e8f0-cb7f168cb7ad@sapo.pt>

Hello,

No, it's not. That's the Shannon diversity index, the test the OP is 
looking for is a t-test for Shannon diversity index equality. The index 
itself is easy to code. A very simple example, based on ?vegan::diversity:


library(vegan)

data(BCI)
H <- diversity(BCI[1,])    # just first row

divers <- function(n){
   p <- n/sum(n)
   log_p <- numeric(length(n))
   log_p[n != 0] <- log(p[n != 0])
   -sum(p * log_p)
}
HRui <- divers(BCI[1,])

identical(H, HRui)
#[1] TRUE


The vegan function is more general, it applies this and other indices 
calculations to a matrix or array.

The t-test doesn't seem difficult to code.
The variance formula in the paper and in the OP's posted link [1] are 
not the same, the original has one more term, but the degrees of freedom 
formula are the same. It all seems straightforward coding.

Luigi: Maybe later today I will have time but I am not making promises.


[1] https://www.dataanalytics.org.uk/comparing-diversity/


Hope this helps,

Rui Barradas


?s 12:35 de 08/09/20, Karl Schilling escreveu:
> Could it be that the test you are looking for is implemented in the 
> vegan package (function diversity(... index = "shannon" ...), and/or the 
> BiodiversityR package, function "diversityresult (..., index = 
> "Shannon",...)
> 
> best,
> Karl Schilling
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Tue Sep  8 20:01:55 2020
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Tue, 8 Sep 2020 20:01:55 +0200
Subject: [R] How to run Hutcheson t-test on R?
In-Reply-To: <88ef05c2-dda5-7e9e-e8f0-cb7f168cb7ad@sapo.pt>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <c1c3409f-9e49-3101-0325-b2f56dac56be@uni-bonn.de>
 <88ef05c2-dda5-7e9e-e8f0-cb7f168cb7ad@sapo.pt>
Message-ID: <b3b12e54-0ce8-f9c4-e665-1555d8577834@uni-bonn.de>

Maybe the following is a solution:

# load package needed
# QSutils is on Bioconductor
library(QSutils)

# here some exemplary data - these are the data from Pilou 1966 that are 
used
# in the second example of Hutcheson, J theor Biol 129:151-154 (1970)

earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)

# here starts the code ; you may replace the variables "earlier" and "later"
# by your own numbers.

# calculate h, var(h) etc
h1 <- Shannon(earlier)
varh1 <- ShannonVar(earlier)
n1 <- sum (earlier)
h2 <- Shannon(later)
varh2 <- ShannonVar(later)
n2 <- sum (later)
degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)

# compare numbers with those in the paper
h1
h2
varh1
varh2

Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess 
that explains the minor numerical differences obtained with the code 
above and the published variances.

# this is the actual t-test
t <- (h1-h2) /sqrt(varh1 + varh2)
p <- 2*pt(-abs(t),df= degfree)
p

that's it
Best
Karl




On 08.09.2020 16:55, Rui Barradas wrote:
> Hello,
> 
> No, it's not. That's the Shannon diversity index, the test the OP is 
> looking for is a t-test for Shannon diversity index equality. The index 
> itself is easy to code. A very simple example, based on ?vegan::diversity:
> 
> 
> library(vegan)
> 
> data(BCI)
> H <- diversity(BCI[1,])??? # just first row
> 
> divers <- function(n){
>  ? p <- n/sum(n)
>  ? log_p <- numeric(length(n))
>  ? log_p[n != 0] <- log(p[n != 0])
>  ? -sum(p * log_p)
> }
> HRui <- divers(BCI[1,])
> 
> identical(H, HRui)
> #[1] TRUE
> 
> 
> The vegan function is more general, it applies this and other indices 
> calculations to a matrix or array.
> 
> The t-test doesn't seem difficult to code.
> The variance formula in the paper and in the OP's posted link [1] are 
> not the same, the original has one more term, but the degrees of freedom 
> formula are the same. It all seems straightforward coding.
> 
> Luigi: Maybe later today I will have time but I am not making promises.
> 
> 
> [1] https://www.dataanalytics.org.uk/comparing-diversity/
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 12:35 de 08/09/20, Karl Schilling escreveu:
>> Could it be that the test you are looking for is implemented in the 
>> vegan package (function diversity(... index = "shannon" ...), and/or 
>> the BiodiversityR package, function "diversityresult (..., index = 
>> "Shannon",...)
>>
>> best,
>> Karl Schilling


From drj|m|emon @end|ng |rom gm@||@com  Wed Sep  9 02:00:10 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 9 Sep 2020 10:00:10 +1000
Subject: [R] Return filematrix column by column names instead of column
 index?
In-Reply-To: <CAN9eD7=-gO1xa9-vqenOjNJMzRCfDJEuAM53PtUrhE4aEoyGmQ@mail.gmail.com>
References: <CAN9eD7=-gO1xa9-vqenOjNJMzRCfDJEuAM53PtUrhE4aEoyGmQ@mail.gmail.com>
Message-ID: <CA+8X3fXCz4-SjRNCipkTjnWyoV9ydVUMxTVFhVJ8R-TF4UJCmw@mail.gmail.com>

Hi Nevil,
As I don't have the filematrix package this is really an "any suggestion":

FM[,which(colnames(FM) %in% c("one","three"))]

Jim

On Tue, Sep 8, 2020 at 9:43 PM nevil amos <nevil.amos at gmail.com> wrote:
>
> Is there a way to get columns out of a filematrix using the column name
> directly in the same way that  you can with a regular matrix?
>
> library(filematrix)
> M<-t(matrix(1:3,3,4))
> colnames(M)<-c("one","two", "three")
> M
> #Extract column
> M[,1]
> M[,"one"]
> M[,c(1,3)]
> M[,c("one","three")]
> FM<-fm.create.from.matrix(filenamebase = "test",mat = M)
> FM[,1]
> colnames(FM)
> #extract by column by name does not work
> FM[,"one"]
>
> #workaround using grep
> #is there a more direct way of doing this  to retrieve more than one column?
> FM[,grep("one",colnames(FM))]
>
> FM[,c(grep("one",colnames(FM)),grep("three",colnames(FM)))]
>
> many thanks for any suggestions
>
> Nevil Amos
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From v@r||61 @end|ng |rom w|ndow@||ve@com  Wed Sep  9 16:13:51 2020
From: v@r||61 @end|ng |rom w|ndow@||ve@com (=?iso-8859-3?Q?ahmet_varl=B9?=)
Date: Wed, 9 Sep 2020 14:13:51 +0000
Subject: [R] calculating a linear regression for each grid cell. firstly
Message-ID: <VI1PR0302MB3199F2DEB96EDFB0B65238C3BB260@VI1PR0302MB3199.eurprd03.prod.outlook.com>

       Hi all,


            for example, ? have 4 raster data and ? try to convert these rasters to 1 array and calculate a linear regression for each grid cell how can ? do this?



                max_consecutive_days_1<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)
                max_consecutive_days_2<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)
                max_consecutive_days_3<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)
                max_consecutive_days_4<- raster(ncol=94, nrow=192, xmn=-180, xmx=180, ymn=-90, ymx=90)

                values(max_consecutive_days_1)  <- 1:ncell(max_consecutive_days_1)
                values(max_consecutive_days_2) <- 1:ncell(max_consecutive_days_2)
                values(max_consecutive_days_3) <- 1:ncell(max_consecutive_days_3)
                values(max_consecutive_days_4) <- 1:ncell(max_consecutive_days_4)
                set.seed(0)
                values(max_consecutive_days_1)  <- runif(ncell(max_consecutive_days_1))
                values(max_consecutive_days_2) <- runif(ncell(max_consecutive_days_2))
                values(max_consecutive_days_3) <- runif(ncell(max_consecutive_days_3))
                values(max_consecutive_days_4) <- runif(ncell(max_consecutive_days_4))

         I tried to convert raster to an array and calculate a linear regression for each cell with these codes. there is something wrong in codes but I didn't find what it's wrong

        library(raster)
            r<-raster("C:/max_consecutive_days_1.tif")
            a<-array(NA,dim=c(dim(r)[1:2],4))
            i <- 1
            dir.in <- "C:/max_consecutive_days/"
            for (year in 1:4) {
              fi<-paste0(dir.in,"max_consecutive_days_",year,".tif")
              r<-raster(fi)
              a[,,i]<-getValues(r,format="matrix")
              i<-i+1
            }


     lmfunction <- function(x){

              if (is.na(x[1])){ NA }

              else

                y<-c(1:length(x))
              m1<- summary(lm(x~y))
              coef <- m1$coef[2]

              coef
             }

            storem <- array(NA,dim=dim(a)[1:2])
            for(i in 1:94){
              for(j in 1:192){
                tst<-mean(a[i,j,],n.rm=T)
                if (is.na(tst)==F){
                  storem[i,j]<-lmfunction(a[i,j,])
                }
              }
            }


Best wishes,

Windows 10 i?in Posta<https://go.microsoft.com/fwlink/?LinkId=550986> ile g?nderildi


	[[alternative HTML version deleted]]


From c@|@ndr@ @end|ng |rom rgzm@de  Wed Sep  9 17:30:13 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 9 Sep 2020 17:30:13 +0200
Subject: [R] facet_wrap(nrow) ignored
Message-ID: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>

Dear useRs,

I have an issue with the argument nrow of ggplot2::facet_wrap().

Let's consider some sample data:
mydf <- data.frame(grp = rep(letters[1:6], each = 15), cat = rep(1:3,
30), var = rnorm(90))

And let's try to plot with 5 rows:
library(ggplot2)
ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
facet_wrap(~grp, nrow = 5)
It plots 2 rows and 3 columns rather than 5 rows and 2 columns as wanted.

These plots are as expected:
ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
facet_wrap(~grp, nrow = 2)
ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
facet_wrap(~grp, nrow = 6)

My guess is that 5 rows is not ideal for 6 facets (5 facets in 1st
column and only 1 facet for 2nd column) so it overrides the value of
nrow. In the case of 2 or 6 rows, the facets are well distributed in the
layout.

The reason why I need 5 rows with 6 facets is that this facet plot is
part of a patchwork and I would like to have the same number of rows for
all facet plots of the patchwork (so that they all align well).

Is there a way to force the number of rows in the facet_wrap()?

Thank you in advance.
Best,
Ivan

-- 


--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 10:35:45 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 10:35:45 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
Message-ID: <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>

Thank you very much for the code, that was very helpful.
I got the article by Hutcheson -- I don't know if I can distribute it
, given the possible copyrights, or if I can attach it here -- but it
does not report numbers directly: it refers to a previous article
counting bird death on a telegraph each year. The numbers
are:
bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
bird_1959 <- c(0,0,14,59,26,68,0)
bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)

This for sake of the argument.
As for my problem, I implemented the Shannon index with the package
iNext, which only gives me the index itself and the 95% CI. Even when
I implemented it with vegan, I only got the index. Essentially I don't
have a count of species I could feed into the Hutcheson's. Is there a
way to extract these data? Or to run a Hutcheson's on the final index?
Thank you

On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
<karl.schilling at uni-bonn.de> wrote:
>
> Dear Luigi,
>
> below some code I cobbled together based on the Hutcheson paper you
> mentioned. I was lucky to find code to calculate h and, importantly, its
> variance in the R-package QSutils - you may find it on the Bioconductor
> website.
>
> here is the code, along with an example. I also attach the code as an
> R-file.
>
> Hope that helps.
> All my best
>
> Karl
> PS don't forget to adjust for multiple testing if you compare more than
> two groups.
> K
>
>
> # load package needed
> # QSutils is on Bioconductor
> library(QSutils)
>
> # here some exemplary data - these are the data from Pilou 1966 that are
> used
> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
>
> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> # numbers of the first example used by Hutcheson were unfortunately not
> # available to me
>
> # here starts the code ; you may replace the variables "earlier" and "later"
> # by your own numbers.
>
> # calculate h, var(h) etc
> h1 <- Shannon(earlier)
> varh1 <- ShannonVar(earlier)
> n1 <- sum (earlier)
> h2 <- Shannon(later)
> varh2 <- ShannonVar(later)
> n2 <- sum (later)
> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
>
> # compare numbers with those in the paper
> h1
> h2
> varh1
> varh2
> # I assume that minor numerical differences are due to differences in the
> # numerical precision of computers in the early seventies and today / KS
>
> # this is the actual t-test
> t <- (h1-h2) /sqrt(varh1 + varh2)
> p <- 2*pt(-abs(t),df= degfree)
> p
>
> # that's it
> # Best
> # Karl
> --
> Karl Schilling, MD
> Professor of Anatomy and Cell Biology
> Anatomisches Institut
> Rheinische Friedrich-Wilhelms-Universit?t
> Nussallee 10
>
> D-53115 Bonn
> Germany
>
> phone ++49-228-73-2602
>


-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 10:38:41 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 10:38:41 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
Message-ID: <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>

Update:
I can see that you used the function Shannon from the package QSutils.
This would supplement the iNext package I used and solve the problem.
Thank you.

On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Thank you very much for the code, that was very helpful.
> I got the article by Hutcheson -- I don't know if I can distribute it
> , given the possible copyrights, or if I can attach it here -- but it
> does not report numbers directly: it refers to a previous article
> counting bird death on a telegraph each year. The numbers
> are:
> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> bird_1959 <- c(0,0,14,59,26,68,0)
> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
>
> This for sake of the argument.
> As for my problem, I implemented the Shannon index with the package
> iNext, which only gives me the index itself and the 95% CI. Even when
> I implemented it with vegan, I only got the index. Essentially I don't
> have a count of species I could feed into the Hutcheson's. Is there a
> way to extract these data? Or to run a Hutcheson's on the final index?
> Thank you
>
> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> <karl.schilling at uni-bonn.de> wrote:
> >
> > Dear Luigi,
> >
> > below some code I cobbled together based on the Hutcheson paper you
> > mentioned. I was lucky to find code to calculate h and, importantly, its
> > variance in the R-package QSutils - you may find it on the Bioconductor
> > website.
> >
> > here is the code, along with an example. I also attach the code as an
> > R-file.
> >
> > Hope that helps.
> > All my best
> >
> > Karl
> > PS don't forget to adjust for multiple testing if you compare more than
> > two groups.
> > K
> >
> >
> > # load package needed
> > # QSutils is on Bioconductor
> > library(QSutils)
> >
> > # here some exemplary data - these are the data from Pilou 1966 that are
> > used
> > # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> >
> > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > # numbers of the first example used by Hutcheson were unfortunately not
> > # available to me
> >
> > # here starts the code ; you may replace the variables "earlier" and "later"
> > # by your own numbers.
> >
> > # calculate h, var(h) etc
> > h1 <- Shannon(earlier)
> > varh1 <- ShannonVar(earlier)
> > n1 <- sum (earlier)
> > h2 <- Shannon(later)
> > varh2 <- ShannonVar(later)
> > n2 <- sum (later)
> > degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> >
> > # compare numbers with those in the paper
> > h1
> > h2
> > varh1
> > varh2
> > # I assume that minor numerical differences are due to differences in the
> > # numerical precision of computers in the early seventies and today / KS
> >
> > # this is the actual t-test
> > t <- (h1-h2) /sqrt(varh1 + varh2)
> > p <- 2*pt(-abs(t),df= degfree)
> > p
> >
> > # that's it
> > # Best
> > # Karl
> > --
> > Karl Schilling, MD
> > Professor of Anatomy and Cell Biology
> > Anatomisches Institut
> > Rheinische Friedrich-Wilhelms-Universit?t
> > Nussallee 10
> >
> > D-53115 Bonn
> > Germany
> >
> > phone ++49-228-73-2602
> >
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de  Thu Sep 10 11:54:52 2020
From: U|r|k@Stervbo @end|ng |rom ruhr-un|-bochum@de (Ulrik Stervbo)
Date: Thu, 10 Sep 2020 11:54:52 +0200
Subject: [R] facet_wrap(nrow) ignored
In-Reply-To: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>
References: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>
Message-ID: <c94070a827f99442f190661149968da4@ruhr-uni-bochum.de>

Dear Ivan,

I don't think it is possible to force a number of rows - but I'm 
honestly just guessing.

What you can do is to add an empty plot. Here I use cowplot, but 
gridExtra should also work well.

I add an indication of the row number for the plot to the initial 
data.frame, and loop over these.

In the first variant, I add an unused factor to the grp which creates an 
empty facet. I personally think this looks a little confusing, so in the 
second variant, I add a number of empty plots.

HTH
Ulrik

```
mydf <- data.frame(
   grp = rep(letters[1:6], each = 15),
   cat = rep(1:3, 30),
   var = rnorm(90),
   row_num = rep(c(1, 1, 2, 3, 4, 5), each = 15)
)

s_mydf <- split(mydf, mydf$row_num)

plots_mydf <- lapply(s_mydf, function(x){
   # Ensure no unused factors
   x$grp <- droplevels.factor(x$grp)
   if(length(unique(x$grp)) == 1){
     x$grp <- factor(x$grp, levels = c(unique(x$grp), ""))
   }
   ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
     facet_wrap(~grp, drop=FALSE)
})

cowplot::plot_grid(plotlist = plots_mydf, nrow = 5)

# Maybe more elegant output
plots_mydf <- lapply(s_mydf, function(x, ncol = 2){
   # Ensure no unused factors
   x$grp <- droplevels.factor(x$grp)
   x <- split(x, x$grp)

   p <- lapply(x, function(x){
     ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
       facet_wrap(~grp)
   })

   if(length(p) < ncol){
     pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
     p <- c(p, pe)
   }
   cowplot::plot_grid(plotlist = p, ncol = ncol)
})

cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)

# Or if you prefer not to split the plots on the same row
plots_mydf <- lapply(s_mydf, function(x, ncol = 2){

   p <- list(ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
     facet_wrap(~grp))

   if(length(unique(x$grp)) < ncol){
     pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
     p <- c(p, pe)
   }else{
     ncol <- 1
   }
   cowplot::plot_grid(plotlist = p, ncol = ncol)
})

cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)

```

On 2020-09-09 17:30, Ivan Calandra wrote:
> Dear useRs,
> 
> I have an issue with the argument nrow of ggplot2::facet_wrap().
> 
> Let's consider some sample data:
> mydf <- data.frame(grp = rep(letters[1:6], each = 15), cat = rep(1:3,
> 30), var = rnorm(90))
> 
> And let's try to plot with 5 rows:
> library(ggplot2)
> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
> facet_wrap(~grp, nrow = 5)
> It plots 2 rows and 3 columns rather than 5 rows and 2 columns as 
> wanted.
> 
> These plots are as expected:
> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
> facet_wrap(~grp, nrow = 2)
> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
> facet_wrap(~grp, nrow = 6)
> 
> My guess is that 5 rows is not ideal for 6 facets (5 facets in 1st
> column and only 1 facet for 2nd column) so it overrides the value of
> nrow. In the case of 2 or 6 rows, the facets are well distributed in 
> the
> layout.
> 
> The reason why I need 5 rows with 6 facets is that this facet plot is
> part of a patchwork and I would like to have the same number of rows 
> for
> all facet plots of the patchwork (so that they all align well).
> 
> Is there a way to force the number of rows in the facet_wrap()?
> 
> Thank you in advance.
> Best,
> Ivan
> 
> --
> 
> 
> --
> Dr. Ivan Calandra
> TraCEr, laboratory for Traceology and Controlled Experiments
> MONREPOS Archaeological Research Centre and
> Museum for Human Behavioural Evolution
> Schloss Monrepos
> 56567 Neuwied, Germany
> +49 (0) 2631 9772-243
> https://www.researchgate.net/profile/Ivan_Calandra
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 10 12:44:39 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 10 Sep 2020 11:44:39 +0100
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
Message-ID: <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>

If you want a function automating Karl's code, here it is. It returns an 
object of S3 class "htest", R's standard for hypothesis tests functions. 
The returned object can then be subset in the usual ways, ht$statistic, 
ht$parameter, ht$p.value, etc.


library(QSutils)

hutcheson.test <- function(x1, x2){
   dataname1 <- deparse(substitute(x1))
   dataname2 <- deparse(substitute(x2))
   method <- "Hutcheson's t-test for Shannon diversity equality"
   alternative <- "the diversities of the two samples are not equal"
   h1 <- Shannon(x1)
   varh1 <- ShannonVar(x1)
   n1 <- sum(x1)
   h2 <- Shannon(x2)
   varh2 <- ShannonVar(x2)
   n2 <- sum(x2)
   degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
   tstat <- (h1 - h2)/sqrt(varh1 + varh2)
   p.value <- 2*pt(-abs(tstat), df = degfree)
   ht <- list(
     statistic = c(t = tstat),
     parameter = c(df = degfree),
     p.value = p.value,
     alternative = alternative,
     method = method,
     data.name = paste(dataname1, dataname2, sep = ", ")
   )
   class(ht) <- "htest"
   ht
}

earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)

hutcheson.test(earlier, later)



With the data you provided:


bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
bird_1959 <- c(0,0,14,59,26,68,0)
bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)

hutcheson.test(bird_1956, bird_1957)




Note that like David said earlier, there might be better ways to 
interpret Shannon's diversity index. If h is the sample's diversity, 
exp(h) gives the number of equally-common species with equivalent 
diversity.


s1 <- Shannon(earlier)
s2 <- Shannon(later)
c(earlier = s1, later = s2)
exp(c(earlier = s1, later = s2))   # Both round to 3
eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
Shannon(eq_common)                 # Slightly greater than the samples' 
diversity


round(exp(sapply(birds, Shannon))) # Your data


#-------------------------------------


Earlier Karl wrote [1] that


Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
that explains the minor numerical differences obtained with the code
above and the published variances.


I don't believe the published variances were computed with the published 
variance estimator. The code below computes the variances like QSutils 
and with formula (4) in Hutcheson's paper. The latter does not give the 
same results.

var_est <- function(n){
   s <- length(n)
   N <- sum(n)
   p <- n/N
   i <- p != 0
   inv.p <- numeric(s)
   inv.p[i] <- 1/p[i]
   log.p <- numeric(s)
   log.p[i] <- log(p[i])
   #
   term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
   term2 <- (s - 1)/(2*N^2)
   #
   numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p * 
log.p)
   denom3 <- 6*N^3
   term3 <- numer3/denom3
   list(
     Bioc = term1 + term2,
     Hutch = term1 + term2 + term3
   )
}

Vh1 <- var_est(earlier)
Vh1
all.equal(ShannonVar(earlier), Vh1$Bioc)
ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31

Vh2 <- var_est(later)
Vh2
identical(ShannonVar(later), Vh2$Bioc)    # TRUE



[1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html


Hope this helps,

Rui Barradas


?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> Update:
> I can see that you used the function Shannon from the package QSutils.
> This would supplement the iNext package I used and solve the problem.
> Thank you.
> 
> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
>>
>> Thank you very much for the code, that was very helpful.
>> I got the article by Hutcheson -- I don't know if I can distribute it
>> , given the possible copyrights, or if I can attach it here -- but it
>> does not report numbers directly: it refers to a previous article
>> counting bird death on a telegraph each year. The numbers
>> are:
>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
>> bird_1959 <- c(0,0,14,59,26,68,0)
>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
>>
>> This for sake of the argument.
>> As for my problem, I implemented the Shannon index with the package
>> iNext, which only gives me the index itself and the 95% CI. Even when
>> I implemented it with vegan, I only got the index. Essentially I don't
>> have a count of species I could feed into the Hutcheson's. Is there a
>> way to extract these data? Or to run a Hutcheson's on the final index?
>> Thank you
>>
>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
>> <karl.schilling at uni-bonn.de> wrote:
>>>
>>> Dear Luigi,
>>>
>>> below some code I cobbled together based on the Hutcheson paper you
>>> mentioned. I was lucky to find code to calculate h and, importantly, its
>>> variance in the R-package QSutils - you may find it on the Bioconductor
>>> website.
>>>
>>> here is the code, along with an example. I also attach the code as an
>>> R-file.
>>>
>>> Hope that helps.
>>> All my best
>>>
>>> Karl
>>> PS don't forget to adjust for multiple testing if you compare more than
>>> two groups.
>>> K
>>>
>>>
>>> # load package needed
>>> # QSutils is on Bioconductor
>>> library(QSutils)
>>>
>>> # here some exemplary data - these are the data from Pilou 1966 that are
>>> used
>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
>>>
>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
>>> # numbers of the first example used by Hutcheson were unfortunately not
>>> # available to me
>>>
>>> # here starts the code ; you may replace the variables "earlier" and "later"
>>> # by your own numbers.
>>>
>>> # calculate h, var(h) etc
>>> h1 <- Shannon(earlier)
>>> varh1 <- ShannonVar(earlier)
>>> n1 <- sum (earlier)
>>> h2 <- Shannon(later)
>>> varh2 <- ShannonVar(later)
>>> n2 <- sum (later)
>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
>>>
>>> # compare numbers with those in the paper
>>> h1
>>> h2
>>> varh1
>>> varh2
>>> # I assume that minor numerical differences are due to differences in the
>>> # numerical precision of computers in the early seventies and today / KS
>>>
>>> # this is the actual t-test
>>> t <- (h1-h2) /sqrt(varh1 + varh2)
>>> p <- 2*pt(-abs(t),df= degfree)
>>> p
>>>
>>> # that's it
>>> # Best
>>> # Karl
>>> --
>>> Karl Schilling, MD
>>> Professor of Anatomy and Cell Biology
>>> Anatomisches Institut
>>> Rheinische Friedrich-Wilhelms-Universit?t
>>> Nussallee 10
>>>
>>> D-53115 Bonn
>>> Germany
>>>
>>> phone ++49-228-73-2602
>>>
>>
>>
>> --
>> Best regards,
>> Luigi
> 
> 
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Sep 10 13:04:17 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 10 Sep 2020 12:04:17 +0100
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
Message-ID: <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>

Hello,

Sorry, there's an instruction missing. See inline.

?s 11:44 de 10/09/20, Rui Barradas escreveu:
> If you want a function automating Karl's code, here it is. It returns an 
> object of S3 class "htest", R's standard for hypothesis tests functions. 
> The returned object can then be subset in the usual ways, ht$statistic, 
> ht$parameter, ht$p.value, etc.
> 
> 
> library(QSutils)
> 
> hutcheson.test <- function(x1, x2){
>  ? dataname1 <- deparse(substitute(x1))
>  ? dataname2 <- deparse(substitute(x2))
>  ? method <- "Hutcheson's t-test for Shannon diversity equality"
>  ? alternative <- "the diversities of the two samples are not equal"
>  ? h1 <- Shannon(x1)
>  ? varh1 <- ShannonVar(x1)
>  ? n1 <- sum(x1)
>  ? h2 <- Shannon(x2)
>  ? varh2 <- ShannonVar(x2)
>  ? n2 <- sum(x2)
>  ? degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
>  ? tstat <- (h1 - h2)/sqrt(varh1 + varh2)
>  ? p.value <- 2*pt(-abs(tstat), df = degfree)
>  ? ht <- list(
>  ??? statistic = c(t = tstat),
>  ??? parameter = c(df = degfree),
>  ??? p.value = p.value,
>  ??? alternative = alternative,
>  ??? method = method,
>  ??? data.name = paste(dataname1, dataname2, sep = ", ")
>  ? )
>  ? class(ht) <- "htest"
>  ? ht
> }
> 
> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> 
> hutcheson.test(earlier, later)
> 
> 
> 
> With the data you provided:
> 
> 
> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> bird_1959 <- c(0,0,14,59,26,68,0)
> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> 
> hutcheson.test(bird_1956, bird_1957)
> 
> 
> 
> 
> Note that like David said earlier, there might be better ways to 
> interpret Shannon's diversity index. If h is the sample's diversity, 
> exp(h) gives the number of equally-common species with equivalent 
> diversity.
> 
> 
> s1 <- Shannon(earlier)
> s2 <- Shannon(later)
> c(earlier = s1, later = s2)
> exp(c(earlier = s1, later = s2))?? # Both round to 3
> eq_common <- rep(1, 3)???????????? # Can be 1 specimen or any other number
> Shannon(eq_common)???????????????? # Slightly greater than the samples' 
> diversity
> 
>

# Create a list with all the data
birds <- mget(ls(pattern = "^bird"))

> round(exp(sapply(birds, Shannon))) # Your data


Hope this helps,

Rui Barradas

> 
> 
> #-------------------------------------
> 
> 
> Earlier Karl wrote [1] that
> 
> 
> Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> that explains the minor numerical differences obtained with the code
> above and the published variances.
> 
> 
> I don't believe the published variances were computed with the published 
> variance estimator. The code below computes the variances like QSutils 
> and with formula (4) in Hutcheson's paper. The latter does not give the 
> same results.
> 
> var_est <- function(n){
>  ? s <- length(n)
>  ? N <- sum(n)
>  ? p <- n/N
>  ? i <- p != 0
>  ? inv.p <- numeric(s)
>  ? inv.p[i] <- 1/p[i]
>  ? log.p <- numeric(s)
>  ? log.p[i] <- log(p[i])
>  ? #
>  ? term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
>  ? term2 <- (s - 1)/(2*N^2)
>  ? #
>  ? numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p * 
> log.p)
>  ? denom3 <- 6*N^3
>  ? term3 <- numer3/denom3
>  ? list(
>  ??? Bioc = term1 + term2,
>  ??? Hutch = term1 + term2 + term3
>  ? )
> }
> 
> Vh1 <- var_est(earlier)
> Vh1
> all.equal(ShannonVar(earlier), Vh1$Bioc)
> ShannonVar(earlier) - Vh1$Bioc??????????? # FAQ 7.31
> 
> Vh2 <- var_est(later)
> Vh2
> identical(ShannonVar(later), Vh2$Bioc)??? # TRUE
> 
> 
> 
> [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
>> Update:
>> I can see that you used the function Shannon from the package QSutils.
>> This would supplement the iNext package I used and solve the problem.
>> Thank you.
>>
>> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
>> <marongiu.luigi at gmail.com> wrote:
>>>
>>> Thank you very much for the code, that was very helpful.
>>> I got the article by Hutcheson -- I don't know if I can distribute it
>>> , given the possible copyrights, or if I can attach it here -- but it
>>> does not report numbers directly: it refers to a previous article
>>> counting bird death on a telegraph each year. The numbers
>>> are:
>>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
>>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
>>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
>>> bird_1959 <- c(0,0,14,59,26,68,0)
>>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
>>>
>>> This for sake of the argument.
>>> As for my problem, I implemented the Shannon index with the package
>>> iNext, which only gives me the index itself and the 95% CI. Even when
>>> I implemented it with vegan, I only got the index. Essentially I don't
>>> have a count of species I could feed into the Hutcheson's. Is there a
>>> way to extract these data? Or to run a Hutcheson's on the final index?
>>> Thank you
>>>
>>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
>>> <karl.schilling at uni-bonn.de> wrote:
>>>>
>>>> Dear Luigi,
>>>>
>>>> below some code I cobbled together based on the Hutcheson paper you
>>>> mentioned. I was lucky to find code to calculate h and, importantly, 
>>>> its
>>>> variance in the R-package QSutils - you may find it on the Bioconductor
>>>> website.
>>>>
>>>> here is the code, along with an example. I also attach the code as an
>>>> R-file.
>>>>
>>>> Hope that helps.
>>>> All my best
>>>>
>>>> Karl
>>>> PS don't forget to adjust for multiple testing if you compare more than
>>>> two groups.
>>>> K
>>>>
>>>>
>>>> # load package needed
>>>> # QSutils is on Bioconductor
>>>> library(QSutils)
>>>>
>>>> # here some exemplary data - these are the data from Pilou 1966 that 
>>>> are
>>>> used
>>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
>>>>
>>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
>>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
>>>> # numbers of the first example used by Hutcheson were unfortunately not
>>>> # available to me
>>>>
>>>> # here starts the code ; you may replace the variables "earlier" and 
>>>> "later"
>>>> # by your own numbers.
>>>>
>>>> # calculate h, var(h) etc
>>>> h1 <- Shannon(earlier)
>>>> varh1 <- ShannonVar(earlier)
>>>> n1 <- sum (earlier)
>>>> h2 <- Shannon(later)
>>>> varh2 <- ShannonVar(later)
>>>> n2 <- sum (later)
>>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
>>>>
>>>> # compare numbers with those in the paper
>>>> h1
>>>> h2
>>>> varh1
>>>> varh2
>>>> # I assume that minor numerical differences are due to differences 
>>>> in the
>>>> # numerical precision of computers in the early seventies and today 
>>>> / KS
>>>>
>>>> # this is the actual t-test
>>>> t <- (h1-h2) /sqrt(varh1 + varh2)
>>>> p <- 2*pt(-abs(t),df= degfree)
>>>> p
>>>>
>>>> # that's it
>>>> # Best
>>>> # Karl
>>>> -- 
>>>> Karl Schilling, MD
>>>> Professor of Anatomy and Cell Biology
>>>> Anatomisches Institut
>>>> Rheinische Friedrich-Wilhelms-Universit?t
>>>> Nussallee 10
>>>>
>>>> D-53115 Bonn
>>>> Germany
>>>>
>>>> phone ++49-228-73-2602
>>>>
>>>
>>>
>>> -- 
>>> Best regards,
>>> Luigi
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From c@|@ndr@ @end|ng |rom rgzm@de  Thu Sep 10 13:53:20 2020
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 10 Sep 2020 13:53:20 +0200
Subject: [R] facet_wrap(nrow) ignored
In-Reply-To: <c94070a827f99442f190661149968da4@ruhr-uni-bochum.de>
References: <2e8ae7a0-d752-8053-937b-607dc96da766@rgzm.de>
 <c94070a827f99442f190661149968da4@ruhr-uni-bochum.de>
Message-ID: <4067e7b0-3a35-9db4-16fe-009e269a51a5@rgzm.de>

Thank you Ulrik for the suggestions.

I was thinking of a similar approach using a nested patchwork (which
would be easier for me).

It's just a shame that it is not possible to force a number of rows.
It's good that ggplot2 tries to do things in the most "appropriate" way,
but at some point, when the user decides it needs to have 5 rows, then
ggplot2 should listen, potentially issuing a warning like "the number of
rows specified is not appropriate, consider other values instead (e.g. 2)".

Best,
Ivan

PS: our email server is having troubles today, so I have not received
any other R-related emails. Are there few today or is it just me? There
might even be more answers to my question...

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 10/09/2020 11:54, Ulrik Stervbo wrote:
> Dear Ivan,
>
> I don't think it is possible to force a number of rows - but I'm
> honestly just guessing.
>
> What you can do is to add an empty plot. Here I use cowplot, but
> gridExtra should also work well.
>
> I add an indication of the row number for the plot to the initial
> data.frame, and loop over these.
>
> In the first variant, I add an unused factor to the grp which creates
> an empty facet. I personally think this looks a little confusing, so
> in the second variant, I add a number of empty plots.
>
> HTH
> Ulrik
>
> ```
> mydf <- data.frame(
> ? grp = rep(letters[1:6], each = 15),
> ? cat = rep(1:3, 30),
> ? var = rnorm(90),
> ? row_num = rep(c(1, 1, 2, 3, 4, 5), each = 15)
> )
>
> s_mydf <- split(mydf, mydf$row_num)
>
> plots_mydf <- lapply(s_mydf, function(x){
> ? # Ensure no unused factors
> ? x$grp <- droplevels.factor(x$grp)
> ? if(length(unique(x$grp)) == 1){
> ??? x$grp <- factor(x$grp, levels = c(unique(x$grp), ""))
> ? }
> ? ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
> ??? facet_wrap(~grp, drop=FALSE)
> })
>
> cowplot::plot_grid(plotlist = plots_mydf, nrow = 5)
>
> # Maybe more elegant output
> plots_mydf <- lapply(s_mydf, function(x, ncol = 2){
> ? # Ensure no unused factors
> ? x$grp <- droplevels.factor(x$grp)
> ? x <- split(x, x$grp)
>
> ? p <- lapply(x, function(x){
> ??? ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
> ????? facet_wrap(~grp)
> ? })
>
> ? if(length(p) < ncol){
> ??? pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
> ??? p <- c(p, pe)
> ? }
> ? cowplot::plot_grid(plotlist = p, ncol = ncol)
> })
>
> cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)
>
> # Or if you prefer not to split the plots on the same row
> plots_mydf <- lapply(s_mydf, function(x, ncol = 2){
>
> ? p <- list(ggplot(data = x, aes(x = cat, y = var)) + geom_point() +
> ??? facet_wrap(~grp))
>
> ? if(length(unique(x$grp)) < ncol){
> ??? pe <- rep(list(ggplot() + theme_void()), ncol - length(p))
> ??? p <- c(p, pe)
> ? }else{
> ??? ncol <- 1
> ? }
> ? cowplot::plot_grid(plotlist = p, ncol = ncol)
> })
>
> cowplot::plot_grid(plotlist = plots_mydf, ncol = 1)
>
> ```
>
> On 2020-09-09 17:30, Ivan Calandra wrote:
>> Dear useRs,
>>
>> I have an issue with the argument nrow of ggplot2::facet_wrap().
>>
>> Let's consider some sample data:
>> mydf <- data.frame(grp = rep(letters[1:6], each = 15), cat = rep(1:3,
>> 30), var = rnorm(90))
>>
>> And let's try to plot with 5 rows:
>> library(ggplot2)
>> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
>> facet_wrap(~grp, nrow = 5)
>> It plots 2 rows and 3 columns rather than 5 rows and 2 columns as
>> wanted.
>>
>> These plots are as expected:
>> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
>> facet_wrap(~grp, nrow = 2)
>> ggplot(data = mydf, aes(x = cat, y = var)) + geom_point() +
>> facet_wrap(~grp, nrow = 6)
>>
>> My guess is that 5 rows is not ideal for 6 facets (5 facets in 1st
>> column and only 1 facet for 2nd column) so it overrides the value of
>> nrow. In the case of 2 or 6 rows, the facets are well distributed in the
>> layout.
>>
>> The reason why I need 5 rows with 6 facets is that this facet plot is
>> part of a patchwork and I would like to have the same number of rows for
>> all facet plots of the patchwork (so that they all align well).
>>
>> Is there a way to force the number of rows in the facet_wrap()?
>>
>> Thank you in advance.
>> Best,
>> Ivan
>>
>> -- 
>>
>>
>> -- 
>> Dr. Ivan Calandra
>> TraCEr, laboratory for Traceology and Controlled Experiments
>> MONREPOS Archaeological Research Centre and
>> Museum for Human Behavioural Evolution
>> Schloss Monrepos
>> 56567 Neuwied, Germany
>> +49 (0) 2631 9772-243
>> https://www.researchgate.net/profile/Ivan_Calandra
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 14:10:26 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 14:10:26 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
Message-ID: <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>

Hello,
thank you for the code. To explain better, when I used vegan, I did
not count the species directly but simply prepared a dataframe where,
for each species, I counted the number of samples bearing such
species:
```

> str(new_df)
'data.frame': 3 obs. of  46 variables:
 $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
 $ NC_001623 Autographa californica nucl...: int  7 7 7
 $ NC_001895 Enterobacteria phage P2       : int  1 0 0
 $ NC_004745 Yersinia phage L-413C         : int  1 0 0
```
here the triplettes refer to healthy, tumor and metastasis. The outcome is:
```
# Shannon index
diversity(new_df)
#> Normal     Tumour     Metastasis
#> 2.520139   3.109512   1.890404
```
Using iNext, I provided a list of all the species counted in a samples
```
> new_list
$Healthy
 [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0

$Tumour
 [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
1 2 1 1 1 1 1 1 1 0 0 0 0

$Metastasis
 [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 1 0 0 1 1 1 1
```
>From this I get:
```
mod = iNEXT(new_list, q=0, datatype="abundance")
mod$AsyEst
#Site         Diversity Observed Estimator   s.e.    LCL     UCL
#1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
#2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
#4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
#5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
#7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
#8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
```
So here the Shannon index is 12 instead of 2.5...
Using Karl's function, I get:
```
# compute Shannon
norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
# compute Hutcheson
degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
canc_var**2 /canc_sum)
test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
(p <- 2*pt(-abs(test),df= degree))
> [1] 0.01825784
```
remarkably, the indices are the same as obtained by vegan:
```
> norm_sIdx
[1] 2.520139
> canc_sIdx
[1] 3.109512
> meta_sIdx
[1] 1.890404
```

I tried Rui's function but I got an error, so I wrote it as
```
hutcheson = function(A, B){
  # compute Shannon index, variance and sum of elements
  A_index <- Shannon(A)
  B_index <- Shannon(B)
  A_var <- ShannonVar(A)
  B_var <- ShannonVar(B)
  A_sum <- sum(A)
  B_sum <- sum(B)
  # compute Hutcheson
  DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
  test <- (A_index-B_index) /sqrt(A_var + B_var)
  p <- 2*pt(-abs(test),df= DF)
  # closure
  cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
index first group: ",
      round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
      "\n\tp-value : ", round(p, 4), "\n", sep = "")
  return(p)
}
```
and I got:
```

> n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 2.5201
Shannon index second group: 3.1095
p-value : 0.0183
> n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 2.5201
Shannon index second group: 1.8904
p-value : 0.0371
> t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 3.1095
Shannon index second group: 1.8904
p-value : 0
```
new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
the original Hutcheson data:
```
> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> hutcheson(bird_1956, bird_1957)
Hutcheson's t-test for Shannon diversity equality
Shannon index first group: 1.8429
Shannon index second group: 1.0689
p-value : 0

```
This is to compare two groups at the time. I'll probably have to
compensate for multiple testing...
But if this all OK, then the case is closed.
Thank you

On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> Sorry, there's an instruction missing. See inline.
>
> ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > If you want a function automating Karl's code, here it is. It returns an
> > object of S3 class "htest", R's standard for hypothesis tests functions.
> > The returned object can then be subset in the usual ways, ht$statistic,
> > ht$parameter, ht$p.value, etc.
> >
> >
> > library(QSutils)
> >
> > hutcheson.test <- function(x1, x2){
> >    dataname1 <- deparse(substitute(x1))
> >    dataname2 <- deparse(substitute(x2))
> >    method <- "Hutcheson's t-test for Shannon diversity equality"
> >    alternative <- "the diversities of the two samples are not equal"
> >    h1 <- Shannon(x1)
> >    varh1 <- ShannonVar(x1)
> >    n1 <- sum(x1)
> >    h2 <- Shannon(x2)
> >    varh2 <- ShannonVar(x2)
> >    n2 <- sum(x2)
> >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> >    p.value <- 2*pt(-abs(tstat), df = degfree)
> >    ht <- list(
> >      statistic = c(t = tstat),
> >      parameter = c(df = degfree),
> >      p.value = p.value,
> >      alternative = alternative,
> >      method = method,
> >      data.name = paste(dataname1, dataname2, sep = ", ")
> >    )
> >    class(ht) <- "htest"
> >    ht
> > }
> >
> > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> >
> > hutcheson.test(earlier, later)
> >
> >
> >
> > With the data you provided:
> >
> >
> > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > bird_1959 <- c(0,0,14,59,26,68,0)
> > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> >
> > hutcheson.test(bird_1956, bird_1957)
> >
> >
> >
> >
> > Note that like David said earlier, there might be better ways to
> > interpret Shannon's diversity index. If h is the sample's diversity,
> > exp(h) gives the number of equally-common species with equivalent
> > diversity.
> >
> >
> > s1 <- Shannon(earlier)
> > s2 <- Shannon(later)
> > c(earlier = s1, later = s2)
> > exp(c(earlier = s1, later = s2))   # Both round to 3
> > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > Shannon(eq_common)                 # Slightly greater than the samples'
> > diversity
> >
> >
>
> # Create a list with all the data
> birds <- mget(ls(pattern = "^bird"))
>
> > round(exp(sapply(birds, Shannon))) # Your data
>
>
> Hope this helps,
>
> Rui Barradas
>
> >
> >
> > #-------------------------------------
> >
> >
> > Earlier Karl wrote [1] that
> >
> >
> > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > that explains the minor numerical differences obtained with the code
> > above and the published variances.
> >
> >
> > I don't believe the published variances were computed with the published
> > variance estimator. The code below computes the variances like QSutils
> > and with formula (4) in Hutcheson's paper. The latter does not give the
> > same results.
> >
> > var_est <- function(n){
> >    s <- length(n)
> >    N <- sum(n)
> >    p <- n/N
> >    i <- p != 0
> >    inv.p <- numeric(s)
> >    inv.p[i] <- 1/p[i]
> >    log.p <- numeric(s)
> >    log.p[i] <- log(p[i])
> >    #
> >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> >    term2 <- (s - 1)/(2*N^2)
> >    #
> >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > log.p)
> >    denom3 <- 6*N^3
> >    term3 <- numer3/denom3
> >    list(
> >      Bioc = term1 + term2,
> >      Hutch = term1 + term2 + term3
> >    )
> > }
> >
> > Vh1 <- var_est(earlier)
> > Vh1
> > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> >
> > Vh2 <- var_est(later)
> > Vh2
> > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> >
> >
> >
> > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> >> Update:
> >> I can see that you used the function Shannon from the package QSutils.
> >> This would supplement the iNext package I used and solve the problem.
> >> Thank you.
> >>
> >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> >> <marongiu.luigi at gmail.com> wrote:
> >>>
> >>> Thank you very much for the code, that was very helpful.
> >>> I got the article by Hutcheson -- I don't know if I can distribute it
> >>> , given the possible copyrights, or if I can attach it here -- but it
> >>> does not report numbers directly: it refers to a previous article
> >>> counting bird death on a telegraph each year. The numbers
> >>> are:
> >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> >>> bird_1959 <- c(0,0,14,59,26,68,0)
> >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> >>>
> >>> This for sake of the argument.
> >>> As for my problem, I implemented the Shannon index with the package
> >>> iNext, which only gives me the index itself and the 95% CI. Even when
> >>> I implemented it with vegan, I only got the index. Essentially I don't
> >>> have a count of species I could feed into the Hutcheson's. Is there a
> >>> way to extract these data? Or to run a Hutcheson's on the final index?
> >>> Thank you
> >>>
> >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> >>> <karl.schilling at uni-bonn.de> wrote:
> >>>>
> >>>> Dear Luigi,
> >>>>
> >>>> below some code I cobbled together based on the Hutcheson paper you
> >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> >>>> its
> >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> >>>> website.
> >>>>
> >>>> here is the code, along with an example. I also attach the code as an
> >>>> R-file.
> >>>>
> >>>> Hope that helps.
> >>>> All my best
> >>>>
> >>>> Karl
> >>>> PS don't forget to adjust for multiple testing if you compare more than
> >>>> two groups.
> >>>> K
> >>>>
> >>>>
> >>>> # load package needed
> >>>> # QSutils is on Bioconductor
> >>>> library(QSutils)
> >>>>
> >>>> # here some exemplary data - these are the data from Pilou 1966 that
> >>>> are
> >>>> used
> >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> >>>>
> >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> >>>> # numbers of the first example used by Hutcheson were unfortunately not
> >>>> # available to me
> >>>>
> >>>> # here starts the code ; you may replace the variables "earlier" and
> >>>> "later"
> >>>> # by your own numbers.
> >>>>
> >>>> # calculate h, var(h) etc
> >>>> h1 <- Shannon(earlier)
> >>>> varh1 <- ShannonVar(earlier)
> >>>> n1 <- sum (earlier)
> >>>> h2 <- Shannon(later)
> >>>> varh2 <- ShannonVar(later)
> >>>> n2 <- sum (later)
> >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> >>>>
> >>>> # compare numbers with those in the paper
> >>>> h1
> >>>> h2
> >>>> varh1
> >>>> varh2
> >>>> # I assume that minor numerical differences are due to differences
> >>>> in the
> >>>> # numerical precision of computers in the early seventies and today
> >>>> / KS
> >>>>
> >>>> # this is the actual t-test
> >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> >>>> p <- 2*pt(-abs(t),df= degfree)
> >>>> p
> >>>>
> >>>> # that's it
> >>>> # Best
> >>>> # Karl
> >>>> --
> >>>> Karl Schilling, MD
> >>>> Professor of Anatomy and Cell Biology
> >>>> Anatomisches Institut
> >>>> Rheinische Friedrich-Wilhelms-Universit?t
> >>>> Nussallee 10
> >>>>
> >>>> D-53115 Bonn
> >>>> Germany
> >>>>
> >>>> phone ++49-228-73-2602
> >>>>
> >>>
> >>>
> >>> --
> >>> Best regards,
> >>> Luigi
> >>
> >>
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Sep 10 14:41:07 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 10 Sep 2020 14:41:07 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
Message-ID: <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>

Update:
I also added the confidence interval for the Shannon index:
```
#! Hutcheson's t-test for Shannon diversity equality
# thanks to Karl Schilling and Rui Barradas
hutcheson = function(A, B){
  # compute Shannon index, variance and sum of elements
  A_index <- Shannon(A)
  B_index <- Shannon(B)
  A_var <- ShannonVar(A)
  B_var <- ShannonVar(B)
  A_sum <- sum(A)
  B_sum <- sum(B)
  # compute Hutcheson
  DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
  test <- (A_index-B_index) /sqrt(A_var + B_var)
  p <- 2*pt(-abs(test),df= DF)
  if (p < 0.001) {
    P = "<0.001"
  } else {
    P = round(p, 3)
  }
  if (p < 0.001) {
    S = "***"
  } else if (p < 0.01) {
    S = "**"
  } else if (p < 0.05) {
    S = "*"
  } else {
    S = ""
  }
  # closure
  cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
index first group: \t",
      round(A_index, 3), " (", round((A_index-2*A_var),3), "-",
round((A_index+2*A_var),3),
      ")\n\tShannon index second group: \t",
      round(B_index, 3), " (", round((B_index-2*B_var),3), "-",
round((B_index+2*B_var),3),
      ")\n\tp-value: ", P, " ", S, "\n", sep = "")
  return(p)
}
```

On Thu, Sep 10, 2020 at 2:10 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> thank you for the code. To explain better, when I used vegan, I did
> not count the species directly but simply prepared a dataframe where,
> for each species, I counted the number of samples bearing such
> species:
> ```
>
> > str(new_df)
> 'data.frame': 3 obs. of  46 variables:
>  $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
>  $ NC_001623 Autographa californica nucl...: int  7 7 7
>  $ NC_001895 Enterobacteria phage P2       : int  1 0 0
>  $ NC_004745 Yersinia phage L-413C         : int  1 0 0
> ```
> here the triplettes refer to healthy, tumor and metastasis. The outcome is:
> ```
> # Shannon index
> diversity(new_df)
> #> Normal     Tumour     Metastasis
> #> 2.520139   3.109512   1.890404
> ```
> Using iNext, I provided a list of all the species counted in a samples
> ```
> > new_list
> $Healthy
>  [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 0 0 0 0 0 0 0 0 0 0 0 0 0
>
> $Tumour
>  [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
> 1 2 1 1 1 1 1 1 1 0 0 0 0
>
> $Metastasis
>  [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> 0 0 0 0 0 0 1 0 0 1 1 1 1
> ```
> From this I get:
> ```
> mod = iNEXT(new_list, q=0, datatype="abundance")
> mod$AsyEst
> #Site         Diversity Observed Estimator   s.e.    LCL     UCL
> #1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
> #2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
> #4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
> #5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
> #7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
> #8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
> ```
> So here the Shannon index is 12 instead of 2.5...
> Using Karl's function, I get:
> ```
> # compute Shannon
> norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
> canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
> meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
> norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
> canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
> meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
> norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
> canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
> meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
> # compute Hutcheson
> degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
> canc_var**2 /canc_sum)
> test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
> (p <- 2*pt(-abs(test),df= degree))
> > [1] 0.01825784
> ```
> remarkably, the indices are the same as obtained by vegan:
> ```
> > norm_sIdx
> [1] 2.520139
> > canc_sIdx
> [1] 3.109512
> > meta_sIdx
> [1] 1.890404
> ```
>
> I tried Rui's function but I got an error, so I wrote it as
> ```
> hutcheson = function(A, B){
>   # compute Shannon index, variance and sum of elements
>   A_index <- Shannon(A)
>   B_index <- Shannon(B)
>   A_var <- ShannonVar(A)
>   B_var <- ShannonVar(B)
>   A_sum <- sum(A)
>   B_sum <- sum(B)
>   # compute Hutcheson
>   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
>   test <- (A_index-B_index) /sqrt(A_var + B_var)
>   p <- 2*pt(-abs(test),df= DF)
>   # closure
>   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> index first group: ",
>       round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
>       "\n\tp-value : ", round(p, 4), "\n", sep = "")
>   return(p)
> }
> ```
> and I got:
> ```
>
> > n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 2.5201
> Shannon index second group: 3.1095
> p-value : 0.0183
> > n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 2.5201
> Shannon index second group: 1.8904
> p-value : 0.0371
> > t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 3.1095
> Shannon index second group: 1.8904
> p-value : 0
> ```
> new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
> the original Hutcheson data:
> ```
> > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > hutcheson(bird_1956, bird_1957)
> Hutcheson's t-test for Shannon diversity equality
> Shannon index first group: 1.8429
> Shannon index second group: 1.0689
> p-value : 0
>
> ```
> This is to compare two groups at the time. I'll probably have to
> compensate for multiple testing...
> But if this all OK, then the case is closed.
> Thank you
>
> On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Sorry, there's an instruction missing. See inline.
> >
> > ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > > If you want a function automating Karl's code, here it is. It returns an
> > > object of S3 class "htest", R's standard for hypothesis tests functions.
> > > The returned object can then be subset in the usual ways, ht$statistic,
> > > ht$parameter, ht$p.value, etc.
> > >
> > >
> > > library(QSutils)
> > >
> > > hutcheson.test <- function(x1, x2){
> > >    dataname1 <- deparse(substitute(x1))
> > >    dataname2 <- deparse(substitute(x2))
> > >    method <- "Hutcheson's t-test for Shannon diversity equality"
> > >    alternative <- "the diversities of the two samples are not equal"
> > >    h1 <- Shannon(x1)
> > >    varh1 <- ShannonVar(x1)
> > >    n1 <- sum(x1)
> > >    h2 <- Shannon(x2)
> > >    varh2 <- ShannonVar(x2)
> > >    n2 <- sum(x2)
> > >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> > >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> > >    p.value <- 2*pt(-abs(tstat), df = degfree)
> > >    ht <- list(
> > >      statistic = c(t = tstat),
> > >      parameter = c(df = degfree),
> > >      p.value = p.value,
> > >      alternative = alternative,
> > >      method = method,
> > >      data.name = paste(dataname1, dataname2, sep = ", ")
> > >    )
> > >    class(ht) <- "htest"
> > >    ht
> > > }
> > >
> > > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > >
> > > hutcheson.test(earlier, later)
> > >
> > >
> > >
> > > With the data you provided:
> > >
> > >
> > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > bird_1959 <- c(0,0,14,59,26,68,0)
> > > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > >
> > > hutcheson.test(bird_1956, bird_1957)
> > >
> > >
> > >
> > >
> > > Note that like David said earlier, there might be better ways to
> > > interpret Shannon's diversity index. If h is the sample's diversity,
> > > exp(h) gives the number of equally-common species with equivalent
> > > diversity.
> > >
> > >
> > > s1 <- Shannon(earlier)
> > > s2 <- Shannon(later)
> > > c(earlier = s1, later = s2)
> > > exp(c(earlier = s1, later = s2))   # Both round to 3
> > > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > > Shannon(eq_common)                 # Slightly greater than the samples'
> > > diversity
> > >
> > >
> >
> > # Create a list with all the data
> > birds <- mget(ls(pattern = "^bird"))
> >
> > > round(exp(sapply(birds, Shannon))) # Your data
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > >
> > >
> > > #-------------------------------------
> > >
> > >
> > > Earlier Karl wrote [1] that
> > >
> > >
> > > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > > that explains the minor numerical differences obtained with the code
> > > above and the published variances.
> > >
> > >
> > > I don't believe the published variances were computed with the published
> > > variance estimator. The code below computes the variances like QSutils
> > > and with formula (4) in Hutcheson's paper. The latter does not give the
> > > same results.
> > >
> > > var_est <- function(n){
> > >    s <- length(n)
> > >    N <- sum(n)
> > >    p <- n/N
> > >    i <- p != 0
> > >    inv.p <- numeric(s)
> > >    inv.p[i] <- 1/p[i]
> > >    log.p <- numeric(s)
> > >    log.p[i] <- log(p[i])
> > >    #
> > >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> > >    term2 <- (s - 1)/(2*N^2)
> > >    #
> > >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > > log.p)
> > >    denom3 <- 6*N^3
> > >    term3 <- numer3/denom3
> > >    list(
> > >      Bioc = term1 + term2,
> > >      Hutch = term1 + term2 + term3
> > >    )
> > > }
> > >
> > > Vh1 <- var_est(earlier)
> > > Vh1
> > > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> > >
> > > Vh2 <- var_est(later)
> > > Vh2
> > > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> > >
> > >
> > >
> > > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> > >> Update:
> > >> I can see that you used the function Shannon from the package QSutils.
> > >> This would supplement the iNext package I used and solve the problem.
> > >> Thank you.
> > >>
> > >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> > >> <marongiu.luigi at gmail.com> wrote:
> > >>>
> > >>> Thank you very much for the code, that was very helpful.
> > >>> I got the article by Hutcheson -- I don't know if I can distribute it
> > >>> , given the possible copyrights, or if I can attach it here -- but it
> > >>> does not report numbers directly: it refers to a previous article
> > >>> counting bird death on a telegraph each year. The numbers
> > >>> are:
> > >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > >>> bird_1959 <- c(0,0,14,59,26,68,0)
> > >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > >>>
> > >>> This for sake of the argument.
> > >>> As for my problem, I implemented the Shannon index with the package
> > >>> iNext, which only gives me the index itself and the 95% CI. Even when
> > >>> I implemented it with vegan, I only got the index. Essentially I don't
> > >>> have a count of species I could feed into the Hutcheson's. Is there a
> > >>> way to extract these data? Or to run a Hutcheson's on the final index?
> > >>> Thank you
> > >>>
> > >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> > >>> <karl.schilling at uni-bonn.de> wrote:
> > >>>>
> > >>>> Dear Luigi,
> > >>>>
> > >>>> below some code I cobbled together based on the Hutcheson paper you
> > >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> > >>>> its
> > >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> > >>>> website.
> > >>>>
> > >>>> here is the code, along with an example. I also attach the code as an
> > >>>> R-file.
> > >>>>
> > >>>> Hope that helps.
> > >>>> All my best
> > >>>>
> > >>>> Karl
> > >>>> PS don't forget to adjust for multiple testing if you compare more than
> > >>>> two groups.
> > >>>> K
> > >>>>
> > >>>>
> > >>>> # load package needed
> > >>>> # QSutils is on Bioconductor
> > >>>> library(QSutils)
> > >>>>
> > >>>> # here some exemplary data - these are the data from Pilou 1966 that
> > >>>> are
> > >>>> used
> > >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> > >>>>
> > >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > >>>> # numbers of the first example used by Hutcheson were unfortunately not
> > >>>> # available to me
> > >>>>
> > >>>> # here starts the code ; you may replace the variables "earlier" and
> > >>>> "later"
> > >>>> # by your own numbers.
> > >>>>
> > >>>> # calculate h, var(h) etc
> > >>>> h1 <- Shannon(earlier)
> > >>>> varh1 <- ShannonVar(earlier)
> > >>>> n1 <- sum (earlier)
> > >>>> h2 <- Shannon(later)
> > >>>> varh2 <- ShannonVar(later)
> > >>>> n2 <- sum (later)
> > >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> > >>>>
> > >>>> # compare numbers with those in the paper
> > >>>> h1
> > >>>> h2
> > >>>> varh1
> > >>>> varh2
> > >>>> # I assume that minor numerical differences are due to differences
> > >>>> in the
> > >>>> # numerical precision of computers in the early seventies and today
> > >>>> / KS
> > >>>>
> > >>>> # this is the actual t-test
> > >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> > >>>> p <- 2*pt(-abs(t),df= degfree)
> > >>>> p
> > >>>>
> > >>>> # that's it
> > >>>> # Best
> > >>>> # Karl
> > >>>> --
> > >>>> Karl Schilling, MD
> > >>>> Professor of Anatomy and Cell Biology
> > >>>> Anatomisches Institut
> > >>>> Rheinische Friedrich-Wilhelms-Universit?t
> > >>>> Nussallee 10
> > >>>>
> > >>>> D-53115 Bonn
> > >>>> Germany
> > >>>>
> > >>>> phone ++49-228-73-2602
> > >>>>
> > >>>
> > >>>
> > >>> --
> > >>> Best regards,
> > >>> Luigi
> > >>
> > >>
> > >>
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 11 11:11:51 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 11 Sep 2020 11:11:51 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
Message-ID: <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>

Hello,
I have just realized in the original paper, the t test is defined as:
`t = h1-h2 -(?1?2)/(var1-var2)^1/2`. is the term -(?1?2) missing in
your formula? How to calculate ?1?2?
Thank you

On Thu, Sep 10, 2020 at 2:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Update:
> I also added the confidence interval for the Shannon index:
> ```
> #! Hutcheson's t-test for Shannon diversity equality
> # thanks to Karl Schilling and Rui Barradas
> hutcheson = function(A, B){
>   # compute Shannon index, variance and sum of elements
>   A_index <- Shannon(A)
>   B_index <- Shannon(B)
>   A_var <- ShannonVar(A)
>   B_var <- ShannonVar(B)
>   A_sum <- sum(A)
>   B_sum <- sum(B)
>   # compute Hutcheson
>   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
>   test <- (A_index-B_index) /sqrt(A_var + B_var)
>   p <- 2*pt(-abs(test),df= DF)
>   if (p < 0.001) {
>     P = "<0.001"
>   } else {
>     P = round(p, 3)
>   }
>   if (p < 0.001) {
>     S = "***"
>   } else if (p < 0.01) {
>     S = "**"
>   } else if (p < 0.05) {
>     S = "*"
>   } else {
>     S = ""
>   }
>   # closure
>   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> index first group: \t",
>       round(A_index, 3), " (", round((A_index-2*A_var),3), "-",
> round((A_index+2*A_var),3),
>       ")\n\tShannon index second group: \t",
>       round(B_index, 3), " (", round((B_index-2*B_var),3), "-",
> round((B_index+2*B_var),3),
>       ")\n\tp-value: ", P, " ", S, "\n", sep = "")
>   return(p)
> }
> ```
>
> On Thu, Sep 10, 2020 at 2:10 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > thank you for the code. To explain better, when I used vegan, I did
> > not count the species directly but simply prepared a dataframe where,
> > for each species, I counted the number of samples bearing such
> > species:
> > ```
> >
> > > str(new_df)
> > 'data.frame': 3 obs. of  46 variables:
> >  $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
> >  $ NC_001623 Autographa californica nucl...: int  7 7 7
> >  $ NC_001895 Enterobacteria phage P2       : int  1 0 0
> >  $ NC_004745 Yersinia phage L-413C         : int  1 0 0
> > ```
> > here the triplettes refer to healthy, tumor and metastasis. The outcome is:
> > ```
> > # Shannon index
> > diversity(new_df)
> > #> Normal     Tumour     Metastasis
> > #> 2.520139   3.109512   1.890404
> > ```
> > Using iNext, I provided a list of all the species counted in a samples
> > ```
> > > new_list
> > $Healthy
> >  [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > 0 0 0 0 0 0 0 0 0 0 0 0 0
> >
> > $Tumour
> >  [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
> > 1 2 1 1 1 1 1 1 1 0 0 0 0
> >
> > $Metastasis
> >  [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > 0 0 0 0 0 0 1 0 0 1 1 1 1
> > ```
> > From this I get:
> > ```
> > mod = iNEXT(new_list, q=0, datatype="abundance")
> > mod$AsyEst
> > #Site         Diversity Observed Estimator   s.e.    LCL     UCL
> > #1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
> > #2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
> > #4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
> > #5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
> > #7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
> > #8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
> > ```
> > So here the Shannon index is 12 instead of 2.5...
> > Using Karl's function, I get:
> > ```
> > # compute Shannon
> > norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
> > canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
> > meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
> > norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
> > canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
> > meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
> > norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
> > canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
> > meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
> > # compute Hutcheson
> > degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
> > canc_var**2 /canc_sum)
> > test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
> > (p <- 2*pt(-abs(test),df= degree))
> > > [1] 0.01825784
> > ```
> > remarkably, the indices are the same as obtained by vegan:
> > ```
> > > norm_sIdx
> > [1] 2.520139
> > > canc_sIdx
> > [1] 3.109512
> > > meta_sIdx
> > [1] 1.890404
> > ```
> >
> > I tried Rui's function but I got an error, so I wrote it as
> > ```
> > hutcheson = function(A, B){
> >   # compute Shannon index, variance and sum of elements
> >   A_index <- Shannon(A)
> >   B_index <- Shannon(B)
> >   A_var <- ShannonVar(A)
> >   B_var <- ShannonVar(B)
> >   A_sum <- sum(A)
> >   B_sum <- sum(B)
> >   # compute Hutcheson
> >   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
> >   test <- (A_index-B_index) /sqrt(A_var + B_var)
> >   p <- 2*pt(-abs(test),df= DF)
> >   # closure
> >   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> > index first group: ",
> >       round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
> >       "\n\tp-value : ", round(p, 4), "\n", sep = "")
> >   return(p)
> > }
> > ```
> > and I got:
> > ```
> >
> > > n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 2.5201
> > Shannon index second group: 3.1095
> > p-value : 0.0183
> > > n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 2.5201
> > Shannon index second group: 1.8904
> > p-value : 0.0371
> > > t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 3.1095
> > Shannon index second group: 1.8904
> > p-value : 0
> > ```
> > new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
> > the original Hutcheson data:
> > ```
> > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > hutcheson(bird_1956, bird_1957)
> > Hutcheson's t-test for Shannon diversity equality
> > Shannon index first group: 1.8429
> > Shannon index second group: 1.0689
> > p-value : 0
> >
> > ```
> > This is to compare two groups at the time. I'll probably have to
> > compensate for multiple testing...
> > But if this all OK, then the case is closed.
> > Thank you
> >
> > On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > >
> > > Hello,
> > >
> > > Sorry, there's an instruction missing. See inline.
> > >
> > > ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > > > If you want a function automating Karl's code, here it is. It returns an
> > > > object of S3 class "htest", R's standard for hypothesis tests functions.
> > > > The returned object can then be subset in the usual ways, ht$statistic,
> > > > ht$parameter, ht$p.value, etc.
> > > >
> > > >
> > > > library(QSutils)
> > > >
> > > > hutcheson.test <- function(x1, x2){
> > > >    dataname1 <- deparse(substitute(x1))
> > > >    dataname2 <- deparse(substitute(x2))
> > > >    method <- "Hutcheson's t-test for Shannon diversity equality"
> > > >    alternative <- "the diversities of the two samples are not equal"
> > > >    h1 <- Shannon(x1)
> > > >    varh1 <- ShannonVar(x1)
> > > >    n1 <- sum(x1)
> > > >    h2 <- Shannon(x2)
> > > >    varh2 <- ShannonVar(x2)
> > > >    n2 <- sum(x2)
> > > >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> > > >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> > > >    p.value <- 2*pt(-abs(tstat), df = degfree)
> > > >    ht <- list(
> > > >      statistic = c(t = tstat),
> > > >      parameter = c(df = degfree),
> > > >      p.value = p.value,
> > > >      alternative = alternative,
> > > >      method = method,
> > > >      data.name = paste(dataname1, dataname2, sep = ", ")
> > > >    )
> > > >    class(ht) <- "htest"
> > > >    ht
> > > > }
> > > >
> > > > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > >
> > > > hutcheson.test(earlier, later)
> > > >
> > > >
> > > >
> > > > With the data you provided:
> > > >
> > > >
> > > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > > bird_1959 <- c(0,0,14,59,26,68,0)
> > > > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > >
> > > > hutcheson.test(bird_1956, bird_1957)
> > > >
> > > >
> > > >
> > > >
> > > > Note that like David said earlier, there might be better ways to
> > > > interpret Shannon's diversity index. If h is the sample's diversity,
> > > > exp(h) gives the number of equally-common species with equivalent
> > > > diversity.
> > > >
> > > >
> > > > s1 <- Shannon(earlier)
> > > > s2 <- Shannon(later)
> > > > c(earlier = s1, later = s2)
> > > > exp(c(earlier = s1, later = s2))   # Both round to 3
> > > > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > > > Shannon(eq_common)                 # Slightly greater than the samples'
> > > > diversity
> > > >
> > > >
> > >
> > > # Create a list with all the data
> > > birds <- mget(ls(pattern = "^bird"))
> > >
> > > > round(exp(sapply(birds, Shannon))) # Your data
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > > >
> > > >
> > > > #-------------------------------------
> > > >
> > > >
> > > > Earlier Karl wrote [1] that
> > > >
> > > >
> > > > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > > > that explains the minor numerical differences obtained with the code
> > > > above and the published variances.
> > > >
> > > >
> > > > I don't believe the published variances were computed with the published
> > > > variance estimator. The code below computes the variances like QSutils
> > > > and with formula (4) in Hutcheson's paper. The latter does not give the
> > > > same results.
> > > >
> > > > var_est <- function(n){
> > > >    s <- length(n)
> > > >    N <- sum(n)
> > > >    p <- n/N
> > > >    i <- p != 0
> > > >    inv.p <- numeric(s)
> > > >    inv.p[i] <- 1/p[i]
> > > >    log.p <- numeric(s)
> > > >    log.p[i] <- log(p[i])
> > > >    #
> > > >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> > > >    term2 <- (s - 1)/(2*N^2)
> > > >    #
> > > >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > > > log.p)
> > > >    denom3 <- 6*N^3
> > > >    term3 <- numer3/denom3
> > > >    list(
> > > >      Bioc = term1 + term2,
> > > >      Hutch = term1 + term2 + term3
> > > >    )
> > > > }
> > > >
> > > > Vh1 <- var_est(earlier)
> > > > Vh1
> > > > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > > > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> > > >
> > > > Vh2 <- var_est(later)
> > > > Vh2
> > > > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> > > >
> > > >
> > > >
> > > > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > > Rui Barradas
> > > >
> > > >
> > > > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> > > >> Update:
> > > >> I can see that you used the function Shannon from the package QSutils.
> > > >> This would supplement the iNext package I used and solve the problem.
> > > >> Thank you.
> > > >>
> > > >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> > > >> <marongiu.luigi at gmail.com> wrote:
> > > >>>
> > > >>> Thank you very much for the code, that was very helpful.
> > > >>> I got the article by Hutcheson -- I don't know if I can distribute it
> > > >>> , given the possible copyrights, or if I can attach it here -- but it
> > > >>> does not report numbers directly: it refers to a previous article
> > > >>> counting bird death on a telegraph each year. The numbers
> > > >>> are:
> > > >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > >>> bird_1959 <- c(0,0,14,59,26,68,0)
> > > >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > >>>
> > > >>> This for sake of the argument.
> > > >>> As for my problem, I implemented the Shannon index with the package
> > > >>> iNext, which only gives me the index itself and the 95% CI. Even when
> > > >>> I implemented it with vegan, I only got the index. Essentially I don't
> > > >>> have a count of species I could feed into the Hutcheson's. Is there a
> > > >>> way to extract these data? Or to run a Hutcheson's on the final index?
> > > >>> Thank you
> > > >>>
> > > >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> > > >>> <karl.schilling at uni-bonn.de> wrote:
> > > >>>>
> > > >>>> Dear Luigi,
> > > >>>>
> > > >>>> below some code I cobbled together based on the Hutcheson paper you
> > > >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> > > >>>> its
> > > >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> > > >>>> website.
> > > >>>>
> > > >>>> here is the code, along with an example. I also attach the code as an
> > > >>>> R-file.
> > > >>>>
> > > >>>> Hope that helps.
> > > >>>> All my best
> > > >>>>
> > > >>>> Karl
> > > >>>> PS don't forget to adjust for multiple testing if you compare more than
> > > >>>> two groups.
> > > >>>> K
> > > >>>>
> > > >>>>
> > > >>>> # load package needed
> > > >>>> # QSutils is on Bioconductor
> > > >>>> library(QSutils)
> > > >>>>
> > > >>>> # here some exemplary data - these are the data from Pilou 1966 that
> > > >>>> are
> > > >>>> used
> > > >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> > > >>>>
> > > >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > >>>> # numbers of the first example used by Hutcheson were unfortunately not
> > > >>>> # available to me
> > > >>>>
> > > >>>> # here starts the code ; you may replace the variables "earlier" and
> > > >>>> "later"
> > > >>>> # by your own numbers.
> > > >>>>
> > > >>>> # calculate h, var(h) etc
> > > >>>> h1 <- Shannon(earlier)
> > > >>>> varh1 <- ShannonVar(earlier)
> > > >>>> n1 <- sum (earlier)
> > > >>>> h2 <- Shannon(later)
> > > >>>> varh2 <- ShannonVar(later)
> > > >>>> n2 <- sum (later)
> > > >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> > > >>>>
> > > >>>> # compare numbers with those in the paper
> > > >>>> h1
> > > >>>> h2
> > > >>>> varh1
> > > >>>> varh2
> > > >>>> # I assume that minor numerical differences are due to differences
> > > >>>> in the
> > > >>>> # numerical precision of computers in the early seventies and today
> > > >>>> / KS
> > > >>>>
> > > >>>> # this is the actual t-test
> > > >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> > > >>>> p <- 2*pt(-abs(t),df= degfree)
> > > >>>> p
> > > >>>>
> > > >>>> # that's it
> > > >>>> # Best
> > > >>>> # Karl
> > > >>>> --
> > > >>>> Karl Schilling, MD
> > > >>>> Professor of Anatomy and Cell Biology
> > > >>>> Anatomisches Institut
> > > >>>> Rheinische Friedrich-Wilhelms-Universit?t
> > > >>>> Nussallee 10
> > > >>>>
> > > >>>> D-53115 Bonn
> > > >>>> Germany
> > > >>>>
> > > >>>> phone ++49-228-73-2602
> > > >>>>
> > > >>>
> > > >>>
> > > >>> --
> > > >>> Best regards,
> > > >>> Luigi
> > > >>
> > > >>
> > > >>
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 11 11:39:17 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 11 Sep 2020 11:39:17 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
 <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
Message-ID: <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>

Actually,
in the working example, Hutcheson himself did not report the term
?1?2: `t0 = h1-h2/(var1-var2)^1/2`. so I think we can live without it.
Case closed.
Thank you

On Fri, Sep 11, 2020 at 11:11 AM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have just realized in the original paper, the t test is defined as:
> `t = h1-h2 -(?1?2)/(var1-var2)^1/2`. is the term -(?1?2) missing in
> your formula? How to calculate ?1?2?
> Thank you
>
> On Thu, Sep 10, 2020 at 2:41 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Update:
> > I also added the confidence interval for the Shannon index:
> > ```
> > #! Hutcheson's t-test for Shannon diversity equality
> > # thanks to Karl Schilling and Rui Barradas
> > hutcheson = function(A, B){
> >   # compute Shannon index, variance and sum of elements
> >   A_index <- Shannon(A)
> >   B_index <- Shannon(B)
> >   A_var <- ShannonVar(A)
> >   B_var <- ShannonVar(B)
> >   A_sum <- sum(A)
> >   B_sum <- sum(B)
> >   # compute Hutcheson
> >   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
> >   test <- (A_index-B_index) /sqrt(A_var + B_var)
> >   p <- 2*pt(-abs(test),df= DF)
> >   if (p < 0.001) {
> >     P = "<0.001"
> >   } else {
> >     P = round(p, 3)
> >   }
> >   if (p < 0.001) {
> >     S = "***"
> >   } else if (p < 0.01) {
> >     S = "**"
> >   } else if (p < 0.05) {
> >     S = "*"
> >   } else {
> >     S = ""
> >   }
> >   # closure
> >   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> > index first group: \t",
> >       round(A_index, 3), " (", round((A_index-2*A_var),3), "-",
> > round((A_index+2*A_var),3),
> >       ")\n\tShannon index second group: \t",
> >       round(B_index, 3), " (", round((B_index-2*B_var),3), "-",
> > round((B_index+2*B_var),3),
> >       ")\n\tp-value: ", P, " ", S, "\n", sep = "")
> >   return(p)
> > }
> > ```
> >
> > On Thu, Sep 10, 2020 at 2:10 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > thank you for the code. To explain better, when I used vegan, I did
> > > not count the species directly but simply prepared a dataframe where,
> > > for each species, I counted the number of samples bearing such
> > > species:
> > > ```
> > >
> > > > str(new_df)
> > > 'data.frame': 3 obs. of  46 variables:
> > >  $ NC_001416 Enterobacteria phage lambda   : int  5 4 5
> > >  $ NC_001623 Autographa californica nucl...: int  7 7 7
> > >  $ NC_001895 Enterobacteria phage P2       : int  1 0 0
> > >  $ NC_004745 Yersinia phage L-413C         : int  1 0 0
> > > ```
> > > here the triplettes refer to healthy, tumor and metastasis. The outcome is:
> > > ```
> > > # Shannon index
> > > diversity(new_df)
> > > #> Normal     Tumour     Metastasis
> > > #> 2.520139   3.109512   1.890404
> > > ```
> > > Using iNext, I provided a list of all the species counted in a samples
> > > ```
> > > > new_list
> > > $Healthy
> > >  [1] 5 7 1 1 1 8 1 1 2 1 2 1 1 1 1 2 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > > 0 0 0 0 0 0 0 0 0 0 0 0 0
> > >
> > > $Tumour
> > >  [1] 4 7 0 0 0 7 0 0 1 0 1 0 0 0 0 2 0 0 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1
> > > 1 2 1 1 1 1 1 1 1 0 0 0 0
> > >
> > > $Metastasis
> > >  [1] 5 7 0 0 0 9 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
> > > 0 0 0 0 0 0 1 0 0 1 1 1 1
> > > ```
> > > From this I get:
> > > ```
> > > mod = iNEXT(new_list, q=0, datatype="abundance")
> > > mod$AsyEst
> > > #Site         Diversity Observed Estimator   s.e.    LCL     UCL
> > > #1     Normal  Species richness   18.000    41.368 19.683 23.563 116.155
> > > #2     Normal Shannon diversity   12.430    21.343  5.183 12.430  31.501
> > > #4     Tumour  Species richness   30.000    94.776 42.936 49.848 241.396
> > > #5     Tumour Shannon diversity   22.410    53.135 14.486 24.743  81.526
> > > #7 Metastasis  Species richness   10.000    27.379 22.821 12.443 133.640
> > > #8 Metastasis Shannon diversity    6.622     9.980  3.102  6.622  16.059
> > > ```
> > > So here the Shannon index is 12 instead of 2.5...
> > > Using Karl's function, I get:
> > > ```
> > > # compute Shannon
> > > norm_sIdx <- Shannon(array(as.numeric(unlist(new_list[1]))))
> > > canc_sIdx <- Shannon(array(as.numeric(unlist(new_list[2]))))
> > > meta_sIdx <- Shannon(array(as.numeric(unlist(new_list[3]))))
> > > norm_var <- ShannonVar(array(as.numeric(unlist(new_list[1]))))
> > > canc_var <- ShannonVar(array(as.numeric(unlist(new_list[2]))))
> > > meta_var <- ShannonVar(array(as.numeric(unlist(new_list[3]))))
> > > norm_sum <- sum(array(as.numeric(unlist(new_list[1]))))
> > > canc_sum <- sum(array(as.numeric(unlist(new_list[2]))))
> > > meta_sum <- sum(array(as.numeric(unlist(new_list[3]))))
> > > # compute Hutcheson
> > > degfree <- (norm_var + canc_var)**2 /(norm_var**2/norm_sum +
> > > canc_var**2 /canc_sum)
> > > test <- (norm_sIdx-canc_sIdx) /sqrt(norm_var + canc_var)
> > > (p <- 2*pt(-abs(test),df= degree))
> > > > [1] 0.01825784
> > > ```
> > > remarkably, the indices are the same as obtained by vegan:
> > > ```
> > > > norm_sIdx
> > > [1] 2.520139
> > > > canc_sIdx
> > > [1] 3.109512
> > > > meta_sIdx
> > > [1] 1.890404
> > > ```
> > >
> > > I tried Rui's function but I got an error, so I wrote it as
> > > ```
> > > hutcheson = function(A, B){
> > >   # compute Shannon index, variance and sum of elements
> > >   A_index <- Shannon(A)
> > >   B_index <- Shannon(B)
> > >   A_var <- ShannonVar(A)
> > >   B_var <- ShannonVar(B)
> > >   A_sum <- sum(A)
> > >   B_sum <- sum(B)
> > >   # compute Hutcheson
> > >   DF <- (A_var + B_var)^2 /(A_var^2/A_sum + B_var^2/B_sum)
> > >   test <- (A_index-B_index) /sqrt(A_var + B_var)
> > >   p <- 2*pt(-abs(test),df= DF)
> > >   # closure
> > >   cat("Hutcheson's t-test for Shannon diversity equality\n\tShannon
> > > index first group: ",
> > >       round(A_index, 4), "\n\tShannon index second group: ", round(B_index, 4),
> > >       "\n\tp-value : ", round(p, 4), "\n", sep = "")
> > >   return(p)
> > > }
> > > ```
> > > and I got:
> > > ```
> > >
> > > > n_t = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[2]))))
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 2.5201
> > > Shannon index second group: 3.1095
> > > p-value : 0.0183
> > > > n_m = hutcheson(array(as.numeric(unlist(new_list[1]))), array(as.numeric(unlist(new_list[3]))))
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 2.5201
> > > Shannon index second group: 1.8904
> > > p-value : 0.0371
> > > > t_m = hutcheson(array(as.numeric(unlist(new_list[2]))), array(as.numeric(unlist(new_list[3]))))
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 3.1095
> > > Shannon index second group: 1.8904
> > > p-value : 0
> > > ```
> > > new_list[1]|[2]|[3] refer to healthy, tumor and metastasis. applied to
> > > the original Hutcheson data:
> > > ```
> > > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > hutcheson(bird_1956, bird_1957)
> > > Hutcheson's t-test for Shannon diversity equality
> > > Shannon index first group: 1.8429
> > > Shannon index second group: 1.0689
> > > p-value : 0
> > >
> > > ```
> > > This is to compare two groups at the time. I'll probably have to
> > > compensate for multiple testing...
> > > But if this all OK, then the case is closed.
> > > Thank you
> > >
> > > On Thu, Sep 10, 2020 at 1:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > > >
> > > > Hello,
> > > >
> > > > Sorry, there's an instruction missing. See inline.
> > > >
> > > > ?s 11:44 de 10/09/20, Rui Barradas escreveu:
> > > > > If you want a function automating Karl's code, here it is. It returns an
> > > > > object of S3 class "htest", R's standard for hypothesis tests functions.
> > > > > The returned object can then be subset in the usual ways, ht$statistic,
> > > > > ht$parameter, ht$p.value, etc.
> > > > >
> > > > >
> > > > > library(QSutils)
> > > > >
> > > > > hutcheson.test <- function(x1, x2){
> > > > >    dataname1 <- deparse(substitute(x1))
> > > > >    dataname2 <- deparse(substitute(x2))
> > > > >    method <- "Hutcheson's t-test for Shannon diversity equality"
> > > > >    alternative <- "the diversities of the two samples are not equal"
> > > > >    h1 <- Shannon(x1)
> > > > >    varh1 <- ShannonVar(x1)
> > > > >    n1 <- sum(x1)
> > > > >    h2 <- Shannon(x2)
> > > > >    varh2 <- ShannonVar(x2)
> > > > >    n2 <- sum(x2)
> > > > >    degfree <- (varh1 + varh2)**2 / (varh1**2/n1 + varh2**2/n2)
> > > > >    tstat <- (h1 - h2)/sqrt(varh1 + varh2)
> > > > >    p.value <- 2*pt(-abs(tstat), df = degfree)
> > > > >    ht <- list(
> > > > >      statistic = c(t = tstat),
> > > > >      parameter = c(df = degfree),
> > > > >      p.value = p.value,
> > > > >      alternative = alternative,
> > > > >      method = method,
> > > > >      data.name = paste(dataname1, dataname2, sep = ", ")
> > > > >    )
> > > > >    class(ht) <- "htest"
> > > > >    ht
> > > > > }
> > > > >
> > > > > earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > > > later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > > >
> > > > > hutcheson.test(earlier, later)
> > > > >
> > > > >
> > > > >
> > > > > With the data you provided:
> > > > >
> > > > >
> > > > > bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > > bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > > bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > > > bird_1959 <- c(0,0,14,59,26,68,0)
> > > > > bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > > >
> > > > > hutcheson.test(bird_1956, bird_1957)
> > > > >
> > > > >
> > > > >
> > > > >
> > > > > Note that like David said earlier, there might be better ways to
> > > > > interpret Shannon's diversity index. If h is the sample's diversity,
> > > > > exp(h) gives the number of equally-common species with equivalent
> > > > > diversity.
> > > > >
> > > > >
> > > > > s1 <- Shannon(earlier)
> > > > > s2 <- Shannon(later)
> > > > > c(earlier = s1, later = s2)
> > > > > exp(c(earlier = s1, later = s2))   # Both round to 3
> > > > > eq_common <- rep(1, 3)             # Can be 1 specimen or any other number
> > > > > Shannon(eq_common)                 # Slightly greater than the samples'
> > > > > diversity
> > > > >
> > > > >
> > > >
> > > > # Create a list with all the data
> > > > birds <- mget(ls(pattern = "^bird"))
> > > >
> > > > > round(exp(sapply(birds, Shannon))) # Your data
> > > >
> > > >
> > > > Hope this helps,
> > > >
> > > > Rui Barradas
> > > >
> > > > >
> > > > >
> > > > > #-------------------------------------
> > > > >
> > > > >
> > > > > Earlier Karl wrote [1] that
> > > > >
> > > > >
> > > > > Here var(h) is calculated as in ref 1 cited by Rui Barradas - I guess
> > > > > that explains the minor numerical differences obtained with the code
> > > > > above and the published variances.
> > > > >
> > > > >
> > > > > I don't believe the published variances were computed with the published
> > > > > variance estimator. The code below computes the variances like QSutils
> > > > > and with formula (4) in Hutcheson's paper. The latter does not give the
> > > > > same results.
> > > > >
> > > > > var_est <- function(n){
> > > > >    s <- length(n)
> > > > >    N <- sum(n)
> > > > >    p <- n/N
> > > > >    i <- p != 0
> > > > >    inv.p <- numeric(s)
> > > > >    inv.p[i] <- 1/p[i]
> > > > >    log.p <- numeric(s)
> > > > >    log.p[i] <- log(p[i])
> > > > >    #
> > > > >    term1 <- (sum(p * log.p^2) - sum(p * log.p)^2)/N
> > > > >    term2 <- (s - 1)/(2*N^2)
> > > > >    #
> > > > >    numer3 <- -1 + sum(inv.p) - sum(inv.p * log.p) + sum(inv.p)*sum(p *
> > > > > log.p)
> > > > >    denom3 <- 6*N^3
> > > > >    term3 <- numer3/denom3
> > > > >    list(
> > > > >      Bioc = term1 + term2,
> > > > >      Hutch = term1 + term2 + term3
> > > > >    )
> > > > > }
> > > > >
> > > > > Vh1 <- var_est(earlier)
> > > > > Vh1
> > > > > all.equal(ShannonVar(earlier), Vh1$Bioc)
> > > > > ShannonVar(earlier) - Vh1$Bioc            # FAQ 7.31
> > > > >
> > > > > Vh2 <- var_est(later)
> > > > > Vh2
> > > > > identical(ShannonVar(later), Vh2$Bioc)    # TRUE
> > > > >
> > > > >
> > > > >
> > > > > [1] https://stat.ethz.ch/pipermail/r-help/2020-September/468664.html
> > > > >
> > > > >
> > > > > Hope this helps,
> > > > >
> > > > > Rui Barradas
> > > > >
> > > > >
> > > > > ?s 09:38 de 10/09/20, Luigi Marongiu escreveu:
> > > > >> Update:
> > > > >> I can see that you used the function Shannon from the package QSutils.
> > > > >> This would supplement the iNext package I used and solve the problem.
> > > > >> Thank you.
> > > > >>
> > > > >> On Thu, Sep 10, 2020 at 10:35 AM Luigi Marongiu
> > > > >> <marongiu.luigi at gmail.com> wrote:
> > > > >>>
> > > > >>> Thank you very much for the code, that was very helpful.
> > > > >>> I got the article by Hutcheson -- I don't know if I can distribute it
> > > > >>> , given the possible copyrights, or if I can attach it here -- but it
> > > > >>> does not report numbers directly: it refers to a previous article
> > > > >>> counting bird death on a telegraph each year. The numbers
> > > > >>> are:
> > > > >>> bird_1956 <- c(4,4,190,135,56,3,2,2,1,12,41,201,1,0,131,3)
> > > > >>> bird_1957 <- c(4,111,53,66,146,222,126,61,0,2323,21)
> > > > >>> bird_1958 <- c(0,3,32,228,56,102,0,11,2,220,0)
> > > > >>> bird_1959 <- c(0,0,14,59,26,68,0)
> > > > >>> bird_1960 <- c(0,0,73,66,71,25,0,109,63,1)
> > > > >>>
> > > > >>> This for sake of the argument.
> > > > >>> As for my problem, I implemented the Shannon index with the package
> > > > >>> iNext, which only gives me the index itself and the 95% CI. Even when
> > > > >>> I implemented it with vegan, I only got the index. Essentially I don't
> > > > >>> have a count of species I could feed into the Hutcheson's. Is there a
> > > > >>> way to extract these data? Or to run a Hutcheson's on the final index?
> > > > >>> Thank you
> > > > >>>
> > > > >>> On Tue, Sep 8, 2020 at 7:43 PM Karl Schilling
> > > > >>> <karl.schilling at uni-bonn.de> wrote:
> > > > >>>>
> > > > >>>> Dear Luigi,
> > > > >>>>
> > > > >>>> below some code I cobbled together based on the Hutcheson paper you
> > > > >>>> mentioned. I was lucky to find code to calculate h and, importantly,
> > > > >>>> its
> > > > >>>> variance in the R-package QSutils - you may find it on the Bioconductor
> > > > >>>> website.
> > > > >>>>
> > > > >>>> here is the code, along with an example. I also attach the code as an
> > > > >>>> R-file.
> > > > >>>>
> > > > >>>> Hope that helps.
> > > > >>>> All my best
> > > > >>>>
> > > > >>>> Karl
> > > > >>>> PS don't forget to adjust for multiple testing if you compare more than
> > > > >>>> two groups.
> > > > >>>> K
> > > > >>>>
> > > > >>>>
> > > > >>>> # load package needed
> > > > >>>> # QSutils is on Bioconductor
> > > > >>>> library(QSutils)
> > > > >>>>
> > > > >>>> # here some exemplary data - these are the data from Pilou 1966 that
> > > > >>>> are
> > > > >>>> used
> > > > >>>> # in the second example of Hutcheson, J theor Biol 129:151-154 (1970)
> > > > >>>>
> > > > >>>> earlier <- c(0,0,146,0,5,46,0,1,295,0,0,3,0,0,0,0,0)
> > > > >>>> later <- c(0,0,142,0,5,46,0,1,246,0,0,3,0,0,0,0,0)
> > > > >>>> # numbers of the first example used by Hutcheson were unfortunately not
> > > > >>>> # available to me
> > > > >>>>
> > > > >>>> # here starts the code ; you may replace the variables "earlier" and
> > > > >>>> "later"
> > > > >>>> # by your own numbers.
> > > > >>>>
> > > > >>>> # calculate h, var(h) etc
> > > > >>>> h1 <- Shannon(earlier)
> > > > >>>> varh1 <- ShannonVar(earlier)
> > > > >>>> n1 <- sum (earlier)
> > > > >>>> h2 <- Shannon(later)
> > > > >>>> varh2 <- ShannonVar(later)
> > > > >>>> n2 <- sum (later)
> > > > >>>> degfree <- (varh1 + varh2)**2 /(varh1**2/n1 + varh2**2 /n2)
> > > > >>>>
> > > > >>>> # compare numbers with those in the paper
> > > > >>>> h1
> > > > >>>> h2
> > > > >>>> varh1
> > > > >>>> varh2
> > > > >>>> # I assume that minor numerical differences are due to differences
> > > > >>>> in the
> > > > >>>> # numerical precision of computers in the early seventies and today
> > > > >>>> / KS
> > > > >>>>
> > > > >>>> # this is the actual t-test
> > > > >>>> t <- (h1-h2) /sqrt(varh1 + varh2)
> > > > >>>> p <- 2*pt(-abs(t),df= degfree)
> > > > >>>> p
> > > > >>>>
> > > > >>>> # that's it
> > > > >>>> # Best
> > > > >>>> # Karl
> > > > >>>> --
> > > > >>>> Karl Schilling, MD
> > > > >>>> Professor of Anatomy and Cell Biology
> > > > >>>> Anatomisches Institut
> > > > >>>> Rheinische Friedrich-Wilhelms-Universit?t
> > > > >>>> Nussallee 10
> > > > >>>>
> > > > >>>> D-53115 Bonn
> > > > >>>> Germany
> > > > >>>>
> > > > >>>> phone ++49-228-73-2602
> > > > >>>>
> > > > >>>
> > > > >>>
> > > > >>> --
> > > > >>> Best regards,
> > > > >>> Luigi
> > > > >>
> > > > >>
> > > > >>
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide
> > > > > http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From k@r|@@ch||||ng @end|ng |rom un|-bonn@de  Fri Sep 11 14:36:01 2020
From: k@r|@@ch||||ng @end|ng |rom un|-bonn@de (Karl Schilling)
Date: Fri, 11 Sep 2020 14:36:01 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
 <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
 <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>
Message-ID: <bf1a4363-f49c-93cd-5c4d-ddf206b60e9e@uni-bonn.de>

Dear Luigi:

no, ?1?2 is not "missing"

First, it should actually be "?1 - ?2".

And as your usual null-hypothesis when comparing h1 and h2 is that they 
are not different (i.e. ?1 = ?2), the latter term adds up to 0 and may 
be omitted.

Karl Schilling


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Sep 11 14:41:36 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 11 Sep 2020 14:41:36 +0200
Subject: [R] Some code to run Hutcheson t-test using R
In-Reply-To: <bf1a4363-f49c-93cd-5c4d-ddf206b60e9e@uni-bonn.de>
References: <CAMk+s2RCugWDzGgfA1=sb=sqR+7bcrkcQuhQ1_CZ6pfj-JoSxw@mail.gmail.com>
 <163f8f33-eadc-b277-624d-0b4f85ff576c@uni-bonn.de>
 <CAMk+s2QDwOEPJ8Gc9RHQNJHp7MYv0jdCDcwB3O+u66xEE3NwYg@mail.gmail.com>
 <405df5ef-2b0a-af11-8112-44ad4ebebecf@uni-bonn.de>
 <CAMk+s2TNXH6GjLiGyeUnQ6GEpMK7y2CUrhExzWmvS6Zt0ycPOw@mail.gmail.com>
 <CAMk+s2Q+ZbdZPZF8HKcwhU0rbzQ6qy9jOyxg5=4DVPcCWeBmmw@mail.gmail.com>
 <5ef9e3e4-f2e7-cc2c-2504-da8d67ba877c@sapo.pt>
 <e4a841ea-656a-ce03-cc2a-867d3b2fa5f3@sapo.pt>
 <CAMk+s2RbCjoeVzP7WbUx+9_CSXn+9kbX5TNCEyqptZJfd5_X4A@mail.gmail.com>
 <CAMk+s2QFdir9t2MJkBnBjrmJyGWK7VWXo8PzZ8SEVMyf2Ls4gA@mail.gmail.com>
 <CAMk+s2TayKaK=aR33G7WFMchVZ_sqty1FwJRc4_kyp5iDTHa4w@mail.gmail.com>
 <CAMk+s2R4xQfXEV23Wa7bxZ9AFCCNYPP-2CQY-kGZEpn108Mepg@mail.gmail.com>
 <bf1a4363-f49c-93cd-5c4d-ddf206b60e9e@uni-bonn.de>
Message-ID: <CAMk+s2RcicQctoGoqr5t2LzmpmfCd326KFzYhufHSOe6wYZ5ig@mail.gmail.com>

Thank you for the clarification.

On Fri, Sep 11, 2020 at 2:36 PM Karl Schilling
<karl.schilling at uni-bonn.de> wrote:
>
> Dear Luigi:
>
> no, ?1?2 is not "missing"
>
> First, it should actually be "?1 - ?2".
>
> And as your usual null-hypothesis when comparing h1 and h2 is that they
> are not different (i.e. ?1 = ?2), the latter term adds up to 0 and may
> be omitted.
>
> Karl Schilling



-- 
Best regards,
Luigi


From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Sep 11 16:37:45 2020
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 11 Sep 2020 09:37:45 -0500
Subject: [R] Adjusting The size and Orientation of x-axis labes for Pareto
 Charts
Message-ID: <CAMOcQfPqt7z=psP2FdwukTtQYVHBsEB-Uy=4xwQcAhx8wbRa6g@mail.gmail.com>

Dear friends,

Hope you are doing well. I am currently using R version 3.6.2. I installed
and loaded package qcc by Mr. Luca Scrucca.

I generated the pareto chart using qcc?s pareto.chart function, but when
the graph gets generated, the x-axis labels aren?t fully shown, and so the
text can?t be viewed properly.

Is there any way to adjust the x-axis labels (font and orientation), so
that they can be easily shown?

This is the structure of my data:

str(dataset2)
'data.frame':   140 obs. of  2 variables:
 $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
106 65 17 ...
 $ Points: num  55 43 24 21 20 20 18 17 16 16 ...


Below is the dput() of my dataset.

dput(dataset2)
structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L,
116L, 35L, 106L, 65L, 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L,
114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L, 76L, 19L, 25L, 93L,
14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L,
125L, 2L, 129L, 71L, 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L,
80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L, 138L, 126L, 34L, 135L,
5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L, 112L,
32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L,
99L, 56L, 9L, 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L,
134L, 122L, 124L, 128L, 94L, 130L, 92L, 33L, 6L, 26L, 113L, 27L,
69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L, 62L, 89L, 90L,
91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
"Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza",
"Anc?n", "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete",
"Barrio Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur",
"Bejuco", "Belisario Fr?as", "Belisario Porras", "Bella Vista",
"Betania", "Buena Vista", "Burunga", "Calidonia", "Ca?averal",
"Canto del Llano", "Capira", "Cativ?", "Cerme?o", "Cerro Silvestre",
"Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
"Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
"David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo",
"El Coco", "El Espino", "El Guabo", "El Harino", "El Higo", "El Llano",
"El Roble", "El Valle", "Ernesto C?rdoba Campos", "Escobal",
"Feuillet", "Garrote o Puerto Lindo", "Guadalupe", "Herrera",
"Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde", "Jos? Domingo
Espinar",
"Juan Dem?stenes Arosemena", "Juan D?az", "La Concepci?n", "La Ensenada",
"La Laguna", "La Mesa", "La Raya de Calobre", "La Represa", "Las Cumbres",
"Las Lajas", "Las Ma?anitas", "Las Ollas Arriba", "L?dice", "Lim?n",
"Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo Iturralde",
"Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
"Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?",
"Omar Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre",
"Pedas?", "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?",
"Portobelo", "Pueblo Nuevo", "Puerto Armuelles", "Puerto Caimito",
"Puerto Pil?n", "Punta Chame", "Rio Abajo", "R?o Abajo", "R?o Grande",
"R?o Hato", "R?o Indio", "Rufina Alfaro", "Sabanagrande", "Sabanitas",
"Sajalices", "Salamanca", "San Carlos", "San Felipe", "San Francisco",
"San Jos?", "San Juan", "San Juan Bautista", "San Mart?n", "San Mart?n de
Porres",
"Santa Ana", "Santa Clara", "Santa Fe", "Santa Isabel", "Santa Rita",
"Santa Rosa", "Santiago", "Santiago Este", "Tinajas", "Tocumen",
"Veracruz", "Victoriano Lorenzo", "Villa Rosario", "Vista Alegre"
), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18,
17, 16, 16, 15, 13, 13, 12, 12, 11, 11, 11, 11, 11, 10, 9, 9,
9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6, 6, 6,
6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4,
4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA, -140L
), class = "data.frame")

Best regards,

Paul

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Sep 11 16:59:41 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 11 Sep 2020 14:59:41 +0000
Subject: [R] 
 Adjusting The size and Orientation of x-axis labes for Pareto Charts
In-Reply-To: <CAMOcQfPqt7z=psP2FdwukTtQYVHBsEB-Uy=4xwQcAhx8wbRa6g@mail.gmail.com>
References: <CAMOcQfPqt7z=psP2FdwukTtQYVHBsEB-Uy=4xwQcAhx8wbRa6g@mail.gmail.com>
Message-ID: <96aa8426e71642d2962f1a0c269088a5@SRVEXCHCM1302.precheza.cz>

Hi.

You could try call pareto.chart with las=2 option.

See ?par.

But I am not sure if it will work as I do not have experience with this.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Paul Bernal
> Sent: Friday, September 11, 2020 4:38 PM
> To: R <r-help at r-project.org>
> Subject: [R] Adjusting The size and Orientation of x-axis labes for Pareto
> Charts
> 
> Dear friends,
> 
> Hope you are doing well. I am currently using R version 3.6.2. I installed and
> loaded package qcc by Mr. Luca Scrucca.
> 
> I generated the pareto chart using qcc?s pareto.chart function, but when the
> graph gets generated, the x-axis labels aren?t fully shown, and so the text
> can?t be viewed properly.
> 
> Is there any way to adjust the x-axis labels (font and orientation), so that they
> can be easily shown?
> 
> This is the structure of my data:
> 
> str(dataset2)
> 'data.frame':   140 obs. of  2 variables:
>  $ School: Factor w/ 140 levels "24 de Diciembre",..: 39 29 66 16 67 116 35
> 106 65 17 ...
>  $ Points: num  55 43 24 21 20 20 18 17 16 16 ...
> 
> 
> Below is the dput() of my dataset.
> 
> dput(dataset2)
> structure(list(School = structure(c(39L, 29L, 66L, 16L, 67L, 116L, 35L, 106L, 65L,
> 17L, 12L, 55L, 136L, 8L, 24L, 140L, 123L, 114L, 22L, 15L, 98L, 4L, 107L, 110L, 20L,
> 76L, 19L, 25L, 93L, 14L, 46L, 7L, 104L, 121L, 23L, 88L, 74L, 41L, 103L, 59L, 96L,
> 95L, 30L, 109L, 117L, 132L, 47L, 21L, 137L, 79L, 115L, 101L, 125L, 2L, 129L, 71L,
> 73L, 58L, 127L, 131L, 78L, 18L, 50L, 100L, 80L, 37L, 38L, 108L, 40L, 85L, 86L, 45L,
> 138L, 126L, 34L, 135L, 5L, 1L, 31L, 82L, 87L, 63L, 105L, 68L, 28L, 72L, 111L, 49L,
> 112L, 32L, 70L, 10L, 3L, 118L, 44L, 133L, 57L, 48L, 64L, 97L, 43L, 99L, 56L, 9L,
> 119L, 61L, 77L, 81L, 51L, 11L, 52L, 42L, 60L, 53L, 134L, 122L, 124L, 128L, 94L,
> 130L, 92L, 33L, 6L, 26L, 113L, 27L, 69L, 36L, 75L, 102L, 83L, 84L, 120L, 13L, 54L,
> 62L, 89L, 90L, 91L, 139L), .Label = c("24 de Diciembre", "Achiote", "Aguadulce",
> "Alcalde D?az", "Alto Boquete", "Amador", "Amelia Denis de Icaza", "Anc?n",
> "Ant?n", "Arnulfo Arias", "Arosemena", "Arraij?n", "Bajo Boquete", "Barrio
> Balboa", "Barrio Col?n", "Barrio Norte", "Barrio Sur", "Bejuco", "Belisario
> Fr?as", "Belisario Porras", "Bella Vista", "Betania", "Buena Vista", "Burunga",
> "Calidonia", "Ca?averal", "Canto del Llano", "Capira", "Cativ?", "Cerme?o",
> "Cerro Silvestre", "Chame", "Chepo", "Chic?", "Chilibre", "Chitr?", "Ciricito",
> "Comarca Guna de Madugand?", "Crist?bal", "Crist?bal Este", "Curund?",
> "David", "Don Bosco", "El Arado", "El Ca?o", "El Chorrillo", "El Coco", "El
> Espino", "El Guabo", "El Harino", "El Higo", "El Llano", "El Roble", "El Valle",
> "Ernesto C?rdoba Campos", "Escobal", "Feuillet", "Garrote o Puerto Lindo",
> "Guadalupe", "Herrera", "Hurtado", "Isla de Ca?as", "Isla Grande", "Iturralde",
> "Jos? Domingo Espinar", "Juan Dem?stenes Arosemena", "Juan D?az", "La
> Concepci?n", "La Ensenada", "La Laguna", "La Mesa", "La Raya de Calobre",
> "La Represa", "Las Cumbres", "Las Lajas", "Las Ma?anitas", "Las Ollas Arriba",
> "L?dice", "Lim?n", "Los D?az", "Los Llanitos", "Mar?a Chiquita", "Mateo
> Iturralde", "Miguel de la Borda", "Nombre de Dios", "Nueva Providencia",
> "Nuevo Chagres", "Nuevo Emperador", "Obald?a", "Oc?", "Ol?", "Omar
> Torrijos", "Pacora", "Pajonal", "Palmas Bellas", "Parque Lefevre", "Pedas?",
> "Pedregal", "Penonom?", "Pi?a", "Playa Leona", "Pocr?", "Portobelo", "Pueblo
> Nuevo", "Puerto Armuelles", "Puerto Caimito", "Puerto Pil?n", "Punta
> Chame", "Rio Abajo", "R?o Abajo", "R?o Grande", "R?o Hato", "R?o Indio",
> "Rufina Alfaro", "Sabanagrande", "Sabanitas", "Sajalices", "Salamanca", "San
> Carlos", "San Felipe", "San Francisco", "San Jos?", "San Juan", "San Juan
> Bautista", "San Mart?n", "San Mart?n de Porres", "Santa Ana", "Santa Clara",
> "Santa Fe", "Santa Isabel", "Santa Rita", "Santa Rosa", "Santiago", "Santiago
> Este", "Tinajas", "Tocumen", "Veracruz", "Victoriano Lorenzo", "Villa Rosario",
> "Vista Alegre"
> ), class = "factor"), Points = c(55, 43, 24, 21, 20, 20, 18, 17, 16, 16, 15, 13, 13,
> 12, 12, 11, 11, 11, 11, 11, 10, 9, 9, 9, 9, 9, 8, 8, 8, 8, 8, 7, 7, 7, 7, 7, 7, 7, 6, 6, 6, 6,
> 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,
> 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)),
> row.names = c(NA, -140L ), class = "data.frame")
> 
> Best regards,
> 
> Paul
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

