From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Dec  1 02:33:52 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 1 Dec 2020 14:33:52 +1300
Subject: [R] A new versatile discrete distribution.
Message-ID: <20201201143352.1234d7b4@rolf-Latitude-E7470>


To all and sundry, near and far,
F. Christmas in particular ...

	--- A. A. Milne

Just ignore that second line .... :-)

A new package of mine, "hse", has just become available on CRAN.
The source package is there; Uwe Ligges has informed me that the
Windoze binary has been built so it should appear shortly.  I'm sure
that the Mac OSX binary will appear in due course.

The package provides tools for working with a new distribution for
discrete data with finitely many values.  I have found this
distribution to be useful for handling data to which the "standard"
discrete distributions (binomial, Poisson, geometric, ...) do not
readily apply.  My hope is that others will likewise find the "hse"
distribution to be useful.  In particular it could have application to
survey responses measured on an ordered discrete (e.g. 1 to 7 or
1 to 10) scale.

I would of course be grateful for any feedback, comments, criticisms,
corrections, etc.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Dec  1 17:16:39 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 1 Dec 2020 16:16:39 +0000
Subject: [R] PCA biplot customising point shape and legend
Message-ID: <1888b9aeb734425fb784814a167704c8@SRVEXCHCM1302.precheza.cz>

Dear all

 

I am struggling to customise biplot from FactoMineR pacakge

 

My code is almost correct but piece of information is missing

 

Here is data

 

temp  <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L, 94479L, 

76563L, 141667L, 111042L, 93333L, 132083L, 103542L, 61667L, 77708L

), macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2, 

89.71, 98, 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58, 2.71, 

0.92, 1, 24.25, 9.29, 1.5, 15.08, 0.92, 0.67, 1), lymphocyte28 = c(1.13, 

0.29, 0.25, 0.54, 0.54, 0.55, 1, 0.5, 2.92, 0.25, 0.25, 0.46), 

    leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L, 

    156250L, 250625L, 183125L, 202917L, 161875L, 184792L, 128333L

    ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3, 

    82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75, 

    3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67, 

    1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3, 

    1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L, 

    3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = c("alumina", 

    "both", "none", "phosphate", "silica", "tungsten", "zirconia"

    ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L, 

    2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", "pigmentary"

    ), class = "factor")), class = "data.frame", row.names = c("G1-1", 

"G2-5", "G3-1", "G4-19", "G5-4", "G6-3", "G7-5", "G8-2", "G9-5", 

"G10-4", "E171-E", "Bayertitan T"))

 

and the code

 

library(factoextra)

library(factoMineR)

 

fit <- PCA(temp[,1:9], quali.sup=9)

 

fviz_pca_biplot(fit, col.ind = temp$coating, repel=T, col.var = "black",

palette = "lancet", invisible="quali", pointsize=5, pointshape=temp$size,

legend.title = list(col = "Coating"),

xlim=c(-6,6), title="Instillation results")

 

Which is quite close. Point shapes are triangles and circles in biplot, but
I would like to add them into legend too. If possible I would like to have
also filled shapes instead of open circle and triangle.

I tried many combinations, aded the size variable into PCA, scale_shape and
other options from ggplot but I was not able to get correct second legend
(size).

Any hint is greatly wellcommed.

 

Best regards.

Petr

 


From dpweyg@nd @end|ng |rom gm@||@com  Tue Dec  1 19:51:01 2020
From: dpweyg@nd @end|ng |rom gm@||@com (Dennis Weygand)
Date: Tue, 1 Dec 2020 13:51:01 -0500
Subject: [R] Readxl on Mac
Message-ID: <CAJgAAVTbA7-baa9c1Hsv1txDY1Jc7AeHH1RLL90Q5biP9vt8Zw@mail.gmail.com>

>From the following lines of code on an iMac running Catalina 10.15.7


library(readxl)
fname <-  "/Volumes/SD/LabData/Lorentz/Lorentz.xlsx"

Helm <- read_excel(fname,sheet="Helmholtz")

I get the following annoying error:
Error: Evaluation error: zip file

To me this makes no sense: the file in question is not a zip file. The
excel file in question, however, is either open on excel, or recently
opened in excel.
Does anyone know about this error, and what to do about it?
I am running R version 3.5.1

Thanks for any assistance you can provide.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Dec  1 20:21:10 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 1 Dec 2020 14:21:10 -0500
Subject: [R] Readxl on Mac
In-Reply-To: <CAJgAAVTbA7-baa9c1Hsv1txDY1Jc7AeHH1RLL90Q5biP9vt8Zw@mail.gmail.com>
References: <CAJgAAVTbA7-baa9c1Hsv1txDY1Jc7AeHH1RLL90Q5biP9vt8Zw@mail.gmail.com>
Message-ID: <96f985bd-57b3-424a-b175-c34cb9261311@gmail.com>

On 01/12/2020 1:51 p.m., Dennis Weygand wrote:
>  From the following lines of code on an iMac running Catalina 10.15.7
> 
> 
> library(readxl)
> fname <-  "/Volumes/SD/LabData/Lorentz/Lorentz.xlsx"
> 
> Helm <- read_excel(fname,sheet="Helmholtz")
> 
> I get the following annoying error:
> Error: Evaluation error: zip file
> 
> To me this makes no sense: the file in question is not a zip file. The
> excel file in question, however, is either open on excel, or recently
> opened in excel.
> Does anyone know about this error, and what to do about it?
> I am running R version 3.5.1
> 
> Thanks for any assistance you can provide.

The .xlsx file format is actually a zip file containing a number of XML 
files.  I'd guess that Excel locks it when it's open, to stop two 
spreadsheets from opening it at once.

So the error message could be more informative, but it's probably 
accurately reporting the immediate problem.

Duncan Murdoch


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Dec  1 20:28:37 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 1 Dec 2020 14:28:37 -0500
Subject: [R] Readxl on Mac
In-Reply-To: <CAJgAAVTbA7-baa9c1Hsv1txDY1Jc7AeHH1RLL90Q5biP9vt8Zw@mail.gmail.com>
References: <CAJgAAVTbA7-baa9c1Hsv1txDY1Jc7AeHH1RLL90Q5biP9vt8Zw@mail.gmail.com>
Message-ID: <75EE2F8F-76E0-4C13-B28A-BBF81D032B9A@me.com>


> On Dec 1, 2020, at 1:51 PM, Dennis Weygand <dpweygand at gmail.com> wrote:
> 
> From the following lines of code on an iMac running Catalina 10.15.7
> 
> 
> library(readxl)
> fname <-  "/Volumes/SD/LabData/Lorentz/Lorentz.xlsx"
> 
> Helm <- read_excel(fname,sheet="Helmholtz")
> 
> I get the following annoying error:
> Error: Evaluation error: zip file
> 
> To me this makes no sense: the file in question is not a zip file. The
> excel file in question, however, is either open on excel, or recently
> opened in excel.
> Does anyone know about this error, and what to do about it?
> I am running R version 3.5.1
> 
> Thanks for any assistance you can provide.


Hi,

Current generation MS Office files (ending with an 'x' in the file extension) are ZIP compressed XML files. Thus, the zip error is relevant.

If the file that you are referencing actually exists, since the error can indicate a non-existent file (error in name and/or path), it is possible that the file is still open, and read_excel() presumably requires an exclusive read on the file, thus cannot open it in that manner.

You might be sure that the file is not in use by Excel or another application, precluding an exclusive lock on the file. If so, close out the other application.

Another possibility is that the Excel file is password protected, and thus cannot be read directly, without saving it in an unprotected fashion.

Regards,

Marc Schwartz


From r@ywong @end|ng |rom t@mu@edu  Tue Dec  1 20:54:00 2020
From: r@ywong @end|ng |rom t@mu@edu (Raymond Wong)
Date: Tue, 1 Dec 2020 13:54:00 -0600
Subject: [R] 2021 John M. Chambers Software Award
Message-ID: <52186554-A25B-4942-B5D1-085119F92F41@tamu.edu>

Dear R-help listers,

I would like to let you know that the submission window of the John M. Chambers Software Award is now open. The submission deadline is December 15, 2020.

The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery (ACM) presented the ACM Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student.

Please visit http://asa.stat.uconn.edu for more information.

Best regards,

Raymond Wong

Awards Chair
ASA Section on Statistical Computing

Associate Professor
Department of Statistics
Texas A&M University

From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Dec  2 11:32:02 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 2 Dec 2020 11:32:02 +0100
Subject: [R] scott-knot ESD effect size test
Message-ID: <CA+nrPnv5sfdZ-353WnQa0wC=J=LaRsTs+xFUW_q3HZFVn8=tDQ@mail.gmail.com>

I have the following data from resample

svm= svm$resample$RMSE
nn= nn$resample$RMSE

we perform the statistical tests like

wilcox.test(svm, nn)

I have a question, can we perform the scott-knot ESD test here? if yes, how?

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Wed Dec  2 11:54:29 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Wed, 2 Dec 2020 10:54:29 +0000
Subject: [R] scott-knot ESD effect size test
In-Reply-To: <CA+nrPnv5sfdZ-353WnQa0wC=J=LaRsTs+xFUW_q3HZFVn8=tDQ@mail.gmail.com>
References: <CA+nrPnv5sfdZ-353WnQa0wC=J=LaRsTs+xFUW_q3HZFVn8=tDQ@mail.gmail.com>
Message-ID: <a8c56cea-0d7e-8f9f-370e-2f7b44a24228@dewey.myzen.co.uk>

There seems to be a package on CRAN dedicated exclusively to this test. 
It is called ScottKnotESD rather unoriginally.

Michael.

On 02/12/2020 10:32, Neha gupta wrote:
> I have the following data from resample
> 
> svm= svm$resample$RMSE
> nn= nn$resample$RMSE
> 
> we perform the statistical tests like
> 
> wilcox.test(svm, nn)
> 
> I have a question, can we perform the scott-knot ESD test here? if yes, how?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Dec  2 12:09:59 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 2 Dec 2020 12:09:59 +0100
Subject: [R] scott-knot ESD effect size test
In-Reply-To: <a8c56cea-0d7e-8f9f-370e-2f7b44a24228@dewey.myzen.co.uk>
References: <CA+nrPnv5sfdZ-353WnQa0wC=J=LaRsTs+xFUW_q3HZFVn8=tDQ@mail.gmail.com>
 <a8c56cea-0d7e-8f9f-370e-2f7b44a24228@dewey.myzen.co.uk>
Message-ID: <CA+nrPnvGTT3QeXyf0JeK3vWEhUugSdNWbG4E7G=Kr5XykT3UkQ@mail.gmail.com>

Thank you Michael,

But when we use the package, how to perform the test?

library(ScottKnottESD)

Can we do like

sk <- sk_esd(svm, nn) to measure the effect size between the svm and nn ?





On Wed, Dec 2, 2020 at 11:54 AM Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> There seems to be a package on CRAN dedicated exclusively to this test.
> It is called ScottKnotESD rather unoriginally.
>
> Michael.
>
> On 02/12/2020 10:32, Neha gupta wrote:
> > I have the following data from resample
> >
> > svm= svm$resample$RMSE
> > nn= nn$resample$RMSE
> >
> > we perform the statistical tests like
> >
> > wilcox.test(svm, nn)
> >
> > I have a question, can we perform the scott-knot ESD test here? if yes,
> how?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From edrenth @end|ng |rom |ry@ke-@k@demy@n|  Wed Dec  2 13:42:19 2020
From: edrenth @end|ng |rom |ry@ke-@k@demy@n| (Eduard Drenth)
Date: Wed, 2 Dec 2020 12:42:19 +0000
Subject: [R] calling r from java
In-Reply-To: <f3180f4d80dcdc1a8bb6b1809bb82ae7e24595c8.camel@fryske-akademy.nl>
References: <fa5236c2ca174ba8e839129cb0b6b047527a0f67.camel@fryske-akademy.nl>
 <CAB8pepxoOo-=Nj7c0Jhk443AVsZANw_H7J0iTn8tZ0OhMKFVhw@mail.gmail.com>
 <d44b09923c04e49e95f57d2714af14ae609ca64e.camel@fryske-akademy.nl>
 <6d917f8f1c537cdb4afcfba1de75b35b4b6da206.camel@fryske-akademy.nl>
 <f3180f4d80dcdc1a8bb6b1809bb82ae7e24595c8.camel@fryske-akademy.nl>
Message-ID: <f257fa11ab502e70968cbac3cb0293646c74429a.camel@fryske-akademy.nl>

For those interested, I succeeded in creating a stable, fast Java/R
connection using https://search.maven.org/search?q=g:org.rosuda.REngine
. The whole solution has a maven/docker setup making it reproducable.



-----Original Message-----
From: Eduard Drenth <edrenth at fryske-akademy.nl>
To: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] calling r from java
Date: Mon, 30 Nov 2020 08:36:16 +0000

sun.misc that is
-----Original Message-----From: Eduard Drenth <
edrenth at fryske-akademy.nl>To: r-help at r-project.org <
r-help at r-project.org>Subject: Re: [R] calling r from javaDate: Mon, 30
Nov 2020 07:18:46 +0000
First attempts to use jri on ubuntu 20.04 stranded.Steps I followed:1)
download rJava from https://www.rforge.net/rJava/files/
2) create a symlink /usr/lib/libjvm.so to /usr/lib/jvm/java-8-openjdk-
amd64/jre/lib/amd64/server/libjvm.so3) configure and make jri4) createa
symlink /usr/lib/libjri.so5) put the built JRI.jar in local mavenrepo6)
include a dependency to the jar7) create and run a hello worldtest for
RengineThe test fails because com.misc.Unsafe.prefetchRead isn't found.
AsIunderstand depending on com.misc.Unsafe.* is a risk.I will not
follow this route any further for now, though I stillthinkhaving jri
available would be great. Steps to get there are Ithink:1) remove
com.misc.Unsafe usage from the solution2) make libjriavailable in
repositories (apt, yum, other)3) make JRI.jar available inmaven
centralBye, Eduard-----Original Message-----From: Eduard Drenth
<edrenth at fryske-akademy.nl>To: spurdle.a at gmail.com
<spurdle.a at gmail.com>Cc: r-help at r-project.org <r-help at r-
project.org>Subject: Re: [R] callingr from javaDate: Sat, 28 Nov 2020
11:57:49 +0000Thanks all, I'll go for https://www.rforge.net/JRI/ and
thelibrariesinmaven https://search.maven.org/search?q=jri

The maven library is build from  here 
https://www.rforge.net/rJava/files/ back in 2017.After this no new
libsare published to maven.It would be nice (understatement) if
publishingnew rJava componentstomaven becomes a regular part of R
deveopmentprocesses.This would promote R use from Java which I think is
good.Andof course I can help.Bye, Eduard-----Original Message-----From: 
AbbySpurdle <spurdle.a at gmail.com>To:Eduard Drenth <edrenth at fryske-
akademy.nl>Cc: r-help at r-project.org <r-help at r-project.org>Subject:
Re:[R] calling r from javaDate: Sat, 28Nov 2020 15:55:36 +1300Hi
Eduard,
> Now I developed a service that
> executesRscript(UsingProcessBuilder),sends text to stdin of the
> process andreadsfromstdout of theprocess.

This doesn't answer your question, but may be relevant.I have a java-
based application that works on a similar
principle.(Thecodeishorrendously bad and most of it should be thrown
away).I'mplanningto write a terminal emulator, in the
nearfuture.(Currently,secondplace on my top-level todo list).The
primary objective is tobuildobject-oriented and messagepassingAPIs on
top of the coreterminalemulation system, with at leastsomecross
platformfunctionality.Notingthat, in my opinion, the cross-platform
aspect ismoreimportant for R,than in many other IPC topics.Hence, I'm
interestedin hearing"wishlist" items
forsuchAPIs.______________________________________________R-help at r-
project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained,
reproduciblecode.______________________________________________R-
help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.______________________________________________R-help at r-project.org 
mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-- 
Eduard Drenth, Software Architekt

edrenth at fryske-akademy.nl

Doelestrjitte 8
8911 DX  Ljouwert
+31 58 234 30 47
+31 62 094 34 28 (priv?)

skype: eduarddrenth
https://github.com/eduarddrenth
frisian.eu
gpg: https://pgp.surfnet.nl/pks/lookup?search=eduarddrenth


Op freed bin ik th?s/wurkje ik minder





-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201202/07017b30/attachment.sig>

From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Dec  2 15:14:50 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 2 Dec 2020 08:14:50 -0600
Subject: [R] Add a third .libPath
References: <001001d6c8b5$80629b30$8127d190$.ref@sbcglobal.net>
Message-ID: <001001d6c8b5$80629b30$8127d190$@sbcglobal.net>

r-help Forum

 

My employer has not yet approved R/RStudio but has allowed me to run
R/RStudio from profile.  I need to add RTools but not sure I can run RTools
from the same location.  

So I unzipped Rtools and added the folder to my profile location containing
R and RStudio and then modified my Rprofile adding a third path to the
RTools folder as follows:

 

# my custom stuff

myPaths <- c(.libPaths(), "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
<file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> ")

.libPaths(myPaths)

 

Not sure if this is the best method but seems to work;

 

> .libPaths()

[1] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0
<file://gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0> "

[2] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library
<file://gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library> "

[3] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
<file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> "  

 

except when I run 

 

> has_rtools()

WARNING: Rtools is required to build R packages, but is not currently
installed.

 

Please download and install Rtools 4.0 from
https://cran.r-project.org/bin/windows/Rtools/.

 

I am assuming R isn't seeing Rtools

 

So can I run Rtools from the same profile location as R and RStudio? IF so
what do I need to do?

 

Jeff Reichman

 


	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Dec  2 16:20:16 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 2 Dec 2020 10:20:16 -0500
Subject: [R] Add a third .libPath
In-Reply-To: <001001d6c8b5$80629b30$8127d190$@sbcglobal.net>
References: <001001d6c8b5$80629b30$8127d190$.ref@sbcglobal.net>
 <001001d6c8b5$80629b30$8127d190$@sbcglobal.net>
Message-ID: <3bbf8f0c-29db-bc67-6112-099f86104e18@gmail.com>

You are mixing up two different things.

The .libPaths() function returns paths where R searches for R packages.

Rtools is not an R package, it is a collection of utilities and support 
files to run in Windows.

For Rtools to be found, you need to add it to the Windows PATH variable, 
not to .libPaths().  You can see the current value of PATH by running 
this in R:

Sys.getenv("PATH")

This will give a long string variable with various directories separated 
by semicolons.  You want to make sure it contains the Rtools40 
executable directory (typically "C:/Rtools40/usr/bin", though for you it 
might be "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40/usr/bin").  If 
it doesn't (which would cause has_rtools() to fail, so I'll assume it's 
not in yours) you can add it temporarily using

Sys.setenv(PATH = paste(Sys.getenv("PATH"), 
"\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40/usr/bin", sep = ";"))

For a permanent addition you need to edit the system PATH setting.  You 
should probably ask an admin to do that for you.

Duncan Murdoch


On 02/12/2020 9:14 a.m., Jeff Reichman wrote:
> r-help Forum
> 
>   
> 
> My employer has not yet approved R/RStudio but has allowed me to run
> R/RStudio from profile.  I need to add RTools but not sure I can run RTools
> from the same location.
> 
> So I unzipped Rtools and added the folder to my profile location containing
> R and RStudio and then modified my Rprofile adding a third path to the
> RTools folder as follows:
> 
>   
> 
> # my custom stuff
> 
> myPaths <- c(.libPaths(), "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
> <file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> ")
> 
> .libPaths(myPaths)
> 
>   
> 
> Not sure if this is the best method but seems to work;
> 
>   
> 
>> .libPaths()
> 
> [1] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0
> <file://gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0> "
> 
> [2] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library
> <file://gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library> "
> 
> [3] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
> <file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> "
> 
>   
> 
> except when I run
> 
>   
> 
>> has_rtools()
> 
> WARNING: Rtools is required to build R packages, but is not currently
> installed.
> 
>   
> 
> Please download and install Rtools 4.0 from
> https://cran.r-project.org/bin/windows/Rtools/.
> 
>   
> 
> I am assuming R isn't seeing Rtools
> 
>   
> 
> So can I run Rtools from the same profile location as R and RStudio? IF so
> what do I need to do?
> 
>   
> 
> Jeff Reichman
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Dec  2 16:33:09 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 02 Dec 2020 07:33:09 -0800
Subject: [R] Add a third .libPath
In-Reply-To: <3bbf8f0c-29db-bc67-6112-099f86104e18@gmail.com>
References: <001001d6c8b5$80629b30$8127d190$.ref@sbcglobal.net>
 <001001d6c8b5$80629b30$8127d190$@sbcglobal.net>
 <3bbf8f0c-29db-bc67-6112-099f86104e18@gmail.com>
Message-ID: <673B4966-3ABC-4C2A-8F47-DE80A41EE8B4@dcn.davis.ca.us>

Current versions of Windows support user environment variables also, so having Administrator change the PATH should not be necessary.

On December 2, 2020 7:20:16 AM PST, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>You are mixing up two different things.
>
>The .libPaths() function returns paths where R searches for R packages.
>
>Rtools is not an R package, it is a collection of utilities and support
>
>files to run in Windows.
>
>For Rtools to be found, you need to add it to the Windows PATH
>variable, 
>not to .libPaths().  You can see the current value of PATH by running 
>this in R:
>
>Sys.getenv("PATH")
>
>This will give a long string variable with various directories
>separated 
>by semicolons.  You want to make sure it contains the Rtools40 
>executable directory (typically "C:/Rtools40/usr/bin", though for you
>it 
>might be "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40/usr/bin"). 
>If 
>it doesn't (which would cause has_rtools() to fail, so I'll assume it's
>
>not in yours) you can add it temporarily using
>
>Sys.setenv(PATH = paste(Sys.getenv("PATH"), 
>"\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40/usr/bin", sep = ";"))
>
>For a permanent addition you need to edit the system PATH setting.  You
>
>should probably ask an admin to do that for you.
>
>Duncan Murdoch
>
>
>On 02/12/2020 9:14 a.m., Jeff Reichman wrote:
>> r-help Forum
>> 
>>   
>> 
>> My employer has not yet approved R/RStudio but has allowed me to run
>> R/RStudio from profile.  I need to add RTools but not sure I can run
>RTools
>> from the same location.
>> 
>> So I unzipped Rtools and added the folder to my profile location
>containing
>> R and RStudio and then modified my Rprofile adding a third path to
>the
>> RTools folder as follows:
>> 
>>   
>> 
>> # my custom stuff
>> 
>> myPaths <- c(.libPaths(),
>"\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
>> <file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> ")
>> 
>> .libPaths(myPaths)
>> 
>>   
>> 
>> Not sure if this is the best method but seems to work;
>> 
>>   
>> 
>>> .libPaths()
>> 
>> [1] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0
>> <file://gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0> "
>> 
>> [2] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library
>> <file://gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library> "
>> 
>> [3] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
>> <file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> "
>> 
>>   
>> 
>> except when I run
>> 
>>   
>> 
>>> has_rtools()
>> 
>> WARNING: Rtools is required to build R packages, but is not currently
>> installed.
>> 
>>   
>> 
>> Please download and install Rtools 4.0 from
>> https://cran.r-project.org/bin/windows/Rtools/.
>> 
>>   
>> 
>> I am assuming R isn't seeing Rtools
>> 
>>   
>> 
>> So can I run Rtools from the same profile location as R and RStudio?
>IF so
>> what do I need to do?
>> 
>>   
>> 
>> Jeff Reichman
>> 
>>   
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Dec  2 17:08:00 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Wed, 2 Dec 2020 10:08:00 -0600
Subject: [R] Add a third .libPath
In-Reply-To: <3bbf8f0c-29db-bc67-6112-099f86104e18@gmail.com>
References: <001001d6c8b5$80629b30$8127d190$.ref@sbcglobal.net>
 <001001d6c8b5$80629b30$8127d190$@sbcglobal.net>
 <3bbf8f0c-29db-bc67-6112-099f86104e18@gmail.com>
Message-ID: <005d01d6c8c5$4f7330b0$ee599210$@sbcglobal.net>

Duncan

Yea sort of knew that (lib path) but was hoping .... Anyway I'm sure our IT folks will allow your suggestion while they go about their actions to cert R / RStudio.

Jeff Newmiller provided another option too.

Jeff

-----Original Message-----
From: Duncan Murdoch <murdoch.duncan at gmail.com> 
Sent: Wednesday, December 2, 2020 9:20 AM
To: reichmanj at sbcglobal.net; r-help at r-project.org
Subject: Re: [R] Add a third .libPath

You are mixing up two different things.

The .libPaths() function returns paths where R searches for R packages.

Rtools is not an R package, it is a collection of utilities and support files to run in Windows.

For Rtools to be found, you need to add it to the Windows PATH variable, not to .libPaths().  You can see the current value of PATH by running this in R:

Sys.getenv("PATH")

This will give a long string variable with various directories separated by semicolons.  You want to make sure it contains the Rtools40 executable directory (typically "C:/Rtools40/usr/bin", though for you it might be "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40/usr/bin").  If it doesn't (which would cause has_rtools() to fail, so I'll assume it's not in yours) you can add it temporarily using

Sys.setenv(PATH = paste(Sys.getenv("PATH"), "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40/usr/bin", sep = ";"))

For a permanent addition you need to edit the system PATH setting.  You should probably ask an admin to do that for you.

Duncan Murdoch


On 02/12/2020 9:14 a.m., Jeff Reichman wrote:
> r-help Forum
> 
>   
> 
> My employer has not yet approved R/RStudio but has allowed me to run 
> R/RStudio from profile.  I need to add RTools but not sure I can run 
> RTools from the same location.
> 
> So I unzipped Rtools and added the folder to my profile location 
> containing R and RStudio and then modified my Rprofile adding a third 
> path to the RTools folder as follows:
> 
>   
> 
> # my custom stuff
> 
> myPaths <- c(.libPaths(), 
> "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
> <file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> ")
> 
> .libPaths(myPaths)
> 
>   
> 
> Not sure if this is the best method but seems to work;
> 
>   
> 
>> .libPaths()
> 
> [1] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0
> <file://gold/home/ndw003/reichmjs/MyDocs/R/win-library/4.0> "
> 
> [2] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library
> <file://gold/home/ndw003/reichmjs/MyDocs/R/R-40.3/library> "
> 
> [3] "\\\\gold/home/ndw003/reichmjs/MyDocs/R/rtools40
> <file://gold/home/ndw003/reichmjs/MyDocs/R/rtools40> "
> 
>   
> 
> except when I run
> 
>   
> 
>> has_rtools()
> 
> WARNING: Rtools is required to build R packages, but is not currently 
> installed.
> 
>   
> 
> Please download and install Rtools 4.0 from 
> https://cran.r-project.org/bin/windows/Rtools/.
> 
>   
> 
> I am assuming R isn't seeing Rtools
> 
>   
> 
> So can I run Rtools from the same profile location as R and RStudio? 
> IF so what do I need to do?
> 
>   
> 
> Jeff Reichman
> 
>   
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From gm@ne @end|ng |rom kno@o|@co@uk  Wed Dec  2 03:25:33 2020
From: gm@ne @end|ng |rom kno@o|@co@uk (Derek Jones)
Date: Wed, 2 Dec 2020 02:25:33 +0000
Subject: [R] RGB -> CYMK, with consistent colors
In-Reply-To: <CAGAA5bcZMLXm6-3izgs8hw26PKOem_e8zf3D4=YEEyuuZv2MTQ@mail.gmail.com>
References: <rpupql$99c$1@ciao.gmane.io>
 <CAGAA5bfU3vrdCHCfZC9yY8Vb_MENY--BjE=5Pz+paTO98Aa_dg@mail.gmail.com>
 <e8a1008c-82bf-b1a0-953a-bbedccee04a9@knosof.co.uk>
 <CAGAA5betTMJu5yKDev5q2P7sBoTYEcub4y7q-haO7yk5n5v06g@mail.gmail.com>
 <65f2cb57-0b88-9de9-acee-97c224f0d64d@knosof.co.uk>
 <CAGAA5bcZMLXm6-3izgs8hw26PKOem_e8zf3D4=YEEyuuZv2MTQ@mail.gmail.com>
Message-ID: <rq6tut$bqs$1@ciao.gmane.io>

Martin,

> However after some testing.
> I totally agree that CMYK handling in R using pdf(..., colormodel = "cmyk")
> is not correct.

Looking at the source code of the function PostScriptSetCol
in file src/librarygrDevices/src/devPS.c
the conversion to CMYK looks correct.

Looking at the generated pdf (qpdf: https://github.com/qpdf/qpdf is
needed to uncompress the pdf)
the numeric color values look correct, although the pdf contents don't exactly
match those generated by PostScriptSetCol

It is possible the problem is in the conversion that occurs when
displaying/printing a pdf.


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Wed Dec  2 18:53:41 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Wed, 2 Dec 2020 17:53:41 +0000
Subject: [R] change frequency of wind data correctly
Message-ID: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>

Dear list users,
I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.

The simple code here reported works well, but the column "interval" groups data forward, not backward:

init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
mydf$vmax <- round(rnorm(13, 35, 10))
mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
means <- aggregate(vmax ~ interval, mydf, mean)

    data_POSIX                  vmax  interval
1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
...

I should work with

    data_POSIX                  vmax  interval
1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
...


Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)

Thank you for your help
Stefano



         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From iuke-tier@ey m@iii@g oii uiow@@edu  Wed Dec  2 22:44:58 2020
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Wed, 2 Dec 2020 15:44:58 -0600 (CST)
Subject: [R] 
 [External] Why is R making a copy-on-modification after using str?
In-Reply-To: <alpine.DEB.2.21.2011301224020.3003@luke-Latitude-7480>
References: <trinity-4420798e-945f-4280-a3cc-b59fe317de08-1606731160638@3c-app-gmx-bs55>
 <alpine.DEB.2.21.2011301224020.3003@luke-Latitude-7480>
Message-ID: <alpine.DEB.2.21.2012021540290.3003@luke-Latitude-7480>

On Mon, 30 Nov 2020, luke-tierney at uiowa.edu wrote:

> On Mon, 30 Nov 2020, Georg Kindermann wrote:
>
>> Dear list members,
>> 
>> I was wondering why R is making a copy-on-modification after using str.
>> 
>> m <- matrix(1:12, 3)
>> tracemem(m)
>> #[1] "<0x559df861af28>"
>> dim(m) <- 4:3
>> m[1,1] <- 0L
>> m[] <- 12:1
>> str(m)
>> # int [1:4, 1:3] 12 11 10 9 8 7 6 5 4 3 ...
>> dim(m) <- 3:4  #Here after str a copy is made
>> #tracemem[0x559df861af28 -> 0x559df838e4a8]:
>> dim(m) <- 3:4
>> str(m)
>> # int [1:3, 1:4] 12 11 10 9 8 7 6 5 4 3 ...
>> dim(m) <- 3:4 #Here again after str a copy
>> #tracemem[0x559df838e4a8 -> 0x559df82c9d78]:
>
> As of R 4.0.0 it is in some cases possible to reduce reference counts
> internally and so avoid a copy in cases like this. It would be too
> costly to try to detect all cases where a count can be dropped, but it
> this case we can do better. It turns out that the internals of
> pos.to.env were unnecessarily creating an extra reference to the call
> environment (here in a call to exists()). This is fixed in r79528.
> Thanks.
>
>> Also I was wondering why a copy is made when having a Task Callback.
>> 
>> TCB <- addTaskCallback(function(...) TRUE)
>> m <- matrix(1:12, nrow = 3)
>> tracemem(m)
>> #[1] "<0x559dfa79def8>"
>> dim(m) <- 4:3  #Copy on modification
>> #tracemem[0x559dfa79def8 -> 0x559dfa8998e8]:
>> removeTaskCallback(TCB)
>> #[1] TRUE
>> dim(m) <- 4:3  #No copy
>> 
>
> This _may_ be related to references created in the process of
> protecting the return value from evaluation. If so, addressing the
> debug issue raised by Duncan may resolve this. If not, someone will
> have to take a closer look.

It turns out there were some issues with the way calls to the
callbacks were handled. This has been revised in R-devel in r79541.
This example will no longere need to duplicate in R-devel.

Thanks for the report.

luke

>
> Best,
>
> luke
>
>> I am using R version 4.0.3.
>> 
>> Kind regards,
>> Georg
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From drj|m|emon @end|ng |rom gm@||@com  Thu Dec  3 04:10:40 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 3 Dec 2020 14:10:40 +1100
Subject: [R] change frequency of wind data correctly
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
Message-ID: <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>

Hi Stefano,
I read in your date-time as two separate fields for convenience. You
can split your single field at the space to get the same result.

ssdf<-read.table(text="date_POSIX time_POSIX vmax
 2018-02-01 00:00:00 27
 2018-02-01 00:10:00 41
 2018-02-01 00:20:00 46
 2018-02-01 00:30:00 39
 2018-02-01 00:40:00 34
 2018-02-01 00:50:00 32",
 header=TRUE,stringsAsFactors=FALSE)
# get the time of day as seconds from the time field
ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
# subtract whatever current date strptime guesses for the date
ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
# create an AM/PM variable
ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
means<-aggregate(vmax~ampm,ssdf,mean)

Jim

On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear list users,
> I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
> I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.
>
> The simple code here reported works well, but the column "interval" groups data forward, not backward:
>
> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> mydf$vmax <- round(rnorm(13, 35, 10))
> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> means <- aggregate(vmax ~ interval, mydf, mean)
>
>     data_POSIX                  vmax  interval
> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> ...
>
> I should work with
>
>     data_POSIX                  vmax  interval
> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> ...
>
>
> Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)
>
> Thank you for your help
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Dec  3 04:41:06 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 3 Dec 2020 14:41:06 +1100
Subject: [R] change frequency of wind data correctly
In-Reply-To: <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>
Message-ID: <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>

Hi again,
Didn't realize that the example didn't even span a full day.

ssdf<-read.table(text="date_POSIX time_POSIX vmax
 2018-02-01 00:00:00 27
 2018-02-01 00:10:00 41
 2018-02-01 00:20:00 46
 2018-02-01 00:30:00 39
 2018-02-01 00:40:00 34
 2018-02-01 00:50:00 32
 2018-02-01 01:00:00 37
 2018-02-01 01:10:00 31
 2018-02-01 01:20:00 26
 2018-02-01 01:30:00 29
 2018-02-01 01:40:00 24
 2018-02-01 01:50:00 35",
 header=TRUE,stringsAsFactors=FALSE)
# extract the hour
ssdf$hour<-
 as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",1)))
# get the time of day as seconds from the time field
ssdf$mins<-
 as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",2)))
# create an AM/PM variable
ssdf$ampm<-ifelse(ssdf$mins > 0 & ssdf$mins <= 30,"am","pm")
# drop first row
ssdf<-ssdf[-1,]
means<-aggregate(vmax~hour+ampm,ssdf,mean)

This does a full day. To do more, add the date_POSIX field to the
aggregate command. If you have the date and time in one field you'll
have to split that. That will distinguish the AM/PM means in each day
as well as hour.

Jim

On Thu, Dec 3, 2020 at 2:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Stefano,
> I read in your date-time as two separate fields for convenience. You
> can split your single field at the space to get the same result.
>
> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>  2018-02-01 00:00:00 27
>  2018-02-01 00:10:00 41
>  2018-02-01 00:20:00 46
>  2018-02-01 00:30:00 39
>  2018-02-01 00:40:00 34
>  2018-02-01 00:50:00 32",
>  header=TRUE,stringsAsFactors=FALSE)
> # get the time of day as seconds from the time field
> ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
> # subtract whatever current date strptime guesses for the date
> ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
> # create an AM/PM variable
> ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
> means<-aggregate(vmax~ampm,ssdf,mean)
>
> Jim
>
> On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear list users,
> > I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
> > I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.
> >
> > The simple code here reported works well, but the column "interval" groups data forward, not backward:
> >
> > init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> > mydf$vmax <- round(rnorm(13, 35, 10))
> > mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> > means <- aggregate(vmax ~ interval, mydf, mean)
> >
> >     data_POSIX                  vmax  interval
> > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> > 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> > 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> > ...
> >
> > I should work with
> >
> >     data_POSIX                  vmax  interval
> > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> > 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> > 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> > ...
> >
> >
> > Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)
> >
> > Thank you for your help
> > Stefano
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo----------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona
> > Uff: 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> > This message was scanned by Libra ESVA and is believed to be clean.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Thu Dec  3 10:23:22 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Thu, 3 Dec 2020 09:23:22 +0000
Subject: [R] change frequency of wind data correctly
In-Reply-To: <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>,
 <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F80A02FBA@ESINO.regionemarche.intra>

Thank you Jim for your solution.
I understood everything. As you say, splitting the POSIXct field is the key.

I apologise for not having used dput. I never used it but I will get aknowleged with it in a short time.

Thank you
Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: gioved? 3 dicembre 2020 4.41
A: Stefano Sofia
Cc: r-help mailing list
Oggetto: Re: [R] change frequency of wind data correctly

Hi again,
Didn't realize that the example didn't even span a full day.

ssdf<-read.table(text="date_POSIX time_POSIX vmax
 2018-02-01 00:00:00 27
 2018-02-01 00:10:00 41
 2018-02-01 00:20:00 46
 2018-02-01 00:30:00 39
 2018-02-01 00:40:00 34
 2018-02-01 00:50:00 32
 2018-02-01 01:00:00 37
 2018-02-01 01:10:00 31
 2018-02-01 01:20:00 26
 2018-02-01 01:30:00 29
 2018-02-01 01:40:00 24
 2018-02-01 01:50:00 35",
 header=TRUE,stringsAsFactors=FALSE)
# extract the hour
ssdf$hour<-
 as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",1)))
# get the time of day as seconds from the time field
ssdf$mins<-
 as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",2)))
# create an AM/PM variable
ssdf$ampm<-ifelse(ssdf$mins > 0 & ssdf$mins <= 30,"am","pm")
# drop first row
ssdf<-ssdf[-1,]
means<-aggregate(vmax~hour+ampm,ssdf,mean)

This does a full day. To do more, add the date_POSIX field to the
aggregate command. If you have the date and time in one field you'll
have to split that. That will distinguish the AM/PM means in each day
as well as hour.

Jim

On Thu, Dec 3, 2020 at 2:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Stefano,
> I read in your date-time as two separate fields for convenience. You
> can split your single field at the space to get the same result.
>
> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>  2018-02-01 00:00:00 27
>  2018-02-01 00:10:00 41
>  2018-02-01 00:20:00 46
>  2018-02-01 00:30:00 39
>  2018-02-01 00:40:00 34
>  2018-02-01 00:50:00 32",
>  header=TRUE,stringsAsFactors=FALSE)
> # get the time of day as seconds from the time field
> ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
> # subtract whatever current date strptime guesses for the date
> ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
> # create an AM/PM variable
> ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
> means<-aggregate(vmax~ampm,ssdf,mean)
>
> Jim
>
> On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear list users,
> > I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
> > I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.
> >
> > The simple code here reported works well, but the column "interval" groups data forward, not backward:
> >
> > init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> > mydf$vmax <- round(rnorm(13, 35, 10))
> > mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> > means <- aggregate(vmax ~ interval, mydf, mean)
> >
> >     data_POSIX                  vmax  interval
> > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> > 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> > 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> > ...
> >
> > I should work with
> >
> >     data_POSIX                  vmax  interval
> > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> > 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> > 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> > ...
> >
> >
> > Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)
> >
> > Thank you for your help
> > Stefano
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo----------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona
> > Uff: 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> > This message was scanned by Libra ESVA and is believed to be clean.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> > and provide commented, minimal, self-contained, reproducible code.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From jo@e@t@d|@t|co @end|ng |rom gm@||@com  Thu Dec  3 12:06:46 2020
From: jo@e@t@d|@t|co @end|ng |rom gm@||@com (=?UTF-8?Q?Jos=C3=A9_Luis_Aguilar?=)
Date: Thu, 3 Dec 2020 12:06:46 +0100
Subject: [R] Download data ph soil
Message-ID: <CACt-d0jb_T5A54OyVuj-FzHvhYvgLdBqsY7RqOcZ7VLhTsk3Hg@mail.gmail.com>

Dear list members,

I am looking for soil pH data for Europe and Africa, but I don't.
I need them to set up a map in R for my research.

Please, someone where to find this data in tif formats preferably.

thank you

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Dec  3 12:40:35 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 3 Dec 2020 22:40:35 +1100
Subject: [R] Download data ph soil
In-Reply-To: <CACt-d0jb_T5A54OyVuj-FzHvhYvgLdBqsY7RqOcZ7VLhTsk3Hg@mail.gmail.com>
References: <CACt-d0jb_T5A54OyVuj-FzHvhYvgLdBqsY7RqOcZ7VLhTsk3Hg@mail.gmail.com>
Message-ID: <CA+8X3fU12-6B3Huc7pV8NY3kjDt7ZKpwQy-XLxzkBvWUx_wU-Q@mail.gmail.com>

Hi Jose,
Searching for "soil pH data" reveals a bucketload of sites with this
sort of data in lots of formats.

Jim



On Thu, Dec 3, 2020 at 10:07 PM Jos? Luis Aguilar
<josestadistico at gmail.com> wrote:
>
> Dear list members,
>
> I am looking for soil pH data for Europe and Africa, but I don't.
> I need them to set up a map in R for my research.
>
> Please, someone where to find this data in tif formats preferably.
>
> thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d|ego@hern@ngomezherrero @end|ng |rom gm@||@com  Thu Dec  3 10:10:56 2020
From: d|ego@hern@ngomezherrero @end|ng |rom gm@||@com (=?UTF-8?Q?Diego_Hernang=C3=B3mez_Herrero?=)
Date: Thu, 3 Dec 2020 10:10:56 +0100
Subject: [R] [R-pkgs] mapSpain on CRAN
Message-ID: <CAA-ibaw1T1uvV+DTYSmq1HZQZkH-sCcW3WMvXm+Y2-=sxzv8oQ@mail.gmail.com>

Dear R users:

mapSpain is now available on CRAN. This package provides the administrative
boundaries of Spain at several levels: all NUTS levels, Autonomous
Communities , Provinces and municipalities (sf objects).

The package also has the ability of downloading WMS/WMTS geotagged images
of different public organisms of Spain for static  maps, a leaflet plugin
for the same providers to use with R leaflet and many other features.

Full documentation and vignettes on:

https://dieghernan.github.io/mapSpain/


Hope this can be useful, regards
-- 



Have a nice day!

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ||@| @end|ng |rom m@||@n|h@gov  Thu Dec  3 20:25:24 2020
From: ||@| @end|ng |rom m@||@n|h@gov (Li, Aiguo (NIH/NCI) [E])
Date: Thu, 3 Dec 2020 19:25:24 +0000
Subject: [R] A general question about targeted sequencing data analysis
Message-ID: <DM6PR09MB5303524B04E525B3E4E43A38EFF20@DM6PR09MB5303.namprd09.prod.outlook.com>

Dear all,

One of our PIs has a targeted sequencing dataset generated a while ago.  He is interested in finding out VAF of a group of genes.  This is the first dataset of this types we have.  I would be appreciative for any suggestions on pipelines for analyzing this type of data.

Thanks

Anna

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Dec  4 01:09:24 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 03 Dec 2020 16:09:24 -0800
Subject: [R] A general question about targeted sequencing data analysis
In-Reply-To: <DM6PR09MB5303524B04E525B3E4E43A38EFF20@DM6PR09MB5303.namprd09.prod.outlook.com>
References: <DM6PR09MB5303524B04E525B3E4E43A38EFF20@DM6PR09MB5303.namprd09.prod.outlook.com>
Message-ID: <E8CB3980-AAE3-4F16-8026-A8F8E40F8675@dcn.davis.ca.us>

My suggestion would be to ask this question in a forum devoted to that topic, such as the Bioconductor forum [1].

[1] https://www.bioconductor.org/help/support/

On December 3, 2020 11:25:24 AM PST, "Li, Aiguo (NIH/NCI) [E] via R-help" <r-help at r-project.org> wrote:
>Dear all,
>
>One of our PIs has a targeted sequencing dataset generated a while ago.
>He is interested in finding out VAF of a group of genes.  This is the
>first dataset of this types we have.  I would be appreciative for any
>suggestions on pipelines for analyzing this type of data.
>
>Thanks
>
>Anna
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Fri Dec  4 04:12:15 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Fri, 4 Dec 2020 08:12:15 +0500
Subject: [R] Save Results in svg format
Message-ID: <CAG0CrLi8K6_eCzn6169iEdjju48VSvDNzE-dfhSouxHWXK7euQ@mail.gmail.com>

#Loading the required libraries
library(ape)
library(phangorn)
library(seqinr)
#Importing the required file
align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format = "fast")
align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format = "fasta")
Computing the distance matrix for both UPGMA and NJ algorithms implementation.
 matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
summary(matrix_5x5)

matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
summary(matrix_119x119)
#Implementation of UPGMA algorithm for a small matrix (5x5) and entire
matrix (119x119)
UPGMA_5x5 <- upgma(matrix_5x5)
UPGMA_119x119 <- upgma(matrix_119x119)
summary(UPGMA_5x5)

summary(UPGMA_119x119)
#Implementation of NJ algorithm for a small matrix (5x5) and entire
matrix (119x119)
NJ_5x5 <- NJ(matrix_5x5)
NJ_119x119 <- NJ(matrix_119x119)
summary(NJ_5x5)

summary(NJ_119x119)


I have done this whole analysis but don't know how can I  the save my
tree file in svg or some other image format

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec  4 04:24:59 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 3 Dec 2020 19:24:59 -0800
Subject: [R] Save Results in svg format
In-Reply-To: <CAG0CrLi8K6_eCzn6169iEdjju48VSvDNzE-dfhSouxHWXK7euQ@mail.gmail.com>
References: <CAG0CrLi8K6_eCzn6169iEdjju48VSvDNzE-dfhSouxHWXK7euQ@mail.gmail.com>
Message-ID: <CAGxFJbREba1LuEvHxM9Eo_nZT04=eNsBUdOc76r-K_PmLsinew@mail.gmail.com>

Warning: I have basically no idea what you are doing. I presume that you
have consulted ?svg, however. If not , you should probably do so.

Also, a search on "save as svg" on rseek.org  brought up the svglite
package, among other resources. You might want to see what that offers.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 3, 2020 at 7:12 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> #Loading the required libraries
> library(ape)
> library(phangorn)
> library(seqinr)
> #Importing the required file
> align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format = "fast")
> align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format =
> "fasta")
> Computing the distance matrix for both UPGMA and NJ algorithms
> implementation.
>  matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
> summary(matrix_5x5)
>
> matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
> summary(matrix_119x119)
> #Implementation of UPGMA algorithm for a small matrix (5x5) and entire
> matrix (119x119)
> UPGMA_5x5 <- upgma(matrix_5x5)
> UPGMA_119x119 <- upgma(matrix_119x119)
> summary(UPGMA_5x5)
>
> summary(UPGMA_119x119)
> #Implementation of NJ algorithm for a small matrix (5x5) and entire
> matrix (119x119)
> NJ_5x5 <- NJ(matrix_5x5)
> NJ_119x119 <- NJ(matrix_119x119)
> summary(NJ_5x5)
>
> summary(NJ_119x119)
>
>
> I have done this whole analysis but don't know how can I  the save my
> tree file in svg or some other image format
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @@m@nz@h|d22 @end|ng |rom gm@||@com  Fri Dec  4 04:54:16 2020
From: @@m@nz@h|d22 @end|ng |rom gm@||@com (Saman Zahid)
Date: Fri, 4 Dec 2020 04:54:16 +0100
Subject: [R] Is there any criteria to compare different models?
Message-ID: <CADdX5hkG9wbXjfL16M3xKgNgmJWxz2+oCwkKUUc79sjtAGgwOg@mail.gmail.com>

Hi,

I am trying to make comparison between the lm, gam(mgcv) and lme(nlme)
models. The problem is I am not able to find a single criterion on which
these 3 models are comparable.

I am using method "ML" for both gam and lme, yet the AIC and BIC formulas
differ due to the degrees of freedom.

Is there any statistical way to compare these three models?

I will really appreciate your help.

Thanks
Saman Zahid

	[[alternative HTML version deleted]]


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Fri Dec  4 05:16:25 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Fri, 4 Dec 2020 09:16:25 +0500
Subject: [R] How to save Results in svg format
Message-ID: <CAG0CrLjntRNJe0FvbA9FOj3F+GVFpE=zg+ar35V_KGf2CBJ9oA@mail.gmail.com>

#Loading the required libraries
library(ape)
library(phangorn)
library(seqinr)
#Importing the required file
align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format = "fast")
align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format = "fasta")
Computing the distance matrix for both UPGMA and NJ algorithms implementation.
 matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
summary(matrix_5x5)

matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
summary(matrix_119x119)
#Implementation of UPGMA algorithm for a small matrix (5x5) and entire
matrix (119x119)
UPGMA_5x5 <- upgma(matrix_5x5)
UPGMA_119x119 <- upgma(matrix_119x119)
summary(UPGMA_5x5)

summary(UPGMA_119x119)
#Implementation of NJ algorithm for a small matrix (5x5) and entire
matrix (119x119)
NJ_5x5 <- NJ(matrix_5x5)
NJ_119x119 <- NJ(matrix_119x119)
summary(NJ_5x5)

summary(NJ_119x119)


I have done this whole analysis but don't know how can I  the save my
tree file in svg or some other image format . In the avove script , I
am applying the phylogenetic algorithm on the distance matrix which I
have created through fasta file

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Dec  4 06:01:45 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 3 Dec 2020 21:01:45 -0800
Subject: [R] Is there any criteria to compare different models?
In-Reply-To: <CADdX5hkG9wbXjfL16M3xKgNgmJWxz2+oCwkKUUc79sjtAGgwOg@mail.gmail.com>
References: <CADdX5hkG9wbXjfL16M3xKgNgmJWxz2+oCwkKUUc79sjtAGgwOg@mail.gmail.com>
Message-ID: <CAGxFJbT9UFkafQE98gZM4zSAoL06wwbu9fGCvEiKHC8BvXToqQ@mail.gmail.com>

Per the posting guide linked below (have you read it??):

"*Questions about statistics:* The R mailing lists are primarily intended
for questions and discussion about the R software. However, questions about
statistical methodology are sometimes posted. If the question is well-asked
and of interest to someone on the list, it *may* elicit an informative
up-to-date answer. See also the Usenet groups sci.stat.consult (applied
statistics and consulting) and sci.stat.math (mathematical stat and
probability).*"*

So don't be surprised if you don't receive any response.

You might also try posting at stats.stackexchange.com. No guarantees there
either.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 3, 2020 at 8:09 PM Saman Zahid <samanzahid22 at gmail.com> wrote:

> Hi,
>
> I am trying to make comparison between the lm, gam(mgcv) and lme(nlme)
> models. The problem is I am not able to find a single criterion on which
> these 3 models are comparable.
>
> I am using method "ML" for both gam and lme, yet the AIC and BIC formulas
> differ due to the degrees of freedom.
>
> Is there any statistical way to compare these three models?
>
> I will really appreciate your help.
>
> Thanks
> Saman Zahid
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Dec  4 06:10:14 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 3 Dec 2020 21:10:14 -0800
Subject: [R] Save Results in svg format
In-Reply-To: <CAG0CrLi8K6_eCzn6169iEdjju48VSvDNzE-dfhSouxHWXK7euQ@mail.gmail.com>
References: <CAG0CrLi8K6_eCzn6169iEdjju48VSvDNzE-dfhSouxHWXK7euQ@mail.gmail.com>
Message-ID: <ff123b2a-83f2-4914-31fe-56f02ecf7a6e@comcast.net>


On 12/3/20 7:12 PM, Anas Jamshed wrote:
> #Loading the required libraries
> library(ape)
> library(phangorn)
> library(seqinr)
> #Importing the required file
> align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format = "fast")
> align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format = "fasta")
> Computing the distance matrix for both UPGMA and NJ algorithms implementation.
>   matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
> summary(matrix_5x5)
>
> matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
> summary(matrix_119x119)
> #Implementation of UPGMA algorithm for a small matrix (5x5) and entire
> matrix (119x119)
> UPGMA_5x5 <- upgma(matrix_5x5)
> UPGMA_119x119 <- upgma(matrix_119x119)
> summary(UPGMA_5x5)
>
> summary(UPGMA_119x119)
> #Implementation of NJ algorithm for a small matrix (5x5) and entire
> matrix (119x119)
> NJ_5x5 <- NJ(matrix_5x5)
> NJ_119x119 <- NJ(matrix_119x119)
> summary(NJ_5x5)
>
> summary(NJ_119x119)
>
>
> I have done this whole analysis but don't know how can I  the save my
> tree file in svg or some other image format


SVG format is for graphics. I don't see any R graphics calls or anything 
I recognize as a "tree". (Perhaps the summary function for objects 
returned from `upgma` include graphics? I surely do not know.)

Cairo graphics is supported in the grDevices package. It should be 
loaded by default. Have your tried this at your console:


?svg


-- 

David.

>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dc@r|@on @end|ng |rom t@mu@edu  Fri Dec  4 06:21:37 2020
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Thu, 3 Dec 2020 23:21:37 -0600
Subject: [R] How to save Results in svg format
In-Reply-To: <CAG0CrLjntRNJe0FvbA9FOj3F+GVFpE=zg+ar35V_KGf2CBJ9oA@mail.gmail.com>
References: <CAG0CrLjntRNJe0FvbA9FOj3F+GVFpE=zg+ar35V_KGf2CBJ9oA@mail.gmail.com>
Message-ID: <CAE-dL2q-KV=gBW1DyUJPoPF-WVdAkZK=HdeaF7O8A1T82VhmXw@mail.gmail.com>

If you look at the examples on the manual pages for the upgma() and NJ()
functions you will see that the results are generally sent to the plot()
function. To save that graph as an .svg file you need to open a graphics
device using the svg() function, plot the data, and close the graphics
device. You probably need something like the following:

svg("UPGMA_5x5.svg")
plot(UPGMA_5x5)
dev.off()

or

svg("NJ_119x119.svg")
plot(NJ_119x119)
dev.off()

There are numerous arguments that set various details for the plot that you
should look at (?svg).

David L Carlson
Texas A&M University


On Thu, Dec 3, 2020 at 10:24 PM Anas Jamshed <anasjamshed1994 at gmail.com>
wrote:

> #Loading the required libraries
> library(ape)
> library(phangorn)
> library(seqinr)
> #Importing the required file
> align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format = "fast")
> align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format =
> "fasta")
> Computing the distance matrix for both UPGMA and NJ algorithms
> implementation.
>  matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
> summary(matrix_5x5)
>
> matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
> summary(matrix_119x119)
> #Implementation of UPGMA algorithm for a small matrix (5x5) and entire
> matrix (119x119)
> UPGMA_5x5 <- upgma(matrix_5x5)
> UPGMA_119x119 <- upgma(matrix_119x119)
> summary(UPGMA_5x5)
>
> summary(UPGMA_119x119)
> #Implementation of NJ algorithm for a small matrix (5x5) and entire
> matrix (119x119)
> NJ_5x5 <- NJ(matrix_5x5)
> NJ_119x119 <- NJ(matrix_119x119)
> summary(NJ_5x5)
>
> summary(NJ_119x119)
>
>
> I have done this whole analysis but don't know how can I  the save my
> tree file in svg or some other image format . In the avove script , I
> am applying the phylogenetic algorithm on the distance matrix which I
> have created through fasta file
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!T-8PRCLc041aD-rW1ehtb14tfQAVpWdpBddf_q6Raeho0RbG9wDodEK_QDpGMCc$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!T-8PRCLc041aD-rW1ehtb14tfQAVpWdpBddf_q6Raeho0RbG9wDodEK_1H9sJRs$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Fri Dec  4 09:54:52 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Fri, 4 Dec 2020 02:54:52 -0600
Subject: [R] How to save Results in svg format
In-Reply-To: <CAE-dL2q-KV=gBW1DyUJPoPF-WVdAkZK=HdeaF7O8A1T82VhmXw@mail.gmail.com>
References: <CAG0CrLjntRNJe0FvbA9FOj3F+GVFpE=zg+ar35V_KGf2CBJ9oA@mail.gmail.com>
 <CAE-dL2q-KV=gBW1DyUJPoPF-WVdAkZK=HdeaF7O8A1T82VhmXw@mail.gmail.com>
Message-ID: <7cb5c7e3-fc1d-969a-5d9d-2edd4f1103ca@effectivedefense.org>

	  I often have trouble with font sizes in the svg files, because they 
rarely are the same as what I see on the screen.  I then have to read 
the documentation for "par" and play with the cex, cex.axis, cex.lab, 
cex.main, and cex.sub parameters until I get what I want in the svg 
file.  I may also need to play with the "mar" argument in "par". 
Occasionally, I may also have to research some of the other plot 
parameters.


	  In some cases, I may also need a png file.  I can use "png" in the 
same way as "svg", but the cex, etc., parameters must be set 
differently.  I've recently learned how to open an svg file in the free 
open-source software GIMP and adjust the "Resolution" from the 90 
pixels/in default to something more like 300 to get what I want.  I 
couldn't import an svg file recently into a Google Doc.  The 90 pixels 
per inch default conversion didn't look very clean and sharp after 
imported into a Google Doc.  I tried 600 pixels/in and found that Google 
Doc looked like it accepted it at first.  However, when I went back 
later, I found that it had subsequently malfunctioned.  I tried 300 
pixels/in, and I think that worked, though I'm not 100% certain.


	  hope this helps.
	  Spencer Graves


On 2020-12-03 23:21, David Carlson wrote:
> If you look at the examples on the manual pages for the upgma() and NJ()
> functions you will see that the results are generally sent to the plot()
> function. To save that graph as an .svg file you need to open a graphics
> device using the svg() function, plot the data, and close the graphics
> device. You probably need something like the following:
> 
> svg("UPGMA_5x5.svg")
> plot(UPGMA_5x5)
> dev.off()
> 
> or
> 
> svg("NJ_119x119.svg")
> plot(NJ_119x119)
> dev.off()
> 
> There are numerous arguments that set various details for the plot that you
> should look at (?svg).
> 
> David L Carlson
> Texas A&M University
> 
> 
> On Thu, Dec 3, 2020 at 10:24 PM Anas Jamshed <anasjamshed1994 at gmail.com>
> wrote:
> 
>> #Loading the required libraries
>> library(ape)
>> library(phangorn)
>> library(seqinr)
>> #Importing the required file
>> align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format = "fast")
>> align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format =
>> "fasta")
>> Computing the distance matrix for both UPGMA and NJ algorithms
>> implementation.
>>   matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
>> summary(matrix_5x5)
>>
>> matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
>> summary(matrix_119x119)
>> #Implementation of UPGMA algorithm for a small matrix (5x5) and entire
>> matrix (119x119)
>> UPGMA_5x5 <- upgma(matrix_5x5)
>> UPGMA_119x119 <- upgma(matrix_119x119)
>> summary(UPGMA_5x5)
>>
>> summary(UPGMA_119x119)
>> #Implementation of NJ algorithm for a small matrix (5x5) and entire
>> matrix (119x119)
>> NJ_5x5 <- NJ(matrix_5x5)
>> NJ_119x119 <- NJ(matrix_119x119)
>> summary(NJ_5x5)
>>
>> summary(NJ_119x119)
>>
>>
>> I have done this whole analysis but don't know how can I  the save my
>> tree file in svg or some other image format . In the avove script , I
>> am applying the phylogenetic algorithm on the distance matrix which I
>> have created through fasta file
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!T-8PRCLc041aD-rW1ehtb14tfQAVpWdpBddf_q6Raeho0RbG9wDodEK_QDpGMCc$
>> PLEASE do read the posting guide
>> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!T-8PRCLc041aD-rW1ehtb14tfQAVpWdpBddf_q6Raeho0RbG9wDodEK_1H9sJRs$
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dc@r|@on @end|ng |rom t@mu@edu  Fri Dec  4 19:08:09 2020
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Fri, 4 Dec 2020 12:08:09 -0600
Subject: [R] How to save Results in svg format
In-Reply-To: <7cb5c7e3-fc1d-969a-5d9d-2edd4f1103ca@effectivedefense.org>
References: <CAG0CrLjntRNJe0FvbA9FOj3F+GVFpE=zg+ar35V_KGf2CBJ9oA@mail.gmail.com>
 <CAE-dL2q-KV=gBW1DyUJPoPF-WVdAkZK=HdeaF7O8A1T82VhmXw@mail.gmail.com>
 <7cb5c7e3-fc1d-969a-5d9d-2edd4f1103ca@effectivedefense.org>
Message-ID: <CAE-dL2pyT-NXVcRFODWUa7fDNcRBWsZggLVZYEDaRqb=M9_99g@mail.gmail.com>

Another option is to open the svg file in Inkscape which is a vector-based
editor. If you are planning to do this and work with the text labels, it is
easier to use svglite() in the package of the same name which draws text as
characters that can be selected and edited more easily than in files saved
with svg(). To see the difference look at the following files in a plain
text editor:

svg("Test.svg")

plot(0:1, 0:1, axes=FALSE, pch="", xlab="", ylab="")

text(.5, .5, "HELLO", cex=5)

dev.off()


library(svglite)

svglite("Testlite.svg")

plot(0:1, 0:1, axes=FALSE, pch="", xlab="", ylab="")

text(.5, .5, "HELLO", cex=5)

dev.off()

David L Carlson

On Fri, Dec 4, 2020 at 2:55 AM Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>           I often have trouble with font sizes in the svg files, because
> they
> rarely are the same as what I see on the screen.  I then have to read
> the documentation for "par" and play with the cex, cex.axis, cex.lab,
> cex.main, and cex.sub parameters until I get what I want in the svg
> file.  I may also need to play with the "mar" argument in "par".
> Occasionally, I may also have to research some of the other plot
> parameters.
>
>
>           In some cases, I may also need a png file.  I can use "png" in
> the
> same way as "svg", but the cex, etc., parameters must be set
> differently.  I've recently learned how to open an svg file in the free
> open-source software GIMP and adjust the "Resolution" from the 90
> pixels/in default to something more like 300 to get what I want.  I
> couldn't import an svg file recently into a Google Doc.  The 90 pixels
> per inch default conversion didn't look very clean and sharp after
> imported into a Google Doc.  I tried 600 pixels/in and found that Google
> Doc looked like it accepted it at first.  However, when I went back
> later, I found that it had subsequently malfunctioned.  I tried 300
> pixels/in, and I think that worked, though I'm not 100% certain.
>
>
>           hope this helps.
>           Spencer Graves
>
>
> On 2020-12-03 23:21, David Carlson wrote:
> > If you look at the examples on the manual pages for the upgma() and NJ()
> > functions you will see that the results are generally sent to the plot()
> > function. To save that graph as an .svg file you need to open a graphics
> > device using the svg() function, plot the data, and close the graphics
> > device. You probably need something like the following:
> >
> > svg("UPGMA_5x5.svg")
> > plot(UPGMA_5x5)
> > dev.off()
> >
> > or
> >
> > svg("NJ_119x119.svg")
> > plot(NJ_119x119)
> > dev.off()
> >
> > There are numerous arguments that set various details for the plot that
> you
> > should look at (?svg).
> >
> > David L Carlson
> > Texas A&M University
> >
> >
> > On Thu, Dec 3, 2020 at 10:24 PM Anas Jamshed <anasjamshed1994 at gmail.com>
> > wrote:
> >
> >> #Loading the required libraries
> >> library(ape)
> >> library(phangorn)
> >> library(seqinr)
> >> #Importing the required file
> >> align_5 <- read.alignment("C:/Users/VAMSI/align 5.fasta", format =
> "fast")
> >> align_119 <- read.alignment("C:/Users/VAMSI/align 119.fasta", format =
> >> "fasta")
> >> Computing the distance matrix for both UPGMA and NJ algorithms
> >> implementation.
> >>   matrix_5x5 <- dist.alignment(align_5, matrix = "identity")
> >> summary(matrix_5x5)
> >>
> >> matrix_119x119 <- dist.alignment(align_119, matrix = "identity")
> >> summary(matrix_119x119)
> >> #Implementation of UPGMA algorithm for a small matrix (5x5) and entire
> >> matrix (119x119)
> >> UPGMA_5x5 <- upgma(matrix_5x5)
> >> UPGMA_119x119 <- upgma(matrix_119x119)
> >> summary(UPGMA_5x5)
> >>
> >> summary(UPGMA_119x119)
> >> #Implementation of NJ algorithm for a small matrix (5x5) and entire
> >> matrix (119x119)
> >> NJ_5x5 <- NJ(matrix_5x5)
> >> NJ_119x119 <- NJ(matrix_119x119)
> >> summary(NJ_5x5)
> >>
> >> summary(NJ_119x119)
> >>
> >>
> >> I have done this whole analysis but don't know how can I  the save my
> >> tree file in svg or some other image format . In the avove script , I
> >> am applying the phylogenetic algorithm on the distance matrix which I
> >> have created through fasta file
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>
> >>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!T-8PRCLc041aD-rW1ehtb14tfQAVpWdpBddf_q6Raeho0RbG9wDodEK_QDpGMCc$
> >> PLEASE do read the posting guide
> >>
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!T-8PRCLc041aD-rW1ehtb14tfQAVpWdpBddf_q6Raeho0RbG9wDodEK_1H9sJRs$
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!UyfE3I-UOC7kXr5ggtIqqdFbBMGcbykadHewhBNQ1kCTKPtmITMg3Okvr-diJ3Y$
> > PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!UyfE3I-UOC7kXr5ggtIqqdFbBMGcbykadHewhBNQ1kCTKPtmITMg3OkvU0m1rBo$
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!UyfE3I-UOC7kXr5ggtIqqdFbBMGcbykadHewhBNQ1kCTKPtmITMg3Okvr-diJ3Y$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!UyfE3I-UOC7kXr5ggtIqqdFbBMGcbykadHewhBNQ1kCTKPtmITMg3OkvU0m1rBo$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sun Dec  6 07:36:50 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 6 Dec 2020 19:36:50 +1300
Subject: [R] graphics::rasterImage and grid::grid.raster,
 doubly upside down images
Message-ID: <CAB8pepwUskxU2ULZHSOs_qjWx_6jakyJoRoRKEVv8hDZ+iOOEg@mail.gmail.com>

Dear list,

I've been writing R-based software for image and spatial data. And
I've decided to support a dual implementation with both base graphics
and grid graphics, and the possibility of other graphics systems
later.

Also, I've decided to plot raster images with the vertical axis
flipped. Which means that each image also needs to be flipped.
(In rasterImage, ybottom/ytop are swapped, and in grid.raster, height
is negative).

This appears to work fine.
However, the help files don't explicitly say that height/etc can be
negative. And then go on to warn users about possible problems.

Given that both functions support scaling, I'm assuming that negative
scaling should be fine. But I thought I'd run it through the list, for
feedback/suggestions on any possible problems that one is likely to
encounter plotting raster images like this.

Examples follow:
(Requires the png package).

#required packages
library (png)
library (grid)

#base graphics wrapper function
base.wrapper <- function (x, y, colm, interpolate)
{   rasterImage (colm, x [1], y [2], x [2], y [1],
        interpolate=interpolate)
}

#grid graphics wrapper function
grid.wrapper <- function (x, y, colm, interpolate)
{   grid.raster (colm, mean (x), mean (y), x [2] - x [1], y [1] - y [2],
        default.units="native", interpolate=interpolate)
}

#create raster object
im <- readPNG (system.file ("img", "Rlogo.png", package="png") )
im <- as.raster (im)

#base graphics example
plot.new ()
plot.window (0:1, 1:0)
base.wrapper (0:1, 0:1, im, FALSE)
axis (2)

#grid graphics example
grid.newpage ()
pushViewport (viewport (xscale=0:1, yscale=1:0, width=0.75, height=0.75) )
grid.wrapper (0:1, 0:1, im, FALSE)
grid.yaxis ()


From bgunter@4567 @end|ng |rom gm@||@com  Sun Dec  6 17:23:44 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 6 Dec 2020 08:23:44 -0800
Subject: [R] Small R documentation bug in ?anyDuplicated
Message-ID: <CAGxFJbT19DZmGDo4RAbNyQ=TRpsLeCO5Uep8ydi3mc9ai0GGdg@mail.gmail.com>

All:

I did not want to bother R folks for an R Bugzilla account, so I'll just
note what appears to be a documentation bug here

In R version 4.0.3, ?anyDuplicated  says:
"anyDuplicated(.) is a ?generalized? more efficient shortcut for
any(duplicated(.)).

However, anyDuplicated returns an integer and any(duplicated)  -- that is
any() -- returns a logical.  I was bitten by this by a function expecting a
logical from anyDuplicated.

I realize that there are scare quotes around "generalized", which would
indicate that anyDuplicated and any(duplicated(.)) aren't identical.
However, I believe that the line above (especially 'shortcut') leads one to
expect that both return a logical. A simple addition such as: "Note,
however, that any() returns a logical and anyDuplicated's  returns an
integer' would avoid the confusion.

Best to all,
Bert

	[[alternative HTML version deleted]]


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Sun Dec  6 19:59:00 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Sun, 6 Dec 2020 18:59:00 +0000
Subject: [R] change frequency of wind data correctly
In-Reply-To: <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>,
 <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F80A03462@ESINO.regionemarche.intra>

Hi Jim.
I studied and implemented your solution in details. The idea is great, but after a sharp revision I came to the conclusion that unfortunately it des not work correctly: for the "am" side (10, 20, 30 minutes) it works well because the hour is exactly the same, while for the "pm" side (40, 50, 00) the algorithm it doesn't because the hour related to 40 and 50 minutes is different from the hour related to 00 (which is the following one). Am I wrong?
I tried to fix it keeping the easy structure of the algorithm, but with no success.

Any hint for that?
Thank you for your attention and your help

Stefano


         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Jim Lemon [drjimlemon at gmail.com]
Inviato: gioved? 3 dicembre 2020 4.41
A: Stefano Sofia
Cc: r-help mailing list
Oggetto: Re: [R] change frequency of wind data correctly

Hi again,
Didn't realize that the example didn't even span a full day.

ssdf<-read.table(text="date_POSIX time_POSIX vmax
 2018-02-01 00:00:00 27
 2018-02-01 00:10:00 41
 2018-02-01 00:20:00 46
 2018-02-01 00:30:00 39
 2018-02-01 00:40:00 34
 2018-02-01 00:50:00 32
 2018-02-01 01:00:00 37
 2018-02-01 01:10:00 31
 2018-02-01 01:20:00 26
 2018-02-01 01:30:00 29
 2018-02-01 01:40:00 24
 2018-02-01 01:50:00 35",
 header=TRUE,stringsAsFactors=FALSE)
# extract the hour
ssdf$hour<-
 as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",1)))
# get the time of day as seconds from the time field
ssdf$mins<-
 as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",2)))
# create an AM/PM variable
ssdf$ampm<-ifelse(ssdf$mins > 0 & ssdf$mins <= 30,"am","pm")
# drop first row
ssdf<-ssdf[-1,]
means<-aggregate(vmax~hour+ampm,ssdf,mean)

This does a full day. To do more, add the date_POSIX field to the
aggregate command. If you have the date and time in one field you'll
have to split that. That will distinguish the AM/PM means in each day
as well as hour.

Jim

On Thu, Dec 3, 2020 at 2:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Stefano,
> I read in your date-time as two separate fields for convenience. You
> can split your single field at the space to get the same result.
>
> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>  2018-02-01 00:00:00 27
>  2018-02-01 00:10:00 41
>  2018-02-01 00:20:00 46
>  2018-02-01 00:30:00 39
>  2018-02-01 00:40:00 34
>  2018-02-01 00:50:00 32",
>  header=TRUE,stringsAsFactors=FALSE)
> # get the time of day as seconds from the time field
> ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
> # subtract whatever current date strptime guesses for the date
> ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
> # create an AM/PM variable
> ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
> means<-aggregate(vmax~ampm,ssdf,mean)
>
> Jim
>
> On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
> <stefano.sofia at regione.marche.it> wrote:
> >
> > Dear list users,
> > I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
> > I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.
> >
> > The simple code here reported works well, but the column "interval" groups data forward, not backward:
> >
> > init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> > mydf$vmax <- round(rnorm(13, 35, 10))
> > mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> > means <- aggregate(vmax ~ interval, mydf, mean)
> >
> >     data_POSIX                  vmax  interval
> > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> > 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> > 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> > ...
> >
> > I should work with
> >
> >     data_POSIX                  vmax  interval
> > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> > 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> > 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> > ...
> >
> >
> > Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)
> >
> > Thank you for your help
> > Stefano
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo----------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region
> > Meteo Section
> > Snow Section
> > Via del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona
> > Uff: 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> >
> > --
> > Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> > This message was scanned by Libra ESVA and is believed to be clean.
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> > and provide commented, minimal, self-contained, reproducible code.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Dec  6 21:41:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 6 Dec 2020 12:41:32 -0800 (PST)
Subject: [R] change frequency of wind data correctly
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F80A03462@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>,
 <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F80A03462@ESINO.regionemarche.intra>
Message-ID: <alpine.BSF.2.00.2012061237050.30288@pedal.dcn.davis.ca.us>

I usually roll my own:

-----------
Sys.setenv( TZ = "GMT" )
ssdf$Dtm <- with( ssdf
                 , as.POSIXct( paste( date_POSIX, time_POSIX ) )
                 )

ceiling_dtmN <- function( dtm, mins ) {
   tm_base <- as.POSIXct( trunc( min( dtm ), units = "days" ) )
   x <- as.numeric( dtm - tm_base, units = "mins" )
   xceil <- ceiling( x %/% mins ) * mins
   tm_base + as.difftime( xceil, units = "mins" )
}

ssdf$Dtm30 <- ceiling_dtmN( ssdf$Dtm, mins = 30 )
ssdf
-----------

On Sun, 6 Dec 2020, Stefano Sofia wrote:

> Hi Jim.
> I studied and implemented your solution in details. The idea is great, but after a sharp revision I came to the conclusion that unfortunately it des not work correctly: for the "am" side (10, 20, 30 minutes) it works well because the hour is exactly the same, while for the "pm" side (40, 50, 00) the algorithm it doesn't because the hour related to 40 and 50 minutes is different from the hour related to 00 (which is the following one). Am I wrong?
> I tried to fix it keeping the easy structure of the algorithm, but with no success.
>
> Any hint for that?
> Thank you for your attention and your help
>
> Stefano
>
>
>         (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________________
> Da: Jim Lemon [drjimlemon at gmail.com]
> Inviato: gioved? 3 dicembre 2020 4.41
> A: Stefano Sofia
> Cc: r-help mailing list
> Oggetto: Re: [R] change frequency of wind data correctly
>
> Hi again,
> Didn't realize that the example didn't even span a full day.
>
> ssdf<-read.table(text="date_POSIX time_POSIX vmax
> 2018-02-01 00:00:00 27
> 2018-02-01 00:10:00 41
> 2018-02-01 00:20:00 46
> 2018-02-01 00:30:00 39
> 2018-02-01 00:40:00 34
> 2018-02-01 00:50:00 32
> 2018-02-01 01:00:00 37
> 2018-02-01 01:10:00 31
> 2018-02-01 01:20:00 26
> 2018-02-01 01:30:00 29
> 2018-02-01 01:40:00 24
> 2018-02-01 01:50:00 35",
> header=TRUE,stringsAsFactors=FALSE)
> # extract the hour
> ssdf$hour<-
> as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",1)))
> # get the time of day as seconds from the time field
> ssdf$mins<-
> as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",2)))
> # create an AM/PM variable
> ssdf$ampm<-ifelse(ssdf$mins > 0 & ssdf$mins <= 30,"am","pm")
> # drop first row
> ssdf<-ssdf[-1,]
> means<-aggregate(vmax~hour+ampm,ssdf,mean)
>
> This does a full day. To do more, add the date_POSIX field to the
> aggregate command. If you have the date and time in one field you'll
> have to split that. That will distinguish the AM/PM means in each day
> as well as hour.
>
> Jim
>
> On Thu, Dec 3, 2020 at 2:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Stefano,
>> I read in your date-time as two separate fields for convenience. You
>> can split your single field at the space to get the same result.
>>
>> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>>  2018-02-01 00:00:00 27
>>  2018-02-01 00:10:00 41
>>  2018-02-01 00:20:00 46
>>  2018-02-01 00:30:00 39
>>  2018-02-01 00:40:00 34
>>  2018-02-01 00:50:00 32",
>>  header=TRUE,stringsAsFactors=FALSE)
>> # get the time of day as seconds from the time field
>> ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
>> # subtract whatever current date strptime guesses for the date
>> ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
>> # create an AM/PM variable
>> ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
>> means<-aggregate(vmax~ampm,ssdf,mean)
>>
>> Jim
>>
>> On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
>> <stefano.sofia at regione.marche.it> wrote:
>>>
>>> Dear list users,
>>> I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
>>> I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.
>>>
>>> The simple code here reported works well, but the column "interval" groups data forward, not backward:
>>>
>>> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
>>> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
>>> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
>>> mydf$vmax <- round(rnorm(13, 35, 10))
>>> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
>>> means <- aggregate(vmax ~ interval, mydf, mean)
>>>
>>>     data_POSIX                  vmax  interval
>>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>>> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
>>> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
>>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>>> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
>>> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
>>> ...
>>>
>>> I should work with
>>>
>>>     data_POSIX                  vmax  interval
>>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>>> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
>>> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
>>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>>> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
>>> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
>>> ...
>>>
>>>
>>> Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)
>>>
>>> Thank you for your help
>>> Stefano
>>>
>>>
>>>
>>>          (oo)
>>> --oOO--( )--OOo----------------
>>> Stefano Sofia PhD
>>> Civil Protection - Marche Region
>>> Meteo Section
>>> Snow Section
>>> Via del Colle Ameno 5
>>> 60126 Torrette di Ancona, Ancona
>>> Uff: 071 806 7743
>>> E-mail: stefano.sofia at regione.marche.it
>>> ---Oo---------oO----------------
>>>
>>> ________________________________
>>>
>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>>> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>>>
>>> --
>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
>>> This message was scanned by Libra ESVA and is believed to be clean.
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
>>> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
>>> and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From mrgu|||oy|e @end|ng |rom gm@||@com  Sun Dec  6 21:29:09 2020
From: mrgu|||oy|e @end|ng |rom gm@||@com (Mathew Guilfoyle)
Date: Sun, 6 Dec 2020 20:29:09 +0000
Subject: [R] change frequency of wind data correctly
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
Message-ID: <4E335EF2-51B4-4EAC-8DAF-5E40A8B5C52B@gmail.com>

Hi Stefano

I think either of these does what you need...


1: This gets the interval column as you want it, but utilises the lubridate package:

library(lubridate)
mydf$interval = ceiling_date(mydf$data_POSIX, unit="30 minutes?)


2: Alternative in base R is a bit more long winded: convert the date to numeric (in seconds), divide by 1800 (seconds in 30min), take the ceiling, and convert back.

mydf$interval = as.POSIXct(ceiling(as.numeric(mydf$data_POSIX)/1800)*1800, origin="1970-01-01", tz="Etc/GMT-1")


Cheers


> On 2 Dec 2020, at 17:53, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
> 
> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> mydf$vmax <- round(rnorm(13, 35, 10))
> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> means <- aggregate(vmax ~ interval, mydf, mean)


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Dec  6 21:55:04 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 6 Dec 2020 12:55:04 -0800 (PST)
Subject: [R] change frequency of wind data correctly
In-Reply-To: <alpine.BSF.2.00.2012061237050.30288@pedal.dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>,
 <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F80A03462@ESINO.regionemarche.intra>
 <alpine.BSF.2.00.2012061237050.30288@pedal.dcn.davis.ca.us>
Message-ID: <alpine.BSF.2.00.2012061254130.30288@pedal.dcn.davis.ca.us>

Sigh. Don't use integer division AND ceiling.

ceiling_dtmN <- function( dtm, mins ) {
   tm_base <- as.POSIXct( trunc( min( dtm ), units = "days" ) )
   x <- as.numeric( dtm - tm_base, units = "mins" )
   xceil <- ceiling( x / mins ) * mins
   tm_base + as.difftime( xceil, units = "mins" )
}

On Sun, 6 Dec 2020, Jeff Newmiller wrote:

> I usually roll my own:
>
> -----------
> Sys.setenv( TZ = "GMT" )
> ssdf$Dtm <- with( ssdf
>                , as.POSIXct( paste( date_POSIX, time_POSIX ) )
>                )
>
> ceiling_dtmN <- function( dtm, mins ) {
>  tm_base <- as.POSIXct( trunc( min( dtm ), units = "days" ) )
>  x <- as.numeric( dtm - tm_base, units = "mins" )
>  xceil <- ceiling( x %/% mins ) * mins
>  tm_base + as.difftime( xceil, units = "mins" )
> }
>
> ssdf$Dtm30 <- ceiling_dtmN( ssdf$Dtm, mins = 30 )
> ssdf
> -----------
>
> On Sun, 6 Dec 2020, Stefano Sofia wrote:
>
>> Hi Jim.
>> I studied and implemented your solution in details. The idea is great, but 
>> after a sharp revision I came to the conclusion that unfortunately it des 
>> not work correctly: for the "am" side (10, 20, 30 minutes) it works well 
>> because the hour is exactly the same, while for the "pm" side (40, 50, 00) 
>> the algorithm it doesn't because the hour related to 40 and 50 minutes is 
>> different from the hour related to 00 (which is the following one). Am I 
>> wrong?
>> I tried to fix it keeping the easy structure of the algorithm, but with no 
>> success.
>> 
>> Any hint for that?
>> Thank you for your attention and your help
>> 
>> Stefano
>> 
>>
>>         (oo)
>> --oOO--( )--OOo----------------
>> Stefano Sofia PhD
>> Civil Protection - Marche Region
>> Meteo Section
>> Snow Section
>> Via del Colle Ameno 5
>> 60126 Torrette di Ancona, Ancona
>> Uff: 071 806 7743
>> E-mail: stefano.sofia at regione.marche.it
>> ---Oo---------oO----------------
>> 
>> ________________________________________
>> Da: Jim Lemon [drjimlemon at gmail.com]
>> Inviato: gioved? 3 dicembre 2020 4.41
>> A: Stefano Sofia
>> Cc: r-help mailing list
>> Oggetto: Re: [R] change frequency of wind data correctly
>> 
>> Hi again,
>> Didn't realize that the example didn't even span a full day.
>> 
>> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>> 2018-02-01 00:00:00 27
>> 2018-02-01 00:10:00 41
>> 2018-02-01 00:20:00 46
>> 2018-02-01 00:30:00 39
>> 2018-02-01 00:40:00 34
>> 2018-02-01 00:50:00 32
>> 2018-02-01 01:00:00 37
>> 2018-02-01 01:10:00 31
>> 2018-02-01 01:20:00 26
>> 2018-02-01 01:30:00 29
>> 2018-02-01 01:40:00 24
>> 2018-02-01 01:50:00 35",
>> header=TRUE,stringsAsFactors=FALSE)
>> # extract the hour
>> ssdf$hour<-
>> as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",1)))
>> # get the time of day as seconds from the time field
>> ssdf$mins<-
>> as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",2)))
>> # create an AM/PM variable
>> ssdf$ampm<-ifelse(ssdf$mins > 0 & ssdf$mins <= 30,"am","pm")
>> # drop first row
>> ssdf<-ssdf[-1,]
>> means<-aggregate(vmax~hour+ampm,ssdf,mean)
>> 
>> This does a full day. To do more, add the date_POSIX field to the
>> aggregate command. If you have the date and time in one field you'll
>> have to split that. That will distinguish the AM/PM means in each day
>> as well as hour.
>> 
>> Jim
>> 
>> On Thu, Dec 3, 2020 at 2:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>> 
>>> Hi Stefano,
>>> I read in your date-time as two separate fields for convenience. You
>>> can split your single field at the space to get the same result.
>>> 
>>> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>>>  2018-02-01 00:00:00 27
>>>  2018-02-01 00:10:00 41
>>>  2018-02-01 00:20:00 46
>>>  2018-02-01 00:30:00 39
>>>  2018-02-01 00:40:00 34
>>>  2018-02-01 00:50:00 32",
>>>  header=TRUE,stringsAsFactors=FALSE)
>>> # get the time of day as seconds from the time field
>>> ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
>>> # subtract whatever current date strptime guesses for the date
>>> ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
>>> # create an AM/PM variable
>>> ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
>>> means<-aggregate(vmax~ampm,ssdf,mean)
>>> 
>>> Jim
>>> 
>>> On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
>>> <stefano.sofia at regione.marche.it> wrote:
>>>> 
>>>> Dear list users,
>>>> I have wind data with frequency of 10 minutes (three years data). For 
>>>> simplicity let me use only max wind speed.
>>>> I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of 
>>>> data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 
>>>> 20 and 30 minutes) of each hour.
>>>> 
>>>> The simple code here reported works well, but the column "interval" 
>>>> groups data forward, not backward:
>>>> 
>>>> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", 
>>>> tz="Etc/GMT-1")
>>>> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", 
>>>> tz="Etc/GMT-1")
>>>> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
>>>> mydf$vmax <- round(rnorm(13, 35, 10))
>>>> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
>>>> means <- aggregate(vmax ~ interval, mydf, mean)
>>>>
>>>>     data_POSIX                  vmax  interval
>>>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>>>> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
>>>> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
>>>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>>>> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
>>>> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
>>>> ...
>>>> 
>>>> I should work with
>>>>
>>>>     data_POSIX                  vmax  interval
>>>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>>>> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
>>>> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
>>>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>>>> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
>>>> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
>>>> ...
>>>> 
>>>> 
>>>> Is there a way to modify this code to groupp data correctly? (I would 
>>>> prefer using only the base package)
>>>> 
>>>> Thank you for your help
>>>> Stefano
>>>> 
>>>> 
>>>>
>>>>          (oo)
>>>> --oOO--( )--OOo----------------
>>>> Stefano Sofia PhD
>>>> Civil Protection - Marche Region
>>>> Meteo Section
>>>> Snow Section
>>>> Via del Colle Ameno 5
>>>> 60126 Torrette di Ancona, Ancona
>>>> Uff: 071 806 7743
>>>> E-mail: stefano.sofia at regione.marche.it
>>>> ---Oo---------oO----------------
>>>> 
>>>> ________________________________
>>>> 
>>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere 
>>>> informazioni confidenziali, pertanto ? destinato solo a persone 
>>>> autorizzate alla ricezione. I messaggi di posta elettronica per i client 
>>>> di Regione Marche possono contenere informazioni confidenziali e con 
>>>> privilegi legali. Se non si ? il destinatario specificato, non leggere, 
>>>> copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo 
>>>> messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente 
>>>> dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 
>>>> 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al 
>>>> presente messaggio di posta elettronica pu? essere visionata da persone 
>>>> estranee al destinatario.
>>>> IMPORTANT NOTICE: This e-mail message is intended to be received only by 
>>>> persons entitled to receive the confidential information it may contain. 
>>>> E-mail messages to clients of Regione Marche may contain information that 
>>>> is confidential and legally privileged. Please do not read, copy, 
>>>> forward, or store this message unless you are an intended recipient of 
>>>> it. If you have received this message in error, please forward it to the 
>>>> sender and delete it completely from your computer system.
>>>> 
>>>> --
>>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non 
>>>> infetto.
>>>> This message was scanned by Libra ESVA and is believed to be clean.
>>>> 
>>>>
>>>>         [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
>>>> PLEASE do read the posting guide 
>>>> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> 
>> Questo messaggio  stato analizzato con Libra ESVA ed  risultato non 
>> infetto.
>> 
>> 
>> ________________________________
>> 
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere 
>> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate 
>> alla ricezione. I messaggi di posta elettronica per i client di Regione 
>> Marche possono contenere informazioni confidenziali e con privilegi legali. 
>> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o 
>> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, 
>> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio 
>> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in 
>> caso di necessit? ed urgenza, la risposta al presente messaggio di posta 
>> elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only by 
>> persons entitled to receive the confidential information it may contain. 
>> E-mail messages to clients of Regione Marche may contain information that 
>> is confidential and legally privileged. Please do not read, copy, forward, 
>> or store this message unless you are an intended recipient of it. If you 
>> have received this message in error, please forward it to the sender and 
>> delete it completely from your computer system.
>> 
>> --
>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
>> This message was scanned by Libra ESVA and is believed to be clean.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From btupper @end|ng |rom b|ge|ow@org  Sun Dec  6 23:51:41 2020
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Sun, 6 Dec 2020 17:51:41 -0500
Subject: [R] change frequency of wind data correctly
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F80A03462@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CA+8X3fWW9xgzkXhQajiTRd5sO6JKtYDLwtZXFBvBJHmH3t-UEA@mail.gmail.com>
 <CA+8X3fWrKHrF1PWHcPZ26Z-0AEGYvLTFK20x4Fk1+7GPVbkdQg@mail.gmail.com>
 <8B435C9568170B469AE31E8891E8CC4F80A03462@ESINO.regionemarche.intra>
Message-ID: <CALrbzg3eucq_sx0ZH8967uDi8uy7-4ERXTY2YTXdy=M5TQTdPg@mail.gmail.com>

Hi,

Perhaps this might work for you.  It leverages findInterval() and a
simple look-up-table of times to do the grouping.  I made it return NA
when computing the mean when there are fewer than the three
observations.

Cheers,
Ben

n <- 144
x <- data.frame(
  datetime = seq(from = as.POSIXct("2018-02-01 00:00:00", tz = "UTC"),
                 by = "10 min",
                 length = n),
  vmax = sample(10:50, n, replace = TRUE)
)

lut <- seq(from = x$datetime[1],
           to = x$datetime[n],
           by = "30 min") + 1     # add one second so that 00 sorts
with 40, 50, 00
                                  # and the other grouping is 10, 20 30

x$interval <- findInterval(x$datetime, lut)
x

y <- aggregate(vmax ~ interval, data = x,
               FUN = function(x){
                 if (length(x) < 3){
                   r <- NA
                 } else {
                   r <- mean(x)
                 }
                 r
               })
y

On Sun, Dec 6, 2020 at 1:59 PM Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Hi Jim.
> I studied and implemented your solution in details. The idea is great, but after a sharp revision I came to the conclusion that unfortunately it des not work correctly: for the "am" side (10, 20, 30 minutes) it works well because the hour is exactly the same, while for the "pm" side (40, 50, 00) the algorithm it doesn't because the hour related to 40 and 50 minutes is different from the hour related to 00 (which is the following one). Am I wrong?
> I tried to fix it keeping the easy structure of the algorithm, but with no success.
>
> Any hint for that?
> Thank you for your attention and your help
>
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________________
> Da: Jim Lemon [drjimlemon at gmail.com]
> Inviato: gioved? 3 dicembre 2020 4.41
> A: Stefano Sofia
> Cc: r-help mailing list
> Oggetto: Re: [R] change frequency of wind data correctly
>
> Hi again,
> Didn't realize that the example didn't even span a full day.
>
> ssdf<-read.table(text="date_POSIX time_POSIX vmax
>  2018-02-01 00:00:00 27
>  2018-02-01 00:10:00 41
>  2018-02-01 00:20:00 46
>  2018-02-01 00:30:00 39
>  2018-02-01 00:40:00 34
>  2018-02-01 00:50:00 32
>  2018-02-01 01:00:00 37
>  2018-02-01 01:10:00 31
>  2018-02-01 01:20:00 26
>  2018-02-01 01:30:00 29
>  2018-02-01 01:40:00 24
>  2018-02-01 01:50:00 35",
>  header=TRUE,stringsAsFactors=FALSE)
> # extract the hour
> ssdf$hour<-
>  as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",1)))
> # get the time of day as seconds from the time field
> ssdf$mins<-
>  as.numeric(unlist(lapply(strsplit(ssdf$time_POSIX,":"),"[",2)))
> # create an AM/PM variable
> ssdf$ampm<-ifelse(ssdf$mins > 0 & ssdf$mins <= 30,"am","pm")
> # drop first row
> ssdf<-ssdf[-1,]
> means<-aggregate(vmax~hour+ampm,ssdf,mean)
>
> This does a full day. To do more, add the date_POSIX field to the
> aggregate command. If you have the date and time in one field you'll
> have to split that. That will distinguish the AM/PM means in each day
> as well as hour.
>
> Jim
>
> On Thu, Dec 3, 2020 at 2:10 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Stefano,
> > I read in your date-time as two separate fields for convenience. You
> > can split your single field at the space to get the same result.
> >
> > ssdf<-read.table(text="date_POSIX time_POSIX vmax
> >  2018-02-01 00:00:00 27
> >  2018-02-01 00:10:00 41
> >  2018-02-01 00:20:00 46
> >  2018-02-01 00:30:00 39
> >  2018-02-01 00:40:00 34
> >  2018-02-01 00:50:00 32",
> >  header=TRUE,stringsAsFactors=FALSE)
> > # get the time of day as seconds from the time field
> > ssdf$seconds<-as.numeric(strptime(ssdf$time_POSIX,"%H:%M:%S"))
> > # subtract whatever current date strptime guesses for the date
> > ssdf$seconds<-ssdf$seconds-min(ssdf$seconds)
> > # create an AM/PM variable
> > ssdf$ampm<-ifelse(ssdf$seconds > 0 & ssdf$seconds <= 1800,"am","pm")
> > means<-aggregate(vmax~ampm,ssdf,mean)
> >
> > Jim
> >
> > On Thu, Dec 3, 2020 at 4:55 AM Stefano Sofia
> > <stefano.sofia at regione.marche.it> wrote:
> > >
> > > Dear list users,
> > > I have wind data with frequency of 10 minutes (three years data). For simplicity let me use only max wind speed.
> > > I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20 and 30 minutes) of each hour.
> > >
> > > The simple code here reported works well, but the column "interval" groups data forward, not backward:
> > >
> > > init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > > fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M", tz="Etc/GMT-1")
> > > mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> > > mydf$vmax <- round(rnorm(13, 35, 10))
> > > mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> > > means <- aggregate(vmax ~ interval, mydf, mean)
> > >
> > >     data_POSIX                  vmax  interval
> > > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > > 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> > > 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> > > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > > 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> > > 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> > > ...
> > >
> > > I should work with
> > >
> > >     data_POSIX                  vmax  interval
> > > 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> > > 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> > > 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> > > 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> > > 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> > > 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> > > ...
> > >
> > >
> > > Is there a way to modify this code to groupp data correctly? (I would prefer using only the base package)
> > >
> > > Thank you for your help
> > > Stefano
> > >
> > >
> > >
> > >          (oo)
> > > --oOO--( )--OOo----------------
> > > Stefano Sofia PhD
> > > Civil Protection - Marche Region
> > > Meteo Section
> > > Snow Section
> > > Via del Colle Ameno 5
> > > 60126 Torrette di Ancona, Ancona
> > > Uff: 071 806 7743
> > > E-mail: stefano.sofia at regione.marche.it
> > > ---Oo---------oO----------------
> > >
> > > ________________________________
> > >
> > > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> > > IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> > >
> > > --
> > > Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> > > This message was scanned by Libra ESVA and is believed to be clean.
> > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> > > PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> > > and provide commented, minimal, self-contained, reproducible code.
>
> --
>
> Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Ben Tupper
Bigelow Laboratory for Ocean Science
East Boothbay, Maine
http://www.bigelow.org/
https://eco.bigelow.org


From r@oknz @end|ng |rom gm@||@com  Mon Dec  7 06:12:01 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 7 Dec 2020 18:12:01 +1300
Subject: [R] change frequency of wind data correctly
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
Message-ID: <CABcYAdJtXefOYrcUutR3b3=he1y_5HdvudU27fxL4Bk66HogfQ@mail.gmail.com>

To be honest, I would do this one of two ways.

(1) Use ?decimate from library(signal),
    decimating by a factor of three.

(2) Convert the variable to an (n/3)*3 matrix using
    as.matrix then use rowMeans or apply.

On Thu, 3 Dec 2020 at 06:55, Stefano Sofia <stefano.sofia at regione.marche.it>
wrote:

> Dear list users,
> I have wind data with frequency of 10 minutes (three years data). For
> simplicity let me use only max wind speed.
> I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of
> data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20
> and 30 minutes) of each hour.
>
> The simple code here reported works well, but the column "interval" groups
> data forward, not backward:
>
> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M",
> tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M",
> tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> mydf$vmax <- round(rnorm(13, 35, 10))
> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> means <- aggregate(vmax ~ interval, mydf, mean)
>
>     data_POSIX                  vmax  interval
> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> ...
>
> I should work with
>
>     data_POSIX                  vmax  interval
> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> ...
>
>
> Is there a way to modify this code to groupp data correctly? (I would
> prefer using only the base package)
>
> Thank you for your help
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Dec  7 07:36:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 06 Dec 2020 22:36:26 -0800
Subject: [R] change frequency of wind data correctly
In-Reply-To: <CABcYAdJtXefOYrcUutR3b3=he1y_5HdvudU27fxL4Bk66HogfQ@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CABcYAdJtXefOYrcUutR3b3=he1y_5HdvudU27fxL4Bk66HogfQ@mail.gmail.com>
Message-ID: <CDA1E743-F8F5-4398-A902-DAF58347713A@dcn.davis.ca.us>

Beware of missing or extra records with these approaches. Also may be tricky to get the time aligned to the hour properly.

On December 6, 2020 9:12:01 PM PST, Richard O'Keefe <raoknz at gmail.com> wrote:
>To be honest, I would do this one of two ways.
>
>(1) Use ?decimate from library(signal),
>    decimating by a factor of three.
>
>(2) Convert the variable to an (n/3)*3 matrix using
>    as.matrix then use rowMeans or apply.
>
>On Thu, 3 Dec 2020 at 06:55, Stefano Sofia
><stefano.sofia at regione.marche.it>
>wrote:
>
>> Dear list users,
>> I have wind data with frequency of 10 minutes (three years data). For
>> simplicity let me use only max wind speed.
>> I need to reduce the frequency to 30 minutes,  at  00 (taking the
>mean of
>> data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at
>10, 20
>> and 30 minutes) of each hour.
>>
>> The simple code here reported works well, but the column "interval"
>groups
>> data forward, not backward:
>>
>> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M",
>> tz="Etc/GMT-1")
>> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M",
>> tz="Etc/GMT-1")
>> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
>> mydf$vmax <- round(rnorm(13, 35, 10))
>> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
>> means <- aggregate(vmax ~ interval, mydf, mean)
>>
>>     data_POSIX                  vmax  interval
>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
>> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
>> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
>> ...
>>
>> I should work with
>>
>>     data_POSIX                  vmax  interval
>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
>> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
>> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
>> ...
>>
>>
>> Is there a way to modify this code to groupp data correctly? (I would
>> prefer using only the base package)
>>
>> Thank you for your help
>> Stefano
>>
>>
>>
>>          (oo)
>> --oOO--( )--OOo----------------
>> Stefano Sofia PhD
>> Civil Protection - Marche Region
>> Meteo Section
>> Snow Section
>> Via del Colle Ameno 5
>> 60126 Torrette di Ancona, Ancona
>> Uff: 071 806 7743
>> E-mail: stefano.sofia at regione.marche.it
>> ---Oo---------oO----------------
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>contenere
>> informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate
>> alla ricezione. I messaggi di posta elettronica per i client di
>Regione
>> Marche possono contenere informazioni confidenziali e con privilegi
>legali.
>> Se non si ? il destinatario specificato, non leggere, copiare,
>inoltrare o
>> archiviare questo messaggio. Se si ? ricevuto questo messaggio per
>errore,
>> inoltrarlo al mittente ed eliminarlo completamente dal sistema del
>proprio
>> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che,
>in
>> caso di necessit? ed urgenza, la risposta al presente messaggio di
>posta
>> elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>by
>> persons entitled to receive the confidential information it may
>contain.
>> E-mail messages to clients of Regione Marche may contain information
>that
>> is confidential and legally privileged. Please do not read, copy,
>forward,
>> or store this message unless you are an intended recipient of it. If
>you
>> have received this message in error, please forward it to the sender
>and
>> delete it completely from your computer system.
>>
>> --
>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>> This message was scanned by Libra ESVA and is believed to be clean.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Dec  7 08:22:49 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 7 Dec 2020 07:22:49 +0000
Subject: [R] second legend in biplot
Message-ID: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>

Dear all

I try to make fviz_pca_biplot with 2 (or more) legends. Below is data and
the code, which gives one legend (colour) for coating variable and correctly
shows triangles and circles for size variable. But this is not shown in the
legend. Hopefully somebody could help.

And before you ask, I tried to contact maintainer about a week ago but did
not get response, therefore I try to post again here. 

Even an answer that current version of fviz_pca_biplot does not support 2
legends with different point shapes is OK as it will send me either to adapt
source code or to stop trying impossible.

Best regards
Petr

library(factoextra)
library(FactoMineR)

fit <- PCA(temp, quali.sup=c(9,10))
fviz_pca_biplot(fit, col.ind = temp$coating, repel=T, col.var = "black",
palette = "lancet", invisible="quali", pointsize=5, pointshape=temp$size,
legend.title = list(col = "Coating", shape="Size"), xlim=c(-6,6),
title="Instillation results")

temp <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L, 94479L, 
76563L, 141667L, 111042L, 93333L, 132083L, 103542L, 61667L, 77708L
), macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2, 
89.71, 98, 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58, 2.71, 
0.92, 1, 24.25, 9.29, 1.5, 15.08, 0.92, 0.67, 1), lymphocyte28 = c(1.13, 
0.29, 0.25, 0.54, 0.54, 0.55, 1, 0.5, 2.92, 0.25, 0.25, 0.46), 
    leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L, 
    156250L, 250625L, 183125L, 202917L, 161875L, 184792L, 128333L
    ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3, 
    82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75, 
    3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67, 
    1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3, 
    1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L, 
    3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = c("alumina", 
    "both", "none", "phosphate", "silica", "tungsten", "zirconia"
    ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L, 
    2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", "pigmentary"
    ), class = "factor")), class = "data.frame", row.names = c(NA, 
12L))


From @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t  Mon Dec  7 08:55:17 2020
From: @te|@no@@o||@ @end|ng |rom reg|one@m@rche@|t (Stefano Sofia)
Date: Mon, 7 Dec 2020 07:55:17 +0000
Subject: [R] change frequency of wind data correctly
In-Reply-To: <CDA1E743-F8F5-4398-A902-DAF58347713A@dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
 <CABcYAdJtXefOYrcUutR3b3=he1y_5HdvudU27fxL4Bk66HogfQ@mail.gmail.com>,
 <CDA1E743-F8F5-4398-A902-DAF58347713A@dcn.davis.ca.us>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F80A0353B@ESINO.regionemarche.intra>

This afternoon I will work on that.
I am thinking to stick to Jim's algorithm, changing the hours related to 40 and 50 mins. If I add one hour to them, everything should work correctly, because wind data at 40, 50 and 00 would have exactly the same hours.
This would not be elegant, but efficient.
Also missing data might be easily handled, changing the "mean" function with a function that accepts NA.
But I will study all the solutions that have been kindly proposed.

Thank you all of you
Stefano


         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Civil Protection - Marche Region
Meteo Section
Snow Section
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________________
Da: Jeff Newmiller [jdnewmil at dcn.davis.ca.us]
Inviato: luned? 7 dicembre 2020 7.36
A: r-help at r-project.org; Richard O'Keefe; Stefano Sofia
Cc: r-help mailing list
Oggetto: Re: [R] change frequency of wind data correctly

Beware of missing or extra records with these approaches. Also may be tricky to get the time aligned to the hour properly.

On December 6, 2020 9:12:01 PM PST, Richard O'Keefe <raoknz at gmail.com> wrote:
>To be honest, I would do this one of two ways.
>
>(1) Use ?decimate from library(signal),
>    decimating by a factor of three.
>
>(2) Convert the variable to an (n/3)*3 matrix using
>    as.matrix then use rowMeans or apply.
>
>On Thu, 3 Dec 2020 at 06:55, Stefano Sofia
><stefano.sofia at regione.marche.it>
>wrote:
>
>> Dear list users,
>> I have wind data with frequency of 10 minutes (three years data). For
>> simplicity let me use only max wind speed.
>> I need to reduce the frequency to 30 minutes,  at  00 (taking the
>mean of
>> data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at
>10, 20
>> and 30 minutes) of each hour.
>>
>> The simple code here reported works well, but the column "interval"
>groups
>> data forward, not backward:
>>
>> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M",
>> tz="Etc/GMT-1")
>> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M",
>> tz="Etc/GMT-1")
>> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
>> mydf$vmax <- round(rnorm(13, 35, 10))
>> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
>> means <- aggregate(vmax ~ interval, mydf, mean)
>>
>>     data_POSIX                  vmax  interval
>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
>> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
>> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
>> ...
>>
>> I should work with
>>
>>     data_POSIX                  vmax  interval
>> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
>> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
>> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
>> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
>> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
>> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
>> ...
>>
>>
>> Is there a way to modify this code to groupp data correctly? (I would
>> prefer using only the base package)
>>
>> Thank you for your help
>> Stefano
>>
>>
>>
>>          (oo)
>> --oOO--( )--OOo----------------
>> Stefano Sofia PhD
>> Civil Protection - Marche Region
>> Meteo Section
>> Snow Section
>> Via del Colle Ameno 5
>> 60126 Torrette di Ancona, Ancona
>> Uff: 071 806 7743
>> E-mail: stefano.sofia at regione.marche.it
>> ---Oo---------oO----------------
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>contenere
>> informazioni confidenziali, pertanto ? destinato solo a persone
>autorizzate
>> alla ricezione. I messaggi di posta elettronica per i client di
>Regione
>> Marche possono contenere informazioni confidenziali e con privilegi
>legali.
>> Se non si ? il destinatario specificato, non leggere, copiare,
>inoltrare o
>> archiviare questo messaggio. Se si ? ricevuto questo messaggio per
>errore,
>> inoltrarlo al mittente ed eliminarlo completamente dal sistema del
>proprio
>> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che,
>in
>> caso di necessit? ed urgenza, la risposta al presente messaggio di
>posta
>> elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>by
>> persons entitled to receive the confidential information it may
>contain.
>> E-mail messages to clients of Regione Marche may contain information
>that
>> is confidential and legally privileged. Please do not read, copy,
>forward,
>> or store this message unless you are an intended recipient of it. If
>you
>> have received this message in error, please forward it to the sender
>and
>> delete it completely from your computer system.
>>
>> --
>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>> This message was scanned by Libra ESVA and is believed to be clean.
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
>> PLEASE do read the posting guide
>>  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>       [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
>PLEASE do read the posting guide
> https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Dec  7 09:23:02 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 7 Dec 2020 09:23:02 +0100
Subject: [R] Small R documentation bug in ?anyDuplicated
In-Reply-To: <CAGxFJbT19DZmGDo4RAbNyQ=TRpsLeCO5Uep8ydi3mc9ai0GGdg@mail.gmail.com>
References: <CAGxFJbT19DZmGDo4RAbNyQ=TRpsLeCO5Uep8ydi3mc9ai0GGdg@mail.gmail.com>
Message-ID: <24525.58982.63543.502430@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Sun, 6 Dec 2020 08:23:44 -0800 writes:

    > All: I did not want to bother R folks for an R Bugzilla
    > account, so I'll just note what appears to be a
    > documentation bug here

    > In R version 4.0.3, ?anyDuplicated says: "anyDuplicated(.)
    > is a ?generalized? more efficient shortcut for
    > any(duplicated(.)).

IIRC, I wrote that text there ..

    > However, anyDuplicated returns an integer and
    > any(duplicated) -- that is any() -- returns a logical.  I
    > was bitten by this by a function expecting a logical from
    > anyDuplicated.

well, I was very aware / conscious of that and here's why I even
more liked the term "generalized" :

I'd argue that in S and hence R,
{0,1}  are "almost the same" as {FALSE,TRUE},
(they are internally coded as integer 0, 1)
and e.g.

> identical(FALSE:TRUE,  0:1)
[1] TRUE
> 

    > I realize that there are scare quotes around
    > "generalized", which would indicate that anyDuplicated and
    > any(duplicated(.)) aren't identical.  However, I believe
    > that the line above (especially 'shortcut') leads one to
    > expect that both return a logical. A simple addition such
    > as: "Note, however, that any() returns a logical and
    > anyDuplicated's returns an integer' would avoid the
    > confusion.

anyDuplicated() is mostly useful for   if(.)  or  while(.)
and for these, it *is* a shortcut.

    > Best to all, Bert


I really think help pages should be allowed to use expressive
language at times.. notably in the section 'Description'.

There's the 'Value:' section which one should *really* read as
well where it clearly says that anyDuplicated returns the index
in case there are duplicates.

To such a bug report  I'm pretty strongly replying
   "Works as documented"

Martin


From drj|m|emon @end|ng |rom gm@||@com  Mon Dec  7 21:53:09 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 8 Dec 2020 07:53:09 +1100
Subject: [R] second legend in biplot
In-Reply-To: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>
References: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fU9F7U+mmPJ_QR4o=k9HUWk3=-J8izJJtXP2CEhb03kZA@mail.gmail.com>

Hi Petr,
Here's an attempt, using the example in biplot.princomp:

biplot(princomp(USArrests))
> par("usr")
[1] -497.2263  624.8856 -497.2263  624.8856
legend(-180,600,c("State","Crime"),lty=1,col=c("black","red"))

Jim

On Mon, Dec 7, 2020 at 6:23 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Dear all
>
> I try to make fviz_pca_biplot with 2 (or more) legends. Below is data and
> the code, which gives one legend (colour) for coating variable and correctly
> shows triangles and circles for size variable. But this is not shown in the
> legend. Hopefully somebody could help.
>
> And before you ask, I tried to contact maintainer about a week ago but did
> not get response, therefore I try to post again here.
>
> Even an answer that current version of fviz_pca_biplot does not support 2
> legends with different point shapes is OK as it will send me either to adapt
> source code or to stop trying impossible.
>
> Best regards
> Petr
>
> library(factoextra)
> library(FactoMineR)
>
> fit <- PCA(temp, quali.sup=c(9,10))
> fviz_pca_biplot(fit, col.ind = temp$coating, repel=T, col.var = "black",
> palette = "lancet", invisible="quali", pointsize=5, pointshape=temp$size,
> legend.title = list(col = "Coating", shape="Size"), xlim=c(-6,6),
> title="Instillation results")
>
> temp <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L, 94479L,
> 76563L, 141667L, 111042L, 93333L, 132083L, 103542L, 61667L, 77708L
> ), macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2,
> 89.71, 98, 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58, 2.71,
> 0.92, 1, 24.25, 9.29, 1.5, 15.08, 0.92, 0.67, 1), lymphocyte28 = c(1.13,
> 0.29, 0.25, 0.54, 0.54, 0.55, 1, 0.5, 2.92, 0.25, 0.25, 0.46),
>     leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L,
>     156250L, 250625L, 183125L, 202917L, 161875L, 184792L, 128333L
>     ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3,
>     82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75,
>     3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67,
>     1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3,
>     1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L,
>     3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = c("alumina",
>     "both", "none", "phosphate", "silica", "tungsten", "zirconia"
>     ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L,
>     2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", "pigmentary"
>     ), class = "factor")), class = "data.frame", row.names = c(NA,
> 12L))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Dec  7 22:08:56 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Mon, 7 Dec 2020 13:08:56 -0800
Subject: [R] change frequency of wind data correctly
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F80A02E48@ESINO.regionemarche.intra>
Message-ID: <CAHqSRuRjhpD64_EwmBbbCr3v1owcuRxwTNd4b7H+CeMnJs1V=w@mail.gmail.com>

Instead of using breaks="30 mins" construct the breaks explicitly with
seq() so you can control the start point.  E.g.,

> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M",
tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M",
tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> mydf$vmax <- seq_len(nrow(mydf)) # instead of rnorm so we can check
result more easily
> # the following line is not very general
> breaks <- seq(init_day-as.difftime(20,units="mins"), fin_day,
by=as.difftime(30,units="mins"))
> mydf$interval <- cut(mydf$data_POSIX, breaks=breaks)
> aggregate(vmax ~ interval, mydf, FUN=function(x)paste(x,collapse=",")) #
paste() so we can check results
             interval   vmax
1 2018-01-31 23:40:00      1
2 2018-02-01 00:10:00  2,3,4
3 2018-02-01 00:40:00  5,6,7
4 2018-02-01 01:10:00 8,9,10

On Wed, Dec 2, 2020 at 9:55 AM Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Dear list users,
> I have wind data with frequency of 10 minutes (three years data). For
> simplicity let me use only max wind speed.
> I need to reduce the frequency to 30 minutes,  at  00 (taking the mean of
> data at 40, 50 and 00 minutes) and at 30 (taking the mean of data at 10, 20
> and 30 minutes) of each hour.
>
> The simple code here reported works well, but the column "interval" groups
> data forward, not backward:
>
> init_day <- as.POSIXct("2018-02-01-00-00", format="%Y-%m-%d-%H-%M",
> tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-01-02-00", format="%Y-%m-%d-%H-%M",
> tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="10 mins"))
> mydf$vmax <- round(rnorm(13, 35, 10))
> mydf$interval <- cut(mydf$data_POSIX, , breaks="30 min")
> means <- aggregate(vmax ~ interval, mydf, mean)
>
>     data_POSIX                  vmax  interval
> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> 2  2018-02-01 00:10:00     41     2018-02-01 00:00:00
> 3  2018-02-01 00:20:00     46     2018-02-01 00:00:00
> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> 5  2018-02-01 00:40:00     34     2018-02-01 00:30:00
> 6  2018-02-01 00:50:00     32     2018-02-01 00:30:00
> ...
>
> I should work with
>
>     data_POSIX                  vmax  interval
> 1  2018-02-01 00:00:00     27     2018-02-01 00:00:00
> 2  2018-02-01 00:10:00     41     2018-02-01 00:30:00
> 3  2018-02-01 00:20:00     46     2018-02-01 00:30:00
> 4  2018-02-01 00:30:00     39     2018-02-01 00:30:00
> 5  2018-02-01 00:40:00     34     2018-02-01 00:00:00
> 6  2018-02-01 00:50:00     32     2018-02-01 00:00:00
> ...
>
>
> Is there a way to modify this code to groupp data correctly? (I would
> prefer using only the base package)
>
> Thank you for your help
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Civil Protection - Marche Region
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rrpr| @end|ng |rom emvt@net  Mon Dec  7 05:00:52 2020
From: rrpr| @end|ng |rom emvt@net (Richard Raubertas)
Date: Sun, 6 Dec 2020 23:00:52 -0500
Subject: [R] [R-pkgs] tablesgg: Presentation-quality tables displayed using
 'ggplot2'
Message-ID: <b941b96f-4b29-c0a9-6446-62938f24dcad@emvt.net>

I'm pleased to announce that package 'tablesgg' is now available:

CRAN: https://CRAN.R-project.org/package=tablesgg
GitHub:? https://github.com/rrprf/tablesgg

The package displays presentation-quality tables as plots on an R 
graphics device.? It is unique in combining two features:

* It is aware of the logical structure of the table being presented, and 
makes use of that for automatic layout and styling of the table.? This 
avoids the need for most manual adjustments to achieve an attractive 
result.

* It displays tables using `ggplot2` graphics.? External software such 
as LaTeX or HTML or their viewers is not required.

A full set of tools is provided to control table appearance, including 
titles, footnotes and reference marks, horizontal and vertical rules, 
and spacing or grouping of rows and columns.? Many properties can be set 
automatically by specifying _styles_.? Default styles are included, and 
the user can define custom styles.? There are also tools for low-level 
manipulation of the appearance of individual table elements if desired.

Methods are included to display data frames; tables created by R's 
ftable(), table(), and xtabs() functions; and tables created by the 
`tables` and `xtable` packages.? Methods can be added to display other 
table-like objects.

A vignette is included that illustrates usage and options available in 
the package.

Richard Raubertas

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From |@h@qb@b@ @end|ng |rom y@hoo@com  Tue Dec  8 10:00:36 2020
From: |@h@qb@b@ @end|ng |rom y@hoo@com (Ishaqbaba)
Date: Tue, 8 Dec 2020 09:00:36 +0000 (UTC)
Subject: [R] ON the installation of:  abnormally-distributed/cvreg
References: <1008868403.3520599.1607418036239.ref@mail.yahoo.com>
Message-ID: <1008868403.3520599.1607418036239@mail.yahoo.com>

Hello Sir,
Hope this email finds you hale, healthy and safe.

I have been having problem in installing this:?
install.packages("remotes")
remotes::install_github("abnormally-distributed/cvreg")I am cureently using R 3.6.2 and Rstudio 4.0.3
https://cran.r-project.org/web/packages/cvreg/index.html
when i use the above link to get even the older version from the archive i always got the following message: ?
Object not found!

The requested URL was not found on this server. If you entered the URL manually please check your spelling and try again

?
Hope you put more light for me on that.
Thank youIshaq 

	[[alternative HTML version deleted]]


From @@rnobguh@ @end|ng |rom gm@||@com  Tue Dec  8 10:09:44 2020
From: @@rnobguh@ @end|ng |rom gm@||@com (Aarnob Guha)
Date: Tue, 8 Dec 2020 22:09:44 +1300
Subject: [R] Google Summer of Code 2021
Message-ID: <CAHJJ=7v+Q2qRt0D59zN2jmrwp0u4sm05b2B2rZ26uRv1fS1jzw@mail.gmail.com>

Dear R Project for Statistical Computing,
My name is Aarnob Guha and I am very enthusiastic about participating in
Google Summer of Code in 2021. I've been going through past projects in the
Google Summer of Code archives for this organisation and I was curious as
to whether R Project for Statistical Computing has any projects planned for
2021? If so, I was curious as to what these projects might be so that I can
get an idea of what I need to learn in order to adequately do well in the
project if I end up doing it. If you are ok with disclosing it that is.
Otherwise, it is also fine. Thank you.

Also, I wasn't particularly sure which mailing list to send this email to,
so I just sent it to the general 'help' mailing list. I apologise for any
inconvenience caused by this.
Kind Regards,
Aarnob Guha.

<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avast.com
<https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Dec  8 20:01:42 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 8 Dec 2020 11:01:42 -0800
Subject: [R] ON the installation of: abnormally-distributed/cvreg
In-Reply-To: <1008868403.3520599.1607418036239@mail.yahoo.com>
References: <1008868403.3520599.1607418036239.ref@mail.yahoo.com>
 <1008868403.3520599.1607418036239@mail.yahoo.com>
Message-ID: <CAGxFJbR2gwCktMJ-bDwRsEvSApTEe6BZE0aOAB1BBsWk+4YqHA@mail.gmail.com>

Do note in the posting guide linked below (Please read it!), it says:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So have you done this?
(though you *might* get a reply here if you get lucky).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 8, 2020 at 10:48 AM Ishaqbaba via R-help <r-help at r-project.org>
wrote:

> Hello Sir,
> Hope this email finds you hale, healthy and safe.
>
> I have been having problem in installing this:
> install.packages("remotes")
> remotes::install_github("abnormally-distributed/cvreg")I am cureently
> using R 3.6.2 and Rstudio 4.0.3
> https://cran.r-project.org/web/packages/cvreg/index.html
> when i use the above link to get even the older version from the archive i
> always got the following message:
> Object not found!
>
> The requested URL was not found on this server. If you entered the URL
> manually please check your spelling and try again
>
>
> Hope you put more light for me on that.
> Thank youIshaq
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Tue Dec  8 21:15:26 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Tue, 8 Dec 2020 14:15:26 -0600
Subject: [R] Google Summer of Code 2021
In-Reply-To: <CAHJJ=7v+Q2qRt0D59zN2jmrwp0u4sm05b2B2rZ26uRv1fS1jzw@mail.gmail.com>
References: <CAHJJ=7v+Q2qRt0D59zN2jmrwp0u4sm05b2B2rZ26uRv1fS1jzw@mail.gmail.com>
Message-ID: <fb1313a6-966d-939f-bb0b-fded0cad7d67@effectivedefense.org>

Hello, Aarnob Guha:


	  I'm not sure, but r-devel at r-project.org might be a better list for 
this question.


	  Over two years ago, I responded to a "Call For Proposals" from the R 
Consortium suggesting a project to improve the capabilities for 
searching R packages.  That proposal was not funded, but documentation 
of the basic idea is still available:


https://en.wikiversity.org/wiki/Draft_Proposal_for_improving_the_ability_of_R_users_to_search_R_packages


	  See also:


https://en.wikiversity.org/wiki/Searching_R_Packages


	  Hope this helps.
	  Spencer Graves
	

On 2020-12-08 03:09, Aarnob Guha wrote:
> Dear R Project for Statistical Computing,
> My name is Aarnob Guha and I am very enthusiastic about participating in
> Google Summer of Code in 2021. I've been going through past projects in the
> Google Summer of Code archives for this organisation and I was curious as
> to whether R Project for Statistical Computing has any projects planned for
> 2021? If so, I was curious as to what these projects might be so that I can
> get an idea of what I need to learn in order to adequately do well in the
> project if I end up doing it. If you are ok with disclosing it that is.
> Otherwise, it is also fine. Thank you.
> 
> Also, I wasn't particularly sure which mailing list to send this email to,
> so I just sent it to the general 'help' mailing list. I apologise for any
> inconvenience caused by this.
> Kind Regards,
> Aarnob Guha.
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pro|jcn@@h @end|ng |rom gm@||@com  Tue Dec  8 21:36:05 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Tue, 8 Dec 2020 15:36:05 -0500
Subject: [R] Google Summer of Code 2021
In-Reply-To: <CAHJJ=7v+Q2qRt0D59zN2jmrwp0u4sm05b2B2rZ26uRv1fS1jzw@mail.gmail.com>
References: <CAHJJ=7v+Q2qRt0D59zN2jmrwp0u4sm05b2B2rZ26uRv1fS1jzw@mail.gmail.com>
Message-ID: <7b0ae9a9-fdfa-b2ac-3243-76e5ec40036f@gmail.com>

https://github.com/rstats-gsoc/gsoc2021/wiki

has been set up, but is NOT up to date as Google has announced changes
to the project structure, essentially making them half the size. That actually
fits with some work I'd like to see done to try to consolidate packages nlsr
and minpack.lm into an improved nls(). nls() is now getting quite ancient
and some fixes I've already proposed seem to be on their way into base R.
However, figuring out how to do these nicely so that legacy code is
preserved needs at least two pairs of eyes to find suitable patches. I'm
sure there are plenty of other projects of this type, and useRs are
encouraged to work up proposals.

I've sent a msg to some of the people who have been involved and am
waiting for a reply. I was co-admin in 2010 with Claudia Beleites, and
am considering upping my effort while things are locked down.

Best, JN

On 2020-12-08 4:09 a.m., Aarnob Guha wrote:
> Dear R Project for Statistical Computing,
> My name is Aarnob Guha and I am very enthusiastic about participating in
> Google Summer of Code in 2021. I've been going through past projects in the
> Google Summer of Code archives for this organisation and I was curious as
> to whether R Project for Statistical Computing has any projects planned for
> 2021? If so, I was curious as to what these projects might be so that I can
> get an idea of what I need to learn in order to adequately do well in the
> project if I end up doing it. If you are ok with disclosing it that is.
> Otherwise, it is also fine. Thank you.
> 
> Also, I wasn't particularly sure which mailing list to send this email to,
> so I just sent it to the general 'help' mailing list. I apologise for any
> inconvenience caused by this.
> Kind Regards,
> Aarnob Guha.
> 
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> Virus-free.
> www.avast.com
> <https://www.avast.com/sig-email?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @b@rr|ogor@k| @end|ng |rom gm@||@com  Tue Dec  8 19:48:29 2020
From: @b@rr|ogor@k| @end|ng |rom gm@||@com (Alejandra Barrio Gorski)
Date: Tue, 8 Dec 2020 10:48:29 -0800
Subject: [R] Help with connection issue for R (just joined,
 leading R for our agency)
Message-ID: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>

Dear fellow R users,

Greetings, I am new to this list. I joined because I am pioneering the use
of R for the agency I work for. I essentially work alone and would like to
reach out for help on an issue I have been having. Here it is:

   - From one day to the next, my RStudio does not execute commands when I
   press ctrl + enter. Nothing happens, and then after a few minutes out of
   nowhere, it runs everything at once. This makes it very hard to do my work.
   - I tried uninstalling and re-installing both R and Rstudio, but the
   error comes up again. I tested commands on my R program alone, and it works
   fine there. It could be the way that Rstudio connects to R.
   - I am on a Windows 10 computer. I work for a government agency so there
   may be a few firewall/virus protection issues.

I would love any pointers.

Thank you,
Alejandra

-- 

*Alejandra Barrio*
Linkedin <https://www.linkedin.com/in/alejandra-barrio/> | Website
<https://www.ocf.berkeley.edu/~alejandrabarrio/>
MPP | M.A., International and Area Studies
University of California, Berkeley

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Dec  8 23:54:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 8 Dec 2020 14:54:10 -0800
Subject: [R] Help with connection issue for R (just joined,
 leading R for our agency)
In-Reply-To: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>
References: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>
Message-ID: <CAGxFJbSJt8asyP_5nAYdg-R3cDeJKOGQPZdAzjfDFDwOmJvrjA@mail.gmail.com>

R and RStudio are separate products developed and supported by separate
organizations, although obviously there is a large intersection between the
two. Nevertheless, if you think this is an RStudio related problem, you
should post on their support site, not here:
https://support.rstudio.com/hc/en-us

One suggestion: You should try to run R using its own built in RGui (it
ships and installs with R) to see if your difficulties replicate there.
That should help pinpoint whether R or RStudio is the source of your
problems, which sound kind of fishy to me.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 8, 2020 at 2:38 PM Alejandra Barrio Gorski <
abarriogorski at gmail.com> wrote:

> Dear fellow R users,
>
> Greetings, I am new to this list. I joined because I am pioneering the use
> of R for the agency I work for. I essentially work alone and would like to
> reach out for help on an issue I have been having. Here it is:
>
>    - From one day to the next, my RStudio does not execute commands when I
>    press ctrl + enter. Nothing happens, and then after a few minutes out of
>    nowhere, it runs everything at once. This makes it very hard to do my
> work.
>    - I tried uninstalling and re-installing both R and Rstudio, but the
>    error comes up again. I tested commands on my R program alone, and it
> works
>    fine there. It could be the way that Rstudio connects to R.
>    - I am on a Windows 10 computer. I work for a government agency so there
>    may be a few firewall/virus protection issues.
>
> I would love any pointers.
>
> Thank you,
> Alejandra
>
> --
>
> *Alejandra Barrio*
> Linkedin <https://www.linkedin.com/in/alejandra-barrio/> | Website
> <https://www.ocf.berkeley.edu/~alejandrabarrio/>
> MPP | M.A., International and Area Studies
> University of California, Berkeley
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Dec  9 02:47:59 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 8 Dec 2020 19:47:59 -0600
Subject: [R] read_delim {readr} - *.zip files
References: <001501d6cdcd$5384cc10$fa8e6430$.ref@sbcglobal.net>
Message-ID: <001501d6cdcd$5384cc10$fa8e6430$@sbcglobal.net>

r-help Forum

 

While read_csv will unzip and read a *.zip file will it read multiply files
in a *.zip file. For example

 

object <- read_csv(unz(description = "fileName.zip", filename =
"fiename1.csv"))  where filename.zip contains two file fileName1.csv and
fileName2.csv (note this line of code doesn't work). So I'm just curious if
read_csv will read a zip file that contains more than one file.

 

Jeff


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec  9 04:00:10 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 8 Dec 2020 19:00:10 -0800
Subject: [R] read_delim {readr} - *.zip files
In-Reply-To: <001501d6cdcd$5384cc10$fa8e6430$@sbcglobal.net>
References: <001501d6cdcd$5384cc10$fa8e6430$.ref@sbcglobal.net>
 <001501d6cdcd$5384cc10$fa8e6430$@sbcglobal.net>
Message-ID: <CAGxFJbR67xLnhrqE+JZW-VT2Xyq-cHEOhDsOC9K6pvpcyKhHHw@mail.gmail.com>

Per the posting guide linked below" (which you _have_ read, right?)

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."

So have you done this? readr is part of the RStudio ecosystem, so posting
on their support page might be another alternative.
(Of course you may get a helpful response here if you get lucky. But you
shouldn't expect one).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 8, 2020 at 5:48 PM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> r-help Forum
>
>
>
> While read_csv will unzip and read a *.zip file will it read multiply files
> in a *.zip file. For example
>
>
>
> object <- read_csv(unz(description = "fileName.zip", filename =
> "fiename1.csv"))  where filename.zip contains two file fileName1.csv and
> fileName2.csv (note this line of code doesn't work). So I'm just curious if
> read_csv will read a zip file that contains more than one file.
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Dec  9 09:06:46 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 9 Dec 2020 21:06:46 +1300
Subject: [R] Subscript and superscript on one symbol; plotmath.
Message-ID: <20201209210646.1b16bbee@rolf-Latitude-E7470>


I would like to produce, as graphical annotation, the Greek letter sigma
with a superscript of 2 and a subcript of 11.  (I.e. the top left hand
entry of a covariance matrix.)

I've tried:

plot(1:10,main=expression({sigma^2}[11]))

(and variants).  This "sort of" works but there is an undesirable
gap between the sigma and the subscript 11. (IOW the subscript is to
the right of the superscript, whereas ideally the first "1" in "11"
should be vertically below the superscript.

I've also tried (hammer and hope!):

plot(1:10,main=expression(sigma*atop(scriptstyle(2),scriptstyle(11))))

and again this "sort of" works but places the putative superscript a
bit too high and the putative subscript a bit too low.

Is there any way to achieve, with plotmath, an effect like unto that
produced by the LaTeX expression $\sigma^2_{11}$?  Or should I just
give up and go to the pub? :-)

cheers,

Rolf Turner

P.S.  I've explicitly CC-ed Paul Murrell, who is obviously the go-to
guy on such matters, in case he does not regularly monitor this list.

R. T.

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From e| @end|ng |rom ||@@e@NA  Wed Dec  9 09:12:54 2020
From: e| @end|ng |rom ||@@e@NA (Dr Eberhard W Lisse)
Date: Wed, 9 Dec 2020 10:12:54 +0200
Subject: [R] Subscript and superscript on one symbol; plotmath.
In-Reply-To: <20201209210646.1b16bbee@rolf-Latitude-E7470>
References: <20201209210646.1b16bbee@rolf-Latitude-E7470>
Message-ID: <ced32aba-1e5c-f626-06d3-4df58e195945@lisse.NA>

They let you guys go to the pup again? :-)-O

el

On 09/12/2020 10:06, Rolf Turner wrote:
[...]
> Is there any way to achieve, with plotmath, an effect like unto that
> produced by the LaTeX expression $\sigma^2_{11}$?  Or should I just
> give up and go to the pub? :-)
[...]
-- 
Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist 
el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Dec  9 09:33:02 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 9 Dec 2020 08:33:02 +0000
Subject: [R] ON the installation of: abnormally-distributed/cvreg
In-Reply-To: <1008868403.3520599.1607418036239@mail.yahoo.com>
References: <1008868403.3520599.1607418036239.ref@mail.yahoo.com>
 <1008868403.3520599.1607418036239@mail.yahoo.com>
Message-ID: <d5833d27-f9e7-a818-1636-aee553309ce4@sapo.pt>

Hello,

There are R versions 3.6.2 and 4.0.3 but no RStudio 4.0.3, the latest is 
RStudio 1.3.1093. To see the versions of R and RStudio you are using run

R.version.string
#[1] "R version 4.0.3 (2020-10-10)"

RStudio.Version()$version
#[1] ?1.3.1093?


The following works with me:

devtools::install_github('abnormally-distributed/cvreg')


Hope this helps,

Rui Barradas

?s 09:00 de 08/12/20, Ishaqbaba via R-help escreveu:
> Hello Sir,
> Hope this email finds you hale, healthy and safe.
> 
> I have been having problem in installing this:
> install.packages("remotes")
> remotes::install_github("abnormally-distributed/cvreg")I am cureently using R 3.6.2 and Rstudio 4.0.3
> https://cran.r-project.org/web/packages/cvreg/index.html
> when i use the above link to get even the older version from the archive i always got the following message:
> Object not found!
> 
> The requested URL was not found on this server. If you entered the URL manually please check your spelling and try again
> 
>   
> Hope you put more light for me on that.
> Thank youIshaq
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Dec  9 10:35:16 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 9 Dec 2020 10:35:16 +0100
Subject: [R] Help with connection issue for R (just joined,
 leading R for our agency)
In-Reply-To: <CAGxFJbSJt8asyP_5nAYdg-R3cDeJKOGQPZdAzjfDFDwOmJvrjA@mail.gmail.com>
References: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>
 <CAGxFJbSJt8asyP_5nAYdg-R3cDeJKOGQPZdAzjfDFDwOmJvrjA@mail.gmail.com>
Message-ID: <24528.39508.67535.190304@stat.math.ethz.ch>

>>>>> Bert Gunter 
>>>>>     on Tue, 8 Dec 2020 14:54:10 -0800 writes:

    > R and RStudio are separate products developed and
    > supported by separate organizations, although obviously
    > there is a large intersection between the
    > two. Nevertheless, if you think this is an RStudio related
    > problem, you should post on their support site, not here:
    > https://support.rstudio.com/hc/en-us

    > One suggestion: You should try to run R using its own
    > built in RGui (it ships and installs with R) to see if
    > your difficulties replicate there.  That should help
    > pinpoint whether R or RStudio is the source of your
    > problems, which sound kind of fishy to me.

    > Bert Gunter

Alejandra did say in her first post that things work fine when
she runs  R  "alone" ..

Welcome to the R user community, Alejandra!

Also, yes indeed, government (or company) firewalls *do* lead
to problems which are sometimes much more prominent when using R
via Rstudio, rather than using R "alone" (or via ESS which I use
99% of the time, "Emacs Speaks Statistics").

This is because Rstudio tries to do many things behind your back (*)
in order to be helpful to you later ...
((a little bit like Windows which you are using too,
  and I am happy I only have to do very rarely))

So, indeed, follow  Bert's advice to ask on the Rstudio
company support site.

Martin


---
*) e.g. looking at all your installed packages, which is still
 pretty detrimentous if you have full CRAN and much bioconductor
 installed as I;  also I think it installs things it needs from
 the internet without asking you, and then may get timeouts
 because of your firewall.






    > On Tue, Dec 8, 2020 at 2:38 PM Alejandra Barrio Gorski <
    > abarriogorski at gmail.com> wrote:

    >> Dear fellow R users,
    >> 
    >> Greetings, I am new to this list. I joined because I am
    >> pioneering the use of R for the agency I work for. I
    >> essentially work alone and would like to reach out for
    >> help on an issue I have been having. Here it is:
    >> 
    >> - From one day to the next, my RStudio does not execute
    >> commands when I press ctrl + enter. Nothing happens, and
    >> then after a few minutes out of nowhere, it runs
    >> everything at once. This makes it very hard to do my
    >> work.  - I tried uninstalling and re-installing both R
    >> and Rstudio, but the error comes up again. I tested
    >> commands on my R program alone, and it works fine
    >> there. It could be the way that Rstudio connects to R.  -
    >> I am on a Windows 10 computer. I work for a government
    >> agency so there may be a few firewall/virus protection
    >> issues.
    >> 
    >> I would love any pointers.
    >> 
    >> Thank you, Alejandra
    >> 
    >> --
    >> 
    >> *Alejandra Barrio* Linkedin
    >> <https://www.linkedin.com/in/alejandra-barrio/> | Website
    >> <https://www.ocf.berkeley.edu/~alejandrabarrio/> MPP |
    >> M.A., International and Area Studies University of
    >> California, Berkeley
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    >> more, see https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.
    >> 

    > 	[[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Wed Dec  9 11:47:50 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 9 Dec 2020 12:47:50 +0200
Subject: [R] Subscript and superscript on one symbol; plotmath.
In-Reply-To: <ced32aba-1e5c-f626-06d3-4df58e195945@lisse.NA>
References: <20201209210646.1b16bbee@rolf-Latitude-E7470>
 <ced32aba-1e5c-f626-06d3-4df58e195945@lisse.NA>
Message-ID: <CAGgJW763yoo3_g_R5L-HwROhBQ0QMAns0ogXzhiO73fwwfowDA@mail.gmail.com>

Hi Rolf,
This is not addressing your implementation, but reformulates the goal.
Specifically, the covariance matrix is normally written as \Sigma (not
\sigma^2).
So to specify the upper left element you would write (in Latex)
\Sigma_{11}.
No superscript (so no problem!)

HTH,
Eric


On Wed, Dec 9, 2020 at 10:17 AM Dr Eberhard W Lisse <el at lisse.na> wrote:

> They let you guys go to the pup again? :-)-O
>
> el
>
> On 09/12/2020 10:06, Rolf Turner wrote:
> [...]
> > Is there any way to achieve, with plotmath, an effect like unto that
> > produced by the LaTeX expression $\sigma^2_{11}$?  Or should I just
> > give up and go to the pub? :-)
> [...]
> --
> Dr. Eberhard W. Lisse   \         /       Obstetrician & Gynaecologist
> el at lisse.NA             / *      |  Telephone: +264 81 124 6733 (cell)
> PO Box 8421 Bachbrecht  \      /  If this email is signed with GPG/PGP
> 10007, Namibia           ;____/ Sect 20 of Act No. 4 of 2019 may apply
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Dec  9 12:18:10 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 9 Dec 2020 06:18:10 -0500
Subject: [R] Subscript and superscript on one symbol; plotmath.
In-Reply-To: <20201209210646.1b16bbee@rolf-Latitude-E7470>
References: <20201209210646.1b16bbee@rolf-Latitude-E7470>
Message-ID: <e005a785-5816-7b2f-9d99-933aa78f8c2c@gmail.com>

On 09/12/2020 3:06 a.m., Rolf Turner wrote:
> 
> I would like to produce, as graphical annotation, the Greek letter sigma
> with a superscript of 2 and a subcript of 11.  (I.e. the top left hand
> entry of a covariance matrix.)
> 
> I've tried:
> 
> plot(1:10,main=expression({sigma^2}[11]))
> 
> (and variants).  This "sort of" works but there is an undesirable
> gap between the sigma and the subscript 11. (IOW the subscript is to
> the right of the superscript, whereas ideally the first "1" in "11"
> should be vertically below the superscript.

When I run

  plot(1:10,main=expression(sigma[11]^2))

I think I get what you want.

Duncan Murdoch

> 
> I've also tried (hammer and hope!):
> 
> plot(1:10,main=expression(sigma*atop(scriptstyle(2),scriptstyle(11))))
> 
> and again this "sort of" works but places the putative superscript a
> bit too high and the putative subscript a bit too low.
> 
> Is there any way to achieve, with plotmath, an effect like unto that
> produced by the LaTeX expression $\sigma^2_{11}$?  Or should I just
> give up and go to the pub? :-)
> 
> cheers,
> 
> Rolf Turner
> 
> P.S.  I've explicitly CC-ed Paul Murrell, who is obviously the go-to
> guy on such matters, in case he does not regularly monitor this list.
> 
> R. T.
>


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Dec  9 12:31:05 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 9 Dec 2020 11:31:05 +0000
Subject: [R] second legend in biplot
In-Reply-To: <CA+8X3fU9F7U+mmPJ_QR4o=k9HUWk3=-J8izJJtXP2CEhb03kZA@mail.gmail.com>
References: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fU9F7U+mmPJ_QR4o=k9HUWk3=-J8izJJtXP2CEhb03kZA@mail.gmail.com>
Message-ID: <94ff7ea1bf4c4bdf9f71819be2a6aa61@SRVEXCHCM1302.precheza.cz>

Thank you Jim.

biplot can have distinct colours of points and arrows but not points coded 
according to some factor. In simple example I provided, points are coded 
according by 2 factors. What I would like to achieve is to colour points and 
have their shapes coded by second factor, which fviz_pca_biplot does, however 
it does not present this second factor in the legend.

Probably the last resort is to rewrite original code which I would like to 
avoid as I am not so experienced in grid graphics.

Best regards
Petr

> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Monday, December 7, 2020 9:53 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] second legend in biplot
>
> Hi Petr,
> Here's an attempt, using the example in biplot.princomp:
>
> biplot(princomp(USArrests))
> > par("usr")
> [1] -497.2263  624.8856 -497.2263  624.8856
> legend(-180,600,c("State","Crime"),lty=1,col=c("black","red"))
>
> Jim
>
> On Mon, Dec 7, 2020 at 6:23 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > Dear all
> >
> > I try to make fviz_pca_biplot with 2 (or more) legends. Below is data
> > and the code, which gives one legend (colour) for coating variable and
> > correctly shows triangles and circles for size variable. But this is
> > not shown in the legend. Hopefully somebody could help.
> >
> > And before you ask, I tried to contact maintainer about a week ago but
> > did not get response, therefore I try to post again here.
> >
> > Even an answer that current version of fviz_pca_biplot does not
> > support 2 legends with different point shapes is OK as it will send me
> > either to adapt source code or to stop trying impossible.
> >
> > Best regards
> > Petr
> >
> > library(factoextra)
> > library(FactoMineR)
> >
> > fit <- PCA(temp, quali.sup=c(9,10))
> > fviz_pca_biplot(fit, col.ind = temp$coating, repel=T, col.var =
> > "black", palette = "lancet", invisible="quali", pointsize=5,
> > pointshape=temp$size, legend.title = list(col = "Coating",
> > shape="Size"), xlim=c(-6,6), title="Instillation results")
> >
> > temp <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L, 94479L,
> > 76563L, 141667L, 111042L, 93333L, 132083L, 103542L, 61667L, 77708L ),
> > macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2, 89.71, 98,
> > 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58, 2.71, 0.92, 1, 24.25,
> > 9.29, 1.5, 15.08, 0.92, 0.67, 1), lymphocyte28 = c(1.13, 0.29, 0.25,
> > 0.54, 0.54, 0.55, 1, 0.5, 2.92, 0.25, 0.25, 0.46),
> >     leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L,
> >     156250L, 250625L, 183125L, 202917L, 161875L, 184792L, 128333L
> >     ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3,
> >     82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75,
> >     3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67,
> >     1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3,
> >     1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L,
> >     3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = c("alumina",
> >     "both", "none", "phosphate", "silica", "tungsten", "zirconia"
> >     ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L,
> >     2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", "pigmentary"
> >     ), class = "factor")), class = "data.frame", row.names = c(NA,
> > 12L))
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From tuech|er @end|ng |rom gmx@@t  Wed Dec  9 12:33:11 2020
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Wed, 9 Dec 2020 12:33:11 +0100
Subject: [R] svglite with multiple files
Message-ID: <9b07897b-43f0-1ba4-8485-30aa88741f39@gmx.at>

Dear All,

while svg() (package grDevices) can produce several files, svglite()
(package svglite) is limited to one file/page only (as documented in the
respective help page).
Is there a simple solution to make svglite() work like svg() to produce
several files?
Of course one could call svglite() before dev.off() after every plot.

best regards,

Heinz

## example
svg("Rplot%03d.svg")
plot(1)
plot(2)
plot(3)
dev.off()
## three files Rplot001.svg, Rplot002.svg, Rplot003.svg are produced

library(svglite)
svglite("Rplot-lite.svg")
plot(1)
plot(2) ## as documented: Error in plot.new() : svglite only supports
one page


From bgunter@4567 @end|ng |rom gm@||@com  Wed Dec  9 17:35:11 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 9 Dec 2020 08:35:11 -0800
Subject: [R] svglite with multiple files
In-Reply-To: <9b07897b-43f0-1ba4-8485-30aa88741f39@gmx.at>
References: <9b07897b-43f0-1ba4-8485-30aa88741f39@gmx.at>
Message-ID: <CAGxFJbRH8M=3DQhBrL50f3nTvbGpSCTjDXcJNYxO9pMWAJ13DQ@mail.gmail.com>

Sigh... Per the posting guide (which you have read, right?):

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.If the question relates to a *contributed package* ,
e.g., one downloaded from CRAN, try contacting the package maintainer
first. You can also use find("functionname") and
packageDescription("packagename") to find this information. *Only* send
such questions to R-help or R-devel if you get no reply or need further
assistance. This applies to both requests for help and to bug reports. "

This certainly sounds like a question for the svglite maintainer,
?maintainer, who might know about "tricks" that one could use. Though you
might get lucky here -- it's just that you should not expect to. If you
tried to contact the maintainer but received no response, do include that
info in your post.

Cheers,

Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 9, 2020 at 3:33 AM Heinz Tuechler <tuechler at gmx.at> wrote:

> Dear All,
>
> while svg() (package grDevices) can produce several files, svglite()
> (package svglite) is limited to one file/page only (as documented in the
> respective help page).
> Is there a simple solution to make svglite() work like svg() to produce
> several files?
> Of course one could call svglite() before dev.off() after every plot.
>
> best regards,
>
> Heinz
>
> ## example
> svg("Rplot%03d.svg")
> plot(1)
> plot(2)
> plot(3)
> dev.off()
> ## three files Rplot001.svg, Rplot002.svg, Rplot003.svg are produced
>
> library(svglite)
> svglite("Rplot-lite.svg")
> plot(1)
> plot(2) ## as documented: Error in plot.new() : svglite only supports
> one page
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tuech|er @end|ng |rom gmx@@t  Wed Dec  9 19:29:57 2020
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Wed, 9 Dec 2020 19:29:57 +0100
Subject: [R] svglite with multiple files
In-Reply-To: <CAGxFJbRH8M=3DQhBrL50f3nTvbGpSCTjDXcJNYxO9pMWAJ13DQ@mail.gmail.com>
References: <9b07897b-43f0-1ba4-8485-30aa88741f39@gmx.at>
 <CAGxFJbRH8M=3DQhBrL50f3nTvbGpSCTjDXcJNYxO9pMWAJ13DQ@mail.gmail.com>
Message-ID: <30d3d9de-315a-6c69-14b6-3f3bd0d64396@gmx.at>

Dear Bert,

of course I have read the posting guide, almost two decades ago, but
usually I focus on reading carefully a posting before replying.
To be more precise, I did *not* ask about the svglite-package, as it
works as described.
My question was: "Is there a simple solution to make svglite() work like
svg() to produce several files?"
To make it more explicit for you, I could add "using standard packages
distributed with R".
So maybe you or others have some ideas, how to solve that question in a
convenient way. As mentioned I know complicated solutions, as e.g. call
svglite() before dev.off() after every plot.

best,
Heinz


Bert Gunter wrote/hat geschrieben on/am 09.12.2020 17:35:
> Sigh... Per the posting guide (which you have read, right?):
>
> "For questions about functions in standard packages distributed with R (see
> the FAQ Add-on packages in R
> <http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
> questions on R-help.If the question relates to a *contributed package* ,
> e.g., one downloaded from CRAN, try contacting the package maintainer
> first. You can also use find("functionname") and
> packageDescription("packagename") to find this information. *Only* send
> such questions to R-help or R-devel if you get no reply or need further
> assistance. This applies to both requests for help and to bug reports. "
>
> This certainly sounds like a question for the svglite maintainer,
> ?maintainer, who might know about "tricks" that one could use. Though you
> might get lucky here -- it's just that you should not expect to. If you
> tried to contact the maintainer but received no response, do include that
> info in your post.
>
> Cheers,
>
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Dec 9, 2020 at 3:33 AM Heinz Tuechler <tuechler at gmx.at> wrote:
>
>> Dear All,
>>
>> while svg() (package grDevices) can produce several files, svglite()
>> (package svglite) is limited to one file/page only (as documented in the
>> respective help page).
>> Is there a simple solution to make svglite() work like svg() to produce
>> several files?
>> Of course one could call svglite() before dev.off() after every plot.
>>
>> best regards,
>>
>> Heinz
>>
>> ## example
>> svg("Rplot%03d.svg")
>> plot(1)
>> plot(2)
>> plot(3)
>> dev.off()
>> ## three files Rplot001.svg, Rplot002.svg, Rplot003.svg are produced
>>
>> library(svglite)
>> svglite("Rplot-lite.svg")
>> plot(1)
>> plot(2) ## as documented: Error in plot.new() : svglite only supports
>> one page
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From drj|m|emon @end|ng |rom gm@||@com  Wed Dec  9 23:37:08 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 10 Dec 2020 09:37:08 +1100
Subject: [R] second legend in biplot
In-Reply-To: <94ff7ea1bf4c4bdf9f71819be2a6aa61@SRVEXCHCM1302.precheza.cz>
References: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fU9F7U+mmPJ_QR4o=k9HUWk3=-J8izJJtXP2CEhb03kZA@mail.gmail.com>
 <94ff7ea1bf4c4bdf9f71819be2a6aa61@SRVEXCHCM1302.precheza.cz>
Message-ID: <CA+8X3fWzZyNJ4tYJ-aSGUqkOg_4+qdNPP91JEmdXyn_1c0p0Pg@mail.gmail.com>

Hi Petr,
Perhaps legendg in plotrix can help:

legendg(-180,600,c("State","Crime"),lty=1,col=list("black","red"),pch=3:4)

Jim

On Wed, Dec 9, 2020 at 10:31 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Thank you Jim.
>
> biplot can have distinct colours of points and arrows but not points coded
> according to some factor. In simple example I provided, points are coded
> according by 2 factors. What I would like to achieve is to colour points and
> have their shapes coded by second factor, which fviz_pca_biplot does, however
> it does not present this second factor in the legend.
>
> Probably the last resort is to rewrite original code which I would like to
> avoid as I am not so experienced in grid graphics.
>
> Best regards
> Petr
>
> > -----Original Message-----
> > From: Jim Lemon <drjimlemon at gmail.com>
> > Sent: Monday, December 7, 2020 9:53 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: R mailing list <r-help at r-project.org>
> > Subject: Re: [R] second legend in biplot
> >
> > Hi Petr,
> > Here's an attempt, using the example in biplot.princomp:
> >
> > biplot(princomp(USArrests))
> > > par("usr")
> > [1] -497.2263  624.8856 -497.2263  624.8856
> > legend(-180,600,c("State","Crime"),lty=1,col=c("black","red"))
> >
> > Jim
> >
> > On Mon, Dec 7, 2020 at 6:23 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
> > >
> > > Dear all
> > >
> > > I try to make fviz_pca_biplot with 2 (or more) legends. Below is data
> > > and the code, which gives one legend (colour) for coating variable and
> > > correctly shows triangles and circles for size variable. But this is
> > > not shown in the legend. Hopefully somebody could help.
> > >
> > > And before you ask, I tried to contact maintainer about a week ago but
> > > did not get response, therefore I try to post again here.
> > >
> > > Even an answer that current version of fviz_pca_biplot does not
> > > support 2 legends with different point shapes is OK as it will send me
> > > either to adapt source code or to stop trying impossible.
> > >
> > > Best regards
> > > Petr
> > >
> > > library(factoextra)
> > > library(FactoMineR)
> > >
> > > fit <- PCA(temp, quali.sup=c(9,10))
> > > fviz_pca_biplot(fit, col.ind = temp$coating, repel=T, col.var =
> > > "black", palette = "lancet", invisible="quali", pointsize=5,
> > > pointshape=temp$size, legend.title = list(col = "Coating",
> > > shape="Size"), xlim=c(-6,6), title="Instillation results")
> > >
> > > temp <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L, 94479L,
> > > 76563L, 141667L, 111042L, 93333L, 132083L, 103542L, 61667L, 77708L ),
> > > macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2, 89.71, 98,
> > > 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58, 2.71, 0.92, 1, 24.25,
> > > 9.29, 1.5, 15.08, 0.92, 0.67, 1), lymphocyte28 = c(1.13, 0.29, 0.25,
> > > 0.54, 0.54, 0.55, 1, 0.5, 2.92, 0.25, 0.25, 0.46),
> > >     leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L,
> > >     156250L, 250625L, 183125L, 202917L, 161875L, 184792L, 128333L
> > >     ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3,
> > >     82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75,
> > >     3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67,
> > >     1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3,
> > >     1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L,
> > >     3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = c("alumina",
> > >     "both", "none", "phosphate", "silica", "tungsten", "zirconia"
> > >     ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L,
> > >     2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", "pigmentary"
> > >     ), class = "factor")), class = "data.frame", row.names = c(NA,
> > > 12L))
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Dec 10 00:45:56 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 10 Dec 2020 12:45:56 +1300
Subject: [R] Subscript and superscript on one symbol; plotmath.
In-Reply-To: <e005a785-5816-7b2f-9d99-933aa78f8c2c@gmail.com>
References: <20201209210646.1b16bbee@rolf-Latitude-E7470>
 <e005a785-5816-7b2f-9d99-933aa78f8c2c@gmail.com>
Message-ID: <20201210124556.3944b4f5@rolf-Latitude-E7470>


On Wed, 9 Dec 2020 06:18:10 -0500
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 09/12/2020 3:06 a.m., Rolf Turner wrote:
> > 
> > I would like to produce, as graphical annotation, the Greek letter
> > sigma with a superscript of 2 and a subcript of 11.  (I.e. the top
> > left hand entry of a covariance matrix.)
> > 
> > I've tried:
> > 
> > plot(1:10,main=expression({sigma^2}[11]))
> > 
> > (and variants).  This "sort of" works but there is an undesirable
> > gap between the sigma and the subscript 11. (IOW the subscript is to
> > the right of the superscript, whereas ideally the first "1" in "11"
> > should be vertically below the superscript.  
> 
> When I run
> 
>   plot(1:10,main=expression(sigma[11]^2))
> 
> I think I get what you want.

<SNIP>

Dang!!! I was sure that that's one of the variants I'd tried!!!
Duh.  This is indeed exactly what I want.  Thanks Duncan.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Dec 10 02:03:01 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 9 Dec 2020 20:03:01 -0500
Subject: [R] Subscript and superscript on one symbol; plotmath.
In-Reply-To: <20201210124556.3944b4f5@rolf-Latitude-E7470>
References: <20201209210646.1b16bbee@rolf-Latitude-E7470>
 <e005a785-5816-7b2f-9d99-933aa78f8c2c@gmail.com>
 <20201210124556.3944b4f5@rolf-Latitude-E7470>
Message-ID: <8514f97d-3019-b2e3-05ef-88bd5dede54b@gmail.com>

On 09/12/2020 6:45 p.m., Rolf Turner wrote:
> 
> On Wed, 9 Dec 2020 06:18:10 -0500
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 09/12/2020 3:06 a.m., Rolf Turner wrote:
>>>
>>> I would like to produce, as graphical annotation, the Greek letter
>>> sigma with a superscript of 2 and a subcript of 11.  (I.e. the top
>>> left hand entry of a covariance matrix.)
>>>
>>> I've tried:
>>>
>>> plot(1:10,main=expression({sigma^2}[11]))
>>>
>>> (and variants).  This "sort of" works but there is an undesirable
>>> gap between the sigma and the subscript 11. (IOW the subscript is to
>>> the right of the superscript, whereas ideally the first "1" in "11"
>>> should be vertically below the superscript.
>>
>> When I run
>>
>>    plot(1:10,main=expression(sigma[11]^2))
>>
>> I think I get what you want.
> 
> <SNIP>
> 
> Dang!!! I was sure that that's one of the variants I'd tried!!!
> Duh.  This is indeed exactly what I want.  Thanks Duncan.

You probably did try it, but remember what Einstein is supposed to have 
said:

?Insanity is doing the same thing over and over and expecting different 
results.?

It just shows that it helps to be a little insane.

Duncan Murdoch


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Dec 10 09:47:27 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 10 Dec 2020 08:47:27 +0000
Subject: [R] second legend in biplot
In-Reply-To: <CA+8X3fWzZyNJ4tYJ-aSGUqkOg_4+qdNPP91JEmdXyn_1c0p0Pg@mail.gmail.com>
References: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fU9F7U+mmPJ_QR4o=k9HUWk3=-J8izJJtXP2CEhb03kZA@mail.gmail.com>
 <94ff7ea1bf4c4bdf9f71819be2a6aa61@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fWzZyNJ4tYJ-aSGUqkOg_4+qdNPP91JEmdXyn_1c0p0Pg@mail.gmail.com>
Message-ID: <f385d4710a204ee4bf5b80403eb9cc25@SRVEXCHCM1302.precheza.cz>

Thank you Jim

I am almost sure that biplot and prcomp itself cannot do point (text) coding 
according to some factor.

The closest way to what I want to achieve is to use result from prcomp and add 
points into existing biplot, something like that

PCA <- prcomp(iris[,-5], scale=T, center=T)
biplot(PCA)
points(PCA$x[,1:2], pch=20, col=iris$Species)
>
But maybe tweeking the code from fviz_pca_biplot could be easier as it is 
possible to have separate legend for point colour and shape but shape and 
colour is the same.
https://stackoverflow.com/questions/47482879/how-to-make-a-pretty-biplot-in-r-without-using-external-packages

I want shape and colour coded by different factors.

Anyway, thanks for your effort.

Cheers
Petr

> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Wednesday, December 9, 2020 11:37 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: R mailing list <r-help at r-project.org>
> Subject: Re: [R] second legend in biplot
>
> Hi Petr,
> Perhaps legendg in plotrix can help:
>
> legendg(-180,600,c("State","Crime"),lty=1,col=list("black","red"),pch=3:4)
>
> Jim
>
> On Wed, Dec 9, 2020 at 10:31 PM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >
> > Thank you Jim.
> >
> > biplot can have distinct colours of points and arrows but not points
> > coded according to some factor. In simple example I provided, points
> > are coded according by 2 factors. What I would like to achieve is to
> > colour points and have their shapes coded by second factor, which
> > fviz_pca_biplot does, however it does not present this second factor in 
> > the
> legend.
> >
> > Probably the last resort is to rewrite original code which I would
> > like to avoid as I am not so experienced in grid graphics.
> >
> > Best regards
> > Petr
> >
> > > -----Original Message-----
> > > From: Jim Lemon <drjimlemon at gmail.com>
> > > Sent: Monday, December 7, 2020 9:53 PM
> > > To: PIKAL Petr <petr.pikal at precheza.cz>
> > > Cc: R mailing list <r-help at r-project.org>
> > > Subject: Re: [R] second legend in biplot
> > >
> > > Hi Petr,
> > > Here's an attempt, using the example in biplot.princomp:
> > >
> > > biplot(princomp(USArrests))
> > > > par("usr")
> > > [1] -497.2263  624.8856 -497.2263  624.8856
> > > legend(-180,600,c("State","Crime"),lty=1,col=c("black","red"))
> > >
> > > Jim
> > >
> > > On Mon, Dec 7, 2020 at 6:23 PM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> > > >
> > > > Dear all
> > > >
> > > > I try to make fviz_pca_biplot with 2 (or more) legends. Below is
> > > > data and the code, which gives one legend (colour) for coating
> > > > variable and correctly shows triangles and circles for size
> > > > variable. But this is not shown in the legend. Hopefully somebody 
> > > > could
> help.
> > > >
> > > > And before you ask, I tried to contact maintainer about a week ago
> > > > but did not get response, therefore I try to post again here.
> > > >
> > > > Even an answer that current version of fviz_pca_biplot does not
> > > > support 2 legends with different point shapes is OK as it will
> > > > send me either to adapt source code or to stop trying impossible.
> > > >
> > > > Best regards
> > > > Petr
> > > >
> > > > library(factoextra)
> > > > library(FactoMineR)
> > > >
> > > > fit <- PCA(temp, quali.sup=c(9,10)) fviz_pca_biplot(fit, col.ind =
> > > > temp$coating, repel=T, col.var = "black", palette = "lancet",
> > > > invisible="quali", pointsize=5, pointshape=temp$size, legend.title
> > > > = list(col = "Coating", shape="Size"), xlim=c(-6,6),
> > > > title="Instillation results")
> > > >
> > > > temp <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L,
> > > > 94479L, 76563L, 141667L, 111042L, 93333L, 132083L, 103542L,
> > > > 61667L, 77708L ),
> > > > macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2, 89.71,
> > > > 98, 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58, 2.71, 0.92,
> > > > 1, 24.25, 9.29, 1.5, 15.08, 0.92, 0.67, 1), lymphocyte28 = c(1.13,
> > > > 0.29, 0.25, 0.54, 0.54, 0.55, 1, 0.5, 2.92, 0.25, 0.25, 0.46),
> > > >     leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L,
> > > >     156250L, 250625L, 183125L, 202917L, 161875L, 184792L, 128333L
> > > >     ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3,
> > > >     82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75,
> > > >     3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67,
> > > >     1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3,
> > > >     1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L,
> > > >     3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = c("alumina",
> > > >     "both", "none", "phosphate", "silica", "tungsten", "zirconia"
> > > >     ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L,
> > > >     2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", "pigmentary"
> > > >     ), class = "factor")), class = "data.frame", row.names = c(NA,
> > > > 12L))
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> > > > http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Dec 10 10:36:26 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 10 Dec 2020 09:36:26 +0000
Subject: [R] second legend in biplot
In-Reply-To: <CA+8X3fUeYMnnfTs_UMQLR+tJbMfut-yKsOP24gpcSYrXka0ggg@mail.gmail.com>
References: <5bbd05118bae4009b423273b6255965f@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fU9F7U+mmPJ_QR4o=k9HUWk3=-J8izJJtXP2CEhb03kZA@mail.gmail.com>
 <94ff7ea1bf4c4bdf9f71819be2a6aa61@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fWzZyNJ4tYJ-aSGUqkOg_4+qdNPP91JEmdXyn_1c0p0Pg@mail.gmail.com>
 <f385d4710a204ee4bf5b80403eb9cc25@SRVEXCHCM1302.precheza.cz>
 <CA+8X3fUeYMnnfTs_UMQLR+tJbMfut-yKsOP24gpcSYrXka0ggg@mail.gmail.com>
Message-ID: <3373fa76dd2c46948ef4e2301a7eba65@SRVEXCHCM1302.precheza.cz>

Hallo Jim

It is OK, your discussion was helpful as I found another way how to present 
PCA results.

It is my job to tweek the code to suite my purpose.

Cheers
Petr

> -----Original Message-----
> From: Jim Lemon <drjimlemon at gmail.com>
> Sent: Thursday, December 10, 2020 9:57 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Re: [R] second legend in biplot
>
> Ah, gotcha. I thought you just wanted the fancy legend. Sorry, I haven't got
> time to rewrite functions at that moment.
>
> Jim
>
> On Thu, Dec 10, 2020 at 7:47 PM PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >
> > Thank you Jim
> >
> > I am almost sure that biplot and prcomp itself cannot do point (text)
> > coding according to some factor.
> >
> > The closest way to what I want to achieve is to use result from prcomp
> > and add points into existing biplot, something like that
> >
> > PCA <- prcomp(iris[,-5], scale=T, center=T)
> > biplot(PCA)
> > points(PCA$x[,1:2], pch=20, col=iris$Species)
> > >
> > But maybe tweeking the code from fviz_pca_biplot could be easier as it
> > is possible to have separate legend for point colour and shape but
> > shape and colour is the same.
> > https://stackoverflow.com/questions/47482879/how-to-make-a-pretty-
> bipl
> > ot-in-r-without-using-external-packages
> >
> > I want shape and colour coded by different factors.
> >
> > Anyway, thanks for your effort.
> >
> > Cheers
> > Petr
> >
> > > -----Original Message-----
> > > From: Jim Lemon <drjimlemon at gmail.com>
> > > Sent: Wednesday, December 9, 2020 11:37 PM
> > > To: PIKAL Petr <petr.pikal at precheza.cz>
> > > Cc: R mailing list <r-help at r-project.org>
> > > Subject: Re: [R] second legend in biplot
> > >
> > > Hi Petr,
> > > Perhaps legendg in plotrix can help:
> > >
> > > legendg(-180,600,c("State","Crime"),lty=1,col=list("black","red"),pc
> > > h=3:4)
> > >
> > > Jim
> > >
> > > On Wed, Dec 9, 2020 at 10:31 PM PIKAL Petr <petr.pikal at precheza.cz>
> > > wrote:
> > > >
> > > > Thank you Jim.
> > > >
> > > > biplot can have distinct colours of points and arrows but not
> > > > points coded according to some factor. In simple example I
> > > > provided, points are coded according by 2 factors. What I would
> > > > like to achieve is to colour points and have their shapes coded by
> > > > second factor, which fviz_pca_biplot does, however it does not
> > > > present this second factor in the
> > > legend.
> > > >
> > > > Probably the last resort is to rewrite original code which I would
> > > > like to avoid as I am not so experienced in grid graphics.
> > > >
> > > > Best regards
> > > > Petr
> > > >
> > > > > -----Original Message-----
> > > > > From: Jim Lemon <drjimlemon at gmail.com>
> > > > > Sent: Monday, December 7, 2020 9:53 PM
> > > > > To: PIKAL Petr <petr.pikal at precheza.cz>
> > > > > Cc: R mailing list <r-help at r-project.org>
> > > > > Subject: Re: [R] second legend in biplot
> > > > >
> > > > > Hi Petr,
> > > > > Here's an attempt, using the example in biplot.princomp:
> > > > >
> > > > > biplot(princomp(USArrests))
> > > > > > par("usr")
> > > > > [1] -497.2263  624.8856 -497.2263  624.8856
> > > > > legend(-180,600,c("State","Crime"),lty=1,col=c("black","red"))
> > > > >
> > > > > Jim
> > > > >
> > > > > On Mon, Dec 7, 2020 at 6:23 PM PIKAL Petr
> > > > > <petr.pikal at precheza.cz>
> > > wrote:
> > > > > >
> > > > > > Dear all
> > > > > >
> > > > > > I try to make fviz_pca_biplot with 2 (or more) legends. Below
> > > > > > is data and the code, which gives one legend (colour) for
> > > > > > coating variable and correctly shows triangles and circles for
> > > > > > size variable. But this is not shown in the legend. Hopefully
> > > > > > somebody could
> > > help.
> > > > > >
> > > > > > And before you ask, I tried to contact maintainer about a week
> > > > > > ago but did not get response, therefore I try to post again here.
> > > > > >
> > > > > > Even an answer that current version of fviz_pca_biplot does
> > > > > > not support 2 legends with different point shapes is OK as it
> > > > > > will send me either to adapt source code or to stop trying
> impossible.
> > > > > >
> > > > > > Best regards
> > > > > > Petr
> > > > > >
> > > > > > library(factoextra)
> > > > > > library(FactoMineR)
> > > > > >
> > > > > > fit <- PCA(temp, quali.sup=c(9,10)) fviz_pca_biplot(fit,
> > > > > > col.ind = temp$coating, repel=T, col.var = "black", palette =
> > > > > > "lancet", invisible="quali", pointsize=5,
> > > > > > pointshape=temp$size, legend.title = list(col = "Coating",
> > > > > > shape="Size"), xlim=c(-6,6), title="Instillation results")
> > > > > >
> > > > > > temp <- structure(list(leukocyte28 = c(96875L, 73438L, 68229L,
> > > > > > 94479L, 76563L, 141667L, 111042L, 93333L, 132083L, 103542L,
> > > > > > 61667L, 77708L ),
> > > > > > macrophage28 = c(60.29, 99.13, 97.04, 98.54, 98.46, 75.2,
> > > > > > 89.71, 98, 82, 98.83, 99.08, 98.54), pmn28 = c(38.58, 0.58,
> > > > > > 2.71, 0.92, 1, 24.25, 9.29, 1.5, 15.08, 0.92, 0.67, 1),
> > > > > > lymphocyte28 = c(1.13, 0.29, 0.25, 0.54, 0.54, 0.55, 1, 0.5, 2.92,
> 0.25, 0.25, 0.46),
> > > > > >     leukocyte3 = c(186042L, 111250L, 114375L, 111146L, 98854L,
> > > > > >     156250L, 250625L, 183125L, 202917L, 161875L, 184792L,
> 128333L
> > > > > >     ), macrophage3 = c(53.88, 95.96, 98.29, 98.92, 98.92, 78.3,
> > > > > >     82.33, 97.83, 84.79, 97.25, 97.75, 98.46), pmn3 = c(44.75,
> > > > > >     3.46, 1.29, 0.67, 0.71, 20.4, 16.67, 1.92, 14.04, 1.92, 1.67,
> > > > > >     1.21), lymphocyte3 = c(1.38, 0.58, 0.42, 0.42, 0.38, 1.3,
> > > > > >     1, 0.25, 1.17, 0.83, 0.58, 0.33), coating = structure(c(3L,
> > > > > >     3L, 3L, 1L, 7L, 1L, 2L, 5L, 4L, 6L, 3L, 3L), .Label = 
> > > > > > c("alumina",
> > > > > >     "both", "none", "phosphate", "silica", "tungsten", "zirconia"
> > > > > >     ), class = "factor"), size = structure(c(1L, 1L, 2L, 2L,
> > > > > >     2L, 1L, 2L, 1L, 2L, 1L, 2L, 2L), .Label = c("nano", 
> > > > > > "pigmentary"
> > > > > >     ), class = "factor")), class = "data.frame", row.names =
> > > > > > c(NA,
> > > > > > 12L))
> > > > > >
> > > > > > ______________________________________________
> > > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > > > see https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > > PLEASE do read the posting guide
> > > > > > http://www.R-project.org/posting-guide.html
> > > > > > and provide commented, minimal, self-contained, reproducible
> code.

From motyoc@k@ @end|ng |rom y@hoo@com  Thu Dec 10 21:57:02 2020
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Thu, 10 Dec 2020 20:57:02 +0000 (UTC)
Subject: [R] plotly: ability to drag points on x axis only and prevent
 change of y axis value
References: <1316249338.4240203.1607633822634.ref@mail.yahoo.com>
Message-ID: <1316249338.4240203.1607633822634@mail.yahoo.com>

Hello,

wonder if you could provide input on the following: please see toy example below, wanted to see if there is a way to have restrictions on how the points are dragged on the plot. More specifically I would like the points draggable horizontally ONLY and have their y axis value remain fixed, ie the movement vertically would be restricted and no change allowed to that direction for each point? much appreciate any input you may have,

library(plotly)
library(purrr)

# creates a list of 32 circle shapes (one for each row/car)
circles <- map2(
? mtcars$mpg,?
? mtcars$wt,?
? ~list(
? ? type = "circle",
? ? # anchor circles at (mpg, wt)
? ? xanchor = .x,
? ? yanchor = .y,
? ? # give each circle a 2 pixel diameter
? ? x0 = -5, x1 = 5,
? ? y0 = -5, y1 = 5,
? ? xsizemode = "pixel",?
? ? ysizemode = "pixel",
? ? # other visual properties
? ? fillcolor = "blue",
? ? line = list(color = "transparent")
? )
)


plot_ly() %>%
? layout(shapes = circles) %>%
? config(edits = list(shapePosition = TRUE))


appreciate the help,


thanks,

Andras?


From jerem|eju@te @end|ng |rom gm@||@com  Fri Dec 11 12:24:39 2020
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Fri, 11 Dec 2020 12:24:39 +0100
Subject: [R] Help with connection issue for R (just joined,
 leading R for our agency)
In-Reply-To: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>
 (Alejandra Barrio Gorski's message of "Tue, 8 Dec 2020 10:48:29
 -0800")
References: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>
Message-ID: <87pn3gfuvc.fsf@gmail.com>


Hello Alejandra,

|| On Tuesday,  8 Dec 2020 at 10:48, Alejandra Barrio Gorski wrote:

Welcome to the mailing list.
> Greetings, I am new to this list. I joined because I am pioneering the use
> of R for the agency I work for. I essentially work alone and would like to
> reach out for help on an issue I have been having. Here it is:
Pioneering R is far from an easy task especially if you are doing it on
your own. Hat for raising up to the challenge!

This is mailing list is dedicated to R usage and I'm afraid you won't
find a lot of help regarding the working of R-Studio here.

|| On Wednesday,  9 Dec 2020 at 10:35, Martin Maechler wrote:
> Also, yes indeed, government (or company) firewalls *do* lead
> to problems which are sometimes much more prominent when using R
> via Rstudio, rather than using R "alone" (or via ESS which I use
> 99% of the time, "Emacs Speaks Statistics").

That said, I take the opportunity Martin gave me to advertise that both
Emacs and  Emacs Speaks Statistics works on Windows as well. The entry cost might seem
expensive in the beginning but I assure you it will pay very quickly.

- For emacs
   - https://www.gnu.org/software/emacs/tour/
   - https://www.youtube.com/watch?v=Iagbv974GlQ
   - emacs mailing-list help-gnu-emacs at gnu.org

- For ESS
   -  https://ess.r-project.org/
   -  ESS mailing list https://stat.ethz.ch/mailman/listinfo/ess-help


Best regards,
Jeremie


From @n@@j@m@hed1994 @end|ng |rom gm@||@com  Fri Dec 11 14:08:11 2020
From: @n@@j@m@hed1994 @end|ng |rom gm@||@com (Anas Jamshed)
Date: Fri, 11 Dec 2020 18:08:11 +0500
Subject: [R] (no subject)
Message-ID: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>

when I tried to install oligo package by

if (!requireNamespace("BiocManager", quietly = TRUE))

    install.packages("BiocManager")

BiocManager::install("oligo

It gives me the following eroor:

Warning messages:
1: In file.copy(savedcopy, lib, recursive = TRUE) :
  problem copying
C:\Users\USER\Documents\R\win-library\4.0\00LOCK\bit\libs\x64\bit.dll
to C:\Users\USER\Documents\R\win-library\4.0\bit\libs\x64\bit.dll:
Permission denied
2: In file.copy(savedcopy, lib, recursive = TRUE) :
  problem copying
C:\Users\USER\Documents\R\win-library\4.0\00LOCK\matrixStats\libs\x64\matrixStats.dll
to C:\Users\USER\Documents\R\win-library\4.0\matrixStats\libs\x64\matrixStats.dll:
Permission denied

Also when i tried to:

#Load the target files which the information about the sample and
their corresponding group by

targets<-read.delim(file="targets.txt", header=T)and create design and
fit the design by
design <- model.matrix(~0+ conditions)

It gives me the error :

Error in model.frame.default(object, data, xlev = xlev) :
  invalid type (closure) for variable 'conditions'

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 14:37:03 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 14:37:03 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
References: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
Message-ID: <20201211133703.GA1504028@posteo.no>

On 2020-12-11 18:08 +0500, Anas Jamshed wrote:
> when I tried to install oligo package by
> 
> if (!requireNamespace("BiocManager", quietly = TRUE))
> 
>     install.packages("BiocManager")
> 
> BiocManager::install("oligo
> 
> It gives me the following eroor:
> 
> Warning messages:
> 1: In file.copy(savedcopy, lib, recursive = TRUE) :
>   problem copying
> C:\Users\USER\Documents\R\win-library\4.0\00LOCK\bit\libs\x64\bit.dll
> to C:\Users\USER\Documents\R\win-library\4.0\bit\libs\x64\bit.dll:
> Permission denied
> 2: In file.copy(savedcopy, lib, recursive = TRUE) :
>   problem copying
> C:\Users\USER\Documents\R\win-library\4.0\00LOCK\matrixStats\libs\x64\matrixStats.dll
> to C:\Users\USER\Documents\R\win-library\4.0\matrixStats\libs\x64\matrixStats.dll:
> Permission denied
> 
> Also when i tried to:
> 
> #Load the target files which the information about the sample and
> their corresponding group by
> 
> targets<-read.delim(file="targets.txt", header=T)and create design and
> fit the design by
> design <- model.matrix(~0+ conditions)
> 
> It gives me the error :
> 
> Error in model.frame.default(object, data, xlev = xlev) :
>   invalid type (closure) for variable 'conditions'

Anas Jamshed,

I found this

https://support.bioconductor.org/p/130817/

maybe it helps ...

Best,
Rasmus Liland


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 15:48:41 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 15:48:41 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
References: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
 <20201211133703.GA1504028@posteo.no>
 <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
Message-ID: <20201211144841.GC1504028@posteo.no>

On 2020-12-11 19:16 +0500, Anas Jamshed wrote:
> On Fri, Dec 11, 2020 at 6:37 PM Rasmus Liland wrote:
> > On 2020-12-11 18:08 +0500, Anas Jamshed wrote:
> > >
> >
> > Anas Jamshed,
> >
> > I found this
> >
> > https://support.bioconductor.org/p/130817/
> >
> > maybe it helps ...
> 
> still have the problem in 2nd error
> 
> > > Also when i tried to:
> > >
> > > #Load the target files which the information about the sample and
> > > their corresponding group by
> > >
> > > targets<-read.delim(file="targets.txt", header=T)and create design and
> > > fit the design by
> > > design <- model.matrix(~0+ conditions)
> > >
> > > It gives me the error :
> > >
> > > Error in model.frame.default(object, data, xlev = xlev) :
> > >   invalid type (closure) for variable 'conditions'

Glad my suggestion helped.  

Do state how you solved that for someone 
else to find it another time (maybe 
yourself even ... ).

One problem at a time ... pocito pocito 
... 

Read here or something 
https://stackoverflow.com/questions/33023508/why-am-i-getting-the-error-invalid-type-closure
...

> https://postimg.cc/1fKPj1xg

Right, it says the object is not a 
matrix ... there is a flag there called 
?data,? perhaps look into specifying you 
matrix there ... 

It would be more helpful for me as a 
helper if you stated your problem in a 
small example code snippet, instead of 
just the error.  I might lack the 
sufficient amount of teaching emphathy 
there to se clearly through images and 
error messages from a distance.  E.g. 
use dput to paste some small dataset 
here ... 

R


From jov@n|@ouz@5 @end|ng |rom gm@||@com  Thu Dec 10 22:20:07 2020
From: jov@n|@ouz@5 @end|ng |rom gm@||@com (Jovani T. de Souza)
Date: Thu, 10 Dec 2020 18:20:07 -0300
Subject: [R] Use clusters.stats function from a hierarchical clustering in R
Message-ID: <CADs2LWTcyNHkYnoV3m8cWcDGgb5sQ-weSH081K4mRUNFHm8E+w@mail.gmail.com>

I would like a great help from you. I used the cluster.stats function that
is part of the `fpc` package to compare the similarity of two custer
solutions using a variety of validation criteria, as you can see in the
code. However, I have two questions:

1 ? Is it possible to know which is the most viable cluster, 2 clusters or
5 clusters? If so, could you explain me better how I can know.

2? Does this package only compare two in two cluster solutions, or is it
possible to compare two more cluster solutions at once?

Thank you so much!

Best Regards.

    library(rdist)
    library(geosphere)
    library(fpc)


    df<-structure(list(Industries = c(1,2,3,4,5,6),
                       Latitude = c(-23.8, -23.8, -23.9, -23.7,
-23.7,-23.7),
                       Longitude = c(-49.5, -49.6, -49.7, -49.8,
-49.6,-49.9),
                       Waste = c(526, 350, 526, 469, 534, 346)), class =
"data.frame", row.names = c(NA, -6L))

    df1<-df

    #clusters
    coordinates<-df[c("Latitude","Longitude")]
    d<-as.dist(distm(coordinates[,2:1]))
    fit.average<-hclust(d,method="average")

    clusters<-cutree(fit.average, k=2)
    df$cluster <- clusters

    clusters1<-cutree(fit.average, k=5)
    df1$cluster <- clusters1

    cluster.stats(d,df$cluster,df1$cluster)



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Remetente
notificado por
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
10/12/20
18:19:59

	[[alternative HTML version deleted]]


From ky2009w @end|ng |rom y@hoo@com  Fri Dec 11 02:53:31 2020
From: ky2009w @end|ng |rom y@hoo@com (K Y)
Date: Thu, 10 Dec 2020 20:53:31 -0500
Subject: [R] dglm()
References: <6637E812-1706-47B3-80EF-7223ABA70278.ref@yahoo.com>
Message-ID: <6637E812-1706-47B3-80EF-7223ABA70278@yahoo.com>

I used the double glm dglm() in R with "family=tweedie(var.power=p,link.power=0)", and need Chi-squared tests for the nested models of excluding each variable.

In order to do those tests,  I need the final working weights.

I was using the codes below to get the working weights from the deviance residuals, but I am not sure this is correct.  Also I wonder if there is a better way doing this.  Can anyone help?

y <- -(z$observed_target)^(2-p)

y <- y + (fitted(out))^(2-p)

y <- y / (2-p)

x <- (z$observed_target)^(2-p)

x <- x - z$observed_target * ((fitted(out))^(1-p))

x <- x / (1-p)



x <- 2 * (y + x)


y <- residuals(out, type = "deviance")

y <- y^2

y <- y / x #This should be the original weight mod by the modeled dispersion parameters or the final working weights.


	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 15:40:40 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 15:40:40 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
References: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
 <20201211133703.GA1504028@posteo.no>
 <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
Message-ID: <20201211144040.GB1504028@posteo.no>

On 2020-12-11 19:16 +0500, Anas Jamshed wrote:
> On Fri, Dec 11, 2020 at 6:37 PM Rasmus Liland wrote:
> > On 2020-12-11 18:08 +0500, Anas Jamshed wrote:
> > >
> >
> > Anas Jamshed,
> >
> > I found this
> >
> > https://support.bioconductor.org/p/130817/
> >
> > maybe it helps ...
> 
> still have the problem in 2nd error
> 
> > > Also when i tried to:
> > >
> > > #Load the target files which the information about the sample and
> > > their corresponding group by
> > >
> > > targets<-read.delim(file="targets.txt", header=T)and create design and
> > > fit the design by
> > > design <- model.matrix(~0+ conditions)
> > >
> > > It gives me the error :
> > >
> > > Error in model.frame.default(object, data, xlev = xlev) :
> > >   invalid type (closure) for variable 'conditions'

Glad my suggestion helped.  

Do state how you solved that for someone 
else to find it another time (maybe 
yourself even ... ).

One problem at a time ... pocito pocito 
... 

Read here or something 
https://stackoverflow.com/questions/33023508/why-am-i-getting-the-error-invalid-type-closure
...

> [image: anas.png]

Right, it says the object is not a 
matrix ... there is a flag there called 
?data,? perhaps look into specifying you 
matrix there ... 

It would be more helpful for me as a 
helper if you stated your problem in a 
small example code snippet, instead of 
just the error.  I might lack the 
sufficient amount of teaching emphathy 
there to se clearly through images and 
error messages from a distance.  E.g. 
use dput to paste some small dataset 
here ... 

R

-------------- next part --------------
A non-text attachment was scrubbed...
Name: anas.png
Type: image/png
Size: 248749 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201211/0163bb60/attachment.png>

From jr@| @end|ng |rom po@teo@no  Fri Dec 11 16:36:56 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 16:36:56 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLjtp0+8i4wyv1ObYsdFECAXsJbFGM3TR0Pu-6Xrqwz7vA@mail.gmail.com>
References: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
 <20201211133703.GA1504028@posteo.no>
 <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
 <20201211144841.GC1504028@posteo.no>
 <CAG0CrLjtp0+8i4wyv1ObYsdFECAXsJbFGM3TR0Pu-6Xrqwz7vA@mail.gmail.com>
Message-ID: <20201211153656.GD1504028@posteo.no>

On 2020-12-11 20:14 +0500, Anas Jamshed wrote:
> On Fri, Dec 11, 2020 at 7:49 PM Rasmus Liland <jral at posteo.no> wrote:
> 
> > On 2020-12-11 19:16 +0500, Anas Jamshed wrote:
> > > On Fri, Dec 11, 2020 at 6:37 PM Rasmus Liland wrote:
> > > > On 2020-12-11 18:08 +0500, Anas Jamshed wrote:
> > > > >
> > > >
> > > > Anas Jamshed,
> > > >
> > > > I found this
> > > >
> > > > https://support.bioconductor.org/p/130817/
> > > >
> > > > maybe it helps ...
> > >
> > > still have the problem in 2nd error
> > >
> > > > > Also when i tried to:
> > > > >
> > > > > #Load the target files which the information about the sample and
> > > > > their corresponding group by
> > > > >
> > > > > targets<-read.delim(file="targets.txt", header=T)and create design
> > and
> > > > > fit the design by
> > > > > design <- model.matrix(~0+ conditions)
> > > > >
> > > > > It gives me the error :
> > > > >
> > > > > Error in model.frame.default(object, data, xlev = xlev) :
> > > > >   invalid type (closure) for variable 'conditions'
> >
> > Glad my suggestion helped.
> >
> > Do state how you solved that for someone
> > else to find it another time (maybe
> > yourself even ... ).
> >
> > One problem at a time ... pocito pocito
> > ...
> >
> > Read here or something
> >
> > https://stackoverflow.com/questions/33023508/why-am-i-getting-the-error-invalid-type-closure
> > ...
> >
> > > https://postimg.cc/1fKPj1xg
> >
> > Right, it says the object is not a
> > matrix ... there is a flag there called
> > ?data,? perhaps look into specifying you
> > matrix there ...
> >
> > It would be more helpful for me as a
> > helper if you stated your problem in a
> > small example code snippet, instead of
> > just the error.  I might lack the
> > sufficient amount of teaching emphathy
> > there to se clearly through images and
> > error messages from a distance.  E.g.
> > use dput to paste some small dataset
> > here ...
> >
> > R
> 
> E-MTAB is an original sample data file and another one is normalized data
> file  but I don't know why I get just one gene(up reg) when I apply top
> table and decide test function
> 
> My R history file is :
> library(oligo)
> if (!requireNamespace("BiocManager", quietly = TRUE))
> install.packages("BiocManager")
> BiocManager::install("pd.hg.u133.plus.2")
> list.celfiles()
> setwd("C:/Users/USER/Desktop/RNA_Seq")
> list.celfiles()
> names = list.celfiles()
> array = read.celfiles(names)
> array
> eset = rma(array)
> write.exprs(eset, file = "data_normalized.txt") #this will be your
> normalized data by rma
> eset
> targets<-read.delim(file="targets.txt", header=T)
> targets<-read.delim(file="E-MTAB-5716.sdrf.txt", header=T)
> targets
> design <- model.matrix(~0+ conditions)
> fit <- lmFit(eset, design)
> fit <- lmFit(eset, targets)
> design <- model.matrix(~ description + 0, gset)
> design
> fit <- lmFit(eset, design)
> targets$Source.Name <-fl
> targets$Source.Name <-fl
> targets$Source.Name <-f1
> sml <- paste("G", sml, sep="")
> targets$Source.Name
> design <- model.matrix(~ description + 0, eset)
> design <- model.matrix(~ targets + 0, eset)
> design <- model.matrix(~ targets + 0, conditions())
> design <- model.matrix(~ targets + 0, conditions)
> design <- model.matrix(~0+ conditions)
> design <- model.matrix(~ description + 0 + conditions)
> design <- model.matrix(~ description + 0 , conditions)
> design <- model.matrix(~ description + 0, gset)
> design <- model.matrix(~ description + 0, eset)
> design <- model.matrix(~ targets + 0, eset)
> targets$Source.Name
> design <- model.matrix(~ Source.Name + 0, eset)
> design <- model.matrix(~ Source + 0, eset)
> gset
> gset$description
> eset <- eset[[idx]]
> eset
> design <- model.matrix(~ description + 0, eset)
> fvarLabels(eset) <- make.names(fvarLabels(eset))
> gsms <- paste0("000000000000000000000000000000XXXXXXXXXXXXXXX11111",
> "1111111111XXXXXXXXXXXXXXXXXXX")
> sml <- c()
> for (i in 1:nchar(gsms)) { sml[i] <- substr(gsms,i,i) }
> make.names()
> fvarLabels(eset) <- make.names(fvarLabels(eset))
> sel <- which(sml != "X")
> sml <- sml[sel]
> gset <- eset[ ,sel]
> eset
> design <- model.matrix(~0+ conditions)
> design <- model.matrix(~0+ eset)
> design
> fit <- lmFit(eset, design)
> fit
> contrast.matrix <- makeContrasts(group1=condition1-control,
> group2=condition2-control, levels = design)
> fit
> cont.matrix <- makeContrasts(G1-G0, levels=design)
> sml <- paste("G", sml, sep="")    # set group names
> fl <- as.factor(sml)
> sml
> cont.matrix <- makeContrasts(G1-G0, levels=design)
> design
> gset
> design
> cont.matrix <- makeContrasts(eset, levels=design)
> fit2 <- contrasts.fit(fit, cont.matrix)
> fit2
> fit3 <- eBayes(fit2, 0.01)
> fit3
> tT <- topTable(fit3, adjust="fdr", sort.by="B", number=1250)
> tT
> tT <- topTable(fit3, adjust="fdr", sort.by="B", number=500000)
> tT
> tT <- topTable(fit3, adjust="fdr", sort.by="B", number=500000,p=0.05)
> tT
> fit.cont <- contrasts.fit(fit, contrast.matrix)
> fit.cont <- contrasts.fit(fit, contrast.matrix)
> fit.cont <- contrasts.fit(fit2, contrast.matrix)
> fit.cont <- contrasts.fit(fit2, contrasts.fit())
> results<-decideTests(fit3,adjust.method="fdr",p=0.05)
> results
> summary(results)
> cont.matrix <- makeContrasts(eset, levels=design)
> fit.cont <- contrasts.fit(fit, cont.matrix)
> fit.cont
> fit.cont<- eBayes(fit.cont)
> fit.cont
> results<-decideTests(fit.cont,adjust.method="fdr",p=0.001)
> results
> summary(results)
> heatmap(results)
> heatmap(results[:,])
> heatmap(results[,])
> heatmap(results[,0])
> heatmap(results[1,4])
> heatmap(results[1,1])
> heatmap(results[2,2])
> heatmap(results[3,2])
> heatmap(results[,:])
> heatmap(results[:,])
> heatmap(results[1,])
> heatmap(results[1,:])

I think that's too many unspecific lines 
and too large files directly here on 
email (24MiB!).

Would you please narrow down your 
question.


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 17:50:31 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 17:50:31 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLg5ZdOBwrx8yyRyzuC3Gtv8jO4sLPrgTXxdHi_GKVQjFw@mail.gmail.com>
References: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
 <20201211133703.GA1504028@posteo.no>
 <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
 <20201211144841.GC1504028@posteo.no>
 <CAG0CrLjtp0+8i4wyv1ObYsdFECAXsJbFGM3TR0Pu-6Xrqwz7vA@mail.gmail.com>
 <20201211153656.GD1504028@posteo.no>
 <CAG0CrLithjwvf+MwQFnH9F5hdOmLss-deHLYw8_gTGJWJGVktQ@mail.gmail.com>
 <CAG0CrLg5ZdOBwrx8yyRyzuC3Gtv8jO4sLPrgTXxdHi_GKVQjFw@mail.gmail.com>
Message-ID: <20201211165031.GE1504028@posteo.no>

On 2020-12-11 21:04 +0500, Anas Jamshed wrote:
> On Fri, Dec 11, 2020 at 9:03 PM Anas Jamshed wrote:
> > On Fri, Dec 11, 2020 at 8:37 PM Rasmus Liland wrote:
> > >
> > > I think that's too many unspecific lines
> > > and too large files directly here on
> > > email (24MiB!).
> > >
> > > Would you please narrow down your
> > > question.
> >
> > E-MTAB is an original sample data file and another one is normalized data
> > file  but I don't know why I get just one gene(up reg) when I apply top
> > table and decide test function
> > results<-decideTests(fit3,adjust.method="fdr",p=0.05)
> > results
> > summary(results)
> > cont.matrix <- makeContrasts(eset, levels=design)
> > fit.cont <- contrasts.fit(fit, cont.matrix)
> > fit.cont
> > fit.cont<- eBayes(fit.cont)
> > fit.cont
> > results<-decideTests(fit.cont,adjust.method="fdr",p=0.001)
> 
> [image: image.png]

Say, how do I create fit3, eset, design, 
etc. ...

R


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 18:17:12 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 18:17:12 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLh5xNqCa=MsVMhf0TcaAvLDO7B-3wZDk1f8Ff3EPp+U4A@mail.gmail.com>
References: <CAG0CrLhCEzLPhLauU8_GmtW_jd=piAHX=oYSrQf7F6pnAE+5dg@mail.gmail.com>
 <20201211133703.GA1504028@posteo.no>
 <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
 <20201211144841.GC1504028@posteo.no>
 <CAG0CrLjtp0+8i4wyv1ObYsdFECAXsJbFGM3TR0Pu-6Xrqwz7vA@mail.gmail.com>
 <20201211153656.GD1504028@posteo.no>
 <CAG0CrLithjwvf+MwQFnH9F5hdOmLss-deHLYw8_gTGJWJGVktQ@mail.gmail.com>
 <CAG0CrLg5ZdOBwrx8yyRyzuC3Gtv8jO4sLPrgTXxdHi_GKVQjFw@mail.gmail.com>
 <20201211165031.GE1504028@posteo.no>
 <CAG0CrLh5xNqCa=MsVMhf0TcaAvLDO7B-3wZDk1f8Ff3EPp+U4A@mail.gmail.com>
Message-ID: <20201211171712.GG1504028@posteo.no>

On 2020-12-11 22:09 +0500, Anas Jamshed wrote:
> On Fri, Dec 11, 2020 at 9:51 PM Rasmus Liland wrote:
> >
> > Say, how do I create fit3, eset, design,
> > etc. ...
> >
> > R
> 
> library(oligo)
> if (!requireNamespace("BiocManager", quietly = TRUE))
> install.packages("BiocManager")
> BiocManager::install("pd.hg.u133.plus.2")
> list.celfiles()
> setwd("C:/Users/USER/Desktop/RNA_Seq")
> list.celfiles()
> names = list.celfiles()
> array = read.celfiles(names)
> array
> eset = rma(array)
> write.exprs(eset, file = "data_normalized.txt") #this will be your
> normalized data by rma
> eset
> targets<-read.delim(file="targets.txt", header=T)
> targets<-read.delim(file="E-MTAB-5716.sdrf.txt", header=T)
> targets
> 
> eset <- eset[[idx]]
> 
> design <- model.matrix(~0+ eset)
> design
> fit <- lmFit(eset, design)
> fit
> 
> cont.matrix <- makeContrasts(eset, levels=design)
> fit2 <- contrasts.fit(fit, cont.matrix)
> fit2
> fit3 <- eBayes(fit2, 0.01)
> fit3
> tT <- topTable(fit3, adjust="fdr", sort.by="B", number=1250)
> tT

Sorry, I think I am too tired atm.  I 
took this pneumonia vaccine, and it 
really banged me up you know ...

Maybe someone else can row this ship 
ashore again ...

R


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 21:12:12 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 21:12:12 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLjgEkNjmB-1y7mO=LPNXFgAiwkAa-8EPUp2sCB+=N=oEA@mail.gmail.com>
References: <CAG0CrLgF2uzzmZ5CmkzbKBvknMf8HHhzbKRsASevE+gyR1y-hg@mail.gmail.com>
 <20201211144841.GC1504028@posteo.no>
 <CAG0CrLjtp0+8i4wyv1ObYsdFECAXsJbFGM3TR0Pu-6Xrqwz7vA@mail.gmail.com>
 <20201211153656.GD1504028@posteo.no>
 <CAG0CrLithjwvf+MwQFnH9F5hdOmLss-deHLYw8_gTGJWJGVktQ@mail.gmail.com>
 <CAG0CrLg5ZdOBwrx8yyRyzuC3Gtv8jO4sLPrgTXxdHi_GKVQjFw@mail.gmail.com>
 <20201211165031.GE1504028@posteo.no>
 <CAG0CrLh5xNqCa=MsVMhf0TcaAvLDO7B-3wZDk1f8Ff3EPp+U4A@mail.gmail.com>
 <20201211171712.GG1504028@posteo.no>
 <CAG0CrLjgEkNjmB-1y7mO=LPNXFgAiwkAa-8EPUp2sCB+=N=oEA@mail.gmail.com>
Message-ID: <20201211201212.GH1504028@posteo.no>

On 2020-12-11 22:19 +0500, Anas Jamshed wrote:
> On Fri, Dec 11, 2020 at 10:17 PM Rasmus Liland wrote:
> >
> > Sorry, I think I am too tired atm.  I
> > took this pneumonia vaccine, and it
> > really banged me up you know ...
> >
> > Maybe someone else can row this ship
> > ashore again ...
> 
> why you are tired?

Anas Jamshed,

I do not need to explain why I am tired 
at all.  Not at all.


From jr@| @end|ng |rom po@teo@no  Fri Dec 11 21:35:16 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 11 Dec 2020 21:35:16 +0100
Subject: [R] (no subject)
In-Reply-To: <CAG0CrLjFhvpUREW3m_mDRvZtymFmN-0Xfqu9z2aGG=z76aKT_g@mail.gmail.com>
References: <CAG0CrLjtp0+8i4wyv1ObYsdFECAXsJbFGM3TR0Pu-6Xrqwz7vA@mail.gmail.com>
 <20201211153656.GD1504028@posteo.no>
 <CAG0CrLithjwvf+MwQFnH9F5hdOmLss-deHLYw8_gTGJWJGVktQ@mail.gmail.com>
 <CAG0CrLg5ZdOBwrx8yyRyzuC3Gtv8jO4sLPrgTXxdHi_GKVQjFw@mail.gmail.com>
 <20201211165031.GE1504028@posteo.no>
 <CAG0CrLh5xNqCa=MsVMhf0TcaAvLDO7B-3wZDk1f8Ff3EPp+U4A@mail.gmail.com>
 <20201211171712.GG1504028@posteo.no>
 <CAG0CrLjgEkNjmB-1y7mO=LPNXFgAiwkAa-8EPUp2sCB+=N=oEA@mail.gmail.com>
 <20201211201212.GH1504028@posteo.no>
 <CAG0CrLjFhvpUREW3m_mDRvZtymFmN-0Xfqu9z2aGG=z76aKT_g@mail.gmail.com>
Message-ID: <20201211203516.GI1504028@posteo.no>

On 2020-12-12 01:14 +0500, Anas Jamshed wrote:
> On Sat, Dec 12, 2020 at 1:12 AM Rasmus Liland wrote:
> >
> > Anas Jamshed,
> >
> > I do not need to explain why I am tired
> > at all.  Not at all.
> 
> but plz try to help me

Once upon a midnight dreary, while I pondered, weak and weary,
Over many a quaint and curious volume of forgotten lore?
    While I nodded, nearly napping, suddenly there came a tapping,
As of some one gently rapping, rapping at my chamber door.
??Tis some visitor,? I muttered, ?tapping at my chamber door?
            Only this and nothing more.?

    Ah, distinctly I remember it was in the bleak December;
And each separate dying ember wrought its ghost upon the floor.
    Eagerly I wished the morrow;?vainly I had sought to borrow
    From my books surcease of sorrow?sorrow for the lost Lenore?
For the rare and radiant maiden whom the angels name Lenore?
            Nameless here for evermore.

    And the silken, sad, uncertain rustling of each purple curtain
Thrilled me?filled me with fantastic terrors never felt before;
    So that now, to still the beating of my heart, I stood repeating
    ??Tis some visitor entreating entrance at my chamber door?
Some late visitor entreating entrance at my chamber door;?
            This it is and nothing more.?

    Presently my soul grew stronger; hesitating then no longer,
?Sir,? said I, ?or Madam, truly your forgiveness I implore;
    But the fact is I was napping, and so gently you came rapping,
    And so faintly you came tapping, tapping at my chamber door,
That I scarce was sure I heard you??here I opened wide the door;?
            Darkness there and nothing more.

    Deep into that darkness peering, long I stood there wondering, fearing,
Doubting, dreaming dreams no mortal ever dared to dream before;
    But the silence was unbroken, and the stillness gave no token,
    And the only word there spoken was the whispered word, ?Lenore??
This I whispered, and an echo murmured back the word, ?Lenore!??
            Merely this and nothing more.

    Back into the chamber turning, all my soul within me burning,
Soon again I heard a tapping somewhat louder than before.
    ?Surely,? said I, ?surely that is something at my window lattice;
      Let me see, then, what thereat is, and this mystery explore?
Let my heart be still a moment and this mystery explore;?
            ?Tis the wind and nothing more!?

    Open here I flung the shutter, when, with many a flirt and flutter,
In there stepped a stately Raven of the saintly days of yore;
    Not the least obeisance made he; not a minute stopped or stayed he;
    But, with mien of lord or lady, perched above my chamber door?
Perched upon a bust of Pallas just above my chamber door?
            Perched, and sat, and nothing more.

Then this ebony bird beguiling my sad fancy into smiling,
By the grave and stern decorum of the countenance it wore,
?Though thy crest be shorn and shaven, thou,? I said, ?art sure no craven,
Ghastly grim and ancient Raven wandering from the Nightly shore?
Tell me what thy lordly name is on the Night?s Plutonian shore!?
            Quoth the Raven ?Nevermore.?

    Much I marvelled this ungainly fowl to hear discourse so plainly,
Though its answer little meaning?little relevancy bore;
    For we cannot help agreeing that no living human being
    Ever yet was blessed with seeing bird above his chamber door?
Bird or beast upon the sculptured bust above his chamber door,
            With such name as ?Nevermore.?

    But the Raven, sitting lonely on the placid bust, spoke only
That one word, as if his soul in that one word he did outpour.
    Nothing farther then he uttered?not a feather then he fluttered?
    Till I scarcely more than muttered ?Other friends have flown before?
On the morrow he will leave me, as my Hopes have flown before.?
            Then the bird said ?Nevermore.?

    Startled at the stillness broken by reply so aptly spoken,
?Doubtless,? said I, ?what it utters is its only stock and store
    Caught from some unhappy master whom unmerciful Disaster
    Followed fast and followed faster till his songs one burden bore?
Till the dirges of his Hope that melancholy burden bore
            Of ?Never?nevermore?.?

    But the Raven still beguiling all my fancy into smiling,
Straight I wheeled a cushioned seat in front of bird, and bust and door;
    Then, upon the velvet sinking, I betook myself to linking
    Fancy unto fancy, thinking what this ominous bird of yore?
What this grim, ungainly, ghastly, gaunt, and ominous bird of yore
            Meant in croaking ?Nevermore.?

    This I sat engaged in guessing, but no syllable expressing
To the fowl whose fiery eyes now burned into my bosom?s core;
    This and more I sat divining, with my head at ease reclining
    On the cushion?s velvet lining that the lamp-light gloated o?er,
But whose velvet-violet lining with the lamp-light gloating o?er,
            She shall press, ah, nevermore!

    Then, methought, the air grew denser, perfumed from an unseen censer
Swung by Seraphim whose foot-falls tinkled on the tufted floor.
    ?Wretch,? I cried, ?thy God hath lent thee?by these angels he hath sent thee
    Respite?respite and nepenthe from thy memories of Lenore;
Quaff, oh quaff this kind nepenthe and forget this lost Lenore!?
            Quoth the Raven ?Nevermore.?

    ?Prophet!? said I, ?thing of evil!?prophet still, if bird or devil!?
Whether Tempter sent, or whether tempest tossed thee here ashore,
    Desolate yet all undaunted, on this desert land enchanted?
    On this home by Horror haunted?tell me truly, I implore?
Is there?is there balm in Gilead??tell me?tell me, I implore!?
            Quoth the Raven ?Nevermore.?

    ?Prophet!? said I, ?thing of evil!?prophet still, if bird or devil!
By that Heaven that bends above us?by that God we both adore?
    Tell this soul with sorrow laden if, within the distant Aidenn,
    It shall clasp a sainted maiden whom the angels name Lenore?
Clasp a rare and radiant maiden whom the angels name Lenore.?
            Quoth the Raven ?Nevermore.?

    ?Be that word our sign of parting, bird or fiend!? I shrieked, upstarting?
?Get thee back into the tempest and the Night?s Plutonian shore!
    Leave no black plume as a token of that lie thy soul hath spoken!
    Leave my loneliness unbroken!?quit the bust above my door!
Take thy beak from out my heart, and take thy form from off my door!?
            Quoth the Raven ?Nevermore.?

    And the Raven, never flitting, still is sitting, still is sitting
On the pallid bust of Pallas just above my chamber door;
    And his eyes have all the seeming of a demon?s that is dreaming,
    And the lamp-light o?er him streaming throws his shadow on the floor;
And my soul from out that shadow that lies floating on the floor
            Shall be lifted?nevermore!

https://www.youtube.com/watch?v=BefliMlEzZ8


From |r@|nj @end|ng |rom gm@||@com  Fri Dec 11 22:18:18 2020
From: |r@|nj @end|ng |rom gm@||@com (John C Frain)
Date: Fri, 11 Dec 2020 21:18:18 +0000
Subject: [R] Help with connection issue for R (just joined,
 leading R for our agency)
In-Reply-To: <87pn3gfuvc.fsf@gmail.com>
References: <CANoEdVaWBLqWLb2pvmSkOBkEFb8sZh7gc04LbBwTPqqLwgyYeg@mail.gmail.com>
 <87pn3gfuvc.fsf@gmail.com>
Message-ID: <CAHrK5168j6vS2pm5Jb9T6AWDCWD+bm2b8XuZPFs1GUqKatd28Q@mail.gmail.com>

On Fri, 11 Dec 2020 at 11:25, Jeremie Juste <jeremiejuste at gmail.com> wrote:


snip

>
> That said, I take the opportunity Martin gave me to advertise that both
> Emacs and  Emacs Speaks Statistics works on Windows as well. The entry
> cost might seem
> expensive in the beginning but I assure you it will pay very quickly.
>
> - For emacs
>    - https://www.gnu.org/software/emacs/tour/
>    - https://www.youtube.com/watch?v=Iagbv974GlQ
>    - emacs mailing-list help-gnu-emacs at gnu.org
>
> - For ESS
>    -  https://ess.r-project.org/
>    -  ESS mailing list https://stat.ethz.ch/mailman/listinfo/ess-help
>
>
> Best regards,
> Jeremie
>
> For Windows, Vincent Goulet has a windows installer of emacs 27.1 that
includes ESS, Auctex for LaTex, and a lot of other emacs extras.  This
installer simplifies the installation of Emacs on windows

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Dec 12 00:50:15 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 12 Dec 2020 12:50:15 +1300
Subject: [R] nls() syntax
Message-ID: <20201212125015.53b31218@rolf-Latitude-E7470>



I want to fit a model y = x/(x-a) where the value of a depends
on the level of a factor z.  I cannot figure out an appropriate
syntax for nls().  The "parameter" a (to be estimated) should be a
vector of length equal to the number of levels of z.

I tried:

strt <- rep(3,length(levels(z))
names(strt=levels(z)
fit <- nls(y ~ x/(x - a[z]),start=strt,data=xxx)

but of course got an error:

> Error in nls(y ~ x/(x - a[z]), start = strt, data = xxx) : 
>   parameters without starting value in 'data': a

I keep thinking that there is something obvious that I should
be doing, but I can't work out what it is.

Does there *exist* an appropriate syntax for doing what I want
to do?  Can anyone enlighten me?  The data set "xxx" is given
in dput() form at the end of this message.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

Data set "xxx":

structure(list(x = c(30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 
130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 
30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 
170, 180, 190, 200, 210, 220, 230, 240, 250, 30, 40, 50, 60, 
70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 
200, 210, 220, 230, 240, 250, 30, 40, 50, 60, 70, 80, 90, 100, 
110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 
240, 250, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 
150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250), y = c(1.27, 
1.16, 1.19, 1.15, 1.09, 1.07, 1.07, 1.05, 1.07, 1.03, 1.05, 1.07, 
1.06, 1.03, 1.05, 1.04, 1.03, 1.03, 1.03, 1.02, 1.02, 1.01, 1.01, 
1.21, 1.15, 1.1, 1.1, 1.06, 1.06, 1.05, 1.03, 1.07, 1.04, 1.04, 
1.02, 1.04, 1.02, 1.04, 1.03, 1.01, 1.03, 1.01, 1, 1.02, 1.03, 
1.02, 1.42, 1.27, 1.23, 1.14, 1.17, 1.08, 1.11, 1.06, 1.07, 1.08, 
1.06, 1.07, 1.04, 1.03, 1.07, 1.04, 1.03, 1.03, 1.03, 1.04, 1.03, 
1.03, 1.04, 1.85, 1.41, 1.35, 1.21, 1.22, 1.15, 1.14, 1.07, 1.1, 
1.09, 1.1, 1.09, 1.08, 1.08, 1.09, 1.09, 1.07, 1.06, 1.03, 1.08, 
1.05, 1.02, 1.05, 1.99, 1.6, 1.44, 1.4, 1.24, 1.3, 1.21, 1.23, 
1.18, 1.18, 1.12, 1.15, 1.09, 1.07, 1.13, 1.1, 1.05, 1.13, 1.09, 
1.03, 1.11, 1.07, 1.05), z = structure(c(1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("p1", 
"p2", "p3", "p4", "p5"), class = "factor")), class = "data.frame", row.names = c(NA, 
-115L))


From ggrothend|eck @end|ng |rom gm@||@com  Sat Dec 12 01:20:26 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Fri, 11 Dec 2020 19:20:26 -0500
Subject: [R] nls() syntax
In-Reply-To: <20201212125015.53b31218@rolf-Latitude-E7470>
References: <20201212125015.53b31218@rolf-Latitude-E7470>
Message-ID: <CAP01uRm7RGdSQK=hDecbegvec9RkskzQVFtvr3SOTgE-cV5L=Q@mail.gmail.com>

The start= argument should be as follows:

 nls(y ~ x/(x - a[z]),start=list(a = strt),data=xxx)

On Fri, Dec 11, 2020 at 6:51 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
>
> I want to fit a model y = x/(x-a) where the value of a depends
> on the level of a factor z.  I cannot figure out an appropriate
> syntax for nls().  The "parameter" a (to be estimated) should be a
> vector of length equal to the number of levels of z.
>
> I tried:
>
> strt <- rep(3,length(levels(z))
> names(strt=levels(z)
> fit <- nls(y ~ x/(x - a[z]),start=strt,data=xxx)
>
> but of course got an error:
>
> > Error in nls(y ~ x/(x - a[z]), start = strt, data = xxx) :
> >   parameters without starting value in 'data': a
>
> I keep thinking that there is something obvious that I should
> be doing, but I can't work out what it is.
>
> Does there *exist* an appropriate syntax for doing what I want
> to do?  Can anyone enlighten me?  The data set "xxx" is given
> in dput() form at the end of this message.
>
> cheers,
>
> Rolf Turner
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> Data set "xxx":
>
> structure(list(x = c(30, 40, 50, 60, 70, 80, 90, 100, 110, 120,
> 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,
> 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160,
> 170, 180, 190, 200, 210, 220, 230, 240, 250, 30, 40, 50, 60,
> 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190,
> 200, 210, 220, 230, 240, 250, 30, 40, 50, 60, 70, 80, 90, 100,
> 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230,
> 240, 250, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140,
> 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250), y = c(1.27,
> 1.16, 1.19, 1.15, 1.09, 1.07, 1.07, 1.05, 1.07, 1.03, 1.05, 1.07,
> 1.06, 1.03, 1.05, 1.04, 1.03, 1.03, 1.03, 1.02, 1.02, 1.01, 1.01,
> 1.21, 1.15, 1.1, 1.1, 1.06, 1.06, 1.05, 1.03, 1.07, 1.04, 1.04,
> 1.02, 1.04, 1.02, 1.04, 1.03, 1.01, 1.03, 1.01, 1, 1.02, 1.03,
> 1.02, 1.42, 1.27, 1.23, 1.14, 1.17, 1.08, 1.11, 1.06, 1.07, 1.08,
> 1.06, 1.07, 1.04, 1.03, 1.07, 1.04, 1.03, 1.03, 1.03, 1.04, 1.03,
> 1.03, 1.04, 1.85, 1.41, 1.35, 1.21, 1.22, 1.15, 1.14, 1.07, 1.1,
> 1.09, 1.1, 1.09, 1.08, 1.08, 1.09, 1.09, 1.07, 1.06, 1.03, 1.08,
> 1.05, 1.02, 1.05, 1.99, 1.6, 1.44, 1.4, 1.24, 1.3, 1.21, 1.23,
> 1.18, 1.18, 1.12, 1.15, 1.09, 1.07, 1.13, 1.1, 1.05, 1.13, 1.09,
> 1.03, 1.11, 1.07, 1.05), z = structure(c(1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label = c("p1",
> "p2", "p3", "p4", "p5"), class = "factor")), class = "data.frame", row.names = c(NA,
> -115L))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Dec 12 03:25:11 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 11 Dec 2020 21:25:11 -0500
Subject: [R] nls() syntax
In-Reply-To: <20201212125015.53b31218@rolf-Latitude-E7470>
References: <20201212125015.53b31218@rolf-Latitude-E7470>
Message-ID: <6455747c-c652-4a13-eafd-7c7456321210@gmail.com>

On 11/12/2020 6:50 p.m., Rolf Turner wrote:
> 
> 
> I want to fit a model y = x/(x-a) where the value of a depends
> on the level of a factor z.  I cannot figure out an appropriate
> syntax for nls().  The "parameter" a (to be estimated) should be a
> vector of length equal to the number of levels of z.
> 
> I tried:
> 
> strt <- rep(3,length(levels(z))
> names(strt=levels(z)
> fit <- nls(y ~ x/(x - a[z]),start=strt,data=xxx)
> 
> but of course got an error:
> 
>> Error in nls(y ~ x/(x - a[z]), start = strt, data = xxx) :
>>    parameters without starting value in 'data': a
> 
> I keep thinking that there is something obvious that I should
> be doing, but I can't work out what it is.
> 
> Does there *exist* an appropriate syntax for doing what I want
> to do?  Can anyone enlighten me?  The data set "xxx" is given
> in dput() form at the end of this message.


I don't know of anything easy here.  I think you need to do some tricky 
stuff with formulas to get what you want.  For example,

pred <- function(x, z, ...) {
   a <- unlist(list(...))
   names(a) <- levels(xxx$z)
   x/(x-a[z])
}
strt <- rep(3,length(levels(xxx$z)))
names(strt) <- levels(xxx$z)
fla <- y ~ pred(x, z)
fla[[3]] <- as.call(c(as.list(fla[[3]]), lapply(levels(xxx$z), as.name)))
fit <- nls(fla,start=strt,data=xxx)

That line starting fla[[3]] is the ugly part:  it takes the simple 
formula y ~ pred(x, z) and changes it to y ~ pred(x, z, a1, a2, a3, a4, 
a5).  As far as I know, nls() can't handle vector paramters, it only 
deals with scalars, so this passes them each as a separate argument.

Maybe rlang or one of the other packages like that has code to make this 
less obscure.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Dec 12 03:39:11 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 12 Dec 2020 15:39:11 +1300
Subject: [R] nls() syntax
In-Reply-To: <CAP01uRm7RGdSQK=hDecbegvec9RkskzQVFtvr3SOTgE-cV5L=Q@mail.gmail.com>
References: <20201212125015.53b31218@rolf-Latitude-E7470>
 <CAP01uRm7RGdSQK=hDecbegvec9RkskzQVFtvr3SOTgE-cV5L=Q@mail.gmail.com>
Message-ID: <20201212153911.61d05c13@rolf-Latitude-E7470>


On Fri, 11 Dec 2020 19:20:26 -0500
Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> The start= argument should be as follows:
> 
>  nls(y ~ x/(x - a[z]),start=list(a = strt),data=xxx)

Nya-ha!  I, uh, clearly wasn't thinking clearly!  (Feel a bit *duh*
now!)

Thanks Gabor.

cheers,

Rolf

> 
> On Fri, Dec 11, 2020 at 6:51 PM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >
> >
> >
> > I want to fit a model y = x/(x-a) where the value of a depends
> > on the level of a factor z.  I cannot figure out an appropriate
> > syntax for nls().  The "parameter" a (to be estimated) should be a
> > vector of length equal to the number of levels of z.
> >
> > I tried:
> >
> > strt <- rep(3,length(levels(z))
> > names(strt=levels(z)
> > fit <- nls(y ~ x/(x - a[z]),start=strt,data=xxx)
> >
> > but of course got an error:
> >  
> > > Error in nls(y ~ x/(x - a[z]), start = strt, data = xxx) :
> > >   parameters without starting value in 'data': a  
> >
> > I keep thinking that there is something obvious that I should
> > be doing, but I can't work out what it is.
> >
> > Does there *exist* an appropriate syntax for doing what I want
> > to do?  Can anyone enlighten me?  The data set "xxx" is given
> > in dput() form at the end of this message.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > Data set "xxx":
> >
> > structure(list(x = c(30, 40, 50, 60, 70, 80, 90, 100, 110, 120,
> > 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,
> > 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160,
> > 170, 180, 190, 200, 210, 220, 230, 240, 250, 30, 40, 50, 60,
> > 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190,
> > 200, 210, 220, 230, 240, 250, 30, 40, 50, 60, 70, 80, 90, 100,
> > 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230,
> > 240, 250, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140,
> > 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250), y = c(1.27,
> > 1.16, 1.19, 1.15, 1.09, 1.07, 1.07, 1.05, 1.07, 1.03, 1.05, 1.07,
> > 1.06, 1.03, 1.05, 1.04, 1.03, 1.03, 1.03, 1.02, 1.02, 1.01, 1.01,
> > 1.21, 1.15, 1.1, 1.1, 1.06, 1.06, 1.05, 1.03, 1.07, 1.04, 1.04,
> > 1.02, 1.04, 1.02, 1.04, 1.03, 1.01, 1.03, 1.01, 1, 1.02, 1.03,
> > 1.02, 1.42, 1.27, 1.23, 1.14, 1.17, 1.08, 1.11, 1.06, 1.07, 1.08,
> > 1.06, 1.07, 1.04, 1.03, 1.07, 1.04, 1.03, 1.03, 1.03, 1.04, 1.03,
> > 1.03, 1.04, 1.85, 1.41, 1.35, 1.21, 1.22, 1.15, 1.14, 1.07, 1.1,
> > 1.09, 1.1, 1.09, 1.08, 1.08, 1.09, 1.09, 1.07, 1.06, 1.03, 1.08,
> > 1.05, 1.02, 1.05, 1.99, 1.6, 1.44, 1.4, 1.24, 1.3, 1.21, 1.23,
> > 1.18, 1.18, 1.12, 1.15, 1.09, 1.07, 1.13, 1.1, 1.05, 1.13, 1.09,
> > 1.03, 1.11, 1.07, 1.05), z = structure(c(1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> > 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> > 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label =
> > c("p1", "p2", "p3", "p4", "p5"), class = "factor")), class =
> > "data.frame", row.names = c(NA, -115L))


From er|nm@hodge@@ @end|ng |rom gm@||@com  Sat Dec 12 05:44:28 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Fri, 11 Dec 2020 21:44:28 -0700
Subject: [R] A holiday related question
Message-ID: <CACxE24mGCM577R_O7uamg1AvNUcprL4sZNFQNpBU=mboNb9WWg@mail.gmail.com>

Hello everyone!

Hope you are all doing well and enjoying whatever December holiday you
celebrate.

Here is my question, please.  Has anyone put together R with a Raspberry Pi
or an Arduino to run music and Christmas lights, please?  I have seen a
little bit about using R with Raspberry Pi, but really nothing in this
vein.

In the past, I have used R with an Ubuntu laptop to run a temperature
sensor, which is a start.

Thanks for any suggestions.  Take care.

Sincerely,
Erin

-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Sat Dec 12 08:39:35 2020
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Sat, 12 Dec 2020 07:39:35 +0000
Subject: [R] [EXT] Re:  nls() syntax
In-Reply-To: <20201212153911.61d05c13@rolf-Latitude-E7470>
References: <20201212125015.53b31218@rolf-Latitude-E7470>
 <CAP01uRm7RGdSQK=hDecbegvec9RkskzQVFtvr3SOTgE-cV5L=Q@mail.gmail.com>,
 <20201212153911.61d05c13@rolf-Latitude-E7470>
Message-ID: <MEAPR01MB45362421F4949BDD942B0467E2C90@MEAPR01MB4536.ausprd01.prod.outlook.com>

Hi Rolf,

It might also be worth experimenting to see if

y ~ 1 / ( 1 - a[z]/x )

yields the same result. It might be cleaner if x appears only once in the expression.

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA; Professor of Biosecurity
School of BioSciences
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: http://cebra.unimelb.edu.au/

I acknowledge the traditional owners of the land I inhabit and pay my respects to their elders.
________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Rolf Turner <r.turner at auckland.ac.nz>
Sent: Saturday, December 12, 2020 1:39:11 PM
To: Gabor Grothendieck <ggrothendieck at gmail.com>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: [EXT] Re: [R] nls() syntax

UoM notice: External email. Be cautious of links, attachments, or impersonation attempts


On Fri, 11 Dec 2020 19:20:26 -0500
Gabor Grothendieck <ggrothendieck at gmail.com> wrote:

> The start= argument should be as follows:
>
>  nls(y ~ x/(x - a[z]),start=list(a = strt),data=xxx)

Nya-ha!  I, uh, clearly wasn't thinking clearly!  (Feel a bit *duh*
now!)

Thanks Gabor.

cheers,

Rolf

>
> On Fri, Dec 11, 2020 at 6:51 PM Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >
> >
> >
> > I want to fit a model y = x/(x-a) where the value of a depends
> > on the level of a factor z.  I cannot figure out an appropriate
> > syntax for nls().  The "parameter" a (to be estimated) should be a
> > vector of length equal to the number of levels of z.
> >
> > I tried:
> >
> > strt <- rep(3,length(levels(z))
> > names(strt=levels(z)
> > fit <- nls(y ~ x/(x - a[z]),start=strt,data=xxx)
> >
> > but of course got an error:
> >
> > > Error in nls(y ~ x/(x - a[z]), start = strt, data = xxx) :
> > >   parameters without starting value in 'data': a
> >
> > I keep thinking that there is something obvious that I should
> > be doing, but I can't work out what it is.
> >
> > Does there *exist* an appropriate syntax for doing what I want
> > to do?  Can anyone enlighten me?  The data set "xxx" is given
> > in dput() form at the end of this message.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > Data set "xxx":
> >
> > structure(list(x = c(30, 40, 50, 60, 70, 80, 90, 100, 110, 120,
> > 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,
> > 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160,
> > 170, 180, 190, 200, 210, 220, 230, 240, 250, 30, 40, 50, 60,
> > 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190,
> > 200, 210, 220, 230, 240, 250, 30, 40, 50, 60, 70, 80, 90, 100,
> > 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230,
> > 240, 250, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140,
> > 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250), y = c(1.27,
> > 1.16, 1.19, 1.15, 1.09, 1.07, 1.07, 1.05, 1.07, 1.03, 1.05, 1.07,
> > 1.06, 1.03, 1.05, 1.04, 1.03, 1.03, 1.03, 1.02, 1.02, 1.01, 1.01,
> > 1.21, 1.15, 1.1, 1.1, 1.06, 1.06, 1.05, 1.03, 1.07, 1.04, 1.04,
> > 1.02, 1.04, 1.02, 1.04, 1.03, 1.01, 1.03, 1.01, 1, 1.02, 1.03,
> > 1.02, 1.42, 1.27, 1.23, 1.14, 1.17, 1.08, 1.11, 1.06, 1.07, 1.08,
> > 1.06, 1.07, 1.04, 1.03, 1.07, 1.04, 1.03, 1.03, 1.03, 1.04, 1.03,
> > 1.03, 1.04, 1.85, 1.41, 1.35, 1.21, 1.22, 1.15, 1.14, 1.07, 1.1,
> > 1.09, 1.1, 1.09, 1.08, 1.08, 1.09, 1.09, 1.07, 1.06, 1.03, 1.08,
> > 1.05, 1.02, 1.05, 1.99, 1.6, 1.44, 1.4, 1.24, 1.3, 1.21, 1.23,
> > 1.18, 1.18, 1.12, 1.15, 1.09, 1.07, 1.13, 1.1, 1.05, 1.13, 1.09,
> > 1.03, 1.11, 1.07, 1.05), z = structure(c(1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> > 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> > 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> > 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L), .Label =
> > c("p1", "p2", "p3", "p4", "p5"), class = "factor")), class =
> > "data.frame", row.names = c(NA, -115L))

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jov@n|@ouz@5 @end|ng |rom gm@||@com  Sat Dec 12 16:27:18 2020
From: jov@n|@ouz@5 @end|ng |rom gm@||@com (Jovani T. de Souza)
Date: Sat, 12 Dec 2020 12:27:18 -0300
Subject: [R] Find the ideal cluster
Message-ID: <CADs2LWRPxb2h1-hv=RbYiwnLCwqXKFkKYD-SNoyT+DYc8zQTvQ@mail.gmail.com>

So, I and some other colleagues developed a hierarchical clustering
algorithm to basically find the main clusters involving agricultural
industries according to a particular city (e.g. London city).. We
structured this algorithm in R. It is working perfectly. So, according to
our filters that we inserted in the algorithm, we were able to generate 6
clustering scenarios to London city. For example, the first scenario
generated 2 clusters, the second scenario 5 clusters, and so on. I would
therefore like some help on how I can choose the most appropriate one. I
saw that there are some packages that help in this process, like `pvclust`,
but I couldn't use it for my case. I am inserting a brief executable code
below to show the essence of what I want.

Any help is welcome! If you know how to use using another package, feel
free to describe.

Best Regards.


    library(rdist)
    library(geosphere)
    library(fpc)


    df<-structure(list(Industries = c(1,2,3,4,5,6),
    +                    Latitude = c(-23.8, -23.8, -23.9, -23.7,
-23.7,-23.7),
    +                    Longitude = c(-49.5, -49.6, -49.7, -49.8,
-49.6,-49.9),
    +                    Waste = c(526, 350, 526, 469, 534, 346)), class =
"data.frame", row.names = c(NA, -6L))

    df1<-df

    #clusters
    coordinates<-df[c("Latitude","Longitude")]
    d<-as.dist(distm(coordinates[,2:1]))
    fit.average<-hclust(d,method="average")

    clusters<-cutree(fit.average, k=2)
    df$cluster <- clusters
    > df
      Industries Latitude Longitude Waste cluster
    1          1    -23.8     -49.5   526       1
    2          2    -23.8     -49.6   350       1
    3          3    -23.9     -49.7   526       1
    4          4    -23.7     -49.8   469       2
    5          5    -23.7     -49.6   534       1
    6          6    -23.7     -49.9   346       2
    >
    clusters1<-cutree(fit.average, k=5)
    df1$cluster <- clusters1
    > df1
      Industries Latitude Longitude Waste cluster
    1          1    -23.8     -49.5   526       1
    2          2    -23.8     -49.6   350       1
    3          3    -23.9     -49.7   526       2
    4          4    -23.7     -49.8   469       3
    5          5    -23.7     -49.6   534       4
    6          6    -23.7     -49.9   346       5
    >

	[[alternative HTML version deleted]]


From dc@r|@on @end|ng |rom t@mu@edu  Sat Dec 12 16:49:46 2020
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Sat, 12 Dec 2020 09:49:46 -0600
Subject: [R] Find the ideal cluster
In-Reply-To: <CADs2LWRPxb2h1-hv=RbYiwnLCwqXKFkKYD-SNoyT+DYc8zQTvQ@mail.gmail.com>
References: <CADs2LWRPxb2h1-hv=RbYiwnLCwqXKFkKYD-SNoyT+DYc8zQTvQ@mail.gmail.com>
Message-ID: <CAE-dL2qk6itKwpoCLwQVsq15TC=9gxs96a8agSKGTMFqUrAC7w@mail.gmail.com>

Look at the Cluster Analysis Task View, particularly section
"Additional Functionality"
(https://cran.r-project.org/web/views/Cluster.html)

Maybe package clValid:

The R package clValid contains functions for validating the results
of a clustering analysis. There are three main types of cluster
validation measures available, ?internal?, ?stability?, and
?biological?. The user can choose from nine clustering algorithms in
existing R packages, including hierarchical, K-means, self-organizing
maps (SOM), and model based clustering. In addition, we provide a
function to perform the self-organizing tree algorithm (SOTA) method
of clustering. Any combination of validation measures and clustering
methods can be requested in a single function call. This allows the
user to simultaneously evaluate several clustering algorithms while
varying the number of clusters, to help determine the most appropriate
method and number of clusters for the dataset of interest.
Additionally, the package can automatically make use of the biological
information contained in the Gene Ontology (GO) database to calculate
the biological validation measures, via the annotation packages
available in Bioconductor. The function returns an object of S4 class
clValid, which has summary, plot, print, and additional methods which
allow the user to display the optimal validation scores and extract
clustering results.

David L Carlson
Professor Emeritus
Texas A&M University


On Sat, Dec 12, 2020 at 9:27 AM Jovani T. de Souza
<jovanisouza5 at gmail.com> wrote:
>
> So, I and some other colleagues developed a hierarchical clustering
> algorithm to basically find the main clusters involving agricultural
> industries according to a particular city (e.g. London city).. We
> structured this algorithm in R. It is working perfectly. So, according to
> our filters that we inserted in the algorithm, we were able to generate 6
> clustering scenarios to London city. For example, the first scenario
> generated 2 clusters, the second scenario 5 clusters, and so on. I would
> therefore like some help on how I can choose the most appropriate one. I
> saw that there are some packages that help in this process, like `pvclust`,
> but I couldn't use it for my case. I am inserting a brief executable code
> below to show the essence of what I want.
>
> Any help is welcome! If you know how to use using another package, feel
> free to describe.
>
> Best Regards.
>
>
>     library(rdist)
>     library(geosphere)
>     library(fpc)
>
>
>     df<-structure(list(Industries = c(1,2,3,4,5,6),
>     +                    Latitude = c(-23.8, -23.8, -23.9, -23.7,
> -23.7,-23.7),
>     +                    Longitude = c(-49.5, -49.6, -49.7, -49.8,
> -49.6,-49.9),
>     +                    Waste = c(526, 350, 526, 469, 534, 346)), class =
> "data.frame", row.names = c(NA, -6L))
>
>     df1<-df
>
>     #clusters
>     coordinates<-df[c("Latitude","Longitude")]
>     d<-as.dist(distm(coordinates[,2:1]))
>     fit.average<-hclust(d,method="average")
>
>     clusters<-cutree(fit.average, k=2)
>     df$cluster <- clusters
>     > df
>       Industries Latitude Longitude Waste cluster
>     1          1    -23.8     -49.5   526       1
>     2          2    -23.8     -49.6   350       1
>     3          3    -23.9     -49.7   526       1
>     4          4    -23.7     -49.8   469       2
>     5          5    -23.7     -49.6   534       1
>     6          6    -23.7     -49.9   346       2
>     >
>     clusters1<-cutree(fit.average, k=5)
>     df1$cluster <- clusters1
>     > df1
>       Industries Latitude Longitude Waste cluster
>     1          1    -23.8     -49.5   526       1
>     2          2    -23.8     -49.6   350       1
>     3          3    -23.9     -49.7   526       2
>     4          4    -23.7     -49.8   469       3
>     5          5    -23.7     -49.6   534       4
>     6          6    -23.7     -49.9   346       5
>     >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!Tws97pkPo-5PwOFVXUKnAB17jy4Wop-N5HsB9u3NBOLATWcys9Qz_h8zZmhqq5I$
> PLEASE do read the posting guide https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!Tws97pkPo-5PwOFVXUKnAB17jy4Wop-N5HsB9u3NBOLATWcys9Qz_h8zUffJHwg$
> and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sat Dec 12 18:06:33 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sat, 12 Dec 2020 17:06:33 +0000
Subject: [R] Find the ideal cluster
In-Reply-To: <CADs2LWRPxb2h1-hv=RbYiwnLCwqXKFkKYD-SNoyT+DYc8zQTvQ@mail.gmail.com>
References: <CADs2LWRPxb2h1-hv=RbYiwnLCwqXKFkKYD-SNoyT+DYc8zQTvQ@mail.gmail.com>
Message-ID: <b96a1756-7b1e-e3ac-b584-cba9eae45fdf@dewey.myzen.co.uk>

Dear Jovani

If you cross-post on CrossValidated as well as here it is polite to give 
a link so people do not answer here when someone has already answered 
there, or vice versa.

Michael

On 12/12/2020 15:27, Jovani T. de Souza wrote:
> So, I and some other colleagues developed a hierarchical clustering
> algorithm to basically find the main clusters involving agricultural
> industries according to a particular city (e.g. London city).. We
> structured this algorithm in R. It is working perfectly. So, according to
> our filters that we inserted in the algorithm, we were able to generate 6
> clustering scenarios to London city. For example, the first scenario
> generated 2 clusters, the second scenario 5 clusters, and so on. I would
> therefore like some help on how I can choose the most appropriate one. I
> saw that there are some packages that help in this process, like `pvclust`,
> but I couldn't use it for my case. I am inserting a brief executable code
> below to show the essence of what I want.
> 
> Any help is welcome! If you know how to use using another package, feel
> free to describe.
> 
> Best Regards.
> 
> 
>      library(rdist)
>      library(geosphere)
>      library(fpc)
> 
> 
>      df<-structure(list(Industries = c(1,2,3,4,5,6),
>      +                    Latitude = c(-23.8, -23.8, -23.9, -23.7,
> -23.7,-23.7),
>      +                    Longitude = c(-49.5, -49.6, -49.7, -49.8,
> -49.6,-49.9),
>      +                    Waste = c(526, 350, 526, 469, 534, 346)), class =
> "data.frame", row.names = c(NA, -6L))
> 
>      df1<-df
> 
>      #clusters
>      coordinates<-df[c("Latitude","Longitude")]
>      d<-as.dist(distm(coordinates[,2:1]))
>      fit.average<-hclust(d,method="average")
> 
>      clusters<-cutree(fit.average, k=2)
>      df$cluster <- clusters
>      > df
>        Industries Latitude Longitude Waste cluster
>      1          1    -23.8     -49.5   526       1
>      2          2    -23.8     -49.6   350       1
>      3          3    -23.9     -49.7   526       1
>      4          4    -23.7     -49.8   469       2
>      5          5    -23.7     -49.6   534       1
>      6          6    -23.7     -49.9   346       2
>      >
>      clusters1<-cutree(fit.average, k=5)
>      df1$cluster <- clusters1
>      > df1
>        Industries Latitude Longitude Waste cluster
>      1          1    -23.8     -49.5   526       1
>      2          2    -23.8     -49.6   350       1
>      3          3    -23.9     -49.7   526       2
>      4          4    -23.7     -49.8   469       3
>      5          5    -23.7     -49.6   534       4
>      6          6    -23.7     -49.9   346       5
>      >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From mr@|uced@n @end|ng |rom hotm@||@|t  Sat Dec 12 18:36:46 2020
From: mr@|uced@n @end|ng |rom hotm@||@|t (Luca Danieli)
Date: Sat, 12 Dec 2020 17:36:46 +0000
Subject: [R] Problem with contrast() - nonconforming number of contrast
 coefficients
Message-ID: <VI1PR03MB3677437078ED28CF4A965DD5F6C90@VI1PR03MB3677.eurprd03.prod.outlook.com>

Hello,

I have written this question on a problem that I have with the method contrast() in this Stackoverflow.
Is here anybody who can advise me on a method to do what I aim to do?

https://stackoverflow.com/questions/65267565/r-lsmeans-contrast-error-nonconforming-number-of-contrast-coefficients

Best
Luca

-----------------------------------------------
Luca Danieli
Ph.D. in music composition
University of Birmingham
http://www.lucadanieli.org
CV: https://bham.academia.edu/LucaDanieli/CurriculumVitae

	[[alternative HTML version deleted]]


From Br|@n@Beck@ge @end|ng |rom uvm@edu  Sun Dec 13 21:49:26 2020
From: Br|@n@Beck@ge @end|ng |rom uvm@edu (Brian Beckage)
Date: Sun, 13 Dec 2020 20:49:26 +0000
Subject: [R] ggplot2 + coord_cartesian + automatic ylim
Message-ID: <876A72CF-5663-42FB-81A3-E632C298ED87@uvm.edu>

As an example to illustrate my question, if I used the following code to plot the price of Apple stock using the tidyquant package and ggplot2


AAPL<-tq_get(x="AAPL")

AAPL %>%
  ggplot(aes(x = date, y = close)) +
  geom_line() +
  labs(title = "AAPL", y = "Closing Price", x = "") +
  coord_x_date(xlim=c(end-weeks(10),end),ylim=c(100,150)) +
  theme_tq()

but I would like the ylim to be set automatically based on the xlim.  In base R, this is a simple thing to do. ggplot is still a bit mysterious to me (not alway clear how it works) and so I would like to automatically set the ylim range based on the xlim range,  something  like the following, though it obviously does not work:


AAPL<-tq_get(x="AAPL")

AAPL %>%
  ggplot(aes(x = date, y = close)) +
  geom_line() +
  labs(title = "AAPL Line Chart", y = "Closing Price", x = "") +
  coord_x_date(xlim=c(end-weeks(10),end),ylim=c(min(y),max(y)) +
  theme_tq()

where the y vector corresponds to the y range delimited by xlim.  Note that coord_x_date is a wrapper for coord_cartesian.

So how do I ?see? and use the data and parms being utilized by ggplot to set the ylim?  Or more generally, how do you step through code like to this to examine for instance what exactly coord_x_date is doing?

Thanks,
Brian







	[[alternative HTML version deleted]]


From gregco@t@ @end|ng |rom me@com  Sat Dec 12 20:18:46 2020
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Sat, 12 Dec 2020 14:18:46 -0500
Subject: [R] How to specify year-month-day for a plot
Message-ID: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>

Starting with year-month-day, for the variable gallons, I can easily plot the variable gallons, while disregarding the date. 
gallons <- c (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226, 14.338, 18.777, 19.652)
plot (gallons, type="l", xlab="X label", ylab="Y label", col="blue?)

How do I direct R to plot the variable gallons, at the appropriate, irregularly-spaced places on the X axis, while paying attention to the year-month-day?

format = "%Y-%m-%d?
2020-01-05 15.973
2020-02-15 18.832
2020-03-10 17.392
2020-05-04 14.774
2020-06-21 19.248
2020-08-01 14.913
2020-08-27 15.226
2020-09-28 14.338
2020-11-09 18.777
2020-12-11 19.652
	[[alternative HTML version deleted]]


From wen||ng||ng912 @end|ng |rom gm@||@com  Sat Dec 12 22:53:25 2020
From: wen||ng||ng912 @end|ng |rom gm@||@com (Lingling Wen)
Date: Sat, 12 Dec 2020 23:53:25 +0200
Subject: [R] multiple t-test with different species and treatments
Message-ID: <CAJ9SxKYWRgAJVpGZFb-v4pyMYGVsr2Hb5=nHn6t4zVc+SDQqxA@mail.gmail.com>

Dear R users,
I would like to ask for help with the code of multiple t-test. I have a
dataset as followed:
Species Treatment var1 var2 var2 var4 var5 var6
Blue D 0.022620093 0.125079631 0.04522571 0.010105835 0.013418019
1.455646741
Blue D 0.02117295 0.073544277 0.0311234 0.008742305 0.03261776 0.982196898
Blue D 0.021896521 0.112681274 0.05664344 0.013512548 0.032380618
1.777003683
Green D 0.032749726 0.087705198 0.13699174 0.009902168 0.083534492
1.553758965
Green D 0.036468693 0.115829755 0.10941521 0.012139481 0.206929915
2.610557732
Green D 0.043594022 0.062832712 0.12232853 0.015045559 0.111687593
1.99552401
Orange D 0.022617656 0.11465489 0.02882994 0.013304181 0.018175693
1.72075866
Orange D 0.026211773 0.099294867 0.03387876 0.013408254 0.02971197
2.184955376
Orange D 0.032205662 0.057267709 0.03883165 0.007744362 0.026553323
1.27255601
White D 0.041135469 0.085531343 0.06921425 0.011496168 0.010196895
0.573205411
White D 0.045142458 0.111429194 0.03546278 0.009196729 0.009968818
0.748529991
White D 0.031471913 0.050175149 0.05233851 0.011447205 0.010424973
0.92385457
Blue W 0.022222296 0.112334911 0.04080824 0.016064488 0.031047157
0.885523847
Blue W 0.040238733 0.121941307 0.04239768 0.010310538 0.020106944
0.751643349
Blue W 0.031508947 0.131547704 0.05212774 0.015720985 0.013932284
0.881234886
Green W 0.021070032 0.121018603 0.38202466 0.022152283 0.038479532
0.662605036
Green W 0.026562365 0.108269047 0.44028708 0.019344875 0.090798566
0.746330971
Green W 0.02926478 0.084080729 0.32376224 0.012609717 0.097744041
0.969301308
Orange W 0.02456562 0.134535891 0.09135624 0.007701481 0.017310058
0.966322354
Orange W 0.032095541 0.149347595 0.06048885 0.010332579 0.017457175
0.561561725
Orange W 0.039120696 0.141941743 0.02962146 0.005889924 0.017162941
0.502529091
White W 0.033903057 0.061460583 0.0492955 0.012457767 0.029929334 0.70986421
White W 0.033630233 0.115782233 0.02675399 0.021391535 0.023774961
1.176680075
White W 0.030638581 0.065074112 0.03678494 0.014781912 0.03529703
0.805500558
I wanted to perform a t-test between the treatment "D" and "W" of each
species for all of the variables (var1, var2,...).  Could anyone suggest
the packages or code for this analysis?

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Dec 13 23:42:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 14 Dec 2020 09:42:11 +1100
Subject: [R] How to specify year-month-day for a plot
In-Reply-To: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>
References: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>
Message-ID: <CA+8X3fV=eZEA+WNQV+wkC4oiaYoTuFaALE2CtB9RY-0r1Bjgyw@mail.gmail.com>

Hi Gregory,
Here's a start:

gcdf<-read.table(text="2020-01-05 15.973
2020-02-15 18.832
2020-03-10 17.392
2020-05-04 14.774
2020-06-21 19.248
2020-08-01 14.913
2020-08-27 15.226
2020-09-28 14.338
2020-11-09 18.777
2020-12-11 19.652",
header=TRUE,stringsAsFactors=FALSE,
col.names=c("date","gallons"))
gcdf$date<-as.Date(gcdf$date,"%Y-%m-%d")
plot(gcdf$date,gcdf$gallons,main="Gallons by date",
xlab="Date",ylab="Gallons")

Jim

On Mon, Dec 14, 2020 at 9:33 AM Gregory Coats via R-help
<r-help at r-project.org> wrote:
>
> Starting with year-month-day, for the variable gallons, I can easily plot the variable gallons, while disregarding the date.
> gallons <- c (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226, 14.338, 18.777, 19.652)
> plot (gallons, type="l", xlab="X label", ylab="Y label", col="blue?)
>
> How do I direct R to plot the variable gallons, at the appropriate, irregularly-spaced places on the X axis, while paying attention to the year-month-day?
>
> format = "%Y-%m-%d?
> 2020-01-05 15.973
> 2020-02-15 18.832
> 2020-03-10 17.392
> 2020-05-04 14.774
> 2020-06-21 19.248
> 2020-08-01 14.913
> 2020-08-27 15.226
> 2020-09-28 14.338
> 2020-11-09 18.777
> 2020-12-11 19.652
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Dec 14 00:06:47 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 13 Dec 2020 15:06:47 -0800
Subject: [R] ggplot2 + coord_cartesian + automatic ylim
In-Reply-To: <876A72CF-5663-42FB-81A3-E632C298ED87@uvm.edu>
References: <876A72CF-5663-42FB-81A3-E632C298ED87@uvm.edu>
Message-ID: <6ab67d64-c22b-2bac-21a9-b6bba2834bf6@comcast.net>


On 12/13/20 12:49 PM, Brian Beckage wrote:
> As an example to illustrate my question, if I used the following code to plot the price of Apple stock using the tidyquant package and ggplot2
>
>
> AAPL<-tq_get(x="AAPL")
>
> AAPL %>%
>    ggplot(aes(x = date, y = close)) +
>    geom_line() +
>    labs(title = "AAPL", y = "Closing Price", x = "") +
>    coord_x_date(xlim=c(end-weeks(10),end),ylim=c(100,150)) +
>    theme_tq()
>
> but I would like the ylim to be set automatically based on the xlim.  In base R, this is a simple thing to do. ggplot is still a bit mysterious to me (not alway clear how it works) and so I would like to automatically set the ylim range based on the xlim range,  something  like the following, though it obviously does not work:
>
>
> AAPL<-tq_get(x="AAPL")
>
> AAPL %>%
>    ggplot(aes(x = date, y = close)) +
>    geom_line() +
>    labs(title = "AAPL Line Chart", y = "Closing Price", x = "") +
>    coord_x_date(xlim=c(end-weeks(10),end),ylim=c(min(y),max(y)) +
>    theme_tq()
>
> where the y vector corresponds to the y range delimited by xlim.  Note that coord_x_date is a wrapper for coord_cartesian.


Why not let ggplot do it for you by "filtering" the data down to the 
date range you expect.


AAPL %>% filter(date > end-weeks(10)) %>%
 ??? ggplot(aes(x = date, y = close)) +
 ??? geom_line() +
 ??? labs(title = "AAPL", y = "Closing Price", x = "") +
 ??? coord_x_date(xlim=c(end-weeks(10),end)) +
 ??? theme_tq()


Might not even need `coord_x_date` call at all.

>
> So how do I ?see? and use the data and parms being utilized by ggplot to set the ylim?  Or more generally, how do you step through code like to this to examine for instance what exactly coord_x_date is doing?
>
> Thanks,
> Brian
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Dec 14 00:08:11 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 13 Dec 2020 15:08:11 -0800
Subject: [R] How to specify year-month-day for a plot
In-Reply-To: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>
References: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>
Message-ID: <B6B3F935-7DBB-4FA1-A085-87E4D263AFCD@dcn.davis.ca.us>

By converting the character date data into a time-like type... e.g. ?as.Date and plotting y-vs-x.

On December 12, 2020 11:18:46 AM PST, Gregory Coats via R-help <r-help at r-project.org> wrote:
>Starting with year-month-day, for the variable gallons, I can easily
>plot the variable gallons, while disregarding the date. 
>gallons <- c (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226,
>14.338, 18.777, 19.652)
>plot (gallons, type="l", xlab="X label", ylab="Y label", col="blue?)
>
>How do I direct R to plot the variable gallons, at the appropriate,
>irregularly-spaced places on the X axis, while paying attention to the
>year-month-day?
>
>format = "%Y-%m-%d?
>2020-01-05 15.973
>2020-02-15 18.832
>2020-03-10 17.392
>2020-05-04 14.774
>2020-06-21 19.248
>2020-08-01 14.913
>2020-08-27 15.226
>2020-09-28 14.338
>2020-11-09 18.777
>2020-12-11 19.652
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Dec 14 00:19:14 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 13 Dec 2020 15:19:14 -0800
Subject: [R] multiple t-test with different species and treatments
In-Reply-To: <CAJ9SxKYWRgAJVpGZFb-v4pyMYGVsr2Hb5=nHn6t4zVc+SDQqxA@mail.gmail.com>
References: <CAJ9SxKYWRgAJVpGZFb-v4pyMYGVsr2Hb5=nHn6t4zVc+SDQqxA@mail.gmail.com>
Message-ID: <CAGxFJbQoC4ZWU+QvCdRgy9EVH14pZqs4P5mqcbHkNcPdn6uxBA@mail.gmail.com>

1. Please read and follow the posting guide linked below.
2. No html -- this is a plain text list.
3. Use ?dput to provide us your data so that we don't have to convert it
for you.
4. We expect you to first make an effort to do your own coding. See
?t.test, which you could also
have found yourself by a web search (rseek.org is a reasonable place to
search from for R-related stuff,
though I have usually found that a plain google search does the job).
5. Is this homework? -- this list has a no homework policy (see the posting
guide).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 13, 2020 at 2:33 PM Lingling Wen <wenlingling912 at gmail.com>
wrote:

> Dear R users,
> I would like to ask for help with the code of multiple t-test. I have a
> dataset as followed:
> Species Treatment var1 var2 var2 var4 var5 var6
> Blue D 0.022620093 0.125079631 0.04522571 0.010105835 0.013418019
> 1.455646741
> Blue D 0.02117295 0.073544277 0.0311234 0.008742305 0.03261776 0.982196898
> Blue D 0.021896521 0.112681274 0.05664344 0.013512548 0.032380618
> 1.777003683
> Green D 0.032749726 0.087705198 0.13699174 0.009902168 0.083534492
> 1.553758965
> Green D 0.036468693 0.115829755 0.10941521 0.012139481 0.206929915
> 2.610557732
> Green D 0.043594022 0.062832712 0.12232853 0.015045559 0.111687593
> 1.99552401
> Orange D 0.022617656 0.11465489 0.02882994 0.013304181 0.018175693
> 1.72075866
> Orange D 0.026211773 0.099294867 0.03387876 0.013408254 0.02971197
> 2.184955376
> Orange D 0.032205662 0.057267709 0.03883165 0.007744362 0.026553323
> 1.27255601
> White D 0.041135469 0.085531343 0.06921425 0.011496168 0.010196895
> 0.573205411
> White D 0.045142458 0.111429194 0.03546278 0.009196729 0.009968818
> 0.748529991
> White D 0.031471913 0.050175149 0.05233851 0.011447205 0.010424973
> 0.92385457
> Blue W 0.022222296 0.112334911 0.04080824 0.016064488 0.031047157
> 0.885523847
> Blue W 0.040238733 0.121941307 0.04239768 0.010310538 0.020106944
> 0.751643349
> Blue W 0.031508947 0.131547704 0.05212774 0.015720985 0.013932284
> 0.881234886
> Green W 0.021070032 0.121018603 0.38202466 0.022152283 0.038479532
> 0.662605036
> Green W 0.026562365 0.108269047 0.44028708 0.019344875 0.090798566
> 0.746330971
> Green W 0.02926478 0.084080729 0.32376224 0.012609717 0.097744041
> 0.969301308
> Orange W 0.02456562 0.134535891 0.09135624 0.007701481 0.017310058
> 0.966322354
> Orange W 0.032095541 0.149347595 0.06048885 0.010332579 0.017457175
> 0.561561725
> Orange W 0.039120696 0.141941743 0.02962146 0.005889924 0.017162941
> 0.502529091
> White W 0.033903057 0.061460583 0.0492955 0.012457767 0.029929334
> 0.70986421
> White W 0.033630233 0.115782233 0.02675399 0.021391535 0.023774961
> 1.176680075
> White W 0.030638581 0.065074112 0.03678494 0.014781912 0.03529703
> 0.805500558
> I wanted to perform a t-test between the treatment "D" and "W" of each
> species for all of the variables (var1, var2,...).  Could anyone suggest
> the packages or code for this analysis?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From djnord|und @end|ng |rom gm@||@com  Mon Dec 14 00:36:22 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sun, 13 Dec 2020 15:36:22 -0800
Subject: [R] ggplot2 + coord_cartesian + automatic ylim
In-Reply-To: <876A72CF-5663-42FB-81A3-E632C298ED87@uvm.edu>
References: <876A72CF-5663-42FB-81A3-E632C298ED87@uvm.edu>
Message-ID: <7bc64ffa-c923-e0bf-f186-1caab95b9627@gmail.com>

On 12/13/2020 12:49 PM, Brian Beckage wrote:
> As an example to illustrate my question, if I used the following code to plot the price of Apple stock using the tidyquant package and ggplot2
>
>
> AAPL<-tq_get(x="AAPL")
>
> AAPL %>%
>    ggplot(aes(x = date, y = close)) +
>    geom_line() +
>    labs(title = "AAPL", y = "Closing Price", x = "") +
>    coord_x_date(xlim=c(end-weeks(10),end),ylim=c(100,150)) +
>    theme_tq()
>
> but I would like the ylim to be set automatically based on the xlim.  In base R, this is a simple thing to do. ggplot is still a bit mysterious to me (not alway clear how it works) and so I would like to automatically set the ylim range based on the xlim range,  something  like the following, though it obviously does not work:
>
>
> AAPL<-tq_get(x="AAPL")
>
> AAPL %>%
>    ggplot(aes(x = date, y = close)) +
>    geom_line() +
>    labs(title = "AAPL Line Chart", y = "Closing Price", x = "") +
>    coord_x_date(xlim=c(end-weeks(10),end),ylim=c(min(y),max(y)) +
>    theme_tq()
>
> where the y vector corresponds to the y range delimited by xlim.  Note that coord_x_date is a wrapper for coord_cartesian.
>
> So how do I ?see? and use the data and parms being utilized by ggplot to set the ylim?  Or more generally, how do you step through code like to this to examine for instance what exactly coord_x_date is doing?
>
> Thanks,
> Brian
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Brian,

I couldn't get your code to work, so I modified it slightly. Someone 
more adept at ggplot than me may be able to give you a better solution.

xmax<-AAPL$date[nrow(AAPL)]
xminmax <- c(xmax-weeks(10), xmax)
yminmax <- with(AAPL, range(AAPL[date>=xmin & date<=xmax,]$close))

AAPL %>%
 ? ggplot(aes(x = date, y = close)) +
 ? geom_line() +
 ? labs(title = "AAPL", y = "Closing Price", x = "") +
 ? coord_x_date(xlim=xminmax, ylim=yminmax) +
 ? theme_tq()


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From Br|@n@Beck@ge @end|ng |rom uvm@edu  Mon Dec 14 01:43:02 2020
From: Br|@n@Beck@ge @end|ng |rom uvm@edu (Brian Beckage)
Date: Mon, 14 Dec 2020 00:43:02 +0000
Subject: [R] ggplot2 + coord_cartesian + automatic ylim
In-Reply-To: <6ab67d64-c22b-2bac-21a9-b6bba2834bf6@comcast.net>
References: <876A72CF-5663-42FB-81A3-E632C298ED87@uvm.edu>
 <6ab67d64-c22b-2bac-21a9-b6bba2834bf6@comcast.net>
Message-ID: <FF2F8392-D879-4CB7-8210-6241CC0F43B2@uvm.edu>

David,

Great suggestion!

Thanks,
Brian






On Dec 13, 2020, at 6:06 PM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:


On 12/13/20 12:49 PM, Brian Beckage wrote:
As an example to illustrate my question, if I used the following code to plot the price of Apple stock using the tidyquant package and ggplot2


AAPL<-tq_get(x="AAPL")

AAPL %>%
  ggplot(aes(x = date, y = close)) +
  geom_line() +
  labs(title = "AAPL", y = "Closing Price", x = "") +
  coord_x_date(xlim=c(end-weeks(10),end),ylim=c(100,150)) +
  theme_tq()

but I would like the ylim to be set automatically based on the xlim.  In base R, this is a simple thing to do. ggplot is still a bit mysterious to me (not alway clear how it works) and so I would like to automatically set the ylim range based on the xlim range,  something  like the following, though it obviously does not work:


AAPL<-tq_get(x="AAPL")

AAPL %>%
  ggplot(aes(x = date, y = close)) +
  geom_line() +
  labs(title = "AAPL Line Chart", y = "Closing Price", x = "") +
  coord_x_date(xlim=c(end-weeks(10),end),ylim=c(min(y),max(y)) +
  theme_tq()

where the y vector corresponds to the y range delimited by xlim.  Note that coord_x_date is a wrapper for coord_cartesian.


Why not let ggplot do it for you by "filtering" the data down to the date range you expect.


AAPL %>% filter(date > end-weeks(10)) %>%
    ggplot(aes(x = date, y = close)) +
    geom_line() +
    labs(title = "AAPL", y = "Closing Price", x = "") +
    coord_x_date(xlim=c(end-weeks(10),end)) +
    theme_tq()


Might not even need `coord_x_date` call at all.


So how do I ?see? and use the data and parms being utilized by ggplot to set the ylim?  Or more generally, how do you step through code like to this to examine for instance what exactly coord_x_date is doing?

Thanks,
Brian







[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From gregco@t@ @end|ng |rom me@com  Mon Dec 14 02:34:45 2020
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Sun, 13 Dec 2020 20:34:45 -0500
Subject: [R] How to specify year-month-day for a plot
In-Reply-To: <CA+8X3fV=eZEA+WNQV+wkC4oiaYoTuFaALE2CtB9RY-0r1Bjgyw@mail.gmail.com>
References: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>
 <CA+8X3fV=eZEA+WNQV+wkC4oiaYoTuFaALE2CtB9RY-0r1Bjgyw@mail.gmail.com>
Message-ID: <215E4A16-5675-4021-BB09-A4B84977457A@me.com>

Hi Jim,
Thank you VERY much!
In what I tried, my values for the vertical Y were automatically understood by R.
But it appears that the string yyyy-mm-dd was NOT recognized by R as a date for the X axis, and gave a red error message.
My values for Year-Month-Day were NOT understood by R.
Is there a convenient way to tell R to interpret ?2020-12-13? as a date?

data <- data.frame(
  day = as.Date("2020-02-15", "2020-03-10", "2020-05-04", "2020-06-21", "2020-08-01", "2020-08-27", "2020-09-28", "2020-11-09", "2020-12-11")
  value = (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226, 14.338, 18.777, 19.652))
p <- ggplot(data, aes(x=day, y=value))
  geom_line()
  xlab("X Label")
p
Error: unexpected symbol in:
"  day = as.Date("2020-02-15", "2020-03-10", "2020-05-04", "2020-06-21", "2020-08-01", "2020-08-27", "2020-09-28", "2020-11-09", "2020-12-11")
  value"

Greg Coats
gregcoats at me.com
Reston, Virginia USA

> On Dec 13, 2020, at 5:42 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Gregory,
> Here's a start:
> 
> gcdf<-read.table(text="2020-01-05 15.973
> 2020-02-15 18.832
> 2020-03-10 17.392
> 2020-05-04 14.774
> 2020-06-21 19.248
> 2020-08-01 14.913
> 2020-08-27 15.226
> 2020-09-28 14.338
> 2020-11-09 18.777
> 2020-12-11 19.652",
> header=TRUE,stringsAsFactors=FALSE,
> col.names=c("date","gallons"))
> gcdf$date<-as.Date(gcdf$date,"%Y-%m-%d")
> plot(gcdf$date,gcdf$gallons,main="Gallons by date",
> xlab="Date",ylab="Gallons")
> 
> Jim
> 
> On Mon, Dec 14, 2020 at 9:33 AM Gregory Coats via R-help
> <r-help at r-project.org> wrote:
>> 
>> Starting with year-month-day, for the variable gallons, I can easily plot the variable gallons, while disregarding the date.
>> gallons <- c (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226, 14.338, 18.777, 19.652)
>> plot (gallons, type="l", xlab="X label", ylab="Y label", col="blue?)
>> 
>> How do I direct R to plot the variable gallons, at the appropriate, irregularly-spaced places on the X axis, while paying attention to the year-month-day?
>> 
>> format = "%Y-%m-%d?
>> 2020-01-05 15.973
>> 2020-02-15 18.832
>> 2020-03-10 17.392
>> 2020-05-04 14.774
>> 2020-06-21 19.248
>> 2020-08-01 14.913
>> 2020-08-27 15.226
>> 2020-09-28 14.338
>> 2020-11-09 18.777
>> 2020-12-11 19.652
>>        [[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Mon Dec 14 03:00:10 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Sun, 13 Dec 2020 18:00:10 -0800
Subject: [R] How to specify year-month-day for a plot
In-Reply-To: <215E4A16-5675-4021-BB09-A4B84977457A@me.com>
References: <C9F99FD4-DDDE-4DD4-95B6-ED5ACBE60018@me.com>
 <CA+8X3fV=eZEA+WNQV+wkC4oiaYoTuFaALE2CtB9RY-0r1Bjgyw@mail.gmail.com>
 <215E4A16-5675-4021-BB09-A4B84977457A@me.com>
Message-ID: <CAHqSRuSWwHnYH0SrjJJDLd-m41NrWKhcY4B=mfpbuMaR6h+aeg@mail.gmail.com>

You left out some calls to c().  Note that
   (2,3,5)
is not valid syntax for making a vector of numbers; use
   c(2,3,5)
You also left out a comma and gave different lengths for day and value.
You also left out plus signs between the various components of your ggplot
expression.

Try
 data <- data.frame(
     day = as.Date(c("2020-02-15", "2020-03-10", "2020-05-04",
"2020-06-21", "2020-08-01", "2020-08-27", "2020-09-28", "2020-11-09",
"2020-12-11", "2020-12-12")),
     value = c(15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226,
14.338, 18.777, 19.652))

 p <- ggplot(data, aes(x=day, y=value))+
       geom_line()+
       xlab("X Label")
 p

On Sun, Dec 13, 2020 at 5:35 PM Gregory Coats via R-help <
r-help at r-project.org> wrote:

> Hi Jim,
> Thank you VERY much!
> In what I tried, my values for the vertical Y were automatically
> understood by R.
> But it appears that the string yyyy-mm-dd was NOT recognized by R as a
> date for the X axis, and gave a red error message.
> My values for Year-Month-Day were NOT understood by R.
> Is there a convenient way to tell R to interpret ?2020-12-13? as a date?
>
> data <- data.frame(
>   day = as.Date("2020-02-15", "2020-03-10", "2020-05-04", "2020-06-21",
> "2020-08-01", "2020-08-27", "2020-09-28", "2020-11-09", "2020-12-11")
>   value = (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226, 14.338,
> 18.777, 19.652))
> p <- ggplot(data, aes(x=day, y=value))
>   geom_line()
>   xlab("X Label")
> p
> Error: unexpected symbol in:
> "  day = as.Date("2020-02-15", "2020-03-10", "2020-05-04", "2020-06-21",
> "2020-08-01", "2020-08-27", "2020-09-28", "2020-11-09", "2020-12-11")
>   value"
>
> Greg Coats
> gregcoats at me.com
> Reston, Virginia USA
>
> > On Dec 13, 2020, at 5:42 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Gregory,
> > Here's a start:
> >
> > gcdf<-read.table(text="2020-01-05 15.973
> > 2020-02-15 18.832
> > 2020-03-10 17.392
> > 2020-05-04 14.774
> > 2020-06-21 19.248
> > 2020-08-01 14.913
> > 2020-08-27 15.226
> > 2020-09-28 14.338
> > 2020-11-09 18.777
> > 2020-12-11 19.652",
> > header=TRUE,stringsAsFactors=FALSE,
> > col.names=c("date","gallons"))
> > gcdf$date<-as.Date(gcdf$date,"%Y-%m-%d")
> > plot(gcdf$date,gcdf$gallons,main="Gallons by date",
> > xlab="Date",ylab="Gallons")
> >
> > Jim
> >
> > On Mon, Dec 14, 2020 at 9:33 AM Gregory Coats via R-help
> > <r-help at r-project.org> wrote:
> >>
> >> Starting with year-month-day, for the variable gallons, I can easily
> plot the variable gallons, while disregarding the date.
> >> gallons <- c (15.973, 18.832, 17.392, 14.774, 19.248, 14.913, 15.226,
> 14.338, 18.777, 19.652)
> >> plot (gallons, type="l", xlab="X label", ylab="Y label", col="blue?)
> >>
> >> How do I direct R to plot the variable gallons, at the appropriate,
> irregularly-spaced places on the X axis, while paying attention to the
> year-month-day?
> >>
> >> format = "%Y-%m-%d?
> >> 2020-01-05 15.973
> >> 2020-02-15 18.832
> >> 2020-03-10 17.392
> >> 2020-05-04 14.774
> >> 2020-06-21 19.248
> >> 2020-08-01 14.913
> >> 2020-08-27 15.226
> >> 2020-09-28 14.338
> >> 2020-11-09 18.777
> >> 2020-12-11 19.652
> >>        [[alternative HTML version deleted]]
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


