From nev||@@mo@ @end|ng |rom gm@||@com  Sun Nov  1 00:01:57 2020
From: nev||@@mo@ @end|ng |rom gm@||@com (nevil amos)
Date: Sun, 1 Nov 2020 10:01:57 +1100
Subject: [R] 
 [R-sig-Geo] raster::levels() not working in packaged function.
In-Reply-To: <312c6bc4-9d77-9521-71a2-1aad75b9ed6d@urjc.es>
References: <CAN9eD7=C3jeZu9yiv4u_=FpQiaihmp3puH8n86RMKyBgXZDWtA@mail.gmail.com>
 <312c6bc4-9d77-9521-71a2-1aad75b9ed6d@urjc.es>
Message-ID: <CAN9eD7=2AuQmaM5MO5EMrxJUJJBRU1+En7GYHTWOYCBg1wYT5w@mail.gmail.com>

Many thanks,

That worked, since the NAMESPACE file incudes a warning about editing it
directly I ysed the reoygen tag in the fucntion script
#' @import raster.

On Sun, 1 Nov 2020 at 00:18, Marcelino de la Cruz Rot <
marcelino.delacruz at urjc.es> wrote:

> Maybe including
>
> import(raster)
>
> or
>
> importFrom("raster", "levels")
>
> in the package NAMESPACE would help.
>
> Cheers,
>
> Marcelino
>
> El 31/10/2020 a las 13:24, nevil amos escribi?:
> > Apologies, I cannot see how to make a rero for this issue.
> >
> > I have a function that uses levels(r) tor return the RAT of a raster "r"
> > when the function is sourced from a script
> > source(".\R\function.r")
> > it works fine.
> > when the function is built into a package and sourced from there
> > library(mypackage) using the same script file to make the package
> > levels(r)[[1]]
> > the same line throws an error, as levels(myraster returns NULL
> >
> > If I modify the script to include the raster namespace:
> > raster::levels(r)[[1]]
> > Then I get the error
> >   Error: 'levels<-' is not an exported object from 'namespace:raster'
> >
> >
> > I have also tried just using levels(r) and putting raster as a depends
> > rather than an import in the DESCRIPTION file for the package, this does
> > not solve the error.
> >
> >
> > Any suggestions on how to overcome the problem?
> >
> > many thanks
> >
> > Nevil Amos
> >
> >       [[alternative HTML version deleted]]
> >
> > _______________________________________________
> > R-sig-Geo mailing list
> > R-sig-Geo at r-project.org
> > https://stat.ethz.ch/mailman/listinfo/r-sig-geo
> > .
>
>
> --
> Marcelino de la Cruz Rot
> Depto. de Biolog?a y Geolog?a
> F?sica y Qu?mica Inorg?nica
> Universidad Rey Juan Carlos
> M?stoles Espa?a
>
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Sun Nov  1 00:10:59 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sun, 1 Nov 2020 12:10:59 +1300
Subject: [R] FREDR and R 3.6
In-Reply-To: <5BD4D1DB-0ADB-400D-8E77-7BBAF7117D53@me.com>
References: <f14e8dbf-9c3e-9971-8ef3-3ccdfce2bd32@meddatainc.com>
 <3069209C-ED94-4400-9ADE-289D38B8A509@me.com>
 <cbb3ade1-196c-14e9-0b60-e7c2ba04c5cd@meddatainc.com>
 <5BD4D1DB-0ADB-400D-8E77-7BBAF7117D53@me.com>
Message-ID: <CABcYAd+PAQ5VwW6e8FnUovxkwGRFzX+D-POPk-5POPgmiyBecA@mail.gmail.com>

I'm running Ubuntu 18.04 LTS and
r-base/bionic-cran35,now 3.6.3-1bionic all [installed]
3.6.3 is also the latest version in the repository.


On Fri, 30 Oct 2020 at 12:21, Marc Schwartz via R-help <r-help at r-project.org>
wrote:

>
> > On Oct 29, 2020, at 6:35 PM, H <agents at meddatainc.com> wrote:
> >
> > On 10/29/2020 01:49 PM, Marc Schwartz wrote:
> >>> On Oct 29, 2020, at 1:29 PM, H <agents at meddatainc.com> wrote:
> >>>
> >>> I tried to install the fredr package yesterday to access the data
> series hosted by the St. Louis Fed but my installation of R, version 3.6,
> tells me it is not available from a cran repository.
> >>>
> >>> I could not find any information on this on the fredr information
> package and was wondering if anyone here might know?
> >>
> >> Hi,
> >>
> >> When that happens, check the CRAN page for the package:
> >>
> >>  https://cran.r-project.org/web/packages/fredr/index.html
> >>
> >> where you will see that the package has been archived as a result of a
> lack of response by the maintainer to problems with the package.
> >>
> >> The archive link on the above page allows you to download the last
> version of the source package tarball, however, the check results for the
> package show numerous issues.
> >>
> >> You may want to contact the package maintainer (sboysel at gmail.com) to
> see what the current status of the package is, and if they plan to resolve
> the issues. If not, consider alternative approaches.
> >>
> >> You should also consider updating your R installation, as 3.6.0 is well
> over a year old at this point. 4.0.3 is the current stable release.
> >>
> >> Regards,
> >>
> >> Marc Schwartz
> >
> > Thank you. That is very surprising! I would have thought there would be
> sufficient number of users and interest enough for this important package
> that it would be maintained!
> >
> > As for R 3.6, it is the latest version in the repository for my
> operating system, CentOS/RHEL...
>
>
> Hi,
>
> On your first point, the number of users is largely irrelevant, if the
> package maintainer no longer has the interest or the time to continue to
> support it. It is possible, in that scenario, that an interested user, who
> has the time and interest, might engage in a process to take over such
> maintenance.
>
> Keep in mind that package maintainers are, in the vast majority of cases,
> volunteers. Their motivations for creating and maintaining CRAN packages
> will vary.
>
> I did a quick check and found that there are discussions in the Issues
> section of the package's Github repo:
>
>   https://github.com/sboysel/fredr
>
> that suggest that such discussions are indeed taking place. So perhaps the
> situation with CRAN will be resolved in time. Again, you should contact the
> maintainer to get a better sense of their plans and possible timeline.
>
> With respect to CentOS/RHEL, you might post to r-sig-fedora, which focuses
> on R issues on RH derived Linux distros, to see if there are any plans to
> update R for your version of the distribution:
>
>   https://stat.ethz.ch/mailman/listinfo/r-sig-fedora
>
> The R RPM maintainers, like Tom Callaway, follow that list.
>
> Regards,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Sun Nov  1 07:02:42 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 1 Nov 2020 19:02:42 +1300
Subject: [R] R: sim1000G
In-Reply-To: <CAEVpY9LOdLrCeKYQ=Y8zHK3gbwJyV-9KfOWAaHvPYHAiO5_Xtg@mail.gmail.com>
References: <CAEVpY9LOdLrCeKYQ=Y8zHK3gbwJyV-9KfOWAaHvPYHAiO5_Xtg@mail.gmail.com>
Message-ID: <CAB8pepy-zK-xG-rO2ZhvB+eboCM6LBf-Zo+nESn_F-4BEaVMBg@mail.gmail.com>

Hi Berina,

I'm not an expert on genetics.
I haven't looked at the package.
And I've only glanced at your question.
So, this is probably not the best response.

But as no one else has responded, here's some comments:

(1)

Have you checked if there's a function in the package to do what you want?
The remainder of these questions assume that you have, and the answer is no.

(2)

I'm having some difficulty following the sample size.
The initial code sets an explicit value to 3000.
But if I'm following it correctly, the object that's returned has 2000
rows, containing two 1000 row groups.
But then your question implies you want 48?

Given that the sample already contains two groups, are they relevant
to the sample you're trying to produce?
And are you wanting to take a small sample of 48 from a larger sample
of 2000, or something else?

(3)

Are the observations (not sure if that's the correct term here) in
each 1000 row group, statistically independent?
If they are, then taking a smaller sample should be relatively simple.
If they're not, then this is a much more complex question, that's
probably off-topic.

(4)

What exactly is in the data?
i.e. Could you call the str() or head() functions on the data, and
show us the results?

(5)

Is there a boolean-style variable in the data, indicating whether each
row is casual or non-casual?


B.


On Fri, Oct 30, 2020 at 10:37 PM Berina Zametica UNI
<s0bezame at uni-bonn.de> wrote:
>
> Hi,
>
> I am using the sim1000G R package to simulate data for case/control study.
> I can not figure out how to manipulate this code to be able to generate 10%
> or 50% causal SNPs in R.
>
> This is whole code provided as example on GitHub:
>
> library(sim1000G)
> vcf_file = "region-chr4-357-ANK2.vcf.gz" #nvariants = 442, ss=1000
>
> vcf = readVCF( vcf_file, maxNumberOfVariants = 442  ,min_maf =
> 0.0005,max_maf = 0.01) #lowest MAF
> dim( vcf$gt1 ) #rows represent number of variants, columns represent
> number of individuals
>
> ## Download and use full chromosome genetic map
> downloadGeneticMap(4)
> readGeneticMap(4)
>
> sample.size=3000
>
> startSimulation(vcf, totalNumberOfIndividuals = sample.size)
>
> data_sim = function(seed.num){
>
>   SIM$reset()
>
>   id = generateUnrelatedIndividuals(sample.size)
>
>   gt = retrieveGenotypes(id)
>
>
>   freq = apply(gt,2,sum)/(2*nrow(gt))
>   causal = sample(setdiff(1:ncol(gt),which(freq==0)),45)
>
>   beta.sign = rep(1,45)
>   c.value = 0.402
>   beta.abs = c.value*abs(log10(freq[causal]))
>   beta.val = beta.sign*beta.abs
>   x.bar = apply(gt[,causal],2,mean)
>   x.bar = as.matrix(x.bar)
>   beta.val = t(as.matrix(beta.val))
>   #disease prvalance = 1%
>   #beta0 = -log(99)-beta.val %*% x.bar
>   #disease prvalance = 1.5%
>   beta0 = 0-beta.val %*% x.bar
>
>   eta = beta.val %*% t(gt[,causal])
>   eta = as.vector(eta) + rep(beta0,nrow(gt))
>   prob = exp(eta)/(1+exp(eta))
>
>   genocase = rep(NA, sample.size)
>
>   set.seed(seed.num)
>   for(i in 1:sample.size){
>     genocase[i] = rbinom(1, 1, prob[i])
>   }
>   case.idx = sample(which(genocase==1),1000)
>   control.idx = sample(which(genocase==0),1000)
>
>   return(rbind(gt[case.idx,],gt[control.idx,]))
> }
>
> How I can modify code in a way that it will simulate:
> 50 % of causal SNPs** ( exmp. 24 causal variants and 24 non causal SNPs)
> 10 % of causal SNP (exmpl. 5 causal and 43 non causal SNPs)
>
> Thanks a lot for any suggestion.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From d@v|d@kepp||nger @end|ng |rom gm@||@com  Sun Nov  1 00:55:42 2020
From: d@v|d@kepp||nger @end|ng |rom gm@||@com (David Kepplinger)
Date: Sat, 31 Oct 2020 16:55:42 -0700
Subject: [R] strptime() keeps emitting warnings after establishing a handler
 with tryCatch()
Message-ID: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>

Dear list members,

I have come about a peculiar behavior in R (4.0.2) which I would
describe as a bug.
On macOS, where `strptime()` raises a warning for invalid timezone
identifiers, the following code will continue to raise the original
warning with every subsequent call to `strptime()`:

```
# attach a handler for warnings for this call only:
tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz =
'Wrong Timezone!'),
                  warning = function (w) { stop("Error") })
# but every subsequent call will emit the original warning ("unknown
timezone 'Wrong Timezone!'")
strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
```

The output of the code above in R 4.0.2 on macOS is:

> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
+                   warning = function (w) { stop("Error") })
Error in value[[3L]](cond) : Error
>
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
[1] "2020-10-31 18:30:00 CET"
Warning message:
In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz =
"Europe/Vienna") :
  unknown timezone 'Wrong Timezone!'
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
[1] "2020-10-31 18:30:00 GMT"
Warning messages:
1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
  unknown timezone 'Wrong Timezone!'

The corresponding R session info is:

> sessionInfo()
R version 4.0.2 Patched (2020-07-13 r78838)
Platform: x86_64-apple-darwin17.0 (64-bit)
Running under: macOS Catalina 10.15.7

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.2


I get the same odd behavior when attaching calling handlers with
`withCallingHandlers()`.
On RHEL 7 and Cent OS 6, which both don't issue warnings for invalid
timezones, the above code works.

I don't see anything wrong with the code itself, but maybe I am
missing something. Any input would be appreciated.

Best wishes,
David


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Nov  1 18:51:02 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 1 Nov 2020 17:51:02 +0000
Subject: [R] 
 strptime() keeps emitting warnings after establishing a handler
 with tryCatch()
In-Reply-To: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>
References: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>
Message-ID: <65f5fea0-97bc-47a6-a7b7-dbc23c544e6b@sapo.pt>

Hello,

I cannot reproduce this behavior and, as documented, the posted code 
doesn't issue warnings due to a wrong timezone but I'm running


sessionInfo()
R version 4.0.3 (2020-10-10)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.1 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0

locale:
  [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
  [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
  [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.3


Hope this helps,

Rui Barradas

?s 23:55 de 31/10/20, David Kepplinger escreveu:
> Dear list members,
> 
> I have come about a peculiar behavior in R (4.0.2) which I would
> describe as a bug.
> On macOS, where `strptime()` raises a warning for invalid timezone
> identifiers, the following code will continue to raise the original
> warning with every subsequent call to `strptime()`:
> 
> ```
> # attach a handler for warnings for this call only:
> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz =
> 'Wrong Timezone!'),
>                    warning = function (w) { stop("Error") })
> # but every subsequent call will emit the original warning ("unknown
> timezone 'Wrong Timezone!'")
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> ```
> 
> The output of the code above in R 4.0.2 on macOS is:
> 
>> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
> +                   warning = function (w) { stop("Error") })
> Error in value[[3L]](cond) : Error
>>
>> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> [1] "2020-10-31 18:30:00 CET"
> Warning message:
> In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz =
> "Europe/Vienna") :
>    unknown timezone 'Wrong Timezone!'
>> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> [1] "2020-10-31 18:30:00 GMT"
> Warning messages:
> 1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
>    unknown timezone 'Wrong Timezone!'
> 
> The corresponding R session info is:
> 
>> sessionInfo()
> R version 4.0.2 Patched (2020-07-13 r78838)
> Platform: x86_64-apple-darwin17.0 (64-bit)
> Running under: macOS Catalina 10.15.7
> 
> Matrix products: default
> BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_4.0.2
> 
> 
> I get the same odd behavior when attaching calling handlers with
> `withCallingHandlers()`.
> On RHEL 7 and Cent OS 6, which both don't issue warnings for invalid
> timezones, the above code works.
> 
> I don't see anything wrong with the code itself, but maybe I am
> missing something. Any input would be appreciated.
> 
> Best wishes,
> David
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sun Nov  1 21:16:41 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sun, 1 Nov 2020 14:16:41 -0600
Subject: [R] analyzing results from Tuesday's US elections
Message-ID: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>

Hello:


       What can you tell me about plans to analyze data from this year's 
general election, especially to detect possible fraud?


       I might be able to help with such an effort.  I have NOT done 
much with election data, but I have developed tools for data analysis, 
including web scraping, and included them in R packages available on the 
Comprehensive R Archive Network (CRAN) and GitHub.[1]


       Penny Abernathy, who holds the Knight Chair in Journalism and 
Digital Media Economics at UNC-Chapel Hill, told me that the electoral 
fraud that disqualified the official winner from NC-09 to the US House 
in 2018 was detected by a college prof, who accessed the data two weeks 
after the election.[2]


       Spencer Graves


[1]
https://github.com/sbgraves237


[2]
https://en.wikiversity.org/wiki/Local_Journalism_Sustainability_Act


From d@v|d@kepp||nger @end|ng |rom gm@||@com  Sun Nov  1 19:34:42 2020
From: d@v|d@kepp||nger @end|ng |rom gm@||@com (David Kepplinger)
Date: Sun, 1 Nov 2020 10:34:42 -0800
Subject: [R] 
 strptime() keeps emitting warnings after establishing a handler
 with tryCatch()
In-Reply-To: <65f5fea0-97bc-47a6-a7b7-dbc23c544e6b@sapo.pt>
References: <CAGmyFCGSHiLYBvu8ZW6u6MerJXGSBUFbfxrXra8FHX8yz_htww@mail.gmail.com>
 <65f5fea0-97bc-47a6-a7b7-dbc23c544e6b@sapo.pt>
Message-ID: <CAGmyFCG3Z0aT=45_aoS2Kh-8tPhJEFheCy7jdisoVOWTbsem6g@mail.gmail.com>

Thanks, Rui, for checking on your end. I don't think any Linux-based
system is affected, as they silently ignore invalid timezone
identifiers (at least the versions I know of).

I now also had a chance to test on Windows 10 and get the same errors
as under macOS. The session info for this test is

> sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 19041)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_4.0.2

I also tested a bit more and it seems that attaching handlers really
messes up `strptime()`. For example, `strptime()` stops to emit any
warning for invalid timezone identifiers:

> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
+                   warning = function (w) { stop("Error") })
Error in value[[3L]](cond) : Error
> # The following calls with a wrong timezone identifier don't emit any warnings anymore?!
> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!')
[1] "2020-10-31 18:30:00"

But a subsequent call to `strptime()` with a valid timezone identifier
does emit the original warning (continuing the R session from above):

> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
[1] "2020-10-31 18:30:00 GMT"
Warning messages:
1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
  unknown timezone 'Wrong Timezone!'

And the next call with an incorrect tz identifier, doesn't emit a
warning, but uses the timezone from the previous call (continuing the
R session as above):

> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!')
[1] "2020-10-31 18:30:00 GMT"

Best wishes,
David


On Sun, Nov 1, 2020 at 9:51 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> I cannot reproduce this behavior and, as documented, the posted code
> doesn't issue warnings due to a wrong timezone but I'm running
>
>
> sessionInfo()
> R version 4.0.3 (2020-10-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.1 LTS
>
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0
> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0
>
> locale:
>   [1] LC_CTYPE=pt_PT.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=pt_PT.UTF-8        LC_COLLATE=pt_PT.UTF-8
>   [5] LC_MONETARY=pt_PT.UTF-8    LC_MESSAGES=pt_PT.UTF-8
>   [7] LC_PAPER=pt_PT.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=pt_PT.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.3
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 23:55 de 31/10/20, David Kepplinger escreveu:
> > Dear list members,
> >
> > I have come about a peculiar behavior in R (4.0.2) which I would
> > describe as a bug.
> > On macOS, where `strptime()` raises a warning for invalid timezone
> > identifiers, the following code will continue to raise the original
> > warning with every subsequent call to `strptime()`:
> >
> > ```
> > # attach a handler for warnings for this call only:
> > tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz =
> > 'Wrong Timezone!'),
> >                    warning = function (w) { stop("Error") })
> > # but every subsequent call will emit the original warning ("unknown
> > timezone 'Wrong Timezone!'")
> > strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> > strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> > ```
> >
> > The output of the code above in R 4.0.2 on macOS is:
> >
> >> tryCatch(strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Wrong Timezone!'),
> > +                   warning = function (w) { stop("Error") })
> > Error in value[[3L]](cond) : Error
> >>
> >> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'Europe/Vienna')
> > [1] "2020-10-31 18:30:00 CET"
> > Warning message:
> > In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz =
> > "Europe/Vienna") :
> >    unknown timezone 'Wrong Timezone!'
> >> strptime('2020-10-31 18:30', format = '%Y-%m-%d %H:%M', tz = 'GMT')
> > [1] "2020-10-31 18:30:00 GMT"
> > Warning messages:
> > 1: In strptime("2020-10-31 18:30", format = "%Y-%m-%d %H:%M", tz = "GMT") :
> >    unknown timezone 'Wrong Timezone!'
> >
> > The corresponding R session info is:
> >
> >> sessionInfo()
> > R version 4.0.2 Patched (2020-07-13 r78838)
> > Platform: x86_64-apple-darwin17.0 (64-bit)
> > Running under: macOS Catalina 10.15.7
> >
> > Matrix products: default
> > BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
> > LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
> >
> > locale:
> > [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] compiler_4.0.2
> >
> >
> > I get the same odd behavior when attaching calling handlers with
> > `withCallingHandlers()`.
> > On RHEL 7 and Cent OS 6, which both don't issue warnings for invalid
> > timezones, the above code works.
> >
> > I don't see anything wrong with the code itself, but maybe I am
> > missing something. Any input would be appreciated.
> >
> > Best wishes,
> > David
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From h@nn@hv@n|mpe @end|ng |rom out|ook@com  Mon Nov  2 14:56:20 2020
From: h@nn@hv@n|mpe @end|ng |rom out|ook@com (Hannah Van Impe)
Date: Mon, 2 Nov 2020 13:56:20 +0000
Subject: [R] Error: vector memory exhausted (limit reached?)
Message-ID: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>

Hello

I have a question about the error: vector memory exhausted (limit reached?). I have the R-studio version 4.0.3 (2020-10-10). 
I have a MacBook Air (13-inch, 2017). I am trying to open a dataset file ?data_dta? through the import dataset ?file from stata? button. 
I already did this with other datasets, and this works fine. Now, I want to work with a bigger dataset of 4.08 GB. When I try to open the dataset, I get this error: vector memory exhausted (limit reached?). 
What can I do about this? I still have 25 GB available on my laptop. 

Thank you very much
Hannah Van Impe

From gob@@|||ngrud @end|ng |rom gm@||@com  Mon Nov  2 18:28:59 2020
From: gob@@|||ngrud @end|ng |rom gm@||@com (Gordon Ballingrud)
Date: Mon, 2 Nov 2020 12:28:59 -0500
Subject: [R] help loading files into R for koRpus analysis
Message-ID: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>

Hello all,



I need some help with loading text-file data into R for analysis with
packages like koRpus.



The problem I am facing is getting R to recognize a folder full of Word
files (about 4,000) as data which I can then make koRpus perform analyses
like Coleman-Liau indexing. If at all possible, I prefer to make this work
with Word files. The key problem is the struggle to cause R to recognize
the text (Word) files in bulk (that is, all at the same time) so that
koRpus can do its thing with those files.



My attempts to make this work have all been in vain, but I know that
packages like koRpus would be limited in usefulness if there were no way to
get the package to do its work on a large collection of files all at once.



I hope this problem will make sense to someone, and that there is a tenable
solution to it.



Thanks,

Gordon

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Nov  2 21:15:28 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 2 Nov 2020 15:15:28 -0500
Subject: [R] help loading files into R for koRpus analysis
In-Reply-To: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
References: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
Message-ID: <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>

You may get a helpful response, but if not, I'd suggest posting code you 
have to read one file.  Then lots of people could likely show you how to 
modify it to read all 4000 files.

Duncan Murdoch

On 02/11/2020 12:28 p.m., Gordon Ballingrud wrote:
> Hello all,
> 
> 
> 
> I need some help with loading text-file data into R for analysis with
> packages like koRpus.
> 
> 
> 
> The problem I am facing is getting R to recognize a folder full of Word
> files (about 4,000) as data which I can then make koRpus perform analyses
> like Coleman-Liau indexing. If at all possible, I prefer to make this work
> with Word files. The key problem is the struggle to cause R to recognize
> the text (Word) files in bulk (that is, all at the same time) so that
> koRpus can do its thing with those files.
> 
> 
> 
> My attempts to make this work have all been in vain, but I know that
> packages like koRpus would be limited in usefulness if there were no way to
> get the package to do its work on a large collection of files all at once.
> 
> 
> 
> I hope this problem will make sense to someone, and that there is a tenable
> solution to it.
> 
> 
> 
> Thanks,
> 
> Gordon
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Nov  2 21:16:41 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 2 Nov 2020 15:16:41 -0500
Subject: [R] Error: vector memory exhausted (limit reached?)
In-Reply-To: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>
References: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>
Message-ID: <CAJc=yOEpvYq-P0z=mzpMK-oZeXQdvg2ZbJ-PDEi4kiMLsCmqDw@mail.gmail.com>

The error probably means what it says. I'm guessing "25 GB available"
is on the hard drive. But the issue is the data must be held in RAM,
and a file >4GB (before de-compression) is quite a lot of RAM on
laptop scales.

Try taking a subset of the data in Stata before importing?

Pat


On Mon, Nov 2, 2020 at 3:09 PM Hannah Van Impe
<hannahvanimpe at outlook.com> wrote:
>
> Hello
>
> I have a question about the error: vector memory exhausted (limit reached?). I have the R-studio version 4.0.3 (2020-10-10).
> I have a MacBook Air (13-inch, 2017). I am trying to open a dataset file ?data_dta? through the import dataset ?file from stata? button.
> I already did this with other datasets, and this works fine. Now, I want to work with a bigger dataset of 4.08 GB. When I try to open the dataset, I get this error: vector memory exhausted (limit reached?).
> What can I do about this? I still have 25 GB available on my laptop.
>
> Thank you very much
> Hannah Van Impe
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Mon Nov  2 21:27:49 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Mon, 2 Nov 2020 15:27:49 -0500
Subject: [R] Error: vector memory exhausted (limit reached?)
In-Reply-To: <293F477F-2475-4AB7-943B-63048D21D54A@outlook.com>
References: <C4E152D0-1EAA-4616-B045-E4E76BB329D9@outlook.com>
 <CAJc=yOEpvYq-P0z=mzpMK-oZeXQdvg2ZbJ-PDEi4kiMLsCmqDw@mail.gmail.com>
 <293F477F-2475-4AB7-943B-63048D21D54A@outlook.com>
Message-ID: <CAJc=yOEM=0sqx8zErs0Hghae=LSrprAbS_X79o_Md3gp=Mwujw@mail.gmail.com>

Re-looping R-help. My error.

Hannah, I can't tell you how much RAM your computer has, certainly not how
much is free for R's use.  Just that you are  probably not going to be able
to load a dataset that Large into a 2017 MacBook.

On Mon, Nov 2, 2020, 3:20 PM Hannah Van Impe <hannahvanimpe at outlook.com>
wrote:

> Thank you very much,
> would it be possible to merge multiple smaller datasets into this one
> dataset?
> How much RAM would be possible for one dataset on laptop scales?
> I need to work with this data for the university, so it would be best if I
> could work with the whole dataset.
> Thank you!
>
> > Op 2 nov. 2020, om 21:16 heeft Patrick (Malone Quantitative) <
> malone at malonequantitative.com> het volgende geschreven:
> >
> > The error probably means what it says. I'm guessing "25 GB available"
> > is on the hard drive. But the issue is the data must be held in RAM,
> > and a file >4GB (before de-compression) is quite a lot of RAM on
> > laptop scales.
> >
> > Try taking a subset of the data in Stata before importing?
> >
> > Pat
> >
> >
> > On Mon, Nov 2, 2020 at 3:09 PM Hannah Van Impe
> > <hannahvanimpe at outlook.com> wrote:
> >>
> >> Hello
> >>
> >> I have a question about the error: vector memory exhausted (limit
> reached?). I have the R-studio version 4.0.3 (2020-10-10).
> >> I have a MacBook Air (13-inch, 2017). I am trying to open a dataset
> file ?data_dta? through the import dataset ?file from stata? button.
> >> I already did this with other datasets, and this works fine. Now, I
> want to work with a bigger dataset of 4.08 GB. When I try to open the
> dataset, I get this error: vector memory exhausted (limit reached?).
> >> What can I do about this? I still have 25 GB available on my laptop.
> >>
> >> Thank you very much
> >> Hannah Van Impe
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Patrick S. Malone, Ph.D., Malone Quantitative
> > NEW Service Models: http://malonequantitative.com
> >
> > He/Him/His
>
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Nov  3 01:43:10 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 2 Nov 2020 19:43:10 -0500
Subject: [R] help loading files into R for koRpus analysis
In-Reply-To: <CAJ6CFDshmrSd7NEvOxz+L_ASbnyXLX08pGdd4YS3EtmEkf9tHg@mail.gmail.com>
References: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
 <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>
 <CAJ6CFDshmrSd7NEvOxz+L_ASbnyXLX08pGdd4YS3EtmEkf9tHg@mail.gmail.com>
Message-ID: <5e5fdad1-f80b-5275-35e6-a80c83c2e0ee@gmail.com>

On 02/11/2020 4:46 p.m., Gordon Ballingrud wrote:
> Thanks; that's a good point. Here is what I have been working with:
> 
> library(quanteda)
> library(readtext)
> 
> texts <- readtext(paste0("/Users/Gordon/Desktop/WPSCASES/", "/word/*.docx"))

On Windows, you can't have an empty entry in a pathname, so you should 
leave off one of the slashes:

   texts <- readtext(paste0("/Users/Gordon/Desktop/WPSCASES/", 
"word/*.docx"))

You could skip the paste0 entirely, and use

   texts <- readtext("/Users/Gordon/Desktop/WPSCASES/word/*.docx")

but I'm assuming this is just an example of a more complex situation.

Duncan Murdoch

> 
> And the error message:
> Error in list_files(file, ignore_missing, TRUE, verbosity) :
>  ? File '' does not exist.
> 
> 
> On Mon, Nov 2, 2020 at 3:15 PM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     You may get a helpful response, but if not, I'd suggest posting code
>     you
>     have to read one file.? Then lots of people could likely show you
>     how to
>     modify it to read all 4000 files.
> 
>     Duncan Murdoch
> 
>     On 02/11/2020 12:28 p.m., Gordon Ballingrud wrote:
>      > Hello all,
>      >
>      >
>      >
>      > I need some help with loading text-file data into R for analysis with
>      > packages like koRpus.
>      >
>      >
>      >
>      > The problem I am facing is getting R to recognize a folder full
>     of Word
>      > files (about 4,000) as data which I can then make koRpus perform
>     analyses
>      > like Coleman-Liau indexing. If at all possible, I prefer to make
>     this work
>      > with Word files. The key problem is the struggle to cause R to
>     recognize
>      > the text (Word) files in bulk (that is, all at the same time) so that
>      > koRpus can do its thing with those files.
>      >
>      >
>      >
>      > My attempts to make this work have all been in vain, but I know that
>      > packages like koRpus would be limited in usefulness if there were
>     no way to
>      > get the package to do its work on a large collection of files all
>     at once.
>      >
>      >
>      >
>      > I hope this problem will make sense to someone, and that there is
>     a tenable
>      > solution to it.
>      >
>      >
>      >
>      > Thanks,
>      >
>      > Gordon
>      >
>      >? ? ? ?[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>


From c||ve||@t@ @end|ng |rom goog|em@||@com  Tue Nov  3 02:14:46 2020
From: c||ve||@t@ @end|ng |rom goog|em@||@com (Clive Nicholas)
Date: Tue, 3 Nov 2020 01:14:46 +0000
Subject: [R] Query on constrained regressions using -mgcv- and -pcls-
Message-ID: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>

Hello all,

I'll level with you: I'm puzzled!

How is it that this constrained regression routine using -pcls- runs
satisfactorily (courtesy of Tian Zheng):

library(mgcv)
options(digits=3)
x.1=rnorm(100, 0, 1)
x.2=rnorm(100, 0, 1)
x.3=rnorm(100, 0, 1)
x.4=rnorm(100, 0, 1)
y=1+0.5*x.1-0.2*x.2+0.3*x.3+0.1*x.4+rnorm(100, 0, 0.01)
x.mat=cbind(rep(1, length(y)), x.1, x.2, x.3, x.4)
ls.print(lsfit(x.mat, y, intercept=FALSE))
M=list(y=y,
w=rep(1, length(y)),
X=x.mat,
C=matrix(0,0,0),
p=rep(1, ncol(x.mat)),
off=array(0,0),
S=list(),
sp=array(0,0),
Ain=diag(ncol(x.mat)),
bin=rep(0, ncol(x.mat)) )
pcls(M)
Residual Standard Error=0.0095
R-Square=1
F-statistic (df=5, 95)=314735
p-value=0

    Estimate Std.Err t-value Pr(>|t|)
       1.000  0.0010  1043.9        0
x.1    0.501  0.0010   512.6        0
x.2   -0.202  0.0009  -231.6        0
x.3    0.298  0.0010   297.8        0
x.4    0.103  0.0011    94.8        0

but this one does not for a panel dataset:

set.seed(02102020)
N=500
M=10
rater=rep(1:M, each = N)
lead_n=as.factor(rep(1:N,M))
a=rep(rnorm(N),M)
z=rep(round(25+2*rnorm(N)+.2*a))
x=a+rnorm(N*M)
y=.5*x+5*a-.5*z+2*rnorm(N*M)
x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
model=lm(y~x+x_cl+z)
summary(model)
y=1+1.5*x+4.6*x_cl-0.5*z
x.mat=cbind(rep(1,length(y)),x,x_cl,z)
ls.print(lsfit(x.mat,y,intercept=FALSE))

Residual Standard Error=0
R-Square=1
F-statistic (df=4, 4996)=5.06e+30
p-value=0

     Estimate Std.Err   t-value Pr(>|t|)
          1.0       0  2.89e+13        0
x         0.8       0  2.71e+14        0
x_cl      4.6       0  1.18e+15        0
z        -0.5       0 -3.63e+14        0

?

There shouldn't be anything wrong with the second set of data, unless I've
missed something obvious (that constraints don't work for panel data? Seems
unlikely to me)!

Also:

(1) I'm ultimately looking just to constrain ONE coefficient whilst
allowing the other coefficients to be unconstrained (I tried this with the
first dataset by setting

y=1+0.5*x.1-x.2+x.3+x.4

in the call, but got similar-looking output to what I got in the second
dataset); and

(2) it would be really useful to have the call to -pcls(M)- produce more
informative output (SEs, t-values, fit stats, etc).

Many thanks in anticipation of your expert help and being told what a
clueless berk I am,
Clive

-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]


From gob@@|||ngrud @end|ng |rom gm@||@com  Mon Nov  2 22:46:59 2020
From: gob@@|||ngrud @end|ng |rom gm@||@com (Gordon Ballingrud)
Date: Mon, 2 Nov 2020 16:46:59 -0500
Subject: [R] help loading files into R for koRpus analysis
In-Reply-To: <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>
References: <CAJ6CFDt6zyem8Tp0Ct-Uij-N6b0sX_W_hrGVEtn7QBgHurYemQ@mail.gmail.com>
 <8957a8f6-c550-5c4e-8964-9318ed6aa71d@gmail.com>
Message-ID: <CAJ6CFDshmrSd7NEvOxz+L_ASbnyXLX08pGdd4YS3EtmEkf9tHg@mail.gmail.com>

Thanks; that's a good point. Here is what I have been working with:

library(quanteda)
library(readtext)

texts <- readtext(paste0("/Users/Gordon/Desktop/WPSCASES/", "/word/*.docx"))

And the error message:
Error in list_files(file, ignore_missing, TRUE, verbosity) :
  File '' does not exist.


On Mon, Nov 2, 2020 at 3:15 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> You may get a helpful response, but if not, I'd suggest posting code you
> have to read one file.  Then lots of people could likely show you how to
> modify it to read all 4000 files.
>
> Duncan Murdoch
>
> On 02/11/2020 12:28 p.m., Gordon Ballingrud wrote:
> > Hello all,
> >
> >
> >
> > I need some help with loading text-file data into R for analysis with
> > packages like koRpus.
> >
> >
> >
> > The problem I am facing is getting R to recognize a folder full of Word
> > files (about 4,000) as data which I can then make koRpus perform analyses
> > like Coleman-Liau indexing. If at all possible, I prefer to make this
> work
> > with Word files. The key problem is the struggle to cause R to recognize
> > the text (Word) files in bulk (that is, all at the same time) so that
> > koRpus can do its thing with those files.
> >
> >
> >
> > My attempts to make this work have all been in vain, but I know that
> > packages like koRpus would be limited in usefulness if there were no way
> to
> > get the package to do its work on a large collection of files all at
> once.
> >
> >
> >
> > I hope this problem will make sense to someone, and that there is a
> tenable
> > solution to it.
> >
> >
> >
> > Thanks,
> >
> > Gordon
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From c||ve||@t@ @end|ng |rom goog|em@||@com  Tue Nov  3 06:28:09 2020
From: c||ve||@t@ @end|ng |rom goog|em@||@com (Clive Nicholas)
Date: Tue, 3 Nov 2020 05:28:09 +0000
Subject: [R] Query on constrained regressions using -mgcv- and -pcls-
In-Reply-To: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>
References: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>
Message-ID: <CAHs5aTi-D+JVf3vtbhn=hEDGgKdSA3wK72nd-_7hotSuBa9ztQ@mail.gmail.com>

As an addendum / erratum to my original post, the second block of code
should read for completeness:

set.seed(02102020)
N=500
M=10
rater=rep(1:M, each = N)
lead_n=as.factor(rep(1:N,M))
a=rep(rnorm(N),M)
z=rep(round(25+2*rnorm(N)+.2*a))
x=a+rnorm(N*M)
y=.5*x+5*a-.5*z+2*rnorm(N*M)
x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
model=lm(y~x+x_cl+z)
summary(model)
y=1+1.5*x+4.6*x_cl-0.5*z
x.mat=cbind(rep(1,length(y)),x,x_cl,z)
ls.print(lsfit(x.mat,y,intercept=FALSE))
M=list(y=y,
w=rep(1, length(y)),
X=x.mat,
C=matrix(0,0,0),
p=rep(1, ncol(x.mat)),
off=array(0,0),
S=list(),
sp=array(0,0),
Ain=diag(ncol(x.mat)),
bin=rep(0, ncol(x.mat)) )
pcls(M)

However, all my questions stand.

Ta, Clive

On Tue, 3 Nov 2020 at 01:14, Clive Nicholas <clivelists at googlemail.com>
wrote:

> Hello all,
>
> I'll level with you: I'm puzzled!
>
> How is it that this constrained regression routine using -pcls- runs
> satisfactorily (courtesy of Tian Zheng):
>
> library(mgcv)
> options(digits=3)
> x.1=rnorm(100, 0, 1)
> x.2=rnorm(100, 0, 1)
> x.3=rnorm(100, 0, 1)
> x.4=rnorm(100, 0, 1)
> y=1+0.5*x.1-0.2*x.2+0.3*x.3+0.1*x.4+rnorm(100, 0, 0.01)
> x.mat=cbind(rep(1, length(y)), x.1, x.2, x.3, x.4)
> ls.print(lsfit(x.mat, y, intercept=FALSE))
> M=list(y=y,
> w=rep(1, length(y)),
> X=x.mat,
> C=matrix(0,0,0),
> p=rep(1, ncol(x.mat)),
> off=array(0,0),
> S=list(),
> sp=array(0,0),
> Ain=diag(ncol(x.mat)),
> bin=rep(0, ncol(x.mat)) )
> pcls(M)
> Residual Standard Error=0.0095
> R-Square=1
> F-statistic (df=5, 95)=314735
> p-value=0
>
>     Estimate Std.Err t-value Pr(>|t|)
>        1.000  0.0010  1043.9        0
> x.1    0.501  0.0010   512.6        0
> x.2   -0.202  0.0009  -231.6        0
> x.3    0.298  0.0010   297.8        0
> x.4    0.103  0.0011    94.8        0
>
> but this one does not for a panel dataset:
>
> set.seed(02102020)
> N=500
> M=10
> rater=rep(1:M, each = N)
> lead_n=as.factor(rep(1:N,M))
> a=rep(rnorm(N),M)
> z=rep(round(25+2*rnorm(N)+.2*a))
> x=a+rnorm(N*M)
> y=.5*x+5*a-.5*z+2*rnorm(N*M)
> x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
> model=lm(y~x+x_cl+z)
> summary(model)
> y=1+1.5*x+4.6*x_cl-0.5*z
> x.mat=cbind(rep(1,length(y)),x,x_cl,z)
> ls.print(lsfit(x.mat,y,intercept=FALSE))
>
> Residual Standard Error=0
> R-Square=1
> F-statistic (df=4, 4996)=5.06e+30
> p-value=0
>
>      Estimate Std.Err   t-value Pr(>|t|)
>           1.0       0  2.89e+13        0
> x         0.8       0  2.71e+14        0
> x_cl      4.6       0  1.18e+15        0
> z        -0.5       0 -3.63e+14        0
>
> ?
>
> There shouldn't be anything wrong with the second set of data, unless I've
> missed something obvious (that constraints don't work for panel data? Seems
> unlikely to me)!
>
> Also:
>
> (1) I'm ultimately looking just to constrain ONE coefficient whilst
> allowing the other coefficients to be unconstrained (I tried this with the
> first dataset by setting
>
> y=1+0.5*x.1-x.2+x.3+x.4
>
> in the call, but got similar-looking output to what I got in the second
> dataset); and
>
> (2) it would be really useful to have the call to -pcls(M)- produce more
> informative output (SEs, t-values, fit stats, etc).
>
> Many thanks in anticipation of your expert help and being told what a
> clueless berk I am,
> Clive
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>


-- 
Clive Nicholas

"My colleagues in the social sciences talk a great deal about methodology.
I prefer to call it style." -- Freeman J. Dyson

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Nov  3 07:18:40 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 2 Nov 2020 22:18:40 -0800
Subject: [R] Query on constrained regressions using -mgcv- and -pcls-
In-Reply-To: <CAHs5aTi-D+JVf3vtbhn=hEDGgKdSA3wK72nd-_7hotSuBa9ztQ@mail.gmail.com>
References: <CAHs5aTis_z1NPHtzkUr6rTK0m1NeEvMbMkkg10rTz1vLVYQqOA@mail.gmail.com>
 <CAHs5aTi-D+JVf3vtbhn=hEDGgKdSA3wK72nd-_7hotSuBa9ztQ@mail.gmail.com>
Message-ID: <CAGxFJbS669NLsjFCBOLLup3z+-s5u45RvspU92aY=-9kEEDzdg@mail.gmail.com>

Warning: I did *not* attempt to follow your query(original or addendum) in
detail. But as you have not yet received a reply, it may be because your
post seems mostly about statistical issues, which are generally off topic
here. This list is primarily about R programming issues. If statistical
issues are your primary focus, SO may be a better place to post:
https://stats.stackexchange.com/

Otherwise, I guess you'll just have to continue waiting.

Incidentally, suggestions for improvements in nonstandard packages should
generally be sent to the package maintainer (?maintainer) rather than
posted here. Maintainers may not even check this list.

Finally, this is a plain text list. HTML posts often get mangled by the
server.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 2, 2020 at 9:28 PM Clive Nicholas via R-help <
r-help at r-project.org> wrote:

> As an addendum / erratum to my original post, the second block of code
> should read for completeness:
>
> set.seed(02102020)
> N=500
> M=10
> rater=rep(1:M, each = N)
> lead_n=as.factor(rep(1:N,M))
> a=rep(rnorm(N),M)
> z=rep(round(25+2*rnorm(N)+.2*a))
> x=a+rnorm(N*M)
> y=.5*x+5*a-.5*z+2*rnorm(N*M)
> x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
> model=lm(y~x+x_cl+z)
> summary(model)
> y=1+1.5*x+4.6*x_cl-0.5*z
> x.mat=cbind(rep(1,length(y)),x,x_cl,z)
> ls.print(lsfit(x.mat,y,intercept=FALSE))
> M=list(y=y,
> w=rep(1, length(y)),
> X=x.mat,
> C=matrix(0,0,0),
> p=rep(1, ncol(x.mat)),
> off=array(0,0),
> S=list(),
> sp=array(0,0),
> Ain=diag(ncol(x.mat)),
> bin=rep(0, ncol(x.mat)) )
> pcls(M)
>
> However, all my questions stand.
>
> Ta, Clive
>
> On Tue, 3 Nov 2020 at 01:14, Clive Nicholas <clivelists at googlemail.com>
> wrote:
>
> > Hello all,
> >
> > I'll level with you: I'm puzzled!
> >
> > How is it that this constrained regression routine using -pcls- runs
> > satisfactorily (courtesy of Tian Zheng):
> >
> > library(mgcv)
> > options(digits=3)
> > x.1=rnorm(100, 0, 1)
> > x.2=rnorm(100, 0, 1)
> > x.3=rnorm(100, 0, 1)
> > x.4=rnorm(100, 0, 1)
> > y=1+0.5*x.1-0.2*x.2+0.3*x.3+0.1*x.4+rnorm(100, 0, 0.01)
> > x.mat=cbind(rep(1, length(y)), x.1, x.2, x.3, x.4)
> > ls.print(lsfit(x.mat, y, intercept=FALSE))
> > M=list(y=y,
> > w=rep(1, length(y)),
> > X=x.mat,
> > C=matrix(0,0,0),
> > p=rep(1, ncol(x.mat)),
> > off=array(0,0),
> > S=list(),
> > sp=array(0,0),
> > Ain=diag(ncol(x.mat)),
> > bin=rep(0, ncol(x.mat)) )
> > pcls(M)
> > Residual Standard Error=0.0095
> > R-Square=1
> > F-statistic (df=5, 95)=314735
> > p-value=0
> >
> >     Estimate Std.Err t-value Pr(>|t|)
> >        1.000  0.0010  1043.9        0
> > x.1    0.501  0.0010   512.6        0
> > x.2   -0.202  0.0009  -231.6        0
> > x.3    0.298  0.0010   297.8        0
> > x.4    0.103  0.0011    94.8        0
> >
> > but this one does not for a panel dataset:
> >
> > set.seed(02102020)
> > N=500
> > M=10
> > rater=rep(1:M, each = N)
> > lead_n=as.factor(rep(1:N,M))
> > a=rep(rnorm(N),M)
> > z=rep(round(25+2*rnorm(N)+.2*a))
> > x=a+rnorm(N*M)
> > y=.5*x+5*a-.5*z+2*rnorm(N*M)
> > x_cl=rep(aggregate(x,list(lead_n) mean)[,2],M)
> > model=lm(y~x+x_cl+z)
> > summary(model)
> > y=1+1.5*x+4.6*x_cl-0.5*z
> > x.mat=cbind(rep(1,length(y)),x,x_cl,z)
> > ls.print(lsfit(x.mat,y,intercept=FALSE))
> >
> > Residual Standard Error=0
> > R-Square=1
> > F-statistic (df=4, 4996)=5.06e+30
> > p-value=0
> >
> >      Estimate Std.Err   t-value Pr(>|t|)
> >           1.0       0  2.89e+13        0
> > x         0.8       0  2.71e+14        0
> > x_cl      4.6       0  1.18e+15        0
> > z        -0.5       0 -3.63e+14        0
> >
> > ?
> >
> > There shouldn't be anything wrong with the second set of data, unless
> I've
> > missed something obvious (that constraints don't work for panel data?
> Seems
> > unlikely to me)!
> >
> > Also:
> >
> > (1) I'm ultimately looking just to constrain ONE coefficient whilst
> > allowing the other coefficients to be unconstrained (I tried this with
> the
> > first dataset by setting
> >
> > y=1+0.5*x.1-x.2+x.3+x.4
> >
> > in the call, but got similar-looking output to what I got in the second
> > dataset); and
> >
> > (2) it would be really useful to have the call to -pcls(M)- produce more
> > informative output (SEs, t-values, fit stats, etc).
> >
> > Many thanks in anticipation of your expert help and being told what a
> > clueless berk I am,
> > Clive
> >
> > --
> > Clive Nicholas
> >
> > "My colleagues in the social sciences talk a great deal about
> methodology.
> > I prefer to call it style." -- Freeman J. Dyson
> >
>
>
> --
> Clive Nicholas
>
> "My colleagues in the social sciences talk a great deal about methodology.
> I prefer to call it style." -- Freeman J. Dyson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@her @end|ng |rom p|e@@th@n@com  Tue Nov  3 21:43:52 2020
From: ||@her @end|ng |rom p|e@@th@n@com (Dennis Fisher)
Date: Tue, 3 Nov 2020 12:43:52 -0800
Subject: [R] segfault from systemfonts::system_fonts
Message-ID: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>

R 4.0.3
OS X 10.15.7

Colleagues

When I run flextable, it generates a segfault.  I traced the problem to systemfonts::system_fonts()

> > require("systemfonts")
> Loading required package: systemfonts
> >  system_fonts()
> 
>  *** caught segfault ***
> address 0x0, cause 'memory not mapped'
> 
> Traceback:
>  1: system_fonts_c()
>  2: system_fonts()
> 
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> 
I updated my OS and R, deleted and reinstalled the systemfonts package -- problem persists.  

I also opened Apple's font application and "validated" all font files (I have never installed any special fonts nor is there anything non-standard (e.g., Homebrew) on my system.

Of note, I can run other functions in systemfonts without problems -- only system_fonts triggers the segfault.

Another similar setup on OS X does not trigger the same problem, so the problem is more likely something in my system rather than a problem in R.

Does anyone have any ideas on how one might address this?

Dennis
 
Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Nov  3 22:00:16 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 3 Nov 2020 16:00:16 -0500
Subject: [R] segfault from systemfonts::system_fonts
In-Reply-To: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>
References: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>
Message-ID: <95284257-712d-4031-ffbc-f222452ba1d9@gmail.com>

On 03/11/2020 3:43 p.m., Dennis Fisher wrote:
> R 4.0.3
> OS X 10.15.7
> 
> Colleagues
> 
> When I run flextable, it generates a segfault.  I traced the problem to systemfonts::system_fonts()
> 
>>> require("systemfonts")
>> Loading required package: systemfonts
>>>   system_fonts()
>>
>>   *** caught segfault ***
>> address 0x0, cause 'memory not mapped'
>>
>> Traceback:
>>   1: system_fonts_c()
>>   2: system_fonts()
>>
>> Possible actions:
>> 1: abort (with core dump, if enabled)
>> 2: normal R exit
>> 3: exit R without saving workspace
>> 4: exit R saving workspace
>>
> I updated my OS and R, deleted and reinstalled the systemfonts package -- problem persists.
> 
> I also opened Apple's font application and "validated" all font files (I have never installed any special fonts nor is there anything non-standard (e.g., Homebrew) on my system.
> 
> Of note, I can run other functions in systemfonts without problems -- only system_fonts triggers the segfault.
> 
> Another similar setup on OS X does not trigger the same problem, so the problem is more likely something in my system rather than a problem in R.
> 
> Does anyone have any ideas on how one might address this?
> 

For what it's worth, I have the same R version and macOS version, and it 
works fine.  Debugging it will be hard:  all the work happens in a 
function called using

     .Call("_systemfonts_system_fonts_c")

If I could reproduce the bug and wanted to track it down, I think I'd do 
it by adding a bunch of Rprintf() commands into the source of 
_systemfonts_system_fonts_c and rebuilding the package.  It would be 
really tedious; I'm glad I'm not doing this!

Duncan Murdoch


From ||@her @end|ng |rom p|e@@th@n@com  Tue Nov  3 22:05:48 2020
From: ||@her @end|ng |rom p|e@@th@n@com (Dennis Fisher)
Date: Tue, 3 Nov 2020 13:05:48 -0800
Subject: [R] segfault from systemfonts::system_fonts
In-Reply-To: <95284257-712d-4031-ffbc-f222452ba1d9@gmail.com>
References: <305BEAD0-7904-46D9-AB83-38194B0827D3@plessthan.com>
 <95284257-712d-4031-ffbc-f222452ba1d9@gmail.com>
Message-ID: <015760A9-EE58-44D0-A2EE-E8C664B20D13@plessthan.com>

Duncan

Thanks for responding -- but your response did not help my mood.
Executing:
	.Call("_systemfonts_system_fonts_c")
triggered the segfault (as you proposed).

Dennis

Dennis Fisher MD
P < (The "P Less Than" Company)
Phone / Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com




> On Nov 3, 2020, at 1:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 03/11/2020 3:43 p.m., Dennis Fisher wrote:
>> R 4.0.3
>> OS X 10.15.7
>> Colleagues
>> When I run flextable, it generates a segfault.  I traced the problem to systemfonts::system_fonts()
>>>> require("systemfonts")
>>> Loading required package: systemfonts
>>>>  system_fonts()
>>> 
>>>  *** caught segfault ***
>>> address 0x0, cause 'memory not mapped'
>>> 
>>> Traceback:
>>>  1: system_fonts_c()
>>>  2: system_fonts()
>>> 
>>> Possible actions:
>>> 1: abort (with core dump, if enabled)
>>> 2: normal R exit
>>> 3: exit R without saving workspace
>>> 4: exit R saving workspace
>>> 
>> I updated my OS and R, deleted and reinstalled the systemfonts package -- problem persists.
>> I also opened Apple's font application and "validated" all font files (I have never installed any special fonts nor is there anything non-standard (e.g., Homebrew) on my system.
>> Of note, I can run other functions in systemfonts without problems -- only system_fonts triggers the segfault.
>> Another similar setup on OS X does not trigger the same problem, so the problem is more likely something in my system rather than a problem in R.
>> Does anyone have any ideas on how one might address this?
> 
> For what it's worth, I have the same R version and macOS version, and it works fine.  Debugging it will be hard:  all the work happens in a function called using
> 
>    .Call("_systemfonts_system_fonts_c")
> 
> If I could reproduce the bug and wanted to track it down, I think I'd do it by adding a bunch of Rprintf() commands into the source of _systemfonts_system_fonts_c and rebuilding the package.  It would be really tedious; I'm glad I'm not doing this!
> 
> Duncan Murdoch


	[[alternative HTML version deleted]]


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Nov  3 22:17:58 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 3 Nov 2020 21:17:58 +0000 (UTC)
Subject: [R] How to correct my error message
In-Reply-To: <CAO29qn7uQkniPBMgYW3iRV7Jnt7-+YFi_6ZC0aZ+FxHsgG+JFA@mail.gmail.com>
References: <497841733.6368680.1603825619018.ref@mail.yahoo.com>
 <497841733.6368680.1603825619018@mail.yahoo.com>
 <CAM_vjunPUTAk+MREgNsueMUmL-BHB41--vdEaofdTrDruomSSg@mail.gmail.com>
 <CAO29qn7uQkniPBMgYW3iRV7Jnt7-+YFi_6ZC0aZ+FxHsgG+JFA@mail.gmail.com>
Message-ID: <437763544.3319706.1604438278312@mail.yahoo.com>

Dear All,

Many thanks for your responses. I got it !

Best,









Le mardi 27 octobre 2020 ? 21:16:50 UTC+1, Md. Moyazzem Hossain <hossainmm at juniv.edu> a ?crit : 





Dear Varin,

I think the following code will solve your problem.

n <- 60
b <- runif(n, 0, 5)
a <- runif(n, 0, 5)
z1 <- data.frame(x0=1:57,
? ? ? ? ? ? ? ? ? ? x1=rnorm(n*0.95,2,3))
z2 <- data.frame(x0=58:60,
? ? ? ? ? ? ? ? ? ? x1=rnorm(n*0.05,2,9))

combined=rbind(z1,z2)
z=combined[,2]
y_model <- 0.1 * b - 0.5 * z - a + 10
y_obs <- y_model +c( rnorm(n*0.95, 0, 0.1), rnorm(n*0.05, 0, 0.5) )
df<-data.frame(b,a,z,y_obs)

Thanks.

Md

On Tue, Oct 27, 2020 at 7:21 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Hi,
> 
> a is of length 60.
> b is of length 60.
> z is of length 57.
> 
> What do you expect to have happen when you create y_model ? What
> happens to those other 3 observations?
> 
> Sarah
> 
> On Tue, Oct 27, 2020 at 3:07 PM varin sacha via R-help
> <r-help at r-project.org> wrote:
>>
>> Dear R-experts,
>>
>> Here below my R code. The warning message is not a problem to me but there is an error message more problematic. I understand the error message but I don't know if it is possible to correct the error and if yes, how to correct it.
>>
>> Many thanks.
>>
>>
>> n <- 60
>> b <- runif(n, 0, 5)
>> a <- runif(n, 0, 5)
>> z <- rnorm(n*0.95,2,3) + rnorm(n*0.05,2,9)
>> y_model <- 0.1 * b - 0.5 * z - a + 10
>> y_obs <- y_model +c( rnorm(n*0.95, 0, 0.1), rnorm(n*0.05, 0, 0.5) )
>> df<-data.frame(b,a,z,y_obs)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Sarah Goslee (she/her)
> http://www.numberwright.com
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh

Website:?http://www.juniv.edu/teachers/hossainmm?
Research:?Google Scholar;?ResearchGate;?ORCID iD


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Nov  3 22:18:30 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 3 Nov 2020 21:18:30 +0000 (UTC)
Subject: [R] How to correct my error message
In-Reply-To: <b692e57d-7da6-9676-7ebe-f30a8fe35b13@gmail.com>
References: <497841733.6368680.1603825619018.ref@mail.yahoo.com>
 <497841733.6368680.1603825619018@mail.yahoo.com>
 <b692e57d-7da6-9676-7ebe-f30a8fe35b13@gmail.com>
Message-ID: <740399640.3324496.1604438310337@mail.yahoo.com>

Many thanks Duncan,

It works !

Best.









Le mardi 27 octobre 2020 ? 20:49:25 UTC+1, Duncan Murdoch <murdoch.duncan at gmail.com> a ?crit : 





On 27/10/2020 3:06 p.m., varin sacha via R-help wrote:

> Dear R-experts,
> 
> Here below my R code. The warning message is not a problem to me but there is an error message more problematic. I understand the error message but I don't know if it is possible to correct the error and if yes, how to correct it.
> 
> Many thanks.
> 
> 
> n <- 60
> b <- runif(n, 0, 5)
> a <- runif(n, 0, 5)
> z <- rnorm(n*0.95,2,3) + rnorm(n*0.05,2,9)
> y_model <- 0.1 * b - 0.5 * z - a + 10
> y_obs <- y_model +c( rnorm(n*0.95, 0, 0.1), rnorm(n*0.05, 0, 0.5) )
> df<-data.frame(b,a,z,y_obs)

> 

I suspect you intended to concatenate the two parts of z, i.e.

? z <- c(rnorm(n*0.95,2,3), rnorm(n*0.05,2,9))

You shouldn't ignore the warning.

By the way, it's not true for every n that my expression for z will 
always give something of length n.? It would be safer to do the 
calculation as

? m <- round(n*0.95)
? z <- c(rnorm(m,2,3), rnorm(n-m,2,9)

Duncan Murdoch


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Tue Nov  3 22:23:50 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Tue, 3 Nov 2020 21:23:50 +0000 (UTC)
Subject: [R] nlcor package
References: <388658574.3320737.1604438630344.ref@mail.yahoo.com>
Message-ID: <388658574.3320737.1604438630344@mail.yahoo.com>

Dear R-helpers,

Here below my R code showing warnings and error messages I don't understand. 
What is going wrong ?

########################
install.packages("devtools")
library(devtools)
install_github("ProcessMiner/nlcor")
library(nlcor) 

A=c(505, 530, 419, 486, 608, 468, 519, 486, 532, 289, 529, 474, 571, 546, 458, 476, 376, 474, 598, 419, 479, 615, 507, 473, 532, 392, 496, 426, 480, 583, 490, 499, 513, 444, 542)
B=c(508, 516, 390, 520, 375, 499, 478, 534, 553, 485, 405, 478, 542, 523, 491, 363, 456, 498, 506, 529, 574, 478, 411, 571, 512, 487, 518, 515, 467, 513, 536, 555, 508, 507, 535)

c<-nlcor(A,B,refine=0.5,plt=T)
c$cor.estimate
c$adjusted.p.value
print(c$cor.plot)
########################


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Nov  4 02:48:29 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 03 Nov 2020 17:48:29 -0800
Subject: [R] nlcor package
In-Reply-To: <388658574.3320737.1604438630344@mail.yahoo.com>
References: <388658574.3320737.1604438630344.ref@mail.yahoo.com>
 <388658574.3320737.1604438630344@mail.yahoo.com>
Message-ID: <E1FC4FC7-2DE3-4C08-9A5C-2A39FEC68BF2@dcn.davis.ca.us>

Someone may investigate this for you anyway, but technically this request is outside of the scope of this mailing list (which is the R programming language, not the theory of use nor possible bugs in the current version of random packages not even registered in CRAN). Do read the Posting Guide and consider corresponding with the package author as directed by the package DESCRIPTION file.

On November 3, 2020 1:23:50 PM PST, varin sacha via R-help <r-help at r-project.org> wrote:
>Dear R-helpers,
>
>Here below my R code showing warnings and error messages I don't
>understand. 
>What is going wrong ?
>
>########################
>install.packages("devtools")
>library(devtools)
>install_github("ProcessMiner/nlcor")
>library(nlcor) 
>
>A=c(505, 530, 419, 486, 608, 468, 519, 486, 532, 289, 529, 474, 571,
>546, 458, 476, 376, 474, 598, 419, 479, 615, 507, 473, 532, 392, 496,
>426, 480, 583, 490, 499, 513, 444, 542)
>B=c(508, 516, 390, 520, 375, 499, 478, 534, 553, 485, 405, 478, 542,
>523, 491, 363, 456, 498, 506, 529, 574, 478, 411, 571, 512, 487, 518,
>515, 467, 513, 536, 555, 508, 507, 535)
>
>c<-nlcor(A,B,refine=0.5,plt=T)
>c$cor.estimate
>c$adjusted.p.value
>print(c$cor.plot)
>########################
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m|@ojpm @end|ng |rom gm@||@com  Wed Nov  4 10:22:26 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Wed, 4 Nov 2020 17:22:26 +0800
Subject: [R] build a literature database
Message-ID: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>

Hi,

   I 'd like to create a table for literature review. Is there any good
data structure (database) I may use? Now I just use a simple dataframe as
follows, but in the second item I swap the order of year and author, and it
records 2013 as author and "XH" as year.  Is there any better structure ?
If not, how may I fix the current condition?Thanks!


df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
df[1, ]<-c(
           author = "Moore",
           year = 2020,
           title = "Statistics and data analysis",
           country = "Colombia",
           sample = NA,
           data = "firm level",
           result = NA,
           note = NA)

df[nrow(df)+1,]<- c(year = 2013,
                    author = "XH",
                    title = NA,
                    country = NA,
                    sample = NA,
                    data = NA,
                    result = NA,
                    note = NA)

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 10:28:13 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 04:28:13 -0500
Subject: [R] build a literature database
In-Reply-To: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
Message-ID: <ac555c04-c994-161c-ea8f-4dd2a1fbb46e@gmail.com>

On 04/11/2020 4:22 a.m., John wrote:
> Hi,
> 
>     I 'd like to create a table for literature review. Is there any good
> data structure (database) I may use? Now I just use a simple dataframe as
> follows, but in the second item I swap the order of year and author, and it
> records 2013 as author and "XH" as year.  Is there any better structure ?
> If not, how may I fix the current condition?Thanks!
> 
> 
> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
> df[1, ]<-c(
>             author = "Moore",
>             year = 2020,
>             title = "Statistics and data analysis",
>             country = "Colombia",
>             sample = NA,
>             data = "firm level",
>             result = NA,
>             note = NA)
> 
> df[nrow(df)+1,]<- c(year = 2013,
>                      author = "XH",
>                      title = NA,
>                      country = NA,
>                      sample = NA,
>                      data = NA,
>                      result = NA,
>                      note = NA)

If you changed the last statement to

df <- rbind(df, data.frame(year = 2013,
                       author = "XH",
                       title = NA,
                       country = NA,
                       sample = NA,
                       data = NA,
                       result = NA,
                       note = NA))

it would correctly sort out the reordered columns.

As to a better data structure:  bibliographic data is hard, because 
different forms of publication should have different fields.  I'd 
suggest storing the data in some existing format rather than rolling 
your own.  For example, the utils::bibentry function is quite a bit like 
BibTeX.

Duncan Murdoch


From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Nov  4 10:50:38 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 4 Nov 2020 09:50:38 +0000
Subject: [R] newdata for predict.lm() ??
Message-ID: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>

Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...

Reprex:

# Data frame with simulated data in columns "h" (independent) and "w" (dependent)
DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118, 
                            1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
                            2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
                            1.522, 1.995), 
                      w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
                            87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
                            84.258, 78.317,101.304, 64.982, 71.237, 77.124,
                            65.010, 81.413)),
                 row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7", 
                                "8",  "9", "10", "11", "12", "13", "14",
                               "15", "16", "17", "18", "19", "20"),
                 class = "data.frame")


myFit <- lm(DAT$w ~ DAT$h)
coef(myFit)

# (Intercept)       DAT$h 
#   11.76475    35.92002 


# Create 50 x-values with seq() to plot confidence intervals
myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))

pc <- predict(myFit, newdata = myNew, interval = "confidence")

# Warning message:
# 'newdata' had 50 rows but variables found have 20 rows 

# Problem: predict() was not able to take the single column in myNew
# as the independent variable.

# Ugly workaround: but with that everything works as expected.
xx <- DAT$h
yy <- DAT$w
myFit <- lm(yy ~ xx)
coef(myFit)

myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
colnames(myNew) <- "xx"  # This fixes it!

pc <- predict(myFit, newdata = myNew, interval = "confidence")
str(pc)

# So: specifying the column in newdata to have same name as the coefficient
# name should work, right?
# Back to the original ...

myFit <- lm(DAT$w ~ DAT$h)
colnames(myNew) <- "`DAT$h`"
# ... same error

colnames(myNew) <- "h"
# ... same error again.

Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...



Thanks!
Boris


From pd@|gd @end|ng |rom gm@||@com  Wed Nov  4 10:56:00 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 4 Nov 2020 10:56:00 +0100
Subject: [R] newdata for predict.lm() ??
In-Reply-To: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
References: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
Message-ID: <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>

Don't use $ notation in lm() formulas. Use lm(w ~ h, data=DAT).

-pd

> On 4 Nov 2020, at 10:50 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...
> 
> Reprex:
> 
> # Data frame with simulated data in columns "h" (independent) and "w" (dependent)
> DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118, 
>                            1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
>                            2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
>                            1.522, 1.995), 
>                      w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
>                            87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
>                            84.258, 78.317,101.304, 64.982, 71.237, 77.124,
>                            65.010, 81.413)),
>                 row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7", 
>                                "8",  "9", "10", "11", "12", "13", "14",
>                               "15", "16", "17", "18", "19", "20"),
>                 class = "data.frame")
> 
> 
> myFit <- lm(DAT$w ~ DAT$h)
> coef(myFit)
> 
> # (Intercept)       DAT$h 
> #   11.76475    35.92002 
> 
> 
> # Create 50 x-values with seq() to plot confidence intervals
> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
> 
> pc <- predict(myFit, newdata = myNew, interval = "confidence")
> 
> # Warning message:
> # 'newdata' had 50 rows but variables found have 20 rows 
> 
> # Problem: predict() was not able to take the single column in myNew
> # as the independent variable.
> 
> # Ugly workaround: but with that everything works as expected.
> xx <- DAT$h
> yy <- DAT$w
> myFit <- lm(yy ~ xx)
> coef(myFit)
> 
> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
> colnames(myNew) <- "xx"  # This fixes it!
> 
> pc <- predict(myFit, newdata = myNew, interval = "confidence")
> str(pc)
> 
> # So: specifying the column in newdata to have same name as the coefficient
> # name should work, right?
> # Back to the original ...
> 
> myFit <- lm(DAT$w ~ DAT$h)
> colnames(myNew) <- "`DAT$h`"
> # ... same error
> 
> colnames(myNew) <- "h"
> # ... same error again.
> 
> Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...
> 
> 
> 
> Thanks!
> Boris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Wed Nov  4 11:05:31 2020
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Wed, 4 Nov 2020 11:05:31 +0100 (CET)
Subject: [R] newdata for predict.lm() ??
In-Reply-To: <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>
References: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
 <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>
Message-ID: <9fb129cf-9ad-cfa5-6f13-377c473131d@uibk.ac.at>

On Wed, 4 Nov 2020, peter dalgaard wrote:

> Don't use $ notation in lm() formulas. Use lm(w ~ h, data=DAT).

...or in any other formula for that matter!

Let me expand a bit on Peter's comment because this is really a pet peeve 
of mine:

The idea is that the formula "w ~ h" described the relationships between 
the variables involved, independent of the data set this should be applied 
to. In contrast "DAT$w ~ DAT$h" hard-wires the data into the formula and 
prevents it from applying the formula to another data set.

Hope that helps,
Achim


>> On 4 Nov 2020, at 10:50 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>
>> Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...
>>
>> Reprex:
>>
>> # Data frame with simulated data in columns "h" (independent) and "w" (dependent)
>> DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118,
>>                            1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
>>                            2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
>>                            1.522, 1.995),
>>                      w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
>>                            87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
>>                            84.258, 78.317,101.304, 64.982, 71.237, 77.124,
>>                            65.010, 81.413)),
>>                 row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7",
>>                                "8",  "9", "10", "11", "12", "13", "14",
>>                               "15", "16", "17", "18", "19", "20"),
>>                 class = "data.frame")
>>
>>
>> myFit <- lm(DAT$w ~ DAT$h)
>> coef(myFit)
>>
>> # (Intercept)       DAT$h
>> #   11.76475    35.92002
>>
>>
>> # Create 50 x-values with seq() to plot confidence intervals
>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>>
>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>>
>> # Warning message:
>> # 'newdata' had 50 rows but variables found have 20 rows
>>
>> # Problem: predict() was not able to take the single column in myNew
>> # as the independent variable.
>>
>> # Ugly workaround: but with that everything works as expected.
>> xx <- DAT$h
>> yy <- DAT$w
>> myFit <- lm(yy ~ xx)
>> coef(myFit)
>>
>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>> colnames(myNew) <- "xx"  # This fixes it!
>>
>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>> str(pc)
>>
>> # So: specifying the column in newdata to have same name as the coefficient
>> # name should work, right?
>> # Back to the original ...
>>
>> myFit <- lm(DAT$w ~ DAT$h)
>> colnames(myNew) <- "`DAT$h`"
>> # ... same error
>>
>> colnames(myNew) <- "h"
>> # ... same error again.
>>
>> Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...
>>
>>
>>
>> Thanks!
>> Boris
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Nov  4 11:11:06 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 4 Nov 2020 10:11:06 +0000
Subject: [R] newdata for predict.lm() ??
In-Reply-To: <9fb129cf-9ad-cfa5-6f13-377c473131d@uibk.ac.at>
References: <03277502-631F-4691-8F25-2F8691CFEFD3@utoronto.ca>
 <B368F474-62D6-496B-A0CB-8E097AA2957B@gmail.com>
 <9fb129cf-9ad-cfa5-6f13-377c473131d@uibk.ac.at>
Message-ID: <2C4C3657-4A87-471A-A7D1-AFF7649D1738@utoronto.ca>

Solved. Thanks Achim and Peter ...

though following that approach we now are relying implicitly on column names. But at least I've got this silly example working now. Thanks for the explanation Achim.

:-)



> On 2020-11-04, at 20:05, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
> 
> EXTERNAL EMAIL:  Treat content with extra caution.
> 
> On Wed, 4 Nov 2020, peter dalgaard wrote:
> 
>> Don't use $ notation in lm() formulas. Use lm(w ~ h, data=DAT).
> 
> ...or in any other formula for that matter!
> 
> Let me expand a bit on Peter's comment because this is really a pet peeve
> of mine:
> 
> The idea is that the formula "w ~ h" described the relationships between
> the variables involved, independent of the data set this should be applied
> to. In contrast "DAT$w ~ DAT$h" hard-wires the data into the formula and
> prevents it from applying the formula to another data set.
> 
> Hope that helps,
> Achim
> 
> 
>>> On 4 Nov 2020, at 10:50 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> 
>>> Can't get data from a data frame into predict() without a detour that seems quite unnecessary ...
>>> 
>>> Reprex:
>>> 
>>> # Data frame with simulated data in columns "h" (independent) and "w" (dependent)
>>> DAT <- structure(list(h = c(2.174, 2.092, 2.059, 1.952, 2.216, 2.118,
>>>                           1.755, 2.060, 2.136, 2.126, 1.792, 1.574,
>>>                           2.117, 1.741, 2.295, 1.526, 1.666, 1.581,
>>>                           1.522, 1.995),
>>>                     w = c(90.552, 89.518, 84.124, 94.685, 94.710, 82.429,
>>>                           87.176, 90.318, 76.873, 84.183, 57.890, 62.005,
>>>                           84.258, 78.317,101.304, 64.982, 71.237, 77.124,
>>>                           65.010, 81.413)),
>>>                row.names = c( "1",  "2",  "3",  "4",  "5",  "6",  "7",
>>>                               "8",  "9", "10", "11", "12", "13", "14",
>>>                              "15", "16", "17", "18", "19", "20"),
>>>                class = "data.frame")
>>> 
>>> 
>>> myFit <- lm(DAT$w ~ DAT$h)
>>> coef(myFit)
>>> 
>>> # (Intercept)       DAT$h
>>> #   11.76475    35.92002
>>> 
>>> 
>>> # Create 50 x-values with seq() to plot confidence intervals
>>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>>> 
>>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>>> 
>>> # Warning message:
>>> # 'newdata' had 50 rows but variables found have 20 rows
>>> 
>>> # Problem: predict() was not able to take the single column in myNew
>>> # as the independent variable.
>>> 
>>> # Ugly workaround: but with that everything works as expected.
>>> xx <- DAT$h
>>> yy <- DAT$w
>>> myFit <- lm(yy ~ xx)
>>> coef(myFit)
>>> 
>>> myNew <- data.frame(seq(min(DAT$h), max(DAT$h), length.out = 50))
>>> colnames(myNew) <- "xx"  # This fixes it!
>>> 
>>> pc <- predict(myFit, newdata = myNew, interval = "confidence")
>>> str(pc)
>>> 
>>> # So: specifying the column in newdata to have same name as the coefficient
>>> # name should work, right?
>>> # Back to the original ...
>>> 
>>> myFit <- lm(DAT$w ~ DAT$h)
>>> colnames(myNew) <- "`DAT$h`"
>>> # ... same error
>>> 
>>> colnames(myNew) <- "h"
>>> # ... same error again.
>>> 
>>> Bottom line: how can I properly specify newdata? The documentation is opaque. It seems the algorithm is trying to EXACTLY match the text of the RHS of the formula, which is unlikely to result in a useful column name, unless I assign to an intermediate variable. There must be a better way ...
>>> 
>>> 
>>> 
>>> Thanks!
>>> Boris
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Office: A 4.23
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Wed Nov  4 13:12:50 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Wed, 4 Nov 2020 12:12:50 +0000
Subject: [R] build a literature database
In-Reply-To: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
Message-ID: <5aad18cb-f404-7b6b-104b-82b3ee6dcbcc@dewey.myzen.co.uk>

Dear John

If you are doing a systematic review have you thought of investigating 
some of the packages in the CRAN Task View on MetaAnalysis like metagear 
or revtools? I have not used any of them but they claim to support that 
part of the process.

Michael

On 04/11/2020 09:22, John wrote:
> Hi,
> 
>     I 'd like to create a table for literature review. Is there any good
> data structure (database) I may use? Now I just use a simple dataframe as
> follows, but in the second item I swap the order of year and author, and it
> records 2013 as author and "XH" as year.  Is there any better structure ?
> If not, how may I fix the current condition?Thanks!
> 
> 
> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
> df[1, ]<-c(
>             author = "Moore",
>             year = 2020,
>             title = "Statistics and data analysis",
>             country = "Colombia",
>             sample = NA,
>             data = "firm level",
>             result = NA,
>             note = NA)
> 
> df[nrow(df)+1,]<- c(year = 2013,
>                      author = "XH",
>                      title = NA,
>                      country = NA,
>                      sample = NA,
>                      data = NA,
>                      result = NA,
>                      note = NA)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From rkoenker @end|ng |rom ||||no|@@edu  Wed Nov  4 14:01:25 2020
From: rkoenker @end|ng |rom ||||no|@@edu (Koenker, Roger W)
Date: Wed, 4 Nov 2020 13:01:25 +0000
Subject: [R] build a literature database
In-Reply-To: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
Message-ID: <C713FE87-D9D8-4B1A-88F8-EA22BDA8B840@illinois.edu>

You might also want to take a look at this survey:  https://ropensci.org/technotes/2020/05/07/rmd-citations/

> On Nov 4, 2020, at 9:22 AM, John <miaojpm at gmail.com> wrote:
> 
> Hi,
> 
>   I 'd like to create a table for literature review. Is there any good
> data structure (database) I may use? Now I just use a simple dataframe as
> follows, but in the second item I swap the order of year and author, and it
> records 2013 as author and "XH" as year.  Is there any better structure ?
> If not, how may I fix the current condition?Thanks!
> 
> 
> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
> df[1, ]<-c(
>           author = "Moore",
>           year = 2020,
>           title = "Statistics and data analysis",
>           country = "Colombia",
>           sample = NA,
>           data = "firm level",
>           result = NA,
>           note = NA)
> 
> df[nrow(df)+1,]<- c(year = 2013,
>                    author = "XH",
>                    title = NA,
>                    country = NA,
>                    sample = NA,
>                    data = NA,
>                    result = NA,
>                    note = NA)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |@p@nyo|com @end|ng |rom gm@||@com  Wed Nov  4 14:26:58 2020
From: |@p@nyo|com @end|ng |rom gm@||@com (=?UTF-8?Q?Engin_Y=C4=B1lmaz?=)
Date: Wed, 4 Nov 2020 16:26:58 +0300
Subject: [R] colMeans function
Message-ID: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>

Dear
I use *flights* database library(nycflights13)

The following code is working as

colMeans(flights[2])

* 6.54851*

but other code is  not working as

colMeans(flights$month)

*Error in colMeans(flights$month) : *
*  'x' must be an array of at least two dimensions*

*flights[2]* is equal to the *month *column in database

*Sincerely*
Engin YILMAZ

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 14:37:00 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 08:37:00 -0500
Subject: [R] colMeans function
In-Reply-To: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
References: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
Message-ID: <8c07f001-6fdd-84b2-9183-3dccff3f028c@gmail.com>

On 04/11/2020 8:26 a.m., Engin Y?lmaz wrote:
> Dear
> I use *flights* database library(nycflights13)
> 
> The following code is working as
> 
> colMeans(flights[2])
> 
> * 6.54851*
> 
> but other code is  not working as
> 
> colMeans(flights$month)
> 
> *Error in colMeans(flights$month) : *
> *  'x' must be an array of at least two dimensions*
> 
> *flights[2]* is equal to the *month *column in database

No, flights[2] is a dataframe with one column.  flights[[2]] would be 
the month column.

Duncan Murdoch


From m@rc_@chw@rtz @end|ng |rom me@com  Wed Nov  4 14:46:12 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Wed, 4 Nov 2020 08:46:12 -0500
Subject: [R] colMeans function
In-Reply-To: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
References: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
Message-ID: <B74F660C-4230-4391-B7B1-9C18ABF2B459@me.com>

Hi,

You might want to become familiar with the ?str and ?dim functions, which can help you identify the structure of the objects that you are passing to colMeans().

In the first case, flights[2] is a data frame with a single column, so will have two dimensions with a row and column structure.

In the second case, flights$month is a single numeric vector within the data frame and does not have a row and column dimension structure.

If you used flights[[2]], that would be equivalent to flights$month, in referencing a single numeric vector.

So, if you used:

str(flights[2])
dim(flights[2])

str(flights$month)
dim(flights$month)

you would see the difference.

Regards,

Marc Schwartz


> On Nov 4, 2020, at 8:26 AM, Engin Y?lmaz <ispanyolcom at gmail.com> wrote:
> 
> Dear
> I use *flights* database library(nycflights13)
> 
> The following code is working as
> 
> colMeans(flights[2])
> 
> * 6.54851*
> 
> but other code is  not working as
> 
> colMeans(flights$month)
> 
> *Error in colMeans(flights$month) : *
> *  'x' must be an array of at least two dimensions*
> 
> *flights[2]* is equal to the *month *column in database
> 
> *Sincerely*
> Engin YILMAZ


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Nov  4 18:19:48 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 4 Nov 2020 17:19:48 +0000
Subject: [R] colMeans function
In-Reply-To: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
References: <CAMUSX8oWtkhow8Tnw2M4btb-e0G-6=Nbi0tP2nfeKyjRMR8qpA@mail.gmail.com>
Message-ID: <61acfed6-cae1-283b-6401-5f6f11c5b8be@sapo.pt>

Hello,

No, flights[2] is *not* equal to flights$months. The former is a 
data.frame with only one column, therefore it has a dimension attribute. 
The latter is a column, a vector of the data.frame flights, it does not 
have the attribute dim set.

The difference is very important, see what class(), str() or dim() 
return when applied to both.

See also this StackOverflow post:

https://stackoverflow.com/questions/1169456/the-difference-between-bracket-and-double-bracket-for-accessing-the-el


Hope this helps,

Rui Barradas

?s 13:26 de 04/11/20, Engin Y?lmaz escreveu:
> Dear
> I use *flights* database library(nycflights13)
> 
> The following code is working as
> 
> colMeans(flights[2])
> 
> * 6.54851*
> 
> but other code is  not working as
> 
> colMeans(flights$month)
> 
> *Error in colMeans(flights$month) : *
> *  'x' must be an array of at least two dimensions*
> 
> *flights[2]* is equal to the *month *column in database
> 
> *Sincerely*
> Engin YILMAZ
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@|ner_krug @end|ng |rom |c|oud@com  Wed Nov  4 10:32:30 2020
From: r@|ner_krug @end|ng |rom |c|oud@com (Rainer Krug)
Date: Wed, 4 Nov 2020 10:32:30 +0100
Subject: [R] build a literature database
In-Reply-To: <ac555c04-c994-161c-ea8f-4dd2a1fbb46e@gmail.com>
References: <CABcx46Ccorvnr0vYNOqjcZEyrE8b+7y-DxC-yKVWy_GbMUVQbA@mail.gmail.com>
 <ac555c04-c994-161c-ea8f-4dd2a1fbb46e@gmail.com>
Message-ID: <DD9969F3-FC00-40C0-965B-373A7992BAE1@icloud.com>

I agree with Duncan.

I co-ordinated a large literature review with initially more than 5000 papers and about 30 reviewers, and all the bibliometrics information was in bibtex format, as it is easy to interchange between programs.

Cheers,

Rainer

> On 4 Nov 2020, at 10:28, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 04/11/2020 4:22 a.m., John wrote:
>> Hi,
>>    I 'd like to create a table for literature review. Is there any good
>> data structure (database) I may use? Now I just use a simple dataframe as
>> follows, but in the second item I swap the order of year and author, and it
>> records 2013 as author and "XH" as year.  Is there any better structure ?
>> If not, how may I fix the current condition?Thanks!
>> df <- data.frame(author = NA, year = NA, title = NA, country = NA, sample =
>> NA, data = NA, result = NA, note = NA, stringsAsFactors=FALSE)
>> df[1, ]<-c(
>>            author = "Moore",
>>            year = 2020,
>>            title = "Statistics and data analysis",
>>            country = "Colombia",
>>            sample = NA,
>>            data = "firm level",
>>            result = NA,
>>            note = NA)
>> df[nrow(df)+1,]<- c(year = 2013,
>>                     author = "XH",
>>                     title = NA,
>>                     country = NA,
>>                     sample = NA,
>>                     data = NA,
>>                     result = NA,
>>                     note = NA)
> 
> If you changed the last statement to
> 
> df <- rbind(df, data.frame(year = 2013,
>                      author = "XH",
>                      title = NA,
>                      country = NA,
>                      sample = NA,
>                      data = NA,
>                      result = NA,
>                      note = NA))
> 
> it would correctly sort out the reordered columns.
> 
> As to a better data structure:  bibliographic data is hard, because different forms of publication should have different fields.  I'd suggest storing the data in some existing format rather than rolling your own.  For example, the utils::bibentry function is quite a bit like BibTeX.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk  Wed Nov  4 12:48:58 2020
From: ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk (Philip Charles)
Date: Wed, 4 Nov 2020 11:48:58 +0000
Subject: [R] Intended use-case for data.matrix
Message-ID: <A3EE86FA-C000-4D2B-9A86-0390AFBD0900@ndm.ox.ac.uk>

Hi R gurus,

We do a lot of work with biological -omics datasets (genomics, proteomics etc).  The text file inputs to R typically contain a mixture of (mostly) character data and numeric data.  The number of columns (both character and numeric data) in the file vary with the number of samples measured (which makes use of colClasses , so a typical approach might be

1) read in the whole file as character matrix

#simulated result of read.table (with stringsAsFactors=FALSE)
raw <- data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo sapiens','Homo sapiens','Sus scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))

2) use grep to identify numeric columns based on column names and split the raw matrix

QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
META_COLS <- !QUANT_COLS
quant.df.char <- raw[,QUANT_COLS]
meta.df <- raw[, META_COLS]

3) convert the quantitation data frame to a numeric matrix

Prior to R version 4, my standard method for step 3 was to use data.matrix() for this last step.  After recently updating from v3.6.3, I've found that all my workflows using this function were giving wildly incorrect results. I figured out that data.matrix now yields a matrix of factor levels rather than the actual numeric values

> quant.df.char
  Intensity.SampleA Intensity.SampleB Intensity.SampleC
1            919948           1625540           1232780
2           1346170            710272           1481040
3             15870             83624             62548

> data.matrix(quant.df.char)
     Intensity.SampleA Intensity.SampleB Intensity.SampleC
[1,]                 3                 1                 1
[2,]                 1                 2                 2
[3,]                 2                 3                 3

The change in behaviour of this function is documented in the R v4.0.0 changelog, so it is clearly intentional:

"data.matrix() now converts character columns to factors and from this to integers."

Now, I know there are other ways to achieve the same conversion, e.g. sapply(quant.df.char, as.numeric). They aren't quite as straightforward to read in the code as data.matrix (sapply/lapply in particular I have to think though whether there will a need to transpose the result!), but the fact that this base function has been changed (without a way to replicate the previous behaviour) leads me to suspect that I have probably not previously been using data.matrix in the intended manner - and I may therefore be making similar mistakes elsewhere! I've certainly distributed/handed out R scripting examples in the past that will now give incorrect results when run on v4+ R.

What even more confusing to me (but possibly related as regards an answer) is that R v4 broke with long-standing convention to change default.stringsAsFactors() to FALSE. So on one hand the update took away what was (at least, from our perspective, with our data - I am sure some here may disagree!) a perennial source of confusion/bugs for R learners, by not introducing string factorisation during data import, and then on the other hand changed a base function to explicitly introduce string factorisation..  I can't see when converting a character dataset, not to factors but, straight to numeric factor levels might be that useful (but of course that doesn't mean it isn't!).

I've had a look through r-help and r-devel archives and couldn't spot any discussion of this, so apologies if this has been asked before. I'm also pretty sure my misunderstanding is with the intended use-case of data.matrix and R ethos around strings/factors rather than the rationale for the change, which is why I'm asking here.

Best wishes,

Phil

Philip Charles
Target Discovery Institute, Nuffield Department Of Medicine
University of Oxford




	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 21:37:40 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 15:37:40 -0500
Subject: [R] Intended use-case for data.matrix
Message-ID: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>

You can see the change to the help page here:

https://github.com/wch/r-source/commit/d1d3863d72613660727379dd5dffacad32ac9c35#diff-9143902e81e6ad39faace2d926725c4c72b078dd13fbb1223c4a35f833b58ee6

Before the change, it said the input should be

a data frame whose components are logical vectors, factors or numeric
vectors

which suggests your input was invalid. But later it says

Logical and factor columns are converted to integers. Any other
column which is not numeric (according to \code{\link{is.numeric}}) is
converted by \code{\link{as.numeric}} or, for S4 objects,
\code{\link{as}(, "numeric")}.

which suggests what you were doing was supported.

It's unfortunate that you didn't know about this change, but it was made in
August 2019, and appeared on the news feed here:

https://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2019/08/08#n2019-08-08

so some of the blame for this goes to you for not paying attention and
testing unreleased R versions.

To protect yourself against this kind of unpleasant surprise in the future,
I'd suggest this:

- Follow the news feed.

- Put your code in a package, and test it against R-devel now and then. (If
your package is on CRAN the testing will happen automatically; if it's not
on CRAN and not in a package, you could still test against R-devel, but why
make your life more difficult by *not* putting it in a package?)

Duncan Murdoch

On 04/11/2020 6:48 a.m., Philip Charles wrote:
> Hi R gurus,
>
> We do a lot of work with biological -omics datasets (genomics, proteomics
etc). The text file inputs to R typically contain a mixture of (mostly)
character data and numeric data. The number of columns (both character and
numeric data) in the file vary with the number of samples measured (which
makes use of colClasses , so a typical approach might be
>
> 1) read in the whole file as character matrix
>
> #simulated result of read.table (with stringsAsFactors=FALSE)
> raw <-
data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular
tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo
sapiens','Homo sapiens','Sus
scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))
>
> 2) use grep to identify numeric columns based on column names and split
the raw matrix
>
> QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
> META_COLS <- !QUANT_COLS
> quant.df.char <- raw[,QUANT_COLS]
> meta.df <- raw[, META_COLS]
>
> 3) convert the quantitation data frame to a numeric matrix
>
> Prior to R version 4, my standard method for step 3 was to use
data.matrix() for this last step. After recently updating from v3.6.3, I've
found that all my workflows using this function were giving wildly
incorrect results. I figured out that data.matrix now yields a matrix of
factor levels rather than the actual numeric values
>
>> quant.df.char
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> 1 919948 1625540 1232780
> 2 1346170 710272 1481040
> 3 15870 83624 62548
>
>> data.matrix(quant.df.char)
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> [1,] 3 1 1
> [2,] 1 2 2
> [3,] 2 3 3
>
> The change in behaviour of this function is documented in the R v4.0.0
changelog, so it is clearly intentional:
>
> "data.matrix() now converts character columns to factors and from this to
integers."
>
> Now, I know there are other ways to achieve the same conversion, e.g.
sapply(quant.df.char, as.numeric). They aren't quite as straightforward to
read in the code as data.matrix (sapply/lapply in particular I have to
think though whether there will a need to transpose the result!), but the
fact that this base function has been changed (without a way to replicate
the previous behaviour) leads me to suspect that I have probably not
previously been using data.matrix in the intended manner - and I may
therefore be making similar mistakes elsewhere! I've certainly
distributed/handed out R scripting examples in the past that will now give
incorrect results when run on v4+ R.
>
> What even more confusing to me (but possibly related as regards an
answer) is that R v4 broke with long-standing convention to change
default.stringsAsFactors() to FALSE. So on one hand the update took away
what was (at least, from our perspective, with our data - I am sure some
here may disagree!) a perennial source of confusion/bugs for R learners, by
not introducing string factorisation during data import, and then on the
other hand changed a base function to explicitly introduce string
factorisation.. I can't see when converting a character dataset, not to
factors but, straight to numeric factor levels might be that useful (but of
course that doesn't mean it isn't!).
>
> I've had a look through r-help and r-devel archives and couldn't spot any
discussion of this, so apologies if this has been asked before. I'm also
pretty sure my misunderstanding is with the intended use-case of
data.matrix and R ethos around strings/factors rather than the rationale
for the change, which is why I'm asking here.
>
> Best wishes,
>
> Phil
>
> Philip Charles
> Target Discovery Institute, Nuffield Department Of Medicine
> University of Oxford
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk  Wed Nov  4 22:43:53 2020
From: ph|||p@ch@r|e@ @end|ng |rom ndm@ox@@c@uk (Philip Charles)
Date: Wed, 4 Nov 2020 21:43:53 +0000
Subject: [R] Intended use-case for data.matrix
In-Reply-To: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>
References: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>
Message-ID: <249C3461-4F26-42DD-9778-A26EC07E25EF@ndm.ox.ac.uk>

Hi Duncan,

Thanks; that's really useful info, and now that you point it out I completely agree that the frame arguments description does make my original use invalid - I will pay closer attention to such details in future.  Would you suggest sapply(...,as.numeric)  is the most 'R'-y way of converting a character dataframe to numeric matrix, or is there a cleaner pattern?

Best wishes,

Phil

On 4 Nov 2020, at 20:37, Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>> wrote:

You can see the change to the help page here:

https://github.com/wch/r-source/commit/d1d3863d72613660727379dd5dffacad32ac9c35#diff-9143902e81e6ad39faace2d926725c4c72b078dd13fbb1223c4a35f833b58ee6

Before the change, it said the input should be

a data frame whose components are logical vectors, factors or numeric vectors

which suggests your input was invalid. But later it says

Logical and factor columns are converted to integers. Any other
column which is not numeric (according to \code{\link{is.numeric}}) is
converted by \code{\link{as.numeric}} or, for S4 objects,
\code{\link{as}(, "numeric")}.

which suggests what you were doing was supported.

It's unfortunate that you didn't know about this change, but it was made in August 2019, and appeared on the news feed here:

https://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2019/08/08#n2019-08-08

so some of the blame for this goes to you for not paying attention and testing unreleased R versions.

To protect yourself against this kind of unpleasant surprise in the future, I'd suggest this:

- Follow the news feed.

- Put your code in a package, and test it against R-devel now and then. (If your package is on CRAN the testing will happen automatically; if it's not on CRAN and not in a package, you could still test against R-devel, but why make your life more difficult by *not* putting it in a package?)

Duncan Murdoch

On 04/11/2020 6:48 a.m., Philip Charles wrote:
> Hi R gurus,
>
> We do a lot of work with biological -omics datasets (genomics, proteomics etc). The text file inputs to R typically contain a mixture of (mostly) character data and numeric data. The number of columns (both character and numeric data) in the file vary with the number of samples measured (which makes use of colClasses , so a typical approach might be
>
> 1) read in the whole file as character matrix
>
> #simulated result of read.table (with stringsAsFactors=FALSE)
> raw <- data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo sapiens','Homo sapiens','Sus scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))
>
> 2) use grep to identify numeric columns based on column names and split the raw matrix
>
> QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
> META_COLS <- !QUANT_COLS
> quant.df.char <- raw[,QUANT_COLS]
> meta.df <- raw[, META_COLS]
>
> 3) convert the quantitation data frame to a numeric matrix
>
> Prior to R version 4, my standard method for step 3 was to use data.matrix() for this last step. After recently updating from v3.6.3, I've found that all my workflows using this function were giving wildly incorrect results. I figured out that data.matrix now yields a matrix of factor levels rather than the actual numeric values
>
>> quant.df.char
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> 1 919948 1625540 1232780
> 2 1346170 710272 1481040
> 3 15870 83624 62548
>
>> data.matrix(quant.df.char)
> Intensity.SampleA Intensity.SampleB Intensity.SampleC
> [1,] 3 1 1
> [2,] 1 2 2
> [3,] 2 3 3
>
> The change in behaviour of this function is documented in the R v4.0.0 changelog, so it is clearly intentional:
>
> "data.matrix() now converts character columns to factors and from this to integers."
>
> Now, I know there are other ways to achieve the same conversion, e.g. sapply(quant.df.char, as.numeric). They aren't quite as straightforward to read in the code as data.matrix (sapply/lapply in particular I have to think though whether there will a need to transpose the result!), but the fact that this base function has been changed (without a way to replicate the previous behaviour) leads me to suspect that I have probably not previously been using data.matrix in the intended manner - and I may therefore be making similar mistakes elsewhere! I've certainly distributed/handed out R scripting examples in the past that will now give incorrect results when run on v4+ R.
>
> What even more confusing to me (but possibly related as regards an answer) is that R v4 broke with long-standing convention to change default.stringsAsFactors() to FALSE. So on one hand the update took away what was (at least, from our perspective, with our data - I am sure some here may disagree!) a perennial source of confusion/bugs for R learners, by not introducing string factorisation during data import, and then on the other hand changed a base function to explicitly introduce string factorisation.. I can't see when converting a character dataset, not to factors but, straight to numeric factor levels might be that useful (but of course that doesn't mean it isn't!).
>
> I've had a look through r-help and r-devel archives and couldn't spot any discussion of this, so apologies if this has been asked before. I'm also pretty sure my misunderstanding is with the intended use-case of data.matrix and R ethos around strings/factors rather than the rationale for the change, which is why I'm asking here.
>
> Best wishes,
>
> Phil
>
> Philip Charles
> Target Discovery Institute, Nuffield Department Of Medicine
> University of Oxford
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>





	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Nov  4 22:50:50 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 4 Nov 2020 16:50:50 -0500
Subject: [R] Intended use-case for data.matrix
In-Reply-To: <249C3461-4F26-42DD-9778-A26EC07E25EF@ndm.ox.ac.uk>
References: <CA+COuteWqLGoj_QyxCZFAEMYN2qr01pQxTHfb3NS60AQPwygFw@mail.gmail.com>
 <249C3461-4F26-42DD-9778-A26EC07E25EF@ndm.ox.ac.uk>
Message-ID: <d17d96ac-e129-cc12-14dd-82ec81d37e1f@gmail.com>

On 04/11/2020 4:43 p.m., Philip Charles wrote:
> Hi Duncan,
> 
> Thanks; that's really useful info, and now that you point it out I 
> completely agree that the frame arguments description does make my 
> original use invalid - I will pay closer attention to such details in 
> future. ?Would you suggest sapply(...,as.numeric) ?is the most 'R'-y way 
> of converting a character dataframe to numeric matrix, or is there a 
> cleaner pattern?

I'd definitely use `as.numeric`. There are some reasons to prefer 
vapply() to sapply() (they are mentioned in the help page).  I tend to 
use for loops more than some people (because I find them more obvious, 
having learned to program a long time ago).

Duncan Murdoch

> 
> Best wishes,
> 
> Phil
> 
>> On 4 Nov 2020, at 20:37, Duncan Murdoch <murdoch.duncan at gmail.com 
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>> You can see the change to the help page here:
>>
>> https://github.com/wch/r-source/commit/d1d3863d72613660727379dd5dffacad32ac9c35#diff-9143902e81e6ad39faace2d926725c4c72b078dd13fbb1223c4a35f833b58ee6
>>
>> Before the change, it said the input should be
>>
>> a data frame whose components are logical vectors, factors or numeric 
>> vectors
>>
>> which suggests your input was invalid. But later it says
>>
>> Logical and factor columns are converted to integers. Any other
>> column which is not numeric (according to \code{\link{is.numeric}}) is
>> converted by \code{\link{as.numeric}} or, for S4 objects,
>> \code{\link{as}(, "numeric")}.
>>
>> which suggests what you were doing was supported.
>>
>> It's unfortunate that you didn't know about this change, but it was 
>> made in August 2019, and appeared on the news feed here:
>>
>> https://developer.r-project.org/blosxom.cgi/R-devel/NEWS/2019/08/08#n2019-08-08
>>
>> so some of the blame for this goes to you for not paying attention and 
>> testing unreleased R versions.
>>
>> To protect yourself against this kind of unpleasant surprise in the 
>> future, I'd suggest this:
>>
>> - Follow the news feed.
>>
>> - Put your code in a package, and test it against R-devel now and 
>> then. (If your package is on CRAN the testing will happen 
>> automatically; if it's not on CRAN and not in a package, you could 
>> still test against R-devel, but why make your life more difficult by 
>> *not* putting it in a package?)
>>
>> Duncan Murdoch
>>
>> On 04/11/2020 6:48 a.m., Philip Charles wrote:
>> > Hi R gurus,
>> > 
>> > We do a lot of work with biological -omics datasets (genomics, proteomics etc). The text file inputs to R typically contain a mixture of (mostly) character data and numeric data. The number of columns (both character and numeric data) in the file vary with the number of samples measured (which makes use of colClasses , so a 
>> typical approach might be
>> > 
>> > 1) read in the whole file as character matrix
>> > 
>> > #simulated result of read.table (with stringsAsFactors=FALSE)
>> > raw <- data.frame(Accession=c('P04637','P01375','P00761'),Description=c('Cellular tumor antigen p53','Tumor necrosis factor','Trypsin'),Species=c('Homo sapiens','Homo sapiens','Sus scrofa'),Intensity.SampleA=c('919948','1346170','15870'),Intensity.SampleB=c('1625540','710272','83624'),Intensity.SampleC=c('1232780','1481040','62548'))
>> > 
>> > 2) use grep to identify numeric columns based on column names and split the raw matrix
>> > 
>> > QUANT_COLS <- grepl('^Intensity\\.',colnames(raw))
>> > META_COLS <- !QUANT_COLS
>> > quant.df.char <- raw[,QUANT_COLS]
>> > meta.df <- raw[, META_COLS]
>> > 
>> > 3) convert the quantitation data frame to a numeric matrix
>> > 
>> > Prior to R version 4, my standard method for step 3 was to use data.matrix() for this last step. After recently updating from v3.6.3, I've found that all my workflows using this function were giving wildly incorrect results. I figured out that data.matrix now yields a matrix of factor levels rather than the actual numeric 
>> values
>> > 
>> >> quant.df.char
>> > Intensity.SampleA Intensity.SampleB Intensity.SampleC
>> > 1 919948 1625540 1232780
>> > 2 1346170 710272 1481040
>> > 3 15870 83624 62548
>> > 
>> >> data.matrix(quant.df.char)
>> > Intensity.SampleA Intensity.SampleB Intensity.SampleC
>> > [1,] 3 1 1
>> > [2,] 1 2 2
>> > [3,] 2 3 3
>> > 
>> > The change in behaviour of this function is documented in the R v4.0.0 changelog, so it is clearly intentional:
>> > 
>> > "data.matrix() now converts character columns to factors and from this to integers."
>> > 
>> > Now, I know there are other ways to achieve the same conversion, e.g. sapply(quant.df.char, as.numeric). They aren't quite as straightforward to read in the code as data.matrix (sapply/lapply in particular I have to think though whether there will a need to transpose the result!), but the fact that this base function has 
>> been changed (without a way to replicate the previous behaviour) leads 
>> me to suspect that I have probably not previously been using 
>> data.matrix in the intended manner - and I may therefore be making 
>> similar mistakes elsewhere! I've certainly distributed/handed out R 
>> scripting examples in the past that will now give incorrect results 
>> when run on v4+ R.
>> > 
>> > What even more confusing to me (but possibly related as regards an answer) is that R v4 broke with long-standing convention to change default.stringsAsFactors() to FALSE. So on one hand the update took away what was (at least, from our perspective, with our data - I am sure some here may disagree!) a perennial source of 
>> confusion/bugs for R learners, by not introducing string factorisation 
>> during data import, and then on the other hand changed a base function 
>> to explicitly introduce string factorisation.. I can't see when 
>> converting a character dataset, not to factors but, straight to 
>> numeric factor levels might be that useful (but of course that doesn't 
>> mean it isn't!).
>> > 
>> > I've had a look through r-help and r-devel archives and couldn't spot any discussion of this, so apologies if this has been asked before. I'm also pretty sure my misunderstanding is with the intended use-case of data.matrix and R ethos around strings/factors rather than the rationale for the change, which is why I'm asking here.
>> > 
>> > Best wishes,
>> > 
>> > Phil
>> > 
>> > Philip Charles
>> > Target Discovery Institute, Nuffield Department Of Medicine
>> > University of Oxford
>> > 
>> > 
>> > 
>> > 
>> > [[alternative HTML version deleted]]
>> > 
>> > ______________________________________________
>> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
>> <http://www.r-project.org/posting-guide.html>
>> > and provide commented, minimal, self-contained, reproducible code.
>> > 
>>
>>
>>
>


From m|@ojpm @end|ng |rom gm@||@com  Thu Nov  5 03:38:51 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 5 Nov 2020 10:38:51 +0800
Subject: [R] Error message when using "revtools" package
Message-ID: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>

Hi,

    I tried to read a bib file by  "read_bibliography" function in
"revtools" package, but I got an error message but don't know how to fix
it. Anyone can help? Thank you so much!!

###
   library(revtools)
   data2 <- read_bibliography("mlf_ref201105_2.bib", return_df = FALSE)
###

Error message:
####
Error in if (any(names(entry_list) == "author")) { :
  missing value where TRUE/FALSE needed
####

   My "mlf_ref201105_2.bib" file is attached.

   I have no problem reading the built-in ris file:

####
file_location <- system.file(
  "extdata",
  "avian_ecology_bibliography.ris",
  package = "revtools")
x <- read_bibliography(file_location)
####

From bgunter@4567 @end|ng |rom gm@||@com  Thu Nov  5 03:40:15 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Nov 2020 18:40:15 -0800
Subject: [R] Error message when using "revtools" package
In-Reply-To: <CAGxFJbTC-Dh6j=m7+0rJMdAN2iz4vNr8w=n8cDaM_MVcdPEy+w@mail.gmail.com>
References: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
 <CAGxFJbTC-Dh6j=m7+0rJMdAN2iz4vNr8w=n8cDaM_MVcdPEy+w@mail.gmail.com>
Message-ID: <CAGxFJbQJCg=X3vvXR7_Gh0met0TBEZ2q0Rx2AsdRPcNui_KhEQ@mail.gmail.com>

Perhaps better suggestion: r-sig-meta-analysis  ?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Nov  5 03:41:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 4 Nov 2020 18:41:24 -0800
Subject: [R] Fwd:  Error message when using "revtools" package
In-Reply-To: <CAGxFJbQJCg=X3vvXR7_Gh0met0TBEZ2q0Rx2AsdRPcNui_KhEQ@mail.gmail.com>
References: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
 <CAGxFJbTC-Dh6j=m7+0rJMdAN2iz4vNr8w=n8cDaM_MVcdPEy+w@mail.gmail.com>
 <CAGxFJbQJCg=X3vvXR7_Gh0met0TBEZ2q0Rx2AsdRPcNui_KhEQ@mail.gmail.com>
Message-ID: <CAGxFJbQCyVbDhFgNgCeeF-d2ngxZK69yznZkJRxURBKdF5Gu1Q@mail.gmail.com>

Neglected to cc the list!

Bert

---------- Forwarded message ---------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Wed, Nov 4, 2020 at 6:40 PM
Subject: Re: [R] Error message when using "revtools" package
To: John <miaojpm at gmail.com>, R-help <r-help at r-project.org>


Perhaps better suggestion: r-sig-meta-analysis  ?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Thu Nov  5 06:25:29 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Thu, 5 Nov 2020 13:25:29 +0800
Subject: [R] string concatenation
Message-ID: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>

Hi,

I have a sequence of characters:

x <- c("Alice", "Bob", "Charles")

How can I produce the following results:

"Alice, Bob, Charles"

?

paste? merge?

Thank you very much!

	[[alternative HTML version deleted]]


From @pro @end|ng |rom un|me|b@edu@@u  Thu Nov  5 06:18:02 2020
From: @pro @end|ng |rom un|me|b@edu@@u (Andrew Robinson)
Date: Thu, 5 Nov 2020 05:18:02 +0000
Subject: [R] [EXT]  string concatenation
In-Reply-To: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
Message-ID: <2905ce7e-24ce-4807-9a24-117ecdfba79e@Spark>

Try

paste(x, collapse = ", ")

Cheers,

Andrew

--
Andrew Robinson
Director, CEBRA and Professor of Biosecurity,
School/s of BioSciences and Mathematics & Statistics
University of Melbourne, VIC 3010 Australia
Tel: (+61) 0403 138 955
Email: apro at unimelb.edu.au
Website: https://researchers.ms.unimelb.edu.au/~apro at unimelb/

I acknowledge the Traditional Owners of the land I inhabit, and pay my respects to their Elders.
On Nov 5, 2020, 4:17 PM +1100, John <miaojpm at gmail.com>, wrote:

x <- c("Alice", "Bob", "Charles")

	[[alternative HTML version deleted]]


From @zwj|08 @end|ng |rom gm@||@com  Thu Nov  5 06:24:17 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Thu, 5 Nov 2020 13:24:17 +0800
Subject: [R] string concatenation
In-Reply-To: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
Message-ID: <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>

Hi John,

Try paste0(x,collapse = ", ")

Best,
Jiefei

On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:

> Hi,
>
> I have a sequence of characters:
>
> x <- c("Alice", "Bob", "Charles")
>
> How can I produce the following results:
>
> "Alice, Bob, Charles"
>
> ?
>
> paste? merge?
>
> Thank you very much!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@k|@we @end|ng |rom gm@||@com  Thu Nov  5 09:20:26 2020
From: m@k|@we @end|ng |rom gm@||@com (Edjabou Vincent)
Date: Thu, 5 Nov 2020 09:20:26 +0100
Subject: [R] string concatenation
In-Reply-To: <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
 <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
Message-ID: <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>

Following John request, I am wondering if it is possible to get this result:

Alice, Bob, Charles (without bracket )

Thank you for your help



Med venlig hilsen/ Best regards

Vincent Edjabou
Mobile: +45 31 95 99 33
linkedin.com/vincent
<http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>

Orcid: 0000-0003-2849-6151



On Thu, Nov 5, 2020 at 6:27 AM Jiefei Wang <szwjf08 at gmail.com> wrote:

> Hi John,
>
> Try paste0(x,collapse = ", ")
>
> Best,
> Jiefei
>
> On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:
>
> > Hi,
> >
> > I have a sequence of characters:
> >
> > x <- c("Alice", "Bob", "Charles")
> >
> > How can I produce the following results:
> >
> > "Alice, Bob, Charles"
> >
> > ?
> >
> > paste? merge?
> >
> > Thank you very much!
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Nov  5 11:51:17 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Nov 2020 05:51:17 -0500
Subject: [R] string concatenation
In-Reply-To: <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
 <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
 <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>
Message-ID: <8b4a119b-cf03-abd0-554f-c586af5957f2@gmail.com>

On 05/11/2020 3:20 a.m., Edjabou Vincent wrote:
> Following John request, I am wondering if it is possible to get this result:
> 
> Alice, Bob, Charles (without bracket )

I think you mean "without the quotes".  Use noquote():

   noquote(paste0(x,collapse = ", "))

will print without quotes.  (Internally the data is the same, but a 
class attribute is added that tells print() not to add quotes.)

Duncan Murdoch
> 
> Thank you for your help
> 
> 
> 
> Med venlig hilsen/ Best regards
> 
> Vincent Edjabou
> Mobile: +45 31 95 99 33
> linkedin.com/vincent
> <http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>
> 
> Orcid: 0000-0003-2849-6151
> 
> 
> 
> On Thu, Nov 5, 2020 at 6:27 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> 
>> Hi John,
>>
>> Try paste0(x,collapse = ", ")
>>
>> Best,
>> Jiefei
>>
>> On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:
>>
>>> Hi,
>>>
>>> I have a sequence of characters:
>>>
>>> x <- c("Alice", "Bob", "Charles")
>>>
>>> How can I produce the following results:
>>>
>>> "Alice, Bob, Charles"
>>>
>>> ?
>>>
>>> paste? merge?
>>>
>>> Thank you very much!
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Nov  5 12:50:46 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 5 Nov 2020 11:50:46 +0000
Subject: [R] Error message when using "revtools" package
In-Reply-To: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
References: <CABcx46D5MabzD3dLEVh6meWa1U=KOg8EbHiZgc51W+t5KOGhrA@mail.gmail.com>
Message-ID: <1973ba7e-479a-7502-f7cd-e26da2cbd246@dewey.myzen.co.uk>

Dear John

Your .bib file did not make it through the system as only a very limited 
set of attachments is supported. Try to make a minimal .bib file which 
triggers the problem by splitting your file in half, testing each half, 
repeat until you get the smallest file which triggers the error. 
Hopefully that will be a single entry which you can then include in your 
post. It also increases the chances of someone looking at it as a large 
.bib file is going to deter people.

Michael

On 05/11/2020 02:38, John wrote:
> Hi,
> 
>      I tried to read a bib file by  "read_bibliography" function in
> "revtools" package, but I got an error message but don't know how to fix
> it. Anyone can help? Thank you so much!!
> 
> ###
>     library(revtools)
>     data2 <- read_bibliography("mlf_ref201105_2.bib", return_df = FALSE)
> ###
> 
> Error message:
> ####
> Error in if (any(names(entry_list) == "author")) { :
>    missing value where TRUE/FALSE needed
> ####
> 
>     My "mlf_ref201105_2.bib" file is attached.
> 
>     I have no problem reading the built-in ris file:
> 
> ####
> file_location <- system.file(
>    "extdata",
>    "avian_ecology_bibliography.ris",
>    package = "revtools")
> x <- read_bibliography(file_location)
> ####
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @zwj|08 @end|ng |rom gm@||@com  Thu Nov  5 12:53:00 2020
From: @zwj|08 @end|ng |rom gm@||@com (Jiefei Wang)
Date: Thu, 5 Nov 2020 19:53:00 +0800
Subject: [R] string concatenation
In-Reply-To: <8b4a119b-cf03-abd0-554f-c586af5957f2@gmail.com>
References: <CABcx46AijVu5w_NiErJCPHaJpnMHDDqPsYcBjEvAAxVEkQCcHQ@mail.gmail.com>
 <CAGiFhPN0Rugu-pXOwTUi0TKksYsmofSw1djfgutqFoeC8nh+=Q@mail.gmail.com>
 <CALFkoEp3vjKmkJo1-++ZWE8_UuXwpXcq4HKy04OpujGcizH7vg@mail.gmail.com>
 <8b4a119b-cf03-abd0-554f-c586af5957f2@gmail.com>
Message-ID: <CAGiFhPMA=0YF88QkjEb4ige8uCmgGJovpgqevHPD3QDM1q84FQ@mail.gmail.com>

Hi,

Thanks for clarifying, there is no quote in the result. The quote in the
output is just R's way to tell you that the variable got printed is a
string. If you add quotes around a string, it will get printed like

"\"Alice, Bob, Charles\""

I hope this helps.

Best,
Jiefei

On Thu, Nov 5, 2020 at 6:51 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 05/11/2020 3:20 a.m., Edjabou Vincent wrote:
> > Following John request, I am wondering if it is possible to get this
> result:
> >
> > Alice, Bob, Charles (without bracket )
>
> I think you mean "without the quotes".  Use noquote():
>
>    noquote(paste0(x,collapse = ", "))
>
> will print without quotes.  (Internally the data is the same, but a
> class attribute is added that tells print() not to add quotes.)
>
> Duncan Murdoch
> >
> > Thank you for your help
> >
> >
> >
> > Med venlig hilsen/ Best regards
> >
> > Vincent Edjabou
> > Mobile: +45 31 95 99 33
> > linkedin.com/vincent
> > <http://linkedin.com/in/vincent-maklawe-edjabou-9742a41b>
> >
> > Orcid: 0000-0003-2849-6151
> >
> >
> >
> > On Thu, Nov 5, 2020 at 6:27 AM Jiefei Wang <szwjf08 at gmail.com> wrote:
> >
> >> Hi John,
> >>
> >> Try paste0(x,collapse = ", ")
> >>
> >> Best,
> >> Jiefei
> >>
> >> On Thu, Nov 5, 2020 at 1:16 PM John <miaojpm at gmail.com> wrote:
> >>
> >>> Hi,
> >>>
> >>> I have a sequence of characters:
> >>>
> >>> x <- c("Alice", "Bob", "Charles")
> >>>
> >>> How can I produce the following results:
> >>>
> >>> "Alice, Bob, Charles"
> >>>
> >>> ?
> >>>
> >>> paste? merge?
> >>>
> >>> Thank you very much!
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From @nthonytrev|@@n @end|ng |rom gm@||@com  Wed Nov  4 13:04:05 2020
From: @nthonytrev|@@n @end|ng |rom gm@||@com (Anthony Trevisan)
Date: Wed, 4 Nov 2020 07:04:05 -0500
Subject: [R] [R-pkgs] fmpcloudr package
Message-ID: <5D40F6F7-71CB-4A7F-BE1A-4CB398F6BB80@gmail.com>

Hello,

As recommended in https://r-pkgs.org/release.html <https://r-pkgs.org/release.html>, I wanted to notify the R community about a new package for accessing financial data metrics. The package fmpcloudr (https://CRAN.R-project.org/package=fmpcloudr <https://cran.r-project.org/package=fmpcloudr>) interacts with the FMP API. 

FMP offers historical pricing data for indexes, stocks, ETFs, mutual finds, currencies, and crypto. Other financial metrics are available such as technical indicators (EMA, RSI, etc), company financials, and 13F. It?s a great data source and could be beneficial to many R users. You can find more details about the package here: https://tonytrevisan.github.io/fmpcloudr/ <https://tonytrevisan.github.io/fmpcloudr/>

Thank you for supporting such an incredible open source community. Learning R has dramatically reshaped my career path which would have been impossible without the R community.  

Best regards,
Tony



	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jo@chim m@iii@g oii zuck@reiii@de  Thu Nov  5 10:55:08 2020
From: jo@chim m@iii@g oii zuck@reiii@de (jo@chim m@iii@g oii zuck@reiii@de)
Date: Thu, 5 Nov 2020 10:55:08 +0100
Subject: [R] [R-pkgs] xmlconvert: A package for converting XML data to R
 data frames and vice versa
Message-ID: <015e01d6b359$bf0c8ba0$3d25a2e0$@zuckarelli.de>

Hello everyone,



Driven by the need to work with XML data from medical systems that use
object-oriented databases I have developed the 'xmlconvert' package. With
its easy-to-use functions xml_to_df() and df_to_xml() it allows to convert
data from XML to R data frames and vice versa. A variety of arguments gives
you control over the specifics of the conversion process.



The package is available on CRAN (visit
https://CRAN.R-project.org/package=xmlconvert for more details). Install it
by executing

> install.packages("xmlconvert", dependencies = TRUE)

in the R console.



You will find more information on GitHub
(https://github.com/jsugarelli/xmlconvert). The GitHub README provides an
intro how to use the package and how to adjust for different ways in which
the data can be represented in the XML documents.



Best,



Joachim



----

Joachim L. Zuckarelli

E-mail: joachim at zuckarelli.de <mailto:joachim at zuckarelli.de>

Website: http://www.zuckarelli.de

Twitter: https://twitter.com/jsugarelli






	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m|@ojpm @end|ng |rom gm@||@com  Fri Nov  6 13:39:31 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Fri, 6 Nov 2020 20:39:31 +0800
Subject: [R] backslash in xtable (generate latex code from R)
Message-ID: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>

I'd like to have $\alpha_1$ in my table, and the column name is $\beta_0$
####
library(xtable)
mytable <- data.frame(beta_0 = c("aa","bb","cc$\\alpha_1$"))
colnames(mytable) <- "$\\beta_0$"
print(xtable(mytable), include.rownames = F, sanitize.colnames.function =
identity)
####

No problem with \beta_0, but a problem with \alpha_1:

\begin{table}[ht]
\centering
\begin{tabular}{l}
  \hline
$\beta_0$ \\
  \hline
aa \\
  bb \\
  cc\$$\backslash$alpha\_1\$ \\
   \hline
\end{tabular}
\end{table}

How may I fix the $\alpha_1$? Thanks!

	[[alternative HTML version deleted]]


From th|erry@onke||nx @end|ng |rom |nbo@be  Fri Nov  6 13:42:32 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Fri, 6 Nov 2020 13:42:32 +0100
Subject: [R] backslash in xtable (generate latex code from R)
In-Reply-To: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
References: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
Message-ID: <CAJuCY5ytmD2diXZeoSqx9Y=W7FiuHKVULN1R_E73gryrLnP_yA@mail.gmail.com>

You could use kable() from the knitr package.

kable(mytable, format = "latex", escape = FALSE)

\begin{tabular}{l}
\hline
$\beta_0$\\
\hline
aa\\
\hline
bb\\
\hline
cc$\alpha_1$\\
\hline
\end{tabular}


ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////


<https://www.inbo.be>


Op vr 6 nov. 2020 om 13:30 schreef John <miaojpm at gmail.com>:

> I'd like to have $\alpha_1$ in my table, and the column name is $\beta_0$
> ####
> library(xtable)
> mytable <- data.frame(beta_0 = c("aa","bb","cc$\\alpha_1$"))
> colnames(mytable) <- "$\\beta_0$"
> print(xtable(mytable), include.rownames = F, sanitize.colnames.function =
> identity)
> ####
>
> No problem with \beta_0, but a problem with \alpha_1:
>
> \begin{table}[ht]
> \centering
> \begin{tabular}{l}
>   \hline
> $\beta_0$ \\
>   \hline
> aa \\
>   bb \\
>   cc\$$\backslash$alpha\_1\$ \\
>    \hline
> \end{tabular}
> \end{table}
>
> How may I fix the $\alpha_1$? Thanks!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Nov  6 14:04:28 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 6 Nov 2020 08:04:28 -0500
Subject: [R] backslash in xtable (generate latex code from R)
In-Reply-To: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
References: <CABcx46CkpyESLgGmcHk+bQQmX3nYOAxRqL7eyuYXSWdTKYR3WA@mail.gmail.com>
Message-ID: <7CDBEC55-DFD0-494A-99B0-B95B445193DF@me.com>

Hi,

It looks like xtable is "sanitizing" special characters in the LaTeX output by default, by adding a double backslash, so that LaTeX will process the characters as literals, rather than specials. It is not parsing the boundary '$' characters to define insertion of math symbols inside text mode.

You have 'sanitize.colnames.function = identity', which is why the column name is output 'as is'.

You would seem to need to do the same thing for the text content within the table content:

> print(xtable(mytable), include.rownames = F, 
        sanitize.colnames.function = identity, 
        sanitize.text.function = identity)
% latex table generated in R 4.0.3 by xtable 1.8-4 package
% Fri Nov  6 07:54:51 2020
\begin{table}[ht]
\centering
\begin{tabular}{l}
  \hline
$\beta_0$ \\ 
  \hline
aa \\ 
  bb \\ 
  cc$\alpha_1$ \\ 
   \hline
\end{tabular}
\end{table}


Regards,

Marc Schwartz


> On Nov 6, 2020, at 7:39 AM, John <miaojpm at gmail.com> wrote:
> 
> I'd like to have $\alpha_1$ in my table, and the column name is $\beta_0$
> ####
> library(xtable)
> mytable <- data.frame(beta_0 = c("aa","bb","cc$\\alpha_1$"))
> colnames(mytable) <- "$\\beta_0$"
> print(xtable(mytable), include.rownames = F, sanitize.colnames.function =
> identity)
> ####
> 
> No problem with \beta_0, but a problem with \alpha_1:
> 
> \begin{table}[ht]
> \centering
> \begin{tabular}{l}
>  \hline
> $\beta_0$ \\
>  \hline
> aa \\
>  bb \\
>  cc\$$\backslash$alpha\_1\$ \\
>   \hline
> \end{tabular}
> \end{table}
> 
> How may I fix the $\alpha_1$? Thanks!


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Nov  6 15:07:50 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 6 Nov 2020 08:07:50 -0600
Subject: [R] how to order variables on correlation plot
Message-ID: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>

Hello

I have data like this:

> head(my_data)
      subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
            C3          C4          C5           C6           C7          C8
1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
           C9         C10
1  0.00328111 -0.00113515
2 -0.00495790  0.00320201
3  0.00208591 -0.00874752
4 -0.00967934  0.00607760
5  0.00611030  0.00876190
6 -0.00990661  0.00635349

I am plotting it with:

library(dplyr)
library(magrittr)
library(corrplot)
d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
res <- cor(d, use = "complete.obs")
pdf("correlation.pdf")
corrplot(res, type = "upper", order = "hclust",
         tl.col = "black", tl.srt = 45)
dev.off()

and I am getting the plot in attach. How to make it so that my
variables are shown on the plot in the order they are in my_data data
frame?

Thanks
Ana


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Nov  6 15:08:21 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 6 Nov 2020 08:08:21 -0600
Subject: [R] how to order variables on correlation plot
In-Reply-To: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
Message-ID: <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>

sorry forgot to attach the plot.

On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello
>
> I have data like this:
>
> > head(my_data)
>       subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
> 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
> 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
> 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
> 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
> 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
> 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
>             C3          C4          C5           C6           C7          C8
> 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
> 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
> 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
> 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
> 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
> 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
>            C9         C10
> 1  0.00328111 -0.00113515
> 2 -0.00495790  0.00320201
> 3  0.00208591 -0.00874752
> 4 -0.00967934  0.00607760
> 5  0.00611030  0.00876190
> 6 -0.00990661  0.00635349
>
> I am plotting it with:
>
> library(dplyr)
> library(magrittr)
> library(corrplot)
> d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
> res <- cor(d, use = "complete.obs")
> pdf("correlation.pdf")
> corrplot(res, type = "upper", order = "hclust",
>          tl.col = "black", tl.srt = 45)
> dev.off()
>
> and I am getting the plot in attach. How to make it so that my
> variables are shown on the plot in the order they are in my_data data
> frame?
>
> Thanks
> Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: correlation.pdf
Type: application/pdf
Size: 11160 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20201106/529c5f8b/attachment.pdf>

From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Nov  6 17:43:03 2020
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 6 Nov 2020 11:43:03 -0500
Subject: [R] Bootstrap P-Value
Message-ID: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>

*Dear All:*

*I am trying to compute the p-value of the bootstrap test; please see
below.*

*In example 1 the p-value agrees with the confidence interval.*
*BUT, in example 2  the p-value DOES NOT agree with the confidence
interval. In Example 2, the p-value should be zero or close to zero.*

*I am not sure what went wrong, or not sure if I missed something.*

*any help would be appreciated.*


*with many thanks*
*abou*



#####  Two - Sample Bootstrap

#####  Source:
http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Chernick2011.pdf

#####  Example 1:
#####  ----------



set.seed(1)

n1 <- 29
n1
x1 <- rnorm(n1, 1.143, 0.164) #some random normal variates: mean1 = 1.143
x1

n2 <- 33
n2
x2 <- rnorm(n2, 1.175, 0.169) #2nd random sample: mean2 = 1.175
x2

obs.diff.theta <- mean(x1) - mean(x2)
obs.diff.theta

theta <- as.vector(NULL) #### vector to hold difference estimates

iterations <- 1000

for (i in 1:1000) {                        #bootstrap resamples
 xx1 <- sample(x1, n1, replace = TRUE)
 xx2 <- sample(x2, n2, replace = TRUE)
 theta[i] <- mean(xx1) - mean(xx2)
 }



##### Confidence Interval:
##### --------------------


quantile(theta, probs = c(.025,0.975)) #Efron percentile CI on difference
in means

##### 2.5% 97.5%
##### - 0.1248539 0.0137601


##### P-Value
##### -------

p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)

#####  p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)

p.value



#### R OUTPUT

#### > quantile(theta, probs = c(.025,0.975))
####        2.5%       97.5%
#### -0.12647744  0.02099391

#### > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
#### > p.value
#### [1] 1

#####  Example 2:
#####  ----------


set.seed(5)

n1 <- 29
### n1
x1 <- rnorm(n1, 10.5, 0.15) ######   sample 1 with mean1 = 10.5
### x1

n2 <- 33
### n2
x2 <- rnorm(n2, 1.5, 0.155) #####  Sample 2 with mean2 = 1.5
### x2

obs.diff.theta <- mean(x1) - mean(x2)
obs.diff.theta

theta <- as.vector(NULL) #### vector to hold difference estimates

iterations <- 1000

#####   bootstrap resamples

for (i in 1:1000) {
 xx1 <- sample(x1, n1, replace = TRUE)
 xx2 <- sample(x2, n2, replace = TRUE)
 theta[i] <- mean(xx1) - mean(xx2)
 }



##### Confidence Interval:
##### --------------------


######  CI on difference in means

quantile(theta, probs = c(.025,0.975))



##### P-Value
##### -------

p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)

##### p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)

p.value

##### R OUTPUT

####   > ######  CI on difference in means
####   >
####   > quantile(theta, probs = c(.025,0.975))
####       2.5%    97.5%
####   8.908398 9.060601

####   > ##### P-Value
####   > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)

####   > p.value
####   [1] 0.4835165

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Nov  6 18:24:07 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 6 Nov 2020 12:24:07 -0500
Subject: [R] [External] Re:  how to order variables on correlation plot
In-Reply-To: <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
 <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
Message-ID: <CAGx1TMCAkY+3xWoWDWE9SsyVYhXFqfAWj8D19YT0E_UfGhOazg@mail.gmail.com>

My guess is that the "%>% data.frame %>%" step turned something into a
character that you thought would be a factor.
See this example.  Remember that the stringsAFactors argument to
data.frame was recently changed.



> tmp <- data.frame(A=c("A","F","B","G","C"), B=1:5, CC=6:10)
> tmp
  A B CC
1 A 1  6
2 F 2  7
3 B 3  8
4 G 4  9
5 C 5 10
> sapply(tmp,class)
          A           B          CC
"character"   "integer"   "integer"
> tmp[order(tmp$A),]
  A B CC
1 A 1  6
3 B 3  8
5 C 5 10
2 F 2  7
4 G 4  9
> tmp$A <- factor(tmp$A, levels=unique(tmp$A))
> sapply(tmp,class)
        A         B        CC
 "factor" "integer" "integer"
> tmp[order(tmp$A),]
  A B CC
1 A 1  6
2 F 2  7
3 B 3  8
4 G 4  9
5 C 5 10
>

On Fri, Nov 6, 2020 at 9:18 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> sorry forgot to attach the plot.
>
> On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello
> >
> > I have data like this:
> >
> > > head(my_data)
> >       subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
> > 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
> > 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
> > 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
> > 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
> > 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
> > 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
> >             C3          C4          C5           C6           C7          C8
> > 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
> > 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
> > 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
> > 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
> > 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
> > 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
> >            C9         C10
> > 1  0.00328111 -0.00113515
> > 2 -0.00495790  0.00320201
> > 3  0.00208591 -0.00874752
> > 4 -0.00967934  0.00607760
> > 5  0.00611030  0.00876190
> > 6 -0.00990661  0.00635349
> >
> > I am plotting it with:
> >
> > library(dplyr)
> > library(magrittr)
> > library(corrplot)
> > d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
> > res <- cor(d, use = "complete.obs")
> > pdf("correlation.pdf")
> > corrplot(res, type = "upper", order = "hclust",
> >          tl.col = "black", tl.srt = 45)
> > dev.off()
> >
> > and I am getting the plot in attach. How to make it so that my
> > variables are shown on the plot in the order they are in my_data data
> > frame?
> >
> > Thanks
> > Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 @end|ng |rom gm@||@com  Fri Nov  6 18:34:48 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Fri, 6 Nov 2020 10:34:48 -0700
Subject: [R] Bootstrap P-Value
In-Reply-To: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>
References: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>
Message-ID: <CAFEqCdy7=XzjQhjOG80qXku4A-p8DFJzVsQ_p9MP5oCGs+5T7g@mail.gmail.com>

A p-value is for testing a specific null hypothesis, but you do not
state your null hypothesis anywhere.

It is the null value that needs to be subtracted from the bootstrap
differences, not the observed difference.  By subtracting the observed
difference you are setting a situation where the p-value will always
be about 0.5 or about 1 (depending on 1 tailed or 2 tailed).  If
instead you subtract a null value (such as 0), then the p-values will
be closer to what you are expecting.

On Fri, Nov 6, 2020 at 9:44 AM AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
>
> *Dear All:*
>
> *I am trying to compute the p-value of the bootstrap test; please see
> below.*
>
> *In example 1 the p-value agrees with the confidence interval.*
> *BUT, in example 2  the p-value DOES NOT agree with the confidence
> interval. In Example 2, the p-value should be zero or close to zero.*
>
> *I am not sure what went wrong, or not sure if I missed something.*
>
> *any help would be appreciated.*
>
>
> *with many thanks*
> *abou*
>
>
>
> #####  Two - Sample Bootstrap
>
> #####  Source:
> http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Chernick2011.pdf
>
> #####  Example 1:
> #####  ----------
>
>
>
> set.seed(1)
>
> n1 <- 29
> n1
> x1 <- rnorm(n1, 1.143, 0.164) #some random normal variates: mean1 = 1.143
> x1
>
> n2 <- 33
> n2
> x2 <- rnorm(n2, 1.175, 0.169) #2nd random sample: mean2 = 1.175
> x2
>
> obs.diff.theta <- mean(x1) - mean(x2)
> obs.diff.theta
>
> theta <- as.vector(NULL) #### vector to hold difference estimates
>
> iterations <- 1000
>
> for (i in 1:1000) {                        #bootstrap resamples
>  xx1 <- sample(x1, n1, replace = TRUE)
>  xx2 <- sample(x2, n2, replace = TRUE)
>  theta[i] <- mean(xx1) - mean(xx2)
>  }
>
>
>
> ##### Confidence Interval:
> ##### --------------------
>
>
> quantile(theta, probs = c(.025,0.975)) #Efron percentile CI on difference
> in means
>
> ##### 2.5% 97.5%
> ##### - 0.1248539 0.0137601
>
>
> ##### P-Value
> ##### -------
>
> p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
>
> #####  p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
>
> p.value
>
>
>
> #### R OUTPUT
>
> #### > quantile(theta, probs = c(.025,0.975))
> ####        2.5%       97.5%
> #### -0.12647744  0.02099391
>
> #### > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
> #### > p.value
> #### [1] 1
>
> #####  Example 2:
> #####  ----------
>
>
> set.seed(5)
>
> n1 <- 29
> ### n1
> x1 <- rnorm(n1, 10.5, 0.15) ######   sample 1 with mean1 = 10.5
> ### x1
>
> n2 <- 33
> ### n2
> x2 <- rnorm(n2, 1.5, 0.155) #####  Sample 2 with mean2 = 1.5
> ### x2
>
> obs.diff.theta <- mean(x1) - mean(x2)
> obs.diff.theta
>
> theta <- as.vector(NULL) #### vector to hold difference estimates
>
> iterations <- 1000
>
> #####   bootstrap resamples
>
> for (i in 1:1000) {
>  xx1 <- sample(x1, n1, replace = TRUE)
>  xx2 <- sample(x2, n2, replace = TRUE)
>  theta[i] <- mean(xx1) - mean(xx2)
>  }
>
>
>
> ##### Confidence Interval:
> ##### --------------------
>
>
> ######  CI on difference in means
>
> quantile(theta, probs = c(.025,0.975))
>
>
>
> ##### P-Value
> ##### -------
>
> p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
>
> ##### p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
>
> p.value
>
> ##### R OUTPUT
>
> ####   > ######  CI on difference in means
> ####   >
> ####   > quantile(theta, probs = c(.025,0.975))
> ####       2.5%    97.5%
> ####   8.908398 9.060601
>
> ####   > ##### P-Value
> ####   > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
>
> ####   > p.value
> ####   [1] 0.4835165
>
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Fri Nov  6 19:01:24 2020
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Fri, 6 Nov 2020 13:01:24 -0500
Subject: [R] Bootstrap P-Value
In-Reply-To: <CAFEqCdy7=XzjQhjOG80qXku4A-p8DFJzVsQ_p9MP5oCGs+5T7g@mail.gmail.com>
References: <CAE9stmeLzw7S4+4e+zjvSVCWG7306F8Eov9=cTm-QUKbYYQOAA@mail.gmail.com>
 <CAFEqCdy7=XzjQhjOG80qXku4A-p8DFJzVsQ_p9MP5oCGs+5T7g@mail.gmail.com>
Message-ID: <CAE9stmdeOVzuRZfq5Lcsvs-E0AcV=21kJJ1atavzPYkO8sPRUg@mail.gmail.com>

Dear Greg:

H0: Mean 1- Mean 2 = 0
Ha: Mean 1 - Mean 2 ! = 0

with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Fri, Nov 6, 2020 at 12:35 PM Greg Snow <538280 at gmail.com> wrote:

> A p-value is for testing a specific null hypothesis, but you do not
> state your null hypothesis anywhere.
>
> It is the null value that needs to be subtracted from the bootstrap
> differences, not the observed difference.  By subtracting the observed
> difference you are setting a situation where the p-value will always
> be about 0.5 or about 1 (depending on 1 tailed or 2 tailed).  If
> instead you subtract a null value (such as 0), then the p-values will
> be closer to what you are expecting.
>
> On Fri, Nov 6, 2020 at 9:44 AM AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> >
> > *Dear All:*
> >
> > *I am trying to compute the p-value of the bootstrap test; please see
> > below.*
> >
> > *In example 1 the p-value agrees with the confidence interval.*
> > *BUT, in example 2  the p-value DOES NOT agree with the confidence
> > interval. In Example 2, the p-value should be zero or close to zero.*
> >
> > *I am not sure what went wrong, or not sure if I missed something.*
> >
> > *any help would be appreciated.*
> >
> >
> > *with many thanks*
> > *abou*
> >
> >
> >
> > #####  Two - Sample Bootstrap
> >
> > #####  Source:
> > http://www.ievbras.ru/ecostat/Kiril/R/Biblio_N/R_Eng/Chernick2011.pdf
> >
> > #####  Example 1:
> > #####  ----------
> >
> >
> >
> > set.seed(1)
> >
> > n1 <- 29
> > n1
> > x1 <- rnorm(n1, 1.143, 0.164) #some random normal variates: mean1 = 1.143
> > x1
> >
> > n2 <- 33
> > n2
> > x2 <- rnorm(n2, 1.175, 0.169) #2nd random sample: mean2 = 1.175
> > x2
> >
> > obs.diff.theta <- mean(x1) - mean(x2)
> > obs.diff.theta
> >
> > theta <- as.vector(NULL) #### vector to hold difference estimates
> >
> > iterations <- 1000
> >
> > for (i in 1:1000) {                        #bootstrap resamples
> >  xx1 <- sample(x1, n1, replace = TRUE)
> >  xx2 <- sample(x2, n2, replace = TRUE)
> >  theta[i] <- mean(xx1) - mean(xx2)
> >  }
> >
> >
> >
> > ##### Confidence Interval:
> > ##### --------------------
> >
> >
> > quantile(theta, probs = c(.025,0.975)) #Efron percentile CI on difference
> > in means
> >
> > ##### 2.5% 97.5%
> > ##### - 0.1248539 0.0137601
> >
> >
> > ##### P-Value
> > ##### -------
> >
> > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > #####  p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > p.value
> >
> >
> >
> > #### R OUTPUT
> >
> > #### > quantile(theta, probs = c(.025,0.975))
> > ####        2.5%       97.5%
> > #### -0.12647744  0.02099391
> >
> > #### > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/
> (iterations+1)
> > #### > p.value
> > #### [1] 1
> >
> > #####  Example 2:
> > #####  ----------
> >
> >
> > set.seed(5)
> >
> > n1 <- 29
> > ### n1
> > x1 <- rnorm(n1, 10.5, 0.15) ######   sample 1 with mean1 = 10.5
> > ### x1
> >
> > n2 <- 33
> > ### n2
> > x2 <- rnorm(n2, 1.5, 0.155) #####  Sample 2 with mean2 = 1.5
> > ### x2
> >
> > obs.diff.theta <- mean(x1) - mean(x2)
> > obs.diff.theta
> >
> > theta <- as.vector(NULL) #### vector to hold difference estimates
> >
> > iterations <- 1000
> >
> > #####   bootstrap resamples
> >
> > for (i in 1:1000) {
> >  xx1 <- sample(x1, n1, replace = TRUE)
> >  xx2 <- sample(x2, n2, replace = TRUE)
> >  theta[i] <- mean(xx1) - mean(xx2)
> >  }
> >
> >
> >
> > ##### Confidence Interval:
> > ##### --------------------
> >
> >
> > ######  CI on difference in means
> >
> > quantile(theta, probs = c(.025,0.975))
> >
> >
> >
> > ##### P-Value
> > ##### -------
> >
> > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > ##### p.value <- (sum (theta >= obs.diff.theta) + 1)/ (iterations+1)
> >
> > p.value
> >
> > ##### R OUTPUT
> >
> > ####   > ######  CI on difference in means
> > ####   >
> > ####   > quantile(theta, probs = c(.025,0.975))
> > ####       2.5%    97.5%
> > ####   8.908398 9.060601
> >
> > ####   > ##### P-Value
> > ####   > p.value <- (sum (abs(theta) >= obs.diff.theta) + 1)/
> (iterations+1)
> >
> > ####   > p.value
> > ####   [1] 0.4835165
> >
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From @@kth|pr|y@m@th@v@r@j @end|ng |rom gm@||@com  Fri Nov  6 15:12:27 2020
From: @@kth|pr|y@m@th@v@r@j @end|ng |rom gm@||@com (Sakthipriya M)
Date: Fri, 6 Nov 2020 19:42:27 +0530
Subject: [R] Error in is biallelic
Message-ID: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>

Hi,
am trying to run the following using my SNP data vcf file
maizelight <- vcfR2genlight(maizevcf,n.cores=1)
Why am getting error
Error in is.biallelic(x) :
  trying to get slot "fix" from an object (class "spec_tbl_df") that is not
an S4 object

anybody help to solve this, am just trying comments of R newly.

From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Nov  6 20:45:19 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 6 Nov 2020 11:45:19 -0800
Subject: [R] how to order variables on correlation plot
In-Reply-To: <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
 <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
Message-ID: <50e643ab-c594-56f8-7d56-0a0a9fda6a4f@comcast.net>

Why did you specify a different order parameter if that is not what you 
wanted?

Suggest you look more carefully at the parameters of the code you are 
copying and pasting and also at the help page, ?corrplot .

-- 

David.

On 11/6/20 6:08 AM, Ana Marija wrote:
> sorry forgot to attach the plot.
>
> On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> Hello
>>
>> I have data like this:
>>
>>> head(my_data)
>>        subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
>> 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
>> 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
>> 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
>> 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
>> 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
>> 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
>>              C3          C4          C5           C6           C7          C8
>> 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
>> 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
>> 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
>> 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
>> 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
>> 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
>>             C9         C10
>> 1  0.00328111 -0.00113515
>> 2 -0.00495790  0.00320201
>> 3  0.00208591 -0.00874752
>> 4 -0.00967934  0.00607760
>> 5  0.00611030  0.00876190
>> 6 -0.00990661  0.00635349
>>
>> I am plotting it with:
>>
>> library(dplyr)
>> library(magrittr)
>> library(corrplot)
>> d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
>> res <- cor(d, use = "complete.obs")
>> pdf("correlation.pdf")
>> corrplot(res, type = "upper", order = "hclust",
>>           tl.col = "black", tl.srt = 45)
>> dev.off()
>>
>> and I am getting the plot in attach. How to make it so that my
>> variables are shown on the plot in the order they are in my_data data
>> frame?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Nov  6 21:14:35 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 6 Nov 2020 14:14:35 -0600
Subject: [R] how to order variables on correlation plot
In-Reply-To: <50e643ab-c594-56f8-7d56-0a0a9fda6a4f@comcast.net>
References: <CAF9-5jO0Txpo5q=udWOM1hD-dLmHiLkh_tSFzvp9ztBwY+X4uA@mail.gmail.com>
 <CAF9-5jOA7tN1F2ng7SU1C+8N68cE_sgSGVmBOibqLH0tm5KQWQ@mail.gmail.com>
 <50e643ab-c594-56f8-7d56-0a0a9fda6a4f@comcast.net>
Message-ID: <CAF9-5jOphsHM0MkX7S2DtnWVG=v1AH7GkUUboPLUkcAA5f55yQ@mail.gmail.com>

Thank you!

On Fri, Nov 6, 2020 at 1:45 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
> Why did you specify a different order parameter if that is not what you wanted?
>
> Suggest you look more carefully at the parameters of the code you are copying and pasting and also at the help page, ?corrplot .
>
> --
>
> David.
>
> On 11/6/20 6:08 AM, Ana Marija wrote:
>
> sorry forgot to attach the plot.
>
> On Fri, Nov 6, 2020 at 8:07 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello
>
> I have data like this:
>
> head(my_data)
>
>       subjects DIABDUR HBA1C ESRD SEX AGE PHENO          C1           C2
> 1 fam0110_G110      38   9.4    1   2  51     2 -0.01144980  0.002661140
> 2 fam0113_G113      30  12.5    1   2  40     2 -0.00502052 -0.000929061
> 3 fam0114_G114      23   8.4    2   2  45     2 -0.00251578 -0.003450950
> 4 fam0117_G117      37   9.0    2   2  46     2 -0.00704917 -0.000573325
> 5 fam0119_G119      22   9.4    1   1  46     1  0.00263433  0.001002370
> 6 fam0119_G120      NA    NA    1   1  71     1 -0.00354795 -0.002045940
>             C3          C4          C5           C6           C7          C8
> 1  0.006028150 -0.00176795 -0.00148375  0.004543550 -0.006272170 -0.00535077
> 2 -0.000453402 -0.00192162  0.00416229  0.007868230 -0.001957670 -0.00473148
> 3 -0.001680860 -0.00620438 -0.00235092  0.000672831 -0.000278318  0.00647337
> 4  0.001436740  0.00155568 -0.00556147 -0.000386401 -0.006885350  0.00135539
> 5 -0.007396920  0.00326229  0.00355575 -0.011149400  0.009156510  0.00120833
> 6  0.004532050  0.00869862 -0.00113207  0.002244520 -0.002119220  0.00657587
>            C9         C10
> 1  0.00328111 -0.00113515
> 2 -0.00495790  0.00320201
> 3  0.00208591 -0.00874752
> 4 -0.00967934  0.00607760
> 5  0.00611030  0.00876190
> 6 -0.00990661  0.00635349
>
> I am plotting it with:
>
> library(dplyr)
> library(magrittr)
> library(corrplot)
> d=my_data %>% data.frame %>% set_rownames(.$subjects) %>% select(-subjects)
> res <- cor(d, use = "complete.obs")
> pdf("correlation.pdf")
> corrplot(res, type = "upper", order = "hclust",
>          tl.col = "black", tl.srt = 45)
> dev.off()
>
> and I am getting the plot in attach. How to make it so that my
> variables are shown on the plot in the order they are in my_data data
> frame?
>
> Thanks
> Ana
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkr|de@u @end|ng |rom gm@||@com  Sat Nov  7 01:11:37 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 6 Nov 2020 19:11:37 -0500
Subject: [R] Error in is biallelic
In-Reply-To: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
References: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
Message-ID: <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>

I think we need a lot mole information.

see these links for suggestions on how to ask a question.

 http://adv-r.had.co.nz/Reproducibility.html

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


On Fri, 6 Nov 2020 at 14:37, Sakthipriya M <sakthipriyamathavaraj at gmail.com>
wrote:

> Hi,
> am trying to run the following using my SNP data vcf file
> maizelight <- vcfR2genlight(maizevcf,n.cores=1)
> Why am getting error
> Error in is.biallelic(x) :
>   trying to get slot "fix" from an object (class "spec_tbl_df") that is not
> an S4 object
>
> anybody help to solve this, am just trying comments of R newly.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sat Nov  7 02:24:24 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 6 Nov 2020 17:24:24 -0800
Subject: [R] Error in is biallelic
In-Reply-To: <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>
References: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
 <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>
Message-ID: <d9ecc859-1170-2304-24c4-1a25ced4e6d3@comcast.net>


On 11/6/20 4:11 PM, John Kane wrote:
> I think we need a lot mole information.
>
> see these links for suggestions on how to ask a question.
>
>   http://adv-r.had.co.nz/Reproducibility.html
>
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

I agree that more information would be needed for a considered answer 
but I also suspect that placement of the question in a venue that had a 
larger population of persons knowledgeable about the domain of genomics 
might be helpful as well. Two possibilities: The BioConductor mailing 
list and the BioInformatics StackExchange forum.

-- 

David

>
>
> On Fri, 6 Nov 2020 at 14:37, Sakthipriya M <sakthipriyamathavaraj at gmail.com>
> wrote:
>
>> Hi,
>> am trying to run the following using my SNP data vcf file
>> maizelight <- vcfR2genlight(maizevcf,n.cores=1)
>> Why am getting error
>> Error in is.biallelic(x) :
>>    trying to get slot "fix" from an object (class "spec_tbl_df") that is not
>> an S4 object
>>
>> anybody help to solve this, am just trying comments of R newly.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From jrkr|de@u @end|ng |rom gm@||@com  Sat Nov  7 03:36:48 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 6 Nov 2020 21:36:48 -0500
Subject: [R] Error in is biallelic
In-Reply-To: <d9ecc859-1170-2304-24c4-1a25ced4e6d3@comcast.net>
References: <CAGYBqHxRdX99N=3zuJaic26h_=-muO0=Ue8px9Dsr+QgVnhiTA@mail.gmail.com>
 <CAKZQJMB_TZnpbdhYQXKYxZxHNiWH5j7cNMhR_s-aOO1xPdZ1NA@mail.gmail.com>
 <d9ecc859-1170-2304-24c4-1a25ced4e6d3@comcast.net>
Message-ID: <CAKZQJMBscxAG3oYXO9bMLcJw-SMpdBpe5daw_T8hNQhLYzv24A@mail.gmail.com>

Ah, good point.

On Fri, 6 Nov 2020 at 20:24, David Winsemius <dwinsemius at comcast.net> wrote:

>
> On 11/6/20 4:11 PM, John Kane wrote:
> > I think we need a lot mole information.
> >
> > see these links for suggestions on how to ask a question.
> >
> >   http://adv-r.had.co.nz/Reproducibility.html
> >
> >
> http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> I agree that more information would be needed for a considered answer
> but I also suspect that placement of the question in a venue that had a
> larger population of persons knowledgeable about the domain of genomics
> might be helpful as well. Two possibilities: The BioConductor mailing
> list and the BioInformatics StackExchange forum.
>
> --
>
> David
>
> >
> >
> > On Fri, 6 Nov 2020 at 14:37, Sakthipriya M <
> sakthipriyamathavaraj at gmail.com>
> > wrote:
> >
> >> Hi,
> >> am trying to run the following using my SNP data vcf file
> >> maizelight <- vcfR2genlight(maizevcf,n.cores=1)
> >> Why am getting error
> >> Error in is.biallelic(x) :
> >>    trying to get slot "fix" from an object (class "spec_tbl_df") that
> is not
> >> an S4 object
> >>
> >> anybody help to solve this, am just trying comments of R newly.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From r|tm84 @end|ng |rom gm@||@com  Sat Nov  7 11:42:58 2020
From: r|tm84 @end|ng |rom gm@||@com (Ritwik Mohapatra)
Date: Sat, 7 Nov 2020 16:12:58 +0530
Subject: [R] Data Table not rendering properly using R shiny
Message-ID: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>

Hi All,

I have a data output as below.I want to display them in an interactive html
report using shiny but the data table is not rendering properly and instead
giving NA values.

max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))

Region Sum_as_Hours
1 Africa 1156.0833
2 Americas 740.1667
3 APAC 740.2833
4 Europe 1895.2000
5 PDO 1053.3500
6 UK 0.0000


Rshiny code:

library(shiny)

ui <- fluidPage(
selectInput("Region","Select
Region",max_usage_hours_per_region$Region,selected = TRUE),
tableOutput("table")
)
server <- function(input, output) {
output$table <- renderTable(
max_usage_hours_per_region[input$Region,])
}
shinyApp(ui = ui, server = server)

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Nov  7 16:22:26 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Nov 2020 07:22:26 -0800
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
References: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
Message-ID: <CAGxFJbQEVtpTMOAQVuGjHbxPJXs7-8CXjLockHJVb0x+tRANpA@mail.gmail.com>

Better to post on  RStudio support, I think. Shiny is an RStudio package
and product and this list if for R language/programming help. The two are
separate.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Nov 7, 2020 at 2:43 AM Ritwik Mohapatra <ritm84 at gmail.com> wrote:

> Hi All,
>
> I have a data output as below.I want to display them in an interactive html
> report using shiny but the data table is not rendering properly and instead
> giving NA values.
>
>
> max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>
> Region Sum_as_Hours
> 1 Africa 1156.0833
> 2 Americas 740.1667
> 3 APAC 740.2833
> 4 Europe 1895.2000
> 5 PDO 1053.3500
> 6 UK 0.0000
>
>
> Rshiny code:
>
> library(shiny)
>
> ui <- fluidPage(
> selectInput("Region","Select
> Region",max_usage_hours_per_region$Region,selected = TRUE),
> tableOutput("table")
> )
> server <- function(input, output) {
> output$table <- renderTable(
> max_usage_hours_per_region[input$Region,])
> }
> shinyApp(ui = ui, server = server)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Nov  7 16:37:09 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Sat, 7 Nov 2020 10:37:09 -0500
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CAGxFJbQEVtpTMOAQVuGjHbxPJXs7-8CXjLockHJVb0x+tRANpA@mail.gmail.com>
References: <CAGxFJbQEVtpTMOAQVuGjHbxPJXs7-8CXjLockHJVb0x+tRANpA@mail.gmail.com>
Message-ID: <795248E9-E917-481E-B5EF-025FB5705ADA@me.com>

Hi,

Please drop R-Devel as a cc: from this thread for further replies.

This topic is definitely not relevant there and cross-posting is not needed, but does require manual moderation.

Thanks,

Marc Schwartz

> On Nov 7, 2020, at 10:23 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?Better to post on  RStudio support, I think. Shiny is an RStudio package
> and product and this list if for R language/programming help. The two are
> separate.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>> On Sat, Nov 7, 2020 at 2:43 AM Ritwik Mohapatra <ritm84 at gmail.com> wrote:
>> 
>> Hi All,
>> 
>> I have a data output as below.I want to display them in an interactive html
>> report using shiny but the data table is not rendering properly and instead
>> giving NA values.
>> 
>> 
>> max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>> 
>> Region Sum_as_Hours
>> 1 Africa 1156.0833
>> 2 Americas 740.1667
>> 3 APAC 740.2833
>> 4 Europe 1895.2000
>> 5 PDO 1053.3500
>> 6 UK 0.0000
>> 
>> 
>> Rshiny code:
>> 
>> library(shiny)
>> 
>> ui <- fluidPage(
>> selectInput("Region","Select
>> Region",max_usage_hours_per_region$Region,selected = TRUE),
>> tableOutput("table")
>> )
>> server <- function(input, output) {
>> output$table <- renderTable(
>> max_usage_hours_per_region[input$Region,])
>> }
>> shinyApp(ui = ui, server = server)
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Nov  7 16:41:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 07 Nov 2020 07:41:32 -0800
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
References: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
Message-ID: <CCD71CB9-FF37-4621-AB4F-74C8720350B3@dcn.davis.ca.us>

This looks odd...

max_usage_hours_per_region[input$Region,]

This would only work if you had rownames on that data frame corresponding to the names of the Regions. This is a common R mistake... you probably need

logical_idx <- max_usage_hours_per_region$Region == input$Region
max_usage_hours_per_region[  logical_idx,]

That said, it is very difficult to separate out R questions when mixed into shiny code, so you would help yourself and this list to work on minimal reproducible examples that focus on the R syntax if possible for posts here. Read the Posting Guide.

On November 7, 2020 2:42:58 AM PST, Ritwik Mohapatra <ritm84 at gmail.com> wrote:
>Hi All,
>
>I have a data output as below.I want to display them in an interactive
>html
>report using shiny but the data table is not rendering properly and
>instead
>giving NA values.
>
>max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>
>Region Sum_as_Hours
>1 Africa 1156.0833
>2 Americas 740.1667
>3 APAC 740.2833
>4 Europe 1895.2000
>5 PDO 1053.3500
>6 UK 0.0000
>
>
>Rshiny code:
>
>library(shiny)
>
>ui <- fluidPage(
>selectInput("Region","Select
>Region",max_usage_hours_per_region$Region,selected = TRUE),
>tableOutput("table")
>)
>server <- function(input, output) {
>output$table <- renderTable(
>max_usage_hours_per_region[input$Region,])
>}
>shinyApp(ui = ui, server = server)
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Nov  7 16:57:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 7 Nov 2020 15:57:44 +0000
Subject: [R] Data Table not rendering properly using R shiny
In-Reply-To: <CCD71CB9-FF37-4621-AB4F-74C8720350B3@dcn.davis.ca.us>
References: <CAGY2U92qYgz1bNR4qRufB1AebgK4SiRRhXF6Wgk_haZowHR9aw@mail.gmail.com>
 <CCD71CB9-FF37-4621-AB4F-74C8720350B3@dcn.davis.ca.us>
Message-ID: <b5a292d0-b467-05ab-f00f-4273448e1dc7@sapo.pt>

Hello,

Or maybe


logical_idx <- max_usage_hours_per_region$Region %in% input$Region


Another option is ?match


Hope this helps,

Rui Barradas


?s 15:41 de 07/11/20, Jeff Newmiller escreveu:
> This looks odd...
> 
> max_usage_hours_per_region[input$Region,]
> 
> This would only work if you had rownames on that data frame corresponding to the names of the Regions. This is a common R mistake... you probably need
> 
> logical_idx <- max_usage_hours_per_region$Region == input$Region
> max_usage_hours_per_region[  logical_idx,]
> 
> That said, it is very difficult to separate out R questions when mixed into shiny code, so you would help yourself and this list to work on minimal reproducible examples that focus on the R syntax if possible for posts here. Read the Posting Guide.
> 
> On November 7, 2020 2:42:58 AM PST, Ritwik Mohapatra <ritm84 at gmail.com> wrote:
>> Hi All,
>>
>> I have a data output as below.I want to display them in an interactive
>> html
>> report using shiny but the data table is not rendering properly and
>> instead
>> giving NA values.
>>
>> max_usage_hours_per_region<-setNames(aggregate(df3_machine_region$sum_as_hours~df3_machine_region$Region,df3_machine_region,max),c("Region","Sum_as_Hours"))
>>
>> Region Sum_as_Hours
>> 1 Africa 1156.0833
>> 2 Americas 740.1667
>> 3 APAC 740.2833
>> 4 Europe 1895.2000
>> 5 PDO 1053.3500
>> 6 UK 0.0000
>>
>>
>> Rshiny code:
>>
>> library(shiny)
>>
>> ui <- fluidPage(
>> selectInput("Region","Select
>> Region",max_usage_hours_per_region$Region,selected = TRUE),
>> tableOutput("table")
>> )
>> server <- function(input, output) {
>> output$table <- renderTable(
>> max_usage_hours_per_region[input$Region,])
>> }
>> shinyApp(ui = ui, server = server)
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From @purd|e@@ @end|ng |rom gm@||@com  Sun Nov  8 06:39:14 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sun, 8 Nov 2020 18:39:14 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
Message-ID: <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>

> What can you tell me about plans to analyze data from this year's
> general election, especially to detect possible fraud?

I was wondering if there's any R packages with out-of-the-box
functions for this sort of thing.
Can you please let us know, if you find any.

> I might be able to help with such an effort.  I have NOT done
> much with election data, but I have developed tools for data analysis,
> including web scraping, and included them in R packages available on the
> Comprehensive R Archive Network (CRAN) and GitHub.[1]

Do you have a URL for detailed election results?
Or even better, a nice R-friendly CSV file...

I recognize that the results aren't complete.
And that such a file may need to be updated later.
But that doesn't necessarily prevent modelling now.


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sun Nov  8 09:24:52 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sun, 8 Nov 2020 02:24:52 -0600
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
Message-ID: <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>



On 2020-11-07 23:39, Abby Spurdle wrote:
>> What can you tell me about plans to analyze data from this year's
>> general election, especially to detect possible fraud?
> 
> I was wondering if there's any R packages with out-of-the-box
> functions for this sort of thing.
> Can you please let us know, if you find any.
> 
>> I might be able to help with such an effort.  I have NOT done
>> much with election data, but I have developed tools for data analysis,
>> including web scraping, and included them in R packages available on the
>> Comprehensive R Archive Network (CRAN) and GitHub.[1]
> 
> Do you have a URL for detailed election results?
> Or even better, a nice R-friendly CSV file...
> 
> I recognize that the results aren't complete.
> And that such a file may need to be updated later.
> But that doesn't necessarily prevent modelling now.


	  I asked, because I don't know of any such.  With the increasingly 
vicious, widespread and systematic attacks on the integrity of elections 
in the US, I think it would be good to have a central database of 
election results with tools regularly scraping websites of local and 
state election authorities.  Whenever new data were posted, the software 
would update the central repository and send emails to anyone 
interested.  That could simplify data acquisition, because historical 
data could already be available there.  And it would be one standard 
format for the entire US and maybe the world.


	  This could be extremely valuable in exposing electoral fraud, thereby 
reducing its magnitude and effectiveness.  This is a global problem, but 
it seems to have gotten dramatically worse in the US in recent years.[2]


	  I'd like to join -- or organize -- a team of people working on this. 
If we can create the database and data analysis tools in a package like 
Ecfun on CRAN, I think we can interest college profs, especially those 
teaching statistics to political science students, who would love to 
involve their students in something like this.  They could access data 
real time in classes, analyze it using standard tools that we could 
develop, and involve their students in discussing what it means and what 
it doesn't.  They could discuss Bayesian sequential updating and quality 
control concepts using data that are real and relevant to the lives of 
their students.  It could help get students excited about both 
statistics and elections.


	  Such a project may already exist.  I know there are projects at some 
major universities that sound like they might support this.  However 
with the limited time I've invested in this so far, I didn't find any 
that seemed to provide easy access to such data and an easy way to join 
such a project.  Ballotpedia has such data but don't want help in 
analyzing it and asked for a few hundred dollars for data for one 
election cycle in Missouri, which is what I requested.  I can get that 
for free from the web site of the Missouri Secretary of State.


	  I thought I might next ask the Carter Center about this.  However, 
but I'm totally consumed with other priorities right now.  I don't plan 
to do anything on this in the short term -- unless I can find 
collaborators.


	  If such a central database doesn't exist -- and maybe even if it does 
-- I thought it might be good to make all the data available in a 
standard format in Wikidata, which is a project of the Wikimedia 
Foundation, which is also the parent organization of Wikipedia.  Then I 
could help create software and documentation on how to scrape data from 
the web sites of different election organizations that have it and 
automatically update Wikidata while also sending emails to people who 
express interest in those election results.  Then we could create 
software for analyzing such data and make that available, e.g., on 
Wikiversity, which is another project of the Wikimedia Foundation -- 
with the R code in Ecfun or some other CRAN package.


	  If we start now, I think we could have something mediocre in time for 
various local elections that occur next year with improvements for the 
2022 US Congressional elections and something even better for the 2024 
US presidential elections.


	  Thanks for asking.
	  Spencer Graves


[1]
https://github.com/sbgraves237


[2]
https://en.wikiversity.org/wiki/Electoral_integrity_in_the_United_States


From bgunter@4567 @end|ng |rom gm@||@com  Sun Nov  8 16:32:50 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 8 Nov 2020 07:32:50 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
Message-ID: <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>

Unless I misunderstand, clearly such a repository already exists -- the NY
Times, AP, CNN, etc. etc. already have interactive web pages that did
this!. It doesn't seem to make any difference to Trump conspiracy theorists
and partisans, though.

Also, as usual, a web search (on "central repository of US election
results") brought up what seemed like many relevant hits of historical
data. You may wish to contact one of these sources for further ino.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Nov 8, 2020 at 12:25 AM Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

>
>
> On 2020-11-07 23:39, Abby Spurdle wrote:
> >> What can you tell me about plans to analyze data from this year's
> >> general election, especially to detect possible fraud?
> >
> > I was wondering if there's any R packages with out-of-the-box
> > functions for this sort of thing.
> > Can you please let us know, if you find any.
> >
> >> I might be able to help with such an effort.  I have NOT done
> >> much with election data, but I have developed tools for data analysis,
> >> including web scraping, and included them in R packages available on the
> >> Comprehensive R Archive Network (CRAN) and GitHub.[1]
> >
> > Do you have a URL for detailed election results?
> > Or even better, a nice R-friendly CSV file...
> >
> > I recognize that the results aren't complete.
> > And that such a file may need to be updated later.
> > But that doesn't necessarily prevent modelling now.
>
>
>           I asked, because I don't know of any such.  With the
> increasingly
> vicious, widespread and systematic attacks on the integrity of elections
> in the US, I think it would be good to have a central database of
> election results with tools regularly scraping websites of local and
> state election authorities.  Whenever new data were posted, the software
> would update the central repository and send emails to anyone
> interested.  That could simplify data acquisition, because historical
> data could already be available there.  And it would be one standard
> format for the entire US and maybe the world.
>
>
>           This could be extremely valuable in exposing electoral fraud,
> thereby
> reducing its magnitude and effectiveness.  This is a global problem, but
> it seems to have gotten dramatically worse in the US in recent years.[2]
>
>
>           I'd like to join -- or organize -- a team of people working on
> this.
> If we can create the database and data analysis tools in a package like
> Ecfun on CRAN, I think we can interest college profs, especially those
> teaching statistics to political science students, who would love to
> involve their students in something like this.  They could access data
> real time in classes, analyze it using standard tools that we could
> develop, and involve their students in discussing what it means and what
> it doesn't.  They could discuss Bayesian sequential updating and quality
> control concepts using data that are real and relevant to the lives of
> their students.  It could help get students excited about both
> statistics and elections.
>
>
>           Such a project may already exist.  I know there are projects at
> some
> major universities that sound like they might support this.  However
> with the limited time I've invested in this so far, I didn't find any
> that seemed to provide easy access to such data and an easy way to join
> such a project.  Ballotpedia has such data but don't want help in
> analyzing it and asked for a few hundred dollars for data for one
> election cycle in Missouri, which is what I requested.  I can get that
> for free from the web site of the Missouri Secretary of State.
>
>
>           I thought I might next ask the Carter Center about this.
> However,
> but I'm totally consumed with other priorities right now.  I don't plan
> to do anything on this in the short term -- unless I can find
> collaborators.
>
>
>           If such a central database doesn't exist -- and maybe even if it
> does
> -- I thought it might be good to make all the data available in a
> standard format in Wikidata, which is a project of the Wikimedia
> Foundation, which is also the parent organization of Wikipedia.  Then I
> could help create software and documentation on how to scrape data from
> the web sites of different election organizations that have it and
> automatically update Wikidata while also sending emails to people who
> express interest in those election results.  Then we could create
> software for analyzing such data and make that available, e.g., on
> Wikiversity, which is another project of the Wikimedia Foundation --
> with the R code in Ecfun or some other CRAN package.
>
>
>           If we start now, I think we could have something mediocre in
> time for
> various local elections that occur next year with improvements for the
> 2022 US Congressional elections and something even better for the 2024
> US presidential elections.
>
>
>           Thanks for asking.
>           Spencer Graves
>
>
> [1]
> https://github.com/sbgraves237
>
>
> [2]
> https://en.wikiversity.org/wiki/Electoral_integrity_in_the_United_States
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Mon Nov  9 05:09:05 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 9 Nov 2020 17:09:05 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
Message-ID: <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>

> such a repository already exists -- the NY Times, AP, CNN, etc. etc. already have interactive web pages that did this

I've been looking for presidential election results, by ***county***.
I've found historic results, including results for 2016.

However, I can't find such a dataset, for 2020.
(Even though this seems like an obvious thing to publish).

I suspect that the NY Times has the data, but I haven't been able to
work where the data is on their website, or how to access it.

More ***specific*** suggestions would be appreciated...?


From bgunter@4567 @end|ng |rom gm@||@com  Mon Nov  9 05:25:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 8 Nov 2020 20:25:33 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
Message-ID: <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>

NYT  had interactive maps that reported  votes by county. So try contacting
them.


Bert

On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> > such a repository already exists -- the NY Times, AP, CNN, etc. etc.
> already have interactive web pages that did this
>
> I've been looking for presidential election results, by ***county***.
> I've found historic results, including results for 2016.
>
> However, I can't find such a dataset, for 2020.
> (Even though this seems like an obvious thing to publish).
>
> I suspect that the NY Times has the data, but I haven't been able to
> work where the data is on their website, or how to access it.
>
> More ***specific*** suggestions would be appreciated...?
>

	[[alternative HTML version deleted]]


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Mon Nov  9 06:53:46 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Mon, 9 Nov 2020 00:53:46 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
 <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
Message-ID: <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>

You can try here: https://decisiondeskhq.com/

I think they have what you are looking for. From their website:

"Create a FREE account to access up to the minute election results and 
insights on all U.S. Federal elections. Decision Desk HQ & ?ptimus 
provide live election night coverage, race-specific results including 
county-level returns, and exclusive race probabilities for key 
battleground races."

 ?? Also, this article provides a little, emphasis on little, of 
statistical analysis of election results, but it may be a place to start.

https://www.theepochtimes.com/statistical-anomalies-in-biden-votes-analyses-indicate_3570518.html?utm_source=newsnoe&utm_medium=email&utm_campaign=breaking-2020-11-08-5

Matthew

On 11/8/20 11:25 PM, Bert Gunter wrote:
>          External Email - Use Caution
>
> NYT  had interactive maps that reported  votes by county. So try contacting
> them.
>
>
> Bert
>
> On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
>>> such a repository already exists -- the NY Times, AP, CNN, etc. etc.
>> already have interactive web pages that did this
>>
>> I've been looking for presidential election results, by ***county***.
>> I've found historic results, including results for 2016.
>>
>> However, I can't find such a dataset, for 2020.
>> (Even though this seems like an obvious thing to publish).
>>
>> I suspect that the NY Times has the data, but I haven't been able to
>> work where the data is on their website, or how to access it.
>>
>> More ***specific*** suggestions would be appreciated...?
>>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJBHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKIFHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gwR3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> PLEASE do read the posting guide http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQn1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2LAcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Nov  9 12:38:12 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 9 Nov 2020 11:38:12 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
Message-ID: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>

I was just surprised by very un-intuitive behaviour of paste(), which appears to collapse a one-column data frame or one-element list into a deparsed expression, rather than producing the expected string. Can someone kindly explain what's going on here?


reprex:
=======

list(s = c("xyz", "uvw"))
#     s
# 1 xyz
# 2 uvw

paste(list(s = c("xyz", "uvw")), collapse = "")
# [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!

I would have expected:
# [1] "xyzuvw"
 
... which I do get with e.g.
paste(list(s = c("xyz", "uvw"))$s, collapse = "")

But what logic is there in returning a deparsed expression?



Thanks!
Boris

From rub@k @end|ng |rom m@th@@@u@dk  Mon Nov  9 13:24:51 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Mon, 9 Nov 2020 12:24:51 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
In-Reply-To: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
References: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
Message-ID: <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>

I think `paste()` just calls `as.character()` on each input argument
and then collapses things afterwards. Calling `as.character()` on the
first input argument generates exactly the output you show (and didn't
expect) and there is nothing to collapse. So changing `collapse = ""`
to anything else doesn't change behaviour.

The question is reduced to how `as.character()` should handle a list as
input. It seems to me that this input is so generic that it is hard to
handle graciously without all kinds of special cases. So you expect the
length one list

as.character(list(s = c("xyz", "uvw"))

to return the length 2 character vector `c("xyz", "uvw")`? What should

as.character(list(s = c("xyz", "uvw"), t = c("a", "b", "c"))

return?

Kind regards,
Ege

On Mon, 2020-11-09 at 11:38 +0000, Boris Steipe wrote:
> I was just surprised by very un-intuitive behaviour of paste(), which
> appears to collapse a one-column data frame or one-element list into
> a deparsed expression, rather than producing the expected string. Can
> someone kindly explain what's going on here?
> 
> 
> reprex:
> =======
> 
> list(s = c("xyz", "uvw"))
> #     s
> # 1 xyz
> # 2 uvw
> 
> paste(list(s = c("xyz", "uvw")), collapse = "")
> # [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!
> 
> I would have expected:
> # [1] "xyzuvw"
>  
> ... which I do get with e.g.
> paste(list(s = c("xyz", "uvw"))$s, collapse = "")
> 
> But what logic is there in returning a deparsed expression?
> 
> 
> 
> Thanks!
> Boris
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Nov  9 13:58:22 2020
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 9 Nov 2020 12:58:22 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
In-Reply-To: <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>
References: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
 <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>
Message-ID: <D76CB58F-F845-4FDE-9FBF-C42C88E1A114@utoronto.ca>

Thanks Ege -

That narrows it down, ... but it's still weird.

My issue is that I don't consider "c(\"xyz\", \"uvw\")" to be a valid character representation of a list. c() is a function, so "c(\"xyz\", \"uvw\")" is a string representation of a function call that could be  eval(parse(...))'ed into a two-element vector ... but considering this a coercion seems really weird.

What do I think your example should return? An object of the same general structure as the input, with non-character components coerced to character. And if that's not possible because there is no good character representation (e.g. if its a closure) than it should return an error. 


Cheers,
Boris

 


> On 2020-11-09, at 22:24, Ege Rubak <rubak at math.aau.dk> wrote:
> 
> EXTERNAL EMAIL:  Treat content with extra caution.
> 
> I think `paste()` just calls `as.character()` on each input argument
> and then collapses things afterwards. Calling `as.character()` on the
> first input argument generates exactly the output you show (and didn't
> expect) and there is nothing to collapse. So changing `collapse = ""`
> to anything else doesn't change behaviour.
> 
> The question is reduced to how `as.character()` should handle a list as
> input. It seems to me that this input is so generic that it is hard to
> handle graciously without all kinds of special cases. So you expect the
> length one list
> 
> as.character(list(s = c("xyz", "uvw"))
> 
> to return the length 2 character vector `c("xyz", "uvw")`? What should
> 
> as.character(list(s = c("xyz", "uvw"), t = c("a", "b", "c"))
> 
> return?
> 
> Kind regards,
> Ege
> 
> On Mon, 2020-11-09 at 11:38 +0000, Boris Steipe wrote:
>> I was just surprised by very un-intuitive behaviour of paste(), which
>> appears to collapse a one-column data frame or one-element list into
>> a deparsed expression, rather than producing the expected string. Can
>> someone kindly explain what's going on here?
>> 
>> 
>> reprex:
>> =======
>> 
>> list(s = c("xyz", "uvw"))
>> #     s
>> # 1 xyz
>> # 2 uvw
>> 
>> paste(list(s = c("xyz", "uvw")), collapse = "")
>> # [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!
>> 
>> I would have expected:
>> # [1] "xyzuvw"
>> 
>> ... which I do get with e.g.
>> paste(list(s = c("xyz", "uvw"))$s, collapse = "")
>> 
>> But what logic is there in returning a deparsed expression?
>> 
>> 
>> 
>> Thanks!
>> Boris
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Mon Nov  9 14:06:08 2020
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Mon, 9 Nov 2020 14:06:08 +0100
Subject: [R] [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
Message-ID: <5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>

Dear list members,

I observe a strange/wrong graphical output when I set the xlevels
in (e. g.) allEffects for an lmer model and plot the effects with
multiline = TRUE. I have compiled a reprex for which you need the
lmer model and the environment in which the model was fitted. They
are contained in the zip file at
https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
After unpacking the following should work:

m <- readRDS("m.rds")   # The lmer-model.
G1 <- readRDS("G1.rds") # Environment in which the model
                          # was fitted; needed by alaEffects.
summary(m) # Just to see the model.

library(effects)
aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
                      # Non-default values for xlevels.

plot(aE)                      # Fine.
plot(aE, x.var = "Age")       # Fine.
plot(aE, lines = list(multiline = TRUE))  # Fine.

plot(aE, lines = list(multiline = TRUE),
       x.var = "Age")        # Nonsense.


Anybody any idea about the reason, my mistake, or a
workaround? Thx for any hint!

   Regards  --  Gerrit


PS:
  > sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] effects_4.2-0 carData_3.0-4

loaded via a namespace (and not attached):
   [1] Rcpp_1.0.5       lattice_0.20-41  MASS_7.3-53      grid_4.0.2 
DBI_1.1.0
   [6] nlme_3.1-149     survey_4.0       estimability_1.3 minqa_1.2.4 
nloptr_1.2.2.2
[11] Matrix_1.2-18    boot_1.3-25      splines_4.0.2    statmod_1.4.34 
lme4_1.1-23
[16] tools_4.0.2      survival_3.2-3   yaml_2.2.1       compiler_4.0.2 
colorspace_1.4-1
[21] mitools_2.4      insight_0.9.5    nnet_7.3-14

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner


From vgher@rd @end|ng |rom @|@@@@|t  Fri Nov  6 16:13:11 2020
From: vgher@rd @end|ng |rom @|@@@@|t (Valerio Gherardi)
Date: Fri, 6 Nov 2020 16:13:11 +0100
Subject: [R] [R-pkgs] sbo: N-gram Stupid Back-Off models in R
Message-ID: <40ef1bf6-d199-287f-4905-b3d532c7049f@sissa.it>

Dear all,

I would like to introduce
sbo: Utilities for building and evaluating text prediction functions 
based on Stupid Back-off N-gram models.

v0.3.0 is now on CRAN: 
https://cran.r-project.org/web/packages/sbo/index.html
website: https://vgherard.github.io/sbo/
For bugs/issues: https://github.com/vgherard/sbo

Feedback of any kind is welcome.

Sincerely,
Valerio Gherardi.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@|| @end|ng |rom @|ex@ndr@thorn@com  Mon Nov  9 15:23:17 2020
From: m@|| @end|ng |rom @|ex@ndr@thorn@com (Alexandra Thorn)
Date: Mon, 9 Nov 2020 09:23:17 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
 <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
 <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>
Message-ID: <20201109092317.1858ddd0@athorn-Lemur-Ultra>

This thread strikes me as pretty far off-topic for a forum dedicated to
software support on R.

https://www.r-project.org/mail.html#instructions
"The ?main? R mailing list, for discussion about problems and solutions
using R, announcements (not covered by ?R-announce? or ?R-packages?,
see above), about the availability of new functionality for R and
documentation of R, comparison and compatibility with S-plus, and for
the posting of nice examples and benchmarks. Do read the posting guide
before sending anything!"

https://www.r-project.org/posting-guide.html
"The R mailing lists are primarily intended for questions and
discussion about the R software. However, questions about statistical
methodology are sometimes posted. If the question is well-asked and of
interest to someone on the list, it may elicit an informative
up-to-date answer. See also the Usenet groups sci.stat.consult (applied
statistics and consulting) and sci.stat.math (mathematical stat and
probability)."

On Mon, 9 Nov 2020 00:53:46 -0500
Matthew McCormack <mccormack at molbio.mgh.harvard.edu> wrote:

> You can try here: https://decisiondeskhq.com/
> 
> I think they have what you are looking for. From their website:
> 
> "Create a FREE account to access up to the minute election results
> and insights on all U.S. Federal elections. Decision Desk HQ &
> ?ptimus provide live election night coverage, race-specific results
> including county-level returns, and exclusive race probabilities for
> key battleground races."
> 
>  ?? Also, this article provides a little, emphasis on little, of 
> statistical analysis of election results, but it may be a place to
> start.
> 
> https://www.theepochtimes.com/statistical-anomalies-in-biden-votes-analyses-indicate_3570518.html?utm_source=newsnoe&utm_medium=email&utm_campaign=breaking-2020-11-08-5
> 
> Matthew
> 
> On 11/8/20 11:25 PM, Bert Gunter wrote:
> >          External Email - Use Caution
> >
> > NYT  had interactive maps that reported  votes by county. So try
> > contacting them.
> >
> >
> > Bert
> >
> > On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com>
> > wrote: 
> >>> such a repository already exists -- the NY Times, AP, CNN, etc.
> >>> etc.  
> >> already have interactive web pages that did this
> >>
> >> I've been looking for presidential election results, by
> >> ***county***. I've found historic results, including results for
> >> 2016.
> >>
> >> However, I can't find such a dataset, for 2020.
> >> (Even though this seems like an obvious thing to publish).
> >>
> >> I suspect that the NY Times has the data, but I haven't been able
> >> to work where the data is on their website, or how to access it.
> >>
> >> More ***specific*** suggestions would be appreciated...?
> >>  
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJBHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKIFHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gwR3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> > PLEASE do read the posting guide
> > http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQn1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2LAcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> > and provide commented, minimal, self-contained, reproducible code. 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Mon Nov  9 18:13:43 2020
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew McCormack)
Date: Mon, 9 Nov 2020 12:13:43 -0500
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <20201109092317.1858ddd0@athorn-Lemur-Ultra>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepxt=QL3UHUdP4bx9ik5XtqubG7fD23_JHj_UjQDDSoTBA@mail.gmail.com>
 <9d0b0ac0-219f-ae28-59f5-eb0c2187fa9e@effectivedefense.org>
 <CAGxFJbR-7em9Hpx43ggwP6Mg+Nf_Oki5DyC=VK8a7WdApLXOWQ@mail.gmail.com>
 <CAB8pepyg5SoAey=2OrczQPAqg3uRhrSedbXRgYTcYubMxKFKFA@mail.gmail.com>
 <CAGxFJbSAO1dmtXPhsOomfQf3f9W2YwEQs+L7eAHL+q6MRGZqJA@mail.gmail.com>
 <ae88e502-8011-95b4-31eb-a5db33371aed@molbio.mgh.harvard.edu>
 <20201109092317.1858ddd0@athorn-Lemur-Ultra>
Message-ID: <1c02cba3-e295-fdd0-21e4-c530c0cdfcb3@molbio.mgh.harvard.edu>


    Benford Analysis for Data Validation and Forensic Analytics

Provides tools that make it easier to validate data using Benford's Law.

https://www.rdocumentation.org/packages/benford.analysis/versions/0.1.5


Matthew

On 11/9/20 9:23 AM, Alexandra Thorn wrote:
>          External Email - Use Caution
>
> This thread strikes me as pretty far off-topic for a forum dedicated to
> software support on R.
>
> https://secure-web.cisco.com/15MzwKoUQfDzeGBDx9gweXKgiYtAPv1UlnW2dg9CuDtSNWgxy3ffTf_uuPizbjoJnovoOD6lrPDluOgGvIUTEF1d_rOTfaF3nUKLvNiZa3fHZ_IHD-SjKotr4lurHjmNPlSrljLipPsrDk2aoo63-GLwvaw64By_MnLST7lt4FgA2pYXgE3x15Xn-kRZ85m29f0BxhHJMVfilvVUoUEBPrw/https%3A%2F%2Fwww.r-project.org%2Fmail.html%23instructions
> "The ?main? R mailing list, for discussion about problems and solutions
> using R, announcements (not covered by ?R-announce? or ?R-packages?,
> see above), about the availability of new functionality for R and
> documentation of R, comparison and compatibility with S-plus, and for
> the posting of nice examples and benchmarks. Do read the posting guide
> before sending anything!"
>
> https://secure-web.cisco.com/1V05G8mWSPHU-YvLbL-UQMy49XX7n7-EivE-gTOlh2nZ3P0oxp6DGUUZQ_Q5VIkE3J0qmhrrSXxJaqZjv-Tllghba8lQrbkazuAHTcltsfo3I-C-SMqhb-CDdFbeEgIsr7py_gKW9BqumTZacywhHVnzhGGR2s1A-2akqQLYSYpYeX5EcVJAYvX1KPCs9kJbOEveOr5yYjetokaZpLTzdMA/https%3A%2F%2Fwww.r-project.org%2Fposting-guide.html
> "The R mailing lists are primarily intended for questions and
> discussion about the R software. However, questions about statistical
> methodology are sometimes posted. If the question is well-asked and of
> interest to someone on the list, it may elicit an informative
> up-to-date answer. See also the Usenet groups sci.stat.consult (applied
> statistics and consulting) and sci.stat.math (mathematical stat and
> probability)."
>
> On Mon, 9 Nov 2020 00:53:46 -0500
> Matthew McCormack <mccormack at molbio.mgh.harvard.edu> wrote:
>
>> You can try here: https://secure-web.cisco.com/17WRivozTB0Frts23cTlTBd3SYWzVXQsLa_jDRN8SldAl35F0SYXRMZczzIXrQFTzbfRV4YfPOVhMSwopcdTU9Sva396s3bX3-KM7-51KjSnY0aXxlADYaHdvs4y4YXrUfk1GT2801rVL26MCEEn2E1azdQ8ECllu1roS_Z8MIj8d6kyCtUYVdOYN1i9DuWBSXPlEi-iOtrQsBp6ELRXNFw/https%3A%2F%2Fdecisiondeskhq.com%2F
>>
>> I think they have what you are looking for. From their website:
>>
>> "Create a FREE account to access up to the minute election results
>> and insights on all U.S. Federal elections. Decision Desk HQ &
>> ?ptimus provide live election night coverage, race-specific results
>> including county-level returns, and exclusive race probabilities for
>> key battleground races."
>>
>>   ?? Also, this article provides a little, emphasis on little, of
>> statistical analysis of election results, but it may be a place to
>> start.
>>
>> https://secure-web.cisco.com/1JA34S9tw27K78g7scwo2aGe4lPpV7HThBE81hhJjb4Ban7fxqbnOZqx7HxfcyqKrcB5BX7oJFHhMPumrxjm6aQJ0trW1Jgk0h9s2mNhZg4T_gTUls8y4l0KZ-AstUtw0eC0TtR9mHblU7KWid-7OO4mg0TfsxWyNpcqkA8MBuGftOEgUF7WtakShYgmCNYJkEfQJHK5_vjwK0taJeUheVw/https%3A%2F%2Fwww.theepochtimes.com%2Fstatistical-anomalies-in-biden-votes-analyses-indicate_3570518.html%3Futm_source%3Dnewsnoe%26utm_medium%3Demail%26utm_campaign%3Dbreaking-2020-11-08-5
>>
>> Matthew
>>
>> On 11/8/20 11:25 PM, Bert Gunter wrote:
>>>           External Email - Use Caution
>>>
>>> NYT  had interactive maps that reported  votes by county. So try
>>> contacting them.
>>>
>>>
>>> Bert
>>>
>>> On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com>
>>> wrote:
>>>>> such a repository already exists -- the NY Times, AP, CNN, etc.
>>>>> etc.
>>>> already have interactive web pages that did this
>>>>
>>>> I've been looking for presidential election results, by
>>>> ***county***. I've found historic results, including results for
>>>> 2016.
>>>>
>>>> However, I can't find such a dataset, for 2020.
>>>> (Even though this seems like an obvious thing to publish).
>>>>
>>>> I suspect that the NY Times has the data, but I haven't been able
>>>> to work where the data is on their website, or how to access it.
>>>>
>>>> More ***specific*** suggestions would be appreciated...?
>>>>   
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJBHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKIFHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gwR3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
>>> PLEASE do read the posting guide
>>> http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQn1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2LAcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WOIqBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfevwdqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23FeltHgtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
>> PLEASE do read the posting guide
>> http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygDoyYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A8qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGKkUK5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html and provide commented,
>> minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WOIqBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfevwdqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23FeltHgtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> PLEASE do read the posting guide http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygDoyYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A8qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGKkUK5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From M@Roo@ @end|ng |rom |1-out@ourc|ng@eu  Mon Nov  9 18:55:53 2020
From: M@Roo@ @end|ng |rom |1-out@ourc|ng@eu (Marc Roos)
Date: Mon, 9 Nov 2020 18:55:53 +0100
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <1c02cba3-e295-fdd0-21e4-c530c0cdfcb3@molbio.mgh.harvard.edu>
Message-ID: <"H0000071001844e9.1604944553.sx.f1-outsourcing.eu*"@MHS>

 
Publish the results/graphs please, like to see what your are doing.



-----Original Message-----
From: Matthew McCormack [mailto:mccormack at molbio.mgh.harvard.edu] 
Sent: Monday, November 09, 2020 6:14 PM
To: r-help at r-project.org
Subject: Re: [R] analyzing results from Tuesday's US elections


    Benford Analysis for Data Validation and Forensic Analytics

Provides tools that make it easier to validate data using Benford's Law.

https://www.rdocumentation.org/packages/benford.analysis/versions/0.1.5


Matthew

On 11/9/20 9:23 AM, Alexandra Thorn wrote:
>          External Email - Use Caution
>
> This thread strikes me as pretty far off-topic for a forum dedicated 
> to software support on R.
>
> https://secure-web.cisco.com/15MzwKoUQfDzeGBDx9gweXKgiYtAPv1UlnW2dg9Cu
> DtSNWgxy3ffTf_uuPizbjoJnovoOD6lrPDluOgGvIUTEF1d_rOTfaF3nUKLvNiZa3fHZ_I
> HD-SjKotr4lurHjmNPlSrljLipPsrDk2aoo63-GLwvaw64By_MnLST7lt4FgA2pYXgE3x1
> 5Xn-kRZ85m29f0BxhHJMVfilvVUoUEBPrw/https%3A%2F%2Fwww.r-project.org%2Fm
> ail.html%23instructions "The main R mailing list, for discussion 
> about problems and solutions using R, announcements (not covered by 
> R-announce or R-packages, see above), about the availability 
of 
> new functionality for R and documentation of R, comparison and 
> compatibility with S-plus, and for the posting of nice examples and 
> benchmarks. Do read the posting guide before sending anything!"
>
> https://secure-web.cisco.com/1V05G8mWSPHU-YvLbL-UQMy49XX7n7-EivE-gTOlh
> 2nZ3P0oxp6DGUUZQ_Q5VIkE3J0qmhrrSXxJaqZjv-Tllghba8lQrbkazuAHTcltsfo3I-C
> -SMqhb-CDdFbeEgIsr7py_gKW9BqumTZacywhHVnzhGGR2s1A-2akqQLYSYpYeX5EcVJAY
> vX1KPCs9kJbOEveOr5yYjetokaZpLTzdMA/https%3A%2F%2Fwww.r-project.org%2Fp
> osting-guide.html "The R mailing lists are primarily intended for 
> questions and discussion about the R software. However, questions 
> about statistical methodology are sometimes posted. If the question is 

> well-asked and of interest to someone on the list, it may elicit an 
> informative up-to-date answer. See also the Usenet groups 
> sci.stat.consult (applied statistics and consulting) and sci.stat.math 

> (mathematical stat and probability)."
>
> On Mon, 9 Nov 2020 00:53:46 -0500
> Matthew McCormack <mccormack at molbio.mgh.harvard.edu> wrote:
>
>> You can try here: 
>> https://secure-web.cisco.com/17WRivozTB0Frts23cTlTBd3SYWzVXQsLa_jDRN8
>> SldAl35F0SYXRMZczzIXrQFTzbfRV4YfPOVhMSwopcdTU9Sva396s3bX3-KM7-51KjSnY
>> 0aXxlADYaHdvs4y4YXrUfk1GT2801rVL26MCEEn2E1azdQ8ECllu1roS_Z8MIj8d6kyCt
>> UYVdOYN1i9DuWBSXPlEi-iOtrQsBp6ELRXNFw/https%3A%2F%2Fdecisiondeskhq.co
>> m%2F
>>
>> I think they have what you are looking for. From their website:
>>
>> "Create a FREE account to access up to the minute election results 
>> and insights on all U.S. Federal elections. Decision Desk HQ & 
>> ?ptimus provide live election night coverage, race-specific results 
>> including county-level returns, and exclusive race probabilities for 
>> key battleground races."
>>
>>   ?? Also, this article provides a little, emphasis on little, of 
>> statistical analysis of election results, but it may be a place to 
>> start.
>>
>> https://secure-web.cisco.com/1JA34S9tw27K78g7scwo2aGe4lPpV7HThBE81hhJ
>> jb4Ban7fxqbnOZqx7HxfcyqKrcB5BX7oJFHhMPumrxjm6aQJ0trW1Jgk0h9s2mNhZg4T_
>> gTUls8y4l0KZ-AstUtw0eC0TtR9mHblU7KWid-7OO4mg0TfsxWyNpcqkA8MBuGftOEgUF
>> 7WtakShYgmCNYJkEfQJHK5_vjwK0taJeUheVw/https%3A%2F%2Fwww.theepochtimes
>> .com%2Fstatistical-anomalies-in-biden-votes-analyses-indicate_3570518
>> .html%3Futm_source%3Dnewsnoe%26utm_medium%3Demail%26utm_campaign%3Dbr
>> eaking-2020-11-08-5
>>
>> Matthew
>>
>> On 11/8/20 11:25 PM, Bert Gunter wrote:
>>>           External Email - Use Caution
>>>
>>> NYT  had interactive maps that reported  votes by county. So try 
>>> contacting them.
>>>
>>>
>>> Bert
>>>
>>> On Sun, Nov 8, 2020, 8:10 PM Abby Spurdle <spurdle.a at gmail.com>
>>> wrote:
>>>>> such a repository already exists -- the NY Times, AP, CNN, etc.
>>>>> etc.
>>>> already have interactive web pages that did this
>>>>
>>>> I've been looking for presidential election results, by 
>>>> ***county***. I've found historic results, including results for 
>>>> 2016.
>>>>
>>>> However, I can't find such a dataset, for 2020.
>>>> (Even though this seems like an obvious thing to publish).
>>>>
>>>> I suspect that the NY Times has the data, but I haven't been able 
>>>> to work where the data is on their website, or how to access it.
>>>>
>>>> More ***specific*** suggestions would be appreciated...?
>>>>   
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://secure-web.cisco.com/1C8m4dUQtDXEQdbAFTH153ehiJcvHuL_FkvDGeJ
>>> BHhMRYZauAp6gdevfmLIh2MLpRjBx7LXAG9QpagRV63oMY5AyQF6uOkNa7JGw-0zGZKI
>>> FHoSuZtjpcIokATDMxqoJlVfCiktqIYXEiJcrovbnxo-DAgLEiREocQrn0yMbLc2A-gw
>>> R3CN9XurWkU21TUD1CLJ-3gpiCLKKe9BdHWdaeEA/https%3A%2F%2Fstat.ethz.ch%
>>> 2Fmailman%2Flistinfo%2Fr-help
>>> PLEASE do read the posting guide
>>> http://secure-web.cisco.com/1ppZyk8SO6U25PKNDKtGQ-VIADLxXgKvnHc8QlV3
>>> cUMNPzLQvS8E0i9cg05EyzUyHnFjj2QWDjvAjyuduvE1P8Nr0TogQweiuBysM9a1rXjQ
>>> n1EOaypHdqwa2_inODK1icu0Ff33AZDB00N4x-nYxZ2e16nArVuaMEddaLXBhtBYMn2L
>>> AcPYJ8s2wGN10heiFWywn-r8--Hw77GJx1hkTgg/http%3A%2F%2Fwww.R-project.o
>>> rg%2Fposting-guide.html and provide commented, minimal, 
>>> self-contained, reproducible code.
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WO
>> IqBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfe
>> vwdqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23Fe
>> ltHgtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fma
>> ilman%2Flistinfo%2Fr-help
>> PLEASE do read the posting guide
>> http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygD
>> 
oyYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A8
qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGKkUK
5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fposting-
guide.html and provide commented, minimal, self-contained, reproducible 
code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://secure-web.cisco.com/1xog0sXCo0fVwdc0ujt6MkmrNnAl7Ju1I7ftl3WOI
> qBrFkywFcF7bqkees3YG_OptzqCKk8FboOkp9RKcW2qVhrPKdAW33mim6BrfyidbZIfevw
> dqsk8o1tOfjXL9HfvQmcD1ZZSORiQo3qDhjQjvbnETfjbVUwoJuHjqBzq9mL_Th23FeltH
> gtF8jDUDwHbfMDA_jvO84ut6QoHpwYxUjg/https%3A%2F%2Fstat.ethz.ch%2Fmailma
> n%2Flistinfo%2Fr-help PLEASE do read the posting guide 
> http://secure-web.cisco.com/1jDnxG8gXefH0FYFkpHN4ytfq9oFGTOV2wSrstygDo
> yYeDl5wcBOTRwYoSBBVqYBzzgdU6ya5v-iShroKo9PEfRnJ6_mwzPKinWeTh-OLAWbiz9A
> 8qqZrVFd1SrWIMiCrlpLXzKEYXYDspvy7N50KWJLR7ZEuZDysXng2zp2ZrCMdq2cJ_ilGK
> kUK5XeaShoIBifwm39A7Zy4wmUNNWeLaA/http%3A%2F%2Fwww.R-project.org%2Fpos
> ting-guide.html and provide commented, minimal, self-contained, 
> reproducible code.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Mon Nov  9 19:51:33 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Mon, 9 Nov 2020 13:51:33 -0500
Subject: [R] 
 [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
 <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
Message-ID: <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>

Dear Gerrit,

This looks like a bug in plot.eff(), which I haven't yet tracked down, 
but the following should give you what you want:

eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30, 
Age=60:100))
plot(eff, lines=list(multiline=TRUE))

or

eff <- predictorEffect("Age", m, xlevels = list(gProt = 1:6 * 30))
plot(eff, lines=list(multiline=TRUE))

A couple of comments on your code, unrelated to the bug in plot.eff():

You don't need allEffects() because there's only one high-order fixed 
effect in the model, I(gProt/10 - 6.2):I(Age/10 - 7.2) (i.e., the 
interaction of gProt with Age).

x.var isn't intended as an argument for plot() with allEffects() because 
there generally isn't a common horizontal axis for all of the high-order 
effect plots.

Finally, thank you for the bug report. Barring unforeseen difficulties, 
we'll fix the bug in due course.

I hope this helps,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-11-09 8:06 a.m., Gerrit Eichner wrote:
> Dear list members,
> 
> I observe a strange/wrong graphical output when I set the xlevels
> in (e. g.) allEffects for an lmer model and plot the effects with
> multiline = TRUE. I have compiled a reprex for which you need the
> lmer model and the environment in which the model was fitted. They
> are contained in the zip file at
> https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
> After unpacking the following should work:
> 
> m <- readRDS("m.rds")?? # The lmer-model.
> G1 <- readRDS("G1.rds") # Environment in which the model
>  ???????????????????????? # was fitted; needed by alaEffects.
> summary(m) # Just to see the model.
> 
> library(effects)
> aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
>  ???????????????????? # Non-default values for xlevels.
> 
> plot(aE)????????????????????? # Fine.
> plot(aE, x.var = "Age")?????? # Fine.
> plot(aE, lines = list(multiline = TRUE))? # Fine.
> 
> plot(aE, lines = list(multiline = TRUE),
>  ????? x.var = "Age")??????? # Nonsense.
> 
> 
> Anybody any idea about the reason, my mistake, or a
> workaround? Thx for any hint!
> 
>  ? Regards? --? Gerrit
> 
> 
> PS:
>  ?> sessionInfo()
> R version 4.0.2 (2020-06-22)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> 
> other attached packages:
> [1] effects_4.2-0 carData_3.0-4
> 
> loaded via a namespace (and not attached):
>  ? [1] Rcpp_1.0.5?????? lattice_0.20-41? MASS_7.3-53????? grid_4.0.2 
> DBI_1.1.0
>  ? [6] nlme_3.1-149???? survey_4.0?????? estimability_1.3 minqa_1.2.4 
> nloptr_1.2.2.2
> [11] Matrix_1.2-18??? boot_1.3-25????? splines_4.0.2??? statmod_1.4.34 
> lme4_1.1-23
> [16] tools_4.0.2????? survival_3.2-3?? yaml_2.2.1?????? compiler_4.0.2 
> colorspace_1.4-1
> [21] mitools_2.4????? insight_0.9.5??? nnet_7.3-14
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> http://www.uni-giessen.de/eichner
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Mon Nov  9 22:51:42 2020
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Mon, 9 Nov 2020 22:51:42 +0100
Subject: [R] 
 [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
 <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
 <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>
Message-ID: <a1928d36-93d3-db2e-7f5d-cecd7536a759@math.uni-giessen.de>

Dear John,

thank you for prompt reply and your hints. The problem is that our
lmer model is much more complicated and has several interaction
terms:

Mass ~ Sex + I(YoE - 1996) + I(PAI/0.1 - 16) + I(gProt/10 - 6.2) +
     I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) + Diuretics +
     Sex:I(PAI/0.1 - 16) + Sex:I(gProt/10 - 6.2) +
     Sex:I(Age/10 - 7.2) + Sex:I((Age/10 - 7.2)^2) +
     I(YoE - 1996):I(Age/10 - 7.2) + I(PAI/0.1 - 16):I(Age/10 - 7.2) +
     I(gProt/10 - 6.2):I(Age/10 - 7.2) +
     (I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) | ID)

so that allEffects is quite efficient, and since I want to place
several interaction terms with Age in one figure with Age on the
horizontal axis the argument x.var = "Age" in plot would be very
helpful. :-)

Further hints using the above complex model: The following works well:
eff <- Effect(c("gProt", "Age"), m,
               xlevels = list(gProt = 1:6 * 30, Age = 60:100))
plot(eff, lines=list(multiline=TRUE), x.var = "Age")

But this fails (note that Age is missing in xlevels):
eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30))
plot(eff, lines=list(multiline=TRUE), x.var = "Age")


And that just led me to a solutution also for allEffects: Specifying
Age in xlevels for allEffects (although it seems unnecessary when
x.var = "Age" is used in plot) produces the correct graphical
output! :-)

Thank you very much for your support and the brilliant effects
package in general! :-)

  Best regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 09.11.2020 um 19:51 schrieb John Fox:
> Dear Gerrit,
> 
> This looks like a bug in plot.eff(), which I haven't yet tracked down, 
> but the following should give you what you want:
> 
> eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30, 
> Age=60:100))
> plot(eff, lines=list(multiline=TRUE))
> 
> or
> 
> eff <- predictorEffect("Age", m, xlevels = list(gProt = 1:6 * 30))
> plot(eff, lines=list(multiline=TRUE))
> 
> A couple of comments on your code, unrelated to the bug in plot.eff():
> 
> You don't need allEffects() because there's only one high-order fixed 
> effect in the model, I(gProt/10 - 6.2):I(Age/10 - 7.2) (i.e., the 
> interaction of gProt with Age).
> 
> x.var isn't intended as an argument for plot() with allEffects() because 
> there generally isn't a common horizontal axis for all of the high-order 
> effect plots.
> 
> Finally, thank you for the bug report. Barring unforeseen difficulties, 
> we'll fix the bug in due course.
> 
> I hope this helps,
>  ?John
> 
> John Fox, Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> web: https://socialsciences.mcmaster.ca/jfox/
> 
> On 2020-11-09 8:06 a.m., Gerrit Eichner wrote:
>> Dear list members,
>>
>> I observe a strange/wrong graphical output when I set the xlevels
>> in (e. g.) allEffects for an lmer model and plot the effects with
>> multiline = TRUE. I have compiled a reprex for which you need the
>> lmer model and the environment in which the model was fitted. They
>> are contained in the zip file at
>> https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
>> After unpacking the following should work:
>>
>> m <- readRDS("m.rds")?? # The lmer-model.
>> G1 <- readRDS("G1.rds") # Environment in which the model
>> ????????????????????????? # was fitted; needed by alaEffects.
>> summary(m) # Just to see the model.
>>
>> library(effects)
>> aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
>> ????????????????????? # Non-default values for xlevels.
>>
>> plot(aE)????????????????????? # Fine.
>> plot(aE, x.var = "Age")?????? # Fine.
>> plot(aE, lines = list(multiline = TRUE))? # Fine.
>>
>> plot(aE, lines = list(multiline = TRUE),
>> ?????? x.var = "Age")??????? # Nonsense.
>>
>>
>> Anybody any idea about the reason, my mistake, or a
>> workaround? Thx for any hint!
>>
>> ?? Regards? --? Gerrit
>>
>>
>> PS:
>> ??> sessionInfo()
>> R version 4.0.2 (2020-06-22)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 18363)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>
>> other attached packages:
>> [1] effects_4.2-0 carData_3.0-4
>>
>> loaded via a namespace (and not attached):
>> ?? [1] Rcpp_1.0.5?????? lattice_0.20-41? MASS_7.3-53????? grid_4.0.2 
>> DBI_1.1.0
>> ?? [6] nlme_3.1-149???? survey_4.0?????? estimability_1.3 minqa_1.2.4 
>> nloptr_1.2.2.2
>> [11] Matrix_1.2-18??? boot_1.3-25????? splines_4.0.2??? statmod_1.4.34 
>> lme4_1.1-23
>> [16] tools_4.0.2????? survival_3.2-3?? yaml_2.2.1?????? compiler_4.0.2 
>> colorspace_1.4-1
>> [21] mitools_2.4????? insight_0.9.5??? nnet_7.3-14
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>> http://www.uni-giessen.de/eichner
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Nov 10 01:45:36 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 10 Nov 2020 13:45:36 +1300
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
Message-ID: <CAB8pepzwig92ZkNHgLcfmZcSsBb+qVhC17rqaOqBVHRYKsHcaQ@mail.gmail.com>

RESENT
INITIAL EMAIL, TOO BIG
ATTACHMENTS REPLACED WITH LINKS

I created a dataset, linked.
Had to manually copy and paste from the NY Times website.

> head (data, 3)
    STATE   EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
1 Alabama     Mobile         13.3           12       181783                 0
2 Alabama     Dallas        -37.5          -38        17861                 0
3 Alabama Tuscaloosa         19.3           15        89760                 0

> tail (data, 3)
       STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
4248 Wyoming    Uinta         58.5           63         9400                 0
4249 Wyoming Sublette         63.0           62         4970                 0
4250 Wyoming  Johnson         64.3           61         4914                 0

> head (data [data [,1] == "Alaska",], 3)
    STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
68 Alaska    ED 40         14.7        -24.0           82                 1
69 Alaska    ED 37         14.7         -1.7          173                 1
70 Alaska    ED 38         14.7         -0.4          249                 1

EQCounty, is the County or Equivalent.
Several states, D.C., Alaska, Connecticut, Maine, Massachusetts, Rhode
Island and Vermont are different.
RMargin(s) are the republican percentages minus the democrate
percentages, as 2 or 3 digit numbers between 0 and 100.
The last column is 0s or 1s, with 1s for Alaska, Connecticut, Maine,
Massachusetts, Rhode Island and Vermont, where I didn't have the 2016
margins, so the 2016 margins have been replaced with state-levels
values.

Then I scaled the margins, based on the number of voters.
i.e.
wx2016 <- 1000 * x2016 * nv / max.nv
(Where x2016 is equal to RMARGIN_2020, and nv is equal to NVOTERS_2020).

There may be a much better way.

And came up the following plots (linked) and output (follows):

---INPUT---
PATH = "<PATH TO FILE>"
data = read.csv (PATH, header=TRUE)

#raw data
x2016 <- as.numeric (data$RMARGIN_2016)
x2020 <- as.numeric (data$RMARGIN_2020)
nv <- as.numeric (data$NVOTERS_2020)
subs <- as.logical (data$SUB_STATEVAL)

#computed data
max.nv <- max (nv)
wx2016 <- 1000 * x2016 * nv / max.nv
wx2020 <- 1000 * x2020 * nv / max.nv
diffs <- wx2020 - wx2016

OFFSET <- 500
p0 <- par (mfrow = c (2, 2) )

#plot 1
plot (wx2016, wx2020,
main="All Votes\n(By County, or Equivalent)",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)

#plot 2
OFFSET <- 200
plot (wx2016, wx2020,
xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
main="All Votes\n(Zoomed In)",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)

OFFSET <- 1000

#plot 3
J1 <- order (diffs, decreasing=TRUE)[1:400]
plot (wx2016 [J1], wx2020 [J1],
xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
main="400 Biggest Shifts Towards Republican",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)
abline (a=0, b=1, lty=2)

#plot 4
J2 <- order (diffs)[1:400]
plot (wx2016 [J2], wx2020 [J2],
xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
main="400 Biggest Shifts Towards Democrat",
xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin, 2020")
abline (h=0, v=0, lty=2)
abline (a=0, b=1, lty=2)

par (p0)

#most democrat
I = order (wx2020)[1:30]
cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])

#biggest move toward democrat
head (cbind (data [J2,], diffs = diffs [J2]), 30)

---OUTPUT---
#most democrat
> cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])
              STATE        EQCOUNTY RMARGIN_2016 RMARGIN_2020
NVOTERS_2020 SUB_STATEVAL_2016 scaled.dem.vote
229      California     Los Angeles        -49.3          -44
3674850                 0       44000.000
769        Illinois            Cook        -53.1          -47
1897721                 0       24271.164
4073     Washington            King        -48.8          -53
1188152                 0       17135.953
3092   Pennsylvania    Philadelphia        -67.0          -63
701647                 0       12028.725
215      California         Alameda        -63.5          -64
625710                 0       10897.163
227      California     Santa Clara        -52.1          -49
726186                 0        9682.875
238      California       San Diego        -19.7          -23
1546144                 0        9676.942
2683       New York        Brooklyn        -62.0          -49
693937                 0        9252.871
2162      Minnesota        Hennepin        -34.9          -43
753716                 0        8819.350
2074       Michigan           Wayne        -37.1          -37
863382                 0        8692.908
2673       New York       Manhattan        -76.9          -70
446861                 0        8511.986
221      California   San Francisco        -75.2          -73
413642                 0        8216.898
3495          Texas          Dallas        -26.1          -32
920772                 0        8017.934
1741       Maryland Prince George's        -79.7          -80
365857                 0        7964.559
510         Florida         Broward        -34.9          -30
959418                 0        7832.303
3057         Oregon       Multnomah        -56.3          -61
458395                 0        7609.044
3563          Texas          Travis        -38.6          -45
605034                 0        7408.882
565         Georgia          DeKalb        -62.9          -67
369341                 0        6733.839
3942       Virginia         Fairfax        -35.8          -42
578931                 0        6616.624
492            D.C.            D.C.        -86.4          -87
279152                 0        6608.766
562         Georgia          Fulton        -40.9          -46
522050                 0        6534.770
230      California    Contra Costa        -43.0          -48
498340                 0        6509.196
2674       New York          Queens        -53.6          -39
597928                 0        6345.617
257        Colorado          Denver        -54.8          -64
350606                 0        6106.041
2677       New York           Bronx        -79.1          -66
329638                 0        5920.271
3530          Texas          Harris        -12.3          -13
1633671                 0        5779.208
1718       Maryland      Montgomery        -55.4          -57
369405                 0        5729.781
2888           Ohio        Cuyahoga        -35.2          -34
605268                 0        5599.987
2745 North Carolina     Mecklenburg        -29.4          -35
565980                 0        5390.506
2894           Ohio        Franklin        -25.8          -31
606022                 0        5112.231

#biggest move toward democrat
> head (cbind (data [J2,], diffs = diffs [J2]), 30)
              STATE         EQCOUNTY RMARGIN_2016 RMARGIN_2020
NVOTERS_2020 SUB_STATEVAL_2016      diffs
1751  Massachusetts           Boston        -26.8       -67.00
273133                 1 -2987.8625
113         Arizona         Maricopa          2.8        -2.00
2046295                 0 -2672.8209
3531          Texas          Tarrant          8.6        -0.16
830104                 0 -1978.7776
2162      Minnesota         Hennepin        -34.9       -43.00
753716                 0 -1661.3194
3564          Texas           Collin         16.7         5.00
486917                 0 -1550.2480
3495          Texas           Dallas        -26.1       -32.00
920772                 0 -1478.3065
238      California        San Diego        -19.7       -23.00
1546144                 0 -1388.4309
563         Georgia         Gwinnett         -5.8       -18.00
413166                 0 -1371.6547
3565          Texas           Denton         20.0         8.00
416610                 0 -1360.4147
4073     Washington             King        -48.8       -53.00
1188152                 0 -1357.9434
564         Georgia             Cobb         -2.2       -14.00
393340                 0 -1263.0208
2075       Michigan          Oakland         -8.1       -14.00
778418                 0 -1249.7561
291        Colorado        Jefferson         -6.9       -19.00
376430                 0 -1239.4528
292        Colorado          El Paso         22.3        11.00
375058                 0 -1153.2866
2321       Missouri St. Louis County        -16.2       -24.00
528107                 0 -1120.9259
3563          Texas           Travis        -38.6       -45.00
605034                 0 -1053.7077
277        Colorado         Arapahoe        -14.1       -25.00
346740                 0 -1028.4681
2744 North Carolina             Wake        -20.2       -26.00
624049                 0  -984.9339
3942       Virginia          Fairfax        -35.8       -42.00
578931                 0  -976.7398
1116         Kansas          Johnson          2.6        -8.00
338343                 0  -975.9407
3562          Texas            Bexar        -13.4       -18.00
757667                 0  -948.4110
2077       Michigan             Kent          3.1        -6.00
359915                 0  -891.2545
257        Colorado           Denver        -54.8       -64.00
350606                 0  -877.7434
110         Arizona             Pima        -13.6       -20.00
501058                 0  -872.6264
2625     New Jersey         Monmouth          9.3        -1.60
292654                 0  -868.0432
2745 North Carolina      Mecklenburg        -29.4       -35.00
565980                 0  -862.4809
3567          Texas       Williamson          9.7        -1.30
287696                 0  -861.1660
2894           Ohio         Franklin        -25.8       -31.00
606022                 0  -857.5355
203      California        Riverside         -5.4       -11.00
558759                 0  -851.4770
3966       Virginia   Virginia Beach          3.5        -8.00
253477                 0  -793.2257

DISCLAIMER:\ I can not guarantee the accuracy of this da...{{dropped:15}}


From bgunter@4567 @end|ng |rom gm@||@com  Tue Nov 10 04:02:01 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Nov 2020 19:02:01 -0800
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <CAB8pepzwig92ZkNHgLcfmZcSsBb+qVhC17rqaOqBVHRYKsHcaQ@mail.gmail.com>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
 <CAB8pepzwig92ZkNHgLcfmZcSsBb+qVhC17rqaOqBVHRYKsHcaQ@mail.gmail.com>
Message-ID: <CAGxFJbRgVENEH_162fyWoRwAbbDvacHsK1hZ9ytNHS+EMbR35Q@mail.gmail.com>

For those who are interested:

Very nice examples of (static) statistical graphics on election results can
be found here:
https://www.nytimes.com/interactive/2020/11/09/us/arizona-election-battleground-state-counties.html?action=click&module=Spotlight&pgtype=Homepage

Takes multidisciplinary teams and lots of hard work to produce, I would
guess.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Nov 9, 2020 at 4:46 PM Abby Spurdle <spurdle.a at gmail.com> wrote:

> RESENT
> INITIAL EMAIL, TOO BIG
> ATTACHMENTS REPLACED WITH LINKS
>
> I created a dataset, linked.
> Had to manually copy and paste from the NY Times website.
>
> > head (data, 3)
>     STATE   EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020
> SUB_STATEVAL_2016
> 1 Alabama     Mobile         13.3           12       181783
>  0
> 2 Alabama     Dallas        -37.5          -38        17861
>  0
> 3 Alabama Tuscaloosa         19.3           15        89760
>  0
>
> > tail (data, 3)
>        STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020
> SUB_STATEVAL_2016
> 4248 Wyoming    Uinta         58.5           63         9400
>    0
> 4249 Wyoming Sublette         63.0           62         4970
>    0
> 4250 Wyoming  Johnson         64.3           61         4914
>    0
>
> > head (data [data [,1] == "Alaska",], 3)
>     STATE EQCOUNTY RMARGIN_2016 RMARGIN_2020 NVOTERS_2020 SUB_STATEVAL_2016
> 68 Alaska    ED 40         14.7        -24.0           82                 1
> 69 Alaska    ED 37         14.7         -1.7          173                 1
> 70 Alaska    ED 38         14.7         -0.4          249                 1
>
> EQCounty, is the County or Equivalent.
> Several states, D.C., Alaska, Connecticut, Maine, Massachusetts, Rhode
> Island and Vermont are different.
> RMargin(s) are the republican percentages minus the democrate
> percentages, as 2 or 3 digit numbers between 0 and 100.
> The last column is 0s or 1s, with 1s for Alaska, Connecticut, Maine,
> Massachusetts, Rhode Island and Vermont, where I didn't have the 2016
> margins, so the 2016 margins have been replaced with state-levels
> values.
>
> Then I scaled the margins, based on the number of voters.
> i.e.
> wx2016 <- 1000 * x2016 * nv / max.nv
> (Where x2016 is equal to RMARGIN_2020, and nv is equal to NVOTERS_2020).
>
> There may be a much better way.
>
> And came up the following plots (linked) and output (follows):
>
> ---INPUT---
> PATH = "<PATH TO FILE>"
> data = read.csv (PATH, header=TRUE)
>
> #raw data
> x2016 <- as.numeric (data$RMARGIN_2016)
> x2020 <- as.numeric (data$RMARGIN_2020)
> nv <- as.numeric (data$NVOTERS_2020)
> subs <- as.logical (data$SUB_STATEVAL)
>
> #computed data
> max.nv <- max (nv)
> wx2016 <- 1000 * x2016 * nv / max.nv
> wx2020 <- 1000 * x2020 * nv / max.nv
> diffs <- wx2020 - wx2016
>
> OFFSET <- 500
> p0 <- par (mfrow = c (2, 2) )
>
> #plot 1
> plot (wx2016, wx2020,
> main="All Votes\n(By County, or Equivalent)",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
>
> #plot 2
> OFFSET <- 200
> plot (wx2016, wx2020,
> xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
> main="All Votes\n(Zoomed In)",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
>
> OFFSET <- 1000
>
> #plot 3
> J1 <- order (diffs, decreasing=TRUE)[1:400]
> plot (wx2016 [J1], wx2020 [J1],
> xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
> main="400 Biggest Shifts Towards Republican",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
> abline (a=0, b=1, lty=2)
>
> #plot 4
> J2 <- order (diffs)[1:400]
> plot (wx2016 [J2], wx2020 [J2],
> xlim = c (-OFFSET, OFFSET), ylim = c (-OFFSET, OFFSET),
> main="400 Biggest Shifts Towards Democrat",
> xlab="Scaled Republican Margin, 2016", ylab="Scaled Republican Margin,
> 2020")
> abline (h=0, v=0, lty=2)
> abline (a=0, b=1, lty=2)
>
> par (p0)
>
> #most democrat
> I = order (wx2020)[1:30]
> cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])
>
> #biggest move toward democrat
> head (cbind (data [J2,], diffs = diffs [J2]), 30)
>
> ---OUTPUT---
> #most democrat
> > cbind (data [I,], scaled.dem.vote = -1 * wx2020 [I])
>               STATE        EQCOUNTY RMARGIN_2016 RMARGIN_2020
> NVOTERS_2020 SUB_STATEVAL_2016 scaled.dem.vote
> 229      California     Los Angeles        -49.3          -44
> 3674850                 0       44000.000
> 769        Illinois            Cook        -53.1          -47
> 1897721                 0       24271.164
> 4073     Washington            King        -48.8          -53
> 1188152                 0       17135.953
> 3092   Pennsylvania    Philadelphia        -67.0          -63
> 701647                 0       12028.725
> 215      California         Alameda        -63.5          -64
> 625710                 0       10897.163
> 227      California     Santa Clara        -52.1          -49
> 726186                 0        9682.875
> 238      California       San Diego        -19.7          -23
> 1546144                 0        9676.942
> 2683       New York        Brooklyn        -62.0          -49
> 693937                 0        9252.871
> 2162      Minnesota        Hennepin        -34.9          -43
> 753716                 0        8819.350
> 2074       Michigan           Wayne        -37.1          -37
> 863382                 0        8692.908
> 2673       New York       Manhattan        -76.9          -70
> 446861                 0        8511.986
> 221      California   San Francisco        -75.2          -73
> 413642                 0        8216.898
> 3495          Texas          Dallas        -26.1          -32
> 920772                 0        8017.934
> 1741       Maryland Prince George's        -79.7          -80
> 365857                 0        7964.559
> 510         Florida         Broward        -34.9          -30
> 959418                 0        7832.303
> 3057         Oregon       Multnomah        -56.3          -61
> 458395                 0        7609.044
> 3563          Texas          Travis        -38.6          -45
> 605034                 0        7408.882
> 565         Georgia          DeKalb        -62.9          -67
> 369341                 0        6733.839
> 3942       Virginia         Fairfax        -35.8          -42
> 578931                 0        6616.624
> 492            D.C.            D.C.        -86.4          -87
> 279152                 0        6608.766
> 562         Georgia          Fulton        -40.9          -46
> 522050                 0        6534.770
> 230      California    Contra Costa        -43.0          -48
> 498340                 0        6509.196
> 2674       New York          Queens        -53.6          -39
> 597928                 0        6345.617
> 257        Colorado          Denver        -54.8          -64
> 350606                 0        6106.041
> 2677       New York           Bronx        -79.1          -66
> 329638                 0        5920.271
> 3530          Texas          Harris        -12.3          -13
> 1633671                 0        5779.208
> 1718       Maryland      Montgomery        -55.4          -57
> 369405                 0        5729.781
> 2888           Ohio        Cuyahoga        -35.2          -34
> 605268                 0        5599.987
> 2745 North Carolina     Mecklenburg        -29.4          -35
> 565980                 0        5390.506
> 2894           Ohio        Franklin        -25.8          -31
> 606022                 0        5112.231
>
> #biggest move toward democrat
> > head (cbind (data [J2,], diffs = diffs [J2]), 30)
>               STATE         EQCOUNTY RMARGIN_2016 RMARGIN_2020
> NVOTERS_2020 SUB_STATEVAL_2016      diffs
> 1751  Massachusetts           Boston        -26.8       -67.00
> 273133                 1 -2987.8625
> 113         Arizona         Maricopa          2.8        -2.00
> 2046295                 0 -2672.8209
> 3531          Texas          Tarrant          8.6        -0.16
> 830104                 0 -1978.7776
> 2162      Minnesota         Hennepin        -34.9       -43.00
> 753716                 0 -1661.3194
> 3564          Texas           Collin         16.7         5.00
> 486917                 0 -1550.2480
> 3495          Texas           Dallas        -26.1       -32.00
> 920772                 0 -1478.3065
> 238      California        San Diego        -19.7       -23.00
> 1546144                 0 -1388.4309
> 563         Georgia         Gwinnett         -5.8       -18.00
> 413166                 0 -1371.6547
> 3565          Texas           Denton         20.0         8.00
> 416610                 0 -1360.4147
> 4073     Washington             King        -48.8       -53.00
> 1188152                 0 -1357.9434
> 564         Georgia             Cobb         -2.2       -14.00
> 393340                 0 -1263.0208
> 2075       Michigan          Oakland         -8.1       -14.00
> 778418                 0 -1249.7561
> 291        Colorado        Jefferson         -6.9       -19.00
> 376430                 0 -1239.4528
> 292        Colorado          El Paso         22.3        11.00
> 375058                 0 -1153.2866
> 2321       Missouri St. Louis County        -16.2       -24.00
> 528107                 0 -1120.9259
> 3563          Texas           Travis        -38.6       -45.00
> 605034                 0 -1053.7077
> 277        Colorado         Arapahoe        -14.1       -25.00
> 346740                 0 -1028.4681
> 2744 North Carolina             Wake        -20.2       -26.00
> 624049                 0  -984.9339
> 3942       Virginia          Fairfax        -35.8       -42.00
> 578931                 0  -976.7398
> 1116         Kansas          Johnson          2.6        -8.00
> 338343                 0  -975.9407
> 3562          Texas            Bexar        -13.4       -18.00
> 757667                 0  -948.4110
> 2077       Michigan             Kent          3.1        -6.00
> 359915                 0  -891.2545
> 257        Colorado           Denver        -54.8       -64.00
> 350606                 0  -877.7434
> 110         Arizona             Pima        -13.6       -20.00
> 501058                 0  -872.6264
> 2625     New Jersey         Monmouth          9.3        -1.60
> 292654                 0  -868.0432
> 2745 North Carolina      Mecklenburg        -29.4       -35.00
> 565980                 0  -862.4809
> 3567          Texas       Williamson          9.7        -1.30
> 287696                 0  -861.1660
> 2894           Ohio         Franklin        -25.8       -31.00
> 606022                 0  -857.5355
> 203      California        Riverside         -5.4       -11.00
> 558759                 0  -851.4770
> 3966       Virginia   Virginia Beach          3.5        -8.00
> 253477                 0  -793.2257
>
> DISCLAIMER:
> I can not guarantee the accuracy of this data, or any conclusions.
>
> NOTE:
> Reiterating, several states used state-level values for 2016.
> (So, the Boston value above, may be off).
>
> Monospaced fonts are required for reading the contents of this email.
>
> LINKS:
>
> https://sites.google.com/site/spurdlea/temp_election
>
> https://sites.google.com/site/spurdlea/exts/election_data.txt
>

	[[alternative HTML version deleted]]


From rub@k @end|ng |rom m@th@@@u@dk  Tue Nov 10 08:30:38 2020
From: rub@k @end|ng |rom m@th@@@u@dk (Ege Rubak)
Date: Tue, 10 Nov 2020 07:30:38 +0000
Subject: [R] paste() turns list element character vector into deparsed
 expression. Why?
In-Reply-To: <D76CB58F-F845-4FDE-9FBF-C42C88E1A114@utoronto.ca>
References: <2B1C773F-F6D7-4F71-BD10-23FF175CA877@utoronto.ca>
 <fa74a036c97f340f484049186eb0a1fecb689df1.camel@math.aau.dk>
 <D76CB58F-F845-4FDE-9FBF-C42C88E1A114@utoronto.ca>
Message-ID: <ba0acac3d86bd8b2789b36bc6569fc1e181d1e82.camel@math.aau.dk>

I agree that it is weird, but I don't see that it is easy to coerce a
list to character of the same structure. In my example (missing the
trailing parenthesis, sorry...) the input is a length two list and the
output is a length two character vector, so in the general case the
rationale seems to be that the output should have the same length as
the input, which makes sense. What specific length two character vector
would you suggest for this example? Would you paste the elements
together with an arbitrary separator of your choice?

In the more general case these elements could be anything: numbers,
characters, functions or even new lists, and I agree that it most often
probably just would make most sense to return an error. Actually I
think it is a bad idea to call `as.character()` on a list in the first
place. Logically this doesn't make much sense. If you want to use
`as.charater()` on each element in the list you should use `lapply()`.

If you really insist on representing a complicated structure as a list
as character I don't see any better general way to represent the list
as character than what R currently does.

Kind regards,
Ege


On Mon, 2020-11-09 at 12:58 +0000, Boris Steipe wrote:
> Thanks Ege -
> 
> That narrows it down, ... but it's still weird.
> 
> My issue is that I don't consider "c(\"xyz\", \"uvw\")" to be a valid
> character representation of a list. c() is a function, so "c(\"xyz\",
> \"uvw\")" is a string representation of a function call that could
> be  eval(parse(...))'ed into a two-element vector ... but considering
> this a coercion seems really weird.
> 
> What do I think your example should return? An object of the same
> general structure as the input, with non-character components coerced
> to character. And if that's not possible because there is no good
> character representation (e.g. if its a closure) than it should
> return an error. 
> 
> 
> Cheers,
> Boris
> 
>  
> 
> 
> > On 2020-11-09, at 22:24, Ege Rubak <rubak at math.aau.dk> wrote:
> > 
> > EXTERNAL EMAIL:  Treat content with extra caution.
> > 
> > I think `paste()` just calls `as.character()` on each input
> > argument
> > and then collapses things afterwards. Calling `as.character()` on
> > the
> > first input argument generates exactly the output you show (and
> > didn't
> > expect) and there is nothing to collapse. So changing `collapse =
> > ""`
> > to anything else doesn't change behaviour.
> > 
> > The question is reduced to how `as.character()` should handle a
> > list as
> > input. It seems to me that this input is so generic that it is hard
> > to
> > handle graciously without all kinds of special cases. So you expect
> > the
> > length one list
> > 
> > as.character(list(s = c("xyz", "uvw"))
> > 
> > to return the length 2 character vector `c("xyz", "uvw")`? What
> > should
> > 
> > as.character(list(s = c("xyz", "uvw"), t = c("a", "b", "c"))
> > 
> > return?
> > 
> > Kind regards,
> > Ege
> > 
> > On Mon, 2020-11-09 at 11:38 +0000, Boris Steipe wrote:
> > > I was just surprised by very un-intuitive behaviour of paste(),
> > > which
> > > appears to collapse a one-column data frame or one-element list
> > > into
> > > a deparsed expression, rather than producing the expected string.
> > > Can
> > > someone kindly explain what's going on here?
> > > 
> > > 
> > > reprex:
> > > =======
> > > 
> > > list(s = c("xyz", "uvw"))
> > > #     s
> > > # 1 xyz
> > > # 2 uvw
> > > 
> > > paste(list(s = c("xyz", "uvw")), collapse = "")
> > > # [1] "c(\"xyz\", \"uvw\")"   # This is unexpected!
> > > 
> > > I would have expected:
> > > # [1] "xyzuvw"
> > > 
> > > ... which I do get with e.g.
> > > paste(list(s = c("xyz", "uvw"))$s, collapse = "")
> > > 
> > > But what logic is there in returning a deparsed expression?
> > > 
> > > 
> > > 
> > > Thanks!
> > > Boris
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible
> > > code.

From m|@ojpm @end|ng |rom gm@||@com  Tue Nov 10 09:06:22 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 10 Nov 2020 16:06:22 +0800
Subject: [R] Remove all factor levels from an R dataframe
Message-ID: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>

Hi,

   I would like to sort the following simple dataframe by "year"
(characters), but the factor structure prevents me from doing so. How can I
remove the factor structure? Thanks!

> df1
  year                  country
4 2007             Asia; survey
5 2010 8 countries in E/SE Asia
6 2015                    Ghana
7
8 2000                      US?
> str(df1)
'data.frame': 5 obs. of  2 variables:
 $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
 $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
performance of the Euro Area",..: 4 5 6 7 8
> df1[order(-year), ]
Error in order(-year) : object 'year' not found

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Nov 10 09:56:04 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Nov 2020 19:56:04 +1100
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
Message-ID: <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>

Hi John,

df1<-sapply(df1,as.character)

Should do what you ask. The error message probably means that you should do
this:

df1<-df1[order(as.character(df1$year)),]

as "year" is the name of the first column in df1, not a separate object.

Jim

On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:

> Hi,
>
>    I would like to sort the following simple dataframe by "year"
> (characters), but the factor structure prevents me from doing so. How can I
> remove the factor structure? Thanks!
>
> > df1
>   year                  country
> 4 2007             Asia; survey
> 5 2010 8 countries in E/SE Asia
> 6 2015                    Ghana
> 7
> 8 2000                      US?
> > str(df1)
> 'data.frame': 5 obs. of  2 variables:
>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
> performance of the Euro Area",..: 4 5 6 7 8
> > df1[order(-year), ]
> Error in order(-year) : object 'year' not found
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m|@ojpm @end|ng |rom gm@||@com  Tue Nov 10 10:14:35 2020
From: m|@ojpm @end|ng |rom gm@||@com (John)
Date: Tue, 10 Nov 2020 17:14:35 +0800
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
 <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
Message-ID: <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>

Thanks Jim. Can we do descending order?

Jim Lemon <drjimlemon at gmail.com> ? 2020?11?10? ?? ??4:56???

> Hi John,
>
> df1<-sapply(df1,as.character)
>
> Should do what you ask. The error message probably means that you should
> do this:
>
> df1<-df1[order(as.character(df1$year)),]
>
> as "year" is the name of the first column in df1, not a separate object.
>
> Jim
>
> On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:
>
>> Hi,
>>
>>    I would like to sort the following simple dataframe by "year"
>> (characters), but the factor structure prevents me from doing so. How can
>> I
>> remove the factor structure? Thanks!
>>
>> > df1
>>   year                  country
>> 4 2007             Asia; survey
>> 5 2010 8 countries in E/SE Asia
>> 6 2015                    Ghana
>> 7
>> 8 2000                      US?
>> > str(df1)
>> 'data.frame': 5 obs. of  2 variables:
>>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
>>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
>> performance of the Euro Area",..: 4 5 6 7 8
>> > df1[order(-year), ]
>> Error in order(-year) : object 'year' not found
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Nov 10 10:15:15 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Nov 2020 20:15:15 +1100
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
 <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
 <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>
Message-ID: <CA+8X3fXLhh4K+-+gbrvpkpd=+mmEhBvDMkJ5XR95xM0sFfLfdQ@mail.gmail.com>

Sure John,

df1<-df1[order(as.character(df1$year),decreasing=TRUE),]

Jim

On Tue, Nov 10, 2020 at 8:05 PM John <miaojpm at gmail.com> wrote:

> Thanks Jim. Can we do descending order?
>
> Jim Lemon <drjimlemon at gmail.com> ? 2020?11?10? ?? ??4:56???
>
>> Hi John,
>>
>> df1<-sapply(df1,as.character)
>>
>> Should do what you ask. The error message probably means that you should
>> do this:
>>
>> df1<-df1[order(as.character(df1$year)),]
>>
>> as "year" is the name of the first column in df1, not a separate object.
>>
>> Jim
>>
>> On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:
>>
>>> Hi,
>>>
>>>    I would like to sort the following simple dataframe by "year"
>>> (characters), but the factor structure prevents me from doing so. How
>>> can I
>>> remove the factor structure? Thanks!
>>>
>>> > df1
>>>   year                  country
>>> 4 2007             Asia; survey
>>> 5 2010 8 countries in E/SE Asia
>>> 6 2015                    Ghana
>>> 7
>>> 8 2000                      US?
>>> > str(df1)
>>> 'data.frame': 5 obs. of  2 variables:
>>>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
>>>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
>>> performance of the Euro Area",..: 4 5 6 7 8
>>> > df1[order(-year), ]
>>> Error in order(-year) : object 'year' not found
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Tue Nov 10 10:19:05 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 10 Nov 2020 11:19:05 +0200
Subject: [R] Remove all factor levels from an R dataframe
In-Reply-To: <CA+8X3fXLhh4K+-+gbrvpkpd=+mmEhBvDMkJ5XR95xM0sFfLfdQ@mail.gmail.com>
References: <CABcx46AQXg1Q3adZMrUv9eJtSqFEpPdrkPtOkSZCzuE1r6hWrg@mail.gmail.com>
 <CA+8X3fW4pdLUYQKH0rOYvJtJtZhrddpsuUwTqH=nC3LiiiPOeQ@mail.gmail.com>
 <CABcx46Chm9MuM6e6JHeKOAd=_CZqf6sOvczqRu0pf43dHZ01ow@mail.gmail.com>
 <CA+8X3fXLhh4K+-+gbrvpkpd=+mmEhBvDMkJ5XR95xM0sFfLfdQ@mail.gmail.com>
Message-ID: <CAGgJW7773YshuYWNHRj+Lea8xBzUi0JNsAUrPOQ1wHwfS7tzuA@mail.gmail.com>

Hi John,
I was thinking that you created df1 in a way that set the 'year'
column as a factor when this is not what you wanted to do.
The data.frame() function takes an argument stringsAsFactors which
controls this behavior.
For R versions 3.6.3 or earlier, the default setting is
stringsAsFactors=TRUE, which means that string columns automatically
become factors.
You have to specify stringsAsFactors=FALSE to avoid this. (In R 4.0.x
the default was changed to FALSE.)

Example:
df1 <- data.frame( a=letters[1:10], stringsAsFactors=FALSE )

HTH,
Eric

On Tue, Nov 10, 2020 at 11:16 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Sure John,
>
> df1<-df1[order(as.character(df1$year),decreasing=TRUE),]
>
> Jim
>
> On Tue, Nov 10, 2020 at 8:05 PM John <miaojpm at gmail.com> wrote:
>
> > Thanks Jim. Can we do descending order?
> >
> > Jim Lemon <drjimlemon at gmail.com> ? 2020?11?10? ?? ??4:56???
> >
> >> Hi John,
> >>
> >> df1<-sapply(df1,as.character)
> >>
> >> Should do what you ask. The error message probably means that you should
> >> do this:
> >>
> >> df1<-df1[order(as.character(df1$year)),]
> >>
> >> as "year" is the name of the first column in df1, not a separate object.
> >>
> >> Jim
> >>
> >> On Tue, Nov 10, 2020 at 6:57 PM John <miaojpm at gmail.com> wrote:
> >>
> >>> Hi,
> >>>
> >>>    I would like to sort the following simple dataframe by "year"
> >>> (characters), but the factor structure prevents me from doing so. How
> >>> can I
> >>> remove the factor structure? Thanks!
> >>>
> >>> > df1
> >>>   year                  country
> >>> 4 2007             Asia; survey
> >>> 5 2010 8 countries in E/SE Asia
> >>> 6 2015                    Ghana
> >>> 7
> >>> 8 2000                      US?
> >>> > str(df1)
> >>> 'data.frame': 5 obs. of  2 variables:
> >>>  $ year   : Factor w/ 9 levels "2017","2016",..: 4 5 3 6 7
> >>>  $ country: Factor w/ 9 levels "Euro Area\\newline Testing the MP
> >>> performance of the Euro Area",..: 4 5 6 7 8
> >>> > df1[order(-year), ]
> >>> Error in order(-year) : object 'year' not found
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nurog@|eo @end|ng |rom gm@||@com  Wed Nov 11 01:54:29 2020
From: nurog@|eo @end|ng |rom gm@||@com (=?UTF-8?B?R2FzcGFyIE7DusOxZXo=?=)
Date: Tue, 10 Nov 2020 18:54:29 -0600
Subject: [R] R ioanalysis pkg
Message-ID: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>

Hi,

Hope you are doing well, I?m trying to start working
with ioanalysis package, however its being difficult for me
to prepare data from my own input-output table,
import it into R in order to apply the ioanalysis functions
Any help on this will be highly appreciated.
Please note that I do not need links to the ioanalysis manual
nor to pages describing the package and its functions,
but something like a tutorial or worked example on
how to prepare data from the input-output table
import data into R, so that after that i can work with ioanalysis

Thank you very much in advance

Gaspar N??ez

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Nov 11 02:08:36 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 10 Nov 2020 17:08:36 -0800
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
Message-ID: <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>

There are around 20,000 specialized packages for R. This list is set up to
help on standard R features and packages, but cannot possibly be expected
to support 20,000 packages. As the posting guide says (did you read it??!):

"If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports."
(Note also: ?maintainer)

So did you you do this?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Nov 10, 2020 at 4:55 PM Gaspar N??ez <nurogaleo at gmail.com> wrote:

> Hi,
>
> Hope you are doing well, I?m trying to start working
> with ioanalysis package, however its being difficult for me
> to prepare data from my own input-output table,
> import it into R in order to apply the ioanalysis functions
> Any help on this will be highly appreciated.
> Please note that I do not need links to the ioanalysis manual
> nor to pages describing the package and its functions,
> but something like a tutorial or worked example on
> how to prepare data from the input-output table
> import data into R, so that after that i can work with ioanalysis
>
> Thank you very much in advance
>
> Gaspar N??ez
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Nov 11 03:06:42 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 10 Nov 2020 18:06:42 -0800
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
 <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
Message-ID: <bfef77fc-e07a-9cc7-71e3-f6ecf3dea12e@comcast.net>


On 11/10/20 5:08 PM, Bert Gunter wrote:
> There are around 20,000 specialized packages for R. This list is set up to
> help on standard R features and packages, but cannot possibly be expected
> to support 20,000 packages. As the posting guide says (did you read it??!):
>
> "If the question relates to a *contributed package* , e.g., one downloaded
> from CRAN, try contacting the package maintainer first. You can also use
> find("functionname") and packageDescription("packagename") to find this
> information. *Only* send such questions to R-help or R-devel if you get no
> reply or need further assistance. This applies to both requests for help
> and to bug reports."
> (Note also: ?maintainer)
>
> So did you you do this?
>
> Bert Gunter

To follow up on this ... the StackOverflow forum also handles coding
questions but it specifically advises against posting overly broad
questions or requests for package recommendations or other requests for
external sources of programming advice or tutoring.

Like Rhelp, SO advises questioners is to prepare a test dataset and to show what efforts have been made using R code. The code should preferably install the package and then load it. It should then make whatever preliminary transformations you have attempted along with the compete error messages or descriptions of what results failed to meet your expectations.

Neither Rhelp or SO should be considered as sources for one-off tutorials or as places to ask for one-off projects builds.

-- 
David.

 ?On Tue, Nov 10, 2020 at 4:55 PM Gaspar N??ez <nurogaleo at gmail.com> wrote:

>> Hi,
>>
>> Hope you are doing well, I?m trying to start working
>> with ioanalysis package, however its being difficult for me
>> to prepare data from my own input-output table,
>> import it into R in order to apply the ioanalysis functions
>> Any help on this will be highly appreciated.
>> Please note that I do not need links to the ioanalysis manual
>> nor to pages describing the package and its functions,
>> but something like a tutorial or worked example on
>> how to prepare data from the input-output table
>> import data into R, so that after that i can work with ioanalysis
>>
>> Thank you very much in advance
>>
>> Gaspar N??ez
>>
>>          [[alternative HTML version deleted]
And .... Rhelp does not accept HTML code. If you had included code, it 
would probably have been mangles. Use plain text.


From drj|m|emon @end|ng |rom gm@||@com  Wed Nov 11 03:20:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 11 Nov 2020 13:20:45 +1100
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
Message-ID: <CA+8X3fX0p+1BSLZPXQ85cUWQs0qnCUsXhFUvCMqdm9=CcHji5w@mail.gmail.com>

Hi Gaspar,
I can see why you are having trouble with this. The "as.inputoutput"
function seems to be the core. While the manual claims you can just input
the "Z", "RS_label" and and "X" matrices to "as.inputoutput" and get the
"InputOutput" object that you need for all the other functions, it looks to
me as though the required input matrices are not trivial to create. The
manual is confusing as the argument name "Z" is overprinted by "RS_label"
My guess is that you will have to know a bit about what you are doing to
use the package.

Jim

On Wed, Nov 11, 2020 at 11:55 AM Gaspar N??ez <nurogaleo at gmail.com> wrote:

> Hi,
>
> Hope you are doing well, I?m trying to start working
> with ioanalysis package, however its being difficult for me
> to prepare data from my own input-output table,
> import it into R in order to apply the ioanalysis functions
> Any help on this will be highly appreciated.
> Please note that I do not need links to the ioanalysis manual
> nor to pages describing the package and its functions,
> but something like a tutorial or worked example on
> how to prepare data from the input-output table
> import data into R, so that after that i can work with ioanalysis
>
> Thank you very much in advance
>
> Gaspar N??ez
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From nurog@|eo @end|ng |rom gm@||@com  Wed Nov 11 21:51:46 2020
From: nurog@|eo @end|ng |rom gm@||@com (=?UTF-8?B?R2FzcGFyIE7DusOxZXo=?=)
Date: Wed, 11 Nov 2020 14:51:46 -0600
Subject: [R] R ioanalysis pkg
In-Reply-To: <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
References: <CAHCwdFFk-fUvPUVKGQeTTscHFPnHDJUxAiyR6Jz0yJTEeaRrAg@mail.gmail.com>
 <CAGxFJbQtcP7V_3AGkpQrYFLxKTzCGXVKAM4=FVn6i6MbURB7Hg@mail.gmail.com>
Message-ID: <CAHCwdFHH=uGPdHhxecC=5x2jA1tvxpw0Bjs2ah_3CSZvDMw+eA@mail.gmail.com>

Thank you very much Bert and David,
I appreciate your kind answers
which will be of great help to me no doubt.

G


On Tue, Nov 10, 2020 at 7:08 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> There are around 20,000 specialized packages for R. This list is set up to
> help on standard R features and packages, but cannot possibly be expected
> to support 20,000 packages. As the posting guide says (did you read it??!):
>
> "If the question relates to a *contributed package* , e.g., one
> downloaded from CRAN, try contacting the package maintainer first. You can
> also use find("functionname") and packageDescription("packagename") to
> find this information. *Only* send such questions to R-help or R-devel if
> you get no reply or need further assistance. This applies to both requests
> for help and to bug reports."
> (Note also: ?maintainer)
>
> So did you you do this?
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Nov 10, 2020 at 4:55 PM Gaspar N??ez <nurogaleo at gmail.com> wrote:
>
>> Hi,
>>
>> Hope you are doing well, I?m trying to start working
>> with ioanalysis package, however its being difficult for me
>> to prepare data from my own input-output table,
>> import it into R in order to apply the ioanalysis functions
>> Any help on this will be highly appreciated.
>> Please note that I do not need links to the ioanalysis manual
>> nor to pages describing the package and its functions,
>> but something like a tutorial or worked example on
>> how to prepare data from the input-output table
>> import data into R, so that after that i can work with ioanalysis
>>
>> Thank you very much in advance
>>
>> Gaspar N??ez
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pr||ett|ngton @end|ng |rom gm@||@com  Wed Nov 11 22:59:44 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Thu, 12 Nov 2020 10:59:44 +1300
Subject: [R] ggtree: color-code multiple paraphyletic clades
Message-ID: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>

I've been using groupOTU to color paraphyletic clades in my tree based on
lists of tips, but I have multiple clades I want to highlight.  Is there
some way to use ggplot to indicate multiple paraphyletic clades?

Thank you

	[[alternative HTML version deleted]]


From m@rce|o|@|@ @end|ng |rom gm@||@com  Wed Nov 11 23:11:20 2020
From: m@rce|o|@|@ @end|ng |rom gm@||@com (Marcelo Laia)
Date: Wed, 11 Nov 2020 19:11:20 -0300
Subject: [R] ggplot2 stat_smooth formula different units
Message-ID: <20201111221120.GB33352@localhost>

Hi,

I am running these approaches:

Model 1

ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) + 
    geom_point(size=0.5) +
    stat_smooth(method = "lm",
                formula = y ~ x + I(x^2), size = 1) +
    facet_grid(Espacamento ~ Clone) +
    theme(legend.position="none")

Model 2

ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) + 
    geom_point(size=0.5) +
    stat_smooth(method = "lm",
                formula = I(log(y)) ~ I(1/x), size = 1) +
    facet_grid(Espacamento ~ Clone) +
    theme(legend.position="none")

In model 1, both, original variables and fitted variables are plotted
in the same units.

However, in the second one, points is plotted in the original variable,
instead of fitted variables. I know that

exp(fitted(model2)) 

do the trick and return the variables to the original units.

But, I don't know how I do this in the stat_smooth function.

Please, have you a tip for help me?

Thank you!

-- 
Marcelo


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov 12 00:10:51 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 11 Nov 2020 23:10:51 +0000
Subject: [R] ggplot2 stat_smooth formula different units
In-Reply-To: <20201111221120.GB33352@localhost>
References: <20201111221120.GB33352@localhost>
Message-ID: <7ec7f3ce-2a5a-bb4d-245c-69c5c56cfafe@sapo.pt>

Hello,

Try removing I() from I(log(y)). But it's hard to say without a 
reproducible example, please post the output of

dput(dat)

or, if dat is big, the output of

dput(head(dat, 20))


Hope this helps,

Rui Barradas

?s 22:11 de 11/11/20, Marcelo Laia escreveu:
> Hi,
> 
> I am running these approaches:
> 
> Model 1
> 
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = y ~ x + I(x^2), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")
> 
> Model 2
> 
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = I(log(y)) ~ I(1/x), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")
> 
> In model 1, both, original variables and fitted variables are plotted
> in the same units.
> 
> However, in the second one, points is plotted in the original variable,
> instead of fitted variables. I know that
> 
> exp(fitted(model2))
> 
> do the trick and return the variables to the original units.
> 
> But, I don't know how I do this in the stat_smooth function.
> 
> Please, have you a tip for help me?
> 
> Thank you!
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Nov 12 00:15:56 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 11 Nov 2020 23:15:56 +0000
Subject: [R] ggtree: color-code multiple paraphyletic clades
In-Reply-To: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>
References: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>
Message-ID: <f19c1ff9-1762-a994-3bb2-9d5fb06781f5@sapo.pt>

Hello,

You should post a reproducible example like the posting guide asks you to.
In the mean time, are you looking for [1], section Group Clades, by 
package ggtree author? It even seems to be the package vignette.

[1] 
https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html


Hope this helps,

Rui Barradas

?s 21:59 de 11/11/20, April Ettington escreveu:
> I've been using groupOTU to color paraphyletic clades in my tree based on
> lists of tips, but I have multiple clades I want to highlight.  Is there
> some way to use ggplot to indicate multiple paraphyletic clades?
> 
> Thank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @pr||ett|ngton @end|ng |rom gm@||@com  Thu Nov 12 00:19:05 2020
From: @pr||ett|ngton @end|ng |rom gm@||@com (April Ettington)
Date: Thu, 12 Nov 2020 12:19:05 +1300
Subject: [R] ggtree: color-code multiple paraphyletic clades
In-Reply-To: <f19c1ff9-1762-a994-3bb2-9d5fb06781f5@sapo.pt>
References: <CAE9tUWd7-uhZH+pCgDteJGDV8zRCk6TnrmVjZyGR8cGXGKaGbw@mail.gmail.com>
 <f19c1ff9-1762-a994-3bb2-9d5fb06781f5@sapo.pt>
Message-ID: <CAE9tUWc4Xj9Kz9D78kP_BYi5OWyAHhoMJkT+-DHAckc=k-2hRg@mail.gmail.com>

Thank you, it seems the solution is to define the nodes in groupOTU using a
list of vectors.

On Thu, Nov 12, 2020 at 12:15 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> You should post a reproducible example like the posting guide asks you to.
> In the mean time, are you looking for [1], section Group Clades, by
> package ggtree author? It even seems to be the package vignette.
>
> [1]
>
> https://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.html
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 21:59 de 11/11/20, April Ettington escreveu:
> > I've been using groupOTU to color paraphyletic clades in my tree based on
> > lists of tips, but I have multiple clades I want to highlight.  Is there
> > some way to use ggplot to indicate multiple paraphyletic clades?
> >
> > Thank you
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From m@rce|o|@|@ @end|ng |rom gm@||@com  Thu Nov 12 00:36:31 2020
From: m@rce|o|@|@ @end|ng |rom gm@||@com (Marcelo Laia)
Date: Wed, 11 Nov 2020 20:36:31 -0300
Subject: [R] ggplot2 stat_smooth formula different units
In-Reply-To: <7ec7f3ce-2a5a-bb4d-245c-69c5c56cfafe@sapo.pt>
References: <20201111221120.GB33352@localhost>
 <7ec7f3ce-2a5a-bb4d-245c-69c5c56cfafe@sapo.pt>
Message-ID: <20201111233631.GA4908@localhost>

Hi Rui,

You are very welcome!

On 11/11/20 at 11:10, Rui Barradas wrote:
> 
> dput(head(dat, 20))
> 

structure(list(Bloco = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), Espacamento = c("3 x 1", 
"3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", 
"3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1", 
"3 x 1", "3 x 1", "3 x 1", "3 x 1", "3 x 1"), Clone = c("AEC 0020", 
"AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", 
"AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", 
"AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", "AEC 0020", 
"AEC 0020"), Sulco = c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L), Arvore = c(1L, 3L, 5L, 
6L, 7L, 8L, 9L, 10L, 11L, 1L, 2L, 4L, 5L, 6L, 8L, 9L, 10L, 11L, 
1L, 2L), DAP = c(7, 7.73, 7.64, 9.61, 11.94, 11.46, 11.68, 11.84, 
13.37, 11.14, 10.5, 12.19, 7.23, 8.94, 9.99, 12.67, 5.09, 6.37, 
10.28, 8.12), Altura = c(14.8, 17.2, 14.8, 17.2, 18.5, 19.2, 
19.2, 18, 19.3, 18.2, 18.1, 18.1, 15.7, 17.1, 19.3, 19.2, 10.9, 
13.2, 17.1, 16.5), Observacao = c("", "", "", "", "", "", "", 
"", "", "", "", "", "", "", "", "", "", "", "", "")), row.names = c(1L, 
3L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 18L, 
19L, 20L, 21L, 22L, 23L), class = "data.frame")

-- 
Marcelo


From tr@xp|@yer @end|ng |rom gm@||@com  Thu Nov 12 01:23:06 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Thu, 12 Nov 2020 01:23:06 +0100
Subject: [R] analyzing results from Tuesday's US elections
In-Reply-To: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
References: <cedcb614-1d08-b600-4ff7-2ba8b3a6330b@effectivedefense.org>
Message-ID: <CAGAA5bcNrJu3vDmihCrTqfySc8xbvaXw7EB9WXb+ajFwzML3eg@mail.gmail.com>

Please watch this video if you wrongly believe that Benford's law easily
can be applied to elections results.

https://youtu.be/etx0k1nLn78



On Sun, Nov 1, 2020, 21:17 Spencer Graves <
spencer.graves at effectivedefense.org> wrote:

> Hello:
>
>
>        What can you tell me about plans to analyze data from this year's
> general election, especially to detect possible fraud?
>
>
>        I might be able to help with such an effort.  I have NOT done
> much with election data, but I have developed tools for data analysis,
> including web scraping, and included them in R packages available on the
> Comprehensive R Archive Network (CRAN) and GitHub.[1]
>
>
>        Penny Abernathy, who holds the Knight Chair in Journalism and
> Digital Media Economics at UNC-Chapel Hill, told me that the electoral
> fraud that disqualified the official winner from NC-09 to the US House
> in 2018 was detected by a college prof, who accessed the data two weeks
> after the election.[2]
>
>
>        Spencer Graves
>
>
> [1]
> https://github.com/sbgraves237
>
>
> [2]
> https://en.wikiversity.org/wiki/Local_Journalism_Sustainability_Act
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycd|ng @end|ng |rom coh@org  Thu Nov 12 01:39:28 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 12 Nov 2020 00:39:28 +0000
Subject: [R] please help with "could not find function "ComBat.mc" "
Message-ID: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>


Hi All,

I am very sorry to bother you.

This week, I updated my R from 3.5.3? to 4.0.3, reinstalled all required R packages  and reran the following R code;  then got the following error: could not find function "ComBat.mc".

> #' firstly Removing chip-well batch effects using ComBat from the sva package
> # First we convert from beta-values to M-values
> Mvals1 <- log2(betas.rcp)-log2(1-betas.rcp)
> #' ComBat eBayes adjustment using a known variable of interest (here we use row)
> Mvals.ComBat1 <- ComBat.mc(Mvals1, batch = pData(WB.noob)$Array,nCores = detectCores()-1)
Error in ComBat.mc(Mvals1, batch = pData(WB.noob)$Array, nCores = detectCores() -? : 
??could not find function "ComBat.mc"

I have successfully run the same R code with same data sets several times since 2017.? Google searching tells me that this ComBat.mc function is from an R package "Enmix".  When typing library(Enmix), no error message, so the Enmix library is installed.? Can you tell me why I got this error after updating to new R version? 

Thank you,

Yuan Chun Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From j|ox @end|ng |rom mcm@@ter@c@  Thu Nov 12 01:52:07 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (John Fox)
Date: Wed, 11 Nov 2020 19:52:07 -0500
Subject: [R] 
 [effects] Wrong xlevels in effects plot for mixed effects model
 when multiline = TRUE
In-Reply-To: <a1928d36-93d3-db2e-7f5d-cecd7536a759@math.uni-giessen.de>
References: <1fbfac1d-5cb6-35b6-f13c-f4ef53cd5944@math.uni-giessen.de>
 <27049_1604927072_0A9D4V3L027674_5d60e77d-cbeb-76c6-39dc-1caf05aa0534@math.uni-giessen.de>
 <b4df868d-77ea-3524-02ef-ca2661225dbf@mcmaster.ca>
 <a1928d36-93d3-db2e-7f5d-cecd7536a759@math.uni-giessen.de>
Message-ID: <80397afa-d93b-ddaf-c3b4-837fc10be8bf@mcmaster.ca>

Dear Gerrit,

The bug you reported should now be fixed in the development version 
4.2-1 of the effects package, which you can currently install from 
R-Forge via  install.packages("effects", 
repos="http://R-Forge.R-project.org") . Eventually, the updated version 
of the effects package will be submitted to CRAN.

Thank you again for the bug report,
  John

John Fox, Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
web: https://socialsciences.mcmaster.ca/jfox/

On 2020-11-09 4:51 p.m., Gerrit Eichner wrote:
> Dear John,
> 
> thank you for prompt reply and your hints. The problem is that our
> lmer model is much more complicated and has several interaction
> terms:
> 
> Mass ~ Sex + I(YoE - 1996) + I(PAI/0.1 - 16) + I(gProt/10 - 6.2) +
>  ??? I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) + Diuretics +
>  ??? Sex:I(PAI/0.1 - 16) + Sex:I(gProt/10 - 6.2) +
>  ??? Sex:I(Age/10 - 7.2) + Sex:I((Age/10 - 7.2)^2) +
>  ??? I(YoE - 1996):I(Age/10 - 7.2) + I(PAI/0.1 - 16):I(Age/10 - 7.2) +
>  ??? I(gProt/10 - 6.2):I(Age/10 - 7.2) +
>  ??? (I(Age/10 - 7.2) + I((Age/10 - 7.2)^2) | ID)
> 
> so that allEffects is quite efficient, and since I want to place
> several interaction terms with Age in one figure with Age on the
> horizontal axis the argument x.var = "Age" in plot would be very
> helpful. :-)
> 
> Further hints using the above complex model: The following works well:
> eff <- Effect(c("gProt", "Age"), m,
>  ????????????? xlevels = list(gProt = 1:6 * 30, Age = 60:100))
> plot(eff, lines=list(multiline=TRUE), x.var = "Age")
> 
> But this fails (note that Age is missing in xlevels):
> eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30))
> plot(eff, lines=list(multiline=TRUE), x.var = "Age")
> 
> 
> And that just led me to a solutution also for allEffects: Specifying
> Age in xlevels for allEffects (although it seems unnecessary when
> x.var = "Age" is used in plot) produces the correct graphical
> output! :-)
> 
> Thank you very much for your support and the brilliant effects
> package in general! :-)
> 
>  ?Best regards? --? Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109??????????? http://www.uni-giessen.de/eichner
> ---------------------------------------------------------------------
> 
> Am 09.11.2020 um 19:51 schrieb John Fox:
>> Dear Gerrit,
>>
>> This looks like a bug in plot.eff(), which I haven't yet tracked down, 
>> but the following should give you what you want:
>>
>> eff <- Effect(c("gProt", "Age"), m, xlevels = list(gProt = 1:6 * 30, 
>> Age=60:100))
>> plot(eff, lines=list(multiline=TRUE))
>>
>> or
>>
>> eff <- predictorEffect("Age", m, xlevels = list(gProt = 1:6 * 30))
>> plot(eff, lines=list(multiline=TRUE))
>>
>> A couple of comments on your code, unrelated to the bug in plot.eff():
>>
>> You don't need allEffects() because there's only one high-order fixed 
>> effect in the model, I(gProt/10 - 6.2):I(Age/10 - 7.2) (i.e., the 
>> interaction of gProt with Age).
>>
>> x.var isn't intended as an argument for plot() with allEffects() 
>> because there generally isn't a common horizontal axis for all of the 
>> high-order effect plots.
>>
>> Finally, thank you for the bug report. Barring unforeseen 
>> difficulties, we'll fix the bug in due course.
>>
>> I hope this helps,
>> ??John
>>
>> John Fox, Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> web: https://socialsciences.mcmaster.ca/jfox/
>>
>> On 2020-11-09 8:06 a.m., Gerrit Eichner wrote:
>>> Dear list members,
>>>
>>> I observe a strange/wrong graphical output when I set the xlevels
>>> in (e. g.) allEffects for an lmer model and plot the effects with
>>> multiline = TRUE. I have compiled a reprex for which you need the
>>> lmer model and the environment in which the model was fitted. They
>>> are contained in the zip file at
>>> https://jlubox.uni-giessen.de/dl/fiSzTCc3bW8z2npZvPpqG1xr/m-and-G1.zip
>>> After unpacking the following should work:
>>>
>>> m <- readRDS("m.rds")?? # The lmer-model.
>>> G1 <- readRDS("G1.rds") # Environment in which the model
>>> ????????????????????????? # was fitted; needed by alaEffects.
>>> summary(m) # Just to see the model.
>>>
>>> library(effects)
>>> aE <- allEffects(m, xlevels = list(gProt = 1:6 * 30))
>>> ????????????????????? # Non-default values for xlevels.
>>>
>>> plot(aE)????????????????????? # Fine.
>>> plot(aE, x.var = "Age")?????? # Fine.
>>> plot(aE, lines = list(multiline = TRUE))? # Fine.
>>>
>>> plot(aE, lines = list(multiline = TRUE),
>>> ?????? x.var = "Age")??????? # Nonsense.
>>>
>>>
>>> Anybody any idea about the reason, my mistake, or a
>>> workaround? Thx for any hint!
>>>
>>> ?? Regards? --? Gerrit
>>>
>>>
>>> PS:
>>> ??> sessionInfo()
>>> R version 4.0.2 (2020-06-22)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 18363)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=German_Germany.1252? LC_CTYPE=German_Germany.1252
>>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>>> [5] LC_TIME=German_Germany.1252
>>>
>>> attached base packages:
>>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>>>
>>> other attached packages:
>>> [1] effects_4.2-0 carData_3.0-4
>>>
>>> loaded via a namespace (and not attached):
>>> ?? [1] Rcpp_1.0.5?????? lattice_0.20-41? MASS_7.3-53????? grid_4.0.2 
>>> DBI_1.1.0
>>> ?? [6] nlme_3.1-149???? survey_4.0?????? estimability_1.3 minqa_1.2.4 
>>> nloptr_1.2.2.2
>>> [11] Matrix_1.2-18??? boot_1.3-25????? splines_4.0.2    
>>> statmod_1.4.34 lme4_1.1-23
>>> [16] tools_4.0.2????? survival_3.2-3?? yaml_2.2.1       
>>> compiler_4.0.2 colorspace_1.4-1
>>> [21] mitools_2.4????? insight_0.9.5??? nnet_7.3-14
>>>
>>> ---------------------------------------------------------------------
>>> Dr. Gerrit Eichner?????????????????? Mathematical Institute, Room 212
>>> gerrit.eichner at math.uni-giessen.de?? Justus-Liebig-University Giessen
>>> Tel: +49-(0)641-99-32104????????? Arndtstr. 2, 35392 Giessen, Germany
>>> http://www.uni-giessen.de/eichner
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From z|@d@e|mou@|y @end|ng |rom u@@metr|x|@b@com  Wed Nov 11 23:06:03 2020
From: z|@d@e|mou@|y @end|ng |rom u@@metr|x|@b@com (Ziad Elmously)
Date: Wed, 11 Nov 2020 22:06:03 +0000
Subject: [R] Error Message With the "MCMCmixfactanal" Function
Message-ID: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>

To Whom It May Concern,

In am using the script below to test the function "MAMCmixfactanal" in the package "MCMCpack".

library(MCMCpack)
data(PErisk)
post <- MCMCmixfactanal(~courts+barb2+prsexp2+prscorr2+gdpw2, factors=1, data=PErisk, lambda.constraints=
  list(courts=list(2,"-")),burnin=5000,mcmc=1000000,thin=50,verbose=500,L0=.25,store.lambda=TRUE,store.scores=TRUE,tune=1.2)
plot(post)
summary(post)

However, I get the error message below.

Acceptance rates:
Error in print.default(t(accepts)/(posterior$burnin + posterior$mcmc),  :
  invalid printing width

Your help would be greatly appreciated.

Kind regards,

Ziad Elmously
Director, Advanced Analytics & Data Science

MetrixLab, a Macromill Group company
Chalfont, PA, USA
T (+1) 267 298 1159 ? M (+1) 267 218 4724
ziad.elmously at us.metrixlab.com<mailto:ziad.elmously at us.metrixlab.com> ? www.metrixlab.com<http://www.metrixlab.com/>

How do you create a powerful packaging design?
Discover our 9 best practices. Read our whitepaper ><http://bit.ly/2sGPKEo>


	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Thu Nov 12 02:35:32 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Nov 2020 12:35:32 +1100
Subject: [R] please help with "could not find function "ComBat.mc" "
In-Reply-To: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>
References: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>
Message-ID: <CA+8X3fVKk0jKX9ZSCr5jc7s4Gugydr+A_T4oipBz2wJUSpLGhQ@mail.gmail.com>

Hi Yuan,
The package named "Enmix" is maintained on Bioconductor. It seems to be
specific to particular lab equipment and so all I can advise is:

1) Try your question on the Bioconductor help list
2) If no help there contact Zongli Xu (the maintainer)

Jim

On Thu, Nov 12, 2020 at 11:40 AM Yuan Chun Ding <ycding at coh.org> wrote:

>
> Hi All,
>
> I am very sorry to bother you.
>
> This week, I updated my R from 3.5.3  to 4.0.3, reinstalled all required R
> packages  and reran the following R code;  then got the following error:
> could not find function "ComBat.mc".
>
> > #' firstly Removing chip-well batch effects using ComBat from the sva
> package
> > # First we convert from beta-values to M-values
> > Mvals1 <- log2(betas.rcp)-log2(1-betas.rcp)
> > #' ComBat eBayes adjustment using a known variable of interest (here we
> use row)
> > Mvals.ComBat1 <- ComBat.mc(Mvals1, batch = pData(WB.noob)$Array,nCores =
> detectCores()-1)
> Error in ComBat.mc(Mvals1, batch = pData(WB.noob)$Array, nCores =
> detectCores() -  :
>   could not find function "ComBat.mc"
>
> I have successfully run the same R code with same data sets several times
> since 2017.  Google searching tells me that this ComBat.mc function is from
> an R package "Enmix".  When typing library(Enmix), no error message, so the
> Enmix library is installed.  Can you tell me why I got this error after
> updating to new R version?
>
> Thank you,
>
> Yuan Chun Ding
>
> ----------------------------------------------------------------------
> ------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
>
> This message and any attachments are intended solely for the individual or
> entity to which they are addressed. This communication may contain
> information that is privileged, confidential, or exempt from disclosure
> under applicable law (e.g., personal health information, research data,
> financial information). Because this e-mail has been sent without
> encryption, individuals other than the intended recipient may be able to
> view the information, forward it to others or tamper with the information
> without the knowledge or consent of the sender. If you are not the intended
> recipient, or the employee or person responsible for delivering the message
> to the intended recipient, any dissemination, distribution or copying of
> the communication is strictly prohibited. If you received the communication
> in error, please notify the sender immediately by replying to this message
> and deleting the message and any accompanying files from your system. If,
> due to the security risks, you do not wish to receive further
> communications via e-mail, please reply to this message and inform the
> sender that you do not wish to receive further e-mail from the sender.
> (LCP301)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Nov 12 03:03:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 11 Nov 2020 18:03:54 -0800
Subject: [R] Error Message With the "MCMCmixfactanal" Function
In-Reply-To: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
References: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
Message-ID: <CAGxFJbSTcaX0AMioHOoThA0r=U8CP7UWJ0Ekh8-5CPWkfiX4AQ@mail.gmail.com>

Please read and follow the posting guide linked below, especially this:

"For questions about functions in standard packages distributed with R (see
the FAQ Add-on packages in R
<http://cran.r-project.org/doc/FAQ/R-FAQ.html#Add-on-packages-in-R>), ask
questions on R-help.
If the question relates to a *contributed package* , e.g., one downloaded
from CRAN, try contacting the package maintainer first. You can also use
find("functionname") and packageDescription("packagename") to find this
information. *Only* send such questions to R-help or R-devel if you get no
reply or need further assistance. This applies to both requests for help
and to bug reports. "

Note: also ?maintainer for finding emails of maintainers.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Nov 11, 2020 at 5:30 PM Ziad Elmously <
ziad.elmously at us.metrixlab.com> wrote:

> To Whom It May Concern,
>
> In am using the script below to test the function "MAMCmixfactanal" in the
> package "MCMCpack".
>
> library(MCMCpack)
> data(PErisk)
> post <- MCMCmixfactanal(~courts+barb2+prsexp2+prscorr2+gdpw2, factors=1,
> data=PErisk, lambda.constraints=
>
> list(courts=list(2,"-")),burnin=5000,mcmc=1000000,thin=50,verbose=500,L0=.25,store.lambda=TRUE,store.scores=TRUE,tune=1.2)
> plot(post)
> summary(post)
>
> However, I get the error message below.
>
> Acceptance rates:
> Error in print.default(t(accepts)/(posterior$burnin + posterior$mcmc),  :
>   invalid printing width
>
> Your help would be greatly appreciated.
>
> Kind regards,
>
> Ziad Elmously
> Director, Advanced Analytics & Data Science
>
> MetrixLab, a Macromill Group company
> Chalfont, PA, USA
> T (+1) 267 298 1159   M (+1) 267 218 4724
> ziad.elmously at us.metrixlab.com<mailto:ziad.elmously at us.metrixlab.com>
> www.metrixlab.com<http://www.metrixlab.com/>
>
> How do you create a powerful packaging design?
> Discover our 9 best practices. Read our whitepaper ><http://bit.ly/2sGPKEo
> >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Nov 12 03:14:15 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 11 Nov 2020 18:14:15 -0800
Subject: [R] ggplot2 stat_smooth formula different units
In-Reply-To: <20201111221120.GB33352@localhost>
References: <20201111221120.GB33352@localhost>
Message-ID: <21450fcf-7386-670f-7d3c-b0aafd1fd771@comcast.net>


On 11/11/20 2:11 PM, Marcelo Laia wrote:
> Hi,
>
> I am running these approaches:
>
> Model 1
>
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = y ~ x + I(x^2), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")
>
> Model 2
>
> ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
>      geom_point(size=0.5) +
>      stat_smooth(method = "lm",
>                  formula = I(log(y)) ~ I(1/x), size = 1) +
>      facet_grid(Espacamento ~ Clone) +
>      theme(legend.position="none")

Removing the I(.) calls has no effect.

I think you should reshape that formula to the equivalent form with no 
transformation on the LHS:


ggplot( dat , aes(x=DAP, y=Altura, color=as.factor(Espacamento) )) +
 ??? geom_point(size=0.5) +
 ??? stat_smooth(method = "lm",
 ??????????????? formula = y ~ exp(1/x), size = 1) +
 ??? facet_grid(Espacamento ~ Clone) +
 ??? theme(legend.position="none")


-- 

David.

>
> In model 1, both, original variables and fitted variables are plotted
> in the same units.
>
> However, in the second one, points is plotted in the original variable,
> instead of fitted variables. I know that
>
> exp(fitted(model2))
>
> do the trick and return the variables to the original units.
>
> But, I don't know how I do this in the stat_smooth function.
>
> Please, have you a tip for help me?
>
> Thank you!
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Nov 12 03:18:56 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 11 Nov 2020 18:18:56 -0800
Subject: [R] Error Message With the "MCMCmixfactanal" Function
In-Reply-To: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
References: <MN2PR14MB2975F40377EB80DEEB484A96CDE80@MN2PR14MB2975.namprd14.prod.outlook.com>
Message-ID: <4F1A4DD6-C62E-4069-8777-07309BACA075@dcn.davis.ca.us>

Someone may feel like tackling this anyway, but technically it is off-topic here, as this forum is about the R language rather than specific contributed packages. (http://www.r-project.org/posting-guide.html). Lookup the package DESCRIPTION file on CRAN and if it does not mention a recommended support forum then correspond with the package maintainer.

On November 11, 2020 2:06:03 PM PST, Ziad Elmously <ziad.elmously at us.metrixlab.com> wrote:
>To Whom It May Concern,
>
>In am using the script below to test the function "MAMCmixfactanal" in
>the package "MCMCpack".
>
>library(MCMCpack)
>data(PErisk)
>post <- MCMCmixfactanal(~courts+barb2+prsexp2+prscorr2+gdpw2,
>factors=1, data=PErisk, lambda.constraints=
>list(courts=list(2,"-")),burnin=5000,mcmc=1000000,thin=50,verbose=500,L0=.25,store.lambda=TRUE,store.scores=TRUE,tune=1.2)
>plot(post)
>summary(post)
>
>However, I get the error message below.
>
>Acceptance rates:
>Error in print.default(t(accepts)/(posterior$burnin + posterior$mcmc), 
>:
>  invalid printing width
>
>Your help would be greatly appreciated.
>
>Kind regards,
>
>Ziad Elmously
>Director, Advanced Analytics & Data Science
>
>MetrixLab, a Macromill Group company
>Chalfont, PA, USA
>T (+1) 267 298 1159 ? M (+1) 267 218 4724
>ziad.elmously at us.metrixlab.com<mailto:ziad.elmously at us.metrixlab.com> ?
>www.metrixlab.com<http://www.metrixlab.com/>
>
>How do you create a powerful packaging design?
>Discover our 9 best practices. Read our whitepaper
>><http://bit.ly/2sGPKEo>
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From phii m@iii@g oii phiiipsmith@c@  Thu Nov 12 04:25:27 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Wed, 11 Nov 2020 22:25:27 -0500
Subject: [R] Data transformation problem
Message-ID: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>

I am stuck on a data transformation problem. I have a data frame, df1 in 
my example, with some original "levels" data. The data pertain to some 
variable, such as GDP, in various reference periods, REF, as estimated 
and released in various release periods, REL. The release periods follow 
after the reference periods by two months or more, sometimes by several 
years. I want to build a second data frame, called df2 in my example, 
with the month-to-month growth rates that existed in each reference 
period, revealing the revisions to those growth rates in subsequent 
periods.

REF1 <- 
c("2017-01-01","2017-01-01","2017-01-01","2017-01-01","2017-01-01",
   "2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
   "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
REL1 <- 
c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
   "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
   "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
VAL1 <- 
c(17974,14567,13425,NA,12900,17974,14000,14000,12999,13245,17197,11500,
   19900,18765,13467)
df1 <- data.frame(REF1,REL1,VAL1)
REF2 <- 
c("2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
   "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
REL2 <- 
c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
   "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
VAL2 <- c(0.0,-3.9,4.3,NA,2.3,-4.3,-17.9,42.1,44.4,1.7)
df2 <- data.frame(REF2,REL2,VAL2)

In my example I have provided some sample data pertaining to three 
reference months, 2017-01-01 through 2017-03-01, and five release 
periods, "2020-09-01","2020-08-01","2020-07-01","2020-06-01" and 
"2019-05-01". In my actual problem I have millions of REF-REL 
combinations, so my data frame is quite large. I am using data.table for 
faster processing, though I am more familiar with the tidyverse. I am 
providing df2 as the target data frame for my example, so you can see 
what I am trying to achieve.

I have not been able to find an efficient way to do these calculations. 
I have tried "for" loops with "if" statements, without success so far, 
and anyway this approach would be too slow, I fear. Suggestions as to 
how I might proceed would be much appreciated.

Philip


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Nov 12 08:20:32 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 11 Nov 2020 23:20:32 -0800 (PST)
Subject: [R] Data transformation problem
In-Reply-To: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>
References: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>
Message-ID: <alpine.BSF.2.00.2011112314400.36172@pedal.dcn.davis.ca.us>

I am not a data.table afficiando, but here is how I would do it with 
dplyr/tidyr:

library(dplyr)
library(tidyr)

do_per_REL <- function( DF ) {
   rng <- range( DF$REF1 ) # watch out for missing months?
   DF <- (   data.frame( REF1 = seq( rng[ 1 ], rng[ 2 ], by = "month" ) )
         %>% left_join( DF, by = "REF1" )
         %>% arrange( REF1 )
         )
   with( DF
       , data.frame( REF2 = REF1[ -1 ]
                   , VAL2 = 100 * diff( VAL1 ) / VAL1[ -length( VAL1 ) ]
                   )
       )
}

df2a <- (   df1
         %>% mutate( REF1 = as.Date( REF1 )
                   , REL1 = as.Date( REL1 )
                   )
         %>% nest( data = -REL1 )
         %>% rename( REL2 = REL1 )
         %>% rowwise()
         %>% mutate( data = list( do_per_REL( data ) ) )
         %>% ungroup()
         %>% unnest( cols = "data" )
         %>% select( REF2, REL2, VAL2 )
         %>% arrange( REF2, desc( REL2 ), VAL2 )
         )
df2a

On Wed, 11 Nov 2020, phil at philipsmith.ca wrote:

> I am stuck on a data transformation problem. I have a data frame, df1 in my 
> example, with some original "levels" data. The data pertain to some variable, 
> such as GDP, in various reference periods, REF, as estimated and released in 
> various release periods, REL. The release periods follow after the reference 
> periods by two months or more, sometimes by several years. I want to build a 
> second data frame, called df2 in my example, with the month-to-month growth 
> rates that existed in each reference period, revealing the revisions to those 
> growth rates in subsequent periods.
>
> REF1 <- c("2017-01-01","2017-01-01","2017-01-01","2017-01-01","2017-01-01",
>  "2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
> REL1 <- c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
> VAL1 <- 
> c(17974,14567,13425,NA,12900,17974,14000,14000,12999,13245,17197,11500,
>  19900,18765,13467)
> df1 <- data.frame(REF1,REL1,VAL1)
> REF2 <- c("2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
> REL2 <- c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
> VAL2 <- c(0.0,-3.9,4.3,NA,2.3,-4.3,-17.9,42.1,44.4,1.7)
> df2 <- data.frame(REF2,REL2,VAL2)
>
> In my example I have provided some sample data pertaining to three reference 
> months, 2017-01-01 through 2017-03-01, and five release periods, 
> "2020-09-01","2020-08-01","2020-07-01","2020-06-01" and "2019-05-01". In my 
> actual problem I have millions of REF-REL combinations, so my data frame is 
> quite large. I am using data.table for faster processing, though I am more 
> familiar with the tidyverse. I am providing df2 as the target data frame for 
> my example, so you can see what I am trying to achieve.
>
> I have not been able to find an efficient way to do these calculations. I 
> have tried "for" loops with "if" statements, without success so far, and 
> anyway this approach would be too slow, I fear. Suggestions as to how I might 
> proceed would be much appreciated.
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From phii m@iii@g oii phiiipsmith@c@  Thu Nov 12 13:23:34 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Thu, 12 Nov 2020 07:23:34 -0500
Subject: [R] Data transformation problem
In-Reply-To: <alpine.BSF.2.00.2011112314400.36172@pedal.dcn.davis.ca.us>
References: <1cea8da18f039c65f3d8b5640d621a31@philipsmith.ca>
 <alpine.BSF.2.00.2011112314400.36172@pedal.dcn.davis.ca.us>
Message-ID: <73f34267eb874bcdc99c5fbd0273d2e1@philipsmith.ca>

Thank you so much for this elegant solution, Jeff.

Philip

On 2020-11-12 02:20, Jeff Newmiller wrote:
> I am not a data.table afficiando, but here is how I would do it with
> dplyr/tidyr:
> 
> library(dplyr)
> library(tidyr)
> 
> do_per_REL <- function( DF ) {
>   rng <- range( DF$REF1 ) # watch out for missing months?
>   DF <- (   data.frame( REF1 = seq( rng[ 1 ], rng[ 2 ], by = "month" ) 
> )
>         %>% left_join( DF, by = "REF1" )
>         %>% arrange( REF1 )
>         )
>   with( DF
>       , data.frame( REF2 = REF1[ -1 ]
>                   , VAL2 = 100 * diff( VAL1 ) / VAL1[ -length( VAL1 ) ]
>                   )
>       )
> }
> 
> df2a <- (   df1
>         %>% mutate( REF1 = as.Date( REF1 )
>                   , REL1 = as.Date( REL1 )
>                   )
>         %>% nest( data = -REL1 )
>         %>% rename( REL2 = REL1 )
>         %>% rowwise()
>         %>% mutate( data = list( do_per_REL( data ) ) )
>         %>% ungroup()
>         %>% unnest( cols = "data" )
>         %>% select( REF2, REL2, VAL2 )
>         %>% arrange( REF2, desc( REL2 ), VAL2 )
>         )
> df2a
> 
> On Wed, 11 Nov 2020, phil at philipsmith.ca wrote:
> 
>> I am stuck on a data transformation problem. I have a data frame, df1 
>> in my example, with some original "levels" data. The data pertain to 
>> some variable, such as GDP, in various reference periods, REF, as 
>> estimated and released in various release periods, REL. The release 
>> periods follow after the reference periods by two months or more, 
>> sometimes by several years. I want to build a second data frame, 
>> called df2 in my example, with the month-to-month growth rates that 
>> existed in each reference period, revealing the revisions to those 
>> growth rates in subsequent periods.
>> 
>> REF1 <- 
>> c("2017-01-01","2017-01-01","2017-01-01","2017-01-01","2017-01-01",
>>  "2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
>> REL1 <- 
>> c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
>> VAL1 <- 
>> c(17974,14567,13425,NA,12900,17974,14000,14000,12999,13245,17197,11500,
>>  19900,18765,13467)
>> df1 <- data.frame(REF1,REL1,VAL1)
>> REF2 <- 
>> c("2017-02-01","2017-02-01","2017-02-01","2017-02-01","2017-02-01",
>>  "2017-03-01","2017-03-01","2017-03-01","2017-03-01","2017-03-01")
>> REL2 <- 
>> c("2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01",
>>  "2020-09-01","2020-08-01","2020-07-01","2020-06-01","2019-05-01")
>> VAL2 <- c(0.0,-3.9,4.3,NA,2.3,-4.3,-17.9,42.1,44.4,1.7)
>> df2 <- data.frame(REF2,REL2,VAL2)
>> 
>> In my example I have provided some sample data pertaining to three 
>> reference months, 2017-01-01 through 2017-03-01, and five release 
>> periods, "2020-09-01","2020-08-01","2020-07-01","2020-06-01" and 
>> "2019-05-01". In my actual problem I have millions of REF-REL 
>> combinations, so my data frame is quite large. I am using data.table 
>> for faster processing, though I am more familiar with the tidyverse. I 
>> am providing df2 as the target data frame for my example, so you can 
>> see what I am trying to achieve.
>> 
>> I have not been able to find an efficient way to do these 
>> calculations. I have tried "for" loops with "if" statements, without 
>> success so far, and anyway this approach would be too slow, I fear. 
>> Suggestions as to how I might proceed would be much appreciated.
>> 
>> Philip
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go 
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live 
> Go...
>                                       Live:   OO#.. Dead: OO#..  
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  
> rocks...1k
> ---------------------------------------------------------------------------


From ycd|ng @end|ng |rom coh@org  Thu Nov 12 18:41:49 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Thu, 12 Nov 2020 17:41:49 +0000
Subject: [R] please help with "could not find function "ComBat.mc" "
In-Reply-To: <CA+8X3fVKk0jKX9ZSCr5jc7s4Gugydr+A_T4oipBz2wJUSpLGhQ@mail.gmail.com>
References: <CH2PR02MB6069C5F94AAF00DBA88F62D9D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>
 <CA+8X3fVKk0jKX9ZSCr5jc7s4Gugydr+A_T4oipBz2wJUSpLGhQ@mail.gmail.com>
Message-ID: <CH2PR02MB60696B8D66862F09BD3C0DC1D4E70@CH2PR02MB6069.namprd02.prod.outlook.com>

Hi Jim,

Thank you for the message!  Yes, you are right, I contacted Dr. Xu Zongli,  he said he removed the ComBat.mc function from the new version.

Ding

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Wednesday, November 11, 2020 5:36 PM
To: Yuan Chun Ding <ycding at coh.org>
Cc: r-help at r-project.org
Subject: Re: [R] please help with "could not find function "ComBat.mc" "

Hi Yuan,
The package named "Enmix" is maintained on Bioconductor. It seems to be specific to particular lab equipment and so all I can advise is:

1) Try your question on the Bioconductor help list
2) If no help there contact Zongli Xu (the maintainer)

Jim

On Thu, Nov 12, 2020 at 11:40 AM Yuan Chun Ding <ycding at coh.org<mailto:ycding at coh.org>> wrote:

Hi All,

I am very sorry to bother you.

This week, I updated my R from 3.5.3  to 4.0.3, reinstalled all required R packages  and reran the following R code;  then got the following error: could not find function "ComBat.mc".

> #' firstly Removing chip-well batch effects using ComBat from the sva package
> # First we convert from beta-values to M-values
> Mvals1 <- log2(betas.rcp)-log2(1-betas.rcp)
> #' ComBat eBayes adjustment using a known variable of interest (here we use row)
> Mvals.ComBat1 <- ComBat.mc(Mvals1, batch = pData(WB.noob)$Array,nCores = detectCores()-1)
Error in ComBat.mc(Mvals1, batch = pData(WB.noob)$Array, nCores = detectCores() -  :
  could not find function "ComBat.mc"

I have successfully run the same R code with same data sets several times since 2017.  Google searching tells me that this ComBat.mc function is from an R package "Enmix".  When typing library(Enmix), no error message, so the Enmix library is installed.  Can you tell me why I got this error after updating to new R version?

Thank you,

Yuan Chun Ding

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://urldefense.com/v3/__https:/stat.ethz.ch/mailman/listinfo/r-help__;!!Fou38LsQmgU!7LIBMZ-Dl-TUctBxHgefJtTy8Nam0_pdDxu6OlxC4fddmXLyFrFFNr_sX0eD$>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<https://urldefense.com/v3/__http:/www.R-project.org/posting-guide.html__;!!Fou38LsQmgU!7LIBMZ-Dl-TUctBxHgefJtTy8Nam0_pdDxu6OlxC4fddmXLyFrFFNuvLUbzY$>
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Fri Nov 13 10:59:48 2020
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Fri, 13 Nov 2020 18:59:48 +0900
Subject: [R] find local max in moving window
Message-ID: <CAHXS41yGAVSowy5dMSJ68doPZ5Ha-jnCkd-PB8D1ty1ZBgeGcA@mail.gmail.com>

Dear r list,

I try to locate any local max value and location of data that follow 7
moving window condition, meaning that this data is largest and
centered in 7 values to the left and 7 values to the right. I can
solve it by using for and if function, like below:

dput(nordn)
c(`1` = 36.3167318892351, `2` = 13.6970407938013, `3` = 24.8984180253768,
`4` = -17.6647224450612, `5` = -7.57647505851449, `6` = -25.2496137259847,
`7` = -2.01332893598408, `8` = -7.69519958042397, `9` = -8.26353826728723,
`10` = -0.711578256473814, `11` = -9.49356104351281, `12` = -2.85486263863268,
`13` = 3.34926923529002, `14` = -31.4961884481779, `15` = -26.1167714774709,
`16` = -42.6411928687283, `17` = -38.0270384442816, `18` = -11.131459061204,
`19` = -23.622369248939, `20` = -3.64517202744244, `21` = 29.9049425605881,
`22` = 32.8660637407913, `23` = 37.5996245139886, `24` = 40.0028071315676,
`25` = 42.1488678067843, `26` = 29.898734204143, `27` = 31.5737226769497,
`28` = 17.1072348768252, `29` = 18.3678580553113, `30` = 2.99488592118706,
`31` = 17.5268614959386, `32` = 4.63931611503325, `33` = 0.780891049248694,
`34` = 1.2451803667649, `35` = -17.4138837461862, `36` = -17.1764836997295,
`37` = -18.9385526336078, `38` = -18.8785134814426, `39` = -18.8892579027502,
`40` = -17.05939841442, `41` = -17.1773872762212, `42` = -13.9956678436841,
`43` = -25.1754328292478, `44` = -14.3751251170127, `45` = -5.72211699349243,
`46` = -5.92331095941663, `47` = 5.70799013331376, `48` = 5.53987608486618,
`49` = 9.93527336363547, `50` = 9.83337030810877, `51` = 9.77591432958593,
`52` = 20.4486541160032, `53` = 20.5004918014168, `54` = 17.2771628653508,
`55` = 14.4829910263769, `56` = 17.7218103830368, `57` = 11.5422494691249,
`58` = 11.9634243026261, `59` = 6.45278534199771, `60` = 7.04912282719943,
`61` = -9.36267510164784, `62` = -8.58224224917278, `63` = -7.70790082260233,
`64` = -23.4156448928377, `65` = -22.3528607985815, `66` = -20.6638955663105,
`67` = -22.8623707541409, `68` = -18.0788043293803, `69` = -21.1362290377644,
`70` = -19.6291679260569, `71` = -18.4864526754101, `72` = -16.8268389833748,
`73` = -1.86517468137026e-13, `74` = -1.86517468137026e-13, `75` =
-1.86517468137026e-13,
`76` = -1.86517468137026e-13, `77` = -1.86517468137026e-13, `78` =
-1.86517468137026e-13,
`79` = -1.86517468137026e-13, `80` = -1.86517468137026e-13, `81` =
-1.86517468137026e-13,
`82` = -1.86517468137026e-13, `83` = -1.86517468137026e-13, `84` =
-1.86517468137026e-13,
`85` = -1.86517468137026e-13, `86` = -1.86517468137026e-13, `87` =
-1.86517468137026e-13,
`88` = 119.769379215677, `89` = 121.143950270482, `90` = -3.3158245341025,
`91` = -2.27565861892447, `92` = -4.73724890799339, `93` = -1.99736436960567,
`94` = -3.75331767972433, `95` = -5.95256351982827, `96` = -6.15867775456779,
`97` = -10.6570276388287, `98` = -11.5475819732368, `99` = -12.8244899190047,
`100` = -7.67798939908287, `101` = -9.82140578284223, `102` = -9.59888007628085,
`103` = -12.7414099822392, `104` = -22.3056908542011, `105` = -12.0279597037476,
`106` = -31.499265969641, `107` = -1.86517468137026e-13, `108` =
-1.86517468137026e-13,
`109` = -1.86517468137026e-13, `110` = -1.86517468137026e-13,
`111` = -1.86517468137026e-13, `112` = -1.86517468137026e-13,
`113` = -1.86517468137026e-13, `114` = -1.86517468137026e-13,
`115` = -1.86517468137026e-13, `116` = -1.86517468137026e-13,
`117` = 32.862745948818, `118` = -1.86517468137026e-13)


position<-matrix(NA,118,2)
for (i in 7:(length(nordn)-7)){
  if (nordn[i]>nordn[i+1]&&
      nordn[i]>nordn[i+2]&&
      nordn[i]>nordn[i+3]&&
      nordn[i]>nordn[i+4]&&
      nordn[i]>nordn[i+5]&&
      nordn[i]>nordn[i+6]&&
      nordn[i]>nordn[i+7]&&
      nordn[i]>nordn[i-7]&&
      nordn[i]>nordn[i-6]&&
      nordn[i]>nordn[i-5]&&
      nordn[i]>nordn[i-4]&&
      nordn[i]>nordn[i-3]&&
      nordn[i]>nordn[i-2]&&
      nordn[i]>nordn[i-1]){
  position[i,1]<-nordn[i]
  position[i,2]<-i
    }
  }

Is there any straight way or lead or function should I check? And can
I just get the value and the position without storing NA value? Thank
you.

Ani


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Nov 13 11:28:55 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 13 Nov 2020 10:28:55 +0000
Subject: [R] find local max in moving window
In-Reply-To: <CAHXS41yGAVSowy5dMSJ68doPZ5Ha-jnCkd-PB8D1ty1ZBgeGcA@mail.gmail.com>
References: <CAHXS41yGAVSowy5dMSJ68doPZ5Ha-jnCkd-PB8D1ty1ZBgeGcA@mail.gmail.com>
Message-ID: <a3f245d1-219f-c405-ac4a-64502dd4e869@sapo.pt>

Hello,

The best option is package zoo, function(s) rollapply.


p <- zoo::rollapply(nordn, width = 15, FUN = max, fill = c(NA, 0, NA))


These are meant as checks, see the differences between the one-liner 
above and your result.

dim(position)
length(p)

w <- which(position[, 1] == p)
position[w, ]



Hope this helps,

Rui Barradas


?s 09:59 de 13/11/20, ani jaya escreveu:
> Dear r list,
> 
> I try to locate any local max value and location of data that follow 7
> moving window condition, meaning that this data is largest and
> centered in 7 values to the left and 7 values to the right. I can
> solve it by using for and if function, like below:
> 
> dput(nordn)
> c(`1` = 36.3167318892351, `2` = 13.6970407938013, `3` = 24.8984180253768,
> `4` = -17.6647224450612, `5` = -7.57647505851449, `6` = -25.2496137259847,
> `7` = -2.01332893598408, `8` = -7.69519958042397, `9` = -8.26353826728723,
> `10` = -0.711578256473814, `11` = -9.49356104351281, `12` = -2.85486263863268,
> `13` = 3.34926923529002, `14` = -31.4961884481779, `15` = -26.1167714774709,
> `16` = -42.6411928687283, `17` = -38.0270384442816, `18` = -11.131459061204,
> `19` = -23.622369248939, `20` = -3.64517202744244, `21` = 29.9049425605881,
> `22` = 32.8660637407913, `23` = 37.5996245139886, `24` = 40.0028071315676,
> `25` = 42.1488678067843, `26` = 29.898734204143, `27` = 31.5737226769497,
> `28` = 17.1072348768252, `29` = 18.3678580553113, `30` = 2.99488592118706,
> `31` = 17.5268614959386, `32` = 4.63931611503325, `33` = 0.780891049248694,
> `34` = 1.2451803667649, `35` = -17.4138837461862, `36` = -17.1764836997295,
> `37` = -18.9385526336078, `38` = -18.8785134814426, `39` = -18.8892579027502,
> `40` = -17.05939841442, `41` = -17.1773872762212, `42` = -13.9956678436841,
> `43` = -25.1754328292478, `44` = -14.3751251170127, `45` = -5.72211699349243,
> `46` = -5.92331095941663, `47` = 5.70799013331376, `48` = 5.53987608486618,
> `49` = 9.93527336363547, `50` = 9.83337030810877, `51` = 9.77591432958593,
> `52` = 20.4486541160032, `53` = 20.5004918014168, `54` = 17.2771628653508,
> `55` = 14.4829910263769, `56` = 17.7218103830368, `57` = 11.5422494691249,
> `58` = 11.9634243026261, `59` = 6.45278534199771, `60` = 7.04912282719943,
> `61` = -9.36267510164784, `62` = -8.58224224917278, `63` = -7.70790082260233,
> `64` = -23.4156448928377, `65` = -22.3528607985815, `66` = -20.6638955663105,
> `67` = -22.8623707541409, `68` = -18.0788043293803, `69` = -21.1362290377644,
> `70` = -19.6291679260569, `71` = -18.4864526754101, `72` = -16.8268389833748,
> `73` = -1.86517468137026e-13, `74` = -1.86517468137026e-13, `75` =
> -1.86517468137026e-13,
> `76` = -1.86517468137026e-13, `77` = -1.86517468137026e-13, `78` =
> -1.86517468137026e-13,
> `79` = -1.86517468137026e-13, `80` = -1.86517468137026e-13, `81` =
> -1.86517468137026e-13,
> `82` = -1.86517468137026e-13, `83` = -1.86517468137026e-13, `84` =
> -1.86517468137026e-13,
> `85` = -1.86517468137026e-13, `86` = -1.86517468137026e-13, `87` =
> -1.86517468137026e-13,
> `88` = 119.769379215677, `89` = 121.143950270482, `90` = -3.3158245341025,
> `91` = -2.27565861892447, `92` = -4.73724890799339, `93` = -1.99736436960567,
> `94` = -3.75331767972433, `95` = -5.95256351982827, `96` = -6.15867775456779,
> `97` = -10.6570276388287, `98` = -11.5475819732368, `99` = -12.8244899190047,
> `100` = -7.67798939908287, `101` = -9.82140578284223, `102` = -9.59888007628085,
> `103` = -12.7414099822392, `104` = -22.3056908542011, `105` = -12.0279597037476,
> `106` = -31.499265969641, `107` = -1.86517468137026e-13, `108` =
> -1.86517468137026e-13,
> `109` = -1.86517468137026e-13, `110` = -1.86517468137026e-13,
> `111` = -1.86517468137026e-13, `112` = -1.86517468137026e-13,
> `113` = -1.86517468137026e-13, `114` = -1.86517468137026e-13,
> `115` = -1.86517468137026e-13, `116` = -1.86517468137026e-13,
> `117` = 32.862745948818, `118` = -1.86517468137026e-13)
> 
> 
> position<-matrix(NA,118,2)
> for (i in 7:(length(nordn)-7)){
>    if (nordn[i]>nordn[i+1]&&
>        nordn[i]>nordn[i+2]&&
>        nordn[i]>nordn[i+3]&&
>        nordn[i]>nordn[i+4]&&
>        nordn[i]>nordn[i+5]&&
>        nordn[i]>nordn[i+6]&&
>        nordn[i]>nordn[i+7]&&
>        nordn[i]>nordn[i-7]&&
>        nordn[i]>nordn[i-6]&&
>        nordn[i]>nordn[i-5]&&
>        nordn[i]>nordn[i-4]&&
>        nordn[i]>nordn[i-3]&&
>        nordn[i]>nordn[i-2]&&
>        nordn[i]>nordn[i-1]){
>    position[i,1]<-nordn[i]
>    position[i,2]<-i
>      }
>    }
> 
> Is there any straight way or lead or function should I check? And can
> I just get the value and the position without storing NA value? Thank
> you.
> 
> Ani
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Fri Nov 13 23:04:20 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Fri, 13 Nov 2020 22:04:20 +0000 (UTC)
Subject: [R] "NaN" answer don't understand why
References: <1304056825.9448168.1605305060839.ref@mail.yahoo.com>
Message-ID: <1304056825.9448168.1605305060839@mail.yahoo.com>

Dear R-experts,

Here below my reproducible example. No error message but I can not get a result. I get "NaN" as a result. I don't understand what is going on. Many thanks for your precious help, as usual.


?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#
x<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
y<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)

library(robustgam)
true.family <- poisson()

#Robust GAM
fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)

#OLS
fit1 <- lm(y~x)

#Huber-M
library(robustbase)
library(MASS)
fit2=rlm(y~x)

#GAM
library(mgcv)
fit3=gam(y~s(x))

# MSE of OLS linear model
mean(residuals(fit1)^2)

# MSE of Huber-M linear model
mean(residuals(fit2)^2)

# MSE of GAM
mean(residuals(fit3)^2)

# MSE of robust GAM
mean(residuals(fit)^2)
?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#?#
?


From w||||@mwdun|@p @end|ng |rom gm@||@com  Sat Nov 14 00:16:58 2020
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 13 Nov 2020 15:16:58 -0800
Subject: [R] "NaN" answer don't understand why
In-Reply-To: <1304056825.9448168.1605305060839@mail.yahoo.com>
References: <1304056825.9448168.1605305060839.ref@mail.yahoo.com>
 <1304056825.9448168.1605305060839@mail.yahoo.com>
Message-ID: <CAHqSRuSquu2gy582AxVArTAsn+onH6tSgKocY98zRBKTr0DRUQ@mail.gmail.com>

fit <- robustgam::robustgam(...) produces a list, with no class attached,
so residuals(fit) invokes the default method for residuals(), which
essentially returns the 'residuals' component of 'fit'.  There is no such
component so it returns NULL, an object of length zero.  The mean of a
length-zero object is NaN.

It would make sense for mean(NULL) or sum(NULL) to give an error since they
are only meant to work on numbers.  However this would probably break some
existing code, since there are various functions that return NULL instead
of numeric(0).

-Bill

On Fri, Nov 13, 2020 at 2:05 PM varin sacha via R-help <r-help at r-project.org>
wrote:

> Dear R-experts,
>
> Here below my reproducible example. No error message but I can not get a
> result. I get "NaN" as a result. I don't understand what is going on. Many
> thanks for your precious help, as usual.
>
>
>  # # # # # # # # # # # # # # # # # # # # # # # # #
>
> x<-c(499,491,500,517,438,495,501,525,516,494,500,453,479,481,505,465,477,520,520,480,477,416,502,503,497,513,492,469,504,482,502,498,463,504,495)
>
> y<-c(499,496,424,537,480,484,503,575,540,436,486,506,496,481,508,425,501,519,546,507,452,498,471,495,499,522,509,474,502,534,504,466,527,485,525)
>
> library(robustgam)
> true.family <- poisson()
>
> #Robust GAM
> fit=robustgam(x,y,sp=0,family=true.family,smooth.basis='ps',K=3)
>
> #OLS
> fit1 <- lm(y~x)
>
> #Huber-M
> library(robustbase)
> library(MASS)
> fit2=rlm(y~x)
>
> #GAM
> library(mgcv)
> fit3=gam(y~s(x))
>
> # MSE of OLS linear model
> mean(residuals(fit1)^2)
>
> # MSE of Huber-M linear model
> mean(residuals(fit2)^2)
>
> # MSE of GAM
> mean(residuals(fit3)^2)
>
> # MSE of robust GAM
> mean(residuals(fit)^2)
>  # # # # # # # # # # # # # # # # # # # # # # # # #
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From you@r|@|@nou@ @end|ng |rom gm@||@com  Sat Nov 14 02:44:46 2020
From: you@r|@|@nou@ @end|ng |rom gm@||@com (Yousri Fanous)
Date: Fri, 13 Nov 2020 20:44:46 -0500
Subject: [R] long integer handling
Message-ID: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>

I want to calculate 2^64-1 which is
18446744073709551615

I set the following options to prevent scientific notation
options("scipen"=100, "digits"=4)
> x<-2^64 -1
> x
[1] 18446744073709551616

This is not correct. There seem to be still some approximation happening.
How can I get the correct result?

Yousri
IBM Canada ltd
Software developer

	[[alternative HTML version deleted]]


From jrg @end|ng |rom |oe@|@u@  Sat Nov 14 02:54:33 2020
From: jrg @end|ng |rom |oe@|@u@ (JRG)
Date: Fri, 13 Nov 2020 20:54:33 -0500
Subject: [R] long integer handling
In-Reply-To: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
Message-ID: <5704f5f8-13ba-21da-ccf5-f28c5e313115@loesl.us>

The largest consecutive integer that can be represented in double
precision is 2^53.

You'll have to move past double precision.

---JRG



On 2020-11-13 20:44, Yousri Fanous wrote:
> I want to calculate 2^64-1 which is
> 18446744073709551615
> 
> I set the following options to prevent scientific notation
> options("scipen"=100, "digits"=4)
>> x<-2^64 -1
>> x
> [1] 18446744073709551616
> 
> This is not correct. There seem to be still some approximation happening.
> How can I get the correct result?
> 
> Yousri
> IBM Canada ltd
> Software developer
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh @end|ng |rom temp|e@edu  Sat Nov 14 03:01:56 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Fri, 13 Nov 2020 21:01:56 -0500
Subject: [R] [External]  long integer handling
In-Reply-To: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
References: <CADsEwScPdo0Bfe-LCu8A_27i1Vmg1rDn1GP-JwVsVqqiK7HSsA@mail.gmail.com>
Message-ID: <CAGx1TMDLLprQ-JeZzcZKcYiqHBRWF33HhqKh5jm+syRSL05PpA@mail.gmail.com>

You need the Rmpfr package.  Your calculation of 2^64 is an ordinary
double precision number with 53 bits of precision.

> library(Rmpfr)
Loading required package: gmp

Attaching package: ?gmp?

The following objects are masked from ?package:base?:

    %*%, apply, crossprod, matrix, tcrossprod

C code of R package 'Rmpfr': GMP using 64 bits per limb


Attaching package: ?Rmpfr?

The following object is masked from ?package:gmp?:

    outer

The following objects are masked from ?package:stats?:

    dbinom, dgamma, dnorm, dpois, pnorm

The following objects are masked from ?package:base?:

    cbind, pmax, pmin, rbind

> class(2)
[1] "numeric"
> class(2^32)
[1] "numeric"
> class(2^64)
[1] "numeric"
> Two <- mpfr(2, precBits=64)
> Two^64
1 'mpfr' number of precision  64   bits
[1] 18446744073709551616
> class(Two^64)
[1] "mpfr"
attr(,"package")
[1] "Rmpfr"
> Two^64 - 1
1 'mpfr' number of precision  64   bits
[1] 18446744073709551615
> getPrec(Two)
[1] 64
> getPrec(2.)
[1] 53
>

On Fri, Nov 13, 2020 at 8:45 PM Yousri Fanous <yousri.fanous at gmail.com> wrote:
>
> I want to calculate 2^64-1 which is
> 18446744073709551615
>
> I set the following options to prevent scientific notation
> options("scipen"=100, "digits"=4)
> > x<-2^64 -1
> > x
> [1] 18446744073709551616
>
> This is not correct. There seem to be still some approximation happening.
> How can I get the correct result?
>
> Yousri
> IBM Canada ltd
> Software developer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


