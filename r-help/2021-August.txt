From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Sun Aug  1 18:59:02 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Sun, 1 Aug 2021 16:59:02 +0000 (UTC)
Subject: [R] Help needed with gender_df
References: <93442086.1530709.1627837142818.ref@mail.yahoo.com>
Message-ID: <93442086.1530709.1627837142818@mail.yahoo.com>

Hello,?
when using the following code -?
gender_df(Test1, name_col = "First", year_col = "Year")

for the file attached below, I get the following result -?
# A tibble: 0 x 6# ... with 6 variables: name <chr>, proportion_male <dbl>, proportion_female <dbl>, gender <lgl>,#? ?year_min <dbl>, year_max <dbl>






| First |  | Year |
| Post R |  | 2012 |
| Kotulska K | 2012 |
| Zi W |  | 2012 |
| Suzuki K |  | 2012 |
| Lynch DR |  | 2012 |
| Paganoni S | 2012 |
| Nourbakhsh B | 2012 |
| Croop R |  | 2012 |
| Bril V |  | 2012 |
| Tan AH |  | 2012 |
| Benedict RHB | 2012 |
| Langeskov-Christensen M | 2012 |
| Chiaravalloti ND | 2012 |
| Zhang Y |  | 2012 |
| Bovis F |  | 2012 |
| Soul JS |  | 2012 |
| Mantegazza R | 2012 |
| Heatwole C | 2012 |
| Molhemi F | 2012 |
| Aggarwal R | 2012 |
| Chung JW |  | 2012 |
| Obermann M | 2012 |
| Albert V |  | 2012 |
| Picillo M |  | 2012 |
| Palace J |  | 2012 |
| Bogan RK |  | 2012 |
| Shoamanesh A | 2012 |
| Jaeckle KA | 2012 |
| Sakamoto S | 2012 |
| Barohn RJ |  | 2012 |
| Fehlings MG | 2012 |
| Barbieri F |  | 2012 |
| Klopstock T | 2012 |
| Martin AK |  | 2012 |
| Griffith R |  | 2012 |
| Maas RPPWM | 2012 |
| Santhosh AP | 2012 |
| Macdonald-Laurs E | 2012 |
| Guinchard M | 2012 |
| Luijten SPR | 2012 |
| Pagan FL |  | 2012 |
| Takeda A |  | 2012 |
| Shin YW |  | 2012 |
| DeLuca J |  | 2012 |
| Zhong F |  | 2012 |
| Toyoda K |  | 2012 |
| Song J |  | 2012 |
| Pan Y |  | 2012 |
| Molloy EN | 2012 |
| Heit JJ |  | 2012 |
| Bird LM |  | 2012 |
| Wu X |  | 2012 |
| Naismith RT | 2012 |
| Yaghi S |  | 2012 |
| Tekeoglu Tosun A | 2012 |
| Vieira-Yano B | 2012 |
| Malt?te D |  | 2012 |
| Gillving M |  | 2012 |
| Sylaja PN |  | 2012 |
| Sawada H |  | 2012 |
| van Dalen JW | 2012 |
| Meador KJ | 2012 |
| Cheshmavar M | 2012 |
| Liu MN |  | 2012 |
| Paprad T |  | 2012 |
| Hogue CW | 2012 |
| Filipovi? TN | 2012 |
| Weiss MD |  | 2012 |
| Bril V |  | 2012 |
| Ishigooka J | 2012 |
| Zhao J |  | 2012 |
| Christensen CE | 2012 |
| Zhang P |  | 2012 |
| Ford JH |  | 2012 |
| Ter Meulen BC | 2012 |
| Giannoni A | 2012 |
| Kuester-Gruber S | 2012 |
| Kumar A |  | 2012 |
| Dominiak M | 2012 |
| Mintun MA | 2012 |
| Guttuso T Jr | 2012 |
| Al-Karagholi MA | 2012 |
| De Icco R |  | 2012 |
| Akhbari Ziegler S | 2012 |
| Hirata K |  | 2012 |
| Schreiner L | 2012 |
| Xiao M |  | 2012 |
| Younis S |  | 2012 |
| Kazemi Z |  | 2012 |
| Johnstone A | 2012 |
| Amatachaya S | 2012 |
| Toyoda K |  | 2012 |
| Fageera W | 2012 |
| Rahn AC |  | 2012 |
| Geed S |  | 2012 |
| El-Hagrassy M | 2012 |
| Cheng C |  | 2012 |
| Kashimura M | 2012 |
| Halakoo S |  | 2012 |
| He W |  | 2012 |
| Deng Y |  | 2012 |
| Gong Y |  | 2012 |
| Vahlberg B | 2012 |
| Bazi A |  | 2012 |
| Hulbert S |  | 2012 |
| Bock JM |  | 2012 |
| Lin CH |  | 2012 |
| Voldsbekk I | 2012 |
| Langezaal LCM | 2012 |
| Araujo TG |  | 2012 |
| Krynicki CR | 2012 |
| Jakobsen G | 2012 |
| Sadlonova M | 2012 |
| Tariot PN |  | 2012 |
| Lindsay C |  | 2012 |
| Altomare D | 2012 |
| Haendel AD | 2012 |
| Yang R |  | 2012 |
| Quintero-Consuegra MD | 2012 |
| Talbot LA |  | 2012 |
| Broberg L |  | 2012 |
| Soto-Perez-de-Celis E | 2012 |
| Aguilar-Ferr?ndiz ME | 2012 |
| Cintoli S |  | 2012 |
| Misra UK |  | 2012 |
| Abdullahi SU | 2012 |
| Vukas H |  | 2012 |
| Zhang L |  | 2012 |
| Friedman BW | 2012 |
| Rao B |  | 2012 |
| De Doncker W | 2012 |
| de Almeida CMO | 2012 |
| Hartmann S | 2012 |
| Bouhassira D | 2012 |
| Ord AS |  | 2012 |
| Wiberg S |  | 2012 |
| Aalaei S |  | 2012 |
| Salehi Dehno N | 2012 |
| Suppan M |  | 2012 |
| Sindi S |  | 2012 |
| Lebares CC | 2012 |
| Sonoda Y |  | 2012 |
| Kortela E |  | 2012 |
| Nelson SE |  | 2012 |
| Dominiak M | 2012 |
| Chen Y |  | 2012 |
| Chen Q |  | 2012 |
| Silberstein SD | 2012 |
| Imamura H | 2012 |
| Moeschler SM | 2012 |
| Geerts M |  | 2012 |
| Wei W |  | 2012 |
| Reid KJ |  | 2012 |
| Hou Y |  | 2012 |
| Zhou Z |  | 2012 |
| Acsadi G |  | 2012 |
| Sterman-Neto H | 2012 |
| Dankiewicz J | 2012 |
| Malavera A | 2012 |
| Rosenberg A | 2012 |
| Asano M |  | 2012 |
| Pett SL |  | 2012 |
| Amato AA |  | 2012 |
| Wouters A | 2012 |
| Phillips MCL | 2012 |
| Mihara M |  | 2012 |
| Kitzman DW | 2012 |
| Chwojnicki K | 2012 |
| Rascol O |  | 2012 |
| Engelter ST | 2012 |
| Taylor PN |  | 2012 |
| Weafer J |  | 2012 |
| Fox RS |  | 2012 |
| Braathen G | 2012 |
| Mahmud R | 2012 |
| Vidoni ED |  | 2012 |
| Zecca C |  | 2012 |
| Haghighi S | 2012 |
| Sandebring-Matton A | 2012 |
| Koh SH |  | 2012 |
| Joosten SA | 2012 |
| Stefani A |  | 2012 |
| Park H |  | 2012 |
| Ali EN |  | 2012 |
| Gudbergsen H | 2012 |
| Moon SY |  | 2012 |
| Bleich-Cohen M | 2012 |
| Wayne PM | 2012 |
| Essmat A |  | 2012 |
| Walgaard C | 2012 |
| Kim HJ |  | 2012 |
| Moncrief GG | 2012 |
| Singh N |  | 2012 |
| Macchi ZA | 2012 |
| Mirpuri P |  | 2012 |
| Rosenthal ES | 2012 |
| Kong Z |  | 2012 |
| Kaarb? MB | 2012 |
| Xiao S |  | 2012 |
| Cheng HR |  | 2012 |



	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  1 19:49:20 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 1 Aug 2021 18:49:20 +0100
Subject: [R] Help needed with gender_df
In-Reply-To: <93442086.1530709.1627837142818@mail.yahoo.com>
References: <93442086.1530709.1627837142818.ref@mail.yahoo.com>
 <93442086.1530709.1627837142818@mail.yahoo.com>
Message-ID: <ed4ddfb4-40bb-8010-5d08-33c3580065ab@sapo.pt>

Hello,

According to the documentation,


This function predicts the gender of a first name given a year or range 
of years in which the person was born.


and your data does not include first names, only names in a form similar 
to Last First_name_initial.


This function/package is not appropriate for your problem.


Hope this helps,

Rui Barradas


?s 17:59 de 01/08/21, bharat rawlley via R-help escreveu:
> Hello,
> when using the following code -
> gender_df(Test1, name_col = "First", year_col = "Year")
> 
> for the file attached below, I get the following result -
> # A tibble: 0 x 6# ... with 6 variables: name <chr>, proportion_male <dbl>, proportion_female <dbl>, gender <lgl>,#? ?year_min <dbl>, year_max <dbl>
> 
> 
> 
> 
> 
> 
> | First |  | Year |
> | Post R |  | 2012 |
> | Kotulska K | 2012 |
> | Zi W |  | 2012 |
> | Suzuki K |  | 2012 |
> | Lynch DR |  | 2012 |
> | Paganoni S | 2012 |
> | Nourbakhsh B | 2012 |
> | Croop R |  | 2012 |
> | Bril V |  | 2012 |
> | Tan AH |  | 2012 |
> | Benedict RHB | 2012 |
> | Langeskov-Christensen M | 2012 |
> | Chiaravalloti ND | 2012 |
> | Zhang Y |  | 2012 |
> | Bovis F |  | 2012 |
> | Soul JS |  | 2012 |
> | Mantegazza R | 2012 |
> | Heatwole C | 2012 |
> | Molhemi F | 2012 |
> | Aggarwal R | 2012 |
> | Chung JW |  | 2012 |
> | Obermann M | 2012 |
> | Albert V |  | 2012 |
> | Picillo M |  | 2012 |
> | Palace J |  | 2012 |
> | Bogan RK |  | 2012 |
> | Shoamanesh A | 2012 |
> | Jaeckle KA | 2012 |
> | Sakamoto S | 2012 |
> | Barohn RJ |  | 2012 |
> | Fehlings MG | 2012 |
> | Barbieri F |  | 2012 |
> | Klopstock T | 2012 |
> | Martin AK |  | 2012 |
> | Griffith R |  | 2012 |
> | Maas RPPWM | 2012 |
> | Santhosh AP | 2012 |
> | Macdonald-Laurs E | 2012 |
> | Guinchard M | 2012 |
> | Luijten SPR | 2012 |
> | Pagan FL |  | 2012 |
> | Takeda A |  | 2012 |
> | Shin YW |  | 2012 |
> | DeLuca J |  | 2012 |
> | Zhong F |  | 2012 |
> | Toyoda K |  | 2012 |
> | Song J |  | 2012 |
> | Pan Y |  | 2012 |
> | Molloy EN | 2012 |
> | Heit JJ |  | 2012 |
> | Bird LM |  | 2012 |
> | Wu X |  | 2012 |
> | Naismith RT | 2012 |
> | Yaghi S |  | 2012 |
> | Tekeoglu Tosun A | 2012 |
> | Vieira-Yano B | 2012 |
> | Malt?te D |  | 2012 |
> | Gillving M |  | 2012 |
> | Sylaja PN |  | 2012 |
> | Sawada H |  | 2012 |
> | van Dalen JW | 2012 |
> | Meador KJ | 2012 |
> | Cheshmavar M | 2012 |
> | Liu MN |  | 2012 |
> | Paprad T |  | 2012 |
> | Hogue CW | 2012 |
> | Filipovi? TN | 2012 |
> | Weiss MD |  | 2012 |
> | Bril V |  | 2012 |
> | Ishigooka J | 2012 |
> | Zhao J |  | 2012 |
> | Christensen CE | 2012 |
> | Zhang P |  | 2012 |
> | Ford JH |  | 2012 |
> | Ter Meulen BC | 2012 |
> | Giannoni A | 2012 |
> | Kuester-Gruber S | 2012 |
> | Kumar A |  | 2012 |
> | Dominiak M | 2012 |
> | Mintun MA | 2012 |
> | Guttuso T Jr | 2012 |
> | Al-Karagholi MA | 2012 |
> | De Icco R |  | 2012 |
> | Akhbari Ziegler S | 2012 |
> | Hirata K |  | 2012 |
> | Schreiner L | 2012 |
> | Xiao M |  | 2012 |
> | Younis S |  | 2012 |
> | Kazemi Z |  | 2012 |
> | Johnstone A | 2012 |
> | Amatachaya S | 2012 |
> | Toyoda K |  | 2012 |
> | Fageera W | 2012 |
> | Rahn AC |  | 2012 |
> | Geed S |  | 2012 |
> | El-Hagrassy M | 2012 |
> | Cheng C |  | 2012 |
> | Kashimura M | 2012 |
> | Halakoo S |  | 2012 |
> | He W |  | 2012 |
> | Deng Y |  | 2012 |
> | Gong Y |  | 2012 |
> | Vahlberg B | 2012 |
> | Bazi A |  | 2012 |
> | Hulbert S |  | 2012 |
> | Bock JM |  | 2012 |
> | Lin CH |  | 2012 |
> | Voldsbekk I | 2012 |
> | Langezaal LCM | 2012 |
> | Araujo TG |  | 2012 |
> | Krynicki CR | 2012 |
> | Jakobsen G | 2012 |
> | Sadlonova M | 2012 |
> | Tariot PN |  | 2012 |
> | Lindsay C |  | 2012 |
> | Altomare D | 2012 |
> | Haendel AD | 2012 |
> | Yang R |  | 2012 |
> | Quintero-Consuegra MD | 2012 |
> | Talbot LA |  | 2012 |
> | Broberg L |  | 2012 |
> | Soto-Perez-de-Celis E | 2012 |
> | Aguilar-Ferr?ndiz ME | 2012 |
> | Cintoli S |  | 2012 |
> | Misra UK |  | 2012 |
> | Abdullahi SU | 2012 |
> | Vukas H |  | 2012 |
> | Zhang L |  | 2012 |
> | Friedman BW | 2012 |
> | Rao B |  | 2012 |
> | De Doncker W | 2012 |
> | de Almeida CMO | 2012 |
> | Hartmann S | 2012 |
> | Bouhassira D | 2012 |
> | Ord AS |  | 2012 |
> | Wiberg S |  | 2012 |
> | Aalaei S |  | 2012 |
> | Salehi Dehno N | 2012 |
> | Suppan M |  | 2012 |
> | Sindi S |  | 2012 |
> | Lebares CC | 2012 |
> | Sonoda Y |  | 2012 |
> | Kortela E |  | 2012 |
> | Nelson SE |  | 2012 |
> | Dominiak M | 2012 |
> | Chen Y |  | 2012 |
> | Chen Q |  | 2012 |
> | Silberstein SD | 2012 |
> | Imamura H | 2012 |
> | Moeschler SM | 2012 |
> | Geerts M |  | 2012 |
> | Wei W |  | 2012 |
> | Reid KJ |  | 2012 |
> | Hou Y |  | 2012 |
> | Zhou Z |  | 2012 |
> | Acsadi G |  | 2012 |
> | Sterman-Neto H | 2012 |
> | Dankiewicz J | 2012 |
> | Malavera A | 2012 |
> | Rosenberg A | 2012 |
> | Asano M |  | 2012 |
> | Pett SL |  | 2012 |
> | Amato AA |  | 2012 |
> | Wouters A | 2012 |
> | Phillips MCL | 2012 |
> | Mihara M |  | 2012 |
> | Kitzman DW | 2012 |
> | Chwojnicki K | 2012 |
> | Rascol O |  | 2012 |
> | Engelter ST | 2012 |
> | Taylor PN |  | 2012 |
> | Weafer J |  | 2012 |
> | Fox RS |  | 2012 |
> | Braathen G | 2012 |
> | Mahmud R | 2012 |
> | Vidoni ED |  | 2012 |
> | Zecca C |  | 2012 |
> | Haghighi S | 2012 |
> | Sandebring-Matton A | 2012 |
> | Koh SH |  | 2012 |
> | Joosten SA | 2012 |
> | Stefani A |  | 2012 |
> | Park H |  | 2012 |
> | Ali EN |  | 2012 |
> | Gudbergsen H | 2012 |
> | Moon SY |  | 2012 |
> | Bleich-Cohen M | 2012 |
> | Wayne PM | 2012 |
> | Essmat A |  | 2012 |
> | Walgaard C | 2012 |
> | Kim HJ |  | 2012 |
> | Moncrief GG | 2012 |
> | Singh N |  | 2012 |
> | Macchi ZA | 2012 |
> | Mirpuri P |  | 2012 |
> | Rosenthal ES | 2012 |
> | Kong Z |  | 2012 |
> | Kaarb? MB | 2012 |
> | Xiao S |  | 2012 |
> | Cheng HR |  | 2012 |
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Sun Aug  1 20:56:37 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Sun, 1 Aug 2021 18:56:37 +0000 (UTC)
Subject: [R] Help needed with gender_df
In-Reply-To: <ed4ddfb4-40bb-8010-5d08-33c3580065ab@sapo.pt>
References: <93442086.1530709.1627837142818.ref@mail.yahoo.com>
 <93442086.1530709.1627837142818@mail.yahoo.com>
 <ed4ddfb4-40bb-8010-5d08-33c3580065ab@sapo.pt>
Message-ID: <1789559256.1536954.1627844197573@mail.yahoo.com>

 That was helpful, thank you very much!?
    On Sunday, 1 August, 2021, 01:49:30 pm GMT-4, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,

According to the documentation,


This function predicts the gender of a first name given a year or range 
of years in which the person was born.


and your data does not include first names, only names in a form similar 
to Last First_name_initial.


This function/package is not appropriate for your problem.


Hope this helps,

Rui Barradas


?s 17:59 de 01/08/21, bharat rawlley via R-help escreveu:
> Hello,
> when using the following code -
> gender_df(Test1, name_col = "First", year_col = "Year")
> 
> for the file attached below, I get the following result -
> # A tibble: 0 x 6# ... with 6 variables: name <chr>, proportion_male <dbl>, proportion_female <dbl>, gender <lgl>,#? ?year_min <dbl>, year_max <dbl>
> 
> 
> 
> 
> 
> 
> | First |? | Year |
> | Post R |? | 2012 |
> | Kotulska K | 2012 |
> | Zi W |? | 2012 |
> | Suzuki K |? | 2012 |
> | Lynch DR |? | 2012 |
> | Paganoni S | 2012 |
> | Nourbakhsh B | 2012 |
> | Croop R |? | 2012 |
> | Bril V |? | 2012 |
> | Tan AH |? | 2012 |
> | Benedict RHB | 2012 |
> | Langeskov-Christensen M | 2012 |
> | Chiaravalloti ND | 2012 |
> | Zhang Y |? | 2012 |
> | Bovis F |? | 2012 |
> | Soul JS |? | 2012 |
> | Mantegazza R | 2012 |
> | Heatwole C | 2012 |
> | Molhemi F | 2012 |
> | Aggarwal R | 2012 |
> | Chung JW |? | 2012 |
> | Obermann M | 2012 |
> | Albert V |? | 2012 |
> | Picillo M |? | 2012 |
> | Palace J |? | 2012 |
> | Bogan RK |? | 2012 |
> | Shoamanesh A | 2012 |
> | Jaeckle KA | 2012 |
> | Sakamoto S | 2012 |
> | Barohn RJ |? | 2012 |
> | Fehlings MG | 2012 |
> | Barbieri F |? | 2012 |
> | Klopstock T | 2012 |
> | Martin AK |? | 2012 |
> | Griffith R |? | 2012 |
> | Maas RPPWM | 2012 |
> | Santhosh AP | 2012 |
> | Macdonald-Laurs E | 2012 |
> | Guinchard M | 2012 |
> | Luijten SPR | 2012 |
> | Pagan FL |? | 2012 |
> | Takeda A |? | 2012 |
> | Shin YW |? | 2012 |
> | DeLuca J |? | 2012 |
> | Zhong F |? | 2012 |
> | Toyoda K |? | 2012 |
> | Song J |? | 2012 |
> | Pan Y |? | 2012 |
> | Molloy EN | 2012 |
> | Heit JJ |? | 2012 |
> | Bird LM |? | 2012 |
> | Wu X |? | 2012 |
> | Naismith RT | 2012 |
> | Yaghi S |? | 2012 |
> | Tekeoglu Tosun A | 2012 |
> | Vieira-Yano B | 2012 |
> | Malt?te D |? | 2012 |
> | Gillving M |? | 2012 |
> | Sylaja PN |? | 2012 |
> | Sawada H |? | 2012 |
> | van Dalen JW | 2012 |
> | Meador KJ | 2012 |
> | Cheshmavar M | 2012 |
> | Liu MN |? | 2012 |
> | Paprad T |? | 2012 |
> | Hogue CW | 2012 |
> | Filipovi? TN | 2012 |
> | Weiss MD |? | 2012 |
> | Bril V |? | 2012 |
> | Ishigooka J | 2012 |
> | Zhao J |? | 2012 |
> | Christensen CE | 2012 |
> | Zhang P |? | 2012 |
> | Ford JH |? | 2012 |
> | Ter Meulen BC | 2012 |
> | Giannoni A | 2012 |
> | Kuester-Gruber S | 2012 |
> | Kumar A |? | 2012 |
> | Dominiak M | 2012 |
> | Mintun MA | 2012 |
> | Guttuso T Jr | 2012 |
> | Al-Karagholi MA | 2012 |
> | De Icco R |? | 2012 |
> | Akhbari Ziegler S | 2012 |
> | Hirata K |? | 2012 |
> | Schreiner L | 2012 |
> | Xiao M |? | 2012 |
> | Younis S |? | 2012 |
> | Kazemi Z |? | 2012 |
> | Johnstone A | 2012 |
> | Amatachaya S | 2012 |
> | Toyoda K |? | 2012 |
> | Fageera W | 2012 |
> | Rahn AC |? | 2012 |
> | Geed S |? | 2012 |
> | El-Hagrassy M | 2012 |
> | Cheng C |? | 2012 |
> | Kashimura M | 2012 |
> | Halakoo S |? | 2012 |
> | He W |? | 2012 |
> | Deng Y |? | 2012 |
> | Gong Y |? | 2012 |
> | Vahlberg B | 2012 |
> | Bazi A |? | 2012 |
> | Hulbert S |? | 2012 |
> | Bock JM |? | 2012 |
> | Lin CH |? | 2012 |
> | Voldsbekk I | 2012 |
> | Langezaal LCM | 2012 |
> | Araujo TG |? | 2012 |
> | Krynicki CR | 2012 |
> | Jakobsen G | 2012 |
> | Sadlonova M | 2012 |
> | Tariot PN |? | 2012 |
> | Lindsay C |? | 2012 |
> | Altomare D | 2012 |
> | Haendel AD | 2012 |
> | Yang R |? | 2012 |
> | Quintero-Consuegra MD | 2012 |
> | Talbot LA |? | 2012 |
> | Broberg L |? | 2012 |
> | Soto-Perez-de-Celis E | 2012 |
> | Aguilar-Ferr?ndiz ME | 2012 |
> | Cintoli S |? | 2012 |
> | Misra UK |? | 2012 |
> | Abdullahi SU | 2012 |
> | Vukas H |? | 2012 |
> | Zhang L |? | 2012 |
> | Friedman BW | 2012 |
> | Rao B |? | 2012 |
> | De Doncker W | 2012 |
> | de Almeida CMO | 2012 |
> | Hartmann S | 2012 |
> | Bouhassira D | 2012 |
> | Ord AS |? | 2012 |
> | Wiberg S |? | 2012 |
> | Aalaei S |? | 2012 |
> | Salehi Dehno N | 2012 |
> | Suppan M |? | 2012 |
> | Sindi S |? | 2012 |
> | Lebares CC | 2012 |
> | Sonoda Y |? | 2012 |
> | Kortela E |? | 2012 |
> | Nelson SE |? | 2012 |
> | Dominiak M | 2012 |
> | Chen Y |? | 2012 |
> | Chen Q |? | 2012 |
> | Silberstein SD | 2012 |
> | Imamura H | 2012 |
> | Moeschler SM | 2012 |
> | Geerts M |? | 2012 |
> | Wei W |? | 2012 |
> | Reid KJ |? | 2012 |
> | Hou Y |? | 2012 |
> | Zhou Z |? | 2012 |
> | Acsadi G |? | 2012 |
> | Sterman-Neto H | 2012 |
> | Dankiewicz J | 2012 |
> | Malavera A | 2012 |
> | Rosenberg A | 2012 |
> | Asano M |? | 2012 |
> | Pett SL |? | 2012 |
> | Amato AA |? | 2012 |
> | Wouters A | 2012 |
> | Phillips MCL | 2012 |
> | Mihara M |? | 2012 |
> | Kitzman DW | 2012 |
> | Chwojnicki K | 2012 |
> | Rascol O |? | 2012 |
> | Engelter ST | 2012 |
> | Taylor PN |? | 2012 |
> | Weafer J |? | 2012 |
> | Fox RS |? | 2012 |
> | Braathen G | 2012 |
> | Mahmud R | 2012 |
> | Vidoni ED |? | 2012 |
> | Zecca C |? | 2012 |
> | Haghighi S | 2012 |
> | Sandebring-Matton A | 2012 |
> | Koh SH |? | 2012 |
> | Joosten SA | 2012 |
> | Stefani A |? | 2012 |
> | Park H |? | 2012 |
> | Ali EN |? | 2012 |
> | Gudbergsen H | 2012 |
> | Moon SY |? | 2012 |
> | Bleich-Cohen M | 2012 |
> | Wayne PM | 2012 |
> | Essmat A |? | 2012 |
> | Walgaard C | 2012 |
> | Kim HJ |? | 2012 |
> | Moncrief GG | 2012 |
> | Singh N |? | 2012 |
> | Macchi ZA | 2012 |
> | Mirpuri P |? | 2012 |
> | Rosenthal ES | 2012 |
> | Kong Z |? | 2012 |
> | Kaarb? MB | 2012 |
> | Xiao S |? | 2012 |
> | Cheng HR |? | 2012 |
> 
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
  
	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Aug  2 04:47:25 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 2 Aug 2021 14:47:25 +1200
Subject: [R] Cumulates of snowfall within a given interval
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FC65AC61E@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FC65AC61E@ESINO.regionemarche.intra>
Message-ID: <CABcYAdK57wP1XZEzjEDAuNeQOwSziEKyE2r0=7eQ_Q58j7ix_Q@mail.gmail.com>

> x <- c(1,2,3)  # a vector of numbers, such as snowfallsum
> (cx <- cumsum(x)) # a vector of cumulative sums.
1 3 6
> i <- 1 # The starting point.
> j <- 2 # The ending point.
> cx[j] - cx[i-1] # sum of x[i] + ... + x[j]
ERROR!
> cx <- c(0, cx) # Oops, we need this step.
> cx[j+1] - cx[i]

So using c(0,cumsum(x)) you take O(#x) time and O(#x) space and get a data
structure that will answer any (i,j) -> x[i]+...+x[j] query in constant time.

Let's now suppose you fix delta = 3 (days) and some threshold:
indices <- (delta + 1):length(cx)
which(cx[indices] - cx[indices - delta] > threshold)

On Fri, 30 Jul 2021 at 19:24, Stefano Sofia
<stefano.sofia at regione.marche.it> wrote:
>
> Dear R users,
> I have a data frame with daily snow cumulates (these quantities are known as "hn" and are expressed in cm), from the 1st of December to the 30th of April, for more than twenty years.
>
> I would need to find days when the sum of a given short interval (I might choose two consecutive days, three consecutive days or something like that) is higher than a threshold (it might be 80 cm, or 100 cm).
>
> I am trying with rle, but I really struggle to find an efficient algorithm.
> Could somebody help me with some hints?
>
> Thank you for your attention and your help
> Stefano
>
>
> init_day <- as.POSIXct("2018-02-01", format="%Y-%m-%d", tz="Etc/GMT-1")
> fin_day <- as.POSIXct("2018-02-20", format="%Y-%m-%d", tz="Etc/GMT-1")
> mydf <- data.frame(data_POSIX=seq(init_day, fin_day, by="1 day"))
> mydf$hn <- c(30, 0, 10, 50, NA, 40, 70, 0, 0, 0 , NA, 10, 50, 30, 30, 10, 0, 0, 90, 0)
>
> - if I choose a threshold of 100 cm in two days, I should get the 6th of February;
> - if I choose a threshold of 80 cm in two days I should get the 6th and the 13th of February, but not the 19th of February because this is a single day;
> - f I choose a threshold of 100 cm in four days, I should get the 12th of February.
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy
> Meteo Section
> Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libraesva ESG ed  risultato non infetto.
> This message was scanned by Libraesva ESG and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug  2 10:34:28 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 2 Aug 2021 20:34:28 +1200
Subject: [R] 
 Plotting confidence intervals with ggplot, in multiple facets.
In-Reply-To: <030701d77d08$1cc9b330$565d1990$@verizon.net>
References: <20210718181706.03a95d29@rolf-Latitude-E7470>
 <016501d77c08$a6d94b40$f48be1c0$@verizon.net>
 <20210720112405.08ec449e@rolf-Latitude-E7470>
 <030701d77d08$1cc9b330$565d1990$@verizon.net>
Message-ID: <20210802203428.7da847a1@rolf-Latitude-E7470>


I would like to tie off this thread (?!?!) by thanking Jeff Newmiller,
Rui Barradas, Avi Gross and Bill Dunlap for their advice and insight.

I have attached the code that I finally put together, on the basis of
the aforementioned advice, in the file ciPlot.txt.  I have also
attached the necessary data set in the file egDat.txt.

Just in case anyone is interested or in case someone else might benefit
from seeing this code.

cheers,

Rolf Turner
-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ciPlot.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210802/82eed2b3/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: egDat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210802/82eed2b3/attachment-0001.txt>

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Aug  2 18:53:34 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 2 Aug 2021 17:53:34 +0100
Subject: [R] 
 Plotting confidence intervals with ggplot, in multiple facets.
In-Reply-To: <20210802203428.7da847a1@rolf-Latitude-E7470>
References: <20210718181706.03a95d29@rolf-Latitude-E7470>
 <016501d77c08$a6d94b40$f48be1c0$@verizon.net>
 <20210720112405.08ec449e@rolf-Latitude-E7470>
 <030701d77d08$1cc9b330$565d1990$@verizon.net>
 <20210802203428.7da847a1@rolf-Latitude-E7470>
Message-ID: <55a53232-7fc1-dbe7-1228-0d968eb953db@sapo.pt>

Hello,

I'm glad it helped.
Here are a couple of ideas for theme.

1) From ?theme:

Theme inheritance
Theme elements inherit properties from other theme elements 
hierarchically. For example, axis.title.x.bottom inherits from 
axis.title.x which inherits from axis.title, which in turn inherits from 
text.


So there is no need for axis.title.x and axis.title.y (or axis.text) and 
  this

   theme_bw() +
   theme(axis.title.x=element_text(size=14),
         axis.title.y=element_text(size=14)) +
   theme(axis.text.x=element_text(size=14),
         axis.text.y=element_text(size=14)) +
   theme(panel.border=element_rect(linetype="solid",fill=NA),
         panel.grid.minor=element_blank(),
         panel.grid.major=element_blank())


can be simplified to this


   theme_bw() +
   theme(axis.title=element_text(size=14),
         axis.text=element_text(size=14)) +
   theme(panel.border=element_rect(linetype="solid",fill=NA),
         panel.grid=element_blank())


2) If you are using the same theme repeatedly, why not define a custom 
theme? It's as easy as


theme_custom <- function(){
   theme_bw() %+replace%    #replace elements we want to change
     theme(axis.title=element_text(size=14),
           axis.text=element_text(size=14),
           panel.border=element_rect(linetype="solid",fill=NA),
           panel.grid=element_blank())
}


(It's also possible to just copy&paste the two theme instructions in 
your code, I have rewritten them as one as a matter of habit.)
The plots would then become easier to read and if themes' rules change, 
the theme will be updated in one place only.


Part.a <- ggplot(cidf.a, aes(Ndat, estimate)) +
   geom_errorbar(aes(ymin = lower, ymax = upper), width = 50) +
   geom_point(size = 1) +
   geom_hline(yintercept = 0,col="red") +
   labs(x="",y=Ylab.a) +
   theme_custom()


And the same for Part.b.

Hope this helps,

Rui Barradas


?s 09:34 de 02/08/21, Rolf Turner escreveu:
> 
> I would like to tie off this thread (?!?!) by thanking Jeff Newmiller,
> Rui Barradas, Avi Gross and Bill Dunlap for their advice and insight.
> 
> I have attached the code that I finally put together, on the basis of
> the aforementioned advice, in the file ciPlot.txt.  I have also
> attached the necessary data set in the file egDat.txt.
> 
> Just in case anyone is interested or in case someone else might benefit
> from seeing this code.
> 
> cheers,
> 
> Rolf Turner
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Aug  2 22:56:16 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 3 Aug 2021 08:56:16 +1200
Subject: [R] 
 Plotting confidence intervals with ggplot, in multiple facets.
In-Reply-To: <55a53232-7fc1-dbe7-1228-0d968eb953db@sapo.pt>
References: <20210718181706.03a95d29@rolf-Latitude-E7470>
 <016501d77c08$a6d94b40$f48be1c0$@verizon.net>
 <20210720112405.08ec449e@rolf-Latitude-E7470>
 <030701d77d08$1cc9b330$565d1990$@verizon.net>
 <20210802203428.7da847a1@rolf-Latitude-E7470>
 <55a53232-7fc1-dbe7-1228-0d968eb953db@sapo.pt>
Message-ID: <20210803085616.1661c7e1@rolf-Latitude-E7470>


On Mon, 2 Aug 2021 17:53:34 +0100
Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> I'm glad it helped.
> Here are a couple of ideas for theme.

<SNIP>

Thanks Rui.  The scope of your knowledge and understanding is simply
amazing!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @tch|rume @end|ng |rom gm@||@com  Sun Aug  1 20:47:34 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Sun, 1 Aug 2021 20:47:34 +0200
Subject: [R] Long Format data
Message-ID: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>

Hello, i hope you are well. May you kindly help me to structure data in the
folder attached herewith in file BOP_All_Countries.csv. I am doing
panel data analysis. *I need it to be structured as it is on the file
R_help.csv.  *

Please kindly see the r-script below *(r_help.R)* that i ran which did not
yield what i wanted.

Thank you in advance.


Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504

From out|ook_789D32266F1FD473 @end|ng |rom out|ook@com  Mon Aug  2 20:25:36 2021
From: out|ook_789D32266F1FD473 @end|ng |rom out|ook@com (Lac Will)
Date: Mon, 2 Aug 2021 18:25:36 +0000
Subject: [R] Generate oauth token using HTTR package in R
Message-ID: <DM6PR02MB4634145115EDFFB48D9CD315EEEF9@DM6PR02MB4634.namprd02.prod.outlook.com>



Novice attempting R, as displayed below, to obtain an oauth token using HTTR package in R and have a status code of 401.

Any insight as to the cause of this error and a resolution?

Thanks in advance.



# Status: 401

library(httr)

base64_value <-
  "123456789="


response16 <-
  httr::POST (url = "https://api.precisely.com/oauth/token" ,
             httr::add_headers(Authorization = paste("Basic", base64_value, sep = "")),
             body = list(grant_type = "client_credentials"),
             encode = "form"
             )

#verbose(data_out = true, data_in = False, info = false, ssl = false)


warn_for_status(response16)
stop_for_status(response16)



























Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug  3 10:05:45 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 3 Aug 2021 18:05:45 +1000
Subject: [R] Long Format data
In-Reply-To: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
References: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
Message-ID: <CA+8X3fXToDQiSw-0MD0KjE8Ei6fTWbXE3wME-aQKxyoKJHB8xQ@mail.gmail.com>

Hi Admire,
Neither the R script nor CSV file was attached to your message. Both
should be plain text files and are unlikely to be rejected by the help
list mail server. Perhaps check your email client.

Jim

On Tue, Aug 3, 2021 at 5:09 PM Admire Tarisirayi Chirume
<atchirume at gmail.com> wrote:
>
> Hello, i hope you are well. May you kindly help me to structure data in the
> folder attached herewith in file BOP_All_Countries.csv. I am doing
> panel data analysis. *I need it to be structured as it is on the file
> R_help.csv.  *
>
> Please kindly see the r-script below *(r_help.R)* that i ran which did not
> yield what i wanted.
>
> Thank you in advance.
>
>
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gm@rk@|ow|er @end|ng |rom out|ook@com  Tue Aug  3 11:39:46 2021
From: gm@rk@|ow|er @end|ng |rom out|ook@com (Mark Fowler)
Date: Tue, 3 Aug 2021 09:39:46 +0000
Subject: [R] Generate oauth token using HTTR package in R
In-Reply-To: <DM6PR02MB4634145115EDFFB48D9CD315EEEF9@DM6PR02MB4634.namprd02.prod.outlook.com>
References: <DM6PR02MB4634145115EDFFB48D9CD315EEEF9@DM6PR02MB4634.namprd02.prod.outlook.com>
Message-ID: <MN2PR07MB72137E38B5CC0E60C5755CE285F09@MN2PR07MB7213.namprd07.prod.outlook.com>

Hi Lac,

The status code means that you were not authorized to access the site, perhaps reflecting some problem with your syntax or your permissions. I note that attempting to simply go to the link to check on it gives status code 405, meaning the typical click on the hypertext is not an accepted method to access the location. Also consider the possibility that the site might be experiencing problems, so even if your syntax was correct it might not work right now. Another possibility is a change to URL syntax (addressing) at the precisely.com end, which appears to have been an issue, but I do not know if it still is.

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10

From: Lac Will<mailto:outlook_789D32266F1FD473 at outlook.com>
Sent: Tuesday, August 3, 2021 4:10 AM
To: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: [R] Generate oauth token using HTTR package in R



Novice attempting R, as displayed below, to obtain an oauth token using HTTR package in R and have a status code of 401.

Any insight as to the cause of this error and a resolution?

Thanks in advance.



# Status: 401

library(httr)

base64_value <-
  "123456789="


response16 <-
  httr::POST (url = "https://api.precisely.com/oauth/token" ,
             httr::add_headers(Authorization = paste("Basic", base64_value, sep = "")),
             body = list(grant_type = "client_credentials"),
             encode = "form"
             )

#verbose(data_out = true, data_in = False, info = false, ssl = false)


warn_for_status(response16)
stop_for_status(response16)



























Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Aug  3 18:20:12 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 3 Aug 2021 17:20:12 +0100
Subject: [R] What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
Message-ID: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>

Short version

Apart from the ability to work with values of p too small to be of much 
practical use what are the advantages and disadvantages of setting this 
to TRUE?

Longer version

I am contemplating upgrading various functions in one of my packages to 
use this and as far as I can see it would only have the advantage of 
allowing people to use very small p-values but before I go ahead have I 
missed anything? I am most concerned with negatives but if there is any 
other advantage I would mention that in the vignette. I am not concerned 
about speed or the extra effort in coding and expanding the documentation.
-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Tue Aug  3 20:20:52 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 3 Aug 2021 18:20:52 +0000 (UTC)
Subject: [R] Help with package EasyPubmed
References: <1046636584.2205366.1628014852065.ref@mail.yahoo.com>
Message-ID: <1046636584.2205366.1628014852065@mail.yahoo.com>

Hello,?
When I try to run the following code using the package Easypubmed, I get a null result -?
> batch_pubmed_download(query_7)
NULL
#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"
However, the exact same search string yields 668 results on Pubmed.?


I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?
Any help would be?greatly appreciated
Thank you!?

	[[alternative HTML version deleted]]


From bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n  Tue Aug  3 20:26:40 2021
From: bh@r@t_m_@|| @end|ng |rom y@hoo@co@|n (bharat rawlley)
Date: Tue, 3 Aug 2021 18:26:40 +0000 (UTC)
Subject: [R] Help with package EasyPubmed
In-Reply-To: <1046636584.2205366.1628014852065@mail.yahoo.com>
References: <1046636584.2205366.1628014852065.ref@mail.yahoo.com>
 <1046636584.2205366.1628014852065@mail.yahoo.com>
Message-ID: <712126143.2207911.1628015200446@mail.yahoo.com>

 ?Okay, the following search string resolved my issue? -?
"Cardiology AND randomized controlled trial[Publication type] AND 2011[PDAT]"

Thank you!
    On Tuesday, 3 August, 2021, 02:21:38 pm GMT-4, bharat rawlley via R-help <r-help at r-project.org> wrote:  
 
 Hello,?
When I try to run the following code using the package Easypubmed, I get a null result -?
> batch_pubmed_download(query_7)
NULL
#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"
However, the exact same search string yields 668 results on Pubmed.?


I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?
Any help would be?greatly appreciated
Thank you!?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Aug  3 20:53:28 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 3 Aug 2021 14:53:28 -0400
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
Message-ID: <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>

On 03/08/2021 12:20 p.m., Michael Dewey wrote:
> Short version
> 
> Apart from the ability to work with values of p too small to be of much
> practical use what are the advantages and disadvantages of setting this
> to TRUE?
> 
> Longer version
> 
> I am contemplating upgrading various functions in one of my packages to
> use this and as far as I can see it would only have the advantage of
> allowing people to use very small p-values but before I go ahead have I
> missed anything? I am most concerned with negatives but if there is any
> other advantage I would mention that in the vignette. I am not concerned
> about speed or the extra effort in coding and expanding the documentation.
> 

These are often needed in likelihood problems.  In just about any 
problem where the normal density shows up in the likelihood, you're 
better off working with the log likelihood and setting log = TRUE in 
dnorm, because sometimes you want to evaluate the likelihood very far 
from its mode.

The same sort of thing happens with pnorm for similar reasons.  Some 
likelihoods involve normal integrals and will need it.

I can't think of an example for qnorm off the top of my head, but I 
imagine there are some:  maybe involving simulation way out in the tails.

The main negative about using logs is that they aren't always needed.

Duncan Murdoch


From w||||@mwdun|@p @end|ng |rom gm@||@com  Tue Aug  3 22:24:08 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Tue, 3 Aug 2021 13:24:08 -0700
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>
Message-ID: <CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A@mail.gmail.com>

In maximum likelihood problems, even when the individual density values are
fairly far from zero, their product may underflow to zero.  Optimizers have
problems when there is a large flat area.
   > q <- runif(n=1000, -0.1, +0.1)
   > prod(dnorm(q))
   [1] 0
   > sum(dnorm(q, log=TRUE))
   [1] -920.6556

A more minor advantage for some probability-related functions is speed.
E.g., dnorm(log=TRUE,...) does not need to evaluate exp().
   > q <- runif(1e6, -10, 10)
   > system.time(for(i in 1:100)dnorm(q, log=FALSE))
      user  system elapsed
      9.13    0.11    9.23
   > system.time(for(i in 1:100)dnorm(q, log=TRUE))
      user  system elapsed
      4.60    0.19    4.78

 -Bill

On Tue, Aug 3, 2021 at 11:53 AM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 03/08/2021 12:20 p.m., Michael Dewey wrote:
> > Short version
> >
> > Apart from the ability to work with values of p too small to be of much
> > practical use what are the advantages and disadvantages of setting this
> > to TRUE?
> >
> > Longer version
> >
> > I am contemplating upgrading various functions in one of my packages to
> > use this and as far as I can see it would only have the advantage of
> > allowing people to use very small p-values but before I go ahead have I
> > missed anything? I am most concerned with negatives but if there is any
> > other advantage I would mention that in the vignette. I am not concerned
> > about speed or the extra effort in coding and expanding the
> documentation.
> >
>
> These are often needed in likelihood problems.  In just about any
> problem where the normal density shows up in the likelihood, you're
> better off working with the log likelihood and setting log = TRUE in
> dnorm, because sometimes you want to evaluate the likelihood very far
> from its mode.
>
> The same sort of thing happens with pnorm for similar reasons.  Some
> likelihoods involve normal integrals and will need it.
>
> I can't think of an example for qnorm off the top of my head, but I
> imagine there are some:  maybe involving simulation way out in the tails.
>
> The main negative about using logs is that they aren't always needed.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Aug  4 00:56:08 2021
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 03 Aug 2021 18:56:08 -0400
Subject: [R] Creating a log-transformed histogram of multiclass data
In-Reply-To: <1ac86e67589f13f2e37a83d0b145260e@ontargettek.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <e18d373f5daf2f463abe4c17b82bbe76@ontargettek.com>
 <1ac86e67589f13f2e37a83d0b145260e@ontargettek.com>
Message-ID: <2bc87c25f161bac1d8e5101e20bf2237@ontargettek.com>


# Resending this message since the original email was held in queue by 
the listserv software because of a "suspicious" subject line, and/or 
because of attached .png histogram chart attachments. I'm guessing that 
the listserv software doesn't like multiple image file attachments.


Hi everyone. I'm working on a research model now that is calculating 
anomaly scores (RMSE values) for three distinct groups within a large 
dataset. The anomaly scores are a continuous data type and are quite 
small, ranging from approximately 1e-04 to 1-e07 across a population of 
approximately 1 million observations.

I have all of the summary and descriptive statistics for each of the 
anomaly score distributions across each group label in the dataset, and 
I am able to create some useful histograms showing how each of the three 
groups is uniquely distributed across the range of scores. However, 
because of the large variance within the frequency of score values and 
the high density peaks within much of the anomaly scores, I need to use 
a log transformation within the histogram to show both the log frequency 
count of each binned observation range (y-axis) and a log transformation 
of the binned score values (x-axis) to be able to appropriately 
illustrate the distributions within the data and make it more readily 
understandable.

Fortunately, ggplot2 is really useful for creating some really 
attractive dual-axis log transformed histograms.

However, I cannot figure out a way to create the log transformed 
histograms to show each of my three groups by color within the same 
histogram. I would want it to look like this, BUT use a log 
transformation for each axis. This plot below shows the 3 groups in one 
histogram but uses the default normal values.

For log transformed axis values, the best I can do so far is produce 
three separate histograms, one for each group.



Below is sample R code to illustrate my problem with a 
randomly-generated example dataset and the ggplot2 approaches that I 
have taken so far:

# Sample R code below:

library(ggplot2)
library(dplyr)
library(hrbrthemes)

# I created some simple random sample data to produce an example 
dataset.
# This produces an example dataframe called d, which contains a class 
label IV of either A, B or C for each observation. The target variable 
is the anomaly_score continuous value for each observation.
# There are 300 rows of dummy data in this dataframe.

DV_score_generator = round(runif(300,0.001,0.999), 3)
d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE, 
prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)

# First, I use ggplot to create the normal distribution histogram that 
shows all 3 groups on the same plot, by color.
# Please note that with this small set of randomized sample data it 
doesn't appear to be necessary to use an x and y-axis log transformation 
to show the distribution patterns, but it does becomes an issue with my 
vastly larger and more complex score values in the DV of the actual 
data.

p <- d %>%
ggplot( aes(x=anomaly_score, fill=label)) +
geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +
theme_ipsum() +
labs(fill="")

p

# Produces a normal multiclass histogram.



# Now produce a series of x and y-axis log-transformed histograms, 
producing one histogram for each distinct label class in the dataset:


# Group A, log transformed

ggplot(group_a, aes(x = anomaly_score)) +
      geom_histogram(aes(y = ..count..), binwidth = 0.05,
      colour = "darkgoldenrod1", fill = "darkgoldenrod2") +
      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
+
      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
Counts") +
      ggtitle("Transformed Anomaly Scores - Group A Only")


# Group A transformed histogram is produced here.



# Group B, log transformed

  ggplot(group_b, aes(x = anomaly_score)) +
      geom_histogram(aes(y = ..count..), binwidth = 0.05,
      colour = "green", fill = "darkgreen") +
      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
+
      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
Counts") +
      ggtitle("Transformed Anomaly Scores - Group B Only")

# Group B transformed histogram is produced here.



# Group C, log transformed

  ggplot(group_c, aes(x = anomaly_score)) +
      geom_histogram(aes(y = ..count..), binwidth = 0.05,
      colour = "red", fill = "darkred") +
      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
+
      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
Counts") +
      ggtitle("Transformed Anomaly Scores - Group C Only")

# Group C transformed histogram is produced here.


# End.



Thanks in advance, everyone!


- Tom


Thomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, MS
On Target Technologies, Inc.
Virginia, USA


From twoo|m@n @end|ng |rom ont@rgettek@com  Wed Aug  4 01:04:29 2021
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Tue, 03 Aug 2021 19:04:29 -0400
Subject: [R] Creating a log-transformed histogram of multiclass data
In-Reply-To: <2bc87c25f161bac1d8e5101e20bf2237@ontargettek.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <e18d373f5daf2f463abe4c17b82bbe76@ontargettek.com>
 <1ac86e67589f13f2e37a83d0b145260e@ontargettek.com>
 <2bc87c25f161bac1d8e5101e20bf2237@ontargettek.com>
Message-ID: <ba170db0581b2b7f5c79448355685e92@ontargettek.com>

Apologies, I left out 3 critical lines of code after the randomized 
sample dataframe is created:

group_a <- d[ which(d$label =='A'), ]
group_b <- d[ which(d$label =='B'), ]
group_c <- d[ which(d$label =='C'), ]





On 2021-08-03 18:56, Tom Woolman wrote:
> # Resending this message since the original email was held in queue by
> the listserv software because of a "suspicious" subject line, and/or
> because of attached .png histogram chart attachments. I'm guessing
> that the listserv software doesn't like multiple image file
> attachments.
> 
> 
> Hi everyone. I'm working on a research model now that is calculating
> anomaly scores (RMSE values) for three distinct groups within a large
> dataset. The anomaly scores are a continuous data type and are quite
> small, ranging from approximately 1e-04 to 1-e07 across a population
> of approximately 1 million observations.
> 
> I have all of the summary and descriptive statistics for each of the
> anomaly score distributions across each group label in the dataset,
> and I am able to create some useful histograms showing how each of the
> three groups is uniquely distributed across the range of scores.
> However, because of the large variance within the frequency of score
> values and the high density peaks within much of the anomaly scores, I
> need to use a log transformation within the histogram to show both the
> log frequency count of each binned observation range (y-axis) and a
> log transformation of the binned score values (x-axis) to be able to
> appropriately illustrate the distributions within the data and make it
> more readily understandable.
> 
> Fortunately, ggplot2 is really useful for creating some really
> attractive dual-axis log transformed histograms.
> 
> However, I cannot figure out a way to create the log transformed
> histograms to show each of my three groups by color within the same
> histogram. I would want it to look like this, BUT use a log
> transformation for each axis. This plot below shows the 3 groups in
> one histogram but uses the default normal values.
> 
> For log transformed axis values, the best I can do so far is produce
> three separate histograms, one for each group.
> 
> 
> 
> Below is sample R code to illustrate my problem with a
> randomly-generated example dataset and the ggplot2 approaches that I
> have taken so far:
> 
> # Sample R code below:
> 
> library(ggplot2)
> library(dplyr)
> library(hrbrthemes)
> 
> # I created some simple random sample data to produce an example 
> dataset.
> # This produces an example dataframe called d, which contains a class
> label IV of either A, B or C for each observation. The target variable
> is the anomaly_score continuous value for each observation.
> # There are 300 rows of dummy data in this dataframe.
> 
> DV_score_generator = round(runif(300,0.001,0.999), 3)
> d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE,
> prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)
> 
> # First, I use ggplot to create the normal distribution histogram that
> shows all 3 groups on the same plot, by color.
> # Please note that with this small set of randomized sample data it
> doesn't appear to be necessary to use an x and y-axis log
> transformation to show the distribution patterns, but it does becomes
> an issue with my vastly larger and more complex score values in the DV
> of the actual data.
> 
> p <- d %>%
> ggplot( aes(x=anomaly_score, fill=label)) +
> geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +
> scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +
> theme_ipsum() +
> labs(fill="")
> 
> p
> 
> # Produces a normal multiclass histogram.
> 
> 
> 
> # Now produce a series of x and y-axis log-transformed histograms,
> producing one histogram for each distinct label class in the dataset:
> 
> 
> # Group A, log transformed
> 
> ggplot(group_a, aes(x = anomaly_score)) +
>      geom_histogram(aes(y = ..count..), binwidth = 0.05,
>      colour = "darkgoldenrod1", fill = "darkgoldenrod2") +
>      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
> +
>      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
> Counts") +
>      ggtitle("Transformed Anomaly Scores - Group A Only")
> 
> 
> # Group A transformed histogram is produced here.
> 
> 
> 
> # Group B, log transformed
> 
>  ggplot(group_b, aes(x = anomaly_score)) +
>      geom_histogram(aes(y = ..count..), binwidth = 0.05,
>      colour = "green", fill = "darkgreen") +
>      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
> +
>      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
> Counts") +
>      ggtitle("Transformed Anomaly Scores - Group B Only")
> 
> # Group B transformed histogram is produced here.
> 
> 
> 
> # Group C, log transformed
> 
>  ggplot(group_c, aes(x = anomaly_score)) +
>      geom_histogram(aes(y = ..count..), binwidth = 0.05,
>      colour = "red", fill = "darkred") +
>      scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") 
> +
>      scale_y_continuous(trans="log2", name="Log-transformed Frequency 
> Counts") +
>      ggtitle("Transformed Anomaly Scores - Group C Only")
> 
> # Group C transformed histogram is produced here.
> 
> 
> # End.
> 
> 
> 
> Thanks in advance, everyone!
> 
> 
> - Tom
> 
> 
> Thomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, 
> MS
> On Target Technologies, Inc.
> Virginia, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@tth|@@-gond@n @end|ng |rom gmx@de  Wed Aug  4 14:08:05 2021
From: m@tth|@@-gond@n @end|ng |rom gmx@de (matthias-gondan)
Date: Wed, 04 Aug 2021 14:08:05 +0200
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <mailman.363724.1.1628071201.45489.r-help@r-project.org>
Message-ID: <1MGz1V-1mODz13MnL-00E3Ov@mail.gmx.net>

Response to 1You need the log version e.g. in maximum likelihood, otherwise the product of the densities and probabilities can become very small.
-------- Urspr?ngliche Nachricht --------Von: r-help-request at r-project.org Datum: 04.08.21  12:01  (GMT+01:00) An: r-help at r-project.org Betreff: R-help Digest, Vol 222, Issue 4 Send R-help mailing list submissions to	r-help at r-project.orgTo subscribe or unsubscribe via the World Wide Web, visit	https://stat.ethz.ch/mailman/listinfo/r-helpor, via email, send a message with subject or body 'help' to	r-help-request at r-project.orgYou can reach the person managing the list at	r-help-owner at r-project.orgWhen replying, please edit your Subject line so it is more specificthan "Re: Contents of R-help digest..."Today's Topics:?? 1. What are the pros and cons of the log.p parameter in????? (p|q)norm and similar? (Michael Dewey)?? 2. Help with package EasyPubmed (bharat rawlley)?? 3. Re: Help with package EasyPubmed (bharat rawlley)?? 4. Re:? What are the pros and cons of the log.p parameter in????? (p|q)norm and similar? (Duncan Murdoch)?? 5. Re:? What are the pros and cons of the log.p parameter in????? (p|q)norm and similar? (Bill Dunlap)?? 6. Creating a log-transformed histogram of multiclass data????? (Tom Woolman)?? 7. Re: Creating a log-transformed histogram of multiclass data????? (Tom Woolman)----------------------------------------------------------------------Message: 1Date: Tue, 3 Aug 2021 17:20:12 +0100From: Michael Dewey <lists at dewey.myzen.co.uk>To: "r-help at r-project.org" <r-help at r-project.org>Subject: [R] What are the pros and cons of the log.p parameter in	(p|q)norm and similar?Message-ID: <e17bdaaa-7945-4f37-ee69-941eb8270f16 at dewey.myzen.co.uk>Content-Type: text/plain; charset="utf-8"; Format="flowed"Short versionApart from the ability to work with values of p too small to be of much practical use what are the advantages and disadvantages of setting this to TRUE?Longer versionI am contemplating upgrading various functions in one of my packages to use this and as far as I can see it would only have the advantage of allowing people to use very small p-values but before I go ahead have I missed anything? I am most concerned with negatives but if there is any other advantage I would mention that in the vignette. I am not concerned about speed or the extra effort in coding and expanding the documentation.-- Michaelhttp://www.dewey.myzen.co.uk/home.html------------------------------Message: 2Date: Tue, 3 Aug 2021 18:20:52 +0000 (UTC)From: bharat rawlley <bharat_m_all at yahoo.co.in>To: R-help Mailing List <r-help at r-project.org>Subject: [R] Help with package EasyPubmedMessage-ID: <1046636584.2205366.1628014852065 at mail.yahoo.com>Content-Type: text/plain; charset="utf-8"Hello,?When I try to run the following code using the package Easypubmed, I get a null result -?> batch_pubmed_download(query_7)NULL#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"However, the exact same search string yields 668 results on Pubmed.?I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?Any help would be?greatly appreciatedThank you!?	[[alternative HTML version deleted]]------------------------------Message: 3Date: Tue, 3 Aug 2021 18:26:40 +0000 (UTC)From: bharat rawlley <bharat_m_all at yahoo.co.in>To: R-help Mailing List <r-help at r-project.org>Subject: Re: [R] Help with package EasyPubmedMessage-ID: <712126143.2207911.1628015200446 at mail.yahoo.com>Content-Type: text/plain; charset="utf-8" ?Okay, the following search string resolved my issue? -?"Cardiology AND randomized controlled trial[Publication type] AND 2011[PDAT]"Thank you!??? On Tuesday, 3 August, 2021, 02:21:38 pm GMT-4, bharat rawlley via R-help <r-help at r-project.org> wrote:?   Hello,?When I try to run the following code using the package Easypubmed, I get a null result -?> batch_pubmed_download(query_7)NULL#query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"However, the exact same search string yields 668 results on Pubmed.?I am unable to figure out why this is happening. If I use the search string?"Cardiology AND 2011[PDAT]" then it works just fine.?Any help would be?greatly appreciatedThank you!???? [[alternative HTML version deleted]]______________________________________________R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, seehttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.? 	[[alternative HTML version deleted]]------------------------------Message: 4Date: Tue, 3 Aug 2021 14:53:28 -0400From: Duncan Murdoch <murdoch.duncan at gmail.com>To: Michael Dewey <lists at dewey.myzen.co.uk>, "r-help at r-project.org"	<r-help at r-project.org>Subject: Re: [R]? What are the pros and cons of the log.p parameter in	(p|q)norm and similar?Message-ID: <c15f610b-7a16-9d84-884c-54cc170bbad8 at gmail.com>Content-Type: text/plain; charset="utf-8"; Format="flowed"On 03/08/2021 12:20 p.m., Michael Dewey wrote:> Short version> > Apart from the ability to work with values of p too small to be of much> practical use what are the advantages and disadvantages of setting this> to TRUE?> > Longer version> > I am contemplating upgrading various functions in one of my packages to> use this and as far as I can see it would only have the advantage of> allowing people to use very small p-values but before I go ahead have I> missed anything? I am most concerned with negatives but if there is any> other advantage I would mention that in the vignette. I am not concerned> about speed or the extra effort in coding and expanding the documentation.> These are often needed in likelihood problems.? In just about any problem where the normal density shows up in the likelihood, you're better off working with the log likelihood and setting log = TRUE in dnorm, because sometimes you want to evaluate the likelihood very far from its mode.The same sort of thing happens with pnorm for similar reasons.? Some likelihoods involve normal integrals and will need it.I can't think of an example for qnorm off the top of my head, but I imagine there are some:? maybe involving simulation way out in the tails.The main negative about using logs is that they aren't always needed.Duncan Murdoch------------------------------Message: 5Date: Tue, 3 Aug 2021 13:24:08 -0700From: Bill Dunlap <williamwdunlap at gmail.com>To: Duncan Murdoch <murdoch.duncan at gmail.com>Cc: Michael Dewey <lists at dewey.myzen.co.uk>, "r-help at r-project.org"	<r-help at r-project.org>Subject: Re: [R]? What are the pros and cons of the log.p parameter in	(p|q)norm and similar?Message-ID:	<CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A at mail.gmail.com>Content-Type: text/plain; charset="utf-8"In maximum likelihood problems, even when the individual density values arefairly far from zero, their product may underflow to zero.? Optimizers haveproblems when there is a large flat area.?? > q <- runif(n=1000, -0.1, +0.1)?? > prod(dnorm(q))?? [1] 0?? > sum(dnorm(q, log=TRUE))?? [1] -920.6556A more minor advantage for some probability-related functions is speed.E.g., dnorm(log=TRUE,...) does not need to evaluate exp().?? > q <- runif(1e6, -10, 10)?? > system.time(for(i in 1:100)dnorm(q, log=FALSE))????? user? system elapsed????? 9.13??? 0.11??? 9.23?? > system.time(for(i in 1:100)dnorm(q, log=TRUE))????? user? system elapsed????? 4.60??? 0.19??? 4.78 -BillOn Tue, Aug 3, 2021 at 11:53 AM Duncan Murdoch <murdoch.duncan at gmail.com>wrote:> On 03/08/2021 12:20 p.m., Michael Dewey wrote:> > Short version> >> > Apart from the ability to work with values of p too small to be of much> > practical use what are the advantages and disadvantages of setting this> > to TRUE?> >> > Longer version> >> > I am contemplating upgrading various functions in one of my packages to> > use this and as far as I can see it would only have the advantage of> > allowing people to use very small p-values but before I go ahead have I> > missed anything? I am most concerned with negatives but if there is any> > other advantage I would mention that in the vignette. I am not concerned> > about speed or the extra effort in coding and expanding the> documentation.> >>> These are often needed in likelihood problems.? In just about any> problem where the normal density shows up in the likelihood, you're> better off working with the log likelihood and setting log = TRUE in> dnorm, because sometimes you want to evaluate the likelihood very far> from its mode.>> The same sort of thing happens with pnorm for similar reasons.? Some> likelihoods involve normal integrals and will need it.>> I can't think of an example for qnorm off the top of my head, but I> imagine there are some:? maybe involving simulation way out in the tails.>> The main negative about using logs is that they aren't always needed.>> Duncan Murdoch>> ______________________________________________> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide> http://www.R-project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.>	[[alternative HTML version deleted]]------------------------------Message: 6Date: Tue, 03 Aug 2021 18:56:08 -0400From: Tom Woolman <twoolman at ontargettek.com>To: r-help at r-project.orgSubject: [R] Creating a log-transformed histogram of multiclass dataMessage-ID: <2bc87c25f161bac1d8e5101e20bf2237 at ontargettek.com>Content-Type: text/plain; charset="us-ascii"; Format="flowed"# Resending this message since the original email was held in queue by the listserv software because of a "suspicious" subject line, and/or because of attached .png histogram chart attachments. I'm guessing that the listserv software doesn't like multiple image file attachments.Hi everyone. I'm working on a research model now that is calculating anomaly scores (RMSE values) for three distinct groups within a large dataset. The anomaly scores are a continuous data type and are quite small, ranging from approximately 1e-04 to 1-e07 across a population of approximately 1 million observations.I have all of the summary and descriptive statistics for each of the anomaly score distributions across each group label in the dataset, and I am able to create some useful histograms showing how each of the three groups is uniquely distributed across the range of scores. However, because of the large variance within the frequency of score values and the high density peaks within much of the anomaly scores, I need to use a log transformation within the histogram to show both the log frequency count of each binned observation range (y-axis) and a log transformation of the binned score values (x-axis) to be able to appropriately illustrate the distributions within the data and make it more readily understandable.Fortunately, ggplot2 is really useful for creating some really attractive dual-axis log transformed histograms.However, I cannot figure out a way to create the log transformed histograms to show each of my three groups by color within the same histogram. I would want it to look like this, BUT use a log transformation for each axis. This plot below shows the 3 groups in one histogram but uses the default normal values.For log transformed axis values, the best I can do so far is produce three separate histograms, one for each group.Below is sample R code to illustrate my problem with a randomly-generated example dataset and the ggplot2 approaches that I have taken so far:# Sample R code below:library(ggplot2)library(dplyr)library(hrbrthemes)# I created some simple random sample data to produce an example dataset.# This produces an example dataframe called d, which contains a class label IV of either A, B or C for each observation. The target variable is the anomaly_score continuous value for each observation.# There are 300 rows of dummy data in this dataframe.DV_score_generator = round(runif(300,0.001,0.999), 3)d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE, prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)# First, I use ggplot to create the normal distribution histogram that shows all 3 groups on the same plot, by color.# Please note that with this small set of randomized sample data it doesn't appear to be necessary to use an x and y-axis log transformation to show the distribution patterns, but it does becomes an issue with my vastly larger and more complex score values in the DV of the actual data.p <- d %>%ggplot( aes(x=anomaly_score, fill=label)) +geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +theme_ipsum() +labs(fill="")p# Produces a normal multiclass histogram.# Now produce a series of x and y-axis log-transformed histograms, producing one histogram for each distinct label class in the dataset:# Group A, log transformedggplot(group_a, aes(x = anomaly_score)) +????? geom_histogram(aes(y = ..count..), binwidth = 0.05,????? colour = "darkgoldenrod1", fill = "darkgoldenrod2") +????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") +????? scale_y_continuous(trans="log2", name="Log-transformed Frequency Counts") +????? ggtitle("Transformed Anomaly Scores - Group A Only")# Group A transformed histogram is produced here.# Group B, log transformed? ggplot(group_b, aes(x = anomaly_score)) +????? geom_histogram(aes(y = ..count..), binwidth = 0.05,????? colour = "green", fill = "darkgreen") +????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") +????? scale_y_continuous(trans="log2", name="Log-transformed Frequency Counts") +????? ggtitle("Transformed Anomaly Scores - Group B Only")# Group B transformed histogram is produced here.# Group C, log transformed? ggplot(group_c, aes(x = anomaly_score)) +????? geom_histogram(aes(y = ..count..), binwidth = 0.05,????? colour = "red", fill = "darkred") +????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") +????? scale_y_continuous(trans="log2", name="Log-transformed Frequency Counts") +????? ggtitle("Transformed Anomaly Scores - Group C Only")# Group C transformed histogram is produced here.# End.Thanks in advance, everyone!- TomThomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, MSOn Target Technologies, Inc.Virginia, USA------------------------------Message: 7Date: Tue, 03 Aug 2021 19:04:29 -0400From: Tom Woolman <twoolman at ontargettek.com>To: r-help at r-project.orgSubject: Re: [R] Creating a log-transformed histogram of multiclass	dataMessage-ID: <ba170db0581b2b7f5c79448355685e92 at ontargettek.com>Content-Type: text/plain; charset="us-ascii"; Format="flowed"Apologies, I left out 3 critical lines of code after the randomized sample dataframe is created:group_a <- d[ which(d$label =='A'), ]group_b <- d[ which(d$label =='B'), ]group_c <- d[ which(d$label =='C'), ]On 2021-08-03 18:56, Tom Woolman wrote:> # Resending this message since the original email was held in queue by> the listserv software because of a "suspicious" subject line, and/or> because of attached .png histogram chart attachments. I'm guessing> that the listserv software doesn't like multiple image file> attachments.> > > Hi everyone. I'm working on a research model now that is calculating> anomaly scores (RMSE values) for three distinct groups within a large> dataset. The anomaly scores are a continuous data type and are quite> small, ranging from approximately 1e-04 to 1-e07 across a population> of approximately 1 million observations.> > I have all of the summary and descriptive statistics for each of the> anomaly score distributions across each group label in the dataset,> and I am able to create some useful histograms showing how each of the> three groups is uniquely distributed across the range of scores.> However, because of the large variance within the frequency of score> values and the high density peaks within much of the anomaly scores, I> need to use a log transformation within the histogram to show both the> log frequency count of each binned observation range (y-axis) and a> log transformation of the binned score values (x-axis) to be able to> appropriately illustrate the distributions within the data and make it> more readily understandable.> > Fortunately, ggplot2 is really useful for creating some really> attractive dual-axis log transformed histograms.> > However, I cannot figure out a way to create the log transformed> histograms to show each of my three groups by color within the same> histogram. I would want it to look like this, BUT use a log> transformation for each axis. This plot below shows the 3 groups in> one histogram but uses the default normal values.> > For log transformed axis values, the best I can do so far is produce> three separate histograms, one for each group.> > > > Below is sample R code to illustrate my problem with a> randomly-generated example dataset and the ggplot2 approaches that I> have taken so far:> > # Sample R code below:> > library(ggplot2)> library(dplyr)> library(hrbrthemes)> > # I created some simple random sample data to produce an example > dataset.> # This produces an example dataframe called d, which contains a class> label IV of either A, B or C for each observation. The target variable> is the anomaly_score continuous value for each observation.> # There are 300 rows of dummy data in this dataframe.> > DV_score_generator = round(runif(300,0.001,0.999), 3)> d <- data.frame( label = sample( LETTERS[1:3], 300, replace=TRUE,> prob=c(0.65, 0.30, 0.05) ), anomaly_score = DV_score_generator)> > # First, I use ggplot to create the normal distribution histogram that> shows all 3 groups on the same plot, by color.> # Please note that with this small set of randomized sample data it> doesn't appear to be necessary to use an x and y-axis log> transformation to show the distribution patterns, but it does becomes> an issue with my vastly larger and more complex score values in the DV> of the actual data.> > p <- d %>%> ggplot( aes(x=anomaly_score, fill=label)) +> geom_histogram( color="#e9ecef", alpha=0.6, position = 'identity') +> scale_fill_manual(values=c("#69b3a2", "blue", "#404080")) +> theme_ipsum() +> labs(fill="")> > p> > # Produces a normal multiclass histogram.> > > > # Now produce a series of x and y-axis log-transformed histograms,> producing one histogram for each distinct label class in the dataset:> > > # Group A, log transformed> > ggplot(group_a, aes(x = anomaly_score)) +>????? geom_histogram(aes(y = ..count..), binwidth = 0.05,>????? colour = "darkgoldenrod1", fill = "darkgoldenrod2") +>????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") > +>????? scale_y_continuous(trans="log2", name="Log-transformed Frequency > Counts") +>????? ggtitle("Transformed Anomaly Scores - Group A Only")> > > # Group A transformed histogram is produced here.> > > > # Group B, log transformed> >? ggplot(group_b, aes(x = anomaly_score)) +>????? geom_histogram(aes(y = ..count..), binwidth = 0.05,>????? colour = "green", fill = "darkgreen") +>????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") > +>????? scale_y_continuous(trans="log2", name="Log-transformed Frequency > Counts") +>????? ggtitle("Transformed Anomaly Scores - Group B Only")> > # Group B transformed histogram is produced here.> > > > # Group C, log transformed> >? ggplot(group_c, aes(x = anomaly_score)) +>????? geom_histogram(aes(y = ..count..), binwidth = 0.05,>????? colour = "red", fill = "darkred") +>????? scale_x_continuous(name = "Log-scale Anomaly Score", trans="log2") > +>????? scale_y_continuous(trans="log2", name="Log-transformed Frequency > Counts") +>????? ggtitle("Transformed Anomaly Scores - Group C Only")> > # Group C transformed histogram is produced here.> > > # End.> > > > Thanks in advance, everyone!> > > - Tom> > > Thomas A. Woolman, PhD Candidate (Indiana State University), MBA, MS, > MS> On Target Technologies, Inc.> Virginia, USA> > ______________________________________________> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see> https://stat.ethz.ch/mailman/listinfo/r-help> PLEASE do read the posting guide > http://www.R-project.org/posting-guide.html> and provide commented, minimal, self-contained, reproducible code.------------------------------Subject: Digest Footer_______________________________________________R-help at r-project.org mailing listhttps://stat.ethz.ch/mailman/listinfo/r-helpPLEASE do read the posting guide http://www.R-project.org/posting-guide.htmland provide commented, minimal, self-contained, reproducible code.------------------------------End of R-help Digest, Vol 222, Issue 4**************************************
	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Aug  4 15:51:52 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 4 Aug 2021 15:51:52 +0200
Subject: [R] How to ignore outliers in a boxplot
Message-ID: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>

Hi

I have values like:

var= c(0, 0, 0,0, 0, 14, 0, 14, 0, 2, 3)

I want to show these values in a boxplot

boxplot (var)

However, the boxplot shows only the zero values and the value till 14 are
shown as outliers.. I want to show all my values as boxplot, can I do that?

If I use outline=F, it excludes all the outliers.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Aug  4 16:01:46 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 4 Aug 2021 15:01:46 +0100
Subject: [R] How to ignore outliers in a boxplot
In-Reply-To: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>
References: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>
Message-ID: <aac00ab8-d192-af2b-a86a-54be812828df@sapo.pt>

Hello,

I'm not sure whether you are looking for argument range:


boxplot(var, range = 0)


14 is now part of the whiskers, see ?boxplot.

Hope this helps,

Rui Barradas

?s 14:51 de 04/08/21, Neha gupta escreveu:
> Hi
> 
> I have values like:
> 
> var= c(0, 0, 0,0, 0, 14, 0, 14, 0, 2, 3)
> 
> I want to show these values in a boxplot
> 
> boxplot (var)
> 
> However, the boxplot shows only the zero values and the value till 14 are
> shown as outliers.. I want to show all my values as boxplot, can I do that?
> 
> If I use outline=F, it excludes all the outliers.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Wed Aug  4 16:04:05 2021
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Wed, 4 Aug 2021 16:04:05 +0200
Subject: [R] How to ignore outliers in a boxplot
In-Reply-To: <aac00ab8-d192-af2b-a86a-54be812828df@sapo.pt>
References: <CA+nrPnstrrnoQvASPJitG2cxPL-gtSw3PEF_WD61Ly+6tgdMNg@mail.gmail.com>
 <aac00ab8-d192-af2b-a86a-54be812828df@sapo.pt>
Message-ID: <CA+nrPntYsyFCye-_xw1d=6k72UDTOXnrp9WupezyssTsWjwHQg@mail.gmail.com>

Thanks a lot Sir

Yes, that's what I was looking for.

Warm regards

On Wed, Aug 4, 2021 at 4:01 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I'm not sure whether you are looking for argument range:
>
>
> boxplot(var, range = 0)
>
>
> 14 is now part of the whiskers, see ?boxplot.
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 14:51 de 04/08/21, Neha gupta escreveu:
> > Hi
> >
> > I have values like:
> >
> > var= c(0, 0, 0,0, 0, 14, 0, 14, 0, 2, 3)
> >
> > I want to show these values in a boxplot
> >
> > boxplot (var)
> >
> > However, the boxplot shows only the zero values and the value till 14 are
> > shown as outliers.. I want to show all my values as boxplot, can I do
> that?
> >
> > If I use outline=F, it excludes all the outliers.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Aug  5 06:57:11 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 4 Aug 2021 21:57:11 -0700
Subject: [R] Help with package EasyPubmed
In-Reply-To: <1046636584.2205366.1628014852065@mail.yahoo.com>
References: <1046636584.2205366.1628014852065.ref@mail.yahoo.com>
 <1046636584.2205366.1628014852065@mail.yahoo.com>
Message-ID: <1D3CCD60-0C84-4B36-AF52-FB491F6C30EC@comcast.net>



> On Aug 3, 2021, at 11:20 AM, bharat rawlley via R-help <r-help at r-project.org> wrote:
> 
> Hello, 
> When I try to run the following code using the package Easypubmed, I get a null result - 
>> batch_pubmed_download(query_7)
> NULL
> #query_7 <- "Cardiology AND randomizedcontrolledtrial[Filter] AND 2011[PDAT]"
> However, the exact same search string yields 668 results on Pubmed. 

Did you try with: 
'Cardiology AND "randomized controlled trial"[Filter] AND 2011[PDAT]'

DAVID.

> 
> 
> I am unable to figure out why this is happening. If I use the search string "Cardiology AND 2011[PDAT]" then it works just fine. 
> Any help would be greatly appreciated
> Thank you! 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Aug  5 11:53:17 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 5 Aug 2021 19:53:17 +1000
Subject: [R] Long Format data
In-Reply-To: <CAFfFd+uViqwkFfELZzzQomzCWyDqQ2HmoB+Qshs2vv_ShOzzig@mail.gmail.com>
References: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
 <CAFfFd+uViqwkFfELZzzQomzCWyDqQ2HmoB+Qshs2vv_ShOzzig@mail.gmail.com>
Message-ID: <CA+8X3fWtCM7TOt9B_0n7d0py5CbqqjUEE+pBexkHQu8Q1wp2Ag@mail.gmail.com>

Hi Admire,
I think rep_n_stack in the prettyR package may do what you want:

# download and install the prettyR package
install.packages("prettyR")
# load the prettyR package
library(prettyR)
# read in your data
ATCdf<-read.csv("BOP_All_Countries.csv",stringsAsFactors=TRUE)
# convert the values you want to long format
ATClong<-rep_n_stack(ATCdf,to.stack=3:17,stack.names=c("year","value"))
# as your column names in Excel will be coerced to character values by
prepending "X",
# coerce them back to numeric
ATClong$year<-as.numeric(substr(ATClong$year,2,5))
# check the first row
ATClong[1,]

As the "Variables" column is messy, you may want to substitute the
numeric value in the long output and print a table of the numeric and
character values of the factor:

unique(ATClong$Variables)
ATClong$Variables<-as.numeric(ATClong$Variables)

Jim

On Tue, Aug 3, 2021 at 9:53 PM Admire Tarisirayi Chirume
<atchirume at gmail.com> wrote:
>
>
>
> Hello Jim, i hope you are well. I think my msg was rejected beacuse of the size of my files. I was kindly help me to structure data in the folder attached herewith in file BOP_All_Countries.csv. I am doing panel data analysis. I need it to be structured as it is on the file R_help.csv.
>
> Please kindly see the r-script below (r_help.R) that i ran which did not yield what i wanted.
>
> Thank you in advance for your help.
>
>
> Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> Skype: admirechirume
> Call: +263773369884
> whatsapp: +818099861504


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug  5 15:16:22 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 5 Aug 2021 15:16:22 +0200
Subject: [R] Sanity check in loading large dataframe
Message-ID: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>

Hello,
I am using a large spreadsheet (over 600 variables).
I tried `str` to check the dimensions of the spreadsheet and I got
```
> (str(df))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
....
$ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
NULL
```
I understand that `[list output truncated]` means that there are more
variables than those allowed by str to be displayed as rows. Thus I
increased the row's output with:
```

> (str(df, list.len=1000))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
...
NULL
```

Does `NULL` mean that some of the variables are not closed? (perhaps a
missing comma somewhere)
Is there a way to check the sanity of the data and avoid that some
separator is not in the right place?
Thank you



-- 
Best regards,
Luigi


From @tch|rume @end|ng |rom gm@||@com  Thu Aug  5 15:23:54 2021
From: @tch|rume @end|ng |rom gm@||@com (Admire Tarisirayi Chirume)
Date: Thu, 5 Aug 2021 15:23:54 +0200
Subject: [R] Long Format data
In-Reply-To: <CA+8X3fWtCM7TOt9B_0n7d0py5CbqqjUEE+pBexkHQu8Q1wp2Ag@mail.gmail.com>
References: <CAFfFd+veadsS2g11Bq7gDvrHnJt0ACHKYGnXrXcfOOSAjykhaQ@mail.gmail.com>
 <CAFfFd+uViqwkFfELZzzQomzCWyDqQ2HmoB+Qshs2vv_ShOzzig@mail.gmail.com>
 <CA+8X3fWtCM7TOt9B_0n7d0py5CbqqjUEE+pBexkHQu8Q1wp2Ag@mail.gmail.com>
Message-ID: <CAFfFd+sv6yLgJ_87Cc7d661KZkEa8mOtOAZpAMx2afu+6urjOg@mail.gmail.com>

Thank you very much, the code worked the trick. Thank you, i appreciate.

Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
Skype: admirechirume
Call: +263773369884
whatsapp: +818099861504


On Thu, Aug 5, 2021 at 11:53 AM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Admire,
> I think rep_n_stack in the prettyR package may do what you want:
>
> # download and install the prettyR package
> install.packages("prettyR")
> # load the prettyR package
> library(prettyR)
> # read in your data
> ATCdf<-read.csv("BOP_All_Countries.csv",stringsAsFactors=TRUE)
> # convert the values you want to long format
> ATClong<-rep_n_stack(ATCdf,to.stack=3:17,stack.names=c("year","value"))
> # as your column names in Excel will be coerced to character values by
> prepending "X",
> # coerce them back to numeric
> ATClong$year<-as.numeric(substr(ATClong$year,2,5))
> # check the first row
> ATClong[1,]
>
> As the "Variables" column is messy, you may want to substitute the
> numeric value in the long output and print a table of the numeric and
> character values of the factor:
>
> unique(ATClong$Variables)
> ATClong$Variables<-as.numeric(ATClong$Variables)
>
> Jim
>
> On Tue, Aug 3, 2021 at 9:53 PM Admire Tarisirayi Chirume
> <atchirume at gmail.com> wrote:
> >
> >
> >
> > Hello Jim, i hope you are well. I think my msg was rejected beacuse of
> the size of my files. I was kindly help me to structure data in the folder
> attached herewith in file BOP_All_Countries.csv. I am doing panel data
> analysis. I need it to be structured as it is on the file R_help.csv.
> >
> > Please kindly see the r-script below (r_help.R) that i ran which did not
> yield what i wanted.
> >
> > Thank you in advance for your help.
> >
> >
> > Alternative email: addtarris at icloud.com/TChirume at rbz.co.zw
> > Skype: admirechirume
> > Call: +263773369884
> > whatsapp: +818099861504
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Aug  5 15:40:51 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 5 Aug 2021 09:40:51 -0400
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
Message-ID: <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>

On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
 > Hello,
 > I am using a large spreadsheet (over 600 variables).
 > I tried `str` to check the dimensions of the spreadsheet and I got
 > ```
 >> (str(df))
 > 'data.frame': 302 obs. of  626 variables:
 >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
 > ....
 > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
 >    [list output truncated]
 > NULL
 > ```
 > I understand that `[list output truncated]` means that there are more
 > variables than those allowed by str to be displayed as rows. Thus I
 > increased the row's output with:
 > ```
 >
 >> (str(df, list.len=1000))
 > 'data.frame': 302 obs. of  626 variables:
 >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
 > ...
 > NULL
 > ```
 >
 > Does `NULL` mean that some of the variables are not closed? (perhaps a
 > missing comma somewhere)
 > Is there a way to check the sanity of the data and avoid that some
 > separator is not in the right place?
 > Thank you

The NULL is the value returned by str().  Normally it is not printed, 
but when you wrap str in parens as (str(df, list.len=1000)), that forces 
the value to print.

str() is unusual in R functions in that it prints to the console as it 
runs and returns nothing.  Many other functions construct a value which 
is only displayed if you print it, but something like

x <- str(df, list.len=1000)

will print the same as if there was no assignment, and then assign NULL 
to x.

Duncan Murdoch


From @v|gro@@ @end|ng |rom ver|zon@net  Thu Aug  5 18:01:52 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Thu, 5 Aug 2021 12:01:52 -0400
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
Message-ID: <025301d78a13$3501c880$9f055980$@verizon.net>

Luigi,

Duncan answered part of your question. My feedback is to consider looking at
your data using other tools besides str(). 

There are ways in base R to get lists of row or column names or count them
or ask what types they are and so forth.

Printing an entire large object is hard but printing many subsets can give
you a handle on it.

You may also want to use packages in the tidyverse such as dplyr and work
with tibbles as a mild variation on a data.frame.

I am not sure what you are hoping to do with str() besides getting the
number of rows and columns but consider:

	dim(df)
	nrow(df)
	ncol(df)

To get names: 
	names(df)
	colnames(df)
	rownames(df)

To get many kinds of info about columns in your data.frame, various
functional methods like this can be used:
	sapply(df, typeof)

The above will tell you for each column if it is an integer or double or
other things.
	
To do more interesting things there are packages. The psych package, for
example, lets you get some metrics about each column:
	psych::describe(df)

And you can use various methods of subsetting to limit what you are looking
at and only show or print a manageable amount.

You seem to be asking about sanity checking in your subject line and that
depends on what you want to check. Clearly that can include making sure
various columns of data are valid in being of the expected data type or not
having any NA values or even removing outliers and so on. Tools are there
for much of that including the few I mention. Your data may seem huge but I
have worked on much larger ones. One suggestion is to consider trimming some
of that data before working on it IF some is not needed. Both base R and the
tidyverse have lots to offer to do such things.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
Sent: Thursday, August 5, 2021 9:16 AM
To: r-help <r-help at r-project.org>
Subject: [R] Sanity check in loading large dataframe

Hello,
I am using a large spreadsheet (over 600 variables).
I tried `str` to check the dimensions of the spreadsheet and I got ```
> (str(df))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
....
$ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
  [list output truncated]
NULL
```
I understand that `[list output truncated]` means that there are more
variables than those allowed by str to be displayed as rows. Thus I
increased the row's output with:
```

> (str(df, list.len=1000))
'data.frame': 302 obs. of  626 variables:
 $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
...
NULL
```

Does `NULL` mean that some of the variables are not closed? (perhaps a
missing comma somewhere) Is there a way to check the sanity of the data and
avoid that some separator is not in the right place?
Thank you



--
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 07:34:05 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 07:34:05 +0200
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
Message-ID: <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>

Ok, so nothing to worry about. Yet, are there other checks I can implement?
Thank you

On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com> wrote:

> On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
>  > Hello,
>  > I am using a large spreadsheet (over 600 variables).
>  > I tried `str` to check the dimensions of the spreadsheet and I got
>  > ```
>  >> (str(df))
>  > 'data.frame': 302 obs. of  626 variables:
>  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
>  > ....
>  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
>  >    [list output truncated]
>  > NULL
>  > ```
>  > I understand that `[list output truncated]` means that there are more
>  > variables than those allowed by str to be displayed as rows. Thus I
>  > increased the row's output with:
>  > ```
>  >
>  >> (str(df, list.len=1000))
>  > 'data.frame': 302 obs. of  626 variables:
>  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
>  > ...
>  > NULL
>  > ```
>  >
>  > Does `NULL` mean that some of the variables are not closed? (perhaps a
>  > missing comma somewhere)
>  > Is there a way to check the sanity of the data and avoid that some
>  > separator is not in the right place?
>  > Thank you
>
> The NULL is the value returned by str().  Normally it is not printed,
> but when you wrap str in parens as (str(df, list.len=1000)), that forces
> the value to print.
>
> str() is unusual in R functions in that it prints to the console as it
> runs and returns nothing.  Many other functions construct a value which
> is only displayed if you print it, but something like
>
> x <- str(df, list.len=1000)
>
> will print the same as if there was no assignment, and then assign NULL
> to x.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Aug  6 09:56:34 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 6 Aug 2021 07:56:34 +0000
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
Message-ID: <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>

Hi 

You already got answer from Avi. I often use dim(data) to inspect how many
rows/columns I have.
After that I check if some columns contain all or many NA values.

colSums(is.na(data))
keep <- which(colSums(is.na(data))<nnn)
cleaned.data <- data[, keep]

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Friday, August 6, 2021 7:34 AM
> To: Duncan Murdoch <murdoch.duncan at gmail.com>
> Cc: r-help <r-help at r-project.org>
> Subject: Re: [R] Sanity check in loading large dataframe
> 
> Ok, so nothing to worry about. Yet, are there other checks I can
implement?
> Thank you
> 
> On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com>
> wrote:
> 
> > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> >  > Hello,
> >  > I am using a large spreadsheet (over 600 variables).
> >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ....
> >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> >  >    [list output truncated]
> >  > NULL
> >  > ```
> >  > I understand that `[list output truncated]` means that there are
> > more  > variables than those allowed by str to be displayed as rows.
> > Thus I  > increased the row's output with:
> >  > ```
> >  >
> >  >> (str(df, list.len=1000))
> >  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ...
> >  > NULL
> >  > ```
> >  >
> >  > Does `NULL` mean that some of the variables are not closed?
> > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > sanity of the data and avoid that some  > separator is not in the
> > right place?
> >  > Thank you
> >
> > The NULL is the value returned by str().  Normally it is not printed,
> > but when you wrap str in parens as (str(df, list.len=1000)), that
> > forces the value to print.
> >
> > str() is unusual in R functions in that it prints to the console as it
> > runs and returns nothing.  Many other functions construct a value
> > which is only displayed if you print it, but something like
> >
> > x <- str(df, list.len=1000)
> >
> > will print the same as if there was no assignment, and then assign
> > NULL to x.
> >
> > Duncan Murdoch
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 10:15:35 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 10:15:35 +0200
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2Tmzi+qF3mcRhLn7PJXtM63PoODCicCmSxB1WHQDSqRtQ@mail.gmail.com>

OK, thank you.

On Fri, Aug 6, 2021 at 9:56 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> You already got answer from Avi. I often use dim(data) to inspect how many
> rows/columns I have.
> After that I check if some columns contain all or many NA values.
>
> colSums(is.na(data))
> keep <- which(colSums(is.na(data))<nnn)
> cleaned.data <- data[, keep]
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Friday, August 6, 2021 7:34 AM
> > To: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Sanity check in loading large dataframe
> >
> > Ok, so nothing to worry about. Yet, are there other checks I can
> implement?
> > Thank you
> >
> > On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com>
> > wrote:
> >
> > > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> > >  > Hello,
> > >  > I am using a large spreadsheet (over 600 variables).
> > >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ....
> > >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> > >  >    [list output truncated]
> > >  > NULL
> > >  > ```
> > >  > I understand that `[list output truncated]` means that there are
> > > more  > variables than those allowed by str to be displayed as rows.
> > > Thus I  > increased the row's output with:
> > >  > ```
> > >  >
> > >  >> (str(df, list.len=1000))
> > >  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ...
> > >  > NULL
> > >  > ```
> > >  >
> > >  > Does `NULL` mean that some of the variables are not closed?
> > > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > > sanity of the data and avoid that some  > separator is not in the
> > > right place?
> > >  > Thank you
> > >
> > > The NULL is the value returned by str().  Normally it is not printed,
> > > but when you wrap str in parens as (str(df, list.len=1000)), that
> > > forces the value to print.
> > >
> > > str() is unusual in R functions in that it prints to the console as it
> > > runs and returns nothing.  Many other functions construct a value
> > > which is only displayed if you print it, but something like
> > >
> > > x <- str(df, list.len=1000)
> > >
> > > will print the same as if there was no assignment, and then assign
> > > NULL to x.
> > >
> > > Duncan Murdoch
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From bgunter@4567 @end|ng |rom gm@||@com  Fri Aug  6 13:28:46 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 6 Aug 2021 04:28:46 -0700
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>

... but remove the which() and use logical indexing ...  ;-)

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 6, 2021 at 12:57 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You already got answer from Avi. I often use dim(data) to inspect how many
> rows/columns I have.
> After that I check if some columns contain all or many NA values.
>
> colSums(is.na(data))
> keep <- which(colSums(is.na(data))<nnn)
> cleaned.data <- data[, keep]
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Friday, August 6, 2021 7:34 AM
> > To: Duncan Murdoch <murdoch.duncan at gmail.com>
> > Cc: r-help <r-help at r-project.org>
> > Subject: Re: [R] Sanity check in loading large dataframe
> >
> > Ok, so nothing to worry about. Yet, are there other checks I can
> implement?
> > Thank you
> >
> > On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <murdoch.duncan at gmail.com>
> > wrote:
> >
> > > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> > >  > Hello,
> > >  > I am using a large spreadsheet (over 600 variables).
> > >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ....
> > >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> > >  >    [list output truncated]
> > >  > NULL
> > >  > ```
> > >  > I understand that `[list output truncated]` means that there are
> > > more  > variables than those allowed by str to be displayed as rows.
> > > Thus I  > increased the row's output with:
> > >  > ```
> > >  >
> > >  >> (str(df, list.len=1000))
> > >  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ...
> > >  > NULL
> > >  > ```
> > >  >
> > >  > Does `NULL` mean that some of the variables are not closed?
> > > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > > sanity of the data and avoid that some  > separator is not in the
> > > right place?
> > >  > Thank you
> > >
> > > The NULL is the value returned by str().  Normally it is not printed,
> > > but when you wrap str in parens as (str(df, list.len=1000)), that
> > > forces the value to print.
> > >
> > > str() is unusual in R functions in that it prints to the console as it
> > > runs and returns nothing.  Many other functions construct a value
> > > which is only displayed if you print it, but something like
> > >
> > > x <- str(df, list.len=1000)
> > >
> > > will print the same as if there was no assignment, and then assign
> > > NULL to x.
> > >
> > > Duncan Murdoch
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 16:13:18 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 16:13:18 +0200
Subject: [R] split element vector
Message-ID: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>

Hello,
I have a vector that contains some elements with concatenated values, such as:
```
> vect
[1] "name_1"
[2] "name_2"
[3] "name_3\nsurname_3"
[4] "some other text\netc"
```
How can I create a new vector where each component is an element, such as:
```
> vect
[1] "name_1"
[2] "name_2"
[3] "name_3"
[4] "surname_3"
[5] "some other text"
[6] "etc"
```
I can split the elements on '\n' but how do I transfer these directly
on a new vector?
Thanks


From w||||@mwdun|@p @end|ng |rom gm@||@com  Fri Aug  6 16:17:45 2021
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Fri, 6 Aug 2021 07:17:45 -0700
Subject: [R] split element vector
In-Reply-To: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>
References: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>
Message-ID: <CAHqSRuQeH403gj7pTkPLF5Y4sEnXmTuqAJhUqbcznbzo4xjR_w@mail.gmail.com>

unlist(strsplit(vect, "\n"))

On Fri, Aug 6, 2021 at 7:13 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I have a vector that contains some elements with concatenated values, such
> as:
> ```
> > vect
> [1] "name_1"
> [2] "name_2"
> [3] "name_3\nsurname_3"
> [4] "some other text\netc"
> ```
> How can I create a new vector where each component is an element, such as:
> ```
> > vect
> [1] "name_1"
> [2] "name_2"
> [3] "name_3"
> [4] "surname_3"
> [5] "some other text"
> [6] "etc"
> ```
> I can split the elements on '\n' but how do I transfer these directly
> on a new vector?
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug  6 16:49:15 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 6 Aug 2021 16:49:15 +0200
Subject: [R] split element vector
In-Reply-To: <CAHqSRuQeH403gj7pTkPLF5Y4sEnXmTuqAJhUqbcznbzo4xjR_w@mail.gmail.com>
References: <CAMk+s2TVYzZNJVTWGTgKECOSFH_t+sPBk+onPT8zQ2HZyy7ntQ@mail.gmail.com>
 <CAHqSRuQeH403gj7pTkPLF5Y4sEnXmTuqAJhUqbcznbzo4xjR_w@mail.gmail.com>
Message-ID: <CAMk+s2RXcft_ayPgU6Fd_rtYzCrkx0pqF+a0Ujwt9ojS-RqdUg@mail.gmail.com>

Perfect!
thank you

On Fri, Aug 6, 2021 at 4:17 PM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> unlist(strsplit(vect, "\n"))
>
> On Fri, Aug 6, 2021 at 7:13 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I have a vector that contains some elements with concatenated values, such as:
>> ```
>> > vect
>> [1] "name_1"
>> [2] "name_2"
>> [3] "name_3\nsurname_3"
>> [4] "some other text\netc"
>> ```
>> How can I create a new vector where each component is an element, such as:
>> ```
>> > vect
>> [1] "name_1"
>> [2] "name_2"
>> [3] "name_3"
>> [4] "surname_3"
>> [5] "some other text"
>> [6] "etc"
>> ```
>> I can split the elements on '\n' but how do I transfer these directly
>> on a new vector?
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Fri Aug  6 18:02:42 2021
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Fri, 6 Aug 2021 17:02:42 +0100
Subject: [R] 
 What are the pros and cons of the log.p parameter in (p|q)norm
 and similar?
In-Reply-To: <CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A@mail.gmail.com>
References: <e17bdaaa-7945-4f37-ee69-941eb8270f16@dewey.myzen.co.uk>
 <c15f610b-7a16-9d84-884c-54cc170bbad8@gmail.com>
 <CAHqSRuSBQyuyJ5a9YrHk3BHXPn5UmbxQ54bKhAU3G6yroCnG4A@mail.gmail.com>
Message-ID: <e2f33304-bae1-8b23-5376-fe26856a2046@dewey.myzen.co.uk>

Sent off-list

Thanks Bill and Duncan. I only asked for advice but I got an education too.

Michael

On 03/08/2021 21:24, Bill Dunlap wrote:
> In maximum likelihood problems, even when the individual density values 
> are fairly far from zero, their product may underflow to zero.  
> Optimizers have problems when there is a?large flat area.
>  ? ?> q <- runif(n=1000, -0.1, +0.1)
>  ? ?> prod(dnorm(q))
>  ? ?[1] 0
>  ? ?> sum(dnorm(q, log=TRUE))
>  ? ?[1] -920.6556
> 
> A more minor advantage for some probability-related functions is speed.  
> E.g., dnorm(log=TRUE,...) does not need to evaluate?exp().
>  ? ?> q <- runif(1e6, -10, 10)
>  ? ?> system.time(for(i in 1:100)dnorm(q, log=FALSE))
>  ? ? ? user ?system elapsed
>  ? ? ? 9.13 ? ?0.11 ? ?9.23
>  ? ?> system.time(for(i in 1:100)dnorm(q, log=TRUE))
>  ? ? ? user ?system elapsed
>  ? ? ? 4.60 ? ?0.19 ? ?4.78
> 
>  ?-Bill
> 
> On Tue, Aug 3, 2021 at 11:53 AM Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 03/08/2021 12:20 p.m., Michael Dewey wrote:
>      > Short version
>      >
>      > Apart from the ability to work with values of p too small to be
>     of much
>      > practical use what are the advantages and disadvantages of
>     setting this
>      > to TRUE?
>      >
>      > Longer version
>      >
>      > I am contemplating upgrading various functions in one of my
>     packages to
>      > use this and as far as I can see it would only have the advantage of
>      > allowing people to use very small p-values but before I go ahead
>     have I
>      > missed anything? I am most concerned with negatives but if there
>     is any
>      > other advantage I would mention that in the vignette. I am not
>     concerned
>      > about speed or the extra effort in coding and expanding the
>     documentation.
>      >
> 
>     These are often needed in likelihood problems.? In just about any
>     problem where the normal density shows up in the likelihood, you're
>     better off working with the log likelihood and setting log = TRUE in
>     dnorm, because sometimes you want to evaluate the likelihood very far
>     from its mode.
> 
>     The same sort of thing happens with pnorm for similar reasons.? Some
>     likelihoods involve normal integrals and will need it.
> 
>     I can't think of an example for qnorm off the top of my head, but I
>     imagine there are some:? maybe involving simulation way out in the
>     tails.
> 
>     The main negative about using logs is that they aren't always needed.
> 
>     Duncan Murdoch
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
> 
> 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 	Virus-free. www.avg.com 
> <http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=emailclient> 
> 
> 
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From hu@p|ng@w@n @end|ng |rom gm@||@com  Sat Aug  7 09:57:17 2021
From: hu@p|ng@w@n @end|ng |rom gm@||@com (hp wan)
Date: Sat, 7 Aug 2021 15:57:17 +0800
Subject: [R] SOS package: findFn does not work
Message-ID: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>

Dear All,

Recently, I found that the SOS package (very helpful package) does not
work.  When I used the "findFn" function to search something, it always
said "found 0 matches" (see below). My desktop system is Win 10 and R
version is R-4.1.0. Any suggestion was greatly appreciated.

HP


> z <- findFn("spline", maxPages = 2)
found 0 matches
Warning message:
In findFn("spline", maxPages = 2) :
  HIT not found in HTML;  processing one page only.

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Sat Aug  7 12:39:29 2021
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Sat, 7 Aug 2021 05:39:29 -0500
Subject: [R] SOS package: findFn does not work
In-Reply-To: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
References: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
Message-ID: <6043d8f0-8ca8-1ce8-b830-8398dc16bb9c@effectivedefense.org>

Thanks for the question.  Two things:


** 1.  TRY THE DEVELOPMENT VERSION OBTAINABLE AS FOLLOWS:


install.packages('devtools') # if it's not installed


library(devtools)


install_github("sbgraves237/sos")


library(sos)


  z <- findFn("spline", maxPages = 2)


# This should work.


** 2.  PLEASE PROVIDE:


sessionInfo()


	  "findFn('spline')" just worked for me using both the CRAN and 
development versions of sos.  (2.1-0 from CRAN under Windows 10; 2.1- 
from GitHub under macOS 11.4; both with R 4.1.0).


	  I need to push the GitHub version to CRAN.  However, it would help me 
if I understood your configuration and if the GitHub version fixes the 
problem for you.


	  Thanks for the report.  I apologize for the inconvenience.


	  Spencer Graves


On 8/7/21 2:57 AM, hp wan wrote:
> Dear All,
> 
> Recently, I found that the SOS package (very helpful package) does not
> work.  When I used the "findFn" function to search something, it always
> said "found 0 matches" (see below). My desktop system is Win 10 and R
> version is R-4.1.0. Any suggestion was greatly appreciated.
> 
> HP
> 
> 
>> z <- findFn("spline", maxPages = 2)
> found 0 matches
> Warning message:
> In findFn("spline", maxPages = 2) :
>    HIT not found in HTML;  processing one page only.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Aug  7 12:42:23 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 7 Aug 2021 11:42:23 +0100
Subject: [R] SOS package: findFn does not work
In-Reply-To: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
References: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
Message-ID: <29cef7dd-0b0d-3189-2131-432b91279d0b@sapo.pt>

Hello,

R 4.1.0 on Ubuntu 20.04.
I cannot reproduce this:


sos::findFn("spline", maxPages = 2)
#found 3867 matches;  retrieving 2 pages, 40 matches.
#2
#Downloaded 40 links in 27 packages.


Possible solutions are to close and restart R and to check your internet 
connection.
Is the package updated?

packageVersion("sos")
#[1] ?2.1.0?


Hope this helps,

Rui Barradas

?s 08:57 de 07/08/21, hp wan escreveu:
> Dear All,
> 
> Recently, I found that the SOS package (very helpful package) does not
> work.  When I used the "findFn" function to search something, it always
> said "found 0 matches" (see below). My desktop system is Win 10 and R
> version is R-4.1.0. Any suggestion was greatly appreciated.
> 
> HP
> 
> 
>> z <- findFn("spline", maxPages = 2)
> found 0 matches
> Warning message:
> In findFn("spline", maxPages = 2) :
>    HIT not found in HTML;  processing one page only.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From er|cjberger @end|ng |rom gm@||@com  Sat Aug  7 14:35:42 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 7 Aug 2021 15:35:42 +0300
Subject: [R] SOS package: findFn does not work
In-Reply-To: <29cef7dd-0b0d-3189-2131-432b91279d0b@sapo.pt>
References: <CAAZWX_xNKyff8+jOQDVPEN0zz9Xf1uLHbcfwyRDT_rPAfAEEyQ@mail.gmail.com>
 <29cef7dd-0b0d-3189-2131-432b91279d0b@sapo.pt>
Message-ID: <CAGgJW760CJAvbUtQDPkOXHvkqHfmMMg-faKw_xOcwn=72pVpwg@mail.gmail.com>

Hi,
I was able to reproduce this problem on R 4.0.3 on Ubuntu 20.04.
I removed the CRAN sos package and installed the github version per
Spencer's advice.
After that it worked fine.

Eric


On Sat, Aug 7, 2021 at 1:50 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> R 4.1.0 on Ubuntu 20.04.
> I cannot reproduce this:
>
>
> sos::findFn("spline", maxPages = 2)
> #found 3867 matches;  retrieving 2 pages, 40 matches.
> #2
> #Downloaded 40 links in 27 packages.
>
>
> Possible solutions are to close and restart R and to check your internet
> connection.
> Is the package updated?
>
> packageVersion("sos")
> #[1] ?2.1.0?
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 08:57 de 07/08/21, hp wan escreveu:
> > Dear All,
> >
> > Recently, I found that the SOS package (very helpful package) does not
> > work.  When I used the "findFn" function to search something, it always
> > said "found 0 matches" (see below). My desktop system is Win 10 and R
> > version is R-4.1.0. Any suggestion was greatly appreciated.
> >
> > HP
> >
> >
> >> z <- findFn("spline", maxPages = 2)
> > found 0 matches
> > Warning message:
> > In findFn("spline", maxPages = 2) :
> >    HIT not found in HTML;  processing one page only.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @gent@ @end|ng |rom medd@t@|nc@com  Sun Aug  8 03:21:31 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Sat, 7 Aug 2021 21:21:31 -0400
Subject: [R] Markov modeling using msm
Message-ID: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>

I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...

The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?

If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?

Appreciate any pointers.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Aug  8 04:33:31 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 7 Aug 2021 19:33:31 -0700
Subject: [R] Markov modeling using msm
In-Reply-To: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
References: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
Message-ID: <CAGxFJbSYCNz3B9-FZJunam_JFVGKwGqoQ4WDLv0j2EQr-VQqqA@mail.gmail.com>

Please read the posting guide linked below, which says, in part:

"Questions about statistics: The R mailing lists are primarily
intended for questions and discussion about the R software. However,
questions about statistical methodology are sometimes posted. If the
question is well-asked and of interest to someone on the list, it may
elicit an informative up-to-date answer. "

So do not be surprised if you do not get a response here.
stats.stackexchange.com may be a better venue for your query, too.

The posting guide also says:
"For questions about functions in standard packages distributed with R
(see the FAQ Add-on packages in R), ask questions on R-help.
If the question relates to a contributed package , e.g., one
downloaded from CRAN, try contacting the package maintainer first. You
can also use find("functionname") and
packageDescription("packagename") to find this information. Only send
such questions to R-help or R-devel if you get no reply or need
further assistance. This applies to both requests for help and to bug
reports."

So perhaps contacting the msm maintainer might be another possibility.
See ?maintainer for how to find their contact info.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Aug 7, 2021 at 6:21 PM H <agents at meddatainc.com> wrote:
>
> I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...
>
> The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?
>
> If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?
>
> Appreciate any pointers.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Aug  8 04:45:07 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sun, 8 Aug 2021 14:45:07 +1200
Subject: [R] No "doc" directory in my installation  of R.
Message-ID: <20210808144507.61a8290e@rolf-Latitude-E7470>


Should/shouldn't there be one?

My R seems to be installed in /usr/lib/R.  If do an "ls" of this
directory, I get:

> bin/  COPYING@	etc/  lib/  library/  modules/
> site-library/  SVN-REVISION

Definitely no "doc".

The (only) reason that I am concerned about this, is that I have decided
to experiment a bit with Rstudio, and it apparently wants a "doc"
directory.  When I try to start Rstudio I get a pop-up window with the
error message

> R doc dir (/usr/local/lib64/R/doc) not found.

Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
The latter is where my installation put R; the former seems to be where
Rstudio wants it to.  So I created the symbolic link.

The discrepancy between locations is another puzzle/worry.

My installation comes from a pre-built binary ("sudo apt install
r-base").  I apparently have the latest version.  I remark that I am
running Ubuntu 20.04 with a Mate 1.20.4 desktop.

How can I get a "doc" directory into my R directory and make Rstudio
happy?

cheers,

Rolf Turner

P.S. I have also tried to ask about this on the  Rstudio community
forum, but it seems to me to more of an R question than an Rstudio one.

R. T.

--
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Aug  8 05:26:13 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 7 Aug 2021 20:26:13 -0700 (PDT)
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210808144507.61a8290e@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
Message-ID: <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>

R documentation on my Ubuntu 20.20 is in /usr/share/R/doc.

I see no doc directories in the locations you mention using

   locate /doc/

Maybe you should be asking on R-sig-debian, perhaps with less noise about 
RStudio?

On Sun, 8 Aug 2021, Rolf Turner wrote:

>
> Should/shouldn't there be one?
>
> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> directory, I get:
>
>> bin/  COPYING@	etc/  lib/  library/  modules/
>> site-library/  SVN-REVISION
>
> Definitely no "doc".
>
> The (only) reason that I am concerned about this, is that I have decided
> to experiment a bit with Rstudio, and it apparently wants a "doc"
> directory.  When I try to start Rstudio I get a pop-up window with the
> error message
>
>> R doc dir (/usr/local/lib64/R/doc) not found.
>
> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> The latter is where my installation put R; the former seems to be where
> Rstudio wants it to.  So I created the symbolic link.
>
> The discrepancy between locations is another puzzle/worry.
>
> My installation comes from a pre-built binary ("sudo apt install
> r-base").  I apparently have the latest version.  I remark that I am
> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>
> How can I get a "doc" directory into my R directory and make Rstudio
> happy?
>
> cheers,
>
> Rolf Turner
>
> P.S. I have also tried to ask about this on the  Rstudio community
> forum, but it seems to me to more of an R question than an Rstudio one.
>
> R. T.
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From drj|m|emon @end|ng |rom gm@||@com  Sun Aug  8 06:29:30 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 8 Aug 2021 14:29:30 +1000
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210808144507.61a8290e@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
Message-ID: <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>

Hi Rolf,
What about:

mkdir /usr/lib/R/doc

Jim

On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Should/shouldn't there be one?
>
> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> directory, I get:
>
> > bin/  COPYING@        etc/  lib/  library/  modules/
> > site-library/  SVN-REVISION
>
> Definitely no "doc".
>
> The (only) reason that I am concerned about this, is that I have decided
> to experiment a bit with Rstudio, and it apparently wants a "doc"
> directory.  When I try to start Rstudio I get a pop-up window with the
> error message
>
> > R doc dir (/usr/local/lib64/R/doc) not found.
>
> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> The latter is where my installation put R; the former seems to be where
> Rstudio wants it to.  So I created the symbolic link.
>
> The discrepancy between locations is another puzzle/worry.
>
> My installation comes from a pre-built binary ("sudo apt install
> r-base").  I apparently have the latest version.  I remark that I am
> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>
> How can I get a "doc" directory into my R directory and make Rstudio
> happy?
>
> cheers,
>
> Rolf Turner
>
> P.S. I have also tried to ask about this on the  Rstudio community
> forum, but it seems to me to more of an R question than an Rstudio one.
>
> R. T.
>
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  8 09:43:17 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Aug 2021 08:43:17 +0100
Subject: [R] Markov modeling using msm
In-Reply-To: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
References: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
Message-ID: <da291c0c-3657-264c-66cb-46f16c275595@sapo.pt>

Hello,

There are CRAN packages, for instance, packages DTMCPack and 
markovchain, that require transition probabilities as input. See this 
R-bloggers post [1].


[1] https://www.r-bloggers.com/2016/01/getting-started-with-markov-chains/


Hope this helps,

Rui Barradas

?s 02:21 de 08/08/21, H escreveu:
> I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...
> 
> The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?
> 
> If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?
> 
> Appreciate any pointers.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkr|de@u @end|ng |rom gm@||@com  Sun Aug  8 14:51:16 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sun, 8 Aug 2021 08:51:16 -0400
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
Message-ID: <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>

R version 4.1.0 (2021-05-18)
RStudio 1.4.1714
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 20.04.2 LTS

I do not see a doc folder at R level but a lot of newer packages,
probably tidyverse derived seem to have a doc sub-folder containing
documentation files

For example corrplot has a doc subfolder containing
corrplot-intro.html
corrplot-intro.R
corrplot-intro.Rmd
index.html

Jim Lemon's suggestion seems worth trying but I really think this is
some RStudio weirdity. I have been using RStudio for 3-4 years and a
several complete installations on new machines and tave never seen
anything like "R doc dir (/usr/local/lib64/R/doc) not found".

RStudio keeps getting tweaked.



On Sun, 8 Aug 2021 at 00:30, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Rolf,
> What about:
>
> mkdir /usr/lib/R/doc
>
> Jim
>
> On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
> >
> >
> > Should/shouldn't there be one?
> >
> > My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> > directory, I get:
> >
> > > bin/  COPYING@        etc/  lib/  library/  modules/
> > > site-library/  SVN-REVISION
> >
> > Definitely no "doc".
> >
> > The (only) reason that I am concerned about this, is that I have decided
> > to experiment a bit with Rstudio, and it apparently wants a "doc"
> > directory.  When I try to start Rstudio I get a pop-up window with the
> > error message
> >
> > > R doc dir (/usr/local/lib64/R/doc) not found.
> >
> > Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> > The latter is where my installation put R; the former seems to be where
> > Rstudio wants it to.  So I created the symbolic link.
> >
> > The discrepancy between locations is another puzzle/worry.
> >
> > My installation comes from a pre-built binary ("sudo apt install
> > r-base").  I apparently have the latest version.  I remark that I am
> > running Ubuntu 20.04 with a Mate 1.20.4 desktop.
> >
> > How can I get a "doc" directory into my R directory and make Rstudio
> > happy?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > P.S. I have also tried to ask about this on the  Rstudio community
> > forum, but it seems to me to more of an R question than an Rstudio one.
> >
> > R. T.
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  8 15:15:23 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 8 Aug 2021 09:15:23 -0400
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
 <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>
Message-ID: <1467d67e-2aa9-bb8d-d3e1-42843cb55aa8@gmail.com>

Jeff pointed out where the doc directory is installed in Ubuntu: 
/usr/share/R/doc.  So this is definitely an RStudio issue:  perhaps it 
got "tweaked", or perhaps Rolf installed a version meant for some other 
distribution.  In either case, off-topic in R-help, I think.

Duncan Murdoch

On 08/08/2021 8:51 a.m., John Kane wrote:
> R version 4.1.0 (2021-05-18)
> RStudio 1.4.1714
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 20.04.2 LTS
> 
> I do not see a doc folder at R level but a lot of newer packages,
> probably tidyverse derived seem to have a doc sub-folder containing
> documentation files
> 
> For example corrplot has a doc subfolder containing
> corrplot-intro.html
> corrplot-intro.R
> corrplot-intro.Rmd
> index.html
> 
> Jim Lemon's suggestion seems worth trying but I really think this is
> some RStudio weirdity. I have been using RStudio for 3-4 years and a
> several complete installations on new machines and tave never seen
> anything like "R doc dir (/usr/local/lib64/R/doc) not found".
> 
> RStudio keeps getting tweaked.
> 
> 
> 
> On Sun, 8 Aug 2021 at 00:30, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Rolf,
>> What about:
>>
>> mkdir /usr/lib/R/doc
>>
>> Jim
>>
>> On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>
>>>
>>> Should/shouldn't there be one?
>>>
>>> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
>>> directory, I get:
>>>
>>>> bin/  COPYING@        etc/  lib/  library/  modules/
>>>> site-library/  SVN-REVISION
>>>
>>> Definitely no "doc".
>>>
>>> The (only) reason that I am concerned about this, is that I have decided
>>> to experiment a bit with Rstudio, and it apparently wants a "doc"
>>> directory.  When I try to start Rstudio I get a pop-up window with the
>>> error message
>>>
>>>> R doc dir (/usr/local/lib64/R/doc) not found.
>>>
>>> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
>>> The latter is where my installation put R; the former seems to be where
>>> Rstudio wants it to.  So I created the symbolic link.
>>>
>>> The discrepancy between locations is another puzzle/worry.
>>>
>>> My installation comes from a pre-built binary ("sudo apt install
>>> r-base").  I apparently have the latest version.  I remark that I am
>>> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>>>
>>> How can I get a "doc" directory into my R directory and make Rstudio
>>> happy?
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> P.S. I have also tried to ask about this on the  Rstudio community
>>> forum, but it seems to me to more of an R question than an Rstudio one.
>>>
>>> R. T.
>>>
>>> --
>>> Honorary Research Fellow
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  8 16:03:32 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Aug 2021 15:03:32 +0100
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <1467d67e-2aa9-bb8d-d3e1-42843cb55aa8@gmail.com>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <CA+8X3fUv+9_b3ipMdbD317iaWASnkj8TcKpBViyYSuZ1RPDd0A@mail.gmail.com>
 <CAKZQJMAsrowOjc_ujKKGcW5eoytnXGzA38yypdrJwJ1n5K=ocA@mail.gmail.com>
 <1467d67e-2aa9-bb8d-d3e1-42843cb55aa8@gmail.com>
Message-ID: <59dc9698-697d-90d4-e64b-1f9e612ce488@sapo.pt>

Hello,

R 4.1.0 on Ubuntu 20.04.
My ls command on /usr/lib/R on my home computer gives what Rolf posted, 
so I agree with every body that this is not an R issue and would insist 
with RStudio and ask for their help again. They are generally helpful, btw.

I follow installation instructions to the letter and have never had any 
problems like this one. If the installation of R seems OK, have you 
tried to uninstall and reinstall RStudio?


rui at rui:~$ ls /usr/lib/R
bin  COPYING  etc  lib  library  modules  site-library  SVN-REVISION
rui at rui:~$ ls /usr/share/R
debian  doc  include  share


Hope this helps,

Rui Barradas


?s 14:15 de 08/08/21, Duncan Murdoch escreveu:
> Jeff pointed out where the doc directory is installed in Ubuntu: 
> /usr/share/R/doc.? So this is definitely an RStudio issue:? perhaps it 
> got "tweaked", or perhaps Rolf installed a version meant for some other 
> distribution.? In either case, off-topic in R-help, I think.
> 
> Duncan Murdoch
> 
> On 08/08/2021 8:51 a.m., John Kane wrote:
>> R version 4.1.0 (2021-05-18)
>> RStudio 1.4.1714
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 20.04.2 LTS
>>
>> I do not see a doc folder at R level but a lot of newer packages,
>> probably tidyverse derived seem to have a doc sub-folder containing
>> documentation files
>>
>> For example corrplot has a doc subfolder containing
>> corrplot-intro.html
>> corrplot-intro.R
>> corrplot-intro.Rmd
>> index.html
>>
>> Jim Lemon's suggestion seems worth trying but I really think this is
>> some RStudio weirdity. I have been using RStudio for 3-4 years and a
>> several complete installations on new machines and tave never seen
>> anything like "R doc dir (/usr/local/lib64/R/doc) not found".
>>
>> RStudio keeps getting tweaked.
>>
>>
>>
>> On Sun, 8 Aug 2021 at 00:30, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Rolf,
>>> What about:
>>>
>>> mkdir /usr/lib/R/doc
>>>
>>> Jim
>>>
>>> On Sun, Aug 8, 2021 at 12:45 PM Rolf Turner <r.turner at auckland.ac.nz> 
>>> wrote:
>>>>
>>>>
>>>> Should/shouldn't there be one?
>>>>
>>>> My R seems to be installed in /usr/lib/R.? If do an "ls" of this
>>>> directory, I get:
>>>>
>>>>> bin/? COPYING@??????? etc/? lib/? library/? modules/
>>>>> site-library/? SVN-REVISION
>>>>
>>>> Definitely no "doc".
>>>>
>>>> The (only) reason that I am concerned about this, is that I have 
>>>> decided
>>>> to experiment a bit with Rstudio, and it apparently wants a "doc"
>>>> directory.? When I try to start Rstudio I get a pop-up window with the
>>>> error message
>>>>
>>>>> R doc dir (/usr/local/lib64/R/doc) not found.
>>>>
>>>> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
>>>> The latter is where my installation put R; the former seems to be where
>>>> Rstudio wants it to.? So I created the symbolic link.
>>>>
>>>> The discrepancy between locations is another puzzle/worry.
>>>>
>>>> My installation comes from a pre-built binary ("sudo apt install
>>>> r-base").? I apparently have the latest version.? I remark that I am
>>>> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
>>>>
>>>> How can I get a "doc" directory into my R directory and make Rstudio
>>>> happy?
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>> P.S. I have also tried to ask about this on the? Rstudio community
>>>> forum, but it seems to me to more of an R question than an Rstudio one.
>>>>
>>>> R. T.
>>>>
>>>> -- 
>>>> Honorary Research Fellow
>>>> Department of Statistics
>>>> University of Auckland
>>>> Phone: +64-9-373-7599 ext. 88276
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide 
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Sun Aug  8 16:52:20 2021
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Sun, 8 Aug 2021 10:52:20 -0400
Subject: [R] Markov modeling using msm
In-Reply-To: <da291c0c-3657-264c-66cb-46f16c275595@sapo.pt>
References: <060376a5-8c50-924f-72e2-e23845a0d92d@meddatainc.com>
 <da291c0c-3657-264c-66cb-46f16c275595@sapo.pt>
Message-ID: <5736aa5f-fbae-4c42-be93-3d6d6c36926b@meddatainc.com>

On 08/08/2021 03:43 AM, Rui Barradas wrote:
> Hello,
>
> There are CRAN packages, for instance, packages DTMCPack and markovchain, that require transition probabilities as input. See this R-bloggers post [1].
>
>
> [1] https://www.r-bloggers.com/2016/01/getting-started-with-markov-chains/
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 02:21 de 08/08/21, H escreveu:
>> I would like to use R and msm to replicate the results from a published study where the authors used Tree Age Pro 2011 for their Markov modeling. I am new to Markov modeling and while I have tried to read up, my understanding is still quite limited...
>>
>> The papers contains the the state transition probabilities but it seems to me that msm requires transition intensities rather than transition probabilities. Is this correct?
>>
>> If so, the msm documentation suggests that msm can output transition probabilities but is there any way I can do the reverse, ie input transition probabilities into my msm model?
>>
>> Appreciate any pointers.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
Thank you, will check those out!


From @|@y@hz@k@r|@ @end|ng |rom un|m@p@edu@my  Sat Aug  7 09:53:43 2021
From: @|@y@hz@k@r|@ @end|ng |rom un|m@p@edu@my (SITI AISYAH ZAKARIA)
Date: Sat, 7 Aug 2021 15:53:43 +0800
Subject: [R] HOW TO SOLVE THIS PROBLEM (RVALS)
Message-ID: <CALcx2Bmkkd1KmB9ASXOaaHQpipehFPqq-j6vSsDHG11+XHCbKQ@mail.gmail.com>

Hi,

Can anyone help me how to solve this problem?

 #calculation of confidence intervals
1. > nc <- 10000
2. > M1 <- matrix(rfrechet(nc*nobs),nrow=nobs,ncol=nc)
3. > M <- t(apply(M1,2,sort))
4. > E <- envelope(mat=M) #compute 95% confidance bands
*Error in envelope.matrix(mat = M) : rvals must be supplied*

My problem is after I run my coding in line 4 the error is highlighted red
is come out. I don't know how to solve it. Please help me.

Thank you

-- 





"..Millions of trees are used to make papers, only to be thrown away 
after a couple of minutes reading from them. Our planet is at stake. Please 
be considerate. THINK TWICE BEFORE PRINTING THIS.."

DISCLAIMER:?This email \ and any files transmitte...{{dropped:24}}


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Aug  8 17:41:22 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 8 Aug 2021 16:41:22 +0100
Subject: [R] HOW TO SOLVE THIS PROBLEM (RVALS)
In-Reply-To: <CALcx2Bmkkd1KmB9ASXOaaHQpipehFPqq-j6vSsDHG11+XHCbKQ@mail.gmail.com>
References: <CALcx2Bmkkd1KmB9ASXOaaHQpipehFPqq-j6vSsDHG11+XHCbKQ@mail.gmail.com>
Message-ID: <518f8de5-7548-9bbd-8bb3-86f213391bc0@sapo.pt>

Hello,

nobs is missing in your example.

Assuming that envelope is the function in package base boot, I cannot 
reproduce the error.


set.seed(2021)
nc <- 10000
nobs <- 100
M1 <- matrix(evd::rfrechet(nc*nobs),nrow=nobs,ncol=nc)
M <- t(apply(M1,2,sort))
E <- boot::envelope(mat=M) #compute 95% confidance bands

str(E)
#List of 7
# $ point  : num [1:2, 1:100] 0.302 0.12 0.341 0.167 0.373 ...
# $ overall: num [1:2, 1:100] 0.3698 0.0832 0.4163 0.1287 0.4499 ...
# $ k.pt   : num [1:2] 250 9751
# $ err.pt : num [1:2] 0.05 0.562
# $ k.ov   : num [1:2] 11 9990
# $ err.ov : num [1:2] 0.0022 0.0496
# $ err.nom: num [1:2] 0.05 0.05


Hope this helps,

Rui Barradas


?s 08:53 de 07/08/21, SITI AISYAH ZAKARIA escreveu:
> Hi,
> 
> Can anyone help me how to solve this problem?
> 
>   #calculation of confidence intervals
> 1. > nc <- 10000
> 2. > M1 <- matrix(rfrechet(nc*nobs),nrow=nobs,ncol=nc)
> 3. > M <- t(apply(M1,2,sort))
> 4. > E <- envelope(mat=M) #compute 95% confidance bands
> *Error in envelope.matrix(mat = M) : rvals must be supplied*
> 
> My problem is after I run my coding in line 4 the error is highlighted red
> is come out. I don't know how to solve it. Please help me.
> 
> Thank you
>


From jwd @end|ng |rom @urewe@t@net  Sun Aug  8 21:43:44 2021
From: jwd @end|ng |rom @urewe@t@net (John Dougherty)
Date: Sun, 8 Aug 2021 12:43:44 -0700
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
Message-ID: <20210808124344.06013fe7.jwd@surewest.net>

On Sat, 7 Aug 2021 20:26:13 -0700 (PDT)
Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

Documentation on most Linux systems, regardless of release, is commonly
located under the /usr/share directory.  For R that is
/usr/share/doc/R.  There is also a "man" entry for R.  The rstudio help
list might be able to help more than this list.  

> R documentation on my Ubuntu 20.20 is in /usr/share/R/doc.
> 
> I see no doc directories in the locations you mention using
> 
>    locate /doc/
> 
> Maybe you should be asking on R-sig-debian, perhaps with less noise
> about RStudio?
> 
> On Sun, 8 Aug 2021, Rolf Turner wrote:
> 
> >
> > Should/shouldn't there be one?
> >
> > My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> > directory, I get:
> >  
> >> bin/  COPYING@	etc/  lib/  library/  modules/
> >> site-library/  SVN-REVISION  
> >
> > Definitely no "doc".
> >
> > The (only) reason that I am concerned about this, is that I have
> > decided to experiment a bit with Rstudio, and it apparently wants a
> > "doc" directory.  When I try to start Rstudio I get a pop-up window
> > with the error message
> >  
> >> R doc dir (/usr/local/lib64/R/doc) not found.  
> >
> > Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> > The latter is where my installation put R; the former seems to be
> > where Rstudio wants it to.  So I created the symbolic link.
> >
> > The discrepancy between locations is another puzzle/worry.
> >
> > My installation comes from a pre-built binary ("sudo apt install
> > r-base").  I apparently have the latest version.  I remark that I am
> > running Ubuntu 20.04 with a Mate 1.20.4 desktop.
> >
> > How can I get a "doc" directory into my R directory and make Rstudio
> > happy?
> >
> > cheers,
> >
> > Rolf Turner
> >
> > P.S. I have also tried to ask about this on the  Rstudio community
> > forum, but it seems to me to more of an R question than an Rstudio
> > one.
> >
> > R. T.
> >
> > --
> > Honorary Research Fellow
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html and provide commented,
> > minimal, self-contained, reproducible code. 
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go
> Live... DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
> ##.#.  Live Go... Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
>


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Aug  8 22:19:54 2021
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 8 Aug 2021 16:19:54 -0400
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210808144507.61a8290e@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
Message-ID: <340f22a2-45b3-e2b8-78c4-e99c1f8736cd@gmail.com>


If you start R just using the regular command line version (not 
RStudio), does

   Sys.getenv("R_DOC_DIR")

point to /usr/share/R/doc ?  The standard R startup script should do 
that, but if it doesn't maybe you've got an override?

Or maybe you have R_DOC_DIR defined yourself?

Duncan Murdoch


On 07/08/2021 10:45 p.m., Rolf Turner wrote:
> 
> Should/shouldn't there be one?
> 
> My R seems to be installed in /usr/lib/R.  If do an "ls" of this
> directory, I get:
> 
>> bin/  COPYING@	etc/  lib/  library/  modules/
>> site-library/  SVN-REVISION
> 
> Definitely no "doc".
> 
> The (only) reason that I am concerned about this, is that I have decided
> to experiment a bit with Rstudio, and it apparently wants a "doc"
> directory.  When I try to start Rstudio I get a pop-up window with the
> error message
> 
>> R doc dir (/usr/local/lib64/R/doc) not found.
> 
> Note that /usr/local/lib64/R is a symbolic link to /usr/lib/R.
> The latter is where my installation put R; the former seems to be where
> Rstudio wants it to.  So I created the symbolic link.
> 
> The discrepancy between locations is another puzzle/worry.
> 
> My installation comes from a pre-built binary ("sudo apt install
> r-base").  I apparently have the latest version.  I remark that I am
> running Ubuntu 20.04 with a Mate 1.20.4 desktop.
> 
> How can I get a "doc" directory into my R directory and make Rstudio
> happy?
> 
> cheers,
> 
> Rolf Turner
> 
> P.S. I have also tried to ask about this on the  Rstudio community
> forum, but it seems to me to more of an R question than an Rstudio one.
> 
> R. T.
> 
> --
> Honorary Research Fellow
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ho@@@|nmm @end|ng |rom jun|v@edu  Sun Aug  8 23:24:35 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Sun, 8 Aug 2021 22:24:35 +0100
Subject: [R] Calculation of Age heaping
Message-ID: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>

Dear R-expert,

I hope that you are doing well.

I am interested to calculate the age heaping for each digit (0,1,...,9)
based on my data set. However, when I run the R code, I got the following
errors. Please help me in this regard.

##########################################
library(remotes)
install_github("timriffe/DemoTools")

###
Downloading GitHub repo timriffe/DemoTools at HEAD
These packages have more recent versions available.
It is recommended to update all of them.
Which would you like to update?

 1: All
 2: CRAN packages only
 3: None

Enter one or more numbers, or an empty line to skip updates: 1

*After installing some packages, I got the following error message*

package ?backports? successfully unpacked and MD5 sums checked
Error: Failed to install 'DemoTools' from GitHub:
  (converted from warning) cannot remove prior installation of package
?backports?

I am attaching the R-code and data file along with this email.

Please help me in this regard.

Thanks in advance.
-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: R-code.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20210808/353b258e/attachment.txt>

From @v|gro@@ @end|ng |rom ver|zon@net  Sun Aug  8 23:48:12 2021
From: @v|gro@@ @end|ng |rom ver|zon@net (Avi Gross)
Date: Sun, 8 Aug 2021 17:48:12 -0400
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
References: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
Message-ID: <117001d78c9f$164183c0$42c48b40$@verizon.net>

It is not too clear to me what you want to do and why that package is the way to do it. Is the package a required part of your assignment? If so, maybe someone else can help you find how to properly install it on your machine, assuming you have permissions to replace the other package it seems to require. You may need to create your own environment. If you are open to other ways, see below.

Are you trying to do something as simple as counting how many people in your data are in various buckets such as each age truncated or rounded to an integer from 0 to 99? If so, you might miss some of my cousins alive at 100 or that died at 103 and 105 recently ?

Or do you want ages in groups of 10 or so meaning the first of two digits is 0 through 9?

Many such things can be done quite easily without the package if you wish.

As far as I can tell, your code reads in a data.frame from your local file with any number of columns that you do not specify. If it is one, the solution becomes much easier. You then for some reason feel the need to convert it to a matrix. You then do whatever your Whipple does several ways.

Here is an outline of ways you can do this yourself.

First, combine all your data into one or more vectors. You already have that in your data.frame but if all columns are numeric, you can of course do something with a matrix.

Then make sure you remove anything objectionable, such as negative numbers or numbers too large or NA or whatever your logic requires.

If you have a variable ready with N entries to hold the buckets, such as length(0:100) or for even buckets of 5, perhaps length(0:99)/5 you initialize that to all zeroes.

Now take your data, and perhaps transform it into a copy where every age is truncated to an integer or divided by 5 first or whatever you need so it contains a pure integer like 6 or 12. What I mean is if your buckets are 5 wide, and you want 5:9 to map into one bucket, your transform might be as.integer(original/5.0) or one of many variants like that.

You can now simply use one of many methods in R to loop through your values that result and assuming you have a zeroed vector called counter and the current value being looked at is N, you simply increment counter[N] or of N-1 or whatever your logic requires.

Alternately R has many built-in methods (or in other packages) like cut() that might do something similar without as much work.

And just for the heck of it, I tried your download instructions. Unlike your three choices, I was offered 13 choices and as I had no clue what YOU were supposed to download, I aborted.

 1: All                               
2: CRAN packages only                
3: None                              
4: colorspace (2.0-1 -> 2.0-2) [CRAN]
5: isoband    (0.2.4 -> 0.2.5) [CRAN]
6: utf8       (1.2.1 -> 1.2.2) [CRAN]
7: cli        (3.0.0 -> 3.0.1) [CRAN]
8: ggplot2    (3.3.3 -> 3.3.5) [CRAN]
9: pillar     (1.6.1 -> 1.6.2) [CRAN]
10: tibble     (3.1.2 -> 3.1.3) [CRAN]
11: dplyr      (1.0.6 -> 1.0.7) [CRAN]
12: Rcpp       (1.0.6 -> 1.0.7) [CRAN]
13: curl       (4.3.1 -> 4.3.2) [CRAN]
14: cpp11      (0.2.7 -> 0.3.1) [CRAN]

In your case, if you selected All, what exactly did you expect?


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Md. Moyazzem Hossain
Sent: Sunday, August 8, 2021 5:25 PM
To: r-help at r-project.org
Subject: [R] Calculation of Age heaping

Dear R-expert,

I hope that you are doing well.

I am interested to calculate the age heaping for each digit (0,1,...,9) based on my data set. However, when I run the R code, I got the following errors. Please help me in this regard.

##########################################
library(remotes)
install_github("timriffe/DemoTools")

###
Downloading GitHub repo timriffe/DemoTools at HEAD These packages have more recent versions available.
It is recommended to update all of them.
Which would you like to update?

 1: All
 2: CRAN packages only
 3: None

Enter one or more numbers, or an empty line to skip updates: 1

*After installing some packages, I got the following error message*

package ?backports? successfully unpacked and MD5 sums checked
Error: Failed to install 'DemoTools' from GitHub:
  (converted from warning) cannot remove prior installation of package ?backports?

I am attaching the R-code and data file along with this email.

Please help me in this regard.

Thanks in advance.
--
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Aug  9 03:39:33 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 8 Aug 2021 18:39:33 -0700
Subject: [R] 
 Issue regarding specifying pdBlocked matrix for random effects
 vcov in nlme package
In-Reply-To: <DS7PR10MB4895D5BE058460D73A4C6907ADEF9@DS7PR10MB4895.namprd10.prod.outlook.com>
References: <DS7PR10MB4895D5BE058460D73A4C6907ADEF9@DS7PR10MB4895.namprd10.prod.outlook.com>
Message-ID: <fa4f197d-5c6e-0d40-1594-d86d5ec487b6@comcast.net>

Dear Dr. David;

Re; List rejection

I'm unable to explain why this posting was refused. It does have 4 image 
files attached. That is more than I typically see on Rhelp. I'm only a 
volunteer moderator, and not one of the owners of the list. I speculate 
that if you were to repost to rhelp (and NOT to R-Core where this 
message does not belong) and you were to substitute copied text from 
your console for all except the first image, it might go through (at 
least to the moderation queue where it could be reviewed by human eyes 
and wetware. (I suspect the number of images and links caused an 
automatic spam rejection.)

I also wonder if your modified re-submission should instead be directed 
to the R-SIG-mixed-models list since that appears to be the question 
topic. Some of the experts there are not regular contributor of viewers 
of Rhelp which is focused on the maechanics of the R language itself.

-- 

David Winsemius

Volunteer moderator.

On 8/2/21 1:43 PM, Benjamin Davis wrote:
>
> Hello,
>
> ??????????????? I have come across an issue regarding specifying the 
> vcov of the random effects while using the /medrc/ package, which I 
> believe is very likely to originate from the /nlme/ package. I have 
> posted the question to StackOverflow if it is easier to read there:
>
> https://stackoverflow.com/questions/68626894/specifying-the-variance-covariance-matrix-for-random-effects-for-medrc-or-nlme 
> <https://urldefense.com/v3/__https://stackoverflow.com/questions/68626894/specifying-the-variance-covariance-matrix-for-random-effects-for-medrc-or-nlme__;!!HGYKHdhaPg!Ghq6dEJafKNBdT7h64jc9_H5JJWEnEQ891_QRsUZClnGXCeYntzRiXDmmq2XMTQ$>.
>
> I am using a 3-parameter log-logistic non-linear function
>
> and am including a species indicator variable based on whether my data 
> originates from humans (H) or rats (R). I am looking to specify a 
> blocked variance-covariance matrix for the random effects where 
> covariances are estimated for the off-diagonals of function parameters 
> within the same species, but not between species.
>
> I have attempted to estimate this vcov using the ?medrm? function from 
> the /medrc/ package. While the notation is slightly different from the 
> ?nlme? function, the estimation is performed in the same manner. I 
> have attempted to specify the random effect vcov using the 
> ?'pdBlocked' function.
>
> M3b <- medrm(inhibition ~ concentration, curveid=b + d + e ~ species,? 
> data=OP,
>
> ?????????????????????????????random= 
> list(subject=pdBlocked(list(b~species, d~species, e~species))),
>
> ?????????????????????fct=LL.3(), control=c(drmc(method="CG"), 
> nlmeControl(msMaxIter = 150)))
>
> However, this results in almost the opposite of what I intended, 
> providing covariances within parameter type but across species (which 
> is non-sensical given that no subject can be both a human and a rat).
>
> Do you have any recommendations on how to fix this, ideally using one 
> of the existing pd-matrix functions?
>
> Thanks in advance for your reply.
>
> *Benjamin Davis, Ph.D.*
> Senior Scientist
> *Exponent*
> Direct +1-202-772-4942
> Email davisb at exponent.com <mailto:davisb at exponent.com>
>
> *Benjamin Davis, Ph.D.*
> Senior Scientist
> *Exponent*
> Direct +1-202-772-4942
> Email davisb at exponent.com <mailto:davisb at exponent.com>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Mon Aug  9 08:30:11 2021
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Mon, 9 Aug 2021 06:30:11 +0000
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>
Message-ID: <9192f7107d4148b18cf19d882cf002cc@SRVEXCHCM1302.precheza.cz>

Hi Bert

Yes, in this case which is not necessary. But in case NAs are involved 
sometimes logical indexing is not a best choice as NA propagates to the 
result, which may be not wanted.

x <- 1:10
x[c(2,5)] <- NA
y<- letters[1:10]
y[x<5]
[1] "a" NA  "c" "d" NA
y[which(x<5)]
[1] "a" "c" "d"
dat <- data.frame(x,y)
dat[x<5,]
      x    y
1     1    a
NA   NA <NA>
3     3    c
4     4    d
NA.1 NA <NA>

> dat[which(x<5),]
  x y
1 1 a
3 3 c
4 4 d

Both results are OK, but one has to consider this NA value propagation.

Cheers
Petr

From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Friday, August 6, 2021 1:29 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
Subject: Re: [R] Sanity check in loading large dataframe

... but remove the which() and use logical indexing ...  ;-)


Bert Gunter

"The trouble with having an open mind is that people keep coming along and 
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Aug 6, 2021 at 12:57 AM PIKAL Petr <mailto:petr.pikal at precheza.cz> 
wrote:
Hi

You already got answer from Avi. I often use dim(data) to inspect how many
rows/columns I have.
After that I check if some columns contain all or many NA values.

colSums(http://is.na(data))
keep <- which(colSums(http://is.na(data))<nnn)
cleaned.data <- data[, keep]

Cheers
Petr


> -----Original Message-----
> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Luigi 
> Marongiu
> Sent: Friday, August 6, 2021 7:34 AM
> To: Duncan Murdoch <mailto:murdoch.duncan at gmail.com>
> Cc: r-help <mailto:r-help at r-project.org>
> Subject: Re: [R] Sanity check in loading large dataframe
>
> Ok, so nothing to worry about. Yet, are there other checks I can
implement?
> Thank you
>
> On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <mailto:murdoch.duncan at gmail.com>
> wrote:
>
> > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> >  > Hello,
> >  > I am using a large spreadsheet (over 600 variables).
> >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ....
> >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> >  >    [list output truncated]
> >  > NULL
> >  > ```
> >  > I understand that `[list output truncated]` means that there are
> > more  > variables than those allowed by str to be displayed as rows.
> > Thus I  > increased the row's output with:
> >  > ```
> >  >
> >  >> (str(df, list.len=1000))
> >  > 'data.frame': 302 obs. of  626 variables:
> >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> >  > ...
> >  > NULL
> >  > ```
> >  >
> >  > Does `NULL` mean that some of the variables are not closed?
> > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > sanity of the data and avoid that some  > separator is not in the
> > right place?
> >  > Thank you
> >
> > The NULL is the value returned by str().  Normally it is not printed,
> > but when you wrap str in parens as (str(df, list.len=1000)), that
> > forces the value to print.
> >
> > str() is unusual in R functions in that it prints to the console as it
> > runs and returns nothing.  Many other functions construct a value
> > which is only displayed if you print it, but something like
> >
> > x <- str(df, list.len=1000)
> >
> > will print the same as if there was no assignment, and then assign
> > NULL to x.
> >
> > Duncan Murdoch
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 10:26:03 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 10:26:03 +0200
Subject: [R] substitute column data frame based on name stored in variable
 in r
Message-ID: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>

Hello,
I would like to recursively select the columns of a dataframe by
strong the names of the dataframe in a vector and extracting one
element of the vector at a time. This I can do with, for instance:
```
vect = names(df)
sub_df[vect[1]]
```

The problem is that I would like also to change the values of the
selected column using some logic as in `df$column[df$column == value]
<- new.value`, but I am confused on the syntax for the vectorized
version. Specifically, this does not work:
```
sub_df[vect[1] == 0] = "No"
```
What would be the correct approach?
Thank you


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 10:42:32 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 10:42:32 +0200
Subject: [R] Apply gsub to dataframe to modify row values
Message-ID: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>

Hello,
I have a dataframe where I would like to change the string of certain
rows, essentially I am looking to remove some useless text from the
variables.
I tried with:
```
> df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> df
  VAR           VAL value is blue Value is red empty
1   1 value is blue          blue         blue  blue
2   2  Value is red           red          red   red
3   3         empty         empty        empty empty
```
which is of course wrong because I was expecting
```
  VAR           VAL
1   1             blue
2   2             red
3   3            empty
```
What is the correct syntax in these cases?
Thank you


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 10:53:29 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 18:53:29 +1000
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
Message-ID: <CA+8X3fVd4Gxg7668KMhB-nCrvxdHVmP8cqxgrUx2sn9G33qFZQ@mail.gmail.com>

Hi Luigi,
It looks to me as though you will have to copy the data frame or store
the output in a new data frame.

Jim

On Mon, Aug 9, 2021 at 6:26 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I would like to recursively select the columns of a dataframe by
> strong the names of the dataframe in a vector and extracting one
> element of the vector at a time. This I can do with, for instance:
> ```
> vect = names(df)
> sub_df[vect[1]]
> ```
>
> The problem is that I would like also to change the values of the
> selected column using some logic as in `df$column[df$column == value]
> <- new.value`, but I am confused on the syntax for the vectorized
> version. Specifically, this does not work:
> ```
> sub_df[vect[1] == 0] = "No"
> ```
> What would be the correct approach?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 10:57:22 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 10:57:22 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CA+8X3fVd4Gxg7668KMhB-nCrvxdHVmP8cqxgrUx2sn9G33qFZQ@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <CA+8X3fVd4Gxg7668KMhB-nCrvxdHVmP8cqxgrUx2sn9G33qFZQ@mail.gmail.com>
Message-ID: <CAMk+s2Rn7sMhvtanE3RiOPC8f-zwA19we4iNhn4MJ5NZ2D55VA@mail.gmail.com>

Thank you very much, but that would make even more work due to the
duplication...

On Mon, Aug 9, 2021 at 10:53 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> It looks to me as though you will have to copy the data frame or store
> the output in a new data frame.
>
> Jim
>
> On Mon, Aug 9, 2021 at 6:26 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I would like to recursively select the columns of a dataframe by
> > strong the names of the dataframe in a vector and extracting one
> > element of the vector at a time. This I can do with, for instance:
> > ```
> > vect = names(df)
> > sub_df[vect[1]]
> > ```
> >
> > The problem is that I would like also to change the values of the
> > selected column using some logic as in `df$column[df$column == value]
> > <- new.value`, but I am confused on the syntax for the vectorized
> > version. Specifically, this does not work:
> > ```
> > sub_df[vect[1] == 0] = "No"
> > ```
> > What would be the correct approach?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 11:01:41 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 19:01:41 +1000
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
Message-ID: <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>

Hi Luigi,
Ah, now I see:

 df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
df
 VAR   VAL
1   1  blue
2   2   red
3   3 empty

Jim

On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I have a dataframe where I would like to change the string of certain
> rows, essentially I am looking to remove some useless text from the
> variables.
> I tried with:
> ```
> > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > df
>   VAR           VAL value is blue Value is red empty
> 1   1 value is blue          blue         blue  blue
> 2   2  Value is red           red          red   red
> 3   3         empty         empty        empty empty
> ```
> which is of course wrong because I was expecting
> ```
>   VAR           VAL
> 1   1             blue
> 2   2             red
> 3   3            empty
> ```
> What is the correct syntax in these cases?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug  9 11:24:51 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 9 Aug 2021 11:24:51 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
Message-ID: <20210809112451.78a21095@trisector>

On Mon, 9 Aug 2021 10:26:03 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> vect = names(df)
> sub_df[vect[1]]

> df$column[df$column == value] <- new.value

Let's see, an equivalent expression without the $ syntax is
`df[['column']][df[['column']] == value] <- new.value`. Slightly
shorter, matrix-like syntax would give us
`df[df[['column']] == value, 'column'] <- new.value`.

Now replace 'column' with vect[i] and you're done. The `[[`-indexing is
used here to get the column contents instead of a single-column
data.frame that `[`-indexing returns for lists.

Also note that df[[names(df)[i]]] should be the same as df[[i]] for
most data.frames.

-- 
Best regards,
Ivan


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  9 12:27:52 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 9 Aug 2021 11:27:52 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <117001d78c9f$164183c0$42c48b40$@verizon.net>
References: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
 <117001d78c9f$164183c0$42c48b40$@verizon.net>
Message-ID: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>

Dear Avi Gross,

Thank you very much for your email. Actually, I have a little knowledge of
R programming.

I have a dataset of ages ranging from 10 to 90. Now, I want to find out the
Whipple?s index for age heaping among individuals for each digit like
0,1,...,9.

I have searched in google I got the following functions. That's why I use
the package and the following code.

*check_heaping_whipple(Value, Age, ageMin = 25, ageMax = 65, digit = c(0,
5)) *     [link:
https://rdrr.io/github/timriffe/DemoTools/man/check_heaping_whipple.html]

Thanks in advance.

Md



On Sun, Aug 8, 2021 at 10:48 PM Avi Gross via R-help <r-help at r-project.org>
wrote:

> It is not too clear to me what you want to do and why that package is the
> way to do it. Is the package a required part of your assignment? If so,
> maybe someone else can help you find how to properly install it on your
> machine, assuming you have permissions to replace the other package it
> seems to require. You may need to create your own environment. If you are
> open to other ways, see below.
>
> Are you trying to do something as simple as counting how many people in
> your data are in various buckets such as each age truncated or rounded to
> an integer from 0 to 99? If so, you might miss some of my cousins alive at
> 100 or that died at 103 and 105 recently ?
>
> Or do you want ages in groups of 10 or so meaning the first of two digits
> is 0 through 9?
>
> Many such things can be done quite easily without the package if you wish.
>
> As far as I can tell, your code reads in a data.frame from your local file
> with any number of columns that you do not specify. If it is one, the
> solution becomes much easier. You then for some reason feel the need to
> convert it to a matrix. You then do whatever your Whipple does several ways.
>
> Here is an outline of ways you can do this yourself.
>
> First, combine all your data into one or more vectors. You already have
> that in your data.frame but if all columns are numeric, you can of course
> do something with a matrix.
>
> Then make sure you remove anything objectionable, such as negative numbers
> or numbers too large or NA or whatever your logic requires.
>
> If you have a variable ready with N entries to hold the buckets, such as
> length(0:100) or for even buckets of 5, perhaps length(0:99)/5 you
> initialize that to all zeroes.
>
> Now take your data, and perhaps transform it into a copy where every age
> is truncated to an integer or divided by 5 first or whatever you need so it
> contains a pure integer like 6 or 12. What I mean is if your buckets are 5
> wide, and you want 5:9 to map into one bucket, your transform might be
> as.integer(original/5.0) or one of many variants like that.
>
> You can now simply use one of many methods in R to loop through your
> values that result and assuming you have a zeroed vector called counter and
> the current value being looked at is N, you simply increment counter[N] or
> of N-1 or whatever your logic requires.
>
> Alternately R has many built-in methods (or in other packages) like cut()
> that might do something similar without as much work.
>
> And just for the heck of it, I tried your download instructions. Unlike
> your three choices, I was offered 13 choices and as I had no clue what YOU
> were supposed to download, I aborted.
>
>  1: All
> 2: CRAN packages only
> 3: None
> 4: colorspace (2.0-1 -> 2.0-2) [CRAN]
> 5: isoband    (0.2.4 -> 0.2.5) [CRAN]
> 6: utf8       (1.2.1 -> 1.2.2) [CRAN]
> 7: cli        (3.0.0 -> 3.0.1) [CRAN]
> 8: ggplot2    (3.3.3 -> 3.3.5) [CRAN]
> 9: pillar     (1.6.1 -> 1.6.2) [CRAN]
> 10: tibble     (3.1.2 -> 3.1.3) [CRAN]
> 11: dplyr      (1.0.6 -> 1.0.7) [CRAN]
> 12: Rcpp       (1.0.6 -> 1.0.7) [CRAN]
> 13: curl       (4.3.1 -> 4.3.2) [CRAN]
> 14: cpp11      (0.2.7 -> 0.3.1) [CRAN]
>
> In your case, if you selected All, what exactly did you expect?
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Md. Moyazzem
> Hossain
> Sent: Sunday, August 8, 2021 5:25 PM
> To: r-help at r-project.org
> Subject: [R] Calculation of Age heaping
>
> Dear R-expert,
>
> I hope that you are doing well.
>
> I am interested to calculate the age heaping for each digit (0,1,...,9)
> based on my data set. However, when I run the R code, I got the following
> errors. Please help me in this regard.
>
> ##########################################
> library(remotes)
> install_github("timriffe/DemoTools")
>
> ###
> Downloading GitHub repo timriffe/DemoTools at HEAD These packages have more
> recent versions available.
> It is recommended to update all of them.
> Which would you like to update?
>
>  1: All
>  2: CRAN packages only
>  3: None
>
> Enter one or more numbers, or an empty line to skip updates: 1
>
> *After installing some packages, I got the following error message*
>
> package ?backports? successfully unpacked and MD5 sums checked
> Error: Failed to install 'DemoTools' from GitHub:
>   (converted from warning) cannot remove prior installation of package
> ?backports?
>
> I am attaching the R-code and data file along with this email.
>
> Please help me in this regard.
>
> Thanks in advance.
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *Google Scholar
> <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 12:40:17 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 12:40:17 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
Message-ID: <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>

Thank you, that is much appreciated. But on the real data, the
substitution works only on few instances. Is there a way to introduce
regex into this?
Cheers
Luigi

On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> Ah, now I see:
>
>  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> df
>  VAR   VAL
> 1   1  blue
> 2   2   red
> 3   3 empty
>
> Jim
>
> On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I have a dataframe where I would like to change the string of certain
> > rows, essentially I am looking to remove some useless text from the
> > variables.
> > I tried with:
> > ```
> > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > df
> >   VAR           VAL value is blue Value is red empty
> > 1   1 value is blue          blue         blue  blue
> > 2   2  Value is red           red          red   red
> > 3   3         empty         empty        empty empty
> > ```
> > which is of course wrong because I was expecting
> > ```
> >   VAR           VAL
> > 1   1             blue
> > 2   2             red
> > 3   3            empty
> > ```
> > What is the correct syntax in these cases?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 12:50:00 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 12:50:00 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
Message-ID: <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>

Sorry, silly question, gsub works already with regex. But still, if I
add `[[:blank:]]` still I don't get rid of all instances. And I am
keeping obtaining extra columns
```
> df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
  VAR           VAL value is blue Value is red empty
1   1 value is blue             b            b     b
2   2  Value is red            rd           rd    rd
3   3         empty          mpty         mpty  mpty
```

On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Thank you, that is much appreciated. But on the real data, the
> substitution works only on few instances. Is there a way to introduce
> regex into this?
> Cheers
> Luigi
>
> On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Luigi,
> > Ah, now I see:
> >
> >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > df
> >  VAR   VAL
> > 1   1  blue
> > 2   2   red
> > 3   3 empty
> >
> > Jim
> >
> > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I have a dataframe where I would like to change the string of certain
> > > rows, essentially I am looking to remove some useless text from the
> > > variables.
> > > I tried with:
> > > ```
> > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > > df
> > >   VAR           VAL value is blue Value is red empty
> > > 1   1 value is blue          blue         blue  blue
> > > 2   2  Value is red           red          red   red
> > > 3   3         empty         empty        empty empty
> > > ```
> > > which is of course wrong because I was expecting
> > > ```
> > >   VAR           VAL
> > > 1   1             blue
> > > 2   2             red
> > > 3   3            empty
> > > ```
> > > What is the correct syntax in these cases?
> > > Thank you
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi



-- 
Best regards,
Luigi


From m|n@h@|| @end|ng |rom um|ch@edu  Mon Aug  9 13:04:51 2021
From: m|n@h@|| @end|ng |rom um|ch@edu (Greg Minshall)
Date: Mon, 09 Aug 2021 14:04:51 +0300
Subject: [R] Calculation of Age heaping
In-Reply-To: Your message of "Mon, 09 Aug 2021 11:27:52 +0100."
 <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
Message-ID: <513810.1628507091@apollo2.minshall.org>

Md,

if this is what you are looking for:
----
https://en.wikipedia.org/wiki/Whipple%27s_index
----

then, the article says the algorithm is
----
The index score is obtained by summing the number of persons in the age
range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
that sum by the total population between ages 23 and 62 years inclusive,
and multiplying the result by 5. Restated as a percentage, index scores
range between 100 (no preference for ages ending in 0 and 5) and 500
(all people reporting ages ending in 0 and 5).
----

that seems fairly straight forward.  if you are trying to learn R,
and/or learn programming, i might suggest you *not* use a package, and
rather work on coding up the calculation yourself.  that would probably
be a good, but not too hard, exercise, of some interest.  enjoy!

cheers, Greg


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 13:16:02 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 13:16:02 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <20210809112451.78a21095@trisector>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
Message-ID: <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>

Thank you but I think I got it wrong:
```
> df = data.frame(VAR = letters[1:5], VAL = c(1, 2, NA, 2, NA)); df
  VAR VAL
1   a   1
2   b   2
3   c  NA
4   d   2
5   e  NA
> vect = letters[1:5]
> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"; df
  VAR VAL vect[2]
1   a   1    <NA>
2   b   2    <NA>
3   c  NA    <NA>
4   d   2    <NA>
5   e  NA    <NA>
```

On Mon, Aug 9, 2021 at 11:25 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Mon, 9 Aug 2021 10:26:03 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > vect = names(df)
> > sub_df[vect[1]]
>
> > df$column[df$column == value] <- new.value
>
> Let's see, an equivalent expression without the $ syntax is
> `df[['column']][df[['column']] == value] <- new.value`. Slightly
> shorter, matrix-like syntax would give us
> `df[df[['column']] == value, 'column'] <- new.value`.
>
> Now replace 'column' with vect[i] and you're done. The `[[`-indexing is
> used here to get the column contents instead of a single-column
> data.frame that `[`-indexing returns for lists.
>
> Also note that df[[names(df)[i]]] should be the same as df[[i]] for
> most data.frames.
>
> --
> Best regards,
> Ivan



-- 
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug  9 13:31:34 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 9 Aug 2021 13:31:34 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
Message-ID: <20210809133134.784edd06@trisector>

On Mon, 9 Aug 2021 13:16:02 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> df = data.frame(VAR = ..., VAL = ...)
> vect = letters[1:5]

What is the relation between vect and the column names of the data
frame? Is it your intention to choose rows or columns using `vect`?

> df[df[['vect[2]']] == 2, 'vect[2]']

'...' creates a string literal. If you want to evaluate an R
expression, don't wrap it in quotes.

I had assumed you wanted to put column names in the vector `vect`, but
now I'm just confused: `vect` is the same as df$VAR, not colnames(df).
What do you want to achieve?

Again, you can access the second column with much less typing by
addressing it directly: df[[2]]

Does it help if you consult [**] or some other tutorial on subsetting
in R?

-- 
Best regards,
Ivan

[**] 
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors
https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Lists


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 13:32:50 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 21:32:50 +1000
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
Message-ID: <CA+8X3fWBgRGEXM-QqkSAumb2e6FgBES_EdBUaX3gvtMTY5_QfQ@mail.gmail.com>

Hi Luigi,
You want to get rid of certain strings in the "VAL" column. You are
assigning to:

df[df$VAL]
Error in `[.data.frame`(df, df$VAL) : undefined columns selected

when I think you should be assigning to:

df$VAL

What do you want to remove other than "[V|v]alue is" ?

JIim

On Mon, Aug 9, 2021 at 8:50 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Sorry, silly question, gsub works already with regex. But still, if I
> add `[[:blank:]]` still I don't get rid of all instances. And I am
> keeping obtaining extra columns
> ```
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
>   VAR           VAL value is blue Value is red empty
> 1   1 value is blue             b            b     b
> 2   2  Value is red            rd           rd    rd
> 3   3         empty          mpty         mpty  mpty
> ```
>
> On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Thank you, that is much appreciated. But on the real data, the
> > substitution works only on few instances. Is there a way to introduce
> > regex into this?
> > Cheers
> > Luigi
> >
> > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > Ah, now I see:
> > >
> > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > > df
> > >  VAR   VAL
> > > 1   1  blue
> > > 2   2   red
> > > 3   3 empty
> > >
> > > Jim
> > >
> > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have a dataframe where I would like to change the string of certain
> > > > rows, essentially I am looking to remove some useless text from the
> > > > variables.
> > > > I tried with:
> > > > ```
> > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > > > df
> > > >   VAR           VAL value is blue Value is red empty
> > > > 1   1 value is blue          blue         blue  blue
> > > > 2   2  Value is red           red          red   red
> > > > 3   3         empty         empty        empty empty
> > > > ```
> > > > which is of course wrong because I was expecting
> > > > ```
> > > >   VAR           VAL
> > > > 1   1             blue
> > > > 2   2             red
> > > > 3   3            empty
> > > > ```
> > > > What is the correct syntax in these cases?
> > > > Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  9 13:36:30 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 9 Aug 2021 12:36:30 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <513810.1628507091@apollo2.minshall.org>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
Message-ID: <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>

Dear Greg,

Thank you very much for your suggestion. I will try it and follow your
advice.

Actually, I want to find out the index for each digit like 0, 1, ..., 9.

Thanks in advance. Take care.

Md



On Mon, Aug 9, 2021 at 12:05 PM Greg Minshall <minshall at umich.edu> wrote:

> Md,
>
> if this is what you are looking for:
> ----
> https://en.wikipedia.org/wiki/Whipple%27s_index
> ----
>
> then, the article says the algorithm is
> ----
> The index score is obtained by summing the number of persons in the age
> range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> that sum by the total population between ages 23 and 62 years inclusive,
> and multiplying the result by 5. Restated as a percentage, index scores
> range between 100 (no preference for ages ending in 0 and 5) and 500
> (all people reporting ages ending in 0 and 5).
> ----
>
> that seems fairly straight forward.  if you are trying to learn R,
> and/or learn programming, i might suggest you *not* use a package, and
> rather work on coding up the calculation yourself.  that would probably
> be a good, but not too hard, exercise, of some interest.  enjoy!
>
> cheers, Greg
>
>

-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Mon Aug  9 13:40:01 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Mon, 9 Aug 2021 23:40:01 +1200
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
References: <CAO29qn6szaNp5FNqZhtefTYz4LHeGFzx6O02VbOmJBX9XFZkKQ@mail.gmail.com>
 <117001d78c9f$164183c0$42c48b40$@verizon.net>
 <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
Message-ID: <CABcYAdLvfO0KGcG8ozF7xVVbG27k__hADy04zpE_8jFXE+QMVw@mail.gmail.com>

According to Wikipedia, this is the definition of Whipple's index:

"The index score is obtained by summing the number of persons in the
age range 23 and 62 inclusive, who report ages ending in 0 and 5,
dividing that sum by the total population between ages 23 and 62 years
inclusive, and multiplying the result by 5. Restated as a percentage,
index scores range between 100 (no preference for ages ending in 0 and
5) and 500 (all people reporting ages ending in 0 and 5)."

Let ages be a vector of integers representing ages.
whipple <- function (ages) {
    mids <- ages[ages >= 23 & ages <= 62] * 2
    5 * mean( mids %% 10 == 0)
}

If you want any other digit(s), you could try
whipple <- function (ages, digits = c(0,5)) {
    mids <- ages[ages >= 23 & ages <= 62] %% 10
    (10/leng(digits)) * mean(mids %in% digits)
}

So it is not clear to me why you want any package to do this.
The Whipple index does not come with any statistical measure of strength,
although https://en.wikipedia.org/wiki/Whipple%27s_index
mentions a UN table of values to compare with.

That Wikipedia page also warns about limits to applicability.
I note that with the exception of using an upper inclusive bound of
62 (as in the Wikipedia page) this definition of the Whipple index
agrees perfectly with that in A'Hearn et al's papers (which use 72)
but NOT with DemoTools.  So you need to be very clear to yourself
and others where your definition of the Whipple index comes from,
what it is, and whether the code you use computes what you think
it does.  (UNTESTED CODE ABOVE!)

On Mon, 9 Aug 2021 at 22:28, Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Dear Avi Gross,
>
> Thank you very much for your email. Actually, I have a little knowledge of
> R programming.
>
> I have a dataset of ages ranging from 10 to 90. Now, I want to find out the
> Whipple?s index for age heaping among individuals for each digit like
> 0,1,...,9.
>
> I have searched in google I got the following functions. That's why I use
> the package and the following code.
>
> *check_heaping_whipple(Value, Age, ageMin = 25, ageMax = 65, digit = c(0,
> 5)) *     [link:
> https://rdrr.io/github/timriffe/DemoTools/man/check_heaping_whipple.html]
>
> Thanks in advance.
>
> Md
>
>
>
> On Sun, Aug 8, 2021 at 10:48 PM Avi Gross via R-help <r-help at r-project.org>
> wrote:
>
> > It is not too clear to me what you want to do and why that package is the
> > way to do it. Is the package a required part of your assignment? If so,
> > maybe someone else can help you find how to properly install it on your
> > machine, assuming you have permissions to replace the other package it
> > seems to require. You may need to create your own environment. If you are
> > open to other ways, see below.
> >
> > Are you trying to do something as simple as counting how many people in
> > your data are in various buckets such as each age truncated or rounded to
> > an integer from 0 to 99? If so, you might miss some of my cousins alive at
> > 100 or that died at 103 and 105 recently ?
> >
> > Or do you want ages in groups of 10 or so meaning the first of two digits
> > is 0 through 9?
> >
> > Many such things can be done quite easily without the package if you wish.
> >
> > As far as I can tell, your code reads in a data.frame from your local file
> > with any number of columns that you do not specify. If it is one, the
> > solution becomes much easier. You then for some reason feel the need to
> > convert it to a matrix. You then do whatever your Whipple does several ways.
> >
> > Here is an outline of ways you can do this yourself.
> >
> > First, combine all your data into one or more vectors. You already have
> > that in your data.frame but if all columns are numeric, you can of course
> > do something with a matrix.
> >
> > Then make sure you remove anything objectionable, such as negative numbers
> > or numbers too large or NA or whatever your logic requires.
> >
> > If you have a variable ready with N entries to hold the buckets, such as
> > length(0:100) or for even buckets of 5, perhaps length(0:99)/5 you
> > initialize that to all zeroes.
> >
> > Now take your data, and perhaps transform it into a copy where every age
> > is truncated to an integer or divided by 5 first or whatever you need so it
> > contains a pure integer like 6 or 12. What I mean is if your buckets are 5
> > wide, and you want 5:9 to map into one bucket, your transform might be
> > as.integer(original/5.0) or one of many variants like that.
> >
> > You can now simply use one of many methods in R to loop through your
> > values that result and assuming you have a zeroed vector called counter and
> > the current value being looked at is N, you simply increment counter[N] or
> > of N-1 or whatever your logic requires.
> >
> > Alternately R has many built-in methods (or in other packages) like cut()
> > that might do something similar without as much work.
> >
> > And just for the heck of it, I tried your download instructions. Unlike
> > your three choices, I was offered 13 choices and as I had no clue what YOU
> > were supposed to download, I aborted.
> >
> >  1: All
> > 2: CRAN packages only
> > 3: None
> > 4: colorspace (2.0-1 -> 2.0-2) [CRAN]
> > 5: isoband    (0.2.4 -> 0.2.5) [CRAN]
> > 6: utf8       (1.2.1 -> 1.2.2) [CRAN]
> > 7: cli        (3.0.0 -> 3.0.1) [CRAN]
> > 8: ggplot2    (3.3.3 -> 3.3.5) [CRAN]
> > 9: pillar     (1.6.1 -> 1.6.2) [CRAN]
> > 10: tibble     (3.1.2 -> 3.1.3) [CRAN]
> > 11: dplyr      (1.0.6 -> 1.0.7) [CRAN]
> > 12: Rcpp       (1.0.6 -> 1.0.7) [CRAN]
> > 13: curl       (4.3.1 -> 4.3.2) [CRAN]
> > 14: cpp11      (0.2.7 -> 0.3.1) [CRAN]
> >
> > In your case, if you selected All, what exactly did you expect?
> >
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Md. Moyazzem
> > Hossain
> > Sent: Sunday, August 8, 2021 5:25 PM
> > To: r-help at r-project.org
> > Subject: [R] Calculation of Age heaping
> >
> > Dear R-expert,
> >
> > I hope that you are doing well.
> >
> > I am interested to calculate the age heaping for each digit (0,1,...,9)
> > based on my data set. However, when I run the R code, I got the following
> > errors. Please help me in this regard.
> >
> > ##########################################
> > library(remotes)
> > install_github("timriffe/DemoTools")
> >
> > ###
> > Downloading GitHub repo timriffe/DemoTools at HEAD These packages have more
> > recent versions available.
> > It is recommended to update all of them.
> > Which would you like to update?
> >
> >  1: All
> >  2: CRAN packages only
> >  3: None
> >
> > Enter one or more numbers, or an empty line to skip updates: 1
> >
> > *After installing some packages, I got the following error message*
> >
> > package ?backports? successfully unpacked and MD5 sums checked
> > Error: Failed to install 'DemoTools' from GitHub:
> >   (converted from warning) cannot remove prior installation of package
> > ?backports?
> >
> > I am attaching the R-code and data file along with this email.
> >
> > Please help me in this regard.
> >
> > Thanks in advance.
> > --
> > Best Regards,
> > Md. Moyazzem Hossain
> > Associate Professor
> > Department of Statistics
> > Jahangirnagar University
> > Savar, Dhaka-1342
> > Bangladesh
> > Website: http://www.juniv.edu/teachers/hossainmm
> > Research: *Google Scholar
> > <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> > *ResearchGate
> > <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> > <https://orcid.org/0000-0003-3593-6936>*
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *Google Scholar
> <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Mon Aug  9 14:17:17 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 9 Aug 2021 22:17:17 +1000
Subject: [R] Calculation of Age heaping
In-Reply-To: <513810.1628507091@apollo2.minshall.org>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
Message-ID: <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>

And if you really don't like programming:

whipple_index<-function(x,td=c(0,5)) {
 wi<-rep(NA,11)
 names(wi)<-c(paste0("wi",0:9),"O/all")
 for(i in 0:9) {
  ttd<-which((x %% 10) %in% i)
  wi[i+1]<-length(ttd) * 100/length(x)
 }
 ttd<-which((x %% 10) %in% td)
 wi[11]<-length(ttd) * 100/(length(x)/length(td))
 return(wi)
}

I haven't tested this extensively, but it may be helpful. You can
specify the final digits for the overall test. Select your ages before
passing them to whipple_index.

Jim

On Mon, Aug 9, 2021 at 9:05 PM Greg Minshall <minshall at umich.edu> wrote:
>
> Md,
>
> if this is what you are looking for:
> ----
> https://en.wikipedia.org/wiki/Whipple%27s_index
> ----
>
> then, the article says the algorithm is
> ----
> The index score is obtained by summing the number of persons in the age
> range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> that sum by the total population between ages 23 and 62 years inclusive,
> and multiplying the result by 5. Restated as a percentage, index scores
> range between 100 (no preference for ages ending in 0 and 5) and 500
> (all people reporting ages ending in 0 and 5).
> ----
>
> that seems fairly straight forward.  if you are trying to learn R,
> and/or learn programming, i might suggest you *not* use a package, and
> rather work on coding up the calculation yourself.  that would probably
> be a good, but not too hard, exercise, of some interest.  enjoy!
>
> cheers, Greg
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ho@@@|nmm @end|ng |rom jun|v@edu  Mon Aug  9 14:50:39 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Mon, 9 Aug 2021 13:50:39 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>
Message-ID: <CAO29qn6Nyis5Xric7ng6qMaZBgXs9ctxS97b6R6+HFmNWK7anA@mail.gmail.com>

Dear Jim,

Thank you very much for your kind help.

Take care.

Md

On Mon, Aug 9, 2021 at 1:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> And if you really don't like programming:
>
> whipple_index<-function(x,td=c(0,5)) {
>  wi<-rep(NA,11)
>  names(wi)<-c(paste0("wi",0:9),"O/all")
>  for(i in 0:9) {
>   ttd<-which((x %% 10) %in% i)
>   wi[i+1]<-length(ttd) * 100/length(x)
>  }
>  ttd<-which((x %% 10) %in% td)
>  wi[11]<-length(ttd) * 100/(length(x)/length(td))
>  return(wi)
> }
>
> I haven't tested this extensively, but it may be helpful. You can
> specify the final digits for the overall test. Select your ages before
> passing them to whipple_index.
>
> Jim
>
> On Mon, Aug 9, 2021 at 9:05 PM Greg Minshall <minshall at umich.edu> wrote:
> >
> > Md,
> >
> > if this is what you are looking for:
> > ----
> > https://en.wikipedia.org/wiki/Whipple%27s_index
> > ----
> >
> > then, the article says the algorithm is
> > ----
> > The index score is obtained by summing the number of persons in the age
> > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> > that sum by the total population between ages 23 and 62 years inclusive,
> > and multiplying the result by 5. Restated as a percentage, index scores
> > range between 100 (no preference for ages ending in 0 and 5) and 500
> > (all people reporting ages ending in 0 and 5).
> > ----
> >
> > that seems fairly straight forward.  if you are trying to learn R,
> > and/or learn programming, i might suggest you *not* use a package, and
> > rather work on coding up the calculation yourself.  that would probably
> > be a good, but not too hard, exercise, of some interest.  enjoy!
> >
> > cheers, Greg
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 15:24:17 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 15:24:17 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CA+8X3fWBgRGEXM-QqkSAumb2e6FgBES_EdBUaX3gvtMTY5_QfQ@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
 <CA+8X3fWBgRGEXM-QqkSAumb2e6FgBES_EdBUaX3gvtMTY5_QfQ@mail.gmail.com>
Message-ID: <CAMk+s2TMVrMTJGy2NwvNUt0EF+WWjR8NUJRxz2FC+Do1oRc6KQ@mail.gmail.com>

I wanted to remove possible white spaces before or after the string.
Actually, it worked, I used `gsub("[:blank:]*val[:blank:]*", "",
df$VAL, ignore.case=TRUE)`. I don't know why in the example there were
extra columns -- they did not came out in the real case.
Thank you, I think the case is closed.
Cheers
Luigi

On Mon, Aug 9, 2021 at 1:33 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Luigi,
> You want to get rid of certain strings in the "VAL" column. You are
> assigning to:
>
> df[df$VAL]
> Error in `[.data.frame`(df, df$VAL) : undefined columns selected
>
> when I think you should be assigning to:
>
> df$VAL
>
> What do you want to remove other than "[V|v]alue is" ?
>
> JIim
>
> On Mon, Aug 9, 2021 at 8:50 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Sorry, silly question, gsub works already with regex. But still, if I
> > add `[[:blank:]]` still I don't get rid of all instances. And I am
> > keeping obtaining extra columns
> > ```
> > > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> > > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
> >   VAR           VAL value is blue Value is red empty
> > 1   1 value is blue             b            b     b
> > 2   2  Value is red            rd           rd    rd
> > 3   3         empty          mpty         mpty  mpty
> > ```
> >
> > On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > >
> > > Thank you, that is much appreciated. But on the real data, the
> > > substitution works only on few instances. Is there a way to introduce
> > > regex into this?
> > > Cheers
> > > Luigi
> > >
> > > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > > Hi Luigi,
> > > > Ah, now I see:
> > > >
> > > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > > > df
> > > >  VAR   VAL
> > > > 1   1  blue
> > > > 2   2   red
> > > > 3   3 empty
> > > >
> > > > Jim
> > > >
> > > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> > > > >
> > > > > Hello,
> > > > > I have a dataframe where I would like to change the string of certain
> > > > > rows, essentially I am looking to remove some useless text from the
> > > > > variables.
> > > > > I tried with:
> > > > > ```
> > > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> > > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
> > > > > > df
> > > > >   VAR           VAL value is blue Value is red empty
> > > > > 1   1 value is blue          blue         blue  blue
> > > > > 2   2  Value is red           red          red   red
> > > > > 3   3         empty         empty        empty empty
> > > > > ```
> > > > > which is of course wrong because I was expecting
> > > > > ```
> > > > >   VAR           VAL
> > > > > 1   1             blue
> > > > > 2   2             red
> > > > > 3   3            empty
> > > > > ```
> > > > > What is the correct syntax in these cases?
> > > > > Thank you
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> >
> >
> >
> > --
> > Best regards,
> > Luigi



-- 
Best regards,
Luigi


From @kw@|mmo @end|ng |rom gm@||@com  Mon Aug  9 15:26:20 2021
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Mon, 9 Aug 2021 09:26:20 -0400
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
Message-ID: <CAPcHnpQiXdgRUjUPafhub4s6jd3otQAATvboMpZZffbD4k_XZg@mail.gmail.com>

Hello,


There are two convenient ways to access a column in a data.frame using `$`
and `[[`. Using `df` from your first email, we would do something like

df <- data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red",
"empty"))
df$VAL
df[["VAL"]]

The two convenient ways to update / / replace a column with something new
are also very similar, something like

df$VAL <- ...
df[["VAL"]] <- ...

As for the regex part, I would suggest using `sub` instead of `gsub` since
you're looking to remove only the first instance of "value is". Also, I
would recommend using "^" to mark the beginning of your string, something
like

df$VAL <- sub("^Value is ", "", df$VAL, ignore.case = TRUE)

I might be misunderstanding, but it sounds like you also want to remove all
leading whitespace. If so, you could do something like

df$VAL <- sub("^[[:blank:]]*Value is ", "", df$VAL, ignore.case = TRUE)

where "*" signifies that there will be zero or more blank characters at the
beginning of the string. You can try `?regex` to read more about this.

I hope this helps!

On Mon, Aug 9, 2021 at 6:50 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Sorry, silly question, gsub works already with regex. But still, if I
> add `[[:blank:]]` still I don't get rid of all instances. And I am
> keeping obtaining extra columns
> ```
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
>   VAR           VAL value is blue Value is red empty
> 1   1 value is blue             b            b     b
> 2   2  Value is red            rd           rd    rd
> 3   3         empty          mpty         mpty  mpty
> ```
>
> On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com>
> wrote:
> >
> > Thank you, that is much appreciated. But on the real data, the
> > substitution works only on few instances. Is there a way to introduce
> > regex into this?
> > Cheers
> > Luigi
> >
> > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > Ah, now I see:
> > >
> > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
> > > df
> > >  VAR   VAL
> > > 1   1  blue
> > > 2   2   red
> > > 3   3 empty
> > >
> > > Jim
> > >
> > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <
> marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I have a dataframe where I would like to change the string of certain
> > > > rows, essentially I am looking to remove some useless text from the
> > > > variables.
> > > > I tried with:
> > > > ```
> > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is
> red", "empty"))
> > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE,
> perl = FALSE)
> > > > > df
> > > >   VAR           VAL value is blue Value is red empty
> > > > 1   1 value is blue          blue         blue  blue
> > > > 2   2  Value is red           red          red   red
> > > > 3   3         empty         empty        empty empty
> > > > ```
> > > > which is of course wrong because I was expecting
> > > > ```
> > > >   VAR           VAL
> > > > 1   1             blue
> > > > 2   2             red
> > > > 3   3            empty
> > > > ```
> > > > What is the correct syntax in these cases?
> > > > Thank you
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 15:33:53 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 15:33:53 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <20210809133134.784edd06@trisector>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
Message-ID: <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>

You are right, vect will contain the names of the columns of the real
dataframe buyt the actual simulation of the real case is more like
this:
```
> df = data.frame(A = 1:5, B = c(1, 2, NA, 2, NA), C = c("value is blue", "Value is red", "empty", "  value is blue", " Value is green"), D = 9:13, E = c("light", "light", "heavy", "heavy", "heavy")); df
  A  B               C  D     E
1 1  1   value is blue  9 light
2 2  2    Value is red 10 light
3 3 NA           empty 11 heavy
4 4  2   value is blue 12 heavy
5 5 NA  Value is green 13 heavy
> vect = LETTERS[1:5]
> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"; df
  A  B               C  D     E vect[2]
1 1  1   value is blue  9 light    <NA>
2 2  2    Value is red 10 light    <NA>
3 3 NA           empty 11 heavy    <NA>
4 4  2   value is blue 12 heavy    <NA>
5 5 NA  Value is green 13 heavy    <NA>
> df[df[[vect[2]]] == 2, vect[2]] <- "No"; df
Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value = "No") :
  missing values are not allowed in subscripted assignments of data frames
```
but still, I get an extra column instead of working on column B
directly. and I can't dispense the quotation marks...

On Mon, Aug 9, 2021 at 1:31 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Mon, 9 Aug 2021 13:16:02 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > df = data.frame(VAR = ..., VAL = ...)
> > vect = letters[1:5]
>
> What is the relation between vect and the column names of the data
> frame? Is it your intention to choose rows or columns using `vect`?
>
> > df[df[['vect[2]']] == 2, 'vect[2]']
>
> '...' creates a string literal. If you want to evaluate an R
> expression, don't wrap it in quotes.
>
> I had assumed you wanted to put column names in the vector `vect`, but
> now I'm just confused: `vect` is the same as df$VAR, not colnames(df).
> What do you want to achieve?
>
> Again, you can access the second column with much less typing by
> addressing it directly: df[[2]]
>
> Does it help if you consult [**] or some other tutorial on subsetting
> in R?
>
> --
> Best regards,
> Ivan
>
> [**]
> https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Index-vectors
> https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Lists



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 15:35:12 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 15:35:12 +0200
Subject: [R] Apply gsub to dataframe to modify row values
In-Reply-To: <CAPcHnpQiXdgRUjUPafhub4s6jd3otQAATvboMpZZffbD4k_XZg@mail.gmail.com>
References: <CAMk+s2Qs_F-LebL3P8aN=4YU9R75mAF6jG6VSBYS74Ut-yqcTA@mail.gmail.com>
 <CA+8X3fXD4kvJTkFqGan2-3n4NKQq+hCqRTtTO8SKhg74ENkrCw@mail.gmail.com>
 <CAMk+s2QrfsR9HOekXkSqK1Ge2T4y345W7BYc1YL+NP0=HmvB7Q@mail.gmail.com>
 <CAMk+s2S66xT3=X3SEUDpYLcgYKW4nG965j4jMPr53aqySDHEjQ@mail.gmail.com>
 <CAPcHnpQiXdgRUjUPafhub4s6jd3otQAATvboMpZZffbD4k_XZg@mail.gmail.com>
Message-ID: <CAMk+s2RN57puWp4+w4UYcmQb_TGzC0yYYXQG-DzFs67Gon=_Sw@mail.gmail.com>

Thank you, it works!

On Mon, Aug 9, 2021 at 3:26 PM Andrew Simmons <akwsimmo at gmail.com> wrote:
>
> Hello,
>
>
> There are two convenient ways to access a column in a data.frame using `$` and `[[`. Using `df` from your first email, we would do something like
>
> df <- data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
> df$VAL
> df[["VAL"]]
>
> The two convenient ways to update / / replace a column with something new are also very similar, something like
>
> df$VAL <- ...
> df[["VAL"]] <- ...
>
> As for the regex part, I would suggest using `sub` instead of `gsub` since you're looking to remove only the first instance of "value is". Also, I would recommend using "^" to mark the beginning of your string, something like
>
> df$VAL <- sub("^Value is ", "", df$VAL, ignore.case = TRUE)
>
> I might be misunderstanding, but it sounds like you also want to remove all leading whitespace. If so, you could do something like
>
> df$VAL <- sub("^[[:blank:]]*Value is ", "", df$VAL, ignore.case = TRUE)
>
> where "*" signifies that there will be zero or more blank characters at the beginning of the string. You can try `?regex` to read more about this.
>
> I hope this helps!
>
> On Mon, Aug 9, 2021 at 6:50 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Sorry, silly question, gsub works already with regex. But still, if I
>> add `[[:blank:]]` still I don't get rid of all instances. And I am
>> keeping obtaining extra columns
>> ```
>> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE)
>> > df[df$VAL] = gsub("[[:blank:]Value is]", "", df$VAL, ignore.case=TRUE);df
>>   VAR           VAL value is blue Value is red empty
>> 1   1 value is blue             b            b     b
>> 2   2  Value is red            rd           rd    rd
>> 3   3         empty          mpty         mpty  mpty
>> ```
>>
>> On Mon, Aug 9, 2021 at 12:40 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> >
>> > Thank you, that is much appreciated. But on the real data, the
>> > substitution works only on few instances. Is there a way to introduce
>> > regex into this?
>> > Cheers
>> > Luigi
>> >
>> > On Mon, Aug 9, 2021 at 11:01 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>> > >
>> > > Hi Luigi,
>> > > Ah, now I see:
>> > >
>> > >  df$VAL<-gsub("Value is","",df$VAL,ignore.case=TRUE)
>> > > df
>> > >  VAR   VAL
>> > > 1   1  blue
>> > > 2   2   red
>> > > 3   3 empty
>> > >
>> > > Jim
>> > >
>> > > On Mon, Aug 9, 2021 at 6:43 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> > > >
>> > > > Hello,
>> > > > I have a dataframe where I would like to change the string of certain
>> > > > rows, essentially I am looking to remove some useless text from the
>> > > > variables.
>> > > > I tried with:
>> > > > ```
>> > > > > df = data.frame(VAR = 1:3, VAL = c("value is blue", "Value is red", "empty"))
>> > > > > df[df$VAL] = gsub("value is ", "", df$VAL, ignore.case = TRUE, perl = FALSE)
>> > > > > df
>> > > >   VAR           VAL value is blue Value is red empty
>> > > > 1   1 value is blue          blue         blue  blue
>> > > > 2   2  Value is red           red          red   red
>> > > > 3   3         empty         empty        empty empty
>> > > > ```
>> > > > which is of course wrong because I was expecting
>> > > > ```
>> > > >   VAR           VAL
>> > > > 1   1             blue
>> > > > 2   2             red
>> > > > 3   3            empty
>> > > > ```
>> > > > What is the correct syntax in these cases?
>> > > > Thank you
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > Best regards,
>> > Luigi
>>
>>
>>
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Mon Aug  9 15:41:04 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Mon, 9 Aug 2021 09:41:04 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
Message-ID: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>

Dear All: good morning



*Re:* Sample Size Determination to Compare Three Independent Proportions



*Situation:*



Three Binary variables (Yes, No)

Three independent populations with fixed sizes (*say:* N1 = 1500, N2 = 900,
N3 = 1350).

Power = 0.80

How to choose the sample sizes to compare the three proportions of ?Yes?
among the three variables.



If you know a reference to this topic, it will be very helpful too.



with many thanks in advance

abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Aug  9 16:19:40 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 9 Aug 2021 07:19:40 -0700
Subject: [R] Sanity check in loading large dataframe
In-Reply-To: <9192f7107d4148b18cf19d882cf002cc@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2SxQsghOnxRXfHJh2N_6drVt4CQzzWbi0XmEHJHWR+Gpw@mail.gmail.com>
 <ea65a24d-9889-4f48-fca7-1bbe088633b6@gmail.com>
 <CAMk+s2Q+gP6kMc7T0eSt_ZEyJTVmgghnf=fmLDrHxKPoMZDv-g@mail.gmail.com>
 <9ff2d324859844f3b9b75f1bd4f6ee78@SRVEXCHCM1302.precheza.cz>
 <CAGxFJbRMdxRV6m5agDgGzhSWbuTZpa5_KJpJn+cf0Pn2yKzxsQ@mail.gmail.com>
 <9192f7107d4148b18cf19d882cf002cc@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbR-6uz7VxgnmMpCVanKpWHPsbr+Cke3kWaQ6n5waxq=Vg@mail.gmail.com>

FWIW:

Yes, thanks for noting that.
My own preference is to always propagate NA's and manually decide how
to deal with them, but others may disagree.

Best,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
On Sun, Aug 8, 2021 at 11:30 PM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi Bert
>
> Yes, in this case which is not necessary. But in case NAs are involved
> sometimes logical indexing is not a best choice as NA propagates to the
> result, which may be not wanted.
>
> x <- 1:10
> x[c(2,5)] <- NA
> y<- letters[1:10]
> y[x<5]
> [1] "a" NA  "c" "d" NA
> y[which(x<5)]
> [1] "a" "c" "d"
> dat <- data.frame(x,y)
> dat[x<5,]
>       x    y
> 1     1    a
> NA   NA <NA>
> 3     3    c
> 4     4    d
> NA.1 NA <NA>
>
> > dat[which(x<5),]
>   x y
> 1 1 a
> 3 3 c
> 4 4 d
>
> Both results are OK, but one has to consider this NA value propagation.
>
> Cheers
> Petr
>
> From: Bert Gunter <bgunter.4567 at gmail.com>
> Sent: Friday, August 6, 2021 1:29 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: Luigi Marongiu <marongiu.luigi at gmail.com>; r-help <r-help at r-project.org>
> Subject: Re: [R] Sanity check in loading large dataframe
>
> ... but remove the which() and use logical indexing ...  ;-)
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Aug 6, 2021 at 12:57 AM PIKAL Petr <mailto:petr.pikal at precheza.cz>
> wrote:
> Hi
>
> You already got answer from Avi. I often use dim(data) to inspect how many
> rows/columns I have.
> After that I check if some columns contain all or many NA values.
>
> colSums(http://is.na(data))
> keep <- which(colSums(http://is.na(data))<nnn)
> cleaned.data <- data[, keep]
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Luigi
> > Marongiu
> > Sent: Friday, August 6, 2021 7:34 AM
> > To: Duncan Murdoch <mailto:murdoch.duncan at gmail.com>
> > Cc: r-help <mailto:r-help at r-project.org>
> > Subject: Re: [R] Sanity check in loading large dataframe
> >
> > Ok, so nothing to worry about. Yet, are there other checks I can
> implement?
> > Thank you
> >
> > On Thu, 5 Aug 2021, 15:40 Duncan Murdoch, <mailto:murdoch.duncan at gmail.com>
> > wrote:
> >
> > > On 05/08/2021 9:16 a.m., Luigi Marongiu wrote:
> > >  > Hello,
> > >  > I am using a large spreadsheet (over 600 variables).
> > >  > I tried `str` to check the dimensions of the spreadsheet and I got
> > > > ```  >> (str(df))  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ....
> > >  > $ v1_medicamento___aceta    : int  1 NA NA NA NA NA NA NA NA NA ...
> > >  >    [list output truncated]
> > >  > NULL
> > >  > ```
> > >  > I understand that `[list output truncated]` means that there are
> > > more  > variables than those allowed by str to be displayed as rows.
> > > Thus I  > increased the row's output with:
> > >  > ```
> > >  >
> > >  >> (str(df, list.len=1000))
> > >  > 'data.frame': 302 obs. of  626 variables:
> > >  >   $ record_id                 : int  1 1 1 1 1 1 1 1 1 1 ...
> > >  > ...
> > >  > NULL
> > >  > ```
> > >  >
> > >  > Does `NULL` mean that some of the variables are not closed?
> > > (perhaps a  > missing comma somewhere)  > Is there a way to check the
> > > sanity of the data and avoid that some  > separator is not in the
> > > right place?
> > >  > Thank you
> > >
> > > The NULL is the value returned by str().  Normally it is not printed,
> > > but when you wrap str in parens as (str(df, list.len=1000)), that
> > > forces the value to print.
> > >
> > > str() is unusual in R functions in that it prints to the console as it
> > > runs and returns nothing.  Many other functions construct a value
> > > which is only displayed if you print it, but something like
> > >
> > > x <- str(df, list.len=1000)
> > >
> > > will print the same as if there was no assignment, and then assign
> > > NULL to x.
> > >
> > > Duncan Murdoch
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rc_@chw@rtz @end|ng |rom me@com  Mon Aug  9 16:53:29 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 9 Aug 2021 10:53:29 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
Message-ID: <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>

Hi,

You are going to need to provide more information than what you have 
below and I may be mis-interpreting what you have provided.

Presuming you are designing a prospective, three-group, randomized 
allocation study, there is typically an a priori specification of the 
ratios of the sample sizes for each group such as 1:1:1, indicating that 
the desired sample size in each group is the same.

You would also need to specify the expected proportions of "Yes" values 
in each group.

Further, you need to specify how you are going to compare the 
proportions in each group. Are you going to perform an initial omnibus 
test of all three groups (e.g. 3 x 2 chi-square), possibly followed by 
all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 2 
versus 3), or are you just going to compare 2 versus 1, and 3 versus 1, 
where 1 is a control group?

Depending upon your testing plan, you may also need to account for p 
value adjustments for multiple comparisons, in which case, you also need 
to specify what adjustment method you plan to use, to know what the 
target alpha level will be.

On the other hand, if you already have the data collected, thus have 
fixed sample sizes available per your wording below, simply go ahead and 
perform your planned analyses, as the notion of "power" is largely an a 
priori consideration, which reflects the probability of finding a 
"statistically significant" result at a given alpha level, given that 
your a priori assumptions are valid.

Regards,

Marc Schwartz


AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
> Dear All: good morning
>
> *Re:* Sample Size Determination to Compare Three Independent Proportions
>
> *Situation:*
>
> Three Binary variables (Yes, No)
>
> Three independent populations with fixed sizes (*say:* N1 = 1500, N2 = 900,
> N3 = 1350).
>
> Power = 0.80
>
> How to choose the sample sizes to compare the three proportions of ?Yes?
> among the three variables.
>
> If you know a reference to this topic, it will be very helpful too.
>
> with many thanks in advance
>
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>


From kry|ov@r00t @end|ng |rom gm@||@com  Mon Aug  9 17:18:43 2021
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Mon, 9 Aug 2021 17:18:43 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
Message-ID: <20210809171843.73629fbb@trisector>

Thanks for providing a reproducible example!

On Mon, 9 Aug 2021 15:33:53 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"

Please don't quote R expressions that you want to evaluate. 'vect[2]'
is just a string, like 'hello world' or 'I want to create a new column
named "vect[2]" instead of accessing the second one'.

> Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
> = "No") : missing values are not allowed in subscripted assignments
> of data frames

Since df[[2]] containts NAs, comparisons with it also contain NAs. While
it's possible to subset data.frames with NAs (the rows corresponding to
the NAs are returned filled with NAs of corresponding types),
assignment to undefined rows is not allowed. A simple way to remove the
NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
to use which(). Compare:

df[df[[vect[2]]] == 2,]
df[which(df[[vect[2]]] == 2),]

-- 
Best regards,
Ivan


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Aug  9 21:22:40 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 9 Aug 2021 21:22:40 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <20210809171843.73629fbb@trisector>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
 <20210809171843.73629fbb@trisector>
Message-ID: <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>

Thank you! it worked fine! The only pitfall is that `NA` became
`<NA>`. This is essentially the same thing anyway...

On Mon, Aug 9, 2021 at 5:18 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> Thanks for providing a reproducible example!
>
> On Mon, 9 Aug 2021 15:33:53 +0200
> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> > df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"
>
> Please don't quote R expressions that you want to evaluate. 'vect[2]'
> is just a string, like 'hello world' or 'I want to create a new column
> named "vect[2]" instead of accessing the second one'.
>
> > Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
> > = "No") : missing values are not allowed in subscripted assignments
> > of data frames
>
> Since df[[2]] containts NAs, comparisons with it also contain NAs. While
> it's possible to subset data.frames with NAs (the rows corresponding to
> the NAs are returned filled with NAs of corresponding types),
> assignment to undefined rows is not allowed. A simple way to remove the
> NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
> to use which(). Compare:
>
> df[df[[vect[2]]] == 2,]
> df[which(df[[vect[2]]] == 2),]
>
> --
> Best regards,
> Ivan



-- 
Best regards,
Luigi


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Aug 10 00:12:26 2021
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 9 Aug 2021 15:12:26 -0700
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
 <20210809171843.73629fbb@trisector>
 <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>
Message-ID: <36fe8019-bd11-3d34-81dc-5a0d4d7d3081@comcast.net>


On 8/9/21 12:22 PM, Luigi Marongiu wrote:
> Thank you! it worked fine! The only pitfall is that `NA` became
> `<NA>`. This is essentially the same thing anyway...


It's not "essentially the same thing". It IS the same thing. The print 
function displays those '<>' characters flanking NA's when the class is 
factor. Type this at your console:


factor(NA)


-- 

David

>
> On Mon, Aug 9, 2021 at 5:18 PM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>> Thanks for providing a reproducible example!
>>
>> On Mon, 9 Aug 2021 15:33:53 +0200
>> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>>> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"
>> Please don't quote R expressions that you want to evaluate. 'vect[2]'
>> is just a string, like 'hello world' or 'I want to create a new column
>> named "vect[2]" instead of accessing the second one'.
>>
>>> Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
>>> = "No") : missing values are not allowed in subscripted assignments
>>> of data frames
>> Since df[[2]] containts NAs, comparisons with it also contain NAs. While
>> it's possible to subset data.frames with NAs (the rows corresponding to
>> the NAs are returned filled with NAs of corresponding types),
>> assignment to undefined rows is not allowed. A simple way to remove the
>> NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
>> to use which(). Compare:
>>
>> df[df[[vect[2]]] == 2,]
>> df[which(df[[vect[2]]] == 2),]
>>
>> --
>> Best regards,
>> Ivan
>
>


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Aug 10 00:39:20 2021
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 10 Aug 2021 10:39:20 +1200
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
Message-ID: <20210810103920.7fdbd930@rolf-Latitude-E7470>


I thought that I should let everyone know that I have, in some sense at
least, resolved my problem with 'no "doc" directory' and Rstudio.  I
got a useful reply off-list from Duncan Murdoch (thanks Duncan) to the
effect that Rstudio requires its own purpose-specific binaries.

I was always under the impression that Rstudio would invoke whatever
instance of R that the user had installed, but this seems not to
be the case.  Duncan pointed me to instructions for installing  R in
such a way as to satisfy Rstudio.  I had not found such instructions
previously.

After considerable travail (I had "curl" problems with which I will not
bore you) I managed to effect this installation, which put R into
/opt/R/4.1.0 and lo and behold /opt/R/4.1.0/lib/R does indeed contain a
"doc" directory (unlike, e.g. /usr/lib/R which is my non-Rstudio
instance of R lives.)

Having done that and having made the appropriate symbolic links,
I was able to click on the Rstudio icon under Applications ->
Programming and get Rstudio running.

So far I can find no way to get Rstudio to do what I had hoped to be
able to do --- something that cannot effectively be done in raw R.
But that's another story.

I raised this same issue on the "Rstudio Community" web site, and the
contrast between what I got from that and what I got from R-help was
striking.  What I got from the former was deafening silence.  I got
seven responses on the R-help mailing list, plus Duncan's off-list
response.

Does this say something about the efficacy of mailing lists as
contrasted with web site fora?  Or is it just a difference between the
R community and the Rstudio community?

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From edd @end|ng |rom deb|@n@org  Tue Aug 10 00:58:21 2021
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 9 Aug 2021 17:58:21 -0500
Subject: [R] No "doc" directory in my installation of R.
In-Reply-To: <20210810103920.7fdbd930@rolf-Latitude-E7470>
References: <20210808144507.61a8290e@rolf-Latitude-E7470>
 <alpine.BSF.2.00.2108072020320.49547@pedal.dcn.davis.ca.us>
 <20210810103920.7fdbd930@rolf-Latitude-E7470>
Message-ID: <24849.45837.453388.549593@rob.eddelbuettel.com>


Rolf,

Sorry for only briefly chiming in, and late, but I don't usually follow
r-help that much these days.

I am writing this from an Ubuntu machine running R as well as RStudio from
pre-made binary .deb packages. R comes via apt from CRAN (using Michael's
binaries), RStudio from them via helper scripts in a package of mine:

  edd at rob:~$ dpkg -l | grep "r-base-core\|rstudio\|rstudio-server" | cut -c-79
  ii  r-base-core                                4.1.0-1.2104.0                  
  ii  rstudio                                    2021-07.0.270                   
  ii  rstudio-server                             2021-07.0.270                   
  edd at rob:~$

Contrary to what you wrote, RStudio *will* use whichever binary it finds
first in the path, just like any other Unix tool.  So when I do

   $ rstudio

I get R 4.1.0 from the binary above, but if I opt into my locally compiled
R-devel via a standard PATH prefix then

   $ PATH=/usr/local/lib/R-devel/bin/:$PATH rstudio

RStudio happily runs with R-devel.

Next, "doc/". This has been in /usr/share/R for probably well over a decade
on these Debian system; almost all other packages on Linux distros also split
between binary ("architecture-specific") directories (such as lib/) and
binary-independent ones (such as share/).

And by the way, in R you can do call R.home() with an argument to see:

   > R.home("doc")
   [1] "/usr/share/R/doc"
   > R.home("library")
   [1] "/usr/lib/R/library"
   > 

Of course, you are free to use whichever R installation and configuration
*you* mind most suitable. It is after all your machine.  But quite a few of
us are happy with these official binaries.

Lastly, and I we may have mentioned this to you before, a dedicated mailing
lists for 'R on Debian + Ubuntu' exists (in r-sig-debian at the usual ETH
server) and you might have gotten useful answers sooner.

Anyway, you are set now, so enjoy R!

Cheers, Dirk

-- 
https://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From drj|m|emon @end|ng |rom gm@||@com  Tue Aug 10 06:21:48 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 10 Aug 2021 14:21:48 +1000
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn6Nyis5Xric7ng6qMaZBgXs9ctxS97b6R6+HFmNWK7anA@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CA+8X3fU4ysODOkvoCJXj=qqk9pmgQWnHMhKwEVq=seFQo2NOzQ@mail.gmail.com>
 <CAO29qn6Nyis5Xric7ng6qMaZBgXs9ctxS97b6R6+HFmNWK7anA@mail.gmail.com>
Message-ID: <CA+8X3fVN4wWkTcg=nnX7GkXTuzGd3yVsf89=38Ru3o4swaPO4A@mail.gmail.com>

Here is my hasty attempt last night checked in the light of morning.
It seems to return the correct extreme values and contains an example.

Jim

On Mon, Aug 9, 2021 at 10:50 PM Md. Moyazzem Hossain
<hossainmm at juniv.edu> wrote:
>
> Dear Jim,
>
> Thank you very much for your kind help.
>
> Take care.
>
> Md
>
> On Mon, Aug 9, 2021 at 1:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> And if you really don't like programming:
>>
>> whipple_index<-function(x,td=c(0,5)) {
>>  wi<-rep(NA,11)
>>  names(wi)<-c(paste0("wi",0:9),"O/all")
>>  for(i in 0:9) {
>>   ttd<-which((x %% 10) %in% i)
>>   wi[i+1]<-length(ttd) * 100/length(x)
>>  }
>>  ttd<-which((x %% 10) %in% td)
>>  wi[11]<-length(ttd) * 100/(length(x)/length(td))
>>  return(wi)
>> }
>>
>> I haven't tested this extensively, but it may be helpful. You can
>> specify the final digits for the overall test. Select your ages before
>> passing them to whipple_index.
>>
>> Jim
>>
>> On Mon, Aug 9, 2021 at 9:05 PM Greg Minshall <minshall at umich.edu> wrote:
>> >
>> > Md,
>> >
>> > if this is what you are looking for:
>> > ----
>> > https://en.wikipedia.org/wiki/Whipple%27s_index
>> > ----
>> >
>> > then, the article says the algorithm is
>> > ----
>> > The index score is obtained by summing the number of persons in the age
>> > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
>> > that sum by the total population between ages 23 and 62 years inclusive,
>> > and multiplying the result by 5. Restated as a percentage, index scores
>> > range between 100 (no preference for ages ending in 0 and 5) and 500
>> > (all people reporting ages ending in 0 and 5).
>> > ----
>> >
>> > that seems fairly straight forward.  if you are trying to learn R,
>> > and/or learn programming, i might suggest you *not* use a package, and
>> > rather work on coding up the calculation yourself.  that would probably
>> > be a good, but not too hard, exercise, of some interest.  enjoy!
>> >
>> > cheers, Greg
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: Google Scholar; ResearchGate; ORCID iD

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Aug 10 07:55:41 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 10 Aug 2021 07:55:41 +0200
Subject: [R] 
 substitute column data frame based on name stored in variable in r
In-Reply-To: <36fe8019-bd11-3d34-81dc-5a0d4d7d3081@comcast.net>
References: <CAMk+s2TZJ4NYw7_yUb5kk3kX=U4Whk7n94FgALp=S50ezo6_cg@mail.gmail.com>
 <20210809112451.78a21095@trisector>
 <CAMk+s2Ta4k1XmMFH0rgt0Z78B5hdN7nQA2pjT6d=EDTW3qOWBA@mail.gmail.com>
 <20210809133134.784edd06@trisector>
 <CAMk+s2RvK9oeUODPM1Y_d8JjMuREXX2joKLiU4KQ=V_7td+Dig@mail.gmail.com>
 <20210809171843.73629fbb@trisector>
 <CAMk+s2SzjHmryz87NdXho2L5UvvupGra-PqwEXmNP_OcwG2dBg@mail.gmail.com>
 <36fe8019-bd11-3d34-81dc-5a0d4d7d3081@comcast.net>
Message-ID: <CAMk+s2RrUBj0JBa-BFtk_UeZwoVB3xSVWUO_m8g_ddExhgrC4w@mail.gmail.com>

Got it, thank you!

On Tue, 10 Aug 2021, 00:12 David Winsemius, <dwinsemius at comcast.net> wrote:

>
> On 8/9/21 12:22 PM, Luigi Marongiu wrote:
> > Thank you! it worked fine! The only pitfall is that `NA` became
> > `<NA>`. This is essentially the same thing anyway...
>
>
> It's not "essentially the same thing". It IS the same thing. The print
> function displays those '<>' characters flanking NA's when the class is
> factor. Type this at your console:
>
>
> factor(NA)
>
>
> --
>
> David
>
> >
> > On Mon, Aug 9, 2021 at 5:18 PM Ivan Krylov <krylov.r00t at gmail.com>
> wrote:
> >> Thanks for providing a reproducible example!
> >>
> >> On Mon, 9 Aug 2021 15:33:53 +0200
> >> Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>
> >>> df[df[['vect[2]']] == 2, 'vect[2]'] <- "No"
> >> Please don't quote R expressions that you want to evaluate. 'vect[2]'
> >> is just a string, like 'hello world' or 'I want to create a new column
> >> named "vect[2]" instead of accessing the second one'.
> >>
> >>> Error in `[<-.data.frame`(`*tmp*`, df[[vect[2]]] == 2, vect[2], value
> >>> = "No") : missing values are not allowed in subscripted assignments
> >>> of data frames
> >> Since df[[2]] containts NAs, comparisons with it also contain NAs. While
> >> it's possible to subset data.frames with NAs (the rows corresponding to
> >> the NAs are returned filled with NAs of corresponding types),
> >> assignment to undefined rows is not allowed. A simple way to remove the
> >> NAs and only leave the cases where df[[vect[2]]] == 2 is TRUE would be
> >> to use which(). Compare:
> >>
> >> df[df[[vect[2]]] == 2,]
> >> df[which(df[[vect[2]]] == 2),]
> >>
> >> --
> >> Best regards,
> >> Ivan
> >
> >
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Tue Aug 10 09:33:02 2021
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Tue, 10 Aug 2021 19:33:02 +1200
Subject: [R] Calculation of Age heaping
In-Reply-To: <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>
Message-ID: <CABcYAdJZmgLfTa=sgOwF6CPoGB0K0zQWBizihpPyt_uQmGbPSQ@mail.gmail.com>

If you want to look at each digit, you should take a step back and
think about what the
Whipple index is actually doing.  Basically, the model underlying the
Whipple index is
that Pr(age = xy) = Pr(age = x*)Pr(age = *y) if there is no age
heaping.  Or rather,
since the age is restricted to 23..62 (a whole number of decades), it is that
Pr(age - 23 = xy) = Pr(age - 23  = x*)Pr(age - 23 = *y) for 0 <= x <=
3, 0 <= y <= 9
and the "nothing to see here" case is Pr(age = *y) = 1/10.

I wasted way too much time trying to find a free age data set where
age *wasn't* already
grouped into 5 year bands.

So what's wrong with a chi-square test?
I would certainly want to check whether the high and low digits of age
- 23 were in fact independent.

On Mon, 9 Aug 2021 at 23:48, Md. Moyazzem Hossain <hossainmm at juniv.edu> wrote:
>
> Dear Greg,
>
> Thank you very much for your suggestion. I will try it and follow your
> advice.
>
> Actually, I want to find out the index for each digit like 0, 1, ..., 9.
>
> Thanks in advance. Take care.
>
> Md
>
>
>
> On Mon, Aug 9, 2021 at 12:05 PM Greg Minshall <minshall at umich.edu> wrote:
>
> > Md,
> >
> > if this is what you are looking for:
> > ----
> > https://en.wikipedia.org/wiki/Whipple%27s_index
> > ----
> >
> > then, the article says the algorithm is
> > ----
> > The index score is obtained by summing the number of persons in the age
> > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> > that sum by the total population between ages 23 and 62 years inclusive,
> > and multiplying the result by 5. Restated as a percentage, index scores
> > range between 100 (no preference for ages ending in 0 and 5) and 500
> > (all people reporting ages ending in 0 and 5).
> > ----
> >
> > that seems fairly straight forward.  if you are trying to learn R,
> > and/or learn programming, i might suggest you *not* use a package, and
> > rather work on coding up the calculation yourself.  that would probably
> > be a good, but not too hard, exercise, of some interest.  enjoy!
> >
> > cheers, Greg
> >
> >
>
> --
> Best Regards,
> Md. Moyazzem Hossain
> Associate Professor
> Department of Statistics
> Jahangirnagar University
> Savar, Dhaka-1342
> Bangladesh
> Website: http://www.juniv.edu/teachers/hossainmm
> Research: *Google Scholar
> <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> *ResearchGate
> <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> <https://orcid.org/0000-0003-3593-6936>*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Tue Aug 10 10:18:08 2021
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Tue, 10 Aug 2021 10:18:08 +0200
Subject: [R] [Rd] R 4.1.1 is released
Message-ID: <8A0CEFBD-74CF-4928-A587-1C58811F799B@gmail.com>

The build system rolled up R-4.1.1.tar.gz (codename "Kick Things") this morning.

The list below details the changes in this release. 

You can get the source code from

https://cran.r-project.org/src/base/R-4/R-4.1.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = da5e7c699a83608d0f1e39c458d9fc56
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 6094024214a482c0d01d2ab2adca4b3f
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = fbc4810ff26ebcec514ebaa1c1909ad7
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = a767f7809324c73c49eaff47d14bce81
MD5 (NEWS.3) = e55ed2c8a547b827b46e08eb7137ba23
MD5 (R-latest.tar.gz) = c278cfeb85b1564540ab214e45fe68d9
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = a79b9b338cab09bd665f6b62ac6f455b
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 34443dff7fcea700c8ec4740e5804374
MD5 (R-4/R-4.1.1.tar.gz) = c278cfeb85b1564540ab214e45fe68d9

9704a7d96c350a48417ef215888a29f1993ee5dec1b73cb95755e8625b860200  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
2894e7a88634a08c05bfafb8a694a26b635e4042160aab46fa6a0f4eb68ea91e  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
e8bdaf546cf65fdc5bf2a81fa5334572886ff2f1317ec6cdc9e61d6de3532dd4  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ba74618bc3f4c0e336dca13d472402a1863d12ba6f7f91a1782bc469ee986f6d  NEWS.2
1910a2405300b9bc7c76beeb0753a5249cf799afe175ce28f8d782fab723e012  NEWS.3
515e03265752257d0b7036f380f82e42b46ed8473f54f25c7b67ed25bbbdd364  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
8b7d3856100220f4555d4d57140829f2e81c27eccec5b441f5dce616e9ec9061  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
02686ea05e64304a755bf776cdeeadafd2c5017a13f9203f1db9278287c81aa6  VERSION-INFO.dcf
515e03265752257d0b7036f380f82e42b46ed8473f54f25c7b67ed25bbbdd364  R-4/R-4.1.1.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.1.1:

  NEW FEATURES:

    * require(pkg, quietly = TRUE) is quieter and in particular does
      not warn if the package is not found.

  DEPRECATED AND DEFUNCT:

    * Use of ftp:// URIs should be regarded as deprecated, with
      on-going support confined to method = "libcurl" and not routinely
      tested.  (Nowadays no major browser supports them.)

    * The non-default method = "internal" is deprecated for http:// and
      ftp:// URIs for both download.file and url.

    * On Windows, method = "wininet" is deprecated for http://,
      https:// and ftp:// URIs for both download.file and url.  (A
      warning is only given for ftp://.)

      For ftp:// URIs the default method is now "libcurl" if available
      (which it is on CRAN builds).

      method = "wininet" remains the default for http:// and https://
      URIs but if libcurl is available, using method = "libcurl" is
      preferred.

  INSTALLATION:

    * make check now works also without a LaTeX installation.  (Thanks
      to Sebastian Meyer's PR#18103.)

  BUG FIXES:

    * make check-devel works again in an R build configured with
      --without-recommended-packages.

    * qnbinom(p, size, mu) for large size/mu is correct now in a range
      of cases (PR#18095); similarly for the (size, prob)
      parametrization of the negative binomial.  Also qpois() and
      qbinom() are better and or faster for extreme cases.  The
      underlying C code has been modularized and is common to all four
      cases of discrete distributions.

    * gap.axis is now part of the axis() arguments which are passed
      from bxp(), and hence boxplot().  (Thanks to Martin Smith's
      report and suggestions in PR#18109.)

    * .First and .Last can again be set from the site profile.

    * seq.int(from, to, *) and seq.default(..) now work better in large
      range cases where from-to is infinite where the two boundaries
      are finite.

    * all.equal(x,y) now returns TRUE correctly also when several
      entries of abs(x) and abs(y) are close to .Machine$double.xmax,
      the largest finite numeric.

    * model.frame() now clears the object bit when removing the class
      attribute of a value via na.action (PR#18100).

    * charClass() now works with multi-character strings on Windows
      (PR#18104, fixed by Bill Dunlap).

    * encodeString() on Solaris now works again in Latin-1 encoding on
      characters represented differently in UTF-8.  Support for
      surrogate pairs on Solaris has been improved.

    * file.show() on Windows now works with non-ASCII path names
      representable in the current native encoding (PR#18132).

    * Embedded R on Windows can now find R home directory via the
      registry even when installed only for the current user
      (PR#18135).

    * pretty(x) with finite x now returns finite values also in the
      case where the extreme x values are close in size to the maximal
      representable number .Machine$double.xmax.

      Also, it's been tweaked for very small ranges and when a boundary
      is close (or equal) to zero; e.g., pretty(c(0,1e-317)) no longer
      has negative numbers, currently still warning about a very small
      range, and pretty(2^-(1024 - 2^-1/(c(24,10)))) is more accurate.

    * The error message for not finding vignette files when weaving has
      correct file sizes now. (Thanks to Sebastian Meyer's PR#18154.)

    * dnbinom(20, <large>, 1) now correctly gives 0, and similar cases
      are more accurate with underflow precaution.  (Reported by
      Francisco Vera Alcivar in PR#18072.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ho@@@|nmm @end|ng |rom jun|v@edu  Tue Aug 10 10:33:48 2021
From: ho@@@|nmm @end|ng |rom jun|v@edu (Md. Moyazzem Hossain)
Date: Tue, 10 Aug 2021 09:33:48 +0100
Subject: [R] Calculation of Age heaping
In-Reply-To: <CABcYAdJZmgLfTa=sgOwF6CPoGB0K0zQWBizihpPyt_uQmGbPSQ@mail.gmail.com>
References: <CAO29qn4j2hHHz8NyM6uiCBeSS_GCiYiwxQNJHLHPW4Ne4TyZog@mail.gmail.com>
 <513810.1628507091@apollo2.minshall.org>
 <CAO29qn4ZsTO0cziLo0fj125rx0ZGnBLgSukwRiv7EAj4XS7qSQ@mail.gmail.com>
 <CABcYAdJZmgLfTa=sgOwF6CPoGB0K0zQWBizihpPyt_uQmGbPSQ@mail.gmail.com>
Message-ID: <CAO29qn7n=ncyk61tVBttqUM0RZcjLE61jp30gP7b-gbd0C45sA@mail.gmail.com>

Dear Richard O'Keefe,

Thank you very much.

Take care.

Md

On Tue, Aug 10, 2021 at 8:33 AM Richard O'Keefe <raoknz at gmail.com> wrote:

> If you want to look at each digit, you should take a step back and
> think about what the
> Whipple index is actually doing.  Basically, the model underlying the
> Whipple index is
> that Pr(age = xy) = Pr(age = x*)Pr(age = *y) if there is no age
> heaping.  Or rather,
> since the age is restricted to 23..62 (a whole number of decades), it is
> that
> Pr(age - 23 = xy) = Pr(age - 23  = x*)Pr(age - 23 = *y) for 0 <= x <=
> 3, 0 <= y <= 9
> and the "nothing to see here" case is Pr(age = *y) = 1/10.
>
> I wasted way too much time trying to find a free age data set where
> age *wasn't* already
> grouped into 5 year bands.
>
> So what's wrong with a chi-square test?
> I would certainly want to check whether the high and low digits of age
> - 23 were in fact independent.
>
> On Mon, 9 Aug 2021 at 23:48, Md. Moyazzem Hossain <hossainmm at juniv.edu>
> wrote:
> >
> > Dear Greg,
> >
> > Thank you very much for your suggestion. I will try it and follow your
> > advice.
> >
> > Actually, I want to find out the index for each digit like 0, 1, ..., 9.
> >
> > Thanks in advance. Take care.
> >
> > Md
> >
> >
> >
> > On Mon, Aug 9, 2021 at 12:05 PM Greg Minshall <minshall at umich.edu>
> wrote:
> >
> > > Md,
> > >
> > > if this is what you are looking for:
> > > ----
> > > https://en.wikipedia.org/wiki/Whipple%27s_index
> > > ----
> > >
> > > then, the article says the algorithm is
> > > ----
> > > The index score is obtained by summing the number of persons in the age
> > > range 23 and 62 inclusive, who report ages ending in 0 and 5, dividing
> > > that sum by the total population between ages 23 and 62 years
> inclusive,
> > > and multiplying the result by 5. Restated as a percentage, index scores
> > > range between 100 (no preference for ages ending in 0 and 5) and 500
> > > (all people reporting ages ending in 0 and 5).
> > > ----
> > >
> > > that seems fairly straight forward.  if you are trying to learn R,
> > > and/or learn programming, i might suggest you *not* use a package, and
> > > rather work on coding up the calculation yourself.  that would probably
> > > be a good, but not too hard, exercise, of some interest.  enjoy!
> > >
> > > cheers, Greg
> > >
> > >
> >
> > --
> > Best Regards,
> > Md. Moyazzem Hossain
> > Associate Professor
> > Department of Statistics
> > Jahangirnagar University
> > Savar, Dhaka-1342
> > Bangladesh
> > Website: http://www.juniv.edu/teachers/hossainmm
> > Research: *Google Scholar
> > <https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
> > *ResearchGate
> > <https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
> > <https://orcid.org/0000-0003-3593-6936>*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Best Regards,
Md. Moyazzem Hossain
Associate Professor
Department of Statistics
Jahangirnagar University
Savar, Dhaka-1342
Bangladesh
Website: http://www.juniv.edu/teachers/hossainmm
Research: *Google Scholar
<https://scholar.google.com/citations?user=-U03XCgAAAAJ&hl=en&oi=ao>*;
*ResearchGate
<https://www.researchgate.net/profile/Md_Hossain107>*; *ORCID iD
<https://orcid.org/0000-0003-3593-6936>*

	[[alternative HTML version deleted]]


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Aug 10 12:34:06 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 10 Aug 2021 06:34:06 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
 <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
Message-ID: <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>

Hi Marc:

First, thank you very much for your help in this matter.


Will perform an initial omnibus test of all three groups (e.g. 3 x 2
chi-square), possibly followed by
all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3,
2 versus 3),

We can assume *either* the desired sample size in each group is the same
*or* proportional to the population size.

 We can set p=0.25 and set p1=p2=p3=p so that the H0 is true.

We can assume that the expected proportion of "Yes" values in each group is
0.25

For the alternative hypotheses, for example,  we can set  p1 = .25, p2=.25,
p3=.35


Again thank you very much in advance.

abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor, Statistics and Data Science*
*Graduate Coordinator*

*Department of Mathematics and Statistics*
*University of Southern Maine*



On Mon, Aug 9, 2021 at 10:53 AM Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> You are going to need to provide more information than what you have
> below and I may be mis-interpreting what you have provided.
>
> Presuming you are designing a prospective, three-group, randomized
> allocation study, there is typically an a priori specification of the
> ratios of the sample sizes for each group such as 1:1:1, indicating that
> the desired sample size in each group is the same.
>
> You would also need to specify the expected proportions of "Yes" values
> in each group.
>
> Further, you need to specify how you are going to compare the
> proportions in each group. Are you going to perform an initial omnibus
> test of all three groups (e.g. 3 x 2 chi-square), possibly followed by
> all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 2
> versus 3), or are you just going to compare 2 versus 1, and 3 versus 1,
> where 1 is a control group?
>
> Depending upon your testing plan, you may also need to account for p
> value adjustments for multiple comparisons, in which case, you also need
> to specify what adjustment method you plan to use, to know what the
> target alpha level will be.
>
> On the other hand, if you already have the data collected, thus have
> fixed sample sizes available per your wording below, simply go ahead and
> perform your planned analyses, as the notion of "power" is largely an a
> priori consideration, which reflects the probability of finding a
> "statistically significant" result at a given alpha level, given that
> your a priori assumptions are valid.
>
> Regards,
>
> Marc Schwartz
>
>
> AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
> > Dear All: good morning
> >
> > *Re:* Sample Size Determination to Compare Three Independent Proportions
> >
> > *Situation:*
> >
> > Three Binary variables (Yes, No)
> >
> > Three independent populations with fixed sizes (*say:* N1 = 1500, N2 =
> 900,
> > N3 = 1350).
> >
> > Power = 0.80
> >
> > How to choose the sample sizes to compare the three proportions of ?Yes?
> > among the three variables.
> >
> > If you know a reference to this topic, it will be very helpful too.
> >
> > with many thanks in advance
> >
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
>
>

	[[alternative HTML version deleted]]


From jrm||k@ @end|ng |rom y@hoo@com  Tue Aug 10 12:58:18 2021
From: jrm||k@ @end|ng |rom y@hoo@com (James Milks)
Date: Tue, 10 Aug 2021 06:58:18 -0400
Subject: [R] Replacing certain rows with values from a different column
References: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D.ref@yahoo.com>
Message-ID: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D@yahoo.com>

I have two columns in a larger data set that list countries in one column and, in some cases, individual provinces within a country or oversea territories in another. I have country population in a second data set that I?m planning to use to calculate per capita rates in the first data set. My issue: I need to match my two data sets. Here are some examples:

First data set:

Province <- c("Australian Capital Territory", "New South Wales", "Northern Territory", "Queensland", "South Australia", "Tasmania", "Victoria", "Western Australia", "", "", "", "Faroe Islands", "Greenland")

Country <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", "Denmark", "Denmark")

firstdf <- data.frame(Province, Country)

Second data set:

Country <- c("Australia", "Austria", "Azerbaijan", "Denmark", "Faroe Islands", "Greenland")

seconddf <- data.frame(Country)

In this example, I need to aggregate sum Australia while keeping Faroe Islands and Greenland separate from Denmark. What I?d like to do is create a column that looks like this:

firstdf$nation <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", ?Faroe Islands", ?Greenland?)

Is there a way to do this or am I stuck doing this by hand?

Thanks for any help on this vexing issue.

Jim Milks
	[[alternative HTML version deleted]]


From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Tue Aug 10 13:07:27 2021
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Tue, 10 Aug 2021 13:07:27 +0200
Subject: [R] Replacing certain rows with values from a different column
In-Reply-To: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D@yahoo.com>
References: <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D.ref@yahoo.com>
 <D2BBA744-DE3F-4BD1-A29E-0D6BEA67DC2D@yahoo.com>
Message-ID: <52d39762-4517-a6f9-393f-0f6d8732e57e@math.uni-giessen.de>

Hi, James,

if I understand you correctly, maybe,

with(firstdf,
   ifelse(Province %in% seconddf$Country,
          Province,
          Country)
)

does what you want?

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 10.08.2021 um 12:58 schrieb James Milks via R-help:
> I have two columns in a larger data set that list countries in one column and, in some cases, individual provinces within a country or oversea territories in another. I have country population in a second data set that I?m planning to use to calculate per capita rates in the first data set. My issue: I need to match my two data sets. Here are some examples:
> 
> First data set:
> 
> Province <- c("Australian Capital Territory", "New South Wales", "Northern Territory", "Queensland", "South Australia", "Tasmania", "Victoria", "Western Australia", "", "", "", "Faroe Islands", "Greenland")
> 
> Country <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", "Denmark", "Denmark")
> 
> firstdf <- data.frame(Province, Country)
> 
> Second data set:
> 
> Country <- c("Australia", "Austria", "Azerbaijan", "Denmark", "Faroe Islands", "Greenland")
> 
> seconddf <- data.frame(Country)
> 
> In this example, I need to aggregate sum Australia while keeping Faroe Islands and Greenland separate from Denmark. What I?d like to do is create a column that looks like this:
> 
> firstdf$nation <- c("Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Australia", "Austria", "Azerbaijan", "Denmark", ?Faroe Islands", ?Greenland?)
> 
> Is there a way to do this or am I stuck doing this by hand?
> 
> Thanks for any help on this vexing issue.
> 
> Jim Milks
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Aug 10 15:28:52 2021
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 10 Aug 2021 09:28:52 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
 <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
 <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>
Message-ID: <27668c28-708f-3674-3e58-f3228c0eccaa@me.com>

Hi,

A search would suggest that there may not be an R function/package that 
provides power/sample size calculations for the specific scenarios that 
you are describing. There may be something that I am missing, and there 
is also other dedicated software such as PASS 
(https://www.ncss.com/software/pass/) which is not free, but provides a 
large library of possibly relevant functions and support.

That being said, you can run Monte Carlo simulations in R to achieve the 
results you want, while providing yourself with options relative to 
study design, intended tests, and adjustments for multiple comparisons 
as apropos. Many prefer this approach, since it gives you specific 
control over this process.

Taking the simple case, where you are going to run a 3 x 2 chi-square as 
your primary endpoint, and want to power for that, here is a possible 
function, with the same sample size in each group:

ThreeGroups <- function(n, p1, p2, p3, R = 10000, power = 0.8) {

   MCSim <- function(n, p1, p2, p3) {
     ## Create a binary distribution for each group
     G1 <- rbinom(n, 1, p1)
     G2 <- rbinom(n, 1, p2)
     G3 <- rbinom(n, 1, p3)

     ## Create a 3 x 2 matrix containing the 3 group counts
     MAT <- cbind(table(G1), table(G2), table(G3))

     ## Perform a chi-square and just return the p value
     chisq.test(MAT)$p.value
   }

   ## Replicate the above R times, and get
   ## a distribution of p values
   MC <- replicate(R, MCSim(n, p1, p2, p3))

   ## Get the p value at the desired "power" quantile
   quantile(MC, power)
}

Essentially, the above internal MCSim() function generates 3 random 
samples of size 'n' from the binomial distribution, at the 3 proportions 
desired. For each run, it will perform a chi-square test of the 3 x 2 
matrix of counts, returning the p value for each run. The main function 
will then return the p value at the quantile (power) within the 
generated distribution of p values.

You can look at the help pages for the various functions that I use 
above, to get a sense for how they work.

You increase the sample size ('n') until you get a p value returned <= 
0.05, if that is your desired alpha level.

You also want 'R', the number of replications within each run, to be 
large enough so that the returned p value quantile is relatively stable. 
Values for 'R', once you get "close to" the desired p value should be on 
the order of 1,000,000 or higher. Stay with lower values for 'R' until 
you get in the ballpark of your target, since larger values take much 
longer to run.

Thus, using your example proportions of 0.25, 0.25, and 0.35:

## 250 per group, 750 total - Not enough
 > ThreeGroups(250, 0.25, 0.25, 0.35, R = 10000)
        80%
0.08884723

## 350 per group, 1050 total - Too high
 > ThreeGroups(350, 0.25, 0.25, 0.35, R = 10000)
       80%
0.0270829

## 300 per group, 900 total - Close!
 > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
        80%
0.04818842


So, keep tweaking the sample size until you get a returned p value at 
your target alpha level, with a large enough 'R', so that you get 
consistent sample sizes for multiple runs.

If I run 300 per group again, with 10,000 replicates:

 > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
        80%
0.05033933

the returned p value is slightly higher. So, again, increase R to 
improve the stability of the returned p value and run it multiple times 
to be comfortable that the p value change is less than an acceptable 
threshold.

Now, the tricky part is to decide if the 3 x 2 is your primary endpoint, 
and want to power only for that, or, if you also want to power for the 
other two-group comparisons, possibly having to account for p value 
adjustments for the multiple comparisons, resulting in the need to power 
for a lower alpha level for those tests. In that scenario, you would end 
up taking the largest sample size that you identify across the various 
hypotheses, recognizing that while you are powering for one hypothesis, 
you may be overpowering for others.

That is something that you need to decide, and perhaps consider 
consulting with other local statistical expertise, as may be apropos, in 
the prospective study design, possibly influenced by other 
relevant/similar research in your domain.

You can easily modify the above function for the two-group scenario as 
well, and I will leave that to you.

Regards,

Marc


AbouEl-Makarim Aboueissa wrote on 8/10/21 6:34 AM:
> Hi?Marc:
> 
> First, thank you very much for your help in this matter.
> 
> 
> Will perform an initial omnibus?test of all three groups (e.g. 3 x 2 
> chi-square), possibly followed by
> all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 
> 2?versus 3),
> 
> We can assume _either_ the desired sample size in each group is the same 
> _or_ proportional to the population size.
> 
>  ?We can set p=0.25 and set p1=p2=p3=p so that the H0 is true.
> 
> We can assume that the expected proportion of "Yes" values in each group 
> is 0.25
> 
> For the alternative hypotheses, for example,? we can set? p1 = .25, 
> p2=.25, p3=.35
> 
> 
> Again thank you very much in?advance.
> 
> abou
> 
> ______________________
> 
> *AbouEl-Makarim Aboueissa, PhD
> *
> *
> *
> *Professor, Statistics and Data Science*
> *Graduate Coordinator*
> *Department of Mathematics and Statistics
> *
> *University of Southern Maine*
> 
> 
> 
> On Mon, Aug 9, 2021 at 10:53 AM Marc Schwartz <marc_schwartz at me.com 
> <mailto:marc_schwartz at me.com>> wrote:
> 
>     Hi,
> 
>     You are going to need to provide more information than what you have
>     below and I may be mis-interpreting what you have provided.
> 
>     Presuming you are designing a prospective, three-group, randomized
>     allocation study, there is typically an a priori specification of the
>     ratios of the sample sizes for each group such as 1:1:1, indicating
>     that
>     the desired sample size in each group is the same.
> 
>     You would also need to specify the expected proportions of "Yes" values
>     in each group.
> 
>     Further, you need to specify how you are going to compare the
>     proportions in each group. Are you going to perform an initial omnibus
>     test of all three groups (e.g. 3 x 2 chi-square), possibly followed by
>     all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3, 2
>     versus 3), or are you just going to compare 2 versus 1, and 3 versus 1,
>     where 1 is a control group?
> 
>     Depending upon your testing plan, you may also need to account for p
>     value adjustments for multiple comparisons, in which case, you also
>     need
>     to specify what adjustment method you plan to use, to know what the
>     target alpha level will be.
> 
>     On the other hand, if you already have the data collected, thus have
>     fixed sample sizes available per your wording below, simply go ahead
>     and
>     perform your planned analyses, as the notion of "power" is largely an a
>     priori consideration, which reflects the probability of finding a
>     "statistically significant" result at a given alpha level, given that
>     your a priori assumptions are valid.
> 
>     Regards,
> 
>     Marc Schwartz
> 
> 
>     AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
>      > Dear All: good morning
>      >
>      > *Re:* Sample Size Determination to Compare Three Independent
>     Proportions
>      >
>      > *Situation:*
>      >
>      > Three Binary variables (Yes, No)
>      >
>      > Three independent populations with fixed sizes (*say:* N1 = 1500,
>     N2 = 900,
>      > N3 = 1350).
>      >
>      > Power = 0.80
>      >
>      > How to choose the sample sizes to compare the three proportions
>     of ?Yes?
>      > among the three variables.
>      >
>      > If you know a reference to this topic, it will be very helpful too.
>      >
>      > with many thanks in advance
>      >
>      > abou
>      > ______________________
>      >
>      >
>      > *AbouEl-Makarim Aboueissa, PhD*
>      >
>      > *Professor, Statistics and Data Science*
>      > *Graduate Coordinator*
>      >
>      > *Department of Mathematics and Statistics*
>      > *University of Southern Maine*
>      >
>


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Wed Aug 11 07:30:57 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Tue, 10 Aug 2021 22:30:57 -0700
Subject: [R] assigning suitability index value
Message-ID: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>

Hi R Users,
I have two tables, one is temperature data (temp) and another table is a
suitability index. I wanted to assign the suitability index value in the
temperature data (temp) based on Table 2 (or graph, which is a suitability
curve), but I could not figure it out.
Are there any suggestions for me how I can assign the suitability index
value in table1 (temp) based on the suitability graph? I have a very big
data set but showing only a few data to illustrate the problem.

temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,

1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,

1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,

1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,

415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,

415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,

415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,

15.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,

15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,

16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859

)), class = "data.frame", row.names = c(NA, -19L))


print(temp)


table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,

0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA,

-6L))

print(table2)


ggplot(data=table2, aes(x=temp, y=Index)) +

  geom_path()+

  geom_point()



# now I would like to assign the index value of table 2 into table 1
(temp), and I was looking for the following table as an output. The index
value in the output I put manually.


Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
 1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,

1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,

1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,

415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,

415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,

415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,

0.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,

15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,

16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859

), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,

0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class = "data.frame", row.names
= c(NA,

-19L))


print(Output)


Thank you very much for your help.

MW

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Aug 11 08:16:08 2021
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 10 Aug 2021 23:16:08 -0700
Subject: [R] assigning suitability index value
In-Reply-To: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>
References: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>
Message-ID: <79717F5E-7972-418A-9727-FF9874CE91EE@dcn.davis.ca.us>

Piecewise linear interpolation is implemented in the ?approx function. It does not agree exactly with your Output, I don't know if there is something else you are accounting for it if your Output is in error.

temp$index <- approx( table2$temp, table2$Index, temp$temp )$y

BTW your code was usable but messed up... please set your email program to send plain text email so your formatting does not mess with your code.


On August 10, 2021 10:30:57 PM PDT, Marna Wagley <marna.wagley at gmail.com> wrote:
>Hi R Users,
>I have two tables, one is temperature data (temp) and another table is a
>suitability index. I wanted to assign the suitability index value in the
>temperature data (temp) based on Table 2 (or graph, which is a suitability
>curve), but I could not figure it out.
>Are there any suggestions for me how I can assign the suitability index
>value in table1 (temp) based on the suitability graph? I have a very big
>data set but showing only a few data to illustrate the problem.
>
>temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
>
>1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
>
>1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
>
>1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
>
>415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
>
>415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
>
>415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
>
>15.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
>
>15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
>
>16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
>
>)), class = "data.frame", row.names = c(NA, -19L))
>
>
>print(temp)
>
>
>table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,
>
>0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA,
>
>-6L))
>
>print(table2)
>
>
>ggplot(data=table2, aes(x=temp, y=Index)) +
>
>  geom_path()+
>
>  geom_point()
>
>
>
># now I would like to assign the index value of table 2 into table 1
>(temp), and I was looking for the following table as an output. The index
>value in the output I put manually.
>
>
>Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
> 1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
>
>1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
>
>1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
>
>415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
>
>415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
>
>415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
>
>0.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
>
>15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
>
>16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
>
>), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,
>
>0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class = "data.frame", row.names
>= c(NA,
>
>-19L))
>
>
>print(Output)
>
>
>Thank you very much for your help.
>
>MW
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@rn@@w@g|ey @end|ng |rom gm@||@com  Wed Aug 11 08:30:51 2021
From: m@rn@@w@g|ey @end|ng |rom gm@||@com (Marna Wagley)
Date: Tue, 10 Aug 2021 23:30:51 -0700
Subject: [R] assigning suitability index value
In-Reply-To: <79717F5E-7972-418A-9727-FF9874CE91EE@dcn.davis.ca.us>
References: <CAMwU6B0qR2Z5Cei7Jnd+5pu8MRtF2ZLRKUssVRm-fjyfxm5+JQ@mail.gmail.com>
 <79717F5E-7972-418A-9727-FF9874CE91EE@dcn.davis.ca.us>
Message-ID: <CAMwU6B13V5ZH1xW7GKKe4VxDgzDOcEfnvXrC3J17EE9fCME6kA@mail.gmail.com>

Thank you Jeff. I think the code you wrote works. The value I put in the
output was just guessing by looking at the graph.
Thank you once again Jeff.

temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27, 415096.27,
415096.27, 415096.27, 415093.27, 415093.27, 415093.27, 415093.27, 415093.27,
415093.27, 415093.27, 415090.27, 415090.27, 415090.27, 415090.27, 415090.27,
415090.27, 415090.27), temp = c(1.959473, 15.092773, 15.128174, 14.368896,
9.892578, 15.720215, 15.767822, 15.26001, 14.642334, 14.6521, 13.916016,
10.3479, 16.052246, 16.094971, 15.167236, 15.455322, 15.472412, 24.741211,
14.755859)), class = "data.frame", row.names = c(NA, -19L))


print(temp)


table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,
 0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA, -6L))

print(table2)


ggplot(data=table2, aes(x=temp, y=Index)) +geom_path()+geom_point()



Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27, 415096.27,
415096.27, 415096.27, 415093.27, 415093.27, 415093.27, 415093.27, 415093.27,
415093.27, 415093.27, 415090.27, 415090.27, 415090.27, 415090.27, 415090.27,
415090.27, 415090.27), temp = c(1.959473, 0.092773, 15.128174, 14.368896,
9.892578, 15.720215, 15.767822, 15.26001, 14.642334, 14.6521, 13.916016,
10.3479, 16.052246, 16.094971, 15.167236, 15.455322, 15.472412, 24.741211,
14.755859), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,
0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class="data.frame", row.names =
c(NA, -19L))


print(Output)

On Tue, Aug 10, 2021 at 11:16 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Piecewise linear interpolation is implemented in the ?approx function. It
> does not agree exactly with your Output, I don't know if there is something
> else you are accounting for it if your Output is in error.
>
> temp$index <- approx( table2$temp, table2$Index, temp$temp )$y
>
> BTW your code was usable but messed up... please set your email program to
> send plain text email so your formatting does not mess with your code.
>
>
> On August 10, 2021 10:30:57 PM PDT, Marna Wagley <marna.wagley at gmail.com>
> wrote:
> >Hi R Users,
> >I have two tables, one is temperature data (temp) and another table is a
> >suitability index. I wanted to assign the suitability index value in the
> >temperature data (temp) based on Table 2 (or graph, which is a suitability
> >curve), but I could not figure it out.
> >Are there any suggestions for me how I can assign the suitability index
> >value in table1 (temp) based on the suitability graph? I have a very big
> >data set but showing only a few data to illustrate the problem.
> >
> >temp<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96, 1468482.96,
> >
> >1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
> >
> >1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
> >
> >1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
> >
> >415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
> >
> >415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
> >
> >415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
> >
> >15.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
> >
> >15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
> >
> >16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
> >
> >)), class = "data.frame", row.names = c(NA, -19L))
> >
> >
> >print(temp)
> >
> >
> >table2<-structure(list(temp = c(0L, 10L, 15L, 17L, 25L, 30L), Index = c(0,
> >
> >0.3, 1, 1, 0.5, 0)), class = "data.frame", row.names = c(NA,
> >
> >-6L))
> >
> >print(table2)
> >
> >
> >ggplot(data=table2, aes(x=temp, y=Index)) +
> >
> >  geom_path()+
> >
> >  geom_point()
> >
> >
> >
> ># now I would like to assign the index value of table 2 into table 1
> >(temp), and I was looking for the following table as an output. The index
> >value in the output I put manually.
> >
> >
> >Output<-structure(list(X = c(1468285.96, 1468476.96, 1468479.96,
> 1468482.96,
> > 1468485.96, 1468467.96, 1468470.96, 1468473.96, 1468476.96, 1468479.96,
> >
> >1468482.96, 1468485.96, 1468458.96, 1468461.96, 1468464.96, 1468467.96,
> >
> >1468470.96, 1468473.96, 1468476.96), Y = c(415099.27, 415096.27,
> >
> >415096.27, 415096.27, 415096.27, 415093.27, 415093.27, 415093.27,
> >
> >415093.27, 415093.27, 415093.27, 415093.27, 415090.27, 415090.27,
> >
> >415090.27, 415090.27, 415090.27, 415090.27, 415090.27), temp = c(1.959473,
> >
> >0.092773, 15.128174, 14.368896, 9.892578, 15.720215, 15.767822,
> >
> >15.26001, 14.642334, 14.6521, 13.916016, 10.3479, 16.052246,
> >
> >16.094971, 15.167236, 15.455322, 15.472412, 24.741211, 14.755859
> >
> >), index = c(0.012, 0.001, 1, 0.9, 0.31, 1, 1, 1, 0.91, 0.921,
> >
> >0.824, 0.254, 1, 1, 1, 1, 1, 0.652, 0.93)), class = "data.frame",
> row.names
> >= c(NA,
> >
> >-19L))
> >
> >
> >print(Output)
> >
> >
> >Thank you very much for your help.
> >
> >MW
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From t|m@t@y|or @end|ng |rom h|ddene|eph@nt@@co@uk  Wed Aug 11 10:45:48 2021
From: t|m@t@y|or @end|ng |rom h|ddene|eph@nt@@co@uk (Tim Taylor)
Date: Wed, 11 Aug 2021 08:45:48 +0000
Subject: [R] Formula compared to call within model call
Message-ID: <LO2P265MB2605932206CC0D6418B8D1E5DDF89@LO2P265MB2605.GBRP265.PROD.OUTLOOK.COM>

Manipulating formulas within different models I notice the following:

m1 <- lm(formula = hp ~ cyl, data = mtcars)
m2 <- update(m1, formula. = hp ~ cyl)
all.equal(m1, m2)
#> [1] TRUE
identical(m1, m2)
#> [1] FALSE
waldo::compare(m1, m2)
#> `old$call[[2]]` is a call
#> `new$call[[2]]` is an S3 object of class <formula>, a call

I'm aware formulas are a form of call but what I'm unsure of is whether there is meaningful difference between the two versions of the models? Any clarification, even just on the relation between formulas and calls would be useful.


From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Wed Aug 11 11:21:01 2021
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Wed, 11 Aug 2021 05:21:01 -0400
Subject: [R] Sample size Determination to Compare Three Independent
 Proportions
In-Reply-To: <27668c28-708f-3674-3e58-f3228c0eccaa@me.com>
References: <CAE9stmfFNdRc=2QPH_go+T8aFMjkTuT4jgQO-8xW3hqMrNhErA@mail.gmail.com>
 <f09cc7b7-537a-c00e-4af4-9d8a24a7c554@me.com>
 <CAE9stme5Stbjm2z15vfmsWNuZ0s7SXUxu0DF_xkOD64MQVDC=A@mail.gmail.com>
 <27668c28-708f-3674-3e58-f3228c0eccaa@me.com>
Message-ID: <CAE9stmecM6b0Sn1otqbWWMxDhKHZjO9ALBUYO8LrMHdVbCWOFA@mail.gmail.com>

Hi Marc:


Thank you for your help in this matter.


With thanks
Abou


On Tue, Aug 10, 2021, 9:28 AM Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi,
>
> A search would suggest that there may not be an R function/package that
> provides power/sample size calculations for the specific scenarios that
> you are describing. There may be something that I am missing, and there
> is also other dedicated software such as PASS
> (https://www.ncss.com/software/pass/) which is not free, but provides a
> large library of possibly relevant functions and support.
>
> That being said, you can run Monte Carlo simulations in R to achieve the
> results you want, while providing yourself with options relative to
> study design, intended tests, and adjustments for multiple comparisons
> as apropos. Many prefer this approach, since it gives you specific
> control over this process.
>
> Taking the simple case, where you are going to run a 3 x 2 chi-square as
> your primary endpoint, and want to power for that, here is a possible
> function, with the same sample size in each group:
>
> ThreeGroups <- function(n, p1, p2, p3, R = 10000, power = 0.8) {
>
>    MCSim <- function(n, p1, p2, p3) {
>      ## Create a binary distribution for each group
>      G1 <- rbinom(n, 1, p1)
>      G2 <- rbinom(n, 1, p2)
>      G3 <- rbinom(n, 1, p3)
>
>      ## Create a 3 x 2 matrix containing the 3 group counts
>      MAT <- cbind(table(G1), table(G2), table(G3))
>
>      ## Perform a chi-square and just return the p value
>      chisq.test(MAT)$p.value
>    }
>
>    ## Replicate the above R times, and get
>    ## a distribution of p values
>    MC <- replicate(R, MCSim(n, p1, p2, p3))
>
>    ## Get the p value at the desired "power" quantile
>    quantile(MC, power)
> }
>
> Essentially, the above internal MCSim() function generates 3 random
> samples of size 'n' from the binomial distribution, at the 3 proportions
> desired. For each run, it will perform a chi-square test of the 3 x 2
> matrix of counts, returning the p value for each run. The main function
> will then return the p value at the quantile (power) within the
> generated distribution of p values.
>
> You can look at the help pages for the various functions that I use
> above, to get a sense for how they work.
>
> You increase the sample size ('n') until you get a p value returned <=
> 0.05, if that is your desired alpha level.
>
> You also want 'R', the number of replications within each run, to be
> large enough so that the returned p value quantile is relatively stable.
> Values for 'R', once you get "close to" the desired p value should be on
> the order of 1,000,000 or higher. Stay with lower values for 'R' until
> you get in the ballpark of your target, since larger values take much
> longer to run.
>
> Thus, using your example proportions of 0.25, 0.25, and 0.35:
>
> ## 250 per group, 750 total - Not enough
>  > ThreeGroups(250, 0.25, 0.25, 0.35, R = 10000)
>         80%
> 0.08884723
>
> ## 350 per group, 1050 total - Too high
>  > ThreeGroups(350, 0.25, 0.25, 0.35, R = 10000)
>        80%
> 0.0270829
>
> ## 300 per group, 900 total - Close!
>  > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
>         80%
> 0.04818842
>
>
> So, keep tweaking the sample size until you get a returned p value at
> your target alpha level, with a large enough 'R', so that you get
> consistent sample sizes for multiple runs.
>
> If I run 300 per group again, with 10,000 replicates:
>
>  > ThreeGroups(300, 0.25, 0.25, 0.35, R = 10000)
>         80%
> 0.05033933
>
> the returned p value is slightly higher. So, again, increase R to
> improve the stability of the returned p value and run it multiple times
> to be comfortable that the p value change is less than an acceptable
> threshold.
>
> Now, the tricky part is to decide if the 3 x 2 is your primary endpoint,
> and want to power only for that, or, if you also want to power for the
> other two-group comparisons, possibly having to account for p value
> adjustments for the multiple comparisons, resulting in the need to power
> for a lower alpha level for those tests. In that scenario, you would end
> up taking the largest sample size that you identify across the various
> hypotheses, recognizing that while you are powering for one hypothesis,
> you may be overpowering for others.
>
> That is something that you need to decide, and perhaps consider
> consulting with other local statistical expertise, as may be apropos, in
> the prospective study design, possibly influenced by other
> relevant/similar research in your domain.
>
> You can easily modify the above function for the two-group scenario as
> well, and I will leave that to you.
>
> Regards,
>
> Marc
>
>
> AbouEl-Makarim Aboueissa wrote on 8/10/21 6:34 AM:
> > Hi Marc:
> >
> > First, thank you very much for your help in this matter.
> >
> >
> > Will perform an initial omnibus test of all three groups (e.g. 3 x 2
> > chi-square), possibly followed by
> > all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus 3,
> > 2 versus 3),
> >
> > We can assume _either_ the desired sample size in each group is the same
> > _or_ proportional to the population size.
> >
> >   We can set p=0.25 and set p1=p2=p3=p so that the H0 is true.
> >
> > We can assume that the expected proportion of "Yes" values in each group
> > is 0.25
> >
> > For the alternative hypotheses, for example,  we can set  p1 = .25,
> > p2=.25, p3=.35
> >
> >
> > Again thank you very much in advance.
> >
> > abou
> >
> > ______________________
> >
> > *AbouEl-Makarim Aboueissa, PhD
> > *
> > *
> > *
> > *Professor, Statistics and Data Science*
> > *Graduate Coordinator*
> > *Department of Mathematics and Statistics
> > *
> > *University of Southern Maine*
> >
> >
> >
> > On Mon, Aug 9, 2021 at 10:53 AM Marc Schwartz <marc_schwartz at me.com
> > <mailto:marc_schwartz at me.com>> wrote:
> >
> >     Hi,
> >
> >     You are going to need to provide more information than what you have
> >     below and I may be mis-interpreting what you have provided.
> >
> >     Presuming you are designing a prospective, three-group, randomized
> >     allocation study, there is typically an a priori specification of the
> >     ratios of the sample sizes for each group such as 1:1:1, indicating
> >     that
> >     the desired sample size in each group is the same.
> >
> >     You would also need to specify the expected proportions of "Yes"
> values
> >     in each group.
> >
> >     Further, you need to specify how you are going to compare the
> >     proportions in each group. Are you going to perform an initial
> omnibus
> >     test of all three groups (e.g. 3 x 2 chi-square), possibly followed
> by
> >     all possible 2 x 2 pairwise comparisons (e.g. 1 versus 2, 1 versus
> 3, 2
> >     versus 3), or are you just going to compare 2 versus 1, and 3 versus
> 1,
> >     where 1 is a control group?
> >
> >     Depending upon your testing plan, you may also need to account for p
> >     value adjustments for multiple comparisons, in which case, you also
> >     need
> >     to specify what adjustment method you plan to use, to know what the
> >     target alpha level will be.
> >
> >     On the other hand, if you already have the data collected, thus have
> >     fixed sample sizes available per your wording below, simply go ahead
> >     and
> >     perform your planned analyses, as the notion of "power" is largely
> an a
> >     priori consideration, which reflects the probability of finding a
> >     "statistically significant" result at a given alpha level, given that
> >     your a priori assumptions are valid.
> >
> >     Regards,
> >
> >     Marc Schwartz
> >
> >
> >     AbouEl-Makarim Aboueissa wrote on 8/9/21 9:41 AM:
> >      > Dear All: good morning
> >      >
> >      > *Re:* Sample Size Determination to Compare Three Independent
> >     Proportions
> >      >
> >      > *Situation:*
> >      >
> >      > Three Binary variables (Yes, No)
> >      >
> >      > Three independent populations with fixed sizes (*say:* N1 = 1500,
> >     N2 = 900,
> >      > N3 = 1350).
> >      >
> >      > Power = 0.80
> >      >
> >      > How to choose the sample sizes to compare the three proportions
> >     of ?Yes?
> >      > among the three variables.
> >      >
> >      > If you know a reference to this topic, it will be very helpful
> too.
> >      >
> >      > with many thanks in advance
> >      >
> >      > abou
> >      > ______________________
> >      >
> >      >
> >      > *AbouEl-Makarim Aboueissa, PhD*
> >      >
> >      > *Professor, Statistics and Data Science*
> >      > *Graduate Coordinator*
> >      >
> >      > *Department of Mathematics and Statistics*
> >      > *University of Southern Maine*
> >      >
> >
>

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Wed Aug 11 11:51:25 2021
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Wed, 11 Aug 2021 11:51:25 +0200
Subject: [R] Formula compared to call within model call
In-Reply-To: <LO2P265MB2605932206CC0D6418B8D1E5DDF89@LO2P265MB2605.GBRP265.PROD.OUTLOOK.COM>
References: <LO2P265MB2605932206CC0D6418B8D1E5DDF89@LO2P265MB2605.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <24851.40349.481350.63082@stat.math.ethz.ch>

>>>>> Tim Taylor 
>>>>>     on Wed, 11 Aug 2021 08:45:48 +0000 writes:

    > Manipulating formulas within different models I notice the following:

    > m1 <- lm(formula = hp ~ cyl, data = mtcars)
    > m2 <- update(m1, formula. = hp ~ cyl)
    > all.equal(m1, m2)
    > #> [1] TRUE
    > identical(m1, m2)
    > #> [1] FALSE
    > waldo::compare(m1, m2)
    > #> `old$call[[2]]` is a call
    > #> `new$call[[2]]` is an S3 object of class <formula>, a call

    > I'm aware formulas are a form of call but what I'm unsure
    > of is whether there is meaningful difference between the
    > two versions of the models? 

A good question.
In principle, the promise of an update()  method should be to
produce the *same* result as calling the original model-creation
(or more generally object-creation) function call.

So, already with identical(), you've shown that this is not
quite the case for simple lm(),
and indeed that is a bit undesirable.

To answer your question re "meaningful" difference,
given what I say above is:
No, there shouldn't be any relevant difference, and if there is,
that may considered a bug in the respective update() method,
here update.lm.

More about this in the following  R code snippet :

## MM: indeed,
identical(m1$call, m2$call) #> [1] FALSE
noCall <- function(x) x[setdiff(names(x), "call")]
identical(noCall(m1), noCall(m2))# TRUE!
## look closer:
c1 <- m1$call
c2 <- m2$call
str(as.list(c1))
## List of 3
##  $        : symbol lm
##  $ formula: language hp ~ cyl
##  $ data   : symbol mtcars

str(as.list(c2))
## List of 3
##  $        : symbol lm
##  $ formula:Class 'formula'  language hp ~ cyl
##   .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
##  $ data   : symbol mtcars

identical(c1[-2], c2[-2]) # TRUE ==> so, indeed the difference is *only* in the formula ( = [2]) component
f1 <- c1$formula
f2 <- c2$formula
all.equal(f1,f2) # TRUE
identical(f1,f2) # FALSE
## Note that this is typically *not* visible if the user uses the accessor functions:
identical(formula(m1), formula(m2)) # TRUE !
## and indeed, the formula() method for 'lm'  does set the environment:
stats:::formula.lm


--
Martin Maechler
ETH Zurich   and  R Core


From d|cook@rj @end|ng |rom gm@||@com  Wed Aug 11 09:29:32 2021
From: d|cook@rj @end|ng |rom gm@||@com (Dianne Cook)
Date: Wed, 11 Aug 2021 17:29:32 +1000
Subject: [R] Volume 13/1, June 2021 now available
Message-ID: <35571119-0C8A-43B1-A7BB-AB9E2630542B@gmail.com>

Dear R Community,

The first issue of the R Journal for 2021 is now available at https://journal.r-project.org/. 

There is also a dev version of rending articles in html at https://journal.r-project.org/dev/. Particularly look at articles by Earo Wang for embedded interactive graphics, and by Mike Kane for html rendering. Feedback and suggestions are welcome.

Happy reading, and coding!

Regards,
Di

%>%>%>%>%
Professor Dianne Cook
Editor-in-Chief, R Journal
dicook.rj at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From e@hoo@hm@nd96 @end|ng |rom gm@||@com  Wed Aug 11 09:34:37 2021
From: e@hoo@hm@nd96 @end|ng |rom gm@||@com (Elham Hooshmand)
Date: Wed, 11 Aug 2021 12:04:37 +0430
Subject: [R] collided row names in heatmap.2
Message-ID: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>

Hi,

I am trying to draw a heatmap for my 45 topvar gene by the use of
heatmap.2, and when I set a srtRow=45 in my code(below):

heatmap.2( assay(rld)[ topVarGenes, ], srtRow=45, scale="row",trace="none",
dendrogram="column",col = colorRampPalette( rev(brewer.pal(9, "RdBu"))
)(255))

row names collided with each other in a messy way.

would you please help me to solve this problem? (also I'm a newbie beginner
using R Studio) Thank you so much
(also I attached the output image)

From bgunter@4567 @end|ng |rom gm@||@com  Wed Aug 11 19:19:20 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 11 Aug 2021 10:19:20 -0700
Subject: [R] collided row names in heatmap.2
In-Reply-To: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
References: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
Message-ID: <CAGxFJbR2kkP+DYribHWgwHBd6ygCUmKNwneB3T6n5_tekD97NA@mail.gmail.com>

1. This is R-help. RStudio is a separate IDE from a private for-profit
company. You should go to their website for help with that:
https://www.rstudio.com/support/

2. I may be wrong, of course, but I believe your information is too
vague for folks to provide useful help: "row names collided with each
other in a messy way,' does not tell us much. What error message did
you get? Please provide a small, reproducible example (perhaps
via head(yourdatset, ...) see e.g. ?head and ?dput and
https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
. You may also wish to download and use the "reprex" package for this
purpose, instead. **See also the posting guide linked below.**

All of us were newbies at one time; take the time to learn these tools
and follow the advice for posting to R-help, and I believe that you
will have much greater success in getting useful help here as you
climb the learning curve.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Aug 11, 2021 at 9:07 AM Elham Hooshmand <e.hooshmand96 at gmail.com> wrote:
>
> Hi,
>
> I am trying to draw a heatmap for my 45 topvar gene by the use of
> heatmap.2, and when I set a srtRow=45 in my code(below):
>
> heatmap.2( assay(rld)[ topVarGenes, ], srtRow=45, scale="row",trace="none",
> dendrogram="column",col = colorRampPalette( rev(brewer.pal(9, "RdBu"))
> )(255))
>
> row names collided with each other in a messy way.
>
> would you please help me to solve this problem? (also I'm a newbie beginner
> using R Studio) Thank you so much
> (also I attached the output image)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Aug 11 23:47:27 2021
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 12 Aug 2021 07:47:27 +1000
Subject: [R] collided row names in heatmap.2
In-Reply-To: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
References: <CAHBfeC0bvQKqJuP1mrLQt67fk147ubevfw-8TqrwCGHoTE9XFw@mail.gmail.com>
Message-ID: <CA+8X3fUEe9726xbE0hCO0-TJXxPo8BH7UYZgt1zo7PMqNoc1DQ@mail.gmail.com>

Hi Elham,
Your image didn't get through, maybe PNG will work. Label crowding is
a common problem, whether horizontal or vertical. One solution is to
set a maximum length on label text (see truncString in the prettyR
package). Others are to stagger labels (staxlab in plotrix) or shift
them apart when crowded (spread.labels in plotrix). These functions
may not work with heatmap.2 (gplots). It will be easier to suggest
something if you can get your image through.

Jim

On Thu, Aug 12, 2021 at 2:07 AM Elham Hooshmand <e.hooshmand96 at gmail.com> wrote:
>
> Hi,
>
> I am trying to draw a heatmap for my 45 topvar gene by the use of
> heatmap.2, and when I set a srtRow=45 in my code(below):
>
> heatmap.2( assay(rld)[ topVarGenes, ], srtRow=45, scale="row",trace="none",
> dendrogram="column",col = colorRampPalette( rev(brewer.pal(9, "RdBu"))
> )(255))
>
> row names collided with each other in a messy way.
>
> would you please help me to solve this problem? (also I'm a newbie beginner
> using R Studio) Thank you so much
> (also I attached the output image)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Aug 12 14:37:32 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 12 Aug 2021 14:37:32 +0200
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
Message-ID: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>

Helo
I have a dataframe whose names are similar and I would like to change
the rows containing given values simultaneously.
I can select the columns using library(dplyr) but I can't modify the data:
```
library(dplyr)
> df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
+                 var2 = c(LETTERS[1:7]),
+                 var3 = c(letters[1:3], letters[1:4]),
+                 var4 = (1:7)^2,
+                 var5 = c("light", "light", "heavy", "heavy", "heavy",
+                          "light", "heavy"),
+                 stringsAsFactors = FALSE); df
  var1 var2 var3 var4  var5
1    a    A    a    1 light
2    b    B    b    4 light
3    c    C    c    9 heavy
4    a    D    a   16 heavy
5    b    E    b   25 heavy
6    c    F    c   36 light
7    d    G    d   49 heavy
> select(df, matches("var[123]"))
  var1 var2 var3
1    a    A    a
2    b    B    b
3    c    C    c
4    a    D    a
5    b    E    b
6    c    F    c
7    d    G    d
> df[[select(df, matches("var[123]")) == "a"]] <- "z"
Error in `[[<-`(`*tmp*`, i, value = value) :
  recursive indexing failed at level 2
> df[[select(df, contains("var1")) == "a"]] <- "z"
Error in `[[<-`(`*tmp*`, i, value = value) :
  recursive indexing failed at level 2
```
If I sue which, I get a wrong substitution :
```
> df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
   var1 var2 var3 var4  var5
1     z    z    z    z     z
2     b    B    b    4 light
3     c    C    c    9 heavy
4     z    z    z    z     z
5     b    E    b   25 heavy
6     c    F    c   36 light
7     d    G    d   49 heavy
8  <NA> <NA> <NA> <NA>  <NA>
9  <NA> <NA> <NA> <NA>  <NA>
10 <NA> <NA> <NA> <NA>  <NA>
11 <NA> <NA> <NA> <NA>  <NA>
12 <NA> <NA> <NA> <NA>  <NA>
13 <NA> <NA> <NA> <NA>  <NA>
14 <NA> <NA> <NA> <NA>  <NA>
15    z    z    z    z     z
16 <NA> <NA> <NA> <NA>  <NA>
17 <NA> <NA> <NA> <NA>  <NA>
18    z    z    z    z     z
```

what is the correct syntax?
Thank you

-- 
Best regards,
Luigi


From er|cjberger @end|ng |rom gm@||@com  Thu Aug 12 16:46:54 2021
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 12 Aug 2021 17:46:54 +0300
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
Message-ID: <CAGgJW74wFo-Q1MBAGDYreApHQ7Kpc1RQVkJw9opHz_B7cKrGRg@mail.gmail.com>

Hi Luigi,
I would take a slightly different approach. Maybe this is helpful.

idV <- grep("var[123]",colnames(df))
df[,idV][df[,idV]=="a"] <- "z"

df
  var1 var2 var3 var4  var5
1    z    A    z    1 light
2    b    B    b    4 light
3    c    C    c    9 heavy
4    z    D    z   16 heavy
5    b    E    b   25 heavy
6    c    F    c   36 light
7    d    G    d   49 heavy

HTH,
Eric


On Thu, Aug 12, 2021 at 3:38 PM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Helo
> I have a dataframe whose names are similar and I would like to change
> the rows containing given values simultaneously.
> I can select the columns using library(dplyr) but I can't modify the data:
> ```
> library(dplyr)
> > df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> +                 var2 = c(LETTERS[1:7]),
> +                 var3 = c(letters[1:3], letters[1:4]),
> +                 var4 = (1:7)^2,
> +                 var5 = c("light", "light", "heavy", "heavy", "heavy",
> +                          "light", "heavy"),
> +                 stringsAsFactors = FALSE); df
>   var1 var2 var3 var4  var5
> 1    a    A    a    1 light
> 2    b    B    b    4 light
> 3    c    C    c    9 heavy
> 4    a    D    a   16 heavy
> 5    b    E    b   25 heavy
> 6    c    F    c   36 light
> 7    d    G    d   49 heavy
> > select(df, matches("var[123]"))
>   var1 var2 var3
> 1    a    A    a
> 2    b    B    b
> 3    c    C    c
> 4    a    D    a
> 5    b    E    b
> 6    c    F    c
> 7    d    G    d
> > df[[select(df, matches("var[123]")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> > df[[select(df, contains("var1")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> ```
> If I sue which, I get a wrong substitution :
> ```
> > df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
>    var1 var2 var3 var4  var5
> 1     z    z    z    z     z
> 2     b    B    b    4 light
> 3     c    C    c    9 heavy
> 4     z    z    z    z     z
> 5     b    E    b   25 heavy
> 6     c    F    c   36 light
> 7     d    G    d   49 heavy
> 8  <NA> <NA> <NA> <NA>  <NA>
> 9  <NA> <NA> <NA> <NA>  <NA>
> 10 <NA> <NA> <NA> <NA>  <NA>
> 11 <NA> <NA> <NA> <NA>  <NA>
> 12 <NA> <NA> <NA> <NA>  <NA>
> 13 <NA> <NA> <NA> <NA>  <NA>
> 14 <NA> <NA> <NA> <NA>  <NA>
> 15    z    z    z    z     z
> 16 <NA> <NA> <NA> <NA>  <NA>
> 17 <NA> <NA> <NA> <NA>  <NA>
> 18    z    z    z    z     z
> ```
>
> what is the correct syntax?
> Thank you
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From k|mmo@e|o @end|ng |rom utu@||  Thu Aug 12 15:17:25 2021
From: k|mmo@e|o @end|ng |rom utu@|| (Kimmo Elo)
Date: Thu, 12 Aug 2021 13:17:25 +0000
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
Message-ID: <44dc842b3afe5faccc0f2074a717fb811cca66af.camel@utu.fi>

Hi,

something like this (a customised version based on this: 
https://stackoverflow.com/questions/25768305/r-replace-multiple-values-in-multiple-columns-of-dataframes-with-na
):

--- snip ---

col_idx<-grep("^var[123]", names(df))
m1<-as.matrix(df[,col_idx])
m1[m1=="a"]<-"z"
df[col_idx]<-m1
df

--- snip ---

HTH,

Kimmo

to, 2021-08-12 kello 14:37 +0200, Luigi Marongiu kirjoitti:
> Helo
> I have a dataframe whose names are similar and I would like to change
> the rows containing given values simultaneously.
> I can select the columns using library(dplyr) but I can't modify the
> data:
> ```
> library(dplyr)
> > df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> +                 var2 = c(LETTERS[1:7]),
> +                 var3 = c(letters[1:3], letters[1:4]),
> +                 var4 = (1:7)^2,
> +                 var5 = c("light", "light", "heavy", "heavy",
> "heavy",
> +                          "light", "heavy"),
> +                 stringsAsFactors = FALSE); df
>   var1 var2 var3 var4  var5
> 1    a    A    a    1 light
> 2    b    B    b    4 light
> 3    c    C    c    9 heavy
> 4    a    D    a   16 heavy
> 5    b    E    b   25 heavy
> 6    c    F    c   36 light
> 7    d    G    d   49 heavy
> > select(df, matches("var[123]"))
>   var1 var2 var3
> 1    a    A    a
> 2    b    B    b
> 3    c    C    c
> 4    a    D    a
> 5    b    E    b
> 6    c    F    c
> 7    d    G    d
> > df[[select(df, matches("var[123]")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> > df[[select(df, contains("var1")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>   recursive indexing failed at level 2
> ```
> If I sue which, I get a wrong substitution :
> ```
> > df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
>    var1 var2 var3 var4  var5
> 1     z    z    z    z     z
> 2     b    B    b    4 light
> 3     c    C    c    9 heavy
> 4     z    z    z    z     z
> 5     b    E    b   25 heavy
> 6     c    F    c   36 light
> 7     d    G    d   49 heavy
> 8  <NA> <NA> <NA> <NA>  <NA>
> 9  <NA> <NA> <NA> <NA>  <NA>
> 10 <NA> <NA> <NA> <NA>  <NA>
> 11 <NA> <NA> <NA> <NA>  <NA>
> 12 <NA> <NA> <NA> <NA>  <NA>
> 13 <NA> <NA> <NA> <NA>  <NA>
> 14 <NA> <NA> <NA> <NA>  <NA>
> 15    z    z    z    z     z
> 16 <NA> <NA> <NA> <NA>  <NA>
> 17 <NA> <NA> <NA> <NA>  <NA>
> 18    z    z    z    z     z
> ```
> 
> what is the correct syntax?
> Thank you
> 

From y@ngk@|9999 @end|ng |rom y@hoo@com  Thu Aug 12 17:38:42 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Thu, 12 Aug 2021 15:38:42 +0000 (UTC)
Subject: [R] ggplot: add percentage for each element in legend and remove
 tick mark
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
Message-ID: <774219336.1144213.1628782722523@mail.yahoo.com>

Hello List,
I use the following code to generate a donut plot.
# Compute percentages
eth$fraction = eth$individuals / sum(eth$individuals)
# Compute the cumulative percentages (top of each rectangle)
eth$ymax = cumsum(eth$fraction)
# Compute the bottom of each rectangle
eth$ymin = c(0, head(eth$ymax, n=-1))
# Make the plot using percentage
ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
? geom_rect() +
? coord_polar(theta="y")? +
? xlim(c(2, 4)?
? )?

I want to improve the plot for two thing:?
1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
2. remove all number (tick mark ?) around the plot
Please help
Thank you,
Kai

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Aug 12 18:59:10 2021
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 12 Aug 2021 17:59:10 +0100
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
Message-ID: <44f605e2-ef51-d25a-24d8-fe5c23e656b7@sapo.pt>

Hello,

And another way, with which(., arr.ind = TRUE).
In two steps, to make it clearer.


i <- which(df[grep("var[123]", names(df))] == "a", arr.ind = TRUE)
df[i] <- "z"

df
#  var1 var2 var3 var4  var5
#1    z    A    z    1 light
#2    b    B    b    4 light
#3    c    C    c    9 heavy
#4    z    D    z   16 heavy
#5    b    E    b   25 heavy
#6    c    F    c   36 light
#7    d    G    d   49 heavy


Hope this helps,

Rui Barradas


?s 13:37 de 12/08/21, Luigi Marongiu escreveu:
> Helo
> I have a dataframe whose names are similar and I would like to change
> the rows containing given values simultaneously.
> I can select the columns using library(dplyr) but I can't modify the data:
> ```
> library(dplyr)
>> df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> +                 var2 = c(LETTERS[1:7]),
> +                 var3 = c(letters[1:3], letters[1:4]),
> +                 var4 = (1:7)^2,
> +                 var5 = c("light", "light", "heavy", "heavy", "heavy",
> +                          "light", "heavy"),
> +                 stringsAsFactors = FALSE); df
>    var1 var2 var3 var4  var5
> 1    a    A    a    1 light
> 2    b    B    b    4 light
> 3    c    C    c    9 heavy
> 4    a    D    a   16 heavy
> 5    b    E    b   25 heavy
> 6    c    F    c   36 light
> 7    d    G    d   49 heavy
>> select(df, matches("var[123]"))
>    var1 var2 var3
> 1    a    A    a
> 2    b    B    b
> 3    c    C    c
> 4    a    D    a
> 5    b    E    b
> 6    c    F    c
> 7    d    G    d
>> df[[select(df, matches("var[123]")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>    recursive indexing failed at level 2
>> df[[select(df, contains("var1")) == "a"]] <- "z"
> Error in `[[<-`(`*tmp*`, i, value = value) :
>    recursive indexing failed at level 2
> ```
> If I sue which, I get a wrong substitution :
> ```
>> df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
>     var1 var2 var3 var4  var5
> 1     z    z    z    z     z
> 2     b    B    b    4 light
> 3     c    C    c    9 heavy
> 4     z    z    z    z     z
> 5     b    E    b   25 heavy
> 6     c    F    c   36 light
> 7     d    G    d   49 heavy
> 8  <NA> <NA> <NA> <NA>  <NA>
> 9  <NA> <NA> <NA> <NA>  <NA>
> 10 <NA> <NA> <NA> <NA>  <NA>
> 11 <NA> <NA> <NA> <NA>  <NA>
> 12 <NA> <NA> <NA> <NA>  <NA>
> 13 <NA> <NA> <NA> <NA>  <NA>
> 14 <NA> <NA> <NA> <NA>  <NA>
> 15    z    z    z    z     z
> 16 <NA> <NA> <NA> <NA>  <NA>
> 17 <NA> <NA> <NA> <NA>  <NA>
> 18    z    z    z    z     z
> ```
> 
> what is the correct syntax?
> Thank you
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Aug 13 15:09:01 2021
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 13 Aug 2021 15:09:01 +0200
Subject: [R] How to modify rows matching patter on multiple columns of
 dataframe?
In-Reply-To: <44f605e2-ef51-d25a-24d8-fe5c23e656b7@sapo.pt>
References: <CAMk+s2SiDnFvZZxnYt6O-184dKWdrU=b38r3jMY8s-u+vvnDcA@mail.gmail.com>
 <44f605e2-ef51-d25a-24d8-fe5c23e656b7@sapo.pt>
Message-ID: <CAMk+s2TRfiC76AZ2yhOp-73_v9Wr42851qNBrphGZe_5mtW6OQ@mail.gmail.com>

Thank you! both hacks worked as needed!

On Thu, Aug 12, 2021 at 6:59 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> And another way, with which(., arr.ind = TRUE).
> In two steps, to make it clearer.
>
>
> i <- which(df[grep("var[123]", names(df))] == "a", arr.ind = TRUE)
> df[i] <- "z"
>
> df
> #  var1 var2 var3 var4  var5
> #1    z    A    z    1 light
> #2    b    B    b    4 light
> #3    c    C    c    9 heavy
> #4    z    D    z   16 heavy
> #5    b    E    b   25 heavy
> #6    c    F    c   36 light
> #7    d    G    d   49 heavy
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 13:37 de 12/08/21, Luigi Marongiu escreveu:
> > Helo
> > I have a dataframe whose names are similar and I would like to change
> > the rows containing given values simultaneously.
> > I can select the columns using library(dplyr) but I can't modify the data:
> > ```
> > library(dplyr)
> >> df <- data.frame(var1 = c(letters[1:3], letters[1:4]),
> > +                 var2 = c(LETTERS[1:7]),
> > +                 var3 = c(letters[1:3], letters[1:4]),
> > +                 var4 = (1:7)^2,
> > +                 var5 = c("light", "light", "heavy", "heavy", "heavy",
> > +                          "light", "heavy"),
> > +                 stringsAsFactors = FALSE); df
> >    var1 var2 var3 var4  var5
> > 1    a    A    a    1 light
> > 2    b    B    b    4 light
> > 3    c    C    c    9 heavy
> > 4    a    D    a   16 heavy
> > 5    b    E    b   25 heavy
> > 6    c    F    c   36 light
> > 7    d    G    d   49 heavy
> >> select(df, matches("var[123]"))
> >    var1 var2 var3
> > 1    a    A    a
> > 2    b    B    b
> > 3    c    C    c
> > 4    a    D    a
> > 5    b    E    b
> > 6    c    F    c
> > 7    d    G    d
> >> df[[select(df, matches("var[123]")) == "a"]] <- "z"
> > Error in `[[<-`(`*tmp*`, i, value = value) :
> >    recursive indexing failed at level 2
> >> df[[select(df, contains("var1")) == "a"]] <- "z"
> > Error in `[[<-`(`*tmp*`, i, value = value) :
> >    recursive indexing failed at level 2
> > ```
> > If I sue which, I get a wrong substitution :
> > ```
> >> df[which(select(df, matches("var[123]")) == "a"), ] <- "z"; df
> >     var1 var2 var3 var4  var5
> > 1     z    z    z    z     z
> > 2     b    B    b    4 light
> > 3     c    C    c    9 heavy
> > 4     z    z    z    z     z
> > 5     b    E    b   25 heavy
> > 6     c    F    c   36 light
> > 7     d    G    d   49 heavy
> > 8  <NA> <NA> <NA> <NA>  <NA>
> > 9  <NA> <NA> <NA> <NA>  <NA>
> > 10 <NA> <NA> <NA> <NA>  <NA>
> > 11 <NA> <NA> <NA> <NA>  <NA>
> > 12 <NA> <NA> <NA> <NA>  <NA>
> > 13 <NA> <NA> <NA> <NA>  <NA>
> > 14 <NA> <NA> <NA> <NA>  <NA>
> > 15    z    z    z    z     z
> > 16 <NA> <NA> <NA> <NA>  <NA>
> > 17 <NA> <NA> <NA> <NA>  <NA>
> > 18    z    z    z    z     z
> > ```
> >
> > what is the correct syntax?
> > Thank you
> >



-- 
Best regards,
Luigi


From jrkr|de@u @end|ng |rom gm@||@com  Fri Aug 13 15:21:17 2021
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Fri, 13 Aug 2021 09:21:17 -0400
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <774219336.1144213.1628782722523@mail.yahoo.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
Message-ID: <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>

Would you supply some sample data please? A handy way to supply sample
data is to use the dput() function. See ?dput.  If you have a very
large data set then something like head(dput(myfile), 100) will likely
supply enough data for us to work with.

On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> I use the following code to generate a donut plot.
> # Compute percentages
> eth$fraction = eth$individuals / sum(eth$individuals)
> # Compute the cumulative percentages (top of each rectangle)
> eth$ymax = cumsum(eth$fraction)
> # Compute the bottom of each rectangle
> eth$ymin = c(0, head(eth$ymax, n=-1))
> # Make the plot using percentage
> ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
>   geom_rect() +
>   coord_polar(theta="y")  +
>   xlim(c(2, 4)
>   )
>
> I want to improve the plot for two thing:
> 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> 2. remove all number (tick mark ?) around the plot
> Please help
> Thank you,
> Kai
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From y@ngk@|9999 @end|ng |rom y@hoo@com  Fri Aug 13 23:48:15 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 13 Aug 2021 21:48:15 +0000 (UTC)
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
Message-ID: <227125051.247175.1628891295722@mail.yahoo.com>

 Hello John,
I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
Thanks,
Kai

| 
ethnicity | 
individuals |
| Caucasian | 36062 |
| Ashkenazi Jewish | 4309 |
| Multiple | 3193 |
| Hispanic | 2113 |
| Asian. not specified | 1538 |
| Chinese | 1031 |
| African | 643 |
| Unknown | 510 |
| Filipino | 222 |
| Japanese | 129 |
| Native American | 116 |
| Indian | 111 |
| Pacific Islander | 23 |



    On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:  
 
 Would you supply some sample data please? A handy way to supply sample
data is to use the dput() function. See ?dput.? If you have a very
large data set then something like head(dput(myfile), 100) will likely
supply enough data for us to work with.

On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
>
> Hello List,
> I use the following code to generate a donut plot.
> # Compute percentages
> eth$fraction = eth$individuals / sum(eth$individuals)
> # Compute the cumulative percentages (top of each rectangle)
> eth$ymax = cumsum(eth$fraction)
> # Compute the bottom of each rectangle
> eth$ymin = c(0, head(eth$ymax, n=-1))
> # Make the plot using percentage
> ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
>? geom_rect() +
>? coord_polar(theta="y")? +
>? xlim(c(2, 4)
>? )
>
> I want to improve the plot for two thing:
> 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> 2. remove all number (tick mark ?) around the plot
> Please help
> Thank you,
> Kai
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada
  
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sat Aug 14 00:02:13 2021
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 13 Aug 2021 15:02:13 -0700
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <227125051.247175.1628891295722@mail.yahoo.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
 <227125051.247175.1628891295722@mail.yahoo.com>
Message-ID: <CAGxFJbR-uWkjeNkNjGUyGEJ5AOMTEAGWSEZ_n9DQHGMYSgv6=Q@mail.gmail.com>

It's dput()  *not* dupt() .  ?dput tells you how to use it (as usual).

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 13, 2021 at 2:48 PM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
>  Hello John,
> I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
> Thanks,
> Kai
>
> |
> ethnicity |
> individuals |
> | Caucasian | 36062 |
> | Ashkenazi Jewish | 4309 |
> | Multiple | 3193 |
> | Hispanic | 2113 |
> | Asian. not specified | 1538 |
> | Chinese | 1031 |
> | African | 643 |
> | Unknown | 510 |
> | Filipino | 222 |
> | Japanese | 129 |
> | Native American | 116 |
> | Indian | 111 |
> | Pacific Islander | 23 |
>
>
>
>     On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:
>
>  Would you supply some sample data please? A handy way to supply sample
> data is to use the dput() function. See ?dput.  If you have a very
> large data set then something like head(dput(myfile), 100) will likely
> supply enough data for us to work with.
>
> On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
> >
> > Hello List,
> > I use the following code to generate a donut plot.
> > # Compute percentages
> > eth$fraction = eth$individuals / sum(eth$individuals)
> > # Compute the cumulative percentages (top of each rectangle)
> > eth$ymax = cumsum(eth$fraction)
> > # Compute the bottom of each rectangle
> > eth$ymin = c(0, head(eth$ymax, n=-1))
> > # Make the plot using percentage
> > ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
> >  geom_rect() +
> >  coord_polar(theta="y")  +
> >  xlim(c(2, 4)
> >  )
> >
> > I want to improve the plot for two thing:
> > 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> > 2. remove all number (tick mark ?) around the plot
> > Please help
> > Thank you,
> > Kai
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Sat Aug 14 01:35:06 2021
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Fri, 13 Aug 2021 23:35:06 +0000 (UTC)
Subject: [R] 
 ggplot: add percentage for each element in legend and remove
 tick mark
In-Reply-To: <CAGxFJbR-uWkjeNkNjGUyGEJ5AOMTEAGWSEZ_n9DQHGMYSgv6=Q@mail.gmail.com>
References: <774219336.1144213.1628782722523.ref@mail.yahoo.com>
 <774219336.1144213.1628782722523@mail.yahoo.com>
 <CAKZQJMD8zXKeS1hVFY2QDgjg59BPOiU5M3tPZLckAW1vM3SSBg@mail.gmail.com>
 <227125051.247175.1628891295722@mail.yahoo.com>
 <CAGxFJbR-uWkjeNkNjGUyGEJ5AOMTEAGWSEZ_n9DQHGMYSgv6=Q@mail.gmail.com>
Message-ID: <2107813080.268761.1628897706580@mail.yahoo.com>

 Got it.Thank you.
    On Friday, August 13, 2021, 03:03:26 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 It's dput()? *not* dupt() .? ?dput tells you how to use it (as usual).

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Aug 13, 2021 at 2:48 PM Kai Yang via R-help
<r-help at r-project.org> wrote:
>
>? Hello John,
> I put my testing data below. I'm not sure how to use dupt() function. would you please give me an example?
> Thanks,
> Kai
>
> |
> ethnicity |
> individuals |
> | Caucasian | 36062 |
> | Ashkenazi Jewish | 4309 |
> | Multiple | 3193 |
> | Hispanic | 2113 |
> | Asian. not specified | 1538 |
> | Chinese | 1031 |
> | African | 643 |
> | Unknown | 510 |
> | Filipino | 222 |
> | Japanese | 129 |
> | Native American | 116 |
> | Indian | 111 |
> | Pacific Islander | 23 |
>
>
>
>? ? On Friday, August 13, 2021, 06:21:29 AM PDT, John Kane <jrkrideau at gmail.com> wrote:
>
>? Would you supply some sample data please? A handy way to supply sample
> data is to use the dput() function. See ?dput.? If you have a very
> large data set then something like head(dput(myfile), 100) will likely
> supply enough data for us to work with.
>
> On Thu, 12 Aug 2021 at 11:45, Kai Yang via R-help <r-help at r-project.org> wrote:
> >
> > Hello List,
> > I use the following code to generate a donut plot.
> > # Compute percentages
> > eth$fraction = eth$individuals / sum(eth$individuals)
> > # Compute the cumulative percentages (top of each rectangle)
> > eth$ymax = cumsum(eth$fraction)
> > # Compute the bottom of each rectangle
> > eth$ymin = c(0, head(eth$ymax, n=-1))
> > # Make the plot using percentage
> > ggplot(eth, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=ethnicity)) +
> >? geom_rect() +
> >? coord_polar(theta="y")? +
> >? xlim(c(2, 4)
> >? )
> >
> > I want to improve the plot for two thing:
> > 1. the legend: I need to add percentage (eth$fraction * 100 and then add %) for each of element.
> > 2. remove all number (tick mark ?) around the plot
> > Please help
> > Thank you,
> > Kai
> >
> >? ? ? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> John Kane
> Kingston ON Canada
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


