From drj|m|emon @end|ng |rom gm@||@com  Mon Jun  1 01:36:23 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 1 Jun 2020 09:36:23 +1000
Subject: [R] Query on contour plots
In-Reply-To: <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
Message-ID: <CA+8X3fVn8eBtLj-+UbDMX-Ui5qJ-N8Tf=RKPtKPfug4T4qc0NQ@mail.gmail.com>

Hi Neo,
It's a bit of a guess, but try this:

bat_call<-read.table(text="Fc      Sc
26.58   -5.95
27.03   -8.2
27.16   -2.07
26.19   -7.68
26.62   -3.99
26.85   -6.08
26.94   0
26.1    -5.74
26.62   -5.96
26.85   -4.05
26.98   -4.09
26.02   -5.69
26.53   -7.89
26.62   -2
26.8    -4.04
28.73   7
25.72   -2.97
26.14   -5.76
26.32   -3.89
26.4    0
26.32   5.88",
header=TRUE)
library(plotrix)
color2D.matplot(makeDensityMatrix(bat_call$Fc,bat_call$Sc,nx=5,ny=5,
 zfun="sum",xlim=range(bat_call$Fc),ylim=range(bat_call$Sc)),
 main="Map of bat calls",extremes=c("blue","red"),xlab="Frequency",
 ylab="Characteristic slope",axes=FALSE)
axis(1,at=seq(0.5,4.5,1),seq(26.3,28.3,0.5))
axis(2,at=seq(0.5,4.5,1),seq(4,-11.2,-3.5))
color.legend(-0.5,-0.65,1,-0.45,legend=seq(0,4,length.out=5),
 rect.col=color.scale(0:4,extremes=c("blue","red")),align="rb")
text(0.25,-0.89,"Density",xpd=TRUE)

Jim

On Mon, Jun 1, 2020 at 3:16 AM Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi all,
>
> While exploring  packages for 3D plots that several folks suggested (Tnx
> all!)
> It seems what I really need is a contour plot.  This is not working int
> he Deducer GUI.
>
> This will be an aid to separating bats by their vocal signatures.
> What I need to do is plot *Fc *against *Sc* with the third dimension
> being the *density* of the data points in the Fc-Sc plot.
>
> Data format is like this abbreviated sample.  Fc is a frequency in kHz
> and Sc is the characteristic slope  (octaves per second) of each call pulse.
>
> Any suggestions, guidance greatly appreciated.
> Bruce
>
> Fc      Sc
> 26.58   -5.95
> 27.03   -8.2
> 27.16   -2.07
> 26.19   -7.68
> 26.62   -3.99
> 26.85   -6.08
> 26.94   0
> 26.1    -5.74
> 26.62   -5.96
> 26.85   -4.05
> 26.98   -4.09
> 26.02   -5.69
> 26.53   -7.89
> 26.62   -2
> 26.8    -4.04
> 28.73   7
> 25.72   -2.97
> 26.14   -5.76
> 26.32   -3.89
> 26.4    0
> 26.32   5.88
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Mon Jun  1 05:03:33 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 1 Jun 2020 13:03:33 +1000
Subject: [R] Query on contour plots
In-Reply-To: <7faded2a-b184-832a-f9a3-8d4216268383@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CA+8X3fVn8eBtLj-+UbDMX-Ui5qJ-N8Tf=RKPtKPfug4T4qc0NQ@mail.gmail.com>
 <7faded2a-b184-832a-f9a3-8d4216268383@gmail.com>
Message-ID: <CA+8X3fUzxuDfjRpQted-Zzn4Wwes5c2GbAggTueRsb7cqWkMcg@mail.gmail.com>

Hi Bruce,
With a much larger data set, you would see a smoother plot like your
sample. I plotted frequency as the abcissa and slope as the ordinate. It
looks as though your sample has it the other way round and the plot limits
are extended beyond the range of the data. However, makeDensityMatrix and
color2D.matplot could produce a plot like it.

Jim

On Mon, Jun 1, 2020 at 11:13 AM Neotropical bat risk assessments <
neotropical.bats at gmail.com> wrote:

> Tnx Jim
>
> Great help.
> I need to read about package plotrix .
> Hoping to achieve something like this sample on right.
>

	[[alternative HTML version deleted]]


From v@h|d@borj|65 @end|ng |rom gm@||@com  Mon Jun  1 12:49:16 2020
From: v@h|d@borj|65 @end|ng |rom gm@||@com (Vahid Borji)
Date: Mon, 1 Jun 2020 15:19:16 +0430
Subject: [R] How to create a warning inside the factorial function for
 decimal numbers
Message-ID: <CAEPHqhYg4CBUHvG5SwgPFo2mc4csn8QQUq=0wn5vUqii1cx5CQ@mail.gmail.com>

I am writing a code for the factorial function. My code is as follows:

> f<- function(n){+ factorial <- 1+ if( n < 0 )+ print("Factorial of negative numbers is not possible")+ else if( n == 0 )+ print("Factorial of 0 is 1")+ else {+ for(i in 1:n)+ factorial <- factorial * i+ print(paste("Factorial of ",n," is ",factorial))+ }+ }

My problem with this code is for decimal numbers as input. For example for
f(6.5) my code computes 720, but we know 6.5 ! does not exist. For decimal
numbers like, or sqrt(2) I would like to see a message like

"The factorial for this number does not exist".

How can I fix this problem in my code?

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Mon Jun  1 13:00:18 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 1 Jun 2020 13:00:18 +0200
Subject: [R] How to create a warning inside the factorial function for
 decimal numbers
In-Reply-To: <CAEPHqhYg4CBUHvG5SwgPFo2mc4csn8QQUq=0wn5vUqii1cx5CQ@mail.gmail.com>
References: <CAEPHqhYg4CBUHvG5SwgPFo2mc4csn8QQUq=0wn5vUqii1cx5CQ@mail.gmail.com>
Message-ID: <F1D4AC4F-5BCB-4544-ABA9-195958DB1C02@gmail.com>

You might check that n %% 1 == 0.

(Factorials do exist for fractional numbers -- check e.g. factorial(6.5). And please don't send HTML because, well, you can see the result below)

- pd

> On 1 Jun 2020, at 12:49 , Vahid Borji <vahid.borji65 at gmail.com> wrote:
> 
> I am writing a code for the factorial function. My code is as follows:
> 
>> f<- function(n){+ factorial <- 1+ if( n < 0 )+ print("Factorial of negative numbers is not possible")+ else if( n == 0 )+ print("Factorial of 0 is 1")+ else {+ for(i in 1:n)+ factorial <- factorial * i+ print(paste("Factorial of ",n," is ",factorial))+ }+ }
> 
> My problem with this code is for decimal numbers as input. For example for
> f(6.5) my code computes 720, but we know 6.5 ! does not exist. For decimal
> numbers like, or sqrt(2) I would like to see a message like
> 
> "The factorial for this number does not exist".
> 
> How can I fix this problem in my code?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jho|tm@n @end|ng |rom gm@||@com  Mon Jun  1 17:34:36 2020
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Mon, 1 Jun 2020 08:34:36 -0700
Subject: [R] Creating file from raw content
In-Reply-To: <MN2PR19MB3166B78FE959F876FCEA75A9928F0@MN2PR19MB3166.namprd19.prod.outlook.com>
References: <MN2PR19MB3166B78FE959F876FCEA75A9928F0@MN2PR19MB3166.namprd19.prod.outlook.com>
Message-ID: <CAAxdm-4AhSEuC+iZHbibNgz9XNZ0cqbc4uwtf5nA9zm5_278Xg@mail.gmail.com>

You can read it in as 'raw'

============
input <- file('your.xlsx', open = 'rb')  # open as binary
excel_file <- readBin(input, raw(), 1e8)  # make sure you read in all the file
close(input)

output <- file('your_new.xlsx', 'wb')
writeBin(excel_file, output)
close(output)
===================


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, May 29, 2020 at 12:12 PM Sebastien Bihorel via R-help
<r-help at r-project.org> wrote:
>
> Hi,
>
> Let's say I can extract the content of an Excel .xlsx file stored in a database and store it as raw content in an R object. What would be the proper way to "create" a .xlsx file and "transfer" the content of this obj into it? I took the example of an Excel file, but my question would extend to any kind of binary file.
>
> Thank you in advance for your input
>
> Sebastien
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Mon Jun  1 18:34:00 2020
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Mon, 1 Jun 2020 18:34:00 +0200
Subject: [R] a question of etiquette
Message-ID: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>

The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.

Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
Is there a general policy about this matter?

Adelchi Azzalini
http://azzalini.stat.unipd.it/


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jun  1 19:37:37 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 1 Jun 2020 18:37:37 +0100
Subject: [R] a question of etiquette
In-Reply-To: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
Message-ID: <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>

You might get better answers on the list dedicated to package 
development r-pkg-devel

This may have already been discussed there so a quick look at the 
archive might also help you.

On 01/06/2020 17:34, Adelchi Azzalini wrote:
> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
> 
> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
> Is there a general policy about this matter?
> 
> Adelchi Azzalini
> http://azzalini.stat.unipd.it/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @eb@@t|@n@kr@ntz @end|ng |rom gr@du@te|n@t|tute@ch  Mon Jun  1 00:33:01 2020
From: @eb@@t|@n@kr@ntz @end|ng |rom gr@du@te|n@t|tute@ch (Sebastian Martin Krantz)
Date: Mon, 1 Jun 2020 00:33:01 +0200
Subject: [R] [R-pkgs] collapse package: Advanced and Fast Data
 Transformation in R
Message-ID: <CAOsNuxCjVm+eRFnK+=7s1PuG7_Nc1UtFBAzgmpj2tgsug=kaLw@mail.gmail.com>

Dear R users, with some delay I would like to make you aware of the recent
CRAN release of *collapse* (https://CRAN.R-project.org/package=collapse), a
large new C/C++ based package for advanced and high-performance general
purpose data transformation in R.

*collapse* has 2 main objectives:

1. To facilitate complex data transformation and exploration tasks in R.
*(In particular grouped and weighted statistical computations, advanced
aggregation of mixed-type data, advanced transformations of time-series and
panel-data, and the manipulation of lists)*

2. To help make R code fast, flexible, parsimonious and programmer
friendly.
*(Providing order of magnitude performance improvements via extensive use
of C/C++ and highly optimized R code, broad object orientation and
infrastructure for grouped programming)*

*collapse*'s main innovation to service these objectives is the
introduction of a comprehensive set of fast generic functions and
transformation operators, with methods for all standard R objects written
in C++.

Currently *collapse* provides 13 fast statistical functions (`fmean`,
`fmedian`, `fmode`, `fsum`, `fprod`, `fsd`, `fvar`, `fmin`, `fmax`,
`ffirst`, `flast`, `fNobs` and `fNdistinct`) supporting grouped and
weighted computations on vectors, matrices and data.frames, and 8
specialized vector-valued functions and associated transformation operators
(`fscale/STD`, `fbetween/B`, `fwithin/W`, `fHDbetween/HDB`,
`fHDwithin/HDW`, `flag/L/F`, `fdiff/D/Dlog` and `fgrowth/G`) particularly
useful for the transformation of time-series and panel-data. Furthermore
the function `collap` painlessly handles complex aggregations of mixed-type
data, and the function `qsu` computes fast (panel-) summary statistics.

Together with these functions, *collapse* also attempts to formalize and
speed up C++ based grouped programming in R: The function `GRP` creates
grouping objects which can be passed to the `g` argument of the above
functions. This eliminates all time spent on grouping when performing
several computations over the same groups! The `TRA` function also exists
for grouped replacing and sweeping out of any computed statistics.

To round things off, *collapse* provides full sets of functions for very
fast manipulation of data.frames, fast ordering, fast factor generation,
fast conversions between common data objects, and for recursive list
processing (such as the function `unlist2d` which creates a tidy data.frame
from a nested list of heterogeneous data objects).

To enhance compatibility with existing frameworks, *collapse* functions
provide methods for *dplyr* grouped tibbles and *plm* classes for
panel-data (pseries and pdata.frame). *data.table*'s are also supported by
all functions. These methods allow for easy integration of *collapse*'s
fast functions into any of the workflows with these packages. The default
methods for transformation functions like `fscale` or `flag` can also
handle most time-series classes. In general attributes are preserved as
much as possible in all *collapse* computations.

Regarding performance: *collapse* seems to be the fastest R package for a
good share of the functionality it offers. Sizable performance gains can be
realized over packages like *dplyr* or *data.table* for various grouped
computations. The emphasis is on C++, and R code employed is carefully
micro-optimized, so a *collapse* script typically evaluates significantly
faster than, say, a *dplyr* script doing the same thing. Some benchmarks
are in the vignettes.

*collapse* also realizes an innovative approach to documentation.
Installing the package and calling `help("collapse-documentation")` brings
up a full hierarchically structured documentation. The introductory
vignette also introduces all main features in a systematic way.

At this point, *collapse* 1.2.1 is already a quite mature package with a
stable user API, passing repeated checks of R and C++ code and > 5600 unit
tests on all supported operating systems. The package will continue to
receive active maintenance and development.

I hope that the availability of *collapse* would lead not only to faster
data science, but especially to faster and richer development of complex
statistical techniques. I welcome initiatives of like-minded developers
willing to speed up grouped programming in R via C++, and encourage the use
of the *collapse* API for such endeavors. For any issues, contributions,
comments or suggestions, use github or send me an e-mail.

Best regards,

Sebastian

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jun  1 20:30:00 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 2 Jun 2020 06:30:00 +1200
Subject: [R] Query on contour plots
In-Reply-To: <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
Message-ID: <CAB8pepw=_i+wwome9t79pkUL-xHAGSoxYeeX9DnkKp7W5wqDzA@mail.gmail.com>

Hi,

I'm probably biased.

But my package, bivariate, contains a wrapper for KernSmooth::bkde2D,
which can produce both 3D surface plots and (pretty) contour plots of
bivariate kernel density estimates, conveniently.

https://cran.r-project.org/web/packages/bivariate/vignettes/bivariate.pdf
(pages 18 to 19)


On Mon, Jun 1, 2020 at 5:16 AM Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi all,
>
> While exploring  packages for 3D plots that several folks suggested (Tnx
> all!)
> It seems what I really need is a contour plot.  This is not working int
> he Deducer GUI.
>
> This will be an aid to separating bats by their vocal signatures.
> What I need to do is plot *Fc *against *Sc* with the third dimension
> being the *density* of the data points in the Fc-Sc plot.
>
> Data format is like this abbreviated sample.  Fc is a frequency in kHz
> and Sc is the characteristic slope  (octaves per second) of each call pulse.
>
> Any suggestions, guidance greatly appreciated.
> Bruce
>
> Fc      Sc
> 26.58   -5.95
> 27.03   -8.2
> 27.16   -2.07
> 26.19   -7.68
> 26.62   -3.99
> 26.85   -6.08
> 26.94   0
> 26.1    -5.74
> 26.62   -5.96
> 26.85   -4.05
> 26.98   -4.09
> 26.02   -5.69
> 26.53   -7.89
> 26.62   -2
> 26.8    -4.04
> 28.73   7
> 25.72   -2.97
> 26.14   -5.76
> 26.32   -3.89
> 26.4    0
> 26.32   5.88
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Mon Jun  1 21:17:37 2020
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Mon, 1 Jun 2020 21:17:37 +0200
Subject: [R] a question of etiquette
In-Reply-To: <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
Message-ID: <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>



> On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> You might get better answers on the list dedicated to package development r-pkg-devel

This is a good suggestion. Thanks, Michael. 

Some initial search of that list did not lead to any indication,
but I will have a second look.  

Best regards,

Adelchi

> 
> This may have already been discussed there so a quick look at the archive might also help you.
> 
> On 01/06/2020 17:34, Adelchi Azzalini wrote:
>> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
>> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
>> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
>> Is there a general policy about this matter?
>> Adelchi Azzalini
>> http://azzalini.stat.unipd.it/
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Jun  1 21:35:06 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Mon, 1 Jun 2020 19:35:06 +0000
Subject: [R] a question of etiquette
In-Reply-To: <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>,
 <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
Message-ID: <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>

Regardless of whether the people who wrote the Matlab code you used as a reference, or who wrote the paper that published the idea that you included in your package are cited as co-authors of your package, the coders and authors should be identified as the people from whom you borrowed the idea and, or, code for the package that you developed.
John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Adelchi Azzalini <azzalini at stat.unipd.it>
Sent: Monday, June 1, 2020 3:17 PM
To: Michael Dewey <lists at dewey.myzen.co.uk>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] a question of etiquette



> On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> You might get better answers on the list dedicated to package development r-pkg-devel

This is a good suggestion. Thanks, Michael.

Some initial search of that list did not lead to any indication,
but I will have a second look.

Best regards,

Adelchi

>
> This may have already been discussed there so a quick look at the archive might also help you.
>
> On 01/06/2020 17:34, Adelchi Azzalini wrote:
>> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
>> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
>> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
>> Is there a general policy about this matter?
>> Adelchi Azzalini
>> https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fazzalini.stat.unipd.it%2F&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=Q9ZyxKn3BS2K1Sg5K00bb146XiUYqa1cEfSeKzNT1E0%3D&amp;reserved=0
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
>> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=XiD8NHBiP2aEKdlyfUsEnACXVT2lzZauof9ZbtexXFI%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Michael
> https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.dewey.myzen.co.uk%2Fhome.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=T9nJx4glgaENYAL2fAfv%2FBSYXJLQB09en0oVIPRZXss%3D&amp;reserved=0

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807929745&amp;sdata=VwPw2Ue%2BTBysaEw3uWzWRRHQ2sY2TTfGU%2B8z6de8oZo%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Mon Jun  1 21:43:01 2020
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Mon, 1 Jun 2020 21:43:01 +0200
Subject: [R] a question of etiquette
In-Reply-To: <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
 <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
 <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <FF4EFEB3-FA52-4965-A1D1-2ECBF3A956A1@stat.unipd.it>



> On 1 Jun 2020, at 21:35, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> Regardless of whether the people who wrote the Matlab code you used as a reference, or who wrote the paper that published the idea that you included in your package are cited as co-authors of your package, the coders and authors should be identified as the people from whom you borrowed the idea and, or, code for the package that you developed. 
> John

I have already stated:

"The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code."

This was not a point in question.   The question was was about something additional, possibly:

"Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?"

regards
Adelchi


> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> From: R-help <r-help-bounces at r-project.org> on behalf of Adelchi Azzalini <azzalini at stat.unipd.it>
> Sent: Monday, June 1, 2020 3:17 PM
> To: Michael Dewey <lists at dewey.myzen.co.uk>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] a question of etiquette
>  
> 
> 
> > On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> > 
> > You might get better answers on the list dedicated to package development r-pkg-devel
> 
> This is a good suggestion. Thanks, Michael. 
> 
> Some initial search of that list did not lead to any indication,
> but I will have a second look.  
> 
> Best regards,
> 
> Adelchi
> 
> > 
> > This may have already been discussed there so a quick look at the archive might also help you.
> > 
> > On 01/06/2020 17:34, Adelchi Azzalini wrote:
> >> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
> >> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
> >> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
> >> Is there a general policy about this matter?
> >> Adelchi Azzalini
> >> https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fazzalini.stat.unipd.it%2F&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=Q9ZyxKn3BS2K1Sg5K00bb146XiUYqa1cEfSeKzNT1E0%3D&amp;reserved=0
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
> >> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=XiD8NHBiP2aEKdlyfUsEnACXVT2lzZauof9ZbtexXFI%3D&amp;reserved=0
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > -- 
> > Michael
> > https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.dewey.myzen.co.uk%2Fhome.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=T9nJx4glgaENYAL2fAfv%2FBSYXJLQB09en0oVIPRZXss%3D&amp;reserved=0
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807929745&amp;sdata=VwPw2Ue%2BTBysaEw3uWzWRRHQ2sY2TTfGU%2B8z6de8oZo%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun  1 21:59:22 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 01 Jun 2020 12:59:22 -0700
Subject: [R] a question of etiquette
In-Reply-To: <FF4EFEB3-FA52-4965-A1D1-2ECBF3A956A1@stat.unipd.it>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
 <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
 <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>
 <FF4EFEB3-FA52-4965-A1D1-2ECBF3A956A1@stat.unipd.it>
Message-ID: <040425FE-41A6-418F-85BD-2554E8D14106@dcn.davis.ca.us>

Please move this discussion to R-package-devel.

On June 1, 2020 12:43:01 PM PDT, Adelchi Azzalini <azzalini at stat.unipd.it> wrote:
>
>
>> On 1 Jun 2020, at 21:35, Sorkin, John <jsorkin at som.umaryland.edu>
>wrote:
>> 
>> Regardless of whether the people who wrote the Matlab code you used
>as a reference, or who wrote the paper that published the idea that you
>included in your package are cited as co-authors of your package, the
>coders and authors should be identified as the people from whom you
>borrowed the idea and, or, code for the package that you developed. 
>> John
>
>I have already stated:
>
>"The documentation of this R function indicates the authors of the
>original Matlab code, reference to their paper, URL of the source
>code."
>
>This was not a point in question.   The question was was about
>something additional, possibly:
>
>"Question: is this adequate, or should I include them as co-authors of
>the package, or as contributors, or what else?"
>
>regards
>Adelchi
>
>
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> 
>> From: R-help <r-help-bounces at r-project.org> on behalf of Adelchi
>Azzalini <azzalini at stat.unipd.it>
>> Sent: Monday, June 1, 2020 3:17 PM
>> To: Michael Dewey <lists at dewey.myzen.co.uk>
>> Cc: r-help at r-project.org <r-help at r-project.org>
>> Subject: Re: [R] a question of etiquette
>>  
>> 
>> 
>> > On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk>
>wrote:
>> > 
>> > You might get better answers on the list dedicated to package
>development r-pkg-devel
>> 
>> This is a good suggestion. Thanks, Michael. 
>> 
>> Some initial search of that list did not lead to any indication,
>> but I will have a second look.  
>> 
>> Best regards,
>> 
>> Adelchi
>> 
>> > 
>> > This may have already been discussed there so a quick look at the
>archive might also help you.
>> > 
>> > On 01/06/2020 17:34, Adelchi Azzalini wrote:
>> >> The new version of a package which I maintain will include a new
>function which I have ported to R from Matlab.
>> >> The documentation of this R function indicates the authors of the
>original Matlab code, reference to their paper, URL of the source code.
>> >> Question: is this adequate, or should I include them as co-authors
>of the package, or as contributors, or what else?
>> >> Is there a general policy about this matter?
>> >> Adelchi Azzalini
>> >>
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fazzalini.stat.unipd.it%2F&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=Q9ZyxKn3BS2K1Sg5K00bb146XiUYqa1cEfSeKzNT1E0%3D&amp;reserved=0
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>
>https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
>> >> PLEASE do read the posting guide
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=XiD8NHBiP2aEKdlyfUsEnACXVT2lzZauof9ZbtexXFI%3D&amp;reserved=0
>> >> and provide commented, minimal, self-contained, reproducible code.
>> > 
>> > -- 
>> > Michael
>> >
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.dewey.myzen.co.uk%2Fhome.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=T9nJx4glgaENYAL2fAfv%2FBSYXJLQB09en0oVIPRZXss%3D&amp;reserved=0
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
>> PLEASE do read the posting guide
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807929745&amp;sdata=VwPw2Ue%2BTBysaEw3uWzWRRHQ2sY2TTfGU%2B8z6de8oZo%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 22:37:54 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 15:37:54 -0500
Subject: [R] how to load data frame where numeric will be numeric instead of
 character
Message-ID: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>

Hello,

I have a dataframe like this:

  Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
...

which I load with:
NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE)

and every column is numeric. How to say have all numeric ones stay numeric
like: Chr, BP, MAF, pValue, N

Thanks
Ana

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  1 22:46:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 1 Jun 2020 13:46:13 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
Message-ID: <CAGxFJbQKsBo+MOCz2yXXBoBWFmPB=0xj0Kae74eGRYu6JGVZoA@mail.gmail.com>

I count 8 fields in your data and 9 names in your heading ??


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 1, 2020 at 1:38 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a dataframe like this:
>
>   Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
> 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
> 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
> ...
>
> which I load with:
> NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE)
>
> and every column is numeric. How to say have all numeric ones stay numeric
> like: Chr, BP, MAF, pValue, N
>
> Thanks
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 22:50:12 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 15:50:12 -0500
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAGxFJbQKsBo+MOCz2yXXBoBWFmPB=0xj0Kae74eGRYu6JGVZoA@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <CAGxFJbQKsBo+MOCz2yXXBoBWFmPB=0xj0Kae74eGRYu6JGVZoA@mail.gmail.com>
Message-ID: <CAF9-5jMCb5zppELZQh8-65HT+r90sMQvcztX861JiQAohrq3LQ@mail.gmail.com>

7th fileld, Direction contains only "+" and "-"


On Mon, Jun 1, 2020 at 3:46 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I count 8 fields in your data and 9 names in your heading ??
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 1, 2020 at 1:38 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hello,
>>
>> I have a dataframe like this:
>>
>>   Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
>> 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
>> 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
>> ...
>>
>> which I load with:
>> NEU <- read.table("gokind.neuropathy.fin",
>> header=T,stringsAsFactors=FALSE)
>>
>> and every column is numeric. How to say have all numeric ones stay numeric
>> like: Chr, BP, MAF, pValue, N
>>
>> Thanks
>> Ana
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jun  1 23:13:27 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 1 Jun 2020 14:13:27 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
Message-ID: <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>


On 6/1/20 1:37 PM, Ana Marija wrote:
> Hello,
>
> I have a dataframe like this:
>
>    Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
> 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
> 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
> ...
>
> which I load with:
> NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE)
>
> and every column is numeric. How to say have all numeric ones stay numeric
> like: Chr, BP, MAF, pValue, N


I cannot figure out what the problem is. You say every column is 
numeric. It's not possible to have a column that contains the value 
"10:100000625:A:G" be numeric.


If you meant to say the every column was character, then the answer 
might be:


colClassvec <- rep("numeric",9)
colClassvec[ c(3,5:7)] <- "character"

NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE, colClasses=colClassvec)

-- 
David.

>
> Thanks
> Ana
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 23:17:46 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 16:17:46 -0500
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
Message-ID: <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>

HI David,

this is the problem:

> NEP <- read.table("gokind.nephropathy.fin",
header=T,stringsAsFactors=FALSE)
> sapply(NEP,class)
        Chr          BP      Marker         MAF          A1          A2
"character" "character" "character" "character" "character" "character"
  Direction      pValue           N

So even entries like Chr, BP, MAF....are characters while they should be
numeric
> head(NEP)
  Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
1  10 100000625 10:100000625:A:G   0.4156  G  A         + 0.484813 1641
2  10 100000645 10:100000645:A:C 0.216027  C  A         +  0.73597 1641


Can you please tell me what colClasses=colClassvec suppose to do?

Thanks
Ana

On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 6/1/20 1:37 PM, Ana Marija wrote:
> > Hello,
> >
> > I have a dataframe like this:
> >
> >    Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
> > 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
> > 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
> > ...
> >
> > which I load with:
> > NEU <- read.table("gokind.neuropathy.fin",
> header=T,stringsAsFactors=FALSE)
> >
> > and every column is numeric. How to say have all numeric ones stay
> numeric
> > like: Chr, BP, MAF, pValue, N
>
>
> I cannot figure out what the problem is. You say every column is
> numeric. It's not possible to have a column that contains the value
> "10:100000625:A:G" be numeric.
>
>
> If you meant to say the every column was character, then the answer
> might be:
>
>
> colClassvec <- rep("numeric",9)
> colClassvec[ c(3,5:7)] <- "character"
>
> NEU <- read.table("gokind.neuropathy.fin",
> header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
>
> --
> David.
>
> >
> > Thanks
> > Ana
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 23:50:09 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 16:50:09 -0500
Subject: [R] is there is a way to extract lines in between 3 files that are
 in common based on one column?
Message-ID: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>

Hello,

I have 3 data frames which have about 3.4 mill lines (but they don't have
exactly the same number of lines)...they look like this:

> neu1=neu[order(neu$Marker),]
> head(neu1)
       Chr        BP          Marker      MAF A1 A2 Direction   pValue    N
209565   1 100000012 1:100000012:G:T 0.229925  T  G         + 0.650403 1594
209566   1 100000827 1:100000827:C:T 0.287014  T  C         + 0.955449 1594
209567   1 100002713 1:100002713:C:T 0.097867  T  C         - 0.290455 1594
209568   1 100002882 1:100002882:T:G 0.287014  G  T         + 0.955449 1594
209569   1 100002991 1:100002991:G:A 0.097867  A  G         - 0.290455 1594
209570   1 100004726 1:100004726:G:A 0.132058  A  G         + 0.115005 1594
> nep1=nep[order(nep$Marker),]
> head(nep1)
       Chr        BP          Marker       MAF A1 A2 Direction    pValue
 N
209642   1 100000012 1:100000012:G:T 0.2300430  T  G         - 0.1420030
1641
209643   1 100000827 1:100000827:C:T 0.2867150  T  C         - 0.2045580
1641
209644   1 100002713 1:100002713:C:T 0.0975015  T  C         - 0.0555507
1641
209645   1 100002882 1:100002882:T:G 0.2867150  G  T         - 0.2045580
1641
209646   1 100002991 1:100002991:G:A 0.0975015  A  G         - 0.0555507
1641
209647   1 100004726 1:100004726:G:A 0.1325410  A  G         - 0.8725660
1641
> ret1=ret[order(ret$Marker),]
> head(ret1)
        Chr        BP          Marker       MAF A1 A2 Direction   pValue
 N
865453    1 100000012 1:100000012:G:T 0.2322760  T  G         - 0.230383
1608
451596    1 100000827 1:100000827:C:T 0.2882460  T  C         - 0.120356
1608
1026046   1 100002713 1:100002713:C:T 0.0982587  T  C         - 0.272936
1608
451597    1 100002882 1:100002882:T:G 0.2882460  G  T         - 0.120356
1608
1026047   1 100002991 1:100002991:G:A 0.0982587  A  G         - 0.272936
1608
2234642   1 100004726 1:100004726:G:A 0.1340170  A  G         - 0.594538
1608

Is there is a way to create another 3 data frames, say neu2, nep2, ret2
which would only contain lines that have the same entries in Marker column
for all 3 data frames?

Thanks
Ana

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jun  2 00:19:37 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 1 Jun 2020 15:19:37 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
 <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
Message-ID: <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>


On 6/1/20 2:17 PM, Ana Marija wrote:
> HI David,
>
> this is the problem:
>
> > NEP <- read.table("gokind.nephropathy.fin", 
> header=T,stringsAsFactors=FALSE)
> > sapply(NEP,class)
> ? ? ? ? Chr ? ? ? ? ?BP ? ? ?Marker ? ? ? ? MAF ? ? ? ? ?A1 ? ? ? ?A2
> "character" "character" "character" "character" "character" "character"
> ? Direction ? ? ?pValue ? ? ? ? ? N
>
> So even entries like Chr, BP, MAF....are characters while they should 
> be numeric
> > head(NEP)
> ? Chr ? ? ? ?BP ? ? ? ? ? Marker ? ? ?MAF A1 A2 Direction pValue ? ?N
> 1 ?10 100000625 10:100000625:A:G ? 0.4156 ?G ?A ? ? ? ? + 0.484813 1641
> 2 ?10 100000645 10:100000645:A:C 0.216027 ?C ?A ? ? ? ? + ?0.73597 1641
>
>
> Can you please tell me what colClasses=colClassvec suppose to do?


I could tell you, but I think instead that you should read the 
documentation for the `read.table` function.


-- 

David

>
> Thanks
> Ana
>
> On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net 
> <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     On 6/1/20 1:37 PM, Ana Marija wrote:
>     > Hello,
>     >
>     > I have a dataframe like this:
>     >
>     >? ? Chr? ? ? ? BP? ? ? ? ? ?Marker? ? ? MAF A1 A2 Direction?
>     ?pValue? ? N
>     > 1? 10 100000625 10:100000625:A:G 0.416562? G? A? ? ? ? ?-
>     0.558228 1594
>     > 2? 10 100000645 10:100000645:A:C 0.215182? C? A? ? ? ? ?-
>     0.880622 1594
>     > ...
>     >
>     > which I load with:
>     > NEU <- read.table("gokind.neuropathy.fin",
>     header=T,stringsAsFactors=FALSE)
>     >
>     > and every column is numeric. How to say have all numeric ones
>     stay numeric
>     > like: Chr, BP, MAF, pValue, N
>
>
>     I cannot figure out what the problem is. You say every column is
>     numeric. It's not possible to have a column that contains the value
>     "10:100000625:A:G" be numeric.
>
>
>     If you meant to say the every column was character, then the answer
>     might be:
>
>
>     colClassvec <- rep("numeric",9)
>     colClassvec[ c(3,5:7)] <- "character"
>
>     NEU <- read.table("gokind.neuropathy.fin",
>     header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
>
>     -- 
>     David.
>
>     >
>     > Thanks
>     > Ana
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 00:50:19 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 08:50:19 +1000
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepw=_i+wwome9t79pkUL-xHAGSoxYeeX9DnkKp7W5wqDzA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepw=_i+wwome9t79pkUL-xHAGSoxYeeX9DnkKp7W5wqDzA@mail.gmail.com>
Message-ID: <CA+8X3fVyUaEFss0o08MZ1DyBN29Xw_8_CPkpamdHmdWT45sNFg@mail.gmail.com>

Good morning Bruce & Abby,
The fruit bats of Sydney have retreated to their camps so I can
finally answer your last two queries. Attached is a plot of your data
set on a 100 x 100 grid. This is how I did it:

bfs<-read.csv("Procen_sample.csv")
dim(bfs)
names(bfs)
library(plotrix)
# set the matrix limits a bit beyond the data ranges
fcsc_mat<-makeDensityMatrix(bfs$Fc,bfs$Sc,nx=100,ny=100,
 zfun="sum",xlim=c(24,29),ylim=c(-20,10))
png("bat_call.png")
par(mar=c(6,4,4,2))
color2D.matplot(fcsc_mat,
 main="Freqency by chirp slope of bat calls",
 extremes=c("yellow","red"),xlab="Frequency (kHz)",
 ylab="Characteristic slope (octaves/s)",
 border=NA,axes=FALSE)
axis(1,at=seq(5,95,10),round(seq(24.5,28.5,length.out=10),1))
axis(2,at=seq(5,95,10),round(seq(-20,10,length.out=10),1))
color.legend(0,-14,25,-10,legend=seq(0,10,length.out=5),
 rect.col=color.scale(0:4,extremes=c("yellow","red")),align="rb")
text(12.5,-20,"Density (cell count)",xpd=TRUE)
dev.off()

Abby's bivariate package looks like it will do some things that
color2D.matplot won't. However, I haven't had time to install it and
try it out, so I don't know whether it will be as easy to plug
different calls onto the same grid. Also, there appears to be
constraints on the frequency and slope in the calls and I don't know
enough about them to say why. Further tweaking may lead to better
solutions.

Jim

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bat_call.png
Type: image/png
Size: 18612 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200602/af0030c1/attachment.png>

From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun  2 01:35:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 1 Jun 2020 16:35:33 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
 <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
 <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>
Message-ID: <CAGxFJbSCKq07sUX=hNegQM1Qf=w5BU6MvgEf_ngoaOevkAd6kQ@mail.gmail.com>

Agreed!

However, there may still be a problem, as read.table() ordinarily would
read numeric columns correctly (via type.convert()) without the colClasses
specification.
So I would suspect that her "numeric" columns contain some non-numeric
detritus (perhaps "," or some NA symbol). But of course, who knows? -- and
she should follow David's advice to read the docs anyway.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 1, 2020 at 3:19 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 6/1/20 2:17 PM, Ana Marija wrote:
> > HI David,
> >
> > this is the problem:
> >
> > > NEP <- read.table("gokind.nephropathy.fin",
> > header=T,stringsAsFactors=FALSE)
> > > sapply(NEP,class)
> >         Chr          BP      Marker         MAF          A1        A2
> > "character" "character" "character" "character" "character" "character"
> >   Direction      pValue           N
> >
> > So even entries like Chr, BP, MAF....are characters while they should
> > be numeric
> > > head(NEP)
> >   Chr        BP           Marker      MAF A1 A2 Direction pValue    N
> > 1  10 100000625 10:100000625:A:G   0.4156  G  A         + 0.484813 1641
> > 2  10 100000645 10:100000645:A:C 0.216027  C  A         +  0.73597 1641
> >
> >
> > Can you please tell me what colClasses=colClassvec suppose to do?
>
>
> I could tell you, but I think instead that you should read the
> documentation for the `read.table` function.
>
>
> --
>
> David
>
> >
> > Thanks
> > Ana
> >
> > On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net
> > <mailto:dwinsemius at comcast.net>> wrote:
> >
> >
> >     On 6/1/20 1:37 PM, Ana Marija wrote:
> >     > Hello,
> >     >
> >     > I have a dataframe like this:
> >     >
> >     >    Chr        BP           Marker      MAF A1 A2 Direction
> >      pValue    N
> >     > 1  10 100000625 10:100000625:A:G 0.416562  G  A         -
> >     0.558228 1594
> >     > 2  10 100000645 10:100000645:A:C 0.215182  C  A         -
> >     0.880622 1594
> >     > ...
> >     >
> >     > which I load with:
> >     > NEU <- read.table("gokind.neuropathy.fin",
> >     header=T,stringsAsFactors=FALSE)
> >     >
> >     > and every column is numeric. How to say have all numeric ones
> >     stay numeric
> >     > like: Chr, BP, MAF, pValue, N
> >
> >
> >     I cannot figure out what the problem is. You say every column is
> >     numeric. It's not possible to have a column that contains the value
> >     "10:100000625:A:G" be numeric.
> >
> >
> >     If you meant to say the every column was character, then the answer
> >     might be:
> >
> >
> >     colClassvec <- rep("numeric",9)
> >     colClassvec[ c(3,5:7)] <- "character"
> >
> >     NEU <- read.table("gokind.neuropathy.fin",
> >     header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
> >
> >     --
> >     David.
> >
> >     >
> >     > Thanks
> >     > Ana
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 02:31:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 10:31:11 +1000
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
Message-ID: <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>

Hi Ana,
Not too hard, but your example has all the "marker" fields in common.
So using a sample that will show the expected result:

neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
 1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
 1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
 1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
 1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
 1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
 1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
 header=TRUE,stringsAsFactors=FALSE)

nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
 1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
 1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
 1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
 1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
 1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
 1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
 header=TRUE,stringsAsFactors=FALSE)

ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
 1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
 1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
 1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
 1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
 1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
 1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
header=TRUE,stringsAsFactors=FALSE)

# merge the three data frames on "Marker"
nn1<-merge(neu1,nep1,by="Marker")
nn2<-merge(nn1,ret1,by="Marker")
# get the common "Marker" strings
Marker3<-nn2$Marker
# subset all three data frames on Marker3
neu2<-neu1[neu1$Marker %in% Marker3,]
nep2<-nep1[nep1$Marker %in% Marker3,]
ret2<-ret1[ret1$Marker %in% Marker3,]

Jim

On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have 3 data frames which have about 3.4 mill lines (but they don't have
> exactly the same number of lines)...they look like this:
> ...
> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> which would only contain lines that have the same entries in Marker column
> for all 3 data frames?
>
> Thanks
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 02:40:32 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 19:40:32 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
Message-ID: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>

Hi Jim,

thank you so much for getting back to me. I tried your code and this is
what I get:
> dim(neu2)
[1] 3740988       9
> dim(nep2)
[1] 3740988       9
> dim(ret2)
[1] 3740001       9

I think I would need to have the same number of lines in all 3 data frames.

Can you please advise.

Cheers
Ana

On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ana,
> Not too hard, but your example has all the "marker" fields in common.
> So using a sample that will show the expected result:
>
> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
>  1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
>  1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
>  1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
>  1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
>  1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
>  1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
>  header=TRUE,stringsAsFactors=FALSE)
>
> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
>  1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
>  1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
>  1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
>  1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
>  1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
>  1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
>  header=TRUE,stringsAsFactors=FALSE)
>
> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
>  1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
>  1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
>  1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
>  1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
>  1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
>  1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> header=TRUE,stringsAsFactors=FALSE)
>
> # merge the three data frames on "Marker"
> nn1<-merge(neu1,nep1,by="Marker")
> nn2<-merge(nn1,ret1,by="Marker")
> # get the common "Marker" strings
> Marker3<-nn2$Marker
> # subset all three data frames on Marker3
> neu2<-neu1[neu1$Marker %in% Marker3,]
> nep2<-nep1[nep1$Marker %in% Marker3,]
> ret2<-ret1[ret1$Marker %in% Marker3,]
>
> Jim
>
> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >
> > Hello,
> >
> > I have 3 data frames which have about 3.4 mill lines (but they don't have
> > exactly the same number of lines)...they look like this:
> > ...
> > Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > which would only contain lines that have the same entries in Marker
> column
> > for all 3 data frames?
> >
> > Thanks
> > Ana
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Tue Jun  2 03:34:31 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 2 Jun 2020 03:34:31 +0200
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
Message-ID: <20200602013431.GA1315@posteo.no>

Dear Ana and Jim,

On 2020-06-01 19:40 -0500, Ana Marija wrote:
> > dim(neu2)
> [1] 3740988       9
> > dim(nep2)
> [1] 3740988       9
> > dim(ret2)
> [1] 3740001       9

Jim's code works out of the box directly from 
the email ... I get:

[1] 6 9
[1] 4 9
[1] 4 9

On 2020-06-01 19:40 -0500, Ana Marija wrote:
> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija wrote:
> > 
> > but they don't have exactly the same 
> > number of lines
> 
> I think I would need to have the same 
> number of lines in all 3 data frames.

This does not make sense :?-\

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200602/b154d574/attachment.sig>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jun  2 03:41:45 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 1 Jun 2020 18:41:45 -0700
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
Message-ID: <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>


On 6/1/20 5:40 PM, Ana Marija wrote:
> Hi Jim,
>
> thank you so much for getting back to me. I tried your code and this is
> what I get:
>> dim(neu2)
> [1] 3740988       9
>> dim(nep2)
> [1] 3740988       9
>> dim(ret2)
> [1] 3740001       9
>
> I think I would need to have the same number of lines in all 3 data frames.
>
> Can you please advise.


You should check for duplicated Marker values.


-- 

David

>
> Cheers
> Ana
>
> On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Ana,
>> Not too hard, but your example has all the "marker" fields in common.
>> So using a sample that will show the expected result:
>>
>> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
>>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
>>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
>>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
>>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
>>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
>>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
>>   header=TRUE,stringsAsFactors=FALSE)
>>
>> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
>>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
>>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
>>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
>>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
>>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
>>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
>>   header=TRUE,stringsAsFactors=FALSE)
>>
>> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
>>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
>>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
>>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
>>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
>>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
>>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
>> header=TRUE,stringsAsFactors=FALSE)
>>
>> # merge the three data frames on "Marker"
>> nn1<-merge(neu1,nep1,by="Marker")
>> nn2<-merge(nn1,ret1,by="Marker")
>> # get the common "Marker" strings
>> Marker3<-nn2$Marker
>> # subset all three data frames on Marker3
>> neu2<-neu1[neu1$Marker %in% Marker3,]
>> nep2<-nep1[nep1$Marker %in% Marker3,]
>> ret2<-ret1[ret1$Marker %in% Marker3,]
>>
>> Jim
>>
>> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>> Hello,
>>>
>>> I have 3 data frames which have about 3.4 mill lines (but they don't have
>>> exactly the same number of lines)...they look like this:
>>> ...
>>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
>>> which would only contain lines that have the same entries in Marker
>> column
>>> for all 3 data frames?
>>>
>>> Thanks
>>> Ana
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 03:48:30 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 11:48:30 +1000
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
Message-ID: <CA+8X3fWnJr0MFEnR83RyFKpHP3=SvGPg-5o8R1cSvSNG+UvS6Q@mail.gmail.com>

Hi Ana,
If I add another 6 rows to neu1, 2 to nep1 and one to ret1 and modify
the "Marker" field so that there is one more match, I get the result I
expect. I think that the program logic is correct. I can't say why
ret1 has fewer lines. If there aren't too many mismatches, maybe
checking the mismatches will help:

neu3<-neu1[!(neu1$Marker %in% Marker3),]
nep3<-nep1[!(nep1$Marker %in% Marker3),]
ret3<-ret1[!(ret1$Marker %in% Marker3),]
neu3
nep3
ret3

Jim

On Tue, Jun 2, 2020 at 10:40 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim,
>
> thank you so much for getting back to me. I tried your code and this is what I get:
> > dim(neu2)
> [1] 3740988       9
> > dim(nep2)
> [1] 3740988       9
> > dim(ret2)
> [1] 3740001       9
>
> I think I would need to have the same number of lines in all 3 data frames.
>
> Can you please advise.
>
> Cheers
> Ana
>
> On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Ana,
>> Not too hard, but your example has all the "marker" fields in common.
>> So using a sample that will show the expected result:
>>
>> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
>>  1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
>>  1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
>>  1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
>>  1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
>>  1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
>>  1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
>>  header=TRUE,stringsAsFactors=FALSE)
>>
>> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
>>  1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
>>  1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
>>  1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
>>  1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
>>  1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
>>  1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
>>  header=TRUE,stringsAsFactors=FALSE)
>>
>> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
>>  1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
>>  1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
>>  1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
>>  1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
>>  1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
>>  1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
>> header=TRUE,stringsAsFactors=FALSE)
>>
>> # merge the three data frames on "Marker"
>> nn1<-merge(neu1,nep1,by="Marker")
>> nn2<-merge(nn1,ret1,by="Marker")
>> # get the common "Marker" strings
>> Marker3<-nn2$Marker
>> # subset all three data frames on Marker3
>> neu2<-neu1[neu1$Marker %in% Marker3,]
>> nep2<-nep1[nep1$Marker %in% Marker3,]
>> ret2<-ret1[ret1$Marker %in% Marker3,]
>>
>> Jim
>>
>> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> > I have 3 data frames which have about 3.4 mill lines (but they don't have
>> > exactly the same number of lines)...they look like this:
>> > ...
>> > Is there is a way to create another 3 data frames, say neu2, nep2, ret2
>> > which would only contain lines that have the same entries in Marker column
>> > for all 3 data frames?
>> >
>> > Thanks
>> > Ana
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 03:50:09 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 20:50:09 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
Message-ID: <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>

Hi David,

that is a great point!
Yes indeed some are non unique:

> dim(neu1)
[1] 3742845       9
> length(unique(neu1$Marker))
[1] 3741858
> length(unique(nep1$Marker))
[1] 3745560
> dim(nep1)
[1] 3746550       9
> length(unique(ret1$Marker))
[1] 3743494
> dim(ret1)
[1] 3743494       9

How would I rewrite this code so that is merging by Chr and Marker
column? It seems that a Marker can be under a few Chr.





On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> On 6/1/20 5:40 PM, Ana Marija wrote:
> > Hi Jim,
> >
> > thank you so much for getting back to me. I tried your code and this is
> > what I get:
> >> dim(neu2)
> > [1] 3740988       9
> >> dim(nep2)
> > [1] 3740988       9
> >> dim(ret2)
> > [1] 3740001       9
> >
> > I think I would need to have the same number of lines in all 3 data frames.
> >
> > Can you please advise.
>
>
> You should check for duplicated Marker values.
>
>
> --
>
> David
>
> >
> > Cheers
> > Ana
> >
> > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Ana,
> >> Not too hard, but your example has all the "marker" fields in common.
> >> So using a sample that will show the expected result:
> >>
> >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> >>   header=TRUE,stringsAsFactors=FALSE)
> >>
> >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> >>   header=TRUE,stringsAsFactors=FALSE)
> >>
> >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> >> header=TRUE,stringsAsFactors=FALSE)
> >>
> >> # merge the three data frames on "Marker"
> >> nn1<-merge(neu1,nep1,by="Marker")
> >> nn2<-merge(nn1,ret1,by="Marker")
> >> # get the common "Marker" strings
> >> Marker3<-nn2$Marker
> >> # subset all three data frames on Marker3
> >> neu2<-neu1[neu1$Marker %in% Marker3,]
> >> nep2<-nep1[nep1$Marker %in% Marker3,]
> >> ret2<-ret1[ret1$Marker %in% Marker3,]
> >>
> >> Jim
> >>
> >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> >> wrote:
> >>> Hello,
> >>>
> >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> >>> exactly the same number of lines)...they look like this:
> >>> ...
> >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> >>> which would only contain lines that have the same entries in Marker
> >> column
> >>> for all 3 data frames?
> >>>
> >>> Thanks
> >>> Ana
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 03:54:52 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 20:54:52 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
 <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
Message-ID: <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>

Hi Jim

> neu3<-neu1[!(neu1$Marker %in% Marker3),]
> dim(neu3)
[1] 1857    9
> nep3<-nep1[!(nep1$Marker %in% Marker3),]
> dim(nep3)
[1] 5562    9
> ret3<-ret1[!(ret1$Marker %in% Marker3),]
> dim(ret3)
[1] 3493    9


If I do:

 nn1<-merge(neu1,nep1,by=c("Marker","Chr"))
nn2<-merge(nn1,ret1,by=c("Marker","Chr"))
> Marker3<-nn2$Marker
> length(Marker3)
[1] 3742962
> Marker4<-nn1$Marker
> length(Marker4)
[1] 3744443

On Mon, Jun 1, 2020 at 8:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi David,
>
> that is a great point!
> Yes indeed some are non unique:
>
> > dim(neu1)
> [1] 3742845       9
> > length(unique(neu1$Marker))
> [1] 3741858
> > length(unique(nep1$Marker))
> [1] 3745560
> > dim(nep1)
> [1] 3746550       9
> > length(unique(ret1$Marker))
> [1] 3743494
> > dim(ret1)
> [1] 3743494       9
>
> How would I rewrite this code so that is merging by Chr and Marker
> column? It seems that a Marker can be under a few Chr.
>
>
>
>
>
> On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
> >
> >
> > On 6/1/20 5:40 PM, Ana Marija wrote:
> > > Hi Jim,
> > >
> > > thank you so much for getting back to me. I tried your code and this is
> > > what I get:
> > >> dim(neu2)
> > > [1] 3740988       9
> > >> dim(nep2)
> > > [1] 3740988       9
> > >> dim(ret2)
> > > [1] 3740001       9
> > >
> > > I think I would need to have the same number of lines in all 3 data frames.
> > >
> > > Can you please advise.
> >
> >
> > You should check for duplicated Marker values.
> >
> >
> > --
> >
> > David
> >
> > >
> > > Cheers
> > > Ana
> > >
> > > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > >> Hi Ana,
> > >> Not too hard, but your example has all the "marker" fields in common.
> > >> So using a sample that will show the expected result:
> > >>
> > >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> > >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> > >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> > >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> > >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> > >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> > >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> > >>   header=TRUE,stringsAsFactors=FALSE)
> > >>
> > >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> > >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> > >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> > >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> > >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> > >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> > >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> > >>   header=TRUE,stringsAsFactors=FALSE)
> > >>
> > >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> > >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> > >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> > >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> > >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> > >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> > >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> > >> header=TRUE,stringsAsFactors=FALSE)
> > >>
> > >> # merge the three data frames on "Marker"
> > >> nn1<-merge(neu1,nep1,by="Marker")
> > >> nn2<-merge(nn1,ret1,by="Marker")
> > >> # get the common "Marker" strings
> > >> Marker3<-nn2$Marker
> > >> # subset all three data frames on Marker3
> > >> neu2<-neu1[neu1$Marker %in% Marker3,]
> > >> nep2<-nep1[nep1$Marker %in% Marker3,]
> > >> ret2<-ret1[ret1$Marker %in% Marker3,]
> > >>
> > >> Jim
> > >>
> > >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> > >> wrote:
> > >>> Hello,
> > >>>
> > >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> > >>> exactly the same number of lines)...they look like this:
> > >>> ...
> > >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > >>> which would only contain lines that have the same entries in Marker
> > >> column
> > >>> for all 3 data frames?
> > >>>
> > >>> Thanks
> > >>> Ana
> > >>>
> > >>>          [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 05:04:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 13:04:11 +1000
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
 <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
 <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>
Message-ID: <CA+8X3fVegAWfMGjvV-0eZe4uMu9NMcDe2DZz10=CFz+BUuNm4Q@mail.gmail.com>

So recombination sticks out its foot before us. Do you want to account
for gene linkage?

JIm

On Tue, Jun 2, 2020 at 11:55 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim
>
> > neu3<-neu1[!(neu1$Marker %in% Marker3),]
> > dim(neu3)
> [1] 1857    9
> > nep3<-nep1[!(nep1$Marker %in% Marker3),]
> > dim(nep3)
> [1] 5562    9
> > ret3<-ret1[!(ret1$Marker %in% Marker3),]
> > dim(ret3)
> [1] 3493    9
>
>
> If I do:
>
>  nn1<-merge(neu1,nep1,by=c("Marker","Chr"))
> nn2<-merge(nn1,ret1,by=c("Marker","Chr"))
> > Marker3<-nn2$Marker
> > length(Marker3)
> [1] 3742962
> > Marker4<-nn1$Marker
> > length(Marker4)
> [1] 3744443
>
> On Mon, Jun 1, 2020 at 8:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi David,
> >
> > that is a great point!
> > Yes indeed some are non unique:
> >
> > > dim(neu1)
> > [1] 3742845       9
> > > length(unique(neu1$Marker))
> > [1] 3741858
> > > length(unique(nep1$Marker))
> > [1] 3745560
> > > dim(nep1)
> > [1] 3746550       9
> > > length(unique(ret1$Marker))
> > [1] 3743494
> > > dim(ret1)
> > [1] 3743494       9
> >
> > How would I rewrite this code so that is merging by Chr and Marker
> > column? It seems that a Marker can be under a few Chr.
> >
> >
> >
> >
> >
> > On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
> > >
> > >
> > > On 6/1/20 5:40 PM, Ana Marija wrote:
> > > > Hi Jim,
> > > >
> > > > thank you so much for getting back to me. I tried your code and this is
> > > > what I get:
> > > >> dim(neu2)
> > > > [1] 3740988       9
> > > >> dim(nep2)
> > > > [1] 3740988       9
> > > >> dim(ret2)
> > > > [1] 3740001       9
> > > >
> > > > I think I would need to have the same number of lines in all 3 data frames.
> > > >
> > > > Can you please advise.
> > >
> > >
> > > You should check for duplicated Marker values.
> > >
> > >
> > > --
> > >
> > > David
> > >
> > > >
> > > > Cheers
> > > > Ana
> > > >
> > > > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > >> Hi Ana,
> > > >> Not too hard, but your example has all the "marker" fields in common.
> > > >> So using a sample that will show the expected result:
> > > >>
> > > >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> > > >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> > > >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> > > >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> > > >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> > > >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> > > >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > >>
> > > >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> > > >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> > > >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> > > >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> > > >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> > > >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> > > >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > >>
> > > >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> > > >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> > > >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> > > >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> > > >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> > > >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> > > >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> > > >> header=TRUE,stringsAsFactors=FALSE)
> > > >>
> > > >> # merge the three data frames on "Marker"
> > > >> nn1<-merge(neu1,nep1,by="Marker")
> > > >> nn2<-merge(nn1,ret1,by="Marker")
> > > >> # get the common "Marker" strings
> > > >> Marker3<-nn2$Marker
> > > >> # subset all three data frames on Marker3
> > > >> neu2<-neu1[neu1$Marker %in% Marker3,]
> > > >> nep2<-nep1[nep1$Marker %in% Marker3,]
> > > >> ret2<-ret1[ret1$Marker %in% Marker3,]
> > > >>
> > > >> Jim
> > > >>
> > > >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> > > >> wrote:
> > > >>> Hello,
> > > >>>
> > > >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> > > >>> exactly the same number of lines)...they look like this:
> > > >>> ...
> > > >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > > >>> which would only contain lines that have the same entries in Marker
> > > >> column
> > > >>> for all 3 data frames?
> > > >>>
> > > >>> Thanks
> > > >>> Ana
> > > >>>
> > > >>>          [[alternative HTML version deleted]]
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>> PLEASE do read the posting guide
> > > >> http://www.R-project.org/posting-guide.html
> > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From dc@r|@on @end|ng |rom t@mu@edu  Tue Jun  2 05:21:32 2020
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Mon, 1 Jun 2020 22:21:32 -0500
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAGxFJbSCKq07sUX=hNegQM1Qf=w5BU6MvgEf_ngoaOevkAd6kQ@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
 <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
 <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>
 <CAGxFJbSCKq07sUX=hNegQM1Qf=w5BU6MvgEf_ngoaOevkAd6kQ@mail.gmail.com>
Message-ID: <CAE-dL2quEhS4Xe0fMbrxJ0oZu5DH+MAyrB+Oyv2D0ebhdGFb+w@mail.gmail.com>

It might be easier to diagnose if you can show us what the first ten lines
in your original file look like.

readLines("gokind.nephropathy.fin", n=10)

David L Carlson


On Mon, Jun 1, 2020 at 6:36 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Agreed!
>
> However, there may still be a problem, as read.table() ordinarily would
> read numeric columns correctly (via type.convert()) without the colClasses
> specification.
> So I would suspect that her "numeric" columns contain some non-numeric
> detritus (perhaps "," or some NA symbol). But of course, who knows? -- and
> she should follow David's advice to read the docs anyway.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 1, 2020 at 3:19 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
> >
> > On 6/1/20 2:17 PM, Ana Marija wrote:
> > > HI David,
> > >
> > > this is the problem:
> > >
> > > > NEP <- read.table("gokind.nephropathy.fin",
> > > header=T,stringsAsFactors=FALSE)
> > > > sapply(NEP,class)
> > >         Chr          BP      Marker         MAF          A1        A2
> > > "character" "character" "character" "character" "character" "character"
> > >   Direction      pValue           N
> > >
> > > So even entries like Chr, BP, MAF....are characters while they should
> > > be numeric
> > > > head(NEP)
> > >   Chr        BP           Marker      MAF A1 A2 Direction pValue    N
> > > 1  10 100000625 10:100000625:A:G   0.4156  G  A         + 0.484813 1641
> > > 2  10 100000645 10:100000645:A:C 0.216027  C  A         +  0.73597 1641
> > >
> > >
> > > Can you please tell me what colClasses=colClassvec suppose to do?
> >
> >
> > I could tell you, but I think instead that you should read the
> > documentation for the `read.table` function.
> >
> >
> > --
> >
> > David
> >
> > >
> > > Thanks
> > > Ana
> > >
> > > On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net
> > > <mailto:dwinsemius at comcast.net>> wrote:
> > >
> > >
> > >     On 6/1/20 1:37 PM, Ana Marija wrote:
> > >     > Hello,
> > >     >
> > >     > I have a dataframe like this:
> > >     >
> > >     >    Chr        BP           Marker      MAF A1 A2 Direction
> > >      pValue    N
> > >     > 1  10 100000625 10:100000625:A:G 0.416562  G  A         -
> > >     0.558228 1594
> > >     > 2  10 100000645 10:100000645:A:C 0.215182  C  A         -
> > >     0.880622 1594
> > >     > ...
> > >     >
> > >     > which I load with:
> > >     > NEU <- read.table("gokind.neuropathy.fin",
> > >     header=T,stringsAsFactors=FALSE)
> > >     >
> > >     > and every column is numeric. How to say have all numeric ones
> > >     stay numeric
> > >     > like: Chr, BP, MAF, pValue, N
> > >
> > >
> > >     I cannot figure out what the problem is. You say every column is
> > >     numeric. It's not possible to have a column that contains the value
> > >     "10:100000625:A:G" be numeric.
> > >
> > >
> > >     If you meant to say the every column was character, then the answer
> > >     might be:
> > >
> > >
> > >     colClassvec <- rep("numeric",9)
> > >     colClassvec[ c(3,5:7)] <- "character"
> > >
> > >     NEU <- read.table("gokind.neuropathy.fin",
> > >     header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
> > >
> > >     --
> > >     David.
> > >
> > >     >
> > >     > Thanks
> > >     > Ana
> > >     >
> > >     >       [[alternative HTML version deleted]]
> > >     >
> > >     > ______________________________________________
> > >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >     >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj2eq-EE8$
> > >     > PLEASE do read the posting guide
> > >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj5SGdDSU$
> > >     > and provide commented, minimal, self-contained, reproducible
> code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj2eq-EE8$
> > PLEASE do read the posting guide
> >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj5SGdDSU$
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj2eq-EE8$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj5SGdDSU$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 05:37:39 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 22:37:39 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CA+8X3fVegAWfMGjvV-0eZe4uMu9NMcDe2DZz10=CFz+BUuNm4Q@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
 <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
 <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>
 <CA+8X3fVegAWfMGjvV-0eZe4uMu9NMcDe2DZz10=CFz+BUuNm4Q@mail.gmail.com>
Message-ID: <CAF9-5jPxb7eMrbQgkDh_fzFjxBoO-c4-m5Rz=nnLbD+0pcCbAA@mail.gmail.com>

Hi Jim,

not in this case, but thanks for asking!

Ana

On Mon, Jun 1, 2020 at 10:04 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> So recombination sticks out its foot before us. Do you want to account
> for gene linkage?
>
> JIm
>
> On Tue, Jun 2, 2020 at 11:55 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi Jim
> >
> > > neu3<-neu1[!(neu1$Marker %in% Marker3),]
> > > dim(neu3)
> > [1] 1857    9
> > > nep3<-nep1[!(nep1$Marker %in% Marker3),]
> > > dim(nep3)
> > [1] 5562    9
> > > ret3<-ret1[!(ret1$Marker %in% Marker3),]
> > > dim(ret3)
> > [1] 3493    9
> >
> >
> > If I do:
> >
> >  nn1<-merge(neu1,nep1,by=c("Marker","Chr"))
> > nn2<-merge(nn1,ret1,by=c("Marker","Chr"))
> > > Marker3<-nn2$Marker
> > > length(Marker3)
> > [1] 3742962
> > > Marker4<-nn1$Marker
> > > length(Marker4)
> > [1] 3744443
> >
> > On Mon, Jun 1, 2020 at 8:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hi David,
> > >
> > > that is a great point!
> > > Yes indeed some are non unique:
> > >
> > > > dim(neu1)
> > > [1] 3742845       9
> > > > length(unique(neu1$Marker))
> > > [1] 3741858
> > > > length(unique(nep1$Marker))
> > > [1] 3745560
> > > > dim(nep1)
> > > [1] 3746550       9
> > > > length(unique(ret1$Marker))
> > > [1] 3743494
> > > > dim(ret1)
> > > [1] 3743494       9
> > >
> > > How would I rewrite this code so that is merging by Chr and Marker
> > > column? It seems that a Marker can be under a few Chr.
> > >
> > >
> > >
> > >
> > >
> > > On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
> > > >
> > > >
> > > > On 6/1/20 5:40 PM, Ana Marija wrote:
> > > > > Hi Jim,
> > > > >
> > > > > thank you so much for getting back to me. I tried your code and this is
> > > > > what I get:
> > > > >> dim(neu2)
> > > > > [1] 3740988       9
> > > > >> dim(nep2)
> > > > > [1] 3740988       9
> > > > >> dim(ret2)
> > > > > [1] 3740001       9
> > > > >
> > > > > I think I would need to have the same number of lines in all 3 data frames.
> > > > >
> > > > > Can you please advise.
> > > >
> > > >
> > > > You should check for duplicated Marker values.
> > > >
> > > >
> > > > --
> > > >
> > > > David
> > > >
> > > > >
> > > > > Cheers
> > > > > Ana
> > > > >
> > > > > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > > >
> > > > >> Hi Ana,
> > > > >> Not too hard, but your example has all the "marker" fields in common.
> > > > >> So using a sample that will show the expected result:
> > > > >>
> > > > >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> > > > >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> > > > >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> > > > >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> > > > >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> > > > >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> > > > >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> > > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > > >>
> > > > >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> > > > >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> > > > >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> > > > >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> > > > >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> > > > >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> > > > >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> > > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > > >>
> > > > >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> > > > >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> > > > >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> > > > >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> > > > >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> > > > >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> > > > >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> > > > >> header=TRUE,stringsAsFactors=FALSE)
> > > > >>
> > > > >> # merge the three data frames on "Marker"
> > > > >> nn1<-merge(neu1,nep1,by="Marker")
> > > > >> nn2<-merge(nn1,ret1,by="Marker")
> > > > >> # get the common "Marker" strings
> > > > >> Marker3<-nn2$Marker
> > > > >> # subset all three data frames on Marker3
> > > > >> neu2<-neu1[neu1$Marker %in% Marker3,]
> > > > >> nep2<-nep1[nep1$Marker %in% Marker3,]
> > > > >> ret2<-ret1[ret1$Marker %in% Marker3,]
> > > > >>
> > > > >> Jim
> > > > >>
> > > > >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> > > > >> wrote:
> > > > >>> Hello,
> > > > >>>
> > > > >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> > > > >>> exactly the same number of lines)...they look like this:
> > > > >>> ...
> > > > >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > > > >>> which would only contain lines that have the same entries in Marker
> > > > >> column
> > > > >>> for all 3 data frames?
> > > > >>>
> > > > >>> Thanks
> > > > >>> Ana
> > > > >>>
> > > > >>>          [[alternative HTML version deleted]]
> > > > >>>
> > > > >>> ______________________________________________
> > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>> PLEASE do read the posting guide
> > > > >> http://www.R-project.org/posting-guide.html
> > > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.


From |omn@v@@|@ @end|ng |rom gm@||@com  Tue Jun  2 02:18:49 2020
From: |omn@v@@|@ @end|ng |rom gm@||@com (Lom Navanyo)
Date: Mon, 1 Jun 2020 19:18:49 -0500
Subject: [R] How to efficiently generate data of points within specified
 radii for each geometric point
Message-ID: <CAKBoCbGbTT2WanrBpFfW6EUeWxQtxtOZGnkPCExq5cjqWZkecA@mail.gmail.com>

Hello,
I have data set of about 3400 location points with which I am trying to
generate data of each point and their neighbors within defined radii (eg,
0.25, 1, and 3 miles).

Below is a reprex using the built-in  nz_height  data:

library(sf)
library(dplyr)
library(spData)
library(ggplot2)
library(stringr)
library(rgdal)
library(lwgeom)
library(sp)


#Transform and project to required UTM

projdata<-st_transform(nz_height, 32759)  #32759 is for UTM Zone 59S


# plot(projdata$geometry)

# sequence of radii

bufferR <- c(402.336, 1609.34, 3218.69, 4828.03, 6437.38)

#Create data of neighboring wells per buffer

dataout <- do.call("rbind", lapply(1:length(bufferR), function(y) {
    bfr <- projdata %>% st_buffer(bufferR[y]) ## create Buffer
    ## minus the next smaller buffer
    if(y>1) {
      inters <- suppressWarnings(st_difference(bfr, projdata %>%
st_buffer(bufferR[y-1])))
      bfr <- inters[which(inters$t50_fid == inters$t50_fid.1),]
    }

    # get ids that intersect with buffer
    inters <- bfr %>% st_intersects(projdata)


    do.call("rbind", lapply(which(sapply(inters, length)>0),
         function(z) data.frame(t50_fid = projdata[z,]$t50_fid, radius =
bufferR[y],
                t50_fid_2 = projdata[unlist(inters[z]),]$t50_fid,
                elevation_mtchd = projdata[unlist(inters[z]),]$elevation)))
}))

This gives data frame as:

> head(dataout)
  t50_fid  radius t50_fid_2 elevation_mtchd
1 2353944 402.336   2353944            2723
2 2354404 402.336   2354404            2820
3 2354405 402.336   2354405            2830
4 2369113 402.336   2369113            3033
5 2362630 402.336   2362630            2749
6 2362814 402.336   2362814            2822

The end goal is that for each (original) point with  t50_fids,  I want its
neighboring points within the specified radius listed under  t50_fid_2 in a
long format. The caveat is that for the very first (ie. the smallest)
radius 402.336,  t50_fid_2 should return neighboring points within that
distance. But for subsequent radii,  t50_fid_2 should return neighboring
points within them but not within the smaller radius. Thus for example, for
radius 1609.34m, I should get as neighboring points, points within 1609.34m
but not within the smaller buffer/radius 402.336m.

The problem is that if I use my full data set of over 3000 rows (points), I
get the following error:

Error in CPL_geos_op2(op, st_geometry(x), st_geometry(y)) : Evaluation
error: std::bad_alloc.

I understand this is a memory issue as the code I am using creates buffers
around each point and this approach is memory intensive.

A suggestion was made that I could achieve my objective  using
st_is_within_distance  instead of  st_buffer  , st_difference  and
st_intersect without creating buffers.

How can I achieve my objective (that is, the table in dataout) efficiently
either with the suggested use of  st_is_within_distance,  or with my code
without running out of memory (RAM) or any other approach?

Thank you for considering my question.
-----------------------
Lom Navanyo Newton

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jun  2 08:38:31 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 01 Jun 2020 23:38:31 -0700
Subject: [R] How to efficiently generate data of points within specified
 radii for each geometric point
In-Reply-To: <CAKBoCbGbTT2WanrBpFfW6EUeWxQtxtOZGnkPCExq5cjqWZkecA@mail.gmail.com>
References: <CAKBoCbGbTT2WanrBpFfW6EUeWxQtxtOZGnkPCExq5cjqWZkecA@mail.gmail.com>
Message-ID: <C3D818DD-C0E7-4985-8008-981396F1B555@dcn.davis.ca.us>

Wrong list. Do _read_ the Posting Guide and then check out r-sig-geo.

On June 1, 2020 5:18:49 PM PDT, Lom Navanyo <lomnavasia at gmail.com> wrote:
>Hello,
>I have data set of about 3400 location points with which I am trying to
>generate data of each point and their neighbors within defined radii
>(eg,
>0.25, 1, and 3 miles).
>
>Below is a reprex using the built-in  nz_height  data:
>
>library(sf)
>library(dplyr)
>library(spData)
>library(ggplot2)
>library(stringr)
>library(rgdal)
>library(lwgeom)
>library(sp)
>
>
>#Transform and project to required UTM
>
>projdata<-st_transform(nz_height, 32759)  #32759 is for UTM Zone 59S
>
>
># plot(projdata$geometry)
>
># sequence of radii
>
>bufferR <- c(402.336, 1609.34, 3218.69, 4828.03, 6437.38)
>
>#Create data of neighboring wells per buffer
>
>dataout <- do.call("rbind", lapply(1:length(bufferR), function(y) {
>    bfr <- projdata %>% st_buffer(bufferR[y]) ## create Buffer
>    ## minus the next smaller buffer
>    if(y>1) {
>      inters <- suppressWarnings(st_difference(bfr, projdata %>%
>st_buffer(bufferR[y-1])))
>      bfr <- inters[which(inters$t50_fid == inters$t50_fid.1),]
>    }
>
>    # get ids that intersect with buffer
>    inters <- bfr %>% st_intersects(projdata)
>
>
>    do.call("rbind", lapply(which(sapply(inters, length)>0),
>        function(z) data.frame(t50_fid = projdata[z,]$t50_fid, radius =
>bufferR[y],
>                t50_fid_2 = projdata[unlist(inters[z]),]$t50_fid,
>            elevation_mtchd = projdata[unlist(inters[z]),]$elevation)))
>}))
>
>This gives data frame as:
>
>> head(dataout)
>  t50_fid  radius t50_fid_2 elevation_mtchd
>1 2353944 402.336   2353944            2723
>2 2354404 402.336   2354404            2820
>3 2354405 402.336   2354405            2830
>4 2369113 402.336   2369113            3033
>5 2362630 402.336   2362630            2749
>6 2362814 402.336   2362814            2822
>
>The end goal is that for each (original) point with  t50_fids,  I want
>its
>neighboring points within the specified radius listed under  t50_fid_2
>in a
>long format. The caveat is that for the very first (ie. the smallest)
>radius 402.336,  t50_fid_2 should return neighboring points within that
>distance. But for subsequent radii,  t50_fid_2 should return
>neighboring
>points within them but not within the smaller radius. Thus for example,
>for
>radius 1609.34m, I should get as neighboring points, points within
>1609.34m
>but not within the smaller buffer/radius 402.336m.
>
>The problem is that if I use my full data set of over 3000 rows
>(points), I
>get the following error:
>
>Error in CPL_geos_op2(op, st_geometry(x), st_geometry(y)) : Evaluation
>error: std::bad_alloc.
>
>I understand this is a memory issue as the code I am using creates
>buffers
>around each point and this approach is memory intensive.
>
>A suggestion was made that I could achieve my objective  using
>st_is_within_distance  instead of  st_buffer  , st_difference  and
>st_intersect without creating buffers.
>
>How can I achieve my objective (that is, the table in dataout)
>efficiently
>either with the suggested use of  st_is_within_distance,  or with my
>code
>without running out of memory (RAM) or any other approach?
>
>Thank you for considering my question.
>-----------------------
>Lom Navanyo Newton
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jun  2 10:23:24 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 2 Jun 2020 20:23:24 +1200
Subject: [R] Query on contour plots
In-Reply-To: <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
Message-ID: <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>

I'm putting this back on the list.

> So how would I set up the code to do this with the data type I have?

> I will need to replicate the same task > 200 times with other data sets.
> What I need to do is plot *Fc *against *Sc* with the third dimension being the *density* of the data points.

Using Jim's bat_call data:

    library (bivariate)

    plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
    {   names <- names (dataset)
        fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
[,1]), k2 * bw.nrd (dataset [,2]) )
        plot (fh, main=main, xlab = names [1], ylab = names [2],
            xlim=xlim, ylim=ylim,
            ncontours=2)
    }

    plot_ds (bat_call, "plot 1", k1=1.25, k2=1.25)

Note that I've used stats::bw.nrd.
The k1 and k2 values, simply scale the default bandwidth.
(In this case, I've increased the smoothness).

If you want to do it 200+ times:
(1) Create another function, to iterate over each data set.
(2) If you want to save the plots, you will need to add in a call to
pdf/png/etc and close the device, in each iteration.
(3) It may be desirable to have constant xlim/ylim values, ideally
based on the ranges of the combined data:

    plot_ds (bat_call, "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
        k1=1.25, k2=1.25)


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 12:20:10 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 20:20:10 +1000
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
Message-ID: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>

Very nice. I forgot that you didn't have the complete data set.

png("as_bat_call.png")
plot_ds (bfs[,c("Fc","Sc")], "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
        k1=1.25, k2=1.25)
dev.off()

Jim

On Tue, Jun 2, 2020 at 6:24 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I'm putting this back on the list.
>
> > So how would I set up the code to do this with the data type I have?
>
> > I will need to replicate the same task > 200 times with other data sets.
> > What I need to do is plot *Fc *against *Sc* with the third dimension being the *density* of the data points.
>
> Using Jim's bat_call data:
>
>     library (bivariate)
>
>     plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
>     {   names <- names (dataset)
>         fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
> [,1]), k2 * bw.nrd (dataset [,2]) )
>         plot (fh, main=main, xlab = names [1], ylab = names [2],
>             xlim=xlim, ylim=ylim,
>             ncontours=2)
>     }
>
>     plot_ds (bat_call, "plot 1", k1=1.25, k2=1.25)
>
> Note that I've used stats::bw.nrd.
> The k1 and k2 values, simply scale the default bandwidth.
> (In this case, I've increased the smoothness).
>
> If you want to do it 200+ times:
> (1) Create another function, to iterate over each data set.
> (2) If you want to save the plots, you will need to add in a call to
> pdf/png/etc and close the device, in each iteration.
> (3) It may be desirable to have constant xlim/ylim values, ideally
> based on the ranges of the combined data:
>
>     plot_ds (bat_call, "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
>         k1=1.25, k2=1.25)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: as_bat_call.png
Type: image/png
Size: 26580 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200602/17c1cb64/attachment.png>

From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Tue Jun  2 14:33:36 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 08:33:36 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
Message-ID: <daf569fd-abe0-e45e-79ca-22b89eae1421@gmail.com>

Hi all,

Many thanks for the efforts and suggestions.

This is getting closer to what is needed.? No legend showing the density 
values yet.
I was able to replicate a similar plot with the original data set.
However when I tried this with a different data set that has other Fc & 
Sc values? the plot does not work... just a blank PNG
Code from console below:

 ?>bfs<-Eptfur
 > dim(bfs)
[1] 5638?? 17
 > names(bfs)
 ?[1] "Filename" "st"?????? "Dur"????? "TBC"????? "Fmax" "Fmin"???? "Fmean"
 ?[8] "Tk"?????? "Fk"?????? "Qk"?????? "Tc"?????? "Fc" "Dc"?????? "S1"
[15] "Sc"?????? "Qual"???? "Pmc"
 > library(plotrix)
 > # set the matrix limits a bit beyond the data ranges
 > fcsc_mat<-makeDensityMatrix(bfs$Fc,bfs$Sc,nx=25,ny=25,
+ zfun="sum",xlim=c(24,29),ylim=c(-20,10))
Range of density (>0) - Inf -Inf
Warning messages:
*1: In min(x) : no non-missing arguments to min; returning Inf**
**2: In max(x) : no non-missing arguments to max; returning -Inf*
 > png("bat_call_plot.png")
 > par(mar=c(6,4,4,2))
 > color2D.matplot(fcsc_mat,
+ main="Freqency by slope of bat calls",
+ extremes=c("yellow","red"),xlab="Frequency (kHz)",
+ ylab="Characteristic slope (octaves/s)",
+ border=NA,axes=FALSE)
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf
 > axis(1,at=seq(5,95,10),round(seq(24.5,28.5,length.out=10),1))
 > axis(2,at=seq(5,95,10),round(seq(-20,10,length.out=10),1))
 > color.legend(0,-14,25,-10,legend=seq(0,10,length.out=5),
+ rect.col=color.scale(0:4,extremes=c("yellow","red")),align="rb")
 > text(12.5,-20,"Density (cell count)",xpd=TRUE)
 > dev.off()
null device
 ????????? 1

I will not need to add a function it iterate as I will not be running? 
this as an iterative task at one time... I just need the code to be able 
to use different data sets that have the same fields.
The Sc values over the 200+ data sets will range from potentially large 
negative numbers to positive numbers depending on the slope of the 
calls, i.e. increasing frequencies or decreasing frequencies.
An example of these two parameters for a single species with descriptive 
stats.
N is valid number of call pulses, then 10%-90% bins of where the call 
pulses fall into.

Parameters 	N 	Min 	Max 	Mean 	St.Dev 	10% 	25% 	75% 	90%
Fc 	32802 	43.01 	50.00 	46.86 	1.31 	45.07 	45.98 	47.76 	48.63
Sc 	32802 	-309.78 	13.76 	-6.60 	10.98 	-10.31 	-7.50 	-3.91 	-2.81


I am very appreciative and thank you both for guiding the efforts.

Bruce
> Very nice. I forgot that you didn't have the complete data set.
>
> png("as_bat_call.png")
> plot_ds (bfs[,c("Fc","Sc")], "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
>          k1=1.25, k2=1.25)
> dev.off()
>
> Jim
>
> On Tue, Jun 2, 2020 at 6:24 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>> I'm putting this back on the list.
>>
>>> So how would I set up the code to do this with the data type I have?
>>> I will need to replicate the same task > 200 times with other data sets.
>>> What I need to do is plot *Fc *against *Sc* with the third dimension being the *density* of the data points.
>> Using Jim's bat_call data:
>>
>>      library (bivariate)
>>
>>      plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
>>      {   names <- names (dataset)
>>          fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
>> [,1]), k2 * bw.nrd (dataset [,2]) )
>>          plot (fh, main=main, xlab = names [1], ylab = names [2],
>>              xlim=xlim, ylim=ylim,
>>              ncontours=2)
>>      }
>>
>>      plot_ds (bat_call, "plot 1", k1=1.25, k2=1.25)
>>
>> Note that I've used stats::bw.nrd.
>> The k1 and k2 values, simply scale the default bandwidth.
>> (In this case, I've increased the smoothness).
>>
>> If you want to do it 200+ times:
>> (1) Create another function, to iterate over each data set.
>> (2) If you want to save the plots, you will need to add in a call to
>> pdf/png/etc and close the device, in each iteration.
>> (3) It may be desirable to have constant xlim/ylim values, ideally
>> based on the ranges of the combined data:
>>
>>      plot_ds (bat_call, "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
>>          k1=1.25, k2=1.25)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Tue Jun  2 19:11:54 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 13:11:54 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
Message-ID: <c3594a31-9283-d61a-c699-1f8ae153705a@gmail.com>

Hi all,

I spent some time this morning fiddling with the parameters in the plot 
code provided by Jim and Abby and? by changing some important ones.

Jim did note
*# set the matrix limits a bit beyond the data ranges*
fcsc_mat<-makeDensityMatrix(bfs$Fc,bfs$Sc,nx=100,ny=100,
 ?zfun="sum",xlim=c(*30,45*),ylim=c(*-55,110*)) and

axis(1,at=seq(5,95,10),round(seq(*30.0,50.0*,length.out=10),1))

axis(2,at=seq(5,95,10),round(seq(*-55,110*,length.out=10),1))

So editing the lines above to match what the data includes the plots for 
various species are working!

I now need to figure out how to add a legend for the density values in 
the bivariate package plots.

I am assuming there can be a line or so of code that can extract the 
min-max values from the actual data files
that will update the xlim, ylim and axis data?? I think this should be a 
simple first step after reading in each new data set.

I can not thank Jim and Abby enough.? Super helpful

Cheers,
Bruce

-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jun  2 20:44:03 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 06:44:03 +1200
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
Message-ID: <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>

> Very nice

Jim, thank you.
However, the (deterministic, or near-deterministic) diagonal lines in
the plot, make me question the suitability of this approach.
In my plot, the contour lines could be removed, and brighter colors
could be used.

But perhaps, a better approach would be to model those lines...
And it's not clear from the plot, if all the observations fall on a
diagonal line...


P.S.
I'm not sure why there's a white line on the plot.
Most of my testing was with PDF output, I will need to do some more
testing with PNG output.


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Tue Jun  2 22:22:06 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 16:22:06 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
Message-ID: <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>

Hi Abby,

The contour lines are actually useful to see groupings.
However w/o a legend for density it is not possible to see what is 
presented.
>> Very nice
> Jim, thank you.
> However, the (deterministic, or near-deterministic) diagonal lines in
> the plot, make me question the suitability of this approach.
> In my plot, the contour lines could be removed, and brighter colors
> could be used.
>
> But perhaps, a better approach would be to model those lines...
> And it's not clear from the plot, if all the observations fall on a
> diagonal line...
>
>
> P.S.
> I'm not sure why there's a white line on the plot.
> Most of my testing was with PDF output, I will need to do some more
> testing with PNG output.


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From drj|m|emon @end|ng |rom gm@||@com  Wed Jun  3 00:50:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 3 Jun 2020 08:50:13 +1000
Subject: [R] Query on contour plots
In-Reply-To: <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
Message-ID: <CA+8X3fWGtUiKJVYGe1tLn_SJMm2WxwHg7_MBdE36qVn=iX2fVg@mail.gmail.com>

Hi Bruce & Abby,
Here is a start on merging the two plots.
Abby - I had to cheat on the legend colors as I could not work out
from the help pages how to specify the range of colors. Also I don't
know the range of densities. Both should be easy to fix. While I
specified xlab and ylab, they don't seem to make it to the plotting
functions. More study needed.
Bruce - The following code gives general idea of how to automate
plotting from a single data set. let me know whether you want
automated adjustment of axes, etc.
Both - I suspect that the constraints forming the diagonal lines are
due to characteristics of the bat larynx.

bfs<-read.csv("Procen_sample.csv")
# split out what you want to identify the plot
species<-unlist(strsplit("Procen_sample.csv","_"))[1]
library(bivariate)
# define the plot sequence
plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
    {   names <- names (dataset)
        fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
[,1]), k2 * bw.nrd (dataset [,2]) )
        plot (fh, main=main, xlab = names [1], ylab = names [2],
            xlim=xlim, ylim=ylim,
            ncontours=2)
}
# open the device
png(paste0(species,".png"))
# leave space for the color legend
par(mar=c(6,4,4,2))
plot_ds (bfs[,c("Fc","Sc")],
 main=paste(species,"characteristic bat call"),
 xlab="Frequency (kHz)",ylab="Characteristic slope (octaves/s)",
 ,k1=1.25, k2=1.25)
library(plotrix)
xylim<-par("usr")
color.legend(xylim[1],xylim[3]-(xylim[4]-xylim[3])/7,
 xylim[1]+(xylim[2]-xylim[1])/4,xylim[3]-(xylim[4]-xylim[3])/10,
legend=seq(0,10,length.out=5),
rect.col=color.scale(0:4,extremes=c("#7be6bd","#bdb3df")),align="rb")
text(xylim[1]+(xylim[2]-xylim[1])/8,
 xylim[3]-(xylim[4]-xylim[3])/5,
 "Density",xpd=TRUE)
dev.off()

Jim

On Wed, Jun 3, 2020 at 6:22 AM Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi Abby,
>
> The contour lines are actually useful to see groupings.
> However w/o a legend for density it is not possible to see what is
> presented.
> >> Very nice
> > Jim, thank you.
> > However, the (deterministic, or near-deterministic) diagonal lines in
> > the plot, make me question the suitability of this approach.
> > In my plot, the contour lines could be removed, and brighter colors
> > could be used.
> >
> > But perhaps, a better approach would be to model those lines...
> > And it's not clear from the plot, if all the observations fall on a
> > diagonal line...
> >
> >
> > P.S.
> > I'm not sure why there's a white line on the plot.
> > Most of my testing was with PDF output, I will need to do some more
> > testing with PNG output.
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
> Conservation Fellow - Wildlife Conservation Society
>
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>
> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Procen.png
Type: image/png
Size: 30320 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200603/112c94e3/attachment.png>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun  3 01:31:52 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 2 Jun 2020 16:31:52 -0700
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
Message-ID: <a88e32f8-1886-8e38-4e68-bb040ebc5c98@comcast.net>


On 6/2/20 11:44 AM, Abby Spurdle wrote:
>> Very nice
> Jim, thank you.
> However, the (deterministic, or near-deterministic) diagonal lines in
> the plot, make me question the suitability of this approach.
> In my plot, the contour lines could be removed, and brighter colors
> could be used.
>
> But perhaps, a better approach would be to model those lines...
> And it's not clear from the plot, if all the observations fall on a
> diagonal line...
>
>
> P.S.
> I'm not sure why there's a white line on the plot.


I think if you search the archives of Rhelp you will find many such 
whinges and that extraneous white lines in PDFs are the fault of the PDF 
viewing program rather than of R.


-- 

David.

> Most of my testing was with PDF output, I will need to do some more
> testing with PNG output.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Wed Jun  3 01:52:21 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 19:52:21 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fWGtUiKJVYGe1tLn_SJMm2WxwHg7_MBdE36qVn=iX2fVg@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
 <CA+8X3fWGtUiKJVYGe1tLn_SJMm2WxwHg7_MBdE36qVn=iX2fVg@mail.gmail.com>
Message-ID: <c21371e7-84be-a8df-d18a-733eadf527e7@gmail.com>

Tnx Jim,

Yes if there is a way to first extract the ranges of each data files Fc 
range and Sc ranges and then link to the plot that would be stellar.
I will look at this code and see how it is working so far.

Thanks a million.
Bruce
> Hi Bruce & Abby,
> Here is a start on merging the two plots.
> Abby - I had to cheat on the legend colors as I could not work out
> from the help pages how to specify the range of colors. Also I don't
> know the range of densities. Both should be easy to fix. While I
> specified xlab and ylab, they don't seem to make it to the plotting
> functions. More study needed.
> Bruce - The following code gives general idea of how to automate
> plotting from a single data set. let me know whether you want
> automated adjustment of axes, etc.
> Both - I suspect that the constraints forming the diagonal lines are
> due to characteristics of the bat larynx.
>
> bfs<-read.csv("Procen_sample.csv")
> # split out what you want to identify the plot
> species<-unlist(strsplit("Procen_sample.csv","_"))[1]
> library(bivariate)
> # define the plot sequence
> plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
>      {   names <- names (dataset)
>          fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
> [,1]), k2 * bw.nrd (dataset [,2]) )
>          plot (fh, main=main, xlab = names [1], ylab = names [2],
>              xlim=xlim, ylim=ylim,
>              ncontours=2)
> }
> # open the device
> png(paste0(species,".png"))
> # leave space for the color legend
> par(mar=c(6,4,4,2))
> plot_ds (bfs[,c("Fc","Sc")],
>   main=paste(species,"characteristic bat call"),
>   xlab="Frequency (kHz)",ylab="Characteristic slope (octaves/s)",
>   ,k1=1.25, k2=1.25)
> library(plotrix)
> xylim<-par("usr")
> color.legend(xylim[1],xylim[3]-(xylim[4]-xylim[3])/7,
>   xylim[1]+(xylim[2]-xylim[1])/4,xylim[3]-(xylim[4]-xylim[3])/10,
> legend=seq(0,10,length.out=5),
> rect.col=color.scale(0:4,extremes=c("#7be6bd","#bdb3df")),align="rb")
> text(xylim[1]+(xylim[2]-xylim[1])/8,
>   xylim[3]-(xylim[4]-xylim[3])/5,
>   "Density",xpd=TRUE)
> dev.off()
>
> Jim
>
> On Wed, Jun 3, 2020 at 6:22 AM Neotropical bat risk assessments
> <neotropical.bats at gmail.com> wrote:
>> Hi Abby,
>>
>> The contour lines are actually useful to see groupings.
>> However w/o a legend for density it is not possible to see what is
>> presented.
>>>> Very nice
>>> Jim, thank you.
>>> However, the (deterministic, or near-deterministic) diagonal lines in
>>> the plot, make me question the suitability of this approach.
>>> In my plot, the contour lines could be removed, and brighter colors
>>> could be used.
>>>
>>> But perhaps, a better approach would be to model those lines...
>>> And it's not clear from the plot, if all the observations fall on a
>>> diagonal line...
>>>
>>>
>>> P.S.
>>> I'm not sure why there's a white line on the plot.
>>> Most of my testing was with PDF output, I will need to do some more
>>> testing with PNG output.
>>
>> --
>> Bruce W. Miller, PhD.
>> Neotropical bat risk assessments
>> Conservation Fellow - Wildlife Conservation Society
>>
>> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>>
>> Using acoustic sampling to identify and map species distributions
>> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>>
>> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>>


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jun  3 02:53:28 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 12:53:28 +1200
Subject: [R] Query on contour plots
In-Reply-To: <a88e32f8-1886-8e38-4e68-bb040ebc5c98@comcast.net>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <a88e32f8-1886-8e38-4e68-bb040ebc5c98@comcast.net>
Message-ID: <CAB8pepxRnkkMT1sYqfbs9eM-RLxsVPtf-Z0wZzHK1RVXSUpNSg@mail.gmail.com>

>  that extraneous white lines in PDFs are the fault of the PDF
> viewing program rather than of R.

Except it's a PNG file.

I've tried to minimize artifacts viewing PDF files.
But assumed (falsely?) that PNGs and other raster formats, would be fine.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jun  3 02:58:01 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 12:58:01 +1200
Subject: [R] Query on contour plots
In-Reply-To: <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
Message-ID: <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>

> The contour lines are actually useful to see groupings.
> However w/o a legend for density it is not possible to see what is
> presented.

I need to re-iterate, that the diagonal lines, may be important.

Also, I'm not sure I see the point in adding density values.
Unless people have a good knowledge of probability theory and
calculus, I doubt that specific density values will be useful.
i.e. If I said the density was 0.0035, what does that tell you...?

If you really want to add a legend, it's possible.

But this creates at least two problems:
(1) In the base graphics system, the resulting plots can't be nested.
(2) It's difficult to interpret specific color-encoded values.

In my opinion, a better idea, is to label the contour lines.
In my packages, this is possible by using contour.labels=TRUE,
however, the defaults are ugly.
(Something else for my todo list).

Here's a slightly more complex example, with prettier contour labels:

    library (barsurf)
    library (KernSmooth)
    set.bs.theme ("heat")

    plot_ds <- function (dataset, main="", xlim, ylim, ...,
        ncontours=3, labcex=0.8, ndec=3,
        k1=1, k2=1, n=30)
    {   names <- names (dataset)
        x <- dataset [,1]
        y <- dataset [,2]
     bw.x <- k1 * bw.nrd (x)
        bw.y <- k2 * bw.nrd (y)
        if (missing (xlim) )
            xlim <- range (x) + c(-1, 1) * bw.x
        if (missing (ylim) )
            ylim <- range (y) + c(-1, 1) * bw.y

        ks <- bkde2D (dataset, c (bw.x, bw.y),
            c (n, n), list (xlim, ylim), FALSE)

        fb <- seq (min (ks$fhat), max (ks$fhat),
            length.out = ncontours + 2)
        fb <- fb [2:(ncontours + 1)]
        fb <- round (fb, ndec)

        plot_cfield (ks$x1, ks$x2, ks$fhat,
            contours=FALSE,
            main=main, xlab = names [1], ylab = names [2],
            xyrel="m")
        points (x, y, pch=16, col="#00000040")
        contour (ks$x1, ks$x2, ks$fhat, levels=fb, labcex=labcex, add=TRUE)
    }

    plot_ds (bat_call, "plot 2", c (25, 28), c (-15, 10), k1=1.25, k2=1.25)

If you still want a legend, have a look at:
graphics::filled.contour

And then modify the second half of my code, starting after ks <- ...


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Wed Jun  3 03:14:27 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 21:14:27 -0400
Subject: [R] did bot execute
In-Reply-To: <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
 <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>
Message-ID: <044c21a6-f301-d033-cb4a-4fac2aaaa999@gmail.com>

Hi Abby,

Tried this new version but did not execute...
Clearly I am missing a step.

Bruce
 > library (barsurf)
 > library (KernSmooth)
 > set.bs.theme ("heat")
 >
 > plot_ds <- function (dataset, main="", xlim, ylim, ...,
+ ncontours=3, labcex=0.8, ndec=3,
+ k1=1, k2=1, n=30)
+ {?? names <- names (dataset)
+ x <- dataset [,1]
+ y <- dataset [,2]
+ bw.x <- k1 * bw.nrd (x)
+ bw.y <- k2 * bw.nrd (y)
+ if (missing (xlim) )
+ xlim <- range (x) + c(-1, 1) * bw.x
+ if (missing (ylim) )
+ ylim <- range (y) + c(-1, 1) * bw.y
+
+ ks <- bkde2D (dataset, c (bw.x, bw.y),
+ c (n, n), list (xlim, ylim), FALSE)
+
+ fb <- seq (min (ks$fhat), max (ks$fhat),
+ length.out = ncontours + 2)
+ fb <- fb [2:(ncontours + 1)]
+ fb <- round (fb, ndec)
+
+ plot_cfield (ks$x1, ks$x2, ks$fhat,
+ contours=FALSE,
+ main=main, xlab = names [1], ylab = names [2],
+ xyrel="m")
+ points (x, y, pch=16, col="#00000040")
+ contour (ks$x1, ks$x2, ks$fhat, levels=fb, labcex=labcex, add=TRUE)
+ }
 >
 > plot_ds (bat_call, "plot 2", c (25, 28), c (-15, 10), k1=1.25, k2=1.25)
*Error in plot_ds(bat_call, "plot 2", c(25, 28), c(-15, 10), k1 = 1.25,? 
: **
**? object 'bat_call' not found*

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Wed Jun  3 03:46:21 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 02 Jun 2020 21:46:21 -0400
Subject: [R] Chart will not display
Message-ID: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>

I have made what must be a simple mistake, but I have not been able to 
find it.

I create a function to plot a chart for a single variable. I want to 
display separate charts for several variables, one after another, with 
"Press [enter] to continue" in between. The function works fine for a 
single variable, but when I try to display several variables 
consecutively, using a for statement, no charts are displayed. The for 
statement executes without apparent error, but no charts appear.

Here is a reprex.

library(tidyverse)
t <- c(1,2,3,4,5)
a <- c(1,4,5,8,7)
b <- c(2,2,5,3,1)
c <- c(3,6,2,8,3)
df <- data.frame(t=t,a=a,b=b,c=c)
df1 <- pivot_longer(df,cols=c(a,b,c),names_to="var",values_to="val")
chfn <- function(chnm) {
   ggplot(filter(df1,var==chnm),aes(x=t,y=val,group=1)) +
     geom_line() +
     labs(title=chnm)
}
chfn("b") # test of the function - it works
chnms <- c("a","b","c")
for (i in chnms) {
   chfn(i)
   readline(prompt="Press [enter] to continue")
}

Thanks for your help.

Philip


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  3 04:02:12 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 2 Jun 2020 19:02:12 -0700
Subject: [R] Chart will not display
In-Reply-To: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
References: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
Message-ID: <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>

In a function you must explicitly print/plot the ggplot() object, I assume.
i.e. plot(ggplot(...)) etc.

I do not use ggplot, so if I'm wrong, sorry.  But try it.  Hopefully
someone else will get it right if it doesn't do it.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 2, 2020 at 6:46 PM <phil at philipsmith.ca> wrote:

> I have made what must be a simple mistake, but I have not been able to
> find it.
>
> I create a function to plot a chart for a single variable. I want to
> display separate charts for several variables, one after another, with
> "Press [enter] to continue" in between. The function works fine for a
> single variable, but when I try to display several variables
> consecutively, using a for statement, no charts are displayed. The for
> statement executes without apparent error, but no charts appear.
>
> Here is a reprex.
>
> library(tidyverse)
> t <- c(1,2,3,4,5)
> a <- c(1,4,5,8,7)
> b <- c(2,2,5,3,1)
> c <- c(3,6,2,8,3)
> df <- data.frame(t=t,a=a,b=b,c=c)
> df1 <- pivot_longer(df,cols=c(a,b,c),names_to="var",values_to="val")
> chfn <- function(chnm) {
>    ggplot(filter(df1,var==chnm),aes(x=t,y=val,group=1)) +
>      geom_line() +
>      labs(title=chnm)
> }
> chfn("b") # test of the function - it works
> chnms <- c("a","b","c")
> for (i in chnms) {
>    chfn(i)
>    readline(prompt="Press [enter] to continue")
> }
>
> Thanks for your help.
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Wed Jun  3 04:21:18 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 02 Jun 2020 22:21:18 -0400
Subject: [R] Chart will not display
In-Reply-To: <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>
References: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
 <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>
Message-ID: <468ff0d758729c9cc9e091fd6c3ff444@philipsmith.ca>

Thanks Bert. That did it.

Philip

On 2020-06-02 22:02, Bert Gunter wrote:
> In a function you must explicitly print/plot the ggplot() object, I
> assume. i.e. plot(ggplot(...)) etc.
> 
> I do not use ggplot, so if I'm wrong, sorry.  But try it.  Hopefully
> someone else will get it right if it doesn't do it.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Tue, Jun 2, 2020 at 6:46 PM <phil at philipsmith.ca> wrote:
> 
>> I have made what must be a simple mistake, but I have not been able
>> to
>> find it.
>> 
>> I create a function to plot a chart for a single variable. I want to
>> 
>> display separate charts for several variables, one after another,
>> with
>> "Press [enter] to continue" in between. The function works fine for
>> a
>> single variable, but when I try to display several variables
>> consecutively, using a for statement, no charts are displayed. The
>> for
>> statement executes without apparent error, but no charts appear.
>> 
>> Here is a reprex.
>> 
>> library(tidyverse)
>> t <- c(1,2,3,4,5)
>> a <- c(1,4,5,8,7)
>> b <- c(2,2,5,3,1)
>> c <- c(3,6,2,8,3)
>> df <- data.frame(t=t,a=a,b=b,c=c)
>> df1 <- pivot_longer(df,cols=c(a,b,c),names_to="var",values_to="val")
>> chfn <- function(chnm) {
>> ggplot(filter(df1,var==chnm),aes(x=t,y=val,group=1)) +
>> geom_line() +
>> labs(title=chnm)
>> }
>> chfn("b") # test of the function - it works
>> chnms <- c("a","b","c")
>> for (i in chnms) {
>> chfn(i)
>> readline(prompt="Press [enter] to continue")
>> }
>> 
>> Thanks for your help.
>> 
>> Philip
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jun  3 04:26:25 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 14:26:25 +1200
Subject: [R] did bot execute
In-Reply-To: <044c21a6-f301-d033-cb4a-4fac2aaaa999@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
 <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>
 <044c21a6-f301-d033-cb4a-4fac2aaaa999@gmail.com>
Message-ID: <CAB8pepysZFJMJG_pv2gU8oLb0ubFwwWRP5m4cVbPhGVjC2zPrg@mail.gmail.com>

(excerpts only)
> Tried this new version but did not execute...
> Error in plot_ds(bat_call, "plot 2", c(25, 28), c(-15, 10), k1 = 1.25,  :
>   object 'bat_call' not found

I've used the bat_call object, from Jim's earlier post.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Jun  3 04:57:20 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 3 Jun 2020 14:57:20 +1200
Subject: [R] [FORGED] Re:  Chart will not display
In-Reply-To: <468ff0d758729c9cc9e091fd6c3ff444@philipsmith.ca>
References: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
 <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>
 <468ff0d758729c9cc9e091fd6c3ff444@philipsmith.ca>
Message-ID: <153bb184-4522-dc3c-9696-a44899102e37@auckland.ac.nz>


On 3/06/20 2:21 pm, phil at philipsmith.ca wrote:

> Thanks Bert. That did it.
> 
> Philip
> 
> On 2020-06-02 22:02, Bert Gunter wrote:
>> In a function you must explicitly print/plot the ggplot() object, I
>> assume. i.e. plot(ggplot(...)) etc.
>>
>> I do not use ggplot, so if I'm wrong, sorry.? But try it.? Hopefully
>> someone else will get it right if it doesn't do it.

<SNIP>

You might find fortunes::fortune(123) to relevant.  The comment was made 
in respect of the *lattice* package, but it would seem to apply equally 
to *ggplot2*.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun  3 16:55:48 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 3 Jun 2020 09:55:48 -0500
Subject: [R] how to filter variables which appear in any row but do not
 include
Message-ID: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>

Hello.

I am trying to filter only rows that have ANY of these variables:
E109, E119, E149

so I did:
controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))

than I checked what I got:
> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> d0=unlist(s0)
> d10=unique(d0)
> d10
 [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
[11] "E107"
s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
d1=unlist(s1)
d11=unique(d1)
> d11
 [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
[11] "E117"

I need help with changing this command
controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))

so that in the output I do not have any rows that include E102 or E112?

Thanks
Ana


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun  3 17:45:36 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 15:45:36 -0000
Subject: [R] iterators : checkFunc with ireadLines
In-Reply-To: <CAA99HCx_VvNJzTQ=mQ7zoRFX5ZJOA3mCgbDkMiCSPAH_6Zv=QA-7372@mail.gmail.com>
References: <72174dd3-a819-b5fd-5a6f-2a6b46342774-2015@free.fr>
 <CAA99HCwtOek_jaNsD6-=CtTRoL9OHYgDqfgdSAfbNBaEZ_w8JQ@mail.gmail.com>
 <a1ad0aec-7457-b516-1a3c-43e9e83d0ae1@free.fr>
 <CAA99HCx_VvNJzTQ=mQ7zoRFX5ZJOA3mCgbDkMiCSPAH_6Zv=QA-7372@mail.gmail.com>
Message-ID: <E2222FD6-1A53-4C9C-87BA-7AEFDB3C83BB-6702@dcn.davis.ca.us>


Laurent... Bill is suggesting building your own indexed database... but this has been done before, so re-inventing the wheel seems inefficient and risky. It is actually impossible to create such a beast without reading the entire file into memory at least temporarily anyway, so you are better off looking at ways to process the entire file efficiently.

For example, you could load the data into a sqlite database in a couple of lines of code and use SQL directly or use the sqldf data frame interface, or use dplyr to query the database.

Or you could look at read_csv_chunked from readr package.

On May 18, 2020 11:37:46 AM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>
>Hi Laurent,
>
>Thank you for explaining your size limitations. Below is an example
>using the read.fwf() function to grab the first column of your input
>file (in 2000 row chunks). This column is converted to an index, and
>the index is used to create an iterator useful for skipping lines when
>reading input with scan(). (You could try processing your large file
>in successive 2000 line chunks, or whatever number of lines fits into
>memory). Maybe not as elegant as the approach you were going for, but
>read.fwf() should be pretty efficient:
>
>> sensors <-  c("N053", "N163")
>> read.fwf("test2.txt", widths=c(4), as.is=TRUE, flush=TRUE, n=2000,
>skip=0)
>    V1
>1 Time
>2 N023
>3 N053
>4 N123
>5 N163
>6 N193
>> first_col <- read.fwf("test2.txt", widths=c(4), as.is=TRUE,
>flush=TRUE, n=2000, skip=0)
>> which(first_col$V1 %in% sensors)
>[1] 3 5
>> index1 <- which(first_col$V1 %in% sensors)
>> iter_index1 <- iter(1:2000, checkFunc= function(n) {n %in% index1})
>> unlist(scan(file="test2.txt",
>what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
> [1] "N053"      "-0.014083" "-0.004741" "0.001443"  "-0.010152"
>"-0.012996" "-0.005337" "-0.008738" "-0.015094" "-0.012104"
>> unlist(scan(file="test2.txt",
>what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
> [1] "N163"      "-0.054023" "-0.049345" "-0.037158" "-0.04112"
>"-0.044612" "-0.036953" "-0.036061" "-0.044516" "-0.046436"
>>
>
>(Note for this email and the previous one, I've deleted the first
>"hash" character from each line of your test file for clarity).
>
>HTH, Bill.
>
>W. Michels, Ph.D.
>
>
>
>
>
>On Mon, May 18, 2020 at 3:35 AM Laurent Rhelp <LaurentRHelp at free.fr>
>wrote:
>>
>> Dear William,
>>   Thank you for your answer
>> My file is very large so I cannot read it in my memory (I cannot use
>> read.table). So I want to put in memory only the line I need to
>process.
>> With readLines, as I did, it works but I would like to use an
>iterator
>> and a foreach loop to understand this way to do because I thought
>that
>> it was a better solution to write a nice code.
>>
>>
>> Le 18/05/2020 ? 04:54, William Michels a ?crit :
>> > Apologies, Laurent, for this two-part answer. I misunderstood your
>> > post where you stated you wanted to "filter(ing) some
>> > selected lines according to the line name... ." I thought that
>meant
>> > you had a separate index (like a series of primes) that you wanted
>to
>> > use to only read-in selected line numbers from a file (test file
>below
>> > with numbers 1:1000 each on a separate line):
>> >
>> >> library(gmp)
>> >> library(iterators)
>> >> iprime <- iter(1:100, checkFunc = function(n) isprime(n))
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 2
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 3
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 5
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 7
>> > However, what it really seems that you want to do is read each line
>of
>> > a (possibly enormous) file, test each line "string-wise" to keep or
>> > discard, and if you're keeping it, append the line to a list. I can
>> > certainly see the advantage of this strategy for reading in very,
>very
>> > large files, but it's not clear to me how the "ireadLines" function
>(
>> > in the "iterators" package) will help you, since it doesn't seem to
>> > generate anything but a sequential index.
>> >
>> > Anyway, below is an absolutely standard read-in of your data using
>> > read.table(). Hopefully some of the code I've posted has been
>useful
>> > to you.
>> >
>> >> sensors <-  c("N053", "N163")
>> >> read.table("test2.txt")
>> >      V1        V2        V3        V4        V5        V6        V7
>> >     V8        V9       V10
>> > 1 Time  0.000000  0.000999  0.001999  0.002998  0.003998  0.004997
>> > 0.005997  0.006996  0.007996
>> > 2 N023 -0.031323 -0.035026 -0.029759 -0.024886 -0.024464 -0.026816
>> > -0.033690 -0.041067 -0.038747
>> > 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>> > -0.008738 -0.015094 -0.012104
>> > 4 N123 -0.019008 -0.013494 -0.013180 -0.029208 -0.032748 -0.020243
>> > -0.015089 -0.014439 -0.011681
>> > 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>> > -0.036061 -0.044516 -0.046436
>> > 6 N193 -0.022171 -0.022384 -0.022338 -0.023304 -0.022569 -0.021827
>> > -0.021996 -0.021755 -0.021846
>> >> Laurent_data <- read.table("test2.txt")
>> >> Laurent_data[Laurent_data$V1 %in% sensors, ]
>> >      V1        V2        V3        V4        V5        V6        V7
>> >     V8        V9       V10
>> > 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>> > -0.008738 -0.015094 -0.012104
>> > 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>> > -0.036061 -0.044516 -0.046436
>> >
>> > Best, Bill.
>> >
>> > W. Michels, Ph.D.
>> >
>> >
>> > On Sun, May 17, 2020 at 5:43 PM Laurent Rhelp
><LaurentRHelp at free.fr> wrote:
>> >> Dear R-Help List,
>> >>
>> >>      I would like to use an iterator to read a file filtering some
>> >> selected lines according to the line name in order to use after a
>> >> foreach loop. I wanted to use the checkFunc argument as the
>following
>> >> example found on internet to select only prime numbers :
>> >>
>> >> |                                iprime <- ||iter||(1:100,
>checkFunc =
>> >> ||function||(n) ||isprime||(n))|
>> >>
>> >> |(https://datawookie.netlify.app/blog/2013/11/iterators-in-r/)
>> >> <https://datawookie.netlify.app/blog/2013/11/iterators-in-r/>|
>> >>
>> >> but the checkFunc argument seems not to be available with the
>function
>> >> ireadLines (package iterators). So, I did the code below to solve
>my
>> >> problem but I am sure that I miss something to use iterators with
>files.
>> >> Since I found nothing on the web about ireadLines and the
>checkFunc
>> >> argument, could somebody help me to understand how we have to use
>> >> iterator (and foreach loop) on files keeping only selected lines ?
>> >>
>> >> Thank you very much
>> >> Laurent
>> >>
>> >> Presently here is my code:
>> >>
>> >> ##        mock file to read: test.txt
>> >> ##
>> >> # Time    0    0.000999    0.001999    0.002998    0.003998
>0.004997
>> >> 0.005997    0.006996    0.007996
>> >> # N023    -0.031323    -0.035026    -0.029759    -0.024886
>-0.024464
>> >> -0.026816    -0.03369    -0.041067    -0.038747
>> >> # N053    -0.014083    -0.004741    0.001443    -0.010152
>-0.012996
>> >> -0.005337    -0.008738    -0.015094    -0.012104
>> >> # N123    -0.019008    -0.013494    -0.01318    -0.029208
>-0.032748
>> >> -0.020243    -0.015089    -0.014439    -0.011681
>> >> # N163    -0.054023    -0.049345    -0.037158    -0.04112
>-0.044612
>> >> -0.036953    -0.036061    -0.044516    -0.046436
>> >> # N193    -0.022171    -0.022384    -0.022338    -0.023304
>-0.022569
>> >> -0.021827    -0.021996    -0.021755    -0.021846
>> >>
>> >>
>> >> # sensors to keep
>> >>
>> >> sensors <-  c("N053", "N163")
>> >>
>> >>
>> >> library(iterators)
>> >>
>> >> library(rlist)
>> >>
>> >>
>> >> file_name <- "test.txt"
>> >>
>> >> con_obj <- file( file_name , "r")
>> >> ifile <- ireadLines( con_obj , n = 1 )
>> >>
>> >>
>> >> ## I do not do a loop for the example
>> >>
>> >> res <- list()
>> >>
>> >> r <- get_Lines_iter( ifile , sensors)
>> >> res <- list.append( res , r )
>> >> res
>> >> r <- get_Lines_iter( ifile , sensors)
>> >> res <- list.append( res , r )
>> >> res
>> >> r <- get_Lines_iter( ifile , sensors)
>> >> do.call("cbind",res)
>> >>
>> >> ## the function get_Lines_iter to select and process the line
>> >>
>> >> get_Lines_iter  <-  function( iter , sensors, sep = '\t', quiet =
>FALSE){
>> >>     ## read the next record in the iterator
>> >>     r = try( nextElem(iter) )
>> >>    while(  TRUE ){
>> >>       if( class(r) == "try-error") {
>> >>             return( stop("The iterator is empty") )
>> >>      } else {
>> >>      ## split the read line according to the separator
>> >>       r_txt <- textConnection(r)
>> >>       fields <- scan(file = r_txt, what = "character", sep = sep,
>quiet =
>> >> quiet)
>> >>        ## test if we have to keep the line
>> >>        if( fields[1] %in% sensors){
>> >>          ## data processing for the selected line (for the example
>> >> transformation in dataframe)
>> >>          n <- length(fields)
>> >>          x <- data.frame( as.numeric(fields[2:n]) )
>> >>          names(x) <- fields[1]
>> >>          ## We return the values
>> >>          print(paste0("sensor ",fields[1]," ok"))
>> >>          return( x )
>> >>        }else{
>> >>         print(paste0("Sensor ", fields[1] ," not selected"))
>> >>         r = try(nextElem(iter) )}
>> >>      }
>> >> }# end while loop
>> >> }
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e
>par le logiciel antivirus Avast.
>> >> https://www.avast.com/antivirus
>> >>
>> >>          [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par
>le logiciel antivirus Avast.
>> https://www.avast.com/antivirus
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From L@urentRHe|p @end|ng |rom |ree@|r  Wed Jun  3 17:46:00 2020
From: L@urentRHe|p @end|ng |rom |ree@|r (Laurent Rhelp)
Date: Wed, 03 Jun 2020 15:46:00 -0000
Subject: [R] iterators : checkFunc with ireadLines
In-Reply-To: <E2222FD6-1A53-4C9C-87BA-7AEFDB3C83BB@dcn.davis.ca.us>
References: <72174dd3-a819-b5fd-5a6f-2a6b46342774-2015@free.fr>
 <CAA99HCwtOek_jaNsD6-=CtTRoL9OHYgDqfgdSAfbNBaEZ_w8JQ@mail.gmail.com>
 <a1ad0aec-7457-b516-1a3c-43e9e83d0ae1@free.fr>
 <CAA99HCx_VvNJzTQ=mQ7zoRFX5ZJOA3mCgbDkMiCSPAH_6Zv=QA-7372@mail.gmail.com>
 <E2222FD6-1A53-4C9C-87BA-7AEFDB3C83BB@dcn.davis.ca.us>
Message-ID: <f0a8e687-c79e-c748-564a-f93cc3fdee23-3078@free.fr>


Ok, thank you for the advice I will take some time to see in details 
these packages.


Le 19/05/2020 ? 05:44, Jeff Newmiller a ?crit?:
> Laurent... Bill is suggesting building your own indexed database... but this has been done before, so re-inventing the wheel seems inefficient and risky. It is actually impossible to create such a beast without reading the entire file into memory at least temporarily anyway, so you are better off looking at ways to process the entire file efficiently.
>
> For example, you could load the data into a sqlite database in a couple of lines of code and use SQL directly or use the sqldf data frame interface, or use dplyr to query the database.
>
> Or you could look at read_csv_chunked from readr package.
>
> On May 18, 2020 11:37:46 AM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>> Hi Laurent,
>>
>> Thank you for explaining your size limitations. Below is an example
>> using the read.fwf() function to grab the first column of your input
>> file (in 2000 row chunks). This column is converted to an index, and
>> the index is used to create an iterator useful for skipping lines when
>> reading input with scan(). (You could try processing your large file
>> in successive 2000 line chunks, or whatever number of lines fits into
>> memory). Maybe not as elegant as the approach you were going for, but
>> read.fwf() should be pretty efficient:
>>
>>> sensors <-  c("N053", "N163")
>>> read.fwf("test2.txt", widths=c(4), as.is=TRUE, flush=TRUE, n=2000,
>> skip=0)
>>     V1
>> 1 Time
>> 2 N023
>> 3 N053
>> 4 N123
>> 5 N163
>> 6 N193
>>> first_col <- read.fwf("test2.txt", widths=c(4), as.is=TRUE,
>> flush=TRUE, n=2000, skip=0)
>>> which(first_col$V1 %in% sensors)
>> [1] 3 5
>>> index1 <- which(first_col$V1 %in% sensors)
>>> iter_index1 <- iter(1:2000, checkFunc= function(n) {n %in% index1})
>>> unlist(scan(file="test2.txt",
>> what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>> skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
>> [1] "N053"      "-0.014083" "-0.004741" "0.001443"  "-0.010152"
>> "-0.012996" "-0.005337" "-0.008738" "-0.015094" "-0.012104"
>>> unlist(scan(file="test2.txt",
>> what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>> skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
>> [1] "N163"      "-0.054023" "-0.049345" "-0.037158" "-0.04112"
>> "-0.044612" "-0.036953" "-0.036061" "-0.044516" "-0.046436"
>> (Note for this email and the previous one, I've deleted the first
>> "hash" character from each line of your test file for clarity).
>>
>> HTH, Bill.
>>
>> W. Michels, Ph.D.
>>
>>
>>
>>
>>
>> On Mon, May 18, 2020 at 3:35 AM Laurent Rhelp <LaurentRHelp at free.fr>
>> wrote:
>>> Dear William,
>>>    Thank you for your answer
>>> My file is very large so I cannot read it in my memory (I cannot use
>>> read.table). So I want to put in memory only the line I need to
>> process.
>>> With readLines, as I did, it works but I would like to use an
>> iterator
>>> and a foreach loop to understand this way to do because I thought
>> that
>>> it was a better solution to write a nice code.
>>>
>>>
>>> Le 18/05/2020 ? 04:54, William Michels a ?crit :
>>>> Apologies, Laurent, for this two-part answer. I misunderstood your
>>>> post where you stated you wanted to "filter(ing) some
>>>> selected lines according to the line name... ." I thought that
>> meant
>>>> you had a separate index (like a series of primes) that you wanted
>> to
>>>> use to only read-in selected line numbers from a file (test file
>> below
>>>> with numbers 1:1000 each on a separate line):
>>>>
>>>>> library(gmp)
>>>>> library(iterators)
>>>>> iprime <- iter(1:100, checkFunc = function(n) isprime(n))
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 2
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 3
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 5
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 7
>>>> However, what it really seems that you want to do is read each line
>> of
>>>> a (possibly enormous) file, test each line "string-wise" to keep or
>>>> discard, and if you're keeping it, append the line to a list. I can
>>>> certainly see the advantage of this strategy for reading in very,
>> very
>>>> large files, but it's not clear to me how the "ireadLines" function
>> (
>>>> in the "iterators" package) will help you, since it doesn't seem to
>>>> generate anything but a sequential index.
>>>>
>>>> Anyway, below is an absolutely standard read-in of your data using
>>>> read.table(). Hopefully some of the code I've posted has been
>> useful
>>>> to you.
>>>>
>>>>> sensors <-  c("N053", "N163")
>>>>> read.table("test2.txt")
>>>>       V1        V2        V3        V4        V5        V6        V7
>>>>      V8        V9       V10
>>>> 1 Time  0.000000  0.000999  0.001999  0.002998  0.003998  0.004997
>>>> 0.005997  0.006996  0.007996
>>>> 2 N023 -0.031323 -0.035026 -0.029759 -0.024886 -0.024464 -0.026816
>>>> -0.033690 -0.041067 -0.038747
>>>> 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>>>> -0.008738 -0.015094 -0.012104
>>>> 4 N123 -0.019008 -0.013494 -0.013180 -0.029208 -0.032748 -0.020243
>>>> -0.015089 -0.014439 -0.011681
>>>> 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>>>> -0.036061 -0.044516 -0.046436
>>>> 6 N193 -0.022171 -0.022384 -0.022338 -0.023304 -0.022569 -0.021827
>>>> -0.021996 -0.021755 -0.021846
>>>>> Laurent_data <- read.table("test2.txt")
>>>>> Laurent_data[Laurent_data$V1 %in% sensors, ]
>>>>       V1        V2        V3        V4        V5        V6        V7
>>>>      V8        V9       V10
>>>> 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>>>> -0.008738 -0.015094 -0.012104
>>>> 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>>>> -0.036061 -0.044516 -0.046436
>>>>
>>>> Best, Bill.
>>>>
>>>> W. Michels, Ph.D.
>>>>
>>>>
>>>> On Sun, May 17, 2020 at 5:43 PM Laurent Rhelp
>> <LaurentRHelp at free.fr> wrote:
>>>>> Dear R-Help List,
>>>>>
>>>>>       I would like to use an iterator to read a file filtering some
>>>>> selected lines according to the line name in order to use after a
>>>>> foreach loop. I wanted to use the checkFunc argument as the
>> following
>>>>> example found on internet to select only prime numbers :
>>>>>
>>>>> |                                iprime <- ||iter||(1:100,
>> checkFunc =
>>>>> ||function||(n) ||isprime||(n))|
>>>>>
>>>>> |(https://datawookie.netlify.app/blog/2013/11/iterators-in-r/)
>>>>> <https://datawookie.netlify.app/blog/2013/11/iterators-in-r/>|
>>>>>
>>>>> but the checkFunc argument seems not to be available with the
>> function
>>>>> ireadLines (package iterators). So, I did the code below to solve
>> my
>>>>> problem but I am sure that I miss something to use iterators with
>> files.
>>>>> Since I found nothing on the web about ireadLines and the
>> checkFunc
>>>>> argument, could somebody help me to understand how we have to use
>>>>> iterator (and foreach loop) on files keeping only selected lines ?
>>>>>
>>>>> Thank you very much
>>>>> Laurent
>>>>>
>>>>> Presently here is my code:
>>>>>
>>>>> ##        mock file to read: test.txt
>>>>> ##
>>>>> # Time    0    0.000999    0.001999    0.002998    0.003998
>> 0.004997
>>>>> 0.005997    0.006996    0.007996
>>>>> # N023    -0.031323    -0.035026    -0.029759    -0.024886
>> -0.024464
>>>>> -0.026816    -0.03369    -0.041067    -0.038747
>>>>> # N053    -0.014083    -0.004741    0.001443    -0.010152
>> -0.012996
>>>>> -0.005337    -0.008738    -0.015094    -0.012104
>>>>> # N123    -0.019008    -0.013494    -0.01318    -0.029208
>> -0.032748
>>>>> -0.020243    -0.015089    -0.014439    -0.011681
>>>>> # N163    -0.054023    -0.049345    -0.037158    -0.04112
>> -0.044612
>>>>> -0.036953    -0.036061    -0.044516    -0.046436
>>>>> # N193    -0.022171    -0.022384    -0.022338    -0.023304
>> -0.022569
>>>>> -0.021827    -0.021996    -0.021755    -0.021846
>>>>>
>>>>>
>>>>> # sensors to keep
>>>>>
>>>>> sensors <-  c("N053", "N163")
>>>>>
>>>>>
>>>>> library(iterators)
>>>>>
>>>>> library(rlist)
>>>>>
>>>>>
>>>>> file_name <- "test.txt"
>>>>>
>>>>> con_obj <- file( file_name , "r")
>>>>> ifile <- ireadLines( con_obj , n = 1 )
>>>>>
>>>>>
>>>>> ## I do not do a loop for the example
>>>>>
>>>>> res <- list()
>>>>>
>>>>> r <- get_Lines_iter( ifile , sensors)
>>>>> res <- list.append( res , r )
>>>>> res
>>>>> r <- get_Lines_iter( ifile , sensors)
>>>>> res <- list.append( res , r )
>>>>> res
>>>>> r <- get_Lines_iter( ifile , sensors)
>>>>> do.call("cbind",res)
>>>>>
>>>>> ## the function get_Lines_iter to select and process the line
>>>>>
>>>>> get_Lines_iter  <-  function( iter , sensors, sep = '\t', quiet =
>> FALSE){
>>>>>      ## read the next record in the iterator
>>>>>      r = try( nextElem(iter) )
>>>>>     while(  TRUE ){
>>>>>        if( class(r) == "try-error") {
>>>>>              return( stop("The iterator is empty") )
>>>>>       } else {
>>>>>       ## split the read line according to the separator
>>>>>        r_txt <- textConnection(r)
>>>>>        fields <- scan(file = r_txt, what = "character", sep = sep,
>> quiet =
>>>>> quiet)
>>>>>         ## test if we have to keep the line
>>>>>         if( fields[1] %in% sensors){
>>>>>           ## data processing for the selected line (for the example
>>>>> transformation in dataframe)
>>>>>           n <- length(fields)
>>>>>           x <- data.frame( as.numeric(fields[2:n]) )
>>>>>           names(x) <- fields[1]
>>>>>           ## We return the values
>>>>>           print(paste0("sensor ",fields[1]," ok"))
>>>>>           return( x )
>>>>>         }else{
>>>>>          print(paste0("Sensor ", fields[1] ," not selected"))
>>>>>          r = try(nextElem(iter) )}
>>>>>       }
>>>>> }# end while loop
>>>>> }
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e
>> par le logiciel antivirus Avast.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> --
>>> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par
>> le logiciel antivirus Avast.
>>> https://www.avast.com/antivirus
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le logiciel antivirus Avast.
https://www.avast.com/antivirus


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  3 18:00:39 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 3 Jun 2020 09:00:39 -0700
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
Message-ID: <CAGxFJbRMBP1xC-uEqeV6bpHVCa+dRrmBmJr4PZZt8MH-44AGMA@mail.gmail.com>

I suggest that you forget all that fancy stuff  (and this is not a use case
for regular expressions).
Use %in%  with logical subscripting instead -- basic R functionality that
can be found in any good R tutorial.

> x <- c("ab","bc","cd")
> x[x %in% c("ab","cd")]
[1] "ab" "cd"
> x[!x %in% c("ab","cd")]
[1] "bc"


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 3, 2020 at 7:56 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello.
>
> I am trying to filter only rows that have ANY of these variables:
> E109, E119, E149
>
> so I did:
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> than I checked what I got:
> > s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> > d0=unlist(s0)
> > d10=unique(d0)
> > d10
>  [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> [11] "E107"
> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> d1=unlist(s1)
> d11=unique(d1)
> > d11
>  [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> [11] "E117"
>
> I need help with changing this command
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> so that in the output I do not have any rows that include E102 or E112?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun  3 18:28:55 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 3 Jun 2020 11:28:55 -0500
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAGxFJbRMBP1xC-uEqeV6bpHVCa+dRrmBmJr4PZZt8MH-44AGMA@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <CAGxFJbRMBP1xC-uEqeV6bpHVCa+dRrmBmJr4PZZt8MH-44AGMA@mail.gmail.com>
Message-ID: <CAF9-5jM_F65ZHtzejqK4U1F4KC3PVD6Mj7YgxOrtHQ44aR+chA@mail.gmail.com>

Hi Bert

The issue is that I have around 2000 columns so I can not be checking if
those two are not present in each column of any row ?by hand? so to
speak....And I need my output to be a data frame where neither E102 nor
E112 are present. Basically from the data frame columns that I already
created just remove any row that contains any of those variables.

Thanks
Ana

On Wed, 3 Jun 2020 at 11:00, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I suggest that you forget all that fancy stuff  (and this is not a use
> case for regular expressions).
> Use %in%  with logical subscripting instead -- basic R functionality that
> can be found in any good R tutorial.
>
> > x <- c("ab","bc","cd")
> > x[x %in% c("ab","cd")]
> [1] "ab" "cd"
> > x[!x %in% c("ab","cd")]
> [1] "bc"
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Jun 3, 2020 at 7:56 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hello.
>>
>> I am trying to filter only rows that have ANY of these variables:
>> E109, E119, E149
>>
>> so I did:
>> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>>
>> than I checked what I got:
>> > s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
>> > d0=unlist(s0)
>> > d10=unique(d0)
>> > d10
>>  [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
>> [11] "E107"
>> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
>> d1=unlist(s1)
>> d11=unique(d1)
>> > d11
>>  [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
>> [11] "E117"
>>
>> I need help with changing this command
>> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>>
>> so that in the output I do not have any rows that include E102 or E112?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jun  3 10:59:06 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 3 Jun 2020 09:59:06 +0100
Subject: [R] Yearly hourly mean and NA
Message-ID: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>

Dear R-Experts,
I have a cosmic ray data that span several years. The data frame is of the
form:
03 01 01 00    3809
03 01 01 01    3771
03 01 01 02    3743
03 01 01 03    3747
03 01 01 04    3737
03 01 01 05    3751
03 01 01 06    3733
03 01 01 07    3732.
where the columns 1 to 5 stand for year, month, day, hour and counts.
Some hours when the station does not have data are assigned zero, implying
there could be several zeros in column 5. Since my aim is to plot the
hourly mean for all the  years, I started learning with one year - year
2003.

I carefully went through the data, removing any day that contains zero for
any of the hours.  Instead of the 365 days in the year 2003, I ended up
with 362 days.

I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
attached please).

If I run the data with my script, it gives me what I am expecting. My
script is:
d<-read.table("CLMX1C",col.names=c("h","count"))
y<-d$count
data<-(y-mean(y))/mean(y)*100

A<-matrix(rep(1:24,362))
B<-matrix(data)

 oodf<-data.frame(A,B)
 oodf<-data.frame(A,B)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
 xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
dispersion(1:24,oomean,oose,arrow.cap=.01)

Now, instead of foraging through the big data removing the day for which
there is a missing data for any hour, I wish to try to replace the missing
data with NA and hoping that it will do the job for me.

I added just three lines in the script above:
d<-read.table("2003",col.names=c("y","m","d","h","count"))
y<-d$count
df<-data.frame(y)#line 1
library('dplyr') # line 2
y<-na_if(df, 0) #line 3
data<-(y-mean(y))/mean(y)*100.
Then I started getting error messages:
Error in is.data.frame(x) :
  (list) object cannot be coerced to type 'double'
In addition: There were 26 warnings (use warnings() to see them).

I hope you will assist me to deal with the issues of replacing zeros with
NA in column 5 in such a way that my code will run.

Iam ever indebted!!
Best regards
Ogbos

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun  3 18:50:19 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Jun 2020 17:50:19 +0100
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
Message-ID: <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>

Hello,

If you want to filter out rows with any of the values in a 'unwanted' 
vector, try the following.

First, create a test data set.

x <- scan(what = character(), text = '
"E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
"E107" "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
"E117"
')

set.seed(2020)
dat <- replicate(5, sample(x, 20, TRUE))
dat <- as.data.frame(dat)


Now, remove all rows that have at least one of "E102" or "E112"


unwanted <- c("E102", "E112")
no <- sapply(dat, function(x){
   grepl(paste(unwanted, collapse = "|"), x)
})
no <- apply(no, 1, any)
dat[!no, ]


That's it, if I understood the problem.


Hope this helps,

Rui Barradas


?s 15:55 de 03/06/20, Ana Marija escreveu:
> Hello.
> 
> I am trying to filter only rows that have ANY of these variables:
> E109, E119, E149
> 
> so I did:
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> 
> than I checked what I got:
>> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
>> d0=unlist(s0)
>> d10=unique(d0)
>> d10
>   [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> [11] "E107"
> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> d1=unlist(s1)
> d11=unique(d1)
>> d11
>   [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> [11] "E117"
> 
> I need help with changing this command
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> 
> so that in the output I do not have any rows that include E102 or E112?
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Jun  3 19:19:26 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 3 Jun 2020 10:19:26 -0700
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
Message-ID: <CAA99HCzKnKuGSQF_B26m1X5fHB4kB9Y5_LSp0kniSjjUqz9Q2A@mail.gmail.com>

#Below returns long list of TRUE/FALSE values,
#Note: "IDs" is a column name,
#Wrap with head() to shorten:
df$IDs %in% c("ident_1", "ident_2");

#Below returns index of IDs that are TRUE,
#Wrap with head() to shorten:
which(df$IDs %in% c("ident_1", "ident_2"));

#Below returns short TRUE/FALSE table:
table(df$IDs %in% c("ident_1", "ident_2"));

#Below check df to see unique IDs returned by "%in%" code above,
#(Good for identifying missing "desired" IDs):
unique(df[df$IDs %in% c("ident_1", "ident_2"), "IDs"]);

#Below returns dimensions of dataframe "filtered" (retained) by desired IDs,
#(Note rows below should equal number of TRUE in table above):
dim(df[df$IDs %in% c("ident_1", "ident_2"), ]);

#Create filtered dataframe object:
df_filtered  <-  df[df$IDs %in% c("ident_1", "ident_2"),  ];

#Below returns row counts per "IDs" ("ident_1", "ident_2", etc.) in df_filtered:
aggregate(df_filtered$IDs, by=list(df_filtered$IDs), FUN = "length");


HTH, Bill.

W. Michels, Ph.D.





On Wed, Jun 3, 2020 at 7:56 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello.
>
> I am trying to filter only rows that have ANY of these variables:
> E109, E119, E149
>
> so I did:
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> than I checked what I got:
> > s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> > d0=unlist(s0)
> > d10=unique(d0)
> > d10
>  [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> [11] "E107"
> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> d1=unlist(s1)
> d11=unique(d1)
> > d11
>  [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> [11] "E117"
>
> I need help with changing this command
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> so that in the output I do not have any rows that include E102 or E112?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  3 19:34:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 3 Jun 2020 10:34:47 -0700
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
Message-ID: <CAGxFJbRQWs6oh4YGr2EQaGRWQUARekgG4OUH9qSQRaXUCpxb2g@mail.gmail.com>

regex's are not needed. Using Rui's example:

> bad <- mapply(function(x) x %in% unwanted,dat)
> dat[!rowSums(bad),]

     V1   V2   V3   V4   V5
2  E117 E113 E119 E100  E10
4  E114  E11 E119 E119 E114
5  E109 E111 E103 E103 E100
7  E108 E113 E119 E117  E11
8  E114 E105  E10 E109 E110
9  E119 E116 E108 E118 E119
10 E100 E110 E104 E111 E101
13 E111 E116 E101 E110 E116
15 E103  E11 E108  E10 E113
16 E111 E117 E103 E115 E119
17 E104 E110 E104 E117 E114
19 E100 E108  E10 E111 E105
20 E109 E115 E117 E108 E106

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 3, 2020 at 9:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If you want to filter out rows with any of the values in a 'unwanted'
> vector, try the following.
>
> First, create a test data set.
>
> x <- scan(what = character(), text = '
> "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> "E107" "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116"
> "E112"
> "E117"
> ')
>
> set.seed(2020)
> dat <- replicate(5, sample(x, 20, TRUE))
> dat <- as.data.frame(dat)
>
>
> Now, remove all rows that have at least one of "E102" or "E112"
>
>
> unwanted <- c("E102", "E112")
> no <- sapply(dat, function(x){
>    grepl(paste(unwanted, collapse = "|"), x)
> })
> no <- apply(no, 1, any)
> dat[!no, ]
>
>
> That's it, if I understood the problem.
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 15:55 de 03/06/20, Ana Marija escreveu:
> > Hello.
> >
> > I am trying to filter only rows that have ANY of these variables:
> > E109, E119, E149
> >
> > so I did:
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > than I checked what I got:
> >> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> >> d0=unlist(s0)
> >> d10=unique(d0)
> >> d10
> >   [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106"
> "E102"
> > [11] "E107"
> > s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> > d1=unlist(s1)
> > d11=unique(d1)
> >> d11
> >   [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116"
> "E112"
> > [11] "E117"
> >
> > I need help with changing this command
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > so that in the output I do not have any rows that include E102 or E112?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun  3 19:49:58 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 3 Jun 2020 12:49:58 -0500
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
Message-ID: <CAF9-5jPbUespAJPR7kyekPKmbsT5_C987b+6wW5HUDVk9vV8vw@mail.gmail.com>

Hi Rui,

thank you so much, that is exactly what I needed!

Cheers,
Ana

On Wed, Jun 3, 2020 at 11:50 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> If you want to filter out rows with any of the values in a 'unwanted'
> vector, try the following.
>
> First, create a test data set.
>
> x <- scan(what = character(), text = '
> "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> "E107" "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> "E117"
> ')
>
> set.seed(2020)
> dat <- replicate(5, sample(x, 20, TRUE))
> dat <- as.data.frame(dat)
>
>
> Now, remove all rows that have at least one of "E102" or "E112"
>
>
> unwanted <- c("E102", "E112")
> no <- sapply(dat, function(x){
>    grepl(paste(unwanted, collapse = "|"), x)
> })
> no <- apply(no, 1, any)
> dat[!no, ]
>
>
> That's it, if I understood the problem.
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 15:55 de 03/06/20, Ana Marija escreveu:
> > Hello.
> >
> > I am trying to filter only rows that have ANY of these variables:
> > E109, E119, E149
> >
> > so I did:
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > than I checked what I got:
> >> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> >> d0=unlist(s0)
> >> d10=unique(d0)
> >> d10
> >   [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> > [11] "E107"
> > s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> > d1=unlist(s1)
> > d11=unique(d1)
> >> d11
> >   [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> > [11] "E117"
> >
> > I need help with changing this command
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > so that in the output I do not have any rows that include E102 or E112?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun  3 21:25:09 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Jun 2020 20:25:09 +0100
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAGxFJbRQWs6oh4YGr2EQaGRWQUARekgG4OUH9qSQRaXUCpxb2g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
 <CAGxFJbRQWs6oh4YGr2EQaGRWQUARekgG4OUH9qSQRaXUCpxb2g@mail.gmail.com>
Message-ID: <2361e4d4-98d8-60be-4af6-fe9daddf6e20@sapo.pt>

Hello,

I forgot about %in%. Maybe because in the OP there were regex's.
And rowSums is much faster than apply.

In my tests this is 7 times faster than mine but with

%in% instead of grepl and apply(no, 1, any)

Hope this helps,

Rui Barradas

?s 18:34 de 03/06/20, Bert Gunter escreveu:
> regex's are not needed. Using Rui's example:
> 
>  > bad <- mapply(function(x) x %in% unwanted,dat)
>  > dat[!rowSums(bad),]
> 
>  ? ?? V1 ? V2 ? V3 ? V4 ? V5
> 2 ?E117 E113 E119 E100 ?E10
> 4 ?E114 ?E11 E119 E119 E114
> 5 ?E109 E111 E103 E103 E100
> 7 ?E108 E113 E119 E117 ?E11
> 8 ?E114 E105 ?E10 E109 E110
> 9 ?E119 E116 E108 E118 E119
> 10 E100 E110 E104 E111 E101
> 13 E111 E116 E101 E110 E116
> 15 E103 ?E11 E108 ?E10 E113
> 16 E111 E117 E103 E115 E119
> 17 E104 E110 E104 E117 E114
> 19 E100 E108 ?E10 E111 E105
> 20 E109 E115 E117 E108 E106
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Jun 3, 2020 at 9:57 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     If you want to filter out rows with any of the values in a 'unwanted'
>     vector, try the following.
> 
>     First, create a test data set.
> 
>     x <- scan(what = character(), text = '
>     "E10"? "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
>     "E107" "E11"? "E119" "E113" "E115" "E111" "E114" "E110" "E118"
>     "E116" "E112"
>     "E117"
>     ')
> 
>     set.seed(2020)
>     dat <- replicate(5, sample(x, 20, TRUE))
>     dat <- as.data.frame(dat)
> 
> 
>     Now, remove all rows that have at least one of "E102" or "E112"
> 
> 
>     unwanted <- c("E102", "E112")
>     no <- sapply(dat, function(x){
>      ? ?grepl(paste(unwanted, collapse = "|"), x)
>     })
>     no <- apply(no, 1, any)
>     dat[!no, ]
> 
> 
>     That's it, if I understood the problem.
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 15:55 de 03/06/20, Ana Marija escreveu:
>      > Hello.
>      >
>      > I am trying to filter only rows that have ANY of these variables:
>      > E109, E119, E149
>      >
>      > so I did:
>      > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>      >
>      > than I checked what I got:
>      >> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
>      >> d0=unlist(s0)
>      >> d10=unique(d0)
>      >> d10
>      >? ?[1] "E10"? "E103" "E104" "E109" "E101" "E108" "E105" "E100"
>     "E106" "E102"
>      > [11] "E107"
>      > s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
>      > d1=unlist(s1)
>      > d11=unique(d1)
>      >> d11
>      >? ?[1] "E11"? "E119" "E113" "E115" "E111" "E114" "E110" "E118"
>     "E116" "E112"
>      > [11] "E117"
>      >
>      > I need help with changing this command
>      > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>      >
>      > so that in the output I do not have any rows that include E102 or
>     E112?
>      >
>      > Thanks
>      > Ana
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun  3 21:47:35 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 12:47:35 -0700
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
Message-ID: <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>

df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA

On June 3, 2020 1:59:06 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear R-Experts,
>I have a cosmic ray data that span several years. The data frame is of
>the
>form:
>03 01 01 00    3809
>03 01 01 01    3771
>03 01 01 02    3743
>03 01 01 03    3747
>03 01 01 04    3737
>03 01 01 05    3751
>03 01 01 06    3733
>03 01 01 07    3732.
>where the columns 1 to 5 stand for year, month, day, hour and counts.
>Some hours when the station does not have data are assigned zero,
>implying
>there could be several zeros in column 5. Since my aim is to plot the
>hourly mean for all the  years, I started learning with one year - year
>2003.
>
>I carefully went through the data, removing any day that contains zero
>for
>any of the hours.  Instead of the 365 days in the year 2003, I ended up
>with 362 days.
>
>I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
>attached please).
>
>If I run the data with my script, it gives me what I am expecting. My
>script is:
>d<-read.table("CLMX1C",col.names=c("h","count"))
>y<-d$count
>data<-(y-mean(y))/mean(y)*100
>
>A<-matrix(rep(1:24,362))
>B<-matrix(data)
>
> oodf<-data.frame(A,B)
> oodf<-data.frame(A,B)
>library(plotrix)
>std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
>oomean<-as.vector(by(oodf$B,oodf$A,mean))
>oose<-as.vector(by(oodf$B,oodf$A,std.error))
>plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
>dispersion(1:24,oomean,oose,arrow.cap=.01)
>
>Now, instead of foraging through the big data removing the day for
>which
>there is a missing data for any hour, I wish to try to replace the
>missing
>data with NA and hoping that it will do the job for me.
>
>I added just three lines in the script above:
>d<-read.table("2003",col.names=c("y","m","d","h","count"))
>y<-d$count
>df<-data.frame(y)#line 1
>library('dplyr') # line 2
>y<-na_if(df, 0) #line 3
>data<-(y-mean(y))/mean(y)*100.
>Then I started getting error messages:
>Error in is.data.frame(x) :
>  (list) object cannot be coerced to type 'double'
>In addition: There were 26 warnings (use warnings() to see them).
>
>I hope you will assist me to deal with the issues of replacing zeros
>with
>NA in column 5 in such a way that my code will run.
>
>Iam ever indebted!!
>Best regards
>Ogbos
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  4 04:14:05 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 19:14:05 -0700
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
Message-ID: <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>

Perhaps read ?mean...

On June 3, 2020 6:15:11 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>Thank you so much for your time.
>I tried your code. It successfully assigned NA to the zeros.
>
>But the main code seems not to work with the NAs. The mean, for
>example,
>resulted in NA. I am attaching the data for a period of one year  and
>the
>code which I use  in plotting the data. Maybe it might be easier for
>you to
>spot where I run into error (my plot was just empty).
>Thanks again.
>Best regards
>Ogbos
>
>
>On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
>>
>> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
><giftedlife2014 at gmail.com>
>> wrote:
>> >Dear R-Experts,
>> >I have a cosmic ray data that span several years. The data frame is
>of
>> >the
>> >form:
>> >03 01 01 00    3809
>> >03 01 01 01    3771
>> >03 01 01 02    3743
>> >03 01 01 03    3747
>> >03 01 01 04    3737
>> >03 01 01 05    3751
>> >03 01 01 06    3733
>> >03 01 01 07    3732.
>> >where the columns 1 to 5 stand for year, month, day, hour and
>counts.
>> >Some hours when the station does not have data are assigned zero,
>> >implying
>> >there could be several zeros in column 5. Since my aim is to plot
>the
>> >hourly mean for all the  years, I started learning with one year -
>year
>> >2003.
>> >
>> >I carefully went through the data, removing any day that contains
>zero
>> >for
>> >any of the hours.  Instead of the 365 days in the year 2003, I ended
>up
>> >with 362 days.
>> >
>> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
>> >attached please).
>> >
>> >If I run the data with my script, it gives me what I am expecting.
>My
>> >script is:
>> >d<-read.table("CLMX1C",col.names=c("h","count"))
>> >y<-d$count
>> >data<-(y-mean(y))/mean(y)*100
>> >
>> >A<-matrix(rep(1:24,362))
>> >B<-matrix(data)
>> >
>> > oodf<-data.frame(A,B)
>> > oodf<-data.frame(A,B)
>> >library(plotrix)
>> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
>> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
>> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
>> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
>> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
>> >dispersion(1:24,oomean,oose,arrow.cap=.01)
>> >
>> >Now, instead of foraging through the big data removing the day for
>> >which
>> >there is a missing data for any hour, I wish to try to replace the
>> >missing
>> >data with NA and hoping that it will do the job for me.
>> >
>> >I added just three lines in the script above:
>> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
>> >y<-d$count
>> >df<-data.frame(y)#line 1
>> >library('dplyr') # line 2
>> >y<-na_if(df, 0) #line 3
>> >data<-(y-mean(y))/mean(y)*100.
>> >Then I started getting error messages:
>> >Error in is.data.frame(x) :
>> >  (list) object cannot be coerced to type 'double'
>> >In addition: There were 26 warnings (use warnings() to see them).
>> >
>> >I hope you will assist me to deal with the issues of replacing zeros
>> >with
>> >NA in column 5 in such a way that my code will run.
>> >
>> >Iam ever indebted!!
>> >Best regards
>> >Ogbos
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jun  4 08:13:28 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 4 Jun 2020 07:13:28 +0100
Subject: [R] Yearly hourly mean and NA: SOLVED
In-Reply-To: <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
 <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
Message-ID: <CAC8ss31QG_0sVPCCJCs8gqD1xO5MFd5wUKPiQabhmRCvLTLYJg@mail.gmail.com>

Dear Jeff,
It worked!!! I took a second look at "?mean" as you suggested.
I then adjusted my code, inserting rm.na here and there until it was fine.
Thank you very much.
Warm regards.
Ogbos
On Thu, Jun 4, 2020 at 3:14 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Perhaps read ?mean...
>
> On June 3, 2020 6:15:11 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >Dear Jeff,
> >Thank you so much for your time.
> >I tried your code. It successfully assigned NA to the zeros.
> >
> >But the main code seems not to work with the NAs. The mean, for
> >example,
> >resulted in NA. I am attaching the data for a period of one year  and
> >the
> >code which I use  in plotting the data. Maybe it might be easier for
> >you to
> >spot where I run into error (my plot was just empty).
> >Thanks again.
> >Best regards
> >Ogbos
> >
> >
> >On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
> >>
> >> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
> ><giftedlife2014 at gmail.com>
> >> wrote:
> >> >Dear R-Experts,
> >> >I have a cosmic ray data that span several years. The data frame is
> >of
> >> >the
> >> >form:
> >> >03 01 01 00    3809
> >> >03 01 01 01    3771
> >> >03 01 01 02    3743
> >> >03 01 01 03    3747
> >> >03 01 01 04    3737
> >> >03 01 01 05    3751
> >> >03 01 01 06    3733
> >> >03 01 01 07    3732.
> >> >where the columns 1 to 5 stand for year, month, day, hour and
> >counts.
> >> >Some hours when the station does not have data are assigned zero,
> >> >implying
> >> >there could be several zeros in column 5. Since my aim is to plot
> >the
> >> >hourly mean for all the  years, I started learning with one year -
> >year
> >> >2003.
> >> >
> >> >I carefully went through the data, removing any day that contains
> >zero
> >> >for
> >> >any of the hours.  Instead of the 365 days in the year 2003, I ended
> >up
> >> >with 362 days.
> >> >
> >> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
> >> >attached please).
> >> >
> >> >If I run the data with my script, it gives me what I am expecting.
> >My
> >> >script is:
> >> >d<-read.table("CLMX1C",col.names=c("h","count"))
> >> >y<-d$count
> >> >data<-(y-mean(y))/mean(y)*100
> >> >
> >> >A<-matrix(rep(1:24,362))
> >> >B<-matrix(data)
> >> >
> >> > oodf<-data.frame(A,B)
> >> > oodf<-data.frame(A,B)
> >> >library(plotrix)
> >> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> >> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> >> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
> >> >dispersion(1:24,oomean,oose,arrow.cap=.01)
> >> >
> >> >Now, instead of foraging through the big data removing the day for
> >> >which
> >> >there is a missing data for any hour, I wish to try to replace the
> >> >missing
> >> >data with NA and hoping that it will do the job for me.
> >> >
> >> >I added just three lines in the script above:
> >> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
> >> >y<-d$count
> >> >df<-data.frame(y)#line 1
> >> >library('dplyr') # line 2
> >> >y<-na_if(df, 0) #line 3
> >> >data<-(y-mean(y))/mean(y)*100.
> >> >Then I started getting error messages:
> >> >Error in is.data.frame(x) :
> >> >  (list) object cannot be coerced to type 'double'
> >> >In addition: There were 26 warnings (use warnings() to see them).
> >> >
> >> >I hope you will assist me to deal with the issues of replacing zeros
> >> >with
> >> >NA in column 5 in such a way that my code will run.
> >> >
> >> >Iam ever indebted!!
> >> >Best regards
> >> >Ogbos
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  4 08:37:51 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 23:37:51 -0700
Subject: [R] Yearly hourly mean and NA: SOLVED
In-Reply-To: <CAC8ss31QG_0sVPCCJCs8gqD1xO5MFd5wUKPiQabhmRCvLTLYJg@mail.gmail.com>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
 <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
 <CAC8ss31QG_0sVPCCJCs8gqD1xO5MFd5wUKPiQabhmRCvLTLYJg@mail.gmail.com>
Message-ID: <61F5E22B-43C7-4F6E-8B65-4B5DE6A0EA8A@dcn.davis.ca.us>

Glad you had a positive experience with the documentation... there are many gems to be found there.

But I don't think rm.na will work... the na comes before the rm for some reason.

On June 3, 2020 11:13:28 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>It worked!!! I took a second look at "?mean" as you suggested.
>I then adjusted my code, inserting rm.na here and there until it was
>fine.
>Thank you very much.
>Warm regards.
>Ogbos
>On Thu, Jun 4, 2020 at 3:14 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Perhaps read ?mean...
>>
>> On June 3, 2020 6:15:11 PM PDT, Ogbos Okike
><giftedlife2014 at gmail.com>
>> wrote:
>> >Dear Jeff,
>> >Thank you so much for your time.
>> >I tried your code. It successfully assigned NA to the zeros.
>> >
>> >But the main code seems not to work with the NAs. The mean, for
>> >example,
>> >resulted in NA. I am attaching the data for a period of one year 
>and
>> >the
>> >code which I use  in plotting the data. Maybe it might be easier for
>> >you to
>> >spot where I run into error (my plot was just empty).
>> >Thanks again.
>> >Best regards
>> >Ogbos
>> >
>> >
>> >On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
>> >>
>> >> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
>> ><giftedlife2014 at gmail.com>
>> >> wrote:
>> >> >Dear R-Experts,
>> >> >I have a cosmic ray data that span several years. The data frame
>is
>> >of
>> >> >the
>> >> >form:
>> >> >03 01 01 00    3809
>> >> >03 01 01 01    3771
>> >> >03 01 01 02    3743
>> >> >03 01 01 03    3747
>> >> >03 01 01 04    3737
>> >> >03 01 01 05    3751
>> >> >03 01 01 06    3733
>> >> >03 01 01 07    3732.
>> >> >where the columns 1 to 5 stand for year, month, day, hour and
>> >counts.
>> >> >Some hours when the station does not have data are assigned zero,
>> >> >implying
>> >> >there could be several zeros in column 5. Since my aim is to plot
>> >the
>> >> >hourly mean for all the  years, I started learning with one year
>-
>> >year
>> >> >2003.
>> >> >
>> >> >I carefully went through the data, removing any day that contains
>> >zero
>> >> >for
>> >> >any of the hours.  Instead of the 365 days in the year 2003, I
>ended
>> >up
>> >> >with 362 days.
>> >> >
>> >> >I saved that as CLMX1C (now stored in Ogbos2 with dput function,
>see
>> >> >attached please).
>> >> >
>> >> >If I run the data with my script, it gives me what I am
>expecting.
>> >My
>> >> >script is:
>> >> >d<-read.table("CLMX1C",col.names=c("h","count"))
>> >> >y<-d$count
>> >> >data<-(y-mean(y))/mean(y)*100
>> >> >
>> >> >A<-matrix(rep(1:24,362))
>> >> >B<-matrix(data)
>> >> >
>> >> > oodf<-data.frame(A,B)
>> >> > oodf<-data.frame(A,B)
>> >> >library(plotrix)
>> >> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
>> >> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
>> >> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
>> >> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
>> >> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
>> >> >dispersion(1:24,oomean,oose,arrow.cap=.01)
>> >> >
>> >> >Now, instead of foraging through the big data removing the day
>for
>> >> >which
>> >> >there is a missing data for any hour, I wish to try to replace
>the
>> >> >missing
>> >> >data with NA and hoping that it will do the job for me.
>> >> >
>> >> >I added just three lines in the script above:
>> >> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
>> >> >y<-d$count
>> >> >df<-data.frame(y)#line 1
>> >> >library('dplyr') # line 2
>> >> >y<-na_if(df, 0) #line 3
>> >> >data<-(y-mean(y))/mean(y)*100.
>> >> >Then I started getting error messages:
>> >> >Error in is.data.frame(x) :
>> >> >  (list) object cannot be coerced to type 'double'
>> >> >In addition: There were 26 warnings (use warnings() to see them).
>> >> >
>> >> >I hope you will assist me to deal with the issues of replacing
>zeros
>> >> >with
>> >> >NA in column 5 in such a way that my code will run.
>> >> >
>> >> >Iam ever indebted!!
>> >> >Best regards
>> >> >Ogbos
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From c@t@||nro|bu @end|ng |rom gm@||@com  Thu Jun  4 15:06:28 2020
From: c@t@||nro|bu @end|ng |rom gm@||@com (Catalin Roibu)
Date: Thu, 4 Jun 2020 16:06:28 +0300
Subject: [R] consecutive n values
Message-ID: <CAEW+BDKYM9Yvbk75fMoOsZ_wqcPnXDJQF=3WNEvRcW_UTAe27g@mail.gmail.com>

Dear R users,

Please help me to detect consecutive n values in R and their interval.


rle.seq1<-rle(reco$extr)
cbind(rle.seq1$values)
index<-any(rle.seq1$values=="DRY"&rle.seq1$lengths>=3)
cumsum(rle.seq1$lengths)[index]

reco is a data frame with 2 columns (year and values (DRY, WET).

I want to have something like this:
1799-1800 - WET - 2
1803-1805 - WET - 3

Thank you very much!

All the best!

Catalin


   year extr
1   1768 <NA>
2   1769 <NA>
3   1770 <NA>
4   1771 <NA>
5   1772 <NA>
6   1773  DRY
7   1774 <NA>
8   1775 <NA>
9   1776 <NA>
10  1777  DRY
11  1778 <NA>
12  1779  DRY
13  1780  DRY
14  1781 <NA>
15  1782  DRY
16  1783 <NA>
17  1784 <NA>
18  1785 <NA>
19  1786 <NA>
20  1787 <NA>
21  1788 <NA>
22  1789 <NA>
23  1790 <NA>
24  1791 <NA>
25  1792 <NA>
26  1793 <NA>
27  1794 <NA>
28  1795  WET
29  1796 <NA>
30  1797 <NA>
31  1798 <NA>
32  1799  WET
33  1800  WET
34  1801 <NA>
35  1802 <NA>
36  1803  WET
37  1804  WET
38  1805  WET
39  1806 <NA>
40  1807 <NA>
41  1808 <NA>
42  1809 <NA>
43  1810  WET
44  1811 <NA>
45  1812 <NA>
46  1813  WET
47  1814  DRY
48  1815 <NA>
49  1816 <NA>
50  1817 <NA>
51  1818 <NA>
52  1819 <NA>
53  1820 <NA>
54  1821 <NA>
55  1822  WET
56  1823  WET
57  1824  WET
58  1825  WET
59  1826 <NA>
60  1827  DRY
61  1828  DRY
62  1829  WET
63  1830  WET
64  1831  WET
65  1832  WET
66  1833 <NA>
67  1834  DRY
68  1835  DRY
69  1836 <NA>
70  1837 <NA>
71  1838 <NA>
72  1839 <NA>
73  1840 <NA>
74  1841 <NA>
75  1842 <NA>
76  1843  WET
77  1844  WET
78  1845 <NA>
79  1846 <NA>
80  1847 <NA>
81  1848  DRY
82  1849  DRY
83  1850 <NA>
84  1851 <NA>
85  1852  WET
86  1853 <NA>
87  1854 <NA>
88  1855 <NA>
89  1856 <NA>
90  1857  WET
91  1858 <NA>
92  1859 <NA>
93  1860 <NA>
94  1861 <NA>
95  1862 <NA>
96  1863 <NA>
97  1864 <NA>
98  1865 <NA>
99  1866  DRY
100 1867  DRY
101 1868 <NA>
102 1869  DRY
103 1870 <NA>
104 1871  WET
105 1872 <NA>
106 1873 <NA>
107 1874  DRY
108 1875  DRY
109 1876 <NA>
110 1877 <NA>
111 1878 <NA>
112 1879 <NA>
113 1880  WET
114 1881  WET
115 1882 <NA>
116 1883 <NA>
117 1884 <NA>
118 1885 <NA>
119 1886  DRY
120 1887  DRY
121 1888  DRY
122 1889 <NA>
123 1890 <NA>
124 1891 <NA>
125 1892 <NA>
126 1893 <NA>
127 1894 <NA>
128 1895 <NA>
129 1896 <NA>
130 1897 <NA>
131 1898 <NA>
132 1899 <NA>
133 1900 <NA>
134 1901 <NA>
135 1902 <NA>
136 1903  WET
137 1904 <NA>
138 1905 <NA>
139 1906  WET
140 1907 <NA>
141 1908 <NA>
142 1909 <NA>
143 1910 <NA>
144 1911  WET
145 1912  WET
146 1913  WET
147 1914  WET
148 1915 <NA>
149 1916 <NA>
150 1917 <NA>
151 1918  DRY
152 1919 <NA>
153 1920 <NA>
154 1921  DRY
155 1922 <NA>
156 1923 <NA>
157 1924 <NA>
158 1925 <NA>
159 1926 <NA>
160 1927 <NA>
161 1928  DRY
162 1929 <NA>
163 1930 <NA>
164 1931 <NA>
165 1932 <NA>
166 1933 <NA>
167 1934 <NA>
168 1935 <NA>
169 1936 <NA>
170 1937 <NA>
171 1938 <NA>
172 1939 <NA>
173 1940 <NA>
174 1941 <NA>
175 1942 <NA>
176 1943 <NA>
177 1944  WET
178 1945 <NA>
179 1946  DRY
180 1947  DRY
181 1948  DRY
182 1949 <NA>
183 1950  WET
184 1951 <NA>
185 1952  DRY
186 1953 <NA>
187 1954 <NA>
188 1955  WET
189 1956 <NA>
190 1957 <NA>
191 1958 <NA>
192 1959  WET
193 1960 <NA>
194 1961 <NA>
195 1962 <NA>
196 1963 <NA>
197 1964  DRY
198 1965 <NA>
199 1966 <NA>
200 1967 <NA>
201 1968  DRY
202 1969  WET
203 1970  WET
204 1971 <NA>
205 1972 <NA>
206 1973 <NA>
207 1974  WET
208 1975  WET
209 1976 <NA>
210 1977 <NA>
211 1978 <NA>
212 1979 <NA>
213 1980 <NA>
214 1981 <NA>
215 1982  WET
216 1983  DRY
217 1984 <NA>
218 1985  DRY
219 1986 <NA>
220 1987 <NA>
221 1988  WET
222 1989  WET
223 1990  WET
224 1991 <NA>
225 1992 <NA>
226 1993 <NA>
227 1994 <NA>
228 1995  DRY
229 1996  DRY
230 1997  WET
231 1998 <NA>
232 1999 <NA>
233 2000  DRY
234 2001 <NA>
235 2002 <NA>
236 2003  DRY
237 2004 <NA>
238 2005 <NA>
239 2006 <NA>
240 2007 <NA>


-- 

-
-
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04.06.20,
16:04:35

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom he@|th@uc@d@edu  Thu Jun  4 19:27:52 2020
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Thu, 4 Jun 2020 17:27:52 +0000
Subject: [R] consecutive n values
In-Reply-To: <CAEW+BDKYM9Yvbk75fMoOsZ_wqcPnXDJQF=3WNEvRcW_UTAe27g@mail.gmail.com>
References: <CAEW+BDKYM9Yvbk75fMoOsZ_wqcPnXDJQF=3WNEvRcW_UTAe27g@mail.gmail.com>
Message-ID: <BB4283DA-8A05-470E-871B-E335EFA51488@health.ucsd.edu>

Catalin,

> On Jun 4, 2020, at 6:06 AM, Catalin Roibu <catalinroibu at gmail.com> wrote:
> 
> Dear R users,
> 
> Please help me to detect consecutive n values in R and their interval.
> 
> 
> rle.seq1<-rle(reco$extr)
> cbind(rle.seq1$values)
> index<-any(rle.seq1$values=="DRY"&rle.seq1$lengths>=3)
> cumsum(rle.seq1$lengths)[index]
> 
> reco is a data frame with 2 columns (year and values (DRY, WET).
> 
> I want to have something like this:
> 1799-1800 - WET - 2
> 1803-1805 - WET - 3
> 
> Thank you very much!


Something like:

  wd.rle <- rle(reco$extr)
  is.wet <- wd.rle[["values"]]=="WET"
  wd.rle[["values"]] <- ifelse(is.wet, cumsum( is.wet ), 0)
  wet.list <- split( reco$year, inverse.rle( wd.rle ) )[ -1 ]
  sapply( wet.list[ lengths(wet.list) > 1 ], range)

should get you started.

The last line returns:

:         2    3    6    7    8   12   15   20   21   23
: [1,] 1799 1803 1822 1829 1843 1880 1911 1969 1974 1988
: [2,] 1800 1805 1825 1832 1844 1881 1914 1970 1975 1990

You can use `apply' to further process this to get the desired format for your result.  

I assume here that reco$years are in groups of consecutive 'WET' years. 

If there are gaps or other oddities you will need to replace `range' with a function that handles that.

HTH,

Chuck


From @|m|n@@t@work @end|ng |rom gm@||@com  Thu Jun  4 05:17:23 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Wed, 3 Jun 2020 23:17:23 -0400
Subject: [R] ask help for ggplot
Message-ID: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>

I have a question about using ggplot.

Is there possible to generate a barplot like the attached file using ggplot?

Thank you,

Aimin

From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jun  4 03:15:11 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 4 Jun 2020 02:15:11 +0100
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
Message-ID: <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>

Dear Jeff,
Thank you so much for your time.
I tried your code. It successfully assigned NA to the zeros.

But the main code seems not to work with the NAs. The mean, for example,
resulted in NA. I am attaching the data for a period of one year  and the
code which I use  in plotting the data. Maybe it might be easier for you to
spot where I run into error (my plot was just empty).
Thanks again.
Best regards
Ogbos


On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
>
> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >Dear R-Experts,
> >I have a cosmic ray data that span several years. The data frame is of
> >the
> >form:
> >03 01 01 00    3809
> >03 01 01 01    3771
> >03 01 01 02    3743
> >03 01 01 03    3747
> >03 01 01 04    3737
> >03 01 01 05    3751
> >03 01 01 06    3733
> >03 01 01 07    3732.
> >where the columns 1 to 5 stand for year, month, day, hour and counts.
> >Some hours when the station does not have data are assigned zero,
> >implying
> >there could be several zeros in column 5. Since my aim is to plot the
> >hourly mean for all the  years, I started learning with one year - year
> >2003.
> >
> >I carefully went through the data, removing any day that contains zero
> >for
> >any of the hours.  Instead of the 365 days in the year 2003, I ended up
> >with 362 days.
> >
> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
> >attached please).
> >
> >If I run the data with my script, it gives me what I am expecting. My
> >script is:
> >d<-read.table("CLMX1C",col.names=c("h","count"))
> >y<-d$count
> >data<-(y-mean(y))/mean(y)*100
> >
> >A<-matrix(rep(1:24,362))
> >B<-matrix(data)
> >
> > oodf<-data.frame(A,B)
> > oodf<-data.frame(A,B)
> >library(plotrix)
> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
> >dispersion(1:24,oomean,oose,arrow.cap=.01)
> >
> >Now, instead of foraging through the big data removing the day for
> >which
> >there is a missing data for any hour, I wish to try to replace the
> >missing
> >data with NA and hoping that it will do the job for me.
> >
> >I added just three lines in the script above:
> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
> >y<-d$count
> >df<-data.frame(y)#line 1
> >library('dplyr') # line 2
> >y<-na_if(df, 0) #line 3
> >data<-(y-mean(y))/mean(y)*100.
> >Then I started getting error messages:
> >Error in is.data.frame(x) :
> >  (list) object cannot be coerced to type 'double'
> >In addition: There were 26 warnings (use warnings() to see them).
> >
> >I hope you will assist me to deal with the issues of replacing zeros
> >with
> >NA in column 5 in such a way that my code will run.
> >
> >Iam ever indebted!!
> >Best regards
> >Ogbos
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jun  4 08:49:59 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 4 Jun 2020 07:49:59 +0100
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
 <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
Message-ID: <CAC8ss33MCO9wvAOFjo8C2tuN9q-Q1orC_f6U6MMHa8LeoWt-SQ@mail.gmail.com>

Dear Jeff,
Yes. It worked. But I am still fine turning the script.
Please permit me to ask again.

Since I can handle one year. I wish to take on more years. I added extra
two years and now have 2000 to 2002.

I wish to plot the same graph for those years such that the x-axis will be
showing 2000, 2001 and 2002.  I tried to manipulate replicate function with
times and length.
I have a result but it does seem like what I am looking for. For each year,
I should get a similar graph. So the three years will just look like
similar plot repeated with some small differences. When I did per year and
added, I got it. But I could not add the error bars by doing them
separately for each year.

Here is part of my adjusted code:
d<-read.table("3years",col.names=c("y","m","d","h","count"))
y<-d$count
 data<-(y-mean(y,na.rm=TRUE))/mean(y,na.rm=TRUE)*100
A<-matrix(rep(1:24,366))
A1<-matrix(rep(25:49,365))
 A2<-matrix(rep(50:72,365))
A<-matrix(c(A,A1,A2),ncol=1)
I have also attached the complete code and data for the three years.
I am thanking you for any pointer.
Best regards
Ogbos

On Thu, Jun 4, 2020 at 3:14 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Perhaps read ?mean...
>
> On June 3, 2020 6:15:11 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >Dear Jeff,
> >Thank you so much for your time.
> >I tried your code. It successfully assigned NA to the zeros.
> >
> >But the main code seems not to work with the NAs. The mean, for
> >example,
> >resulted in NA. I am attaching the data for a period of one year  and
> >the
> >code which I use  in plotting the data. Maybe it might be easier for
> >you to
> >spot where I run into error (my plot was just empty).
> >Thanks again.
> >Best regards
> >Ogbos
> >
> >
> >On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
> >>
> >> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
> ><giftedlife2014 at gmail.com>
> >> wrote:
> >> >Dear R-Experts,
> >> >I have a cosmic ray data that span several years. The data frame is
> >of
> >> >the
> >> >form:
> >> >03 01 01 00    3809
> >> >03 01 01 01    3771
> >> >03 01 01 02    3743
> >> >03 01 01 03    3747
> >> >03 01 01 04    3737
> >> >03 01 01 05    3751
> >> >03 01 01 06    3733
> >> >03 01 01 07    3732.
> >> >where the columns 1 to 5 stand for year, month, day, hour and
> >counts.
> >> >Some hours when the station does not have data are assigned zero,
> >> >implying
> >> >there could be several zeros in column 5. Since my aim is to plot
> >the
> >> >hourly mean for all the  years, I started learning with one year -
> >year
> >> >2003.
> >> >
> >> >I carefully went through the data, removing any day that contains
> >zero
> >> >for
> >> >any of the hours.  Instead of the 365 days in the year 2003, I ended
> >up
> >> >with 362 days.
> >> >
> >> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
> >> >attached please).
> >> >
> >> >If I run the data with my script, it gives me what I am expecting.
> >My
> >> >script is:
> >> >d<-read.table("CLMX1C",col.names=c("h","count"))
> >> >y<-d$count
> >> >data<-(y-mean(y))/mean(y)*100
> >> >
> >> >A<-matrix(rep(1:24,362))
> >> >B<-matrix(data)
> >> >
> >> > oodf<-data.frame(A,B)
> >> > oodf<-data.frame(A,B)
> >> >library(plotrix)
> >> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> >> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> >> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
> >> >dispersion(1:24,oomean,oose,arrow.cap=.01)
> >> >
> >> >Now, instead of foraging through the big data removing the day for
> >> >which
> >> >there is a missing data for any hour, I wish to try to replace the
> >> >missing
> >> >data with NA and hoping that it will do the job for me.
> >> >
> >> >I added just three lines in the script above:
> >> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
> >> >y<-d$count
> >> >df<-data.frame(y)#line 1
> >> >library('dplyr') # line 2
> >> >y<-na_if(df, 0) #line 3
> >> >data<-(y-mean(y))/mean(y)*100.
> >> >Then I started getting error messages:
> >> >Error in is.data.frame(x) :
> >> >  (list) object cannot be coerced to type 'double'
> >> >In addition: There were 26 warnings (use warnings() to see them).
> >> >
> >> >I hope you will assist me to deal with the issues of replacing zeros
> >> >with
> >> >NA in column 5 in such a way that my code will run.
> >> >
> >> >Iam ever indebted!!
> >> >Best regards
> >> >Ogbos
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

From @turm|echen @end|ng |rom gm@||@com  Thu Jun  4 19:31:04 2020
From: @turm|echen @end|ng |rom gm@||@com (Lena Fehlhaber)
Date: Thu, 4 Jun 2020 19:31:04 +0200
Subject: [R] GLM model with spatialspillover on categorical variables
Message-ID: <CA+yGT=FjdTETUQ8hs=uSM0=4B6LQdWRZVfuk4iWP12OYhsTeZA@mail.gmail.com>

I did a regression analysis with categorical data with a glm model
approach, which worked fine. I have longitude and latitude coordinates for
each observation and I want to add their geographic spillover effect to the
model.

My sample data is structured:

Index DV IVI IVII IVIII IVIV Long Lat
 1  0  2  1  3  -12  -17.8  12
 2  0  1  1  6  112  11  -122
 3  1  3  6  1  91  57  53

with regression eq. DV ~ IVI + IVII + IVIII + IVIV

That mentioned, I assume that the nearer regions are, the more it may
influence my dependant variable. I found several approaches for spatial
regression models, but not for categorical data. I tried to use existing
libraries and functions, such as spdep's lagsarlm, glmmfields, spatialreg,
gstat, geoRglm and many more (I used this list as a reference:
https://cran.r-project.org/web/views/Spatial.html ). For numeric values, I
am able to do spatial regression, but for categorical values, I struggle.
The data structure is the following:

library(dplyr)
data <- data %>%
  mutate(
    DV = as.factor(DV),
    IVI = as.factor(IVI),
    IVII = as.factor(IVII),
    IVIII = as.factor(IVIII),
    IVIV = as.numeric(IVIV),
    longitude = as.numeric(longitude),
    latitude = as.numeric(latitude)
  )

My dependant variable (0|1) as well as my independant variables are
categorical and it would be no use to transform them, of course. I want to
have an other glm model in the end, but with spatial spillover effects
included. The libraries I tested so far can't handle categorical data. Any
leads/ideas would be greatly appreciated.

Thanks a lot.

	[[alternative HTML version deleted]]


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Thu Jun  4 19:56:22 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Thu, 4 Jun 2020 17:56:22 +0000
Subject: [R] na.omit not omitting rows
Message-ID: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>

Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.

> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, Shade))  #Create the dataframe with variables of interest from an attached dataset
> row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as rownames
> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
> str(Protect1)
'data.frame': 319 obs. of  4 variables:
 $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
 $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
 $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
 - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
  ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...

Dr. Ted Stankowich
Associate Professor
Department of Biological Sciences
California State University Long Beach
Long Beach, CA 90840
theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
562-985-4826
http://www.csulb.edu/mammal-lab/
@CSULBMammalLab




	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Thu Jun  4 21:38:45 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 4 Jun 2020 12:38:45 -0700
Subject: [R] na.omit not omitting rows
In-Reply-To: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>

Does droplevels() help?

> d <- data.frame(size = factor(c("S","M","M","L","L"),
levels=c("S","M","L")), id=c(101,NA,NA,104,105))
> str(d)
'data.frame':   5 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
 $ id  : num  101 NA NA 104 105
> str(na.omit(d))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 3 3
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"
> str(droplevels(na.omit(d)))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 2 levels "S","L": 1 2 2
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <
Theodore.Stankowich at csulb.edu> wrote:

> Hello! I'm trying to create a subset of a dataset and then remove all rows
> with NAs in them. Ultimately, I am running phylogenetic analyses with trees
> that require the tree tiplabels to match exactly with the rows in the
> dataframe. But when I use na.omit to delete the rows with NAs, there is
> still a trace of those omitted rows in the data.frame, which then causes an
> error in the phylogenetic analyses. Is there any way to completely scrub
> those omitted rows from the dataframe? The code is below. As you can see
> from the result of the final str(Protect1) line, there are attributes with
> the omitted features still in the dataframe (356 species names in the
> UphamComplBinomial factor, but only 319 observations). These traces are
> causing errors with the phylo analyses.
>
> > Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep,
> Shade))  #Create the dataframe with variables of interest from an attached
> dataset
> > row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as
> rownames
> > Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
> > str(Protect1)
> 'data.frame': 319 obs. of  4 variables:
>  $ UphamComplBinomial: Factor w/ 356 levels
> "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10
> 11 12 ...
>  $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>  $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>  $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53
> 17 49 52 52 39 39 41 ...
>  - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>   ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES"
> "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES"
> "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach
> Long Beach, CA 90840
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun  4 22:07:16 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 4 Jun 2020 13:07:16 -0700
Subject: [R] GLM model with spatialspillover on categorical variables
In-Reply-To: <CA+yGT=FjdTETUQ8hs=uSM0=4B6LQdWRZVfuk4iWP12OYhsTeZA@mail.gmail.com>
References: <CA+yGT=FjdTETUQ8hs=uSM0=4B6LQdWRZVfuk4iWP12OYhsTeZA@mail.gmail.com>
Message-ID: <CAGxFJbR3b-k-heaQPfSq4eRa1znRP8ctFys=j-FT_sEYiKQKMw@mail.gmail.com>

You should post on r-sig-geo, the list devoted to spatial data analysis,
rather than here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 4, 2020 at 12:17 PM Lena Fehlhaber <sturmiechen at gmail.com>
wrote:

> I did a regression analysis with categorical data with a glm model
> approach, which worked fine. I have longitude and latitude coordinates for
> each observation and I want to add their geographic spillover effect to the
> model.
>
> My sample data is structured:
>
> Index DV IVI IVII IVIII IVIV Long Lat
>  1  0  2  1  3  -12  -17.8  12
>  2  0  1  1  6  112  11  -122
>  3  1  3  6  1  91  57  53
>
> with regression eq. DV ~ IVI + IVII + IVIII + IVIV
>
> That mentioned, I assume that the nearer regions are, the more it may
> influence my dependant variable. I found several approaches for spatial
> regression models, but not for categorical data. I tried to use existing
> libraries and functions, such as spdep's lagsarlm, glmmfields, spatialreg,
> gstat, geoRglm and many more (I used this list as a reference:
> https://cran.r-project.org/web/views/Spatial.html ). For numeric values, I
> am able to do spatial regression, but for categorical values, I struggle.
> The data structure is the following:
>
> library(dplyr)
> data <- data %>%
>   mutate(
>     DV = as.factor(DV),
>     IVI = as.factor(IVI),
>     IVII = as.factor(IVII),
>     IVIII = as.factor(IVIII),
>     IVIV = as.numeric(IVIV),
>     longitude = as.numeric(longitude),
>     latitude = as.numeric(latitude)
>   )
>
> My dependant variable (0|1) as well as my independant variables are
> categorical and it would be no use to transform them, of course. I want to
> have an other glm model in the end, but with spatial spillover effects
> included. The libraries I tested so far can't handle categorical data. Any
> leads/ideas would be greatly appreciated.
>
> Thanks a lot.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Thu Jun  4 23:27:18 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Thu, 4 Jun 2020 21:27:18 +0000
Subject: [R] na.omit not omitting rows
In-Reply-To: <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
Message-ID: <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>

Thanks, but no that doesn?t work. The na.omit attributes are still in the dataframe, which you can see in the str outputs from the post. The problem line is likely:  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Thursday, June 4, 2020 12:39 PM
To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
Cc: r-help at r-project.org
Subject: Re: [R] na.omit not omitting rows

CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.

Does droplevels() help?

> d <- data.frame(size = factor(c("S","M","M","L","L"), levels=c("S","M","L")), id=c(101,NA,NA,104,105))
> str(d)
'data.frame':   5 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
 $ id  : num  101 NA NA 104 105
> str(na.omit(d))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 3 3
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"
> str(droplevels(na.omit(d)))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 2 levels "S","L": 1 2 2
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>


On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.

> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, Shade))  #Create the dataframe with variables of interest from an attached dataset
> row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as rownames
> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
> str(Protect1)
'data.frame': 319 obs. of  4 variables:
 $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
 $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
 $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
 - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
  ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...

Dr. Ted Stankowich
Associate Professor
Department of Biological Sciences
California State University Long Beach
Long Beach, CA 90840
theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><mailto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>>
562-985-4826
http://www.csulb.edu/mammal-lab/
@CSULBMammalLab




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jun  4 23:49:22 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 4 Jun 2020 22:49:22 +0100
Subject: [R] na.omit not omitting rows
In-Reply-To: <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
 <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <3f5abbbd-cb19-4ef2-11fb-6b0373b95d00@sapo.pt>

Hello,

If the problem is the "na.action" attribute, here are two ways of 
solving it.

First, an example data set.

set.seed(2020)    # Make the example reproducible
phamComplBinomial <- sprintf("f%003d", 1:356)
is.na(UphamComplBinomial) <- sample(356, 37)
DarkEum <- factor(sample(1:2, 356, TRUE))
Protect1 <- data.frame(UphamComplBinomial = factor(UphamComplBinomial), 
DarkEum)


1. Setting the attribute "na.action" to NULL removes it

Protect2 <- na.omit(Protect1)
attributes(Protect2)
attr(Protect2, "na.action") <- NULL
attributes(Protect2)


2. Use an index vector to subset the data

na <- is.na(Protect1$UphamComplBinomial)
Protect3 <- Protect1[!na, ]


The results are identical. But if you have more than one column with 
NA's, this second way will be more complicated.

identical(Protect2, Protect3)
#[1] TRUE


Hope this helps,

Rui Barradas

?s 22:27 de 04/06/20, Ted Stankowich escreveu:
> Thanks, but no that doesn?t work. The na.omit attributes are still in the dataframe, which you can see in the str outputs from the post. The problem line is likely:  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
> 
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Thursday, June 4, 2020 12:39 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
> 
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
> 
> Does droplevels() help?
> 
>> d <- data.frame(size = factor(c("S","M","M","L","L"), levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>> str(d)
> 'data.frame':   5 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
>   $ id  : num  101 NA NA 104 105
>> str(na.omit(d))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 3 3
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
>> str(droplevels(na.omit(d)))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 2 levels "S","L": 1 2 2
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
> 
> 
> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
> 
>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, Shade))  #Create the dataframe with variables of interest from an attached dataset
>> row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as rownames
>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
>> str(Protect1)
> 'data.frame': 319 obs. of  4 variables:
>   $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>   $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>   $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>   $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>   - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>    ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
> 
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach
> Long Beach, CA 90840
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><mailto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
> 
> 
> 
> 
>          [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  4 21:50:03 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Jun 2020 12:50:03 -0700
Subject: [R] ask help for ggplot
In-Reply-To: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
Message-ID: <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>

Better read the Posting Guide mentioned in the footer of this and every email on this list. Attachments can only be among a very few file types and still be passed through... yours did not.

As for your question, it is very likely that the answer is yes, though since this list is about the R language rather than specifics of contributed packages ... ggplot-specific questions are technically not in scope (though if you show a good reproducible example someone might respond anyway).

On June 3, 2020 8:17:23 PM PDT, Aimin Yan <aimin.at.work at gmail.com> wrote:
>I have a question about using ggplot.
>
>Is there possible to generate a barplot like the attached file using
>ggplot?
>
>Thank you,
>
>Aimin
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Fri Jun  5 00:35:51 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Thu, 4 Jun 2020 22:35:51 +0000
Subject: [R] na.omit not omitting rows
In-Reply-To: <3f5abbbd-cb19-4ef2-11fb-6b0373b95d00@sapo.pt>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
 <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <3f5abbbd-cb19-4ef2-11fb-6b0373b95d00@sapo.pt>
Message-ID: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>

This worked! Thank you!

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: Thursday, June 4, 2020 2:49 PM
To: Ted Stankowich <Theodore.Stankowich at csulb.edu>; William Dunlap <wdunlap at tibco.com>
Cc: r-help at r-project.org
Subject: Re: [R] na.omit not omitting rows

CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.


Hello,

If the problem is the "na.action" attribute, here are two ways of solving it.

First, an example data set.

set.seed(2020)    # Make the example reproducible
phamComplBinomial <- sprintf("f%003d", 1:356)
is.na(UphamComplBinomial) <- sample(356, 37) DarkEum <- factor(sample(1:2, 356, TRUE))
Protect1 <- data.frame(UphamComplBinomial = factor(UphamComplBinomial),
DarkEum)


1. Setting the attribute "na.action" to NULL removes it

Protect2 <- na.omit(Protect1)
attributes(Protect2)
attr(Protect2, "na.action") <- NULL
attributes(Protect2)


2. Use an index vector to subset the data

na <- is.na(Protect1$UphamComplBinomial)
Protect3 <- Protect1[!na, ]


The results are identical. But if you have more than one column with NA's, this second way will be more complicated.

identical(Protect2, Protect3)
#[1] TRUE


Hope this helps,

Rui Barradas

?s 22:27 de 04/06/20, Ted Stankowich escreveu:
> Thanks, but no that doesn?t work. The na.omit attributes are still in 
> the dataframe, which you can see in the str outputs from the post. The 
> problem line is likely:  - attr(*, "na.action")= 'omit' Named int 
> [1:2] 2 3
>
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Thursday, June 4, 2020 12:39 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
>
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>
> Does droplevels() help?
>
>> d <- data.frame(size = factor(c("S","M","M","L","L"), 
>> levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>> str(d)
> 'data.frame':   5 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
>   $ id  : num  101 NA NA 104 105
>> str(na.omit(d))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 3 3
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
>> str(droplevels(na.omit(d)))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 2 levels "S","L": 1 2 2
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
>
>
> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
>
>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, 
>> Shade))  #Create the dataframe with variables of interest from an 
>> attached dataset row.names(Protect1)=Protect1$UphamComplBinomial 
>> #assign species names as rownames
>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing 
>> data
>> str(Protect1)
> 'data.frame': 319 obs. of  4 variables:
>   $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>   $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>   $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>   $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>   - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>    ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach Long Beach, CA 90840 
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><ma
> ilto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.ed
> u>>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
>
>
>
>
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun  5 02:01:31 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 4 Jun 2020 17:01:31 -0700
Subject: [R] na.omit not omitting rows
In-Reply-To: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <215D5057-E4B3-46C4-9FBE-04B659CFC830@comcast.net>

Perhaps indexing with rowSums(is.na(dfrm))?

? 
David

Sent from my iPhone

> On Jun 4, 2020, at 4:58 PM, Ted Stankowich <Theodore.Stankowich at csulb.edu> wrote:
> 
> ?This worked! Thank you!
> 
> -----Original Message-----
> From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
> Sent: Thursday, June 4, 2020 2:49 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>; William Dunlap <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
> 
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
> 
> 
> Hello,
> 
> If the problem is the "na.action" attribute, here are two ways of solving it.
> 
> First, an example data set.
> 
> set.seed(2020)    # Make the example reproducible
> phamComplBinomial <- sprintf("f%003d", 1:356)
> is.na(UphamComplBinomial) <- sample(356, 37) DarkEum <- factor(sample(1:2, 356, TRUE))
> Protect1 <- data.frame(UphamComplBinomial = factor(UphamComplBinomial),
> DarkEum)
> 
> 
> 1. Setting the attribute "na.action" to NULL removes it
> 
> Protect2 <- na.omit(Protect1)
> attributes(Protect2)
> attr(Protect2, "na.action") <- NULL
> attributes(Protect2)
> 
> 
> 2. Use an index vector to subset the data
> 
> na <- is.na(Protect1$UphamComplBinomial)
> Protect3 <- Protect1[!na, ]
> 
> 
> The results are identical. But if you have more than one column with NA's, this second way will be more complicated.
> 
> identical(Protect2, Protect3)
> #[1] TRUE
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 22:27 de 04/06/20, Ted Stankowich escreveu:
>> Thanks, but no that doesn?t work. The na.omit attributes are still in 
>> the dataframe, which you can see in the str outputs from the post. The 
>> problem line is likely:  - attr(*, "na.action")= 'omit' Named int 
>> [1:2] 2 3
>> 
>> From: William Dunlap [mailto:wdunlap at tibco.com]
>> Sent: Thursday, June 4, 2020 12:39 PM
>> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] na.omit not omitting rows
>> 
>> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>> 
>> Does droplevels() help?
>> 
>>> d <- data.frame(size = factor(c("S","M","M","L","L"), 
>>> levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>>> str(d)
>> 'data.frame':   5 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
>>  $ id  : num  101 NA NA 104 105
>>> str(na.omit(d))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 3 3
>>  $ id  : num  101 104 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>>> str(droplevels(na.omit(d)))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 2 levels "S","L": 1 2 2
>>  $ id  : num  101 104 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com<http://tibco.com>
>> 
>> 
>> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
>> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
>> 
>>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, 
>>> Shade))  #Create the dataframe with variables of interest from an 
>>> attached dataset row.names(Protect1)=Protect1$UphamComplBinomial 
>>> #assign species names as rownames
>>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing 
>>> data
>>> str(Protect1)
>> 'data.frame': 319 obs. of  4 variables:
>>  $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>>  $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>>  $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>>  $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>>  - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>>   ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>> 
>> Dr. Ted Stankowich
>> Associate Professor
>> Department of Biological Sciences
>> California State University Long Beach Long Beach, CA 90840 
>> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><ma
>> ilto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.ed
>> u>>
>> 562-985-4826
>> http://www.csulb.edu/mammal-lab/
>> @CSULBMammalLab
>> 
>> 
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Fri Jun  5 03:03:13 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Fri, 5 Jun 2020 01:03:13 +0000
Subject: [R] na.omit not omitting rows
In-Reply-To: <215D5057-E4B3-46C4-9FBE-04B659CFC830@comcast.net>
References: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <215D5057-E4B3-46C4-9FBE-04B659CFC830@comcast.net>
Message-ID: <BY5PR12MB4180515FEB50F998A68F37C4F6860@BY5PR12MB4180.namprd12.prod.outlook.com>

Thanks - a previous response resolved the issue and I'm off and running with the analyses. 

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Thursday, June 4, 2020 5:02 PM
To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
Cc: Rui Barradas <ruipbarradas at sapo.pt>; William Dunlap <wdunlap at tibco.com>; r-help at r-project.org
Subject: Re: [R] na.omit not omitting rows

CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.


Perhaps indexing with rowSums(is.na(dfrm))?

?
David

Sent from my iPhone

> On Jun 4, 2020, at 4:58 PM, Ted Stankowich <Theodore.Stankowich at csulb.edu> wrote:
>
> ?This worked! Thank you!
>
> -----Original Message-----
> From: Rui Barradas [mailto:ruipbarradas at sapo.pt]
> Sent: Thursday, June 4, 2020 2:49 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>; William Dunlap 
> <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
>
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>
>
> Hello,
>
> If the problem is the "na.action" attribute, here are two ways of solving it.
>
> First, an example data set.
>
> set.seed(2020)    # Make the example reproducible
> phamComplBinomial <- sprintf("f%003d", 1:356)
> is.na(UphamComplBinomial) <- sample(356, 37) DarkEum <- 
> factor(sample(1:2, 356, TRUE))
> Protect1 <- data.frame(UphamComplBinomial = 
> factor(UphamComplBinomial),
> DarkEum)
>
>
> 1. Setting the attribute "na.action" to NULL removes it
>
> Protect2 <- na.omit(Protect1)
> attributes(Protect2)
> attr(Protect2, "na.action") <- NULL
> attributes(Protect2)
>
>
> 2. Use an index vector to subset the data
>
> na <- is.na(Protect1$UphamComplBinomial)
> Protect3 <- Protect1[!na, ]
>
>
> The results are identical. But if you have more than one column with NA's, this second way will be more complicated.
>
> identical(Protect2, Protect3)
> #[1] TRUE
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 22:27 de 04/06/20, Ted Stankowich escreveu:
>> Thanks, but no that doesn?t work. The na.omit attributes are still in 
>> the dataframe, which you can see in the str outputs from the post. 
>> The problem line is likely:  - attr(*, "na.action")= 'omit' Named int 
>> [1:2] 2 3
>>
>> From: William Dunlap [mailto:wdunlap at tibco.com]
>> Sent: Thursday, June 4, 2020 12:39 PM
>> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] na.omit not omitting rows
>>
>> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>>
>> Does droplevels() help?
>>
>>> d <- data.frame(size = factor(c("S","M","M","L","L"), 
>>> levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>>> str(d)
>> 'data.frame':   5 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3  $ id  : num  101 
>> NA NA 104 105
>>> str(na.omit(d))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 3 3  $ id  : num  101 104 
>> 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>>> str(droplevels(na.omit(d)))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 2 levels "S","L": 1 2 2  $ id  : num  101 104 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com<http://tibco.com>
>>
>>
>> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
>> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
>>
>>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep,
>>> Shade))  #Create the dataframe with variables of interest from an 
>>> attached dataset row.names(Protect1)=Protect1$UphamComplBinomial
>>> #assign species names as rownames
>>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing 
>>> data
>>> str(Protect1)
>> 'data.frame': 319 obs. of  4 variables:
>>  $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>>  $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>>  $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>>  $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>>  - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>>   ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>>
>> Dr. Ted Stankowich
>> Associate Professor
>> Department of Biological Sciences
>> California State University Long Beach Long Beach, CA 90840 
>> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><m
>> a 
>> ilto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.e
>> d
>> u>>
>> 562-985-4826
>> http://www.csulb.edu/mammal-lab/
>> @CSULBMammalLab
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>      [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jun  5 03:34:14 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 4 Jun 2020 19:34:14 -0600
Subject: [R] confusion about write.csv
Message-ID: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>

 Hello!

Hope everyone is doing as well as possible.

I have a question about write.csv.  I thought that the append argument
would permit adding another data frame with the same column names.

Here is my example:

 date1 <- as.Date("2020-03-09")
 wday <- weekdays(date1)
 x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
 x1
        date    day lev           y
1 2020-03-09 Monday   1 -0.09543049
2 2020-03-09 Monday   2  0.53943428
3 2020-03-09 Monday   3 -0.79224851
4 2020-03-09 Monday   4  0.68168147
5 2020-03-09 Monday   5 -1.02902897
 write.csv(file="test1.csv",x1,row.names=FALSE)
 date1 <- date1 + 1
 wday <- weekdays(date1)
 x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
 x2
        date     day lev          y
1 2020-03-10 Tuesday   1 -0.6648301
2 2020-03-10 Tuesday   2 -0.1137580
3 2020-03-10 Tuesday   3  1.6532675
4 2020-03-10 Tuesday   4 -0.5845293
5 2020-03-10 Tuesday   5  0.2849392
 write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
Warning message:
In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE) :
  attempt to set 'append' ignored

The values from x2 appear in the test1.csv file.

What am I missing, please?

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jun  5 03:48:00 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 4 Jun 2020 19:48:00 -0600
Subject: [R] Solved: confusion with write.csv
Message-ID: <CACxE24kvdzPK9=x7xn-iz63y0DvsZaWoFLrb3_zysR2zr01+og@mail.gmail.com>

Change over to write.table.

Sorry for the wasted bandwidth.

Thanks,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From m@rk|eed@2 @end|ng |rom gm@||@com  Fri Jun  5 03:48:34 2020
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Thu, 4 Jun 2020 21:48:34 -0400
Subject: [R] confusion about write.csv
In-Reply-To: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
Message-ID: <CAHz+bWaSab5numOVVbJ2JVcNeMeJ+2dKX22UMpv+nmO=mjC99w@mail.gmail.com>

Hi Erin: The default for write.csv is col.names = TRUE . So, in the second
one,
if you put, col.names = FALSE, that should work.  It's confused right now
because you want to append but also write the column names again.


Mark




On Thu, Jun 4, 2020 at 9:34 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:

>  Hello!
>
> Hope everyone is doing as well as possible.
>
> I have a question about write.csv.  I thought that the append argument
> would permit adding another data frame with the same column names.
>
> Here is my example:
>
>  date1 <- as.Date("2020-03-09")
>  wday <- weekdays(date1)
>  x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x1
>         date    day lev           y
> 1 2020-03-09 Monday   1 -0.09543049
> 2 2020-03-09 Monday   2  0.53943428
> 3 2020-03-09 Monday   3 -0.79224851
> 4 2020-03-09 Monday   4  0.68168147
> 5 2020-03-09 Monday   5 -1.02902897
>  write.csv(file="test1.csv",x1,row.names=FALSE)
>  date1 <- date1 + 1
>  wday <- weekdays(date1)
>  x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x2
>         date     day lev          y
> 1 2020-03-10 Tuesday   1 -0.6648301
> 2 2020-03-10 Tuesday   2 -0.1137580
> 3 2020-03-10 Tuesday   3  1.6532675
> 4 2020-03-10 Tuesday   4 -0.5845293
> 5 2020-03-10 Tuesday   5  0.2849392
>  write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
> Warning message:
> In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE) :
>   attempt to set 'append' ignored
>
> The values from x2 appear in the test1.csv file.
>
> What am I missing, please?
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  5 03:56:45 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Jun 2020 18:56:45 -0700
Subject: [R] confusion about write.csv
In-Reply-To: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
Message-ID: <4A8C1F82-474C-4458-B6C0-79990A830AC6@dcn.davis.ca.us>

Use write.table.

Write.csv follows a very specific definition for csv... one element of which is that it is not allowed to have a second header line after data lines. The only way for write.csv to enforce this is to disallow appending.

On June 4, 2020 6:34:14 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
>Hope everyone is doing as well as possible.
>
>I have a question about write.csv.  I thought that the append argument
>would permit adding another data frame with the same column names.
>
>Here is my example:
>
> date1 <- as.Date("2020-03-09")
> wday <- weekdays(date1)
> x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> x1
>        date    day lev           y
>1 2020-03-09 Monday   1 -0.09543049
>2 2020-03-09 Monday   2  0.53943428
>3 2020-03-09 Monday   3 -0.79224851
>4 2020-03-09 Monday   4  0.68168147
>5 2020-03-09 Monday   5 -1.02902897
> write.csv(file="test1.csv",x1,row.names=FALSE)
> date1 <- date1 + 1
> wday <- weekdays(date1)
> x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> x2
>        date     day lev          y
>1 2020-03-10 Tuesday   1 -0.6648301
>2 2020-03-10 Tuesday   2 -0.1137580
>3 2020-03-10 Tuesday   3  1.6532675
>4 2020-03-10 Tuesday   4 -0.5845293
>5 2020-03-10 Tuesday   5  0.2849392
> write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
>Warning message:
>In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE)
>:
>  attempt to set 'append' ignored
>
>The values from x2 appear in the test1.csv file.
>
>What am I missing, please?
>
>Thanks,
>Erin
>
>
>Erin Hodgess, PhD
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  5 03:55:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 4 Jun 2020 18:55:04 -0700
Subject: [R] confusion about write.csv
In-Reply-To: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
Message-ID: <CAGxFJbSTt52oZ=eVQUAUHrdo8jwOa8HEhHQ5V64PNJs4y3GQ-Q@mail.gmail.com>

... :

"arguments to write.table: append, col.names, sep, dec and qmethod cannot
be altered."

The default is FALSE, so cannot be altered.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 4, 2020 at 6:34 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:

>  Hello!
>
> Hope everyone is doing as well as possible.
>
> I have a question about write.csv.  I thought that the append argument
> would permit adding another data frame with the same column names.
>
> Here is my example:
>
>  date1 <- as.Date("2020-03-09")
>  wday <- weekdays(date1)
>  x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x1
>         date    day lev           y
> 1 2020-03-09 Monday   1 -0.09543049
> 2 2020-03-09 Monday   2  0.53943428
> 3 2020-03-09 Monday   3 -0.79224851
> 4 2020-03-09 Monday   4  0.68168147
> 5 2020-03-09 Monday   5 -1.02902897
>  write.csv(file="test1.csv",x1,row.names=FALSE)
>  date1 <- date1 + 1
>  wday <- weekdays(date1)
>  x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x2
>         date     day lev          y
> 1 2020-03-10 Tuesday   1 -0.6648301
> 2 2020-03-10 Tuesday   2 -0.1137580
> 3 2020-03-10 Tuesday   3  1.6532675
> 4 2020-03-10 Tuesday   4 -0.5845293
> 5 2020-03-10 Tuesday   5  0.2849392
>  write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
> Warning message:
> In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE) :
>   attempt to set 'append' ignored
>
> The values from x2 appear in the test1.csv file.
>
> What am I missing, please?
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jun  5 04:12:11 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 4 Jun 2020 20:12:11 -0600
Subject: [R] confusion about write.csv
In-Reply-To: <4A8C1F82-474C-4458-B6C0-79990A830AC6@dcn.davis.ca.us>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
 <4A8C1F82-474C-4458-B6C0-79990A830AC6@dcn.davis.ca.us>
Message-ID: <CACxE24mo6S63xLJLfmLtA3iZDa4RvaNrs5woMieCoO29bYfUpw@mail.gmail.com>

Thanks to all for the help.

I found that write.table works nicely, with col.names = FALSE with append =
TRUE.

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Thu, Jun 4, 2020 at 7:56 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Use write.table.
>
> Write.csv follows a very specific definition for csv... one element of
> which is that it is not allowed to have a second header line after data
> lines. The only way for write.csv to enforce this is to disallow appending.
>
> On June 4, 2020 6:34:14 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> > Hello!
> >
> >Hope everyone is doing as well as possible.
> >
> >I have a question about write.csv.  I thought that the append argument
> >would permit adding another data frame with the same column names.
> >
> >Here is my example:
> >
> > date1 <- as.Date("2020-03-09")
> > wday <- weekdays(date1)
> > x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> > x1
> >        date    day lev           y
> >1 2020-03-09 Monday   1 -0.09543049
> >2 2020-03-09 Monday   2  0.53943428
> >3 2020-03-09 Monday   3 -0.79224851
> >4 2020-03-09 Monday   4  0.68168147
> >5 2020-03-09 Monday   5 -1.02902897
> > write.csv(file="test1.csv",x1,row.names=FALSE)
> > date1 <- date1 + 1
> > wday <- weekdays(date1)
> > x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> > x2
> >        date     day lev          y
> >1 2020-03-10 Tuesday   1 -0.6648301
> >2 2020-03-10 Tuesday   2 -0.1137580
> >3 2020-03-10 Tuesday   3  1.6532675
> >4 2020-03-10 Tuesday   4 -0.5845293
> >5 2020-03-10 Tuesday   5  0.2849392
> > write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
> >Warning message:
> >In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE)
> >:
> >  attempt to set 'append' ignored
> >
> >The values from x2 appear in the test1.csv file.
> >
> >What am I missing, please?
> >
> >Thanks,
> >Erin
> >
> >
> >Erin Hodgess, PhD
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Fri Jun  5 06:14:16 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 5 Jun 2020 00:14:16 -0400
Subject: [R] ask help for ggplot
In-Reply-To: <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
 <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
Message-ID: <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>

Is there possible to generate a barplot in the following link using ggplot?

https://photos.app.goo.gl/E3MC461dKaTZfHza9

here is what I did

library(ggplot2)

df <- read.csv(text=
"trt,gene,freq,cols
M6,ALDH16A1,100.0000000,red
M6,Others,0.0000000,lightgrey
M12,ALDH16A1,64.6638015,red
M12,GBE1,2.0074865,#4C00FF
M12,ZNF598,1.5832525,#004CFF
M12,CHMP6,1.3503397,#00E5FF
M12,C20orf27,1.2033828,#00FF4D
M12,NEGR1,0.9676972,#4DFF00
M12,TNFAIP6,0.9122418,#E6FF00
M12,ZSCAN25,0.7375572,#FFFF00
M12,BCL2,0.6848745,#FFDE59
M12,CBL,0.6765562,#FFE0B3
M12,Others,25.2128102,lightgrey
M18,ALDH16A1,42.4503581,red
M18,ATF2,2.2360682,#4C00FF
M18,DIAPH1,1.5256507,#004CFF
M18,SESTD1,1.2053805,#00E5FF
M18,TFCP2,1.1587958,#00FF4D
M18,SCAPER,1.1180341,#4DFF00
M18,CUX1,1.0306877,#E6FF00
M18,TEX10,0.9841030,#FFFF00
M18,C6orf89,0.9666337,#FFDE59
M18,PTTG1IP,0.9258720,#FFE0B3
M18,Others,46.3984161,lightgrey")

df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = unique(as.character(df$gene)))

ggplot(df, aes(x=trt,y=freq, fill = gene))+geom_bar(stat = "identity",
width = 0.5,color="black") + theme(axis.text.x = element_text(angle = 45,
hjust = 1,size = 4))

df$cols is the color I want to use to label different gene in M6, M12,M18
as shown in Figure, and in each bar, the 'Others' of df$gene is always in
the bottom of bar in M6,M12,M18

Thank you

Aimin

	[[alternative HTML version deleted]]


From tcmu|g@| @end|ng |rom gm@||@com  Fri Jun  5 06:18:00 2020
From: tcmu|g@| @end|ng |rom gm@||@com (Charles Thuo)
Date: Fri, 5 Jun 2020 07:18:00 +0300
Subject: [R] how to add a calculated column into a data frame
Message-ID: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>

Dear  Sirs,

I have a data frame that has a column that shows the transaction date.

How do i add another column that  extracts the year of transaction from the
transaction date.

Charles

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  5 07:38:31 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Jun 2020 22:38:31 -0700
Subject: [R] how to add a calculated column into a data frame
In-Reply-To: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
References: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
Message-ID: <24C10DD2-48E5-457A-AA55-38B7B501A0E2@dcn.davis.ca.us>

This should get you started:

x <- "2009-03-21"
substr( x, 1, 4 )
y <- as.integer( substr( x, 1, 4 ) )
y

or

yy <- as.POSIXlt( x )$year + 1900
yy

RShowDoc( "R-intro" )

On June 4, 2020 9:18:00 PM PDT, Charles Thuo <tcmuigai at gmail.com> wrote:
>Dear  Sirs,
>
>I have a data frame that has a column that shows the transaction date.
>
>How do i add another column that  extracts the year of transaction from
>the
>transaction date.
>
>Charles
>
>	[[alternative HTML version deleted]]

Please post in plain text. It will get converted for you if you forget, and the quality of the automatic conversion can be awful.

>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From teotjunk @end|ng |rom hotm@||@com  Fri Jun  5 09:02:44 2020
From: teotjunk @end|ng |rom hotm@||@com (TJUN KIAT TEO)
Date: Fri, 5 Jun 2020 07:02:44 +0000
Subject: [R] Applying a function to dataframe column where the function
 value depends on the value of another column
Message-ID: <SG2PR03MB5103D5B625F973B3F2D975E9DF860@SG2PR03MB5103.apcprd03.prod.outlook.com>

Suppose I have a dataframe in this from

a b c
g 2 3
h 4 5
i 6 7

I want to apply a function to individual elements of column C where the function value depends on the value of column A

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  5 09:13:57 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 05 Jun 2020 00:13:57 -0700
Subject: [R] Applying a function to dataframe column where the function
 value depends on the value of another column
In-Reply-To: <SG2PR03MB5103D5B625F973B3F2D975E9DF860@SG2PR03MB5103.apcprd03.prod.outlook.com>
References: <SG2PR03MB5103D5B625F973B3F2D975E9DF860@SG2PR03MB5103.apcprd03.prod.outlook.com>
Message-ID: <A7C5D61E-1871-41AA-A411-E8183E548763@dcn.davis.ca.us>

Press send too soon? This is not actually a question.

Do read the Posting Guide... for one thing you need to post in plain text because the automatic text conversion tends to mess up what you send if it is HTML.

On June 5, 2020 12:02:44 AM PDT, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
>Suppose I have a dataframe in this from
>
>a b c
>g 2 3
>h 4 5
>i 6 7
>
>I want to apply a function to individual elements of column C where the
>function value depends on the value of column A
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ph@t@ch@u @end|ng |rom m@||@utoronto@c@  Thu Jun  4 22:17:41 2020
From: ph@t@ch@u @end|ng |rom m@||@utoronto@c@ (Phat Chau)
Date: Thu, 4 Jun 2020 20:17:41 +0000
Subject: [R] Error in gee.fit$working.correlation[1,
 2] : subscript out of bounds
Message-ID: <D53BCA3D-7D29-428A-9830-482061E164FE@mail.utoronto.ca>

Hello,

I have a dataframe in R that looks like the following

  cluster id period   u_3 timeID startTrt Ijt    error      y
1:       1  1      0 -1.26      1        1   0   1.2015 17.809
2:       1  2      0 -1.26      1        1   0  -1.6577 14.950
3:       1  3      0 -1.26      1        1   0  -3.8639 12.744
4:       1  4      0 -1.26      1        1   0   1.4978 18.105
5:       1  5      0 -1.26      1        1   0  -5.3182 11.289

When I try to run a gee model on it using the geesmv package which adjusts the variance covariance matrix for small sample sizes as follows

test <- GEE.var.fg(y ~ factor(period) + factor(Ijt),id="id",family=gaussian, dx,corstr="exchangeable")

I get this error message:

Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
    (Intercept) factor(period)1 factor(period)2 factor(period)3 factor(period)4 factor(period)5    factor(Ijt)1
          17.25           -8.27           -6.47           -9.13           -8.17          -11.89            8.96
Error in gee.fit$working.correlation[1, 2] : subscript out of bounds

I think the usual culprit for this kind of error message is that the variable being referred to (id in this case I assume) is non-existent. That is clearly not the case here and I checked to make sure it is it not a typo.

Does anyone know why this is? How would I troubleshoot this?

Thank you,
Edward


	[[alternative HTML version deleted]]


From @turm|echen @end|ng |rom gm@||@com  Thu Jun  4 14:38:35 2020
From: @turm|echen @end|ng |rom gm@||@com (Lena Fehlhaber)
Date: Thu, 4 Jun 2020 14:38:35 +0200
Subject: [R] Spatial model for categorical data
Message-ID: <CA+yGT=GbxwR-MZjQPvgzKWRC_sBa0JvwbR8eLJEUchkAywEuLQ@mail.gmail.com>

I did a regression analysis with categorical data with a glm model
approach, which worked fine. I have longitude and latitude coordinates for
each observation and I want to add their geographic spillover effect to the
model.

My sample data is structured:

Index DV IVI IVII IVIII IVIV Long Lat
 1  0  2  1  3  -12  -17.8  12
 2  0  1  1  6  112  11  -122
 3  1  3  6  1  91  57  53

with regression eq. DV ~ IVI + IVII + IVIII + IVIV

That mentioned, I assume that the nearer regions are, the more it may
influence my dependant variable. I found several approaches for spatial
regression models, but not for categorical data. When I try to use existing
libraries and functions, such as spdep's lagsarlm, glmmfields, spatialreg,
gstat, geoRglm and many more (I used this list as a reference:
https://cran.r-project.org/web/views/Spatial.html ). For numeric values, I
am able to do spatial regression, but for categorical values, I struggle.
The data structure is the following:

library(dplyr)
data <- data %>%
  mutate(
    DV = as.factor(DV),
    IVI = as.factor(IVI),
    IVII = as.factor(IVII),
    IVIII = as.factor(IVIII),
    IVIV = as.numeric(IVIV),
    longitude = as.numeric(longitude),
    latitude = as.numeric(latitude)
  )

My dependant variable (0|1) as well as my independant variables are
categorical and it would be no use to transform them, of course. I want to
have an other glm model in the end, but with spatial spillover effects
included. The libraries I tested so far can't handle categorical data. Any
leads/ideas would be greatly appreciated.

Thanks a lot.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun  5 11:36:33 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 5 Jun 2020 10:36:33 +0100
Subject: [R] ask help for ggplot
In-Reply-To: <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
 <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
 <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>
Message-ID: <794a30da-af67-b10b-bae5-87dcc99faf43@sapo.pt>

Hello,

Something like this?


g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[i], g[-i])
df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = g)

ggplot(df, aes(x=trt,y=freq, fill = gene, group = gene)) +
   geom_bar(stat = "identity", width = 0.5,
            position = position_fill()) +
   scale_fill_manual(breaks = df$gene, values = df$cols) +
   theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4))


But this places "Others" at the top of each bar.
To move it to the bottom, instead of the code that creates 'g' run

g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])


Hope this helps,

Rui Barradas


?s 05:14 de 05/06/20, Aimin Yan escreveu:
> Is there possible to generate a barplot in the following link using ggplot?
> 
> https://photos.app.goo.gl/E3MC461dKaTZfHza9
> 
> here is what I did
> 
> library(ggplot2)
> 
> df <- read.csv(text=
> "trt,gene,freq,cols
> M6,ALDH16A1,100.0000000,red
> M6,Others,0.0000000,lightgrey
> M12,ALDH16A1,64.6638015,red
> M12,GBE1,2.0074865,#4C00FF
> M12,ZNF598,1.5832525,#004CFF
> M12,CHMP6,1.3503397,#00E5FF
> M12,C20orf27,1.2033828,#00FF4D
> M12,NEGR1,0.9676972,#4DFF00
> M12,TNFAIP6,0.9122418,#E6FF00
> M12,ZSCAN25,0.7375572,#FFFF00
> M12,BCL2,0.6848745,#FFDE59
> M12,CBL,0.6765562,#FFE0B3
> M12,Others,25.2128102,lightgrey
> M18,ALDH16A1,42.4503581,red
> M18,ATF2,2.2360682,#4C00FF
> M18,DIAPH1,1.5256507,#004CFF
> M18,SESTD1,1.2053805,#00E5FF
> M18,TFCP2,1.1587958,#00FF4D
> M18,SCAPER,1.1180341,#4DFF00
> M18,CUX1,1.0306877,#E6FF00
> M18,TEX10,0.9841030,#FFFF00
> M18,C6orf89,0.9666337,#FFDE59
> M18,PTTG1IP,0.9258720,#FFE0B3
> M18,Others,46.3984161,lightgrey")
> 
> df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
> df$gene <- factor(df$gene,levels = unique(as.character(df$gene)))
> 
> ggplot(df, aes(x=trt,y=freq, fill = gene))+geom_bar(stat = "identity",
> width = 0.5,color="black") + theme(axis.text.x = element_text(angle = 45,
> hjust = 1,size = 4))
> 
> df$cols is the color I want to use to label different gene in M6, M12,M18
> as shown in Figure, and in each bar, the 'Others' of df$gene is always in
> the bottom of bar in M6,M12,M18
> 
> Thank you
> 
> Aimin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@v|76 @end|ng |rom gm@||@com  Fri Jun  5 18:32:36 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Fri, 5 Jun 2020 12:32:36 -0400
Subject: [R] Cumulative split of value in data frame column
Message-ID: <02a701d63b56$ec6b2780$c5417680$@gmail.com>

Assuming, I have a data frame like this ..

df <- data.frame(ID=1:3, FOO=c('A_B','A_B_C','A_B_C_D_E'))

I want to do a 'cumulative split' of the values in column FOO based on the
delimiter '_'.  The end result should be like this ..

ID  FOO		FOO_SPLIT1		FOO_SPLIT2 	FOO_SPLIT3
FOO_SPLIT4		FOO_SPLIT5
1   A_B		A		     A_B	
2   A_B_C	    	A			A_B
A_B_C
3   A_B_C_D_E	A		     A_B		    	A_B_C
A_B_C_D		A_B_C_D_E

Any efficient, optimized way to do this?


-- 
This email has been checked for viruses by AVG.
https://www.avg.com

	[[alternative HTML version deleted]]


From r@v|76 @end|ng |rom gm@||@com  Fri Jun  5 18:41:10 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Fri, 5 Jun 2020 12:41:10 -0400
Subject: [R] how to add a calculated column into a data frame
In-Reply-To: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
References: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
Message-ID: <035701d63b58$1e7f5330$5b7df990$@gmail.com>

How about something like this?

df <- data.frame(ID=1:3, DTVAL=c("2009-03-21","2010-05-11","2020-05-05"))

df <- df %>% mutate(YEAR = as.numeric(format(as.Date(DTVAL,'%Y-%m-%d'),
'%Y')))



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Charles Thuo
Sent: Friday, June 05, 2020 12:18 AM
To: r-help at r-project.org
Subject: [R] how to add a calculated column into a data frame

Dear  Sirs,

I have a data frame that has a column that shows the transaction date.

How do i add another column that  extracts the year of transaction from the
transaction date.

Charles

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


-- 
This email has been checked for viruses by AVG.
https://www.avg.com

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Fri Jun  5 18:52:32 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 5 Jun 2020 09:52:32 -0700
Subject: [R] Error in gee.fit$working.correlation[1,
 2] : subscript out of bounds
In-Reply-To: <D53BCA3D-7D29-428A-9830-482061E164FE@mail.utoronto.ca>
References: <D53BCA3D-7D29-428A-9830-482061E164FE@mail.utoronto.ca>
Message-ID: <CAF8bMcZFLg+7kpH6DDg8z-dR6JnvaOXQTL4j-GPBKvZ=4m24xg@mail.gmail.com>

The usual reason for the 'subscript out of bounds' error is that an array's
subscripts exceed the dimensions of the array.  In this case
gee.fit$working.correlation is a 1 by 1 matrix, so subscripting with [1,2]
will cause the error.

Here is a self-contained example that you can send the package's maintainer.

> maintainer("geesmv")
[1] "Zheng Li <zheng.li at outlook.com>"

> dx <- cbind(id=1:18, y=sin(1:18), expand.grid(period=c(1.1,1.2,1.3),
Ijt=c("i","ii","iii"))[c(1:9,1:9),])
> options(error=recover)
> test <- GEE.var.fg(y ~ factor(period) +
factor(Ijt),id="id",family=gaussian, dx,corstr="exchangeable")
Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
      (Intercept) factor(period)1.2 factor(period)1.3     factor(Ijt)ii
       0.02712257       -0.06015777       -0.11555784        0.04243596
   factor(Ijt)iii
       0.04114518
Error in gee.fit$working.correlation[1, 2] : subscript out of bounds

Enter a frame number, or 0 to exit

1: GEE.var.fg(y ~ factor(period) + factor(Ijt), id = "id", family =
gaussian,

Selection: 1
Called from: top level
Browse[1]> str(gee.fit$working.correlation)
 num [1, 1] 1

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jun 5, 2020 at 12:28 AM Phat Chau <phat.chau at mail.utoronto.ca>
wrote:

> Hello,
>
> I have a dataframe in R that looks like the following
>
>   cluster id period   u_3 timeID startTrt Ijt    error      y
> 1:       1  1      0 -1.26      1        1   0   1.2015 17.809
> 2:       1  2      0 -1.26      1        1   0  -1.6577 14.950
> 3:       1  3      0 -1.26      1        1   0  -3.8639 12.744
> 4:       1  4      0 -1.26      1        1   0   1.4978 18.105
> 5:       1  5      0 -1.26      1        1   0  -5.3182 11.289
>
> When I try to run a gee model on it using the geesmv package which adjusts
> the variance covariance matrix for small sample sizes as follows
>
> test <- GEE.var.fg(y ~ factor(period) +
> factor(Ijt),id="id",family=gaussian, dx,corstr="exchangeable")
>
> I get this error message:
>
> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
> running glm to get initial regression estimate
>     (Intercept) factor(period)1 factor(period)2 factor(period)3
> factor(period)4 factor(period)5    factor(Ijt)1
>           17.25           -8.27           -6.47           -9.13
>  -8.17          -11.89            8.96
> Error in gee.fit$working.correlation[1, 2] : subscript out of bounds
>
> I think the usual culprit for this kind of error message is that the
> variable being referred to (id in this case I assume) is non-existent. That
> is clearly not the case here and I checked to make sure it is it not a typo.
>
> Does anyone know why this is? How would I troubleshoot this?
>
> Thank you,
> Edward
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  5 20:28:50 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 5 Jun 2020 11:28:50 -0700
Subject: [R] Cumulative split of value in data frame column
In-Reply-To: <02a701d63b56$ec6b2780$c5417680$@gmail.com>
References: <02a701d63b56$ec6b2780$c5417680$@gmail.com>
Message-ID: <CAGxFJbTLHYmc1Q5Jmc-+cCEmY1zFNwjcHE94K+DZPXA2RJObcw@mail.gmail.com>

This is a **plain text list **. In future please post in plain text so that
your post does not get mangled.

Anyway,...

I don't know about "efficient, optimized", but here's one simple way to do
it using ?strsplit to unsplit and then ?paste to recombine:

df <- data.frame(ID=1:3, FOO=c('A_B','A_B_C','A_B_C_D_E'))

cumsplit<- function(x,split = "_"){
    w <- x[1]
    for(i in seq_along(x)[-1])  w <- c(w, paste(w[i-1],x[i], sep = split))
    w
}

> lapply(strsplit(df$FOO, split = "_"), cumsplit)
[[1]]
[1] "A"   "A_B"

[[2]]
[1] "A"     "A_B"   "A_B_C"

[[3]]
[1] "A"         "A_B"       "A_B_C"     "A_B_C_D"   "A_B_C_D_E"

I wouldn't be surprised if clever use of regex's would be faster, but as I
said, this is simple.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 5, 2020 at 9:33 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:

> Assuming, I have a data frame like this ..
>
> df <- data.frame(ID=1:3, FOO=c('A_B','A_B_C','A_B_C_D_E'))
>
> I want to do a 'cumulative split' of the values in column FOO based on the
> delimiter '_'.  The end result should be like this ..
>
> ID  FOO         FOO_SPLIT1              FOO_SPLIT2      FOO_SPLIT3
> FOO_SPLIT4              FOO_SPLIT5
> 1   A_B         A                    A_B
> 2   A_B_C               A                       A_B
> A_B_C
> 3   A_B_C_D_E   A                    A_B                        A_B_C
> A_B_C_D         A_B_C_D_E
>
> Any efficient, optimized way to do this?
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Fri Jun  5 21:49:57 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 5 Jun 2020 15:49:57 -0400
Subject: [R] ask help for ggplot
In-Reply-To: <794a30da-af67-b10b-bae5-87dcc99faf43@sapo.pt>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
 <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
 <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>
 <794a30da-af67-b10b-bae5-87dcc99faf43@sapo.pt>
Message-ID: <CALn2QVhu2t2GSYHeqyWUi1u6h24uy5bwyBqFvzgetsoomvMzEA@mail.gmail.com>

Thank you, it is very helpful.

I tried the following way to generate stacked bar plot for trt 'M6' and
'M12'

However, the label position of legend in 'M12' is not what I want,
actually in the legend I also want to keep "Others" in the bottom(like the
gene order in stacked bar)

In addition, how to  make  a stacked bar plot for 'M6','M12' and 'M18'
together with different legends('M6', 'M12', 'M18')

Thank you,

Aimin

df.1 <- df[df$trt=='M6',]

g <- unique(as.character(df.1$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df.1$trt <- factor(df.1$trt,levels=unique(as.character(df$trt)))
df.1$gene <- factor(df.1$gene,levels = g)

df.1 %>% ggplot(aes(x=trt,y=freq, fill = gene, group = gene)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(breaks = df$gene, values = df$cols) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4)) +
theme(legend.position="bottom")+guides(fill=guide_legend(title=df.1$trt,title.position
= "top", ncol=1, keyheight=0.35, default.unit="inch"))

df.2 <- df[df$trt=='M12',]

g <- unique(as.character(df.2$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df.2$trt <- factor(df.2$trt,levels=unique(as.character(df$trt)))
df.2$gene <- factor(df.2$gene,levels = g)

df.2 %>% ggplot(aes(x=trt,y=freq, fill = gene, group = gene)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(breaks = df$gene, values = df$cols) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4)) +
theme(legend.position="bottom")+guides(fill=guide_legend(title=df.2$trt,title.position
= "top", ncol=1, keyheight=0.35, default.unit="inch"))




On Fri, Jun 5, 2020 at 5:36 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Something like this?
>
>
> g <- unique(as.character(df$gene))
> i <- which(g == "Others")
> g <- c(g[i], g[-i])
> df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
> df$gene <- factor(df$gene,levels = g)
>
> ggplot(df, aes(x=trt,y=freq, fill = gene, group = gene)) +
>    geom_bar(stat = "identity", width = 0.5,
>             position = position_fill()) +
>    scale_fill_manual(breaks = df$gene, values = df$cols) +
>    theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4))
>
>
> But this places "Others" at the top of each bar.
> To move it to the bottom, instead of the code that creates 'g' run
>
> g <- unique(as.character(df$gene))
> i <- which(g == "Others")
> g <- c(g[-i], g[i])
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 05:14 de 05/06/20, Aimin Yan escreveu:
> > Is there possible to generate a barplot in the following link using
> ggplot?
> >
> > https://photos.app.goo.gl/E3MC461dKaTZfHza9
> >
> > here is what I did
> >
> > library(ggplot2)
> >
> > df <- read.csv(text=
> > "trt,gene,freq,cols
> > M6,ALDH16A1,100.0000000,red
> > M6,Others,0.0000000,lightgrey
> > M12,ALDH16A1,64.6638015,red
> > M12,GBE1,2.0074865,#4C00FF
> > M12,ZNF598,1.5832525,#004CFF
> > M12,CHMP6,1.3503397,#00E5FF
> > M12,C20orf27,1.2033828,#00FF4D
> > M12,NEGR1,0.9676972,#4DFF00
> > M12,TNFAIP6,0.9122418,#E6FF00
> > M12,ZSCAN25,0.7375572,#FFFF00
> > M12,BCL2,0.6848745,#FFDE59
> > M12,CBL,0.6765562,#FFE0B3
> > M12,Others,25.2128102,lightgrey
> > M18,ALDH16A1,42.4503581,red
> > M18,ATF2,2.2360682,#4C00FF
> > M18,DIAPH1,1.5256507,#004CFF
> > M18,SESTD1,1.2053805,#00E5FF
> > M18,TFCP2,1.1587958,#00FF4D
> > M18,SCAPER,1.1180341,#4DFF00
> > M18,CUX1,1.0306877,#E6FF00
> > M18,TEX10,0.9841030,#FFFF00
> > M18,C6orf89,0.9666337,#FFDE59
> > M18,PTTG1IP,0.9258720,#FFE0B3
> > M18,Others,46.3984161,lightgrey")
> >
> > df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
> > df$gene <- factor(df$gene,levels = unique(as.character(df$gene)))
> >
> > ggplot(df, aes(x=trt,y=freq, fill = gene))+geom_bar(stat = "identity",
> > width = 0.5,color="black") + theme(axis.text.x = element_text(angle = 45,
> > hjust = 1,size = 4))
> >
> > df$cols is the color I want to use to label different gene in M6, M12,M18
> > as shown in Figure, and in each bar, the 'Others' of df$gene is always in
> > the bottom of bar in M6,M12,M18
> >
> > Thank you
> >
> > Aimin
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Sat Jun  6 05:59:47 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 5 Jun 2020 23:59:47 -0400
Subject: [R] (no subject)
Message-ID: <CALn2QVjjWchdZMQX_JQHq8ADfqUFB4QpOi1j6uWwCm3tvMWuLg@mail.gmail.com>

I want the stacked bar and its legend following the order as tr from
left to right like the following:

"100.0.250ng_CellLine_0" "75.25.250ng_CellLine_0"
"50.50.250ng_CellLine_0" "10.90.250ng_CellLine_0"
"1.99.250ng_CellLine_0" "0.100.250ng_CellLine_0"
"100.0.500ng_CellLine_0" "75.25.500ng_CellLine_0"
"50.50.500ng_CellLine_0" "10.90.500ng_CellLine_0"
"1.99.500ng_CellLine_0" "0.100.500ng_CellLine_0"

However, It seems the above code does not generate the stacked bar as this order

In addition, for '0.100.500ng_CellLine_0' in df, the order for gene
and color in stacked bar is not same as the order in df:



0.100.500ng_CellLine_0       ALYREF   1.5326986       red
                  0.100.500ng_CellLine_0        HCG18   1.5108475   #4C00FF
                  0.100.500ng_CellLine_0    RNU7-146P   0.9224286   #004CFF
                  0.100.500ng_CellLine_0      ST3GAL3   0.8849696   #00E5FF
                  0.100.500ng_CellLine_0         HSF1   0.8116123   #00FF4D
                  0.100.500ng_CellLine_0       HP1BP3   0.7928828   #4DFF00
                  0.100.500ng_CellLine_0         DAOA   0.7366942   #E6FF00
                  0.100.500ng_CellLine_0        CDK13   0.6898705   #FFFF00
                  0.100.500ng_CellLine_0       PDXDC1   0.6805057   #FFDE59
                  0.100.500ng_CellLine_0        CKAP5   0.6477290   #FFE0B3
                  0.100.500ng_CellLine_0       Others  90.7897612 lightgrey'

library(dplyr)
library(tidyverse)
library(ggnewscale)

df <- read.csv(text='"trt","gene","freq","cols"
                 "100.0.250ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.250ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.250ng_CellLine_0","ALDH16A1",64.6638014695688,"red"
                 "75.25.250ng_CellLine_0","GBE1",2.0074864827395,"#4C00FF"
                 "75.25.250ng_CellLine_0","ZNF598",1.5832524608346,"#004CFF"
                 "75.25.250ng_CellLine_0","CHMP6",1.35033966449466,"#00E5FF"
                 "75.25.250ng_CellLine_0","C20orf27",1.2033827810897,"#00FF4D"
                 "75.25.250ng_CellLine_0","NEGR1",0.967697213364758,"#4DFF00"
                 "75.25.250ng_CellLine_0","TNFAIP6",0.912241785664772,"#E6FF00"
                 "75.25.250ng_CellLine_0","ZSCAN25",0.737557188409816,"#FFFF00"
                 "75.25.250ng_CellLine_0","BCL2",0.684874532094829,"#FFDE59"
                 "75.25.250ng_CellLine_0","CBL",0.676556217939831,"#FFE0B3"
                 "75.25.250ng_CellLine_0","Others",25.2128102037987,"lightgrey"
                 "50.50.250ng_CellLine_0","ALDH16A1",42.4503581203051,"red"
                 "50.50.250ng_CellLine_0","ATF2",2.23606824666628,"#4C00FF"
                 "50.50.250ng_CellLine_0","DIAPH1",1.52565073079835,"#004CFF"
                 "50.50.250ng_CellLine_0","SESTD1",1.20538053921854,"#00E5FF"
                 "50.50.250ng_CellLine_0","TFCP2",1.15879578407966,"#00FF4D"
                 "50.50.250ng_CellLine_0","SCAPER",1.11803412333314,"#4DFF00"
                 "50.50.250ng_CellLine_0","CUX1",1.03068770744774,"#E6FF00"
                 "50.50.250ng_CellLine_0","TEX10",0.984102952308857,"#FFFF00"
                 "50.50.250ng_CellLine_0","C6orf89",0.966633669131777,"#FFDE59"
                 "50.50.250ng_CellLine_0","PTTG1IP",0.925872008385256,"#FFE0B3"
                 "50.50.250ng_CellLine_0","Others",46.3984161183253,"lightgrey"
                 "10.90.250ng_CellLine_0","ALDH16A1",4.68952007835455,"red"
                 "10.90.250ng_CellLine_0","STK11",1.93143976493634,"#4C00FF"
                 "10.90.250ng_CellLine_0","ERGIC2",1.46523016650343,"#004CFF"
                 "10.90.250ng_CellLine_0","EFR3A",1.1126346718903,"#00E5FF"
                 "10.90.250ng_CellLine_0","TMEM235",1.03819784524976,"#00FF4D"
                 "10.90.250ng_CellLine_0","NGLY1",1.01469147894221,"#4DFF00"
                 "10.90.250ng_CellLine_0","CNOT10",0.991185112634672,"#E6FF00"
                 "10.90.250ng_CellLine_0","NPLOC4",0.983349657198825,"#FFFF00"
                 "10.90.250ng_CellLine_0","GZMB",0.928501469147894,"#FFDE59"
                 "10.90.250ng_CellLine_0","KIF2C",0.924583741429971,"#FFE0B3"
                 "10.90.250ng_CellLine_0","Others",84.9206660137121,"lightgrey"
                 "1.99.250ng_CellLine_0","DNAH1",2.36284289276808,"red"
                 "1.99.250ng_CellLine_0","ALOX5AP",2.29426433915212,"#4C00FF"
                 "1.99.250ng_CellLine_0","SEPT7",1.78304239401496,"#004CFF"
                 "1.99.250ng_CellLine_0","TCF20",1.35910224438903,"#00E5FF"
                 "1.99.250ng_CellLine_0","USP32",1.27805486284289,"#00FF4D"
                 "1.99.250ng_CellLine_0","MUS81",1.24688279301746,"#4DFF00"
                 "1.99.250ng_CellLine_0","CEP44",1.22817955112219,"#E6FF00"
                 "1.99.250ng_CellLine_0","TMEM164",1.20324189526185,"#FFFF00"
                 "1.99.250ng_CellLine_0","RAP1B",1.18453865336658,"#FFDE59"
                 "1.99.250ng_CellLine_0","GSN",1.14713216957606,"#FFE0B3"
                 "1.99.250ng_CellLine_0","Others",84.9127182044888,"lightgrey"
                 "0.100.250ng_CellLine_0","RTN3",2.3050199437531,"red"
                 "0.100.250ng_CellLine_0","CHTF18",1.67637814091135,"#4C00FF"
                 "0.100.250ng_CellLine_0","RNPS1",1.41168685550429,"#004CFF"
                 "0.100.250ng_CellLine_0","RBKS",1.05325073984891,"#00E5FF"
                 "0.100.250ng_CellLine_0","ZNF805",0.987077918497142,"#00FF4D"
                 "0.100.250ng_CellLine_0","TMBIM6",0.865761079352242,"#4DFF00"

"0.100.250ng_CellLine_0","RP3-449O17.1",0.841865338308549,"#E6FF00"
                 "0.100.250ng_CellLine_0","RNASEH2A",0.814293329411981,"#FFFF00"
                 "0.100.250ng_CellLine_0","FAM46A",0.810617061559105,"#FFDE59"
                 "0.100.250ng_CellLine_0","CYB561A3",0.79775012407404,"#FFE0B3"
                 "0.100.250ng_CellLine_0","Others",88.4362994687793,"lightgrey"
                 "100.0.500ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.500ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.500ng_CellLine_0","ALDH16A1",64.6680558047111,"red"
                 "75.25.500ng_CellLine_0","STX18",0.76034608856445,"#4C00FF"
                 "75.25.500ng_CellLine_0","BCL7A",0.685829412008224,"#004CFF"
                 "75.25.500ng_CellLine_0","PTPRC",0.634771689182662,"#00E5FF"
                 "75.25.500ng_CellLine_0","GABRB1",0.626492058454193,"#00FF4D"
                 "75.25.500ng_CellLine_0","EDNRB",0.59751335090455,"#4DFF00"
                 "75.25.500ng_CellLine_0","TBC1D10C",0.538175997350518,"#E6FF00"
                 "75.25.500ng_CellLine_0","SRGAP2B",0.534036181986283,"#FFFF00"
                 "75.25.500ng_CellLine_0","RABGAP1",0.527136489712559,"#FFDE59"
                 "75.25.500ng_CellLine_0","CD44",0.485738336070211,"#FFE0B3"
                 "75.25.500ng_CellLine_0","Others",29.9419045910552,"lightgrey"
                 "50.50.500ng_CellLine_0","ALDH16A1",40.5808575357307,"red"
                 "50.50.500ng_CellLine_0","TNPO1",0.979207466977791,"#4C00FF"
                 "50.50.500ng_CellLine_0","RNA5SP443",0.93337222384266,"#004CFF"
                 "50.50.500ng_CellLine_0","MND1",0.912538022417601,"#00E5FF"
                 "50.50.500ng_CellLine_0","RB1",0.900037501562565,"#00FF4D"
                 "50.50.500ng_CellLine_0","PTPRA",0.791699654152256,"#4DFF00"
                 "50.50.500ng_CellLine_0","SUCNR1",0.783365973582233,"#E6FF00"
                 "50.50.500ng_CellLine_0","MIR1284",0.625026042751781,"#FFFF00"
                 "50.50.500ng_CellLine_0","RWDD1",0.587524480186674,"#FFDE59"
                 "50.50.500ng_CellLine_0","NTN1",0.575023959331639,"#FFE0B3"
                 "50.50.500ng_CellLine_0","Others",52.3313471394641,"lightgrey"
                 "10.90.500ng_CellLine_0","ALDH16A1",7.05601485476812,"red"
                 "10.90.500ng_CellLine_0","ENTPD5",1.4722136257129,"#4C00FF"
                 "10.90.500ng_CellLine_0","MFSD10",1.28210796233255,"#004CFF"

"10.90.500ng_CellLine_0","LENG8-AS1",0.915159821389098,"#00E5FF"
                 "10.90.500ng_CellLine_0","FRMD4B",0.884212387815553,"#00FF4D"
                 "10.90.500ng_CellLine_0","TWISTNB",0.853264954242009,"#4DFF00"
                 "10.90.500ng_CellLine_0","ZNF544",0.778106901277687,"#E6FF00"
                 "10.90.500ng_CellLine_0","NUDCD1",0.738317343825987,"#FFFF00"
                 "10.90.500ng_CellLine_0","PHF20",0.720633096069676,"#FFDE59"
                 "10.90.500ng_CellLine_0","HNRNPK",0.702948848313365,"#FFE0B3"
                 "10.90.500ng_CellLine_0","Others",84.5970202042531,"lightgrey"
                 "1.99.500ng_CellLine_0","SND1",2.97318305479984,"red"
                 "1.99.500ng_CellLine_0","ATF1",2.18940277237984,"#4C00FF"
                 "1.99.500ng_CellLine_0","CARM1",1.96916699054282,"#004CFF"
                 "1.99.500ng_CellLine_0","OR4K15",1.28902707604612,"#00E5FF"
                 "1.99.500ng_CellLine_0","MTMR3",1.26311698406529,"#00FF4D"
                 "1.99.500ng_CellLine_0","CDK13",1.13356652416116,"#4DFF00"
                 "1.99.500ng_CellLine_0","RNU6-385P",1.0752688172043,"#E6FF00"
                 "1.99.500ng_CellLine_0","SLC4A2",0.809690374400829,"#FFFF00"
                 "1.99.500ng_CellLine_0","TMF1",0.770825236429589,"#FFDE59"
                 "1.99.500ng_CellLine_0","MAN1A1",0.738437621453556,"#FFE0B3"
                 "1.99.500ng_CellLine_0","Others",85.7883145485167,"lightgrey"
                 "0.100.500ng_CellLine_0","ALYREF",1.53269861089433,"red"
                 "0.100.500ng_CellLine_0","HCG18",1.51084751053535,"#4C00FF"

"0.100.500ng_CellLine_0","RNU7-146P",0.922428593725613,"#004CFF"
                 "0.100.500ng_CellLine_0","ST3GAL3",0.884969564538786,"#00E5FF"
                 "0.100.500ng_CellLine_0","HSF1",0.811612299047916,"#00FF4D"
                 "0.100.500ng_CellLine_0","HP1BP3",0.792882784454503,"#4DFF00"
                 "0.100.500ng_CellLine_0","DAOA",0.736694240674262,"#E6FF00"
                 "0.100.500ng_CellLine_0","CDK13",0.689870454190729,"#FFFF00"
                 "0.100.500ng_CellLine_0","PDXDC1",0.680505696894022,"#FFDE59"
                 "0.100.500ng_CellLine_0","CKAP5",0.647729046355549,"#FFE0B3"
                 "0.100.500ng_CellLine_0","Others",90.7897611986889,"lightgrey"'
                 ,sep=",",header=T)

g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = g)

cols <- dplyr::select(df, gene, cols) %>%
  distinct() %>%
  deframe()

tr <- levels(df$trt)

p <- ggplot() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[1]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[1],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[2]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[2],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[3]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[3],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[4]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[4],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[5]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[5],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[6]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[6],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[7]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[7],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[8]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[8],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[9]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[9],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[10]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[10], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[11]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[11], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[12]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[12], ncol = 1, title.position = "top")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4),
legend.position = "bottom", legend.justification = 0)

p

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Sat Jun  6 06:08:02 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Sat, 6 Jun 2020 00:08:02 -0400
Subject: [R] Change the oder of stacked bar
In-Reply-To: <CALn2QVjjWchdZMQX_JQHq8ADfqUFB4QpOi1j6uWwCm3tvMWuLg@mail.gmail.com>
References: <CALn2QVjjWchdZMQX_JQHq8ADfqUFB4QpOi1j6uWwCm3tvMWuLg@mail.gmail.com>
Message-ID: <CALn2QVivU2zbsmSfZ8wW8=ce847YgV4G2kaVHB=6PXQT2hx-jw@mail.gmail.com>

I want to use the code below this message to make stacked bar plot, my
question is :


I want the stacked bar and its legend following the order as tr from
left to right like the following:

"100.0.250ng_CellLine_0" "75.25.250ng_CellLine_0"
"50.50.250ng_CellLine_0" "10.90.250ng_CellLine_0"
"1.99.250ng_CellLine_0" "0.100.250ng_CellLine_0"
"100.0.500ng_CellLine_0" "75.25.500ng_CellLine_0"
"50.50.500ng_CellLine_0" "10.90.500ng_CellLine_0"
"1.99.500ng_CellLine_0" "0.100.500ng_CellLine_0"

However, It seems the following code does not generate the stacked bar
as this order

In addition, for '0.100.500ng_CellLine_0' in df, the order for gene
and color in stacked bar is not same as the order in df, how to change
this?

Another question is:

tr has 12 treatments, I have to add new_scale_fill() for each
treatment, so I get long code, Is there a way to simplify this?

Thank you

Aimin


library(ggplot2)

library(dplyr)

library(tidyverse)

library(ggnewscale)

df <- read.csv(text='"trt","gene","freq","cols"
                 "100.0.250ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.250ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.250ng_CellLine_0","ALDH16A1",64.6638014695688,"red"
                 "75.25.250ng_CellLine_0","GBE1",2.0074864827395,"#4C00FF"
                 "75.25.250ng_CellLine_0","ZNF598",1.5832524608346,"#004CFF"
                 "75.25.250ng_CellLine_0","CHMP6",1.35033966449466,"#00E5FF"
                 "75.25.250ng_CellLine_0","C20orf27",1.2033827810897,"#00FF4D"
                 "75.25.250ng_CellLine_0","NEGR1",0.967697213364758,"#4DFF00"
                 "75.25.250ng_CellLine_0","TNFAIP6",0.912241785664772,"#E6FF00"
                 "75.25.250ng_CellLine_0","ZSCAN25",0.737557188409816,"#FFFF00"
                 "75.25.250ng_CellLine_0","BCL2",0.684874532094829,"#FFDE59"
                 "75.25.250ng_CellLine_0","CBL",0.676556217939831,"#FFE0B3"
                 "75.25.250ng_CellLine_0","Others",25.2128102037987,"lightgrey"
                 "50.50.250ng_CellLine_0","ALDH16A1",42.4503581203051,"red"
                 "50.50.250ng_CellLine_0","ATF2",2.23606824666628,"#4C00FF"
                 "50.50.250ng_CellLine_0","DIAPH1",1.52565073079835,"#004CFF"
                 "50.50.250ng_CellLine_0","SESTD1",1.20538053921854,"#00E5FF"
                 "50.50.250ng_CellLine_0","TFCP2",1.15879578407966,"#00FF4D"
                 "50.50.250ng_CellLine_0","SCAPER",1.11803412333314,"#4DFF00"
                 "50.50.250ng_CellLine_0","CUX1",1.03068770744774,"#E6FF00"
                 "50.50.250ng_CellLine_0","TEX10",0.984102952308857,"#FFFF00"
                 "50.50.250ng_CellLine_0","C6orf89",0.966633669131777,"#FFDE59"
                 "50.50.250ng_CellLine_0","PTTG1IP",0.925872008385256,"#FFE0B3"
                 "50.50.250ng_CellLine_0","Others",46.3984161183253,"lightgrey"
                 "10.90.250ng_CellLine_0","ALDH16A1",4.68952007835455,"red"
                 "10.90.250ng_CellLine_0","STK11",1.93143976493634,"#4C00FF"
                 "10.90.250ng_CellLine_0","ERGIC2",1.46523016650343,"#004CFF"
                 "10.90.250ng_CellLine_0","EFR3A",1.1126346718903,"#00E5FF"
                 "10.90.250ng_CellLine_0","TMEM235",1.03819784524976,"#00FF4D"
                 "10.90.250ng_CellLine_0","NGLY1",1.01469147894221,"#4DFF00"
                 "10.90.250ng_CellLine_0","CNOT10",0.991185112634672,"#E6FF00"
                 "10.90.250ng_CellLine_0","NPLOC4",0.983349657198825,"#FFFF00"
                 "10.90.250ng_CellLine_0","GZMB",0.928501469147894,"#FFDE59"
                 "10.90.250ng_CellLine_0","KIF2C",0.924583741429971,"#FFE0B3"
                 "10.90.250ng_CellLine_0","Others",84.9206660137121,"lightgrey"
                 "1.99.250ng_CellLine_0","DNAH1",2.36284289276808,"red"
                 "1.99.250ng_CellLine_0","ALOX5AP",2.29426433915212,"#4C00FF"
                 "1.99.250ng_CellLine_0","SEPT7",1.78304239401496,"#004CFF"
                 "1.99.250ng_CellLine_0","TCF20",1.35910224438903,"#00E5FF"
                 "1.99.250ng_CellLine_0","USP32",1.27805486284289,"#00FF4D"
                 "1.99.250ng_CellLine_0","MUS81",1.24688279301746,"#4DFF00"
                 "1.99.250ng_CellLine_0","CEP44",1.22817955112219,"#E6FF00"
                 "1.99.250ng_CellLine_0","TMEM164",1.20324189526185,"#FFFF00"
                 "1.99.250ng_CellLine_0","RAP1B",1.18453865336658,"#FFDE59"
                 "1.99.250ng_CellLine_0","GSN",1.14713216957606,"#FFE0B3"
                 "1.99.250ng_CellLine_0","Others",84.9127182044888,"lightgrey"
                 "0.100.250ng_CellLine_0","RTN3",2.3050199437531,"red"
                 "0.100.250ng_CellLine_0","CHTF18",1.67637814091135,"#4C00FF"
                 "0.100.250ng_CellLine_0","RNPS1",1.41168685550429,"#004CFF"
                 "0.100.250ng_CellLine_0","RBKS",1.05325073984891,"#00E5FF"
                 "0.100.250ng_CellLine_0","ZNF805",0.987077918497142,"#00FF4D"
                 "0.100.250ng_CellLine_0","TMBIM6",0.865761079352242,"#4DFF00"

"0.100.250ng_CellLine_0","RP3-449O17.1",0.841865338308549,"#E6FF00"
                 "0.100.250ng_CellLine_0","RNASEH2A",0.814293329411981,"#FFFF00"
                 "0.100.250ng_CellLine_0","FAM46A",0.810617061559105,"#FFDE59"
                 "0.100.250ng_CellLine_0","CYB561A3",0.79775012407404,"#FFE0B3"
                 "0.100.250ng_CellLine_0","Others",88.4362994687793,"lightgrey"
                 "100.0.500ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.500ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.500ng_CellLine_0","ALDH16A1",64.6680558047111,"red"
                 "75.25.500ng_CellLine_0","STX18",0.76034608856445,"#4C00FF"
                 "75.25.500ng_CellLine_0","BCL7A",0.685829412008224,"#004CFF"
                 "75.25.500ng_CellLine_0","PTPRC",0.634771689182662,"#00E5FF"
                 "75.25.500ng_CellLine_0","GABRB1",0.626492058454193,"#00FF4D"
                 "75.25.500ng_CellLine_0","EDNRB",0.59751335090455,"#4DFF00"
                 "75.25.500ng_CellLine_0","TBC1D10C",0.538175997350518,"#E6FF00"
                 "75.25.500ng_CellLine_0","SRGAP2B",0.534036181986283,"#FFFF00"
                 "75.25.500ng_CellLine_0","RABGAP1",0.527136489712559,"#FFDE59"
                 "75.25.500ng_CellLine_0","CD44",0.485738336070211,"#FFE0B3"
                 "75.25.500ng_CellLine_0","Others",29.9419045910552,"lightgrey"
                 "50.50.500ng_CellLine_0","ALDH16A1",40.5808575357307,"red"
                 "50.50.500ng_CellLine_0","TNPO1",0.979207466977791,"#4C00FF"
                 "50.50.500ng_CellLine_0","RNA5SP443",0.93337222384266,"#004CFF"
                 "50.50.500ng_CellLine_0","MND1",0.912538022417601,"#00E5FF"
                 "50.50.500ng_CellLine_0","RB1",0.900037501562565,"#00FF4D"
                 "50.50.500ng_CellLine_0","PTPRA",0.791699654152256,"#4DFF00"
                 "50.50.500ng_CellLine_0","SUCNR1",0.783365973582233,"#E6FF00"
                 "50.50.500ng_CellLine_0","MIR1284",0.625026042751781,"#FFFF00"
                 "50.50.500ng_CellLine_0","RWDD1",0.587524480186674,"#FFDE59"
                 "50.50.500ng_CellLine_0","NTN1",0.575023959331639,"#FFE0B3"
                 "50.50.500ng_CellLine_0","Others",52.3313471394641,"lightgrey"
                 "10.90.500ng_CellLine_0","ALDH16A1",7.05601485476812,"red"
                 "10.90.500ng_CellLine_0","ENTPD5",1.4722136257129,"#4C00FF"
                 "10.90.500ng_CellLine_0","MFSD10",1.28210796233255,"#004CFF"

"10.90.500ng_CellLine_0","LENG8-AS1",0.915159821389098,"#00E5FF"
                 "10.90.500ng_CellLine_0","FRMD4B",0.884212387815553,"#00FF4D"
                 "10.90.500ng_CellLine_0","TWISTNB",0.853264954242009,"#4DFF00"
                 "10.90.500ng_CellLine_0","ZNF544",0.778106901277687,"#E6FF00"
                 "10.90.500ng_CellLine_0","NUDCD1",0.738317343825987,"#FFFF00"
                 "10.90.500ng_CellLine_0","PHF20",0.720633096069676,"#FFDE59"
                 "10.90.500ng_CellLine_0","HNRNPK",0.702948848313365,"#FFE0B3"
                 "10.90.500ng_CellLine_0","Others",84.5970202042531,"lightgrey"
                 "1.99.500ng_CellLine_0","SND1",2.97318305479984,"red"
                 "1.99.500ng_CellLine_0","ATF1",2.18940277237984,"#4C00FF"
                 "1.99.500ng_CellLine_0","CARM1",1.96916699054282,"#004CFF"
                 "1.99.500ng_CellLine_0","OR4K15",1.28902707604612,"#00E5FF"
                 "1.99.500ng_CellLine_0","MTMR3",1.26311698406529,"#00FF4D"
                 "1.99.500ng_CellLine_0","CDK13",1.13356652416116,"#4DFF00"
                 "1.99.500ng_CellLine_0","RNU6-385P",1.0752688172043,"#E6FF00"
                 "1.99.500ng_CellLine_0","SLC4A2",0.809690374400829,"#FFFF00"
                 "1.99.500ng_CellLine_0","TMF1",0.770825236429589,"#FFDE59"
                 "1.99.500ng_CellLine_0","MAN1A1",0.738437621453556,"#FFE0B3"
                 "1.99.500ng_CellLine_0","Others",85.7883145485167,"lightgrey"
                 "0.100.500ng_CellLine_0","ALYREF",1.53269861089433,"red"
                 "0.100.500ng_CellLine_0","HCG18",1.51084751053535,"#4C00FF"

"0.100.500ng_CellLine_0","RNU7-146P",0.922428593725613,"#004CFF"
                 "0.100.500ng_CellLine_0","ST3GAL3",0.884969564538786,"#00E5FF"
                 "0.100.500ng_CellLine_0","HSF1",0.811612299047916,"#00FF4D"
                 "0.100.500ng_CellLine_0","HP1BP3",0.792882784454503,"#4DFF00"
                 "0.100.500ng_CellLine_0","DAOA",0.736694240674262,"#E6FF00"
                 "0.100.500ng_CellLine_0","CDK13",0.689870454190729,"#FFFF00"
                 "0.100.500ng_CellLine_0","PDXDC1",0.680505696894022,"#FFDE59"
                 "0.100.500ng_CellLine_0","CKAP5",0.647729046355549,"#FFE0B3"
                 "0.100.500ng_CellLine_0","Others",90.7897611986889,"lightgrey"'
                 ,sep=",",header=T)

g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = g)

cols <- dplyr::select(df, gene, cols) %>%
  distinct() %>%
  deframe()

tr <- levels(df$trt)

p <- ggplot() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[1]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[1],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[2]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[2],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[3]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[3],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[4]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[4],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[5]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[5],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[6]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[6],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[7]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[7],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[8]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[8],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[9]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[9],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[10]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[10], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[11]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[11], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[12]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[12], ncol = 1, title.position = "top")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4),
legend.position = "bottom", legend.justification = 0)

p

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Sat Jun  6 10:25:36 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Sat, 6 Jun 2020 08:25:36 +0000
Subject: [R] R 4.0.1 is released
Message-ID: <E3CC9F48-B248-43DF-82A5-E51EFDD0BFDD@cbs.dk>

The build system rolled up R-4.0.1.tar.gz (codename "See Things Now") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-4/R-4.0.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 425fd186ac71e462e66af7fb33f86ab4
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = 8d199d11865c202cf2bd006e7f32dab7
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 7d8af8c338a1e146f9471744d092078a
MD5 (R-4/R-4.0.1.tar.gz) = 8d199d11865c202cf2bd006e7f32dab7

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
1dfd76a990f2a1b11ee4ff17284d18c2177179ee7bbaef51b32e1e7a58719596  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e  NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0  NEWS.3
95fe24a4d8d8f8f888460c8f5fe4311cec656e7a1722d233218bc03861bc6f32  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
d3cdccb1b1645fce356d08892baa0587aa2aef2e851ad552d47cce856137d9b3  VERSION-INFO.dcf
95fe24a4d8d8f8f888460c8f5fe4311cec656e7a1722d233218bc03861bc6f32  R-4/R-4.0.1.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.0.1:

  NEW FEATURES:

    * paste() and paste0() gain a new optional argument recycle0.  When
      set to true, zero-length arguments are recycled leading to
      character(0) after the sep-concatenation, i.e., to the empty
      string "" if collapse is a string and to the zero-length value
      character(0) when collapse = NULL.

      A package whose code uses this should depend on R (>= 4.0.1).

    * The summary(<warnings>) method now maps the counts correctly to
      the warning messages.

  BUG FIXES:

    * aov(frml, ...) now also works where the formula deparses to more
      than 500 characters, thanks to a report and patch proposal by Jan
      Hauffa.

    * Fix a dozen places (code, examples) as Sys.setlocale() returns
      the new rather than the previous setting.

    * Fix for adding two complex grid units via sum().  Thanks to Gu
      Zuguang for the report and Thomas Lin Pedersen for the patch.

    * Fix parallel::mclapply(..., mc.preschedule=FALSE) to handle raw
      vector results correctly. PR#17779

    * Computing the base value, i.e., 2, "everywhere", now uses
      FLT_RADIX, as the original machar code looped indefinitely on the
      ppc64 architecture for the longdouble case.

    * In R 4.0.0, sort.list(x) when is.object(x) was true, e.g., for x
      <- I(letters), was accidentally using method = "radix".
      Consequently, e.g., merge(<data.frame>) was much slower than
      previously; reported in PR#17794.

    * plot(y ~ x, ylab = quote(y[i])) now works, as e.g., for xlab;
      related to PR#10525.

    * parallel::detect.cores(all.tests = TRUE) tries a matching OS name
      before the other tests (which were intended only for unknown
      OSes).

    * Parse data for raw strings is now recorded correctly. Reported by
      Gabor Csardi.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From m@n|@hmukherjee @end|ng |rom hotm@||@com  Sat Jun  6 11:42:49 2020
From: m@n|@hmukherjee @end|ng |rom hotm@||@com (Manish Mukherjee)
Date: Sat, 6 Jun 2020 09:42:49 +0000
Subject: [R] Dependent data validation in R
Message-ID: <MA1PR01MB3513091A15B791E38F84092CB9870@MA1PR01MB3513.INDPRD01.PROD.OUTLOOK.COM>

Hi All ,
I need help in creating dependent data validation in R while creating an excel workbook
So i have two columns one has country and other states . I have to create the excel workbook in such a way that when i select the one specific country , the corresponding states appear in the next column . Something similar to dependent input in shiny ,
Here is the code what i have written

wb <- createWorkbook()
addWorksheet(wb, "Input")
addWorksheet(wb, "list")

df = data.frame("Country"=c("India","US"))
df1=data.frame("IndiaStates"=c("tamilnadu","Andhra pradesh"))
df2=data.frame("USStates"=c("Texas","California"))

# Add drop-down values "
writeData(wb, sheet = "list", x = df, startCol = 1)
writeData(wb, sheet = "list", x = df1, startCol = 2)
writeData(wb, sheet = "list", x = df2, startCol = 3)
#Add drop-downs to the column
dataValidation(wb, "input", col = 1, rows = 2:5, type = "list", value =
                 "'db'!$A$2:$A$3")

dataValidation(wb, "input", col = 2, rows = 2:5, type = "list", value =
                 "'db'!$b$2:$b$3")

dataValidation(wb, "input", col = 3, rows = 2:5, type = "list", value =
                 "'db'!$c$2:$c$3")

saveWorkbook(wb, "dataValidationExample.xlsx", overwrite = TRUE)


The states should be in single column in exported excel workbook with dependent data validation


Thanks, and Regards

Manish Mukherjee



	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun  6 15:55:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 06 Jun 2020 06:55:26 -0700
Subject: [R] Dependent data validation in R
In-Reply-To: <MA1PR01MB3513091A15B791E38F84092CB9870@MA1PR01MB3513.INDPRD01.PROD.OUTLOOK.COM>
References: <MA1PR01MB3513091A15B791E38F84092CB9870@MA1PR01MB3513.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <ACC8241B-924A-4F4E-A009-59D1C501587F@dcn.davis.ca.us>

Why are you telling us all of this? Do you have a question about the R language? Dragging in stuff about Excel makes it seem like you just want us to do your work for you.

Try to be more specific about what your difficulty is with R. Here are some links that may help:

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On June 6, 2020 2:42:49 AM PDT, Manish Mukherjee <manishmukherjee at hotmail.com> wrote:
>Hi All ,
>I need help in creating dependent data validation in R while creating
>an excel workbook
>So i have two columns one has country and other states . I have to
>create the excel workbook in such a way that when i select the one
>specific country , the corresponding states appear in the next column .
>Something similar to dependent input in shiny ,
>Here is the code what i have written
>
>wb <- createWorkbook()
>addWorksheet(wb, "Input")
>addWorksheet(wb, "list")
>
>df = data.frame("Country"=c("India","US"))
>df1=data.frame("IndiaStates"=c("tamilnadu","Andhra pradesh"))
>df2=data.frame("USStates"=c("Texas","California"))
>
># Add drop-down values "
>writeData(wb, sheet = "list", x = df, startCol = 1)
>writeData(wb, sheet = "list", x = df1, startCol = 2)
>writeData(wb, sheet = "list", x = df2, startCol = 3)
>#Add drop-downs to the column
>dataValidation(wb, "input", col = 1, rows = 2:5, type = "list", value =
>                 "'db'!$A$2:$A$3")
>
>dataValidation(wb, "input", col = 2, rows = 2:5, type = "list", value =
>                 "'db'!$b$2:$b$3")
>
>dataValidation(wb, "input", col = 3, rows = 2:5, type = "list", value =
>                 "'db'!$c$2:$c$3")
>
>saveWorkbook(wb, "dataValidationExample.xlsx", overwrite = TRUE)
>
>
>The states should be in single column in exported excel workbook with
>dependent data validation
>
>
>Thanks, and Regards
>
>Manish Mukherjee
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From rob@|or@yth @end|ng |rom newc@@t|e@@c@uk  Sun Jun  7 12:59:14 2020
From: rob@|or@yth @end|ng |rom newc@@t|e@@c@uk (Rob Forsyth)
Date: Sun, 7 Jun 2020 10:59:14 +0000
Subject: [R] Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
Message-ID: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>

I am using the eRm package to examine the properties of a clinical rating scale using a Partial Credit Model (PCM). I understand how to extract the person ability estimates (thetas) from a simple fitted PCM but I have a dataset with repeated observations over time (~1200 observations of the instrument in ~250 individuals). So as not to violate assumptions of conditional independence I've fitted the PCM to single observations drawn at random from each subject. This works but I would now like to use the item diffculty estimates from the fitted PCM to generate person-ability estimates for the remaining ~950 observations (at other timepoints) not used to fit the model; and I can't see from the eRm package documentation how to do this?

Advice very much appreciated
Rob

From bgunter@4567 @end|ng |rom gm@||@com  Sun Jun  7 17:15:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 7 Jun 2020 08:15:21 -0700
Subject: [R] 
 Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
In-Reply-To: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
References: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
Message-ID: <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>

Such package/methodology specific questions may well go unanswered here.
They are essentially offtopic anyway: this list is about general R
programming questions and cannot be expected to support the ~ 20000
packages now in the ecosystem. I suggest that you contact the package
maintainer (?maintainer) for help or to find out what support resources may
be available.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 7, 2020 at 3:59 AM Rob Forsyth <rob.forsyth at newcastle.ac.uk>
wrote:

> I am using the eRm package to examine the properties of a clinical rating
> scale using a Partial Credit Model (PCM). I understand how to extract the
> person ability estimates (thetas) from a simple fitted PCM but I have a
> dataset with repeated observations over time (~1200 observations of the
> instrument in ~250 individuals). So as not to violate assumptions of
> conditional independence I've fitted the PCM to single observations drawn
> at random from each subject. This works but I would now like to use the
> item diffculty estimates from the fitted PCM to generate person-ability
> estimates for the remaining ~950 observations (at other timepoints) not
> used to fit the model; and I can't see from the eRm package documentation
> how to do this?
>
> Advice very much appreciated
> Rob
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rob@|or@yth @end|ng |rom newc@@t|e@@c@uk  Sun Jun  7 17:31:54 2020
From: rob@|or@yth @end|ng |rom newc@@t|e@@c@uk (Rob Forsyth)
Date: Sun, 7 Jun 2020 15:31:54 +0000
Subject: [R] 
 Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
In-Reply-To: <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>
References: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
 <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>
Message-ID: <968BD577-CB95-4D71-B76A-2907FD1F2129@newcastle.ac.uk>

OK thanks for the guidance
Rob

> On 7 Jun 2020, at 16:15, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ? External sender. Take care when opening links or attachments. Do not provide your login details.
> Such package/methodology specific questions may well go unanswered here. They are essentially offtopic anyway: this list is about general R programming questions and cannot be expected to support the ~ 20000 packages now in the ecosystem. I suggest that you contact the package maintainer (?maintainer) for help or to find out what support resources may be available.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Jun 7, 2020 at 3:59 AM Rob Forsyth <rob.forsyth at newcastle.ac.uk> wrote:
> I am using the eRm package to examine the properties of a clinical rating scale using a Partial Credit Model (PCM). I understand how to extract the person ability estimates (thetas) from a simple fitted PCM but I have a dataset with repeated observations over time (~1200 observations of the instrument in ~250 individuals). So as not to violate assumptions of conditional independence I've fitted the PCM to single observations drawn at random from each subject. This works but I would now like to use the item diffculty estimates from the fitted PCM to generate person-ability estimates for the remaining ~950 observations (at other timepoints) not used to fit the model; and I can't see from the eRm package documentation how to do this?
> 
> Advice very much appreciated
> Rob
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jun  7 20:48:49 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 7 Jun 2020 11:48:49 -0700
Subject: [R] 
 Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
In-Reply-To: <968BD577-CB95-4D71-B76A-2907FD1F2129@newcastle.ac.uk>
References: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
 <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>
 <968BD577-CB95-4D71-B76A-2907FD1F2129@newcastle.ac.uk>
Message-ID: <5612414e-43e4-5a23-f3fa-5bc1e2fd00ab@comcast.net>

There is a StackExchange forum dedicated to Quantitative Finance.


-- 

David.

On 6/7/20 8:31 AM, Rob Forsyth wrote:
> OK thanks for the guidance
> Rob
>
>> On 7 Jun 2020, at 16:15, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> ? External sender. Take care when opening links or attachments. Do not provide your login details.
>> Such package/methodology specific questions may well go unanswered here. They are essentially offtopic anyway: this list is about general R programming questions and cannot be expected to support the ~ 20000 packages now in the ecosystem. I suggest that you contact the package maintainer (?maintainer) for help or to find out what support resources may be available.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Jun 7, 2020 at 3:59 AM Rob Forsyth <rob.forsyth at newcastle.ac.uk> wrote:
>> I am using the eRm package to examine the properties of a clinical rating scale using a Partial Credit Model (PCM). I understand how to extract the person ability estimates (thetas) from a simple fitted PCM but I have a dataset with repeated observations over time (~1200 observations of the instrument in ~250 individuals). So as not to violate assumptions of conditional independence I've fitted the PCM to single observations drawn at random from each subject. This works but I would now like to use the item diffculty estimates from the fitted PCM to generate person-ability estimates for the remaining ~950 observations (at other timepoints) not used to fit the model; and I can't see from the eRm package documentation how to do this?
>>
>> Advice very much appreciated
>> Rob
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u|o@pheno| @end|ng |rom gm@||@com  Sun Jun  7 19:15:56 2020
From: p@u|o@pheno| @end|ng |rom gm@||@com (Paulo Figueiredo)
Date: Sun, 7 Jun 2020 18:15:56 +0100
Subject: [R] R 4.0.1 crashes with R commander
Message-ID: <4362ca7f-e88c-089f-8f2a-b6e7e1d9ac40@gmail.com>

Hi,

I just updated R from 4.0 to 4.0.1 and when trying to load R commander 
(both in R and RStudio) the programme crashes. Any suggestion?

Thanks


-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From p@u|o@pheno| @end|ng |rom gm@||@com  Sun Jun  7 19:53:14 2020
From: p@u|o@pheno| @end|ng |rom gm@||@com (Paulo Figueiredo)
Date: Sun, 7 Jun 2020 18:53:14 +0100
Subject: [R] R 4.0.1 crashes with R Commander
Message-ID: <815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>

Hi again,

as an update, I tried to open R Commander under R 32 bits and it worked, 
but not with R Studio choosing the 32 bit R.

Thus, trying to load R Commander under R Studio (32 and 64 bits) or R 64 
bits crashes the programmes. It only loads under 32 bit R 4.0.1.

Appreciate any help.

Cheers


-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From n|ko@m@t@@ve|@@ @end|ng |rom gm@||@com  Sun Jun  7 23:39:15 2020
From: n|ko@m@t@@ve|@@ @end|ng |rom gm@||@com (Nikos Matsavelas)
Date: Mon, 8 Jun 2020 00:39:15 +0300
Subject: [R] Dynamic Programming in R
Message-ID: <1BCA1844-7297-4D13-B6BE-14A0C76E0A19@gmail.com>

Is there any package that implements Dynamic Programming like maximises/minizises the sum or product in a three way matrix in R?Like the problem that i have solved by hand (attached pdf file)

From |eg|d| @end|ng |rom un|t@@|t  Sun Jun  7 14:49:18 2020
From: |eg|d| @end|ng |rom un|t@@|t (EGIDI LEONARDO)
Date: Sun, 7 Jun 2020 12:49:18 +0000
Subject: [R] [R-pkgs] R: pivmet 0.3.0
In-Reply-To: <DB7PR04MB4714DDBBE318A4F7640A12B3B6860@DB7PR04MB4714.eurprd04.prod.outlook.com>
References: <DB7PR04MB4714DDBBE318A4F7640A12B3B6860@DB7PR04MB4714.eurprd04.prod.outlook.com>
Message-ID: <DB7PR04MB4714A8BB6BF07B57FE04B59CB6840@DB7PR04MB4714.eurprd04.prod.outlook.com>

Dear R users,

pivmet 0.3.0 for pivotal relabelling in Bayesian Mixture Models and Kmeans clustering with pivotal seeding is on CRAN .
The new updated version includes the following new features:


  *   multivariate mixtures
  *   bayesplot plots now available and linked to the package
  *   Stan divergences and diagnostics
  *   updated vignette

CRAN: https://CRAN.R-project.org/package=pivmet<https://cran.r-project.org/package=pivmet>
Github: https://github.com/LeoEgidi/pivmet

Cheers,

Leonardo Egidi
University of Trieste




________________________________
Da: EGIDI LEONARDO
Inviato: venerd? 5 giugno 2020 17:40
A: r-packages at r-project.org <r-packages at r-project.org>
Oggetto: pivmet 0.3.0

Dear R users,

pivmet 0.3.0 for pivotal relabelling in Bayesian Mixture Models and Kmeans clustering with pivotal seeding is on CRAN .
The new updated version includes the following new features:


  *   multivariate mixtures
  *   bayesplot plots now available and linked to the package
  *   Stan divergences and diagnostics
  *   updated vignette

CRAN: https://cran.r-project.org/web/packages/pivmet/index.html
Github: https://github.com/LeoEgidi/pivmet

Cheers,

Leonardo Egidi
University of Trieste


	[[alternative HTML version deleted]]


-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From j|ox @end|ng |rom mcm@@ter@c@  Mon Jun  8 15:43:46 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 8 Jun 2020 13:43:46 +0000
Subject: [R] R 4.0.1 crashes with R Commander
In-Reply-To: <27736_1591620860_058CsJa8002784_815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
References: <27736_1591620860_058CsJa8002784_815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
Message-ID: <5C475426-099C-4920-92B8-FF6B183654FC@mcmaster.ca>

Dear Paulo,

This is due to a known bug in R 4.0.1 for Windows that is general to Tcl/Tk. The bug should be fixed in the current patched version of R 4.0.1 for Windows, so you could use that or just go back to R 4.0.0. 

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Jun 7, 2020, at 1:53 PM, Paulo Figueiredo <paulo.phenol at gmail.com> wrote:
> 
> Hi again,
> 
> as an update, I tried to open R Commander under R 32 bits and it worked, but not with R Studio choosing the 32 bit R.
> 
> Thus, trying to load R Commander under R Studio (32 and 64 bits) or R 64 bits crashes the programmes. It only loads under 32 bit R 4.0.1.
> 
> Appreciate any help.
> 
> Cheers
> 
> 
> -- 
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Mon Jun  8 15:46:28 2020
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Mon, 8 Jun 2020 15:46:28 +0200
Subject: [R] R 4.0.1 crashes with R commander
In-Reply-To: <4362ca7f-e88c-089f-8f2a-b6e7e1d9ac40@gmail.com>
References: <4362ca7f-e88c-089f-8f2a-b6e7e1d9ac40@gmail.com>
Message-ID: <9FCF712D-1807-441C-9F67-E86996FEC835@gmail.com>

This was fixed by r78653, so should be in R-patched already

https://cran.r-project.org/bin/windows/base/rpatched.html

-pd

> On 7 Jun 2020, at 19:15 , Paulo Figueiredo <paulo.phenol at gmail.com> wrote:
> 
> Hi,
> 
> I just updated R from 4.0 to 4.0.1 and when trying to load R commander (both in R and RStudio) the programme crashes. Any suggestion?
> 
> Thanks
> 
> 
> -- 
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jun  8 15:47:25 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 8 Jun 2020 09:47:25 -0400
Subject: [R] R 4.0.1 crashes with R Commander
In-Reply-To: <815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
References: <815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
Message-ID: <62c47f43-ae45-601f-1d0f-9429dae5abc8@gmail.com>

On 07/06/2020 1:53 p.m., Paulo Figueiredo wrote:
> Hi again,
> 
> as an update, I tried to open R Commander under R 32 bits and it worked,
> but not with R Studio choosing the 32 bit R.
> 
> Thus, trying to load R Commander under R Studio (32 and 64 bits) or R 64
> bits crashes the programmes. It only loads under 32 bit R 4.0.1.

There's a report of a bug in 4.0.1 that causes this.  So far it's only 
known to affect Windows, but it may also affect other systems. The only 
thing you can do at the moment is install a nightly build of R-patched 
with revision number of at least r78653.  You can get it from here:

https://cloud.r-project.org/bin/windows/base/rpatched.html

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 16:45:34 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 07:45:34 -0700
Subject: [R] Dynamic Programming in R
In-Reply-To: <1BCA1844-7297-4D13-B6BE-14A0C76E0A19@gmail.com>
References: <1BCA1844-7297-4D13-B6BE-14A0C76E0A19@gmail.com>
Message-ID: <CAGxFJbQ6CgmWEObxRTRbobUnWzJD+XgbyODyQDSFgLTyS9mcug@mail.gmail.com>

Search before posting here!

"dynamic programming R" brought up several relevant hits.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 5:54 AM Nikos Matsavelas <nikosmatsavelas at gmail.com>
wrote:

> Is there any package that implements Dynamic Programming like
> maximises/minizises the sum or product in a three way matrix in R?Like the
> problem that i have solved by hand (attached pdf file)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Jun  8 17:37:46 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 8 Jun 2020 17:37:46 +0200
Subject: [R] ggplot to visualize data
Message-ID: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>

I have a model NN, which has 10 piece of data in 10 folds of test (ts) data
such as 0.1, 0.5, 0.3 etc.
And another model SVM, which also have this type of information. I usually
visualize it like:

boxplot (NN, SVM)

I have two questions?

(1) I want to ask how can I visualize them via ggplot?

(2) If I have to process it again on another dataset, then how can I
combine these two boxplots in order to make a better prediction.

Regards

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 17:41:35 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 08:41:35 -0700
Subject: [R] ggplot to visualize data
In-Reply-To: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
Message-ID: <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>

Largely off topic here. RStudio has Help forums on ggplot and other of its
R software products. Post there.
Or on stats.stackexchange.com perhaps for questions about how to visualize
statistical data.
See the posting guide linked below for what is ON topic here.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 8:38 AM Neha gupta <neha.bologna90 at gmail.com> wrote:

> I have a model NN, which has 10 piece of data in 10 folds of test (ts) data
> such as 0.1, 0.5, 0.3 etc.
> And another model SVM, which also have this type of information. I usually
> visualize it like:
>
> boxplot (NN, SVM)
>
> I have two questions?
>
> (1) I want to ask how can I visualize them via ggplot?
>
> (2) If I have to process it again on another dataset, then how can I
> combine these two boxplots in order to make a better prediction.
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Jun  8 18:18:00 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 8 Jun 2020 18:18:00 +0200
Subject: [R] ggplot to visualize data
In-Reply-To: <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
 <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
Message-ID: <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>

I am still waiting for someone to respond.

If someone want to help other, they do not need a special platform for it.

Thank you, yet again for not helping.

Regards

On Mon, Jun 8, 2020 at 5:41 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Largely off topic here. RStudio has Help forums on ggplot and other of its
> R software products. Post there.
> Or on stats.stackexchange.com perhaps for questions about how to
> visualize statistical data.
> See the posting guide linked below for what is ON topic here.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 8, 2020 at 8:38 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
>
>> I have a model NN, which has 10 piece of data in 10 folds of test (ts)
>> data
>> such as 0.1, 0.5, 0.3 etc.
>> And another model SVM, which also have this type of information. I usually
>> visualize it like:
>>
>> boxplot (NN, SVM)
>>
>> I have two questions?
>>
>> (1) I want to ask how can I visualize them via ggplot?
>>
>> (2) If I have to process it again on another dataset, then how can I
>> combine these two boxplots in order to make a better prediction.
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Mon Jun  8 19:22:28 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 8 Jun 2020 19:22:28 +0200
Subject: [R] ggplot to visualize data
In-Reply-To: <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
 <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
 <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
Message-ID: <CAGAA5bcf_gQLcGM+ytTNtifB8QjEar0+oaZ-34Htb=+oab4Lng@mail.gmail.com>

On Mon, 8 Jun 2020 at 18:25, Neha gupta <neha.bologna90 at gmail.com> wrote:

> I am still waiting for someone to respond.
>
>
Please read this guide about asking questions and try again on the correct
mailing-list.
https://www.r-project.org/posting-guide.html

Regards
Martin

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jun  8 18:58:20 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 8 Jun 2020 17:58:20 +0100
Subject: [R] ggplot to visualize data
In-Reply-To: <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
 <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
 <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
Message-ID: <3c0d8a32-ff1b-8ffb-9388-a753751155bc@sapo.pt>

Hello,

Inline.


?s 17:18 de 08/06/20, Neha gupta escreveu:
> I am still waiting for someone to respond.
> 
> If someone want to help other, they do not need a special platform for it.
> 
> Thank you, yet again for not helping.


1. You have waited 41 minutes.
2. You have not posted data and code.
3. Read the posting guide, please. It's not the first time you post 
questions, and this one does *not* give enough information for anyone to 
answer.
4. I wonder how you can have two models, NN and SVM, and run

boxplot(NN, SVM)

without error. Given the problem description, the code line above simply 
doesn't make sense.

So it's not our fault if you are not getting answers.

Do read the posting guide, please.


Rui Barradas

> 
> Regards
> 
> On Mon, Jun 8, 2020 at 5:41 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Largely off topic here. RStudio has Help forums on ggplot and other of its
>> R software products. Post there.
>> Or on stats.stackexchange.com perhaps for questions about how to
>> visualize statistical data.
>> See the posting guide linked below for what is ON topic here.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Jun 8, 2020 at 8:38 AM Neha gupta <neha.bologna90 at gmail.com>
>> wrote:
>>
>>> I have a model NN, which has 10 piece of data in 10 folds of test (ts)
>>> data
>>> such as 0.1, 0.5, 0.3 etc.
>>> And another model SVM, which also have this type of information. I usually
>>> visualize it like:
>>>

>>>
>>> I have two questions?
>>>
>>> (1) I want to ask how can I visualize them via ggplot?
>>>
>>> (2) If I have to process it again on another dataset, then how can I
>>> combine these two boxplots in order to make a better prediction.
>>>
>>> Regards
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Mon Jun  8 21:27:56 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Mon, 8 Jun 2020 19:27:56 +0000
Subject: [R] phyl.RMA error
Message-ID: <BY5PR12MB418052F64481EA592994FD49F6850@BY5PR12MB4180.namprd12.prod.outlook.com>

Hello,

We're trying to run phylogenetically corrected reduced major axes regression analyses and have encountered an error we can't debug. We're using the function phyl.RMA in the package 'phytools'. Here is the code we are using and the error it returns.



>Model <- phyl.RMA(log(Skull), log(Tusk), tree, h0=1.0)

Error in if (sign(beta1) != sign(h0)) { :

  missing value where TRUE/FALSE needed

We can't seem to figure out which argument is missing, and we've tried including all of the T/F based arguments we think are possible. Our species dataset and nexus file are printed below.  Any advice would be greatly appreciated.

We have the following dataset:
Binomial                 Skull  Tusk
   <chr>                    <dbl> <dbl>
1 Tragulus_javanicus        93.7  14.6
2 Tragulus_kanchil          99.7  13.9
3 Tragulus_napu             98.1  11.1
4 Tragulus_nigricans        99.8  13.2
5 Moschiola_meminna        101.   14.6
6 Moschus_berezovskii      134.   55.0
7 Moschus_moschiferus      152.   52.9
8 Muntiacus_muntjak        193.   26.4
9 Muntiacus_reevesi        159.   23.4
10 Muntiacus_truongsonensis 184.   27.7
11 Muntiacus_vaginalis      203.   28.6
12 Hydropotes_inermis       162.   48.5
13 Hyemoschus_aquaticus     122.   20.1
14 Elaphodus_cephalophus    186.   17.3

And the following nexus tree:

#NEXUS
[R-package APE, Mon Jun 08 12:20:01 2020]

BEGIN TAXA;
              DIMENSIONS NTAX = 12;
              TAXLABELS
                             Tragulus_napu
                             Tragulus_kanchil
                             Tragulus_javanicus
                             Hyemoschus_aquaticus
                             Moschiola_meminna
                             Muntiacus_reevesi
                             Muntiacus_muntjak
                             Muntiacus_truongsonensis
                             Elaphodus_cephalophus
                             Hydropotes_inermis
                             Moschus_moschiferus
                             Moschus_berezovskii
              ;
END;
BEGIN TREES;
              TRANSLATE
                             1            Tragulus_napu,
                             2            Tragulus_kanchil,
                             3            Tragulus_javanicus,
                             4            Hyemoschus_aquaticus,
                             5            Moschiola_meminna,
                             6            Muntiacus_reevesi,
                             7            Muntiacus_muntjak,
                             8            Muntiacus_truongsonensis,
                             9            Elaphodus_cephalophus,
                             10          Hydropotes_inermis,
                             11          Moschus_moschiferus,
                             12          Moschus_berezovskii
              ;
              TREE * UNTITLED = [&R] ((((1:5.540957781,(2:2.978817423,3:2.978817423):2.562139698):10.78911152,4:16.33006601):6.360692368,5:22.69076035):5.725388419,(((((6:1.611149584,7:1.611149848):1.556474893,8:3.167624477):4.130280196,9:7.297904013):1.497063399,10:8.794967413):7.19682079,(11:2.539095678,12:2.539096008):13.45269085):12.42436025);



Dr. Ted Stankowich
Associate Professor
Department of Biological Sciences
California State University Long Beach
Long Beach, CA 90840
theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
562-985-4826
http://www.csulb.edu/mammal-lab/
@CSULBMammalLab




	[[alternative HTML version deleted]]


From motyoc@k@ @end|ng |rom y@hoo@com  Mon Jun  8 21:28:35 2020
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Mon, 8 Jun 2020 19:28:35 +0000 (UTC)
Subject: [R] (almost) rolling function or fill?
References: <2102647901.806088.1591644515768.ref@mail.yahoo.com>
Message-ID: <2102647901.806088.1591644515768@mail.yahoo.com>

Hello,
please see if you have a thought on how to achieve the following:
we have:
 df<-data.frame(a=Sys.Date()+1:10,? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,NA,rep(3,4),NA,NA,3),? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,NA,rep(9,4),NA,NA,9))


the idea I have difficulty wrapping my head around is to do the following: I need the system to look at df$a by row (lets call it the index row) and look at df$b and df$c 1 row before the given row in df$a? (lets call it index row -1)?and evaluate if the index row value in df$a falls into the range (>= and <=) of the index row -1 values in df$b and df$c. If it does, then copy over?the index row -1 values in df$b and df$c into the index row in?df$b and df$c, if not place an NA in both cells of the?index row in?df$b and df$c.?
?examples:
1. the date value in df$a[8] is between df$b[7] and df$c[7] so we can copy the values in?df$b[7] and df$c[7] into?df$b[8] and df$c[8]2.??the date value in df$a[9] is between df$b[8] and df$c[8] (as we copied it in in step 1)? so we can copy the values in?df$b[8] and df$c[8] into?df$b[9] and df$c[9]3.??the date value in df$a[10] is NOT between df$b[9] and df$c[9] (as we copied it in in step 2)? so we can place NA in?df$b[10] and df$c[10]?

also would like to do this going up, too, similar to fill(...,"downup"). On the end we would want to have this:
 dfwanted<-data.frame(a=Sys.Date()+1:10,? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,rep(3,7),NA),? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,rep(9,7),NA))


much appreciate any help you could provide.
thanks,

Andras?
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 23:00:42 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 14:00:42 -0700
Subject: [R] (almost) rolling function or fill?
In-Reply-To: <2102647901.806088.1591644515768@mail.yahoo.com>
References: <2102647901.806088.1591644515768.ref@mail.yahoo.com>
 <2102647901.806088.1591644515768@mail.yahoo.com>
Message-ID: <CAGxFJbRhkEekk403cmavG_FDi_dwzM_3rMHkm5Vi0NM=ij=zQw@mail.gmail.com>

This is a plain text list. Your html post was completely mangled. Re-post
in plain text, please.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 1:08 PM Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Hello,
> please see if you have a thought on how to achieve the following:
> we have:
>  df<-data.frame(a=Sys.Date()+1:10,
>  b=Sys.Date()+c(NA,NA,NA,rep(3,4),NA,NA,3),
>  c=Sys.Date()+c(NA,NA,NA,rep(9,4),NA,NA,9))
>
>
> the idea I have difficulty wrapping my head around is to do the following:
> I need the system to look at df$a by row (lets call it the index row) and
> look at df$b and df$c 1 row before the given row in df$a  (lets call it
> index row -1) and evaluate if the index row value in df$a falls into the
> range (>= and <=) of the index row -1 values in df$b and df$c. If it does,
> then copy over the index row -1 values in df$b and df$c into the index row
> in df$b and df$c, if not place an NA in both cells of the index row in df$b
> and df$c.
>  examples:
> 1. the date value in df$a[8] is between df$b[7] and df$c[7] so we can copy
> the values in df$b[7] and df$c[7] into df$b[8] and df$c[8]2.  the date
> value in df$a[9] is between df$b[8] and df$c[8] (as we copied it in in step
> 1)  so we can copy the values in df$b[8] and df$c[8] into df$b[9] and
> df$c[9]3.  the date value in df$a[10] is NOT between df$b[9] and df$c[9]
> (as we copied it in in step 2)  so we can place NA in df$b[10] and df$c[10]
>
> also would like to do this going up, too, similar to fill(...,"downup").
> On the end we would want to have this:
>  dfwanted<-data.frame(a=Sys.Date()+1:10,
>  b=Sys.Date()+c(NA,NA,rep(3,7),NA),
>  c=Sys.Date()+c(NA,NA,rep(9,7),NA))
>
>
> much appreciate any help you could provide.
> thanks,
>
> Andras
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 23:08:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 14:08:54 -0700
Subject: [R] phyl.RMA error
In-Reply-To: <BY5PR12MB418052F64481EA592994FD49F6850@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB418052F64481EA592994FD49F6850@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <CAGxFJbQG5+4=RgqxLdW+tHr-uzOmRY+v8hSTcivx8yxTPjotTg@mail.gmail.com>

Do you have NA's or Infs in your beta1 due to the use of log(Skull) and
log(Tusk) in your modeling or did you misspell something?.

If it's not something "obvious" like that, you should probably post on the
r-sig-ecology list instead, where you are more likely to find both the
interest and expertise in this specialized topic. This list is for general
R language questions primarily.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 12:28 PM Ted Stankowich <
Theodore.Stankowich at csulb.edu> wrote:

> Hello,
>
> We're trying to run phylogenetically corrected reduced major axes
> regression analyses and have encountered an error we can't debug. We're
> using the function phyl.RMA in the package 'phytools'. Here is the code we
> are using and the error it returns.
>
>
>
> >Model <- phyl.RMA(log(Skull), log(Tusk), tree, h0=1.0)
>
> Error in if (sign(beta1) != sign(h0)) { :
>
>   missing value where TRUE/FALSE needed
>
> We can't seem to figure out which argument is missing, and we've tried
> including all of the T/F based arguments we think are possible. Our species
> dataset and nexus file are printed below.  Any advice would be greatly
> appreciated.
>
> We have the following dataset:
> Binomial                 Skull  Tusk
>    <chr>                    <dbl> <dbl>
> 1 Tragulus_javanicus        93.7  14.6
> 2 Tragulus_kanchil          99.7  13.9
> 3 Tragulus_napu             98.1  11.1
> 4 Tragulus_nigricans        99.8  13.2
> 5 Moschiola_meminna        101.   14.6
> 6 Moschus_berezovskii      134.   55.0
> 7 Moschus_moschiferus      152.   52.9
> 8 Muntiacus_muntjak        193.   26.4
> 9 Muntiacus_reevesi        159.   23.4
> 10 Muntiacus_truongsonensis 184.   27.7
> 11 Muntiacus_vaginalis      203.   28.6
> 12 Hydropotes_inermis       162.   48.5
> 13 Hyemoschus_aquaticus     122.   20.1
> 14 Elaphodus_cephalophus    186.   17.3
>
> And the following nexus tree:
>
> #NEXUS
> [R-package APE, Mon Jun 08 12:20:01 2020]
>
> BEGIN TAXA;
>               DIMENSIONS NTAX = 12;
>               TAXLABELS
>                              Tragulus_napu
>                              Tragulus_kanchil
>                              Tragulus_javanicus
>                              Hyemoschus_aquaticus
>                              Moschiola_meminna
>                              Muntiacus_reevesi
>                              Muntiacus_muntjak
>                              Muntiacus_truongsonensis
>                              Elaphodus_cephalophus
>                              Hydropotes_inermis
>                              Moschus_moschiferus
>                              Moschus_berezovskii
>               ;
> END;
> BEGIN TREES;
>               TRANSLATE
>                              1            Tragulus_napu,
>                              2            Tragulus_kanchil,
>                              3            Tragulus_javanicus,
>                              4            Hyemoschus_aquaticus,
>                              5            Moschiola_meminna,
>                              6            Muntiacus_reevesi,
>                              7            Muntiacus_muntjak,
>                              8            Muntiacus_truongsonensis,
>                              9            Elaphodus_cephalophus,
>                              10          Hydropotes_inermis,
>                              11          Moschus_moschiferus,
>                              12          Moschus_berezovskii
>               ;
>               TREE * UNTITLED = [&R]
> ((((1:5.540957781,(2:2.978817423,3:2.978817423):2.562139698):10.78911152,4:16.33006601):6.360692368,5:22.69076035):5.725388419,(((((6:1.611149584,7:1.611149848):1.556474893,8:3.167624477):4.130280196,9:7.297904013):1.497063399,10:8.794967413):7.19682079,(11:2.539095678,12:2.539096008):13.45269085):12.42436025);
>
>
>
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach
> Long Beach, CA 90840
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From V|ncent@Gou|et @end|ng |rom @ct@u|@v@|@c@  Mon Jun  8 16:46:08 2020
From: V|ncent@Gou|et @end|ng |rom @ct@u|@v@|@c@ (Vincent Goulet)
Date: Mon, 8 Jun 2020 14:46:08 +0000
Subject: [R] [R-pkgs] 3.0-0 milestone for actuar
Message-ID: <4E58D00B-0A44-47EA-810F-9EB09EDC02D2@act.ulaval.ca>

Dear useRs and developeRs,

We are proud to announce that version 3.0-0 of actuar is now available on CRAN.

This newest release further extends support of the package for heavy tail and extreme value size distributions. It also introduces a package API, so that developers may easily integrate our C code into their own package.

From the NEWS file:

? Support functions ?[dpqrm,lev]fpareto? for the Feller-Pareto
  distribution and related Pareto distributions with a
  location parameter. The Feller-Pareto defines a large family
  of distributions encompassing the transformed beta family
  and many variants of the Pareto distribution. Using the
  nomenclature of Arnold (2015), the following distributions
  are now supported by ?actuar?: Feller-Pareto, Pareto IV,
  Pareto III, and Pareto II. The Pareto I was already
  supported under the name Single Parameter Pareto.

? The package now exposes through an API its 200+ C routines
  for probability functions and the beta integral. This is
  documented in a new section of the ?distributions? package
  vignette. See file ?include/actuarAPI.h? in the package
  installation directory for the complete list of exported
  routines.

The complete NEWS is available on CRAN as usual:

	https://cran.r-project.org/web/packages/actuar/news.html

Cheers,

Vincent Goulet
Professor
?cole d'actuariat, Universit? Laval

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From |v@|ery @end|ng |rom out|ook@|r  Mon Jun  8 18:52:08 2020
From: |v@|ery @end|ng |rom out|ook@|r (=?utf-8?B?TG/Dr2MgVmFsw6lyeQ==?=)
Date: Mon, 8 Jun 2020 16:52:08 +0000
Subject: [R] Need help using GRASS within R - problem with CRS using the
 'v.generalize' command
Message-ID: <AM5PR0601MB2692F2F68C0EA1E1169E663BD0850@AM5PR0601MB2692.eurprd06.prod.outlook.com>

Dear all,

First of all, this is my first message on the list. Therefore, please be indulgent if my message is not perfectly formatted as it should be. 

I am currently encountering a difficulty with GRASS 7.8 within R when using the 'v.generalize' command to smooth the contour of polygons after a segmentation step.

I tried two different ways to "call" GRASS: 

          1 - using the RQGIS3 package
          2 - using the rgrass7 package

The first method returns an error message (i.e. "proj_create_from_database: Cannot find proj.db") and therefore does not produce any result.
The second method results in a layer of smoothed polygons but the projection reference (i.e. CRS) is lost whereas the input layer has one.

Since in both cases the problem seems to be the same (i.e. GRASS fails to access the projection information), I thought it was interesting to deal with these two cases simultaneously. So, below you will find two small examples - each dealing with one of the two procedures - in order to clarify the problem.

1 - Example using the RQGIS3 package :

> setwd("D:/test")
> library(sp)
> library(rgdal)
rgdal: version: 1.4-8, (SVN revision 845)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20
Path to GDAL shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/gdal
GDAL binary built with GEOS: TRUE 
Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]
Path to PROJ.4 shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj
Linking to sp version: 1.4-1 
> library(rgeos)
rgeos version: 0.5-3, (SVN revision 634)
GEOS runtime version: 3.8.0-CAPI-1.13.1 
Linking to sp version: 1.4-1 
Polygon checking: TRUE 
> library(raster)
> library(sf)
Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1
> library(reticulate, lib.loc="C:/Users/toto/documents/RQGIS3")
> library(RQGIS3, lib.loc="C:/Users/toto/Documents/RQGIS3")

> # set the environment to run QGIS from within R
> set_env(root="C:/Program Files/QGIS 3.12")

$root
[1] "C:/Program Files/QGIS 3.12"

$qgis_prefix_path
[1] "C:/Program Files/QGIS 3.12/apps/qgis"

$python_plugins
[1] "C:/Program Files/QGIS 3.12/apps/qgis/python/plugins"

$platform
[1] "Windows"

 

> # Opening of the application
> open_app()
proj_create_from_database: Cannot find proj.db
proj_create_from_database: Cannot find proj.db

However, this does not completely prevent the package from working because I can find the function I want, call it and enter the input parameters. Here is an excerpt :

> # Search for the desired function within QGIS 3.12
> find_algorithms(search_term="generalize", name_only=TRUE)
[1] "grass7:v.generalize"

> # Information on how to use the selected function (here, the function 'generalize' from GRASS 7 within QGIS 3.12)
> get_usage(alg="grass7:v.generalize")
v.generalize (grass7:v.generalize)
Vector based generalization.
 ----------------
Input parameters
----------------

input: Input layer
         Parameter type:  QgsProcessingParameterFeatureSource
         Accepted data types:
                 - str: layer ID
                 - str: layer name
                 - str: layer source
                 - QgsProcessingFeatureSourceDefinition
                 - QgsProperty
                 - QgsVectorLayer
 
type: Input feature type
         Parameter type:  QgsProcessingParameterEnum
         Available values:
                 - 0: line
                 - 1: boundary
                 - 2: area
         Accepted data types:
                 - int
                 - str: as string representation of int
e.g. 1
                 - QgsProperty

 
> # Indicates the mandatory parameters
> params <- get_args_man(alg = "grass7:v.generalize")
Choosing default values for following parameters:
type: 0
method: 0
GRASS_OUTPUT_TYPE_PARAMETER: 0
See get_options('grass7:v.generalize') for all available options.

> # Input of mandatory parameters
> params$input<-"D:/test/seg_poly.shp"
> params$type<-"0"
> params$method<-"7"
> params$threshold<-1
> params$output<-"D:/test/smooth_seg_poly.shp"
> params$error<- "D:/test/smooth_seg_poly_error.shp"
> params$GRASS_OUTPUT_TYPE_PARAMETER<-"0"

But when I execute the function, R returns an error message that is related to the previous error message (i.e. when I executed the 'open_app()' command). Please find below the second error message :

> # Execution of the selected function
> out <- run_qgis(alg = "grass7:v.generalize",
+                 params = params,
+                 load_output = TRUE)

ERROR 1: PROJ: proj_identify: Cannot find proj.db
proj_create_from_wkt: Cannot find proj.db
proj_identify: Cannot find proj.db
Error in py_call_impl(callable, dots$args, dots$keywords) : 

  QgsProcessingException: There were errors executing the algorithm.

Detailed traceback: 
  File "C:/Program Files/QGIS 3.12/apps/qgis/python/plugins\processing\tools\general.py", line 106, in run
    return Processing.runAlgorithm(algOrName, parameters, onFinish, feedback, context)
  File "C:/Program Files/QGIS 3.12/apps/qgis/python/plugins\processing\core\Processing.py", line 181, in runAlgorithm
    raise QgsProcessingException(msg)

 

To help you find the solution to the problem, here are the results of some commands specifying the working environment :

> Sys.info()
       sysname        release        version       nodename        machine          login           user effective_user 
     "Windows"      "8.1 x64"   "build 9600"     "BERNACHE"       "x86-64"         "toto"         "toto"         "toto" 

> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8.1 x64 (build 9600)
Matrix products: default

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C                  
[5] LC_TIME=French_France.1252    
 
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RQGIS3_1.0.1.9000 reticulate_1.16   sf_0.9-3          raster_3.1-5      rgeos_0.5-3       rgdal_1.4-8       sp_1.4-2         

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6       compiler_3.6.3     pillar_1.4.4       class_7.3-15       tools_3.6.3        jsonlite_1.6.1     tibble_3.0.1      
 [8] lifecycle_0.2.0    lattice_0.20-38    pkgconfig_2.0.3    rlang_0.4.6        Matrix_1.2-18      DBI_1.1.0          cli_2.0.2         
[15] rstudioapi_0.11    parallel_3.6.3     e1071_1.7-3        stringr_1.4.0      vctrs_0.3.0        hms_0.5.3          classInt_0.4-3    
[22] grid_3.6.3         glue_1.4.1         R6_2.4.1           fansi_0.4.1        readr_1.3.1        magrittr_1.5       codetools_0.2-16  
[29] ellipsis_0.3.1     units_0.6-6        assertthat_0.2.1   KernSmooth_2.23-16 stringi_1.4.6      crayon_1.3.4      

> qgis_session_info()

$gdal
[1] "3.0.4"

$grass7
[1] FALSE

$qgis_version
[1] "3.12.0-Bucure?ti"

$saga
[1] "2.3.2"

 Finally, since the problem probably comes from accessing the proj.db file, I ran the command Sys.getenv(?PROJ_LIB?) and R finds two locations?

> Sys.getenv("PROJ_LIB")
[1] "C:/Program Files/QGIS 3.12/share/proj;C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj"

 
Please, note that, when searching on my computer, the file proj.db is also found in the following locations (which R does not seem to find) :
1.       C:/Users/toto/Documents/R/win-library/3.6/sf/proj
2.       C:/Programmes/GRASS GIS 7.8/share/proj
3.       C:/Programmes/QGIS 3.12/apps/Python3.7/lib/site-packages/pyproj/proj-dir/share/proj



2 - EXAMPLE USING THE RGRASS7 PACKAGE

seg_poly = a SpatialPolygonsDataFrame with CRS (cf. below) :

> setwd("D:/test")
> library(rgrass7)
> 
> # characteristics of the SpatialPolygonsDataFrame 'seg_poly' : CRS does exist
> seg_poly
class       : SpatialPolygonsDataFrame 
features    : 31 
extent      : 477371.3, 477397.6, 5631995, 5632020  (xmin, xmax, ymin, ymax)
crs         : +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs 
variables   : 1
names       : Seg_ID 
min values  :      1 
max values  :     31 
Warning message:
In proj4string(x) : CRS object has comment, which is lost in output
> 
> # initialization of GRASS 7.8 from R
> initGRASS(gisBase ="C:/Program Files/GRASS GIS 7.8", home="temp/GRASS",gisDbase="temp/GRASS", use_g.dirseps.exe=F,remove_GISRC=T, override=T)
gisdbase    temp/GRASS 
location    file19685026c56 
mapset      file196829fa7141 
rows        1 
columns     1 
north       1 
south       0 
west        0 
east        1 
nsres       1 
ewres       1 
projection  NA 

I suspect that the problem comes from 'projection NA' when initializing GRASS (cf. just above)


Running GRASS : everything seems to be going fine...

> # specifies to GRASS that objects of type "sp" are used
> rgrass7::use_sp()
> 
> # export of the vector in GRASS format from the sp object 'seg_poly'
> writeVECT(seg_poly,"vec1",v.in.ogr_flags=c("o", "overwrite"), driver="ESRI Shapefile")
>

> # run the 'v.generalize' command to smooth the contours of polygons
> execGRASS("v.generalize",flag=c("overwrite"),parameters=list(input="vec1",
+                                                              output="GRASS_smooth_seg_poly",
+                                                              error="GRASS_smooth_seg_poly_error",
+                                                              method="distance_weighting",
+                                                              threshold=1))


...but when retrieving the result, the CRS has been lost :

> # retrieving the result of the 'v.generalize' command in a SpatialPolygonDataFrame : 'smooth_seg_poly'
> smooth_seg_poly<-readVECT("GRASS_smooth_seg_poly", with_prj=T, driver="ESRI Shapefile")
Exporting 31 areas (may take some time)...
 100%
VOUTOG~1 termin?. 31 features (Polygon type) written to <GRASS_sm>
(ESRI_Shapefile format).
OGR data source with driver: ESRI Shapefile 
Source: "D:\test\temp\GRASS\file19685026c56\file196829fa7141\.tmp\unknown", layer: "GRASS_sm"
with 31 features
It has 2 fields
Warning message:
In vColumns(vname) : vColumns: v.info -c output not in two columns:
Displaying column types/names for database connection of layer <1>:
> 
> # characteristics of the SpatialPolygonsDataFrame 'smoooth_seg_poly' : CRS no longer exists !!!
> smooth_seg_poly
class       : SpatialPolygonsDataFrame 
features    : 31 
extent      : 477371.3, 477397.6, 5631995, 5632020  (xmin, xmax, ymin, ymax)
crs         : NA 
variables   : 2
names       : cat, Seg_ID 
min values  :   1,      1 
max values  :  31,     31 


If it helps some info on my R session and on some environment variables (i.e. PROJ_LIB and GRASS_PROJSHARE)

> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8.1 x64 (build 9600)

Matrix products: default

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C                  
[5] LC_TIME=French_France.1252    

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] RSAGA_1.3.0         plyr_1.8.6          shapefiles_0.7      foreign_0.8-75      gstat_2.0-6         exactextractr_0.4.0 sf_0.9-3           
 [8] rgrass7_0.2-1       RSQLite_2.2.0       XML_3.99-0.3        RQGIS3_1.0.1.9000   reticulate_1.16     smoothr_0.1.2       maptools_1.0-1     
[15] link2GI_0.4.3       glue_1.4.1          listviewer_3.0.0    raster_3.1-5        rgeos_0.5-3         rgdal_1.5-8         sp_1.4-2           

loaded via a namespace (and not attached):
 [1] pkgload_1.0.2      bit64_0.9-7        jsonlite_1.6.1     R.utils_2.9.2      assertthat_0.2.1   blob_1.2.1         remotes_2.1.1     
 [8] sessioninfo_1.1.1  pillar_1.4.4       backports_1.1.7    lattice_0.20-38    digest_0.6.25      R.oo_1.23.0        htmltools_0.4.0   
[15] Matrix_1.2-18      pkgconfig_2.0.3    devtools_2.3.0     purrr_0.3.4        intervals_0.15.2   processx_3.4.2     tibble_3.0.1      
[22] usethis_1.6.1      ellipsis_0.3.1     withr_2.2.0        cli_2.0.2          magrittr_1.5       crayon_1.3.4       memoise_1.1.0     
[29] ps_1.3.3           R.methodsS3_1.8.0  fs_1.4.1           fansi_0.4.1        xts_0.12-0         xml2_1.3.2         class_7.3-15      
[36] FNN_1.1.3          pkgbuild_1.0.8     prettyunits_1.1.1  hms_0.5.3          lifecycle_0.2.0    stringr_1.4.0      callr_3.4.3       
[43] compiler_3.6.3     e1071_1.7-3        spacetime_1.2-3    rlang_0.4.6        classInt_0.4-3     units_0.6-6        grid_3.6.3        
[50] rstudioapi_0.11    htmlwidgets_1.5.1  testthat_2.3.2     codetools_0.2-16   DBI_1.1.0          roxygen2_7.1.0     R6_2.4.1          
[57] zoo_1.8-8          knitr_1.28         bit_1.1-15.2       rprojroot_1.3-2    KernSmooth_2.23-16 readr_1.3.1        desc_1.2.0        
[64] stringi_1.4.6      parallel_3.6.3     Rcpp_1.0.4.6       vctrs_0.3.0        xfun_0.14         
> 
> Sys.getenv("PROJ_LIB")
[1] "C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj"
> Sys.getenv("GRASS_PROJSHARE")
[1] "NA\\share\\proj"

I guess that the "NA\\share\\proj" just above is not normal but I don't know precisely what path should be the right one...  and this anomaly may not be the only problem...

As a novice in the field, I would be very grateful for your help.
I remain at your entire disposal for any further information you may need to help me in finding a solution to this problem.

Yours sincerely,
Lo?c

From h||u @end|ng |rom w@ve|||e@c|@com  Mon Jun  8 21:58:21 2020
From: h||u @end|ng |rom w@ve|||e@c|@com (Hui Liu)
Date: Mon, 8 Jun 2020 19:58:21 +0000
Subject: [R] to read data for GCalignR package
Message-ID: <BN8PR04MB6259F64C7F6C96E12549E467D7850@BN8PR04MB6259.namprd04.prod.outlook.com>

Dear R-help colleagues,

I am looking for a way to read my txt file into R such that it can pass the check_input() function and be processed by in GCalignR.

The vignette mentioned to save data in txt format, with first row listing items, 2nd row listing RT and Area, third rows and afterwards concatenate multiple RT and area from items listed in first row.

I did this but did not find an effective way to import this data. Tried read.delim, scan, read individual and combine into a list. Saved to system.file and read as the example data. None worked.

Any suggestions?

Thank you very much.

Hui

Wave Life Sciences Email Confidentiality Notice: This message, including any attachments, is for use by the intended recipient(s) and may be proprietary, confidential and/or privileged. If you are not the intended recipient(s), please destroy all copies of this message and any attachments. Any use, forwarding, copying, or printing of this message or portion thereof by anyone other than the intended recipient(s) is prohibited. This email neither constitutes an agreement to conduct transactions by electronic means nor creates any legally binding contract or enforceable obligation in the absence of a fully signed written contract.

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: CDs02.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200608/44326c74/attachment.txt>

From jrkr|de@u @end|ng |rom gm@||@com  Tue Jun  9 00:08:11 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 8 Jun 2020 18:08:11 -0400
Subject: [R] to read data for GCalignR package
In-Reply-To: <BN8PR04MB6259F64C7F6C96E12549E467D7850@BN8PR04MB6259.namprd04.prod.outlook.com>
References: <BN8PR04MB6259F64C7F6C96E12549E467D7850@BN8PR04MB6259.namprd04.prod.outlook.com>
Message-ID: <CAKZQJMDasKsL=+4K3Ntb8PfPPXic2saccL8kuaQDtNp2xk+-xQ@mail.gmail.com>

I am not sure what they are doing but have a look at
https://rdrr.io/cran/GCalignR/man/read_peak_list.html




On Mon, 8 Jun 2020 at 17:38, Hui Liu <hliu at wavelifesci.com> wrote:

> Dear R-help colleagues,
>
> I am looking for a way to read my txt file into R such that it can pass
> the check_input() function and be processed by in GCalignR.
>
> The vignette mentioned to save data in txt format, with first row listing
> items, 2nd row listing RT and Area, third rows and afterwards concatenate
> multiple RT and area from items listed in first row.
>
> I did this but did not find an effective way to import this data. Tried
> read.delim, scan, read individual and combine into a list. Saved to
> system.file and read as the example data. None worked.
>
> Any suggestions?
>
> Thank you very much.
>
> Hui
>
> Wave Life Sciences Email Confidentiality Notice: This message, including
> any attachments, is for use by the intended recipient(s) and may be
> proprietary, confidential and/or privileged. If you are not the intended
> recipient(s), please destroy all copies of this message and any
> attachments. Any use, forwarding, copying, or printing of this message or
> portion thereof by anyone other than the intended recipient(s) is
> prohibited. This email neither constitutes an agreement to conduct
> transactions by electronic means nor creates any legally binding contract
> or enforceable obligation in the absence of a fully signed written contract.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From motyoc@k@ @end|ng |rom y@hoo@com  Tue Jun  9 00:13:07 2020
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Mon, 8 Jun 2020 22:13:07 +0000 (UTC)
Subject: [R] (almost) rolling or fill function?
References: <1502226575.863816.1591654387337.ref@mail.yahoo.com>
Message-ID: <1502226575.863816.1591654387337@mail.yahoo.com>

Thanks Bert, here it is in plain.



Hello,

please see if you have a thought on how to achieve the following:

we have:

df<-data.frame(a=Sys.Date()+1:10,
? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,NA,rep(3,4),NA,NA,3),
? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,NA,rep(9,4),NA,NA,9))



the idea I have difficulty wrapping my head around is to do the following: I need the system to look at df$a by row (lets call it the index row) and look at df$b and df$c 1 row before the given row in df$a??(lets call it index row -1)?and evaluate if the index row value in df$a falls into the range (>= and <=) of the index row -1 values in df$b and df$c. If it does, then copy over?the index row -1 values in df$b and df$c into the index row in?df$b and df$c, if not place an NA in both cells of the?index row in?df$b and df$c.?

?examples:

1. the date value in df$a[8] is between df$b[7] and df$c[7] so we can copy the values in?df$b[7] and df$c[7] into?df$b[8] and df$c[8]
2.??the date value in df$a[9] is between df$b[8] and df$c[8] (as we copied it in in step 1)? so we can copy the values in?df$b[8] and df$c[8] into?df$b[9] and df$c[9]
3.??the date value in df$a[10] is NOT between df$b[9] and df$c[9] (as we copied it in in step 2)? so we can place NA in?df$b[10] and df$c[10]?


also would like to do this going up, too, similar to fill(...,"downup"). On the end we would want to have this:

dfwanted<-data.frame(a=Sys.Date()+1:10,
? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,rep(3,7),NA),
? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,rep(9,7),NA))



much appreciate any help you could provide.

thanks,


Andras?


Andras?


From t@v|b@r @end|ng |rom gm@||@com  Tue Jun  9 08:44:19 2020
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 9 Jun 2020 09:44:19 +0300
Subject: [R] Need help using GRASS within R - problem with CRS using the
 'v.generalize' command
In-Reply-To: <AM5PR0601MB2692F2F68C0EA1E1169E663BD0850@AM5PR0601MB2692.eurprd06.prod.outlook.com>
References: <AM5PR0601MB2692F2F68C0EA1E1169E663BD0850@AM5PR0601MB2692.eurprd06.prod.outlook.com>
Message-ID: <dabf4146-6c35-030b-e7ff-2b88b6ef117b@gmail.com>

Hello


On 08/06/2020 19:52, Lo?c Val?ry wrote:
> Dear all,
>
> First of all, this is my first message on the list. Therefore, please be indulgent if my message is not perfectly formatted as it should be.
>
> I am currently encountering a difficulty with GRASS 7.8 within R when using the 'v.generalize' command to smooth the contour of polygons after a segmentation step.
>
> I tried two different ways to "call" GRASS:
>
>            1 - using the RQGIS3 package

My first suggestion: no need for getting QGIS involved here. That's an 
extra layer of complication that seems unnecessary, given your goal of 
using the GRASS module, v.generalize.


>            2 - using the rgrass7 package
>
> The first method returns an error message (i.e. "proj_create_from_database: Cannot find proj.db") and therefore does not produce any result.
> The second method results in a layer of smoothed polygons but the projection reference (i.e. CRS) is lost whereas the input layer has one.
>
> Since in both cases the problem seems to be the same (i.e. GRASS fails to access the projection information), I thought it was interesting to deal with these two cases simultaneously. So, below you will find two small examples - each dealing with one of the two procedures - in order to clarify the problem.
>
> 1 - Example using the RQGIS3 package :
>
>> setwd("D:/test")
>> library(sp)
>> library(rgdal)
> rgdal: version: 1.4-8, (SVN revision 845)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20
> Path to GDAL shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/gdal
> GDAL binary built with GEOS: TRUE
> Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]
> Path to PROJ.4 shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj
> Linking to sp version: 1.4-1


Please note that you have older versions of GDAL (2.2.3 here) and PROJ.4 
(4.9 here). These are currently being replaced by GDAL 3.0 and PROJ 6.3. 
You might (should) want to follow the discussion the the r-sig-geo maillist:


https://stat.ethz.ch/pipermail/r-sig-geo/2020-June/028165.html


....... (skipped all the discussion regarding RQGIS3 as I think it's not 
relevant)
>
>
> 2 - EXAMPLE USING THE RGRASS7 PACKAGE
>
> seg_poly = a SpatialPolygonsDataFrame with CRS (cf. below) :
>
>> setwd("D:/test")
>> library(rgrass7)
>>
>> # characteristics of the SpatialPolygonsDataFrame 'seg_poly' : CRS does exist
>> seg_poly
> class       : SpatialPolygonsDataFrame
> features    : 31
> extent      : 477371.3, 477397.6, 5631995, 5632020  (xmin, xmax, ymin, ymax)
> crs         : +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs
> variables   : 1
> names       : Seg_ID
> min values  :      1
> max values  :     31
> Warning message:
> In proj4string(x) : CRS object has comment, which is lost in output
>> # initialization of GRASS 7.8 from R
>> initGRASS(gisBase ="C:/Program Files/GRASS GIS 7.8", home="temp/GRASS",gisDbase="temp/GRASS", use_g.dirseps.exe=F,remove_GISRC=T, override=T)
> gisdbase    temp/GRASS
> location    file19685026c56
> mapset      file196829fa7141
> rows        1
> columns     1
> north       1
> south       0
> west        0
> east        1
> nsres       1
> ewres       1
> projection  NA
>
> I suspect that the problem comes from 'projection NA' when initializing GRASS (cf. just above)


What you need to do here is setup the CRS of your new location. 
Typically, you would run initGRASS and point to a *previously created*? 
LOCATION, with CRS already defined. In this case, since you are creating 
a new location, you must define it's coordinate system. (GRASS is very 
"picky" about that).

Here's a GIS Stackexchange post that explains:

https://gis.stackexchange.com/questions/183032/create-a-new-grass-database-in-r-with-crs-projection


You can derive the full proj4 string from your sp object with:


p4str = sp::proj4string(seg_poly)


Then use that to set the project parameters for the new LOCATION, with

execGRASS("g.proj", flags = "c", proj4 = p4str) Now you should be able 
to continue with...


>> execGRASS("v.generalize",flag=c("overwrite"),parameters=list(input="vec1",
> +                                                              output="GRASS_smooth_seg_poly",
> +                                                              error="GRASS_smooth_seg_poly_error",
> +                                                              method="distance_weighting",
> +                                                              threshold=1))
>
>
>
> As a novice in the field, I would be very grateful for your help.
> I remain at your entire disposal for any further information you may need to help me in finding a solution to this problem.
>
> Yours sincerely,
> Lo?c
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918
https://orcid.org/0000-0002-1128-1325


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jun  9 13:20:43 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 9 Jun 2020 11:20:43 +0000
Subject: [R] almost logistic data evaluation
Message-ID: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>

Dear all

I have several files with data like those.

> dput(temp)
temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 
120L, 135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 
285L, 300L, 315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 
103.28, 107.44, 110.06, 114.26, 117.6, 121.04, 123.8533333, 126.66, 
129.98, 134.1866667, 139.04, 144.6, 152.08, 161.3, 169.8733333, 
176.6133333, 181.92, 186.0266667, 188.7533333, 190.7066667, 192.0533333, 
192.9933333, 193.3533333)), class = "data.frame", row.names = c(NA, 
-25L))

plot(temp)

They resemble logistics curve but they do not start as flat curve but
growing curve. Can you please give me some hints how to deal with such data?
I know that it is not strictly speaking R question but maybe somebody could
give me directions how to model such data and find model parameters.

I considered stepwise regression but it is not completely satisfactory.

Thanks beforehand
Petr Pikal

From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jun  9 14:29:27 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 9 Jun 2020 12:29:27 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>
Message-ID: <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>

Hallo Patrick

 

Thanks. Actually ?y? is growing temperature, which, at some point, rise more rapidly due to exothermic reaction. This reaction starts and ends and proceed with some speed (hopefully different in each material). I hope to get starting point and speed of temperature rise by evaluating shape of curves.

 

I do not think left censoring could help. As seen from data plot at first ?y? is linearly growing but logistics curve needs to start from flat (left asymptote) and end as flat (right asymptote, AFAIK). With linear growth on left site simple logistics fail to model data correctly.

 

One option could be to estimate linear part and deduct it from the data and fit simple logistics model on deducted data. If this is the only way, I will do it but I, as always, first try to ask helpful and ingenious people on this list.

 

Cheers

Petr

 

From: Patrick (Malone Quantitative) <malone at malonequantitative.com> 
Sent: Tuesday, June 9, 2020 2:05 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] almost logistic data evaluation

 

Off-list because off-topic.

 

I didn't plot your data, but took your word that "They resemble logistics curve but they do not start as flat curve but
growing curve."

 

You also didn't say what your research question is. But if you're trying to model the growth, could it be *part* of a logistic curve, with a censoring point on the left? Maybe that helps with some avenues.

 

On Tue, Jun 9, 2020 at 7:21 AM PIKAL Petr <petr.pikal at precheza.cz <mailto:petr.pikal at precheza.cz> > wrote:

Dear all

I have several files with data like those.

> dput(temp)
temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 
120L, 135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 
285L, 300L, 315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 
103.28, 107.44, 110.06, 114.26, 117.6, 121.04, 123.8533333, 126.66, 
129.98, 134.1866667, 139.04, 144.6, 152.08, 161.3, 169.8733333, 
176.6133333, 181.92, 186.0266667, 188.7533333, 190.7066667, 192.0533333, 
192.9933333, 193.3533333)), class = "data.frame", row.names = c(NA, 
-25L))

plot(temp)

They resemble logistics curve but they do not start as flat curve but
growing curve. Can you please give me some hints how to deal with such data?
I know that it is not strictly speaking R question but maybe somebody could
give me directions how to model such data and find model parameters.

I considered stepwise regression but it is not completely satisfactory.

Thanks beforehand
Petr Pikal
______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 

Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From SUSANA@ALBERICHMESA @end|ng |rom o@@k|detz@@eu@  Tue Jun  9 13:33:24 2020
From: SUSANA@ALBERICHMESA @end|ng |rom o@@k|detz@@eu@ (SUSANA ALBERICH MESA)
Date: Tue, 9 Jun 2020 11:33:24 +0000
Subject: [R] Error in ordinal mixed effects
Message-ID: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>

Hi,
I'm trying to run an ordinal mixed effects model with Mixor command. I have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is the following:

cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9, datos$cannabis12, datos$cannabis18)
time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
id<-c(rep(datos$id, 5))
group<-c(rep(datos$group, 5))

res<-data.frame(cbind(id, group, time, cannabis))
names(res)<-c("id", "group", "time", "cannabis")
res<-res[order(res$id),]

cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id, na.exclude, which.random.slope=na, link="logit")
summary(cannabismod)


However, I have obtained this error:

Error in xj[i] : invalid subscript type 'closure'

Please, could anyone help me to solve it?

Many thanks,
Susana

[https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]



	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jun  9 15:57:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 09 Jun 2020 06:57:26 -0700
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <A89F6684-354B-4D81-83B1-5591C91A8813@dcn.davis.ca.us>

Can't tell... example is not reproducible because it is missing "datos'.

On June 9, 2020 4:33:24 AM PDT, SUSANA ALBERICH MESA <SUSANA.ALBERICHMESA at osakidetza.eus> wrote:
>Hi,
>I'm trying to run an ordinal mixed effects model with Mixor command. I
>have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code
>is the following:
>
>cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9,
>datos$cannabis12, datos$cannabis18)
>time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
>id<-c(rep(datos$id, 5))
>group<-c(rep(datos$group, 5))
>
>res<-data.frame(cbind(id, group, time, cannabis))
>names(res)<-c("id", "group", "time", "cannabis")
>res<-res[order(res$id),]
>
>cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id,
>na.exclude, which.random.slope=na, link="logit")
>summary(cannabismod)
>
>
>However, I have obtained this error:
>
>Error in xj[i] : invalid subscript type 'closure'
>
>Please, could anyone help me to solve it?
>
>Many thanks,
>Susana
>
>[https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun  9 16:51:05 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 9 Jun 2020 07:51:05 -0700
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <CAGxFJbS5sM593BkT_sDNtXLY=5dkxz7VOhxRwesqWdnkjja_OA@mail.gmail.com>

Not sure, and we don't have your data, datos, but this is almost always a
bad thing to do:

res<-data.frame(cbind(id, group, time, cannabis))

Change it to:

res<-data.frame(id, group, time, cannabis)
## and you then won't need to name them either

and see if that fixes things.
Also, res$id is probably a factor: is order(res$id) really meaningful as a
subscript?

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 9, 2020 at 6:01 AM SUSANA ALBERICH MESA
<SUSANA.ALBERICHMESA at osakidetza.eus> wrote:

> Hi,
> I'm trying to run an ordinal mixed effects model with Mixor command. I
> have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is
> the following:
>
> cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9,
> datos$cannabis12, datos$cannabis18)
> time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
> id<-c(rep(datos$id, 5))
> group<-c(rep(datos$group, 5))
>
> res<-data.frame(cbind(id, group, time, cannabis))
> names(res)<-c("id", "group", "time", "cannabis")
> res<-res[order(res$id),]
>
> cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id,
> na.exclude, which.random.slope=na, link="logit")
> summary(cannabismod)
>
>
> However, I have obtained this error:
>
> Error in xj[i] : invalid subscript type 'closure'
>
> Please, could anyone help me to solve it?
>
> Many thanks,
> Susana
>
> [https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Jun  9 17:00:36 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 9 Jun 2020 16:00:36 +0100
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <30e89b76-d72c-bef6-25c1-620e482e5e49@dewey.myzen.co.uk>

Dear Susana

Without your dat  it is hard to say (and it would have helped to know 
where mixor() comes from) but this almost always means that ne of your 
parameters to the call is not what you thought it was so trying str(res) 
might be enlightening. Also I do not see anywhere in your example where 
you define na unless it is really NA and you did not copy it correctly.

Michael

On 09/06/2020 12:33, SUSANA ALBERICH MESA wrote:
> Hi,
> I'm trying to run an ordinal mixed effects model with Mixor command. I have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is the following:
> 
> cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9, datos$cannabis12, datos$cannabis18)
> time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
> id<-c(rep(datos$id, 5))
> group<-c(rep(datos$group, 5))
> 
> res<-data.frame(cbind(id, group, time, cannabis))
> names(res)<-c("id", "group", "time", "cannabis")
> res<-res[order(res$id),]
> 
> cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id, na.exclude, which.random.slope=na, link="logit")
> summary(cannabismod)
> 
> 
> However, I have obtained this error:
> 
> Error in xj[i] : invalid subscript type 'closure'
> 
> Please, could anyone help me to solve it?
> 
> Many thanks,
> Susana
> 
> [https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From S@E|||@on @end|ng |rom LGCGroup@com  Tue Jun  9 19:10:59 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Tue, 9 Jun 2020 17:10:59 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>,
 <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
Message-ID: <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>

> Actually ?y? is growing temperature, which, at some point, rise more rapidly due to exothermic reaction. 
> This reaction starts and ends and proceed with some speed (hopefully different in each material). 

Are you applying external heating or is it solely due to reaction kinetics?


Steve E

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From j@vedbtk111 @end|ng |rom gm@||@com  Tue Jun  9 23:08:53 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Tue, 9 Jun 2020 23:08:53 +0200
Subject: [R] Error in code (no applicable method for 'train' applied to an
 object of class "formula" )
Message-ID: <CAJhui+sn5vgMC+vqNY+oB44D4h9Wf9bFwLcWbKjrtRDRoq4feA@mail.gmail.com>

Greetings, till yesterday the following code was executed normally but
today, it give me the following error:

 Error in UseMethod("train") :
  no applicable method for 'train' applied to an object of class "formula"


I have tried other methods also such as rf, pls, but all gives the same
error message. Could you plz guide why it happens?

data=readARFF("albrecht.arff")

index <- createDataPartition(data$Effort, p = .70,list = FALSE)
tr <- data[index, ]
ts <- data[-index, ]

CV <- trainControl(method = "repeatedcv", number=10, repeats=10)

m1 <- train(Effort ~ ., data = tr,
                 method = "mlp",
                 metric = "RMSE",
                 preProc = c("center", "scale"),
                 trControl = CV)

m1

My data structure is the following

structure(list(Input = c(25, 193, 70, 40), Output = c(150, 98,
27, 60), Inquiry = c(75, 70, 0, 20), File = c(60, 36, 12, 12),
    FPAdj = c(1, 1, 0.8, 1.15), RawFPcounts = c(1750, 1902, 535,
    660), AdjFP = c(1750, 1902, 428, 759), Effort = c(102.4,
    105.2, 11.1, 21.1)), row.names = c(NA, 4L), class = "data.frame")

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Tue Jun  9 23:28:03 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Tue, 9 Jun 2020 21:28:03 +0000
Subject: [R] [Rd] R 4.0.2 scheduled for June 22
Message-ID: <270EFEE1-89B1-48F7-BBD6-E66B46D1C32C@cbs.dk>

Unfortunatly, a memory allocation bug prevented the R Commander package from working on Windows. This is fixed in R-patched, but we cannot have this not working in the official release when IT departments start installing for the Fall semester, so we need to issue a new release.

Full schedule is available on developer.r-project.org.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jun  9 23:37:50 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 9 Jun 2020 21:37:50 +0000
Subject: [R] [Rd] R 4.0.2 scheduled for June 22
In-Reply-To: <4168_1591738244_059LUFtX007139_270EFEE1-89B1-48F7-BBD6-E66B46D1C32C@cbs.dk>
References: <4168_1591738244_059LUFtX007139_270EFEE1-89B1-48F7-BBD6-E66B46D1C32C@cbs.dk>
Message-ID: <F16DCD72-2D0C-47D4-ABDB-196BB02B63E1@mcmaster.ca>

Dear Peter,

Thank you very much for this.

To clarify slightly, the bug affects not just the Rcmdr package but use of the tcltk package on Windows more generally.

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Jun 9, 2020, at 5:28 PM, Peter Dalgaard via R-help <r-help at r-project.org> wrote:
> 
> Unfortunatly, a memory allocation bug prevented the R Commander package from working on Windows. This is fixed in R-patched, but we cannot have this not working in the official release when IT departments start installing for the Fall semester, so we need to issue a new release.
> 
> Full schedule is available on developer.r-project.org.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> _______________________________________________
> R-announce at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-announce
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From drj|m|emon @end|ng |rom gm@||@com  Wed Jun 10 03:09:03 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 10 Jun 2020 11:09:03 +1000
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <CA+8X3fXXrDCVrBbwyssUF7upe+Gj1FgrYgfSAXHEsNSGEuuPVA@mail.gmail.com>

Hi Susana,
I ran your code on a fake data frame:

datos<-data.frame(id=paste0("s",1:65),
 group=c(rep("control",30),rep("treat",35)),
 cannabis0=sample(1:5,65,TRUE),
 cannabis6=sample(1:5,65,TRUE),
 cannabis9=sample(1:5,65,TRUE),
 cannabis12=sample(1:5,65,TRUE),
 cannabis18=sample(1:5,65,TRUE))
time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
id<-c(rep(datos$id, 5))
group<-c(rep(datos$group, 5))
res<-data.frame(cbind(id, group, time, cannabis))
names(res)<-c("id", "group", "time", "cannabis")
res<-res[order(res$id),]
library(mixor)
cannabismod<-mixor(cannabis~ time + as.factor(group), data=res,
 id=id,which.random.slope=NA,link="logit")

The error seems to be that you have inserted a function name
"na.exclude" in the arguments. When I removed it as above, it ran okay
with a warning.

Jim

On Tue, Jun 9, 2020 at 11:01 PM SUSANA ALBERICH MESA
<SUSANA.ALBERICHMESA at osakidetza.eus> wrote:
>
> Hi,
> I'm trying to run an ordinal mixed effects model with Mixor command. I have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is the following:
>
> cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9, datos$cannabis12, datos$cannabis18)
> time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
> id<-c(rep(datos$id, 5))
> group<-c(rep(datos$group, 5))
>
> res<-data.frame(cbind(id, group, time, cannabis))
> names(res)<-c("id", "group", "time", "cannabis")
> res<-res[order(res$id),]
>
> cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id, na.exclude, which.random.slope=na, link="logit")
> summary(cannabismod)
>
>
> However, I have obtained this error:
>
> Error in xj[i] : invalid subscript type 'closure'
>
> Please, could anyone help me to solve it?
>
> Many thanks,
> Susana
>
> [https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jun 10 08:59:42 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 10 Jun 2020 06:59:42 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>,
 <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
 <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <d88d94d3831b44aa993130658169a007@SRVEXCHCM1302.precheza.cz>

Hi

External heating. Normally I would use TA instrumentation but for technical
reasons it is impossible. And other complicating factor is that temperature
rise is from beginning almost parabolic (it's derivation is straight line).

Therefore I started with double exponential fit, which is sometimes
satisfactory but sometimes gives nonsense result. After help from R
community I got in almost all cases reasonable fit. 

However I want to concentrate on just the reaction part and to find some
more simple way how to get slope for temperature rise and maybe other
parameters related to changes in experiments.

I was advised to look at "growth curve analysis" which I will try to, but I
wonder if due to twisted data is appropriate.

Thanks.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stephen Ellison
> Sent: Tuesday, June 9, 2020 7:11 PM
> To: r-help at r-project.org
> Subject: Re: [R] almost logistic data evaluation
> 
> > Actually "y" is growing temperature, which, at some point, rise more
rapidly
> due to exothermic reaction.
> > This reaction starts and ends and proceed with some speed (hopefully
> different in each material).
> 
> Are you applying external heating or is it solely due to reaction
kinetics?
> 
> 
> Steve E
> 
> *****************************************************************
> **
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jun 10 10:20:01 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 10 Jun 2020 10:20:01 +0200
Subject: [R] How to convert European short dates to ISO format?
Message-ID: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>

Hello,
I have been trying to convert European short dates formatted as
dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
as American ones (mm/dd/yy), thus I get:

```
oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
"27/01/20", "28/01/20", "29/01/20", "30/01/20",
             "31/01/20", "01/02/20", "02/02/20", "03/02/20",
"04/02/20", "05/02/20", "06/02/20", "07/02/20")
isoDates = as.Date(oriDates, format = "%m/%d/%y")
> isoDates
 [1] NA           NA           NA           NA           NA
NA           NA
 [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
"2020-04-02" "2020-05-02"
[15] "2020-06-02" "2020-07-02"
```

How can I convert properly?
-- 
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jun 10 10:28:33 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 10 Jun 2020 11:28:33 +0300
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <20200610112833.3cf4a5c2@Tarkus>

On Wed, 10 Jun 2020 10:20:01 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> the function as.Dates interprets them as American ones (mm/dd/yy)

> isoDates = as.Date(oriDates, format = "%m/%d/%y")

> How can I convert properly?

Pass the correct format? (Swap m and d in the format string.)

-- 
Best regards,
Ivan


From djnord|und @end|ng |rom gm@||@com  Wed Jun 10 10:29:11 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Wed, 10 Jun 2020 01:29:11 -0700
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <a1a9bb99-aff9-db5f-e8d4-aad02d724efd@gmail.com>

On 6/10/2020 1:20 AM, Luigi Marongiu wrote:
> isoDates = as.Date(oriDates, format = "%m/%d/%y")

You need to use the format for European short dates.

isoDates = as.Date(oriDates, format = "%d/%m/%y")


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From m@||||@t@ @end|ng |rom pp@|net@||  Wed Jun 10 10:30:54 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (Kimmo Elo)
Date: Wed, 10 Jun 2020 11:30:54 +0300
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <b328e7565108b4bf705e051ee258239a9b01e3f9.camel@pp.inet.fi>

Hi!

Should it be:

as.Date(oriDates, format="%d/%m/%y") # See the order of %d and %m!!

This command seems to work for me, here the output:

 [1] "2020-01-23" "2020-01-24" "2020-01-25" "2020-01-26" "2020-01-27"
"2020-01-28" "2020-01-29" "2020-01-30"
 [9] "2020-01-31" "2020-02-01" "2020-02-02" "2020-02-03" "2020-02-04"
"2020-02-05" "2020-02-06" "2020-02-07"

HTH,
Kimmo

ke, 2020-06-10 kello 10:20 +0200, Luigi Marongiu kirjoitti:
> Hello,
> I have been trying to convert European short dates formatted as
> dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
> as American ones (mm/dd/yy), thus I get:
> 
> ```
> oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
> "27/01/20", "28/01/20", "29/01/20", "30/01/20",
>              "31/01/20", "01/02/20", "02/02/20", "03/02/20",
> "04/02/20", "05/02/20", "06/02/20", "07/02/20")
> isoDates = as.Date(oriDates, format = "%m/%d/%y")
> > isoDates
> 
>  [1] NA           NA           NA           NA           NA
> NA           NA
>  [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
> "2020-04-02" "2020-05-02"
> [15] "2020-06-02" "2020-07-02"
> ```
> 
> How can I convert properly?


From bhh @end|ng |rom x@4@||@n|  Wed Jun 10 10:30:54 2020
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Wed, 10 Jun 2020 10:30:54 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <66A418C2-CB3C-41CC-A752-5733D2F885C3@xs4all.nl>

Luigi,

Try format = "%d/%m/%y"

Berend Hasselman

> On 10 Jun 2020, at 10:20, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
>  ISO 8601


From tuech|er @end|ng |rom gmx@@t  Wed Jun 10 10:34:37 2020
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Wed, 10 Jun 2020 10:34:37 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <1b9b9e00-7d45-3804-ae3f-4c44258eab7e@gmx.at>

maybe
isoDates <- as.Date(oriDates, format = "%d/%m/%y")

Heinz

Luigi Marongiu wrote/hat geschrieben on/am 10.06.2020 10:20:
> Hello,
> I have been trying to convert European short dates formatted as
> dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
> as American ones (mm/dd/yy), thus I get:
>
> ```
> oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
> "27/01/20", "28/01/20", "29/01/20", "30/01/20",
>              "31/01/20", "01/02/20", "02/02/20", "03/02/20",
> "04/02/20", "05/02/20", "06/02/20", "07/02/20")
> isoDates = as.Date(oriDates, format = "%m/%d/%y")
>> isoDates
>  [1] NA           NA           NA           NA           NA
> NA           NA
>  [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
> "2020-04-02" "2020-05-02"
> [15] "2020-06-02" "2020-07-02"
> ```
>
> How can I convert properly?
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jun 10 10:36:47 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 10 Jun 2020 10:36:47 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <a1a9bb99-aff9-db5f-e8d4-aad02d724efd@gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <a1a9bb99-aff9-db5f-e8d4-aad02d724efd@gmail.com>
Message-ID: <CAMk+s2T8f42vL_XBxAg34XCohcB90=auiuQxioFEA=Dmtd+aaA@mail.gmail.com>

Thank you!

On Wed, Jun 10, 2020 at 10:29 AM Daniel Nordlund <djnordlund at gmail.com> wrote:
>
> On 6/10/2020 1:20 AM, Luigi Marongiu wrote:
> > isoDates = as.Date(oriDates, format = "%m/%d/%y")
>
> You need to use the format for European short dates.
>
> isoDates = as.Date(oriDates, format = "%d/%m/%y")
>
>
> Hope this is helpful,
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>


-- 
Best regards,
Luigi


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jun 10 12:09:19 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 10 Jun 2020 10:09:19 +0000
Subject: [R] segmented do not correctly fit data (variable names problem)
Message-ID: <996341cc2b9d4a1e8be200d87238c2e1@SRVEXCHCM1302.precheza.cz>

Dear all

To make my problem more on topic I would like to ask about weird results
from segmented fit, despite of Bert's warning.

Here is my data

temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 120L,
135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 285L, 300L,
315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 103.28, 107.44, 110.06,
114.26, 117.6, 121.04, 123.8533333, 126.66, 129.98, 134.1866667, 139.04,
144.6, 152.08, 161.3, 169.8733333, 176.6133333, 181.92, 186.0266667,
188.7533333, 190.7066667, 192.0533333, 192.9933333, 193.3533333)), class =
"data.frame", row.names = c(NA,
+ -25L))

Here is the fit.

library(segmented)
plot(temp$V1, temp$V2)
fit <- lm(V2~V1, temp)
fit.s <- segmented(fit, seg.Z = ~ V1, npsi=2)
plot(fit.s, add=TRUE, col=2)

which is wrong.

If I take example from web, the result is OK.

set.seed(12)
xx <- 1:100
zz <- runif(100)
yy <- 2 + 1.5*pmax(xx - 35, 0) - 1.5*pmax(xx - 70, 0) + 15*pmax(zz - .5, 0)
+  rnorm(100,0,2)
dati <- data.frame(x = xx, y = yy, z = zz)
out.lm <- lm(y ~ x, data = dati)
o <- segmented(out.lm, seg.Z = ~x, psi = list(x = c(30,60)),  control =
seg.control(display = FALSE)
)
plot(dati$x, dati$y)
plot(o, add=TRUE, col=2)

What am I doing wrong? Is there a bug in segmented? BTW, if I change column
names in temp to x and y, segmented found correct fit.

names(temp) <- c("x", "y")
plot(temp$x, temp$y)
fit <- lm(y~x, temp)
fit.s <- segmented(fit, seg.Z = ~x, npsi=2)
plot(fit.s, add=TRUE, col=2)

> sessionInfo()
R Under development (unstable) (2020-03-08 r77917)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=Czech_Czechia.1250  LC_CTYPE=Czech_Czechia.1250   
[3] LC_MONETARY=Czech_Czechia.1250 LC_NUMERIC=C                  
[5] LC_TIME=Czech_Czechia.1250    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] segmented_1.1-0

loaded via a namespace (and not attached):
[1] compiler_4.0.0 tools_4.0.0    splines_4.0.0 


Cheers
Petr



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jun 10 15:29:05 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 10 Jun 2020 15:29:05 +0200
Subject: [R] Doubling time definition package incidence
Message-ID: <CAMk+s2SaG5HDhkd5oyoHSXE7_zVj=vUKZAom-yCsd2tLPnJwYw@mail.gmail.com>

The package incidence provides the function fit_optim_split that
returns a predicted doubling time in days. Would this be serial
interval described in the epidemiology manuals?
Thank you


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 10 16:29:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 10 Jun 2020 07:29:13 -0700
Subject: [R] 
 segmented do not correctly fit data (variable names problem)
In-Reply-To: <996341cc2b9d4a1e8be200d87238c2e1@SRVEXCHCM1302.precheza.cz>
References: <996341cc2b9d4a1e8be200d87238c2e1@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbTuwY7bafOE1orEx-X-dFo4UMJk0H72j_pELFJdurMe=Q@mail.gmail.com>

Note: My warning was for "stepwise" regression, which is what *you wrote*,
not "segmented".

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 10, 2020 at 3:09 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Dear all
>
> To make my problem more on topic I would like to ask about weird results
> from segmented fit, despite of Bert's warning.
>
> Here is my data
>
> temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 120L,
> 135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 285L, 300L,
> 315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 103.28, 107.44, 110.06,
> 114.26, 117.6, 121.04, 123.8533333, 126.66, 129.98, 134.1866667, 139.04,
> 144.6, 152.08, 161.3, 169.8733333, 176.6133333, 181.92, 186.0266667,
> 188.7533333, 190.7066667, 192.0533333, 192.9933333, 193.3533333)), class =
> "data.frame", row.names = c(NA,
> + -25L))
>
> Here is the fit.
>
> library(segmented)
> plot(temp$V1, temp$V2)
> fit <- lm(V2~V1, temp)
> fit.s <- segmented(fit, seg.Z = ~ V1, npsi=2)
> plot(fit.s, add=TRUE, col=2)
>
> which is wrong.
>
> If I take example from web, the result is OK.
>
> set.seed(12)
> xx <- 1:100
> zz <- runif(100)
> yy <- 2 + 1.5*pmax(xx - 35, 0) - 1.5*pmax(xx - 70, 0) + 15*pmax(zz - .5, 0)
> +  rnorm(100,0,2)
> dati <- data.frame(x = xx, y = yy, z = zz)
> out.lm <- lm(y ~ x, data = dati)
> o <- segmented(out.lm, seg.Z = ~x, psi = list(x = c(30,60)),  control =
> seg.control(display = FALSE)
> )
> plot(dati$x, dati$y)
> plot(o, add=TRUE, col=2)
>
> What am I doing wrong? Is there a bug in segmented? BTW, if I change column
> names in temp to x and y, segmented found correct fit.
>
> names(temp) <- c("x", "y")
> plot(temp$x, temp$y)
> fit <- lm(y~x, temp)
> fit.s <- segmented(fit, seg.Z = ~x, npsi=2)
> plot(fit.s, add=TRUE, col=2)
>
> > sessionInfo()
> R Under development (unstable) (2020-03-08 r77917)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Czech_Czechia.1250  LC_CTYPE=Czech_Czechia.1250
> [3] LC_MONETARY=Czech_Czechia.1250 LC_NUMERIC=C
> [5] LC_TIME=Czech_Czechia.1250
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] segmented_1.1-0
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.0 tools_4.0.0    splines_4.0.0
>
>
> Cheers
> Petr
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 10 16:37:23 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 10 Jun 2020 07:37:23 -0700
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>

Fix your format specification?

?strptime

On June 10, 2020 1:20:01 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Hello,
>I have been trying to convert European short dates formatted as
>dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
>as American ones (mm/dd/yy), thus I get:
>
>```
>oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
>"27/01/20", "28/01/20", "29/01/20", "30/01/20",
>             "31/01/20", "01/02/20", "02/02/20", "03/02/20",
>"04/02/20", "05/02/20", "06/02/20", "07/02/20")
>isoDates = as.Date(oriDates, format = "%m/%d/%y")
>> isoDates
> [1] NA           NA           NA           NA           NA
>NA           NA
> [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
>"2020-04-02" "2020-05-02"
>[15] "2020-06-02" "2020-07-02"
>```
>
>How can I convert properly?

-- 
Sent from my phone. Please excuse my brevity.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jun 10 16:44:49 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 10 Jun 2020 07:44:49 -0700 (PDT)
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>

On Wed, 10 Jun 2020, Jeff Newmiller wrote:

> Fix your format specification?
> ?strptime

>> I have been trying to convert European short dates formatted as dd/mm/yy
>> into the ISO 8601 but the function as.Dates interprets them as American
>> ones (mm/dd/yy), thus I get:

Look at Hadley Wickham's 'tidyverse' collection as described in R for Data
Science. There are date, datetime, and time functions that will do just what
you want.

Rich


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Jun 10 17:46:29 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 10 Jun 2020 15:46:29 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <d88d94d3831b44aa993130658169a007@SRVEXCHCM1302.precheza.cz>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>,
 <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
 <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>,
 <d88d94d3831b44aa993130658169a007@SRVEXCHCM1302.precheza.cz>
Message-ID: <9f904a1a4d9d4708b0660a1ad58f7ecd@GBDCVPEXC08.corp.lgc-group.com>


I'm not sure this is really a statistical problem, in the sense of looking for a convenient but arbitrary statistical function; to do it well is more of a physicochemical modelling problem.
I can't give you an answer but maybe a direction I'd consider if I wanted to take it seriously ...

You have a steady heat input (which is initially a straight line but becomes asymptotic as cooling rate approaches heating rate),  plus an exothermic reaction whose rate will almost certainly depend on temperature (I guess close to the usual 'double every 10K' rule of thumb for chemistry, but of course there are plenty of exceptions and diffusion control doesn't follow Arrhenius rate dependence. ). On a bad day it may self-catalyse as well, but it's already self-accelerating in the sense that the rate will go up with the temperature and the temperature will go up faster at higher rates.

To model that you would ideally set up a kinetic model for the chemistry, with coefficients for (probably) an activation energy rather than a simple rate constant, enthalpy of reaction, heat input and at least one arbitrary heat capacity so that you have something that relates heat input and enthalpy to temperature. There'll be another term (probably based on newton's law of cooling) to model external heating and cooling, again with that system heat capacity to convert energy to temperature.
 
That'll be a moderately awkward differential equation.  For the common exponential relation of temperature and rate (assuming an Arrhenius relationship for the rate constant), with temperature not constant, it will almost certainly need numerical solution with something like the deSolve package. That can give you an integrated change at different times. After that 'all' you need to do is wrap that in a function to return a residual sum of squares and then plug that into something like optim() or perhaps nls() to fit the curve. 

You may want to set I say 'all you need ...'; obviously, that's a fair bit of work...

________________________________________
From: PIKAL Petr [petr.pikal at precheza.cz]
Sent: 10 June 2020 07:59
To: Stephen Ellison; r-help at r-project.org
Subject: RE: [R] almost logistic data evaluation

Hi

External heating. Normally I would use TA instrumentation but for technical
reasons it is impossible. And other complicating factor is that temperature
rise is from beginning almost parabolic (it's derivation is straight line).

Therefore I started with double exponential fit, which is sometimes
satisfactory but sometimes gives nonsense result. After help from R
community I got in almost all cases reasonable fit.

However I want to concentrate on just the reaction part and to find some
more simple way how to get slope for temperature rise and maybe other
parameters related to changes in experiments.

I was advised to look at "growth curve analysis" which I will try to, but I
wonder if due to twisted data is appropriate.

Thanks.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stephen Ellison
> Sent: Tuesday, June 9, 2020 7:11 PM
> To: r-help at r-project.org
> Subject: Re: [R] almost logistic data evaluation
>
> > Actually "y" is growing temperature, which, at some point, rise more
rapidly
> due to exothermic reaction.
> > This reaction starts and ends and proceed with some speed (hopefully
> different in each material).
>
> Are you applying external heating or is it solely due to reaction
kinetics?
>
>
> Steve E
>
> *****************************************************************
> **
> This email and any attachments are confidential. Any u...{{dropped:19}}


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 10 20:13:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 10 Jun 2020 13:13:03 -0500
Subject: [R] Error in plot.window(...) : need finite 'ylim' values
Message-ID: <CAF9-5jNMgUnPZ=XVTW8UHTL044O-h=KFmK+tOoiyMKPAdYdbvQ@mail.gmail.com>

Hello,

I do have a file like this:
head M3.assoc.logistic.C
CHR SNP BP P
1 1:785989:T:C 785989 0.4544
1 1:785989:T:C 785989 0.689
1 1:1130727:A:C 1130727 0.05068
1 1:1130727:A:C 1130727 0.07381
1 1:1156131:T:C 1156131 0.6008
1 1:1156131:T:C 1156131 0.8685
...

And I don't have any "NA" or "inf" values in it

and I am plotting it in R via:

library(qqman)
results_log <- read.table("M3.assoc.logistic.C", head=TRUE)
jpeg("Logistic_manhattan_retinopathy_M3.jpeg")
manhattan(results_log,chr="CHR",bp="BP",p="P",snp="SNP", main =
"Manhattan plot: logistic")
dev.off()

but I am getting:

Error in plot.window(...) : need finite 'ylim' values
Calls: manhattan ... do.call -> plot -> plot.default -> localWindow ->
plot.window
Execution halted

Please advise,

Thanks
Ana


From k@pr@@@d@h @end|ng |rom gm@||@com  Wed Jun 10 06:36:06 2020
From: k@pr@@@d@h @end|ng |rom gm@||@com (Keshava PRASADa Halemane)
Date: Wed, 10 Jun 2020 10:06:06 +0530
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
Message-ID: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>

Friends:
i am a retired Professor -
not having any access to the resources (human/financial/business/whatever)
that may be required -
therefore i am seeking implementation of my algorithm 'spdspds' -
a novel algorithm for solving Linear Programming Problems with O(L^1.5)
computational complexity -
in order to show/convince the esteemed world optimization community
that it is indeed a great grand breakthrough in terms of achievement of the
linear programming performance challenge of the millennium -
with far reaching deep impact on optimization algorithm development in
general -
holy grail fantasy realized!

I need some individual or team who is interested & willing to work on this.
Earlier experience in implementation of optimization/LP algorithms will
greatly help.

You may access / download / read my paper -
"Unbelievable *O*(*L*^1.5) worst case computational complexity achieved by
spdspds algorithm for linear programming problem"
which is available at - arxiv . org / abs / 1405 . 6902

Thanks a lot.
 - Dr(Prof) Keshava Prasad Halemane

	[[alternative HTML version deleted]]


From @y@g||@d @end|ng |rom gm@||@com  Wed Jun 10 09:57:46 2020
From: @y@g||@d @end|ng |rom gm@||@com (Aya Gilad)
Date: Wed, 10 Jun 2020 10:57:46 +0300
Subject: [R] Help about extracting data
Message-ID: <CABirntQV6SHK6sFNCVSqCTfUYCM_6S5Ce0=B+No-0oWqu=WwLA@mail.gmail.com>

Hello,
I'm analyzing a 6-question questionnaire. I need to exclude participants
who answered more than 4 questions with a grade of 3 or higher.
How do I write such a code?
Thank you!

	[[alternative HTML version deleted]]


From mozhg@n@o|eym@n| @end|ng |rom gm@||@com  Wed Jun 10 11:08:46 2020
From: mozhg@n@o|eym@n| @end|ng |rom gm@||@com (Mozhgan Soleimani)
Date: Wed, 10 Jun 2020 13:38:46 +0430
Subject: [R] request
Message-ID: <CAKOwFD=hMNi_ruOmHobaBLjjAJNY8p1=YGppX6zuP6j+q2T1Eg@mail.gmail.com>

Hello
thank you for reading email
please help me,
I have used mgcv package for GAM model.

To get contributions of each variable, Which code should I write in the R
software?
please see attached file

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1.PNG
Type: image/png
Size: 9624 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200610/2d64a69f/attachment.png>

From uret@@@|ej@ndro @end|ng |rom gm@||@com  Wed Jun 10 17:13:24 2020
From: uret@@@|ej@ndro @end|ng |rom gm@||@com (Alejandro Ureta)
Date: Wed, 10 Jun 2020 12:13:24 -0300
Subject: [R] Creating one df from 85 df present in a list
Message-ID: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>

hi, I am trying to fuse (cbind, merge... NOT rbind) several dataframes with
different numbers of rows, all df included in a list, and using the code
extract shown below. The function merge() works well with two df but not
more than two...I have 85 dataframes to join in this way (85 df in the
list)....could you please let me know how to get all 85 df merged ?,,,,,
thanks

fusion_de_tablas = merge(red_tablas_por_punto[["1 - Bv.Artigas y la Rambla
(Terminal CUTCSA)"]],
red_tablas_por_punto[["10 - Avenida Mill?n 2515 (Hospital Vilardeb?)"]],
red_tablas_por_punto[["100 - Fauquet 6358 (Hospital Saint Bois)"]],
by= 'toma_de_muestras', all = T )

-- 
*Alejandro *

	[[alternative HTML version deleted]]


From @@ud|@@d|q @end|ng |rom gm@||@com  Wed Jun 10 17:47:52 2020
From: @@ud|@@d|q @end|ng |rom gm@||@com (Saudi Sadiq)
Date: Wed, 10 Jun 2020 17:47:52 +0200
Subject: [R] Help with a (g)lmer code
Message-ID: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>

Dear Sir/Madam,

Hope everyone is safe and sound. I appreciate your help a lot.

I am evaluating two Arabic subtitles of a humorous English scene and asked
263 participants (part) to evaluate the two subtitles (named Standard
Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them to
rank the two subtitles in terms of how much each subtitle is

2) more humorous (hum),

5) closer to Egyptian culture (cul)



The questionnaire contained two 1-10 linear scale questions regarding the 2
points clarified, with 1 meaning the most humorous and closest to Egyptian
culture, and 1 meaning the least humorous and furthest from Egyptian
culture. Also, the questionnaire had a general multiple-choice question
regarding which subtitle is better in general (better). General information
about the participants were also collected concerning gender (categorical
factor), age (numeric factor) and education (categorical factor).

Two versions of the questionnaire were relied on: one showing the ?SA
subtitle first? and another showing the ?EA subtitle first?. Nearly half
the participants answered the first and nearly half answered the latter.

I am focusing on which social factor/s lead/s the participants to evaluate
one of the two subtitles as generally better and which subtitle is more
humorous and closer to Egyptian culture. Each of these points alone can be
the dependent factor, but the results altogether can be linked.

I thought that mixed effects analyses would clarify the picture and answer
the research questions (which  factor/s lead/s participants to favour a
subtitle over another?) and, so,  tried the lme4 package in R and ran many
models but all the codes I have used are not working.

I ran the following codes, which yielded Error messages, like:

model1<- lmer (better ~ gender + age + education + WF + (1 | part),
data=sub_data)

Error: number of levels of each grouping factor must be < number of
observations (problems: part)



Model2 <- glmer (better ~ gender + age + education + WF + (1 | part), data
= sub_data, family='binomial')

Error in mkRespMod(fr, family = family) :

  response must be numeric or factor



Model3 <- glmer (better ~ age + gender + education + WF + (1 | part), data
= sub_data, family='binomial', control=glmerControl(optimizer=c("bobyqa")))

Error in mkRespMod(fr, family = family) :

  response must be numeric or factor



Why does the model crash? Does the problem lie in the random factor part (which
is a code for participants)? Or is it something related to the mixed
effects analysis?

Best
Saudi Sadiq

	[[alternative HTML version deleted]]


From @ong@k@y|@ @end|ng |rom gm@||@com  Wed Jun 10 20:33:53 2020
From: @ong@k@y|@ @end|ng |rom gm@||@com (Kayla Song)
Date: Wed, 10 Jun 2020 14:33:53 -0400
Subject: [R] Error messages (Long vectors not supported)
Message-ID: <7610FEE1-D09B-4ECF-9164-1E9D7AE74E35@gmail.com>

Hello there,

I hope this email finds you well.

I?m just having a difficulty running RServe, which I?m trying to get communicate with Tableau. I have this error message every time I try to do this:

Error: long vectors not supported yet: qap_encode.c:36
Fatal error: unable to initialize the JIT

I searched some online forums but could not find the answer that resolved this problem. For example, I tried:

install.packages("Rserve", "Rserve_1.8-6.tgz", "http://www.rforge.net/?)

But the error message still appears. 
Could you please advise?

thanks so much,
Kayla
	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun 10 21:39:05 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 10 Jun 2020 12:39:05 -0700
Subject: [R] Error messages (Long vectors not supported)
In-Reply-To: <7610FEE1-D09B-4ECF-9164-1E9D7AE74E35@gmail.com>
References: <7610FEE1-D09B-4ECF-9164-1E9D7AE74E35@gmail.com>
Message-ID: <ab38359c-804e-c170-0155-4a204115fa46@comcast.net>

If that is an exact copy of the issued command than it should be 
throwing an error related to the use of "smart quotes".


Furthermore it was not clear if that command was the proximate cause of 
the error or perhaps it was encountered when you tried to load (rather 
than install) the Rserve package?

-- 

David

On 6/10/20 11:33 AM, Kayla Song wrote:
> Hello there,
>
> I hope this email finds you well.
>
> I?m just having a difficulty running RServe, which I?m trying to get communicate with Tableau. I have this error message every time I try to do this:
>
> Error: long vectors not supported yet: qap_encode.c:36
> Fatal error: unable to initialize the JIT
>
> I searched some online forums but could not find the answer that resolved this problem. For example, I tried:
>
> install.packages("Rserve", "Rserve_1.8-6.tgz", "http://www.rforge.net/?)
>
> But the error message still appears.
> Could you please advise?
>
> thanks so much,
> Kayla
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 10 22:14:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 10 Jun 2020 13:14:04 -0700
Subject: [R] Creating one df from 85 df present in a list
In-Reply-To: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
References: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
Message-ID: <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>

?do.call  -- takes a list of arguments to a function
... as in
do.call(merge, yourlist)  ## or similar perhaps


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 10, 2020 at 11:48 AM Alejandro Ureta <ureta.alejandro at gmail.com>
wrote:

> hi, I am trying to fuse (cbind, merge... NOT rbind) several dataframes with
> different numbers of rows, all df included in a list, and using the code
> extract shown below. The function merge() works well with two df but not
> more than two...I have 85 dataframes to join in this way (85 df in the
> list)....could you please let me know how to get all 85 df merged ?,,,,,
> thanks
>
> fusion_de_tablas = merge(red_tablas_por_punto[["1 - Bv.Artigas y la Rambla
> (Terminal CUTCSA)"]],
> red_tablas_por_punto[["10 - Avenida Mill?n 2515 (Hospital Vilardeb?)"]],
> red_tablas_por_punto[["100 - Fauquet 6358 (Hospital Saint Bois)"]],
> by= 'toma_de_muestras', all = T )
>
> --
> *Alejandro *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 10 22:36:11 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 10 Jun 2020 15:36:11 -0500
Subject: [R] How to stack two Stack manhattan plots?
Message-ID: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>

Hello,

I have a data frame like this:

> head(tmp1)
  CHR      BP   Pold    Pnew
1   1  785989 0.9521 0.09278
2   1 1130727 0.4750 0.19010
3   1 1156131 0.5289 0.48520
4   1 1158631 0.2554 0.18140
5   1 1211292 0.2954 0.48590
6   1 1478153 0.5542 0.68790
...

I did:
tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
jpeg("over.jpeg")
ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
facet_wrap(~CHR, nrow=1)
dev.off()

but I got this plot in attach which doesn't make sense. Can you please
advise how to make this plot?

thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-06-10 at 3.34.47 PM.png
Type: image/png
Size: 311087 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200610/59234ecb/attachment.png>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 10 23:49:58 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 10 Jun 2020 14:49:58 -0700
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
Message-ID: <39898A38-9C09-4BD4-86EC-0C13A92DE0A3@dcn.davis.ca.us>

?dput

We cannot tell how the columns are being stored in memory from your head() output.

On June 10, 2020 1:36:11 PM PDT, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hello,
>
>I have a data frame like this:
>
>> head(tmp1)
>  CHR      BP   Pold    Pnew
>1   1  785989 0.9521 0.09278
>2   1 1130727 0.4750 0.19010
>3   1 1156131 0.5289 0.48520
>4   1 1158631 0.2554 0.18140
>5   1 1211292 0.2954 0.48590
>6   1 1478153 0.5542 0.68790
>...
>
>I did:
>tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
>jpeg("over.jpeg")
>ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
>facet_wrap(~CHR, nrow=1)
>dev.off()
>
>but I got this plot in attach which doesn't make sense. Can you please
>advise how to make this plot?
>
>thanks
>Ana

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 00:11:32 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 08:11:32 +1000
Subject: [R] Error in plot.window(...) : need finite 'ylim' values
In-Reply-To: <CAF9-5jNMgUnPZ=XVTW8UHTL044O-h=KFmK+tOoiyMKPAdYdbvQ@mail.gmail.com>
References: <CAF9-5jNMgUnPZ=XVTW8UHTL044O-h=KFmK+tOoiyMKPAdYdbvQ@mail.gmail.com>
Message-ID: <CA+8X3fVSJqO7yfSC3KFC+WtfjrkLnYDj4_tRNBxGAeQg2mboog@mail.gmail.com>

Hi Ana,
I don't have the qqman package, but is your "P" column in
"M3.assoc.logistic.C" numeric or has it been read in as a factor?

Jim

On Thu, Jun 11, 2020 at 4:13 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I do have a file like this:
> head M3.assoc.logistic.C
> CHR SNP BP P
> 1 1:785989:T:C 785989 0.4544
> 1 1:785989:T:C 785989 0.689
> 1 1:1130727:A:C 1130727 0.05068
> 1 1:1130727:A:C 1130727 0.07381
> 1 1:1156131:T:C 1156131 0.6008
> 1 1:1156131:T:C 1156131 0.8685
> ...
>
> And I don't have any "NA" or "inf" values in it
>
> and I am plotting it in R via:
>
> library(qqman)
> results_log <- read.table("M3.assoc.logistic.C", head=TRUE)
> jpeg("Logistic_manhattan_retinopathy_M3.jpeg")
> manhattan(results_log,chr="CHR",bp="BP",p="P",snp="SNP", main =
> "Manhattan plot: logistic")
> dev.off()
>
> but I am getting:
>
> Error in plot.window(...) : need finite 'ylim' values
> Calls: manhattan ... do.call -> plot -> plot.default -> localWindow ->
> plot.window
> Execution halted
>
> Please advise,
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 00:17:14 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 08:17:14 +1000
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
Message-ID: <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>

Hi Ana,
The problem may be that the JPEG device doesn't handle transparency.
Perhaps PNG?

Jim

On Thu, Jun 11, 2020 at 6:48 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a data frame like this:
>
> > head(tmp1)
>   CHR      BP   Pold    Pnew
> 1   1  785989 0.9521 0.09278
> 2   1 1130727 0.4750 0.19010
> 3   1 1156131 0.5289 0.48520
> 4   1 1158631 0.2554 0.18140
> 5   1 1211292 0.2954 0.48590
> 6   1 1478153 0.5542 0.68790
> ...
>
> I did:
> tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> jpeg("over.jpeg")
> ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> facet_wrap(~CHR, nrow=1)
> dev.off()
>
> but I got this plot in attach which doesn't make sense. Can you please
> advise how to make this plot?
>
> thanks
> Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 00:22:04 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 10 Jun 2020 17:22:04 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>
Message-ID: <CAF9-5jNVnYXouU-T2v-BMTjt+YJ=ZXwx4gmUkCrjB+ce4XuTZA@mail.gmail.com>

HI Jim

I run it like this:
Rscript --no-save Manhattan_plot.R

and just in case I added: stringsAsFactors=FALSE

so the script looks like this:
library(qqman)
results_log <- read.table("logistic_results_M3.assoc.logistic.C",
head=TRUE,stringsAsFactors=FALSE)
jpeg("M3.assoc.logistic.jpeg")
manhattan(results_log,chr="CHR",bp="BP",p="P",snp="SNP", main =
"Manhattan plot:logistic")
dev.off()

this code does work with another data set, the jpeg() does work. I
will try now with PNG

On Wed, Jun 10, 2020 at 5:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> The problem may be that the JPEG device doesn't handle transparency.
> Perhaps PNG?
>
> Jim
>
> On Thu, Jun 11, 2020 at 6:48 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have a data frame like this:
> >
> > > head(tmp1)
> >   CHR      BP   Pold    Pnew
> > 1   1  785989 0.9521 0.09278
> > 2   1 1130727 0.4750 0.19010
> > 3   1 1156131 0.5289 0.48520
> > 4   1 1158631 0.2554 0.18140
> > 5   1 1211292 0.2954 0.48590
> > 6   1 1478153 0.5542 0.68790
> > ...
> >
> > I did:
> > tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> > jpeg("over.jpeg")
> > ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> > facet_wrap(~CHR, nrow=1)
> > dev.off()
> >
> > but I got this plot in attach which doesn't make sense. Can you please
> > advise how to make this plot?
> >
> > thanks
> > Ana
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 00:22:38 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 08:22:38 +1000
Subject: [R] request
In-Reply-To: <CAKOwFD=hMNi_ruOmHobaBLjjAJNY8p1=YGppX6zuP6j+q2T1Eg@mail.gmail.com>
References: <CAKOwFD=hMNi_ruOmHobaBLjjAJNY8p1=YGppX6zuP6j+q2T1Eg@mail.gmail.com>
Message-ID: <CA+8X3fXhKYisq+TD5U7hcedc_50NzS=Viwd3kewraDaxkQxivA@mail.gmail.com>

Hi Mozhgan,
This is pretty obscure. If you have entered all of the variables in
your attached list, You can start by looking at the summary of the
output. This may help:

https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/summary.gam.html

Jim

On Thu, Jun 11, 2020 at 4:47 AM Mozhgan Soleimani
<mozhgansoleymani at gmail.com> wrote:
>
> Hello
> thank you for reading email
> please help me,
> I have used mgcv package for GAM model.
>
> To get contributions of each variable, Which code should I write in the R
> software?
> please see attached file
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Jun 11 00:49:18 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 10 Jun 2020 18:49:18 -0400
Subject: [R] kernlab ksvm rbfdot kernel - prediction returning fewer rows
 than provided for input
In-Reply-To: <546404572.1122955.1586898034318@mail.yahoo.com>
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
 <546404572.1122955.1586898034318@mail.yahoo.com>
Message-ID: <20200610184918.Horde.Zaj5ME0PfiJF648X5AR2u7D@www.ontargettek.com>


Hi everyone. I'm using the kernlab ksvm function with the rbfdot  
kernel for a binary classification problem and getting a strange  
result back. The predictions seem to be very accurate judging by the  
training results provided by the algorithm, but I'm unable to generate  
a confusion matrix because there is a difference in the number of  
output records from my model test compared to what was input into the  
test dataframe.

I've used ksvm before but never had this problem.

Here's my sample code:



install.packages("kernlab")
library(kernlab)


set.seed(3233)


trainIndex <-  
caret::createDataPartition(dataset_labeled_fraud$isFraud,  
p=0.70,kist=FALSE)

train <- dataset_labeled_fraud[trainIndex,]
test <- dataset_labeled_fraud[-trainIndex,]


#clear out the training model
filter <- NULL

filter <-  
kernlab::ksvm(isFraud~.,data=train,kernel="rbfdot",kpar=list(sigma=0.5),C=3,prob.model=TRUE)


#clear out the test results
test_pred_rbfdot <- NULL

test_pred_rbfdot <- kernlab::predict(filter,test,type="probabilities")

dataframe_test_pred_rbfdot <- as.data.frame(test_pred_rbfdot)


nrow(dataframe_test_pred_rbfdot)

> 23300

nrow(test)

> 24408


# ok, how did I go from 24408 input rows to only 23300 output  
prediction rows? :(


Thanks in advance anyone!




Thomas A. Woolman
PhD Candidate, Technology Management
Indiana State University


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Jun 11 00:51:01 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 10 Jun 2020 18:51:01 -0400
Subject: [R] 
 kernlab ksvm rbfdot kernel - prediction returning fewer rows
 than provided for input
In-Reply-To: <20200610184918.Horde.Zaj5ME0PfiJF648X5AR2u7D@www.ontargettek.com>
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
 <546404572.1122955.1586898034318@mail.yahoo.com>
 <20200610184918.Horde.Zaj5ME0PfiJF648X5AR2u7D@www.ontargettek.com>
Message-ID: <20200610185101.Horde.m_98poAiaPc7cthZzJTMjaE@www.ontargettek.com>

forgot to mention, the training and testing dataframes are composed of  
4 IVs (one double numeric IV and three factor IVs) and one DV  
(dichotomous factor, i.e. true or false).

The training dataframe consists of 48819 rows and test dataframe  
consists of 24408 rows.



Thanks again.



Quoting Tom Woolman <twoolman at ontargettek.com>:

> Hi everyone. I'm using the kernlab ksvm function with the rbfdot  
> kernel for a binary classification problem and getting a strange  
> result back. The predictions seem to be very accurate judging by the  
> training results provided by the algorithm, but I'm unable to  
> generate a confusion matrix because there is a difference in the  
> number of output records from my model test compared to what was  
> input into the test dataframe.
>
> I've used ksvm before but never had this problem.
>
> Here's my sample code:
>
>
>
> install.packages("kernlab")
> library(kernlab)
>
>
> set.seed(3233)
>
>
> trainIndex <-  
> caret::createDataPartition(dataset_labeled_fraud$isFraud,  
> p=0.70,kist=FALSE)
>
> train <- dataset_labeled_fraud[trainIndex,]
> test <- dataset_labeled_fraud[-trainIndex,]
>
>
> #clear out the training model
> filter <- NULL
>
> filter <-  
> kernlab::ksvm(isFraud~.,data=train,kernel="rbfdot",kpar=list(sigma=0.5),C=3,prob.model=TRUE)
>
>
> #clear out the test results
> test_pred_rbfdot <- NULL
>
> test_pred_rbfdot <- kernlab::predict(filter,test,type="probabilities")
>
> dataframe_test_pred_rbfdot <- as.data.frame(test_pred_rbfdot)
>
>
> nrow(dataframe_test_pred_rbfdot)
>
>> 23300
>
> nrow(test)
>
>> 24408
>
>
> # ok, how did I go from 24408 input rows to only 23300 output  
> prediction rows? :(
>
>
> Thanks in advance anyone!
>
>
>
>
> Thomas A. Woolman
> PhD Candidate, Technology Management
> Indiana State University


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Jun 11 01:00:29 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 10 Jun 2020 19:00:29 -0400
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
Message-ID: <76e9f973-aa59-db58-db28-ab0998622edb@gmail.com>

Your best chance to get some interest is to adapt an existing package
such as linprog or lpSolve to use your algorithm. Then there will be
sufficient structure to allow R users and developers to see your
ideas working, even if they are not efficiently programmed. It's
always easier to start with something that is working and improve it.
And you would be able to show comparisons of the existing examples by
the current and new methods.

I've worked on a lot of optimization (mainly function minimization) methods
over many decades, and there are several "brilliant" ideas that have not
turned out to be very good practical methods, while some rather pedestrian
ideas have proved reliable and effective, even if they don't fulfill nice
theoretical properties. There are, however, a few nice cases where theory
and practice are both great.

JN

On 2020-06-10 12:36 a.m., Keshava PRASADa Halemane wrote:
> Friends:
> i am a retired Professor -
> not having any access to the resources (human/financial/business/whatever)
> that may be required -
> therefore i am seeking implementation of my algorithm 'spdspds' -
> a novel algorithm for solving Linear Programming Problems with O(L^1.5)
> computational complexity -
> in order to show/convince the esteemed world optimization community
> that it is indeed a great grand breakthrough in terms of achievement of the
> linear programming performance challenge of the millennium -
> with far reaching deep impact on optimization algorithm development in
> general -
> holy grail fantasy realized!
> 
> I need some individual or team who is interested & willing to work on this.
> Earlier experience in implementation of optimization/LP algorithms will
> greatly help.
> 
> You may access / download / read my paper -
> "Unbelievable *O*(*L*^1.5) worst case computational complexity achieved by
> spdspds algorithm for linear programming problem"
> which is available at - arxiv . org / abs / 1405 . 6902
> 
> Thanks a lot.
>  - Dr(Prof) Keshava Prasad Halemane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 @end|ng |rom gm@||@com  Thu Jun 11 01:16:40 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Wed, 10 Jun 2020 17:16:40 -0600
Subject: [R] Help about extracting data
In-Reply-To: <CABirntQV6SHK6sFNCVSqCTfUYCM_6S5Ce0=B+No-0oWqu=WwLA@mail.gmail.com>
References: <CABirntQV6SHK6sFNCVSqCTfUYCM_6S5Ce0=B+No-0oWqu=WwLA@mail.gmail.com>
Message-ID: <CAFEqCdxLvM3aNHrR+ym7MeOw2BsAB0VBvNFXEuqh2xybt1OBrQ@mail.gmail.com>

There are more than one way to do it, and it would help if you
provided some sample data.

But here is an example for one way to do it:

examp.dat <- as.data.frame(matrix(sample(1:5, 100*6, replace=TRUE), ncol=6)
tmp.count <- apply(examp.dat, 1, function(x) sum(x>=3))
examp2.dat <- examp.dat[tmp.count <= 4, ]

examp.dat is a data frame with example data.
tmp.count is then the result of applying an anonymous function to each
row, the function counts how many entries in each row are greater than
or equal to 3
examp2.dat is then created as the subset where tmp.count is less than
or equal to 4.


On Wed, Jun 10, 2020 at 12:47 PM Aya Gilad <ayagilad at gmail.com> wrote:
>
> Hello,
> I'm analyzing a 6-question questionnaire. I need to exclude participants
> who answered more than 4 questions with a grade of 3 or higher.
> How do I write such a code?
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From cpoiw@rt m@iii@g oii chemo@org@uk  Thu Jun 11 01:17:24 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Thu, 11 Jun 2020 00:17:24 +0100
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jNVnYXouU-T2v-BMTjt+YJ=ZXwx4gmUkCrjB+ce4XuTZA@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>
 <CAF9-5jNVnYXouU-T2v-BMTjt+YJ=ZXwx4gmUkCrjB+ce4XuTZA@mail.gmail.com>
Message-ID: <d28ffccd630a828a4eb446df507a1edb@chemo.org.uk>

What did you expect?

I'm assuming two plots (based on the subject) and side by side based on 
the code (nrow =1)

But you are getting several graphs (facets) on the row and only expected 
2?

What is in CHR?  i.e. summary(tmp1$CHR)

I'm assuming its not a factor with 2 elements...?


>> > Hello,
>> >
>> > I have a data frame like this:
>> >
>> > > head(tmp1)
>> >   CHR      BP   Pold    Pnew
>> > 1   1  785989 0.9521 0.09278
>> > 2   1 1130727 0.4750 0.19010
>> > 3   1 1156131 0.5289 0.48520
>> > 4   1 1158631 0.2554 0.18140
>> > 5   1 1211292 0.2954 0.48590
>> > 6   1 1478153 0.5542 0.68790
>> > ...
>> > ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
>> > facet_wrap(~CHR, nrow=1)


From j@zh@o @end|ng |rom ye@h@net  Thu Jun 11 02:29:10 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Thu, 11 Jun 2020 08:29:10 +0800
Subject: [R] how to extract specific subscript of a matrix
Message-ID: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>

Hi there,

I have a matrix similar as:

M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)

I hope to get the border subscript of the block with value 1. In the 
above example, I hope to get:

(3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)

Is there any function can do that? or any implement idea? Thanks!

Best,
Jinsong


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 11 03:01:57 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 10 Jun 2020 18:01:57 -0700
Subject: [R] how to extract specific subscript of a matrix
In-Reply-To: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
References: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
Message-ID: <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>

M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
ix <- expand.grid( r = seq.int( nrow( M ) )
                 , c = seq.int( ncol( M ) )
                 )
ix[ 1 == c(M), ]


On June 10, 2020 5:29:10 PM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>Hi there,
>
>I have a matrix similar as:
>
>M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
>
>I hope to get the border subscript of the block with value 1. In the 
>above example, I hope to get:
>
>(3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)
>
>Is there any function can do that? or any implement idea? Thanks!
>
>Best,
>Jinsong
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Thu Jun 11 03:21:40 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Jun 2020 03:21:40 +0200
Subject: [R] how to extract specific subscript of a matrix
In-Reply-To: <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>
References: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
 <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>
Message-ID: <20200611012140.GA162277@posteo.no>

On 2020-06-10 18:01 -0700, Jeff Newmiller wrote:
> On June 10, 2020 5:29:10 PM PDT, Jinsong Zhao wrote:
> > 
> > (3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)
> 
> M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
> ix <- expand.grid( r = seq.int( nrow( M ) )
>                  , c = seq.int( ncol( M ) )
>                  )
> ix[ 1 == c(M), ]

Dear Jinsong and Jeff,

I thought out this, really similar to Jeff's answer:

	M <- matrix(c(2, 2, rep(1, 12), 2),
	            nrow=5, byrow=FALSE)
	
	points <- expand.grid(1:nrow(M), 1:ncol(M))
	points <- apply(points, 1, paste, collapse=",")
	points <- matrix(paste0("(", points, ")"),
	                 nrow=nrow(M))
	
	paste(points[M==1], collapse=", ")

you get

	[1] "(3,1), (4,1), (5,1), (1,2), (2,2), (3,2), (4,2), (5,2), (1,3), (2,3), (3,3), (4,3)"

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200611/5675bb5e/attachment.sig>

From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 05:24:27 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 13:24:27 +1000
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
Message-ID: <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>

Hi Saudi,
I can only make a guess, but that is that a variable having a unique
value for each participant has been read in as a factor. I assume that
"better" is some combination of "hum" and "cul" and exactly what is
WF?

Jim

On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:
>
> Dear Sir/Madam,
>
> Hope everyone is safe and sound. I appreciate your help a lot.
>
> I am evaluating two Arabic subtitles of a humorous English scene and asked
> 263 participants (part) to evaluate the two subtitles (named Standard
> Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them to
> rank the two subtitles in terms of how much each subtitle is
>
> 2) more humorous (hum),
>
> 5) closer to Egyptian culture (cul)
>
>
>
> The questionnaire contained two 1-10 linear scale questions regarding the 2
> points clarified, with 1 meaning the most humorous and closest to Egyptian
> culture, and 1 meaning the least humorous and furthest from Egyptian
> culture. Also, the questionnaire had a general multiple-choice question
> regarding which subtitle is better in general (better). General information
> about the participants were also collected concerning gender (categorical
> factor), age (numeric factor) and education (categorical factor).
>
> Two versions of the questionnaire were relied on: one showing the ?SA
> subtitle first? and another showing the ?EA subtitle first?. Nearly half
> the participants answered the first and nearly half answered the latter.
>
> I am focusing on which social factor/s lead/s the participants to evaluate
> one of the two subtitles as generally better and which subtitle is more
> humorous and closer to Egyptian culture. Each of these points alone can be
> the dependent factor, but the results altogether can be linked.
>
> I thought that mixed effects analyses would clarify the picture and answer
> the research questions (which  factor/s lead/s participants to favour a
> subtitle over another?) and, so,  tried the lme4 package in R and ran many
> models but all the codes I have used are not working.
>
> I ran the following codes, which yielded Error messages, like:
>
> model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> data=sub_data)
>
> Error: number of levels of each grouping factor must be < number of
> observations (problems: part)
>
>
>
> Model2 <- glmer (better ~ gender + age + education + WF + (1 | part), data
> = sub_data, family='binomial')
>
> Error in mkRespMod(fr, family = family) :
>
>   response must be numeric or factor
>
>
>
> Model3 <- glmer (better ~ age + gender + education + WF + (1 | part), data
> = sub_data, family='binomial', control=glmerControl(optimizer=c("bobyqa")))
>
> Error in mkRespMod(fr, family = family) :
>
>   response must be numeric or factor
>
>
>
> Why does the model crash? Does the problem lie in the random factor part (which
> is a code for participants)? Or is it something related to the mixed
> effects analysis?
>
> Best
> Saudi Sadiq
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd @end|ng |rom @urewe@t@net  Thu Jun 11 06:24:55 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 10 Jun 2020 21:24:55 -0700
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
Message-ID: <20200610212455.52872fd6@Draco>

On Wed, 10 Jun 2020 15:36:11 -0500
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hello,
> 
> I have a data frame like this:
> 
> > head(tmp1)  
>   CHR      BP   Pold    Pnew
> 1   1  785989 0.9521 0.09278
> 2   1 1130727 0.4750 0.19010
> 3   1 1156131 0.5289 0.48520
> 4   1 1158631 0.2554 0.18140
> 5   1 1211292 0.2954 0.48590
> 6   1 1478153 0.5542 0.68790
> ...
> 
> I did:
> tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> jpeg("over.jpeg")
> ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> facet_wrap(~CHR, nrow=1)
> dev.off()
> 
> but I got this plot in attach which doesn't make sense. Can you please
> advise how to make this plot?
> 
> thanks
> Ana

If you would, the str() output might help people understand what is
happening, and also how many records you're looking at.  The head()
output is a bit thin on information.  There are various manhattan plot
packages for R including a specialized package for ggplot2. 

JWDougherty


From chr|@ho|d @end|ng |rom p@yctc@org  Thu Jun 11 08:48:52 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Thu, 11 Jun 2020 07:48:52 +0100 (BST)
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <76e9f973-aa59-db58-db28-ab0998622edb@gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
 <76e9f973-aa59-db58-db28-ab0998622edb@gmail.com>
Message-ID: <1377273822.3824145.1591858132256.JavaMail.zimbra@psyctc.org>



----- Original Message -----
> From: "J C Nash" <profjcnash at gmail.com>
> To: "Keshava PRASADa Halemane" <k.prasad.h at gmail.com>, r-help at r-project.org
> Sent: Thursday, 11 June, 2020 01:00:29
> Subject: Re: [R] Seeking implementation of my algorithm 'spdspds' - a novel algorithm for solving Linear Programming
> Problems with O(L^1.5) computational complexity

[snipped]
 
> I've worked on a lot of optimization (mainly function minimization) methods
> over many decades, and there are several "brilliant" ideas that have not
> turned out to be very good practical methods, while some rather pedestrian
> ideas have proved reliable and effective, even if they don't fulfill nice
> theoretical properties. There are, however, a few nice cases where theory
> and practice are both great.

Fortune nomination!   Glorious.  Thanks for making me smile.

Chris

[rest snipped]

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jun 11 09:17:28 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 11 Jun 2020 09:17:28 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
Message-ID: <24289.55944.187150.598914@stat.math.ethz.ch>

>>>>> Rich Shepard 
>>>>>     on Wed, 10 Jun 2020 07:44:49 -0700 writes:

    > On Wed, 10 Jun 2020, Jeff Newmiller wrote:
    >> Fix your format specification?  ?strptime

    >>> I have been trying to convert European short dates
    >>> formatted as dd/mm/yy into the ISO 8601 but the function
    >>> as.Dates interprets them as American ones (mm/dd/yy),
    >>> thus I get:

    > Look at Hadley Wickham's 'tidyverse' collection as
    > described in R for Data Science. There are date, datetime,
    > and time functions that will do just what you want.

    > Rich

I strongly disagree that automatic guessing of date format is a
good idea:

If you have dates such as  01/02/03, 10/11/12 , ...
you cannot have a software (and also not a human) to *guess* for
you what it means.  You have to *know* or get that knowledge "exogenously",
i.e., from context (say "meta data" if you want) that you as
data analyst must have before you can reliably work with that
data.

There is a global standard (ISO) for dates,  2020-06-11, for today's;
These have the huge advantage that alphabetical ordering is
equivalent to time ordering ... and honestly I don't see why
smart people (such as most? R users) do not all use these much
more often, notably when it comes to data.

But as long as most people in the world don't use that format
and practically all default formats for dates (e.g. in
spreadsheats and computer locales) do not use the ISO
standard, but rather regional conventions, one must add meta
data to have 100% garantee to use the correct format.

Of course, you can often guess correctly with very high
(subjective) probability, e.g.,   11/23/99  is highly probably
the 23rd of Nov, 1999.... and indeed if you have more than a few
dates, it often helps to guess correctly.  But there's no
guarantee.

No, I state that it is much better to ask from the data analyst
to use their brains a little bit and enter the date format
explicitly, than using software that does guess it for them
correctly most of the time.  How should they find out at all in
the rare cases the automatic guess will be wrong ?

Martin Maechler
ETH Zurich  and  R Core team


From jk|boger@ @end|ng |rom gm@||@com  Thu Jun 11 09:28:37 2020
From: jk|boger@ @end|ng |rom gm@||@com (jacob bogers)
Date: Thu, 11 Jun 2020 09:28:37 +0200
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
Message-ID: <CALuwgN6cozcT+zG+3m3n6aMy3aU9Z0L3MRwRY_18meNdxtyNsQ@mail.gmail.com>

" not having any access to the resources "
You have internet (as is proven by sending this email)
you even have R cli these days on mobile (I do anyway).
Learn R , code,  let me know how it turns out



On Wed, Jun 10, 2020 at 8:46 PM Keshava PRASADa Halemane <
k.prasad.h at gmail.com> wrote:

> Friends:
> i am a retired Professor -
> not having any access to the resources (human/financial/business/whatever)
> that may be required -
> therefore i am seeking implementation of my algorithm 'spdspds' -
> a novel algorithm for solving Linear Programming Problems with O(L^1.5)
> computational complexity -
> in order to show/convince the esteemed world optimization community
> that it is indeed a great grand breakthrough in terms of achievement of the
> linear programming performance challenge of the millennium -
> with far reaching deep impact on optimization algorithm development in
> general -
> holy grail fantasy realized!
>
> I need some individual or team who is interested & willing to work on this.
> Earlier experience in implementation of optimization/LP algorithms will
> greatly help.
>
> You may access / download / read my paper -
> "Unbelievable *O*(*L*^1.5) worst case computational complexity achieved by
> spdspds algorithm for linear programming problem"
> which is available at - arxiv . org / abs / 1405 . 6902
>
> Thanks a lot.
>  - Dr(Prof) Keshava Prasad Halemane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Thu Jun 11 11:31:58 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 11 Jun 2020 21:31:58 +1200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <24289.55944.187150.598914@stat.math.ethz.ch>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
Message-ID: <CABcYAdL8pfCFcf6Ka+4jGNMFcn44-dQTYmjgfHh+QkA5MwMqpw@mail.gmail.com>

I would add to this that in an important data set I was working with,
most of the dates were dd/mm/yy but some of them were mm/dd/yy and
that led to the realisation that I couldn't *tell* for about 40% of
the dates which they were.  If they were all one or the other, no
worries, but when you have people from mixed backgrounds writing in
mixed formats, you have a problem.

On Thu, 11 Jun 2020 at 19:17, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Rich Shepard
> >>>>>     on Wed, 10 Jun 2020 07:44:49 -0700 writes:
>
>     > On Wed, 10 Jun 2020, Jeff Newmiller wrote:
>     >> Fix your format specification?  ?strptime
>
>     >>> I have been trying to convert European short dates
>     >>> formatted as dd/mm/yy into the ISO 8601 but the function
>     >>> as.Dates interprets them as American ones (mm/dd/yy),
>     >>> thus I get:
>
>     > Look at Hadley Wickham's 'tidyverse' collection as
>     > described in R for Data Science. There are date, datetime,
>     > and time functions that will do just what you want.
>
>     > Rich
>
> I strongly disagree that automatic guessing of date format is a
> good idea:
>
> If you have dates such as  01/02/03, 10/11/12 , ...
> you cannot have a software (and also not a human) to *guess* for
> you what it means.  You have to *know* or get that knowledge "exogenously",
> i.e., from context (say "meta data" if you want) that you as
> data analyst must have before you can reliably work with that
> data.
>
> There is a global standard (ISO) for dates,  2020-06-11, for today's;
> These have the huge advantage that alphabetical ordering is
> equivalent to time ordering ... and honestly I don't see why
> smart people (such as most? R users) do not all use these much
> more often, notably when it comes to data.
>
> But as long as most people in the world don't use that format
> and practically all default formats for dates (e.g. in
> spreadsheats and computer locales) do not use the ISO
> standard, but rather regional conventions, one must add meta
> data to have 100% garantee to use the correct format.
>
> Of course, you can often guess correctly with very high
> (subjective) probability, e.g.,   11/23/99  is highly probably
> the 23rd of Nov, 1999.... and indeed if you have more than a few
> dates, it often helps to guess correctly.  But there's no
> guarantee.
>
> No, I state that it is much better to ask from the data analyst
> to use their brains a little bit and enter the date format
> explicitly, than using software that does guess it for them
> correctly most of the time.  How should they find out at all in
> the rare cases the automatic guess will be wrong ?
>
> Martin Maechler
> ETH Zurich  and  R Core team
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@v|76 @end|ng |rom gm@||@com  Thu Jun 11 15:00:28 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Thu, 11 Jun 2020 09:00:28 -0400
Subject: [R] sqldf and number of records affected
Message-ID: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>

Hello all, When I execute a SQL using SQLDF, how do I get the number of
records affected?  I mean, if I run an UPDATE on a data frame, it doesn't
tell me if and how many records got updated.  I've read through the
documentation and there don't seem to be a way to get this info unless it's
done on a database.  Any ideas?

Thanks
Ravi


-- 
This email has been checked for viruses by AVG.
https://www.avg.com


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jun 11 15:12:22 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 11 Jun 2020 09:12:22 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
Message-ID: <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>

Here is an example.  Ignore the warning or use the workaround discussed here
https://github.com/ggrothendieck/sqldf/issues/40
to avoid the warning.

  library(sqldf)
  sqldf()  # use same connection until next sqldf()
  sqldf(c("pragma count_changes = 1", "update BOD set demand = 99
where Time > 4"))
  sqldf("select * from main.BOD")
  sqldf()


On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Hello all, When I execute a SQL using SQLDF, how do I get the number of
> records affected?  I mean, if I run an UPDATE on a data frame, it doesn't
> tell me if and how many records got updated.  I've read through the
> documentation and there don't seem to be a way to get this info unless it's
> done on a database.  Any ideas?
>
> Thanks
> Ravi
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jun 11 15:29:13 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 11 Jun 2020 06:29:13 -0700 (PDT)
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <24289.55944.187150.598914@stat.math.ethz.ch>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
Message-ID: <alpine.LNX.2.20.2006110625040.13945@salmo.appl-ecosys.com>

On Thu, 11 Jun 2020, Martin Maechler wrote:

>    > Look at Hadley Wickham's 'tidyverse' collection as
>    > described in R for Data Science. There are date, datetime,
>    > and time functions that will do just what you want.

> I strongly disagree that automatic guessing of date format is a
> good idea:

Martin,

I think either you misunderstood what I wrote or I was not sufficiently
explicit in my brief response. I did not mean to imply there was any
automatic guessing involved. Specifying input and output formats is
required.

Reading Hadley's book I was impressed that one could specify the format of
dates in the dataset and convert them all to the ISO-8601 format. Before
learning this I'd use emacs regex to do the reformating I needed (or,
sometimes, awk).

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jun 11 15:32:20 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 11 Jun 2020 06:32:20 -0700 (PDT)
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CABcYAdL8pfCFcf6Ka+4jGNMFcn44-dQTYmjgfHh+QkA5MwMqpw@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
 <CABcYAdL8pfCFcf6Ka+4jGNMFcn44-dQTYmjgfHh+QkA5MwMqpw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2006110629250.13945@salmo.appl-ecosys.com>

On Thu, 11 Jun 2020, Richard O'Keefe wrote:

> I would add to this that in an important data set I was working with, most
> of the dates were dd/mm/yy but some of them were mm/dd/yy and that led to
> the realisation that I couldn't *tell* for about 40% of the dates which
> they were. If they were all one or the other, no worries, but when you
> have people from mixed backgrounds writing in mixed formats, you have a
> problem.

Richard,

Ouch! While I've not had data sets with this problem I've had many that were
extracted from spreadsheets that had a mix of date formats mm/dd/yyyy,
mm-dd-yyyy, and other strange strings. That's why I encourage my clients to
use a database rather than spreadsheets for their environmental data.

Regards,

Rich


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 15:54:40 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 08:54:40 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <20200610212455.52872fd6@Draco>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
Message-ID: <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>

Hello,

I expected it to look like this:
https://imgur.com/a/pj40c

where x-axis would be CHR, there is 22 of them
> unique(tmp.tidy$CHR)
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22

I also have two phenotypes (keys) which I would like to compare
> unique(tmp.tidy$key)
[1] "Pold" "Pnew"

> dim(tmp.tidy)
[1] 2600184       4

I would like the x-axis to be separated by CHR

> sapply(tmp.tidy,class)
        CHR          BP         key       value
  "integer"   "integer" "character"   "numeric"

> str(tmp.tidy)
'data.frame':    2600184 obs. of  4 variables:
 $ CHR  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ BP   : int  785989 1130727 1156131 1158631 1211292 1478153 1500941
1506035 1510801 1721479 ...
 $ key  : chr  "Pold" "Pold" "Pold" "Pold" ...
 $ value: num  0.952 0.475 0.529 0.255 0.295 ...

Unfortunately qqman doesn't do this kind of overlay of two plots

On Wed, Jun 10, 2020 at 11:24 PM John <jwd at surewest.net> wrote:
>
> On Wed, 10 Jun 2020 15:36:11 -0500
> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> > Hello,
> >
> > I have a data frame like this:
> >
> > > head(tmp1)
> >   CHR      BP   Pold    Pnew
> > 1   1  785989 0.9521 0.09278
> > 2   1 1130727 0.4750 0.19010
> > 3   1 1156131 0.5289 0.48520
> > 4   1 1158631 0.2554 0.18140
> > 5   1 1211292 0.2954 0.48590
> > 6   1 1478153 0.5542 0.68790
> > ...
> >
> > I did:
> > tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> > jpeg("over.jpeg")
> > ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> > facet_wrap(~CHR, nrow=1)
> > dev.off()
> >
> > but I got this plot in attach which doesn't make sense. Can you please
> > advise how to make this plot?
> >
> > thanks
> > Ana
>
> If you would, the str() output might help people understand what is
> happening, and also how many records you're looking at.  The head()
> output is a bit thin on information.  There are various manhattan plot
> packages for R including a specialized package for ggplot2.
>
> JWDougherty


From r@v|76 @end|ng |rom gm@||@com  Thu Jun 11 16:06:35 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Thu, 11 Jun 2020 10:06:35 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
 <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
Message-ID: <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>

Thanks for the response Gabor.  Looks like the below example will work when using SQLite, but in my case I'm just creating a dataframe in R and trying to update it using sqldf as below and it doesn't seem to work ...

con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
sqldf()
sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 "))
ans <- sqldf("select * from main.con")
sqldf()

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Thursday, June 11, 2020 9:12 AM
To: Ravi Jeyaraman <ravi76 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] sqldf and number of records affected

Here is an example.  Ignore the warning or use the workaround discussed here
https://github.com/ggrothendieck/sqldf/issues/40
to avoid the warning.

  library(sqldf)
  sqldf()  # use same connection until next sqldf()
  sqldf(c("pragma count_changes = 1", "update BOD set demand = 99 where Time > 4"))
  sqldf("select * from main.BOD")
  sqldf()


On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Hello all, When I execute a SQL using SQLDF, how do I get the number 
> of records affected?  I mean, if I run an UPDATE on a data frame, it 
> doesn't tell me if and how many records got updated.  I've read 
> through the documentation and there don't seem to be a way to get this 
> info unless it's done on a database.  Any ideas?
>
> Thanks
> Ravi
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


-- 
This email has been checked for viruses by AVG.
https://www.avg.com


From cpoiw@rt m@iii@g oii chemo@org@uk  Thu Jun 11 16:26:40 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Thu, 11 Jun 2020 15:26:40 +0100
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
Message-ID: <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>

On 2020-06-11 14:54, Ana Marija wrote:
> Hello,
> 
> I expected it to look like this:
> https://imgur.com/a/pj40c
> 

Ah - so all on the one plot? - so you don't want a facet. It puts two 
plots side by side (or 22)

> where x-axis would be CHR, there is 22 of them
>> unique(tmp.tidy$CHR)
>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22
> 

You have 22 plots all appearing side by size as part of the facet

I think you want color=CHR - but I don't know what your current color 
setting is doing.

> I also have two phenotypes (keys) which I would like to compare
>> unique(tmp.tidy$key)
> [1] "Pold" "Pnew"
> 

So did you want to Facet those?


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jun 11 16:27:30 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 11 Jun 2020 16:27:30 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <alpine.LNX.2.20.2006110625040.13945@salmo.appl-ecosys.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
 <alpine.LNX.2.20.2006110625040.13945@salmo.appl-ecosys.com>
Message-ID: <24290.16210.645249.430350@stat.math.ethz.ch>

>>>>> Rich Shepard 
>>>>>     on Thu, 11 Jun 2020 06:29:13 -0700 writes:

    > On Thu, 11 Jun 2020, Martin Maechler wrote:
    >> > Look at Hadley Wickham's 'tidyverse' collection as >
    >> described in R for Data Science. There are date,
    >> datetime, > and time functions that will do just what you
    >> want.

    >> I strongly disagree that automatic guessing of date
    >> format is a good idea:

    > Martin,

    > I think either you misunderstood what I wrote or I was not
    > sufficiently explicit in my brief response. I did not mean
    > to imply there was any automatic guessing
    > involved. Specifying input and output formats is required.

Well, ok.  Yes, then I misunderstood.  I know there *are* R
packages out there which boast automatically finding the correct format.

If you are willing to specify the input format, I don't see why
one should use the huge tidyverse  instead of just using the
potent enough base R functions,  one of which Jeff Newmiller was
talking about (and to whom you replied saying you'd rather use
the extra functions).

    > Reading Hadley's book I was impressed that one could
    > specify the format of dates in the dataset and convert
    > them all to the ISO-8601 format. Before learning this I'd
    > use emacs regex to do the reformating I needed (or,
    > sometimes, awk).

Well, as you know I use emacs even more than R (because I use R
via emacs's ESS),  but I think I wouldn't use it to transform
dates or date times [well, unless such a date/datetime column
is so severely messed up that one format is not appropriate for
at least a few large chunks of these] because I'd rather try to
use completely reproducible R code from the beginning of
cleaning/reading/analysing the raw data to the end.

And for that, base R is entirely sufficient in spite of all the
advertisements of the many date/time formatting packages.
But yes, I wrote more about this about 10 weeks ago on the
R-devel list here  (which also seemed to have been
rather mis-understood, for which I must mostly blame myself of course) :

  https://stat.ethz.ch/pipermail/r-devel/2020-April/079260.html

In that thread, the following  'R News' article was mentioned as
good introduction in the subject from a 'base R' (+ "almost
recommended" package 'chron') point of view 

  https://www.researchgate.net/publication/229087103_R_Help_Desk_Date_and_time_classes_in_R

which is really from here

  https://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf

'R News' was the predecessor of the
R Journal, https://journal.r-project.org/

I think we should leave it here, because we've been diverting
too much.

Best,
Martin


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jun 11 16:30:02 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 11 Jun 2020 10:30:02 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
 <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
 <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>
Message-ID: <CAP01uRkF_CgC9BehTE79VherJyKF0TBUuMLY5Wuq+KepQY9P-g@mail.gmail.com>

There is no real difference between your example and the example I provided.
Both use a data.frame in R and both work for me under R 3.5 with RSQLite 2.2.0
See log below.

Note that there is a bug in R 4.0 related to tcltk that could possibly affect
sqldf as it uses tcltk.  A fix has been announced for R 4.0.2.

> library(sqldf)
Loading required package: gsubfn
Loading required package: proto
Loading required package: RSQLite
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
<SQLiteConnection>
  Path: :memory:
  Extensions: TRUE
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 "))
  rows updated
1            5
Warning message:
In result_fetch(res at ptr, n = n) :
  SQL statements must be issued with dbExecute() or dbSendStatement()
instead of dbGetQuery() or dbSendQuery().
> ans <- sqldf("select * from main.con")
> sqldf()
NULL
> ans
   V1
1   1
2   2
3   3
4   4
5   5
6   0
7   0
8   0
9   0
10  0
> R.version.string
[1] "R version 3.5.3 (2019-03-11)"
> packageVersion("sqldf")
[1] ?0.4.11?
> packageVersion("RSQLite")
[1] ?2.2.0?
> packageVersion("DBI")
[1] ?1.1.0?



On Thu, Jun 11, 2020 at 10:06 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Thanks for the response Gabor.  Looks like the below example will work when using SQLite, but in my case I'm just creating a dataframe in R and trying to update it using sqldf as below and it doesn't seem to work ...
>
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 "))
> ans <- sqldf("select * from main.con")
> sqldf()
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Thursday, June 11, 2020 9:12 AM
> To: Ravi Jeyaraman <ravi76 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] sqldf and number of records affected
>
> Here is an example.  Ignore the warning or use the workaround discussed here
> https://github.com/ggrothendieck/sqldf/issues/40
> to avoid the warning.
>
>   library(sqldf)
>   sqldf()  # use same connection until next sqldf()
>   sqldf(c("pragma count_changes = 1", "update BOD set demand = 99 where Time > 4"))
>   sqldf("select * from main.BOD")
>   sqldf()
>
>
> On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
> >
> > Hello all, When I execute a SQL using SQLDF, how do I get the number
> > of records affected?  I mean, if I run an UPDATE on a data frame, it
> > doesn't tell me if and how many records got updated.  I've read
> > through the documentation and there don't seem to be a way to get this
> > info unless it's done on a database.  Any ideas?
> >
> > Thanks
> > Ravi
> >
> >
> > --
> > This email has been checked for viruses by AVG.
> > https://www.avg.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jr@| @end|ng |rom po@teo@no  Thu Jun 11 16:48:51 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Jun 2020 16:48:51 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <20200611144851.GB162277@posteo.no>

On 2020-06-10 10:20 +0200, Luigi Marongiu wrote:
> I have been trying to convert European 
> short dates formatted as dd/mm/yy into the 
> ISO 8601 but the function as.Dates 
> interprets them as American ones 
> (mm/dd/yy)

Dear Luigi,

?strptime says:

	?%D? Date format such as ?%m/%d/%y?: the C99 standard says it
	     should be that exact format (but not all OSes comply).

as.Date(oriDates, format="%d/%m/%y") works 
fine for me here on the Linux laptop ... 

You could also try to work on the strings 
themselves to convert them to ISO format, 
like:

	oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
	             "27/01/20", "28/01/20", "29/01/20", "30/01/20",
	             "31/01/20", "01/02/20", "02/02/20", "03/02/20",
	             "04/02/20", "05/02/20", "06/02/20", "07/02/20")
	d <- t(as.data.frame(strsplit(oriDates, "/")))
	dimnames(d) <- list(NULL, c("d", "m", "y"))
	u <- unique(d[,"y"])
	millenia <- "20"
	if (length(u)==1 & u==millenia) {
	  Dates <- paste0(millenia, d[,"y"], "-",
	                  d[,"m"], "-", d[,"d"])
	  Dates <- as.Date(Dates)
	} else {
	  Dates <- "'Allo 'allo ... error, error ... more complicated formatting is required to digest those dates ..."
	}
	print(Dates)

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200611/1108b6bb/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 16:59:37 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 09:59:37 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
 <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
Message-ID: <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>

yes all in one plot.
So I want key (and therefore color)to be "Pold" and "Pnew" as those I
am comparing per CHR
so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
On the end x-axis would have two strikes of Pold and Pnew (different
colors) per one chromosome, and CHR would go from 1 to 22

On Thu, Jun 11, 2020 at 9:26 AM <cpolwart at chemo.org.uk> wrote:
>
> On 2020-06-11 14:54, Ana Marija wrote:
> > Hello,
> >
> > I expected it to look like this:
> > https://imgur.com/a/pj40c
> >
>
> Ah - so all on the one plot? - so you don't want a facet. It puts two
> plots side by side (or 22)
>
> > where x-axis would be CHR, there is 22 of them
> >> unique(tmp.tidy$CHR)
> >  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22
> >
>
> You have 22 plots all appearing side by size as part of the facet
>
> I think you want color=CHR - but I don't know what your current color
> setting is doing.
>
> > I also have two phenotypes (keys) which I would like to compare
> >> unique(tmp.tidy$key)
> > [1] "Pold" "Pnew"
> >
>
> So did you want to Facet those?


From r@v|76 @end|ng |rom gm@||@com  Thu Jun 11 17:30:40 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Thu, 11 Jun 2020 11:30:40 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <CAP01uRkF_CgC9BehTE79VherJyKF0TBUuMLY5Wuq+KepQY9P-g@mail.gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
 <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
 <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>
 <CAP01uRkF_CgC9BehTE79VherJyKF0TBUuMLY5Wuq+KepQY9P-g@mail.gmail.com>
Message-ID: <107201d64005$43ced190$cb6c74b0$@gmail.com>

You're correct.  It does work.  I was looking at some other result printed.  My bad.

Looks like we can also get the same result using 'SELECT changes()'.     

Approach 1:

con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
sqldf()
suppressWarnings(sqldf(c(" update con set V1 = 0 where V1 > 5 ", "select changes()")))
sqldf("select * from main.con")
sqldf()

Approach 2:

con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
sqldf()
suppressWarnings(sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 ")))
sqldf("select * from main.con")
sqldf()



-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Thursday, June 11, 2020 10:30 AM
To: Ravi Jeyaraman <ravi76 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] sqldf and number of records affected

There is no real difference between your example and the example I provided.
Both use a data.frame in R and both work for me under R 3.5 with RSQLite 2.2.0 See log below.

Note that there is a bug in R 4.0 related to tcltk that could possibly affect sqldf as it uses tcltk.  A fix has been announced for R 4.0.2.

> library(sqldf)
Loading required package: gsubfn
Loading required package: proto
Loading required package: RSQLite
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
<SQLiteConnection>
  Path: :memory:
  Extensions: TRUE
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 
> 5 "))
  rows updated
1            5
Warning message:
In result_fetch(res at ptr, n = n) :
  SQL statements must be issued with dbExecute() or dbSendStatement() instead of dbGetQuery() or dbSendQuery().
> ans <- sqldf("select * from main.con")
> sqldf()
NULL
> ans
   V1
1   1
2   2
3   3
4   4
5   5
6   0
7   0
8   0
9   0
10  0
> R.version.string
[1] "R version 3.5.3 (2019-03-11)"
> packageVersion("sqldf")
[1] ?0.4.11?
> packageVersion("RSQLite")
[1] ?2.2.0?
> packageVersion("DBI")
[1] ?1.1.0?



On Thu, Jun 11, 2020 at 10:06 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Thanks for the response Gabor.  Looks like the below example will work when using SQLite, but in my case I'm just creating a dataframe in R and trying to update it using sqldf as below and it doesn't seem to work ...
>
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 
> 5 ")) ans <- sqldf("select * from main.con")
> sqldf()
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Thursday, June 11, 2020 9:12 AM
> To: Ravi Jeyaraman <ravi76 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] sqldf and number of records affected
>
> Here is an example.  Ignore the warning or use the workaround 
> discussed here
> https://github.com/ggrothendieck/sqldf/issues/40
> to avoid the warning.
>
>   library(sqldf)
>   sqldf()  # use same connection until next sqldf()
>   sqldf(c("pragma count_changes = 1", "update BOD set demand = 99 where Time > 4"))
>   sqldf("select * from main.BOD")
>   sqldf()
>
>
> On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
> >
> > Hello all, When I execute a SQL using SQLDF, how do I get the number 
> > of records affected?  I mean, if I run an UPDATE on a data frame, it 
> > doesn't tell me if and how many records got updated.  I've read 
> > through the documentation and there don't seem to be a way to get 
> > this info unless it's done on a database.  Any ideas?
> >
> > Thanks
> > Ravi
> >
> >
> > --
> > This email has been checked for viruses by AVG.
> > https://www.avg.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From cpoiw@rt m@iii@g oii chemo@org@uk  Thu Jun 11 18:52:38 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Thu, 11 Jun 2020 17:52:38 +0100
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
 <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
 <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>
Message-ID: <f5bbf6217dc3af9d5b83bcea68a2a20a@chemo.org.uk>

On 2020-06-11 15:59, Ana Marija wrote:
> yes all in one plot.
> So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> am comparing per CHR
> so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> On the end x-axis would have two strikes of Pold and Pnew (different
> colors) per one chromosome, and CHR would go from 1 to 22
> 


ggplot( data = tmp.tidy) +
geom_point( aes(
             y = BP,
             x = CHR,
             color=key) )

?


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 22:41:41 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 15:41:41 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <f5bbf6217dc3af9d5b83bcea68a2a20a@chemo.org.uk>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
 <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
 <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>
 <f5bbf6217dc3af9d5b83bcea68a2a20a@chemo.org.uk>
Message-ID: <CAF9-5jNkXvuBabj8Ep9cu25R4w-mdvct=hWPniNChLuA87mb_Q@mail.gmail.com>

Hello,

I tried your code and this is what I got

I really need two groups side by side shown per chromosome as it is here:
https://imgur.com/a/pj40c
on the image there are 4 groups I do have only two

On Thu, Jun 11, 2020 at 11:52 AM <cpolwart at chemo.org.uk> wrote:
>
> On 2020-06-11 15:59, Ana Marija wrote:
> > yes all in one plot.
> > So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> > am comparing per CHR
> > so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> > On the end x-axis would have two strikes of Pold and Pnew (different
> > colors) per one chromosome, and CHR would go from 1 to 22
> >
>
>
> ggplot( data = tmp.tidy) +
> geom_point( aes(
>              y = BP,
>              x = CHR,
>              color=key) )
>
> ?

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 23:26:49 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 16:26:49 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <eb1a2f83-fc61-4df9-99c3-afc620b15b59@email.android.com>
References: <CAF9-5jNkXvuBabj8Ep9cu25R4w-mdvct=hWPniNChLuA87mb_Q@mail.gmail.com>
 <eb1a2f83-fc61-4df9-99c3-afc620b15b59@email.android.com>
Message-ID: <CAF9-5jPG855OJZx7PmE204vi4awWBCjR6c5rV57-dKmKVho_eA@mail.gmail.com>

I tried it,
ggplot( data = tmp.tidy) +geom_point( aes(y = BP,x = CHR,color=key)
,position = "jitter" )
I got the attached

On Thu, Jun 11, 2020 at 4:18 PM <cpolwart at chemo.org.uk> wrote:
>
> Try adding
> position = "jitter" to the geom_point(...
>
>
>
> On 11 Jun 2020 21:41, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I tried your code and this is what I got
>
> I really need two groups side by side shown per chromosome as it is here:
> https://imgur.com/a/pj40c
> on the image there are 4 groups I do have only two
>
> On Thu, Jun 11, 2020 at 11:52 AM <cpolwart at chemo.org.uk> wrote:
> >
> > On 2020-06-11 15:59, Ana Marija wrote:
> > > yes all in one plot.
> > > So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> > > am comparing per CHR
> > > so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> > > On the end x-axis would have two strikes of Pold and Pnew (different
> > > colors) per one chromosome, and CHR would go from 1 to 22
> > >
> >
> >
> > ggplot( data = tmp.tidy) +
> > geom_point( aes(
> >              y = BP,
> >              x = CHR,
> >              color=key) )
> >
> > ?
>
>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 23:50:31 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 16:50:31 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <7759e2a5-2d68-4c48-933a-0b853a4e9e38@email.android.com>
References: <CAF9-5jPG855OJZx7PmE204vi4awWBCjR6c5rV57-dKmKVho_eA@mail.gmail.com>
 <7759e2a5-2d68-4c48-933a-0b853a4e9e38@email.android.com>
Message-ID: <CAF9-5jMb=9ugeZC_isVL1p0TF-BPJwPWYQMXb4YVTH6-3=axSA@mail.gmail.com>

Thank you so much it is getting better (see attach) when I do:
ggplot( data = tmp.tidy) +geom_point( aes(y = -log10(value),x =
CHR,color=key) ,position = "jitter", size=0.5 )

is there is a way to have separation between every chromosome shown
better and also every number of chromosome shown on the x-axis?

On Thu, Jun 11, 2020 at 4:39 PM <cpolwart at chemo.org.uk> wrote:
>
> Your dots are too big!
>
> Add
>
> geom_points(... , size = 1
>
> May need to play... 0.5 or 0.1?
>
> On 11 Jun 2020 22:26, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> I tried it,
> ggplot( data = tmp.tidy) +geom_point( aes(y = BP,x = CHR,color=key)
> ,position = "jitter" )
> I got the attached
>
> On Thu, Jun 11, 2020 at 4:18 PM <cpolwart at chemo.org.uk> wrote:
> >
> > Try adding
> > position = "jitter" to the geom_point(...
> >
> >
> >
> > On 11 Jun 2020 21:41, Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I tried your code and this is what I got
> >
> > I really need two groups side by side shown per chromosome as it is here:
> > https://imgur.com/a/pj40c
> > on the image there are 4 groups I do have only two
> >
> > On Thu, Jun 11, 2020 at 11:52 AM <cpolwart at chemo.org.uk> wrote:
> > >
> > > On 2020-06-11 15:59, Ana Marija wrote:
> > > > yes all in one plot.
> > > > So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> > > > am comparing per CHR
> > > > so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> > > > On the end x-axis would have two strikes of Pold and Pnew (different
> > > > colors) per one chromosome, and CHR would go from 1 to 22
> > > >
> > >
> > >
> > > ggplot( data = tmp.tidy) +
> > > geom_point( aes(
> > >              y = BP,
> > >              x = CHR,
> > >              color=key) )
> > >
> > > ?
> >
> >
>
>

From @purd|e@@ @end|ng |rom gm@||@com  Fri Jun 12 02:14:29 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 12 Jun 2020 12:14:29 +1200
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
Message-ID: <CAB8pepwWxvw_RDQydtoBtdBu8k5NpudfKHC_Af5P5X2Jkkui3w@mail.gmail.com>

> solving Linear Programming Problems with O(L^1.5)
> computational complexity

I'm not an expert on this topic.
However, a quick glance at the topic suggests that these sorts of
algorithms are usually exponential in "n", here the number of
variables/dimensions.
Apparently, "L" is the number of input bits.

Your notation suggests your algorithm is dependent on the number input
bits only, and is otherwise constant in the number of
variables/dimensions.
So, we can solve an LP with hundreds of millions of variables,
near-instantaneously...?


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Jun 12 08:45:15 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 12 Jun 2020 08:45:15 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <20200611144851.GB162277@posteo.no>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <20200611144851.GB162277@posteo.no>
Message-ID: <CAMk+s2R087CY8BZnuBCy1Y9PtxQVG90fvVue5txruft6p+byEA@mail.gmail.com>

Thank you. It worked. Case closed

On Thu, 11 Jun 2020, 16:48 Rasmus Liland, <jral at posteo.no> wrote:

> On 2020-06-10 10:20 +0200, Luigi Marongiu wrote:
> > I have been trying to convert European
> > short dates formatted as dd/mm/yy into the
> > ISO 8601 but the function as.Dates
> > interprets them as American ones
> > (mm/dd/yy)
>
> Dear Luigi,
>
> ?strptime says:
>
>         ?%D? Date format such as ?%m/%d/%y?: the C99 standard says it
>              should be that exact format (but not all OSes comply).
>
> as.Date(oriDates, format="%d/%m/%y") works
> fine for me here on the Linux laptop ...
>
> You could also try to work on the strings
> themselves to convert them to ISO format,
> like:
>
>         oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
>                      "27/01/20", "28/01/20", "29/01/20", "30/01/20",
>                      "31/01/20", "01/02/20", "02/02/20", "03/02/20",
>                      "04/02/20", "05/02/20", "06/02/20", "07/02/20")
>         d <- t(as.data.frame(strsplit(oriDates, "/")))
>         dimnames(d) <- list(NULL, c("d", "m", "y"))
>         u <- unique(d[,"y"])
>         millenia <- "20"
>         if (length(u)==1 & u==millenia) {
>           Dates <- paste0(millenia, d[,"y"], "-",
>                           d[,"m"], "-", d[,"d"])
>           Dates <- as.Date(Dates)
>         } else {
>           Dates <- "'Allo 'allo ... error, error ... more complicated
> formatting is required to digest those dates ..."
>         }
>         print(Dates)
>
> Best,
> Rasmus
>

	[[alternative HTML version deleted]]


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Fri Jun 12 11:52:28 2020
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Fri, 12 Jun 2020 05:52:28 -0400
Subject: [R] function to return plots
Message-ID: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>


I want to write a function that will return lattice plots.  This simple
function output a list of two plots.  These plots can be
individually shown on the console.  But I am unable to put them on two
panels of a single plot.

What changes do I need to make to this function?

Thanks,
Naresh

library(lattice)

getPlots <- function(){
    x <- rnorm(1000)
    plt1 <- histogram(x)
    plt2 <- bwplot(x)
    list(plt1, plt2)
}

plot.list <- getPlots()

plot.list[1] #Plots graph
plot.list[2] #Plots graph

plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message

## Plotting outside function works
x <- rnorm(1000)
plt1 <- histogram(x)
plt2 <- bwplot(x)
plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)


From drj|m|emon @end|ng |rom gm@||@com  Fri Jun 12 12:50:41 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 12 Jun 2020 20:50:41 +1000
Subject: [R] function to return plots
In-Reply-To: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
References: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
Message-ID: <CA+8X3fUBcjxW9Pj=E9Wgi_kSKJ3Vqo1Xw-cd59TU94Haamiaaw@mail.gmail.com>

Hi Naresh,
The somewhat obscure syntax of lattice.

print(plot.list[[1]])
print(plot.list[[2]])

Jim

On Fri, Jun 12, 2020 at 7:53 PM Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
>
>
> I want to write a function that will return lattice plots.  This simple
> function output a list of two plots.  These plots can be
> individually shown on the console.  But I am unable to put them on two
> panels of a single plot.
>
> What changes do I need to make to this function?
>
> Thanks,
> Naresh
>
> library(lattice)
>
> getPlots <- function(){
>     x <- rnorm(1000)
>     plt1 <- histogram(x)
>     plt2 <- bwplot(x)
>     list(plt1, plt2)
> }
>
> plot.list <- getPlots()
>
> plot.list[1] #Plots graph
> plot.list[2] #Plots graph
>
> plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
> plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message
>
> ## Plotting outside function works
> x <- rnorm(1000)
> plt1 <- histogram(x)
> plt2 <- bwplot(x)
> plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
> plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun 12 13:08:18 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 12 Jun 2020 12:08:18 +0100
Subject: [R] function to return plots
In-Reply-To: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
References: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
Message-ID: <2283fcb4-e247-f4cf-4f4e-f6ff2c700629@sapo.pt>

Hello,

plot.list is a list, try '[[' to access its members.
('[' returns sub-lists.)


plot(plot.list[[1]], position = c(0, 0, 1, 0.5), more = TRUE) #Works
plot(plot.list[[2]], position = c(0, 0.5, 1, 1), more = FALSE) #Works


Hope this helps,

Rui Barradas

?s 10:52 de 12/06/20, Naresh Gurbuxani escreveu:
> 
> I want to write a function that will return lattice plots.  This simple
> function output a list of two plots.  These plots can be
> individually shown on the console.  But I am unable to put them on two
> panels of a single plot.
> 
> What changes do I need to make to this function?
> 
> Thanks,
> Naresh
> 
> library(lattice)
> 
> getPlots <- function(){
>      x <- rnorm(1000)
>      plt1 <- histogram(x)
>      plt2 <- bwplot(x)
>      list(plt1, plt2)
> }
> 
> plot.list <- getPlots()
> 
> plot.list[1] #Plots graph
> plot.list[2] #Plots graph
> 
> plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
> plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message
> 
> ## Plotting outside function works
> x <- rnorm(1000)
> plt1 <- histogram(x)
> plt2 <- bwplot(x)
> plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
> plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Fri Jun 12 14:37:08 2020
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Fri, 12 Jun 2020 12:37:08 +0000
Subject: [R] function to return plots
In-Reply-To: <2283fcb4-e247-f4cf-4f4e-f6ff2c700629@sapo.pt>
References: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>,
 <2283fcb4-e247-f4cf-4f4e-f6ff2c700629@sapo.pt>
Message-ID: <BL0PR01MB4036C3868E1E84C2BD210DF8FA810@BL0PR01MB4036.prod.exchangelabs.com>

Thanks for your quick response. ?It works as I wanted.?



From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Friday, June 12, 2020 7:08 AM
To: Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>; r-help at r-project.org <r-help at R-project.org>
Subject: Re: [R] function to return plots 
?
Hello,

plot.list is a list, try '[[' to access its members.
('[' returns sub-lists.)


plot(plot.list[[1]], position = c(0, 0, 1, 0.5), more = TRUE) #Works
plot(plot.list[[2]], position = c(0, 0.5, 1, 1), more = FALSE) #Works


Hope this helps,

Rui Barradas

?s 10:52 de 12/06/20, Naresh Gurbuxani escreveu:
> 
> I want to write a function that will return lattice plots.? This simple
> function output a list of two plots.? These plots can be
> individually shown on the console.? But I am unable to put them on two
> panels of a single plot.
> 
> What changes do I need to make to this function?
> 
> Thanks,
> Naresh
> 
> library(lattice)
> 
> getPlots <- function(){
>????? x <- rnorm(1000)
>????? plt1 <- histogram(x)
>????? plt2 <- bwplot(x)
>????? list(plt1, plt2)
> }
> 
> plot.list <- getPlots()
> 
> plot.list[1] #Plots graph
> plot.list[2] #Plots graph
> 
> plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
> plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message
> 
> ## Plotting outside function works
> x <- rnorm(1000)
> plt1 <- histogram(x)
> plt2 <- bwplot(x)
> plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
> plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From @@ud|@@d|q @end|ng |rom gm@||@com  Fri Jun 12 16:18:05 2020
From: @@ud|@@d|q @end|ng |rom gm@||@com (Saudi Sadiq)
Date: Fri, 12 Jun 2020 16:18:05 +0200
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
 <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
Message-ID: <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>

Hi Jim,

So many thanks for your reply. I actually made a mistake in presenting the
problem; I should have clarified that the 1-10 linear scale questions went
as: 10 most humorous/closest to Egyptian culture and 1 the least. Also, I
should have attached some examples so the participant issue could be clear.
Here is attached the dataset (if there is no problem or I am not going
against the rules of the R-help group).

Actually, I wanted better to be the only dependent factor and asking
participants 'which subtitle is better?' could be enough, but I wanted to
have detailed information of why a subtitle is better by asking
participants specific questions (regarding which subtitle is more humorous
and closer to Egyptian culture). Most of the time, the total of the hum +
cul = better, but sometimes it is not (e.g. the sum for subtitle EA could
be bigger than for SA, but the participant prefers SA in the better
column).

The WF (*watched first*) is the mode via which participants watched the two
subtitles; some participants watched the SA subtitle first and other
watched the EA first.

Does this make sense?

All the best

On Thu, 11 Jun 2020 at 05:24, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Saudi,
> I can only make a guess, but that is that a variable having a unique
> value for each participant has been read in as a factor. I assume that
> "better" is some combination of "hum" and "cul" and exactly what is
> WF?
>
> Jim
>
> On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:
> >
> > Dear Sir/Madam,
> >
> > Hope everyone is safe and sound. I appreciate your help a lot.
> >
> > I am evaluating two Arabic subtitles of a humorous English scene and
> asked
> > 263 participants (part) to evaluate the two subtitles (named Standard
> > Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them
> to
> > rank the two subtitles in terms of how much each subtitle is
> >
> > 2) more humorous (hum),
> >
> > 5) closer to Egyptian culture (cul)
> >
> >
> >
> > The questionnaire contained two 1-10 linear scale questions regarding
> the 2
> > points clarified, with 1 meaning the most humorous and closest to
> Egyptian
> > culture, and 1 meaning the least humorous and furthest from Egyptian
> > culture. Also, the questionnaire had a general multiple-choice question
> > regarding which subtitle is better in general (better). General
> information
> > about the participants were also collected concerning gender (categorical
> > factor), age (numeric factor) and education (categorical factor).
> >
> > Two versions of the questionnaire were relied on: one showing the ?SA
> > subtitle first? and another showing the ?EA subtitle first?. Nearly half
> > the participants answered the first and nearly half answered the latter.
> >
> > I am focusing on which social factor/s lead/s the participants to
> evaluate
> > one of the two subtitles as generally better and which subtitle is more
> > humorous and closer to Egyptian culture. Each of these points alone can
> be
> > the dependent factor, but the results altogether can be linked.
> >
> > I thought that mixed effects analyses would clarify the picture and
> answer
> > the research questions (which  factor/s lead/s participants to favour a
> > subtitle over another?) and, so,  tried the lme4 package in R and ran
> many
> > models but all the codes I have used are not working.
> >
> > I ran the following codes, which yielded Error messages, like:
> >
> > model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> > data=sub_data)
> >
> > Error: number of levels of each grouping factor must be < number of
> > observations (problems: part)
> >
> >
> >
> > Model2 <- glmer (better ~ gender + age + education + WF + (1 | part),
> data
> > = sub_data, family='binomial')
> >
> > Error in mkRespMod(fr, family = family) :
> >
> >   response must be numeric or factor
> >
> >
> >
> > Model3 <- glmer (better ~ age + gender + education + WF + (1 | part),
> data
> > = sub_data, family='binomial',
> control=glmerControl(optimizer=c("bobyqa")))
> >
> > Error in mkRespMod(fr, family = family) :
> >
> >   response must be numeric or factor
> >
> >
> >
> > Why does the model crash? Does the problem lie in the random factor part
> (which
> > is a code for participants)? Or is it something related to the mixed
> > effects analysis?
> >
> > Best
> > Saudi Sadiq
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Saudi Sadiq,

Lecturer, Minia University, Egypt

Academia <http://york.academia.edu/SaudiSadiq>, Reserachgate
<https://www.researchgate.net/profile/Saudi_Sadiq>, Google Scholar
<https://scholar.google.co.uk/citations?user=h0latzcAAAAJ&hl=en>, Publons
<https://publons.com/researcher/2950905/saudi-sadiq/>

Certified Translator by (Egyta) <https://www.egyta.com/>

Associate Fellow of the Higher Education Academy, UK
<https://www.heacademy.ac.uk/>

From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 12 16:28:17 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Jun 2020 07:28:17 -0700
Subject: [R] Update of addScales package with vignette on CRAN
Message-ID: <CAGxFJbTNzDC6UZRNsbdp8deOohwKLAxtiBBs-=J3LHMToyFoTA@mail.gmail.com>

I have added a couple of what I would like to think are worthwhile features
to my addScales package. More important, also a short vignette. While this
is part of the lattice graphics ecosystem, have a look at the vignette as
it may have ideas that can be adapted/improved on in other graphics
paradigms (e.g. ggplot).

Apologies for the noise -- just trying to promote better data graphics.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 12 16:30:44 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Jun 2020 07:30:44 -0700
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
 <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
 <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>
Message-ID: <CAGxFJbSsa35p6KY4eF7eWZ+6XE6y+JRFSmkTHMt9QfsmOhz7CQ@mail.gmail.com>

Questions on mixed models methodology, which this is, should be posted on
the r-sig-mixed-models list, not here.
That's where both the interest and expertise are.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 12, 2020 at 7:19 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:

> Hi Jim,
>
> So many thanks for your reply. I actually made a mistake in presenting the
> problem; I should have clarified that the 1-10 linear scale questions went
> as: 10 most humorous/closest to Egyptian culture and 1 the least. Also, I
> should have attached some examples so the participant issue could be clear.
> Here is attached the dataset (if there is no problem or I am not going
> against the rules of the R-help group).
>
> Actually, I wanted better to be the only dependent factor and asking
> participants 'which subtitle is better?' could be enough, but I wanted to
> have detailed information of why a subtitle is better by asking
> participants specific questions (regarding which subtitle is more humorous
> and closer to Egyptian culture). Most of the time, the total of the hum +
> cul = better, but sometimes it is not (e.g. the sum for subtitle EA could
> be bigger than for SA, but the participant prefers SA in the better
> column).
>
> The WF (*watched first*) is the mode via which participants watched the two
> subtitles; some participants watched the SA subtitle first and other
> watched the EA first.
>
> Does this make sense?
>
> All the best
>
> On Thu, 11 Jun 2020 at 05:24, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Saudi,
> > I can only make a guess, but that is that a variable having a unique
> > value for each participant has been read in as a factor. I assume that
> > "better" is some combination of "hum" and "cul" and exactly what is
> > WF?
> >
> > Jim
> >
> > On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com>
> wrote:
> > >
> > > Dear Sir/Madam,
> > >
> > > Hope everyone is safe and sound. I appreciate your help a lot.
> > >
> > > I am evaluating two Arabic subtitles of a humorous English scene and
> > asked
> > > 263 participants (part) to evaluate the two subtitles (named Standard
> > > Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked
> them
> > to
> > > rank the two subtitles in terms of how much each subtitle is
> > >
> > > 2) more humorous (hum),
> > >
> > > 5) closer to Egyptian culture (cul)
> > >
> > >
> > >
> > > The questionnaire contained two 1-10 linear scale questions regarding
> > the 2
> > > points clarified, with 1 meaning the most humorous and closest to
> > Egyptian
> > > culture, and 1 meaning the least humorous and furthest from Egyptian
> > > culture. Also, the questionnaire had a general multiple-choice question
> > > regarding which subtitle is better in general (better). General
> > information
> > > about the participants were also collected concerning gender
> (categorical
> > > factor), age (numeric factor) and education (categorical factor).
> > >
> > > Two versions of the questionnaire were relied on: one showing the ?SA
> > > subtitle first? and another showing the ?EA subtitle first?. Nearly
> half
> > > the participants answered the first and nearly half answered the
> latter.
> > >
> > > I am focusing on which social factor/s lead/s the participants to
> > evaluate
> > > one of the two subtitles as generally better and which subtitle is more
> > > humorous and closer to Egyptian culture. Each of these points alone can
> > be
> > > the dependent factor, but the results altogether can be linked.
> > >
> > > I thought that mixed effects analyses would clarify the picture and
> > answer
> > > the research questions (which  factor/s lead/s participants to favour a
> > > subtitle over another?) and, so,  tried the lme4 package in R and ran
> > many
> > > models but all the codes I have used are not working.
> > >
> > > I ran the following codes, which yielded Error messages, like:
> > >
> > > model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> > > data=sub_data)
> > >
> > > Error: number of levels of each grouping factor must be < number of
> > > observations (problems: part)
> > >
> > >
> > >
> > > Model2 <- glmer (better ~ gender + age + education + WF + (1 | part),
> > data
> > > = sub_data, family='binomial')
> > >
> > > Error in mkRespMod(fr, family = family) :
> > >
> > >   response must be numeric or factor
> > >
> > >
> > >
> > > Model3 <- glmer (better ~ age + gender + education + WF + (1 | part),
> > data
> > > = sub_data, family='binomial',
> > control=glmerControl(optimizer=c("bobyqa")))
> > >
> > > Error in mkRespMod(fr, family = family) :
> > >
> > >   response must be numeric or factor
> > >
> > >
> > >
> > > Why does the model crash? Does the problem lie in the random factor
> part
> > (which
> > > is a code for participants)? Or is it something related to the mixed
> > > effects analysis?
> > >
> > > Best
> > > Saudi Sadiq
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Saudi Sadiq,
>
> Lecturer, Minia University, Egypt
>
> Academia <http://york.academia.edu/SaudiSadiq>, Reserachgate
> <https://www.researchgate.net/profile/Saudi_Sadiq>, Google Scholar
> <https://scholar.google.co.uk/citations?user=h0latzcAAAAJ&hl=en>, Publons
> <https://publons.com/researcher/2950905/saudi-sadiq/>
>
> Certified Translator by (Egyta) <https://www.egyta.com/>
>
> Associate Fellow of the Higher Education Academy, UK
> <https://www.heacademy.ac.uk/>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Jun 12 23:34:44 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 12 Jun 2020 21:34:44 +0000
Subject: [R] Obtaining p values from t-test run with a by function
Message-ID: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>

Colleagues,
I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.

An annotated repeatable example (including data) can be found below.
Thank you,
John


# Test data
mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
           2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
           WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
           82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))

cat("This is what mydata looks like\n")
mydata

result <- by(mydata$WtBaseline,mydata$Group,t.test)
cat("Student's t-test run using by command\n")
cat("Result has results for both groups, EPA and P\n")
result

cat("I can isolate the collective results for group EPA\n")
result[1]
cat("I can isolate the collective results for group P\n")
result[2]

cat("I cant get the p-values for the gruops")
result[1]$p.value
result[2]$p.value

cat("When run without by function, one can get the p value\n")
xxx <- t.test(WtBaseline~Group,data=mydata)
cat("t-test run without by fundtion\n")
xxx
cat("p value isolated from t-test run without by function\n")
xxx$p.value


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From S@E|||@on @end|ng |rom LGCGroup@com  Sat Jun 13 00:10:28 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Fri, 12 Jun 2020 22:10:28 +0000
Subject: [R] Obtaining p values from t-test run with a by function
In-Reply-To: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <f76d5ac5a608499e8148336e9551d589@GBDCVPEXC08.corp.lgc-group.com>

Define a wrapper function for the t test that only returns the p-value?

by(mydata$WtBaseline,mydata$Group, function(...) t.test(...)$p.value)

S Ellison
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Sorkin, John [jsorkin at som.umaryland.edu]
Sent: 12 June 2020 22:34
To: r-help at r-project.org (r-help at r-project.org)
Subject: [R] Obtaining p values from t-test run with a by function

===============
 EXTERNAL EMAIL
===============

Colleagues,
I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.

An annotated repeatable example (including data) can be found below.
Thank you,
John


# Test data
mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
           2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
           WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
           82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))

cat("This is what mydata looks like\n")
mydata

result <- by(mydata$WtBaseline,mydata$Group,t.test)
cat("Student's t-test run using by command\n")
cat("Result has results for both groups, EPA and P\n")
result

cat("I can isolate the collective results for group EPA\n")
result[1]
cat("I can isolate the collective results for group P\n")
result[2]

cat("I cant get the p-values for the gruops")
result[1]$p.value
result[2]$p.value

cat("When run without by function, one can get the p value\n")
xxx <- t.test(WtBaseline~Group,data=mydata)
cat("t-test run without by fundtion\n")
xxx
cat("p value isolated from t-test run without by function\n")
xxx$p.value


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


==============================================================================================
WARNING - EXTERNAL: This email originated from outside of LGC. Do not click any links or open any attachments
unless you trust the sender and know that the content is safe
==============================================================================================


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sat Jun 13 00:20:04 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 12 Jun 2020 18:20:04 -0400
Subject: [R] Obtaining p values from t-test run with a by function
In-Reply-To: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <CAM_vju=mkUdwONAYgk=fK4Oy2XXs402rGzOnRojv7hi1xsNjFQ@mail.gmail.com>

Where you have

result[1]$p.value
result[2]$p.value

You need

result[[1]]$p.value
result[[2]]$p.value

to get the first component of the list.

Sarah

On Fri, Jun 12, 2020 at 5:35 PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> Colleagues,
> I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.
>
> An annotated repeatable example (including data) can be found below.
> Thank you,
> John
>
>
> # Test data
> mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
>            2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
>            WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
>            82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))
>
> cat("This is what mydata looks like\n")
> mydata
>
> result <- by(mydata$WtBaseline,mydata$Group,t.test)
> cat("Student's t-test run using by command\n")
> cat("Result has results for both groups, EPA and P\n")
> result
>
> cat("I can isolate the collective results for group EPA\n")
> result[1]
> cat("I can isolate the collective results for group P\n")
> result[2]
>
> cat("I cant get the p-values for the gruops")
> result[1]$p.value
> result[2]$p.value
>
> cat("When run without by function, one can get the p value\n")
> xxx <- t.test(WtBaseline~Group,data=mydata)
> cat("t-test run without by fundtion\n")
> xxx
> cat("p value isolated from t-test run without by function\n")
> xxx$p.value
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From jr@| @end|ng |rom po@teo@no  Sat Jun 13 01:54:17 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 13 Jun 2020 01:54:17 +0200
Subject: [R] Creating one df from 85 df present in a list
In-Reply-To: <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>
References: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
 <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>
Message-ID: <20200612235417.GB723678@posteo.no>

On 2020-06-10 13:14 -0700, Bert Gunter wrote:
> On Wed, Jun 10, 2020 at 11:48 AM Alejandro Ureta wrote:
> > 
> > hi, I am trying to fuse (cbind, merge... 
> > NOT rbind) several dataframes with 
> > different numbers of rows, all df 
> > included in a list, and using the code 
> > extract shown below. The function merge() 
> > works well with two df but not more than 
> > two...I have 85 dataframes to join in 
> > this way (85 df in the list)....could you 
> > please let me know how to get all 85 df 
> > merged ?,,,,, thanks
> >
> > fusion_de_tablas = merge(red_tablas_por_punto[["1 - Bv.Artigas y la Rambla
> > (Terminal CUTCSA)"]],
> > red_tablas_por_punto[["10 - Avenida Mill?n 2515 (Hospital Vilardeb?)"]],
> > red_tablas_por_punto[["100 - Fauquet 6358 (Hospital Saint Bois)"]],
> > by= 'toma_de_muestras', all = T )
> 
> ?do.call  -- takes a list of arguments to a function
> ... as in
> do.call(merge, yourlist)  ## or similar perhaps

Dear Alejandro,

it would be easier to help you if you 
provided some example of how fusion_de_tablas 
looks like.  

Here is a small example on uniting some odd 
sized dataframes with some common and some 
differently named columns. 

	red_tablas_por_punto <-
	  list(
	    "1 - Bv.Artigas y la Rambla (Terminal CUTCSA)" =
	      data.frame("a"=1:3,
	                 "b"=4:6,
	                 "c"=4:6,
	                 'toma_de_muestras'=1),
	    "10 - Avenida Mill?n 2515 (Hospital Vilardeb?)" =
	      data.frame("d"=4:8,
	                 "b"=8:12,
	                 'toma_de_muestras'=7),
	    "100 - Fauquet 6358 (Hospital Saint Bois)" =
	      data.frame("e"=100:101,
	                 "a"=85:86,
	                 'toma_de_muestras'=4)
	  )
	unified.df <- lapply(names(red_tablas_por_punto),
	  function(tabla, cn) {
	    x <- red_tablas_por_punto[[tabla]]
	    x[,cn[!(cn %in% colnames(x))]] <- NA
	    x <- x[,cn]
	    x$tabla <- tabla
	    return(x)
	  }, cn=unique(unlist(lapply(red_tablas_por_punto, colnames))))
	unified.df <- do.call(rbind, unified.df)
	unified.df

which yields

	    a  b  c toma_de_muestras  d   e                                         tabla
	1   1  4  4                1 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	2   2  5  5                1 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	3   3  6  6                1 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	4  NA  8 NA                7  4  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	5  NA  9 NA                7  5  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	6  NA 10 NA                7  6  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	7  NA 11 NA                7  7  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	8  NA 12 NA                7  8  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	9  85 NA NA                4 NA 100      100 - Fauquet 6358 (Hospital Saint Bois)
	10 86 NA NA                4 NA 101      100 - Fauquet 6358 (Hospital Saint Bois)

I also found that [1] you could use merge 
like you tried with Reduce, like 

	Reduce(function(x, y)
	  merge(x, y, by='toma_de_muestras', all=T),
	  red_tablas_por_punto)

which yields

	   toma_de_muestras a.x b.x  c  d b.y   e a.y
	1             10001   1   4  4 NA  NA  NA  NA
	2             10002   2   5  5 NA  NA  NA  NA
	3             10003   3   6  6 NA  NA  NA  NA
	4             10004  NA  NA NA  4   8  NA  NA
	5             10005  NA  NA NA  5   9  NA  NA
	6             10006  NA  NA NA  6  10  NA  NA
	7             10007  NA  NA NA  7  11  NA  NA
	8             10008  NA  NA NA  8  12  NA  NA
	9             10009  NA  NA NA NA  NA 100  85
	10            10010  NA  NA NA NA  NA 101  86

where the semi-common ?a? column does not 
become unified ...  thus, I like my initial 
step-by-step apply-based solution better ... 

Best,
Rasmus

[1] https://stackoverflow.com/questions/22644780/merging-multiple-csv-files-in-r-using-do-call

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200613/f877bdec/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Sat Jun 13 02:25:08 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 13 Jun 2020 02:25:08 +0200
Subject: [R] Creating one df from 85 df present in a list
In-Reply-To: <20200612235417.GB723678@posteo.no>
References: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
 <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>
 <20200612235417.GB723678@posteo.no>
Message-ID: <20200613002508.GC723678@posteo.no>

On 2020-06-13 01:54 +0200, Rasmus Liland wrote:
> Dear Alejandro,

Sorry, I programmed and wrote that email at 
the same time, changed the ?toma_de_muestras? 
perhaps other things, then continued 
programming, thus this might make more 
sense ...

Firstly, it would be easier to help you if 
you provided some example of how 
fusion_de_tablas looks like.

In this first example, I create a small list 
of oddly shaped data.frames which might look 
like your 85-element-long list.  Then, 
determining the unique colnames.  Lastly, 
applying my way through the list again to 
fill in N/A in the columns not there, so the 
do.call function recieves what it expects ... 

	red_tablas_por_punto <-
	  list(
	    "1 - Bv.Artigas y la Rambla (Terminal CUTCSA)" =
	      data.frame("a"=1:3,
	                 "b"=4:6,
	                 "c"=4:6,
	                 'toma_de_muestras'=10001:10003),
	    "10 - Avenida Mill?n 2515 (Hospital Vilardeb?)" =
	      data.frame("d"=4:8,
	                 "b"=8:12,
	                 'toma_de_muestras'=10004:10008),
	    "100 - Fauquet 6358 (Hospital Saint Bois)" =
	      data.frame("e"=100:101,
	                 "a"=85:86,
	                 'toma_de_muestras'=10009:10010)
	  )
	unified.df <- lapply(names(red_tablas_por_punto),
	  function(tabla, cn) {
	    x <- red_tablas_por_punto[[tabla]]
	    x[,cn[!(cn %in% colnames(x))]] <- NA
	    x <- x[,cn]
	    x$tabla <- tabla
	    return(x)
	  }, cn=unique(unlist(lapply(red_tablas_por_punto, colnames))))
	unified.df <- do.call(rbind, unified.df)
	unified.df

yields this:

	    a  b  c toma_de_muestras  d   e                                         tabla
	1   1  4  4            10001 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	2   2  5  5            10002 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	3   3  6  6            10003 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	4  NA  8 NA            10004  4  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	5  NA  9 NA            10005  5  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	6  NA 10 NA            10006  6  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	7  NA 11 NA            10007  7  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	8  NA 12 NA            10008  8  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	9  85 NA NA            10009 NA 100      100 - Fauquet 6358 (Hospital Saint Bois)
	10 86 NA NA            10010 NA 101      100 - Fauquet 6358 (Hospital Saint Bois)

... right, so you could also use merge with 
Reduce like in that stackoverflow answer [1], 
which might have been what you were looking 
for anyway:

	Reduce(function(x, y)
	  merge(x, y, by='toma_de_muestras', all=T),
	  red_tablas_por_punto)

yields this:

	   toma_de_muestras a.x b.x  c  d b.y   e a.y
	1             10001   1   4  4 NA  NA  NA  NA
	2             10002   2   5  5 NA  NA  NA  NA
	3             10003   3   6  6 NA  NA  NA  NA
	4             10004  NA  NA NA  4   8  NA  NA
	5             10005  NA  NA NA  5   9  NA  NA
	6             10006  NA  NA NA  6  10  NA  NA
	7             10007  NA  NA NA  7  11  NA  NA
	8             10008  NA  NA NA  8  12  NA  NA
	9             10009  NA  NA NA NA  NA 100  85
	10            10010  NA  NA NA NA  NA 101  86

Best,
Rasmus

[1] https://stackoverflow.com/questions/22644780/merging-multiple-csv-files-in-r-using-do-call

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200613/4defe719/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 02:46:02 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 19:46:02 -0500
Subject: [R] if else statement adjustemtn
Message-ID: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>

Hello

I have a data frame like this:

> head(b)
       FID   IID FLASER PLASER
1: fam1000 G1000      1      1
2: fam1001 G1001      1      1
3: fam1003 G1003      1      2
4: fam1005 G1005      1      1
5: fam1009 G1009      1      1
6: fam1052 G1052      1      1
...

> table(b$PLASER,b$FLASER, exclude = NULL)

         1   2   3 <NA>
  1    836  14   0    0
  2    691  70  43    2
  3      2   7  21    0
  <NA>   4   1   0    7

I am trying to make a new column "pheno" so that I reduce the number of NAs

right now I am doing:

> b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> table(b$pheno, exclude = NULL)

   1    2 <NA>
 859  828   11

I would like to reduce this number of NAs to be 7
so I would like to have in "pheno column"
7 NAs
825 2s (825=691+14+70+7+43)
and the rest would be 1s (866=1698-7-825)

How can I change the above command to get these numbers?

Thanks
Ana


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 03:06:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 11:06:45 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
Message-ID: <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>

Hi Ana,
>From your desired result, it looks like those two NA values in PLASER
are the ones you want to drop.
If so, try this:

b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |
 is.na(b$PLASER) & b$FLASER == 2,2,1)

and if I have it the wrong way round, swap FLASER and PLASER in the
bit I have added.

Jim

On Sat, Jun 13, 2020 at 10:46 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello
>
> I have a data frame like this:
>
> > head(b)
>        FID   IID FLASER PLASER
> 1: fam1000 G1000      1      1
> 2: fam1001 G1001      1      1
> 3: fam1003 G1003      1      2
> 4: fam1005 G1005      1      1
> 5: fam1009 G1009      1      1
> 6: fam1052 G1052      1      1
> ...
>
> > table(b$PLASER,b$FLASER, exclude = NULL)
>
>          1   2   3 <NA>
>   1    836  14   0    0
>   2    691  70  43    2
>   3      2   7  21    0
>   <NA>   4   1   0    7
>
> I am trying to make a new column "pheno" so that I reduce the number of NAs
>
> right now I am doing:
>
> > b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> > table(b$pheno, exclude = NULL)
>
>    1    2 <NA>
>  859  828   11
>
> I would like to reduce this number of NAs to be 7
> so I would like to have in "pheno column"
> 7 NAs
> 825 2s (825=691+14+70+7+43)
> and the rest would be 1s (866=1698-7-825)
>
> How can I change the above command to get these numbers?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 03:16:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 20:16:03 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
Message-ID: <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>

Hi Jim,

I tried it:
> b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$PLASER) & b$FLASER == 2,2,1)
> table(b$pheno,exclude = NULL)

   1    2 <NA>
 859  828   11
> b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$FLASER) & b$PLASER == 2,2,1)
> table(b$pheno,exclude = NULL)

   1    2 <NA>
 859  828   11

Am I am doing something wrong?

Thanks
Ana

On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> From your desired result, it looks like those two NA values in PLASER
> are the ones you want to drop.
> If so, try this:
>
> b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |
>  is.na(b$PLASER) & b$FLASER == 2,2,1)
>
> and if I have it the wrong way round, swap FLASER and PLASER in the
> bit I have added.
>
> Jim
>
> On Sat, Jun 13, 2020 at 10:46 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello
> >
> > I have a data frame like this:
> >
> > > head(b)
> >        FID   IID FLASER PLASER
> > 1: fam1000 G1000      1      1
> > 2: fam1001 G1001      1      1
> > 3: fam1003 G1003      1      2
> > 4: fam1005 G1005      1      1
> > 5: fam1009 G1009      1      1
> > 6: fam1052 G1052      1      1
> > ...
> >
> > > table(b$PLASER,b$FLASER, exclude = NULL)
> >
> >          1   2   3 <NA>
> >   1    836  14   0    0
> >   2    691  70  43    2
> >   3      2   7  21    0
> >   <NA>   4   1   0    7
> >
> > I am trying to make a new column "pheno" so that I reduce the number of NAs
> >
> > right now I am doing:
> >
> > > b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> > > table(b$pheno, exclude = NULL)
> >
> >    1    2 <NA>
> >  859  828   11
> >
> > I would like to reduce this number of NAs to be 7
> > so I would like to have in "pheno column"
> > 7 NAs
> > 825 2s (825=691+14+70+7+43)
> > and the rest would be 1s (866=1698-7-825)
> >
> > How can I change the above command to get these numbers?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 03:30:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 11:30:45 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
Message-ID: <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>

Obviously my guess was wrong. I thought you wanted to impute the value
of "pheno" from FLASER if PLASER was missing. From just your summary
table, it's hard to guess the distribution of NA values. My guess that
the two undesirable NAs were cases where PLASER was missing and FLASER
was 2. My tactic at this point would be to look at the cases where
either FLASER or PLASER was missing and work out the logic to impute
the two that are giving you trouble.

Jim

On Sat, Jun 13, 2020 at 11:16 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim,
>
> I tried it:
> > b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$PLASER) & b$FLASER == 2,2,1)
> > table(b$pheno,exclude = NULL)
>
>    1    2 <NA>
>  859  828   11
> > b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$FLASER) & b$PLASER == 2,2,1)
> > table(b$pheno,exclude = NULL)
>
>    1    2 <NA>
>  859  828   11
>
> Am I am doing something wrong?
>
> Thanks
> Ana
>
> On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Ana,
> > From your desired result, it looks like those two NA values in PLASER
> > are the ones you want to drop.
> > If so, try this:
> >
> > b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |
> >  is.na(b$PLASER) & b$FLASER == 2,2,1)
> >
> > and if I have it the wrong way round, swap FLASER and PLASER in the
> > bit I have added.
> >
> > Jim
> >
> > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hello
> > >
> > > I have a data frame like this:
> > >
> > > > head(b)
> > >        FID   IID FLASER PLASER
> > > 1: fam1000 G1000      1      1
> > > 2: fam1001 G1001      1      1
> > > 3: fam1003 G1003      1      2
> > > 4: fam1005 G1005      1      1
> > > 5: fam1009 G1009      1      1
> > > 6: fam1052 G1052      1      1
> > > ...
> > >
> > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > >
> > >          1   2   3 <NA>
> > >   1    836  14   0    0
> > >   2    691  70  43    2
> > >   3      2   7  21    0
> > >   <NA>   4   1   0    7
> > >
> > > I am trying to make a new column "pheno" so that I reduce the number of NAs
> > >
> > > right now I am doing:
> > >
> > > > b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> > > > table(b$pheno, exclude = NULL)
> > >
> > >    1    2 <NA>
> > >  859  828   11
> > >
> > > I would like to reduce this number of NAs to be 7
> > > so I would like to have in "pheno column"
> > > 7 NAs
> > > 825 2s (825=691+14+70+7+43)
> > > and the rest would be 1s (866=1698-7-825)
> > >
> > > How can I change the above command to get these numbers?
> > >
> > > Thanks
> > > Ana
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Sat Jun 13 04:28:37 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 13 Jun 2020 04:28:37 +0200
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
Message-ID: <20200613022837.GD723678@posteo.no>

On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > >
> > > I am trying to make a new column 
> > > "pheno" so that I reduce the number 
> > > of NAs
> >
> > it looks like those two NA values in 
> > PLASER are the ones you want to drop.
> 
> From just your summary table, it's hard to 
> guess the distribution of NA values.

Dear Ana,

This small sample

	b <- read.table(text="FLASER;PLASER
	1;2
	;2
	;
	1;
	2;
	2;2
	3;2
	3;3
	1;1", sep=";", header=TRUE)
	
	table(b$PLASER,b$FLASER, exclude = NULL)

yields the same combinations you showed 
earlier:

	       1 2 3 <NA>
	  1    1 0 0    0
	  2    1 1 1    1
	  3    0 0 1    0
	  <NA> 1 1 0    1

If you want to eliminate the four <NA>-based 
combinations completely, this line

	b$pheno <-
	  ifelse(b$PLASER==2 |
	         b$FLASER==2 |
	         is.na(b$PLASER) |
	         is.na(b$PLASER) & b$FLASER %in% 1:2 |
	         is.na(b$FLASER) & b$PLASER == 2,
	         2, 1)
	table(b$pheno, exclude = NULL)

will do it:

	1 2
	2 7

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200613/40a643bb/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 04:50:04 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 21:50:04 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <20200613022837.GD723678@posteo.no>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
Message-ID: <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>

Hi Rasmus,

thank you for getting back to be, the command your provided seems to
add all 11 NAs to 2s
> b$pheno <-
+           ifelse(b$PLASER==2 |
+                  b$FLASER==2 |
+                  is.na(b$PLASER) |
+                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
+                  is.na(b$FLASER) & b$PLASER == 2,
+                  2, 1)
>         table(b$pheno, exclude = NULL)

  1   2
859 839

Once again my desired results is to keep these 7 NAs as NAs
> table(b$PLASER,b$FLASER, exclude = NULL)

         1   2   3 <NA>
  1    836  14   0    0
  2    691  70  43    2
  3      2   7  21    0
  <NA>   4   1   0    7

and have
825 2s (825=691+14+70+7+43)
and the rest would be 1s (866=1698-7-825)

On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
>
> On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > >
> > > > I am trying to make a new column
> > > > "pheno" so that I reduce the number
> > > > of NAs
> > >
> > > it looks like those two NA values in
> > > PLASER are the ones you want to drop.
> >
> > From just your summary table, it's hard to
> > guess the distribution of NA values.
>
> Dear Ana,
>
> This small sample
>
>         b <- read.table(text="FLASER;PLASER
>         1;2
>         ;2
>         ;
>         1;
>         2;
>         2;2
>         3;2
>         3;3
>         1;1", sep=";", header=TRUE)
>
>         table(b$PLASER,b$FLASER, exclude = NULL)
>
> yields the same combinations you showed
> earlier:
>
>                1 2 3 <NA>
>           1    1 0 0    0
>           2    1 1 1    1
>           3    0 0 1    0
>           <NA> 1 1 0    1
>
> If you want to eliminate the four <NA>-based
> combinations completely, this line
>
>         b$pheno <-
>           ifelse(b$PLASER==2 |
>                  b$FLASER==2 |
>                  is.na(b$PLASER) |
>                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
>                  is.na(b$FLASER) & b$PLASER == 2,
>                  2, 1)
>         table(b$pheno, exclude = NULL)
>
> will do it:
>
>         1 2
>         2 7
>
> Best,
> Rasmus
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 05:29:17 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 13:29:17 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
Message-ID: <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>

Since you have only a few troublesome NA values, if you look at them,
or even better, post them:

b[is.na(b$FLASER) | is.na(b$PLASER),]

perhaps we can work out the appropriate logic to get rid of only the
ones you don't want.

Jim

On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Rasmus,
>
> thank you for getting back to be, the command your provided seems to
> add all 11 NAs to 2s
> > b$pheno <-
> +           ifelse(b$PLASER==2 |
> +                  b$FLASER==2 |
> +                  is.na(b$PLASER) |
> +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> +                  is.na(b$FLASER) & b$PLASER == 2,
> +                  2, 1)
> >         table(b$pheno, exclude = NULL)
>
>   1   2
> 859 839
>
> Once again my desired results is to keep these 7 NAs as NAs
> > table(b$PLASER,b$FLASER, exclude = NULL)
>
>          1   2   3 <NA>
>   1    836  14   0    0
>   2    691  70  43    2
>   3      2   7  21    0
>   <NA>   4   1   0    7
>
> and have
> 825 2s (825=691+14+70+7+43)
> and the rest would be 1s (866=1698-7-825)
>
> On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> >
> > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > >
> > > > > I am trying to make a new column
> > > > > "pheno" so that I reduce the number
> > > > > of NAs
> > > >
> > > > it looks like those two NA values in
> > > > PLASER are the ones you want to drop.
> > >
> > > From just your summary table, it's hard to
> > > guess the distribution of NA values.
> >
> > Dear Ana,
> >
> > This small sample
> >
> >         b <- read.table(text="FLASER;PLASER
> >         1;2
> >         ;2
> >         ;
> >         1;
> >         2;
> >         2;2
> >         3;2
> >         3;3
> >         1;1", sep=";", header=TRUE)
> >
> >         table(b$PLASER,b$FLASER, exclude = NULL)
> >
> > yields the same combinations you showed
> > earlier:
> >
> >                1 2 3 <NA>
> >           1    1 0 0    0
> >           2    1 1 1    1
> >           3    0 0 1    0
> >           <NA> 1 1 0    1
> >
> > If you want to eliminate the four <NA>-based
> > combinations completely, this line
> >
> >         b$pheno <-
> >           ifelse(b$PLASER==2 |
> >                  b$FLASER==2 |
> >                  is.na(b$PLASER) |
> >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> >                  is.na(b$FLASER) & b$PLASER == 2,
> >                  2, 1)
> >         table(b$pheno, exclude = NULL)
> >
> > will do it:
> >
> >         1 2
> >         2 7
> >
> > Best,
> > Rasmus
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 05:59:13 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 22:59:13 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
 <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
Message-ID: <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>

Great idea!
Here it is:
> b[is.na(b$FLASER) | is.na(b$PLASER),]
        FID   IID FLASER PLASER pheno
 1: fam1837 G1837      1     NA     2
 2: fam2410 G2410     NA     NA     2
 3: fam2838 G2838     NA      2     2
 4: fam3367 G3367      1     NA     2
 5: fam3410 G3410      1     NA     2
 6: fam3492 G3492      1     NA     2
 7: fam3834 G3834      2     NA     2
 8: fam4708 G4708     NA      2     2
 9: fam5162 G5162     NA     NA     2
10: fam5274 G5274     NA     NA     2
11: fam0637  G637     NA     NA     2
12: fam0640  G640     NA     NA     2
13: fam0743  G743     NA     NA     2
14: fam0911  G911     NA     NA     2

On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Since you have only a few troublesome NA values, if you look at them,
> or even better, post them:
>
> b[is.na(b$FLASER) | is.na(b$PLASER),]
>
> perhaps we can work out the appropriate logic to get rid of only the
> ones you don't want.
>
> Jim
>
> On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi Rasmus,
> >
> > thank you for getting back to be, the command your provided seems to
> > add all 11 NAs to 2s
> > > b$pheno <-
> > +           ifelse(b$PLASER==2 |
> > +                  b$FLASER==2 |
> > +                  is.na(b$PLASER) |
> > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > +                  is.na(b$FLASER) & b$PLASER == 2,
> > +                  2, 1)
> > >         table(b$pheno, exclude = NULL)
> >
> >   1   2
> > 859 839
> >
> > Once again my desired results is to keep these 7 NAs as NAs
> > > table(b$PLASER,b$FLASER, exclude = NULL)
> >
> >          1   2   3 <NA>
> >   1    836  14   0    0
> >   2    691  70  43    2
> >   3      2   7  21    0
> >   <NA>   4   1   0    7
> >
> > and have
> > 825 2s (825=691+14+70+7+43)
> > and the rest would be 1s (866=1698-7-825)
> >
> > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > >
> > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > >
> > > > > > I am trying to make a new column
> > > > > > "pheno" so that I reduce the number
> > > > > > of NAs
> > > > >
> > > > > it looks like those two NA values in
> > > > > PLASER are the ones you want to drop.
> > > >
> > > > From just your summary table, it's hard to
> > > > guess the distribution of NA values.
> > >
> > > Dear Ana,
> > >
> > > This small sample
> > >
> > >         b <- read.table(text="FLASER;PLASER
> > >         1;2
> > >         ;2
> > >         ;
> > >         1;
> > >         2;
> > >         2;2
> > >         3;2
> > >         3;3
> > >         1;1", sep=";", header=TRUE)
> > >
> > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > >
> > > yields the same combinations you showed
> > > earlier:
> > >
> > >                1 2 3 <NA>
> > >           1    1 0 0    0
> > >           2    1 1 1    1
> > >           3    0 0 1    0
> > >           <NA> 1 1 0    1
> > >
> > > If you want to eliminate the four <NA>-based
> > > combinations completely, this line
> > >
> > >         b$pheno <-
> > >           ifelse(b$PLASER==2 |
> > >                  b$FLASER==2 |
> > >                  is.na(b$PLASER) |
> > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > >                  is.na(b$FLASER) & b$PLASER == 2,
> > >                  2, 1)
> > >         table(b$pheno, exclude = NULL)
> > >
> > > will do it:
> > >
> > >         1 2
> > >         2 7
> > >
> > > Best,
> > > Rasmus
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jun 13 07:20:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 13 Jun 2020 06:20:44 +0100
Subject: [R] Obtaining p values from t-test run with a by function
In-Reply-To: <CAM_vju=mkUdwONAYgk=fK4Oy2XXs402rGzOnRojv7hi1xsNjFQ@mail.gmail.com>
References: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
 <CAM_vju=mkUdwONAYgk=fK4Oy2XXs402rGzOnRojv7hi1xsNjFQ@mail.gmail.com>
Message-ID: <7a18ddac-e653-9f6e-a9bf-5ca51f2c4abd@sapo.pt>

Hello,

Or in one go with *apply, function '[[':

sapply(result, '[[', 'p.value')
#         EPA            P
#2.564503e-04 4.173480e-06


Hope this helps,

Rui Barradas

?s 23:20 de 12/06/20, Sarah Goslee escreveu:
> Where you have
> 
> result[1]$p.value
> result[2]$p.value
> 
> You need
> 
> result[[1]]$p.value
> result[[2]]$p.value
> 
> to get the first component of the list.
> 
> Sarah
> 
> On Fri, Jun 12, 2020 at 5:35 PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>>
>> Colleagues,
>> I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.
>>
>> An annotated repeatable example (including data) can be found below.
>> Thank you,
>> John
>>
>>
>> # Test data
>> mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
>>             2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
>>             WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
>>             82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))
>>
>> cat("This is what mydata looks like\n")
>> mydata
>>
>> result <- by(mydata$WtBaseline,mydata$Group,t.test)
>> cat("Student's t-test run using by command\n")
>> cat("Result has results for both groups, EPA and P\n")
>> result
>>
>> cat("I can isolate the collective results for group EPA\n")
>> result[1]
>> cat("I can isolate the collective results for group P\n")
>> result[2]
>>
>> cat("I cant get the p-values for the gruops")
>> result[1]$p.value
>> result[2]$p.value
>>
>> cat("When run without by function, one can get the p value\n")
>> xxx <- t.test(WtBaseline~Group,data=mydata)
>> cat("t-test run without by fundtion\n")
>> xxx
>> cat("p value isolated from t-test run without by function\n")
>> xxx$p.value
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 11:09:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 19:09:11 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
 <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
 <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>
Message-ID: <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw@mail.gmail.com>

Right, back from shopping. Since you have fourteen rows containing NAs
and you only want seven, we can infer that half of them must go. As
they are neatly divided into seven rows in which only one NA appears
and seven in which two stare meaninglessly out at us. I will assume
that the latter are the ones to be discarded. As your condition for
calculating "pheno" stated that a 2 in either FLASER or PLASER should
result in a 2 in pheno, the following statement closely conforms to
that:

b<-read.table(text="FID   IID FLASER PLASER
  fam1837 G1837      1     NA
  fam2410 G2410     NA     NA
  fam2838 G2838     NA      2
  fam3367 G3367      1     NA
  fam3410 G3410      1     NA
  fam3492 G3492      1     NA
  fam0911  G911     NA     NA
  fam3834 G3834      2     NA
  fam4708 G4708     NA      2
  fam5162 G5162     NA     NA
  fam5274 G5274     NA     NA
  fam0637  G637     NA     NA
  fam0640  G640     NA     NA
  fam0743  G743     NA     NA
  fam0911  G911     NA     NA",
  header=TRUE,stringsAsFactors=FALSE)

b$pheno<-ifelse(b$FLASER == 2 | b$PLASER == 2,2,1)
# use the valid FLASER values when PLASER is NA
b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$FLASER),
 b[is.na(b$pheno),]$FLASER,NA)
# use the valid PLASER values when FLASER if NA
b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$PLASER),
 b[is.na(b$pheno),]$PLASER,NA)
b

I could write that mess in one straitjacket of conditional statements
but my brain hurts enough.

Jim


On Sat, Jun 13, 2020 at 1:59 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Great idea!
> Here it is:
> > b[is.na(b$FLASER) | is.na(b$PLASER),]
>         FID   IID FLASER PLASER pheno
>  1: fam1837 G1837      1     NA     2
>  2: fam2410 G2410     NA     NA     2
>  3: fam2838 G2838     NA      2     2
>  4: fam3367 G3367      1     NA     2
>  5: fam3410 G3410      1     NA     2
>  6: fam3492 G3492      1     NA     2
>  7: fam3834 G3834      2     NA     2
>  8: fam4708 G4708     NA      2     2
>  9: fam5162 G5162     NA     NA     2
> 10: fam5274 G5274     NA     NA     2
> 11: fam0637  G637     NA     NA     2
> 12: fam0640  G640     NA     NA     2
> 13: fam0743  G743     NA     NA     2
> 14: fam0911  G911     NA     NA     2
>
> On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Since you have only a few troublesome NA values, if you look at them,
> > or even better, post them:
> >
> > b[is.na(b$FLASER) | is.na(b$PLASER),]
> >
> > perhaps we can work out the appropriate logic to get rid of only the
> > ones you don't want.
> >
> > Jim
> >
> > On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hi Rasmus,
> > >
> > > thank you for getting back to be, the command your provided seems to
> > > add all 11 NAs to 2s
> > > > b$pheno <-
> > > +           ifelse(b$PLASER==2 |
> > > +                  b$FLASER==2 |
> > > +                  is.na(b$PLASER) |
> > > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > +                  is.na(b$FLASER) & b$PLASER == 2,
> > > +                  2, 1)
> > > >         table(b$pheno, exclude = NULL)
> > >
> > >   1   2
> > > 859 839
> > >
> > > Once again my desired results is to keep these 7 NAs as NAs
> > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > >
> > >          1   2   3 <NA>
> > >   1    836  14   0    0
> > >   2    691  70  43    2
> > >   3      2   7  21    0
> > >   <NA>   4   1   0    7
> > >
> > > and have
> > > 825 2s (825=691+14+70+7+43)
> > > and the rest would be 1s (866=1698-7-825)
> > >
> > > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > > >
> > > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > > >
> > > > > > > I am trying to make a new column
> > > > > > > "pheno" so that I reduce the number
> > > > > > > of NAs
> > > > > >
> > > > > > it looks like those two NA values in
> > > > > > PLASER are the ones you want to drop.
> > > > >
> > > > > From just your summary table, it's hard to
> > > > > guess the distribution of NA values.
> > > >
> > > > Dear Ana,
> > > >
> > > > This small sample
> > > >
> > > >         b <- read.table(text="FLASER;PLASER
> > > >         1;2
> > > >         ;2
> > > >         ;
> > > >         1;
> > > >         2;
> > > >         2;2
> > > >         3;2
> > > >         3;3
> > > >         1;1", sep=";", header=TRUE)
> > > >
> > > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > > >
> > > > yields the same combinations you showed
> > > > earlier:
> > > >
> > > >                1 2 3 <NA>
> > > >           1    1 0 0    0
> > > >           2    1 1 1    1
> > > >           3    0 0 1    0
> > > >           <NA> 1 1 0    1
> > > >
> > > > If you want to eliminate the four <NA>-based
> > > > combinations completely, this line
> > > >
> > > >         b$pheno <-
> > > >           ifelse(b$PLASER==2 |
> > > >                  b$FLASER==2 |
> > > >                  is.na(b$PLASER) |
> > > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > >                  is.na(b$FLASER) & b$PLASER == 2,
> > > >                  2, 1)
> > > >         table(b$pheno, exclude = NULL)
> > > >
> > > > will do it:
> > > >
> > > >         1 2
> > > >         2 7
> > > >
> > > > Best,
> > > > Rasmus
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From m@rk@@z@|@|@hu @end|ng |rom gm@||@com  Sat Jun 13 14:39:59 2020
From: m@rk@@z@|@|@hu @end|ng |rom gm@||@com (=?UTF-8?B?TcOhcmsgU3phbGFp?=)
Date: Sat, 13 Jun 2020 14:39:59 +0200
Subject: [R] if else statement adjustemtn
In-Reply-To: <mailman.359442.1.1592042401.7337.r-help@r-project.org>
References: <mailman.359442.1.1592042401.7337.r-help@r-project.org>
Message-ID: <CAA14ACwTD_kbcUMg+G3HoTCpeZJpHKn+pTH7GbOoiF_zu4BrxA@mail.gmail.com>

Dear Ana,

pmax could also fit here.
pmax(b$FLASER, b$PLASER, na.rm = TRUE)

Bests,
Mark



> ------------------------------
>
> Message: 21
> Date: Sat, 13 Jun 2020 19:09:11 +1000
> From: Jim Lemon <drjimlemon at gmail.com>
> To: sokovic.anamarija at gmail.com
> Cc: Rasmus Liland <jral at posteo.no>, r-help <r-help at r-project.org>
> Subject: Re: [R] if else statement adjustemtn
> Message-ID:
>         <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Right, back from shopping. Since you have fourteen rows containing NAs
> and you only want seven, we can infer that half of them must go. As
> they are neatly divided into seven rows in which only one NA appears
> and seven in which two stare meaninglessly out at us. I will assume
> that the latter are the ones to be discarded. As your condition for
> calculating "pheno" stated that a 2 in either FLASER or PLASER should
> result in a 2 in pheno, the following statement closely conforms to
> that:
>
> b<-read.table(text="FID   IID FLASER PLASER
>   fam1837 G1837      1     NA
>   fam2410 G2410     NA     NA
>   fam2838 G2838     NA      2
>   fam3367 G3367      1     NA
>   fam3410 G3410      1     NA
>   fam3492 G3492      1     NA
>   fam0911  G911     NA     NA
>   fam3834 G3834      2     NA
>   fam4708 G4708     NA      2
>   fam5162 G5162     NA     NA
>   fam5274 G5274     NA     NA
>   fam0637  G637     NA     NA
>   fam0640  G640     NA     NA
>   fam0743  G743     NA     NA
>   fam0911  G911     NA     NA",
>   header=TRUE,stringsAsFactors=FALSE)
>
> b$pheno<-ifelse(b$FLASER == 2 | b$PLASER == 2,2,1)
> # use the valid FLASER values when PLASER is NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$FLASER),
>  b[is.na(b$pheno),]$FLASER,NA)
> # use the valid PLASER values when FLASER if NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$PLASER),
>  b[is.na(b$pheno),]$PLASER,NA)
> b
>
> I could write that mess in one straitjacket of conditional statements
> but my brain hurts enough.
>
> Jim
>
>
> On Sat, Jun 13, 2020 at 1:59 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Great idea!
> > Here it is:
> > > b[is.na(b$FLASER) | is.na(b$PLASER),]
> >         FID   IID FLASER PLASER pheno
> >  1: fam1837 G1837      1     NA     2
> >  2: fam2410 G2410     NA     NA     2
> >  3: fam2838 G2838     NA      2     2
> >  4: fam3367 G3367      1     NA     2
> >  5: fam3410 G3410      1     NA     2
> >  6: fam3492 G3492      1     NA     2
> >  7: fam3834 G3834      2     NA     2
> >  8: fam4708 G4708     NA      2     2
> >  9: fam5162 G5162     NA     NA     2
> > 10: fam5274 G5274     NA     NA     2
> > 11: fam0637  G637     NA     NA     2
> > 12: fam0640  G640     NA     NA     2
> > 13: fam0743  G743     NA     NA     2
> > 14: fam0911  G911     NA     NA     2
> >
> > On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Since you have only a few troublesome NA values, if you look at them,
> > > or even better, post them:
> > >
> > > b[is.na(b$FLASER) | is.na(b$PLASER),]
> > >
> > > perhaps we can work out the appropriate logic to get rid of only the
> > > ones you don't want.
> > >
> > > Jim
> > >
> > > On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > >
> > > > Hi Rasmus,
> > > >
> > > > thank you for getting back to be, the command your provided seems to
> > > > add all 11 NAs to 2s
> > > > > b$pheno <-
> > > > +           ifelse(b$PLASER==2 |
> > > > +                  b$FLASER==2 |
> > > > +                  is.na(b$PLASER) |
> > > > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > > +                  is.na(b$FLASER) & b$PLASER == 2,
> > > > +                  2, 1)
> > > > >         table(b$pheno, exclude = NULL)
> > > >
> > > >   1   2
> > > > 859 839
> > > >
> > > > Once again my desired results is to keep these 7 NAs as NAs
> > > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > > >
> > > >          1   2   3 <NA>
> > > >   1    836  14   0    0
> > > >   2    691  70  43    2
> > > >   3      2   7  21    0
> > > >   <NA>   4   1   0    7
> > > >
> > > > and have
> > > > 825 2s (825=691+14+70+7+43)
> > > > and the rest would be 1s (866=1698-7-825)
> > > >
> > > > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > > > >
> > > > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > > > >
> > > > > > > > I am trying to make a new column
> > > > > > > > "pheno" so that I reduce the number
> > > > > > > > of NAs
> > > > > > >
> > > > > > > it looks like those two NA values in
> > > > > > > PLASER are the ones you want to drop.
> > > > > >
> > > > > > From just your summary table, it's hard to
> > > > > > guess the distribution of NA values.
> > > > >
> > > > > Dear Ana,
> > > > >
> > > > > This small sample
> > > > >
> > > > >         b <- read.table(text="FLASER;PLASER
> > > > >         1;2
> > > > >         ;2
> > > > >         ;
> > > > >         1;
> > > > >         2;
> > > > >         2;2
> > > > >         3;2
> > > > >         3;3
> > > > >         1;1", sep=";", header=TRUE)
> > > > >
> > > > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > > > >
> > > > > yields the same combinations you showed
> > > > > earlier:
> > > > >
> > > > >                1 2 3 <NA>
> > > > >           1    1 0 0    0
> > > > >           2    1 1 1    1
> > > > >           3    0 0 1    0
> > > > >           <NA> 1 1 0    1
> > > > >
> > > > > If you want to eliminate the four <NA>-based
> > > > > combinations completely, this line
> > > > >
> > > > >         b$pheno <-
> > > > >           ifelse(b$PLASER==2 |
> > > > >                  b$FLASER==2 |
> > > > >                  is.na(b$PLASER) |
> > > > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > > >                  is.na(b$FLASER) & b$PLASER == 2,
> > > > >                  2, 1)
> > > > >         table(b$pheno, exclude = NULL)
> > > > >
> > > > > will do it:
> > > > >
> > > > >         1 2
> > > > >         2 7
> > > > >
> > > > > Best,
> > > > > Rasmus
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From bennet @end|ng |rom um|ch@edu  Sat Jun 13 19:13:15 2020
From: bennet @end|ng |rom um|ch@edu (Bennet Fauber)
Date: Sat, 13 Jun 2020 13:13:15 -0400
Subject: [R] rgdal errors from proj
Message-ID: <CAB2ovotcvr9SQXwXGCN2neCAOZcVLWty6HqvUhf7GoCVa=fapg@mail.gmail.com>

I am trying to install rgdal from source on CentOS 7.

I have installed geos, proj, and gdal successfully, they test fine.

This is with R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
compiled with gcc/8.2.0.

This is an HPC system, and I have the following modules loaded,

Currently Loaded Modules:
  1) gcc/8.2.0   3) image-libraries/190711.1   5) proj/6.2.1
  2) R/3.6.3     4) geos/3.8.1                 6) gdal/3.1.0

I get the output included below.  In that output, it appears that the
configure correctly identifies the proj options needed from
pkg-config, repeated here

configure: pkg-config proj exists, will use it
configure: PROJ version: 6.2.1
configure: proj CPP flags: -DPROJ_H_API
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj

and

$ nm /sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib/libproj.so | grep
proj_context_create
00000000001ef4e0 T proj_context_create

seems to indicate that is truly there.

I unpacked the rgdal source tar ball and ran ./configure from its
directory and get the same error.  Looking in the generated
config.log, I find

configure:3869: checking for proj_context_create in -lproj
configure:3894: gcc -o conftest -O3 -mtune=native -I/usr/local/include
-DPROJ_H_API -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
-L/usr/local/lib64 conftest.c -lproj
-L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal >&5
/usr/bin/ld: cannot find -lproj

and from that, it appears that configure is not including the correct
CFLAGS to include proj.  It is, instead, putting in
-L/usr/local/lib64, and that is not where the proj libraries are.

Extracting the confdefs.h and conftest.c file from config.log and
running the test compilation command modified by hand to include the
correct library directory for proj,

$ gcc -o conftest -O3 -mtune=native -I/usr/local/include -DPROJ_H_API
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
-L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib conftest.c -lproj
-L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal
$ echo $?
0

So, I believe there is an error in configure.ac, or in the included
configure script that is not properly registering the library path for
proj.  Note, also, that I get the same result if using

$ ./configure --with-proj-include=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
\
    --with-proj-lib=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib \
    --with-proj-share=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/share/proj
. . . .
configure: error: proj_context_create not found in libproj.

Might anyone know what needs to be done to fix this?

Thanks,    -- bennet

Full output of install.packages('rgdal')
#----------------------------------------------
> install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repo="https:Warning: unable to access index for repository https:repo.miserver.it.umich.edu/cran/src/contrib:
> install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repos="https://repo.miserver.it.umich.edu/cran/")
trying URL 'https://repo.miserver.it.umich.edu/cran/src/contrib/rgdal_1.5-10.tar.gz'
Content type 'application/octet-stream' length 2300923 bytes (2.2 MB)
==================================================
downloaded 2.2 MB

* installing *source* package ?rgdal? ...
** package ?rgdal? successfully unpacked and MD5 sums checked
** using staged installation
configure: R_HOME: /sw/arcts/centos7/R/3.6.3/lib64/R
configure: CC: gcc
configure: CXX: g++ -std=gnu++11
configure: CXX11 is: g++, CXX11STD is: -std=gnu++11
configure: CXX is: g++ -std=gnu++11
configure: C++11 support available
configure: rgdal: 1.5-10
checking for /usr/bin/svnversion... yes
configure: svn revision: 1006
checking for gdal-config...
/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 3.1.0
checking GDAL version >= 1.11.4... yes
checking GDAL version <= 2.5 or >= 3.0... yes
checking gdal: linking with --libs only... yes
checking GDAL: gdal-config data directory readable... yes
checking GDAL: /sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/share/gdal/stateplane.csv
readable... yes
configure: pkg-config proj exists, will use it
configure: PROJ version: 6.2.1
configure: proj CPP flags: -DPROJ_H_API
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
checking PROJ header API:... yes
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -E
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking proj.h usability... yes
checking proj.h presence... yes
checking for proj.h... yes
checking for proj_context_create in -lproj... no
configure: error: proj_context_create not found in libproj.
ERROR: configuration failed for package ?rgdal?


From bennet @end|ng |rom um|ch@edu  Sun Jun 14 00:51:03 2020
From: bennet @end|ng |rom um|ch@edu (Bennet Fauber)
Date: Sat, 13 Jun 2020 18:51:03 -0400
Subject: [R] rgdal errors from proj
In-Reply-To: <CAB2ovotcvr9SQXwXGCN2neCAOZcVLWty6HqvUhf7GoCVa=fapg@mail.gmail.com>
References: <CAB2ovotcvr9SQXwXGCN2neCAOZcVLWty6HqvUhf7GoCVa=fapg@mail.gmail.com>
Message-ID: <CAB2ovot7PuPUJ3H8XvnxBVVfDBrk3O_5_K4hVtYMYOzKEydd=A@mail.gmail.com>

After doing some experimentation,  I find that making the following
change to configure.ac and running autoreconf produces a configure
script that does not error.

*** configure.ac.original    2020-06-13 15:23:43.865733311 -0400
--- configure.ac    2020-06-13 15:25:05.455499480 -0400
***************
*** 397,402 ****
--- 397,404 ----
    fi # proj_config_ok
  fi # proj_lib_path

+ LIBS="${PKG_LIBS} ${LIBS}"
+
  AC_MSG_NOTICE([PROJ LIBS: ${PKG_LIBS}])

and leads to

checking for proj.h... yes
checking for proj_context_create in -lproj... yes
checking Using GDAL < 3 with PROJ >= 6... no
checking PROJ version >= 4.8.0... yes
checking PROJ: proj.db found and readable... yes
configure: Package CPP flags:
-I/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/include
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include   -DPROJ_H_API
configure: Package LIBS:  -L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib
-lgdal -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
configure: creating ./config.status
config.status: creating src/Makevars

In config.log, this shows

configure:3871: checking for proj_context_create in -lproj
configure:3896: gcc -o conftest -O3 -mtune=native -I/usr/local/include
-DPROJ_H_API -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
-L/usr/local/lib64 conftest.c -lproj
-L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
-L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal >&5
configure:3896: $? = 0
configure:3905: result: yes

I am unable to find a repository to which I can submit this for
consideration as a patch.



On Sat, Jun 13, 2020 at 1:13 PM Bennet Fauber <bennet at umich.edu> wrote:
>
> I am trying to install rgdal from source on CentOS 7.
>
> I have installed geos, proj, and gdal successfully, they test fine.
>
> This is with R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
> compiled with gcc/8.2.0.
>
> This is an HPC system, and I have the following modules loaded,
>
> Currently Loaded Modules:
>   1) gcc/8.2.0   3) image-libraries/190711.1   5) proj/6.2.1
>   2) R/3.6.3     4) geos/3.8.1                 6) gdal/3.1.0
>
> I get the output included below.  In that output, it appears that the
> configure correctly identifies the proj options needed from
> pkg-config, repeated here
>
> configure: pkg-config proj exists, will use it
> configure: PROJ version: 6.2.1
> configure: proj CPP flags: -DPROJ_H_API
> -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
>
> and
>
> $ nm /sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib/libproj.so | grep
> proj_context_create
> 00000000001ef4e0 T proj_context_create
>
> seems to indicate that is truly there.
>
> I unpacked the rgdal source tar ball and ran ./configure from its
> directory and get the same error.  Looking in the generated
> config.log, I find
>
> configure:3869: checking for proj_context_create in -lproj
> configure:3894: gcc -o conftest -O3 -mtune=native -I/usr/local/include
> -DPROJ_H_API -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> -L/usr/local/lib64 conftest.c -lproj
> -L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal >&5
> /usr/bin/ld: cannot find -lproj
>
> and from that, it appears that configure is not including the correct
> CFLAGS to include proj.  It is, instead, putting in
> -L/usr/local/lib64, and that is not where the proj libraries are.
>
> Extracting the confdefs.h and conftest.c file from config.log and
> running the test compilation command modified by hand to include the
> correct library directory for proj,
>
> $ gcc -o conftest -O3 -mtune=native -I/usr/local/include -DPROJ_H_API
> -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib conftest.c -lproj
> -L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal
> $ echo $?
> 0
>
> So, I believe there is an error in configure.ac, or in the included
> configure script that is not properly registering the library path for
> proj.  Note, also, that I get the same result if using
>
> $ ./configure --with-proj-include=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> \
>     --with-proj-lib=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib \
>     --with-proj-share=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/share/proj
> . . . .
> configure: error: proj_context_create not found in libproj.
>
> Might anyone know what needs to be done to fix this?
>
> Thanks,    -- bennet
>
> Full output of install.packages('rgdal')
> #----------------------------------------------
> > install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repo="https:Warning: unable to access index for repository https:repo.miserver.it.umich.edu/cran/src/contrib:
> > install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repos="https://repo.miserver.it.umich.edu/cran/")
> trying URL 'https://repo.miserver.it.umich.edu/cran/src/contrib/rgdal_1.5-10.tar.gz'
> Content type 'application/octet-stream' length 2300923 bytes (2.2 MB)
> ==================================================
> downloaded 2.2 MB
>
> * installing *source* package ?rgdal? ...
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> ** using staged installation
> configure: R_HOME: /sw/arcts/centos7/R/3.6.3/lib64/R
> configure: CC: gcc
> configure: CXX: g++ -std=gnu++11
> configure: CXX11 is: g++, CXX11STD is: -std=gnu++11
> configure: CXX is: g++ -std=gnu++11
> configure: C++11 support available
> configure: rgdal: 1.5-10
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 1006
> checking for gdal-config...
> /sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 3.1.0
> checking GDAL version >= 1.11.4... yes
> checking GDAL version <= 2.5 or >= 3.0... yes
> checking gdal: linking with --libs only... yes
> checking GDAL: gdal-config data directory readable... yes
> checking GDAL: /sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/share/gdal/stateplane.csv
> readable... yes
> configure: pkg-config proj exists, will use it
> configure: PROJ version: 6.2.1
> configure: proj CPP flags: -DPROJ_H_API
> -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
> checking PROJ header API:... yes
> checking for gcc... gcc
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking proj.h usability... yes
> checking proj.h presence... yes
> checking for proj.h... yes
> checking for proj_context_create in -lproj... no
> configure: error: proj_context_create not found in libproj.
> ERROR: configuration failed for package ?rgdal?


